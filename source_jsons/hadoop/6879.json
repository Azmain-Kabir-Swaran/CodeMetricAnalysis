{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "INodeDirectory.java",
  "functionName": "computeContentSummary",
  "functionId": "computeContentSummary___snapshotId-int__summary-ContentSummaryComputationContext",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeDirectory.java",
  "functionStartLine": 686,
  "functionEndLine": 706,
  "numCommitsSeen": 337,
  "timeTaken": 7374,
  "changeHistory": [
    "f413ee33df301659c4ca9024380c2354983dcc84",
    "a1f12bb543778ddc243205eaa962e99da4d8f135",
    "a29fe100b3c671954b759add5923a2b44af9e6a4",
    "b8b69d797aed8dfeb65ea462c2856f62e9aa1023",
    "6a38d118d86b7907009bcec34f1b788d076f1d1c",
    "e52d6e7a46ceef74dd8d8a3d49c49420e3271365",
    "f0efea490e5aa9dd629d2199aae9c5b1290a17ee",
    "3f4275310203de4ccfb15337f3c503e25408a265",
    "5dae97a584d30cef3e34141edfaca49c4ec57913",
    "28051e415591b8e33dbe954f65230ede23b11683",
    "44a6560b5da3f79d2299579a36e7a2a60a91f823",
    "82ff2d3f2e569879500d851f4d67dfa2d02b5c9b",
    "fe67e30bc2794e7ff073cf938ee80eba805d1e69"
  ],
  "changeHistoryShort": {
    "f413ee33df301659c4ca9024380c2354983dcc84": "Yexceptionschange",
    "a1f12bb543778ddc243205eaa962e99da4d8f135": "Yexceptionschange",
    "a29fe100b3c671954b759add5923a2b44af9e6a4": "Yexceptionschange",
    "b8b69d797aed8dfeb65ea462c2856f62e9aa1023": "Ybodychange",
    "6a38d118d86b7907009bcec34f1b788d076f1d1c": "Ybodychange",
    "e52d6e7a46ceef74dd8d8a3d49c49420e3271365": "Ybodychange",
    "f0efea490e5aa9dd629d2199aae9c5b1290a17ee": "Ybodychange",
    "3f4275310203de4ccfb15337f3c503e25408a265": "Ymultichange(Yparameterchange,Ybodychange)",
    "5dae97a584d30cef3e34141edfaca49c4ec57913": "Ybodychange",
    "28051e415591b8e33dbe954f65230ede23b11683": "Ybodychange",
    "44a6560b5da3f79d2299579a36e7a2a60a91f823": "Ybodychange",
    "82ff2d3f2e569879500d851f4d67dfa2d02b5c9b": "Ybodychange",
    "fe67e30bc2794e7ff073cf938ee80eba805d1e69": "Ymultichange(Yparameterchange,Yreturntypechange,Ybodychange)"
  },
  "changeHistoryDetails": {
    "f413ee33df301659c4ca9024380c2354983dcc84": {
      "type": "Yexceptionschange",
      "commitMessage": "HDFS-12130. Optimizing permission check for getContentSummary.  Contributed by  Chen Liang\n",
      "commitDate": "14/07/17 2:35 PM",
      "commitName": "f413ee33df301659c4ca9024380c2354983dcc84",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "14/07/17 2:34 PM",
      "commitNameOld": "a1f12bb543778ddc243205eaa962e99da4d8f135",
      "commitAuthorOld": "Tsz-Wo Nicholas Sze",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,21 @@\n   public ContentSummaryComputationContext computeContentSummary(int snapshotId,\n-      ContentSummaryComputationContext summary) {\n+      ContentSummaryComputationContext summary) throws AccessControlException {\n     final DirectoryWithSnapshotFeature sf \u003d getDirectoryWithSnapshotFeature();\n     if (sf !\u003d null \u0026\u0026 snapshotId \u003d\u003d Snapshot.CURRENT_STATE_ID) {\n       final ContentCounts counts \u003d new ContentCounts.Builder().build();\n       // if the getContentSummary call is against a non-snapshot path, the\n       // computation should include all the deleted files/directories\n       sf.computeContentSummary4Snapshot(summary.getBlockStoragePolicySuite(),\n           counts);\n       summary.getCounts().addContents(counts);\n       // Also add ContentSummary to snapshotCounts (So we can extract it\n       // later from the ContentSummary of all).\n       summary.getSnapshotCounts().addContents(counts);\n     }\n     final DirectoryWithQuotaFeature q \u003d getDirectoryWithQuotaFeature();\n     if (q !\u003d null \u0026\u0026 snapshotId \u003d\u003d Snapshot.CURRENT_STATE_ID) {\n       return q.computeContentSummary(this, summary);\n     } else {\n       return computeDirectoryContentSummary(summary, snapshotId);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ContentSummaryComputationContext computeContentSummary(int snapshotId,\n      ContentSummaryComputationContext summary) throws AccessControlException {\n    final DirectoryWithSnapshotFeature sf \u003d getDirectoryWithSnapshotFeature();\n    if (sf !\u003d null \u0026\u0026 snapshotId \u003d\u003d Snapshot.CURRENT_STATE_ID) {\n      final ContentCounts counts \u003d new ContentCounts.Builder().build();\n      // if the getContentSummary call is against a non-snapshot path, the\n      // computation should include all the deleted files/directories\n      sf.computeContentSummary4Snapshot(summary.getBlockStoragePolicySuite(),\n          counts);\n      summary.getCounts().addContents(counts);\n      // Also add ContentSummary to snapshotCounts (So we can extract it\n      // later from the ContentSummary of all).\n      summary.getSnapshotCounts().addContents(counts);\n    }\n    final DirectoryWithQuotaFeature q \u003d getDirectoryWithQuotaFeature();\n    if (q !\u003d null \u0026\u0026 snapshotId \u003d\u003d Snapshot.CURRENT_STATE_ID) {\n      return q.computeContentSummary(this, summary);\n    } else {\n      return computeDirectoryContentSummary(summary, snapshotId);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeDirectory.java",
      "extendedDetails": {
        "oldValue": "[]",
        "newValue": "[AccessControlException]"
      }
    },
    "a1f12bb543778ddc243205eaa962e99da4d8f135": {
      "type": "Yexceptionschange",
      "commitMessage": "Revert \"HDFS-12130. Optimizing permission check for getContentSummary.\" to fix commit message.\n\nThis reverts commit a29fe100b3c671954b759add5923a2b44af9e6a4.\n",
      "commitDate": "14/07/17 2:34 PM",
      "commitName": "a1f12bb543778ddc243205eaa962e99da4d8f135",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "14/07/17 1:36 PM",
      "commitNameOld": "a29fe100b3c671954b759add5923a2b44af9e6a4",
      "commitAuthorOld": "Tsz-Wo Nicholas Sze",
      "daysBetweenCommits": 0.04,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,21 @@\n   public ContentSummaryComputationContext computeContentSummary(int snapshotId,\n-      ContentSummaryComputationContext summary) throws AccessControlException {\n+      ContentSummaryComputationContext summary) {\n     final DirectoryWithSnapshotFeature sf \u003d getDirectoryWithSnapshotFeature();\n     if (sf !\u003d null \u0026\u0026 snapshotId \u003d\u003d Snapshot.CURRENT_STATE_ID) {\n       final ContentCounts counts \u003d new ContentCounts.Builder().build();\n       // if the getContentSummary call is against a non-snapshot path, the\n       // computation should include all the deleted files/directories\n       sf.computeContentSummary4Snapshot(summary.getBlockStoragePolicySuite(),\n           counts);\n       summary.getCounts().addContents(counts);\n       // Also add ContentSummary to snapshotCounts (So we can extract it\n       // later from the ContentSummary of all).\n       summary.getSnapshotCounts().addContents(counts);\n     }\n     final DirectoryWithQuotaFeature q \u003d getDirectoryWithQuotaFeature();\n     if (q !\u003d null \u0026\u0026 snapshotId \u003d\u003d Snapshot.CURRENT_STATE_ID) {\n       return q.computeContentSummary(this, summary);\n     } else {\n       return computeDirectoryContentSummary(summary, snapshotId);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ContentSummaryComputationContext computeContentSummary(int snapshotId,\n      ContentSummaryComputationContext summary) {\n    final DirectoryWithSnapshotFeature sf \u003d getDirectoryWithSnapshotFeature();\n    if (sf !\u003d null \u0026\u0026 snapshotId \u003d\u003d Snapshot.CURRENT_STATE_ID) {\n      final ContentCounts counts \u003d new ContentCounts.Builder().build();\n      // if the getContentSummary call is against a non-snapshot path, the\n      // computation should include all the deleted files/directories\n      sf.computeContentSummary4Snapshot(summary.getBlockStoragePolicySuite(),\n          counts);\n      summary.getCounts().addContents(counts);\n      // Also add ContentSummary to snapshotCounts (So we can extract it\n      // later from the ContentSummary of all).\n      summary.getSnapshotCounts().addContents(counts);\n    }\n    final DirectoryWithQuotaFeature q \u003d getDirectoryWithQuotaFeature();\n    if (q !\u003d null \u0026\u0026 snapshotId \u003d\u003d Snapshot.CURRENT_STATE_ID) {\n      return q.computeContentSummary(this, summary);\n    } else {\n      return computeDirectoryContentSummary(summary, snapshotId);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeDirectory.java",
      "extendedDetails": {
        "oldValue": "[AccessControlException]",
        "newValue": "[]"
      }
    },
    "a29fe100b3c671954b759add5923a2b44af9e6a4": {
      "type": "Yexceptionschange",
      "commitMessage": "HDFS-12130. Optimizing permission check for getContentSummary.\n",
      "commitDate": "14/07/17 1:36 PM",
      "commitName": "a29fe100b3c671954b759add5923a2b44af9e6a4",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "30/06/17 10:28 AM",
      "commitNameOld": "bcba844d1144cc334e2babbc34c9d42eac1c203a",
      "commitAuthorOld": "Wei-Chiu Chuang",
      "daysBetweenCommits": 14.13,
      "commitsBetweenForRepo": 54,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,21 @@\n   public ContentSummaryComputationContext computeContentSummary(int snapshotId,\n-      ContentSummaryComputationContext summary) {\n+      ContentSummaryComputationContext summary) throws AccessControlException {\n     final DirectoryWithSnapshotFeature sf \u003d getDirectoryWithSnapshotFeature();\n     if (sf !\u003d null \u0026\u0026 snapshotId \u003d\u003d Snapshot.CURRENT_STATE_ID) {\n       final ContentCounts counts \u003d new ContentCounts.Builder().build();\n       // if the getContentSummary call is against a non-snapshot path, the\n       // computation should include all the deleted files/directories\n       sf.computeContentSummary4Snapshot(summary.getBlockStoragePolicySuite(),\n           counts);\n       summary.getCounts().addContents(counts);\n       // Also add ContentSummary to snapshotCounts (So we can extract it\n       // later from the ContentSummary of all).\n       summary.getSnapshotCounts().addContents(counts);\n     }\n     final DirectoryWithQuotaFeature q \u003d getDirectoryWithQuotaFeature();\n     if (q !\u003d null \u0026\u0026 snapshotId \u003d\u003d Snapshot.CURRENT_STATE_ID) {\n       return q.computeContentSummary(this, summary);\n     } else {\n       return computeDirectoryContentSummary(summary, snapshotId);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ContentSummaryComputationContext computeContentSummary(int snapshotId,\n      ContentSummaryComputationContext summary) throws AccessControlException {\n    final DirectoryWithSnapshotFeature sf \u003d getDirectoryWithSnapshotFeature();\n    if (sf !\u003d null \u0026\u0026 snapshotId \u003d\u003d Snapshot.CURRENT_STATE_ID) {\n      final ContentCounts counts \u003d new ContentCounts.Builder().build();\n      // if the getContentSummary call is against a non-snapshot path, the\n      // computation should include all the deleted files/directories\n      sf.computeContentSummary4Snapshot(summary.getBlockStoragePolicySuite(),\n          counts);\n      summary.getCounts().addContents(counts);\n      // Also add ContentSummary to snapshotCounts (So we can extract it\n      // later from the ContentSummary of all).\n      summary.getSnapshotCounts().addContents(counts);\n    }\n    final DirectoryWithQuotaFeature q \u003d getDirectoryWithQuotaFeature();\n    if (q !\u003d null \u0026\u0026 snapshotId \u003d\u003d Snapshot.CURRENT_STATE_ID) {\n      return q.computeContentSummary(this, summary);\n    } else {\n      return computeDirectoryContentSummary(summary, snapshotId);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeDirectory.java",
      "extendedDetails": {
        "oldValue": "[]",
        "newValue": "[AccessControlException]"
      }
    },
    "b8b69d797aed8dfeb65ea462c2856f62e9aa1023": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-10797. Disk usage summary of snapshots causes renamed blocks to get counted twice. Contributed by Sean Mackrory.\"\n\nThis reverts commit 6a38d118d86b7907009bcec34f1b788d076f1d1c.\n",
      "commitDate": "24/05/17 5:21 PM",
      "commitName": "b8b69d797aed8dfeb65ea462c2856f62e9aa1023",
      "commitAuthor": "Wei-Chiu Chuang",
      "commitDateOld": "21/04/17 8:35 PM",
      "commitNameOld": "20e3ae260b40cd6ef657b2a629a02219d68f162f",
      "commitAuthorOld": "Yongjun Zhang",
      "daysBetweenCommits": 32.86,
      "commitsBetweenForRepo": 175,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,21 @@\n   public ContentSummaryComputationContext computeContentSummary(int snapshotId,\n       ContentSummaryComputationContext summary) {\n-    summary.nodeIncluded(this);\n     final DirectoryWithSnapshotFeature sf \u003d getDirectoryWithSnapshotFeature();\n     if (sf !\u003d null \u0026\u0026 snapshotId \u003d\u003d Snapshot.CURRENT_STATE_ID) {\n-      sf.computeContentSummary4Snapshot(summary);\n+      final ContentCounts counts \u003d new ContentCounts.Builder().build();\n+      // if the getContentSummary call is against a non-snapshot path, the\n+      // computation should include all the deleted files/directories\n+      sf.computeContentSummary4Snapshot(summary.getBlockStoragePolicySuite(),\n+          counts);\n+      summary.getCounts().addContents(counts);\n+      // Also add ContentSummary to snapshotCounts (So we can extract it\n+      // later from the ContentSummary of all).\n+      summary.getSnapshotCounts().addContents(counts);\n     }\n     final DirectoryWithQuotaFeature q \u003d getDirectoryWithQuotaFeature();\n     if (q !\u003d null \u0026\u0026 snapshotId \u003d\u003d Snapshot.CURRENT_STATE_ID) {\n       return q.computeContentSummary(this, summary);\n     } else {\n       return computeDirectoryContentSummary(summary, snapshotId);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ContentSummaryComputationContext computeContentSummary(int snapshotId,\n      ContentSummaryComputationContext summary) {\n    final DirectoryWithSnapshotFeature sf \u003d getDirectoryWithSnapshotFeature();\n    if (sf !\u003d null \u0026\u0026 snapshotId \u003d\u003d Snapshot.CURRENT_STATE_ID) {\n      final ContentCounts counts \u003d new ContentCounts.Builder().build();\n      // if the getContentSummary call is against a non-snapshot path, the\n      // computation should include all the deleted files/directories\n      sf.computeContentSummary4Snapshot(summary.getBlockStoragePolicySuite(),\n          counts);\n      summary.getCounts().addContents(counts);\n      // Also add ContentSummary to snapshotCounts (So we can extract it\n      // later from the ContentSummary of all).\n      summary.getSnapshotCounts().addContents(counts);\n    }\n    final DirectoryWithQuotaFeature q \u003d getDirectoryWithQuotaFeature();\n    if (q !\u003d null \u0026\u0026 snapshotId \u003d\u003d Snapshot.CURRENT_STATE_ID) {\n      return q.computeContentSummary(this, summary);\n    } else {\n      return computeDirectoryContentSummary(summary, snapshotId);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeDirectory.java",
      "extendedDetails": {}
    },
    "6a38d118d86b7907009bcec34f1b788d076f1d1c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10797. Disk usage summary of snapshots causes renamed blocks to get counted twice. Contributed by Sean Mackrory.\n",
      "commitDate": "07/10/16 5:37 PM",
      "commitName": "6a38d118d86b7907009bcec34f1b788d076f1d1c",
      "commitAuthor": "Xiao Chen",
      "commitDateOld": "19/09/16 9:44 PM",
      "commitNameOld": "e52d6e7a46ceef74dd8d8a3d49c49420e3271365",
      "commitAuthorOld": "Xiao Chen",
      "daysBetweenCommits": 17.83,
      "commitsBetweenForRepo": 133,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,14 @@\n   public ContentSummaryComputationContext computeContentSummary(int snapshotId,\n       ContentSummaryComputationContext summary) {\n+    summary.nodeIncluded(this);\n     final DirectoryWithSnapshotFeature sf \u003d getDirectoryWithSnapshotFeature();\n     if (sf !\u003d null \u0026\u0026 snapshotId \u003d\u003d Snapshot.CURRENT_STATE_ID) {\n-      final ContentCounts counts \u003d new ContentCounts.Builder().build();\n-      // if the getContentSummary call is against a non-snapshot path, the\n-      // computation should include all the deleted files/directories\n-      sf.computeContentSummary4Snapshot(summary.getBlockStoragePolicySuite(),\n-          counts);\n-      summary.getCounts().addContents(counts);\n-      // Also add ContentSummary to snapshotCounts (So we can extract it\n-      // later from the ContentSummary of all).\n-      summary.getSnapshotCounts().addContents(counts);\n+      sf.computeContentSummary4Snapshot(summary);\n     }\n     final DirectoryWithQuotaFeature q \u003d getDirectoryWithQuotaFeature();\n     if (q !\u003d null \u0026\u0026 snapshotId \u003d\u003d Snapshot.CURRENT_STATE_ID) {\n       return q.computeContentSummary(this, summary);\n     } else {\n       return computeDirectoryContentSummary(summary, snapshotId);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ContentSummaryComputationContext computeContentSummary(int snapshotId,\n      ContentSummaryComputationContext summary) {\n    summary.nodeIncluded(this);\n    final DirectoryWithSnapshotFeature sf \u003d getDirectoryWithSnapshotFeature();\n    if (sf !\u003d null \u0026\u0026 snapshotId \u003d\u003d Snapshot.CURRENT_STATE_ID) {\n      sf.computeContentSummary4Snapshot(summary);\n    }\n    final DirectoryWithQuotaFeature q \u003d getDirectoryWithQuotaFeature();\n    if (q !\u003d null \u0026\u0026 snapshotId \u003d\u003d Snapshot.CURRENT_STATE_ID) {\n      return q.computeContentSummary(this, summary);\n    } else {\n      return computeDirectoryContentSummary(summary, snapshotId);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeDirectory.java",
      "extendedDetails": {}
    },
    "e52d6e7a46ceef74dd8d8a3d49c49420e3271365": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10875. Optimize du -x to cache intermediate result. Contributed by Xiao Chen.\n",
      "commitDate": "19/09/16 9:44 PM",
      "commitName": "e52d6e7a46ceef74dd8d8a3d49c49420e3271365",
      "commitAuthor": "Xiao Chen",
      "commitDateOld": "23/08/16 4:14 AM",
      "commitNameOld": "f0efea490e5aa9dd629d2199aae9c5b1290a17ee",
      "commitAuthorOld": "Wei-Chiu Chuang",
      "daysBetweenCommits": 27.73,
      "commitsBetweenForRepo": 148,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,21 @@\n   public ContentSummaryComputationContext computeContentSummary(int snapshotId,\n       ContentSummaryComputationContext summary) {\n     final DirectoryWithSnapshotFeature sf \u003d getDirectoryWithSnapshotFeature();\n     if (sf !\u003d null \u0026\u0026 snapshotId \u003d\u003d Snapshot.CURRENT_STATE_ID) {\n+      final ContentCounts counts \u003d new ContentCounts.Builder().build();\n       // if the getContentSummary call is against a non-snapshot path, the\n       // computation should include all the deleted files/directories\n       sf.computeContentSummary4Snapshot(summary.getBlockStoragePolicySuite(),\n-          summary.getCounts());\n-      // Also compute ContentSummary for snapshotCounts (So we can extract it\n+          counts);\n+      summary.getCounts().addContents(counts);\n+      // Also add ContentSummary to snapshotCounts (So we can extract it\n       // later from the ContentSummary of all).\n-      sf.computeContentSummary4Snapshot(summary.getBlockStoragePolicySuite(),\n-          summary.getSnapshotCounts());\n+      summary.getSnapshotCounts().addContents(counts);\n     }\n     final DirectoryWithQuotaFeature q \u003d getDirectoryWithQuotaFeature();\n     if (q !\u003d null \u0026\u0026 snapshotId \u003d\u003d Snapshot.CURRENT_STATE_ID) {\n       return q.computeContentSummary(this, summary);\n     } else {\n       return computeDirectoryContentSummary(summary, snapshotId);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ContentSummaryComputationContext computeContentSummary(int snapshotId,\n      ContentSummaryComputationContext summary) {\n    final DirectoryWithSnapshotFeature sf \u003d getDirectoryWithSnapshotFeature();\n    if (sf !\u003d null \u0026\u0026 snapshotId \u003d\u003d Snapshot.CURRENT_STATE_ID) {\n      final ContentCounts counts \u003d new ContentCounts.Builder().build();\n      // if the getContentSummary call is against a non-snapshot path, the\n      // computation should include all the deleted files/directories\n      sf.computeContentSummary4Snapshot(summary.getBlockStoragePolicySuite(),\n          counts);\n      summary.getCounts().addContents(counts);\n      // Also add ContentSummary to snapshotCounts (So we can extract it\n      // later from the ContentSummary of all).\n      summary.getSnapshotCounts().addContents(counts);\n    }\n    final DirectoryWithQuotaFeature q \u003d getDirectoryWithQuotaFeature();\n    if (q !\u003d null \u0026\u0026 snapshotId \u003d\u003d Snapshot.CURRENT_STATE_ID) {\n      return q.computeContentSummary(this, summary);\n    } else {\n      return computeDirectoryContentSummary(summary, snapshotId);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeDirectory.java",
      "extendedDetails": {}
    },
    "f0efea490e5aa9dd629d2199aae9c5b1290a17ee": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8986. Add option to -du to calculate directory space usage excluding snapshots. Contributed by Xiao Chen.\n",
      "commitDate": "23/08/16 4:14 AM",
      "commitName": "f0efea490e5aa9dd629d2199aae9c5b1290a17ee",
      "commitAuthor": "Wei-Chiu Chuang",
      "commitDateOld": "18/09/15 9:26 AM",
      "commitNameOld": "3f4275310203de4ccfb15337f3c503e25408a265",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 339.78,
      "commitsBetweenForRepo": 2402,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,20 @@\n   public ContentSummaryComputationContext computeContentSummary(int snapshotId,\n       ContentSummaryComputationContext summary) {\n     final DirectoryWithSnapshotFeature sf \u003d getDirectoryWithSnapshotFeature();\n     if (sf !\u003d null \u0026\u0026 snapshotId \u003d\u003d Snapshot.CURRENT_STATE_ID) {\n       // if the getContentSummary call is against a non-snapshot path, the\n       // computation should include all the deleted files/directories\n       sf.computeContentSummary4Snapshot(summary.getBlockStoragePolicySuite(),\n           summary.getCounts());\n+      // Also compute ContentSummary for snapshotCounts (So we can extract it\n+      // later from the ContentSummary of all).\n+      sf.computeContentSummary4Snapshot(summary.getBlockStoragePolicySuite(),\n+          summary.getSnapshotCounts());\n     }\n     final DirectoryWithQuotaFeature q \u003d getDirectoryWithQuotaFeature();\n     if (q !\u003d null \u0026\u0026 snapshotId \u003d\u003d Snapshot.CURRENT_STATE_ID) {\n       return q.computeContentSummary(this, summary);\n     } else {\n       return computeDirectoryContentSummary(summary, snapshotId);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ContentSummaryComputationContext computeContentSummary(int snapshotId,\n      ContentSummaryComputationContext summary) {\n    final DirectoryWithSnapshotFeature sf \u003d getDirectoryWithSnapshotFeature();\n    if (sf !\u003d null \u0026\u0026 snapshotId \u003d\u003d Snapshot.CURRENT_STATE_ID) {\n      // if the getContentSummary call is against a non-snapshot path, the\n      // computation should include all the deleted files/directories\n      sf.computeContentSummary4Snapshot(summary.getBlockStoragePolicySuite(),\n          summary.getCounts());\n      // Also compute ContentSummary for snapshotCounts (So we can extract it\n      // later from the ContentSummary of all).\n      sf.computeContentSummary4Snapshot(summary.getBlockStoragePolicySuite(),\n          summary.getSnapshotCounts());\n    }\n    final DirectoryWithQuotaFeature q \u003d getDirectoryWithQuotaFeature();\n    if (q !\u003d null \u0026\u0026 snapshotId \u003d\u003d Snapshot.CURRENT_STATE_ID) {\n      return q.computeContentSummary(this, summary);\n    } else {\n      return computeDirectoryContentSummary(summary, snapshotId);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeDirectory.java",
      "extendedDetails": {}
    },
    "3f4275310203de4ccfb15337f3c503e25408a265": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-9063. Correctly handle snapshot path for getContentSummary. Contributed by Jing Zhao.\n",
      "commitDate": "18/09/15 9:26 AM",
      "commitName": "3f4275310203de4ccfb15337f3c503e25408a265",
      "commitAuthor": "Jing Zhao",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-9063. Correctly handle snapshot path for getContentSummary. Contributed by Jing Zhao.\n",
          "commitDate": "18/09/15 9:26 AM",
          "commitName": "3f4275310203de4ccfb15337f3c503e25408a265",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "09/09/15 11:38 AM",
          "commitNameOld": "4014ce5990bff9b0ecb3d38a633d40eaf6cf07a7",
          "commitAuthorOld": "Vinayakumar B",
          "daysBetweenCommits": 8.91,
          "commitsBetweenForRepo": 66,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,14 +1,16 @@\n-  public ContentSummaryComputationContext computeContentSummary(\n+  public ContentSummaryComputationContext computeContentSummary(int snapshotId,\n       ContentSummaryComputationContext summary) {\n     final DirectoryWithSnapshotFeature sf \u003d getDirectoryWithSnapshotFeature();\n-    if (sf !\u003d null) {\n+    if (sf !\u003d null \u0026\u0026 snapshotId \u003d\u003d Snapshot.CURRENT_STATE_ID) {\n+      // if the getContentSummary call is against a non-snapshot path, the\n+      // computation should include all the deleted files/directories\n       sf.computeContentSummary4Snapshot(summary.getBlockStoragePolicySuite(),\n           summary.getCounts());\n     }\n     final DirectoryWithQuotaFeature q \u003d getDirectoryWithQuotaFeature();\n-    if (q !\u003d null) {\n+    if (q !\u003d null \u0026\u0026 snapshotId \u003d\u003d Snapshot.CURRENT_STATE_ID) {\n       return q.computeContentSummary(this, summary);\n     } else {\n-      return computeDirectoryContentSummary(summary, Snapshot.CURRENT_STATE_ID);\n+      return computeDirectoryContentSummary(summary, snapshotId);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public ContentSummaryComputationContext computeContentSummary(int snapshotId,\n      ContentSummaryComputationContext summary) {\n    final DirectoryWithSnapshotFeature sf \u003d getDirectoryWithSnapshotFeature();\n    if (sf !\u003d null \u0026\u0026 snapshotId \u003d\u003d Snapshot.CURRENT_STATE_ID) {\n      // if the getContentSummary call is against a non-snapshot path, the\n      // computation should include all the deleted files/directories\n      sf.computeContentSummary4Snapshot(summary.getBlockStoragePolicySuite(),\n          summary.getCounts());\n    }\n    final DirectoryWithQuotaFeature q \u003d getDirectoryWithQuotaFeature();\n    if (q !\u003d null \u0026\u0026 snapshotId \u003d\u003d Snapshot.CURRENT_STATE_ID) {\n      return q.computeContentSummary(this, summary);\n    } else {\n      return computeDirectoryContentSummary(summary, snapshotId);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeDirectory.java",
          "extendedDetails": {
            "oldValue": "[summary-ContentSummaryComputationContext]",
            "newValue": "[snapshotId-int, summary-ContentSummaryComputationContext]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-9063. Correctly handle snapshot path for getContentSummary. Contributed by Jing Zhao.\n",
          "commitDate": "18/09/15 9:26 AM",
          "commitName": "3f4275310203de4ccfb15337f3c503e25408a265",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "09/09/15 11:38 AM",
          "commitNameOld": "4014ce5990bff9b0ecb3d38a633d40eaf6cf07a7",
          "commitAuthorOld": "Vinayakumar B",
          "daysBetweenCommits": 8.91,
          "commitsBetweenForRepo": 66,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,14 +1,16 @@\n-  public ContentSummaryComputationContext computeContentSummary(\n+  public ContentSummaryComputationContext computeContentSummary(int snapshotId,\n       ContentSummaryComputationContext summary) {\n     final DirectoryWithSnapshotFeature sf \u003d getDirectoryWithSnapshotFeature();\n-    if (sf !\u003d null) {\n+    if (sf !\u003d null \u0026\u0026 snapshotId \u003d\u003d Snapshot.CURRENT_STATE_ID) {\n+      // if the getContentSummary call is against a non-snapshot path, the\n+      // computation should include all the deleted files/directories\n       sf.computeContentSummary4Snapshot(summary.getBlockStoragePolicySuite(),\n           summary.getCounts());\n     }\n     final DirectoryWithQuotaFeature q \u003d getDirectoryWithQuotaFeature();\n-    if (q !\u003d null) {\n+    if (q !\u003d null \u0026\u0026 snapshotId \u003d\u003d Snapshot.CURRENT_STATE_ID) {\n       return q.computeContentSummary(this, summary);\n     } else {\n-      return computeDirectoryContentSummary(summary, Snapshot.CURRENT_STATE_ID);\n+      return computeDirectoryContentSummary(summary, snapshotId);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public ContentSummaryComputationContext computeContentSummary(int snapshotId,\n      ContentSummaryComputationContext summary) {\n    final DirectoryWithSnapshotFeature sf \u003d getDirectoryWithSnapshotFeature();\n    if (sf !\u003d null \u0026\u0026 snapshotId \u003d\u003d Snapshot.CURRENT_STATE_ID) {\n      // if the getContentSummary call is against a non-snapshot path, the\n      // computation should include all the deleted files/directories\n      sf.computeContentSummary4Snapshot(summary.getBlockStoragePolicySuite(),\n          summary.getCounts());\n    }\n    final DirectoryWithQuotaFeature q \u003d getDirectoryWithQuotaFeature();\n    if (q !\u003d null \u0026\u0026 snapshotId \u003d\u003d Snapshot.CURRENT_STATE_ID) {\n      return q.computeContentSummary(this, summary);\n    } else {\n      return computeDirectoryContentSummary(summary, snapshotId);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeDirectory.java",
          "extendedDetails": {}
        }
      ]
    },
    "5dae97a584d30cef3e34141edfaca49c4ec57913": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7723. Quota By Storage Type namenode implemenation. (Contributed by Xiaoyu Yao)\n",
      "commitDate": "11/02/15 10:41 AM",
      "commitName": "5dae97a584d30cef3e34141edfaca49c4ec57913",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "02/02/15 4:32 PM",
      "commitNameOld": "8cb473124c1cf1c6f68ead7bde06558ebf7ce47e",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 8.76,
      "commitsBetweenForRepo": 109,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,14 @@\n   public ContentSummaryComputationContext computeContentSummary(\n       ContentSummaryComputationContext summary) {\n     final DirectoryWithSnapshotFeature sf \u003d getDirectoryWithSnapshotFeature();\n     if (sf !\u003d null) {\n-      sf.computeContentSummary4Snapshot(summary.getCounts());\n+      sf.computeContentSummary4Snapshot(summary.getBlockStoragePolicySuite(),\n+          summary.getCounts());\n     }\n     final DirectoryWithQuotaFeature q \u003d getDirectoryWithQuotaFeature();\n     if (q !\u003d null) {\n       return q.computeContentSummary(this, summary);\n     } else {\n       return computeDirectoryContentSummary(summary, Snapshot.CURRENT_STATE_ID);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ContentSummaryComputationContext computeContentSummary(\n      ContentSummaryComputationContext summary) {\n    final DirectoryWithSnapshotFeature sf \u003d getDirectoryWithSnapshotFeature();\n    if (sf !\u003d null) {\n      sf.computeContentSummary4Snapshot(summary.getBlockStoragePolicySuite(),\n          summary.getCounts());\n    }\n    final DirectoryWithQuotaFeature q \u003d getDirectoryWithQuotaFeature();\n    if (q !\u003d null) {\n      return q.computeContentSummary(this, summary);\n    } else {\n      return computeDirectoryContentSummary(summary, Snapshot.CURRENT_STATE_ID);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeDirectory.java",
      "extendedDetails": {}
    },
    "28051e415591b8e33dbe954f65230ede23b11683": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-6857. FsShell should report raw disk usage including replication factor. Contributed by Byron Wong.\n",
      "commitDate": "25/10/14 12:31 PM",
      "commitName": "28051e415591b8e33dbe954f65230ede23b11683",
      "commitAuthor": "Byron Wong",
      "commitDateOld": "24/09/14 10:05 AM",
      "commitNameOld": "073bbd805c6680f47bbfcc6e8efd708ad729bca4",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 31.1,
      "commitsBetweenForRepo": 295,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,13 @@\n   public ContentSummaryComputationContext computeContentSummary(\n       ContentSummaryComputationContext summary) {\n     final DirectoryWithSnapshotFeature sf \u003d getDirectoryWithSnapshotFeature();\n     if (sf !\u003d null) {\n       sf.computeContentSummary4Snapshot(summary.getCounts());\n     }\n     final DirectoryWithQuotaFeature q \u003d getDirectoryWithQuotaFeature();\n     if (q !\u003d null) {\n       return q.computeContentSummary(this, summary);\n     } else {\n-      return computeDirectoryContentSummary(summary);\n+      return computeDirectoryContentSummary(summary, Snapshot.CURRENT_STATE_ID);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ContentSummaryComputationContext computeContentSummary(\n      ContentSummaryComputationContext summary) {\n    final DirectoryWithSnapshotFeature sf \u003d getDirectoryWithSnapshotFeature();\n    if (sf !\u003d null) {\n      sf.computeContentSummary4Snapshot(summary.getCounts());\n    }\n    final DirectoryWithQuotaFeature q \u003d getDirectoryWithQuotaFeature();\n    if (q !\u003d null) {\n      return q.computeContentSummary(this, summary);\n    } else {\n      return computeDirectoryContentSummary(summary, Snapshot.CURRENT_STATE_ID);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeDirectory.java",
      "extendedDetails": {}
    },
    "44a6560b5da3f79d2299579a36e7a2a60a91f823": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5632. Flatten INodeDirectory hierarchy: Replace INodeDirectoryWithSnapshot with DirectoryWithSnapshotFeature.  Contributed by jing9 \n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1550917 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/12/13 2:13 AM",
      "commitName": "44a6560b5da3f79d2299579a36e7a2a60a91f823",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "12/12/13 10:26 AM",
      "commitNameOld": "5fd7230671bb3d90081d4138c364c3f65b35cdbc",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 1.66,
      "commitsBetweenForRepo": 12,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,9 +1,13 @@\n   public ContentSummaryComputationContext computeContentSummary(\n       ContentSummaryComputationContext summary) {\n+    final DirectoryWithSnapshotFeature sf \u003d getDirectoryWithSnapshotFeature();\n+    if (sf !\u003d null) {\n+      sf.computeContentSummary4Snapshot(summary.getCounts());\n+    }\n     final DirectoryWithQuotaFeature q \u003d getDirectoryWithQuotaFeature();\n     if (q !\u003d null) {\n       return q.computeContentSummary(this, summary);\n     } else {\n       return computeDirectoryContentSummary(summary);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ContentSummaryComputationContext computeContentSummary(\n      ContentSummaryComputationContext summary) {\n    final DirectoryWithSnapshotFeature sf \u003d getDirectoryWithSnapshotFeature();\n    if (sf !\u003d null) {\n      sf.computeContentSummary4Snapshot(summary.getCounts());\n    }\n    final DirectoryWithQuotaFeature q \u003d getDirectoryWithQuotaFeature();\n    if (q !\u003d null) {\n      return q.computeContentSummary(this, summary);\n    } else {\n      return computeDirectoryContentSummary(summary);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeDirectory.java",
      "extendedDetails": {}
    },
    "82ff2d3f2e569879500d851f4d67dfa2d02b5c9b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5286. Flatten INodeDirectory hierarchy: Replace INodeDirectoryWithQuota with DirectoryWithQuotaFeature.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1545768 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "26/11/13 10:33 AM",
      "commitName": "82ff2d3f2e569879500d851f4d67dfa2d02b5c9b",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "21/11/13 5:39 PM",
      "commitNameOld": "ce68f410b05a58ad05965f32ad7f5b246b363a75",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 4.7,
      "commitsBetweenForRepo": 12,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,40 +1,9 @@\n   public ContentSummaryComputationContext computeContentSummary(\n       ContentSummaryComputationContext summary) {\n-    ReadOnlyList\u003cINode\u003e childrenList \u003d getChildrenList(null);\n-    // Explicit traversing is done to enable repositioning after relinquishing\n-    // and reacquiring locks.\n-    for (int i \u003d 0;  i \u003c childrenList.size(); i++) {\n-      INode child \u003d childrenList.get(i);\n-      byte[] childName \u003d child.getLocalNameBytes();\n-\n-      long lastYieldCount \u003d summary.getYieldCount();\n-      child.computeContentSummary(summary);\n-\n-      // Check whether the computation was paused in the subtree.\n-      // The counts may be off, but traversing the rest of children\n-      // should be made safe.\n-      if (lastYieldCount \u003d\u003d summary.getYieldCount()) {\n-        continue;\n-      }\n-\n-      // The locks were released and reacquired. Check parent first.\n-      if (getParent() \u003d\u003d null) {\n-        // Stop further counting and return whatever we have so far.\n-        break;\n-      }\n-\n-      // Obtain the children list again since it may have been modified.\n-      childrenList \u003d getChildrenList(null);\n-      // Reposition in case the children list is changed. Decrement by 1\n-      // since it will be incremented when loops.\n-      i \u003d nextChild(childrenList, childName) - 1;\n+    final DirectoryWithQuotaFeature q \u003d getDirectoryWithQuotaFeature();\n+    if (q !\u003d null) {\n+      return q.computeContentSummary(this, summary);\n+    } else {\n+      return computeDirectoryContentSummary(summary);\n     }\n-\n-    // Increment the directory count for this directory.\n-    summary.getCounts().add(Content.DIRECTORY, 1);\n-\n-    // Relinquish and reacquire locks if necessary.\n-    summary.yield();\n-\n-    return summary;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ContentSummaryComputationContext computeContentSummary(\n      ContentSummaryComputationContext summary) {\n    final DirectoryWithQuotaFeature q \u003d getDirectoryWithQuotaFeature();\n    if (q !\u003d null) {\n      return q.computeContentSummary(this, summary);\n    } else {\n      return computeDirectoryContentSummary(summary);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeDirectory.java",
      "extendedDetails": {}
    },
    "fe67e30bc2794e7ff073cf938ee80eba805d1e69": {
      "type": "Ymultichange(Yparameterchange,Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-4995. Make getContentSummary less expensive. Contributed by Kihwal Lee.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1541971 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/11/13 8:49 AM",
      "commitName": "fe67e30bc2794e7ff073cf938ee80eba805d1e69",
      "commitAuthor": "Kihwal Lee",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-4995. Make getContentSummary less expensive. Contributed by Kihwal Lee.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1541971 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "14/11/13 8:49 AM",
          "commitName": "fe67e30bc2794e7ff073cf938ee80eba805d1e69",
          "commitAuthor": "Kihwal Lee",
          "commitDateOld": "17/07/13 5:04 PM",
          "commitNameOld": "68faa67f1b3b681b40ecdc9002d9fb508e529af4",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 119.7,
          "commitsBetweenForRepo": 751,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,7 +1,40 @@\n-  public Content.Counts computeContentSummary(final Content.Counts counts) {\n-    for (INode child : getChildrenList(null)) {\n-      child.computeContentSummary(counts);\n+  public ContentSummaryComputationContext computeContentSummary(\n+      ContentSummaryComputationContext summary) {\n+    ReadOnlyList\u003cINode\u003e childrenList \u003d getChildrenList(null);\n+    // Explicit traversing is done to enable repositioning after relinquishing\n+    // and reacquiring locks.\n+    for (int i \u003d 0;  i \u003c childrenList.size(); i++) {\n+      INode child \u003d childrenList.get(i);\n+      byte[] childName \u003d child.getLocalNameBytes();\n+\n+      long lastYieldCount \u003d summary.getYieldCount();\n+      child.computeContentSummary(summary);\n+\n+      // Check whether the computation was paused in the subtree.\n+      // The counts may be off, but traversing the rest of children\n+      // should be made safe.\n+      if (lastYieldCount \u003d\u003d summary.getYieldCount()) {\n+        continue;\n+      }\n+\n+      // The locks were released and reacquired. Check parent first.\n+      if (getParent() \u003d\u003d null) {\n+        // Stop further counting and return whatever we have so far.\n+        break;\n+      }\n+\n+      // Obtain the children list again since it may have been modified.\n+      childrenList \u003d getChildrenList(null);\n+      // Reposition in case the children list is changed. Decrement by 1\n+      // since it will be incremented when loops.\n+      i \u003d nextChild(childrenList, childName) - 1;\n     }\n-    counts.add(Content.DIRECTORY, 1);\n-    return counts;\n+\n+    // Increment the directory count for this directory.\n+    summary.getCounts().add(Content.DIRECTORY, 1);\n+\n+    // Relinquish and reacquire locks if necessary.\n+    summary.yield();\n+\n+    return summary;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public ContentSummaryComputationContext computeContentSummary(\n      ContentSummaryComputationContext summary) {\n    ReadOnlyList\u003cINode\u003e childrenList \u003d getChildrenList(null);\n    // Explicit traversing is done to enable repositioning after relinquishing\n    // and reacquiring locks.\n    for (int i \u003d 0;  i \u003c childrenList.size(); i++) {\n      INode child \u003d childrenList.get(i);\n      byte[] childName \u003d child.getLocalNameBytes();\n\n      long lastYieldCount \u003d summary.getYieldCount();\n      child.computeContentSummary(summary);\n\n      // Check whether the computation was paused in the subtree.\n      // The counts may be off, but traversing the rest of children\n      // should be made safe.\n      if (lastYieldCount \u003d\u003d summary.getYieldCount()) {\n        continue;\n      }\n\n      // The locks were released and reacquired. Check parent first.\n      if (getParent() \u003d\u003d null) {\n        // Stop further counting and return whatever we have so far.\n        break;\n      }\n\n      // Obtain the children list again since it may have been modified.\n      childrenList \u003d getChildrenList(null);\n      // Reposition in case the children list is changed. Decrement by 1\n      // since it will be incremented when loops.\n      i \u003d nextChild(childrenList, childName) - 1;\n    }\n\n    // Increment the directory count for this directory.\n    summary.getCounts().add(Content.DIRECTORY, 1);\n\n    // Relinquish and reacquire locks if necessary.\n    summary.yield();\n\n    return summary;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeDirectory.java",
          "extendedDetails": {
            "oldValue": "[counts-Content.Counts(modifiers-final)]",
            "newValue": "[summary-ContentSummaryComputationContext]"
          }
        },
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-4995. Make getContentSummary less expensive. Contributed by Kihwal Lee.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1541971 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "14/11/13 8:49 AM",
          "commitName": "fe67e30bc2794e7ff073cf938ee80eba805d1e69",
          "commitAuthor": "Kihwal Lee",
          "commitDateOld": "17/07/13 5:04 PM",
          "commitNameOld": "68faa67f1b3b681b40ecdc9002d9fb508e529af4",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 119.7,
          "commitsBetweenForRepo": 751,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,7 +1,40 @@\n-  public Content.Counts computeContentSummary(final Content.Counts counts) {\n-    for (INode child : getChildrenList(null)) {\n-      child.computeContentSummary(counts);\n+  public ContentSummaryComputationContext computeContentSummary(\n+      ContentSummaryComputationContext summary) {\n+    ReadOnlyList\u003cINode\u003e childrenList \u003d getChildrenList(null);\n+    // Explicit traversing is done to enable repositioning after relinquishing\n+    // and reacquiring locks.\n+    for (int i \u003d 0;  i \u003c childrenList.size(); i++) {\n+      INode child \u003d childrenList.get(i);\n+      byte[] childName \u003d child.getLocalNameBytes();\n+\n+      long lastYieldCount \u003d summary.getYieldCount();\n+      child.computeContentSummary(summary);\n+\n+      // Check whether the computation was paused in the subtree.\n+      // The counts may be off, but traversing the rest of children\n+      // should be made safe.\n+      if (lastYieldCount \u003d\u003d summary.getYieldCount()) {\n+        continue;\n+      }\n+\n+      // The locks were released and reacquired. Check parent first.\n+      if (getParent() \u003d\u003d null) {\n+        // Stop further counting and return whatever we have so far.\n+        break;\n+      }\n+\n+      // Obtain the children list again since it may have been modified.\n+      childrenList \u003d getChildrenList(null);\n+      // Reposition in case the children list is changed. Decrement by 1\n+      // since it will be incremented when loops.\n+      i \u003d nextChild(childrenList, childName) - 1;\n     }\n-    counts.add(Content.DIRECTORY, 1);\n-    return counts;\n+\n+    // Increment the directory count for this directory.\n+    summary.getCounts().add(Content.DIRECTORY, 1);\n+\n+    // Relinquish and reacquire locks if necessary.\n+    summary.yield();\n+\n+    return summary;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public ContentSummaryComputationContext computeContentSummary(\n      ContentSummaryComputationContext summary) {\n    ReadOnlyList\u003cINode\u003e childrenList \u003d getChildrenList(null);\n    // Explicit traversing is done to enable repositioning after relinquishing\n    // and reacquiring locks.\n    for (int i \u003d 0;  i \u003c childrenList.size(); i++) {\n      INode child \u003d childrenList.get(i);\n      byte[] childName \u003d child.getLocalNameBytes();\n\n      long lastYieldCount \u003d summary.getYieldCount();\n      child.computeContentSummary(summary);\n\n      // Check whether the computation was paused in the subtree.\n      // The counts may be off, but traversing the rest of children\n      // should be made safe.\n      if (lastYieldCount \u003d\u003d summary.getYieldCount()) {\n        continue;\n      }\n\n      // The locks were released and reacquired. Check parent first.\n      if (getParent() \u003d\u003d null) {\n        // Stop further counting and return whatever we have so far.\n        break;\n      }\n\n      // Obtain the children list again since it may have been modified.\n      childrenList \u003d getChildrenList(null);\n      // Reposition in case the children list is changed. Decrement by 1\n      // since it will be incremented when loops.\n      i \u003d nextChild(childrenList, childName) - 1;\n    }\n\n    // Increment the directory count for this directory.\n    summary.getCounts().add(Content.DIRECTORY, 1);\n\n    // Relinquish and reacquire locks if necessary.\n    summary.yield();\n\n    return summary;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeDirectory.java",
          "extendedDetails": {
            "oldValue": "Content.Counts",
            "newValue": "ContentSummaryComputationContext"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-4995. Make getContentSummary less expensive. Contributed by Kihwal Lee.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1541971 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "14/11/13 8:49 AM",
          "commitName": "fe67e30bc2794e7ff073cf938ee80eba805d1e69",
          "commitAuthor": "Kihwal Lee",
          "commitDateOld": "17/07/13 5:04 PM",
          "commitNameOld": "68faa67f1b3b681b40ecdc9002d9fb508e529af4",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 119.7,
          "commitsBetweenForRepo": 751,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,7 +1,40 @@\n-  public Content.Counts computeContentSummary(final Content.Counts counts) {\n-    for (INode child : getChildrenList(null)) {\n-      child.computeContentSummary(counts);\n+  public ContentSummaryComputationContext computeContentSummary(\n+      ContentSummaryComputationContext summary) {\n+    ReadOnlyList\u003cINode\u003e childrenList \u003d getChildrenList(null);\n+    // Explicit traversing is done to enable repositioning after relinquishing\n+    // and reacquiring locks.\n+    for (int i \u003d 0;  i \u003c childrenList.size(); i++) {\n+      INode child \u003d childrenList.get(i);\n+      byte[] childName \u003d child.getLocalNameBytes();\n+\n+      long lastYieldCount \u003d summary.getYieldCount();\n+      child.computeContentSummary(summary);\n+\n+      // Check whether the computation was paused in the subtree.\n+      // The counts may be off, but traversing the rest of children\n+      // should be made safe.\n+      if (lastYieldCount \u003d\u003d summary.getYieldCount()) {\n+        continue;\n+      }\n+\n+      // The locks were released and reacquired. Check parent first.\n+      if (getParent() \u003d\u003d null) {\n+        // Stop further counting and return whatever we have so far.\n+        break;\n+      }\n+\n+      // Obtain the children list again since it may have been modified.\n+      childrenList \u003d getChildrenList(null);\n+      // Reposition in case the children list is changed. Decrement by 1\n+      // since it will be incremented when loops.\n+      i \u003d nextChild(childrenList, childName) - 1;\n     }\n-    counts.add(Content.DIRECTORY, 1);\n-    return counts;\n+\n+    // Increment the directory count for this directory.\n+    summary.getCounts().add(Content.DIRECTORY, 1);\n+\n+    // Relinquish and reacquire locks if necessary.\n+    summary.yield();\n+\n+    return summary;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public ContentSummaryComputationContext computeContentSummary(\n      ContentSummaryComputationContext summary) {\n    ReadOnlyList\u003cINode\u003e childrenList \u003d getChildrenList(null);\n    // Explicit traversing is done to enable repositioning after relinquishing\n    // and reacquiring locks.\n    for (int i \u003d 0;  i \u003c childrenList.size(); i++) {\n      INode child \u003d childrenList.get(i);\n      byte[] childName \u003d child.getLocalNameBytes();\n\n      long lastYieldCount \u003d summary.getYieldCount();\n      child.computeContentSummary(summary);\n\n      // Check whether the computation was paused in the subtree.\n      // The counts may be off, but traversing the rest of children\n      // should be made safe.\n      if (lastYieldCount \u003d\u003d summary.getYieldCount()) {\n        continue;\n      }\n\n      // The locks were released and reacquired. Check parent first.\n      if (getParent() \u003d\u003d null) {\n        // Stop further counting and return whatever we have so far.\n        break;\n      }\n\n      // Obtain the children list again since it may have been modified.\n      childrenList \u003d getChildrenList(null);\n      // Reposition in case the children list is changed. Decrement by 1\n      // since it will be incremented when loops.\n      i \u003d nextChild(childrenList, childName) - 1;\n    }\n\n    // Increment the directory count for this directory.\n    summary.getCounts().add(Content.DIRECTORY, 1);\n\n    // Relinquish and reacquire locks if necessary.\n    summary.yield();\n\n    return summary;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeDirectory.java",
          "extendedDetails": {}
        }
      ]
    }
  }
}