{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ShuffleHandler.java",
  "functionName": "sendMapOutput",
  "functionId": "sendMapOutput___ctx-ChannelHandlerContext__ch-Channel__user-String__mapId-String__reduce-int__mapOutputInfo-MapOutputInfo",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java",
  "functionStartLine": 1249,
  "functionEndLine": 1296,
  "numCommitsSeen": 86,
  "timeTaken": 9092,
  "changeHistory": [
    "a90a5c24525bf6b92c49f7476b6de286338018c0",
    "a5c08eed16e797d2ba9f98f7bc6a8e1bf09aaddd",
    "86dc50c1ebb34dc35c03141cd92a00d64c98beb4",
    "982753dc8e49ad51ad75698e0b30e2c75a4605a6",
    "47d1ca402fe0bafae32507dee0d27cd1e345a7e9",
    "5ac6abe107f56c3a787ee62b92181bc183623e2c",
    "3eb0cb27e8c037e6b29ac57ad72b5bffa362da38",
    "9d16c9354b0c05edb30d23003dcdec4cc44ed925",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517"
  ],
  "changeHistoryShort": {
    "a90a5c24525bf6b92c49f7476b6de286338018c0": "Ybodychange",
    "a5c08eed16e797d2ba9f98f7bc6a8e1bf09aaddd": "Ymultichange(Yparameterchange,Ybodychange)",
    "86dc50c1ebb34dc35c03141cd92a00d64c98beb4": "Ybodychange",
    "982753dc8e49ad51ad75698e0b30e2c75a4605a6": "Ybodychange",
    "47d1ca402fe0bafae32507dee0d27cd1e345a7e9": "Ybodychange",
    "5ac6abe107f56c3a787ee62b92181bc183623e2c": "Ybodychange",
    "3eb0cb27e8c037e6b29ac57ad72b5bffa362da38": "Ybodychange",
    "9d16c9354b0c05edb30d23003dcdec4cc44ed925": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yintroduced"
  },
  "changeHistoryDetails": {
    "a90a5c24525bf6b92c49f7476b6de286338018c0": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5791. Shuffle phase is slow in Windows - FadviseFileRegion::transferTo does not read disks efficiently. Contributed by Nikola Vujic.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1580994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/03/14 11:57 AM",
      "commitName": "a90a5c24525bf6b92c49f7476b6de286338018c0",
      "commitAuthor": "Chris Nauroth",
      "commitDateOld": "21/03/14 2:43 PM",
      "commitNameOld": "a5c08eed16e797d2ba9f98f7bc6a8e1bf09aaddd",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 2.88,
      "commitsBetweenForRepo": 17,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,47 +1,48 @@\n     protected ChannelFuture sendMapOutput(ChannelHandlerContext ctx, Channel ch,\n         String user, String mapId, int reduce, MapOutputInfo mapOutputInfo)\n         throws IOException {\n       final IndexRecord info \u003d mapOutputInfo.indexRecord;\n       final ShuffleHeader header \u003d\n         new ShuffleHeader(mapId, info.partLength, info.rawLength, reduce);\n       final DataOutputBuffer dob \u003d new DataOutputBuffer();\n       header.write(dob);\n       ch.write(wrappedBuffer(dob.getData(), 0, dob.getLength()));\n       final File spillfile \u003d\n           new File(mapOutputInfo.mapOutputFileName.toString());\n       RandomAccessFile spill;\n       try {\n         spill \u003d SecureIOUtils.openForRandomRead(spillfile, \"r\", user, null);\n       } catch (FileNotFoundException e) {\n         LOG.info(spillfile + \" not found\");\n         return null;\n       }\n       ChannelFuture writeFuture;\n       if (ch.getPipeline().get(SslHandler.class) \u003d\u003d null) {\n         final FadvisedFileRegion partition \u003d new FadvisedFileRegion(spill,\n             info.startOffset, info.partLength, manageOsCache, readaheadLength,\n-            readaheadPool, spillfile.getAbsolutePath());\n+            readaheadPool, spillfile.getAbsolutePath(), \n+            shuffleBufferSize, shuffleTransferToAllowed);\n         writeFuture \u003d ch.write(partition);\n         writeFuture.addListener(new ChannelFutureListener() {\n             // TODO error handling; distinguish IO/connection failures,\n             //      attribute to appropriate spill output\n           @Override\n           public void operationComplete(ChannelFuture future) {\n             if (future.isSuccess()) {\n               partition.transferSuccessful();\n             }\n             partition.releaseExternalResources();\n           }\n         });\n       } else {\n         // HTTPS cannot be done with zero copy.\n         final FadvisedChunkedFile chunk \u003d new FadvisedChunkedFile(spill,\n             info.startOffset, info.partLength, sslFileBufferSize,\n             manageOsCache, readaheadLength, readaheadPool,\n             spillfile.getAbsolutePath());\n         writeFuture \u003d ch.write(chunk);\n       }\n       metrics.shuffleConnections.incr();\n       metrics.shuffleOutputBytes.incr(info.partLength); // optimistic\n       return writeFuture;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    protected ChannelFuture sendMapOutput(ChannelHandlerContext ctx, Channel ch,\n        String user, String mapId, int reduce, MapOutputInfo mapOutputInfo)\n        throws IOException {\n      final IndexRecord info \u003d mapOutputInfo.indexRecord;\n      final ShuffleHeader header \u003d\n        new ShuffleHeader(mapId, info.partLength, info.rawLength, reduce);\n      final DataOutputBuffer dob \u003d new DataOutputBuffer();\n      header.write(dob);\n      ch.write(wrappedBuffer(dob.getData(), 0, dob.getLength()));\n      final File spillfile \u003d\n          new File(mapOutputInfo.mapOutputFileName.toString());\n      RandomAccessFile spill;\n      try {\n        spill \u003d SecureIOUtils.openForRandomRead(spillfile, \"r\", user, null);\n      } catch (FileNotFoundException e) {\n        LOG.info(spillfile + \" not found\");\n        return null;\n      }\n      ChannelFuture writeFuture;\n      if (ch.getPipeline().get(SslHandler.class) \u003d\u003d null) {\n        final FadvisedFileRegion partition \u003d new FadvisedFileRegion(spill,\n            info.startOffset, info.partLength, manageOsCache, readaheadLength,\n            readaheadPool, spillfile.getAbsolutePath(), \n            shuffleBufferSize, shuffleTransferToAllowed);\n        writeFuture \u003d ch.write(partition);\n        writeFuture.addListener(new ChannelFutureListener() {\n            // TODO error handling; distinguish IO/connection failures,\n            //      attribute to appropriate spill output\n          @Override\n          public void operationComplete(ChannelFuture future) {\n            if (future.isSuccess()) {\n              partition.transferSuccessful();\n            }\n            partition.releaseExternalResources();\n          }\n        });\n      } else {\n        // HTTPS cannot be done with zero copy.\n        final FadvisedChunkedFile chunk \u003d new FadvisedChunkedFile(spill,\n            info.startOffset, info.partLength, sslFileBufferSize,\n            manageOsCache, readaheadLength, readaheadPool,\n            spillfile.getAbsolutePath());\n        writeFuture \u003d ch.write(chunk);\n      }\n      metrics.shuffleConnections.incr();\n      metrics.shuffleOutputBytes.incr(info.partLength); // optimistic\n      return writeFuture;\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java",
      "extendedDetails": {}
    },
    "a5c08eed16e797d2ba9f98f7bc6a8e1bf09aaddd": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "MAPREDUCE-5787. Added the ability to keep alive shuffle connections in the MapReduce shuffle-handler. Contributed by Rajesh Balamohan.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1580062 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/03/14 2:43 PM",
      "commitName": "a5c08eed16e797d2ba9f98f7bc6a8e1bf09aaddd",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "MAPREDUCE-5787. Added the ability to keep alive shuffle connections in the MapReduce shuffle-handler. Contributed by Rajesh Balamohan.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1580062 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "21/03/14 2:43 PM",
          "commitName": "a5c08eed16e797d2ba9f98f7bc6a8e1bf09aaddd",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "24/02/14 5:24 PM",
          "commitNameOld": "ae29d9ee0419bce28530da5ef1c6fe36a6d50ad0",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 24.85,
          "commitsBetweenForRepo": 224,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,70 +1,47 @@\n     protected ChannelFuture sendMapOutput(ChannelHandlerContext ctx, Channel ch,\n-        String user, String jobId, String mapId, int reduce)\n+        String user, String mapId, int reduce, MapOutputInfo mapOutputInfo)\n         throws IOException {\n-      // TODO replace w/ rsrc alloc\n-      // $x/$user/appcache/$appId/output/$mapId\n-      // TODO: Once Shuffle is out of NM, this can use MR APIs to convert between App and Job\n-      JobID jobID \u003d JobID.forName(jobId);\n-      ApplicationId appID \u003d ApplicationId.newInstance(\n-          Long.parseLong(jobID.getJtIdentifier()), jobID.getId());\n-      final String base \u003d\n-          ContainerLocalizer.USERCACHE + \"/\" + user + \"/\"\n-              + ContainerLocalizer.APPCACHE + \"/\"\n-              + ConverterUtils.toString(appID) + \"/output\" + \"/\" + mapId;\n-      if (LOG.isDebugEnabled()) {\n-        LOG.debug(\"DEBUG0 \" + base);\n-      }\n-      // Index file\n-      Path indexFileName \u003d lDirAlloc.getLocalPathToRead(\n-          base + \"/file.out.index\", conf);\n-      // Map-output file\n-      Path mapOutputFileName \u003d lDirAlloc.getLocalPathToRead(\n-          base + \"/file.out\", conf);\n-      if (LOG.isDebugEnabled()) {\n-        LOG.debug(\"DEBUG1 \" + base + \" : \" + mapOutputFileName + \" : \"\n-            + indexFileName);\n-      }\n-      final IndexRecord info \u003d \n-        indexCache.getIndexInformation(mapId, reduce, indexFileName, user);\n+      final IndexRecord info \u003d mapOutputInfo.indexRecord;\n       final ShuffleHeader header \u003d\n         new ShuffleHeader(mapId, info.partLength, info.rawLength, reduce);\n       final DataOutputBuffer dob \u003d new DataOutputBuffer();\n       header.write(dob);\n       ch.write(wrappedBuffer(dob.getData(), 0, dob.getLength()));\n-      final File spillfile \u003d new File(mapOutputFileName.toString());\n+      final File spillfile \u003d\n+          new File(mapOutputInfo.mapOutputFileName.toString());\n       RandomAccessFile spill;\n       try {\n         spill \u003d SecureIOUtils.openForRandomRead(spillfile, \"r\", user, null);\n       } catch (FileNotFoundException e) {\n         LOG.info(spillfile + \" not found\");\n         return null;\n       }\n       ChannelFuture writeFuture;\n       if (ch.getPipeline().get(SslHandler.class) \u003d\u003d null) {\n         final FadvisedFileRegion partition \u003d new FadvisedFileRegion(spill,\n             info.startOffset, info.partLength, manageOsCache, readaheadLength,\n             readaheadPool, spillfile.getAbsolutePath());\n         writeFuture \u003d ch.write(partition);\n         writeFuture.addListener(new ChannelFutureListener() {\n             // TODO error handling; distinguish IO/connection failures,\n             //      attribute to appropriate spill output\n           @Override\n           public void operationComplete(ChannelFuture future) {\n             if (future.isSuccess()) {\n               partition.transferSuccessful();\n             }\n             partition.releaseExternalResources();\n           }\n         });\n       } else {\n         // HTTPS cannot be done with zero copy.\n         final FadvisedChunkedFile chunk \u003d new FadvisedChunkedFile(spill,\n             info.startOffset, info.partLength, sslFileBufferSize,\n             manageOsCache, readaheadLength, readaheadPool,\n             spillfile.getAbsolutePath());\n         writeFuture \u003d ch.write(chunk);\n       }\n       metrics.shuffleConnections.incr();\n       metrics.shuffleOutputBytes.incr(info.partLength); // optimistic\n       return writeFuture;\n     }\n\\ No newline at end of file\n",
          "actualSource": "    protected ChannelFuture sendMapOutput(ChannelHandlerContext ctx, Channel ch,\n        String user, String mapId, int reduce, MapOutputInfo mapOutputInfo)\n        throws IOException {\n      final IndexRecord info \u003d mapOutputInfo.indexRecord;\n      final ShuffleHeader header \u003d\n        new ShuffleHeader(mapId, info.partLength, info.rawLength, reduce);\n      final DataOutputBuffer dob \u003d new DataOutputBuffer();\n      header.write(dob);\n      ch.write(wrappedBuffer(dob.getData(), 0, dob.getLength()));\n      final File spillfile \u003d\n          new File(mapOutputInfo.mapOutputFileName.toString());\n      RandomAccessFile spill;\n      try {\n        spill \u003d SecureIOUtils.openForRandomRead(spillfile, \"r\", user, null);\n      } catch (FileNotFoundException e) {\n        LOG.info(spillfile + \" not found\");\n        return null;\n      }\n      ChannelFuture writeFuture;\n      if (ch.getPipeline().get(SslHandler.class) \u003d\u003d null) {\n        final FadvisedFileRegion partition \u003d new FadvisedFileRegion(spill,\n            info.startOffset, info.partLength, manageOsCache, readaheadLength,\n            readaheadPool, spillfile.getAbsolutePath());\n        writeFuture \u003d ch.write(partition);\n        writeFuture.addListener(new ChannelFutureListener() {\n            // TODO error handling; distinguish IO/connection failures,\n            //      attribute to appropriate spill output\n          @Override\n          public void operationComplete(ChannelFuture future) {\n            if (future.isSuccess()) {\n              partition.transferSuccessful();\n            }\n            partition.releaseExternalResources();\n          }\n        });\n      } else {\n        // HTTPS cannot be done with zero copy.\n        final FadvisedChunkedFile chunk \u003d new FadvisedChunkedFile(spill,\n            info.startOffset, info.partLength, sslFileBufferSize,\n            manageOsCache, readaheadLength, readaheadPool,\n            spillfile.getAbsolutePath());\n        writeFuture \u003d ch.write(chunk);\n      }\n      metrics.shuffleConnections.incr();\n      metrics.shuffleOutputBytes.incr(info.partLength); // optimistic\n      return writeFuture;\n    }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java",
          "extendedDetails": {
            "oldValue": "[ctx-ChannelHandlerContext, ch-Channel, user-String, jobId-String, mapId-String, reduce-int]",
            "newValue": "[ctx-ChannelHandlerContext, ch-Channel, user-String, mapId-String, reduce-int, mapOutputInfo-MapOutputInfo]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "MAPREDUCE-5787. Added the ability to keep alive shuffle connections in the MapReduce shuffle-handler. Contributed by Rajesh Balamohan.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1580062 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "21/03/14 2:43 PM",
          "commitName": "a5c08eed16e797d2ba9f98f7bc6a8e1bf09aaddd",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "24/02/14 5:24 PM",
          "commitNameOld": "ae29d9ee0419bce28530da5ef1c6fe36a6d50ad0",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 24.85,
          "commitsBetweenForRepo": 224,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,70 +1,47 @@\n     protected ChannelFuture sendMapOutput(ChannelHandlerContext ctx, Channel ch,\n-        String user, String jobId, String mapId, int reduce)\n+        String user, String mapId, int reduce, MapOutputInfo mapOutputInfo)\n         throws IOException {\n-      // TODO replace w/ rsrc alloc\n-      // $x/$user/appcache/$appId/output/$mapId\n-      // TODO: Once Shuffle is out of NM, this can use MR APIs to convert between App and Job\n-      JobID jobID \u003d JobID.forName(jobId);\n-      ApplicationId appID \u003d ApplicationId.newInstance(\n-          Long.parseLong(jobID.getJtIdentifier()), jobID.getId());\n-      final String base \u003d\n-          ContainerLocalizer.USERCACHE + \"/\" + user + \"/\"\n-              + ContainerLocalizer.APPCACHE + \"/\"\n-              + ConverterUtils.toString(appID) + \"/output\" + \"/\" + mapId;\n-      if (LOG.isDebugEnabled()) {\n-        LOG.debug(\"DEBUG0 \" + base);\n-      }\n-      // Index file\n-      Path indexFileName \u003d lDirAlloc.getLocalPathToRead(\n-          base + \"/file.out.index\", conf);\n-      // Map-output file\n-      Path mapOutputFileName \u003d lDirAlloc.getLocalPathToRead(\n-          base + \"/file.out\", conf);\n-      if (LOG.isDebugEnabled()) {\n-        LOG.debug(\"DEBUG1 \" + base + \" : \" + mapOutputFileName + \" : \"\n-            + indexFileName);\n-      }\n-      final IndexRecord info \u003d \n-        indexCache.getIndexInformation(mapId, reduce, indexFileName, user);\n+      final IndexRecord info \u003d mapOutputInfo.indexRecord;\n       final ShuffleHeader header \u003d\n         new ShuffleHeader(mapId, info.partLength, info.rawLength, reduce);\n       final DataOutputBuffer dob \u003d new DataOutputBuffer();\n       header.write(dob);\n       ch.write(wrappedBuffer(dob.getData(), 0, dob.getLength()));\n-      final File spillfile \u003d new File(mapOutputFileName.toString());\n+      final File spillfile \u003d\n+          new File(mapOutputInfo.mapOutputFileName.toString());\n       RandomAccessFile spill;\n       try {\n         spill \u003d SecureIOUtils.openForRandomRead(spillfile, \"r\", user, null);\n       } catch (FileNotFoundException e) {\n         LOG.info(spillfile + \" not found\");\n         return null;\n       }\n       ChannelFuture writeFuture;\n       if (ch.getPipeline().get(SslHandler.class) \u003d\u003d null) {\n         final FadvisedFileRegion partition \u003d new FadvisedFileRegion(spill,\n             info.startOffset, info.partLength, manageOsCache, readaheadLength,\n             readaheadPool, spillfile.getAbsolutePath());\n         writeFuture \u003d ch.write(partition);\n         writeFuture.addListener(new ChannelFutureListener() {\n             // TODO error handling; distinguish IO/connection failures,\n             //      attribute to appropriate spill output\n           @Override\n           public void operationComplete(ChannelFuture future) {\n             if (future.isSuccess()) {\n               partition.transferSuccessful();\n             }\n             partition.releaseExternalResources();\n           }\n         });\n       } else {\n         // HTTPS cannot be done with zero copy.\n         final FadvisedChunkedFile chunk \u003d new FadvisedChunkedFile(spill,\n             info.startOffset, info.partLength, sslFileBufferSize,\n             manageOsCache, readaheadLength, readaheadPool,\n             spillfile.getAbsolutePath());\n         writeFuture \u003d ch.write(chunk);\n       }\n       metrics.shuffleConnections.incr();\n       metrics.shuffleOutputBytes.incr(info.partLength); // optimistic\n       return writeFuture;\n     }\n\\ No newline at end of file\n",
          "actualSource": "    protected ChannelFuture sendMapOutput(ChannelHandlerContext ctx, Channel ch,\n        String user, String mapId, int reduce, MapOutputInfo mapOutputInfo)\n        throws IOException {\n      final IndexRecord info \u003d mapOutputInfo.indexRecord;\n      final ShuffleHeader header \u003d\n        new ShuffleHeader(mapId, info.partLength, info.rawLength, reduce);\n      final DataOutputBuffer dob \u003d new DataOutputBuffer();\n      header.write(dob);\n      ch.write(wrappedBuffer(dob.getData(), 0, dob.getLength()));\n      final File spillfile \u003d\n          new File(mapOutputInfo.mapOutputFileName.toString());\n      RandomAccessFile spill;\n      try {\n        spill \u003d SecureIOUtils.openForRandomRead(spillfile, \"r\", user, null);\n      } catch (FileNotFoundException e) {\n        LOG.info(spillfile + \" not found\");\n        return null;\n      }\n      ChannelFuture writeFuture;\n      if (ch.getPipeline().get(SslHandler.class) \u003d\u003d null) {\n        final FadvisedFileRegion partition \u003d new FadvisedFileRegion(spill,\n            info.startOffset, info.partLength, manageOsCache, readaheadLength,\n            readaheadPool, spillfile.getAbsolutePath());\n        writeFuture \u003d ch.write(partition);\n        writeFuture.addListener(new ChannelFutureListener() {\n            // TODO error handling; distinguish IO/connection failures,\n            //      attribute to appropriate spill output\n          @Override\n          public void operationComplete(ChannelFuture future) {\n            if (future.isSuccess()) {\n              partition.transferSuccessful();\n            }\n            partition.releaseExternalResources();\n          }\n        });\n      } else {\n        // HTTPS cannot be done with zero copy.\n        final FadvisedChunkedFile chunk \u003d new FadvisedChunkedFile(spill,\n            info.startOffset, info.partLength, sslFileBufferSize,\n            manageOsCache, readaheadLength, readaheadPool,\n            spillfile.getAbsolutePath());\n        writeFuture \u003d ch.write(chunk);\n      }\n      metrics.shuffleConnections.incr();\n      metrics.shuffleOutputBytes.incr(info.partLength); // optimistic\n      return writeFuture;\n    }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java",
          "extendedDetails": {}
        }
      ]
    },
    "86dc50c1ebb34dc35c03141cd92a00d64c98beb4": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5601. ShuffleHandler fadvises file regions as DONTNEED even when fetch fails (Sandy Ryza)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1537855 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "01/11/13 1:51 AM",
      "commitName": "86dc50c1ebb34dc35c03141cd92a00d64c98beb4",
      "commitAuthor": "Sanford Ryza",
      "commitDateOld": "29/10/13 6:41 AM",
      "commitNameOld": "e0c99b80d47aaf65ee51c601cb8124ce5df79b2f",
      "commitAuthorOld": "Jason Darrell Lowe",
      "daysBetweenCommits": 2.8,
      "commitsBetweenForRepo": 21,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,67 +1,70 @@\n     protected ChannelFuture sendMapOutput(ChannelHandlerContext ctx, Channel ch,\n         String user, String jobId, String mapId, int reduce)\n         throws IOException {\n       // TODO replace w/ rsrc alloc\n       // $x/$user/appcache/$appId/output/$mapId\n       // TODO: Once Shuffle is out of NM, this can use MR APIs to convert between App and Job\n       JobID jobID \u003d JobID.forName(jobId);\n       ApplicationId appID \u003d ApplicationId.newInstance(\n           Long.parseLong(jobID.getJtIdentifier()), jobID.getId());\n       final String base \u003d\n           ContainerLocalizer.USERCACHE + \"/\" + user + \"/\"\n               + ContainerLocalizer.APPCACHE + \"/\"\n               + ConverterUtils.toString(appID) + \"/output\" + \"/\" + mapId;\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"DEBUG0 \" + base);\n       }\n       // Index file\n       Path indexFileName \u003d lDirAlloc.getLocalPathToRead(\n           base + \"/file.out.index\", conf);\n       // Map-output file\n       Path mapOutputFileName \u003d lDirAlloc.getLocalPathToRead(\n           base + \"/file.out\", conf);\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"DEBUG1 \" + base + \" : \" + mapOutputFileName + \" : \"\n             + indexFileName);\n       }\n       final IndexRecord info \u003d \n         indexCache.getIndexInformation(mapId, reduce, indexFileName, user);\n       final ShuffleHeader header \u003d\n         new ShuffleHeader(mapId, info.partLength, info.rawLength, reduce);\n       final DataOutputBuffer dob \u003d new DataOutputBuffer();\n       header.write(dob);\n       ch.write(wrappedBuffer(dob.getData(), 0, dob.getLength()));\n       final File spillfile \u003d new File(mapOutputFileName.toString());\n       RandomAccessFile spill;\n       try {\n         spill \u003d SecureIOUtils.openForRandomRead(spillfile, \"r\", user, null);\n       } catch (FileNotFoundException e) {\n         LOG.info(spillfile + \" not found\");\n         return null;\n       }\n       ChannelFuture writeFuture;\n       if (ch.getPipeline().get(SslHandler.class) \u003d\u003d null) {\n         final FadvisedFileRegion partition \u003d new FadvisedFileRegion(spill,\n             info.startOffset, info.partLength, manageOsCache, readaheadLength,\n             readaheadPool, spillfile.getAbsolutePath());\n         writeFuture \u003d ch.write(partition);\n         writeFuture.addListener(new ChannelFutureListener() {\n             // TODO error handling; distinguish IO/connection failures,\n             //      attribute to appropriate spill output\n           @Override\n           public void operationComplete(ChannelFuture future) {\n+            if (future.isSuccess()) {\n+              partition.transferSuccessful();\n+            }\n             partition.releaseExternalResources();\n           }\n         });\n       } else {\n         // HTTPS cannot be done with zero copy.\n         final FadvisedChunkedFile chunk \u003d new FadvisedChunkedFile(spill,\n             info.startOffset, info.partLength, sslFileBufferSize,\n             manageOsCache, readaheadLength, readaheadPool,\n             spillfile.getAbsolutePath());\n         writeFuture \u003d ch.write(chunk);\n       }\n       metrics.shuffleConnections.incr();\n       metrics.shuffleOutputBytes.incr(info.partLength); // optimistic\n       return writeFuture;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    protected ChannelFuture sendMapOutput(ChannelHandlerContext ctx, Channel ch,\n        String user, String jobId, String mapId, int reduce)\n        throws IOException {\n      // TODO replace w/ rsrc alloc\n      // $x/$user/appcache/$appId/output/$mapId\n      // TODO: Once Shuffle is out of NM, this can use MR APIs to convert between App and Job\n      JobID jobID \u003d JobID.forName(jobId);\n      ApplicationId appID \u003d ApplicationId.newInstance(\n          Long.parseLong(jobID.getJtIdentifier()), jobID.getId());\n      final String base \u003d\n          ContainerLocalizer.USERCACHE + \"/\" + user + \"/\"\n              + ContainerLocalizer.APPCACHE + \"/\"\n              + ConverterUtils.toString(appID) + \"/output\" + \"/\" + mapId;\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"DEBUG0 \" + base);\n      }\n      // Index file\n      Path indexFileName \u003d lDirAlloc.getLocalPathToRead(\n          base + \"/file.out.index\", conf);\n      // Map-output file\n      Path mapOutputFileName \u003d lDirAlloc.getLocalPathToRead(\n          base + \"/file.out\", conf);\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"DEBUG1 \" + base + \" : \" + mapOutputFileName + \" : \"\n            + indexFileName);\n      }\n      final IndexRecord info \u003d \n        indexCache.getIndexInformation(mapId, reduce, indexFileName, user);\n      final ShuffleHeader header \u003d\n        new ShuffleHeader(mapId, info.partLength, info.rawLength, reduce);\n      final DataOutputBuffer dob \u003d new DataOutputBuffer();\n      header.write(dob);\n      ch.write(wrappedBuffer(dob.getData(), 0, dob.getLength()));\n      final File spillfile \u003d new File(mapOutputFileName.toString());\n      RandomAccessFile spill;\n      try {\n        spill \u003d SecureIOUtils.openForRandomRead(spillfile, \"r\", user, null);\n      } catch (FileNotFoundException e) {\n        LOG.info(spillfile + \" not found\");\n        return null;\n      }\n      ChannelFuture writeFuture;\n      if (ch.getPipeline().get(SslHandler.class) \u003d\u003d null) {\n        final FadvisedFileRegion partition \u003d new FadvisedFileRegion(spill,\n            info.startOffset, info.partLength, manageOsCache, readaheadLength,\n            readaheadPool, spillfile.getAbsolutePath());\n        writeFuture \u003d ch.write(partition);\n        writeFuture.addListener(new ChannelFutureListener() {\n            // TODO error handling; distinguish IO/connection failures,\n            //      attribute to appropriate spill output\n          @Override\n          public void operationComplete(ChannelFuture future) {\n            if (future.isSuccess()) {\n              partition.transferSuccessful();\n            }\n            partition.releaseExternalResources();\n          }\n        });\n      } else {\n        // HTTPS cannot be done with zero copy.\n        final FadvisedChunkedFile chunk \u003d new FadvisedChunkedFile(spill,\n            info.startOffset, info.partLength, sslFileBufferSize,\n            manageOsCache, readaheadLength, readaheadPool,\n            spillfile.getAbsolutePath());\n        writeFuture \u003d ch.write(chunk);\n      }\n      metrics.shuffleConnections.incr();\n      metrics.shuffleOutputBytes.incr(info.partLength); // optimistic\n      return writeFuture;\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java",
      "extendedDetails": {}
    },
    "982753dc8e49ad51ad75698e0b30e2c75a4605a6": {
      "type": "Ybodychange",
      "commitMessage": "YARN-716. Making ApplicationID immutable. Contributed by Siddharth Seth.\nMAPREDUCE-5282. Updating MR App to use immutable ApplicationID after YARN-716. Contributed by Siddharth Seth.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1487994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "30/05/13 1:18 PM",
      "commitName": "982753dc8e49ad51ad75698e0b30e2c75a4605a6",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "12/05/13 2:59 PM",
      "commitNameOld": "47d1ca402fe0bafae32507dee0d27cd1e345a7e9",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 17.93,
      "commitsBetweenForRepo": 79,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,68 +1,67 @@\n     protected ChannelFuture sendMapOutput(ChannelHandlerContext ctx, Channel ch,\n         String user, String jobId, String mapId, int reduce)\n         throws IOException {\n       // TODO replace w/ rsrc alloc\n       // $x/$user/appcache/$appId/output/$mapId\n       // TODO: Once Shuffle is out of NM, this can use MR APIs to convert between App and Job\n       JobID jobID \u003d JobID.forName(jobId);\n-      ApplicationId appID \u003d Records.newRecord(ApplicationId.class);\n-      appID.setClusterTimestamp(Long.parseLong(jobID.getJtIdentifier()));\n-      appID.setId(jobID.getId());\n+      ApplicationId appID \u003d ApplicationId.newInstance(\n+          Long.parseLong(jobID.getJtIdentifier()), jobID.getId());\n       final String base \u003d\n           ContainerLocalizer.USERCACHE + \"/\" + user + \"/\"\n               + ContainerLocalizer.APPCACHE + \"/\"\n               + ConverterUtils.toString(appID) + \"/output\" + \"/\" + mapId;\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"DEBUG0 \" + base);\n       }\n       // Index file\n       Path indexFileName \u003d lDirAlloc.getLocalPathToRead(\n           base + \"/file.out.index\", conf);\n       // Map-output file\n       Path mapOutputFileName \u003d lDirAlloc.getLocalPathToRead(\n           base + \"/file.out\", conf);\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"DEBUG1 \" + base + \" : \" + mapOutputFileName + \" : \"\n             + indexFileName);\n       }\n       final IndexRecord info \u003d \n         indexCache.getIndexInformation(mapId, reduce, indexFileName, user);\n       final ShuffleHeader header \u003d\n         new ShuffleHeader(mapId, info.partLength, info.rawLength, reduce);\n       final DataOutputBuffer dob \u003d new DataOutputBuffer();\n       header.write(dob);\n       ch.write(wrappedBuffer(dob.getData(), 0, dob.getLength()));\n       final File spillfile \u003d new File(mapOutputFileName.toString());\n       RandomAccessFile spill;\n       try {\n         spill \u003d SecureIOUtils.openForRandomRead(spillfile, \"r\", user, null);\n       } catch (FileNotFoundException e) {\n         LOG.info(spillfile + \" not found\");\n         return null;\n       }\n       ChannelFuture writeFuture;\n       if (ch.getPipeline().get(SslHandler.class) \u003d\u003d null) {\n         final FadvisedFileRegion partition \u003d new FadvisedFileRegion(spill,\n             info.startOffset, info.partLength, manageOsCache, readaheadLength,\n             readaheadPool, spillfile.getAbsolutePath());\n         writeFuture \u003d ch.write(partition);\n         writeFuture.addListener(new ChannelFutureListener() {\n             // TODO error handling; distinguish IO/connection failures,\n             //      attribute to appropriate spill output\n           @Override\n           public void operationComplete(ChannelFuture future) {\n             partition.releaseExternalResources();\n           }\n         });\n       } else {\n         // HTTPS cannot be done with zero copy.\n         final FadvisedChunkedFile chunk \u003d new FadvisedChunkedFile(spill,\n             info.startOffset, info.partLength, sslFileBufferSize,\n             manageOsCache, readaheadLength, readaheadPool,\n             spillfile.getAbsolutePath());\n         writeFuture \u003d ch.write(chunk);\n       }\n       metrics.shuffleConnections.incr();\n       metrics.shuffleOutputBytes.incr(info.partLength); // optimistic\n       return writeFuture;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    protected ChannelFuture sendMapOutput(ChannelHandlerContext ctx, Channel ch,\n        String user, String jobId, String mapId, int reduce)\n        throws IOException {\n      // TODO replace w/ rsrc alloc\n      // $x/$user/appcache/$appId/output/$mapId\n      // TODO: Once Shuffle is out of NM, this can use MR APIs to convert between App and Job\n      JobID jobID \u003d JobID.forName(jobId);\n      ApplicationId appID \u003d ApplicationId.newInstance(\n          Long.parseLong(jobID.getJtIdentifier()), jobID.getId());\n      final String base \u003d\n          ContainerLocalizer.USERCACHE + \"/\" + user + \"/\"\n              + ContainerLocalizer.APPCACHE + \"/\"\n              + ConverterUtils.toString(appID) + \"/output\" + \"/\" + mapId;\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"DEBUG0 \" + base);\n      }\n      // Index file\n      Path indexFileName \u003d lDirAlloc.getLocalPathToRead(\n          base + \"/file.out.index\", conf);\n      // Map-output file\n      Path mapOutputFileName \u003d lDirAlloc.getLocalPathToRead(\n          base + \"/file.out\", conf);\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"DEBUG1 \" + base + \" : \" + mapOutputFileName + \" : \"\n            + indexFileName);\n      }\n      final IndexRecord info \u003d \n        indexCache.getIndexInformation(mapId, reduce, indexFileName, user);\n      final ShuffleHeader header \u003d\n        new ShuffleHeader(mapId, info.partLength, info.rawLength, reduce);\n      final DataOutputBuffer dob \u003d new DataOutputBuffer();\n      header.write(dob);\n      ch.write(wrappedBuffer(dob.getData(), 0, dob.getLength()));\n      final File spillfile \u003d new File(mapOutputFileName.toString());\n      RandomAccessFile spill;\n      try {\n        spill \u003d SecureIOUtils.openForRandomRead(spillfile, \"r\", user, null);\n      } catch (FileNotFoundException e) {\n        LOG.info(spillfile + \" not found\");\n        return null;\n      }\n      ChannelFuture writeFuture;\n      if (ch.getPipeline().get(SslHandler.class) \u003d\u003d null) {\n        final FadvisedFileRegion partition \u003d new FadvisedFileRegion(spill,\n            info.startOffset, info.partLength, manageOsCache, readaheadLength,\n            readaheadPool, spillfile.getAbsolutePath());\n        writeFuture \u003d ch.write(partition);\n        writeFuture.addListener(new ChannelFutureListener() {\n            // TODO error handling; distinguish IO/connection failures,\n            //      attribute to appropriate spill output\n          @Override\n          public void operationComplete(ChannelFuture future) {\n            partition.releaseExternalResources();\n          }\n        });\n      } else {\n        // HTTPS cannot be done with zero copy.\n        final FadvisedChunkedFile chunk \u003d new FadvisedChunkedFile(spill,\n            info.startOffset, info.partLength, sslFileBufferSize,\n            manageOsCache, readaheadLength, readaheadPool,\n            spillfile.getAbsolutePath());\n        writeFuture \u003d ch.write(chunk);\n      }\n      metrics.shuffleConnections.incr();\n      metrics.shuffleOutputBytes.incr(info.partLength); // optimistic\n      return writeFuture;\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java",
      "extendedDetails": {}
    },
    "47d1ca402fe0bafae32507dee0d27cd1e345a7e9": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5208. Modified ShuffleHandler to use SecureIOUtils for reading local files. Contributed by Omkar Vinit Joshi.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1481657 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/05/13 2:59 PM",
      "commitName": "47d1ca402fe0bafae32507dee0d27cd1e345a7e9",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "02/05/13 8:58 AM",
      "commitNameOld": "9b97df9abe4383cde612a6050ae5db315647931c",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 10.25,
      "commitsBetweenForRepo": 57,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,68 +1,68 @@\n     protected ChannelFuture sendMapOutput(ChannelHandlerContext ctx, Channel ch,\n         String user, String jobId, String mapId, int reduce)\n         throws IOException {\n       // TODO replace w/ rsrc alloc\n       // $x/$user/appcache/$appId/output/$mapId\n       // TODO: Once Shuffle is out of NM, this can use MR APIs to convert between App and Job\n       JobID jobID \u003d JobID.forName(jobId);\n       ApplicationId appID \u003d Records.newRecord(ApplicationId.class);\n       appID.setClusterTimestamp(Long.parseLong(jobID.getJtIdentifier()));\n       appID.setId(jobID.getId());\n       final String base \u003d\n           ContainerLocalizer.USERCACHE + \"/\" + user + \"/\"\n               + ContainerLocalizer.APPCACHE + \"/\"\n               + ConverterUtils.toString(appID) + \"/output\" + \"/\" + mapId;\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"DEBUG0 \" + base);\n       }\n       // Index file\n       Path indexFileName \u003d lDirAlloc.getLocalPathToRead(\n           base + \"/file.out.index\", conf);\n       // Map-output file\n       Path mapOutputFileName \u003d lDirAlloc.getLocalPathToRead(\n           base + \"/file.out\", conf);\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"DEBUG1 \" + base + \" : \" + mapOutputFileName + \" : \"\n             + indexFileName);\n       }\n       final IndexRecord info \u003d \n         indexCache.getIndexInformation(mapId, reduce, indexFileName, user);\n       final ShuffleHeader header \u003d\n         new ShuffleHeader(mapId, info.partLength, info.rawLength, reduce);\n       final DataOutputBuffer dob \u003d new DataOutputBuffer();\n       header.write(dob);\n       ch.write(wrappedBuffer(dob.getData(), 0, dob.getLength()));\n       final File spillfile \u003d new File(mapOutputFileName.toString());\n       RandomAccessFile spill;\n       try {\n-        spill \u003d new RandomAccessFile(spillfile, \"r\");\n+        spill \u003d SecureIOUtils.openForRandomRead(spillfile, \"r\", user, null);\n       } catch (FileNotFoundException e) {\n         LOG.info(spillfile + \" not found\");\n         return null;\n       }\n       ChannelFuture writeFuture;\n       if (ch.getPipeline().get(SslHandler.class) \u003d\u003d null) {\n         final FadvisedFileRegion partition \u003d new FadvisedFileRegion(spill,\n             info.startOffset, info.partLength, manageOsCache, readaheadLength,\n             readaheadPool, spillfile.getAbsolutePath());\n         writeFuture \u003d ch.write(partition);\n         writeFuture.addListener(new ChannelFutureListener() {\n             // TODO error handling; distinguish IO/connection failures,\n             //      attribute to appropriate spill output\n           @Override\n           public void operationComplete(ChannelFuture future) {\n             partition.releaseExternalResources();\n           }\n         });\n       } else {\n         // HTTPS cannot be done with zero copy.\n         final FadvisedChunkedFile chunk \u003d new FadvisedChunkedFile(spill,\n             info.startOffset, info.partLength, sslFileBufferSize,\n             manageOsCache, readaheadLength, readaheadPool,\n             spillfile.getAbsolutePath());\n         writeFuture \u003d ch.write(chunk);\n       }\n       metrics.shuffleConnections.incr();\n       metrics.shuffleOutputBytes.incr(info.partLength); // optimistic\n       return writeFuture;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    protected ChannelFuture sendMapOutput(ChannelHandlerContext ctx, Channel ch,\n        String user, String jobId, String mapId, int reduce)\n        throws IOException {\n      // TODO replace w/ rsrc alloc\n      // $x/$user/appcache/$appId/output/$mapId\n      // TODO: Once Shuffle is out of NM, this can use MR APIs to convert between App and Job\n      JobID jobID \u003d JobID.forName(jobId);\n      ApplicationId appID \u003d Records.newRecord(ApplicationId.class);\n      appID.setClusterTimestamp(Long.parseLong(jobID.getJtIdentifier()));\n      appID.setId(jobID.getId());\n      final String base \u003d\n          ContainerLocalizer.USERCACHE + \"/\" + user + \"/\"\n              + ContainerLocalizer.APPCACHE + \"/\"\n              + ConverterUtils.toString(appID) + \"/output\" + \"/\" + mapId;\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"DEBUG0 \" + base);\n      }\n      // Index file\n      Path indexFileName \u003d lDirAlloc.getLocalPathToRead(\n          base + \"/file.out.index\", conf);\n      // Map-output file\n      Path mapOutputFileName \u003d lDirAlloc.getLocalPathToRead(\n          base + \"/file.out\", conf);\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"DEBUG1 \" + base + \" : \" + mapOutputFileName + \" : \"\n            + indexFileName);\n      }\n      final IndexRecord info \u003d \n        indexCache.getIndexInformation(mapId, reduce, indexFileName, user);\n      final ShuffleHeader header \u003d\n        new ShuffleHeader(mapId, info.partLength, info.rawLength, reduce);\n      final DataOutputBuffer dob \u003d new DataOutputBuffer();\n      header.write(dob);\n      ch.write(wrappedBuffer(dob.getData(), 0, dob.getLength()));\n      final File spillfile \u003d new File(mapOutputFileName.toString());\n      RandomAccessFile spill;\n      try {\n        spill \u003d SecureIOUtils.openForRandomRead(spillfile, \"r\", user, null);\n      } catch (FileNotFoundException e) {\n        LOG.info(spillfile + \" not found\");\n        return null;\n      }\n      ChannelFuture writeFuture;\n      if (ch.getPipeline().get(SslHandler.class) \u003d\u003d null) {\n        final FadvisedFileRegion partition \u003d new FadvisedFileRegion(spill,\n            info.startOffset, info.partLength, manageOsCache, readaheadLength,\n            readaheadPool, spillfile.getAbsolutePath());\n        writeFuture \u003d ch.write(partition);\n        writeFuture.addListener(new ChannelFutureListener() {\n            // TODO error handling; distinguish IO/connection failures,\n            //      attribute to appropriate spill output\n          @Override\n          public void operationComplete(ChannelFuture future) {\n            partition.releaseExternalResources();\n          }\n        });\n      } else {\n        // HTTPS cannot be done with zero copy.\n        final FadvisedChunkedFile chunk \u003d new FadvisedChunkedFile(spill,\n            info.startOffset, info.partLength, sslFileBufferSize,\n            manageOsCache, readaheadLength, readaheadPool,\n            spillfile.getAbsolutePath());\n        writeFuture \u003d ch.write(chunk);\n      }\n      metrics.shuffleConnections.incr();\n      metrics.shuffleOutputBytes.incr(info.partLength); // optimistic\n      return writeFuture;\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java",
      "extendedDetails": {}
    },
    "5ac6abe107f56c3a787ee62b92181bc183623e2c": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4990. Construct debug strings conditionally in ShuffleHandler.Shuffle#sendMapOutput(). (kkambatl via tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1457914 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/03/13 11:45 AM",
      "commitName": "5ac6abe107f56c3a787ee62b92181bc183623e2c",
      "commitAuthor": "Alejandro Abdelnur",
      "commitDateOld": "05/03/13 4:03 PM",
      "commitNameOld": "e1062b8b787b871e6f01546de9f2e4a4c05039b0",
      "commitAuthorOld": "Jonathan Turner Eagles",
      "daysBetweenCommits": 12.78,
      "commitsBetweenForRepo": 73,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,64 +1,68 @@\n     protected ChannelFuture sendMapOutput(ChannelHandlerContext ctx, Channel ch,\n         String user, String jobId, String mapId, int reduce)\n         throws IOException {\n       // TODO replace w/ rsrc alloc\n       // $x/$user/appcache/$appId/output/$mapId\n       // TODO: Once Shuffle is out of NM, this can use MR APIs to convert between App and Job\n       JobID jobID \u003d JobID.forName(jobId);\n       ApplicationId appID \u003d Records.newRecord(ApplicationId.class);\n       appID.setClusterTimestamp(Long.parseLong(jobID.getJtIdentifier()));\n       appID.setId(jobID.getId());\n       final String base \u003d\n           ContainerLocalizer.USERCACHE + \"/\" + user + \"/\"\n               + ContainerLocalizer.APPCACHE + \"/\"\n               + ConverterUtils.toString(appID) + \"/output\" + \"/\" + mapId;\n-      LOG.debug(\"DEBUG0 \" + base);\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(\"DEBUG0 \" + base);\n+      }\n       // Index file\n       Path indexFileName \u003d lDirAlloc.getLocalPathToRead(\n           base + \"/file.out.index\", conf);\n       // Map-output file\n       Path mapOutputFileName \u003d lDirAlloc.getLocalPathToRead(\n           base + \"/file.out\", conf);\n-      LOG.debug(\"DEBUG1 \" + base + \" : \" + mapOutputFileName + \" : \" +\n-          indexFileName);\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(\"DEBUG1 \" + base + \" : \" + mapOutputFileName + \" : \"\n+            + indexFileName);\n+      }\n       final IndexRecord info \u003d \n         indexCache.getIndexInformation(mapId, reduce, indexFileName, user);\n       final ShuffleHeader header \u003d\n         new ShuffleHeader(mapId, info.partLength, info.rawLength, reduce);\n       final DataOutputBuffer dob \u003d new DataOutputBuffer();\n       header.write(dob);\n       ch.write(wrappedBuffer(dob.getData(), 0, dob.getLength()));\n       final File spillfile \u003d new File(mapOutputFileName.toString());\n       RandomAccessFile spill;\n       try {\n         spill \u003d new RandomAccessFile(spillfile, \"r\");\n       } catch (FileNotFoundException e) {\n         LOG.info(spillfile + \" not found\");\n         return null;\n       }\n       ChannelFuture writeFuture;\n       if (ch.getPipeline().get(SslHandler.class) \u003d\u003d null) {\n         final FadvisedFileRegion partition \u003d new FadvisedFileRegion(spill,\n             info.startOffset, info.partLength, manageOsCache, readaheadLength,\n             readaheadPool, spillfile.getAbsolutePath());\n         writeFuture \u003d ch.write(partition);\n         writeFuture.addListener(new ChannelFutureListener() {\n             // TODO error handling; distinguish IO/connection failures,\n             //      attribute to appropriate spill output\n           @Override\n           public void operationComplete(ChannelFuture future) {\n             partition.releaseExternalResources();\n           }\n         });\n       } else {\n         // HTTPS cannot be done with zero copy.\n         final FadvisedChunkedFile chunk \u003d new FadvisedChunkedFile(spill,\n             info.startOffset, info.partLength, sslFileBufferSize,\n             manageOsCache, readaheadLength, readaheadPool,\n             spillfile.getAbsolutePath());\n         writeFuture \u003d ch.write(chunk);\n       }\n       metrics.shuffleConnections.incr();\n       metrics.shuffleOutputBytes.incr(info.partLength); // optimistic\n       return writeFuture;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    protected ChannelFuture sendMapOutput(ChannelHandlerContext ctx, Channel ch,\n        String user, String jobId, String mapId, int reduce)\n        throws IOException {\n      // TODO replace w/ rsrc alloc\n      // $x/$user/appcache/$appId/output/$mapId\n      // TODO: Once Shuffle is out of NM, this can use MR APIs to convert between App and Job\n      JobID jobID \u003d JobID.forName(jobId);\n      ApplicationId appID \u003d Records.newRecord(ApplicationId.class);\n      appID.setClusterTimestamp(Long.parseLong(jobID.getJtIdentifier()));\n      appID.setId(jobID.getId());\n      final String base \u003d\n          ContainerLocalizer.USERCACHE + \"/\" + user + \"/\"\n              + ContainerLocalizer.APPCACHE + \"/\"\n              + ConverterUtils.toString(appID) + \"/output\" + \"/\" + mapId;\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"DEBUG0 \" + base);\n      }\n      // Index file\n      Path indexFileName \u003d lDirAlloc.getLocalPathToRead(\n          base + \"/file.out.index\", conf);\n      // Map-output file\n      Path mapOutputFileName \u003d lDirAlloc.getLocalPathToRead(\n          base + \"/file.out\", conf);\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"DEBUG1 \" + base + \" : \" + mapOutputFileName + \" : \"\n            + indexFileName);\n      }\n      final IndexRecord info \u003d \n        indexCache.getIndexInformation(mapId, reduce, indexFileName, user);\n      final ShuffleHeader header \u003d\n        new ShuffleHeader(mapId, info.partLength, info.rawLength, reduce);\n      final DataOutputBuffer dob \u003d new DataOutputBuffer();\n      header.write(dob);\n      ch.write(wrappedBuffer(dob.getData(), 0, dob.getLength()));\n      final File spillfile \u003d new File(mapOutputFileName.toString());\n      RandomAccessFile spill;\n      try {\n        spill \u003d new RandomAccessFile(spillfile, \"r\");\n      } catch (FileNotFoundException e) {\n        LOG.info(spillfile + \" not found\");\n        return null;\n      }\n      ChannelFuture writeFuture;\n      if (ch.getPipeline().get(SslHandler.class) \u003d\u003d null) {\n        final FadvisedFileRegion partition \u003d new FadvisedFileRegion(spill,\n            info.startOffset, info.partLength, manageOsCache, readaheadLength,\n            readaheadPool, spillfile.getAbsolutePath());\n        writeFuture \u003d ch.write(partition);\n        writeFuture.addListener(new ChannelFutureListener() {\n            // TODO error handling; distinguish IO/connection failures,\n            //      attribute to appropriate spill output\n          @Override\n          public void operationComplete(ChannelFuture future) {\n            partition.releaseExternalResources();\n          }\n        });\n      } else {\n        // HTTPS cannot be done with zero copy.\n        final FadvisedChunkedFile chunk \u003d new FadvisedChunkedFile(spill,\n            info.startOffset, info.partLength, sslFileBufferSize,\n            manageOsCache, readaheadLength, readaheadPool,\n            spillfile.getAbsolutePath());\n        writeFuture \u003d ch.write(chunk);\n      }\n      metrics.shuffleConnections.incr();\n      metrics.shuffleOutputBytes.incr(info.partLength); // optimistic\n      return writeFuture;\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java",
      "extendedDetails": {}
    },
    "3eb0cb27e8c037e6b29ac57ad72b5bffa362da38": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3289. Make use of fadvise in the NM\u0027s shuffle handler. (Contributed by Todd Lipcon and Siddharth Seth)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1368718 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/08/12 2:55 PM",
      "commitName": "3eb0cb27e8c037e6b29ac57ad72b5bffa362da38",
      "commitAuthor": "Siddharth Seth",
      "commitDateOld": "26/07/12 6:23 AM",
      "commitNameOld": "9d16c9354b0c05edb30d23003dcdec4cc44ed925",
      "commitAuthorOld": "Alejandro Abdelnur",
      "daysBetweenCommits": 7.36,
      "commitsBetweenForRepo": 40,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,61 +1,64 @@\n     protected ChannelFuture sendMapOutput(ChannelHandlerContext ctx, Channel ch,\n         String user, String jobId, String mapId, int reduce)\n         throws IOException {\n       // TODO replace w/ rsrc alloc\n       // $x/$user/appcache/$appId/output/$mapId\n       // TODO: Once Shuffle is out of NM, this can use MR APIs to convert between App and Job\n       JobID jobID \u003d JobID.forName(jobId);\n       ApplicationId appID \u003d Records.newRecord(ApplicationId.class);\n       appID.setClusterTimestamp(Long.parseLong(jobID.getJtIdentifier()));\n       appID.setId(jobID.getId());\n       final String base \u003d\n           ContainerLocalizer.USERCACHE + \"/\" + user + \"/\"\n               + ContainerLocalizer.APPCACHE + \"/\"\n               + ConverterUtils.toString(appID) + \"/output\" + \"/\" + mapId;\n       LOG.debug(\"DEBUG0 \" + base);\n       // Index file\n       Path indexFileName \u003d lDirAlloc.getLocalPathToRead(\n           base + \"/file.out.index\", conf);\n       // Map-output file\n       Path mapOutputFileName \u003d lDirAlloc.getLocalPathToRead(\n           base + \"/file.out\", conf);\n       LOG.debug(\"DEBUG1 \" + base + \" : \" + mapOutputFileName + \" : \" +\n           indexFileName);\n-      IndexRecord info \u003d \n+      final IndexRecord info \u003d \n         indexCache.getIndexInformation(mapId, reduce, indexFileName, user);\n       final ShuffleHeader header \u003d\n         new ShuffleHeader(mapId, info.partLength, info.rawLength, reduce);\n       final DataOutputBuffer dob \u003d new DataOutputBuffer();\n       header.write(dob);\n       ch.write(wrappedBuffer(dob.getData(), 0, dob.getLength()));\n-      File spillfile \u003d new File(mapOutputFileName.toString());\n+      final File spillfile \u003d new File(mapOutputFileName.toString());\n       RandomAccessFile spill;\n       try {\n         spill \u003d new RandomAccessFile(spillfile, \"r\");\n       } catch (FileNotFoundException e) {\n         LOG.info(spillfile + \" not found\");\n         return null;\n       }\n       ChannelFuture writeFuture;\n       if (ch.getPipeline().get(SslHandler.class) \u003d\u003d null) {\n-        final FileRegion partition \u003d new DefaultFileRegion(\n-            spill.getChannel(), info.startOffset, info.partLength);\n+        final FadvisedFileRegion partition \u003d new FadvisedFileRegion(spill,\n+            info.startOffset, info.partLength, manageOsCache, readaheadLength,\n+            readaheadPool, spillfile.getAbsolutePath());\n         writeFuture \u003d ch.write(partition);\n         writeFuture.addListener(new ChannelFutureListener() {\n             // TODO error handling; distinguish IO/connection failures,\n             //      attribute to appropriate spill output\n-            @Override\n-            public void operationComplete(ChannelFuture future) {\n-              partition.releaseExternalResources();\n-            }\n-          });\n+          @Override\n+          public void operationComplete(ChannelFuture future) {\n+            partition.releaseExternalResources();\n+          }\n+        });\n       } else {\n         // HTTPS cannot be done with zero copy.\n-        writeFuture \u003d ch.write(new ChunkedFile(spill, info.startOffset,\n-                                               info.partLength,\n-                                               sslFileBufferSize));\n+        final FadvisedChunkedFile chunk \u003d new FadvisedChunkedFile(spill,\n+            info.startOffset, info.partLength, sslFileBufferSize,\n+            manageOsCache, readaheadLength, readaheadPool,\n+            spillfile.getAbsolutePath());\n+        writeFuture \u003d ch.write(chunk);\n       }\n       metrics.shuffleConnections.incr();\n       metrics.shuffleOutputBytes.incr(info.partLength); // optimistic\n       return writeFuture;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    protected ChannelFuture sendMapOutput(ChannelHandlerContext ctx, Channel ch,\n        String user, String jobId, String mapId, int reduce)\n        throws IOException {\n      // TODO replace w/ rsrc alloc\n      // $x/$user/appcache/$appId/output/$mapId\n      // TODO: Once Shuffle is out of NM, this can use MR APIs to convert between App and Job\n      JobID jobID \u003d JobID.forName(jobId);\n      ApplicationId appID \u003d Records.newRecord(ApplicationId.class);\n      appID.setClusterTimestamp(Long.parseLong(jobID.getJtIdentifier()));\n      appID.setId(jobID.getId());\n      final String base \u003d\n          ContainerLocalizer.USERCACHE + \"/\" + user + \"/\"\n              + ContainerLocalizer.APPCACHE + \"/\"\n              + ConverterUtils.toString(appID) + \"/output\" + \"/\" + mapId;\n      LOG.debug(\"DEBUG0 \" + base);\n      // Index file\n      Path indexFileName \u003d lDirAlloc.getLocalPathToRead(\n          base + \"/file.out.index\", conf);\n      // Map-output file\n      Path mapOutputFileName \u003d lDirAlloc.getLocalPathToRead(\n          base + \"/file.out\", conf);\n      LOG.debug(\"DEBUG1 \" + base + \" : \" + mapOutputFileName + \" : \" +\n          indexFileName);\n      final IndexRecord info \u003d \n        indexCache.getIndexInformation(mapId, reduce, indexFileName, user);\n      final ShuffleHeader header \u003d\n        new ShuffleHeader(mapId, info.partLength, info.rawLength, reduce);\n      final DataOutputBuffer dob \u003d new DataOutputBuffer();\n      header.write(dob);\n      ch.write(wrappedBuffer(dob.getData(), 0, dob.getLength()));\n      final File spillfile \u003d new File(mapOutputFileName.toString());\n      RandomAccessFile spill;\n      try {\n        spill \u003d new RandomAccessFile(spillfile, \"r\");\n      } catch (FileNotFoundException e) {\n        LOG.info(spillfile + \" not found\");\n        return null;\n      }\n      ChannelFuture writeFuture;\n      if (ch.getPipeline().get(SslHandler.class) \u003d\u003d null) {\n        final FadvisedFileRegion partition \u003d new FadvisedFileRegion(spill,\n            info.startOffset, info.partLength, manageOsCache, readaheadLength,\n            readaheadPool, spillfile.getAbsolutePath());\n        writeFuture \u003d ch.write(partition);\n        writeFuture.addListener(new ChannelFutureListener() {\n            // TODO error handling; distinguish IO/connection failures,\n            //      attribute to appropriate spill output\n          @Override\n          public void operationComplete(ChannelFuture future) {\n            partition.releaseExternalResources();\n          }\n        });\n      } else {\n        // HTTPS cannot be done with zero copy.\n        final FadvisedChunkedFile chunk \u003d new FadvisedChunkedFile(spill,\n            info.startOffset, info.partLength, sslFileBufferSize,\n            manageOsCache, readaheadLength, readaheadPool,\n            spillfile.getAbsolutePath());\n        writeFuture \u003d ch.write(chunk);\n      }\n      metrics.shuffleConnections.incr();\n      metrics.shuffleOutputBytes.incr(info.partLength); // optimistic\n      return writeFuture;\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java",
      "extendedDetails": {}
    },
    "9d16c9354b0c05edb30d23003dcdec4cc44ed925": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4417. add support for encrypted shuffle (tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1365979 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "26/07/12 6:23 AM",
      "commitName": "9d16c9354b0c05edb30d23003dcdec4cc44ed925",
      "commitAuthor": "Alejandro Abdelnur",
      "commitDateOld": "09/01/12 6:15 PM",
      "commitNameOld": "849c68c7b5f80064de3692d766444c2f8864f47a",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 198.46,
      "commitsBetweenForRepo": 1336,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,53 +1,61 @@\n     protected ChannelFuture sendMapOutput(ChannelHandlerContext ctx, Channel ch,\n         String user, String jobId, String mapId, int reduce)\n         throws IOException {\n       // TODO replace w/ rsrc alloc\n       // $x/$user/appcache/$appId/output/$mapId\n       // TODO: Once Shuffle is out of NM, this can use MR APIs to convert between App and Job\n       JobID jobID \u003d JobID.forName(jobId);\n       ApplicationId appID \u003d Records.newRecord(ApplicationId.class);\n       appID.setClusterTimestamp(Long.parseLong(jobID.getJtIdentifier()));\n       appID.setId(jobID.getId());\n       final String base \u003d\n           ContainerLocalizer.USERCACHE + \"/\" + user + \"/\"\n               + ContainerLocalizer.APPCACHE + \"/\"\n               + ConverterUtils.toString(appID) + \"/output\" + \"/\" + mapId;\n       LOG.debug(\"DEBUG0 \" + base);\n       // Index file\n       Path indexFileName \u003d lDirAlloc.getLocalPathToRead(\n           base + \"/file.out.index\", conf);\n       // Map-output file\n       Path mapOutputFileName \u003d lDirAlloc.getLocalPathToRead(\n           base + \"/file.out\", conf);\n       LOG.debug(\"DEBUG1 \" + base + \" : \" + mapOutputFileName + \" : \" +\n           indexFileName);\n       IndexRecord info \u003d \n         indexCache.getIndexInformation(mapId, reduce, indexFileName, user);\n       final ShuffleHeader header \u003d\n         new ShuffleHeader(mapId, info.partLength, info.rawLength, reduce);\n       final DataOutputBuffer dob \u003d new DataOutputBuffer();\n       header.write(dob);\n       ch.write(wrappedBuffer(dob.getData(), 0, dob.getLength()));\n       File spillfile \u003d new File(mapOutputFileName.toString());\n       RandomAccessFile spill;\n       try {\n         spill \u003d new RandomAccessFile(spillfile, \"r\");\n       } catch (FileNotFoundException e) {\n         LOG.info(spillfile + \" not found\");\n         return null;\n       }\n-      final FileRegion partition \u003d new DefaultFileRegion(\n-          spill.getChannel(), info.startOffset, info.partLength);\n-      ChannelFuture writeFuture \u003d ch.write(partition);\n-      writeFuture.addListener(new ChannelFutureListener() {\n-          // TODO error handling; distinguish IO/connection failures,\n-          //      attribute to appropriate spill output\n-          @Override\n-          public void operationComplete(ChannelFuture future) {\n-            partition.releaseExternalResources();\n-          }\n-        });\n+      ChannelFuture writeFuture;\n+      if (ch.getPipeline().get(SslHandler.class) \u003d\u003d null) {\n+        final FileRegion partition \u003d new DefaultFileRegion(\n+            spill.getChannel(), info.startOffset, info.partLength);\n+        writeFuture \u003d ch.write(partition);\n+        writeFuture.addListener(new ChannelFutureListener() {\n+            // TODO error handling; distinguish IO/connection failures,\n+            //      attribute to appropriate spill output\n+            @Override\n+            public void operationComplete(ChannelFuture future) {\n+              partition.releaseExternalResources();\n+            }\n+          });\n+      } else {\n+        // HTTPS cannot be done with zero copy.\n+        writeFuture \u003d ch.write(new ChunkedFile(spill, info.startOffset,\n+                                               info.partLength,\n+                                               sslFileBufferSize));\n+      }\n       metrics.shuffleConnections.incr();\n       metrics.shuffleOutputBytes.incr(info.partLength); // optimistic\n       return writeFuture;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    protected ChannelFuture sendMapOutput(ChannelHandlerContext ctx, Channel ch,\n        String user, String jobId, String mapId, int reduce)\n        throws IOException {\n      // TODO replace w/ rsrc alloc\n      // $x/$user/appcache/$appId/output/$mapId\n      // TODO: Once Shuffle is out of NM, this can use MR APIs to convert between App and Job\n      JobID jobID \u003d JobID.forName(jobId);\n      ApplicationId appID \u003d Records.newRecord(ApplicationId.class);\n      appID.setClusterTimestamp(Long.parseLong(jobID.getJtIdentifier()));\n      appID.setId(jobID.getId());\n      final String base \u003d\n          ContainerLocalizer.USERCACHE + \"/\" + user + \"/\"\n              + ContainerLocalizer.APPCACHE + \"/\"\n              + ConverterUtils.toString(appID) + \"/output\" + \"/\" + mapId;\n      LOG.debug(\"DEBUG0 \" + base);\n      // Index file\n      Path indexFileName \u003d lDirAlloc.getLocalPathToRead(\n          base + \"/file.out.index\", conf);\n      // Map-output file\n      Path mapOutputFileName \u003d lDirAlloc.getLocalPathToRead(\n          base + \"/file.out\", conf);\n      LOG.debug(\"DEBUG1 \" + base + \" : \" + mapOutputFileName + \" : \" +\n          indexFileName);\n      IndexRecord info \u003d \n        indexCache.getIndexInformation(mapId, reduce, indexFileName, user);\n      final ShuffleHeader header \u003d\n        new ShuffleHeader(mapId, info.partLength, info.rawLength, reduce);\n      final DataOutputBuffer dob \u003d new DataOutputBuffer();\n      header.write(dob);\n      ch.write(wrappedBuffer(dob.getData(), 0, dob.getLength()));\n      File spillfile \u003d new File(mapOutputFileName.toString());\n      RandomAccessFile spill;\n      try {\n        spill \u003d new RandomAccessFile(spillfile, \"r\");\n      } catch (FileNotFoundException e) {\n        LOG.info(spillfile + \" not found\");\n        return null;\n      }\n      ChannelFuture writeFuture;\n      if (ch.getPipeline().get(SslHandler.class) \u003d\u003d null) {\n        final FileRegion partition \u003d new DefaultFileRegion(\n            spill.getChannel(), info.startOffset, info.partLength);\n        writeFuture \u003d ch.write(partition);\n        writeFuture.addListener(new ChannelFutureListener() {\n            // TODO error handling; distinguish IO/connection failures,\n            //      attribute to appropriate spill output\n            @Override\n            public void operationComplete(ChannelFuture future) {\n              partition.releaseExternalResources();\n            }\n          });\n      } else {\n        // HTTPS cannot be done with zero copy.\n        writeFuture \u003d ch.write(new ChunkedFile(spill, info.startOffset,\n                                               info.partLength,\n                                               sslFileBufferSize));\n      }\n      metrics.shuffleConnections.incr();\n      metrics.shuffleOutputBytes.incr(info.partLength); // optimistic\n      return writeFuture;\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    protected ChannelFuture sendMapOutput(ChannelHandlerContext ctx, Channel ch,\n        String user, String jobId, String mapId, int reduce)\n        throws IOException {\n      // TODO replace w/ rsrc alloc\n      // $x/$user/appcache/$appId/output/$mapId\n      // TODO: Once Shuffle is out of NM, this can use MR APIs to convert between App and Job\n      JobID jobID \u003d JobID.forName(jobId);\n      ApplicationId appID \u003d Records.newRecord(ApplicationId.class);\n      appID.setClusterTimestamp(Long.parseLong(jobID.getJtIdentifier()));\n      appID.setId(jobID.getId());\n      final String base \u003d\n          ContainerLocalizer.USERCACHE + \"/\" + user + \"/\"\n              + ContainerLocalizer.APPCACHE + \"/\"\n              + ConverterUtils.toString(appID) + \"/output\" + \"/\" + mapId;\n      LOG.debug(\"DEBUG0 \" + base);\n      // Index file\n      Path indexFileName \u003d lDirAlloc.getLocalPathToRead(\n          base + \"/file.out.index\", conf);\n      // Map-output file\n      Path mapOutputFileName \u003d lDirAlloc.getLocalPathToRead(\n          base + \"/file.out\", conf);\n      LOG.debug(\"DEBUG1 \" + base + \" : \" + mapOutputFileName + \" : \" +\n          indexFileName);\n      IndexRecord info \u003d \n        indexCache.getIndexInformation(mapId, reduce, indexFileName, user);\n      final ShuffleHeader header \u003d\n        new ShuffleHeader(mapId, info.partLength, info.rawLength, reduce);\n      final DataOutputBuffer dob \u003d new DataOutputBuffer();\n      header.write(dob);\n      ch.write(wrappedBuffer(dob.getData(), 0, dob.getLength()));\n      File spillfile \u003d new File(mapOutputFileName.toString());\n      RandomAccessFile spill;\n      try {\n        spill \u003d new RandomAccessFile(spillfile, \"r\");\n      } catch (FileNotFoundException e) {\n        LOG.info(spillfile + \" not found\");\n        return null;\n      }\n      final FileRegion partition \u003d new DefaultFileRegion(\n          spill.getChannel(), info.startOffset, info.partLength);\n      ChannelFuture writeFuture \u003d ch.write(partition);\n      writeFuture.addListener(new ChannelFutureListener() {\n          // TODO error handling; distinguish IO/connection failures,\n          //      attribute to appropriate spill output\n          @Override\n          public void operationComplete(ChannelFuture future) {\n            partition.releaseExternalResources();\n          }\n        });\n      metrics.shuffleConnections.incr();\n      metrics.shuffleOutputBytes.incr(info.partLength); // optimistic\n      return writeFuture;\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java",
        "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "diff": "@@ -0,0 +1,53 @@\n+    protected ChannelFuture sendMapOutput(ChannelHandlerContext ctx, Channel ch,\n+        String user, String jobId, String mapId, int reduce)\n+        throws IOException {\n+      // TODO replace w/ rsrc alloc\n+      // $x/$user/appcache/$appId/output/$mapId\n+      // TODO: Once Shuffle is out of NM, this can use MR APIs to convert between App and Job\n+      JobID jobID \u003d JobID.forName(jobId);\n+      ApplicationId appID \u003d Records.newRecord(ApplicationId.class);\n+      appID.setClusterTimestamp(Long.parseLong(jobID.getJtIdentifier()));\n+      appID.setId(jobID.getId());\n+      final String base \u003d\n+          ContainerLocalizer.USERCACHE + \"/\" + user + \"/\"\n+              + ContainerLocalizer.APPCACHE + \"/\"\n+              + ConverterUtils.toString(appID) + \"/output\" + \"/\" + mapId;\n+      LOG.debug(\"DEBUG0 \" + base);\n+      // Index file\n+      Path indexFileName \u003d lDirAlloc.getLocalPathToRead(\n+          base + \"/file.out.index\", conf);\n+      // Map-output file\n+      Path mapOutputFileName \u003d lDirAlloc.getLocalPathToRead(\n+          base + \"/file.out\", conf);\n+      LOG.debug(\"DEBUG1 \" + base + \" : \" + mapOutputFileName + \" : \" +\n+          indexFileName);\n+      IndexRecord info \u003d \n+        indexCache.getIndexInformation(mapId, reduce, indexFileName, user);\n+      final ShuffleHeader header \u003d\n+        new ShuffleHeader(mapId, info.partLength, info.rawLength, reduce);\n+      final DataOutputBuffer dob \u003d new DataOutputBuffer();\n+      header.write(dob);\n+      ch.write(wrappedBuffer(dob.getData(), 0, dob.getLength()));\n+      File spillfile \u003d new File(mapOutputFileName.toString());\n+      RandomAccessFile spill;\n+      try {\n+        spill \u003d new RandomAccessFile(spillfile, \"r\");\n+      } catch (FileNotFoundException e) {\n+        LOG.info(spillfile + \" not found\");\n+        return null;\n+      }\n+      final FileRegion partition \u003d new DefaultFileRegion(\n+          spill.getChannel(), info.startOffset, info.partLength);\n+      ChannelFuture writeFuture \u003d ch.write(partition);\n+      writeFuture.addListener(new ChannelFutureListener() {\n+          // TODO error handling; distinguish IO/connection failures,\n+          //      attribute to appropriate spill output\n+          @Override\n+          public void operationComplete(ChannelFuture future) {\n+            partition.releaseExternalResources();\n+          }\n+        });\n+      metrics.shuffleConnections.incr();\n+      metrics.shuffleOutputBytes.incr(info.partLength); // optimistic\n+      return writeFuture;\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    protected ChannelFuture sendMapOutput(ChannelHandlerContext ctx, Channel ch,\n        String user, String jobId, String mapId, int reduce)\n        throws IOException {\n      // TODO replace w/ rsrc alloc\n      // $x/$user/appcache/$appId/output/$mapId\n      // TODO: Once Shuffle is out of NM, this can use MR APIs to convert between App and Job\n      JobID jobID \u003d JobID.forName(jobId);\n      ApplicationId appID \u003d Records.newRecord(ApplicationId.class);\n      appID.setClusterTimestamp(Long.parseLong(jobID.getJtIdentifier()));\n      appID.setId(jobID.getId());\n      final String base \u003d\n          ContainerLocalizer.USERCACHE + \"/\" + user + \"/\"\n              + ContainerLocalizer.APPCACHE + \"/\"\n              + ConverterUtils.toString(appID) + \"/output\" + \"/\" + mapId;\n      LOG.debug(\"DEBUG0 \" + base);\n      // Index file\n      Path indexFileName \u003d lDirAlloc.getLocalPathToRead(\n          base + \"/file.out.index\", conf);\n      // Map-output file\n      Path mapOutputFileName \u003d lDirAlloc.getLocalPathToRead(\n          base + \"/file.out\", conf);\n      LOG.debug(\"DEBUG1 \" + base + \" : \" + mapOutputFileName + \" : \" +\n          indexFileName);\n      IndexRecord info \u003d \n        indexCache.getIndexInformation(mapId, reduce, indexFileName, user);\n      final ShuffleHeader header \u003d\n        new ShuffleHeader(mapId, info.partLength, info.rawLength, reduce);\n      final DataOutputBuffer dob \u003d new DataOutputBuffer();\n      header.write(dob);\n      ch.write(wrappedBuffer(dob.getData(), 0, dob.getLength()));\n      File spillfile \u003d new File(mapOutputFileName.toString());\n      RandomAccessFile spill;\n      try {\n        spill \u003d new RandomAccessFile(spillfile, \"r\");\n      } catch (FileNotFoundException e) {\n        LOG.info(spillfile + \" not found\");\n        return null;\n      }\n      final FileRegion partition \u003d new DefaultFileRegion(\n          spill.getChannel(), info.startOffset, info.partLength);\n      ChannelFuture writeFuture \u003d ch.write(partition);\n      writeFuture.addListener(new ChannelFutureListener() {\n          // TODO error handling; distinguish IO/connection failures,\n          //      attribute to appropriate spill output\n          @Override\n          public void operationComplete(ChannelFuture future) {\n            partition.releaseExternalResources();\n          }\n        });\n      metrics.shuffleConnections.incr();\n      metrics.shuffleOutputBytes.incr(info.partLength); // optimistic\n      return writeFuture;\n    }",
      "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java"
    }
  }
}