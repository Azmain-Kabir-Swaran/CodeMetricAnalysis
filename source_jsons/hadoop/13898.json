{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockManager.java",
  "functionName": "isNodeHealthyForDecommissionOrMaintenance",
  "functionId": "isNodeHealthyForDecommissionOrMaintenance___node-DatanodeDescriptor",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
  "functionStartLine": 4528,
  "functionEndLine": 4555,
  "numCommitsSeen": 828,
  "timeTaken": 13966,
  "changeHistory": [
    "b61fb267b92b2736920b4bd0c673d31e7632ebb9",
    "5865fe2bf01284993572ea60b3ec3bf8b4492818",
    "32d043d9c5f4615058ea4f65a58ba271ba47fcb5",
    "be7a0add8b6561d3c566237cc0370b06e7f32bb4",
    "5a540c3d3107199f4632e2ad7ee8ff913b107a04",
    "6ee0d32b98bc3aa5ed42859f1325d5a14fd1722a"
  ],
  "changeHistoryShort": {
    "b61fb267b92b2736920b4bd0c673d31e7632ebb9": "Ymultichange(Yrename,Ybodychange)",
    "5865fe2bf01284993572ea60b3ec3bf8b4492818": "Ybodychange",
    "32d043d9c5f4615058ea4f65a58ba271ba47fcb5": "Ybodychange",
    "be7a0add8b6561d3c566237cc0370b06e7f32bb4": "Ybodychange",
    "5a540c3d3107199f4632e2ad7ee8ff913b107a04": "Ybodychange",
    "6ee0d32b98bc3aa5ed42859f1325d5a14fd1722a": "Yintroduced"
  },
  "changeHistoryDetails": {
    "b61fb267b92b2736920b4bd0c673d31e7632ebb9": {
      "type": "Ymultichange(Yrename,Ybodychange)",
      "commitMessage": "HDFS-9390. Block management for maintenance states.\n",
      "commitDate": "17/10/16 5:45 PM",
      "commitName": "b61fb267b92b2736920b4bd0c673d31e7632ebb9",
      "commitAuthor": "Ming Ma",
      "subchanges": [
        {
          "type": "Yrename",
          "commitMessage": "HDFS-9390. Block management for maintenance states.\n",
          "commitDate": "17/10/16 5:45 PM",
          "commitName": "b61fb267b92b2736920b4bd0c673d31e7632ebb9",
          "commitAuthor": "Ming Ma",
          "commitDateOld": "14/10/16 6:13 PM",
          "commitNameOld": "391ce535a739dc92cb90017d759217265a4fd969",
          "commitAuthorOld": "Vinitha Reddy Gankidi",
          "daysBetweenCommits": 2.98,
          "commitsBetweenForRepo": 11,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,27 +1,28 @@\n-  boolean isNodeHealthyForDecommission(DatanodeDescriptor node) {\n+  boolean isNodeHealthyForDecommissionOrMaintenance(DatanodeDescriptor node) {\n     if (!node.checkBlockReportReceived()) {\n       LOG.info(\"Node {} hasn\u0027t sent its first block report.\", node);\n       return false;\n     }\n \n     if (node.isAlive()) {\n       return true;\n     }\n \n     updateState();\n     if (pendingReconstructionBlocksCount \u003d\u003d 0 \u0026\u0026\n         lowRedundancyBlocksCount \u003d\u003d 0) {\n       LOG.info(\"Node {} is dead and there are no low redundancy\" +\n-          \" blocks or blocks pending reconstruction. Safe to decommission.\",\n-          node);\n+          \" blocks or blocks pending reconstruction. Safe to decommission or\",\n+          \" put in maintenance.\", node);\n       return true;\n     }\n \n     LOG.warn(\"Node {} is dead \" +\n-        \"while decommission is in progress. Cannot be safely \" +\n-        \"decommissioned since there is risk of reduced \" +\n-        \"data durability or data loss. Either restart the failed node or\" +\n-        \" force decommissioning by removing, calling refreshNodes, \" +\n-        \"then re-adding to the excludes files.\", node);\n+        \"while in {}. Cannot be safely \" +\n+        \"decommissioned or be in maintenance since there is risk of reduced \" +\n+        \"data durability or data loss. Either restart the failed node or \" +\n+        \"force decommissioning or maintenance by removing, calling \" +\n+        \"refreshNodes, then re-adding to the excludes or host config files.\",\n+        node, node.getAdminState());\n     return false;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  boolean isNodeHealthyForDecommissionOrMaintenance(DatanodeDescriptor node) {\n    if (!node.checkBlockReportReceived()) {\n      LOG.info(\"Node {} hasn\u0027t sent its first block report.\", node);\n      return false;\n    }\n\n    if (node.isAlive()) {\n      return true;\n    }\n\n    updateState();\n    if (pendingReconstructionBlocksCount \u003d\u003d 0 \u0026\u0026\n        lowRedundancyBlocksCount \u003d\u003d 0) {\n      LOG.info(\"Node {} is dead and there are no low redundancy\" +\n          \" blocks or blocks pending reconstruction. Safe to decommission or\",\n          \" put in maintenance.\", node);\n      return true;\n    }\n\n    LOG.warn(\"Node {} is dead \" +\n        \"while in {}. Cannot be safely \" +\n        \"decommissioned or be in maintenance since there is risk of reduced \" +\n        \"data durability or data loss. Either restart the failed node or \" +\n        \"force decommissioning or maintenance by removing, calling \" +\n        \"refreshNodes, then re-adding to the excludes or host config files.\",\n        node, node.getAdminState());\n    return false;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
          "extendedDetails": {
            "oldValue": "isNodeHealthyForDecommission",
            "newValue": "isNodeHealthyForDecommissionOrMaintenance"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-9390. Block management for maintenance states.\n",
          "commitDate": "17/10/16 5:45 PM",
          "commitName": "b61fb267b92b2736920b4bd0c673d31e7632ebb9",
          "commitAuthor": "Ming Ma",
          "commitDateOld": "14/10/16 6:13 PM",
          "commitNameOld": "391ce535a739dc92cb90017d759217265a4fd969",
          "commitAuthorOld": "Vinitha Reddy Gankidi",
          "daysBetweenCommits": 2.98,
          "commitsBetweenForRepo": 11,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,27 +1,28 @@\n-  boolean isNodeHealthyForDecommission(DatanodeDescriptor node) {\n+  boolean isNodeHealthyForDecommissionOrMaintenance(DatanodeDescriptor node) {\n     if (!node.checkBlockReportReceived()) {\n       LOG.info(\"Node {} hasn\u0027t sent its first block report.\", node);\n       return false;\n     }\n \n     if (node.isAlive()) {\n       return true;\n     }\n \n     updateState();\n     if (pendingReconstructionBlocksCount \u003d\u003d 0 \u0026\u0026\n         lowRedundancyBlocksCount \u003d\u003d 0) {\n       LOG.info(\"Node {} is dead and there are no low redundancy\" +\n-          \" blocks or blocks pending reconstruction. Safe to decommission.\",\n-          node);\n+          \" blocks or blocks pending reconstruction. Safe to decommission or\",\n+          \" put in maintenance.\", node);\n       return true;\n     }\n \n     LOG.warn(\"Node {} is dead \" +\n-        \"while decommission is in progress. Cannot be safely \" +\n-        \"decommissioned since there is risk of reduced \" +\n-        \"data durability or data loss. Either restart the failed node or\" +\n-        \" force decommissioning by removing, calling refreshNodes, \" +\n-        \"then re-adding to the excludes files.\", node);\n+        \"while in {}. Cannot be safely \" +\n+        \"decommissioned or be in maintenance since there is risk of reduced \" +\n+        \"data durability or data loss. Either restart the failed node or \" +\n+        \"force decommissioning or maintenance by removing, calling \" +\n+        \"refreshNodes, then re-adding to the excludes or host config files.\",\n+        node, node.getAdminState());\n     return false;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  boolean isNodeHealthyForDecommissionOrMaintenance(DatanodeDescriptor node) {\n    if (!node.checkBlockReportReceived()) {\n      LOG.info(\"Node {} hasn\u0027t sent its first block report.\", node);\n      return false;\n    }\n\n    if (node.isAlive()) {\n      return true;\n    }\n\n    updateState();\n    if (pendingReconstructionBlocksCount \u003d\u003d 0 \u0026\u0026\n        lowRedundancyBlocksCount \u003d\u003d 0) {\n      LOG.info(\"Node {} is dead and there are no low redundancy\" +\n          \" blocks or blocks pending reconstruction. Safe to decommission or\",\n          \" put in maintenance.\", node);\n      return true;\n    }\n\n    LOG.warn(\"Node {} is dead \" +\n        \"while in {}. Cannot be safely \" +\n        \"decommissioned or be in maintenance since there is risk of reduced \" +\n        \"data durability or data loss. Either restart the failed node or \" +\n        \"force decommissioning or maintenance by removing, calling \" +\n        \"refreshNodes, then re-adding to the excludes or host config files.\",\n        node, node.getAdminState());\n    return false;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "5865fe2bf01284993572ea60b3ec3bf8b4492818": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9869. Erasure Coding: Rename replication-based names in BlockManager to more generic [part-2]. Contributed by Rakesh R.\n",
      "commitDate": "25/04/16 10:01 PM",
      "commitName": "5865fe2bf01284993572ea60b3ec3bf8b4492818",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "17/04/16 6:28 PM",
      "commitNameOld": "67523ffcf491f4f2db5335899c00a174d0caaa9b",
      "commitAuthorOld": "Walter Su",
      "daysBetweenCommits": 8.15,
      "commitsBetweenForRepo": 47,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,27 +1,27 @@\n   boolean isNodeHealthyForDecommission(DatanodeDescriptor node) {\n     if (!node.checkBlockReportReceived()) {\n       LOG.info(\"Node {} hasn\u0027t sent its first block report.\", node);\n       return false;\n     }\n \n     if (node.isAlive()) {\n       return true;\n     }\n \n     updateState();\n-    if (pendingReplicationBlocksCount \u003d\u003d 0 \u0026\u0026\n+    if (pendingReconstructionBlocksCount \u003d\u003d 0 \u0026\u0026\n         lowRedundancyBlocksCount \u003d\u003d 0) {\n       LOG.info(\"Node {} is dead and there are no low redundancy\" +\n           \" blocks or blocks pending reconstruction. Safe to decommission.\",\n           node);\n       return true;\n     }\n \n     LOG.warn(\"Node {} is dead \" +\n         \"while decommission is in progress. Cannot be safely \" +\n         \"decommissioned since there is risk of reduced \" +\n         \"data durability or data loss. Either restart the failed node or\" +\n         \" force decommissioning by removing, calling refreshNodes, \" +\n         \"then re-adding to the excludes files.\", node);\n     return false;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  boolean isNodeHealthyForDecommission(DatanodeDescriptor node) {\n    if (!node.checkBlockReportReceived()) {\n      LOG.info(\"Node {} hasn\u0027t sent its first block report.\", node);\n      return false;\n    }\n\n    if (node.isAlive()) {\n      return true;\n    }\n\n    updateState();\n    if (pendingReconstructionBlocksCount \u003d\u003d 0 \u0026\u0026\n        lowRedundancyBlocksCount \u003d\u003d 0) {\n      LOG.info(\"Node {} is dead and there are no low redundancy\" +\n          \" blocks or blocks pending reconstruction. Safe to decommission.\",\n          node);\n      return true;\n    }\n\n    LOG.warn(\"Node {} is dead \" +\n        \"while decommission is in progress. Cannot be safely \" +\n        \"decommissioned since there is risk of reduced \" +\n        \"data durability or data loss. Either restart the failed node or\" +\n        \" force decommissioning by removing, calling refreshNodes, \" +\n        \"then re-adding to the excludes files.\", node);\n    return false;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "32d043d9c5f4615058ea4f65a58ba271ba47fcb5": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9857. Erasure Coding: Rename replication-based names in BlockManager to more generic [part-1]. Contributed by Rakesh R.\n",
      "commitDate": "16/03/16 4:53 PM",
      "commitName": "32d043d9c5f4615058ea4f65a58ba271ba47fcb5",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "10/03/16 7:03 PM",
      "commitNameOld": "e01c6ea688e62f25c4310e771a0cd85b53a5fb87",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 5.87,
      "commitsBetweenForRepo": 26,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,27 +1,27 @@\n   boolean isNodeHealthyForDecommission(DatanodeDescriptor node) {\n     if (!node.checkBlockReportReceived()) {\n       LOG.info(\"Node {} hasn\u0027t sent its first block report.\", node);\n       return false;\n     }\n \n     if (node.isAlive()) {\n       return true;\n     }\n \n     updateState();\n     if (pendingReplicationBlocksCount \u003d\u003d 0 \u0026\u0026\n-        underReplicatedBlocksCount \u003d\u003d 0) {\n-      LOG.info(\"Node {} is dead and there are no under-replicated\" +\n-          \" blocks or blocks pending replication. Safe to decommission.\",\n+        lowRedundancyBlocksCount \u003d\u003d 0) {\n+      LOG.info(\"Node {} is dead and there are no low redundancy\" +\n+          \" blocks or blocks pending reconstruction. Safe to decommission.\",\n           node);\n       return true;\n     }\n \n     LOG.warn(\"Node {} is dead \" +\n         \"while decommission is in progress. Cannot be safely \" +\n         \"decommissioned since there is risk of reduced \" +\n         \"data durability or data loss. Either restart the failed node or\" +\n         \" force decommissioning by removing, calling refreshNodes, \" +\n         \"then re-adding to the excludes files.\", node);\n     return false;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  boolean isNodeHealthyForDecommission(DatanodeDescriptor node) {\n    if (!node.checkBlockReportReceived()) {\n      LOG.info(\"Node {} hasn\u0027t sent its first block report.\", node);\n      return false;\n    }\n\n    if (node.isAlive()) {\n      return true;\n    }\n\n    updateState();\n    if (pendingReplicationBlocksCount \u003d\u003d 0 \u0026\u0026\n        lowRedundancyBlocksCount \u003d\u003d 0) {\n      LOG.info(\"Node {} is dead and there are no low redundancy\" +\n          \" blocks or blocks pending reconstruction. Safe to decommission.\",\n          node);\n      return true;\n    }\n\n    LOG.warn(\"Node {} is dead \" +\n        \"while decommission is in progress. Cannot be safely \" +\n        \"decommissioned since there is risk of reduced \" +\n        \"data durability or data loss. Either restart the failed node or\" +\n        \" force decommissioning by removing, calling refreshNodes, \" +\n        \"then re-adding to the excludes files.\", node);\n    return false;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "be7a0add8b6561d3c566237cc0370b06e7f32bb4": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9223. Code cleanup for DatanodeDescriptor and HeartbeatManager. Contributed by Jing Zhao.\n",
      "commitDate": "14/10/15 4:17 PM",
      "commitName": "be7a0add8b6561d3c566237cc0370b06e7f32bb4",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "13/10/15 11:00 PM",
      "commitNameOld": "2a987243423eb5c7e191de2ba969b7591a441c70",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 0.72,
      "commitsBetweenForRepo": 12,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,27 +1,27 @@\n   boolean isNodeHealthyForDecommission(DatanodeDescriptor node) {\n     if (!node.checkBlockReportReceived()) {\n       LOG.info(\"Node {} hasn\u0027t sent its first block report.\", node);\n       return false;\n     }\n \n-    if (node.isAlive) {\n+    if (node.isAlive()) {\n       return true;\n     }\n \n     updateState();\n     if (pendingReplicationBlocksCount \u003d\u003d 0 \u0026\u0026\n         underReplicatedBlocksCount \u003d\u003d 0) {\n       LOG.info(\"Node {} is dead and there are no under-replicated\" +\n           \" blocks or blocks pending replication. Safe to decommission.\",\n           node);\n       return true;\n     }\n \n     LOG.warn(\"Node {} is dead \" +\n         \"while decommission is in progress. Cannot be safely \" +\n         \"decommissioned since there is risk of reduced \" +\n         \"data durability or data loss. Either restart the failed node or\" +\n         \" force decommissioning by removing, calling refreshNodes, \" +\n         \"then re-adding to the excludes files.\", node);\n     return false;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  boolean isNodeHealthyForDecommission(DatanodeDescriptor node) {\n    if (!node.checkBlockReportReceived()) {\n      LOG.info(\"Node {} hasn\u0027t sent its first block report.\", node);\n      return false;\n    }\n\n    if (node.isAlive()) {\n      return true;\n    }\n\n    updateState();\n    if (pendingReplicationBlocksCount \u003d\u003d 0 \u0026\u0026\n        underReplicatedBlocksCount \u003d\u003d 0) {\n      LOG.info(\"Node {} is dead and there are no under-replicated\" +\n          \" blocks or blocks pending replication. Safe to decommission.\",\n          node);\n      return true;\n    }\n\n    LOG.warn(\"Node {} is dead \" +\n        \"while decommission is in progress. Cannot be safely \" +\n        \"decommissioned since there is risk of reduced \" +\n        \"data durability or data loss. Either restart the failed node or\" +\n        \" force decommissioning by removing, calling refreshNodes, \" +\n        \"then re-adding to the excludes files.\", node);\n    return false;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "5a540c3d3107199f4632e2ad7ee8ff913b107a04": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8025. Addendum fix for HDFS-3087 Decomissioning on NN restart can complete without blocks being replicated. Contributed by Ming Ma.\n",
      "commitDate": "08/04/15 4:09 PM",
      "commitName": "5a540c3d3107199f4632e2ad7ee8ff913b107a04",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "02/04/15 11:36 AM",
      "commitNameOld": "96649c38f9ab00a9845d2c6e35e6264894da5309",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 6.19,
      "commitsBetweenForRepo": 49,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,27 @@\n   boolean isNodeHealthyForDecommission(DatanodeDescriptor node) {\n+    if (!node.checkBlockReportReceived()) {\n+      LOG.info(\"Node {} hasn\u0027t sent its first block report.\", node);\n+      return false;\n+    }\n+\n     if (node.isAlive) {\n       return true;\n     }\n \n     updateState();\n     if (pendingReplicationBlocksCount \u003d\u003d 0 \u0026\u0026\n         underReplicatedBlocksCount \u003d\u003d 0) {\n       LOG.info(\"Node {} is dead and there are no under-replicated\" +\n           \" blocks or blocks pending replication. Safe to decommission.\", \n           node);\n       return true;\n     }\n \n     LOG.warn(\"Node {} is dead \" +\n         \"while decommission is in progress. Cannot be safely \" +\n         \"decommissioned since there is risk of reduced \" +\n         \"data durability or data loss. Either restart the failed node or\" +\n         \" force decommissioning by removing, calling refreshNodes, \" +\n         \"then re-adding to the excludes files.\", node);\n     return false;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  boolean isNodeHealthyForDecommission(DatanodeDescriptor node) {\n    if (!node.checkBlockReportReceived()) {\n      LOG.info(\"Node {} hasn\u0027t sent its first block report.\", node);\n      return false;\n    }\n\n    if (node.isAlive) {\n      return true;\n    }\n\n    updateState();\n    if (pendingReplicationBlocksCount \u003d\u003d 0 \u0026\u0026\n        underReplicatedBlocksCount \u003d\u003d 0) {\n      LOG.info(\"Node {} is dead and there are no under-replicated\" +\n          \" blocks or blocks pending replication. Safe to decommission.\", \n          node);\n      return true;\n    }\n\n    LOG.warn(\"Node {} is dead \" +\n        \"while decommission is in progress. Cannot be safely \" +\n        \"decommissioned since there is risk of reduced \" +\n        \"data durability or data loss. Either restart the failed node or\" +\n        \" force decommissioning by removing, calling refreshNodes, \" +\n        \"then re-adding to the excludes files.\", node);\n    return false;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "6ee0d32b98bc3aa5ed42859f1325d5a14fd1722a": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-7411. Change decommission logic to throttle by blocks rather\nthan nodes in each interval. Contributed by Andrew Wang\n",
      "commitDate": "08/03/15 6:31 PM",
      "commitName": "6ee0d32b98bc3aa5ed42859f1325d5a14fd1722a",
      "commitAuthor": "Chris Douglas",
      "diff": "@@ -0,0 +1,22 @@\n+  boolean isNodeHealthyForDecommission(DatanodeDescriptor node) {\n+    if (node.isAlive) {\n+      return true;\n+    }\n+\n+    updateState();\n+    if (pendingReplicationBlocksCount \u003d\u003d 0 \u0026\u0026\n+        underReplicatedBlocksCount \u003d\u003d 0) {\n+      LOG.info(\"Node {} is dead and there are no under-replicated\" +\n+          \" blocks or blocks pending replication. Safe to decommission.\", \n+          node);\n+      return true;\n+    }\n+\n+    LOG.warn(\"Node {} is dead \" +\n+        \"while decommission is in progress. Cannot be safely \" +\n+        \"decommissioned since there is risk of reduced \" +\n+        \"data durability or data loss. Either restart the failed node or\" +\n+        \" force decommissioning by removing, calling refreshNodes, \" +\n+        \"then re-adding to the excludes files.\", node);\n+    return false;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  boolean isNodeHealthyForDecommission(DatanodeDescriptor node) {\n    if (node.isAlive) {\n      return true;\n    }\n\n    updateState();\n    if (pendingReplicationBlocksCount \u003d\u003d 0 \u0026\u0026\n        underReplicatedBlocksCount \u003d\u003d 0) {\n      LOG.info(\"Node {} is dead and there are no under-replicated\" +\n          \" blocks or blocks pending replication. Safe to decommission.\", \n          node);\n      return true;\n    }\n\n    LOG.warn(\"Node {} is dead \" +\n        \"while decommission is in progress. Cannot be safely \" +\n        \"decommissioned since there is risk of reduced \" +\n        \"data durability or data loss. Either restart the failed node or\" +\n        \" force decommissioning by removing, calling refreshNodes, \" +\n        \"then re-adding to the excludes files.\", node);\n    return false;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java"
    }
  }
}