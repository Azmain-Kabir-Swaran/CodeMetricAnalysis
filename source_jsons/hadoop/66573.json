{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "HadoopArchiveLogs.java",
  "functionName": "run",
  "functionId": "run___args-String[]",
  "sourceFilePath": "hadoop-tools/hadoop-archive-logs/src/main/java/org/apache/hadoop/tools/HadoopArchiveLogs.java",
  "functionStartLine": 139,
  "functionEndLine": 214,
  "numCommitsSeen": 11,
  "timeTaken": 1665,
  "changeHistory": [
    "f47659fb9709f69846f08c489bcafd1e36f5bf09",
    "5af572b6443715b7a741296c1bd520a1840f9a7c",
    "5db371f52f5c6e894a7e6a5d523084f4b316a7ab",
    "d3c49e76624b7e42a1321c649a1d7bb9906b3073",
    "119cc75e7ebd723790f6326498383304aba384a2"
  ],
  "changeHistoryShort": {
    "f47659fb9709f69846f08c489bcafd1e36f5bf09": "Ybodychange",
    "5af572b6443715b7a741296c1bd520a1840f9a7c": "Ybodychange",
    "5db371f52f5c6e894a7e6a5d523084f4b316a7ab": "Ybodychange",
    "d3c49e76624b7e42a1321c649a1d7bb9906b3073": "Ybodychange",
    "119cc75e7ebd723790f6326498383304aba384a2": "Yintroduced"
  },
  "changeHistoryDetails": {
    "f47659fb9709f69846f08c489bcafd1e36f5bf09": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-7047. Make HAR tool support IndexedLogAggregtionController. (Xuan Gong via wangda)\n\nChange-Id: Ice5ae1c706f2476361997dcbb29f2c33c77d4f0c\n",
      "commitDate": "15/03/18 1:26 PM",
      "commitName": "f47659fb9709f69846f08c489bcafd1e36f5bf09",
      "commitAuthor": "Wangda Tan",
      "commitDateOld": "15/11/16 10:57 AM",
      "commitNameOld": "5af572b6443715b7a741296c1bd520a1840f9a7c",
      "commitAuthorOld": "Mingliang Liu",
      "daysBetweenCommits": 485.06,
      "commitsBetweenForRepo": 3078,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,52 +1,76 @@\n   public int run(String[] args) throws Exception {\n     int exitCode \u003d 1;\n \n     handleOpts(args);\n \n     FileSystem fs \u003d null;\n-    Path remoteRootLogDir \u003d new Path(conf.get(\n-        YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n-        YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n-    String suffix \u003d LogAggregationUtils.getRemoteNodeLogDirSuffix(conf);\n-    Path workingDir \u003d new Path(remoteRootLogDir, \"archive-logs-work\");\n-    if (verbose) {\n-      LOG.info(\"Remote Log Dir Root: \" + remoteRootLogDir);\n-      LOG.info(\"Log Suffix: \" + suffix);\n-      LOG.info(\"Working Dir: \" + workingDir);\n+\n+    LogAggregationFileControllerFactory factory \u003d\n+        new LogAggregationFileControllerFactory(conf);\n+    List\u003cLogAggregationFileController\u003e fileControllers \u003d factory\n+        .getConfiguredLogAggregationFileControllerList();\n+    if (fileControllers \u003d\u003d null || fileControllers.isEmpty()) {\n+      LOG.info(\"Can not find any valid fileControllers.\");\n+      if (verbose) {\n+        LOG.info(\"The configurated fileControllers:\"\n+            + YarnConfiguration.LOG_AGGREGATION_FILE_FORMATS);\n+      }\n+      return 0;\n     }\n     try {\n       fs \u003d FileSystem.get(conf);\n-      if (prepareWorkingDir(fs, workingDir)) {\n-\n-        checkFilesAndSeedApps(fs, remoteRootLogDir, suffix);\n+      // find eligibleApplications for all the fileControllers\n+      int previousTotal \u003d 0;\n+      for (LogAggregationFileController fileController : fileControllers) {\n+        Path remoteRootLogDir \u003d fileController.getRemoteRootLogDir();\n+        String suffix \u003d fileController.getRemoteRootLogDirSuffix();\n+        Path workingDir \u003d new Path(remoteRootLogDir, \"archive-logs-work\");\n+        if (verbose) {\n+          LOG.info(\"LogAggregationFileController:\" + fileController\n+              .getClass().getName());\n+          LOG.info(\"Remote Log Dir Root: \" + remoteRootLogDir);\n+          LOG.info(\"Log Suffix: \" + suffix);\n+          LOG.info(\"Working Dir: \" + workingDir);\n+        }\n+        checkFilesAndSeedApps(fs, remoteRootLogDir, suffix, workingDir);\n \n         filterAppsByAggregatedStatus();\n \n-        checkMaxEligible();\n-\n-        if (eligibleApplications.isEmpty()) {\n-          LOG.info(\"No eligible applications to process\");\n-          exitCode \u003d 0;\n-        } else {\n-          StringBuilder sb \u003d\n-              new StringBuilder(\"Will process the following applications:\");\n-          for (AppInfo app : eligibleApplications) {\n-            sb.append(\"\\n\\t\").append(app.getAppId());\n-          }\n-          LOG.info(sb.toString());\n-\n-          File localScript \u003d File.createTempFile(\"hadoop-archive-logs-\", \".sh\");\n-          generateScript(localScript, workingDir, remoteRootLogDir, suffix);\n-\n-          exitCode \u003d runDistributedShell(localScript) ? 0 : 1;\n+        if (eligibleApplications.size() \u003e previousTotal) {\n+          workingDirs.add(workingDir);\n+          previousTotal \u003d eligibleApplications.size();\n         }\n       }\n+      checkMaxEligible();\n+      if (workingDirs.isEmpty() || eligibleApplications.isEmpty()) {\n+        LOG.info(\"No eligible applications to process\");\n+        return 0;\n+      }\n+      for (Path workingDir : workingDirs) {\n+        if (!prepareWorkingDir(fs, workingDir)) {\n+          LOG.error(\"Failed to create the workingDir:\"\n+              + workingDir.toString());\n+          return 1;\n+        }\n+      }\n+      StringBuilder sb \u003d\n+          new StringBuilder(\"Will process the following applications:\");\n+      for (AppInfo app : eligibleApplications) {\n+        sb.append(\"\\n\\t\").append(app.getAppId());\n+      }\n+      LOG.info(sb.toString());\n+      File localScript \u003d File.createTempFile(\"hadoop-archive-logs-\", \".sh\");\n+      generateScript(localScript);\n+\n+      exitCode \u003d runDistributedShell(localScript) ? 0 : 1;\n     } finally {\n       if (fs !\u003d null) {\n         // Cleanup working directory\n-        fs.delete(workingDir, true);\n+        for (Path workingDir : workingDirs) {\n+          fs.delete(workingDir, true);\n+        }\n         fs.close();\n       }\n     }\n     return exitCode;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int run(String[] args) throws Exception {\n    int exitCode \u003d 1;\n\n    handleOpts(args);\n\n    FileSystem fs \u003d null;\n\n    LogAggregationFileControllerFactory factory \u003d\n        new LogAggregationFileControllerFactory(conf);\n    List\u003cLogAggregationFileController\u003e fileControllers \u003d factory\n        .getConfiguredLogAggregationFileControllerList();\n    if (fileControllers \u003d\u003d null || fileControllers.isEmpty()) {\n      LOG.info(\"Can not find any valid fileControllers.\");\n      if (verbose) {\n        LOG.info(\"The configurated fileControllers:\"\n            + YarnConfiguration.LOG_AGGREGATION_FILE_FORMATS);\n      }\n      return 0;\n    }\n    try {\n      fs \u003d FileSystem.get(conf);\n      // find eligibleApplications for all the fileControllers\n      int previousTotal \u003d 0;\n      for (LogAggregationFileController fileController : fileControllers) {\n        Path remoteRootLogDir \u003d fileController.getRemoteRootLogDir();\n        String suffix \u003d fileController.getRemoteRootLogDirSuffix();\n        Path workingDir \u003d new Path(remoteRootLogDir, \"archive-logs-work\");\n        if (verbose) {\n          LOG.info(\"LogAggregationFileController:\" + fileController\n              .getClass().getName());\n          LOG.info(\"Remote Log Dir Root: \" + remoteRootLogDir);\n          LOG.info(\"Log Suffix: \" + suffix);\n          LOG.info(\"Working Dir: \" + workingDir);\n        }\n        checkFilesAndSeedApps(fs, remoteRootLogDir, suffix, workingDir);\n\n        filterAppsByAggregatedStatus();\n\n        if (eligibleApplications.size() \u003e previousTotal) {\n          workingDirs.add(workingDir);\n          previousTotal \u003d eligibleApplications.size();\n        }\n      }\n      checkMaxEligible();\n      if (workingDirs.isEmpty() || eligibleApplications.isEmpty()) {\n        LOG.info(\"No eligible applications to process\");\n        return 0;\n      }\n      for (Path workingDir : workingDirs) {\n        if (!prepareWorkingDir(fs, workingDir)) {\n          LOG.error(\"Failed to create the workingDir:\"\n              + workingDir.toString());\n          return 1;\n        }\n      }\n      StringBuilder sb \u003d\n          new StringBuilder(\"Will process the following applications:\");\n      for (AppInfo app : eligibleApplications) {\n        sb.append(\"\\n\\t\").append(app.getAppId());\n      }\n      LOG.info(sb.toString());\n      File localScript \u003d File.createTempFile(\"hadoop-archive-logs-\", \".sh\");\n      generateScript(localScript);\n\n      exitCode \u003d runDistributedShell(localScript) ? 0 : 1;\n    } finally {\n      if (fs !\u003d null) {\n        // Cleanup working directory\n        for (Path workingDir : workingDirs) {\n          fs.delete(workingDir, true);\n        }\n        fs.close();\n      }\n    }\n    return exitCode;\n  }",
      "path": "hadoop-tools/hadoop-archive-logs/src/main/java/org/apache/hadoop/tools/HadoopArchiveLogs.java",
      "extendedDetails": {}
    },
    "5af572b6443715b7a741296c1bd520a1840f9a7c": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-13427. Eliminate needless uses of FileSystem#{exists(), isFile(), isDirectory()}. Contributed by Steve Loughran and Mingliang Liu\n",
      "commitDate": "15/11/16 10:57 AM",
      "commitName": "5af572b6443715b7a741296c1bd520a1840f9a7c",
      "commitAuthor": "Mingliang Liu",
      "commitDateOld": "14/06/16 3:06 PM",
      "commitNameOld": "c77a1095dc556e8bea87df6d8ddf36e898f27e86",
      "commitAuthorOld": "Wangda Tan",
      "daysBetweenCommits": 153.87,
      "commitsBetweenForRepo": 1240,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,54 +1,52 @@\n   public int run(String[] args) throws Exception {\n     int exitCode \u003d 1;\n \n     handleOpts(args);\n \n     FileSystem fs \u003d null;\n     Path remoteRootLogDir \u003d new Path(conf.get(\n         YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n         YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n     String suffix \u003d LogAggregationUtils.getRemoteNodeLogDirSuffix(conf);\n     Path workingDir \u003d new Path(remoteRootLogDir, \"archive-logs-work\");\n     if (verbose) {\n       LOG.info(\"Remote Log Dir Root: \" + remoteRootLogDir);\n       LOG.info(\"Log Suffix: \" + suffix);\n       LOG.info(\"Working Dir: \" + workingDir);\n     }\n     try {\n       fs \u003d FileSystem.get(conf);\n       if (prepareWorkingDir(fs, workingDir)) {\n \n         checkFilesAndSeedApps(fs, remoteRootLogDir, suffix);\n \n         filterAppsByAggregatedStatus();\n \n         checkMaxEligible();\n \n         if (eligibleApplications.isEmpty()) {\n           LOG.info(\"No eligible applications to process\");\n           exitCode \u003d 0;\n         } else {\n           StringBuilder sb \u003d\n               new StringBuilder(\"Will process the following applications:\");\n           for (AppInfo app : eligibleApplications) {\n             sb.append(\"\\n\\t\").append(app.getAppId());\n           }\n           LOG.info(sb.toString());\n \n           File localScript \u003d File.createTempFile(\"hadoop-archive-logs-\", \".sh\");\n           generateScript(localScript, workingDir, remoteRootLogDir, suffix);\n \n           exitCode \u003d runDistributedShell(localScript) ? 0 : 1;\n         }\n       }\n     } finally {\n       if (fs !\u003d null) {\n         // Cleanup working directory\n-        if (fs.exists(workingDir)) {\n-          fs.delete(workingDir, true);\n-        }\n+        fs.delete(workingDir, true);\n         fs.close();\n       }\n     }\n     return exitCode;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int run(String[] args) throws Exception {\n    int exitCode \u003d 1;\n\n    handleOpts(args);\n\n    FileSystem fs \u003d null;\n    Path remoteRootLogDir \u003d new Path(conf.get(\n        YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n        YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n    String suffix \u003d LogAggregationUtils.getRemoteNodeLogDirSuffix(conf);\n    Path workingDir \u003d new Path(remoteRootLogDir, \"archive-logs-work\");\n    if (verbose) {\n      LOG.info(\"Remote Log Dir Root: \" + remoteRootLogDir);\n      LOG.info(\"Log Suffix: \" + suffix);\n      LOG.info(\"Working Dir: \" + workingDir);\n    }\n    try {\n      fs \u003d FileSystem.get(conf);\n      if (prepareWorkingDir(fs, workingDir)) {\n\n        checkFilesAndSeedApps(fs, remoteRootLogDir, suffix);\n\n        filterAppsByAggregatedStatus();\n\n        checkMaxEligible();\n\n        if (eligibleApplications.isEmpty()) {\n          LOG.info(\"No eligible applications to process\");\n          exitCode \u003d 0;\n        } else {\n          StringBuilder sb \u003d\n              new StringBuilder(\"Will process the following applications:\");\n          for (AppInfo app : eligibleApplications) {\n            sb.append(\"\\n\\t\").append(app.getAppId());\n          }\n          LOG.info(sb.toString());\n\n          File localScript \u003d File.createTempFile(\"hadoop-archive-logs-\", \".sh\");\n          generateScript(localScript, workingDir, remoteRootLogDir, suffix);\n\n          exitCode \u003d runDistributedShell(localScript) ? 0 : 1;\n        }\n      }\n    } finally {\n      if (fs !\u003d null) {\n        // Cleanup working directory\n        fs.delete(workingDir, true);\n        fs.close();\n      }\n    }\n    return exitCode;\n  }",
      "path": "hadoop-tools/hadoop-archive-logs/src/main/java/org/apache/hadoop/tools/HadoopArchiveLogs.java",
      "extendedDetails": {}
    },
    "5db371f52f5c6e894a7e6a5d523084f4b316a7ab": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6494. Permission issue when running archive-logs tool as different users (rkanter)\n",
      "commitDate": "30/09/15 5:33 PM",
      "commitName": "5db371f52f5c6e894a7e6a5d523084f4b316a7ab",
      "commitAuthor": "Robert Kanter",
      "commitDateOld": "25/09/15 3:02 PM",
      "commitNameOld": "d3c49e76624b7e42a1321c649a1d7bb9906b3073",
      "commitAuthorOld": "Robert Kanter",
      "daysBetweenCommits": 5.1,
      "commitsBetweenForRepo": 40,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,55 +1,54 @@\n   public int run(String[] args) throws Exception {\n+    int exitCode \u003d 1;\n+\n     handleOpts(args);\n \n     FileSystem fs \u003d null;\n     Path remoteRootLogDir \u003d new Path(conf.get(\n         YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n         YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n     String suffix \u003d LogAggregationUtils.getRemoteNodeLogDirSuffix(conf);\n     Path workingDir \u003d new Path(remoteRootLogDir, \"archive-logs-work\");\n     if (verbose) {\n       LOG.info(\"Remote Log Dir Root: \" + remoteRootLogDir);\n       LOG.info(\"Log Suffix: \" + suffix);\n       LOG.info(\"Working Dir: \" + workingDir);\n     }\n     try {\n       fs \u003d FileSystem.get(conf);\n-      checkFilesAndSeedApps(fs, remoteRootLogDir, suffix);\n+      if (prepareWorkingDir(fs, workingDir)) {\n \n-      // Prepare working directory\n-      if (fs.exists(workingDir)) {\n-        fs.delete(workingDir, true);\n+        checkFilesAndSeedApps(fs, remoteRootLogDir, suffix);\n+\n+        filterAppsByAggregatedStatus();\n+\n+        checkMaxEligible();\n+\n+        if (eligibleApplications.isEmpty()) {\n+          LOG.info(\"No eligible applications to process\");\n+          exitCode \u003d 0;\n+        } else {\n+          StringBuilder sb \u003d\n+              new StringBuilder(\"Will process the following applications:\");\n+          for (AppInfo app : eligibleApplications) {\n+            sb.append(\"\\n\\t\").append(app.getAppId());\n+          }\n+          LOG.info(sb.toString());\n+\n+          File localScript \u003d File.createTempFile(\"hadoop-archive-logs-\", \".sh\");\n+          generateScript(localScript, workingDir, remoteRootLogDir, suffix);\n+\n+          exitCode \u003d runDistributedShell(localScript) ? 0 : 1;\n+        }\n       }\n-      fs.mkdirs(workingDir);\n-      fs.setPermission(workingDir,\n-          new FsPermission(FsAction.ALL, FsAction.NONE, FsAction.NONE));\n     } finally {\n       if (fs !\u003d null) {\n+        // Cleanup working directory\n+        if (fs.exists(workingDir)) {\n+          fs.delete(workingDir, true);\n+        }\n         fs.close();\n       }\n     }\n-\n-    filterAppsByAggregatedStatus();\n-\n-    checkMaxEligible();\n-\n-    if (eligibleApplications.isEmpty()) {\n-      LOG.info(\"No eligible applications to process\");\n-      System.exit(0);\n-    }\n-\n-    StringBuilder sb \u003d\n-        new StringBuilder(\"Will process the following applications:\");\n-    for (AppInfo app : eligibleApplications) {\n-      sb.append(\"\\n\\t\").append(app.getAppId());\n-    }\n-    LOG.info(sb.toString());\n-\n-    File localScript \u003d File.createTempFile(\"hadoop-archive-logs-\", \".sh\");\n-    generateScript(localScript, workingDir, remoteRootLogDir, suffix);\n-\n-    if (runDistributedShell(localScript)) {\n-      return 0;\n-    }\n-    return -1;\n+    return exitCode;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int run(String[] args) throws Exception {\n    int exitCode \u003d 1;\n\n    handleOpts(args);\n\n    FileSystem fs \u003d null;\n    Path remoteRootLogDir \u003d new Path(conf.get(\n        YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n        YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n    String suffix \u003d LogAggregationUtils.getRemoteNodeLogDirSuffix(conf);\n    Path workingDir \u003d new Path(remoteRootLogDir, \"archive-logs-work\");\n    if (verbose) {\n      LOG.info(\"Remote Log Dir Root: \" + remoteRootLogDir);\n      LOG.info(\"Log Suffix: \" + suffix);\n      LOG.info(\"Working Dir: \" + workingDir);\n    }\n    try {\n      fs \u003d FileSystem.get(conf);\n      if (prepareWorkingDir(fs, workingDir)) {\n\n        checkFilesAndSeedApps(fs, remoteRootLogDir, suffix);\n\n        filterAppsByAggregatedStatus();\n\n        checkMaxEligible();\n\n        if (eligibleApplications.isEmpty()) {\n          LOG.info(\"No eligible applications to process\");\n          exitCode \u003d 0;\n        } else {\n          StringBuilder sb \u003d\n              new StringBuilder(\"Will process the following applications:\");\n          for (AppInfo app : eligibleApplications) {\n            sb.append(\"\\n\\t\").append(app.getAppId());\n          }\n          LOG.info(sb.toString());\n\n          File localScript \u003d File.createTempFile(\"hadoop-archive-logs-\", \".sh\");\n          generateScript(localScript, workingDir, remoteRootLogDir, suffix);\n\n          exitCode \u003d runDistributedShell(localScript) ? 0 : 1;\n        }\n      }\n    } finally {\n      if (fs !\u003d null) {\n        // Cleanup working directory\n        if (fs.exists(workingDir)) {\n          fs.delete(workingDir, true);\n        }\n        fs.close();\n      }\n    }\n    return exitCode;\n  }",
      "path": "hadoop-tools/hadoop-archive-logs/src/main/java/org/apache/hadoop/tools/HadoopArchiveLogs.java",
      "extendedDetails": {}
    },
    "d3c49e76624b7e42a1321c649a1d7bb9906b3073": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6480. archive-logs tool may miss applications (rkanter)\n",
      "commitDate": "25/09/15 3:02 PM",
      "commitName": "d3c49e76624b7e42a1321c649a1d7bb9906b3073",
      "commitAuthor": "Robert Kanter",
      "commitDateOld": "09/09/15 5:45 PM",
      "commitNameOld": "119cc75e7ebd723790f6326498383304aba384a2",
      "commitAuthorOld": "Karthik Kambatla",
      "daysBetweenCommits": 15.89,
      "commitsBetweenForRepo": 119,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,50 +1,55 @@\n   public int run(String[] args) throws Exception {\n     handleOpts(args);\n \n-    findAggregatedApps();\n-\n     FileSystem fs \u003d null;\n     Path remoteRootLogDir \u003d new Path(conf.get(\n         YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n         YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n     String suffix \u003d LogAggregationUtils.getRemoteNodeLogDirSuffix(conf);\n     Path workingDir \u003d new Path(remoteRootLogDir, \"archive-logs-work\");\n+    if (verbose) {\n+      LOG.info(\"Remote Log Dir Root: \" + remoteRootLogDir);\n+      LOG.info(\"Log Suffix: \" + suffix);\n+      LOG.info(\"Working Dir: \" + workingDir);\n+    }\n     try {\n       fs \u003d FileSystem.get(conf);\n-      checkFiles(fs, remoteRootLogDir, suffix);\n+      checkFilesAndSeedApps(fs, remoteRootLogDir, suffix);\n \n       // Prepare working directory\n       if (fs.exists(workingDir)) {\n         fs.delete(workingDir, true);\n       }\n       fs.mkdirs(workingDir);\n       fs.setPermission(workingDir,\n           new FsPermission(FsAction.ALL, FsAction.NONE, FsAction.NONE));\n     } finally {\n       if (fs !\u003d null) {\n         fs.close();\n       }\n     }\n \n+    filterAppsByAggregatedStatus();\n+\n     checkMaxEligible();\n \n     if (eligibleApplications.isEmpty()) {\n       LOG.info(\"No eligible applications to process\");\n       System.exit(0);\n     }\n \n     StringBuilder sb \u003d\n         new StringBuilder(\"Will process the following applications:\");\n-    for (ApplicationReport report : eligibleApplications) {\n-      sb.append(\"\\n\\t\").append(report.getApplicationId());\n+    for (AppInfo app : eligibleApplications) {\n+      sb.append(\"\\n\\t\").append(app.getAppId());\n     }\n     LOG.info(sb.toString());\n \n     File localScript \u003d File.createTempFile(\"hadoop-archive-logs-\", \".sh\");\n     generateScript(localScript, workingDir, remoteRootLogDir, suffix);\n \n     if (runDistributedShell(localScript)) {\n       return 0;\n     }\n     return -1;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int run(String[] args) throws Exception {\n    handleOpts(args);\n\n    FileSystem fs \u003d null;\n    Path remoteRootLogDir \u003d new Path(conf.get(\n        YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n        YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n    String suffix \u003d LogAggregationUtils.getRemoteNodeLogDirSuffix(conf);\n    Path workingDir \u003d new Path(remoteRootLogDir, \"archive-logs-work\");\n    if (verbose) {\n      LOG.info(\"Remote Log Dir Root: \" + remoteRootLogDir);\n      LOG.info(\"Log Suffix: \" + suffix);\n      LOG.info(\"Working Dir: \" + workingDir);\n    }\n    try {\n      fs \u003d FileSystem.get(conf);\n      checkFilesAndSeedApps(fs, remoteRootLogDir, suffix);\n\n      // Prepare working directory\n      if (fs.exists(workingDir)) {\n        fs.delete(workingDir, true);\n      }\n      fs.mkdirs(workingDir);\n      fs.setPermission(workingDir,\n          new FsPermission(FsAction.ALL, FsAction.NONE, FsAction.NONE));\n    } finally {\n      if (fs !\u003d null) {\n        fs.close();\n      }\n    }\n\n    filterAppsByAggregatedStatus();\n\n    checkMaxEligible();\n\n    if (eligibleApplications.isEmpty()) {\n      LOG.info(\"No eligible applications to process\");\n      System.exit(0);\n    }\n\n    StringBuilder sb \u003d\n        new StringBuilder(\"Will process the following applications:\");\n    for (AppInfo app : eligibleApplications) {\n      sb.append(\"\\n\\t\").append(app.getAppId());\n    }\n    LOG.info(sb.toString());\n\n    File localScript \u003d File.createTempFile(\"hadoop-archive-logs-\", \".sh\");\n    generateScript(localScript, workingDir, remoteRootLogDir, suffix);\n\n    if (runDistributedShell(localScript)) {\n      return 0;\n    }\n    return -1;\n  }",
      "path": "hadoop-tools/hadoop-archive-logs/src/main/java/org/apache/hadoop/tools/HadoopArchiveLogs.java",
      "extendedDetails": {}
    },
    "119cc75e7ebd723790f6326498383304aba384a2": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-6415. Create a tool to combine aggregated logs into HAR files. (Robert Kanter via kasha)\n",
      "commitDate": "09/09/15 5:45 PM",
      "commitName": "119cc75e7ebd723790f6326498383304aba384a2",
      "commitAuthor": "Karthik Kambatla",
      "diff": "@@ -0,0 +1,50 @@\n+  public int run(String[] args) throws Exception {\n+    handleOpts(args);\n+\n+    findAggregatedApps();\n+\n+    FileSystem fs \u003d null;\n+    Path remoteRootLogDir \u003d new Path(conf.get(\n+        YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n+        YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n+    String suffix \u003d LogAggregationUtils.getRemoteNodeLogDirSuffix(conf);\n+    Path workingDir \u003d new Path(remoteRootLogDir, \"archive-logs-work\");\n+    try {\n+      fs \u003d FileSystem.get(conf);\n+      checkFiles(fs, remoteRootLogDir, suffix);\n+\n+      // Prepare working directory\n+      if (fs.exists(workingDir)) {\n+        fs.delete(workingDir, true);\n+      }\n+      fs.mkdirs(workingDir);\n+      fs.setPermission(workingDir,\n+          new FsPermission(FsAction.ALL, FsAction.NONE, FsAction.NONE));\n+    } finally {\n+      if (fs !\u003d null) {\n+        fs.close();\n+      }\n+    }\n+\n+    checkMaxEligible();\n+\n+    if (eligibleApplications.isEmpty()) {\n+      LOG.info(\"No eligible applications to process\");\n+      System.exit(0);\n+    }\n+\n+    StringBuilder sb \u003d\n+        new StringBuilder(\"Will process the following applications:\");\n+    for (ApplicationReport report : eligibleApplications) {\n+      sb.append(\"\\n\\t\").append(report.getApplicationId());\n+    }\n+    LOG.info(sb.toString());\n+\n+    File localScript \u003d File.createTempFile(\"hadoop-archive-logs-\", \".sh\");\n+    generateScript(localScript, workingDir, remoteRootLogDir, suffix);\n+\n+    if (runDistributedShell(localScript)) {\n+      return 0;\n+    }\n+    return -1;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public int run(String[] args) throws Exception {\n    handleOpts(args);\n\n    findAggregatedApps();\n\n    FileSystem fs \u003d null;\n    Path remoteRootLogDir \u003d new Path(conf.get(\n        YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n        YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n    String suffix \u003d LogAggregationUtils.getRemoteNodeLogDirSuffix(conf);\n    Path workingDir \u003d new Path(remoteRootLogDir, \"archive-logs-work\");\n    try {\n      fs \u003d FileSystem.get(conf);\n      checkFiles(fs, remoteRootLogDir, suffix);\n\n      // Prepare working directory\n      if (fs.exists(workingDir)) {\n        fs.delete(workingDir, true);\n      }\n      fs.mkdirs(workingDir);\n      fs.setPermission(workingDir,\n          new FsPermission(FsAction.ALL, FsAction.NONE, FsAction.NONE));\n    } finally {\n      if (fs !\u003d null) {\n        fs.close();\n      }\n    }\n\n    checkMaxEligible();\n\n    if (eligibleApplications.isEmpty()) {\n      LOG.info(\"No eligible applications to process\");\n      System.exit(0);\n    }\n\n    StringBuilder sb \u003d\n        new StringBuilder(\"Will process the following applications:\");\n    for (ApplicationReport report : eligibleApplications) {\n      sb.append(\"\\n\\t\").append(report.getApplicationId());\n    }\n    LOG.info(sb.toString());\n\n    File localScript \u003d File.createTempFile(\"hadoop-archive-logs-\", \".sh\");\n    generateScript(localScript, workingDir, remoteRootLogDir, suffix);\n\n    if (runDistributedShell(localScript)) {\n      return 0;\n    }\n    return -1;\n  }",
      "path": "hadoop-tools/hadoop-archive-logs/src/main/java/org/apache/hadoop/tools/HadoopArchiveLogs.java"
    }
  }
}