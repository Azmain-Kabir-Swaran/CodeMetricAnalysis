{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "KeyManager.java",
  "functionName": "newDataEncryptionKey",
  "functionId": "newDataEncryptionKey",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/balancer/KeyManager.java",
  "functionStartLine": 120,
  "functionEndLine": 149,
  "numCommitsSeen": 49,
  "timeTaken": 4168,
  "changeHistory": [
    "6a3fc685a98718742c351ed6625dc7a4dee55e77",
    "83b9933db3349e6a6faf23bce35c9d4ce3f7bcf2",
    "3b54223c0f32d42a84436c670d80b791a8e9696d",
    "1fbb04e367d7c330e6052207f9f11911f4f5f368",
    "9b4a7900c7dfc0590316eedaa97144f938885651"
  ],
  "changeHistoryShort": {
    "6a3fc685a98718742c351ed6625dc7a4dee55e77": "Ybodychange",
    "83b9933db3349e6a6faf23bce35c9d4ce3f7bcf2": "Ymovefromfile",
    "3b54223c0f32d42a84436c670d80b791a8e9696d": "Ymultichange(Yrename,Ymodifierchange,Yexceptionschange,Ybodychange)",
    "1fbb04e367d7c330e6052207f9f11911f4f5f368": "Ybodychange",
    "9b4a7900c7dfc0590316eedaa97144f938885651": "Yintroduced"
  },
  "changeHistoryDetails": {
    "6a3fc685a98718742c351ed6625dc7a4dee55e77": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11741. Long running balancer may fail due to expired DataEncryptionKey. Contributed by Wei-Chiu Chuang and Xiao Chen.\n",
      "commitDate": "01/06/17 2:05 PM",
      "commitName": "6a3fc685a98718742c351ed6625dc7a4dee55e77",
      "commitAuthor": "Xiao Chen",
      "commitDateOld": "05/05/17 12:01 PM",
      "commitNameOld": "a3954ccab148bddc290cb96528e63ff19799bcc9",
      "commitAuthorOld": "Chris Douglas",
      "daysBetweenCommits": 27.09,
      "commitsBetweenForRepo": 140,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,30 @@\n   public DataEncryptionKey newDataEncryptionKey() {\n     if (encryptDataTransfer) {\n       synchronized (this) {\n-        if (encryptionKey \u003d\u003d null) {\n+        if (encryptionKey \u003d\u003d null ||\n+            encryptionKey.expiryDate \u003c timer.now()) {\n+          // Encryption Key (EK) is generated from Block Key (BK).\n+          // Check if EK is expired, and generate a new one using the current BK\n+          // if so, otherwise continue to use the previously generated EK.\n+          //\n+          // It\u0027s important to make sure that when EK is not expired, the BK\n+          // used to generate the EK is not expired and removed, because\n+          // the same BK will be used to re-generate the EK\n+          // by BlockTokenSecretManager.\n+          //\n+          // The current implementation ensures that when an EK is not expired\n+          // (within tokenLifetime), the BK that\u0027s used to generate it\n+          // still has at least \"keyUpdateInterval\" of life time before\n+          // the BK gets expired and removed.\n+          // See BlockTokenSecretManager for details.\n+          LOG.debug(\"Generating new data encryption key because current key \"\n+              + (encryptionKey \u003d\u003d null ?\n+              \"is null.\" : \"expired on \" + encryptionKey.expiryDate));\n           encryptionKey \u003d blockTokenSecretManager.generateDataEncryptionKey();\n         }\n         return encryptionKey;\n       }\n     } else {\n       return null;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public DataEncryptionKey newDataEncryptionKey() {\n    if (encryptDataTransfer) {\n      synchronized (this) {\n        if (encryptionKey \u003d\u003d null ||\n            encryptionKey.expiryDate \u003c timer.now()) {\n          // Encryption Key (EK) is generated from Block Key (BK).\n          // Check if EK is expired, and generate a new one using the current BK\n          // if so, otherwise continue to use the previously generated EK.\n          //\n          // It\u0027s important to make sure that when EK is not expired, the BK\n          // used to generate the EK is not expired and removed, because\n          // the same BK will be used to re-generate the EK\n          // by BlockTokenSecretManager.\n          //\n          // The current implementation ensures that when an EK is not expired\n          // (within tokenLifetime), the BK that\u0027s used to generate it\n          // still has at least \"keyUpdateInterval\" of life time before\n          // the BK gets expired and removed.\n          // See BlockTokenSecretManager for details.\n          LOG.debug(\"Generating new data encryption key because current key \"\n              + (encryptionKey \u003d\u003d null ?\n              \"is null.\" : \"expired on \" + encryptionKey.expiryDate));\n          encryptionKey \u003d blockTokenSecretManager.generateDataEncryptionKey();\n        }\n        return encryptionKey;\n      }\n    } else {\n      return null;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/balancer/KeyManager.java",
      "extendedDetails": {}
    },
    "83b9933db3349e6a6faf23bce35c9d4ce3f7bcf2": {
      "type": "Ymovefromfile",
      "commitMessage": "HDFS-6809. Move Balancer\u0027s inner classes MovedBlocks and Matcher as to standalone classes and separates KeyManager from NameNodeConnector.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1616422 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/08/14 12:18 AM",
      "commitName": "83b9933db3349e6a6faf23bce35c9d4ce3f7bcf2",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "06/08/14 10:36 PM",
      "commitNameOld": "be6360593b65019852c685d7975136c7cd2889ab",
      "commitAuthorOld": "Zhijie Shen",
      "daysBetweenCommits": 0.07,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public DataEncryptionKey newDataEncryptionKey() {\n    if (encryptDataTransfer) {\n      synchronized (this) {\n        if (encryptionKey \u003d\u003d null) {\n          encryptionKey \u003d blockTokenSecretManager.generateDataEncryptionKey();\n        }\n        return encryptionKey;\n      }\n    } else {\n      return null;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/balancer/KeyManager.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/balancer/NameNodeConnector.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/balancer/KeyManager.java",
        "oldMethodName": "newDataEncryptionKey",
        "newMethodName": "newDataEncryptionKey"
      }
    },
    "3b54223c0f32d42a84436c670d80b791a8e9696d": {
      "type": "Ymultichange(Yrename,Ymodifierchange,Yexceptionschange,Ybodychange)",
      "commitMessage": "HDFS-2856. Fix block protocol so that Datanodes don\u0027t require root or jsvc. Contributed by Chris Nauroth.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1610474 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/07/14 11:10 AM",
      "commitName": "3b54223c0f32d42a84436c670d80b791a8e9696d",
      "commitAuthor": "Chris Nauroth",
      "subchanges": [
        {
          "type": "Yrename",
          "commitMessage": "HDFS-2856. Fix block protocol so that Datanodes don\u0027t require root or jsvc. Contributed by Chris Nauroth.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1610474 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "14/07/14 11:10 AM",
          "commitName": "3b54223c0f32d42a84436c670d80b791a8e9696d",
          "commitAuthor": "Chris Nauroth",
          "commitDateOld": "16/05/14 2:56 AM",
          "commitNameOld": "0fb47dbe4e8a65f202b57ce70a1c00e266706c32",
          "commitAuthorOld": "Junping Du",
          "daysBetweenCommits": 59.34,
          "commitsBetweenForRepo": 346,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,13 +1,12 @@\n-  DataEncryptionKey getDataEncryptionKey()\n-      throws IOException {\n-    if (encryptDataTransfer \u0026\u0026 !this.trustedChannelResolver.isTrusted()) {\n+  public DataEncryptionKey newDataEncryptionKey() {\n+    if (encryptDataTransfer) {\n       synchronized (this) {\n         if (encryptionKey \u003d\u003d null) {\n           encryptionKey \u003d blockTokenSecretManager.generateDataEncryptionKey();\n         }\n         return encryptionKey;\n       }\n     } else {\n       return null;\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public DataEncryptionKey newDataEncryptionKey() {\n    if (encryptDataTransfer) {\n      synchronized (this) {\n        if (encryptionKey \u003d\u003d null) {\n          encryptionKey \u003d blockTokenSecretManager.generateDataEncryptionKey();\n        }\n        return encryptionKey;\n      }\n    } else {\n      return null;\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/balancer/NameNodeConnector.java",
          "extendedDetails": {
            "oldValue": "getDataEncryptionKey",
            "newValue": "newDataEncryptionKey"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-2856. Fix block protocol so that Datanodes don\u0027t require root or jsvc. Contributed by Chris Nauroth.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1610474 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "14/07/14 11:10 AM",
          "commitName": "3b54223c0f32d42a84436c670d80b791a8e9696d",
          "commitAuthor": "Chris Nauroth",
          "commitDateOld": "16/05/14 2:56 AM",
          "commitNameOld": "0fb47dbe4e8a65f202b57ce70a1c00e266706c32",
          "commitAuthorOld": "Junping Du",
          "daysBetweenCommits": 59.34,
          "commitsBetweenForRepo": 346,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,13 +1,12 @@\n-  DataEncryptionKey getDataEncryptionKey()\n-      throws IOException {\n-    if (encryptDataTransfer \u0026\u0026 !this.trustedChannelResolver.isTrusted()) {\n+  public DataEncryptionKey newDataEncryptionKey() {\n+    if (encryptDataTransfer) {\n       synchronized (this) {\n         if (encryptionKey \u003d\u003d null) {\n           encryptionKey \u003d blockTokenSecretManager.generateDataEncryptionKey();\n         }\n         return encryptionKey;\n       }\n     } else {\n       return null;\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public DataEncryptionKey newDataEncryptionKey() {\n    if (encryptDataTransfer) {\n      synchronized (this) {\n        if (encryptionKey \u003d\u003d null) {\n          encryptionKey \u003d blockTokenSecretManager.generateDataEncryptionKey();\n        }\n        return encryptionKey;\n      }\n    } else {\n      return null;\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/balancer/NameNodeConnector.java",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[public]"
          }
        },
        {
          "type": "Yexceptionschange",
          "commitMessage": "HDFS-2856. Fix block protocol so that Datanodes don\u0027t require root or jsvc. Contributed by Chris Nauroth.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1610474 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "14/07/14 11:10 AM",
          "commitName": "3b54223c0f32d42a84436c670d80b791a8e9696d",
          "commitAuthor": "Chris Nauroth",
          "commitDateOld": "16/05/14 2:56 AM",
          "commitNameOld": "0fb47dbe4e8a65f202b57ce70a1c00e266706c32",
          "commitAuthorOld": "Junping Du",
          "daysBetweenCommits": 59.34,
          "commitsBetweenForRepo": 346,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,13 +1,12 @@\n-  DataEncryptionKey getDataEncryptionKey()\n-      throws IOException {\n-    if (encryptDataTransfer \u0026\u0026 !this.trustedChannelResolver.isTrusted()) {\n+  public DataEncryptionKey newDataEncryptionKey() {\n+    if (encryptDataTransfer) {\n       synchronized (this) {\n         if (encryptionKey \u003d\u003d null) {\n           encryptionKey \u003d blockTokenSecretManager.generateDataEncryptionKey();\n         }\n         return encryptionKey;\n       }\n     } else {\n       return null;\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public DataEncryptionKey newDataEncryptionKey() {\n    if (encryptDataTransfer) {\n      synchronized (this) {\n        if (encryptionKey \u003d\u003d null) {\n          encryptionKey \u003d blockTokenSecretManager.generateDataEncryptionKey();\n        }\n        return encryptionKey;\n      }\n    } else {\n      return null;\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/balancer/NameNodeConnector.java",
          "extendedDetails": {
            "oldValue": "[IOException]",
            "newValue": "[]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-2856. Fix block protocol so that Datanodes don\u0027t require root or jsvc. Contributed by Chris Nauroth.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1610474 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "14/07/14 11:10 AM",
          "commitName": "3b54223c0f32d42a84436c670d80b791a8e9696d",
          "commitAuthor": "Chris Nauroth",
          "commitDateOld": "16/05/14 2:56 AM",
          "commitNameOld": "0fb47dbe4e8a65f202b57ce70a1c00e266706c32",
          "commitAuthorOld": "Junping Du",
          "daysBetweenCommits": 59.34,
          "commitsBetweenForRepo": 346,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,13 +1,12 @@\n-  DataEncryptionKey getDataEncryptionKey()\n-      throws IOException {\n-    if (encryptDataTransfer \u0026\u0026 !this.trustedChannelResolver.isTrusted()) {\n+  public DataEncryptionKey newDataEncryptionKey() {\n+    if (encryptDataTransfer) {\n       synchronized (this) {\n         if (encryptionKey \u003d\u003d null) {\n           encryptionKey \u003d blockTokenSecretManager.generateDataEncryptionKey();\n         }\n         return encryptionKey;\n       }\n     } else {\n       return null;\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public DataEncryptionKey newDataEncryptionKey() {\n    if (encryptDataTransfer) {\n      synchronized (this) {\n        if (encryptionKey \u003d\u003d null) {\n          encryptionKey \u003d blockTokenSecretManager.generateDataEncryptionKey();\n        }\n        return encryptionKey;\n      }\n    } else {\n      return null;\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/balancer/NameNodeConnector.java",
          "extendedDetails": {}
        }
      ]
    },
    "1fbb04e367d7c330e6052207f9f11911f4f5f368": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5910. Enhance DataTransferProtocol to allow per-connection choice of encryption/plain-text. (Contributed by Benoy Antony)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1581688 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "25/03/14 9:11 PM",
      "commitName": "1fbb04e367d7c330e6052207f9f11911f4f5f368",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "10/01/13 3:20 PM",
      "commitNameOld": "be5509c53743a0beddda3f5798e72b919e797bd0",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 439.2,
      "commitsBetweenForRepo": 2855,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,13 @@\n   DataEncryptionKey getDataEncryptionKey()\n       throws IOException {\n-    if (encryptDataTransfer) {\n+    if (encryptDataTransfer \u0026\u0026 !this.trustedChannelResolver.isTrusted()) {\n       synchronized (this) {\n         if (encryptionKey \u003d\u003d null) {\n           encryptionKey \u003d blockTokenSecretManager.generateDataEncryptionKey();\n         }\n         return encryptionKey;\n       }\n     } else {\n       return null;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  DataEncryptionKey getDataEncryptionKey()\n      throws IOException {\n    if (encryptDataTransfer \u0026\u0026 !this.trustedChannelResolver.isTrusted()) {\n      synchronized (this) {\n        if (encryptionKey \u003d\u003d null) {\n          encryptionKey \u003d blockTokenSecretManager.generateDataEncryptionKey();\n        }\n        return encryptionKey;\n      }\n    } else {\n      return null;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/balancer/NameNodeConnector.java",
      "extendedDetails": {}
    },
    "9b4a7900c7dfc0590316eedaa97144f938885651": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-3637. Add support for encrypting the DataTransferProtocol. Contributed by Aaron T. Myers.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1370354 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/08/12 9:40 AM",
      "commitName": "9b4a7900c7dfc0590316eedaa97144f938885651",
      "commitAuthor": "Aaron Myers",
      "diff": "@@ -0,0 +1,13 @@\n+  DataEncryptionKey getDataEncryptionKey()\n+      throws IOException {\n+    if (encryptDataTransfer) {\n+      synchronized (this) {\n+        if (encryptionKey \u003d\u003d null) {\n+          encryptionKey \u003d blockTokenSecretManager.generateDataEncryptionKey();\n+        }\n+        return encryptionKey;\n+      }\n+    } else {\n+      return null;\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  DataEncryptionKey getDataEncryptionKey()\n      throws IOException {\n    if (encryptDataTransfer) {\n      synchronized (this) {\n        if (encryptionKey \u003d\u003d null) {\n          encryptionKey \u003d blockTokenSecretManager.generateDataEncryptionKey();\n        }\n        return encryptionKey;\n      }\n    } else {\n      return null;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/balancer/NameNodeConnector.java"
    }
  }
}