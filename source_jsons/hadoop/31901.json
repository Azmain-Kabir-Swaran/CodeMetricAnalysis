{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FlowScanner.java",
  "functionName": "processSummationMajorCompaction",
  "functionId": "processSummationMajorCompaction___currentColumnCells-SortedSet__Cell____converter-NumericValueConverter__currentTimestamp-long",
  "sourceFilePath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-server/hadoop-yarn-server-timelineservice-hbase-server-1/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/flow/FlowScanner.java",
  "functionStartLine": 431,
  "functionEndLine": 529,
  "numCommitsSeen": 22,
  "timeTaken": 5473,
  "changeHistory": [
    "55ba49dd071b66e72c47a1c41e88b9a5feddf53b",
    "10663b78c8596693322dc3636f173035195bf607",
    "5e37ca5bb49f945e27f49a413d08baab562dfa9c",
    "9af30d46c6e82332a8eda20cb3eb5f987e25e7a2",
    "b01514f65bc6090a50a583f67d1ecb5d74b6d276",
    "55f5886ea24671ff3db87a64aaba2e76b3355455",
    "7b8cfa5c2ff62005c8b78867fedd64b48e50383d",
    "9bdd455dced15c84430ea0a0a59410df924f02a7"
  ],
  "changeHistoryShort": {
    "55ba49dd071b66e72c47a1c41e88b9a5feddf53b": "Ymultichange(Yfilerename,Ybodychange)",
    "10663b78c8596693322dc3636f173035195bf607": "Ymultichange(Yfilerename,Ybodychange)",
    "5e37ca5bb49f945e27f49a413d08baab562dfa9c": "Ymultichange(Yfilerename,Ybodychange)",
    "9af30d46c6e82332a8eda20cb3eb5f987e25e7a2": "Ymultichange(Yfilerename,Ybodychange)",
    "b01514f65bc6090a50a583f67d1ecb5d74b6d276": "Yfilerename",
    "55f5886ea24671ff3db87a64aaba2e76b3355455": "Ybodychange",
    "7b8cfa5c2ff62005c8b78867fedd64b48e50383d": "Ybodychange",
    "9bdd455dced15c84430ea0a0a59410df924f02a7": "Yintroduced"
  },
  "changeHistoryDetails": {
    "55ba49dd071b66e72c47a1c41e88b9a5feddf53b": {
      "type": "Ymultichange(Yfilerename,Ybodychange)",
      "commitMessage": "YARN-7346. Add a profile to allow optional compilation for ATSv2 with HBase-2.0. Contributed by Haibo Chen and Rohith.\n",
      "commitDate": "05/03/18 10:25 PM",
      "commitName": "55ba49dd071b66e72c47a1c41e88b9a5feddf53b",
      "commitAuthor": "Rohith Sharma K S",
      "subchanges": [
        {
          "type": "Yfilerename",
          "commitMessage": "YARN-7346. Add a profile to allow optional compilation for ATSv2 with HBase-2.0. Contributed by Haibo Chen and Rohith.\n",
          "commitDate": "05/03/18 10:25 PM",
          "commitName": "55ba49dd071b66e72c47a1c41e88b9a5feddf53b",
          "commitAuthor": "Rohith Sharma K S",
          "commitDateOld": "05/03/18 6:15 PM",
          "commitNameOld": "745190ecdca8f7dfc5eebffdd1c1aa4f86229120",
          "commitAuthorOld": "Takanobu Asanuma",
          "daysBetweenCommits": 0.17,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,97 +1,99 @@\n   List\u003cCell\u003e processSummationMajorCompaction(\n       SortedSet\u003cCell\u003e currentColumnCells, NumericValueConverter converter,\n       long currentTimestamp)\n       throws IOException {\n     Number sum \u003d 0;\n     Number currentValue \u003d 0;\n     long ts \u003d 0L;\n     boolean summationDone \u003d false;\n     List\u003cCell\u003e finalCells \u003d new ArrayList\u003cCell\u003e();\n     if (currentColumnCells \u003d\u003d null) {\n       return finalCells;\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"In processSummationMajorCompaction,\"\n           + \" will drop cells older than \" + currentTimestamp\n           + \" CurrentColumnCells size\u003d\" + currentColumnCells.size());\n     }\n \n     for (Cell cell : currentColumnCells) {\n       AggregationOperation cellAggOp \u003d getCurrentAggOp(cell);\n       // if this is the existing flow sum cell\n-      List\u003cTag\u003e tags \u003d Tag.asList(cell.getTagsArray(), cell.getTagsOffset(),\n-          cell.getTagsLength());\n+      List\u003cTag\u003e tags \u003d HBaseTimelineServerUtils.convertCellAsTagList(cell);\n       String appId \u003d HBaseTimelineServerUtils\n           .getAggregationCompactionDimension(tags);\n       if (appId \u003d\u003d FLOW_APP_ID) {\n         sum \u003d converter.add(sum, currentValue);\n         summationDone \u003d true;\n         if (LOG.isTraceEnabled()) {\n           LOG.trace(\"reading flow app id sum\u003d\" + sum);\n         }\n       } else {\n         currentValue \u003d (Number) converter.decodeValue(CellUtil\n             .cloneValue(cell));\n         // read the timestamp truncated by the generator\n         ts \u003d  TimestampGenerator.getTruncatedTimestamp(cell.getTimestamp());\n         if ((cellAggOp \u003d\u003d AggregationOperation.SUM_FINAL)\n             \u0026\u0026 ((ts + this.appFinalValueRetentionThreshold)\n                 \u003c currentTimestamp)) {\n           sum \u003d converter.add(sum, currentValue);\n           summationDone \u003d true;\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"MAJOR COMPACTION loop sum\u003d \" + sum\n                 + \" discarding now: \" + \" qualifier\u003d\"\n                 + Bytes.toString(CellUtil.cloneQualifier(cell)) + \" value\u003d\"\n                 + converter.decodeValue(CellUtil.cloneValue(cell))\n                 + \" timestamp\u003d\" + cell.getTimestamp() + \" \" + this.action);\n           }\n         } else {\n           // not a final value but it\u0027s the latest cell for this app\n           // so include this cell in the list of cells to write back\n           finalCells.add(cell);\n         }\n       }\n     }\n     if (summationDone) {\n       Cell anyCell \u003d currentColumnCells.first();\n       List\u003cTag\u003e tags \u003d new ArrayList\u003cTag\u003e();\n-      Tag t \u003d new Tag(AggregationOperation.SUM_FINAL.getTagType(),\n+      Tag t \u003d HBaseTimelineServerUtils.createTag(\n+          AggregationOperation.SUM_FINAL.getTagType(),\n           Bytes.toBytes(FLOW_APP_ID));\n       tags.add(t);\n-      t \u003d new Tag(AggregationCompactionDimension.APPLICATION_ID.getTagType(),\n+      t \u003d HBaseTimelineServerUtils.createTag(\n+          AggregationCompactionDimension.APPLICATION_ID.getTagType(),\n           Bytes.toBytes(FLOW_APP_ID));\n       tags.add(t);\n-      byte[] tagByteArray \u003d Tag.fromList(tags);\n+      byte[] tagByteArray \u003d\n+          HBaseTimelineServerUtils.convertTagListToByteArray(tags);\n       Cell sumCell \u003d HBaseTimelineServerUtils.createNewCell(\n           CellUtil.cloneRow(anyCell),\n           CellUtil.cloneFamily(anyCell),\n           CellUtil.cloneQualifier(anyCell),\n           TimestampGenerator.getSupplementedTimestamp(\n               System.currentTimeMillis(), FLOW_APP_ID),\n               converter.encodeValue(sum), tagByteArray);\n       finalCells.add(sumCell);\n       if (LOG.isTraceEnabled()) {\n         LOG.trace(\"MAJOR COMPACTION final sum\u003d \" + sum + \" for \"\n             + Bytes.toString(CellUtil.cloneQualifier(sumCell))\n             + \" \" + this.action);\n       }\n       LOG.info(\"After major compaction for qualifier\u003d\"\n           + Bytes.toString(CellUtil.cloneQualifier(sumCell))\n           + \" with currentColumnCells.size\u003d\"\n           + currentColumnCells.size()\n           + \" returning finalCells.size\u003d\" + finalCells.size()\n           + \" with sum\u003d\" + sum.longValue()\n           + \" with cell timestamp \" + sumCell.getTimestamp());\n     } else {\n       String qualifier \u003d \"\";\n       LOG.info(\"After major compaction for qualifier\u003d\" + qualifier\n           + \" with currentColumnCells.size\u003d\"\n           + currentColumnCells.size()\n           + \" returning finalCells.size\u003d\" + finalCells.size()\n           + \" with zero sum\u003d\"\n           + sum.longValue());\n     }\n     return finalCells;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  List\u003cCell\u003e processSummationMajorCompaction(\n      SortedSet\u003cCell\u003e currentColumnCells, NumericValueConverter converter,\n      long currentTimestamp)\n      throws IOException {\n    Number sum \u003d 0;\n    Number currentValue \u003d 0;\n    long ts \u003d 0L;\n    boolean summationDone \u003d false;\n    List\u003cCell\u003e finalCells \u003d new ArrayList\u003cCell\u003e();\n    if (currentColumnCells \u003d\u003d null) {\n      return finalCells;\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"In processSummationMajorCompaction,\"\n          + \" will drop cells older than \" + currentTimestamp\n          + \" CurrentColumnCells size\u003d\" + currentColumnCells.size());\n    }\n\n    for (Cell cell : currentColumnCells) {\n      AggregationOperation cellAggOp \u003d getCurrentAggOp(cell);\n      // if this is the existing flow sum cell\n      List\u003cTag\u003e tags \u003d HBaseTimelineServerUtils.convertCellAsTagList(cell);\n      String appId \u003d HBaseTimelineServerUtils\n          .getAggregationCompactionDimension(tags);\n      if (appId \u003d\u003d FLOW_APP_ID) {\n        sum \u003d converter.add(sum, currentValue);\n        summationDone \u003d true;\n        if (LOG.isTraceEnabled()) {\n          LOG.trace(\"reading flow app id sum\u003d\" + sum);\n        }\n      } else {\n        currentValue \u003d (Number) converter.decodeValue(CellUtil\n            .cloneValue(cell));\n        // read the timestamp truncated by the generator\n        ts \u003d  TimestampGenerator.getTruncatedTimestamp(cell.getTimestamp());\n        if ((cellAggOp \u003d\u003d AggregationOperation.SUM_FINAL)\n            \u0026\u0026 ((ts + this.appFinalValueRetentionThreshold)\n                \u003c currentTimestamp)) {\n          sum \u003d converter.add(sum, currentValue);\n          summationDone \u003d true;\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"MAJOR COMPACTION loop sum\u003d \" + sum\n                + \" discarding now: \" + \" qualifier\u003d\"\n                + Bytes.toString(CellUtil.cloneQualifier(cell)) + \" value\u003d\"\n                + converter.decodeValue(CellUtil.cloneValue(cell))\n                + \" timestamp\u003d\" + cell.getTimestamp() + \" \" + this.action);\n          }\n        } else {\n          // not a final value but it\u0027s the latest cell for this app\n          // so include this cell in the list of cells to write back\n          finalCells.add(cell);\n        }\n      }\n    }\n    if (summationDone) {\n      Cell anyCell \u003d currentColumnCells.first();\n      List\u003cTag\u003e tags \u003d new ArrayList\u003cTag\u003e();\n      Tag t \u003d HBaseTimelineServerUtils.createTag(\n          AggregationOperation.SUM_FINAL.getTagType(),\n          Bytes.toBytes(FLOW_APP_ID));\n      tags.add(t);\n      t \u003d HBaseTimelineServerUtils.createTag(\n          AggregationCompactionDimension.APPLICATION_ID.getTagType(),\n          Bytes.toBytes(FLOW_APP_ID));\n      tags.add(t);\n      byte[] tagByteArray \u003d\n          HBaseTimelineServerUtils.convertTagListToByteArray(tags);\n      Cell sumCell \u003d HBaseTimelineServerUtils.createNewCell(\n          CellUtil.cloneRow(anyCell),\n          CellUtil.cloneFamily(anyCell),\n          CellUtil.cloneQualifier(anyCell),\n          TimestampGenerator.getSupplementedTimestamp(\n              System.currentTimeMillis(), FLOW_APP_ID),\n              converter.encodeValue(sum), tagByteArray);\n      finalCells.add(sumCell);\n      if (LOG.isTraceEnabled()) {\n        LOG.trace(\"MAJOR COMPACTION final sum\u003d \" + sum + \" for \"\n            + Bytes.toString(CellUtil.cloneQualifier(sumCell))\n            + \" \" + this.action);\n      }\n      LOG.info(\"After major compaction for qualifier\u003d\"\n          + Bytes.toString(CellUtil.cloneQualifier(sumCell))\n          + \" with currentColumnCells.size\u003d\"\n          + currentColumnCells.size()\n          + \" returning finalCells.size\u003d\" + finalCells.size()\n          + \" with sum\u003d\" + sum.longValue()\n          + \" with cell timestamp \" + sumCell.getTimestamp());\n    } else {\n      String qualifier \u003d \"\";\n      LOG.info(\"After major compaction for qualifier\u003d\" + qualifier\n          + \" with currentColumnCells.size\u003d\"\n          + currentColumnCells.size()\n          + \" returning finalCells.size\u003d\" + finalCells.size()\n          + \" with zero sum\u003d\"\n          + sum.longValue());\n    }\n    return finalCells;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-server/hadoop-yarn-server-timelineservice-hbase-server-1/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/flow/FlowScanner.java",
          "extendedDetails": {
            "oldPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-server/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/flow/FlowScanner.java",
            "newPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-server/hadoop-yarn-server-timelineservice-hbase-server-1/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/flow/FlowScanner.java"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-7346. Add a profile to allow optional compilation for ATSv2 with HBase-2.0. Contributed by Haibo Chen and Rohith.\n",
          "commitDate": "05/03/18 10:25 PM",
          "commitName": "55ba49dd071b66e72c47a1c41e88b9a5feddf53b",
          "commitAuthor": "Rohith Sharma K S",
          "commitDateOld": "05/03/18 6:15 PM",
          "commitNameOld": "745190ecdca8f7dfc5eebffdd1c1aa4f86229120",
          "commitAuthorOld": "Takanobu Asanuma",
          "daysBetweenCommits": 0.17,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,97 +1,99 @@\n   List\u003cCell\u003e processSummationMajorCompaction(\n       SortedSet\u003cCell\u003e currentColumnCells, NumericValueConverter converter,\n       long currentTimestamp)\n       throws IOException {\n     Number sum \u003d 0;\n     Number currentValue \u003d 0;\n     long ts \u003d 0L;\n     boolean summationDone \u003d false;\n     List\u003cCell\u003e finalCells \u003d new ArrayList\u003cCell\u003e();\n     if (currentColumnCells \u003d\u003d null) {\n       return finalCells;\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"In processSummationMajorCompaction,\"\n           + \" will drop cells older than \" + currentTimestamp\n           + \" CurrentColumnCells size\u003d\" + currentColumnCells.size());\n     }\n \n     for (Cell cell : currentColumnCells) {\n       AggregationOperation cellAggOp \u003d getCurrentAggOp(cell);\n       // if this is the existing flow sum cell\n-      List\u003cTag\u003e tags \u003d Tag.asList(cell.getTagsArray(), cell.getTagsOffset(),\n-          cell.getTagsLength());\n+      List\u003cTag\u003e tags \u003d HBaseTimelineServerUtils.convertCellAsTagList(cell);\n       String appId \u003d HBaseTimelineServerUtils\n           .getAggregationCompactionDimension(tags);\n       if (appId \u003d\u003d FLOW_APP_ID) {\n         sum \u003d converter.add(sum, currentValue);\n         summationDone \u003d true;\n         if (LOG.isTraceEnabled()) {\n           LOG.trace(\"reading flow app id sum\u003d\" + sum);\n         }\n       } else {\n         currentValue \u003d (Number) converter.decodeValue(CellUtil\n             .cloneValue(cell));\n         // read the timestamp truncated by the generator\n         ts \u003d  TimestampGenerator.getTruncatedTimestamp(cell.getTimestamp());\n         if ((cellAggOp \u003d\u003d AggregationOperation.SUM_FINAL)\n             \u0026\u0026 ((ts + this.appFinalValueRetentionThreshold)\n                 \u003c currentTimestamp)) {\n           sum \u003d converter.add(sum, currentValue);\n           summationDone \u003d true;\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"MAJOR COMPACTION loop sum\u003d \" + sum\n                 + \" discarding now: \" + \" qualifier\u003d\"\n                 + Bytes.toString(CellUtil.cloneQualifier(cell)) + \" value\u003d\"\n                 + converter.decodeValue(CellUtil.cloneValue(cell))\n                 + \" timestamp\u003d\" + cell.getTimestamp() + \" \" + this.action);\n           }\n         } else {\n           // not a final value but it\u0027s the latest cell for this app\n           // so include this cell in the list of cells to write back\n           finalCells.add(cell);\n         }\n       }\n     }\n     if (summationDone) {\n       Cell anyCell \u003d currentColumnCells.first();\n       List\u003cTag\u003e tags \u003d new ArrayList\u003cTag\u003e();\n-      Tag t \u003d new Tag(AggregationOperation.SUM_FINAL.getTagType(),\n+      Tag t \u003d HBaseTimelineServerUtils.createTag(\n+          AggregationOperation.SUM_FINAL.getTagType(),\n           Bytes.toBytes(FLOW_APP_ID));\n       tags.add(t);\n-      t \u003d new Tag(AggregationCompactionDimension.APPLICATION_ID.getTagType(),\n+      t \u003d HBaseTimelineServerUtils.createTag(\n+          AggregationCompactionDimension.APPLICATION_ID.getTagType(),\n           Bytes.toBytes(FLOW_APP_ID));\n       tags.add(t);\n-      byte[] tagByteArray \u003d Tag.fromList(tags);\n+      byte[] tagByteArray \u003d\n+          HBaseTimelineServerUtils.convertTagListToByteArray(tags);\n       Cell sumCell \u003d HBaseTimelineServerUtils.createNewCell(\n           CellUtil.cloneRow(anyCell),\n           CellUtil.cloneFamily(anyCell),\n           CellUtil.cloneQualifier(anyCell),\n           TimestampGenerator.getSupplementedTimestamp(\n               System.currentTimeMillis(), FLOW_APP_ID),\n               converter.encodeValue(sum), tagByteArray);\n       finalCells.add(sumCell);\n       if (LOG.isTraceEnabled()) {\n         LOG.trace(\"MAJOR COMPACTION final sum\u003d \" + sum + \" for \"\n             + Bytes.toString(CellUtil.cloneQualifier(sumCell))\n             + \" \" + this.action);\n       }\n       LOG.info(\"After major compaction for qualifier\u003d\"\n           + Bytes.toString(CellUtil.cloneQualifier(sumCell))\n           + \" with currentColumnCells.size\u003d\"\n           + currentColumnCells.size()\n           + \" returning finalCells.size\u003d\" + finalCells.size()\n           + \" with sum\u003d\" + sum.longValue()\n           + \" with cell timestamp \" + sumCell.getTimestamp());\n     } else {\n       String qualifier \u003d \"\";\n       LOG.info(\"After major compaction for qualifier\u003d\" + qualifier\n           + \" with currentColumnCells.size\u003d\"\n           + currentColumnCells.size()\n           + \" returning finalCells.size\u003d\" + finalCells.size()\n           + \" with zero sum\u003d\"\n           + sum.longValue());\n     }\n     return finalCells;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  List\u003cCell\u003e processSummationMajorCompaction(\n      SortedSet\u003cCell\u003e currentColumnCells, NumericValueConverter converter,\n      long currentTimestamp)\n      throws IOException {\n    Number sum \u003d 0;\n    Number currentValue \u003d 0;\n    long ts \u003d 0L;\n    boolean summationDone \u003d false;\n    List\u003cCell\u003e finalCells \u003d new ArrayList\u003cCell\u003e();\n    if (currentColumnCells \u003d\u003d null) {\n      return finalCells;\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"In processSummationMajorCompaction,\"\n          + \" will drop cells older than \" + currentTimestamp\n          + \" CurrentColumnCells size\u003d\" + currentColumnCells.size());\n    }\n\n    for (Cell cell : currentColumnCells) {\n      AggregationOperation cellAggOp \u003d getCurrentAggOp(cell);\n      // if this is the existing flow sum cell\n      List\u003cTag\u003e tags \u003d HBaseTimelineServerUtils.convertCellAsTagList(cell);\n      String appId \u003d HBaseTimelineServerUtils\n          .getAggregationCompactionDimension(tags);\n      if (appId \u003d\u003d FLOW_APP_ID) {\n        sum \u003d converter.add(sum, currentValue);\n        summationDone \u003d true;\n        if (LOG.isTraceEnabled()) {\n          LOG.trace(\"reading flow app id sum\u003d\" + sum);\n        }\n      } else {\n        currentValue \u003d (Number) converter.decodeValue(CellUtil\n            .cloneValue(cell));\n        // read the timestamp truncated by the generator\n        ts \u003d  TimestampGenerator.getTruncatedTimestamp(cell.getTimestamp());\n        if ((cellAggOp \u003d\u003d AggregationOperation.SUM_FINAL)\n            \u0026\u0026 ((ts + this.appFinalValueRetentionThreshold)\n                \u003c currentTimestamp)) {\n          sum \u003d converter.add(sum, currentValue);\n          summationDone \u003d true;\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"MAJOR COMPACTION loop sum\u003d \" + sum\n                + \" discarding now: \" + \" qualifier\u003d\"\n                + Bytes.toString(CellUtil.cloneQualifier(cell)) + \" value\u003d\"\n                + converter.decodeValue(CellUtil.cloneValue(cell))\n                + \" timestamp\u003d\" + cell.getTimestamp() + \" \" + this.action);\n          }\n        } else {\n          // not a final value but it\u0027s the latest cell for this app\n          // so include this cell in the list of cells to write back\n          finalCells.add(cell);\n        }\n      }\n    }\n    if (summationDone) {\n      Cell anyCell \u003d currentColumnCells.first();\n      List\u003cTag\u003e tags \u003d new ArrayList\u003cTag\u003e();\n      Tag t \u003d HBaseTimelineServerUtils.createTag(\n          AggregationOperation.SUM_FINAL.getTagType(),\n          Bytes.toBytes(FLOW_APP_ID));\n      tags.add(t);\n      t \u003d HBaseTimelineServerUtils.createTag(\n          AggregationCompactionDimension.APPLICATION_ID.getTagType(),\n          Bytes.toBytes(FLOW_APP_ID));\n      tags.add(t);\n      byte[] tagByteArray \u003d\n          HBaseTimelineServerUtils.convertTagListToByteArray(tags);\n      Cell sumCell \u003d HBaseTimelineServerUtils.createNewCell(\n          CellUtil.cloneRow(anyCell),\n          CellUtil.cloneFamily(anyCell),\n          CellUtil.cloneQualifier(anyCell),\n          TimestampGenerator.getSupplementedTimestamp(\n              System.currentTimeMillis(), FLOW_APP_ID),\n              converter.encodeValue(sum), tagByteArray);\n      finalCells.add(sumCell);\n      if (LOG.isTraceEnabled()) {\n        LOG.trace(\"MAJOR COMPACTION final sum\u003d \" + sum + \" for \"\n            + Bytes.toString(CellUtil.cloneQualifier(sumCell))\n            + \" \" + this.action);\n      }\n      LOG.info(\"After major compaction for qualifier\u003d\"\n          + Bytes.toString(CellUtil.cloneQualifier(sumCell))\n          + \" with currentColumnCells.size\u003d\"\n          + currentColumnCells.size()\n          + \" returning finalCells.size\u003d\" + finalCells.size()\n          + \" with sum\u003d\" + sum.longValue()\n          + \" with cell timestamp \" + sumCell.getTimestamp());\n    } else {\n      String qualifier \u003d \"\";\n      LOG.info(\"After major compaction for qualifier\u003d\" + qualifier\n          + \" with currentColumnCells.size\u003d\"\n          + currentColumnCells.size()\n          + \" returning finalCells.size\u003d\" + finalCells.size()\n          + \" with zero sum\u003d\"\n          + sum.longValue());\n    }\n    return finalCells;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-server/hadoop-yarn-server-timelineservice-hbase-server-1/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/flow/FlowScanner.java",
          "extendedDetails": {}
        }
      ]
    },
    "10663b78c8596693322dc3636f173035195bf607": {
      "type": "Ymultichange(Yfilerename,Ybodychange)",
      "commitMessage": "Revert \"yarn-7346.07.patch\"\n\nThis reverts commit 5e37ca5bb49f945e27f49a413d08baab562dfa9c.\n",
      "commitDate": "28/02/18 9:11 PM",
      "commitName": "10663b78c8596693322dc3636f173035195bf607",
      "commitAuthor": "Haibo Chen",
      "subchanges": [
        {
          "type": "Yfilerename",
          "commitMessage": "Revert \"yarn-7346.07.patch\"\n\nThis reverts commit 5e37ca5bb49f945e27f49a413d08baab562dfa9c.\n",
          "commitDate": "28/02/18 9:11 PM",
          "commitName": "10663b78c8596693322dc3636f173035195bf607",
          "commitAuthor": "Haibo Chen",
          "commitDateOld": "28/02/18 9:10 PM",
          "commitNameOld": "d1274c3b71549cb000868500c293cafd880b3713",
          "commitAuthorOld": "Haibo Chen",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,99 +1,97 @@\n   List\u003cCell\u003e processSummationMajorCompaction(\n       SortedSet\u003cCell\u003e currentColumnCells, NumericValueConverter converter,\n       long currentTimestamp)\n       throws IOException {\n     Number sum \u003d 0;\n     Number currentValue \u003d 0;\n     long ts \u003d 0L;\n     boolean summationDone \u003d false;\n     List\u003cCell\u003e finalCells \u003d new ArrayList\u003cCell\u003e();\n     if (currentColumnCells \u003d\u003d null) {\n       return finalCells;\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"In processSummationMajorCompaction,\"\n           + \" will drop cells older than \" + currentTimestamp\n           + \" CurrentColumnCells size\u003d\" + currentColumnCells.size());\n     }\n \n     for (Cell cell : currentColumnCells) {\n       AggregationOperation cellAggOp \u003d getCurrentAggOp(cell);\n       // if this is the existing flow sum cell\n-      List\u003cTag\u003e tags \u003d HBaseTimelineServerUtils.convertCellAsTagList(cell);\n+      List\u003cTag\u003e tags \u003d Tag.asList(cell.getTagsArray(), cell.getTagsOffset(),\n+          cell.getTagsLength());\n       String appId \u003d HBaseTimelineServerUtils\n           .getAggregationCompactionDimension(tags);\n       if (appId \u003d\u003d FLOW_APP_ID) {\n         sum \u003d converter.add(sum, currentValue);\n         summationDone \u003d true;\n         if (LOG.isTraceEnabled()) {\n           LOG.trace(\"reading flow app id sum\u003d\" + sum);\n         }\n       } else {\n         currentValue \u003d (Number) converter.decodeValue(CellUtil\n             .cloneValue(cell));\n         // read the timestamp truncated by the generator\n         ts \u003d  TimestampGenerator.getTruncatedTimestamp(cell.getTimestamp());\n         if ((cellAggOp \u003d\u003d AggregationOperation.SUM_FINAL)\n             \u0026\u0026 ((ts + this.appFinalValueRetentionThreshold)\n                 \u003c currentTimestamp)) {\n           sum \u003d converter.add(sum, currentValue);\n           summationDone \u003d true;\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"MAJOR COMPACTION loop sum\u003d \" + sum\n                 + \" discarding now: \" + \" qualifier\u003d\"\n                 + Bytes.toString(CellUtil.cloneQualifier(cell)) + \" value\u003d\"\n                 + converter.decodeValue(CellUtil.cloneValue(cell))\n                 + \" timestamp\u003d\" + cell.getTimestamp() + \" \" + this.action);\n           }\n         } else {\n           // not a final value but it\u0027s the latest cell for this app\n           // so include this cell in the list of cells to write back\n           finalCells.add(cell);\n         }\n       }\n     }\n     if (summationDone) {\n       Cell anyCell \u003d currentColumnCells.first();\n       List\u003cTag\u003e tags \u003d new ArrayList\u003cTag\u003e();\n-      Tag t \u003d HBaseTimelineServerUtils.createTag(\n-          AggregationOperation.SUM_FINAL.getTagType(),\n+      Tag t \u003d new Tag(AggregationOperation.SUM_FINAL.getTagType(),\n           Bytes.toBytes(FLOW_APP_ID));\n       tags.add(t);\n-      t \u003d HBaseTimelineServerUtils.createTag(\n-          AggregationCompactionDimension.APPLICATION_ID.getTagType(),\n+      t \u003d new Tag(AggregationCompactionDimension.APPLICATION_ID.getTagType(),\n           Bytes.toBytes(FLOW_APP_ID));\n       tags.add(t);\n-      byte[] tagByteArray \u003d\n-          HBaseTimelineServerUtils.convertTagListToByteArray(tags);\n+      byte[] tagByteArray \u003d Tag.fromList(tags);\n       Cell sumCell \u003d HBaseTimelineServerUtils.createNewCell(\n           CellUtil.cloneRow(anyCell),\n           CellUtil.cloneFamily(anyCell),\n           CellUtil.cloneQualifier(anyCell),\n           TimestampGenerator.getSupplementedTimestamp(\n               System.currentTimeMillis(), FLOW_APP_ID),\n               converter.encodeValue(sum), tagByteArray);\n       finalCells.add(sumCell);\n       if (LOG.isTraceEnabled()) {\n         LOG.trace(\"MAJOR COMPACTION final sum\u003d \" + sum + \" for \"\n             + Bytes.toString(CellUtil.cloneQualifier(sumCell))\n             + \" \" + this.action);\n       }\n       LOG.info(\"After major compaction for qualifier\u003d\"\n           + Bytes.toString(CellUtil.cloneQualifier(sumCell))\n           + \" with currentColumnCells.size\u003d\"\n           + currentColumnCells.size()\n           + \" returning finalCells.size\u003d\" + finalCells.size()\n           + \" with sum\u003d\" + sum.longValue()\n           + \" with cell timestamp \" + sumCell.getTimestamp());\n     } else {\n       String qualifier \u003d \"\";\n       LOG.info(\"After major compaction for qualifier\u003d\" + qualifier\n           + \" with currentColumnCells.size\u003d\"\n           + currentColumnCells.size()\n           + \" returning finalCells.size\u003d\" + finalCells.size()\n           + \" with zero sum\u003d\"\n           + sum.longValue());\n     }\n     return finalCells;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  List\u003cCell\u003e processSummationMajorCompaction(\n      SortedSet\u003cCell\u003e currentColumnCells, NumericValueConverter converter,\n      long currentTimestamp)\n      throws IOException {\n    Number sum \u003d 0;\n    Number currentValue \u003d 0;\n    long ts \u003d 0L;\n    boolean summationDone \u003d false;\n    List\u003cCell\u003e finalCells \u003d new ArrayList\u003cCell\u003e();\n    if (currentColumnCells \u003d\u003d null) {\n      return finalCells;\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"In processSummationMajorCompaction,\"\n          + \" will drop cells older than \" + currentTimestamp\n          + \" CurrentColumnCells size\u003d\" + currentColumnCells.size());\n    }\n\n    for (Cell cell : currentColumnCells) {\n      AggregationOperation cellAggOp \u003d getCurrentAggOp(cell);\n      // if this is the existing flow sum cell\n      List\u003cTag\u003e tags \u003d Tag.asList(cell.getTagsArray(), cell.getTagsOffset(),\n          cell.getTagsLength());\n      String appId \u003d HBaseTimelineServerUtils\n          .getAggregationCompactionDimension(tags);\n      if (appId \u003d\u003d FLOW_APP_ID) {\n        sum \u003d converter.add(sum, currentValue);\n        summationDone \u003d true;\n        if (LOG.isTraceEnabled()) {\n          LOG.trace(\"reading flow app id sum\u003d\" + sum);\n        }\n      } else {\n        currentValue \u003d (Number) converter.decodeValue(CellUtil\n            .cloneValue(cell));\n        // read the timestamp truncated by the generator\n        ts \u003d  TimestampGenerator.getTruncatedTimestamp(cell.getTimestamp());\n        if ((cellAggOp \u003d\u003d AggregationOperation.SUM_FINAL)\n            \u0026\u0026 ((ts + this.appFinalValueRetentionThreshold)\n                \u003c currentTimestamp)) {\n          sum \u003d converter.add(sum, currentValue);\n          summationDone \u003d true;\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"MAJOR COMPACTION loop sum\u003d \" + sum\n                + \" discarding now: \" + \" qualifier\u003d\"\n                + Bytes.toString(CellUtil.cloneQualifier(cell)) + \" value\u003d\"\n                + converter.decodeValue(CellUtil.cloneValue(cell))\n                + \" timestamp\u003d\" + cell.getTimestamp() + \" \" + this.action);\n          }\n        } else {\n          // not a final value but it\u0027s the latest cell for this app\n          // so include this cell in the list of cells to write back\n          finalCells.add(cell);\n        }\n      }\n    }\n    if (summationDone) {\n      Cell anyCell \u003d currentColumnCells.first();\n      List\u003cTag\u003e tags \u003d new ArrayList\u003cTag\u003e();\n      Tag t \u003d new Tag(AggregationOperation.SUM_FINAL.getTagType(),\n          Bytes.toBytes(FLOW_APP_ID));\n      tags.add(t);\n      t \u003d new Tag(AggregationCompactionDimension.APPLICATION_ID.getTagType(),\n          Bytes.toBytes(FLOW_APP_ID));\n      tags.add(t);\n      byte[] tagByteArray \u003d Tag.fromList(tags);\n      Cell sumCell \u003d HBaseTimelineServerUtils.createNewCell(\n          CellUtil.cloneRow(anyCell),\n          CellUtil.cloneFamily(anyCell),\n          CellUtil.cloneQualifier(anyCell),\n          TimestampGenerator.getSupplementedTimestamp(\n              System.currentTimeMillis(), FLOW_APP_ID),\n              converter.encodeValue(sum), tagByteArray);\n      finalCells.add(sumCell);\n      if (LOG.isTraceEnabled()) {\n        LOG.trace(\"MAJOR COMPACTION final sum\u003d \" + sum + \" for \"\n            + Bytes.toString(CellUtil.cloneQualifier(sumCell))\n            + \" \" + this.action);\n      }\n      LOG.info(\"After major compaction for qualifier\u003d\"\n          + Bytes.toString(CellUtil.cloneQualifier(sumCell))\n          + \" with currentColumnCells.size\u003d\"\n          + currentColumnCells.size()\n          + \" returning finalCells.size\u003d\" + finalCells.size()\n          + \" with sum\u003d\" + sum.longValue()\n          + \" with cell timestamp \" + sumCell.getTimestamp());\n    } else {\n      String qualifier \u003d \"\";\n      LOG.info(\"After major compaction for qualifier\u003d\" + qualifier\n          + \" with currentColumnCells.size\u003d\"\n          + currentColumnCells.size()\n          + \" returning finalCells.size\u003d\" + finalCells.size()\n          + \" with zero sum\u003d\"\n          + sum.longValue());\n    }\n    return finalCells;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-server/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/flow/FlowScanner.java",
          "extendedDetails": {
            "oldPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-server/hadoop-yarn-server-timelineservice-hbase-server-1/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/flow/FlowScanner.java",
            "newPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-server/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/flow/FlowScanner.java"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "Revert \"yarn-7346.07.patch\"\n\nThis reverts commit 5e37ca5bb49f945e27f49a413d08baab562dfa9c.\n",
          "commitDate": "28/02/18 9:11 PM",
          "commitName": "10663b78c8596693322dc3636f173035195bf607",
          "commitAuthor": "Haibo Chen",
          "commitDateOld": "28/02/18 9:10 PM",
          "commitNameOld": "d1274c3b71549cb000868500c293cafd880b3713",
          "commitAuthorOld": "Haibo Chen",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,99 +1,97 @@\n   List\u003cCell\u003e processSummationMajorCompaction(\n       SortedSet\u003cCell\u003e currentColumnCells, NumericValueConverter converter,\n       long currentTimestamp)\n       throws IOException {\n     Number sum \u003d 0;\n     Number currentValue \u003d 0;\n     long ts \u003d 0L;\n     boolean summationDone \u003d false;\n     List\u003cCell\u003e finalCells \u003d new ArrayList\u003cCell\u003e();\n     if (currentColumnCells \u003d\u003d null) {\n       return finalCells;\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"In processSummationMajorCompaction,\"\n           + \" will drop cells older than \" + currentTimestamp\n           + \" CurrentColumnCells size\u003d\" + currentColumnCells.size());\n     }\n \n     for (Cell cell : currentColumnCells) {\n       AggregationOperation cellAggOp \u003d getCurrentAggOp(cell);\n       // if this is the existing flow sum cell\n-      List\u003cTag\u003e tags \u003d HBaseTimelineServerUtils.convertCellAsTagList(cell);\n+      List\u003cTag\u003e tags \u003d Tag.asList(cell.getTagsArray(), cell.getTagsOffset(),\n+          cell.getTagsLength());\n       String appId \u003d HBaseTimelineServerUtils\n           .getAggregationCompactionDimension(tags);\n       if (appId \u003d\u003d FLOW_APP_ID) {\n         sum \u003d converter.add(sum, currentValue);\n         summationDone \u003d true;\n         if (LOG.isTraceEnabled()) {\n           LOG.trace(\"reading flow app id sum\u003d\" + sum);\n         }\n       } else {\n         currentValue \u003d (Number) converter.decodeValue(CellUtil\n             .cloneValue(cell));\n         // read the timestamp truncated by the generator\n         ts \u003d  TimestampGenerator.getTruncatedTimestamp(cell.getTimestamp());\n         if ((cellAggOp \u003d\u003d AggregationOperation.SUM_FINAL)\n             \u0026\u0026 ((ts + this.appFinalValueRetentionThreshold)\n                 \u003c currentTimestamp)) {\n           sum \u003d converter.add(sum, currentValue);\n           summationDone \u003d true;\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"MAJOR COMPACTION loop sum\u003d \" + sum\n                 + \" discarding now: \" + \" qualifier\u003d\"\n                 + Bytes.toString(CellUtil.cloneQualifier(cell)) + \" value\u003d\"\n                 + converter.decodeValue(CellUtil.cloneValue(cell))\n                 + \" timestamp\u003d\" + cell.getTimestamp() + \" \" + this.action);\n           }\n         } else {\n           // not a final value but it\u0027s the latest cell for this app\n           // so include this cell in the list of cells to write back\n           finalCells.add(cell);\n         }\n       }\n     }\n     if (summationDone) {\n       Cell anyCell \u003d currentColumnCells.first();\n       List\u003cTag\u003e tags \u003d new ArrayList\u003cTag\u003e();\n-      Tag t \u003d HBaseTimelineServerUtils.createTag(\n-          AggregationOperation.SUM_FINAL.getTagType(),\n+      Tag t \u003d new Tag(AggregationOperation.SUM_FINAL.getTagType(),\n           Bytes.toBytes(FLOW_APP_ID));\n       tags.add(t);\n-      t \u003d HBaseTimelineServerUtils.createTag(\n-          AggregationCompactionDimension.APPLICATION_ID.getTagType(),\n+      t \u003d new Tag(AggregationCompactionDimension.APPLICATION_ID.getTagType(),\n           Bytes.toBytes(FLOW_APP_ID));\n       tags.add(t);\n-      byte[] tagByteArray \u003d\n-          HBaseTimelineServerUtils.convertTagListToByteArray(tags);\n+      byte[] tagByteArray \u003d Tag.fromList(tags);\n       Cell sumCell \u003d HBaseTimelineServerUtils.createNewCell(\n           CellUtil.cloneRow(anyCell),\n           CellUtil.cloneFamily(anyCell),\n           CellUtil.cloneQualifier(anyCell),\n           TimestampGenerator.getSupplementedTimestamp(\n               System.currentTimeMillis(), FLOW_APP_ID),\n               converter.encodeValue(sum), tagByteArray);\n       finalCells.add(sumCell);\n       if (LOG.isTraceEnabled()) {\n         LOG.trace(\"MAJOR COMPACTION final sum\u003d \" + sum + \" for \"\n             + Bytes.toString(CellUtil.cloneQualifier(sumCell))\n             + \" \" + this.action);\n       }\n       LOG.info(\"After major compaction for qualifier\u003d\"\n           + Bytes.toString(CellUtil.cloneQualifier(sumCell))\n           + \" with currentColumnCells.size\u003d\"\n           + currentColumnCells.size()\n           + \" returning finalCells.size\u003d\" + finalCells.size()\n           + \" with sum\u003d\" + sum.longValue()\n           + \" with cell timestamp \" + sumCell.getTimestamp());\n     } else {\n       String qualifier \u003d \"\";\n       LOG.info(\"After major compaction for qualifier\u003d\" + qualifier\n           + \" with currentColumnCells.size\u003d\"\n           + currentColumnCells.size()\n           + \" returning finalCells.size\u003d\" + finalCells.size()\n           + \" with zero sum\u003d\"\n           + sum.longValue());\n     }\n     return finalCells;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  List\u003cCell\u003e processSummationMajorCompaction(\n      SortedSet\u003cCell\u003e currentColumnCells, NumericValueConverter converter,\n      long currentTimestamp)\n      throws IOException {\n    Number sum \u003d 0;\n    Number currentValue \u003d 0;\n    long ts \u003d 0L;\n    boolean summationDone \u003d false;\n    List\u003cCell\u003e finalCells \u003d new ArrayList\u003cCell\u003e();\n    if (currentColumnCells \u003d\u003d null) {\n      return finalCells;\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"In processSummationMajorCompaction,\"\n          + \" will drop cells older than \" + currentTimestamp\n          + \" CurrentColumnCells size\u003d\" + currentColumnCells.size());\n    }\n\n    for (Cell cell : currentColumnCells) {\n      AggregationOperation cellAggOp \u003d getCurrentAggOp(cell);\n      // if this is the existing flow sum cell\n      List\u003cTag\u003e tags \u003d Tag.asList(cell.getTagsArray(), cell.getTagsOffset(),\n          cell.getTagsLength());\n      String appId \u003d HBaseTimelineServerUtils\n          .getAggregationCompactionDimension(tags);\n      if (appId \u003d\u003d FLOW_APP_ID) {\n        sum \u003d converter.add(sum, currentValue);\n        summationDone \u003d true;\n        if (LOG.isTraceEnabled()) {\n          LOG.trace(\"reading flow app id sum\u003d\" + sum);\n        }\n      } else {\n        currentValue \u003d (Number) converter.decodeValue(CellUtil\n            .cloneValue(cell));\n        // read the timestamp truncated by the generator\n        ts \u003d  TimestampGenerator.getTruncatedTimestamp(cell.getTimestamp());\n        if ((cellAggOp \u003d\u003d AggregationOperation.SUM_FINAL)\n            \u0026\u0026 ((ts + this.appFinalValueRetentionThreshold)\n                \u003c currentTimestamp)) {\n          sum \u003d converter.add(sum, currentValue);\n          summationDone \u003d true;\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"MAJOR COMPACTION loop sum\u003d \" + sum\n                + \" discarding now: \" + \" qualifier\u003d\"\n                + Bytes.toString(CellUtil.cloneQualifier(cell)) + \" value\u003d\"\n                + converter.decodeValue(CellUtil.cloneValue(cell))\n                + \" timestamp\u003d\" + cell.getTimestamp() + \" \" + this.action);\n          }\n        } else {\n          // not a final value but it\u0027s the latest cell for this app\n          // so include this cell in the list of cells to write back\n          finalCells.add(cell);\n        }\n      }\n    }\n    if (summationDone) {\n      Cell anyCell \u003d currentColumnCells.first();\n      List\u003cTag\u003e tags \u003d new ArrayList\u003cTag\u003e();\n      Tag t \u003d new Tag(AggregationOperation.SUM_FINAL.getTagType(),\n          Bytes.toBytes(FLOW_APP_ID));\n      tags.add(t);\n      t \u003d new Tag(AggregationCompactionDimension.APPLICATION_ID.getTagType(),\n          Bytes.toBytes(FLOW_APP_ID));\n      tags.add(t);\n      byte[] tagByteArray \u003d Tag.fromList(tags);\n      Cell sumCell \u003d HBaseTimelineServerUtils.createNewCell(\n          CellUtil.cloneRow(anyCell),\n          CellUtil.cloneFamily(anyCell),\n          CellUtil.cloneQualifier(anyCell),\n          TimestampGenerator.getSupplementedTimestamp(\n              System.currentTimeMillis(), FLOW_APP_ID),\n              converter.encodeValue(sum), tagByteArray);\n      finalCells.add(sumCell);\n      if (LOG.isTraceEnabled()) {\n        LOG.trace(\"MAJOR COMPACTION final sum\u003d \" + sum + \" for \"\n            + Bytes.toString(CellUtil.cloneQualifier(sumCell))\n            + \" \" + this.action);\n      }\n      LOG.info(\"After major compaction for qualifier\u003d\"\n          + Bytes.toString(CellUtil.cloneQualifier(sumCell))\n          + \" with currentColumnCells.size\u003d\"\n          + currentColumnCells.size()\n          + \" returning finalCells.size\u003d\" + finalCells.size()\n          + \" with sum\u003d\" + sum.longValue()\n          + \" with cell timestamp \" + sumCell.getTimestamp());\n    } else {\n      String qualifier \u003d \"\";\n      LOG.info(\"After major compaction for qualifier\u003d\" + qualifier\n          + \" with currentColumnCells.size\u003d\"\n          + currentColumnCells.size()\n          + \" returning finalCells.size\u003d\" + finalCells.size()\n          + \" with zero sum\u003d\"\n          + sum.longValue());\n    }\n    return finalCells;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-server/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/flow/FlowScanner.java",
          "extendedDetails": {}
        }
      ]
    },
    "5e37ca5bb49f945e27f49a413d08baab562dfa9c": {
      "type": "Ymultichange(Yfilerename,Ybodychange)",
      "commitMessage": "yarn-7346.07.patch\n",
      "commitDate": "28/02/18 9:04 PM",
      "commitName": "5e37ca5bb49f945e27f49a413d08baab562dfa9c",
      "commitAuthor": "Haibo Chen",
      "subchanges": [
        {
          "type": "Yfilerename",
          "commitMessage": "yarn-7346.07.patch\n",
          "commitDate": "28/02/18 9:04 PM",
          "commitName": "5e37ca5bb49f945e27f49a413d08baab562dfa9c",
          "commitAuthor": "Haibo Chen",
          "commitDateOld": "28/02/18 6:18 PM",
          "commitNameOld": "6e6945cd78d76c6beaec85c963f27e28bf96c0f2",
          "commitAuthorOld": "Weiwei Yang",
          "daysBetweenCommits": 0.12,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,97 +1,99 @@\n   List\u003cCell\u003e processSummationMajorCompaction(\n       SortedSet\u003cCell\u003e currentColumnCells, NumericValueConverter converter,\n       long currentTimestamp)\n       throws IOException {\n     Number sum \u003d 0;\n     Number currentValue \u003d 0;\n     long ts \u003d 0L;\n     boolean summationDone \u003d false;\n     List\u003cCell\u003e finalCells \u003d new ArrayList\u003cCell\u003e();\n     if (currentColumnCells \u003d\u003d null) {\n       return finalCells;\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"In processSummationMajorCompaction,\"\n           + \" will drop cells older than \" + currentTimestamp\n           + \" CurrentColumnCells size\u003d\" + currentColumnCells.size());\n     }\n \n     for (Cell cell : currentColumnCells) {\n       AggregationOperation cellAggOp \u003d getCurrentAggOp(cell);\n       // if this is the existing flow sum cell\n-      List\u003cTag\u003e tags \u003d Tag.asList(cell.getTagsArray(), cell.getTagsOffset(),\n-          cell.getTagsLength());\n+      List\u003cTag\u003e tags \u003d HBaseTimelineServerUtils.convertCellAsTagList(cell);\n       String appId \u003d HBaseTimelineServerUtils\n           .getAggregationCompactionDimension(tags);\n       if (appId \u003d\u003d FLOW_APP_ID) {\n         sum \u003d converter.add(sum, currentValue);\n         summationDone \u003d true;\n         if (LOG.isTraceEnabled()) {\n           LOG.trace(\"reading flow app id sum\u003d\" + sum);\n         }\n       } else {\n         currentValue \u003d (Number) converter.decodeValue(CellUtil\n             .cloneValue(cell));\n         // read the timestamp truncated by the generator\n         ts \u003d  TimestampGenerator.getTruncatedTimestamp(cell.getTimestamp());\n         if ((cellAggOp \u003d\u003d AggregationOperation.SUM_FINAL)\n             \u0026\u0026 ((ts + this.appFinalValueRetentionThreshold)\n                 \u003c currentTimestamp)) {\n           sum \u003d converter.add(sum, currentValue);\n           summationDone \u003d true;\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"MAJOR COMPACTION loop sum\u003d \" + sum\n                 + \" discarding now: \" + \" qualifier\u003d\"\n                 + Bytes.toString(CellUtil.cloneQualifier(cell)) + \" value\u003d\"\n                 + converter.decodeValue(CellUtil.cloneValue(cell))\n                 + \" timestamp\u003d\" + cell.getTimestamp() + \" \" + this.action);\n           }\n         } else {\n           // not a final value but it\u0027s the latest cell for this app\n           // so include this cell in the list of cells to write back\n           finalCells.add(cell);\n         }\n       }\n     }\n     if (summationDone) {\n       Cell anyCell \u003d currentColumnCells.first();\n       List\u003cTag\u003e tags \u003d new ArrayList\u003cTag\u003e();\n-      Tag t \u003d new Tag(AggregationOperation.SUM_FINAL.getTagType(),\n+      Tag t \u003d HBaseTimelineServerUtils.createTag(\n+          AggregationOperation.SUM_FINAL.getTagType(),\n           Bytes.toBytes(FLOW_APP_ID));\n       tags.add(t);\n-      t \u003d new Tag(AggregationCompactionDimension.APPLICATION_ID.getTagType(),\n+      t \u003d HBaseTimelineServerUtils.createTag(\n+          AggregationCompactionDimension.APPLICATION_ID.getTagType(),\n           Bytes.toBytes(FLOW_APP_ID));\n       tags.add(t);\n-      byte[] tagByteArray \u003d Tag.fromList(tags);\n+      byte[] tagByteArray \u003d\n+          HBaseTimelineServerUtils.convertTagListToByteArray(tags);\n       Cell sumCell \u003d HBaseTimelineServerUtils.createNewCell(\n           CellUtil.cloneRow(anyCell),\n           CellUtil.cloneFamily(anyCell),\n           CellUtil.cloneQualifier(anyCell),\n           TimestampGenerator.getSupplementedTimestamp(\n               System.currentTimeMillis(), FLOW_APP_ID),\n               converter.encodeValue(sum), tagByteArray);\n       finalCells.add(sumCell);\n       if (LOG.isTraceEnabled()) {\n         LOG.trace(\"MAJOR COMPACTION final sum\u003d \" + sum + \" for \"\n             + Bytes.toString(CellUtil.cloneQualifier(sumCell))\n             + \" \" + this.action);\n       }\n       LOG.info(\"After major compaction for qualifier\u003d\"\n           + Bytes.toString(CellUtil.cloneQualifier(sumCell))\n           + \" with currentColumnCells.size\u003d\"\n           + currentColumnCells.size()\n           + \" returning finalCells.size\u003d\" + finalCells.size()\n           + \" with sum\u003d\" + sum.longValue()\n           + \" with cell timestamp \" + sumCell.getTimestamp());\n     } else {\n       String qualifier \u003d \"\";\n       LOG.info(\"After major compaction for qualifier\u003d\" + qualifier\n           + \" with currentColumnCells.size\u003d\"\n           + currentColumnCells.size()\n           + \" returning finalCells.size\u003d\" + finalCells.size()\n           + \" with zero sum\u003d\"\n           + sum.longValue());\n     }\n     return finalCells;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  List\u003cCell\u003e processSummationMajorCompaction(\n      SortedSet\u003cCell\u003e currentColumnCells, NumericValueConverter converter,\n      long currentTimestamp)\n      throws IOException {\n    Number sum \u003d 0;\n    Number currentValue \u003d 0;\n    long ts \u003d 0L;\n    boolean summationDone \u003d false;\n    List\u003cCell\u003e finalCells \u003d new ArrayList\u003cCell\u003e();\n    if (currentColumnCells \u003d\u003d null) {\n      return finalCells;\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"In processSummationMajorCompaction,\"\n          + \" will drop cells older than \" + currentTimestamp\n          + \" CurrentColumnCells size\u003d\" + currentColumnCells.size());\n    }\n\n    for (Cell cell : currentColumnCells) {\n      AggregationOperation cellAggOp \u003d getCurrentAggOp(cell);\n      // if this is the existing flow sum cell\n      List\u003cTag\u003e tags \u003d HBaseTimelineServerUtils.convertCellAsTagList(cell);\n      String appId \u003d HBaseTimelineServerUtils\n          .getAggregationCompactionDimension(tags);\n      if (appId \u003d\u003d FLOW_APP_ID) {\n        sum \u003d converter.add(sum, currentValue);\n        summationDone \u003d true;\n        if (LOG.isTraceEnabled()) {\n          LOG.trace(\"reading flow app id sum\u003d\" + sum);\n        }\n      } else {\n        currentValue \u003d (Number) converter.decodeValue(CellUtil\n            .cloneValue(cell));\n        // read the timestamp truncated by the generator\n        ts \u003d  TimestampGenerator.getTruncatedTimestamp(cell.getTimestamp());\n        if ((cellAggOp \u003d\u003d AggregationOperation.SUM_FINAL)\n            \u0026\u0026 ((ts + this.appFinalValueRetentionThreshold)\n                \u003c currentTimestamp)) {\n          sum \u003d converter.add(sum, currentValue);\n          summationDone \u003d true;\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"MAJOR COMPACTION loop sum\u003d \" + sum\n                + \" discarding now: \" + \" qualifier\u003d\"\n                + Bytes.toString(CellUtil.cloneQualifier(cell)) + \" value\u003d\"\n                + converter.decodeValue(CellUtil.cloneValue(cell))\n                + \" timestamp\u003d\" + cell.getTimestamp() + \" \" + this.action);\n          }\n        } else {\n          // not a final value but it\u0027s the latest cell for this app\n          // so include this cell in the list of cells to write back\n          finalCells.add(cell);\n        }\n      }\n    }\n    if (summationDone) {\n      Cell anyCell \u003d currentColumnCells.first();\n      List\u003cTag\u003e tags \u003d new ArrayList\u003cTag\u003e();\n      Tag t \u003d HBaseTimelineServerUtils.createTag(\n          AggregationOperation.SUM_FINAL.getTagType(),\n          Bytes.toBytes(FLOW_APP_ID));\n      tags.add(t);\n      t \u003d HBaseTimelineServerUtils.createTag(\n          AggregationCompactionDimension.APPLICATION_ID.getTagType(),\n          Bytes.toBytes(FLOW_APP_ID));\n      tags.add(t);\n      byte[] tagByteArray \u003d\n          HBaseTimelineServerUtils.convertTagListToByteArray(tags);\n      Cell sumCell \u003d HBaseTimelineServerUtils.createNewCell(\n          CellUtil.cloneRow(anyCell),\n          CellUtil.cloneFamily(anyCell),\n          CellUtil.cloneQualifier(anyCell),\n          TimestampGenerator.getSupplementedTimestamp(\n              System.currentTimeMillis(), FLOW_APP_ID),\n              converter.encodeValue(sum), tagByteArray);\n      finalCells.add(sumCell);\n      if (LOG.isTraceEnabled()) {\n        LOG.trace(\"MAJOR COMPACTION final sum\u003d \" + sum + \" for \"\n            + Bytes.toString(CellUtil.cloneQualifier(sumCell))\n            + \" \" + this.action);\n      }\n      LOG.info(\"After major compaction for qualifier\u003d\"\n          + Bytes.toString(CellUtil.cloneQualifier(sumCell))\n          + \" with currentColumnCells.size\u003d\"\n          + currentColumnCells.size()\n          + \" returning finalCells.size\u003d\" + finalCells.size()\n          + \" with sum\u003d\" + sum.longValue()\n          + \" with cell timestamp \" + sumCell.getTimestamp());\n    } else {\n      String qualifier \u003d \"\";\n      LOG.info(\"After major compaction for qualifier\u003d\" + qualifier\n          + \" with currentColumnCells.size\u003d\"\n          + currentColumnCells.size()\n          + \" returning finalCells.size\u003d\" + finalCells.size()\n          + \" with zero sum\u003d\"\n          + sum.longValue());\n    }\n    return finalCells;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-server/hadoop-yarn-server-timelineservice-hbase-server-1/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/flow/FlowScanner.java",
          "extendedDetails": {
            "oldPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-server/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/flow/FlowScanner.java",
            "newPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-server/hadoop-yarn-server-timelineservice-hbase-server-1/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/flow/FlowScanner.java"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "yarn-7346.07.patch\n",
          "commitDate": "28/02/18 9:04 PM",
          "commitName": "5e37ca5bb49f945e27f49a413d08baab562dfa9c",
          "commitAuthor": "Haibo Chen",
          "commitDateOld": "28/02/18 6:18 PM",
          "commitNameOld": "6e6945cd78d76c6beaec85c963f27e28bf96c0f2",
          "commitAuthorOld": "Weiwei Yang",
          "daysBetweenCommits": 0.12,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,97 +1,99 @@\n   List\u003cCell\u003e processSummationMajorCompaction(\n       SortedSet\u003cCell\u003e currentColumnCells, NumericValueConverter converter,\n       long currentTimestamp)\n       throws IOException {\n     Number sum \u003d 0;\n     Number currentValue \u003d 0;\n     long ts \u003d 0L;\n     boolean summationDone \u003d false;\n     List\u003cCell\u003e finalCells \u003d new ArrayList\u003cCell\u003e();\n     if (currentColumnCells \u003d\u003d null) {\n       return finalCells;\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"In processSummationMajorCompaction,\"\n           + \" will drop cells older than \" + currentTimestamp\n           + \" CurrentColumnCells size\u003d\" + currentColumnCells.size());\n     }\n \n     for (Cell cell : currentColumnCells) {\n       AggregationOperation cellAggOp \u003d getCurrentAggOp(cell);\n       // if this is the existing flow sum cell\n-      List\u003cTag\u003e tags \u003d Tag.asList(cell.getTagsArray(), cell.getTagsOffset(),\n-          cell.getTagsLength());\n+      List\u003cTag\u003e tags \u003d HBaseTimelineServerUtils.convertCellAsTagList(cell);\n       String appId \u003d HBaseTimelineServerUtils\n           .getAggregationCompactionDimension(tags);\n       if (appId \u003d\u003d FLOW_APP_ID) {\n         sum \u003d converter.add(sum, currentValue);\n         summationDone \u003d true;\n         if (LOG.isTraceEnabled()) {\n           LOG.trace(\"reading flow app id sum\u003d\" + sum);\n         }\n       } else {\n         currentValue \u003d (Number) converter.decodeValue(CellUtil\n             .cloneValue(cell));\n         // read the timestamp truncated by the generator\n         ts \u003d  TimestampGenerator.getTruncatedTimestamp(cell.getTimestamp());\n         if ((cellAggOp \u003d\u003d AggregationOperation.SUM_FINAL)\n             \u0026\u0026 ((ts + this.appFinalValueRetentionThreshold)\n                 \u003c currentTimestamp)) {\n           sum \u003d converter.add(sum, currentValue);\n           summationDone \u003d true;\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"MAJOR COMPACTION loop sum\u003d \" + sum\n                 + \" discarding now: \" + \" qualifier\u003d\"\n                 + Bytes.toString(CellUtil.cloneQualifier(cell)) + \" value\u003d\"\n                 + converter.decodeValue(CellUtil.cloneValue(cell))\n                 + \" timestamp\u003d\" + cell.getTimestamp() + \" \" + this.action);\n           }\n         } else {\n           // not a final value but it\u0027s the latest cell for this app\n           // so include this cell in the list of cells to write back\n           finalCells.add(cell);\n         }\n       }\n     }\n     if (summationDone) {\n       Cell anyCell \u003d currentColumnCells.first();\n       List\u003cTag\u003e tags \u003d new ArrayList\u003cTag\u003e();\n-      Tag t \u003d new Tag(AggregationOperation.SUM_FINAL.getTagType(),\n+      Tag t \u003d HBaseTimelineServerUtils.createTag(\n+          AggregationOperation.SUM_FINAL.getTagType(),\n           Bytes.toBytes(FLOW_APP_ID));\n       tags.add(t);\n-      t \u003d new Tag(AggregationCompactionDimension.APPLICATION_ID.getTagType(),\n+      t \u003d HBaseTimelineServerUtils.createTag(\n+          AggregationCompactionDimension.APPLICATION_ID.getTagType(),\n           Bytes.toBytes(FLOW_APP_ID));\n       tags.add(t);\n-      byte[] tagByteArray \u003d Tag.fromList(tags);\n+      byte[] tagByteArray \u003d\n+          HBaseTimelineServerUtils.convertTagListToByteArray(tags);\n       Cell sumCell \u003d HBaseTimelineServerUtils.createNewCell(\n           CellUtil.cloneRow(anyCell),\n           CellUtil.cloneFamily(anyCell),\n           CellUtil.cloneQualifier(anyCell),\n           TimestampGenerator.getSupplementedTimestamp(\n               System.currentTimeMillis(), FLOW_APP_ID),\n               converter.encodeValue(sum), tagByteArray);\n       finalCells.add(sumCell);\n       if (LOG.isTraceEnabled()) {\n         LOG.trace(\"MAJOR COMPACTION final sum\u003d \" + sum + \" for \"\n             + Bytes.toString(CellUtil.cloneQualifier(sumCell))\n             + \" \" + this.action);\n       }\n       LOG.info(\"After major compaction for qualifier\u003d\"\n           + Bytes.toString(CellUtil.cloneQualifier(sumCell))\n           + \" with currentColumnCells.size\u003d\"\n           + currentColumnCells.size()\n           + \" returning finalCells.size\u003d\" + finalCells.size()\n           + \" with sum\u003d\" + sum.longValue()\n           + \" with cell timestamp \" + sumCell.getTimestamp());\n     } else {\n       String qualifier \u003d \"\";\n       LOG.info(\"After major compaction for qualifier\u003d\" + qualifier\n           + \" with currentColumnCells.size\u003d\"\n           + currentColumnCells.size()\n           + \" returning finalCells.size\u003d\" + finalCells.size()\n           + \" with zero sum\u003d\"\n           + sum.longValue());\n     }\n     return finalCells;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  List\u003cCell\u003e processSummationMajorCompaction(\n      SortedSet\u003cCell\u003e currentColumnCells, NumericValueConverter converter,\n      long currentTimestamp)\n      throws IOException {\n    Number sum \u003d 0;\n    Number currentValue \u003d 0;\n    long ts \u003d 0L;\n    boolean summationDone \u003d false;\n    List\u003cCell\u003e finalCells \u003d new ArrayList\u003cCell\u003e();\n    if (currentColumnCells \u003d\u003d null) {\n      return finalCells;\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"In processSummationMajorCompaction,\"\n          + \" will drop cells older than \" + currentTimestamp\n          + \" CurrentColumnCells size\u003d\" + currentColumnCells.size());\n    }\n\n    for (Cell cell : currentColumnCells) {\n      AggregationOperation cellAggOp \u003d getCurrentAggOp(cell);\n      // if this is the existing flow sum cell\n      List\u003cTag\u003e tags \u003d HBaseTimelineServerUtils.convertCellAsTagList(cell);\n      String appId \u003d HBaseTimelineServerUtils\n          .getAggregationCompactionDimension(tags);\n      if (appId \u003d\u003d FLOW_APP_ID) {\n        sum \u003d converter.add(sum, currentValue);\n        summationDone \u003d true;\n        if (LOG.isTraceEnabled()) {\n          LOG.trace(\"reading flow app id sum\u003d\" + sum);\n        }\n      } else {\n        currentValue \u003d (Number) converter.decodeValue(CellUtil\n            .cloneValue(cell));\n        // read the timestamp truncated by the generator\n        ts \u003d  TimestampGenerator.getTruncatedTimestamp(cell.getTimestamp());\n        if ((cellAggOp \u003d\u003d AggregationOperation.SUM_FINAL)\n            \u0026\u0026 ((ts + this.appFinalValueRetentionThreshold)\n                \u003c currentTimestamp)) {\n          sum \u003d converter.add(sum, currentValue);\n          summationDone \u003d true;\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"MAJOR COMPACTION loop sum\u003d \" + sum\n                + \" discarding now: \" + \" qualifier\u003d\"\n                + Bytes.toString(CellUtil.cloneQualifier(cell)) + \" value\u003d\"\n                + converter.decodeValue(CellUtil.cloneValue(cell))\n                + \" timestamp\u003d\" + cell.getTimestamp() + \" \" + this.action);\n          }\n        } else {\n          // not a final value but it\u0027s the latest cell for this app\n          // so include this cell in the list of cells to write back\n          finalCells.add(cell);\n        }\n      }\n    }\n    if (summationDone) {\n      Cell anyCell \u003d currentColumnCells.first();\n      List\u003cTag\u003e tags \u003d new ArrayList\u003cTag\u003e();\n      Tag t \u003d HBaseTimelineServerUtils.createTag(\n          AggregationOperation.SUM_FINAL.getTagType(),\n          Bytes.toBytes(FLOW_APP_ID));\n      tags.add(t);\n      t \u003d HBaseTimelineServerUtils.createTag(\n          AggregationCompactionDimension.APPLICATION_ID.getTagType(),\n          Bytes.toBytes(FLOW_APP_ID));\n      tags.add(t);\n      byte[] tagByteArray \u003d\n          HBaseTimelineServerUtils.convertTagListToByteArray(tags);\n      Cell sumCell \u003d HBaseTimelineServerUtils.createNewCell(\n          CellUtil.cloneRow(anyCell),\n          CellUtil.cloneFamily(anyCell),\n          CellUtil.cloneQualifier(anyCell),\n          TimestampGenerator.getSupplementedTimestamp(\n              System.currentTimeMillis(), FLOW_APP_ID),\n              converter.encodeValue(sum), tagByteArray);\n      finalCells.add(sumCell);\n      if (LOG.isTraceEnabled()) {\n        LOG.trace(\"MAJOR COMPACTION final sum\u003d \" + sum + \" for \"\n            + Bytes.toString(CellUtil.cloneQualifier(sumCell))\n            + \" \" + this.action);\n      }\n      LOG.info(\"After major compaction for qualifier\u003d\"\n          + Bytes.toString(CellUtil.cloneQualifier(sumCell))\n          + \" with currentColumnCells.size\u003d\"\n          + currentColumnCells.size()\n          + \" returning finalCells.size\u003d\" + finalCells.size()\n          + \" with sum\u003d\" + sum.longValue()\n          + \" with cell timestamp \" + sumCell.getTimestamp());\n    } else {\n      String qualifier \u003d \"\";\n      LOG.info(\"After major compaction for qualifier\u003d\" + qualifier\n          + \" with currentColumnCells.size\u003d\"\n          + currentColumnCells.size()\n          + \" returning finalCells.size\u003d\" + finalCells.size()\n          + \" with zero sum\u003d\"\n          + sum.longValue());\n    }\n    return finalCells;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-server/hadoop-yarn-server-timelineservice-hbase-server-1/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/flow/FlowScanner.java",
          "extendedDetails": {}
        }
      ]
    },
    "9af30d46c6e82332a8eda20cb3eb5f987e25e7a2": {
      "type": "Ymultichange(Yfilerename,Ybodychange)",
      "commitMessage": "YARN-7919. Refactor timelineservice-hbase module into submodules. Contributed by Haibo Chen.\n",
      "commitDate": "17/02/18 7:00 AM",
      "commitName": "9af30d46c6e82332a8eda20cb3eb5f987e25e7a2",
      "commitAuthor": "Rohith Sharma K S",
      "subchanges": [
        {
          "type": "Yfilerename",
          "commitMessage": "YARN-7919. Refactor timelineservice-hbase module into submodules. Contributed by Haibo Chen.\n",
          "commitDate": "17/02/18 7:00 AM",
          "commitName": "9af30d46c6e82332a8eda20cb3eb5f987e25e7a2",
          "commitAuthor": "Rohith Sharma K S",
          "commitDateOld": "17/02/18 3:24 AM",
          "commitNameOld": "a1e56a62863d8d494af309ec5f476c4b7e4d5ef9",
          "commitAuthorOld": "Arun Suresh",
          "daysBetweenCommits": 0.15,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,97 +1,97 @@\n   List\u003cCell\u003e processSummationMajorCompaction(\n       SortedSet\u003cCell\u003e currentColumnCells, NumericValueConverter converter,\n       long currentTimestamp)\n       throws IOException {\n     Number sum \u003d 0;\n     Number currentValue \u003d 0;\n     long ts \u003d 0L;\n     boolean summationDone \u003d false;\n     List\u003cCell\u003e finalCells \u003d new ArrayList\u003cCell\u003e();\n     if (currentColumnCells \u003d\u003d null) {\n       return finalCells;\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"In processSummationMajorCompaction,\"\n           + \" will drop cells older than \" + currentTimestamp\n           + \" CurrentColumnCells size\u003d\" + currentColumnCells.size());\n     }\n \n     for (Cell cell : currentColumnCells) {\n       AggregationOperation cellAggOp \u003d getCurrentAggOp(cell);\n       // if this is the existing flow sum cell\n       List\u003cTag\u003e tags \u003d Tag.asList(cell.getTagsArray(), cell.getTagsOffset(),\n           cell.getTagsLength());\n-      String appId \u003d HBaseTimelineStorageUtils\n+      String appId \u003d HBaseTimelineServerUtils\n           .getAggregationCompactionDimension(tags);\n       if (appId \u003d\u003d FLOW_APP_ID) {\n         sum \u003d converter.add(sum, currentValue);\n         summationDone \u003d true;\n         if (LOG.isTraceEnabled()) {\n           LOG.trace(\"reading flow app id sum\u003d\" + sum);\n         }\n       } else {\n         currentValue \u003d (Number) converter.decodeValue(CellUtil\n             .cloneValue(cell));\n         // read the timestamp truncated by the generator\n         ts \u003d  TimestampGenerator.getTruncatedTimestamp(cell.getTimestamp());\n         if ((cellAggOp \u003d\u003d AggregationOperation.SUM_FINAL)\n             \u0026\u0026 ((ts + this.appFinalValueRetentionThreshold)\n                 \u003c currentTimestamp)) {\n           sum \u003d converter.add(sum, currentValue);\n           summationDone \u003d true;\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"MAJOR COMPACTION loop sum\u003d \" + sum\n                 + \" discarding now: \" + \" qualifier\u003d\"\n                 + Bytes.toString(CellUtil.cloneQualifier(cell)) + \" value\u003d\"\n                 + converter.decodeValue(CellUtil.cloneValue(cell))\n                 + \" timestamp\u003d\" + cell.getTimestamp() + \" \" + this.action);\n           }\n         } else {\n           // not a final value but it\u0027s the latest cell for this app\n           // so include this cell in the list of cells to write back\n           finalCells.add(cell);\n         }\n       }\n     }\n     if (summationDone) {\n       Cell anyCell \u003d currentColumnCells.first();\n       List\u003cTag\u003e tags \u003d new ArrayList\u003cTag\u003e();\n       Tag t \u003d new Tag(AggregationOperation.SUM_FINAL.getTagType(),\n           Bytes.toBytes(FLOW_APP_ID));\n       tags.add(t);\n       t \u003d new Tag(AggregationCompactionDimension.APPLICATION_ID.getTagType(),\n           Bytes.toBytes(FLOW_APP_ID));\n       tags.add(t);\n       byte[] tagByteArray \u003d Tag.fromList(tags);\n-      Cell sumCell \u003d HBaseTimelineStorageUtils.createNewCell(\n+      Cell sumCell \u003d HBaseTimelineServerUtils.createNewCell(\n           CellUtil.cloneRow(anyCell),\n           CellUtil.cloneFamily(anyCell),\n           CellUtil.cloneQualifier(anyCell),\n           TimestampGenerator.getSupplementedTimestamp(\n               System.currentTimeMillis(), FLOW_APP_ID),\n               converter.encodeValue(sum), tagByteArray);\n       finalCells.add(sumCell);\n       if (LOG.isTraceEnabled()) {\n         LOG.trace(\"MAJOR COMPACTION final sum\u003d \" + sum + \" for \"\n             + Bytes.toString(CellUtil.cloneQualifier(sumCell))\n             + \" \" + this.action);\n       }\n       LOG.info(\"After major compaction for qualifier\u003d\"\n           + Bytes.toString(CellUtil.cloneQualifier(sumCell))\n           + \" with currentColumnCells.size\u003d\"\n           + currentColumnCells.size()\n           + \" returning finalCells.size\u003d\" + finalCells.size()\n           + \" with sum\u003d\" + sum.longValue()\n           + \" with cell timestamp \" + sumCell.getTimestamp());\n     } else {\n       String qualifier \u003d \"\";\n       LOG.info(\"After major compaction for qualifier\u003d\" + qualifier\n           + \" with currentColumnCells.size\u003d\"\n           + currentColumnCells.size()\n           + \" returning finalCells.size\u003d\" + finalCells.size()\n           + \" with zero sum\u003d\"\n           + sum.longValue());\n     }\n     return finalCells;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  List\u003cCell\u003e processSummationMajorCompaction(\n      SortedSet\u003cCell\u003e currentColumnCells, NumericValueConverter converter,\n      long currentTimestamp)\n      throws IOException {\n    Number sum \u003d 0;\n    Number currentValue \u003d 0;\n    long ts \u003d 0L;\n    boolean summationDone \u003d false;\n    List\u003cCell\u003e finalCells \u003d new ArrayList\u003cCell\u003e();\n    if (currentColumnCells \u003d\u003d null) {\n      return finalCells;\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"In processSummationMajorCompaction,\"\n          + \" will drop cells older than \" + currentTimestamp\n          + \" CurrentColumnCells size\u003d\" + currentColumnCells.size());\n    }\n\n    for (Cell cell : currentColumnCells) {\n      AggregationOperation cellAggOp \u003d getCurrentAggOp(cell);\n      // if this is the existing flow sum cell\n      List\u003cTag\u003e tags \u003d Tag.asList(cell.getTagsArray(), cell.getTagsOffset(),\n          cell.getTagsLength());\n      String appId \u003d HBaseTimelineServerUtils\n          .getAggregationCompactionDimension(tags);\n      if (appId \u003d\u003d FLOW_APP_ID) {\n        sum \u003d converter.add(sum, currentValue);\n        summationDone \u003d true;\n        if (LOG.isTraceEnabled()) {\n          LOG.trace(\"reading flow app id sum\u003d\" + sum);\n        }\n      } else {\n        currentValue \u003d (Number) converter.decodeValue(CellUtil\n            .cloneValue(cell));\n        // read the timestamp truncated by the generator\n        ts \u003d  TimestampGenerator.getTruncatedTimestamp(cell.getTimestamp());\n        if ((cellAggOp \u003d\u003d AggregationOperation.SUM_FINAL)\n            \u0026\u0026 ((ts + this.appFinalValueRetentionThreshold)\n                \u003c currentTimestamp)) {\n          sum \u003d converter.add(sum, currentValue);\n          summationDone \u003d true;\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"MAJOR COMPACTION loop sum\u003d \" + sum\n                + \" discarding now: \" + \" qualifier\u003d\"\n                + Bytes.toString(CellUtil.cloneQualifier(cell)) + \" value\u003d\"\n                + converter.decodeValue(CellUtil.cloneValue(cell))\n                + \" timestamp\u003d\" + cell.getTimestamp() + \" \" + this.action);\n          }\n        } else {\n          // not a final value but it\u0027s the latest cell for this app\n          // so include this cell in the list of cells to write back\n          finalCells.add(cell);\n        }\n      }\n    }\n    if (summationDone) {\n      Cell anyCell \u003d currentColumnCells.first();\n      List\u003cTag\u003e tags \u003d new ArrayList\u003cTag\u003e();\n      Tag t \u003d new Tag(AggregationOperation.SUM_FINAL.getTagType(),\n          Bytes.toBytes(FLOW_APP_ID));\n      tags.add(t);\n      t \u003d new Tag(AggregationCompactionDimension.APPLICATION_ID.getTagType(),\n          Bytes.toBytes(FLOW_APP_ID));\n      tags.add(t);\n      byte[] tagByteArray \u003d Tag.fromList(tags);\n      Cell sumCell \u003d HBaseTimelineServerUtils.createNewCell(\n          CellUtil.cloneRow(anyCell),\n          CellUtil.cloneFamily(anyCell),\n          CellUtil.cloneQualifier(anyCell),\n          TimestampGenerator.getSupplementedTimestamp(\n              System.currentTimeMillis(), FLOW_APP_ID),\n              converter.encodeValue(sum), tagByteArray);\n      finalCells.add(sumCell);\n      if (LOG.isTraceEnabled()) {\n        LOG.trace(\"MAJOR COMPACTION final sum\u003d \" + sum + \" for \"\n            + Bytes.toString(CellUtil.cloneQualifier(sumCell))\n            + \" \" + this.action);\n      }\n      LOG.info(\"After major compaction for qualifier\u003d\"\n          + Bytes.toString(CellUtil.cloneQualifier(sumCell))\n          + \" with currentColumnCells.size\u003d\"\n          + currentColumnCells.size()\n          + \" returning finalCells.size\u003d\" + finalCells.size()\n          + \" with sum\u003d\" + sum.longValue()\n          + \" with cell timestamp \" + sumCell.getTimestamp());\n    } else {\n      String qualifier \u003d \"\";\n      LOG.info(\"After major compaction for qualifier\u003d\" + qualifier\n          + \" with currentColumnCells.size\u003d\"\n          + currentColumnCells.size()\n          + \" returning finalCells.size\u003d\" + finalCells.size()\n          + \" with zero sum\u003d\"\n          + sum.longValue());\n    }\n    return finalCells;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-server/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/flow/FlowScanner.java",
          "extendedDetails": {
            "oldPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/flow/FlowScanner.java",
            "newPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-server/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/flow/FlowScanner.java"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-7919. Refactor timelineservice-hbase module into submodules. Contributed by Haibo Chen.\n",
          "commitDate": "17/02/18 7:00 AM",
          "commitName": "9af30d46c6e82332a8eda20cb3eb5f987e25e7a2",
          "commitAuthor": "Rohith Sharma K S",
          "commitDateOld": "17/02/18 3:24 AM",
          "commitNameOld": "a1e56a62863d8d494af309ec5f476c4b7e4d5ef9",
          "commitAuthorOld": "Arun Suresh",
          "daysBetweenCommits": 0.15,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,97 +1,97 @@\n   List\u003cCell\u003e processSummationMajorCompaction(\n       SortedSet\u003cCell\u003e currentColumnCells, NumericValueConverter converter,\n       long currentTimestamp)\n       throws IOException {\n     Number sum \u003d 0;\n     Number currentValue \u003d 0;\n     long ts \u003d 0L;\n     boolean summationDone \u003d false;\n     List\u003cCell\u003e finalCells \u003d new ArrayList\u003cCell\u003e();\n     if (currentColumnCells \u003d\u003d null) {\n       return finalCells;\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"In processSummationMajorCompaction,\"\n           + \" will drop cells older than \" + currentTimestamp\n           + \" CurrentColumnCells size\u003d\" + currentColumnCells.size());\n     }\n \n     for (Cell cell : currentColumnCells) {\n       AggregationOperation cellAggOp \u003d getCurrentAggOp(cell);\n       // if this is the existing flow sum cell\n       List\u003cTag\u003e tags \u003d Tag.asList(cell.getTagsArray(), cell.getTagsOffset(),\n           cell.getTagsLength());\n-      String appId \u003d HBaseTimelineStorageUtils\n+      String appId \u003d HBaseTimelineServerUtils\n           .getAggregationCompactionDimension(tags);\n       if (appId \u003d\u003d FLOW_APP_ID) {\n         sum \u003d converter.add(sum, currentValue);\n         summationDone \u003d true;\n         if (LOG.isTraceEnabled()) {\n           LOG.trace(\"reading flow app id sum\u003d\" + sum);\n         }\n       } else {\n         currentValue \u003d (Number) converter.decodeValue(CellUtil\n             .cloneValue(cell));\n         // read the timestamp truncated by the generator\n         ts \u003d  TimestampGenerator.getTruncatedTimestamp(cell.getTimestamp());\n         if ((cellAggOp \u003d\u003d AggregationOperation.SUM_FINAL)\n             \u0026\u0026 ((ts + this.appFinalValueRetentionThreshold)\n                 \u003c currentTimestamp)) {\n           sum \u003d converter.add(sum, currentValue);\n           summationDone \u003d true;\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"MAJOR COMPACTION loop sum\u003d \" + sum\n                 + \" discarding now: \" + \" qualifier\u003d\"\n                 + Bytes.toString(CellUtil.cloneQualifier(cell)) + \" value\u003d\"\n                 + converter.decodeValue(CellUtil.cloneValue(cell))\n                 + \" timestamp\u003d\" + cell.getTimestamp() + \" \" + this.action);\n           }\n         } else {\n           // not a final value but it\u0027s the latest cell for this app\n           // so include this cell in the list of cells to write back\n           finalCells.add(cell);\n         }\n       }\n     }\n     if (summationDone) {\n       Cell anyCell \u003d currentColumnCells.first();\n       List\u003cTag\u003e tags \u003d new ArrayList\u003cTag\u003e();\n       Tag t \u003d new Tag(AggregationOperation.SUM_FINAL.getTagType(),\n           Bytes.toBytes(FLOW_APP_ID));\n       tags.add(t);\n       t \u003d new Tag(AggregationCompactionDimension.APPLICATION_ID.getTagType(),\n           Bytes.toBytes(FLOW_APP_ID));\n       tags.add(t);\n       byte[] tagByteArray \u003d Tag.fromList(tags);\n-      Cell sumCell \u003d HBaseTimelineStorageUtils.createNewCell(\n+      Cell sumCell \u003d HBaseTimelineServerUtils.createNewCell(\n           CellUtil.cloneRow(anyCell),\n           CellUtil.cloneFamily(anyCell),\n           CellUtil.cloneQualifier(anyCell),\n           TimestampGenerator.getSupplementedTimestamp(\n               System.currentTimeMillis(), FLOW_APP_ID),\n               converter.encodeValue(sum), tagByteArray);\n       finalCells.add(sumCell);\n       if (LOG.isTraceEnabled()) {\n         LOG.trace(\"MAJOR COMPACTION final sum\u003d \" + sum + \" for \"\n             + Bytes.toString(CellUtil.cloneQualifier(sumCell))\n             + \" \" + this.action);\n       }\n       LOG.info(\"After major compaction for qualifier\u003d\"\n           + Bytes.toString(CellUtil.cloneQualifier(sumCell))\n           + \" with currentColumnCells.size\u003d\"\n           + currentColumnCells.size()\n           + \" returning finalCells.size\u003d\" + finalCells.size()\n           + \" with sum\u003d\" + sum.longValue()\n           + \" with cell timestamp \" + sumCell.getTimestamp());\n     } else {\n       String qualifier \u003d \"\";\n       LOG.info(\"After major compaction for qualifier\u003d\" + qualifier\n           + \" with currentColumnCells.size\u003d\"\n           + currentColumnCells.size()\n           + \" returning finalCells.size\u003d\" + finalCells.size()\n           + \" with zero sum\u003d\"\n           + sum.longValue());\n     }\n     return finalCells;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  List\u003cCell\u003e processSummationMajorCompaction(\n      SortedSet\u003cCell\u003e currentColumnCells, NumericValueConverter converter,\n      long currentTimestamp)\n      throws IOException {\n    Number sum \u003d 0;\n    Number currentValue \u003d 0;\n    long ts \u003d 0L;\n    boolean summationDone \u003d false;\n    List\u003cCell\u003e finalCells \u003d new ArrayList\u003cCell\u003e();\n    if (currentColumnCells \u003d\u003d null) {\n      return finalCells;\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"In processSummationMajorCompaction,\"\n          + \" will drop cells older than \" + currentTimestamp\n          + \" CurrentColumnCells size\u003d\" + currentColumnCells.size());\n    }\n\n    for (Cell cell : currentColumnCells) {\n      AggregationOperation cellAggOp \u003d getCurrentAggOp(cell);\n      // if this is the existing flow sum cell\n      List\u003cTag\u003e tags \u003d Tag.asList(cell.getTagsArray(), cell.getTagsOffset(),\n          cell.getTagsLength());\n      String appId \u003d HBaseTimelineServerUtils\n          .getAggregationCompactionDimension(tags);\n      if (appId \u003d\u003d FLOW_APP_ID) {\n        sum \u003d converter.add(sum, currentValue);\n        summationDone \u003d true;\n        if (LOG.isTraceEnabled()) {\n          LOG.trace(\"reading flow app id sum\u003d\" + sum);\n        }\n      } else {\n        currentValue \u003d (Number) converter.decodeValue(CellUtil\n            .cloneValue(cell));\n        // read the timestamp truncated by the generator\n        ts \u003d  TimestampGenerator.getTruncatedTimestamp(cell.getTimestamp());\n        if ((cellAggOp \u003d\u003d AggregationOperation.SUM_FINAL)\n            \u0026\u0026 ((ts + this.appFinalValueRetentionThreshold)\n                \u003c currentTimestamp)) {\n          sum \u003d converter.add(sum, currentValue);\n          summationDone \u003d true;\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"MAJOR COMPACTION loop sum\u003d \" + sum\n                + \" discarding now: \" + \" qualifier\u003d\"\n                + Bytes.toString(CellUtil.cloneQualifier(cell)) + \" value\u003d\"\n                + converter.decodeValue(CellUtil.cloneValue(cell))\n                + \" timestamp\u003d\" + cell.getTimestamp() + \" \" + this.action);\n          }\n        } else {\n          // not a final value but it\u0027s the latest cell for this app\n          // so include this cell in the list of cells to write back\n          finalCells.add(cell);\n        }\n      }\n    }\n    if (summationDone) {\n      Cell anyCell \u003d currentColumnCells.first();\n      List\u003cTag\u003e tags \u003d new ArrayList\u003cTag\u003e();\n      Tag t \u003d new Tag(AggregationOperation.SUM_FINAL.getTagType(),\n          Bytes.toBytes(FLOW_APP_ID));\n      tags.add(t);\n      t \u003d new Tag(AggregationCompactionDimension.APPLICATION_ID.getTagType(),\n          Bytes.toBytes(FLOW_APP_ID));\n      tags.add(t);\n      byte[] tagByteArray \u003d Tag.fromList(tags);\n      Cell sumCell \u003d HBaseTimelineServerUtils.createNewCell(\n          CellUtil.cloneRow(anyCell),\n          CellUtil.cloneFamily(anyCell),\n          CellUtil.cloneQualifier(anyCell),\n          TimestampGenerator.getSupplementedTimestamp(\n              System.currentTimeMillis(), FLOW_APP_ID),\n              converter.encodeValue(sum), tagByteArray);\n      finalCells.add(sumCell);\n      if (LOG.isTraceEnabled()) {\n        LOG.trace(\"MAJOR COMPACTION final sum\u003d \" + sum + \" for \"\n            + Bytes.toString(CellUtil.cloneQualifier(sumCell))\n            + \" \" + this.action);\n      }\n      LOG.info(\"After major compaction for qualifier\u003d\"\n          + Bytes.toString(CellUtil.cloneQualifier(sumCell))\n          + \" with currentColumnCells.size\u003d\"\n          + currentColumnCells.size()\n          + \" returning finalCells.size\u003d\" + finalCells.size()\n          + \" with sum\u003d\" + sum.longValue()\n          + \" with cell timestamp \" + sumCell.getTimestamp());\n    } else {\n      String qualifier \u003d \"\";\n      LOG.info(\"After major compaction for qualifier\u003d\" + qualifier\n          + \" with currentColumnCells.size\u003d\"\n          + currentColumnCells.size()\n          + \" returning finalCells.size\u003d\" + finalCells.size()\n          + \" with zero sum\u003d\"\n          + sum.longValue());\n    }\n    return finalCells;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-server/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/flow/FlowScanner.java",
          "extendedDetails": {}
        }
      ]
    },
    "b01514f65bc6090a50a583f67d1ecb5d74b6d276": {
      "type": "Yfilerename",
      "commitMessage": "YARN-5928. Move ATSv2 HBase backend code into a new module that is only dependent at runtime by yarn servers. Contributed by Haibo Chen.\n",
      "commitDate": "19/01/17 8:52 PM",
      "commitName": "b01514f65bc6090a50a583f67d1ecb5d74b6d276",
      "commitAuthor": "Sangjin Lee",
      "commitDateOld": "19/01/17 5:32 PM",
      "commitNameOld": "60865c8ea08053f3d6ac23f81c3376a3de3ca996",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 0.14,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  List\u003cCell\u003e processSummationMajorCompaction(\n      SortedSet\u003cCell\u003e currentColumnCells, NumericValueConverter converter,\n      long currentTimestamp)\n      throws IOException {\n    Number sum \u003d 0;\n    Number currentValue \u003d 0;\n    long ts \u003d 0L;\n    boolean summationDone \u003d false;\n    List\u003cCell\u003e finalCells \u003d new ArrayList\u003cCell\u003e();\n    if (currentColumnCells \u003d\u003d null) {\n      return finalCells;\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"In processSummationMajorCompaction,\"\n          + \" will drop cells older than \" + currentTimestamp\n          + \" CurrentColumnCells size\u003d\" + currentColumnCells.size());\n    }\n\n    for (Cell cell : currentColumnCells) {\n      AggregationOperation cellAggOp \u003d getCurrentAggOp(cell);\n      // if this is the existing flow sum cell\n      List\u003cTag\u003e tags \u003d Tag.asList(cell.getTagsArray(), cell.getTagsOffset(),\n          cell.getTagsLength());\n      String appId \u003d HBaseTimelineStorageUtils\n          .getAggregationCompactionDimension(tags);\n      if (appId \u003d\u003d FLOW_APP_ID) {\n        sum \u003d converter.add(sum, currentValue);\n        summationDone \u003d true;\n        if (LOG.isTraceEnabled()) {\n          LOG.trace(\"reading flow app id sum\u003d\" + sum);\n        }\n      } else {\n        currentValue \u003d (Number) converter.decodeValue(CellUtil\n            .cloneValue(cell));\n        // read the timestamp truncated by the generator\n        ts \u003d  TimestampGenerator.getTruncatedTimestamp(cell.getTimestamp());\n        if ((cellAggOp \u003d\u003d AggregationOperation.SUM_FINAL)\n            \u0026\u0026 ((ts + this.appFinalValueRetentionThreshold)\n                \u003c currentTimestamp)) {\n          sum \u003d converter.add(sum, currentValue);\n          summationDone \u003d true;\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"MAJOR COMPACTION loop sum\u003d \" + sum\n                + \" discarding now: \" + \" qualifier\u003d\"\n                + Bytes.toString(CellUtil.cloneQualifier(cell)) + \" value\u003d\"\n                + converter.decodeValue(CellUtil.cloneValue(cell))\n                + \" timestamp\u003d\" + cell.getTimestamp() + \" \" + this.action);\n          }\n        } else {\n          // not a final value but it\u0027s the latest cell for this app\n          // so include this cell in the list of cells to write back\n          finalCells.add(cell);\n        }\n      }\n    }\n    if (summationDone) {\n      Cell anyCell \u003d currentColumnCells.first();\n      List\u003cTag\u003e tags \u003d new ArrayList\u003cTag\u003e();\n      Tag t \u003d new Tag(AggregationOperation.SUM_FINAL.getTagType(),\n          Bytes.toBytes(FLOW_APP_ID));\n      tags.add(t);\n      t \u003d new Tag(AggregationCompactionDimension.APPLICATION_ID.getTagType(),\n          Bytes.toBytes(FLOW_APP_ID));\n      tags.add(t);\n      byte[] tagByteArray \u003d Tag.fromList(tags);\n      Cell sumCell \u003d HBaseTimelineStorageUtils.createNewCell(\n          CellUtil.cloneRow(anyCell),\n          CellUtil.cloneFamily(anyCell),\n          CellUtil.cloneQualifier(anyCell),\n          TimestampGenerator.getSupplementedTimestamp(\n              System.currentTimeMillis(), FLOW_APP_ID),\n              converter.encodeValue(sum), tagByteArray);\n      finalCells.add(sumCell);\n      if (LOG.isTraceEnabled()) {\n        LOG.trace(\"MAJOR COMPACTION final sum\u003d \" + sum + \" for \"\n            + Bytes.toString(CellUtil.cloneQualifier(sumCell))\n            + \" \" + this.action);\n      }\n      LOG.info(\"After major compaction for qualifier\u003d\"\n          + Bytes.toString(CellUtil.cloneQualifier(sumCell))\n          + \" with currentColumnCells.size\u003d\"\n          + currentColumnCells.size()\n          + \" returning finalCells.size\u003d\" + finalCells.size()\n          + \" with sum\u003d\" + sum.longValue()\n          + \" with cell timestamp \" + sumCell.getTimestamp());\n    } else {\n      String qualifier \u003d \"\";\n      LOG.info(\"After major compaction for qualifier\u003d\" + qualifier\n          + \" with currentColumnCells.size\u003d\"\n          + currentColumnCells.size()\n          + \" returning finalCells.size\u003d\" + finalCells.size()\n          + \" with zero sum\u003d\"\n          + sum.longValue());\n    }\n    return finalCells;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/flow/FlowScanner.java",
      "extendedDetails": {
        "oldPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/flow/FlowScanner.java",
        "newPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/flow/FlowScanner.java"
      }
    },
    "55f5886ea24671ff3db87a64aaba2e76b3355455": {
      "type": "Ybodychange",
      "commitMessage": "YARN-5925. Extract hbase-backend-exclusive utility methods from TimelineStorageUtil. Contributed by Haibo Chen.\n",
      "commitDate": "09/12/16 4:17 PM",
      "commitName": "55f5886ea24671ff3db87a64aaba2e76b3355455",
      "commitAuthor": "Sangjin Lee",
      "commitDateOld": "10/07/16 8:46 AM",
      "commitNameOld": "1a227744ac0ceff178171fc4ddbf3d27275bdc4f",
      "commitAuthorOld": "Sangjin Lee",
      "daysBetweenCommits": 152.36,
      "commitsBetweenForRepo": 1107,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,97 +1,97 @@\n   List\u003cCell\u003e processSummationMajorCompaction(\n       SortedSet\u003cCell\u003e currentColumnCells, NumericValueConverter converter,\n       long currentTimestamp)\n       throws IOException {\n     Number sum \u003d 0;\n     Number currentValue \u003d 0;\n     long ts \u003d 0L;\n     boolean summationDone \u003d false;\n     List\u003cCell\u003e finalCells \u003d new ArrayList\u003cCell\u003e();\n     if (currentColumnCells \u003d\u003d null) {\n       return finalCells;\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"In processSummationMajorCompaction,\"\n           + \" will drop cells older than \" + currentTimestamp\n           + \" CurrentColumnCells size\u003d\" + currentColumnCells.size());\n     }\n \n     for (Cell cell : currentColumnCells) {\n       AggregationOperation cellAggOp \u003d getCurrentAggOp(cell);\n       // if this is the existing flow sum cell\n       List\u003cTag\u003e tags \u003d Tag.asList(cell.getTagsArray(), cell.getTagsOffset(),\n           cell.getTagsLength());\n-      String appId \u003d TimelineStorageUtils\n+      String appId \u003d HBaseTimelineStorageUtils\n           .getAggregationCompactionDimension(tags);\n       if (appId \u003d\u003d FLOW_APP_ID) {\n         sum \u003d converter.add(sum, currentValue);\n         summationDone \u003d true;\n         if (LOG.isTraceEnabled()) {\n           LOG.trace(\"reading flow app id sum\u003d\" + sum);\n         }\n       } else {\n         currentValue \u003d (Number) converter.decodeValue(CellUtil\n             .cloneValue(cell));\n         // read the timestamp truncated by the generator\n         ts \u003d  TimestampGenerator.getTruncatedTimestamp(cell.getTimestamp());\n         if ((cellAggOp \u003d\u003d AggregationOperation.SUM_FINAL)\n             \u0026\u0026 ((ts + this.appFinalValueRetentionThreshold)\n                 \u003c currentTimestamp)) {\n           sum \u003d converter.add(sum, currentValue);\n           summationDone \u003d true;\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"MAJOR COMPACTION loop sum\u003d \" + sum\n                 + \" discarding now: \" + \" qualifier\u003d\"\n                 + Bytes.toString(CellUtil.cloneQualifier(cell)) + \" value\u003d\"\n                 + converter.decodeValue(CellUtil.cloneValue(cell))\n                 + \" timestamp\u003d\" + cell.getTimestamp() + \" \" + this.action);\n           }\n         } else {\n           // not a final value but it\u0027s the latest cell for this app\n           // so include this cell in the list of cells to write back\n           finalCells.add(cell);\n         }\n       }\n     }\n     if (summationDone) {\n       Cell anyCell \u003d currentColumnCells.first();\n       List\u003cTag\u003e tags \u003d new ArrayList\u003cTag\u003e();\n       Tag t \u003d new Tag(AggregationOperation.SUM_FINAL.getTagType(),\n           Bytes.toBytes(FLOW_APP_ID));\n       tags.add(t);\n       t \u003d new Tag(AggregationCompactionDimension.APPLICATION_ID.getTagType(),\n           Bytes.toBytes(FLOW_APP_ID));\n       tags.add(t);\n       byte[] tagByteArray \u003d Tag.fromList(tags);\n-      Cell sumCell \u003d TimelineStorageUtils.createNewCell(\n+      Cell sumCell \u003d HBaseTimelineStorageUtils.createNewCell(\n           CellUtil.cloneRow(anyCell),\n           CellUtil.cloneFamily(anyCell),\n           CellUtil.cloneQualifier(anyCell),\n           TimestampGenerator.getSupplementedTimestamp(\n               System.currentTimeMillis(), FLOW_APP_ID),\n               converter.encodeValue(sum), tagByteArray);\n       finalCells.add(sumCell);\n       if (LOG.isTraceEnabled()) {\n         LOG.trace(\"MAJOR COMPACTION final sum\u003d \" + sum + \" for \"\n             + Bytes.toString(CellUtil.cloneQualifier(sumCell))\n             + \" \" + this.action);\n       }\n       LOG.info(\"After major compaction for qualifier\u003d\"\n           + Bytes.toString(CellUtil.cloneQualifier(sumCell))\n           + \" with currentColumnCells.size\u003d\"\n           + currentColumnCells.size()\n           + \" returning finalCells.size\u003d\" + finalCells.size()\n           + \" with sum\u003d\" + sum.longValue()\n           + \" with cell timestamp \" + sumCell.getTimestamp());\n     } else {\n       String qualifier \u003d \"\";\n       LOG.info(\"After major compaction for qualifier\u003d\" + qualifier\n           + \" with currentColumnCells.size\u003d\"\n           + currentColumnCells.size()\n           + \" returning finalCells.size\u003d\" + finalCells.size()\n           + \" with zero sum\u003d\"\n           + sum.longValue());\n     }\n     return finalCells;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  List\u003cCell\u003e processSummationMajorCompaction(\n      SortedSet\u003cCell\u003e currentColumnCells, NumericValueConverter converter,\n      long currentTimestamp)\n      throws IOException {\n    Number sum \u003d 0;\n    Number currentValue \u003d 0;\n    long ts \u003d 0L;\n    boolean summationDone \u003d false;\n    List\u003cCell\u003e finalCells \u003d new ArrayList\u003cCell\u003e();\n    if (currentColumnCells \u003d\u003d null) {\n      return finalCells;\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"In processSummationMajorCompaction,\"\n          + \" will drop cells older than \" + currentTimestamp\n          + \" CurrentColumnCells size\u003d\" + currentColumnCells.size());\n    }\n\n    for (Cell cell : currentColumnCells) {\n      AggregationOperation cellAggOp \u003d getCurrentAggOp(cell);\n      // if this is the existing flow sum cell\n      List\u003cTag\u003e tags \u003d Tag.asList(cell.getTagsArray(), cell.getTagsOffset(),\n          cell.getTagsLength());\n      String appId \u003d HBaseTimelineStorageUtils\n          .getAggregationCompactionDimension(tags);\n      if (appId \u003d\u003d FLOW_APP_ID) {\n        sum \u003d converter.add(sum, currentValue);\n        summationDone \u003d true;\n        if (LOG.isTraceEnabled()) {\n          LOG.trace(\"reading flow app id sum\u003d\" + sum);\n        }\n      } else {\n        currentValue \u003d (Number) converter.decodeValue(CellUtil\n            .cloneValue(cell));\n        // read the timestamp truncated by the generator\n        ts \u003d  TimestampGenerator.getTruncatedTimestamp(cell.getTimestamp());\n        if ((cellAggOp \u003d\u003d AggregationOperation.SUM_FINAL)\n            \u0026\u0026 ((ts + this.appFinalValueRetentionThreshold)\n                \u003c currentTimestamp)) {\n          sum \u003d converter.add(sum, currentValue);\n          summationDone \u003d true;\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"MAJOR COMPACTION loop sum\u003d \" + sum\n                + \" discarding now: \" + \" qualifier\u003d\"\n                + Bytes.toString(CellUtil.cloneQualifier(cell)) + \" value\u003d\"\n                + converter.decodeValue(CellUtil.cloneValue(cell))\n                + \" timestamp\u003d\" + cell.getTimestamp() + \" \" + this.action);\n          }\n        } else {\n          // not a final value but it\u0027s the latest cell for this app\n          // so include this cell in the list of cells to write back\n          finalCells.add(cell);\n        }\n      }\n    }\n    if (summationDone) {\n      Cell anyCell \u003d currentColumnCells.first();\n      List\u003cTag\u003e tags \u003d new ArrayList\u003cTag\u003e();\n      Tag t \u003d new Tag(AggregationOperation.SUM_FINAL.getTagType(),\n          Bytes.toBytes(FLOW_APP_ID));\n      tags.add(t);\n      t \u003d new Tag(AggregationCompactionDimension.APPLICATION_ID.getTagType(),\n          Bytes.toBytes(FLOW_APP_ID));\n      tags.add(t);\n      byte[] tagByteArray \u003d Tag.fromList(tags);\n      Cell sumCell \u003d HBaseTimelineStorageUtils.createNewCell(\n          CellUtil.cloneRow(anyCell),\n          CellUtil.cloneFamily(anyCell),\n          CellUtil.cloneQualifier(anyCell),\n          TimestampGenerator.getSupplementedTimestamp(\n              System.currentTimeMillis(), FLOW_APP_ID),\n              converter.encodeValue(sum), tagByteArray);\n      finalCells.add(sumCell);\n      if (LOG.isTraceEnabled()) {\n        LOG.trace(\"MAJOR COMPACTION final sum\u003d \" + sum + \" for \"\n            + Bytes.toString(CellUtil.cloneQualifier(sumCell))\n            + \" \" + this.action);\n      }\n      LOG.info(\"After major compaction for qualifier\u003d\"\n          + Bytes.toString(CellUtil.cloneQualifier(sumCell))\n          + \" with currentColumnCells.size\u003d\"\n          + currentColumnCells.size()\n          + \" returning finalCells.size\u003d\" + finalCells.size()\n          + \" with sum\u003d\" + sum.longValue()\n          + \" with cell timestamp \" + sumCell.getTimestamp());\n    } else {\n      String qualifier \u003d \"\";\n      LOG.info(\"After major compaction for qualifier\u003d\" + qualifier\n          + \" with currentColumnCells.size\u003d\"\n          + currentColumnCells.size()\n          + \" returning finalCells.size\u003d\" + finalCells.size()\n          + \" with zero sum\u003d\"\n          + sum.longValue());\n    }\n    return finalCells;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/flow/FlowScanner.java",
      "extendedDetails": {}
    },
    "7b8cfa5c2ff62005c8b78867fedd64b48e50383d": {
      "type": "Ybodychange",
      "commitMessage": "YARN-5109. timestamps are stored unencoded causing parse errors (Varun Saxena via sjlee)\n",
      "commitDate": "10/07/16 8:46 AM",
      "commitName": "7b8cfa5c2ff62005c8b78867fedd64b48e50383d",
      "commitAuthor": "Sangjin Lee",
      "commitDateOld": "10/07/16 8:45 AM",
      "commitNameOld": "69dc561b61bf694cfdf0d2059f4f3dcee30e0632",
      "commitAuthorOld": "Sangjin Lee",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 15,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,97 +1,97 @@\n   List\u003cCell\u003e processSummationMajorCompaction(\n       SortedSet\u003cCell\u003e currentColumnCells, NumericValueConverter converter,\n       long currentTimestamp)\n       throws IOException {\n     Number sum \u003d 0;\n     Number currentValue \u003d 0;\n     long ts \u003d 0L;\n     boolean summationDone \u003d false;\n     List\u003cCell\u003e finalCells \u003d new ArrayList\u003cCell\u003e();\n     if (currentColumnCells \u003d\u003d null) {\n       return finalCells;\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"In processSummationMajorCompaction,\"\n           + \" will drop cells older than \" + currentTimestamp\n           + \" CurrentColumnCells size\u003d\" + currentColumnCells.size());\n     }\n \n     for (Cell cell : currentColumnCells) {\n       AggregationOperation cellAggOp \u003d getCurrentAggOp(cell);\n       // if this is the existing flow sum cell\n       List\u003cTag\u003e tags \u003d Tag.asList(cell.getTagsArray(), cell.getTagsOffset(),\n           cell.getTagsLength());\n       String appId \u003d TimelineStorageUtils\n           .getAggregationCompactionDimension(tags);\n       if (appId \u003d\u003d FLOW_APP_ID) {\n         sum \u003d converter.add(sum, currentValue);\n         summationDone \u003d true;\n         if (LOG.isTraceEnabled()) {\n           LOG.trace(\"reading flow app id sum\u003d\" + sum);\n         }\n       } else {\n         currentValue \u003d (Number) converter.decodeValue(CellUtil\n             .cloneValue(cell));\n         // read the timestamp truncated by the generator\n         ts \u003d  TimestampGenerator.getTruncatedTimestamp(cell.getTimestamp());\n         if ((cellAggOp \u003d\u003d AggregationOperation.SUM_FINAL)\n             \u0026\u0026 ((ts + this.appFinalValueRetentionThreshold)\n                 \u003c currentTimestamp)) {\n           sum \u003d converter.add(sum, currentValue);\n           summationDone \u003d true;\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"MAJOR COMPACTION loop sum\u003d \" + sum\n                 + \" discarding now: \" + \" qualifier\u003d\"\n                 + Bytes.toString(CellUtil.cloneQualifier(cell)) + \" value\u003d\"\n-                + (Number) converter.decodeValue(CellUtil.cloneValue(cell))\n+                + converter.decodeValue(CellUtil.cloneValue(cell))\n                 + \" timestamp\u003d\" + cell.getTimestamp() + \" \" + this.action);\n           }\n         } else {\n           // not a final value but it\u0027s the latest cell for this app\n           // so include this cell in the list of cells to write back\n           finalCells.add(cell);\n         }\n       }\n     }\n     if (summationDone) {\n       Cell anyCell \u003d currentColumnCells.first();\n       List\u003cTag\u003e tags \u003d new ArrayList\u003cTag\u003e();\n       Tag t \u003d new Tag(AggregationOperation.SUM_FINAL.getTagType(),\n           Bytes.toBytes(FLOW_APP_ID));\n       tags.add(t);\n       t \u003d new Tag(AggregationCompactionDimension.APPLICATION_ID.getTagType(),\n           Bytes.toBytes(FLOW_APP_ID));\n       tags.add(t);\n       byte[] tagByteArray \u003d Tag.fromList(tags);\n       Cell sumCell \u003d TimelineStorageUtils.createNewCell(\n           CellUtil.cloneRow(anyCell),\n           CellUtil.cloneFamily(anyCell),\n           CellUtil.cloneQualifier(anyCell),\n           TimestampGenerator.getSupplementedTimestamp(\n               System.currentTimeMillis(), FLOW_APP_ID),\n               converter.encodeValue(sum), tagByteArray);\n       finalCells.add(sumCell);\n       if (LOG.isTraceEnabled()) {\n         LOG.trace(\"MAJOR COMPACTION final sum\u003d \" + sum + \" for \"\n             + Bytes.toString(CellUtil.cloneQualifier(sumCell))\n             + \" \" + this.action);\n       }\n       LOG.info(\"After major compaction for qualifier\u003d\"\n           + Bytes.toString(CellUtil.cloneQualifier(sumCell))\n           + \" with currentColumnCells.size\u003d\"\n           + currentColumnCells.size()\n           + \" returning finalCells.size\u003d\" + finalCells.size()\n           + \" with sum\u003d\" + sum.longValue()\n           + \" with cell timestamp \" + sumCell.getTimestamp());\n     } else {\n       String qualifier \u003d \"\";\n       LOG.info(\"After major compaction for qualifier\u003d\" + qualifier\n           + \" with currentColumnCells.size\u003d\"\n           + currentColumnCells.size()\n           + \" returning finalCells.size\u003d\" + finalCells.size()\n           + \" with zero sum\u003d\"\n           + sum.longValue());\n     }\n     return finalCells;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  List\u003cCell\u003e processSummationMajorCompaction(\n      SortedSet\u003cCell\u003e currentColumnCells, NumericValueConverter converter,\n      long currentTimestamp)\n      throws IOException {\n    Number sum \u003d 0;\n    Number currentValue \u003d 0;\n    long ts \u003d 0L;\n    boolean summationDone \u003d false;\n    List\u003cCell\u003e finalCells \u003d new ArrayList\u003cCell\u003e();\n    if (currentColumnCells \u003d\u003d null) {\n      return finalCells;\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"In processSummationMajorCompaction,\"\n          + \" will drop cells older than \" + currentTimestamp\n          + \" CurrentColumnCells size\u003d\" + currentColumnCells.size());\n    }\n\n    for (Cell cell : currentColumnCells) {\n      AggregationOperation cellAggOp \u003d getCurrentAggOp(cell);\n      // if this is the existing flow sum cell\n      List\u003cTag\u003e tags \u003d Tag.asList(cell.getTagsArray(), cell.getTagsOffset(),\n          cell.getTagsLength());\n      String appId \u003d TimelineStorageUtils\n          .getAggregationCompactionDimension(tags);\n      if (appId \u003d\u003d FLOW_APP_ID) {\n        sum \u003d converter.add(sum, currentValue);\n        summationDone \u003d true;\n        if (LOG.isTraceEnabled()) {\n          LOG.trace(\"reading flow app id sum\u003d\" + sum);\n        }\n      } else {\n        currentValue \u003d (Number) converter.decodeValue(CellUtil\n            .cloneValue(cell));\n        // read the timestamp truncated by the generator\n        ts \u003d  TimestampGenerator.getTruncatedTimestamp(cell.getTimestamp());\n        if ((cellAggOp \u003d\u003d AggregationOperation.SUM_FINAL)\n            \u0026\u0026 ((ts + this.appFinalValueRetentionThreshold)\n                \u003c currentTimestamp)) {\n          sum \u003d converter.add(sum, currentValue);\n          summationDone \u003d true;\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"MAJOR COMPACTION loop sum\u003d \" + sum\n                + \" discarding now: \" + \" qualifier\u003d\"\n                + Bytes.toString(CellUtil.cloneQualifier(cell)) + \" value\u003d\"\n                + converter.decodeValue(CellUtil.cloneValue(cell))\n                + \" timestamp\u003d\" + cell.getTimestamp() + \" \" + this.action);\n          }\n        } else {\n          // not a final value but it\u0027s the latest cell for this app\n          // so include this cell in the list of cells to write back\n          finalCells.add(cell);\n        }\n      }\n    }\n    if (summationDone) {\n      Cell anyCell \u003d currentColumnCells.first();\n      List\u003cTag\u003e tags \u003d new ArrayList\u003cTag\u003e();\n      Tag t \u003d new Tag(AggregationOperation.SUM_FINAL.getTagType(),\n          Bytes.toBytes(FLOW_APP_ID));\n      tags.add(t);\n      t \u003d new Tag(AggregationCompactionDimension.APPLICATION_ID.getTagType(),\n          Bytes.toBytes(FLOW_APP_ID));\n      tags.add(t);\n      byte[] tagByteArray \u003d Tag.fromList(tags);\n      Cell sumCell \u003d TimelineStorageUtils.createNewCell(\n          CellUtil.cloneRow(anyCell),\n          CellUtil.cloneFamily(anyCell),\n          CellUtil.cloneQualifier(anyCell),\n          TimestampGenerator.getSupplementedTimestamp(\n              System.currentTimeMillis(), FLOW_APP_ID),\n              converter.encodeValue(sum), tagByteArray);\n      finalCells.add(sumCell);\n      if (LOG.isTraceEnabled()) {\n        LOG.trace(\"MAJOR COMPACTION final sum\u003d \" + sum + \" for \"\n            + Bytes.toString(CellUtil.cloneQualifier(sumCell))\n            + \" \" + this.action);\n      }\n      LOG.info(\"After major compaction for qualifier\u003d\"\n          + Bytes.toString(CellUtil.cloneQualifier(sumCell))\n          + \" with currentColumnCells.size\u003d\"\n          + currentColumnCells.size()\n          + \" returning finalCells.size\u003d\" + finalCells.size()\n          + \" with sum\u003d\" + sum.longValue()\n          + \" with cell timestamp \" + sumCell.getTimestamp());\n    } else {\n      String qualifier \u003d \"\";\n      LOG.info(\"After major compaction for qualifier\u003d\" + qualifier\n          + \" with currentColumnCells.size\u003d\"\n          + currentColumnCells.size()\n          + \" returning finalCells.size\u003d\" + finalCells.size()\n          + \" with zero sum\u003d\"\n          + sum.longValue());\n    }\n    return finalCells;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/flow/FlowScanner.java",
      "extendedDetails": {}
    },
    "9bdd455dced15c84430ea0a0a59410df924f02a7": {
      "type": "Yintroduced",
      "commitMessage": "YARN-4062. Add the flush and compaction functionality via coprocessors and scanners for flow run table (Vrushali C via sjlee)\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "9bdd455dced15c84430ea0a0a59410df924f02a7",
      "commitAuthor": "Sangjin Lee",
      "diff": "@@ -0,0 +1,97 @@\n+  List\u003cCell\u003e processSummationMajorCompaction(\n+      SortedSet\u003cCell\u003e currentColumnCells, NumericValueConverter converter,\n+      long currentTimestamp)\n+      throws IOException {\n+    Number sum \u003d 0;\n+    Number currentValue \u003d 0;\n+    long ts \u003d 0L;\n+    boolean summationDone \u003d false;\n+    List\u003cCell\u003e finalCells \u003d new ArrayList\u003cCell\u003e();\n+    if (currentColumnCells \u003d\u003d null) {\n+      return finalCells;\n+    }\n+\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"In processSummationMajorCompaction,\"\n+          + \" will drop cells older than \" + currentTimestamp\n+          + \" CurrentColumnCells size\u003d\" + currentColumnCells.size());\n+    }\n+\n+    for (Cell cell : currentColumnCells) {\n+      AggregationOperation cellAggOp \u003d getCurrentAggOp(cell);\n+      // if this is the existing flow sum cell\n+      List\u003cTag\u003e tags \u003d Tag.asList(cell.getTagsArray(), cell.getTagsOffset(),\n+          cell.getTagsLength());\n+      String appId \u003d TimelineStorageUtils\n+          .getAggregationCompactionDimension(tags);\n+      if (appId \u003d\u003d FLOW_APP_ID) {\n+        sum \u003d converter.add(sum, currentValue);\n+        summationDone \u003d true;\n+        if (LOG.isTraceEnabled()) {\n+          LOG.trace(\"reading flow app id sum\u003d\" + sum);\n+        }\n+      } else {\n+        currentValue \u003d (Number) converter.decodeValue(CellUtil\n+            .cloneValue(cell));\n+        // read the timestamp truncated by the generator\n+        ts \u003d  TimestampGenerator.getTruncatedTimestamp(cell.getTimestamp());\n+        if ((cellAggOp \u003d\u003d AggregationOperation.SUM_FINAL)\n+            \u0026\u0026 ((ts + this.appFinalValueRetentionThreshold)\n+                \u003c currentTimestamp)) {\n+          sum \u003d converter.add(sum, currentValue);\n+          summationDone \u003d true;\n+          if (LOG.isTraceEnabled()) {\n+            LOG.trace(\"MAJOR COMPACTION loop sum\u003d \" + sum\n+                + \" discarding now: \" + \" qualifier\u003d\"\n+                + Bytes.toString(CellUtil.cloneQualifier(cell)) + \" value\u003d\"\n+                + (Number) converter.decodeValue(CellUtil.cloneValue(cell))\n+                + \" timestamp\u003d\" + cell.getTimestamp() + \" \" + this.action);\n+          }\n+        } else {\n+          // not a final value but it\u0027s the latest cell for this app\n+          // so include this cell in the list of cells to write back\n+          finalCells.add(cell);\n+        }\n+      }\n+    }\n+    if (summationDone) {\n+      Cell anyCell \u003d currentColumnCells.first();\n+      List\u003cTag\u003e tags \u003d new ArrayList\u003cTag\u003e();\n+      Tag t \u003d new Tag(AggregationOperation.SUM_FINAL.getTagType(),\n+          Bytes.toBytes(FLOW_APP_ID));\n+      tags.add(t);\n+      t \u003d new Tag(AggregationCompactionDimension.APPLICATION_ID.getTagType(),\n+          Bytes.toBytes(FLOW_APP_ID));\n+      tags.add(t);\n+      byte[] tagByteArray \u003d Tag.fromList(tags);\n+      Cell sumCell \u003d TimelineStorageUtils.createNewCell(\n+          CellUtil.cloneRow(anyCell),\n+          CellUtil.cloneFamily(anyCell),\n+          CellUtil.cloneQualifier(anyCell),\n+          TimestampGenerator.getSupplementedTimestamp(\n+              System.currentTimeMillis(), FLOW_APP_ID),\n+              converter.encodeValue(sum), tagByteArray);\n+      finalCells.add(sumCell);\n+      if (LOG.isTraceEnabled()) {\n+        LOG.trace(\"MAJOR COMPACTION final sum\u003d \" + sum + \" for \"\n+            + Bytes.toString(CellUtil.cloneQualifier(sumCell))\n+            + \" \" + this.action);\n+      }\n+      LOG.info(\"After major compaction for qualifier\u003d\"\n+          + Bytes.toString(CellUtil.cloneQualifier(sumCell))\n+          + \" with currentColumnCells.size\u003d\"\n+          + currentColumnCells.size()\n+          + \" returning finalCells.size\u003d\" + finalCells.size()\n+          + \" with sum\u003d\" + sum.longValue()\n+          + \" with cell timestamp \" + sumCell.getTimestamp());\n+    } else {\n+      String qualifier \u003d \"\";\n+      LOG.info(\"After major compaction for qualifier\u003d\" + qualifier\n+          + \" with currentColumnCells.size\u003d\"\n+          + currentColumnCells.size()\n+          + \" returning finalCells.size\u003d\" + finalCells.size()\n+          + \" with zero sum\u003d\"\n+          + sum.longValue());\n+    }\n+    return finalCells;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  List\u003cCell\u003e processSummationMajorCompaction(\n      SortedSet\u003cCell\u003e currentColumnCells, NumericValueConverter converter,\n      long currentTimestamp)\n      throws IOException {\n    Number sum \u003d 0;\n    Number currentValue \u003d 0;\n    long ts \u003d 0L;\n    boolean summationDone \u003d false;\n    List\u003cCell\u003e finalCells \u003d new ArrayList\u003cCell\u003e();\n    if (currentColumnCells \u003d\u003d null) {\n      return finalCells;\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"In processSummationMajorCompaction,\"\n          + \" will drop cells older than \" + currentTimestamp\n          + \" CurrentColumnCells size\u003d\" + currentColumnCells.size());\n    }\n\n    for (Cell cell : currentColumnCells) {\n      AggregationOperation cellAggOp \u003d getCurrentAggOp(cell);\n      // if this is the existing flow sum cell\n      List\u003cTag\u003e tags \u003d Tag.asList(cell.getTagsArray(), cell.getTagsOffset(),\n          cell.getTagsLength());\n      String appId \u003d TimelineStorageUtils\n          .getAggregationCompactionDimension(tags);\n      if (appId \u003d\u003d FLOW_APP_ID) {\n        sum \u003d converter.add(sum, currentValue);\n        summationDone \u003d true;\n        if (LOG.isTraceEnabled()) {\n          LOG.trace(\"reading flow app id sum\u003d\" + sum);\n        }\n      } else {\n        currentValue \u003d (Number) converter.decodeValue(CellUtil\n            .cloneValue(cell));\n        // read the timestamp truncated by the generator\n        ts \u003d  TimestampGenerator.getTruncatedTimestamp(cell.getTimestamp());\n        if ((cellAggOp \u003d\u003d AggregationOperation.SUM_FINAL)\n            \u0026\u0026 ((ts + this.appFinalValueRetentionThreshold)\n                \u003c currentTimestamp)) {\n          sum \u003d converter.add(sum, currentValue);\n          summationDone \u003d true;\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"MAJOR COMPACTION loop sum\u003d \" + sum\n                + \" discarding now: \" + \" qualifier\u003d\"\n                + Bytes.toString(CellUtil.cloneQualifier(cell)) + \" value\u003d\"\n                + (Number) converter.decodeValue(CellUtil.cloneValue(cell))\n                + \" timestamp\u003d\" + cell.getTimestamp() + \" \" + this.action);\n          }\n        } else {\n          // not a final value but it\u0027s the latest cell for this app\n          // so include this cell in the list of cells to write back\n          finalCells.add(cell);\n        }\n      }\n    }\n    if (summationDone) {\n      Cell anyCell \u003d currentColumnCells.first();\n      List\u003cTag\u003e tags \u003d new ArrayList\u003cTag\u003e();\n      Tag t \u003d new Tag(AggregationOperation.SUM_FINAL.getTagType(),\n          Bytes.toBytes(FLOW_APP_ID));\n      tags.add(t);\n      t \u003d new Tag(AggregationCompactionDimension.APPLICATION_ID.getTagType(),\n          Bytes.toBytes(FLOW_APP_ID));\n      tags.add(t);\n      byte[] tagByteArray \u003d Tag.fromList(tags);\n      Cell sumCell \u003d TimelineStorageUtils.createNewCell(\n          CellUtil.cloneRow(anyCell),\n          CellUtil.cloneFamily(anyCell),\n          CellUtil.cloneQualifier(anyCell),\n          TimestampGenerator.getSupplementedTimestamp(\n              System.currentTimeMillis(), FLOW_APP_ID),\n              converter.encodeValue(sum), tagByteArray);\n      finalCells.add(sumCell);\n      if (LOG.isTraceEnabled()) {\n        LOG.trace(\"MAJOR COMPACTION final sum\u003d \" + sum + \" for \"\n            + Bytes.toString(CellUtil.cloneQualifier(sumCell))\n            + \" \" + this.action);\n      }\n      LOG.info(\"After major compaction for qualifier\u003d\"\n          + Bytes.toString(CellUtil.cloneQualifier(sumCell))\n          + \" with currentColumnCells.size\u003d\"\n          + currentColumnCells.size()\n          + \" returning finalCells.size\u003d\" + finalCells.size()\n          + \" with sum\u003d\" + sum.longValue()\n          + \" with cell timestamp \" + sumCell.getTimestamp());\n    } else {\n      String qualifier \u003d \"\";\n      LOG.info(\"After major compaction for qualifier\u003d\" + qualifier\n          + \" with currentColumnCells.size\u003d\"\n          + currentColumnCells.size()\n          + \" returning finalCells.size\u003d\" + finalCells.size()\n          + \" with zero sum\u003d\"\n          + sum.longValue());\n    }\n    return finalCells;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/flow/FlowScanner.java"
    }
  }
}