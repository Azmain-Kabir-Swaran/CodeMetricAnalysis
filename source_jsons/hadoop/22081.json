{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "Shuffle.java",
  "functionName": "run",
  "functionId": "run",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/Shuffle.java",
  "functionStartLine": 97,
  "functionEndLine": 174,
  "numCommitsSeen": 15,
  "timeTaken": 4690,
  "changeHistory": [
    "0cb2fdc3b4fbbaa6153b6421a63082dc006f8eb4",
    "7d7553c4eb7d9a282410a3213d26a89fea9b7865",
    "905b17876c44634545a68300ff2f2d73fb86d3b7",
    "895029b2f2535f1ba8275be29fda16d0f80be790",
    "078ae89a4793eb6a153a88b106d330fd059a4933",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "0cb2fdc3b4fbbaa6153b6421a63082dc006f8eb4": "Ybodychange",
    "7d7553c4eb7d9a282410a3213d26a89fea9b7865": "Ybodychange",
    "905b17876c44634545a68300ff2f2d73fb86d3b7": "Ybodychange",
    "895029b2f2535f1ba8275be29fda16d0f80be790": "Ybodychange",
    "078ae89a4793eb6a153a88b106d330fd059a4933": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "0cb2fdc3b4fbbaa6153b6421a63082dc006f8eb4": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-434. LocalJobRunner limited to single reducer (Sandy Ryza and Aaron Kimball via Sandy Ryza)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1510866 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "05/08/13 11:36 PM",
      "commitName": "0cb2fdc3b4fbbaa6153b6421a63082dc006f8eb4",
      "commitAuthor": "Sanford Ryza",
      "commitDateOld": "15/06/13 8:07 PM",
      "commitNameOld": "1a389305b27ac1efec4d7923b87de3e703bf70e1",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 51.15,
      "commitsBetweenForRepo": 309,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,69 +1,78 @@\n   public RawKeyValueIterator run() throws IOException, InterruptedException {\n     // Scale the maximum events we fetch per RPC call to mitigate OOM issues\n     // on the ApplicationMaster when a thundering herd of reducers fetch events\n     // TODO: This should not be necessary after HADOOP-8942\n     int eventsPerReducer \u003d Math.max(MIN_EVENTS_TO_FETCH,\n         MAX_RPC_OUTSTANDING_EVENTS / jobConf.getNumReduceTasks());\n     int maxEventsToFetch \u003d Math.min(MAX_EVENTS_TO_FETCH, eventsPerReducer);\n \n     // Start the map-completion events fetcher thread\n     final EventFetcher\u003cK,V\u003e eventFetcher \u003d \n       new EventFetcher\u003cK,V\u003e(reduceId, umbilical, scheduler, this,\n           maxEventsToFetch);\n     eventFetcher.start();\n     \n     // Start the map-output fetcher threads\n-    final int numFetchers \u003d jobConf.getInt(MRJobConfig.SHUFFLE_PARALLEL_COPIES, 5);\n+    boolean isLocal \u003d localMapFiles !\u003d null;\n+    final int numFetchers \u003d isLocal ? 1 :\n+      jobConf.getInt(MRJobConfig.SHUFFLE_PARALLEL_COPIES, 5);\n     Fetcher\u003cK,V\u003e[] fetchers \u003d new Fetcher[numFetchers];\n-    for (int i\u003d0; i \u003c numFetchers; ++i) {\n-      fetchers[i] \u003d new Fetcher\u003cK,V\u003e(jobConf, reduceId, scheduler, merger, \n-                                     reporter, metrics, this, \n-                                     reduceTask.getShuffleSecret());\n-      fetchers[i].start();\n+    if (isLocal) {\n+      fetchers[0] \u003d new LocalFetcher\u003cK, V\u003e(jobConf, reduceId, scheduler,\n+          merger, reporter, metrics, this, reduceTask.getShuffleSecret(),\n+          localMapFiles);\n+      fetchers[0].start();\n+    } else {\n+      for (int i\u003d0; i \u003c numFetchers; ++i) {\n+        fetchers[i] \u003d new Fetcher\u003cK,V\u003e(jobConf, reduceId, scheduler, merger, \n+                                       reporter, metrics, this, \n+                                       reduceTask.getShuffleSecret());\n+        fetchers[i].start();\n+      }\n     }\n     \n     // Wait for shuffle to complete successfully\n     while (!scheduler.waitUntilDone(PROGRESS_FREQUENCY)) {\n       reporter.progress();\n       \n       synchronized (this) {\n         if (throwable !\u003d null) {\n           throw new ShuffleError(\"error in shuffle in \" + throwingThreadName,\n                                  throwable);\n         }\n       }\n     }\n \n     // Stop the event-fetcher thread\n     eventFetcher.shutDown();\n     \n     // Stop the map-output fetcher threads\n     for (Fetcher\u003cK,V\u003e fetcher : fetchers) {\n       fetcher.shutDown();\n     }\n     \n     // stop the scheduler\n     scheduler.close();\n \n     copyPhase.complete(); // copy is already complete\n     taskStatus.setPhase(TaskStatus.Phase.SORT);\n     reduceTask.statusUpdate(umbilical);\n \n     // Finish the on-going merges...\n     RawKeyValueIterator kvIter \u003d null;\n     try {\n       kvIter \u003d merger.close();\n     } catch (Throwable e) {\n       throw new ShuffleError(\"Error while doing final merge \" , e);\n     }\n \n     // Sanity check\n     synchronized (this) {\n       if (throwable !\u003d null) {\n         throw new ShuffleError(\"error in shuffle in \" + throwingThreadName,\n                                throwable);\n       }\n     }\n     \n     return kvIter;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public RawKeyValueIterator run() throws IOException, InterruptedException {\n    // Scale the maximum events we fetch per RPC call to mitigate OOM issues\n    // on the ApplicationMaster when a thundering herd of reducers fetch events\n    // TODO: This should not be necessary after HADOOP-8942\n    int eventsPerReducer \u003d Math.max(MIN_EVENTS_TO_FETCH,\n        MAX_RPC_OUTSTANDING_EVENTS / jobConf.getNumReduceTasks());\n    int maxEventsToFetch \u003d Math.min(MAX_EVENTS_TO_FETCH, eventsPerReducer);\n\n    // Start the map-completion events fetcher thread\n    final EventFetcher\u003cK,V\u003e eventFetcher \u003d \n      new EventFetcher\u003cK,V\u003e(reduceId, umbilical, scheduler, this,\n          maxEventsToFetch);\n    eventFetcher.start();\n    \n    // Start the map-output fetcher threads\n    boolean isLocal \u003d localMapFiles !\u003d null;\n    final int numFetchers \u003d isLocal ? 1 :\n      jobConf.getInt(MRJobConfig.SHUFFLE_PARALLEL_COPIES, 5);\n    Fetcher\u003cK,V\u003e[] fetchers \u003d new Fetcher[numFetchers];\n    if (isLocal) {\n      fetchers[0] \u003d new LocalFetcher\u003cK, V\u003e(jobConf, reduceId, scheduler,\n          merger, reporter, metrics, this, reduceTask.getShuffleSecret(),\n          localMapFiles);\n      fetchers[0].start();\n    } else {\n      for (int i\u003d0; i \u003c numFetchers; ++i) {\n        fetchers[i] \u003d new Fetcher\u003cK,V\u003e(jobConf, reduceId, scheduler, merger, \n                                       reporter, metrics, this, \n                                       reduceTask.getShuffleSecret());\n        fetchers[i].start();\n      }\n    }\n    \n    // Wait for shuffle to complete successfully\n    while (!scheduler.waitUntilDone(PROGRESS_FREQUENCY)) {\n      reporter.progress();\n      \n      synchronized (this) {\n        if (throwable !\u003d null) {\n          throw new ShuffleError(\"error in shuffle in \" + throwingThreadName,\n                                 throwable);\n        }\n      }\n    }\n\n    // Stop the event-fetcher thread\n    eventFetcher.shutDown();\n    \n    // Stop the map-output fetcher threads\n    for (Fetcher\u003cK,V\u003e fetcher : fetchers) {\n      fetcher.shutDown();\n    }\n    \n    // stop the scheduler\n    scheduler.close();\n\n    copyPhase.complete(); // copy is already complete\n    taskStatus.setPhase(TaskStatus.Phase.SORT);\n    reduceTask.statusUpdate(umbilical);\n\n    // Finish the on-going merges...\n    RawKeyValueIterator kvIter \u003d null;\n    try {\n      kvIter \u003d merger.close();\n    } catch (Throwable e) {\n      throw new ShuffleError(\"Error while doing final merge \" , e);\n    }\n\n    // Sanity check\n    synchronized (this) {\n      if (throwable !\u003d null) {\n        throw new ShuffleError(\"error in shuffle in \" + throwingThreadName,\n                               throwable);\n      }\n    }\n    \n    return kvIter;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/Shuffle.java",
      "extendedDetails": {}
    },
    "7d7553c4eb7d9a282410a3213d26a89fea9b7865": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5042. Reducer unable to fetch for a map task that was recovered (Jason Lowe via bobby)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1457119 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "15/03/13 2:09 PM",
      "commitName": "7d7553c4eb7d9a282410a3213d26a89fea9b7865",
      "commitAuthor": "Robert Joseph Evans",
      "commitDateOld": "22/01/13 6:10 AM",
      "commitNameOld": "73fd247c7649919350ecfd16806af57ffe554649",
      "commitAuthorOld": "Alejandro Abdelnur",
      "daysBetweenCommits": 52.29,
      "commitsBetweenForRepo": 234,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,69 +1,69 @@\n   public RawKeyValueIterator run() throws IOException, InterruptedException {\n     // Scale the maximum events we fetch per RPC call to mitigate OOM issues\n     // on the ApplicationMaster when a thundering herd of reducers fetch events\n     // TODO: This should not be necessary after HADOOP-8942\n     int eventsPerReducer \u003d Math.max(MIN_EVENTS_TO_FETCH,\n         MAX_RPC_OUTSTANDING_EVENTS / jobConf.getNumReduceTasks());\n     int maxEventsToFetch \u003d Math.min(MAX_EVENTS_TO_FETCH, eventsPerReducer);\n \n     // Start the map-completion events fetcher thread\n     final EventFetcher\u003cK,V\u003e eventFetcher \u003d \n       new EventFetcher\u003cK,V\u003e(reduceId, umbilical, scheduler, this,\n           maxEventsToFetch);\n     eventFetcher.start();\n     \n     // Start the map-output fetcher threads\n     final int numFetchers \u003d jobConf.getInt(MRJobConfig.SHUFFLE_PARALLEL_COPIES, 5);\n     Fetcher\u003cK,V\u003e[] fetchers \u003d new Fetcher[numFetchers];\n     for (int i\u003d0; i \u003c numFetchers; ++i) {\n       fetchers[i] \u003d new Fetcher\u003cK,V\u003e(jobConf, reduceId, scheduler, merger, \n                                      reporter, metrics, this, \n-                                     reduceTask.getJobTokenSecret());\n+                                     reduceTask.getShuffleSecret());\n       fetchers[i].start();\n     }\n     \n     // Wait for shuffle to complete successfully\n     while (!scheduler.waitUntilDone(PROGRESS_FREQUENCY)) {\n       reporter.progress();\n       \n       synchronized (this) {\n         if (throwable !\u003d null) {\n           throw new ShuffleError(\"error in shuffle in \" + throwingThreadName,\n                                  throwable);\n         }\n       }\n     }\n \n     // Stop the event-fetcher thread\n     eventFetcher.shutDown();\n     \n     // Stop the map-output fetcher threads\n     for (Fetcher\u003cK,V\u003e fetcher : fetchers) {\n       fetcher.shutDown();\n     }\n     \n     // stop the scheduler\n     scheduler.close();\n \n     copyPhase.complete(); // copy is already complete\n     taskStatus.setPhase(TaskStatus.Phase.SORT);\n     reduceTask.statusUpdate(umbilical);\n \n     // Finish the on-going merges...\n     RawKeyValueIterator kvIter \u003d null;\n     try {\n       kvIter \u003d merger.close();\n     } catch (Throwable e) {\n       throw new ShuffleError(\"Error while doing final merge \" , e);\n     }\n \n     // Sanity check\n     synchronized (this) {\n       if (throwable !\u003d null) {\n         throw new ShuffleError(\"error in shuffle in \" + throwingThreadName,\n                                throwable);\n       }\n     }\n     \n     return kvIter;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public RawKeyValueIterator run() throws IOException, InterruptedException {\n    // Scale the maximum events we fetch per RPC call to mitigate OOM issues\n    // on the ApplicationMaster when a thundering herd of reducers fetch events\n    // TODO: This should not be necessary after HADOOP-8942\n    int eventsPerReducer \u003d Math.max(MIN_EVENTS_TO_FETCH,\n        MAX_RPC_OUTSTANDING_EVENTS / jobConf.getNumReduceTasks());\n    int maxEventsToFetch \u003d Math.min(MAX_EVENTS_TO_FETCH, eventsPerReducer);\n\n    // Start the map-completion events fetcher thread\n    final EventFetcher\u003cK,V\u003e eventFetcher \u003d \n      new EventFetcher\u003cK,V\u003e(reduceId, umbilical, scheduler, this,\n          maxEventsToFetch);\n    eventFetcher.start();\n    \n    // Start the map-output fetcher threads\n    final int numFetchers \u003d jobConf.getInt(MRJobConfig.SHUFFLE_PARALLEL_COPIES, 5);\n    Fetcher\u003cK,V\u003e[] fetchers \u003d new Fetcher[numFetchers];\n    for (int i\u003d0; i \u003c numFetchers; ++i) {\n      fetchers[i] \u003d new Fetcher\u003cK,V\u003e(jobConf, reduceId, scheduler, merger, \n                                     reporter, metrics, this, \n                                     reduceTask.getShuffleSecret());\n      fetchers[i].start();\n    }\n    \n    // Wait for shuffle to complete successfully\n    while (!scheduler.waitUntilDone(PROGRESS_FREQUENCY)) {\n      reporter.progress();\n      \n      synchronized (this) {\n        if (throwable !\u003d null) {\n          throw new ShuffleError(\"error in shuffle in \" + throwingThreadName,\n                                 throwable);\n        }\n      }\n    }\n\n    // Stop the event-fetcher thread\n    eventFetcher.shutDown();\n    \n    // Stop the map-output fetcher threads\n    for (Fetcher\u003cK,V\u003e fetcher : fetchers) {\n      fetcher.shutDown();\n    }\n    \n    // stop the scheduler\n    scheduler.close();\n\n    copyPhase.complete(); // copy is already complete\n    taskStatus.setPhase(TaskStatus.Phase.SORT);\n    reduceTask.statusUpdate(umbilical);\n\n    // Finish the on-going merges...\n    RawKeyValueIterator kvIter \u003d null;\n    try {\n      kvIter \u003d merger.close();\n    } catch (Throwable e) {\n      throw new ShuffleError(\"Error while doing final merge \" , e);\n    }\n\n    // Sanity check\n    synchronized (this) {\n      if (throwable !\u003d null) {\n        throw new ShuffleError(\"error in shuffle in \" + throwingThreadName,\n                               throwable);\n      }\n    }\n    \n    return kvIter;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/Shuffle.java",
      "extendedDetails": {}
    },
    "905b17876c44634545a68300ff2f2d73fb86d3b7": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4723. Fix warnings found by findbugs 2. Contributed by Sandy Ryza\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1409601 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/11/12 4:16 PM",
      "commitName": "905b17876c44634545a68300ff2f2d73fb86d3b7",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "24/10/12 6:26 PM",
      "commitNameOld": "895029b2f2535f1ba8275be29fda16d0f80be790",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 20.95,
      "commitsBetweenForRepo": 117,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,70 +1,69 @@\n   public RawKeyValueIterator run() throws IOException, InterruptedException {\n     // Scale the maximum events we fetch per RPC call to mitigate OOM issues\n     // on the ApplicationMaster when a thundering herd of reducers fetch events\n     // TODO: This should not be necessary after HADOOP-8942\n     int eventsPerReducer \u003d Math.max(MIN_EVENTS_TO_FETCH,\n         MAX_RPC_OUTSTANDING_EVENTS / jobConf.getNumReduceTasks());\n     int maxEventsToFetch \u003d Math.min(MAX_EVENTS_TO_FETCH, eventsPerReducer);\n \n     // Start the map-completion events fetcher thread\n     final EventFetcher\u003cK,V\u003e eventFetcher \u003d \n       new EventFetcher\u003cK,V\u003e(reduceId, umbilical, scheduler, this,\n           maxEventsToFetch);\n     eventFetcher.start();\n     \n     // Start the map-output fetcher threads\n     final int numFetchers \u003d jobConf.getInt(MRJobConfig.SHUFFLE_PARALLEL_COPIES, 5);\n     Fetcher\u003cK,V\u003e[] fetchers \u003d new Fetcher[numFetchers];\n     for (int i\u003d0; i \u003c numFetchers; ++i) {\n       fetchers[i] \u003d new Fetcher\u003cK,V\u003e(jobConf, reduceId, scheduler, merger, \n                                      reporter, metrics, this, \n                                      reduceTask.getJobTokenSecret());\n       fetchers[i].start();\n     }\n     \n     // Wait for shuffle to complete successfully\n     while (!scheduler.waitUntilDone(PROGRESS_FREQUENCY)) {\n       reporter.progress();\n       \n       synchronized (this) {\n         if (throwable !\u003d null) {\n           throw new ShuffleError(\"error in shuffle in \" + throwingThreadName,\n                                  throwable);\n         }\n       }\n     }\n \n     // Stop the event-fetcher thread\n     eventFetcher.shutDown();\n     \n     // Stop the map-output fetcher threads\n     for (Fetcher\u003cK,V\u003e fetcher : fetchers) {\n       fetcher.shutDown();\n     }\n-    fetchers \u003d null;\n     \n     // stop the scheduler\n     scheduler.close();\n \n     copyPhase.complete(); // copy is already complete\n     taskStatus.setPhase(TaskStatus.Phase.SORT);\n     reduceTask.statusUpdate(umbilical);\n \n     // Finish the on-going merges...\n     RawKeyValueIterator kvIter \u003d null;\n     try {\n       kvIter \u003d merger.close();\n     } catch (Throwable e) {\n       throw new ShuffleError(\"Error while doing final merge \" , e);\n     }\n \n     // Sanity check\n     synchronized (this) {\n       if (throwable !\u003d null) {\n         throw new ShuffleError(\"error in shuffle in \" + throwingThreadName,\n                                throwable);\n       }\n     }\n     \n     return kvIter;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public RawKeyValueIterator run() throws IOException, InterruptedException {\n    // Scale the maximum events we fetch per RPC call to mitigate OOM issues\n    // on the ApplicationMaster when a thundering herd of reducers fetch events\n    // TODO: This should not be necessary after HADOOP-8942\n    int eventsPerReducer \u003d Math.max(MIN_EVENTS_TO_FETCH,\n        MAX_RPC_OUTSTANDING_EVENTS / jobConf.getNumReduceTasks());\n    int maxEventsToFetch \u003d Math.min(MAX_EVENTS_TO_FETCH, eventsPerReducer);\n\n    // Start the map-completion events fetcher thread\n    final EventFetcher\u003cK,V\u003e eventFetcher \u003d \n      new EventFetcher\u003cK,V\u003e(reduceId, umbilical, scheduler, this,\n          maxEventsToFetch);\n    eventFetcher.start();\n    \n    // Start the map-output fetcher threads\n    final int numFetchers \u003d jobConf.getInt(MRJobConfig.SHUFFLE_PARALLEL_COPIES, 5);\n    Fetcher\u003cK,V\u003e[] fetchers \u003d new Fetcher[numFetchers];\n    for (int i\u003d0; i \u003c numFetchers; ++i) {\n      fetchers[i] \u003d new Fetcher\u003cK,V\u003e(jobConf, reduceId, scheduler, merger, \n                                     reporter, metrics, this, \n                                     reduceTask.getJobTokenSecret());\n      fetchers[i].start();\n    }\n    \n    // Wait for shuffle to complete successfully\n    while (!scheduler.waitUntilDone(PROGRESS_FREQUENCY)) {\n      reporter.progress();\n      \n      synchronized (this) {\n        if (throwable !\u003d null) {\n          throw new ShuffleError(\"error in shuffle in \" + throwingThreadName,\n                                 throwable);\n        }\n      }\n    }\n\n    // Stop the event-fetcher thread\n    eventFetcher.shutDown();\n    \n    // Stop the map-output fetcher threads\n    for (Fetcher\u003cK,V\u003e fetcher : fetchers) {\n      fetcher.shutDown();\n    }\n    \n    // stop the scheduler\n    scheduler.close();\n\n    copyPhase.complete(); // copy is already complete\n    taskStatus.setPhase(TaskStatus.Phase.SORT);\n    reduceTask.statusUpdate(umbilical);\n\n    // Finish the on-going merges...\n    RawKeyValueIterator kvIter \u003d null;\n    try {\n      kvIter \u003d merger.close();\n    } catch (Throwable e) {\n      throw new ShuffleError(\"Error while doing final merge \" , e);\n    }\n\n    // Sanity check\n    synchronized (this) {\n      if (throwable !\u003d null) {\n        throw new ShuffleError(\"error in shuffle in \" + throwingThreadName,\n                               throwable);\n      }\n    }\n    \n    return kvIter;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/Shuffle.java",
      "extendedDetails": {}
    },
    "895029b2f2535f1ba8275be29fda16d0f80be790": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4730. Fix Reducer\u0027s EventFetcher to scale the map-completion requests slowly to avoid HADOOP-8942. Contributed by Jason Lowe.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1401941 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/10/12 6:26 PM",
      "commitName": "895029b2f2535f1ba8275be29fda16d0f80be790",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "24/01/12 3:18 PM",
      "commitNameOld": "078ae89a4793eb6a153a88b106d330fd059a4933",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 274.09,
      "commitsBetweenForRepo": 1800,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,62 +1,70 @@\n   public RawKeyValueIterator run() throws IOException, InterruptedException {\n+    // Scale the maximum events we fetch per RPC call to mitigate OOM issues\n+    // on the ApplicationMaster when a thundering herd of reducers fetch events\n+    // TODO: This should not be necessary after HADOOP-8942\n+    int eventsPerReducer \u003d Math.max(MIN_EVENTS_TO_FETCH,\n+        MAX_RPC_OUTSTANDING_EVENTS / jobConf.getNumReduceTasks());\n+    int maxEventsToFetch \u003d Math.min(MAX_EVENTS_TO_FETCH, eventsPerReducer);\n+\n     // Start the map-completion events fetcher thread\n     final EventFetcher\u003cK,V\u003e eventFetcher \u003d \n-      new EventFetcher\u003cK,V\u003e(reduceId, umbilical, scheduler, this);\n+      new EventFetcher\u003cK,V\u003e(reduceId, umbilical, scheduler, this,\n+          maxEventsToFetch);\n     eventFetcher.start();\n     \n     // Start the map-output fetcher threads\n     final int numFetchers \u003d jobConf.getInt(MRJobConfig.SHUFFLE_PARALLEL_COPIES, 5);\n     Fetcher\u003cK,V\u003e[] fetchers \u003d new Fetcher[numFetchers];\n     for (int i\u003d0; i \u003c numFetchers; ++i) {\n       fetchers[i] \u003d new Fetcher\u003cK,V\u003e(jobConf, reduceId, scheduler, merger, \n                                      reporter, metrics, this, \n                                      reduceTask.getJobTokenSecret());\n       fetchers[i].start();\n     }\n     \n     // Wait for shuffle to complete successfully\n     while (!scheduler.waitUntilDone(PROGRESS_FREQUENCY)) {\n       reporter.progress();\n       \n       synchronized (this) {\n         if (throwable !\u003d null) {\n           throw new ShuffleError(\"error in shuffle in \" + throwingThreadName,\n                                  throwable);\n         }\n       }\n     }\n \n     // Stop the event-fetcher thread\n     eventFetcher.shutDown();\n     \n     // Stop the map-output fetcher threads\n     for (Fetcher\u003cK,V\u003e fetcher : fetchers) {\n       fetcher.shutDown();\n     }\n     fetchers \u003d null;\n     \n     // stop the scheduler\n     scheduler.close();\n \n     copyPhase.complete(); // copy is already complete\n     taskStatus.setPhase(TaskStatus.Phase.SORT);\n     reduceTask.statusUpdate(umbilical);\n \n     // Finish the on-going merges...\n     RawKeyValueIterator kvIter \u003d null;\n     try {\n       kvIter \u003d merger.close();\n     } catch (Throwable e) {\n       throw new ShuffleError(\"Error while doing final merge \" , e);\n     }\n \n     // Sanity check\n     synchronized (this) {\n       if (throwable !\u003d null) {\n         throw new ShuffleError(\"error in shuffle in \" + throwingThreadName,\n                                throwable);\n       }\n     }\n     \n     return kvIter;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public RawKeyValueIterator run() throws IOException, InterruptedException {\n    // Scale the maximum events we fetch per RPC call to mitigate OOM issues\n    // on the ApplicationMaster when a thundering herd of reducers fetch events\n    // TODO: This should not be necessary after HADOOP-8942\n    int eventsPerReducer \u003d Math.max(MIN_EVENTS_TO_FETCH,\n        MAX_RPC_OUTSTANDING_EVENTS / jobConf.getNumReduceTasks());\n    int maxEventsToFetch \u003d Math.min(MAX_EVENTS_TO_FETCH, eventsPerReducer);\n\n    // Start the map-completion events fetcher thread\n    final EventFetcher\u003cK,V\u003e eventFetcher \u003d \n      new EventFetcher\u003cK,V\u003e(reduceId, umbilical, scheduler, this,\n          maxEventsToFetch);\n    eventFetcher.start();\n    \n    // Start the map-output fetcher threads\n    final int numFetchers \u003d jobConf.getInt(MRJobConfig.SHUFFLE_PARALLEL_COPIES, 5);\n    Fetcher\u003cK,V\u003e[] fetchers \u003d new Fetcher[numFetchers];\n    for (int i\u003d0; i \u003c numFetchers; ++i) {\n      fetchers[i] \u003d new Fetcher\u003cK,V\u003e(jobConf, reduceId, scheduler, merger, \n                                     reporter, metrics, this, \n                                     reduceTask.getJobTokenSecret());\n      fetchers[i].start();\n    }\n    \n    // Wait for shuffle to complete successfully\n    while (!scheduler.waitUntilDone(PROGRESS_FREQUENCY)) {\n      reporter.progress();\n      \n      synchronized (this) {\n        if (throwable !\u003d null) {\n          throw new ShuffleError(\"error in shuffle in \" + throwingThreadName,\n                                 throwable);\n        }\n      }\n    }\n\n    // Stop the event-fetcher thread\n    eventFetcher.shutDown();\n    \n    // Stop the map-output fetcher threads\n    for (Fetcher\u003cK,V\u003e fetcher : fetchers) {\n      fetcher.shutDown();\n    }\n    fetchers \u003d null;\n    \n    // stop the scheduler\n    scheduler.close();\n\n    copyPhase.complete(); // copy is already complete\n    taskStatus.setPhase(TaskStatus.Phase.SORT);\n    reduceTask.statusUpdate(umbilical);\n\n    // Finish the on-going merges...\n    RawKeyValueIterator kvIter \u003d null;\n    try {\n      kvIter \u003d merger.close();\n    } catch (Throwable e) {\n      throw new ShuffleError(\"Error while doing final merge \" , e);\n    }\n\n    // Sanity check\n    synchronized (this) {\n      if (throwable !\u003d null) {\n        throw new ShuffleError(\"error in shuffle in \" + throwingThreadName,\n                               throwable);\n      }\n    }\n    \n    return kvIter;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/Shuffle.java",
      "extendedDetails": {}
    },
    "078ae89a4793eb6a153a88b106d330fd059a4933": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3714. Fixed EventFetcher and Fetcher threads to shut-down properly so that reducers don\u0027t hang in corner cases. (vinodkv)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1235545 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/01/12 3:18 PM",
      "commitName": "078ae89a4793eb6a153a88b106d330fd059a4933",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "24/08/11 5:14 PM",
      "commitNameOld": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 152.96,
      "commitsBetweenForRepo": 935,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,70 +1,62 @@\n   public RawKeyValueIterator run() throws IOException, InterruptedException {\n     // Start the map-completion events fetcher thread\n     final EventFetcher\u003cK,V\u003e eventFetcher \u003d \n       new EventFetcher\u003cK,V\u003e(reduceId, umbilical, scheduler, this);\n     eventFetcher.start();\n     \n     // Start the map-output fetcher threads\n     final int numFetchers \u003d jobConf.getInt(MRJobConfig.SHUFFLE_PARALLEL_COPIES, 5);\n     Fetcher\u003cK,V\u003e[] fetchers \u003d new Fetcher[numFetchers];\n     for (int i\u003d0; i \u003c numFetchers; ++i) {\n       fetchers[i] \u003d new Fetcher\u003cK,V\u003e(jobConf, reduceId, scheduler, merger, \n                                      reporter, metrics, this, \n                                      reduceTask.getJobTokenSecret());\n       fetchers[i].start();\n     }\n     \n     // Wait for shuffle to complete successfully\n     while (!scheduler.waitUntilDone(PROGRESS_FREQUENCY)) {\n       reporter.progress();\n       \n       synchronized (this) {\n         if (throwable !\u003d null) {\n           throw new ShuffleError(\"error in shuffle in \" + throwingThreadName,\n                                  throwable);\n         }\n       }\n     }\n \n     // Stop the event-fetcher thread\n-    eventFetcher.interrupt();\n-    try {\n-      eventFetcher.join();\n-    } catch(Throwable t) {\n-      LOG.info(\"Failed to stop \" + eventFetcher.getName(), t);\n-    }\n+    eventFetcher.shutDown();\n     \n     // Stop the map-output fetcher threads\n     for (Fetcher\u003cK,V\u003e fetcher : fetchers) {\n-      fetcher.interrupt();\n-    }\n-    for (Fetcher\u003cK,V\u003e fetcher : fetchers) {\n-      fetcher.join();\n+      fetcher.shutDown();\n     }\n     fetchers \u003d null;\n     \n     // stop the scheduler\n     scheduler.close();\n \n     copyPhase.complete(); // copy is already complete\n     taskStatus.setPhase(TaskStatus.Phase.SORT);\n     reduceTask.statusUpdate(umbilical);\n \n     // Finish the on-going merges...\n     RawKeyValueIterator kvIter \u003d null;\n     try {\n       kvIter \u003d merger.close();\n     } catch (Throwable e) {\n       throw new ShuffleError(\"Error while doing final merge \" , e);\n     }\n \n     // Sanity check\n     synchronized (this) {\n       if (throwable !\u003d null) {\n         throw new ShuffleError(\"error in shuffle in \" + throwingThreadName,\n                                throwable);\n       }\n     }\n     \n     return kvIter;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public RawKeyValueIterator run() throws IOException, InterruptedException {\n    // Start the map-completion events fetcher thread\n    final EventFetcher\u003cK,V\u003e eventFetcher \u003d \n      new EventFetcher\u003cK,V\u003e(reduceId, umbilical, scheduler, this);\n    eventFetcher.start();\n    \n    // Start the map-output fetcher threads\n    final int numFetchers \u003d jobConf.getInt(MRJobConfig.SHUFFLE_PARALLEL_COPIES, 5);\n    Fetcher\u003cK,V\u003e[] fetchers \u003d new Fetcher[numFetchers];\n    for (int i\u003d0; i \u003c numFetchers; ++i) {\n      fetchers[i] \u003d new Fetcher\u003cK,V\u003e(jobConf, reduceId, scheduler, merger, \n                                     reporter, metrics, this, \n                                     reduceTask.getJobTokenSecret());\n      fetchers[i].start();\n    }\n    \n    // Wait for shuffle to complete successfully\n    while (!scheduler.waitUntilDone(PROGRESS_FREQUENCY)) {\n      reporter.progress();\n      \n      synchronized (this) {\n        if (throwable !\u003d null) {\n          throw new ShuffleError(\"error in shuffle in \" + throwingThreadName,\n                                 throwable);\n        }\n      }\n    }\n\n    // Stop the event-fetcher thread\n    eventFetcher.shutDown();\n    \n    // Stop the map-output fetcher threads\n    for (Fetcher\u003cK,V\u003e fetcher : fetchers) {\n      fetcher.shutDown();\n    }\n    fetchers \u003d null;\n    \n    // stop the scheduler\n    scheduler.close();\n\n    copyPhase.complete(); // copy is already complete\n    taskStatus.setPhase(TaskStatus.Phase.SORT);\n    reduceTask.statusUpdate(umbilical);\n\n    // Finish the on-going merges...\n    RawKeyValueIterator kvIter \u003d null;\n    try {\n      kvIter \u003d merger.close();\n    } catch (Throwable e) {\n      throw new ShuffleError(\"Error while doing final merge \" , e);\n    }\n\n    // Sanity check\n    synchronized (this) {\n      if (throwable !\u003d null) {\n        throw new ShuffleError(\"error in shuffle in \" + throwingThreadName,\n                               throwable);\n      }\n    }\n    \n    return kvIter;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/Shuffle.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public RawKeyValueIterator run() throws IOException, InterruptedException {\n    // Start the map-completion events fetcher thread\n    final EventFetcher\u003cK,V\u003e eventFetcher \u003d \n      new EventFetcher\u003cK,V\u003e(reduceId, umbilical, scheduler, this);\n    eventFetcher.start();\n    \n    // Start the map-output fetcher threads\n    final int numFetchers \u003d jobConf.getInt(MRJobConfig.SHUFFLE_PARALLEL_COPIES, 5);\n    Fetcher\u003cK,V\u003e[] fetchers \u003d new Fetcher[numFetchers];\n    for (int i\u003d0; i \u003c numFetchers; ++i) {\n      fetchers[i] \u003d new Fetcher\u003cK,V\u003e(jobConf, reduceId, scheduler, merger, \n                                     reporter, metrics, this, \n                                     reduceTask.getJobTokenSecret());\n      fetchers[i].start();\n    }\n    \n    // Wait for shuffle to complete successfully\n    while (!scheduler.waitUntilDone(PROGRESS_FREQUENCY)) {\n      reporter.progress();\n      \n      synchronized (this) {\n        if (throwable !\u003d null) {\n          throw new ShuffleError(\"error in shuffle in \" + throwingThreadName,\n                                 throwable);\n        }\n      }\n    }\n\n    // Stop the event-fetcher thread\n    eventFetcher.interrupt();\n    try {\n      eventFetcher.join();\n    } catch(Throwable t) {\n      LOG.info(\"Failed to stop \" + eventFetcher.getName(), t);\n    }\n    \n    // Stop the map-output fetcher threads\n    for (Fetcher\u003cK,V\u003e fetcher : fetchers) {\n      fetcher.interrupt();\n    }\n    for (Fetcher\u003cK,V\u003e fetcher : fetchers) {\n      fetcher.join();\n    }\n    fetchers \u003d null;\n    \n    // stop the scheduler\n    scheduler.close();\n\n    copyPhase.complete(); // copy is already complete\n    taskStatus.setPhase(TaskStatus.Phase.SORT);\n    reduceTask.statusUpdate(umbilical);\n\n    // Finish the on-going merges...\n    RawKeyValueIterator kvIter \u003d null;\n    try {\n      kvIter \u003d merger.close();\n    } catch (Throwable e) {\n      throw new ShuffleError(\"Error while doing final merge \" , e);\n    }\n\n    // Sanity check\n    synchronized (this) {\n      if (throwable !\u003d null) {\n        throw new ShuffleError(\"error in shuffle in \" + throwingThreadName,\n                               throwable);\n      }\n    }\n    \n    return kvIter;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/Shuffle.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/Shuffle.java",
        "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/Shuffle.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yfilerename",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "17/08/11 8:02 PM",
      "commitNameOld": "dd86860633d2ed64705b669a75bf318442ed6225",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 0.34,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public RawKeyValueIterator run() throws IOException, InterruptedException {\n    // Start the map-completion events fetcher thread\n    final EventFetcher\u003cK,V\u003e eventFetcher \u003d \n      new EventFetcher\u003cK,V\u003e(reduceId, umbilical, scheduler, this);\n    eventFetcher.start();\n    \n    // Start the map-output fetcher threads\n    final int numFetchers \u003d jobConf.getInt(MRJobConfig.SHUFFLE_PARALLEL_COPIES, 5);\n    Fetcher\u003cK,V\u003e[] fetchers \u003d new Fetcher[numFetchers];\n    for (int i\u003d0; i \u003c numFetchers; ++i) {\n      fetchers[i] \u003d new Fetcher\u003cK,V\u003e(jobConf, reduceId, scheduler, merger, \n                                     reporter, metrics, this, \n                                     reduceTask.getJobTokenSecret());\n      fetchers[i].start();\n    }\n    \n    // Wait for shuffle to complete successfully\n    while (!scheduler.waitUntilDone(PROGRESS_FREQUENCY)) {\n      reporter.progress();\n      \n      synchronized (this) {\n        if (throwable !\u003d null) {\n          throw new ShuffleError(\"error in shuffle in \" + throwingThreadName,\n                                 throwable);\n        }\n      }\n    }\n\n    // Stop the event-fetcher thread\n    eventFetcher.interrupt();\n    try {\n      eventFetcher.join();\n    } catch(Throwable t) {\n      LOG.info(\"Failed to stop \" + eventFetcher.getName(), t);\n    }\n    \n    // Stop the map-output fetcher threads\n    for (Fetcher\u003cK,V\u003e fetcher : fetchers) {\n      fetcher.interrupt();\n    }\n    for (Fetcher\u003cK,V\u003e fetcher : fetchers) {\n      fetcher.join();\n    }\n    fetchers \u003d null;\n    \n    // stop the scheduler\n    scheduler.close();\n\n    copyPhase.complete(); // copy is already complete\n    taskStatus.setPhase(TaskStatus.Phase.SORT);\n    reduceTask.statusUpdate(umbilical);\n\n    // Finish the on-going merges...\n    RawKeyValueIterator kvIter \u003d null;\n    try {\n      kvIter \u003d merger.close();\n    } catch (Throwable e) {\n      throw new ShuffleError(\"Error while doing final merge \" , e);\n    }\n\n    // Sanity check\n    synchronized (this) {\n      if (throwable !\u003d null) {\n        throw new ShuffleError(\"error in shuffle in \" + throwingThreadName,\n                               throwable);\n      }\n    }\n    \n    return kvIter;\n  }",
      "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/Shuffle.java",
      "extendedDetails": {
        "oldPath": "mapreduce/src/java/org/apache/hadoop/mapreduce/task/reduce/Shuffle.java",
        "newPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/Shuffle.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,70 @@\n+  public RawKeyValueIterator run() throws IOException, InterruptedException {\n+    // Start the map-completion events fetcher thread\n+    final EventFetcher\u003cK,V\u003e eventFetcher \u003d \n+      new EventFetcher\u003cK,V\u003e(reduceId, umbilical, scheduler, this);\n+    eventFetcher.start();\n+    \n+    // Start the map-output fetcher threads\n+    final int numFetchers \u003d jobConf.getInt(MRJobConfig.SHUFFLE_PARALLEL_COPIES, 5);\n+    Fetcher\u003cK,V\u003e[] fetchers \u003d new Fetcher[numFetchers];\n+    for (int i\u003d0; i \u003c numFetchers; ++i) {\n+      fetchers[i] \u003d new Fetcher\u003cK,V\u003e(jobConf, reduceId, scheduler, merger, \n+                                     reporter, metrics, this, \n+                                     reduceTask.getJobTokenSecret());\n+      fetchers[i].start();\n+    }\n+    \n+    // Wait for shuffle to complete successfully\n+    while (!scheduler.waitUntilDone(PROGRESS_FREQUENCY)) {\n+      reporter.progress();\n+      \n+      synchronized (this) {\n+        if (throwable !\u003d null) {\n+          throw new ShuffleError(\"error in shuffle in \" + throwingThreadName,\n+                                 throwable);\n+        }\n+      }\n+    }\n+\n+    // Stop the event-fetcher thread\n+    eventFetcher.interrupt();\n+    try {\n+      eventFetcher.join();\n+    } catch(Throwable t) {\n+      LOG.info(\"Failed to stop \" + eventFetcher.getName(), t);\n+    }\n+    \n+    // Stop the map-output fetcher threads\n+    for (Fetcher\u003cK,V\u003e fetcher : fetchers) {\n+      fetcher.interrupt();\n+    }\n+    for (Fetcher\u003cK,V\u003e fetcher : fetchers) {\n+      fetcher.join();\n+    }\n+    fetchers \u003d null;\n+    \n+    // stop the scheduler\n+    scheduler.close();\n+\n+    copyPhase.complete(); // copy is already complete\n+    taskStatus.setPhase(TaskStatus.Phase.SORT);\n+    reduceTask.statusUpdate(umbilical);\n+\n+    // Finish the on-going merges...\n+    RawKeyValueIterator kvIter \u003d null;\n+    try {\n+      kvIter \u003d merger.close();\n+    } catch (Throwable e) {\n+      throw new ShuffleError(\"Error while doing final merge \" , e);\n+    }\n+\n+    // Sanity check\n+    synchronized (this) {\n+      if (throwable !\u003d null) {\n+        throw new ShuffleError(\"error in shuffle in \" + throwingThreadName,\n+                               throwable);\n+      }\n+    }\n+    \n+    return kvIter;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public RawKeyValueIterator run() throws IOException, InterruptedException {\n    // Start the map-completion events fetcher thread\n    final EventFetcher\u003cK,V\u003e eventFetcher \u003d \n      new EventFetcher\u003cK,V\u003e(reduceId, umbilical, scheduler, this);\n    eventFetcher.start();\n    \n    // Start the map-output fetcher threads\n    final int numFetchers \u003d jobConf.getInt(MRJobConfig.SHUFFLE_PARALLEL_COPIES, 5);\n    Fetcher\u003cK,V\u003e[] fetchers \u003d new Fetcher[numFetchers];\n    for (int i\u003d0; i \u003c numFetchers; ++i) {\n      fetchers[i] \u003d new Fetcher\u003cK,V\u003e(jobConf, reduceId, scheduler, merger, \n                                     reporter, metrics, this, \n                                     reduceTask.getJobTokenSecret());\n      fetchers[i].start();\n    }\n    \n    // Wait for shuffle to complete successfully\n    while (!scheduler.waitUntilDone(PROGRESS_FREQUENCY)) {\n      reporter.progress();\n      \n      synchronized (this) {\n        if (throwable !\u003d null) {\n          throw new ShuffleError(\"error in shuffle in \" + throwingThreadName,\n                                 throwable);\n        }\n      }\n    }\n\n    // Stop the event-fetcher thread\n    eventFetcher.interrupt();\n    try {\n      eventFetcher.join();\n    } catch(Throwable t) {\n      LOG.info(\"Failed to stop \" + eventFetcher.getName(), t);\n    }\n    \n    // Stop the map-output fetcher threads\n    for (Fetcher\u003cK,V\u003e fetcher : fetchers) {\n      fetcher.interrupt();\n    }\n    for (Fetcher\u003cK,V\u003e fetcher : fetchers) {\n      fetcher.join();\n    }\n    fetchers \u003d null;\n    \n    // stop the scheduler\n    scheduler.close();\n\n    copyPhase.complete(); // copy is already complete\n    taskStatus.setPhase(TaskStatus.Phase.SORT);\n    reduceTask.statusUpdate(umbilical);\n\n    // Finish the on-going merges...\n    RawKeyValueIterator kvIter \u003d null;\n    try {\n      kvIter \u003d merger.close();\n    } catch (Throwable e) {\n      throw new ShuffleError(\"Error while doing final merge \" , e);\n    }\n\n    // Sanity check\n    synchronized (this) {\n      if (throwable !\u003d null) {\n        throw new ShuffleError(\"error in shuffle in \" + throwingThreadName,\n                               throwable);\n      }\n    }\n    \n    return kvIter;\n  }",
      "path": "mapreduce/src/java/org/apache/hadoop/mapreduce/task/reduce/Shuffle.java"
    }
  }
}