{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSImage.java",
  "functionName": "rollingRollback",
  "functionId": "rollingRollback___discardSegmentTxId-long__ckptId-long",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
  "functionStartLine": 777,
  "functionEndLine": 795,
  "numCommitsSeen": 123,
  "timeTaken": 2160,
  "changeHistory": [
    "987c9e12e184b35a5abab49f4188e22509ad63a5"
  ],
  "changeHistoryShort": {
    "987c9e12e184b35a5abab49f4188e22509ad63a5": "Ybodychange"
  },
  "changeHistoryDetails": {
    "987c9e12e184b35a5abab49f4188e22509ad63a5": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7939. Two fsimage_rollback_* files are created which are not deleted after rollback. (Contributed by J.Andreina)\n",
      "commitDate": "09/04/15 10:42 PM",
      "commitName": "987c9e12e184b35a5abab49f4188e22509ad63a5",
      "commitAuthor": "Vinayakumar B",
      "commitDateOld": "02/04/15 9:20 PM",
      "commitNameOld": "72f6bd4893dcf10d6dad24753f9be99505a87a1f",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 7.06,
      "commitsBetweenForRepo": 59,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,19 @@\n   private void rollingRollback(long discardSegmentTxId, long ckptId)\n       throws IOException {\n     // discard discard unnecessary editlog segments starting from the given id\n     this.editLog.discardSegments(discardSegmentTxId);\n     // rename the special checkpoint\n     renameCheckpoint(ckptId, NameNodeFile.IMAGE_ROLLBACK, NameNodeFile.IMAGE,\n         true);\n     // purge all the checkpoints after the marker\n     archivalManager.purgeCheckpoinsAfter(NameNodeFile.IMAGE, ckptId);\n+    // HDFS-7939: purge all old fsimage_rollback_*\n+    archivalManager.purgeCheckpoints(NameNodeFile.IMAGE_ROLLBACK);\n     String nameserviceId \u003d DFSUtil.getNamenodeNameServiceId(conf);\n     if (HAUtil.isHAEnabled(conf, nameserviceId)) {\n       // close the editlog since it is currently open for write\n       this.editLog.close();\n       // reopen the editlog for read\n       this.editLog.initSharedJournalsForRead();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void rollingRollback(long discardSegmentTxId, long ckptId)\n      throws IOException {\n    // discard discard unnecessary editlog segments starting from the given id\n    this.editLog.discardSegments(discardSegmentTxId);\n    // rename the special checkpoint\n    renameCheckpoint(ckptId, NameNodeFile.IMAGE_ROLLBACK, NameNodeFile.IMAGE,\n        true);\n    // purge all the checkpoints after the marker\n    archivalManager.purgeCheckpoinsAfter(NameNodeFile.IMAGE, ckptId);\n    // HDFS-7939: purge all old fsimage_rollback_*\n    archivalManager.purgeCheckpoints(NameNodeFile.IMAGE_ROLLBACK);\n    String nameserviceId \u003d DFSUtil.getNamenodeNameServiceId(conf);\n    if (HAUtil.isHAEnabled(conf, nameserviceId)) {\n      // close the editlog since it is currently open for write\n      this.editLog.close();\n      // reopen the editlog for read\n      this.editLog.initSharedJournalsForRead();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
      "extendedDetails": {}
    }
  }
}