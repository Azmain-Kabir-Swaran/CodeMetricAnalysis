{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ProvidedStorageMap.java",
  "functionName": "removeDatanode",
  "functionId": "removeDatanode___dnToRemove-DatanodeDescriptor",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/ProvidedStorageMap.java",
  "functionStartLine": 176,
  "functionEndLine": 185,
  "numCommitsSeen": 17,
  "timeTaken": 1846,
  "changeHistory": [
    "71d0a825711387fe06396323a9ca6a5af0ade415",
    "98f5ed5aa377ddd3f35b763b20c499d2ccac2ed5",
    "546b95f4843f3cbbbdf72d90d202cad551696082"
  ],
  "changeHistoryShort": {
    "71d0a825711387fe06396323a9ca6a5af0ade415": "Ybodychange",
    "98f5ed5aa377ddd3f35b763b20c499d2ccac2ed5": "Ybodychange",
    "546b95f4843f3cbbbdf72d90d202cad551696082": "Yintroduced"
  },
  "changeHistoryDetails": {
    "71d0a825711387fe06396323a9ca6a5af0ade415": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12607. [READ] Even one dead datanode with PROVIDED storage results in ProvidedStorageInfo being marked as FAILED\n",
      "commitDate": "15/12/17 5:51 PM",
      "commitName": "71d0a825711387fe06396323a9ca6a5af0ade415",
      "commitAuthor": "Virajith Jalaparti",
      "commitDateOld": "15/12/17 5:51 PM",
      "commitNameOld": "98f5ed5aa377ddd3f35b763b20c499d2ccac2ed5",
      "commitAuthorOld": "Virajith Jalaparti",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,9 +1,10 @@\n   public void removeDatanode(DatanodeDescriptor dnToRemove) {\n     if (providedEnabled) {\n       assert lock.hasWriteLock() : \"Not holding write lock\";\n-      int remainingDatanodes \u003d providedDescriptor.remove(dnToRemove);\n-      if (remainingDatanodes \u003d\u003d 0) {\n-        hasDNs \u003d false;\n+      providedDescriptor.remove(dnToRemove);\n+      // if all datanodes fail, set the block report count to 0\n+      if (providedDescriptor.activeProvidedDatanodes() \u003d\u003d 0) {\n+        providedStorageInfo.setBlockReportCount(0);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void removeDatanode(DatanodeDescriptor dnToRemove) {\n    if (providedEnabled) {\n      assert lock.hasWriteLock() : \"Not holding write lock\";\n      providedDescriptor.remove(dnToRemove);\n      // if all datanodes fail, set the block report count to 0\n      if (providedDescriptor.activeProvidedDatanodes() \u003d\u003d 0) {\n        providedStorageInfo.setBlockReportCount(0);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/ProvidedStorageMap.java",
      "extendedDetails": {}
    },
    "98f5ed5aa377ddd3f35b763b20c499d2ccac2ed5": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11902. [READ] Merge BlockFormatProvider and FileRegionProvider.\n",
      "commitDate": "15/12/17 5:51 PM",
      "commitName": "98f5ed5aa377ddd3f35b763b20c499d2ccac2ed5",
      "commitAuthor": "Virajith Jalaparti",
      "commitDateOld": "15/12/17 5:51 PM",
      "commitNameOld": "546b95f4843f3cbbbdf72d90d202cad551696082",
      "commitAuthorOld": "Virajith Jalaparti",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 6,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,8 +1,9 @@\n   public void removeDatanode(DatanodeDescriptor dnToRemove) {\n-    if (providedDescriptor !\u003d null) {\n+    if (providedEnabled) {\n+      assert lock.hasWriteLock() : \"Not holding write lock\";\n       int remainingDatanodes \u003d providedDescriptor.remove(dnToRemove);\n       if (remainingDatanodes \u003d\u003d 0) {\n-        blockProvider.stop();\n+        hasDNs \u003d false;\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void removeDatanode(DatanodeDescriptor dnToRemove) {\n    if (providedEnabled) {\n      assert lock.hasWriteLock() : \"Not holding write lock\";\n      int remainingDatanodes \u003d providedDescriptor.remove(dnToRemove);\n      if (remainingDatanodes \u003d\u003d 0) {\n        hasDNs \u003d false;\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/ProvidedStorageMap.java",
      "extendedDetails": {}
    },
    "546b95f4843f3cbbbdf72d90d202cad551696082": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-11673. [READ] Handle failures of Datanode with PROVIDED storage\n",
      "commitDate": "15/12/17 5:51 PM",
      "commitName": "546b95f4843f3cbbbdf72d90d202cad551696082",
      "commitAuthor": "Virajith Jalaparti",
      "diff": "@@ -0,0 +1,8 @@\n+  public void removeDatanode(DatanodeDescriptor dnToRemove) {\n+    if (providedDescriptor !\u003d null) {\n+      int remainingDatanodes \u003d providedDescriptor.remove(dnToRemove);\n+      if (remainingDatanodes \u003d\u003d 0) {\n+        blockProvider.stop();\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void removeDatanode(DatanodeDescriptor dnToRemove) {\n    if (providedDescriptor !\u003d null) {\n      int remainingDatanodes \u003d providedDescriptor.remove(dnToRemove);\n      if (remainingDatanodes \u003d\u003d 0) {\n        blockProvider.stop();\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/ProvidedStorageMap.java"
    }
  }
}