{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "JournalNodeRpcServer.java",
  "functionName": "acceptRecovery",
  "functionId": "acceptRecovery___reqInfo-RequestInfo__log-SegmentStateProto__fromUrl-URL",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JournalNodeRpcServer.java",
  "functionStartLine": 254,
  "functionEndLine": 258,
  "numCommitsSeen": 27,
  "timeTaken": 1487,
  "changeHistory": [
    "8dd1eeb94fef59feaf19182dd8f1fcf1389c7f34",
    "74d4573a23db5586c6e47ff2277aa7c35237da34"
  ],
  "changeHistoryShort": {
    "8dd1eeb94fef59feaf19182dd8f1fcf1389c7f34": "Ybodychange",
    "74d4573a23db5586c6e47ff2277aa7c35237da34": "Yintroduced"
  },
  "changeHistoryDetails": {
    "8dd1eeb94fef59feaf19182dd8f1fcf1389c7f34": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12553. Add nameServiceId to QJournalProtocol. Contributed by Bharat Viswanadham\n",
      "commitDate": "13/10/17 2:22 PM",
      "commitName": "8dd1eeb94fef59feaf19182dd8f1fcf1389c7f34",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "20/05/16 12:47 PM",
      "commitNameOld": "bcde1562d25c4f5595f4e3436dc3630315b1ceed",
      "commitAuthorOld": "Chris Nauroth",
      "daysBetweenCommits": 511.07,
      "commitsBetweenForRepo": 3444,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,5 +1,5 @@\n   public void acceptRecovery(RequestInfo reqInfo, SegmentStateProto log,\n       URL fromUrl) throws IOException {\n-    jn.getOrCreateJournal(reqInfo.getJournalId())\n+    jn.getOrCreateJournal(reqInfo.getJournalId(), reqInfo.getNameServiceId())\n         .acceptRecovery(reqInfo, log, fromUrl);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void acceptRecovery(RequestInfo reqInfo, SegmentStateProto log,\n      URL fromUrl) throws IOException {\n    jn.getOrCreateJournal(reqInfo.getJournalId(), reqInfo.getNameServiceId())\n        .acceptRecovery(reqInfo, log, fromUrl);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JournalNodeRpcServer.java",
      "extendedDetails": {}
    },
    "74d4573a23db5586c6e47ff2277aa7c35237da34": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-3077. Quorum-based protocol for reading and writing edit logs. Contributed by Todd Lipcon based on initial work from Brandon Li and Hari Mankude.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1363596 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/07/12 5:25 PM",
      "commitName": "74d4573a23db5586c6e47ff2277aa7c35237da34",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,5 @@\n+  public void acceptRecovery(RequestInfo reqInfo, SegmentStateProto log,\n+      URL fromUrl) throws IOException {\n+    jn.getOrCreateJournal(reqInfo.getJournalId())\n+        .acceptRecovery(reqInfo, log, fromUrl);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void acceptRecovery(RequestInfo reqInfo, SegmentStateProto log,\n      URL fromUrl) throws IOException {\n    jn.getOrCreateJournal(reqInfo.getJournalId())\n        .acceptRecovery(reqInfo, log, fromUrl);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JournalNodeRpcServer.java"
    }
  }
}