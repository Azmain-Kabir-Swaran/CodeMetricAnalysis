{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "LowRedundancyBlocks.java",
  "functionName": "getPriority",
  "functionId": "getPriority___block-BlockInfo__curReplicas-int__readOnlyReplicas-int__outOfServiceReplicas-int__expectedReplicas-int",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/LowRedundancyBlocks.java",
  "functionStartLine": 208,
  "functionEndLine": 226,
  "numCommitsSeen": 45,
  "timeTaken": 3630,
  "changeHistory": [
    "b61fb267b92b2736920b4bd0c673d31e7632ebb9",
    "32d043d9c5f4615058ea4f65a58ba271ba47fcb5",
    "5411dc559d5f73e4153e76fdff94a26869c17a37"
  ],
  "changeHistoryShort": {
    "b61fb267b92b2736920b4bd0c673d31e7632ebb9": "Ymultichange(Yparameterchange,Ybodychange)",
    "32d043d9c5f4615058ea4f65a58ba271ba47fcb5": "Yfilerename",
    "5411dc559d5f73e4153e76fdff94a26869c17a37": "Ymultichange(Yparameterchange,Ybodychange)"
  },
  "changeHistoryDetails": {
    "b61fb267b92b2736920b4bd0c673d31e7632ebb9": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-9390. Block management for maintenance states.\n",
      "commitDate": "17/10/16 5:45 PM",
      "commitName": "b61fb267b92b2736920b4bd0c673d31e7632ebb9",
      "commitAuthor": "Ming Ma",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-9390. Block management for maintenance states.\n",
          "commitDate": "17/10/16 5:45 PM",
          "commitName": "b61fb267b92b2736920b4bd0c673d31e7632ebb9",
          "commitAuthor": "Ming Ma",
          "commitDateOld": "16/03/16 4:53 PM",
          "commitNameOld": "32d043d9c5f4615058ea4f65a58ba271ba47fcb5",
          "commitAuthorOld": "Zhe Zhang",
          "daysBetweenCommits": 215.04,
          "commitsBetweenForRepo": 1525,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,19 +1,19 @@\n   private int getPriority(BlockInfo block,\n                           int curReplicas,\n                           int readOnlyReplicas,\n-                          int decommissionedReplicas,\n+                          int outOfServiceReplicas,\n                           int expectedReplicas) {\n     assert curReplicas \u003e\u003d 0 : \"Negative replicas!\";\n     if (curReplicas \u003e\u003d expectedReplicas) {\n       // Block has enough copies, but not enough racks\n       return QUEUE_REPLICAS_BADLY_DISTRIBUTED;\n     }\n     if (block.isStriped()) {\n       BlockInfoStriped sblk \u003d (BlockInfoStriped) block;\n-      return getPriorityStriped(curReplicas, decommissionedReplicas,\n+      return getPriorityStriped(curReplicas, outOfServiceReplicas,\n           sblk.getRealDataBlockNum(), sblk.getParityBlockNum());\n     } else {\n       return getPriorityContiguous(curReplicas, readOnlyReplicas,\n-          decommissionedReplicas, expectedReplicas);\n+          outOfServiceReplicas, expectedReplicas);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private int getPriority(BlockInfo block,\n                          int curReplicas,\n                          int readOnlyReplicas,\n                          int outOfServiceReplicas,\n                          int expectedReplicas) {\n    assert curReplicas \u003e\u003d 0 : \"Negative replicas!\";\n    if (curReplicas \u003e\u003d expectedReplicas) {\n      // Block has enough copies, but not enough racks\n      return QUEUE_REPLICAS_BADLY_DISTRIBUTED;\n    }\n    if (block.isStriped()) {\n      BlockInfoStriped sblk \u003d (BlockInfoStriped) block;\n      return getPriorityStriped(curReplicas, outOfServiceReplicas,\n          sblk.getRealDataBlockNum(), sblk.getParityBlockNum());\n    } else {\n      return getPriorityContiguous(curReplicas, readOnlyReplicas,\n          outOfServiceReplicas, expectedReplicas);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/LowRedundancyBlocks.java",
          "extendedDetails": {
            "oldValue": "[block-BlockInfo, curReplicas-int, readOnlyReplicas-int, decommissionedReplicas-int, expectedReplicas-int]",
            "newValue": "[block-BlockInfo, curReplicas-int, readOnlyReplicas-int, outOfServiceReplicas-int, expectedReplicas-int]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-9390. Block management for maintenance states.\n",
          "commitDate": "17/10/16 5:45 PM",
          "commitName": "b61fb267b92b2736920b4bd0c673d31e7632ebb9",
          "commitAuthor": "Ming Ma",
          "commitDateOld": "16/03/16 4:53 PM",
          "commitNameOld": "32d043d9c5f4615058ea4f65a58ba271ba47fcb5",
          "commitAuthorOld": "Zhe Zhang",
          "daysBetweenCommits": 215.04,
          "commitsBetweenForRepo": 1525,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,19 +1,19 @@\n   private int getPriority(BlockInfo block,\n                           int curReplicas,\n                           int readOnlyReplicas,\n-                          int decommissionedReplicas,\n+                          int outOfServiceReplicas,\n                           int expectedReplicas) {\n     assert curReplicas \u003e\u003d 0 : \"Negative replicas!\";\n     if (curReplicas \u003e\u003d expectedReplicas) {\n       // Block has enough copies, but not enough racks\n       return QUEUE_REPLICAS_BADLY_DISTRIBUTED;\n     }\n     if (block.isStriped()) {\n       BlockInfoStriped sblk \u003d (BlockInfoStriped) block;\n-      return getPriorityStriped(curReplicas, decommissionedReplicas,\n+      return getPriorityStriped(curReplicas, outOfServiceReplicas,\n           sblk.getRealDataBlockNum(), sblk.getParityBlockNum());\n     } else {\n       return getPriorityContiguous(curReplicas, readOnlyReplicas,\n-          decommissionedReplicas, expectedReplicas);\n+          outOfServiceReplicas, expectedReplicas);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private int getPriority(BlockInfo block,\n                          int curReplicas,\n                          int readOnlyReplicas,\n                          int outOfServiceReplicas,\n                          int expectedReplicas) {\n    assert curReplicas \u003e\u003d 0 : \"Negative replicas!\";\n    if (curReplicas \u003e\u003d expectedReplicas) {\n      // Block has enough copies, but not enough racks\n      return QUEUE_REPLICAS_BADLY_DISTRIBUTED;\n    }\n    if (block.isStriped()) {\n      BlockInfoStriped sblk \u003d (BlockInfoStriped) block;\n      return getPriorityStriped(curReplicas, outOfServiceReplicas,\n          sblk.getRealDataBlockNum(), sblk.getParityBlockNum());\n    } else {\n      return getPriorityContiguous(curReplicas, readOnlyReplicas,\n          outOfServiceReplicas, expectedReplicas);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/LowRedundancyBlocks.java",
          "extendedDetails": {}
        }
      ]
    },
    "32d043d9c5f4615058ea4f65a58ba271ba47fcb5": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-9857. Erasure Coding: Rename replication-based names in BlockManager to more generic [part-1]. Contributed by Rakesh R.\n",
      "commitDate": "16/03/16 4:53 PM",
      "commitName": "32d043d9c5f4615058ea4f65a58ba271ba47fcb5",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "16/03/16 7:35 AM",
      "commitNameOld": "605fdcbb81687c73ba91a3bd0d607cabd3dc5a67",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 0.39,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private int getPriority(BlockInfo block,\n                          int curReplicas,\n                          int readOnlyReplicas,\n                          int decommissionedReplicas,\n                          int expectedReplicas) {\n    assert curReplicas \u003e\u003d 0 : \"Negative replicas!\";\n    if (curReplicas \u003e\u003d expectedReplicas) {\n      // Block has enough copies, but not enough racks\n      return QUEUE_REPLICAS_BADLY_DISTRIBUTED;\n    }\n    if (block.isStriped()) {\n      BlockInfoStriped sblk \u003d (BlockInfoStriped) block;\n      return getPriorityStriped(curReplicas, decommissionedReplicas,\n          sblk.getRealDataBlockNum(), sblk.getParityBlockNum());\n    } else {\n      return getPriorityContiguous(curReplicas, readOnlyReplicas,\n          decommissionedReplicas, expectedReplicas);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/LowRedundancyBlocks.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/UnderReplicatedBlocks.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/LowRedundancyBlocks.java"
      }
    },
    "5411dc559d5f73e4153e76fdff94a26869c17a37": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-9205. Do not schedule corrupt blocks for replication.  (szetszwo)\n",
      "commitDate": "15/10/15 3:07 AM",
      "commitName": "5411dc559d5f73e4153e76fdff94a26869c17a37",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-9205. Do not schedule corrupt blocks for replication.  (szetszwo)\n",
          "commitDate": "15/10/15 3:07 AM",
          "commitName": "5411dc559d5f73e4153e76fdff94a26869c17a37",
          "commitAuthor": "Tsz-Wo Nicholas Sze",
          "commitDateOld": "24/08/15 12:59 PM",
          "commitNameOld": "6b6a63bbbda920315d3d24b61ed3344a78a981b6",
          "commitAuthorOld": "",
          "daysBetweenCommits": 51.59,
          "commitsBetweenForRepo": 371,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,18 +1,19 @@\n   private int getPriority(BlockInfo block,\n                           int curReplicas,\n+                          int readOnlyReplicas,\n                           int decommissionedReplicas,\n                           int expectedReplicas) {\n     assert curReplicas \u003e\u003d 0 : \"Negative replicas!\";\n     if (curReplicas \u003e\u003d expectedReplicas) {\n       // Block has enough copies, but not enough racks\n       return QUEUE_REPLICAS_BADLY_DISTRIBUTED;\n     }\n     if (block.isStriped()) {\n       BlockInfoStriped sblk \u003d (BlockInfoStriped) block;\n       return getPriorityStriped(curReplicas, decommissionedReplicas,\n           sblk.getRealDataBlockNum(), sblk.getParityBlockNum());\n     } else {\n-      return getPriorityContiguous(curReplicas, decommissionedReplicas,\n-          expectedReplicas);\n+      return getPriorityContiguous(curReplicas, readOnlyReplicas,\n+          decommissionedReplicas, expectedReplicas);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private int getPriority(BlockInfo block,\n                          int curReplicas,\n                          int readOnlyReplicas,\n                          int decommissionedReplicas,\n                          int expectedReplicas) {\n    assert curReplicas \u003e\u003d 0 : \"Negative replicas!\";\n    if (curReplicas \u003e\u003d expectedReplicas) {\n      // Block has enough copies, but not enough racks\n      return QUEUE_REPLICAS_BADLY_DISTRIBUTED;\n    }\n    if (block.isStriped()) {\n      BlockInfoStriped sblk \u003d (BlockInfoStriped) block;\n      return getPriorityStriped(curReplicas, decommissionedReplicas,\n          sblk.getRealDataBlockNum(), sblk.getParityBlockNum());\n    } else {\n      return getPriorityContiguous(curReplicas, readOnlyReplicas,\n          decommissionedReplicas, expectedReplicas);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/UnderReplicatedBlocks.java",
          "extendedDetails": {
            "oldValue": "[block-BlockInfo, curReplicas-int, decommissionedReplicas-int, expectedReplicas-int]",
            "newValue": "[block-BlockInfo, curReplicas-int, readOnlyReplicas-int, decommissionedReplicas-int, expectedReplicas-int]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-9205. Do not schedule corrupt blocks for replication.  (szetszwo)\n",
          "commitDate": "15/10/15 3:07 AM",
          "commitName": "5411dc559d5f73e4153e76fdff94a26869c17a37",
          "commitAuthor": "Tsz-Wo Nicholas Sze",
          "commitDateOld": "24/08/15 12:59 PM",
          "commitNameOld": "6b6a63bbbda920315d3d24b61ed3344a78a981b6",
          "commitAuthorOld": "",
          "daysBetweenCommits": 51.59,
          "commitsBetweenForRepo": 371,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,18 +1,19 @@\n   private int getPriority(BlockInfo block,\n                           int curReplicas,\n+                          int readOnlyReplicas,\n                           int decommissionedReplicas,\n                           int expectedReplicas) {\n     assert curReplicas \u003e\u003d 0 : \"Negative replicas!\";\n     if (curReplicas \u003e\u003d expectedReplicas) {\n       // Block has enough copies, but not enough racks\n       return QUEUE_REPLICAS_BADLY_DISTRIBUTED;\n     }\n     if (block.isStriped()) {\n       BlockInfoStriped sblk \u003d (BlockInfoStriped) block;\n       return getPriorityStriped(curReplicas, decommissionedReplicas,\n           sblk.getRealDataBlockNum(), sblk.getParityBlockNum());\n     } else {\n-      return getPriorityContiguous(curReplicas, decommissionedReplicas,\n-          expectedReplicas);\n+      return getPriorityContiguous(curReplicas, readOnlyReplicas,\n+          decommissionedReplicas, expectedReplicas);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private int getPriority(BlockInfo block,\n                          int curReplicas,\n                          int readOnlyReplicas,\n                          int decommissionedReplicas,\n                          int expectedReplicas) {\n    assert curReplicas \u003e\u003d 0 : \"Negative replicas!\";\n    if (curReplicas \u003e\u003d expectedReplicas) {\n      // Block has enough copies, but not enough racks\n      return QUEUE_REPLICAS_BADLY_DISTRIBUTED;\n    }\n    if (block.isStriped()) {\n      BlockInfoStriped sblk \u003d (BlockInfoStriped) block;\n      return getPriorityStriped(curReplicas, decommissionedReplicas,\n          sblk.getRealDataBlockNum(), sblk.getParityBlockNum());\n    } else {\n      return getPriorityContiguous(curReplicas, readOnlyReplicas,\n          decommissionedReplicas, expectedReplicas);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/UnderReplicatedBlocks.java",
          "extendedDetails": {}
        }
      ]
    }
  }
}