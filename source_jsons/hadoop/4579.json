{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DatanodeProtocolClientSideTranslatorPB.java",
  "functionName": "cacheReport",
  "functionId": "cacheReport___registration-DatanodeRegistration__poolId-String__blockIds-List__Long__",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolClientSideTranslatorPB.java",
  "functionStartLine": 226,
  "functionEndLine": 246,
  "numCommitsSeen": 69,
  "timeTaken": 2011,
  "changeHistory": [
    "f9c08d02ebe4a5477cf5d753f0d9d48fc6f9fa48",
    "52ccc6c6d539d0587c3fd9693709bd1f6e12619d"
  ],
  "changeHistoryShort": {
    "f9c08d02ebe4a5477cf5d753f0d9d48fc6f9fa48": "Ymultichange(Yparameterchange,Ybodychange)",
    "52ccc6c6d539d0587c3fd9693709bd1f6e12619d": "Yintroduced"
  },
  "changeHistoryDetails": {
    "f9c08d02ebe4a5477cf5d753f0d9d48fc6f9fa48": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-5378. In CacheReport, don\u0027t send genstamp and length on the wire (Contributed by Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1534334 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/10/13 12:29 PM",
      "commitName": "f9c08d02ebe4a5477cf5d753f0d9d48fc6f9fa48",
      "commitAuthor": "Colin McCabe",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-5378. In CacheReport, don\u0027t send genstamp and length on the wire (Contributed by Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1534334 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "21/10/13 12:29 PM",
          "commitName": "f9c08d02ebe4a5477cf5d753f0d9d48fc6f9fa48",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "30/08/13 3:15 PM",
          "commitNameOld": "fc14a92c6b46cc435a8f33e6fa0512c70caa06e0",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 51.88,
          "commitsBetweenForRepo": 332,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,21 +1,21 @@\n   public DatanodeCommand cacheReport(DatanodeRegistration registration,\n-      String poolId, long[] blocks) throws IOException {\n+      String poolId, List\u003cLong\u003e blockIds) throws IOException {\n     CacheReportRequestProto.Builder builder \u003d\n         CacheReportRequestProto.newBuilder()\n         .setRegistration(PBHelper.convert(registration))\n         .setBlockPoolId(poolId);\n-    for (int i\u003d0; i\u003cblocks.length; i++) {\n-      builder.addBlocks(blocks[i]);\n+    for (Long blockId : blockIds) {\n+      builder.addBlocks(blockId);\n     }\n     \n     CacheReportResponseProto resp;\n     try {\n       resp \u003d rpcProxy.cacheReport(NULL_CONTROLLER, builder.build());\n     } catch (ServiceException se) {\n       throw ProtobufHelper.getRemoteException(se);\n     }\n     if (resp.hasCmd()) {\n       return PBHelper.convert(resp.getCmd());\n     }\n     return null;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public DatanodeCommand cacheReport(DatanodeRegistration registration,\n      String poolId, List\u003cLong\u003e blockIds) throws IOException {\n    CacheReportRequestProto.Builder builder \u003d\n        CacheReportRequestProto.newBuilder()\n        .setRegistration(PBHelper.convert(registration))\n        .setBlockPoolId(poolId);\n    for (Long blockId : blockIds) {\n      builder.addBlocks(blockId);\n    }\n    \n    CacheReportResponseProto resp;\n    try {\n      resp \u003d rpcProxy.cacheReport(NULL_CONTROLLER, builder.build());\n    } catch (ServiceException se) {\n      throw ProtobufHelper.getRemoteException(se);\n    }\n    if (resp.hasCmd()) {\n      return PBHelper.convert(resp.getCmd());\n    }\n    return null;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolClientSideTranslatorPB.java",
          "extendedDetails": {
            "oldValue": "[registration-DatanodeRegistration, poolId-String, blocks-long[]]",
            "newValue": "[registration-DatanodeRegistration, poolId-String, blockIds-List\u003cLong\u003e]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5378. In CacheReport, don\u0027t send genstamp and length on the wire (Contributed by Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1534334 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "21/10/13 12:29 PM",
          "commitName": "f9c08d02ebe4a5477cf5d753f0d9d48fc6f9fa48",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "30/08/13 3:15 PM",
          "commitNameOld": "fc14a92c6b46cc435a8f33e6fa0512c70caa06e0",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 51.88,
          "commitsBetweenForRepo": 332,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,21 +1,21 @@\n   public DatanodeCommand cacheReport(DatanodeRegistration registration,\n-      String poolId, long[] blocks) throws IOException {\n+      String poolId, List\u003cLong\u003e blockIds) throws IOException {\n     CacheReportRequestProto.Builder builder \u003d\n         CacheReportRequestProto.newBuilder()\n         .setRegistration(PBHelper.convert(registration))\n         .setBlockPoolId(poolId);\n-    for (int i\u003d0; i\u003cblocks.length; i++) {\n-      builder.addBlocks(blocks[i]);\n+    for (Long blockId : blockIds) {\n+      builder.addBlocks(blockId);\n     }\n     \n     CacheReportResponseProto resp;\n     try {\n       resp \u003d rpcProxy.cacheReport(NULL_CONTROLLER, builder.build());\n     } catch (ServiceException se) {\n       throw ProtobufHelper.getRemoteException(se);\n     }\n     if (resp.hasCmd()) {\n       return PBHelper.convert(resp.getCmd());\n     }\n     return null;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public DatanodeCommand cacheReport(DatanodeRegistration registration,\n      String poolId, List\u003cLong\u003e blockIds) throws IOException {\n    CacheReportRequestProto.Builder builder \u003d\n        CacheReportRequestProto.newBuilder()\n        .setRegistration(PBHelper.convert(registration))\n        .setBlockPoolId(poolId);\n    for (Long blockId : blockIds) {\n      builder.addBlocks(blockId);\n    }\n    \n    CacheReportResponseProto resp;\n    try {\n      resp \u003d rpcProxy.cacheReport(NULL_CONTROLLER, builder.build());\n    } catch (ServiceException se) {\n      throw ProtobufHelper.getRemoteException(se);\n    }\n    if (resp.hasCmd()) {\n      return PBHelper.convert(resp.getCmd());\n    }\n    return null;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolClientSideTranslatorPB.java",
          "extendedDetails": {}
        }
      ]
    },
    "52ccc6c6d539d0587c3fd9693709bd1f6e12619d": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-5051.  Propagate cache status information from the DataNode to the NameNode  (Andrew Wang via Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1513653 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/08/13 2:05 PM",
      "commitName": "52ccc6c6d539d0587c3fd9693709bd1f6e12619d",
      "commitAuthor": "Colin McCabe",
      "diff": "@@ -0,0 +1,21 @@\n+  public DatanodeCommand cacheReport(DatanodeRegistration registration,\n+      String poolId, long[] blocks) throws IOException {\n+    CacheReportRequestProto.Builder builder \u003d\n+        CacheReportRequestProto.newBuilder()\n+        .setRegistration(PBHelper.convert(registration))\n+        .setBlockPoolId(poolId);\n+    for (int i\u003d0; i\u003cblocks.length; i++) {\n+      builder.addBlocks(blocks[i]);\n+    }\n+    \n+    CacheReportResponseProto resp;\n+    try {\n+      resp \u003d rpcProxy.cacheReport(NULL_CONTROLLER, builder.build());\n+    } catch (ServiceException se) {\n+      throw ProtobufHelper.getRemoteException(se);\n+    }\n+    if (resp.hasCmd()) {\n+      return PBHelper.convert(resp.getCmd());\n+    }\n+    return null;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public DatanodeCommand cacheReport(DatanodeRegistration registration,\n      String poolId, long[] blocks) throws IOException {\n    CacheReportRequestProto.Builder builder \u003d\n        CacheReportRequestProto.newBuilder()\n        .setRegistration(PBHelper.convert(registration))\n        .setBlockPoolId(poolId);\n    for (int i\u003d0; i\u003cblocks.length; i++) {\n      builder.addBlocks(blocks[i]);\n    }\n    \n    CacheReportResponseProto resp;\n    try {\n      resp \u003d rpcProxy.cacheReport(NULL_CONTROLLER, builder.build());\n    } catch (ServiceException se) {\n      throw ProtobufHelper.getRemoteException(se);\n    }\n    if (resp.hasCmd()) {\n      return PBHelper.convert(resp.getCmd());\n    }\n    return null;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolClientSideTranslatorPB.java"
    }
  }
}