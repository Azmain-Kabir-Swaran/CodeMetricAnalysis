{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FileChecksumHelper.java",
  "functionName": "compute",
  "functionId": "compute",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/FileChecksumHelper.java",
  "functionStartLine": 237,
  "functionEndLine": 255,
  "numCommitsSeen": 9,
  "timeTaken": 1294,
  "changeHistory": [
    "cc1292e73acd39c1f1023ad4841ffe30176f7daf",
    "307ec80acae3b4a41d21b2d4b3a55032e55fcdc6"
  ],
  "changeHistoryShort": {
    "cc1292e73acd39c1f1023ad4841ffe30176f7daf": "Ybodychange",
    "307ec80acae3b4a41d21b2d4b3a55032e55fcdc6": "Yintroduced"
  },
  "changeHistoryDetails": {
    "cc1292e73acd39c1f1023ad4841ffe30176f7daf": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9705. Refine the behaviour of getFileChecksum when length \u003d 0. Contributed by Kai Zheng and SammiChen.\n",
      "commitDate": "14/03/17 4:41 PM",
      "commitName": "cc1292e73acd39c1f1023ad4841ffe30176f7daf",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "24/06/16 2:39 AM",
      "commitNameOld": "e6cb07520f935efde3e881de8f84ee7f6e0a746f",
      "commitAuthorOld": "Kai Zheng",
      "daysBetweenCommits": 263.58,
      "commitsBetweenForRepo": 1765,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,5 +1,19 @@\n     void compute() throws IOException {\n-      checksumBlocks();\n-\n-      fileChecksum \u003d makeFinalResult();\n+      /**\n+       * request length is 0 or the file is empty, return one with the\n+       * magic entry that matches what previous hdfs versions return.\n+       */\n+      if (locatedBlocks \u003d\u003d null || locatedBlocks.isEmpty()) {\n+        // Explicitly specified here in case the default DataOutputBuffer\n+        // buffer length value is changed in future. This matters because the\n+        // fixed value 32 has to be used to repeat the magic value for previous\n+        // HDFS version.\n+        final int lenOfZeroBytes \u003d 32;\n+        byte[] emptyBlockMd5 \u003d new byte[lenOfZeroBytes];\n+        MD5Hash fileMD5 \u003d MD5Hash.digest(emptyBlockMd5);\n+        fileChecksum \u003d  new MD5MD5CRC32GzipFileChecksum(0, 0, fileMD5);\n+      } else {\n+        checksumBlocks();\n+        fileChecksum \u003d makeFinalResult();\n+      }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void compute() throws IOException {\n      /**\n       * request length is 0 or the file is empty, return one with the\n       * magic entry that matches what previous hdfs versions return.\n       */\n      if (locatedBlocks \u003d\u003d null || locatedBlocks.isEmpty()) {\n        // Explicitly specified here in case the default DataOutputBuffer\n        // buffer length value is changed in future. This matters because the\n        // fixed value 32 has to be used to repeat the magic value for previous\n        // HDFS version.\n        final int lenOfZeroBytes \u003d 32;\n        byte[] emptyBlockMd5 \u003d new byte[lenOfZeroBytes];\n        MD5Hash fileMD5 \u003d MD5Hash.digest(emptyBlockMd5);\n        fileChecksum \u003d  new MD5MD5CRC32GzipFileChecksum(0, 0, fileMD5);\n      } else {\n        checksumBlocks();\n        fileChecksum \u003d makeFinalResult();\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/FileChecksumHelper.java",
      "extendedDetails": {}
    },
    "307ec80acae3b4a41d21b2d4b3a55032e55fcdc6": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-9733. Refactor DFSClient#getFileChecksum and DataXceiver#blockChecksum. Contributed by Kai Zheng\n",
      "commitDate": "29/02/16 9:52 PM",
      "commitName": "307ec80acae3b4a41d21b2d4b3a55032e55fcdc6",
      "commitAuthor": "Uma Maheswara Rao G",
      "diff": "@@ -0,0 +1,5 @@\n+    void compute() throws IOException {\n+      checksumBlocks();\n+\n+      fileChecksum \u003d makeFinalResult();\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    void compute() throws IOException {\n      checksumBlocks();\n\n      fileChecksum \u003d makeFinalResult();\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/FileChecksumHelper.java"
    }
  }
}