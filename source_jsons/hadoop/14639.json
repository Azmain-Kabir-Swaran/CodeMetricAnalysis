{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DFSNetworkTopology.java",
  "functionName": "chooseRandomWithStorageType",
  "functionId": "chooseRandomWithStorageType___scope-String(modifiers-final)__excludedScope-String__excludedNodes-Collection__Node__(modifiers-final)__type-StorageType",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/net/DFSNetworkTopology.java",
  "functionStartLine": 179,
  "functionEndLine": 258,
  "numCommitsSeen": 11,
  "timeTaken": 4644,
  "changeHistory": [
    "c84e6beada4e604175f7f138c9878a29665a8c47",
    "1189af4746919774035f5d64ccb4d2ce21905aaa",
    "b643a1cbe8a82ca331ffcd14fccc1dc0d90da5c7",
    "74c2329fc36e0878555342085defb4e474ef1aad",
    "54dc6b7d720851eb6017906d664aa0fda2698225",
    "c30e495557359b23681a61edbc90cfafafdb7dfe",
    "97c2e576c91c2316c2b52bfc948bae9bff8ca49f",
    "9832ae0ed8853d29072c9ea7031cd2373e6b16f9"
  ],
  "changeHistoryShort": {
    "c84e6beada4e604175f7f138c9878a29665a8c47": "Ybodychange",
    "1189af4746919774035f5d64ccb4d2ce21905aaa": "Ybodychange",
    "b643a1cbe8a82ca331ffcd14fccc1dc0d90da5c7": "Ybodychange",
    "74c2329fc36e0878555342085defb4e474ef1aad": "Ybodychange",
    "54dc6b7d720851eb6017906d664aa0fda2698225": "Ybodychange",
    "c30e495557359b23681a61edbc90cfafafdb7dfe": "Ybodychange",
    "97c2e576c91c2316c2b52bfc948bae9bff8ca49f": "Ybodychange",
    "9832ae0ed8853d29072c9ea7031cd2373e6b16f9": "Yintroduced"
  },
  "changeHistoryDetails": {
    "c84e6beada4e604175f7f138c9878a29665a8c47": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14999. Avoid Potential Infinite Loop in DFSNetworkTopology. Contributed by Ayush Saxena.\n",
      "commitDate": "18/05/20 9:54 AM",
      "commitName": "c84e6beada4e604175f7f138c9878a29665a8c47",
      "commitAuthor": "Ayush Saxena",
      "commitDateOld": "08/04/20 3:25 AM",
      "commitNameOld": "1189af4746919774035f5d64ccb4d2ce21905aaa",
      "commitAuthorOld": "Ayush Saxena",
      "daysBetweenCommits": 40.27,
      "commitsBetweenForRepo": 144,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,87 +1,80 @@\n   Node chooseRandomWithStorageType(final String scope,\n       String excludedScope, final Collection\u003cNode\u003e excludedNodes,\n       StorageType type) {\n     if (excludedScope !\u003d null) {\n       if (isChildScope(scope, excludedScope)) {\n         return null;\n       }\n       if (!isChildScope(excludedScope, scope)) {\n         excludedScope \u003d null;\n       }\n     }\n     Node node \u003d getNode(scope);\n     if (node \u003d\u003d null) {\n       LOG.debug(\"Invalid scope {}, non-existing node\", scope);\n       return null;\n     }\n     if (!(node instanceof DFSTopologyNodeImpl)) {\n       // a node is either DFSTopologyNodeImpl, or a DatanodeDescriptor\n       // if a node is DatanodeDescriptor and excludedNodes contains it,\n       // return null;\n       if (excludedNodes !\u003d null \u0026\u0026 excludedNodes.contains(node)) {\n         LOG.debug(\"{} in excludedNodes\", node);\n         return null;\n       }\n       return ((DatanodeDescriptor) node).hasStorageType(type) ? node : null;\n     }\n     DFSTopologyNodeImpl root \u003d (DFSTopologyNodeImpl)node;\n     Node excludeRoot \u003d excludedScope \u003d\u003d null ? null : getNode(excludedScope);\n \n     // check to see if there are nodes satisfying the condition at all\n     int availableCount \u003d root.getSubtreeStorageCount(type);\n     if (excludeRoot !\u003d null \u0026\u0026 root.isAncestor(excludeRoot)) {\n       if (excludeRoot instanceof DFSTopologyNodeImpl) {\n         availableCount -\u003d ((DFSTopologyNodeImpl)excludeRoot)\n             .getSubtreeStorageCount(type);\n       } else {\n         availableCount -\u003d ((DatanodeDescriptor)excludeRoot)\n             .hasStorageType(type) ? 1 : 0;\n       }\n     }\n     if (excludedNodes !\u003d null) {\n       for (Node excludedNode : excludedNodes) {\n         if (excludeRoot !\u003d null \u0026\u0026 isNodeInScope(excludedNode, excludedScope)) {\n           continue;\n         }\n         if (excludedNode instanceof DatanodeDescriptor) {\n           availableCount -\u003d ((DatanodeDescriptor) excludedNode)\n               .hasStorageType(type) ? 1 : 0;\n         } else if (excludedNode instanceof DFSTopologyNodeImpl) {\n           availableCount -\u003d ((DFSTopologyNodeImpl) excludedNode)\n               .getSubtreeStorageCount(type);\n         } else if (excludedNode instanceof DatanodeInfo) {\n           // find out the corresponding DatanodeDescriptor object, beacuse\n           // we need to get its storage type info.\n           // could be expensive operation, fortunately the size of excluded\n           // nodes set is supposed to be very small.\n           String nodeLocation \u003d excludedNode.getNetworkLocation()\n               + \"/\" + excludedNode.getName();\n           DatanodeDescriptor dn \u003d (DatanodeDescriptor)getNode(nodeLocation);\n           if (dn \u003d\u003d null) {\n             continue;\n           }\n           availableCount -\u003d dn.hasStorageType(type)? 1 : 0;\n         } else {\n           LOG.error(\"Unexpected node type: {}.\", excludedNode.getClass());\n         }\n       }\n     }\n     if (availableCount \u003c\u003d 0) {\n       // should never be \u003c0 in general, adding \u003c0 check for safety purpose\n       return null;\n     }\n     // to this point, it is guaranteed that there is at least one node\n-    // that satisfies the requirement, keep trying until we found one.\n-    Node chosen;\n-    do {\n-      chosen \u003d chooseRandomWithStorageTypeAndExcludeRoot(root, excludeRoot,\n-          type);\n-      if (excludedNodes \u003d\u003d null || !excludedNodes.contains(chosen)) {\n-        break;\n-      } else {\n-        LOG.debug(\"Node {} is excluded, continuing.\", chosen);\n-      }\n-    } while (true);\n+    // that satisfies the requirement.\n+    Node chosen \u003d\n+        chooseRandomWithStorageTypeAndExcludeRoot(root, excludeRoot, type,\n+            excludedNodes);\n     LOG.debug(\"chooseRandom returning {}\", chosen);\n     return chosen;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  Node chooseRandomWithStorageType(final String scope,\n      String excludedScope, final Collection\u003cNode\u003e excludedNodes,\n      StorageType type) {\n    if (excludedScope !\u003d null) {\n      if (isChildScope(scope, excludedScope)) {\n        return null;\n      }\n      if (!isChildScope(excludedScope, scope)) {\n        excludedScope \u003d null;\n      }\n    }\n    Node node \u003d getNode(scope);\n    if (node \u003d\u003d null) {\n      LOG.debug(\"Invalid scope {}, non-existing node\", scope);\n      return null;\n    }\n    if (!(node instanceof DFSTopologyNodeImpl)) {\n      // a node is either DFSTopologyNodeImpl, or a DatanodeDescriptor\n      // if a node is DatanodeDescriptor and excludedNodes contains it,\n      // return null;\n      if (excludedNodes !\u003d null \u0026\u0026 excludedNodes.contains(node)) {\n        LOG.debug(\"{} in excludedNodes\", node);\n        return null;\n      }\n      return ((DatanodeDescriptor) node).hasStorageType(type) ? node : null;\n    }\n    DFSTopologyNodeImpl root \u003d (DFSTopologyNodeImpl)node;\n    Node excludeRoot \u003d excludedScope \u003d\u003d null ? null : getNode(excludedScope);\n\n    // check to see if there are nodes satisfying the condition at all\n    int availableCount \u003d root.getSubtreeStorageCount(type);\n    if (excludeRoot !\u003d null \u0026\u0026 root.isAncestor(excludeRoot)) {\n      if (excludeRoot instanceof DFSTopologyNodeImpl) {\n        availableCount -\u003d ((DFSTopologyNodeImpl)excludeRoot)\n            .getSubtreeStorageCount(type);\n      } else {\n        availableCount -\u003d ((DatanodeDescriptor)excludeRoot)\n            .hasStorageType(type) ? 1 : 0;\n      }\n    }\n    if (excludedNodes !\u003d null) {\n      for (Node excludedNode : excludedNodes) {\n        if (excludeRoot !\u003d null \u0026\u0026 isNodeInScope(excludedNode, excludedScope)) {\n          continue;\n        }\n        if (excludedNode instanceof DatanodeDescriptor) {\n          availableCount -\u003d ((DatanodeDescriptor) excludedNode)\n              .hasStorageType(type) ? 1 : 0;\n        } else if (excludedNode instanceof DFSTopologyNodeImpl) {\n          availableCount -\u003d ((DFSTopologyNodeImpl) excludedNode)\n              .getSubtreeStorageCount(type);\n        } else if (excludedNode instanceof DatanodeInfo) {\n          // find out the corresponding DatanodeDescriptor object, beacuse\n          // we need to get its storage type info.\n          // could be expensive operation, fortunately the size of excluded\n          // nodes set is supposed to be very small.\n          String nodeLocation \u003d excludedNode.getNetworkLocation()\n              + \"/\" + excludedNode.getName();\n          DatanodeDescriptor dn \u003d (DatanodeDescriptor)getNode(nodeLocation);\n          if (dn \u003d\u003d null) {\n            continue;\n          }\n          availableCount -\u003d dn.hasStorageType(type)? 1 : 0;\n        } else {\n          LOG.error(\"Unexpected node type: {}.\", excludedNode.getClass());\n        }\n      }\n    }\n    if (availableCount \u003c\u003d 0) {\n      // should never be \u003c0 in general, adding \u003c0 check for safety purpose\n      return null;\n    }\n    // to this point, it is guaranteed that there is at least one node\n    // that satisfies the requirement.\n    Node chosen \u003d\n        chooseRandomWithStorageTypeAndExcludeRoot(root, excludeRoot, type,\n            excludedNodes);\n    LOG.debug(\"chooseRandom returning {}\", chosen);\n    return chosen;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/net/DFSNetworkTopology.java",
      "extendedDetails": {}
    },
    "1189af4746919774035f5d64ccb4d2ce21905aaa": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-15263. Fix the logic of scope and excluded scope in Network Topology. Contributed by Ayush Saxena.\n",
      "commitDate": "08/04/20 3:25 AM",
      "commitName": "1189af4746919774035f5d64ccb4d2ce21905aaa",
      "commitAuthor": "Ayush Saxena",
      "commitDateOld": "04/11/19 7:53 PM",
      "commitNameOld": "b643a1cbe8a82ca331ffcd14fccc1dc0d90da5c7",
      "commitAuthorOld": "Ayush Saxena",
      "daysBetweenCommits": 155.27,
      "commitsBetweenForRepo": 532,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,87 +1,87 @@\n   Node chooseRandomWithStorageType(final String scope,\n       String excludedScope, final Collection\u003cNode\u003e excludedNodes,\n       StorageType type) {\n     if (excludedScope !\u003d null) {\n-      if (scope.startsWith(excludedScope)) {\n+      if (isChildScope(scope, excludedScope)) {\n         return null;\n       }\n-      if (!excludedScope.startsWith(scope)) {\n+      if (!isChildScope(excludedScope, scope)) {\n         excludedScope \u003d null;\n       }\n     }\n     Node node \u003d getNode(scope);\n     if (node \u003d\u003d null) {\n       LOG.debug(\"Invalid scope {}, non-existing node\", scope);\n       return null;\n     }\n     if (!(node instanceof DFSTopologyNodeImpl)) {\n       // a node is either DFSTopologyNodeImpl, or a DatanodeDescriptor\n       // if a node is DatanodeDescriptor and excludedNodes contains it,\n       // return null;\n       if (excludedNodes !\u003d null \u0026\u0026 excludedNodes.contains(node)) {\n         LOG.debug(\"{} in excludedNodes\", node);\n         return null;\n       }\n       return ((DatanodeDescriptor) node).hasStorageType(type) ? node : null;\n     }\n     DFSTopologyNodeImpl root \u003d (DFSTopologyNodeImpl)node;\n     Node excludeRoot \u003d excludedScope \u003d\u003d null ? null : getNode(excludedScope);\n \n     // check to see if there are nodes satisfying the condition at all\n     int availableCount \u003d root.getSubtreeStorageCount(type);\n     if (excludeRoot !\u003d null \u0026\u0026 root.isAncestor(excludeRoot)) {\n       if (excludeRoot instanceof DFSTopologyNodeImpl) {\n         availableCount -\u003d ((DFSTopologyNodeImpl)excludeRoot)\n             .getSubtreeStorageCount(type);\n       } else {\n         availableCount -\u003d ((DatanodeDescriptor)excludeRoot)\n             .hasStorageType(type) ? 1 : 0;\n       }\n     }\n     if (excludedNodes !\u003d null) {\n       for (Node excludedNode : excludedNodes) {\n         if (excludeRoot !\u003d null \u0026\u0026 isNodeInScope(excludedNode, excludedScope)) {\n           continue;\n         }\n         if (excludedNode instanceof DatanodeDescriptor) {\n           availableCount -\u003d ((DatanodeDescriptor) excludedNode)\n               .hasStorageType(type) ? 1 : 0;\n         } else if (excludedNode instanceof DFSTopologyNodeImpl) {\n           availableCount -\u003d ((DFSTopologyNodeImpl) excludedNode)\n               .getSubtreeStorageCount(type);\n         } else if (excludedNode instanceof DatanodeInfo) {\n           // find out the corresponding DatanodeDescriptor object, beacuse\n           // we need to get its storage type info.\n           // could be expensive operation, fortunately the size of excluded\n           // nodes set is supposed to be very small.\n           String nodeLocation \u003d excludedNode.getNetworkLocation()\n               + \"/\" + excludedNode.getName();\n           DatanodeDescriptor dn \u003d (DatanodeDescriptor)getNode(nodeLocation);\n           if (dn \u003d\u003d null) {\n             continue;\n           }\n           availableCount -\u003d dn.hasStorageType(type)? 1 : 0;\n         } else {\n           LOG.error(\"Unexpected node type: {}.\", excludedNode.getClass());\n         }\n       }\n     }\n     if (availableCount \u003c\u003d 0) {\n       // should never be \u003c0 in general, adding \u003c0 check for safety purpose\n       return null;\n     }\n     // to this point, it is guaranteed that there is at least one node\n     // that satisfies the requirement, keep trying until we found one.\n     Node chosen;\n     do {\n       chosen \u003d chooseRandomWithStorageTypeAndExcludeRoot(root, excludeRoot,\n           type);\n       if (excludedNodes \u003d\u003d null || !excludedNodes.contains(chosen)) {\n         break;\n       } else {\n         LOG.debug(\"Node {} is excluded, continuing.\", chosen);\n       }\n     } while (true);\n     LOG.debug(\"chooseRandom returning {}\", chosen);\n     return chosen;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  Node chooseRandomWithStorageType(final String scope,\n      String excludedScope, final Collection\u003cNode\u003e excludedNodes,\n      StorageType type) {\n    if (excludedScope !\u003d null) {\n      if (isChildScope(scope, excludedScope)) {\n        return null;\n      }\n      if (!isChildScope(excludedScope, scope)) {\n        excludedScope \u003d null;\n      }\n    }\n    Node node \u003d getNode(scope);\n    if (node \u003d\u003d null) {\n      LOG.debug(\"Invalid scope {}, non-existing node\", scope);\n      return null;\n    }\n    if (!(node instanceof DFSTopologyNodeImpl)) {\n      // a node is either DFSTopologyNodeImpl, or a DatanodeDescriptor\n      // if a node is DatanodeDescriptor and excludedNodes contains it,\n      // return null;\n      if (excludedNodes !\u003d null \u0026\u0026 excludedNodes.contains(node)) {\n        LOG.debug(\"{} in excludedNodes\", node);\n        return null;\n      }\n      return ((DatanodeDescriptor) node).hasStorageType(type) ? node : null;\n    }\n    DFSTopologyNodeImpl root \u003d (DFSTopologyNodeImpl)node;\n    Node excludeRoot \u003d excludedScope \u003d\u003d null ? null : getNode(excludedScope);\n\n    // check to see if there are nodes satisfying the condition at all\n    int availableCount \u003d root.getSubtreeStorageCount(type);\n    if (excludeRoot !\u003d null \u0026\u0026 root.isAncestor(excludeRoot)) {\n      if (excludeRoot instanceof DFSTopologyNodeImpl) {\n        availableCount -\u003d ((DFSTopologyNodeImpl)excludeRoot)\n            .getSubtreeStorageCount(type);\n      } else {\n        availableCount -\u003d ((DatanodeDescriptor)excludeRoot)\n            .hasStorageType(type) ? 1 : 0;\n      }\n    }\n    if (excludedNodes !\u003d null) {\n      for (Node excludedNode : excludedNodes) {\n        if (excludeRoot !\u003d null \u0026\u0026 isNodeInScope(excludedNode, excludedScope)) {\n          continue;\n        }\n        if (excludedNode instanceof DatanodeDescriptor) {\n          availableCount -\u003d ((DatanodeDescriptor) excludedNode)\n              .hasStorageType(type) ? 1 : 0;\n        } else if (excludedNode instanceof DFSTopologyNodeImpl) {\n          availableCount -\u003d ((DFSTopologyNodeImpl) excludedNode)\n              .getSubtreeStorageCount(type);\n        } else if (excludedNode instanceof DatanodeInfo) {\n          // find out the corresponding DatanodeDescriptor object, beacuse\n          // we need to get its storage type info.\n          // could be expensive operation, fortunately the size of excluded\n          // nodes set is supposed to be very small.\n          String nodeLocation \u003d excludedNode.getNetworkLocation()\n              + \"/\" + excludedNode.getName();\n          DatanodeDescriptor dn \u003d (DatanodeDescriptor)getNode(nodeLocation);\n          if (dn \u003d\u003d null) {\n            continue;\n          }\n          availableCount -\u003d dn.hasStorageType(type)? 1 : 0;\n        } else {\n          LOG.error(\"Unexpected node type: {}.\", excludedNode.getClass());\n        }\n      }\n    }\n    if (availableCount \u003c\u003d 0) {\n      // should never be \u003c0 in general, adding \u003c0 check for safety purpose\n      return null;\n    }\n    // to this point, it is guaranteed that there is at least one node\n    // that satisfies the requirement, keep trying until we found one.\n    Node chosen;\n    do {\n      chosen \u003d chooseRandomWithStorageTypeAndExcludeRoot(root, excludeRoot,\n          type);\n      if (excludedNodes \u003d\u003d null || !excludedNodes.contains(chosen)) {\n        break;\n      } else {\n        LOG.debug(\"Node {} is excluded, continuing.\", chosen);\n      }\n    } while (true);\n    LOG.debug(\"chooseRandom returning {}\", chosen);\n    return chosen;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/net/DFSNetworkTopology.java",
      "extendedDetails": {}
    },
    "b643a1cbe8a82ca331ffcd14fccc1dc0d90da5c7": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14938. Add check if excludedNodes contain scope in DFSNetworkTopology#chooseRandomWithStorageType(). Contributed by Lisheng Sun.\n",
      "commitDate": "04/11/19 7:53 PM",
      "commitName": "b643a1cbe8a82ca331ffcd14fccc1dc0d90da5c7",
      "commitAuthor": "Ayush Saxena",
      "commitDateOld": "29/10/19 12:00 AM",
      "commitNameOld": "fa4904cdcaaa294149a1c92465c71359407de93f",
      "commitAuthorOld": "Ayush Saxena",
      "daysBetweenCommits": 6.87,
      "commitsBetweenForRepo": 25,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,81 +1,87 @@\n   Node chooseRandomWithStorageType(final String scope,\n       String excludedScope, final Collection\u003cNode\u003e excludedNodes,\n       StorageType type) {\n     if (excludedScope !\u003d null) {\n       if (scope.startsWith(excludedScope)) {\n         return null;\n       }\n       if (!excludedScope.startsWith(scope)) {\n         excludedScope \u003d null;\n       }\n     }\n     Node node \u003d getNode(scope);\n     if (node \u003d\u003d null) {\n       LOG.debug(\"Invalid scope {}, non-existing node\", scope);\n       return null;\n     }\n     if (!(node instanceof DFSTopologyNodeImpl)) {\n       // a node is either DFSTopologyNodeImpl, or a DatanodeDescriptor\n-      return ((DatanodeDescriptor)node).hasStorageType(type) ? node : null;\n+      // if a node is DatanodeDescriptor and excludedNodes contains it,\n+      // return null;\n+      if (excludedNodes !\u003d null \u0026\u0026 excludedNodes.contains(node)) {\n+        LOG.debug(\"{} in excludedNodes\", node);\n+        return null;\n+      }\n+      return ((DatanodeDescriptor) node).hasStorageType(type) ? node : null;\n     }\n     DFSTopologyNodeImpl root \u003d (DFSTopologyNodeImpl)node;\n     Node excludeRoot \u003d excludedScope \u003d\u003d null ? null : getNode(excludedScope);\n \n     // check to see if there are nodes satisfying the condition at all\n     int availableCount \u003d root.getSubtreeStorageCount(type);\n     if (excludeRoot !\u003d null \u0026\u0026 root.isAncestor(excludeRoot)) {\n       if (excludeRoot instanceof DFSTopologyNodeImpl) {\n         availableCount -\u003d ((DFSTopologyNodeImpl)excludeRoot)\n             .getSubtreeStorageCount(type);\n       } else {\n         availableCount -\u003d ((DatanodeDescriptor)excludeRoot)\n             .hasStorageType(type) ? 1 : 0;\n       }\n     }\n     if (excludedNodes !\u003d null) {\n       for (Node excludedNode : excludedNodes) {\n         if (excludeRoot !\u003d null \u0026\u0026 isNodeInScope(excludedNode, excludedScope)) {\n           continue;\n         }\n         if (excludedNode instanceof DatanodeDescriptor) {\n           availableCount -\u003d ((DatanodeDescriptor) excludedNode)\n               .hasStorageType(type) ? 1 : 0;\n         } else if (excludedNode instanceof DFSTopologyNodeImpl) {\n           availableCount -\u003d ((DFSTopologyNodeImpl) excludedNode)\n               .getSubtreeStorageCount(type);\n         } else if (excludedNode instanceof DatanodeInfo) {\n           // find out the corresponding DatanodeDescriptor object, beacuse\n           // we need to get its storage type info.\n           // could be expensive operation, fortunately the size of excluded\n           // nodes set is supposed to be very small.\n           String nodeLocation \u003d excludedNode.getNetworkLocation()\n               + \"/\" + excludedNode.getName();\n           DatanodeDescriptor dn \u003d (DatanodeDescriptor)getNode(nodeLocation);\n           if (dn \u003d\u003d null) {\n             continue;\n           }\n           availableCount -\u003d dn.hasStorageType(type)? 1 : 0;\n         } else {\n           LOG.error(\"Unexpected node type: {}.\", excludedNode.getClass());\n         }\n       }\n     }\n     if (availableCount \u003c\u003d 0) {\n       // should never be \u003c0 in general, adding \u003c0 check for safety purpose\n       return null;\n     }\n     // to this point, it is guaranteed that there is at least one node\n     // that satisfies the requirement, keep trying until we found one.\n     Node chosen;\n     do {\n       chosen \u003d chooseRandomWithStorageTypeAndExcludeRoot(root, excludeRoot,\n           type);\n       if (excludedNodes \u003d\u003d null || !excludedNodes.contains(chosen)) {\n         break;\n       } else {\n         LOG.debug(\"Node {} is excluded, continuing.\", chosen);\n       }\n     } while (true);\n     LOG.debug(\"chooseRandom returning {}\", chosen);\n     return chosen;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  Node chooseRandomWithStorageType(final String scope,\n      String excludedScope, final Collection\u003cNode\u003e excludedNodes,\n      StorageType type) {\n    if (excludedScope !\u003d null) {\n      if (scope.startsWith(excludedScope)) {\n        return null;\n      }\n      if (!excludedScope.startsWith(scope)) {\n        excludedScope \u003d null;\n      }\n    }\n    Node node \u003d getNode(scope);\n    if (node \u003d\u003d null) {\n      LOG.debug(\"Invalid scope {}, non-existing node\", scope);\n      return null;\n    }\n    if (!(node instanceof DFSTopologyNodeImpl)) {\n      // a node is either DFSTopologyNodeImpl, or a DatanodeDescriptor\n      // if a node is DatanodeDescriptor and excludedNodes contains it,\n      // return null;\n      if (excludedNodes !\u003d null \u0026\u0026 excludedNodes.contains(node)) {\n        LOG.debug(\"{} in excludedNodes\", node);\n        return null;\n      }\n      return ((DatanodeDescriptor) node).hasStorageType(type) ? node : null;\n    }\n    DFSTopologyNodeImpl root \u003d (DFSTopologyNodeImpl)node;\n    Node excludeRoot \u003d excludedScope \u003d\u003d null ? null : getNode(excludedScope);\n\n    // check to see if there are nodes satisfying the condition at all\n    int availableCount \u003d root.getSubtreeStorageCount(type);\n    if (excludeRoot !\u003d null \u0026\u0026 root.isAncestor(excludeRoot)) {\n      if (excludeRoot instanceof DFSTopologyNodeImpl) {\n        availableCount -\u003d ((DFSTopologyNodeImpl)excludeRoot)\n            .getSubtreeStorageCount(type);\n      } else {\n        availableCount -\u003d ((DatanodeDescriptor)excludeRoot)\n            .hasStorageType(type) ? 1 : 0;\n      }\n    }\n    if (excludedNodes !\u003d null) {\n      for (Node excludedNode : excludedNodes) {\n        if (excludeRoot !\u003d null \u0026\u0026 isNodeInScope(excludedNode, excludedScope)) {\n          continue;\n        }\n        if (excludedNode instanceof DatanodeDescriptor) {\n          availableCount -\u003d ((DatanodeDescriptor) excludedNode)\n              .hasStorageType(type) ? 1 : 0;\n        } else if (excludedNode instanceof DFSTopologyNodeImpl) {\n          availableCount -\u003d ((DFSTopologyNodeImpl) excludedNode)\n              .getSubtreeStorageCount(type);\n        } else if (excludedNode instanceof DatanodeInfo) {\n          // find out the corresponding DatanodeDescriptor object, beacuse\n          // we need to get its storage type info.\n          // could be expensive operation, fortunately the size of excluded\n          // nodes set is supposed to be very small.\n          String nodeLocation \u003d excludedNode.getNetworkLocation()\n              + \"/\" + excludedNode.getName();\n          DatanodeDescriptor dn \u003d (DatanodeDescriptor)getNode(nodeLocation);\n          if (dn \u003d\u003d null) {\n            continue;\n          }\n          availableCount -\u003d dn.hasStorageType(type)? 1 : 0;\n        } else {\n          LOG.error(\"Unexpected node type: {}.\", excludedNode.getClass());\n        }\n      }\n    }\n    if (availableCount \u003c\u003d 0) {\n      // should never be \u003c0 in general, adding \u003c0 check for safety purpose\n      return null;\n    }\n    // to this point, it is guaranteed that there is at least one node\n    // that satisfies the requirement, keep trying until we found one.\n    Node chosen;\n    do {\n      chosen \u003d chooseRandomWithStorageTypeAndExcludeRoot(root, excludeRoot,\n          type);\n      if (excludedNodes \u003d\u003d null || !excludedNodes.contains(chosen)) {\n        break;\n      } else {\n        LOG.debug(\"Node {} is excluded, continuing.\", chosen);\n      }\n    } while (true);\n    LOG.debug(\"chooseRandom returning {}\", chosen);\n    return chosen;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/net/DFSNetworkTopology.java",
      "extendedDetails": {}
    },
    "74c2329fc36e0878555342085defb4e474ef1aad": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14913. Correct the value of available count in DFSNetworkTopology#chooseRandomWithStorageType(). Contributed by Ayush Saxena.\n",
      "commitDate": "21/10/19 6:05 AM",
      "commitName": "74c2329fc36e0878555342085defb4e474ef1aad",
      "commitAuthor": "Ayush Saxena",
      "commitDateOld": "17/10/19 9:58 AM",
      "commitNameOld": "54dc6b7d720851eb6017906d664aa0fda2698225",
      "commitAuthorOld": "Surendra Singh Lilhore",
      "daysBetweenCommits": 3.84,
      "commitsBetweenForRepo": 10,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,82 +1,81 @@\n   Node chooseRandomWithStorageType(final String scope,\n       String excludedScope, final Collection\u003cNode\u003e excludedNodes,\n       StorageType type) {\n     if (excludedScope !\u003d null) {\n       if (scope.startsWith(excludedScope)) {\n         return null;\n       }\n       if (!excludedScope.startsWith(scope)) {\n         excludedScope \u003d null;\n       }\n     }\n     Node node \u003d getNode(scope);\n     if (node \u003d\u003d null) {\n       LOG.debug(\"Invalid scope {}, non-existing node\", scope);\n       return null;\n     }\n     if (!(node instanceof DFSTopologyNodeImpl)) {\n       // a node is either DFSTopologyNodeImpl, or a DatanodeDescriptor\n       return ((DatanodeDescriptor)node).hasStorageType(type) ? node : null;\n     }\n     DFSTopologyNodeImpl root \u003d (DFSTopologyNodeImpl)node;\n     Node excludeRoot \u003d excludedScope \u003d\u003d null ? null : getNode(excludedScope);\n \n     // check to see if there are nodes satisfying the condition at all\n     int availableCount \u003d root.getSubtreeStorageCount(type);\n     if (excludeRoot !\u003d null \u0026\u0026 root.isAncestor(excludeRoot)) {\n       if (excludeRoot instanceof DFSTopologyNodeImpl) {\n         availableCount -\u003d ((DFSTopologyNodeImpl)excludeRoot)\n             .getSubtreeStorageCount(type);\n       } else {\n         availableCount -\u003d ((DatanodeDescriptor)excludeRoot)\n             .hasStorageType(type) ? 1 : 0;\n       }\n     }\n     if (excludedNodes !\u003d null) {\n       for (Node excludedNode : excludedNodes) {\n-        if (excludeRoot !\u003d null\n-            \u0026\u0026 excludedNode.getNetworkLocation().startsWith(excludedScope)) {\n+        if (excludeRoot !\u003d null \u0026\u0026 isNodeInScope(excludedNode, excludedScope)) {\n           continue;\n         }\n         if (excludedNode instanceof DatanodeDescriptor) {\n           availableCount -\u003d ((DatanodeDescriptor) excludedNode)\n               .hasStorageType(type) ? 1 : 0;\n         } else if (excludedNode instanceof DFSTopologyNodeImpl) {\n           availableCount -\u003d ((DFSTopologyNodeImpl) excludedNode)\n               .getSubtreeStorageCount(type);\n         } else if (excludedNode instanceof DatanodeInfo) {\n           // find out the corresponding DatanodeDescriptor object, beacuse\n           // we need to get its storage type info.\n           // could be expensive operation, fortunately the size of excluded\n           // nodes set is supposed to be very small.\n           String nodeLocation \u003d excludedNode.getNetworkLocation()\n               + \"/\" + excludedNode.getName();\n           DatanodeDescriptor dn \u003d (DatanodeDescriptor)getNode(nodeLocation);\n           if (dn \u003d\u003d null) {\n             continue;\n           }\n           availableCount -\u003d dn.hasStorageType(type)? 1 : 0;\n         } else {\n           LOG.error(\"Unexpected node type: {}.\", excludedNode.getClass());\n         }\n       }\n     }\n     if (availableCount \u003c\u003d 0) {\n       // should never be \u003c0 in general, adding \u003c0 check for safety purpose\n       return null;\n     }\n     // to this point, it is guaranteed that there is at least one node\n     // that satisfies the requirement, keep trying until we found one.\n     Node chosen;\n     do {\n       chosen \u003d chooseRandomWithStorageTypeAndExcludeRoot(root, excludeRoot,\n           type);\n       if (excludedNodes \u003d\u003d null || !excludedNodes.contains(chosen)) {\n         break;\n       } else {\n         LOG.debug(\"Node {} is excluded, continuing.\", chosen);\n       }\n     } while (true);\n     LOG.debug(\"chooseRandom returning {}\", chosen);\n     return chosen;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  Node chooseRandomWithStorageType(final String scope,\n      String excludedScope, final Collection\u003cNode\u003e excludedNodes,\n      StorageType type) {\n    if (excludedScope !\u003d null) {\n      if (scope.startsWith(excludedScope)) {\n        return null;\n      }\n      if (!excludedScope.startsWith(scope)) {\n        excludedScope \u003d null;\n      }\n    }\n    Node node \u003d getNode(scope);\n    if (node \u003d\u003d null) {\n      LOG.debug(\"Invalid scope {}, non-existing node\", scope);\n      return null;\n    }\n    if (!(node instanceof DFSTopologyNodeImpl)) {\n      // a node is either DFSTopologyNodeImpl, or a DatanodeDescriptor\n      return ((DatanodeDescriptor)node).hasStorageType(type) ? node : null;\n    }\n    DFSTopologyNodeImpl root \u003d (DFSTopologyNodeImpl)node;\n    Node excludeRoot \u003d excludedScope \u003d\u003d null ? null : getNode(excludedScope);\n\n    // check to see if there are nodes satisfying the condition at all\n    int availableCount \u003d root.getSubtreeStorageCount(type);\n    if (excludeRoot !\u003d null \u0026\u0026 root.isAncestor(excludeRoot)) {\n      if (excludeRoot instanceof DFSTopologyNodeImpl) {\n        availableCount -\u003d ((DFSTopologyNodeImpl)excludeRoot)\n            .getSubtreeStorageCount(type);\n      } else {\n        availableCount -\u003d ((DatanodeDescriptor)excludeRoot)\n            .hasStorageType(type) ? 1 : 0;\n      }\n    }\n    if (excludedNodes !\u003d null) {\n      for (Node excludedNode : excludedNodes) {\n        if (excludeRoot !\u003d null \u0026\u0026 isNodeInScope(excludedNode, excludedScope)) {\n          continue;\n        }\n        if (excludedNode instanceof DatanodeDescriptor) {\n          availableCount -\u003d ((DatanodeDescriptor) excludedNode)\n              .hasStorageType(type) ? 1 : 0;\n        } else if (excludedNode instanceof DFSTopologyNodeImpl) {\n          availableCount -\u003d ((DFSTopologyNodeImpl) excludedNode)\n              .getSubtreeStorageCount(type);\n        } else if (excludedNode instanceof DatanodeInfo) {\n          // find out the corresponding DatanodeDescriptor object, beacuse\n          // we need to get its storage type info.\n          // could be expensive operation, fortunately the size of excluded\n          // nodes set is supposed to be very small.\n          String nodeLocation \u003d excludedNode.getNetworkLocation()\n              + \"/\" + excludedNode.getName();\n          DatanodeDescriptor dn \u003d (DatanodeDescriptor)getNode(nodeLocation);\n          if (dn \u003d\u003d null) {\n            continue;\n          }\n          availableCount -\u003d dn.hasStorageType(type)? 1 : 0;\n        } else {\n          LOG.error(\"Unexpected node type: {}.\", excludedNode.getClass());\n        }\n      }\n    }\n    if (availableCount \u003c\u003d 0) {\n      // should never be \u003c0 in general, adding \u003c0 check for safety purpose\n      return null;\n    }\n    // to this point, it is guaranteed that there is at least one node\n    // that satisfies the requirement, keep trying until we found one.\n    Node chosen;\n    do {\n      chosen \u003d chooseRandomWithStorageTypeAndExcludeRoot(root, excludeRoot,\n          type);\n      if (excludedNodes \u003d\u003d null || !excludedNodes.contains(chosen)) {\n        break;\n      } else {\n        LOG.debug(\"Node {} is excluded, continuing.\", chosen);\n      }\n    } while (true);\n    LOG.debug(\"chooseRandom returning {}\", chosen);\n    return chosen;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/net/DFSNetworkTopology.java",
      "extendedDetails": {}
    },
    "54dc6b7d720851eb6017906d664aa0fda2698225": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14909. DFSNetworkTopology#chooseRandomWithStorageType() should not decrease storage count for excluded node which is already part of excluded scope. Contributed by Surendra Singh Lilhore.\n",
      "commitDate": "17/10/19 9:58 AM",
      "commitName": "54dc6b7d720851eb6017906d664aa0fda2698225",
      "commitAuthor": "Surendra Singh Lilhore",
      "commitDateOld": "23/09/19 8:52 AM",
      "commitNameOld": "c30e495557359b23681a61edbc90cfafafdb7dfe",
      "commitAuthorOld": "Ayush Saxena",
      "daysBetweenCommits": 24.05,
      "commitsBetweenForRepo": 186,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,78 +1,82 @@\n   Node chooseRandomWithStorageType(final String scope,\n       String excludedScope, final Collection\u003cNode\u003e excludedNodes,\n       StorageType type) {\n     if (excludedScope !\u003d null) {\n       if (scope.startsWith(excludedScope)) {\n         return null;\n       }\n       if (!excludedScope.startsWith(scope)) {\n         excludedScope \u003d null;\n       }\n     }\n     Node node \u003d getNode(scope);\n     if (node \u003d\u003d null) {\n       LOG.debug(\"Invalid scope {}, non-existing node\", scope);\n       return null;\n     }\n     if (!(node instanceof DFSTopologyNodeImpl)) {\n       // a node is either DFSTopologyNodeImpl, or a DatanodeDescriptor\n       return ((DatanodeDescriptor)node).hasStorageType(type) ? node : null;\n     }\n     DFSTopologyNodeImpl root \u003d (DFSTopologyNodeImpl)node;\n     Node excludeRoot \u003d excludedScope \u003d\u003d null ? null : getNode(excludedScope);\n \n     // check to see if there are nodes satisfying the condition at all\n     int availableCount \u003d root.getSubtreeStorageCount(type);\n     if (excludeRoot !\u003d null \u0026\u0026 root.isAncestor(excludeRoot)) {\n       if (excludeRoot instanceof DFSTopologyNodeImpl) {\n         availableCount -\u003d ((DFSTopologyNodeImpl)excludeRoot)\n             .getSubtreeStorageCount(type);\n       } else {\n         availableCount -\u003d ((DatanodeDescriptor)excludeRoot)\n             .hasStorageType(type) ? 1 : 0;\n       }\n     }\n     if (excludedNodes !\u003d null) {\n       for (Node excludedNode : excludedNodes) {\n+        if (excludeRoot !\u003d null\n+            \u0026\u0026 excludedNode.getNetworkLocation().startsWith(excludedScope)) {\n+          continue;\n+        }\n         if (excludedNode instanceof DatanodeDescriptor) {\n           availableCount -\u003d ((DatanodeDescriptor) excludedNode)\n               .hasStorageType(type) ? 1 : 0;\n         } else if (excludedNode instanceof DFSTopologyNodeImpl) {\n           availableCount -\u003d ((DFSTopologyNodeImpl) excludedNode)\n               .getSubtreeStorageCount(type);\n         } else if (excludedNode instanceof DatanodeInfo) {\n           // find out the corresponding DatanodeDescriptor object, beacuse\n           // we need to get its storage type info.\n           // could be expensive operation, fortunately the size of excluded\n           // nodes set is supposed to be very small.\n           String nodeLocation \u003d excludedNode.getNetworkLocation()\n               + \"/\" + excludedNode.getName();\n           DatanodeDescriptor dn \u003d (DatanodeDescriptor)getNode(nodeLocation);\n           if (dn \u003d\u003d null) {\n             continue;\n           }\n           availableCount -\u003d dn.hasStorageType(type)? 1 : 0;\n         } else {\n           LOG.error(\"Unexpected node type: {}.\", excludedNode.getClass());\n         }\n       }\n     }\n     if (availableCount \u003c\u003d 0) {\n       // should never be \u003c0 in general, adding \u003c0 check for safety purpose\n       return null;\n     }\n     // to this point, it is guaranteed that there is at least one node\n     // that satisfies the requirement, keep trying until we found one.\n     Node chosen;\n     do {\n       chosen \u003d chooseRandomWithStorageTypeAndExcludeRoot(root, excludeRoot,\n           type);\n       if (excludedNodes \u003d\u003d null || !excludedNodes.contains(chosen)) {\n         break;\n       } else {\n         LOG.debug(\"Node {} is excluded, continuing.\", chosen);\n       }\n     } while (true);\n     LOG.debug(\"chooseRandom returning {}\", chosen);\n     return chosen;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  Node chooseRandomWithStorageType(final String scope,\n      String excludedScope, final Collection\u003cNode\u003e excludedNodes,\n      StorageType type) {\n    if (excludedScope !\u003d null) {\n      if (scope.startsWith(excludedScope)) {\n        return null;\n      }\n      if (!excludedScope.startsWith(scope)) {\n        excludedScope \u003d null;\n      }\n    }\n    Node node \u003d getNode(scope);\n    if (node \u003d\u003d null) {\n      LOG.debug(\"Invalid scope {}, non-existing node\", scope);\n      return null;\n    }\n    if (!(node instanceof DFSTopologyNodeImpl)) {\n      // a node is either DFSTopologyNodeImpl, or a DatanodeDescriptor\n      return ((DatanodeDescriptor)node).hasStorageType(type) ? node : null;\n    }\n    DFSTopologyNodeImpl root \u003d (DFSTopologyNodeImpl)node;\n    Node excludeRoot \u003d excludedScope \u003d\u003d null ? null : getNode(excludedScope);\n\n    // check to see if there are nodes satisfying the condition at all\n    int availableCount \u003d root.getSubtreeStorageCount(type);\n    if (excludeRoot !\u003d null \u0026\u0026 root.isAncestor(excludeRoot)) {\n      if (excludeRoot instanceof DFSTopologyNodeImpl) {\n        availableCount -\u003d ((DFSTopologyNodeImpl)excludeRoot)\n            .getSubtreeStorageCount(type);\n      } else {\n        availableCount -\u003d ((DatanodeDescriptor)excludeRoot)\n            .hasStorageType(type) ? 1 : 0;\n      }\n    }\n    if (excludedNodes !\u003d null) {\n      for (Node excludedNode : excludedNodes) {\n        if (excludeRoot !\u003d null\n            \u0026\u0026 excludedNode.getNetworkLocation().startsWith(excludedScope)) {\n          continue;\n        }\n        if (excludedNode instanceof DatanodeDescriptor) {\n          availableCount -\u003d ((DatanodeDescriptor) excludedNode)\n              .hasStorageType(type) ? 1 : 0;\n        } else if (excludedNode instanceof DFSTopologyNodeImpl) {\n          availableCount -\u003d ((DFSTopologyNodeImpl) excludedNode)\n              .getSubtreeStorageCount(type);\n        } else if (excludedNode instanceof DatanodeInfo) {\n          // find out the corresponding DatanodeDescriptor object, beacuse\n          // we need to get its storage type info.\n          // could be expensive operation, fortunately the size of excluded\n          // nodes set is supposed to be very small.\n          String nodeLocation \u003d excludedNode.getNetworkLocation()\n              + \"/\" + excludedNode.getName();\n          DatanodeDescriptor dn \u003d (DatanodeDescriptor)getNode(nodeLocation);\n          if (dn \u003d\u003d null) {\n            continue;\n          }\n          availableCount -\u003d dn.hasStorageType(type)? 1 : 0;\n        } else {\n          LOG.error(\"Unexpected node type: {}.\", excludedNode.getClass());\n        }\n      }\n    }\n    if (availableCount \u003c\u003d 0) {\n      // should never be \u003c0 in general, adding \u003c0 check for safety purpose\n      return null;\n    }\n    // to this point, it is guaranteed that there is at least one node\n    // that satisfies the requirement, keep trying until we found one.\n    Node chosen;\n    do {\n      chosen \u003d chooseRandomWithStorageTypeAndExcludeRoot(root, excludeRoot,\n          type);\n      if (excludedNodes \u003d\u003d null || !excludedNodes.contains(chosen)) {\n        break;\n      } else {\n        LOG.debug(\"Node {} is excluded, continuing.\", chosen);\n      }\n    } while (true);\n    LOG.debug(\"chooseRandom returning {}\", chosen);\n    return chosen;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/net/DFSNetworkTopology.java",
      "extendedDetails": {}
    },
    "c30e495557359b23681a61edbc90cfafafdb7dfe": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14853. NPE in DFSNetworkTopology#chooseRandomWithStorageType() when the excludedNode is not present. Contributed by Ranith Sardar.\n",
      "commitDate": "23/09/19 8:52 AM",
      "commitName": "c30e495557359b23681a61edbc90cfafafdb7dfe",
      "commitAuthor": "Ayush Saxena",
      "commitDateOld": "13/04/18 2:55 AM",
      "commitNameOld": "0725953efec89b35b7586b846abb01f7c5963b37",
      "commitAuthorOld": "Yiqun Lin",
      "daysBetweenCommits": 528.25,
      "commitsBetweenForRepo": 4579,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,75 +1,78 @@\n   Node chooseRandomWithStorageType(final String scope,\n       String excludedScope, final Collection\u003cNode\u003e excludedNodes,\n       StorageType type) {\n     if (excludedScope !\u003d null) {\n       if (scope.startsWith(excludedScope)) {\n         return null;\n       }\n       if (!excludedScope.startsWith(scope)) {\n         excludedScope \u003d null;\n       }\n     }\n     Node node \u003d getNode(scope);\n     if (node \u003d\u003d null) {\n       LOG.debug(\"Invalid scope {}, non-existing node\", scope);\n       return null;\n     }\n     if (!(node instanceof DFSTopologyNodeImpl)) {\n       // a node is either DFSTopologyNodeImpl, or a DatanodeDescriptor\n       return ((DatanodeDescriptor)node).hasStorageType(type) ? node : null;\n     }\n     DFSTopologyNodeImpl root \u003d (DFSTopologyNodeImpl)node;\n     Node excludeRoot \u003d excludedScope \u003d\u003d null ? null : getNode(excludedScope);\n \n     // check to see if there are nodes satisfying the condition at all\n     int availableCount \u003d root.getSubtreeStorageCount(type);\n     if (excludeRoot !\u003d null \u0026\u0026 root.isAncestor(excludeRoot)) {\n       if (excludeRoot instanceof DFSTopologyNodeImpl) {\n         availableCount -\u003d ((DFSTopologyNodeImpl)excludeRoot)\n             .getSubtreeStorageCount(type);\n       } else {\n         availableCount -\u003d ((DatanodeDescriptor)excludeRoot)\n             .hasStorageType(type) ? 1 : 0;\n       }\n     }\n     if (excludedNodes !\u003d null) {\n       for (Node excludedNode : excludedNodes) {\n         if (excludedNode instanceof DatanodeDescriptor) {\n           availableCount -\u003d ((DatanodeDescriptor) excludedNode)\n               .hasStorageType(type) ? 1 : 0;\n         } else if (excludedNode instanceof DFSTopologyNodeImpl) {\n           availableCount -\u003d ((DFSTopologyNodeImpl) excludedNode)\n               .getSubtreeStorageCount(type);\n         } else if (excludedNode instanceof DatanodeInfo) {\n           // find out the corresponding DatanodeDescriptor object, beacuse\n           // we need to get its storage type info.\n           // could be expensive operation, fortunately the size of excluded\n           // nodes set is supposed to be very small.\n           String nodeLocation \u003d excludedNode.getNetworkLocation()\n               + \"/\" + excludedNode.getName();\n           DatanodeDescriptor dn \u003d (DatanodeDescriptor)getNode(nodeLocation);\n+          if (dn \u003d\u003d null) {\n+            continue;\n+          }\n           availableCount -\u003d dn.hasStorageType(type)? 1 : 0;\n         } else {\n           LOG.error(\"Unexpected node type: {}.\", excludedNode.getClass());\n         }\n       }\n     }\n     if (availableCount \u003c\u003d 0) {\n       // should never be \u003c0 in general, adding \u003c0 check for safety purpose\n       return null;\n     }\n     // to this point, it is guaranteed that there is at least one node\n     // that satisfies the requirement, keep trying until we found one.\n     Node chosen;\n     do {\n       chosen \u003d chooseRandomWithStorageTypeAndExcludeRoot(root, excludeRoot,\n           type);\n       if (excludedNodes \u003d\u003d null || !excludedNodes.contains(chosen)) {\n         break;\n       } else {\n         LOG.debug(\"Node {} is excluded, continuing.\", chosen);\n       }\n     } while (true);\n     LOG.debug(\"chooseRandom returning {}\", chosen);\n     return chosen;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  Node chooseRandomWithStorageType(final String scope,\n      String excludedScope, final Collection\u003cNode\u003e excludedNodes,\n      StorageType type) {\n    if (excludedScope !\u003d null) {\n      if (scope.startsWith(excludedScope)) {\n        return null;\n      }\n      if (!excludedScope.startsWith(scope)) {\n        excludedScope \u003d null;\n      }\n    }\n    Node node \u003d getNode(scope);\n    if (node \u003d\u003d null) {\n      LOG.debug(\"Invalid scope {}, non-existing node\", scope);\n      return null;\n    }\n    if (!(node instanceof DFSTopologyNodeImpl)) {\n      // a node is either DFSTopologyNodeImpl, or a DatanodeDescriptor\n      return ((DatanodeDescriptor)node).hasStorageType(type) ? node : null;\n    }\n    DFSTopologyNodeImpl root \u003d (DFSTopologyNodeImpl)node;\n    Node excludeRoot \u003d excludedScope \u003d\u003d null ? null : getNode(excludedScope);\n\n    // check to see if there are nodes satisfying the condition at all\n    int availableCount \u003d root.getSubtreeStorageCount(type);\n    if (excludeRoot !\u003d null \u0026\u0026 root.isAncestor(excludeRoot)) {\n      if (excludeRoot instanceof DFSTopologyNodeImpl) {\n        availableCount -\u003d ((DFSTopologyNodeImpl)excludeRoot)\n            .getSubtreeStorageCount(type);\n      } else {\n        availableCount -\u003d ((DatanodeDescriptor)excludeRoot)\n            .hasStorageType(type) ? 1 : 0;\n      }\n    }\n    if (excludedNodes !\u003d null) {\n      for (Node excludedNode : excludedNodes) {\n        if (excludedNode instanceof DatanodeDescriptor) {\n          availableCount -\u003d ((DatanodeDescriptor) excludedNode)\n              .hasStorageType(type) ? 1 : 0;\n        } else if (excludedNode instanceof DFSTopologyNodeImpl) {\n          availableCount -\u003d ((DFSTopologyNodeImpl) excludedNode)\n              .getSubtreeStorageCount(type);\n        } else if (excludedNode instanceof DatanodeInfo) {\n          // find out the corresponding DatanodeDescriptor object, beacuse\n          // we need to get its storage type info.\n          // could be expensive operation, fortunately the size of excluded\n          // nodes set is supposed to be very small.\n          String nodeLocation \u003d excludedNode.getNetworkLocation()\n              + \"/\" + excludedNode.getName();\n          DatanodeDescriptor dn \u003d (DatanodeDescriptor)getNode(nodeLocation);\n          if (dn \u003d\u003d null) {\n            continue;\n          }\n          availableCount -\u003d dn.hasStorageType(type)? 1 : 0;\n        } else {\n          LOG.error(\"Unexpected node type: {}.\", excludedNode.getClass());\n        }\n      }\n    }\n    if (availableCount \u003c\u003d 0) {\n      // should never be \u003c0 in general, adding \u003c0 check for safety purpose\n      return null;\n    }\n    // to this point, it is guaranteed that there is at least one node\n    // that satisfies the requirement, keep trying until we found one.\n    Node chosen;\n    do {\n      chosen \u003d chooseRandomWithStorageTypeAndExcludeRoot(root, excludeRoot,\n          type);\n      if (excludedNodes \u003d\u003d null || !excludedNodes.contains(chosen)) {\n        break;\n      } else {\n        LOG.debug(\"Node {} is excluded, continuing.\", chosen);\n      }\n    } while (true);\n    LOG.debug(\"chooseRandom returning {}\", chosen);\n    return chosen;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/net/DFSNetworkTopology.java",
      "extendedDetails": {}
    },
    "97c2e576c91c2316c2b52bfc948bae9bff8ca49f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11530. Use HDFS specific network topology to choose datanode in BlockPlacementPolicyDefault. Contributed by Yiqun Lin and Chen Liang.\n",
      "commitDate": "04/05/17 8:54 PM",
      "commitName": "97c2e576c91c2316c2b52bfc948bae9bff8ca49f",
      "commitAuthor": "Yiqun Lin",
      "commitDateOld": "28/03/17 8:02 AM",
      "commitNameOld": "6b0933643835d7696ced011cfdb8b74f63022e8b",
      "commitAuthorOld": "Yiqun Lin",
      "daysBetweenCommits": 37.54,
      "commitsBetweenForRepo": 220,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,61 +1,75 @@\n   Node chooseRandomWithStorageType(final String scope,\n       String excludedScope, final Collection\u003cNode\u003e excludedNodes,\n       StorageType type) {\n     if (excludedScope !\u003d null) {\n       if (scope.startsWith(excludedScope)) {\n         return null;\n       }\n       if (!excludedScope.startsWith(scope)) {\n         excludedScope \u003d null;\n       }\n     }\n     Node node \u003d getNode(scope);\n     if (node \u003d\u003d null) {\n       LOG.debug(\"Invalid scope {}, non-existing node\", scope);\n       return null;\n     }\n     if (!(node instanceof DFSTopologyNodeImpl)) {\n       // a node is either DFSTopologyNodeImpl, or a DatanodeDescriptor\n       return ((DatanodeDescriptor)node).hasStorageType(type) ? node : null;\n     }\n     DFSTopologyNodeImpl root \u003d (DFSTopologyNodeImpl)node;\n     Node excludeRoot \u003d excludedScope \u003d\u003d null ? null : getNode(excludedScope);\n \n     // check to see if there are nodes satisfying the condition at all\n     int availableCount \u003d root.getSubtreeStorageCount(type);\n     if (excludeRoot !\u003d null \u0026\u0026 root.isAncestor(excludeRoot)) {\n       if (excludeRoot instanceof DFSTopologyNodeImpl) {\n         availableCount -\u003d ((DFSTopologyNodeImpl)excludeRoot)\n             .getSubtreeStorageCount(type);\n       } else {\n         availableCount -\u003d ((DatanodeDescriptor)excludeRoot)\n             .hasStorageType(type) ? 1 : 0;\n       }\n     }\n     if (excludedNodes !\u003d null) {\n       for (Node excludedNode : excludedNodes) {\n-        // all excluded nodes should be DatanodeDescriptor\n-        Preconditions.checkArgument(excludedNode instanceof DatanodeDescriptor);\n-        availableCount -\u003d ((DatanodeDescriptor) excludedNode)\n-            .hasStorageType(type) ? 1 : 0;\n+        if (excludedNode instanceof DatanodeDescriptor) {\n+          availableCount -\u003d ((DatanodeDescriptor) excludedNode)\n+              .hasStorageType(type) ? 1 : 0;\n+        } else if (excludedNode instanceof DFSTopologyNodeImpl) {\n+          availableCount -\u003d ((DFSTopologyNodeImpl) excludedNode)\n+              .getSubtreeStorageCount(type);\n+        } else if (excludedNode instanceof DatanodeInfo) {\n+          // find out the corresponding DatanodeDescriptor object, beacuse\n+          // we need to get its storage type info.\n+          // could be expensive operation, fortunately the size of excluded\n+          // nodes set is supposed to be very small.\n+          String nodeLocation \u003d excludedNode.getNetworkLocation()\n+              + \"/\" + excludedNode.getName();\n+          DatanodeDescriptor dn \u003d (DatanodeDescriptor)getNode(nodeLocation);\n+          availableCount -\u003d dn.hasStorageType(type)? 1 : 0;\n+        } else {\n+          LOG.error(\"Unexpected node type: {}.\", excludedNode.getClass());\n+        }\n       }\n     }\n     if (availableCount \u003c\u003d 0) {\n       // should never be \u003c0 in general, adding \u003c0 check for safety purpose\n       return null;\n     }\n     // to this point, it is guaranteed that there is at least one node\n     // that satisfies the requirement, keep trying until we found one.\n     Node chosen;\n     do {\n       chosen \u003d chooseRandomWithStorageTypeAndExcludeRoot(root, excludeRoot,\n           type);\n       if (excludedNodes \u003d\u003d null || !excludedNodes.contains(chosen)) {\n         break;\n       } else {\n         LOG.debug(\"Node {} is excluded, continuing.\", chosen);\n       }\n     } while (true);\n     LOG.debug(\"chooseRandom returning {}\", chosen);\n     return chosen;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  Node chooseRandomWithStorageType(final String scope,\n      String excludedScope, final Collection\u003cNode\u003e excludedNodes,\n      StorageType type) {\n    if (excludedScope !\u003d null) {\n      if (scope.startsWith(excludedScope)) {\n        return null;\n      }\n      if (!excludedScope.startsWith(scope)) {\n        excludedScope \u003d null;\n      }\n    }\n    Node node \u003d getNode(scope);\n    if (node \u003d\u003d null) {\n      LOG.debug(\"Invalid scope {}, non-existing node\", scope);\n      return null;\n    }\n    if (!(node instanceof DFSTopologyNodeImpl)) {\n      // a node is either DFSTopologyNodeImpl, or a DatanodeDescriptor\n      return ((DatanodeDescriptor)node).hasStorageType(type) ? node : null;\n    }\n    DFSTopologyNodeImpl root \u003d (DFSTopologyNodeImpl)node;\n    Node excludeRoot \u003d excludedScope \u003d\u003d null ? null : getNode(excludedScope);\n\n    // check to see if there are nodes satisfying the condition at all\n    int availableCount \u003d root.getSubtreeStorageCount(type);\n    if (excludeRoot !\u003d null \u0026\u0026 root.isAncestor(excludeRoot)) {\n      if (excludeRoot instanceof DFSTopologyNodeImpl) {\n        availableCount -\u003d ((DFSTopologyNodeImpl)excludeRoot)\n            .getSubtreeStorageCount(type);\n      } else {\n        availableCount -\u003d ((DatanodeDescriptor)excludeRoot)\n            .hasStorageType(type) ? 1 : 0;\n      }\n    }\n    if (excludedNodes !\u003d null) {\n      for (Node excludedNode : excludedNodes) {\n        if (excludedNode instanceof DatanodeDescriptor) {\n          availableCount -\u003d ((DatanodeDescriptor) excludedNode)\n              .hasStorageType(type) ? 1 : 0;\n        } else if (excludedNode instanceof DFSTopologyNodeImpl) {\n          availableCount -\u003d ((DFSTopologyNodeImpl) excludedNode)\n              .getSubtreeStorageCount(type);\n        } else if (excludedNode instanceof DatanodeInfo) {\n          // find out the corresponding DatanodeDescriptor object, beacuse\n          // we need to get its storage type info.\n          // could be expensive operation, fortunately the size of excluded\n          // nodes set is supposed to be very small.\n          String nodeLocation \u003d excludedNode.getNetworkLocation()\n              + \"/\" + excludedNode.getName();\n          DatanodeDescriptor dn \u003d (DatanodeDescriptor)getNode(nodeLocation);\n          availableCount -\u003d dn.hasStorageType(type)? 1 : 0;\n        } else {\n          LOG.error(\"Unexpected node type: {}.\", excludedNode.getClass());\n        }\n      }\n    }\n    if (availableCount \u003c\u003d 0) {\n      // should never be \u003c0 in general, adding \u003c0 check for safety purpose\n      return null;\n    }\n    // to this point, it is guaranteed that there is at least one node\n    // that satisfies the requirement, keep trying until we found one.\n    Node chosen;\n    do {\n      chosen \u003d chooseRandomWithStorageTypeAndExcludeRoot(root, excludeRoot,\n          type);\n      if (excludedNodes \u003d\u003d null || !excludedNodes.contains(chosen)) {\n        break;\n      } else {\n        LOG.debug(\"Node {} is excluded, continuing.\", chosen);\n      }\n    } while (true);\n    LOG.debug(\"chooseRandom returning {}\", chosen);\n    return chosen;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/net/DFSNetworkTopology.java",
      "extendedDetails": {}
    },
    "9832ae0ed8853d29072c9ea7031cd2373e6b16f9": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-11482. Add storage type demand to into DFSNetworkTopology#chooseRandom. Contributed by Chen Liang.\n",
      "commitDate": "13/03/17 5:30 PM",
      "commitName": "9832ae0ed8853d29072c9ea7031cd2373e6b16f9",
      "commitAuthor": "Chen Liang",
      "diff": "@@ -0,0 +1,61 @@\n+  Node chooseRandomWithStorageType(final String scope,\n+      String excludedScope, final Collection\u003cNode\u003e excludedNodes,\n+      StorageType type) {\n+    if (excludedScope !\u003d null) {\n+      if (scope.startsWith(excludedScope)) {\n+        return null;\n+      }\n+      if (!excludedScope.startsWith(scope)) {\n+        excludedScope \u003d null;\n+      }\n+    }\n+    Node node \u003d getNode(scope);\n+    if (node \u003d\u003d null) {\n+      LOG.debug(\"Invalid scope {}, non-existing node\", scope);\n+      return null;\n+    }\n+    if (!(node instanceof DFSTopologyNodeImpl)) {\n+      // a node is either DFSTopologyNodeImpl, or a DatanodeDescriptor\n+      return ((DatanodeDescriptor)node).hasStorageType(type) ? node : null;\n+    }\n+    DFSTopologyNodeImpl root \u003d (DFSTopologyNodeImpl)node;\n+    Node excludeRoot \u003d excludedScope \u003d\u003d null ? null : getNode(excludedScope);\n+\n+    // check to see if there are nodes satisfying the condition at all\n+    int availableCount \u003d root.getSubtreeStorageCount(type);\n+    if (excludeRoot !\u003d null \u0026\u0026 root.isAncestor(excludeRoot)) {\n+      if (excludeRoot instanceof DFSTopologyNodeImpl) {\n+        availableCount -\u003d ((DFSTopologyNodeImpl)excludeRoot)\n+            .getSubtreeStorageCount(type);\n+      } else {\n+        availableCount -\u003d ((DatanodeDescriptor)excludeRoot)\n+            .hasStorageType(type) ? 1 : 0;\n+      }\n+    }\n+    if (excludedNodes !\u003d null) {\n+      for (Node excludedNode : excludedNodes) {\n+        // all excluded nodes should be DatanodeDescriptor\n+        Preconditions.checkArgument(excludedNode instanceof DatanodeDescriptor);\n+        availableCount -\u003d ((DatanodeDescriptor) excludedNode)\n+            .hasStorageType(type) ? 1 : 0;\n+      }\n+    }\n+    if (availableCount \u003c\u003d 0) {\n+      // should never be \u003c0 in general, adding \u003c0 check for safety purpose\n+      return null;\n+    }\n+    // to this point, it is guaranteed that there is at least one node\n+    // that satisfies the requirement, keep trying until we found one.\n+    Node chosen;\n+    do {\n+      chosen \u003d chooseRandomWithStorageTypeAndExcludeRoot(root, excludeRoot,\n+          type);\n+      if (excludedNodes \u003d\u003d null || !excludedNodes.contains(chosen)) {\n+        break;\n+      } else {\n+        LOG.debug(\"Node {} is excluded, continuing.\", chosen);\n+      }\n+    } while (true);\n+    LOG.debug(\"chooseRandom returning {}\", chosen);\n+    return chosen;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  Node chooseRandomWithStorageType(final String scope,\n      String excludedScope, final Collection\u003cNode\u003e excludedNodes,\n      StorageType type) {\n    if (excludedScope !\u003d null) {\n      if (scope.startsWith(excludedScope)) {\n        return null;\n      }\n      if (!excludedScope.startsWith(scope)) {\n        excludedScope \u003d null;\n      }\n    }\n    Node node \u003d getNode(scope);\n    if (node \u003d\u003d null) {\n      LOG.debug(\"Invalid scope {}, non-existing node\", scope);\n      return null;\n    }\n    if (!(node instanceof DFSTopologyNodeImpl)) {\n      // a node is either DFSTopologyNodeImpl, or a DatanodeDescriptor\n      return ((DatanodeDescriptor)node).hasStorageType(type) ? node : null;\n    }\n    DFSTopologyNodeImpl root \u003d (DFSTopologyNodeImpl)node;\n    Node excludeRoot \u003d excludedScope \u003d\u003d null ? null : getNode(excludedScope);\n\n    // check to see if there are nodes satisfying the condition at all\n    int availableCount \u003d root.getSubtreeStorageCount(type);\n    if (excludeRoot !\u003d null \u0026\u0026 root.isAncestor(excludeRoot)) {\n      if (excludeRoot instanceof DFSTopologyNodeImpl) {\n        availableCount -\u003d ((DFSTopologyNodeImpl)excludeRoot)\n            .getSubtreeStorageCount(type);\n      } else {\n        availableCount -\u003d ((DatanodeDescriptor)excludeRoot)\n            .hasStorageType(type) ? 1 : 0;\n      }\n    }\n    if (excludedNodes !\u003d null) {\n      for (Node excludedNode : excludedNodes) {\n        // all excluded nodes should be DatanodeDescriptor\n        Preconditions.checkArgument(excludedNode instanceof DatanodeDescriptor);\n        availableCount -\u003d ((DatanodeDescriptor) excludedNode)\n            .hasStorageType(type) ? 1 : 0;\n      }\n    }\n    if (availableCount \u003c\u003d 0) {\n      // should never be \u003c0 in general, adding \u003c0 check for safety purpose\n      return null;\n    }\n    // to this point, it is guaranteed that there is at least one node\n    // that satisfies the requirement, keep trying until we found one.\n    Node chosen;\n    do {\n      chosen \u003d chooseRandomWithStorageTypeAndExcludeRoot(root, excludeRoot,\n          type);\n      if (excludedNodes \u003d\u003d null || !excludedNodes.contains(chosen)) {\n        break;\n      } else {\n        LOG.debug(\"Node {} is excluded, continuing.\", chosen);\n      }\n    } while (true);\n    LOG.debug(\"chooseRandom returning {}\", chosen);\n    return chosen;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/net/DFSNetworkTopology.java"
    }
  }
}