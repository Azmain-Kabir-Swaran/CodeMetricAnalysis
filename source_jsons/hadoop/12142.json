{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DataNode.java",
  "functionName": "initBlockPool",
  "functionId": "initBlockPool___bpos-BPOfferService",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java",
  "functionStartLine": 1688,
  "functionEndLine": 1715,
  "numCommitsSeen": 358,
  "timeTaken": 3299,
  "changeHistory": [
    "87c198468bb6a6312bbb27b174c18822b6b9ccf8",
    "34b14061b38dccab25058dff1b8743d8a3f82734",
    "dfcb331ba3516264398121c9f23af3a79c0509cc"
  ],
  "changeHistoryShort": {
    "87c198468bb6a6312bbb27b174c18822b6b9ccf8": "Ybodychange",
    "34b14061b38dccab25058dff1b8743d8a3f82734": "Ybodychange",
    "dfcb331ba3516264398121c9f23af3a79c0509cc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "87c198468bb6a6312bbb27b174c18822b6b9ccf8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14993. checkDiskError doesn\u0027t work during datanode startup. Contributed by Yang Yun.\n",
      "commitDate": "28/01/20 9:39 AM",
      "commitName": "87c198468bb6a6312bbb27b174c18822b6b9ccf8",
      "commitAuthor": "Ayush Saxena",
      "commitDateOld": "03/01/20 8:55 AM",
      "commitNameOld": "037ec8cfb1406ea3a8225a1b6306c2e78440353b",
      "commitAuthorOld": "Masatake Iwasaki",
      "daysBetweenCommits": 25.03,
      "commitsBetweenForRepo": 96,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,28 +1,28 @@\n   void initBlockPool(BPOfferService bpos) throws IOException {\n     NamespaceInfo nsInfo \u003d bpos.getNamespaceInfo();\n     if (nsInfo \u003d\u003d null) {\n       throw new IOException(\"NamespaceInfo not found: Block pool \" + bpos\n           + \" should have retrieved namespace info before initBlockPool.\");\n     }\n     \n     setClusterId(nsInfo.clusterID, nsInfo.getBlockPoolID());\n \n     // Register the new block pool with the BP manager.\n     blockPoolManager.addBlockPool(bpos);\n     \n     // In the case that this is the first block pool to connect, initialize\n     // the dataset, block scanners, etc.\n     initStorage(nsInfo);\n \n-    // Exclude failed disks before initializing the block pools to avoid startup\n-    // failures.\n-    checkDiskError();\n     try {\n       data.addBlockPool(nsInfo.getBlockPoolID(), getConf());\n     } catch (AddBlockPoolException e) {\n       handleAddBlockPoolError(e);\n     }\n+    // HDFS-14993: check disk after add the block pool info.\n+    checkDiskError();\n+\n     blockScanner.enableBlockPoolId(bpos.getBlockPoolId());\n     initDirectoryScanner(getConf());\n     initDiskBalancer(data, getConf());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void initBlockPool(BPOfferService bpos) throws IOException {\n    NamespaceInfo nsInfo \u003d bpos.getNamespaceInfo();\n    if (nsInfo \u003d\u003d null) {\n      throw new IOException(\"NamespaceInfo not found: Block pool \" + bpos\n          + \" should have retrieved namespace info before initBlockPool.\");\n    }\n    \n    setClusterId(nsInfo.clusterID, nsInfo.getBlockPoolID());\n\n    // Register the new block pool with the BP manager.\n    blockPoolManager.addBlockPool(bpos);\n    \n    // In the case that this is the first block pool to connect, initialize\n    // the dataset, block scanners, etc.\n    initStorage(nsInfo);\n\n    try {\n      data.addBlockPool(nsInfo.getBlockPoolID(), getConf());\n    } catch (AddBlockPoolException e) {\n      handleAddBlockPoolError(e);\n    }\n    // HDFS-14993: check disk after add the block pool info.\n    checkDiskError();\n\n    blockScanner.enableBlockPoolId(bpos.getBlockPoolId());\n    initDirectoryScanner(getConf());\n    initDiskBalancer(data, getConf());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java",
      "extendedDetails": {}
    },
    "34b14061b38dccab25058dff1b8743d8a3f82734": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14333. Datanode fails to start if any disk has errors during Namenode registration. Contributed by Stephen O\u0027Donnell.\n\nSigned-off-by: Wei-Chiu Chuang \u003cweichiu@apache.org\u003e\n",
      "commitDate": "12/03/19 10:17 AM",
      "commitName": "34b14061b38dccab25058dff1b8743d8a3f82734",
      "commitAuthor": "Stephen O\u0027Donnell",
      "commitDateOld": "15/02/19 4:32 PM",
      "commitNameOld": "dde0ab55aadcf7c9cf71dbe36d90e97da6bc9498",
      "commitAuthorOld": "Inigo Goiri",
      "daysBetweenCommits": 24.7,
      "commitsBetweenForRepo": 215,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,25 +1,28 @@\n   void initBlockPool(BPOfferService bpos) throws IOException {\n     NamespaceInfo nsInfo \u003d bpos.getNamespaceInfo();\n     if (nsInfo \u003d\u003d null) {\n       throw new IOException(\"NamespaceInfo not found: Block pool \" + bpos\n           + \" should have retrieved namespace info before initBlockPool.\");\n     }\n     \n     setClusterId(nsInfo.clusterID, nsInfo.getBlockPoolID());\n \n     // Register the new block pool with the BP manager.\n     blockPoolManager.addBlockPool(bpos);\n     \n     // In the case that this is the first block pool to connect, initialize\n     // the dataset, block scanners, etc.\n     initStorage(nsInfo);\n \n     // Exclude failed disks before initializing the block pools to avoid startup\n     // failures.\n     checkDiskError();\n-\n-    data.addBlockPool(nsInfo.getBlockPoolID(), getConf());\n+    try {\n+      data.addBlockPool(nsInfo.getBlockPoolID(), getConf());\n+    } catch (AddBlockPoolException e) {\n+      handleAddBlockPoolError(e);\n+    }\n     blockScanner.enableBlockPoolId(bpos.getBlockPoolId());\n     initDirectoryScanner(getConf());\n     initDiskBalancer(data, getConf());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void initBlockPool(BPOfferService bpos) throws IOException {\n    NamespaceInfo nsInfo \u003d bpos.getNamespaceInfo();\n    if (nsInfo \u003d\u003d null) {\n      throw new IOException(\"NamespaceInfo not found: Block pool \" + bpos\n          + \" should have retrieved namespace info before initBlockPool.\");\n    }\n    \n    setClusterId(nsInfo.clusterID, nsInfo.getBlockPoolID());\n\n    // Register the new block pool with the BP manager.\n    blockPoolManager.addBlockPool(bpos);\n    \n    // In the case that this is the first block pool to connect, initialize\n    // the dataset, block scanners, etc.\n    initStorage(nsInfo);\n\n    // Exclude failed disks before initializing the block pools to avoid startup\n    // failures.\n    checkDiskError();\n    try {\n      data.addBlockPool(nsInfo.getBlockPoolID(), getConf());\n    } catch (AddBlockPoolException e) {\n      handleAddBlockPoolError(e);\n    }\n    blockScanner.enableBlockPoolId(bpos.getBlockPoolId());\n    initDirectoryScanner(getConf());\n    initDiskBalancer(data, getConf());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java",
      "extendedDetails": {}
    },
    "dfcb331ba3516264398121c9f23af3a79c0509cc": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-13076: [SPS]: Addendum. Resolve conflicts after rebasing branch to trunk. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "dfcb331ba3516264398121c9f23af3a79c0509cc",
      "commitAuthor": "Rakesh Radhakrishnan",
      "diff": "@@ -0,0 +1,25 @@\n+  void initBlockPool(BPOfferService bpos) throws IOException {\n+    NamespaceInfo nsInfo \u003d bpos.getNamespaceInfo();\n+    if (nsInfo \u003d\u003d null) {\n+      throw new IOException(\"NamespaceInfo not found: Block pool \" + bpos\n+          + \" should have retrieved namespace info before initBlockPool.\");\n+    }\n+    \n+    setClusterId(nsInfo.clusterID, nsInfo.getBlockPoolID());\n+\n+    // Register the new block pool with the BP manager.\n+    blockPoolManager.addBlockPool(bpos);\n+    \n+    // In the case that this is the first block pool to connect, initialize\n+    // the dataset, block scanners, etc.\n+    initStorage(nsInfo);\n+\n+    // Exclude failed disks before initializing the block pools to avoid startup\n+    // failures.\n+    checkDiskError();\n+\n+    data.addBlockPool(nsInfo.getBlockPoolID(), getConf());\n+    blockScanner.enableBlockPoolId(bpos.getBlockPoolId());\n+    initDirectoryScanner(getConf());\n+    initDiskBalancer(data, getConf());\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  void initBlockPool(BPOfferService bpos) throws IOException {\n    NamespaceInfo nsInfo \u003d bpos.getNamespaceInfo();\n    if (nsInfo \u003d\u003d null) {\n      throw new IOException(\"NamespaceInfo not found: Block pool \" + bpos\n          + \" should have retrieved namespace info before initBlockPool.\");\n    }\n    \n    setClusterId(nsInfo.clusterID, nsInfo.getBlockPoolID());\n\n    // Register the new block pool with the BP manager.\n    blockPoolManager.addBlockPool(bpos);\n    \n    // In the case that this is the first block pool to connect, initialize\n    // the dataset, block scanners, etc.\n    initStorage(nsInfo);\n\n    // Exclude failed disks before initializing the block pools to avoid startup\n    // failures.\n    checkDiskError();\n\n    data.addBlockPool(nsInfo.getBlockPoolID(), getConf());\n    blockScanner.enableBlockPoolId(bpos.getBlockPoolId());\n    initDirectoryScanner(getConf());\n    initDiskBalancer(data, getConf());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java"
    }
  }
}