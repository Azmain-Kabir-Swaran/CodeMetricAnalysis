{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "Fetcher.java",
  "functionName": "openShuffleUrl",
  "functionId": "openShuffleUrl___host-MapHost__remaining-Set__TaskAttemptID____url-URL",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/Fetcher.java",
  "functionStartLine": 266,
  "functionEndLine": 296,
  "numCommitsSeen": 35,
  "timeTaken": 2362,
  "changeHistory": [
    "4d98936eec1b5d196053426c70d455cf8f83f84f",
    "d4725bfcb2d300219d65395a78f957afbf37b201",
    "8cc4a67059e37b2083cd5468b35a64a403a3e3ae",
    "eccb7d46efbf07abcc6a01bd5e7d682f6815b824"
  ],
  "changeHistoryShort": {
    "4d98936eec1b5d196053426c70d455cf8f83f84f": "Ybodychange",
    "d4725bfcb2d300219d65395a78f957afbf37b201": "Ybodychange",
    "8cc4a67059e37b2083cd5468b35a64a403a3e3ae": "Ybodychange",
    "eccb7d46efbf07abcc6a01bd5e7d682f6815b824": "Yintroduced"
  },
  "changeHistoryDetails": {
    "4d98936eec1b5d196053426c70d455cf8f83f84f": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6957. shuffle hangs after a node manager connection timeout. Contributed by Jooseong Kim\n",
      "commitDate": "13/09/17 3:21 PM",
      "commitName": "4d98936eec1b5d196053426c70d455cf8f83f84f",
      "commitAuthor": "Jason Lowe",
      "commitDateOld": "29/05/17 10:48 PM",
      "commitNameOld": "d4015f8628dd973c7433639451a9acc3e741d2a2",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 106.69,
      "commitsBetweenForRepo": 747,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,39 +1,31 @@\n   private DataInputStream openShuffleUrl(MapHost host,\n       Set\u003cTaskAttemptID\u003e remaining, URL url) {\n     DataInputStream input \u003d null;\n \n     try {\n       setupConnectionsWithRetry(url);\n       if (stopped) {\n         abortConnect(host, remaining);\n       } else {\n         input \u003d new DataInputStream(connection.getInputStream());\n       }\n     } catch (TryAgainLaterException te) {\n       LOG.warn(\"Connection rejected by the host \" + te.host +\n           \". Will retry later.\");\n       scheduler.penalize(host, te.backoff);\n-      for (TaskAttemptID left : remaining) {\n-        scheduler.putBackKnownMapOutput(host, left);\n-      }\n     } catch (IOException ie) {\n       boolean connectExcpt \u003d ie instanceof ConnectException;\n       ioErrs.increment(1);\n       LOG.warn(\"Failed to connect to \" + host + \" with \" + remaining.size() +\n                \" map outputs\", ie);\n \n       // If connect did not succeed, just mark all the maps as failed,\n       // indirectly penalizing the host\n       scheduler.hostFailed(host.getHostName());\n       for(TaskAttemptID left: remaining) {\n         scheduler.copyFailed(left, host, false, connectExcpt);\n       }\n-\n-      // Add back all the remaining maps, WITHOUT marking them as failed\n-      for(TaskAttemptID left: remaining) {\n-        scheduler.putBackKnownMapOutput(host, left);\n-      }\n     }\n \n     return input;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private DataInputStream openShuffleUrl(MapHost host,\n      Set\u003cTaskAttemptID\u003e remaining, URL url) {\n    DataInputStream input \u003d null;\n\n    try {\n      setupConnectionsWithRetry(url);\n      if (stopped) {\n        abortConnect(host, remaining);\n      } else {\n        input \u003d new DataInputStream(connection.getInputStream());\n      }\n    } catch (TryAgainLaterException te) {\n      LOG.warn(\"Connection rejected by the host \" + te.host +\n          \". Will retry later.\");\n      scheduler.penalize(host, te.backoff);\n    } catch (IOException ie) {\n      boolean connectExcpt \u003d ie instanceof ConnectException;\n      ioErrs.increment(1);\n      LOG.warn(\"Failed to connect to \" + host + \" with \" + remaining.size() +\n               \" map outputs\", ie);\n\n      // If connect did not succeed, just mark all the maps as failed,\n      // indirectly penalizing the host\n      scheduler.hostFailed(host.getHostName());\n      for(TaskAttemptID left: remaining) {\n        scheduler.copyFailed(left, host, false, connectExcpt);\n      }\n    }\n\n    return input;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/Fetcher.java",
      "extendedDetails": {}
    },
    "d4725bfcb2d300219d65395a78f957afbf37b201": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6728. Give fetchers hint when ShuffleHandler rejects a shuffling connection (haibochen via rkanter)\n",
      "commitDate": "21/10/16 5:46 PM",
      "commitName": "d4725bfcb2d300219d65395a78f957afbf37b201",
      "commitAuthor": "Robert Kanter",
      "commitDateOld": "23/08/16 1:04 AM",
      "commitNameOld": "8cc4a67059e37b2083cd5468b35a64a403a3e3ae",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 59.7,
      "commitsBetweenForRepo": 399,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,32 +1,39 @@\n   private DataInputStream openShuffleUrl(MapHost host,\n       Set\u003cTaskAttemptID\u003e remaining, URL url) {\n     DataInputStream input \u003d null;\n \n     try {\n       setupConnectionsWithRetry(url);\n       if (stopped) {\n         abortConnect(host, remaining);\n       } else {\n         input \u003d new DataInputStream(connection.getInputStream());\n       }\n+    } catch (TryAgainLaterException te) {\n+      LOG.warn(\"Connection rejected by the host \" + te.host +\n+          \". Will retry later.\");\n+      scheduler.penalize(host, te.backoff);\n+      for (TaskAttemptID left : remaining) {\n+        scheduler.putBackKnownMapOutput(host, left);\n+      }\n     } catch (IOException ie) {\n       boolean connectExcpt \u003d ie instanceof ConnectException;\n       ioErrs.increment(1);\n       LOG.warn(\"Failed to connect to \" + host + \" with \" + remaining.size() +\n                \" map outputs\", ie);\n \n       // If connect did not succeed, just mark all the maps as failed,\n       // indirectly penalizing the host\n       scheduler.hostFailed(host.getHostName());\n       for(TaskAttemptID left: remaining) {\n         scheduler.copyFailed(left, host, false, connectExcpt);\n       }\n \n       // Add back all the remaining maps, WITHOUT marking them as failed\n       for(TaskAttemptID left: remaining) {\n         scheduler.putBackKnownMapOutput(host, left);\n       }\n     }\n \n     return input;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private DataInputStream openShuffleUrl(MapHost host,\n      Set\u003cTaskAttemptID\u003e remaining, URL url) {\n    DataInputStream input \u003d null;\n\n    try {\n      setupConnectionsWithRetry(url);\n      if (stopped) {\n        abortConnect(host, remaining);\n      } else {\n        input \u003d new DataInputStream(connection.getInputStream());\n      }\n    } catch (TryAgainLaterException te) {\n      LOG.warn(\"Connection rejected by the host \" + te.host +\n          \". Will retry later.\");\n      scheduler.penalize(host, te.backoff);\n      for (TaskAttemptID left : remaining) {\n        scheduler.putBackKnownMapOutput(host, left);\n      }\n    } catch (IOException ie) {\n      boolean connectExcpt \u003d ie instanceof ConnectException;\n      ioErrs.increment(1);\n      LOG.warn(\"Failed to connect to \" + host + \" with \" + remaining.size() +\n               \" map outputs\", ie);\n\n      // If connect did not succeed, just mark all the maps as failed,\n      // indirectly penalizing the host\n      scheduler.hostFailed(host.getHostName());\n      for(TaskAttemptID left: remaining) {\n        scheduler.copyFailed(left, host, false, connectExcpt);\n      }\n\n      // Add back all the remaining maps, WITHOUT marking them as failed\n      for(TaskAttemptID left: remaining) {\n        scheduler.putBackKnownMapOutput(host, left);\n      }\n    }\n\n    return input;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/Fetcher.java",
      "extendedDetails": {}
    },
    "8cc4a67059e37b2083cd5468b35a64a403a3e3ae": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6587. Remove unused params in connection-related methods of Fetcher. Contributed by Yiqun Lin.\n",
      "commitDate": "23/08/16 1:04 AM",
      "commitName": "8cc4a67059e37b2083cd5468b35a64a403a3e3ae",
      "commitAuthor": "Akira Ajisaka",
      "commitDateOld": "09/04/16 9:51 AM",
      "commitNameOld": "1fec06e037d2b22dafc64f33d4f1231bef4ceba8",
      "commitAuthorOld": "Eric Payne",
      "daysBetweenCommits": 135.63,
      "commitsBetweenForRepo": 1025,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,32 +1,32 @@\n   private DataInputStream openShuffleUrl(MapHost host,\n       Set\u003cTaskAttemptID\u003e remaining, URL url) {\n     DataInputStream input \u003d null;\n \n     try {\n-      setupConnectionsWithRetry(host, remaining, url);\n+      setupConnectionsWithRetry(url);\n       if (stopped) {\n         abortConnect(host, remaining);\n       } else {\n         input \u003d new DataInputStream(connection.getInputStream());\n       }\n     } catch (IOException ie) {\n       boolean connectExcpt \u003d ie instanceof ConnectException;\n       ioErrs.increment(1);\n       LOG.warn(\"Failed to connect to \" + host + \" with \" + remaining.size() +\n                \" map outputs\", ie);\n \n       // If connect did not succeed, just mark all the maps as failed,\n       // indirectly penalizing the host\n       scheduler.hostFailed(host.getHostName());\n       for(TaskAttemptID left: remaining) {\n         scheduler.copyFailed(left, host, false, connectExcpt);\n       }\n \n       // Add back all the remaining maps, WITHOUT marking them as failed\n       for(TaskAttemptID left: remaining) {\n         scheduler.putBackKnownMapOutput(host, left);\n       }\n     }\n \n     return input;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private DataInputStream openShuffleUrl(MapHost host,\n      Set\u003cTaskAttemptID\u003e remaining, URL url) {\n    DataInputStream input \u003d null;\n\n    try {\n      setupConnectionsWithRetry(url);\n      if (stopped) {\n        abortConnect(host, remaining);\n      } else {\n        input \u003d new DataInputStream(connection.getInputStream());\n      }\n    } catch (IOException ie) {\n      boolean connectExcpt \u003d ie instanceof ConnectException;\n      ioErrs.increment(1);\n      LOG.warn(\"Failed to connect to \" + host + \" with \" + remaining.size() +\n               \" map outputs\", ie);\n\n      // If connect did not succeed, just mark all the maps as failed,\n      // indirectly penalizing the host\n      scheduler.hostFailed(host.getHostName());\n      for(TaskAttemptID left: remaining) {\n        scheduler.copyFailed(left, host, false, connectExcpt);\n      }\n\n      // Add back all the remaining maps, WITHOUT marking them as failed\n      for(TaskAttemptID left: remaining) {\n        scheduler.putBackKnownMapOutput(host, left);\n      }\n    }\n\n    return input;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/Fetcher.java",
      "extendedDetails": {}
    },
    "eccb7d46efbf07abcc6a01bd5e7d682f6815b824": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-6303. Read timeout when retrying a fetch error can be fatal to a reducer. Contributed by Jason Lowe.\n",
      "commitDate": "02/04/15 12:13 PM",
      "commitName": "eccb7d46efbf07abcc6a01bd5e7d682f6815b824",
      "commitAuthor": "Junping Du",
      "diff": "@@ -0,0 +1,32 @@\n+  private DataInputStream openShuffleUrl(MapHost host,\n+      Set\u003cTaskAttemptID\u003e remaining, URL url) {\n+    DataInputStream input \u003d null;\n+\n+    try {\n+      setupConnectionsWithRetry(host, remaining, url);\n+      if (stopped) {\n+        abortConnect(host, remaining);\n+      } else {\n+        input \u003d new DataInputStream(connection.getInputStream());\n+      }\n+    } catch (IOException ie) {\n+      boolean connectExcpt \u003d ie instanceof ConnectException;\n+      ioErrs.increment(1);\n+      LOG.warn(\"Failed to connect to \" + host + \" with \" + remaining.size() +\n+               \" map outputs\", ie);\n+\n+      // If connect did not succeed, just mark all the maps as failed,\n+      // indirectly penalizing the host\n+      scheduler.hostFailed(host.getHostName());\n+      for(TaskAttemptID left: remaining) {\n+        scheduler.copyFailed(left, host, false, connectExcpt);\n+      }\n+\n+      // Add back all the remaining maps, WITHOUT marking them as failed\n+      for(TaskAttemptID left: remaining) {\n+        scheduler.putBackKnownMapOutput(host, left);\n+      }\n+    }\n+\n+    return input;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private DataInputStream openShuffleUrl(MapHost host,\n      Set\u003cTaskAttemptID\u003e remaining, URL url) {\n    DataInputStream input \u003d null;\n\n    try {\n      setupConnectionsWithRetry(host, remaining, url);\n      if (stopped) {\n        abortConnect(host, remaining);\n      } else {\n        input \u003d new DataInputStream(connection.getInputStream());\n      }\n    } catch (IOException ie) {\n      boolean connectExcpt \u003d ie instanceof ConnectException;\n      ioErrs.increment(1);\n      LOG.warn(\"Failed to connect to \" + host + \" with \" + remaining.size() +\n               \" map outputs\", ie);\n\n      // If connect did not succeed, just mark all the maps as failed,\n      // indirectly penalizing the host\n      scheduler.hostFailed(host.getHostName());\n      for(TaskAttemptID left: remaining) {\n        scheduler.copyFailed(left, host, false, connectExcpt);\n      }\n\n      // Add back all the remaining maps, WITHOUT marking them as failed\n      for(TaskAttemptID left: remaining) {\n        scheduler.putBackKnownMapOutput(host, left);\n      }\n    }\n\n    return input;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/Fetcher.java"
    }
  }
}