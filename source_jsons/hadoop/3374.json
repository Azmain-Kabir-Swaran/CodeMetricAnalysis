{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ByteRangeInputStream.java",
  "functionName": "read",
  "functionId": "read___b-byte[](annotations-@Nonnull)__off-int__len-int",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/ByteRangeInputStream.java",
  "functionStartLine": 208,
  "functionEndLine": 210,
  "numCommitsSeen": 20,
  "timeTaken": 1609,
  "changeHistory": [
    "7136e8c5582dc4061b566cb9f11a0d6a6d08bb93",
    "bcf89ddc7d52e04725caf104f5958e33d9f51b35",
    "68a79b0d3f189dfdbd3a3e2a0b906627db3eff8d",
    "f86352c2dff7e75314a8fc08c32f4a37c098cc62"
  ],
  "changeHistoryShort": {
    "7136e8c5582dc4061b566cb9f11a0d6a6d08bb93": "Yparametermetachange",
    "bcf89ddc7d52e04725caf104f5958e33d9f51b35": "Yfilerename",
    "68a79b0d3f189dfdbd3a3e2a0b906627db3eff8d": "Yfilerename",
    "f86352c2dff7e75314a8fc08c32f4a37c098cc62": "Yintroduced"
  },
  "changeHistoryDetails": {
    "7136e8c5582dc4061b566cb9f11a0d6a6d08bb93": {
      "type": "Yparametermetachange",
      "commitMessage": "HDFS-8979. Clean up checkstyle warnings in hadoop-hdfs-client module. Contributed by Mingliang Liu.\n",
      "commitDate": "03/10/15 11:38 AM",
      "commitName": "7136e8c5582dc4061b566cb9f11a0d6a6d08bb93",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "03/09/15 3:40 AM",
      "commitNameOld": "c92e31bd659e95c8baa0f3b2bf0cd7f6f72278e6",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 30.33,
      "commitsBetweenForRepo": 220,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,3 +1,3 @@\n-  public int read(byte b[], int off, int len) throws IOException {\n+  public int read(@Nonnull byte b[], int off, int len) throws IOException {\n     return update(getInputStream().read(b, off, len));\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int read(@Nonnull byte b[], int off, int len) throws IOException {\n    return update(getInputStream().read(b, off, len));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/ByteRangeInputStream.java",
      "extendedDetails": {
        "oldValue": "[b-byte[], off-int, len-int]",
        "newValue": "[b-byte[](annotations-@Nonnull), off-int, len-int]"
      }
    },
    "bcf89ddc7d52e04725caf104f5958e33d9f51b35": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8052. Move WebHdfsFileSystem into hadoop-hdfs-client. Contributed by Haohui Mai.\n",
      "commitDate": "23/04/15 5:33 PM",
      "commitName": "bcf89ddc7d52e04725caf104f5958e33d9f51b35",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "23/04/15 4:40 PM",
      "commitNameOld": "0b3f8957a87ada1a275c9904b211fdbdcefafb02",
      "commitAuthorOld": "Xuan",
      "daysBetweenCommits": 0.04,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public int read(byte b[], int off, int len) throws IOException {\n    return update(getInputStream().read(b, off, len));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/ByteRangeInputStream.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/ByteRangeInputStream.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/ByteRangeInputStream.java"
      }
    },
    "68a79b0d3f189dfdbd3a3e2a0b906627db3eff8d": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-5436. Move HsFtpFileSystem and HFtpFileSystem into org.apache.hdfs.web. (Contributed by Haohui Mai)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1536921 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "29/10/13 3:44 PM",
      "commitName": "68a79b0d3f189dfdbd3a3e2a0b906627db3eff8d",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "29/10/13 2:11 PM",
      "commitNameOld": "7dd201c541c811069a898403cf28a50152a38737",
      "commitAuthorOld": "Bikas Saha",
      "daysBetweenCommits": 0.06,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public int read(byte b[], int off, int len) throws IOException {\n    return update(getInputStream().read(b, off, len));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/ByteRangeInputStream.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/ByteRangeInputStream.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/ByteRangeInputStream.java"
      }
    },
    "f86352c2dff7e75314a8fc08c32f4a37c098cc62": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-3318. Use BoundedInputStream in ByteRangeInputStream, otherwise, it hangs on transfers \u003e2 GB.  Contributed by Daryn Sharp \n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1330500 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "25/04/12 12:24 PM",
      "commitName": "f86352c2dff7e75314a8fc08c32f4a37c098cc62",
      "commitAuthor": "Tsz-wo Sze",
      "diff": "@@ -0,0 +1,3 @@\n+  public int read(byte b[], int off, int len) throws IOException {\n+    return update(getInputStream().read(b, off, len));\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public int read(byte b[], int off, int len) throws IOException {\n    return update(getInputStream().read(b, off, len));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/ByteRangeInputStream.java"
    }
  }
}