{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "MultiObjectDeleteSupport.java",
  "functionName": "splitUndeletedKeys",
  "functionId": "splitUndeletedKeys___deleteException-MultiObjectDeleteException(modifiers-final)__keysToDelete-Collection__DeleteObjectsRequest.KeyVersion__(modifiers-final)",
  "sourceFilePath": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/impl/MultiObjectDeleteSupport.java",
  "functionStartLine": 116,
  "functionEndLine": 133,
  "numCommitsSeen": 3,
  "timeTaken": 1361,
  "changeHistory": [
    "e02eb24e0a9139418120027b694492e0738df20a"
  ],
  "changeHistoryShort": {
    "e02eb24e0a9139418120027b694492e0738df20a": "Yintroduced"
  },
  "changeHistoryDetails": {
    "e02eb24e0a9139418120027b694492e0738df20a": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-15183. S3Guard store becomes inconsistent after partial failure of rename.\n\nContributed by Steve Loughran.\n\nChange-Id: I825b0bc36be960475d2d259b1cdab45ae1bb78eb\n",
      "commitDate": "20/06/19 1:56 AM",
      "commitName": "e02eb24e0a9139418120027b694492e0738df20a",
      "commitAuthor": "Steve Loughran",
      "diff": "@@ -0,0 +1,18 @@\n+  public Pair\u003cList\u003cPath\u003e, List\u003cPath\u003e\u003e splitUndeletedKeys(\n+      final MultiObjectDeleteException deleteException,\n+      final Collection\u003cDeleteObjectsRequest.KeyVersion\u003e keysToDelete) {\n+    LOG.debug(\"Processing delete failure; keys to delete count \u003d {};\"\n+            + \" errors in exception {}; successful deletions \u003d {}\",\n+        keysToDelete.size(),\n+        deleteException.getErrors().size(),\n+        deleteException.getDeletedObjects().size());\n+    // convert the collection of keys being deleted into paths\n+    final List\u003cPath\u003e pathsBeingDeleted \u003d keysToPaths(keysToDelete);\n+    // Take this is list of paths\n+    // extract all undeleted entries contained in the exception and\n+    // then removes them from the original list.\n+    List\u003cPath\u003e undeleted \u003d removeUndeletedPaths(deleteException,\n+        pathsBeingDeleted,\n+        getStoreContext()::keyToPath);\n+    return Pair.of(undeleted, pathsBeingDeleted);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public Pair\u003cList\u003cPath\u003e, List\u003cPath\u003e\u003e splitUndeletedKeys(\n      final MultiObjectDeleteException deleteException,\n      final Collection\u003cDeleteObjectsRequest.KeyVersion\u003e keysToDelete) {\n    LOG.debug(\"Processing delete failure; keys to delete count \u003d {};\"\n            + \" errors in exception {}; successful deletions \u003d {}\",\n        keysToDelete.size(),\n        deleteException.getErrors().size(),\n        deleteException.getDeletedObjects().size());\n    // convert the collection of keys being deleted into paths\n    final List\u003cPath\u003e pathsBeingDeleted \u003d keysToPaths(keysToDelete);\n    // Take this is list of paths\n    // extract all undeleted entries contained in the exception and\n    // then removes them from the original list.\n    List\u003cPath\u003e undeleted \u003d removeUndeletedPaths(deleteException,\n        pathsBeingDeleted,\n        getStoreContext()::keyToPath);\n    return Pair.of(undeleted, pathsBeingDeleted);\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/impl/MultiObjectDeleteSupport.java"
    }
  }
}