{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "AbstractS3ACommitter.java",
  "functionName": "setupJob",
  "functionId": "setupJob___context-JobContext",
  "sourceFilePath": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/commit/AbstractS3ACommitter.java",
  "functionStartLine": 418,
  "functionEndLine": 425,
  "numCommitsSeen": 6,
  "timeTaken": 1705,
  "changeHistory": [
    "6574f27fa348542411bff888b184cd7ce34e5d9e"
  ],
  "changeHistoryShort": {
    "6574f27fa348542411bff888b184cd7ce34e5d9e": "Yintroduced"
  },
  "changeHistoryDetails": {
    "6574f27fa348542411bff888b184cd7ce34e5d9e": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-16570. S3A committers encounter scale issues.\n\nContributed by Steve Loughran.\n\nThis addresses two scale issues which has surfaced in large scale benchmarks\nof the S3A Committers.\n\n* Thread pools are not cleaned up.\n  This now happens, with tests.\n\n* OOM on job commit for jobs with many thousands of tasks,\n  each generating tens of (very large) files.\n\nInstead of loading all pending commits into memory as a single list, the list\nof files to load is the sole list which is passed around; .pendingset files are\nloaded and processed in isolation -and reloaded if necessary for any\nabort/rollback operation.\n\nThe parallel commit/abort/revert operations now work at the .pendingset level,\nrather than that of individual pending commit files. The existing parallelized\nTasks API is still used to commit those files, but with a null thread pool, so\nas to serialize the operations.\n\nChange-Id: I5c8240cd31800eaa83d112358770ca0eb2bca797\n",
      "commitDate": "04/10/19 10:54 AM",
      "commitName": "6574f27fa348542411bff888b184cd7ce34e5d9e",
      "commitAuthor": "Steve Loughran",
      "diff": "@@ -0,0 +1,8 @@\n+  public void setupJob(JobContext context) throws IOException {\n+    try (DurationInfo d \u003d new DurationInfo(LOG, \"preparing destination\")) {\n+      if (createJobMarker){\n+        commitOperations.deleteSuccessMarker(getOutputPath());\n+      }\n+      getDestFS().mkdirs(getOutputPath());\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void setupJob(JobContext context) throws IOException {\n    try (DurationInfo d \u003d new DurationInfo(LOG, \"preparing destination\")) {\n      if (createJobMarker){\n        commitOperations.deleteSuccessMarker(getOutputPath());\n      }\n      getDestFS().mkdirs(getOutputPath());\n    }\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/commit/AbstractS3ACommitter.java"
    }
  }
}