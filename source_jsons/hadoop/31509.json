{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "TimelineEntityReader.java",
  "functionName": "readEntities",
  "functionId": "readEntities___hbaseConf-Configuration__conn-Connection",
  "sourceFilePath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-client/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/reader/TimelineEntityReader.java",
  "functionStartLine": 271,
  "functionEndLine": 297,
  "numCommitsSeen": 22,
  "timeTaken": 4511,
  "changeHistory": [
    "2064ca015d1584263aac0cc20c60b925a3aff612",
    "9af30d46c6e82332a8eda20cb3eb5f987e25e7a2",
    "02a9710a099fc9572122d87dd3e90c78522f5836",
    "b01514f65bc6090a50a583f67d1ecb5d74b6d276",
    "c2efdc415a13496da43a9a8d13c73d88ca8565a1",
    "9cb1287e9b8425f91de925f411c3c2a8fa9fe2a3",
    "88f02941144824187b70fa2aaf0c6d90bcb77d8f",
    "1f710484e5b8ab4d5c67379c012004e8a4242d15",
    "0f44b5508d2ffcae08f130b6535a9832d37e2b38",
    "708fa8b1ae85b6efda318368bc0c0ba02d4958c8",
    "10fa6da7d8a6013698767c6136ae20f0e04415e9"
  ],
  "changeHistoryShort": {
    "2064ca015d1584263aac0cc20c60b925a3aff612": "Ybodychange",
    "9af30d46c6e82332a8eda20cb3eb5f987e25e7a2": "Yfilerename",
    "02a9710a099fc9572122d87dd3e90c78522f5836": "Ybodychange",
    "b01514f65bc6090a50a583f67d1ecb5d74b6d276": "Yfilerename",
    "c2efdc415a13496da43a9a8d13c73d88ca8565a1": "Ybodychange",
    "9cb1287e9b8425f91de925f411c3c2a8fa9fe2a3": "Ybodychange",
    "88f02941144824187b70fa2aaf0c6d90bcb77d8f": "Yfilerename",
    "1f710484e5b8ab4d5c67379c012004e8a4242d15": "Ybodychange",
    "0f44b5508d2ffcae08f130b6535a9832d37e2b38": "Ybodychange",
    "708fa8b1ae85b6efda318368bc0c0ba02d4958c8": "Ybodychange",
    "10fa6da7d8a6013698767c6136ae20f0e04415e9": "Yintroduced"
  },
  "changeHistoryDetails": {
    "2064ca015d1584263aac0cc20c60b925a3aff612": {
      "type": "Ybodychange",
      "commitMessage": "YARN-9349.  Changed logging to use slf4j api.\n            Contributed by Prabhu Joseph\n",
      "commitDate": "15/03/19 4:20 PM",
      "commitName": "2064ca015d1584263aac0cc20c60b925a3aff612",
      "commitAuthor": "Eric Yang",
      "commitDateOld": "20/03/18 7:41 PM",
      "commitNameOld": "29acea5000337a7f529bb1810a2af2b0af4d5f1d",
      "commitAuthorOld": "Rohith Sharma K S",
      "daysBetweenCommits": 359.86,
      "commitsBetweenForRepo": 3408,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,27 +1,27 @@\n   public Set\u003cTimelineEntity\u003e readEntities(Configuration hbaseConf,\n       Connection conn) throws IOException {\n     validateParams();\n     augmentParams(hbaseConf, conn);\n \n     Set\u003cTimelineEntity\u003e entities \u003d new LinkedHashSet\u003c\u003e();\n     FilterList filterList \u003d createFilterList();\n-    if (LOG.isDebugEnabled() \u0026\u0026 filterList !\u003d null) {\n-      LOG.debug(\"FilterList created for scan is - \" + filterList);\n+    if (filterList !\u003d null) {\n+      LOG.debug(\"FilterList created for scan is - {}\", filterList);\n     }\n     ResultScanner results \u003d getResults(hbaseConf, conn, filterList);\n     try {\n       for (Result result : results) {\n         TimelineEntity entity \u003d parseEntity(result);\n         if (entity \u003d\u003d null) {\n           continue;\n         }\n         entities.add(entity);\n         if (entities.size() \u003d\u003d filters.getLimit()) {\n           break;\n         }\n       }\n       return entities;\n     } finally {\n       results.close();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public Set\u003cTimelineEntity\u003e readEntities(Configuration hbaseConf,\n      Connection conn) throws IOException {\n    validateParams();\n    augmentParams(hbaseConf, conn);\n\n    Set\u003cTimelineEntity\u003e entities \u003d new LinkedHashSet\u003c\u003e();\n    FilterList filterList \u003d createFilterList();\n    if (filterList !\u003d null) {\n      LOG.debug(\"FilterList created for scan is - {}\", filterList);\n    }\n    ResultScanner results \u003d getResults(hbaseConf, conn, filterList);\n    try {\n      for (Result result : results) {\n        TimelineEntity entity \u003d parseEntity(result);\n        if (entity \u003d\u003d null) {\n          continue;\n        }\n        entities.add(entity);\n        if (entities.size() \u003d\u003d filters.getLimit()) {\n          break;\n        }\n      }\n      return entities;\n    } finally {\n      results.close();\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-client/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/reader/TimelineEntityReader.java",
      "extendedDetails": {}
    },
    "9af30d46c6e82332a8eda20cb3eb5f987e25e7a2": {
      "type": "Yfilerename",
      "commitMessage": "YARN-7919. Refactor timelineservice-hbase module into submodules. Contributed by Haibo Chen.\n",
      "commitDate": "17/02/18 7:00 AM",
      "commitName": "9af30d46c6e82332a8eda20cb3eb5f987e25e7a2",
      "commitAuthor": "Rohith Sharma K S",
      "commitDateOld": "17/02/18 3:24 AM",
      "commitNameOld": "a1e56a62863d8d494af309ec5f476c4b7e4d5ef9",
      "commitAuthorOld": "Arun Suresh",
      "daysBetweenCommits": 0.15,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public Set\u003cTimelineEntity\u003e readEntities(Configuration hbaseConf,\n      Connection conn) throws IOException {\n    validateParams();\n    augmentParams(hbaseConf, conn);\n\n    Set\u003cTimelineEntity\u003e entities \u003d new LinkedHashSet\u003c\u003e();\n    FilterList filterList \u003d createFilterList();\n    if (LOG.isDebugEnabled() \u0026\u0026 filterList !\u003d null) {\n      LOG.debug(\"FilterList created for scan is - \" + filterList);\n    }\n    ResultScanner results \u003d getResults(hbaseConf, conn, filterList);\n    try {\n      for (Result result : results) {\n        TimelineEntity entity \u003d parseEntity(result);\n        if (entity \u003d\u003d null) {\n          continue;\n        }\n        entities.add(entity);\n        if (entities.size() \u003d\u003d filters.getLimit()) {\n          break;\n        }\n      }\n      return entities;\n    } finally {\n      results.close();\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-client/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/reader/TimelineEntityReader.java",
      "extendedDetails": {
        "oldPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/reader/TimelineEntityReader.java",
        "newPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-client/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/reader/TimelineEntityReader.java"
      }
    },
    "02a9710a099fc9572122d87dd3e90c78522f5836": {
      "type": "Ybodychange",
      "commitMessage": "YARN-5585. [Atsv2] Reader side changes for entity prefix and support for pagination via additional filters (Rohith Sharma K S via Varun Saxena)\n",
      "commitDate": "29/08/17 10:59 PM",
      "commitName": "02a9710a099fc9572122d87dd3e90c78522f5836",
      "commitAuthor": "Varun Saxena",
      "commitDateOld": "29/08/17 10:59 PM",
      "commitNameOld": "4481561e4a3433197dd8e73f38856eef84f0fd03",
      "commitAuthorOld": "Sangjin Lee",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,33 +1,27 @@\n   public Set\u003cTimelineEntity\u003e readEntities(Configuration hbaseConf,\n       Connection conn) throws IOException {\n     validateParams();\n     augmentParams(hbaseConf, conn);\n \n-    NavigableSet\u003cTimelineEntity\u003e entities \u003d new TreeSet\u003c\u003e();\n+    Set\u003cTimelineEntity\u003e entities \u003d new LinkedHashSet\u003c\u003e();\n     FilterList filterList \u003d createFilterList();\n     if (LOG.isDebugEnabled() \u0026\u0026 filterList !\u003d null) {\n       LOG.debug(\"FilterList created for scan is - \" + filterList);\n     }\n     ResultScanner results \u003d getResults(hbaseConf, conn, filterList);\n     try {\n       for (Result result : results) {\n         TimelineEntity entity \u003d parseEntity(result);\n         if (entity \u003d\u003d null) {\n           continue;\n         }\n         entities.add(entity);\n-        if (!sortedKeys) {\n-          if (entities.size() \u003e filters.getLimit()) {\n-            entities.pollLast();\n-          }\n-        } else {\n-          if (entities.size() \u003d\u003d filters.getLimit()) {\n-            break;\n-          }\n+        if (entities.size() \u003d\u003d filters.getLimit()) {\n+          break;\n         }\n       }\n       return entities;\n     } finally {\n       results.close();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public Set\u003cTimelineEntity\u003e readEntities(Configuration hbaseConf,\n      Connection conn) throws IOException {\n    validateParams();\n    augmentParams(hbaseConf, conn);\n\n    Set\u003cTimelineEntity\u003e entities \u003d new LinkedHashSet\u003c\u003e();\n    FilterList filterList \u003d createFilterList();\n    if (LOG.isDebugEnabled() \u0026\u0026 filterList !\u003d null) {\n      LOG.debug(\"FilterList created for scan is - \" + filterList);\n    }\n    ResultScanner results \u003d getResults(hbaseConf, conn, filterList);\n    try {\n      for (Result result : results) {\n        TimelineEntity entity \u003d parseEntity(result);\n        if (entity \u003d\u003d null) {\n          continue;\n        }\n        entities.add(entity);\n        if (entities.size() \u003d\u003d filters.getLimit()) {\n          break;\n        }\n      }\n      return entities;\n    } finally {\n      results.close();\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/reader/TimelineEntityReader.java",
      "extendedDetails": {}
    },
    "b01514f65bc6090a50a583f67d1ecb5d74b6d276": {
      "type": "Yfilerename",
      "commitMessage": "YARN-5928. Move ATSv2 HBase backend code into a new module that is only dependent at runtime by yarn servers. Contributed by Haibo Chen.\n",
      "commitDate": "19/01/17 8:52 PM",
      "commitName": "b01514f65bc6090a50a583f67d1ecb5d74b6d276",
      "commitAuthor": "Sangjin Lee",
      "commitDateOld": "19/01/17 5:32 PM",
      "commitNameOld": "60865c8ea08053f3d6ac23f81c3376a3de3ca996",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 0.14,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public Set\u003cTimelineEntity\u003e readEntities(Configuration hbaseConf,\n      Connection conn) throws IOException {\n    validateParams();\n    augmentParams(hbaseConf, conn);\n\n    NavigableSet\u003cTimelineEntity\u003e entities \u003d new TreeSet\u003c\u003e();\n    FilterList filterList \u003d createFilterList();\n    if (LOG.isDebugEnabled() \u0026\u0026 filterList !\u003d null) {\n      LOG.debug(\"FilterList created for scan is - \" + filterList);\n    }\n    ResultScanner results \u003d getResults(hbaseConf, conn, filterList);\n    try {\n      for (Result result : results) {\n        TimelineEntity entity \u003d parseEntity(result);\n        if (entity \u003d\u003d null) {\n          continue;\n        }\n        entities.add(entity);\n        if (!sortedKeys) {\n          if (entities.size() \u003e filters.getLimit()) {\n            entities.pollLast();\n          }\n        } else {\n          if (entities.size() \u003d\u003d filters.getLimit()) {\n            break;\n          }\n        }\n      }\n      return entities;\n    } finally {\n      results.close();\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/reader/TimelineEntityReader.java",
      "extendedDetails": {
        "oldPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/reader/TimelineEntityReader.java",
        "newPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/reader/TimelineEntityReader.java"
      }
    },
    "c2efdc415a13496da43a9a8d13c73d88ca8565a1": {
      "type": "Ybodychange",
      "commitMessage": "YARN-3863. Support complex filters in TimelineReader (Varun Saxena via sjlee)\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "c2efdc415a13496da43a9a8d13c73d88ca8565a1",
      "commitAuthor": "Sangjin Lee",
      "commitDateOld": "10/07/16 8:45 AM",
      "commitNameOld": "960af7d4717b8a8949d0b2e43949e7daab45aa88",
      "commitAuthorOld": "Sangjin Lee",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 8,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,30 +1,33 @@\n   public Set\u003cTimelineEntity\u003e readEntities(Configuration hbaseConf,\n       Connection conn) throws IOException {\n     validateParams();\n     augmentParams(hbaseConf, conn);\n \n     NavigableSet\u003cTimelineEntity\u003e entities \u003d new TreeSet\u003c\u003e();\n-    FilterList filterList \u003d constructFilterListBasedOnFields();\n+    FilterList filterList \u003d createFilterList();\n+    if (LOG.isDebugEnabled() \u0026\u0026 filterList !\u003d null) {\n+      LOG.debug(\"FilterList created for scan is - \" + filterList);\n+    }\n     ResultScanner results \u003d getResults(hbaseConf, conn, filterList);\n     try {\n       for (Result result : results) {\n         TimelineEntity entity \u003d parseEntity(result);\n         if (entity \u003d\u003d null) {\n           continue;\n         }\n         entities.add(entity);\n         if (!sortedKeys) {\n           if (entities.size() \u003e filters.getLimit()) {\n             entities.pollLast();\n           }\n         } else {\n           if (entities.size() \u003d\u003d filters.getLimit()) {\n             break;\n           }\n         }\n       }\n       return entities;\n     } finally {\n       results.close();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public Set\u003cTimelineEntity\u003e readEntities(Configuration hbaseConf,\n      Connection conn) throws IOException {\n    validateParams();\n    augmentParams(hbaseConf, conn);\n\n    NavigableSet\u003cTimelineEntity\u003e entities \u003d new TreeSet\u003c\u003e();\n    FilterList filterList \u003d createFilterList();\n    if (LOG.isDebugEnabled() \u0026\u0026 filterList !\u003d null) {\n      LOG.debug(\"FilterList created for scan is - \" + filterList);\n    }\n    ResultScanner results \u003d getResults(hbaseConf, conn, filterList);\n    try {\n      for (Result result : results) {\n        TimelineEntity entity \u003d parseEntity(result);\n        if (entity \u003d\u003d null) {\n          continue;\n        }\n        entities.add(entity);\n        if (!sortedKeys) {\n          if (entities.size() \u003e filters.getLimit()) {\n            entities.pollLast();\n          }\n        } else {\n          if (entities.size() \u003d\u003d filters.getLimit()) {\n            break;\n          }\n        }\n      }\n      return entities;\n    } finally {\n      results.close();\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/reader/TimelineEntityReader.java",
      "extendedDetails": {}
    },
    "9cb1287e9b8425f91de925f411c3c2a8fa9fe2a3": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4446. Refactor reader API for better extensibility (Varun Saxena via sjlee)\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "9cb1287e9b8425f91de925f411c3c2a8fa9fe2a3",
      "commitAuthor": "Sangjin Lee",
      "commitDateOld": "10/07/16 8:45 AM",
      "commitNameOld": "6934b05c7117a12286fb2ba7a47f75e227cacb22",
      "commitAuthorOld": "Naganarasimha",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,30 +1,30 @@\n   public Set\u003cTimelineEntity\u003e readEntities(Configuration hbaseConf,\n       Connection conn) throws IOException {\n     validateParams();\n     augmentParams(hbaseConf, conn);\n \n     NavigableSet\u003cTimelineEntity\u003e entities \u003d new TreeSet\u003c\u003e();\n     FilterList filterList \u003d constructFilterListBasedOnFields();\n     ResultScanner results \u003d getResults(hbaseConf, conn, filterList);\n     try {\n       for (Result result : results) {\n         TimelineEntity entity \u003d parseEntity(result);\n         if (entity \u003d\u003d null) {\n           continue;\n         }\n         entities.add(entity);\n         if (!sortedKeys) {\n-          if (entities.size() \u003e limit) {\n+          if (entities.size() \u003e filters.getLimit()) {\n             entities.pollLast();\n           }\n         } else {\n-          if (entities.size() \u003d\u003d limit) {\n+          if (entities.size() \u003d\u003d filters.getLimit()) {\n             break;\n           }\n         }\n       }\n       return entities;\n     } finally {\n       results.close();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public Set\u003cTimelineEntity\u003e readEntities(Configuration hbaseConf,\n      Connection conn) throws IOException {\n    validateParams();\n    augmentParams(hbaseConf, conn);\n\n    NavigableSet\u003cTimelineEntity\u003e entities \u003d new TreeSet\u003c\u003e();\n    FilterList filterList \u003d constructFilterListBasedOnFields();\n    ResultScanner results \u003d getResults(hbaseConf, conn, filterList);\n    try {\n      for (Result result : results) {\n        TimelineEntity entity \u003d parseEntity(result);\n        if (entity \u003d\u003d null) {\n          continue;\n        }\n        entities.add(entity);\n        if (!sortedKeys) {\n          if (entities.size() \u003e filters.getLimit()) {\n            entities.pollLast();\n          }\n        } else {\n          if (entities.size() \u003d\u003d filters.getLimit()) {\n            break;\n          }\n        }\n      }\n      return entities;\n    } finally {\n      results.close();\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/reader/TimelineEntityReader.java",
      "extendedDetails": {}
    },
    "88f02941144824187b70fa2aaf0c6d90bcb77d8f": {
      "type": "Yfilerename",
      "commitMessage": "YARN-4200. Refactor reader classes in storage to nest under hbase\nspecific package name. Contributed by Li Lu.\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "88f02941144824187b70fa2aaf0c6d90bcb77d8f",
      "commitAuthor": "Li Lu",
      "commitDateOld": "10/07/16 8:45 AM",
      "commitNameOld": "cc16683cefe2611cf4de7819496aa54854f5394c",
      "commitAuthorOld": "Sangjin Lee",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public Set\u003cTimelineEntity\u003e readEntities(Configuration hbaseConf,\n      Connection conn) throws IOException {\n    validateParams();\n    augmentParams(hbaseConf, conn);\n\n    NavigableSet\u003cTimelineEntity\u003e entities \u003d new TreeSet\u003c\u003e();\n    FilterList filterList \u003d constructFilterListBasedOnFields();\n    ResultScanner results \u003d getResults(hbaseConf, conn, filterList);\n    try {\n      for (Result result : results) {\n        TimelineEntity entity \u003d parseEntity(result);\n        if (entity \u003d\u003d null) {\n          continue;\n        }\n        entities.add(entity);\n        if (!sortedKeys) {\n          if (entities.size() \u003e limit) {\n            entities.pollLast();\n          }\n        } else {\n          if (entities.size() \u003d\u003d limit) {\n            break;\n          }\n        }\n      }\n      return entities;\n    } finally {\n      results.close();\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/reader/TimelineEntityReader.java",
      "extendedDetails": {
        "oldPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/TimelineEntityReader.java",
        "newPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/reader/TimelineEntityReader.java"
      }
    },
    "1f710484e5b8ab4d5c67379c012004e8a4242d15": {
      "type": "Ybodychange",
      "commitMessage": "YARN-3862. Support for fetching specific configs and metrics based on prefixes (Varun Saxena via sjlee)\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "1f710484e5b8ab4d5c67379c012004e8a4242d15",
      "commitAuthor": "Sangjin Lee",
      "commitDateOld": "10/07/16 8:45 AM",
      "commitNameOld": "d014f2ffd24c1aaebda7503ce0e5a81334a5f266",
      "commitAuthorOld": "Li Lu",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 6,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,29 +1,30 @@\n   public Set\u003cTimelineEntity\u003e readEntities(Configuration hbaseConf,\n       Connection conn) throws IOException {\n     validateParams();\n     augmentParams(hbaseConf, conn);\n \n     NavigableSet\u003cTimelineEntity\u003e entities \u003d new TreeSet\u003c\u003e();\n-    ResultScanner results \u003d getResults(hbaseConf, conn);\n+    FilterList filterList \u003d constructFilterListBasedOnFields();\n+    ResultScanner results \u003d getResults(hbaseConf, conn, filterList);\n     try {\n       for (Result result : results) {\n         TimelineEntity entity \u003d parseEntity(result);\n         if (entity \u003d\u003d null) {\n           continue;\n         }\n         entities.add(entity);\n         if (!sortedKeys) {\n           if (entities.size() \u003e limit) {\n             entities.pollLast();\n           }\n         } else {\n           if (entities.size() \u003d\u003d limit) {\n             break;\n           }\n         }\n       }\n       return entities;\n     } finally {\n       results.close();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public Set\u003cTimelineEntity\u003e readEntities(Configuration hbaseConf,\n      Connection conn) throws IOException {\n    validateParams();\n    augmentParams(hbaseConf, conn);\n\n    NavigableSet\u003cTimelineEntity\u003e entities \u003d new TreeSet\u003c\u003e();\n    FilterList filterList \u003d constructFilterListBasedOnFields();\n    ResultScanner results \u003d getResults(hbaseConf, conn, filterList);\n    try {\n      for (Result result : results) {\n        TimelineEntity entity \u003d parseEntity(result);\n        if (entity \u003d\u003d null) {\n          continue;\n        }\n        entities.add(entity);\n        if (!sortedKeys) {\n          if (entities.size() \u003e limit) {\n            entities.pollLast();\n          }\n        } else {\n          if (entities.size() \u003d\u003d limit) {\n            break;\n          }\n        }\n      }\n      return entities;\n    } finally {\n      results.close();\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/TimelineEntityReader.java",
      "extendedDetails": {}
    },
    "0f44b5508d2ffcae08f130b6535a9832d37e2b38": {
      "type": "Ybodychange",
      "commitMessage": "YARN-3864. Implement support for querying single app and all apps for a flow run (Varun Saxena via sjlee)\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "0f44b5508d2ffcae08f130b6535a9832d37e2b38",
      "commitAuthor": "Sangjin Lee",
      "commitDateOld": "10/07/16 8:45 AM",
      "commitNameOld": "708fa8b1ae85b6efda318368bc0c0ba02d4958c8",
      "commitAuthorOld": "Vrushali Channapattan",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,29 @@\n   public Set\u003cTimelineEntity\u003e readEntities(Configuration hbaseConf,\n       Connection conn) throws IOException {\n     validateParams();\n     augmentParams(hbaseConf, conn);\n \n     NavigableSet\u003cTimelineEntity\u003e entities \u003d new TreeSet\u003c\u003e();\n     ResultScanner results \u003d getResults(hbaseConf, conn);\n     try {\n       for (Result result : results) {\n         TimelineEntity entity \u003d parseEntity(result);\n         if (entity \u003d\u003d null) {\n           continue;\n         }\n         entities.add(entity);\n-        if (entities.size() \u003e limit) {\n-          entities.pollLast();\n+        if (!sortedKeys) {\n+          if (entities.size() \u003e limit) {\n+            entities.pollLast();\n+          }\n+        } else {\n+          if (entities.size() \u003d\u003d limit) {\n+            break;\n+          }\n         }\n       }\n       return entities;\n     } finally {\n       results.close();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public Set\u003cTimelineEntity\u003e readEntities(Configuration hbaseConf,\n      Connection conn) throws IOException {\n    validateParams();\n    augmentParams(hbaseConf, conn);\n\n    NavigableSet\u003cTimelineEntity\u003e entities \u003d new TreeSet\u003c\u003e();\n    ResultScanner results \u003d getResults(hbaseConf, conn);\n    try {\n      for (Result result : results) {\n        TimelineEntity entity \u003d parseEntity(result);\n        if (entity \u003d\u003d null) {\n          continue;\n        }\n        entities.add(entity);\n        if (!sortedKeys) {\n          if (entities.size() \u003e limit) {\n            entities.pollLast();\n          }\n        } else {\n          if (entities.size() \u003d\u003d limit) {\n            break;\n          }\n        }\n      }\n      return entities;\n    } finally {\n      results.close();\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/TimelineEntityReader.java",
      "extendedDetails": {}
    },
    "708fa8b1ae85b6efda318368bc0c0ba02d4958c8": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4210. HBase reader throws NPE if Get returns no rows (Varun Saxena via vrushali)\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "708fa8b1ae85b6efda318368bc0c0ba02d4958c8",
      "commitAuthor": "Vrushali Channapattan",
      "commitDateOld": "10/07/16 8:45 AM",
      "commitNameOld": "10fa6da7d8a6013698767c6136ae20f0e04415e9",
      "commitAuthorOld": "Vrushali",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,19 +1,23 @@\n   public Set\u003cTimelineEntity\u003e readEntities(Configuration hbaseConf,\n       Connection conn) throws IOException {\n     validateParams();\n     augmentParams(hbaseConf, conn);\n \n     NavigableSet\u003cTimelineEntity\u003e entities \u003d new TreeSet\u003c\u003e();\n-    Iterable\u003cResult\u003e results \u003d getResults(hbaseConf, conn);\n-    for (Result result : results) {\n-      TimelineEntity entity \u003d parseEntity(result);\n-      if (entity \u003d\u003d null) {\n-        continue;\n+    ResultScanner results \u003d getResults(hbaseConf, conn);\n+    try {\n+      for (Result result : results) {\n+        TimelineEntity entity \u003d parseEntity(result);\n+        if (entity \u003d\u003d null) {\n+          continue;\n+        }\n+        entities.add(entity);\n+        if (entities.size() \u003e limit) {\n+          entities.pollLast();\n+        }\n       }\n-      entities.add(entity);\n-      if (entities.size() \u003e limit) {\n-        entities.pollLast();\n-      }\n+      return entities;\n+    } finally {\n+      results.close();\n     }\n-    return entities;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public Set\u003cTimelineEntity\u003e readEntities(Configuration hbaseConf,\n      Connection conn) throws IOException {\n    validateParams();\n    augmentParams(hbaseConf, conn);\n\n    NavigableSet\u003cTimelineEntity\u003e entities \u003d new TreeSet\u003c\u003e();\n    ResultScanner results \u003d getResults(hbaseConf, conn);\n    try {\n      for (Result result : results) {\n        TimelineEntity entity \u003d parseEntity(result);\n        if (entity \u003d\u003d null) {\n          continue;\n        }\n        entities.add(entity);\n        if (entities.size() \u003e limit) {\n          entities.pollLast();\n        }\n      }\n      return entities;\n    } finally {\n      results.close();\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/TimelineEntityReader.java",
      "extendedDetails": {}
    },
    "10fa6da7d8a6013698767c6136ae20f0e04415e9": {
      "type": "Yintroduced",
      "commitMessage": "YARN-4074. [timeline reader] implement support for querying for flows and flow runs (sjlee via vrushali)\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "10fa6da7d8a6013698767c6136ae20f0e04415e9",
      "commitAuthor": "Vrushali",
      "diff": "@@ -0,0 +1,19 @@\n+  public Set\u003cTimelineEntity\u003e readEntities(Configuration hbaseConf,\n+      Connection conn) throws IOException {\n+    validateParams();\n+    augmentParams(hbaseConf, conn);\n+\n+    NavigableSet\u003cTimelineEntity\u003e entities \u003d new TreeSet\u003c\u003e();\n+    Iterable\u003cResult\u003e results \u003d getResults(hbaseConf, conn);\n+    for (Result result : results) {\n+      TimelineEntity entity \u003d parseEntity(result);\n+      if (entity \u003d\u003d null) {\n+        continue;\n+      }\n+      entities.add(entity);\n+      if (entities.size() \u003e limit) {\n+        entities.pollLast();\n+      }\n+    }\n+    return entities;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public Set\u003cTimelineEntity\u003e readEntities(Configuration hbaseConf,\n      Connection conn) throws IOException {\n    validateParams();\n    augmentParams(hbaseConf, conn);\n\n    NavigableSet\u003cTimelineEntity\u003e entities \u003d new TreeSet\u003c\u003e();\n    Iterable\u003cResult\u003e results \u003d getResults(hbaseConf, conn);\n    for (Result result : results) {\n      TimelineEntity entity \u003d parseEntity(result);\n      if (entity \u003d\u003d null) {\n        continue;\n      }\n      entities.add(entity);\n      if (entities.size() \u003e limit) {\n        entities.pollLast();\n      }\n    }\n    return entities;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/TimelineEntityReader.java"
    }
  }
}