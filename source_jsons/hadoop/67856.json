{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "RegexCopyFilter.java",
  "functionName": "initialize",
  "functionId": "initialize",
  "sourceFilePath": "hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/RegexCopyFilter.java",
  "functionStartLine": 63,
  "functionEndLine": 82,
  "numCommitsSeen": 4,
  "timeTaken": 1467,
  "changeHistory": [
    "7a3188d054481b9bd563e337901e93476303ce7f",
    "3e3963b035911703c61e6d9a2939eb894da5644c",
    "0790275f058b0cf41780ad337c9150a1e8ebebc6"
  ],
  "changeHistoryShort": {
    "7a3188d054481b9bd563e337901e93476303ce7f": "Ybodychange",
    "3e3963b035911703c61e6d9a2939eb894da5644c": "Ybodychange",
    "0790275f058b0cf41780ad337c9150a1e8ebebc6": "Yintroduced"
  },
  "changeHistoryDetails": {
    "7a3188d054481b9bd563e337901e93476303ce7f": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-16282. Avoid FileStream to improve performance. Contributed by Ayush Saxena.\n",
      "commitDate": "02/05/19 12:58 PM",
      "commitName": "7a3188d054481b9bd563e337901e93476303ce7f",
      "commitAuthor": "Giovanni Matteo Fumarola",
      "commitDateOld": "15/08/18 8:31 AM",
      "commitNameOld": "3e3963b035911703c61e6d9a2939eb894da5644c",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 260.19,
      "commitsBetweenForRepo": 1997,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,20 @@\n   public void initialize() {\n     BufferedReader reader \u003d null;\n     try {\n-      InputStream is \u003d new FileInputStream(filtersFile);\n+      InputStream is \u003d Files.newInputStream(filtersFile.toPath());\n       reader \u003d new BufferedReader(new InputStreamReader(is,\n           Charset.forName(\"UTF-8\")));\n       String line;\n       while ((line \u003d reader.readLine()) !\u003d null) {\n         Pattern pattern \u003d Pattern.compile(line);\n         filters.add(pattern);\n       }\n     } catch (FileNotFoundException notFound) {\n       LOG.error(\"Can\u0027t find filters file \" + filtersFile);\n     } catch (IOException cantRead) {\n       LOG.error(\"An error occurred while attempting to read from \" +\n           filtersFile);\n     } finally {\n       IOUtils.cleanupWithLogger(LOG, reader);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void initialize() {\n    BufferedReader reader \u003d null;\n    try {\n      InputStream is \u003d Files.newInputStream(filtersFile.toPath());\n      reader \u003d new BufferedReader(new InputStreamReader(is,\n          Charset.forName(\"UTF-8\")));\n      String line;\n      while ((line \u003d reader.readLine()) !\u003d null) {\n        Pattern pattern \u003d Pattern.compile(line);\n        filters.add(pattern);\n      }\n    } catch (FileNotFoundException notFound) {\n      LOG.error(\"Can\u0027t find filters file \" + filtersFile);\n    } catch (IOException cantRead) {\n      LOG.error(\"An error occurred while attempting to read from \" +\n          filtersFile);\n    } finally {\n      IOUtils.cleanupWithLogger(LOG, reader);\n    }\n  }",
      "path": "hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/RegexCopyFilter.java",
      "extendedDetails": {}
    },
    "3e3963b035911703c61e6d9a2939eb894da5644c": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-15552. Move logging APIs over to slf4j in hadoop-tools - Part2. Contributed by Ian Pickering.\n",
      "commitDate": "15/08/18 8:31 AM",
      "commitName": "3e3963b035911703c61e6d9a2939eb894da5644c",
      "commitAuthor": "Akira Ajisaka",
      "commitDateOld": "11/01/16 9:46 AM",
      "commitNameOld": "95f32015ad9273420299130a9f10acdbafe63556",
      "commitAuthorOld": "Zhe Zhang",
      "daysBetweenCommits": 946.91,
      "commitsBetweenForRepo": 7074,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,20 @@\n   public void initialize() {\n     BufferedReader reader \u003d null;\n     try {\n       InputStream is \u003d new FileInputStream(filtersFile);\n       reader \u003d new BufferedReader(new InputStreamReader(is,\n           Charset.forName(\"UTF-8\")));\n       String line;\n       while ((line \u003d reader.readLine()) !\u003d null) {\n         Pattern pattern \u003d Pattern.compile(line);\n         filters.add(pattern);\n       }\n     } catch (FileNotFoundException notFound) {\n       LOG.error(\"Can\u0027t find filters file \" + filtersFile);\n     } catch (IOException cantRead) {\n       LOG.error(\"An error occurred while attempting to read from \" +\n           filtersFile);\n     } finally {\n-      IOUtils.cleanup(LOG, reader);\n+      IOUtils.cleanupWithLogger(LOG, reader);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void initialize() {\n    BufferedReader reader \u003d null;\n    try {\n      InputStream is \u003d new FileInputStream(filtersFile);\n      reader \u003d new BufferedReader(new InputStreamReader(is,\n          Charset.forName(\"UTF-8\")));\n      String line;\n      while ((line \u003d reader.readLine()) !\u003d null) {\n        Pattern pattern \u003d Pattern.compile(line);\n        filters.add(pattern);\n      }\n    } catch (FileNotFoundException notFound) {\n      LOG.error(\"Can\u0027t find filters file \" + filtersFile);\n    } catch (IOException cantRead) {\n      LOG.error(\"An error occurred while attempting to read from \" +\n          filtersFile);\n    } finally {\n      IOUtils.cleanupWithLogger(LOG, reader);\n    }\n  }",
      "path": "hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/RegexCopyFilter.java",
      "extendedDetails": {}
    },
    "0790275f058b0cf41780ad337c9150a1e8ebebc6": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-1540. Support file exclusion list in distcp. Contributed by Rich Haase.\n",
      "commitDate": "18/05/15 1:24 PM",
      "commitName": "0790275f058b0cf41780ad337c9150a1e8ebebc6",
      "commitAuthor": "Jing Zhao",
      "diff": "@@ -0,0 +1,20 @@\n+  public void initialize() {\n+    BufferedReader reader \u003d null;\n+    try {\n+      InputStream is \u003d new FileInputStream(filtersFile);\n+      reader \u003d new BufferedReader(new InputStreamReader(is,\n+          Charset.forName(\"UTF-8\")));\n+      String line;\n+      while ((line \u003d reader.readLine()) !\u003d null) {\n+        Pattern pattern \u003d Pattern.compile(line);\n+        filters.add(pattern);\n+      }\n+    } catch (FileNotFoundException notFound) {\n+      LOG.error(\"Can\u0027t find filters file \" + filtersFile);\n+    } catch (IOException cantRead) {\n+      LOG.error(\"An error occurred while attempting to read from \" +\n+          filtersFile);\n+    } finally {\n+      IOUtils.cleanup(LOG, reader);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void initialize() {\n    BufferedReader reader \u003d null;\n    try {\n      InputStream is \u003d new FileInputStream(filtersFile);\n      reader \u003d new BufferedReader(new InputStreamReader(is,\n          Charset.forName(\"UTF-8\")));\n      String line;\n      while ((line \u003d reader.readLine()) !\u003d null) {\n        Pattern pattern \u003d Pattern.compile(line);\n        filters.add(pattern);\n      }\n    } catch (FileNotFoundException notFound) {\n      LOG.error(\"Can\u0027t find filters file \" + filtersFile);\n    } catch (IOException cantRead) {\n      LOG.error(\"An error occurred while attempting to read from \" +\n          filtersFile);\n    } finally {\n      IOUtils.cleanup(LOG, reader);\n    }\n  }",
      "path": "hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/RegexCopyFilter.java"
    }
  }
}