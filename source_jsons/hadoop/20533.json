{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DelegatingInputFormat.java",
  "functionName": "getSplits",
  "functionId": "getSplits___conf-JobConf__numSplits-int",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/lib/DelegatingInputFormat.java",
  "functionStartLine": 51,
  "functionEndLine": 116,
  "numCommitsSeen": 4,
  "timeTaken": 4194,
  "changeHistory": [
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public InputSplit[] getSplits(JobConf conf, int numSplits) throws IOException {\n\n    JobConf confCopy \u003d new JobConf(conf);\n    List\u003cInputSplit\u003e splits \u003d new ArrayList\u003cInputSplit\u003e();\n    Map\u003cPath, InputFormat\u003e formatMap \u003d MultipleInputs.getInputFormatMap(conf);\n    Map\u003cPath, Class\u003c? extends Mapper\u003e\u003e mapperMap \u003d MultipleInputs\n       .getMapperTypeMap(conf);\n    Map\u003cClass\u003c? extends InputFormat\u003e, List\u003cPath\u003e\u003e formatPaths\n        \u003d new HashMap\u003cClass\u003c? extends InputFormat\u003e, List\u003cPath\u003e\u003e();\n\n    // First, build a map of InputFormats to Paths\n    for (Entry\u003cPath, InputFormat\u003e entry : formatMap.entrySet()) {\n      if (!formatPaths.containsKey(entry.getValue().getClass())) {\n       formatPaths.put(entry.getValue().getClass(), new LinkedList\u003cPath\u003e());\n      }\n\n      formatPaths.get(entry.getValue().getClass()).add(entry.getKey());\n    }\n\n    for (Entry\u003cClass\u003c? extends InputFormat\u003e, List\u003cPath\u003e\u003e formatEntry : \n        formatPaths.entrySet()) {\n      Class\u003c? extends InputFormat\u003e formatClass \u003d formatEntry.getKey();\n      InputFormat format \u003d (InputFormat) ReflectionUtils.newInstance(\n         formatClass, conf);\n      List\u003cPath\u003e paths \u003d formatEntry.getValue();\n\n      Map\u003cClass\u003c? extends Mapper\u003e, List\u003cPath\u003e\u003e mapperPaths\n          \u003d new HashMap\u003cClass\u003c? extends Mapper\u003e, List\u003cPath\u003e\u003e();\n\n      // Now, for each set of paths that have a common InputFormat, build\n      // a map of Mappers to the paths they\u0027re used for\n      for (Path path : paths) {\n       Class\u003c? extends Mapper\u003e mapperClass \u003d mapperMap.get(path);\n       if (!mapperPaths.containsKey(mapperClass)) {\n         mapperPaths.put(mapperClass, new LinkedList\u003cPath\u003e());\n       }\n\n       mapperPaths.get(mapperClass).add(path);\n      }\n\n      // Now each set of paths that has a common InputFormat and Mapper can\n      // be added to the same job, and split together.\n      for (Entry\u003cClass\u003c? extends Mapper\u003e, List\u003cPath\u003e\u003e mapEntry : mapperPaths\n         .entrySet()) {\n       paths \u003d mapEntry.getValue();\n       Class\u003c? extends Mapper\u003e mapperClass \u003d mapEntry.getKey();\n\n       if (mapperClass \u003d\u003d null) {\n         mapperClass \u003d conf.getMapperClass();\n       }\n\n       FileInputFormat.setInputPaths(confCopy, paths.toArray(new Path[paths\n           .size()]));\n\n       // Get splits for each input path and tag with InputFormat\n       // and Mapper types by wrapping in a TaggedInputSplit.\n       InputSplit[] pathSplits \u003d format.getSplits(confCopy, numSplits);\n       for (InputSplit pathSplit : pathSplits) {\n         splits.add(new TaggedInputSplit(pathSplit, conf, format.getClass(),\n             mapperClass));\n       }\n      }\n    }\n\n    return splits.toArray(new InputSplit[splits.size()]);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/lib/DelegatingInputFormat.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/lib/DelegatingInputFormat.java",
        "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/lib/DelegatingInputFormat.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yfilerename",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "17/08/11 8:02 PM",
      "commitNameOld": "dd86860633d2ed64705b669a75bf318442ed6225",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 0.34,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public InputSplit[] getSplits(JobConf conf, int numSplits) throws IOException {\n\n    JobConf confCopy \u003d new JobConf(conf);\n    List\u003cInputSplit\u003e splits \u003d new ArrayList\u003cInputSplit\u003e();\n    Map\u003cPath, InputFormat\u003e formatMap \u003d MultipleInputs.getInputFormatMap(conf);\n    Map\u003cPath, Class\u003c? extends Mapper\u003e\u003e mapperMap \u003d MultipleInputs\n       .getMapperTypeMap(conf);\n    Map\u003cClass\u003c? extends InputFormat\u003e, List\u003cPath\u003e\u003e formatPaths\n        \u003d new HashMap\u003cClass\u003c? extends InputFormat\u003e, List\u003cPath\u003e\u003e();\n\n    // First, build a map of InputFormats to Paths\n    for (Entry\u003cPath, InputFormat\u003e entry : formatMap.entrySet()) {\n      if (!formatPaths.containsKey(entry.getValue().getClass())) {\n       formatPaths.put(entry.getValue().getClass(), new LinkedList\u003cPath\u003e());\n      }\n\n      formatPaths.get(entry.getValue().getClass()).add(entry.getKey());\n    }\n\n    for (Entry\u003cClass\u003c? extends InputFormat\u003e, List\u003cPath\u003e\u003e formatEntry : \n        formatPaths.entrySet()) {\n      Class\u003c? extends InputFormat\u003e formatClass \u003d formatEntry.getKey();\n      InputFormat format \u003d (InputFormat) ReflectionUtils.newInstance(\n         formatClass, conf);\n      List\u003cPath\u003e paths \u003d formatEntry.getValue();\n\n      Map\u003cClass\u003c? extends Mapper\u003e, List\u003cPath\u003e\u003e mapperPaths\n          \u003d new HashMap\u003cClass\u003c? extends Mapper\u003e, List\u003cPath\u003e\u003e();\n\n      // Now, for each set of paths that have a common InputFormat, build\n      // a map of Mappers to the paths they\u0027re used for\n      for (Path path : paths) {\n       Class\u003c? extends Mapper\u003e mapperClass \u003d mapperMap.get(path);\n       if (!mapperPaths.containsKey(mapperClass)) {\n         mapperPaths.put(mapperClass, new LinkedList\u003cPath\u003e());\n       }\n\n       mapperPaths.get(mapperClass).add(path);\n      }\n\n      // Now each set of paths that has a common InputFormat and Mapper can\n      // be added to the same job, and split together.\n      for (Entry\u003cClass\u003c? extends Mapper\u003e, List\u003cPath\u003e\u003e mapEntry : mapperPaths\n         .entrySet()) {\n       paths \u003d mapEntry.getValue();\n       Class\u003c? extends Mapper\u003e mapperClass \u003d mapEntry.getKey();\n\n       if (mapperClass \u003d\u003d null) {\n         mapperClass \u003d conf.getMapperClass();\n       }\n\n       FileInputFormat.setInputPaths(confCopy, paths.toArray(new Path[paths\n           .size()]));\n\n       // Get splits for each input path and tag with InputFormat\n       // and Mapper types by wrapping in a TaggedInputSplit.\n       InputSplit[] pathSplits \u003d format.getSplits(confCopy, numSplits);\n       for (InputSplit pathSplit : pathSplits) {\n         splits.add(new TaggedInputSplit(pathSplit, conf, format.getClass(),\n             mapperClass));\n       }\n      }\n    }\n\n    return splits.toArray(new InputSplit[splits.size()]);\n  }",
      "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/lib/DelegatingInputFormat.java",
      "extendedDetails": {
        "oldPath": "mapreduce/src/java/org/apache/hadoop/mapred/lib/DelegatingInputFormat.java",
        "newPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/lib/DelegatingInputFormat.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,66 @@\n+  public InputSplit[] getSplits(JobConf conf, int numSplits) throws IOException {\n+\n+    JobConf confCopy \u003d new JobConf(conf);\n+    List\u003cInputSplit\u003e splits \u003d new ArrayList\u003cInputSplit\u003e();\n+    Map\u003cPath, InputFormat\u003e formatMap \u003d MultipleInputs.getInputFormatMap(conf);\n+    Map\u003cPath, Class\u003c? extends Mapper\u003e\u003e mapperMap \u003d MultipleInputs\n+       .getMapperTypeMap(conf);\n+    Map\u003cClass\u003c? extends InputFormat\u003e, List\u003cPath\u003e\u003e formatPaths\n+        \u003d new HashMap\u003cClass\u003c? extends InputFormat\u003e, List\u003cPath\u003e\u003e();\n+\n+    // First, build a map of InputFormats to Paths\n+    for (Entry\u003cPath, InputFormat\u003e entry : formatMap.entrySet()) {\n+      if (!formatPaths.containsKey(entry.getValue().getClass())) {\n+       formatPaths.put(entry.getValue().getClass(), new LinkedList\u003cPath\u003e());\n+      }\n+\n+      formatPaths.get(entry.getValue().getClass()).add(entry.getKey());\n+    }\n+\n+    for (Entry\u003cClass\u003c? extends InputFormat\u003e, List\u003cPath\u003e\u003e formatEntry : \n+        formatPaths.entrySet()) {\n+      Class\u003c? extends InputFormat\u003e formatClass \u003d formatEntry.getKey();\n+      InputFormat format \u003d (InputFormat) ReflectionUtils.newInstance(\n+         formatClass, conf);\n+      List\u003cPath\u003e paths \u003d formatEntry.getValue();\n+\n+      Map\u003cClass\u003c? extends Mapper\u003e, List\u003cPath\u003e\u003e mapperPaths\n+          \u003d new HashMap\u003cClass\u003c? extends Mapper\u003e, List\u003cPath\u003e\u003e();\n+\n+      // Now, for each set of paths that have a common InputFormat, build\n+      // a map of Mappers to the paths they\u0027re used for\n+      for (Path path : paths) {\n+       Class\u003c? extends Mapper\u003e mapperClass \u003d mapperMap.get(path);\n+       if (!mapperPaths.containsKey(mapperClass)) {\n+         mapperPaths.put(mapperClass, new LinkedList\u003cPath\u003e());\n+       }\n+\n+       mapperPaths.get(mapperClass).add(path);\n+      }\n+\n+      // Now each set of paths that has a common InputFormat and Mapper can\n+      // be added to the same job, and split together.\n+      for (Entry\u003cClass\u003c? extends Mapper\u003e, List\u003cPath\u003e\u003e mapEntry : mapperPaths\n+         .entrySet()) {\n+       paths \u003d mapEntry.getValue();\n+       Class\u003c? extends Mapper\u003e mapperClass \u003d mapEntry.getKey();\n+\n+       if (mapperClass \u003d\u003d null) {\n+         mapperClass \u003d conf.getMapperClass();\n+       }\n+\n+       FileInputFormat.setInputPaths(confCopy, paths.toArray(new Path[paths\n+           .size()]));\n+\n+       // Get splits for each input path and tag with InputFormat\n+       // and Mapper types by wrapping in a TaggedInputSplit.\n+       InputSplit[] pathSplits \u003d format.getSplits(confCopy, numSplits);\n+       for (InputSplit pathSplit : pathSplits) {\n+         splits.add(new TaggedInputSplit(pathSplit, conf, format.getClass(),\n+             mapperClass));\n+       }\n+      }\n+    }\n+\n+    return splits.toArray(new InputSplit[splits.size()]);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public InputSplit[] getSplits(JobConf conf, int numSplits) throws IOException {\n\n    JobConf confCopy \u003d new JobConf(conf);\n    List\u003cInputSplit\u003e splits \u003d new ArrayList\u003cInputSplit\u003e();\n    Map\u003cPath, InputFormat\u003e formatMap \u003d MultipleInputs.getInputFormatMap(conf);\n    Map\u003cPath, Class\u003c? extends Mapper\u003e\u003e mapperMap \u003d MultipleInputs\n       .getMapperTypeMap(conf);\n    Map\u003cClass\u003c? extends InputFormat\u003e, List\u003cPath\u003e\u003e formatPaths\n        \u003d new HashMap\u003cClass\u003c? extends InputFormat\u003e, List\u003cPath\u003e\u003e();\n\n    // First, build a map of InputFormats to Paths\n    for (Entry\u003cPath, InputFormat\u003e entry : formatMap.entrySet()) {\n      if (!formatPaths.containsKey(entry.getValue().getClass())) {\n       formatPaths.put(entry.getValue().getClass(), new LinkedList\u003cPath\u003e());\n      }\n\n      formatPaths.get(entry.getValue().getClass()).add(entry.getKey());\n    }\n\n    for (Entry\u003cClass\u003c? extends InputFormat\u003e, List\u003cPath\u003e\u003e formatEntry : \n        formatPaths.entrySet()) {\n      Class\u003c? extends InputFormat\u003e formatClass \u003d formatEntry.getKey();\n      InputFormat format \u003d (InputFormat) ReflectionUtils.newInstance(\n         formatClass, conf);\n      List\u003cPath\u003e paths \u003d formatEntry.getValue();\n\n      Map\u003cClass\u003c? extends Mapper\u003e, List\u003cPath\u003e\u003e mapperPaths\n          \u003d new HashMap\u003cClass\u003c? extends Mapper\u003e, List\u003cPath\u003e\u003e();\n\n      // Now, for each set of paths that have a common InputFormat, build\n      // a map of Mappers to the paths they\u0027re used for\n      for (Path path : paths) {\n       Class\u003c? extends Mapper\u003e mapperClass \u003d mapperMap.get(path);\n       if (!mapperPaths.containsKey(mapperClass)) {\n         mapperPaths.put(mapperClass, new LinkedList\u003cPath\u003e());\n       }\n\n       mapperPaths.get(mapperClass).add(path);\n      }\n\n      // Now each set of paths that has a common InputFormat and Mapper can\n      // be added to the same job, and split together.\n      for (Entry\u003cClass\u003c? extends Mapper\u003e, List\u003cPath\u003e\u003e mapEntry : mapperPaths\n         .entrySet()) {\n       paths \u003d mapEntry.getValue();\n       Class\u003c? extends Mapper\u003e mapperClass \u003d mapEntry.getKey();\n\n       if (mapperClass \u003d\u003d null) {\n         mapperClass \u003d conf.getMapperClass();\n       }\n\n       FileInputFormat.setInputPaths(confCopy, paths.toArray(new Path[paths\n           .size()]));\n\n       // Get splits for each input path and tag with InputFormat\n       // and Mapper types by wrapping in a TaggedInputSplit.\n       InputSplit[] pathSplits \u003d format.getSplits(confCopy, numSplits);\n       for (InputSplit pathSplit : pathSplits) {\n         splits.add(new TaggedInputSplit(pathSplit, conf, format.getClass(),\n             mapperClass));\n       }\n      }\n    }\n\n    return splits.toArray(new InputSplit[splits.size()]);\n  }",
      "path": "mapreduce/src/java/org/apache/hadoop/mapred/lib/DelegatingInputFormat.java"
    }
  }
}