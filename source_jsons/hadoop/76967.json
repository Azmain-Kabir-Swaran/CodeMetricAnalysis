{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ErasureDecoder.java",
  "functionName": "getOutputBlocks",
  "functionId": "getOutputBlocks___blockGroup-ECBlockGroup",
  "sourceFilePath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/coder/ErasureDecoder.java",
  "functionStartLine": 89,
  "functionEndLine": 107,
  "numCommitsSeen": 11,
  "timeTaken": 2853,
  "changeHistory": [
    "c023c748869063fb67d14ea996569c42578d1cea",
    "c201cf951d5adefefe7c68e882a0c07962248577",
    "b64f6745a45754dcf79c9c2626f3db7db2f33858",
    "8f89d7489df0d5c8236a1929c93e3f5ab7149031"
  ],
  "changeHistoryShort": {
    "c023c748869063fb67d14ea996569c42578d1cea": "Yfilerename",
    "c201cf951d5adefefe7c68e882a0c07962248577": "Ybodychange",
    "b64f6745a45754dcf79c9c2626f3db7db2f33858": "Ybodychange",
    "8f89d7489df0d5c8236a1929c93e3f5ab7149031": "Yintroduced"
  },
  "changeHistoryDetails": {
    "c023c748869063fb67d14ea996569c42578d1cea": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-13061. Refactor erasure coders. Contributed by Kai Sasaki\n",
      "commitDate": "17/10/16 11:02 PM",
      "commitName": "c023c748869063fb67d14ea996569c42578d1cea",
      "commitAuthor": "Kai Zheng",
      "commitDateOld": "17/10/16 11:00 PM",
      "commitNameOld": "bedfec0c10144087168bc79501ffd5ab4fa52606",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  protected ECBlock[] getOutputBlocks(ECBlockGroup blockGroup) {\n    ECBlock[] outputBlocks \u003d new ECBlock[getNumErasedBlocks(blockGroup)];\n\n    int idx \u003d 0;\n\n    for (int i \u003d 0; i \u003c getNumDataUnits(); i++) {\n      if (blockGroup.getDataBlocks()[i].isErased()) {\n        outputBlocks[idx++] \u003d blockGroup.getDataBlocks()[i];\n      }\n    }\n\n    for (int i \u003d 0; i \u003c getNumParityUnits(); i++) {\n      if (blockGroup.getParityBlocks()[i].isErased()) {\n        outputBlocks[idx++] \u003d blockGroup.getParityBlocks()[i];\n      }\n    }\n\n    return outputBlocks;\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/coder/ErasureDecoder.java",
      "extendedDetails": {
        "oldPath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/coder/AbstractErasureDecoder.java",
        "newPath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/coder/ErasureDecoder.java"
      }
    },
    "c201cf951d5adefefe7c68e882a0c07962248577": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-12040. Adjust inputs order for the decode API in raw erasure coder. (Kai Zheng via yliu)\n",
      "commitDate": "28/10/15 1:18 AM",
      "commitName": "c201cf951d5adefefe7c68e882a0c07962248577",
      "commitAuthor": "yliu",
      "commitDateOld": "07/10/15 6:12 PM",
      "commitNameOld": "66e2cfa1a0285f2b4f62a4ffb4d5c1ee54f76156",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 20.3,
      "commitsBetweenForRepo": 184,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,19 +1,19 @@\n   protected ECBlock[] getOutputBlocks(ECBlockGroup blockGroup) {\n     ECBlock[] outputBlocks \u003d new ECBlock[getNumErasedBlocks(blockGroup)];\n \n     int idx \u003d 0;\n \n-    for (int i \u003d 0; i \u003c getNumParityUnits(); i++) {\n-      if (blockGroup.getParityBlocks()[i].isErased()) {\n-        outputBlocks[idx++] \u003d blockGroup.getParityBlocks()[i];\n-      }\n-    }\n-\n     for (int i \u003d 0; i \u003c getNumDataUnits(); i++) {\n       if (blockGroup.getDataBlocks()[i].isErased()) {\n         outputBlocks[idx++] \u003d blockGroup.getDataBlocks()[i];\n       }\n     }\n \n+    for (int i \u003d 0; i \u003c getNumParityUnits(); i++) {\n+      if (blockGroup.getParityBlocks()[i].isErased()) {\n+        outputBlocks[idx++] \u003d blockGroup.getParityBlocks()[i];\n+      }\n+    }\n+\n     return outputBlocks;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected ECBlock[] getOutputBlocks(ECBlockGroup blockGroup) {\n    ECBlock[] outputBlocks \u003d new ECBlock[getNumErasedBlocks(blockGroup)];\n\n    int idx \u003d 0;\n\n    for (int i \u003d 0; i \u003c getNumDataUnits(); i++) {\n      if (blockGroup.getDataBlocks()[i].isErased()) {\n        outputBlocks[idx++] \u003d blockGroup.getDataBlocks()[i];\n      }\n    }\n\n    for (int i \u003d 0; i \u003c getNumParityUnits(); i++) {\n      if (blockGroup.getParityBlocks()[i].isErased()) {\n        outputBlocks[idx++] \u003d blockGroup.getParityBlocks()[i];\n      }\n    }\n\n    return outputBlocks;\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/coder/AbstractErasureDecoder.java",
      "extendedDetails": {}
    },
    "b64f6745a45754dcf79c9c2626f3db7db2f33858": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-11566. Add tests and fix for erasure coders to recover erased parity units. Contributed by Kai Zheng.\n",
      "commitDate": "26/05/15 12:02 PM",
      "commitName": "b64f6745a45754dcf79c9c2626f3db7db2f33858",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "26/05/15 11:55 AM",
      "commitNameOld": "e54a74b566f89a424a2f4735a35553ece3bd35d9",
      "commitAuthorOld": "Zhe Zhang",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 78,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,19 @@\n   protected ECBlock[] getOutputBlocks(ECBlockGroup blockGroup) {\n-    ECBlock[] outputBlocks \u003d new ECBlock[\n-        getNumErasedBlocks(blockGroup.getDataBlocks())];\n+    ECBlock[] outputBlocks \u003d new ECBlock[getNumErasedBlocks(blockGroup)];\n \n     int idx \u003d 0;\n+\n+    for (int i \u003d 0; i \u003c getNumParityUnits(); i++) {\n+      if (blockGroup.getParityBlocks()[i].isErased()) {\n+        outputBlocks[idx++] \u003d blockGroup.getParityBlocks()[i];\n+      }\n+    }\n+\n     for (int i \u003d 0; i \u003c getNumDataUnits(); i++) {\n       if (blockGroup.getDataBlocks()[i].isErased()) {\n         outputBlocks[idx++] \u003d blockGroup.getDataBlocks()[i];\n       }\n     }\n \n     return outputBlocks;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected ECBlock[] getOutputBlocks(ECBlockGroup blockGroup) {\n    ECBlock[] outputBlocks \u003d new ECBlock[getNumErasedBlocks(blockGroup)];\n\n    int idx \u003d 0;\n\n    for (int i \u003d 0; i \u003c getNumParityUnits(); i++) {\n      if (blockGroup.getParityBlocks()[i].isErased()) {\n        outputBlocks[idx++] \u003d blockGroup.getParityBlocks()[i];\n      }\n    }\n\n    for (int i \u003d 0; i \u003c getNumDataUnits(); i++) {\n      if (blockGroup.getDataBlocks()[i].isErased()) {\n        outputBlocks[idx++] \u003d blockGroup.getDataBlocks()[i];\n      }\n    }\n\n    return outputBlocks;\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/coder/AbstractErasureDecoder.java",
      "extendedDetails": {}
    },
    "8f89d7489df0d5c8236a1929c93e3f5ab7149031": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-11646. Erasure Coder API for encoding and decoding of block group ( Contributed by Kai Zheng )\n",
      "commitDate": "26/05/15 11:32 AM",
      "commitName": "8f89d7489df0d5c8236a1929c93e3f5ab7149031",
      "commitAuthor": "Vinayakumar B",
      "diff": "@@ -0,0 +1,13 @@\n+  protected ECBlock[] getOutputBlocks(ECBlockGroup blockGroup) {\n+    ECBlock[] outputBlocks \u003d new ECBlock[\n+        getNumErasedBlocks(blockGroup.getDataBlocks())];\n+\n+    int idx \u003d 0;\n+    for (int i \u003d 0; i \u003c getNumDataUnits(); i++) {\n+      if (blockGroup.getDataBlocks()[i].isErased()) {\n+        outputBlocks[idx++] \u003d blockGroup.getDataBlocks()[i];\n+      }\n+    }\n+\n+    return outputBlocks;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  protected ECBlock[] getOutputBlocks(ECBlockGroup blockGroup) {\n    ECBlock[] outputBlocks \u003d new ECBlock[\n        getNumErasedBlocks(blockGroup.getDataBlocks())];\n\n    int idx \u003d 0;\n    for (int i \u003d 0; i \u003c getNumDataUnits(); i++) {\n      if (blockGroup.getDataBlocks()[i].isErased()) {\n        outputBlocks[idx++] \u003d blockGroup.getDataBlocks()[i];\n      }\n    }\n\n    return outputBlocks;\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/coder/AbstractErasureDecoder.java"
    }
  }
}