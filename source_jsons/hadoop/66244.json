{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "SLSRunner.java",
  "functionName": "startAMFromRumenTrace",
  "functionId": "startAMFromRumenTrace___inputTrace-String__baselineTimeMS-long",
  "sourceFilePath": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java",
  "functionStartLine": 627,
  "functionEndLine": 647,
  "numCommitsSeen": 51,
  "timeTaken": 3291,
  "changeHistory": [
    "134ae8fc8045e2ae1ed7ca54df95f14ffc863d09",
    "3369540653a41dd0194b65f5ef1d53225fb97ba8",
    "475f933b41276b1bdeeec09e30369120f7eccdb8",
    "de69d6e81128470dd5d2fd865d4b3a79188f740b",
    "4efdf3a979c361348612f817a3253be6d0de58f7",
    "58b08e11b9f04c9190ab4a07473f0ee04e01ec6b"
  ],
  "changeHistoryShort": {
    "134ae8fc8045e2ae1ed7ca54df95f14ffc863d09": "Ybodychange",
    "3369540653a41dd0194b65f5ef1d53225fb97ba8": "Ybodychange",
    "475f933b41276b1bdeeec09e30369120f7eccdb8": "Ymultichange(Yrename,Yparameterchange,Ybodychange)",
    "de69d6e81128470dd5d2fd865d4b3a79188f740b": "Ybodychange",
    "4efdf3a979c361348612f817a3253be6d0de58f7": "Ybodychange",
    "58b08e11b9f04c9190ab4a07473f0ee04e01ec6b": "Yintroduced"
  },
  "changeHistoryDetails": {
    "134ae8fc8045e2ae1ed7ca54df95f14ffc863d09": {
      "type": "Ybodychange",
      "commitMessage": "YARN-9293. Optimize MockAMLauncher event handling. Contributed by Bibin A Chundatt.\n",
      "commitDate": "14/02/19 9:26 AM",
      "commitName": "134ae8fc8045e2ae1ed7ca54df95f14ffc863d09",
      "commitAuthor": "bibinchundatt",
      "commitDateOld": "15/10/18 3:40 AM",
      "commitNameOld": "b4a38e7b3e530756fb79d23dd4e218beeb5e3190",
      "commitAuthorOld": "bibinchundatt",
      "daysBetweenCommits": 122.28,
      "commitsBetweenForRepo": 866,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,21 @@\n   private void startAMFromRumenTrace(String inputTrace, long baselineTimeMS)\n       throws IOException {\n     Configuration conf \u003d new Configuration();\n     conf.set(\"fs.defaultFS\", \"file:///\");\n     File fin \u003d new File(inputTrace);\n \n     try (JobTraceReader reader \u003d new JobTraceReader(\n         new Path(fin.getAbsolutePath()), conf)) {\n       LoggedJob job \u003d reader.getNext();\n \n       while (job !\u003d null) {\n         try {\n           createAMForJob(job, baselineTimeMS);\n         } catch (Exception e) {\n-          LOG.error(\"Failed to create an AM: {}\", e.getMessage());\n+          LOG.error(\"Failed to create an AM\", e);\n         }\n \n         job \u003d reader.getNext();\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void startAMFromRumenTrace(String inputTrace, long baselineTimeMS)\n      throws IOException {\n    Configuration conf \u003d new Configuration();\n    conf.set(\"fs.defaultFS\", \"file:///\");\n    File fin \u003d new File(inputTrace);\n\n    try (JobTraceReader reader \u003d new JobTraceReader(\n        new Path(fin.getAbsolutePath()), conf)) {\n      LoggedJob job \u003d reader.getNext();\n\n      while (job !\u003d null) {\n        try {\n          createAMForJob(job, baselineTimeMS);\n        } catch (Exception e) {\n          LOG.error(\"Failed to create an AM\", e);\n        }\n\n        job \u003d reader.getNext();\n      }\n    }\n  }",
      "path": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java",
      "extendedDetails": {}
    },
    "3369540653a41dd0194b65f5ef1d53225fb97ba8": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-14296. Move logging APIs over to slf4j in hadoop-tools.\n",
      "commitDate": "19/06/17 9:18 PM",
      "commitName": "3369540653a41dd0194b65f5ef1d53225fb97ba8",
      "commitAuthor": "Akira Ajisaka",
      "commitDateOld": "06/06/17 5:19 PM",
      "commitNameOld": "b65100c14bf9134de2bd8248dc62735682bee26c",
      "commitAuthorOld": "Carlo Curino",
      "daysBetweenCommits": 13.17,
      "commitsBetweenForRepo": 53,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,21 @@\n   private void startAMFromRumenTrace(String inputTrace, long baselineTimeMS)\n       throws IOException {\n     Configuration conf \u003d new Configuration();\n     conf.set(\"fs.defaultFS\", \"file:///\");\n     File fin \u003d new File(inputTrace);\n \n     try (JobTraceReader reader \u003d new JobTraceReader(\n         new Path(fin.getAbsolutePath()), conf)) {\n       LoggedJob job \u003d reader.getNext();\n \n       while (job !\u003d null) {\n         try {\n           createAMForJob(job, baselineTimeMS);\n         } catch (Exception e) {\n-          LOG.error(\"Failed to create an AM: \" + e.getMessage());\n+          LOG.error(\"Failed to create an AM: {}\", e.getMessage());\n         }\n \n         job \u003d reader.getNext();\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void startAMFromRumenTrace(String inputTrace, long baselineTimeMS)\n      throws IOException {\n    Configuration conf \u003d new Configuration();\n    conf.set(\"fs.defaultFS\", \"file:///\");\n    File fin \u003d new File(inputTrace);\n\n    try (JobTraceReader reader \u003d new JobTraceReader(\n        new Path(fin.getAbsolutePath()), conf)) {\n      LoggedJob job \u003d reader.getNext();\n\n      while (job !\u003d null) {\n        try {\n          createAMForJob(job, baselineTimeMS);\n        } catch (Exception e) {\n          LOG.error(\"Failed to create an AM: {}\", e.getMessage());\n        }\n\n        job \u003d reader.getNext();\n      }\n    }\n  }",
      "path": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java",
      "extendedDetails": {}
    },
    "475f933b41276b1bdeeec09e30369120f7eccdb8": {
      "type": "Ymultichange(Yrename,Yparameterchange,Ybodychange)",
      "commitMessage": "YARN-6423. Queue metrics doesn\u0027t work for Fair Scheduler in SLS (yufeigu via rkanter)\n",
      "commitDate": "25/04/17 4:26 PM",
      "commitName": "475f933b41276b1bdeeec09e30369120f7eccdb8",
      "commitAuthor": "Robert Kanter",
      "subchanges": [
        {
          "type": "Yrename",
          "commitMessage": "YARN-6423. Queue metrics doesn\u0027t work for Fair Scheduler in SLS (yufeigu via rkanter)\n",
          "commitDate": "25/04/17 4:26 PM",
          "commitName": "475f933b41276b1bdeeec09e30369120f7eccdb8",
          "commitAuthor": "Robert Kanter",
          "commitDateOld": "20/04/17 9:54 PM",
          "commitNameOld": "de69d6e81128470dd5d2fd865d4b3a79188f740b",
          "commitAuthorOld": "Wangda Tan",
          "daysBetweenCommits": 4.77,
          "commitsBetweenForRepo": 13,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,85 +1,21 @@\n-  private void startAMFromRumenTraces(Resource containerResource,\n-      int heartbeatInterval) throws IOException {\n+  private void startAMFromRumenTrace(String inputTrace, long baselineTimeMS)\n+      throws IOException {\n     Configuration conf \u003d new Configuration();\n     conf.set(\"fs.defaultFS\", \"file:///\");\n-    long baselineTimeMS \u003d 0;\n-    for (String inputTrace : inputTraces) {\n-      File fin \u003d new File(inputTrace);\n-      JobTraceReader reader \u003d\n-          new JobTraceReader(new Path(fin.getAbsolutePath()), conf);\n-      try {\n-        LoggedJob job \u003d null;\n-        while ((job \u003d reader.getNext()) !\u003d null) {\n-          // only support MapReduce currently\n-          String jobType \u003d \"mapreduce\";\n-          String user \u003d\n-              job.getUser() \u003d\u003d null ? \"default\" : job.getUser().getValue();\n-          String jobQueue \u003d job.getQueue().getValue();\n-          String oldJobId \u003d job.getJobID().toString();\n-          long jobStartTimeMS \u003d job.getSubmitTime();\n-          long jobFinishTimeMS \u003d job.getFinishTime();\n-          if (baselineTimeMS \u003d\u003d 0) {\n-            baselineTimeMS \u003d jobStartTimeMS;\n-          }\n-          jobStartTimeMS -\u003d baselineTimeMS;\n-          jobFinishTimeMS -\u003d baselineTimeMS;\n-          if (jobStartTimeMS \u003c 0) {\n-            LOG.warn(\"Warning: reset job \" + oldJobId + \" start time to 0.\");\n-            jobFinishTimeMS \u003d jobFinishTimeMS - jobStartTimeMS;\n-            jobStartTimeMS \u003d 0;\n-          }\n+    File fin \u003d new File(inputTrace);\n \n-          boolean isTracked \u003d trackedApps.contains(oldJobId);\n-          int queueSize \u003d queueAppNumMap.containsKey(jobQueue)\n-              ? queueAppNumMap.get(jobQueue) : 0;\n-          queueSize++;\n-          queueAppNumMap.put(jobQueue, queueSize);\n+    try (JobTraceReader reader \u003d new JobTraceReader(\n+        new Path(fin.getAbsolutePath()), conf)) {\n+      LoggedJob job \u003d reader.getNext();\n \n-          List\u003cContainerSimulator\u003e containerList \u003d\n-              new ArrayList\u003cContainerSimulator\u003e();\n-          // map tasks\n-          for (LoggedTask mapTask : job.getMapTasks()) {\n-            if (mapTask.getAttempts().size() \u003d\u003d 0) {\n-              continue;\n-            }\n-            LoggedTaskAttempt taskAttempt \u003d\n-                mapTask.getAttempts().get(mapTask.getAttempts().size() - 1);\n-            String hostname \u003d taskAttempt.getHostName().getValue();\n-            long containerLifeTime \u003d\n-                taskAttempt.getFinishTime() - taskAttempt.getStartTime();\n-            containerList.add(new ContainerSimulator(containerResource,\n-                containerLifeTime, hostname, 10, \"map\"));\n-          }\n-\n-          // reduce tasks\n-          for (LoggedTask reduceTask : job.getReduceTasks()) {\n-            if (reduceTask.getAttempts().size() \u003d\u003d 0) {\n-              continue;\n-            }\n-            LoggedTaskAttempt taskAttempt \u003d reduceTask.getAttempts()\n-                .get(reduceTask.getAttempts().size() - 1);\n-            String hostname \u003d taskAttempt.getHostName().getValue();\n-            long containerLifeTime \u003d\n-                taskAttempt.getFinishTime() - taskAttempt.getStartTime();\n-            containerList.add(new ContainerSimulator(containerResource,\n-                containerLifeTime, hostname, 20, \"reduce\"));\n-          }\n-\n-          // create a new AM\n-          AMSimulator amSim \u003d (AMSimulator) ReflectionUtils\n-              .newInstance(amClassMap.get(jobType), conf);\n-          if (amSim !\u003d null) {\n-            amSim.init(AM_ID++, heartbeatInterval, containerList, rm, this,\n-                jobStartTimeMS, jobFinishTimeMS, user, jobQueue, isTracked,\n-                oldJobId, null, runner.getStartTimeMS());\n-            runner.schedule(amSim);\n-            maxRuntime \u003d Math.max(maxRuntime, jobFinishTimeMS);\n-            numTasks +\u003d containerList.size();\n-            amMap.put(oldJobId, amSim);\n-          }\n+      while (job !\u003d null) {\n+        try {\n+          createAMForJob(job, baselineTimeMS);\n+        } catch (Exception e) {\n+          LOG.error(\"Failed to create an AM: \" + e.getMessage());\n         }\n-      } finally {\n-        reader.close();\n+\n+        job \u003d reader.getNext();\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void startAMFromRumenTrace(String inputTrace, long baselineTimeMS)\n      throws IOException {\n    Configuration conf \u003d new Configuration();\n    conf.set(\"fs.defaultFS\", \"file:///\");\n    File fin \u003d new File(inputTrace);\n\n    try (JobTraceReader reader \u003d new JobTraceReader(\n        new Path(fin.getAbsolutePath()), conf)) {\n      LoggedJob job \u003d reader.getNext();\n\n      while (job !\u003d null) {\n        try {\n          createAMForJob(job, baselineTimeMS);\n        } catch (Exception e) {\n          LOG.error(\"Failed to create an AM: \" + e.getMessage());\n        }\n\n        job \u003d reader.getNext();\n      }\n    }\n  }",
          "path": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java",
          "extendedDetails": {
            "oldValue": "startAMFromRumenTraces",
            "newValue": "startAMFromRumenTrace"
          }
        },
        {
          "type": "Yparameterchange",
          "commitMessage": "YARN-6423. Queue metrics doesn\u0027t work for Fair Scheduler in SLS (yufeigu via rkanter)\n",
          "commitDate": "25/04/17 4:26 PM",
          "commitName": "475f933b41276b1bdeeec09e30369120f7eccdb8",
          "commitAuthor": "Robert Kanter",
          "commitDateOld": "20/04/17 9:54 PM",
          "commitNameOld": "de69d6e81128470dd5d2fd865d4b3a79188f740b",
          "commitAuthorOld": "Wangda Tan",
          "daysBetweenCommits": 4.77,
          "commitsBetweenForRepo": 13,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,85 +1,21 @@\n-  private void startAMFromRumenTraces(Resource containerResource,\n-      int heartbeatInterval) throws IOException {\n+  private void startAMFromRumenTrace(String inputTrace, long baselineTimeMS)\n+      throws IOException {\n     Configuration conf \u003d new Configuration();\n     conf.set(\"fs.defaultFS\", \"file:///\");\n-    long baselineTimeMS \u003d 0;\n-    for (String inputTrace : inputTraces) {\n-      File fin \u003d new File(inputTrace);\n-      JobTraceReader reader \u003d\n-          new JobTraceReader(new Path(fin.getAbsolutePath()), conf);\n-      try {\n-        LoggedJob job \u003d null;\n-        while ((job \u003d reader.getNext()) !\u003d null) {\n-          // only support MapReduce currently\n-          String jobType \u003d \"mapreduce\";\n-          String user \u003d\n-              job.getUser() \u003d\u003d null ? \"default\" : job.getUser().getValue();\n-          String jobQueue \u003d job.getQueue().getValue();\n-          String oldJobId \u003d job.getJobID().toString();\n-          long jobStartTimeMS \u003d job.getSubmitTime();\n-          long jobFinishTimeMS \u003d job.getFinishTime();\n-          if (baselineTimeMS \u003d\u003d 0) {\n-            baselineTimeMS \u003d jobStartTimeMS;\n-          }\n-          jobStartTimeMS -\u003d baselineTimeMS;\n-          jobFinishTimeMS -\u003d baselineTimeMS;\n-          if (jobStartTimeMS \u003c 0) {\n-            LOG.warn(\"Warning: reset job \" + oldJobId + \" start time to 0.\");\n-            jobFinishTimeMS \u003d jobFinishTimeMS - jobStartTimeMS;\n-            jobStartTimeMS \u003d 0;\n-          }\n+    File fin \u003d new File(inputTrace);\n \n-          boolean isTracked \u003d trackedApps.contains(oldJobId);\n-          int queueSize \u003d queueAppNumMap.containsKey(jobQueue)\n-              ? queueAppNumMap.get(jobQueue) : 0;\n-          queueSize++;\n-          queueAppNumMap.put(jobQueue, queueSize);\n+    try (JobTraceReader reader \u003d new JobTraceReader(\n+        new Path(fin.getAbsolutePath()), conf)) {\n+      LoggedJob job \u003d reader.getNext();\n \n-          List\u003cContainerSimulator\u003e containerList \u003d\n-              new ArrayList\u003cContainerSimulator\u003e();\n-          // map tasks\n-          for (LoggedTask mapTask : job.getMapTasks()) {\n-            if (mapTask.getAttempts().size() \u003d\u003d 0) {\n-              continue;\n-            }\n-            LoggedTaskAttempt taskAttempt \u003d\n-                mapTask.getAttempts().get(mapTask.getAttempts().size() - 1);\n-            String hostname \u003d taskAttempt.getHostName().getValue();\n-            long containerLifeTime \u003d\n-                taskAttempt.getFinishTime() - taskAttempt.getStartTime();\n-            containerList.add(new ContainerSimulator(containerResource,\n-                containerLifeTime, hostname, 10, \"map\"));\n-          }\n-\n-          // reduce tasks\n-          for (LoggedTask reduceTask : job.getReduceTasks()) {\n-            if (reduceTask.getAttempts().size() \u003d\u003d 0) {\n-              continue;\n-            }\n-            LoggedTaskAttempt taskAttempt \u003d reduceTask.getAttempts()\n-                .get(reduceTask.getAttempts().size() - 1);\n-            String hostname \u003d taskAttempt.getHostName().getValue();\n-            long containerLifeTime \u003d\n-                taskAttempt.getFinishTime() - taskAttempt.getStartTime();\n-            containerList.add(new ContainerSimulator(containerResource,\n-                containerLifeTime, hostname, 20, \"reduce\"));\n-          }\n-\n-          // create a new AM\n-          AMSimulator amSim \u003d (AMSimulator) ReflectionUtils\n-              .newInstance(amClassMap.get(jobType), conf);\n-          if (amSim !\u003d null) {\n-            amSim.init(AM_ID++, heartbeatInterval, containerList, rm, this,\n-                jobStartTimeMS, jobFinishTimeMS, user, jobQueue, isTracked,\n-                oldJobId, null, runner.getStartTimeMS());\n-            runner.schedule(amSim);\n-            maxRuntime \u003d Math.max(maxRuntime, jobFinishTimeMS);\n-            numTasks +\u003d containerList.size();\n-            amMap.put(oldJobId, amSim);\n-          }\n+      while (job !\u003d null) {\n+        try {\n+          createAMForJob(job, baselineTimeMS);\n+        } catch (Exception e) {\n+          LOG.error(\"Failed to create an AM: \" + e.getMessage());\n         }\n-      } finally {\n-        reader.close();\n+\n+        job \u003d reader.getNext();\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void startAMFromRumenTrace(String inputTrace, long baselineTimeMS)\n      throws IOException {\n    Configuration conf \u003d new Configuration();\n    conf.set(\"fs.defaultFS\", \"file:///\");\n    File fin \u003d new File(inputTrace);\n\n    try (JobTraceReader reader \u003d new JobTraceReader(\n        new Path(fin.getAbsolutePath()), conf)) {\n      LoggedJob job \u003d reader.getNext();\n\n      while (job !\u003d null) {\n        try {\n          createAMForJob(job, baselineTimeMS);\n        } catch (Exception e) {\n          LOG.error(\"Failed to create an AM: \" + e.getMessage());\n        }\n\n        job \u003d reader.getNext();\n      }\n    }\n  }",
          "path": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java",
          "extendedDetails": {
            "oldValue": "[containerResource-Resource, heartbeatInterval-int]",
            "newValue": "[inputTrace-String, baselineTimeMS-long]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-6423. Queue metrics doesn\u0027t work for Fair Scheduler in SLS (yufeigu via rkanter)\n",
          "commitDate": "25/04/17 4:26 PM",
          "commitName": "475f933b41276b1bdeeec09e30369120f7eccdb8",
          "commitAuthor": "Robert Kanter",
          "commitDateOld": "20/04/17 9:54 PM",
          "commitNameOld": "de69d6e81128470dd5d2fd865d4b3a79188f740b",
          "commitAuthorOld": "Wangda Tan",
          "daysBetweenCommits": 4.77,
          "commitsBetweenForRepo": 13,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,85 +1,21 @@\n-  private void startAMFromRumenTraces(Resource containerResource,\n-      int heartbeatInterval) throws IOException {\n+  private void startAMFromRumenTrace(String inputTrace, long baselineTimeMS)\n+      throws IOException {\n     Configuration conf \u003d new Configuration();\n     conf.set(\"fs.defaultFS\", \"file:///\");\n-    long baselineTimeMS \u003d 0;\n-    for (String inputTrace : inputTraces) {\n-      File fin \u003d new File(inputTrace);\n-      JobTraceReader reader \u003d\n-          new JobTraceReader(new Path(fin.getAbsolutePath()), conf);\n-      try {\n-        LoggedJob job \u003d null;\n-        while ((job \u003d reader.getNext()) !\u003d null) {\n-          // only support MapReduce currently\n-          String jobType \u003d \"mapreduce\";\n-          String user \u003d\n-              job.getUser() \u003d\u003d null ? \"default\" : job.getUser().getValue();\n-          String jobQueue \u003d job.getQueue().getValue();\n-          String oldJobId \u003d job.getJobID().toString();\n-          long jobStartTimeMS \u003d job.getSubmitTime();\n-          long jobFinishTimeMS \u003d job.getFinishTime();\n-          if (baselineTimeMS \u003d\u003d 0) {\n-            baselineTimeMS \u003d jobStartTimeMS;\n-          }\n-          jobStartTimeMS -\u003d baselineTimeMS;\n-          jobFinishTimeMS -\u003d baselineTimeMS;\n-          if (jobStartTimeMS \u003c 0) {\n-            LOG.warn(\"Warning: reset job \" + oldJobId + \" start time to 0.\");\n-            jobFinishTimeMS \u003d jobFinishTimeMS - jobStartTimeMS;\n-            jobStartTimeMS \u003d 0;\n-          }\n+    File fin \u003d new File(inputTrace);\n \n-          boolean isTracked \u003d trackedApps.contains(oldJobId);\n-          int queueSize \u003d queueAppNumMap.containsKey(jobQueue)\n-              ? queueAppNumMap.get(jobQueue) : 0;\n-          queueSize++;\n-          queueAppNumMap.put(jobQueue, queueSize);\n+    try (JobTraceReader reader \u003d new JobTraceReader(\n+        new Path(fin.getAbsolutePath()), conf)) {\n+      LoggedJob job \u003d reader.getNext();\n \n-          List\u003cContainerSimulator\u003e containerList \u003d\n-              new ArrayList\u003cContainerSimulator\u003e();\n-          // map tasks\n-          for (LoggedTask mapTask : job.getMapTasks()) {\n-            if (mapTask.getAttempts().size() \u003d\u003d 0) {\n-              continue;\n-            }\n-            LoggedTaskAttempt taskAttempt \u003d\n-                mapTask.getAttempts().get(mapTask.getAttempts().size() - 1);\n-            String hostname \u003d taskAttempt.getHostName().getValue();\n-            long containerLifeTime \u003d\n-                taskAttempt.getFinishTime() - taskAttempt.getStartTime();\n-            containerList.add(new ContainerSimulator(containerResource,\n-                containerLifeTime, hostname, 10, \"map\"));\n-          }\n-\n-          // reduce tasks\n-          for (LoggedTask reduceTask : job.getReduceTasks()) {\n-            if (reduceTask.getAttempts().size() \u003d\u003d 0) {\n-              continue;\n-            }\n-            LoggedTaskAttempt taskAttempt \u003d reduceTask.getAttempts()\n-                .get(reduceTask.getAttempts().size() - 1);\n-            String hostname \u003d taskAttempt.getHostName().getValue();\n-            long containerLifeTime \u003d\n-                taskAttempt.getFinishTime() - taskAttempt.getStartTime();\n-            containerList.add(new ContainerSimulator(containerResource,\n-                containerLifeTime, hostname, 20, \"reduce\"));\n-          }\n-\n-          // create a new AM\n-          AMSimulator amSim \u003d (AMSimulator) ReflectionUtils\n-              .newInstance(amClassMap.get(jobType), conf);\n-          if (amSim !\u003d null) {\n-            amSim.init(AM_ID++, heartbeatInterval, containerList, rm, this,\n-                jobStartTimeMS, jobFinishTimeMS, user, jobQueue, isTracked,\n-                oldJobId, null, runner.getStartTimeMS());\n-            runner.schedule(amSim);\n-            maxRuntime \u003d Math.max(maxRuntime, jobFinishTimeMS);\n-            numTasks +\u003d containerList.size();\n-            amMap.put(oldJobId, amSim);\n-          }\n+      while (job !\u003d null) {\n+        try {\n+          createAMForJob(job, baselineTimeMS);\n+        } catch (Exception e) {\n+          LOG.error(\"Failed to create an AM: \" + e.getMessage());\n         }\n-      } finally {\n-        reader.close();\n+\n+        job \u003d reader.getNext();\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void startAMFromRumenTrace(String inputTrace, long baselineTimeMS)\n      throws IOException {\n    Configuration conf \u003d new Configuration();\n    conf.set(\"fs.defaultFS\", \"file:///\");\n    File fin \u003d new File(inputTrace);\n\n    try (JobTraceReader reader \u003d new JobTraceReader(\n        new Path(fin.getAbsolutePath()), conf)) {\n      LoggedJob job \u003d reader.getNext();\n\n      while (job !\u003d null) {\n        try {\n          createAMForJob(job, baselineTimeMS);\n        } catch (Exception e) {\n          LOG.error(\"Failed to create an AM: \" + e.getMessage());\n        }\n\n        job \u003d reader.getNext();\n      }\n    }\n  }",
          "path": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java",
          "extendedDetails": {}
        }
      ]
    },
    "de69d6e81128470dd5d2fd865d4b3a79188f740b": {
      "type": "Ybodychange",
      "commitMessage": "YARN-6363. Extending SLS: Synthetic Load Generator. (Carlo Curino via wangda)\n",
      "commitDate": "20/04/17 9:54 PM",
      "commitName": "de69d6e81128470dd5d2fd865d4b3a79188f740b",
      "commitAuthor": "Wangda Tan",
      "commitDateOld": "29/03/17 4:18 PM",
      "commitNameOld": "6a5516c2381f107d96b8326939514de3c6e53d3d",
      "commitAuthorOld": "Robert Kanter",
      "daysBetweenCommits": 22.23,
      "commitsBetweenForRepo": 128,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,86 +1,85 @@\n   private void startAMFromRumenTraces(Resource containerResource,\n-                                      int heartbeatInterval)\n-          throws IOException {\n+      int heartbeatInterval) throws IOException {\n     Configuration conf \u003d new Configuration();\n     conf.set(\"fs.defaultFS\", \"file:///\");\n     long baselineTimeMS \u003d 0;\n     for (String inputTrace : inputTraces) {\n       File fin \u003d new File(inputTrace);\n-      JobTraceReader reader \u003d new JobTraceReader(\n-              new Path(fin.getAbsolutePath()), conf);\n+      JobTraceReader reader \u003d\n+          new JobTraceReader(new Path(fin.getAbsolutePath()), conf);\n       try {\n         LoggedJob job \u003d null;\n         while ((job \u003d reader.getNext()) !\u003d null) {\n           // only support MapReduce currently\n           String jobType \u003d \"mapreduce\";\n-          String user \u003d job.getUser() \u003d\u003d null ?\n-                  \"default\" : job.getUser().getValue();\n+          String user \u003d\n+              job.getUser() \u003d\u003d null ? \"default\" : job.getUser().getValue();\n           String jobQueue \u003d job.getQueue().getValue();\n           String oldJobId \u003d job.getJobID().toString();\n           long jobStartTimeMS \u003d job.getSubmitTime();\n           long jobFinishTimeMS \u003d job.getFinishTime();\n           if (baselineTimeMS \u003d\u003d 0) {\n             baselineTimeMS \u003d jobStartTimeMS;\n           }\n           jobStartTimeMS -\u003d baselineTimeMS;\n           jobFinishTimeMS -\u003d baselineTimeMS;\n           if (jobStartTimeMS \u003c 0) {\n             LOG.warn(\"Warning: reset job \" + oldJobId + \" start time to 0.\");\n             jobFinishTimeMS \u003d jobFinishTimeMS - jobStartTimeMS;\n             jobStartTimeMS \u003d 0;\n           }\n \n           boolean isTracked \u003d trackedApps.contains(oldJobId);\n-          int queueSize \u003d queueAppNumMap.containsKey(jobQueue) ?\n-                  queueAppNumMap.get(jobQueue) : 0;\n-          queueSize ++;\n+          int queueSize \u003d queueAppNumMap.containsKey(jobQueue)\n+              ? queueAppNumMap.get(jobQueue) : 0;\n+          queueSize++;\n           queueAppNumMap.put(jobQueue, queueSize);\n \n           List\u003cContainerSimulator\u003e containerList \u003d\n-                  new ArrayList\u003cContainerSimulator\u003e();\n+              new ArrayList\u003cContainerSimulator\u003e();\n           // map tasks\n-          for(LoggedTask mapTask : job.getMapTasks()) {\n+          for (LoggedTask mapTask : job.getMapTasks()) {\n             if (mapTask.getAttempts().size() \u003d\u003d 0) {\n               continue;\n             }\n-            LoggedTaskAttempt taskAttempt \u003d mapTask.getAttempts()\n-                    .get(mapTask.getAttempts().size() - 1);\n+            LoggedTaskAttempt taskAttempt \u003d\n+                mapTask.getAttempts().get(mapTask.getAttempts().size() - 1);\n             String hostname \u003d taskAttempt.getHostName().getValue();\n-            long containerLifeTime \u003d taskAttempt.getFinishTime()\n-                    - taskAttempt.getStartTime();\n+            long containerLifeTime \u003d\n+                taskAttempt.getFinishTime() - taskAttempt.getStartTime();\n             containerList.add(new ContainerSimulator(containerResource,\n-                    containerLifeTime, hostname, 10, \"map\"));\n+                containerLifeTime, hostname, 10, \"map\"));\n           }\n \n           // reduce tasks\n-          for(LoggedTask reduceTask : job.getReduceTasks()) {\n+          for (LoggedTask reduceTask : job.getReduceTasks()) {\n             if (reduceTask.getAttempts().size() \u003d\u003d 0) {\n               continue;\n             }\n             LoggedTaskAttempt taskAttempt \u003d reduceTask.getAttempts()\n-                    .get(reduceTask.getAttempts().size() - 1);\n+                .get(reduceTask.getAttempts().size() - 1);\n             String hostname \u003d taskAttempt.getHostName().getValue();\n-            long containerLifeTime \u003d taskAttempt.getFinishTime()\n-                    - taskAttempt.getStartTime();\n+            long containerLifeTime \u003d\n+                taskAttempt.getFinishTime() - taskAttempt.getStartTime();\n             containerList.add(new ContainerSimulator(containerResource,\n-                    containerLifeTime, hostname, 20, \"reduce\"));\n+                containerLifeTime, hostname, 20, \"reduce\"));\n           }\n \n           // create a new AM\n-          AMSimulator amSim \u003d (AMSimulator) ReflectionUtils.newInstance(\n-                  amClassMap.get(jobType), conf);\n+          AMSimulator amSim \u003d (AMSimulator) ReflectionUtils\n+              .newInstance(amClassMap.get(jobType), conf);\n           if (amSim !\u003d null) {\n-            amSim.init(AM_ID ++, heartbeatInterval, containerList,\n-                    rm, this, jobStartTimeMS, jobFinishTimeMS, user, jobQueue,\n-                    isTracked, oldJobId);\n+            amSim.init(AM_ID++, heartbeatInterval, containerList, rm, this,\n+                jobStartTimeMS, jobFinishTimeMS, user, jobQueue, isTracked,\n+                oldJobId, null, runner.getStartTimeMS());\n             runner.schedule(amSim);\n             maxRuntime \u003d Math.max(maxRuntime, jobFinishTimeMS);\n             numTasks +\u003d containerList.size();\n             amMap.put(oldJobId, amSim);\n           }\n         }\n       } finally {\n         reader.close();\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void startAMFromRumenTraces(Resource containerResource,\n      int heartbeatInterval) throws IOException {\n    Configuration conf \u003d new Configuration();\n    conf.set(\"fs.defaultFS\", \"file:///\");\n    long baselineTimeMS \u003d 0;\n    for (String inputTrace : inputTraces) {\n      File fin \u003d new File(inputTrace);\n      JobTraceReader reader \u003d\n          new JobTraceReader(new Path(fin.getAbsolutePath()), conf);\n      try {\n        LoggedJob job \u003d null;\n        while ((job \u003d reader.getNext()) !\u003d null) {\n          // only support MapReduce currently\n          String jobType \u003d \"mapreduce\";\n          String user \u003d\n              job.getUser() \u003d\u003d null ? \"default\" : job.getUser().getValue();\n          String jobQueue \u003d job.getQueue().getValue();\n          String oldJobId \u003d job.getJobID().toString();\n          long jobStartTimeMS \u003d job.getSubmitTime();\n          long jobFinishTimeMS \u003d job.getFinishTime();\n          if (baselineTimeMS \u003d\u003d 0) {\n            baselineTimeMS \u003d jobStartTimeMS;\n          }\n          jobStartTimeMS -\u003d baselineTimeMS;\n          jobFinishTimeMS -\u003d baselineTimeMS;\n          if (jobStartTimeMS \u003c 0) {\n            LOG.warn(\"Warning: reset job \" + oldJobId + \" start time to 0.\");\n            jobFinishTimeMS \u003d jobFinishTimeMS - jobStartTimeMS;\n            jobStartTimeMS \u003d 0;\n          }\n\n          boolean isTracked \u003d trackedApps.contains(oldJobId);\n          int queueSize \u003d queueAppNumMap.containsKey(jobQueue)\n              ? queueAppNumMap.get(jobQueue) : 0;\n          queueSize++;\n          queueAppNumMap.put(jobQueue, queueSize);\n\n          List\u003cContainerSimulator\u003e containerList \u003d\n              new ArrayList\u003cContainerSimulator\u003e();\n          // map tasks\n          for (LoggedTask mapTask : job.getMapTasks()) {\n            if (mapTask.getAttempts().size() \u003d\u003d 0) {\n              continue;\n            }\n            LoggedTaskAttempt taskAttempt \u003d\n                mapTask.getAttempts().get(mapTask.getAttempts().size() - 1);\n            String hostname \u003d taskAttempt.getHostName().getValue();\n            long containerLifeTime \u003d\n                taskAttempt.getFinishTime() - taskAttempt.getStartTime();\n            containerList.add(new ContainerSimulator(containerResource,\n                containerLifeTime, hostname, 10, \"map\"));\n          }\n\n          // reduce tasks\n          for (LoggedTask reduceTask : job.getReduceTasks()) {\n            if (reduceTask.getAttempts().size() \u003d\u003d 0) {\n              continue;\n            }\n            LoggedTaskAttempt taskAttempt \u003d reduceTask.getAttempts()\n                .get(reduceTask.getAttempts().size() - 1);\n            String hostname \u003d taskAttempt.getHostName().getValue();\n            long containerLifeTime \u003d\n                taskAttempt.getFinishTime() - taskAttempt.getStartTime();\n            containerList.add(new ContainerSimulator(containerResource,\n                containerLifeTime, hostname, 20, \"reduce\"));\n          }\n\n          // create a new AM\n          AMSimulator amSim \u003d (AMSimulator) ReflectionUtils\n              .newInstance(amClassMap.get(jobType), conf);\n          if (amSim !\u003d null) {\n            amSim.init(AM_ID++, heartbeatInterval, containerList, rm, this,\n                jobStartTimeMS, jobFinishTimeMS, user, jobQueue, isTracked,\n                oldJobId, null, runner.getStartTimeMS());\n            runner.schedule(amSim);\n            maxRuntime \u003d Math.max(maxRuntime, jobFinishTimeMS);\n            numTasks +\u003d containerList.size();\n            amMap.put(oldJobId, amSim);\n          }\n        }\n      } finally {\n        reader.close();\n      }\n    }\n  }",
      "path": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java",
      "extendedDetails": {}
    },
    "4efdf3a979c361348612f817a3253be6d0de58f7": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4612. Fix rumen and scheduler load simulator handle killed tasks\nproperly. Contributed by Ming Ma.\n",
      "commitDate": "26/01/16 6:17 PM",
      "commitName": "4efdf3a979c361348612f817a3253be6d0de58f7",
      "commitAuthor": "Xuan",
      "commitDateOld": "30/04/15 3:34 AM",
      "commitNameOld": "f384a063a653b33d69f7d2c7d4fd45c24b5aa46a",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 271.65,
      "commitsBetweenForRepo": 2111,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,80 +1,86 @@\n   private void startAMFromRumenTraces(Resource containerResource,\n                                       int heartbeatInterval)\n           throws IOException {\n     Configuration conf \u003d new Configuration();\n     conf.set(\"fs.defaultFS\", \"file:///\");\n     long baselineTimeMS \u003d 0;\n     for (String inputTrace : inputTraces) {\n       File fin \u003d new File(inputTrace);\n       JobTraceReader reader \u003d new JobTraceReader(\n               new Path(fin.getAbsolutePath()), conf);\n       try {\n         LoggedJob job \u003d null;\n         while ((job \u003d reader.getNext()) !\u003d null) {\n           // only support MapReduce currently\n           String jobType \u003d \"mapreduce\";\n           String user \u003d job.getUser() \u003d\u003d null ?\n                   \"default\" : job.getUser().getValue();\n           String jobQueue \u003d job.getQueue().getValue();\n           String oldJobId \u003d job.getJobID().toString();\n           long jobStartTimeMS \u003d job.getSubmitTime();\n           long jobFinishTimeMS \u003d job.getFinishTime();\n           if (baselineTimeMS \u003d\u003d 0) {\n             baselineTimeMS \u003d jobStartTimeMS;\n           }\n           jobStartTimeMS -\u003d baselineTimeMS;\n           jobFinishTimeMS -\u003d baselineTimeMS;\n           if (jobStartTimeMS \u003c 0) {\n             LOG.warn(\"Warning: reset job \" + oldJobId + \" start time to 0.\");\n             jobFinishTimeMS \u003d jobFinishTimeMS - jobStartTimeMS;\n             jobStartTimeMS \u003d 0;\n           }\n \n           boolean isTracked \u003d trackedApps.contains(oldJobId);\n           int queueSize \u003d queueAppNumMap.containsKey(jobQueue) ?\n                   queueAppNumMap.get(jobQueue) : 0;\n           queueSize ++;\n           queueAppNumMap.put(jobQueue, queueSize);\n \n           List\u003cContainerSimulator\u003e containerList \u003d\n                   new ArrayList\u003cContainerSimulator\u003e();\n           // map tasks\n           for(LoggedTask mapTask : job.getMapTasks()) {\n+            if (mapTask.getAttempts().size() \u003d\u003d 0) {\n+              continue;\n+            }\n             LoggedTaskAttempt taskAttempt \u003d mapTask.getAttempts()\n                     .get(mapTask.getAttempts().size() - 1);\n             String hostname \u003d taskAttempt.getHostName().getValue();\n             long containerLifeTime \u003d taskAttempt.getFinishTime()\n                     - taskAttempt.getStartTime();\n             containerList.add(new ContainerSimulator(containerResource,\n                     containerLifeTime, hostname, 10, \"map\"));\n           }\n \n           // reduce tasks\n           for(LoggedTask reduceTask : job.getReduceTasks()) {\n+            if (reduceTask.getAttempts().size() \u003d\u003d 0) {\n+              continue;\n+            }\n             LoggedTaskAttempt taskAttempt \u003d reduceTask.getAttempts()\n                     .get(reduceTask.getAttempts().size() - 1);\n             String hostname \u003d taskAttempt.getHostName().getValue();\n             long containerLifeTime \u003d taskAttempt.getFinishTime()\n                     - taskAttempt.getStartTime();\n             containerList.add(new ContainerSimulator(containerResource,\n                     containerLifeTime, hostname, 20, \"reduce\"));\n           }\n \n           // create a new AM\n           AMSimulator amSim \u003d (AMSimulator) ReflectionUtils.newInstance(\n                   amClassMap.get(jobType), conf);\n           if (amSim !\u003d null) {\n             amSim.init(AM_ID ++, heartbeatInterval, containerList,\n                     rm, this, jobStartTimeMS, jobFinishTimeMS, user, jobQueue,\n                     isTracked, oldJobId);\n             runner.schedule(amSim);\n             maxRuntime \u003d Math.max(maxRuntime, jobFinishTimeMS);\n             numTasks +\u003d containerList.size();\n             amMap.put(oldJobId, amSim);\n           }\n         }\n       } finally {\n         reader.close();\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void startAMFromRumenTraces(Resource containerResource,\n                                      int heartbeatInterval)\n          throws IOException {\n    Configuration conf \u003d new Configuration();\n    conf.set(\"fs.defaultFS\", \"file:///\");\n    long baselineTimeMS \u003d 0;\n    for (String inputTrace : inputTraces) {\n      File fin \u003d new File(inputTrace);\n      JobTraceReader reader \u003d new JobTraceReader(\n              new Path(fin.getAbsolutePath()), conf);\n      try {\n        LoggedJob job \u003d null;\n        while ((job \u003d reader.getNext()) !\u003d null) {\n          // only support MapReduce currently\n          String jobType \u003d \"mapreduce\";\n          String user \u003d job.getUser() \u003d\u003d null ?\n                  \"default\" : job.getUser().getValue();\n          String jobQueue \u003d job.getQueue().getValue();\n          String oldJobId \u003d job.getJobID().toString();\n          long jobStartTimeMS \u003d job.getSubmitTime();\n          long jobFinishTimeMS \u003d job.getFinishTime();\n          if (baselineTimeMS \u003d\u003d 0) {\n            baselineTimeMS \u003d jobStartTimeMS;\n          }\n          jobStartTimeMS -\u003d baselineTimeMS;\n          jobFinishTimeMS -\u003d baselineTimeMS;\n          if (jobStartTimeMS \u003c 0) {\n            LOG.warn(\"Warning: reset job \" + oldJobId + \" start time to 0.\");\n            jobFinishTimeMS \u003d jobFinishTimeMS - jobStartTimeMS;\n            jobStartTimeMS \u003d 0;\n          }\n\n          boolean isTracked \u003d trackedApps.contains(oldJobId);\n          int queueSize \u003d queueAppNumMap.containsKey(jobQueue) ?\n                  queueAppNumMap.get(jobQueue) : 0;\n          queueSize ++;\n          queueAppNumMap.put(jobQueue, queueSize);\n\n          List\u003cContainerSimulator\u003e containerList \u003d\n                  new ArrayList\u003cContainerSimulator\u003e();\n          // map tasks\n          for(LoggedTask mapTask : job.getMapTasks()) {\n            if (mapTask.getAttempts().size() \u003d\u003d 0) {\n              continue;\n            }\n            LoggedTaskAttempt taskAttempt \u003d mapTask.getAttempts()\n                    .get(mapTask.getAttempts().size() - 1);\n            String hostname \u003d taskAttempt.getHostName().getValue();\n            long containerLifeTime \u003d taskAttempt.getFinishTime()\n                    - taskAttempt.getStartTime();\n            containerList.add(new ContainerSimulator(containerResource,\n                    containerLifeTime, hostname, 10, \"map\"));\n          }\n\n          // reduce tasks\n          for(LoggedTask reduceTask : job.getReduceTasks()) {\n            if (reduceTask.getAttempts().size() \u003d\u003d 0) {\n              continue;\n            }\n            LoggedTaskAttempt taskAttempt \u003d reduceTask.getAttempts()\n                    .get(reduceTask.getAttempts().size() - 1);\n            String hostname \u003d taskAttempt.getHostName().getValue();\n            long containerLifeTime \u003d taskAttempt.getFinishTime()\n                    - taskAttempt.getStartTime();\n            containerList.add(new ContainerSimulator(containerResource,\n                    containerLifeTime, hostname, 20, \"reduce\"));\n          }\n\n          // create a new AM\n          AMSimulator amSim \u003d (AMSimulator) ReflectionUtils.newInstance(\n                  amClassMap.get(jobType), conf);\n          if (amSim !\u003d null) {\n            amSim.init(AM_ID ++, heartbeatInterval, containerList,\n                    rm, this, jobStartTimeMS, jobFinishTimeMS, user, jobQueue,\n                    isTracked, oldJobId);\n            runner.schedule(amSim);\n            maxRuntime \u003d Math.max(maxRuntime, jobFinishTimeMS);\n            numTasks +\u003d containerList.size();\n            amMap.put(oldJobId, amSim);\n          }\n        }\n      } finally {\n        reader.close();\n      }\n    }\n  }",
      "path": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java",
      "extendedDetails": {}
    },
    "58b08e11b9f04c9190ab4a07473f0ee04e01ec6b": {
      "type": "Yintroduced",
      "commitMessage": "YARN-1021. Yarn Scheduler Load Simulator. (ywskycn via tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1527059 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/09/13 1:23 PM",
      "commitName": "58b08e11b9f04c9190ab4a07473f0ee04e01ec6b",
      "commitAuthor": "Alejandro Abdelnur",
      "diff": "@@ -0,0 +1,80 @@\n+  private void startAMFromRumenTraces(Resource containerResource,\n+                                      int heartbeatInterval)\n+          throws IOException {\n+    Configuration conf \u003d new Configuration();\n+    conf.set(\"fs.defaultFS\", \"file:///\");\n+    long baselineTimeMS \u003d 0;\n+    for (String inputTrace : inputTraces) {\n+      File fin \u003d new File(inputTrace);\n+      JobTraceReader reader \u003d new JobTraceReader(\n+              new Path(fin.getAbsolutePath()), conf);\n+      try {\n+        LoggedJob job \u003d null;\n+        while ((job \u003d reader.getNext()) !\u003d null) {\n+          // only support MapReduce currently\n+          String jobType \u003d \"mapreduce\";\n+          String user \u003d job.getUser() \u003d\u003d null ?\n+                  \"default\" : job.getUser().getValue();\n+          String jobQueue \u003d job.getQueue().getValue();\n+          String oldJobId \u003d job.getJobID().toString();\n+          long jobStartTimeMS \u003d job.getSubmitTime();\n+          long jobFinishTimeMS \u003d job.getFinishTime();\n+          if (baselineTimeMS \u003d\u003d 0) {\n+            baselineTimeMS \u003d jobStartTimeMS;\n+          }\n+          jobStartTimeMS -\u003d baselineTimeMS;\n+          jobFinishTimeMS -\u003d baselineTimeMS;\n+          if (jobStartTimeMS \u003c 0) {\n+            LOG.warn(\"Warning: reset job \" + oldJobId + \" start time to 0.\");\n+            jobFinishTimeMS \u003d jobFinishTimeMS - jobStartTimeMS;\n+            jobStartTimeMS \u003d 0;\n+          }\n+\n+          boolean isTracked \u003d trackedApps.contains(oldJobId);\n+          int queueSize \u003d queueAppNumMap.containsKey(jobQueue) ?\n+                  queueAppNumMap.get(jobQueue) : 0;\n+          queueSize ++;\n+          queueAppNumMap.put(jobQueue, queueSize);\n+\n+          List\u003cContainerSimulator\u003e containerList \u003d\n+                  new ArrayList\u003cContainerSimulator\u003e();\n+          // map tasks\n+          for(LoggedTask mapTask : job.getMapTasks()) {\n+            LoggedTaskAttempt taskAttempt \u003d mapTask.getAttempts()\n+                    .get(mapTask.getAttempts().size() - 1);\n+            String hostname \u003d taskAttempt.getHostName().getValue();\n+            long containerLifeTime \u003d taskAttempt.getFinishTime()\n+                    - taskAttempt.getStartTime();\n+            containerList.add(new ContainerSimulator(containerResource,\n+                    containerLifeTime, hostname, 10, \"map\"));\n+          }\n+\n+          // reduce tasks\n+          for(LoggedTask reduceTask : job.getReduceTasks()) {\n+            LoggedTaskAttempt taskAttempt \u003d reduceTask.getAttempts()\n+                    .get(reduceTask.getAttempts().size() - 1);\n+            String hostname \u003d taskAttempt.getHostName().getValue();\n+            long containerLifeTime \u003d taskAttempt.getFinishTime()\n+                    - taskAttempt.getStartTime();\n+            containerList.add(new ContainerSimulator(containerResource,\n+                    containerLifeTime, hostname, 20, \"reduce\"));\n+          }\n+\n+          // create a new AM\n+          AMSimulator amSim \u003d (AMSimulator) ReflectionUtils.newInstance(\n+                  amClassMap.get(jobType), conf);\n+          if (amSim !\u003d null) {\n+            amSim.init(AM_ID ++, heartbeatInterval, containerList,\n+                    rm, this, jobStartTimeMS, jobFinishTimeMS, user, jobQueue,\n+                    isTracked, oldJobId);\n+            runner.schedule(amSim);\n+            maxRuntime \u003d Math.max(maxRuntime, jobFinishTimeMS);\n+            numTasks +\u003d containerList.size();\n+            amMap.put(oldJobId, amSim);\n+          }\n+        }\n+      } finally {\n+        reader.close();\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void startAMFromRumenTraces(Resource containerResource,\n                                      int heartbeatInterval)\n          throws IOException {\n    Configuration conf \u003d new Configuration();\n    conf.set(\"fs.defaultFS\", \"file:///\");\n    long baselineTimeMS \u003d 0;\n    for (String inputTrace : inputTraces) {\n      File fin \u003d new File(inputTrace);\n      JobTraceReader reader \u003d new JobTraceReader(\n              new Path(fin.getAbsolutePath()), conf);\n      try {\n        LoggedJob job \u003d null;\n        while ((job \u003d reader.getNext()) !\u003d null) {\n          // only support MapReduce currently\n          String jobType \u003d \"mapreduce\";\n          String user \u003d job.getUser() \u003d\u003d null ?\n                  \"default\" : job.getUser().getValue();\n          String jobQueue \u003d job.getQueue().getValue();\n          String oldJobId \u003d job.getJobID().toString();\n          long jobStartTimeMS \u003d job.getSubmitTime();\n          long jobFinishTimeMS \u003d job.getFinishTime();\n          if (baselineTimeMS \u003d\u003d 0) {\n            baselineTimeMS \u003d jobStartTimeMS;\n          }\n          jobStartTimeMS -\u003d baselineTimeMS;\n          jobFinishTimeMS -\u003d baselineTimeMS;\n          if (jobStartTimeMS \u003c 0) {\n            LOG.warn(\"Warning: reset job \" + oldJobId + \" start time to 0.\");\n            jobFinishTimeMS \u003d jobFinishTimeMS - jobStartTimeMS;\n            jobStartTimeMS \u003d 0;\n          }\n\n          boolean isTracked \u003d trackedApps.contains(oldJobId);\n          int queueSize \u003d queueAppNumMap.containsKey(jobQueue) ?\n                  queueAppNumMap.get(jobQueue) : 0;\n          queueSize ++;\n          queueAppNumMap.put(jobQueue, queueSize);\n\n          List\u003cContainerSimulator\u003e containerList \u003d\n                  new ArrayList\u003cContainerSimulator\u003e();\n          // map tasks\n          for(LoggedTask mapTask : job.getMapTasks()) {\n            LoggedTaskAttempt taskAttempt \u003d mapTask.getAttempts()\n                    .get(mapTask.getAttempts().size() - 1);\n            String hostname \u003d taskAttempt.getHostName().getValue();\n            long containerLifeTime \u003d taskAttempt.getFinishTime()\n                    - taskAttempt.getStartTime();\n            containerList.add(new ContainerSimulator(containerResource,\n                    containerLifeTime, hostname, 10, \"map\"));\n          }\n\n          // reduce tasks\n          for(LoggedTask reduceTask : job.getReduceTasks()) {\n            LoggedTaskAttempt taskAttempt \u003d reduceTask.getAttempts()\n                    .get(reduceTask.getAttempts().size() - 1);\n            String hostname \u003d taskAttempt.getHostName().getValue();\n            long containerLifeTime \u003d taskAttempt.getFinishTime()\n                    - taskAttempt.getStartTime();\n            containerList.add(new ContainerSimulator(containerResource,\n                    containerLifeTime, hostname, 20, \"reduce\"));\n          }\n\n          // create a new AM\n          AMSimulator amSim \u003d (AMSimulator) ReflectionUtils.newInstance(\n                  amClassMap.get(jobType), conf);\n          if (amSim !\u003d null) {\n            amSim.init(AM_ID ++, heartbeatInterval, containerList,\n                    rm, this, jobStartTimeMS, jobFinishTimeMS, user, jobQueue,\n                    isTracked, oldJobId);\n            runner.schedule(amSim);\n            maxRuntime \u003d Math.max(maxRuntime, jobFinishTimeMS);\n            numTasks +\u003d containerList.size();\n            amMap.put(oldJobId, amSim);\n          }\n        }\n      } finally {\n        reader.close();\n      }\n    }\n  }",
      "path": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java"
    }
  }
}