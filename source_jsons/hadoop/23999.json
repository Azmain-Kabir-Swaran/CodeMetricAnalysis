{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ShuffleHandler.java",
  "functionName": "messageReceived",
  "functionId": "messageReceived___ctx-ChannelHandlerContext__evt-MessageEvent",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java",
  "functionStartLine": 929,
  "functionEndLine": 1035,
  "numCommitsSeen": 60,
  "timeTaken": 10901,
  "changeHistory": [
    "3a20debddeac69596ceb5b36f8413529ea8570e6",
    "ea845ba58c585647c4be8d30d9b814f098e34a12",
    "b3d61304f2fa4a99526f7a60ccaac9f262083079",
    "c8bd5fc7a86f9890ceaa37a89491ab650e7e9a64",
    "a7463b6c88f698950a2f326030261001aa51b35e",
    "521f34317a2f94ea7e60f3d59db335cef3358e5b",
    "d8107fcd1c93c202925f2946d0cd4072fe0aef1e",
    "8e615588d5216394d0251a9c97bd706537856c6d",
    "bff67dfe2f811654ffb1bbcbd87509c185f452b6",
    "b3ffa870034d06608a1946e2d9ce7dbd535a2c53",
    "a5c08eed16e797d2ba9f98f7bc6a8e1bf09aaddd",
    "11bcd2ed12f7f0e02fdaefaefea56929b32d5ee6",
    "47d1ca402fe0bafae32507dee0d27cd1e345a7e9",
    "1f46b991da9b91585608a0babd3eda39485dce09",
    "ade0f0560f729e50382c6992f713f29e2dd5b270",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517"
  ],
  "changeHistoryShort": {
    "3a20debddeac69596ceb5b36f8413529ea8570e6": "Ybodychange",
    "ea845ba58c585647c4be8d30d9b814f098e34a12": "Ybodychange",
    "b3d61304f2fa4a99526f7a60ccaac9f262083079": "Ybodychange",
    "c8bd5fc7a86f9890ceaa37a89491ab650e7e9a64": "Ybodychange",
    "a7463b6c88f698950a2f326030261001aa51b35e": "Ybodychange",
    "521f34317a2f94ea7e60f3d59db335cef3358e5b": "Ybodychange",
    "d8107fcd1c93c202925f2946d0cd4072fe0aef1e": "Ybodychange",
    "8e615588d5216394d0251a9c97bd706537856c6d": "Ybodychange",
    "bff67dfe2f811654ffb1bbcbd87509c185f452b6": "Ybodychange",
    "b3ffa870034d06608a1946e2d9ce7dbd535a2c53": "Ybodychange",
    "a5c08eed16e797d2ba9f98f7bc6a8e1bf09aaddd": "Ybodychange",
    "11bcd2ed12f7f0e02fdaefaefea56929b32d5ee6": "Ybodychange",
    "47d1ca402fe0bafae32507dee0d27cd1e345a7e9": "Ybodychange",
    "1f46b991da9b91585608a0babd3eda39485dce09": "Ybodychange",
    "ade0f0560f729e50382c6992f713f29e2dd5b270": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yintroduced"
  },
  "changeHistoryDetails": {
    "3a20debddeac69596ceb5b36f8413529ea8570e6": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6958. Shuffle audit logger should log size of shuffle transfer. Contributed by Jason Lowe\n",
      "commitDate": "19/09/17 7:13 AM",
      "commitName": "3a20debddeac69596ceb5b36f8413529ea8570e6",
      "commitAuthor": "Jason Lowe",
      "commitDateOld": "19/09/17 6:45 AM",
      "commitNameOld": "ea845ba58c585647c4be8d30d9b814f098e34a12",
      "commitAuthorOld": "Jason Lowe",
      "daysBetweenCommits": 0.02,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,114 +1,107 @@\n     public void messageReceived(ChannelHandlerContext ctx, MessageEvent evt)\n         throws Exception {\n       HttpRequest request \u003d (HttpRequest) evt.getMessage();\n       if (request.getMethod() !\u003d GET) {\n           sendError(ctx, METHOD_NOT_ALLOWED);\n           return;\n       }\n       // Check whether the shuffle version is compatible\n       if (!ShuffleHeader.DEFAULT_HTTP_HEADER_NAME.equals(\n           request.headers() !\u003d null ?\n               request.headers().get(ShuffleHeader.HTTP_HEADER_NAME) : null)\n           || !ShuffleHeader.DEFAULT_HTTP_HEADER_VERSION.equals(\n               request.headers() !\u003d null ?\n                   request.headers()\n                       .get(ShuffleHeader.HTTP_HEADER_VERSION) : null)) {\n         sendError(ctx, \"Incompatible shuffle request version\", BAD_REQUEST);\n       }\n       final Map\u003cString,List\u003cString\u003e\u003e q \u003d\n         new QueryStringDecoder(request.getUri()).getParameters();\n       final List\u003cString\u003e keepAliveList \u003d q.get(\"keepAlive\");\n       boolean keepAliveParam \u003d false;\n       if (keepAliveList !\u003d null \u0026\u0026 keepAliveList.size() \u003d\u003d 1) {\n         keepAliveParam \u003d Boolean.valueOf(keepAliveList.get(0));\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"KeepAliveParam : \" + keepAliveList\n             + \" : \" + keepAliveParam);\n         }\n       }\n       final List\u003cString\u003e mapIds \u003d splitMaps(q.get(\"map\"));\n       final List\u003cString\u003e reduceQ \u003d q.get(\"reduce\");\n       final List\u003cString\u003e jobQ \u003d q.get(\"job\");\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"RECV: \" + request.getUri() +\n             \"\\n  mapId: \" + mapIds +\n             \"\\n  reduceId: \" + reduceQ +\n             \"\\n  jobId: \" + jobQ +\n             \"\\n  keepAlive: \" + keepAliveParam);\n       }\n \n       if (mapIds \u003d\u003d null || reduceQ \u003d\u003d null || jobQ \u003d\u003d null) {\n         sendError(ctx, \"Required param job, map and reduce\", BAD_REQUEST);\n         return;\n       }\n       if (reduceQ.size() !\u003d 1 || jobQ.size() !\u003d 1) {\n         sendError(ctx, \"Too many job/reduce parameters\", BAD_REQUEST);\n         return;\n       }\n \n-      // this audit log is disabled by default,\n-      // to turn it on please enable this audit log\n-      // on log4j.properties by uncommenting the setting\n-      if (AUDITLOG.isDebugEnabled()) {\n-        AUDITLOG.debug(\"shuffle for \" + jobQ.get(0) + \" mappers: \" + mapIds +\n-                         \" reducer \" + reduceQ.get(0));\n-      }\n       int reduceId;\n       String jobId;\n       try {\n         reduceId \u003d Integer.parseInt(reduceQ.get(0));\n         jobId \u003d jobQ.get(0);\n       } catch (NumberFormatException e) {\n         sendError(ctx, \"Bad reduce parameter\", BAD_REQUEST);\n         return;\n       } catch (IllegalArgumentException e) {\n         sendError(ctx, \"Bad job parameter\", BAD_REQUEST);\n         return;\n       }\n       final String reqUri \u003d request.getUri();\n       if (null \u003d\u003d reqUri) {\n         // TODO? add upstream?\n         sendError(ctx, FORBIDDEN);\n         return;\n       }\n       HttpResponse response \u003d new DefaultHttpResponse(HTTP_1_1, OK);\n       try {\n         verifyRequest(jobId, ctx, request, response,\n             new URL(\"http\", \"\", this.port, reqUri));\n       } catch (IOException e) {\n         LOG.warn(\"Shuffle failure \", e);\n         sendError(ctx, e.getMessage(), UNAUTHORIZED);\n         return;\n       }\n \n       Map\u003cString, MapOutputInfo\u003e mapOutputInfoMap \u003d\n           new HashMap\u003cString, MapOutputInfo\u003e();\n       Channel ch \u003d evt.getChannel();\n       ChannelPipeline pipeline \u003d ch.getPipeline();\n       TimeoutHandler timeoutHandler \u003d\n           (TimeoutHandler)pipeline.get(TIMEOUT_HANDLER);\n       timeoutHandler.setEnabledTimeout(false);\n       String user \u003d userRsrc.get(jobId);\n \n       try {\n         populateHeaders(mapIds, jobId, user, reduceId, request,\n           response, keepAliveParam, mapOutputInfoMap);\n       } catch(IOException e) {\n         ch.write(response);\n         LOG.error(\"Shuffle error in populating headers :\", e);\n         String errorMessage \u003d getErrorMessage(e);\n         sendError(ctx,errorMessage , INTERNAL_SERVER_ERROR);\n         return;\n       }\n       ch.write(response);\n       //Initialize one ReduceContext object per messageReceived call\n       boolean keepAlive \u003d keepAliveParam || connectionKeepAliveEnabled;\n       ReduceContext reduceContext \u003d new ReduceContext(mapIds, reduceId, ctx,\n           user, mapOutputInfoMap, jobId, keepAlive);\n       for (int i \u003d 0; i \u003c Math.min(maxSessionOpenFiles, mapIds.size()); i++) {\n         ChannelFuture nextMap \u003d sendMap(reduceContext);\n         if(nextMap \u003d\u003d null) {\n           return;\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void messageReceived(ChannelHandlerContext ctx, MessageEvent evt)\n        throws Exception {\n      HttpRequest request \u003d (HttpRequest) evt.getMessage();\n      if (request.getMethod() !\u003d GET) {\n          sendError(ctx, METHOD_NOT_ALLOWED);\n          return;\n      }\n      // Check whether the shuffle version is compatible\n      if (!ShuffleHeader.DEFAULT_HTTP_HEADER_NAME.equals(\n          request.headers() !\u003d null ?\n              request.headers().get(ShuffleHeader.HTTP_HEADER_NAME) : null)\n          || !ShuffleHeader.DEFAULT_HTTP_HEADER_VERSION.equals(\n              request.headers() !\u003d null ?\n                  request.headers()\n                      .get(ShuffleHeader.HTTP_HEADER_VERSION) : null)) {\n        sendError(ctx, \"Incompatible shuffle request version\", BAD_REQUEST);\n      }\n      final Map\u003cString,List\u003cString\u003e\u003e q \u003d\n        new QueryStringDecoder(request.getUri()).getParameters();\n      final List\u003cString\u003e keepAliveList \u003d q.get(\"keepAlive\");\n      boolean keepAliveParam \u003d false;\n      if (keepAliveList !\u003d null \u0026\u0026 keepAliveList.size() \u003d\u003d 1) {\n        keepAliveParam \u003d Boolean.valueOf(keepAliveList.get(0));\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"KeepAliveParam : \" + keepAliveList\n            + \" : \" + keepAliveParam);\n        }\n      }\n      final List\u003cString\u003e mapIds \u003d splitMaps(q.get(\"map\"));\n      final List\u003cString\u003e reduceQ \u003d q.get(\"reduce\");\n      final List\u003cString\u003e jobQ \u003d q.get(\"job\");\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"RECV: \" + request.getUri() +\n            \"\\n  mapId: \" + mapIds +\n            \"\\n  reduceId: \" + reduceQ +\n            \"\\n  jobId: \" + jobQ +\n            \"\\n  keepAlive: \" + keepAliveParam);\n      }\n\n      if (mapIds \u003d\u003d null || reduceQ \u003d\u003d null || jobQ \u003d\u003d null) {\n        sendError(ctx, \"Required param job, map and reduce\", BAD_REQUEST);\n        return;\n      }\n      if (reduceQ.size() !\u003d 1 || jobQ.size() !\u003d 1) {\n        sendError(ctx, \"Too many job/reduce parameters\", BAD_REQUEST);\n        return;\n      }\n\n      int reduceId;\n      String jobId;\n      try {\n        reduceId \u003d Integer.parseInt(reduceQ.get(0));\n        jobId \u003d jobQ.get(0);\n      } catch (NumberFormatException e) {\n        sendError(ctx, \"Bad reduce parameter\", BAD_REQUEST);\n        return;\n      } catch (IllegalArgumentException e) {\n        sendError(ctx, \"Bad job parameter\", BAD_REQUEST);\n        return;\n      }\n      final String reqUri \u003d request.getUri();\n      if (null \u003d\u003d reqUri) {\n        // TODO? add upstream?\n        sendError(ctx, FORBIDDEN);\n        return;\n      }\n      HttpResponse response \u003d new DefaultHttpResponse(HTTP_1_1, OK);\n      try {\n        verifyRequest(jobId, ctx, request, response,\n            new URL(\"http\", \"\", this.port, reqUri));\n      } catch (IOException e) {\n        LOG.warn(\"Shuffle failure \", e);\n        sendError(ctx, e.getMessage(), UNAUTHORIZED);\n        return;\n      }\n\n      Map\u003cString, MapOutputInfo\u003e mapOutputInfoMap \u003d\n          new HashMap\u003cString, MapOutputInfo\u003e();\n      Channel ch \u003d evt.getChannel();\n      ChannelPipeline pipeline \u003d ch.getPipeline();\n      TimeoutHandler timeoutHandler \u003d\n          (TimeoutHandler)pipeline.get(TIMEOUT_HANDLER);\n      timeoutHandler.setEnabledTimeout(false);\n      String user \u003d userRsrc.get(jobId);\n\n      try {\n        populateHeaders(mapIds, jobId, user, reduceId, request,\n          response, keepAliveParam, mapOutputInfoMap);\n      } catch(IOException e) {\n        ch.write(response);\n        LOG.error(\"Shuffle error in populating headers :\", e);\n        String errorMessage \u003d getErrorMessage(e);\n        sendError(ctx,errorMessage , INTERNAL_SERVER_ERROR);\n        return;\n      }\n      ch.write(response);\n      //Initialize one ReduceContext object per messageReceived call\n      boolean keepAlive \u003d keepAliveParam || connectionKeepAliveEnabled;\n      ReduceContext reduceContext \u003d new ReduceContext(mapIds, reduceId, ctx,\n          user, mapOutputInfoMap, jobId, keepAlive);\n      for (int i \u003d 0; i \u003c Math.min(maxSessionOpenFiles, mapIds.size()); i++) {\n        ChannelFuture nextMap \u003d sendMap(reduceContext);\n        if(nextMap \u003d\u003d null) {\n          return;\n        }\n      }\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java",
      "extendedDetails": {}
    },
    "ea845ba58c585647c4be8d30d9b814f098e34a12": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"MAPREDUCE-6958. Shuffle audit logger should log size of shuffle transfer. Contributed by Jason Lowe\"\n\nThis reverts commit b3d61304f2fa4a99526f7a60ccaac9f262083079.\n",
      "commitDate": "19/09/17 6:45 AM",
      "commitName": "ea845ba58c585647c4be8d30d9b814f098e34a12",
      "commitAuthor": "Jason Lowe",
      "commitDateOld": "18/09/17 3:04 PM",
      "commitNameOld": "b3d61304f2fa4a99526f7a60ccaac9f262083079",
      "commitAuthorOld": "Jason Lowe",
      "daysBetweenCommits": 0.65,
      "commitsBetweenForRepo": 6,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,107 +1,114 @@\n     public void messageReceived(ChannelHandlerContext ctx, MessageEvent evt)\n         throws Exception {\n       HttpRequest request \u003d (HttpRequest) evt.getMessage();\n       if (request.getMethod() !\u003d GET) {\n           sendError(ctx, METHOD_NOT_ALLOWED);\n           return;\n       }\n       // Check whether the shuffle version is compatible\n       if (!ShuffleHeader.DEFAULT_HTTP_HEADER_NAME.equals(\n           request.headers() !\u003d null ?\n               request.headers().get(ShuffleHeader.HTTP_HEADER_NAME) : null)\n           || !ShuffleHeader.DEFAULT_HTTP_HEADER_VERSION.equals(\n               request.headers() !\u003d null ?\n                   request.headers()\n                       .get(ShuffleHeader.HTTP_HEADER_VERSION) : null)) {\n         sendError(ctx, \"Incompatible shuffle request version\", BAD_REQUEST);\n       }\n       final Map\u003cString,List\u003cString\u003e\u003e q \u003d\n         new QueryStringDecoder(request.getUri()).getParameters();\n       final List\u003cString\u003e keepAliveList \u003d q.get(\"keepAlive\");\n       boolean keepAliveParam \u003d false;\n       if (keepAliveList !\u003d null \u0026\u0026 keepAliveList.size() \u003d\u003d 1) {\n         keepAliveParam \u003d Boolean.valueOf(keepAliveList.get(0));\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"KeepAliveParam : \" + keepAliveList\n             + \" : \" + keepAliveParam);\n         }\n       }\n       final List\u003cString\u003e mapIds \u003d splitMaps(q.get(\"map\"));\n       final List\u003cString\u003e reduceQ \u003d q.get(\"reduce\");\n       final List\u003cString\u003e jobQ \u003d q.get(\"job\");\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"RECV: \" + request.getUri() +\n             \"\\n  mapId: \" + mapIds +\n             \"\\n  reduceId: \" + reduceQ +\n             \"\\n  jobId: \" + jobQ +\n             \"\\n  keepAlive: \" + keepAliveParam);\n       }\n \n       if (mapIds \u003d\u003d null || reduceQ \u003d\u003d null || jobQ \u003d\u003d null) {\n         sendError(ctx, \"Required param job, map and reduce\", BAD_REQUEST);\n         return;\n       }\n       if (reduceQ.size() !\u003d 1 || jobQ.size() !\u003d 1) {\n         sendError(ctx, \"Too many job/reduce parameters\", BAD_REQUEST);\n         return;\n       }\n \n+      // this audit log is disabled by default,\n+      // to turn it on please enable this audit log\n+      // on log4j.properties by uncommenting the setting\n+      if (AUDITLOG.isDebugEnabled()) {\n+        AUDITLOG.debug(\"shuffle for \" + jobQ.get(0) + \" mappers: \" + mapIds +\n+                         \" reducer \" + reduceQ.get(0));\n+      }\n       int reduceId;\n       String jobId;\n       try {\n         reduceId \u003d Integer.parseInt(reduceQ.get(0));\n         jobId \u003d jobQ.get(0);\n       } catch (NumberFormatException e) {\n         sendError(ctx, \"Bad reduce parameter\", BAD_REQUEST);\n         return;\n       } catch (IllegalArgumentException e) {\n         sendError(ctx, \"Bad job parameter\", BAD_REQUEST);\n         return;\n       }\n       final String reqUri \u003d request.getUri();\n       if (null \u003d\u003d reqUri) {\n         // TODO? add upstream?\n         sendError(ctx, FORBIDDEN);\n         return;\n       }\n       HttpResponse response \u003d new DefaultHttpResponse(HTTP_1_1, OK);\n       try {\n         verifyRequest(jobId, ctx, request, response,\n             new URL(\"http\", \"\", this.port, reqUri));\n       } catch (IOException e) {\n         LOG.warn(\"Shuffle failure \", e);\n         sendError(ctx, e.getMessage(), UNAUTHORIZED);\n         return;\n       }\n \n       Map\u003cString, MapOutputInfo\u003e mapOutputInfoMap \u003d\n           new HashMap\u003cString, MapOutputInfo\u003e();\n       Channel ch \u003d evt.getChannel();\n       ChannelPipeline pipeline \u003d ch.getPipeline();\n       TimeoutHandler timeoutHandler \u003d\n           (TimeoutHandler)pipeline.get(TIMEOUT_HANDLER);\n       timeoutHandler.setEnabledTimeout(false);\n       String user \u003d userRsrc.get(jobId);\n \n       try {\n         populateHeaders(mapIds, jobId, user, reduceId, request,\n           response, keepAliveParam, mapOutputInfoMap);\n       } catch(IOException e) {\n         ch.write(response);\n         LOG.error(\"Shuffle error in populating headers :\", e);\n         String errorMessage \u003d getErrorMessage(e);\n         sendError(ctx,errorMessage , INTERNAL_SERVER_ERROR);\n         return;\n       }\n       ch.write(response);\n       //Initialize one ReduceContext object per messageReceived call\n       boolean keepAlive \u003d keepAliveParam || connectionKeepAliveEnabled;\n       ReduceContext reduceContext \u003d new ReduceContext(mapIds, reduceId, ctx,\n           user, mapOutputInfoMap, jobId, keepAlive);\n       for (int i \u003d 0; i \u003c Math.min(maxSessionOpenFiles, mapIds.size()); i++) {\n         ChannelFuture nextMap \u003d sendMap(reduceContext);\n         if(nextMap \u003d\u003d null) {\n           return;\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void messageReceived(ChannelHandlerContext ctx, MessageEvent evt)\n        throws Exception {\n      HttpRequest request \u003d (HttpRequest) evt.getMessage();\n      if (request.getMethod() !\u003d GET) {\n          sendError(ctx, METHOD_NOT_ALLOWED);\n          return;\n      }\n      // Check whether the shuffle version is compatible\n      if (!ShuffleHeader.DEFAULT_HTTP_HEADER_NAME.equals(\n          request.headers() !\u003d null ?\n              request.headers().get(ShuffleHeader.HTTP_HEADER_NAME) : null)\n          || !ShuffleHeader.DEFAULT_HTTP_HEADER_VERSION.equals(\n              request.headers() !\u003d null ?\n                  request.headers()\n                      .get(ShuffleHeader.HTTP_HEADER_VERSION) : null)) {\n        sendError(ctx, \"Incompatible shuffle request version\", BAD_REQUEST);\n      }\n      final Map\u003cString,List\u003cString\u003e\u003e q \u003d\n        new QueryStringDecoder(request.getUri()).getParameters();\n      final List\u003cString\u003e keepAliveList \u003d q.get(\"keepAlive\");\n      boolean keepAliveParam \u003d false;\n      if (keepAliveList !\u003d null \u0026\u0026 keepAliveList.size() \u003d\u003d 1) {\n        keepAliveParam \u003d Boolean.valueOf(keepAliveList.get(0));\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"KeepAliveParam : \" + keepAliveList\n            + \" : \" + keepAliveParam);\n        }\n      }\n      final List\u003cString\u003e mapIds \u003d splitMaps(q.get(\"map\"));\n      final List\u003cString\u003e reduceQ \u003d q.get(\"reduce\");\n      final List\u003cString\u003e jobQ \u003d q.get(\"job\");\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"RECV: \" + request.getUri() +\n            \"\\n  mapId: \" + mapIds +\n            \"\\n  reduceId: \" + reduceQ +\n            \"\\n  jobId: \" + jobQ +\n            \"\\n  keepAlive: \" + keepAliveParam);\n      }\n\n      if (mapIds \u003d\u003d null || reduceQ \u003d\u003d null || jobQ \u003d\u003d null) {\n        sendError(ctx, \"Required param job, map and reduce\", BAD_REQUEST);\n        return;\n      }\n      if (reduceQ.size() !\u003d 1 || jobQ.size() !\u003d 1) {\n        sendError(ctx, \"Too many job/reduce parameters\", BAD_REQUEST);\n        return;\n      }\n\n      // this audit log is disabled by default,\n      // to turn it on please enable this audit log\n      // on log4j.properties by uncommenting the setting\n      if (AUDITLOG.isDebugEnabled()) {\n        AUDITLOG.debug(\"shuffle for \" + jobQ.get(0) + \" mappers: \" + mapIds +\n                         \" reducer \" + reduceQ.get(0));\n      }\n      int reduceId;\n      String jobId;\n      try {\n        reduceId \u003d Integer.parseInt(reduceQ.get(0));\n        jobId \u003d jobQ.get(0);\n      } catch (NumberFormatException e) {\n        sendError(ctx, \"Bad reduce parameter\", BAD_REQUEST);\n        return;\n      } catch (IllegalArgumentException e) {\n        sendError(ctx, \"Bad job parameter\", BAD_REQUEST);\n        return;\n      }\n      final String reqUri \u003d request.getUri();\n      if (null \u003d\u003d reqUri) {\n        // TODO? add upstream?\n        sendError(ctx, FORBIDDEN);\n        return;\n      }\n      HttpResponse response \u003d new DefaultHttpResponse(HTTP_1_1, OK);\n      try {\n        verifyRequest(jobId, ctx, request, response,\n            new URL(\"http\", \"\", this.port, reqUri));\n      } catch (IOException e) {\n        LOG.warn(\"Shuffle failure \", e);\n        sendError(ctx, e.getMessage(), UNAUTHORIZED);\n        return;\n      }\n\n      Map\u003cString, MapOutputInfo\u003e mapOutputInfoMap \u003d\n          new HashMap\u003cString, MapOutputInfo\u003e();\n      Channel ch \u003d evt.getChannel();\n      ChannelPipeline pipeline \u003d ch.getPipeline();\n      TimeoutHandler timeoutHandler \u003d\n          (TimeoutHandler)pipeline.get(TIMEOUT_HANDLER);\n      timeoutHandler.setEnabledTimeout(false);\n      String user \u003d userRsrc.get(jobId);\n\n      try {\n        populateHeaders(mapIds, jobId, user, reduceId, request,\n          response, keepAliveParam, mapOutputInfoMap);\n      } catch(IOException e) {\n        ch.write(response);\n        LOG.error(\"Shuffle error in populating headers :\", e);\n        String errorMessage \u003d getErrorMessage(e);\n        sendError(ctx,errorMessage , INTERNAL_SERVER_ERROR);\n        return;\n      }\n      ch.write(response);\n      //Initialize one ReduceContext object per messageReceived call\n      boolean keepAlive \u003d keepAliveParam || connectionKeepAliveEnabled;\n      ReduceContext reduceContext \u003d new ReduceContext(mapIds, reduceId, ctx,\n          user, mapOutputInfoMap, jobId, keepAlive);\n      for (int i \u003d 0; i \u003c Math.min(maxSessionOpenFiles, mapIds.size()); i++) {\n        ChannelFuture nextMap \u003d sendMap(reduceContext);\n        if(nextMap \u003d\u003d null) {\n          return;\n        }\n      }\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java",
      "extendedDetails": {}
    },
    "b3d61304f2fa4a99526f7a60ccaac9f262083079": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6958. Shuffle audit logger should log size of shuffle transfer. Contributed by Jason Lowe\n",
      "commitDate": "18/09/17 3:04 PM",
      "commitName": "b3d61304f2fa4a99526f7a60ccaac9f262083079",
      "commitAuthor": "Jason Lowe",
      "commitDateOld": "30/03/17 8:57 AM",
      "commitNameOld": "c8bd5fc7a86f9890ceaa37a89491ab650e7e9a64",
      "commitAuthorOld": "Jason Lowe",
      "daysBetweenCommits": 172.26,
      "commitsBetweenForRepo": 1121,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,114 +1,107 @@\n     public void messageReceived(ChannelHandlerContext ctx, MessageEvent evt)\n         throws Exception {\n       HttpRequest request \u003d (HttpRequest) evt.getMessage();\n       if (request.getMethod() !\u003d GET) {\n           sendError(ctx, METHOD_NOT_ALLOWED);\n           return;\n       }\n       // Check whether the shuffle version is compatible\n       if (!ShuffleHeader.DEFAULT_HTTP_HEADER_NAME.equals(\n           request.headers() !\u003d null ?\n               request.headers().get(ShuffleHeader.HTTP_HEADER_NAME) : null)\n           || !ShuffleHeader.DEFAULT_HTTP_HEADER_VERSION.equals(\n               request.headers() !\u003d null ?\n                   request.headers()\n                       .get(ShuffleHeader.HTTP_HEADER_VERSION) : null)) {\n         sendError(ctx, \"Incompatible shuffle request version\", BAD_REQUEST);\n       }\n       final Map\u003cString,List\u003cString\u003e\u003e q \u003d\n         new QueryStringDecoder(request.getUri()).getParameters();\n       final List\u003cString\u003e keepAliveList \u003d q.get(\"keepAlive\");\n       boolean keepAliveParam \u003d false;\n       if (keepAliveList !\u003d null \u0026\u0026 keepAliveList.size() \u003d\u003d 1) {\n         keepAliveParam \u003d Boolean.valueOf(keepAliveList.get(0));\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"KeepAliveParam : \" + keepAliveList\n             + \" : \" + keepAliveParam);\n         }\n       }\n       final List\u003cString\u003e mapIds \u003d splitMaps(q.get(\"map\"));\n       final List\u003cString\u003e reduceQ \u003d q.get(\"reduce\");\n       final List\u003cString\u003e jobQ \u003d q.get(\"job\");\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"RECV: \" + request.getUri() +\n             \"\\n  mapId: \" + mapIds +\n             \"\\n  reduceId: \" + reduceQ +\n             \"\\n  jobId: \" + jobQ +\n             \"\\n  keepAlive: \" + keepAliveParam);\n       }\n \n       if (mapIds \u003d\u003d null || reduceQ \u003d\u003d null || jobQ \u003d\u003d null) {\n         sendError(ctx, \"Required param job, map and reduce\", BAD_REQUEST);\n         return;\n       }\n       if (reduceQ.size() !\u003d 1 || jobQ.size() !\u003d 1) {\n         sendError(ctx, \"Too many job/reduce parameters\", BAD_REQUEST);\n         return;\n       }\n \n-      // this audit log is disabled by default,\n-      // to turn it on please enable this audit log\n-      // on log4j.properties by uncommenting the setting\n-      if (AUDITLOG.isDebugEnabled()) {\n-        AUDITLOG.debug(\"shuffle for \" + jobQ.get(0) + \" mappers: \" + mapIds +\n-                         \" reducer \" + reduceQ.get(0));\n-      }\n       int reduceId;\n       String jobId;\n       try {\n         reduceId \u003d Integer.parseInt(reduceQ.get(0));\n         jobId \u003d jobQ.get(0);\n       } catch (NumberFormatException e) {\n         sendError(ctx, \"Bad reduce parameter\", BAD_REQUEST);\n         return;\n       } catch (IllegalArgumentException e) {\n         sendError(ctx, \"Bad job parameter\", BAD_REQUEST);\n         return;\n       }\n       final String reqUri \u003d request.getUri();\n       if (null \u003d\u003d reqUri) {\n         // TODO? add upstream?\n         sendError(ctx, FORBIDDEN);\n         return;\n       }\n       HttpResponse response \u003d new DefaultHttpResponse(HTTP_1_1, OK);\n       try {\n         verifyRequest(jobId, ctx, request, response,\n             new URL(\"http\", \"\", this.port, reqUri));\n       } catch (IOException e) {\n         LOG.warn(\"Shuffle failure \", e);\n         sendError(ctx, e.getMessage(), UNAUTHORIZED);\n         return;\n       }\n \n       Map\u003cString, MapOutputInfo\u003e mapOutputInfoMap \u003d\n           new HashMap\u003cString, MapOutputInfo\u003e();\n       Channel ch \u003d evt.getChannel();\n       ChannelPipeline pipeline \u003d ch.getPipeline();\n       TimeoutHandler timeoutHandler \u003d\n           (TimeoutHandler)pipeline.get(TIMEOUT_HANDLER);\n       timeoutHandler.setEnabledTimeout(false);\n       String user \u003d userRsrc.get(jobId);\n \n       try {\n         populateHeaders(mapIds, jobId, user, reduceId, request,\n           response, keepAliveParam, mapOutputInfoMap);\n       } catch(IOException e) {\n         ch.write(response);\n         LOG.error(\"Shuffle error in populating headers :\", e);\n         String errorMessage \u003d getErrorMessage(e);\n         sendError(ctx,errorMessage , INTERNAL_SERVER_ERROR);\n         return;\n       }\n       ch.write(response);\n       //Initialize one ReduceContext object per messageReceived call\n       boolean keepAlive \u003d keepAliveParam || connectionKeepAliveEnabled;\n       ReduceContext reduceContext \u003d new ReduceContext(mapIds, reduceId, ctx,\n           user, mapOutputInfoMap, jobId, keepAlive);\n       for (int i \u003d 0; i \u003c Math.min(maxSessionOpenFiles, mapIds.size()); i++) {\n         ChannelFuture nextMap \u003d sendMap(reduceContext);\n         if(nextMap \u003d\u003d null) {\n           return;\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void messageReceived(ChannelHandlerContext ctx, MessageEvent evt)\n        throws Exception {\n      HttpRequest request \u003d (HttpRequest) evt.getMessage();\n      if (request.getMethod() !\u003d GET) {\n          sendError(ctx, METHOD_NOT_ALLOWED);\n          return;\n      }\n      // Check whether the shuffle version is compatible\n      if (!ShuffleHeader.DEFAULT_HTTP_HEADER_NAME.equals(\n          request.headers() !\u003d null ?\n              request.headers().get(ShuffleHeader.HTTP_HEADER_NAME) : null)\n          || !ShuffleHeader.DEFAULT_HTTP_HEADER_VERSION.equals(\n              request.headers() !\u003d null ?\n                  request.headers()\n                      .get(ShuffleHeader.HTTP_HEADER_VERSION) : null)) {\n        sendError(ctx, \"Incompatible shuffle request version\", BAD_REQUEST);\n      }\n      final Map\u003cString,List\u003cString\u003e\u003e q \u003d\n        new QueryStringDecoder(request.getUri()).getParameters();\n      final List\u003cString\u003e keepAliveList \u003d q.get(\"keepAlive\");\n      boolean keepAliveParam \u003d false;\n      if (keepAliveList !\u003d null \u0026\u0026 keepAliveList.size() \u003d\u003d 1) {\n        keepAliveParam \u003d Boolean.valueOf(keepAliveList.get(0));\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"KeepAliveParam : \" + keepAliveList\n            + \" : \" + keepAliveParam);\n        }\n      }\n      final List\u003cString\u003e mapIds \u003d splitMaps(q.get(\"map\"));\n      final List\u003cString\u003e reduceQ \u003d q.get(\"reduce\");\n      final List\u003cString\u003e jobQ \u003d q.get(\"job\");\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"RECV: \" + request.getUri() +\n            \"\\n  mapId: \" + mapIds +\n            \"\\n  reduceId: \" + reduceQ +\n            \"\\n  jobId: \" + jobQ +\n            \"\\n  keepAlive: \" + keepAliveParam);\n      }\n\n      if (mapIds \u003d\u003d null || reduceQ \u003d\u003d null || jobQ \u003d\u003d null) {\n        sendError(ctx, \"Required param job, map and reduce\", BAD_REQUEST);\n        return;\n      }\n      if (reduceQ.size() !\u003d 1 || jobQ.size() !\u003d 1) {\n        sendError(ctx, \"Too many job/reduce parameters\", BAD_REQUEST);\n        return;\n      }\n\n      int reduceId;\n      String jobId;\n      try {\n        reduceId \u003d Integer.parseInt(reduceQ.get(0));\n        jobId \u003d jobQ.get(0);\n      } catch (NumberFormatException e) {\n        sendError(ctx, \"Bad reduce parameter\", BAD_REQUEST);\n        return;\n      } catch (IllegalArgumentException e) {\n        sendError(ctx, \"Bad job parameter\", BAD_REQUEST);\n        return;\n      }\n      final String reqUri \u003d request.getUri();\n      if (null \u003d\u003d reqUri) {\n        // TODO? add upstream?\n        sendError(ctx, FORBIDDEN);\n        return;\n      }\n      HttpResponse response \u003d new DefaultHttpResponse(HTTP_1_1, OK);\n      try {\n        verifyRequest(jobId, ctx, request, response,\n            new URL(\"http\", \"\", this.port, reqUri));\n      } catch (IOException e) {\n        LOG.warn(\"Shuffle failure \", e);\n        sendError(ctx, e.getMessage(), UNAUTHORIZED);\n        return;\n      }\n\n      Map\u003cString, MapOutputInfo\u003e mapOutputInfoMap \u003d\n          new HashMap\u003cString, MapOutputInfo\u003e();\n      Channel ch \u003d evt.getChannel();\n      ChannelPipeline pipeline \u003d ch.getPipeline();\n      TimeoutHandler timeoutHandler \u003d\n          (TimeoutHandler)pipeline.get(TIMEOUT_HANDLER);\n      timeoutHandler.setEnabledTimeout(false);\n      String user \u003d userRsrc.get(jobId);\n\n      try {\n        populateHeaders(mapIds, jobId, user, reduceId, request,\n          response, keepAliveParam, mapOutputInfoMap);\n      } catch(IOException e) {\n        ch.write(response);\n        LOG.error(\"Shuffle error in populating headers :\", e);\n        String errorMessage \u003d getErrorMessage(e);\n        sendError(ctx,errorMessage , INTERNAL_SERVER_ERROR);\n        return;\n      }\n      ch.write(response);\n      //Initialize one ReduceContext object per messageReceived call\n      boolean keepAlive \u003d keepAliveParam || connectionKeepAliveEnabled;\n      ReduceContext reduceContext \u003d new ReduceContext(mapIds, reduceId, ctx,\n          user, mapOutputInfoMap, jobId, keepAlive);\n      for (int i \u003d 0; i \u003c Math.min(maxSessionOpenFiles, mapIds.size()); i++) {\n        ChannelFuture nextMap \u003d sendMap(reduceContext);\n        if(nextMap \u003d\u003d null) {\n          return;\n        }\n      }\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java",
      "extendedDetails": {}
    },
    "c8bd5fc7a86f9890ceaa37a89491ab650e7e9a64": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6850. Shuffle Handler keep-alive connections are closed from the server side. Contributed by Jonathan Eagles\n",
      "commitDate": "30/03/17 8:57 AM",
      "commitName": "c8bd5fc7a86f9890ceaa37a89491ab650e7e9a64",
      "commitAuthor": "Jason Lowe",
      "commitDateOld": "25/01/17 2:32 PM",
      "commitNameOld": "a7463b6c88f698950a2f326030261001aa51b35e",
      "commitAuthorOld": "Daniel Templeton",
      "daysBetweenCommits": 63.73,
      "commitsBetweenForRepo": 348,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,109 +1,114 @@\n     public void messageReceived(ChannelHandlerContext ctx, MessageEvent evt)\n         throws Exception {\n       HttpRequest request \u003d (HttpRequest) evt.getMessage();\n       if (request.getMethod() !\u003d GET) {\n           sendError(ctx, METHOD_NOT_ALLOWED);\n           return;\n       }\n       // Check whether the shuffle version is compatible\n       if (!ShuffleHeader.DEFAULT_HTTP_HEADER_NAME.equals(\n           request.headers() !\u003d null ?\n               request.headers().get(ShuffleHeader.HTTP_HEADER_NAME) : null)\n           || !ShuffleHeader.DEFAULT_HTTP_HEADER_VERSION.equals(\n               request.headers() !\u003d null ?\n                   request.headers()\n                       .get(ShuffleHeader.HTTP_HEADER_VERSION) : null)) {\n         sendError(ctx, \"Incompatible shuffle request version\", BAD_REQUEST);\n       }\n       final Map\u003cString,List\u003cString\u003e\u003e q \u003d\n         new QueryStringDecoder(request.getUri()).getParameters();\n       final List\u003cString\u003e keepAliveList \u003d q.get(\"keepAlive\");\n       boolean keepAliveParam \u003d false;\n       if (keepAliveList !\u003d null \u0026\u0026 keepAliveList.size() \u003d\u003d 1) {\n         keepAliveParam \u003d Boolean.valueOf(keepAliveList.get(0));\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"KeepAliveParam : \" + keepAliveList\n             + \" : \" + keepAliveParam);\n         }\n       }\n       final List\u003cString\u003e mapIds \u003d splitMaps(q.get(\"map\"));\n       final List\u003cString\u003e reduceQ \u003d q.get(\"reduce\");\n       final List\u003cString\u003e jobQ \u003d q.get(\"job\");\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"RECV: \" + request.getUri() +\n             \"\\n  mapId: \" + mapIds +\n             \"\\n  reduceId: \" + reduceQ +\n             \"\\n  jobId: \" + jobQ +\n             \"\\n  keepAlive: \" + keepAliveParam);\n       }\n \n       if (mapIds \u003d\u003d null || reduceQ \u003d\u003d null || jobQ \u003d\u003d null) {\n         sendError(ctx, \"Required param job, map and reduce\", BAD_REQUEST);\n         return;\n       }\n       if (reduceQ.size() !\u003d 1 || jobQ.size() !\u003d 1) {\n         sendError(ctx, \"Too many job/reduce parameters\", BAD_REQUEST);\n         return;\n       }\n \n       // this audit log is disabled by default,\n       // to turn it on please enable this audit log\n       // on log4j.properties by uncommenting the setting\n       if (AUDITLOG.isDebugEnabled()) {\n         AUDITLOG.debug(\"shuffle for \" + jobQ.get(0) + \" mappers: \" + mapIds +\n                          \" reducer \" + reduceQ.get(0));\n       }\n       int reduceId;\n       String jobId;\n       try {\n         reduceId \u003d Integer.parseInt(reduceQ.get(0));\n         jobId \u003d jobQ.get(0);\n       } catch (NumberFormatException e) {\n         sendError(ctx, \"Bad reduce parameter\", BAD_REQUEST);\n         return;\n       } catch (IllegalArgumentException e) {\n         sendError(ctx, \"Bad job parameter\", BAD_REQUEST);\n         return;\n       }\n       final String reqUri \u003d request.getUri();\n       if (null \u003d\u003d reqUri) {\n         // TODO? add upstream?\n         sendError(ctx, FORBIDDEN);\n         return;\n       }\n       HttpResponse response \u003d new DefaultHttpResponse(HTTP_1_1, OK);\n       try {\n         verifyRequest(jobId, ctx, request, response,\n             new URL(\"http\", \"\", this.port, reqUri));\n       } catch (IOException e) {\n         LOG.warn(\"Shuffle failure \", e);\n         sendError(ctx, e.getMessage(), UNAUTHORIZED);\n         return;\n       }\n \n       Map\u003cString, MapOutputInfo\u003e mapOutputInfoMap \u003d\n           new HashMap\u003cString, MapOutputInfo\u003e();\n       Channel ch \u003d evt.getChannel();\n+      ChannelPipeline pipeline \u003d ch.getPipeline();\n+      TimeoutHandler timeoutHandler \u003d\n+          (TimeoutHandler)pipeline.get(TIMEOUT_HANDLER);\n+      timeoutHandler.setEnabledTimeout(false);\n       String user \u003d userRsrc.get(jobId);\n \n       try {\n         populateHeaders(mapIds, jobId, user, reduceId, request,\n           response, keepAliveParam, mapOutputInfoMap);\n       } catch(IOException e) {\n         ch.write(response);\n         LOG.error(\"Shuffle error in populating headers :\", e);\n         String errorMessage \u003d getErrorMessage(e);\n         sendError(ctx,errorMessage , INTERNAL_SERVER_ERROR);\n         return;\n       }\n       ch.write(response);\n       //Initialize one ReduceContext object per messageReceived call\n+      boolean keepAlive \u003d keepAliveParam || connectionKeepAliveEnabled;\n       ReduceContext reduceContext \u003d new ReduceContext(mapIds, reduceId, ctx,\n-          user, mapOutputInfoMap, jobId);\n+          user, mapOutputInfoMap, jobId, keepAlive);\n       for (int i \u003d 0; i \u003c Math.min(maxSessionOpenFiles, mapIds.size()); i++) {\n         ChannelFuture nextMap \u003d sendMap(reduceContext);\n         if(nextMap \u003d\u003d null) {\n           return;\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void messageReceived(ChannelHandlerContext ctx, MessageEvent evt)\n        throws Exception {\n      HttpRequest request \u003d (HttpRequest) evt.getMessage();\n      if (request.getMethod() !\u003d GET) {\n          sendError(ctx, METHOD_NOT_ALLOWED);\n          return;\n      }\n      // Check whether the shuffle version is compatible\n      if (!ShuffleHeader.DEFAULT_HTTP_HEADER_NAME.equals(\n          request.headers() !\u003d null ?\n              request.headers().get(ShuffleHeader.HTTP_HEADER_NAME) : null)\n          || !ShuffleHeader.DEFAULT_HTTP_HEADER_VERSION.equals(\n              request.headers() !\u003d null ?\n                  request.headers()\n                      .get(ShuffleHeader.HTTP_HEADER_VERSION) : null)) {\n        sendError(ctx, \"Incompatible shuffle request version\", BAD_REQUEST);\n      }\n      final Map\u003cString,List\u003cString\u003e\u003e q \u003d\n        new QueryStringDecoder(request.getUri()).getParameters();\n      final List\u003cString\u003e keepAliveList \u003d q.get(\"keepAlive\");\n      boolean keepAliveParam \u003d false;\n      if (keepAliveList !\u003d null \u0026\u0026 keepAliveList.size() \u003d\u003d 1) {\n        keepAliveParam \u003d Boolean.valueOf(keepAliveList.get(0));\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"KeepAliveParam : \" + keepAliveList\n            + \" : \" + keepAliveParam);\n        }\n      }\n      final List\u003cString\u003e mapIds \u003d splitMaps(q.get(\"map\"));\n      final List\u003cString\u003e reduceQ \u003d q.get(\"reduce\");\n      final List\u003cString\u003e jobQ \u003d q.get(\"job\");\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"RECV: \" + request.getUri() +\n            \"\\n  mapId: \" + mapIds +\n            \"\\n  reduceId: \" + reduceQ +\n            \"\\n  jobId: \" + jobQ +\n            \"\\n  keepAlive: \" + keepAliveParam);\n      }\n\n      if (mapIds \u003d\u003d null || reduceQ \u003d\u003d null || jobQ \u003d\u003d null) {\n        sendError(ctx, \"Required param job, map and reduce\", BAD_REQUEST);\n        return;\n      }\n      if (reduceQ.size() !\u003d 1 || jobQ.size() !\u003d 1) {\n        sendError(ctx, \"Too many job/reduce parameters\", BAD_REQUEST);\n        return;\n      }\n\n      // this audit log is disabled by default,\n      // to turn it on please enable this audit log\n      // on log4j.properties by uncommenting the setting\n      if (AUDITLOG.isDebugEnabled()) {\n        AUDITLOG.debug(\"shuffle for \" + jobQ.get(0) + \" mappers: \" + mapIds +\n                         \" reducer \" + reduceQ.get(0));\n      }\n      int reduceId;\n      String jobId;\n      try {\n        reduceId \u003d Integer.parseInt(reduceQ.get(0));\n        jobId \u003d jobQ.get(0);\n      } catch (NumberFormatException e) {\n        sendError(ctx, \"Bad reduce parameter\", BAD_REQUEST);\n        return;\n      } catch (IllegalArgumentException e) {\n        sendError(ctx, \"Bad job parameter\", BAD_REQUEST);\n        return;\n      }\n      final String reqUri \u003d request.getUri();\n      if (null \u003d\u003d reqUri) {\n        // TODO? add upstream?\n        sendError(ctx, FORBIDDEN);\n        return;\n      }\n      HttpResponse response \u003d new DefaultHttpResponse(HTTP_1_1, OK);\n      try {\n        verifyRequest(jobId, ctx, request, response,\n            new URL(\"http\", \"\", this.port, reqUri));\n      } catch (IOException e) {\n        LOG.warn(\"Shuffle failure \", e);\n        sendError(ctx, e.getMessage(), UNAUTHORIZED);\n        return;\n      }\n\n      Map\u003cString, MapOutputInfo\u003e mapOutputInfoMap \u003d\n          new HashMap\u003cString, MapOutputInfo\u003e();\n      Channel ch \u003d evt.getChannel();\n      ChannelPipeline pipeline \u003d ch.getPipeline();\n      TimeoutHandler timeoutHandler \u003d\n          (TimeoutHandler)pipeline.get(TIMEOUT_HANDLER);\n      timeoutHandler.setEnabledTimeout(false);\n      String user \u003d userRsrc.get(jobId);\n\n      try {\n        populateHeaders(mapIds, jobId, user, reduceId, request,\n          response, keepAliveParam, mapOutputInfoMap);\n      } catch(IOException e) {\n        ch.write(response);\n        LOG.error(\"Shuffle error in populating headers :\", e);\n        String errorMessage \u003d getErrorMessage(e);\n        sendError(ctx,errorMessage , INTERNAL_SERVER_ERROR);\n        return;\n      }\n      ch.write(response);\n      //Initialize one ReduceContext object per messageReceived call\n      boolean keepAlive \u003d keepAliveParam || connectionKeepAliveEnabled;\n      ReduceContext reduceContext \u003d new ReduceContext(mapIds, reduceId, ctx,\n          user, mapOutputInfoMap, jobId, keepAlive);\n      for (int i \u003d 0; i \u003c Math.min(maxSessionOpenFiles, mapIds.size()); i++) {\n        ChannelFuture nextMap \u003d sendMap(reduceContext);\n        if(nextMap \u003d\u003d null) {\n          return;\n        }\n      }\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java",
      "extendedDetails": {}
    },
    "a7463b6c88f698950a2f326030261001aa51b35e": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6808. Log map attempts as part of shuffle handler audit log (Contributed by Gergő Pásztor via Daniel Templeton)\n",
      "commitDate": "25/01/17 2:32 PM",
      "commitName": "a7463b6c88f698950a2f326030261001aa51b35e",
      "commitAuthor": "Daniel Templeton",
      "commitDateOld": "27/10/16 4:09 PM",
      "commitNameOld": "5877f20f9c3f6f0afa505715e9a2ee312475af17",
      "commitAuthorOld": "Robert Kanter",
      "daysBetweenCommits": 89.97,
      "commitsBetweenForRepo": 543,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,109 +1,109 @@\n     public void messageReceived(ChannelHandlerContext ctx, MessageEvent evt)\n         throws Exception {\n       HttpRequest request \u003d (HttpRequest) evt.getMessage();\n       if (request.getMethod() !\u003d GET) {\n           sendError(ctx, METHOD_NOT_ALLOWED);\n           return;\n       }\n       // Check whether the shuffle version is compatible\n       if (!ShuffleHeader.DEFAULT_HTTP_HEADER_NAME.equals(\n           request.headers() !\u003d null ?\n               request.headers().get(ShuffleHeader.HTTP_HEADER_NAME) : null)\n           || !ShuffleHeader.DEFAULT_HTTP_HEADER_VERSION.equals(\n               request.headers() !\u003d null ?\n                   request.headers()\n                       .get(ShuffleHeader.HTTP_HEADER_VERSION) : null)) {\n         sendError(ctx, \"Incompatible shuffle request version\", BAD_REQUEST);\n       }\n       final Map\u003cString,List\u003cString\u003e\u003e q \u003d\n         new QueryStringDecoder(request.getUri()).getParameters();\n       final List\u003cString\u003e keepAliveList \u003d q.get(\"keepAlive\");\n       boolean keepAliveParam \u003d false;\n       if (keepAliveList !\u003d null \u0026\u0026 keepAliveList.size() \u003d\u003d 1) {\n         keepAliveParam \u003d Boolean.valueOf(keepAliveList.get(0));\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"KeepAliveParam : \" + keepAliveList\n             + \" : \" + keepAliveParam);\n         }\n       }\n       final List\u003cString\u003e mapIds \u003d splitMaps(q.get(\"map\"));\n       final List\u003cString\u003e reduceQ \u003d q.get(\"reduce\");\n       final List\u003cString\u003e jobQ \u003d q.get(\"job\");\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"RECV: \" + request.getUri() +\n             \"\\n  mapId: \" + mapIds +\n             \"\\n  reduceId: \" + reduceQ +\n             \"\\n  jobId: \" + jobQ +\n             \"\\n  keepAlive: \" + keepAliveParam);\n       }\n \n       if (mapIds \u003d\u003d null || reduceQ \u003d\u003d null || jobQ \u003d\u003d null) {\n         sendError(ctx, \"Required param job, map and reduce\", BAD_REQUEST);\n         return;\n       }\n       if (reduceQ.size() !\u003d 1 || jobQ.size() !\u003d 1) {\n         sendError(ctx, \"Too many job/reduce parameters\", BAD_REQUEST);\n         return;\n       }\n \n       // this audit log is disabled by default,\n       // to turn it on please enable this audit log\n       // on log4j.properties by uncommenting the setting\n       if (AUDITLOG.isDebugEnabled()) {\n-        AUDITLOG.debug(\"shuffle for \" + jobQ.get(0) +\n+        AUDITLOG.debug(\"shuffle for \" + jobQ.get(0) + \" mappers: \" + mapIds +\n                          \" reducer \" + reduceQ.get(0));\n       }\n       int reduceId;\n       String jobId;\n       try {\n         reduceId \u003d Integer.parseInt(reduceQ.get(0));\n         jobId \u003d jobQ.get(0);\n       } catch (NumberFormatException e) {\n         sendError(ctx, \"Bad reduce parameter\", BAD_REQUEST);\n         return;\n       } catch (IllegalArgumentException e) {\n         sendError(ctx, \"Bad job parameter\", BAD_REQUEST);\n         return;\n       }\n       final String reqUri \u003d request.getUri();\n       if (null \u003d\u003d reqUri) {\n         // TODO? add upstream?\n         sendError(ctx, FORBIDDEN);\n         return;\n       }\n       HttpResponse response \u003d new DefaultHttpResponse(HTTP_1_1, OK);\n       try {\n         verifyRequest(jobId, ctx, request, response,\n             new URL(\"http\", \"\", this.port, reqUri));\n       } catch (IOException e) {\n         LOG.warn(\"Shuffle failure \", e);\n         sendError(ctx, e.getMessage(), UNAUTHORIZED);\n         return;\n       }\n \n       Map\u003cString, MapOutputInfo\u003e mapOutputInfoMap \u003d\n           new HashMap\u003cString, MapOutputInfo\u003e();\n       Channel ch \u003d evt.getChannel();\n       String user \u003d userRsrc.get(jobId);\n \n       try {\n         populateHeaders(mapIds, jobId, user, reduceId, request,\n           response, keepAliveParam, mapOutputInfoMap);\n       } catch(IOException e) {\n         ch.write(response);\n         LOG.error(\"Shuffle error in populating headers :\", e);\n         String errorMessage \u003d getErrorMessage(e);\n         sendError(ctx,errorMessage , INTERNAL_SERVER_ERROR);\n         return;\n       }\n       ch.write(response);\n       //Initialize one ReduceContext object per messageReceived call\n       ReduceContext reduceContext \u003d new ReduceContext(mapIds, reduceId, ctx,\n           user, mapOutputInfoMap, jobId);\n       for (int i \u003d 0; i \u003c Math.min(maxSessionOpenFiles, mapIds.size()); i++) {\n         ChannelFuture nextMap \u003d sendMap(reduceContext);\n         if(nextMap \u003d\u003d null) {\n           return;\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void messageReceived(ChannelHandlerContext ctx, MessageEvent evt)\n        throws Exception {\n      HttpRequest request \u003d (HttpRequest) evt.getMessage();\n      if (request.getMethod() !\u003d GET) {\n          sendError(ctx, METHOD_NOT_ALLOWED);\n          return;\n      }\n      // Check whether the shuffle version is compatible\n      if (!ShuffleHeader.DEFAULT_HTTP_HEADER_NAME.equals(\n          request.headers() !\u003d null ?\n              request.headers().get(ShuffleHeader.HTTP_HEADER_NAME) : null)\n          || !ShuffleHeader.DEFAULT_HTTP_HEADER_VERSION.equals(\n              request.headers() !\u003d null ?\n                  request.headers()\n                      .get(ShuffleHeader.HTTP_HEADER_VERSION) : null)) {\n        sendError(ctx, \"Incompatible shuffle request version\", BAD_REQUEST);\n      }\n      final Map\u003cString,List\u003cString\u003e\u003e q \u003d\n        new QueryStringDecoder(request.getUri()).getParameters();\n      final List\u003cString\u003e keepAliveList \u003d q.get(\"keepAlive\");\n      boolean keepAliveParam \u003d false;\n      if (keepAliveList !\u003d null \u0026\u0026 keepAliveList.size() \u003d\u003d 1) {\n        keepAliveParam \u003d Boolean.valueOf(keepAliveList.get(0));\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"KeepAliveParam : \" + keepAliveList\n            + \" : \" + keepAliveParam);\n        }\n      }\n      final List\u003cString\u003e mapIds \u003d splitMaps(q.get(\"map\"));\n      final List\u003cString\u003e reduceQ \u003d q.get(\"reduce\");\n      final List\u003cString\u003e jobQ \u003d q.get(\"job\");\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"RECV: \" + request.getUri() +\n            \"\\n  mapId: \" + mapIds +\n            \"\\n  reduceId: \" + reduceQ +\n            \"\\n  jobId: \" + jobQ +\n            \"\\n  keepAlive: \" + keepAliveParam);\n      }\n\n      if (mapIds \u003d\u003d null || reduceQ \u003d\u003d null || jobQ \u003d\u003d null) {\n        sendError(ctx, \"Required param job, map and reduce\", BAD_REQUEST);\n        return;\n      }\n      if (reduceQ.size() !\u003d 1 || jobQ.size() !\u003d 1) {\n        sendError(ctx, \"Too many job/reduce parameters\", BAD_REQUEST);\n        return;\n      }\n\n      // this audit log is disabled by default,\n      // to turn it on please enable this audit log\n      // on log4j.properties by uncommenting the setting\n      if (AUDITLOG.isDebugEnabled()) {\n        AUDITLOG.debug(\"shuffle for \" + jobQ.get(0) + \" mappers: \" + mapIds +\n                         \" reducer \" + reduceQ.get(0));\n      }\n      int reduceId;\n      String jobId;\n      try {\n        reduceId \u003d Integer.parseInt(reduceQ.get(0));\n        jobId \u003d jobQ.get(0);\n      } catch (NumberFormatException e) {\n        sendError(ctx, \"Bad reduce parameter\", BAD_REQUEST);\n        return;\n      } catch (IllegalArgumentException e) {\n        sendError(ctx, \"Bad job parameter\", BAD_REQUEST);\n        return;\n      }\n      final String reqUri \u003d request.getUri();\n      if (null \u003d\u003d reqUri) {\n        // TODO? add upstream?\n        sendError(ctx, FORBIDDEN);\n        return;\n      }\n      HttpResponse response \u003d new DefaultHttpResponse(HTTP_1_1, OK);\n      try {\n        verifyRequest(jobId, ctx, request, response,\n            new URL(\"http\", \"\", this.port, reqUri));\n      } catch (IOException e) {\n        LOG.warn(\"Shuffle failure \", e);\n        sendError(ctx, e.getMessage(), UNAUTHORIZED);\n        return;\n      }\n\n      Map\u003cString, MapOutputInfo\u003e mapOutputInfoMap \u003d\n          new HashMap\u003cString, MapOutputInfo\u003e();\n      Channel ch \u003d evt.getChannel();\n      String user \u003d userRsrc.get(jobId);\n\n      try {\n        populateHeaders(mapIds, jobId, user, reduceId, request,\n          response, keepAliveParam, mapOutputInfoMap);\n      } catch(IOException e) {\n        ch.write(response);\n        LOG.error(\"Shuffle error in populating headers :\", e);\n        String errorMessage \u003d getErrorMessage(e);\n        sendError(ctx,errorMessage , INTERNAL_SERVER_ERROR);\n        return;\n      }\n      ch.write(response);\n      //Initialize one ReduceContext object per messageReceived call\n      ReduceContext reduceContext \u003d new ReduceContext(mapIds, reduceId, ctx,\n          user, mapOutputInfoMap, jobId);\n      for (int i \u003d 0; i \u003c Math.min(maxSessionOpenFiles, mapIds.size()); i++) {\n        ChannelFuture nextMap \u003d sendMap(reduceContext);\n        if(nextMap \u003d\u003d null) {\n          return;\n        }\n      }\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java",
      "extendedDetails": {}
    },
    "521f34317a2f94ea7e60f3d59db335cef3358e5b": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-12928. Update netty to 3.10.5.Final to sync with zookeeper. (lei)\n",
      "commitDate": "20/07/16 8:38 PM",
      "commitName": "521f34317a2f94ea7e60f3d59db335cef3358e5b",
      "commitAuthor": "Lei Xu",
      "commitDateOld": "21/06/16 2:25 PM",
      "commitNameOld": "d8107fcd1c93c202925f2946d0cd4072fe0aef1e",
      "commitAuthorOld": "Jian He",
      "daysBetweenCommits": 29.26,
      "commitsBetweenForRepo": 326,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,106 +1,109 @@\n     public void messageReceived(ChannelHandlerContext ctx, MessageEvent evt)\n         throws Exception {\n       HttpRequest request \u003d (HttpRequest) evt.getMessage();\n       if (request.getMethod() !\u003d GET) {\n           sendError(ctx, METHOD_NOT_ALLOWED);\n           return;\n       }\n       // Check whether the shuffle version is compatible\n       if (!ShuffleHeader.DEFAULT_HTTP_HEADER_NAME.equals(\n-          request.getHeader(ShuffleHeader.HTTP_HEADER_NAME))\n+          request.headers() !\u003d null ?\n+              request.headers().get(ShuffleHeader.HTTP_HEADER_NAME) : null)\n           || !ShuffleHeader.DEFAULT_HTTP_HEADER_VERSION.equals(\n-              request.getHeader(ShuffleHeader.HTTP_HEADER_VERSION))) {\n+              request.headers() !\u003d null ?\n+                  request.headers()\n+                      .get(ShuffleHeader.HTTP_HEADER_VERSION) : null)) {\n         sendError(ctx, \"Incompatible shuffle request version\", BAD_REQUEST);\n       }\n       final Map\u003cString,List\u003cString\u003e\u003e q \u003d\n         new QueryStringDecoder(request.getUri()).getParameters();\n       final List\u003cString\u003e keepAliveList \u003d q.get(\"keepAlive\");\n       boolean keepAliveParam \u003d false;\n       if (keepAliveList !\u003d null \u0026\u0026 keepAliveList.size() \u003d\u003d 1) {\n         keepAliveParam \u003d Boolean.valueOf(keepAliveList.get(0));\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"KeepAliveParam : \" + keepAliveList\n             + \" : \" + keepAliveParam);\n         }\n       }\n       final List\u003cString\u003e mapIds \u003d splitMaps(q.get(\"map\"));\n       final List\u003cString\u003e reduceQ \u003d q.get(\"reduce\");\n       final List\u003cString\u003e jobQ \u003d q.get(\"job\");\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"RECV: \" + request.getUri() +\n             \"\\n  mapId: \" + mapIds +\n             \"\\n  reduceId: \" + reduceQ +\n             \"\\n  jobId: \" + jobQ +\n             \"\\n  keepAlive: \" + keepAliveParam);\n       }\n \n       if (mapIds \u003d\u003d null || reduceQ \u003d\u003d null || jobQ \u003d\u003d null) {\n         sendError(ctx, \"Required param job, map and reduce\", BAD_REQUEST);\n         return;\n       }\n       if (reduceQ.size() !\u003d 1 || jobQ.size() !\u003d 1) {\n         sendError(ctx, \"Too many job/reduce parameters\", BAD_REQUEST);\n         return;\n       }\n \n       // this audit log is disabled by default,\n       // to turn it on please enable this audit log\n       // on log4j.properties by uncommenting the setting\n       if (AUDITLOG.isDebugEnabled()) {\n         AUDITLOG.debug(\"shuffle for \" + jobQ.get(0) +\n                          \" reducer \" + reduceQ.get(0));\n       }\n       int reduceId;\n       String jobId;\n       try {\n         reduceId \u003d Integer.parseInt(reduceQ.get(0));\n         jobId \u003d jobQ.get(0);\n       } catch (NumberFormatException e) {\n         sendError(ctx, \"Bad reduce parameter\", BAD_REQUEST);\n         return;\n       } catch (IllegalArgumentException e) {\n         sendError(ctx, \"Bad job parameter\", BAD_REQUEST);\n         return;\n       }\n       final String reqUri \u003d request.getUri();\n       if (null \u003d\u003d reqUri) {\n         // TODO? add upstream?\n         sendError(ctx, FORBIDDEN);\n         return;\n       }\n       HttpResponse response \u003d new DefaultHttpResponse(HTTP_1_1, OK);\n       try {\n         verifyRequest(jobId, ctx, request, response,\n             new URL(\"http\", \"\", this.port, reqUri));\n       } catch (IOException e) {\n         LOG.warn(\"Shuffle failure \", e);\n         sendError(ctx, e.getMessage(), UNAUTHORIZED);\n         return;\n       }\n \n       Map\u003cString, MapOutputInfo\u003e mapOutputInfoMap \u003d\n           new HashMap\u003cString, MapOutputInfo\u003e();\n       Channel ch \u003d evt.getChannel();\n       String user \u003d userRsrc.get(jobId);\n \n       try {\n         populateHeaders(mapIds, jobId, user, reduceId, request,\n           response, keepAliveParam, mapOutputInfoMap);\n       } catch(IOException e) {\n         ch.write(response);\n         LOG.error(\"Shuffle error in populating headers :\", e);\n         String errorMessage \u003d getErrorMessage(e);\n         sendError(ctx,errorMessage , INTERNAL_SERVER_ERROR);\n         return;\n       }\n       ch.write(response);\n       //Initialize one ReduceContext object per messageReceived call\n       ReduceContext reduceContext \u003d new ReduceContext(mapIds, reduceId, ctx,\n           user, mapOutputInfoMap, jobId);\n       for (int i \u003d 0; i \u003c Math.min(maxSessionOpenFiles, mapIds.size()); i++) {\n         ChannelFuture nextMap \u003d sendMap(reduceContext);\n         if(nextMap \u003d\u003d null) {\n           return;\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void messageReceived(ChannelHandlerContext ctx, MessageEvent evt)\n        throws Exception {\n      HttpRequest request \u003d (HttpRequest) evt.getMessage();\n      if (request.getMethod() !\u003d GET) {\n          sendError(ctx, METHOD_NOT_ALLOWED);\n          return;\n      }\n      // Check whether the shuffle version is compatible\n      if (!ShuffleHeader.DEFAULT_HTTP_HEADER_NAME.equals(\n          request.headers() !\u003d null ?\n              request.headers().get(ShuffleHeader.HTTP_HEADER_NAME) : null)\n          || !ShuffleHeader.DEFAULT_HTTP_HEADER_VERSION.equals(\n              request.headers() !\u003d null ?\n                  request.headers()\n                      .get(ShuffleHeader.HTTP_HEADER_VERSION) : null)) {\n        sendError(ctx, \"Incompatible shuffle request version\", BAD_REQUEST);\n      }\n      final Map\u003cString,List\u003cString\u003e\u003e q \u003d\n        new QueryStringDecoder(request.getUri()).getParameters();\n      final List\u003cString\u003e keepAliveList \u003d q.get(\"keepAlive\");\n      boolean keepAliveParam \u003d false;\n      if (keepAliveList !\u003d null \u0026\u0026 keepAliveList.size() \u003d\u003d 1) {\n        keepAliveParam \u003d Boolean.valueOf(keepAliveList.get(0));\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"KeepAliveParam : \" + keepAliveList\n            + \" : \" + keepAliveParam);\n        }\n      }\n      final List\u003cString\u003e mapIds \u003d splitMaps(q.get(\"map\"));\n      final List\u003cString\u003e reduceQ \u003d q.get(\"reduce\");\n      final List\u003cString\u003e jobQ \u003d q.get(\"job\");\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"RECV: \" + request.getUri() +\n            \"\\n  mapId: \" + mapIds +\n            \"\\n  reduceId: \" + reduceQ +\n            \"\\n  jobId: \" + jobQ +\n            \"\\n  keepAlive: \" + keepAliveParam);\n      }\n\n      if (mapIds \u003d\u003d null || reduceQ \u003d\u003d null || jobQ \u003d\u003d null) {\n        sendError(ctx, \"Required param job, map and reduce\", BAD_REQUEST);\n        return;\n      }\n      if (reduceQ.size() !\u003d 1 || jobQ.size() !\u003d 1) {\n        sendError(ctx, \"Too many job/reduce parameters\", BAD_REQUEST);\n        return;\n      }\n\n      // this audit log is disabled by default,\n      // to turn it on please enable this audit log\n      // on log4j.properties by uncommenting the setting\n      if (AUDITLOG.isDebugEnabled()) {\n        AUDITLOG.debug(\"shuffle for \" + jobQ.get(0) +\n                         \" reducer \" + reduceQ.get(0));\n      }\n      int reduceId;\n      String jobId;\n      try {\n        reduceId \u003d Integer.parseInt(reduceQ.get(0));\n        jobId \u003d jobQ.get(0);\n      } catch (NumberFormatException e) {\n        sendError(ctx, \"Bad reduce parameter\", BAD_REQUEST);\n        return;\n      } catch (IllegalArgumentException e) {\n        sendError(ctx, \"Bad job parameter\", BAD_REQUEST);\n        return;\n      }\n      final String reqUri \u003d request.getUri();\n      if (null \u003d\u003d reqUri) {\n        // TODO? add upstream?\n        sendError(ctx, FORBIDDEN);\n        return;\n      }\n      HttpResponse response \u003d new DefaultHttpResponse(HTTP_1_1, OK);\n      try {\n        verifyRequest(jobId, ctx, request, response,\n            new URL(\"http\", \"\", this.port, reqUri));\n      } catch (IOException e) {\n        LOG.warn(\"Shuffle failure \", e);\n        sendError(ctx, e.getMessage(), UNAUTHORIZED);\n        return;\n      }\n\n      Map\u003cString, MapOutputInfo\u003e mapOutputInfoMap \u003d\n          new HashMap\u003cString, MapOutputInfo\u003e();\n      Channel ch \u003d evt.getChannel();\n      String user \u003d userRsrc.get(jobId);\n\n      try {\n        populateHeaders(mapIds, jobId, user, reduceId, request,\n          response, keepAliveParam, mapOutputInfoMap);\n      } catch(IOException e) {\n        ch.write(response);\n        LOG.error(\"Shuffle error in populating headers :\", e);\n        String errorMessage \u003d getErrorMessage(e);\n        sendError(ctx,errorMessage , INTERNAL_SERVER_ERROR);\n        return;\n      }\n      ch.write(response);\n      //Initialize one ReduceContext object per messageReceived call\n      ReduceContext reduceContext \u003d new ReduceContext(mapIds, reduceId, ctx,\n          user, mapOutputInfoMap, jobId);\n      for (int i \u003d 0; i \u003c Math.min(maxSessionOpenFiles, mapIds.size()); i++) {\n        ChannelFuture nextMap \u003d sendMap(reduceContext);\n        if(nextMap \u003d\u003d null) {\n          return;\n        }\n      }\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java",
      "extendedDetails": {}
    },
    "d8107fcd1c93c202925f2946d0cd4072fe0aef1e": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6197. Cache MapOutputLocations in ShuffleHandler. Contributed by Junping Du\n",
      "commitDate": "21/06/16 2:25 PM",
      "commitName": "d8107fcd1c93c202925f2946d0cd4072fe0aef1e",
      "commitAuthor": "Jian He",
      "commitDateOld": "14/06/16 3:06 PM",
      "commitNameOld": "c77a1095dc556e8bea87df6d8ddf36e898f27e86",
      "commitAuthorOld": "Wangda Tan",
      "daysBetweenCommits": 6.97,
      "commitsBetweenForRepo": 45,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,111 +1,106 @@\n     public void messageReceived(ChannelHandlerContext ctx, MessageEvent evt)\n         throws Exception {\n       HttpRequest request \u003d (HttpRequest) evt.getMessage();\n       if (request.getMethod() !\u003d GET) {\n           sendError(ctx, METHOD_NOT_ALLOWED);\n           return;\n       }\n       // Check whether the shuffle version is compatible\n       if (!ShuffleHeader.DEFAULT_HTTP_HEADER_NAME.equals(\n           request.getHeader(ShuffleHeader.HTTP_HEADER_NAME))\n           || !ShuffleHeader.DEFAULT_HTTP_HEADER_VERSION.equals(\n               request.getHeader(ShuffleHeader.HTTP_HEADER_VERSION))) {\n         sendError(ctx, \"Incompatible shuffle request version\", BAD_REQUEST);\n       }\n       final Map\u003cString,List\u003cString\u003e\u003e q \u003d\n         new QueryStringDecoder(request.getUri()).getParameters();\n       final List\u003cString\u003e keepAliveList \u003d q.get(\"keepAlive\");\n       boolean keepAliveParam \u003d false;\n       if (keepAliveList !\u003d null \u0026\u0026 keepAliveList.size() \u003d\u003d 1) {\n         keepAliveParam \u003d Boolean.valueOf(keepAliveList.get(0));\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"KeepAliveParam : \" + keepAliveList\n             + \" : \" + keepAliveParam);\n         }\n       }\n       final List\u003cString\u003e mapIds \u003d splitMaps(q.get(\"map\"));\n       final List\u003cString\u003e reduceQ \u003d q.get(\"reduce\");\n       final List\u003cString\u003e jobQ \u003d q.get(\"job\");\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"RECV: \" + request.getUri() +\n             \"\\n  mapId: \" + mapIds +\n             \"\\n  reduceId: \" + reduceQ +\n             \"\\n  jobId: \" + jobQ +\n             \"\\n  keepAlive: \" + keepAliveParam);\n       }\n \n       if (mapIds \u003d\u003d null || reduceQ \u003d\u003d null || jobQ \u003d\u003d null) {\n         sendError(ctx, \"Required param job, map and reduce\", BAD_REQUEST);\n         return;\n       }\n       if (reduceQ.size() !\u003d 1 || jobQ.size() !\u003d 1) {\n         sendError(ctx, \"Too many job/reduce parameters\", BAD_REQUEST);\n         return;\n       }\n \n       // this audit log is disabled by default,\n       // to turn it on please enable this audit log\n       // on log4j.properties by uncommenting the setting\n       if (AUDITLOG.isDebugEnabled()) {\n         AUDITLOG.debug(\"shuffle for \" + jobQ.get(0) +\n                          \" reducer \" + reduceQ.get(0));\n       }\n       int reduceId;\n       String jobId;\n       try {\n         reduceId \u003d Integer.parseInt(reduceQ.get(0));\n         jobId \u003d jobQ.get(0);\n       } catch (NumberFormatException e) {\n         sendError(ctx, \"Bad reduce parameter\", BAD_REQUEST);\n         return;\n       } catch (IllegalArgumentException e) {\n         sendError(ctx, \"Bad job parameter\", BAD_REQUEST);\n         return;\n       }\n       final String reqUri \u003d request.getUri();\n       if (null \u003d\u003d reqUri) {\n         // TODO? add upstream?\n         sendError(ctx, FORBIDDEN);\n         return;\n       }\n       HttpResponse response \u003d new DefaultHttpResponse(HTTP_1_1, OK);\n       try {\n         verifyRequest(jobId, ctx, request, response,\n             new URL(\"http\", \"\", this.port, reqUri));\n       } catch (IOException e) {\n         LOG.warn(\"Shuffle failure \", e);\n         sendError(ctx, e.getMessage(), UNAUTHORIZED);\n         return;\n       }\n \n       Map\u003cString, MapOutputInfo\u003e mapOutputInfoMap \u003d\n           new HashMap\u003cString, MapOutputInfo\u003e();\n       Channel ch \u003d evt.getChannel();\n       String user \u003d userRsrc.get(jobId);\n \n-      // $x/$user/appcache/$appId/output/$mapId\n-      // TODO: Once Shuffle is out of NM, this can use MR APIs to convert\n-      // between App and Job\n-      String outputBasePathStr \u003d getBaseLocation(jobId, user);\n-\n       try {\n-        populateHeaders(mapIds, outputBasePathStr, user, reduceId, request,\n+        populateHeaders(mapIds, jobId, user, reduceId, request,\n           response, keepAliveParam, mapOutputInfoMap);\n       } catch(IOException e) {\n         ch.write(response);\n         LOG.error(\"Shuffle error in populating headers :\", e);\n         String errorMessage \u003d getErrorMessage(e);\n         sendError(ctx,errorMessage , INTERNAL_SERVER_ERROR);\n         return;\n       }\n       ch.write(response);\n       //Initialize one ReduceContext object per messageReceived call\n       ReduceContext reduceContext \u003d new ReduceContext(mapIds, reduceId, ctx,\n-          user, mapOutputInfoMap, outputBasePathStr);\n+          user, mapOutputInfoMap, jobId);\n       for (int i \u003d 0; i \u003c Math.min(maxSessionOpenFiles, mapIds.size()); i++) {\n         ChannelFuture nextMap \u003d sendMap(reduceContext);\n         if(nextMap \u003d\u003d null) {\n           return;\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void messageReceived(ChannelHandlerContext ctx, MessageEvent evt)\n        throws Exception {\n      HttpRequest request \u003d (HttpRequest) evt.getMessage();\n      if (request.getMethod() !\u003d GET) {\n          sendError(ctx, METHOD_NOT_ALLOWED);\n          return;\n      }\n      // Check whether the shuffle version is compatible\n      if (!ShuffleHeader.DEFAULT_HTTP_HEADER_NAME.equals(\n          request.getHeader(ShuffleHeader.HTTP_HEADER_NAME))\n          || !ShuffleHeader.DEFAULT_HTTP_HEADER_VERSION.equals(\n              request.getHeader(ShuffleHeader.HTTP_HEADER_VERSION))) {\n        sendError(ctx, \"Incompatible shuffle request version\", BAD_REQUEST);\n      }\n      final Map\u003cString,List\u003cString\u003e\u003e q \u003d\n        new QueryStringDecoder(request.getUri()).getParameters();\n      final List\u003cString\u003e keepAliveList \u003d q.get(\"keepAlive\");\n      boolean keepAliveParam \u003d false;\n      if (keepAliveList !\u003d null \u0026\u0026 keepAliveList.size() \u003d\u003d 1) {\n        keepAliveParam \u003d Boolean.valueOf(keepAliveList.get(0));\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"KeepAliveParam : \" + keepAliveList\n            + \" : \" + keepAliveParam);\n        }\n      }\n      final List\u003cString\u003e mapIds \u003d splitMaps(q.get(\"map\"));\n      final List\u003cString\u003e reduceQ \u003d q.get(\"reduce\");\n      final List\u003cString\u003e jobQ \u003d q.get(\"job\");\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"RECV: \" + request.getUri() +\n            \"\\n  mapId: \" + mapIds +\n            \"\\n  reduceId: \" + reduceQ +\n            \"\\n  jobId: \" + jobQ +\n            \"\\n  keepAlive: \" + keepAliveParam);\n      }\n\n      if (mapIds \u003d\u003d null || reduceQ \u003d\u003d null || jobQ \u003d\u003d null) {\n        sendError(ctx, \"Required param job, map and reduce\", BAD_REQUEST);\n        return;\n      }\n      if (reduceQ.size() !\u003d 1 || jobQ.size() !\u003d 1) {\n        sendError(ctx, \"Too many job/reduce parameters\", BAD_REQUEST);\n        return;\n      }\n\n      // this audit log is disabled by default,\n      // to turn it on please enable this audit log\n      // on log4j.properties by uncommenting the setting\n      if (AUDITLOG.isDebugEnabled()) {\n        AUDITLOG.debug(\"shuffle for \" + jobQ.get(0) +\n                         \" reducer \" + reduceQ.get(0));\n      }\n      int reduceId;\n      String jobId;\n      try {\n        reduceId \u003d Integer.parseInt(reduceQ.get(0));\n        jobId \u003d jobQ.get(0);\n      } catch (NumberFormatException e) {\n        sendError(ctx, \"Bad reduce parameter\", BAD_REQUEST);\n        return;\n      } catch (IllegalArgumentException e) {\n        sendError(ctx, \"Bad job parameter\", BAD_REQUEST);\n        return;\n      }\n      final String reqUri \u003d request.getUri();\n      if (null \u003d\u003d reqUri) {\n        // TODO? add upstream?\n        sendError(ctx, FORBIDDEN);\n        return;\n      }\n      HttpResponse response \u003d new DefaultHttpResponse(HTTP_1_1, OK);\n      try {\n        verifyRequest(jobId, ctx, request, response,\n            new URL(\"http\", \"\", this.port, reqUri));\n      } catch (IOException e) {\n        LOG.warn(\"Shuffle failure \", e);\n        sendError(ctx, e.getMessage(), UNAUTHORIZED);\n        return;\n      }\n\n      Map\u003cString, MapOutputInfo\u003e mapOutputInfoMap \u003d\n          new HashMap\u003cString, MapOutputInfo\u003e();\n      Channel ch \u003d evt.getChannel();\n      String user \u003d userRsrc.get(jobId);\n\n      try {\n        populateHeaders(mapIds, jobId, user, reduceId, request,\n          response, keepAliveParam, mapOutputInfoMap);\n      } catch(IOException e) {\n        ch.write(response);\n        LOG.error(\"Shuffle error in populating headers :\", e);\n        String errorMessage \u003d getErrorMessage(e);\n        sendError(ctx,errorMessage , INTERNAL_SERVER_ERROR);\n        return;\n      }\n      ch.write(response);\n      //Initialize one ReduceContext object per messageReceived call\n      ReduceContext reduceContext \u003d new ReduceContext(mapIds, reduceId, ctx,\n          user, mapOutputInfoMap, jobId);\n      for (int i \u003d 0; i \u003c Math.min(maxSessionOpenFiles, mapIds.size()); i++) {\n        ChannelFuture nextMap \u003d sendMap(reduceContext);\n        if(nextMap \u003d\u003d null) {\n          return;\n        }\n      }\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java",
      "extendedDetails": {}
    },
    "8e615588d5216394d0251a9c97bd706537856c6d": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6474. ShuffleHandler can possibly exhaust nodemanager file descriptors. Contributed by Kuhu Shukla\n",
      "commitDate": "10/09/15 9:00 AM",
      "commitName": "8e615588d5216394d0251a9c97bd706537856c6d",
      "commitAuthor": "Jason Lowe",
      "commitDateOld": "06/07/15 1:16 AM",
      "commitNameOld": "bff67dfe2f811654ffb1bbcbd87509c185f452b6",
      "commitAuthorOld": "Devaraj K",
      "daysBetweenCommits": 66.32,
      "commitsBetweenForRepo": 376,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,127 +1,111 @@\n     public void messageReceived(ChannelHandlerContext ctx, MessageEvent evt)\n         throws Exception {\n       HttpRequest request \u003d (HttpRequest) evt.getMessage();\n       if (request.getMethod() !\u003d GET) {\n           sendError(ctx, METHOD_NOT_ALLOWED);\n           return;\n       }\n       // Check whether the shuffle version is compatible\n       if (!ShuffleHeader.DEFAULT_HTTP_HEADER_NAME.equals(\n           request.getHeader(ShuffleHeader.HTTP_HEADER_NAME))\n           || !ShuffleHeader.DEFAULT_HTTP_HEADER_VERSION.equals(\n               request.getHeader(ShuffleHeader.HTTP_HEADER_VERSION))) {\n         sendError(ctx, \"Incompatible shuffle request version\", BAD_REQUEST);\n       }\n       final Map\u003cString,List\u003cString\u003e\u003e q \u003d\n         new QueryStringDecoder(request.getUri()).getParameters();\n       final List\u003cString\u003e keepAliveList \u003d q.get(\"keepAlive\");\n       boolean keepAliveParam \u003d false;\n       if (keepAliveList !\u003d null \u0026\u0026 keepAliveList.size() \u003d\u003d 1) {\n         keepAliveParam \u003d Boolean.valueOf(keepAliveList.get(0));\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"KeepAliveParam : \" + keepAliveList\n             + \" : \" + keepAliveParam);\n         }\n       }\n       final List\u003cString\u003e mapIds \u003d splitMaps(q.get(\"map\"));\n       final List\u003cString\u003e reduceQ \u003d q.get(\"reduce\");\n       final List\u003cString\u003e jobQ \u003d q.get(\"job\");\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"RECV: \" + request.getUri() +\n             \"\\n  mapId: \" + mapIds +\n             \"\\n  reduceId: \" + reduceQ +\n             \"\\n  jobId: \" + jobQ +\n             \"\\n  keepAlive: \" + keepAliveParam);\n       }\n \n       if (mapIds \u003d\u003d null || reduceQ \u003d\u003d null || jobQ \u003d\u003d null) {\n         sendError(ctx, \"Required param job, map and reduce\", BAD_REQUEST);\n         return;\n       }\n       if (reduceQ.size() !\u003d 1 || jobQ.size() !\u003d 1) {\n         sendError(ctx, \"Too many job/reduce parameters\", BAD_REQUEST);\n         return;\n       }\n \n       // this audit log is disabled by default,\n       // to turn it on please enable this audit log\n       // on log4j.properties by uncommenting the setting\n       if (AUDITLOG.isDebugEnabled()) {\n         AUDITLOG.debug(\"shuffle for \" + jobQ.get(0) +\n                          \" reducer \" + reduceQ.get(0));\n       }\n       int reduceId;\n       String jobId;\n       try {\n         reduceId \u003d Integer.parseInt(reduceQ.get(0));\n         jobId \u003d jobQ.get(0);\n       } catch (NumberFormatException e) {\n         sendError(ctx, \"Bad reduce parameter\", BAD_REQUEST);\n         return;\n       } catch (IllegalArgumentException e) {\n         sendError(ctx, \"Bad job parameter\", BAD_REQUEST);\n         return;\n       }\n       final String reqUri \u003d request.getUri();\n       if (null \u003d\u003d reqUri) {\n         // TODO? add upstream?\n         sendError(ctx, FORBIDDEN);\n         return;\n       }\n       HttpResponse response \u003d new DefaultHttpResponse(HTTP_1_1, OK);\n       try {\n         verifyRequest(jobId, ctx, request, response,\n             new URL(\"http\", \"\", this.port, reqUri));\n       } catch (IOException e) {\n         LOG.warn(\"Shuffle failure \", e);\n         sendError(ctx, e.getMessage(), UNAUTHORIZED);\n         return;\n       }\n \n       Map\u003cString, MapOutputInfo\u003e mapOutputInfoMap \u003d\n           new HashMap\u003cString, MapOutputInfo\u003e();\n       Channel ch \u003d evt.getChannel();\n       String user \u003d userRsrc.get(jobId);\n \n       // $x/$user/appcache/$appId/output/$mapId\n       // TODO: Once Shuffle is out of NM, this can use MR APIs to convert\n       // between App and Job\n       String outputBasePathStr \u003d getBaseLocation(jobId, user);\n \n       try {\n         populateHeaders(mapIds, outputBasePathStr, user, reduceId, request,\n           response, keepAliveParam, mapOutputInfoMap);\n       } catch(IOException e) {\n         ch.write(response);\n         LOG.error(\"Shuffle error in populating headers :\", e);\n         String errorMessage \u003d getErrorMessage(e);\n         sendError(ctx,errorMessage , INTERNAL_SERVER_ERROR);\n         return;\n       }\n       ch.write(response);\n-      // TODO refactor the following into the pipeline\n-      ChannelFuture lastMap \u003d null;\n-      for (String mapId : mapIds) {\n-        try {\n-          MapOutputInfo info \u003d mapOutputInfoMap.get(mapId);\n-          if (info \u003d\u003d null) {\n-            info \u003d getMapOutputInfo(outputBasePathStr + mapId,\n-                mapId, reduceId, user);\n-          }\n-          lastMap \u003d\n-              sendMapOutput(ctx, ch, user, mapId,\n-                reduceId, info);\n-          if (null \u003d\u003d lastMap) {\n-            sendError(ctx, NOT_FOUND);\n-            return;\n-          }\n-        } catch (IOException e) {\n-          LOG.error(\"Shuffle error :\", e);\n-          String errorMessage \u003d getErrorMessage(e);\n-          sendError(ctx,errorMessage , INTERNAL_SERVER_ERROR);\n+      //Initialize one ReduceContext object per messageReceived call\n+      ReduceContext reduceContext \u003d new ReduceContext(mapIds, reduceId, ctx,\n+          user, mapOutputInfoMap, outputBasePathStr);\n+      for (int i \u003d 0; i \u003c Math.min(maxSessionOpenFiles, mapIds.size()); i++) {\n+        ChannelFuture nextMap \u003d sendMap(reduceContext);\n+        if(nextMap \u003d\u003d null) {\n           return;\n         }\n       }\n-      lastMap.addListener(metrics);\n-      lastMap.addListener(ChannelFutureListener.CLOSE);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void messageReceived(ChannelHandlerContext ctx, MessageEvent evt)\n        throws Exception {\n      HttpRequest request \u003d (HttpRequest) evt.getMessage();\n      if (request.getMethod() !\u003d GET) {\n          sendError(ctx, METHOD_NOT_ALLOWED);\n          return;\n      }\n      // Check whether the shuffle version is compatible\n      if (!ShuffleHeader.DEFAULT_HTTP_HEADER_NAME.equals(\n          request.getHeader(ShuffleHeader.HTTP_HEADER_NAME))\n          || !ShuffleHeader.DEFAULT_HTTP_HEADER_VERSION.equals(\n              request.getHeader(ShuffleHeader.HTTP_HEADER_VERSION))) {\n        sendError(ctx, \"Incompatible shuffle request version\", BAD_REQUEST);\n      }\n      final Map\u003cString,List\u003cString\u003e\u003e q \u003d\n        new QueryStringDecoder(request.getUri()).getParameters();\n      final List\u003cString\u003e keepAliveList \u003d q.get(\"keepAlive\");\n      boolean keepAliveParam \u003d false;\n      if (keepAliveList !\u003d null \u0026\u0026 keepAliveList.size() \u003d\u003d 1) {\n        keepAliveParam \u003d Boolean.valueOf(keepAliveList.get(0));\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"KeepAliveParam : \" + keepAliveList\n            + \" : \" + keepAliveParam);\n        }\n      }\n      final List\u003cString\u003e mapIds \u003d splitMaps(q.get(\"map\"));\n      final List\u003cString\u003e reduceQ \u003d q.get(\"reduce\");\n      final List\u003cString\u003e jobQ \u003d q.get(\"job\");\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"RECV: \" + request.getUri() +\n            \"\\n  mapId: \" + mapIds +\n            \"\\n  reduceId: \" + reduceQ +\n            \"\\n  jobId: \" + jobQ +\n            \"\\n  keepAlive: \" + keepAliveParam);\n      }\n\n      if (mapIds \u003d\u003d null || reduceQ \u003d\u003d null || jobQ \u003d\u003d null) {\n        sendError(ctx, \"Required param job, map and reduce\", BAD_REQUEST);\n        return;\n      }\n      if (reduceQ.size() !\u003d 1 || jobQ.size() !\u003d 1) {\n        sendError(ctx, \"Too many job/reduce parameters\", BAD_REQUEST);\n        return;\n      }\n\n      // this audit log is disabled by default,\n      // to turn it on please enable this audit log\n      // on log4j.properties by uncommenting the setting\n      if (AUDITLOG.isDebugEnabled()) {\n        AUDITLOG.debug(\"shuffle for \" + jobQ.get(0) +\n                         \" reducer \" + reduceQ.get(0));\n      }\n      int reduceId;\n      String jobId;\n      try {\n        reduceId \u003d Integer.parseInt(reduceQ.get(0));\n        jobId \u003d jobQ.get(0);\n      } catch (NumberFormatException e) {\n        sendError(ctx, \"Bad reduce parameter\", BAD_REQUEST);\n        return;\n      } catch (IllegalArgumentException e) {\n        sendError(ctx, \"Bad job parameter\", BAD_REQUEST);\n        return;\n      }\n      final String reqUri \u003d request.getUri();\n      if (null \u003d\u003d reqUri) {\n        // TODO? add upstream?\n        sendError(ctx, FORBIDDEN);\n        return;\n      }\n      HttpResponse response \u003d new DefaultHttpResponse(HTTP_1_1, OK);\n      try {\n        verifyRequest(jobId, ctx, request, response,\n            new URL(\"http\", \"\", this.port, reqUri));\n      } catch (IOException e) {\n        LOG.warn(\"Shuffle failure \", e);\n        sendError(ctx, e.getMessage(), UNAUTHORIZED);\n        return;\n      }\n\n      Map\u003cString, MapOutputInfo\u003e mapOutputInfoMap \u003d\n          new HashMap\u003cString, MapOutputInfo\u003e();\n      Channel ch \u003d evt.getChannel();\n      String user \u003d userRsrc.get(jobId);\n\n      // $x/$user/appcache/$appId/output/$mapId\n      // TODO: Once Shuffle is out of NM, this can use MR APIs to convert\n      // between App and Job\n      String outputBasePathStr \u003d getBaseLocation(jobId, user);\n\n      try {\n        populateHeaders(mapIds, outputBasePathStr, user, reduceId, request,\n          response, keepAliveParam, mapOutputInfoMap);\n      } catch(IOException e) {\n        ch.write(response);\n        LOG.error(\"Shuffle error in populating headers :\", e);\n        String errorMessage \u003d getErrorMessage(e);\n        sendError(ctx,errorMessage , INTERNAL_SERVER_ERROR);\n        return;\n      }\n      ch.write(response);\n      //Initialize one ReduceContext object per messageReceived call\n      ReduceContext reduceContext \u003d new ReduceContext(mapIds, reduceId, ctx,\n          user, mapOutputInfoMap, outputBasePathStr);\n      for (int i \u003d 0; i \u003c Math.min(maxSessionOpenFiles, mapIds.size()); i++) {\n        ChannelFuture nextMap \u003d sendMap(reduceContext);\n        if(nextMap \u003d\u003d null) {\n          return;\n        }\n      }\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java",
      "extendedDetails": {}
    },
    "bff67dfe2f811654ffb1bbcbd87509c185f452b6": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6425. ShuffleHandler passes wrong \"base\" parameter to\ngetMapOutputInfo if mapId is not in the cache. Contributed by zhihai xu.\n",
      "commitDate": "06/07/15 1:16 AM",
      "commitName": "bff67dfe2f811654ffb1bbcbd87509c185f452b6",
      "commitAuthor": "Devaraj K",
      "commitDateOld": "05/06/15 3:38 PM",
      "commitNameOld": "b3ffa870034d06608a1946e2d9ce7dbd535a2c53",
      "commitAuthorOld": "Jason Lowe",
      "daysBetweenCommits": 30.4,
      "commitsBetweenForRepo": 184,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,126 +1,127 @@\n     public void messageReceived(ChannelHandlerContext ctx, MessageEvent evt)\n         throws Exception {\n       HttpRequest request \u003d (HttpRequest) evt.getMessage();\n       if (request.getMethod() !\u003d GET) {\n           sendError(ctx, METHOD_NOT_ALLOWED);\n           return;\n       }\n       // Check whether the shuffle version is compatible\n       if (!ShuffleHeader.DEFAULT_HTTP_HEADER_NAME.equals(\n           request.getHeader(ShuffleHeader.HTTP_HEADER_NAME))\n           || !ShuffleHeader.DEFAULT_HTTP_HEADER_VERSION.equals(\n               request.getHeader(ShuffleHeader.HTTP_HEADER_VERSION))) {\n         sendError(ctx, \"Incompatible shuffle request version\", BAD_REQUEST);\n       }\n       final Map\u003cString,List\u003cString\u003e\u003e q \u003d\n         new QueryStringDecoder(request.getUri()).getParameters();\n       final List\u003cString\u003e keepAliveList \u003d q.get(\"keepAlive\");\n       boolean keepAliveParam \u003d false;\n       if (keepAliveList !\u003d null \u0026\u0026 keepAliveList.size() \u003d\u003d 1) {\n         keepAliveParam \u003d Boolean.valueOf(keepAliveList.get(0));\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"KeepAliveParam : \" + keepAliveList\n             + \" : \" + keepAliveParam);\n         }\n       }\n       final List\u003cString\u003e mapIds \u003d splitMaps(q.get(\"map\"));\n       final List\u003cString\u003e reduceQ \u003d q.get(\"reduce\");\n       final List\u003cString\u003e jobQ \u003d q.get(\"job\");\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"RECV: \" + request.getUri() +\n             \"\\n  mapId: \" + mapIds +\n             \"\\n  reduceId: \" + reduceQ +\n             \"\\n  jobId: \" + jobQ +\n             \"\\n  keepAlive: \" + keepAliveParam);\n       }\n \n       if (mapIds \u003d\u003d null || reduceQ \u003d\u003d null || jobQ \u003d\u003d null) {\n         sendError(ctx, \"Required param job, map and reduce\", BAD_REQUEST);\n         return;\n       }\n       if (reduceQ.size() !\u003d 1 || jobQ.size() !\u003d 1) {\n         sendError(ctx, \"Too many job/reduce parameters\", BAD_REQUEST);\n         return;\n       }\n \n       // this audit log is disabled by default,\n       // to turn it on please enable this audit log\n       // on log4j.properties by uncommenting the setting\n       if (AUDITLOG.isDebugEnabled()) {\n         AUDITLOG.debug(\"shuffle for \" + jobQ.get(0) +\n                          \" reducer \" + reduceQ.get(0));\n       }\n       int reduceId;\n       String jobId;\n       try {\n         reduceId \u003d Integer.parseInt(reduceQ.get(0));\n         jobId \u003d jobQ.get(0);\n       } catch (NumberFormatException e) {\n         sendError(ctx, \"Bad reduce parameter\", BAD_REQUEST);\n         return;\n       } catch (IllegalArgumentException e) {\n         sendError(ctx, \"Bad job parameter\", BAD_REQUEST);\n         return;\n       }\n       final String reqUri \u003d request.getUri();\n       if (null \u003d\u003d reqUri) {\n         // TODO? add upstream?\n         sendError(ctx, FORBIDDEN);\n         return;\n       }\n       HttpResponse response \u003d new DefaultHttpResponse(HTTP_1_1, OK);\n       try {\n         verifyRequest(jobId, ctx, request, response,\n             new URL(\"http\", \"\", this.port, reqUri));\n       } catch (IOException e) {\n         LOG.warn(\"Shuffle failure \", e);\n         sendError(ctx, e.getMessage(), UNAUTHORIZED);\n         return;\n       }\n \n       Map\u003cString, MapOutputInfo\u003e mapOutputInfoMap \u003d\n           new HashMap\u003cString, MapOutputInfo\u003e();\n       Channel ch \u003d evt.getChannel();\n       String user \u003d userRsrc.get(jobId);\n \n       // $x/$user/appcache/$appId/output/$mapId\n       // TODO: Once Shuffle is out of NM, this can use MR APIs to convert\n       // between App and Job\n       String outputBasePathStr \u003d getBaseLocation(jobId, user);\n \n       try {\n         populateHeaders(mapIds, outputBasePathStr, user, reduceId, request,\n           response, keepAliveParam, mapOutputInfoMap);\n       } catch(IOException e) {\n         ch.write(response);\n         LOG.error(\"Shuffle error in populating headers :\", e);\n         String errorMessage \u003d getErrorMessage(e);\n         sendError(ctx,errorMessage , INTERNAL_SERVER_ERROR);\n         return;\n       }\n       ch.write(response);\n       // TODO refactor the following into the pipeline\n       ChannelFuture lastMap \u003d null;\n       for (String mapId : mapIds) {\n         try {\n           MapOutputInfo info \u003d mapOutputInfoMap.get(mapId);\n           if (info \u003d\u003d null) {\n-            info \u003d getMapOutputInfo(outputBasePathStr, mapId, reduceId, user);\n+            info \u003d getMapOutputInfo(outputBasePathStr + mapId,\n+                mapId, reduceId, user);\n           }\n           lastMap \u003d\n               sendMapOutput(ctx, ch, user, mapId,\n                 reduceId, info);\n           if (null \u003d\u003d lastMap) {\n             sendError(ctx, NOT_FOUND);\n             return;\n           }\n         } catch (IOException e) {\n           LOG.error(\"Shuffle error :\", e);\n           String errorMessage \u003d getErrorMessage(e);\n           sendError(ctx,errorMessage , INTERNAL_SERVER_ERROR);\n           return;\n         }\n       }\n       lastMap.addListener(metrics);\n       lastMap.addListener(ChannelFutureListener.CLOSE);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void messageReceived(ChannelHandlerContext ctx, MessageEvent evt)\n        throws Exception {\n      HttpRequest request \u003d (HttpRequest) evt.getMessage();\n      if (request.getMethod() !\u003d GET) {\n          sendError(ctx, METHOD_NOT_ALLOWED);\n          return;\n      }\n      // Check whether the shuffle version is compatible\n      if (!ShuffleHeader.DEFAULT_HTTP_HEADER_NAME.equals(\n          request.getHeader(ShuffleHeader.HTTP_HEADER_NAME))\n          || !ShuffleHeader.DEFAULT_HTTP_HEADER_VERSION.equals(\n              request.getHeader(ShuffleHeader.HTTP_HEADER_VERSION))) {\n        sendError(ctx, \"Incompatible shuffle request version\", BAD_REQUEST);\n      }\n      final Map\u003cString,List\u003cString\u003e\u003e q \u003d\n        new QueryStringDecoder(request.getUri()).getParameters();\n      final List\u003cString\u003e keepAliveList \u003d q.get(\"keepAlive\");\n      boolean keepAliveParam \u003d false;\n      if (keepAliveList !\u003d null \u0026\u0026 keepAliveList.size() \u003d\u003d 1) {\n        keepAliveParam \u003d Boolean.valueOf(keepAliveList.get(0));\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"KeepAliveParam : \" + keepAliveList\n            + \" : \" + keepAliveParam);\n        }\n      }\n      final List\u003cString\u003e mapIds \u003d splitMaps(q.get(\"map\"));\n      final List\u003cString\u003e reduceQ \u003d q.get(\"reduce\");\n      final List\u003cString\u003e jobQ \u003d q.get(\"job\");\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"RECV: \" + request.getUri() +\n            \"\\n  mapId: \" + mapIds +\n            \"\\n  reduceId: \" + reduceQ +\n            \"\\n  jobId: \" + jobQ +\n            \"\\n  keepAlive: \" + keepAliveParam);\n      }\n\n      if (mapIds \u003d\u003d null || reduceQ \u003d\u003d null || jobQ \u003d\u003d null) {\n        sendError(ctx, \"Required param job, map and reduce\", BAD_REQUEST);\n        return;\n      }\n      if (reduceQ.size() !\u003d 1 || jobQ.size() !\u003d 1) {\n        sendError(ctx, \"Too many job/reduce parameters\", BAD_REQUEST);\n        return;\n      }\n\n      // this audit log is disabled by default,\n      // to turn it on please enable this audit log\n      // on log4j.properties by uncommenting the setting\n      if (AUDITLOG.isDebugEnabled()) {\n        AUDITLOG.debug(\"shuffle for \" + jobQ.get(0) +\n                         \" reducer \" + reduceQ.get(0));\n      }\n      int reduceId;\n      String jobId;\n      try {\n        reduceId \u003d Integer.parseInt(reduceQ.get(0));\n        jobId \u003d jobQ.get(0);\n      } catch (NumberFormatException e) {\n        sendError(ctx, \"Bad reduce parameter\", BAD_REQUEST);\n        return;\n      } catch (IllegalArgumentException e) {\n        sendError(ctx, \"Bad job parameter\", BAD_REQUEST);\n        return;\n      }\n      final String reqUri \u003d request.getUri();\n      if (null \u003d\u003d reqUri) {\n        // TODO? add upstream?\n        sendError(ctx, FORBIDDEN);\n        return;\n      }\n      HttpResponse response \u003d new DefaultHttpResponse(HTTP_1_1, OK);\n      try {\n        verifyRequest(jobId, ctx, request, response,\n            new URL(\"http\", \"\", this.port, reqUri));\n      } catch (IOException e) {\n        LOG.warn(\"Shuffle failure \", e);\n        sendError(ctx, e.getMessage(), UNAUTHORIZED);\n        return;\n      }\n\n      Map\u003cString, MapOutputInfo\u003e mapOutputInfoMap \u003d\n          new HashMap\u003cString, MapOutputInfo\u003e();\n      Channel ch \u003d evt.getChannel();\n      String user \u003d userRsrc.get(jobId);\n\n      // $x/$user/appcache/$appId/output/$mapId\n      // TODO: Once Shuffle is out of NM, this can use MR APIs to convert\n      // between App and Job\n      String outputBasePathStr \u003d getBaseLocation(jobId, user);\n\n      try {\n        populateHeaders(mapIds, outputBasePathStr, user, reduceId, request,\n          response, keepAliveParam, mapOutputInfoMap);\n      } catch(IOException e) {\n        ch.write(response);\n        LOG.error(\"Shuffle error in populating headers :\", e);\n        String errorMessage \u003d getErrorMessage(e);\n        sendError(ctx,errorMessage , INTERNAL_SERVER_ERROR);\n        return;\n      }\n      ch.write(response);\n      // TODO refactor the following into the pipeline\n      ChannelFuture lastMap \u003d null;\n      for (String mapId : mapIds) {\n        try {\n          MapOutputInfo info \u003d mapOutputInfoMap.get(mapId);\n          if (info \u003d\u003d null) {\n            info \u003d getMapOutputInfo(outputBasePathStr + mapId,\n                mapId, reduceId, user);\n          }\n          lastMap \u003d\n              sendMapOutput(ctx, ch, user, mapId,\n                reduceId, info);\n          if (null \u003d\u003d lastMap) {\n            sendError(ctx, NOT_FOUND);\n            return;\n          }\n        } catch (IOException e) {\n          LOG.error(\"Shuffle error :\", e);\n          String errorMessage \u003d getErrorMessage(e);\n          sendError(ctx,errorMessage , INTERNAL_SERVER_ERROR);\n          return;\n        }\n      }\n      lastMap.addListener(metrics);\n      lastMap.addListener(ChannelFutureListener.CLOSE);\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java",
      "extendedDetails": {}
    },
    "b3ffa870034d06608a1946e2d9ce7dbd535a2c53": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6354. ShuffleHandler should be able to log shuffle connections. Contributed by Chang Li\n",
      "commitDate": "05/06/15 3:38 PM",
      "commitName": "b3ffa870034d06608a1946e2d9ce7dbd535a2c53",
      "commitAuthor": "Jason Lowe",
      "commitDateOld": "19/12/14 4:56 PM",
      "commitNameOld": "808cba3821d5bc4267f69d14220757f01cd55715",
      "commitAuthorOld": "Jian He",
      "daysBetweenCommits": 167.9,
      "commitsBetweenForRepo": 1438,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,118 +1,126 @@\n     public void messageReceived(ChannelHandlerContext ctx, MessageEvent evt)\n         throws Exception {\n       HttpRequest request \u003d (HttpRequest) evt.getMessage();\n       if (request.getMethod() !\u003d GET) {\n           sendError(ctx, METHOD_NOT_ALLOWED);\n           return;\n       }\n       // Check whether the shuffle version is compatible\n       if (!ShuffleHeader.DEFAULT_HTTP_HEADER_NAME.equals(\n           request.getHeader(ShuffleHeader.HTTP_HEADER_NAME))\n           || !ShuffleHeader.DEFAULT_HTTP_HEADER_VERSION.equals(\n               request.getHeader(ShuffleHeader.HTTP_HEADER_VERSION))) {\n         sendError(ctx, \"Incompatible shuffle request version\", BAD_REQUEST);\n       }\n       final Map\u003cString,List\u003cString\u003e\u003e q \u003d\n         new QueryStringDecoder(request.getUri()).getParameters();\n       final List\u003cString\u003e keepAliveList \u003d q.get(\"keepAlive\");\n       boolean keepAliveParam \u003d false;\n       if (keepAliveList !\u003d null \u0026\u0026 keepAliveList.size() \u003d\u003d 1) {\n         keepAliveParam \u003d Boolean.valueOf(keepAliveList.get(0));\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"KeepAliveParam : \" + keepAliveList\n             + \" : \" + keepAliveParam);\n         }\n       }\n       final List\u003cString\u003e mapIds \u003d splitMaps(q.get(\"map\"));\n       final List\u003cString\u003e reduceQ \u003d q.get(\"reduce\");\n       final List\u003cString\u003e jobQ \u003d q.get(\"job\");\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"RECV: \" + request.getUri() +\n             \"\\n  mapId: \" + mapIds +\n             \"\\n  reduceId: \" + reduceQ +\n             \"\\n  jobId: \" + jobQ +\n             \"\\n  keepAlive: \" + keepAliveParam);\n       }\n \n       if (mapIds \u003d\u003d null || reduceQ \u003d\u003d null || jobQ \u003d\u003d null) {\n         sendError(ctx, \"Required param job, map and reduce\", BAD_REQUEST);\n         return;\n       }\n       if (reduceQ.size() !\u003d 1 || jobQ.size() !\u003d 1) {\n         sendError(ctx, \"Too many job/reduce parameters\", BAD_REQUEST);\n         return;\n       }\n+\n+      // this audit log is disabled by default,\n+      // to turn it on please enable this audit log\n+      // on log4j.properties by uncommenting the setting\n+      if (AUDITLOG.isDebugEnabled()) {\n+        AUDITLOG.debug(\"shuffle for \" + jobQ.get(0) +\n+                         \" reducer \" + reduceQ.get(0));\n+      }\n       int reduceId;\n       String jobId;\n       try {\n         reduceId \u003d Integer.parseInt(reduceQ.get(0));\n         jobId \u003d jobQ.get(0);\n       } catch (NumberFormatException e) {\n         sendError(ctx, \"Bad reduce parameter\", BAD_REQUEST);\n         return;\n       } catch (IllegalArgumentException e) {\n         sendError(ctx, \"Bad job parameter\", BAD_REQUEST);\n         return;\n       }\n       final String reqUri \u003d request.getUri();\n       if (null \u003d\u003d reqUri) {\n         // TODO? add upstream?\n         sendError(ctx, FORBIDDEN);\n         return;\n       }\n       HttpResponse response \u003d new DefaultHttpResponse(HTTP_1_1, OK);\n       try {\n         verifyRequest(jobId, ctx, request, response,\n             new URL(\"http\", \"\", this.port, reqUri));\n       } catch (IOException e) {\n         LOG.warn(\"Shuffle failure \", e);\n         sendError(ctx, e.getMessage(), UNAUTHORIZED);\n         return;\n       }\n \n       Map\u003cString, MapOutputInfo\u003e mapOutputInfoMap \u003d\n           new HashMap\u003cString, MapOutputInfo\u003e();\n       Channel ch \u003d evt.getChannel();\n       String user \u003d userRsrc.get(jobId);\n \n       // $x/$user/appcache/$appId/output/$mapId\n       // TODO: Once Shuffle is out of NM, this can use MR APIs to convert\n       // between App and Job\n       String outputBasePathStr \u003d getBaseLocation(jobId, user);\n \n       try {\n         populateHeaders(mapIds, outputBasePathStr, user, reduceId, request,\n           response, keepAliveParam, mapOutputInfoMap);\n       } catch(IOException e) {\n         ch.write(response);\n         LOG.error(\"Shuffle error in populating headers :\", e);\n         String errorMessage \u003d getErrorMessage(e);\n         sendError(ctx,errorMessage , INTERNAL_SERVER_ERROR);\n         return;\n       }\n       ch.write(response);\n       // TODO refactor the following into the pipeline\n       ChannelFuture lastMap \u003d null;\n       for (String mapId : mapIds) {\n         try {\n           MapOutputInfo info \u003d mapOutputInfoMap.get(mapId);\n           if (info \u003d\u003d null) {\n             info \u003d getMapOutputInfo(outputBasePathStr, mapId, reduceId, user);\n           }\n           lastMap \u003d\n               sendMapOutput(ctx, ch, user, mapId,\n                 reduceId, info);\n           if (null \u003d\u003d lastMap) {\n             sendError(ctx, NOT_FOUND);\n             return;\n           }\n         } catch (IOException e) {\n           LOG.error(\"Shuffle error :\", e);\n           String errorMessage \u003d getErrorMessage(e);\n           sendError(ctx,errorMessage , INTERNAL_SERVER_ERROR);\n           return;\n         }\n       }\n       lastMap.addListener(metrics);\n       lastMap.addListener(ChannelFutureListener.CLOSE);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void messageReceived(ChannelHandlerContext ctx, MessageEvent evt)\n        throws Exception {\n      HttpRequest request \u003d (HttpRequest) evt.getMessage();\n      if (request.getMethod() !\u003d GET) {\n          sendError(ctx, METHOD_NOT_ALLOWED);\n          return;\n      }\n      // Check whether the shuffle version is compatible\n      if (!ShuffleHeader.DEFAULT_HTTP_HEADER_NAME.equals(\n          request.getHeader(ShuffleHeader.HTTP_HEADER_NAME))\n          || !ShuffleHeader.DEFAULT_HTTP_HEADER_VERSION.equals(\n              request.getHeader(ShuffleHeader.HTTP_HEADER_VERSION))) {\n        sendError(ctx, \"Incompatible shuffle request version\", BAD_REQUEST);\n      }\n      final Map\u003cString,List\u003cString\u003e\u003e q \u003d\n        new QueryStringDecoder(request.getUri()).getParameters();\n      final List\u003cString\u003e keepAliveList \u003d q.get(\"keepAlive\");\n      boolean keepAliveParam \u003d false;\n      if (keepAliveList !\u003d null \u0026\u0026 keepAliveList.size() \u003d\u003d 1) {\n        keepAliveParam \u003d Boolean.valueOf(keepAliveList.get(0));\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"KeepAliveParam : \" + keepAliveList\n            + \" : \" + keepAliveParam);\n        }\n      }\n      final List\u003cString\u003e mapIds \u003d splitMaps(q.get(\"map\"));\n      final List\u003cString\u003e reduceQ \u003d q.get(\"reduce\");\n      final List\u003cString\u003e jobQ \u003d q.get(\"job\");\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"RECV: \" + request.getUri() +\n            \"\\n  mapId: \" + mapIds +\n            \"\\n  reduceId: \" + reduceQ +\n            \"\\n  jobId: \" + jobQ +\n            \"\\n  keepAlive: \" + keepAliveParam);\n      }\n\n      if (mapIds \u003d\u003d null || reduceQ \u003d\u003d null || jobQ \u003d\u003d null) {\n        sendError(ctx, \"Required param job, map and reduce\", BAD_REQUEST);\n        return;\n      }\n      if (reduceQ.size() !\u003d 1 || jobQ.size() !\u003d 1) {\n        sendError(ctx, \"Too many job/reduce parameters\", BAD_REQUEST);\n        return;\n      }\n\n      // this audit log is disabled by default,\n      // to turn it on please enable this audit log\n      // on log4j.properties by uncommenting the setting\n      if (AUDITLOG.isDebugEnabled()) {\n        AUDITLOG.debug(\"shuffle for \" + jobQ.get(0) +\n                         \" reducer \" + reduceQ.get(0));\n      }\n      int reduceId;\n      String jobId;\n      try {\n        reduceId \u003d Integer.parseInt(reduceQ.get(0));\n        jobId \u003d jobQ.get(0);\n      } catch (NumberFormatException e) {\n        sendError(ctx, \"Bad reduce parameter\", BAD_REQUEST);\n        return;\n      } catch (IllegalArgumentException e) {\n        sendError(ctx, \"Bad job parameter\", BAD_REQUEST);\n        return;\n      }\n      final String reqUri \u003d request.getUri();\n      if (null \u003d\u003d reqUri) {\n        // TODO? add upstream?\n        sendError(ctx, FORBIDDEN);\n        return;\n      }\n      HttpResponse response \u003d new DefaultHttpResponse(HTTP_1_1, OK);\n      try {\n        verifyRequest(jobId, ctx, request, response,\n            new URL(\"http\", \"\", this.port, reqUri));\n      } catch (IOException e) {\n        LOG.warn(\"Shuffle failure \", e);\n        sendError(ctx, e.getMessage(), UNAUTHORIZED);\n        return;\n      }\n\n      Map\u003cString, MapOutputInfo\u003e mapOutputInfoMap \u003d\n          new HashMap\u003cString, MapOutputInfo\u003e();\n      Channel ch \u003d evt.getChannel();\n      String user \u003d userRsrc.get(jobId);\n\n      // $x/$user/appcache/$appId/output/$mapId\n      // TODO: Once Shuffle is out of NM, this can use MR APIs to convert\n      // between App and Job\n      String outputBasePathStr \u003d getBaseLocation(jobId, user);\n\n      try {\n        populateHeaders(mapIds, outputBasePathStr, user, reduceId, request,\n          response, keepAliveParam, mapOutputInfoMap);\n      } catch(IOException e) {\n        ch.write(response);\n        LOG.error(\"Shuffle error in populating headers :\", e);\n        String errorMessage \u003d getErrorMessage(e);\n        sendError(ctx,errorMessage , INTERNAL_SERVER_ERROR);\n        return;\n      }\n      ch.write(response);\n      // TODO refactor the following into the pipeline\n      ChannelFuture lastMap \u003d null;\n      for (String mapId : mapIds) {\n        try {\n          MapOutputInfo info \u003d mapOutputInfoMap.get(mapId);\n          if (info \u003d\u003d null) {\n            info \u003d getMapOutputInfo(outputBasePathStr, mapId, reduceId, user);\n          }\n          lastMap \u003d\n              sendMapOutput(ctx, ch, user, mapId,\n                reduceId, info);\n          if (null \u003d\u003d lastMap) {\n            sendError(ctx, NOT_FOUND);\n            return;\n          }\n        } catch (IOException e) {\n          LOG.error(\"Shuffle error :\", e);\n          String errorMessage \u003d getErrorMessage(e);\n          sendError(ctx,errorMessage , INTERNAL_SERVER_ERROR);\n          return;\n        }\n      }\n      lastMap.addListener(metrics);\n      lastMap.addListener(ChannelFutureListener.CLOSE);\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java",
      "extendedDetails": {}
    },
    "a5c08eed16e797d2ba9f98f7bc6a8e1bf09aaddd": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5787. Added the ability to keep alive shuffle connections in the MapReduce shuffle-handler. Contributed by Rajesh Balamohan.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1580062 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/03/14 2:43 PM",
      "commitName": "a5c08eed16e797d2ba9f98f7bc6a8e1bf09aaddd",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "24/02/14 5:24 PM",
      "commitNameOld": "ae29d9ee0419bce28530da5ef1c6fe36a6d50ad0",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 24.85,
      "commitsBetweenForRepo": 224,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,89 +1,118 @@\n     public void messageReceived(ChannelHandlerContext ctx, MessageEvent evt)\n         throws Exception {\n       HttpRequest request \u003d (HttpRequest) evt.getMessage();\n       if (request.getMethod() !\u003d GET) {\n           sendError(ctx, METHOD_NOT_ALLOWED);\n           return;\n       }\n       // Check whether the shuffle version is compatible\n       if (!ShuffleHeader.DEFAULT_HTTP_HEADER_NAME.equals(\n           request.getHeader(ShuffleHeader.HTTP_HEADER_NAME))\n           || !ShuffleHeader.DEFAULT_HTTP_HEADER_VERSION.equals(\n               request.getHeader(ShuffleHeader.HTTP_HEADER_VERSION))) {\n         sendError(ctx, \"Incompatible shuffle request version\", BAD_REQUEST);\n       }\n       final Map\u003cString,List\u003cString\u003e\u003e q \u003d\n         new QueryStringDecoder(request.getUri()).getParameters();\n+      final List\u003cString\u003e keepAliveList \u003d q.get(\"keepAlive\");\n+      boolean keepAliveParam \u003d false;\n+      if (keepAliveList !\u003d null \u0026\u0026 keepAliveList.size() \u003d\u003d 1) {\n+        keepAliveParam \u003d Boolean.valueOf(keepAliveList.get(0));\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\"KeepAliveParam : \" + keepAliveList\n+            + \" : \" + keepAliveParam);\n+        }\n+      }\n       final List\u003cString\u003e mapIds \u003d splitMaps(q.get(\"map\"));\n       final List\u003cString\u003e reduceQ \u003d q.get(\"reduce\");\n       final List\u003cString\u003e jobQ \u003d q.get(\"job\");\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"RECV: \" + request.getUri() +\n             \"\\n  mapId: \" + mapIds +\n             \"\\n  reduceId: \" + reduceQ +\n-            \"\\n  jobId: \" + jobQ);\n+            \"\\n  jobId: \" + jobQ +\n+            \"\\n  keepAlive: \" + keepAliveParam);\n       }\n \n       if (mapIds \u003d\u003d null || reduceQ \u003d\u003d null || jobQ \u003d\u003d null) {\n         sendError(ctx, \"Required param job, map and reduce\", BAD_REQUEST);\n         return;\n       }\n       if (reduceQ.size() !\u003d 1 || jobQ.size() !\u003d 1) {\n         sendError(ctx, \"Too many job/reduce parameters\", BAD_REQUEST);\n         return;\n       }\n       int reduceId;\n       String jobId;\n       try {\n         reduceId \u003d Integer.parseInt(reduceQ.get(0));\n         jobId \u003d jobQ.get(0);\n       } catch (NumberFormatException e) {\n         sendError(ctx, \"Bad reduce parameter\", BAD_REQUEST);\n         return;\n       } catch (IllegalArgumentException e) {\n         sendError(ctx, \"Bad job parameter\", BAD_REQUEST);\n         return;\n       }\n       final String reqUri \u003d request.getUri();\n       if (null \u003d\u003d reqUri) {\n         // TODO? add upstream?\n         sendError(ctx, FORBIDDEN);\n         return;\n       }\n       HttpResponse response \u003d new DefaultHttpResponse(HTTP_1_1, OK);\n       try {\n         verifyRequest(jobId, ctx, request, response,\n             new URL(\"http\", \"\", this.port, reqUri));\n       } catch (IOException e) {\n         LOG.warn(\"Shuffle failure \", e);\n         sendError(ctx, e.getMessage(), UNAUTHORIZED);\n         return;\n       }\n \n+      Map\u003cString, MapOutputInfo\u003e mapOutputInfoMap \u003d\n+          new HashMap\u003cString, MapOutputInfo\u003e();\n       Channel ch \u003d evt.getChannel();\n+      String user \u003d userRsrc.get(jobId);\n+\n+      // $x/$user/appcache/$appId/output/$mapId\n+      // TODO: Once Shuffle is out of NM, this can use MR APIs to convert\n+      // between App and Job\n+      String outputBasePathStr \u003d getBaseLocation(jobId, user);\n+\n+      try {\n+        populateHeaders(mapIds, outputBasePathStr, user, reduceId, request,\n+          response, keepAliveParam, mapOutputInfoMap);\n+      } catch(IOException e) {\n+        ch.write(response);\n+        LOG.error(\"Shuffle error in populating headers :\", e);\n+        String errorMessage \u003d getErrorMessage(e);\n+        sendError(ctx,errorMessage , INTERNAL_SERVER_ERROR);\n+        return;\n+      }\n       ch.write(response);\n       // TODO refactor the following into the pipeline\n       ChannelFuture lastMap \u003d null;\n       for (String mapId : mapIds) {\n         try {\n+          MapOutputInfo info \u003d mapOutputInfoMap.get(mapId);\n+          if (info \u003d\u003d null) {\n+            info \u003d getMapOutputInfo(outputBasePathStr, mapId, reduceId, user);\n+          }\n           lastMap \u003d\n-            sendMapOutput(ctx, ch, userRsrc.get(jobId), jobId, mapId, reduceId);\n+              sendMapOutput(ctx, ch, user, mapId,\n+                reduceId, info);\n           if (null \u003d\u003d lastMap) {\n             sendError(ctx, NOT_FOUND);\n             return;\n           }\n         } catch (IOException e) {\n           LOG.error(\"Shuffle error :\", e);\n-          StringBuffer sb \u003d new StringBuffer(e.getMessage());\n-          Throwable t \u003d e;\n-          while (t.getCause() !\u003d null) {\n-            sb.append(t.getCause().getMessage());\n-            t \u003d t.getCause();\n-          }\n-          sendError(ctx,sb.toString() , INTERNAL_SERVER_ERROR);\n+          String errorMessage \u003d getErrorMessage(e);\n+          sendError(ctx,errorMessage , INTERNAL_SERVER_ERROR);\n           return;\n         }\n       }\n       lastMap.addListener(metrics);\n       lastMap.addListener(ChannelFutureListener.CLOSE);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void messageReceived(ChannelHandlerContext ctx, MessageEvent evt)\n        throws Exception {\n      HttpRequest request \u003d (HttpRequest) evt.getMessage();\n      if (request.getMethod() !\u003d GET) {\n          sendError(ctx, METHOD_NOT_ALLOWED);\n          return;\n      }\n      // Check whether the shuffle version is compatible\n      if (!ShuffleHeader.DEFAULT_HTTP_HEADER_NAME.equals(\n          request.getHeader(ShuffleHeader.HTTP_HEADER_NAME))\n          || !ShuffleHeader.DEFAULT_HTTP_HEADER_VERSION.equals(\n              request.getHeader(ShuffleHeader.HTTP_HEADER_VERSION))) {\n        sendError(ctx, \"Incompatible shuffle request version\", BAD_REQUEST);\n      }\n      final Map\u003cString,List\u003cString\u003e\u003e q \u003d\n        new QueryStringDecoder(request.getUri()).getParameters();\n      final List\u003cString\u003e keepAliveList \u003d q.get(\"keepAlive\");\n      boolean keepAliveParam \u003d false;\n      if (keepAliveList !\u003d null \u0026\u0026 keepAliveList.size() \u003d\u003d 1) {\n        keepAliveParam \u003d Boolean.valueOf(keepAliveList.get(0));\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"KeepAliveParam : \" + keepAliveList\n            + \" : \" + keepAliveParam);\n        }\n      }\n      final List\u003cString\u003e mapIds \u003d splitMaps(q.get(\"map\"));\n      final List\u003cString\u003e reduceQ \u003d q.get(\"reduce\");\n      final List\u003cString\u003e jobQ \u003d q.get(\"job\");\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"RECV: \" + request.getUri() +\n            \"\\n  mapId: \" + mapIds +\n            \"\\n  reduceId: \" + reduceQ +\n            \"\\n  jobId: \" + jobQ +\n            \"\\n  keepAlive: \" + keepAliveParam);\n      }\n\n      if (mapIds \u003d\u003d null || reduceQ \u003d\u003d null || jobQ \u003d\u003d null) {\n        sendError(ctx, \"Required param job, map and reduce\", BAD_REQUEST);\n        return;\n      }\n      if (reduceQ.size() !\u003d 1 || jobQ.size() !\u003d 1) {\n        sendError(ctx, \"Too many job/reduce parameters\", BAD_REQUEST);\n        return;\n      }\n      int reduceId;\n      String jobId;\n      try {\n        reduceId \u003d Integer.parseInt(reduceQ.get(0));\n        jobId \u003d jobQ.get(0);\n      } catch (NumberFormatException e) {\n        sendError(ctx, \"Bad reduce parameter\", BAD_REQUEST);\n        return;\n      } catch (IllegalArgumentException e) {\n        sendError(ctx, \"Bad job parameter\", BAD_REQUEST);\n        return;\n      }\n      final String reqUri \u003d request.getUri();\n      if (null \u003d\u003d reqUri) {\n        // TODO? add upstream?\n        sendError(ctx, FORBIDDEN);\n        return;\n      }\n      HttpResponse response \u003d new DefaultHttpResponse(HTTP_1_1, OK);\n      try {\n        verifyRequest(jobId, ctx, request, response,\n            new URL(\"http\", \"\", this.port, reqUri));\n      } catch (IOException e) {\n        LOG.warn(\"Shuffle failure \", e);\n        sendError(ctx, e.getMessage(), UNAUTHORIZED);\n        return;\n      }\n\n      Map\u003cString, MapOutputInfo\u003e mapOutputInfoMap \u003d\n          new HashMap\u003cString, MapOutputInfo\u003e();\n      Channel ch \u003d evt.getChannel();\n      String user \u003d userRsrc.get(jobId);\n\n      // $x/$user/appcache/$appId/output/$mapId\n      // TODO: Once Shuffle is out of NM, this can use MR APIs to convert\n      // between App and Job\n      String outputBasePathStr \u003d getBaseLocation(jobId, user);\n\n      try {\n        populateHeaders(mapIds, outputBasePathStr, user, reduceId, request,\n          response, keepAliveParam, mapOutputInfoMap);\n      } catch(IOException e) {\n        ch.write(response);\n        LOG.error(\"Shuffle error in populating headers :\", e);\n        String errorMessage \u003d getErrorMessage(e);\n        sendError(ctx,errorMessage , INTERNAL_SERVER_ERROR);\n        return;\n      }\n      ch.write(response);\n      // TODO refactor the following into the pipeline\n      ChannelFuture lastMap \u003d null;\n      for (String mapId : mapIds) {\n        try {\n          MapOutputInfo info \u003d mapOutputInfoMap.get(mapId);\n          if (info \u003d\u003d null) {\n            info \u003d getMapOutputInfo(outputBasePathStr, mapId, reduceId, user);\n          }\n          lastMap \u003d\n              sendMapOutput(ctx, ch, user, mapId,\n                reduceId, info);\n          if (null \u003d\u003d lastMap) {\n            sendError(ctx, NOT_FOUND);\n            return;\n          }\n        } catch (IOException e) {\n          LOG.error(\"Shuffle error :\", e);\n          String errorMessage \u003d getErrorMessage(e);\n          sendError(ctx,errorMessage , INTERNAL_SERVER_ERROR);\n          return;\n        }\n      }\n      lastMap.addListener(metrics);\n      lastMap.addListener(ChannelFutureListener.CLOSE);\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java",
      "extendedDetails": {}
    },
    "11bcd2ed12f7f0e02fdaefaefea56929b32d5ee6": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5326. Added version to shuffle header. Contributed by Zhijie Shen.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1496741 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "25/06/13 10:49 PM",
      "commitName": "11bcd2ed12f7f0e02fdaefaefea56929b32d5ee6",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "17/06/13 11:20 PM",
      "commitNameOld": "f4d80e91ae314d316100baa7770b9d73ea853d9c",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 7.98,
      "commitsBetweenForRepo": 50,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,82 +1,89 @@\n     public void messageReceived(ChannelHandlerContext ctx, MessageEvent evt)\n         throws Exception {\n       HttpRequest request \u003d (HttpRequest) evt.getMessage();\n       if (request.getMethod() !\u003d GET) {\n           sendError(ctx, METHOD_NOT_ALLOWED);\n           return;\n       }\n+      // Check whether the shuffle version is compatible\n+      if (!ShuffleHeader.DEFAULT_HTTP_HEADER_NAME.equals(\n+          request.getHeader(ShuffleHeader.HTTP_HEADER_NAME))\n+          || !ShuffleHeader.DEFAULT_HTTP_HEADER_VERSION.equals(\n+              request.getHeader(ShuffleHeader.HTTP_HEADER_VERSION))) {\n+        sendError(ctx, \"Incompatible shuffle request version\", BAD_REQUEST);\n+      }\n       final Map\u003cString,List\u003cString\u003e\u003e q \u003d\n         new QueryStringDecoder(request.getUri()).getParameters();\n       final List\u003cString\u003e mapIds \u003d splitMaps(q.get(\"map\"));\n       final List\u003cString\u003e reduceQ \u003d q.get(\"reduce\");\n       final List\u003cString\u003e jobQ \u003d q.get(\"job\");\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"RECV: \" + request.getUri() +\n             \"\\n  mapId: \" + mapIds +\n             \"\\n  reduceId: \" + reduceQ +\n             \"\\n  jobId: \" + jobQ);\n       }\n \n       if (mapIds \u003d\u003d null || reduceQ \u003d\u003d null || jobQ \u003d\u003d null) {\n         sendError(ctx, \"Required param job, map and reduce\", BAD_REQUEST);\n         return;\n       }\n       if (reduceQ.size() !\u003d 1 || jobQ.size() !\u003d 1) {\n         sendError(ctx, \"Too many job/reduce parameters\", BAD_REQUEST);\n         return;\n       }\n       int reduceId;\n       String jobId;\n       try {\n         reduceId \u003d Integer.parseInt(reduceQ.get(0));\n         jobId \u003d jobQ.get(0);\n       } catch (NumberFormatException e) {\n         sendError(ctx, \"Bad reduce parameter\", BAD_REQUEST);\n         return;\n       } catch (IllegalArgumentException e) {\n         sendError(ctx, \"Bad job parameter\", BAD_REQUEST);\n         return;\n       }\n       final String reqUri \u003d request.getUri();\n       if (null \u003d\u003d reqUri) {\n         // TODO? add upstream?\n         sendError(ctx, FORBIDDEN);\n         return;\n       }\n       HttpResponse response \u003d new DefaultHttpResponse(HTTP_1_1, OK);\n       try {\n         verifyRequest(jobId, ctx, request, response,\n             new URL(\"http\", \"\", this.port, reqUri));\n       } catch (IOException e) {\n         LOG.warn(\"Shuffle failure \", e);\n         sendError(ctx, e.getMessage(), UNAUTHORIZED);\n         return;\n       }\n \n       Channel ch \u003d evt.getChannel();\n       ch.write(response);\n       // TODO refactor the following into the pipeline\n       ChannelFuture lastMap \u003d null;\n       for (String mapId : mapIds) {\n         try {\n           lastMap \u003d\n             sendMapOutput(ctx, ch, userRsrc.get(jobId), jobId, mapId, reduceId);\n           if (null \u003d\u003d lastMap) {\n             sendError(ctx, NOT_FOUND);\n             return;\n           }\n         } catch (IOException e) {\n           LOG.error(\"Shuffle error :\", e);\n           StringBuffer sb \u003d new StringBuffer(e.getMessage());\n           Throwable t \u003d e;\n           while (t.getCause() !\u003d null) {\n             sb.append(t.getCause().getMessage());\n             t \u003d t.getCause();\n           }\n           sendError(ctx,sb.toString() , INTERNAL_SERVER_ERROR);\n           return;\n         }\n       }\n       lastMap.addListener(metrics);\n       lastMap.addListener(ChannelFutureListener.CLOSE);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void messageReceived(ChannelHandlerContext ctx, MessageEvent evt)\n        throws Exception {\n      HttpRequest request \u003d (HttpRequest) evt.getMessage();\n      if (request.getMethod() !\u003d GET) {\n          sendError(ctx, METHOD_NOT_ALLOWED);\n          return;\n      }\n      // Check whether the shuffle version is compatible\n      if (!ShuffleHeader.DEFAULT_HTTP_HEADER_NAME.equals(\n          request.getHeader(ShuffleHeader.HTTP_HEADER_NAME))\n          || !ShuffleHeader.DEFAULT_HTTP_HEADER_VERSION.equals(\n              request.getHeader(ShuffleHeader.HTTP_HEADER_VERSION))) {\n        sendError(ctx, \"Incompatible shuffle request version\", BAD_REQUEST);\n      }\n      final Map\u003cString,List\u003cString\u003e\u003e q \u003d\n        new QueryStringDecoder(request.getUri()).getParameters();\n      final List\u003cString\u003e mapIds \u003d splitMaps(q.get(\"map\"));\n      final List\u003cString\u003e reduceQ \u003d q.get(\"reduce\");\n      final List\u003cString\u003e jobQ \u003d q.get(\"job\");\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"RECV: \" + request.getUri() +\n            \"\\n  mapId: \" + mapIds +\n            \"\\n  reduceId: \" + reduceQ +\n            \"\\n  jobId: \" + jobQ);\n      }\n\n      if (mapIds \u003d\u003d null || reduceQ \u003d\u003d null || jobQ \u003d\u003d null) {\n        sendError(ctx, \"Required param job, map and reduce\", BAD_REQUEST);\n        return;\n      }\n      if (reduceQ.size() !\u003d 1 || jobQ.size() !\u003d 1) {\n        sendError(ctx, \"Too many job/reduce parameters\", BAD_REQUEST);\n        return;\n      }\n      int reduceId;\n      String jobId;\n      try {\n        reduceId \u003d Integer.parseInt(reduceQ.get(0));\n        jobId \u003d jobQ.get(0);\n      } catch (NumberFormatException e) {\n        sendError(ctx, \"Bad reduce parameter\", BAD_REQUEST);\n        return;\n      } catch (IllegalArgumentException e) {\n        sendError(ctx, \"Bad job parameter\", BAD_REQUEST);\n        return;\n      }\n      final String reqUri \u003d request.getUri();\n      if (null \u003d\u003d reqUri) {\n        // TODO? add upstream?\n        sendError(ctx, FORBIDDEN);\n        return;\n      }\n      HttpResponse response \u003d new DefaultHttpResponse(HTTP_1_1, OK);\n      try {\n        verifyRequest(jobId, ctx, request, response,\n            new URL(\"http\", \"\", this.port, reqUri));\n      } catch (IOException e) {\n        LOG.warn(\"Shuffle failure \", e);\n        sendError(ctx, e.getMessage(), UNAUTHORIZED);\n        return;\n      }\n\n      Channel ch \u003d evt.getChannel();\n      ch.write(response);\n      // TODO refactor the following into the pipeline\n      ChannelFuture lastMap \u003d null;\n      for (String mapId : mapIds) {\n        try {\n          lastMap \u003d\n            sendMapOutput(ctx, ch, userRsrc.get(jobId), jobId, mapId, reduceId);\n          if (null \u003d\u003d lastMap) {\n            sendError(ctx, NOT_FOUND);\n            return;\n          }\n        } catch (IOException e) {\n          LOG.error(\"Shuffle error :\", e);\n          StringBuffer sb \u003d new StringBuffer(e.getMessage());\n          Throwable t \u003d e;\n          while (t.getCause() !\u003d null) {\n            sb.append(t.getCause().getMessage());\n            t \u003d t.getCause();\n          }\n          sendError(ctx,sb.toString() , INTERNAL_SERVER_ERROR);\n          return;\n        }\n      }\n      lastMap.addListener(metrics);\n      lastMap.addListener(ChannelFutureListener.CLOSE);\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java",
      "extendedDetails": {}
    },
    "47d1ca402fe0bafae32507dee0d27cd1e345a7e9": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5208. Modified ShuffleHandler to use SecureIOUtils for reading local files. Contributed by Omkar Vinit Joshi.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1481657 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/05/13 2:59 PM",
      "commitName": "47d1ca402fe0bafae32507dee0d27cd1e345a7e9",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "02/05/13 8:58 AM",
      "commitNameOld": "9b97df9abe4383cde612a6050ae5db315647931c",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 10.25,
      "commitsBetweenForRepo": 57,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,76 +1,82 @@\n     public void messageReceived(ChannelHandlerContext ctx, MessageEvent evt)\n         throws Exception {\n       HttpRequest request \u003d (HttpRequest) evt.getMessage();\n       if (request.getMethod() !\u003d GET) {\n           sendError(ctx, METHOD_NOT_ALLOWED);\n           return;\n       }\n       final Map\u003cString,List\u003cString\u003e\u003e q \u003d\n         new QueryStringDecoder(request.getUri()).getParameters();\n       final List\u003cString\u003e mapIds \u003d splitMaps(q.get(\"map\"));\n       final List\u003cString\u003e reduceQ \u003d q.get(\"reduce\");\n       final List\u003cString\u003e jobQ \u003d q.get(\"job\");\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"RECV: \" + request.getUri() +\n             \"\\n  mapId: \" + mapIds +\n             \"\\n  reduceId: \" + reduceQ +\n             \"\\n  jobId: \" + jobQ);\n       }\n \n       if (mapIds \u003d\u003d null || reduceQ \u003d\u003d null || jobQ \u003d\u003d null) {\n         sendError(ctx, \"Required param job, map and reduce\", BAD_REQUEST);\n         return;\n       }\n       if (reduceQ.size() !\u003d 1 || jobQ.size() !\u003d 1) {\n         sendError(ctx, \"Too many job/reduce parameters\", BAD_REQUEST);\n         return;\n       }\n       int reduceId;\n       String jobId;\n       try {\n         reduceId \u003d Integer.parseInt(reduceQ.get(0));\n         jobId \u003d jobQ.get(0);\n       } catch (NumberFormatException e) {\n         sendError(ctx, \"Bad reduce parameter\", BAD_REQUEST);\n         return;\n       } catch (IllegalArgumentException e) {\n         sendError(ctx, \"Bad job parameter\", BAD_REQUEST);\n         return;\n       }\n       final String reqUri \u003d request.getUri();\n       if (null \u003d\u003d reqUri) {\n         // TODO? add upstream?\n         sendError(ctx, FORBIDDEN);\n         return;\n       }\n       HttpResponse response \u003d new DefaultHttpResponse(HTTP_1_1, OK);\n       try {\n         verifyRequest(jobId, ctx, request, response,\n             new URL(\"http\", \"\", this.port, reqUri));\n       } catch (IOException e) {\n         LOG.warn(\"Shuffle failure \", e);\n         sendError(ctx, e.getMessage(), UNAUTHORIZED);\n         return;\n       }\n \n       Channel ch \u003d evt.getChannel();\n       ch.write(response);\n       // TODO refactor the following into the pipeline\n       ChannelFuture lastMap \u003d null;\n       for (String mapId : mapIds) {\n         try {\n           lastMap \u003d\n             sendMapOutput(ctx, ch, userRsrc.get(jobId), jobId, mapId, reduceId);\n           if (null \u003d\u003d lastMap) {\n             sendError(ctx, NOT_FOUND);\n             return;\n           }\n         } catch (IOException e) {\n-          LOG.error(\"Shuffle error \", e);\n-          sendError(ctx, e.getMessage(), INTERNAL_SERVER_ERROR);\n+          LOG.error(\"Shuffle error :\", e);\n+          StringBuffer sb \u003d new StringBuffer(e.getMessage());\n+          Throwable t \u003d e;\n+          while (t.getCause() !\u003d null) {\n+            sb.append(t.getCause().getMessage());\n+            t \u003d t.getCause();\n+          }\n+          sendError(ctx,sb.toString() , INTERNAL_SERVER_ERROR);\n           return;\n         }\n       }\n       lastMap.addListener(metrics);\n       lastMap.addListener(ChannelFutureListener.CLOSE);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void messageReceived(ChannelHandlerContext ctx, MessageEvent evt)\n        throws Exception {\n      HttpRequest request \u003d (HttpRequest) evt.getMessage();\n      if (request.getMethod() !\u003d GET) {\n          sendError(ctx, METHOD_NOT_ALLOWED);\n          return;\n      }\n      final Map\u003cString,List\u003cString\u003e\u003e q \u003d\n        new QueryStringDecoder(request.getUri()).getParameters();\n      final List\u003cString\u003e mapIds \u003d splitMaps(q.get(\"map\"));\n      final List\u003cString\u003e reduceQ \u003d q.get(\"reduce\");\n      final List\u003cString\u003e jobQ \u003d q.get(\"job\");\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"RECV: \" + request.getUri() +\n            \"\\n  mapId: \" + mapIds +\n            \"\\n  reduceId: \" + reduceQ +\n            \"\\n  jobId: \" + jobQ);\n      }\n\n      if (mapIds \u003d\u003d null || reduceQ \u003d\u003d null || jobQ \u003d\u003d null) {\n        sendError(ctx, \"Required param job, map and reduce\", BAD_REQUEST);\n        return;\n      }\n      if (reduceQ.size() !\u003d 1 || jobQ.size() !\u003d 1) {\n        sendError(ctx, \"Too many job/reduce parameters\", BAD_REQUEST);\n        return;\n      }\n      int reduceId;\n      String jobId;\n      try {\n        reduceId \u003d Integer.parseInt(reduceQ.get(0));\n        jobId \u003d jobQ.get(0);\n      } catch (NumberFormatException e) {\n        sendError(ctx, \"Bad reduce parameter\", BAD_REQUEST);\n        return;\n      } catch (IllegalArgumentException e) {\n        sendError(ctx, \"Bad job parameter\", BAD_REQUEST);\n        return;\n      }\n      final String reqUri \u003d request.getUri();\n      if (null \u003d\u003d reqUri) {\n        // TODO? add upstream?\n        sendError(ctx, FORBIDDEN);\n        return;\n      }\n      HttpResponse response \u003d new DefaultHttpResponse(HTTP_1_1, OK);\n      try {\n        verifyRequest(jobId, ctx, request, response,\n            new URL(\"http\", \"\", this.port, reqUri));\n      } catch (IOException e) {\n        LOG.warn(\"Shuffle failure \", e);\n        sendError(ctx, e.getMessage(), UNAUTHORIZED);\n        return;\n      }\n\n      Channel ch \u003d evt.getChannel();\n      ch.write(response);\n      // TODO refactor the following into the pipeline\n      ChannelFuture lastMap \u003d null;\n      for (String mapId : mapIds) {\n        try {\n          lastMap \u003d\n            sendMapOutput(ctx, ch, userRsrc.get(jobId), jobId, mapId, reduceId);\n          if (null \u003d\u003d lastMap) {\n            sendError(ctx, NOT_FOUND);\n            return;\n          }\n        } catch (IOException e) {\n          LOG.error(\"Shuffle error :\", e);\n          StringBuffer sb \u003d new StringBuffer(e.getMessage());\n          Throwable t \u003d e;\n          while (t.getCause() !\u003d null) {\n            sb.append(t.getCause().getMessage());\n            t \u003d t.getCause();\n          }\n          sendError(ctx,sb.toString() , INTERNAL_SERVER_ERROR);\n          return;\n        }\n      }\n      lastMap.addListener(metrics);\n      lastMap.addListener(ChannelFutureListener.CLOSE);\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java",
      "extendedDetails": {}
    },
    "1f46b991da9b91585608a0babd3eda39485dce09": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-2908. Fix all findbugs warnings. Contributed by Vinod K V. \n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1166838 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/09/11 11:26 AM",
      "commitName": "1f46b991da9b91585608a0babd3eda39485dce09",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "31/08/11 4:38 AM",
      "commitNameOld": "ade0f0560f729e50382c6992f713f29e2dd5b270",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 8.28,
      "commitsBetweenForRepo": 41,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,76 +1,76 @@\n     public void messageReceived(ChannelHandlerContext ctx, MessageEvent evt)\n         throws Exception {\n       HttpRequest request \u003d (HttpRequest) evt.getMessage();\n       if (request.getMethod() !\u003d GET) {\n           sendError(ctx, METHOD_NOT_ALLOWED);\n           return;\n       }\n       final Map\u003cString,List\u003cString\u003e\u003e q \u003d\n         new QueryStringDecoder(request.getUri()).getParameters();\n       final List\u003cString\u003e mapIds \u003d splitMaps(q.get(\"map\"));\n       final List\u003cString\u003e reduceQ \u003d q.get(\"reduce\");\n       final List\u003cString\u003e jobQ \u003d q.get(\"job\");\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"RECV: \" + request.getUri() +\n             \"\\n  mapId: \" + mapIds +\n             \"\\n  reduceId: \" + reduceQ +\n             \"\\n  jobId: \" + jobQ);\n       }\n \n       if (mapIds \u003d\u003d null || reduceQ \u003d\u003d null || jobQ \u003d\u003d null) {\n         sendError(ctx, \"Required param job, map and reduce\", BAD_REQUEST);\n         return;\n       }\n       if (reduceQ.size() !\u003d 1 || jobQ.size() !\u003d 1) {\n         sendError(ctx, \"Too many job/reduce parameters\", BAD_REQUEST);\n         return;\n       }\n       int reduceId;\n       String jobId;\n       try {\n         reduceId \u003d Integer.parseInt(reduceQ.get(0));\n         jobId \u003d jobQ.get(0);\n       } catch (NumberFormatException e) {\n         sendError(ctx, \"Bad reduce parameter\", BAD_REQUEST);\n         return;\n       } catch (IllegalArgumentException e) {\n         sendError(ctx, \"Bad job parameter\", BAD_REQUEST);\n         return;\n       }\n       final String reqUri \u003d request.getUri();\n       if (null \u003d\u003d reqUri) {\n         // TODO? add upstream?\n         sendError(ctx, FORBIDDEN);\n         return;\n       }\n       HttpResponse response \u003d new DefaultHttpResponse(HTTP_1_1, OK);\n       try {\n         verifyRequest(jobId, ctx, request, response,\n-            new URL(\"http\", \"\", port, reqUri));\n+            new URL(\"http\", \"\", this.port, reqUri));\n       } catch (IOException e) {\n         LOG.warn(\"Shuffle failure \", e);\n         sendError(ctx, e.getMessage(), UNAUTHORIZED);\n         return;\n       }\n \n       Channel ch \u003d evt.getChannel();\n       ch.write(response);\n       // TODO refactor the following into the pipeline\n       ChannelFuture lastMap \u003d null;\n       for (String mapId : mapIds) {\n         try {\n           lastMap \u003d\n             sendMapOutput(ctx, ch, userRsrc.get(jobId), jobId, mapId, reduceId);\n           if (null \u003d\u003d lastMap) {\n             sendError(ctx, NOT_FOUND);\n             return;\n           }\n         } catch (IOException e) {\n           LOG.error(\"Shuffle error \", e);\n           sendError(ctx, e.getMessage(), INTERNAL_SERVER_ERROR);\n           return;\n         }\n       }\n       lastMap.addListener(metrics);\n       lastMap.addListener(ChannelFutureListener.CLOSE);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void messageReceived(ChannelHandlerContext ctx, MessageEvent evt)\n        throws Exception {\n      HttpRequest request \u003d (HttpRequest) evt.getMessage();\n      if (request.getMethod() !\u003d GET) {\n          sendError(ctx, METHOD_NOT_ALLOWED);\n          return;\n      }\n      final Map\u003cString,List\u003cString\u003e\u003e q \u003d\n        new QueryStringDecoder(request.getUri()).getParameters();\n      final List\u003cString\u003e mapIds \u003d splitMaps(q.get(\"map\"));\n      final List\u003cString\u003e reduceQ \u003d q.get(\"reduce\");\n      final List\u003cString\u003e jobQ \u003d q.get(\"job\");\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"RECV: \" + request.getUri() +\n            \"\\n  mapId: \" + mapIds +\n            \"\\n  reduceId: \" + reduceQ +\n            \"\\n  jobId: \" + jobQ);\n      }\n\n      if (mapIds \u003d\u003d null || reduceQ \u003d\u003d null || jobQ \u003d\u003d null) {\n        sendError(ctx, \"Required param job, map and reduce\", BAD_REQUEST);\n        return;\n      }\n      if (reduceQ.size() !\u003d 1 || jobQ.size() !\u003d 1) {\n        sendError(ctx, \"Too many job/reduce parameters\", BAD_REQUEST);\n        return;\n      }\n      int reduceId;\n      String jobId;\n      try {\n        reduceId \u003d Integer.parseInt(reduceQ.get(0));\n        jobId \u003d jobQ.get(0);\n      } catch (NumberFormatException e) {\n        sendError(ctx, \"Bad reduce parameter\", BAD_REQUEST);\n        return;\n      } catch (IllegalArgumentException e) {\n        sendError(ctx, \"Bad job parameter\", BAD_REQUEST);\n        return;\n      }\n      final String reqUri \u003d request.getUri();\n      if (null \u003d\u003d reqUri) {\n        // TODO? add upstream?\n        sendError(ctx, FORBIDDEN);\n        return;\n      }\n      HttpResponse response \u003d new DefaultHttpResponse(HTTP_1_1, OK);\n      try {\n        verifyRequest(jobId, ctx, request, response,\n            new URL(\"http\", \"\", this.port, reqUri));\n      } catch (IOException e) {\n        LOG.warn(\"Shuffle failure \", e);\n        sendError(ctx, e.getMessage(), UNAUTHORIZED);\n        return;\n      }\n\n      Channel ch \u003d evt.getChannel();\n      ch.write(response);\n      // TODO refactor the following into the pipeline\n      ChannelFuture lastMap \u003d null;\n      for (String mapId : mapIds) {\n        try {\n          lastMap \u003d\n            sendMapOutput(ctx, ch, userRsrc.get(jobId), jobId, mapId, reduceId);\n          if (null \u003d\u003d lastMap) {\n            sendError(ctx, NOT_FOUND);\n            return;\n          }\n        } catch (IOException e) {\n          LOG.error(\"Shuffle error \", e);\n          sendError(ctx, e.getMessage(), INTERNAL_SERVER_ERROR);\n          return;\n        }\n      }\n      lastMap.addListener(metrics);\n      lastMap.addListener(ChannelFutureListener.CLOSE);\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java",
      "extendedDetails": {}
    },
    "ade0f0560f729e50382c6992f713f29e2dd5b270": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-2652. Enabled multiple NMs to be runnable on a single node by making shuffle service port to be truely configurable. Contributed by Robert Joseph Evans.\n\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1163585 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "31/08/11 4:38 AM",
      "commitName": "ade0f0560f729e50382c6992f713f29e2dd5b270",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "24/08/11 5:14 PM",
      "commitNameOld": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 6.48,
      "commitsBetweenForRepo": 37,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,76 +1,76 @@\n     public void messageReceived(ChannelHandlerContext ctx, MessageEvent evt)\n         throws Exception {\n       HttpRequest request \u003d (HttpRequest) evt.getMessage();\n       if (request.getMethod() !\u003d GET) {\n           sendError(ctx, METHOD_NOT_ALLOWED);\n           return;\n       }\n       final Map\u003cString,List\u003cString\u003e\u003e q \u003d\n         new QueryStringDecoder(request.getUri()).getParameters();\n       final List\u003cString\u003e mapIds \u003d splitMaps(q.get(\"map\"));\n       final List\u003cString\u003e reduceQ \u003d q.get(\"reduce\");\n       final List\u003cString\u003e jobQ \u003d q.get(\"job\");\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"RECV: \" + request.getUri() +\n             \"\\n  mapId: \" + mapIds +\n             \"\\n  reduceId: \" + reduceQ +\n             \"\\n  jobId: \" + jobQ);\n       }\n \n       if (mapIds \u003d\u003d null || reduceQ \u003d\u003d null || jobQ \u003d\u003d null) {\n         sendError(ctx, \"Required param job, map and reduce\", BAD_REQUEST);\n         return;\n       }\n       if (reduceQ.size() !\u003d 1 || jobQ.size() !\u003d 1) {\n         sendError(ctx, \"Too many job/reduce parameters\", BAD_REQUEST);\n         return;\n       }\n       int reduceId;\n       String jobId;\n       try {\n         reduceId \u003d Integer.parseInt(reduceQ.get(0));\n         jobId \u003d jobQ.get(0);\n       } catch (NumberFormatException e) {\n         sendError(ctx, \"Bad reduce parameter\", BAD_REQUEST);\n         return;\n       } catch (IllegalArgumentException e) {\n         sendError(ctx, \"Bad job parameter\", BAD_REQUEST);\n         return;\n       }\n       final String reqUri \u003d request.getUri();\n       if (null \u003d\u003d reqUri) {\n         // TODO? add upstream?\n         sendError(ctx, FORBIDDEN);\n         return;\n       }\n       HttpResponse response \u003d new DefaultHttpResponse(HTTP_1_1, OK);\n       try {\n         verifyRequest(jobId, ctx, request, response,\n-            new URL(\"http\", \"\", 8080, reqUri));\n+            new URL(\"http\", \"\", port, reqUri));\n       } catch (IOException e) {\n         LOG.warn(\"Shuffle failure \", e);\n         sendError(ctx, e.getMessage(), UNAUTHORIZED);\n         return;\n       }\n \n       Channel ch \u003d evt.getChannel();\n       ch.write(response);\n       // TODO refactor the following into the pipeline\n       ChannelFuture lastMap \u003d null;\n       for (String mapId : mapIds) {\n         try {\n           lastMap \u003d\n             sendMapOutput(ctx, ch, userRsrc.get(jobId), jobId, mapId, reduceId);\n           if (null \u003d\u003d lastMap) {\n             sendError(ctx, NOT_FOUND);\n             return;\n           }\n         } catch (IOException e) {\n           LOG.error(\"Shuffle error \", e);\n           sendError(ctx, e.getMessage(), INTERNAL_SERVER_ERROR);\n           return;\n         }\n       }\n       lastMap.addListener(metrics);\n       lastMap.addListener(ChannelFutureListener.CLOSE);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void messageReceived(ChannelHandlerContext ctx, MessageEvent evt)\n        throws Exception {\n      HttpRequest request \u003d (HttpRequest) evt.getMessage();\n      if (request.getMethod() !\u003d GET) {\n          sendError(ctx, METHOD_NOT_ALLOWED);\n          return;\n      }\n      final Map\u003cString,List\u003cString\u003e\u003e q \u003d\n        new QueryStringDecoder(request.getUri()).getParameters();\n      final List\u003cString\u003e mapIds \u003d splitMaps(q.get(\"map\"));\n      final List\u003cString\u003e reduceQ \u003d q.get(\"reduce\");\n      final List\u003cString\u003e jobQ \u003d q.get(\"job\");\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"RECV: \" + request.getUri() +\n            \"\\n  mapId: \" + mapIds +\n            \"\\n  reduceId: \" + reduceQ +\n            \"\\n  jobId: \" + jobQ);\n      }\n\n      if (mapIds \u003d\u003d null || reduceQ \u003d\u003d null || jobQ \u003d\u003d null) {\n        sendError(ctx, \"Required param job, map and reduce\", BAD_REQUEST);\n        return;\n      }\n      if (reduceQ.size() !\u003d 1 || jobQ.size() !\u003d 1) {\n        sendError(ctx, \"Too many job/reduce parameters\", BAD_REQUEST);\n        return;\n      }\n      int reduceId;\n      String jobId;\n      try {\n        reduceId \u003d Integer.parseInt(reduceQ.get(0));\n        jobId \u003d jobQ.get(0);\n      } catch (NumberFormatException e) {\n        sendError(ctx, \"Bad reduce parameter\", BAD_REQUEST);\n        return;\n      } catch (IllegalArgumentException e) {\n        sendError(ctx, \"Bad job parameter\", BAD_REQUEST);\n        return;\n      }\n      final String reqUri \u003d request.getUri();\n      if (null \u003d\u003d reqUri) {\n        // TODO? add upstream?\n        sendError(ctx, FORBIDDEN);\n        return;\n      }\n      HttpResponse response \u003d new DefaultHttpResponse(HTTP_1_1, OK);\n      try {\n        verifyRequest(jobId, ctx, request, response,\n            new URL(\"http\", \"\", port, reqUri));\n      } catch (IOException e) {\n        LOG.warn(\"Shuffle failure \", e);\n        sendError(ctx, e.getMessage(), UNAUTHORIZED);\n        return;\n      }\n\n      Channel ch \u003d evt.getChannel();\n      ch.write(response);\n      // TODO refactor the following into the pipeline\n      ChannelFuture lastMap \u003d null;\n      for (String mapId : mapIds) {\n        try {\n          lastMap \u003d\n            sendMapOutput(ctx, ch, userRsrc.get(jobId), jobId, mapId, reduceId);\n          if (null \u003d\u003d lastMap) {\n            sendError(ctx, NOT_FOUND);\n            return;\n          }\n        } catch (IOException e) {\n          LOG.error(\"Shuffle error \", e);\n          sendError(ctx, e.getMessage(), INTERNAL_SERVER_ERROR);\n          return;\n        }\n      }\n      lastMap.addListener(metrics);\n      lastMap.addListener(ChannelFutureListener.CLOSE);\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    public void messageReceived(ChannelHandlerContext ctx, MessageEvent evt)\n        throws Exception {\n      HttpRequest request \u003d (HttpRequest) evt.getMessage();\n      if (request.getMethod() !\u003d GET) {\n          sendError(ctx, METHOD_NOT_ALLOWED);\n          return;\n      }\n      final Map\u003cString,List\u003cString\u003e\u003e q \u003d\n        new QueryStringDecoder(request.getUri()).getParameters();\n      final List\u003cString\u003e mapIds \u003d splitMaps(q.get(\"map\"));\n      final List\u003cString\u003e reduceQ \u003d q.get(\"reduce\");\n      final List\u003cString\u003e jobQ \u003d q.get(\"job\");\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"RECV: \" + request.getUri() +\n            \"\\n  mapId: \" + mapIds +\n            \"\\n  reduceId: \" + reduceQ +\n            \"\\n  jobId: \" + jobQ);\n      }\n\n      if (mapIds \u003d\u003d null || reduceQ \u003d\u003d null || jobQ \u003d\u003d null) {\n        sendError(ctx, \"Required param job, map and reduce\", BAD_REQUEST);\n        return;\n      }\n      if (reduceQ.size() !\u003d 1 || jobQ.size() !\u003d 1) {\n        sendError(ctx, \"Too many job/reduce parameters\", BAD_REQUEST);\n        return;\n      }\n      int reduceId;\n      String jobId;\n      try {\n        reduceId \u003d Integer.parseInt(reduceQ.get(0));\n        jobId \u003d jobQ.get(0);\n      } catch (NumberFormatException e) {\n        sendError(ctx, \"Bad reduce parameter\", BAD_REQUEST);\n        return;\n      } catch (IllegalArgumentException e) {\n        sendError(ctx, \"Bad job parameter\", BAD_REQUEST);\n        return;\n      }\n      final String reqUri \u003d request.getUri();\n      if (null \u003d\u003d reqUri) {\n        // TODO? add upstream?\n        sendError(ctx, FORBIDDEN);\n        return;\n      }\n      HttpResponse response \u003d new DefaultHttpResponse(HTTP_1_1, OK);\n      try {\n        verifyRequest(jobId, ctx, request, response,\n            new URL(\"http\", \"\", 8080, reqUri));\n      } catch (IOException e) {\n        LOG.warn(\"Shuffle failure \", e);\n        sendError(ctx, e.getMessage(), UNAUTHORIZED);\n        return;\n      }\n\n      Channel ch \u003d evt.getChannel();\n      ch.write(response);\n      // TODO refactor the following into the pipeline\n      ChannelFuture lastMap \u003d null;\n      for (String mapId : mapIds) {\n        try {\n          lastMap \u003d\n            sendMapOutput(ctx, ch, userRsrc.get(jobId), jobId, mapId, reduceId);\n          if (null \u003d\u003d lastMap) {\n            sendError(ctx, NOT_FOUND);\n            return;\n          }\n        } catch (IOException e) {\n          LOG.error(\"Shuffle error \", e);\n          sendError(ctx, e.getMessage(), INTERNAL_SERVER_ERROR);\n          return;\n        }\n      }\n      lastMap.addListener(metrics);\n      lastMap.addListener(ChannelFutureListener.CLOSE);\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java",
        "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "diff": "@@ -0,0 +1,76 @@\n+    public void messageReceived(ChannelHandlerContext ctx, MessageEvent evt)\n+        throws Exception {\n+      HttpRequest request \u003d (HttpRequest) evt.getMessage();\n+      if (request.getMethod() !\u003d GET) {\n+          sendError(ctx, METHOD_NOT_ALLOWED);\n+          return;\n+      }\n+      final Map\u003cString,List\u003cString\u003e\u003e q \u003d\n+        new QueryStringDecoder(request.getUri()).getParameters();\n+      final List\u003cString\u003e mapIds \u003d splitMaps(q.get(\"map\"));\n+      final List\u003cString\u003e reduceQ \u003d q.get(\"reduce\");\n+      final List\u003cString\u003e jobQ \u003d q.get(\"job\");\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(\"RECV: \" + request.getUri() +\n+            \"\\n  mapId: \" + mapIds +\n+            \"\\n  reduceId: \" + reduceQ +\n+            \"\\n  jobId: \" + jobQ);\n+      }\n+\n+      if (mapIds \u003d\u003d null || reduceQ \u003d\u003d null || jobQ \u003d\u003d null) {\n+        sendError(ctx, \"Required param job, map and reduce\", BAD_REQUEST);\n+        return;\n+      }\n+      if (reduceQ.size() !\u003d 1 || jobQ.size() !\u003d 1) {\n+        sendError(ctx, \"Too many job/reduce parameters\", BAD_REQUEST);\n+        return;\n+      }\n+      int reduceId;\n+      String jobId;\n+      try {\n+        reduceId \u003d Integer.parseInt(reduceQ.get(0));\n+        jobId \u003d jobQ.get(0);\n+      } catch (NumberFormatException e) {\n+        sendError(ctx, \"Bad reduce parameter\", BAD_REQUEST);\n+        return;\n+      } catch (IllegalArgumentException e) {\n+        sendError(ctx, \"Bad job parameter\", BAD_REQUEST);\n+        return;\n+      }\n+      final String reqUri \u003d request.getUri();\n+      if (null \u003d\u003d reqUri) {\n+        // TODO? add upstream?\n+        sendError(ctx, FORBIDDEN);\n+        return;\n+      }\n+      HttpResponse response \u003d new DefaultHttpResponse(HTTP_1_1, OK);\n+      try {\n+        verifyRequest(jobId, ctx, request, response,\n+            new URL(\"http\", \"\", 8080, reqUri));\n+      } catch (IOException e) {\n+        LOG.warn(\"Shuffle failure \", e);\n+        sendError(ctx, e.getMessage(), UNAUTHORIZED);\n+        return;\n+      }\n+\n+      Channel ch \u003d evt.getChannel();\n+      ch.write(response);\n+      // TODO refactor the following into the pipeline\n+      ChannelFuture lastMap \u003d null;\n+      for (String mapId : mapIds) {\n+        try {\n+          lastMap \u003d\n+            sendMapOutput(ctx, ch, userRsrc.get(jobId), jobId, mapId, reduceId);\n+          if (null \u003d\u003d lastMap) {\n+            sendError(ctx, NOT_FOUND);\n+            return;\n+          }\n+        } catch (IOException e) {\n+          LOG.error(\"Shuffle error \", e);\n+          sendError(ctx, e.getMessage(), INTERNAL_SERVER_ERROR);\n+          return;\n+        }\n+      }\n+      lastMap.addListener(metrics);\n+      lastMap.addListener(ChannelFutureListener.CLOSE);\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    public void messageReceived(ChannelHandlerContext ctx, MessageEvent evt)\n        throws Exception {\n      HttpRequest request \u003d (HttpRequest) evt.getMessage();\n      if (request.getMethod() !\u003d GET) {\n          sendError(ctx, METHOD_NOT_ALLOWED);\n          return;\n      }\n      final Map\u003cString,List\u003cString\u003e\u003e q \u003d\n        new QueryStringDecoder(request.getUri()).getParameters();\n      final List\u003cString\u003e mapIds \u003d splitMaps(q.get(\"map\"));\n      final List\u003cString\u003e reduceQ \u003d q.get(\"reduce\");\n      final List\u003cString\u003e jobQ \u003d q.get(\"job\");\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"RECV: \" + request.getUri() +\n            \"\\n  mapId: \" + mapIds +\n            \"\\n  reduceId: \" + reduceQ +\n            \"\\n  jobId: \" + jobQ);\n      }\n\n      if (mapIds \u003d\u003d null || reduceQ \u003d\u003d null || jobQ \u003d\u003d null) {\n        sendError(ctx, \"Required param job, map and reduce\", BAD_REQUEST);\n        return;\n      }\n      if (reduceQ.size() !\u003d 1 || jobQ.size() !\u003d 1) {\n        sendError(ctx, \"Too many job/reduce parameters\", BAD_REQUEST);\n        return;\n      }\n      int reduceId;\n      String jobId;\n      try {\n        reduceId \u003d Integer.parseInt(reduceQ.get(0));\n        jobId \u003d jobQ.get(0);\n      } catch (NumberFormatException e) {\n        sendError(ctx, \"Bad reduce parameter\", BAD_REQUEST);\n        return;\n      } catch (IllegalArgumentException e) {\n        sendError(ctx, \"Bad job parameter\", BAD_REQUEST);\n        return;\n      }\n      final String reqUri \u003d request.getUri();\n      if (null \u003d\u003d reqUri) {\n        // TODO? add upstream?\n        sendError(ctx, FORBIDDEN);\n        return;\n      }\n      HttpResponse response \u003d new DefaultHttpResponse(HTTP_1_1, OK);\n      try {\n        verifyRequest(jobId, ctx, request, response,\n            new URL(\"http\", \"\", 8080, reqUri));\n      } catch (IOException e) {\n        LOG.warn(\"Shuffle failure \", e);\n        sendError(ctx, e.getMessage(), UNAUTHORIZED);\n        return;\n      }\n\n      Channel ch \u003d evt.getChannel();\n      ch.write(response);\n      // TODO refactor the following into the pipeline\n      ChannelFuture lastMap \u003d null;\n      for (String mapId : mapIds) {\n        try {\n          lastMap \u003d\n            sendMapOutput(ctx, ch, userRsrc.get(jobId), jobId, mapId, reduceId);\n          if (null \u003d\u003d lastMap) {\n            sendError(ctx, NOT_FOUND);\n            return;\n          }\n        } catch (IOException e) {\n          LOG.error(\"Shuffle error \", e);\n          sendError(ctx, e.getMessage(), INTERNAL_SERVER_ERROR);\n          return;\n        }\n      }\n      lastMap.addListener(metrics);\n      lastMap.addListener(ChannelFutureListener.CLOSE);\n    }",
      "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java"
    }
  }
}