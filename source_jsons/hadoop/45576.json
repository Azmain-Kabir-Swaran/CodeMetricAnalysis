{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "LogCLIHelpers.java",
  "functionName": "dumpAContainersLogs",
  "functionId": "dumpAContainersLogs___appId-String__containerId-String__nodeId-String__jobOwner-String",
  "sourceFilePath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogCLIHelpers.java",
  "functionStartLine": 58,
  "functionEndLine": 69,
  "numCommitsSeen": 44,
  "timeTaken": 10253,
  "changeHistory": [
    "e605d47df05619c6b1c18aca59f709899498da75",
    "6ab5aa1c1f82f81726c6daa38b3db90d8c3ad856",
    "c77a1095dc556e8bea87df6d8ddf36e898f27e86",
    "0bc05e40fa7e183efe8463ada459c621da3ce3bf",
    "bde819abbbcea940cfa6426a9e4920e6c8dc9cf1",
    "ef1757790d89cc72f88f5330761b1c8901c59e94",
    "a77d628339afaf2f5a085c73fd81a805b18348c9",
    "58e9f24e0f06efede21085b7ffe36af042fa7b38",
    "e90718fa5a0e7c18592af61534668acebb9db51b",
    "6ff600d9e3496008d81361c17ea427a8675cd0d4",
    "67699c2d187a8480a46acf5031652ff19196823d",
    "e1fdf62123625e4ba399af02f8aad500637d29d1",
    "6ba0375b21c4ce07d2b6b592c4963f705c35222b",
    "c27601fefebd0af887a12d684bfc6f90d9fc0321",
    "47a381e306877750b5a3ce5d76e0a5ff652ec188",
    "670fa24b48acb407c22fbfdde87ae3123dcbf449",
    "fafe8cd28e726566509c679e19d7da622f29f90d",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517"
  ],
  "changeHistoryShort": {
    "e605d47df05619c6b1c18aca59f709899498da75": "Ybodychange",
    "6ab5aa1c1f82f81726c6daa38b3db90d8c3ad856": "Ybodychange",
    "c77a1095dc556e8bea87df6d8ddf36e898f27e86": "Ybodychange",
    "0bc05e40fa7e183efe8463ada459c621da3ce3bf": "Ybodychange",
    "bde819abbbcea940cfa6426a9e4920e6c8dc9cf1": "Ybodychange",
    "ef1757790d89cc72f88f5330761b1c8901c59e94": "Ybodychange",
    "a77d628339afaf2f5a085c73fd81a805b18348c9": "Ybodychange",
    "58e9f24e0f06efede21085b7ffe36af042fa7b38": "Ybodychange",
    "e90718fa5a0e7c18592af61534668acebb9db51b": "Ybodychange",
    "6ff600d9e3496008d81361c17ea427a8675cd0d4": "Ymovefromfile",
    "67699c2d187a8480a46acf5031652ff19196823d": "Ybodychange",
    "e1fdf62123625e4ba399af02f8aad500637d29d1": "Yfilerename",
    "6ba0375b21c4ce07d2b6b592c4963f705c35222b": "Ymultichange(Yreturntypechange,Ybodychange)",
    "c27601fefebd0af887a12d684bfc6f90d9fc0321": "Ymultichange(Yfilerename,Ybodychange)",
    "47a381e306877750b5a3ce5d76e0a5ff652ec188": "Ymultichange(Yrename,Yparameterchange,Ymodifierchange,Ybodychange)",
    "670fa24b48acb407c22fbfdde87ae3123dcbf449": "Ybodychange",
    "fafe8cd28e726566509c679e19d7da622f29f90d": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yintroduced"
  },
  "changeHistoryDetails": {
    "e605d47df05619c6b1c18aca59f709899498da75": {
      "type": "Ybodychange",
      "commitMessage": "YARN-5470. Differentiate exactly match with regex in yarn log CLI. Contributed by Xuan Gong.\n",
      "commitDate": "05/08/16 10:55 AM",
      "commitName": "e605d47df05619c6b1c18aca59f709899498da75",
      "commitAuthor": "Junping Du",
      "commitDateOld": "19/07/16 7:17 AM",
      "commitNameOld": "dc2f4b6ac8a6f8848457046cf9e1362d8f48495d",
      "commitAuthorOld": "Junping Du",
      "daysBetweenCommits": 17.15,
      "commitsBetweenForRepo": 128,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,12 @@\n   public int dumpAContainersLogs(String appId, String containerId,\n       String nodeId, String jobOwner) throws IOException {\n     ContainerLogsRequest options \u003d new ContainerLogsRequest();\n     options.setAppId(ApplicationId.fromString(appId));\n     options.setContainerId(containerId);\n     options.setNodeId(nodeId);\n     options.setAppOwner(jobOwner);\n-    List\u003cString\u003e logs \u003d new ArrayList\u003cString\u003e();\n+    Set\u003cString\u003e logs \u003d new HashSet\u003cString\u003e();\n     options.setLogTypes(logs);\n     options.setBytes(Long.MAX_VALUE);\n     return dumpAContainerLogsForLogType(options, false);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int dumpAContainersLogs(String appId, String containerId,\n      String nodeId, String jobOwner) throws IOException {\n    ContainerLogsRequest options \u003d new ContainerLogsRequest();\n    options.setAppId(ApplicationId.fromString(appId));\n    options.setContainerId(containerId);\n    options.setNodeId(nodeId);\n    options.setAppOwner(jobOwner);\n    Set\u003cString\u003e logs \u003d new HashSet\u003cString\u003e();\n    options.setLogTypes(logs);\n    options.setBytes(Long.MAX_VALUE);\n    return dumpAContainerLogsForLogType(options, false);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogCLIHelpers.java",
      "extendedDetails": {}
    },
    "6ab5aa1c1f82f81726c6daa38b3db90d8c3ad856": {
      "type": "Ybodychange",
      "commitMessage": "YARN-5266. Wrong exit code while trying to get app logs using regex via CLI. Contributed by Xuan Gong\n",
      "commitDate": "22/06/16 9:48 PM",
      "commitName": "6ab5aa1c1f82f81726c6daa38b3db90d8c3ad856",
      "commitAuthor": "Xuan",
      "commitDateOld": "15/06/16 12:12 AM",
      "commitNameOld": "25064fb2fb79751cedbb8019900d811e07549ecf",
      "commitAuthorOld": "Varun Vasudev",
      "daysBetweenCommits": 7.9,
      "commitsBetweenForRepo": 48,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,12 @@\n   public int dumpAContainersLogs(String appId, String containerId,\n       String nodeId, String jobOwner) throws IOException {\n     ContainerLogsRequest options \u003d new ContainerLogsRequest();\n     options.setAppId(ApplicationId.fromString(appId));\n     options.setContainerId(containerId);\n     options.setNodeId(nodeId);\n     options.setAppOwner(jobOwner);\n     List\u003cString\u003e logs \u003d new ArrayList\u003cString\u003e();\n     options.setLogTypes(logs);\n     options.setBytes(Long.MAX_VALUE);\n-    return dumpAContainersLogsForALogType(options, false);\n+    return dumpAContainerLogsForLogType(options, false);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int dumpAContainersLogs(String appId, String containerId,\n      String nodeId, String jobOwner) throws IOException {\n    ContainerLogsRequest options \u003d new ContainerLogsRequest();\n    options.setAppId(ApplicationId.fromString(appId));\n    options.setContainerId(containerId);\n    options.setNodeId(nodeId);\n    options.setAppOwner(jobOwner);\n    List\u003cString\u003e logs \u003d new ArrayList\u003cString\u003e();\n    options.setLogTypes(logs);\n    options.setBytes(Long.MAX_VALUE);\n    return dumpAContainerLogsForLogType(options, false);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogCLIHelpers.java",
      "extendedDetails": {}
    },
    "c77a1095dc556e8bea87df6d8ddf36e898f27e86": {
      "type": "Ybodychange",
      "commitMessage": "YARN-1942. Deprecate toString/fromString methods from ConverterUtils and move them to records classes like ContainerId/ApplicationId, etc. (wangda)\n",
      "commitDate": "14/06/16 3:06 PM",
      "commitName": "c77a1095dc556e8bea87df6d8ddf36e898f27e86",
      "commitAuthor": "Wangda Tan",
      "commitDateOld": "01/06/16 1:44 PM",
      "commitNameOld": "0bc05e40fa7e183efe8463ada459c621da3ce3bf",
      "commitAuthorOld": "Xuan",
      "daysBetweenCommits": 13.06,
      "commitsBetweenForRepo": 84,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,12 @@\n   public int dumpAContainersLogs(String appId, String containerId,\n       String nodeId, String jobOwner) throws IOException {\n     ContainerLogsRequest options \u003d new ContainerLogsRequest();\n-    options.setAppId(ConverterUtils.toApplicationId(appId));\n+    options.setAppId(ApplicationId.fromString(appId));\n     options.setContainerId(containerId);\n     options.setNodeId(nodeId);\n     options.setAppOwner(jobOwner);\n     List\u003cString\u003e logs \u003d new ArrayList\u003cString\u003e();\n     options.setLogTypes(logs);\n     options.setBytes(Long.MAX_VALUE);\n     return dumpAContainersLogsForALogType(options, false);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int dumpAContainersLogs(String appId, String containerId,\n      String nodeId, String jobOwner) throws IOException {\n    ContainerLogsRequest options \u003d new ContainerLogsRequest();\n    options.setAppId(ApplicationId.fromString(appId));\n    options.setContainerId(containerId);\n    options.setNodeId(nodeId);\n    options.setAppOwner(jobOwner);\n    List\u003cString\u003e logs \u003d new ArrayList\u003cString\u003e();\n    options.setLogTypes(logs);\n    options.setBytes(Long.MAX_VALUE);\n    return dumpAContainersLogsForALogType(options, false);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogCLIHelpers.java",
      "extendedDetails": {}
    },
    "0bc05e40fa7e183efe8463ada459c621da3ce3bf": {
      "type": "Ybodychange",
      "commitMessage": "YARN-5088. Improve \"yarn log\" command-line to read the last K bytes for the log files. Contributed by Xuan Gong\n",
      "commitDate": "01/06/16 1:44 PM",
      "commitName": "0bc05e40fa7e183efe8463ada459c621da3ce3bf",
      "commitAuthor": "Xuan",
      "commitDateOld": "26/05/16 11:49 PM",
      "commitNameOld": "bde819abbbcea940cfa6426a9e4920e6c8dc9cf1",
      "commitAuthorOld": "Xuan",
      "daysBetweenCommits": 5.58,
      "commitsBetweenForRepo": 22,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,11 +1,12 @@\n   public int dumpAContainersLogs(String appId, String containerId,\n       String nodeId, String jobOwner) throws IOException {\n     ContainerLogsRequest options \u003d new ContainerLogsRequest();\n     options.setAppId(ConverterUtils.toApplicationId(appId));\n     options.setContainerId(containerId);\n     options.setNodeId(nodeId);\n     options.setAppOwner(jobOwner);\n     List\u003cString\u003e logs \u003d new ArrayList\u003cString\u003e();\n     options.setLogTypes(logs);\n+    options.setBytes(Long.MAX_VALUE);\n     return dumpAContainersLogsForALogType(options, false);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int dumpAContainersLogs(String appId, String containerId,\n      String nodeId, String jobOwner) throws IOException {\n    ContainerLogsRequest options \u003d new ContainerLogsRequest();\n    options.setAppId(ConverterUtils.toApplicationId(appId));\n    options.setContainerId(containerId);\n    options.setNodeId(nodeId);\n    options.setAppOwner(jobOwner);\n    List\u003cString\u003e logs \u003d new ArrayList\u003cString\u003e();\n    options.setLogTypes(logs);\n    options.setBytes(Long.MAX_VALUE);\n    return dumpAContainersLogsForALogType(options, false);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogCLIHelpers.java",
      "extendedDetails": {}
    },
    "bde819abbbcea940cfa6426a9e4920e6c8dc9cf1": {
      "type": "Ybodychange",
      "commitMessage": "YARN-5089. Improve \"yarn log\" command-line \"logFiles\" option to support\nregex. Contributed by Xuan Gong\n",
      "commitDate": "26/05/16 11:49 PM",
      "commitName": "bde819abbbcea940cfa6426a9e4920e6c8dc9cf1",
      "commitAuthor": "Xuan",
      "commitDateOld": "18/05/16 10:14 AM",
      "commitNameOld": "ef1757790d89cc72f88f5330761b1c8901c59e94",
      "commitAuthorOld": "Varun Vasudev",
      "daysBetweenCommits": 8.57,
      "commitsBetweenForRepo": 66,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,5 +1,11 @@\n   public int dumpAContainersLogs(String appId, String containerId,\n       String nodeId, String jobOwner) throws IOException {\n-    return dumpAContainersLogsForALogType(appId, containerId, nodeId, jobOwner,\n-      null, null);\n+    ContainerLogsRequest options \u003d new ContainerLogsRequest();\n+    options.setAppId(ConverterUtils.toApplicationId(appId));\n+    options.setContainerId(containerId);\n+    options.setNodeId(nodeId);\n+    options.setAppOwner(jobOwner);\n+    List\u003cString\u003e logs \u003d new ArrayList\u003cString\u003e();\n+    options.setLogTypes(logs);\n+    return dumpAContainersLogsForALogType(options, false);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int dumpAContainersLogs(String appId, String containerId,\n      String nodeId, String jobOwner) throws IOException {\n    ContainerLogsRequest options \u003d new ContainerLogsRequest();\n    options.setAppId(ConverterUtils.toApplicationId(appId));\n    options.setContainerId(containerId);\n    options.setNodeId(nodeId);\n    options.setAppOwner(jobOwner);\n    List\u003cString\u003e logs \u003d new ArrayList\u003cString\u003e();\n    options.setLogTypes(logs);\n    return dumpAContainersLogsForALogType(options, false);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogCLIHelpers.java",
      "extendedDetails": {}
    },
    "ef1757790d89cc72f88f5330761b1c8901c59e94": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4913. Yarn logs should take a -out option to write to a directory. Contributed by Xuan Gong.\n",
      "commitDate": "18/05/16 10:14 AM",
      "commitName": "ef1757790d89cc72f88f5330761b1c8901c59e94",
      "commitAuthor": "Varun Vasudev",
      "commitDateOld": "09/05/16 10:41 PM",
      "commitNameOld": "87f5e351337a905af5215af76c72b9312616cd4f",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 8.48,
      "commitsBetweenForRepo": 78,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,5 +1,5 @@\n   public int dumpAContainersLogs(String appId, String containerId,\n       String nodeId, String jobOwner) throws IOException {\n     return dumpAContainersLogsForALogType(appId, containerId, nodeId, jobOwner,\n-      null);\n+      null, null);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int dumpAContainersLogs(String appId, String containerId,\n      String nodeId, String jobOwner) throws IOException {\n    return dumpAContainersLogsForALogType(appId, containerId, nodeId, jobOwner,\n      null, null);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogCLIHelpers.java",
      "extendedDetails": {}
    },
    "a77d628339afaf2f5a085c73fd81a805b18348c9": {
      "type": "Ybodychange",
      "commitMessage": "YARN-3347. Improve YARN log command to get AMContainer logs as well as running containers logs. Contributed by Xuan Gong.\n",
      "commitDate": "13/04/15 5:29 PM",
      "commitName": "a77d628339afaf2f5a085c73fd81a805b18348c9",
      "commitAuthor": "Junping Du",
      "commitDateOld": "21/01/15 7:25 PM",
      "commitNameOld": "5712c9f96a2cf4ff63d36906ab3876444c0cddec",
      "commitAuthorOld": "Tsuyoshi Ozawa",
      "daysBetweenCommits": 81.88,
      "commitsBetweenForRepo": 752,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,49 +1,5 @@\n   public int dumpAContainersLogs(String appId, String containerId,\n       String nodeId, String jobOwner) throws IOException {\n-    Path remoteRootLogDir \u003d new Path(getConf().get(\n-        YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n-        YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n-    String suffix \u003d LogAggregationUtils.getRemoteNodeLogDirSuffix(getConf());\n-    Path remoteAppLogDir \u003d LogAggregationUtils.getRemoteAppLogDir(\n-        remoteRootLogDir, ConverterUtils.toApplicationId(appId), jobOwner,\n-        suffix);\n-    RemoteIterator\u003cFileStatus\u003e nodeFiles;\n-    try {\n-      Path qualifiedLogDir \u003d\n-          FileContext.getFileContext(getConf()).makeQualified(\n-            remoteAppLogDir);\n-      nodeFiles \u003d\n-          FileContext.getFileContext(qualifiedLogDir.toUri(), getConf())\n-            .listStatus(remoteAppLogDir);\n-    } catch (FileNotFoundException fnf) {\n-      logDirNotExist(remoteAppLogDir.toString());\n-      return -1;\n-    }\n-    boolean foundContainerLogs \u003d false;\n-    while (nodeFiles.hasNext()) {\n-      FileStatus thisNodeFile \u003d nodeFiles.next();\n-      String fileName \u003d thisNodeFile.getPath().getName();\n-      if (fileName.contains(LogAggregationUtils.getNodeString(nodeId))\n-          \u0026\u0026 !fileName.endsWith(LogAggregationUtils.TMP_FILE_SUFFIX)) {\n-        AggregatedLogFormat.LogReader reader \u003d null;\n-        try {\n-          reader \u003d\n-              new AggregatedLogFormat.LogReader(getConf(),\n-                thisNodeFile.getPath());\n-          if (dumpAContainerLogs(containerId, reader, System.out,\n-              thisNodeFile.getModificationTime()) \u003e -1) {\n-            foundContainerLogs \u003d true;\n-          }\n-        } finally {\n-          if (reader !\u003d null) {\n-            reader.close();\n-          }\n-        }\n-      }\n-    }\n-    if (!foundContainerLogs) {\n-      containerLogNotFound(containerId);\n-      return -1;\n-    }\n-    return 0;\n+    return dumpAContainersLogsForALogType(appId, containerId, nodeId, jobOwner,\n+      null);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int dumpAContainersLogs(String appId, String containerId,\n      String nodeId, String jobOwner) throws IOException {\n    return dumpAContainersLogsForALogType(appId, containerId, nodeId, jobOwner,\n      null);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogCLIHelpers.java",
      "extendedDetails": {}
    },
    "58e9f24e0f06efede21085b7ffe36af042fa7b38": {
      "type": "Ybodychange",
      "commitMessage": "YARN-2788. Fixed backwards compatiblity issues with log-aggregation feature that were caused when adding log-upload-time via YARN-2703. Contributed by Xuan Gong.\n",
      "commitDate": "03/11/14 1:16 PM",
      "commitName": "58e9f24e0f06efede21085b7ffe36af042fa7b38",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "20/10/14 10:21 PM",
      "commitNameOld": "171f2376d23d51b61b9c9b3804ee86dbd4de033a",
      "commitAuthorOld": "Zhijie Shen",
      "daysBetweenCommits": 13.66,
      "commitsBetweenForRepo": 138,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,48 +1,49 @@\n   public int dumpAContainersLogs(String appId, String containerId,\n       String nodeId, String jobOwner) throws IOException {\n     Path remoteRootLogDir \u003d new Path(getConf().get(\n         YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n         YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n     String suffix \u003d LogAggregationUtils.getRemoteNodeLogDirSuffix(getConf());\n     Path remoteAppLogDir \u003d LogAggregationUtils.getRemoteAppLogDir(\n         remoteRootLogDir, ConverterUtils.toApplicationId(appId), jobOwner,\n         suffix);\n     RemoteIterator\u003cFileStatus\u003e nodeFiles;\n     try {\n       Path qualifiedLogDir \u003d\n           FileContext.getFileContext(getConf()).makeQualified(\n             remoteAppLogDir);\n       nodeFiles \u003d\n           FileContext.getFileContext(qualifiedLogDir.toUri(), getConf())\n             .listStatus(remoteAppLogDir);\n     } catch (FileNotFoundException fnf) {\n       logDirNotExist(remoteAppLogDir.toString());\n       return -1;\n     }\n     boolean foundContainerLogs \u003d false;\n     while (nodeFiles.hasNext()) {\n       FileStatus thisNodeFile \u003d nodeFiles.next();\n       String fileName \u003d thisNodeFile.getPath().getName();\n       if (fileName.contains(LogAggregationUtils.getNodeString(nodeId))\n           \u0026\u0026 !fileName.endsWith(LogAggregationUtils.TMP_FILE_SUFFIX)) {\n         AggregatedLogFormat.LogReader reader \u003d null;\n         try {\n           reader \u003d\n               new AggregatedLogFormat.LogReader(getConf(),\n                 thisNodeFile.getPath());\n-          if (dumpAContainerLogs(containerId, reader, System.out) \u003e -1) {\n+          if (dumpAContainerLogs(containerId, reader, System.out,\n+              thisNodeFile.getModificationTime()) \u003e -1) {\n             foundContainerLogs \u003d true;\n           }\n         } finally {\n           if (reader !\u003d null) {\n             reader.close();\n           }\n         }\n       }\n     }\n     if (!foundContainerLogs) {\n       containerLogNotFound(containerId);\n       return -1;\n     }\n     return 0;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int dumpAContainersLogs(String appId, String containerId,\n      String nodeId, String jobOwner) throws IOException {\n    Path remoteRootLogDir \u003d new Path(getConf().get(\n        YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n        YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n    String suffix \u003d LogAggregationUtils.getRemoteNodeLogDirSuffix(getConf());\n    Path remoteAppLogDir \u003d LogAggregationUtils.getRemoteAppLogDir(\n        remoteRootLogDir, ConverterUtils.toApplicationId(appId), jobOwner,\n        suffix);\n    RemoteIterator\u003cFileStatus\u003e nodeFiles;\n    try {\n      Path qualifiedLogDir \u003d\n          FileContext.getFileContext(getConf()).makeQualified(\n            remoteAppLogDir);\n      nodeFiles \u003d\n          FileContext.getFileContext(qualifiedLogDir.toUri(), getConf())\n            .listStatus(remoteAppLogDir);\n    } catch (FileNotFoundException fnf) {\n      logDirNotExist(remoteAppLogDir.toString());\n      return -1;\n    }\n    boolean foundContainerLogs \u003d false;\n    while (nodeFiles.hasNext()) {\n      FileStatus thisNodeFile \u003d nodeFiles.next();\n      String fileName \u003d thisNodeFile.getPath().getName();\n      if (fileName.contains(LogAggregationUtils.getNodeString(nodeId))\n          \u0026\u0026 !fileName.endsWith(LogAggregationUtils.TMP_FILE_SUFFIX)) {\n        AggregatedLogFormat.LogReader reader \u003d null;\n        try {\n          reader \u003d\n              new AggregatedLogFormat.LogReader(getConf(),\n                thisNodeFile.getPath());\n          if (dumpAContainerLogs(containerId, reader, System.out,\n              thisNodeFile.getModificationTime()) \u003e -1) {\n            foundContainerLogs \u003d true;\n          }\n        } finally {\n          if (reader !\u003d null) {\n            reader.close();\n          }\n        }\n      }\n    }\n    if (!foundContainerLogs) {\n      containerLogNotFound(containerId);\n      return -1;\n    }\n    return 0;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogCLIHelpers.java",
      "extendedDetails": {}
    },
    "e90718fa5a0e7c18592af61534668acebb9db51b": {
      "type": "Ybodychange",
      "commitMessage": "YARN-2582. Fixed Log CLI and Web UI for showing aggregated logs of LRS. Contributed Xuan Gong.\n",
      "commitDate": "20/10/14 1:38 PM",
      "commitName": "e90718fa5a0e7c18592af61534668acebb9db51b",
      "commitAuthor": "Zhijie Shen",
      "commitDateOld": "20/05/14 9:19 AM",
      "commitNameOld": "64ec743e6c5384a7b68e4f9852ed12e261643c1f",
      "commitAuthorOld": "Jason Darrell Lowe",
      "daysBetweenCommits": 153.18,
      "commitsBetweenForRepo": 1320,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,48 @@\n   public int dumpAContainersLogs(String appId, String containerId,\n       String nodeId, String jobOwner) throws IOException {\n     Path remoteRootLogDir \u003d new Path(getConf().get(\n         YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n         YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n     String suffix \u003d LogAggregationUtils.getRemoteNodeLogDirSuffix(getConf());\n-    Path logPath \u003d LogAggregationUtils.getRemoteNodeLogFileForApp(\n+    Path remoteAppLogDir \u003d LogAggregationUtils.getRemoteAppLogDir(\n         remoteRootLogDir, ConverterUtils.toApplicationId(appId), jobOwner,\n-        ConverterUtils.toNodeId(nodeId), suffix);\n-    AggregatedLogFormat.LogReader reader;\n+        suffix);\n+    RemoteIterator\u003cFileStatus\u003e nodeFiles;\n     try {\n-      reader \u003d new AggregatedLogFormat.LogReader(getConf(), logPath);\n-    } catch (FileNotFoundException fnfe) {\n-      System.out.println(\"Logs not available at \" + logPath.toString());\n-      System.out\n-          .println(\"Log aggregation has not completed or is not enabled.\");\n+      Path qualifiedLogDir \u003d\n+          FileContext.getFileContext(getConf()).makeQualified(\n+            remoteAppLogDir);\n+      nodeFiles \u003d\n+          FileContext.getFileContext(qualifiedLogDir.toUri(), getConf())\n+            .listStatus(remoteAppLogDir);\n+    } catch (FileNotFoundException fnf) {\n+      logDirNotExist(remoteAppLogDir.toString());\n       return -1;\n     }\n-    return dumpAContainerLogs(containerId, reader, System.out);\n+    boolean foundContainerLogs \u003d false;\n+    while (nodeFiles.hasNext()) {\n+      FileStatus thisNodeFile \u003d nodeFiles.next();\n+      String fileName \u003d thisNodeFile.getPath().getName();\n+      if (fileName.contains(LogAggregationUtils.getNodeString(nodeId))\n+          \u0026\u0026 !fileName.endsWith(LogAggregationUtils.TMP_FILE_SUFFIX)) {\n+        AggregatedLogFormat.LogReader reader \u003d null;\n+        try {\n+          reader \u003d\n+              new AggregatedLogFormat.LogReader(getConf(),\n+                thisNodeFile.getPath());\n+          if (dumpAContainerLogs(containerId, reader, System.out) \u003e -1) {\n+            foundContainerLogs \u003d true;\n+          }\n+        } finally {\n+          if (reader !\u003d null) {\n+            reader.close();\n+          }\n+        }\n+      }\n+    }\n+    if (!foundContainerLogs) {\n+      containerLogNotFound(containerId);\n+      return -1;\n+    }\n+    return 0;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int dumpAContainersLogs(String appId, String containerId,\n      String nodeId, String jobOwner) throws IOException {\n    Path remoteRootLogDir \u003d new Path(getConf().get(\n        YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n        YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n    String suffix \u003d LogAggregationUtils.getRemoteNodeLogDirSuffix(getConf());\n    Path remoteAppLogDir \u003d LogAggregationUtils.getRemoteAppLogDir(\n        remoteRootLogDir, ConverterUtils.toApplicationId(appId), jobOwner,\n        suffix);\n    RemoteIterator\u003cFileStatus\u003e nodeFiles;\n    try {\n      Path qualifiedLogDir \u003d\n          FileContext.getFileContext(getConf()).makeQualified(\n            remoteAppLogDir);\n      nodeFiles \u003d\n          FileContext.getFileContext(qualifiedLogDir.toUri(), getConf())\n            .listStatus(remoteAppLogDir);\n    } catch (FileNotFoundException fnf) {\n      logDirNotExist(remoteAppLogDir.toString());\n      return -1;\n    }\n    boolean foundContainerLogs \u003d false;\n    while (nodeFiles.hasNext()) {\n      FileStatus thisNodeFile \u003d nodeFiles.next();\n      String fileName \u003d thisNodeFile.getPath().getName();\n      if (fileName.contains(LogAggregationUtils.getNodeString(nodeId))\n          \u0026\u0026 !fileName.endsWith(LogAggregationUtils.TMP_FILE_SUFFIX)) {\n        AggregatedLogFormat.LogReader reader \u003d null;\n        try {\n          reader \u003d\n              new AggregatedLogFormat.LogReader(getConf(),\n                thisNodeFile.getPath());\n          if (dumpAContainerLogs(containerId, reader, System.out) \u003e -1) {\n            foundContainerLogs \u003d true;\n          }\n        } finally {\n          if (reader !\u003d null) {\n            reader.close();\n          }\n        }\n      }\n    }\n    if (!foundContainerLogs) {\n      containerLogNotFound(containerId);\n      return -1;\n    }\n    return 0;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogCLIHelpers.java",
      "extendedDetails": {}
    },
    "6ff600d9e3496008d81361c17ea427a8675cd0d4": {
      "type": "Ymovefromfile",
      "commitMessage": "YARN-1131.  logs command should return an appropriate error message if YARN application is still running. Contributed by Siddharth Seth.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1529068 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "03/10/13 7:36 PM",
      "commitName": "6ff600d9e3496008d81361c17ea427a8675cd0d4",
      "commitAuthor": "Hitesh Shah",
      "commitDateOld": "03/10/13 6:30 PM",
      "commitNameOld": "d8ea364d07f782f8693b1ac0c340d4bd8d471c32",
      "commitAuthorOld": "Sanford Ryza",
      "daysBetweenCommits": 0.05,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,20 @@\n   public int dumpAContainersLogs(String appId, String containerId,\n       String nodeId, String jobOwner) throws IOException {\n-    Path remoteRootLogDir \u003d\n-        new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n-            YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n+    Path remoteRootLogDir \u003d new Path(getConf().get(\n+        YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n+        YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n     String suffix \u003d LogAggregationUtils.getRemoteNodeLogDirSuffix(getConf());\n     Path logPath \u003d LogAggregationUtils.getRemoteNodeLogFileForApp(\n         remoteRootLogDir, ConverterUtils.toApplicationId(appId), jobOwner,\n         ConverterUtils.toNodeId(nodeId), suffix);\n     AggregatedLogFormat.LogReader reader;\n     try {\n       reader \u003d new AggregatedLogFormat.LogReader(getConf(), logPath);\n     } catch (FileNotFoundException fnfe) {\n       System.out.println(\"Logs not available at \" + logPath.toString());\n-      System.out.println(\n-          \"Log aggregation has not completed or is not enabled.\");\n+      System.out\n+          .println(\"Log aggregation has not completed or is not enabled.\");\n       return -1;\n     }\n     return dumpAContainerLogs(containerId, reader, System.out);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int dumpAContainersLogs(String appId, String containerId,\n      String nodeId, String jobOwner) throws IOException {\n    Path remoteRootLogDir \u003d new Path(getConf().get(\n        YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n        YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n    String suffix \u003d LogAggregationUtils.getRemoteNodeLogDirSuffix(getConf());\n    Path logPath \u003d LogAggregationUtils.getRemoteNodeLogFileForApp(\n        remoteRootLogDir, ConverterUtils.toApplicationId(appId), jobOwner,\n        ConverterUtils.toNodeId(nodeId), suffix);\n    AggregatedLogFormat.LogReader reader;\n    try {\n      reader \u003d new AggregatedLogFormat.LogReader(getConf(), logPath);\n    } catch (FileNotFoundException fnfe) {\n      System.out.println(\"Logs not available at \" + logPath.toString());\n      System.out\n          .println(\"Log aggregation has not completed or is not enabled.\");\n      return -1;\n    }\n    return dumpAContainerLogs(containerId, reader, System.out);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogCLIHelpers.java",
      "extendedDetails": {
        "oldPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogDumper.java",
        "newPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogCLIHelpers.java",
        "oldMethodName": "dumpAContainersLogs",
        "newMethodName": "dumpAContainersLogs"
      }
    },
    "67699c2d187a8480a46acf5031652ff19196823d": {
      "type": "Ybodychange",
      "commitMessage": "YARN-200. yarn log does not output all needed information, and is in a binary format. Contributed by Ravi Prakash\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1458466 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/03/13 12:29 PM",
      "commitName": "67699c2d187a8480a46acf5031652ff19196823d",
      "commitAuthor": "Jason Darrell Lowe",
      "commitDateOld": "07/08/12 10:22 PM",
      "commitNameOld": "e1fdf62123625e4ba399af02f8aad500637d29d1",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 223.59,
      "commitsBetweenForRepo": 1140,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,20 @@\n   public int dumpAContainersLogs(String appId, String containerId,\n       String nodeId, String jobOwner) throws IOException {\n     Path remoteRootLogDir \u003d\n         new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n             YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n     String suffix \u003d LogAggregationUtils.getRemoteNodeLogDirSuffix(getConf());\n     Path logPath \u003d LogAggregationUtils.getRemoteNodeLogFileForApp(\n         remoteRootLogDir, ConverterUtils.toApplicationId(appId), jobOwner,\n         ConverterUtils.toNodeId(nodeId), suffix);\n     AggregatedLogFormat.LogReader reader;\n     try {\n       reader \u003d new AggregatedLogFormat.LogReader(getConf(), logPath);\n     } catch (FileNotFoundException fnfe) {\n       System.out.println(\"Logs not available at \" + logPath.toString());\n       System.out.println(\n           \"Log aggregation has not completed or is not enabled.\");\n       return -1;\n     }\n-    DataOutputStream out \u003d new DataOutputStream(System.out);\n-    return dumpAContainerLogs(containerId, reader, out);\n+    return dumpAContainerLogs(containerId, reader, System.out);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int dumpAContainersLogs(String appId, String containerId,\n      String nodeId, String jobOwner) throws IOException {\n    Path remoteRootLogDir \u003d\n        new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n            YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n    String suffix \u003d LogAggregationUtils.getRemoteNodeLogDirSuffix(getConf());\n    Path logPath \u003d LogAggregationUtils.getRemoteNodeLogFileForApp(\n        remoteRootLogDir, ConverterUtils.toApplicationId(appId), jobOwner,\n        ConverterUtils.toNodeId(nodeId), suffix);\n    AggregatedLogFormat.LogReader reader;\n    try {\n      reader \u003d new AggregatedLogFormat.LogReader(getConf(), logPath);\n    } catch (FileNotFoundException fnfe) {\n      System.out.println(\"Logs not available at \" + logPath.toString());\n      System.out.println(\n          \"Log aggregation has not completed or is not enabled.\");\n      return -1;\n    }\n    return dumpAContainerLogs(containerId, reader, System.out);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogDumper.java",
      "extendedDetails": {}
    },
    "e1fdf62123625e4ba399af02f8aad500637d29d1": {
      "type": "Yfilerename",
      "commitMessage": "YARN-1. Promote YARN to be a sub-project of Apache Hadoop.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1370666 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/08/12 10:22 PM",
      "commitName": "e1fdf62123625e4ba399af02f8aad500637d29d1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "07/08/12 7:53 PM",
      "commitNameOld": "34554d1e11ee1d5b564d7d9ed3e6d55931d72749",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 0.1,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public int dumpAContainersLogs(String appId, String containerId,\n      String nodeId, String jobOwner) throws IOException {\n    Path remoteRootLogDir \u003d\n        new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n            YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n    String suffix \u003d LogAggregationUtils.getRemoteNodeLogDirSuffix(getConf());\n    Path logPath \u003d LogAggregationUtils.getRemoteNodeLogFileForApp(\n        remoteRootLogDir, ConverterUtils.toApplicationId(appId), jobOwner,\n        ConverterUtils.toNodeId(nodeId), suffix);\n    AggregatedLogFormat.LogReader reader;\n    try {\n      reader \u003d new AggregatedLogFormat.LogReader(getConf(), logPath);\n    } catch (FileNotFoundException fnfe) {\n      System.out.println(\"Logs not available at \" + logPath.toString());\n      System.out.println(\n          \"Log aggregation has not completed or is not enabled.\");\n      return -1;\n    }\n    DataOutputStream out \u003d new DataOutputStream(System.out);\n    return dumpAContainerLogs(containerId, reader, out);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogDumper.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogDumper.java",
        "newPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogDumper.java"
      }
    },
    "6ba0375b21c4ce07d2b6b592c4963f705c35222b": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": "MAPREDUCE-3744. Fix the yarn logs command line. Improve error messages for mapred job -logs. (Contributed by Jason Lowe)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1239433 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "01/02/12 5:43 PM",
      "commitName": "6ba0375b21c4ce07d2b6b592c4963f705c35222b",
      "commitAuthor": "Siddharth Seth",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "MAPREDUCE-3744. Fix the yarn logs command line. Improve error messages for mapred job -logs. (Contributed by Jason Lowe)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1239433 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "01/02/12 5:43 PM",
          "commitName": "6ba0375b21c4ce07d2b6b592c4963f705c35222b",
          "commitAuthor": "Siddharth Seth",
          "commitDateOld": "03/11/11 1:02 AM",
          "commitNameOld": "c27601fefebd0af887a12d684bfc6f90d9fc0321",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 90.74,
          "commitsBetweenForRepo": 447,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,14 +1,21 @@\n-  public void dumpAContainersLogs(String appId, String containerId,\n+  public int dumpAContainersLogs(String appId, String containerId,\n       String nodeId, String jobOwner) throws IOException {\n     Path remoteRootLogDir \u003d\n         new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n             YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n     String suffix \u003d LogAggregationUtils.getRemoteNodeLogDirSuffix(getConf());\n-    AggregatedLogFormat.LogReader reader \u003d\n-        new AggregatedLogFormat.LogReader(getConf(),\n-            LogAggregationUtils.getRemoteNodeLogFileForApp(remoteRootLogDir,\n-                ConverterUtils.toApplicationId(appId), jobOwner,\n-                ConverterUtils.toNodeId(nodeId), suffix));\n+    Path logPath \u003d LogAggregationUtils.getRemoteNodeLogFileForApp(\n+        remoteRootLogDir, ConverterUtils.toApplicationId(appId), jobOwner,\n+        ConverterUtils.toNodeId(nodeId), suffix);\n+    AggregatedLogFormat.LogReader reader;\n+    try {\n+      reader \u003d new AggregatedLogFormat.LogReader(getConf(), logPath);\n+    } catch (FileNotFoundException fnfe) {\n+      System.out.println(\"Logs not available at \" + logPath.toString());\n+      System.out.println(\n+          \"Log aggregation has not completed or is not enabled.\");\n+      return -1;\n+    }\n     DataOutputStream out \u003d new DataOutputStream(System.out);\n-    dumpAContainerLogs(containerId, reader, out);\n+    return dumpAContainerLogs(containerId, reader, out);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public int dumpAContainersLogs(String appId, String containerId,\n      String nodeId, String jobOwner) throws IOException {\n    Path remoteRootLogDir \u003d\n        new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n            YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n    String suffix \u003d LogAggregationUtils.getRemoteNodeLogDirSuffix(getConf());\n    Path logPath \u003d LogAggregationUtils.getRemoteNodeLogFileForApp(\n        remoteRootLogDir, ConverterUtils.toApplicationId(appId), jobOwner,\n        ConverterUtils.toNodeId(nodeId), suffix);\n    AggregatedLogFormat.LogReader reader;\n    try {\n      reader \u003d new AggregatedLogFormat.LogReader(getConf(), logPath);\n    } catch (FileNotFoundException fnfe) {\n      System.out.println(\"Logs not available at \" + logPath.toString());\n      System.out.println(\n          \"Log aggregation has not completed or is not enabled.\");\n      return -1;\n    }\n    DataOutputStream out \u003d new DataOutputStream(System.out);\n    return dumpAContainerLogs(containerId, reader, out);\n  }",
          "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogDumper.java",
          "extendedDetails": {
            "oldValue": "void",
            "newValue": "int"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "MAPREDUCE-3744. Fix the yarn logs command line. Improve error messages for mapred job -logs. (Contributed by Jason Lowe)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1239433 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "01/02/12 5:43 PM",
          "commitName": "6ba0375b21c4ce07d2b6b592c4963f705c35222b",
          "commitAuthor": "Siddharth Seth",
          "commitDateOld": "03/11/11 1:02 AM",
          "commitNameOld": "c27601fefebd0af887a12d684bfc6f90d9fc0321",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 90.74,
          "commitsBetweenForRepo": 447,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,14 +1,21 @@\n-  public void dumpAContainersLogs(String appId, String containerId,\n+  public int dumpAContainersLogs(String appId, String containerId,\n       String nodeId, String jobOwner) throws IOException {\n     Path remoteRootLogDir \u003d\n         new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n             YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n     String suffix \u003d LogAggregationUtils.getRemoteNodeLogDirSuffix(getConf());\n-    AggregatedLogFormat.LogReader reader \u003d\n-        new AggregatedLogFormat.LogReader(getConf(),\n-            LogAggregationUtils.getRemoteNodeLogFileForApp(remoteRootLogDir,\n-                ConverterUtils.toApplicationId(appId), jobOwner,\n-                ConverterUtils.toNodeId(nodeId), suffix));\n+    Path logPath \u003d LogAggregationUtils.getRemoteNodeLogFileForApp(\n+        remoteRootLogDir, ConverterUtils.toApplicationId(appId), jobOwner,\n+        ConverterUtils.toNodeId(nodeId), suffix);\n+    AggregatedLogFormat.LogReader reader;\n+    try {\n+      reader \u003d new AggregatedLogFormat.LogReader(getConf(), logPath);\n+    } catch (FileNotFoundException fnfe) {\n+      System.out.println(\"Logs not available at \" + logPath.toString());\n+      System.out.println(\n+          \"Log aggregation has not completed or is not enabled.\");\n+      return -1;\n+    }\n     DataOutputStream out \u003d new DataOutputStream(System.out);\n-    dumpAContainerLogs(containerId, reader, out);\n+    return dumpAContainerLogs(containerId, reader, out);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public int dumpAContainersLogs(String appId, String containerId,\n      String nodeId, String jobOwner) throws IOException {\n    Path remoteRootLogDir \u003d\n        new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n            YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n    String suffix \u003d LogAggregationUtils.getRemoteNodeLogDirSuffix(getConf());\n    Path logPath \u003d LogAggregationUtils.getRemoteNodeLogFileForApp(\n        remoteRootLogDir, ConverterUtils.toApplicationId(appId), jobOwner,\n        ConverterUtils.toNodeId(nodeId), suffix);\n    AggregatedLogFormat.LogReader reader;\n    try {\n      reader \u003d new AggregatedLogFormat.LogReader(getConf(), logPath);\n    } catch (FileNotFoundException fnfe) {\n      System.out.println(\"Logs not available at \" + logPath.toString());\n      System.out.println(\n          \"Log aggregation has not completed or is not enabled.\");\n      return -1;\n    }\n    DataOutputStream out \u003d new DataOutputStream(System.out);\n    return dumpAContainerLogs(containerId, reader, out);\n  }",
          "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogDumper.java",
          "extendedDetails": {}
        }
      ]
    },
    "c27601fefebd0af887a12d684bfc6f90d9fc0321": {
      "type": "Ymultichange(Yfilerename,Ybodychange)",
      "commitMessage": "MAPREDUCE-3297. Moved log related components into yarn-common so that HistoryServer and clients can use them without depending on the yarn-server-nodemanager module. Contributed by Siddharth Seth.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1196986 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "03/11/11 1:02 AM",
      "commitName": "c27601fefebd0af887a12d684bfc6f90d9fc0321",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "subchanges": [
        {
          "type": "Yfilerename",
          "commitMessage": "MAPREDUCE-3297. Moved log related components into yarn-common so that HistoryServer and clients can use them without depending on the yarn-server-nodemanager module. Contributed by Siddharth Seth.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1196986 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "03/11/11 1:02 AM",
          "commitName": "c27601fefebd0af887a12d684bfc6f90d9fc0321",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "03/11/11 12:06 AM",
          "commitNameOld": "0df4878033b797b9313c887ca9d75f8ea104d029",
          "commitAuthorOld": "Arun Murthy",
          "daysBetweenCommits": 0.04,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,14 +1,14 @@\n   public void dumpAContainersLogs(String appId, String containerId,\n       String nodeId, String jobOwner) throws IOException {\n     Path remoteRootLogDir \u003d\n         new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n             YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n-    String suffix \u003d LogAggregationService.getRemoteNodeLogDirSuffix(getConf());\n+    String suffix \u003d LogAggregationUtils.getRemoteNodeLogDirSuffix(getConf());\n     AggregatedLogFormat.LogReader reader \u003d\n         new AggregatedLogFormat.LogReader(getConf(),\n-            LogAggregationService.getRemoteNodeLogFileForApp(remoteRootLogDir,\n+            LogAggregationUtils.getRemoteNodeLogFileForApp(remoteRootLogDir,\n                 ConverterUtils.toApplicationId(appId), jobOwner,\n                 ConverterUtils.toNodeId(nodeId), suffix));\n     DataOutputStream out \u003d new DataOutputStream(System.out);\n     dumpAContainerLogs(containerId, reader, out);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void dumpAContainersLogs(String appId, String containerId,\n      String nodeId, String jobOwner) throws IOException {\n    Path remoteRootLogDir \u003d\n        new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n            YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n    String suffix \u003d LogAggregationUtils.getRemoteNodeLogDirSuffix(getConf());\n    AggregatedLogFormat.LogReader reader \u003d\n        new AggregatedLogFormat.LogReader(getConf(),\n            LogAggregationUtils.getRemoteNodeLogFileForApp(remoteRootLogDir,\n                ConverterUtils.toApplicationId(appId), jobOwner,\n                ConverterUtils.toNodeId(nodeId), suffix));\n    DataOutputStream out \u003d new DataOutputStream(System.out);\n    dumpAContainerLogs(containerId, reader, out);\n  }",
          "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogDumper.java",
          "extendedDetails": {
            "oldPath": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/logaggregation/LogDumper.java",
            "newPath": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogDumper.java"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "MAPREDUCE-3297. Moved log related components into yarn-common so that HistoryServer and clients can use them without depending on the yarn-server-nodemanager module. Contributed by Siddharth Seth.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1196986 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "03/11/11 1:02 AM",
          "commitName": "c27601fefebd0af887a12d684bfc6f90d9fc0321",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "03/11/11 12:06 AM",
          "commitNameOld": "0df4878033b797b9313c887ca9d75f8ea104d029",
          "commitAuthorOld": "Arun Murthy",
          "daysBetweenCommits": 0.04,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,14 +1,14 @@\n   public void dumpAContainersLogs(String appId, String containerId,\n       String nodeId, String jobOwner) throws IOException {\n     Path remoteRootLogDir \u003d\n         new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n             YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n-    String suffix \u003d LogAggregationService.getRemoteNodeLogDirSuffix(getConf());\n+    String suffix \u003d LogAggregationUtils.getRemoteNodeLogDirSuffix(getConf());\n     AggregatedLogFormat.LogReader reader \u003d\n         new AggregatedLogFormat.LogReader(getConf(),\n-            LogAggregationService.getRemoteNodeLogFileForApp(remoteRootLogDir,\n+            LogAggregationUtils.getRemoteNodeLogFileForApp(remoteRootLogDir,\n                 ConverterUtils.toApplicationId(appId), jobOwner,\n                 ConverterUtils.toNodeId(nodeId), suffix));\n     DataOutputStream out \u003d new DataOutputStream(System.out);\n     dumpAContainerLogs(containerId, reader, out);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void dumpAContainersLogs(String appId, String containerId,\n      String nodeId, String jobOwner) throws IOException {\n    Path remoteRootLogDir \u003d\n        new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n            YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n    String suffix \u003d LogAggregationUtils.getRemoteNodeLogDirSuffix(getConf());\n    AggregatedLogFormat.LogReader reader \u003d\n        new AggregatedLogFormat.LogReader(getConf(),\n            LogAggregationUtils.getRemoteNodeLogFileForApp(remoteRootLogDir,\n                ConverterUtils.toApplicationId(appId), jobOwner,\n                ConverterUtils.toNodeId(nodeId), suffix));\n    DataOutputStream out \u003d new DataOutputStream(System.out);\n    dumpAContainerLogs(containerId, reader, out);\n  }",
          "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogDumper.java",
          "extendedDetails": {}
        }
      ]
    },
    "47a381e306877750b5a3ce5d76e0a5ff652ec188": {
      "type": "Ymultichange(Yrename,Yparameterchange,Ymodifierchange,Ybodychange)",
      "commitMessage": "MAPREDUCE-3146. Added a MR specific command line to dump logs for a given TaskAttemptID. Contributed by Siddharth Seth.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1195349 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "30/10/11 11:42 PM",
      "commitName": "47a381e306877750b5a3ce5d76e0a5ff652ec188",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "subchanges": [
        {
          "type": "Yrename",
          "commitMessage": "MAPREDUCE-3146. Added a MR specific command line to dump logs for a given TaskAttemptID. Contributed by Siddharth Seth.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1195349 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "30/10/11 11:42 PM",
          "commitName": "47a381e306877750b5a3ce5d76e0a5ff652ec188",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "27/10/11 11:45 PM",
          "commitNameOld": "670fa24b48acb407c22fbfdde87ae3123dcbf449",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 3.0,
          "commitsBetweenForRepo": 23,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,44 +1,14 @@\n-      dumpAllContainersLogs(ApplicationId appId, DataOutputStream out)\n-          throws IOException {\n+  public void dumpAContainersLogs(String appId, String containerId,\n+      String nodeId, String jobOwner) throws IOException {\n     Path remoteRootLogDir \u003d\n         new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n             YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n-    String user \u003d UserGroupInformation.getCurrentUser().getShortUserName();\n-    String logDirSuffix \u003d\n-        getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n-            YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR_SUFFIX);\n-    //TODO Change this to get a list of files from the LAS.\n-    Path remoteAppLogDir \u003d\n-        LogAggregationService.getRemoteAppLogDir(remoteRootLogDir, appId, user,\n-            logDirSuffix);\n-    RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d\n-        FileContext.getFileContext().listStatus(remoteAppLogDir);\n-    while (nodeFiles.hasNext()) {\n-      FileStatus thisNodeFile \u003d nodeFiles.next();\n-      AggregatedLogFormat.LogReader reader \u003d\n-          new AggregatedLogFormat.LogReader(getConf(),\n-              new Path(remoteAppLogDir, thisNodeFile.getPath().getName()));\n-      try {\n-\n-        DataInputStream valueStream;\n-        LogKey key \u003d new LogKey();\n-        valueStream \u003d reader.next(key);\n-\n-        while (valueStream !\u003d null) {\n-          while (true) {\n-            try {\n-              LogReader.readAContainerLogsForALogType(valueStream, out);\n-            } catch (EOFException eof) {\n-              break;\n-            }\n-          }\n-\n-          // Next container\n-          key \u003d new LogKey();\n-          valueStream \u003d reader.next(key);\n-        }\n-      } finally {\n-        reader.close();\n-      }\n-    }\n+    String suffix \u003d LogAggregationService.getRemoteNodeLogDirSuffix(getConf());\n+    AggregatedLogFormat.LogReader reader \u003d\n+        new AggregatedLogFormat.LogReader(getConf(),\n+            LogAggregationService.getRemoteNodeLogFileForApp(remoteRootLogDir,\n+                ConverterUtils.toApplicationId(appId), jobOwner,\n+                ConverterUtils.toNodeId(nodeId), suffix));\n+    DataOutputStream out \u003d new DataOutputStream(System.out);\n+    dumpAContainerLogs(containerId, reader, out);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void dumpAContainersLogs(String appId, String containerId,\n      String nodeId, String jobOwner) throws IOException {\n    Path remoteRootLogDir \u003d\n        new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n            YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n    String suffix \u003d LogAggregationService.getRemoteNodeLogDirSuffix(getConf());\n    AggregatedLogFormat.LogReader reader \u003d\n        new AggregatedLogFormat.LogReader(getConf(),\n            LogAggregationService.getRemoteNodeLogFileForApp(remoteRootLogDir,\n                ConverterUtils.toApplicationId(appId), jobOwner,\n                ConverterUtils.toNodeId(nodeId), suffix));\n    DataOutputStream out \u003d new DataOutputStream(System.out);\n    dumpAContainerLogs(containerId, reader, out);\n  }",
          "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/logaggregation/LogDumper.java",
          "extendedDetails": {
            "oldValue": "dumpAllContainersLogs",
            "newValue": "dumpAContainersLogs"
          }
        },
        {
          "type": "Yparameterchange",
          "commitMessage": "MAPREDUCE-3146. Added a MR specific command line to dump logs for a given TaskAttemptID. Contributed by Siddharth Seth.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1195349 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "30/10/11 11:42 PM",
          "commitName": "47a381e306877750b5a3ce5d76e0a5ff652ec188",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "27/10/11 11:45 PM",
          "commitNameOld": "670fa24b48acb407c22fbfdde87ae3123dcbf449",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 3.0,
          "commitsBetweenForRepo": 23,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,44 +1,14 @@\n-      dumpAllContainersLogs(ApplicationId appId, DataOutputStream out)\n-          throws IOException {\n+  public void dumpAContainersLogs(String appId, String containerId,\n+      String nodeId, String jobOwner) throws IOException {\n     Path remoteRootLogDir \u003d\n         new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n             YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n-    String user \u003d UserGroupInformation.getCurrentUser().getShortUserName();\n-    String logDirSuffix \u003d\n-        getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n-            YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR_SUFFIX);\n-    //TODO Change this to get a list of files from the LAS.\n-    Path remoteAppLogDir \u003d\n-        LogAggregationService.getRemoteAppLogDir(remoteRootLogDir, appId, user,\n-            logDirSuffix);\n-    RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d\n-        FileContext.getFileContext().listStatus(remoteAppLogDir);\n-    while (nodeFiles.hasNext()) {\n-      FileStatus thisNodeFile \u003d nodeFiles.next();\n-      AggregatedLogFormat.LogReader reader \u003d\n-          new AggregatedLogFormat.LogReader(getConf(),\n-              new Path(remoteAppLogDir, thisNodeFile.getPath().getName()));\n-      try {\n-\n-        DataInputStream valueStream;\n-        LogKey key \u003d new LogKey();\n-        valueStream \u003d reader.next(key);\n-\n-        while (valueStream !\u003d null) {\n-          while (true) {\n-            try {\n-              LogReader.readAContainerLogsForALogType(valueStream, out);\n-            } catch (EOFException eof) {\n-              break;\n-            }\n-          }\n-\n-          // Next container\n-          key \u003d new LogKey();\n-          valueStream \u003d reader.next(key);\n-        }\n-      } finally {\n-        reader.close();\n-      }\n-    }\n+    String suffix \u003d LogAggregationService.getRemoteNodeLogDirSuffix(getConf());\n+    AggregatedLogFormat.LogReader reader \u003d\n+        new AggregatedLogFormat.LogReader(getConf(),\n+            LogAggregationService.getRemoteNodeLogFileForApp(remoteRootLogDir,\n+                ConverterUtils.toApplicationId(appId), jobOwner,\n+                ConverterUtils.toNodeId(nodeId), suffix));\n+    DataOutputStream out \u003d new DataOutputStream(System.out);\n+    dumpAContainerLogs(containerId, reader, out);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void dumpAContainersLogs(String appId, String containerId,\n      String nodeId, String jobOwner) throws IOException {\n    Path remoteRootLogDir \u003d\n        new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n            YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n    String suffix \u003d LogAggregationService.getRemoteNodeLogDirSuffix(getConf());\n    AggregatedLogFormat.LogReader reader \u003d\n        new AggregatedLogFormat.LogReader(getConf(),\n            LogAggregationService.getRemoteNodeLogFileForApp(remoteRootLogDir,\n                ConverterUtils.toApplicationId(appId), jobOwner,\n                ConverterUtils.toNodeId(nodeId), suffix));\n    DataOutputStream out \u003d new DataOutputStream(System.out);\n    dumpAContainerLogs(containerId, reader, out);\n  }",
          "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/logaggregation/LogDumper.java",
          "extendedDetails": {
            "oldValue": "[appId-ApplicationId, out-DataOutputStream]",
            "newValue": "[appId-String, containerId-String, nodeId-String, jobOwner-String]"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "MAPREDUCE-3146. Added a MR specific command line to dump logs for a given TaskAttemptID. Contributed by Siddharth Seth.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1195349 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "30/10/11 11:42 PM",
          "commitName": "47a381e306877750b5a3ce5d76e0a5ff652ec188",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "27/10/11 11:45 PM",
          "commitNameOld": "670fa24b48acb407c22fbfdde87ae3123dcbf449",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 3.0,
          "commitsBetweenForRepo": 23,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,44 +1,14 @@\n-      dumpAllContainersLogs(ApplicationId appId, DataOutputStream out)\n-          throws IOException {\n+  public void dumpAContainersLogs(String appId, String containerId,\n+      String nodeId, String jobOwner) throws IOException {\n     Path remoteRootLogDir \u003d\n         new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n             YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n-    String user \u003d UserGroupInformation.getCurrentUser().getShortUserName();\n-    String logDirSuffix \u003d\n-        getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n-            YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR_SUFFIX);\n-    //TODO Change this to get a list of files from the LAS.\n-    Path remoteAppLogDir \u003d\n-        LogAggregationService.getRemoteAppLogDir(remoteRootLogDir, appId, user,\n-            logDirSuffix);\n-    RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d\n-        FileContext.getFileContext().listStatus(remoteAppLogDir);\n-    while (nodeFiles.hasNext()) {\n-      FileStatus thisNodeFile \u003d nodeFiles.next();\n-      AggregatedLogFormat.LogReader reader \u003d\n-          new AggregatedLogFormat.LogReader(getConf(),\n-              new Path(remoteAppLogDir, thisNodeFile.getPath().getName()));\n-      try {\n-\n-        DataInputStream valueStream;\n-        LogKey key \u003d new LogKey();\n-        valueStream \u003d reader.next(key);\n-\n-        while (valueStream !\u003d null) {\n-          while (true) {\n-            try {\n-              LogReader.readAContainerLogsForALogType(valueStream, out);\n-            } catch (EOFException eof) {\n-              break;\n-            }\n-          }\n-\n-          // Next container\n-          key \u003d new LogKey();\n-          valueStream \u003d reader.next(key);\n-        }\n-      } finally {\n-        reader.close();\n-      }\n-    }\n+    String suffix \u003d LogAggregationService.getRemoteNodeLogDirSuffix(getConf());\n+    AggregatedLogFormat.LogReader reader \u003d\n+        new AggregatedLogFormat.LogReader(getConf(),\n+            LogAggregationService.getRemoteNodeLogFileForApp(remoteRootLogDir,\n+                ConverterUtils.toApplicationId(appId), jobOwner,\n+                ConverterUtils.toNodeId(nodeId), suffix));\n+    DataOutputStream out \u003d new DataOutputStream(System.out);\n+    dumpAContainerLogs(containerId, reader, out);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void dumpAContainersLogs(String appId, String containerId,\n      String nodeId, String jobOwner) throws IOException {\n    Path remoteRootLogDir \u003d\n        new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n            YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n    String suffix \u003d LogAggregationService.getRemoteNodeLogDirSuffix(getConf());\n    AggregatedLogFormat.LogReader reader \u003d\n        new AggregatedLogFormat.LogReader(getConf(),\n            LogAggregationService.getRemoteNodeLogFileForApp(remoteRootLogDir,\n                ConverterUtils.toApplicationId(appId), jobOwner,\n                ConverterUtils.toNodeId(nodeId), suffix));\n    DataOutputStream out \u003d new DataOutputStream(System.out);\n    dumpAContainerLogs(containerId, reader, out);\n  }",
          "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/logaggregation/LogDumper.java",
          "extendedDetails": {
            "oldValue": "[private]",
            "newValue": "[public]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "MAPREDUCE-3146. Added a MR specific command line to dump logs for a given TaskAttemptID. Contributed by Siddharth Seth.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1195349 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "30/10/11 11:42 PM",
          "commitName": "47a381e306877750b5a3ce5d76e0a5ff652ec188",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "27/10/11 11:45 PM",
          "commitNameOld": "670fa24b48acb407c22fbfdde87ae3123dcbf449",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 3.0,
          "commitsBetweenForRepo": 23,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,44 +1,14 @@\n-      dumpAllContainersLogs(ApplicationId appId, DataOutputStream out)\n-          throws IOException {\n+  public void dumpAContainersLogs(String appId, String containerId,\n+      String nodeId, String jobOwner) throws IOException {\n     Path remoteRootLogDir \u003d\n         new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n             YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n-    String user \u003d UserGroupInformation.getCurrentUser().getShortUserName();\n-    String logDirSuffix \u003d\n-        getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n-            YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR_SUFFIX);\n-    //TODO Change this to get a list of files from the LAS.\n-    Path remoteAppLogDir \u003d\n-        LogAggregationService.getRemoteAppLogDir(remoteRootLogDir, appId, user,\n-            logDirSuffix);\n-    RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d\n-        FileContext.getFileContext().listStatus(remoteAppLogDir);\n-    while (nodeFiles.hasNext()) {\n-      FileStatus thisNodeFile \u003d nodeFiles.next();\n-      AggregatedLogFormat.LogReader reader \u003d\n-          new AggregatedLogFormat.LogReader(getConf(),\n-              new Path(remoteAppLogDir, thisNodeFile.getPath().getName()));\n-      try {\n-\n-        DataInputStream valueStream;\n-        LogKey key \u003d new LogKey();\n-        valueStream \u003d reader.next(key);\n-\n-        while (valueStream !\u003d null) {\n-          while (true) {\n-            try {\n-              LogReader.readAContainerLogsForALogType(valueStream, out);\n-            } catch (EOFException eof) {\n-              break;\n-            }\n-          }\n-\n-          // Next container\n-          key \u003d new LogKey();\n-          valueStream \u003d reader.next(key);\n-        }\n-      } finally {\n-        reader.close();\n-      }\n-    }\n+    String suffix \u003d LogAggregationService.getRemoteNodeLogDirSuffix(getConf());\n+    AggregatedLogFormat.LogReader reader \u003d\n+        new AggregatedLogFormat.LogReader(getConf(),\n+            LogAggregationService.getRemoteNodeLogFileForApp(remoteRootLogDir,\n+                ConverterUtils.toApplicationId(appId), jobOwner,\n+                ConverterUtils.toNodeId(nodeId), suffix));\n+    DataOutputStream out \u003d new DataOutputStream(System.out);\n+    dumpAContainerLogs(containerId, reader, out);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void dumpAContainersLogs(String appId, String containerId,\n      String nodeId, String jobOwner) throws IOException {\n    Path remoteRootLogDir \u003d\n        new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n            YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n    String suffix \u003d LogAggregationService.getRemoteNodeLogDirSuffix(getConf());\n    AggregatedLogFormat.LogReader reader \u003d\n        new AggregatedLogFormat.LogReader(getConf(),\n            LogAggregationService.getRemoteNodeLogFileForApp(remoteRootLogDir,\n                ConverterUtils.toApplicationId(appId), jobOwner,\n                ConverterUtils.toNodeId(nodeId), suffix));\n    DataOutputStream out \u003d new DataOutputStream(System.out);\n    dumpAContainerLogs(containerId, reader, out);\n  }",
          "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/logaggregation/LogDumper.java",
          "extendedDetails": {}
        }
      ]
    },
    "670fa24b48acb407c22fbfdde87ae3123dcbf449": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-2989. Modified JobHistory to link to task and AM logs from the JobHistoryServer. Contributed by Siddharth Seth.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1190174 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/10/11 11:45 PM",
      "commitName": "670fa24b48acb407c22fbfdde87ae3123dcbf449",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "08/09/11 6:44 PM",
      "commitNameOld": "fafe8cd28e726566509c679e19d7da622f29f90d",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 49.21,
      "commitsBetweenForRepo": 395,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,39 +1,44 @@\n       dumpAllContainersLogs(ApplicationId appId, DataOutputStream out)\n           throws IOException {\n     Path remoteRootLogDir \u003d\n         new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n             YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n+    String user \u003d UserGroupInformation.getCurrentUser().getShortUserName();\n+    String logDirSuffix \u003d\n+        getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n+            YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR_SUFFIX);\n+    //TODO Change this to get a list of files from the LAS.\n     Path remoteAppLogDir \u003d\n-        LogAggregationService.getRemoteAppLogDir(remoteRootLogDir, appId);\n+        LogAggregationService.getRemoteAppLogDir(remoteRootLogDir, appId, user,\n+            logDirSuffix);\n     RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d\n         FileContext.getFileContext().listStatus(remoteAppLogDir);\n     while (nodeFiles.hasNext()) {\n       FileStatus thisNodeFile \u003d nodeFiles.next();\n       AggregatedLogFormat.LogReader reader \u003d\n           new AggregatedLogFormat.LogReader(getConf(),\n-              LogAggregationService.getRemoteNodeLogFileForApp(\n-                  remoteRootLogDir, appId, thisNodeFile.getPath().getName()));\n+              new Path(remoteAppLogDir, thisNodeFile.getPath().getName()));\n       try {\n \n         DataInputStream valueStream;\n         LogKey key \u003d new LogKey();\n         valueStream \u003d reader.next(key);\n \n         while (valueStream !\u003d null) {\n           while (true) {\n             try {\n               LogReader.readAContainerLogsForALogType(valueStream, out);\n             } catch (EOFException eof) {\n               break;\n             }\n           }\n \n           // Next container\n           key \u003d new LogKey();\n           valueStream \u003d reader.next(key);\n         }\n       } finally {\n         reader.close();\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "      dumpAllContainersLogs(ApplicationId appId, DataOutputStream out)\n          throws IOException {\n    Path remoteRootLogDir \u003d\n        new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n            YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n    String user \u003d UserGroupInformation.getCurrentUser().getShortUserName();\n    String logDirSuffix \u003d\n        getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n            YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR_SUFFIX);\n    //TODO Change this to get a list of files from the LAS.\n    Path remoteAppLogDir \u003d\n        LogAggregationService.getRemoteAppLogDir(remoteRootLogDir, appId, user,\n            logDirSuffix);\n    RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d\n        FileContext.getFileContext().listStatus(remoteAppLogDir);\n    while (nodeFiles.hasNext()) {\n      FileStatus thisNodeFile \u003d nodeFiles.next();\n      AggregatedLogFormat.LogReader reader \u003d\n          new AggregatedLogFormat.LogReader(getConf(),\n              new Path(remoteAppLogDir, thisNodeFile.getPath().getName()));\n      try {\n\n        DataInputStream valueStream;\n        LogKey key \u003d new LogKey();\n        valueStream \u003d reader.next(key);\n\n        while (valueStream !\u003d null) {\n          while (true) {\n            try {\n              LogReader.readAContainerLogsForALogType(valueStream, out);\n            } catch (EOFException eof) {\n              break;\n            }\n          }\n\n          // Next container\n          key \u003d new LogKey();\n          valueStream \u003d reader.next(key);\n        }\n      } finally {\n        reader.close();\n      }\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/logaggregation/LogDumper.java",
      "extendedDetails": {}
    },
    "fafe8cd28e726566509c679e19d7da622f29f90d": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-2864. Normalize configuration variable names for YARN. Contributed by Robert Evans.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1166955 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/09/11 6:44 PM",
      "commitName": "fafe8cd28e726566509c679e19d7da622f29f90d",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:14 PM",
      "commitNameOld": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 15.06,
      "commitsBetweenForRepo": 86,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,39 +1,39 @@\n       dumpAllContainersLogs(ApplicationId appId, DataOutputStream out)\n           throws IOException {\n     Path remoteRootLogDir \u003d\n-        new Path(getConf().get(NMConfig.REMOTE_USER_LOG_DIR,\n-            NMConfig.DEFAULT_REMOTE_APP_LOG_DIR));\n+        new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n+            YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n     Path remoteAppLogDir \u003d\n         LogAggregationService.getRemoteAppLogDir(remoteRootLogDir, appId);\n     RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d\n         FileContext.getFileContext().listStatus(remoteAppLogDir);\n     while (nodeFiles.hasNext()) {\n       FileStatus thisNodeFile \u003d nodeFiles.next();\n       AggregatedLogFormat.LogReader reader \u003d\n           new AggregatedLogFormat.LogReader(getConf(),\n               LogAggregationService.getRemoteNodeLogFileForApp(\n                   remoteRootLogDir, appId, thisNodeFile.getPath().getName()));\n       try {\n \n         DataInputStream valueStream;\n         LogKey key \u003d new LogKey();\n         valueStream \u003d reader.next(key);\n \n         while (valueStream !\u003d null) {\n           while (true) {\n             try {\n               LogReader.readAContainerLogsForALogType(valueStream, out);\n             } catch (EOFException eof) {\n               break;\n             }\n           }\n \n           // Next container\n           key \u003d new LogKey();\n           valueStream \u003d reader.next(key);\n         }\n       } finally {\n         reader.close();\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "      dumpAllContainersLogs(ApplicationId appId, DataOutputStream out)\n          throws IOException {\n    Path remoteRootLogDir \u003d\n        new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n            YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n    Path remoteAppLogDir \u003d\n        LogAggregationService.getRemoteAppLogDir(remoteRootLogDir, appId);\n    RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d\n        FileContext.getFileContext().listStatus(remoteAppLogDir);\n    while (nodeFiles.hasNext()) {\n      FileStatus thisNodeFile \u003d nodeFiles.next();\n      AggregatedLogFormat.LogReader reader \u003d\n          new AggregatedLogFormat.LogReader(getConf(),\n              LogAggregationService.getRemoteNodeLogFileForApp(\n                  remoteRootLogDir, appId, thisNodeFile.getPath().getName()));\n      try {\n\n        DataInputStream valueStream;\n        LogKey key \u003d new LogKey();\n        valueStream \u003d reader.next(key);\n\n        while (valueStream !\u003d null) {\n          while (true) {\n            try {\n              LogReader.readAContainerLogsForALogType(valueStream, out);\n            } catch (EOFException eof) {\n              break;\n            }\n          }\n\n          // Next container\n          key \u003d new LogKey();\n          valueStream \u003d reader.next(key);\n        }\n      } finally {\n        reader.close();\n      }\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/logaggregation/LogDumper.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "      dumpAllContainersLogs(ApplicationId appId, DataOutputStream out)\n          throws IOException {\n    Path remoteRootLogDir \u003d\n        new Path(getConf().get(NMConfig.REMOTE_USER_LOG_DIR,\n            NMConfig.DEFAULT_REMOTE_APP_LOG_DIR));\n    Path remoteAppLogDir \u003d\n        LogAggregationService.getRemoteAppLogDir(remoteRootLogDir, appId);\n    RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d\n        FileContext.getFileContext().listStatus(remoteAppLogDir);\n    while (nodeFiles.hasNext()) {\n      FileStatus thisNodeFile \u003d nodeFiles.next();\n      AggregatedLogFormat.LogReader reader \u003d\n          new AggregatedLogFormat.LogReader(getConf(),\n              LogAggregationService.getRemoteNodeLogFileForApp(\n                  remoteRootLogDir, appId, thisNodeFile.getPath().getName()));\n      try {\n\n        DataInputStream valueStream;\n        LogKey key \u003d new LogKey();\n        valueStream \u003d reader.next(key);\n\n        while (valueStream !\u003d null) {\n          while (true) {\n            try {\n              LogReader.readAContainerLogsForALogType(valueStream, out);\n            } catch (EOFException eof) {\n              break;\n            }\n          }\n\n          // Next container\n          key \u003d new LogKey();\n          valueStream \u003d reader.next(key);\n        }\n      } finally {\n        reader.close();\n      }\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/logaggregation/LogDumper.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/logaggregation/LogDumper.java",
        "newPath": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/logaggregation/LogDumper.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "diff": "@@ -0,0 +1,39 @@\n+      dumpAllContainersLogs(ApplicationId appId, DataOutputStream out)\n+          throws IOException {\n+    Path remoteRootLogDir \u003d\n+        new Path(getConf().get(NMConfig.REMOTE_USER_LOG_DIR,\n+            NMConfig.DEFAULT_REMOTE_APP_LOG_DIR));\n+    Path remoteAppLogDir \u003d\n+        LogAggregationService.getRemoteAppLogDir(remoteRootLogDir, appId);\n+    RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d\n+        FileContext.getFileContext().listStatus(remoteAppLogDir);\n+    while (nodeFiles.hasNext()) {\n+      FileStatus thisNodeFile \u003d nodeFiles.next();\n+      AggregatedLogFormat.LogReader reader \u003d\n+          new AggregatedLogFormat.LogReader(getConf(),\n+              LogAggregationService.getRemoteNodeLogFileForApp(\n+                  remoteRootLogDir, appId, thisNodeFile.getPath().getName()));\n+      try {\n+\n+        DataInputStream valueStream;\n+        LogKey key \u003d new LogKey();\n+        valueStream \u003d reader.next(key);\n+\n+        while (valueStream !\u003d null) {\n+          while (true) {\n+            try {\n+              LogReader.readAContainerLogsForALogType(valueStream, out);\n+            } catch (EOFException eof) {\n+              break;\n+            }\n+          }\n+\n+          // Next container\n+          key \u003d new LogKey();\n+          valueStream \u003d reader.next(key);\n+        }\n+      } finally {\n+        reader.close();\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "      dumpAllContainersLogs(ApplicationId appId, DataOutputStream out)\n          throws IOException {\n    Path remoteRootLogDir \u003d\n        new Path(getConf().get(NMConfig.REMOTE_USER_LOG_DIR,\n            NMConfig.DEFAULT_REMOTE_APP_LOG_DIR));\n    Path remoteAppLogDir \u003d\n        LogAggregationService.getRemoteAppLogDir(remoteRootLogDir, appId);\n    RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d\n        FileContext.getFileContext().listStatus(remoteAppLogDir);\n    while (nodeFiles.hasNext()) {\n      FileStatus thisNodeFile \u003d nodeFiles.next();\n      AggregatedLogFormat.LogReader reader \u003d\n          new AggregatedLogFormat.LogReader(getConf(),\n              LogAggregationService.getRemoteNodeLogFileForApp(\n                  remoteRootLogDir, appId, thisNodeFile.getPath().getName()));\n      try {\n\n        DataInputStream valueStream;\n        LogKey key \u003d new LogKey();\n        valueStream \u003d reader.next(key);\n\n        while (valueStream !\u003d null) {\n          while (true) {\n            try {\n              LogReader.readAContainerLogsForALogType(valueStream, out);\n            } catch (EOFException eof) {\n              break;\n            }\n          }\n\n          // Next container\n          key \u003d new LogKey();\n          valueStream \u003d reader.next(key);\n        }\n      } finally {\n        reader.close();\n      }\n    }\n  }",
      "path": "hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/logaggregation/LogDumper.java"
    }
  }
}