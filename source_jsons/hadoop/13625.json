{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DatanodeAdminBackoffMonitor.java",
  "functionName": "processPendingNodes",
  "functionId": "processPendingNodes",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminBackoffMonitor.java",
  "functionStartLine": 222,
  "functionEndLine": 228,
  "numCommitsSeen": 40,
  "timeTaken": 4026,
  "changeHistory": [
    "c93cb6790e0f1c64efd03d859f907a0522010894",
    "79df1e750ef558afed6d166ce225a23061b36aed",
    "9dcbdbdb5a34d85910707f81ebc1bb1f81c99978",
    "6ee0d32b98bc3aa5ed42859f1325d5a14fd1722a"
  ],
  "changeHistoryShort": {
    "c93cb6790e0f1c64efd03d859f907a0522010894": "Ymovefromfile",
    "79df1e750ef558afed6d166ce225a23061b36aed": "Yfilerename",
    "9dcbdbdb5a34d85910707f81ebc1bb1f81c99978": "Ybodychange",
    "6ee0d32b98bc3aa5ed42859f1325d5a14fd1722a": "Yintroduced"
  },
  "changeHistoryDetails": {
    "c93cb6790e0f1c64efd03d859f907a0522010894": {
      "type": "Ymovefromfile",
      "commitMessage": "HDFS-14854. Create improved decommission monitor implementation. Contributed by Stephen O\u0027Donnell.\n\nReviewed-by: Inigo Goiri \u003cinigoiri@apache.org\u003e\nSigned-off-by: Wei-Chiu Chuang \u003cweichiu@apache.org\u003e\n",
      "commitDate": "10/12/19 5:16 PM",
      "commitName": "c93cb6790e0f1c64efd03d859f907a0522010894",
      "commitAuthor": "Stephen O\u0027Donnell",
      "commitDateOld": "10/12/19 6:51 AM",
      "commitNameOld": "875a3e97dd4a26fe224a1858c54d1b4512db6be3",
      "commitAuthorOld": "Gabor Bota",
      "daysBetweenCommits": 0.43,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,7 +1,7 @@\n-    private void processPendingNodes() {\n-      while (!pendingNodes.isEmpty() \u0026\u0026\n-          (maxConcurrentTrackedNodes \u003d\u003d 0 ||\n-          outOfServiceNodeBlocks.size() \u003c maxConcurrentTrackedNodes)) {\n-        outOfServiceNodeBlocks.put(pendingNodes.poll(), null);\n-      }\n-    }\n\\ No newline at end of file\n+  private void processPendingNodes() {\n+    while (!pendingNodes.isEmpty() \u0026\u0026\n+        (maxConcurrentTrackedNodes \u003d\u003d 0 ||\n+            outOfServiceNodeBlocks.size() \u003c maxConcurrentTrackedNodes)) {\n+      outOfServiceNodeBlocks.put(pendingNodes.poll(), null);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void processPendingNodes() {\n    while (!pendingNodes.isEmpty() \u0026\u0026\n        (maxConcurrentTrackedNodes \u003d\u003d 0 ||\n            outOfServiceNodeBlocks.size() \u003c maxConcurrentTrackedNodes)) {\n      outOfServiceNodeBlocks.put(pendingNodes.poll(), null);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminBackoffMonitor.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminManager.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminBackoffMonitor.java",
        "oldMethodName": "processPendingNodes",
        "newMethodName": "processPendingNodes"
      }
    },
    "79df1e750ef558afed6d166ce225a23061b36aed": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-9388. Decommission related code to support Maintenance State for datanodes.\n",
      "commitDate": "02/08/17 2:22 PM",
      "commitName": "79df1e750ef558afed6d166ce225a23061b36aed",
      "commitAuthor": "Manoj Govindassamy",
      "commitDateOld": "02/08/17 12:12 PM",
      "commitNameOld": "12e44e7bdaf53d3720a89d32f0cc2717241bd6b2",
      "commitAuthorOld": "Chris Douglas",
      "daysBetweenCommits": 0.09,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    private void processPendingNodes() {\n      while (!pendingNodes.isEmpty() \u0026\u0026\n          (maxConcurrentTrackedNodes \u003d\u003d 0 ||\n          outOfServiceNodeBlocks.size() \u003c maxConcurrentTrackedNodes)) {\n        outOfServiceNodeBlocks.put(pendingNodes.poll(), null);\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminManager.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DecommissionManager.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminManager.java"
      }
    },
    "9dcbdbdb5a34d85910707f81ebc1bb1f81c99978": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9392. Admins support for maintenance state. Contributed by Ming Ma.\n",
      "commitDate": "30/08/16 2:00 PM",
      "commitName": "9dcbdbdb5a34d85910707f81ebc1bb1f81c99978",
      "commitAuthor": "Ming Ma",
      "commitDateOld": "26/05/16 4:50 PM",
      "commitNameOld": "8c84a2a93c22a93b4ff46dd917f6efb995675fbd",
      "commitAuthorOld": "Zhe Zhang",
      "daysBetweenCommits": 95.88,
      "commitsBetweenForRepo": 766,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,7 +1,7 @@\n     private void processPendingNodes() {\n       while (!pendingNodes.isEmpty() \u0026\u0026\n           (maxConcurrentTrackedNodes \u003d\u003d 0 ||\n-           decomNodeBlocks.size() \u003c maxConcurrentTrackedNodes)) {\n-        decomNodeBlocks.put(pendingNodes.poll(), null);\n+          outOfServiceNodeBlocks.size() \u003c maxConcurrentTrackedNodes)) {\n+        outOfServiceNodeBlocks.put(pendingNodes.poll(), null);\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void processPendingNodes() {\n      while (!pendingNodes.isEmpty() \u0026\u0026\n          (maxConcurrentTrackedNodes \u003d\u003d 0 ||\n          outOfServiceNodeBlocks.size() \u003c maxConcurrentTrackedNodes)) {\n        outOfServiceNodeBlocks.put(pendingNodes.poll(), null);\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DecommissionManager.java",
      "extendedDetails": {}
    },
    "6ee0d32b98bc3aa5ed42859f1325d5a14fd1722a": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-7411. Change decommission logic to throttle by blocks rather\nthan nodes in each interval. Contributed by Andrew Wang\n",
      "commitDate": "08/03/15 6:31 PM",
      "commitName": "6ee0d32b98bc3aa5ed42859f1325d5a14fd1722a",
      "commitAuthor": "Chris Douglas",
      "diff": "@@ -0,0 +1,7 @@\n+    private void processPendingNodes() {\n+      while (!pendingNodes.isEmpty() \u0026\u0026\n+          (maxConcurrentTrackedNodes \u003d\u003d 0 ||\n+           decomNodeBlocks.size() \u003c maxConcurrentTrackedNodes)) {\n+        decomNodeBlocks.put(pendingNodes.poll(), null);\n+      }\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    private void processPendingNodes() {\n      while (!pendingNodes.isEmpty() \u0026\u0026\n          (maxConcurrentTrackedNodes \u003d\u003d 0 ||\n           decomNodeBlocks.size() \u003c maxConcurrentTrackedNodes)) {\n        decomNodeBlocks.put(pendingNodes.poll(), null);\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DecommissionManager.java"
    }
  }
}