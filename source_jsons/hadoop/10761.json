{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockPoolSliceStorage.java",
  "functionName": "restoreBlockFilesFromTrash",
  "functionId": "restoreBlockFilesFromTrash___trashRoot-File",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockPoolSliceStorage.java",
  "functionStartLine": 551,
  "functionEndLine": 590,
  "numCommitsSeen": 38,
  "timeTaken": 2618,
  "changeHistory": [
    "b3ae11d59790bb08b81848e9f944db7d3afbbd8a",
    "f949f6b54825dac61511a5761837e2fd14437239",
    "dbf14320c093991d2ca97b3608efe1c3c0af9888",
    "3f7852bd27de4f87e242ad4eb73932b739922a5b",
    "329c7051817c956bfc64661f4e1349b7009a2747",
    "5df82fa01d26c18685ad7617128dbc2913547cb3"
  ],
  "changeHistoryShort": {
    "b3ae11d59790bb08b81848e9f944db7d3afbbd8a": "Ybodychange",
    "f949f6b54825dac61511a5761837e2fd14437239": "Ybodychange",
    "dbf14320c093991d2ca97b3608efe1c3c0af9888": "Ybodychange",
    "3f7852bd27de4f87e242ad4eb73932b739922a5b": "Ybodychange",
    "329c7051817c956bfc64661f4e1349b7009a2747": "Ymultichange(Yexceptionschange,Ybodychange)",
    "5df82fa01d26c18685ad7617128dbc2913547cb3": "Yintroduced"
  },
  "changeHistoryDetails": {
    "b3ae11d59790bb08b81848e9f944db7d3afbbd8a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12997. Move logging to slf4j in BlockPoolSliceStorage and Storage. Contributed by Ajay Kumar.\n",
      "commitDate": "01/02/18 10:45 AM",
      "commitName": "b3ae11d59790bb08b81848e9f944db7d3afbbd8a",
      "commitAuthor": "Xiaoyu Yao",
      "commitDateOld": "15/12/17 5:51 PM",
      "commitNameOld": "8239e3afb31d3c4485817d4b8b8b195b554acbe7",
      "commitAuthorOld": "Virajith Jalaparti",
      "daysBetweenCommits": 47.7,
      "commitsBetweenForRepo": 240,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,40 +1,40 @@\n   private int restoreBlockFilesFromTrash(File trashRoot)\n       throws  IOException {\n     int filesRestored \u003d 0;\n     File[] children \u003d trashRoot.exists() ? trashRoot.listFiles() : null;\n     if (children \u003d\u003d null) {\n       return 0;\n     }\n \n     File restoreDirectory \u003d null;\n     for (File child : children) {\n       if (child.isDirectory()) {\n         // Recurse to process subdirectories.\n         filesRestored +\u003d restoreBlockFilesFromTrash(child);\n         continue;\n       }\n \n       if (restoreDirectory \u003d\u003d null) {\n         restoreDirectory \u003d new File(getRestoreDirectory(child));\n         if (!restoreDirectory.exists() \u0026\u0026 !restoreDirectory.mkdirs()) {\n           throw new IOException(\"Failed to create directory \" + restoreDirectory);\n         }\n       }\n \n       final File newChild \u003d new File(restoreDirectory, child.getName());\n \n       if (newChild.exists() \u0026\u0026 newChild.length() \u003e\u003d child.length()) {\n         // Failsafe - we should not hit this case but let\u0027s make sure\n         // we never overwrite a newer version of a block file with an\n         // older version.\n-        LOG.info(\"Not overwriting \" + newChild + \" with smaller file from \" +\n-                     \"trash directory. This message can be safely ignored.\");\n+        LOG.info(\"Not overwriting {} with smaller file from \" +\n+            \"trash directory. This message can be safely ignored.\", newChild);\n       } else if (!child.renameTo(newChild)) {\n         throw new IOException(\"Failed to rename \" + child + \" to \" + newChild);\n       } else {\n         ++filesRestored;\n       }\n     }\n     FileUtil.fullyDelete(trashRoot);\n     return filesRestored;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private int restoreBlockFilesFromTrash(File trashRoot)\n      throws  IOException {\n    int filesRestored \u003d 0;\n    File[] children \u003d trashRoot.exists() ? trashRoot.listFiles() : null;\n    if (children \u003d\u003d null) {\n      return 0;\n    }\n\n    File restoreDirectory \u003d null;\n    for (File child : children) {\n      if (child.isDirectory()) {\n        // Recurse to process subdirectories.\n        filesRestored +\u003d restoreBlockFilesFromTrash(child);\n        continue;\n      }\n\n      if (restoreDirectory \u003d\u003d null) {\n        restoreDirectory \u003d new File(getRestoreDirectory(child));\n        if (!restoreDirectory.exists() \u0026\u0026 !restoreDirectory.mkdirs()) {\n          throw new IOException(\"Failed to create directory \" + restoreDirectory);\n        }\n      }\n\n      final File newChild \u003d new File(restoreDirectory, child.getName());\n\n      if (newChild.exists() \u0026\u0026 newChild.length() \u003e\u003d child.length()) {\n        // Failsafe - we should not hit this case but let\u0027s make sure\n        // we never overwrite a newer version of a block file with an\n        // older version.\n        LOG.info(\"Not overwriting {} with smaller file from \" +\n            \"trash directory. This message can be safely ignored.\", newChild);\n      } else if (!child.renameTo(newChild)) {\n        throw new IOException(\"Failed to rename \" + child + \" to \" + newChild);\n      } else {\n        ++filesRestored;\n      }\n    }\n    FileUtil.fullyDelete(trashRoot);\n    return filesRestored;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockPoolSliceStorage.java",
      "extendedDetails": {}
    },
    "f949f6b54825dac61511a5761837e2fd14437239": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6981. Fix DN upgrade with layout version change. (Arpit Agarwal)\n",
      "commitDate": "08/09/14 9:20 PM",
      "commitName": "f949f6b54825dac61511a5761837e2fd14437239",
      "commitAuthor": "arp",
      "commitDateOld": "29/08/14 1:00 PM",
      "commitNameOld": "7eab2a29a5706ce10912c12fa225ef6b27a82cbe",
      "commitAuthorOld": "Aaron T. Myers",
      "daysBetweenCommits": 10.35,
      "commitsBetweenForRepo": 71,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,32 +1,40 @@\n   private int restoreBlockFilesFromTrash(File trashRoot)\n       throws  IOException {\n     int filesRestored \u003d 0;\n     File[] children \u003d trashRoot.exists() ? trashRoot.listFiles() : null;\n     if (children \u003d\u003d null) {\n       return 0;\n     }\n \n     File restoreDirectory \u003d null;\n     for (File child : children) {\n       if (child.isDirectory()) {\n         // Recurse to process subdirectories.\n         filesRestored +\u003d restoreBlockFilesFromTrash(child);\n         continue;\n       }\n \n       if (restoreDirectory \u003d\u003d null) {\n         restoreDirectory \u003d new File(getRestoreDirectory(child));\n         if (!restoreDirectory.exists() \u0026\u0026 !restoreDirectory.mkdirs()) {\n           throw new IOException(\"Failed to create directory \" + restoreDirectory);\n         }\n       }\n \n       final File newChild \u003d new File(restoreDirectory, child.getName());\n-      if (!child.renameTo(newChild)) {\n+\n+      if (newChild.exists() \u0026\u0026 newChild.length() \u003e\u003d child.length()) {\n+        // Failsafe - we should not hit this case but let\u0027s make sure\n+        // we never overwrite a newer version of a block file with an\n+        // older version.\n+        LOG.info(\"Not overwriting \" + newChild + \" with smaller file from \" +\n+                     \"trash directory. This message can be safely ignored.\");\n+      } else if (!child.renameTo(newChild)) {\n         throw new IOException(\"Failed to rename \" + child + \" to \" + newChild);\n+      } else {\n+        ++filesRestored;\n       }\n-      ++filesRestored;\n     }\n     FileUtil.fullyDelete(trashRoot);\n     return filesRestored;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private int restoreBlockFilesFromTrash(File trashRoot)\n      throws  IOException {\n    int filesRestored \u003d 0;\n    File[] children \u003d trashRoot.exists() ? trashRoot.listFiles() : null;\n    if (children \u003d\u003d null) {\n      return 0;\n    }\n\n    File restoreDirectory \u003d null;\n    for (File child : children) {\n      if (child.isDirectory()) {\n        // Recurse to process subdirectories.\n        filesRestored +\u003d restoreBlockFilesFromTrash(child);\n        continue;\n      }\n\n      if (restoreDirectory \u003d\u003d null) {\n        restoreDirectory \u003d new File(getRestoreDirectory(child));\n        if (!restoreDirectory.exists() \u0026\u0026 !restoreDirectory.mkdirs()) {\n          throw new IOException(\"Failed to create directory \" + restoreDirectory);\n        }\n      }\n\n      final File newChild \u003d new File(restoreDirectory, child.getName());\n\n      if (newChild.exists() \u0026\u0026 newChild.length() \u003e\u003d child.length()) {\n        // Failsafe - we should not hit this case but let\u0027s make sure\n        // we never overwrite a newer version of a block file with an\n        // older version.\n        LOG.info(\"Not overwriting \" + newChild + \" with smaller file from \" +\n                     \"trash directory. This message can be safely ignored.\");\n      } else if (!child.renameTo(newChild)) {\n        throw new IOException(\"Failed to rename \" + child + \" to \" + newChild);\n      } else {\n        ++filesRestored;\n      }\n    }\n    FileUtil.fullyDelete(trashRoot);\n    return filesRestored;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockPoolSliceStorage.java",
      "extendedDetails": {}
    },
    "dbf14320c093991d2ca97b3608efe1c3c0af9888": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6005. Simplify Datanode rollback and downgrade. (Contributed by Suresh Srinivas)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535@1571431 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/02/14 12:46 PM",
      "commitName": "dbf14320c093991d2ca97b3608efe1c3c0af9888",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "21/02/14 2:40 PM",
      "commitNameOld": "3f7852bd27de4f87e242ad4eb73932b739922a5b",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 2.92,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,27 +1,32 @@\n-  private int restoreBlockFilesFromTrash(File trashRoot) throws IOException {\n+  private int restoreBlockFilesFromTrash(File trashRoot)\n+      throws  IOException {\n     int filesRestored \u003d 0;\n-    File restoreDirectory \u003d null;\n+    File[] children \u003d trashRoot.exists() ? trashRoot.listFiles() : null;\n+    if (children \u003d\u003d null) {\n+      return 0;\n+    }\n \n-    for (File child : trashRoot.listFiles()) {\n+    File restoreDirectory \u003d null;\n+    for (File child : children) {\n       if (child.isDirectory()) {\n         // Recurse to process subdirectories.\n         filesRestored +\u003d restoreBlockFilesFromTrash(child);\n         continue;\n       }\n \n       if (restoreDirectory \u003d\u003d null) {\n         restoreDirectory \u003d new File(getRestoreDirectory(child));\n         if (!restoreDirectory.exists() \u0026\u0026 !restoreDirectory.mkdirs()) {\n           throw new IOException(\"Failed to create directory \" + restoreDirectory);\n         }\n       }\n \n       final File newChild \u003d new File(restoreDirectory, child.getName());\n       if (!child.renameTo(newChild)) {\n         throw new IOException(\"Failed to rename \" + child + \" to \" + newChild);\n       }\n       ++filesRestored;\n     }\n-\n+    FileUtil.fullyDelete(trashRoot);\n     return filesRestored;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private int restoreBlockFilesFromTrash(File trashRoot)\n      throws  IOException {\n    int filesRestored \u003d 0;\n    File[] children \u003d trashRoot.exists() ? trashRoot.listFiles() : null;\n    if (children \u003d\u003d null) {\n      return 0;\n    }\n\n    File restoreDirectory \u003d null;\n    for (File child : children) {\n      if (child.isDirectory()) {\n        // Recurse to process subdirectories.\n        filesRestored +\u003d restoreBlockFilesFromTrash(child);\n        continue;\n      }\n\n      if (restoreDirectory \u003d\u003d null) {\n        restoreDirectory \u003d new File(getRestoreDirectory(child));\n        if (!restoreDirectory.exists() \u0026\u0026 !restoreDirectory.mkdirs()) {\n          throw new IOException(\"Failed to create directory \" + restoreDirectory);\n        }\n      }\n\n      final File newChild \u003d new File(restoreDirectory, child.getName());\n      if (!child.renameTo(newChild)) {\n        throw new IOException(\"Failed to rename \" + child + \" to \" + newChild);\n      }\n      ++filesRestored;\n    }\n    FileUtil.fullyDelete(trashRoot);\n    return filesRestored;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockPoolSliceStorage.java",
      "extendedDetails": {}
    },
    "3f7852bd27de4f87e242ad4eb73932b739922a5b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5994. Fix TestDataNodeRollingUpgrade.  Contributed by Arpit Agarwal\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535@1570734 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/02/14 2:40 PM",
      "commitName": "3f7852bd27de4f87e242ad4eb73932b739922a5b",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "20/02/14 3:21 PM",
      "commitNameOld": "329c7051817c956bfc64661f4e1349b7009a2747",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 0.97,
      "commitsBetweenForRepo": 14,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,26 +1,27 @@\n   private int restoreBlockFilesFromTrash(File trashRoot) throws IOException {\n     int filesRestored \u003d 0;\n     File restoreDirectory \u003d null;\n \n     for (File child : trashRoot.listFiles()) {\n       if (child.isDirectory()) {\n         // Recurse to process subdirectories.\n         filesRestored +\u003d restoreBlockFilesFromTrash(child);\n+        continue;\n       }\n \n       if (restoreDirectory \u003d\u003d null) {\n         restoreDirectory \u003d new File(getRestoreDirectory(child));\n-        if (!restoreDirectory.mkdirs()) {\n+        if (!restoreDirectory.exists() \u0026\u0026 !restoreDirectory.mkdirs()) {\n           throw new IOException(\"Failed to create directory \" + restoreDirectory);\n         }\n       }\n \n       final File newChild \u003d new File(restoreDirectory, child.getName());\n       if (!child.renameTo(newChild)) {\n         throw new IOException(\"Failed to rename \" + child + \" to \" + newChild);\n       }\n       ++filesRestored;\n     }\n \n     return filesRestored;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private int restoreBlockFilesFromTrash(File trashRoot) throws IOException {\n    int filesRestored \u003d 0;\n    File restoreDirectory \u003d null;\n\n    for (File child : trashRoot.listFiles()) {\n      if (child.isDirectory()) {\n        // Recurse to process subdirectories.\n        filesRestored +\u003d restoreBlockFilesFromTrash(child);\n        continue;\n      }\n\n      if (restoreDirectory \u003d\u003d null) {\n        restoreDirectory \u003d new File(getRestoreDirectory(child));\n        if (!restoreDirectory.exists() \u0026\u0026 !restoreDirectory.mkdirs()) {\n          throw new IOException(\"Failed to create directory \" + restoreDirectory);\n        }\n      }\n\n      final File newChild \u003d new File(restoreDirectory, child.getName());\n      if (!child.renameTo(newChild)) {\n        throw new IOException(\"Failed to rename \" + child + \" to \" + newChild);\n      }\n      ++filesRestored;\n    }\n\n    return filesRestored;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockPoolSliceStorage.java",
      "extendedDetails": {}
    },
    "329c7051817c956bfc64661f4e1349b7009a2747": {
      "type": "Ymultichange(Yexceptionschange,Ybodychange)",
      "commitMessage": "HDFS-5987. Fix findbugs warnings in Rolling Upgrade branch. (Contributed by szetszwo)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535@1570389 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/02/14 3:21 PM",
      "commitName": "329c7051817c956bfc64661f4e1349b7009a2747",
      "commitAuthor": "Arpit Agarwal",
      "subchanges": [
        {
          "type": "Yexceptionschange",
          "commitMessage": "HDFS-5987. Fix findbugs warnings in Rolling Upgrade branch. (Contributed by szetszwo)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535@1570389 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "20/02/14 3:21 PM",
          "commitName": "329c7051817c956bfc64661f4e1349b7009a2747",
          "commitAuthor": "Arpit Agarwal",
          "commitDateOld": "19/02/14 11:41 AM",
          "commitNameOld": "377424e36a25ab34bba9aaed5feaae9d293eb57f",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 1.15,
          "commitsBetweenForRepo": 17,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,21 +1,26 @@\n-  private int restoreBlockFilesFromTrash(File trashRoot) {\n+  private int restoreBlockFilesFromTrash(File trashRoot) throws IOException {\n     int filesRestored \u003d 0;\n     File restoreDirectory \u003d null;\n \n     for (File child : trashRoot.listFiles()) {\n       if (child.isDirectory()) {\n         // Recurse to process subdirectories.\n         filesRestored +\u003d restoreBlockFilesFromTrash(child);\n       }\n \n       if (restoreDirectory \u003d\u003d null) {\n         restoreDirectory \u003d new File(getRestoreDirectory(child));\n-        restoreDirectory.mkdirs();\n+        if (!restoreDirectory.mkdirs()) {\n+          throw new IOException(\"Failed to create directory \" + restoreDirectory);\n+        }\n       }\n \n-      child.renameTo(new File(restoreDirectory, child.getName()));\n+      final File newChild \u003d new File(restoreDirectory, child.getName());\n+      if (!child.renameTo(newChild)) {\n+        throw new IOException(\"Failed to rename \" + child + \" to \" + newChild);\n+      }\n       ++filesRestored;\n     }\n \n     return filesRestored;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private int restoreBlockFilesFromTrash(File trashRoot) throws IOException {\n    int filesRestored \u003d 0;\n    File restoreDirectory \u003d null;\n\n    for (File child : trashRoot.listFiles()) {\n      if (child.isDirectory()) {\n        // Recurse to process subdirectories.\n        filesRestored +\u003d restoreBlockFilesFromTrash(child);\n      }\n\n      if (restoreDirectory \u003d\u003d null) {\n        restoreDirectory \u003d new File(getRestoreDirectory(child));\n        if (!restoreDirectory.mkdirs()) {\n          throw new IOException(\"Failed to create directory \" + restoreDirectory);\n        }\n      }\n\n      final File newChild \u003d new File(restoreDirectory, child.getName());\n      if (!child.renameTo(newChild)) {\n        throw new IOException(\"Failed to rename \" + child + \" to \" + newChild);\n      }\n      ++filesRestored;\n    }\n\n    return filesRestored;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockPoolSliceStorage.java",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[IOException]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5987. Fix findbugs warnings in Rolling Upgrade branch. (Contributed by szetszwo)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535@1570389 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "20/02/14 3:21 PM",
          "commitName": "329c7051817c956bfc64661f4e1349b7009a2747",
          "commitAuthor": "Arpit Agarwal",
          "commitDateOld": "19/02/14 11:41 AM",
          "commitNameOld": "377424e36a25ab34bba9aaed5feaae9d293eb57f",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 1.15,
          "commitsBetweenForRepo": 17,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,21 +1,26 @@\n-  private int restoreBlockFilesFromTrash(File trashRoot) {\n+  private int restoreBlockFilesFromTrash(File trashRoot) throws IOException {\n     int filesRestored \u003d 0;\n     File restoreDirectory \u003d null;\n \n     for (File child : trashRoot.listFiles()) {\n       if (child.isDirectory()) {\n         // Recurse to process subdirectories.\n         filesRestored +\u003d restoreBlockFilesFromTrash(child);\n       }\n \n       if (restoreDirectory \u003d\u003d null) {\n         restoreDirectory \u003d new File(getRestoreDirectory(child));\n-        restoreDirectory.mkdirs();\n+        if (!restoreDirectory.mkdirs()) {\n+          throw new IOException(\"Failed to create directory \" + restoreDirectory);\n+        }\n       }\n \n-      child.renameTo(new File(restoreDirectory, child.getName()));\n+      final File newChild \u003d new File(restoreDirectory, child.getName());\n+      if (!child.renameTo(newChild)) {\n+        throw new IOException(\"Failed to rename \" + child + \" to \" + newChild);\n+      }\n       ++filesRestored;\n     }\n \n     return filesRestored;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private int restoreBlockFilesFromTrash(File trashRoot) throws IOException {\n    int filesRestored \u003d 0;\n    File restoreDirectory \u003d null;\n\n    for (File child : trashRoot.listFiles()) {\n      if (child.isDirectory()) {\n        // Recurse to process subdirectories.\n        filesRestored +\u003d restoreBlockFilesFromTrash(child);\n      }\n\n      if (restoreDirectory \u003d\u003d null) {\n        restoreDirectory \u003d new File(getRestoreDirectory(child));\n        if (!restoreDirectory.mkdirs()) {\n          throw new IOException(\"Failed to create directory \" + restoreDirectory);\n        }\n      }\n\n      final File newChild \u003d new File(restoreDirectory, child.getName());\n      if (!child.renameTo(newChild)) {\n        throw new IOException(\"Failed to rename \" + child + \" to \" + newChild);\n      }\n      ++filesRestored;\n    }\n\n    return filesRestored;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockPoolSliceStorage.java",
          "extendedDetails": {}
        }
      ]
    },
    "5df82fa01d26c18685ad7617128dbc2913547cb3": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-5907. BlockPoolSliceStorage trash to handle block deletions during rolling upgrade. (Arpit Agarwal)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535@1568346 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/02/14 8:37 AM",
      "commitName": "5df82fa01d26c18685ad7617128dbc2913547cb3",
      "commitAuthor": "Arpit Agarwal",
      "diff": "@@ -0,0 +1,21 @@\n+  private int restoreBlockFilesFromTrash(File trashRoot) {\n+    int filesRestored \u003d 0;\n+    File restoreDirectory \u003d null;\n+\n+    for (File child : trashRoot.listFiles()) {\n+      if (child.isDirectory()) {\n+        // Recurse to process subdirectories.\n+        filesRestored +\u003d restoreBlockFilesFromTrash(child);\n+      }\n+\n+      if (restoreDirectory \u003d\u003d null) {\n+        restoreDirectory \u003d new File(getRestoreDirectory(child));\n+        restoreDirectory.mkdirs();\n+      }\n+\n+      child.renameTo(new File(restoreDirectory, child.getName()));\n+      ++filesRestored;\n+    }\n+\n+    return filesRestored;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private int restoreBlockFilesFromTrash(File trashRoot) {\n    int filesRestored \u003d 0;\n    File restoreDirectory \u003d null;\n\n    for (File child : trashRoot.listFiles()) {\n      if (child.isDirectory()) {\n        // Recurse to process subdirectories.\n        filesRestored +\u003d restoreBlockFilesFromTrash(child);\n      }\n\n      if (restoreDirectory \u003d\u003d null) {\n        restoreDirectory \u003d new File(getRestoreDirectory(child));\n        restoreDirectory.mkdirs();\n      }\n\n      child.renameTo(new File(restoreDirectory, child.getName()));\n      ++filesRestored;\n    }\n\n    return filesRestored;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockPoolSliceStorage.java"
    }
  }
}