{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "SecondaryNameNode.java",
  "functionName": "processStartupCommand",
  "functionId": "processStartupCommand___opts-CommandLineOpts",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
  "functionStartLine": 604,
  "functionEndLine": 657,
  "numCommitsSeen": 104,
  "timeTaken": 6490,
  "changeHistory": [
    "d1c6accb6f87b08975175580e15f1ff1fe29ab04",
    "9cedad11d8d2197a54732667a15344983de5c437",
    "946456c6d88780abe0251b098dd771e9e1e93ab3",
    "cdae6953e80e81693bb4c9eb38b62eaba3ac8cf9",
    "5b8dcb20a2fad2e7e9dee56c451f68f9d865b5ae",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "28e6a4e44a3e920dcaf858f9a74a6358226b3a63",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "d1c6accb6f87b08975175580e15f1ff1fe29ab04": "Ybodychange",
    "9cedad11d8d2197a54732667a15344983de5c437": "Ybodychange",
    "946456c6d88780abe0251b098dd771e9e1e93ab3": "Ybodychange",
    "cdae6953e80e81693bb4c9eb38b62eaba3ac8cf9": "Ybodychange",
    "5b8dcb20a2fad2e7e9dee56c451f68f9d865b5ae": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "28e6a4e44a3e920dcaf858f9a74a6358226b3a63": "Ymultichange(Yrename,Yparameterchange,Ybodychange)",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "d1c6accb6f87b08975175580e15f1ff1fe29ab04": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-11602. Fix toUpperCase/toLowerCase to use Locale.ENGLISH. (ozawa)\n",
      "commitDate": "02/03/15 9:17 PM",
      "commitName": "d1c6accb6f87b08975175580e15f1ff1fe29ab04",
      "commitAuthor": "Tsuyoshi Ozawa",
      "commitDateOld": "24/02/15 7:32 AM",
      "commitNameOld": "9cedad11d8d2197a54732667a15344983de5c437",
      "commitAuthorOld": "Tsuyoshi Ozawa",
      "daysBetweenCommits": 6.57,
      "commitsBetweenForRepo": 57,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,54 +1,54 @@\n   private int processStartupCommand(CommandLineOpts opts) throws Exception {\n     if (opts.getCommand() \u003d\u003d null) {\n       return 0;\n     }\n     \n-    String cmd \u003d opts.getCommand().toString().toLowerCase();\n+    String cmd \u003d StringUtils.toLowerCase(opts.getCommand().toString());\n     \n     int exitCode \u003d 0;\n     try {\n       switch (opts.getCommand()) {\n       case CHECKPOINT:\n         long count \u003d countUncheckpointedTxns();\n         if (count \u003e checkpointConf.getTxnCount() ||\n             opts.shouldForceCheckpoint()) {\n           doCheckpoint();\n         } else {\n           System.err.println(\"EditLog size \" + count + \" transactions is \" +\n                              \"smaller than configured checkpoint \" +\n                              \"interval \" + checkpointConf.getTxnCount() + \" transactions.\");\n           System.err.println(\"Skipping checkpoint.\");\n         }\n         break;\n       case GETEDITSIZE:\n         long uncheckpointed \u003d countUncheckpointedTxns();\n         System.out.println(\"NameNode has \" + uncheckpointed +\n             \" uncheckpointed transactions\");\n         break;\n       default:\n         throw new AssertionError(\"bad command enum: \" + opts.getCommand());\n       }\n       \n     } catch (RemoteException e) {\n       //\n       // This is a error returned by hadoop server. Print\n       // out the first line of the error mesage, ignore the stack trace.\n       exitCode \u003d 1;\n       try {\n         String[] content;\n         content \u003d e.getLocalizedMessage().split(\"\\n\");\n         LOG.error(cmd + \": \" + content[0]);\n       } catch (Exception ex) {\n         LOG.error(cmd + \": \" + ex.getLocalizedMessage());\n       }\n     } catch (IOException e) {\n       //\n       // IO exception encountered locally.\n       //\n       exitCode \u003d 1;\n       LOG.error(cmd + \": \" + e.getLocalizedMessage());\n     } finally {\n       // Does the RPC connection need to be closed?\n     }\n     return exitCode;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private int processStartupCommand(CommandLineOpts opts) throws Exception {\n    if (opts.getCommand() \u003d\u003d null) {\n      return 0;\n    }\n    \n    String cmd \u003d StringUtils.toLowerCase(opts.getCommand().toString());\n    \n    int exitCode \u003d 0;\n    try {\n      switch (opts.getCommand()) {\n      case CHECKPOINT:\n        long count \u003d countUncheckpointedTxns();\n        if (count \u003e checkpointConf.getTxnCount() ||\n            opts.shouldForceCheckpoint()) {\n          doCheckpoint();\n        } else {\n          System.err.println(\"EditLog size \" + count + \" transactions is \" +\n                             \"smaller than configured checkpoint \" +\n                             \"interval \" + checkpointConf.getTxnCount() + \" transactions.\");\n          System.err.println(\"Skipping checkpoint.\");\n        }\n        break;\n      case GETEDITSIZE:\n        long uncheckpointed \u003d countUncheckpointedTxns();\n        System.out.println(\"NameNode has \" + uncheckpointed +\n            \" uncheckpointed transactions\");\n        break;\n      default:\n        throw new AssertionError(\"bad command enum: \" + opts.getCommand());\n      }\n      \n    } catch (RemoteException e) {\n      //\n      // This is a error returned by hadoop server. Print\n      // out the first line of the error mesage, ignore the stack trace.\n      exitCode \u003d 1;\n      try {\n        String[] content;\n        content \u003d e.getLocalizedMessage().split(\"\\n\");\n        LOG.error(cmd + \": \" + content[0]);\n      } catch (Exception ex) {\n        LOG.error(cmd + \": \" + ex.getLocalizedMessage());\n      }\n    } catch (IOException e) {\n      //\n      // IO exception encountered locally.\n      //\n      exitCode \u003d 1;\n      LOG.error(cmd + \": \" + e.getLocalizedMessage());\n    } finally {\n      // Does the RPC connection need to be closed?\n    }\n    return exitCode;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
      "extendedDetails": {}
    },
    "9cedad11d8d2197a54732667a15344983de5c437": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HADOOP-11602. Fix toUpperCase/toLowerCase to use Locale.ENGLISH. (ozawa)\"\n\nThis reverts commit 946456c6d88780abe0251b098dd771e9e1e93ab3.\n\nConflicts:\n\thadoop-common-project/hadoop-common/CHANGES.txt\n\thadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/QuotaByStorageTypeEntry.java\n",
      "commitDate": "24/02/15 7:32 AM",
      "commitName": "9cedad11d8d2197a54732667a15344983de5c437",
      "commitAuthor": "Tsuyoshi Ozawa",
      "commitDateOld": "18/02/15 8:06 PM",
      "commitNameOld": "946456c6d88780abe0251b098dd771e9e1e93ab3",
      "commitAuthorOld": "Tsuyoshi Ozawa",
      "daysBetweenCommits": 5.48,
      "commitsBetweenForRepo": 31,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,54 +1,54 @@\n   private int processStartupCommand(CommandLineOpts opts) throws Exception {\n     if (opts.getCommand() \u003d\u003d null) {\n       return 0;\n     }\n     \n-    String cmd \u003d opts.getCommand().toString().toLowerCase(Locale.ENGLISH);\n+    String cmd \u003d opts.getCommand().toString().toLowerCase();\n     \n     int exitCode \u003d 0;\n     try {\n       switch (opts.getCommand()) {\n       case CHECKPOINT:\n         long count \u003d countUncheckpointedTxns();\n         if (count \u003e checkpointConf.getTxnCount() ||\n             opts.shouldForceCheckpoint()) {\n           doCheckpoint();\n         } else {\n           System.err.println(\"EditLog size \" + count + \" transactions is \" +\n                              \"smaller than configured checkpoint \" +\n                              \"interval \" + checkpointConf.getTxnCount() + \" transactions.\");\n           System.err.println(\"Skipping checkpoint.\");\n         }\n         break;\n       case GETEDITSIZE:\n         long uncheckpointed \u003d countUncheckpointedTxns();\n         System.out.println(\"NameNode has \" + uncheckpointed +\n             \" uncheckpointed transactions\");\n         break;\n       default:\n         throw new AssertionError(\"bad command enum: \" + opts.getCommand());\n       }\n       \n     } catch (RemoteException e) {\n       //\n       // This is a error returned by hadoop server. Print\n       // out the first line of the error mesage, ignore the stack trace.\n       exitCode \u003d 1;\n       try {\n         String[] content;\n         content \u003d e.getLocalizedMessage().split(\"\\n\");\n         LOG.error(cmd + \": \" + content[0]);\n       } catch (Exception ex) {\n         LOG.error(cmd + \": \" + ex.getLocalizedMessage());\n       }\n     } catch (IOException e) {\n       //\n       // IO exception encountered locally.\n       //\n       exitCode \u003d 1;\n       LOG.error(cmd + \": \" + e.getLocalizedMessage());\n     } finally {\n       // Does the RPC connection need to be closed?\n     }\n     return exitCode;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private int processStartupCommand(CommandLineOpts opts) throws Exception {\n    if (opts.getCommand() \u003d\u003d null) {\n      return 0;\n    }\n    \n    String cmd \u003d opts.getCommand().toString().toLowerCase();\n    \n    int exitCode \u003d 0;\n    try {\n      switch (opts.getCommand()) {\n      case CHECKPOINT:\n        long count \u003d countUncheckpointedTxns();\n        if (count \u003e checkpointConf.getTxnCount() ||\n            opts.shouldForceCheckpoint()) {\n          doCheckpoint();\n        } else {\n          System.err.println(\"EditLog size \" + count + \" transactions is \" +\n                             \"smaller than configured checkpoint \" +\n                             \"interval \" + checkpointConf.getTxnCount() + \" transactions.\");\n          System.err.println(\"Skipping checkpoint.\");\n        }\n        break;\n      case GETEDITSIZE:\n        long uncheckpointed \u003d countUncheckpointedTxns();\n        System.out.println(\"NameNode has \" + uncheckpointed +\n            \" uncheckpointed transactions\");\n        break;\n      default:\n        throw new AssertionError(\"bad command enum: \" + opts.getCommand());\n      }\n      \n    } catch (RemoteException e) {\n      //\n      // This is a error returned by hadoop server. Print\n      // out the first line of the error mesage, ignore the stack trace.\n      exitCode \u003d 1;\n      try {\n        String[] content;\n        content \u003d e.getLocalizedMessage().split(\"\\n\");\n        LOG.error(cmd + \": \" + content[0]);\n      } catch (Exception ex) {\n        LOG.error(cmd + \": \" + ex.getLocalizedMessage());\n      }\n    } catch (IOException e) {\n      //\n      // IO exception encountered locally.\n      //\n      exitCode \u003d 1;\n      LOG.error(cmd + \": \" + e.getLocalizedMessage());\n    } finally {\n      // Does the RPC connection need to be closed?\n    }\n    return exitCode;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
      "extendedDetails": {}
    },
    "946456c6d88780abe0251b098dd771e9e1e93ab3": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-11602. Fix toUpperCase/toLowerCase to use Locale.ENGLISH. (ozawa)\n",
      "commitDate": "18/02/15 8:06 PM",
      "commitName": "946456c6d88780abe0251b098dd771e9e1e93ab3",
      "commitAuthor": "Tsuyoshi Ozawa",
      "commitDateOld": "12/02/15 5:40 PM",
      "commitNameOld": "46b6d23e8fbed4c2ba537dd752116c173805bca7",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 6.1,
      "commitsBetweenForRepo": 61,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,54 +1,54 @@\n   private int processStartupCommand(CommandLineOpts opts) throws Exception {\n     if (opts.getCommand() \u003d\u003d null) {\n       return 0;\n     }\n     \n-    String cmd \u003d opts.getCommand().toString().toLowerCase();\n+    String cmd \u003d opts.getCommand().toString().toLowerCase(Locale.ENGLISH);\n     \n     int exitCode \u003d 0;\n     try {\n       switch (opts.getCommand()) {\n       case CHECKPOINT:\n         long count \u003d countUncheckpointedTxns();\n         if (count \u003e checkpointConf.getTxnCount() ||\n             opts.shouldForceCheckpoint()) {\n           doCheckpoint();\n         } else {\n           System.err.println(\"EditLog size \" + count + \" transactions is \" +\n                              \"smaller than configured checkpoint \" +\n                              \"interval \" + checkpointConf.getTxnCount() + \" transactions.\");\n           System.err.println(\"Skipping checkpoint.\");\n         }\n         break;\n       case GETEDITSIZE:\n         long uncheckpointed \u003d countUncheckpointedTxns();\n         System.out.println(\"NameNode has \" + uncheckpointed +\n             \" uncheckpointed transactions\");\n         break;\n       default:\n         throw new AssertionError(\"bad command enum: \" + opts.getCommand());\n       }\n       \n     } catch (RemoteException e) {\n       //\n       // This is a error returned by hadoop server. Print\n       // out the first line of the error mesage, ignore the stack trace.\n       exitCode \u003d 1;\n       try {\n         String[] content;\n         content \u003d e.getLocalizedMessage().split(\"\\n\");\n         LOG.error(cmd + \": \" + content[0]);\n       } catch (Exception ex) {\n         LOG.error(cmd + \": \" + ex.getLocalizedMessage());\n       }\n     } catch (IOException e) {\n       //\n       // IO exception encountered locally.\n       //\n       exitCode \u003d 1;\n       LOG.error(cmd + \": \" + e.getLocalizedMessage());\n     } finally {\n       // Does the RPC connection need to be closed?\n     }\n     return exitCode;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private int processStartupCommand(CommandLineOpts opts) throws Exception {\n    if (opts.getCommand() \u003d\u003d null) {\n      return 0;\n    }\n    \n    String cmd \u003d opts.getCommand().toString().toLowerCase(Locale.ENGLISH);\n    \n    int exitCode \u003d 0;\n    try {\n      switch (opts.getCommand()) {\n      case CHECKPOINT:\n        long count \u003d countUncheckpointedTxns();\n        if (count \u003e checkpointConf.getTxnCount() ||\n            opts.shouldForceCheckpoint()) {\n          doCheckpoint();\n        } else {\n          System.err.println(\"EditLog size \" + count + \" transactions is \" +\n                             \"smaller than configured checkpoint \" +\n                             \"interval \" + checkpointConf.getTxnCount() + \" transactions.\");\n          System.err.println(\"Skipping checkpoint.\");\n        }\n        break;\n      case GETEDITSIZE:\n        long uncheckpointed \u003d countUncheckpointedTxns();\n        System.out.println(\"NameNode has \" + uncheckpointed +\n            \" uncheckpointed transactions\");\n        break;\n      default:\n        throw new AssertionError(\"bad command enum: \" + opts.getCommand());\n      }\n      \n    } catch (RemoteException e) {\n      //\n      // This is a error returned by hadoop server. Print\n      // out the first line of the error mesage, ignore the stack trace.\n      exitCode \u003d 1;\n      try {\n        String[] content;\n        content \u003d e.getLocalizedMessage().split(\"\\n\");\n        LOG.error(cmd + \": \" + content[0]);\n      } catch (Exception ex) {\n        LOG.error(cmd + \": \" + ex.getLocalizedMessage());\n      }\n    } catch (IOException e) {\n      //\n      // IO exception encountered locally.\n      //\n      exitCode \u003d 1;\n      LOG.error(cmd + \": \" + e.getLocalizedMessage());\n    } finally {\n      // Does the RPC connection need to be closed?\n    }\n    return exitCode;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
      "extendedDetails": {}
    },
    "cdae6953e80e81693bb4c9eb38b62eaba3ac8cf9": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3582. Hook daemon process exit for testing. Contributed by Eli Collins\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1360329 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/07/12 10:58 AM",
      "commitName": "cdae6953e80e81693bb4c9eb38b62eaba3ac8cf9",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "27/06/12 3:41 PM",
      "commitNameOld": "5770a453f304d83463879db6101da1f1e81e5563",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 13.8,
      "commitsBetweenForRepo": 86,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,54 +1,54 @@\n   private int processStartupCommand(CommandLineOpts opts) throws Exception {\n     if (opts.getCommand() \u003d\u003d null) {\n       return 0;\n     }\n     \n     String cmd \u003d opts.getCommand().toString().toLowerCase();\n     \n     int exitCode \u003d 0;\n     try {\n       switch (opts.getCommand()) {\n       case CHECKPOINT:\n         long count \u003d countUncheckpointedTxns();\n         if (count \u003e checkpointConf.getTxnCount() ||\n             opts.shouldForceCheckpoint()) {\n           doCheckpoint();\n         } else {\n           System.err.println(\"EditLog size \" + count + \" transactions is \" +\n                              \"smaller than configured checkpoint \" +\n                              \"interval \" + checkpointConf.getTxnCount() + \" transactions.\");\n           System.err.println(\"Skipping checkpoint.\");\n         }\n         break;\n       case GETEDITSIZE:\n         long uncheckpointed \u003d countUncheckpointedTxns();\n         System.out.println(\"NameNode has \" + uncheckpointed +\n             \" uncheckpointed transactions\");\n         break;\n       default:\n         throw new AssertionError(\"bad command enum: \" + opts.getCommand());\n       }\n       \n     } catch (RemoteException e) {\n       //\n       // This is a error returned by hadoop server. Print\n       // out the first line of the error mesage, ignore the stack trace.\n-      exitCode \u003d -1;\n+      exitCode \u003d 1;\n       try {\n         String[] content;\n         content \u003d e.getLocalizedMessage().split(\"\\n\");\n         LOG.error(cmd + \": \" + content[0]);\n       } catch (Exception ex) {\n         LOG.error(cmd + \": \" + ex.getLocalizedMessage());\n       }\n     } catch (IOException e) {\n       //\n       // IO exception encountered locally.\n       //\n-      exitCode \u003d -1;\n+      exitCode \u003d 1;\n       LOG.error(cmd + \": \" + e.getLocalizedMessage());\n     } finally {\n       // Does the RPC connection need to be closed?\n     }\n     return exitCode;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private int processStartupCommand(CommandLineOpts opts) throws Exception {\n    if (opts.getCommand() \u003d\u003d null) {\n      return 0;\n    }\n    \n    String cmd \u003d opts.getCommand().toString().toLowerCase();\n    \n    int exitCode \u003d 0;\n    try {\n      switch (opts.getCommand()) {\n      case CHECKPOINT:\n        long count \u003d countUncheckpointedTxns();\n        if (count \u003e checkpointConf.getTxnCount() ||\n            opts.shouldForceCheckpoint()) {\n          doCheckpoint();\n        } else {\n          System.err.println(\"EditLog size \" + count + \" transactions is \" +\n                             \"smaller than configured checkpoint \" +\n                             \"interval \" + checkpointConf.getTxnCount() + \" transactions.\");\n          System.err.println(\"Skipping checkpoint.\");\n        }\n        break;\n      case GETEDITSIZE:\n        long uncheckpointed \u003d countUncheckpointedTxns();\n        System.out.println(\"NameNode has \" + uncheckpointed +\n            \" uncheckpointed transactions\");\n        break;\n      default:\n        throw new AssertionError(\"bad command enum: \" + opts.getCommand());\n      }\n      \n    } catch (RemoteException e) {\n      //\n      // This is a error returned by hadoop server. Print\n      // out the first line of the error mesage, ignore the stack trace.\n      exitCode \u003d 1;\n      try {\n        String[] content;\n        content \u003d e.getLocalizedMessage().split(\"\\n\");\n        LOG.error(cmd + \": \" + content[0]);\n      } catch (Exception ex) {\n        LOG.error(cmd + \": \" + ex.getLocalizedMessage());\n      }\n    } catch (IOException e) {\n      //\n      // IO exception encountered locally.\n      //\n      exitCode \u003d 1;\n      LOG.error(cmd + \": \" + e.getLocalizedMessage());\n    } finally {\n      // Does the RPC connection need to be closed?\n    }\n    return exitCode;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
      "extendedDetails": {}
    },
    "5b8dcb20a2fad2e7e9dee56c451f68f9d865b5ae": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2291. Allow the StandbyNode to make checkpoints in an HA setup. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1227411 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/01/12 4:22 PM",
      "commitName": "5b8dcb20a2fad2e7e9dee56c451f68f9d865b5ae",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "30/12/11 5:53 PM",
      "commitNameOld": "737df8b67b972155b12ed615e23f3f1e8e4e9ca9",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 4.94,
      "commitsBetweenForRepo": 14,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,54 +1,54 @@\n   private int processStartupCommand(CommandLineOpts opts) throws Exception {\n     if (opts.getCommand() \u003d\u003d null) {\n       return 0;\n     }\n     \n     String cmd \u003d opts.getCommand().toString().toLowerCase();\n     \n     int exitCode \u003d 0;\n     try {\n       switch (opts.getCommand()) {\n       case CHECKPOINT:\n         long count \u003d countUncheckpointedTxns();\n-        if (count \u003e checkpointTxnCount ||\n+        if (count \u003e checkpointConf.getTxnCount() ||\n             opts.shouldForceCheckpoint()) {\n           doCheckpoint();\n         } else {\n           System.err.println(\"EditLog size \" + count + \" transactions is \" +\n                              \"smaller than configured checkpoint \" +\n-                             \"interval \" + checkpointTxnCount + \" transactions.\");\n+                             \"interval \" + checkpointConf.getTxnCount() + \" transactions.\");\n           System.err.println(\"Skipping checkpoint.\");\n         }\n         break;\n       case GETEDITSIZE:\n         long uncheckpointed \u003d countUncheckpointedTxns();\n         System.out.println(\"NameNode has \" + uncheckpointed +\n             \" uncheckpointed transactions\");\n         break;\n       default:\n         throw new AssertionError(\"bad command enum: \" + opts.getCommand());\n       }\n       \n     } catch (RemoteException e) {\n       //\n       // This is a error returned by hadoop server. Print\n       // out the first line of the error mesage, ignore the stack trace.\n       exitCode \u003d -1;\n       try {\n         String[] content;\n         content \u003d e.getLocalizedMessage().split(\"\\n\");\n         LOG.error(cmd + \": \" + content[0]);\n       } catch (Exception ex) {\n         LOG.error(cmd + \": \" + ex.getLocalizedMessage());\n       }\n     } catch (IOException e) {\n       //\n       // IO exception encountered locally.\n       //\n       exitCode \u003d -1;\n       LOG.error(cmd + \": \" + e.getLocalizedMessage());\n     } finally {\n       // Does the RPC connection need to be closed?\n     }\n     return exitCode;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private int processStartupCommand(CommandLineOpts opts) throws Exception {\n    if (opts.getCommand() \u003d\u003d null) {\n      return 0;\n    }\n    \n    String cmd \u003d opts.getCommand().toString().toLowerCase();\n    \n    int exitCode \u003d 0;\n    try {\n      switch (opts.getCommand()) {\n      case CHECKPOINT:\n        long count \u003d countUncheckpointedTxns();\n        if (count \u003e checkpointConf.getTxnCount() ||\n            opts.shouldForceCheckpoint()) {\n          doCheckpoint();\n        } else {\n          System.err.println(\"EditLog size \" + count + \" transactions is \" +\n                             \"smaller than configured checkpoint \" +\n                             \"interval \" + checkpointConf.getTxnCount() + \" transactions.\");\n          System.err.println(\"Skipping checkpoint.\");\n        }\n        break;\n      case GETEDITSIZE:\n        long uncheckpointed \u003d countUncheckpointedTxns();\n        System.out.println(\"NameNode has \" + uncheckpointed +\n            \" uncheckpointed transactions\");\n        break;\n      default:\n        throw new AssertionError(\"bad command enum: \" + opts.getCommand());\n      }\n      \n    } catch (RemoteException e) {\n      //\n      // This is a error returned by hadoop server. Print\n      // out the first line of the error mesage, ignore the stack trace.\n      exitCode \u003d -1;\n      try {\n        String[] content;\n        content \u003d e.getLocalizedMessage().split(\"\\n\");\n        LOG.error(cmd + \": \" + content[0]);\n      } catch (Exception ex) {\n        LOG.error(cmd + \": \" + ex.getLocalizedMessage());\n      }\n    } catch (IOException e) {\n      //\n      // IO exception encountered locally.\n      //\n      exitCode \u003d -1;\n      LOG.error(cmd + \": \" + e.getLocalizedMessage());\n    } finally {\n      // Does the RPC connection need to be closed?\n    }\n    return exitCode;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private int processStartupCommand(CommandLineOpts opts) throws Exception {\n    if (opts.getCommand() \u003d\u003d null) {\n      return 0;\n    }\n    \n    String cmd \u003d opts.getCommand().toString().toLowerCase();\n    \n    int exitCode \u003d 0;\n    try {\n      switch (opts.getCommand()) {\n      case CHECKPOINT:\n        long count \u003d countUncheckpointedTxns();\n        if (count \u003e checkpointTxnCount ||\n            opts.shouldForceCheckpoint()) {\n          doCheckpoint();\n        } else {\n          System.err.println(\"EditLog size \" + count + \" transactions is \" +\n                             \"smaller than configured checkpoint \" +\n                             \"interval \" + checkpointTxnCount + \" transactions.\");\n          System.err.println(\"Skipping checkpoint.\");\n        }\n        break;\n      case GETEDITSIZE:\n        long uncheckpointed \u003d countUncheckpointedTxns();\n        System.out.println(\"NameNode has \" + uncheckpointed +\n            \" uncheckpointed transactions\");\n        break;\n      default:\n        throw new AssertionError(\"bad command enum: \" + opts.getCommand());\n      }\n      \n    } catch (RemoteException e) {\n      //\n      // This is a error returned by hadoop server. Print\n      // out the first line of the error mesage, ignore the stack trace.\n      exitCode \u003d -1;\n      try {\n        String[] content;\n        content \u003d e.getLocalizedMessage().split(\"\\n\");\n        LOG.error(cmd + \": \" + content[0]);\n      } catch (Exception ex) {\n        LOG.error(cmd + \": \" + ex.getLocalizedMessage());\n      }\n    } catch (IOException e) {\n      //\n      // IO exception encountered locally.\n      //\n      exitCode \u003d -1;\n      LOG.error(cmd + \": \" + e.getLocalizedMessage());\n    } finally {\n      // Does the RPC connection need to be closed?\n    }\n    return exitCode;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private int processStartupCommand(CommandLineOpts opts) throws Exception {\n    if (opts.getCommand() \u003d\u003d null) {\n      return 0;\n    }\n    \n    String cmd \u003d opts.getCommand().toString().toLowerCase();\n    \n    int exitCode \u003d 0;\n    try {\n      switch (opts.getCommand()) {\n      case CHECKPOINT:\n        long count \u003d countUncheckpointedTxns();\n        if (count \u003e checkpointTxnCount ||\n            opts.shouldForceCheckpoint()) {\n          doCheckpoint();\n        } else {\n          System.err.println(\"EditLog size \" + count + \" transactions is \" +\n                             \"smaller than configured checkpoint \" +\n                             \"interval \" + checkpointTxnCount + \" transactions.\");\n          System.err.println(\"Skipping checkpoint.\");\n        }\n        break;\n      case GETEDITSIZE:\n        long uncheckpointed \u003d countUncheckpointedTxns();\n        System.out.println(\"NameNode has \" + uncheckpointed +\n            \" uncheckpointed transactions\");\n        break;\n      default:\n        throw new AssertionError(\"bad command enum: \" + opts.getCommand());\n      }\n      \n    } catch (RemoteException e) {\n      //\n      // This is a error returned by hadoop server. Print\n      // out the first line of the error mesage, ignore the stack trace.\n      exitCode \u003d -1;\n      try {\n        String[] content;\n        content \u003d e.getLocalizedMessage().split(\"\\n\");\n        LOG.error(cmd + \": \" + content[0]);\n      } catch (Exception ex) {\n        LOG.error(cmd + \": \" + ex.getLocalizedMessage());\n      }\n    } catch (IOException e) {\n      //\n      // IO exception encountered locally.\n      //\n      exitCode \u003d -1;\n      LOG.error(cmd + \": \" + e.getLocalizedMessage());\n    } finally {\n      // Does the RPC connection need to be closed?\n    }\n    return exitCode;\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java"
      }
    },
    "28e6a4e44a3e920dcaf858f9a74a6358226b3a63": {
      "type": "Ymultichange(Yrename,Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-1073. Redesign the NameNode\u0027s storage layout for image checkpoints and edit logs to introduce transaction IDs and be more robust. Contributed by Todd Lipcon and Ivan Kelly.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1152295 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "29/07/11 9:28 AM",
      "commitName": "28e6a4e44a3e920dcaf858f9a74a6358226b3a63",
      "commitAuthor": "Todd Lipcon",
      "subchanges": [
        {
          "type": "Yrename",
          "commitMessage": "HDFS-1073. Redesign the NameNode\u0027s storage layout for image checkpoints and edit logs to introduce transaction IDs and be more robust. Contributed by Todd Lipcon and Ivan Kelly.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1152295 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "29/07/11 9:28 AM",
          "commitName": "28e6a4e44a3e920dcaf858f9a74a6358226b3a63",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "27/07/11 8:19 PM",
          "commitNameOld": "ffbe9e5972bf3eee9037e2602c1330e0dc744646",
          "commitAuthorOld": "Eli Collins",
          "daysBetweenCommits": 1.55,
          "commitsBetweenForRepo": 6,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,77 +1,54 @@\n-  private int processArgs(String[] argv) throws Exception {\n-\n-    if (argv.length \u003c 1) {\n-      printUsage(\"\");\n-      return -1;\n+  private int processStartupCommand(CommandLineOpts opts) throws Exception {\n+    if (opts.getCommand() \u003d\u003d null) {\n+      return 0;\n     }\n-\n-    int exitCode \u003d -1;\n-    int i \u003d 0;\n-    String cmd \u003d argv[i++];\n-\n-    //\n-    // verify that we have enough command line parameters\n-    //\n-    if (\"-geteditsize\".equals(cmd)) {\n-      if (argv.length !\u003d 1) {\n-        printUsage(cmd);\n-        return exitCode;\n-      }\n-    } else if (\"-checkpoint\".equals(cmd)) {\n-      if (argv.length !\u003d 1 \u0026\u0026 argv.length !\u003d 2) {\n-        printUsage(cmd);\n-        return exitCode;\n-      }\n-      if (argv.length \u003d\u003d 2 \u0026\u0026 !\"force\".equals(argv[i])) {\n-        printUsage(cmd);\n-        return exitCode;\n-      }\n-    }\n-\n-    exitCode \u003d 0;\n+    \n+    String cmd \u003d opts.getCommand().toString().toLowerCase();\n+    \n+    int exitCode \u003d 0;\n     try {\n-      if (\"-checkpoint\".equals(cmd)) {\n-        long size \u003d namenode.getEditLogSize();\n-        if (size \u003e\u003d checkpointSize || \n-            argv.length \u003d\u003d 2 \u0026\u0026 \"force\".equals(argv[i])) {\n+      switch (opts.getCommand()) {\n+      case CHECKPOINT:\n+        long count \u003d countUncheckpointedTxns();\n+        if (count \u003e checkpointTxnCount ||\n+            opts.shouldForceCheckpoint()) {\n           doCheckpoint();\n         } else {\n-          System.err.println(\"EditLog size \" + size + \" bytes is \" +\n+          System.err.println(\"EditLog size \" + count + \" transactions is \" +\n                              \"smaller than configured checkpoint \" +\n-                             \"size \" + checkpointSize + \" bytes.\");\n+                             \"interval \" + checkpointTxnCount + \" transactions.\");\n           System.err.println(\"Skipping checkpoint.\");\n         }\n-      } else if (\"-geteditsize\".equals(cmd)) {\n-        long size \u003d namenode.getEditLogSize();\n-        System.out.println(\"EditLog size is \" + size + \" bytes\");\n-      } else {\n-        exitCode \u003d -1;\n-        LOG.error(cmd.substring(1) + \": Unknown command\");\n-        printUsage(\"\");\n+        break;\n+      case GETEDITSIZE:\n+        long uncheckpointed \u003d countUncheckpointedTxns();\n+        System.out.println(\"NameNode has \" + uncheckpointed +\n+            \" uncheckpointed transactions\");\n+        break;\n+      default:\n+        throw new AssertionError(\"bad command enum: \" + opts.getCommand());\n       }\n+      \n     } catch (RemoteException e) {\n       //\n       // This is a error returned by hadoop server. Print\n       // out the first line of the error mesage, ignore the stack trace.\n       exitCode \u003d -1;\n       try {\n         String[] content;\n         content \u003d e.getLocalizedMessage().split(\"\\n\");\n-        LOG.error(cmd.substring(1) + \": \"\n-                  + content[0]);\n+        LOG.error(cmd + \": \" + content[0]);\n       } catch (Exception ex) {\n-        LOG.error(cmd.substring(1) + \": \"\n-                  + ex.getLocalizedMessage());\n+        LOG.error(cmd + \": \" + ex.getLocalizedMessage());\n       }\n     } catch (IOException e) {\n       //\n       // IO exception encountered locally.\n       //\n       exitCode \u003d -1;\n-      LOG.error(cmd.substring(1) + \": \"\n-                + e.getLocalizedMessage());\n+      LOG.error(cmd + \": \" + e.getLocalizedMessage());\n     } finally {\n       // Does the RPC connection need to be closed?\n     }\n     return exitCode;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private int processStartupCommand(CommandLineOpts opts) throws Exception {\n    if (opts.getCommand() \u003d\u003d null) {\n      return 0;\n    }\n    \n    String cmd \u003d opts.getCommand().toString().toLowerCase();\n    \n    int exitCode \u003d 0;\n    try {\n      switch (opts.getCommand()) {\n      case CHECKPOINT:\n        long count \u003d countUncheckpointedTxns();\n        if (count \u003e checkpointTxnCount ||\n            opts.shouldForceCheckpoint()) {\n          doCheckpoint();\n        } else {\n          System.err.println(\"EditLog size \" + count + \" transactions is \" +\n                             \"smaller than configured checkpoint \" +\n                             \"interval \" + checkpointTxnCount + \" transactions.\");\n          System.err.println(\"Skipping checkpoint.\");\n        }\n        break;\n      case GETEDITSIZE:\n        long uncheckpointed \u003d countUncheckpointedTxns();\n        System.out.println(\"NameNode has \" + uncheckpointed +\n            \" uncheckpointed transactions\");\n        break;\n      default:\n        throw new AssertionError(\"bad command enum: \" + opts.getCommand());\n      }\n      \n    } catch (RemoteException e) {\n      //\n      // This is a error returned by hadoop server. Print\n      // out the first line of the error mesage, ignore the stack trace.\n      exitCode \u003d -1;\n      try {\n        String[] content;\n        content \u003d e.getLocalizedMessage().split(\"\\n\");\n        LOG.error(cmd + \": \" + content[0]);\n      } catch (Exception ex) {\n        LOG.error(cmd + \": \" + ex.getLocalizedMessage());\n      }\n    } catch (IOException e) {\n      //\n      // IO exception encountered locally.\n      //\n      exitCode \u003d -1;\n      LOG.error(cmd + \": \" + e.getLocalizedMessage());\n    } finally {\n      // Does the RPC connection need to be closed?\n    }\n    return exitCode;\n  }",
          "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
          "extendedDetails": {
            "oldValue": "processArgs",
            "newValue": "processStartupCommand"
          }
        },
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-1073. Redesign the NameNode\u0027s storage layout for image checkpoints and edit logs to introduce transaction IDs and be more robust. Contributed by Todd Lipcon and Ivan Kelly.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1152295 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "29/07/11 9:28 AM",
          "commitName": "28e6a4e44a3e920dcaf858f9a74a6358226b3a63",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "27/07/11 8:19 PM",
          "commitNameOld": "ffbe9e5972bf3eee9037e2602c1330e0dc744646",
          "commitAuthorOld": "Eli Collins",
          "daysBetweenCommits": 1.55,
          "commitsBetweenForRepo": 6,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,77 +1,54 @@\n-  private int processArgs(String[] argv) throws Exception {\n-\n-    if (argv.length \u003c 1) {\n-      printUsage(\"\");\n-      return -1;\n+  private int processStartupCommand(CommandLineOpts opts) throws Exception {\n+    if (opts.getCommand() \u003d\u003d null) {\n+      return 0;\n     }\n-\n-    int exitCode \u003d -1;\n-    int i \u003d 0;\n-    String cmd \u003d argv[i++];\n-\n-    //\n-    // verify that we have enough command line parameters\n-    //\n-    if (\"-geteditsize\".equals(cmd)) {\n-      if (argv.length !\u003d 1) {\n-        printUsage(cmd);\n-        return exitCode;\n-      }\n-    } else if (\"-checkpoint\".equals(cmd)) {\n-      if (argv.length !\u003d 1 \u0026\u0026 argv.length !\u003d 2) {\n-        printUsage(cmd);\n-        return exitCode;\n-      }\n-      if (argv.length \u003d\u003d 2 \u0026\u0026 !\"force\".equals(argv[i])) {\n-        printUsage(cmd);\n-        return exitCode;\n-      }\n-    }\n-\n-    exitCode \u003d 0;\n+    \n+    String cmd \u003d opts.getCommand().toString().toLowerCase();\n+    \n+    int exitCode \u003d 0;\n     try {\n-      if (\"-checkpoint\".equals(cmd)) {\n-        long size \u003d namenode.getEditLogSize();\n-        if (size \u003e\u003d checkpointSize || \n-            argv.length \u003d\u003d 2 \u0026\u0026 \"force\".equals(argv[i])) {\n+      switch (opts.getCommand()) {\n+      case CHECKPOINT:\n+        long count \u003d countUncheckpointedTxns();\n+        if (count \u003e checkpointTxnCount ||\n+            opts.shouldForceCheckpoint()) {\n           doCheckpoint();\n         } else {\n-          System.err.println(\"EditLog size \" + size + \" bytes is \" +\n+          System.err.println(\"EditLog size \" + count + \" transactions is \" +\n                              \"smaller than configured checkpoint \" +\n-                             \"size \" + checkpointSize + \" bytes.\");\n+                             \"interval \" + checkpointTxnCount + \" transactions.\");\n           System.err.println(\"Skipping checkpoint.\");\n         }\n-      } else if (\"-geteditsize\".equals(cmd)) {\n-        long size \u003d namenode.getEditLogSize();\n-        System.out.println(\"EditLog size is \" + size + \" bytes\");\n-      } else {\n-        exitCode \u003d -1;\n-        LOG.error(cmd.substring(1) + \": Unknown command\");\n-        printUsage(\"\");\n+        break;\n+      case GETEDITSIZE:\n+        long uncheckpointed \u003d countUncheckpointedTxns();\n+        System.out.println(\"NameNode has \" + uncheckpointed +\n+            \" uncheckpointed transactions\");\n+        break;\n+      default:\n+        throw new AssertionError(\"bad command enum: \" + opts.getCommand());\n       }\n+      \n     } catch (RemoteException e) {\n       //\n       // This is a error returned by hadoop server. Print\n       // out the first line of the error mesage, ignore the stack trace.\n       exitCode \u003d -1;\n       try {\n         String[] content;\n         content \u003d e.getLocalizedMessage().split(\"\\n\");\n-        LOG.error(cmd.substring(1) + \": \"\n-                  + content[0]);\n+        LOG.error(cmd + \": \" + content[0]);\n       } catch (Exception ex) {\n-        LOG.error(cmd.substring(1) + \": \"\n-                  + ex.getLocalizedMessage());\n+        LOG.error(cmd + \": \" + ex.getLocalizedMessage());\n       }\n     } catch (IOException e) {\n       //\n       // IO exception encountered locally.\n       //\n       exitCode \u003d -1;\n-      LOG.error(cmd.substring(1) + \": \"\n-                + e.getLocalizedMessage());\n+      LOG.error(cmd + \": \" + e.getLocalizedMessage());\n     } finally {\n       // Does the RPC connection need to be closed?\n     }\n     return exitCode;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private int processStartupCommand(CommandLineOpts opts) throws Exception {\n    if (opts.getCommand() \u003d\u003d null) {\n      return 0;\n    }\n    \n    String cmd \u003d opts.getCommand().toString().toLowerCase();\n    \n    int exitCode \u003d 0;\n    try {\n      switch (opts.getCommand()) {\n      case CHECKPOINT:\n        long count \u003d countUncheckpointedTxns();\n        if (count \u003e checkpointTxnCount ||\n            opts.shouldForceCheckpoint()) {\n          doCheckpoint();\n        } else {\n          System.err.println(\"EditLog size \" + count + \" transactions is \" +\n                             \"smaller than configured checkpoint \" +\n                             \"interval \" + checkpointTxnCount + \" transactions.\");\n          System.err.println(\"Skipping checkpoint.\");\n        }\n        break;\n      case GETEDITSIZE:\n        long uncheckpointed \u003d countUncheckpointedTxns();\n        System.out.println(\"NameNode has \" + uncheckpointed +\n            \" uncheckpointed transactions\");\n        break;\n      default:\n        throw new AssertionError(\"bad command enum: \" + opts.getCommand());\n      }\n      \n    } catch (RemoteException e) {\n      //\n      // This is a error returned by hadoop server. Print\n      // out the first line of the error mesage, ignore the stack trace.\n      exitCode \u003d -1;\n      try {\n        String[] content;\n        content \u003d e.getLocalizedMessage().split(\"\\n\");\n        LOG.error(cmd + \": \" + content[0]);\n      } catch (Exception ex) {\n        LOG.error(cmd + \": \" + ex.getLocalizedMessage());\n      }\n    } catch (IOException e) {\n      //\n      // IO exception encountered locally.\n      //\n      exitCode \u003d -1;\n      LOG.error(cmd + \": \" + e.getLocalizedMessage());\n    } finally {\n      // Does the RPC connection need to be closed?\n    }\n    return exitCode;\n  }",
          "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
          "extendedDetails": {
            "oldValue": "[argv-String[]]",
            "newValue": "[opts-CommandLineOpts]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-1073. Redesign the NameNode\u0027s storage layout for image checkpoints and edit logs to introduce transaction IDs and be more robust. Contributed by Todd Lipcon and Ivan Kelly.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1152295 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "29/07/11 9:28 AM",
          "commitName": "28e6a4e44a3e920dcaf858f9a74a6358226b3a63",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "27/07/11 8:19 PM",
          "commitNameOld": "ffbe9e5972bf3eee9037e2602c1330e0dc744646",
          "commitAuthorOld": "Eli Collins",
          "daysBetweenCommits": 1.55,
          "commitsBetweenForRepo": 6,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,77 +1,54 @@\n-  private int processArgs(String[] argv) throws Exception {\n-\n-    if (argv.length \u003c 1) {\n-      printUsage(\"\");\n-      return -1;\n+  private int processStartupCommand(CommandLineOpts opts) throws Exception {\n+    if (opts.getCommand() \u003d\u003d null) {\n+      return 0;\n     }\n-\n-    int exitCode \u003d -1;\n-    int i \u003d 0;\n-    String cmd \u003d argv[i++];\n-\n-    //\n-    // verify that we have enough command line parameters\n-    //\n-    if (\"-geteditsize\".equals(cmd)) {\n-      if (argv.length !\u003d 1) {\n-        printUsage(cmd);\n-        return exitCode;\n-      }\n-    } else if (\"-checkpoint\".equals(cmd)) {\n-      if (argv.length !\u003d 1 \u0026\u0026 argv.length !\u003d 2) {\n-        printUsage(cmd);\n-        return exitCode;\n-      }\n-      if (argv.length \u003d\u003d 2 \u0026\u0026 !\"force\".equals(argv[i])) {\n-        printUsage(cmd);\n-        return exitCode;\n-      }\n-    }\n-\n-    exitCode \u003d 0;\n+    \n+    String cmd \u003d opts.getCommand().toString().toLowerCase();\n+    \n+    int exitCode \u003d 0;\n     try {\n-      if (\"-checkpoint\".equals(cmd)) {\n-        long size \u003d namenode.getEditLogSize();\n-        if (size \u003e\u003d checkpointSize || \n-            argv.length \u003d\u003d 2 \u0026\u0026 \"force\".equals(argv[i])) {\n+      switch (opts.getCommand()) {\n+      case CHECKPOINT:\n+        long count \u003d countUncheckpointedTxns();\n+        if (count \u003e checkpointTxnCount ||\n+            opts.shouldForceCheckpoint()) {\n           doCheckpoint();\n         } else {\n-          System.err.println(\"EditLog size \" + size + \" bytes is \" +\n+          System.err.println(\"EditLog size \" + count + \" transactions is \" +\n                              \"smaller than configured checkpoint \" +\n-                             \"size \" + checkpointSize + \" bytes.\");\n+                             \"interval \" + checkpointTxnCount + \" transactions.\");\n           System.err.println(\"Skipping checkpoint.\");\n         }\n-      } else if (\"-geteditsize\".equals(cmd)) {\n-        long size \u003d namenode.getEditLogSize();\n-        System.out.println(\"EditLog size is \" + size + \" bytes\");\n-      } else {\n-        exitCode \u003d -1;\n-        LOG.error(cmd.substring(1) + \": Unknown command\");\n-        printUsage(\"\");\n+        break;\n+      case GETEDITSIZE:\n+        long uncheckpointed \u003d countUncheckpointedTxns();\n+        System.out.println(\"NameNode has \" + uncheckpointed +\n+            \" uncheckpointed transactions\");\n+        break;\n+      default:\n+        throw new AssertionError(\"bad command enum: \" + opts.getCommand());\n       }\n+      \n     } catch (RemoteException e) {\n       //\n       // This is a error returned by hadoop server. Print\n       // out the first line of the error mesage, ignore the stack trace.\n       exitCode \u003d -1;\n       try {\n         String[] content;\n         content \u003d e.getLocalizedMessage().split(\"\\n\");\n-        LOG.error(cmd.substring(1) + \": \"\n-                  + content[0]);\n+        LOG.error(cmd + \": \" + content[0]);\n       } catch (Exception ex) {\n-        LOG.error(cmd.substring(1) + \": \"\n-                  + ex.getLocalizedMessage());\n+        LOG.error(cmd + \": \" + ex.getLocalizedMessage());\n       }\n     } catch (IOException e) {\n       //\n       // IO exception encountered locally.\n       //\n       exitCode \u003d -1;\n-      LOG.error(cmd.substring(1) + \": \"\n-                + e.getLocalizedMessage());\n+      LOG.error(cmd + \": \" + e.getLocalizedMessage());\n     } finally {\n       // Does the RPC connection need to be closed?\n     }\n     return exitCode;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private int processStartupCommand(CommandLineOpts opts) throws Exception {\n    if (opts.getCommand() \u003d\u003d null) {\n      return 0;\n    }\n    \n    String cmd \u003d opts.getCommand().toString().toLowerCase();\n    \n    int exitCode \u003d 0;\n    try {\n      switch (opts.getCommand()) {\n      case CHECKPOINT:\n        long count \u003d countUncheckpointedTxns();\n        if (count \u003e checkpointTxnCount ||\n            opts.shouldForceCheckpoint()) {\n          doCheckpoint();\n        } else {\n          System.err.println(\"EditLog size \" + count + \" transactions is \" +\n                             \"smaller than configured checkpoint \" +\n                             \"interval \" + checkpointTxnCount + \" transactions.\");\n          System.err.println(\"Skipping checkpoint.\");\n        }\n        break;\n      case GETEDITSIZE:\n        long uncheckpointed \u003d countUncheckpointedTxns();\n        System.out.println(\"NameNode has \" + uncheckpointed +\n            \" uncheckpointed transactions\");\n        break;\n      default:\n        throw new AssertionError(\"bad command enum: \" + opts.getCommand());\n      }\n      \n    } catch (RemoteException e) {\n      //\n      // This is a error returned by hadoop server. Print\n      // out the first line of the error mesage, ignore the stack trace.\n      exitCode \u003d -1;\n      try {\n        String[] content;\n        content \u003d e.getLocalizedMessage().split(\"\\n\");\n        LOG.error(cmd + \": \" + content[0]);\n      } catch (Exception ex) {\n        LOG.error(cmd + \": \" + ex.getLocalizedMessage());\n      }\n    } catch (IOException e) {\n      //\n      // IO exception encountered locally.\n      //\n      exitCode \u003d -1;\n      LOG.error(cmd + \": \" + e.getLocalizedMessage());\n    } finally {\n      // Does the RPC connection need to be closed?\n    }\n    return exitCode;\n  }",
          "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
          "extendedDetails": {}
        }
      ]
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,77 @@\n+  private int processArgs(String[] argv) throws Exception {\n+\n+    if (argv.length \u003c 1) {\n+      printUsage(\"\");\n+      return -1;\n+    }\n+\n+    int exitCode \u003d -1;\n+    int i \u003d 0;\n+    String cmd \u003d argv[i++];\n+\n+    //\n+    // verify that we have enough command line parameters\n+    //\n+    if (\"-geteditsize\".equals(cmd)) {\n+      if (argv.length !\u003d 1) {\n+        printUsage(cmd);\n+        return exitCode;\n+      }\n+    } else if (\"-checkpoint\".equals(cmd)) {\n+      if (argv.length !\u003d 1 \u0026\u0026 argv.length !\u003d 2) {\n+        printUsage(cmd);\n+        return exitCode;\n+      }\n+      if (argv.length \u003d\u003d 2 \u0026\u0026 !\"force\".equals(argv[i])) {\n+        printUsage(cmd);\n+        return exitCode;\n+      }\n+    }\n+\n+    exitCode \u003d 0;\n+    try {\n+      if (\"-checkpoint\".equals(cmd)) {\n+        long size \u003d namenode.getEditLogSize();\n+        if (size \u003e\u003d checkpointSize || \n+            argv.length \u003d\u003d 2 \u0026\u0026 \"force\".equals(argv[i])) {\n+          doCheckpoint();\n+        } else {\n+          System.err.println(\"EditLog size \" + size + \" bytes is \" +\n+                             \"smaller than configured checkpoint \" +\n+                             \"size \" + checkpointSize + \" bytes.\");\n+          System.err.println(\"Skipping checkpoint.\");\n+        }\n+      } else if (\"-geteditsize\".equals(cmd)) {\n+        long size \u003d namenode.getEditLogSize();\n+        System.out.println(\"EditLog size is \" + size + \" bytes\");\n+      } else {\n+        exitCode \u003d -1;\n+        LOG.error(cmd.substring(1) + \": Unknown command\");\n+        printUsage(\"\");\n+      }\n+    } catch (RemoteException e) {\n+      //\n+      // This is a error returned by hadoop server. Print\n+      // out the first line of the error mesage, ignore the stack trace.\n+      exitCode \u003d -1;\n+      try {\n+        String[] content;\n+        content \u003d e.getLocalizedMessage().split(\"\\n\");\n+        LOG.error(cmd.substring(1) + \": \"\n+                  + content[0]);\n+      } catch (Exception ex) {\n+        LOG.error(cmd.substring(1) + \": \"\n+                  + ex.getLocalizedMessage());\n+      }\n+    } catch (IOException e) {\n+      //\n+      // IO exception encountered locally.\n+      //\n+      exitCode \u003d -1;\n+      LOG.error(cmd.substring(1) + \": \"\n+                + e.getLocalizedMessage());\n+    } finally {\n+      // Does the RPC connection need to be closed?\n+    }\n+    return exitCode;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private int processArgs(String[] argv) throws Exception {\n\n    if (argv.length \u003c 1) {\n      printUsage(\"\");\n      return -1;\n    }\n\n    int exitCode \u003d -1;\n    int i \u003d 0;\n    String cmd \u003d argv[i++];\n\n    //\n    // verify that we have enough command line parameters\n    //\n    if (\"-geteditsize\".equals(cmd)) {\n      if (argv.length !\u003d 1) {\n        printUsage(cmd);\n        return exitCode;\n      }\n    } else if (\"-checkpoint\".equals(cmd)) {\n      if (argv.length !\u003d 1 \u0026\u0026 argv.length !\u003d 2) {\n        printUsage(cmd);\n        return exitCode;\n      }\n      if (argv.length \u003d\u003d 2 \u0026\u0026 !\"force\".equals(argv[i])) {\n        printUsage(cmd);\n        return exitCode;\n      }\n    }\n\n    exitCode \u003d 0;\n    try {\n      if (\"-checkpoint\".equals(cmd)) {\n        long size \u003d namenode.getEditLogSize();\n        if (size \u003e\u003d checkpointSize || \n            argv.length \u003d\u003d 2 \u0026\u0026 \"force\".equals(argv[i])) {\n          doCheckpoint();\n        } else {\n          System.err.println(\"EditLog size \" + size + \" bytes is \" +\n                             \"smaller than configured checkpoint \" +\n                             \"size \" + checkpointSize + \" bytes.\");\n          System.err.println(\"Skipping checkpoint.\");\n        }\n      } else if (\"-geteditsize\".equals(cmd)) {\n        long size \u003d namenode.getEditLogSize();\n        System.out.println(\"EditLog size is \" + size + \" bytes\");\n      } else {\n        exitCode \u003d -1;\n        LOG.error(cmd.substring(1) + \": Unknown command\");\n        printUsage(\"\");\n      }\n    } catch (RemoteException e) {\n      //\n      // This is a error returned by hadoop server. Print\n      // out the first line of the error mesage, ignore the stack trace.\n      exitCode \u003d -1;\n      try {\n        String[] content;\n        content \u003d e.getLocalizedMessage().split(\"\\n\");\n        LOG.error(cmd.substring(1) + \": \"\n                  + content[0]);\n      } catch (Exception ex) {\n        LOG.error(cmd.substring(1) + \": \"\n                  + ex.getLocalizedMessage());\n      }\n    } catch (IOException e) {\n      //\n      // IO exception encountered locally.\n      //\n      exitCode \u003d -1;\n      LOG.error(cmd.substring(1) + \": \"\n                + e.getLocalizedMessage());\n    } finally {\n      // Does the RPC connection need to be closed?\n    }\n    return exitCode;\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java"
    }
  }
}