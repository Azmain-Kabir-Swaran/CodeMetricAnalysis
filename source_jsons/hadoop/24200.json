{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "JobHistoryUtils.java",
  "functionName": "getPreviousJobHistoryPath",
  "functionId": "getPreviousJobHistoryPath___conf-Configuration__applicationAttemptId-ApplicationAttemptId",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common/src/main/java/org/apache/hadoop/mapreduce/v2/jobhistory/JobHistoryUtils.java",
  "functionStartLine": 582,
  "functionEndLine": 595,
  "numCommitsSeen": 46,
  "timeTaken": 2692,
  "changeHistory": [
    "6a1c41111edcdc58c846fc50e53554fbba230171",
    "390d1fbef889092fc8f4296bd9e547f3200c8b37",
    "64e4fb983e022d8d3375a3e1b8facbf95f7ba403",
    "42d1eaf237ef0a3a30c061888d35329b2a2e1453"
  ],
  "changeHistoryShort": {
    "6a1c41111edcdc58c846fc50e53554fbba230171": "Ymultichange(Ymovefromfile,Yreturntypechange,Ybodychange,Yrename)",
    "390d1fbef889092fc8f4296bd9e547f3200c8b37": "Ybodychange",
    "64e4fb983e022d8d3375a3e1b8facbf95f7ba403": "Ybodychange",
    "42d1eaf237ef0a3a30c061888d35329b2a2e1453": "Yintroduced"
  },
  "changeHistoryDetails": {
    "6a1c41111edcdc58c846fc50e53554fbba230171": {
      "type": "Ymultichange(Ymovefromfile,Yreturntypechange,Ybodychange,Yrename)",
      "commitMessage": "MAPREDUCE-5079. Changes job recovery to restore state directly from job history, instaed of simulating state machine events. Contributed by Jason Lowe and Robert Parker.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1466767 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/04/13 9:52 PM",
      "commitName": "6a1c41111edcdc58c846fc50e53554fbba230171",
      "commitAuthor": "Siddharth Seth",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "MAPREDUCE-5079. Changes job recovery to restore state directly from job history, instaed of simulating state machine events. Contributed by Jason Lowe and Robert Parker.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1466767 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "10/04/13 9:52 PM",
          "commitName": "6a1c41111edcdc58c846fc50e53554fbba230171",
          "commitAuthor": "Siddharth Seth",
          "commitDateOld": "10/04/13 9:05 PM",
          "commitNameOld": "3ddf8319ca974c65f2605a97532bdb9516367029",
          "commitAuthorOld": "Alejandro Abdelnur",
          "daysBetweenCommits": 0.03,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,22 +1,14 @@\n-  public static FSDataInputStream getPreviousJobHistoryFileStream(\n+  public static Path getPreviousJobHistoryPath(\n       Configuration conf, ApplicationAttemptId applicationAttemptId)\n       throws IOException {\n-    FSDataInputStream in \u003d null;\n-    Path historyFile \u003d null;\n     String jobId \u003d\n         TypeConverter.fromYarn(applicationAttemptId.getApplicationId())\n           .toString();\n     String jobhistoryDir \u003d\n         JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf, jobId);\n-    Path histDirPath \u003d\n-        FileContext.getFileContext(conf).makeQualified(new Path(jobhistoryDir));\n-    LOG.info(\"Trying file \" + histDirPath.toString());\n+    Path histDirPath \u003d FileContext.getFileContext(conf).makeQualified(\n+            new Path(jobhistoryDir));\n     FileContext fc \u003d FileContext.getFileContext(histDirPath.toUri(), conf);\n-    // read the previous history file\n-    historyFile \u003d\n-        fc.makeQualified(JobHistoryUtils.getStagingJobHistoryFile(histDirPath,\n-          jobId, (applicationAttemptId.getAttemptId() - 1)));\n-    LOG.info(\"History file is at \" + historyFile);\n-    in \u003d fc.open(historyFile);\n-    return in;\n+    return fc.makeQualified(JobHistoryUtils.getStagingJobHistoryFile(\n+        histDirPath,jobId, (applicationAttemptId.getAttemptId() - 1)));\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static Path getPreviousJobHistoryPath(\n      Configuration conf, ApplicationAttemptId applicationAttemptId)\n      throws IOException {\n    String jobId \u003d\n        TypeConverter.fromYarn(applicationAttemptId.getApplicationId())\n          .toString();\n    String jobhistoryDir \u003d\n        JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf, jobId);\n    Path histDirPath \u003d FileContext.getFileContext(conf).makeQualified(\n            new Path(jobhistoryDir));\n    FileContext fc \u003d FileContext.getFileContext(histDirPath.toUri(), conf);\n    return fc.makeQualified(JobHistoryUtils.getStagingJobHistoryFile(\n        histDirPath,jobId, (applicationAttemptId.getAttemptId() - 1)));\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common/src/main/java/org/apache/hadoop/mapreduce/v2/jobhistory/JobHistoryUtils.java",
          "extendedDetails": {
            "oldPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/recover/RecoveryService.java",
            "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common/src/main/java/org/apache/hadoop/mapreduce/v2/jobhistory/JobHistoryUtils.java",
            "oldMethodName": "getPreviousJobHistoryFileStream",
            "newMethodName": "getPreviousJobHistoryPath"
          }
        },
        {
          "type": "Yreturntypechange",
          "commitMessage": "MAPREDUCE-5079. Changes job recovery to restore state directly from job history, instaed of simulating state machine events. Contributed by Jason Lowe and Robert Parker.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1466767 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "10/04/13 9:52 PM",
          "commitName": "6a1c41111edcdc58c846fc50e53554fbba230171",
          "commitAuthor": "Siddharth Seth",
          "commitDateOld": "10/04/13 9:05 PM",
          "commitNameOld": "3ddf8319ca974c65f2605a97532bdb9516367029",
          "commitAuthorOld": "Alejandro Abdelnur",
          "daysBetweenCommits": 0.03,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,22 +1,14 @@\n-  public static FSDataInputStream getPreviousJobHistoryFileStream(\n+  public static Path getPreviousJobHistoryPath(\n       Configuration conf, ApplicationAttemptId applicationAttemptId)\n       throws IOException {\n-    FSDataInputStream in \u003d null;\n-    Path historyFile \u003d null;\n     String jobId \u003d\n         TypeConverter.fromYarn(applicationAttemptId.getApplicationId())\n           .toString();\n     String jobhistoryDir \u003d\n         JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf, jobId);\n-    Path histDirPath \u003d\n-        FileContext.getFileContext(conf).makeQualified(new Path(jobhistoryDir));\n-    LOG.info(\"Trying file \" + histDirPath.toString());\n+    Path histDirPath \u003d FileContext.getFileContext(conf).makeQualified(\n+            new Path(jobhistoryDir));\n     FileContext fc \u003d FileContext.getFileContext(histDirPath.toUri(), conf);\n-    // read the previous history file\n-    historyFile \u003d\n-        fc.makeQualified(JobHistoryUtils.getStagingJobHistoryFile(histDirPath,\n-          jobId, (applicationAttemptId.getAttemptId() - 1)));\n-    LOG.info(\"History file is at \" + historyFile);\n-    in \u003d fc.open(historyFile);\n-    return in;\n+    return fc.makeQualified(JobHistoryUtils.getStagingJobHistoryFile(\n+        histDirPath,jobId, (applicationAttemptId.getAttemptId() - 1)));\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static Path getPreviousJobHistoryPath(\n      Configuration conf, ApplicationAttemptId applicationAttemptId)\n      throws IOException {\n    String jobId \u003d\n        TypeConverter.fromYarn(applicationAttemptId.getApplicationId())\n          .toString();\n    String jobhistoryDir \u003d\n        JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf, jobId);\n    Path histDirPath \u003d FileContext.getFileContext(conf).makeQualified(\n            new Path(jobhistoryDir));\n    FileContext fc \u003d FileContext.getFileContext(histDirPath.toUri(), conf);\n    return fc.makeQualified(JobHistoryUtils.getStagingJobHistoryFile(\n        histDirPath,jobId, (applicationAttemptId.getAttemptId() - 1)));\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common/src/main/java/org/apache/hadoop/mapreduce/v2/jobhistory/JobHistoryUtils.java",
          "extendedDetails": {
            "oldValue": "FSDataInputStream",
            "newValue": "Path"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "MAPREDUCE-5079. Changes job recovery to restore state directly from job history, instaed of simulating state machine events. Contributed by Jason Lowe and Robert Parker.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1466767 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "10/04/13 9:52 PM",
          "commitName": "6a1c41111edcdc58c846fc50e53554fbba230171",
          "commitAuthor": "Siddharth Seth",
          "commitDateOld": "10/04/13 9:05 PM",
          "commitNameOld": "3ddf8319ca974c65f2605a97532bdb9516367029",
          "commitAuthorOld": "Alejandro Abdelnur",
          "daysBetweenCommits": 0.03,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,22 +1,14 @@\n-  public static FSDataInputStream getPreviousJobHistoryFileStream(\n+  public static Path getPreviousJobHistoryPath(\n       Configuration conf, ApplicationAttemptId applicationAttemptId)\n       throws IOException {\n-    FSDataInputStream in \u003d null;\n-    Path historyFile \u003d null;\n     String jobId \u003d\n         TypeConverter.fromYarn(applicationAttemptId.getApplicationId())\n           .toString();\n     String jobhistoryDir \u003d\n         JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf, jobId);\n-    Path histDirPath \u003d\n-        FileContext.getFileContext(conf).makeQualified(new Path(jobhistoryDir));\n-    LOG.info(\"Trying file \" + histDirPath.toString());\n+    Path histDirPath \u003d FileContext.getFileContext(conf).makeQualified(\n+            new Path(jobhistoryDir));\n     FileContext fc \u003d FileContext.getFileContext(histDirPath.toUri(), conf);\n-    // read the previous history file\n-    historyFile \u003d\n-        fc.makeQualified(JobHistoryUtils.getStagingJobHistoryFile(histDirPath,\n-          jobId, (applicationAttemptId.getAttemptId() - 1)));\n-    LOG.info(\"History file is at \" + historyFile);\n-    in \u003d fc.open(historyFile);\n-    return in;\n+    return fc.makeQualified(JobHistoryUtils.getStagingJobHistoryFile(\n+        histDirPath,jobId, (applicationAttemptId.getAttemptId() - 1)));\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static Path getPreviousJobHistoryPath(\n      Configuration conf, ApplicationAttemptId applicationAttemptId)\n      throws IOException {\n    String jobId \u003d\n        TypeConverter.fromYarn(applicationAttemptId.getApplicationId())\n          .toString();\n    String jobhistoryDir \u003d\n        JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf, jobId);\n    Path histDirPath \u003d FileContext.getFileContext(conf).makeQualified(\n            new Path(jobhistoryDir));\n    FileContext fc \u003d FileContext.getFileContext(histDirPath.toUri(), conf);\n    return fc.makeQualified(JobHistoryUtils.getStagingJobHistoryFile(\n        histDirPath,jobId, (applicationAttemptId.getAttemptId() - 1)));\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common/src/main/java/org/apache/hadoop/mapreduce/v2/jobhistory/JobHistoryUtils.java",
          "extendedDetails": {}
        },
        {
          "type": "Yrename",
          "commitMessage": "MAPREDUCE-5079. Changes job recovery to restore state directly from job history, instaed of simulating state machine events. Contributed by Jason Lowe and Robert Parker.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1466767 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "10/04/13 9:52 PM",
          "commitName": "6a1c41111edcdc58c846fc50e53554fbba230171",
          "commitAuthor": "Siddharth Seth",
          "commitDateOld": "10/04/13 9:05 PM",
          "commitNameOld": "3ddf8319ca974c65f2605a97532bdb9516367029",
          "commitAuthorOld": "Alejandro Abdelnur",
          "daysBetweenCommits": 0.03,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,22 +1,14 @@\n-  public static FSDataInputStream getPreviousJobHistoryFileStream(\n+  public static Path getPreviousJobHistoryPath(\n       Configuration conf, ApplicationAttemptId applicationAttemptId)\n       throws IOException {\n-    FSDataInputStream in \u003d null;\n-    Path historyFile \u003d null;\n     String jobId \u003d\n         TypeConverter.fromYarn(applicationAttemptId.getApplicationId())\n           .toString();\n     String jobhistoryDir \u003d\n         JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf, jobId);\n-    Path histDirPath \u003d\n-        FileContext.getFileContext(conf).makeQualified(new Path(jobhistoryDir));\n-    LOG.info(\"Trying file \" + histDirPath.toString());\n+    Path histDirPath \u003d FileContext.getFileContext(conf).makeQualified(\n+            new Path(jobhistoryDir));\n     FileContext fc \u003d FileContext.getFileContext(histDirPath.toUri(), conf);\n-    // read the previous history file\n-    historyFile \u003d\n-        fc.makeQualified(JobHistoryUtils.getStagingJobHistoryFile(histDirPath,\n-          jobId, (applicationAttemptId.getAttemptId() - 1)));\n-    LOG.info(\"History file is at \" + historyFile);\n-    in \u003d fc.open(historyFile);\n-    return in;\n+    return fc.makeQualified(JobHistoryUtils.getStagingJobHistoryFile(\n+        histDirPath,jobId, (applicationAttemptId.getAttemptId() - 1)));\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static Path getPreviousJobHistoryPath(\n      Configuration conf, ApplicationAttemptId applicationAttemptId)\n      throws IOException {\n    String jobId \u003d\n        TypeConverter.fromYarn(applicationAttemptId.getApplicationId())\n          .toString();\n    String jobhistoryDir \u003d\n        JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf, jobId);\n    Path histDirPath \u003d FileContext.getFileContext(conf).makeQualified(\n            new Path(jobhistoryDir));\n    FileContext fc \u003d FileContext.getFileContext(histDirPath.toUri(), conf);\n    return fc.makeQualified(JobHistoryUtils.getStagingJobHistoryFile(\n        histDirPath,jobId, (applicationAttemptId.getAttemptId() - 1)));\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common/src/main/java/org/apache/hadoop/mapreduce/v2/jobhistory/JobHistoryUtils.java",
          "extendedDetails": {
            "oldValue": "getPreviousJobHistoryFileStream",
            "newValue": "getPreviousJobHistoryPath"
          }
        }
      ]
    },
    "390d1fbef889092fc8f4296bd9e547f3200c8b37": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4992. AM hangs in RecoveryService when recovering tasks with speculative attempts. Contributed by Robert Parker\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1445456 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/02/13 6:11 PM",
      "commitName": "390d1fbef889092fc8f4296bd9e547f3200c8b37",
      "commitAuthor": "Jason Darrell Lowe",
      "commitDateOld": "09/01/13 2:56 PM",
      "commitNameOld": "b16dfc125dfd172900e34de1b46d3a06fe9aceb6",
      "commitAuthorOld": "Jason Darrell Lowe",
      "daysBetweenCommits": 34.14,
      "commitsBetweenForRepo": 164,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,22 @@\n   public static FSDataInputStream getPreviousJobHistoryFileStream(\n       Configuration conf, ApplicationAttemptId applicationAttemptId)\n       throws IOException {\n     FSDataInputStream in \u003d null;\n     Path historyFile \u003d null;\n     String jobId \u003d\n         TypeConverter.fromYarn(applicationAttemptId.getApplicationId())\n           .toString();\n     String jobhistoryDir \u003d\n         JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf, jobId);\n     Path histDirPath \u003d\n         FileContext.getFileContext(conf).makeQualified(new Path(jobhistoryDir));\n+    LOG.info(\"Trying file \" + histDirPath.toString());\n     FileContext fc \u003d FileContext.getFileContext(histDirPath.toUri(), conf);\n     // read the previous history file\n     historyFile \u003d\n         fc.makeQualified(JobHistoryUtils.getStagingJobHistoryFile(histDirPath,\n           jobId, (applicationAttemptId.getAttemptId() - 1)));\n     LOG.info(\"History file is at \" + historyFile);\n     in \u003d fc.open(historyFile);\n     return in;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static FSDataInputStream getPreviousJobHistoryFileStream(\n      Configuration conf, ApplicationAttemptId applicationAttemptId)\n      throws IOException {\n    FSDataInputStream in \u003d null;\n    Path historyFile \u003d null;\n    String jobId \u003d\n        TypeConverter.fromYarn(applicationAttemptId.getApplicationId())\n          .toString();\n    String jobhistoryDir \u003d\n        JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf, jobId);\n    Path histDirPath \u003d\n        FileContext.getFileContext(conf).makeQualified(new Path(jobhistoryDir));\n    LOG.info(\"Trying file \" + histDirPath.toString());\n    FileContext fc \u003d FileContext.getFileContext(histDirPath.toUri(), conf);\n    // read the previous history file\n    historyFile \u003d\n        fc.makeQualified(JobHistoryUtils.getStagingJobHistoryFile(histDirPath,\n          jobId, (applicationAttemptId.getAttemptId() - 1)));\n    LOG.info(\"History file is at \" + historyFile);\n    in \u003d fc.open(historyFile);\n    return in;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/recover/RecoveryService.java",
      "extendedDetails": {}
    },
    "64e4fb983e022d8d3375a3e1b8facbf95f7ba403": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4819. AM can rerun job after reporting final job status to the client (bobby and Bikas Saha via bobby)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1429114 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/01/13 12:35 PM",
      "commitName": "64e4fb983e022d8d3375a3e1b8facbf95f7ba403",
      "commitAuthor": "Robert Joseph Evans",
      "commitDateOld": "28/12/12 7:01 AM",
      "commitNameOld": "402eb1851341fce72c8e46266a2578bb67b5b684",
      "commitAuthorOld": "Robert Joseph Evans",
      "daysBetweenCommits": 7.23,
      "commitsBetweenForRepo": 24,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,21 @@\n   public static FSDataInputStream getPreviousJobHistoryFileStream(\n       Configuration conf, ApplicationAttemptId applicationAttemptId)\n       throws IOException {\n     FSDataInputStream in \u003d null;\n     Path historyFile \u003d null;\n-    String jobName \u003d\n+    String jobId \u003d\n         TypeConverter.fromYarn(applicationAttemptId.getApplicationId())\n           .toString();\n     String jobhistoryDir \u003d\n-        JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf);\n+        JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf, jobId);\n     Path histDirPath \u003d\n         FileContext.getFileContext(conf).makeQualified(new Path(jobhistoryDir));\n     FileContext fc \u003d FileContext.getFileContext(histDirPath.toUri(), conf);\n     // read the previous history file\n     historyFile \u003d\n         fc.makeQualified(JobHistoryUtils.getStagingJobHistoryFile(histDirPath,\n-          jobName, (applicationAttemptId.getAttemptId() - 1)));\n+          jobId, (applicationAttemptId.getAttemptId() - 1)));\n     LOG.info(\"History file is at \" + historyFile);\n     in \u003d fc.open(historyFile);\n     return in;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static FSDataInputStream getPreviousJobHistoryFileStream(\n      Configuration conf, ApplicationAttemptId applicationAttemptId)\n      throws IOException {\n    FSDataInputStream in \u003d null;\n    Path historyFile \u003d null;\n    String jobId \u003d\n        TypeConverter.fromYarn(applicationAttemptId.getApplicationId())\n          .toString();\n    String jobhistoryDir \u003d\n        JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf, jobId);\n    Path histDirPath \u003d\n        FileContext.getFileContext(conf).makeQualified(new Path(jobhistoryDir));\n    FileContext fc \u003d FileContext.getFileContext(histDirPath.toUri(), conf);\n    // read the previous history file\n    historyFile \u003d\n        fc.makeQualified(JobHistoryUtils.getStagingJobHistoryFile(histDirPath,\n          jobId, (applicationAttemptId.getAttemptId() - 1)));\n    LOG.info(\"History file is at \" + historyFile);\n    in \u003d fc.open(historyFile);\n    return in;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/recover/RecoveryService.java",
      "extendedDetails": {}
    },
    "42d1eaf237ef0a3a30c061888d35329b2a2e1453": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-4729. job history UI not showing all job attempts. Contributed by Vinod Kumar Vavilapalli\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1404817 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "01/11/12 3:59 PM",
      "commitName": "42d1eaf237ef0a3a30c061888d35329b2a2e1453",
      "commitAuthor": "Jason Darrell Lowe",
      "diff": "@@ -0,0 +1,21 @@\n+  public static FSDataInputStream getPreviousJobHistoryFileStream(\n+      Configuration conf, ApplicationAttemptId applicationAttemptId)\n+      throws IOException {\n+    FSDataInputStream in \u003d null;\n+    Path historyFile \u003d null;\n+    String jobName \u003d\n+        TypeConverter.fromYarn(applicationAttemptId.getApplicationId())\n+          .toString();\n+    String jobhistoryDir \u003d\n+        JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf);\n+    Path histDirPath \u003d\n+        FileContext.getFileContext(conf).makeQualified(new Path(jobhistoryDir));\n+    FileContext fc \u003d FileContext.getFileContext(histDirPath.toUri(), conf);\n+    // read the previous history file\n+    historyFile \u003d\n+        fc.makeQualified(JobHistoryUtils.getStagingJobHistoryFile(histDirPath,\n+          jobName, (applicationAttemptId.getAttemptId() - 1)));\n+    LOG.info(\"History file is at \" + historyFile);\n+    in \u003d fc.open(historyFile);\n+    return in;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public static FSDataInputStream getPreviousJobHistoryFileStream(\n      Configuration conf, ApplicationAttemptId applicationAttemptId)\n      throws IOException {\n    FSDataInputStream in \u003d null;\n    Path historyFile \u003d null;\n    String jobName \u003d\n        TypeConverter.fromYarn(applicationAttemptId.getApplicationId())\n          .toString();\n    String jobhistoryDir \u003d\n        JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf);\n    Path histDirPath \u003d\n        FileContext.getFileContext(conf).makeQualified(new Path(jobhistoryDir));\n    FileContext fc \u003d FileContext.getFileContext(histDirPath.toUri(), conf);\n    // read the previous history file\n    historyFile \u003d\n        fc.makeQualified(JobHistoryUtils.getStagingJobHistoryFile(histDirPath,\n          jobName, (applicationAttemptId.getAttemptId() - 1)));\n    LOG.info(\"History file is at \" + historyFile);\n    in \u003d fc.open(historyFile);\n    return in;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/recover/RecoveryService.java"
    }
  }
}