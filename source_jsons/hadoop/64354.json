{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "S3AInstrumentation.java",
  "functionName": "mergeInputStreamStatistics",
  "functionId": "mergeInputStreamStatistics___statistics-InputStreamStatistics",
  "sourceFilePath": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AInstrumentation.java",
  "functionStartLine": 591,
  "functionEndLine": 610,
  "numCommitsSeen": 27,
  "timeTaken": 1563,
  "changeHistory": [
    "6fa229891e06eea62cb9634efde755f40247e816",
    "4ee3543625c77c06d566fe81644d21c607d6d74d",
    "27c4e90efce04e1b1302f668b5eb22412e00d033"
  ],
  "changeHistoryShort": {
    "6fa229891e06eea62cb9634efde755f40247e816": "Ybodychange",
    "4ee3543625c77c06d566fe81644d21c607d6d74d": "Ybodychange",
    "27c4e90efce04e1b1302f668b5eb22412e00d033": "Yintroduced"
  },
  "changeHistoryDetails": {
    "6fa229891e06eea62cb9634efde755f40247e816": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-15625. S3A input stream to use etags/version number to detect changed source files.\n\nAuthor: Ben Roling \u003cben.roling@gmail.com\u003e\n\nInitial patch from Brahma Reddy Battula.\n",
      "commitDate": "13/03/19 1:37 PM",
      "commitName": "6fa229891e06eea62cb9634efde755f40247e816",
      "commitAuthor": "Ben Roling",
      "commitDateOld": "05/02/19 3:51 AM",
      "commitNameOld": "f365957c6326f88734bc0a5d01cfb7eac713db20",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 36.37,
      "commitsBetweenForRepo": 327,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,18 +1,20 @@\n   private void mergeInputStreamStatistics(InputStreamStatistics statistics) {\n     streamOpenOperations.incr(statistics.openOperations);\n     streamCloseOperations.incr(statistics.closeOperations);\n     streamClosed.incr(statistics.closed);\n     streamAborted.incr(statistics.aborted);\n     streamSeekOperations.incr(statistics.seekOperations);\n     streamReadExceptions.incr(statistics.readExceptions);\n     streamForwardSeekOperations.incr(statistics.forwardSeekOperations);\n     streamBytesSkippedOnSeek.incr(statistics.bytesSkippedOnSeek);\n     streamBackwardSeekOperations.incr(statistics.backwardSeekOperations);\n     streamBytesBackwardsOnSeek.incr(statistics.bytesBackwardsOnSeek);\n     streamBytesRead.incr(statistics.bytesRead);\n     streamReadOperations.incr(statistics.readOperations);\n     streamReadFullyOperations.incr(statistics.readFullyOperations);\n     streamReadsIncomplete.incr(statistics.readsIncomplete);\n     streamBytesReadInClose.incr(statistics.bytesReadInClose);\n     streamBytesDiscardedInAbort.incr(statistics.bytesDiscardedInAbort);\n+    incrementCounter(STREAM_READ_VERSION_MISMATCHES,\n+        statistics.versionMismatches.get());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void mergeInputStreamStatistics(InputStreamStatistics statistics) {\n    streamOpenOperations.incr(statistics.openOperations);\n    streamCloseOperations.incr(statistics.closeOperations);\n    streamClosed.incr(statistics.closed);\n    streamAborted.incr(statistics.aborted);\n    streamSeekOperations.incr(statistics.seekOperations);\n    streamReadExceptions.incr(statistics.readExceptions);\n    streamForwardSeekOperations.incr(statistics.forwardSeekOperations);\n    streamBytesSkippedOnSeek.incr(statistics.bytesSkippedOnSeek);\n    streamBackwardSeekOperations.incr(statistics.backwardSeekOperations);\n    streamBytesBackwardsOnSeek.incr(statistics.bytesBackwardsOnSeek);\n    streamBytesRead.incr(statistics.bytesRead);\n    streamReadOperations.incr(statistics.readOperations);\n    streamReadFullyOperations.incr(statistics.readFullyOperations);\n    streamReadsIncomplete.incr(statistics.readsIncomplete);\n    streamBytesReadInClose.incr(statistics.bytesReadInClose);\n    streamBytesDiscardedInAbort.incr(statistics.bytesDiscardedInAbort);\n    incrementCounter(STREAM_READ_VERSION_MISMATCHES,\n        statistics.versionMismatches.get());\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AInstrumentation.java",
      "extendedDetails": {}
    },
    "4ee3543625c77c06d566fe81644d21c607d6d74d": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-13203 S3A: Support fadvise \"random\" mode for high performance readPositioned() reads. Contributed by Rajesh Balamohan and stevel.\n",
      "commitDate": "22/06/16 7:45 AM",
      "commitName": "4ee3543625c77c06d566fe81644d21c607d6d74d",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "03/06/16 8:55 AM",
      "commitNameOld": "c58a59f7081d55dd2108545ebf9ee48cf43ca944",
      "commitAuthorOld": "Chris Nauroth",
      "daysBetweenCommits": 18.95,
      "commitsBetweenForRepo": 123,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,18 @@\n   private void mergeInputStreamStatistics(InputStreamStatistics statistics) {\n     streamOpenOperations.incr(statistics.openOperations);\n     streamCloseOperations.incr(statistics.closeOperations);\n     streamClosed.incr(statistics.closed);\n     streamAborted.incr(statistics.aborted);\n     streamSeekOperations.incr(statistics.seekOperations);\n     streamReadExceptions.incr(statistics.readExceptions);\n     streamForwardSeekOperations.incr(statistics.forwardSeekOperations);\n     streamBytesSkippedOnSeek.incr(statistics.bytesSkippedOnSeek);\n     streamBackwardSeekOperations.incr(statistics.backwardSeekOperations);\n     streamBytesBackwardsOnSeek.incr(statistics.bytesBackwardsOnSeek);\n     streamBytesRead.incr(statistics.bytesRead);\n     streamReadOperations.incr(statistics.readOperations);\n     streamReadFullyOperations.incr(statistics.readFullyOperations);\n     streamReadsIncomplete.incr(statistics.readsIncomplete);\n+    streamBytesReadInClose.incr(statistics.bytesReadInClose);\n+    streamBytesDiscardedInAbort.incr(statistics.bytesDiscardedInAbort);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void mergeInputStreamStatistics(InputStreamStatistics statistics) {\n    streamOpenOperations.incr(statistics.openOperations);\n    streamCloseOperations.incr(statistics.closeOperations);\n    streamClosed.incr(statistics.closed);\n    streamAborted.incr(statistics.aborted);\n    streamSeekOperations.incr(statistics.seekOperations);\n    streamReadExceptions.incr(statistics.readExceptions);\n    streamForwardSeekOperations.incr(statistics.forwardSeekOperations);\n    streamBytesSkippedOnSeek.incr(statistics.bytesSkippedOnSeek);\n    streamBackwardSeekOperations.incr(statistics.backwardSeekOperations);\n    streamBytesBackwardsOnSeek.incr(statistics.bytesBackwardsOnSeek);\n    streamBytesRead.incr(statistics.bytesRead);\n    streamReadOperations.incr(statistics.readOperations);\n    streamReadFullyOperations.incr(statistics.readFullyOperations);\n    streamReadsIncomplete.incr(statistics.readsIncomplete);\n    streamBytesReadInClose.incr(statistics.bytesReadInClose);\n    streamBytesDiscardedInAbort.incr(statistics.bytesDiscardedInAbort);\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AInstrumentation.java",
      "extendedDetails": {}
    },
    "27c4e90efce04e1b1302f668b5eb22412e00d033": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-13028 add low level counter metrics for S3A; use in read performance tests. contributed by: stevel\npatch includes\nHADOOP-12844 Recover when S3A fails on IOException in read()\nHADOOP-13058 S3A FS fails during init against a read-only FS if multipart purge\nHADOOP-13047 S3a Forward seek in stream length to be configurable\n",
      "commitDate": "12/05/16 11:24 AM",
      "commitName": "27c4e90efce04e1b1302f668b5eb22412e00d033",
      "commitAuthor": "Steve Loughran",
      "diff": "@@ -0,0 +1,16 @@\n+  private void mergeInputStreamStatistics(InputStreamStatistics statistics) {\n+    streamOpenOperations.incr(statistics.openOperations);\n+    streamCloseOperations.incr(statistics.closeOperations);\n+    streamClosed.incr(statistics.closed);\n+    streamAborted.incr(statistics.aborted);\n+    streamSeekOperations.incr(statistics.seekOperations);\n+    streamReadExceptions.incr(statistics.readExceptions);\n+    streamForwardSeekOperations.incr(statistics.forwardSeekOperations);\n+    streamBytesSkippedOnSeek.incr(statistics.bytesSkippedOnSeek);\n+    streamBackwardSeekOperations.incr(statistics.backwardSeekOperations);\n+    streamBytesBackwardsOnSeek.incr(statistics.bytesBackwardsOnSeek);\n+    streamBytesRead.incr(statistics.bytesRead);\n+    streamReadOperations.incr(statistics.readOperations);\n+    streamReadFullyOperations.incr(statistics.readFullyOperations);\n+    streamReadsIncomplete.incr(statistics.readsIncomplete);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void mergeInputStreamStatistics(InputStreamStatistics statistics) {\n    streamOpenOperations.incr(statistics.openOperations);\n    streamCloseOperations.incr(statistics.closeOperations);\n    streamClosed.incr(statistics.closed);\n    streamAborted.incr(statistics.aborted);\n    streamSeekOperations.incr(statistics.seekOperations);\n    streamReadExceptions.incr(statistics.readExceptions);\n    streamForwardSeekOperations.incr(statistics.forwardSeekOperations);\n    streamBytesSkippedOnSeek.incr(statistics.bytesSkippedOnSeek);\n    streamBackwardSeekOperations.incr(statistics.backwardSeekOperations);\n    streamBytesBackwardsOnSeek.incr(statistics.bytesBackwardsOnSeek);\n    streamBytesRead.incr(statistics.bytesRead);\n    streamReadOperations.incr(statistics.readOperations);\n    streamReadFullyOperations.incr(statistics.readFullyOperations);\n    streamReadsIncomplete.incr(statistics.readsIncomplete);\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AInstrumentation.java"
    }
  }
}