{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockReaderLocal.java",
  "functionName": "releaseNoChecksumContext",
  "functionId": "releaseNoChecksumContext",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/client/impl/BlockReaderLocal.java",
  "functionStartLine": 403,
  "functionEndLine": 409,
  "numCommitsSeen": 47,
  "timeTaken": 2610,
  "changeHistory": [
    "f308561f1d885491b88db73ac63003202056d661",
    "e2c9b288b223b9fd82dc12018936e13128413492",
    "463aec11718e47d4aabb86a7a539cb973460aae6",
    "dd049a2f6097da189ccce2f5890a2b9bc77fa73f"
  ],
  "changeHistoryShort": {
    "f308561f1d885491b88db73ac63003202056d661": "Yfilerename",
    "e2c9b288b223b9fd82dc12018936e13128413492": "Yfilerename",
    "463aec11718e47d4aabb86a7a539cb973460aae6": "Ybodychange",
    "dd049a2f6097da189ccce2f5890a2b9bc77fa73f": "Yintroduced"
  },
  "changeHistoryDetails": {
    "f308561f1d885491b88db73ac63003202056d661": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8057 Move BlockReader implementation to the client implementation package.  Contributed by Takanobu Asanuma\n",
      "commitDate": "25/04/16 12:01 PM",
      "commitName": "f308561f1d885491b88db73ac63003202056d661",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "25/04/16 9:38 AM",
      "commitNameOld": "10f0f7851a3255caab775777e8fb6c2781d97062",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 0.1,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private void releaseNoChecksumContext() {\n    if (verifyChecksum) {\n      if (storageType \u003d\u003d null || !storageType.isTransient()) {\n        replica.removeNoChecksumAnchor();\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/client/impl/BlockReaderLocal.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocal.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/client/impl/BlockReaderLocal.java"
      }
    },
    "e2c9b288b223b9fd82dc12018936e13128413492": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8925. Move BlockReaderLocal to hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "28/08/15 2:38 PM",
      "commitName": "e2c9b288b223b9fd82dc12018936e13128413492",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "28/08/15 2:21 PM",
      "commitNameOld": "b94b56806d3d6e04984e229b479f7ac15b62bbfa",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private void releaseNoChecksumContext() {\n    if (verifyChecksum) {\n      if (storageType \u003d\u003d null || !storageType.isTransient()) {\n        replica.removeNoChecksumAnchor();\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocal.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocal.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocal.java"
      }
    },
    "463aec11718e47d4aabb86a7a539cb973460aae6": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6934. Move checksum computation off the hot path when writing to RAM disk. Contributed by Chris Nauroth.\n",
      "commitDate": "27/10/14 9:38 AM",
      "commitName": "463aec11718e47d4aabb86a7a539cb973460aae6",
      "commitAuthor": "cnauroth",
      "commitDateOld": "03/10/14 1:35 PM",
      "commitNameOld": "7f6ed7fe365166e8075359f1d0ad035fa876c70f",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 23.84,
      "commitsBetweenForRepo": 188,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,5 +1,7 @@\n   private void releaseNoChecksumContext() {\n     if (verifyChecksum) {\n-      replica.removeNoChecksumAnchor();\n+      if (storageType \u003d\u003d null || !storageType.isTransient()) {\n+        replica.removeNoChecksumAnchor();\n+      }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void releaseNoChecksumContext() {\n    if (verifyChecksum) {\n      if (storageType \u003d\u003d null || !storageType.isTransient()) {\n        replica.removeNoChecksumAnchor();\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocal.java",
      "extendedDetails": {}
    },
    "dd049a2f6097da189ccce2f5890a2b9bc77fa73f": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-5950. The DFSClient and DataNode should use shared memory segments to communicate short-circuit information (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1573433 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/03/14 7:58 PM",
      "commitName": "dd049a2f6097da189ccce2f5890a2b9bc77fa73f",
      "commitAuthor": "Colin McCabe",
      "diff": "@@ -0,0 +1,5 @@\n+  private void releaseNoChecksumContext() {\n+    if (verifyChecksum) {\n+      replica.removeNoChecksumAnchor();\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void releaseNoChecksumContext() {\n    if (verifyChecksum) {\n      replica.removeNoChecksumAnchor();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocal.java"
    }
  }
}