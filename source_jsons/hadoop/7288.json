{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "EditLogTailer.java",
  "functionName": "doTailEdits",
  "functionId": "doTailEdits",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ha/EditLogTailer.java",
  "functionStartLine": 324,
  "functionEndLine": 384,
  "numCommitsSeen": 51,
  "timeTaken": 6024,
  "changeHistory": [
    "827dbb11e24be294b40088a8aa46086ba8ca4ba8",
    "b5b9b77707933257d446a09f076d594aa170b3d8",
    "8e7548d33be9c4874daab18b2e774bdc2ed216d3",
    "ebe5853a458150b7e42fe7434851bfcbe25e354d",
    "098ec2b11ff3f677eb823f75b147a1ac8dbf959e",
    "dfd807afab0fae3839c9cc5d552aa0304444f956",
    "75ead273bea8a7dad61c4f99c3a16cab2697c498",
    "d8bc523754181b4c1321bcfab886ebf228d9c98f",
    "23b6ed973e1ff5ace1e3a97cded008908e8daa55",
    "74dfa8f1f22d58df64a78c660af111e17ab7053e",
    "706394d03992b394e9f907aff2155df493e4ea4e",
    "641f79a325bad571b11b5700a42efb844eabc5af",
    "c3e62de9ce952aa8572b3cae6a8497b8fdef40aa",
    "d880c7cc784cf636b2590fd98ea7c8ee67065a30",
    "9a07ba8945407cd8f63169faf9e0faa4311d38c7",
    "5b8dcb20a2fad2e7e9dee56c451f68f9d865b5ae",
    "36d1c49486587c2dbb193e8538b1d4510c462fa6",
    "2481474bd9c50a23e4fd2eea67ac2dea11ca1f58"
  ],
  "changeHistoryShort": {
    "827dbb11e24be294b40088a8aa46086ba8ca4ba8": "Ymultichange(Yreturntypechange,Ybodychange)",
    "b5b9b77707933257d446a09f076d594aa170b3d8": "Ymodifierchange",
    "8e7548d33be9c4874daab18b2e774bdc2ed216d3": "Ybodychange",
    "ebe5853a458150b7e42fe7434851bfcbe25e354d": "Ybodychange",
    "098ec2b11ff3f677eb823f75b147a1ac8dbf959e": "Ybodychange",
    "dfd807afab0fae3839c9cc5d552aa0304444f956": "Ybodychange",
    "75ead273bea8a7dad61c4f99c3a16cab2697c498": "Ybodychange",
    "d8bc523754181b4c1321bcfab886ebf228d9c98f": "Ybodychange",
    "23b6ed973e1ff5ace1e3a97cded008908e8daa55": "Ymodifierchange",
    "74dfa8f1f22d58df64a78c660af111e17ab7053e": "Ybodychange",
    "706394d03992b394e9f907aff2155df493e4ea4e": "Ybodychange",
    "641f79a325bad571b11b5700a42efb844eabc5af": "Ybodychange",
    "c3e62de9ce952aa8572b3cae6a8497b8fdef40aa": "Ybodychange",
    "d880c7cc784cf636b2590fd98ea7c8ee67065a30": "Ybodychange",
    "9a07ba8945407cd8f63169faf9e0faa4311d38c7": "Ybodychange",
    "5b8dcb20a2fad2e7e9dee56c451f68f9d865b5ae": "Ybodychange",
    "36d1c49486587c2dbb193e8538b1d4510c462fa6": "Ymultichange(Yexceptionschange,Ybodychange)",
    "2481474bd9c50a23e4fd2eea67ac2dea11ca1f58": "Yintroduced"
  },
  "changeHistoryDetails": {
    "827dbb11e24be294b40088a8aa46086ba8ca4ba8": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-14370. Add exponential backoff to the edit log tailer to avoid spinning on empty edit tail requests. Contributed by Erik Krogen.\n",
      "commitDate": "07/08/19 9:25 AM",
      "commitName": "827dbb11e24be294b40088a8aa46086ba8ca4ba8",
      "commitAuthor": "Erik Krogen",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-14370. Add exponential backoff to the edit log tailer to avoid spinning on empty edit tail requests. Contributed by Erik Krogen.\n",
          "commitDate": "07/08/19 9:25 AM",
          "commitName": "827dbb11e24be294b40088a8aa46086ba8ca4ba8",
          "commitAuthor": "Erik Krogen",
          "commitDateOld": "14/06/19 1:37 PM",
          "commitNameOld": "b24efa11ea2b3ecbae6578058aea89b6823d18d8",
          "commitAuthorOld": "Giovanni Matteo Fumarola",
          "daysBetweenCommits": 53.83,
          "commitsBetweenForRepo": 445,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,60 +1,61 @@\n-  public void doTailEdits() throws IOException, InterruptedException {\n+  public long doTailEdits() throws IOException, InterruptedException {\n     // Write lock needs to be interruptible here because the \n     // transitionToActive RPC takes the write lock before calling\n     // tailer.stop() -- so if we\u0027re not interruptible, it will\n     // deadlock.\n     namesystem.writeLockInterruptibly();\n     try {\n       FSImage image \u003d namesystem.getFSImage();\n \n       long lastTxnId \u003d image.getLastAppliedTxId();\n       \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"lastTxnId: \" + lastTxnId);\n       }\n       Collection\u003cEditLogInputStream\u003e streams;\n       long startTime \u003d Time.monotonicNow();\n       try {\n         streams \u003d editLog.selectInputStreams(lastTxnId + 1, 0,\n             null, inProgressOk, true);\n       } catch (IOException ioe) {\n         // This is acceptable. If we try to tail edits in the middle of an edits\n         // log roll, i.e. the last one has been finalized but the new inprogress\n         // edits file hasn\u0027t been started yet.\n         LOG.warn(\"Edits tailer failed to find any streams. Will try again \" +\n             \"later.\", ioe);\n-        return;\n+        return 0;\n       } finally {\n         NameNode.getNameNodeMetrics().addEditLogFetchTime(\n             Time.monotonicNow() - startTime);\n       }\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"edit streams to load from: \" + streams.size());\n       }\n       \n       // Once we have streams to load, errors encountered are legitimate cause\n       // for concern, so we don\u0027t catch them here. Simple errors reading from\n       // disk are ignored.\n       long editsLoaded \u003d 0;\n       try {\n         editsLoaded \u003d image.loadEdits(\n             streams, namesystem, maxTxnsPerLock, null, null);\n       } catch (EditLogInputException elie) {\n         editsLoaded \u003d elie.getNumEditsLoaded();\n         throw elie;\n       } finally {\n         if (editsLoaded \u003e 0 || LOG.isDebugEnabled()) {\n           LOG.debug(String.format(\"Loaded %d edits starting from txid %d \",\n               editsLoaded, lastTxnId));\n         }\n         NameNode.getNameNodeMetrics().addNumEditLogLoaded(editsLoaded);\n       }\n \n       if (editsLoaded \u003e 0) {\n         lastLoadTimeMs \u003d monotonicNow();\n       }\n       lastLoadedTxnId \u003d image.getLastAppliedTxId();\n+      return editsLoaded;\n     } finally {\n       namesystem.writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public long doTailEdits() throws IOException, InterruptedException {\n    // Write lock needs to be interruptible here because the \n    // transitionToActive RPC takes the write lock before calling\n    // tailer.stop() -- so if we\u0027re not interruptible, it will\n    // deadlock.\n    namesystem.writeLockInterruptibly();\n    try {\n      FSImage image \u003d namesystem.getFSImage();\n\n      long lastTxnId \u003d image.getLastAppliedTxId();\n      \n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"lastTxnId: \" + lastTxnId);\n      }\n      Collection\u003cEditLogInputStream\u003e streams;\n      long startTime \u003d Time.monotonicNow();\n      try {\n        streams \u003d editLog.selectInputStreams(lastTxnId + 1, 0,\n            null, inProgressOk, true);\n      } catch (IOException ioe) {\n        // This is acceptable. If we try to tail edits in the middle of an edits\n        // log roll, i.e. the last one has been finalized but the new inprogress\n        // edits file hasn\u0027t been started yet.\n        LOG.warn(\"Edits tailer failed to find any streams. Will try again \" +\n            \"later.\", ioe);\n        return 0;\n      } finally {\n        NameNode.getNameNodeMetrics().addEditLogFetchTime(\n            Time.monotonicNow() - startTime);\n      }\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"edit streams to load from: \" + streams.size());\n      }\n      \n      // Once we have streams to load, errors encountered are legitimate cause\n      // for concern, so we don\u0027t catch them here. Simple errors reading from\n      // disk are ignored.\n      long editsLoaded \u003d 0;\n      try {\n        editsLoaded \u003d image.loadEdits(\n            streams, namesystem, maxTxnsPerLock, null, null);\n      } catch (EditLogInputException elie) {\n        editsLoaded \u003d elie.getNumEditsLoaded();\n        throw elie;\n      } finally {\n        if (editsLoaded \u003e 0 || LOG.isDebugEnabled()) {\n          LOG.debug(String.format(\"Loaded %d edits starting from txid %d \",\n              editsLoaded, lastTxnId));\n        }\n        NameNode.getNameNodeMetrics().addNumEditLogLoaded(editsLoaded);\n      }\n\n      if (editsLoaded \u003e 0) {\n        lastLoadTimeMs \u003d monotonicNow();\n      }\n      lastLoadedTxnId \u003d image.getLastAppliedTxId();\n      return editsLoaded;\n    } finally {\n      namesystem.writeUnlock();\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ha/EditLogTailer.java",
          "extendedDetails": {
            "oldValue": "void",
            "newValue": "long"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-14370. Add exponential backoff to the edit log tailer to avoid spinning on empty edit tail requests. Contributed by Erik Krogen.\n",
          "commitDate": "07/08/19 9:25 AM",
          "commitName": "827dbb11e24be294b40088a8aa46086ba8ca4ba8",
          "commitAuthor": "Erik Krogen",
          "commitDateOld": "14/06/19 1:37 PM",
          "commitNameOld": "b24efa11ea2b3ecbae6578058aea89b6823d18d8",
          "commitAuthorOld": "Giovanni Matteo Fumarola",
          "daysBetweenCommits": 53.83,
          "commitsBetweenForRepo": 445,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,60 +1,61 @@\n-  public void doTailEdits() throws IOException, InterruptedException {\n+  public long doTailEdits() throws IOException, InterruptedException {\n     // Write lock needs to be interruptible here because the \n     // transitionToActive RPC takes the write lock before calling\n     // tailer.stop() -- so if we\u0027re not interruptible, it will\n     // deadlock.\n     namesystem.writeLockInterruptibly();\n     try {\n       FSImage image \u003d namesystem.getFSImage();\n \n       long lastTxnId \u003d image.getLastAppliedTxId();\n       \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"lastTxnId: \" + lastTxnId);\n       }\n       Collection\u003cEditLogInputStream\u003e streams;\n       long startTime \u003d Time.monotonicNow();\n       try {\n         streams \u003d editLog.selectInputStreams(lastTxnId + 1, 0,\n             null, inProgressOk, true);\n       } catch (IOException ioe) {\n         // This is acceptable. If we try to tail edits in the middle of an edits\n         // log roll, i.e. the last one has been finalized but the new inprogress\n         // edits file hasn\u0027t been started yet.\n         LOG.warn(\"Edits tailer failed to find any streams. Will try again \" +\n             \"later.\", ioe);\n-        return;\n+        return 0;\n       } finally {\n         NameNode.getNameNodeMetrics().addEditLogFetchTime(\n             Time.monotonicNow() - startTime);\n       }\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"edit streams to load from: \" + streams.size());\n       }\n       \n       // Once we have streams to load, errors encountered are legitimate cause\n       // for concern, so we don\u0027t catch them here. Simple errors reading from\n       // disk are ignored.\n       long editsLoaded \u003d 0;\n       try {\n         editsLoaded \u003d image.loadEdits(\n             streams, namesystem, maxTxnsPerLock, null, null);\n       } catch (EditLogInputException elie) {\n         editsLoaded \u003d elie.getNumEditsLoaded();\n         throw elie;\n       } finally {\n         if (editsLoaded \u003e 0 || LOG.isDebugEnabled()) {\n           LOG.debug(String.format(\"Loaded %d edits starting from txid %d \",\n               editsLoaded, lastTxnId));\n         }\n         NameNode.getNameNodeMetrics().addNumEditLogLoaded(editsLoaded);\n       }\n \n       if (editsLoaded \u003e 0) {\n         lastLoadTimeMs \u003d monotonicNow();\n       }\n       lastLoadedTxnId \u003d image.getLastAppliedTxId();\n+      return editsLoaded;\n     } finally {\n       namesystem.writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public long doTailEdits() throws IOException, InterruptedException {\n    // Write lock needs to be interruptible here because the \n    // transitionToActive RPC takes the write lock before calling\n    // tailer.stop() -- so if we\u0027re not interruptible, it will\n    // deadlock.\n    namesystem.writeLockInterruptibly();\n    try {\n      FSImage image \u003d namesystem.getFSImage();\n\n      long lastTxnId \u003d image.getLastAppliedTxId();\n      \n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"lastTxnId: \" + lastTxnId);\n      }\n      Collection\u003cEditLogInputStream\u003e streams;\n      long startTime \u003d Time.monotonicNow();\n      try {\n        streams \u003d editLog.selectInputStreams(lastTxnId + 1, 0,\n            null, inProgressOk, true);\n      } catch (IOException ioe) {\n        // This is acceptable. If we try to tail edits in the middle of an edits\n        // log roll, i.e. the last one has been finalized but the new inprogress\n        // edits file hasn\u0027t been started yet.\n        LOG.warn(\"Edits tailer failed to find any streams. Will try again \" +\n            \"later.\", ioe);\n        return 0;\n      } finally {\n        NameNode.getNameNodeMetrics().addEditLogFetchTime(\n            Time.monotonicNow() - startTime);\n      }\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"edit streams to load from: \" + streams.size());\n      }\n      \n      // Once we have streams to load, errors encountered are legitimate cause\n      // for concern, so we don\u0027t catch them here. Simple errors reading from\n      // disk are ignored.\n      long editsLoaded \u003d 0;\n      try {\n        editsLoaded \u003d image.loadEdits(\n            streams, namesystem, maxTxnsPerLock, null, null);\n      } catch (EditLogInputException elie) {\n        editsLoaded \u003d elie.getNumEditsLoaded();\n        throw elie;\n      } finally {\n        if (editsLoaded \u003e 0 || LOG.isDebugEnabled()) {\n          LOG.debug(String.format(\"Loaded %d edits starting from txid %d \",\n              editsLoaded, lastTxnId));\n        }\n        NameNode.getNameNodeMetrics().addNumEditLogLoaded(editsLoaded);\n      }\n\n      if (editsLoaded \u003e 0) {\n        lastLoadTimeMs \u003d monotonicNow();\n      }\n      lastLoadedTxnId \u003d image.getLastAppliedTxId();\n      return editsLoaded;\n    } finally {\n      namesystem.writeUnlock();\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ha/EditLogTailer.java",
          "extendedDetails": {}
        }
      ]
    },
    "b5b9b77707933257d446a09f076d594aa170b3d8": {
      "type": "Ymodifierchange",
      "commitMessage": "HDFS-13961. [SBN read] TestObserverNode refactoring. Contributed by Konstantin Shvachko.",
      "commitDate": "24/12/18 9:34 AM",
      "commitName": "b5b9b77707933257d446a09f076d594aa170b3d8",
      "commitAuthor": "Konstantin V Shvachko",
      "commitDateOld": "24/12/18 9:33 AM",
      "commitNameOld": "00e99c65943e64fd696ec715cf21e851b93115f1",
      "commitAuthorOld": "Erik Krogen",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 16,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,60 +1,60 @@\n-  void doTailEdits() throws IOException, InterruptedException {\n+  public void doTailEdits() throws IOException, InterruptedException {\n     // Write lock needs to be interruptible here because the \n     // transitionToActive RPC takes the write lock before calling\n     // tailer.stop() -- so if we\u0027re not interruptible, it will\n     // deadlock.\n     namesystem.writeLockInterruptibly();\n     try {\n       FSImage image \u003d namesystem.getFSImage();\n \n       long lastTxnId \u003d image.getLastAppliedTxId();\n       \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"lastTxnId: \" + lastTxnId);\n       }\n       Collection\u003cEditLogInputStream\u003e streams;\n       long startTime \u003d Time.monotonicNow();\n       try {\n         streams \u003d editLog.selectInputStreams(lastTxnId + 1, 0,\n             null, inProgressOk, true);\n       } catch (IOException ioe) {\n         // This is acceptable. If we try to tail edits in the middle of an edits\n         // log roll, i.e. the last one has been finalized but the new inprogress\n         // edits file hasn\u0027t been started yet.\n         LOG.warn(\"Edits tailer failed to find any streams. Will try again \" +\n             \"later.\", ioe);\n         return;\n       } finally {\n         NameNode.getNameNodeMetrics().addEditLogFetchTime(\n             Time.monotonicNow() - startTime);\n       }\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"edit streams to load from: \" + streams.size());\n       }\n       \n       // Once we have streams to load, errors encountered are legitimate cause\n       // for concern, so we don\u0027t catch them here. Simple errors reading from\n       // disk are ignored.\n       long editsLoaded \u003d 0;\n       try {\n         editsLoaded \u003d image.loadEdits(\n             streams, namesystem, maxTxnsPerLock, null, null);\n       } catch (EditLogInputException elie) {\n         editsLoaded \u003d elie.getNumEditsLoaded();\n         throw elie;\n       } finally {\n         if (editsLoaded \u003e 0 || LOG.isDebugEnabled()) {\n           LOG.debug(String.format(\"Loaded %d edits starting from txid %d \",\n               editsLoaded, lastTxnId));\n         }\n         NameNode.getNameNodeMetrics().addNumEditLogLoaded(editsLoaded);\n       }\n \n       if (editsLoaded \u003e 0) {\n         lastLoadTimeMs \u003d monotonicNow();\n       }\n       lastLoadedTxnId \u003d image.getLastAppliedTxId();\n     } finally {\n       namesystem.writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void doTailEdits() throws IOException, InterruptedException {\n    // Write lock needs to be interruptible here because the \n    // transitionToActive RPC takes the write lock before calling\n    // tailer.stop() -- so if we\u0027re not interruptible, it will\n    // deadlock.\n    namesystem.writeLockInterruptibly();\n    try {\n      FSImage image \u003d namesystem.getFSImage();\n\n      long lastTxnId \u003d image.getLastAppliedTxId();\n      \n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"lastTxnId: \" + lastTxnId);\n      }\n      Collection\u003cEditLogInputStream\u003e streams;\n      long startTime \u003d Time.monotonicNow();\n      try {\n        streams \u003d editLog.selectInputStreams(lastTxnId + 1, 0,\n            null, inProgressOk, true);\n      } catch (IOException ioe) {\n        // This is acceptable. If we try to tail edits in the middle of an edits\n        // log roll, i.e. the last one has been finalized but the new inprogress\n        // edits file hasn\u0027t been started yet.\n        LOG.warn(\"Edits tailer failed to find any streams. Will try again \" +\n            \"later.\", ioe);\n        return;\n      } finally {\n        NameNode.getNameNodeMetrics().addEditLogFetchTime(\n            Time.monotonicNow() - startTime);\n      }\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"edit streams to load from: \" + streams.size());\n      }\n      \n      // Once we have streams to load, errors encountered are legitimate cause\n      // for concern, so we don\u0027t catch them here. Simple errors reading from\n      // disk are ignored.\n      long editsLoaded \u003d 0;\n      try {\n        editsLoaded \u003d image.loadEdits(\n            streams, namesystem, maxTxnsPerLock, null, null);\n      } catch (EditLogInputException elie) {\n        editsLoaded \u003d elie.getNumEditsLoaded();\n        throw elie;\n      } finally {\n        if (editsLoaded \u003e 0 || LOG.isDebugEnabled()) {\n          LOG.debug(String.format(\"Loaded %d edits starting from txid %d \",\n              editsLoaded, lastTxnId));\n        }\n        NameNode.getNameNodeMetrics().addNumEditLogLoaded(editsLoaded);\n      }\n\n      if (editsLoaded \u003e 0) {\n        lastLoadTimeMs \u003d monotonicNow();\n      }\n      lastLoadedTxnId \u003d image.getLastAppliedTxId();\n    } finally {\n      namesystem.writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ha/EditLogTailer.java",
      "extendedDetails": {
        "oldValue": "[]",
        "newValue": "[public]"
      }
    },
    "8e7548d33be9c4874daab18b2e774bdc2ed216d3": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13641. Add metrics for edit log tailing. Contributed by Chao Sun.\n",
      "commitDate": "13/06/18 5:05 AM",
      "commitName": "8e7548d33be9c4874daab18b2e774bdc2ed216d3",
      "commitAuthor": "Yiqun Lin",
      "commitDateOld": "31/05/18 2:56 PM",
      "commitNameOld": "ebe5853a458150b7e42fe7434851bfcbe25e354d",
      "commitAuthorOld": "Konstantin V Shvachko",
      "daysBetweenCommits": 12.59,
      "commitsBetweenForRepo": 104,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,55 +1,60 @@\n   void doTailEdits() throws IOException, InterruptedException {\n     // Write lock needs to be interruptible here because the \n     // transitionToActive RPC takes the write lock before calling\n     // tailer.stop() -- so if we\u0027re not interruptible, it will\n     // deadlock.\n     namesystem.writeLockInterruptibly();\n     try {\n       FSImage image \u003d namesystem.getFSImage();\n \n       long lastTxnId \u003d image.getLastAppliedTxId();\n       \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"lastTxnId: \" + lastTxnId);\n       }\n       Collection\u003cEditLogInputStream\u003e streams;\n+      long startTime \u003d Time.monotonicNow();\n       try {\n         streams \u003d editLog.selectInputStreams(lastTxnId + 1, 0,\n             null, inProgressOk, true);\n       } catch (IOException ioe) {\n         // This is acceptable. If we try to tail edits in the middle of an edits\n         // log roll, i.e. the last one has been finalized but the new inprogress\n         // edits file hasn\u0027t been started yet.\n         LOG.warn(\"Edits tailer failed to find any streams. Will try again \" +\n             \"later.\", ioe);\n         return;\n+      } finally {\n+        NameNode.getNameNodeMetrics().addEditLogFetchTime(\n+            Time.monotonicNow() - startTime);\n       }\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"edit streams to load from: \" + streams.size());\n       }\n       \n       // Once we have streams to load, errors encountered are legitimate cause\n       // for concern, so we don\u0027t catch them here. Simple errors reading from\n       // disk are ignored.\n       long editsLoaded \u003d 0;\n       try {\n         editsLoaded \u003d image.loadEdits(\n             streams, namesystem, maxTxnsPerLock, null, null);\n       } catch (EditLogInputException elie) {\n         editsLoaded \u003d elie.getNumEditsLoaded();\n         throw elie;\n       } finally {\n         if (editsLoaded \u003e 0 || LOG.isDebugEnabled()) {\n           LOG.debug(String.format(\"Loaded %d edits starting from txid %d \",\n               editsLoaded, lastTxnId));\n         }\n+        NameNode.getNameNodeMetrics().addNumEditLogLoaded(editsLoaded);\n       }\n \n       if (editsLoaded \u003e 0) {\n         lastLoadTimeMs \u003d monotonicNow();\n       }\n       lastLoadedTxnId \u003d image.getLastAppliedTxId();\n     } finally {\n       namesystem.writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void doTailEdits() throws IOException, InterruptedException {\n    // Write lock needs to be interruptible here because the \n    // transitionToActive RPC takes the write lock before calling\n    // tailer.stop() -- so if we\u0027re not interruptible, it will\n    // deadlock.\n    namesystem.writeLockInterruptibly();\n    try {\n      FSImage image \u003d namesystem.getFSImage();\n\n      long lastTxnId \u003d image.getLastAppliedTxId();\n      \n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"lastTxnId: \" + lastTxnId);\n      }\n      Collection\u003cEditLogInputStream\u003e streams;\n      long startTime \u003d Time.monotonicNow();\n      try {\n        streams \u003d editLog.selectInputStreams(lastTxnId + 1, 0,\n            null, inProgressOk, true);\n      } catch (IOException ioe) {\n        // This is acceptable. If we try to tail edits in the middle of an edits\n        // log roll, i.e. the last one has been finalized but the new inprogress\n        // edits file hasn\u0027t been started yet.\n        LOG.warn(\"Edits tailer failed to find any streams. Will try again \" +\n            \"later.\", ioe);\n        return;\n      } finally {\n        NameNode.getNameNodeMetrics().addEditLogFetchTime(\n            Time.monotonicNow() - startTime);\n      }\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"edit streams to load from: \" + streams.size());\n      }\n      \n      // Once we have streams to load, errors encountered are legitimate cause\n      // for concern, so we don\u0027t catch them here. Simple errors reading from\n      // disk are ignored.\n      long editsLoaded \u003d 0;\n      try {\n        editsLoaded \u003d image.loadEdits(\n            streams, namesystem, maxTxnsPerLock, null, null);\n      } catch (EditLogInputException elie) {\n        editsLoaded \u003d elie.getNumEditsLoaded();\n        throw elie;\n      } finally {\n        if (editsLoaded \u003e 0 || LOG.isDebugEnabled()) {\n          LOG.debug(String.format(\"Loaded %d edits starting from txid %d \",\n              editsLoaded, lastTxnId));\n        }\n        NameNode.getNameNodeMetrics().addNumEditLogLoaded(editsLoaded);\n      }\n\n      if (editsLoaded \u003e 0) {\n        lastLoadTimeMs \u003d monotonicNow();\n      }\n      lastLoadedTxnId \u003d image.getLastAppliedTxId();\n    } finally {\n      namesystem.writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ha/EditLogTailer.java",
      "extendedDetails": {}
    },
    "ebe5853a458150b7e42fe7434851bfcbe25e354d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12978. Fine-grained locking while consuming journal stream. Contributed by Konstantin Shvachko.",
      "commitDate": "31/05/18 2:56 PM",
      "commitName": "ebe5853a458150b7e42fe7434851bfcbe25e354d",
      "commitAuthor": "Konstantin V Shvachko",
      "commitDateOld": "14/09/17 11:17 AM",
      "commitNameOld": "65a941008d4bbf906772399d3f035f2a0da5abfa",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 259.15,
      "commitsBetweenForRepo": 2439,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,54 +1,55 @@\n   void doTailEdits() throws IOException, InterruptedException {\n     // Write lock needs to be interruptible here because the \n     // transitionToActive RPC takes the write lock before calling\n     // tailer.stop() -- so if we\u0027re not interruptible, it will\n     // deadlock.\n     namesystem.writeLockInterruptibly();\n     try {\n       FSImage image \u003d namesystem.getFSImage();\n \n       long lastTxnId \u003d image.getLastAppliedTxId();\n       \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"lastTxnId: \" + lastTxnId);\n       }\n       Collection\u003cEditLogInputStream\u003e streams;\n       try {\n         streams \u003d editLog.selectInputStreams(lastTxnId + 1, 0,\n             null, inProgressOk, true);\n       } catch (IOException ioe) {\n         // This is acceptable. If we try to tail edits in the middle of an edits\n         // log roll, i.e. the last one has been finalized but the new inprogress\n         // edits file hasn\u0027t been started yet.\n         LOG.warn(\"Edits tailer failed to find any streams. Will try again \" +\n             \"later.\", ioe);\n         return;\n       }\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"edit streams to load from: \" + streams.size());\n       }\n       \n       // Once we have streams to load, errors encountered are legitimate cause\n       // for concern, so we don\u0027t catch them here. Simple errors reading from\n       // disk are ignored.\n       long editsLoaded \u003d 0;\n       try {\n-        editsLoaded \u003d image.loadEdits(streams, namesystem);\n+        editsLoaded \u003d image.loadEdits(\n+            streams, namesystem, maxTxnsPerLock, null, null);\n       } catch (EditLogInputException elie) {\n         editsLoaded \u003d elie.getNumEditsLoaded();\n         throw elie;\n       } finally {\n         if (editsLoaded \u003e 0 || LOG.isDebugEnabled()) {\n           LOG.debug(String.format(\"Loaded %d edits starting from txid %d \",\n               editsLoaded, lastTxnId));\n         }\n       }\n \n       if (editsLoaded \u003e 0) {\n         lastLoadTimeMs \u003d monotonicNow();\n       }\n       lastLoadedTxnId \u003d image.getLastAppliedTxId();\n     } finally {\n       namesystem.writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void doTailEdits() throws IOException, InterruptedException {\n    // Write lock needs to be interruptible here because the \n    // transitionToActive RPC takes the write lock before calling\n    // tailer.stop() -- so if we\u0027re not interruptible, it will\n    // deadlock.\n    namesystem.writeLockInterruptibly();\n    try {\n      FSImage image \u003d namesystem.getFSImage();\n\n      long lastTxnId \u003d image.getLastAppliedTxId();\n      \n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"lastTxnId: \" + lastTxnId);\n      }\n      Collection\u003cEditLogInputStream\u003e streams;\n      try {\n        streams \u003d editLog.selectInputStreams(lastTxnId + 1, 0,\n            null, inProgressOk, true);\n      } catch (IOException ioe) {\n        // This is acceptable. If we try to tail edits in the middle of an edits\n        // log roll, i.e. the last one has been finalized but the new inprogress\n        // edits file hasn\u0027t been started yet.\n        LOG.warn(\"Edits tailer failed to find any streams. Will try again \" +\n            \"later.\", ioe);\n        return;\n      }\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"edit streams to load from: \" + streams.size());\n      }\n      \n      // Once we have streams to load, errors encountered are legitimate cause\n      // for concern, so we don\u0027t catch them here. Simple errors reading from\n      // disk are ignored.\n      long editsLoaded \u003d 0;\n      try {\n        editsLoaded \u003d image.loadEdits(\n            streams, namesystem, maxTxnsPerLock, null, null);\n      } catch (EditLogInputException elie) {\n        editsLoaded \u003d elie.getNumEditsLoaded();\n        throw elie;\n      } finally {\n        if (editsLoaded \u003e 0 || LOG.isDebugEnabled()) {\n          LOG.debug(String.format(\"Loaded %d edits starting from txid %d \",\n              editsLoaded, lastTxnId));\n        }\n      }\n\n      if (editsLoaded \u003e 0) {\n        lastLoadTimeMs \u003d monotonicNow();\n      }\n      lastLoadedTxnId \u003d image.getLastAppliedTxId();\n    } finally {\n      namesystem.writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ha/EditLogTailer.java",
      "extendedDetails": {}
    },
    "098ec2b11ff3f677eb823f75b147a1ac8dbf959e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10519. Add a configuration option to enable in-progress edit log tailing. Contributed by Jiayi Zhou.\n",
      "commitDate": "27/07/16 5:55 PM",
      "commitName": "098ec2b11ff3f677eb823f75b147a1ac8dbf959e",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "26/06/16 3:15 AM",
      "commitNameOld": "73615a789d96292e2731b5aa33ce46aa004d8211",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 31.61,
      "commitsBetweenForRepo": 296,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,53 +1,54 @@\n   void doTailEdits() throws IOException, InterruptedException {\n     // Write lock needs to be interruptible here because the \n     // transitionToActive RPC takes the write lock before calling\n     // tailer.stop() -- so if we\u0027re not interruptible, it will\n     // deadlock.\n     namesystem.writeLockInterruptibly();\n     try {\n       FSImage image \u003d namesystem.getFSImage();\n \n       long lastTxnId \u003d image.getLastAppliedTxId();\n       \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"lastTxnId: \" + lastTxnId);\n       }\n       Collection\u003cEditLogInputStream\u003e streams;\n       try {\n-        streams \u003d editLog.selectInputStreams(lastTxnId + 1, 0, null, false);\n+        streams \u003d editLog.selectInputStreams(lastTxnId + 1, 0,\n+            null, inProgressOk, true);\n       } catch (IOException ioe) {\n         // This is acceptable. If we try to tail edits in the middle of an edits\n         // log roll, i.e. the last one has been finalized but the new inprogress\n         // edits file hasn\u0027t been started yet.\n         LOG.warn(\"Edits tailer failed to find any streams. Will try again \" +\n             \"later.\", ioe);\n         return;\n       }\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"edit streams to load from: \" + streams.size());\n       }\n       \n       // Once we have streams to load, errors encountered are legitimate cause\n       // for concern, so we don\u0027t catch them here. Simple errors reading from\n       // disk are ignored.\n       long editsLoaded \u003d 0;\n       try {\n         editsLoaded \u003d image.loadEdits(streams, namesystem);\n       } catch (EditLogInputException elie) {\n         editsLoaded \u003d elie.getNumEditsLoaded();\n         throw elie;\n       } finally {\n         if (editsLoaded \u003e 0 || LOG.isDebugEnabled()) {\n           LOG.debug(String.format(\"Loaded %d edits starting from txid %d \",\n               editsLoaded, lastTxnId));\n         }\n       }\n \n       if (editsLoaded \u003e 0) {\n         lastLoadTimeMs \u003d monotonicNow();\n       }\n       lastLoadedTxnId \u003d image.getLastAppliedTxId();\n     } finally {\n       namesystem.writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void doTailEdits() throws IOException, InterruptedException {\n    // Write lock needs to be interruptible here because the \n    // transitionToActive RPC takes the write lock before calling\n    // tailer.stop() -- so if we\u0027re not interruptible, it will\n    // deadlock.\n    namesystem.writeLockInterruptibly();\n    try {\n      FSImage image \u003d namesystem.getFSImage();\n\n      long lastTxnId \u003d image.getLastAppliedTxId();\n      \n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"lastTxnId: \" + lastTxnId);\n      }\n      Collection\u003cEditLogInputStream\u003e streams;\n      try {\n        streams \u003d editLog.selectInputStreams(lastTxnId + 1, 0,\n            null, inProgressOk, true);\n      } catch (IOException ioe) {\n        // This is acceptable. If we try to tail edits in the middle of an edits\n        // log roll, i.e. the last one has been finalized but the new inprogress\n        // edits file hasn\u0027t been started yet.\n        LOG.warn(\"Edits tailer failed to find any streams. Will try again \" +\n            \"later.\", ioe);\n        return;\n      }\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"edit streams to load from: \" + streams.size());\n      }\n      \n      // Once we have streams to load, errors encountered are legitimate cause\n      // for concern, so we don\u0027t catch them here. Simple errors reading from\n      // disk are ignored.\n      long editsLoaded \u003d 0;\n      try {\n        editsLoaded \u003d image.loadEdits(streams, namesystem);\n      } catch (EditLogInputException elie) {\n        editsLoaded \u003d elie.getNumEditsLoaded();\n        throw elie;\n      } finally {\n        if (editsLoaded \u003e 0 || LOG.isDebugEnabled()) {\n          LOG.debug(String.format(\"Loaded %d edits starting from txid %d \",\n              editsLoaded, lastTxnId));\n        }\n      }\n\n      if (editsLoaded \u003e 0) {\n        lastLoadTimeMs \u003d monotonicNow();\n      }\n      lastLoadedTxnId \u003d image.getLastAppliedTxId();\n    } finally {\n      namesystem.writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ha/EditLogTailer.java",
      "extendedDetails": {}
    },
    "dfd807afab0fae3839c9cc5d552aa0304444f956": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-12428. Fix inconsistency between log-level guards and statements. Contributed by Jagadesh Kiran N and Jackie Chang.\n",
      "commitDate": "21/09/15 8:54 PM",
      "commitName": "dfd807afab0fae3839c9cc5d552aa0304444f956",
      "commitAuthor": "Tsuyoshi Ozawa",
      "commitDateOld": "23/06/15 5:26 PM",
      "commitNameOld": "49dfad942970459297f72632ed8dfd353e0c86de",
      "commitAuthorOld": "Aaron T. Myers",
      "daysBetweenCommits": 90.14,
      "commitsBetweenForRepo": 531,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,53 +1,53 @@\n   void doTailEdits() throws IOException, InterruptedException {\n     // Write lock needs to be interruptible here because the \n     // transitionToActive RPC takes the write lock before calling\n     // tailer.stop() -- so if we\u0027re not interruptible, it will\n     // deadlock.\n     namesystem.writeLockInterruptibly();\n     try {\n       FSImage image \u003d namesystem.getFSImage();\n \n       long lastTxnId \u003d image.getLastAppliedTxId();\n       \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"lastTxnId: \" + lastTxnId);\n       }\n       Collection\u003cEditLogInputStream\u003e streams;\n       try {\n         streams \u003d editLog.selectInputStreams(lastTxnId + 1, 0, null, false);\n       } catch (IOException ioe) {\n         // This is acceptable. If we try to tail edits in the middle of an edits\n         // log roll, i.e. the last one has been finalized but the new inprogress\n         // edits file hasn\u0027t been started yet.\n         LOG.warn(\"Edits tailer failed to find any streams. Will try again \" +\n             \"later.\", ioe);\n         return;\n       }\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"edit streams to load from: \" + streams.size());\n       }\n       \n       // Once we have streams to load, errors encountered are legitimate cause\n       // for concern, so we don\u0027t catch them here. Simple errors reading from\n       // disk are ignored.\n       long editsLoaded \u003d 0;\n       try {\n         editsLoaded \u003d image.loadEdits(streams, namesystem);\n       } catch (EditLogInputException elie) {\n         editsLoaded \u003d elie.getNumEditsLoaded();\n         throw elie;\n       } finally {\n         if (editsLoaded \u003e 0 || LOG.isDebugEnabled()) {\n-          LOG.info(String.format(\"Loaded %d edits starting from txid %d \",\n+          LOG.debug(String.format(\"Loaded %d edits starting from txid %d \",\n               editsLoaded, lastTxnId));\n         }\n       }\n \n       if (editsLoaded \u003e 0) {\n         lastLoadTimeMs \u003d monotonicNow();\n       }\n       lastLoadedTxnId \u003d image.getLastAppliedTxId();\n     } finally {\n       namesystem.writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void doTailEdits() throws IOException, InterruptedException {\n    // Write lock needs to be interruptible here because the \n    // transitionToActive RPC takes the write lock before calling\n    // tailer.stop() -- so if we\u0027re not interruptible, it will\n    // deadlock.\n    namesystem.writeLockInterruptibly();\n    try {\n      FSImage image \u003d namesystem.getFSImage();\n\n      long lastTxnId \u003d image.getLastAppliedTxId();\n      \n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"lastTxnId: \" + lastTxnId);\n      }\n      Collection\u003cEditLogInputStream\u003e streams;\n      try {\n        streams \u003d editLog.selectInputStreams(lastTxnId + 1, 0, null, false);\n      } catch (IOException ioe) {\n        // This is acceptable. If we try to tail edits in the middle of an edits\n        // log roll, i.e. the last one has been finalized but the new inprogress\n        // edits file hasn\u0027t been started yet.\n        LOG.warn(\"Edits tailer failed to find any streams. Will try again \" +\n            \"later.\", ioe);\n        return;\n      }\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"edit streams to load from: \" + streams.size());\n      }\n      \n      // Once we have streams to load, errors encountered are legitimate cause\n      // for concern, so we don\u0027t catch them here. Simple errors reading from\n      // disk are ignored.\n      long editsLoaded \u003d 0;\n      try {\n        editsLoaded \u003d image.loadEdits(streams, namesystem);\n      } catch (EditLogInputException elie) {\n        editsLoaded \u003d elie.getNumEditsLoaded();\n        throw elie;\n      } finally {\n        if (editsLoaded \u003e 0 || LOG.isDebugEnabled()) {\n          LOG.debug(String.format(\"Loaded %d edits starting from txid %d \",\n              editsLoaded, lastTxnId));\n        }\n      }\n\n      if (editsLoaded \u003e 0) {\n        lastLoadTimeMs \u003d monotonicNow();\n      }\n      lastLoadedTxnId \u003d image.getLastAppliedTxId();\n    } finally {\n      namesystem.writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ha/EditLogTailer.java",
      "extendedDetails": {}
    },
    "75ead273bea8a7dad61c4f99c3a16cab2697c498": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6841. Use Time.monotonicNow() wherever applicable instead of Time.now(). Contributed by Vinayakumar B\n",
      "commitDate": "20/03/15 12:02 PM",
      "commitName": "75ead273bea8a7dad61c4f99c3a16cab2697c498",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "25/11/14 3:37 PM",
      "commitNameOld": "f43a20c529ac3f104add95b222de6580757b3763",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 114.81,
      "commitsBetweenForRepo": 883,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,53 +1,53 @@\n   void doTailEdits() throws IOException, InterruptedException {\n     // Write lock needs to be interruptible here because the \n     // transitionToActive RPC takes the write lock before calling\n     // tailer.stop() -- so if we\u0027re not interruptible, it will\n     // deadlock.\n     namesystem.writeLockInterruptibly();\n     try {\n       FSImage image \u003d namesystem.getFSImage();\n \n       long lastTxnId \u003d image.getLastAppliedTxId();\n       \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"lastTxnId: \" + lastTxnId);\n       }\n       Collection\u003cEditLogInputStream\u003e streams;\n       try {\n         streams \u003d editLog.selectInputStreams(lastTxnId + 1, 0, null, false);\n       } catch (IOException ioe) {\n         // This is acceptable. If we try to tail edits in the middle of an edits\n         // log roll, i.e. the last one has been finalized but the new inprogress\n         // edits file hasn\u0027t been started yet.\n         LOG.warn(\"Edits tailer failed to find any streams. Will try again \" +\n             \"later.\", ioe);\n         return;\n       }\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"edit streams to load from: \" + streams.size());\n       }\n       \n       // Once we have streams to load, errors encountered are legitimate cause\n       // for concern, so we don\u0027t catch them here. Simple errors reading from\n       // disk are ignored.\n       long editsLoaded \u003d 0;\n       try {\n         editsLoaded \u003d image.loadEdits(streams, namesystem);\n       } catch (EditLogInputException elie) {\n         editsLoaded \u003d elie.getNumEditsLoaded();\n         throw elie;\n       } finally {\n         if (editsLoaded \u003e 0 || LOG.isDebugEnabled()) {\n           LOG.info(String.format(\"Loaded %d edits starting from txid %d \",\n               editsLoaded, lastTxnId));\n         }\n       }\n \n       if (editsLoaded \u003e 0) {\n-        lastLoadTimestamp \u003d now();\n+        lastLoadTimeMs \u003d monotonicNow();\n       }\n       lastLoadedTxnId \u003d image.getLastAppliedTxId();\n     } finally {\n       namesystem.writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void doTailEdits() throws IOException, InterruptedException {\n    // Write lock needs to be interruptible here because the \n    // transitionToActive RPC takes the write lock before calling\n    // tailer.stop() -- so if we\u0027re not interruptible, it will\n    // deadlock.\n    namesystem.writeLockInterruptibly();\n    try {\n      FSImage image \u003d namesystem.getFSImage();\n\n      long lastTxnId \u003d image.getLastAppliedTxId();\n      \n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"lastTxnId: \" + lastTxnId);\n      }\n      Collection\u003cEditLogInputStream\u003e streams;\n      try {\n        streams \u003d editLog.selectInputStreams(lastTxnId + 1, 0, null, false);\n      } catch (IOException ioe) {\n        // This is acceptable. If we try to tail edits in the middle of an edits\n        // log roll, i.e. the last one has been finalized but the new inprogress\n        // edits file hasn\u0027t been started yet.\n        LOG.warn(\"Edits tailer failed to find any streams. Will try again \" +\n            \"later.\", ioe);\n        return;\n      }\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"edit streams to load from: \" + streams.size());\n      }\n      \n      // Once we have streams to load, errors encountered are legitimate cause\n      // for concern, so we don\u0027t catch them here. Simple errors reading from\n      // disk are ignored.\n      long editsLoaded \u003d 0;\n      try {\n        editsLoaded \u003d image.loadEdits(streams, namesystem);\n      } catch (EditLogInputException elie) {\n        editsLoaded \u003d elie.getNumEditsLoaded();\n        throw elie;\n      } finally {\n        if (editsLoaded \u003e 0 || LOG.isDebugEnabled()) {\n          LOG.info(String.format(\"Loaded %d edits starting from txid %d \",\n              editsLoaded, lastTxnId));\n        }\n      }\n\n      if (editsLoaded \u003e 0) {\n        lastLoadTimeMs \u003d monotonicNow();\n      }\n      lastLoadedTxnId \u003d image.getLastAppliedTxId();\n    } finally {\n      namesystem.writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ha/EditLogTailer.java",
      "extendedDetails": {}
    },
    "d8bc523754181b4c1321bcfab886ebf228d9c98f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5753. Add new NN startup options for downgrade and rollback using upgrade marker.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535@1559907 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/01/14 6:38 PM",
      "commitName": "d8bc523754181b4c1321bcfab886ebf228d9c98f",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "10/12/13 5:32 PM",
      "commitNameOld": "512a18a8d92305a34f3037064ceabdc5aff1f8bf",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 41.05,
      "commitsBetweenForRepo": 194,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,53 +1,53 @@\n   void doTailEdits() throws IOException, InterruptedException {\n     // Write lock needs to be interruptible here because the \n     // transitionToActive RPC takes the write lock before calling\n     // tailer.stop() -- so if we\u0027re not interruptible, it will\n     // deadlock.\n     namesystem.writeLockInterruptibly();\n     try {\n       FSImage image \u003d namesystem.getFSImage();\n \n       long lastTxnId \u003d image.getLastAppliedTxId();\n       \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"lastTxnId: \" + lastTxnId);\n       }\n       Collection\u003cEditLogInputStream\u003e streams;\n       try {\n         streams \u003d editLog.selectInputStreams(lastTxnId + 1, 0, null, false);\n       } catch (IOException ioe) {\n         // This is acceptable. If we try to tail edits in the middle of an edits\n         // log roll, i.e. the last one has been finalized but the new inprogress\n         // edits file hasn\u0027t been started yet.\n         LOG.warn(\"Edits tailer failed to find any streams. Will try again \" +\n             \"later.\", ioe);\n         return;\n       }\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"edit streams to load from: \" + streams.size());\n       }\n       \n       // Once we have streams to load, errors encountered are legitimate cause\n       // for concern, so we don\u0027t catch them here. Simple errors reading from\n       // disk are ignored.\n       long editsLoaded \u003d 0;\n       try {\n-        editsLoaded \u003d image.loadEdits(streams, namesystem, null);\n+        editsLoaded \u003d image.loadEdits(streams, namesystem);\n       } catch (EditLogInputException elie) {\n         editsLoaded \u003d elie.getNumEditsLoaded();\n         throw elie;\n       } finally {\n         if (editsLoaded \u003e 0 || LOG.isDebugEnabled()) {\n           LOG.info(String.format(\"Loaded %d edits starting from txid %d \",\n               editsLoaded, lastTxnId));\n         }\n       }\n \n       if (editsLoaded \u003e 0) {\n         lastLoadTimestamp \u003d now();\n       }\n       lastLoadedTxnId \u003d image.getLastAppliedTxId();\n     } finally {\n       namesystem.writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void doTailEdits() throws IOException, InterruptedException {\n    // Write lock needs to be interruptible here because the \n    // transitionToActive RPC takes the write lock before calling\n    // tailer.stop() -- so if we\u0027re not interruptible, it will\n    // deadlock.\n    namesystem.writeLockInterruptibly();\n    try {\n      FSImage image \u003d namesystem.getFSImage();\n\n      long lastTxnId \u003d image.getLastAppliedTxId();\n      \n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"lastTxnId: \" + lastTxnId);\n      }\n      Collection\u003cEditLogInputStream\u003e streams;\n      try {\n        streams \u003d editLog.selectInputStreams(lastTxnId + 1, 0, null, false);\n      } catch (IOException ioe) {\n        // This is acceptable. If we try to tail edits in the middle of an edits\n        // log roll, i.e. the last one has been finalized but the new inprogress\n        // edits file hasn\u0027t been started yet.\n        LOG.warn(\"Edits tailer failed to find any streams. Will try again \" +\n            \"later.\", ioe);\n        return;\n      }\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"edit streams to load from: \" + streams.size());\n      }\n      \n      // Once we have streams to load, errors encountered are legitimate cause\n      // for concern, so we don\u0027t catch them here. Simple errors reading from\n      // disk are ignored.\n      long editsLoaded \u003d 0;\n      try {\n        editsLoaded \u003d image.loadEdits(streams, namesystem);\n      } catch (EditLogInputException elie) {\n        editsLoaded \u003d elie.getNumEditsLoaded();\n        throw elie;\n      } finally {\n        if (editsLoaded \u003e 0 || LOG.isDebugEnabled()) {\n          LOG.info(String.format(\"Loaded %d edits starting from txid %d \",\n              editsLoaded, lastTxnId));\n        }\n      }\n\n      if (editsLoaded \u003e 0) {\n        lastLoadTimestamp \u003d now();\n      }\n      lastLoadedTxnId \u003d image.getLastAppliedTxId();\n    } finally {\n      namesystem.writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ha/EditLogTailer.java",
      "extendedDetails": {}
    },
    "23b6ed973e1ff5ace1e3a97cded008908e8daa55": {
      "type": "Ymodifierchange",
      "commitMessage": "HDFS-3605. Block mistakenly marked corrupt during edit log catchup phase of failover. Contributed by Todd Lipcon and Brahma Reddy Battula.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1363175 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/07/12 4:42 PM",
      "commitName": "23b6ed973e1ff5ace1e3a97cded008908e8daa55",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "16/07/12 2:26 PM",
      "commitNameOld": "527933f4f351a3df5e369c8bb6e2cfc4937e0836",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 2.09,
      "commitsBetweenForRepo": 19,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,53 +1,53 @@\n-  private void doTailEdits() throws IOException, InterruptedException {\n+  void doTailEdits() throws IOException, InterruptedException {\n     // Write lock needs to be interruptible here because the \n     // transitionToActive RPC takes the write lock before calling\n     // tailer.stop() -- so if we\u0027re not interruptible, it will\n     // deadlock.\n     namesystem.writeLockInterruptibly();\n     try {\n       FSImage image \u003d namesystem.getFSImage();\n \n       long lastTxnId \u003d image.getLastAppliedTxId();\n       \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"lastTxnId: \" + lastTxnId);\n       }\n       Collection\u003cEditLogInputStream\u003e streams;\n       try {\n         streams \u003d editLog.selectInputStreams(lastTxnId + 1, 0, null, false);\n       } catch (IOException ioe) {\n         // This is acceptable. If we try to tail edits in the middle of an edits\n         // log roll, i.e. the last one has been finalized but the new inprogress\n         // edits file hasn\u0027t been started yet.\n         LOG.warn(\"Edits tailer failed to find any streams. Will try again \" +\n             \"later.\", ioe);\n         return;\n       }\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"edit streams to load from: \" + streams.size());\n       }\n       \n       // Once we have streams to load, errors encountered are legitimate cause\n       // for concern, so we don\u0027t catch them here. Simple errors reading from\n       // disk are ignored.\n       long editsLoaded \u003d 0;\n       try {\n         editsLoaded \u003d image.loadEdits(streams, namesystem, null);\n       } catch (EditLogInputException elie) {\n         editsLoaded \u003d elie.getNumEditsLoaded();\n         throw elie;\n       } finally {\n         if (editsLoaded \u003e 0 || LOG.isDebugEnabled()) {\n           LOG.info(String.format(\"Loaded %d edits starting from txid %d \",\n               editsLoaded, lastTxnId));\n         }\n       }\n \n       if (editsLoaded \u003e 0) {\n         lastLoadTimestamp \u003d now();\n       }\n       lastLoadedTxnId \u003d image.getLastAppliedTxId();\n     } finally {\n       namesystem.writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void doTailEdits() throws IOException, InterruptedException {\n    // Write lock needs to be interruptible here because the \n    // transitionToActive RPC takes the write lock before calling\n    // tailer.stop() -- so if we\u0027re not interruptible, it will\n    // deadlock.\n    namesystem.writeLockInterruptibly();\n    try {\n      FSImage image \u003d namesystem.getFSImage();\n\n      long lastTxnId \u003d image.getLastAppliedTxId();\n      \n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"lastTxnId: \" + lastTxnId);\n      }\n      Collection\u003cEditLogInputStream\u003e streams;\n      try {\n        streams \u003d editLog.selectInputStreams(lastTxnId + 1, 0, null, false);\n      } catch (IOException ioe) {\n        // This is acceptable. If we try to tail edits in the middle of an edits\n        // log roll, i.e. the last one has been finalized but the new inprogress\n        // edits file hasn\u0027t been started yet.\n        LOG.warn(\"Edits tailer failed to find any streams. Will try again \" +\n            \"later.\", ioe);\n        return;\n      }\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"edit streams to load from: \" + streams.size());\n      }\n      \n      // Once we have streams to load, errors encountered are legitimate cause\n      // for concern, so we don\u0027t catch them here. Simple errors reading from\n      // disk are ignored.\n      long editsLoaded \u003d 0;\n      try {\n        editsLoaded \u003d image.loadEdits(streams, namesystem, null);\n      } catch (EditLogInputException elie) {\n        editsLoaded \u003d elie.getNumEditsLoaded();\n        throw elie;\n      } finally {\n        if (editsLoaded \u003e 0 || LOG.isDebugEnabled()) {\n          LOG.info(String.format(\"Loaded %d edits starting from txid %d \",\n              editsLoaded, lastTxnId));\n        }\n      }\n\n      if (editsLoaded \u003e 0) {\n        lastLoadTimestamp \u003d now();\n      }\n      lastLoadedTxnId \u003d image.getLastAppliedTxId();\n    } finally {\n      namesystem.writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ha/EditLogTailer.java",
      "extendedDetails": {
        "oldValue": "[private]",
        "newValue": "[]"
      }
    },
    "74dfa8f1f22d58df64a78c660af111e17ab7053e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2982. Startup performance suffers when there are many edit log segments. Contributed by Colin Patrick McCabe.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1342042 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "23/05/12 1:42 PM",
      "commitName": "74dfa8f1f22d58df64a78c660af111e17ab7053e",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "09/04/12 12:39 PM",
      "commitNameOld": "706394d03992b394e9f907aff2155df493e4ea4e",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 44.04,
      "commitsBetweenForRepo": 290,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,53 +1,53 @@\n   private void doTailEdits() throws IOException, InterruptedException {\n     // Write lock needs to be interruptible here because the \n     // transitionToActive RPC takes the write lock before calling\n     // tailer.stop() -- so if we\u0027re not interruptible, it will\n     // deadlock.\n     namesystem.writeLockInterruptibly();\n     try {\n       FSImage image \u003d namesystem.getFSImage();\n \n       long lastTxnId \u003d image.getLastAppliedTxId();\n       \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"lastTxnId: \" + lastTxnId);\n       }\n       Collection\u003cEditLogInputStream\u003e streams;\n       try {\n-        streams \u003d editLog.selectInputStreams(lastTxnId + 1, 0, false);\n+        streams \u003d editLog.selectInputStreams(lastTxnId + 1, 0, null, false);\n       } catch (IOException ioe) {\n         // This is acceptable. If we try to tail edits in the middle of an edits\n         // log roll, i.e. the last one has been finalized but the new inprogress\n         // edits file hasn\u0027t been started yet.\n         LOG.warn(\"Edits tailer failed to find any streams. Will try again \" +\n             \"later.\", ioe);\n         return;\n       }\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"edit streams to load from: \" + streams.size());\n       }\n       \n       // Once we have streams to load, errors encountered are legitimate cause\n       // for concern, so we don\u0027t catch them here. Simple errors reading from\n       // disk are ignored.\n       long editsLoaded \u003d 0;\n       try {\n         editsLoaded \u003d image.loadEdits(streams, namesystem, null);\n       } catch (EditLogInputException elie) {\n         editsLoaded \u003d elie.getNumEditsLoaded();\n         throw elie;\n       } finally {\n         if (editsLoaded \u003e 0 || LOG.isDebugEnabled()) {\n           LOG.info(String.format(\"Loaded %d edits starting from txid %d \",\n               editsLoaded, lastTxnId));\n         }\n       }\n \n       if (editsLoaded \u003e 0) {\n         lastLoadTimestamp \u003d now();\n       }\n       lastLoadedTxnId \u003d image.getLastAppliedTxId();\n     } finally {\n       namesystem.writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void doTailEdits() throws IOException, InterruptedException {\n    // Write lock needs to be interruptible here because the \n    // transitionToActive RPC takes the write lock before calling\n    // tailer.stop() -- so if we\u0027re not interruptible, it will\n    // deadlock.\n    namesystem.writeLockInterruptibly();\n    try {\n      FSImage image \u003d namesystem.getFSImage();\n\n      long lastTxnId \u003d image.getLastAppliedTxId();\n      \n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"lastTxnId: \" + lastTxnId);\n      }\n      Collection\u003cEditLogInputStream\u003e streams;\n      try {\n        streams \u003d editLog.selectInputStreams(lastTxnId + 1, 0, null, false);\n      } catch (IOException ioe) {\n        // This is acceptable. If we try to tail edits in the middle of an edits\n        // log roll, i.e. the last one has been finalized but the new inprogress\n        // edits file hasn\u0027t been started yet.\n        LOG.warn(\"Edits tailer failed to find any streams. Will try again \" +\n            \"later.\", ioe);\n        return;\n      }\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"edit streams to load from: \" + streams.size());\n      }\n      \n      // Once we have streams to load, errors encountered are legitimate cause\n      // for concern, so we don\u0027t catch them here. Simple errors reading from\n      // disk are ignored.\n      long editsLoaded \u003d 0;\n      try {\n        editsLoaded \u003d image.loadEdits(streams, namesystem, null);\n      } catch (EditLogInputException elie) {\n        editsLoaded \u003d elie.getNumEditsLoaded();\n        throw elie;\n      } finally {\n        if (editsLoaded \u003e 0 || LOG.isDebugEnabled()) {\n          LOG.info(String.format(\"Loaded %d edits starting from txid %d \",\n              editsLoaded, lastTxnId));\n        }\n      }\n\n      if (editsLoaded \u003e 0) {\n        lastLoadTimestamp \u003d now();\n      }\n      lastLoadedTxnId \u003d image.getLastAppliedTxId();\n    } finally {\n      namesystem.writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ha/EditLogTailer.java",
      "extendedDetails": {}
    },
    "706394d03992b394e9f907aff2155df493e4ea4e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3004. Implement Recovery Mode. Contributed by Colin Patrick McCabe\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1311394 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/04/12 12:39 PM",
      "commitName": "706394d03992b394e9f907aff2155df493e4ea4e",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "03/04/12 7:51 PM",
      "commitNameOld": "8c0366bf103ca638b5ef9e962671f7728db4fd10",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 5.7,
      "commitsBetweenForRepo": 52,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,53 +1,53 @@\n   private void doTailEdits() throws IOException, InterruptedException {\n     // Write lock needs to be interruptible here because the \n     // transitionToActive RPC takes the write lock before calling\n     // tailer.stop() -- so if we\u0027re not interruptible, it will\n     // deadlock.\n     namesystem.writeLockInterruptibly();\n     try {\n       FSImage image \u003d namesystem.getFSImage();\n \n       long lastTxnId \u003d image.getLastAppliedTxId();\n       \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"lastTxnId: \" + lastTxnId);\n       }\n       Collection\u003cEditLogInputStream\u003e streams;\n       try {\n         streams \u003d editLog.selectInputStreams(lastTxnId + 1, 0, false);\n       } catch (IOException ioe) {\n         // This is acceptable. If we try to tail edits in the middle of an edits\n         // log roll, i.e. the last one has been finalized but the new inprogress\n         // edits file hasn\u0027t been started yet.\n         LOG.warn(\"Edits tailer failed to find any streams. Will try again \" +\n             \"later.\", ioe);\n         return;\n       }\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"edit streams to load from: \" + streams.size());\n       }\n       \n       // Once we have streams to load, errors encountered are legitimate cause\n       // for concern, so we don\u0027t catch them here. Simple errors reading from\n       // disk are ignored.\n       long editsLoaded \u003d 0;\n       try {\n-        editsLoaded \u003d image.loadEdits(streams, namesystem);\n+        editsLoaded \u003d image.loadEdits(streams, namesystem, null);\n       } catch (EditLogInputException elie) {\n         editsLoaded \u003d elie.getNumEditsLoaded();\n         throw elie;\n       } finally {\n         if (editsLoaded \u003e 0 || LOG.isDebugEnabled()) {\n           LOG.info(String.format(\"Loaded %d edits starting from txid %d \",\n               editsLoaded, lastTxnId));\n         }\n       }\n \n       if (editsLoaded \u003e 0) {\n         lastLoadTimestamp \u003d now();\n       }\n       lastLoadedTxnId \u003d image.getLastAppliedTxId();\n     } finally {\n       namesystem.writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void doTailEdits() throws IOException, InterruptedException {\n    // Write lock needs to be interruptible here because the \n    // transitionToActive RPC takes the write lock before calling\n    // tailer.stop() -- so if we\u0027re not interruptible, it will\n    // deadlock.\n    namesystem.writeLockInterruptibly();\n    try {\n      FSImage image \u003d namesystem.getFSImage();\n\n      long lastTxnId \u003d image.getLastAppliedTxId();\n      \n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"lastTxnId: \" + lastTxnId);\n      }\n      Collection\u003cEditLogInputStream\u003e streams;\n      try {\n        streams \u003d editLog.selectInputStreams(lastTxnId + 1, 0, false);\n      } catch (IOException ioe) {\n        // This is acceptable. If we try to tail edits in the middle of an edits\n        // log roll, i.e. the last one has been finalized but the new inprogress\n        // edits file hasn\u0027t been started yet.\n        LOG.warn(\"Edits tailer failed to find any streams. Will try again \" +\n            \"later.\", ioe);\n        return;\n      }\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"edit streams to load from: \" + streams.size());\n      }\n      \n      // Once we have streams to load, errors encountered are legitimate cause\n      // for concern, so we don\u0027t catch them here. Simple errors reading from\n      // disk are ignored.\n      long editsLoaded \u003d 0;\n      try {\n        editsLoaded \u003d image.loadEdits(streams, namesystem, null);\n      } catch (EditLogInputException elie) {\n        editsLoaded \u003d elie.getNumEditsLoaded();\n        throw elie;\n      } finally {\n        if (editsLoaded \u003e 0 || LOG.isDebugEnabled()) {\n          LOG.info(String.format(\"Loaded %d edits starting from txid %d \",\n              editsLoaded, lastTxnId));\n        }\n      }\n\n      if (editsLoaded \u003e 0) {\n        lastLoadTimestamp \u003d now();\n      }\n      lastLoadedTxnId \u003d image.getLastAppliedTxId();\n    } finally {\n      namesystem.writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ha/EditLogTailer.java",
      "extendedDetails": {}
    },
    "641f79a325bad571b11b5700a42efb844eabc5af": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2824. Fix failover when prior NN died just after creating an edit log segment. Contributed by Aaron T. Myers.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1238069 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "30/01/12 3:05 PM",
      "commitName": "641f79a325bad571b11b5700a42efb844eabc5af",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "20/01/12 7:17 PM",
      "commitNameOld": "c3e62de9ce952aa8572b3cae6a8497b8fdef40aa",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 9.82,
      "commitsBetweenForRepo": 64,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,53 +1,53 @@\n   private void doTailEdits() throws IOException, InterruptedException {\n     // Write lock needs to be interruptible here because the \n     // transitionToActive RPC takes the write lock before calling\n     // tailer.stop() -- so if we\u0027re not interruptible, it will\n     // deadlock.\n     namesystem.writeLockInterruptibly();\n     try {\n       FSImage image \u003d namesystem.getFSImage();\n \n       long lastTxnId \u003d image.getLastAppliedTxId();\n       \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"lastTxnId: \" + lastTxnId);\n       }\n       Collection\u003cEditLogInputStream\u003e streams;\n       try {\n         streams \u003d editLog.selectInputStreams(lastTxnId + 1, 0, false);\n       } catch (IOException ioe) {\n         // This is acceptable. If we try to tail edits in the middle of an edits\n         // log roll, i.e. the last one has been finalized but the new inprogress\n         // edits file hasn\u0027t been started yet.\n         LOG.warn(\"Edits tailer failed to find any streams. Will try again \" +\n             \"later.\", ioe);\n         return;\n       }\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"edit streams to load from: \" + streams.size());\n       }\n       \n       // Once we have streams to load, errors encountered are legitimate cause\n       // for concern, so we don\u0027t catch them here. Simple errors reading from\n       // disk are ignored.\n       long editsLoaded \u003d 0;\n       try {\n         editsLoaded \u003d image.loadEdits(streams, namesystem);\n       } catch (EditLogInputException elie) {\n         editsLoaded \u003d elie.getNumEditsLoaded();\n         throw elie;\n       } finally {\n-        if (editsLoaded \u003e 0) {\n+        if (editsLoaded \u003e 0 || LOG.isDebugEnabled()) {\n           LOG.info(String.format(\"Loaded %d edits starting from txid %d \",\n               editsLoaded, lastTxnId));\n         }\n       }\n \n       if (editsLoaded \u003e 0) {\n         lastLoadTimestamp \u003d now();\n       }\n       lastLoadedTxnId \u003d image.getLastAppliedTxId();\n     } finally {\n       namesystem.writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void doTailEdits() throws IOException, InterruptedException {\n    // Write lock needs to be interruptible here because the \n    // transitionToActive RPC takes the write lock before calling\n    // tailer.stop() -- so if we\u0027re not interruptible, it will\n    // deadlock.\n    namesystem.writeLockInterruptibly();\n    try {\n      FSImage image \u003d namesystem.getFSImage();\n\n      long lastTxnId \u003d image.getLastAppliedTxId();\n      \n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"lastTxnId: \" + lastTxnId);\n      }\n      Collection\u003cEditLogInputStream\u003e streams;\n      try {\n        streams \u003d editLog.selectInputStreams(lastTxnId + 1, 0, false);\n      } catch (IOException ioe) {\n        // This is acceptable. If we try to tail edits in the middle of an edits\n        // log roll, i.e. the last one has been finalized but the new inprogress\n        // edits file hasn\u0027t been started yet.\n        LOG.warn(\"Edits tailer failed to find any streams. Will try again \" +\n            \"later.\", ioe);\n        return;\n      }\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"edit streams to load from: \" + streams.size());\n      }\n      \n      // Once we have streams to load, errors encountered are legitimate cause\n      // for concern, so we don\u0027t catch them here. Simple errors reading from\n      // disk are ignored.\n      long editsLoaded \u003d 0;\n      try {\n        editsLoaded \u003d image.loadEdits(streams, namesystem);\n      } catch (EditLogInputException elie) {\n        editsLoaded \u003d elie.getNumEditsLoaded();\n        throw elie;\n      } finally {\n        if (editsLoaded \u003e 0 || LOG.isDebugEnabled()) {\n          LOG.info(String.format(\"Loaded %d edits starting from txid %d \",\n              editsLoaded, lastTxnId));\n        }\n      }\n\n      if (editsLoaded \u003e 0) {\n        lastLoadTimestamp \u003d now();\n      }\n      lastLoadedTxnId \u003d image.getLastAppliedTxId();\n    } finally {\n      namesystem.writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ha/EditLogTailer.java",
      "extendedDetails": {}
    },
    "c3e62de9ce952aa8572b3cae6a8497b8fdef40aa": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2737. Automatically trigger log rolls periodically on the active NN. Contributed by Todd Lipcon and Aaron T. Myers.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1234256 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/01/12 7:17 PM",
      "commitName": "c3e62de9ce952aa8572b3cae6a8497b8fdef40aa",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "16/01/12 2:16 PM",
      "commitNameOld": "d880c7cc784cf636b2590fd98ea7c8ee67065a30",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 4.21,
      "commitsBetweenForRepo": 19,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,48 +1,53 @@\n   private void doTailEdits() throws IOException, InterruptedException {\n     // Write lock needs to be interruptible here because the \n     // transitionToActive RPC takes the write lock before calling\n     // tailer.stop() -- so if we\u0027re not interruptible, it will\n     // deadlock.\n     namesystem.writeLockInterruptibly();\n     try {\n       FSImage image \u003d namesystem.getFSImage();\n \n       long lastTxnId \u003d image.getLastAppliedTxId();\n       \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"lastTxnId: \" + lastTxnId);\n       }\n       Collection\u003cEditLogInputStream\u003e streams;\n       try {\n         streams \u003d editLog.selectInputStreams(lastTxnId + 1, 0, false);\n       } catch (IOException ioe) {\n         // This is acceptable. If we try to tail edits in the middle of an edits\n         // log roll, i.e. the last one has been finalized but the new inprogress\n         // edits file hasn\u0027t been started yet.\n         LOG.warn(\"Edits tailer failed to find any streams. Will try again \" +\n             \"later.\", ioe);\n         return;\n       }\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"edit streams to load from: \" + streams.size());\n       }\n       \n       // Once we have streams to load, errors encountered are legitimate cause\n       // for concern, so we don\u0027t catch them here. Simple errors reading from\n       // disk are ignored.\n       long editsLoaded \u003d 0;\n       try {\n         editsLoaded \u003d image.loadEdits(streams, namesystem);\n       } catch (EditLogInputException elie) {\n         editsLoaded \u003d elie.getNumEditsLoaded();\n         throw elie;\n       } finally {\n         if (editsLoaded \u003e 0) {\n           LOG.info(String.format(\"Loaded %d edits starting from txid %d \",\n               editsLoaded, lastTxnId));\n         }\n       }\n+\n+      if (editsLoaded \u003e 0) {\n+        lastLoadTimestamp \u003d now();\n+      }\n+      lastLoadedTxnId \u003d image.getLastAppliedTxId();\n     } finally {\n       namesystem.writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void doTailEdits() throws IOException, InterruptedException {\n    // Write lock needs to be interruptible here because the \n    // transitionToActive RPC takes the write lock before calling\n    // tailer.stop() -- so if we\u0027re not interruptible, it will\n    // deadlock.\n    namesystem.writeLockInterruptibly();\n    try {\n      FSImage image \u003d namesystem.getFSImage();\n\n      long lastTxnId \u003d image.getLastAppliedTxId();\n      \n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"lastTxnId: \" + lastTxnId);\n      }\n      Collection\u003cEditLogInputStream\u003e streams;\n      try {\n        streams \u003d editLog.selectInputStreams(lastTxnId + 1, 0, false);\n      } catch (IOException ioe) {\n        // This is acceptable. If we try to tail edits in the middle of an edits\n        // log roll, i.e. the last one has been finalized but the new inprogress\n        // edits file hasn\u0027t been started yet.\n        LOG.warn(\"Edits tailer failed to find any streams. Will try again \" +\n            \"later.\", ioe);\n        return;\n      }\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"edit streams to load from: \" + streams.size());\n      }\n      \n      // Once we have streams to load, errors encountered are legitimate cause\n      // for concern, so we don\u0027t catch them here. Simple errors reading from\n      // disk are ignored.\n      long editsLoaded \u003d 0;\n      try {\n        editsLoaded \u003d image.loadEdits(streams, namesystem);\n      } catch (EditLogInputException elie) {\n        editsLoaded \u003d elie.getNumEditsLoaded();\n        throw elie;\n      } finally {\n        if (editsLoaded \u003e 0) {\n          LOG.info(String.format(\"Loaded %d edits starting from txid %d \",\n              editsLoaded, lastTxnId));\n        }\n      }\n\n      if (editsLoaded \u003e 0) {\n        lastLoadTimestamp \u003d now();\n      }\n      lastLoadedTxnId \u003d image.getLastAppliedTxId();\n    } finally {\n      namesystem.writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ha/EditLogTailer.java",
      "extendedDetails": {}
    },
    "d880c7cc784cf636b2590fd98ea7c8ee67065a30": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2772. On transition to active, standby should not swallow ELIE. Contributed by Aaron T. Myers\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1232197 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/01/12 2:16 PM",
      "commitName": "d880c7cc784cf636b2590fd98ea7c8ee67065a30",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "06/01/12 12:44 PM",
      "commitNameOld": "9a07ba8945407cd8f63169faf9e0faa4311d38c7",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 10.06,
      "commitsBetweenForRepo": 56,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,46 +1,48 @@\n   private void doTailEdits() throws IOException, InterruptedException {\n     // Write lock needs to be interruptible here because the \n     // transitionToActive RPC takes the write lock before calling\n     // tailer.stop() -- so if we\u0027re not interruptible, it will\n     // deadlock.\n     namesystem.writeLockInterruptibly();\n     try {\n       FSImage image \u003d namesystem.getFSImage();\n \n       long lastTxnId \u003d image.getLastAppliedTxId();\n       \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"lastTxnId: \" + lastTxnId);\n       }\n       Collection\u003cEditLogInputStream\u003e streams;\n       try {\n         streams \u003d editLog.selectInputStreams(lastTxnId + 1, 0, false);\n       } catch (IOException ioe) {\n         // This is acceptable. If we try to tail edits in the middle of an edits\n         // log roll, i.e. the last one has been finalized but the new inprogress\n         // edits file hasn\u0027t been started yet.\n         LOG.warn(\"Edits tailer failed to find any streams. Will try again \" +\n             \"later.\", ioe);\n         return;\n       }\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"edit streams to load from: \" + streams.size());\n       }\n       \n       // Once we have streams to load, errors encountered are legitimate cause\n       // for concern, so we don\u0027t catch them here. Simple errors reading from\n       // disk are ignored.\n       long editsLoaded \u003d 0;\n       try {\n         editsLoaded \u003d image.loadEdits(streams, namesystem);\n       } catch (EditLogInputException elie) {\n-        LOG.warn(\"Error while reading edits from disk. Will try again.\", elie);\n         editsLoaded \u003d elie.getNumEditsLoaded();\n-      }\n-      if (LOG.isDebugEnabled()) {\n-        LOG.debug(\"editsLoaded: \" + editsLoaded);\n+        throw elie;\n+      } finally {\n+        if (editsLoaded \u003e 0) {\n+          LOG.info(String.format(\"Loaded %d edits starting from txid %d \",\n+              editsLoaded, lastTxnId));\n+        }\n       }\n     } finally {\n       namesystem.writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void doTailEdits() throws IOException, InterruptedException {\n    // Write lock needs to be interruptible here because the \n    // transitionToActive RPC takes the write lock before calling\n    // tailer.stop() -- so if we\u0027re not interruptible, it will\n    // deadlock.\n    namesystem.writeLockInterruptibly();\n    try {\n      FSImage image \u003d namesystem.getFSImage();\n\n      long lastTxnId \u003d image.getLastAppliedTxId();\n      \n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"lastTxnId: \" + lastTxnId);\n      }\n      Collection\u003cEditLogInputStream\u003e streams;\n      try {\n        streams \u003d editLog.selectInputStreams(lastTxnId + 1, 0, false);\n      } catch (IOException ioe) {\n        // This is acceptable. If we try to tail edits in the middle of an edits\n        // log roll, i.e. the last one has been finalized but the new inprogress\n        // edits file hasn\u0027t been started yet.\n        LOG.warn(\"Edits tailer failed to find any streams. Will try again \" +\n            \"later.\", ioe);\n        return;\n      }\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"edit streams to load from: \" + streams.size());\n      }\n      \n      // Once we have streams to load, errors encountered are legitimate cause\n      // for concern, so we don\u0027t catch them here. Simple errors reading from\n      // disk are ignored.\n      long editsLoaded \u003d 0;\n      try {\n        editsLoaded \u003d image.loadEdits(streams, namesystem);\n      } catch (EditLogInputException elie) {\n        editsLoaded \u003d elie.getNumEditsLoaded();\n        throw elie;\n      } finally {\n        if (editsLoaded \u003e 0) {\n          LOG.info(String.format(\"Loaded %d edits starting from txid %d \",\n              editsLoaded, lastTxnId));\n        }\n      }\n    } finally {\n      namesystem.writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ha/EditLogTailer.java",
      "extendedDetails": {}
    },
    "9a07ba8945407cd8f63169faf9e0faa4311d38c7": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2709. Appropriately handle error conditions in EditLogTailer. Contributed by Aaron T. Myers.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1228390 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "06/01/12 12:44 PM",
      "commitName": "9a07ba8945407cd8f63169faf9e0faa4311d38c7",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "04/01/12 4:22 PM",
      "commitNameOld": "5b8dcb20a2fad2e7e9dee56c451f68f9d865b5ae",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 1.85,
      "commitsBetweenForRepo": 21,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,28 +1,46 @@\n   private void doTailEdits() throws IOException, InterruptedException {\n     // Write lock needs to be interruptible here because the \n     // transitionToActive RPC takes the write lock before calling\n     // tailer.stop() -- so if we\u0027re not interruptible, it will\n     // deadlock.\n     namesystem.writeLockInterruptibly();\n     try {\n       FSImage image \u003d namesystem.getFSImage();\n \n       long lastTxnId \u003d image.getLastAppliedTxId();\n       \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"lastTxnId: \" + lastTxnId);\n       }\n-      Collection\u003cEditLogInputStream\u003e streams \u003d editLog\n-          .selectInputStreams(lastTxnId + 1, 0, false);\n+      Collection\u003cEditLogInputStream\u003e streams;\n+      try {\n+        streams \u003d editLog.selectInputStreams(lastTxnId + 1, 0, false);\n+      } catch (IOException ioe) {\n+        // This is acceptable. If we try to tail edits in the middle of an edits\n+        // log roll, i.e. the last one has been finalized but the new inprogress\n+        // edits file hasn\u0027t been started yet.\n+        LOG.warn(\"Edits tailer failed to find any streams. Will try again \" +\n+            \"later.\", ioe);\n+        return;\n+      }\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"edit streams to load from: \" + streams.size());\n       }\n       \n-      long editsLoaded \u003d image.loadEdits(streams, namesystem);\n+      // Once we have streams to load, errors encountered are legitimate cause\n+      // for concern, so we don\u0027t catch them here. Simple errors reading from\n+      // disk are ignored.\n+      long editsLoaded \u003d 0;\n+      try {\n+        editsLoaded \u003d image.loadEdits(streams, namesystem);\n+      } catch (EditLogInputException elie) {\n+        LOG.warn(\"Error while reading edits from disk. Will try again.\", elie);\n+        editsLoaded \u003d elie.getNumEditsLoaded();\n+      }\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"editsLoaded: \" + editsLoaded);\n       }\n     } finally {\n       namesystem.writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void doTailEdits() throws IOException, InterruptedException {\n    // Write lock needs to be interruptible here because the \n    // transitionToActive RPC takes the write lock before calling\n    // tailer.stop() -- so if we\u0027re not interruptible, it will\n    // deadlock.\n    namesystem.writeLockInterruptibly();\n    try {\n      FSImage image \u003d namesystem.getFSImage();\n\n      long lastTxnId \u003d image.getLastAppliedTxId();\n      \n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"lastTxnId: \" + lastTxnId);\n      }\n      Collection\u003cEditLogInputStream\u003e streams;\n      try {\n        streams \u003d editLog.selectInputStreams(lastTxnId + 1, 0, false);\n      } catch (IOException ioe) {\n        // This is acceptable. If we try to tail edits in the middle of an edits\n        // log roll, i.e. the last one has been finalized but the new inprogress\n        // edits file hasn\u0027t been started yet.\n        LOG.warn(\"Edits tailer failed to find any streams. Will try again \" +\n            \"later.\", ioe);\n        return;\n      }\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"edit streams to load from: \" + streams.size());\n      }\n      \n      // Once we have streams to load, errors encountered are legitimate cause\n      // for concern, so we don\u0027t catch them here. Simple errors reading from\n      // disk are ignored.\n      long editsLoaded \u003d 0;\n      try {\n        editsLoaded \u003d image.loadEdits(streams, namesystem);\n      } catch (EditLogInputException elie) {\n        LOG.warn(\"Error while reading edits from disk. Will try again.\", elie);\n        editsLoaded \u003d elie.getNumEditsLoaded();\n      }\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"editsLoaded: \" + editsLoaded);\n      }\n    } finally {\n      namesystem.writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ha/EditLogTailer.java",
      "extendedDetails": {}
    },
    "5b8dcb20a2fad2e7e9dee56c451f68f9d865b5ae": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2291. Allow the StandbyNode to make checkpoints in an HA setup. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1227411 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/01/12 4:22 PM",
      "commitName": "5b8dcb20a2fad2e7e9dee56c451f68f9d865b5ae",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "29/12/11 4:30 PM",
      "commitNameOld": "20a6560bdfd8c4e3b6c3ac9b0f0f62d32e3a2191",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 5.99,
      "commitsBetweenForRepo": 16,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,26 +1,28 @@\n   private void doTailEdits() throws IOException, InterruptedException {\n     // Write lock needs to be interruptible here because the \n     // transitionToActive RPC takes the write lock before calling\n     // tailer.stop() -- so if we\u0027re not interruptible, it will\n     // deadlock.\n     namesystem.writeLockInterruptibly();\n     try {\n+      FSImage image \u003d namesystem.getFSImage();\n+\n       long lastTxnId \u003d image.getLastAppliedTxId();\n       \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"lastTxnId: \" + lastTxnId);\n       }\n       Collection\u003cEditLogInputStream\u003e streams \u003d editLog\n           .selectInputStreams(lastTxnId + 1, 0, false);\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"edit streams to load from: \" + streams.size());\n       }\n       \n       long editsLoaded \u003d image.loadEdits(streams, namesystem);\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"editsLoaded: \" + editsLoaded);\n       }\n     } finally {\n       namesystem.writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void doTailEdits() throws IOException, InterruptedException {\n    // Write lock needs to be interruptible here because the \n    // transitionToActive RPC takes the write lock before calling\n    // tailer.stop() -- so if we\u0027re not interruptible, it will\n    // deadlock.\n    namesystem.writeLockInterruptibly();\n    try {\n      FSImage image \u003d namesystem.getFSImage();\n\n      long lastTxnId \u003d image.getLastAppliedTxId();\n      \n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"lastTxnId: \" + lastTxnId);\n      }\n      Collection\u003cEditLogInputStream\u003e streams \u003d editLog\n          .selectInputStreams(lastTxnId + 1, 0, false);\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"edit streams to load from: \" + streams.size());\n      }\n      \n      long editsLoaded \u003d image.loadEdits(streams, namesystem);\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"editsLoaded: \" + editsLoaded);\n      }\n    } finally {\n      namesystem.writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ha/EditLogTailer.java",
      "extendedDetails": {}
    },
    "36d1c49486587c2dbb193e8538b1d4510c462fa6": {
      "type": "Ymultichange(Yexceptionschange,Ybodychange)",
      "commitMessage": "HDFS-2693. Fix synchronization issues around state transition. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1221582 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/12/11 7:03 PM",
      "commitName": "36d1c49486587c2dbb193e8538b1d4510c462fa6",
      "commitAuthor": "Todd Lipcon",
      "subchanges": [
        {
          "type": "Yexceptionschange",
          "commitMessage": "HDFS-2693. Fix synchronization issues around state transition. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1221582 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "20/12/11 7:03 PM",
          "commitName": "36d1c49486587c2dbb193e8538b1d4510c462fa6",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "15/12/11 8:18 PM",
          "commitNameOld": "71071b904d0c9aec7b3713d41740f24182e81c36",
          "commitAuthorOld": "Aaron Myers",
          "daysBetweenCommits": 4.95,
          "commitsBetweenForRepo": 24,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,20 +1,26 @@\n-  private void doTailEdits() throws IOException {\n-    // TODO(HA) in a transition from active to standby,\n-    // the following is wrong and ends up causing all of the\n-    // last log segment to get re-read\n-    long lastTxnId \u003d image.getLastAppliedTxId();\n-    \n-    if (LOG.isDebugEnabled()) {\n-      LOG.debug(\"lastTxnId: \" + lastTxnId);\n-    }\n-    Collection\u003cEditLogInputStream\u003e streams \u003d editLog\n-        .selectInputStreams(lastTxnId + 1, 0, false);\n-    if (LOG.isDebugEnabled()) {\n-      LOG.debug(\"edit streams to load from: \" + streams.size());\n-    }\n-    \n-    long editsLoaded \u003d image.loadEdits(streams, namesystem);\n-    if (LOG.isDebugEnabled()) {\n-      LOG.debug(\"editsLoaded: \" + editsLoaded);\n+  private void doTailEdits() throws IOException, InterruptedException {\n+    // Write lock needs to be interruptible here because the \n+    // transitionToActive RPC takes the write lock before calling\n+    // tailer.stop() -- so if we\u0027re not interruptible, it will\n+    // deadlock.\n+    namesystem.writeLockInterruptibly();\n+    try {\n+      long lastTxnId \u003d image.getLastAppliedTxId();\n+      \n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(\"lastTxnId: \" + lastTxnId);\n+      }\n+      Collection\u003cEditLogInputStream\u003e streams \u003d editLog\n+          .selectInputStreams(lastTxnId + 1, 0, false);\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(\"edit streams to load from: \" + streams.size());\n+      }\n+      \n+      long editsLoaded \u003d image.loadEdits(streams, namesystem);\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(\"editsLoaded: \" + editsLoaded);\n+      }\n+    } finally {\n+      namesystem.writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void doTailEdits() throws IOException, InterruptedException {\n    // Write lock needs to be interruptible here because the \n    // transitionToActive RPC takes the write lock before calling\n    // tailer.stop() -- so if we\u0027re not interruptible, it will\n    // deadlock.\n    namesystem.writeLockInterruptibly();\n    try {\n      long lastTxnId \u003d image.getLastAppliedTxId();\n      \n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"lastTxnId: \" + lastTxnId);\n      }\n      Collection\u003cEditLogInputStream\u003e streams \u003d editLog\n          .selectInputStreams(lastTxnId + 1, 0, false);\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"edit streams to load from: \" + streams.size());\n      }\n      \n      long editsLoaded \u003d image.loadEdits(streams, namesystem);\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"editsLoaded: \" + editsLoaded);\n      }\n    } finally {\n      namesystem.writeUnlock();\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ha/EditLogTailer.java",
          "extendedDetails": {
            "oldValue": "[IOException]",
            "newValue": "[IOException, InterruptedException]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-2693. Fix synchronization issues around state transition. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1221582 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "20/12/11 7:03 PM",
          "commitName": "36d1c49486587c2dbb193e8538b1d4510c462fa6",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "15/12/11 8:18 PM",
          "commitNameOld": "71071b904d0c9aec7b3713d41740f24182e81c36",
          "commitAuthorOld": "Aaron Myers",
          "daysBetweenCommits": 4.95,
          "commitsBetweenForRepo": 24,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,20 +1,26 @@\n-  private void doTailEdits() throws IOException {\n-    // TODO(HA) in a transition from active to standby,\n-    // the following is wrong and ends up causing all of the\n-    // last log segment to get re-read\n-    long lastTxnId \u003d image.getLastAppliedTxId();\n-    \n-    if (LOG.isDebugEnabled()) {\n-      LOG.debug(\"lastTxnId: \" + lastTxnId);\n-    }\n-    Collection\u003cEditLogInputStream\u003e streams \u003d editLog\n-        .selectInputStreams(lastTxnId + 1, 0, false);\n-    if (LOG.isDebugEnabled()) {\n-      LOG.debug(\"edit streams to load from: \" + streams.size());\n-    }\n-    \n-    long editsLoaded \u003d image.loadEdits(streams, namesystem);\n-    if (LOG.isDebugEnabled()) {\n-      LOG.debug(\"editsLoaded: \" + editsLoaded);\n+  private void doTailEdits() throws IOException, InterruptedException {\n+    // Write lock needs to be interruptible here because the \n+    // transitionToActive RPC takes the write lock before calling\n+    // tailer.stop() -- so if we\u0027re not interruptible, it will\n+    // deadlock.\n+    namesystem.writeLockInterruptibly();\n+    try {\n+      long lastTxnId \u003d image.getLastAppliedTxId();\n+      \n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(\"lastTxnId: \" + lastTxnId);\n+      }\n+      Collection\u003cEditLogInputStream\u003e streams \u003d editLog\n+          .selectInputStreams(lastTxnId + 1, 0, false);\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(\"edit streams to load from: \" + streams.size());\n+      }\n+      \n+      long editsLoaded \u003d image.loadEdits(streams, namesystem);\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(\"editsLoaded: \" + editsLoaded);\n+      }\n+    } finally {\n+      namesystem.writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void doTailEdits() throws IOException, InterruptedException {\n    // Write lock needs to be interruptible here because the \n    // transitionToActive RPC takes the write lock before calling\n    // tailer.stop() -- so if we\u0027re not interruptible, it will\n    // deadlock.\n    namesystem.writeLockInterruptibly();\n    try {\n      long lastTxnId \u003d image.getLastAppliedTxId();\n      \n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"lastTxnId: \" + lastTxnId);\n      }\n      Collection\u003cEditLogInputStream\u003e streams \u003d editLog\n          .selectInputStreams(lastTxnId + 1, 0, false);\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"edit streams to load from: \" + streams.size());\n      }\n      \n      long editsLoaded \u003d image.loadEdits(streams, namesystem);\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"editsLoaded: \" + editsLoaded);\n      }\n    } finally {\n      namesystem.writeUnlock();\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ha/EditLogTailer.java",
          "extendedDetails": {}
        }
      ]
    },
    "2481474bd9c50a23e4fd2eea67ac2dea11ca1f58": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-2634. Standby needs to ingest latest edit logs before transitioning to active. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1212187 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/12/11 3:55 PM",
      "commitName": "2481474bd9c50a23e4fd2eea67ac2dea11ca1f58",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,20 @@\n+  private void doTailEdits() throws IOException {\n+    // TODO(HA) in a transition from active to standby,\n+    // the following is wrong and ends up causing all of the\n+    // last log segment to get re-read\n+    long lastTxnId \u003d image.getLastAppliedTxId();\n+    \n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"lastTxnId: \" + lastTxnId);\n+    }\n+    Collection\u003cEditLogInputStream\u003e streams \u003d editLog\n+        .selectInputStreams(lastTxnId + 1, 0, false);\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"edit streams to load from: \" + streams.size());\n+    }\n+    \n+    long editsLoaded \u003d image.loadEdits(streams, namesystem);\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"editsLoaded: \" + editsLoaded);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void doTailEdits() throws IOException {\n    // TODO(HA) in a transition from active to standby,\n    // the following is wrong and ends up causing all of the\n    // last log segment to get re-read\n    long lastTxnId \u003d image.getLastAppliedTxId();\n    \n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"lastTxnId: \" + lastTxnId);\n    }\n    Collection\u003cEditLogInputStream\u003e streams \u003d editLog\n        .selectInputStreams(lastTxnId + 1, 0, false);\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"edit streams to load from: \" + streams.size());\n    }\n    \n    long editsLoaded \u003d image.loadEdits(streams, namesystem);\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"editsLoaded: \" + editsLoaded);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ha/EditLogTailer.java"
    }
  }
}