{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DFSStripedOutputStream.java",
  "functionName": "waitCreatingStreamers",
  "functionId": "waitCreatingStreamers___healthyStreamers-Set__StripedDataStreamer__",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSStripedOutputStream.java",
  "functionStartLine": 752,
  "functionEndLine": 795,
  "numCommitsSeen": 60,
  "timeTaken": 1548,
  "changeHistory": [
    "ccd2ac60ecc5fccce56debf21a068e663c1d5f11",
    "a8b4d0ff283a0af1075aaa94904d4c6e63a9a3dd"
  ],
  "changeHistoryShort": {
    "ccd2ac60ecc5fccce56debf21a068e663c1d5f11": "Yrename",
    "a8b4d0ff283a0af1075aaa94904d4c6e63a9a3dd": "Ybodychange"
  },
  "changeHistoryDetails": {
    "ccd2ac60ecc5fccce56debf21a068e663c1d5f11": {
      "type": "Yrename",
      "commitMessage": "HDFS-11882. Precisely calculate acked length of striped block groups in updatePipeline.\n",
      "commitDate": "05/09/17 2:16 PM",
      "commitName": "ccd2ac60ecc5fccce56debf21a068e663c1d5f11",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "05/09/17 2:46 AM",
      "commitNameOld": "5dba54596a1587e0ba5f9f02f40483e597b0df64",
      "commitAuthorOld": "Kai Zheng",
      "daysBetweenCommits": 0.48,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,44 +1,44 @@\n-  private Set\u003cStripedDataStreamer\u003e waitCreatingNewStreams(\n+  private Set\u003cStripedDataStreamer\u003e waitCreatingStreamers(\n       Set\u003cStripedDataStreamer\u003e healthyStreamers) throws IOException {\n     Set\u003cStripedDataStreamer\u003e failed \u003d new HashSet\u003c\u003e();\n     final int expectedNum \u003d healthyStreamers.size();\n     final long socketTimeout \u003d dfsClient.getConf().getSocketTimeout();\n     // the total wait time should be less than the socket timeout, otherwise\n     // a slow streamer may cause other streamers to timeout. here we wait for\n     // half of the socket timeout\n     long remaingTime \u003d socketTimeout \u003e 0 ? socketTimeout/2 : Long.MAX_VALUE;\n     final long waitInterval \u003d 1000;\n     synchronized (coordinator) {\n       while (checkStreamerUpdates(failed, healthyStreamers) \u003c expectedNum\n           \u0026\u0026 remaingTime \u003e 0) {\n         try {\n           long start \u003d Time.monotonicNow();\n           coordinator.wait(waitInterval);\n           remaingTime -\u003d Time.monotonicNow() - start;\n         } catch (InterruptedException e) {\n           throw DFSUtilClient.toInterruptedIOException(\"Interrupted when waiting\" +\n               \" for results of updating striped streamers\", e);\n         }\n       }\n     }\n     synchronized (coordinator) {\n       for (StripedDataStreamer streamer : healthyStreamers) {\n         if (!coordinator.updateStreamerMap.containsKey(streamer)) {\n           // close the streamer if it is too slow to create new connection\n           LOG.info(\"close the slow stream \" + streamer);\n           streamer.setStreamerAsClosed();\n           failed.add(streamer);\n         }\n       }\n     }\n     for (Map.Entry\u003cStripedDataStreamer, Boolean\u003e entry :\n         coordinator.updateStreamerMap.entrySet()) {\n       if (!entry.getValue()) {\n         failed.add(entry.getKey());\n       }\n     }\n     for (StripedDataStreamer failedStreamer : failed) {\n       healthyStreamers.remove(failedStreamer);\n     }\n     return failed;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private Set\u003cStripedDataStreamer\u003e waitCreatingStreamers(\n      Set\u003cStripedDataStreamer\u003e healthyStreamers) throws IOException {\n    Set\u003cStripedDataStreamer\u003e failed \u003d new HashSet\u003c\u003e();\n    final int expectedNum \u003d healthyStreamers.size();\n    final long socketTimeout \u003d dfsClient.getConf().getSocketTimeout();\n    // the total wait time should be less than the socket timeout, otherwise\n    // a slow streamer may cause other streamers to timeout. here we wait for\n    // half of the socket timeout\n    long remaingTime \u003d socketTimeout \u003e 0 ? socketTimeout/2 : Long.MAX_VALUE;\n    final long waitInterval \u003d 1000;\n    synchronized (coordinator) {\n      while (checkStreamerUpdates(failed, healthyStreamers) \u003c expectedNum\n          \u0026\u0026 remaingTime \u003e 0) {\n        try {\n          long start \u003d Time.monotonicNow();\n          coordinator.wait(waitInterval);\n          remaingTime -\u003d Time.monotonicNow() - start;\n        } catch (InterruptedException e) {\n          throw DFSUtilClient.toInterruptedIOException(\"Interrupted when waiting\" +\n              \" for results of updating striped streamers\", e);\n        }\n      }\n    }\n    synchronized (coordinator) {\n      for (StripedDataStreamer streamer : healthyStreamers) {\n        if (!coordinator.updateStreamerMap.containsKey(streamer)) {\n          // close the streamer if it is too slow to create new connection\n          LOG.info(\"close the slow stream \" + streamer);\n          streamer.setStreamerAsClosed();\n          failed.add(streamer);\n        }\n      }\n    }\n    for (Map.Entry\u003cStripedDataStreamer, Boolean\u003e entry :\n        coordinator.updateStreamerMap.entrySet()) {\n      if (!entry.getValue()) {\n        failed.add(entry.getKey());\n      }\n    }\n    for (StripedDataStreamer failedStreamer : failed) {\n      healthyStreamers.remove(failedStreamer);\n    }\n    return failed;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSStripedOutputStream.java",
      "extendedDetails": {
        "oldValue": "waitCreatingNewStreams",
        "newValue": "waitCreatingStreamers"
      }
    },
    "a8b4d0ff283a0af1075aaa94904d4c6e63a9a3dd": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9180. Update excluded DataNodes in DFSStripedOutputStream based on failures in data streamers. Contributed by Jing Zhao.\n",
      "commitDate": "06/10/15 10:56 AM",
      "commitName": "a8b4d0ff283a0af1075aaa94904d4c6e63a9a3dd",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "03/10/15 11:38 AM",
      "commitNameOld": "7136e8c5582dc4061b566cb9f11a0d6a6d08bb93",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 2.97,
      "commitsBetweenForRepo": 12,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,43 +1,44 @@\n   private Set\u003cStripedDataStreamer\u003e waitCreatingNewStreams(\n       Set\u003cStripedDataStreamer\u003e healthyStreamers) throws IOException {\n     Set\u003cStripedDataStreamer\u003e failed \u003d new HashSet\u003c\u003e();\n     final int expectedNum \u003d healthyStreamers.size();\n     final long socketTimeout \u003d dfsClient.getConf().getSocketTimeout();\n     // the total wait time should be less than the socket timeout, otherwise\n     // a slow streamer may cause other streamers to timeout. here we wait for\n     // half of the socket timeout\n     long remaingTime \u003d socketTimeout \u003e 0 ? socketTimeout/2 : Long.MAX_VALUE;\n     final long waitInterval \u003d 1000;\n     synchronized (coordinator) {\n       while (checkStreamerUpdates(failed, healthyStreamers) \u003c expectedNum\n           \u0026\u0026 remaingTime \u003e 0) {\n         try {\n           long start \u003d Time.monotonicNow();\n           coordinator.wait(waitInterval);\n           remaingTime -\u003d Time.monotonicNow() - start;\n         } catch (InterruptedException e) {\n           throw DFSUtilClient.toInterruptedIOException(\"Interrupted when waiting\" +\n               \" for results of updating striped streamers\", e);\n         }\n       }\n     }\n     synchronized (coordinator) {\n       for (StripedDataStreamer streamer : healthyStreamers) {\n         if (!coordinator.updateStreamerMap.containsKey(streamer)) {\n           // close the streamer if it is too slow to create new connection\n+          LOG.info(\"close the slow stream \" + streamer);\n           streamer.setStreamerAsClosed();\n           failed.add(streamer);\n         }\n       }\n     }\n     for (Map.Entry\u003cStripedDataStreamer, Boolean\u003e entry :\n         coordinator.updateStreamerMap.entrySet()) {\n       if (!entry.getValue()) {\n         failed.add(entry.getKey());\n       }\n     }\n     for (StripedDataStreamer failedStreamer : failed) {\n       healthyStreamers.remove(failedStreamer);\n     }\n     return failed;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private Set\u003cStripedDataStreamer\u003e waitCreatingNewStreams(\n      Set\u003cStripedDataStreamer\u003e healthyStreamers) throws IOException {\n    Set\u003cStripedDataStreamer\u003e failed \u003d new HashSet\u003c\u003e();\n    final int expectedNum \u003d healthyStreamers.size();\n    final long socketTimeout \u003d dfsClient.getConf().getSocketTimeout();\n    // the total wait time should be less than the socket timeout, otherwise\n    // a slow streamer may cause other streamers to timeout. here we wait for\n    // half of the socket timeout\n    long remaingTime \u003d socketTimeout \u003e 0 ? socketTimeout/2 : Long.MAX_VALUE;\n    final long waitInterval \u003d 1000;\n    synchronized (coordinator) {\n      while (checkStreamerUpdates(failed, healthyStreamers) \u003c expectedNum\n          \u0026\u0026 remaingTime \u003e 0) {\n        try {\n          long start \u003d Time.monotonicNow();\n          coordinator.wait(waitInterval);\n          remaingTime -\u003d Time.monotonicNow() - start;\n        } catch (InterruptedException e) {\n          throw DFSUtilClient.toInterruptedIOException(\"Interrupted when waiting\" +\n              \" for results of updating striped streamers\", e);\n        }\n      }\n    }\n    synchronized (coordinator) {\n      for (StripedDataStreamer streamer : healthyStreamers) {\n        if (!coordinator.updateStreamerMap.containsKey(streamer)) {\n          // close the streamer if it is too slow to create new connection\n          LOG.info(\"close the slow stream \" + streamer);\n          streamer.setStreamerAsClosed();\n          failed.add(streamer);\n        }\n      }\n    }\n    for (Map.Entry\u003cStripedDataStreamer, Boolean\u003e entry :\n        coordinator.updateStreamerMap.entrySet()) {\n      if (!entry.getValue()) {\n        failed.add(entry.getKey());\n      }\n    }\n    for (StripedDataStreamer failedStreamer : failed) {\n      healthyStreamers.remove(failedStreamer);\n    }\n    return failed;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSStripedOutputStream.java",
      "extendedDetails": {}
    }
  }
}