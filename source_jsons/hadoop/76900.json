{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "HHXORErasureEncodingStep.java",
  "functionName": "encodeWithPiggyBacks",
  "functionId": "encodeWithPiggyBacks___piggyBacks-ByteBuffer[]__outputs-ByteBuffer[][]__numParityUnits-int__bIsDirect-boolean",
  "sourceFilePath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/coder/HHXORErasureEncodingStep.java",
  "functionStartLine": 120,
  "functionEndLine": 148,
  "numCommitsSeen": 3,
  "timeTaken": 592,
  "changeHistory": [
    "1bb31fb22e6f8e6df8e9ff4e94adf20308b4c743"
  ],
  "changeHistoryShort": {
    "1bb31fb22e6f8e6df8e9ff4e94adf20308b4c743": "Yintroduced"
  },
  "changeHistoryDetails": {
    "1bb31fb22e6f8e6df8e9ff4e94adf20308b4c743": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-11828. Implement the Hitchhiker erasure coding algorithm. Contributed by Jack Liu Quan.\n\nChange-Id: If43475ccc2574df60949c947af562722db076251\n",
      "commitDate": "21/01/16 10:30 AM",
      "commitName": "1bb31fb22e6f8e6df8e9ff4e94adf20308b4c743",
      "commitAuthor": "Zhe Zhang",
      "diff": "@@ -0,0 +1,29 @@\n+  private void encodeWithPiggyBacks(ByteBuffer[] piggyBacks,\n+                                    ByteBuffer[][] outputs,\n+                                    int numParityUnits,\n+                                    boolean bIsDirect) {\n+    if (!bIsDirect) {\n+      for (int i \u003d 0; i \u003c numParityUnits - 1; i++) {\n+        int parityIndex \u003d i + 1;\n+        int bufSize \u003d piggyBacks[i].remaining();\n+        byte[] newOut \u003d outputs[1][parityIndex].array();\n+        int offset \u003d outputs[1][parityIndex].arrayOffset()\n+                + outputs[1][parityIndex].position();\n+\n+        for (int k \u003d offset, j \u003d 0; j \u003c bufSize; k++, j++) {\n+          newOut[k] \u003d (byte) (newOut[k] ^ piggyBacks[i].get(j));\n+        }\n+      }\n+      return;\n+    }\n+\n+    for (int i \u003d 0; i \u003c numParityUnits - 1; i++) {\n+      int parityIndex \u003d i + 1;\n+      for (int k \u003d piggyBacks[i].position(),\n+           m \u003d outputs[1][parityIndex].position();\n+           k \u003c piggyBacks[i].limit(); k++, m++) {\n+        outputs[1][parityIndex].put(m,\n+                (byte) (outputs[1][parityIndex].get(m) ^ piggyBacks[i].get(k)));\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void encodeWithPiggyBacks(ByteBuffer[] piggyBacks,\n                                    ByteBuffer[][] outputs,\n                                    int numParityUnits,\n                                    boolean bIsDirect) {\n    if (!bIsDirect) {\n      for (int i \u003d 0; i \u003c numParityUnits - 1; i++) {\n        int parityIndex \u003d i + 1;\n        int bufSize \u003d piggyBacks[i].remaining();\n        byte[] newOut \u003d outputs[1][parityIndex].array();\n        int offset \u003d outputs[1][parityIndex].arrayOffset()\n                + outputs[1][parityIndex].position();\n\n        for (int k \u003d offset, j \u003d 0; j \u003c bufSize; k++, j++) {\n          newOut[k] \u003d (byte) (newOut[k] ^ piggyBacks[i].get(j));\n        }\n      }\n      return;\n    }\n\n    for (int i \u003d 0; i \u003c numParityUnits - 1; i++) {\n      int parityIndex \u003d i + 1;\n      for (int k \u003d piggyBacks[i].position(),\n           m \u003d outputs[1][parityIndex].position();\n           k \u003c piggyBacks[i].limit(); k++, m++) {\n        outputs[1][parityIndex].put(m,\n                (byte) (outputs[1][parityIndex].get(m) ^ piggyBacks[i].get(k)));\n      }\n    }\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/coder/HHXORErasureEncodingStep.java"
    }
  }
}