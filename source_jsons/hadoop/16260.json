{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "RouterWebHdfsMethods.java",
  "functionName": "chooseDatanode",
  "functionId": "chooseDatanode___router-Router(modifiers-final)__path-String(modifiers-final)__op-HttpOpParam.Op(modifiers-final)__openOffset-long(modifiers-final)__excludeDatanodes-String(modifiers-final)",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterWebHdfsMethods.java",
  "functionStartLine": 454,
  "functionEndLine": 512,
  "numCommitsSeen": 6,
  "timeTaken": 1199,
  "changeHistory": [
    "021a43b1a4bbc8a68c31461e206214a5eadc38dd",
    "6e31a090842f8aeedb331b653b075499f8df6c60"
  ],
  "changeHistoryShort": {
    "021a43b1a4bbc8a68c31461e206214a5eadc38dd": "Ybodychange",
    "6e31a090842f8aeedb331b653b075499f8df6c60": "Yintroduced"
  },
  "changeHistoryDetails": {
    "021a43b1a4bbc8a68c31461e206214a5eadc38dd": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13972. RBF: Support for Delegation Token (WebHDFS). Contributed by CR Hota.\n",
      "commitDate": "24/06/19 9:33 AM",
      "commitName": "021a43b1a4bbc8a68c31461e206214a5eadc38dd",
      "commitAuthor": "Brahma Reddy Battula",
      "commitDateOld": "26/03/19 11:27 AM",
      "commitNameOld": "55fb3c32fb48ca26a629d4d5f3f07e2858d09594",
      "commitAuthorOld": "Takanobu Asanuma",
      "daysBetweenCommits": 89.92,
      "commitsBetweenForRepo": 632,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,61 +1,59 @@\n   private DatanodeInfo chooseDatanode(final Router router,\n       final String path, final HttpOpParam.Op op, final long openOffset,\n       final String excludeDatanodes) throws IOException {\n     // We need to get the DNs as a privileged user\n     final RouterRpcServer rpcServer \u003d getRPCServer(router);\n     UserGroupInformation loginUser \u003d UserGroupInformation.getLoginUser();\n+    RouterRpcServer.setCurrentUser(loginUser);\n \n-    DatanodeInfo[] dns \u003d loginUser.doAs(\n-        new PrivilegedAction\u003cDatanodeInfo[]\u003e() {\n-          @Override\n-          public DatanodeInfo[] run() {\n-            try {\n-              return rpcServer.getDatanodeReport(DatanodeReportType.LIVE);\n-            } catch (IOException e) {\n-              LOG.error(\"Cannot get the datanodes from the RPC server\", e);\n-              return null;\n-            }\n-          }\n-        });\n+    DatanodeInfo[] dns \u003d null;\n+    try {\n+      dns \u003d rpcServer.getDatanodeReport(DatanodeReportType.LIVE);\n+    } catch (IOException e) {\n+      LOG.error(\"Cannot get the datanodes from the RPC server\", e);\n+    } finally {\n+      // Reset ugi to remote user for remaining operations.\n+      RouterRpcServer.resetCurrentUser();\n+    }\n \n     HashSet\u003cNode\u003e excludes \u003d new HashSet\u003cNode\u003e();\n     if (excludeDatanodes !\u003d null) {\n       Collection\u003cString\u003e collection \u003d\n           getTrimmedStringCollection(excludeDatanodes);\n       for (DatanodeInfo dn : dns) {\n         if (collection.contains(dn.getName())) {\n           excludes.add(dn);\n         }\n       }\n     }\n \n     if (op \u003d\u003d GetOpParam.Op.OPEN ||\n         op \u003d\u003d PostOpParam.Op.APPEND ||\n         op \u003d\u003d GetOpParam.Op.GETFILECHECKSUM) {\n       // Choose a datanode containing a replica\n       final ClientProtocol cp \u003d getRpcClientProtocol();\n       final HdfsFileStatus status \u003d cp.getFileInfo(path);\n       if (status \u003d\u003d null) {\n         throw new FileNotFoundException(\"File \" + path + \" not found.\");\n       }\n       final long len \u003d status.getLen();\n       if (op \u003d\u003d GetOpParam.Op.OPEN) {\n         if (openOffset \u003c 0L || (openOffset \u003e\u003d len \u0026\u0026 len \u003e 0)) {\n           throw new IOException(\"Offset\u003d\" + openOffset\n               + \" out of the range [0, \" + len + \"); \" + op + \", path\u003d\" + path);\n         }\n       }\n \n       if (len \u003e 0) {\n         final long offset \u003d op \u003d\u003d GetOpParam.Op.OPEN ? openOffset : len - 1;\n         final LocatedBlocks locations \u003d cp.getBlockLocations(path, offset, 1);\n         final int count \u003d locations.locatedBlockCount();\n         if (count \u003e 0) {\n           LocatedBlock location0 \u003d locations.get(0);\n           return bestNode(location0.getLocations(), excludes);\n         }\n       }\n     }\n \n     return getRandomDatanode(dns, excludes);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private DatanodeInfo chooseDatanode(final Router router,\n      final String path, final HttpOpParam.Op op, final long openOffset,\n      final String excludeDatanodes) throws IOException {\n    // We need to get the DNs as a privileged user\n    final RouterRpcServer rpcServer \u003d getRPCServer(router);\n    UserGroupInformation loginUser \u003d UserGroupInformation.getLoginUser();\n    RouterRpcServer.setCurrentUser(loginUser);\n\n    DatanodeInfo[] dns \u003d null;\n    try {\n      dns \u003d rpcServer.getDatanodeReport(DatanodeReportType.LIVE);\n    } catch (IOException e) {\n      LOG.error(\"Cannot get the datanodes from the RPC server\", e);\n    } finally {\n      // Reset ugi to remote user for remaining operations.\n      RouterRpcServer.resetCurrentUser();\n    }\n\n    HashSet\u003cNode\u003e excludes \u003d new HashSet\u003cNode\u003e();\n    if (excludeDatanodes !\u003d null) {\n      Collection\u003cString\u003e collection \u003d\n          getTrimmedStringCollection(excludeDatanodes);\n      for (DatanodeInfo dn : dns) {\n        if (collection.contains(dn.getName())) {\n          excludes.add(dn);\n        }\n      }\n    }\n\n    if (op \u003d\u003d GetOpParam.Op.OPEN ||\n        op \u003d\u003d PostOpParam.Op.APPEND ||\n        op \u003d\u003d GetOpParam.Op.GETFILECHECKSUM) {\n      // Choose a datanode containing a replica\n      final ClientProtocol cp \u003d getRpcClientProtocol();\n      final HdfsFileStatus status \u003d cp.getFileInfo(path);\n      if (status \u003d\u003d null) {\n        throw new FileNotFoundException(\"File \" + path + \" not found.\");\n      }\n      final long len \u003d status.getLen();\n      if (op \u003d\u003d GetOpParam.Op.OPEN) {\n        if (openOffset \u003c 0L || (openOffset \u003e\u003d len \u0026\u0026 len \u003e 0)) {\n          throw new IOException(\"Offset\u003d\" + openOffset\n              + \" out of the range [0, \" + len + \"); \" + op + \", path\u003d\" + path);\n        }\n      }\n\n      if (len \u003e 0) {\n        final long offset \u003d op \u003d\u003d GetOpParam.Op.OPEN ? openOffset : len - 1;\n        final LocatedBlocks locations \u003d cp.getBlockLocations(path, offset, 1);\n        final int count \u003d locations.locatedBlockCount();\n        if (count \u003e 0) {\n          LocatedBlock location0 \u003d locations.get(0);\n          return bestNode(location0.getLocations(), excludes);\n        }\n      }\n    }\n\n    return getRandomDatanode(dns, excludes);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterWebHdfsMethods.java",
      "extendedDetails": {}
    },
    "6e31a090842f8aeedb331b653b075499f8df6c60": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-12512. RBF: Add WebHDFS.\n",
      "commitDate": "23/03/18 8:32 AM",
      "commitName": "6e31a090842f8aeedb331b653b075499f8df6c60",
      "commitAuthor": "weiy",
      "diff": "@@ -0,0 +1,61 @@\n+  private DatanodeInfo chooseDatanode(final Router router,\n+      final String path, final HttpOpParam.Op op, final long openOffset,\n+      final String excludeDatanodes) throws IOException {\n+    // We need to get the DNs as a privileged user\n+    final RouterRpcServer rpcServer \u003d getRPCServer(router);\n+    UserGroupInformation loginUser \u003d UserGroupInformation.getLoginUser();\n+\n+    DatanodeInfo[] dns \u003d loginUser.doAs(\n+        new PrivilegedAction\u003cDatanodeInfo[]\u003e() {\n+          @Override\n+          public DatanodeInfo[] run() {\n+            try {\n+              return rpcServer.getDatanodeReport(DatanodeReportType.LIVE);\n+            } catch (IOException e) {\n+              LOG.error(\"Cannot get the datanodes from the RPC server\", e);\n+              return null;\n+            }\n+          }\n+        });\n+\n+    HashSet\u003cNode\u003e excludes \u003d new HashSet\u003cNode\u003e();\n+    if (excludeDatanodes !\u003d null) {\n+      Collection\u003cString\u003e collection \u003d\n+          getTrimmedStringCollection(excludeDatanodes);\n+      for (DatanodeInfo dn : dns) {\n+        if (collection.contains(dn.getName())) {\n+          excludes.add(dn);\n+        }\n+      }\n+    }\n+\n+    if (op \u003d\u003d GetOpParam.Op.OPEN ||\n+        op \u003d\u003d PostOpParam.Op.APPEND ||\n+        op \u003d\u003d GetOpParam.Op.GETFILECHECKSUM) {\n+      // Choose a datanode containing a replica\n+      final ClientProtocol cp \u003d getRpcClientProtocol();\n+      final HdfsFileStatus status \u003d cp.getFileInfo(path);\n+      if (status \u003d\u003d null) {\n+        throw new FileNotFoundException(\"File \" + path + \" not found.\");\n+      }\n+      final long len \u003d status.getLen();\n+      if (op \u003d\u003d GetOpParam.Op.OPEN) {\n+        if (openOffset \u003c 0L || (openOffset \u003e\u003d len \u0026\u0026 len \u003e 0)) {\n+          throw new IOException(\"Offset\u003d\" + openOffset\n+              + \" out of the range [0, \" + len + \"); \" + op + \", path\u003d\" + path);\n+        }\n+      }\n+\n+      if (len \u003e 0) {\n+        final long offset \u003d op \u003d\u003d GetOpParam.Op.OPEN ? openOffset : len - 1;\n+        final LocatedBlocks locations \u003d cp.getBlockLocations(path, offset, 1);\n+        final int count \u003d locations.locatedBlockCount();\n+        if (count \u003e 0) {\n+          LocatedBlock location0 \u003d locations.get(0);\n+          return bestNode(location0.getLocations(), excludes);\n+        }\n+      }\n+    }\n+\n+    return getRandomDatanode(dns, excludes);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private DatanodeInfo chooseDatanode(final Router router,\n      final String path, final HttpOpParam.Op op, final long openOffset,\n      final String excludeDatanodes) throws IOException {\n    // We need to get the DNs as a privileged user\n    final RouterRpcServer rpcServer \u003d getRPCServer(router);\n    UserGroupInformation loginUser \u003d UserGroupInformation.getLoginUser();\n\n    DatanodeInfo[] dns \u003d loginUser.doAs(\n        new PrivilegedAction\u003cDatanodeInfo[]\u003e() {\n          @Override\n          public DatanodeInfo[] run() {\n            try {\n              return rpcServer.getDatanodeReport(DatanodeReportType.LIVE);\n            } catch (IOException e) {\n              LOG.error(\"Cannot get the datanodes from the RPC server\", e);\n              return null;\n            }\n          }\n        });\n\n    HashSet\u003cNode\u003e excludes \u003d new HashSet\u003cNode\u003e();\n    if (excludeDatanodes !\u003d null) {\n      Collection\u003cString\u003e collection \u003d\n          getTrimmedStringCollection(excludeDatanodes);\n      for (DatanodeInfo dn : dns) {\n        if (collection.contains(dn.getName())) {\n          excludes.add(dn);\n        }\n      }\n    }\n\n    if (op \u003d\u003d GetOpParam.Op.OPEN ||\n        op \u003d\u003d PostOpParam.Op.APPEND ||\n        op \u003d\u003d GetOpParam.Op.GETFILECHECKSUM) {\n      // Choose a datanode containing a replica\n      final ClientProtocol cp \u003d getRpcClientProtocol();\n      final HdfsFileStatus status \u003d cp.getFileInfo(path);\n      if (status \u003d\u003d null) {\n        throw new FileNotFoundException(\"File \" + path + \" not found.\");\n      }\n      final long len \u003d status.getLen();\n      if (op \u003d\u003d GetOpParam.Op.OPEN) {\n        if (openOffset \u003c 0L || (openOffset \u003e\u003d len \u0026\u0026 len \u003e 0)) {\n          throw new IOException(\"Offset\u003d\" + openOffset\n              + \" out of the range [0, \" + len + \"); \" + op + \", path\u003d\" + path);\n        }\n      }\n\n      if (len \u003e 0) {\n        final long offset \u003d op \u003d\u003d GetOpParam.Op.OPEN ? openOffset : len - 1;\n        final LocatedBlocks locations \u003d cp.getBlockLocations(path, offset, 1);\n        final int count \u003d locations.locatedBlockCount();\n        if (count \u003e 0) {\n          LocatedBlock location0 \u003d locations.get(0);\n          return bestNode(location0.getLocations(), excludes);\n        }\n      }\n    }\n\n    return getRandomDatanode(dns, excludes);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterWebHdfsMethods.java"
    }
  }
}