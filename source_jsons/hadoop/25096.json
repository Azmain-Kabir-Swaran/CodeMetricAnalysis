{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ClientServiceDelegate.java",
  "functionName": "getJobStatus",
  "functionId": "getJobStatus___oldJobID-JobID",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/ClientServiceDelegate.java",
  "functionStartLine": 424,
  "functionEndLine": 444,
  "numCommitsSeen": 51,
  "timeTaken": 7753,
  "changeHistory": [
    "9b9ddf29e28f38648c142adc8bfd8845b7cd7688",
    "4bca22005f48f426b9bc7cf36d435ead470a2590",
    "97ae5b675ff675224fdc7dcf45cd06a26d79218d",
    "7609243e582da9a7d008fc71569897715ced80cb",
    "fab57a144de0cd515e1de9107e4d3ac58037d846",
    "0b3c654d83c5e73fe946de194f3aea0a9fe06f5a",
    "0d2bb0623696c2cc822cb44e431345b2c773dbff",
    "a5c9ede1433871fcf4e2e802ee2a65950ecd1e72",
    "6bdf5746d5d677f9c17598768c4ae86384c000c6",
    "f2b91a8367a762091482074505618b570a520b19",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517"
  ],
  "changeHistoryShort": {
    "9b9ddf29e28f38648c142adc8bfd8845b7cd7688": "Ybodychange",
    "4bca22005f48f426b9bc7cf36d435ead470a2590": "Ybodychange",
    "97ae5b675ff675224fdc7dcf45cd06a26d79218d": "Yexceptionschange",
    "7609243e582da9a7d008fc71569897715ced80cb": "Ybodychange",
    "fab57a144de0cd515e1de9107e4d3ac58037d846": "Ybodychange",
    "0b3c654d83c5e73fe946de194f3aea0a9fe06f5a": "Ybodychange",
    "0d2bb0623696c2cc822cb44e431345b2c773dbff": "Ymodifierchange",
    "a5c9ede1433871fcf4e2e802ee2a65950ecd1e72": "Ybodychange",
    "6bdf5746d5d677f9c17598768c4ae86384c000c6": "Ymultichange(Yexceptionschange,Ybodychange)",
    "f2b91a8367a762091482074505618b570a520b19": "Ymultichange(Ymodifierchange,Ybodychange)",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yintroduced"
  },
  "changeHistoryDetails": {
    "9b9ddf29e28f38648c142adc8bfd8845b7cd7688": {
      "type": "Ybodychange",
      "commitMessage": "YARN-1283. Fixed RM to give a fully-qualified proxy URL for an application so that clients don\u0027t need to do scheme-mangling. Contributed by Omkar Vinit Joshi.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1530819 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/10/13 3:49 PM",
      "commitName": "9b9ddf29e28f38648c142adc8bfd8845b7cd7688",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "19/09/13 3:35 PM",
      "commitNameOld": "af78fd729c3b847c447d4a8edd758fb0c9b25b02",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 20.01,
      "commitsBetweenForRepo": 148,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,21 @@\n   public JobStatus getJobStatus(JobID oldJobID) throws IOException {\n     org.apache.hadoop.mapreduce.v2.api.records.JobId jobId \u003d\n       TypeConverter.toYarn(oldJobID);\n     GetJobReportRequest request \u003d\n         recordFactory.newRecordInstance(GetJobReportRequest.class);\n     request.setJobId(jobId);\n     JobReport report \u003d ((GetJobReportResponse) invoke(\"getJobReport\",\n         GetJobReportRequest.class, request)).getJobReport();\n     JobStatus jobStatus \u003d null;\n     if (report !\u003d null) {\n       if (StringUtils.isEmpty(report.getJobFile())) {\n         String jobFile \u003d MRApps.getJobFile(conf, report.getUser(), oldJobID);\n         report.setJobFile(jobFile);\n       }\n       String historyTrackingUrl \u003d report.getTrackingUrl();\n       String url \u003d StringUtils.isNotEmpty(historyTrackingUrl)\n           ? historyTrackingUrl : trackingUrl;\n-      if (!UNAVAILABLE.equals(url)) {\n-        url \u003d HttpConfig.getSchemePrefix() + url;\n-      }\n       jobStatus \u003d TypeConverter.fromYarn(report, url);\n     }\n     return jobStatus;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public JobStatus getJobStatus(JobID oldJobID) throws IOException {\n    org.apache.hadoop.mapreduce.v2.api.records.JobId jobId \u003d\n      TypeConverter.toYarn(oldJobID);\n    GetJobReportRequest request \u003d\n        recordFactory.newRecordInstance(GetJobReportRequest.class);\n    request.setJobId(jobId);\n    JobReport report \u003d ((GetJobReportResponse) invoke(\"getJobReport\",\n        GetJobReportRequest.class, request)).getJobReport();\n    JobStatus jobStatus \u003d null;\n    if (report !\u003d null) {\n      if (StringUtils.isEmpty(report.getJobFile())) {\n        String jobFile \u003d MRApps.getJobFile(conf, report.getUser(), oldJobID);\n        report.setJobFile(jobFile);\n      }\n      String historyTrackingUrl \u003d report.getTrackingUrl();\n      String url \u003d StringUtils.isNotEmpty(historyTrackingUrl)\n          ? historyTrackingUrl : trackingUrl;\n      jobStatus \u003d TypeConverter.fromYarn(report, url);\n    }\n    return jobStatus;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/ClientServiceDelegate.java",
      "extendedDetails": {}
    },
    "4bca22005f48f426b9bc7cf36d435ead470a2590": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-8681. add support for HTTPS to the web UIs. (tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1371525 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/08/12 3:52 PM",
      "commitName": "4bca22005f48f426b9bc7cf36d435ead470a2590",
      "commitAuthor": "Alejandro Abdelnur",
      "commitDateOld": "15/07/12 2:46 PM",
      "commitNameOld": "ae6cc14611a5898ed637a2e0f9df559f6c29093e",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 25.05,
      "commitsBetweenForRepo": 125,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,24 @@\n   public JobStatus getJobStatus(JobID oldJobID) throws IOException {\n     org.apache.hadoop.mapreduce.v2.api.records.JobId jobId \u003d\n       TypeConverter.toYarn(oldJobID);\n     GetJobReportRequest request \u003d\n         recordFactory.newRecordInstance(GetJobReportRequest.class);\n     request.setJobId(jobId);\n     JobReport report \u003d ((GetJobReportResponse) invoke(\"getJobReport\",\n         GetJobReportRequest.class, request)).getJobReport();\n     JobStatus jobStatus \u003d null;\n     if (report !\u003d null) {\n       if (StringUtils.isEmpty(report.getJobFile())) {\n         String jobFile \u003d MRApps.getJobFile(conf, report.getUser(), oldJobID);\n         report.setJobFile(jobFile);\n       }\n       String historyTrackingUrl \u003d report.getTrackingUrl();\n       String url \u003d StringUtils.isNotEmpty(historyTrackingUrl)\n           ? historyTrackingUrl : trackingUrl;\n       if (!UNAVAILABLE.equals(url)) {\n-        url \u003d \"http://\" + url;\n+        url \u003d HttpConfig.getSchemePrefix() + url;\n       }\n       jobStatus \u003d TypeConverter.fromYarn(report, url);\n     }\n     return jobStatus;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public JobStatus getJobStatus(JobID oldJobID) throws IOException {\n    org.apache.hadoop.mapreduce.v2.api.records.JobId jobId \u003d\n      TypeConverter.toYarn(oldJobID);\n    GetJobReportRequest request \u003d\n        recordFactory.newRecordInstance(GetJobReportRequest.class);\n    request.setJobId(jobId);\n    JobReport report \u003d ((GetJobReportResponse) invoke(\"getJobReport\",\n        GetJobReportRequest.class, request)).getJobReport();\n    JobStatus jobStatus \u003d null;\n    if (report !\u003d null) {\n      if (StringUtils.isEmpty(report.getJobFile())) {\n        String jobFile \u003d MRApps.getJobFile(conf, report.getUser(), oldJobID);\n        report.setJobFile(jobFile);\n      }\n      String historyTrackingUrl \u003d report.getTrackingUrl();\n      String url \u003d StringUtils.isNotEmpty(historyTrackingUrl)\n          ? historyTrackingUrl : trackingUrl;\n      if (!UNAVAILABLE.equals(url)) {\n        url \u003d HttpConfig.getSchemePrefix() + url;\n      }\n      jobStatus \u003d TypeConverter.fromYarn(report, url);\n    }\n    return jobStatus;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/ClientServiceDelegate.java",
      "extendedDetails": {}
    },
    "97ae5b675ff675224fdc7dcf45cd06a26d79218d": {
      "type": "Yexceptionschange",
      "commitMessage": "MAPREDUCE-4074. Client continuously retries to RM When RM goes down before launching Application Master (xieguiming via tgraves)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1327972 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/04/12 7:44 AM",
      "commitName": "97ae5b675ff675224fdc7dcf45cd06a26d79218d",
      "commitAuthor": "Thomas Graves",
      "commitDateOld": "14/03/12 3:02 PM",
      "commitNameOld": "7609243e582da9a7d008fc71569897715ced80cb",
      "commitAuthorOld": "Alejandro Abdelnur",
      "daysBetweenCommits": 35.7,
      "commitsBetweenForRepo": 286,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,24 @@\n-  public JobStatus getJobStatus(JobID oldJobID) throws YarnRemoteException {\n+  public JobStatus getJobStatus(JobID oldJobID) throws IOException {\n     org.apache.hadoop.mapreduce.v2.api.records.JobId jobId \u003d\n       TypeConverter.toYarn(oldJobID);\n     GetJobReportRequest request \u003d\n         recordFactory.newRecordInstance(GetJobReportRequest.class);\n     request.setJobId(jobId);\n     JobReport report \u003d ((GetJobReportResponse) invoke(\"getJobReport\",\n         GetJobReportRequest.class, request)).getJobReport();\n     JobStatus jobStatus \u003d null;\n     if (report !\u003d null) {\n       if (StringUtils.isEmpty(report.getJobFile())) {\n         String jobFile \u003d MRApps.getJobFile(conf, report.getUser(), oldJobID);\n         report.setJobFile(jobFile);\n       }\n       String historyTrackingUrl \u003d report.getTrackingUrl();\n       String url \u003d StringUtils.isNotEmpty(historyTrackingUrl)\n           ? historyTrackingUrl : trackingUrl;\n       if (!UNAVAILABLE.equals(url)) {\n         url \u003d \"http://\" + url;\n       }\n       jobStatus \u003d TypeConverter.fromYarn(report, url);\n     }\n     return jobStatus;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public JobStatus getJobStatus(JobID oldJobID) throws IOException {\n    org.apache.hadoop.mapreduce.v2.api.records.JobId jobId \u003d\n      TypeConverter.toYarn(oldJobID);\n    GetJobReportRequest request \u003d\n        recordFactory.newRecordInstance(GetJobReportRequest.class);\n    request.setJobId(jobId);\n    JobReport report \u003d ((GetJobReportResponse) invoke(\"getJobReport\",\n        GetJobReportRequest.class, request)).getJobReport();\n    JobStatus jobStatus \u003d null;\n    if (report !\u003d null) {\n      if (StringUtils.isEmpty(report.getJobFile())) {\n        String jobFile \u003d MRApps.getJobFile(conf, report.getUser(), oldJobID);\n        report.setJobFile(jobFile);\n      }\n      String historyTrackingUrl \u003d report.getTrackingUrl();\n      String url \u003d StringUtils.isNotEmpty(historyTrackingUrl)\n          ? historyTrackingUrl : trackingUrl;\n      if (!UNAVAILABLE.equals(url)) {\n        url \u003d \"http://\" + url;\n      }\n      jobStatus \u003d TypeConverter.fromYarn(report, url);\n    }\n    return jobStatus;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/ClientServiceDelegate.java",
      "extendedDetails": {
        "oldValue": "[YarnRemoteException]",
        "newValue": "[IOException]"
      }
    },
    "7609243e582da9a7d008fc71569897715ced80cb": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4007. JobClient getJob(JobID) should return NULL if the job does not exist (for backwards compatibility) (tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1300750 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/03/12 3:02 PM",
      "commitName": "7609243e582da9a7d008fc71569897715ced80cb",
      "commitAuthor": "Alejandro Abdelnur",
      "commitDateOld": "09/03/12 10:53 AM",
      "commitNameOld": "ad3d3f54d5f9d2b3648da43481c72bc3f6748ace",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 5.13,
      "commitsBetweenForRepo": 17,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,24 @@\n   public JobStatus getJobStatus(JobID oldJobID) throws YarnRemoteException {\n     org.apache.hadoop.mapreduce.v2.api.records.JobId jobId \u003d\n       TypeConverter.toYarn(oldJobID);\n     GetJobReportRequest request \u003d\n         recordFactory.newRecordInstance(GetJobReportRequest.class);\n     request.setJobId(jobId);\n     JobReport report \u003d ((GetJobReportResponse) invoke(\"getJobReport\",\n         GetJobReportRequest.class, request)).getJobReport();\n-    if (StringUtils.isEmpty(report.getJobFile())) {\n-      String jobFile \u003d MRApps.getJobFile(conf, report.getUser(), oldJobID);\n-      report.setJobFile(jobFile);\n+    JobStatus jobStatus \u003d null;\n+    if (report !\u003d null) {\n+      if (StringUtils.isEmpty(report.getJobFile())) {\n+        String jobFile \u003d MRApps.getJobFile(conf, report.getUser(), oldJobID);\n+        report.setJobFile(jobFile);\n+      }\n+      String historyTrackingUrl \u003d report.getTrackingUrl();\n+      String url \u003d StringUtils.isNotEmpty(historyTrackingUrl)\n+          ? historyTrackingUrl : trackingUrl;\n+      if (!UNAVAILABLE.equals(url)) {\n+        url \u003d \"http://\" + url;\n+      }\n+      jobStatus \u003d TypeConverter.fromYarn(report, url);\n     }\n-    String historyTrackingUrl \u003d report.getTrackingUrl();\n-    String url \u003d StringUtils.isNotEmpty(historyTrackingUrl)\n-        ? historyTrackingUrl : trackingUrl;\n-    if (!UNAVAILABLE.equals(url)) {\n-      url \u003d \"http://\" + url;\n-    }\n-    return TypeConverter.fromYarn(report, url);\n+    return jobStatus;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public JobStatus getJobStatus(JobID oldJobID) throws YarnRemoteException {\n    org.apache.hadoop.mapreduce.v2.api.records.JobId jobId \u003d\n      TypeConverter.toYarn(oldJobID);\n    GetJobReportRequest request \u003d\n        recordFactory.newRecordInstance(GetJobReportRequest.class);\n    request.setJobId(jobId);\n    JobReport report \u003d ((GetJobReportResponse) invoke(\"getJobReport\",\n        GetJobReportRequest.class, request)).getJobReport();\n    JobStatus jobStatus \u003d null;\n    if (report !\u003d null) {\n      if (StringUtils.isEmpty(report.getJobFile())) {\n        String jobFile \u003d MRApps.getJobFile(conf, report.getUser(), oldJobID);\n        report.setJobFile(jobFile);\n      }\n      String historyTrackingUrl \u003d report.getTrackingUrl();\n      String url \u003d StringUtils.isNotEmpty(historyTrackingUrl)\n          ? historyTrackingUrl : trackingUrl;\n      if (!UNAVAILABLE.equals(url)) {\n        url \u003d \"http://\" + url;\n      }\n      jobStatus \u003d TypeConverter.fromYarn(report, url);\n    }\n    return jobStatus;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/ClientServiceDelegate.java",
      "extendedDetails": {}
    },
    "fab57a144de0cd515e1de9107e4d3ac58037d846": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3792. Fix \"bin/mapred job -list\" to display all jobs instead of only the jobs owned by the user. Contributed by Jason Lowe.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1296721 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "03/03/12 3:40 PM",
      "commitName": "fab57a144de0cd515e1de9107e4d3ac58037d846",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "16/02/12 4:54 PM",
      "commitNameOld": "a64046d16fb1569c5454f52f6ecc466eb28e084a",
      "commitAuthorOld": "Siddharth Seth",
      "daysBetweenCommits": 15.95,
      "commitsBetweenForRepo": 125,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,20 @@\n   public JobStatus getJobStatus(JobID oldJobID) throws YarnRemoteException {\n     org.apache.hadoop.mapreduce.v2.api.records.JobId jobId \u003d\n       TypeConverter.toYarn(oldJobID);\n     GetJobReportRequest request \u003d\n         recordFactory.newRecordInstance(GetJobReportRequest.class);\n     request.setJobId(jobId);\n     JobReport report \u003d ((GetJobReportResponse) invoke(\"getJobReport\",\n         GetJobReportRequest.class, request)).getJobReport();\n     if (StringUtils.isEmpty(report.getJobFile())) {\n       String jobFile \u003d MRApps.getJobFile(conf, report.getUser(), oldJobID);\n       report.setJobFile(jobFile);\n     }\n     String historyTrackingUrl \u003d report.getTrackingUrl();\n-    return TypeConverter.fromYarn(report, \"http://\"\n-        + (StringUtils.isNotEmpty(historyTrackingUrl) ? historyTrackingUrl\n-            : trackingUrl));\n+    String url \u003d StringUtils.isNotEmpty(historyTrackingUrl)\n+        ? historyTrackingUrl : trackingUrl;\n+    if (!UNAVAILABLE.equals(url)) {\n+      url \u003d \"http://\" + url;\n+    }\n+    return TypeConverter.fromYarn(report, url);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public JobStatus getJobStatus(JobID oldJobID) throws YarnRemoteException {\n    org.apache.hadoop.mapreduce.v2.api.records.JobId jobId \u003d\n      TypeConverter.toYarn(oldJobID);\n    GetJobReportRequest request \u003d\n        recordFactory.newRecordInstance(GetJobReportRequest.class);\n    request.setJobId(jobId);\n    JobReport report \u003d ((GetJobReportResponse) invoke(\"getJobReport\",\n        GetJobReportRequest.class, request)).getJobReport();\n    if (StringUtils.isEmpty(report.getJobFile())) {\n      String jobFile \u003d MRApps.getJobFile(conf, report.getUser(), oldJobID);\n      report.setJobFile(jobFile);\n    }\n    String historyTrackingUrl \u003d report.getTrackingUrl();\n    String url \u003d StringUtils.isNotEmpty(historyTrackingUrl)\n        ? historyTrackingUrl : trackingUrl;\n    if (!UNAVAILABLE.equals(url)) {\n      url \u003d \"http://\" + url;\n    }\n    return TypeConverter.fromYarn(report, url);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/ClientServiceDelegate.java",
      "extendedDetails": {}
    },
    "0b3c654d83c5e73fe946de194f3aea0a9fe06f5a": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-2791. Added missing info on \u0027job -status\u0027 output. Contributed by Devaraj K.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1177487 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "29/09/11 8:08 PM",
      "commitName": "0b3c654d83c5e73fe946de194f3aea0a9fe06f5a",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "27/09/11 1:30 PM",
      "commitNameOld": "0d2bb0623696c2cc822cb44e431345b2c773dbff",
      "commitAuthorOld": "Mahadev Konar",
      "daysBetweenCommits": 2.28,
      "commitsBetweenForRepo": 27,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,17 @@\n   public JobStatus getJobStatus(JobID oldJobID) throws YarnRemoteException {\n     org.apache.hadoop.mapreduce.v2.api.records.JobId jobId \u003d \n       TypeConverter.toYarn(oldJobID);\n     GetJobReportRequest request \u003d \n         recordFactory.newRecordInstance(GetJobReportRequest.class);\n     request.setJobId(jobId);\n     JobReport report \u003d ((GetJobReportResponse) invoke(\"getJobReport\", \n         GetJobReportRequest.class, request)).getJobReport();\n-    String jobFile \u003d MRApps.getJobFile(conf, report.getUser(), oldJobID); \n-\n-    return TypeConverter.fromYarn(report, jobFile);\n+    if (StringUtils.isEmpty(report.getJobFile())) {\n+      String jobFile \u003d MRApps.getJobFile(conf, report.getUser(), oldJobID);\n+      report.setJobFile(jobFile);\n+    }\n+    String historyTrackingUrl \u003d report.getTrackingUrl();\n+    return TypeConverter.fromYarn(report, \"http://\"\n+        + (StringUtils.isNotEmpty(historyTrackingUrl) ? historyTrackingUrl\n+            : trackingUrl));\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public JobStatus getJobStatus(JobID oldJobID) throws YarnRemoteException {\n    org.apache.hadoop.mapreduce.v2.api.records.JobId jobId \u003d \n      TypeConverter.toYarn(oldJobID);\n    GetJobReportRequest request \u003d \n        recordFactory.newRecordInstance(GetJobReportRequest.class);\n    request.setJobId(jobId);\n    JobReport report \u003d ((GetJobReportResponse) invoke(\"getJobReport\", \n        GetJobReportRequest.class, request)).getJobReport();\n    if (StringUtils.isEmpty(report.getJobFile())) {\n      String jobFile \u003d MRApps.getJobFile(conf, report.getUser(), oldJobID);\n      report.setJobFile(jobFile);\n    }\n    String historyTrackingUrl \u003d report.getTrackingUrl();\n    return TypeConverter.fromYarn(report, \"http://\"\n        + (StringUtils.isNotEmpty(historyTrackingUrl) ? historyTrackingUrl\n            : trackingUrl));\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/ClientServiceDelegate.java",
      "extendedDetails": {}
    },
    "0d2bb0623696c2cc822cb44e431345b2c773dbff": {
      "type": "Ymodifierchange",
      "commitMessage": "MAPREDUCE-3054. Unable to kill submitted jobs. (mahadev)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1176600 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/09/11 1:30 PM",
      "commitName": "0d2bb0623696c2cc822cb44e431345b2c773dbff",
      "commitAuthor": "Mahadev Konar",
      "commitDateOld": "25/09/11 7:46 AM",
      "commitNameOld": "a5c9ede1433871fcf4e2e802ee2a65950ecd1e72",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 2.24,
      "commitsBetweenForRepo": 13,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,12 @@\n-  JobStatus getJobStatus(JobID oldJobID) throws YarnRemoteException {\n+  public JobStatus getJobStatus(JobID oldJobID) throws YarnRemoteException {\n     org.apache.hadoop.mapreduce.v2.api.records.JobId jobId \u003d \n       TypeConverter.toYarn(oldJobID);\n     GetJobReportRequest request \u003d \n         recordFactory.newRecordInstance(GetJobReportRequest.class);\n     request.setJobId(jobId);\n     JobReport report \u003d ((GetJobReportResponse) invoke(\"getJobReport\", \n         GetJobReportRequest.class, request)).getJobReport();\n     String jobFile \u003d MRApps.getJobFile(conf, report.getUser(), oldJobID); \n \n     return TypeConverter.fromYarn(report, jobFile);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public JobStatus getJobStatus(JobID oldJobID) throws YarnRemoteException {\n    org.apache.hadoop.mapreduce.v2.api.records.JobId jobId \u003d \n      TypeConverter.toYarn(oldJobID);\n    GetJobReportRequest request \u003d \n        recordFactory.newRecordInstance(GetJobReportRequest.class);\n    request.setJobId(jobId);\n    JobReport report \u003d ((GetJobReportResponse) invoke(\"getJobReport\", \n        GetJobReportRequest.class, request)).getJobReport();\n    String jobFile \u003d MRApps.getJobFile(conf, report.getUser(), oldJobID); \n\n    return TypeConverter.fromYarn(report, jobFile);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/ClientServiceDelegate.java",
      "extendedDetails": {
        "oldValue": "[]",
        "newValue": "[public]"
      }
    },
    "a5c9ede1433871fcf4e2e802ee2a65950ecd1e72": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-2952. Fixed ResourceManager/MR-client to consume diagnostics for AM failures in a couple of corner cases. Contributed by Arun C Murthy.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1175403 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "25/09/11 7:46 AM",
      "commitName": "a5c9ede1433871fcf4e2e802ee2a65950ecd1e72",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "19/09/11 5:26 AM",
      "commitNameOld": "29552eeb36dd8a9246fb648d65b5cfb94ae46d77",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 6.1,
      "commitsBetweenForRepo": 43,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,12 @@\n   JobStatus getJobStatus(JobID oldJobID) throws YarnRemoteException {\n     org.apache.hadoop.mapreduce.v2.api.records.JobId jobId \u003d \n       TypeConverter.toYarn(oldJobID);\n-    GetJobReportRequest request \u003d recordFactory.newRecordInstance(GetJobReportRequest.class);\n+    GetJobReportRequest request \u003d \n+        recordFactory.newRecordInstance(GetJobReportRequest.class);\n     request.setJobId(jobId);\n     JobReport report \u003d ((GetJobReportResponse) invoke(\"getJobReport\", \n         GetJobReportRequest.class, request)).getJobReport();\n     String jobFile \u003d MRApps.getJobFile(conf, report.getUser(), oldJobID); \n \n-    //TODO: add tracking url in JobReport\n-    return TypeConverter.fromYarn(report, jobFile, \"\");\n+    return TypeConverter.fromYarn(report, jobFile);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  JobStatus getJobStatus(JobID oldJobID) throws YarnRemoteException {\n    org.apache.hadoop.mapreduce.v2.api.records.JobId jobId \u003d \n      TypeConverter.toYarn(oldJobID);\n    GetJobReportRequest request \u003d \n        recordFactory.newRecordInstance(GetJobReportRequest.class);\n    request.setJobId(jobId);\n    JobReport report \u003d ((GetJobReportResponse) invoke(\"getJobReport\", \n        GetJobReportRequest.class, request)).getJobReport();\n    String jobFile \u003d MRApps.getJobFile(conf, report.getUser(), oldJobID); \n\n    return TypeConverter.fromYarn(report, jobFile);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/ClientServiceDelegate.java",
      "extendedDetails": {}
    },
    "6bdf5746d5d677f9c17598768c4ae86384c000c6": {
      "type": "Ymultichange(Yexceptionschange,Ybodychange)",
      "commitMessage": "MAPREDUCE-2716. MRReliabilityTest job fails because of missing job-file. Contributed by Jeffrey Naisbitt.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1164805 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/09/11 11:22 PM",
      "commitName": "6bdf5746d5d677f9c17598768c4ae86384c000c6",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "subchanges": [
        {
          "type": "Yexceptionschange",
          "commitMessage": "MAPREDUCE-2716. MRReliabilityTest job fails because of missing job-file. Contributed by Jeffrey Naisbitt.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1164805 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "02/09/11 11:22 PM",
          "commitName": "6bdf5746d5d677f9c17598768c4ae86384c000c6",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "24/08/11 11:35 PM",
          "commitNameOld": "f2b91a8367a762091482074505618b570a520b19",
          "commitAuthorOld": "Sharad Agarwal",
          "daysBetweenCommits": 8.99,
          "commitsBetweenForRepo": 50,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,14 +1,12 @@\n-  JobStatus getJobStatus(JobID oldJobID) throws YarnRemoteException,\n-       YarnRemoteException {\n+  JobStatus getJobStatus(JobID oldJobID) throws YarnRemoteException {\n     org.apache.hadoop.mapreduce.v2.api.records.JobId jobId \u003d \n       TypeConverter.toYarn(oldJobID);\n-    String stagingDir \u003d conf.get(\"yarn.apps.stagingDir\");\n-    String jobFile \u003d stagingDir + \"/\" + jobId.toString();\n-    MRClientProtocol protocol;\n     GetJobReportRequest request \u003d recordFactory.newRecordInstance(GetJobReportRequest.class);\n     request.setJobId(jobId);\n-    JobReport  report \u003d ((GetJobReportResponse) invoke(\"getJobReport\", \n+    JobReport report \u003d ((GetJobReportResponse) invoke(\"getJobReport\", \n         GetJobReportRequest.class, request)).getJobReport();\n+    String jobFile \u003d MRApps.getJobFile(conf, report.getUser(), oldJobID); \n+\n     //TODO: add tracking url in JobReport\n     return TypeConverter.fromYarn(report, jobFile, \"\");\n   }\n\\ No newline at end of file\n",
          "actualSource": "  JobStatus getJobStatus(JobID oldJobID) throws YarnRemoteException {\n    org.apache.hadoop.mapreduce.v2.api.records.JobId jobId \u003d \n      TypeConverter.toYarn(oldJobID);\n    GetJobReportRequest request \u003d recordFactory.newRecordInstance(GetJobReportRequest.class);\n    request.setJobId(jobId);\n    JobReport report \u003d ((GetJobReportResponse) invoke(\"getJobReport\", \n        GetJobReportRequest.class, request)).getJobReport();\n    String jobFile \u003d MRApps.getJobFile(conf, report.getUser(), oldJobID); \n\n    //TODO: add tracking url in JobReport\n    return TypeConverter.fromYarn(report, jobFile, \"\");\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/ClientServiceDelegate.java",
          "extendedDetails": {
            "oldValue": "[YarnRemoteException, YarnRemoteException]",
            "newValue": "[YarnRemoteException]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "MAPREDUCE-2716. MRReliabilityTest job fails because of missing job-file. Contributed by Jeffrey Naisbitt.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1164805 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "02/09/11 11:22 PM",
          "commitName": "6bdf5746d5d677f9c17598768c4ae86384c000c6",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "24/08/11 11:35 PM",
          "commitNameOld": "f2b91a8367a762091482074505618b570a520b19",
          "commitAuthorOld": "Sharad Agarwal",
          "daysBetweenCommits": 8.99,
          "commitsBetweenForRepo": 50,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,14 +1,12 @@\n-  JobStatus getJobStatus(JobID oldJobID) throws YarnRemoteException,\n-       YarnRemoteException {\n+  JobStatus getJobStatus(JobID oldJobID) throws YarnRemoteException {\n     org.apache.hadoop.mapreduce.v2.api.records.JobId jobId \u003d \n       TypeConverter.toYarn(oldJobID);\n-    String stagingDir \u003d conf.get(\"yarn.apps.stagingDir\");\n-    String jobFile \u003d stagingDir + \"/\" + jobId.toString();\n-    MRClientProtocol protocol;\n     GetJobReportRequest request \u003d recordFactory.newRecordInstance(GetJobReportRequest.class);\n     request.setJobId(jobId);\n-    JobReport  report \u003d ((GetJobReportResponse) invoke(\"getJobReport\", \n+    JobReport report \u003d ((GetJobReportResponse) invoke(\"getJobReport\", \n         GetJobReportRequest.class, request)).getJobReport();\n+    String jobFile \u003d MRApps.getJobFile(conf, report.getUser(), oldJobID); \n+\n     //TODO: add tracking url in JobReport\n     return TypeConverter.fromYarn(report, jobFile, \"\");\n   }\n\\ No newline at end of file\n",
          "actualSource": "  JobStatus getJobStatus(JobID oldJobID) throws YarnRemoteException {\n    org.apache.hadoop.mapreduce.v2.api.records.JobId jobId \u003d \n      TypeConverter.toYarn(oldJobID);\n    GetJobReportRequest request \u003d recordFactory.newRecordInstance(GetJobReportRequest.class);\n    request.setJobId(jobId);\n    JobReport report \u003d ((GetJobReportResponse) invoke(\"getJobReport\", \n        GetJobReportRequest.class, request)).getJobReport();\n    String jobFile \u003d MRApps.getJobFile(conf, report.getUser(), oldJobID); \n\n    //TODO: add tracking url in JobReport\n    return TypeConverter.fromYarn(report, jobFile, \"\");\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/ClientServiceDelegate.java",
          "extendedDetails": {}
        }
      ]
    },
    "f2b91a8367a762091482074505618b570a520b19": {
      "type": "Ymultichange(Ymodifierchange,Ybodychange)",
      "commitMessage": " MAPREDUCE-2807. Fix AM restart and client redirection. Contributed by Sharad Agarwal.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161408 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 11:35 PM",
      "commitName": "f2b91a8367a762091482074505618b570a520b19",
      "commitAuthor": "Sharad Agarwal",
      "subchanges": [
        {
          "type": "Ymodifierchange",
          "commitMessage": " MAPREDUCE-2807. Fix AM restart and client redirection. Contributed by Sharad Agarwal.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161408 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "24/08/11 11:35 PM",
          "commitName": "f2b91a8367a762091482074505618b570a520b19",
          "commitAuthor": "Sharad Agarwal",
          "commitDateOld": "24/08/11 5:14 PM",
          "commitNameOld": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
          "commitAuthorOld": "Arun Murthy",
          "daysBetweenCommits": 0.26,
          "commitsBetweenForRepo": 2,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,36 +1,14 @@\n-  public JobStatus getJobStatus(JobID oldJobID) throws YarnRemoteException,\n-  YarnRemoteException {\n+  JobStatus getJobStatus(JobID oldJobID) throws YarnRemoteException,\n+       YarnRemoteException {\n     org.apache.hadoop.mapreduce.v2.api.records.JobId jobId \u003d \n       TypeConverter.toYarn(oldJobID);\n     String stagingDir \u003d conf.get(\"yarn.apps.stagingDir\");\n     String jobFile \u003d stagingDir + \"/\" + jobId.toString();\n-    JobReport report \u003d null;\n     MRClientProtocol protocol;\n     GetJobReportRequest request \u003d recordFactory.newRecordInstance(GetJobReportRequest.class);\n-    try {\n-      request.setJobId(jobId);\n-      protocol \u003d getProxy(oldJobID);\n-      \n-      if (protocol \u003d\u003d null) {\n-        return createFakeJobReport(currentAppState, jobId, jobFile);\n-      }\n-      report \u003d getProxy(oldJobID).getJobReport(request).getJobReport();\n-    } catch(YarnRemoteException yre) {//thrown by remote server, no need to redirect\n-      LOG.warn(RPCUtil.toString(yre));\n-      throw yre;\n-    } catch (Exception e) {\n-      try {\n-        request.setJobId(jobId);\n-        protocol \u003d getRefreshedProxy(oldJobID);\n-        /* this is possible if an application that was running is killed */\n-        if (protocol \u003d\u003d null)  {\n-          return createFakeJobReport(currentAppState, jobId, jobFile);\n-        }\n-        report \u003d protocol.getJobReport(request).getJobReport();\n-      } catch(YarnRemoteException yre) {\n-        LOG.warn(RPCUtil.toString(yre));\n-        throw yre;\n-      }\n-    }\n-    return TypeConverter.fromYarn(report, jobFile, serviceHttpAddr);\n+    request.setJobId(jobId);\n+    JobReport  report \u003d ((GetJobReportResponse) invoke(\"getJobReport\", \n+        GetJobReportRequest.class, request)).getJobReport();\n+    //TODO: add tracking url in JobReport\n+    return TypeConverter.fromYarn(report, jobFile, \"\");\n   }\n\\ No newline at end of file\n",
          "actualSource": "  JobStatus getJobStatus(JobID oldJobID) throws YarnRemoteException,\n       YarnRemoteException {\n    org.apache.hadoop.mapreduce.v2.api.records.JobId jobId \u003d \n      TypeConverter.toYarn(oldJobID);\n    String stagingDir \u003d conf.get(\"yarn.apps.stagingDir\");\n    String jobFile \u003d stagingDir + \"/\" + jobId.toString();\n    MRClientProtocol protocol;\n    GetJobReportRequest request \u003d recordFactory.newRecordInstance(GetJobReportRequest.class);\n    request.setJobId(jobId);\n    JobReport  report \u003d ((GetJobReportResponse) invoke(\"getJobReport\", \n        GetJobReportRequest.class, request)).getJobReport();\n    //TODO: add tracking url in JobReport\n    return TypeConverter.fromYarn(report, jobFile, \"\");\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/ClientServiceDelegate.java",
          "extendedDetails": {
            "oldValue": "[public]",
            "newValue": "[]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": " MAPREDUCE-2807. Fix AM restart and client redirection. Contributed by Sharad Agarwal.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161408 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "24/08/11 11:35 PM",
          "commitName": "f2b91a8367a762091482074505618b570a520b19",
          "commitAuthor": "Sharad Agarwal",
          "commitDateOld": "24/08/11 5:14 PM",
          "commitNameOld": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
          "commitAuthorOld": "Arun Murthy",
          "daysBetweenCommits": 0.26,
          "commitsBetweenForRepo": 2,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,36 +1,14 @@\n-  public JobStatus getJobStatus(JobID oldJobID) throws YarnRemoteException,\n-  YarnRemoteException {\n+  JobStatus getJobStatus(JobID oldJobID) throws YarnRemoteException,\n+       YarnRemoteException {\n     org.apache.hadoop.mapreduce.v2.api.records.JobId jobId \u003d \n       TypeConverter.toYarn(oldJobID);\n     String stagingDir \u003d conf.get(\"yarn.apps.stagingDir\");\n     String jobFile \u003d stagingDir + \"/\" + jobId.toString();\n-    JobReport report \u003d null;\n     MRClientProtocol protocol;\n     GetJobReportRequest request \u003d recordFactory.newRecordInstance(GetJobReportRequest.class);\n-    try {\n-      request.setJobId(jobId);\n-      protocol \u003d getProxy(oldJobID);\n-      \n-      if (protocol \u003d\u003d null) {\n-        return createFakeJobReport(currentAppState, jobId, jobFile);\n-      }\n-      report \u003d getProxy(oldJobID).getJobReport(request).getJobReport();\n-    } catch(YarnRemoteException yre) {//thrown by remote server, no need to redirect\n-      LOG.warn(RPCUtil.toString(yre));\n-      throw yre;\n-    } catch (Exception e) {\n-      try {\n-        request.setJobId(jobId);\n-        protocol \u003d getRefreshedProxy(oldJobID);\n-        /* this is possible if an application that was running is killed */\n-        if (protocol \u003d\u003d null)  {\n-          return createFakeJobReport(currentAppState, jobId, jobFile);\n-        }\n-        report \u003d protocol.getJobReport(request).getJobReport();\n-      } catch(YarnRemoteException yre) {\n-        LOG.warn(RPCUtil.toString(yre));\n-        throw yre;\n-      }\n-    }\n-    return TypeConverter.fromYarn(report, jobFile, serviceHttpAddr);\n+    request.setJobId(jobId);\n+    JobReport  report \u003d ((GetJobReportResponse) invoke(\"getJobReport\", \n+        GetJobReportRequest.class, request)).getJobReport();\n+    //TODO: add tracking url in JobReport\n+    return TypeConverter.fromYarn(report, jobFile, \"\");\n   }\n\\ No newline at end of file\n",
          "actualSource": "  JobStatus getJobStatus(JobID oldJobID) throws YarnRemoteException,\n       YarnRemoteException {\n    org.apache.hadoop.mapreduce.v2.api.records.JobId jobId \u003d \n      TypeConverter.toYarn(oldJobID);\n    String stagingDir \u003d conf.get(\"yarn.apps.stagingDir\");\n    String jobFile \u003d stagingDir + \"/\" + jobId.toString();\n    MRClientProtocol protocol;\n    GetJobReportRequest request \u003d recordFactory.newRecordInstance(GetJobReportRequest.class);\n    request.setJobId(jobId);\n    JobReport  report \u003d ((GetJobReportResponse) invoke(\"getJobReport\", \n        GetJobReportRequest.class, request)).getJobReport();\n    //TODO: add tracking url in JobReport\n    return TypeConverter.fromYarn(report, jobFile, \"\");\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/ClientServiceDelegate.java",
          "extendedDetails": {}
        }
      ]
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public JobStatus getJobStatus(JobID oldJobID) throws YarnRemoteException,\n  YarnRemoteException {\n    org.apache.hadoop.mapreduce.v2.api.records.JobId jobId \u003d \n      TypeConverter.toYarn(oldJobID);\n    String stagingDir \u003d conf.get(\"yarn.apps.stagingDir\");\n    String jobFile \u003d stagingDir + \"/\" + jobId.toString();\n    JobReport report \u003d null;\n    MRClientProtocol protocol;\n    GetJobReportRequest request \u003d recordFactory.newRecordInstance(GetJobReportRequest.class);\n    try {\n      request.setJobId(jobId);\n      protocol \u003d getProxy(oldJobID);\n      \n      if (protocol \u003d\u003d null) {\n        return createFakeJobReport(currentAppState, jobId, jobFile);\n      }\n      report \u003d getProxy(oldJobID).getJobReport(request).getJobReport();\n    } catch(YarnRemoteException yre) {//thrown by remote server, no need to redirect\n      LOG.warn(RPCUtil.toString(yre));\n      throw yre;\n    } catch (Exception e) {\n      try {\n        request.setJobId(jobId);\n        protocol \u003d getRefreshedProxy(oldJobID);\n        /* this is possible if an application that was running is killed */\n        if (protocol \u003d\u003d null)  {\n          return createFakeJobReport(currentAppState, jobId, jobFile);\n        }\n        report \u003d protocol.getJobReport(request).getJobReport();\n      } catch(YarnRemoteException yre) {\n        LOG.warn(RPCUtil.toString(yre));\n        throw yre;\n      }\n    }\n    return TypeConverter.fromYarn(report, jobFile, serviceHttpAddr);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/ClientServiceDelegate.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/ClientServiceDelegate.java",
        "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/ClientServiceDelegate.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "diff": "@@ -0,0 +1,36 @@\n+  public JobStatus getJobStatus(JobID oldJobID) throws YarnRemoteException,\n+  YarnRemoteException {\n+    org.apache.hadoop.mapreduce.v2.api.records.JobId jobId \u003d \n+      TypeConverter.toYarn(oldJobID);\n+    String stagingDir \u003d conf.get(\"yarn.apps.stagingDir\");\n+    String jobFile \u003d stagingDir + \"/\" + jobId.toString();\n+    JobReport report \u003d null;\n+    MRClientProtocol protocol;\n+    GetJobReportRequest request \u003d recordFactory.newRecordInstance(GetJobReportRequest.class);\n+    try {\n+      request.setJobId(jobId);\n+      protocol \u003d getProxy(oldJobID);\n+      \n+      if (protocol \u003d\u003d null) {\n+        return createFakeJobReport(currentAppState, jobId, jobFile);\n+      }\n+      report \u003d getProxy(oldJobID).getJobReport(request).getJobReport();\n+    } catch(YarnRemoteException yre) {//thrown by remote server, no need to redirect\n+      LOG.warn(RPCUtil.toString(yre));\n+      throw yre;\n+    } catch (Exception e) {\n+      try {\n+        request.setJobId(jobId);\n+        protocol \u003d getRefreshedProxy(oldJobID);\n+        /* this is possible if an application that was running is killed */\n+        if (protocol \u003d\u003d null)  {\n+          return createFakeJobReport(currentAppState, jobId, jobFile);\n+        }\n+        report \u003d protocol.getJobReport(request).getJobReport();\n+      } catch(YarnRemoteException yre) {\n+        LOG.warn(RPCUtil.toString(yre));\n+        throw yre;\n+      }\n+    }\n+    return TypeConverter.fromYarn(report, jobFile, serviceHttpAddr);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public JobStatus getJobStatus(JobID oldJobID) throws YarnRemoteException,\n  YarnRemoteException {\n    org.apache.hadoop.mapreduce.v2.api.records.JobId jobId \u003d \n      TypeConverter.toYarn(oldJobID);\n    String stagingDir \u003d conf.get(\"yarn.apps.stagingDir\");\n    String jobFile \u003d stagingDir + \"/\" + jobId.toString();\n    JobReport report \u003d null;\n    MRClientProtocol protocol;\n    GetJobReportRequest request \u003d recordFactory.newRecordInstance(GetJobReportRequest.class);\n    try {\n      request.setJobId(jobId);\n      protocol \u003d getProxy(oldJobID);\n      \n      if (protocol \u003d\u003d null) {\n        return createFakeJobReport(currentAppState, jobId, jobFile);\n      }\n      report \u003d getProxy(oldJobID).getJobReport(request).getJobReport();\n    } catch(YarnRemoteException yre) {//thrown by remote server, no need to redirect\n      LOG.warn(RPCUtil.toString(yre));\n      throw yre;\n    } catch (Exception e) {\n      try {\n        request.setJobId(jobId);\n        protocol \u003d getRefreshedProxy(oldJobID);\n        /* this is possible if an application that was running is killed */\n        if (protocol \u003d\u003d null)  {\n          return createFakeJobReport(currentAppState, jobId, jobFile);\n        }\n        report \u003d protocol.getJobReport(request).getJobReport();\n      } catch(YarnRemoteException yre) {\n        LOG.warn(RPCUtil.toString(yre));\n        throw yre;\n      }\n    }\n    return TypeConverter.fromYarn(report, jobFile, serviceHttpAddr);\n  }",
      "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/ClientServiceDelegate.java"
    }
  }
}