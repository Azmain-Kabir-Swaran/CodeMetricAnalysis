{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DFSUtilClient.java",
  "functionName": "checkRpcAuxiliary",
  "functionId": "checkRpcAuxiliary___conf-Configuration__suffix-String__address-String",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSUtilClient.java",
  "functionStartLine": 499,
  "functionEndLine": 531,
  "numCommitsSeen": 44,
  "timeTaken": 1781,
  "changeHistory": [
    "fb8932a727f757b2e9c1c61a18145878d0eb77bd",
    "635786a511344b53b1d3f25c2f29ab5298f6ac74"
  ],
  "changeHistoryShort": {
    "fb8932a727f757b2e9c1c61a18145878d0eb77bd": "Ybodychange",
    "635786a511344b53b1d3f25c2f29ab5298f6ac74": "Yintroduced"
  },
  "changeHistoryDetails": {
    "fb8932a727f757b2e9c1c61a18145878d0eb77bd": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-16029. Consecutive StringBuilder.append can be reused. Contributed by Ayush Saxena.\n",
      "commitDate": "11/01/19 10:54 AM",
      "commitName": "fb8932a727f757b2e9c1c61a18145878d0eb77bd",
      "commitAuthor": "Giovanni Matteo Fumarola",
      "commitDateOld": "23/10/18 2:53 PM",
      "commitNameOld": "635786a511344b53b1d3f25c2f29ab5298f6ac74",
      "commitAuthorOld": "Chen Liang",
      "daysBetweenCommits": 79.88,
      "commitsBetweenForRepo": 522,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,33 +1,33 @@\n   private static String checkRpcAuxiliary(Configuration conf, String suffix,\n       String address) {\n     String key \u003d DFS_NAMENODE_RPC_ADDRESS_AUXILIARY_KEY;\n     key \u003d addSuffix(key, suffix);\n     int[] ports \u003d conf.getInts(key);\n     if (ports \u003d\u003d null || ports.length \u003d\u003d 0) {\n       return address;\n     }\n     LOG.info(\"Using server auxiliary ports \" + Arrays.toString(ports));\n     URI uri;\n     try {\n       uri \u003d new URI(address);\n     } catch (URISyntaxException e) {\n       // return the original address untouched if it is not a valid URI. This\n       // happens in unit test, as MiniDFSCluster sets the value to\n       // 127.0.0.1:0, without schema (i.e. \"hdfs://\"). While in practice, this\n       // should not be the case. So log a warning message here.\n       LOG.warn(\"NameNode address is not a valid uri:\" + address);\n       return address;\n     }\n     // Ignore the port, only take the schema(e.g. hdfs) and host (e.g.\n     // localhost), then append port\n     // TODO : revisit if there is a better way\n     StringBuilder sb \u003d new StringBuilder();\n-    sb.append(uri.getScheme());\n-    sb.append(\"://\");\n-    sb.append(uri.getHost());\n-    sb.append(\":\");\n+    sb.append(uri.getScheme())\n+        .append(\"://\")\n+        .append(uri.getHost())\n+        .append(\":\");\n     // TODO : currently, only the very first auxiliary port is being used.\n     // But actually NN supports running multiple auxiliary\n     sb.append(ports[0]);\n     return sb.toString();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private static String checkRpcAuxiliary(Configuration conf, String suffix,\n      String address) {\n    String key \u003d DFS_NAMENODE_RPC_ADDRESS_AUXILIARY_KEY;\n    key \u003d addSuffix(key, suffix);\n    int[] ports \u003d conf.getInts(key);\n    if (ports \u003d\u003d null || ports.length \u003d\u003d 0) {\n      return address;\n    }\n    LOG.info(\"Using server auxiliary ports \" + Arrays.toString(ports));\n    URI uri;\n    try {\n      uri \u003d new URI(address);\n    } catch (URISyntaxException e) {\n      // return the original address untouched if it is not a valid URI. This\n      // happens in unit test, as MiniDFSCluster sets the value to\n      // 127.0.0.1:0, without schema (i.e. \"hdfs://\"). While in practice, this\n      // should not be the case. So log a warning message here.\n      LOG.warn(\"NameNode address is not a valid uri:\" + address);\n      return address;\n    }\n    // Ignore the port, only take the schema(e.g. hdfs) and host (e.g.\n    // localhost), then append port\n    // TODO : revisit if there is a better way\n    StringBuilder sb \u003d new StringBuilder();\n    sb.append(uri.getScheme())\n        .append(\"://\")\n        .append(uri.getHost())\n        .append(\":\");\n    // TODO : currently, only the very first auxiliary port is being used.\n    // But actually NN supports running multiple auxiliary\n    sb.append(ports[0]);\n    return sb.toString();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSUtilClient.java",
      "extendedDetails": {}
    },
    "635786a511344b53b1d3f25c2f29ab5298f6ac74": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-13566. Add configurable additional RPC listener to NameNode. Contributed by Chen Liang.\n",
      "commitDate": "23/10/18 2:53 PM",
      "commitName": "635786a511344b53b1d3f25c2f29ab5298f6ac74",
      "commitAuthor": "Chen Liang",
      "diff": "@@ -0,0 +1,33 @@\n+  private static String checkRpcAuxiliary(Configuration conf, String suffix,\n+      String address) {\n+    String key \u003d DFS_NAMENODE_RPC_ADDRESS_AUXILIARY_KEY;\n+    key \u003d addSuffix(key, suffix);\n+    int[] ports \u003d conf.getInts(key);\n+    if (ports \u003d\u003d null || ports.length \u003d\u003d 0) {\n+      return address;\n+    }\n+    LOG.info(\"Using server auxiliary ports \" + Arrays.toString(ports));\n+    URI uri;\n+    try {\n+      uri \u003d new URI(address);\n+    } catch (URISyntaxException e) {\n+      // return the original address untouched if it is not a valid URI. This\n+      // happens in unit test, as MiniDFSCluster sets the value to\n+      // 127.0.0.1:0, without schema (i.e. \"hdfs://\"). While in practice, this\n+      // should not be the case. So log a warning message here.\n+      LOG.warn(\"NameNode address is not a valid uri:\" + address);\n+      return address;\n+    }\n+    // Ignore the port, only take the schema(e.g. hdfs) and host (e.g.\n+    // localhost), then append port\n+    // TODO : revisit if there is a better way\n+    StringBuilder sb \u003d new StringBuilder();\n+    sb.append(uri.getScheme());\n+    sb.append(\"://\");\n+    sb.append(uri.getHost());\n+    sb.append(\":\");\n+    // TODO : currently, only the very first auxiliary port is being used.\n+    // But actually NN supports running multiple auxiliary\n+    sb.append(ports[0]);\n+    return sb.toString();\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private static String checkRpcAuxiliary(Configuration conf, String suffix,\n      String address) {\n    String key \u003d DFS_NAMENODE_RPC_ADDRESS_AUXILIARY_KEY;\n    key \u003d addSuffix(key, suffix);\n    int[] ports \u003d conf.getInts(key);\n    if (ports \u003d\u003d null || ports.length \u003d\u003d 0) {\n      return address;\n    }\n    LOG.info(\"Using server auxiliary ports \" + Arrays.toString(ports));\n    URI uri;\n    try {\n      uri \u003d new URI(address);\n    } catch (URISyntaxException e) {\n      // return the original address untouched if it is not a valid URI. This\n      // happens in unit test, as MiniDFSCluster sets the value to\n      // 127.0.0.1:0, without schema (i.e. \"hdfs://\"). While in practice, this\n      // should not be the case. So log a warning message here.\n      LOG.warn(\"NameNode address is not a valid uri:\" + address);\n      return address;\n    }\n    // Ignore the port, only take the schema(e.g. hdfs) and host (e.g.\n    // localhost), then append port\n    // TODO : revisit if there is a better way\n    StringBuilder sb \u003d new StringBuilder();\n    sb.append(uri.getScheme());\n    sb.append(\"://\");\n    sb.append(uri.getHost());\n    sb.append(\":\");\n    // TODO : currently, only the very first auxiliary port is being used.\n    // But actually NN supports running multiple auxiliary\n    sb.append(ports[0]);\n    return sb.toString();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSUtilClient.java"
    }
  }
}