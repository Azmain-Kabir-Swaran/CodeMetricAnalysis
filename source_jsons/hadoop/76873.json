{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ECSchema.java",
  "functionName": "toString",
  "functionId": "toString",
  "sourceFilePath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/ECSchema.java",
  "functionStartLine": 187,
  "functionEndLine": 204,
  "numCommitsSeen": 16,
  "timeTaken": 1981,
  "changeHistory": [
    "fb8932a727f757b2e9c1c61a18145878d0eb77bd",
    "092ebdf885468a2bf79cbfb168286b7cddc4a0db",
    "1d37a8812160bb030244a1e6b1c753f962d8d2ed",
    "5a391e1d2584dc5d77fb1325ea91c8e5854934d1",
    "e8df2581c3293d0b6c43862edbf034f9e7851dbf",
    "c0945a8971097d56a37e6d0a4085df3f0b9d0589"
  ],
  "changeHistoryShort": {
    "fb8932a727f757b2e9c1c61a18145878d0eb77bd": "Ybodychange",
    "092ebdf885468a2bf79cbfb168286b7cddc4a0db": "Ybodychange",
    "1d37a8812160bb030244a1e6b1c753f962d8d2ed": "Ybodychange",
    "5a391e1d2584dc5d77fb1325ea91c8e5854934d1": "Ybodychange",
    "e8df2581c3293d0b6c43862edbf034f9e7851dbf": "Ybodychange",
    "c0945a8971097d56a37e6d0a4085df3f0b9d0589": "Yintroduced"
  },
  "changeHistoryDetails": {
    "fb8932a727f757b2e9c1c61a18145878d0eb77bd": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-16029. Consecutive StringBuilder.append can be reused. Contributed by Ayush Saxena.\n",
      "commitDate": "11/01/19 10:54 AM",
      "commitName": "fb8932a727f757b2e9c1c61a18145878d0eb77bd",
      "commitAuthor": "Giovanni Matteo Fumarola",
      "commitDateOld": "27/06/18 10:37 PM",
      "commitNameOld": "2b2399d623539ab68e71a38fa9fbfc9a405bddb8",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 197.55,
      "commitsBetweenForRepo": 1542,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,18 +1,18 @@\n   public String toString() {\n     StringBuilder sb \u003d new StringBuilder(\"ECSchema\u003d[\");\n \n-    sb.append(\"Codec\u003d\" + codecName + \", \");\n-    sb.append(NUM_DATA_UNITS_KEY + \"\u003d\" + numDataUnits + \", \");\n-    sb.append(NUM_PARITY_UNITS_KEY + \"\u003d\" + numParityUnits);\n-    sb.append((extraOptions.isEmpty() ? \"\" : \", \"));\n+    sb.append(\"Codec\u003d\" + codecName + \", \")\n+        .append(NUM_DATA_UNITS_KEY + \"\u003d\" + numDataUnits + \", \")\n+        .append(NUM_PARITY_UNITS_KEY + \"\u003d\" + numParityUnits)\n+        .append((extraOptions.isEmpty() ? \"\" : \", \"));\n \n     int i \u003d 0;\n     for (Map.Entry\u003cString, String\u003e entry : extraOptions.entrySet()) {\n       sb.append(entry.getKey() + \"\u003d\" + entry.getValue() +\n           (++i \u003c extraOptions.size() ? \", \" : \"\"));\n     }\n \n     sb.append(\"]\");\n \n     return sb.toString();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public String toString() {\n    StringBuilder sb \u003d new StringBuilder(\"ECSchema\u003d[\");\n\n    sb.append(\"Codec\u003d\" + codecName + \", \")\n        .append(NUM_DATA_UNITS_KEY + \"\u003d\" + numDataUnits + \", \")\n        .append(NUM_PARITY_UNITS_KEY + \"\u003d\" + numParityUnits)\n        .append((extraOptions.isEmpty() ? \"\" : \", \"));\n\n    int i \u003d 0;\n    for (Map.Entry\u003cString, String\u003e entry : extraOptions.entrySet()) {\n      sb.append(entry.getKey() + \"\u003d\" + entry.getValue() +\n          (++i \u003c extraOptions.size() ? \", \" : \"\"));\n    }\n\n    sb.append(\"]\");\n\n    return sb.toString();\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/ECSchema.java",
      "extendedDetails": {}
    },
    "092ebdf885468a2bf79cbfb168286b7cddc4a0db": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-12940. Fix warnings from Spotbugs in hadoop-common.\n",
      "commitDate": "22/06/17 6:28 PM",
      "commitName": "092ebdf885468a2bf79cbfb168286b7cddc4a0db",
      "commitAuthor": "Akira Ajisaka",
      "commitDateOld": "27/04/17 10:18 PM",
      "commitNameOld": "cb672a45a0bbd8950b9b5e304c2e03f516945903",
      "commitAuthorOld": "Kai Zheng",
      "daysBetweenCommits": 55.84,
      "commitsBetweenForRepo": 282,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,18 +1,18 @@\n   public String toString() {\n     StringBuilder sb \u003d new StringBuilder(\"ECSchema\u003d[\");\n \n     sb.append(\"Codec\u003d\" + codecName + \", \");\n     sb.append(NUM_DATA_UNITS_KEY + \"\u003d\" + numDataUnits + \", \");\n     sb.append(NUM_PARITY_UNITS_KEY + \"\u003d\" + numParityUnits);\n     sb.append((extraOptions.isEmpty() ? \"\" : \", \"));\n \n     int i \u003d 0;\n-    for (String opt : extraOptions.keySet()) {\n-      sb.append(opt + \"\u003d\" + extraOptions.get(opt) +\n+    for (Map.Entry\u003cString, String\u003e entry : extraOptions.entrySet()) {\n+      sb.append(entry.getKey() + \"\u003d\" + entry.getValue() +\n           (++i \u003c extraOptions.size() ? \", \" : \"\"));\n     }\n \n     sb.append(\"]\");\n \n     return sb.toString();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public String toString() {\n    StringBuilder sb \u003d new StringBuilder(\"ECSchema\u003d[\");\n\n    sb.append(\"Codec\u003d\" + codecName + \", \");\n    sb.append(NUM_DATA_UNITS_KEY + \"\u003d\" + numDataUnits + \", \");\n    sb.append(NUM_PARITY_UNITS_KEY + \"\u003d\" + numParityUnits);\n    sb.append((extraOptions.isEmpty() ? \"\" : \", \"));\n\n    int i \u003d 0;\n    for (Map.Entry\u003cString, String\u003e entry : extraOptions.entrySet()) {\n      sb.append(entry.getKey() + \"\u003d\" + entry.getValue() +\n          (++i \u003c extraOptions.size() ? \", \" : \"\"));\n    }\n\n    sb.append(\"]\");\n\n    return sb.toString();\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/ECSchema.java",
      "extendedDetails": {}
    },
    "1d37a8812160bb030244a1e6b1c753f962d8d2ed": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8854. Erasure coding: add ECPolicy to replace schema+cellSize in hadoop-hdfs. Contributed by Walter Su.\n",
      "commitDate": "13/08/15 10:04 AM",
      "commitName": "1d37a8812160bb030244a1e6b1c753f962d8d2ed",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "20/07/15 10:15 AM",
      "commitNameOld": "29495cb8f6b940caa9964c39a290ef233ce1ec7c",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 23.99,
      "commitsBetweenForRepo": 11,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,19 +1,18 @@\n   public String toString() {\n     StringBuilder sb \u003d new StringBuilder(\"ECSchema\u003d[\");\n \n-    sb.append(\"Name\u003d\" + schemaName + \", \");\n     sb.append(\"Codec\u003d\" + codecName + \", \");\n     sb.append(NUM_DATA_UNITS_KEY + \"\u003d\" + numDataUnits + \", \");\n     sb.append(NUM_PARITY_UNITS_KEY + \"\u003d\" + numParityUnits);\n     sb.append((extraOptions.isEmpty() ? \"\" : \", \"));\n \n     int i \u003d 0;\n     for (String opt : extraOptions.keySet()) {\n       sb.append(opt + \"\u003d\" + extraOptions.get(opt) +\n           (++i \u003c extraOptions.size() ? \", \" : \"\"));\n     }\n \n     sb.append(\"]\");\n \n     return sb.toString();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public String toString() {\n    StringBuilder sb \u003d new StringBuilder(\"ECSchema\u003d[\");\n\n    sb.append(\"Codec\u003d\" + codecName + \", \");\n    sb.append(NUM_DATA_UNITS_KEY + \"\u003d\" + numDataUnits + \", \");\n    sb.append(NUM_PARITY_UNITS_KEY + \"\u003d\" + numParityUnits);\n    sb.append((extraOptions.isEmpty() ? \"\" : \", \"));\n\n    int i \u003d 0;\n    for (String opt : extraOptions.keySet()) {\n      sb.append(opt + \"\u003d\" + extraOptions.get(opt) +\n          (++i \u003c extraOptions.size() ? \", \" : \"\"));\n    }\n\n    sb.append(\"]\");\n\n    return sb.toString();\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/ECSchema.java",
      "extendedDetails": {}
    },
    "5a391e1d2584dc5d77fb1325ea91c8e5854934d1": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-12029. Remove chunkSize from ECSchema as its not required for coders (Contributed by Vinayakumar B)\n",
      "commitDate": "26/05/15 12:07 PM",
      "commitName": "5a391e1d2584dc5d77fb1325ea91c8e5854934d1",
      "commitAuthor": "Vinayakumar B",
      "commitDateOld": "26/05/15 11:59 AM",
      "commitNameOld": "e8df2581c3293d0b6c43862edbf034f9e7851dbf",
      "commitAuthorOld": "Zhe Zhang",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 59,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,19 @@\n   public String toString() {\n     StringBuilder sb \u003d new StringBuilder(\"ECSchema\u003d[\");\n \n     sb.append(\"Name\u003d\" + schemaName + \", \");\n     sb.append(\"Codec\u003d\" + codecName + \", \");\n     sb.append(NUM_DATA_UNITS_KEY + \"\u003d\" + numDataUnits + \", \");\n-    sb.append(NUM_PARITY_UNITS_KEY + \"\u003d\" + numParityUnits + \", \");\n-    sb.append(CHUNK_SIZE_KEY + \"\u003d\" + chunkSize +\n-        (extraOptions.isEmpty() ? \"\" : \", \"));\n+    sb.append(NUM_PARITY_UNITS_KEY + \"\u003d\" + numParityUnits);\n+    sb.append((extraOptions.isEmpty() ? \"\" : \", \"));\n \n     int i \u003d 0;\n     for (String opt : extraOptions.keySet()) {\n       sb.append(opt + \"\u003d\" + extraOptions.get(opt) +\n           (++i \u003c extraOptions.size() ? \", \" : \"\"));\n     }\n \n     sb.append(\"]\");\n \n     return sb.toString();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public String toString() {\n    StringBuilder sb \u003d new StringBuilder(\"ECSchema\u003d[\");\n\n    sb.append(\"Name\u003d\" + schemaName + \", \");\n    sb.append(\"Codec\u003d\" + codecName + \", \");\n    sb.append(NUM_DATA_UNITS_KEY + \"\u003d\" + numDataUnits + \", \");\n    sb.append(NUM_PARITY_UNITS_KEY + \"\u003d\" + numParityUnits);\n    sb.append((extraOptions.isEmpty() ? \"\" : \", \"));\n\n    int i \u003d 0;\n    for (String opt : extraOptions.keySet()) {\n      sb.append(opt + \"\u003d\" + extraOptions.get(opt) +\n          (++i \u003c extraOptions.size() ? \", \" : \"\"));\n    }\n\n    sb.append(\"]\");\n\n    return sb.toString();\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/ECSchema.java",
      "extendedDetails": {}
    },
    "e8df2581c3293d0b6c43862edbf034f9e7851dbf": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8156. Add/implement necessary APIs even we just have the system default schema. Contributed by Kai Zheng.\n",
      "commitDate": "26/05/15 11:59 AM",
      "commitName": "e8df2581c3293d0b6c43862edbf034f9e7851dbf",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "26/05/15 11:58 AM",
      "commitNameOld": "f53e402635a990458113ba0595655751d83c02e1",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 21,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,20 @@\n   public String toString() {\n     StringBuilder sb \u003d new StringBuilder(\"ECSchema\u003d[\");\n \n-    sb.append(\"Name\u003d\" + schemaName + \",\");\n-    sb.append(NUM_DATA_UNITS_KEY + \"\u003d\" + numDataUnits + \",\");\n-    sb.append(NUM_PARITY_UNITS_KEY + \"\u003d\" + numParityUnits + \",\");\n-    sb.append(CHUNK_SIZE_KEY + \"\u003d\" + chunkSize + \",\");\n+    sb.append(\"Name\u003d\" + schemaName + \", \");\n+    sb.append(\"Codec\u003d\" + codecName + \", \");\n+    sb.append(NUM_DATA_UNITS_KEY + \"\u003d\" + numDataUnits + \", \");\n+    sb.append(NUM_PARITY_UNITS_KEY + \"\u003d\" + numParityUnits + \", \");\n+    sb.append(CHUNK_SIZE_KEY + \"\u003d\" + chunkSize +\n+        (extraOptions.isEmpty() ? \"\" : \", \"));\n \n-    for (String opt : options.keySet()) {\n-      boolean skip \u003d (opt.equals(NUM_DATA_UNITS_KEY) ||\n-          opt.equals(NUM_PARITY_UNITS_KEY) ||\n-          opt.equals(CHUNK_SIZE_KEY));\n-      if (! skip) {\n-        sb.append(opt + \"\u003d\" + options.get(opt) + \",\");\n-      }\n+    int i \u003d 0;\n+    for (String opt : extraOptions.keySet()) {\n+      sb.append(opt + \"\u003d\" + extraOptions.get(opt) +\n+          (++i \u003c extraOptions.size() ? \", \" : \"\"));\n     }\n \n     sb.append(\"]\");\n \n     return sb.toString();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public String toString() {\n    StringBuilder sb \u003d new StringBuilder(\"ECSchema\u003d[\");\n\n    sb.append(\"Name\u003d\" + schemaName + \", \");\n    sb.append(\"Codec\u003d\" + codecName + \", \");\n    sb.append(NUM_DATA_UNITS_KEY + \"\u003d\" + numDataUnits + \", \");\n    sb.append(NUM_PARITY_UNITS_KEY + \"\u003d\" + numParityUnits + \", \");\n    sb.append(CHUNK_SIZE_KEY + \"\u003d\" + chunkSize +\n        (extraOptions.isEmpty() ? \"\" : \", \"));\n\n    int i \u003d 0;\n    for (String opt : extraOptions.keySet()) {\n      sb.append(opt + \"\u003d\" + extraOptions.get(opt) +\n          (++i \u003c extraOptions.size() ? \", \" : \"\"));\n    }\n\n    sb.append(\"]\");\n\n    return sb.toString();\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/ECSchema.java",
      "extendedDetails": {}
    },
    "c0945a8971097d56a37e6d0a4085df3f0b9d0589": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-11643. Define EC schema API for ErasureCodec. Contributed by Kai Zheng\n",
      "commitDate": "26/05/15 11:32 AM",
      "commitName": "c0945a8971097d56a37e6d0a4085df3f0b9d0589",
      "commitAuthor": "drankye",
      "diff": "@@ -0,0 +1,21 @@\n+  public String toString() {\n+    StringBuilder sb \u003d new StringBuilder(\"ECSchema\u003d[\");\n+\n+    sb.append(\"Name\u003d\" + schemaName + \",\");\n+    sb.append(NUM_DATA_UNITS_KEY + \"\u003d\" + numDataUnits + \",\");\n+    sb.append(NUM_PARITY_UNITS_KEY + \"\u003d\" + numParityUnits + \",\");\n+    sb.append(CHUNK_SIZE_KEY + \"\u003d\" + chunkSize + \",\");\n+\n+    for (String opt : options.keySet()) {\n+      boolean skip \u003d (opt.equals(NUM_DATA_UNITS_KEY) ||\n+          opt.equals(NUM_PARITY_UNITS_KEY) ||\n+          opt.equals(CHUNK_SIZE_KEY));\n+      if (! skip) {\n+        sb.append(opt + \"\u003d\" + options.get(opt) + \",\");\n+      }\n+    }\n+\n+    sb.append(\"]\");\n+\n+    return sb.toString();\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public String toString() {\n    StringBuilder sb \u003d new StringBuilder(\"ECSchema\u003d[\");\n\n    sb.append(\"Name\u003d\" + schemaName + \",\");\n    sb.append(NUM_DATA_UNITS_KEY + \"\u003d\" + numDataUnits + \",\");\n    sb.append(NUM_PARITY_UNITS_KEY + \"\u003d\" + numParityUnits + \",\");\n    sb.append(CHUNK_SIZE_KEY + \"\u003d\" + chunkSize + \",\");\n\n    for (String opt : options.keySet()) {\n      boolean skip \u003d (opt.equals(NUM_DATA_UNITS_KEY) ||\n          opt.equals(NUM_PARITY_UNITS_KEY) ||\n          opt.equals(CHUNK_SIZE_KEY));\n      if (! skip) {\n        sb.append(opt + \"\u003d\" + options.get(opt) + \",\");\n      }\n    }\n\n    sb.append(\"]\");\n\n    return sb.toString();\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/ECSchema.java"
    }
  }
}