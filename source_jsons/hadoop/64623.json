{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "S3AFileSystem.java",
  "functionName": "deleteObjects",
  "functionId": "deleteObjects___deleteRequest-DeleteObjectsRequest",
  "sourceFilePath": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java",
  "functionStartLine": 2039,
  "functionEndLine": 2068,
  "numCommitsSeen": 141,
  "timeTaken": 7099,
  "changeHistory": [
    "56dee667707926f3796c7757be1a133a362f05c9",
    "511df1e837b19ccb9271520589452d82d50ac69d",
    "e02eb24e0a9139418120027b694492e0738df20a",
    "9a013b255f301c557c3868dc1ad657202e9e7a67",
    "de8b6ca5ef8614de6d6277b7617e27c788b0555c",
    "ba70225cf6a1e7dc756f4991881de04f525ff088",
    "c58a59f7081d55dd2108545ebf9ee48cf43ca944"
  ],
  "changeHistoryShort": {
    "56dee667707926f3796c7757be1a133a362f05c9": "Ybodychange",
    "511df1e837b19ccb9271520589452d82d50ac69d": "Ymultichange(Yreturntypechange,Ybodychange)",
    "e02eb24e0a9139418120027b694492e0738df20a": "Ybodychange",
    "9a013b255f301c557c3868dc1ad657202e9e7a67": "Ybodychange",
    "de8b6ca5ef8614de6d6277b7617e27c788b0555c": "Ymultichange(Yexceptionschange,Ybodychange)",
    "ba70225cf6a1e7dc756f4991881de04f525ff088": "Ymultichange(Yexceptionschange,Ybodychange)",
    "c58a59f7081d55dd2108545ebf9ee48cf43ca944": "Yintroduced"
  },
  "changeHistoryDetails": {
    "56dee667707926f3796c7757be1a133a362f05c9": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-16823. Large DeleteObject requests are their own Thundering Herd.\n\nContributed by Steve Loughran.\n\nDuring S3A rename() and delete() calls, the list of objects delete is\nbuilt up into batches of a thousand and then POSTed in a single large\nDeleteObjects request.\n\nBut as the IO capacity allowed on an S3 partition may only be 3500 writes\nper second *and* each entry in that POST counts as a single write, then\none of those posts alone can trigger throttling on an already loaded\nS3 directory tree. Which can trigger backoff and retry, with the same\nthousand entry post, and so recreate the exact same problem.\n\nFixes\n\n* Page size for delete object requests is set in\n  fs.s3a.bulk.delete.page.size; the default is 250.\n* The property fs.s3a.experimental.aws.s3.throttling (default\u003dtrue)\n  can be set to false to disable throttle retry logic in the AWS\n  client SDK -it is all handled in the S3A client. This\n  gives more visibility in to when operations are being throttled\n* Bulk delete throttling events are logged to the log\n  org.apache.hadoop.fs.s3a.throttled log at INFO; if this appears\n  often then choose a smaller page size.\n* The metric \"store_io_throttled\" adds the entire count of delete\n  requests when a single DeleteObjects request is throttled.\n* A new quantile, \"store_io_throttle_rate\" can track throttling\n  load over time.\n* DynamoDB metastore throttle resilience issues have also been\n  identified and fixed. Note: the fs.s3a.experimental.aws.s3.throttling\n  flag does not apply to DDB IO precisely because there may still be\n  lurking issues there and it safest to rely on the DynamoDB client\n  SDK.\n\nChange-Id: I00f85cdd94fc008864d060533f6bd4870263fd84\n",
      "commitDate": "13/02/20 11:09 AM",
      "commitName": "56dee667707926f3796c7757be1a133a362f05c9",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "30/01/20 2:16 AM",
      "commitNameOld": "5977360878e6780bd04842c8a2156f9848e1d088",
      "commitAuthorOld": "Mustafa Ä°man",
      "daysBetweenCommits": 14.37,
      "commitsBetweenForRepo": 35,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,30 @@\n   private DeleteObjectsResult deleteObjects(DeleteObjectsRequest deleteRequest)\n       throws MultiObjectDeleteException, AmazonClientException, IOException {\n     incrementWriteOperations();\n+    BulkDeleteRetryHandler retryHandler \u003d\n+        new BulkDeleteRetryHandler(createStoreContext());\n     try(DurationInfo ignored \u003d\n             new DurationInfo(LOG, false, \"DELETE %d keys\",\n                 deleteRequest.getKeys().size())) {\n       return invoker.retryUntranslated(\"delete\",\n           DELETE_CONSIDERED_IDEMPOTENT,\n+          (text, e, r, i) -\u003e {\n+            // handle the failure\n+            retryHandler.bulkDeleteRetried(deleteRequest, e);\n+          },\n           () -\u003e {\n             incrementStatistic(OBJECT_DELETE_REQUESTS, 1);\n             return s3.deleteObjects(deleteRequest);\n           });\n     } catch (MultiObjectDeleteException e) {\n-      // one or more of the operations failed.\n+      // one or more of the keys could not be deleted.\n+      // log and rethrow\n       List\u003cMultiObjectDeleteException.DeleteError\u003e errors \u003d e.getErrors();\n       LOG.debug(\"Partial failure of delete, {} errors\", errors.size(), e);\n       for (MultiObjectDeleteException.DeleteError error : errors) {\n         LOG.debug(\"{}: \\\"{}\\\" - {}\",\n             error.getKey(), error.getCode(), error.getMessage());\n       }\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private DeleteObjectsResult deleteObjects(DeleteObjectsRequest deleteRequest)\n      throws MultiObjectDeleteException, AmazonClientException, IOException {\n    incrementWriteOperations();\n    BulkDeleteRetryHandler retryHandler \u003d\n        new BulkDeleteRetryHandler(createStoreContext());\n    try(DurationInfo ignored \u003d\n            new DurationInfo(LOG, false, \"DELETE %d keys\",\n                deleteRequest.getKeys().size())) {\n      return invoker.retryUntranslated(\"delete\",\n          DELETE_CONSIDERED_IDEMPOTENT,\n          (text, e, r, i) -\u003e {\n            // handle the failure\n            retryHandler.bulkDeleteRetried(deleteRequest, e);\n          },\n          () -\u003e {\n            incrementStatistic(OBJECT_DELETE_REQUESTS, 1);\n            return s3.deleteObjects(deleteRequest);\n          });\n    } catch (MultiObjectDeleteException e) {\n      // one or more of the keys could not be deleted.\n      // log and rethrow\n      List\u003cMultiObjectDeleteException.DeleteError\u003e errors \u003d e.getErrors();\n      LOG.debug(\"Partial failure of delete, {} errors\", errors.size(), e);\n      for (MultiObjectDeleteException.DeleteError error : errors) {\n        LOG.debug(\"{}: \\\"{}\\\" - {}\",\n            error.getKey(), error.getCode(), error.getMessage());\n      }\n      throw e;\n    }\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java",
      "extendedDetails": {}
    },
    "511df1e837b19ccb9271520589452d82d50ac69d": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": "HADOOP-16430. S3AFilesystem.delete to incrementally update s3guard with deletions\n\nContributed by Steve Loughran.\n\nThis overlaps the scanning for directory entries with batched calls to S3 DELETE and updates of the S3Guard tables.\nIt also uses S3Guard to list the files to delete, so find newly created files even when S3 listings are not use consistent.\n\nFor path which the client considers S3Guard to be authoritative, we also do a recursive LIST of the store and delete files; this is to find unindexed files and do guarantee that the delete(path, true) call really does delete everything underneath.\n\nChange-Id: Ice2f6e940c506e0b3a78fa534a99721b1698708e\n",
      "commitDate": "05/09/19 6:25 AM",
      "commitName": "511df1e837b19ccb9271520589452d82d50ac69d",
      "commitAuthor": "Steve Loughran",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "HADOOP-16430. S3AFilesystem.delete to incrementally update s3guard with deletions\n\nContributed by Steve Loughran.\n\nThis overlaps the scanning for directory entries with batched calls to S3 DELETE and updates of the S3Guard tables.\nIt also uses S3Guard to list the files to delete, so find newly created files even when S3 listings are not use consistent.\n\nFor path which the client considers S3Guard to be authoritative, we also do a recursive LIST of the store and delete files; this is to find unindexed files and do guarantee that the delete(path, true) call really does delete everything underneath.\n\nChange-Id: Ice2f6e940c506e0b3a78fa534a99721b1698708e\n",
          "commitDate": "05/09/19 6:25 AM",
          "commitName": "511df1e837b19ccb9271520589452d82d50ac69d",
          "commitAuthor": "Steve Loughran",
          "commitDateOld": "23/07/19 6:52 AM",
          "commitNameOld": "4317d332321778269a583e2223d433107fab82eb",
          "commitAuthorOld": "Steve Loughran",
          "daysBetweenCommits": 43.98,
          "commitsBetweenForRepo": 415,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,23 +1,23 @@\n-  private void deleteObjects(DeleteObjectsRequest deleteRequest)\n+  private DeleteObjectsResult deleteObjects(DeleteObjectsRequest deleteRequest)\n       throws MultiObjectDeleteException, AmazonClientException, IOException {\n     incrementWriteOperations();\n     try(DurationInfo ignored \u003d\n             new DurationInfo(LOG, false, \"DELETE %d keys\",\n                 deleteRequest.getKeys().size())) {\n-      invoker.retryUntranslated(\"delete\",\n+      return invoker.retryUntranslated(\"delete\",\n           DELETE_CONSIDERED_IDEMPOTENT,\n           () -\u003e {\n             incrementStatistic(OBJECT_DELETE_REQUESTS, 1);\n             return s3.deleteObjects(deleteRequest);\n           });\n     } catch (MultiObjectDeleteException e) {\n       // one or more of the operations failed.\n       List\u003cMultiObjectDeleteException.DeleteError\u003e errors \u003d e.getErrors();\n       LOG.debug(\"Partial failure of delete, {} errors\", errors.size(), e);\n       for (MultiObjectDeleteException.DeleteError error : errors) {\n         LOG.debug(\"{}: \\\"{}\\\" - {}\",\n             error.getKey(), error.getCode(), error.getMessage());\n       }\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private DeleteObjectsResult deleteObjects(DeleteObjectsRequest deleteRequest)\n      throws MultiObjectDeleteException, AmazonClientException, IOException {\n    incrementWriteOperations();\n    try(DurationInfo ignored \u003d\n            new DurationInfo(LOG, false, \"DELETE %d keys\",\n                deleteRequest.getKeys().size())) {\n      return invoker.retryUntranslated(\"delete\",\n          DELETE_CONSIDERED_IDEMPOTENT,\n          () -\u003e {\n            incrementStatistic(OBJECT_DELETE_REQUESTS, 1);\n            return s3.deleteObjects(deleteRequest);\n          });\n    } catch (MultiObjectDeleteException e) {\n      // one or more of the operations failed.\n      List\u003cMultiObjectDeleteException.DeleteError\u003e errors \u003d e.getErrors();\n      LOG.debug(\"Partial failure of delete, {} errors\", errors.size(), e);\n      for (MultiObjectDeleteException.DeleteError error : errors) {\n        LOG.debug(\"{}: \\\"{}\\\" - {}\",\n            error.getKey(), error.getCode(), error.getMessage());\n      }\n      throw e;\n    }\n  }",
          "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java",
          "extendedDetails": {
            "oldValue": "void",
            "newValue": "DeleteObjectsResult"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HADOOP-16430. S3AFilesystem.delete to incrementally update s3guard with deletions\n\nContributed by Steve Loughran.\n\nThis overlaps the scanning for directory entries with batched calls to S3 DELETE and updates of the S3Guard tables.\nIt also uses S3Guard to list the files to delete, so find newly created files even when S3 listings are not use consistent.\n\nFor path which the client considers S3Guard to be authoritative, we also do a recursive LIST of the store and delete files; this is to find unindexed files and do guarantee that the delete(path, true) call really does delete everything underneath.\n\nChange-Id: Ice2f6e940c506e0b3a78fa534a99721b1698708e\n",
          "commitDate": "05/09/19 6:25 AM",
          "commitName": "511df1e837b19ccb9271520589452d82d50ac69d",
          "commitAuthor": "Steve Loughran",
          "commitDateOld": "23/07/19 6:52 AM",
          "commitNameOld": "4317d332321778269a583e2223d433107fab82eb",
          "commitAuthorOld": "Steve Loughran",
          "daysBetweenCommits": 43.98,
          "commitsBetweenForRepo": 415,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,23 +1,23 @@\n-  private void deleteObjects(DeleteObjectsRequest deleteRequest)\n+  private DeleteObjectsResult deleteObjects(DeleteObjectsRequest deleteRequest)\n       throws MultiObjectDeleteException, AmazonClientException, IOException {\n     incrementWriteOperations();\n     try(DurationInfo ignored \u003d\n             new DurationInfo(LOG, false, \"DELETE %d keys\",\n                 deleteRequest.getKeys().size())) {\n-      invoker.retryUntranslated(\"delete\",\n+      return invoker.retryUntranslated(\"delete\",\n           DELETE_CONSIDERED_IDEMPOTENT,\n           () -\u003e {\n             incrementStatistic(OBJECT_DELETE_REQUESTS, 1);\n             return s3.deleteObjects(deleteRequest);\n           });\n     } catch (MultiObjectDeleteException e) {\n       // one or more of the operations failed.\n       List\u003cMultiObjectDeleteException.DeleteError\u003e errors \u003d e.getErrors();\n       LOG.debug(\"Partial failure of delete, {} errors\", errors.size(), e);\n       for (MultiObjectDeleteException.DeleteError error : errors) {\n         LOG.debug(\"{}: \\\"{}\\\" - {}\",\n             error.getKey(), error.getCode(), error.getMessage());\n       }\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private DeleteObjectsResult deleteObjects(DeleteObjectsRequest deleteRequest)\n      throws MultiObjectDeleteException, AmazonClientException, IOException {\n    incrementWriteOperations();\n    try(DurationInfo ignored \u003d\n            new DurationInfo(LOG, false, \"DELETE %d keys\",\n                deleteRequest.getKeys().size())) {\n      return invoker.retryUntranslated(\"delete\",\n          DELETE_CONSIDERED_IDEMPOTENT,\n          () -\u003e {\n            incrementStatistic(OBJECT_DELETE_REQUESTS, 1);\n            return s3.deleteObjects(deleteRequest);\n          });\n    } catch (MultiObjectDeleteException e) {\n      // one or more of the operations failed.\n      List\u003cMultiObjectDeleteException.DeleteError\u003e errors \u003d e.getErrors();\n      LOG.debug(\"Partial failure of delete, {} errors\", errors.size(), e);\n      for (MultiObjectDeleteException.DeleteError error : errors) {\n        LOG.debug(\"{}: \\\"{}\\\" - {}\",\n            error.getKey(), error.getCode(), error.getMessage());\n      }\n      throw e;\n    }\n  }",
          "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java",
          "extendedDetails": {}
        }
      ]
    },
    "e02eb24e0a9139418120027b694492e0738df20a": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-15183. S3Guard store becomes inconsistent after partial failure of rename.\n\nContributed by Steve Loughran.\n\nChange-Id: I825b0bc36be960475d2d259b1cdab45ae1bb78eb\n",
      "commitDate": "20/06/19 1:56 AM",
      "commitName": "e02eb24e0a9139418120027b694492e0738df20a",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "16/06/19 9:05 AM",
      "commitNameOld": "f9cc9e162175444efe9d5b07ecb9a795f750ca3c",
      "commitAuthorOld": "Gabor Bota",
      "daysBetweenCommits": 3.7,
      "commitsBetweenForRepo": 44,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,23 @@\n   private void deleteObjects(DeleteObjectsRequest deleteRequest)\n       throws MultiObjectDeleteException, AmazonClientException, IOException {\n     incrementWriteOperations();\n-    try {\n+    try(DurationInfo ignored \u003d\n+            new DurationInfo(LOG, false, \"DELETE %d keys\",\n+                deleteRequest.getKeys().size())) {\n       invoker.retryUntranslated(\"delete\",\n           DELETE_CONSIDERED_IDEMPOTENT,\n           () -\u003e {\n             incrementStatistic(OBJECT_DELETE_REQUESTS, 1);\n             return s3.deleteObjects(deleteRequest);\n           });\n     } catch (MultiObjectDeleteException e) {\n       // one or more of the operations failed.\n       List\u003cMultiObjectDeleteException.DeleteError\u003e errors \u003d e.getErrors();\n       LOG.debug(\"Partial failure of delete, {} errors\", errors.size(), e);\n       for (MultiObjectDeleteException.DeleteError error : errors) {\n         LOG.debug(\"{}: \\\"{}\\\" - {}\",\n             error.getKey(), error.getCode(), error.getMessage());\n       }\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void deleteObjects(DeleteObjectsRequest deleteRequest)\n      throws MultiObjectDeleteException, AmazonClientException, IOException {\n    incrementWriteOperations();\n    try(DurationInfo ignored \u003d\n            new DurationInfo(LOG, false, \"DELETE %d keys\",\n                deleteRequest.getKeys().size())) {\n      invoker.retryUntranslated(\"delete\",\n          DELETE_CONSIDERED_IDEMPOTENT,\n          () -\u003e {\n            incrementStatistic(OBJECT_DELETE_REQUESTS, 1);\n            return s3.deleteObjects(deleteRequest);\n          });\n    } catch (MultiObjectDeleteException e) {\n      // one or more of the operations failed.\n      List\u003cMultiObjectDeleteException.DeleteError\u003e errors \u003d e.getErrors();\n      LOG.debug(\"Partial failure of delete, {} errors\", errors.size(), e);\n      for (MultiObjectDeleteException.DeleteError error : errors) {\n        LOG.debug(\"{}: \\\"{}\\\" - {}\",\n            error.getKey(), error.getCode(), error.getMessage());\n      }\n      throw e;\n    }\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java",
      "extendedDetails": {}
    },
    "9a013b255f301c557c3868dc1ad657202e9e7a67": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-15176. Enhance IAM Assumed Role support in S3A client.\nContributed by Steve Loughran\n\n(cherry picked from commit 96c047fbb98c2378eed9693a724d4cbbd03c00fd)\n",
      "commitDate": "15/02/18 7:57 AM",
      "commitName": "9a013b255f301c557c3868dc1ad657202e9e7a67",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "18/01/18 5:13 AM",
      "commitNameOld": "1093a73689912f78547e6d23023be2fd1c7ddc85",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 28.11,
      "commitsBetweenForRepo": 184,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,21 @@\n   private void deleteObjects(DeleteObjectsRequest deleteRequest)\n       throws MultiObjectDeleteException, AmazonClientException, IOException {\n     incrementWriteOperations();\n     try {\n       invoker.retryUntranslated(\"delete\",\n           DELETE_CONSIDERED_IDEMPOTENT,\n           () -\u003e {\n             incrementStatistic(OBJECT_DELETE_REQUESTS, 1);\n             return s3.deleteObjects(deleteRequest);\n           });\n     } catch (MultiObjectDeleteException e) {\n       // one or more of the operations failed.\n       List\u003cMultiObjectDeleteException.DeleteError\u003e errors \u003d e.getErrors();\n-      LOG.error(\"Partial failure of delete, {} errors\", errors.size(), e);\n+      LOG.debug(\"Partial failure of delete, {} errors\", errors.size(), e);\n       for (MultiObjectDeleteException.DeleteError error : errors) {\n-        LOG.error(\"{}: \\\"{}\\\" - {}\",\n+        LOG.debug(\"{}: \\\"{}\\\" - {}\",\n             error.getKey(), error.getCode(), error.getMessage());\n       }\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void deleteObjects(DeleteObjectsRequest deleteRequest)\n      throws MultiObjectDeleteException, AmazonClientException, IOException {\n    incrementWriteOperations();\n    try {\n      invoker.retryUntranslated(\"delete\",\n          DELETE_CONSIDERED_IDEMPOTENT,\n          () -\u003e {\n            incrementStatistic(OBJECT_DELETE_REQUESTS, 1);\n            return s3.deleteObjects(deleteRequest);\n          });\n    } catch (MultiObjectDeleteException e) {\n      // one or more of the operations failed.\n      List\u003cMultiObjectDeleteException.DeleteError\u003e errors \u003d e.getErrors();\n      LOG.debug(\"Partial failure of delete, {} errors\", errors.size(), e);\n      for (MultiObjectDeleteException.DeleteError error : errors) {\n        LOG.debug(\"{}: \\\"{}\\\" - {}\",\n            error.getKey(), error.getCode(), error.getMessage());\n      }\n      throw e;\n    }\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java",
      "extendedDetails": {}
    },
    "de8b6ca5ef8614de6d6277b7617e27c788b0555c": {
      "type": "Ymultichange(Yexceptionschange,Ybodychange)",
      "commitMessage": "HADOOP-13786 Add S3A committer for zero-rename commits to S3 endpoints.\nContributed by Steve Loughran and Ryan Blue.\n",
      "commitDate": "22/11/17 7:28 AM",
      "commitName": "de8b6ca5ef8614de6d6277b7617e27c788b0555c",
      "commitAuthor": "Steve Loughran",
      "subchanges": [
        {
          "type": "Yexceptionschange",
          "commitMessage": "HADOOP-13786 Add S3A committer for zero-rename commits to S3 endpoints.\nContributed by Steve Loughran and Ryan Blue.\n",
          "commitDate": "22/11/17 7:28 AM",
          "commitName": "de8b6ca5ef8614de6d6277b7617e27c788b0555c",
          "commitAuthor": "Steve Loughran",
          "commitDateOld": "25/09/17 3:59 PM",
          "commitNameOld": "47011d7dd300b0c74bb6cfe25b918c479d718f4f",
          "commitAuthorOld": "Aaron Fabbri",
          "daysBetweenCommits": 57.69,
          "commitsBetweenForRepo": 477,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,17 +1,21 @@\n   private void deleteObjects(DeleteObjectsRequest deleteRequest)\n-      throws MultiObjectDeleteException, AmazonClientException {\n+      throws MultiObjectDeleteException, AmazonClientException, IOException {\n     incrementWriteOperations();\n-    incrementStatistic(OBJECT_DELETE_REQUESTS, 1);\n     try {\n-      s3.deleteObjects(deleteRequest);\n+      invoker.retryUntranslated(\"delete\",\n+          DELETE_CONSIDERED_IDEMPOTENT,\n+          () -\u003e {\n+            incrementStatistic(OBJECT_DELETE_REQUESTS, 1);\n+            return s3.deleteObjects(deleteRequest);\n+          });\n     } catch (MultiObjectDeleteException e) {\n       // one or more of the operations failed.\n       List\u003cMultiObjectDeleteException.DeleteError\u003e errors \u003d e.getErrors();\n       LOG.error(\"Partial failure of delete, {} errors\", errors.size(), e);\n       for (MultiObjectDeleteException.DeleteError error : errors) {\n         LOG.error(\"{}: \\\"{}\\\" - {}\",\n             error.getKey(), error.getCode(), error.getMessage());\n       }\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void deleteObjects(DeleteObjectsRequest deleteRequest)\n      throws MultiObjectDeleteException, AmazonClientException, IOException {\n    incrementWriteOperations();\n    try {\n      invoker.retryUntranslated(\"delete\",\n          DELETE_CONSIDERED_IDEMPOTENT,\n          () -\u003e {\n            incrementStatistic(OBJECT_DELETE_REQUESTS, 1);\n            return s3.deleteObjects(deleteRequest);\n          });\n    } catch (MultiObjectDeleteException e) {\n      // one or more of the operations failed.\n      List\u003cMultiObjectDeleteException.DeleteError\u003e errors \u003d e.getErrors();\n      LOG.error(\"Partial failure of delete, {} errors\", errors.size(), e);\n      for (MultiObjectDeleteException.DeleteError error : errors) {\n        LOG.error(\"{}: \\\"{}\\\" - {}\",\n            error.getKey(), error.getCode(), error.getMessage());\n      }\n      throw e;\n    }\n  }",
          "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java",
          "extendedDetails": {
            "oldValue": "[MultiObjectDeleteException, AmazonClientException]",
            "newValue": "[MultiObjectDeleteException, AmazonClientException, IOException]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HADOOP-13786 Add S3A committer for zero-rename commits to S3 endpoints.\nContributed by Steve Loughran and Ryan Blue.\n",
          "commitDate": "22/11/17 7:28 AM",
          "commitName": "de8b6ca5ef8614de6d6277b7617e27c788b0555c",
          "commitAuthor": "Steve Loughran",
          "commitDateOld": "25/09/17 3:59 PM",
          "commitNameOld": "47011d7dd300b0c74bb6cfe25b918c479d718f4f",
          "commitAuthorOld": "Aaron Fabbri",
          "daysBetweenCommits": 57.69,
          "commitsBetweenForRepo": 477,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,17 +1,21 @@\n   private void deleteObjects(DeleteObjectsRequest deleteRequest)\n-      throws MultiObjectDeleteException, AmazonClientException {\n+      throws MultiObjectDeleteException, AmazonClientException, IOException {\n     incrementWriteOperations();\n-    incrementStatistic(OBJECT_DELETE_REQUESTS, 1);\n     try {\n-      s3.deleteObjects(deleteRequest);\n+      invoker.retryUntranslated(\"delete\",\n+          DELETE_CONSIDERED_IDEMPOTENT,\n+          () -\u003e {\n+            incrementStatistic(OBJECT_DELETE_REQUESTS, 1);\n+            return s3.deleteObjects(deleteRequest);\n+          });\n     } catch (MultiObjectDeleteException e) {\n       // one or more of the operations failed.\n       List\u003cMultiObjectDeleteException.DeleteError\u003e errors \u003d e.getErrors();\n       LOG.error(\"Partial failure of delete, {} errors\", errors.size(), e);\n       for (MultiObjectDeleteException.DeleteError error : errors) {\n         LOG.error(\"{}: \\\"{}\\\" - {}\",\n             error.getKey(), error.getCode(), error.getMessage());\n       }\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void deleteObjects(DeleteObjectsRequest deleteRequest)\n      throws MultiObjectDeleteException, AmazonClientException, IOException {\n    incrementWriteOperations();\n    try {\n      invoker.retryUntranslated(\"delete\",\n          DELETE_CONSIDERED_IDEMPOTENT,\n          () -\u003e {\n            incrementStatistic(OBJECT_DELETE_REQUESTS, 1);\n            return s3.deleteObjects(deleteRequest);\n          });\n    } catch (MultiObjectDeleteException e) {\n      // one or more of the operations failed.\n      List\u003cMultiObjectDeleteException.DeleteError\u003e errors \u003d e.getErrors();\n      LOG.error(\"Partial failure of delete, {} errors\", errors.size(), e);\n      for (MultiObjectDeleteException.DeleteError error : errors) {\n        LOG.error(\"{}: \\\"{}\\\" - {}\",\n            error.getKey(), error.getCode(), error.getMessage());\n      }\n      throw e;\n    }\n  }",
          "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java",
          "extendedDetails": {}
        }
      ]
    },
    "ba70225cf6a1e7dc756f4991881de04f525ff088": {
      "type": "Ymultichange(Yexceptionschange,Ybodychange)",
      "commitMessage": "HADOOP-11572. s3a delete() operation fails during a concurrent delete of child entries.\nContributed by Steve Loughran.\n\n(cherry picked from commit 2ac5aab8d725f761a9f9723471a4426f6b5d78c4)\n",
      "commitDate": "18/05/17 7:44 AM",
      "commitName": "ba70225cf6a1e7dc756f4991881de04f525ff088",
      "commitAuthor": "Steve Loughran",
      "subchanges": [
        {
          "type": "Yexceptionschange",
          "commitMessage": "HADOOP-11572. s3a delete() operation fails during a concurrent delete of child entries.\nContributed by Steve Loughran.\n\n(cherry picked from commit 2ac5aab8d725f761a9f9723471a4426f6b5d78c4)\n",
          "commitDate": "18/05/17 7:44 AM",
          "commitName": "ba70225cf6a1e7dc756f4991881de04f525ff088",
          "commitAuthor": "Steve Loughran",
          "commitDateOld": "20/04/17 5:13 PM",
          "commitNameOld": "667966c13c1e09077c2e2088bd66c9d7851dd14e",
          "commitAuthorOld": "Mingliang Liu",
          "daysBetweenCommits": 27.6,
          "commitsBetweenForRepo": 151,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,5 +1,17 @@\n-  private void deleteObjects(DeleteObjectsRequest deleteRequest) {\n+  private void deleteObjects(DeleteObjectsRequest deleteRequest)\n+      throws MultiObjectDeleteException, AmazonClientException {\n     incrementWriteOperations();\n     incrementStatistic(OBJECT_DELETE_REQUESTS, 1);\n-    s3.deleteObjects(deleteRequest);\n+    try {\n+      s3.deleteObjects(deleteRequest);\n+    } catch (MultiObjectDeleteException e) {\n+      // one or more of the operations failed.\n+      List\u003cMultiObjectDeleteException.DeleteError\u003e errors \u003d e.getErrors();\n+      LOG.error(\"Partial failure of delete, {} errors\", errors.size(), e);\n+      for (MultiObjectDeleteException.DeleteError error : errors) {\n+        LOG.error(\"{}: \\\"{}\\\" - {}\",\n+            error.getKey(), error.getCode(), error.getMessage());\n+      }\n+      throw e;\n+    }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void deleteObjects(DeleteObjectsRequest deleteRequest)\n      throws MultiObjectDeleteException, AmazonClientException {\n    incrementWriteOperations();\n    incrementStatistic(OBJECT_DELETE_REQUESTS, 1);\n    try {\n      s3.deleteObjects(deleteRequest);\n    } catch (MultiObjectDeleteException e) {\n      // one or more of the operations failed.\n      List\u003cMultiObjectDeleteException.DeleteError\u003e errors \u003d e.getErrors();\n      LOG.error(\"Partial failure of delete, {} errors\", errors.size(), e);\n      for (MultiObjectDeleteException.DeleteError error : errors) {\n        LOG.error(\"{}: \\\"{}\\\" - {}\",\n            error.getKey(), error.getCode(), error.getMessage());\n      }\n      throw e;\n    }\n  }",
          "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[MultiObjectDeleteException, AmazonClientException]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HADOOP-11572. s3a delete() operation fails during a concurrent delete of child entries.\nContributed by Steve Loughran.\n\n(cherry picked from commit 2ac5aab8d725f761a9f9723471a4426f6b5d78c4)\n",
          "commitDate": "18/05/17 7:44 AM",
          "commitName": "ba70225cf6a1e7dc756f4991881de04f525ff088",
          "commitAuthor": "Steve Loughran",
          "commitDateOld": "20/04/17 5:13 PM",
          "commitNameOld": "667966c13c1e09077c2e2088bd66c9d7851dd14e",
          "commitAuthorOld": "Mingliang Liu",
          "daysBetweenCommits": 27.6,
          "commitsBetweenForRepo": 151,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,5 +1,17 @@\n-  private void deleteObjects(DeleteObjectsRequest deleteRequest) {\n+  private void deleteObjects(DeleteObjectsRequest deleteRequest)\n+      throws MultiObjectDeleteException, AmazonClientException {\n     incrementWriteOperations();\n     incrementStatistic(OBJECT_DELETE_REQUESTS, 1);\n-    s3.deleteObjects(deleteRequest);\n+    try {\n+      s3.deleteObjects(deleteRequest);\n+    } catch (MultiObjectDeleteException e) {\n+      // one or more of the operations failed.\n+      List\u003cMultiObjectDeleteException.DeleteError\u003e errors \u003d e.getErrors();\n+      LOG.error(\"Partial failure of delete, {} errors\", errors.size(), e);\n+      for (MultiObjectDeleteException.DeleteError error : errors) {\n+        LOG.error(\"{}: \\\"{}\\\" - {}\",\n+            error.getKey(), error.getCode(), error.getMessage());\n+      }\n+      throw e;\n+    }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void deleteObjects(DeleteObjectsRequest deleteRequest)\n      throws MultiObjectDeleteException, AmazonClientException {\n    incrementWriteOperations();\n    incrementStatistic(OBJECT_DELETE_REQUESTS, 1);\n    try {\n      s3.deleteObjects(deleteRequest);\n    } catch (MultiObjectDeleteException e) {\n      // one or more of the operations failed.\n      List\u003cMultiObjectDeleteException.DeleteError\u003e errors \u003d e.getErrors();\n      LOG.error(\"Partial failure of delete, {} errors\", errors.size(), e);\n      for (MultiObjectDeleteException.DeleteError error : errors) {\n        LOG.error(\"{}: \\\"{}\\\" - {}\",\n            error.getKey(), error.getCode(), error.getMessage());\n      }\n      throw e;\n    }\n  }",
          "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java",
          "extendedDetails": {}
        }
      ]
    },
    "c58a59f7081d55dd2108545ebf9ee48cf43ca944": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-13171. Add StorageStatistics to S3A; instrument some more operations. Contributed by Steve Loughran.\n",
      "commitDate": "03/06/16 8:55 AM",
      "commitName": "c58a59f7081d55dd2108545ebf9ee48cf43ca944",
      "commitAuthor": "Chris Nauroth",
      "diff": "@@ -0,0 +1,5 @@\n+  private void deleteObjects(DeleteObjectsRequest deleteRequest) {\n+    incrementWriteOperations();\n+    incrementStatistic(OBJECT_DELETE_REQUESTS, 1);\n+    s3.deleteObjects(deleteRequest);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void deleteObjects(DeleteObjectsRequest deleteRequest) {\n    incrementWriteOperations();\n    incrementStatistic(OBJECT_DELETE_REQUESTS, 1);\n    s3.deleteObjects(deleteRequest);\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java"
    }
  }
}