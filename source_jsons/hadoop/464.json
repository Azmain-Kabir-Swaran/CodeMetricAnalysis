{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockReaderLocal.java",
  "functionName": "readWithBounceBuffer",
  "functionId": "readWithBounceBuffer___buf-ByteBuffer__canSkipChecksum-boolean",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/client/impl/BlockReaderLocal.java",
  "functionStartLine": 507,
  "functionEndLine": 549,
  "numCommitsSeen": 47,
  "timeTaken": 2526,
  "changeHistory": [
    "f308561f1d885491b88db73ac63003202056d661",
    "e2c9b288b223b9fd82dc12018936e13128413492",
    "d59dbc9e38167d24e337d214b3b21816fda7b25d",
    "037a89abc5cc5ea6b983b21c568a50bc729aa194",
    "124e507674c0d396f8494585e64226957199097b"
  ],
  "changeHistoryShort": {
    "f308561f1d885491b88db73ac63003202056d661": "Yfilerename",
    "e2c9b288b223b9fd82dc12018936e13128413492": "Yfilerename",
    "d59dbc9e38167d24e337d214b3b21816fda7b25d": "Ybodychange",
    "037a89abc5cc5ea6b983b21c568a50bc729aa194": "Ybodychange",
    "124e507674c0d396f8494585e64226957199097b": "Yintroduced"
  },
  "changeHistoryDetails": {
    "f308561f1d885491b88db73ac63003202056d661": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8057 Move BlockReader implementation to the client implementation package.  Contributed by Takanobu Asanuma\n",
      "commitDate": "25/04/16 12:01 PM",
      "commitName": "f308561f1d885491b88db73ac63003202056d661",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "25/04/16 9:38 AM",
      "commitNameOld": "10f0f7851a3255caab775777e8fb6c2781d97062",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 0.1,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private synchronized int readWithBounceBuffer(ByteBuffer buf,\n        boolean canSkipChecksum) throws IOException {\n    int total \u003d 0;\n    int bb \u003d drainDataBuf(buf); // drain bounce buffer if possible\n    if (bb \u003e\u003d 0) {\n      total +\u003d bb;\n      if (buf.remaining() \u003d\u003d 0) return total;\n    }\n    boolean eof \u003d true, done \u003d false;\n    do {\n      if (buf.isDirect() \u0026\u0026 (buf.remaining() \u003e\u003d maxReadaheadLength)\n            \u0026\u0026 ((dataPos % bytesPerChecksum) \u003d\u003d 0)) {\n        // Fast lane: try to read directly into user-supplied buffer, bypassing\n        // bounce buffer.\n        int oldLimit \u003d buf.limit();\n        int nRead;\n        try {\n          buf.limit(buf.position() + maxReadaheadLength);\n          nRead \u003d fillBuffer(buf, canSkipChecksum);\n        } finally {\n          buf.limit(oldLimit);\n        }\n        if (nRead \u003c maxReadaheadLength) {\n          done \u003d true;\n        }\n        if (nRead \u003e 0) {\n          eof \u003d false;\n        }\n        total +\u003d nRead;\n      } else {\n        // Slow lane: refill bounce buffer.\n        if (fillDataBuf(canSkipChecksum)) {\n          done \u003d true;\n        }\n        bb \u003d drainDataBuf(buf); // drain bounce buffer if possible\n        if (bb \u003e\u003d 0) {\n          eof \u003d false;\n          total +\u003d bb;\n        }\n      }\n    } while ((!done) \u0026\u0026 (buf.remaining() \u003e 0));\n    return (eof \u0026\u0026 total \u003d\u003d 0) ? -1 : total;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/client/impl/BlockReaderLocal.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocal.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/client/impl/BlockReaderLocal.java"
      }
    },
    "e2c9b288b223b9fd82dc12018936e13128413492": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8925. Move BlockReaderLocal to hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "28/08/15 2:38 PM",
      "commitName": "e2c9b288b223b9fd82dc12018936e13128413492",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "28/08/15 2:21 PM",
      "commitNameOld": "b94b56806d3d6e04984e229b479f7ac15b62bbfa",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private synchronized int readWithBounceBuffer(ByteBuffer buf,\n        boolean canSkipChecksum) throws IOException {\n    int total \u003d 0;\n    int bb \u003d drainDataBuf(buf); // drain bounce buffer if possible\n    if (bb \u003e\u003d 0) {\n      total +\u003d bb;\n      if (buf.remaining() \u003d\u003d 0) return total;\n    }\n    boolean eof \u003d true, done \u003d false;\n    do {\n      if (buf.isDirect() \u0026\u0026 (buf.remaining() \u003e\u003d maxReadaheadLength)\n            \u0026\u0026 ((dataPos % bytesPerChecksum) \u003d\u003d 0)) {\n        // Fast lane: try to read directly into user-supplied buffer, bypassing\n        // bounce buffer.\n        int oldLimit \u003d buf.limit();\n        int nRead;\n        try {\n          buf.limit(buf.position() + maxReadaheadLength);\n          nRead \u003d fillBuffer(buf, canSkipChecksum);\n        } finally {\n          buf.limit(oldLimit);\n        }\n        if (nRead \u003c maxReadaheadLength) {\n          done \u003d true;\n        }\n        if (nRead \u003e 0) {\n          eof \u003d false;\n        }\n        total +\u003d nRead;\n      } else {\n        // Slow lane: refill bounce buffer.\n        if (fillDataBuf(canSkipChecksum)) {\n          done \u003d true;\n        }\n        bb \u003d drainDataBuf(buf); // drain bounce buffer if possible\n        if (bb \u003e\u003d 0) {\n          eof \u003d false;\n          total +\u003d bb;\n        }\n      }\n    } while ((!done) \u0026\u0026 (buf.remaining() \u003e 0));\n    return (eof \u0026\u0026 total \u003d\u003d 0) ? -1 : total;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocal.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocal.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocal.java"
      }
    },
    "d59dbc9e38167d24e337d214b3b21816fda7b25d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6071. BlockReaderLocal does not return -1 on EOF when doing a zero-length read on a short file. (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1575797 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/03/14 7:41 PM",
      "commitName": "d59dbc9e38167d24e337d214b3b21816fda7b25d",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "02/03/14 7:58 PM",
      "commitNameOld": "dd049a2f6097da189ccce2f5890a2b9bc77fa73f",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 6.95,
      "commitsBetweenForRepo": 68,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,39 +1,43 @@\n   private synchronized int readWithBounceBuffer(ByteBuffer buf,\n         boolean canSkipChecksum) throws IOException {\n     int total \u003d 0;\n     int bb \u003d drainDataBuf(buf); // drain bounce buffer if possible\n     if (bb \u003e\u003d 0) {\n       total +\u003d bb;\n       if (buf.remaining() \u003d\u003d 0) return total;\n     }\n-    boolean eof \u003d false;\n+    boolean eof \u003d true, done \u003d false;\n     do {\n       if (buf.isDirect() \u0026\u0026 (buf.remaining() \u003e\u003d maxReadaheadLength)\n             \u0026\u0026 ((dataPos % bytesPerChecksum) \u003d\u003d 0)) {\n         // Fast lane: try to read directly into user-supplied buffer, bypassing\n         // bounce buffer.\n         int oldLimit \u003d buf.limit();\n         int nRead;\n         try {\n           buf.limit(buf.position() + maxReadaheadLength);\n           nRead \u003d fillBuffer(buf, canSkipChecksum);\n         } finally {\n           buf.limit(oldLimit);\n         }\n         if (nRead \u003c maxReadaheadLength) {\n-          eof \u003d true;\n+          done \u003d true;\n+        }\n+        if (nRead \u003e 0) {\n+          eof \u003d false;\n         }\n         total +\u003d nRead;\n       } else {\n         // Slow lane: refill bounce buffer.\n         if (fillDataBuf(canSkipChecksum)) {\n-          eof \u003d true;\n+          done \u003d true;\n         }\n         bb \u003d drainDataBuf(buf); // drain bounce buffer if possible\n         if (bb \u003e\u003d 0) {\n+          eof \u003d false;\n           total +\u003d bb;\n         }\n       }\n-    } while ((!eof) \u0026\u0026 (buf.remaining() \u003e 0));\n+    } while ((!done) \u0026\u0026 (buf.remaining() \u003e 0));\n     return (eof \u0026\u0026 total \u003d\u003d 0) ? -1 : total;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized int readWithBounceBuffer(ByteBuffer buf,\n        boolean canSkipChecksum) throws IOException {\n    int total \u003d 0;\n    int bb \u003d drainDataBuf(buf); // drain bounce buffer if possible\n    if (bb \u003e\u003d 0) {\n      total +\u003d bb;\n      if (buf.remaining() \u003d\u003d 0) return total;\n    }\n    boolean eof \u003d true, done \u003d false;\n    do {\n      if (buf.isDirect() \u0026\u0026 (buf.remaining() \u003e\u003d maxReadaheadLength)\n            \u0026\u0026 ((dataPos % bytesPerChecksum) \u003d\u003d 0)) {\n        // Fast lane: try to read directly into user-supplied buffer, bypassing\n        // bounce buffer.\n        int oldLimit \u003d buf.limit();\n        int nRead;\n        try {\n          buf.limit(buf.position() + maxReadaheadLength);\n          nRead \u003d fillBuffer(buf, canSkipChecksum);\n        } finally {\n          buf.limit(oldLimit);\n        }\n        if (nRead \u003c maxReadaheadLength) {\n          done \u003d true;\n        }\n        if (nRead \u003e 0) {\n          eof \u003d false;\n        }\n        total +\u003d nRead;\n      } else {\n        // Slow lane: refill bounce buffer.\n        if (fillDataBuf(canSkipChecksum)) {\n          done \u003d true;\n        }\n        bb \u003d drainDataBuf(buf); // drain bounce buffer if possible\n        if (bb \u003e\u003d 0) {\n          eof \u003d false;\n          total +\u003d bb;\n        }\n      }\n    } while ((!done) \u0026\u0026 (buf.remaining() \u003e 0));\n    return (eof \u0026\u0026 total \u003d\u003d 0) ? -1 : total;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocal.java",
      "extendedDetails": {}
    },
    "037a89abc5cc5ea6b983b21c568a50bc729aa194": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5762. BlockReaderLocal does not return -1 on EOF when doing zero-length reads (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1558526 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "15/01/14 11:17 AM",
      "commitName": "037a89abc5cc5ea6b983b21c568a50bc729aa194",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "17/12/13 12:57 PM",
      "commitNameOld": "124e507674c0d396f8494585e64226957199097b",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 28.93,
      "commitsBetweenForRepo": 117,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,35 +1,39 @@\n   private synchronized int readWithBounceBuffer(ByteBuffer buf,\n         boolean canSkipChecksum) throws IOException {\n     int total \u003d 0;\n-    boolean eof \u003d false;\n-    while (true) {\n-      int bb \u003d drainDataBuf(buf); // drain bounce buffer if possible\n+    int bb \u003d drainDataBuf(buf); // drain bounce buffer if possible\n+    if (bb \u003e\u003d 0) {\n       total +\u003d bb;\n-      int needed \u003d buf.remaining();\n-      if (eof || (needed \u003d\u003d 0)) {\n-        break;\n-      } else if (buf.isDirect() \u0026\u0026 (needed \u003e\u003d maxReadaheadLength)\n-          \u0026\u0026 ((dataPos % bytesPerChecksum) \u003d\u003d 0)) {\n+      if (buf.remaining() \u003d\u003d 0) return total;\n+    }\n+    boolean eof \u003d false;\n+    do {\n+      if (buf.isDirect() \u0026\u0026 (buf.remaining() \u003e\u003d maxReadaheadLength)\n+            \u0026\u0026 ((dataPos % bytesPerChecksum) \u003d\u003d 0)) {\n         // Fast lane: try to read directly into user-supplied buffer, bypassing\n         // bounce buffer.\n         int oldLimit \u003d buf.limit();\n         int nRead;\n         try {\n           buf.limit(buf.position() + maxReadaheadLength);\n           nRead \u003d fillBuffer(buf, canSkipChecksum);\n         } finally {\n           buf.limit(oldLimit);\n         }\n         if (nRead \u003c maxReadaheadLength) {\n           eof \u003d true;\n         }\n         total +\u003d nRead;\n       } else {\n         // Slow lane: refill bounce buffer.\n         if (fillDataBuf(canSkipChecksum)) {\n           eof \u003d true;\n         }\n+        bb \u003d drainDataBuf(buf); // drain bounce buffer if possible\n+        if (bb \u003e\u003d 0) {\n+          total +\u003d bb;\n+        }\n       }\n-    }\n-    return total \u003d\u003d 0 ? -1 : total;\n+    } while ((!eof) \u0026\u0026 (buf.remaining() \u003e 0));\n+    return (eof \u0026\u0026 total \u003d\u003d 0) ? -1 : total;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized int readWithBounceBuffer(ByteBuffer buf,\n        boolean canSkipChecksum) throws IOException {\n    int total \u003d 0;\n    int bb \u003d drainDataBuf(buf); // drain bounce buffer if possible\n    if (bb \u003e\u003d 0) {\n      total +\u003d bb;\n      if (buf.remaining() \u003d\u003d 0) return total;\n    }\n    boolean eof \u003d false;\n    do {\n      if (buf.isDirect() \u0026\u0026 (buf.remaining() \u003e\u003d maxReadaheadLength)\n            \u0026\u0026 ((dataPos % bytesPerChecksum) \u003d\u003d 0)) {\n        // Fast lane: try to read directly into user-supplied buffer, bypassing\n        // bounce buffer.\n        int oldLimit \u003d buf.limit();\n        int nRead;\n        try {\n          buf.limit(buf.position() + maxReadaheadLength);\n          nRead \u003d fillBuffer(buf, canSkipChecksum);\n        } finally {\n          buf.limit(oldLimit);\n        }\n        if (nRead \u003c maxReadaheadLength) {\n          eof \u003d true;\n        }\n        total +\u003d nRead;\n      } else {\n        // Slow lane: refill bounce buffer.\n        if (fillDataBuf(canSkipChecksum)) {\n          eof \u003d true;\n        }\n        bb \u003d drainDataBuf(buf); // drain bounce buffer if possible\n        if (bb \u003e\u003d 0) {\n          total +\u003d bb;\n        }\n      }\n    } while ((!eof) \u0026\u0026 (buf.remaining() \u003e 0));\n    return (eof \u0026\u0026 total \u003d\u003d 0) ? -1 : total;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocal.java",
      "extendedDetails": {}
    },
    "124e507674c0d396f8494585e64226957199097b": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-5634. Allow BlockReaderLocal to switch between checksumming and not (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1551701 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/12/13 12:57 PM",
      "commitName": "124e507674c0d396f8494585e64226957199097b",
      "commitAuthor": "Colin McCabe",
      "diff": "@@ -0,0 +1,35 @@\n+  private synchronized int readWithBounceBuffer(ByteBuffer buf,\n+        boolean canSkipChecksum) throws IOException {\n+    int total \u003d 0;\n+    boolean eof \u003d false;\n+    while (true) {\n+      int bb \u003d drainDataBuf(buf); // drain bounce buffer if possible\n+      total +\u003d bb;\n+      int needed \u003d buf.remaining();\n+      if (eof || (needed \u003d\u003d 0)) {\n+        break;\n+      } else if (buf.isDirect() \u0026\u0026 (needed \u003e\u003d maxReadaheadLength)\n+          \u0026\u0026 ((dataPos % bytesPerChecksum) \u003d\u003d 0)) {\n+        // Fast lane: try to read directly into user-supplied buffer, bypassing\n+        // bounce buffer.\n+        int oldLimit \u003d buf.limit();\n+        int nRead;\n+        try {\n+          buf.limit(buf.position() + maxReadaheadLength);\n+          nRead \u003d fillBuffer(buf, canSkipChecksum);\n+        } finally {\n+          buf.limit(oldLimit);\n+        }\n+        if (nRead \u003c maxReadaheadLength) {\n+          eof \u003d true;\n+        }\n+        total +\u003d nRead;\n+      } else {\n+        // Slow lane: refill bounce buffer.\n+        if (fillDataBuf(canSkipChecksum)) {\n+          eof \u003d true;\n+        }\n+      }\n+    }\n+    return total \u003d\u003d 0 ? -1 : total;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized int readWithBounceBuffer(ByteBuffer buf,\n        boolean canSkipChecksum) throws IOException {\n    int total \u003d 0;\n    boolean eof \u003d false;\n    while (true) {\n      int bb \u003d drainDataBuf(buf); // drain bounce buffer if possible\n      total +\u003d bb;\n      int needed \u003d buf.remaining();\n      if (eof || (needed \u003d\u003d 0)) {\n        break;\n      } else if (buf.isDirect() \u0026\u0026 (needed \u003e\u003d maxReadaheadLength)\n          \u0026\u0026 ((dataPos % bytesPerChecksum) \u003d\u003d 0)) {\n        // Fast lane: try to read directly into user-supplied buffer, bypassing\n        // bounce buffer.\n        int oldLimit \u003d buf.limit();\n        int nRead;\n        try {\n          buf.limit(buf.position() + maxReadaheadLength);\n          nRead \u003d fillBuffer(buf, canSkipChecksum);\n        } finally {\n          buf.limit(oldLimit);\n        }\n        if (nRead \u003c maxReadaheadLength) {\n          eof \u003d true;\n        }\n        total +\u003d nRead;\n      } else {\n        // Slow lane: refill bounce buffer.\n        if (fillDataBuf(canSkipChecksum)) {\n          eof \u003d true;\n        }\n      }\n    }\n    return total \u003d\u003d 0 ? -1 : total;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocal.java"
    }
  }
}