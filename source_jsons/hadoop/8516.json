{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSImage.java",
  "functionName": "loadFSImage",
  "functionId": "loadFSImage___curFile-File__expectedMd5-MD5Hash__target-FSNamesystem__recovery-MetaRecoveryContext__requireSameLayoutVersion-boolean",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
  "functionStartLine": 956,
  "functionEndLine": 980,
  "numCommitsSeen": 240,
  "timeTaken": 7937,
  "changeHistory": [
    "18620649f96d9e378fb7ea40de216284a9d525c7",
    "5409908026dd791cce62a7d71ae56c92a70a9753",
    "a2edb11b68ae01a44092cb14ac2717a6aad93305",
    "6770de7ec4f73e16740f1723f4e35d2fef2c22c8",
    "06406d705677845e1e303550e3bb0e2d4ccdbf70",
    "706394d03992b394e9f907aff2155df493e4ea4e",
    "a87328dfab96a335535e8952e548534b73c00b7c",
    "06e84a1bca19bd01568a3095e33944d4d6387fd3",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "28e6a4e44a3e920dcaf858f9a74a6358226b3a63",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "18620649f96d9e378fb7ea40de216284a9d525c7": "Ymultichange(Yparameterchange,Ybodychange)",
    "5409908026dd791cce62a7d71ae56c92a70a9753": "Ybodychange",
    "a2edb11b68ae01a44092cb14ac2717a6aad93305": "Ybodychange",
    "6770de7ec4f73e16740f1723f4e35d2fef2c22c8": "Ybodychange",
    "06406d705677845e1e303550e3bb0e2d4ccdbf70": "Ybodychange",
    "706394d03992b394e9f907aff2155df493e4ea4e": "Yparameterchange",
    "a87328dfab96a335535e8952e548534b73c00b7c": "Ybodychange",
    "06e84a1bca19bd01568a3095e33944d4d6387fd3": "Ymultichange(Yparameterchange,Ybodychange)",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "28e6a4e44a3e920dcaf858f9a74a6358226b3a63": "Ymultichange(Yparameterchange,Yreturntypechange,Ymodifierchange,Ybodychange)",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "18620649f96d9e378fb7ea40de216284a9d525c7": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-7185. The active NameNode will not accept an fsimage sent from the standby during rolling upgrade. Contributed by Jing Zhao.\n",
      "commitDate": "15/10/14 10:27 AM",
      "commitName": "18620649f96d9e378fb7ea40de216284a9d525c7",
      "commitAuthor": "Jing Zhao",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-7185. The active NameNode will not accept an fsimage sent from the standby during rolling upgrade. Contributed by Jing Zhao.\n",
          "commitDate": "15/10/14 10:27 AM",
          "commitName": "18620649f96d9e378fb7ea40de216284a9d525c7",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "18/07/14 10:14 AM",
          "commitNameOld": "5f9e52f7459d3dc4ac3a5febd1dc6e00829d30ed",
          "commitAuthorOld": "Chris Nauroth",
          "daysBetweenCommits": 89.01,
          "commitsBetweenForRepo": 875,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,25 @@\n   private void loadFSImage(File curFile, MD5Hash expectedMd5,\n-      FSNamesystem target, MetaRecoveryContext recovery) throws IOException {\n+      FSNamesystem target, MetaRecoveryContext recovery,\n+      boolean requireSameLayoutVersion) throws IOException {\n     // BlockPoolId is required when the FsImageLoader loads the rolling upgrade\n     // information. Make sure the ID is properly set.\n     target.setBlockPoolId(this.getBlockPoolID());\n \n     FSImageFormat.LoaderDelegator loader \u003d FSImageFormat.newLoader(conf, target);\n-    loader.load(curFile);\n+    loader.load(curFile, requireSameLayoutVersion);\n \n     // Check that the image digest we loaded matches up with what\n     // we expected\n     MD5Hash readImageMd5 \u003d loader.getLoadedImageMd5();\n     if (expectedMd5 !\u003d null \u0026\u0026\n         !expectedMd5.equals(readImageMd5)) {\n       throw new IOException(\"Image file \" + curFile +\n           \" is corrupt with MD5 checksum of \" + readImageMd5 +\n           \" but expecting \" + expectedMd5);\n     }\n \n     long txId \u003d loader.getLoadedImageTxId();\n     LOG.info(\"Loaded image for txid \" + txId + \" from \" + curFile);\n     lastAppliedTxId \u003d txId;\n     storage.setMostRecentCheckpointInfo(txId, curFile.lastModified());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void loadFSImage(File curFile, MD5Hash expectedMd5,\n      FSNamesystem target, MetaRecoveryContext recovery,\n      boolean requireSameLayoutVersion) throws IOException {\n    // BlockPoolId is required when the FsImageLoader loads the rolling upgrade\n    // information. Make sure the ID is properly set.\n    target.setBlockPoolId(this.getBlockPoolID());\n\n    FSImageFormat.LoaderDelegator loader \u003d FSImageFormat.newLoader(conf, target);\n    loader.load(curFile, requireSameLayoutVersion);\n\n    // Check that the image digest we loaded matches up with what\n    // we expected\n    MD5Hash readImageMd5 \u003d loader.getLoadedImageMd5();\n    if (expectedMd5 !\u003d null \u0026\u0026\n        !expectedMd5.equals(readImageMd5)) {\n      throw new IOException(\"Image file \" + curFile +\n          \" is corrupt with MD5 checksum of \" + readImageMd5 +\n          \" but expecting \" + expectedMd5);\n    }\n\n    long txId \u003d loader.getLoadedImageTxId();\n    LOG.info(\"Loaded image for txid \" + txId + \" from \" + curFile);\n    lastAppliedTxId \u003d txId;\n    storage.setMostRecentCheckpointInfo(txId, curFile.lastModified());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
          "extendedDetails": {
            "oldValue": "[curFile-File, expectedMd5-MD5Hash, target-FSNamesystem, recovery-MetaRecoveryContext]",
            "newValue": "[curFile-File, expectedMd5-MD5Hash, target-FSNamesystem, recovery-MetaRecoveryContext, requireSameLayoutVersion-boolean]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7185. The active NameNode will not accept an fsimage sent from the standby during rolling upgrade. Contributed by Jing Zhao.\n",
          "commitDate": "15/10/14 10:27 AM",
          "commitName": "18620649f96d9e378fb7ea40de216284a9d525c7",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "18/07/14 10:14 AM",
          "commitNameOld": "5f9e52f7459d3dc4ac3a5febd1dc6e00829d30ed",
          "commitAuthorOld": "Chris Nauroth",
          "daysBetweenCommits": 89.01,
          "commitsBetweenForRepo": 875,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,25 @@\n   private void loadFSImage(File curFile, MD5Hash expectedMd5,\n-      FSNamesystem target, MetaRecoveryContext recovery) throws IOException {\n+      FSNamesystem target, MetaRecoveryContext recovery,\n+      boolean requireSameLayoutVersion) throws IOException {\n     // BlockPoolId is required when the FsImageLoader loads the rolling upgrade\n     // information. Make sure the ID is properly set.\n     target.setBlockPoolId(this.getBlockPoolID());\n \n     FSImageFormat.LoaderDelegator loader \u003d FSImageFormat.newLoader(conf, target);\n-    loader.load(curFile);\n+    loader.load(curFile, requireSameLayoutVersion);\n \n     // Check that the image digest we loaded matches up with what\n     // we expected\n     MD5Hash readImageMd5 \u003d loader.getLoadedImageMd5();\n     if (expectedMd5 !\u003d null \u0026\u0026\n         !expectedMd5.equals(readImageMd5)) {\n       throw new IOException(\"Image file \" + curFile +\n           \" is corrupt with MD5 checksum of \" + readImageMd5 +\n           \" but expecting \" + expectedMd5);\n     }\n \n     long txId \u003d loader.getLoadedImageTxId();\n     LOG.info(\"Loaded image for txid \" + txId + \" from \" + curFile);\n     lastAppliedTxId \u003d txId;\n     storage.setMostRecentCheckpointInfo(txId, curFile.lastModified());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void loadFSImage(File curFile, MD5Hash expectedMd5,\n      FSNamesystem target, MetaRecoveryContext recovery,\n      boolean requireSameLayoutVersion) throws IOException {\n    // BlockPoolId is required when the FsImageLoader loads the rolling upgrade\n    // information. Make sure the ID is properly set.\n    target.setBlockPoolId(this.getBlockPoolID());\n\n    FSImageFormat.LoaderDelegator loader \u003d FSImageFormat.newLoader(conf, target);\n    loader.load(curFile, requireSameLayoutVersion);\n\n    // Check that the image digest we loaded matches up with what\n    // we expected\n    MD5Hash readImageMd5 \u003d loader.getLoadedImageMd5();\n    if (expectedMd5 !\u003d null \u0026\u0026\n        !expectedMd5.equals(readImageMd5)) {\n      throw new IOException(\"Image file \" + curFile +\n          \" is corrupt with MD5 checksum of \" + readImageMd5 +\n          \" but expecting \" + expectedMd5);\n    }\n\n    long txId \u003d loader.getLoadedImageTxId();\n    LOG.info(\"Loaded image for txid \" + txId + \" from \" + curFile);\n    lastAppliedTxId \u003d txId;\n    storage.setMostRecentCheckpointInfo(txId, curFile.lastModified());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
          "extendedDetails": {}
        }
      ]
    },
    "5409908026dd791cce62a7d71ae56c92a70a9753": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6032. -rollingUpgrade query hits NPE after the NN restarts. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535@1572801 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/02/14 5:23 PM",
      "commitName": "5409908026dd791cce62a7d71ae56c92a70a9753",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "25/02/14 1:58 PM",
      "commitNameOld": "e3d2e4c156851de7dac16154521a2e06ea83ec7b",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 2.14,
      "commitsBetweenForRepo": 28,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,24 @@\n   private void loadFSImage(File curFile, MD5Hash expectedMd5,\n       FSNamesystem target, MetaRecoveryContext recovery) throws IOException {\n+    // BlockPoolId is required when the FsImageLoader loads the rolling upgrade\n+    // information. Make sure the ID is properly set.\n+    target.setBlockPoolId(this.getBlockPoolID());\n+\n     FSImageFormat.LoaderDelegator loader \u003d FSImageFormat.newLoader(conf, target);\n     loader.load(curFile);\n-    target.setBlockPoolId(this.getBlockPoolID());\n \n     // Check that the image digest we loaded matches up with what\n     // we expected\n     MD5Hash readImageMd5 \u003d loader.getLoadedImageMd5();\n     if (expectedMd5 !\u003d null \u0026\u0026\n         !expectedMd5.equals(readImageMd5)) {\n       throw new IOException(\"Image file \" + curFile +\n           \" is corrupt with MD5 checksum of \" + readImageMd5 +\n           \" but expecting \" + expectedMd5);\n     }\n \n     long txId \u003d loader.getLoadedImageTxId();\n     LOG.info(\"Loaded image for txid \" + txId + \" from \" + curFile);\n     lastAppliedTxId \u003d txId;\n     storage.setMostRecentCheckpointInfo(txId, curFile.lastModified());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void loadFSImage(File curFile, MD5Hash expectedMd5,\n      FSNamesystem target, MetaRecoveryContext recovery) throws IOException {\n    // BlockPoolId is required when the FsImageLoader loads the rolling upgrade\n    // information. Make sure the ID is properly set.\n    target.setBlockPoolId(this.getBlockPoolID());\n\n    FSImageFormat.LoaderDelegator loader \u003d FSImageFormat.newLoader(conf, target);\n    loader.load(curFile);\n\n    // Check that the image digest we loaded matches up with what\n    // we expected\n    MD5Hash readImageMd5 \u003d loader.getLoadedImageMd5();\n    if (expectedMd5 !\u003d null \u0026\u0026\n        !expectedMd5.equals(readImageMd5)) {\n      throw new IOException(\"Image file \" + curFile +\n          \" is corrupt with MD5 checksum of \" + readImageMd5 +\n          \" but expecting \" + expectedMd5);\n    }\n\n    long txId \u003d loader.getLoadedImageTxId();\n    LOG.info(\"Loaded image for txid \" + txId + \" from \" + curFile);\n    lastAppliedTxId \u003d txId;\n    storage.setMostRecentCheckpointInfo(txId, curFile.lastModified());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
      "extendedDetails": {}
    },
    "a2edb11b68ae01a44092cb14ac2717a6aad93305": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5698. Use protobuf to serialize / deserialize FSImage. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1566359 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/02/14 11:18 AM",
      "commitName": "a2edb11b68ae01a44092cb14ac2717a6aad93305",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "25/01/14 12:01 PM",
      "commitNameOld": "edb6dc5f303093c2604cd07b0c0dacf12dbce5de",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 14.97,
      "commitsBetweenForRepo": 114,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,21 @@\n   private void loadFSImage(File curFile, MD5Hash expectedMd5,\n       FSNamesystem target, MetaRecoveryContext recovery) throws IOException {\n-    FSImageFormat.Loader loader \u003d new FSImageFormat.Loader(\n-        conf, target);\n+    FSImageFormat.LoaderDelegator loader \u003d FSImageFormat.newLoader(conf, target);\n     loader.load(curFile);\n     target.setBlockPoolId(this.getBlockPoolID());\n \n     // Check that the image digest we loaded matches up with what\n     // we expected\n     MD5Hash readImageMd5 \u003d loader.getLoadedImageMd5();\n     if (expectedMd5 !\u003d null \u0026\u0026\n         !expectedMd5.equals(readImageMd5)) {\n       throw new IOException(\"Image file \" + curFile +\n           \" is corrupt with MD5 checksum of \" + readImageMd5 +\n           \" but expecting \" + expectedMd5);\n     }\n \n     long txId \u003d loader.getLoadedImageTxId();\n     LOG.info(\"Loaded image for txid \" + txId + \" from \" + curFile);\n     lastAppliedTxId \u003d txId;\n     storage.setMostRecentCheckpointInfo(txId, curFile.lastModified());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void loadFSImage(File curFile, MD5Hash expectedMd5,\n      FSNamesystem target, MetaRecoveryContext recovery) throws IOException {\n    FSImageFormat.LoaderDelegator loader \u003d FSImageFormat.newLoader(conf, target);\n    loader.load(curFile);\n    target.setBlockPoolId(this.getBlockPoolID());\n\n    // Check that the image digest we loaded matches up with what\n    // we expected\n    MD5Hash readImageMd5 \u003d loader.getLoadedImageMd5();\n    if (expectedMd5 !\u003d null \u0026\u0026\n        !expectedMd5.equals(readImageMd5)) {\n      throw new IOException(\"Image file \" + curFile +\n          \" is corrupt with MD5 checksum of \" + readImageMd5 +\n          \" but expecting \" + expectedMd5);\n    }\n\n    long txId \u003d loader.getLoadedImageTxId();\n    LOG.info(\"Loaded image for txid \" + txId + \" from \" + curFile);\n    lastAppliedTxId \u003d txId;\n    storage.setMostRecentCheckpointInfo(txId, curFile.lastModified());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
      "extendedDetails": {}
    },
    "6770de7ec4f73e16740f1723f4e35d2fef2c22c8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4645.  Move from randomly generated block ID to sequentially generated block ID.  Contributed by Arpit Agarwal\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1500580 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/07/13 10:29 PM",
      "commitName": "6770de7ec4f73e16740f1723f4e35d2fef2c22c8",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "24/04/13 1:31 PM",
      "commitNameOld": "0fa5cad0b27780c27a284c23101b1099d4886506",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 74.37,
      "commitsBetweenForRepo": 459,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,25 +1,22 @@\n   private void loadFSImage(File curFile, MD5Hash expectedMd5,\n       FSNamesystem target, MetaRecoveryContext recovery) throws IOException {\n     FSImageFormat.Loader loader \u003d new FSImageFormat.Loader(\n         conf, target);\n     loader.load(curFile);\n-    // BlockIdGenerator is determined after loading image\n-    // currently there is only one BlockIdGenerator\n-    blockIdGenerator \u003d createBlockIdGenerator(target);\n     target.setBlockPoolId(this.getBlockPoolID());\n \n     // Check that the image digest we loaded matches up with what\n     // we expected\n     MD5Hash readImageMd5 \u003d loader.getLoadedImageMd5();\n     if (expectedMd5 !\u003d null \u0026\u0026\n         !expectedMd5.equals(readImageMd5)) {\n       throw new IOException(\"Image file \" + curFile +\n           \" is corrupt with MD5 checksum of \" + readImageMd5 +\n           \" but expecting \" + expectedMd5);\n     }\n \n     long txId \u003d loader.getLoadedImageTxId();\n     LOG.info(\"Loaded image for txid \" + txId + \" from \" + curFile);\n     lastAppliedTxId \u003d txId;\n     storage.setMostRecentCheckpointInfo(txId, curFile.lastModified());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void loadFSImage(File curFile, MD5Hash expectedMd5,\n      FSNamesystem target, MetaRecoveryContext recovery) throws IOException {\n    FSImageFormat.Loader loader \u003d new FSImageFormat.Loader(\n        conf, target);\n    loader.load(curFile);\n    target.setBlockPoolId(this.getBlockPoolID());\n\n    // Check that the image digest we loaded matches up with what\n    // we expected\n    MD5Hash readImageMd5 \u003d loader.getLoadedImageMd5();\n    if (expectedMd5 !\u003d null \u0026\u0026\n        !expectedMd5.equals(readImageMd5)) {\n      throw new IOException(\"Image file \" + curFile +\n          \" is corrupt with MD5 checksum of \" + readImageMd5 +\n          \" but expecting \" + expectedMd5);\n    }\n\n    long txId \u003d loader.getLoadedImageTxId();\n    LOG.info(\"Loaded image for txid \" + txId + \" from \" + curFile);\n    lastAppliedTxId \u003d txId;\n    storage.setMostRecentCheckpointInfo(txId, curFile.lastModified());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
      "extendedDetails": {}
    },
    "06406d705677845e1e303550e3bb0e2d4ccdbf70": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-1245. Plugable block id generation. Contributed by Konstantin Shvachko.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1432539 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/01/13 5:13 PM",
      "commitName": "06406d705677845e1e303550e3bb0e2d4ccdbf70",
      "commitAuthor": "Konstantin Shvachko",
      "commitDateOld": "19/11/12 6:00 PM",
      "commitNameOld": "573c41c2666e084f3988a288bb40d2305fc23d8f",
      "commitAuthorOld": "Konstantin Shvachko",
      "daysBetweenCommits": 53.97,
      "commitsBetweenForRepo": 205,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,25 @@\n   private void loadFSImage(File curFile, MD5Hash expectedMd5,\n       FSNamesystem target, MetaRecoveryContext recovery) throws IOException {\n     FSImageFormat.Loader loader \u003d new FSImageFormat.Loader(\n         conf, target);\n     loader.load(curFile);\n+    // BlockIdGenerator is determined after loading image\n+    // currently there is only one BlockIdGenerator\n+    blockIdGenerator \u003d createBlockIdGenerator(target);\n     target.setBlockPoolId(this.getBlockPoolID());\n \n     // Check that the image digest we loaded matches up with what\n     // we expected\n     MD5Hash readImageMd5 \u003d loader.getLoadedImageMd5();\n     if (expectedMd5 !\u003d null \u0026\u0026\n         !expectedMd5.equals(readImageMd5)) {\n       throw new IOException(\"Image file \" + curFile +\n           \" is corrupt with MD5 checksum of \" + readImageMd5 +\n           \" but expecting \" + expectedMd5);\n     }\n \n     long txId \u003d loader.getLoadedImageTxId();\n     LOG.info(\"Loaded image for txid \" + txId + \" from \" + curFile);\n     lastAppliedTxId \u003d txId;\n     storage.setMostRecentCheckpointInfo(txId, curFile.lastModified());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void loadFSImage(File curFile, MD5Hash expectedMd5,\n      FSNamesystem target, MetaRecoveryContext recovery) throws IOException {\n    FSImageFormat.Loader loader \u003d new FSImageFormat.Loader(\n        conf, target);\n    loader.load(curFile);\n    // BlockIdGenerator is determined after loading image\n    // currently there is only one BlockIdGenerator\n    blockIdGenerator \u003d createBlockIdGenerator(target);\n    target.setBlockPoolId(this.getBlockPoolID());\n\n    // Check that the image digest we loaded matches up with what\n    // we expected\n    MD5Hash readImageMd5 \u003d loader.getLoadedImageMd5();\n    if (expectedMd5 !\u003d null \u0026\u0026\n        !expectedMd5.equals(readImageMd5)) {\n      throw new IOException(\"Image file \" + curFile +\n          \" is corrupt with MD5 checksum of \" + readImageMd5 +\n          \" but expecting \" + expectedMd5);\n    }\n\n    long txId \u003d loader.getLoadedImageTxId();\n    LOG.info(\"Loaded image for txid \" + txId + \" from \" + curFile);\n    lastAppliedTxId \u003d txId;\n    storage.setMostRecentCheckpointInfo(txId, curFile.lastModified());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
      "extendedDetails": {}
    },
    "706394d03992b394e9f907aff2155df493e4ea4e": {
      "type": "Yparameterchange",
      "commitMessage": "HDFS-3004. Implement Recovery Mode. Contributed by Colin Patrick McCabe\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1311394 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/04/12 12:39 PM",
      "commitName": "706394d03992b394e9f907aff2155df493e4ea4e",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "12/03/12 12:41 PM",
      "commitNameOld": "1a75ec82885e45baf4d5cd56d6c738d8e68d8bc7",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 28.0,
      "commitsBetweenForRepo": 204,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,22 @@\n   private void loadFSImage(File curFile, MD5Hash expectedMd5,\n-      FSNamesystem target) throws IOException {\n+      FSNamesystem target, MetaRecoveryContext recovery) throws IOException {\n     FSImageFormat.Loader loader \u003d new FSImageFormat.Loader(\n         conf, target);\n     loader.load(curFile);\n     target.setBlockPoolId(this.getBlockPoolID());\n \n     // Check that the image digest we loaded matches up with what\n     // we expected\n     MD5Hash readImageMd5 \u003d loader.getLoadedImageMd5();\n     if (expectedMd5 !\u003d null \u0026\u0026\n         !expectedMd5.equals(readImageMd5)) {\n       throw new IOException(\"Image file \" + curFile +\n           \" is corrupt with MD5 checksum of \" + readImageMd5 +\n           \" but expecting \" + expectedMd5);\n     }\n \n     long txId \u003d loader.getLoadedImageTxId();\n     LOG.info(\"Loaded image for txid \" + txId + \" from \" + curFile);\n     lastAppliedTxId \u003d txId;\n     storage.setMostRecentCheckpointInfo(txId, curFile.lastModified());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void loadFSImage(File curFile, MD5Hash expectedMd5,\n      FSNamesystem target, MetaRecoveryContext recovery) throws IOException {\n    FSImageFormat.Loader loader \u003d new FSImageFormat.Loader(\n        conf, target);\n    loader.load(curFile);\n    target.setBlockPoolId(this.getBlockPoolID());\n\n    // Check that the image digest we loaded matches up with what\n    // we expected\n    MD5Hash readImageMd5 \u003d loader.getLoadedImageMd5();\n    if (expectedMd5 !\u003d null \u0026\u0026\n        !expectedMd5.equals(readImageMd5)) {\n      throw new IOException(\"Image file \" + curFile +\n          \" is corrupt with MD5 checksum of \" + readImageMd5 +\n          \" but expecting \" + expectedMd5);\n    }\n\n    long txId \u003d loader.getLoadedImageTxId();\n    LOG.info(\"Loaded image for txid \" + txId + \" from \" + curFile);\n    lastAppliedTxId \u003d txId;\n    storage.setMostRecentCheckpointInfo(txId, curFile.lastModified());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
      "extendedDetails": {
        "oldValue": "[curFile-File, expectedMd5-MD5Hash, target-FSNamesystem]",
        "newValue": "[curFile-File, expectedMd5-MD5Hash, target-FSNamesystem, recovery-MetaRecoveryContext]"
      }
    },
    "a87328dfab96a335535e8952e548534b73c00b7c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2943. Expose last checkpoint time and transaction stats as JMX metrics. Contributed by Aaron T. Myers.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1243822 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/02/12 12:27 AM",
      "commitName": "a87328dfab96a335535e8952e548534b73c00b7c",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "07/12/11 1:47 PM",
      "commitNameOld": "a27adf3de4ea88a80401fc7157c5e39747230c2a",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 68.44,
      "commitsBetweenForRepo": 392,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,22 @@\n   private void loadFSImage(File curFile, MD5Hash expectedMd5,\n       FSNamesystem target) throws IOException {\n     FSImageFormat.Loader loader \u003d new FSImageFormat.Loader(\n         conf, target);\n     loader.load(curFile);\n     target.setBlockPoolId(this.getBlockPoolID());\n \n     // Check that the image digest we loaded matches up with what\n     // we expected\n     MD5Hash readImageMd5 \u003d loader.getLoadedImageMd5();\n     if (expectedMd5 !\u003d null \u0026\u0026\n         !expectedMd5.equals(readImageMd5)) {\n       throw new IOException(\"Image file \" + curFile +\n           \" is corrupt with MD5 checksum of \" + readImageMd5 +\n           \" but expecting \" + expectedMd5);\n     }\n \n     long txId \u003d loader.getLoadedImageTxId();\n     LOG.info(\"Loaded image for txid \" + txId + \" from \" + curFile);\n     lastAppliedTxId \u003d txId;\n-    storage.setMostRecentCheckpointTxId(txId);\n+    storage.setMostRecentCheckpointInfo(txId, curFile.lastModified());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void loadFSImage(File curFile, MD5Hash expectedMd5,\n      FSNamesystem target) throws IOException {\n    FSImageFormat.Loader loader \u003d new FSImageFormat.Loader(\n        conf, target);\n    loader.load(curFile);\n    target.setBlockPoolId(this.getBlockPoolID());\n\n    // Check that the image digest we loaded matches up with what\n    // we expected\n    MD5Hash readImageMd5 \u003d loader.getLoadedImageMd5();\n    if (expectedMd5 !\u003d null \u0026\u0026\n        !expectedMd5.equals(readImageMd5)) {\n      throw new IOException(\"Image file \" + curFile +\n          \" is corrupt with MD5 checksum of \" + readImageMd5 +\n          \" but expecting \" + expectedMd5);\n    }\n\n    long txId \u003d loader.getLoadedImageTxId();\n    LOG.info(\"Loaded image for txid \" + txId + \" from \" + curFile);\n    lastAppliedTxId \u003d txId;\n    storage.setMostRecentCheckpointInfo(txId, curFile.lastModified());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
      "extendedDetails": {}
    },
    "06e84a1bca19bd01568a3095e33944d4d6387fd3": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-2223. Untangle depencencies between NN components. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1166466 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/09/11 4:23 PM",
      "commitName": "06e84a1bca19bd01568a3095e33944d4d6387fd3",
      "commitAuthor": "Todd Lipcon",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-2223. Untangle depencencies between NN components. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1166466 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "07/09/11 4:23 PM",
          "commitName": "06e84a1bca19bd01568a3095e33944d4d6387fd3",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "06/09/11 1:27 PM",
          "commitNameOld": "bdc3720d5b67a1c8fc2dfb29be16e4155c0e7f15",
          "commitAuthorOld": "Jitendra Nath Pandey",
          "daysBetweenCommits": 1.12,
          "commitsBetweenForRepo": 13,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,21 +1,22 @@\n-  private void loadFSImage(File curFile, MD5Hash expectedMd5) throws IOException {\n+  private void loadFSImage(File curFile, MD5Hash expectedMd5,\n+      FSNamesystem target) throws IOException {\n     FSImageFormat.Loader loader \u003d new FSImageFormat.Loader(\n-        conf, getFSNamesystem());\n+        conf, target);\n     loader.load(curFile);\n-    namesystem.setBlockPoolId(this.getBlockPoolID());\n+    target.setBlockPoolId(this.getBlockPoolID());\n \n     // Check that the image digest we loaded matches up with what\n     // we expected\n     MD5Hash readImageMd5 \u003d loader.getLoadedImageMd5();\n     if (expectedMd5 !\u003d null \u0026\u0026\n         !expectedMd5.equals(readImageMd5)) {\n       throw new IOException(\"Image file \" + curFile +\n           \" is corrupt with MD5 checksum of \" + readImageMd5 +\n           \" but expecting \" + expectedMd5);\n     }\n \n     long txId \u003d loader.getLoadedImageTxId();\n     LOG.info(\"Loaded image for txid \" + txId + \" from \" + curFile);\n     lastAppliedTxId \u003d txId;\n     storage.setMostRecentCheckpointTxId(txId);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void loadFSImage(File curFile, MD5Hash expectedMd5,\n      FSNamesystem target) throws IOException {\n    FSImageFormat.Loader loader \u003d new FSImageFormat.Loader(\n        conf, target);\n    loader.load(curFile);\n    target.setBlockPoolId(this.getBlockPoolID());\n\n    // Check that the image digest we loaded matches up with what\n    // we expected\n    MD5Hash readImageMd5 \u003d loader.getLoadedImageMd5();\n    if (expectedMd5 !\u003d null \u0026\u0026\n        !expectedMd5.equals(readImageMd5)) {\n      throw new IOException(\"Image file \" + curFile +\n          \" is corrupt with MD5 checksum of \" + readImageMd5 +\n          \" but expecting \" + expectedMd5);\n    }\n\n    long txId \u003d loader.getLoadedImageTxId();\n    LOG.info(\"Loaded image for txid \" + txId + \" from \" + curFile);\n    lastAppliedTxId \u003d txId;\n    storage.setMostRecentCheckpointTxId(txId);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
          "extendedDetails": {
            "oldValue": "[curFile-File, expectedMd5-MD5Hash]",
            "newValue": "[curFile-File, expectedMd5-MD5Hash, target-FSNamesystem]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-2223. Untangle depencencies between NN components. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1166466 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "07/09/11 4:23 PM",
          "commitName": "06e84a1bca19bd01568a3095e33944d4d6387fd3",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "06/09/11 1:27 PM",
          "commitNameOld": "bdc3720d5b67a1c8fc2dfb29be16e4155c0e7f15",
          "commitAuthorOld": "Jitendra Nath Pandey",
          "daysBetweenCommits": 1.12,
          "commitsBetweenForRepo": 13,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,21 +1,22 @@\n-  private void loadFSImage(File curFile, MD5Hash expectedMd5) throws IOException {\n+  private void loadFSImage(File curFile, MD5Hash expectedMd5,\n+      FSNamesystem target) throws IOException {\n     FSImageFormat.Loader loader \u003d new FSImageFormat.Loader(\n-        conf, getFSNamesystem());\n+        conf, target);\n     loader.load(curFile);\n-    namesystem.setBlockPoolId(this.getBlockPoolID());\n+    target.setBlockPoolId(this.getBlockPoolID());\n \n     // Check that the image digest we loaded matches up with what\n     // we expected\n     MD5Hash readImageMd5 \u003d loader.getLoadedImageMd5();\n     if (expectedMd5 !\u003d null \u0026\u0026\n         !expectedMd5.equals(readImageMd5)) {\n       throw new IOException(\"Image file \" + curFile +\n           \" is corrupt with MD5 checksum of \" + readImageMd5 +\n           \" but expecting \" + expectedMd5);\n     }\n \n     long txId \u003d loader.getLoadedImageTxId();\n     LOG.info(\"Loaded image for txid \" + txId + \" from \" + curFile);\n     lastAppliedTxId \u003d txId;\n     storage.setMostRecentCheckpointTxId(txId);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void loadFSImage(File curFile, MD5Hash expectedMd5,\n      FSNamesystem target) throws IOException {\n    FSImageFormat.Loader loader \u003d new FSImageFormat.Loader(\n        conf, target);\n    loader.load(curFile);\n    target.setBlockPoolId(this.getBlockPoolID());\n\n    // Check that the image digest we loaded matches up with what\n    // we expected\n    MD5Hash readImageMd5 \u003d loader.getLoadedImageMd5();\n    if (expectedMd5 !\u003d null \u0026\u0026\n        !expectedMd5.equals(readImageMd5)) {\n      throw new IOException(\"Image file \" + curFile +\n          \" is corrupt with MD5 checksum of \" + readImageMd5 +\n          \" but expecting \" + expectedMd5);\n    }\n\n    long txId \u003d loader.getLoadedImageTxId();\n    LOG.info(\"Loaded image for txid \" + txId + \" from \" + curFile);\n    lastAppliedTxId \u003d txId;\n    storage.setMostRecentCheckpointTxId(txId);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
          "extendedDetails": {}
        }
      ]
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private void loadFSImage(File curFile, MD5Hash expectedMd5) throws IOException {\n    FSImageFormat.Loader loader \u003d new FSImageFormat.Loader(\n        conf, getFSNamesystem());\n    loader.load(curFile);\n    namesystem.setBlockPoolId(this.getBlockPoolID());\n\n    // Check that the image digest we loaded matches up with what\n    // we expected\n    MD5Hash readImageMd5 \u003d loader.getLoadedImageMd5();\n    if (expectedMd5 !\u003d null \u0026\u0026\n        !expectedMd5.equals(readImageMd5)) {\n      throw new IOException(\"Image file \" + curFile +\n          \" is corrupt with MD5 checksum of \" + readImageMd5 +\n          \" but expecting \" + expectedMd5);\n    }\n\n    long txId \u003d loader.getLoadedImageTxId();\n    LOG.info(\"Loaded image for txid \" + txId + \" from \" + curFile);\n    lastAppliedTxId \u003d txId;\n    storage.setMostRecentCheckpointTxId(txId);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private void loadFSImage(File curFile, MD5Hash expectedMd5) throws IOException {\n    FSImageFormat.Loader loader \u003d new FSImageFormat.Loader(\n        conf, getFSNamesystem());\n    loader.load(curFile);\n    namesystem.setBlockPoolId(this.getBlockPoolID());\n\n    // Check that the image digest we loaded matches up with what\n    // we expected\n    MD5Hash readImageMd5 \u003d loader.getLoadedImageMd5();\n    if (expectedMd5 !\u003d null \u0026\u0026\n        !expectedMd5.equals(readImageMd5)) {\n      throw new IOException(\"Image file \" + curFile +\n          \" is corrupt with MD5 checksum of \" + readImageMd5 +\n          \" but expecting \" + expectedMd5);\n    }\n\n    long txId \u003d loader.getLoadedImageTxId();\n    LOG.info(\"Loaded image for txid \" + txId + \" from \" + curFile);\n    lastAppliedTxId \u003d txId;\n    storage.setMostRecentCheckpointTxId(txId);\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java"
      }
    },
    "28e6a4e44a3e920dcaf858f9a74a6358226b3a63": {
      "type": "Ymultichange(Yparameterchange,Yreturntypechange,Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-1073. Redesign the NameNode\u0027s storage layout for image checkpoints and edit logs to introduce transaction IDs and be more robust. Contributed by Todd Lipcon and Ivan Kelly.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1152295 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "29/07/11 9:28 AM",
      "commitName": "28e6a4e44a3e920dcaf858f9a74a6358226b3a63",
      "commitAuthor": "Todd Lipcon",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-1073. Redesign the NameNode\u0027s storage layout for image checkpoints and edit logs to introduce transaction IDs and be more robust. Contributed by Todd Lipcon and Ivan Kelly.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1152295 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "29/07/11 9:28 AM",
          "commitName": "28e6a4e44a3e920dcaf858f9a74a6358226b3a63",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "27/07/11 8:19 PM",
          "commitNameOld": "ffbe9e5972bf3eee9037e2602c1330e0dc744646",
          "commitAuthorOld": "Eli Collins",
          "daysBetweenCommits": 1.55,
          "commitsBetweenForRepo": 6,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,21 @@\n-  boolean loadFSImage(File curFile) throws IOException {\n+  private void loadFSImage(File curFile, MD5Hash expectedMd5) throws IOException {\n     FSImageFormat.Loader loader \u003d new FSImageFormat.Loader(\n         conf, getFSNamesystem());\n     loader.load(curFile);\n     namesystem.setBlockPoolId(this.getBlockPoolID());\n \n     // Check that the image digest we loaded matches up with what\n     // we expected\n     MD5Hash readImageMd5 \u003d loader.getLoadedImageMd5();\n-    if (storage.getImageDigest() \u003d\u003d null) {\n-      storage.setImageDigest(readImageMd5); // set this fsimage\u0027s checksum\n-    } else if (!storage.getImageDigest().equals(readImageMd5)) {\n+    if (expectedMd5 !\u003d null \u0026\u0026\n+        !expectedMd5.equals(readImageMd5)) {\n       throw new IOException(\"Image file \" + curFile +\n           \" is corrupt with MD5 checksum of \" + readImageMd5 +\n-          \" but expecting \" + storage.getImageDigest());\n+          \" but expecting \" + expectedMd5);\n     }\n \n-    storage.namespaceID \u003d loader.getLoadedNamespaceID();\n-    storage.layoutVersion \u003d loader.getLoadedImageVersion();\n-\n-    boolean needToSave \u003d\n-      loader.getLoadedImageVersion() !\u003d FSConstants.LAYOUT_VERSION;\n-    return needToSave;\n+    long txId \u003d loader.getLoadedImageTxId();\n+    LOG.info(\"Loaded image for txid \" + txId + \" from \" + curFile);\n+    lastAppliedTxId \u003d txId;\n+    storage.setMostRecentCheckpointTxId(txId);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void loadFSImage(File curFile, MD5Hash expectedMd5) throws IOException {\n    FSImageFormat.Loader loader \u003d new FSImageFormat.Loader(\n        conf, getFSNamesystem());\n    loader.load(curFile);\n    namesystem.setBlockPoolId(this.getBlockPoolID());\n\n    // Check that the image digest we loaded matches up with what\n    // we expected\n    MD5Hash readImageMd5 \u003d loader.getLoadedImageMd5();\n    if (expectedMd5 !\u003d null \u0026\u0026\n        !expectedMd5.equals(readImageMd5)) {\n      throw new IOException(\"Image file \" + curFile +\n          \" is corrupt with MD5 checksum of \" + readImageMd5 +\n          \" but expecting \" + expectedMd5);\n    }\n\n    long txId \u003d loader.getLoadedImageTxId();\n    LOG.info(\"Loaded image for txid \" + txId + \" from \" + curFile);\n    lastAppliedTxId \u003d txId;\n    storage.setMostRecentCheckpointTxId(txId);\n  }",
          "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
          "extendedDetails": {
            "oldValue": "[curFile-File]",
            "newValue": "[curFile-File, expectedMd5-MD5Hash]"
          }
        },
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-1073. Redesign the NameNode\u0027s storage layout for image checkpoints and edit logs to introduce transaction IDs and be more robust. Contributed by Todd Lipcon and Ivan Kelly.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1152295 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "29/07/11 9:28 AM",
          "commitName": "28e6a4e44a3e920dcaf858f9a74a6358226b3a63",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "27/07/11 8:19 PM",
          "commitNameOld": "ffbe9e5972bf3eee9037e2602c1330e0dc744646",
          "commitAuthorOld": "Eli Collins",
          "daysBetweenCommits": 1.55,
          "commitsBetweenForRepo": 6,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,21 @@\n-  boolean loadFSImage(File curFile) throws IOException {\n+  private void loadFSImage(File curFile, MD5Hash expectedMd5) throws IOException {\n     FSImageFormat.Loader loader \u003d new FSImageFormat.Loader(\n         conf, getFSNamesystem());\n     loader.load(curFile);\n     namesystem.setBlockPoolId(this.getBlockPoolID());\n \n     // Check that the image digest we loaded matches up with what\n     // we expected\n     MD5Hash readImageMd5 \u003d loader.getLoadedImageMd5();\n-    if (storage.getImageDigest() \u003d\u003d null) {\n-      storage.setImageDigest(readImageMd5); // set this fsimage\u0027s checksum\n-    } else if (!storage.getImageDigest().equals(readImageMd5)) {\n+    if (expectedMd5 !\u003d null \u0026\u0026\n+        !expectedMd5.equals(readImageMd5)) {\n       throw new IOException(\"Image file \" + curFile +\n           \" is corrupt with MD5 checksum of \" + readImageMd5 +\n-          \" but expecting \" + storage.getImageDigest());\n+          \" but expecting \" + expectedMd5);\n     }\n \n-    storage.namespaceID \u003d loader.getLoadedNamespaceID();\n-    storage.layoutVersion \u003d loader.getLoadedImageVersion();\n-\n-    boolean needToSave \u003d\n-      loader.getLoadedImageVersion() !\u003d FSConstants.LAYOUT_VERSION;\n-    return needToSave;\n+    long txId \u003d loader.getLoadedImageTxId();\n+    LOG.info(\"Loaded image for txid \" + txId + \" from \" + curFile);\n+    lastAppliedTxId \u003d txId;\n+    storage.setMostRecentCheckpointTxId(txId);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void loadFSImage(File curFile, MD5Hash expectedMd5) throws IOException {\n    FSImageFormat.Loader loader \u003d new FSImageFormat.Loader(\n        conf, getFSNamesystem());\n    loader.load(curFile);\n    namesystem.setBlockPoolId(this.getBlockPoolID());\n\n    // Check that the image digest we loaded matches up with what\n    // we expected\n    MD5Hash readImageMd5 \u003d loader.getLoadedImageMd5();\n    if (expectedMd5 !\u003d null \u0026\u0026\n        !expectedMd5.equals(readImageMd5)) {\n      throw new IOException(\"Image file \" + curFile +\n          \" is corrupt with MD5 checksum of \" + readImageMd5 +\n          \" but expecting \" + expectedMd5);\n    }\n\n    long txId \u003d loader.getLoadedImageTxId();\n    LOG.info(\"Loaded image for txid \" + txId + \" from \" + curFile);\n    lastAppliedTxId \u003d txId;\n    storage.setMostRecentCheckpointTxId(txId);\n  }",
          "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
          "extendedDetails": {
            "oldValue": "boolean",
            "newValue": "void"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-1073. Redesign the NameNode\u0027s storage layout for image checkpoints and edit logs to introduce transaction IDs and be more robust. Contributed by Todd Lipcon and Ivan Kelly.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1152295 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "29/07/11 9:28 AM",
          "commitName": "28e6a4e44a3e920dcaf858f9a74a6358226b3a63",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "27/07/11 8:19 PM",
          "commitNameOld": "ffbe9e5972bf3eee9037e2602c1330e0dc744646",
          "commitAuthorOld": "Eli Collins",
          "daysBetweenCommits": 1.55,
          "commitsBetweenForRepo": 6,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,21 @@\n-  boolean loadFSImage(File curFile) throws IOException {\n+  private void loadFSImage(File curFile, MD5Hash expectedMd5) throws IOException {\n     FSImageFormat.Loader loader \u003d new FSImageFormat.Loader(\n         conf, getFSNamesystem());\n     loader.load(curFile);\n     namesystem.setBlockPoolId(this.getBlockPoolID());\n \n     // Check that the image digest we loaded matches up with what\n     // we expected\n     MD5Hash readImageMd5 \u003d loader.getLoadedImageMd5();\n-    if (storage.getImageDigest() \u003d\u003d null) {\n-      storage.setImageDigest(readImageMd5); // set this fsimage\u0027s checksum\n-    } else if (!storage.getImageDigest().equals(readImageMd5)) {\n+    if (expectedMd5 !\u003d null \u0026\u0026\n+        !expectedMd5.equals(readImageMd5)) {\n       throw new IOException(\"Image file \" + curFile +\n           \" is corrupt with MD5 checksum of \" + readImageMd5 +\n-          \" but expecting \" + storage.getImageDigest());\n+          \" but expecting \" + expectedMd5);\n     }\n \n-    storage.namespaceID \u003d loader.getLoadedNamespaceID();\n-    storage.layoutVersion \u003d loader.getLoadedImageVersion();\n-\n-    boolean needToSave \u003d\n-      loader.getLoadedImageVersion() !\u003d FSConstants.LAYOUT_VERSION;\n-    return needToSave;\n+    long txId \u003d loader.getLoadedImageTxId();\n+    LOG.info(\"Loaded image for txid \" + txId + \" from \" + curFile);\n+    lastAppliedTxId \u003d txId;\n+    storage.setMostRecentCheckpointTxId(txId);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void loadFSImage(File curFile, MD5Hash expectedMd5) throws IOException {\n    FSImageFormat.Loader loader \u003d new FSImageFormat.Loader(\n        conf, getFSNamesystem());\n    loader.load(curFile);\n    namesystem.setBlockPoolId(this.getBlockPoolID());\n\n    // Check that the image digest we loaded matches up with what\n    // we expected\n    MD5Hash readImageMd5 \u003d loader.getLoadedImageMd5();\n    if (expectedMd5 !\u003d null \u0026\u0026\n        !expectedMd5.equals(readImageMd5)) {\n      throw new IOException(\"Image file \" + curFile +\n          \" is corrupt with MD5 checksum of \" + readImageMd5 +\n          \" but expecting \" + expectedMd5);\n    }\n\n    long txId \u003d loader.getLoadedImageTxId();\n    LOG.info(\"Loaded image for txid \" + txId + \" from \" + curFile);\n    lastAppliedTxId \u003d txId;\n    storage.setMostRecentCheckpointTxId(txId);\n  }",
          "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[private]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-1073. Redesign the NameNode\u0027s storage layout for image checkpoints and edit logs to introduce transaction IDs and be more robust. Contributed by Todd Lipcon and Ivan Kelly.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1152295 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "29/07/11 9:28 AM",
          "commitName": "28e6a4e44a3e920dcaf858f9a74a6358226b3a63",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "27/07/11 8:19 PM",
          "commitNameOld": "ffbe9e5972bf3eee9037e2602c1330e0dc744646",
          "commitAuthorOld": "Eli Collins",
          "daysBetweenCommits": 1.55,
          "commitsBetweenForRepo": 6,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,21 @@\n-  boolean loadFSImage(File curFile) throws IOException {\n+  private void loadFSImage(File curFile, MD5Hash expectedMd5) throws IOException {\n     FSImageFormat.Loader loader \u003d new FSImageFormat.Loader(\n         conf, getFSNamesystem());\n     loader.load(curFile);\n     namesystem.setBlockPoolId(this.getBlockPoolID());\n \n     // Check that the image digest we loaded matches up with what\n     // we expected\n     MD5Hash readImageMd5 \u003d loader.getLoadedImageMd5();\n-    if (storage.getImageDigest() \u003d\u003d null) {\n-      storage.setImageDigest(readImageMd5); // set this fsimage\u0027s checksum\n-    } else if (!storage.getImageDigest().equals(readImageMd5)) {\n+    if (expectedMd5 !\u003d null \u0026\u0026\n+        !expectedMd5.equals(readImageMd5)) {\n       throw new IOException(\"Image file \" + curFile +\n           \" is corrupt with MD5 checksum of \" + readImageMd5 +\n-          \" but expecting \" + storage.getImageDigest());\n+          \" but expecting \" + expectedMd5);\n     }\n \n-    storage.namespaceID \u003d loader.getLoadedNamespaceID();\n-    storage.layoutVersion \u003d loader.getLoadedImageVersion();\n-\n-    boolean needToSave \u003d\n-      loader.getLoadedImageVersion() !\u003d FSConstants.LAYOUT_VERSION;\n-    return needToSave;\n+    long txId \u003d loader.getLoadedImageTxId();\n+    LOG.info(\"Loaded image for txid \" + txId + \" from \" + curFile);\n+    lastAppliedTxId \u003d txId;\n+    storage.setMostRecentCheckpointTxId(txId);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void loadFSImage(File curFile, MD5Hash expectedMd5) throws IOException {\n    FSImageFormat.Loader loader \u003d new FSImageFormat.Loader(\n        conf, getFSNamesystem());\n    loader.load(curFile);\n    namesystem.setBlockPoolId(this.getBlockPoolID());\n\n    // Check that the image digest we loaded matches up with what\n    // we expected\n    MD5Hash readImageMd5 \u003d loader.getLoadedImageMd5();\n    if (expectedMd5 !\u003d null \u0026\u0026\n        !expectedMd5.equals(readImageMd5)) {\n      throw new IOException(\"Image file \" + curFile +\n          \" is corrupt with MD5 checksum of \" + readImageMd5 +\n          \" but expecting \" + expectedMd5);\n    }\n\n    long txId \u003d loader.getLoadedImageTxId();\n    LOG.info(\"Loaded image for txid \" + txId + \" from \" + curFile);\n    lastAppliedTxId \u003d txId;\n    storage.setMostRecentCheckpointTxId(txId);\n  }",
          "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
          "extendedDetails": {}
        }
      ]
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,24 @@\n+  boolean loadFSImage(File curFile) throws IOException {\n+    FSImageFormat.Loader loader \u003d new FSImageFormat.Loader(\n+        conf, getFSNamesystem());\n+    loader.load(curFile);\n+    namesystem.setBlockPoolId(this.getBlockPoolID());\n+\n+    // Check that the image digest we loaded matches up with what\n+    // we expected\n+    MD5Hash readImageMd5 \u003d loader.getLoadedImageMd5();\n+    if (storage.getImageDigest() \u003d\u003d null) {\n+      storage.setImageDigest(readImageMd5); // set this fsimage\u0027s checksum\n+    } else if (!storage.getImageDigest().equals(readImageMd5)) {\n+      throw new IOException(\"Image file \" + curFile +\n+          \" is corrupt with MD5 checksum of \" + readImageMd5 +\n+          \" but expecting \" + storage.getImageDigest());\n+    }\n+\n+    storage.namespaceID \u003d loader.getLoadedNamespaceID();\n+    storage.layoutVersion \u003d loader.getLoadedImageVersion();\n+\n+    boolean needToSave \u003d\n+      loader.getLoadedImageVersion() !\u003d FSConstants.LAYOUT_VERSION;\n+    return needToSave;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  boolean loadFSImage(File curFile) throws IOException {\n    FSImageFormat.Loader loader \u003d new FSImageFormat.Loader(\n        conf, getFSNamesystem());\n    loader.load(curFile);\n    namesystem.setBlockPoolId(this.getBlockPoolID());\n\n    // Check that the image digest we loaded matches up with what\n    // we expected\n    MD5Hash readImageMd5 \u003d loader.getLoadedImageMd5();\n    if (storage.getImageDigest() \u003d\u003d null) {\n      storage.setImageDigest(readImageMd5); // set this fsimage\u0027s checksum\n    } else if (!storage.getImageDigest().equals(readImageMd5)) {\n      throw new IOException(\"Image file \" + curFile +\n          \" is corrupt with MD5 checksum of \" + readImageMd5 +\n          \" but expecting \" + storage.getImageDigest());\n    }\n\n    storage.namespaceID \u003d loader.getLoadedNamespaceID();\n    storage.layoutVersion \u003d loader.getLoadedImageVersion();\n\n    boolean needToSave \u003d\n      loader.getLoadedImageVersion() !\u003d FSConstants.LAYOUT_VERSION;\n    return needToSave;\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java"
    }
  }
}