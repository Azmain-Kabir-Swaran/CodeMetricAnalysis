{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSEditLog.java",
  "functionName": "logSync",
  "functionId": "logSync",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java",
  "functionStartLine": 646,
  "functionEndLine": 649,
  "numCommitsSeen": 149,
  "timeTaken": 7700,
  "changeHistory": [
    "2151716832ad14932dd65b1a4e47e64d8d6cd767",
    "53c38cc89ab979ec47557dcfa7affbad20578c0a",
    "75ead273bea8a7dad61c4f99c3a16cab2697c498",
    "faa4455be512e070fa420084be8d1be5c72f3b08",
    "fd24c6e83357d4d3c937e112328a1eb378327eb0",
    "527933f4f351a3df5e369c8bb6e2cfc4937e0836",
    "cdae6953e80e81693bb4c9eb38b62eaba3ac8cf9",
    "a27adf3de4ea88a80401fc7157c5e39747230c2a",
    "1ae5b5e338ef383c5642e2f04b927871c7b184f6",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "28e6a4e44a3e920dcaf858f9a74a6358226b3a63",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "2151716832ad14932dd65b1a4e47e64d8d6cd767": "Ybodychange",
    "53c38cc89ab979ec47557dcfa7affbad20578c0a": "Ybodychange",
    "75ead273bea8a7dad61c4f99c3a16cab2697c498": "Ybodychange",
    "faa4455be512e070fa420084be8d1be5c72f3b08": "Ybodychange",
    "fd24c6e83357d4d3c937e112328a1eb378327eb0": "Ybodychange",
    "527933f4f351a3df5e369c8bb6e2cfc4937e0836": "Ybodychange",
    "cdae6953e80e81693bb4c9eb38b62eaba3ac8cf9": "Ybodychange",
    "a27adf3de4ea88a80401fc7157c5e39747230c2a": "Ybodychange",
    "1ae5b5e338ef383c5642e2f04b927871c7b184f6": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "28e6a4e44a3e920dcaf858f9a74a6358226b3a63": "Ybodychange",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "2151716832ad14932dd65b1a4e47e64d8d6cd767": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7964. Add support for async edit logging. Contributed by Daryn Sharp.\n",
      "commitDate": "29/02/16 3:34 PM",
      "commitName": "2151716832ad14932dd65b1a4e47e64d8d6cd767",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "27/01/16 4:34 PM",
      "commitNameOld": "ec25c7f9c7e60c077d8c4143253c20445fcdaecf",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 32.96,
      "commitsBetweenForRepo": 229,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,109 +1,4 @@\n   public void logSync() {\n-    long syncStart \u003d 0;\n-\n-    // Fetch the transactionId of this thread. \n-    long mytxid \u003d myTransactionId.get().txid;\n-    \n-    boolean sync \u003d false;\n-    try {\n-      EditLogOutputStream logStream \u003d null;\n-      synchronized (this) {\n-        try {\n-          printStatistics(false);\n-\n-          // if somebody is already syncing, then wait\n-          while (mytxid \u003e synctxid \u0026\u0026 isSyncRunning) {\n-            try {\n-              wait(1000);\n-            } catch (InterruptedException ie) {\n-            }\n-          }\n-  \n-          //\n-          // If this transaction was already flushed, then nothing to do\n-          //\n-          if (mytxid \u003c\u003d synctxid) {\n-            numTransactionsBatchedInSync++;\n-            if (metrics !\u003d null) {\n-              // Metrics is non-null only when used inside name node\n-              metrics.incrTransactionsBatchedInSync();\n-            }\n-            return;\n-          }\n-     \n-          // now, this thread will do the sync\n-          syncStart \u003d txid;\n-          isSyncRunning \u003d true;\n-          sync \u003d true;\n-  \n-          // swap buffers\n-          try {\n-            if (journalSet.isEmpty()) {\n-              throw new IOException(\"No journals available to flush\");\n-            }\n-            editLogStream.setReadyToFlush();\n-          } catch (IOException e) {\n-            final String msg \u003d\n-                \"Could not sync enough journals to persistent storage \" +\n-                \"due to \" + e.getMessage() + \". \" +\n-                \"Unsynced transactions: \" + (txid - synctxid);\n-            LOG.fatal(msg, new Exception());\n-            synchronized(journalSetLock) {\n-              IOUtils.cleanup(LOG, journalSet);\n-            }\n-            terminate(1, msg);\n-          }\n-        } finally {\n-          // Prevent RuntimeException from blocking other log edit write \n-          doneWithAutoSyncScheduling();\n-        }\n-        //editLogStream may become null,\n-        //so store a local variable for flush.\n-        logStream \u003d editLogStream;\n-      }\n-      \n-      // do the sync\n-      long start \u003d monotonicNow();\n-      try {\n-        if (logStream !\u003d null) {\n-          logStream.flush();\n-        }\n-      } catch (IOException ex) {\n-        synchronized (this) {\n-          final String msg \u003d\n-              \"Could not sync enough journals to persistent storage. \"\n-              + \"Unsynced transactions: \" + (txid - synctxid);\n-          LOG.fatal(msg, new Exception());\n-          synchronized(journalSetLock) {\n-            IOUtils.cleanup(LOG, journalSet);\n-          }\n-          terminate(1, msg);\n-        }\n-      }\n-      long elapsed \u003d monotonicNow() - start;\n-  \n-      if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n-        metrics.addSync(elapsed);\n-      }\n-      \n-    } finally {\n-      // Prevent RuntimeException from blocking other log edit sync \n-      synchronized (this) {\n-        if (sync) {\n-          synctxid \u003d syncStart;\n-          for (JournalManager jm : journalSet.getJournalManagers()) {\n-            /**\n-             * {@link FileJournalManager#lastReadableTxId} is only meaningful\n-             * for file-based journals. Therefore the interface is not added to\n-             * other types of {@link JournalManager}.\n-             */\n-            if (jm instanceof FileJournalManager) {\n-              ((FileJournalManager)jm).setLastReadableTxId(syncStart);\n-            }\n-          }\n-          isSyncRunning \u003d false;\n-        }\n-        this.notifyAll();\n-     }\n-    }\n+    // Fetch the transactionId of this thread.\n+    logSync(myTransactionId.get().txid);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void logSync() {\n    // Fetch the transactionId of this thread.\n    logSync(myTransactionId.get().txid);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java",
      "extendedDetails": {}
    },
    "53c38cc89ab979ec47557dcfa7affbad20578c0a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8964. When validating the edit log, do not read at or beyond the file offset that is being written (Zhe Zhang via Colin P. McCabe)\n",
      "commitDate": "03/09/15 11:22 AM",
      "commitName": "53c38cc89ab979ec47557dcfa7affbad20578c0a",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "27/08/15 1:03 PM",
      "commitNameOld": "f97a0f8c2cdad0668a3892319f6969fafc2f04cd",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 6.93,
      "commitsBetweenForRepo": 45,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,99 +1,109 @@\n   public void logSync() {\n     long syncStart \u003d 0;\n \n     // Fetch the transactionId of this thread. \n     long mytxid \u003d myTransactionId.get().txid;\n     \n     boolean sync \u003d false;\n     try {\n       EditLogOutputStream logStream \u003d null;\n       synchronized (this) {\n         try {\n           printStatistics(false);\n \n           // if somebody is already syncing, then wait\n           while (mytxid \u003e synctxid \u0026\u0026 isSyncRunning) {\n             try {\n               wait(1000);\n             } catch (InterruptedException ie) {\n             }\n           }\n   \n           //\n           // If this transaction was already flushed, then nothing to do\n           //\n           if (mytxid \u003c\u003d synctxid) {\n             numTransactionsBatchedInSync++;\n             if (metrics !\u003d null) {\n               // Metrics is non-null only when used inside name node\n               metrics.incrTransactionsBatchedInSync();\n             }\n             return;\n           }\n      \n           // now, this thread will do the sync\n           syncStart \u003d txid;\n           isSyncRunning \u003d true;\n           sync \u003d true;\n   \n           // swap buffers\n           try {\n             if (journalSet.isEmpty()) {\n               throw new IOException(\"No journals available to flush\");\n             }\n             editLogStream.setReadyToFlush();\n           } catch (IOException e) {\n             final String msg \u003d\n                 \"Could not sync enough journals to persistent storage \" +\n                 \"due to \" + e.getMessage() + \". \" +\n                 \"Unsynced transactions: \" + (txid - synctxid);\n             LOG.fatal(msg, new Exception());\n             synchronized(journalSetLock) {\n               IOUtils.cleanup(LOG, journalSet);\n             }\n             terminate(1, msg);\n           }\n         } finally {\n           // Prevent RuntimeException from blocking other log edit write \n           doneWithAutoSyncScheduling();\n         }\n         //editLogStream may become null,\n         //so store a local variable for flush.\n         logStream \u003d editLogStream;\n       }\n       \n       // do the sync\n       long start \u003d monotonicNow();\n       try {\n         if (logStream !\u003d null) {\n           logStream.flush();\n         }\n       } catch (IOException ex) {\n         synchronized (this) {\n           final String msg \u003d\n               \"Could not sync enough journals to persistent storage. \"\n               + \"Unsynced transactions: \" + (txid - synctxid);\n           LOG.fatal(msg, new Exception());\n           synchronized(journalSetLock) {\n             IOUtils.cleanup(LOG, journalSet);\n           }\n           terminate(1, msg);\n         }\n       }\n       long elapsed \u003d monotonicNow() - start;\n   \n       if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n         metrics.addSync(elapsed);\n       }\n       \n     } finally {\n       // Prevent RuntimeException from blocking other log edit sync \n       synchronized (this) {\n         if (sync) {\n           synctxid \u003d syncStart;\n+          for (JournalManager jm : journalSet.getJournalManagers()) {\n+            /**\n+             * {@link FileJournalManager#lastReadableTxId} is only meaningful\n+             * for file-based journals. Therefore the interface is not added to\n+             * other types of {@link JournalManager}.\n+             */\n+            if (jm instanceof FileJournalManager) {\n+              ((FileJournalManager)jm).setLastReadableTxId(syncStart);\n+            }\n+          }\n           isSyncRunning \u003d false;\n         }\n         this.notifyAll();\n      }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void logSync() {\n    long syncStart \u003d 0;\n\n    // Fetch the transactionId of this thread. \n    long mytxid \u003d myTransactionId.get().txid;\n    \n    boolean sync \u003d false;\n    try {\n      EditLogOutputStream logStream \u003d null;\n      synchronized (this) {\n        try {\n          printStatistics(false);\n\n          // if somebody is already syncing, then wait\n          while (mytxid \u003e synctxid \u0026\u0026 isSyncRunning) {\n            try {\n              wait(1000);\n            } catch (InterruptedException ie) {\n            }\n          }\n  \n          //\n          // If this transaction was already flushed, then nothing to do\n          //\n          if (mytxid \u003c\u003d synctxid) {\n            numTransactionsBatchedInSync++;\n            if (metrics !\u003d null) {\n              // Metrics is non-null only when used inside name node\n              metrics.incrTransactionsBatchedInSync();\n            }\n            return;\n          }\n     \n          // now, this thread will do the sync\n          syncStart \u003d txid;\n          isSyncRunning \u003d true;\n          sync \u003d true;\n  \n          // swap buffers\n          try {\n            if (journalSet.isEmpty()) {\n              throw new IOException(\"No journals available to flush\");\n            }\n            editLogStream.setReadyToFlush();\n          } catch (IOException e) {\n            final String msg \u003d\n                \"Could not sync enough journals to persistent storage \" +\n                \"due to \" + e.getMessage() + \". \" +\n                \"Unsynced transactions: \" + (txid - synctxid);\n            LOG.fatal(msg, new Exception());\n            synchronized(journalSetLock) {\n              IOUtils.cleanup(LOG, journalSet);\n            }\n            terminate(1, msg);\n          }\n        } finally {\n          // Prevent RuntimeException from blocking other log edit write \n          doneWithAutoSyncScheduling();\n        }\n        //editLogStream may become null,\n        //so store a local variable for flush.\n        logStream \u003d editLogStream;\n      }\n      \n      // do the sync\n      long start \u003d monotonicNow();\n      try {\n        if (logStream !\u003d null) {\n          logStream.flush();\n        }\n      } catch (IOException ex) {\n        synchronized (this) {\n          final String msg \u003d\n              \"Could not sync enough journals to persistent storage. \"\n              + \"Unsynced transactions: \" + (txid - synctxid);\n          LOG.fatal(msg, new Exception());\n          synchronized(journalSetLock) {\n            IOUtils.cleanup(LOG, journalSet);\n          }\n          terminate(1, msg);\n        }\n      }\n      long elapsed \u003d monotonicNow() - start;\n  \n      if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n        metrics.addSync(elapsed);\n      }\n      \n    } finally {\n      // Prevent RuntimeException from blocking other log edit sync \n      synchronized (this) {\n        if (sync) {\n          synctxid \u003d syncStart;\n          for (JournalManager jm : journalSet.getJournalManagers()) {\n            /**\n             * {@link FileJournalManager#lastReadableTxId} is only meaningful\n             * for file-based journals. Therefore the interface is not added to\n             * other types of {@link JournalManager}.\n             */\n            if (jm instanceof FileJournalManager) {\n              ((FileJournalManager)jm).setLastReadableTxId(syncStart);\n            }\n          }\n          isSyncRunning \u003d false;\n        }\n        this.notifyAll();\n     }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java",
      "extendedDetails": {}
    },
    "75ead273bea8a7dad61c4f99c3a16cab2697c498": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6841. Use Time.monotonicNow() wherever applicable instead of Time.now(). Contributed by Vinayakumar B\n",
      "commitDate": "20/03/15 12:02 PM",
      "commitName": "75ead273bea8a7dad61c4f99c3a16cab2697c498",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "21/02/15 3:38 PM",
      "commitNameOld": "8b465b4b8caed31ca9daeaae108f9a868a30a455",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 26.81,
      "commitsBetweenForRepo": 229,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,99 +1,99 @@\n   public void logSync() {\n     long syncStart \u003d 0;\n \n     // Fetch the transactionId of this thread. \n     long mytxid \u003d myTransactionId.get().txid;\n     \n     boolean sync \u003d false;\n     try {\n       EditLogOutputStream logStream \u003d null;\n       synchronized (this) {\n         try {\n           printStatistics(false);\n \n           // if somebody is already syncing, then wait\n           while (mytxid \u003e synctxid \u0026\u0026 isSyncRunning) {\n             try {\n               wait(1000);\n             } catch (InterruptedException ie) {\n             }\n           }\n   \n           //\n           // If this transaction was already flushed, then nothing to do\n           //\n           if (mytxid \u003c\u003d synctxid) {\n             numTransactionsBatchedInSync++;\n             if (metrics !\u003d null) {\n               // Metrics is non-null only when used inside name node\n               metrics.incrTransactionsBatchedInSync();\n             }\n             return;\n           }\n      \n           // now, this thread will do the sync\n           syncStart \u003d txid;\n           isSyncRunning \u003d true;\n           sync \u003d true;\n   \n           // swap buffers\n           try {\n             if (journalSet.isEmpty()) {\n               throw new IOException(\"No journals available to flush\");\n             }\n             editLogStream.setReadyToFlush();\n           } catch (IOException e) {\n             final String msg \u003d\n                 \"Could not sync enough journals to persistent storage \" +\n                 \"due to \" + e.getMessage() + \". \" +\n                 \"Unsynced transactions: \" + (txid - synctxid);\n             LOG.fatal(msg, new Exception());\n             synchronized(journalSetLock) {\n               IOUtils.cleanup(LOG, journalSet);\n             }\n             terminate(1, msg);\n           }\n         } finally {\n           // Prevent RuntimeException from blocking other log edit write \n           doneWithAutoSyncScheduling();\n         }\n         //editLogStream may become null,\n         //so store a local variable for flush.\n         logStream \u003d editLogStream;\n       }\n       \n       // do the sync\n-      long start \u003d now();\n+      long start \u003d monotonicNow();\n       try {\n         if (logStream !\u003d null) {\n           logStream.flush();\n         }\n       } catch (IOException ex) {\n         synchronized (this) {\n           final String msg \u003d\n               \"Could not sync enough journals to persistent storage. \"\n               + \"Unsynced transactions: \" + (txid - synctxid);\n           LOG.fatal(msg, new Exception());\n           synchronized(journalSetLock) {\n             IOUtils.cleanup(LOG, journalSet);\n           }\n           terminate(1, msg);\n         }\n       }\n-      long elapsed \u003d now() - start;\n+      long elapsed \u003d monotonicNow() - start;\n   \n       if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n         metrics.addSync(elapsed);\n       }\n       \n     } finally {\n       // Prevent RuntimeException from blocking other log edit sync \n       synchronized (this) {\n         if (sync) {\n           synctxid \u003d syncStart;\n           isSyncRunning \u003d false;\n         }\n         this.notifyAll();\n      }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void logSync() {\n    long syncStart \u003d 0;\n\n    // Fetch the transactionId of this thread. \n    long mytxid \u003d myTransactionId.get().txid;\n    \n    boolean sync \u003d false;\n    try {\n      EditLogOutputStream logStream \u003d null;\n      synchronized (this) {\n        try {\n          printStatistics(false);\n\n          // if somebody is already syncing, then wait\n          while (mytxid \u003e synctxid \u0026\u0026 isSyncRunning) {\n            try {\n              wait(1000);\n            } catch (InterruptedException ie) {\n            }\n          }\n  \n          //\n          // If this transaction was already flushed, then nothing to do\n          //\n          if (mytxid \u003c\u003d synctxid) {\n            numTransactionsBatchedInSync++;\n            if (metrics !\u003d null) {\n              // Metrics is non-null only when used inside name node\n              metrics.incrTransactionsBatchedInSync();\n            }\n            return;\n          }\n     \n          // now, this thread will do the sync\n          syncStart \u003d txid;\n          isSyncRunning \u003d true;\n          sync \u003d true;\n  \n          // swap buffers\n          try {\n            if (journalSet.isEmpty()) {\n              throw new IOException(\"No journals available to flush\");\n            }\n            editLogStream.setReadyToFlush();\n          } catch (IOException e) {\n            final String msg \u003d\n                \"Could not sync enough journals to persistent storage \" +\n                \"due to \" + e.getMessage() + \". \" +\n                \"Unsynced transactions: \" + (txid - synctxid);\n            LOG.fatal(msg, new Exception());\n            synchronized(journalSetLock) {\n              IOUtils.cleanup(LOG, journalSet);\n            }\n            terminate(1, msg);\n          }\n        } finally {\n          // Prevent RuntimeException from blocking other log edit write \n          doneWithAutoSyncScheduling();\n        }\n        //editLogStream may become null,\n        //so store a local variable for flush.\n        logStream \u003d editLogStream;\n      }\n      \n      // do the sync\n      long start \u003d monotonicNow();\n      try {\n        if (logStream !\u003d null) {\n          logStream.flush();\n        }\n      } catch (IOException ex) {\n        synchronized (this) {\n          final String msg \u003d\n              \"Could not sync enough journals to persistent storage. \"\n              + \"Unsynced transactions: \" + (txid - synctxid);\n          LOG.fatal(msg, new Exception());\n          synchronized(journalSetLock) {\n            IOUtils.cleanup(LOG, journalSet);\n          }\n          terminate(1, msg);\n        }\n      }\n      long elapsed \u003d monotonicNow() - start;\n  \n      if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n        metrics.addSync(elapsed);\n      }\n      \n    } finally {\n      // Prevent RuntimeException from blocking other log edit sync \n      synchronized (this) {\n        if (sync) {\n          synctxid \u003d syncStart;\n          isSyncRunning \u003d false;\n        }\n        this.notifyAll();\n     }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java",
      "extendedDetails": {}
    },
    "faa4455be512e070fa420084be8d1be5c72f3b08": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6634. inotify in HDFS. Contributed by James Thomas.\n",
      "commitDate": "02/09/14 2:02 PM",
      "commitName": "faa4455be512e070fa420084be8d1be5c72f3b08",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "23/07/14 12:05 PM",
      "commitNameOld": "5343b43fd989ec596afed807ddce29ad96c23e2d",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 41.08,
      "commitsBetweenForRepo": 314,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,95 +1,99 @@\n   public void logSync() {\n     long syncStart \u003d 0;\n \n     // Fetch the transactionId of this thread. \n     long mytxid \u003d myTransactionId.get().txid;\n     \n     boolean sync \u003d false;\n     try {\n       EditLogOutputStream logStream \u003d null;\n       synchronized (this) {\n         try {\n           printStatistics(false);\n \n           // if somebody is already syncing, then wait\n           while (mytxid \u003e synctxid \u0026\u0026 isSyncRunning) {\n             try {\n               wait(1000);\n             } catch (InterruptedException ie) {\n             }\n           }\n   \n           //\n           // If this transaction was already flushed, then nothing to do\n           //\n           if (mytxid \u003c\u003d synctxid) {\n             numTransactionsBatchedInSync++;\n             if (metrics !\u003d null) {\n               // Metrics is non-null only when used inside name node\n               metrics.incrTransactionsBatchedInSync();\n             }\n             return;\n           }\n      \n           // now, this thread will do the sync\n           syncStart \u003d txid;\n           isSyncRunning \u003d true;\n           sync \u003d true;\n   \n           // swap buffers\n           try {\n             if (journalSet.isEmpty()) {\n               throw new IOException(\"No journals available to flush\");\n             }\n             editLogStream.setReadyToFlush();\n           } catch (IOException e) {\n             final String msg \u003d\n                 \"Could not sync enough journals to persistent storage \" +\n                 \"due to \" + e.getMessage() + \". \" +\n                 \"Unsynced transactions: \" + (txid - synctxid);\n             LOG.fatal(msg, new Exception());\n-            IOUtils.cleanup(LOG, journalSet);\n+            synchronized(journalSetLock) {\n+              IOUtils.cleanup(LOG, journalSet);\n+            }\n             terminate(1, msg);\n           }\n         } finally {\n           // Prevent RuntimeException from blocking other log edit write \n           doneWithAutoSyncScheduling();\n         }\n         //editLogStream may become null,\n         //so store a local variable for flush.\n         logStream \u003d editLogStream;\n       }\n       \n       // do the sync\n       long start \u003d now();\n       try {\n         if (logStream !\u003d null) {\n           logStream.flush();\n         }\n       } catch (IOException ex) {\n         synchronized (this) {\n           final String msg \u003d\n               \"Could not sync enough journals to persistent storage. \"\n               + \"Unsynced transactions: \" + (txid - synctxid);\n           LOG.fatal(msg, new Exception());\n-          IOUtils.cleanup(LOG, journalSet);\n+          synchronized(journalSetLock) {\n+            IOUtils.cleanup(LOG, journalSet);\n+          }\n           terminate(1, msg);\n         }\n       }\n       long elapsed \u003d now() - start;\n   \n       if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n         metrics.addSync(elapsed);\n       }\n       \n     } finally {\n       // Prevent RuntimeException from blocking other log edit sync \n       synchronized (this) {\n         if (sync) {\n           synctxid \u003d syncStart;\n           isSyncRunning \u003d false;\n         }\n         this.notifyAll();\n      }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void logSync() {\n    long syncStart \u003d 0;\n\n    // Fetch the transactionId of this thread. \n    long mytxid \u003d myTransactionId.get().txid;\n    \n    boolean sync \u003d false;\n    try {\n      EditLogOutputStream logStream \u003d null;\n      synchronized (this) {\n        try {\n          printStatistics(false);\n\n          // if somebody is already syncing, then wait\n          while (mytxid \u003e synctxid \u0026\u0026 isSyncRunning) {\n            try {\n              wait(1000);\n            } catch (InterruptedException ie) {\n            }\n          }\n  \n          //\n          // If this transaction was already flushed, then nothing to do\n          //\n          if (mytxid \u003c\u003d synctxid) {\n            numTransactionsBatchedInSync++;\n            if (metrics !\u003d null) {\n              // Metrics is non-null only when used inside name node\n              metrics.incrTransactionsBatchedInSync();\n            }\n            return;\n          }\n     \n          // now, this thread will do the sync\n          syncStart \u003d txid;\n          isSyncRunning \u003d true;\n          sync \u003d true;\n  \n          // swap buffers\n          try {\n            if (journalSet.isEmpty()) {\n              throw new IOException(\"No journals available to flush\");\n            }\n            editLogStream.setReadyToFlush();\n          } catch (IOException e) {\n            final String msg \u003d\n                \"Could not sync enough journals to persistent storage \" +\n                \"due to \" + e.getMessage() + \". \" +\n                \"Unsynced transactions: \" + (txid - synctxid);\n            LOG.fatal(msg, new Exception());\n            synchronized(journalSetLock) {\n              IOUtils.cleanup(LOG, journalSet);\n            }\n            terminate(1, msg);\n          }\n        } finally {\n          // Prevent RuntimeException from blocking other log edit write \n          doneWithAutoSyncScheduling();\n        }\n        //editLogStream may become null,\n        //so store a local variable for flush.\n        logStream \u003d editLogStream;\n      }\n      \n      // do the sync\n      long start \u003d now();\n      try {\n        if (logStream !\u003d null) {\n          logStream.flush();\n        }\n      } catch (IOException ex) {\n        synchronized (this) {\n          final String msg \u003d\n              \"Could not sync enough journals to persistent storage. \"\n              + \"Unsynced transactions: \" + (txid - synctxid);\n          LOG.fatal(msg, new Exception());\n          synchronized(journalSetLock) {\n            IOUtils.cleanup(LOG, journalSet);\n          }\n          terminate(1, msg);\n        }\n      }\n      long elapsed \u003d now() - start;\n  \n      if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n        metrics.addSync(elapsed);\n      }\n      \n    } finally {\n      // Prevent RuntimeException from blocking other log edit sync \n      synchronized (this) {\n        if (sync) {\n          synctxid \u003d syncStart;\n          isSyncRunning \u003d false;\n        }\n        this.notifyAll();\n     }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java",
      "extendedDetails": {}
    },
    "fd24c6e83357d4d3c937e112328a1eb378327eb0": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4725. Fix HDFS file handle leaks in FSEditLog, NameNode, OfflineEditsBinaryLoader and some tests.  Contributed by Chris Nauroth\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1470771 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "22/04/13 6:18 PM",
      "commitName": "fd24c6e83357d4d3c937e112328a1eb378327eb0",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "08/04/13 4:57 PM",
      "commitNameOld": "19201622be1db8e166d1cc0dd7e62af4702d2784",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 14.06,
      "commitsBetweenForRepo": 76,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,93 +1,95 @@\n   public void logSync() {\n     long syncStart \u003d 0;\n \n     // Fetch the transactionId of this thread. \n     long mytxid \u003d myTransactionId.get().txid;\n     \n     boolean sync \u003d false;\n     try {\n       EditLogOutputStream logStream \u003d null;\n       synchronized (this) {\n         try {\n           printStatistics(false);\n \n           // if somebody is already syncing, then wait\n           while (mytxid \u003e synctxid \u0026\u0026 isSyncRunning) {\n             try {\n               wait(1000);\n             } catch (InterruptedException ie) {\n             }\n           }\n   \n           //\n           // If this transaction was already flushed, then nothing to do\n           //\n           if (mytxid \u003c\u003d synctxid) {\n             numTransactionsBatchedInSync++;\n             if (metrics !\u003d null) {\n               // Metrics is non-null only when used inside name node\n               metrics.incrTransactionsBatchedInSync();\n             }\n             return;\n           }\n      \n           // now, this thread will do the sync\n           syncStart \u003d txid;\n           isSyncRunning \u003d true;\n           sync \u003d true;\n   \n           // swap buffers\n           try {\n             if (journalSet.isEmpty()) {\n               throw new IOException(\"No journals available to flush\");\n             }\n             editLogStream.setReadyToFlush();\n           } catch (IOException e) {\n             final String msg \u003d\n                 \"Could not sync enough journals to persistent storage \" +\n                 \"due to \" + e.getMessage() + \". \" +\n                 \"Unsynced transactions: \" + (txid - synctxid);\n             LOG.fatal(msg, new Exception());\n+            IOUtils.cleanup(LOG, journalSet);\n             terminate(1, msg);\n           }\n         } finally {\n           // Prevent RuntimeException from blocking other log edit write \n           doneWithAutoSyncScheduling();\n         }\n         //editLogStream may become null,\n         //so store a local variable for flush.\n         logStream \u003d editLogStream;\n       }\n       \n       // do the sync\n       long start \u003d now();\n       try {\n         if (logStream !\u003d null) {\n           logStream.flush();\n         }\n       } catch (IOException ex) {\n         synchronized (this) {\n           final String msg \u003d\n               \"Could not sync enough journals to persistent storage. \"\n               + \"Unsynced transactions: \" + (txid - synctxid);\n           LOG.fatal(msg, new Exception());\n+          IOUtils.cleanup(LOG, journalSet);\n           terminate(1, msg);\n         }\n       }\n       long elapsed \u003d now() - start;\n   \n       if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n         metrics.addSync(elapsed);\n       }\n       \n     } finally {\n       // Prevent RuntimeException from blocking other log edit sync \n       synchronized (this) {\n         if (sync) {\n           synctxid \u003d syncStart;\n           isSyncRunning \u003d false;\n         }\n         this.notifyAll();\n      }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void logSync() {\n    long syncStart \u003d 0;\n\n    // Fetch the transactionId of this thread. \n    long mytxid \u003d myTransactionId.get().txid;\n    \n    boolean sync \u003d false;\n    try {\n      EditLogOutputStream logStream \u003d null;\n      synchronized (this) {\n        try {\n          printStatistics(false);\n\n          // if somebody is already syncing, then wait\n          while (mytxid \u003e synctxid \u0026\u0026 isSyncRunning) {\n            try {\n              wait(1000);\n            } catch (InterruptedException ie) {\n            }\n          }\n  \n          //\n          // If this transaction was already flushed, then nothing to do\n          //\n          if (mytxid \u003c\u003d synctxid) {\n            numTransactionsBatchedInSync++;\n            if (metrics !\u003d null) {\n              // Metrics is non-null only when used inside name node\n              metrics.incrTransactionsBatchedInSync();\n            }\n            return;\n          }\n     \n          // now, this thread will do the sync\n          syncStart \u003d txid;\n          isSyncRunning \u003d true;\n          sync \u003d true;\n  \n          // swap buffers\n          try {\n            if (journalSet.isEmpty()) {\n              throw new IOException(\"No journals available to flush\");\n            }\n            editLogStream.setReadyToFlush();\n          } catch (IOException e) {\n            final String msg \u003d\n                \"Could not sync enough journals to persistent storage \" +\n                \"due to \" + e.getMessage() + \". \" +\n                \"Unsynced transactions: \" + (txid - synctxid);\n            LOG.fatal(msg, new Exception());\n            IOUtils.cleanup(LOG, journalSet);\n            terminate(1, msg);\n          }\n        } finally {\n          // Prevent RuntimeException from blocking other log edit write \n          doneWithAutoSyncScheduling();\n        }\n        //editLogStream may become null,\n        //so store a local variable for flush.\n        logStream \u003d editLogStream;\n      }\n      \n      // do the sync\n      long start \u003d now();\n      try {\n        if (logStream !\u003d null) {\n          logStream.flush();\n        }\n      } catch (IOException ex) {\n        synchronized (this) {\n          final String msg \u003d\n              \"Could not sync enough journals to persistent storage. \"\n              + \"Unsynced transactions: \" + (txid - synctxid);\n          LOG.fatal(msg, new Exception());\n          IOUtils.cleanup(LOG, journalSet);\n          terminate(1, msg);\n        }\n      }\n      long elapsed \u003d now() - start;\n  \n      if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n        metrics.addSync(elapsed);\n      }\n      \n    } finally {\n      // Prevent RuntimeException from blocking other log edit sync \n      synchronized (this) {\n        if (sync) {\n          synctxid \u003d syncStart;\n          isSyncRunning \u003d false;\n        }\n        this.notifyAll();\n     }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java",
      "extendedDetails": {}
    },
    "527933f4f351a3df5e369c8bb6e2cfc4937e0836": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3666. Plumb more exception messages to terminate. Contributed by Eli Collins\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1362270 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/07/12 2:26 PM",
      "commitName": "527933f4f351a3df5e369c8bb6e2cfc4937e0836",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "15/07/12 7:58 PM",
      "commitNameOld": "0e8e499ff482c165d21c8e4f5ff9c33f306ca0d9",
      "commitAuthorOld": "Harsh J",
      "daysBetweenCommits": 0.77,
      "commitsBetweenForRepo": 9,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,92 +1,93 @@\n   public void logSync() {\n     long syncStart \u003d 0;\n \n     // Fetch the transactionId of this thread. \n     long mytxid \u003d myTransactionId.get().txid;\n     \n     boolean sync \u003d false;\n     try {\n       EditLogOutputStream logStream \u003d null;\n       synchronized (this) {\n         try {\n           printStatistics(false);\n \n           // if somebody is already syncing, then wait\n           while (mytxid \u003e synctxid \u0026\u0026 isSyncRunning) {\n             try {\n               wait(1000);\n             } catch (InterruptedException ie) {\n             }\n           }\n   \n           //\n           // If this transaction was already flushed, then nothing to do\n           //\n           if (mytxid \u003c\u003d synctxid) {\n             numTransactionsBatchedInSync++;\n             if (metrics !\u003d null) {\n               // Metrics is non-null only when used inside name node\n               metrics.incrTransactionsBatchedInSync();\n             }\n             return;\n           }\n      \n           // now, this thread will do the sync\n           syncStart \u003d txid;\n           isSyncRunning \u003d true;\n           sync \u003d true;\n   \n           // swap buffers\n           try {\n             if (journalSet.isEmpty()) {\n               throw new IOException(\"No journals available to flush\");\n             }\n             editLogStream.setReadyToFlush();\n           } catch (IOException e) {\n             final String msg \u003d\n-                \"Could not sync enough journals to persistent storage. \"\n-                + \"Unsynced transactions: \" + (txid - synctxid);\n+                \"Could not sync enough journals to persistent storage \" +\n+                \"due to \" + e.getMessage() + \". \" +\n+                \"Unsynced transactions: \" + (txid - synctxid);\n             LOG.fatal(msg, new Exception());\n             terminate(1, msg);\n           }\n         } finally {\n           // Prevent RuntimeException from blocking other log edit write \n           doneWithAutoSyncScheduling();\n         }\n         //editLogStream may become null,\n         //so store a local variable for flush.\n         logStream \u003d editLogStream;\n       }\n       \n       // do the sync\n       long start \u003d now();\n       try {\n         if (logStream !\u003d null) {\n           logStream.flush();\n         }\n       } catch (IOException ex) {\n         synchronized (this) {\n           final String msg \u003d\n               \"Could not sync enough journals to persistent storage. \"\n               + \"Unsynced transactions: \" + (txid - synctxid);\n           LOG.fatal(msg, new Exception());\n           terminate(1, msg);\n         }\n       }\n       long elapsed \u003d now() - start;\n   \n       if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n         metrics.addSync(elapsed);\n       }\n       \n     } finally {\n       // Prevent RuntimeException from blocking other log edit sync \n       synchronized (this) {\n         if (sync) {\n           synctxid \u003d syncStart;\n           isSyncRunning \u003d false;\n         }\n         this.notifyAll();\n      }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void logSync() {\n    long syncStart \u003d 0;\n\n    // Fetch the transactionId of this thread. \n    long mytxid \u003d myTransactionId.get().txid;\n    \n    boolean sync \u003d false;\n    try {\n      EditLogOutputStream logStream \u003d null;\n      synchronized (this) {\n        try {\n          printStatistics(false);\n\n          // if somebody is already syncing, then wait\n          while (mytxid \u003e synctxid \u0026\u0026 isSyncRunning) {\n            try {\n              wait(1000);\n            } catch (InterruptedException ie) {\n            }\n          }\n  \n          //\n          // If this transaction was already flushed, then nothing to do\n          //\n          if (mytxid \u003c\u003d synctxid) {\n            numTransactionsBatchedInSync++;\n            if (metrics !\u003d null) {\n              // Metrics is non-null only when used inside name node\n              metrics.incrTransactionsBatchedInSync();\n            }\n            return;\n          }\n     \n          // now, this thread will do the sync\n          syncStart \u003d txid;\n          isSyncRunning \u003d true;\n          sync \u003d true;\n  \n          // swap buffers\n          try {\n            if (journalSet.isEmpty()) {\n              throw new IOException(\"No journals available to flush\");\n            }\n            editLogStream.setReadyToFlush();\n          } catch (IOException e) {\n            final String msg \u003d\n                \"Could not sync enough journals to persistent storage \" +\n                \"due to \" + e.getMessage() + \". \" +\n                \"Unsynced transactions: \" + (txid - synctxid);\n            LOG.fatal(msg, new Exception());\n            terminate(1, msg);\n          }\n        } finally {\n          // Prevent RuntimeException from blocking other log edit write \n          doneWithAutoSyncScheduling();\n        }\n        //editLogStream may become null,\n        //so store a local variable for flush.\n        logStream \u003d editLogStream;\n      }\n      \n      // do the sync\n      long start \u003d now();\n      try {\n        if (logStream !\u003d null) {\n          logStream.flush();\n        }\n      } catch (IOException ex) {\n        synchronized (this) {\n          final String msg \u003d\n              \"Could not sync enough journals to persistent storage. \"\n              + \"Unsynced transactions: \" + (txid - synctxid);\n          LOG.fatal(msg, new Exception());\n          terminate(1, msg);\n        }\n      }\n      long elapsed \u003d now() - start;\n  \n      if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n        metrics.addSync(elapsed);\n      }\n      \n    } finally {\n      // Prevent RuntimeException from blocking other log edit sync \n      synchronized (this) {\n        if (sync) {\n          synctxid \u003d syncStart;\n          isSyncRunning \u003d false;\n        }\n        this.notifyAll();\n     }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java",
      "extendedDetails": {}
    },
    "cdae6953e80e81693bb4c9eb38b62eaba3ac8cf9": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3582. Hook daemon process exit for testing. Contributed by Eli Collins\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1360329 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/07/12 10:58 AM",
      "commitName": "cdae6953e80e81693bb4c9eb38b62eaba3ac8cf9",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "02/07/12 11:21 AM",
      "commitNameOld": "7accbabdee0b7619ff83514c173e815d290b33bf",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 8.98,
      "commitsBetweenForRepo": 61,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,89 +1,92 @@\n   public void logSync() {\n     long syncStart \u003d 0;\n \n     // Fetch the transactionId of this thread. \n     long mytxid \u003d myTransactionId.get().txid;\n     \n     boolean sync \u003d false;\n     try {\n       EditLogOutputStream logStream \u003d null;\n       synchronized (this) {\n         try {\n           printStatistics(false);\n \n           // if somebody is already syncing, then wait\n           while (mytxid \u003e synctxid \u0026\u0026 isSyncRunning) {\n             try {\n               wait(1000);\n             } catch (InterruptedException ie) {\n             }\n           }\n   \n           //\n           // If this transaction was already flushed, then nothing to do\n           //\n           if (mytxid \u003c\u003d synctxid) {\n             numTransactionsBatchedInSync++;\n             if (metrics !\u003d null) {\n               // Metrics is non-null only when used inside name node\n               metrics.incrTransactionsBatchedInSync();\n             }\n             return;\n           }\n      \n           // now, this thread will do the sync\n           syncStart \u003d txid;\n           isSyncRunning \u003d true;\n           sync \u003d true;\n   \n           // swap buffers\n           try {\n             if (journalSet.isEmpty()) {\n               throw new IOException(\"No journals available to flush\");\n             }\n             editLogStream.setReadyToFlush();\n           } catch (IOException e) {\n-            LOG.fatal(\"Could not sync enough journals to persistent storage. \"\n-                + \"Unsynced transactions: \" + (txid - synctxid),\n-                new Exception());\n-            runtime.exit(1);\n+            final String msg \u003d\n+                \"Could not sync enough journals to persistent storage. \"\n+                + \"Unsynced transactions: \" + (txid - synctxid);\n+            LOG.fatal(msg, new Exception());\n+            terminate(1, msg);\n           }\n         } finally {\n           // Prevent RuntimeException from blocking other log edit write \n           doneWithAutoSyncScheduling();\n         }\n         //editLogStream may become null,\n         //so store a local variable for flush.\n         logStream \u003d editLogStream;\n       }\n       \n       // do the sync\n       long start \u003d now();\n       try {\n         if (logStream !\u003d null) {\n           logStream.flush();\n         }\n       } catch (IOException ex) {\n         synchronized (this) {\n-          LOG.fatal(\"Could not sync enough journals to persistent storage. \"\n-              + \"Unsynced transactions: \" + (txid - synctxid), new Exception());\n-          runtime.exit(1);\n+          final String msg \u003d\n+              \"Could not sync enough journals to persistent storage. \"\n+              + \"Unsynced transactions: \" + (txid - synctxid);\n+          LOG.fatal(msg, new Exception());\n+          terminate(1, msg);\n         }\n       }\n       long elapsed \u003d now() - start;\n   \n       if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n         metrics.addSync(elapsed);\n       }\n       \n     } finally {\n       // Prevent RuntimeException from blocking other log edit sync \n       synchronized (this) {\n         if (sync) {\n           synctxid \u003d syncStart;\n           isSyncRunning \u003d false;\n         }\n         this.notifyAll();\n      }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void logSync() {\n    long syncStart \u003d 0;\n\n    // Fetch the transactionId of this thread. \n    long mytxid \u003d myTransactionId.get().txid;\n    \n    boolean sync \u003d false;\n    try {\n      EditLogOutputStream logStream \u003d null;\n      synchronized (this) {\n        try {\n          printStatistics(false);\n\n          // if somebody is already syncing, then wait\n          while (mytxid \u003e synctxid \u0026\u0026 isSyncRunning) {\n            try {\n              wait(1000);\n            } catch (InterruptedException ie) {\n            }\n          }\n  \n          //\n          // If this transaction was already flushed, then nothing to do\n          //\n          if (mytxid \u003c\u003d synctxid) {\n            numTransactionsBatchedInSync++;\n            if (metrics !\u003d null) {\n              // Metrics is non-null only when used inside name node\n              metrics.incrTransactionsBatchedInSync();\n            }\n            return;\n          }\n     \n          // now, this thread will do the sync\n          syncStart \u003d txid;\n          isSyncRunning \u003d true;\n          sync \u003d true;\n  \n          // swap buffers\n          try {\n            if (journalSet.isEmpty()) {\n              throw new IOException(\"No journals available to flush\");\n            }\n            editLogStream.setReadyToFlush();\n          } catch (IOException e) {\n            final String msg \u003d\n                \"Could not sync enough journals to persistent storage. \"\n                + \"Unsynced transactions: \" + (txid - synctxid);\n            LOG.fatal(msg, new Exception());\n            terminate(1, msg);\n          }\n        } finally {\n          // Prevent RuntimeException from blocking other log edit write \n          doneWithAutoSyncScheduling();\n        }\n        //editLogStream may become null,\n        //so store a local variable for flush.\n        logStream \u003d editLogStream;\n      }\n      \n      // do the sync\n      long start \u003d now();\n      try {\n        if (logStream !\u003d null) {\n          logStream.flush();\n        }\n      } catch (IOException ex) {\n        synchronized (this) {\n          final String msg \u003d\n              \"Could not sync enough journals to persistent storage. \"\n              + \"Unsynced transactions: \" + (txid - synctxid);\n          LOG.fatal(msg, new Exception());\n          terminate(1, msg);\n        }\n      }\n      long elapsed \u003d now() - start;\n  \n      if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n        metrics.addSync(elapsed);\n      }\n      \n    } finally {\n      // Prevent RuntimeException from blocking other log edit sync \n      synchronized (this) {\n        if (sync) {\n          synctxid \u003d syncStart;\n          isSyncRunning \u003d false;\n        }\n        this.notifyAll();\n     }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java",
      "extendedDetails": {}
    },
    "a27adf3de4ea88a80401fc7157c5e39747230c2a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2430. The number of failed or low-resource volumes the NN can tolerate should be configurable. Contributed by Aaron T. Myers\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1211650 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/12/11 1:47 PM",
      "commitName": "a27adf3de4ea88a80401fc7157c5e39747230c2a",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "05/12/11 12:10 PM",
      "commitNameOld": "d18e5b38447273b95d975c703df25fe5f679e006",
      "commitAuthorOld": "Jitendra Nath Pandey",
      "daysBetweenCommits": 2.07,
      "commitsBetweenForRepo": 10,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,89 +1,89 @@\n   public void logSync() {\n     long syncStart \u003d 0;\n \n     // Fetch the transactionId of this thread. \n     long mytxid \u003d myTransactionId.get().txid;\n     \n     boolean sync \u003d false;\n     try {\n       EditLogOutputStream logStream \u003d null;\n       synchronized (this) {\n         try {\n           printStatistics(false);\n \n           // if somebody is already syncing, then wait\n           while (mytxid \u003e synctxid \u0026\u0026 isSyncRunning) {\n             try {\n               wait(1000);\n             } catch (InterruptedException ie) {\n             }\n           }\n   \n           //\n           // If this transaction was already flushed, then nothing to do\n           //\n           if (mytxid \u003c\u003d synctxid) {\n             numTransactionsBatchedInSync++;\n             if (metrics !\u003d null) {\n               // Metrics is non-null only when used inside name node\n               metrics.incrTransactionsBatchedInSync();\n             }\n             return;\n           }\n      \n           // now, this thread will do the sync\n           syncStart \u003d txid;\n           isSyncRunning \u003d true;\n           sync \u003d true;\n   \n           // swap buffers\n           try {\n             if (journalSet.isEmpty()) {\n               throw new IOException(\"No journals available to flush\");\n             }\n             editLogStream.setReadyToFlush();\n           } catch (IOException e) {\n-            LOG.fatal(\"Could not sync any journal to persistent storage. \"\n+            LOG.fatal(\"Could not sync enough journals to persistent storage. \"\n                 + \"Unsynced transactions: \" + (txid - synctxid),\n                 new Exception());\n             runtime.exit(1);\n           }\n         } finally {\n           // Prevent RuntimeException from blocking other log edit write \n           doneWithAutoSyncScheduling();\n         }\n         //editLogStream may become null,\n         //so store a local variable for flush.\n         logStream \u003d editLogStream;\n       }\n       \n       // do the sync\n       long start \u003d now();\n       try {\n         if (logStream !\u003d null) {\n           logStream.flush();\n         }\n       } catch (IOException ex) {\n         synchronized (this) {\n-          LOG.fatal(\"Could not sync any journal to persistent storage. \"\n+          LOG.fatal(\"Could not sync enough journals to persistent storage. \"\n               + \"Unsynced transactions: \" + (txid - synctxid), new Exception());\n           runtime.exit(1);\n         }\n       }\n       long elapsed \u003d now() - start;\n   \n       if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n         metrics.addSync(elapsed);\n       }\n       \n     } finally {\n       // Prevent RuntimeException from blocking other log edit sync \n       synchronized (this) {\n         if (sync) {\n           synctxid \u003d syncStart;\n           isSyncRunning \u003d false;\n         }\n         this.notifyAll();\n      }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void logSync() {\n    long syncStart \u003d 0;\n\n    // Fetch the transactionId of this thread. \n    long mytxid \u003d myTransactionId.get().txid;\n    \n    boolean sync \u003d false;\n    try {\n      EditLogOutputStream logStream \u003d null;\n      synchronized (this) {\n        try {\n          printStatistics(false);\n\n          // if somebody is already syncing, then wait\n          while (mytxid \u003e synctxid \u0026\u0026 isSyncRunning) {\n            try {\n              wait(1000);\n            } catch (InterruptedException ie) {\n            }\n          }\n  \n          //\n          // If this transaction was already flushed, then nothing to do\n          //\n          if (mytxid \u003c\u003d synctxid) {\n            numTransactionsBatchedInSync++;\n            if (metrics !\u003d null) {\n              // Metrics is non-null only when used inside name node\n              metrics.incrTransactionsBatchedInSync();\n            }\n            return;\n          }\n     \n          // now, this thread will do the sync\n          syncStart \u003d txid;\n          isSyncRunning \u003d true;\n          sync \u003d true;\n  \n          // swap buffers\n          try {\n            if (journalSet.isEmpty()) {\n              throw new IOException(\"No journals available to flush\");\n            }\n            editLogStream.setReadyToFlush();\n          } catch (IOException e) {\n            LOG.fatal(\"Could not sync enough journals to persistent storage. \"\n                + \"Unsynced transactions: \" + (txid - synctxid),\n                new Exception());\n            runtime.exit(1);\n          }\n        } finally {\n          // Prevent RuntimeException from blocking other log edit write \n          doneWithAutoSyncScheduling();\n        }\n        //editLogStream may become null,\n        //so store a local variable for flush.\n        logStream \u003d editLogStream;\n      }\n      \n      // do the sync\n      long start \u003d now();\n      try {\n        if (logStream !\u003d null) {\n          logStream.flush();\n        }\n      } catch (IOException ex) {\n        synchronized (this) {\n          LOG.fatal(\"Could not sync enough journals to persistent storage. \"\n              + \"Unsynced transactions: \" + (txid - synctxid), new Exception());\n          runtime.exit(1);\n        }\n      }\n      long elapsed \u003d now() - start;\n  \n      if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n        metrics.addSync(elapsed);\n      }\n      \n    } finally {\n      // Prevent RuntimeException from blocking other log edit sync \n      synchronized (this) {\n        if (sync) {\n          synctxid \u003d syncStart;\n          isSyncRunning \u003d false;\n        }\n        this.notifyAll();\n     }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java",
      "extendedDetails": {}
    },
    "1ae5b5e338ef383c5642e2f04b927871c7b184f6": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2158. Add JournalSet to manage the set of journals.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1177473 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "29/09/11 6:14 PM",
      "commitName": "1ae5b5e338ef383c5642e2f04b927871c7b184f6",
      "commitAuthor": "Jitendra Nath Pandey",
      "commitDateOld": "06/09/11 1:27 PM",
      "commitNameOld": "bdc3720d5b67a1c8fc2dfb29be16e4155c0e7f15",
      "commitAuthorOld": "Jitendra Nath Pandey",
      "daysBetweenCommits": 23.2,
      "commitsBetweenForRepo": 169,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,97 +1,89 @@\n   public void logSync() {\n     long syncStart \u003d 0;\n \n     // Fetch the transactionId of this thread. \n     long mytxid \u003d myTransactionId.get().txid;\n     \n-    List\u003cJournalAndStream\u003e candidateJournals \u003d\n-      Lists.newArrayListWithCapacity(journals.size());\n-    List\u003cJournalAndStream\u003e badJournals \u003d Lists.newArrayList();\n-    \n     boolean sync \u003d false;\n     try {\n+      EditLogOutputStream logStream \u003d null;\n       synchronized (this) {\n         try {\n-        printStatistics(false);\n-  \n-        // if somebody is already syncing, then wait\n-        while (mytxid \u003e synctxid \u0026\u0026 isSyncRunning) {\n-          try {\n-            wait(1000);\n-          } catch (InterruptedException ie) { \n+          printStatistics(false);\n+\n+          // if somebody is already syncing, then wait\n+          while (mytxid \u003e synctxid \u0026\u0026 isSyncRunning) {\n+            try {\n+              wait(1000);\n+            } catch (InterruptedException ie) {\n+            }\n           }\n-        }\n   \n-        //\n-        // If this transaction was already flushed, then nothing to do\n-        //\n-        if (mytxid \u003c\u003d synctxid) {\n-          numTransactionsBatchedInSync++;\n-          if (metrics !\u003d null) // Metrics is non-null only when used inside name node\n-            metrics.incrTransactionsBatchedInSync();\n-          return;\n-        }\n+          //\n+          // If this transaction was already flushed, then nothing to do\n+          //\n+          if (mytxid \u003c\u003d synctxid) {\n+            numTransactionsBatchedInSync++;\n+            if (metrics !\u003d null) {\n+              // Metrics is non-null only when used inside name node\n+              metrics.incrTransactionsBatchedInSync();\n+            }\n+            return;\n+          }\n      \n-        // now, this thread will do the sync\n-        syncStart \u003d txid;\n-        isSyncRunning \u003d true;\n-        sync \u003d true;\n+          // now, this thread will do the sync\n+          syncStart \u003d txid;\n+          isSyncRunning \u003d true;\n+          sync \u003d true;\n   \n-        // swap buffers\n-        assert !journals.isEmpty() : \"no editlog streams\";\n-        \n-        for (JournalAndStream jas : journals) {\n-          if (!jas.isActive()) continue;\n+          // swap buffers\n           try {\n-            jas.getCurrentStream().setReadyToFlush();\n-            candidateJournals.add(jas);\n-          } catch (IOException ie) {\n-            LOG.error(\"Unable to get ready to flush.\", ie);\n-            badJournals.add(jas);\n+            if (journalSet.isEmpty()) {\n+              throw new IOException(\"No journals available to flush\");\n+            }\n+            editLogStream.setReadyToFlush();\n+          } catch (IOException e) {\n+            LOG.fatal(\"Could not sync any journal to persistent storage. \"\n+                + \"Unsynced transactions: \" + (txid - synctxid),\n+                new Exception());\n+            runtime.exit(1);\n           }\n-        }\n         } finally {\n           // Prevent RuntimeException from blocking other log edit write \n           doneWithAutoSyncScheduling();\n         }\n+        //editLogStream may become null,\n+        //so store a local variable for flush.\n+        logStream \u003d editLogStream;\n       }\n-  \n+      \n       // do the sync\n       long start \u003d now();\n-      for (JournalAndStream jas : candidateJournals) {\n-        if (!jas.isActive()) continue;\n-        try {\n-          jas.getCurrentStream().flush();\n-        } catch (IOException ie) {\n-          LOG.error(\"Unable to sync edit log.\", ie);\n-          //\n-          // remember the streams that encountered an error.\n-          //\n-          badJournals.add(jas);\n+      try {\n+        if (logStream !\u003d null) {\n+          logStream.flush();\n+        }\n+      } catch (IOException ex) {\n+        synchronized (this) {\n+          LOG.fatal(\"Could not sync any journal to persistent storage. \"\n+              + \"Unsynced transactions: \" + (txid - synctxid), new Exception());\n+          runtime.exit(1);\n         }\n       }\n       long elapsed \u003d now() - start;\n-      disableAndReportErrorOnJournals(badJournals);\n   \n       if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n         metrics.addSync(elapsed);\n       }\n       \n     } finally {\n       // Prevent RuntimeException from blocking other log edit sync \n       synchronized (this) {\n         if (sync) {\n-          if (badJournals.size() \u003e\u003d journals.size()) {\n-            LOG.fatal(\"Could not sync any journal to persistent storage. \" +\n-                \"Unsynced transactions: \" + (txid - synctxid),\n-                new Exception());\n-            runtime.exit(1);\n-          }\n-\n           synctxid \u003d syncStart;\n           isSyncRunning \u003d false;\n         }\n         this.notifyAll();\n      }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void logSync() {\n    long syncStart \u003d 0;\n\n    // Fetch the transactionId of this thread. \n    long mytxid \u003d myTransactionId.get().txid;\n    \n    boolean sync \u003d false;\n    try {\n      EditLogOutputStream logStream \u003d null;\n      synchronized (this) {\n        try {\n          printStatistics(false);\n\n          // if somebody is already syncing, then wait\n          while (mytxid \u003e synctxid \u0026\u0026 isSyncRunning) {\n            try {\n              wait(1000);\n            } catch (InterruptedException ie) {\n            }\n          }\n  \n          //\n          // If this transaction was already flushed, then nothing to do\n          //\n          if (mytxid \u003c\u003d synctxid) {\n            numTransactionsBatchedInSync++;\n            if (metrics !\u003d null) {\n              // Metrics is non-null only when used inside name node\n              metrics.incrTransactionsBatchedInSync();\n            }\n            return;\n          }\n     \n          // now, this thread will do the sync\n          syncStart \u003d txid;\n          isSyncRunning \u003d true;\n          sync \u003d true;\n  \n          // swap buffers\n          try {\n            if (journalSet.isEmpty()) {\n              throw new IOException(\"No journals available to flush\");\n            }\n            editLogStream.setReadyToFlush();\n          } catch (IOException e) {\n            LOG.fatal(\"Could not sync any journal to persistent storage. \"\n                + \"Unsynced transactions: \" + (txid - synctxid),\n                new Exception());\n            runtime.exit(1);\n          }\n        } finally {\n          // Prevent RuntimeException from blocking other log edit write \n          doneWithAutoSyncScheduling();\n        }\n        //editLogStream may become null,\n        //so store a local variable for flush.\n        logStream \u003d editLogStream;\n      }\n      \n      // do the sync\n      long start \u003d now();\n      try {\n        if (logStream !\u003d null) {\n          logStream.flush();\n        }\n      } catch (IOException ex) {\n        synchronized (this) {\n          LOG.fatal(\"Could not sync any journal to persistent storage. \"\n              + \"Unsynced transactions: \" + (txid - synctxid), new Exception());\n          runtime.exit(1);\n        }\n      }\n      long elapsed \u003d now() - start;\n  \n      if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n        metrics.addSync(elapsed);\n      }\n      \n    } finally {\n      // Prevent RuntimeException from blocking other log edit sync \n      synchronized (this) {\n        if (sync) {\n          synctxid \u003d syncStart;\n          isSyncRunning \u003d false;\n        }\n        this.notifyAll();\n     }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void logSync() {\n    long syncStart \u003d 0;\n\n    // Fetch the transactionId of this thread. \n    long mytxid \u003d myTransactionId.get().txid;\n    \n    List\u003cJournalAndStream\u003e candidateJournals \u003d\n      Lists.newArrayListWithCapacity(journals.size());\n    List\u003cJournalAndStream\u003e badJournals \u003d Lists.newArrayList();\n    \n    boolean sync \u003d false;\n    try {\n      synchronized (this) {\n        try {\n        printStatistics(false);\n  \n        // if somebody is already syncing, then wait\n        while (mytxid \u003e synctxid \u0026\u0026 isSyncRunning) {\n          try {\n            wait(1000);\n          } catch (InterruptedException ie) { \n          }\n        }\n  \n        //\n        // If this transaction was already flushed, then nothing to do\n        //\n        if (mytxid \u003c\u003d synctxid) {\n          numTransactionsBatchedInSync++;\n          if (metrics !\u003d null) // Metrics is non-null only when used inside name node\n            metrics.incrTransactionsBatchedInSync();\n          return;\n        }\n     \n        // now, this thread will do the sync\n        syncStart \u003d txid;\n        isSyncRunning \u003d true;\n        sync \u003d true;\n  \n        // swap buffers\n        assert !journals.isEmpty() : \"no editlog streams\";\n        \n        for (JournalAndStream jas : journals) {\n          if (!jas.isActive()) continue;\n          try {\n            jas.getCurrentStream().setReadyToFlush();\n            candidateJournals.add(jas);\n          } catch (IOException ie) {\n            LOG.error(\"Unable to get ready to flush.\", ie);\n            badJournals.add(jas);\n          }\n        }\n        } finally {\n          // Prevent RuntimeException from blocking other log edit write \n          doneWithAutoSyncScheduling();\n        }\n      }\n  \n      // do the sync\n      long start \u003d now();\n      for (JournalAndStream jas : candidateJournals) {\n        if (!jas.isActive()) continue;\n        try {\n          jas.getCurrentStream().flush();\n        } catch (IOException ie) {\n          LOG.error(\"Unable to sync edit log.\", ie);\n          //\n          // remember the streams that encountered an error.\n          //\n          badJournals.add(jas);\n        }\n      }\n      long elapsed \u003d now() - start;\n      disableAndReportErrorOnJournals(badJournals);\n  \n      if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n        metrics.addSync(elapsed);\n      }\n      \n    } finally {\n      // Prevent RuntimeException from blocking other log edit sync \n      synchronized (this) {\n        if (sync) {\n          if (badJournals.size() \u003e\u003d journals.size()) {\n            LOG.fatal(\"Could not sync any journal to persistent storage. \" +\n                \"Unsynced transactions: \" + (txid - synctxid),\n                new Exception());\n            runtime.exit(1);\n          }\n\n          synctxid \u003d syncStart;\n          isSyncRunning \u003d false;\n        }\n        this.notifyAll();\n     }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void logSync() {\n    long syncStart \u003d 0;\n\n    // Fetch the transactionId of this thread. \n    long mytxid \u003d myTransactionId.get().txid;\n    \n    List\u003cJournalAndStream\u003e candidateJournals \u003d\n      Lists.newArrayListWithCapacity(journals.size());\n    List\u003cJournalAndStream\u003e badJournals \u003d Lists.newArrayList();\n    \n    boolean sync \u003d false;\n    try {\n      synchronized (this) {\n        try {\n        printStatistics(false);\n  \n        // if somebody is already syncing, then wait\n        while (mytxid \u003e synctxid \u0026\u0026 isSyncRunning) {\n          try {\n            wait(1000);\n          } catch (InterruptedException ie) { \n          }\n        }\n  \n        //\n        // If this transaction was already flushed, then nothing to do\n        //\n        if (mytxid \u003c\u003d synctxid) {\n          numTransactionsBatchedInSync++;\n          if (metrics !\u003d null) // Metrics is non-null only when used inside name node\n            metrics.incrTransactionsBatchedInSync();\n          return;\n        }\n     \n        // now, this thread will do the sync\n        syncStart \u003d txid;\n        isSyncRunning \u003d true;\n        sync \u003d true;\n  \n        // swap buffers\n        assert !journals.isEmpty() : \"no editlog streams\";\n        \n        for (JournalAndStream jas : journals) {\n          if (!jas.isActive()) continue;\n          try {\n            jas.getCurrentStream().setReadyToFlush();\n            candidateJournals.add(jas);\n          } catch (IOException ie) {\n            LOG.error(\"Unable to get ready to flush.\", ie);\n            badJournals.add(jas);\n          }\n        }\n        } finally {\n          // Prevent RuntimeException from blocking other log edit write \n          doneWithAutoSyncScheduling();\n        }\n      }\n  \n      // do the sync\n      long start \u003d now();\n      for (JournalAndStream jas : candidateJournals) {\n        if (!jas.isActive()) continue;\n        try {\n          jas.getCurrentStream().flush();\n        } catch (IOException ie) {\n          LOG.error(\"Unable to sync edit log.\", ie);\n          //\n          // remember the streams that encountered an error.\n          //\n          badJournals.add(jas);\n        }\n      }\n      long elapsed \u003d now() - start;\n      disableAndReportErrorOnJournals(badJournals);\n  \n      if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n        metrics.addSync(elapsed);\n      }\n      \n    } finally {\n      // Prevent RuntimeException from blocking other log edit sync \n      synchronized (this) {\n        if (sync) {\n          if (badJournals.size() \u003e\u003d journals.size()) {\n            LOG.fatal(\"Could not sync any journal to persistent storage. \" +\n                \"Unsynced transactions: \" + (txid - synctxid),\n                new Exception());\n            runtime.exit(1);\n          }\n\n          synctxid \u003d syncStart;\n          isSyncRunning \u003d false;\n        }\n        this.notifyAll();\n     }\n    }\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java"
      }
    },
    "28e6a4e44a3e920dcaf858f9a74a6358226b3a63": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-1073. Redesign the NameNode\u0027s storage layout for image checkpoints and edit logs to introduce transaction IDs and be more robust. Contributed by Todd Lipcon and Ivan Kelly.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1152295 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "29/07/11 9:28 AM",
      "commitName": "28e6a4e44a3e920dcaf858f9a74a6358226b3a63",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "26/07/11 1:46 PM",
      "commitNameOld": "438c32aaf9fb0c63f55044cf5ef1b2e0adcf7fea",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 2.82,
      "commitsBetweenForRepo": 17,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,91 +1,97 @@\n   public void logSync() {\n-    ArrayList\u003cEditLogOutputStream\u003e errorStreams \u003d null;\n     long syncStart \u003d 0;\n \n     // Fetch the transactionId of this thread. \n     long mytxid \u003d myTransactionId.get().txid;\n-    ArrayList\u003cEditLogOutputStream\u003e streams \u003d new ArrayList\u003cEditLogOutputStream\u003e();\n+    \n+    List\u003cJournalAndStream\u003e candidateJournals \u003d\n+      Lists.newArrayListWithCapacity(journals.size());\n+    List\u003cJournalAndStream\u003e badJournals \u003d Lists.newArrayList();\n+    \n     boolean sync \u003d false;\n     try {\n       synchronized (this) {\n         try {\n         printStatistics(false);\n   \n         // if somebody is already syncing, then wait\n         while (mytxid \u003e synctxid \u0026\u0026 isSyncRunning) {\n           try {\n             wait(1000);\n           } catch (InterruptedException ie) { \n           }\n         }\n   \n         //\n         // If this transaction was already flushed, then nothing to do\n         //\n         if (mytxid \u003c\u003d synctxid) {\n           numTransactionsBatchedInSync++;\n           if (metrics !\u003d null) // Metrics is non-null only when used inside name node\n             metrics.incrTransactionsBatchedInSync();\n           return;\n         }\n      \n         // now, this thread will do the sync\n         syncStart \u003d txid;\n         isSyncRunning \u003d true;\n         sync \u003d true;\n   \n         // swap buffers\n-        assert editStreams.size() \u003e 0 : \"no editlog streams\";\n-        for(EditLogOutputStream eStream : editStreams) {\n+        assert !journals.isEmpty() : \"no editlog streams\";\n+        \n+        for (JournalAndStream jas : journals) {\n+          if (!jas.isActive()) continue;\n           try {\n-            eStream.setReadyToFlush();\n-            streams.add(eStream);\n+            jas.getCurrentStream().setReadyToFlush();\n+            candidateJournals.add(jas);\n           } catch (IOException ie) {\n             LOG.error(\"Unable to get ready to flush.\", ie);\n-            //\n-            // remember the streams that encountered an error.\n-            //\n-            if (errorStreams \u003d\u003d null) {\n-              errorStreams \u003d new ArrayList\u003cEditLogOutputStream\u003e(1);\n-            }\n-            errorStreams.add(eStream);\n+            badJournals.add(jas);\n           }\n         }\n         } finally {\n           // Prevent RuntimeException from blocking other log edit write \n           doneWithAutoSyncScheduling();\n         }\n       }\n   \n       // do the sync\n       long start \u003d now();\n-      for (EditLogOutputStream eStream : streams) {\n+      for (JournalAndStream jas : candidateJournals) {\n+        if (!jas.isActive()) continue;\n         try {\n-          eStream.flush();\n+          jas.getCurrentStream().flush();\n         } catch (IOException ie) {\n           LOG.error(\"Unable to sync edit log.\", ie);\n           //\n           // remember the streams that encountered an error.\n           //\n-          if (errorStreams \u003d\u003d null) {\n-            errorStreams \u003d new ArrayList\u003cEditLogOutputStream\u003e(1);\n-          }\n-          errorStreams.add(eStream);\n+          badJournals.add(jas);\n         }\n       }\n       long elapsed \u003d now() - start;\n-      disableAndReportErrorOnStreams(errorStreams);\n+      disableAndReportErrorOnJournals(badJournals);\n   \n-      if (metrics !\u003d null) // Metrics non-null only when used inside name node\n+      if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n         metrics.addSync(elapsed);\n+      }\n+      \n     } finally {\n       // Prevent RuntimeException from blocking other log edit sync \n       synchronized (this) {\n         if (sync) {\n+          if (badJournals.size() \u003e\u003d journals.size()) {\n+            LOG.fatal(\"Could not sync any journal to persistent storage. \" +\n+                \"Unsynced transactions: \" + (txid - synctxid),\n+                new Exception());\n+            runtime.exit(1);\n+          }\n+\n           synctxid \u003d syncStart;\n           isSyncRunning \u003d false;\n         }\n         this.notifyAll();\n      }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void logSync() {\n    long syncStart \u003d 0;\n\n    // Fetch the transactionId of this thread. \n    long mytxid \u003d myTransactionId.get().txid;\n    \n    List\u003cJournalAndStream\u003e candidateJournals \u003d\n      Lists.newArrayListWithCapacity(journals.size());\n    List\u003cJournalAndStream\u003e badJournals \u003d Lists.newArrayList();\n    \n    boolean sync \u003d false;\n    try {\n      synchronized (this) {\n        try {\n        printStatistics(false);\n  \n        // if somebody is already syncing, then wait\n        while (mytxid \u003e synctxid \u0026\u0026 isSyncRunning) {\n          try {\n            wait(1000);\n          } catch (InterruptedException ie) { \n          }\n        }\n  \n        //\n        // If this transaction was already flushed, then nothing to do\n        //\n        if (mytxid \u003c\u003d synctxid) {\n          numTransactionsBatchedInSync++;\n          if (metrics !\u003d null) // Metrics is non-null only when used inside name node\n            metrics.incrTransactionsBatchedInSync();\n          return;\n        }\n     \n        // now, this thread will do the sync\n        syncStart \u003d txid;\n        isSyncRunning \u003d true;\n        sync \u003d true;\n  \n        // swap buffers\n        assert !journals.isEmpty() : \"no editlog streams\";\n        \n        for (JournalAndStream jas : journals) {\n          if (!jas.isActive()) continue;\n          try {\n            jas.getCurrentStream().setReadyToFlush();\n            candidateJournals.add(jas);\n          } catch (IOException ie) {\n            LOG.error(\"Unable to get ready to flush.\", ie);\n            badJournals.add(jas);\n          }\n        }\n        } finally {\n          // Prevent RuntimeException from blocking other log edit write \n          doneWithAutoSyncScheduling();\n        }\n      }\n  \n      // do the sync\n      long start \u003d now();\n      for (JournalAndStream jas : candidateJournals) {\n        if (!jas.isActive()) continue;\n        try {\n          jas.getCurrentStream().flush();\n        } catch (IOException ie) {\n          LOG.error(\"Unable to sync edit log.\", ie);\n          //\n          // remember the streams that encountered an error.\n          //\n          badJournals.add(jas);\n        }\n      }\n      long elapsed \u003d now() - start;\n      disableAndReportErrorOnJournals(badJournals);\n  \n      if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n        metrics.addSync(elapsed);\n      }\n      \n    } finally {\n      // Prevent RuntimeException from blocking other log edit sync \n      synchronized (this) {\n        if (sync) {\n          if (badJournals.size() \u003e\u003d journals.size()) {\n            LOG.fatal(\"Could not sync any journal to persistent storage. \" +\n                \"Unsynced transactions: \" + (txid - synctxid),\n                new Exception());\n            runtime.exit(1);\n          }\n\n          synctxid \u003d syncStart;\n          isSyncRunning \u003d false;\n        }\n        this.notifyAll();\n     }\n    }\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java",
      "extendedDetails": {}
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,91 @@\n+  public void logSync() {\n+    ArrayList\u003cEditLogOutputStream\u003e errorStreams \u003d null;\n+    long syncStart \u003d 0;\n+\n+    // Fetch the transactionId of this thread. \n+    long mytxid \u003d myTransactionId.get().txid;\n+    ArrayList\u003cEditLogOutputStream\u003e streams \u003d new ArrayList\u003cEditLogOutputStream\u003e();\n+    boolean sync \u003d false;\n+    try {\n+      synchronized (this) {\n+        try {\n+        printStatistics(false);\n+  \n+        // if somebody is already syncing, then wait\n+        while (mytxid \u003e synctxid \u0026\u0026 isSyncRunning) {\n+          try {\n+            wait(1000);\n+          } catch (InterruptedException ie) { \n+          }\n+        }\n+  \n+        //\n+        // If this transaction was already flushed, then nothing to do\n+        //\n+        if (mytxid \u003c\u003d synctxid) {\n+          numTransactionsBatchedInSync++;\n+          if (metrics !\u003d null) // Metrics is non-null only when used inside name node\n+            metrics.incrTransactionsBatchedInSync();\n+          return;\n+        }\n+     \n+        // now, this thread will do the sync\n+        syncStart \u003d txid;\n+        isSyncRunning \u003d true;\n+        sync \u003d true;\n+  \n+        // swap buffers\n+        assert editStreams.size() \u003e 0 : \"no editlog streams\";\n+        for(EditLogOutputStream eStream : editStreams) {\n+          try {\n+            eStream.setReadyToFlush();\n+            streams.add(eStream);\n+          } catch (IOException ie) {\n+            LOG.error(\"Unable to get ready to flush.\", ie);\n+            //\n+            // remember the streams that encountered an error.\n+            //\n+            if (errorStreams \u003d\u003d null) {\n+              errorStreams \u003d new ArrayList\u003cEditLogOutputStream\u003e(1);\n+            }\n+            errorStreams.add(eStream);\n+          }\n+        }\n+        } finally {\n+          // Prevent RuntimeException from blocking other log edit write \n+          doneWithAutoSyncScheduling();\n+        }\n+      }\n+  \n+      // do the sync\n+      long start \u003d now();\n+      for (EditLogOutputStream eStream : streams) {\n+        try {\n+          eStream.flush();\n+        } catch (IOException ie) {\n+          LOG.error(\"Unable to sync edit log.\", ie);\n+          //\n+          // remember the streams that encountered an error.\n+          //\n+          if (errorStreams \u003d\u003d null) {\n+            errorStreams \u003d new ArrayList\u003cEditLogOutputStream\u003e(1);\n+          }\n+          errorStreams.add(eStream);\n+        }\n+      }\n+      long elapsed \u003d now() - start;\n+      disableAndReportErrorOnStreams(errorStreams);\n+  \n+      if (metrics !\u003d null) // Metrics non-null only when used inside name node\n+        metrics.addSync(elapsed);\n+    } finally {\n+      // Prevent RuntimeException from blocking other log edit sync \n+      synchronized (this) {\n+        if (sync) {\n+          synctxid \u003d syncStart;\n+          isSyncRunning \u003d false;\n+        }\n+        this.notifyAll();\n+     }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void logSync() {\n    ArrayList\u003cEditLogOutputStream\u003e errorStreams \u003d null;\n    long syncStart \u003d 0;\n\n    // Fetch the transactionId of this thread. \n    long mytxid \u003d myTransactionId.get().txid;\n    ArrayList\u003cEditLogOutputStream\u003e streams \u003d new ArrayList\u003cEditLogOutputStream\u003e();\n    boolean sync \u003d false;\n    try {\n      synchronized (this) {\n        try {\n        printStatistics(false);\n  \n        // if somebody is already syncing, then wait\n        while (mytxid \u003e synctxid \u0026\u0026 isSyncRunning) {\n          try {\n            wait(1000);\n          } catch (InterruptedException ie) { \n          }\n        }\n  \n        //\n        // If this transaction was already flushed, then nothing to do\n        //\n        if (mytxid \u003c\u003d synctxid) {\n          numTransactionsBatchedInSync++;\n          if (metrics !\u003d null) // Metrics is non-null only when used inside name node\n            metrics.incrTransactionsBatchedInSync();\n          return;\n        }\n     \n        // now, this thread will do the sync\n        syncStart \u003d txid;\n        isSyncRunning \u003d true;\n        sync \u003d true;\n  \n        // swap buffers\n        assert editStreams.size() \u003e 0 : \"no editlog streams\";\n        for(EditLogOutputStream eStream : editStreams) {\n          try {\n            eStream.setReadyToFlush();\n            streams.add(eStream);\n          } catch (IOException ie) {\n            LOG.error(\"Unable to get ready to flush.\", ie);\n            //\n            // remember the streams that encountered an error.\n            //\n            if (errorStreams \u003d\u003d null) {\n              errorStreams \u003d new ArrayList\u003cEditLogOutputStream\u003e(1);\n            }\n            errorStreams.add(eStream);\n          }\n        }\n        } finally {\n          // Prevent RuntimeException from blocking other log edit write \n          doneWithAutoSyncScheduling();\n        }\n      }\n  \n      // do the sync\n      long start \u003d now();\n      for (EditLogOutputStream eStream : streams) {\n        try {\n          eStream.flush();\n        } catch (IOException ie) {\n          LOG.error(\"Unable to sync edit log.\", ie);\n          //\n          // remember the streams that encountered an error.\n          //\n          if (errorStreams \u003d\u003d null) {\n            errorStreams \u003d new ArrayList\u003cEditLogOutputStream\u003e(1);\n          }\n          errorStreams.add(eStream);\n        }\n      }\n      long elapsed \u003d now() - start;\n      disableAndReportErrorOnStreams(errorStreams);\n  \n      if (metrics !\u003d null) // Metrics non-null only when used inside name node\n        metrics.addSync(elapsed);\n    } finally {\n      // Prevent RuntimeException from blocking other log edit sync \n      synchronized (this) {\n        if (sync) {\n          synctxid \u003d syncStart;\n          isSyncRunning \u003d false;\n        }\n        this.notifyAll();\n     }\n    }\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java"
    }
  }
}