{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FsDatasetImpl.java",
  "functionName": "addVolume",
  "functionId": "addVolume___sd-Storage.StorageDirectory",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
  "functionStartLine": 464,
  "functionEndLine": 484,
  "numCommitsSeen": 362,
  "timeTaken": 10819,
  "changeHistory": [
    "d7c136b9ed6d99e1b03f5b89723b3a20df359ba8",
    "02e2a9b1152b0e144fcf43bec2fce26d8a6c6dbc",
    "6ba9587d370fbf39c129c08c00ebbb894ccc1389",
    "96b12662ea76e3ded4ef13944fc8df206cfb4613",
    "8ae4729107d33c6001cf1fdc8837afb71ea6c0d3",
    "04375756a5ed6e907ee7548469c2c508aebbafb7",
    "6e62a1a6728b1f782f64065424f92b292c3f163a",
    "a9331fe9b071fdcdae0c6c747d7b6b306142e671",
    "bb84f1fccb18c6c7373851e05d2451d55e908242",
    "b2d5ed36bcb80e2581191dcdc3976e825c959142",
    "fe38d2e9b5ac7e13f97cd2d3d2a984ab6bbaaf77",
    "c92837aeab5188f6171d4016f91b3b4936a66beb",
    "a317bd7b02c37bd57743bfad59593ec12f53f4ed",
    "d758be1f35f6c1c7e9edd491af559721a3b8b8f8"
  ],
  "changeHistoryShort": {
    "d7c136b9ed6d99e1b03f5b89723b3a20df359ba8": "Ybodychange",
    "02e2a9b1152b0e144fcf43bec2fce26d8a6c6dbc": "Yparameterchange",
    "6ba9587d370fbf39c129c08c00ebbb894ccc1389": "Ybodychange",
    "96b12662ea76e3ded4ef13944fc8df206cfb4613": "Ybodychange",
    "8ae4729107d33c6001cf1fdc8837afb71ea6c0d3": "Ybodychange",
    "04375756a5ed6e907ee7548469c2c508aebbafb7": "Ybodychange",
    "6e62a1a6728b1f782f64065424f92b292c3f163a": "Ybodychange",
    "a9331fe9b071fdcdae0c6c747d7b6b306142e671": "Ybodychange",
    "bb84f1fccb18c6c7373851e05d2451d55e908242": "Ybodychange",
    "b2d5ed36bcb80e2581191dcdc3976e825c959142": "Ybodychange",
    "fe38d2e9b5ac7e13f97cd2d3d2a984ab6bbaaf77": "Ybodychange",
    "c92837aeab5188f6171d4016f91b3b4936a66beb": "Ybodychange",
    "a317bd7b02c37bd57743bfad59593ec12f53f4ed": "Ybodychange",
    "d758be1f35f6c1c7e9edd491af559721a3b8b8f8": "Yintroduced"
  },
  "changeHistoryDetails": {
    "d7c136b9ed6d99e1b03f5b89723b3a20df359ba8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-15150. Introduce read write lock to Datanode. Contributed Stephen O\u0027Donnell.\n\nSigned-off-by: Wei-Chiu Chuang \u003cweichiu@apache.org\u003e\n",
      "commitDate": "11/02/20 8:00 AM",
      "commitName": "d7c136b9ed6d99e1b03f5b89723b3a20df359ba8",
      "commitAuthor": "Stephen O\u0027Donnell",
      "commitDateOld": "28/01/20 10:10 AM",
      "commitNameOld": "1839c467f60cbb8592d446694ec3d7710cda5142",
      "commitAuthorOld": "Inigo Goiri",
      "daysBetweenCommits": 13.91,
      "commitsBetweenForRepo": 33,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,21 @@\n   private void addVolume(Storage.StorageDirectory sd) throws IOException {\n     final StorageLocation storageLocation \u003d sd.getStorageLocation();\n \n     // If IOException raises from FsVolumeImpl() or getVolumeMap(), there is\n     // nothing needed to be rolled back to make various data structures, e.g.,\n     // storageMap and asyncDiskService, consistent.\n     FsVolumeImpl fsVolume \u003d new FsVolumeImplBuilder()\n                               .setDataset(this)\n                               .setStorageID(sd.getStorageUuid())\n                               .setStorageDirectory(sd)\n                               .setFileIoProvider(datanode.getFileIoProvider())\n                               .setConf(this.conf)\n                               .build();\n     FsVolumeReference ref \u003d fsVolume.obtainReference();\n-    ReplicaMap tempVolumeMap \u003d new ReplicaMap(datasetLock);\n+    ReplicaMap tempVolumeMap \u003d new ReplicaMap(datasetRWLock);\n     fsVolume.getVolumeMap(tempVolumeMap, ramDiskReplicaTracker);\n \n     activateVolume(tempVolumeMap, sd, storageLocation.getStorageType(), ref);\n     LOG.info(\"Added volume - \" + storageLocation + \", StorageType: \" +\n         storageLocation.getStorageType());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void addVolume(Storage.StorageDirectory sd) throws IOException {\n    final StorageLocation storageLocation \u003d sd.getStorageLocation();\n\n    // If IOException raises from FsVolumeImpl() or getVolumeMap(), there is\n    // nothing needed to be rolled back to make various data structures, e.g.,\n    // storageMap and asyncDiskService, consistent.\n    FsVolumeImpl fsVolume \u003d new FsVolumeImplBuilder()\n                              .setDataset(this)\n                              .setStorageID(sd.getStorageUuid())\n                              .setStorageDirectory(sd)\n                              .setFileIoProvider(datanode.getFileIoProvider())\n                              .setConf(this.conf)\n                              .build();\n    FsVolumeReference ref \u003d fsVolume.obtainReference();\n    ReplicaMap tempVolumeMap \u003d new ReplicaMap(datasetRWLock);\n    fsVolume.getVolumeMap(tempVolumeMap, ramDiskReplicaTracker);\n\n    activateVolume(tempVolumeMap, sd, storageLocation.getStorageType(), ref);\n    LOG.info(\"Added volume - \" + storageLocation + \", StorageType: \" +\n        storageLocation.getStorageType());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "02e2a9b1152b0e144fcf43bec2fce26d8a6c6dbc": {
      "type": "Yparameterchange",
      "commitMessage": "HDFS-12304. Remove unused parameter from FsDatasetImpl#addVolume. Contributed by Chen Liang.\n",
      "commitDate": "25/09/17 9:25 AM",
      "commitName": "02e2a9b1152b0e144fcf43bec2fce26d8a6c6dbc",
      "commitAuthor": "Akira Ajisaka",
      "commitDateOld": "09/08/17 7:03 AM",
      "commitNameOld": "69afa26f19adad4c630a307c274130eb8b697141",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 47.1,
      "commitsBetweenForRepo": 427,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,21 @@\n-  private void addVolume(Collection\u003cStorageLocation\u003e dataLocations,\n-      Storage.StorageDirectory sd) throws IOException {\n+  private void addVolume(Storage.StorageDirectory sd) throws IOException {\n     final StorageLocation storageLocation \u003d sd.getStorageLocation();\n \n     // If IOException raises from FsVolumeImpl() or getVolumeMap(), there is\n     // nothing needed to be rolled back to make various data structures, e.g.,\n     // storageMap and asyncDiskService, consistent.\n     FsVolumeImpl fsVolume \u003d new FsVolumeImplBuilder()\n                               .setDataset(this)\n                               .setStorageID(sd.getStorageUuid())\n                               .setStorageDirectory(sd)\n                               .setFileIoProvider(datanode.getFileIoProvider())\n                               .setConf(this.conf)\n                               .build();\n     FsVolumeReference ref \u003d fsVolume.obtainReference();\n     ReplicaMap tempVolumeMap \u003d new ReplicaMap(datasetLock);\n     fsVolume.getVolumeMap(tempVolumeMap, ramDiskReplicaTracker);\n \n     activateVolume(tempVolumeMap, sd, storageLocation.getStorageType(), ref);\n     LOG.info(\"Added volume - \" + storageLocation + \", StorageType: \" +\n         storageLocation.getStorageType());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void addVolume(Storage.StorageDirectory sd) throws IOException {\n    final StorageLocation storageLocation \u003d sd.getStorageLocation();\n\n    // If IOException raises from FsVolumeImpl() or getVolumeMap(), there is\n    // nothing needed to be rolled back to make various data structures, e.g.,\n    // storageMap and asyncDiskService, consistent.\n    FsVolumeImpl fsVolume \u003d new FsVolumeImplBuilder()\n                              .setDataset(this)\n                              .setStorageID(sd.getStorageUuid())\n                              .setStorageDirectory(sd)\n                              .setFileIoProvider(datanode.getFileIoProvider())\n                              .setConf(this.conf)\n                              .build();\n    FsVolumeReference ref \u003d fsVolume.obtainReference();\n    ReplicaMap tempVolumeMap \u003d new ReplicaMap(datasetLock);\n    fsVolume.getVolumeMap(tempVolumeMap, ramDiskReplicaTracker);\n\n    activateVolume(tempVolumeMap, sd, storageLocation.getStorageType(), ref);\n    LOG.info(\"Added volume - \" + storageLocation + \", StorageType: \" +\n        storageLocation.getStorageType());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {
        "oldValue": "[dataLocations-Collection\u003cStorageLocation\u003e, sd-Storage.StorageDirectory]",
        "newValue": "[sd-Storage.StorageDirectory]"
      }
    },
    "6ba9587d370fbf39c129c08c00ebbb894ccc1389": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10958. Add instrumentation hooks around Datanode disk IO.\n",
      "commitDate": "14/12/16 11:18 AM",
      "commitName": "6ba9587d370fbf39c129c08c00ebbb894ccc1389",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "06/12/16 11:05 AM",
      "commitNameOld": "df983b524ab68ea0c70cee9033bfff2d28052cbf",
      "commitAuthorOld": "Xiaoyu Yao",
      "daysBetweenCommits": 8.01,
      "commitsBetweenForRepo": 51,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,22 @@\n   private void addVolume(Collection\u003cStorageLocation\u003e dataLocations,\n       Storage.StorageDirectory sd) throws IOException {\n     final StorageLocation storageLocation \u003d sd.getStorageLocation();\n \n     // If IOException raises from FsVolumeImpl() or getVolumeMap(), there is\n     // nothing needed to be rolled back to make various data structures, e.g.,\n     // storageMap and asyncDiskService, consistent.\n     FsVolumeImpl fsVolume \u003d new FsVolumeImplBuilder()\n                               .setDataset(this)\n                               .setStorageID(sd.getStorageUuid())\n                               .setStorageDirectory(sd)\n+                              .setFileIoProvider(datanode.getFileIoProvider())\n                               .setConf(this.conf)\n                               .build();\n     FsVolumeReference ref \u003d fsVolume.obtainReference();\n     ReplicaMap tempVolumeMap \u003d new ReplicaMap(datasetLock);\n     fsVolume.getVolumeMap(tempVolumeMap, ramDiskReplicaTracker);\n \n     activateVolume(tempVolumeMap, sd, storageLocation.getStorageType(), ref);\n     LOG.info(\"Added volume - \" + storageLocation + \", StorageType: \" +\n         storageLocation.getStorageType());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void addVolume(Collection\u003cStorageLocation\u003e dataLocations,\n      Storage.StorageDirectory sd) throws IOException {\n    final StorageLocation storageLocation \u003d sd.getStorageLocation();\n\n    // If IOException raises from FsVolumeImpl() or getVolumeMap(), there is\n    // nothing needed to be rolled back to make various data structures, e.g.,\n    // storageMap and asyncDiskService, consistent.\n    FsVolumeImpl fsVolume \u003d new FsVolumeImplBuilder()\n                              .setDataset(this)\n                              .setStorageID(sd.getStorageUuid())\n                              .setStorageDirectory(sd)\n                              .setFileIoProvider(datanode.getFileIoProvider())\n                              .setConf(this.conf)\n                              .build();\n    FsVolumeReference ref \u003d fsVolume.obtainReference();\n    ReplicaMap tempVolumeMap \u003d new ReplicaMap(datasetLock);\n    fsVolume.getVolumeMap(tempVolumeMap, ramDiskReplicaTracker);\n\n    activateVolume(tempVolumeMap, sd, storageLocation.getStorageType(), ref);\n    LOG.info(\"Added volume - \" + storageLocation + \", StorageType: \" +\n        storageLocation.getStorageType());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "96b12662ea76e3ded4ef13944fc8df206cfb4613": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10637. Modifications to remove the assumption that FsVolumes are backed by java.io.File. (Virajith Jalaparti via lei)\n",
      "commitDate": "10/10/16 3:30 PM",
      "commitName": "96b12662ea76e3ded4ef13944fc8df206cfb4613",
      "commitAuthor": "Lei Xu",
      "commitDateOld": "30/09/16 11:11 PM",
      "commitNameOld": "fe9ebe20ab113567f0777c11cb48ce0d3ce587a8",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 9.68,
      "commitsBetweenForRepo": 64,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,18 +1,21 @@\n   private void addVolume(Collection\u003cStorageLocation\u003e dataLocations,\n       Storage.StorageDirectory sd) throws IOException {\n-    final File dir \u003d sd.getCurrentDir();\n-    final StorageType storageType \u003d\n-        getStorageTypeFromLocations(dataLocations, sd.getRoot());\n+    final StorageLocation storageLocation \u003d sd.getStorageLocation();\n \n     // If IOException raises from FsVolumeImpl() or getVolumeMap(), there is\n     // nothing needed to be rolled back to make various data structures, e.g.,\n     // storageMap and asyncDiskService, consistent.\n-    FsVolumeImpl fsVolume \u003d new FsVolumeImpl(\n-        this, sd.getStorageUuid(), dir, this.conf, storageType);\n+    FsVolumeImpl fsVolume \u003d new FsVolumeImplBuilder()\n+                              .setDataset(this)\n+                              .setStorageID(sd.getStorageUuid())\n+                              .setStorageDirectory(sd)\n+                              .setConf(this.conf)\n+                              .build();\n     FsVolumeReference ref \u003d fsVolume.obtainReference();\n     ReplicaMap tempVolumeMap \u003d new ReplicaMap(datasetLock);\n     fsVolume.getVolumeMap(tempVolumeMap, ramDiskReplicaTracker);\n \n-    activateVolume(tempVolumeMap, sd, storageType, ref);\n-    LOG.info(\"Added volume - \" + dir + \", StorageType: \" + storageType);\n+    activateVolume(tempVolumeMap, sd, storageLocation.getStorageType(), ref);\n+    LOG.info(\"Added volume - \" + storageLocation + \", StorageType: \" +\n+        storageLocation.getStorageType());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void addVolume(Collection\u003cStorageLocation\u003e dataLocations,\n      Storage.StorageDirectory sd) throws IOException {\n    final StorageLocation storageLocation \u003d sd.getStorageLocation();\n\n    // If IOException raises from FsVolumeImpl() or getVolumeMap(), there is\n    // nothing needed to be rolled back to make various data structures, e.g.,\n    // storageMap and asyncDiskService, consistent.\n    FsVolumeImpl fsVolume \u003d new FsVolumeImplBuilder()\n                              .setDataset(this)\n                              .setStorageID(sd.getStorageUuid())\n                              .setStorageDirectory(sd)\n                              .setConf(this.conf)\n                              .build();\n    FsVolumeReference ref \u003d fsVolume.obtainReference();\n    ReplicaMap tempVolumeMap \u003d new ReplicaMap(datasetLock);\n    fsVolume.getVolumeMap(tempVolumeMap, ramDiskReplicaTracker);\n\n    activateVolume(tempVolumeMap, sd, storageLocation.getStorageType(), ref);\n    LOG.info(\"Added volume - \" + storageLocation + \", StorageType: \" +\n        storageLocation.getStorageType());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "8ae4729107d33c6001cf1fdc8837afb71ea6c0d3": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10828. Fix usage of FsDatasetImpl object lock in ReplicaMap. (Arpit Agarwal)\n",
      "commitDate": "27/09/16 10:02 AM",
      "commitName": "8ae4729107d33c6001cf1fdc8837afb71ea6c0d3",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "13/09/16 12:54 PM",
      "commitNameOld": "86c9862bec0248d671e657aa56094a2919b8ac14",
      "commitAuthorOld": "Lei Xu",
      "daysBetweenCommits": 13.88,
      "commitsBetweenForRepo": 72,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,18 +1,18 @@\n   private void addVolume(Collection\u003cStorageLocation\u003e dataLocations,\n       Storage.StorageDirectory sd) throws IOException {\n     final File dir \u003d sd.getCurrentDir();\n     final StorageType storageType \u003d\n         getStorageTypeFromLocations(dataLocations, sd.getRoot());\n \n     // If IOException raises from FsVolumeImpl() or getVolumeMap(), there is\n     // nothing needed to be rolled back to make various data structures, e.g.,\n     // storageMap and asyncDiskService, consistent.\n     FsVolumeImpl fsVolume \u003d new FsVolumeImpl(\n         this, sd.getStorageUuid(), dir, this.conf, storageType);\n     FsVolumeReference ref \u003d fsVolume.obtainReference();\n-    ReplicaMap tempVolumeMap \u003d new ReplicaMap(this);\n+    ReplicaMap tempVolumeMap \u003d new ReplicaMap(datasetLock);\n     fsVolume.getVolumeMap(tempVolumeMap, ramDiskReplicaTracker);\n \n     activateVolume(tempVolumeMap, sd, storageType, ref);\n     LOG.info(\"Added volume - \" + dir + \", StorageType: \" + storageType);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void addVolume(Collection\u003cStorageLocation\u003e dataLocations,\n      Storage.StorageDirectory sd) throws IOException {\n    final File dir \u003d sd.getCurrentDir();\n    final StorageType storageType \u003d\n        getStorageTypeFromLocations(dataLocations, sd.getRoot());\n\n    // If IOException raises from FsVolumeImpl() or getVolumeMap(), there is\n    // nothing needed to be rolled back to make various data structures, e.g.,\n    // storageMap and asyncDiskService, consistent.\n    FsVolumeImpl fsVolume \u003d new FsVolumeImpl(\n        this, sd.getStorageUuid(), dir, this.conf, storageType);\n    FsVolumeReference ref \u003d fsVolume.obtainReference();\n    ReplicaMap tempVolumeMap \u003d new ReplicaMap(datasetLock);\n    fsVolume.getVolumeMap(tempVolumeMap, ramDiskReplicaTracker);\n\n    activateVolume(tempVolumeMap, sd, storageType, ref);\n    LOG.info(\"Added volume - \" + dir + \", StorageType: \" + storageType);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "04375756a5ed6e907ee7548469c2c508aebbafb7": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9715. Check storage ID uniqueness on datanode startup (Contributed by Lei (Eddy) Xu)\n",
      "commitDate": "02/02/16 6:05 PM",
      "commitName": "04375756a5ed6e907ee7548469c2c508aebbafb7",
      "commitAuthor": "Vinayakumar B",
      "commitDateOld": "01/02/16 12:56 PM",
      "commitNameOld": "e50aa53eed3d0ff1bc8fe60381524bb3bbe53bc1",
      "commitAuthorOld": "Lei Xu",
      "daysBetweenCommits": 1.21,
      "commitsBetweenForRepo": 19,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,27 +1,18 @@\n   private void addVolume(Collection\u003cStorageLocation\u003e dataLocations,\n       Storage.StorageDirectory sd) throws IOException {\n     final File dir \u003d sd.getCurrentDir();\n     final StorageType storageType \u003d\n         getStorageTypeFromLocations(dataLocations, sd.getRoot());\n \n     // If IOException raises from FsVolumeImpl() or getVolumeMap(), there is\n     // nothing needed to be rolled back to make various data structures, e.g.,\n     // storageMap and asyncDiskService, consistent.\n     FsVolumeImpl fsVolume \u003d new FsVolumeImpl(\n         this, sd.getStorageUuid(), dir, this.conf, storageType);\n     FsVolumeReference ref \u003d fsVolume.obtainReference();\n     ReplicaMap tempVolumeMap \u003d new ReplicaMap(this);\n     fsVolume.getVolumeMap(tempVolumeMap, ramDiskReplicaTracker);\n \n-    synchronized (this) {\n-      volumeMap.addAll(tempVolumeMap);\n-      storageMap.put(sd.getStorageUuid(),\n-          new DatanodeStorage(sd.getStorageUuid(),\n-              DatanodeStorage.State.NORMAL,\n-              storageType));\n-      asyncDiskService.addVolume(sd.getCurrentDir());\n-      volumes.addVolume(ref);\n-    }\n-\n+    activateVolume(tempVolumeMap, sd, storageType, ref);\n     LOG.info(\"Added volume - \" + dir + \", StorageType: \" + storageType);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void addVolume(Collection\u003cStorageLocation\u003e dataLocations,\n      Storage.StorageDirectory sd) throws IOException {\n    final File dir \u003d sd.getCurrentDir();\n    final StorageType storageType \u003d\n        getStorageTypeFromLocations(dataLocations, sd.getRoot());\n\n    // If IOException raises from FsVolumeImpl() or getVolumeMap(), there is\n    // nothing needed to be rolled back to make various data structures, e.g.,\n    // storageMap and asyncDiskService, consistent.\n    FsVolumeImpl fsVolume \u003d new FsVolumeImpl(\n        this, sd.getStorageUuid(), dir, this.conf, storageType);\n    FsVolumeReference ref \u003d fsVolume.obtainReference();\n    ReplicaMap tempVolumeMap \u003d new ReplicaMap(this);\n    fsVolume.getVolumeMap(tempVolumeMap, ramDiskReplicaTracker);\n\n    activateVolume(tempVolumeMap, sd, storageType, ref);\n    LOG.info(\"Added volume - \" + dir + \", StorageType: \" + storageType);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "6e62a1a6728b1f782f64065424f92b292c3f163a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7430. Refactor the BlockScanner to use O(1) memory and use multiple threads (cmccabe)\n",
      "commitDate": "21/01/15 7:00 PM",
      "commitName": "6e62a1a6728b1f782f64065424f92b292c3f163a",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "21/01/15 12:41 PM",
      "commitNameOld": "c0af72c7f74b6925786e24543cac433b906dd6d3",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 0.26,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,26 +1,27 @@\n   private void addVolume(Collection\u003cStorageLocation\u003e dataLocations,\n       Storage.StorageDirectory sd) throws IOException {\n     final File dir \u003d sd.getCurrentDir();\n     final StorageType storageType \u003d\n         getStorageTypeFromLocations(dataLocations, sd.getRoot());\n \n     // If IOException raises from FsVolumeImpl() or getVolumeMap(), there is\n     // nothing needed to be rolled back to make various data structures, e.g.,\n     // storageMap and asyncDiskService, consistent.\n     FsVolumeImpl fsVolume \u003d new FsVolumeImpl(\n         this, sd.getStorageUuid(), dir, this.conf, storageType);\n+    FsVolumeReference ref \u003d fsVolume.obtainReference();\n     ReplicaMap tempVolumeMap \u003d new ReplicaMap(this);\n     fsVolume.getVolumeMap(tempVolumeMap, ramDiskReplicaTracker);\n \n     synchronized (this) {\n       volumeMap.addAll(tempVolumeMap);\n       storageMap.put(sd.getStorageUuid(),\n           new DatanodeStorage(sd.getStorageUuid(),\n               DatanodeStorage.State.NORMAL,\n               storageType));\n       asyncDiskService.addVolume(sd.getCurrentDir());\n-      volumes.addVolume(fsVolume);\n+      volumes.addVolume(ref);\n     }\n \n     LOG.info(\"Added volume - \" + dir + \", StorageType: \" + storageType);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void addVolume(Collection\u003cStorageLocation\u003e dataLocations,\n      Storage.StorageDirectory sd) throws IOException {\n    final File dir \u003d sd.getCurrentDir();\n    final StorageType storageType \u003d\n        getStorageTypeFromLocations(dataLocations, sd.getRoot());\n\n    // If IOException raises from FsVolumeImpl() or getVolumeMap(), there is\n    // nothing needed to be rolled back to make various data structures, e.g.,\n    // storageMap and asyncDiskService, consistent.\n    FsVolumeImpl fsVolume \u003d new FsVolumeImpl(\n        this, sd.getStorageUuid(), dir, this.conf, storageType);\n    FsVolumeReference ref \u003d fsVolume.obtainReference();\n    ReplicaMap tempVolumeMap \u003d new ReplicaMap(this);\n    fsVolume.getVolumeMap(tempVolumeMap, ramDiskReplicaTracker);\n\n    synchronized (this) {\n      volumeMap.addAll(tempVolumeMap);\n      storageMap.put(sd.getStorageUuid(),\n          new DatanodeStorage(sd.getStorageUuid(),\n              DatanodeStorage.State.NORMAL,\n              storageType));\n      asyncDiskService.addVolume(sd.getCurrentDir());\n      volumes.addVolume(ref);\n    }\n\n    LOG.info(\"Added volume - \" + dir + \", StorageType: \" + storageType);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "a9331fe9b071fdcdae0c6c747d7b6b306142e671": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7035. Make adding a new data directory to the DataNode an atomic operation and improve error handling (Lei Xu via Colin P. McCabe)\n",
      "commitDate": "30/10/14 5:31 PM",
      "commitName": "a9331fe9b071fdcdae0c6c747d7b6b306142e671",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "28/10/14 4:41 PM",
      "commitNameOld": "ac9ab037e9a9b03e4fa9bd471d3ab9940beb53fb",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 2.03,
      "commitsBetweenForRepo": 30,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,26 @@\n   private void addVolume(Collection\u003cStorageLocation\u003e dataLocations,\n       Storage.StorageDirectory sd) throws IOException {\n     final File dir \u003d sd.getCurrentDir();\n     final StorageType storageType \u003d\n         getStorageTypeFromLocations(dataLocations, sd.getRoot());\n \n     // If IOException raises from FsVolumeImpl() or getVolumeMap(), there is\n     // nothing needed to be rolled back to make various data structures, e.g.,\n     // storageMap and asyncDiskService, consistent.\n     FsVolumeImpl fsVolume \u003d new FsVolumeImpl(\n         this, sd.getStorageUuid(), dir, this.conf, storageType);\n     ReplicaMap tempVolumeMap \u003d new ReplicaMap(this);\n     fsVolume.getVolumeMap(tempVolumeMap, ramDiskReplicaTracker);\n \n-    volumeMap.addAll(tempVolumeMap);\n-    volumes.addVolume(fsVolume);\n-    storageMap.put(sd.getStorageUuid(),\n-        new DatanodeStorage(sd.getStorageUuid(),\n-            DatanodeStorage.State.NORMAL,\n-            storageType));\n-    asyncDiskService.addVolume(sd.getCurrentDir());\n+    synchronized (this) {\n+      volumeMap.addAll(tempVolumeMap);\n+      storageMap.put(sd.getStorageUuid(),\n+          new DatanodeStorage(sd.getStorageUuid(),\n+              DatanodeStorage.State.NORMAL,\n+              storageType));\n+      asyncDiskService.addVolume(sd.getCurrentDir());\n+      volumes.addVolume(fsVolume);\n+    }\n \n     LOG.info(\"Added volume - \" + dir + \", StorageType: \" + storageType);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void addVolume(Collection\u003cStorageLocation\u003e dataLocations,\n      Storage.StorageDirectory sd) throws IOException {\n    final File dir \u003d sd.getCurrentDir();\n    final StorageType storageType \u003d\n        getStorageTypeFromLocations(dataLocations, sd.getRoot());\n\n    // If IOException raises from FsVolumeImpl() or getVolumeMap(), there is\n    // nothing needed to be rolled back to make various data structures, e.g.,\n    // storageMap and asyncDiskService, consistent.\n    FsVolumeImpl fsVolume \u003d new FsVolumeImpl(\n        this, sd.getStorageUuid(), dir, this.conf, storageType);\n    ReplicaMap tempVolumeMap \u003d new ReplicaMap(this);\n    fsVolume.getVolumeMap(tempVolumeMap, ramDiskReplicaTracker);\n\n    synchronized (this) {\n      volumeMap.addAll(tempVolumeMap);\n      storageMap.put(sd.getStorageUuid(),\n          new DatanodeStorage(sd.getStorageUuid(),\n              DatanodeStorage.State.NORMAL,\n              storageType));\n      asyncDiskService.addVolume(sd.getCurrentDir());\n      volumes.addVolume(fsVolume);\n    }\n\n    LOG.info(\"Added volume - \" + dir + \", StorageType: \" + storageType);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "bb84f1fccb18c6c7373851e05d2451d55e908242": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7159. Use block storage policy to set lazy persist preference. (Arpit Agarwal)\n",
      "commitDate": "29/09/14 10:27 PM",
      "commitName": "bb84f1fccb18c6c7373851e05d2451d55e908242",
      "commitAuthor": "arp",
      "commitDateOld": "20/09/14 1:25 PM",
      "commitNameOld": "b2d5ed36bcb80e2581191dcdc3976e825c959142",
      "commitAuthorOld": "arp",
      "daysBetweenCommits": 9.38,
      "commitsBetweenForRepo": 104,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,24 @@\n   private void addVolume(Collection\u003cStorageLocation\u003e dataLocations,\n       Storage.StorageDirectory sd) throws IOException {\n     final File dir \u003d sd.getCurrentDir();\n     final StorageType storageType \u003d\n         getStorageTypeFromLocations(dataLocations, sd.getRoot());\n \n     // If IOException raises from FsVolumeImpl() or getVolumeMap(), there is\n     // nothing needed to be rolled back to make various data structures, e.g.,\n     // storageMap and asyncDiskService, consistent.\n-    FsVolumeImpl fsVolume \u003d FsVolumeImplAllocator.createVolume(\n+    FsVolumeImpl fsVolume \u003d new FsVolumeImpl(\n         this, sd.getStorageUuid(), dir, this.conf, storageType);\n     ReplicaMap tempVolumeMap \u003d new ReplicaMap(this);\n     fsVolume.getVolumeMap(tempVolumeMap, ramDiskReplicaTracker);\n \n     volumeMap.addAll(tempVolumeMap);\n     volumes.addVolume(fsVolume);\n     storageMap.put(sd.getStorageUuid(),\n         new DatanodeStorage(sd.getStorageUuid(),\n             DatanodeStorage.State.NORMAL,\n             storageType));\n     asyncDiskService.addVolume(sd.getCurrentDir());\n \n     LOG.info(\"Added volume - \" + dir + \", StorageType: \" + storageType);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void addVolume(Collection\u003cStorageLocation\u003e dataLocations,\n      Storage.StorageDirectory sd) throws IOException {\n    final File dir \u003d sd.getCurrentDir();\n    final StorageType storageType \u003d\n        getStorageTypeFromLocations(dataLocations, sd.getRoot());\n\n    // If IOException raises from FsVolumeImpl() or getVolumeMap(), there is\n    // nothing needed to be rolled back to make various data structures, e.g.,\n    // storageMap and asyncDiskService, consistent.\n    FsVolumeImpl fsVolume \u003d new FsVolumeImpl(\n        this, sd.getStorageUuid(), dir, this.conf, storageType);\n    ReplicaMap tempVolumeMap \u003d new ReplicaMap(this);\n    fsVolume.getVolumeMap(tempVolumeMap, ramDiskReplicaTracker);\n\n    volumeMap.addAll(tempVolumeMap);\n    volumes.addVolume(fsVolume);\n    storageMap.put(sd.getStorageUuid(),\n        new DatanodeStorage(sd.getStorageUuid(),\n            DatanodeStorage.State.NORMAL,\n            storageType));\n    asyncDiskService.addVolume(sd.getCurrentDir());\n\n    LOG.info(\"Added volume - \" + dir + \", StorageType: \" + storageType);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "b2d5ed36bcb80e2581191dcdc3976e825c959142": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7100. Make eviction scheme pluggable. (Arpit Agarwal)\n",
      "commitDate": "20/09/14 1:25 PM",
      "commitName": "b2d5ed36bcb80e2581191dcdc3976e825c959142",
      "commitAuthor": "arp",
      "commitDateOld": "19/09/14 10:02 AM",
      "commitNameOld": "222bf0fe6706ee43964fd39b8315c1a339fbc84a",
      "commitAuthorOld": "",
      "daysBetweenCommits": 1.14,
      "commitsBetweenForRepo": 11,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,24 @@\n   private void addVolume(Collection\u003cStorageLocation\u003e dataLocations,\n       Storage.StorageDirectory sd) throws IOException {\n     final File dir \u003d sd.getCurrentDir();\n     final StorageType storageType \u003d\n         getStorageTypeFromLocations(dataLocations, sd.getRoot());\n \n     // If IOException raises from FsVolumeImpl() or getVolumeMap(), there is\n     // nothing needed to be rolled back to make various data structures, e.g.,\n     // storageMap and asyncDiskService, consistent.\n     FsVolumeImpl fsVolume \u003d FsVolumeImplAllocator.createVolume(\n         this, sd.getStorageUuid(), dir, this.conf, storageType);\n     ReplicaMap tempVolumeMap \u003d new ReplicaMap(this);\n-    fsVolume.getVolumeMap(tempVolumeMap, lazyWriteReplicaTracker);\n+    fsVolume.getVolumeMap(tempVolumeMap, ramDiskReplicaTracker);\n \n     volumeMap.addAll(tempVolumeMap);\n     volumes.addVolume(fsVolume);\n     storageMap.put(sd.getStorageUuid(),\n         new DatanodeStorage(sd.getStorageUuid(),\n             DatanodeStorage.State.NORMAL,\n             storageType));\n     asyncDiskService.addVolume(sd.getCurrentDir());\n \n     LOG.info(\"Added volume - \" + dir + \", StorageType: \" + storageType);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void addVolume(Collection\u003cStorageLocation\u003e dataLocations,\n      Storage.StorageDirectory sd) throws IOException {\n    final File dir \u003d sd.getCurrentDir();\n    final StorageType storageType \u003d\n        getStorageTypeFromLocations(dataLocations, sd.getRoot());\n\n    // If IOException raises from FsVolumeImpl() or getVolumeMap(), there is\n    // nothing needed to be rolled back to make various data structures, e.g.,\n    // storageMap and asyncDiskService, consistent.\n    FsVolumeImpl fsVolume \u003d FsVolumeImplAllocator.createVolume(\n        this, sd.getStorageUuid(), dir, this.conf, storageType);\n    ReplicaMap tempVolumeMap \u003d new ReplicaMap(this);\n    fsVolume.getVolumeMap(tempVolumeMap, ramDiskReplicaTracker);\n\n    volumeMap.addAll(tempVolumeMap);\n    volumes.addVolume(fsVolume);\n    storageMap.put(sd.getStorageUuid(),\n        new DatanodeStorage(sd.getStorageUuid(),\n            DatanodeStorage.State.NORMAL,\n            storageType));\n    asyncDiskService.addVolume(sd.getCurrentDir());\n\n    LOG.info(\"Added volume - \" + dir + \", StorageType: \" + storageType);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "fe38d2e9b5ac7e13f97cd2d3d2a984ab6bbaaf77": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6727. Refresh data volumes on DataNode based on configuration changes (Lei Xu via Colin Patrick McCabe)\n",
      "commitDate": "18/09/14 4:52 PM",
      "commitName": "fe38d2e9b5ac7e13f97cd2d3d2a984ab6bbaaf77",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "08/09/14 9:20 PM",
      "commitNameOld": "f949f6b54825dac61511a5761837e2fd14437239",
      "commitAuthorOld": "arp",
      "daysBetweenCommits": 9.81,
      "commitsBetweenForRepo": 117,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,24 @@\n   private void addVolume(Collection\u003cStorageLocation\u003e dataLocations,\n       Storage.StorageDirectory sd) throws IOException {\n     final File dir \u003d sd.getCurrentDir();\n     final StorageType storageType \u003d\n         getStorageTypeFromLocations(dataLocations, sd.getRoot());\n \n     // If IOException raises from FsVolumeImpl() or getVolumeMap(), there is\n     // nothing needed to be rolled back to make various data structures, e.g.,\n     // storageMap and asyncDiskService, consistent.\n     FsVolumeImpl fsVolume \u003d new FsVolumeImpl(\n         this, sd.getStorageUuid(), dir, this.conf, storageType);\n-    fsVolume.getVolumeMap(volumeMap);\n+    ReplicaMap tempVolumeMap \u003d new ReplicaMap(this);\n+    fsVolume.getVolumeMap(tempVolumeMap);\n \n+    volumeMap.addAll(tempVolumeMap);\n     volumes.addVolume(fsVolume);\n     storageMap.put(sd.getStorageUuid(),\n         new DatanodeStorage(sd.getStorageUuid(),\n-                            DatanodeStorage.State.NORMAL,\n-                            storageType));\n+            DatanodeStorage.State.NORMAL,\n+            storageType));\n     asyncDiskService.addVolume(sd.getCurrentDir());\n \n     LOG.info(\"Added volume - \" + dir + \", StorageType: \" + storageType);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void addVolume(Collection\u003cStorageLocation\u003e dataLocations,\n      Storage.StorageDirectory sd) throws IOException {\n    final File dir \u003d sd.getCurrentDir();\n    final StorageType storageType \u003d\n        getStorageTypeFromLocations(dataLocations, sd.getRoot());\n\n    // If IOException raises from FsVolumeImpl() or getVolumeMap(), there is\n    // nothing needed to be rolled back to make various data structures, e.g.,\n    // storageMap and asyncDiskService, consistent.\n    FsVolumeImpl fsVolume \u003d new FsVolumeImpl(\n        this, sd.getStorageUuid(), dir, this.conf, storageType);\n    ReplicaMap tempVolumeMap \u003d new ReplicaMap(this);\n    fsVolume.getVolumeMap(tempVolumeMap);\n\n    volumeMap.addAll(tempVolumeMap);\n    volumes.addVolume(fsVolume);\n    storageMap.put(sd.getStorageUuid(),\n        new DatanodeStorage(sd.getStorageUuid(),\n            DatanodeStorage.State.NORMAL,\n            storageType));\n    asyncDiskService.addVolume(sd.getCurrentDir());\n\n    LOG.info(\"Added volume - \" + dir + \", StorageType: \" + storageType);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "c92837aeab5188f6171d4016f91b3b4936a66beb": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6931. Move lazily persisted replicas to finalized directory on DN startup. (Arpit Agarwal)\n",
      "commitDate": "28/08/14 11:13 PM",
      "commitName": "c92837aeab5188f6171d4016f91b3b4936a66beb",
      "commitAuthor": "arp",
      "commitDateOld": "28/08/14 11:05 PM",
      "commitNameOld": "4cf9afacbe3d0814fb616d238aa9b16b1ae68386",
      "commitAuthorOld": "arp",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,22 @@\n   private void addVolume(Collection\u003cStorageLocation\u003e dataLocations,\n       Storage.StorageDirectory sd) throws IOException {\n     final File dir \u003d sd.getCurrentDir();\n     final StorageType storageType \u003d\n         getStorageTypeFromLocations(dataLocations, sd.getRoot());\n \n     // If IOException raises from FsVolumeImpl() or getVolumeMap(), there is\n     // nothing needed to be rolled back to make various data structures, e.g.,\n     // storageMap and asyncDiskService, consistent.\n     FsVolumeImpl fsVolume \u003d FsVolumeImplAllocator.createVolume(\n         this, sd.getStorageUuid(), dir, this.conf, storageType);\n-    fsVolume.getVolumeMap(volumeMap);\n+    fsVolume.getVolumeMap(volumeMap, lazyWriteReplicaTracker);\n \n     volumes.addVolume(fsVolume);\n     storageMap.put(sd.getStorageUuid(),\n         new DatanodeStorage(sd.getStorageUuid(),\n                             DatanodeStorage.State.NORMAL,\n                             storageType));\n     asyncDiskService.addVolume(sd.getCurrentDir());\n \n     LOG.info(\"Added volume - \" + dir + \", StorageType: \" + storageType);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void addVolume(Collection\u003cStorageLocation\u003e dataLocations,\n      Storage.StorageDirectory sd) throws IOException {\n    final File dir \u003d sd.getCurrentDir();\n    final StorageType storageType \u003d\n        getStorageTypeFromLocations(dataLocations, sd.getRoot());\n\n    // If IOException raises from FsVolumeImpl() or getVolumeMap(), there is\n    // nothing needed to be rolled back to make various data structures, e.g.,\n    // storageMap and asyncDiskService, consistent.\n    FsVolumeImpl fsVolume \u003d FsVolumeImplAllocator.createVolume(\n        this, sd.getStorageUuid(), dir, this.conf, storageType);\n    fsVolume.getVolumeMap(volumeMap, lazyWriteReplicaTracker);\n\n    volumes.addVolume(fsVolume);\n    storageMap.put(sd.getStorageUuid(),\n        new DatanodeStorage(sd.getStorageUuid(),\n                            DatanodeStorage.State.NORMAL,\n                            storageType));\n    asyncDiskService.addVolume(sd.getCurrentDir());\n\n    LOG.info(\"Added volume - \" + dir + \", StorageType: \" + storageType);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "a317bd7b02c37bd57743bfad59593ec12f53f4ed": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6925. DataNode should attempt to place replicas on transient storage first if lazyPersist flag is received. (Arpit Agarwal)\n",
      "commitDate": "27/08/14 9:47 PM",
      "commitName": "a317bd7b02c37bd57743bfad59593ec12f53f4ed",
      "commitAuthor": "arp",
      "commitDateOld": "07/08/14 3:59 PM",
      "commitNameOld": "d758be1f35f6c1c7e9edd491af559721a3b8b8f8",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 20.24,
      "commitsBetweenForRepo": 166,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,22 @@\n   private void addVolume(Collection\u003cStorageLocation\u003e dataLocations,\n       Storage.StorageDirectory sd) throws IOException {\n     final File dir \u003d sd.getCurrentDir();\n     final StorageType storageType \u003d\n         getStorageTypeFromLocations(dataLocations, sd.getRoot());\n \n     // If IOException raises from FsVolumeImpl() or getVolumeMap(), there is\n     // nothing needed to be rolled back to make various data structures, e.g.,\n     // storageMap and asyncDiskService, consistent.\n-    FsVolumeImpl fsVolume \u003d new FsVolumeImpl(\n+    FsVolumeImpl fsVolume \u003d FsVolumeImplAllocator.createVolume(\n         this, sd.getStorageUuid(), dir, this.conf, storageType);\n     fsVolume.getVolumeMap(volumeMap);\n \n     volumes.addVolume(fsVolume);\n     storageMap.put(sd.getStorageUuid(),\n         new DatanodeStorage(sd.getStorageUuid(),\n                             DatanodeStorage.State.NORMAL,\n                             storageType));\n     asyncDiskService.addVolume(sd.getCurrentDir());\n \n     LOG.info(\"Added volume - \" + dir + \", StorageType: \" + storageType);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void addVolume(Collection\u003cStorageLocation\u003e dataLocations,\n      Storage.StorageDirectory sd) throws IOException {\n    final File dir \u003d sd.getCurrentDir();\n    final StorageType storageType \u003d\n        getStorageTypeFromLocations(dataLocations, sd.getRoot());\n\n    // If IOException raises from FsVolumeImpl() or getVolumeMap(), there is\n    // nothing needed to be rolled back to make various data structures, e.g.,\n    // storageMap and asyncDiskService, consistent.\n    FsVolumeImpl fsVolume \u003d FsVolumeImplAllocator.createVolume(\n        this, sd.getStorageUuid(), dir, this.conf, storageType);\n    fsVolume.getVolumeMap(volumeMap);\n\n    volumes.addVolume(fsVolume);\n    storageMap.put(sd.getStorageUuid(),\n        new DatanodeStorage(sd.getStorageUuid(),\n                            DatanodeStorage.State.NORMAL,\n                            storageType));\n    asyncDiskService.addVolume(sd.getCurrentDir());\n\n    LOG.info(\"Added volume - \" + dir + \", StorageType: \" + storageType);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "d758be1f35f6c1c7e9edd491af559721a3b8b8f8": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-6740. Make FSDataset support adding data volumes dynamically. Contributed by Lei Xu.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1616623 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/08/14 3:59 PM",
      "commitName": "d758be1f35f6c1c7e9edd491af559721a3b8b8f8",
      "commitAuthor": "Aaron Myers",
      "diff": "@@ -0,0 +1,22 @@\n+  private void addVolume(Collection\u003cStorageLocation\u003e dataLocations,\n+      Storage.StorageDirectory sd) throws IOException {\n+    final File dir \u003d sd.getCurrentDir();\n+    final StorageType storageType \u003d\n+        getStorageTypeFromLocations(dataLocations, sd.getRoot());\n+\n+    // If IOException raises from FsVolumeImpl() or getVolumeMap(), there is\n+    // nothing needed to be rolled back to make various data structures, e.g.,\n+    // storageMap and asyncDiskService, consistent.\n+    FsVolumeImpl fsVolume \u003d new FsVolumeImpl(\n+        this, sd.getStorageUuid(), dir, this.conf, storageType);\n+    fsVolume.getVolumeMap(volumeMap);\n+\n+    volumes.addVolume(fsVolume);\n+    storageMap.put(sd.getStorageUuid(),\n+        new DatanodeStorage(sd.getStorageUuid(),\n+                            DatanodeStorage.State.NORMAL,\n+                            storageType));\n+    asyncDiskService.addVolume(sd.getCurrentDir());\n+\n+    LOG.info(\"Added volume - \" + dir + \", StorageType: \" + storageType);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void addVolume(Collection\u003cStorageLocation\u003e dataLocations,\n      Storage.StorageDirectory sd) throws IOException {\n    final File dir \u003d sd.getCurrentDir();\n    final StorageType storageType \u003d\n        getStorageTypeFromLocations(dataLocations, sd.getRoot());\n\n    // If IOException raises from FsVolumeImpl() or getVolumeMap(), there is\n    // nothing needed to be rolled back to make various data structures, e.g.,\n    // storageMap and asyncDiskService, consistent.\n    FsVolumeImpl fsVolume \u003d new FsVolumeImpl(\n        this, sd.getStorageUuid(), dir, this.conf, storageType);\n    fsVolume.getVolumeMap(volumeMap);\n\n    volumes.addVolume(fsVolume);\n    storageMap.put(sd.getStorageUuid(),\n        new DatanodeStorage(sd.getStorageUuid(),\n                            DatanodeStorage.State.NORMAL,\n                            storageType));\n    asyncDiskService.addVolume(sd.getCurrentDir());\n\n    LOG.info(\"Added volume - \" + dir + \", StorageType: \" + storageType);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java"
    }
  }
}