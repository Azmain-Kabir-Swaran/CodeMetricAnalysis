{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FsDatasetImpl.java",
  "functionName": "getBlockLocalPathInfo",
  "functionId": "getBlockLocalPathInfo___block-ExtendedBlock",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
  "functionStartLine": 3033,
  "functionEndLine": 3056,
  "numCommitsSeen": 221,
  "timeTaken": 8708,
  "changeHistory": [
    "d7c136b9ed6d99e1b03f5b89723b3a20df359ba8",
    "86c9862bec0248d671e657aa56094a2919b8ac14",
    "8c0638471f8f1dd47667b2d6727d4d2d54e4b48c",
    "24db0812be64e83a48ade01fc1eaaeaedad4dec0",
    "bc13dfb1426944ce45293cb8f444239a7406762c",
    "b6ffb08a467f1b5bc89e5114c462c3117b337be6",
    "2ab10e29d9cca5018064be46a40e3c74423615a8"
  ],
  "changeHistoryShort": {
    "d7c136b9ed6d99e1b03f5b89723b3a20df359ba8": "Ybodychange",
    "86c9862bec0248d671e657aa56094a2919b8ac14": "Ybodychange",
    "8c0638471f8f1dd47667b2d6727d4d2d54e4b48c": "Ybodychange",
    "24db0812be64e83a48ade01fc1eaaeaedad4dec0": "Ybodychange",
    "bc13dfb1426944ce45293cb8f444239a7406762c": "Ymultichange(Ymovefromfile,Ybodychange)",
    "b6ffb08a467f1b5bc89e5114c462c3117b337be6": "Ybodychange",
    "2ab10e29d9cca5018064be46a40e3c74423615a8": "Yintroduced"
  },
  "changeHistoryDetails": {
    "d7c136b9ed6d99e1b03f5b89723b3a20df359ba8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-15150. Introduce read write lock to Datanode. Contributed Stephen O\u0027Donnell.\n\nSigned-off-by: Wei-Chiu Chuang \u003cweichiu@apache.org\u003e\n",
      "commitDate": "11/02/20 8:00 AM",
      "commitName": "d7c136b9ed6d99e1b03f5b89723b3a20df359ba8",
      "commitAuthor": "Stephen O\u0027Donnell",
      "commitDateOld": "28/01/20 10:10 AM",
      "commitNameOld": "1839c467f60cbb8592d446694ec3d7710cda5142",
      "commitAuthorOld": "Inigo Goiri",
      "daysBetweenCommits": 13.91,
      "commitsBetweenForRepo": 33,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,24 @@\n   public BlockLocalPathInfo getBlockLocalPathInfo(ExtendedBlock block)\n       throws IOException {\n-    try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n+    try (AutoCloseableLock lock \u003d datasetWriteLock.acquire()) {\n       final Replica replica \u003d volumeMap.get(block.getBlockPoolId(),\n           block.getBlockId());\n       if (replica \u003d\u003d null) {\n         throw new ReplicaNotFoundException(block);\n       }\n       if (replica.getGenerationStamp() \u003c block.getGenerationStamp()) {\n         throw new IOException(\n             \"Replica generation stamp \u003c block generation stamp, block\u003d\"\n             + block + \", replica\u003d\" + replica);\n       } else if (replica.getGenerationStamp() \u003e block.getGenerationStamp()) {\n         block.setGenerationStamp(replica.getGenerationStamp());\n       }\n     }\n \n     ReplicaInfo r \u003d getBlockReplica(block);\n     File blockFile \u003d new File(r.getBlockURI());\n     File metaFile \u003d new File(r.getMetadataURI());\n     BlockLocalPathInfo info \u003d new BlockLocalPathInfo(block,\n         blockFile.getAbsolutePath(), metaFile.toString());\n     return info;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public BlockLocalPathInfo getBlockLocalPathInfo(ExtendedBlock block)\n      throws IOException {\n    try (AutoCloseableLock lock \u003d datasetWriteLock.acquire()) {\n      final Replica replica \u003d volumeMap.get(block.getBlockPoolId(),\n          block.getBlockId());\n      if (replica \u003d\u003d null) {\n        throw new ReplicaNotFoundException(block);\n      }\n      if (replica.getGenerationStamp() \u003c block.getGenerationStamp()) {\n        throw new IOException(\n            \"Replica generation stamp \u003c block generation stamp, block\u003d\"\n            + block + \", replica\u003d\" + replica);\n      } else if (replica.getGenerationStamp() \u003e block.getGenerationStamp()) {\n        block.setGenerationStamp(replica.getGenerationStamp());\n      }\n    }\n\n    ReplicaInfo r \u003d getBlockReplica(block);\n    File blockFile \u003d new File(r.getBlockURI());\n    File metaFile \u003d new File(r.getMetadataURI());\n    BlockLocalPathInfo info \u003d new BlockLocalPathInfo(block,\n        blockFile.getAbsolutePath(), metaFile.toString());\n    return info;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "86c9862bec0248d671e657aa56094a2919b8ac14": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10636. Modify ReplicaInfo to remove the assumption that replica metadata and data are stored in java.io.File. (Virajith Jalaparti via lei)\n",
      "commitDate": "13/09/16 12:54 PM",
      "commitName": "86c9862bec0248d671e657aa56094a2919b8ac14",
      "commitAuthor": "Lei Xu",
      "commitDateOld": "10/09/16 6:22 PM",
      "commitNameOld": "a99bf26a0899bcc4307c3a242c8414eaef555aa7",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 2.77,
      "commitsBetweenForRepo": 15,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,24 @@\n   public BlockLocalPathInfo getBlockLocalPathInfo(ExtendedBlock block)\n       throws IOException {\n     try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n       final Replica replica \u003d volumeMap.get(block.getBlockPoolId(),\n           block.getBlockId());\n       if (replica \u003d\u003d null) {\n         throw new ReplicaNotFoundException(block);\n       }\n       if (replica.getGenerationStamp() \u003c block.getGenerationStamp()) {\n         throw new IOException(\n             \"Replica generation stamp \u003c block generation stamp, block\u003d\"\n             + block + \", replica\u003d\" + replica);\n       } else if (replica.getGenerationStamp() \u003e block.getGenerationStamp()) {\n         block.setGenerationStamp(replica.getGenerationStamp());\n       }\n     }\n \n-    File datafile \u003d getBlockFile(block);\n-    File metafile \u003d FsDatasetUtil.getMetaFile(datafile, block.getGenerationStamp());\n+    ReplicaInfo r \u003d getBlockReplica(block);\n+    File blockFile \u003d new File(r.getBlockURI());\n+    File metaFile \u003d new File(r.getMetadataURI());\n     BlockLocalPathInfo info \u003d new BlockLocalPathInfo(block,\n-        datafile.getAbsolutePath(), metafile.getAbsolutePath());\n+        blockFile.getAbsolutePath(), metaFile.toString());\n     return info;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public BlockLocalPathInfo getBlockLocalPathInfo(ExtendedBlock block)\n      throws IOException {\n    try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n      final Replica replica \u003d volumeMap.get(block.getBlockPoolId(),\n          block.getBlockId());\n      if (replica \u003d\u003d null) {\n        throw new ReplicaNotFoundException(block);\n      }\n      if (replica.getGenerationStamp() \u003c block.getGenerationStamp()) {\n        throw new IOException(\n            \"Replica generation stamp \u003c block generation stamp, block\u003d\"\n            + block + \", replica\u003d\" + replica);\n      } else if (replica.getGenerationStamp() \u003e block.getGenerationStamp()) {\n        block.setGenerationStamp(replica.getGenerationStamp());\n      }\n    }\n\n    ReplicaInfo r \u003d getBlockReplica(block);\n    File blockFile \u003d new File(r.getBlockURI());\n    File metaFile \u003d new File(r.getMetadataURI());\n    BlockLocalPathInfo info \u003d new BlockLocalPathInfo(block,\n        blockFile.getAbsolutePath(), metaFile.toString());\n    return info;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "8c0638471f8f1dd47667b2d6727d4d2d54e4b48c": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-10682. Replace FsDatasetImpl object lock with a separate lock object. (Chen Liang)\n",
      "commitDate": "08/08/16 12:02 PM",
      "commitName": "8c0638471f8f1dd47667b2d6727d4d2d54e4b48c",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "08/07/16 7:40 PM",
      "commitNameOld": "da6f1b88dd47e22b24d44f6fc8bbee73e85746f7",
      "commitAuthorOld": "Yongjun Zhang",
      "daysBetweenCommits": 30.68,
      "commitsBetweenForRepo": 320,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,23 @@\n   public BlockLocalPathInfo getBlockLocalPathInfo(ExtendedBlock block)\n       throws IOException {\n-    synchronized(this) {\n+    try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n       final Replica replica \u003d volumeMap.get(block.getBlockPoolId(),\n           block.getBlockId());\n       if (replica \u003d\u003d null) {\n         throw new ReplicaNotFoundException(block);\n       }\n       if (replica.getGenerationStamp() \u003c block.getGenerationStamp()) {\n         throw new IOException(\n             \"Replica generation stamp \u003c block generation stamp, block\u003d\"\n             + block + \", replica\u003d\" + replica);\n       } else if (replica.getGenerationStamp() \u003e block.getGenerationStamp()) {\n         block.setGenerationStamp(replica.getGenerationStamp());\n       }\n     }\n \n     File datafile \u003d getBlockFile(block);\n     File metafile \u003d FsDatasetUtil.getMetaFile(datafile, block.getGenerationStamp());\n     BlockLocalPathInfo info \u003d new BlockLocalPathInfo(block,\n         datafile.getAbsolutePath(), metafile.getAbsolutePath());\n     return info;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public BlockLocalPathInfo getBlockLocalPathInfo(ExtendedBlock block)\n      throws IOException {\n    try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n      final Replica replica \u003d volumeMap.get(block.getBlockPoolId(),\n          block.getBlockId());\n      if (replica \u003d\u003d null) {\n        throw new ReplicaNotFoundException(block);\n      }\n      if (replica.getGenerationStamp() \u003c block.getGenerationStamp()) {\n        throw new IOException(\n            \"Replica generation stamp \u003c block generation stamp, block\u003d\"\n            + block + \", replica\u003d\" + replica);\n      } else if (replica.getGenerationStamp() \u003e block.getGenerationStamp()) {\n        block.setGenerationStamp(replica.getGenerationStamp());\n      }\n    }\n\n    File datafile \u003d getBlockFile(block);\n    File metafile \u003d FsDatasetUtil.getMetaFile(datafile, block.getGenerationStamp());\n    BlockLocalPathInfo info \u003d new BlockLocalPathInfo(block,\n        datafile.getAbsolutePath(), metafile.getAbsolutePath());\n    return info;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "24db0812be64e83a48ade01fc1eaaeaedad4dec0": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7885. Datanode should not trust the generation stamp provided by client. Contributed by Tsz Wo Nicholas Sze.\n",
      "commitDate": "06/03/15 10:55 AM",
      "commitName": "24db0812be64e83a48ade01fc1eaaeaedad4dec0",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "21/02/15 3:38 PM",
      "commitNameOld": "8b465b4b8caed31ca9daeaae108f9a868a30a455",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 12.8,
      "commitsBetweenForRepo": 101,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,8 +1,23 @@\n   public BlockLocalPathInfo getBlockLocalPathInfo(ExtendedBlock block)\n       throws IOException {\n+    synchronized(this) {\n+      final Replica replica \u003d volumeMap.get(block.getBlockPoolId(),\n+          block.getBlockId());\n+      if (replica \u003d\u003d null) {\n+        throw new ReplicaNotFoundException(block);\n+      }\n+      if (replica.getGenerationStamp() \u003c block.getGenerationStamp()) {\n+        throw new IOException(\n+            \"Replica generation stamp \u003c block generation stamp, block\u003d\"\n+            + block + \", replica\u003d\" + replica);\n+      } else if (replica.getGenerationStamp() \u003e block.getGenerationStamp()) {\n+        block.setGenerationStamp(replica.getGenerationStamp());\n+      }\n+    }\n+\n     File datafile \u003d getBlockFile(block);\n     File metafile \u003d FsDatasetUtil.getMetaFile(datafile, block.getGenerationStamp());\n     BlockLocalPathInfo info \u003d new BlockLocalPathInfo(block,\n         datafile.getAbsolutePath(), metafile.getAbsolutePath());\n     return info;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public BlockLocalPathInfo getBlockLocalPathInfo(ExtendedBlock block)\n      throws IOException {\n    synchronized(this) {\n      final Replica replica \u003d volumeMap.get(block.getBlockPoolId(),\n          block.getBlockId());\n      if (replica \u003d\u003d null) {\n        throw new ReplicaNotFoundException(block);\n      }\n      if (replica.getGenerationStamp() \u003c block.getGenerationStamp()) {\n        throw new IOException(\n            \"Replica generation stamp \u003c block generation stamp, block\u003d\"\n            + block + \", replica\u003d\" + replica);\n      } else if (replica.getGenerationStamp() \u003e block.getGenerationStamp()) {\n        block.setGenerationStamp(replica.getGenerationStamp());\n      }\n    }\n\n    File datafile \u003d getBlockFile(block);\n    File metafile \u003d FsDatasetUtil.getMetaFile(datafile, block.getGenerationStamp());\n    BlockLocalPathInfo info \u003d new BlockLocalPathInfo(block,\n        datafile.getAbsolutePath(), metafile.getAbsolutePath());\n    return info;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "bc13dfb1426944ce45293cb8f444239a7406762c": {
      "type": "Ymultichange(Ymovefromfile,Ybodychange)",
      "commitMessage": "HDFS-3130. Move fsdataset implementation to a package.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1308437 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/04/12 10:38 AM",
      "commitName": "bc13dfb1426944ce45293cb8f444239a7406762c",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-3130. Move fsdataset implementation to a package.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1308437 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "02/04/12 10:38 AM",
          "commitName": "bc13dfb1426944ce45293cb8f444239a7406762c",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "01/04/12 8:48 PM",
          "commitNameOld": "a4ccb8f504e79802f1b3c69acbcbb00b2343c529",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 0.58,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,8 +1,8 @@\n   public BlockLocalPathInfo getBlockLocalPathInfo(ExtendedBlock block)\n       throws IOException {\n     File datafile \u003d getBlockFile(block);\n-    File metafile \u003d DatanodeUtil.getMetaFile(datafile, block.getGenerationStamp());\n+    File metafile \u003d FsDatasetUtil.getMetaFile(datafile, block.getGenerationStamp());\n     BlockLocalPathInfo info \u003d new BlockLocalPathInfo(block,\n         datafile.getAbsolutePath(), metafile.getAbsolutePath());\n     return info;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public BlockLocalPathInfo getBlockLocalPathInfo(ExtendedBlock block)\n      throws IOException {\n    File datafile \u003d getBlockFile(block);\n    File metafile \u003d FsDatasetUtil.getMetaFile(datafile, block.getGenerationStamp());\n    BlockLocalPathInfo info \u003d new BlockLocalPathInfo(block,\n        datafile.getAbsolutePath(), metafile.getAbsolutePath());\n    return info;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/FSDataset.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
            "oldMethodName": "getBlockLocalPathInfo",
            "newMethodName": "getBlockLocalPathInfo"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-3130. Move fsdataset implementation to a package.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1308437 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "02/04/12 10:38 AM",
          "commitName": "bc13dfb1426944ce45293cb8f444239a7406762c",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "01/04/12 8:48 PM",
          "commitNameOld": "a4ccb8f504e79802f1b3c69acbcbb00b2343c529",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 0.58,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,8 +1,8 @@\n   public BlockLocalPathInfo getBlockLocalPathInfo(ExtendedBlock block)\n       throws IOException {\n     File datafile \u003d getBlockFile(block);\n-    File metafile \u003d DatanodeUtil.getMetaFile(datafile, block.getGenerationStamp());\n+    File metafile \u003d FsDatasetUtil.getMetaFile(datafile, block.getGenerationStamp());\n     BlockLocalPathInfo info \u003d new BlockLocalPathInfo(block,\n         datafile.getAbsolutePath(), metafile.getAbsolutePath());\n     return info;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public BlockLocalPathInfo getBlockLocalPathInfo(ExtendedBlock block)\n      throws IOException {\n    File datafile \u003d getBlockFile(block);\n    File metafile \u003d FsDatasetUtil.getMetaFile(datafile, block.getGenerationStamp());\n    BlockLocalPathInfo info \u003d new BlockLocalPathInfo(block,\n        datafile.getAbsolutePath(), metafile.getAbsolutePath());\n    return info;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
          "extendedDetails": {}
        }
      ]
    },
    "b6ffb08a467f1b5bc89e5114c462c3117b337be6": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2887. FSVolume, is a part of FSDatasetInterface implementation, should not be referred outside FSDataset.  A new FSVolumeInterface is defined.  The BlockVolumeChoosingPolicy.chooseVolume(..) method signature is also updated.  (szetszwo)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1242087 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/02/12 12:58 PM",
      "commitName": "b6ffb08a467f1b5bc89e5114c462c3117b337be6",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "02/02/12 11:26 PM",
      "commitNameOld": "38ad4b503686a0d18cb2d42ffdecf06f0ba7b98f",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 5.56,
      "commitsBetweenForRepo": 61,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,8 +1,8 @@\n   public BlockLocalPathInfo getBlockLocalPathInfo(ExtendedBlock block)\n       throws IOException {\n     File datafile \u003d getBlockFile(block);\n-    File metafile \u003d getMetaFile(datafile, block.getGenerationStamp());\n+    File metafile \u003d DatanodeUtil.getMetaFile(datafile, block.getGenerationStamp());\n     BlockLocalPathInfo info \u003d new BlockLocalPathInfo(block,\n         datafile.getAbsolutePath(), metafile.getAbsolutePath());\n     return info;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public BlockLocalPathInfo getBlockLocalPathInfo(ExtendedBlock block)\n      throws IOException {\n    File datafile \u003d getBlockFile(block);\n    File metafile \u003d DatanodeUtil.getMetaFile(datafile, block.getGenerationStamp());\n    BlockLocalPathInfo info \u003d new BlockLocalPathInfo(block,\n        datafile.getAbsolutePath(), metafile.getAbsolutePath());\n    return info;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/FSDataset.java",
      "extendedDetails": {}
    },
    "2ab10e29d9cca5018064be46a40e3c74423615a8": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-2246. Enable reading a block directly from local file system for a client on the same node as the block file.  Contributed by Andrew Purtell, Suresh Srinivas and Jitendra Nath Pandey\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1204792 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/11/11 6:57 PM",
      "commitName": "2ab10e29d9cca5018064be46a40e3c74423615a8",
      "commitAuthor": "Tsz-wo Sze",
      "diff": "@@ -0,0 +1,8 @@\n+  public BlockLocalPathInfo getBlockLocalPathInfo(ExtendedBlock block)\n+      throws IOException {\n+    File datafile \u003d getBlockFile(block);\n+    File metafile \u003d getMetaFile(datafile, block.getGenerationStamp());\n+    BlockLocalPathInfo info \u003d new BlockLocalPathInfo(block,\n+        datafile.getAbsolutePath(), metafile.getAbsolutePath());\n+    return info;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public BlockLocalPathInfo getBlockLocalPathInfo(ExtendedBlock block)\n      throws IOException {\n    File datafile \u003d getBlockFile(block);\n    File metafile \u003d getMetaFile(datafile, block.getGenerationStamp());\n    BlockLocalPathInfo info \u003d new BlockLocalPathInfo(block,\n        datafile.getAbsolutePath(), metafile.getAbsolutePath());\n    return info;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/FSDataset.java"
    }
  }
}