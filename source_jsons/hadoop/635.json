{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockReaderLocalLegacy.java",
  "functionName": "getSlowReadBufferNumChunks",
  "functionId": "getSlowReadBufferNumChunks___bufferSizeBytes-int__bytesPerChecksum-int",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/client/impl/BlockReaderLocalLegacy.java",
  "functionStartLine": 304,
  "functionEndLine": 316,
  "numCommitsSeen": 34,
  "timeTaken": 3588,
  "changeHistory": [
    "f308561f1d885491b88db73ac63003202056d661",
    "e2c9b288b223b9fd82dc12018936e13128413492",
    "75bbcc8bf3fa1daf54f56868dae737f6da12ab1f",
    "c68b1d1b31e304c27e419e810ded0fc97e435ea6",
    "bbb24fbf5d220fbe137d43651ba3802a9806b1a3",
    "694a6721316aea14c1244447974231abc8dff0cb"
  ],
  "changeHistoryShort": {
    "f308561f1d885491b88db73ac63003202056d661": "Yfilerename",
    "e2c9b288b223b9fd82dc12018936e13128413492": "Yfilerename",
    "75bbcc8bf3fa1daf54f56868dae737f6da12ab1f": "Ybodychange",
    "c68b1d1b31e304c27e419e810ded0fc97e435ea6": "Ymultichange(Yparameterchange,Ybodychange)",
    "bbb24fbf5d220fbe137d43651ba3802a9806b1a3": "Ybodychange",
    "694a6721316aea14c1244447974231abc8dff0cb": "Yintroduced"
  },
  "changeHistoryDetails": {
    "f308561f1d885491b88db73ac63003202056d661": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8057 Move BlockReader implementation to the client implementation package.  Contributed by Takanobu Asanuma\n",
      "commitDate": "25/04/16 12:01 PM",
      "commitName": "f308561f1d885491b88db73ac63003202056d661",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "25/04/16 9:38 AM",
      "commitNameOld": "10f0f7851a3255caab775777e8fb6c2781d97062",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 0.1,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private static int getSlowReadBufferNumChunks(int bufferSizeBytes,\n      int bytesPerChecksum) {\n    if (bufferSizeBytes \u003c bytesPerChecksum) {\n      throw new IllegalArgumentException(\"Configured BlockReaderLocalLegacy \" +\n          \"buffer size (\" + bufferSizeBytes + \") is not large enough to hold \" +\n          \"a single chunk (\" + bytesPerChecksum +  \"). Please configure \" +\n          HdfsClientConfigKeys.Read.ShortCircuit.BUFFER_SIZE_KEY +\n          \" appropriately\");\n    }\n\n    // Round down to nearest chunk size\n    return bufferSizeBytes / bytesPerChecksum;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/client/impl/BlockReaderLocalLegacy.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocalLegacy.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/client/impl/BlockReaderLocalLegacy.java"
      }
    },
    "e2c9b288b223b9fd82dc12018936e13128413492": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8925. Move BlockReaderLocal to hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "28/08/15 2:38 PM",
      "commitName": "e2c9b288b223b9fd82dc12018936e13128413492",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "28/08/15 2:21 PM",
      "commitNameOld": "b94b56806d3d6e04984e229b479f7ac15b62bbfa",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private static int getSlowReadBufferNumChunks(int bufferSizeBytes,\n      int bytesPerChecksum) {\n    if (bufferSizeBytes \u003c bytesPerChecksum) {\n      throw new IllegalArgumentException(\"Configured BlockReaderLocalLegacy \" +\n          \"buffer size (\" + bufferSizeBytes + \") is not large enough to hold \" +\n          \"a single chunk (\" + bytesPerChecksum +  \"). Please configure \" +\n          HdfsClientConfigKeys.Read.ShortCircuit.BUFFER_SIZE_KEY +\n          \" appropriately\");\n    }\n\n    // Round down to nearest chunk size\n    return bufferSizeBytes / bytesPerChecksum;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocalLegacy.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocalLegacy.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocalLegacy.java"
      }
    },
    "75bbcc8bf3fa1daf54f56868dae737f6da12ab1f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8082. Move dfs.client.read.*, dfs.client.short.circuit.*, dfs.client.mmap.* and dfs.client.hedged.read.* conf from DFSConfigKeys to HdfsClientConfigKeys.\n",
      "commitDate": "16/04/15 1:22 PM",
      "commitName": "75bbcc8bf3fa1daf54f56868dae737f6da12ab1f",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "10/04/15 2:48 PM",
      "commitNameOld": "2cc9514ad643ae49d30524743420ee9744e571bd",
      "commitAuthorOld": "Tsz-Wo Nicholas Sze",
      "daysBetweenCommits": 5.94,
      "commitsBetweenForRepo": 36,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,13 @@\n   private static int getSlowReadBufferNumChunks(int bufferSizeBytes,\n       int bytesPerChecksum) {\n     if (bufferSizeBytes \u003c bytesPerChecksum) {\n       throw new IllegalArgumentException(\"Configured BlockReaderLocalLegacy \" +\n           \"buffer size (\" + bufferSizeBytes + \") is not large enough to hold \" +\n           \"a single chunk (\" + bytesPerChecksum +  \"). Please configure \" +\n-          DFSConfigKeys.DFS_CLIENT_READ_SHORTCIRCUIT_BUFFER_SIZE_KEY +\n+          HdfsClientConfigKeys.Read.ShortCircuit.BUFFER_SIZE_KEY +\n           \" appropriately\");\n     }\n \n     // Round down to nearest chunk size\n     return bufferSizeBytes / bytesPerChecksum;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private static int getSlowReadBufferNumChunks(int bufferSizeBytes,\n      int bytesPerChecksum) {\n    if (bufferSizeBytes \u003c bytesPerChecksum) {\n      throw new IllegalArgumentException(\"Configured BlockReaderLocalLegacy \" +\n          \"buffer size (\" + bufferSizeBytes + \") is not large enough to hold \" +\n          \"a single chunk (\" + bytesPerChecksum +  \"). Please configure \" +\n          HdfsClientConfigKeys.Read.ShortCircuit.BUFFER_SIZE_KEY +\n          \" appropriately\");\n    }\n\n    // Round down to nearest chunk size\n    return bufferSizeBytes / bytesPerChecksum;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocalLegacy.java",
      "extendedDetails": {}
    },
    "c68b1d1b31e304c27e419e810ded0fc97e435ea6": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-4914. Use DFSClient.Conf instead of Configuration.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1494854 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/06/13 9:43 PM",
      "commitName": "c68b1d1b31e304c27e419e810ded0fc97e435ea6",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-4914. Use DFSClient.Conf instead of Configuration.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1494854 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "19/06/13 9:43 PM",
          "commitName": "c68b1d1b31e304c27e419e810ded0fc97e435ea6",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "10/05/13 10:58 AM",
          "commitNameOld": "4ed1fc58c0683bbcd5c4c211ea162ed37bf7dc4f",
          "commitAuthorOld": "Aaron Myers",
          "daysBetweenCommits": 40.45,
          "commitsBetweenForRepo": 278,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,15 +1,13 @@\n-  private static int getSlowReadBufferNumChunks(Configuration conf, int bytesPerChecksum) {\n-    int bufferSizeBytes \u003d conf.getInt(DFSConfigKeys.DFS_CLIENT_READ_SHORTCIRCUIT_BUFFER_SIZE_KEY,\n-        DFSConfigKeys.DFS_CLIENT_READ_SHORTCIRCUIT_BUFFER_SIZE_DEFAULT);\n-\n+  private static int getSlowReadBufferNumChunks(int bufferSizeBytes,\n+      int bytesPerChecksum) {\n     if (bufferSizeBytes \u003c bytesPerChecksum) {\n       throw new IllegalArgumentException(\"Configured BlockReaderLocalLegacy \" +\n           \"buffer size (\" + bufferSizeBytes + \") is not large enough to hold \" +\n           \"a single chunk (\" + bytesPerChecksum +  \"). Please configure \" +\n           DFSConfigKeys.DFS_CLIENT_READ_SHORTCIRCUIT_BUFFER_SIZE_KEY +\n           \" appropriately\");\n     }\n \n     // Round down to nearest chunk size\n     return bufferSizeBytes / bytesPerChecksum;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private static int getSlowReadBufferNumChunks(int bufferSizeBytes,\n      int bytesPerChecksum) {\n    if (bufferSizeBytes \u003c bytesPerChecksum) {\n      throw new IllegalArgumentException(\"Configured BlockReaderLocalLegacy \" +\n          \"buffer size (\" + bufferSizeBytes + \") is not large enough to hold \" +\n          \"a single chunk (\" + bytesPerChecksum +  \"). Please configure \" +\n          DFSConfigKeys.DFS_CLIENT_READ_SHORTCIRCUIT_BUFFER_SIZE_KEY +\n          \" appropriately\");\n    }\n\n    // Round down to nearest chunk size\n    return bufferSizeBytes / bytesPerChecksum;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocalLegacy.java",
          "extendedDetails": {
            "oldValue": "[conf-Configuration, bytesPerChecksum-int]",
            "newValue": "[bufferSizeBytes-int, bytesPerChecksum-int]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-4914. Use DFSClient.Conf instead of Configuration.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1494854 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "19/06/13 9:43 PM",
          "commitName": "c68b1d1b31e304c27e419e810ded0fc97e435ea6",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "10/05/13 10:58 AM",
          "commitNameOld": "4ed1fc58c0683bbcd5c4c211ea162ed37bf7dc4f",
          "commitAuthorOld": "Aaron Myers",
          "daysBetweenCommits": 40.45,
          "commitsBetweenForRepo": 278,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,15 +1,13 @@\n-  private static int getSlowReadBufferNumChunks(Configuration conf, int bytesPerChecksum) {\n-    int bufferSizeBytes \u003d conf.getInt(DFSConfigKeys.DFS_CLIENT_READ_SHORTCIRCUIT_BUFFER_SIZE_KEY,\n-        DFSConfigKeys.DFS_CLIENT_READ_SHORTCIRCUIT_BUFFER_SIZE_DEFAULT);\n-\n+  private static int getSlowReadBufferNumChunks(int bufferSizeBytes,\n+      int bytesPerChecksum) {\n     if (bufferSizeBytes \u003c bytesPerChecksum) {\n       throw new IllegalArgumentException(\"Configured BlockReaderLocalLegacy \" +\n           \"buffer size (\" + bufferSizeBytes + \") is not large enough to hold \" +\n           \"a single chunk (\" + bytesPerChecksum +  \"). Please configure \" +\n           DFSConfigKeys.DFS_CLIENT_READ_SHORTCIRCUIT_BUFFER_SIZE_KEY +\n           \" appropriately\");\n     }\n \n     // Round down to nearest chunk size\n     return bufferSizeBytes / bytesPerChecksum;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private static int getSlowReadBufferNumChunks(int bufferSizeBytes,\n      int bytesPerChecksum) {\n    if (bufferSizeBytes \u003c bytesPerChecksum) {\n      throw new IllegalArgumentException(\"Configured BlockReaderLocalLegacy \" +\n          \"buffer size (\" + bufferSizeBytes + \") is not large enough to hold \" +\n          \"a single chunk (\" + bytesPerChecksum +  \"). Please configure \" +\n          DFSConfigKeys.DFS_CLIENT_READ_SHORTCIRCUIT_BUFFER_SIZE_KEY +\n          \" appropriately\");\n    }\n\n    // Round down to nearest chunk size\n    return bufferSizeBytes / bytesPerChecksum;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocalLegacy.java",
          "extendedDetails": {}
        }
      ]
    },
    "bbb24fbf5d220fbe137d43651ba3802a9806b1a3": {
      "type": "Ybodychange",
      "commitMessage": "Merge trunk into branch.\n\nConflicts resolved:\nC       hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestShortCircuitLocalRead.java\n!     C hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/SocketCache.java\nC       hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java\nC       hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java\nC       hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java\nC       hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocal.java\n\n(thanks to Colin for help resolving)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-347@1462652 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "29/03/13 2:33 PM",
      "commitName": "bbb24fbf5d220fbe137d43651ba3802a9806b1a3",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "27/03/13 12:28 PM",
      "commitNameOld": "694a6721316aea14c1244447974231abc8dff0cb",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 2.09,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,15 @@\n   private static int getSlowReadBufferNumChunks(Configuration conf, int bytesPerChecksum) {\n     int bufferSizeBytes \u003d conf.getInt(DFSConfigKeys.DFS_CLIENT_READ_SHORTCIRCUIT_BUFFER_SIZE_KEY,\n         DFSConfigKeys.DFS_CLIENT_READ_SHORTCIRCUIT_BUFFER_SIZE_DEFAULT);\n \n     if (bufferSizeBytes \u003c bytesPerChecksum) {\n-      throw new IllegalArgumentException(\"Configured BlockReaderLocalLegacy buffer size (\" + bufferSizeBytes + \") \" +\n-          \"is not large enough to hold a single chunk (\" + bytesPerChecksum +  \"). Please configure \" +\n-          DFSConfigKeys.DFS_CLIENT_READ_SHORTCIRCUIT_BUFFER_SIZE_KEY + \" appropriately\");\n+      throw new IllegalArgumentException(\"Configured BlockReaderLocalLegacy \" +\n+          \"buffer size (\" + bufferSizeBytes + \") is not large enough to hold \" +\n+          \"a single chunk (\" + bytesPerChecksum +  \"). Please configure \" +\n+          DFSConfigKeys.DFS_CLIENT_READ_SHORTCIRCUIT_BUFFER_SIZE_KEY +\n+          \" appropriately\");\n     }\n \n     // Round down to nearest chunk size\n     return bufferSizeBytes / bytesPerChecksum;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private static int getSlowReadBufferNumChunks(Configuration conf, int bytesPerChecksum) {\n    int bufferSizeBytes \u003d conf.getInt(DFSConfigKeys.DFS_CLIENT_READ_SHORTCIRCUIT_BUFFER_SIZE_KEY,\n        DFSConfigKeys.DFS_CLIENT_READ_SHORTCIRCUIT_BUFFER_SIZE_DEFAULT);\n\n    if (bufferSizeBytes \u003c bytesPerChecksum) {\n      throw new IllegalArgumentException(\"Configured BlockReaderLocalLegacy \" +\n          \"buffer size (\" + bufferSizeBytes + \") is not large enough to hold \" +\n          \"a single chunk (\" + bytesPerChecksum +  \"). Please configure \" +\n          DFSConfigKeys.DFS_CLIENT_READ_SHORTCIRCUIT_BUFFER_SIZE_KEY +\n          \" appropriately\");\n    }\n\n    // Round down to nearest chunk size\n    return bufferSizeBytes / bytesPerChecksum;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocalLegacy.java",
      "extendedDetails": {}
    },
    "694a6721316aea14c1244447974231abc8dff0cb": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-4538. Allow use of legacy blockreader. Contributed by Colin Patrick McCabe.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-347@1461818 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/03/13 12:28 PM",
      "commitName": "694a6721316aea14c1244447974231abc8dff0cb",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,13 @@\n+  private static int getSlowReadBufferNumChunks(Configuration conf, int bytesPerChecksum) {\n+    int bufferSizeBytes \u003d conf.getInt(DFSConfigKeys.DFS_CLIENT_READ_SHORTCIRCUIT_BUFFER_SIZE_KEY,\n+        DFSConfigKeys.DFS_CLIENT_READ_SHORTCIRCUIT_BUFFER_SIZE_DEFAULT);\n+\n+    if (bufferSizeBytes \u003c bytesPerChecksum) {\n+      throw new IllegalArgumentException(\"Configured BlockReaderLocalLegacy buffer size (\" + bufferSizeBytes + \") \" +\n+          \"is not large enough to hold a single chunk (\" + bytesPerChecksum +  \"). Please configure \" +\n+          DFSConfigKeys.DFS_CLIENT_READ_SHORTCIRCUIT_BUFFER_SIZE_KEY + \" appropriately\");\n+    }\n+\n+    // Round down to nearest chunk size\n+    return bufferSizeBytes / bytesPerChecksum;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private static int getSlowReadBufferNumChunks(Configuration conf, int bytesPerChecksum) {\n    int bufferSizeBytes \u003d conf.getInt(DFSConfigKeys.DFS_CLIENT_READ_SHORTCIRCUIT_BUFFER_SIZE_KEY,\n        DFSConfigKeys.DFS_CLIENT_READ_SHORTCIRCUIT_BUFFER_SIZE_DEFAULT);\n\n    if (bufferSizeBytes \u003c bytesPerChecksum) {\n      throw new IllegalArgumentException(\"Configured BlockReaderLocalLegacy buffer size (\" + bufferSizeBytes + \") \" +\n          \"is not large enough to hold a single chunk (\" + bytesPerChecksum +  \"). Please configure \" +\n          DFSConfigKeys.DFS_CLIENT_READ_SHORTCIRCUIT_BUFFER_SIZE_KEY + \" appropriately\");\n    }\n\n    // Round down to nearest chunk size\n    return bufferSizeBytes / bytesPerChecksum;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocalLegacy.java"
    }
  }
}