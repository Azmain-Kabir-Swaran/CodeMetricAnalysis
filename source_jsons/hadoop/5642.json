{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSTreeTraverser.java",
  "functionName": "traverseDir",
  "functionId": "traverseDir___parent-INodeDirectory(modifiers-final)__startId-long(modifiers-final)__startAfter-byte[]__traverseInfo-TraverseInfo(modifiers-final)",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSTreeTraverser.java",
  "functionStartLine": 87,
  "functionEndLine": 109,
  "numCommitsSeen": 3,
  "timeTaken": 884,
  "changeHistory": [
    "f89594f0b80e8efffdcb887daa4a18a2b0a228b3"
  ],
  "changeHistoryShort": {
    "f89594f0b80e8efffdcb887daa4a18a2b0a228b3": "Yintroduced"
  },
  "changeHistoryDetails": {
    "f89594f0b80e8efffdcb887daa4a18a2b0a228b3": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-13328. Abstract ReencryptionHandler recursive logic in separate class. Contributed by Surendra Singh Lilhore.\n",
      "commitDate": "10/04/18 11:05 AM",
      "commitName": "f89594f0b80e8efffdcb887daa4a18a2b0a228b3",
      "commitAuthor": "Rakesh Radhakrishnan",
      "diff": "@@ -0,0 +1,23 @@\n+  protected void traverseDir(final INodeDirectory parent, final long startId,\n+      byte[] startAfter, final TraverseInfo traverseInfo)\n+      throws IOException, InterruptedException {\n+    List\u003cbyte[]\u003e startAfters \u003d new ArrayList\u003c\u003e();\n+    if (parent \u003d\u003d null) {\n+      return;\n+    }\n+    INode curr \u003d parent;\n+    // construct startAfters all the way up to the zone inode.\n+    startAfters.add(startAfter);\n+    while (curr.getId() !\u003d startId) {\n+      startAfters.add(0, curr.getLocalNameBytes());\n+      curr \u003d curr.getParent();\n+    }\n+    curr \u003d traverseDirInt(startId, parent, startAfters, traverseInfo);\n+    while (!startAfters.isEmpty()) {\n+      if (curr \u003d\u003d null) {\n+        // lock was reacquired, re-resolve path.\n+        curr \u003d resolvePaths(startId, startAfters);\n+      }\n+      curr \u003d traverseDirInt(startId, curr, startAfters, traverseInfo);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  protected void traverseDir(final INodeDirectory parent, final long startId,\n      byte[] startAfter, final TraverseInfo traverseInfo)\n      throws IOException, InterruptedException {\n    List\u003cbyte[]\u003e startAfters \u003d new ArrayList\u003c\u003e();\n    if (parent \u003d\u003d null) {\n      return;\n    }\n    INode curr \u003d parent;\n    // construct startAfters all the way up to the zone inode.\n    startAfters.add(startAfter);\n    while (curr.getId() !\u003d startId) {\n      startAfters.add(0, curr.getLocalNameBytes());\n      curr \u003d curr.getParent();\n    }\n    curr \u003d traverseDirInt(startId, parent, startAfters, traverseInfo);\n    while (!startAfters.isEmpty()) {\n      if (curr \u003d\u003d null) {\n        // lock was reacquired, re-resolve path.\n        curr \u003d resolvePaths(startId, startAfters);\n      }\n      curr \u003d traverseDirInt(startId, curr, startAfters, traverseInfo);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSTreeTraverser.java"
    }
  }
}