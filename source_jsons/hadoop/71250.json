{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "AuditReplayMapper.java",
  "functionName": "cleanup",
  "functionId": "cleanup___context-Mapper.Context",
  "sourceFilePath": "hadoop-tools/hadoop-dynamometer/hadoop-dynamometer-workload/src/main/java/org/apache/hadoop/tools/dynamometer/workloadgenerator/audit/AuditReplayMapper.java",
  "functionStartLine": 261,
  "functionEndLine": 293,
  "numCommitsSeen": 3,
  "timeTaken": 1276,
  "changeHistory": [
    "477505ccfc480f2605a7b65de95ea6f6ff5ce090",
    "ab0b180ddb5d0775a2452d5eeb7badd252aadb91"
  ],
  "changeHistoryShort": {
    "477505ccfc480f2605a7b65de95ea6f6ff5ce090": "Ymultichange(Yexceptionschange,Ybodychange)",
    "ab0b180ddb5d0775a2452d5eeb7badd252aadb91": "Yintroduced"
  },
  "changeHistoryDetails": {
    "477505ccfc480f2605a7b65de95ea6f6ff5ce090": {
      "type": "Ymultichange(Yexceptionschange,Ybodychange)",
      "commitMessage": "HDFS-14824. [Dynamometer] Dynamometer in org.apache.hadoop.tools does not output the benchmark results. (#1685)\n\n\r\n",
      "commitDate": "01/11/19 9:32 AM",
      "commitName": "477505ccfc480f2605a7b65de95ea6f6ff5ce090",
      "commitAuthor": "Takanobu Asanuma",
      "subchanges": [
        {
          "type": "Yexceptionschange",
          "commitMessage": "HDFS-14824. [Dynamometer] Dynamometer in org.apache.hadoop.tools does not output the benchmark results. (#1685)\n\n\r\n",
          "commitDate": "01/11/19 9:32 AM",
          "commitName": "477505ccfc480f2605a7b65de95ea6f6ff5ce090",
          "commitAuthor": "Takanobu Asanuma",
          "commitDateOld": "08/07/19 5:44 PM",
          "commitNameOld": "738c09349eb6178065797fc9cd624bf5e2285069",
          "commitAuthorOld": "Masatake Iwasaki",
          "daysBetweenCommits": 115.66,
          "commitsBetweenForRepo": 909,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,31 +1,33 @@\n-  public void cleanup(Mapper.Context context) throws InterruptedException {\n+  public void cleanup(Mapper.Context context)\n+      throws InterruptedException, IOException {\n     for (AuditReplayThread t : threads) {\n       // Add in an indicator for each thread to shut down after the last real\n       // command\n       t.addToQueue(AuditReplayCommand.getPoisonPill(highestTimestamp + 1));\n     }\n     Optional\u003cException\u003e threadException \u003d Optional.empty();\n     for (AuditReplayThread t : threads) {\n       t.join();\n       t.drainCounters(context);\n+      t.drainCommandLatencies(context);\n       if (t.getException() !\u003d null) {\n         threadException \u003d Optional.of(t.getException());\n       }\n     }\n     progressExecutor.shutdown();\n \n     if (threadException.isPresent()) {\n       throw new RuntimeException(\"Exception in AuditReplayThread\",\n           threadException.get());\n     }\n     LOG.info(\"Time taken to replay the logs in ms: \"\n         + (System.currentTimeMillis() - startTimestampMs));\n     long totalCommands \u003d context.getCounter(REPLAYCOUNTERS.TOTALCOMMANDS)\n         .getValue();\n     if (totalCommands !\u003d 0) {\n       double percentageOfInvalidOps \u003d\n           context.getCounter(REPLAYCOUNTERS.TOTALINVALIDCOMMANDS).getValue()\n               * 100.0 / totalCommands;\n       LOG.info(\"Percentage of invalid ops: \" + percentageOfInvalidOps);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void cleanup(Mapper.Context context)\n      throws InterruptedException, IOException {\n    for (AuditReplayThread t : threads) {\n      // Add in an indicator for each thread to shut down after the last real\n      // command\n      t.addToQueue(AuditReplayCommand.getPoisonPill(highestTimestamp + 1));\n    }\n    Optional\u003cException\u003e threadException \u003d Optional.empty();\n    for (AuditReplayThread t : threads) {\n      t.join();\n      t.drainCounters(context);\n      t.drainCommandLatencies(context);\n      if (t.getException() !\u003d null) {\n        threadException \u003d Optional.of(t.getException());\n      }\n    }\n    progressExecutor.shutdown();\n\n    if (threadException.isPresent()) {\n      throw new RuntimeException(\"Exception in AuditReplayThread\",\n          threadException.get());\n    }\n    LOG.info(\"Time taken to replay the logs in ms: \"\n        + (System.currentTimeMillis() - startTimestampMs));\n    long totalCommands \u003d context.getCounter(REPLAYCOUNTERS.TOTALCOMMANDS)\n        .getValue();\n    if (totalCommands !\u003d 0) {\n      double percentageOfInvalidOps \u003d\n          context.getCounter(REPLAYCOUNTERS.TOTALINVALIDCOMMANDS).getValue()\n              * 100.0 / totalCommands;\n      LOG.info(\"Percentage of invalid ops: \" + percentageOfInvalidOps);\n    }\n  }",
          "path": "hadoop-tools/hadoop-dynamometer/hadoop-dynamometer-workload/src/main/java/org/apache/hadoop/tools/dynamometer/workloadgenerator/audit/AuditReplayMapper.java",
          "extendedDetails": {
            "oldValue": "[InterruptedException]",
            "newValue": "[InterruptedException, IOException]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-14824. [Dynamometer] Dynamometer in org.apache.hadoop.tools does not output the benchmark results. (#1685)\n\n\r\n",
          "commitDate": "01/11/19 9:32 AM",
          "commitName": "477505ccfc480f2605a7b65de95ea6f6ff5ce090",
          "commitAuthor": "Takanobu Asanuma",
          "commitDateOld": "08/07/19 5:44 PM",
          "commitNameOld": "738c09349eb6178065797fc9cd624bf5e2285069",
          "commitAuthorOld": "Masatake Iwasaki",
          "daysBetweenCommits": 115.66,
          "commitsBetweenForRepo": 909,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,31 +1,33 @@\n-  public void cleanup(Mapper.Context context) throws InterruptedException {\n+  public void cleanup(Mapper.Context context)\n+      throws InterruptedException, IOException {\n     for (AuditReplayThread t : threads) {\n       // Add in an indicator for each thread to shut down after the last real\n       // command\n       t.addToQueue(AuditReplayCommand.getPoisonPill(highestTimestamp + 1));\n     }\n     Optional\u003cException\u003e threadException \u003d Optional.empty();\n     for (AuditReplayThread t : threads) {\n       t.join();\n       t.drainCounters(context);\n+      t.drainCommandLatencies(context);\n       if (t.getException() !\u003d null) {\n         threadException \u003d Optional.of(t.getException());\n       }\n     }\n     progressExecutor.shutdown();\n \n     if (threadException.isPresent()) {\n       throw new RuntimeException(\"Exception in AuditReplayThread\",\n           threadException.get());\n     }\n     LOG.info(\"Time taken to replay the logs in ms: \"\n         + (System.currentTimeMillis() - startTimestampMs));\n     long totalCommands \u003d context.getCounter(REPLAYCOUNTERS.TOTALCOMMANDS)\n         .getValue();\n     if (totalCommands !\u003d 0) {\n       double percentageOfInvalidOps \u003d\n           context.getCounter(REPLAYCOUNTERS.TOTALINVALIDCOMMANDS).getValue()\n               * 100.0 / totalCommands;\n       LOG.info(\"Percentage of invalid ops: \" + percentageOfInvalidOps);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void cleanup(Mapper.Context context)\n      throws InterruptedException, IOException {\n    for (AuditReplayThread t : threads) {\n      // Add in an indicator for each thread to shut down after the last real\n      // command\n      t.addToQueue(AuditReplayCommand.getPoisonPill(highestTimestamp + 1));\n    }\n    Optional\u003cException\u003e threadException \u003d Optional.empty();\n    for (AuditReplayThread t : threads) {\n      t.join();\n      t.drainCounters(context);\n      t.drainCommandLatencies(context);\n      if (t.getException() !\u003d null) {\n        threadException \u003d Optional.of(t.getException());\n      }\n    }\n    progressExecutor.shutdown();\n\n    if (threadException.isPresent()) {\n      throw new RuntimeException(\"Exception in AuditReplayThread\",\n          threadException.get());\n    }\n    LOG.info(\"Time taken to replay the logs in ms: \"\n        + (System.currentTimeMillis() - startTimestampMs));\n    long totalCommands \u003d context.getCounter(REPLAYCOUNTERS.TOTALCOMMANDS)\n        .getValue();\n    if (totalCommands !\u003d 0) {\n      double percentageOfInvalidOps \u003d\n          context.getCounter(REPLAYCOUNTERS.TOTALINVALIDCOMMANDS).getValue()\n              * 100.0 / totalCommands;\n      LOG.info(\"Percentage of invalid ops: \" + percentageOfInvalidOps);\n    }\n  }",
          "path": "hadoop-tools/hadoop-dynamometer/hadoop-dynamometer-workload/src/main/java/org/apache/hadoop/tools/dynamometer/workloadgenerator/audit/AuditReplayMapper.java",
          "extendedDetails": {}
        }
      ]
    },
    "ab0b180ddb5d0775a2452d5eeb7badd252aadb91": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-12345 Add Dynamometer to hadoop-tools, a tool for scale testing the HDFS NameNode with real metadata and workloads. Contributed by Erik Krogen.\n",
      "commitDate": "25/06/19 8:07 AM",
      "commitName": "ab0b180ddb5d0775a2452d5eeb7badd252aadb91",
      "commitAuthor": "Erik Krogen",
      "diff": "@@ -0,0 +1,31 @@\n+  public void cleanup(Mapper.Context context) throws InterruptedException {\n+    for (AuditReplayThread t : threads) {\n+      // Add in an indicator for each thread to shut down after the last real\n+      // command\n+      t.addToQueue(AuditReplayCommand.getPoisonPill(highestTimestamp + 1));\n+    }\n+    Optional\u003cException\u003e threadException \u003d Optional.empty();\n+    for (AuditReplayThread t : threads) {\n+      t.join();\n+      t.drainCounters(context);\n+      if (t.getException() !\u003d null) {\n+        threadException \u003d Optional.of(t.getException());\n+      }\n+    }\n+    progressExecutor.shutdown();\n+\n+    if (threadException.isPresent()) {\n+      throw new RuntimeException(\"Exception in AuditReplayThread\",\n+          threadException.get());\n+    }\n+    LOG.info(\"Time taken to replay the logs in ms: \"\n+        + (System.currentTimeMillis() - startTimestampMs));\n+    long totalCommands \u003d context.getCounter(REPLAYCOUNTERS.TOTALCOMMANDS)\n+        .getValue();\n+    if (totalCommands !\u003d 0) {\n+      double percentageOfInvalidOps \u003d\n+          context.getCounter(REPLAYCOUNTERS.TOTALINVALIDCOMMANDS).getValue()\n+              * 100.0 / totalCommands;\n+      LOG.info(\"Percentage of invalid ops: \" + percentageOfInvalidOps);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void cleanup(Mapper.Context context) throws InterruptedException {\n    for (AuditReplayThread t : threads) {\n      // Add in an indicator for each thread to shut down after the last real\n      // command\n      t.addToQueue(AuditReplayCommand.getPoisonPill(highestTimestamp + 1));\n    }\n    Optional\u003cException\u003e threadException \u003d Optional.empty();\n    for (AuditReplayThread t : threads) {\n      t.join();\n      t.drainCounters(context);\n      if (t.getException() !\u003d null) {\n        threadException \u003d Optional.of(t.getException());\n      }\n    }\n    progressExecutor.shutdown();\n\n    if (threadException.isPresent()) {\n      throw new RuntimeException(\"Exception in AuditReplayThread\",\n          threadException.get());\n    }\n    LOG.info(\"Time taken to replay the logs in ms: \"\n        + (System.currentTimeMillis() - startTimestampMs));\n    long totalCommands \u003d context.getCounter(REPLAYCOUNTERS.TOTALCOMMANDS)\n        .getValue();\n    if (totalCommands !\u003d 0) {\n      double percentageOfInvalidOps \u003d\n          context.getCounter(REPLAYCOUNTERS.TOTALINVALIDCOMMANDS).getValue()\n              * 100.0 / totalCommands;\n      LOG.info(\"Percentage of invalid ops: \" + percentageOfInvalidOps);\n    }\n  }",
      "path": "hadoop-tools/hadoop-dynamometer/hadoop-dynamometer-workload/src/main/java/org/apache/hadoop/tools/dynamometer/workloadgenerator/audit/AuditReplayMapper.java"
    }
  }
}