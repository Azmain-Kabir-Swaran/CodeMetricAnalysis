{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "OpenFileCtx.java",
  "functionName": "checkCommit",
  "functionId": "checkCommit___dfsClient-DFSClient__commitOffset-long__channel-Channel__xid-int__preOpAttr-Nfs3FileAttributes__fromRead-boolean",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
  "functionStartLine": 769,
  "functionEndLine": 803,
  "numCommitsSeen": 61,
  "timeTaken": 2709,
  "changeHistory": [
    "f20dc0d5770d3876954faf0a6e8dcce6539ffc23",
    "f37849188b05a6251584de1aed5e66d5dfa7da4f",
    "5ea533c2bfc72fd3adbfd972d18806fbc397e0f8",
    "a2200a64175867a1c66cf8338f536ccaaaa36508",
    "7429debd866b3ebf41b9aae4a602b240a8387b2b",
    "5c02d2f6225144772dcb975d3144b057b71d6476",
    "28e3d09230971b32f74284311931525cb7ad1b7c",
    "37f587563a943a827fbff865f5302bac6d202415"
  ],
  "changeHistoryShort": {
    "f20dc0d5770d3876954faf0a6e8dcce6539ffc23": "Ybodychange",
    "f37849188b05a6251584de1aed5e66d5dfa7da4f": "Ybodychange",
    "5ea533c2bfc72fd3adbfd972d18806fbc397e0f8": "Ymultichange(Yparameterchange,Ybodychange)",
    "a2200a64175867a1c66cf8338f536ccaaaa36508": "Ybodychange",
    "7429debd866b3ebf41b9aae4a602b240a8387b2b": "Ybodychange",
    "5c02d2f6225144772dcb975d3144b057b71d6476": "Ymultichange(Yparameterchange,Yreturntypechange,Ybodychange)",
    "28e3d09230971b32f74284311931525cb7ad1b7c": "Ybodychange",
    "37f587563a943a827fbff865f5302bac6d202415": "Yintroduced"
  },
  "changeHistoryDetails": {
    "f20dc0d5770d3876954faf0a6e8dcce6539ffc23": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-10571. Use Log.*(Object, Throwable) overload to log exceptions.\nContributed by Andras Bokor.\n",
      "commitDate": "14/02/18 8:20 AM",
      "commitName": "f20dc0d5770d3876954faf0a6e8dcce6539ffc23",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "10/10/17 10:38 AM",
      "commitNameOld": "d6602b5f39833611b4afa4581552f6c4c37e23a8",
      "commitAuthorOld": "Jitendra Pandey",
      "daysBetweenCommits": 126.95,
      "commitsBetweenForRepo": 833,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,37 +1,35 @@\n   public COMMIT_STATUS checkCommit(DFSClient dfsClient, long commitOffset,\n       Channel channel, int xid, Nfs3FileAttributes preOpAttr, boolean fromRead) {\n     if (!fromRead) {\n       Preconditions.checkState(channel !\u003d null \u0026\u0026 preOpAttr !\u003d null);\n       // Keep stream active\n       updateLastAccessTime();\n     }\n     Preconditions.checkState(commitOffset \u003e\u003d 0);\n \n     COMMIT_STATUS ret \u003d checkCommitInternal(commitOffset, channel, xid,\n         preOpAttr, fromRead);\n-    if (LOG.isDebugEnabled()) {\n-      LOG.debug(\"Got commit status: \" + ret.name());\n-    }\n+    LOG.debug(\"Got commit status: {}\", ret.name());\n     // Do the sync outside the lock\n     if (ret \u003d\u003d COMMIT_STATUS.COMMIT_DO_SYNC\n         || ret \u003d\u003d COMMIT_STATUS.COMMIT_FINISHED) {\n       try {\n         // Sync file data and length\n         fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n         ret \u003d COMMIT_STATUS.COMMIT_FINISHED; // Remove COMMIT_DO_SYNC status \n         // Nothing to do for metadata since attr related change is pass-through\n       } catch (ClosedChannelException cce) {\n         if (pendingWrites.isEmpty()) {\n           ret \u003d COMMIT_STATUS.COMMIT_FINISHED;\n         } else {\n           ret \u003d COMMIT_STATUS.COMMIT_ERROR;\n         }\n       } catch (IOException e) {\n-        LOG.error(\"Got stream error during data sync: \" + e);\n+        LOG.error(\"Got stream error during data sync\", e);\n         // Do nothing. Stream will be closed eventually by StreamMonitor.\n         // status \u003d Nfs3Status.NFS3ERR_IO;\n         ret \u003d COMMIT_STATUS.COMMIT_ERROR;\n       }\n     }\n     return ret;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public COMMIT_STATUS checkCommit(DFSClient dfsClient, long commitOffset,\n      Channel channel, int xid, Nfs3FileAttributes preOpAttr, boolean fromRead) {\n    if (!fromRead) {\n      Preconditions.checkState(channel !\u003d null \u0026\u0026 preOpAttr !\u003d null);\n      // Keep stream active\n      updateLastAccessTime();\n    }\n    Preconditions.checkState(commitOffset \u003e\u003d 0);\n\n    COMMIT_STATUS ret \u003d checkCommitInternal(commitOffset, channel, xid,\n        preOpAttr, fromRead);\n    LOG.debug(\"Got commit status: {}\", ret.name());\n    // Do the sync outside the lock\n    if (ret \u003d\u003d COMMIT_STATUS.COMMIT_DO_SYNC\n        || ret \u003d\u003d COMMIT_STATUS.COMMIT_FINISHED) {\n      try {\n        // Sync file data and length\n        fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n        ret \u003d COMMIT_STATUS.COMMIT_FINISHED; // Remove COMMIT_DO_SYNC status \n        // Nothing to do for metadata since attr related change is pass-through\n      } catch (ClosedChannelException cce) {\n        if (pendingWrites.isEmpty()) {\n          ret \u003d COMMIT_STATUS.COMMIT_FINISHED;\n        } else {\n          ret \u003d COMMIT_STATUS.COMMIT_ERROR;\n        }\n      } catch (IOException e) {\n        LOG.error(\"Got stream error during data sync\", e);\n        // Do nothing. Stream will be closed eventually by StreamMonitor.\n        // status \u003d Nfs3Status.NFS3ERR_IO;\n        ret \u003d COMMIT_STATUS.COMMIT_ERROR;\n      }\n    }\n    return ret;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {}
    },
    "f37849188b05a6251584de1aed5e66d5dfa7da4f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7423. various typos and message formatting fixes in nfs daemon and doc. (Charles Lamb via yliu)\n",
      "commitDate": "28/01/15 12:56 PM",
      "commitName": "f37849188b05a6251584de1aed5e66d5dfa7da4f",
      "commitAuthor": "yliu",
      "commitDateOld": "11/12/14 3:40 PM",
      "commitNameOld": "f6f2a3f1c73266bfedd802eacde60d8b19b81015",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 47.89,
      "commitsBetweenForRepo": 279,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,37 +1,37 @@\n   public COMMIT_STATUS checkCommit(DFSClient dfsClient, long commitOffset,\n       Channel channel, int xid, Nfs3FileAttributes preOpAttr, boolean fromRead) {\n     if (!fromRead) {\n       Preconditions.checkState(channel !\u003d null \u0026\u0026 preOpAttr !\u003d null);\n       // Keep stream active\n       updateLastAccessTime();\n     }\n     Preconditions.checkState(commitOffset \u003e\u003d 0);\n \n     COMMIT_STATUS ret \u003d checkCommitInternal(commitOffset, channel, xid,\n         preOpAttr, fromRead);\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"Got commit status: \" + ret.name());\n     }\n     // Do the sync outside the lock\n     if (ret \u003d\u003d COMMIT_STATUS.COMMIT_DO_SYNC\n         || ret \u003d\u003d COMMIT_STATUS.COMMIT_FINISHED) {\n       try {\n         // Sync file data and length\n         fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n         ret \u003d COMMIT_STATUS.COMMIT_FINISHED; // Remove COMMIT_DO_SYNC status \n         // Nothing to do for metadata since attr related change is pass-through\n       } catch (ClosedChannelException cce) {\n         if (pendingWrites.isEmpty()) {\n           ret \u003d COMMIT_STATUS.COMMIT_FINISHED;\n         } else {\n           ret \u003d COMMIT_STATUS.COMMIT_ERROR;\n         }\n       } catch (IOException e) {\n-        LOG.error(\"Got stream error during data sync:\" + e);\n+        LOG.error(\"Got stream error during data sync: \" + e);\n         // Do nothing. Stream will be closed eventually by StreamMonitor.\n         // status \u003d Nfs3Status.NFS3ERR_IO;\n         ret \u003d COMMIT_STATUS.COMMIT_ERROR;\n       }\n     }\n     return ret;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public COMMIT_STATUS checkCommit(DFSClient dfsClient, long commitOffset,\n      Channel channel, int xid, Nfs3FileAttributes preOpAttr, boolean fromRead) {\n    if (!fromRead) {\n      Preconditions.checkState(channel !\u003d null \u0026\u0026 preOpAttr !\u003d null);\n      // Keep stream active\n      updateLastAccessTime();\n    }\n    Preconditions.checkState(commitOffset \u003e\u003d 0);\n\n    COMMIT_STATUS ret \u003d checkCommitInternal(commitOffset, channel, xid,\n        preOpAttr, fromRead);\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Got commit status: \" + ret.name());\n    }\n    // Do the sync outside the lock\n    if (ret \u003d\u003d COMMIT_STATUS.COMMIT_DO_SYNC\n        || ret \u003d\u003d COMMIT_STATUS.COMMIT_FINISHED) {\n      try {\n        // Sync file data and length\n        fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n        ret \u003d COMMIT_STATUS.COMMIT_FINISHED; // Remove COMMIT_DO_SYNC status \n        // Nothing to do for metadata since attr related change is pass-through\n      } catch (ClosedChannelException cce) {\n        if (pendingWrites.isEmpty()) {\n          ret \u003d COMMIT_STATUS.COMMIT_FINISHED;\n        } else {\n          ret \u003d COMMIT_STATUS.COMMIT_ERROR;\n        }\n      } catch (IOException e) {\n        LOG.error(\"Got stream error during data sync: \" + e);\n        // Do nothing. Stream will be closed eventually by StreamMonitor.\n        // status \u003d Nfs3Status.NFS3ERR_IO;\n        ret \u003d COMMIT_STATUS.COMMIT_ERROR;\n      }\n    }\n    return ret;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {}
    },
    "5ea533c2bfc72fd3adbfd972d18806fbc397e0f8": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-5563. NFS gateway should commit the buffered data when read request comes after write to the same file. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1546233 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/11/13 3:41 PM",
      "commitName": "5ea533c2bfc72fd3adbfd972d18806fbc397e0f8",
      "commitAuthor": "Brandon Li",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-5563. NFS gateway should commit the buffered data when read request comes after write to the same file. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1546233 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "27/11/13 3:41 PM",
          "commitName": "5ea533c2bfc72fd3adbfd972d18806fbc397e0f8",
          "commitAuthor": "Brandon Li",
          "commitDateOld": "15/11/13 4:57 PM",
          "commitNameOld": "a2200a64175867a1c66cf8338f536ccaaaa36508",
          "commitAuthorOld": "Brandon Li",
          "daysBetweenCommits": 11.95,
          "commitsBetweenForRepo": 69,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,34 +1,37 @@\n   public COMMIT_STATUS checkCommit(DFSClient dfsClient, long commitOffset,\n-      Channel channel, int xid, Nfs3FileAttributes preOpAttr) {\n-    // Keep stream active\n-    updateLastAccessTime();\n+      Channel channel, int xid, Nfs3FileAttributes preOpAttr, boolean fromRead) {\n+    if (!fromRead) {\n+      Preconditions.checkState(channel !\u003d null \u0026\u0026 preOpAttr !\u003d null);\n+      // Keep stream active\n+      updateLastAccessTime();\n+    }\n     Preconditions.checkState(commitOffset \u003e\u003d 0);\n \n     COMMIT_STATUS ret \u003d checkCommitInternal(commitOffset, channel, xid,\n-        preOpAttr);\n+        preOpAttr, fromRead);\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"Got commit status: \" + ret.name());\n     }\n     // Do the sync outside the lock\n     if (ret \u003d\u003d COMMIT_STATUS.COMMIT_DO_SYNC\n         || ret \u003d\u003d COMMIT_STATUS.COMMIT_FINISHED) {\n       try {\n         // Sync file data and length\n         fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n         ret \u003d COMMIT_STATUS.COMMIT_FINISHED; // Remove COMMIT_DO_SYNC status \n         // Nothing to do for metadata since attr related change is pass-through\n       } catch (ClosedChannelException cce) {\n         if (pendingWrites.isEmpty()) {\n           ret \u003d COMMIT_STATUS.COMMIT_FINISHED;\n         } else {\n           ret \u003d COMMIT_STATUS.COMMIT_ERROR;\n         }\n       } catch (IOException e) {\n         LOG.error(\"Got stream error during data sync:\" + e);\n         // Do nothing. Stream will be closed eventually by StreamMonitor.\n         // status \u003d Nfs3Status.NFS3ERR_IO;\n         ret \u003d COMMIT_STATUS.COMMIT_ERROR;\n       }\n     }\n     return ret;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public COMMIT_STATUS checkCommit(DFSClient dfsClient, long commitOffset,\n      Channel channel, int xid, Nfs3FileAttributes preOpAttr, boolean fromRead) {\n    if (!fromRead) {\n      Preconditions.checkState(channel !\u003d null \u0026\u0026 preOpAttr !\u003d null);\n      // Keep stream active\n      updateLastAccessTime();\n    }\n    Preconditions.checkState(commitOffset \u003e\u003d 0);\n\n    COMMIT_STATUS ret \u003d checkCommitInternal(commitOffset, channel, xid,\n        preOpAttr, fromRead);\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Got commit status: \" + ret.name());\n    }\n    // Do the sync outside the lock\n    if (ret \u003d\u003d COMMIT_STATUS.COMMIT_DO_SYNC\n        || ret \u003d\u003d COMMIT_STATUS.COMMIT_FINISHED) {\n      try {\n        // Sync file data and length\n        fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n        ret \u003d COMMIT_STATUS.COMMIT_FINISHED; // Remove COMMIT_DO_SYNC status \n        // Nothing to do for metadata since attr related change is pass-through\n      } catch (ClosedChannelException cce) {\n        if (pendingWrites.isEmpty()) {\n          ret \u003d COMMIT_STATUS.COMMIT_FINISHED;\n        } else {\n          ret \u003d COMMIT_STATUS.COMMIT_ERROR;\n        }\n      } catch (IOException e) {\n        LOG.error(\"Got stream error during data sync:\" + e);\n        // Do nothing. Stream will be closed eventually by StreamMonitor.\n        // status \u003d Nfs3Status.NFS3ERR_IO;\n        ret \u003d COMMIT_STATUS.COMMIT_ERROR;\n      }\n    }\n    return ret;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
          "extendedDetails": {
            "oldValue": "[dfsClient-DFSClient, commitOffset-long, channel-Channel, xid-int, preOpAttr-Nfs3FileAttributes]",
            "newValue": "[dfsClient-DFSClient, commitOffset-long, channel-Channel, xid-int, preOpAttr-Nfs3FileAttributes, fromRead-boolean]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5563. NFS gateway should commit the buffered data when read request comes after write to the same file. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1546233 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "27/11/13 3:41 PM",
          "commitName": "5ea533c2bfc72fd3adbfd972d18806fbc397e0f8",
          "commitAuthor": "Brandon Li",
          "commitDateOld": "15/11/13 4:57 PM",
          "commitNameOld": "a2200a64175867a1c66cf8338f536ccaaaa36508",
          "commitAuthorOld": "Brandon Li",
          "daysBetweenCommits": 11.95,
          "commitsBetweenForRepo": 69,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,34 +1,37 @@\n   public COMMIT_STATUS checkCommit(DFSClient dfsClient, long commitOffset,\n-      Channel channel, int xid, Nfs3FileAttributes preOpAttr) {\n-    // Keep stream active\n-    updateLastAccessTime();\n+      Channel channel, int xid, Nfs3FileAttributes preOpAttr, boolean fromRead) {\n+    if (!fromRead) {\n+      Preconditions.checkState(channel !\u003d null \u0026\u0026 preOpAttr !\u003d null);\n+      // Keep stream active\n+      updateLastAccessTime();\n+    }\n     Preconditions.checkState(commitOffset \u003e\u003d 0);\n \n     COMMIT_STATUS ret \u003d checkCommitInternal(commitOffset, channel, xid,\n-        preOpAttr);\n+        preOpAttr, fromRead);\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"Got commit status: \" + ret.name());\n     }\n     // Do the sync outside the lock\n     if (ret \u003d\u003d COMMIT_STATUS.COMMIT_DO_SYNC\n         || ret \u003d\u003d COMMIT_STATUS.COMMIT_FINISHED) {\n       try {\n         // Sync file data and length\n         fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n         ret \u003d COMMIT_STATUS.COMMIT_FINISHED; // Remove COMMIT_DO_SYNC status \n         // Nothing to do for metadata since attr related change is pass-through\n       } catch (ClosedChannelException cce) {\n         if (pendingWrites.isEmpty()) {\n           ret \u003d COMMIT_STATUS.COMMIT_FINISHED;\n         } else {\n           ret \u003d COMMIT_STATUS.COMMIT_ERROR;\n         }\n       } catch (IOException e) {\n         LOG.error(\"Got stream error during data sync:\" + e);\n         // Do nothing. Stream will be closed eventually by StreamMonitor.\n         // status \u003d Nfs3Status.NFS3ERR_IO;\n         ret \u003d COMMIT_STATUS.COMMIT_ERROR;\n       }\n     }\n     return ret;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public COMMIT_STATUS checkCommit(DFSClient dfsClient, long commitOffset,\n      Channel channel, int xid, Nfs3FileAttributes preOpAttr, boolean fromRead) {\n    if (!fromRead) {\n      Preconditions.checkState(channel !\u003d null \u0026\u0026 preOpAttr !\u003d null);\n      // Keep stream active\n      updateLastAccessTime();\n    }\n    Preconditions.checkState(commitOffset \u003e\u003d 0);\n\n    COMMIT_STATUS ret \u003d checkCommitInternal(commitOffset, channel, xid,\n        preOpAttr, fromRead);\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Got commit status: \" + ret.name());\n    }\n    // Do the sync outside the lock\n    if (ret \u003d\u003d COMMIT_STATUS.COMMIT_DO_SYNC\n        || ret \u003d\u003d COMMIT_STATUS.COMMIT_FINISHED) {\n      try {\n        // Sync file data and length\n        fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n        ret \u003d COMMIT_STATUS.COMMIT_FINISHED; // Remove COMMIT_DO_SYNC status \n        // Nothing to do for metadata since attr related change is pass-through\n      } catch (ClosedChannelException cce) {\n        if (pendingWrites.isEmpty()) {\n          ret \u003d COMMIT_STATUS.COMMIT_FINISHED;\n        } else {\n          ret \u003d COMMIT_STATUS.COMMIT_ERROR;\n        }\n      } catch (IOException e) {\n        LOG.error(\"Got stream error during data sync:\" + e);\n        // Do nothing. Stream will be closed eventually by StreamMonitor.\n        // status \u003d Nfs3Status.NFS3ERR_IO;\n        ret \u003d COMMIT_STATUS.COMMIT_ERROR;\n      }\n    }\n    return ret;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
          "extendedDetails": {}
        }
      ]
    },
    "a2200a64175867a1c66cf8338f536ccaaaa36508": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5519. COMMIT handler should update the commit status after sync. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1542437 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "15/11/13 4:57 PM",
      "commitName": "a2200a64175867a1c66cf8338f536ccaaaa36508",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "07/11/13 1:49 PM",
      "commitNameOld": "3fccdec6e0a8e9305fc75921211c3745eddb9c45",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 8.13,
      "commitsBetweenForRepo": 59,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,33 +1,34 @@\n   public COMMIT_STATUS checkCommit(DFSClient dfsClient, long commitOffset,\n       Channel channel, int xid, Nfs3FileAttributes preOpAttr) {\n     // Keep stream active\n     updateLastAccessTime();\n     Preconditions.checkState(commitOffset \u003e\u003d 0);\n \n     COMMIT_STATUS ret \u003d checkCommitInternal(commitOffset, channel, xid,\n         preOpAttr);\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"Got commit status: \" + ret.name());\n     }\n     // Do the sync outside the lock\n     if (ret \u003d\u003d COMMIT_STATUS.COMMIT_DO_SYNC\n         || ret \u003d\u003d COMMIT_STATUS.COMMIT_FINISHED) {\n       try {\n         // Sync file data and length\n         fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n+        ret \u003d COMMIT_STATUS.COMMIT_FINISHED; // Remove COMMIT_DO_SYNC status \n         // Nothing to do for metadata since attr related change is pass-through\n       } catch (ClosedChannelException cce) {\n         if (pendingWrites.isEmpty()) {\n           ret \u003d COMMIT_STATUS.COMMIT_FINISHED;\n         } else {\n           ret \u003d COMMIT_STATUS.COMMIT_ERROR;\n         }\n       } catch (IOException e) {\n         LOG.error(\"Got stream error during data sync:\" + e);\n         // Do nothing. Stream will be closed eventually by StreamMonitor.\n         // status \u003d Nfs3Status.NFS3ERR_IO;\n         ret \u003d COMMIT_STATUS.COMMIT_ERROR;\n       }\n     }\n     return ret;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public COMMIT_STATUS checkCommit(DFSClient dfsClient, long commitOffset,\n      Channel channel, int xid, Nfs3FileAttributes preOpAttr) {\n    // Keep stream active\n    updateLastAccessTime();\n    Preconditions.checkState(commitOffset \u003e\u003d 0);\n\n    COMMIT_STATUS ret \u003d checkCommitInternal(commitOffset, channel, xid,\n        preOpAttr);\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Got commit status: \" + ret.name());\n    }\n    // Do the sync outside the lock\n    if (ret \u003d\u003d COMMIT_STATUS.COMMIT_DO_SYNC\n        || ret \u003d\u003d COMMIT_STATUS.COMMIT_FINISHED) {\n      try {\n        // Sync file data and length\n        fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n        ret \u003d COMMIT_STATUS.COMMIT_FINISHED; // Remove COMMIT_DO_SYNC status \n        // Nothing to do for metadata since attr related change is pass-through\n      } catch (ClosedChannelException cce) {\n        if (pendingWrites.isEmpty()) {\n          ret \u003d COMMIT_STATUS.COMMIT_FINISHED;\n        } else {\n          ret \u003d COMMIT_STATUS.COMMIT_ERROR;\n        }\n      } catch (IOException e) {\n        LOG.error(\"Got stream error during data sync:\" + e);\n        // Do nothing. Stream will be closed eventually by StreamMonitor.\n        // status \u003d Nfs3Status.NFS3ERR_IO;\n        ret \u003d COMMIT_STATUS.COMMIT_ERROR;\n      }\n    }\n    return ret;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {}
    },
    "7429debd866b3ebf41b9aae4a602b240a8387b2b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5337. should do hsync for a commit request even there is no pending writes. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1530835 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/10/13 5:52 PM",
      "commitName": "7429debd866b3ebf41b9aae4a602b240a8387b2b",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "08/10/13 4:40 PM",
      "commitNameOld": "5c02d2f6225144772dcb975d3144b057b71d6476",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 1.05,
      "commitsBetweenForRepo": 15,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,32 +1,33 @@\n   public COMMIT_STATUS checkCommit(DFSClient dfsClient, long commitOffset,\n       Channel channel, int xid, Nfs3FileAttributes preOpAttr) {\n     // Keep stream active\n     updateLastAccessTime();\n     Preconditions.checkState(commitOffset \u003e\u003d 0);\n \n     COMMIT_STATUS ret \u003d checkCommitInternal(commitOffset, channel, xid,\n         preOpAttr);\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"Got commit status: \" + ret.name());\n     }\n     // Do the sync outside the lock\n-    if (ret \u003d\u003d COMMIT_STATUS.COMMIT_DO_SYNC) {\n+    if (ret \u003d\u003d COMMIT_STATUS.COMMIT_DO_SYNC\n+        || ret \u003d\u003d COMMIT_STATUS.COMMIT_FINISHED) {\n       try {\n         // Sync file data and length\n         fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n         // Nothing to do for metadata since attr related change is pass-through\n       } catch (ClosedChannelException cce) {\n         if (pendingWrites.isEmpty()) {\n           ret \u003d COMMIT_STATUS.COMMIT_FINISHED;\n         } else {\n           ret \u003d COMMIT_STATUS.COMMIT_ERROR;\n         }\n       } catch (IOException e) {\n         LOG.error(\"Got stream error during data sync:\" + e);\n         // Do nothing. Stream will be closed eventually by StreamMonitor.\n         // status \u003d Nfs3Status.NFS3ERR_IO;\n         ret \u003d COMMIT_STATUS.COMMIT_ERROR;\n       }\n     }\n     return ret;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public COMMIT_STATUS checkCommit(DFSClient dfsClient, long commitOffset,\n      Channel channel, int xid, Nfs3FileAttributes preOpAttr) {\n    // Keep stream active\n    updateLastAccessTime();\n    Preconditions.checkState(commitOffset \u003e\u003d 0);\n\n    COMMIT_STATUS ret \u003d checkCommitInternal(commitOffset, channel, xid,\n        preOpAttr);\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Got commit status: \" + ret.name());\n    }\n    // Do the sync outside the lock\n    if (ret \u003d\u003d COMMIT_STATUS.COMMIT_DO_SYNC\n        || ret \u003d\u003d COMMIT_STATUS.COMMIT_FINISHED) {\n      try {\n        // Sync file data and length\n        fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n        // Nothing to do for metadata since attr related change is pass-through\n      } catch (ClosedChannelException cce) {\n        if (pendingWrites.isEmpty()) {\n          ret \u003d COMMIT_STATUS.COMMIT_FINISHED;\n        } else {\n          ret \u003d COMMIT_STATUS.COMMIT_ERROR;\n        }\n      } catch (IOException e) {\n        LOG.error(\"Got stream error during data sync:\" + e);\n        // Do nothing. Stream will be closed eventually by StreamMonitor.\n        // status \u003d Nfs3Status.NFS3ERR_IO;\n        ret \u003d COMMIT_STATUS.COMMIT_ERROR;\n      }\n    }\n    return ret;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {}
    },
    "5c02d2f6225144772dcb975d3144b057b71d6476": {
      "type": "Ymultichange(Yparameterchange,Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-5281. COMMIT request should not block. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1530461 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/10/13 4:40 PM",
      "commitName": "5c02d2f6225144772dcb975d3144b057b71d6476",
      "commitAuthor": "Brandon Li",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-5281. COMMIT request should not block. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1530461 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "08/10/13 4:40 PM",
          "commitName": "5c02d2f6225144772dcb975d3144b057b71d6476",
          "commitAuthor": "Brandon Li",
          "commitDateOld": "06/10/13 7:57 PM",
          "commitNameOld": "caa4abd30cfc4361c7bc9f212a9092840d7c3b53",
          "commitAuthorOld": "Brandon Li",
          "daysBetweenCommits": 1.86,
          "commitsBetweenForRepo": 12,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,4 +1,32 @@\n-  public int checkCommit(long commitOffset) {\n-    return activeState ? checkCommitInternal(commitOffset)\n-        : COMMIT_INACTIVE_CTX;\n+  public COMMIT_STATUS checkCommit(DFSClient dfsClient, long commitOffset,\n+      Channel channel, int xid, Nfs3FileAttributes preOpAttr) {\n+    // Keep stream active\n+    updateLastAccessTime();\n+    Preconditions.checkState(commitOffset \u003e\u003d 0);\n+\n+    COMMIT_STATUS ret \u003d checkCommitInternal(commitOffset, channel, xid,\n+        preOpAttr);\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"Got commit status: \" + ret.name());\n+    }\n+    // Do the sync outside the lock\n+    if (ret \u003d\u003d COMMIT_STATUS.COMMIT_DO_SYNC) {\n+      try {\n+        // Sync file data and length\n+        fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n+        // Nothing to do for metadata since attr related change is pass-through\n+      } catch (ClosedChannelException cce) {\n+        if (pendingWrites.isEmpty()) {\n+          ret \u003d COMMIT_STATUS.COMMIT_FINISHED;\n+        } else {\n+          ret \u003d COMMIT_STATUS.COMMIT_ERROR;\n+        }\n+      } catch (IOException e) {\n+        LOG.error(\"Got stream error during data sync:\" + e);\n+        // Do nothing. Stream will be closed eventually by StreamMonitor.\n+        // status \u003d Nfs3Status.NFS3ERR_IO;\n+        ret \u003d COMMIT_STATUS.COMMIT_ERROR;\n+      }\n+    }\n+    return ret;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public COMMIT_STATUS checkCommit(DFSClient dfsClient, long commitOffset,\n      Channel channel, int xid, Nfs3FileAttributes preOpAttr) {\n    // Keep stream active\n    updateLastAccessTime();\n    Preconditions.checkState(commitOffset \u003e\u003d 0);\n\n    COMMIT_STATUS ret \u003d checkCommitInternal(commitOffset, channel, xid,\n        preOpAttr);\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Got commit status: \" + ret.name());\n    }\n    // Do the sync outside the lock\n    if (ret \u003d\u003d COMMIT_STATUS.COMMIT_DO_SYNC) {\n      try {\n        // Sync file data and length\n        fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n        // Nothing to do for metadata since attr related change is pass-through\n      } catch (ClosedChannelException cce) {\n        if (pendingWrites.isEmpty()) {\n          ret \u003d COMMIT_STATUS.COMMIT_FINISHED;\n        } else {\n          ret \u003d COMMIT_STATUS.COMMIT_ERROR;\n        }\n      } catch (IOException e) {\n        LOG.error(\"Got stream error during data sync:\" + e);\n        // Do nothing. Stream will be closed eventually by StreamMonitor.\n        // status \u003d Nfs3Status.NFS3ERR_IO;\n        ret \u003d COMMIT_STATUS.COMMIT_ERROR;\n      }\n    }\n    return ret;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
          "extendedDetails": {
            "oldValue": "[commitOffset-long]",
            "newValue": "[dfsClient-DFSClient, commitOffset-long, channel-Channel, xid-int, preOpAttr-Nfs3FileAttributes]"
          }
        },
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-5281. COMMIT request should not block. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1530461 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "08/10/13 4:40 PM",
          "commitName": "5c02d2f6225144772dcb975d3144b057b71d6476",
          "commitAuthor": "Brandon Li",
          "commitDateOld": "06/10/13 7:57 PM",
          "commitNameOld": "caa4abd30cfc4361c7bc9f212a9092840d7c3b53",
          "commitAuthorOld": "Brandon Li",
          "daysBetweenCommits": 1.86,
          "commitsBetweenForRepo": 12,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,4 +1,32 @@\n-  public int checkCommit(long commitOffset) {\n-    return activeState ? checkCommitInternal(commitOffset)\n-        : COMMIT_INACTIVE_CTX;\n+  public COMMIT_STATUS checkCommit(DFSClient dfsClient, long commitOffset,\n+      Channel channel, int xid, Nfs3FileAttributes preOpAttr) {\n+    // Keep stream active\n+    updateLastAccessTime();\n+    Preconditions.checkState(commitOffset \u003e\u003d 0);\n+\n+    COMMIT_STATUS ret \u003d checkCommitInternal(commitOffset, channel, xid,\n+        preOpAttr);\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"Got commit status: \" + ret.name());\n+    }\n+    // Do the sync outside the lock\n+    if (ret \u003d\u003d COMMIT_STATUS.COMMIT_DO_SYNC) {\n+      try {\n+        // Sync file data and length\n+        fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n+        // Nothing to do for metadata since attr related change is pass-through\n+      } catch (ClosedChannelException cce) {\n+        if (pendingWrites.isEmpty()) {\n+          ret \u003d COMMIT_STATUS.COMMIT_FINISHED;\n+        } else {\n+          ret \u003d COMMIT_STATUS.COMMIT_ERROR;\n+        }\n+      } catch (IOException e) {\n+        LOG.error(\"Got stream error during data sync:\" + e);\n+        // Do nothing. Stream will be closed eventually by StreamMonitor.\n+        // status \u003d Nfs3Status.NFS3ERR_IO;\n+        ret \u003d COMMIT_STATUS.COMMIT_ERROR;\n+      }\n+    }\n+    return ret;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public COMMIT_STATUS checkCommit(DFSClient dfsClient, long commitOffset,\n      Channel channel, int xid, Nfs3FileAttributes preOpAttr) {\n    // Keep stream active\n    updateLastAccessTime();\n    Preconditions.checkState(commitOffset \u003e\u003d 0);\n\n    COMMIT_STATUS ret \u003d checkCommitInternal(commitOffset, channel, xid,\n        preOpAttr);\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Got commit status: \" + ret.name());\n    }\n    // Do the sync outside the lock\n    if (ret \u003d\u003d COMMIT_STATUS.COMMIT_DO_SYNC) {\n      try {\n        // Sync file data and length\n        fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n        // Nothing to do for metadata since attr related change is pass-through\n      } catch (ClosedChannelException cce) {\n        if (pendingWrites.isEmpty()) {\n          ret \u003d COMMIT_STATUS.COMMIT_FINISHED;\n        } else {\n          ret \u003d COMMIT_STATUS.COMMIT_ERROR;\n        }\n      } catch (IOException e) {\n        LOG.error(\"Got stream error during data sync:\" + e);\n        // Do nothing. Stream will be closed eventually by StreamMonitor.\n        // status \u003d Nfs3Status.NFS3ERR_IO;\n        ret \u003d COMMIT_STATUS.COMMIT_ERROR;\n      }\n    }\n    return ret;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
          "extendedDetails": {
            "oldValue": "int",
            "newValue": "COMMIT_STATUS"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5281. COMMIT request should not block. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1530461 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "08/10/13 4:40 PM",
          "commitName": "5c02d2f6225144772dcb975d3144b057b71d6476",
          "commitAuthor": "Brandon Li",
          "commitDateOld": "06/10/13 7:57 PM",
          "commitNameOld": "caa4abd30cfc4361c7bc9f212a9092840d7c3b53",
          "commitAuthorOld": "Brandon Li",
          "daysBetweenCommits": 1.86,
          "commitsBetweenForRepo": 12,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,4 +1,32 @@\n-  public int checkCommit(long commitOffset) {\n-    return activeState ? checkCommitInternal(commitOffset)\n-        : COMMIT_INACTIVE_CTX;\n+  public COMMIT_STATUS checkCommit(DFSClient dfsClient, long commitOffset,\n+      Channel channel, int xid, Nfs3FileAttributes preOpAttr) {\n+    // Keep stream active\n+    updateLastAccessTime();\n+    Preconditions.checkState(commitOffset \u003e\u003d 0);\n+\n+    COMMIT_STATUS ret \u003d checkCommitInternal(commitOffset, channel, xid,\n+        preOpAttr);\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"Got commit status: \" + ret.name());\n+    }\n+    // Do the sync outside the lock\n+    if (ret \u003d\u003d COMMIT_STATUS.COMMIT_DO_SYNC) {\n+      try {\n+        // Sync file data and length\n+        fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n+        // Nothing to do for metadata since attr related change is pass-through\n+      } catch (ClosedChannelException cce) {\n+        if (pendingWrites.isEmpty()) {\n+          ret \u003d COMMIT_STATUS.COMMIT_FINISHED;\n+        } else {\n+          ret \u003d COMMIT_STATUS.COMMIT_ERROR;\n+        }\n+      } catch (IOException e) {\n+        LOG.error(\"Got stream error during data sync:\" + e);\n+        // Do nothing. Stream will be closed eventually by StreamMonitor.\n+        // status \u003d Nfs3Status.NFS3ERR_IO;\n+        ret \u003d COMMIT_STATUS.COMMIT_ERROR;\n+      }\n+    }\n+    return ret;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public COMMIT_STATUS checkCommit(DFSClient dfsClient, long commitOffset,\n      Channel channel, int xid, Nfs3FileAttributes preOpAttr) {\n    // Keep stream active\n    updateLastAccessTime();\n    Preconditions.checkState(commitOffset \u003e\u003d 0);\n\n    COMMIT_STATUS ret \u003d checkCommitInternal(commitOffset, channel, xid,\n        preOpAttr);\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Got commit status: \" + ret.name());\n    }\n    // Do the sync outside the lock\n    if (ret \u003d\u003d COMMIT_STATUS.COMMIT_DO_SYNC) {\n      try {\n        // Sync file data and length\n        fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n        // Nothing to do for metadata since attr related change is pass-through\n      } catch (ClosedChannelException cce) {\n        if (pendingWrites.isEmpty()) {\n          ret \u003d COMMIT_STATUS.COMMIT_FINISHED;\n        } else {\n          ret \u003d COMMIT_STATUS.COMMIT_ERROR;\n        }\n      } catch (IOException e) {\n        LOG.error(\"Got stream error during data sync:\" + e);\n        // Do nothing. Stream will be closed eventually by StreamMonitor.\n        // status \u003d Nfs3Status.NFS3ERR_IO;\n        ret \u003d COMMIT_STATUS.COMMIT_ERROR;\n      }\n    }\n    return ret;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
          "extendedDetails": {}
        }
      ]
    },
    "28e3d09230971b32f74284311931525cb7ad1b7c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4971. Move IO operations out of locking in OpenFileCtx. Contributed by Jing Zhao and Brandon Li.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1525681 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "23/09/13 1:02 PM",
      "commitName": "28e3d09230971b32f74284311931525cb7ad1b7c",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "17/09/13 11:08 PM",
      "commitNameOld": "5e18410e06dd63113c49029894007e0878312903",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 5.58,
      "commitsBetweenForRepo": 25,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,15 +1,4 @@\n   public int checkCommit(long commitOffset) {\n-    int ret \u003d COMMIT_WAIT;\n-\n-    lockCtx();\n-    try {\n-      if (!activeState) {\n-        ret \u003d COMMIT_INACTIVE_CTX;\n-      } else {\n-        ret \u003d checkCommitInternal(commitOffset);\n-      }\n-    } finally {\n-      unlockCtx();\n-    }\n-    return ret;\n+    return activeState ? checkCommitInternal(commitOffset)\n+        : COMMIT_INACTIVE_CTX;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int checkCommit(long commitOffset) {\n    return activeState ? checkCommitInternal(commitOffset)\n        : COMMIT_INACTIVE_CTX;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {}
    },
    "37f587563a943a827fbff865f5302bac6d202415": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-4762 Provide HDFS based NFSv3 and Mountd implementation. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1499029 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/07/13 10:31 AM",
      "commitName": "37f587563a943a827fbff865f5302bac6d202415",
      "commitAuthor": "Brandon Li",
      "diff": "@@ -0,0 +1,15 @@\n+  public int checkCommit(long commitOffset) {\n+    int ret \u003d COMMIT_WAIT;\n+\n+    lockCtx();\n+    try {\n+      if (!activeState) {\n+        ret \u003d COMMIT_INACTIVE_CTX;\n+      } else {\n+        ret \u003d checkCommitInternal(commitOffset);\n+      }\n+    } finally {\n+      unlockCtx();\n+    }\n+    return ret;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public int checkCommit(long commitOffset) {\n    int ret \u003d COMMIT_WAIT;\n\n    lockCtx();\n    try {\n      if (!activeState) {\n        ret \u003d COMMIT_INACTIVE_CTX;\n      } else {\n        ret \u003d checkCommitInternal(commitOffset);\n      }\n    } finally {\n      unlockCtx();\n    }\n    return ret;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java"
    }
  }
}