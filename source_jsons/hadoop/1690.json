{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "Sender.java",
  "functionName": "writeBlock",
  "functionId": "writeBlock___blk-ExtendedBlock(modifiers-final)__storageType-StorageType(modifiers-final)__blockToken-Token__BlockTokenIdentifier__(modifiers-final)__clientName-String(modifiers-final)__targets-DatanodeInfo[](modifiers-final)__targetStorageTypes-StorageType[](modifiers-final)__source-DatanodeInfo(modifiers-final)__stage-BlockConstructionStage(modifiers-final)__pipelineSize-int(modifiers-final)__minBytesRcvd-long(modifiers-final)__maxBytesRcvd-long(modifiers-final)__latestGenerationStamp-long(modifiers-final)__requestedChecksum-DataChecksum__cachingStrategy-CachingStrategy(modifiers-final)__allowLazyPersist-boolean(modifiers-final)__pinning-boolean(modifiers-final)__targetPinnings-boolean[](modifiers-final)__storageId-String(modifiers-final)__targetStorageIds-String[](modifiers-final)",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Sender.java",
  "functionStartLine": 121,
  "functionEndLine": 171,
  "numCommitsSeen": 54,
  "timeTaken": 2870,
  "changeHistory": [
    "a3954ccab148bddc290cb96528e63ff19799bcc9",
    "490bb5ebd6c6d6f9c08fcad167f976687fc3aa42",
    "085b1e293ff53f7a86aa21406cfd4bfa0f3bf33b"
  ],
  "changeHistoryShort": {
    "a3954ccab148bddc290cb96528e63ff19799bcc9": "Ymultichange(Yparameterchange,Ybodychange)",
    "490bb5ebd6c6d6f9c08fcad167f976687fc3aa42": "Ymultichange(Yfilerename,Ybodychange)",
    "085b1e293ff53f7a86aa21406cfd4bfa0f3bf33b": "Ymultichange(Yparameterchange,Ybodychange)"
  },
  "changeHistoryDetails": {
    "a3954ccab148bddc290cb96528e63ff19799bcc9": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-9807. Add an optional StorageID to writes. Contributed by Ewan Higgs\n",
      "commitDate": "05/05/17 12:01 PM",
      "commitName": "a3954ccab148bddc290cb96528e63ff19799bcc9",
      "commitAuthor": "Chris Douglas",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-9807. Add an optional StorageID to writes. Contributed by Ewan Higgs\n",
          "commitDate": "05/05/17 12:01 PM",
          "commitName": "a3954ccab148bddc290cb96528e63ff19799bcc9",
          "commitAuthor": "Chris Douglas",
          "commitDateOld": "24/06/16 2:39 AM",
          "commitNameOld": "e6cb07520f935efde3e881de8f84ee7f6e0a746f",
          "commitAuthorOld": "Kai Zheng",
          "daysBetweenCommits": 315.39,
          "commitsBetweenForRepo": 2062,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,46 +1,51 @@\n   public void writeBlock(final ExtendedBlock blk,\n       final StorageType storageType,\n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientName,\n       final DatanodeInfo[] targets,\n       final StorageType[] targetStorageTypes,\n       final DatanodeInfo source,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum,\n       final CachingStrategy cachingStrategy,\n       final boolean allowLazyPersist,\n       final boolean pinning,\n-      final boolean[] targetPinnings) throws IOException {\n+      final boolean[] targetPinnings,\n+      final String storageId,\n+      final String[] targetStorageIds) throws IOException {\n     ClientOperationHeaderProto header \u003d DataTransferProtoUtil.buildClientHeader(\n         blk, clientName, blockToken);\n \n     ChecksumProto checksumProto \u003d\n         DataTransferProtoUtil.toProto(requestedChecksum);\n \n     OpWriteBlockProto.Builder proto \u003d OpWriteBlockProto.newBuilder()\n         .setHeader(header)\n         .setStorageType(PBHelperClient.convertStorageType(storageType))\n         .addAllTargets(PBHelperClient.convert(targets, 1))\n         .addAllTargetStorageTypes(\n             PBHelperClient.convertStorageTypes(targetStorageTypes, 1))\n         .setStage(toProto(stage))\n         .setPipelineSize(pipelineSize)\n         .setMinBytesRcvd(minBytesRcvd)\n         .setMaxBytesRcvd(maxBytesRcvd)\n         .setLatestGenerationStamp(latestGenerationStamp)\n         .setRequestedChecksum(checksumProto)\n         .setCachingStrategy(getCachingStrategy(cachingStrategy))\n         .setAllowLazyPersist(allowLazyPersist)\n         .setPinning(pinning)\n-        .addAllTargetPinnings(PBHelperClient.convert(targetPinnings, 1));\n-\n+        .addAllTargetPinnings(PBHelperClient.convert(targetPinnings, 1))\n+        .addAllTargetStorageIds(PBHelperClient.convert(targetStorageIds, 1));\n     if (source !\u003d null) {\n       proto.setSource(PBHelperClient.convertDatanodeInfo(source));\n     }\n+    if (storageId !\u003d null) {\n+      proto.setStorageId(storageId);\n+    }\n \n     send(out, Op.WRITE_BLOCK, proto.build());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void writeBlock(final ExtendedBlock blk,\n      final StorageType storageType,\n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientName,\n      final DatanodeInfo[] targets,\n      final StorageType[] targetStorageTypes,\n      final DatanodeInfo source,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      final CachingStrategy cachingStrategy,\n      final boolean allowLazyPersist,\n      final boolean pinning,\n      final boolean[] targetPinnings,\n      final String storageId,\n      final String[] targetStorageIds) throws IOException {\n    ClientOperationHeaderProto header \u003d DataTransferProtoUtil.buildClientHeader(\n        blk, clientName, blockToken);\n\n    ChecksumProto checksumProto \u003d\n        DataTransferProtoUtil.toProto(requestedChecksum);\n\n    OpWriteBlockProto.Builder proto \u003d OpWriteBlockProto.newBuilder()\n        .setHeader(header)\n        .setStorageType(PBHelperClient.convertStorageType(storageType))\n        .addAllTargets(PBHelperClient.convert(targets, 1))\n        .addAllTargetStorageTypes(\n            PBHelperClient.convertStorageTypes(targetStorageTypes, 1))\n        .setStage(toProto(stage))\n        .setPipelineSize(pipelineSize)\n        .setMinBytesRcvd(minBytesRcvd)\n        .setMaxBytesRcvd(maxBytesRcvd)\n        .setLatestGenerationStamp(latestGenerationStamp)\n        .setRequestedChecksum(checksumProto)\n        .setCachingStrategy(getCachingStrategy(cachingStrategy))\n        .setAllowLazyPersist(allowLazyPersist)\n        .setPinning(pinning)\n        .addAllTargetPinnings(PBHelperClient.convert(targetPinnings, 1))\n        .addAllTargetStorageIds(PBHelperClient.convert(targetStorageIds, 1));\n    if (source !\u003d null) {\n      proto.setSource(PBHelperClient.convertDatanodeInfo(source));\n    }\n    if (storageId !\u003d null) {\n      proto.setStorageId(storageId);\n    }\n\n    send(out, Op.WRITE_BLOCK, proto.build());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Sender.java",
          "extendedDetails": {
            "oldValue": "[blk-ExtendedBlock(modifiers-final), storageType-StorageType(modifiers-final), blockToken-Token\u003cBlockTokenIdentifier\u003e(modifiers-final), clientName-String(modifiers-final), targets-DatanodeInfo[](modifiers-final), targetStorageTypes-StorageType[](modifiers-final), source-DatanodeInfo(modifiers-final), stage-BlockConstructionStage(modifiers-final), pipelineSize-int(modifiers-final), minBytesRcvd-long(modifiers-final), maxBytesRcvd-long(modifiers-final), latestGenerationStamp-long(modifiers-final), requestedChecksum-DataChecksum, cachingStrategy-CachingStrategy(modifiers-final), allowLazyPersist-boolean(modifiers-final), pinning-boolean(modifiers-final), targetPinnings-boolean[](modifiers-final)]",
            "newValue": "[blk-ExtendedBlock(modifiers-final), storageType-StorageType(modifiers-final), blockToken-Token\u003cBlockTokenIdentifier\u003e(modifiers-final), clientName-String(modifiers-final), targets-DatanodeInfo[](modifiers-final), targetStorageTypes-StorageType[](modifiers-final), source-DatanodeInfo(modifiers-final), stage-BlockConstructionStage(modifiers-final), pipelineSize-int(modifiers-final), minBytesRcvd-long(modifiers-final), maxBytesRcvd-long(modifiers-final), latestGenerationStamp-long(modifiers-final), requestedChecksum-DataChecksum, cachingStrategy-CachingStrategy(modifiers-final), allowLazyPersist-boolean(modifiers-final), pinning-boolean(modifiers-final), targetPinnings-boolean[](modifiers-final), storageId-String(modifiers-final), targetStorageIds-String[](modifiers-final)]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-9807. Add an optional StorageID to writes. Contributed by Ewan Higgs\n",
          "commitDate": "05/05/17 12:01 PM",
          "commitName": "a3954ccab148bddc290cb96528e63ff19799bcc9",
          "commitAuthor": "Chris Douglas",
          "commitDateOld": "24/06/16 2:39 AM",
          "commitNameOld": "e6cb07520f935efde3e881de8f84ee7f6e0a746f",
          "commitAuthorOld": "Kai Zheng",
          "daysBetweenCommits": 315.39,
          "commitsBetweenForRepo": 2062,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,46 +1,51 @@\n   public void writeBlock(final ExtendedBlock blk,\n       final StorageType storageType,\n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientName,\n       final DatanodeInfo[] targets,\n       final StorageType[] targetStorageTypes,\n       final DatanodeInfo source,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum,\n       final CachingStrategy cachingStrategy,\n       final boolean allowLazyPersist,\n       final boolean pinning,\n-      final boolean[] targetPinnings) throws IOException {\n+      final boolean[] targetPinnings,\n+      final String storageId,\n+      final String[] targetStorageIds) throws IOException {\n     ClientOperationHeaderProto header \u003d DataTransferProtoUtil.buildClientHeader(\n         blk, clientName, blockToken);\n \n     ChecksumProto checksumProto \u003d\n         DataTransferProtoUtil.toProto(requestedChecksum);\n \n     OpWriteBlockProto.Builder proto \u003d OpWriteBlockProto.newBuilder()\n         .setHeader(header)\n         .setStorageType(PBHelperClient.convertStorageType(storageType))\n         .addAllTargets(PBHelperClient.convert(targets, 1))\n         .addAllTargetStorageTypes(\n             PBHelperClient.convertStorageTypes(targetStorageTypes, 1))\n         .setStage(toProto(stage))\n         .setPipelineSize(pipelineSize)\n         .setMinBytesRcvd(minBytesRcvd)\n         .setMaxBytesRcvd(maxBytesRcvd)\n         .setLatestGenerationStamp(latestGenerationStamp)\n         .setRequestedChecksum(checksumProto)\n         .setCachingStrategy(getCachingStrategy(cachingStrategy))\n         .setAllowLazyPersist(allowLazyPersist)\n         .setPinning(pinning)\n-        .addAllTargetPinnings(PBHelperClient.convert(targetPinnings, 1));\n-\n+        .addAllTargetPinnings(PBHelperClient.convert(targetPinnings, 1))\n+        .addAllTargetStorageIds(PBHelperClient.convert(targetStorageIds, 1));\n     if (source !\u003d null) {\n       proto.setSource(PBHelperClient.convertDatanodeInfo(source));\n     }\n+    if (storageId !\u003d null) {\n+      proto.setStorageId(storageId);\n+    }\n \n     send(out, Op.WRITE_BLOCK, proto.build());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void writeBlock(final ExtendedBlock blk,\n      final StorageType storageType,\n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientName,\n      final DatanodeInfo[] targets,\n      final StorageType[] targetStorageTypes,\n      final DatanodeInfo source,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      final CachingStrategy cachingStrategy,\n      final boolean allowLazyPersist,\n      final boolean pinning,\n      final boolean[] targetPinnings,\n      final String storageId,\n      final String[] targetStorageIds) throws IOException {\n    ClientOperationHeaderProto header \u003d DataTransferProtoUtil.buildClientHeader(\n        blk, clientName, blockToken);\n\n    ChecksumProto checksumProto \u003d\n        DataTransferProtoUtil.toProto(requestedChecksum);\n\n    OpWriteBlockProto.Builder proto \u003d OpWriteBlockProto.newBuilder()\n        .setHeader(header)\n        .setStorageType(PBHelperClient.convertStorageType(storageType))\n        .addAllTargets(PBHelperClient.convert(targets, 1))\n        .addAllTargetStorageTypes(\n            PBHelperClient.convertStorageTypes(targetStorageTypes, 1))\n        .setStage(toProto(stage))\n        .setPipelineSize(pipelineSize)\n        .setMinBytesRcvd(minBytesRcvd)\n        .setMaxBytesRcvd(maxBytesRcvd)\n        .setLatestGenerationStamp(latestGenerationStamp)\n        .setRequestedChecksum(checksumProto)\n        .setCachingStrategy(getCachingStrategy(cachingStrategy))\n        .setAllowLazyPersist(allowLazyPersist)\n        .setPinning(pinning)\n        .addAllTargetPinnings(PBHelperClient.convert(targetPinnings, 1))\n        .addAllTargetStorageIds(PBHelperClient.convert(targetStorageIds, 1));\n    if (source !\u003d null) {\n      proto.setSource(PBHelperClient.convertDatanodeInfo(source));\n    }\n    if (storageId !\u003d null) {\n      proto.setStorageId(storageId);\n    }\n\n    send(out, Op.WRITE_BLOCK, proto.build());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Sender.java",
          "extendedDetails": {}
        }
      ]
    },
    "490bb5ebd6c6d6f9c08fcad167f976687fc3aa42": {
      "type": "Ymultichange(Yfilerename,Ybodychange)",
      "commitMessage": "HDFS-8934. Move ShortCircuitShm to hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "22/08/15 1:31 PM",
      "commitName": "490bb5ebd6c6d6f9c08fcad167f976687fc3aa42",
      "commitAuthor": "Haohui Mai",
      "subchanges": [
        {
          "type": "Yfilerename",
          "commitMessage": "HDFS-8934. Move ShortCircuitShm to hdfs-client. Contributed by Mingliang Liu.\n",
          "commitDate": "22/08/15 1:31 PM",
          "commitName": "490bb5ebd6c6d6f9c08fcad167f976687fc3aa42",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "22/08/15 12:39 AM",
          "commitNameOld": "61bf9cae6f3882c6e9a9222f59457b9be91e3018",
          "commitAuthorOld": "Karthik Kambatla",
          "daysBetweenCommits": 0.54,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,45 +1,45 @@\n   public void writeBlock(final ExtendedBlock blk,\n       final StorageType storageType, \n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientName,\n       final DatanodeInfo[] targets,\n       final StorageType[] targetStorageTypes, \n       final DatanodeInfo source,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum,\n       final CachingStrategy cachingStrategy,\n       final boolean allowLazyPersist,\n       final boolean pinning,\n       final boolean[] targetPinnings) throws IOException {\n     ClientOperationHeaderProto header \u003d DataTransferProtoUtil.buildClientHeader(\n         blk, clientName, blockToken);\n     \n     ChecksumProto checksumProto \u003d\n       DataTransferProtoUtil.toProto(requestedChecksum);\n \n     OpWriteBlockProto.Builder proto \u003d OpWriteBlockProto.newBuilder()\n       .setHeader(header)\n-      .setStorageType(PBHelper.convertStorageType(storageType))\n-      .addAllTargets(PBHelper.convert(targets, 1))\n-      .addAllTargetStorageTypes(PBHelper.convertStorageTypes(targetStorageTypes, 1))\n+      .setStorageType(PBHelperClient.convertStorageType(storageType))\n+      .addAllTargets(PBHelperClient.convert(targets, 1))\n+      .addAllTargetStorageTypes(PBHelperClient.convertStorageTypes(targetStorageTypes, 1))\n       .setStage(toProto(stage))\n       .setPipelineSize(pipelineSize)\n       .setMinBytesRcvd(minBytesRcvd)\n       .setMaxBytesRcvd(maxBytesRcvd)\n       .setLatestGenerationStamp(latestGenerationStamp)\n       .setRequestedChecksum(checksumProto)\n       .setCachingStrategy(getCachingStrategy(cachingStrategy))\n       .setAllowLazyPersist(allowLazyPersist)\n       .setPinning(pinning)\n-      .addAllTargetPinnings(PBHelper.convert(targetPinnings, 1));\n+      .addAllTargetPinnings(PBHelperClient.convert(targetPinnings, 1));\n     \n     if (source !\u003d null) {\n-      proto.setSource(PBHelper.convertDatanodeInfo(source));\n+      proto.setSource(PBHelperClient.convertDatanodeInfo(source));\n     }\n \n     send(out, Op.WRITE_BLOCK, proto.build());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void writeBlock(final ExtendedBlock blk,\n      final StorageType storageType, \n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientName,\n      final DatanodeInfo[] targets,\n      final StorageType[] targetStorageTypes, \n      final DatanodeInfo source,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      final CachingStrategy cachingStrategy,\n      final boolean allowLazyPersist,\n      final boolean pinning,\n      final boolean[] targetPinnings) throws IOException {\n    ClientOperationHeaderProto header \u003d DataTransferProtoUtil.buildClientHeader(\n        blk, clientName, blockToken);\n    \n    ChecksumProto checksumProto \u003d\n      DataTransferProtoUtil.toProto(requestedChecksum);\n\n    OpWriteBlockProto.Builder proto \u003d OpWriteBlockProto.newBuilder()\n      .setHeader(header)\n      .setStorageType(PBHelperClient.convertStorageType(storageType))\n      .addAllTargets(PBHelperClient.convert(targets, 1))\n      .addAllTargetStorageTypes(PBHelperClient.convertStorageTypes(targetStorageTypes, 1))\n      .setStage(toProto(stage))\n      .setPipelineSize(pipelineSize)\n      .setMinBytesRcvd(minBytesRcvd)\n      .setMaxBytesRcvd(maxBytesRcvd)\n      .setLatestGenerationStamp(latestGenerationStamp)\n      .setRequestedChecksum(checksumProto)\n      .setCachingStrategy(getCachingStrategy(cachingStrategy))\n      .setAllowLazyPersist(allowLazyPersist)\n      .setPinning(pinning)\n      .addAllTargetPinnings(PBHelperClient.convert(targetPinnings, 1));\n    \n    if (source !\u003d null) {\n      proto.setSource(PBHelperClient.convertDatanodeInfo(source));\n    }\n\n    send(out, Op.WRITE_BLOCK, proto.build());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Sender.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Sender.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Sender.java"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-8934. Move ShortCircuitShm to hdfs-client. Contributed by Mingliang Liu.\n",
          "commitDate": "22/08/15 1:31 PM",
          "commitName": "490bb5ebd6c6d6f9c08fcad167f976687fc3aa42",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "22/08/15 12:39 AM",
          "commitNameOld": "61bf9cae6f3882c6e9a9222f59457b9be91e3018",
          "commitAuthorOld": "Karthik Kambatla",
          "daysBetweenCommits": 0.54,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,45 +1,45 @@\n   public void writeBlock(final ExtendedBlock blk,\n       final StorageType storageType, \n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientName,\n       final DatanodeInfo[] targets,\n       final StorageType[] targetStorageTypes, \n       final DatanodeInfo source,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum,\n       final CachingStrategy cachingStrategy,\n       final boolean allowLazyPersist,\n       final boolean pinning,\n       final boolean[] targetPinnings) throws IOException {\n     ClientOperationHeaderProto header \u003d DataTransferProtoUtil.buildClientHeader(\n         blk, clientName, blockToken);\n     \n     ChecksumProto checksumProto \u003d\n       DataTransferProtoUtil.toProto(requestedChecksum);\n \n     OpWriteBlockProto.Builder proto \u003d OpWriteBlockProto.newBuilder()\n       .setHeader(header)\n-      .setStorageType(PBHelper.convertStorageType(storageType))\n-      .addAllTargets(PBHelper.convert(targets, 1))\n-      .addAllTargetStorageTypes(PBHelper.convertStorageTypes(targetStorageTypes, 1))\n+      .setStorageType(PBHelperClient.convertStorageType(storageType))\n+      .addAllTargets(PBHelperClient.convert(targets, 1))\n+      .addAllTargetStorageTypes(PBHelperClient.convertStorageTypes(targetStorageTypes, 1))\n       .setStage(toProto(stage))\n       .setPipelineSize(pipelineSize)\n       .setMinBytesRcvd(minBytesRcvd)\n       .setMaxBytesRcvd(maxBytesRcvd)\n       .setLatestGenerationStamp(latestGenerationStamp)\n       .setRequestedChecksum(checksumProto)\n       .setCachingStrategy(getCachingStrategy(cachingStrategy))\n       .setAllowLazyPersist(allowLazyPersist)\n       .setPinning(pinning)\n-      .addAllTargetPinnings(PBHelper.convert(targetPinnings, 1));\n+      .addAllTargetPinnings(PBHelperClient.convert(targetPinnings, 1));\n     \n     if (source !\u003d null) {\n-      proto.setSource(PBHelper.convertDatanodeInfo(source));\n+      proto.setSource(PBHelperClient.convertDatanodeInfo(source));\n     }\n \n     send(out, Op.WRITE_BLOCK, proto.build());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void writeBlock(final ExtendedBlock blk,\n      final StorageType storageType, \n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientName,\n      final DatanodeInfo[] targets,\n      final StorageType[] targetStorageTypes, \n      final DatanodeInfo source,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      final CachingStrategy cachingStrategy,\n      final boolean allowLazyPersist,\n      final boolean pinning,\n      final boolean[] targetPinnings) throws IOException {\n    ClientOperationHeaderProto header \u003d DataTransferProtoUtil.buildClientHeader(\n        blk, clientName, blockToken);\n    \n    ChecksumProto checksumProto \u003d\n      DataTransferProtoUtil.toProto(requestedChecksum);\n\n    OpWriteBlockProto.Builder proto \u003d OpWriteBlockProto.newBuilder()\n      .setHeader(header)\n      .setStorageType(PBHelperClient.convertStorageType(storageType))\n      .addAllTargets(PBHelperClient.convert(targets, 1))\n      .addAllTargetStorageTypes(PBHelperClient.convertStorageTypes(targetStorageTypes, 1))\n      .setStage(toProto(stage))\n      .setPipelineSize(pipelineSize)\n      .setMinBytesRcvd(minBytesRcvd)\n      .setMaxBytesRcvd(maxBytesRcvd)\n      .setLatestGenerationStamp(latestGenerationStamp)\n      .setRequestedChecksum(checksumProto)\n      .setCachingStrategy(getCachingStrategy(cachingStrategy))\n      .setAllowLazyPersist(allowLazyPersist)\n      .setPinning(pinning)\n      .addAllTargetPinnings(PBHelperClient.convert(targetPinnings, 1));\n    \n    if (source !\u003d null) {\n      proto.setSource(PBHelperClient.convertDatanodeInfo(source));\n    }\n\n    send(out, Op.WRITE_BLOCK, proto.build());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Sender.java",
          "extendedDetails": {}
        }
      ]
    },
    "085b1e293ff53f7a86aa21406cfd4bfa0f3bf33b": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-6133. Add a feature for replica pinning so that a pinned replica will not be moved by Balancer/Mover.  Contributed by zhaoyunjiong\n",
      "commitDate": "11/02/15 3:12 PM",
      "commitName": "085b1e293ff53f7a86aa21406cfd4bfa0f3bf33b",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-6133. Add a feature for replica pinning so that a pinned replica will not be moved by Balancer/Mover.  Contributed by zhaoyunjiong\n",
          "commitDate": "11/02/15 3:12 PM",
          "commitName": "085b1e293ff53f7a86aa21406cfd4bfa0f3bf33b",
          "commitAuthor": "Tsz-Wo Nicholas Sze",
          "commitDateOld": "30/01/15 4:01 PM",
          "commitNameOld": "09ad9a868a89922e9b55b3e7c5b9f41fa54d3770",
          "commitAuthorOld": "Colin Patrick Mccabe",
          "daysBetweenCommits": 11.97,
          "commitsBetweenForRepo": 127,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,41 +1,45 @@\n   public void writeBlock(final ExtendedBlock blk,\n       final StorageType storageType, \n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientName,\n       final DatanodeInfo[] targets,\n       final StorageType[] targetStorageTypes, \n       final DatanodeInfo source,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum,\n       final CachingStrategy cachingStrategy,\n-      final boolean allowLazyPersist) throws IOException {\n+      final boolean allowLazyPersist,\n+      final boolean pinning,\n+      final boolean[] targetPinnings) throws IOException {\n     ClientOperationHeaderProto header \u003d DataTransferProtoUtil.buildClientHeader(\n         blk, clientName, blockToken);\n     \n     ChecksumProto checksumProto \u003d\n       DataTransferProtoUtil.toProto(requestedChecksum);\n \n     OpWriteBlockProto.Builder proto \u003d OpWriteBlockProto.newBuilder()\n       .setHeader(header)\n       .setStorageType(PBHelper.convertStorageType(storageType))\n       .addAllTargets(PBHelper.convert(targets, 1))\n       .addAllTargetStorageTypes(PBHelper.convertStorageTypes(targetStorageTypes, 1))\n       .setStage(toProto(stage))\n       .setPipelineSize(pipelineSize)\n       .setMinBytesRcvd(minBytesRcvd)\n       .setMaxBytesRcvd(maxBytesRcvd)\n       .setLatestGenerationStamp(latestGenerationStamp)\n       .setRequestedChecksum(checksumProto)\n       .setCachingStrategy(getCachingStrategy(cachingStrategy))\n-      .setAllowLazyPersist(allowLazyPersist);\n+      .setAllowLazyPersist(allowLazyPersist)\n+      .setPinning(pinning)\n+      .addAllTargetPinnings(PBHelper.convert(targetPinnings, 1));\n     \n     if (source !\u003d null) {\n       proto.setSource(PBHelper.convertDatanodeInfo(source));\n     }\n \n     send(out, Op.WRITE_BLOCK, proto.build());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void writeBlock(final ExtendedBlock blk,\n      final StorageType storageType, \n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientName,\n      final DatanodeInfo[] targets,\n      final StorageType[] targetStorageTypes, \n      final DatanodeInfo source,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      final CachingStrategy cachingStrategy,\n      final boolean allowLazyPersist,\n      final boolean pinning,\n      final boolean[] targetPinnings) throws IOException {\n    ClientOperationHeaderProto header \u003d DataTransferProtoUtil.buildClientHeader(\n        blk, clientName, blockToken);\n    \n    ChecksumProto checksumProto \u003d\n      DataTransferProtoUtil.toProto(requestedChecksum);\n\n    OpWriteBlockProto.Builder proto \u003d OpWriteBlockProto.newBuilder()\n      .setHeader(header)\n      .setStorageType(PBHelper.convertStorageType(storageType))\n      .addAllTargets(PBHelper.convert(targets, 1))\n      .addAllTargetStorageTypes(PBHelper.convertStorageTypes(targetStorageTypes, 1))\n      .setStage(toProto(stage))\n      .setPipelineSize(pipelineSize)\n      .setMinBytesRcvd(minBytesRcvd)\n      .setMaxBytesRcvd(maxBytesRcvd)\n      .setLatestGenerationStamp(latestGenerationStamp)\n      .setRequestedChecksum(checksumProto)\n      .setCachingStrategy(getCachingStrategy(cachingStrategy))\n      .setAllowLazyPersist(allowLazyPersist)\n      .setPinning(pinning)\n      .addAllTargetPinnings(PBHelper.convert(targetPinnings, 1));\n    \n    if (source !\u003d null) {\n      proto.setSource(PBHelper.convertDatanodeInfo(source));\n    }\n\n    send(out, Op.WRITE_BLOCK, proto.build());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Sender.java",
          "extendedDetails": {
            "oldValue": "[blk-ExtendedBlock(modifiers-final), storageType-StorageType(modifiers-final), blockToken-Token\u003cBlockTokenIdentifier\u003e(modifiers-final), clientName-String(modifiers-final), targets-DatanodeInfo[](modifiers-final), targetStorageTypes-StorageType[](modifiers-final), source-DatanodeInfo(modifiers-final), stage-BlockConstructionStage(modifiers-final), pipelineSize-int(modifiers-final), minBytesRcvd-long(modifiers-final), maxBytesRcvd-long(modifiers-final), latestGenerationStamp-long(modifiers-final), requestedChecksum-DataChecksum, cachingStrategy-CachingStrategy(modifiers-final), allowLazyPersist-boolean(modifiers-final)]",
            "newValue": "[blk-ExtendedBlock(modifiers-final), storageType-StorageType(modifiers-final), blockToken-Token\u003cBlockTokenIdentifier\u003e(modifiers-final), clientName-String(modifiers-final), targets-DatanodeInfo[](modifiers-final), targetStorageTypes-StorageType[](modifiers-final), source-DatanodeInfo(modifiers-final), stage-BlockConstructionStage(modifiers-final), pipelineSize-int(modifiers-final), minBytesRcvd-long(modifiers-final), maxBytesRcvd-long(modifiers-final), latestGenerationStamp-long(modifiers-final), requestedChecksum-DataChecksum, cachingStrategy-CachingStrategy(modifiers-final), allowLazyPersist-boolean(modifiers-final), pinning-boolean(modifiers-final), targetPinnings-boolean[](modifiers-final)]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-6133. Add a feature for replica pinning so that a pinned replica will not be moved by Balancer/Mover.  Contributed by zhaoyunjiong\n",
          "commitDate": "11/02/15 3:12 PM",
          "commitName": "085b1e293ff53f7a86aa21406cfd4bfa0f3bf33b",
          "commitAuthor": "Tsz-Wo Nicholas Sze",
          "commitDateOld": "30/01/15 4:01 PM",
          "commitNameOld": "09ad9a868a89922e9b55b3e7c5b9f41fa54d3770",
          "commitAuthorOld": "Colin Patrick Mccabe",
          "daysBetweenCommits": 11.97,
          "commitsBetweenForRepo": 127,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,41 +1,45 @@\n   public void writeBlock(final ExtendedBlock blk,\n       final StorageType storageType, \n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientName,\n       final DatanodeInfo[] targets,\n       final StorageType[] targetStorageTypes, \n       final DatanodeInfo source,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum,\n       final CachingStrategy cachingStrategy,\n-      final boolean allowLazyPersist) throws IOException {\n+      final boolean allowLazyPersist,\n+      final boolean pinning,\n+      final boolean[] targetPinnings) throws IOException {\n     ClientOperationHeaderProto header \u003d DataTransferProtoUtil.buildClientHeader(\n         blk, clientName, blockToken);\n     \n     ChecksumProto checksumProto \u003d\n       DataTransferProtoUtil.toProto(requestedChecksum);\n \n     OpWriteBlockProto.Builder proto \u003d OpWriteBlockProto.newBuilder()\n       .setHeader(header)\n       .setStorageType(PBHelper.convertStorageType(storageType))\n       .addAllTargets(PBHelper.convert(targets, 1))\n       .addAllTargetStorageTypes(PBHelper.convertStorageTypes(targetStorageTypes, 1))\n       .setStage(toProto(stage))\n       .setPipelineSize(pipelineSize)\n       .setMinBytesRcvd(minBytesRcvd)\n       .setMaxBytesRcvd(maxBytesRcvd)\n       .setLatestGenerationStamp(latestGenerationStamp)\n       .setRequestedChecksum(checksumProto)\n       .setCachingStrategy(getCachingStrategy(cachingStrategy))\n-      .setAllowLazyPersist(allowLazyPersist);\n+      .setAllowLazyPersist(allowLazyPersist)\n+      .setPinning(pinning)\n+      .addAllTargetPinnings(PBHelper.convert(targetPinnings, 1));\n     \n     if (source !\u003d null) {\n       proto.setSource(PBHelper.convertDatanodeInfo(source));\n     }\n \n     send(out, Op.WRITE_BLOCK, proto.build());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void writeBlock(final ExtendedBlock blk,\n      final StorageType storageType, \n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientName,\n      final DatanodeInfo[] targets,\n      final StorageType[] targetStorageTypes, \n      final DatanodeInfo source,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      final CachingStrategy cachingStrategy,\n      final boolean allowLazyPersist,\n      final boolean pinning,\n      final boolean[] targetPinnings) throws IOException {\n    ClientOperationHeaderProto header \u003d DataTransferProtoUtil.buildClientHeader(\n        blk, clientName, blockToken);\n    \n    ChecksumProto checksumProto \u003d\n      DataTransferProtoUtil.toProto(requestedChecksum);\n\n    OpWriteBlockProto.Builder proto \u003d OpWriteBlockProto.newBuilder()\n      .setHeader(header)\n      .setStorageType(PBHelper.convertStorageType(storageType))\n      .addAllTargets(PBHelper.convert(targets, 1))\n      .addAllTargetStorageTypes(PBHelper.convertStorageTypes(targetStorageTypes, 1))\n      .setStage(toProto(stage))\n      .setPipelineSize(pipelineSize)\n      .setMinBytesRcvd(minBytesRcvd)\n      .setMaxBytesRcvd(maxBytesRcvd)\n      .setLatestGenerationStamp(latestGenerationStamp)\n      .setRequestedChecksum(checksumProto)\n      .setCachingStrategy(getCachingStrategy(cachingStrategy))\n      .setAllowLazyPersist(allowLazyPersist)\n      .setPinning(pinning)\n      .addAllTargetPinnings(PBHelper.convert(targetPinnings, 1));\n    \n    if (source !\u003d null) {\n      proto.setSource(PBHelper.convertDatanodeInfo(source));\n    }\n\n    send(out, Op.WRITE_BLOCK, proto.build());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Sender.java",
          "extendedDetails": {}
        }
      ]
    }
  }
}