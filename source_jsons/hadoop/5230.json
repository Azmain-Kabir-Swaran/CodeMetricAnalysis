{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSDirWriteFileOp.java",
  "functionName": "analyzeFileState",
  "functionId": "analyzeFileState___fsn-FSNamesystem__iip-INodesInPath__fileId-long__clientName-String__previous-ExtendedBlock__onRetryBlock-LocatedBlock[]",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirWriteFileOp.java",
  "functionStartLine": 596,
  "functionEndLine": 678,
  "numCommitsSeen": 653,
  "timeTaken": 33600,
  "changeHistory": [
    "869393643de23dcb010cc33091c8eb398de0fd6c",
    "164cbe643988f878f0f4100a4de51783e5b6738e",
    "e535e0f05b5fbd087c93238deb888cc985254b4c",
    "f4c523b69ba55b1fd35e8995c3011a9f546ac835",
    "c17439c2ddd921b63b1635e6f1cba634b8da8557",
    "4928f5473394981829e5ffd4b16ea0801baf5c45",
    "d8ea443af0b1c8289a1dd738945831ff8be0e9c1",
    "1af8c148626effe1b41fc536019fd3349f485d59",
    "e5afac5896a1a88e152746598527d91f73cbb724",
    "6ae2a0d048e133b43249c248a75a4d77d9abb80d",
    "76e7264e8d6407f527bd877009aca11f7bb63bd7",
    "75c545486080042952c775f7964212c15ce65f73",
    "c7c71cdba50cb7d8282622cd496cc913c80cff54",
    "1382ae525c67bf95d8f3a436b547dbc72cfbb177",
    "c78e3a7cdd10c40454e9acb06986ba6d8573cb19",
    "18312804e9c86c0ea6a259e288994fea6fa366ef",
    "6e8722e49c29a19dd13e161001d2464bb1f22189",
    "d9c5f20333ef510c0ace066c0a811f9e953e9e17",
    "f131dba8a3d603a5d15c4f035ed3da75b4daf0dc",
    "ce68f410b05a58ad05965f32ad7f5b246b363a75",
    "e3d7ef36ef7dd31b295b1f1d86a1bfa7887ca771",
    "34f08944b7c8d58f531a3f3bf3d4ee4cd3fa643a",
    "1fe1942328856dd832e9f94fb56a40ab3d810870",
    "3f070e83b1f4e0211ece8c0ab508a61188ad352a",
    "b1333e5b561d01a010e2e1311e8501879f377bdc",
    "fac3883188d9c4f1fe188d98f88cb3c83b243bbd"
  ],
  "changeHistoryShort": {
    "869393643de23dcb010cc33091c8eb398de0fd6c": "Ymultichange(Yparameterchange,Ybodychange)",
    "164cbe643988f878f0f4100a4de51783e5b6738e": "Ybodychange",
    "e535e0f05b5fbd087c93238deb888cc985254b4c": "Ybodychange",
    "f4c523b69ba55b1fd35e8995c3011a9f546ac835": "Ybodychange",
    "c17439c2ddd921b63b1635e6f1cba634b8da8557": "Ybodychange",
    "4928f5473394981829e5ffd4b16ea0801baf5c45": "Ybodychange",
    "d8ea443af0b1c8289a1dd738945831ff8be0e9c1": "Ybodychange",
    "1af8c148626effe1b41fc536019fd3349f485d59": "Ybodychange",
    "e5afac5896a1a88e152746598527d91f73cbb724": "Ymultichange(Ymovefromfile,Ymodifierchange,Ybodychange,Yparameterchange)",
    "6ae2a0d048e133b43249c248a75a4d77d9abb80d": "Ybodychange",
    "76e7264e8d6407f527bd877009aca11f7bb63bd7": "Ybodychange",
    "75c545486080042952c775f7964212c15ce65f73": "Ybodychange",
    "c7c71cdba50cb7d8282622cd496cc913c80cff54": "Ybodychange",
    "1382ae525c67bf95d8f3a436b547dbc72cfbb177": "Ybodychange",
    "c78e3a7cdd10c40454e9acb06986ba6d8573cb19": "Ybodychange",
    "18312804e9c86c0ea6a259e288994fea6fa366ef": "Ybodychange",
    "6e8722e49c29a19dd13e161001d2464bb1f22189": "Ybodychange",
    "d9c5f20333ef510c0ace066c0a811f9e953e9e17": "Ymultichange(Yreturntypechange,Ybodychange)",
    "f131dba8a3d603a5d15c4f035ed3da75b4daf0dc": "Ymultichange(Yreturntypechange,Ybodychange)",
    "ce68f410b05a58ad05965f32ad7f5b246b363a75": "Ybodychange",
    "e3d7ef36ef7dd31b295b1f1d86a1bfa7887ca771": "Ybodychange",
    "34f08944b7c8d58f531a3f3bf3d4ee4cd3fa643a": "Ybodychange",
    "1fe1942328856dd832e9f94fb56a40ab3d810870": "Ybodychange",
    "3f070e83b1f4e0211ece8c0ab508a61188ad352a": "Ybodychange",
    "b1333e5b561d01a010e2e1311e8501879f377bdc": "Ybodychange",
    "fac3883188d9c4f1fe188d98f88cb3c83b243bbd": "Ybodychange"
  },
  "changeHistoryDetails": {
    "869393643de23dcb010cc33091c8eb398de0fd6c": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-10745. Directly resolve paths into INodesInPath. Contributed by Daryn Sharp.\n",
      "commitDate": "17/08/16 1:53 PM",
      "commitName": "869393643de23dcb010cc33091c8eb398de0fd6c",
      "commitAuthor": "Kihwal Lee",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-10745. Directly resolve paths into INodesInPath. Contributed by Daryn Sharp.\n",
          "commitDate": "17/08/16 1:53 PM",
          "commitName": "869393643de23dcb010cc33091c8eb398de0fd6c",
          "commitAuthor": "Kihwal Lee",
          "commitDateOld": "15/08/16 2:45 PM",
          "commitNameOld": "03dea65e0b17ca2f9460bb6110f6ab3a321b8bf2",
          "commitAuthorOld": "Kihwal Lee",
          "daysBetweenCommits": 1.96,
          "commitsBetweenForRepo": 23,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,100 +1,83 @@\n   private static FileState analyzeFileState(\n-      FSNamesystem fsn, String src, long fileId, String clientName,\n+      FSNamesystem fsn, INodesInPath iip, long fileId, String clientName,\n       ExtendedBlock previous, LocatedBlock[] onRetryBlock)\n       throws IOException {\n     assert fsn.hasReadLock();\n-\n+    String src \u003d iip.getPath();\n     checkBlock(fsn, previous);\n     onRetryBlock[0] \u003d null;\n     fsn.checkNameNodeSafeMode(\"Cannot add block to \" + src);\n \n     // have we exceeded the configured limit of fs objects.\n     fsn.checkFsObjectLimit();\n \n     Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n-    final INode inode;\n-    final INodesInPath iip;\n-    if (fileId \u003d\u003d HdfsConstants.GRANDFATHER_INODE_ID) {\n-      // Older clients may not have given us an inode ID to work with.\n-      // In this case, we have to try to resolve the path and hope it\n-      // hasn\u0027t changed or been deleted since the file was opened for write.\n-      iip \u003d fsn.dir.getINodesInPath4Write(src);\n-      inode \u003d iip.getLastINode();\n-    } else {\n-      // Newer clients pass the inode ID, so we can just get the inode\n-      // directly.\n-      inode \u003d fsn.dir.getInode(fileId);\n-      iip \u003d INodesInPath.fromINode(inode);\n-      if (inode !\u003d null) {\n-        src \u003d iip.getPath();\n-      }\n-    }\n-    final INodeFile file \u003d fsn.checkLease(src, clientName, inode, fileId);\n+    final INodeFile file \u003d fsn.checkLease(iip, clientName, fileId);\n     BlockInfo lastBlockInFile \u003d file.getLastBlock();\n     if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n       // The block that the client claims is the current last block\n       // doesn\u0027t match up with what we think is the last block. There are\n       // four possibilities:\n       // 1) This is the first block allocation of an append() pipeline\n       //    which started appending exactly at or exceeding the block boundary.\n       //    In this case, the client isn\u0027t passed the previous block,\n       //    so it makes the allocateBlock() call with previous\u003dnull.\n       //    We can distinguish this since the last block of the file\n       //    will be exactly a full block.\n       // 2) This is a retry from a client that missed the response of a\n       //    prior getAdditionalBlock() call, perhaps because of a network\n       //    timeout, or because of an HA failover. In that case, we know\n       //    by the fact that the client is re-issuing the RPC that it\n       //    never began to write to the old block. Hence it is safe to\n       //    to return the existing block.\n       // 3) This is an entirely bogus request/bug -- we should error out\n       //    rather than potentially appending a new block with an empty\n       //    one in the middle, etc\n       // 4) This is a retry from a client that timed out while\n       //    the prior getAdditionalBlock() is still being processed,\n       //    currently working on chooseTarget().\n       //    There are no means to distinguish between the first and\n       //    the second attempts in Part I, because the first one hasn\u0027t\n       //    changed the namesystem state yet.\n       //    We run this analysis again in Part II where case 4 is impossible.\n \n       BlockInfo penultimateBlock \u003d file.getPenultimateBlock();\n       if (previous \u003d\u003d null \u0026\u0026\n           lastBlockInFile !\u003d null \u0026\u0026\n           lastBlockInFile.getNumBytes() \u003e\u003d file.getPreferredBlockSize() \u0026\u0026\n           lastBlockInFile.isComplete()) {\n         // Case 1\n         if (NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\n                \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n                \" writing to a file with a complete previous block: src\u003d\" +\n                src + \" lastBlock\u003d\" + lastBlockInFile);\n         }\n       } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n         if (lastBlockInFile.getNumBytes() !\u003d 0) {\n           throw new IOException(\n               \"Request looked like a retry to allocate block \" +\n               lastBlockInFile + \" but it already contains \" +\n               lastBlockInFile.getNumBytes() + \" bytes\");\n         }\n \n         // Case 2\n         // Return the last block.\n         NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: caught retry for \" +\n             \"allocation of a new block in \" + src + \". Returning previously\" +\n             \" allocated block \" + lastBlockInFile);\n         long offset \u003d file.computeFileSize();\n         BlockUnderConstructionFeature uc \u003d\n             lastBlockInFile.getUnderConstructionFeature();\n         onRetryBlock[0] \u003d makeLocatedBlock(fsn, lastBlockInFile,\n             uc.getExpectedStorageLocations(), offset);\n         return new FileState(file, src, iip);\n       } else {\n         // Case 3\n         throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n             \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n             \"last block in file \" + lastBlockInFile);\n       }\n     }\n     return new FileState(file, src, iip);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private static FileState analyzeFileState(\n      FSNamesystem fsn, INodesInPath iip, long fileId, String clientName,\n      ExtendedBlock previous, LocatedBlock[] onRetryBlock)\n      throws IOException {\n    assert fsn.hasReadLock();\n    String src \u003d iip.getPath();\n    checkBlock(fsn, previous);\n    onRetryBlock[0] \u003d null;\n    fsn.checkNameNodeSafeMode(\"Cannot add block to \" + src);\n\n    // have we exceeded the configured limit of fs objects.\n    fsn.checkFsObjectLimit();\n\n    Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n    final INodeFile file \u003d fsn.checkLease(iip, clientName, fileId);\n    BlockInfo lastBlockInFile \u003d file.getLastBlock();\n    if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n      // The block that the client claims is the current last block\n      // doesn\u0027t match up with what we think is the last block. There are\n      // four possibilities:\n      // 1) This is the first block allocation of an append() pipeline\n      //    which started appending exactly at or exceeding the block boundary.\n      //    In this case, the client isn\u0027t passed the previous block,\n      //    so it makes the allocateBlock() call with previous\u003dnull.\n      //    We can distinguish this since the last block of the file\n      //    will be exactly a full block.\n      // 2) This is a retry from a client that missed the response of a\n      //    prior getAdditionalBlock() call, perhaps because of a network\n      //    timeout, or because of an HA failover. In that case, we know\n      //    by the fact that the client is re-issuing the RPC that it\n      //    never began to write to the old block. Hence it is safe to\n      //    to return the existing block.\n      // 3) This is an entirely bogus request/bug -- we should error out\n      //    rather than potentially appending a new block with an empty\n      //    one in the middle, etc\n      // 4) This is a retry from a client that timed out while\n      //    the prior getAdditionalBlock() is still being processed,\n      //    currently working on chooseTarget().\n      //    There are no means to distinguish between the first and\n      //    the second attempts in Part I, because the first one hasn\u0027t\n      //    changed the namesystem state yet.\n      //    We run this analysis again in Part II where case 4 is impossible.\n\n      BlockInfo penultimateBlock \u003d file.getPenultimateBlock();\n      if (previous \u003d\u003d null \u0026\u0026\n          lastBlockInFile !\u003d null \u0026\u0026\n          lastBlockInFile.getNumBytes() \u003e\u003d file.getPreferredBlockSize() \u0026\u0026\n          lastBlockInFile.isComplete()) {\n        // Case 1\n        if (NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\n               \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n               \" writing to a file with a complete previous block: src\u003d\" +\n               src + \" lastBlock\u003d\" + lastBlockInFile);\n        }\n      } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n        if (lastBlockInFile.getNumBytes() !\u003d 0) {\n          throw new IOException(\n              \"Request looked like a retry to allocate block \" +\n              lastBlockInFile + \" but it already contains \" +\n              lastBlockInFile.getNumBytes() + \" bytes\");\n        }\n\n        // Case 2\n        // Return the last block.\n        NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: caught retry for \" +\n            \"allocation of a new block in \" + src + \". Returning previously\" +\n            \" allocated block \" + lastBlockInFile);\n        long offset \u003d file.computeFileSize();\n        BlockUnderConstructionFeature uc \u003d\n            lastBlockInFile.getUnderConstructionFeature();\n        onRetryBlock[0] \u003d makeLocatedBlock(fsn, lastBlockInFile,\n            uc.getExpectedStorageLocations(), offset);\n        return new FileState(file, src, iip);\n      } else {\n        // Case 3\n        throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n            \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n            \"last block in file \" + lastBlockInFile);\n      }\n    }\n    return new FileState(file, src, iip);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirWriteFileOp.java",
          "extendedDetails": {
            "oldValue": "[fsn-FSNamesystem, src-String, fileId-long, clientName-String, previous-ExtendedBlock, onRetryBlock-LocatedBlock[]]",
            "newValue": "[fsn-FSNamesystem, iip-INodesInPath, fileId-long, clientName-String, previous-ExtendedBlock, onRetryBlock-LocatedBlock[]]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-10745. Directly resolve paths into INodesInPath. Contributed by Daryn Sharp.\n",
          "commitDate": "17/08/16 1:53 PM",
          "commitName": "869393643de23dcb010cc33091c8eb398de0fd6c",
          "commitAuthor": "Kihwal Lee",
          "commitDateOld": "15/08/16 2:45 PM",
          "commitNameOld": "03dea65e0b17ca2f9460bb6110f6ab3a321b8bf2",
          "commitAuthorOld": "Kihwal Lee",
          "daysBetweenCommits": 1.96,
          "commitsBetweenForRepo": 23,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,100 +1,83 @@\n   private static FileState analyzeFileState(\n-      FSNamesystem fsn, String src, long fileId, String clientName,\n+      FSNamesystem fsn, INodesInPath iip, long fileId, String clientName,\n       ExtendedBlock previous, LocatedBlock[] onRetryBlock)\n       throws IOException {\n     assert fsn.hasReadLock();\n-\n+    String src \u003d iip.getPath();\n     checkBlock(fsn, previous);\n     onRetryBlock[0] \u003d null;\n     fsn.checkNameNodeSafeMode(\"Cannot add block to \" + src);\n \n     // have we exceeded the configured limit of fs objects.\n     fsn.checkFsObjectLimit();\n \n     Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n-    final INode inode;\n-    final INodesInPath iip;\n-    if (fileId \u003d\u003d HdfsConstants.GRANDFATHER_INODE_ID) {\n-      // Older clients may not have given us an inode ID to work with.\n-      // In this case, we have to try to resolve the path and hope it\n-      // hasn\u0027t changed or been deleted since the file was opened for write.\n-      iip \u003d fsn.dir.getINodesInPath4Write(src);\n-      inode \u003d iip.getLastINode();\n-    } else {\n-      // Newer clients pass the inode ID, so we can just get the inode\n-      // directly.\n-      inode \u003d fsn.dir.getInode(fileId);\n-      iip \u003d INodesInPath.fromINode(inode);\n-      if (inode !\u003d null) {\n-        src \u003d iip.getPath();\n-      }\n-    }\n-    final INodeFile file \u003d fsn.checkLease(src, clientName, inode, fileId);\n+    final INodeFile file \u003d fsn.checkLease(iip, clientName, fileId);\n     BlockInfo lastBlockInFile \u003d file.getLastBlock();\n     if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n       // The block that the client claims is the current last block\n       // doesn\u0027t match up with what we think is the last block. There are\n       // four possibilities:\n       // 1) This is the first block allocation of an append() pipeline\n       //    which started appending exactly at or exceeding the block boundary.\n       //    In this case, the client isn\u0027t passed the previous block,\n       //    so it makes the allocateBlock() call with previous\u003dnull.\n       //    We can distinguish this since the last block of the file\n       //    will be exactly a full block.\n       // 2) This is a retry from a client that missed the response of a\n       //    prior getAdditionalBlock() call, perhaps because of a network\n       //    timeout, or because of an HA failover. In that case, we know\n       //    by the fact that the client is re-issuing the RPC that it\n       //    never began to write to the old block. Hence it is safe to\n       //    to return the existing block.\n       // 3) This is an entirely bogus request/bug -- we should error out\n       //    rather than potentially appending a new block with an empty\n       //    one in the middle, etc\n       // 4) This is a retry from a client that timed out while\n       //    the prior getAdditionalBlock() is still being processed,\n       //    currently working on chooseTarget().\n       //    There are no means to distinguish between the first and\n       //    the second attempts in Part I, because the first one hasn\u0027t\n       //    changed the namesystem state yet.\n       //    We run this analysis again in Part II where case 4 is impossible.\n \n       BlockInfo penultimateBlock \u003d file.getPenultimateBlock();\n       if (previous \u003d\u003d null \u0026\u0026\n           lastBlockInFile !\u003d null \u0026\u0026\n           lastBlockInFile.getNumBytes() \u003e\u003d file.getPreferredBlockSize() \u0026\u0026\n           lastBlockInFile.isComplete()) {\n         // Case 1\n         if (NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\n                \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n                \" writing to a file with a complete previous block: src\u003d\" +\n                src + \" lastBlock\u003d\" + lastBlockInFile);\n         }\n       } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n         if (lastBlockInFile.getNumBytes() !\u003d 0) {\n           throw new IOException(\n               \"Request looked like a retry to allocate block \" +\n               lastBlockInFile + \" but it already contains \" +\n               lastBlockInFile.getNumBytes() + \" bytes\");\n         }\n \n         // Case 2\n         // Return the last block.\n         NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: caught retry for \" +\n             \"allocation of a new block in \" + src + \". Returning previously\" +\n             \" allocated block \" + lastBlockInFile);\n         long offset \u003d file.computeFileSize();\n         BlockUnderConstructionFeature uc \u003d\n             lastBlockInFile.getUnderConstructionFeature();\n         onRetryBlock[0] \u003d makeLocatedBlock(fsn, lastBlockInFile,\n             uc.getExpectedStorageLocations(), offset);\n         return new FileState(file, src, iip);\n       } else {\n         // Case 3\n         throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n             \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n             \"last block in file \" + lastBlockInFile);\n       }\n     }\n     return new FileState(file, src, iip);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private static FileState analyzeFileState(\n      FSNamesystem fsn, INodesInPath iip, long fileId, String clientName,\n      ExtendedBlock previous, LocatedBlock[] onRetryBlock)\n      throws IOException {\n    assert fsn.hasReadLock();\n    String src \u003d iip.getPath();\n    checkBlock(fsn, previous);\n    onRetryBlock[0] \u003d null;\n    fsn.checkNameNodeSafeMode(\"Cannot add block to \" + src);\n\n    // have we exceeded the configured limit of fs objects.\n    fsn.checkFsObjectLimit();\n\n    Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n    final INodeFile file \u003d fsn.checkLease(iip, clientName, fileId);\n    BlockInfo lastBlockInFile \u003d file.getLastBlock();\n    if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n      // The block that the client claims is the current last block\n      // doesn\u0027t match up with what we think is the last block. There are\n      // four possibilities:\n      // 1) This is the first block allocation of an append() pipeline\n      //    which started appending exactly at or exceeding the block boundary.\n      //    In this case, the client isn\u0027t passed the previous block,\n      //    so it makes the allocateBlock() call with previous\u003dnull.\n      //    We can distinguish this since the last block of the file\n      //    will be exactly a full block.\n      // 2) This is a retry from a client that missed the response of a\n      //    prior getAdditionalBlock() call, perhaps because of a network\n      //    timeout, or because of an HA failover. In that case, we know\n      //    by the fact that the client is re-issuing the RPC that it\n      //    never began to write to the old block. Hence it is safe to\n      //    to return the existing block.\n      // 3) This is an entirely bogus request/bug -- we should error out\n      //    rather than potentially appending a new block with an empty\n      //    one in the middle, etc\n      // 4) This is a retry from a client that timed out while\n      //    the prior getAdditionalBlock() is still being processed,\n      //    currently working on chooseTarget().\n      //    There are no means to distinguish between the first and\n      //    the second attempts in Part I, because the first one hasn\u0027t\n      //    changed the namesystem state yet.\n      //    We run this analysis again in Part II where case 4 is impossible.\n\n      BlockInfo penultimateBlock \u003d file.getPenultimateBlock();\n      if (previous \u003d\u003d null \u0026\u0026\n          lastBlockInFile !\u003d null \u0026\u0026\n          lastBlockInFile.getNumBytes() \u003e\u003d file.getPreferredBlockSize() \u0026\u0026\n          lastBlockInFile.isComplete()) {\n        // Case 1\n        if (NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\n               \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n               \" writing to a file with a complete previous block: src\u003d\" +\n               src + \" lastBlock\u003d\" + lastBlockInFile);\n        }\n      } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n        if (lastBlockInFile.getNumBytes() !\u003d 0) {\n          throw new IOException(\n              \"Request looked like a retry to allocate block \" +\n              lastBlockInFile + \" but it already contains \" +\n              lastBlockInFile.getNumBytes() + \" bytes\");\n        }\n\n        // Case 2\n        // Return the last block.\n        NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: caught retry for \" +\n            \"allocation of a new block in \" + src + \". Returning previously\" +\n            \" allocated block \" + lastBlockInFile);\n        long offset \u003d file.computeFileSize();\n        BlockUnderConstructionFeature uc \u003d\n            lastBlockInFile.getUnderConstructionFeature();\n        onRetryBlock[0] \u003d makeLocatedBlock(fsn, lastBlockInFile,\n            uc.getExpectedStorageLocations(), offset);\n        return new FileState(file, src, iip);\n      } else {\n        // Case 3\n        throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n            \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n            \"last block in file \" + lastBlockInFile);\n      }\n    }\n    return new FileState(file, src, iip);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirWriteFileOp.java",
          "extendedDetails": {}
        }
      ]
    },
    "164cbe643988f878f0f4100a4de51783e5b6738e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8909. Erasure coding: update BlockInfoContiguousUC and BlockInfoStripedUC to use BlockUnderConstructionFeature. Contributed by Jing Zhao.\n",
      "commitDate": "27/08/15 1:02 AM",
      "commitName": "164cbe643988f878f0f4100a4de51783e5b6738e",
      "commitAuthor": "Walter Su",
      "commitDateOld": "26/08/15 6:11 PM",
      "commitNameOld": "067ec8c2b14fb0929dc348b763383838e06ff8a5",
      "commitAuthorOld": "Walter Su",
      "daysBetweenCommits": 0.29,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,100 +1,100 @@\n   private static FileState analyzeFileState(\n       FSNamesystem fsn, String src, long fileId, String clientName,\n       ExtendedBlock previous, LocatedBlock[] onRetryBlock)\n       throws IOException {\n     assert fsn.hasReadLock();\n \n     checkBlock(fsn, previous);\n     onRetryBlock[0] \u003d null;\n     fsn.checkNameNodeSafeMode(\"Cannot add block to \" + src);\n \n     // have we exceeded the configured limit of fs objects.\n     fsn.checkFsObjectLimit();\n \n     Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n     final INode inode;\n     final INodesInPath iip;\n     if (fileId \u003d\u003d HdfsConstants.GRANDFATHER_INODE_ID) {\n       // Older clients may not have given us an inode ID to work with.\n       // In this case, we have to try to resolve the path and hope it\n       // hasn\u0027t changed or been deleted since the file was opened for write.\n       iip \u003d fsn.dir.getINodesInPath4Write(src);\n       inode \u003d iip.getLastINode();\n     } else {\n       // Newer clients pass the inode ID, so we can just get the inode\n       // directly.\n       inode \u003d fsn.dir.getInode(fileId);\n       iip \u003d INodesInPath.fromINode(inode);\n       if (inode !\u003d null) {\n         src \u003d iip.getPath();\n       }\n     }\n     final INodeFile file \u003d fsn.checkLease(src, clientName, inode, fileId);\n     BlockInfo lastBlockInFile \u003d file.getLastBlock();\n     if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n       // The block that the client claims is the current last block\n       // doesn\u0027t match up with what we think is the last block. There are\n       // four possibilities:\n       // 1) This is the first block allocation of an append() pipeline\n       //    which started appending exactly at or exceeding the block boundary.\n       //    In this case, the client isn\u0027t passed the previous block,\n       //    so it makes the allocateBlock() call with previous\u003dnull.\n       //    We can distinguish this since the last block of the file\n       //    will be exactly a full block.\n       // 2) This is a retry from a client that missed the response of a\n       //    prior getAdditionalBlock() call, perhaps because of a network\n       //    timeout, or because of an HA failover. In that case, we know\n       //    by the fact that the client is re-issuing the RPC that it\n       //    never began to write to the old block. Hence it is safe to\n       //    to return the existing block.\n       // 3) This is an entirely bogus request/bug -- we should error out\n       //    rather than potentially appending a new block with an empty\n       //    one in the middle, etc\n       // 4) This is a retry from a client that timed out while\n       //    the prior getAdditionalBlock() is still being processed,\n       //    currently working on chooseTarget().\n       //    There are no means to distinguish between the first and\n       //    the second attempts in Part I, because the first one hasn\u0027t\n       //    changed the namesystem state yet.\n       //    We run this analysis again in Part II where case 4 is impossible.\n \n       BlockInfo penultimateBlock \u003d file.getPenultimateBlock();\n       if (previous \u003d\u003d null \u0026\u0026\n           lastBlockInFile !\u003d null \u0026\u0026\n           lastBlockInFile.getNumBytes() \u003e\u003d file.getPreferredBlockSize() \u0026\u0026\n           lastBlockInFile.isComplete()) {\n         // Case 1\n         if (NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\n                \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n                \" writing to a file with a complete previous block: src\u003d\" +\n                src + \" lastBlock\u003d\" + lastBlockInFile);\n         }\n       } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n         if (lastBlockInFile.getNumBytes() !\u003d 0) {\n           throw new IOException(\n               \"Request looked like a retry to allocate block \" +\n               lastBlockInFile + \" but it already contains \" +\n               lastBlockInFile.getNumBytes() + \" bytes\");\n         }\n \n         // Case 2\n         // Return the last block.\n         NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: caught retry for \" +\n             \"allocation of a new block in \" + src + \". Returning previously\" +\n             \" allocated block \" + lastBlockInFile);\n         long offset \u003d file.computeFileSize();\n-        BlockInfoUnderConstruction lastBlockUC \u003d\n-            (BlockInfoUnderConstruction) lastBlockInFile;\n+        BlockUnderConstructionFeature uc \u003d\n+            lastBlockInFile.getUnderConstructionFeature();\n         onRetryBlock[0] \u003d makeLocatedBlock(fsn, lastBlockInFile,\n-            lastBlockUC.getExpectedStorageLocations(), offset);\n+            uc.getExpectedStorageLocations(), offset);\n         return new FileState(file, src, iip);\n       } else {\n         // Case 3\n         throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n             \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n             \"last block in file \" + lastBlockInFile);\n       }\n     }\n     return new FileState(file, src, iip);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private static FileState analyzeFileState(\n      FSNamesystem fsn, String src, long fileId, String clientName,\n      ExtendedBlock previous, LocatedBlock[] onRetryBlock)\n      throws IOException {\n    assert fsn.hasReadLock();\n\n    checkBlock(fsn, previous);\n    onRetryBlock[0] \u003d null;\n    fsn.checkNameNodeSafeMode(\"Cannot add block to \" + src);\n\n    // have we exceeded the configured limit of fs objects.\n    fsn.checkFsObjectLimit();\n\n    Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n    final INode inode;\n    final INodesInPath iip;\n    if (fileId \u003d\u003d HdfsConstants.GRANDFATHER_INODE_ID) {\n      // Older clients may not have given us an inode ID to work with.\n      // In this case, we have to try to resolve the path and hope it\n      // hasn\u0027t changed or been deleted since the file was opened for write.\n      iip \u003d fsn.dir.getINodesInPath4Write(src);\n      inode \u003d iip.getLastINode();\n    } else {\n      // Newer clients pass the inode ID, so we can just get the inode\n      // directly.\n      inode \u003d fsn.dir.getInode(fileId);\n      iip \u003d INodesInPath.fromINode(inode);\n      if (inode !\u003d null) {\n        src \u003d iip.getPath();\n      }\n    }\n    final INodeFile file \u003d fsn.checkLease(src, clientName, inode, fileId);\n    BlockInfo lastBlockInFile \u003d file.getLastBlock();\n    if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n      // The block that the client claims is the current last block\n      // doesn\u0027t match up with what we think is the last block. There are\n      // four possibilities:\n      // 1) This is the first block allocation of an append() pipeline\n      //    which started appending exactly at or exceeding the block boundary.\n      //    In this case, the client isn\u0027t passed the previous block,\n      //    so it makes the allocateBlock() call with previous\u003dnull.\n      //    We can distinguish this since the last block of the file\n      //    will be exactly a full block.\n      // 2) This is a retry from a client that missed the response of a\n      //    prior getAdditionalBlock() call, perhaps because of a network\n      //    timeout, or because of an HA failover. In that case, we know\n      //    by the fact that the client is re-issuing the RPC that it\n      //    never began to write to the old block. Hence it is safe to\n      //    to return the existing block.\n      // 3) This is an entirely bogus request/bug -- we should error out\n      //    rather than potentially appending a new block with an empty\n      //    one in the middle, etc\n      // 4) This is a retry from a client that timed out while\n      //    the prior getAdditionalBlock() is still being processed,\n      //    currently working on chooseTarget().\n      //    There are no means to distinguish between the first and\n      //    the second attempts in Part I, because the first one hasn\u0027t\n      //    changed the namesystem state yet.\n      //    We run this analysis again in Part II where case 4 is impossible.\n\n      BlockInfo penultimateBlock \u003d file.getPenultimateBlock();\n      if (previous \u003d\u003d null \u0026\u0026\n          lastBlockInFile !\u003d null \u0026\u0026\n          lastBlockInFile.getNumBytes() \u003e\u003d file.getPreferredBlockSize() \u0026\u0026\n          lastBlockInFile.isComplete()) {\n        // Case 1\n        if (NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\n               \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n               \" writing to a file with a complete previous block: src\u003d\" +\n               src + \" lastBlock\u003d\" + lastBlockInFile);\n        }\n      } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n        if (lastBlockInFile.getNumBytes() !\u003d 0) {\n          throw new IOException(\n              \"Request looked like a retry to allocate block \" +\n              lastBlockInFile + \" but it already contains \" +\n              lastBlockInFile.getNumBytes() + \" bytes\");\n        }\n\n        // Case 2\n        // Return the last block.\n        NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: caught retry for \" +\n            \"allocation of a new block in \" + src + \". Returning previously\" +\n            \" allocated block \" + lastBlockInFile);\n        long offset \u003d file.computeFileSize();\n        BlockUnderConstructionFeature uc \u003d\n            lastBlockInFile.getUnderConstructionFeature();\n        onRetryBlock[0] \u003d makeLocatedBlock(fsn, lastBlockInFile,\n            uc.getExpectedStorageLocations(), offset);\n        return new FileState(file, src, iip);\n      } else {\n        // Case 3\n        throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n            \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n            \"last block in file \" + lastBlockInFile);\n      }\n    }\n    return new FileState(file, src, iip);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirWriteFileOp.java",
      "extendedDetails": {}
    },
    "e535e0f05b5fbd087c93238deb888cc985254b4c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8801. Convert BlockInfoUnderConstruction as a feature. Contributed by Jing Zhao.\n",
      "commitDate": "17/08/15 11:28 AM",
      "commitName": "e535e0f05b5fbd087c93238deb888cc985254b4c",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "11/08/15 10:28 AM",
      "commitNameOld": "1fc3c779a422bafdb86ad1a5b2349802dda1cb62",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 6.04,
      "commitsBetweenForRepo": 37,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,100 +1,100 @@\n   private static FileState analyzeFileState(\n       FSNamesystem fsn, String src, long fileId, String clientName,\n       ExtendedBlock previous, LocatedBlock[] onRetryBlock)\n           throws IOException  {\n     assert fsn.hasReadLock();\n \n     checkBlock(fsn, previous);\n     onRetryBlock[0] \u003d null;\n     fsn.checkNameNodeSafeMode(\"Cannot add block to \" + src);\n \n     // have we exceeded the configured limit of fs objects.\n     fsn.checkFsObjectLimit();\n \n     Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n     final INode inode;\n     final INodesInPath iip;\n     if (fileId \u003d\u003d HdfsConstants.GRANDFATHER_INODE_ID) {\n       // Older clients may not have given us an inode ID to work with.\n       // In this case, we have to try to resolve the path and hope it\n       // hasn\u0027t changed or been deleted since the file was opened for write.\n       iip \u003d fsn.dir.getINodesInPath4Write(src);\n       inode \u003d iip.getLastINode();\n     } else {\n       // Newer clients pass the inode ID, so we can just get the inode\n       // directly.\n       inode \u003d fsn.dir.getInode(fileId);\n       iip \u003d INodesInPath.fromINode(inode);\n       if (inode !\u003d null) {\n         src \u003d iip.getPath();\n       }\n     }\n     final INodeFile file \u003d fsn.checkLease(src, clientName, inode, fileId);\n     BlockInfo lastBlockInFile \u003d file.getLastBlock();\n     if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n       // The block that the client claims is the current last block\n       // doesn\u0027t match up with what we think is the last block. There are\n       // four possibilities:\n       // 1) This is the first block allocation of an append() pipeline\n       //    which started appending exactly at or exceeding the block boundary.\n       //    In this case, the client isn\u0027t passed the previous block,\n       //    so it makes the allocateBlock() call with previous\u003dnull.\n       //    We can distinguish this since the last block of the file\n       //    will be exactly a full block.\n       // 2) This is a retry from a client that missed the response of a\n       //    prior getAdditionalBlock() call, perhaps because of a network\n       //    timeout, or because of an HA failover. In that case, we know\n       //    by the fact that the client is re-issuing the RPC that it\n       //    never began to write to the old block. Hence it is safe to\n       //    to return the existing block.\n       // 3) This is an entirely bogus request/bug -- we should error out\n       //    rather than potentially appending a new block with an empty\n       //    one in the middle, etc\n       // 4) This is a retry from a client that timed out while\n       //    the prior getAdditionalBlock() is still being processed,\n       //    currently working on chooseTarget().\n       //    There are no means to distinguish between the first and\n       //    the second attempts in Part I, because the first one hasn\u0027t\n       //    changed the namesystem state yet.\n       //    We run this analysis again in Part II where case 4 is impossible.\n \n       BlockInfo penultimateBlock \u003d file.getPenultimateBlock();\n       if (previous \u003d\u003d null \u0026\u0026\n           lastBlockInFile !\u003d null \u0026\u0026\n           lastBlockInFile.getNumBytes() \u003e\u003d file.getPreferredBlockSize() \u0026\u0026\n           lastBlockInFile.isComplete()) {\n         // Case 1\n         if (NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\n                \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n                \" writing to a file with a complete previous block: src\u003d\" +\n                src + \" lastBlock\u003d\" + lastBlockInFile);\n         }\n       } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n         if (lastBlockInFile.getNumBytes() !\u003d 0) {\n           throw new IOException(\n               \"Request looked like a retry to allocate block \" +\n               lastBlockInFile + \" but it already contains \" +\n               lastBlockInFile.getNumBytes() + \" bytes\");\n         }\n \n         // Case 2\n         // Return the last block.\n         NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: caught retry for \" +\n             \"allocation of a new block in \" + src + \". Returning previously\" +\n             \" allocated block \" + lastBlockInFile);\n         long offset \u003d file.computeFileSize();\n-        BlockInfoContiguousUnderConstruction lastBlockUC \u003d\n-            (BlockInfoContiguousUnderConstruction) lastBlockInFile;\n+        BlockUnderConstructionFeature uc \u003d\n+            lastBlockInFile.getUnderConstructionFeature();\n         onRetryBlock[0] \u003d makeLocatedBlock(fsn, lastBlockInFile,\n-            lastBlockUC.getExpectedStorageLocations(), offset);\n+            uc.getExpectedStorageLocations(), offset);\n         return new FileState(file, src, iip);\n       } else {\n         // Case 3\n         throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n             \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n             \"last block in file \" + lastBlockInFile);\n       }\n     }\n     return new FileState(file, src, iip);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private static FileState analyzeFileState(\n      FSNamesystem fsn, String src, long fileId, String clientName,\n      ExtendedBlock previous, LocatedBlock[] onRetryBlock)\n          throws IOException  {\n    assert fsn.hasReadLock();\n\n    checkBlock(fsn, previous);\n    onRetryBlock[0] \u003d null;\n    fsn.checkNameNodeSafeMode(\"Cannot add block to \" + src);\n\n    // have we exceeded the configured limit of fs objects.\n    fsn.checkFsObjectLimit();\n\n    Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n    final INode inode;\n    final INodesInPath iip;\n    if (fileId \u003d\u003d HdfsConstants.GRANDFATHER_INODE_ID) {\n      // Older clients may not have given us an inode ID to work with.\n      // In this case, we have to try to resolve the path and hope it\n      // hasn\u0027t changed or been deleted since the file was opened for write.\n      iip \u003d fsn.dir.getINodesInPath4Write(src);\n      inode \u003d iip.getLastINode();\n    } else {\n      // Newer clients pass the inode ID, so we can just get the inode\n      // directly.\n      inode \u003d fsn.dir.getInode(fileId);\n      iip \u003d INodesInPath.fromINode(inode);\n      if (inode !\u003d null) {\n        src \u003d iip.getPath();\n      }\n    }\n    final INodeFile file \u003d fsn.checkLease(src, clientName, inode, fileId);\n    BlockInfo lastBlockInFile \u003d file.getLastBlock();\n    if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n      // The block that the client claims is the current last block\n      // doesn\u0027t match up with what we think is the last block. There are\n      // four possibilities:\n      // 1) This is the first block allocation of an append() pipeline\n      //    which started appending exactly at or exceeding the block boundary.\n      //    In this case, the client isn\u0027t passed the previous block,\n      //    so it makes the allocateBlock() call with previous\u003dnull.\n      //    We can distinguish this since the last block of the file\n      //    will be exactly a full block.\n      // 2) This is a retry from a client that missed the response of a\n      //    prior getAdditionalBlock() call, perhaps because of a network\n      //    timeout, or because of an HA failover. In that case, we know\n      //    by the fact that the client is re-issuing the RPC that it\n      //    never began to write to the old block. Hence it is safe to\n      //    to return the existing block.\n      // 3) This is an entirely bogus request/bug -- we should error out\n      //    rather than potentially appending a new block with an empty\n      //    one in the middle, etc\n      // 4) This is a retry from a client that timed out while\n      //    the prior getAdditionalBlock() is still being processed,\n      //    currently working on chooseTarget().\n      //    There are no means to distinguish between the first and\n      //    the second attempts in Part I, because the first one hasn\u0027t\n      //    changed the namesystem state yet.\n      //    We run this analysis again in Part II where case 4 is impossible.\n\n      BlockInfo penultimateBlock \u003d file.getPenultimateBlock();\n      if (previous \u003d\u003d null \u0026\u0026\n          lastBlockInFile !\u003d null \u0026\u0026\n          lastBlockInFile.getNumBytes() \u003e\u003d file.getPreferredBlockSize() \u0026\u0026\n          lastBlockInFile.isComplete()) {\n        // Case 1\n        if (NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\n               \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n               \" writing to a file with a complete previous block: src\u003d\" +\n               src + \" lastBlock\u003d\" + lastBlockInFile);\n        }\n      } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n        if (lastBlockInFile.getNumBytes() !\u003d 0) {\n          throw new IOException(\n              \"Request looked like a retry to allocate block \" +\n              lastBlockInFile + \" but it already contains \" +\n              lastBlockInFile.getNumBytes() + \" bytes\");\n        }\n\n        // Case 2\n        // Return the last block.\n        NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: caught retry for \" +\n            \"allocation of a new block in \" + src + \". Returning previously\" +\n            \" allocated block \" + lastBlockInFile);\n        long offset \u003d file.computeFileSize();\n        BlockUnderConstructionFeature uc \u003d\n            lastBlockInFile.getUnderConstructionFeature();\n        onRetryBlock[0] \u003d makeLocatedBlock(fsn, lastBlockInFile,\n            uc.getExpectedStorageLocations(), offset);\n        return new FileState(file, src, iip);\n      } else {\n        // Case 3\n        throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n            \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n            \"last block in file \" + lastBlockInFile);\n      }\n    }\n    return new FileState(file, src, iip);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirWriteFileOp.java",
      "extendedDetails": {}
    },
    "f4c523b69ba55b1fd35e8995c3011a9f546ac835": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-8499. Refactor BlockInfo class hierarchy with static helper class. Contributed by Zhe Zhang.\"\n\nThis reverts commit c17439c2ddd921b63b1635e6f1cba634b8da8557.\n",
      "commitDate": "06/08/15 10:21 AM",
      "commitName": "f4c523b69ba55b1fd35e8995c3011a9f546ac835",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "21/07/15 5:25 PM",
      "commitNameOld": "31f117138a00794de4951ee8433e304d72b04094",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 15.71,
      "commitsBetweenForRepo": 92,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,100 +1,100 @@\n   private static FileState analyzeFileState(\n       FSNamesystem fsn, String src, long fileId, String clientName,\n       ExtendedBlock previous, LocatedBlock[] onRetryBlock)\n           throws IOException  {\n     assert fsn.hasReadLock();\n \n     checkBlock(fsn, previous);\n     onRetryBlock[0] \u003d null;\n     fsn.checkNameNodeSafeMode(\"Cannot add block to \" + src);\n \n     // have we exceeded the configured limit of fs objects.\n     fsn.checkFsObjectLimit();\n \n     Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n     final INode inode;\n     final INodesInPath iip;\n     if (fileId \u003d\u003d HdfsConstants.GRANDFATHER_INODE_ID) {\n       // Older clients may not have given us an inode ID to work with.\n       // In this case, we have to try to resolve the path and hope it\n       // hasn\u0027t changed or been deleted since the file was opened for write.\n       iip \u003d fsn.dir.getINodesInPath4Write(src);\n       inode \u003d iip.getLastINode();\n     } else {\n       // Newer clients pass the inode ID, so we can just get the inode\n       // directly.\n       inode \u003d fsn.dir.getInode(fileId);\n       iip \u003d INodesInPath.fromINode(inode);\n       if (inode !\u003d null) {\n         src \u003d iip.getPath();\n       }\n     }\n     final INodeFile file \u003d fsn.checkLease(src, clientName, inode, fileId);\n     BlockInfo lastBlockInFile \u003d file.getLastBlock();\n     if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n       // The block that the client claims is the current last block\n       // doesn\u0027t match up with what we think is the last block. There are\n       // four possibilities:\n       // 1) This is the first block allocation of an append() pipeline\n       //    which started appending exactly at or exceeding the block boundary.\n       //    In this case, the client isn\u0027t passed the previous block,\n       //    so it makes the allocateBlock() call with previous\u003dnull.\n       //    We can distinguish this since the last block of the file\n       //    will be exactly a full block.\n       // 2) This is a retry from a client that missed the response of a\n       //    prior getAdditionalBlock() call, perhaps because of a network\n       //    timeout, or because of an HA failover. In that case, we know\n       //    by the fact that the client is re-issuing the RPC that it\n       //    never began to write to the old block. Hence it is safe to\n       //    to return the existing block.\n       // 3) This is an entirely bogus request/bug -- we should error out\n       //    rather than potentially appending a new block with an empty\n       //    one in the middle, etc\n       // 4) This is a retry from a client that timed out while\n       //    the prior getAdditionalBlock() is still being processed,\n       //    currently working on chooseTarget().\n       //    There are no means to distinguish between the first and\n       //    the second attempts in Part I, because the first one hasn\u0027t\n       //    changed the namesystem state yet.\n       //    We run this analysis again in Part II where case 4 is impossible.\n \n       BlockInfo penultimateBlock \u003d file.getPenultimateBlock();\n       if (previous \u003d\u003d null \u0026\u0026\n           lastBlockInFile !\u003d null \u0026\u0026\n           lastBlockInFile.getNumBytes() \u003e\u003d file.getPreferredBlockSize() \u0026\u0026\n           lastBlockInFile.isComplete()) {\n         // Case 1\n         if (NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\n                \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n                \" writing to a file with a complete previous block: src\u003d\" +\n                src + \" lastBlock\u003d\" + lastBlockInFile);\n         }\n       } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n         if (lastBlockInFile.getNumBytes() !\u003d 0) {\n           throw new IOException(\n               \"Request looked like a retry to allocate block \" +\n               lastBlockInFile + \" but it already contains \" +\n               lastBlockInFile.getNumBytes() + \" bytes\");\n         }\n \n         // Case 2\n         // Return the last block.\n         NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: caught retry for \" +\n             \"allocation of a new block in \" + src + \". Returning previously\" +\n             \" allocated block \" + lastBlockInFile);\n         long offset \u003d file.computeFileSize();\n-        BlockInfoUnderConstruction lastBlockUC \u003d\n-            (BlockInfoUnderConstruction) lastBlockInFile;\n+        BlockInfoContiguousUnderConstruction lastBlockUC \u003d\n+            (BlockInfoContiguousUnderConstruction) lastBlockInFile;\n         onRetryBlock[0] \u003d makeLocatedBlock(fsn, lastBlockInFile,\n             lastBlockUC.getExpectedStorageLocations(), offset);\n         return new FileState(file, src, iip);\n       } else {\n         // Case 3\n         throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n             \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n             \"last block in file \" + lastBlockInFile);\n       }\n     }\n     return new FileState(file, src, iip);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private static FileState analyzeFileState(\n      FSNamesystem fsn, String src, long fileId, String clientName,\n      ExtendedBlock previous, LocatedBlock[] onRetryBlock)\n          throws IOException  {\n    assert fsn.hasReadLock();\n\n    checkBlock(fsn, previous);\n    onRetryBlock[0] \u003d null;\n    fsn.checkNameNodeSafeMode(\"Cannot add block to \" + src);\n\n    // have we exceeded the configured limit of fs objects.\n    fsn.checkFsObjectLimit();\n\n    Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n    final INode inode;\n    final INodesInPath iip;\n    if (fileId \u003d\u003d HdfsConstants.GRANDFATHER_INODE_ID) {\n      // Older clients may not have given us an inode ID to work with.\n      // In this case, we have to try to resolve the path and hope it\n      // hasn\u0027t changed or been deleted since the file was opened for write.\n      iip \u003d fsn.dir.getINodesInPath4Write(src);\n      inode \u003d iip.getLastINode();\n    } else {\n      // Newer clients pass the inode ID, so we can just get the inode\n      // directly.\n      inode \u003d fsn.dir.getInode(fileId);\n      iip \u003d INodesInPath.fromINode(inode);\n      if (inode !\u003d null) {\n        src \u003d iip.getPath();\n      }\n    }\n    final INodeFile file \u003d fsn.checkLease(src, clientName, inode, fileId);\n    BlockInfo lastBlockInFile \u003d file.getLastBlock();\n    if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n      // The block that the client claims is the current last block\n      // doesn\u0027t match up with what we think is the last block. There are\n      // four possibilities:\n      // 1) This is the first block allocation of an append() pipeline\n      //    which started appending exactly at or exceeding the block boundary.\n      //    In this case, the client isn\u0027t passed the previous block,\n      //    so it makes the allocateBlock() call with previous\u003dnull.\n      //    We can distinguish this since the last block of the file\n      //    will be exactly a full block.\n      // 2) This is a retry from a client that missed the response of a\n      //    prior getAdditionalBlock() call, perhaps because of a network\n      //    timeout, or because of an HA failover. In that case, we know\n      //    by the fact that the client is re-issuing the RPC that it\n      //    never began to write to the old block. Hence it is safe to\n      //    to return the existing block.\n      // 3) This is an entirely bogus request/bug -- we should error out\n      //    rather than potentially appending a new block with an empty\n      //    one in the middle, etc\n      // 4) This is a retry from a client that timed out while\n      //    the prior getAdditionalBlock() is still being processed,\n      //    currently working on chooseTarget().\n      //    There are no means to distinguish between the first and\n      //    the second attempts in Part I, because the first one hasn\u0027t\n      //    changed the namesystem state yet.\n      //    We run this analysis again in Part II where case 4 is impossible.\n\n      BlockInfo penultimateBlock \u003d file.getPenultimateBlock();\n      if (previous \u003d\u003d null \u0026\u0026\n          lastBlockInFile !\u003d null \u0026\u0026\n          lastBlockInFile.getNumBytes() \u003e\u003d file.getPreferredBlockSize() \u0026\u0026\n          lastBlockInFile.isComplete()) {\n        // Case 1\n        if (NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\n               \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n               \" writing to a file with a complete previous block: src\u003d\" +\n               src + \" lastBlock\u003d\" + lastBlockInFile);\n        }\n      } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n        if (lastBlockInFile.getNumBytes() !\u003d 0) {\n          throw new IOException(\n              \"Request looked like a retry to allocate block \" +\n              lastBlockInFile + \" but it already contains \" +\n              lastBlockInFile.getNumBytes() + \" bytes\");\n        }\n\n        // Case 2\n        // Return the last block.\n        NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: caught retry for \" +\n            \"allocation of a new block in \" + src + \". Returning previously\" +\n            \" allocated block \" + lastBlockInFile);\n        long offset \u003d file.computeFileSize();\n        BlockInfoContiguousUnderConstruction lastBlockUC \u003d\n            (BlockInfoContiguousUnderConstruction) lastBlockInFile;\n        onRetryBlock[0] \u003d makeLocatedBlock(fsn, lastBlockInFile,\n            lastBlockUC.getExpectedStorageLocations(), offset);\n        return new FileState(file, src, iip);\n      } else {\n        // Case 3\n        throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n            \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n            \"last block in file \" + lastBlockInFile);\n      }\n    }\n    return new FileState(file, src, iip);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirWriteFileOp.java",
      "extendedDetails": {}
    },
    "c17439c2ddd921b63b1635e6f1cba634b8da8557": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8499. Refactor BlockInfo class hierarchy with static helper class. Contributed by Zhe Zhang.\n",
      "commitDate": "12/06/15 11:38 AM",
      "commitName": "c17439c2ddd921b63b1635e6f1cba634b8da8557",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "27/05/15 3:42 PM",
      "commitNameOld": "4928f5473394981829e5ffd4b16ea0801baf5c45",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 15.83,
      "commitsBetweenForRepo": 122,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,100 +1,100 @@\n   private static FileState analyzeFileState(\n       FSNamesystem fsn, String src, long fileId, String clientName,\n       ExtendedBlock previous, LocatedBlock[] onRetryBlock)\n           throws IOException  {\n     assert fsn.hasReadLock();\n \n     checkBlock(fsn, previous);\n     onRetryBlock[0] \u003d null;\n     fsn.checkNameNodeSafeMode(\"Cannot add block to \" + src);\n \n     // have we exceeded the configured limit of fs objects.\n     fsn.checkFsObjectLimit();\n \n     Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n     final INode inode;\n     final INodesInPath iip;\n     if (fileId \u003d\u003d HdfsConstants.GRANDFATHER_INODE_ID) {\n       // Older clients may not have given us an inode ID to work with.\n       // In this case, we have to try to resolve the path and hope it\n       // hasn\u0027t changed or been deleted since the file was opened for write.\n       iip \u003d fsn.dir.getINodesInPath4Write(src);\n       inode \u003d iip.getLastINode();\n     } else {\n       // Newer clients pass the inode ID, so we can just get the inode\n       // directly.\n       inode \u003d fsn.dir.getInode(fileId);\n       iip \u003d INodesInPath.fromINode(inode);\n       if (inode !\u003d null) {\n         src \u003d iip.getPath();\n       }\n     }\n     final INodeFile file \u003d fsn.checkLease(src, clientName, inode, fileId);\n     BlockInfo lastBlockInFile \u003d file.getLastBlock();\n     if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n       // The block that the client claims is the current last block\n       // doesn\u0027t match up with what we think is the last block. There are\n       // four possibilities:\n       // 1) This is the first block allocation of an append() pipeline\n       //    which started appending exactly at or exceeding the block boundary.\n       //    In this case, the client isn\u0027t passed the previous block,\n       //    so it makes the allocateBlock() call with previous\u003dnull.\n       //    We can distinguish this since the last block of the file\n       //    will be exactly a full block.\n       // 2) This is a retry from a client that missed the response of a\n       //    prior getAdditionalBlock() call, perhaps because of a network\n       //    timeout, or because of an HA failover. In that case, we know\n       //    by the fact that the client is re-issuing the RPC that it\n       //    never began to write to the old block. Hence it is safe to\n       //    to return the existing block.\n       // 3) This is an entirely bogus request/bug -- we should error out\n       //    rather than potentially appending a new block with an empty\n       //    one in the middle, etc\n       // 4) This is a retry from a client that timed out while\n       //    the prior getAdditionalBlock() is still being processed,\n       //    currently working on chooseTarget().\n       //    There are no means to distinguish between the first and\n       //    the second attempts in Part I, because the first one hasn\u0027t\n       //    changed the namesystem state yet.\n       //    We run this analysis again in Part II where case 4 is impossible.\n \n       BlockInfo penultimateBlock \u003d file.getPenultimateBlock();\n       if (previous \u003d\u003d null \u0026\u0026\n           lastBlockInFile !\u003d null \u0026\u0026\n           lastBlockInFile.getNumBytes() \u003e\u003d file.getPreferredBlockSize() \u0026\u0026\n           lastBlockInFile.isComplete()) {\n         // Case 1\n         if (NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\n                \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n                \" writing to a file with a complete previous block: src\u003d\" +\n                src + \" lastBlock\u003d\" + lastBlockInFile);\n         }\n       } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n         if (lastBlockInFile.getNumBytes() !\u003d 0) {\n           throw new IOException(\n               \"Request looked like a retry to allocate block \" +\n               lastBlockInFile + \" but it already contains \" +\n               lastBlockInFile.getNumBytes() + \" bytes\");\n         }\n \n         // Case 2\n         // Return the last block.\n         NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: caught retry for \" +\n             \"allocation of a new block in \" + src + \". Returning previously\" +\n             \" allocated block \" + lastBlockInFile);\n         long offset \u003d file.computeFileSize();\n-        BlockInfoContiguousUnderConstruction lastBlockUC \u003d\n-            (BlockInfoContiguousUnderConstruction) lastBlockInFile;\n+        BlockInfoUnderConstruction lastBlockUC \u003d\n+            (BlockInfoUnderConstruction) lastBlockInFile;\n         onRetryBlock[0] \u003d makeLocatedBlock(fsn, lastBlockInFile,\n             lastBlockUC.getExpectedStorageLocations(), offset);\n         return new FileState(file, src, iip);\n       } else {\n         // Case 3\n         throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n             \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n             \"last block in file \" + lastBlockInFile);\n       }\n     }\n     return new FileState(file, src, iip);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private static FileState analyzeFileState(\n      FSNamesystem fsn, String src, long fileId, String clientName,\n      ExtendedBlock previous, LocatedBlock[] onRetryBlock)\n          throws IOException  {\n    assert fsn.hasReadLock();\n\n    checkBlock(fsn, previous);\n    onRetryBlock[0] \u003d null;\n    fsn.checkNameNodeSafeMode(\"Cannot add block to \" + src);\n\n    // have we exceeded the configured limit of fs objects.\n    fsn.checkFsObjectLimit();\n\n    Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n    final INode inode;\n    final INodesInPath iip;\n    if (fileId \u003d\u003d HdfsConstants.GRANDFATHER_INODE_ID) {\n      // Older clients may not have given us an inode ID to work with.\n      // In this case, we have to try to resolve the path and hope it\n      // hasn\u0027t changed or been deleted since the file was opened for write.\n      iip \u003d fsn.dir.getINodesInPath4Write(src);\n      inode \u003d iip.getLastINode();\n    } else {\n      // Newer clients pass the inode ID, so we can just get the inode\n      // directly.\n      inode \u003d fsn.dir.getInode(fileId);\n      iip \u003d INodesInPath.fromINode(inode);\n      if (inode !\u003d null) {\n        src \u003d iip.getPath();\n      }\n    }\n    final INodeFile file \u003d fsn.checkLease(src, clientName, inode, fileId);\n    BlockInfo lastBlockInFile \u003d file.getLastBlock();\n    if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n      // The block that the client claims is the current last block\n      // doesn\u0027t match up with what we think is the last block. There are\n      // four possibilities:\n      // 1) This is the first block allocation of an append() pipeline\n      //    which started appending exactly at or exceeding the block boundary.\n      //    In this case, the client isn\u0027t passed the previous block,\n      //    so it makes the allocateBlock() call with previous\u003dnull.\n      //    We can distinguish this since the last block of the file\n      //    will be exactly a full block.\n      // 2) This is a retry from a client that missed the response of a\n      //    prior getAdditionalBlock() call, perhaps because of a network\n      //    timeout, or because of an HA failover. In that case, we know\n      //    by the fact that the client is re-issuing the RPC that it\n      //    never began to write to the old block. Hence it is safe to\n      //    to return the existing block.\n      // 3) This is an entirely bogus request/bug -- we should error out\n      //    rather than potentially appending a new block with an empty\n      //    one in the middle, etc\n      // 4) This is a retry from a client that timed out while\n      //    the prior getAdditionalBlock() is still being processed,\n      //    currently working on chooseTarget().\n      //    There are no means to distinguish between the first and\n      //    the second attempts in Part I, because the first one hasn\u0027t\n      //    changed the namesystem state yet.\n      //    We run this analysis again in Part II where case 4 is impossible.\n\n      BlockInfo penultimateBlock \u003d file.getPenultimateBlock();\n      if (previous \u003d\u003d null \u0026\u0026\n          lastBlockInFile !\u003d null \u0026\u0026\n          lastBlockInFile.getNumBytes() \u003e\u003d file.getPreferredBlockSize() \u0026\u0026\n          lastBlockInFile.isComplete()) {\n        // Case 1\n        if (NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\n               \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n               \" writing to a file with a complete previous block: src\u003d\" +\n               src + \" lastBlock\u003d\" + lastBlockInFile);\n        }\n      } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n        if (lastBlockInFile.getNumBytes() !\u003d 0) {\n          throw new IOException(\n              \"Request looked like a retry to allocate block \" +\n              lastBlockInFile + \" but it already contains \" +\n              lastBlockInFile.getNumBytes() + \" bytes\");\n        }\n\n        // Case 2\n        // Return the last block.\n        NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: caught retry for \" +\n            \"allocation of a new block in \" + src + \". Returning previously\" +\n            \" allocated block \" + lastBlockInFile);\n        long offset \u003d file.computeFileSize();\n        BlockInfoUnderConstruction lastBlockUC \u003d\n            (BlockInfoUnderConstruction) lastBlockInFile;\n        onRetryBlock[0] \u003d makeLocatedBlock(fsn, lastBlockInFile,\n            lastBlockUC.getExpectedStorageLocations(), offset);\n        return new FileState(file, src, iip);\n      } else {\n        // Case 3\n        throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n            \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n            \"last block in file \" + lastBlockInFile);\n      }\n    }\n    return new FileState(file, src, iip);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirWriteFileOp.java",
      "extendedDetails": {}
    },
    "4928f5473394981829e5ffd4b16ea0801baf5c45": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8482. Rename BlockInfoContiguous to BlockInfo. Contributed by Zhe Zhang.\n",
      "commitDate": "27/05/15 3:42 PM",
      "commitName": "4928f5473394981829e5ffd4b16ea0801baf5c45",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "21/05/15 8:08 AM",
      "commitNameOld": "2b6bcfdafa91223a4116e3e9304579f5f91dccac",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 6.32,
      "commitsBetweenForRepo": 32,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,100 +1,100 @@\n   private static FileState analyzeFileState(\n       FSNamesystem fsn, String src, long fileId, String clientName,\n       ExtendedBlock previous, LocatedBlock[] onRetryBlock)\n           throws IOException  {\n     assert fsn.hasReadLock();\n \n     checkBlock(fsn, previous);\n     onRetryBlock[0] \u003d null;\n     fsn.checkNameNodeSafeMode(\"Cannot add block to \" + src);\n \n     // have we exceeded the configured limit of fs objects.\n     fsn.checkFsObjectLimit();\n \n     Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n     final INode inode;\n     final INodesInPath iip;\n     if (fileId \u003d\u003d HdfsConstants.GRANDFATHER_INODE_ID) {\n       // Older clients may not have given us an inode ID to work with.\n       // In this case, we have to try to resolve the path and hope it\n       // hasn\u0027t changed or been deleted since the file was opened for write.\n       iip \u003d fsn.dir.getINodesInPath4Write(src);\n       inode \u003d iip.getLastINode();\n     } else {\n       // Newer clients pass the inode ID, so we can just get the inode\n       // directly.\n       inode \u003d fsn.dir.getInode(fileId);\n       iip \u003d INodesInPath.fromINode(inode);\n       if (inode !\u003d null) {\n         src \u003d iip.getPath();\n       }\n     }\n     final INodeFile file \u003d fsn.checkLease(src, clientName, inode, fileId);\n-    BlockInfoContiguous lastBlockInFile \u003d file.getLastBlock();\n+    BlockInfo lastBlockInFile \u003d file.getLastBlock();\n     if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n       // The block that the client claims is the current last block\n       // doesn\u0027t match up with what we think is the last block. There are\n       // four possibilities:\n       // 1) This is the first block allocation of an append() pipeline\n       //    which started appending exactly at or exceeding the block boundary.\n       //    In this case, the client isn\u0027t passed the previous block,\n       //    so it makes the allocateBlock() call with previous\u003dnull.\n       //    We can distinguish this since the last block of the file\n       //    will be exactly a full block.\n       // 2) This is a retry from a client that missed the response of a\n       //    prior getAdditionalBlock() call, perhaps because of a network\n       //    timeout, or because of an HA failover. In that case, we know\n       //    by the fact that the client is re-issuing the RPC that it\n       //    never began to write to the old block. Hence it is safe to\n       //    to return the existing block.\n       // 3) This is an entirely bogus request/bug -- we should error out\n       //    rather than potentially appending a new block with an empty\n       //    one in the middle, etc\n       // 4) This is a retry from a client that timed out while\n       //    the prior getAdditionalBlock() is still being processed,\n       //    currently working on chooseTarget().\n       //    There are no means to distinguish between the first and\n       //    the second attempts in Part I, because the first one hasn\u0027t\n       //    changed the namesystem state yet.\n       //    We run this analysis again in Part II where case 4 is impossible.\n \n-      BlockInfoContiguous penultimateBlock \u003d file.getPenultimateBlock();\n+      BlockInfo penultimateBlock \u003d file.getPenultimateBlock();\n       if (previous \u003d\u003d null \u0026\u0026\n           lastBlockInFile !\u003d null \u0026\u0026\n           lastBlockInFile.getNumBytes() \u003e\u003d file.getPreferredBlockSize() \u0026\u0026\n           lastBlockInFile.isComplete()) {\n         // Case 1\n         if (NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\n                \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n                \" writing to a file with a complete previous block: src\u003d\" +\n                src + \" lastBlock\u003d\" + lastBlockInFile);\n         }\n       } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n         if (lastBlockInFile.getNumBytes() !\u003d 0) {\n           throw new IOException(\n               \"Request looked like a retry to allocate block \" +\n               lastBlockInFile + \" but it already contains \" +\n               lastBlockInFile.getNumBytes() + \" bytes\");\n         }\n \n         // Case 2\n         // Return the last block.\n         NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: caught retry for \" +\n             \"allocation of a new block in \" + src + \". Returning previously\" +\n             \" allocated block \" + lastBlockInFile);\n         long offset \u003d file.computeFileSize();\n         BlockInfoContiguousUnderConstruction lastBlockUC \u003d\n             (BlockInfoContiguousUnderConstruction) lastBlockInFile;\n         onRetryBlock[0] \u003d makeLocatedBlock(fsn, lastBlockInFile,\n             lastBlockUC.getExpectedStorageLocations(), offset);\n         return new FileState(file, src, iip);\n       } else {\n         // Case 3\n         throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n             \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n             \"last block in file \" + lastBlockInFile);\n       }\n     }\n     return new FileState(file, src, iip);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private static FileState analyzeFileState(\n      FSNamesystem fsn, String src, long fileId, String clientName,\n      ExtendedBlock previous, LocatedBlock[] onRetryBlock)\n          throws IOException  {\n    assert fsn.hasReadLock();\n\n    checkBlock(fsn, previous);\n    onRetryBlock[0] \u003d null;\n    fsn.checkNameNodeSafeMode(\"Cannot add block to \" + src);\n\n    // have we exceeded the configured limit of fs objects.\n    fsn.checkFsObjectLimit();\n\n    Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n    final INode inode;\n    final INodesInPath iip;\n    if (fileId \u003d\u003d HdfsConstants.GRANDFATHER_INODE_ID) {\n      // Older clients may not have given us an inode ID to work with.\n      // In this case, we have to try to resolve the path and hope it\n      // hasn\u0027t changed or been deleted since the file was opened for write.\n      iip \u003d fsn.dir.getINodesInPath4Write(src);\n      inode \u003d iip.getLastINode();\n    } else {\n      // Newer clients pass the inode ID, so we can just get the inode\n      // directly.\n      inode \u003d fsn.dir.getInode(fileId);\n      iip \u003d INodesInPath.fromINode(inode);\n      if (inode !\u003d null) {\n        src \u003d iip.getPath();\n      }\n    }\n    final INodeFile file \u003d fsn.checkLease(src, clientName, inode, fileId);\n    BlockInfo lastBlockInFile \u003d file.getLastBlock();\n    if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n      // The block that the client claims is the current last block\n      // doesn\u0027t match up with what we think is the last block. There are\n      // four possibilities:\n      // 1) This is the first block allocation of an append() pipeline\n      //    which started appending exactly at or exceeding the block boundary.\n      //    In this case, the client isn\u0027t passed the previous block,\n      //    so it makes the allocateBlock() call with previous\u003dnull.\n      //    We can distinguish this since the last block of the file\n      //    will be exactly a full block.\n      // 2) This is a retry from a client that missed the response of a\n      //    prior getAdditionalBlock() call, perhaps because of a network\n      //    timeout, or because of an HA failover. In that case, we know\n      //    by the fact that the client is re-issuing the RPC that it\n      //    never began to write to the old block. Hence it is safe to\n      //    to return the existing block.\n      // 3) This is an entirely bogus request/bug -- we should error out\n      //    rather than potentially appending a new block with an empty\n      //    one in the middle, etc\n      // 4) This is a retry from a client that timed out while\n      //    the prior getAdditionalBlock() is still being processed,\n      //    currently working on chooseTarget().\n      //    There are no means to distinguish between the first and\n      //    the second attempts in Part I, because the first one hasn\u0027t\n      //    changed the namesystem state yet.\n      //    We run this analysis again in Part II where case 4 is impossible.\n\n      BlockInfo penultimateBlock \u003d file.getPenultimateBlock();\n      if (previous \u003d\u003d null \u0026\u0026\n          lastBlockInFile !\u003d null \u0026\u0026\n          lastBlockInFile.getNumBytes() \u003e\u003d file.getPreferredBlockSize() \u0026\u0026\n          lastBlockInFile.isComplete()) {\n        // Case 1\n        if (NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\n               \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n               \" writing to a file with a complete previous block: src\u003d\" +\n               src + \" lastBlock\u003d\" + lastBlockInFile);\n        }\n      } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n        if (lastBlockInFile.getNumBytes() !\u003d 0) {\n          throw new IOException(\n              \"Request looked like a retry to allocate block \" +\n              lastBlockInFile + \" but it already contains \" +\n              lastBlockInFile.getNumBytes() + \" bytes\");\n        }\n\n        // Case 2\n        // Return the last block.\n        NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: caught retry for \" +\n            \"allocation of a new block in \" + src + \". Returning previously\" +\n            \" allocated block \" + lastBlockInFile);\n        long offset \u003d file.computeFileSize();\n        BlockInfoContiguousUnderConstruction lastBlockUC \u003d\n            (BlockInfoContiguousUnderConstruction) lastBlockInFile;\n        onRetryBlock[0] \u003d makeLocatedBlock(fsn, lastBlockInFile,\n            lastBlockUC.getExpectedStorageLocations(), offset);\n        return new FileState(file, src, iip);\n      } else {\n        // Case 3\n        throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n            \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n            \"last block in file \" + lastBlockInFile);\n      }\n    }\n    return new FileState(file, src, iip);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirWriteFileOp.java",
      "extendedDetails": {}
    },
    "d8ea443af0b1c8289a1dd738945831ff8be0e9c1": {
      "type": "Ybodychange",
      "commitMessage": "Merge HDFS-8394 from trunk: Move getAdditionalBlock() and related functionalities into a separate class.\n",
      "commitDate": "26/05/15 12:02 PM",
      "commitName": "d8ea443af0b1c8289a1dd738945831ff8be0e9c1",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "26/05/15 11:55 AM",
      "commitNameOld": "1af8c148626effe1b41fc536019fd3349f485d59",
      "commitAuthorOld": "Zhe Zhang",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 74,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,100 +1,100 @@\n   private static FileState analyzeFileState(\n       FSNamesystem fsn, String src, long fileId, String clientName,\n       ExtendedBlock previous, LocatedBlock[] onRetryBlock)\n-          throws IOException  {\n+      throws IOException {\n     assert fsn.hasReadLock();\n \n     checkBlock(fsn, previous);\n     onRetryBlock[0] \u003d null;\n     fsn.checkNameNodeSafeMode(\"Cannot add block to \" + src);\n \n     // have we exceeded the configured limit of fs objects.\n     fsn.checkFsObjectLimit();\n \n     Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n     final INode inode;\n     final INodesInPath iip;\n     if (fileId \u003d\u003d HdfsConstants.GRANDFATHER_INODE_ID) {\n       // Older clients may not have given us an inode ID to work with.\n       // In this case, we have to try to resolve the path and hope it\n       // hasn\u0027t changed or been deleted since the file was opened for write.\n       iip \u003d fsn.dir.getINodesInPath4Write(src);\n       inode \u003d iip.getLastINode();\n     } else {\n       // Newer clients pass the inode ID, so we can just get the inode\n       // directly.\n       inode \u003d fsn.dir.getInode(fileId);\n       iip \u003d INodesInPath.fromINode(inode);\n       if (inode !\u003d null) {\n         src \u003d iip.getPath();\n       }\n     }\n     final INodeFile file \u003d fsn.checkLease(src, clientName, inode, fileId);\n     BlockInfo lastBlockInFile \u003d file.getLastBlock();\n     if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n       // The block that the client claims is the current last block\n       // doesn\u0027t match up with what we think is the last block. There are\n       // four possibilities:\n       // 1) This is the first block allocation of an append() pipeline\n       //    which started appending exactly at or exceeding the block boundary.\n       //    In this case, the client isn\u0027t passed the previous block,\n       //    so it makes the allocateBlock() call with previous\u003dnull.\n       //    We can distinguish this since the last block of the file\n       //    will be exactly a full block.\n       // 2) This is a retry from a client that missed the response of a\n       //    prior getAdditionalBlock() call, perhaps because of a network\n       //    timeout, or because of an HA failover. In that case, we know\n       //    by the fact that the client is re-issuing the RPC that it\n       //    never began to write to the old block. Hence it is safe to\n       //    to return the existing block.\n       // 3) This is an entirely bogus request/bug -- we should error out\n       //    rather than potentially appending a new block with an empty\n       //    one in the middle, etc\n       // 4) This is a retry from a client that timed out while\n       //    the prior getAdditionalBlock() is still being processed,\n       //    currently working on chooseTarget().\n       //    There are no means to distinguish between the first and\n       //    the second attempts in Part I, because the first one hasn\u0027t\n       //    changed the namesystem state yet.\n       //    We run this analysis again in Part II where case 4 is impossible.\n \n       BlockInfo penultimateBlock \u003d file.getPenultimateBlock();\n       if (previous \u003d\u003d null \u0026\u0026\n           lastBlockInFile !\u003d null \u0026\u0026\n           lastBlockInFile.getNumBytes() \u003e\u003d file.getPreferredBlockSize() \u0026\u0026\n           lastBlockInFile.isComplete()) {\n         // Case 1\n         if (NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\n                \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n                \" writing to a file with a complete previous block: src\u003d\" +\n                src + \" lastBlock\u003d\" + lastBlockInFile);\n         }\n       } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n         if (lastBlockInFile.getNumBytes() !\u003d 0) {\n           throw new IOException(\n               \"Request looked like a retry to allocate block \" +\n               lastBlockInFile + \" but it already contains \" +\n               lastBlockInFile.getNumBytes() + \" bytes\");\n         }\n \n         // Case 2\n         // Return the last block.\n         NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: caught retry for \" +\n             \"allocation of a new block in \" + src + \". Returning previously\" +\n             \" allocated block \" + lastBlockInFile);\n         long offset \u003d file.computeFileSize();\n-        BlockInfoContiguousUnderConstruction lastBlockUC \u003d\n-            (BlockInfoContiguousUnderConstruction) lastBlockInFile;\n+        BlockInfoUnderConstruction lastBlockUC \u003d\n+            (BlockInfoUnderConstruction) lastBlockInFile;\n         onRetryBlock[0] \u003d makeLocatedBlock(fsn, lastBlockInFile,\n             lastBlockUC.getExpectedStorageLocations(), offset);\n         return new FileState(file, src, iip);\n       } else {\n         // Case 3\n         throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n             \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n             \"last block in file \" + lastBlockInFile);\n       }\n     }\n     return new FileState(file, src, iip);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private static FileState analyzeFileState(\n      FSNamesystem fsn, String src, long fileId, String clientName,\n      ExtendedBlock previous, LocatedBlock[] onRetryBlock)\n      throws IOException {\n    assert fsn.hasReadLock();\n\n    checkBlock(fsn, previous);\n    onRetryBlock[0] \u003d null;\n    fsn.checkNameNodeSafeMode(\"Cannot add block to \" + src);\n\n    // have we exceeded the configured limit of fs objects.\n    fsn.checkFsObjectLimit();\n\n    Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n    final INode inode;\n    final INodesInPath iip;\n    if (fileId \u003d\u003d HdfsConstants.GRANDFATHER_INODE_ID) {\n      // Older clients may not have given us an inode ID to work with.\n      // In this case, we have to try to resolve the path and hope it\n      // hasn\u0027t changed or been deleted since the file was opened for write.\n      iip \u003d fsn.dir.getINodesInPath4Write(src);\n      inode \u003d iip.getLastINode();\n    } else {\n      // Newer clients pass the inode ID, so we can just get the inode\n      // directly.\n      inode \u003d fsn.dir.getInode(fileId);\n      iip \u003d INodesInPath.fromINode(inode);\n      if (inode !\u003d null) {\n        src \u003d iip.getPath();\n      }\n    }\n    final INodeFile file \u003d fsn.checkLease(src, clientName, inode, fileId);\n    BlockInfo lastBlockInFile \u003d file.getLastBlock();\n    if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n      // The block that the client claims is the current last block\n      // doesn\u0027t match up with what we think is the last block. There are\n      // four possibilities:\n      // 1) This is the first block allocation of an append() pipeline\n      //    which started appending exactly at or exceeding the block boundary.\n      //    In this case, the client isn\u0027t passed the previous block,\n      //    so it makes the allocateBlock() call with previous\u003dnull.\n      //    We can distinguish this since the last block of the file\n      //    will be exactly a full block.\n      // 2) This is a retry from a client that missed the response of a\n      //    prior getAdditionalBlock() call, perhaps because of a network\n      //    timeout, or because of an HA failover. In that case, we know\n      //    by the fact that the client is re-issuing the RPC that it\n      //    never began to write to the old block. Hence it is safe to\n      //    to return the existing block.\n      // 3) This is an entirely bogus request/bug -- we should error out\n      //    rather than potentially appending a new block with an empty\n      //    one in the middle, etc\n      // 4) This is a retry from a client that timed out while\n      //    the prior getAdditionalBlock() is still being processed,\n      //    currently working on chooseTarget().\n      //    There are no means to distinguish between the first and\n      //    the second attempts in Part I, because the first one hasn\u0027t\n      //    changed the namesystem state yet.\n      //    We run this analysis again in Part II where case 4 is impossible.\n\n      BlockInfo penultimateBlock \u003d file.getPenultimateBlock();\n      if (previous \u003d\u003d null \u0026\u0026\n          lastBlockInFile !\u003d null \u0026\u0026\n          lastBlockInFile.getNumBytes() \u003e\u003d file.getPreferredBlockSize() \u0026\u0026\n          lastBlockInFile.isComplete()) {\n        // Case 1\n        if (NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\n               \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n               \" writing to a file with a complete previous block: src\u003d\" +\n               src + \" lastBlock\u003d\" + lastBlockInFile);\n        }\n      } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n        if (lastBlockInFile.getNumBytes() !\u003d 0) {\n          throw new IOException(\n              \"Request looked like a retry to allocate block \" +\n              lastBlockInFile + \" but it already contains \" +\n              lastBlockInFile.getNumBytes() + \" bytes\");\n        }\n\n        // Case 2\n        // Return the last block.\n        NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: caught retry for \" +\n            \"allocation of a new block in \" + src + \". Returning previously\" +\n            \" allocated block \" + lastBlockInFile);\n        long offset \u003d file.computeFileSize();\n        BlockInfoUnderConstruction lastBlockUC \u003d\n            (BlockInfoUnderConstruction) lastBlockInFile;\n        onRetryBlock[0] \u003d makeLocatedBlock(fsn, lastBlockInFile,\n            lastBlockUC.getExpectedStorageLocations(), offset);\n        return new FileState(file, src, iip);\n      } else {\n        // Case 3\n        throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n            \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n            \"last block in file \" + lastBlockInFile);\n      }\n    }\n    return new FileState(file, src, iip);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirWriteFileOp.java",
      "extendedDetails": {}
    },
    "1af8c148626effe1b41fc536019fd3349f485d59": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7839. Erasure coding: implement facilities in NameNode to create and manage EC zones. Contributed by Zhe Zhang\n",
      "commitDate": "26/05/15 11:55 AM",
      "commitName": "1af8c148626effe1b41fc536019fd3349f485d59",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "26/05/15 11:32 AM",
      "commitNameOld": "1e1e93040748231dc913190aec1e031c379d8271",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 0.02,
      "commitsBetweenForRepo": 28,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,100 +1,100 @@\n   private static FileState analyzeFileState(\n       FSNamesystem fsn, String src, long fileId, String clientName,\n       ExtendedBlock previous, LocatedBlock[] onRetryBlock)\n           throws IOException  {\n     assert fsn.hasReadLock();\n \n     checkBlock(fsn, previous);\n     onRetryBlock[0] \u003d null;\n     fsn.checkNameNodeSafeMode(\"Cannot add block to \" + src);\n \n     // have we exceeded the configured limit of fs objects.\n     fsn.checkFsObjectLimit();\n \n     Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n     final INode inode;\n     final INodesInPath iip;\n     if (fileId \u003d\u003d HdfsConstants.GRANDFATHER_INODE_ID) {\n       // Older clients may not have given us an inode ID to work with.\n       // In this case, we have to try to resolve the path and hope it\n       // hasn\u0027t changed or been deleted since the file was opened for write.\n       iip \u003d fsn.dir.getINodesInPath4Write(src);\n       inode \u003d iip.getLastINode();\n     } else {\n       // Newer clients pass the inode ID, so we can just get the inode\n       // directly.\n       inode \u003d fsn.dir.getInode(fileId);\n       iip \u003d INodesInPath.fromINode(inode);\n       if (inode !\u003d null) {\n         src \u003d iip.getPath();\n       }\n     }\n     final INodeFile file \u003d fsn.checkLease(src, clientName, inode, fileId);\n-    BlockInfoContiguous lastBlockInFile \u003d file.getLastBlock();\n+    BlockInfo lastBlockInFile \u003d file.getLastBlock();\n     if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n       // The block that the client claims is the current last block\n       // doesn\u0027t match up with what we think is the last block. There are\n       // four possibilities:\n       // 1) This is the first block allocation of an append() pipeline\n       //    which started appending exactly at or exceeding the block boundary.\n       //    In this case, the client isn\u0027t passed the previous block,\n       //    so it makes the allocateBlock() call with previous\u003dnull.\n       //    We can distinguish this since the last block of the file\n       //    will be exactly a full block.\n       // 2) This is a retry from a client that missed the response of a\n       //    prior getAdditionalBlock() call, perhaps because of a network\n       //    timeout, or because of an HA failover. In that case, we know\n       //    by the fact that the client is re-issuing the RPC that it\n       //    never began to write to the old block. Hence it is safe to\n       //    to return the existing block.\n       // 3) This is an entirely bogus request/bug -- we should error out\n       //    rather than potentially appending a new block with an empty\n       //    one in the middle, etc\n       // 4) This is a retry from a client that timed out while\n       //    the prior getAdditionalBlock() is still being processed,\n       //    currently working on chooseTarget().\n       //    There are no means to distinguish between the first and\n       //    the second attempts in Part I, because the first one hasn\u0027t\n       //    changed the namesystem state yet.\n       //    We run this analysis again in Part II where case 4 is impossible.\n \n-      BlockInfoContiguous penultimateBlock \u003d file.getPenultimateBlock();\n+      BlockInfo penultimateBlock \u003d file.getPenultimateBlock();\n       if (previous \u003d\u003d null \u0026\u0026\n           lastBlockInFile !\u003d null \u0026\u0026\n           lastBlockInFile.getNumBytes() \u003e\u003d file.getPreferredBlockSize() \u0026\u0026\n           lastBlockInFile.isComplete()) {\n         // Case 1\n         if (NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\n                \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n                \" writing to a file with a complete previous block: src\u003d\" +\n                src + \" lastBlock\u003d\" + lastBlockInFile);\n         }\n       } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n         if (lastBlockInFile.getNumBytes() !\u003d 0) {\n           throw new IOException(\n               \"Request looked like a retry to allocate block \" +\n               lastBlockInFile + \" but it already contains \" +\n               lastBlockInFile.getNumBytes() + \" bytes\");\n         }\n \n         // Case 2\n         // Return the last block.\n         NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: caught retry for \" +\n             \"allocation of a new block in \" + src + \". Returning previously\" +\n             \" allocated block \" + lastBlockInFile);\n         long offset \u003d file.computeFileSize();\n         BlockInfoContiguousUnderConstruction lastBlockUC \u003d\n             (BlockInfoContiguousUnderConstruction) lastBlockInFile;\n         onRetryBlock[0] \u003d makeLocatedBlock(fsn, lastBlockInFile,\n             lastBlockUC.getExpectedStorageLocations(), offset);\n         return new FileState(file, src, iip);\n       } else {\n         // Case 3\n         throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n             \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n             \"last block in file \" + lastBlockInFile);\n       }\n     }\n     return new FileState(file, src, iip);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private static FileState analyzeFileState(\n      FSNamesystem fsn, String src, long fileId, String clientName,\n      ExtendedBlock previous, LocatedBlock[] onRetryBlock)\n          throws IOException  {\n    assert fsn.hasReadLock();\n\n    checkBlock(fsn, previous);\n    onRetryBlock[0] \u003d null;\n    fsn.checkNameNodeSafeMode(\"Cannot add block to \" + src);\n\n    // have we exceeded the configured limit of fs objects.\n    fsn.checkFsObjectLimit();\n\n    Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n    final INode inode;\n    final INodesInPath iip;\n    if (fileId \u003d\u003d HdfsConstants.GRANDFATHER_INODE_ID) {\n      // Older clients may not have given us an inode ID to work with.\n      // In this case, we have to try to resolve the path and hope it\n      // hasn\u0027t changed or been deleted since the file was opened for write.\n      iip \u003d fsn.dir.getINodesInPath4Write(src);\n      inode \u003d iip.getLastINode();\n    } else {\n      // Newer clients pass the inode ID, so we can just get the inode\n      // directly.\n      inode \u003d fsn.dir.getInode(fileId);\n      iip \u003d INodesInPath.fromINode(inode);\n      if (inode !\u003d null) {\n        src \u003d iip.getPath();\n      }\n    }\n    final INodeFile file \u003d fsn.checkLease(src, clientName, inode, fileId);\n    BlockInfo lastBlockInFile \u003d file.getLastBlock();\n    if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n      // The block that the client claims is the current last block\n      // doesn\u0027t match up with what we think is the last block. There are\n      // four possibilities:\n      // 1) This is the first block allocation of an append() pipeline\n      //    which started appending exactly at or exceeding the block boundary.\n      //    In this case, the client isn\u0027t passed the previous block,\n      //    so it makes the allocateBlock() call with previous\u003dnull.\n      //    We can distinguish this since the last block of the file\n      //    will be exactly a full block.\n      // 2) This is a retry from a client that missed the response of a\n      //    prior getAdditionalBlock() call, perhaps because of a network\n      //    timeout, or because of an HA failover. In that case, we know\n      //    by the fact that the client is re-issuing the RPC that it\n      //    never began to write to the old block. Hence it is safe to\n      //    to return the existing block.\n      // 3) This is an entirely bogus request/bug -- we should error out\n      //    rather than potentially appending a new block with an empty\n      //    one in the middle, etc\n      // 4) This is a retry from a client that timed out while\n      //    the prior getAdditionalBlock() is still being processed,\n      //    currently working on chooseTarget().\n      //    There are no means to distinguish between the first and\n      //    the second attempts in Part I, because the first one hasn\u0027t\n      //    changed the namesystem state yet.\n      //    We run this analysis again in Part II where case 4 is impossible.\n\n      BlockInfo penultimateBlock \u003d file.getPenultimateBlock();\n      if (previous \u003d\u003d null \u0026\u0026\n          lastBlockInFile !\u003d null \u0026\u0026\n          lastBlockInFile.getNumBytes() \u003e\u003d file.getPreferredBlockSize() \u0026\u0026\n          lastBlockInFile.isComplete()) {\n        // Case 1\n        if (NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\n               \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n               \" writing to a file with a complete previous block: src\u003d\" +\n               src + \" lastBlock\u003d\" + lastBlockInFile);\n        }\n      } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n        if (lastBlockInFile.getNumBytes() !\u003d 0) {\n          throw new IOException(\n              \"Request looked like a retry to allocate block \" +\n              lastBlockInFile + \" but it already contains \" +\n              lastBlockInFile.getNumBytes() + \" bytes\");\n        }\n\n        // Case 2\n        // Return the last block.\n        NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: caught retry for \" +\n            \"allocation of a new block in \" + src + \". Returning previously\" +\n            \" allocated block \" + lastBlockInFile);\n        long offset \u003d file.computeFileSize();\n        BlockInfoContiguousUnderConstruction lastBlockUC \u003d\n            (BlockInfoContiguousUnderConstruction) lastBlockInFile;\n        onRetryBlock[0] \u003d makeLocatedBlock(fsn, lastBlockInFile,\n            lastBlockUC.getExpectedStorageLocations(), offset);\n        return new FileState(file, src, iip);\n      } else {\n        // Case 3\n        throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n            \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n            \"last block in file \" + lastBlockInFile);\n      }\n    }\n    return new FileState(file, src, iip);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirWriteFileOp.java",
      "extendedDetails": {}
    },
    "e5afac5896a1a88e152746598527d91f73cbb724": {
      "type": "Ymultichange(Ymovefromfile,Ymodifierchange,Ybodychange,Yparameterchange)",
      "commitMessage": "HDFS-8394. Move getAdditionalBlock() and related functionalities into a separate class. Contributed by Haohui Mai.\n",
      "commitDate": "15/05/15 7:09 PM",
      "commitName": "e5afac5896a1a88e152746598527d91f73cbb724",
      "commitAuthor": "Haohui Mai",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-8394. Move getAdditionalBlock() and related functionalities into a separate class. Contributed by Haohui Mai.\n",
          "commitDate": "15/05/15 7:09 PM",
          "commitName": "e5afac5896a1a88e152746598527d91f73cbb724",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "15/05/15 4:14 PM",
          "commitNameOld": "8f378733423a5244461df79a92c00239514b8b93",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 0.12,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,101 +1,101 @@\n-  FileState analyzeFileState(String src,\n-                                long fileId,\n-                                String clientName,\n-                                ExtendedBlock previous,\n-                                LocatedBlock[] onRetryBlock)\n+  private static FileState analyzeFileState(\n+      FSNamesystem fsn, String src, long fileId, String clientName,\n+      ExtendedBlock previous, LocatedBlock[] onRetryBlock)\n           throws IOException  {\n-    assert hasReadLock();\n+    assert fsn.hasReadLock();\n \n-    checkBlock(previous);\n+    checkBlock(fsn, previous);\n     onRetryBlock[0] \u003d null;\n-    checkNameNodeSafeMode(\"Cannot add block to \" + src);\n+    fsn.checkNameNodeSafeMode(\"Cannot add block to \" + src);\n \n     // have we exceeded the configured limit of fs objects.\n-    checkFsObjectLimit();\n+    fsn.checkFsObjectLimit();\n \n     Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n     final INode inode;\n     final INodesInPath iip;\n     if (fileId \u003d\u003d HdfsConstants.GRANDFATHER_INODE_ID) {\n       // Older clients may not have given us an inode ID to work with.\n       // In this case, we have to try to resolve the path and hope it\n       // hasn\u0027t changed or been deleted since the file was opened for write.\n-      iip \u003d dir.getINodesInPath4Write(src);\n+      iip \u003d fsn.dir.getINodesInPath4Write(src);\n       inode \u003d iip.getLastINode();\n     } else {\n       // Newer clients pass the inode ID, so we can just get the inode\n       // directly.\n-      inode \u003d dir.getInode(fileId);\n+      inode \u003d fsn.dir.getInode(fileId);\n       iip \u003d INodesInPath.fromINode(inode);\n       if (inode !\u003d null) {\n         src \u003d iip.getPath();\n       }\n     }\n-    final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n-    BlockInfoContiguous lastBlockInFile \u003d pendingFile.getLastBlock();\n+    final INodeFile file \u003d fsn.checkLease(src, clientName,\n+                                                 inode, fileId);\n+    BlockInfoContiguous lastBlockInFile \u003d file.getLastBlock();\n     if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n       // The block that the client claims is the current last block\n       // doesn\u0027t match up with what we think is the last block. There are\n       // four possibilities:\n       // 1) This is the first block allocation of an append() pipeline\n       //    which started appending exactly at or exceeding the block boundary.\n       //    In this case, the client isn\u0027t passed the previous block,\n       //    so it makes the allocateBlock() call with previous\u003dnull.\n       //    We can distinguish this since the last block of the file\n       //    will be exactly a full block.\n       // 2) This is a retry from a client that missed the response of a\n       //    prior getAdditionalBlock() call, perhaps because of a network\n       //    timeout, or because of an HA failover. In that case, we know\n       //    by the fact that the client is re-issuing the RPC that it\n       //    never began to write to the old block. Hence it is safe to\n       //    to return the existing block.\n       // 3) This is an entirely bogus request/bug -- we should error out\n       //    rather than potentially appending a new block with an empty\n       //    one in the middle, etc\n       // 4) This is a retry from a client that timed out while\n       //    the prior getAdditionalBlock() is still being processed,\n-      //    currently working on chooseTarget(). \n-      //    There are no means to distinguish between the first and \n+      //    currently working on chooseTarget().\n+      //    There are no means to distinguish between the first and\n       //    the second attempts in Part I, because the first one hasn\u0027t\n       //    changed the namesystem state yet.\n       //    We run this analysis again in Part II where case 4 is impossible.\n \n-      BlockInfoContiguous penultimateBlock \u003d pendingFile.getPenultimateBlock();\n+      BlockInfoContiguous penultimateBlock \u003d file.getPenultimateBlock();\n       if (previous \u003d\u003d null \u0026\u0026\n           lastBlockInFile !\u003d null \u0026\u0026\n-          lastBlockInFile.getNumBytes() \u003e\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n+          lastBlockInFile.getNumBytes() \u003e\u003d file.getPreferredBlockSize() \u0026\u0026\n           lastBlockInFile.isComplete()) {\n         // Case 1\n         if (NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\n                \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n                \" writing to a file with a complete previous block: src\u003d\" +\n                src + \" lastBlock\u003d\" + lastBlockInFile);\n         }\n       } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n         if (lastBlockInFile.getNumBytes() !\u003d 0) {\n           throw new IOException(\n               \"Request looked like a retry to allocate block \" +\n               lastBlockInFile + \" but it already contains \" +\n               lastBlockInFile.getNumBytes() + \" bytes\");\n         }\n \n         // Case 2\n         // Return the last block.\n-        NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: \" +\n-            \"caught retry for allocation of a new block in \" +\n-            src + \". Returning previously allocated block \" + lastBlockInFile);\n-        long offset \u003d pendingFile.computeFileSize();\n-        onRetryBlock[0] \u003d makeLocatedBlock(lastBlockInFile,\n-            ((BlockInfoContiguousUnderConstruction)lastBlockInFile).getExpectedStorageLocations(),\n-            offset);\n-        return new FileState(pendingFile, src, iip);\n+        NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: caught retry for \" +\n+            \"allocation of a new block in \" + src + \". Returning previously\" +\n+            \" allocated block \" + lastBlockInFile);\n+        long offset \u003d file.computeFileSize();\n+        BlockInfoContiguousUnderConstruction lastBlockUC \u003d\n+            (BlockInfoContiguousUnderConstruction) lastBlockInFile;\n+        onRetryBlock[0] \u003d makeLocatedBlock(fsn, lastBlockInFile,\n+            lastBlockUC.getExpectedStorageLocations(), offset);\n+        return new FileState(file, src, iip);\n       } else {\n         // Case 3\n         throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n             \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n             \"last block in file \" + lastBlockInFile);\n       }\n     }\n-    return new FileState(pendingFile, src, iip);\n+    return new FileState(file, src, iip);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private static FileState analyzeFileState(\n      FSNamesystem fsn, String src, long fileId, String clientName,\n      ExtendedBlock previous, LocatedBlock[] onRetryBlock)\n          throws IOException  {\n    assert fsn.hasReadLock();\n\n    checkBlock(fsn, previous);\n    onRetryBlock[0] \u003d null;\n    fsn.checkNameNodeSafeMode(\"Cannot add block to \" + src);\n\n    // have we exceeded the configured limit of fs objects.\n    fsn.checkFsObjectLimit();\n\n    Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n    final INode inode;\n    final INodesInPath iip;\n    if (fileId \u003d\u003d HdfsConstants.GRANDFATHER_INODE_ID) {\n      // Older clients may not have given us an inode ID to work with.\n      // In this case, we have to try to resolve the path and hope it\n      // hasn\u0027t changed or been deleted since the file was opened for write.\n      iip \u003d fsn.dir.getINodesInPath4Write(src);\n      inode \u003d iip.getLastINode();\n    } else {\n      // Newer clients pass the inode ID, so we can just get the inode\n      // directly.\n      inode \u003d fsn.dir.getInode(fileId);\n      iip \u003d INodesInPath.fromINode(inode);\n      if (inode !\u003d null) {\n        src \u003d iip.getPath();\n      }\n    }\n    final INodeFile file \u003d fsn.checkLease(src, clientName,\n                                                 inode, fileId);\n    BlockInfoContiguous lastBlockInFile \u003d file.getLastBlock();\n    if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n      // The block that the client claims is the current last block\n      // doesn\u0027t match up with what we think is the last block. There are\n      // four possibilities:\n      // 1) This is the first block allocation of an append() pipeline\n      //    which started appending exactly at or exceeding the block boundary.\n      //    In this case, the client isn\u0027t passed the previous block,\n      //    so it makes the allocateBlock() call with previous\u003dnull.\n      //    We can distinguish this since the last block of the file\n      //    will be exactly a full block.\n      // 2) This is a retry from a client that missed the response of a\n      //    prior getAdditionalBlock() call, perhaps because of a network\n      //    timeout, or because of an HA failover. In that case, we know\n      //    by the fact that the client is re-issuing the RPC that it\n      //    never began to write to the old block. Hence it is safe to\n      //    to return the existing block.\n      // 3) This is an entirely bogus request/bug -- we should error out\n      //    rather than potentially appending a new block with an empty\n      //    one in the middle, etc\n      // 4) This is a retry from a client that timed out while\n      //    the prior getAdditionalBlock() is still being processed,\n      //    currently working on chooseTarget().\n      //    There are no means to distinguish between the first and\n      //    the second attempts in Part I, because the first one hasn\u0027t\n      //    changed the namesystem state yet.\n      //    We run this analysis again in Part II where case 4 is impossible.\n\n      BlockInfoContiguous penultimateBlock \u003d file.getPenultimateBlock();\n      if (previous \u003d\u003d null \u0026\u0026\n          lastBlockInFile !\u003d null \u0026\u0026\n          lastBlockInFile.getNumBytes() \u003e\u003d file.getPreferredBlockSize() \u0026\u0026\n          lastBlockInFile.isComplete()) {\n        // Case 1\n        if (NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\n               \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n               \" writing to a file with a complete previous block: src\u003d\" +\n               src + \" lastBlock\u003d\" + lastBlockInFile);\n        }\n      } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n        if (lastBlockInFile.getNumBytes() !\u003d 0) {\n          throw new IOException(\n              \"Request looked like a retry to allocate block \" +\n              lastBlockInFile + \" but it already contains \" +\n              lastBlockInFile.getNumBytes() + \" bytes\");\n        }\n\n        // Case 2\n        // Return the last block.\n        NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: caught retry for \" +\n            \"allocation of a new block in \" + src + \". Returning previously\" +\n            \" allocated block \" + lastBlockInFile);\n        long offset \u003d file.computeFileSize();\n        BlockInfoContiguousUnderConstruction lastBlockUC \u003d\n            (BlockInfoContiguousUnderConstruction) lastBlockInFile;\n        onRetryBlock[0] \u003d makeLocatedBlock(fsn, lastBlockInFile,\n            lastBlockUC.getExpectedStorageLocations(), offset);\n        return new FileState(file, src, iip);\n      } else {\n        // Case 3\n        throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n            \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n            \"last block in file \" + lastBlockInFile);\n      }\n    }\n    return new FileState(file, src, iip);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirWriteFileOp.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirWriteFileOp.java",
            "oldMethodName": "analyzeFileState",
            "newMethodName": "analyzeFileState"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-8394. Move getAdditionalBlock() and related functionalities into a separate class. Contributed by Haohui Mai.\n",
          "commitDate": "15/05/15 7:09 PM",
          "commitName": "e5afac5896a1a88e152746598527d91f73cbb724",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "15/05/15 4:14 PM",
          "commitNameOld": "8f378733423a5244461df79a92c00239514b8b93",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 0.12,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,101 +1,101 @@\n-  FileState analyzeFileState(String src,\n-                                long fileId,\n-                                String clientName,\n-                                ExtendedBlock previous,\n-                                LocatedBlock[] onRetryBlock)\n+  private static FileState analyzeFileState(\n+      FSNamesystem fsn, String src, long fileId, String clientName,\n+      ExtendedBlock previous, LocatedBlock[] onRetryBlock)\n           throws IOException  {\n-    assert hasReadLock();\n+    assert fsn.hasReadLock();\n \n-    checkBlock(previous);\n+    checkBlock(fsn, previous);\n     onRetryBlock[0] \u003d null;\n-    checkNameNodeSafeMode(\"Cannot add block to \" + src);\n+    fsn.checkNameNodeSafeMode(\"Cannot add block to \" + src);\n \n     // have we exceeded the configured limit of fs objects.\n-    checkFsObjectLimit();\n+    fsn.checkFsObjectLimit();\n \n     Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n     final INode inode;\n     final INodesInPath iip;\n     if (fileId \u003d\u003d HdfsConstants.GRANDFATHER_INODE_ID) {\n       // Older clients may not have given us an inode ID to work with.\n       // In this case, we have to try to resolve the path and hope it\n       // hasn\u0027t changed or been deleted since the file was opened for write.\n-      iip \u003d dir.getINodesInPath4Write(src);\n+      iip \u003d fsn.dir.getINodesInPath4Write(src);\n       inode \u003d iip.getLastINode();\n     } else {\n       // Newer clients pass the inode ID, so we can just get the inode\n       // directly.\n-      inode \u003d dir.getInode(fileId);\n+      inode \u003d fsn.dir.getInode(fileId);\n       iip \u003d INodesInPath.fromINode(inode);\n       if (inode !\u003d null) {\n         src \u003d iip.getPath();\n       }\n     }\n-    final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n-    BlockInfoContiguous lastBlockInFile \u003d pendingFile.getLastBlock();\n+    final INodeFile file \u003d fsn.checkLease(src, clientName,\n+                                                 inode, fileId);\n+    BlockInfoContiguous lastBlockInFile \u003d file.getLastBlock();\n     if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n       // The block that the client claims is the current last block\n       // doesn\u0027t match up with what we think is the last block. There are\n       // four possibilities:\n       // 1) This is the first block allocation of an append() pipeline\n       //    which started appending exactly at or exceeding the block boundary.\n       //    In this case, the client isn\u0027t passed the previous block,\n       //    so it makes the allocateBlock() call with previous\u003dnull.\n       //    We can distinguish this since the last block of the file\n       //    will be exactly a full block.\n       // 2) This is a retry from a client that missed the response of a\n       //    prior getAdditionalBlock() call, perhaps because of a network\n       //    timeout, or because of an HA failover. In that case, we know\n       //    by the fact that the client is re-issuing the RPC that it\n       //    never began to write to the old block. Hence it is safe to\n       //    to return the existing block.\n       // 3) This is an entirely bogus request/bug -- we should error out\n       //    rather than potentially appending a new block with an empty\n       //    one in the middle, etc\n       // 4) This is a retry from a client that timed out while\n       //    the prior getAdditionalBlock() is still being processed,\n-      //    currently working on chooseTarget(). \n-      //    There are no means to distinguish between the first and \n+      //    currently working on chooseTarget().\n+      //    There are no means to distinguish between the first and\n       //    the second attempts in Part I, because the first one hasn\u0027t\n       //    changed the namesystem state yet.\n       //    We run this analysis again in Part II where case 4 is impossible.\n \n-      BlockInfoContiguous penultimateBlock \u003d pendingFile.getPenultimateBlock();\n+      BlockInfoContiguous penultimateBlock \u003d file.getPenultimateBlock();\n       if (previous \u003d\u003d null \u0026\u0026\n           lastBlockInFile !\u003d null \u0026\u0026\n-          lastBlockInFile.getNumBytes() \u003e\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n+          lastBlockInFile.getNumBytes() \u003e\u003d file.getPreferredBlockSize() \u0026\u0026\n           lastBlockInFile.isComplete()) {\n         // Case 1\n         if (NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\n                \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n                \" writing to a file with a complete previous block: src\u003d\" +\n                src + \" lastBlock\u003d\" + lastBlockInFile);\n         }\n       } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n         if (lastBlockInFile.getNumBytes() !\u003d 0) {\n           throw new IOException(\n               \"Request looked like a retry to allocate block \" +\n               lastBlockInFile + \" but it already contains \" +\n               lastBlockInFile.getNumBytes() + \" bytes\");\n         }\n \n         // Case 2\n         // Return the last block.\n-        NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: \" +\n-            \"caught retry for allocation of a new block in \" +\n-            src + \". Returning previously allocated block \" + lastBlockInFile);\n-        long offset \u003d pendingFile.computeFileSize();\n-        onRetryBlock[0] \u003d makeLocatedBlock(lastBlockInFile,\n-            ((BlockInfoContiguousUnderConstruction)lastBlockInFile).getExpectedStorageLocations(),\n-            offset);\n-        return new FileState(pendingFile, src, iip);\n+        NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: caught retry for \" +\n+            \"allocation of a new block in \" + src + \". Returning previously\" +\n+            \" allocated block \" + lastBlockInFile);\n+        long offset \u003d file.computeFileSize();\n+        BlockInfoContiguousUnderConstruction lastBlockUC \u003d\n+            (BlockInfoContiguousUnderConstruction) lastBlockInFile;\n+        onRetryBlock[0] \u003d makeLocatedBlock(fsn, lastBlockInFile,\n+            lastBlockUC.getExpectedStorageLocations(), offset);\n+        return new FileState(file, src, iip);\n       } else {\n         // Case 3\n         throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n             \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n             \"last block in file \" + lastBlockInFile);\n       }\n     }\n-    return new FileState(pendingFile, src, iip);\n+    return new FileState(file, src, iip);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private static FileState analyzeFileState(\n      FSNamesystem fsn, String src, long fileId, String clientName,\n      ExtendedBlock previous, LocatedBlock[] onRetryBlock)\n          throws IOException  {\n    assert fsn.hasReadLock();\n\n    checkBlock(fsn, previous);\n    onRetryBlock[0] \u003d null;\n    fsn.checkNameNodeSafeMode(\"Cannot add block to \" + src);\n\n    // have we exceeded the configured limit of fs objects.\n    fsn.checkFsObjectLimit();\n\n    Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n    final INode inode;\n    final INodesInPath iip;\n    if (fileId \u003d\u003d HdfsConstants.GRANDFATHER_INODE_ID) {\n      // Older clients may not have given us an inode ID to work with.\n      // In this case, we have to try to resolve the path and hope it\n      // hasn\u0027t changed or been deleted since the file was opened for write.\n      iip \u003d fsn.dir.getINodesInPath4Write(src);\n      inode \u003d iip.getLastINode();\n    } else {\n      // Newer clients pass the inode ID, so we can just get the inode\n      // directly.\n      inode \u003d fsn.dir.getInode(fileId);\n      iip \u003d INodesInPath.fromINode(inode);\n      if (inode !\u003d null) {\n        src \u003d iip.getPath();\n      }\n    }\n    final INodeFile file \u003d fsn.checkLease(src, clientName,\n                                                 inode, fileId);\n    BlockInfoContiguous lastBlockInFile \u003d file.getLastBlock();\n    if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n      // The block that the client claims is the current last block\n      // doesn\u0027t match up with what we think is the last block. There are\n      // four possibilities:\n      // 1) This is the first block allocation of an append() pipeline\n      //    which started appending exactly at or exceeding the block boundary.\n      //    In this case, the client isn\u0027t passed the previous block,\n      //    so it makes the allocateBlock() call with previous\u003dnull.\n      //    We can distinguish this since the last block of the file\n      //    will be exactly a full block.\n      // 2) This is a retry from a client that missed the response of a\n      //    prior getAdditionalBlock() call, perhaps because of a network\n      //    timeout, or because of an HA failover. In that case, we know\n      //    by the fact that the client is re-issuing the RPC that it\n      //    never began to write to the old block. Hence it is safe to\n      //    to return the existing block.\n      // 3) This is an entirely bogus request/bug -- we should error out\n      //    rather than potentially appending a new block with an empty\n      //    one in the middle, etc\n      // 4) This is a retry from a client that timed out while\n      //    the prior getAdditionalBlock() is still being processed,\n      //    currently working on chooseTarget().\n      //    There are no means to distinguish between the first and\n      //    the second attempts in Part I, because the first one hasn\u0027t\n      //    changed the namesystem state yet.\n      //    We run this analysis again in Part II where case 4 is impossible.\n\n      BlockInfoContiguous penultimateBlock \u003d file.getPenultimateBlock();\n      if (previous \u003d\u003d null \u0026\u0026\n          lastBlockInFile !\u003d null \u0026\u0026\n          lastBlockInFile.getNumBytes() \u003e\u003d file.getPreferredBlockSize() \u0026\u0026\n          lastBlockInFile.isComplete()) {\n        // Case 1\n        if (NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\n               \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n               \" writing to a file with a complete previous block: src\u003d\" +\n               src + \" lastBlock\u003d\" + lastBlockInFile);\n        }\n      } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n        if (lastBlockInFile.getNumBytes() !\u003d 0) {\n          throw new IOException(\n              \"Request looked like a retry to allocate block \" +\n              lastBlockInFile + \" but it already contains \" +\n              lastBlockInFile.getNumBytes() + \" bytes\");\n        }\n\n        // Case 2\n        // Return the last block.\n        NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: caught retry for \" +\n            \"allocation of a new block in \" + src + \". Returning previously\" +\n            \" allocated block \" + lastBlockInFile);\n        long offset \u003d file.computeFileSize();\n        BlockInfoContiguousUnderConstruction lastBlockUC \u003d\n            (BlockInfoContiguousUnderConstruction) lastBlockInFile;\n        onRetryBlock[0] \u003d makeLocatedBlock(fsn, lastBlockInFile,\n            lastBlockUC.getExpectedStorageLocations(), offset);\n        return new FileState(file, src, iip);\n      } else {\n        // Case 3\n        throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n            \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n            \"last block in file \" + lastBlockInFile);\n      }\n    }\n    return new FileState(file, src, iip);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirWriteFileOp.java",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[private, static]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-8394. Move getAdditionalBlock() and related functionalities into a separate class. Contributed by Haohui Mai.\n",
          "commitDate": "15/05/15 7:09 PM",
          "commitName": "e5afac5896a1a88e152746598527d91f73cbb724",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "15/05/15 4:14 PM",
          "commitNameOld": "8f378733423a5244461df79a92c00239514b8b93",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 0.12,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,101 +1,101 @@\n-  FileState analyzeFileState(String src,\n-                                long fileId,\n-                                String clientName,\n-                                ExtendedBlock previous,\n-                                LocatedBlock[] onRetryBlock)\n+  private static FileState analyzeFileState(\n+      FSNamesystem fsn, String src, long fileId, String clientName,\n+      ExtendedBlock previous, LocatedBlock[] onRetryBlock)\n           throws IOException  {\n-    assert hasReadLock();\n+    assert fsn.hasReadLock();\n \n-    checkBlock(previous);\n+    checkBlock(fsn, previous);\n     onRetryBlock[0] \u003d null;\n-    checkNameNodeSafeMode(\"Cannot add block to \" + src);\n+    fsn.checkNameNodeSafeMode(\"Cannot add block to \" + src);\n \n     // have we exceeded the configured limit of fs objects.\n-    checkFsObjectLimit();\n+    fsn.checkFsObjectLimit();\n \n     Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n     final INode inode;\n     final INodesInPath iip;\n     if (fileId \u003d\u003d HdfsConstants.GRANDFATHER_INODE_ID) {\n       // Older clients may not have given us an inode ID to work with.\n       // In this case, we have to try to resolve the path and hope it\n       // hasn\u0027t changed or been deleted since the file was opened for write.\n-      iip \u003d dir.getINodesInPath4Write(src);\n+      iip \u003d fsn.dir.getINodesInPath4Write(src);\n       inode \u003d iip.getLastINode();\n     } else {\n       // Newer clients pass the inode ID, so we can just get the inode\n       // directly.\n-      inode \u003d dir.getInode(fileId);\n+      inode \u003d fsn.dir.getInode(fileId);\n       iip \u003d INodesInPath.fromINode(inode);\n       if (inode !\u003d null) {\n         src \u003d iip.getPath();\n       }\n     }\n-    final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n-    BlockInfoContiguous lastBlockInFile \u003d pendingFile.getLastBlock();\n+    final INodeFile file \u003d fsn.checkLease(src, clientName,\n+                                                 inode, fileId);\n+    BlockInfoContiguous lastBlockInFile \u003d file.getLastBlock();\n     if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n       // The block that the client claims is the current last block\n       // doesn\u0027t match up with what we think is the last block. There are\n       // four possibilities:\n       // 1) This is the first block allocation of an append() pipeline\n       //    which started appending exactly at or exceeding the block boundary.\n       //    In this case, the client isn\u0027t passed the previous block,\n       //    so it makes the allocateBlock() call with previous\u003dnull.\n       //    We can distinguish this since the last block of the file\n       //    will be exactly a full block.\n       // 2) This is a retry from a client that missed the response of a\n       //    prior getAdditionalBlock() call, perhaps because of a network\n       //    timeout, or because of an HA failover. In that case, we know\n       //    by the fact that the client is re-issuing the RPC that it\n       //    never began to write to the old block. Hence it is safe to\n       //    to return the existing block.\n       // 3) This is an entirely bogus request/bug -- we should error out\n       //    rather than potentially appending a new block with an empty\n       //    one in the middle, etc\n       // 4) This is a retry from a client that timed out while\n       //    the prior getAdditionalBlock() is still being processed,\n-      //    currently working on chooseTarget(). \n-      //    There are no means to distinguish between the first and \n+      //    currently working on chooseTarget().\n+      //    There are no means to distinguish between the first and\n       //    the second attempts in Part I, because the first one hasn\u0027t\n       //    changed the namesystem state yet.\n       //    We run this analysis again in Part II where case 4 is impossible.\n \n-      BlockInfoContiguous penultimateBlock \u003d pendingFile.getPenultimateBlock();\n+      BlockInfoContiguous penultimateBlock \u003d file.getPenultimateBlock();\n       if (previous \u003d\u003d null \u0026\u0026\n           lastBlockInFile !\u003d null \u0026\u0026\n-          lastBlockInFile.getNumBytes() \u003e\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n+          lastBlockInFile.getNumBytes() \u003e\u003d file.getPreferredBlockSize() \u0026\u0026\n           lastBlockInFile.isComplete()) {\n         // Case 1\n         if (NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\n                \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n                \" writing to a file with a complete previous block: src\u003d\" +\n                src + \" lastBlock\u003d\" + lastBlockInFile);\n         }\n       } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n         if (lastBlockInFile.getNumBytes() !\u003d 0) {\n           throw new IOException(\n               \"Request looked like a retry to allocate block \" +\n               lastBlockInFile + \" but it already contains \" +\n               lastBlockInFile.getNumBytes() + \" bytes\");\n         }\n \n         // Case 2\n         // Return the last block.\n-        NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: \" +\n-            \"caught retry for allocation of a new block in \" +\n-            src + \". Returning previously allocated block \" + lastBlockInFile);\n-        long offset \u003d pendingFile.computeFileSize();\n-        onRetryBlock[0] \u003d makeLocatedBlock(lastBlockInFile,\n-            ((BlockInfoContiguousUnderConstruction)lastBlockInFile).getExpectedStorageLocations(),\n-            offset);\n-        return new FileState(pendingFile, src, iip);\n+        NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: caught retry for \" +\n+            \"allocation of a new block in \" + src + \". Returning previously\" +\n+            \" allocated block \" + lastBlockInFile);\n+        long offset \u003d file.computeFileSize();\n+        BlockInfoContiguousUnderConstruction lastBlockUC \u003d\n+            (BlockInfoContiguousUnderConstruction) lastBlockInFile;\n+        onRetryBlock[0] \u003d makeLocatedBlock(fsn, lastBlockInFile,\n+            lastBlockUC.getExpectedStorageLocations(), offset);\n+        return new FileState(file, src, iip);\n       } else {\n         // Case 3\n         throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n             \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n             \"last block in file \" + lastBlockInFile);\n       }\n     }\n-    return new FileState(pendingFile, src, iip);\n+    return new FileState(file, src, iip);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private static FileState analyzeFileState(\n      FSNamesystem fsn, String src, long fileId, String clientName,\n      ExtendedBlock previous, LocatedBlock[] onRetryBlock)\n          throws IOException  {\n    assert fsn.hasReadLock();\n\n    checkBlock(fsn, previous);\n    onRetryBlock[0] \u003d null;\n    fsn.checkNameNodeSafeMode(\"Cannot add block to \" + src);\n\n    // have we exceeded the configured limit of fs objects.\n    fsn.checkFsObjectLimit();\n\n    Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n    final INode inode;\n    final INodesInPath iip;\n    if (fileId \u003d\u003d HdfsConstants.GRANDFATHER_INODE_ID) {\n      // Older clients may not have given us an inode ID to work with.\n      // In this case, we have to try to resolve the path and hope it\n      // hasn\u0027t changed or been deleted since the file was opened for write.\n      iip \u003d fsn.dir.getINodesInPath4Write(src);\n      inode \u003d iip.getLastINode();\n    } else {\n      // Newer clients pass the inode ID, so we can just get the inode\n      // directly.\n      inode \u003d fsn.dir.getInode(fileId);\n      iip \u003d INodesInPath.fromINode(inode);\n      if (inode !\u003d null) {\n        src \u003d iip.getPath();\n      }\n    }\n    final INodeFile file \u003d fsn.checkLease(src, clientName,\n                                                 inode, fileId);\n    BlockInfoContiguous lastBlockInFile \u003d file.getLastBlock();\n    if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n      // The block that the client claims is the current last block\n      // doesn\u0027t match up with what we think is the last block. There are\n      // four possibilities:\n      // 1) This is the first block allocation of an append() pipeline\n      //    which started appending exactly at or exceeding the block boundary.\n      //    In this case, the client isn\u0027t passed the previous block,\n      //    so it makes the allocateBlock() call with previous\u003dnull.\n      //    We can distinguish this since the last block of the file\n      //    will be exactly a full block.\n      // 2) This is a retry from a client that missed the response of a\n      //    prior getAdditionalBlock() call, perhaps because of a network\n      //    timeout, or because of an HA failover. In that case, we know\n      //    by the fact that the client is re-issuing the RPC that it\n      //    never began to write to the old block. Hence it is safe to\n      //    to return the existing block.\n      // 3) This is an entirely bogus request/bug -- we should error out\n      //    rather than potentially appending a new block with an empty\n      //    one in the middle, etc\n      // 4) This is a retry from a client that timed out while\n      //    the prior getAdditionalBlock() is still being processed,\n      //    currently working on chooseTarget().\n      //    There are no means to distinguish between the first and\n      //    the second attempts in Part I, because the first one hasn\u0027t\n      //    changed the namesystem state yet.\n      //    We run this analysis again in Part II where case 4 is impossible.\n\n      BlockInfoContiguous penultimateBlock \u003d file.getPenultimateBlock();\n      if (previous \u003d\u003d null \u0026\u0026\n          lastBlockInFile !\u003d null \u0026\u0026\n          lastBlockInFile.getNumBytes() \u003e\u003d file.getPreferredBlockSize() \u0026\u0026\n          lastBlockInFile.isComplete()) {\n        // Case 1\n        if (NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\n               \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n               \" writing to a file with a complete previous block: src\u003d\" +\n               src + \" lastBlock\u003d\" + lastBlockInFile);\n        }\n      } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n        if (lastBlockInFile.getNumBytes() !\u003d 0) {\n          throw new IOException(\n              \"Request looked like a retry to allocate block \" +\n              lastBlockInFile + \" but it already contains \" +\n              lastBlockInFile.getNumBytes() + \" bytes\");\n        }\n\n        // Case 2\n        // Return the last block.\n        NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: caught retry for \" +\n            \"allocation of a new block in \" + src + \". Returning previously\" +\n            \" allocated block \" + lastBlockInFile);\n        long offset \u003d file.computeFileSize();\n        BlockInfoContiguousUnderConstruction lastBlockUC \u003d\n            (BlockInfoContiguousUnderConstruction) lastBlockInFile;\n        onRetryBlock[0] \u003d makeLocatedBlock(fsn, lastBlockInFile,\n            lastBlockUC.getExpectedStorageLocations(), offset);\n        return new FileState(file, src, iip);\n      } else {\n        // Case 3\n        throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n            \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n            \"last block in file \" + lastBlockInFile);\n      }\n    }\n    return new FileState(file, src, iip);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirWriteFileOp.java",
          "extendedDetails": {}
        },
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-8394. Move getAdditionalBlock() and related functionalities into a separate class. Contributed by Haohui Mai.\n",
          "commitDate": "15/05/15 7:09 PM",
          "commitName": "e5afac5896a1a88e152746598527d91f73cbb724",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "15/05/15 4:14 PM",
          "commitNameOld": "8f378733423a5244461df79a92c00239514b8b93",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 0.12,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,101 +1,101 @@\n-  FileState analyzeFileState(String src,\n-                                long fileId,\n-                                String clientName,\n-                                ExtendedBlock previous,\n-                                LocatedBlock[] onRetryBlock)\n+  private static FileState analyzeFileState(\n+      FSNamesystem fsn, String src, long fileId, String clientName,\n+      ExtendedBlock previous, LocatedBlock[] onRetryBlock)\n           throws IOException  {\n-    assert hasReadLock();\n+    assert fsn.hasReadLock();\n \n-    checkBlock(previous);\n+    checkBlock(fsn, previous);\n     onRetryBlock[0] \u003d null;\n-    checkNameNodeSafeMode(\"Cannot add block to \" + src);\n+    fsn.checkNameNodeSafeMode(\"Cannot add block to \" + src);\n \n     // have we exceeded the configured limit of fs objects.\n-    checkFsObjectLimit();\n+    fsn.checkFsObjectLimit();\n \n     Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n     final INode inode;\n     final INodesInPath iip;\n     if (fileId \u003d\u003d HdfsConstants.GRANDFATHER_INODE_ID) {\n       // Older clients may not have given us an inode ID to work with.\n       // In this case, we have to try to resolve the path and hope it\n       // hasn\u0027t changed or been deleted since the file was opened for write.\n-      iip \u003d dir.getINodesInPath4Write(src);\n+      iip \u003d fsn.dir.getINodesInPath4Write(src);\n       inode \u003d iip.getLastINode();\n     } else {\n       // Newer clients pass the inode ID, so we can just get the inode\n       // directly.\n-      inode \u003d dir.getInode(fileId);\n+      inode \u003d fsn.dir.getInode(fileId);\n       iip \u003d INodesInPath.fromINode(inode);\n       if (inode !\u003d null) {\n         src \u003d iip.getPath();\n       }\n     }\n-    final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n-    BlockInfoContiguous lastBlockInFile \u003d pendingFile.getLastBlock();\n+    final INodeFile file \u003d fsn.checkLease(src, clientName,\n+                                                 inode, fileId);\n+    BlockInfoContiguous lastBlockInFile \u003d file.getLastBlock();\n     if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n       // The block that the client claims is the current last block\n       // doesn\u0027t match up with what we think is the last block. There are\n       // four possibilities:\n       // 1) This is the first block allocation of an append() pipeline\n       //    which started appending exactly at or exceeding the block boundary.\n       //    In this case, the client isn\u0027t passed the previous block,\n       //    so it makes the allocateBlock() call with previous\u003dnull.\n       //    We can distinguish this since the last block of the file\n       //    will be exactly a full block.\n       // 2) This is a retry from a client that missed the response of a\n       //    prior getAdditionalBlock() call, perhaps because of a network\n       //    timeout, or because of an HA failover. In that case, we know\n       //    by the fact that the client is re-issuing the RPC that it\n       //    never began to write to the old block. Hence it is safe to\n       //    to return the existing block.\n       // 3) This is an entirely bogus request/bug -- we should error out\n       //    rather than potentially appending a new block with an empty\n       //    one in the middle, etc\n       // 4) This is a retry from a client that timed out while\n       //    the prior getAdditionalBlock() is still being processed,\n-      //    currently working on chooseTarget(). \n-      //    There are no means to distinguish between the first and \n+      //    currently working on chooseTarget().\n+      //    There are no means to distinguish between the first and\n       //    the second attempts in Part I, because the first one hasn\u0027t\n       //    changed the namesystem state yet.\n       //    We run this analysis again in Part II where case 4 is impossible.\n \n-      BlockInfoContiguous penultimateBlock \u003d pendingFile.getPenultimateBlock();\n+      BlockInfoContiguous penultimateBlock \u003d file.getPenultimateBlock();\n       if (previous \u003d\u003d null \u0026\u0026\n           lastBlockInFile !\u003d null \u0026\u0026\n-          lastBlockInFile.getNumBytes() \u003e\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n+          lastBlockInFile.getNumBytes() \u003e\u003d file.getPreferredBlockSize() \u0026\u0026\n           lastBlockInFile.isComplete()) {\n         // Case 1\n         if (NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\n                \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n                \" writing to a file with a complete previous block: src\u003d\" +\n                src + \" lastBlock\u003d\" + lastBlockInFile);\n         }\n       } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n         if (lastBlockInFile.getNumBytes() !\u003d 0) {\n           throw new IOException(\n               \"Request looked like a retry to allocate block \" +\n               lastBlockInFile + \" but it already contains \" +\n               lastBlockInFile.getNumBytes() + \" bytes\");\n         }\n \n         // Case 2\n         // Return the last block.\n-        NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: \" +\n-            \"caught retry for allocation of a new block in \" +\n-            src + \". Returning previously allocated block \" + lastBlockInFile);\n-        long offset \u003d pendingFile.computeFileSize();\n-        onRetryBlock[0] \u003d makeLocatedBlock(lastBlockInFile,\n-            ((BlockInfoContiguousUnderConstruction)lastBlockInFile).getExpectedStorageLocations(),\n-            offset);\n-        return new FileState(pendingFile, src, iip);\n+        NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: caught retry for \" +\n+            \"allocation of a new block in \" + src + \". Returning previously\" +\n+            \" allocated block \" + lastBlockInFile);\n+        long offset \u003d file.computeFileSize();\n+        BlockInfoContiguousUnderConstruction lastBlockUC \u003d\n+            (BlockInfoContiguousUnderConstruction) lastBlockInFile;\n+        onRetryBlock[0] \u003d makeLocatedBlock(fsn, lastBlockInFile,\n+            lastBlockUC.getExpectedStorageLocations(), offset);\n+        return new FileState(file, src, iip);\n       } else {\n         // Case 3\n         throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n             \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n             \"last block in file \" + lastBlockInFile);\n       }\n     }\n-    return new FileState(pendingFile, src, iip);\n+    return new FileState(file, src, iip);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private static FileState analyzeFileState(\n      FSNamesystem fsn, String src, long fileId, String clientName,\n      ExtendedBlock previous, LocatedBlock[] onRetryBlock)\n          throws IOException  {\n    assert fsn.hasReadLock();\n\n    checkBlock(fsn, previous);\n    onRetryBlock[0] \u003d null;\n    fsn.checkNameNodeSafeMode(\"Cannot add block to \" + src);\n\n    // have we exceeded the configured limit of fs objects.\n    fsn.checkFsObjectLimit();\n\n    Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n    final INode inode;\n    final INodesInPath iip;\n    if (fileId \u003d\u003d HdfsConstants.GRANDFATHER_INODE_ID) {\n      // Older clients may not have given us an inode ID to work with.\n      // In this case, we have to try to resolve the path and hope it\n      // hasn\u0027t changed or been deleted since the file was opened for write.\n      iip \u003d fsn.dir.getINodesInPath4Write(src);\n      inode \u003d iip.getLastINode();\n    } else {\n      // Newer clients pass the inode ID, so we can just get the inode\n      // directly.\n      inode \u003d fsn.dir.getInode(fileId);\n      iip \u003d INodesInPath.fromINode(inode);\n      if (inode !\u003d null) {\n        src \u003d iip.getPath();\n      }\n    }\n    final INodeFile file \u003d fsn.checkLease(src, clientName,\n                                                 inode, fileId);\n    BlockInfoContiguous lastBlockInFile \u003d file.getLastBlock();\n    if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n      // The block that the client claims is the current last block\n      // doesn\u0027t match up with what we think is the last block. There are\n      // four possibilities:\n      // 1) This is the first block allocation of an append() pipeline\n      //    which started appending exactly at or exceeding the block boundary.\n      //    In this case, the client isn\u0027t passed the previous block,\n      //    so it makes the allocateBlock() call with previous\u003dnull.\n      //    We can distinguish this since the last block of the file\n      //    will be exactly a full block.\n      // 2) This is a retry from a client that missed the response of a\n      //    prior getAdditionalBlock() call, perhaps because of a network\n      //    timeout, or because of an HA failover. In that case, we know\n      //    by the fact that the client is re-issuing the RPC that it\n      //    never began to write to the old block. Hence it is safe to\n      //    to return the existing block.\n      // 3) This is an entirely bogus request/bug -- we should error out\n      //    rather than potentially appending a new block with an empty\n      //    one in the middle, etc\n      // 4) This is a retry from a client that timed out while\n      //    the prior getAdditionalBlock() is still being processed,\n      //    currently working on chooseTarget().\n      //    There are no means to distinguish between the first and\n      //    the second attempts in Part I, because the first one hasn\u0027t\n      //    changed the namesystem state yet.\n      //    We run this analysis again in Part II where case 4 is impossible.\n\n      BlockInfoContiguous penultimateBlock \u003d file.getPenultimateBlock();\n      if (previous \u003d\u003d null \u0026\u0026\n          lastBlockInFile !\u003d null \u0026\u0026\n          lastBlockInFile.getNumBytes() \u003e\u003d file.getPreferredBlockSize() \u0026\u0026\n          lastBlockInFile.isComplete()) {\n        // Case 1\n        if (NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\n               \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n               \" writing to a file with a complete previous block: src\u003d\" +\n               src + \" lastBlock\u003d\" + lastBlockInFile);\n        }\n      } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n        if (lastBlockInFile.getNumBytes() !\u003d 0) {\n          throw new IOException(\n              \"Request looked like a retry to allocate block \" +\n              lastBlockInFile + \" but it already contains \" +\n              lastBlockInFile.getNumBytes() + \" bytes\");\n        }\n\n        // Case 2\n        // Return the last block.\n        NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: caught retry for \" +\n            \"allocation of a new block in \" + src + \". Returning previously\" +\n            \" allocated block \" + lastBlockInFile);\n        long offset \u003d file.computeFileSize();\n        BlockInfoContiguousUnderConstruction lastBlockUC \u003d\n            (BlockInfoContiguousUnderConstruction) lastBlockInFile;\n        onRetryBlock[0] \u003d makeLocatedBlock(fsn, lastBlockInFile,\n            lastBlockUC.getExpectedStorageLocations(), offset);\n        return new FileState(file, src, iip);\n      } else {\n        // Case 3\n        throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n            \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n            \"last block in file \" + lastBlockInFile);\n      }\n    }\n    return new FileState(file, src, iip);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirWriteFileOp.java",
          "extendedDetails": {
            "oldValue": "[src-String, fileId-long, clientName-String, previous-ExtendedBlock, onRetryBlock-LocatedBlock[]]",
            "newValue": "[fsn-FSNamesystem, src-String, fileId-long, clientName-String, previous-ExtendedBlock, onRetryBlock-LocatedBlock[]]"
          }
        }
      ]
    },
    "6ae2a0d048e133b43249c248a75a4d77d9abb80d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8249. Separate HdfsConstants into the client and the server side class. Contributed by Haohui Mai.\n",
      "commitDate": "02/05/15 10:03 AM",
      "commitName": "6ae2a0d048e133b43249c248a75a4d77d9abb80d",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "01/05/15 4:42 PM",
      "commitNameOld": "6f541edce0ed64bf316276715c4bc07794ff20ac",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 0.72,
      "commitsBetweenForRepo": 6,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,101 +1,101 @@\n   FileState analyzeFileState(String src,\n                                 long fileId,\n                                 String clientName,\n                                 ExtendedBlock previous,\n                                 LocatedBlock[] onRetryBlock)\n           throws IOException  {\n     assert hasReadLock();\n \n     checkBlock(previous);\n     onRetryBlock[0] \u003d null;\n     checkNameNodeSafeMode(\"Cannot add block to \" + src);\n \n     // have we exceeded the configured limit of fs objects.\n     checkFsObjectLimit();\n \n     Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n     final INode inode;\n     final INodesInPath iip;\n-    if (fileId \u003d\u003d HdfsConstantsClient.GRANDFATHER_INODE_ID) {\n+    if (fileId \u003d\u003d HdfsConstants.GRANDFATHER_INODE_ID) {\n       // Older clients may not have given us an inode ID to work with.\n       // In this case, we have to try to resolve the path and hope it\n       // hasn\u0027t changed or been deleted since the file was opened for write.\n       iip \u003d dir.getINodesInPath4Write(src);\n       inode \u003d iip.getLastINode();\n     } else {\n       // Newer clients pass the inode ID, so we can just get the inode\n       // directly.\n       inode \u003d dir.getInode(fileId);\n       iip \u003d INodesInPath.fromINode(inode);\n       if (inode !\u003d null) {\n         src \u003d iip.getPath();\n       }\n     }\n     final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n     BlockInfoContiguous lastBlockInFile \u003d pendingFile.getLastBlock();\n     if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n       // The block that the client claims is the current last block\n       // doesn\u0027t match up with what we think is the last block. There are\n       // four possibilities:\n       // 1) This is the first block allocation of an append() pipeline\n       //    which started appending exactly at or exceeding the block boundary.\n       //    In this case, the client isn\u0027t passed the previous block,\n       //    so it makes the allocateBlock() call with previous\u003dnull.\n       //    We can distinguish this since the last block of the file\n       //    will be exactly a full block.\n       // 2) This is a retry from a client that missed the response of a\n       //    prior getAdditionalBlock() call, perhaps because of a network\n       //    timeout, or because of an HA failover. In that case, we know\n       //    by the fact that the client is re-issuing the RPC that it\n       //    never began to write to the old block. Hence it is safe to\n       //    to return the existing block.\n       // 3) This is an entirely bogus request/bug -- we should error out\n       //    rather than potentially appending a new block with an empty\n       //    one in the middle, etc\n       // 4) This is a retry from a client that timed out while\n       //    the prior getAdditionalBlock() is still being processed,\n       //    currently working on chooseTarget(). \n       //    There are no means to distinguish between the first and \n       //    the second attempts in Part I, because the first one hasn\u0027t\n       //    changed the namesystem state yet.\n       //    We run this analysis again in Part II where case 4 is impossible.\n \n       BlockInfoContiguous penultimateBlock \u003d pendingFile.getPenultimateBlock();\n       if (previous \u003d\u003d null \u0026\u0026\n           lastBlockInFile !\u003d null \u0026\u0026\n           lastBlockInFile.getNumBytes() \u003e\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n           lastBlockInFile.isComplete()) {\n         // Case 1\n         if (NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\n                \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n                \" writing to a file with a complete previous block: src\u003d\" +\n                src + \" lastBlock\u003d\" + lastBlockInFile);\n         }\n       } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n         if (lastBlockInFile.getNumBytes() !\u003d 0) {\n           throw new IOException(\n               \"Request looked like a retry to allocate block \" +\n               lastBlockInFile + \" but it already contains \" +\n               lastBlockInFile.getNumBytes() + \" bytes\");\n         }\n \n         // Case 2\n         // Return the last block.\n         NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: \" +\n             \"caught retry for allocation of a new block in \" +\n             src + \". Returning previously allocated block \" + lastBlockInFile);\n         long offset \u003d pendingFile.computeFileSize();\n         onRetryBlock[0] \u003d makeLocatedBlock(lastBlockInFile,\n             ((BlockInfoContiguousUnderConstruction)lastBlockInFile).getExpectedStorageLocations(),\n             offset);\n         return new FileState(pendingFile, src, iip);\n       } else {\n         // Case 3\n         throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n             \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n             \"last block in file \" + lastBlockInFile);\n       }\n     }\n     return new FileState(pendingFile, src, iip);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  FileState analyzeFileState(String src,\n                                long fileId,\n                                String clientName,\n                                ExtendedBlock previous,\n                                LocatedBlock[] onRetryBlock)\n          throws IOException  {\n    assert hasReadLock();\n\n    checkBlock(previous);\n    onRetryBlock[0] \u003d null;\n    checkNameNodeSafeMode(\"Cannot add block to \" + src);\n\n    // have we exceeded the configured limit of fs objects.\n    checkFsObjectLimit();\n\n    Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n    final INode inode;\n    final INodesInPath iip;\n    if (fileId \u003d\u003d HdfsConstants.GRANDFATHER_INODE_ID) {\n      // Older clients may not have given us an inode ID to work with.\n      // In this case, we have to try to resolve the path and hope it\n      // hasn\u0027t changed or been deleted since the file was opened for write.\n      iip \u003d dir.getINodesInPath4Write(src);\n      inode \u003d iip.getLastINode();\n    } else {\n      // Newer clients pass the inode ID, so we can just get the inode\n      // directly.\n      inode \u003d dir.getInode(fileId);\n      iip \u003d INodesInPath.fromINode(inode);\n      if (inode !\u003d null) {\n        src \u003d iip.getPath();\n      }\n    }\n    final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n    BlockInfoContiguous lastBlockInFile \u003d pendingFile.getLastBlock();\n    if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n      // The block that the client claims is the current last block\n      // doesn\u0027t match up with what we think is the last block. There are\n      // four possibilities:\n      // 1) This is the first block allocation of an append() pipeline\n      //    which started appending exactly at or exceeding the block boundary.\n      //    In this case, the client isn\u0027t passed the previous block,\n      //    so it makes the allocateBlock() call with previous\u003dnull.\n      //    We can distinguish this since the last block of the file\n      //    will be exactly a full block.\n      // 2) This is a retry from a client that missed the response of a\n      //    prior getAdditionalBlock() call, perhaps because of a network\n      //    timeout, or because of an HA failover. In that case, we know\n      //    by the fact that the client is re-issuing the RPC that it\n      //    never began to write to the old block. Hence it is safe to\n      //    to return the existing block.\n      // 3) This is an entirely bogus request/bug -- we should error out\n      //    rather than potentially appending a new block with an empty\n      //    one in the middle, etc\n      // 4) This is a retry from a client that timed out while\n      //    the prior getAdditionalBlock() is still being processed,\n      //    currently working on chooseTarget(). \n      //    There are no means to distinguish between the first and \n      //    the second attempts in Part I, because the first one hasn\u0027t\n      //    changed the namesystem state yet.\n      //    We run this analysis again in Part II where case 4 is impossible.\n\n      BlockInfoContiguous penultimateBlock \u003d pendingFile.getPenultimateBlock();\n      if (previous \u003d\u003d null \u0026\u0026\n          lastBlockInFile !\u003d null \u0026\u0026\n          lastBlockInFile.getNumBytes() \u003e\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n          lastBlockInFile.isComplete()) {\n        // Case 1\n        if (NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\n               \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n               \" writing to a file with a complete previous block: src\u003d\" +\n               src + \" lastBlock\u003d\" + lastBlockInFile);\n        }\n      } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n        if (lastBlockInFile.getNumBytes() !\u003d 0) {\n          throw new IOException(\n              \"Request looked like a retry to allocate block \" +\n              lastBlockInFile + \" but it already contains \" +\n              lastBlockInFile.getNumBytes() + \" bytes\");\n        }\n\n        // Case 2\n        // Return the last block.\n        NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: \" +\n            \"caught retry for allocation of a new block in \" +\n            src + \". Returning previously allocated block \" + lastBlockInFile);\n        long offset \u003d pendingFile.computeFileSize();\n        onRetryBlock[0] \u003d makeLocatedBlock(lastBlockInFile,\n            ((BlockInfoContiguousUnderConstruction)lastBlockInFile).getExpectedStorageLocations(),\n            offset);\n        return new FileState(pendingFile, src, iip);\n      } else {\n        // Case 3\n        throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n            \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n            \"last block in file \" + lastBlockInFile);\n      }\n    }\n    return new FileState(pendingFile, src, iip);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "76e7264e8d6407f527bd877009aca11f7bb63bd7": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8165. Move GRANDFATHER_GENERATION_STAMP and GRANDFATER_INODE_ID to hdfs-client. Contributed by Haohui Mai.\n",
      "commitDate": "16/04/15 10:49 PM",
      "commitName": "76e7264e8d6407f527bd877009aca11f7bb63bd7",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "14/04/15 3:05 PM",
      "commitNameOld": "fddd55279d0bdd08b3b40aba6fe2ded1d2e0d846",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 2.32,
      "commitsBetweenForRepo": 17,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,101 +1,101 @@\n   FileState analyzeFileState(String src,\n                                 long fileId,\n                                 String clientName,\n                                 ExtendedBlock previous,\n                                 LocatedBlock[] onRetryBlock)\n           throws IOException  {\n     assert hasReadLock();\n \n     checkBlock(previous);\n     onRetryBlock[0] \u003d null;\n     checkNameNodeSafeMode(\"Cannot add block to \" + src);\n \n     // have we exceeded the configured limit of fs objects.\n     checkFsObjectLimit();\n \n     Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n     final INode inode;\n     final INodesInPath iip;\n-    if (fileId \u003d\u003d INodeId.GRANDFATHER_INODE_ID) {\n+    if (fileId \u003d\u003d HdfsConstantsClient.GRANDFATHER_INODE_ID) {\n       // Older clients may not have given us an inode ID to work with.\n       // In this case, we have to try to resolve the path and hope it\n       // hasn\u0027t changed or been deleted since the file was opened for write.\n       iip \u003d dir.getINodesInPath4Write(src);\n       inode \u003d iip.getLastINode();\n     } else {\n       // Newer clients pass the inode ID, so we can just get the inode\n       // directly.\n       inode \u003d dir.getInode(fileId);\n       iip \u003d INodesInPath.fromINode(inode);\n       if (inode !\u003d null) {\n         src \u003d iip.getPath();\n       }\n     }\n     final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n     BlockInfoContiguous lastBlockInFile \u003d pendingFile.getLastBlock();\n     if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n       // The block that the client claims is the current last block\n       // doesn\u0027t match up with what we think is the last block. There are\n       // four possibilities:\n       // 1) This is the first block allocation of an append() pipeline\n       //    which started appending exactly at or exceeding the block boundary.\n       //    In this case, the client isn\u0027t passed the previous block,\n       //    so it makes the allocateBlock() call with previous\u003dnull.\n       //    We can distinguish this since the last block of the file\n       //    will be exactly a full block.\n       // 2) This is a retry from a client that missed the response of a\n       //    prior getAdditionalBlock() call, perhaps because of a network\n       //    timeout, or because of an HA failover. In that case, we know\n       //    by the fact that the client is re-issuing the RPC that it\n       //    never began to write to the old block. Hence it is safe to\n       //    to return the existing block.\n       // 3) This is an entirely bogus request/bug -- we should error out\n       //    rather than potentially appending a new block with an empty\n       //    one in the middle, etc\n       // 4) This is a retry from a client that timed out while\n       //    the prior getAdditionalBlock() is still being processed,\n       //    currently working on chooseTarget(). \n       //    There are no means to distinguish between the first and \n       //    the second attempts in Part I, because the first one hasn\u0027t\n       //    changed the namesystem state yet.\n       //    We run this analysis again in Part II where case 4 is impossible.\n \n       BlockInfoContiguous penultimateBlock \u003d pendingFile.getPenultimateBlock();\n       if (previous \u003d\u003d null \u0026\u0026\n           lastBlockInFile !\u003d null \u0026\u0026\n           lastBlockInFile.getNumBytes() \u003e\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n           lastBlockInFile.isComplete()) {\n         // Case 1\n         if (NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\n                \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n                \" writing to a file with a complete previous block: src\u003d\" +\n                src + \" lastBlock\u003d\" + lastBlockInFile);\n         }\n       } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n         if (lastBlockInFile.getNumBytes() !\u003d 0) {\n           throw new IOException(\n               \"Request looked like a retry to allocate block \" +\n               lastBlockInFile + \" but it already contains \" +\n               lastBlockInFile.getNumBytes() + \" bytes\");\n         }\n \n         // Case 2\n         // Return the last block.\n         NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: \" +\n             \"caught retry for allocation of a new block in \" +\n             src + \". Returning previously allocated block \" + lastBlockInFile);\n         long offset \u003d pendingFile.computeFileSize();\n         onRetryBlock[0] \u003d makeLocatedBlock(lastBlockInFile,\n             ((BlockInfoContiguousUnderConstruction)lastBlockInFile).getExpectedStorageLocations(),\n             offset);\n         return new FileState(pendingFile, src, iip);\n       } else {\n         // Case 3\n         throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n             \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n             \"last block in file \" + lastBlockInFile);\n       }\n     }\n     return new FileState(pendingFile, src, iip);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  FileState analyzeFileState(String src,\n                                long fileId,\n                                String clientName,\n                                ExtendedBlock previous,\n                                LocatedBlock[] onRetryBlock)\n          throws IOException  {\n    assert hasReadLock();\n\n    checkBlock(previous);\n    onRetryBlock[0] \u003d null;\n    checkNameNodeSafeMode(\"Cannot add block to \" + src);\n\n    // have we exceeded the configured limit of fs objects.\n    checkFsObjectLimit();\n\n    Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n    final INode inode;\n    final INodesInPath iip;\n    if (fileId \u003d\u003d HdfsConstantsClient.GRANDFATHER_INODE_ID) {\n      // Older clients may not have given us an inode ID to work with.\n      // In this case, we have to try to resolve the path and hope it\n      // hasn\u0027t changed or been deleted since the file was opened for write.\n      iip \u003d dir.getINodesInPath4Write(src);\n      inode \u003d iip.getLastINode();\n    } else {\n      // Newer clients pass the inode ID, so we can just get the inode\n      // directly.\n      inode \u003d dir.getInode(fileId);\n      iip \u003d INodesInPath.fromINode(inode);\n      if (inode !\u003d null) {\n        src \u003d iip.getPath();\n      }\n    }\n    final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n    BlockInfoContiguous lastBlockInFile \u003d pendingFile.getLastBlock();\n    if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n      // The block that the client claims is the current last block\n      // doesn\u0027t match up with what we think is the last block. There are\n      // four possibilities:\n      // 1) This is the first block allocation of an append() pipeline\n      //    which started appending exactly at or exceeding the block boundary.\n      //    In this case, the client isn\u0027t passed the previous block,\n      //    so it makes the allocateBlock() call with previous\u003dnull.\n      //    We can distinguish this since the last block of the file\n      //    will be exactly a full block.\n      // 2) This is a retry from a client that missed the response of a\n      //    prior getAdditionalBlock() call, perhaps because of a network\n      //    timeout, or because of an HA failover. In that case, we know\n      //    by the fact that the client is re-issuing the RPC that it\n      //    never began to write to the old block. Hence it is safe to\n      //    to return the existing block.\n      // 3) This is an entirely bogus request/bug -- we should error out\n      //    rather than potentially appending a new block with an empty\n      //    one in the middle, etc\n      // 4) This is a retry from a client that timed out while\n      //    the prior getAdditionalBlock() is still being processed,\n      //    currently working on chooseTarget(). \n      //    There are no means to distinguish between the first and \n      //    the second attempts in Part I, because the first one hasn\u0027t\n      //    changed the namesystem state yet.\n      //    We run this analysis again in Part II where case 4 is impossible.\n\n      BlockInfoContiguous penultimateBlock \u003d pendingFile.getPenultimateBlock();\n      if (previous \u003d\u003d null \u0026\u0026\n          lastBlockInFile !\u003d null \u0026\u0026\n          lastBlockInFile.getNumBytes() \u003e\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n          lastBlockInFile.isComplete()) {\n        // Case 1\n        if (NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\n               \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n               \" writing to a file with a complete previous block: src\u003d\" +\n               src + \" lastBlock\u003d\" + lastBlockInFile);\n        }\n      } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n        if (lastBlockInFile.getNumBytes() !\u003d 0) {\n          throw new IOException(\n              \"Request looked like a retry to allocate block \" +\n              lastBlockInFile + \" but it already contains \" +\n              lastBlockInFile.getNumBytes() + \" bytes\");\n        }\n\n        // Case 2\n        // Return the last block.\n        NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: \" +\n            \"caught retry for allocation of a new block in \" +\n            src + \". Returning previously allocated block \" + lastBlockInFile);\n        long offset \u003d pendingFile.computeFileSize();\n        onRetryBlock[0] \u003d makeLocatedBlock(lastBlockInFile,\n            ((BlockInfoContiguousUnderConstruction)lastBlockInFile).getExpectedStorageLocations(),\n            offset);\n        return new FileState(pendingFile, src, iip);\n      } else {\n        // Case 3\n        throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n            \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n            \"last block in file \" + lastBlockInFile);\n      }\n    }\n    return new FileState(pendingFile, src, iip);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "75c545486080042952c775f7964212c15ce65f73": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8071. Redundant checkFileProgress() in PART II of getAdditionalBlock(). Contributed by Konstantin Shvachko.",
      "commitDate": "06/04/15 10:20 PM",
      "commitName": "75c545486080042952c775f7964212c15ce65f73",
      "commitAuthor": "Konstantin V Shvachko",
      "commitDateOld": "02/04/15 11:36 AM",
      "commitNameOld": "96649c38f9ab00a9845d2c6e35e6264894da5309",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 4.45,
      "commitsBetweenForRepo": 23,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,106 +1,101 @@\n   FileState analyzeFileState(String src,\n                                 long fileId,\n                                 String clientName,\n                                 ExtendedBlock previous,\n                                 LocatedBlock[] onRetryBlock)\n           throws IOException  {\n     assert hasReadLock();\n \n     checkBlock(previous);\n     onRetryBlock[0] \u003d null;\n     checkNameNodeSafeMode(\"Cannot add block to \" + src);\n \n     // have we exceeded the configured limit of fs objects.\n     checkFsObjectLimit();\n \n     Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n     final INode inode;\n     final INodesInPath iip;\n     if (fileId \u003d\u003d INodeId.GRANDFATHER_INODE_ID) {\n       // Older clients may not have given us an inode ID to work with.\n       // In this case, we have to try to resolve the path and hope it\n       // hasn\u0027t changed or been deleted since the file was opened for write.\n       iip \u003d dir.getINodesInPath4Write(src);\n       inode \u003d iip.getLastINode();\n     } else {\n       // Newer clients pass the inode ID, so we can just get the inode\n       // directly.\n       inode \u003d dir.getInode(fileId);\n       iip \u003d INodesInPath.fromINode(inode);\n       if (inode !\u003d null) {\n         src \u003d iip.getPath();\n       }\n     }\n     final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n     BlockInfoContiguous lastBlockInFile \u003d pendingFile.getLastBlock();\n     if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n       // The block that the client claims is the current last block\n       // doesn\u0027t match up with what we think is the last block. There are\n       // four possibilities:\n       // 1) This is the first block allocation of an append() pipeline\n       //    which started appending exactly at or exceeding the block boundary.\n       //    In this case, the client isn\u0027t passed the previous block,\n       //    so it makes the allocateBlock() call with previous\u003dnull.\n       //    We can distinguish this since the last block of the file\n       //    will be exactly a full block.\n       // 2) This is a retry from a client that missed the response of a\n       //    prior getAdditionalBlock() call, perhaps because of a network\n       //    timeout, or because of an HA failover. In that case, we know\n       //    by the fact that the client is re-issuing the RPC that it\n       //    never began to write to the old block. Hence it is safe to\n       //    to return the existing block.\n       // 3) This is an entirely bogus request/bug -- we should error out\n       //    rather than potentially appending a new block with an empty\n       //    one in the middle, etc\n       // 4) This is a retry from a client that timed out while\n       //    the prior getAdditionalBlock() is still being processed,\n       //    currently working on chooseTarget(). \n       //    There are no means to distinguish between the first and \n       //    the second attempts in Part I, because the first one hasn\u0027t\n       //    changed the namesystem state yet.\n       //    We run this analysis again in Part II where case 4 is impossible.\n \n       BlockInfoContiguous penultimateBlock \u003d pendingFile.getPenultimateBlock();\n       if (previous \u003d\u003d null \u0026\u0026\n           lastBlockInFile !\u003d null \u0026\u0026\n           lastBlockInFile.getNumBytes() \u003e\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n           lastBlockInFile.isComplete()) {\n         // Case 1\n         if (NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\n                \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n                \" writing to a file with a complete previous block: src\u003d\" +\n                src + \" lastBlock\u003d\" + lastBlockInFile);\n         }\n       } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n         if (lastBlockInFile.getNumBytes() !\u003d 0) {\n           throw new IOException(\n               \"Request looked like a retry to allocate block \" +\n               lastBlockInFile + \" but it already contains \" +\n               lastBlockInFile.getNumBytes() + \" bytes\");\n         }\n \n         // Case 2\n         // Return the last block.\n         NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: \" +\n             \"caught retry for allocation of a new block in \" +\n             src + \". Returning previously allocated block \" + lastBlockInFile);\n         long offset \u003d pendingFile.computeFileSize();\n         onRetryBlock[0] \u003d makeLocatedBlock(lastBlockInFile,\n             ((BlockInfoContiguousUnderConstruction)lastBlockInFile).getExpectedStorageLocations(),\n             offset);\n         return new FileState(pendingFile, src, iip);\n       } else {\n         // Case 3\n         throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n             \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n             \"last block in file \" + lastBlockInFile);\n       }\n     }\n-\n-    // Check if the penultimate block is minimally replicated\n-    if (!checkFileProgress(src, pendingFile, false)) {\n-      throw new NotReplicatedYetException(\"Not replicated yet: \" + src);\n-    }\n     return new FileState(pendingFile, src, iip);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  FileState analyzeFileState(String src,\n                                long fileId,\n                                String clientName,\n                                ExtendedBlock previous,\n                                LocatedBlock[] onRetryBlock)\n          throws IOException  {\n    assert hasReadLock();\n\n    checkBlock(previous);\n    onRetryBlock[0] \u003d null;\n    checkNameNodeSafeMode(\"Cannot add block to \" + src);\n\n    // have we exceeded the configured limit of fs objects.\n    checkFsObjectLimit();\n\n    Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n    final INode inode;\n    final INodesInPath iip;\n    if (fileId \u003d\u003d INodeId.GRANDFATHER_INODE_ID) {\n      // Older clients may not have given us an inode ID to work with.\n      // In this case, we have to try to resolve the path and hope it\n      // hasn\u0027t changed or been deleted since the file was opened for write.\n      iip \u003d dir.getINodesInPath4Write(src);\n      inode \u003d iip.getLastINode();\n    } else {\n      // Newer clients pass the inode ID, so we can just get the inode\n      // directly.\n      inode \u003d dir.getInode(fileId);\n      iip \u003d INodesInPath.fromINode(inode);\n      if (inode !\u003d null) {\n        src \u003d iip.getPath();\n      }\n    }\n    final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n    BlockInfoContiguous lastBlockInFile \u003d pendingFile.getLastBlock();\n    if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n      // The block that the client claims is the current last block\n      // doesn\u0027t match up with what we think is the last block. There are\n      // four possibilities:\n      // 1) This is the first block allocation of an append() pipeline\n      //    which started appending exactly at or exceeding the block boundary.\n      //    In this case, the client isn\u0027t passed the previous block,\n      //    so it makes the allocateBlock() call with previous\u003dnull.\n      //    We can distinguish this since the last block of the file\n      //    will be exactly a full block.\n      // 2) This is a retry from a client that missed the response of a\n      //    prior getAdditionalBlock() call, perhaps because of a network\n      //    timeout, or because of an HA failover. In that case, we know\n      //    by the fact that the client is re-issuing the RPC that it\n      //    never began to write to the old block. Hence it is safe to\n      //    to return the existing block.\n      // 3) This is an entirely bogus request/bug -- we should error out\n      //    rather than potentially appending a new block with an empty\n      //    one in the middle, etc\n      // 4) This is a retry from a client that timed out while\n      //    the prior getAdditionalBlock() is still being processed,\n      //    currently working on chooseTarget(). \n      //    There are no means to distinguish between the first and \n      //    the second attempts in Part I, because the first one hasn\u0027t\n      //    changed the namesystem state yet.\n      //    We run this analysis again in Part II where case 4 is impossible.\n\n      BlockInfoContiguous penultimateBlock \u003d pendingFile.getPenultimateBlock();\n      if (previous \u003d\u003d null \u0026\u0026\n          lastBlockInFile !\u003d null \u0026\u0026\n          lastBlockInFile.getNumBytes() \u003e\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n          lastBlockInFile.isComplete()) {\n        // Case 1\n        if (NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\n               \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n               \" writing to a file with a complete previous block: src\u003d\" +\n               src + \" lastBlock\u003d\" + lastBlockInFile);\n        }\n      } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n        if (lastBlockInFile.getNumBytes() !\u003d 0) {\n          throw new IOException(\n              \"Request looked like a retry to allocate block \" +\n              lastBlockInFile + \" but it already contains \" +\n              lastBlockInFile.getNumBytes() + \" bytes\");\n        }\n\n        // Case 2\n        // Return the last block.\n        NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: \" +\n            \"caught retry for allocation of a new block in \" +\n            src + \". Returning previously allocated block \" + lastBlockInFile);\n        long offset \u003d pendingFile.computeFileSize();\n        onRetryBlock[0] \u003d makeLocatedBlock(lastBlockInFile,\n            ((BlockInfoContiguousUnderConstruction)lastBlockInFile).getExpectedStorageLocations(),\n            offset);\n        return new FileState(pendingFile, src, iip);\n      } else {\n        // Case 3\n        throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n            \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n            \"last block in file \" + lastBlockInFile);\n      }\n    }\n    return new FileState(pendingFile, src, iip);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "c7c71cdba50cb7d8282622cd496cc913c80cff54": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7587. Edit log corruption can happen if append fails with a quota violation. Contributed by Jing Zhao.\n",
      "commitDate": "18/03/15 6:53 PM",
      "commitName": "c7c71cdba50cb7d8282622cd496cc913c80cff54",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "13/03/15 10:42 AM",
      "commitNameOld": "f446669afb5c3d31a00c65449f27088b39e11ae3",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 5.34,
      "commitsBetweenForRepo": 58,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,106 +1,106 @@\n   FileState analyzeFileState(String src,\n                                 long fileId,\n                                 String clientName,\n                                 ExtendedBlock previous,\n                                 LocatedBlock[] onRetryBlock)\n           throws IOException  {\n     assert hasReadLock();\n \n     checkBlock(previous);\n     onRetryBlock[0] \u003d null;\n     checkNameNodeSafeMode(\"Cannot add block to \" + src);\n \n     // have we exceeded the configured limit of fs objects.\n     checkFsObjectLimit();\n \n     Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n     final INode inode;\n     final INodesInPath iip;\n     if (fileId \u003d\u003d INodeId.GRANDFATHER_INODE_ID) {\n       // Older clients may not have given us an inode ID to work with.\n       // In this case, we have to try to resolve the path and hope it\n       // hasn\u0027t changed or been deleted since the file was opened for write.\n       iip \u003d dir.getINodesInPath4Write(src);\n       inode \u003d iip.getLastINode();\n     } else {\n       // Newer clients pass the inode ID, so we can just get the inode\n       // directly.\n       inode \u003d dir.getInode(fileId);\n       iip \u003d INodesInPath.fromINode(inode);\n       if (inode !\u003d null) {\n         src \u003d iip.getPath();\n       }\n     }\n     final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n     BlockInfoContiguous lastBlockInFile \u003d pendingFile.getLastBlock();\n     if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n       // The block that the client claims is the current last block\n       // doesn\u0027t match up with what we think is the last block. There are\n       // four possibilities:\n       // 1) This is the first block allocation of an append() pipeline\n-      //    which started appending exactly at a block boundary.\n+      //    which started appending exactly at or exceeding the block boundary.\n       //    In this case, the client isn\u0027t passed the previous block,\n       //    so it makes the allocateBlock() call with previous\u003dnull.\n       //    We can distinguish this since the last block of the file\n       //    will be exactly a full block.\n       // 2) This is a retry from a client that missed the response of a\n       //    prior getAdditionalBlock() call, perhaps because of a network\n       //    timeout, or because of an HA failover. In that case, we know\n       //    by the fact that the client is re-issuing the RPC that it\n       //    never began to write to the old block. Hence it is safe to\n       //    to return the existing block.\n       // 3) This is an entirely bogus request/bug -- we should error out\n       //    rather than potentially appending a new block with an empty\n       //    one in the middle, etc\n       // 4) This is a retry from a client that timed out while\n       //    the prior getAdditionalBlock() is still being processed,\n       //    currently working on chooseTarget(). \n       //    There are no means to distinguish between the first and \n       //    the second attempts in Part I, because the first one hasn\u0027t\n       //    changed the namesystem state yet.\n       //    We run this analysis again in Part II where case 4 is impossible.\n \n       BlockInfoContiguous penultimateBlock \u003d pendingFile.getPenultimateBlock();\n       if (previous \u003d\u003d null \u0026\u0026\n           lastBlockInFile !\u003d null \u0026\u0026\n-          lastBlockInFile.getNumBytes() \u003d\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n+          lastBlockInFile.getNumBytes() \u003e\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n           lastBlockInFile.isComplete()) {\n         // Case 1\n         if (NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\n                \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n                \" writing to a file with a complete previous block: src\u003d\" +\n                src + \" lastBlock\u003d\" + lastBlockInFile);\n         }\n       } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n         if (lastBlockInFile.getNumBytes() !\u003d 0) {\n           throw new IOException(\n               \"Request looked like a retry to allocate block \" +\n               lastBlockInFile + \" but it already contains \" +\n               lastBlockInFile.getNumBytes() + \" bytes\");\n         }\n \n         // Case 2\n         // Return the last block.\n         NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: \" +\n             \"caught retry for allocation of a new block in \" +\n             src + \". Returning previously allocated block \" + lastBlockInFile);\n         long offset \u003d pendingFile.computeFileSize();\n         onRetryBlock[0] \u003d makeLocatedBlock(lastBlockInFile,\n             ((BlockInfoContiguousUnderConstruction)lastBlockInFile).getExpectedStorageLocations(),\n             offset);\n         return new FileState(pendingFile, src, iip);\n       } else {\n         // Case 3\n         throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n             \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n             \"last block in file \" + lastBlockInFile);\n       }\n     }\n \n     // Check if the penultimate block is minimally replicated\n     if (!checkFileProgress(src, pendingFile, false)) {\n       throw new NotReplicatedYetException(\"Not replicated yet: \" + src);\n     }\n     return new FileState(pendingFile, src, iip);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  FileState analyzeFileState(String src,\n                                long fileId,\n                                String clientName,\n                                ExtendedBlock previous,\n                                LocatedBlock[] onRetryBlock)\n          throws IOException  {\n    assert hasReadLock();\n\n    checkBlock(previous);\n    onRetryBlock[0] \u003d null;\n    checkNameNodeSafeMode(\"Cannot add block to \" + src);\n\n    // have we exceeded the configured limit of fs objects.\n    checkFsObjectLimit();\n\n    Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n    final INode inode;\n    final INodesInPath iip;\n    if (fileId \u003d\u003d INodeId.GRANDFATHER_INODE_ID) {\n      // Older clients may not have given us an inode ID to work with.\n      // In this case, we have to try to resolve the path and hope it\n      // hasn\u0027t changed or been deleted since the file was opened for write.\n      iip \u003d dir.getINodesInPath4Write(src);\n      inode \u003d iip.getLastINode();\n    } else {\n      // Newer clients pass the inode ID, so we can just get the inode\n      // directly.\n      inode \u003d dir.getInode(fileId);\n      iip \u003d INodesInPath.fromINode(inode);\n      if (inode !\u003d null) {\n        src \u003d iip.getPath();\n      }\n    }\n    final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n    BlockInfoContiguous lastBlockInFile \u003d pendingFile.getLastBlock();\n    if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n      // The block that the client claims is the current last block\n      // doesn\u0027t match up with what we think is the last block. There are\n      // four possibilities:\n      // 1) This is the first block allocation of an append() pipeline\n      //    which started appending exactly at or exceeding the block boundary.\n      //    In this case, the client isn\u0027t passed the previous block,\n      //    so it makes the allocateBlock() call with previous\u003dnull.\n      //    We can distinguish this since the last block of the file\n      //    will be exactly a full block.\n      // 2) This is a retry from a client that missed the response of a\n      //    prior getAdditionalBlock() call, perhaps because of a network\n      //    timeout, or because of an HA failover. In that case, we know\n      //    by the fact that the client is re-issuing the RPC that it\n      //    never began to write to the old block. Hence it is safe to\n      //    to return the existing block.\n      // 3) This is an entirely bogus request/bug -- we should error out\n      //    rather than potentially appending a new block with an empty\n      //    one in the middle, etc\n      // 4) This is a retry from a client that timed out while\n      //    the prior getAdditionalBlock() is still being processed,\n      //    currently working on chooseTarget(). \n      //    There are no means to distinguish between the first and \n      //    the second attempts in Part I, because the first one hasn\u0027t\n      //    changed the namesystem state yet.\n      //    We run this analysis again in Part II where case 4 is impossible.\n\n      BlockInfoContiguous penultimateBlock \u003d pendingFile.getPenultimateBlock();\n      if (previous \u003d\u003d null \u0026\u0026\n          lastBlockInFile !\u003d null \u0026\u0026\n          lastBlockInFile.getNumBytes() \u003e\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n          lastBlockInFile.isComplete()) {\n        // Case 1\n        if (NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\n               \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n               \" writing to a file with a complete previous block: src\u003d\" +\n               src + \" lastBlock\u003d\" + lastBlockInFile);\n        }\n      } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n        if (lastBlockInFile.getNumBytes() !\u003d 0) {\n          throw new IOException(\n              \"Request looked like a retry to allocate block \" +\n              lastBlockInFile + \" but it already contains \" +\n              lastBlockInFile.getNumBytes() + \" bytes\");\n        }\n\n        // Case 2\n        // Return the last block.\n        NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: \" +\n            \"caught retry for allocation of a new block in \" +\n            src + \". Returning previously allocated block \" + lastBlockInFile);\n        long offset \u003d pendingFile.computeFileSize();\n        onRetryBlock[0] \u003d makeLocatedBlock(lastBlockInFile,\n            ((BlockInfoContiguousUnderConstruction)lastBlockInFile).getExpectedStorageLocations(),\n            offset);\n        return new FileState(pendingFile, src, iip);\n      } else {\n        // Case 3\n        throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n            \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n            \"last block in file \" + lastBlockInFile);\n      }\n    }\n\n    // Check if the penultimate block is minimally replicated\n    if (!checkFileProgress(src, pendingFile, false)) {\n      throw new NotReplicatedYetException(\"Not replicated yet: \" + src);\n    }\n    return new FileState(pendingFile, src, iip);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "1382ae525c67bf95d8f3a436b547dbc72cfbb177": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7743. Code cleanup of BlockInfo and rename BlockInfo to BlockInfoContiguous. Contributed by Jing Zhao.\n",
      "commitDate": "08/02/15 11:51 AM",
      "commitName": "1382ae525c67bf95d8f3a436b547dbc72cfbb177",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "07/02/15 3:21 PM",
      "commitNameOld": "8f7d4bb09f760780dd193c97796ebf4d22cfd2d7",
      "commitAuthorOld": "Tsz-Wo Nicholas Sze",
      "daysBetweenCommits": 0.85,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,106 +1,106 @@\n   FileState analyzeFileState(String src,\n                                 long fileId,\n                                 String clientName,\n                                 ExtendedBlock previous,\n                                 LocatedBlock[] onRetryBlock)\n           throws IOException  {\n     assert hasReadLock();\n \n     checkBlock(previous);\n     onRetryBlock[0] \u003d null;\n     checkNameNodeSafeMode(\"Cannot add block to \" + src);\n \n     // have we exceeded the configured limit of fs objects.\n     checkFsObjectLimit();\n \n     Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n     final INode inode;\n     final INodesInPath iip;\n     if (fileId \u003d\u003d INodeId.GRANDFATHER_INODE_ID) {\n       // Older clients may not have given us an inode ID to work with.\n       // In this case, we have to try to resolve the path and hope it\n       // hasn\u0027t changed or been deleted since the file was opened for write.\n       iip \u003d dir.getINodesInPath4Write(src);\n       inode \u003d iip.getLastINode();\n     } else {\n       // Newer clients pass the inode ID, so we can just get the inode\n       // directly.\n       inode \u003d dir.getInode(fileId);\n       iip \u003d INodesInPath.fromINode(inode);\n       if (inode !\u003d null) {\n         src \u003d iip.getPath();\n       }\n     }\n     final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n-    BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n+    BlockInfoContiguous lastBlockInFile \u003d pendingFile.getLastBlock();\n     if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n       // The block that the client claims is the current last block\n       // doesn\u0027t match up with what we think is the last block. There are\n       // four possibilities:\n       // 1) This is the first block allocation of an append() pipeline\n       //    which started appending exactly at a block boundary.\n       //    In this case, the client isn\u0027t passed the previous block,\n       //    so it makes the allocateBlock() call with previous\u003dnull.\n       //    We can distinguish this since the last block of the file\n       //    will be exactly a full block.\n       // 2) This is a retry from a client that missed the response of a\n       //    prior getAdditionalBlock() call, perhaps because of a network\n       //    timeout, or because of an HA failover. In that case, we know\n       //    by the fact that the client is re-issuing the RPC that it\n       //    never began to write to the old block. Hence it is safe to\n       //    to return the existing block.\n       // 3) This is an entirely bogus request/bug -- we should error out\n       //    rather than potentially appending a new block with an empty\n       //    one in the middle, etc\n       // 4) This is a retry from a client that timed out while\n       //    the prior getAdditionalBlock() is still being processed,\n       //    currently working on chooseTarget(). \n       //    There are no means to distinguish between the first and \n       //    the second attempts in Part I, because the first one hasn\u0027t\n       //    changed the namesystem state yet.\n       //    We run this analysis again in Part II where case 4 is impossible.\n \n-      BlockInfo penultimateBlock \u003d pendingFile.getPenultimateBlock();\n+      BlockInfoContiguous penultimateBlock \u003d pendingFile.getPenultimateBlock();\n       if (previous \u003d\u003d null \u0026\u0026\n           lastBlockInFile !\u003d null \u0026\u0026\n           lastBlockInFile.getNumBytes() \u003d\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n           lastBlockInFile.isComplete()) {\n         // Case 1\n         if (NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\n                \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n                \" writing to a file with a complete previous block: src\u003d\" +\n                src + \" lastBlock\u003d\" + lastBlockInFile);\n         }\n       } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n         if (lastBlockInFile.getNumBytes() !\u003d 0) {\n           throw new IOException(\n               \"Request looked like a retry to allocate block \" +\n               lastBlockInFile + \" but it already contains \" +\n               lastBlockInFile.getNumBytes() + \" bytes\");\n         }\n \n         // Case 2\n         // Return the last block.\n         NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: \" +\n             \"caught retry for allocation of a new block in \" +\n             src + \". Returning previously allocated block \" + lastBlockInFile);\n         long offset \u003d pendingFile.computeFileSize();\n         onRetryBlock[0] \u003d makeLocatedBlock(lastBlockInFile,\n-            ((BlockInfoUnderConstruction)lastBlockInFile).getExpectedStorageLocations(),\n+            ((BlockInfoContiguousUnderConstruction)lastBlockInFile).getExpectedStorageLocations(),\n             offset);\n         return new FileState(pendingFile, src, iip);\n       } else {\n         // Case 3\n         throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n             \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n             \"last block in file \" + lastBlockInFile);\n       }\n     }\n \n     // Check if the penultimate block is minimally replicated\n     if (!checkFileProgress(src, pendingFile, false)) {\n       throw new NotReplicatedYetException(\"Not replicated yet: \" + src);\n     }\n     return new FileState(pendingFile, src, iip);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  FileState analyzeFileState(String src,\n                                long fileId,\n                                String clientName,\n                                ExtendedBlock previous,\n                                LocatedBlock[] onRetryBlock)\n          throws IOException  {\n    assert hasReadLock();\n\n    checkBlock(previous);\n    onRetryBlock[0] \u003d null;\n    checkNameNodeSafeMode(\"Cannot add block to \" + src);\n\n    // have we exceeded the configured limit of fs objects.\n    checkFsObjectLimit();\n\n    Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n    final INode inode;\n    final INodesInPath iip;\n    if (fileId \u003d\u003d INodeId.GRANDFATHER_INODE_ID) {\n      // Older clients may not have given us an inode ID to work with.\n      // In this case, we have to try to resolve the path and hope it\n      // hasn\u0027t changed or been deleted since the file was opened for write.\n      iip \u003d dir.getINodesInPath4Write(src);\n      inode \u003d iip.getLastINode();\n    } else {\n      // Newer clients pass the inode ID, so we can just get the inode\n      // directly.\n      inode \u003d dir.getInode(fileId);\n      iip \u003d INodesInPath.fromINode(inode);\n      if (inode !\u003d null) {\n        src \u003d iip.getPath();\n      }\n    }\n    final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n    BlockInfoContiguous lastBlockInFile \u003d pendingFile.getLastBlock();\n    if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n      // The block that the client claims is the current last block\n      // doesn\u0027t match up with what we think is the last block. There are\n      // four possibilities:\n      // 1) This is the first block allocation of an append() pipeline\n      //    which started appending exactly at a block boundary.\n      //    In this case, the client isn\u0027t passed the previous block,\n      //    so it makes the allocateBlock() call with previous\u003dnull.\n      //    We can distinguish this since the last block of the file\n      //    will be exactly a full block.\n      // 2) This is a retry from a client that missed the response of a\n      //    prior getAdditionalBlock() call, perhaps because of a network\n      //    timeout, or because of an HA failover. In that case, we know\n      //    by the fact that the client is re-issuing the RPC that it\n      //    never began to write to the old block. Hence it is safe to\n      //    to return the existing block.\n      // 3) This is an entirely bogus request/bug -- we should error out\n      //    rather than potentially appending a new block with an empty\n      //    one in the middle, etc\n      // 4) This is a retry from a client that timed out while\n      //    the prior getAdditionalBlock() is still being processed,\n      //    currently working on chooseTarget(). \n      //    There are no means to distinguish between the first and \n      //    the second attempts in Part I, because the first one hasn\u0027t\n      //    changed the namesystem state yet.\n      //    We run this analysis again in Part II where case 4 is impossible.\n\n      BlockInfoContiguous penultimateBlock \u003d pendingFile.getPenultimateBlock();\n      if (previous \u003d\u003d null \u0026\u0026\n          lastBlockInFile !\u003d null \u0026\u0026\n          lastBlockInFile.getNumBytes() \u003d\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n          lastBlockInFile.isComplete()) {\n        // Case 1\n        if (NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\n               \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n               \" writing to a file with a complete previous block: src\u003d\" +\n               src + \" lastBlock\u003d\" + lastBlockInFile);\n        }\n      } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n        if (lastBlockInFile.getNumBytes() !\u003d 0) {\n          throw new IOException(\n              \"Request looked like a retry to allocate block \" +\n              lastBlockInFile + \" but it already contains \" +\n              lastBlockInFile.getNumBytes() + \" bytes\");\n        }\n\n        // Case 2\n        // Return the last block.\n        NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: \" +\n            \"caught retry for allocation of a new block in \" +\n            src + \". Returning previously allocated block \" + lastBlockInFile);\n        long offset \u003d pendingFile.computeFileSize();\n        onRetryBlock[0] \u003d makeLocatedBlock(lastBlockInFile,\n            ((BlockInfoContiguousUnderConstruction)lastBlockInFile).getExpectedStorageLocations(),\n            offset);\n        return new FileState(pendingFile, src, iip);\n      } else {\n        // Case 3\n        throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n            \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n            \"last block in file \" + lastBlockInFile);\n      }\n    }\n\n    // Check if the penultimate block is minimally replicated\n    if (!checkFileProgress(src, pendingFile, false)) {\n      throw new NotReplicatedYetException(\"Not replicated yet: \" + src);\n    }\n    return new FileState(pendingFile, src, iip);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "c78e3a7cdd10c40454e9acb06986ba6d8573cb19": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7059. Avoid resolving path multiple times. Contributed by Jing Zhao.\n",
      "commitDate": "12/12/14 3:13 PM",
      "commitName": "c78e3a7cdd10c40454e9acb06986ba6d8573cb19",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "12/12/14 11:51 AM",
      "commitNameOld": "46612c7a5135d20b20403780b47dd00654aab057",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 0.14,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,102 +1,106 @@\n   FileState analyzeFileState(String src,\n                                 long fileId,\n                                 String clientName,\n                                 ExtendedBlock previous,\n                                 LocatedBlock[] onRetryBlock)\n           throws IOException  {\n     assert hasReadLock();\n \n     checkBlock(previous);\n     onRetryBlock[0] \u003d null;\n     checkNameNodeSafeMode(\"Cannot add block to \" + src);\n \n     // have we exceeded the configured limit of fs objects.\n     checkFsObjectLimit();\n \n     Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n-    INode inode;\n+    final INode inode;\n+    final INodesInPath iip;\n     if (fileId \u003d\u003d INodeId.GRANDFATHER_INODE_ID) {\n       // Older clients may not have given us an inode ID to work with.\n       // In this case, we have to try to resolve the path and hope it\n       // hasn\u0027t changed or been deleted since the file was opened for write.\n-      final INodesInPath iip \u003d dir.getINodesInPath4Write(src);\n+      iip \u003d dir.getINodesInPath4Write(src);\n       inode \u003d iip.getLastINode();\n     } else {\n       // Newer clients pass the inode ID, so we can just get the inode\n       // directly.\n       inode \u003d dir.getInode(fileId);\n-      if (inode !\u003d null) src \u003d inode.getFullPathName();\n+      iip \u003d INodesInPath.fromINode(inode);\n+      if (inode !\u003d null) {\n+        src \u003d iip.getPath();\n+      }\n     }\n     final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n     BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n     if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n       // The block that the client claims is the current last block\n       // doesn\u0027t match up with what we think is the last block. There are\n       // four possibilities:\n       // 1) This is the first block allocation of an append() pipeline\n       //    which started appending exactly at a block boundary.\n       //    In this case, the client isn\u0027t passed the previous block,\n       //    so it makes the allocateBlock() call with previous\u003dnull.\n       //    We can distinguish this since the last block of the file\n       //    will be exactly a full block.\n       // 2) This is a retry from a client that missed the response of a\n       //    prior getAdditionalBlock() call, perhaps because of a network\n       //    timeout, or because of an HA failover. In that case, we know\n       //    by the fact that the client is re-issuing the RPC that it\n       //    never began to write to the old block. Hence it is safe to\n       //    to return the existing block.\n       // 3) This is an entirely bogus request/bug -- we should error out\n       //    rather than potentially appending a new block with an empty\n       //    one in the middle, etc\n       // 4) This is a retry from a client that timed out while\n       //    the prior getAdditionalBlock() is still being processed,\n       //    currently working on chooseTarget(). \n       //    There are no means to distinguish between the first and \n       //    the second attempts in Part I, because the first one hasn\u0027t\n       //    changed the namesystem state yet.\n       //    We run this analysis again in Part II where case 4 is impossible.\n \n       BlockInfo penultimateBlock \u003d pendingFile.getPenultimateBlock();\n       if (previous \u003d\u003d null \u0026\u0026\n           lastBlockInFile !\u003d null \u0026\u0026\n           lastBlockInFile.getNumBytes() \u003d\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n           lastBlockInFile.isComplete()) {\n         // Case 1\n         if (NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\n                \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n                \" writing to a file with a complete previous block: src\u003d\" +\n                src + \" lastBlock\u003d\" + lastBlockInFile);\n         }\n       } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n         if (lastBlockInFile.getNumBytes() !\u003d 0) {\n           throw new IOException(\n               \"Request looked like a retry to allocate block \" +\n               lastBlockInFile + \" but it already contains \" +\n               lastBlockInFile.getNumBytes() + \" bytes\");\n         }\n \n         // Case 2\n         // Return the last block.\n         NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: \" +\n             \"caught retry for allocation of a new block in \" +\n             src + \". Returning previously allocated block \" + lastBlockInFile);\n         long offset \u003d pendingFile.computeFileSize();\n         onRetryBlock[0] \u003d makeLocatedBlock(lastBlockInFile,\n             ((BlockInfoUnderConstruction)lastBlockInFile).getExpectedStorageLocations(),\n             offset);\n-        return new FileState(pendingFile, src);\n+        return new FileState(pendingFile, src, iip);\n       } else {\n         // Case 3\n         throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n             \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n             \"last block in file \" + lastBlockInFile);\n       }\n     }\n \n     // Check if the penultimate block is minimally replicated\n     if (!checkFileProgress(src, pendingFile, false)) {\n       throw new NotReplicatedYetException(\"Not replicated yet: \" + src);\n     }\n-    return new FileState(pendingFile, src);\n+    return new FileState(pendingFile, src, iip);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  FileState analyzeFileState(String src,\n                                long fileId,\n                                String clientName,\n                                ExtendedBlock previous,\n                                LocatedBlock[] onRetryBlock)\n          throws IOException  {\n    assert hasReadLock();\n\n    checkBlock(previous);\n    onRetryBlock[0] \u003d null;\n    checkNameNodeSafeMode(\"Cannot add block to \" + src);\n\n    // have we exceeded the configured limit of fs objects.\n    checkFsObjectLimit();\n\n    Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n    final INode inode;\n    final INodesInPath iip;\n    if (fileId \u003d\u003d INodeId.GRANDFATHER_INODE_ID) {\n      // Older clients may not have given us an inode ID to work with.\n      // In this case, we have to try to resolve the path and hope it\n      // hasn\u0027t changed or been deleted since the file was opened for write.\n      iip \u003d dir.getINodesInPath4Write(src);\n      inode \u003d iip.getLastINode();\n    } else {\n      // Newer clients pass the inode ID, so we can just get the inode\n      // directly.\n      inode \u003d dir.getInode(fileId);\n      iip \u003d INodesInPath.fromINode(inode);\n      if (inode !\u003d null) {\n        src \u003d iip.getPath();\n      }\n    }\n    final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n    BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n    if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n      // The block that the client claims is the current last block\n      // doesn\u0027t match up with what we think is the last block. There are\n      // four possibilities:\n      // 1) This is the first block allocation of an append() pipeline\n      //    which started appending exactly at a block boundary.\n      //    In this case, the client isn\u0027t passed the previous block,\n      //    so it makes the allocateBlock() call with previous\u003dnull.\n      //    We can distinguish this since the last block of the file\n      //    will be exactly a full block.\n      // 2) This is a retry from a client that missed the response of a\n      //    prior getAdditionalBlock() call, perhaps because of a network\n      //    timeout, or because of an HA failover. In that case, we know\n      //    by the fact that the client is re-issuing the RPC that it\n      //    never began to write to the old block. Hence it is safe to\n      //    to return the existing block.\n      // 3) This is an entirely bogus request/bug -- we should error out\n      //    rather than potentially appending a new block with an empty\n      //    one in the middle, etc\n      // 4) This is a retry from a client that timed out while\n      //    the prior getAdditionalBlock() is still being processed,\n      //    currently working on chooseTarget(). \n      //    There are no means to distinguish between the first and \n      //    the second attempts in Part I, because the first one hasn\u0027t\n      //    changed the namesystem state yet.\n      //    We run this analysis again in Part II where case 4 is impossible.\n\n      BlockInfo penultimateBlock \u003d pendingFile.getPenultimateBlock();\n      if (previous \u003d\u003d null \u0026\u0026\n          lastBlockInFile !\u003d null \u0026\u0026\n          lastBlockInFile.getNumBytes() \u003d\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n          lastBlockInFile.isComplete()) {\n        // Case 1\n        if (NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\n               \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n               \" writing to a file with a complete previous block: src\u003d\" +\n               src + \" lastBlock\u003d\" + lastBlockInFile);\n        }\n      } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n        if (lastBlockInFile.getNumBytes() !\u003d 0) {\n          throw new IOException(\n              \"Request looked like a retry to allocate block \" +\n              lastBlockInFile + \" but it already contains \" +\n              lastBlockInFile.getNumBytes() + \" bytes\");\n        }\n\n        // Case 2\n        // Return the last block.\n        NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: \" +\n            \"caught retry for allocation of a new block in \" +\n            src + \". Returning previously allocated block \" + lastBlockInFile);\n        long offset \u003d pendingFile.computeFileSize();\n        onRetryBlock[0] \u003d makeLocatedBlock(lastBlockInFile,\n            ((BlockInfoUnderConstruction)lastBlockInFile).getExpectedStorageLocations(),\n            offset);\n        return new FileState(pendingFile, src, iip);\n      } else {\n        // Case 3\n        throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n            \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n            \"last block in file \" + lastBlockInFile);\n      }\n    }\n\n    // Check if the penultimate block is minimally replicated\n    if (!checkFileProgress(src, pendingFile, false)) {\n      throw new NotReplicatedYetException(\"Not replicated yet: \" + src);\n    }\n    return new FileState(pendingFile, src, iip);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "18312804e9c86c0ea6a259e288994fea6fa366ef": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7357. FSNamesystem.checkFileProgress should log file path. Contributed by Tsz Wo Nicholas Sze.\n",
      "commitDate": "05/11/14 10:14 AM",
      "commitName": "18312804e9c86c0ea6a259e288994fea6fa366ef",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "05/11/14 9:32 AM",
      "commitNameOld": "6e8722e49c29a19dd13e161001d2464bb1f22189",
      "commitAuthorOld": "Konstantin V Shvachko",
      "daysBetweenCommits": 0.03,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,102 +1,102 @@\n   FileState analyzeFileState(String src,\n                                 long fileId,\n                                 String clientName,\n                                 ExtendedBlock previous,\n                                 LocatedBlock[] onRetryBlock)\n           throws IOException  {\n     assert hasReadLock();\n \n     checkBlock(previous);\n     onRetryBlock[0] \u003d null;\n     checkNameNodeSafeMode(\"Cannot add block to \" + src);\n \n     // have we exceeded the configured limit of fs objects.\n     checkFsObjectLimit();\n \n     Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n     INode inode;\n     if (fileId \u003d\u003d INodeId.GRANDFATHER_INODE_ID) {\n       // Older clients may not have given us an inode ID to work with.\n       // In this case, we have to try to resolve the path and hope it\n       // hasn\u0027t changed or been deleted since the file was opened for write.\n       final INodesInPath iip \u003d dir.getINodesInPath4Write(src);\n       inode \u003d iip.getLastINode();\n     } else {\n       // Newer clients pass the inode ID, so we can just get the inode\n       // directly.\n       inode \u003d dir.getInode(fileId);\n       if (inode !\u003d null) src \u003d inode.getFullPathName();\n     }\n     final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n     BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n     if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n       // The block that the client claims is the current last block\n       // doesn\u0027t match up with what we think is the last block. There are\n       // four possibilities:\n       // 1) This is the first block allocation of an append() pipeline\n       //    which started appending exactly at a block boundary.\n       //    In this case, the client isn\u0027t passed the previous block,\n       //    so it makes the allocateBlock() call with previous\u003dnull.\n       //    We can distinguish this since the last block of the file\n       //    will be exactly a full block.\n       // 2) This is a retry from a client that missed the response of a\n       //    prior getAdditionalBlock() call, perhaps because of a network\n       //    timeout, or because of an HA failover. In that case, we know\n       //    by the fact that the client is re-issuing the RPC that it\n       //    never began to write to the old block. Hence it is safe to\n       //    to return the existing block.\n       // 3) This is an entirely bogus request/bug -- we should error out\n       //    rather than potentially appending a new block with an empty\n       //    one in the middle, etc\n       // 4) This is a retry from a client that timed out while\n       //    the prior getAdditionalBlock() is still being processed,\n       //    currently working on chooseTarget(). \n       //    There are no means to distinguish between the first and \n       //    the second attempts in Part I, because the first one hasn\u0027t\n       //    changed the namesystem state yet.\n       //    We run this analysis again in Part II where case 4 is impossible.\n \n       BlockInfo penultimateBlock \u003d pendingFile.getPenultimateBlock();\n       if (previous \u003d\u003d null \u0026\u0026\n           lastBlockInFile !\u003d null \u0026\u0026\n           lastBlockInFile.getNumBytes() \u003d\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n           lastBlockInFile.isComplete()) {\n         // Case 1\n         if (NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\n                \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n                \" writing to a file with a complete previous block: src\u003d\" +\n                src + \" lastBlock\u003d\" + lastBlockInFile);\n         }\n       } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n         if (lastBlockInFile.getNumBytes() !\u003d 0) {\n           throw new IOException(\n               \"Request looked like a retry to allocate block \" +\n               lastBlockInFile + \" but it already contains \" +\n               lastBlockInFile.getNumBytes() + \" bytes\");\n         }\n \n         // Case 2\n         // Return the last block.\n         NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: \" +\n             \"caught retry for allocation of a new block in \" +\n             src + \". Returning previously allocated block \" + lastBlockInFile);\n         long offset \u003d pendingFile.computeFileSize();\n         onRetryBlock[0] \u003d makeLocatedBlock(lastBlockInFile,\n             ((BlockInfoUnderConstruction)lastBlockInFile).getExpectedStorageLocations(),\n             offset);\n         return new FileState(pendingFile, src);\n       } else {\n         // Case 3\n         throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n             \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n             \"last block in file \" + lastBlockInFile);\n       }\n     }\n \n     // Check if the penultimate block is minimally replicated\n-    if (!checkFileProgress(pendingFile, false)) {\n+    if (!checkFileProgress(src, pendingFile, false)) {\n       throw new NotReplicatedYetException(\"Not replicated yet: \" + src);\n     }\n     return new FileState(pendingFile, src);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  FileState analyzeFileState(String src,\n                                long fileId,\n                                String clientName,\n                                ExtendedBlock previous,\n                                LocatedBlock[] onRetryBlock)\n          throws IOException  {\n    assert hasReadLock();\n\n    checkBlock(previous);\n    onRetryBlock[0] \u003d null;\n    checkNameNodeSafeMode(\"Cannot add block to \" + src);\n\n    // have we exceeded the configured limit of fs objects.\n    checkFsObjectLimit();\n\n    Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n    INode inode;\n    if (fileId \u003d\u003d INodeId.GRANDFATHER_INODE_ID) {\n      // Older clients may not have given us an inode ID to work with.\n      // In this case, we have to try to resolve the path and hope it\n      // hasn\u0027t changed or been deleted since the file was opened for write.\n      final INodesInPath iip \u003d dir.getINodesInPath4Write(src);\n      inode \u003d iip.getLastINode();\n    } else {\n      // Newer clients pass the inode ID, so we can just get the inode\n      // directly.\n      inode \u003d dir.getInode(fileId);\n      if (inode !\u003d null) src \u003d inode.getFullPathName();\n    }\n    final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n    BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n    if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n      // The block that the client claims is the current last block\n      // doesn\u0027t match up with what we think is the last block. There are\n      // four possibilities:\n      // 1) This is the first block allocation of an append() pipeline\n      //    which started appending exactly at a block boundary.\n      //    In this case, the client isn\u0027t passed the previous block,\n      //    so it makes the allocateBlock() call with previous\u003dnull.\n      //    We can distinguish this since the last block of the file\n      //    will be exactly a full block.\n      // 2) This is a retry from a client that missed the response of a\n      //    prior getAdditionalBlock() call, perhaps because of a network\n      //    timeout, or because of an HA failover. In that case, we know\n      //    by the fact that the client is re-issuing the RPC that it\n      //    never began to write to the old block. Hence it is safe to\n      //    to return the existing block.\n      // 3) This is an entirely bogus request/bug -- we should error out\n      //    rather than potentially appending a new block with an empty\n      //    one in the middle, etc\n      // 4) This is a retry from a client that timed out while\n      //    the prior getAdditionalBlock() is still being processed,\n      //    currently working on chooseTarget(). \n      //    There are no means to distinguish between the first and \n      //    the second attempts in Part I, because the first one hasn\u0027t\n      //    changed the namesystem state yet.\n      //    We run this analysis again in Part II where case 4 is impossible.\n\n      BlockInfo penultimateBlock \u003d pendingFile.getPenultimateBlock();\n      if (previous \u003d\u003d null \u0026\u0026\n          lastBlockInFile !\u003d null \u0026\u0026\n          lastBlockInFile.getNumBytes() \u003d\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n          lastBlockInFile.isComplete()) {\n        // Case 1\n        if (NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\n               \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n               \" writing to a file with a complete previous block: src\u003d\" +\n               src + \" lastBlock\u003d\" + lastBlockInFile);\n        }\n      } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n        if (lastBlockInFile.getNumBytes() !\u003d 0) {\n          throw new IOException(\n              \"Request looked like a retry to allocate block \" +\n              lastBlockInFile + \" but it already contains \" +\n              lastBlockInFile.getNumBytes() + \" bytes\");\n        }\n\n        // Case 2\n        // Return the last block.\n        NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: \" +\n            \"caught retry for allocation of a new block in \" +\n            src + \". Returning previously allocated block \" + lastBlockInFile);\n        long offset \u003d pendingFile.computeFileSize();\n        onRetryBlock[0] \u003d makeLocatedBlock(lastBlockInFile,\n            ((BlockInfoUnderConstruction)lastBlockInFile).getExpectedStorageLocations(),\n            offset);\n        return new FileState(pendingFile, src);\n      } else {\n        // Case 3\n        throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n            \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n            \"last block in file \" + lastBlockInFile);\n      }\n    }\n\n    // Check if the penultimate block is minimally replicated\n    if (!checkFileProgress(src, pendingFile, false)) {\n      throw new NotReplicatedYetException(\"Not replicated yet: \" + src);\n    }\n    return new FileState(pendingFile, src);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "6e8722e49c29a19dd13e161001d2464bb1f22189": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7335. Redundant checkOperation() in FSN.analyzeFileState(). Contributed by Milan Desai.",
      "commitDate": "05/11/14 9:32 AM",
      "commitName": "6e8722e49c29a19dd13e161001d2464bb1f22189",
      "commitAuthor": "Konstantin V Shvachko",
      "commitDateOld": "04/11/14 11:49 PM",
      "commitNameOld": "73e601259fed0646f115b09112995b51ffef3468",
      "commitAuthorOld": "yliu",
      "daysBetweenCommits": 0.4,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,103 +1,102 @@\n   FileState analyzeFileState(String src,\n                                 long fileId,\n                                 String clientName,\n                                 ExtendedBlock previous,\n                                 LocatedBlock[] onRetryBlock)\n           throws IOException  {\n     assert hasReadLock();\n \n     checkBlock(previous);\n     onRetryBlock[0] \u003d null;\n-    checkOperation(OperationCategory.WRITE);\n     checkNameNodeSafeMode(\"Cannot add block to \" + src);\n \n     // have we exceeded the configured limit of fs objects.\n     checkFsObjectLimit();\n \n     Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n     INode inode;\n     if (fileId \u003d\u003d INodeId.GRANDFATHER_INODE_ID) {\n       // Older clients may not have given us an inode ID to work with.\n       // In this case, we have to try to resolve the path and hope it\n       // hasn\u0027t changed or been deleted since the file was opened for write.\n       final INodesInPath iip \u003d dir.getINodesInPath4Write(src);\n       inode \u003d iip.getLastINode();\n     } else {\n       // Newer clients pass the inode ID, so we can just get the inode\n       // directly.\n       inode \u003d dir.getInode(fileId);\n       if (inode !\u003d null) src \u003d inode.getFullPathName();\n     }\n     final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n     BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n     if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n       // The block that the client claims is the current last block\n       // doesn\u0027t match up with what we think is the last block. There are\n       // four possibilities:\n       // 1) This is the first block allocation of an append() pipeline\n       //    which started appending exactly at a block boundary.\n       //    In this case, the client isn\u0027t passed the previous block,\n       //    so it makes the allocateBlock() call with previous\u003dnull.\n       //    We can distinguish this since the last block of the file\n       //    will be exactly a full block.\n       // 2) This is a retry from a client that missed the response of a\n       //    prior getAdditionalBlock() call, perhaps because of a network\n       //    timeout, or because of an HA failover. In that case, we know\n       //    by the fact that the client is re-issuing the RPC that it\n       //    never began to write to the old block. Hence it is safe to\n       //    to return the existing block.\n       // 3) This is an entirely bogus request/bug -- we should error out\n       //    rather than potentially appending a new block with an empty\n       //    one in the middle, etc\n       // 4) This is a retry from a client that timed out while\n       //    the prior getAdditionalBlock() is still being processed,\n       //    currently working on chooseTarget(). \n       //    There are no means to distinguish between the first and \n       //    the second attempts in Part I, because the first one hasn\u0027t\n       //    changed the namesystem state yet.\n       //    We run this analysis again in Part II where case 4 is impossible.\n \n       BlockInfo penultimateBlock \u003d pendingFile.getPenultimateBlock();\n       if (previous \u003d\u003d null \u0026\u0026\n           lastBlockInFile !\u003d null \u0026\u0026\n           lastBlockInFile.getNumBytes() \u003d\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n           lastBlockInFile.isComplete()) {\n         // Case 1\n         if (NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\n                \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n                \" writing to a file with a complete previous block: src\u003d\" +\n                src + \" lastBlock\u003d\" + lastBlockInFile);\n         }\n       } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n         if (lastBlockInFile.getNumBytes() !\u003d 0) {\n           throw new IOException(\n               \"Request looked like a retry to allocate block \" +\n               lastBlockInFile + \" but it already contains \" +\n               lastBlockInFile.getNumBytes() + \" bytes\");\n         }\n \n         // Case 2\n         // Return the last block.\n         NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: \" +\n             \"caught retry for allocation of a new block in \" +\n             src + \". Returning previously allocated block \" + lastBlockInFile);\n         long offset \u003d pendingFile.computeFileSize();\n         onRetryBlock[0] \u003d makeLocatedBlock(lastBlockInFile,\n             ((BlockInfoUnderConstruction)lastBlockInFile).getExpectedStorageLocations(),\n             offset);\n         return new FileState(pendingFile, src);\n       } else {\n         // Case 3\n         throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n             \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n             \"last block in file \" + lastBlockInFile);\n       }\n     }\n \n     // Check if the penultimate block is minimally replicated\n     if (!checkFileProgress(pendingFile, false)) {\n       throw new NotReplicatedYetException(\"Not replicated yet: \" + src);\n     }\n     return new FileState(pendingFile, src);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  FileState analyzeFileState(String src,\n                                long fileId,\n                                String clientName,\n                                ExtendedBlock previous,\n                                LocatedBlock[] onRetryBlock)\n          throws IOException  {\n    assert hasReadLock();\n\n    checkBlock(previous);\n    onRetryBlock[0] \u003d null;\n    checkNameNodeSafeMode(\"Cannot add block to \" + src);\n\n    // have we exceeded the configured limit of fs objects.\n    checkFsObjectLimit();\n\n    Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n    INode inode;\n    if (fileId \u003d\u003d INodeId.GRANDFATHER_INODE_ID) {\n      // Older clients may not have given us an inode ID to work with.\n      // In this case, we have to try to resolve the path and hope it\n      // hasn\u0027t changed or been deleted since the file was opened for write.\n      final INodesInPath iip \u003d dir.getINodesInPath4Write(src);\n      inode \u003d iip.getLastINode();\n    } else {\n      // Newer clients pass the inode ID, so we can just get the inode\n      // directly.\n      inode \u003d dir.getInode(fileId);\n      if (inode !\u003d null) src \u003d inode.getFullPathName();\n    }\n    final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n    BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n    if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n      // The block that the client claims is the current last block\n      // doesn\u0027t match up with what we think is the last block. There are\n      // four possibilities:\n      // 1) This is the first block allocation of an append() pipeline\n      //    which started appending exactly at a block boundary.\n      //    In this case, the client isn\u0027t passed the previous block,\n      //    so it makes the allocateBlock() call with previous\u003dnull.\n      //    We can distinguish this since the last block of the file\n      //    will be exactly a full block.\n      // 2) This is a retry from a client that missed the response of a\n      //    prior getAdditionalBlock() call, perhaps because of a network\n      //    timeout, or because of an HA failover. In that case, we know\n      //    by the fact that the client is re-issuing the RPC that it\n      //    never began to write to the old block. Hence it is safe to\n      //    to return the existing block.\n      // 3) This is an entirely bogus request/bug -- we should error out\n      //    rather than potentially appending a new block with an empty\n      //    one in the middle, etc\n      // 4) This is a retry from a client that timed out while\n      //    the prior getAdditionalBlock() is still being processed,\n      //    currently working on chooseTarget(). \n      //    There are no means to distinguish between the first and \n      //    the second attempts in Part I, because the first one hasn\u0027t\n      //    changed the namesystem state yet.\n      //    We run this analysis again in Part II where case 4 is impossible.\n\n      BlockInfo penultimateBlock \u003d pendingFile.getPenultimateBlock();\n      if (previous \u003d\u003d null \u0026\u0026\n          lastBlockInFile !\u003d null \u0026\u0026\n          lastBlockInFile.getNumBytes() \u003d\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n          lastBlockInFile.isComplete()) {\n        // Case 1\n        if (NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\n               \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n               \" writing to a file with a complete previous block: src\u003d\" +\n               src + \" lastBlock\u003d\" + lastBlockInFile);\n        }\n      } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n        if (lastBlockInFile.getNumBytes() !\u003d 0) {\n          throw new IOException(\n              \"Request looked like a retry to allocate block \" +\n              lastBlockInFile + \" but it already contains \" +\n              lastBlockInFile.getNumBytes() + \" bytes\");\n        }\n\n        // Case 2\n        // Return the last block.\n        NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: \" +\n            \"caught retry for allocation of a new block in \" +\n            src + \". Returning previously allocated block \" + lastBlockInFile);\n        long offset \u003d pendingFile.computeFileSize();\n        onRetryBlock[0] \u003d makeLocatedBlock(lastBlockInFile,\n            ((BlockInfoUnderConstruction)lastBlockInFile).getExpectedStorageLocations(),\n            offset);\n        return new FileState(pendingFile, src);\n      } else {\n        // Case 3\n        throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n            \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n            \"last block in file \" + lastBlockInFile);\n      }\n    }\n\n    // Check if the penultimate block is minimally replicated\n    if (!checkFileProgress(pendingFile, false)) {\n      throw new NotReplicatedYetException(\"Not replicated yet: \" + src);\n    }\n    return new FileState(pendingFile, src);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "d9c5f20333ef510c0ace066c0a811f9e953e9e17": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-6622. Rename and AddBlock may race and produce invalid edits (kihwal via cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1609384 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/07/14 9:03 PM",
      "commitName": "d9c5f20333ef510c0ace066c0a811f9e953e9e17",
      "commitAuthor": "Colin McCabe",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-6622. Rename and AddBlock may race and produce invalid edits (kihwal via cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1609384 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "09/07/14 9:03 PM",
          "commitName": "d9c5f20333ef510c0ace066c0a811f9e953e9e17",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "09/07/14 8:49 PM",
          "commitNameOld": "8044a12ac02cc4495935a3afded8c1d4369c1445",
          "commitAuthorOld": "Colin McCabe",
          "daysBetweenCommits": 0.01,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,103 +1,103 @@\n-  INodeFile analyzeFileState(String src,\n+  FileState analyzeFileState(String src,\n                                 long fileId,\n                                 String clientName,\n                                 ExtendedBlock previous,\n                                 LocatedBlock[] onRetryBlock)\n           throws IOException  {\n     assert hasReadLock();\n \n     checkBlock(previous);\n     onRetryBlock[0] \u003d null;\n     checkOperation(OperationCategory.WRITE);\n     checkNameNodeSafeMode(\"Cannot add block to \" + src);\n \n     // have we exceeded the configured limit of fs objects.\n     checkFsObjectLimit();\n \n     Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n     INode inode;\n     if (fileId \u003d\u003d INodeId.GRANDFATHER_INODE_ID) {\n       // Older clients may not have given us an inode ID to work with.\n       // In this case, we have to try to resolve the path and hope it\n       // hasn\u0027t changed or been deleted since the file was opened for write.\n       final INodesInPath iip \u003d dir.getINodesInPath4Write(src);\n       inode \u003d iip.getLastINode();\n     } else {\n       // Newer clients pass the inode ID, so we can just get the inode\n       // directly.\n       inode \u003d dir.getInode(fileId);\n       if (inode !\u003d null) src \u003d inode.getFullPathName();\n     }\n     final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n     BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n     if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n       // The block that the client claims is the current last block\n       // doesn\u0027t match up with what we think is the last block. There are\n       // four possibilities:\n       // 1) This is the first block allocation of an append() pipeline\n       //    which started appending exactly at a block boundary.\n       //    In this case, the client isn\u0027t passed the previous block,\n       //    so it makes the allocateBlock() call with previous\u003dnull.\n       //    We can distinguish this since the last block of the file\n       //    will be exactly a full block.\n       // 2) This is a retry from a client that missed the response of a\n       //    prior getAdditionalBlock() call, perhaps because of a network\n       //    timeout, or because of an HA failover. In that case, we know\n       //    by the fact that the client is re-issuing the RPC that it\n       //    never began to write to the old block. Hence it is safe to\n       //    to return the existing block.\n       // 3) This is an entirely bogus request/bug -- we should error out\n       //    rather than potentially appending a new block with an empty\n       //    one in the middle, etc\n       // 4) This is a retry from a client that timed out while\n       //    the prior getAdditionalBlock() is still being processed,\n       //    currently working on chooseTarget(). \n       //    There are no means to distinguish between the first and \n       //    the second attempts in Part I, because the first one hasn\u0027t\n       //    changed the namesystem state yet.\n       //    We run this analysis again in Part II where case 4 is impossible.\n \n       BlockInfo penultimateBlock \u003d pendingFile.getPenultimateBlock();\n       if (previous \u003d\u003d null \u0026\u0026\n           lastBlockInFile !\u003d null \u0026\u0026\n           lastBlockInFile.getNumBytes() \u003d\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n           lastBlockInFile.isComplete()) {\n         // Case 1\n         if (NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\n                \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n                \" writing to a file with a complete previous block: src\u003d\" +\n                src + \" lastBlock\u003d\" + lastBlockInFile);\n         }\n       } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n         if (lastBlockInFile.getNumBytes() !\u003d 0) {\n           throw new IOException(\n               \"Request looked like a retry to allocate block \" +\n               lastBlockInFile + \" but it already contains \" +\n               lastBlockInFile.getNumBytes() + \" bytes\");\n         }\n \n         // Case 2\n         // Return the last block.\n         NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: \" +\n             \"caught retry for allocation of a new block in \" +\n             src + \". Returning previously allocated block \" + lastBlockInFile);\n         long offset \u003d pendingFile.computeFileSize();\n         onRetryBlock[0] \u003d makeLocatedBlock(lastBlockInFile,\n             ((BlockInfoUnderConstruction)lastBlockInFile).getExpectedStorageLocations(),\n             offset);\n-        return pendingFile;\n+        return new FileState(pendingFile, src);\n       } else {\n         // Case 3\n         throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n             \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n             \"last block in file \" + lastBlockInFile);\n       }\n     }\n \n     // Check if the penultimate block is minimally replicated\n     if (!checkFileProgress(pendingFile, false)) {\n       throw new NotReplicatedYetException(\"Not replicated yet: \" + src);\n     }\n-    return pendingFile;\n+    return new FileState(pendingFile, src);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  FileState analyzeFileState(String src,\n                                long fileId,\n                                String clientName,\n                                ExtendedBlock previous,\n                                LocatedBlock[] onRetryBlock)\n          throws IOException  {\n    assert hasReadLock();\n\n    checkBlock(previous);\n    onRetryBlock[0] \u003d null;\n    checkOperation(OperationCategory.WRITE);\n    checkNameNodeSafeMode(\"Cannot add block to \" + src);\n\n    // have we exceeded the configured limit of fs objects.\n    checkFsObjectLimit();\n\n    Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n    INode inode;\n    if (fileId \u003d\u003d INodeId.GRANDFATHER_INODE_ID) {\n      // Older clients may not have given us an inode ID to work with.\n      // In this case, we have to try to resolve the path and hope it\n      // hasn\u0027t changed or been deleted since the file was opened for write.\n      final INodesInPath iip \u003d dir.getINodesInPath4Write(src);\n      inode \u003d iip.getLastINode();\n    } else {\n      // Newer clients pass the inode ID, so we can just get the inode\n      // directly.\n      inode \u003d dir.getInode(fileId);\n      if (inode !\u003d null) src \u003d inode.getFullPathName();\n    }\n    final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n    BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n    if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n      // The block that the client claims is the current last block\n      // doesn\u0027t match up with what we think is the last block. There are\n      // four possibilities:\n      // 1) This is the first block allocation of an append() pipeline\n      //    which started appending exactly at a block boundary.\n      //    In this case, the client isn\u0027t passed the previous block,\n      //    so it makes the allocateBlock() call with previous\u003dnull.\n      //    We can distinguish this since the last block of the file\n      //    will be exactly a full block.\n      // 2) This is a retry from a client that missed the response of a\n      //    prior getAdditionalBlock() call, perhaps because of a network\n      //    timeout, or because of an HA failover. In that case, we know\n      //    by the fact that the client is re-issuing the RPC that it\n      //    never began to write to the old block. Hence it is safe to\n      //    to return the existing block.\n      // 3) This is an entirely bogus request/bug -- we should error out\n      //    rather than potentially appending a new block with an empty\n      //    one in the middle, etc\n      // 4) This is a retry from a client that timed out while\n      //    the prior getAdditionalBlock() is still being processed,\n      //    currently working on chooseTarget(). \n      //    There are no means to distinguish between the first and \n      //    the second attempts in Part I, because the first one hasn\u0027t\n      //    changed the namesystem state yet.\n      //    We run this analysis again in Part II where case 4 is impossible.\n\n      BlockInfo penultimateBlock \u003d pendingFile.getPenultimateBlock();\n      if (previous \u003d\u003d null \u0026\u0026\n          lastBlockInFile !\u003d null \u0026\u0026\n          lastBlockInFile.getNumBytes() \u003d\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n          lastBlockInFile.isComplete()) {\n        // Case 1\n        if (NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\n               \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n               \" writing to a file with a complete previous block: src\u003d\" +\n               src + \" lastBlock\u003d\" + lastBlockInFile);\n        }\n      } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n        if (lastBlockInFile.getNumBytes() !\u003d 0) {\n          throw new IOException(\n              \"Request looked like a retry to allocate block \" +\n              lastBlockInFile + \" but it already contains \" +\n              lastBlockInFile.getNumBytes() + \" bytes\");\n        }\n\n        // Case 2\n        // Return the last block.\n        NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: \" +\n            \"caught retry for allocation of a new block in \" +\n            src + \". Returning previously allocated block \" + lastBlockInFile);\n        long offset \u003d pendingFile.computeFileSize();\n        onRetryBlock[0] \u003d makeLocatedBlock(lastBlockInFile,\n            ((BlockInfoUnderConstruction)lastBlockInFile).getExpectedStorageLocations(),\n            offset);\n        return new FileState(pendingFile, src);\n      } else {\n        // Case 3\n        throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n            \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n            \"last block in file \" + lastBlockInFile);\n      }\n    }\n\n    // Check if the penultimate block is minimally replicated\n    if (!checkFileProgress(pendingFile, false)) {\n      throw new NotReplicatedYetException(\"Not replicated yet: \" + src);\n    }\n    return new FileState(pendingFile, src);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {
            "oldValue": "INodeFile",
            "newValue": "FileState"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-6622. Rename and AddBlock may race and produce invalid edits (kihwal via cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1609384 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "09/07/14 9:03 PM",
          "commitName": "d9c5f20333ef510c0ace066c0a811f9e953e9e17",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "09/07/14 8:49 PM",
          "commitNameOld": "8044a12ac02cc4495935a3afded8c1d4369c1445",
          "commitAuthorOld": "Colin McCabe",
          "daysBetweenCommits": 0.01,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,103 +1,103 @@\n-  INodeFile analyzeFileState(String src,\n+  FileState analyzeFileState(String src,\n                                 long fileId,\n                                 String clientName,\n                                 ExtendedBlock previous,\n                                 LocatedBlock[] onRetryBlock)\n           throws IOException  {\n     assert hasReadLock();\n \n     checkBlock(previous);\n     onRetryBlock[0] \u003d null;\n     checkOperation(OperationCategory.WRITE);\n     checkNameNodeSafeMode(\"Cannot add block to \" + src);\n \n     // have we exceeded the configured limit of fs objects.\n     checkFsObjectLimit();\n \n     Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n     INode inode;\n     if (fileId \u003d\u003d INodeId.GRANDFATHER_INODE_ID) {\n       // Older clients may not have given us an inode ID to work with.\n       // In this case, we have to try to resolve the path and hope it\n       // hasn\u0027t changed or been deleted since the file was opened for write.\n       final INodesInPath iip \u003d dir.getINodesInPath4Write(src);\n       inode \u003d iip.getLastINode();\n     } else {\n       // Newer clients pass the inode ID, so we can just get the inode\n       // directly.\n       inode \u003d dir.getInode(fileId);\n       if (inode !\u003d null) src \u003d inode.getFullPathName();\n     }\n     final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n     BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n     if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n       // The block that the client claims is the current last block\n       // doesn\u0027t match up with what we think is the last block. There are\n       // four possibilities:\n       // 1) This is the first block allocation of an append() pipeline\n       //    which started appending exactly at a block boundary.\n       //    In this case, the client isn\u0027t passed the previous block,\n       //    so it makes the allocateBlock() call with previous\u003dnull.\n       //    We can distinguish this since the last block of the file\n       //    will be exactly a full block.\n       // 2) This is a retry from a client that missed the response of a\n       //    prior getAdditionalBlock() call, perhaps because of a network\n       //    timeout, or because of an HA failover. In that case, we know\n       //    by the fact that the client is re-issuing the RPC that it\n       //    never began to write to the old block. Hence it is safe to\n       //    to return the existing block.\n       // 3) This is an entirely bogus request/bug -- we should error out\n       //    rather than potentially appending a new block with an empty\n       //    one in the middle, etc\n       // 4) This is a retry from a client that timed out while\n       //    the prior getAdditionalBlock() is still being processed,\n       //    currently working on chooseTarget(). \n       //    There are no means to distinguish between the first and \n       //    the second attempts in Part I, because the first one hasn\u0027t\n       //    changed the namesystem state yet.\n       //    We run this analysis again in Part II where case 4 is impossible.\n \n       BlockInfo penultimateBlock \u003d pendingFile.getPenultimateBlock();\n       if (previous \u003d\u003d null \u0026\u0026\n           lastBlockInFile !\u003d null \u0026\u0026\n           lastBlockInFile.getNumBytes() \u003d\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n           lastBlockInFile.isComplete()) {\n         // Case 1\n         if (NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\n                \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n                \" writing to a file with a complete previous block: src\u003d\" +\n                src + \" lastBlock\u003d\" + lastBlockInFile);\n         }\n       } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n         if (lastBlockInFile.getNumBytes() !\u003d 0) {\n           throw new IOException(\n               \"Request looked like a retry to allocate block \" +\n               lastBlockInFile + \" but it already contains \" +\n               lastBlockInFile.getNumBytes() + \" bytes\");\n         }\n \n         // Case 2\n         // Return the last block.\n         NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: \" +\n             \"caught retry for allocation of a new block in \" +\n             src + \". Returning previously allocated block \" + lastBlockInFile);\n         long offset \u003d pendingFile.computeFileSize();\n         onRetryBlock[0] \u003d makeLocatedBlock(lastBlockInFile,\n             ((BlockInfoUnderConstruction)lastBlockInFile).getExpectedStorageLocations(),\n             offset);\n-        return pendingFile;\n+        return new FileState(pendingFile, src);\n       } else {\n         // Case 3\n         throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n             \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n             \"last block in file \" + lastBlockInFile);\n       }\n     }\n \n     // Check if the penultimate block is minimally replicated\n     if (!checkFileProgress(pendingFile, false)) {\n       throw new NotReplicatedYetException(\"Not replicated yet: \" + src);\n     }\n-    return pendingFile;\n+    return new FileState(pendingFile, src);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  FileState analyzeFileState(String src,\n                                long fileId,\n                                String clientName,\n                                ExtendedBlock previous,\n                                LocatedBlock[] onRetryBlock)\n          throws IOException  {\n    assert hasReadLock();\n\n    checkBlock(previous);\n    onRetryBlock[0] \u003d null;\n    checkOperation(OperationCategory.WRITE);\n    checkNameNodeSafeMode(\"Cannot add block to \" + src);\n\n    // have we exceeded the configured limit of fs objects.\n    checkFsObjectLimit();\n\n    Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n    INode inode;\n    if (fileId \u003d\u003d INodeId.GRANDFATHER_INODE_ID) {\n      // Older clients may not have given us an inode ID to work with.\n      // In this case, we have to try to resolve the path and hope it\n      // hasn\u0027t changed or been deleted since the file was opened for write.\n      final INodesInPath iip \u003d dir.getINodesInPath4Write(src);\n      inode \u003d iip.getLastINode();\n    } else {\n      // Newer clients pass the inode ID, so we can just get the inode\n      // directly.\n      inode \u003d dir.getInode(fileId);\n      if (inode !\u003d null) src \u003d inode.getFullPathName();\n    }\n    final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n    BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n    if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n      // The block that the client claims is the current last block\n      // doesn\u0027t match up with what we think is the last block. There are\n      // four possibilities:\n      // 1) This is the first block allocation of an append() pipeline\n      //    which started appending exactly at a block boundary.\n      //    In this case, the client isn\u0027t passed the previous block,\n      //    so it makes the allocateBlock() call with previous\u003dnull.\n      //    We can distinguish this since the last block of the file\n      //    will be exactly a full block.\n      // 2) This is a retry from a client that missed the response of a\n      //    prior getAdditionalBlock() call, perhaps because of a network\n      //    timeout, or because of an HA failover. In that case, we know\n      //    by the fact that the client is re-issuing the RPC that it\n      //    never began to write to the old block. Hence it is safe to\n      //    to return the existing block.\n      // 3) This is an entirely bogus request/bug -- we should error out\n      //    rather than potentially appending a new block with an empty\n      //    one in the middle, etc\n      // 4) This is a retry from a client that timed out while\n      //    the prior getAdditionalBlock() is still being processed,\n      //    currently working on chooseTarget(). \n      //    There are no means to distinguish between the first and \n      //    the second attempts in Part I, because the first one hasn\u0027t\n      //    changed the namesystem state yet.\n      //    We run this analysis again in Part II where case 4 is impossible.\n\n      BlockInfo penultimateBlock \u003d pendingFile.getPenultimateBlock();\n      if (previous \u003d\u003d null \u0026\u0026\n          lastBlockInFile !\u003d null \u0026\u0026\n          lastBlockInFile.getNumBytes() \u003d\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n          lastBlockInFile.isComplete()) {\n        // Case 1\n        if (NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\n               \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n               \" writing to a file with a complete previous block: src\u003d\" +\n               src + \" lastBlock\u003d\" + lastBlockInFile);\n        }\n      } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n        if (lastBlockInFile.getNumBytes() !\u003d 0) {\n          throw new IOException(\n              \"Request looked like a retry to allocate block \" +\n              lastBlockInFile + \" but it already contains \" +\n              lastBlockInFile.getNumBytes() + \" bytes\");\n        }\n\n        // Case 2\n        // Return the last block.\n        NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: \" +\n            \"caught retry for allocation of a new block in \" +\n            src + \". Returning previously allocated block \" + lastBlockInFile);\n        long offset \u003d pendingFile.computeFileSize();\n        onRetryBlock[0] \u003d makeLocatedBlock(lastBlockInFile,\n            ((BlockInfoUnderConstruction)lastBlockInFile).getExpectedStorageLocations(),\n            offset);\n        return new FileState(pendingFile, src);\n      } else {\n        // Case 3\n        throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n            \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n            \"last block in file \" + lastBlockInFile);\n      }\n    }\n\n    // Check if the penultimate block is minimally replicated\n    if (!checkFileProgress(pendingFile, false)) {\n      throw new NotReplicatedYetException(\"Not replicated yet: \" + src);\n    }\n    return new FileState(pendingFile, src);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {}
        }
      ]
    },
    "f131dba8a3d603a5d15c4f035ed3da75b4daf0dc": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-6294. Use INode IDs to avoid conflicts when a file open for write is renamed (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1593634 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/05/14 3:36 PM",
      "commitName": "f131dba8a3d603a5d15c4f035ed3da75b4daf0dc",
      "commitAuthor": "Colin McCabe",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-6294. Use INode IDs to avoid conflicts when a file open for write is renamed (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1593634 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "09/05/14 3:36 PM",
          "commitName": "f131dba8a3d603a5d15c4f035ed3da75b4daf0dc",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "30/04/14 10:44 AM",
          "commitNameOld": "0689363343a281a6f7f6f395227668bddc2663eb",
          "commitAuthorOld": "Haohui Mai",
          "daysBetweenCommits": 9.2,
          "commitsBetweenForRepo": 39,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,92 +1,103 @@\n-  INodesInPath analyzeFileState(String src,\n+  INodeFile analyzeFileState(String src,\n                                 long fileId,\n                                 String clientName,\n                                 ExtendedBlock previous,\n                                 LocatedBlock[] onRetryBlock)\n           throws IOException  {\n     assert hasReadLock();\n \n     checkBlock(previous);\n     onRetryBlock[0] \u003d null;\n     checkOperation(OperationCategory.WRITE);\n     checkNameNodeSafeMode(\"Cannot add block to \" + src);\n \n     // have we exceeded the configured limit of fs objects.\n     checkFsObjectLimit();\n \n     Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n-    final INodesInPath iip \u003d dir.getINodesInPath4Write(src);\n-    final INodeFile pendingFile\n-        \u003d checkLease(src, fileId, clientName, iip.getLastINode());\n+    INode inode;\n+    if (fileId \u003d\u003d INodeId.GRANDFATHER_INODE_ID) {\n+      // Older clients may not have given us an inode ID to work with.\n+      // In this case, we have to try to resolve the path and hope it\n+      // hasn\u0027t changed or been deleted since the file was opened for write.\n+      final INodesInPath iip \u003d dir.getINodesInPath4Write(src);\n+      inode \u003d iip.getLastINode();\n+    } else {\n+      // Newer clients pass the inode ID, so we can just get the inode\n+      // directly.\n+      inode \u003d dir.getInode(fileId);\n+      if (inode !\u003d null) src \u003d inode.getFullPathName();\n+    }\n+    final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n     BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n     if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n       // The block that the client claims is the current last block\n       // doesn\u0027t match up with what we think is the last block. There are\n       // four possibilities:\n       // 1) This is the first block allocation of an append() pipeline\n       //    which started appending exactly at a block boundary.\n       //    In this case, the client isn\u0027t passed the previous block,\n       //    so it makes the allocateBlock() call with previous\u003dnull.\n       //    We can distinguish this since the last block of the file\n       //    will be exactly a full block.\n       // 2) This is a retry from a client that missed the response of a\n       //    prior getAdditionalBlock() call, perhaps because of a network\n       //    timeout, or because of an HA failover. In that case, we know\n       //    by the fact that the client is re-issuing the RPC that it\n       //    never began to write to the old block. Hence it is safe to\n       //    to return the existing block.\n       // 3) This is an entirely bogus request/bug -- we should error out\n       //    rather than potentially appending a new block with an empty\n       //    one in the middle, etc\n       // 4) This is a retry from a client that timed out while\n       //    the prior getAdditionalBlock() is still being processed,\n       //    currently working on chooseTarget(). \n       //    There are no means to distinguish between the first and \n       //    the second attempts in Part I, because the first one hasn\u0027t\n       //    changed the namesystem state yet.\n       //    We run this analysis again in Part II where case 4 is impossible.\n \n       BlockInfo penultimateBlock \u003d pendingFile.getPenultimateBlock();\n       if (previous \u003d\u003d null \u0026\u0026\n           lastBlockInFile !\u003d null \u0026\u0026\n           lastBlockInFile.getNumBytes() \u003d\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n           lastBlockInFile.isComplete()) {\n         // Case 1\n         if (NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\n                \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n                \" writing to a file with a complete previous block: src\u003d\" +\n                src + \" lastBlock\u003d\" + lastBlockInFile);\n         }\n       } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n         if (lastBlockInFile.getNumBytes() !\u003d 0) {\n           throw new IOException(\n               \"Request looked like a retry to allocate block \" +\n               lastBlockInFile + \" but it already contains \" +\n               lastBlockInFile.getNumBytes() + \" bytes\");\n         }\n \n         // Case 2\n         // Return the last block.\n         NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: \" +\n             \"caught retry for allocation of a new block in \" +\n             src + \". Returning previously allocated block \" + lastBlockInFile);\n         long offset \u003d pendingFile.computeFileSize();\n         onRetryBlock[0] \u003d makeLocatedBlock(lastBlockInFile,\n             ((BlockInfoUnderConstruction)lastBlockInFile).getExpectedStorageLocations(),\n             offset);\n-        return iip;\n+        return pendingFile;\n       } else {\n         // Case 3\n         throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n             \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n             \"last block in file \" + lastBlockInFile);\n       }\n     }\n \n     // Check if the penultimate block is minimally replicated\n     if (!checkFileProgress(pendingFile, false)) {\n       throw new NotReplicatedYetException(\"Not replicated yet: \" + src);\n     }\n-    return iip;\n+    return pendingFile;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  INodeFile analyzeFileState(String src,\n                                long fileId,\n                                String clientName,\n                                ExtendedBlock previous,\n                                LocatedBlock[] onRetryBlock)\n          throws IOException  {\n    assert hasReadLock();\n\n    checkBlock(previous);\n    onRetryBlock[0] \u003d null;\n    checkOperation(OperationCategory.WRITE);\n    checkNameNodeSafeMode(\"Cannot add block to \" + src);\n\n    // have we exceeded the configured limit of fs objects.\n    checkFsObjectLimit();\n\n    Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n    INode inode;\n    if (fileId \u003d\u003d INodeId.GRANDFATHER_INODE_ID) {\n      // Older clients may not have given us an inode ID to work with.\n      // In this case, we have to try to resolve the path and hope it\n      // hasn\u0027t changed or been deleted since the file was opened for write.\n      final INodesInPath iip \u003d dir.getINodesInPath4Write(src);\n      inode \u003d iip.getLastINode();\n    } else {\n      // Newer clients pass the inode ID, so we can just get the inode\n      // directly.\n      inode \u003d dir.getInode(fileId);\n      if (inode !\u003d null) src \u003d inode.getFullPathName();\n    }\n    final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n    BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n    if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n      // The block that the client claims is the current last block\n      // doesn\u0027t match up with what we think is the last block. There are\n      // four possibilities:\n      // 1) This is the first block allocation of an append() pipeline\n      //    which started appending exactly at a block boundary.\n      //    In this case, the client isn\u0027t passed the previous block,\n      //    so it makes the allocateBlock() call with previous\u003dnull.\n      //    We can distinguish this since the last block of the file\n      //    will be exactly a full block.\n      // 2) This is a retry from a client that missed the response of a\n      //    prior getAdditionalBlock() call, perhaps because of a network\n      //    timeout, or because of an HA failover. In that case, we know\n      //    by the fact that the client is re-issuing the RPC that it\n      //    never began to write to the old block. Hence it is safe to\n      //    to return the existing block.\n      // 3) This is an entirely bogus request/bug -- we should error out\n      //    rather than potentially appending a new block with an empty\n      //    one in the middle, etc\n      // 4) This is a retry from a client that timed out while\n      //    the prior getAdditionalBlock() is still being processed,\n      //    currently working on chooseTarget(). \n      //    There are no means to distinguish between the first and \n      //    the second attempts in Part I, because the first one hasn\u0027t\n      //    changed the namesystem state yet.\n      //    We run this analysis again in Part II where case 4 is impossible.\n\n      BlockInfo penultimateBlock \u003d pendingFile.getPenultimateBlock();\n      if (previous \u003d\u003d null \u0026\u0026\n          lastBlockInFile !\u003d null \u0026\u0026\n          lastBlockInFile.getNumBytes() \u003d\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n          lastBlockInFile.isComplete()) {\n        // Case 1\n        if (NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\n               \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n               \" writing to a file with a complete previous block: src\u003d\" +\n               src + \" lastBlock\u003d\" + lastBlockInFile);\n        }\n      } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n        if (lastBlockInFile.getNumBytes() !\u003d 0) {\n          throw new IOException(\n              \"Request looked like a retry to allocate block \" +\n              lastBlockInFile + \" but it already contains \" +\n              lastBlockInFile.getNumBytes() + \" bytes\");\n        }\n\n        // Case 2\n        // Return the last block.\n        NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: \" +\n            \"caught retry for allocation of a new block in \" +\n            src + \". Returning previously allocated block \" + lastBlockInFile);\n        long offset \u003d pendingFile.computeFileSize();\n        onRetryBlock[0] \u003d makeLocatedBlock(lastBlockInFile,\n            ((BlockInfoUnderConstruction)lastBlockInFile).getExpectedStorageLocations(),\n            offset);\n        return pendingFile;\n      } else {\n        // Case 3\n        throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n            \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n            \"last block in file \" + lastBlockInFile);\n      }\n    }\n\n    // Check if the penultimate block is minimally replicated\n    if (!checkFileProgress(pendingFile, false)) {\n      throw new NotReplicatedYetException(\"Not replicated yet: \" + src);\n    }\n    return pendingFile;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {
            "oldValue": "INodesInPath",
            "newValue": "INodeFile"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-6294. Use INode IDs to avoid conflicts when a file open for write is renamed (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1593634 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "09/05/14 3:36 PM",
          "commitName": "f131dba8a3d603a5d15c4f035ed3da75b4daf0dc",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "30/04/14 10:44 AM",
          "commitNameOld": "0689363343a281a6f7f6f395227668bddc2663eb",
          "commitAuthorOld": "Haohui Mai",
          "daysBetweenCommits": 9.2,
          "commitsBetweenForRepo": 39,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,92 +1,103 @@\n-  INodesInPath analyzeFileState(String src,\n+  INodeFile analyzeFileState(String src,\n                                 long fileId,\n                                 String clientName,\n                                 ExtendedBlock previous,\n                                 LocatedBlock[] onRetryBlock)\n           throws IOException  {\n     assert hasReadLock();\n \n     checkBlock(previous);\n     onRetryBlock[0] \u003d null;\n     checkOperation(OperationCategory.WRITE);\n     checkNameNodeSafeMode(\"Cannot add block to \" + src);\n \n     // have we exceeded the configured limit of fs objects.\n     checkFsObjectLimit();\n \n     Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n-    final INodesInPath iip \u003d dir.getINodesInPath4Write(src);\n-    final INodeFile pendingFile\n-        \u003d checkLease(src, fileId, clientName, iip.getLastINode());\n+    INode inode;\n+    if (fileId \u003d\u003d INodeId.GRANDFATHER_INODE_ID) {\n+      // Older clients may not have given us an inode ID to work with.\n+      // In this case, we have to try to resolve the path and hope it\n+      // hasn\u0027t changed or been deleted since the file was opened for write.\n+      final INodesInPath iip \u003d dir.getINodesInPath4Write(src);\n+      inode \u003d iip.getLastINode();\n+    } else {\n+      // Newer clients pass the inode ID, so we can just get the inode\n+      // directly.\n+      inode \u003d dir.getInode(fileId);\n+      if (inode !\u003d null) src \u003d inode.getFullPathName();\n+    }\n+    final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n     BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n     if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n       // The block that the client claims is the current last block\n       // doesn\u0027t match up with what we think is the last block. There are\n       // four possibilities:\n       // 1) This is the first block allocation of an append() pipeline\n       //    which started appending exactly at a block boundary.\n       //    In this case, the client isn\u0027t passed the previous block,\n       //    so it makes the allocateBlock() call with previous\u003dnull.\n       //    We can distinguish this since the last block of the file\n       //    will be exactly a full block.\n       // 2) This is a retry from a client that missed the response of a\n       //    prior getAdditionalBlock() call, perhaps because of a network\n       //    timeout, or because of an HA failover. In that case, we know\n       //    by the fact that the client is re-issuing the RPC that it\n       //    never began to write to the old block. Hence it is safe to\n       //    to return the existing block.\n       // 3) This is an entirely bogus request/bug -- we should error out\n       //    rather than potentially appending a new block with an empty\n       //    one in the middle, etc\n       // 4) This is a retry from a client that timed out while\n       //    the prior getAdditionalBlock() is still being processed,\n       //    currently working on chooseTarget(). \n       //    There are no means to distinguish between the first and \n       //    the second attempts in Part I, because the first one hasn\u0027t\n       //    changed the namesystem state yet.\n       //    We run this analysis again in Part II where case 4 is impossible.\n \n       BlockInfo penultimateBlock \u003d pendingFile.getPenultimateBlock();\n       if (previous \u003d\u003d null \u0026\u0026\n           lastBlockInFile !\u003d null \u0026\u0026\n           lastBlockInFile.getNumBytes() \u003d\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n           lastBlockInFile.isComplete()) {\n         // Case 1\n         if (NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\n                \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n                \" writing to a file with a complete previous block: src\u003d\" +\n                src + \" lastBlock\u003d\" + lastBlockInFile);\n         }\n       } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n         if (lastBlockInFile.getNumBytes() !\u003d 0) {\n           throw new IOException(\n               \"Request looked like a retry to allocate block \" +\n               lastBlockInFile + \" but it already contains \" +\n               lastBlockInFile.getNumBytes() + \" bytes\");\n         }\n \n         // Case 2\n         // Return the last block.\n         NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: \" +\n             \"caught retry for allocation of a new block in \" +\n             src + \". Returning previously allocated block \" + lastBlockInFile);\n         long offset \u003d pendingFile.computeFileSize();\n         onRetryBlock[0] \u003d makeLocatedBlock(lastBlockInFile,\n             ((BlockInfoUnderConstruction)lastBlockInFile).getExpectedStorageLocations(),\n             offset);\n-        return iip;\n+        return pendingFile;\n       } else {\n         // Case 3\n         throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n             \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n             \"last block in file \" + lastBlockInFile);\n       }\n     }\n \n     // Check if the penultimate block is minimally replicated\n     if (!checkFileProgress(pendingFile, false)) {\n       throw new NotReplicatedYetException(\"Not replicated yet: \" + src);\n     }\n-    return iip;\n+    return pendingFile;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  INodeFile analyzeFileState(String src,\n                                long fileId,\n                                String clientName,\n                                ExtendedBlock previous,\n                                LocatedBlock[] onRetryBlock)\n          throws IOException  {\n    assert hasReadLock();\n\n    checkBlock(previous);\n    onRetryBlock[0] \u003d null;\n    checkOperation(OperationCategory.WRITE);\n    checkNameNodeSafeMode(\"Cannot add block to \" + src);\n\n    // have we exceeded the configured limit of fs objects.\n    checkFsObjectLimit();\n\n    Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n    INode inode;\n    if (fileId \u003d\u003d INodeId.GRANDFATHER_INODE_ID) {\n      // Older clients may not have given us an inode ID to work with.\n      // In this case, we have to try to resolve the path and hope it\n      // hasn\u0027t changed or been deleted since the file was opened for write.\n      final INodesInPath iip \u003d dir.getINodesInPath4Write(src);\n      inode \u003d iip.getLastINode();\n    } else {\n      // Newer clients pass the inode ID, so we can just get the inode\n      // directly.\n      inode \u003d dir.getInode(fileId);\n      if (inode !\u003d null) src \u003d inode.getFullPathName();\n    }\n    final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n    BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n    if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n      // The block that the client claims is the current last block\n      // doesn\u0027t match up with what we think is the last block. There are\n      // four possibilities:\n      // 1) This is the first block allocation of an append() pipeline\n      //    which started appending exactly at a block boundary.\n      //    In this case, the client isn\u0027t passed the previous block,\n      //    so it makes the allocateBlock() call with previous\u003dnull.\n      //    We can distinguish this since the last block of the file\n      //    will be exactly a full block.\n      // 2) This is a retry from a client that missed the response of a\n      //    prior getAdditionalBlock() call, perhaps because of a network\n      //    timeout, or because of an HA failover. In that case, we know\n      //    by the fact that the client is re-issuing the RPC that it\n      //    never began to write to the old block. Hence it is safe to\n      //    to return the existing block.\n      // 3) This is an entirely bogus request/bug -- we should error out\n      //    rather than potentially appending a new block with an empty\n      //    one in the middle, etc\n      // 4) This is a retry from a client that timed out while\n      //    the prior getAdditionalBlock() is still being processed,\n      //    currently working on chooseTarget(). \n      //    There are no means to distinguish between the first and \n      //    the second attempts in Part I, because the first one hasn\u0027t\n      //    changed the namesystem state yet.\n      //    We run this analysis again in Part II where case 4 is impossible.\n\n      BlockInfo penultimateBlock \u003d pendingFile.getPenultimateBlock();\n      if (previous \u003d\u003d null \u0026\u0026\n          lastBlockInFile !\u003d null \u0026\u0026\n          lastBlockInFile.getNumBytes() \u003d\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n          lastBlockInFile.isComplete()) {\n        // Case 1\n        if (NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\n               \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n               \" writing to a file with a complete previous block: src\u003d\" +\n               src + \" lastBlock\u003d\" + lastBlockInFile);\n        }\n      } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n        if (lastBlockInFile.getNumBytes() !\u003d 0) {\n          throw new IOException(\n              \"Request looked like a retry to allocate block \" +\n              lastBlockInFile + \" but it already contains \" +\n              lastBlockInFile.getNumBytes() + \" bytes\");\n        }\n\n        // Case 2\n        // Return the last block.\n        NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: \" +\n            \"caught retry for allocation of a new block in \" +\n            src + \". Returning previously allocated block \" + lastBlockInFile);\n        long offset \u003d pendingFile.computeFileSize();\n        onRetryBlock[0] \u003d makeLocatedBlock(lastBlockInFile,\n            ((BlockInfoUnderConstruction)lastBlockInFile).getExpectedStorageLocations(),\n            offset);\n        return pendingFile;\n      } else {\n        // Case 3\n        throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n            \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n            \"last block in file \" + lastBlockInFile);\n      }\n    }\n\n    // Check if the penultimate block is minimally replicated\n    if (!checkFileProgress(pendingFile, false)) {\n      throw new NotReplicatedYetException(\"Not replicated yet: \" + src);\n    }\n    return pendingFile;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {}
        }
      ]
    },
    "ce68f410b05a58ad05965f32ad7f5b246b363a75": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5285. Flatten INodeFile hierarchy: Replace INodeFileUnderConstruction and INodeFileUnderConstructionWithSnapshot with FileUnderContructionFeature.  Contributed by jing9\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1544389 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/11/13 5:39 PM",
      "commitName": "ce68f410b05a58ad05965f32ad7f5b246b363a75",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "21/11/13 9:12 AM",
      "commitNameOld": "f91a45a96c21db9e5d40097c7d3f5d005ae10dde",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 0.35,
      "commitsBetweenForRepo": 6,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,92 +1,92 @@\n   INodesInPath analyzeFileState(String src,\n                                 long fileId,\n                                 String clientName,\n                                 ExtendedBlock previous,\n                                 LocatedBlock[] onRetryBlock)\n           throws IOException  {\n     assert hasReadLock();\n \n     checkBlock(previous);\n     onRetryBlock[0] \u003d null;\n     checkOperation(OperationCategory.WRITE);\n     checkNameNodeSafeMode(\"Cannot add block to \" + src);\n \n     // have we exceeded the configured limit of fs objects.\n     checkFsObjectLimit();\n \n     Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n     final INodesInPath iip \u003d dir.getINodesInPath4Write(src);\n-    final INodeFileUnderConstruction pendingFile\n+    final INodeFile pendingFile\n         \u003d checkLease(src, fileId, clientName, iip.getLastINode());\n     BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n     if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n       // The block that the client claims is the current last block\n       // doesn\u0027t match up with what we think is the last block. There are\n       // four possibilities:\n       // 1) This is the first block allocation of an append() pipeline\n       //    which started appending exactly at a block boundary.\n       //    In this case, the client isn\u0027t passed the previous block,\n       //    so it makes the allocateBlock() call with previous\u003dnull.\n       //    We can distinguish this since the last block of the file\n       //    will be exactly a full block.\n       // 2) This is a retry from a client that missed the response of a\n       //    prior getAdditionalBlock() call, perhaps because of a network\n       //    timeout, or because of an HA failover. In that case, we know\n       //    by the fact that the client is re-issuing the RPC that it\n       //    never began to write to the old block. Hence it is safe to\n       //    to return the existing block.\n       // 3) This is an entirely bogus request/bug -- we should error out\n       //    rather than potentially appending a new block with an empty\n       //    one in the middle, etc\n       // 4) This is a retry from a client that timed out while\n       //    the prior getAdditionalBlock() is still being processed,\n       //    currently working on chooseTarget(). \n       //    There are no means to distinguish between the first and \n       //    the second attempts in Part I, because the first one hasn\u0027t\n       //    changed the namesystem state yet.\n       //    We run this analysis again in Part II where case 4 is impossible.\n \n       BlockInfo penultimateBlock \u003d pendingFile.getPenultimateBlock();\n       if (previous \u003d\u003d null \u0026\u0026\n           lastBlockInFile !\u003d null \u0026\u0026\n           lastBlockInFile.getNumBytes() \u003d\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n           lastBlockInFile.isComplete()) {\n         // Case 1\n         if (NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\n                \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n                \" writing to a file with a complete previous block: src\u003d\" +\n                src + \" lastBlock\u003d\" + lastBlockInFile);\n         }\n       } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n         if (lastBlockInFile.getNumBytes() !\u003d 0) {\n           throw new IOException(\n               \"Request looked like a retry to allocate block \" +\n               lastBlockInFile + \" but it already contains \" +\n               lastBlockInFile.getNumBytes() + \" bytes\");\n         }\n \n         // Case 2\n         // Return the last block.\n         NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: \" +\n             \"caught retry for allocation of a new block in \" +\n             src + \". Returning previously allocated block \" + lastBlockInFile);\n         long offset \u003d pendingFile.computeFileSize();\n         onRetryBlock[0] \u003d makeLocatedBlock(lastBlockInFile,\n             ((BlockInfoUnderConstruction)lastBlockInFile).getExpectedLocations(),\n             offset);\n         return iip;\n       } else {\n         // Case 3\n         throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n             \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n             \"last block in file \" + lastBlockInFile);\n       }\n     }\n \n     // Check if the penultimate block is minimally replicated\n     if (!checkFileProgress(pendingFile, false)) {\n       throw new NotReplicatedYetException(\"Not replicated yet: \" + src);\n     }\n     return iip;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  INodesInPath analyzeFileState(String src,\n                                long fileId,\n                                String clientName,\n                                ExtendedBlock previous,\n                                LocatedBlock[] onRetryBlock)\n          throws IOException  {\n    assert hasReadLock();\n\n    checkBlock(previous);\n    onRetryBlock[0] \u003d null;\n    checkOperation(OperationCategory.WRITE);\n    checkNameNodeSafeMode(\"Cannot add block to \" + src);\n\n    // have we exceeded the configured limit of fs objects.\n    checkFsObjectLimit();\n\n    Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n    final INodesInPath iip \u003d dir.getINodesInPath4Write(src);\n    final INodeFile pendingFile\n        \u003d checkLease(src, fileId, clientName, iip.getLastINode());\n    BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n    if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n      // The block that the client claims is the current last block\n      // doesn\u0027t match up with what we think is the last block. There are\n      // four possibilities:\n      // 1) This is the first block allocation of an append() pipeline\n      //    which started appending exactly at a block boundary.\n      //    In this case, the client isn\u0027t passed the previous block,\n      //    so it makes the allocateBlock() call with previous\u003dnull.\n      //    We can distinguish this since the last block of the file\n      //    will be exactly a full block.\n      // 2) This is a retry from a client that missed the response of a\n      //    prior getAdditionalBlock() call, perhaps because of a network\n      //    timeout, or because of an HA failover. In that case, we know\n      //    by the fact that the client is re-issuing the RPC that it\n      //    never began to write to the old block. Hence it is safe to\n      //    to return the existing block.\n      // 3) This is an entirely bogus request/bug -- we should error out\n      //    rather than potentially appending a new block with an empty\n      //    one in the middle, etc\n      // 4) This is a retry from a client that timed out while\n      //    the prior getAdditionalBlock() is still being processed,\n      //    currently working on chooseTarget(). \n      //    There are no means to distinguish between the first and \n      //    the second attempts in Part I, because the first one hasn\u0027t\n      //    changed the namesystem state yet.\n      //    We run this analysis again in Part II where case 4 is impossible.\n\n      BlockInfo penultimateBlock \u003d pendingFile.getPenultimateBlock();\n      if (previous \u003d\u003d null \u0026\u0026\n          lastBlockInFile !\u003d null \u0026\u0026\n          lastBlockInFile.getNumBytes() \u003d\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n          lastBlockInFile.isComplete()) {\n        // Case 1\n        if (NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\n               \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n               \" writing to a file with a complete previous block: src\u003d\" +\n               src + \" lastBlock\u003d\" + lastBlockInFile);\n        }\n      } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n        if (lastBlockInFile.getNumBytes() !\u003d 0) {\n          throw new IOException(\n              \"Request looked like a retry to allocate block \" +\n              lastBlockInFile + \" but it already contains \" +\n              lastBlockInFile.getNumBytes() + \" bytes\");\n        }\n\n        // Case 2\n        // Return the last block.\n        NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: \" +\n            \"caught retry for allocation of a new block in \" +\n            src + \". Returning previously allocated block \" + lastBlockInFile);\n        long offset \u003d pendingFile.computeFileSize();\n        onRetryBlock[0] \u003d makeLocatedBlock(lastBlockInFile,\n            ((BlockInfoUnderConstruction)lastBlockInFile).getExpectedLocations(),\n            offset);\n        return iip;\n      } else {\n        // Case 3\n        throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n            \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n            \"last block in file \" + lastBlockInFile);\n      }\n    }\n\n    // Check if the penultimate block is minimally replicated\n    if (!checkFileProgress(pendingFile, false)) {\n      throw new NotReplicatedYetException(\"Not replicated yet: \" + src);\n    }\n    return iip;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "e3d7ef36ef7dd31b295b1f1d86a1bfa7887ca771": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5372. In FSNamesystem, hasReadLock() returns false if the current thread holds the write lock (Contributed by Vinay)\n\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1542887 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/11/13 8:18 PM",
      "commitName": "e3d7ef36ef7dd31b295b1f1d86a1bfa7887ca771",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "14/11/13 12:11 PM",
      "commitNameOld": "ceea91c9cd8b2a18be13217894ccf1c17198de18",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 3.34,
      "commitsBetweenForRepo": 12,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,92 +1,92 @@\n   INodesInPath analyzeFileState(String src,\n                                 long fileId,\n                                 String clientName,\n                                 ExtendedBlock previous,\n                                 LocatedBlock[] onRetryBlock)\n           throws IOException  {\n-    assert hasReadOrWriteLock();\n+    assert hasReadLock();\n \n     checkBlock(previous);\n     onRetryBlock[0] \u003d null;\n     checkOperation(OperationCategory.WRITE);\n     checkNameNodeSafeMode(\"Cannot add block to \" + src);\n \n     // have we exceeded the configured limit of fs objects.\n     checkFsObjectLimit();\n \n     Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n     final INodesInPath iip \u003d dir.getINodesInPath4Write(src);\n     final INodeFileUnderConstruction pendingFile\n         \u003d checkLease(src, fileId, clientName, iip.getLastINode());\n     BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n     if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n       // The block that the client claims is the current last block\n       // doesn\u0027t match up with what we think is the last block. There are\n       // four possibilities:\n       // 1) This is the first block allocation of an append() pipeline\n       //    which started appending exactly at a block boundary.\n       //    In this case, the client isn\u0027t passed the previous block,\n       //    so it makes the allocateBlock() call with previous\u003dnull.\n       //    We can distinguish this since the last block of the file\n       //    will be exactly a full block.\n       // 2) This is a retry from a client that missed the response of a\n       //    prior getAdditionalBlock() call, perhaps because of a network\n       //    timeout, or because of an HA failover. In that case, we know\n       //    by the fact that the client is re-issuing the RPC that it\n       //    never began to write to the old block. Hence it is safe to\n       //    to return the existing block.\n       // 3) This is an entirely bogus request/bug -- we should error out\n       //    rather than potentially appending a new block with an empty\n       //    one in the middle, etc\n       // 4) This is a retry from a client that timed out while\n       //    the prior getAdditionalBlock() is still being processed,\n       //    currently working on chooseTarget(). \n       //    There are no means to distinguish between the first and \n       //    the second attempts in Part I, because the first one hasn\u0027t\n       //    changed the namesystem state yet.\n       //    We run this analysis again in Part II where case 4 is impossible.\n \n       BlockInfo penultimateBlock \u003d pendingFile.getPenultimateBlock();\n       if (previous \u003d\u003d null \u0026\u0026\n           lastBlockInFile !\u003d null \u0026\u0026\n           lastBlockInFile.getNumBytes() \u003d\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n           lastBlockInFile.isComplete()) {\n         // Case 1\n         if (NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\n                \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n                \" writing to a file with a complete previous block: src\u003d\" +\n                src + \" lastBlock\u003d\" + lastBlockInFile);\n         }\n       } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n         if (lastBlockInFile.getNumBytes() !\u003d 0) {\n           throw new IOException(\n               \"Request looked like a retry to allocate block \" +\n               lastBlockInFile + \" but it already contains \" +\n               lastBlockInFile.getNumBytes() + \" bytes\");\n         }\n \n         // Case 2\n         // Return the last block.\n         NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: \" +\n             \"caught retry for allocation of a new block in \" +\n             src + \". Returning previously allocated block \" + lastBlockInFile);\n         long offset \u003d pendingFile.computeFileSize();\n         onRetryBlock[0] \u003d makeLocatedBlock(lastBlockInFile,\n             ((BlockInfoUnderConstruction)lastBlockInFile).getExpectedLocations(),\n             offset);\n         return iip;\n       } else {\n         // Case 3\n         throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n             \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n             \"last block in file \" + lastBlockInFile);\n       }\n     }\n \n     // Check if the penultimate block is minimally replicated\n     if (!checkFileProgress(pendingFile, false)) {\n       throw new NotReplicatedYetException(\"Not replicated yet: \" + src);\n     }\n     return iip;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  INodesInPath analyzeFileState(String src,\n                                long fileId,\n                                String clientName,\n                                ExtendedBlock previous,\n                                LocatedBlock[] onRetryBlock)\n          throws IOException  {\n    assert hasReadLock();\n\n    checkBlock(previous);\n    onRetryBlock[0] \u003d null;\n    checkOperation(OperationCategory.WRITE);\n    checkNameNodeSafeMode(\"Cannot add block to \" + src);\n\n    // have we exceeded the configured limit of fs objects.\n    checkFsObjectLimit();\n\n    Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n    final INodesInPath iip \u003d dir.getINodesInPath4Write(src);\n    final INodeFileUnderConstruction pendingFile\n        \u003d checkLease(src, fileId, clientName, iip.getLastINode());\n    BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n    if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n      // The block that the client claims is the current last block\n      // doesn\u0027t match up with what we think is the last block. There are\n      // four possibilities:\n      // 1) This is the first block allocation of an append() pipeline\n      //    which started appending exactly at a block boundary.\n      //    In this case, the client isn\u0027t passed the previous block,\n      //    so it makes the allocateBlock() call with previous\u003dnull.\n      //    We can distinguish this since the last block of the file\n      //    will be exactly a full block.\n      // 2) This is a retry from a client that missed the response of a\n      //    prior getAdditionalBlock() call, perhaps because of a network\n      //    timeout, or because of an HA failover. In that case, we know\n      //    by the fact that the client is re-issuing the RPC that it\n      //    never began to write to the old block. Hence it is safe to\n      //    to return the existing block.\n      // 3) This is an entirely bogus request/bug -- we should error out\n      //    rather than potentially appending a new block with an empty\n      //    one in the middle, etc\n      // 4) This is a retry from a client that timed out while\n      //    the prior getAdditionalBlock() is still being processed,\n      //    currently working on chooseTarget(). \n      //    There are no means to distinguish between the first and \n      //    the second attempts in Part I, because the first one hasn\u0027t\n      //    changed the namesystem state yet.\n      //    We run this analysis again in Part II where case 4 is impossible.\n\n      BlockInfo penultimateBlock \u003d pendingFile.getPenultimateBlock();\n      if (previous \u003d\u003d null \u0026\u0026\n          lastBlockInFile !\u003d null \u0026\u0026\n          lastBlockInFile.getNumBytes() \u003d\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n          lastBlockInFile.isComplete()) {\n        // Case 1\n        if (NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\n               \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n               \" writing to a file with a complete previous block: src\u003d\" +\n               src + \" lastBlock\u003d\" + lastBlockInFile);\n        }\n      } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n        if (lastBlockInFile.getNumBytes() !\u003d 0) {\n          throw new IOException(\n              \"Request looked like a retry to allocate block \" +\n              lastBlockInFile + \" but it already contains \" +\n              lastBlockInFile.getNumBytes() + \" bytes\");\n        }\n\n        // Case 2\n        // Return the last block.\n        NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: \" +\n            \"caught retry for allocation of a new block in \" +\n            src + \". Returning previously allocated block \" + lastBlockInFile);\n        long offset \u003d pendingFile.computeFileSize();\n        onRetryBlock[0] \u003d makeLocatedBlock(lastBlockInFile,\n            ((BlockInfoUnderConstruction)lastBlockInFile).getExpectedLocations(),\n            offset);\n        return iip;\n      } else {\n        // Case 3\n        throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n            \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n            \"last block in file \" + lastBlockInFile);\n      }\n    }\n\n    // Check if the penultimate block is minimally replicated\n    if (!checkFileProgress(pendingFile, false)) {\n      throw new NotReplicatedYetException(\"Not replicated yet: \" + src);\n    }\n    return iip;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "34f08944b7c8d58f531a3f3bf3d4ee4cd3fa643a": {
      "type": "Ybodychange",
      "commitMessage": "merge trunk to branch HDFS-4949\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1532952 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/10/13 7:14 PM",
      "commitName": "34f08944b7c8d58f531a3f3bf3d4ee4cd3fa643a",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "16/10/13 3:15 PM",
      "commitNameOld": "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 0.17,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,94 +1,92 @@\n   INodesInPath analyzeFileState(String src,\n                                 long fileId,\n                                 String clientName,\n                                 ExtendedBlock previous,\n                                 LocatedBlock[] onRetryBlock)\n           throws IOException  {\n     assert hasReadOrWriteLock();\n \n     checkBlock(previous);\n     onRetryBlock[0] \u003d null;\n     checkOperation(OperationCategory.WRITE);\n-    if (isInSafeMode()) {\n-      throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n-    }\n+    checkNameNodeSafeMode(\"Cannot add block to \" + src);\n \n     // have we exceeded the configured limit of fs objects.\n     checkFsObjectLimit();\n \n     Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n     final INodesInPath iip \u003d dir.getINodesInPath4Write(src);\n     final INodeFileUnderConstruction pendingFile\n         \u003d checkLease(src, fileId, clientName, iip.getLastINode());\n     BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n     if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n       // The block that the client claims is the current last block\n       // doesn\u0027t match up with what we think is the last block. There are\n       // four possibilities:\n       // 1) This is the first block allocation of an append() pipeline\n       //    which started appending exactly at a block boundary.\n       //    In this case, the client isn\u0027t passed the previous block,\n       //    so it makes the allocateBlock() call with previous\u003dnull.\n       //    We can distinguish this since the last block of the file\n       //    will be exactly a full block.\n       // 2) This is a retry from a client that missed the response of a\n       //    prior getAdditionalBlock() call, perhaps because of a network\n       //    timeout, or because of an HA failover. In that case, we know\n       //    by the fact that the client is re-issuing the RPC that it\n       //    never began to write to the old block. Hence it is safe to\n       //    to return the existing block.\n       // 3) This is an entirely bogus request/bug -- we should error out\n       //    rather than potentially appending a new block with an empty\n       //    one in the middle, etc\n       // 4) This is a retry from a client that timed out while\n       //    the prior getAdditionalBlock() is still being processed,\n       //    currently working on chooseTarget(). \n       //    There are no means to distinguish between the first and \n       //    the second attempts in Part I, because the first one hasn\u0027t\n       //    changed the namesystem state yet.\n       //    We run this analysis again in Part II where case 4 is impossible.\n \n       BlockInfo penultimateBlock \u003d pendingFile.getPenultimateBlock();\n       if (previous \u003d\u003d null \u0026\u0026\n           lastBlockInFile !\u003d null \u0026\u0026\n           lastBlockInFile.getNumBytes() \u003d\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n           lastBlockInFile.isComplete()) {\n         // Case 1\n         if (NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\n                \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n                \" writing to a file with a complete previous block: src\u003d\" +\n                src + \" lastBlock\u003d\" + lastBlockInFile);\n         }\n       } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n         if (lastBlockInFile.getNumBytes() !\u003d 0) {\n           throw new IOException(\n               \"Request looked like a retry to allocate block \" +\n               lastBlockInFile + \" but it already contains \" +\n               lastBlockInFile.getNumBytes() + \" bytes\");\n         }\n \n         // Case 2\n         // Return the last block.\n         NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: \" +\n             \"caught retry for allocation of a new block in \" +\n             src + \". Returning previously allocated block \" + lastBlockInFile);\n         long offset \u003d pendingFile.computeFileSize();\n         onRetryBlock[0] \u003d makeLocatedBlock(lastBlockInFile,\n             ((BlockInfoUnderConstruction)lastBlockInFile).getExpectedLocations(),\n             offset);\n         return iip;\n       } else {\n         // Case 3\n         throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n             \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n             \"last block in file \" + lastBlockInFile);\n       }\n     }\n \n     // Check if the penultimate block is minimally replicated\n     if (!checkFileProgress(pendingFile, false)) {\n       throw new NotReplicatedYetException(\"Not replicated yet: \" + src);\n     }\n     return iip;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  INodesInPath analyzeFileState(String src,\n                                long fileId,\n                                String clientName,\n                                ExtendedBlock previous,\n                                LocatedBlock[] onRetryBlock)\n          throws IOException  {\n    assert hasReadOrWriteLock();\n\n    checkBlock(previous);\n    onRetryBlock[0] \u003d null;\n    checkOperation(OperationCategory.WRITE);\n    checkNameNodeSafeMode(\"Cannot add block to \" + src);\n\n    // have we exceeded the configured limit of fs objects.\n    checkFsObjectLimit();\n\n    Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n    final INodesInPath iip \u003d dir.getINodesInPath4Write(src);\n    final INodeFileUnderConstruction pendingFile\n        \u003d checkLease(src, fileId, clientName, iip.getLastINode());\n    BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n    if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n      // The block that the client claims is the current last block\n      // doesn\u0027t match up with what we think is the last block. There are\n      // four possibilities:\n      // 1) This is the first block allocation of an append() pipeline\n      //    which started appending exactly at a block boundary.\n      //    In this case, the client isn\u0027t passed the previous block,\n      //    so it makes the allocateBlock() call with previous\u003dnull.\n      //    We can distinguish this since the last block of the file\n      //    will be exactly a full block.\n      // 2) This is a retry from a client that missed the response of a\n      //    prior getAdditionalBlock() call, perhaps because of a network\n      //    timeout, or because of an HA failover. In that case, we know\n      //    by the fact that the client is re-issuing the RPC that it\n      //    never began to write to the old block. Hence it is safe to\n      //    to return the existing block.\n      // 3) This is an entirely bogus request/bug -- we should error out\n      //    rather than potentially appending a new block with an empty\n      //    one in the middle, etc\n      // 4) This is a retry from a client that timed out while\n      //    the prior getAdditionalBlock() is still being processed,\n      //    currently working on chooseTarget(). \n      //    There are no means to distinguish between the first and \n      //    the second attempts in Part I, because the first one hasn\u0027t\n      //    changed the namesystem state yet.\n      //    We run this analysis again in Part II where case 4 is impossible.\n\n      BlockInfo penultimateBlock \u003d pendingFile.getPenultimateBlock();\n      if (previous \u003d\u003d null \u0026\u0026\n          lastBlockInFile !\u003d null \u0026\u0026\n          lastBlockInFile.getNumBytes() \u003d\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n          lastBlockInFile.isComplete()) {\n        // Case 1\n        if (NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\n               \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n               \" writing to a file with a complete previous block: src\u003d\" +\n               src + \" lastBlock\u003d\" + lastBlockInFile);\n        }\n      } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n        if (lastBlockInFile.getNumBytes() !\u003d 0) {\n          throw new IOException(\n              \"Request looked like a retry to allocate block \" +\n              lastBlockInFile + \" but it already contains \" +\n              lastBlockInFile.getNumBytes() + \" bytes\");\n        }\n\n        // Case 2\n        // Return the last block.\n        NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: \" +\n            \"caught retry for allocation of a new block in \" +\n            src + \". Returning previously allocated block \" + lastBlockInFile);\n        long offset \u003d pendingFile.computeFileSize();\n        onRetryBlock[0] \u003d makeLocatedBlock(lastBlockInFile,\n            ((BlockInfoUnderConstruction)lastBlockInFile).getExpectedLocations(),\n            offset);\n        return iip;\n      } else {\n        // Case 3\n        throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n            \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n            \"last block in file \" + lastBlockInFile);\n      }\n    }\n\n    // Check if the penultimate block is minimally replicated\n    if (!checkFileProgress(pendingFile, false)) {\n      throw new NotReplicatedYetException(\"Not replicated yet: \" + src);\n    }\n    return iip;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "1fe1942328856dd832e9f94fb56a40ab3d810870": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5291. Standby namenode after transition to active goes into safemode. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1530112 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/10/13 4:58 PM",
      "commitName": "1fe1942328856dd832e9f94fb56a40ab3d810870",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "06/10/13 11:39 AM",
      "commitNameOld": "7317e97bd72ca30f5db37fa94389dbdb52ae079e",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 1.22,
      "commitsBetweenForRepo": 10,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,94 +1,92 @@\n   INodesInPath analyzeFileState(String src,\n                                 long fileId,\n                                 String clientName,\n                                 ExtendedBlock previous,\n                                 LocatedBlock[] onRetryBlock)\n           throws IOException  {\n     assert hasReadOrWriteLock();\n \n     checkBlock(previous);\n     onRetryBlock[0] \u003d null;\n     checkOperation(OperationCategory.WRITE);\n-    if (isInSafeMode()) {\n-      throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n-    }\n+    checkNameNodeSafeMode(\"Cannot add block to \" + src);\n \n     // have we exceeded the configured limit of fs objects.\n     checkFsObjectLimit();\n \n     Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n     final INodesInPath iip \u003d dir.getINodesInPath4Write(src);\n     final INodeFileUnderConstruction pendingFile\n         \u003d checkLease(src, fileId, clientName, iip.getLastINode());\n     BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n     if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n       // The block that the client claims is the current last block\n       // doesn\u0027t match up with what we think is the last block. There are\n       // four possibilities:\n       // 1) This is the first block allocation of an append() pipeline\n       //    which started appending exactly at a block boundary.\n       //    In this case, the client isn\u0027t passed the previous block,\n       //    so it makes the allocateBlock() call with previous\u003dnull.\n       //    We can distinguish this since the last block of the file\n       //    will be exactly a full block.\n       // 2) This is a retry from a client that missed the response of a\n       //    prior getAdditionalBlock() call, perhaps because of a network\n       //    timeout, or because of an HA failover. In that case, we know\n       //    by the fact that the client is re-issuing the RPC that it\n       //    never began to write to the old block. Hence it is safe to\n       //    to return the existing block.\n       // 3) This is an entirely bogus request/bug -- we should error out\n       //    rather than potentially appending a new block with an empty\n       //    one in the middle, etc\n       // 4) This is a retry from a client that timed out while\n       //    the prior getAdditionalBlock() is still being processed,\n       //    currently working on chooseTarget(). \n       //    There are no means to distinguish between the first and \n       //    the second attempts in Part I, because the first one hasn\u0027t\n       //    changed the namesystem state yet.\n       //    We run this analysis again in Part II where case 4 is impossible.\n \n       BlockInfo penultimateBlock \u003d pendingFile.getPenultimateBlock();\n       if (previous \u003d\u003d null \u0026\u0026\n           lastBlockInFile !\u003d null \u0026\u0026\n           lastBlockInFile.getNumBytes() \u003d\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n           lastBlockInFile.isComplete()) {\n         // Case 1\n         if (NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\n                \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n                \" writing to a file with a complete previous block: src\u003d\" +\n                src + \" lastBlock\u003d\" + lastBlockInFile);\n         }\n       } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n         if (lastBlockInFile.getNumBytes() !\u003d 0) {\n           throw new IOException(\n               \"Request looked like a retry to allocate block \" +\n               lastBlockInFile + \" but it already contains \" +\n               lastBlockInFile.getNumBytes() + \" bytes\");\n         }\n \n         // Case 2\n         // Return the last block.\n         NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: \" +\n             \"caught retry for allocation of a new block in \" +\n             src + \". Returning previously allocated block \" + lastBlockInFile);\n         long offset \u003d pendingFile.computeFileSize();\n         onRetryBlock[0] \u003d makeLocatedBlock(lastBlockInFile,\n             ((BlockInfoUnderConstruction)lastBlockInFile).getExpectedLocations(),\n             offset);\n         return iip;\n       } else {\n         // Case 3\n         throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n             \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n             \"last block in file \" + lastBlockInFile);\n       }\n     }\n \n     // Check if the penultimate block is minimally replicated\n     if (!checkFileProgress(pendingFile, false)) {\n       throw new NotReplicatedYetException(\"Not replicated yet: \" + src);\n     }\n     return iip;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  INodesInPath analyzeFileState(String src,\n                                long fileId,\n                                String clientName,\n                                ExtendedBlock previous,\n                                LocatedBlock[] onRetryBlock)\n          throws IOException  {\n    assert hasReadOrWriteLock();\n\n    checkBlock(previous);\n    onRetryBlock[0] \u003d null;\n    checkOperation(OperationCategory.WRITE);\n    checkNameNodeSafeMode(\"Cannot add block to \" + src);\n\n    // have we exceeded the configured limit of fs objects.\n    checkFsObjectLimit();\n\n    Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n    final INodesInPath iip \u003d dir.getINodesInPath4Write(src);\n    final INodeFileUnderConstruction pendingFile\n        \u003d checkLease(src, fileId, clientName, iip.getLastINode());\n    BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n    if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n      // The block that the client claims is the current last block\n      // doesn\u0027t match up with what we think is the last block. There are\n      // four possibilities:\n      // 1) This is the first block allocation of an append() pipeline\n      //    which started appending exactly at a block boundary.\n      //    In this case, the client isn\u0027t passed the previous block,\n      //    so it makes the allocateBlock() call with previous\u003dnull.\n      //    We can distinguish this since the last block of the file\n      //    will be exactly a full block.\n      // 2) This is a retry from a client that missed the response of a\n      //    prior getAdditionalBlock() call, perhaps because of a network\n      //    timeout, or because of an HA failover. In that case, we know\n      //    by the fact that the client is re-issuing the RPC that it\n      //    never began to write to the old block. Hence it is safe to\n      //    to return the existing block.\n      // 3) This is an entirely bogus request/bug -- we should error out\n      //    rather than potentially appending a new block with an empty\n      //    one in the middle, etc\n      // 4) This is a retry from a client that timed out while\n      //    the prior getAdditionalBlock() is still being processed,\n      //    currently working on chooseTarget(). \n      //    There are no means to distinguish between the first and \n      //    the second attempts in Part I, because the first one hasn\u0027t\n      //    changed the namesystem state yet.\n      //    We run this analysis again in Part II where case 4 is impossible.\n\n      BlockInfo penultimateBlock \u003d pendingFile.getPenultimateBlock();\n      if (previous \u003d\u003d null \u0026\u0026\n          lastBlockInFile !\u003d null \u0026\u0026\n          lastBlockInFile.getNumBytes() \u003d\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n          lastBlockInFile.isComplete()) {\n        // Case 1\n        if (NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\n               \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n               \" writing to a file with a complete previous block: src\u003d\" +\n               src + \" lastBlock\u003d\" + lastBlockInFile);\n        }\n      } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n        if (lastBlockInFile.getNumBytes() !\u003d 0) {\n          throw new IOException(\n              \"Request looked like a retry to allocate block \" +\n              lastBlockInFile + \" but it already contains \" +\n              lastBlockInFile.getNumBytes() + \" bytes\");\n        }\n\n        // Case 2\n        // Return the last block.\n        NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: \" +\n            \"caught retry for allocation of a new block in \" +\n            src + \". Returning previously allocated block \" + lastBlockInFile);\n        long offset \u003d pendingFile.computeFileSize();\n        onRetryBlock[0] \u003d makeLocatedBlock(lastBlockInFile,\n            ((BlockInfoUnderConstruction)lastBlockInFile).getExpectedLocations(),\n            offset);\n        return iip;\n      } else {\n        // Case 3\n        throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n            \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n            \"last block in file \" + lastBlockInFile);\n      }\n    }\n\n    // Check if the penultimate block is minimally replicated\n    if (!checkFileProgress(pendingFile, false)) {\n      throw new NotReplicatedYetException(\"Not replicated yet: \" + src);\n    }\n    return iip;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "3f070e83b1f4e0211ece8c0ab508a61188ad352a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5009. Include storage information in the LocatedBlock.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2832@1519691 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "03/09/13 7:03 AM",
      "commitName": "3f070e83b1f4e0211ece8c0ab508a61188ad352a",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "27/08/13 11:30 PM",
      "commitNameOld": "5d9d702607913685eab0d8ad077040ddc82bf085",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 6.31,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,94 +1,94 @@\n   INodesInPath analyzeFileState(String src,\n                                 long fileId,\n                                 String clientName,\n                                 ExtendedBlock previous,\n                                 LocatedBlock[] onRetryBlock)\n           throws IOException  {\n     assert hasReadOrWriteLock();\n \n     checkBlock(previous);\n     onRetryBlock[0] \u003d null;\n     checkOperation(OperationCategory.WRITE);\n     if (isInSafeMode()) {\n       throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n     }\n \n     // have we exceeded the configured limit of fs objects.\n     checkFsObjectLimit();\n \n     Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n     final INodesInPath iip \u003d dir.getINodesInPath4Write(src);\n     final INodeFileUnderConstruction pendingFile\n         \u003d checkLease(src, fileId, clientName, iip.getLastINode());\n     BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n     if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n       // The block that the client claims is the current last block\n       // doesn\u0027t match up with what we think is the last block. There are\n       // four possibilities:\n       // 1) This is the first block allocation of an append() pipeline\n       //    which started appending exactly at a block boundary.\n       //    In this case, the client isn\u0027t passed the previous block,\n       //    so it makes the allocateBlock() call with previous\u003dnull.\n       //    We can distinguish this since the last block of the file\n       //    will be exactly a full block.\n       // 2) This is a retry from a client that missed the response of a\n       //    prior getAdditionalBlock() call, perhaps because of a network\n       //    timeout, or because of an HA failover. In that case, we know\n       //    by the fact that the client is re-issuing the RPC that it\n       //    never began to write to the old block. Hence it is safe to\n       //    to return the existing block.\n       // 3) This is an entirely bogus request/bug -- we should error out\n       //    rather than potentially appending a new block with an empty\n       //    one in the middle, etc\n       // 4) This is a retry from a client that timed out while\n       //    the prior getAdditionalBlock() is still being processed,\n       //    currently working on chooseTarget(). \n       //    There are no means to distinguish between the first and \n       //    the second attempts in Part I, because the first one hasn\u0027t\n       //    changed the namesystem state yet.\n       //    We run this analysis again in Part II where case 4 is impossible.\n \n       BlockInfo penultimateBlock \u003d pendingFile.getPenultimateBlock();\n       if (previous \u003d\u003d null \u0026\u0026\n           lastBlockInFile !\u003d null \u0026\u0026\n           lastBlockInFile.getNumBytes() \u003d\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n           lastBlockInFile.isComplete()) {\n         // Case 1\n         if (NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\n                \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n                \" writing to a file with a complete previous block: src\u003d\" +\n                src + \" lastBlock\u003d\" + lastBlockInFile);\n         }\n       } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n         if (lastBlockInFile.getNumBytes() !\u003d 0) {\n           throw new IOException(\n               \"Request looked like a retry to allocate block \" +\n               lastBlockInFile + \" but it already contains \" +\n               lastBlockInFile.getNumBytes() + \" bytes\");\n         }\n \n         // Case 2\n         // Return the last block.\n         NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: \" +\n             \"caught retry for allocation of a new block in \" +\n             src + \". Returning previously allocated block \" + lastBlockInFile);\n         long offset \u003d pendingFile.computeFileSize();\n         onRetryBlock[0] \u003d makeLocatedBlock(lastBlockInFile,\n-            ((BlockInfoUnderConstruction)lastBlockInFile).getExpectedLocations(),\n+            ((BlockInfoUnderConstruction)lastBlockInFile).getExpectedStorageLocations(),\n             offset);\n         return iip;\n       } else {\n         // Case 3\n         throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n             \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n             \"last block in file \" + lastBlockInFile);\n       }\n     }\n \n     // Check if the penultimate block is minimally replicated\n     if (!checkFileProgress(pendingFile, false)) {\n       throw new NotReplicatedYetException(\"Not replicated yet: \" + src);\n     }\n     return iip;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  INodesInPath analyzeFileState(String src,\n                                long fileId,\n                                String clientName,\n                                ExtendedBlock previous,\n                                LocatedBlock[] onRetryBlock)\n          throws IOException  {\n    assert hasReadOrWriteLock();\n\n    checkBlock(previous);\n    onRetryBlock[0] \u003d null;\n    checkOperation(OperationCategory.WRITE);\n    if (isInSafeMode()) {\n      throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n    }\n\n    // have we exceeded the configured limit of fs objects.\n    checkFsObjectLimit();\n\n    Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n    final INodesInPath iip \u003d dir.getINodesInPath4Write(src);\n    final INodeFileUnderConstruction pendingFile\n        \u003d checkLease(src, fileId, clientName, iip.getLastINode());\n    BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n    if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n      // The block that the client claims is the current last block\n      // doesn\u0027t match up with what we think is the last block. There are\n      // four possibilities:\n      // 1) This is the first block allocation of an append() pipeline\n      //    which started appending exactly at a block boundary.\n      //    In this case, the client isn\u0027t passed the previous block,\n      //    so it makes the allocateBlock() call with previous\u003dnull.\n      //    We can distinguish this since the last block of the file\n      //    will be exactly a full block.\n      // 2) This is a retry from a client that missed the response of a\n      //    prior getAdditionalBlock() call, perhaps because of a network\n      //    timeout, or because of an HA failover. In that case, we know\n      //    by the fact that the client is re-issuing the RPC that it\n      //    never began to write to the old block. Hence it is safe to\n      //    to return the existing block.\n      // 3) This is an entirely bogus request/bug -- we should error out\n      //    rather than potentially appending a new block with an empty\n      //    one in the middle, etc\n      // 4) This is a retry from a client that timed out while\n      //    the prior getAdditionalBlock() is still being processed,\n      //    currently working on chooseTarget(). \n      //    There are no means to distinguish between the first and \n      //    the second attempts in Part I, because the first one hasn\u0027t\n      //    changed the namesystem state yet.\n      //    We run this analysis again in Part II where case 4 is impossible.\n\n      BlockInfo penultimateBlock \u003d pendingFile.getPenultimateBlock();\n      if (previous \u003d\u003d null \u0026\u0026\n          lastBlockInFile !\u003d null \u0026\u0026\n          lastBlockInFile.getNumBytes() \u003d\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n          lastBlockInFile.isComplete()) {\n        // Case 1\n        if (NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\n               \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n               \" writing to a file with a complete previous block: src\u003d\" +\n               src + \" lastBlock\u003d\" + lastBlockInFile);\n        }\n      } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n        if (lastBlockInFile.getNumBytes() !\u003d 0) {\n          throw new IOException(\n              \"Request looked like a retry to allocate block \" +\n              lastBlockInFile + \" but it already contains \" +\n              lastBlockInFile.getNumBytes() + \" bytes\");\n        }\n\n        // Case 2\n        // Return the last block.\n        NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: \" +\n            \"caught retry for allocation of a new block in \" +\n            src + \". Returning previously allocated block \" + lastBlockInFile);\n        long offset \u003d pendingFile.computeFileSize();\n        onRetryBlock[0] \u003d makeLocatedBlock(lastBlockInFile,\n            ((BlockInfoUnderConstruction)lastBlockInFile).getExpectedStorageLocations(),\n            offset);\n        return iip;\n      } else {\n        // Case 3\n        throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n            \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n            \"last block in file \" + lastBlockInFile);\n      }\n    }\n\n    // Check if the penultimate block is minimally replicated\n    if (!checkFileProgress(pendingFile, false)) {\n      throw new NotReplicatedYetException(\"Not replicated yet: \" + src);\n    }\n    return iip;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "b1333e5b561d01a010e2e1311e8501879f377bdc": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4545. With snapshots, FSDirectory.unprotectedSetReplication(..) always changes file replication but it may or may not changes block replication.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2802@1452636 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/03/13 6:23 PM",
      "commitName": "b1333e5b561d01a010e2e1311e8501879f377bdc",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "26/02/13 2:04 PM",
      "commitNameOld": "e2a618e1cc3fb99115547af6540932860dc6766e",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 6.18,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,95 +1,94 @@\n   INodesInPath analyzeFileState(String src,\n                                 long fileId,\n                                 String clientName,\n                                 ExtendedBlock previous,\n                                 LocatedBlock[] onRetryBlock)\n           throws IOException  {\n     assert hasReadOrWriteLock();\n \n     checkBlock(previous);\n     onRetryBlock[0] \u003d null;\n     checkOperation(OperationCategory.WRITE);\n     if (isInSafeMode()) {\n       throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n     }\n \n     // have we exceeded the configured limit of fs objects.\n     checkFsObjectLimit();\n \n     Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n-    final INodesInPath inodesInPath \u003d dir.getINodesInPath4Write(src);\n-    final INode[] inodes \u003d inodesInPath.getINodes();\n+    final INodesInPath iip \u003d dir.getINodesInPath4Write(src);\n     final INodeFileUnderConstruction pendingFile\n-        \u003d checkLease(src, fileId, clientName, inodes[inodes.length - 1]);\n+        \u003d checkLease(src, fileId, clientName, iip.getLastINode());\n     BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n     if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n       // The block that the client claims is the current last block\n       // doesn\u0027t match up with what we think is the last block. There are\n       // four possibilities:\n       // 1) This is the first block allocation of an append() pipeline\n       //    which started appending exactly at a block boundary.\n       //    In this case, the client isn\u0027t passed the previous block,\n       //    so it makes the allocateBlock() call with previous\u003dnull.\n       //    We can distinguish this since the last block of the file\n       //    will be exactly a full block.\n       // 2) This is a retry from a client that missed the response of a\n       //    prior getAdditionalBlock() call, perhaps because of a network\n       //    timeout, or because of an HA failover. In that case, we know\n       //    by the fact that the client is re-issuing the RPC that it\n       //    never began to write to the old block. Hence it is safe to\n       //    to return the existing block.\n       // 3) This is an entirely bogus request/bug -- we should error out\n       //    rather than potentially appending a new block with an empty\n       //    one in the middle, etc\n       // 4) This is a retry from a client that timed out while\n       //    the prior getAdditionalBlock() is still being processed,\n       //    currently working on chooseTarget(). \n       //    There are no means to distinguish between the first and \n       //    the second attempts in Part I, because the first one hasn\u0027t\n       //    changed the namesystem state yet.\n       //    We run this analysis again in Part II where case 4 is impossible.\n \n       BlockInfo penultimateBlock \u003d pendingFile.getPenultimateBlock();\n       if (previous \u003d\u003d null \u0026\u0026\n           lastBlockInFile !\u003d null \u0026\u0026\n           lastBlockInFile.getNumBytes() \u003d\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n           lastBlockInFile.isComplete()) {\n         // Case 1\n         if (NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\n                \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n                \" writing to a file with a complete previous block: src\u003d\" +\n                src + \" lastBlock\u003d\" + lastBlockInFile);\n         }\n       } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n         if (lastBlockInFile.getNumBytes() !\u003d 0) {\n           throw new IOException(\n               \"Request looked like a retry to allocate block \" +\n               lastBlockInFile + \" but it already contains \" +\n               lastBlockInFile.getNumBytes() + \" bytes\");\n         }\n \n         // Case 2\n         // Return the last block.\n         NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: \" +\n             \"caught retry for allocation of a new block in \" +\n             src + \". Returning previously allocated block \" + lastBlockInFile);\n         long offset \u003d pendingFile.computeFileSize();\n         onRetryBlock[0] \u003d makeLocatedBlock(lastBlockInFile,\n             ((BlockInfoUnderConstruction)lastBlockInFile).getExpectedLocations(),\n             offset);\n-        return inodesInPath;\n+        return iip;\n       } else {\n         // Case 3\n         throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n             \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n             \"last block in file \" + lastBlockInFile);\n       }\n     }\n \n     // Check if the penultimate block is minimally replicated\n     if (!checkFileProgress(pendingFile, false)) {\n       throw new NotReplicatedYetException(\"Not replicated yet: \" + src);\n     }\n-    return inodesInPath;\n+    return iip;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  INodesInPath analyzeFileState(String src,\n                                long fileId,\n                                String clientName,\n                                ExtendedBlock previous,\n                                LocatedBlock[] onRetryBlock)\n          throws IOException  {\n    assert hasReadOrWriteLock();\n\n    checkBlock(previous);\n    onRetryBlock[0] \u003d null;\n    checkOperation(OperationCategory.WRITE);\n    if (isInSafeMode()) {\n      throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n    }\n\n    // have we exceeded the configured limit of fs objects.\n    checkFsObjectLimit();\n\n    Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n    final INodesInPath iip \u003d dir.getINodesInPath4Write(src);\n    final INodeFileUnderConstruction pendingFile\n        \u003d checkLease(src, fileId, clientName, iip.getLastINode());\n    BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n    if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n      // The block that the client claims is the current last block\n      // doesn\u0027t match up with what we think is the last block. There are\n      // four possibilities:\n      // 1) This is the first block allocation of an append() pipeline\n      //    which started appending exactly at a block boundary.\n      //    In this case, the client isn\u0027t passed the previous block,\n      //    so it makes the allocateBlock() call with previous\u003dnull.\n      //    We can distinguish this since the last block of the file\n      //    will be exactly a full block.\n      // 2) This is a retry from a client that missed the response of a\n      //    prior getAdditionalBlock() call, perhaps because of a network\n      //    timeout, or because of an HA failover. In that case, we know\n      //    by the fact that the client is re-issuing the RPC that it\n      //    never began to write to the old block. Hence it is safe to\n      //    to return the existing block.\n      // 3) This is an entirely bogus request/bug -- we should error out\n      //    rather than potentially appending a new block with an empty\n      //    one in the middle, etc\n      // 4) This is a retry from a client that timed out while\n      //    the prior getAdditionalBlock() is still being processed,\n      //    currently working on chooseTarget(). \n      //    There are no means to distinguish between the first and \n      //    the second attempts in Part I, because the first one hasn\u0027t\n      //    changed the namesystem state yet.\n      //    We run this analysis again in Part II where case 4 is impossible.\n\n      BlockInfo penultimateBlock \u003d pendingFile.getPenultimateBlock();\n      if (previous \u003d\u003d null \u0026\u0026\n          lastBlockInFile !\u003d null \u0026\u0026\n          lastBlockInFile.getNumBytes() \u003d\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n          lastBlockInFile.isComplete()) {\n        // Case 1\n        if (NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\n               \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n               \" writing to a file with a complete previous block: src\u003d\" +\n               src + \" lastBlock\u003d\" + lastBlockInFile);\n        }\n      } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n        if (lastBlockInFile.getNumBytes() !\u003d 0) {\n          throw new IOException(\n              \"Request looked like a retry to allocate block \" +\n              lastBlockInFile + \" but it already contains \" +\n              lastBlockInFile.getNumBytes() + \" bytes\");\n        }\n\n        // Case 2\n        // Return the last block.\n        NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: \" +\n            \"caught retry for allocation of a new block in \" +\n            src + \". Returning previously allocated block \" + lastBlockInFile);\n        long offset \u003d pendingFile.computeFileSize();\n        onRetryBlock[0] \u003d makeLocatedBlock(lastBlockInFile,\n            ((BlockInfoUnderConstruction)lastBlockInFile).getExpectedLocations(),\n            offset);\n        return iip;\n      } else {\n        // Case 3\n        throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n            \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n            \"last block in file \" + lastBlockInFile);\n      }\n    }\n\n    // Check if the penultimate block is minimally replicated\n    if (!checkFileProgress(pendingFile, false)) {\n      throw new NotReplicatedYetException(\"Not replicated yet: \" + src);\n    }\n    return iip;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "fac3883188d9c4f1fe188d98f88cb3c83b243bbd": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4503. Update computeContentSummary(..), spaceConsumedInTree(..) and diskspaceConsumed(..) in INode for snapshot.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2802@1448373 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/02/13 12:02 PM",
      "commitName": "fac3883188d9c4f1fe188d98f88cb3c83b243bbd",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "15/02/13 2:57 AM",
      "commitNameOld": "a9f6a27e9372436f91ae9a9392528bb02801b5bb",
      "commitAuthorOld": "",
      "daysBetweenCommits": 5.38,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,95 +1,95 @@\n   INodesInPath analyzeFileState(String src,\n                                 long fileId,\n                                 String clientName,\n                                 ExtendedBlock previous,\n                                 LocatedBlock[] onRetryBlock)\n           throws IOException  {\n     assert hasReadOrWriteLock();\n \n     checkBlock(previous);\n     onRetryBlock[0] \u003d null;\n     checkOperation(OperationCategory.WRITE);\n     if (isInSafeMode()) {\n       throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n     }\n \n     // have we exceeded the configured limit of fs objects.\n     checkFsObjectLimit();\n \n     Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n     final INodesInPath inodesInPath \u003d dir.getINodesInPath4Write(src);\n     final INode[] inodes \u003d inodesInPath.getINodes();\n     final INodeFileUnderConstruction pendingFile\n         \u003d checkLease(src, fileId, clientName, inodes[inodes.length - 1]);\n     BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n     if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n       // The block that the client claims is the current last block\n       // doesn\u0027t match up with what we think is the last block. There are\n       // four possibilities:\n       // 1) This is the first block allocation of an append() pipeline\n       //    which started appending exactly at a block boundary.\n       //    In this case, the client isn\u0027t passed the previous block,\n       //    so it makes the allocateBlock() call with previous\u003dnull.\n       //    We can distinguish this since the last block of the file\n       //    will be exactly a full block.\n       // 2) This is a retry from a client that missed the response of a\n       //    prior getAdditionalBlock() call, perhaps because of a network\n       //    timeout, or because of an HA failover. In that case, we know\n       //    by the fact that the client is re-issuing the RPC that it\n       //    never began to write to the old block. Hence it is safe to\n       //    to return the existing block.\n       // 3) This is an entirely bogus request/bug -- we should error out\n       //    rather than potentially appending a new block with an empty\n       //    one in the middle, etc\n       // 4) This is a retry from a client that timed out while\n       //    the prior getAdditionalBlock() is still being processed,\n       //    currently working on chooseTarget(). \n       //    There are no means to distinguish between the first and \n       //    the second attempts in Part I, because the first one hasn\u0027t\n       //    changed the namesystem state yet.\n       //    We run this analysis again in Part II where case 4 is impossible.\n \n       BlockInfo penultimateBlock \u003d pendingFile.getPenultimateBlock();\n       if (previous \u003d\u003d null \u0026\u0026\n           lastBlockInFile !\u003d null \u0026\u0026\n           lastBlockInFile.getNumBytes() \u003d\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n           lastBlockInFile.isComplete()) {\n         // Case 1\n         if (NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\n                \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n                \" writing to a file with a complete previous block: src\u003d\" +\n                src + \" lastBlock\u003d\" + lastBlockInFile);\n         }\n       } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n         if (lastBlockInFile.getNumBytes() !\u003d 0) {\n           throw new IOException(\n               \"Request looked like a retry to allocate block \" +\n               lastBlockInFile + \" but it already contains \" +\n               lastBlockInFile.getNumBytes() + \" bytes\");\n         }\n \n         // Case 2\n         // Return the last block.\n         NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: \" +\n             \"caught retry for allocation of a new block in \" +\n             src + \". Returning previously allocated block \" + lastBlockInFile);\n-        long offset \u003d pendingFile.computeFileSize(true);\n+        long offset \u003d pendingFile.computeFileSize();\n         onRetryBlock[0] \u003d makeLocatedBlock(lastBlockInFile,\n             ((BlockInfoUnderConstruction)lastBlockInFile).getExpectedLocations(),\n             offset);\n         return inodesInPath;\n       } else {\n         // Case 3\n         throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n             \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n             \"last block in file \" + lastBlockInFile);\n       }\n     }\n \n     // Check if the penultimate block is minimally replicated\n     if (!checkFileProgress(pendingFile, false)) {\n       throw new NotReplicatedYetException(\"Not replicated yet: \" + src);\n     }\n     return inodesInPath;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  INodesInPath analyzeFileState(String src,\n                                long fileId,\n                                String clientName,\n                                ExtendedBlock previous,\n                                LocatedBlock[] onRetryBlock)\n          throws IOException  {\n    assert hasReadOrWriteLock();\n\n    checkBlock(previous);\n    onRetryBlock[0] \u003d null;\n    checkOperation(OperationCategory.WRITE);\n    if (isInSafeMode()) {\n      throw new SafeModeException(\"Cannot add block to \" + src, safeMode);\n    }\n\n    // have we exceeded the configured limit of fs objects.\n    checkFsObjectLimit();\n\n    Block previousBlock \u003d ExtendedBlock.getLocalBlock(previous);\n    final INodesInPath inodesInPath \u003d dir.getINodesInPath4Write(src);\n    final INode[] inodes \u003d inodesInPath.getINodes();\n    final INodeFileUnderConstruction pendingFile\n        \u003d checkLease(src, fileId, clientName, inodes[inodes.length - 1]);\n    BlockInfo lastBlockInFile \u003d pendingFile.getLastBlock();\n    if (!Block.matchingIdAndGenStamp(previousBlock, lastBlockInFile)) {\n      // The block that the client claims is the current last block\n      // doesn\u0027t match up with what we think is the last block. There are\n      // four possibilities:\n      // 1) This is the first block allocation of an append() pipeline\n      //    which started appending exactly at a block boundary.\n      //    In this case, the client isn\u0027t passed the previous block,\n      //    so it makes the allocateBlock() call with previous\u003dnull.\n      //    We can distinguish this since the last block of the file\n      //    will be exactly a full block.\n      // 2) This is a retry from a client that missed the response of a\n      //    prior getAdditionalBlock() call, perhaps because of a network\n      //    timeout, or because of an HA failover. In that case, we know\n      //    by the fact that the client is re-issuing the RPC that it\n      //    never began to write to the old block. Hence it is safe to\n      //    to return the existing block.\n      // 3) This is an entirely bogus request/bug -- we should error out\n      //    rather than potentially appending a new block with an empty\n      //    one in the middle, etc\n      // 4) This is a retry from a client that timed out while\n      //    the prior getAdditionalBlock() is still being processed,\n      //    currently working on chooseTarget(). \n      //    There are no means to distinguish between the first and \n      //    the second attempts in Part I, because the first one hasn\u0027t\n      //    changed the namesystem state yet.\n      //    We run this analysis again in Part II where case 4 is impossible.\n\n      BlockInfo penultimateBlock \u003d pendingFile.getPenultimateBlock();\n      if (previous \u003d\u003d null \u0026\u0026\n          lastBlockInFile !\u003d null \u0026\u0026\n          lastBlockInFile.getNumBytes() \u003d\u003d pendingFile.getPreferredBlockSize() \u0026\u0026\n          lastBlockInFile.isComplete()) {\n        // Case 1\n        if (NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\n               \"BLOCK* NameSystem.allocateBlock: handling block allocation\" +\n               \" writing to a file with a complete previous block: src\u003d\" +\n               src + \" lastBlock\u003d\" + lastBlockInFile);\n        }\n      } else if (Block.matchingIdAndGenStamp(penultimateBlock, previousBlock)) {\n        if (lastBlockInFile.getNumBytes() !\u003d 0) {\n          throw new IOException(\n              \"Request looked like a retry to allocate block \" +\n              lastBlockInFile + \" but it already contains \" +\n              lastBlockInFile.getNumBytes() + \" bytes\");\n        }\n\n        // Case 2\n        // Return the last block.\n        NameNode.stateChangeLog.info(\"BLOCK* allocateBlock: \" +\n            \"caught retry for allocation of a new block in \" +\n            src + \". Returning previously allocated block \" + lastBlockInFile);\n        long offset \u003d pendingFile.computeFileSize();\n        onRetryBlock[0] \u003d makeLocatedBlock(lastBlockInFile,\n            ((BlockInfoUnderConstruction)lastBlockInFile).getExpectedLocations(),\n            offset);\n        return inodesInPath;\n      } else {\n        // Case 3\n        throw new IOException(\"Cannot allocate block in \" + src + \": \" +\n            \"passed \u0027previous\u0027 block \" + previous + \" does not match actual \" +\n            \"last block in file \" + lastBlockInFile);\n      }\n    }\n\n    // Check if the penultimate block is minimally replicated\n    if (!checkFileProgress(pendingFile, false)) {\n      throw new NotReplicatedYetException(\"Not replicated yet: \" + src);\n    }\n    return inodesInPath;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    }
  }
}