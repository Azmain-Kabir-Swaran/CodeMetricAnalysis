{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ContentSummaryComputationContext.java",
  "functionName": "yield",
  "functionId": "yield",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ContentSummaryComputationContext.java",
  "functionStartLine": 101,
  "functionEndLine": 146,
  "numCommitsSeen": 17,
  "timeTaken": 3004,
  "changeHistory": [
    "b8b69d797aed8dfeb65ea462c2856f62e9aa1023",
    "ff0b99eafeda035ebe0dc82cfe689808047a8893",
    "6a38d118d86b7907009bcec34f1b788d076f1d1c",
    "285b31e75e51ec8e3a796c2cb0208739368ca9b8",
    "3d0708bdb0a75af3d87bbac9f6c4ffbcabab98ca",
    "fe67e30bc2794e7ff073cf938ee80eba805d1e69"
  ],
  "changeHistoryShort": {
    "b8b69d797aed8dfeb65ea462c2856f62e9aa1023": "Ybodychange",
    "ff0b99eafeda035ebe0dc82cfe689808047a8893": "Ybodychange",
    "6a38d118d86b7907009bcec34f1b788d076f1d1c": "Ybodychange",
    "285b31e75e51ec8e3a796c2cb0208739368ca9b8": "Ybodychange",
    "3d0708bdb0a75af3d87bbac9f6c4ffbcabab98ca": "Ybodychange",
    "fe67e30bc2794e7ff073cf938ee80eba805d1e69": "Yintroduced"
  },
  "changeHistoryDetails": {
    "b8b69d797aed8dfeb65ea462c2856f62e9aa1023": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-10797. Disk usage summary of snapshots causes renamed blocks to get counted twice. Contributed by Sean Mackrory.\"\n\nThis reverts commit 6a38d118d86b7907009bcec34f1b788d076f1d1c.\n",
      "commitDate": "24/05/17 5:21 PM",
      "commitName": "b8b69d797aed8dfeb65ea462c2856f62e9aa1023",
      "commitAuthor": "Wei-Chiu Chuang",
      "commitDateOld": "14/11/16 11:05 AM",
      "commitNameOld": "ff0b99eafeda035ebe0dc82cfe689808047a8893",
      "commitAuthorOld": "Zhe Zhang",
      "daysBetweenCommits": 191.22,
      "commitsBetweenForRepo": 1036,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,47 +1,46 @@\n   public boolean yield() {\n     // Are we set up to do this?\n     if (limitPerRun \u003c\u003d 0 || dir \u003d\u003d null || fsn \u003d\u003d null) {\n       return false;\n     }\n \n     // Have we reached the limit?\n-    ContentCounts counts \u003d getCounts();\n     long currentCount \u003d counts.getFileCount() +\n         counts.getSymlinkCount() +\n         counts.getDirectoryCount() +\n         counts.getSnapshotableDirectoryCount();\n     if (currentCount \u003c\u003d nextCountLimit) {\n       return false;\n     }\n \n     // Update the next limit\n     nextCountLimit \u003d currentCount + limitPerRun;\n \n     boolean hadDirReadLock \u003d dir.hasReadLock();\n     boolean hadDirWriteLock \u003d dir.hasWriteLock();\n     boolean hadFsnReadLock \u003d fsn.hasReadLock();\n     boolean hadFsnWriteLock \u003d fsn.hasWriteLock();\n \n     // sanity check.\n     if (!hadDirReadLock || !hadFsnReadLock || hadDirWriteLock ||\n         hadFsnWriteLock || dir.getReadHoldCount() !\u003d 1 ||\n         fsn.getReadHoldCount() !\u003d 1) {\n       // cannot relinquish\n       return false;\n     }\n \n     // unlock\n     dir.readUnlock();\n     fsn.readUnlock(\"contentSummary\");\n \n     try {\n       Thread.sleep(sleepMilliSec, sleepNanoSec);\n     } catch (InterruptedException ie) {\n     } finally {\n       // reacquire\n       fsn.readLock();\n       dir.readLock();\n     }\n     yieldCount++;\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean yield() {\n    // Are we set up to do this?\n    if (limitPerRun \u003c\u003d 0 || dir \u003d\u003d null || fsn \u003d\u003d null) {\n      return false;\n    }\n\n    // Have we reached the limit?\n    long currentCount \u003d counts.getFileCount() +\n        counts.getSymlinkCount() +\n        counts.getDirectoryCount() +\n        counts.getSnapshotableDirectoryCount();\n    if (currentCount \u003c\u003d nextCountLimit) {\n      return false;\n    }\n\n    // Update the next limit\n    nextCountLimit \u003d currentCount + limitPerRun;\n\n    boolean hadDirReadLock \u003d dir.hasReadLock();\n    boolean hadDirWriteLock \u003d dir.hasWriteLock();\n    boolean hadFsnReadLock \u003d fsn.hasReadLock();\n    boolean hadFsnWriteLock \u003d fsn.hasWriteLock();\n\n    // sanity check.\n    if (!hadDirReadLock || !hadFsnReadLock || hadDirWriteLock ||\n        hadFsnWriteLock || dir.getReadHoldCount() !\u003d 1 ||\n        fsn.getReadHoldCount() !\u003d 1) {\n      // cannot relinquish\n      return false;\n    }\n\n    // unlock\n    dir.readUnlock();\n    fsn.readUnlock(\"contentSummary\");\n\n    try {\n      Thread.sleep(sleepMilliSec, sleepNanoSec);\n    } catch (InterruptedException ie) {\n    } finally {\n      // reacquire\n      fsn.readLock();\n      dir.readLock();\n    }\n    yieldCount++;\n    return true;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ContentSummaryComputationContext.java",
      "extendedDetails": {}
    },
    "ff0b99eafeda035ebe0dc82cfe689808047a8893": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10872. Add MutableRate metrics for FSNamesystemLock operations. Contributed by Erik Krogen.\n",
      "commitDate": "14/11/16 11:05 AM",
      "commitName": "ff0b99eafeda035ebe0dc82cfe689808047a8893",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "07/10/16 5:37 PM",
      "commitNameOld": "6a38d118d86b7907009bcec34f1b788d076f1d1c",
      "commitAuthorOld": "Xiao Chen",
      "daysBetweenCommits": 37.77,
      "commitsBetweenForRepo": 336,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,47 +1,47 @@\n   public boolean yield() {\n     // Are we set up to do this?\n     if (limitPerRun \u003c\u003d 0 || dir \u003d\u003d null || fsn \u003d\u003d null) {\n       return false;\n     }\n \n     // Have we reached the limit?\n     ContentCounts counts \u003d getCounts();\n     long currentCount \u003d counts.getFileCount() +\n         counts.getSymlinkCount() +\n         counts.getDirectoryCount() +\n         counts.getSnapshotableDirectoryCount();\n     if (currentCount \u003c\u003d nextCountLimit) {\n       return false;\n     }\n \n     // Update the next limit\n     nextCountLimit \u003d currentCount + limitPerRun;\n \n     boolean hadDirReadLock \u003d dir.hasReadLock();\n     boolean hadDirWriteLock \u003d dir.hasWriteLock();\n     boolean hadFsnReadLock \u003d fsn.hasReadLock();\n     boolean hadFsnWriteLock \u003d fsn.hasWriteLock();\n \n     // sanity check.\n     if (!hadDirReadLock || !hadFsnReadLock || hadDirWriteLock ||\n         hadFsnWriteLock || dir.getReadHoldCount() !\u003d 1 ||\n         fsn.getReadHoldCount() !\u003d 1) {\n       // cannot relinquish\n       return false;\n     }\n \n     // unlock\n     dir.readUnlock();\n-    fsn.readUnlock();\n+    fsn.readUnlock(\"contentSummary\");\n \n     try {\n       Thread.sleep(sleepMilliSec, sleepNanoSec);\n     } catch (InterruptedException ie) {\n     } finally {\n       // reacquire\n       fsn.readLock();\n       dir.readLock();\n     }\n     yieldCount++;\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean yield() {\n    // Are we set up to do this?\n    if (limitPerRun \u003c\u003d 0 || dir \u003d\u003d null || fsn \u003d\u003d null) {\n      return false;\n    }\n\n    // Have we reached the limit?\n    ContentCounts counts \u003d getCounts();\n    long currentCount \u003d counts.getFileCount() +\n        counts.getSymlinkCount() +\n        counts.getDirectoryCount() +\n        counts.getSnapshotableDirectoryCount();\n    if (currentCount \u003c\u003d nextCountLimit) {\n      return false;\n    }\n\n    // Update the next limit\n    nextCountLimit \u003d currentCount + limitPerRun;\n\n    boolean hadDirReadLock \u003d dir.hasReadLock();\n    boolean hadDirWriteLock \u003d dir.hasWriteLock();\n    boolean hadFsnReadLock \u003d fsn.hasReadLock();\n    boolean hadFsnWriteLock \u003d fsn.hasWriteLock();\n\n    // sanity check.\n    if (!hadDirReadLock || !hadFsnReadLock || hadDirWriteLock ||\n        hadFsnWriteLock || dir.getReadHoldCount() !\u003d 1 ||\n        fsn.getReadHoldCount() !\u003d 1) {\n      // cannot relinquish\n      return false;\n    }\n\n    // unlock\n    dir.readUnlock();\n    fsn.readUnlock(\"contentSummary\");\n\n    try {\n      Thread.sleep(sleepMilliSec, sleepNanoSec);\n    } catch (InterruptedException ie) {\n    } finally {\n      // reacquire\n      fsn.readLock();\n      dir.readLock();\n    }\n    yieldCount++;\n    return true;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ContentSummaryComputationContext.java",
      "extendedDetails": {}
    },
    "6a38d118d86b7907009bcec34f1b788d076f1d1c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10797. Disk usage summary of snapshots causes renamed blocks to get counted twice. Contributed by Sean Mackrory.\n",
      "commitDate": "07/10/16 5:37 PM",
      "commitName": "6a38d118d86b7907009bcec34f1b788d076f1d1c",
      "commitAuthor": "Xiao Chen",
      "commitDateOld": "23/08/16 4:14 AM",
      "commitNameOld": "f0efea490e5aa9dd629d2199aae9c5b1290a17ee",
      "commitAuthorOld": "Wei-Chiu Chuang",
      "daysBetweenCommits": 45.56,
      "commitsBetweenForRepo": 281,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,46 +1,47 @@\n   public boolean yield() {\n     // Are we set up to do this?\n     if (limitPerRun \u003c\u003d 0 || dir \u003d\u003d null || fsn \u003d\u003d null) {\n       return false;\n     }\n \n     // Have we reached the limit?\n+    ContentCounts counts \u003d getCounts();\n     long currentCount \u003d counts.getFileCount() +\n         counts.getSymlinkCount() +\n         counts.getDirectoryCount() +\n         counts.getSnapshotableDirectoryCount();\n     if (currentCount \u003c\u003d nextCountLimit) {\n       return false;\n     }\n \n     // Update the next limit\n     nextCountLimit \u003d currentCount + limitPerRun;\n \n     boolean hadDirReadLock \u003d dir.hasReadLock();\n     boolean hadDirWriteLock \u003d dir.hasWriteLock();\n     boolean hadFsnReadLock \u003d fsn.hasReadLock();\n     boolean hadFsnWriteLock \u003d fsn.hasWriteLock();\n \n     // sanity check.\n     if (!hadDirReadLock || !hadFsnReadLock || hadDirWriteLock ||\n         hadFsnWriteLock || dir.getReadHoldCount() !\u003d 1 ||\n         fsn.getReadHoldCount() !\u003d 1) {\n       // cannot relinquish\n       return false;\n     }\n \n     // unlock\n     dir.readUnlock();\n     fsn.readUnlock();\n \n     try {\n       Thread.sleep(sleepMilliSec, sleepNanoSec);\n     } catch (InterruptedException ie) {\n     } finally {\n       // reacquire\n       fsn.readLock();\n       dir.readLock();\n     }\n     yieldCount++;\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean yield() {\n    // Are we set up to do this?\n    if (limitPerRun \u003c\u003d 0 || dir \u003d\u003d null || fsn \u003d\u003d null) {\n      return false;\n    }\n\n    // Have we reached the limit?\n    ContentCounts counts \u003d getCounts();\n    long currentCount \u003d counts.getFileCount() +\n        counts.getSymlinkCount() +\n        counts.getDirectoryCount() +\n        counts.getSnapshotableDirectoryCount();\n    if (currentCount \u003c\u003d nextCountLimit) {\n      return false;\n    }\n\n    // Update the next limit\n    nextCountLimit \u003d currentCount + limitPerRun;\n\n    boolean hadDirReadLock \u003d dir.hasReadLock();\n    boolean hadDirWriteLock \u003d dir.hasWriteLock();\n    boolean hadFsnReadLock \u003d fsn.hasReadLock();\n    boolean hadFsnWriteLock \u003d fsn.hasWriteLock();\n\n    // sanity check.\n    if (!hadDirReadLock || !hadFsnReadLock || hadDirWriteLock ||\n        hadFsnWriteLock || dir.getReadHoldCount() !\u003d 1 ||\n        fsn.getReadHoldCount() !\u003d 1) {\n      // cannot relinquish\n      return false;\n    }\n\n    // unlock\n    dir.readUnlock();\n    fsn.readUnlock();\n\n    try {\n      Thread.sleep(sleepMilliSec, sleepNanoSec);\n    } catch (InterruptedException ie) {\n    } finally {\n      // reacquire\n      fsn.readLock();\n      dir.readLock();\n    }\n    yieldCount++;\n    return true;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ContentSummaryComputationContext.java",
      "extendedDetails": {}
    },
    "285b31e75e51ec8e3a796c2cb0208739368ca9b8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8046. Allow better control of getContentSummary. Contributed by Kihwal Lee.\n",
      "commitDate": "08/04/15 1:38 PM",
      "commitName": "285b31e75e51ec8e3a796c2cb0208739368ca9b8",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "26/03/15 10:24 AM",
      "commitNameOld": "3d0708bdb0a75af3d87bbac9f6c4ffbcabab98ca",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 13.13,
      "commitsBetweenForRepo": 105,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,46 +1,46 @@\n   public boolean yield() {\n     // Are we set up to do this?\n     if (limitPerRun \u003c\u003d 0 || dir \u003d\u003d null || fsn \u003d\u003d null) {\n       return false;\n     }\n \n     // Have we reached the limit?\n     long currentCount \u003d counts.getFileCount() +\n         counts.getSymlinkCount() +\n         counts.getDirectoryCount() +\n         counts.getSnapshotableDirectoryCount();\n     if (currentCount \u003c\u003d nextCountLimit) {\n       return false;\n     }\n \n     // Update the next limit\n     nextCountLimit \u003d currentCount + limitPerRun;\n \n     boolean hadDirReadLock \u003d dir.hasReadLock();\n     boolean hadDirWriteLock \u003d dir.hasWriteLock();\n     boolean hadFsnReadLock \u003d fsn.hasReadLock();\n     boolean hadFsnWriteLock \u003d fsn.hasWriteLock();\n \n     // sanity check.\n     if (!hadDirReadLock || !hadFsnReadLock || hadDirWriteLock ||\n         hadFsnWriteLock || dir.getReadHoldCount() !\u003d 1 ||\n         fsn.getReadHoldCount() !\u003d 1) {\n       // cannot relinquish\n       return false;\n     }\n \n     // unlock\n     dir.readUnlock();\n     fsn.readUnlock();\n \n     try {\n-      Thread.sleep(1);\n+      Thread.sleep(sleepMilliSec, sleepNanoSec);\n     } catch (InterruptedException ie) {\n     } finally {\n       // reacquire\n       fsn.readLock();\n       dir.readLock();\n     }\n     yieldCount++;\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean yield() {\n    // Are we set up to do this?\n    if (limitPerRun \u003c\u003d 0 || dir \u003d\u003d null || fsn \u003d\u003d null) {\n      return false;\n    }\n\n    // Have we reached the limit?\n    long currentCount \u003d counts.getFileCount() +\n        counts.getSymlinkCount() +\n        counts.getDirectoryCount() +\n        counts.getSnapshotableDirectoryCount();\n    if (currentCount \u003c\u003d nextCountLimit) {\n      return false;\n    }\n\n    // Update the next limit\n    nextCountLimit \u003d currentCount + limitPerRun;\n\n    boolean hadDirReadLock \u003d dir.hasReadLock();\n    boolean hadDirWriteLock \u003d dir.hasWriteLock();\n    boolean hadFsnReadLock \u003d fsn.hasReadLock();\n    boolean hadFsnWriteLock \u003d fsn.hasWriteLock();\n\n    // sanity check.\n    if (!hadDirReadLock || !hadFsnReadLock || hadDirWriteLock ||\n        hadFsnWriteLock || dir.getReadHoldCount() !\u003d 1 ||\n        fsn.getReadHoldCount() !\u003d 1) {\n      // cannot relinquish\n      return false;\n    }\n\n    // unlock\n    dir.readUnlock();\n    fsn.readUnlock();\n\n    try {\n      Thread.sleep(sleepMilliSec, sleepNanoSec);\n    } catch (InterruptedException ie) {\n    } finally {\n      // reacquire\n      fsn.readLock();\n      dir.readLock();\n    }\n    yieldCount++;\n    return true;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ContentSummaryComputationContext.java",
      "extendedDetails": {}
    },
    "3d0708bdb0a75af3d87bbac9f6c4ffbcabab98ca": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7824. GetContentSummary API and its namenode implementation for Storage Type Quota/Usage. (Contributed by Xiaoyu Yao)\n",
      "commitDate": "26/03/15 10:24 AM",
      "commitName": "3d0708bdb0a75af3d87bbac9f6c4ffbcabab98ca",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "11/02/15 10:41 AM",
      "commitNameOld": "5dae97a584d30cef3e34141edfaca49c4ec57913",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 42.95,
      "commitsBetweenForRepo": 409,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,46 +1,46 @@\n   public boolean yield() {\n     // Are we set up to do this?\n     if (limitPerRun \u003c\u003d 0 || dir \u003d\u003d null || fsn \u003d\u003d null) {\n       return false;\n     }\n \n     // Have we reached the limit?\n-    long currentCount \u003d counts.get(Content.FILE) +\n-        counts.get(Content.SYMLINK) +\n-        counts.get(Content.DIRECTORY) +\n-        counts.get(Content.SNAPSHOTTABLE_DIRECTORY);\n+    long currentCount \u003d counts.getFileCount() +\n+        counts.getSymlinkCount() +\n+        counts.getDirectoryCount() +\n+        counts.getSnapshotableDirectoryCount();\n     if (currentCount \u003c\u003d nextCountLimit) {\n       return false;\n     }\n \n     // Update the next limit\n     nextCountLimit \u003d currentCount + limitPerRun;\n \n     boolean hadDirReadLock \u003d dir.hasReadLock();\n     boolean hadDirWriteLock \u003d dir.hasWriteLock();\n     boolean hadFsnReadLock \u003d fsn.hasReadLock();\n     boolean hadFsnWriteLock \u003d fsn.hasWriteLock();\n \n     // sanity check.\n     if (!hadDirReadLock || !hadFsnReadLock || hadDirWriteLock ||\n         hadFsnWriteLock || dir.getReadHoldCount() !\u003d 1 ||\n         fsn.getReadHoldCount() !\u003d 1) {\n       // cannot relinquish\n       return false;\n     }\n \n     // unlock\n     dir.readUnlock();\n     fsn.readUnlock();\n \n     try {\n       Thread.sleep(1);\n     } catch (InterruptedException ie) {\n     } finally {\n       // reacquire\n       fsn.readLock();\n       dir.readLock();\n     }\n     yieldCount++;\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean yield() {\n    // Are we set up to do this?\n    if (limitPerRun \u003c\u003d 0 || dir \u003d\u003d null || fsn \u003d\u003d null) {\n      return false;\n    }\n\n    // Have we reached the limit?\n    long currentCount \u003d counts.getFileCount() +\n        counts.getSymlinkCount() +\n        counts.getDirectoryCount() +\n        counts.getSnapshotableDirectoryCount();\n    if (currentCount \u003c\u003d nextCountLimit) {\n      return false;\n    }\n\n    // Update the next limit\n    nextCountLimit \u003d currentCount + limitPerRun;\n\n    boolean hadDirReadLock \u003d dir.hasReadLock();\n    boolean hadDirWriteLock \u003d dir.hasWriteLock();\n    boolean hadFsnReadLock \u003d fsn.hasReadLock();\n    boolean hadFsnWriteLock \u003d fsn.hasWriteLock();\n\n    // sanity check.\n    if (!hadDirReadLock || !hadFsnReadLock || hadDirWriteLock ||\n        hadFsnWriteLock || dir.getReadHoldCount() !\u003d 1 ||\n        fsn.getReadHoldCount() !\u003d 1) {\n      // cannot relinquish\n      return false;\n    }\n\n    // unlock\n    dir.readUnlock();\n    fsn.readUnlock();\n\n    try {\n      Thread.sleep(1);\n    } catch (InterruptedException ie) {\n    } finally {\n      // reacquire\n      fsn.readLock();\n      dir.readLock();\n    }\n    yieldCount++;\n    return true;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ContentSummaryComputationContext.java",
      "extendedDetails": {}
    },
    "fe67e30bc2794e7ff073cf938ee80eba805d1e69": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-4995. Make getContentSummary less expensive. Contributed by Kihwal Lee.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1541971 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/11/13 8:49 AM",
      "commitName": "fe67e30bc2794e7ff073cf938ee80eba805d1e69",
      "commitAuthor": "Kihwal Lee",
      "diff": "@@ -0,0 +1,46 @@\n+  public boolean yield() {\n+    // Are we set up to do this?\n+    if (limitPerRun \u003c\u003d 0 || dir \u003d\u003d null || fsn \u003d\u003d null) {\n+      return false;\n+    }\n+\n+    // Have we reached the limit?\n+    long currentCount \u003d counts.get(Content.FILE) +\n+        counts.get(Content.SYMLINK) +\n+        counts.get(Content.DIRECTORY) +\n+        counts.get(Content.SNAPSHOTTABLE_DIRECTORY);\n+    if (currentCount \u003c\u003d nextCountLimit) {\n+      return false;\n+    }\n+\n+    // Update the next limit\n+    nextCountLimit \u003d currentCount + limitPerRun;\n+\n+    boolean hadDirReadLock \u003d dir.hasReadLock();\n+    boolean hadDirWriteLock \u003d dir.hasWriteLock();\n+    boolean hadFsnReadLock \u003d fsn.hasReadLock();\n+    boolean hadFsnWriteLock \u003d fsn.hasWriteLock();\n+\n+    // sanity check.\n+    if (!hadDirReadLock || !hadFsnReadLock || hadDirWriteLock ||\n+        hadFsnWriteLock || dir.getReadHoldCount() !\u003d 1 ||\n+        fsn.getReadHoldCount() !\u003d 1) {\n+      // cannot relinquish\n+      return false;\n+    }\n+\n+    // unlock\n+    dir.readUnlock();\n+    fsn.readUnlock();\n+\n+    try {\n+      Thread.sleep(1);\n+    } catch (InterruptedException ie) {\n+    } finally {\n+      // reacquire\n+      fsn.readLock();\n+      dir.readLock();\n+    }\n+    yieldCount++;\n+    return true;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean yield() {\n    // Are we set up to do this?\n    if (limitPerRun \u003c\u003d 0 || dir \u003d\u003d null || fsn \u003d\u003d null) {\n      return false;\n    }\n\n    // Have we reached the limit?\n    long currentCount \u003d counts.get(Content.FILE) +\n        counts.get(Content.SYMLINK) +\n        counts.get(Content.DIRECTORY) +\n        counts.get(Content.SNAPSHOTTABLE_DIRECTORY);\n    if (currentCount \u003c\u003d nextCountLimit) {\n      return false;\n    }\n\n    // Update the next limit\n    nextCountLimit \u003d currentCount + limitPerRun;\n\n    boolean hadDirReadLock \u003d dir.hasReadLock();\n    boolean hadDirWriteLock \u003d dir.hasWriteLock();\n    boolean hadFsnReadLock \u003d fsn.hasReadLock();\n    boolean hadFsnWriteLock \u003d fsn.hasWriteLock();\n\n    // sanity check.\n    if (!hadDirReadLock || !hadFsnReadLock || hadDirWriteLock ||\n        hadFsnWriteLock || dir.getReadHoldCount() !\u003d 1 ||\n        fsn.getReadHoldCount() !\u003d 1) {\n      // cannot relinquish\n      return false;\n    }\n\n    // unlock\n    dir.readUnlock();\n    fsn.readUnlock();\n\n    try {\n      Thread.sleep(1);\n    } catch (InterruptedException ie) {\n    } finally {\n      // reacquire\n      fsn.readLock();\n      dir.readLock();\n    }\n    yieldCount++;\n    return true;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ContentSummaryComputationContext.java"
    }
  }
}