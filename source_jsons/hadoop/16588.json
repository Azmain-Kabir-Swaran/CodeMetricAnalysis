{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "RouterRpcServer.java",
  "functionName": "getAdditionalDatanode",
  "functionId": "getAdditionalDatanode___src-String(modifiers-final)__fileId-long(modifiers-final)__blk-ExtendedBlock(modifiers-final)__existings-DatanodeInfo[](modifiers-final)__existingStorageIDs-String[](modifiers-final)__excludes-DatanodeInfo[](modifiers-final)__numAdditionalNodes-int(modifiers-final)__clientName-String(modifiers-final)",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcServer.java",
  "functionStartLine": 742,
  "functionEndLine": 749,
  "numCommitsSeen": 75,
  "timeTaken": 4335,
  "changeHistory": [
    "6425ed27ea638da75f656204d6df4adad1d91fe1",
    "fb5b3dce6192265bce9b9d93ab663bdc5be8048e",
    "fa121eb66bc42e9cb5586f8c2e268cfdc2ed187a",
    "6e2b5fa493ff8e8c2bb28e6f6f4c19347bc9b99d",
    "ca4f209b49e3aad6a80306f7342c9b6b560a79a7"
  ],
  "changeHistoryShort": {
    "6425ed27ea638da75f656204d6df4adad1d91fe1": "Ybodychange",
    "fb5b3dce6192265bce9b9d93ab663bdc5be8048e": "Ybodychange",
    "fa121eb66bc42e9cb5586f8c2e268cfdc2ed187a": "Ybodychange",
    "6e2b5fa493ff8e8c2bb28e6f6f4c19347bc9b99d": "Yfilerename",
    "ca4f209b49e3aad6a80306f7342c9b6b560a79a7": "Yintroduced"
  },
  "changeHistoryDetails": {
    "6425ed27ea638da75f656204d6df4adad1d91fe1": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13790. RBF: Move ClientProtocol APIs to its own module. Contributed by Chao Sun.\n",
      "commitDate": "19/08/18 11:50 PM",
      "commitName": "6425ed27ea638da75f656204d6df4adad1d91fe1",
      "commitAuthor": "Brahma Reddy Battula",
      "commitDateOld": "17/08/18 8:01 AM",
      "commitNameOld": "fb5b3dce6192265bce9b9d93ab663bdc5be8048e",
      "commitAuthorOld": "Xiaoyu Yao",
      "daysBetweenCommits": 2.66,
      "commitsBetweenForRepo": 8,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,8 @@\n   public LocatedBlock getAdditionalDatanode(final String src, final long fileId,\n       final ExtendedBlock blk, final DatanodeInfo[] existings,\n       final String[] existingStorageIDs, final DatanodeInfo[] excludes,\n       final int numAdditionalNodes, final String clientName)\n           throws IOException {\n-    checkOperation(OperationCategory.READ);\n-\n-    final List\u003cRemoteLocation\u003e locations \u003d getLocationsForPath(src, false);\n-    RemoteMethod method \u003d new RemoteMethod(\"getAdditionalDatanode\",\n-        new Class\u003c?\u003e[] {String.class, long.class, ExtendedBlock.class,\n-                        DatanodeInfo[].class, String[].class,\n-                        DatanodeInfo[].class, int.class, String.class},\n-        new RemoteParam(), fileId, blk, existings, existingStorageIDs, excludes,\n-        numAdditionalNodes, clientName);\n-    return (LocatedBlock) rpcClient.invokeSequential(\n-        locations, method, LocatedBlock.class, null);\n+    return clientProto.getAdditionalDatanode(src, fileId, blk, existings,\n+        existingStorageIDs, excludes, numAdditionalNodes, clientName);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public LocatedBlock getAdditionalDatanode(final String src, final long fileId,\n      final ExtendedBlock blk, final DatanodeInfo[] existings,\n      final String[] existingStorageIDs, final DatanodeInfo[] excludes,\n      final int numAdditionalNodes, final String clientName)\n          throws IOException {\n    return clientProto.getAdditionalDatanode(src, fileId, blk, existings,\n        existingStorageIDs, excludes, numAdditionalNodes, clientName);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcServer.java",
      "extendedDetails": {}
    },
    "fb5b3dce6192265bce9b9d93ab663bdc5be8048e": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-13790. RBF: Move ClientProtocol APIs to its own module. Contributed by Chao Sun.\"\n\nThis reverts commit fa121eb66bc42e9cb5586f8c2e268cfdc2ed187a.\n",
      "commitDate": "17/08/18 8:01 AM",
      "commitName": "fb5b3dce6192265bce9b9d93ab663bdc5be8048e",
      "commitAuthor": "Xiaoyu Yao",
      "commitDateOld": "17/08/18 2:52 AM",
      "commitNameOld": "fa121eb66bc42e9cb5586f8c2e268cfdc2ed187a",
      "commitAuthorOld": "Brahma Reddy Battula",
      "daysBetweenCommits": 0.21,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,8 +1,17 @@\n   public LocatedBlock getAdditionalDatanode(final String src, final long fileId,\n       final ExtendedBlock blk, final DatanodeInfo[] existings,\n       final String[] existingStorageIDs, final DatanodeInfo[] excludes,\n       final int numAdditionalNodes, final String clientName)\n           throws IOException {\n-    return clientProto.getAdditionalDatanode(src, fileId, blk, existings,\n-        existingStorageIDs, excludes, numAdditionalNodes, clientName);\n+    checkOperation(OperationCategory.READ);\n+\n+    final List\u003cRemoteLocation\u003e locations \u003d getLocationsForPath(src, false);\n+    RemoteMethod method \u003d new RemoteMethod(\"getAdditionalDatanode\",\n+        new Class\u003c?\u003e[] {String.class, long.class, ExtendedBlock.class,\n+                        DatanodeInfo[].class, String[].class,\n+                        DatanodeInfo[].class, int.class, String.class},\n+        new RemoteParam(), fileId, blk, existings, existingStorageIDs, excludes,\n+        numAdditionalNodes, clientName);\n+    return (LocatedBlock) rpcClient.invokeSequential(\n+        locations, method, LocatedBlock.class, null);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public LocatedBlock getAdditionalDatanode(final String src, final long fileId,\n      final ExtendedBlock blk, final DatanodeInfo[] existings,\n      final String[] existingStorageIDs, final DatanodeInfo[] excludes,\n      final int numAdditionalNodes, final String clientName)\n          throws IOException {\n    checkOperation(OperationCategory.READ);\n\n    final List\u003cRemoteLocation\u003e locations \u003d getLocationsForPath(src, false);\n    RemoteMethod method \u003d new RemoteMethod(\"getAdditionalDatanode\",\n        new Class\u003c?\u003e[] {String.class, long.class, ExtendedBlock.class,\n                        DatanodeInfo[].class, String[].class,\n                        DatanodeInfo[].class, int.class, String.class},\n        new RemoteParam(), fileId, blk, existings, existingStorageIDs, excludes,\n        numAdditionalNodes, clientName);\n    return (LocatedBlock) rpcClient.invokeSequential(\n        locations, method, LocatedBlock.class, null);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcServer.java",
      "extendedDetails": {}
    },
    "fa121eb66bc42e9cb5586f8c2e268cfdc2ed187a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13790. RBF: Move ClientProtocol APIs to its own module. Contributed by Chao Sun.\n",
      "commitDate": "17/08/18 2:52 AM",
      "commitName": "fa121eb66bc42e9cb5586f8c2e268cfdc2ed187a",
      "commitAuthor": "Brahma Reddy Battula",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "39ed3a66dbb01383ed16b141183fc48bfd2e613d",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 4.99,
      "commitsBetweenForRepo": 43,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,8 @@\n   public LocatedBlock getAdditionalDatanode(final String src, final long fileId,\n       final ExtendedBlock blk, final DatanodeInfo[] existings,\n       final String[] existingStorageIDs, final DatanodeInfo[] excludes,\n       final int numAdditionalNodes, final String clientName)\n           throws IOException {\n-    checkOperation(OperationCategory.READ);\n-\n-    final List\u003cRemoteLocation\u003e locations \u003d getLocationsForPath(src, false);\n-    RemoteMethod method \u003d new RemoteMethod(\"getAdditionalDatanode\",\n-        new Class\u003c?\u003e[] {String.class, long.class, ExtendedBlock.class,\n-                        DatanodeInfo[].class, String[].class,\n-                        DatanodeInfo[].class, int.class, String.class},\n-        new RemoteParam(), fileId, blk, existings, existingStorageIDs, excludes,\n-        numAdditionalNodes, clientName);\n-    return (LocatedBlock) rpcClient.invokeSequential(\n-        locations, method, LocatedBlock.class, null);\n+    return clientProto.getAdditionalDatanode(src, fileId, blk, existings,\n+        existingStorageIDs, excludes, numAdditionalNodes, clientName);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public LocatedBlock getAdditionalDatanode(final String src, final long fileId,\n      final ExtendedBlock blk, final DatanodeInfo[] existings,\n      final String[] existingStorageIDs, final DatanodeInfo[] excludes,\n      final int numAdditionalNodes, final String clientName)\n          throws IOException {\n    return clientProto.getAdditionalDatanode(src, fileId, blk, existings,\n        existingStorageIDs, excludes, numAdditionalNodes, clientName);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcServer.java",
      "extendedDetails": {}
    },
    "6e2b5fa493ff8e8c2bb28e6f6f4c19347bc9b99d": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-13215. RBF: Move Router to its own module. Contributed by Wei Yan\n",
      "commitDate": "19/03/18 10:13 PM",
      "commitName": "6e2b5fa493ff8e8c2bb28e6f6f4c19347bc9b99d",
      "commitAuthor": "weiy",
      "commitDateOld": "19/03/18 5:19 PM",
      "commitNameOld": "e65ff1c8be48ef4f04ed96f96ac4caef4974944d",
      "commitAuthorOld": "Inigo Goiri",
      "daysBetweenCommits": 0.2,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public LocatedBlock getAdditionalDatanode(final String src, final long fileId,\n      final ExtendedBlock blk, final DatanodeInfo[] existings,\n      final String[] existingStorageIDs, final DatanodeInfo[] excludes,\n      final int numAdditionalNodes, final String clientName)\n          throws IOException {\n    checkOperation(OperationCategory.READ);\n\n    final List\u003cRemoteLocation\u003e locations \u003d getLocationsForPath(src, false);\n    RemoteMethod method \u003d new RemoteMethod(\"getAdditionalDatanode\",\n        new Class\u003c?\u003e[] {String.class, long.class, ExtendedBlock.class,\n                        DatanodeInfo[].class, String[].class,\n                        DatanodeInfo[].class, int.class, String.class},\n        new RemoteParam(), fileId, blk, existings, existingStorageIDs, excludes,\n        numAdditionalNodes, clientName);\n    return (LocatedBlock) rpcClient.invokeSequential(\n        locations, method, LocatedBlock.class, null);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcServer.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcServer.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcServer.java"
      }
    },
    "ca4f209b49e3aad6a80306f7342c9b6b560a79a7": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-11546. Federation Router RPC server. Contributed by Jason Kace and Inigo Goiri.\n\n(cherry picked from commit 8a9cdebebf26841a0f1e99fb08135f4597f2eba2)\n",
      "commitDate": "06/10/17 6:50 PM",
      "commitName": "ca4f209b49e3aad6a80306f7342c9b6b560a79a7",
      "commitAuthor": "Inigo Goiri",
      "diff": "@@ -0,0 +1,17 @@\n+  public LocatedBlock getAdditionalDatanode(final String src, final long fileId,\n+      final ExtendedBlock blk, final DatanodeInfo[] existings,\n+      final String[] existingStorageIDs, final DatanodeInfo[] excludes,\n+      final int numAdditionalNodes, final String clientName)\n+          throws IOException {\n+    checkOperation(OperationCategory.READ);\n+\n+    final List\u003cRemoteLocation\u003e locations \u003d getLocationsForPath(src, false);\n+    RemoteMethod method \u003d new RemoteMethod(\"getAdditionalDatanode\",\n+        new Class\u003c?\u003e[] {String.class, long.class, ExtendedBlock.class,\n+                        DatanodeInfo[].class, String[].class,\n+                        DatanodeInfo[].class, int.class, String.class},\n+        new RemoteParam(), fileId, blk, existings, existingStorageIDs, excludes,\n+        numAdditionalNodes, clientName);\n+    return (LocatedBlock) rpcClient.invokeSequential(\n+        locations, method, LocatedBlock.class, null);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public LocatedBlock getAdditionalDatanode(final String src, final long fileId,\n      final ExtendedBlock blk, final DatanodeInfo[] existings,\n      final String[] existingStorageIDs, final DatanodeInfo[] excludes,\n      final int numAdditionalNodes, final String clientName)\n          throws IOException {\n    checkOperation(OperationCategory.READ);\n\n    final List\u003cRemoteLocation\u003e locations \u003d getLocationsForPath(src, false);\n    RemoteMethod method \u003d new RemoteMethod(\"getAdditionalDatanode\",\n        new Class\u003c?\u003e[] {String.class, long.class, ExtendedBlock.class,\n                        DatanodeInfo[].class, String[].class,\n                        DatanodeInfo[].class, int.class, String.class},\n        new RemoteParam(), fileId, blk, existings, existingStorageIDs, excludes,\n        numAdditionalNodes, clientName);\n    return (LocatedBlock) rpcClient.invokeSequential(\n        locations, method, LocatedBlock.class, null);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcServer.java"
    }
  }
}