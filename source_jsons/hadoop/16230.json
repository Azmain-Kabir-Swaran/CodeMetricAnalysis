{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "RouterNamenodeProtocol.java",
  "functionName": "getBlocks",
  "functionId": "getBlocks___datanode-DatanodeInfo__size-long__minBlockSize-long",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterNamenodeProtocol.java",
  "functionStartLine": 55,
  "functionEndLine": 87,
  "numCommitsSeen": 4,
  "timeTaken": 831,
  "changeHistory": [
    "2be64eb201134502a92f7239bef8aa780771ca0b"
  ],
  "changeHistoryShort": {
    "2be64eb201134502a92f7239bef8aa780771ca0b": "Yintroduced"
  },
  "changeHistoryDetails": {
    "2be64eb201134502a92f7239bef8aa780771ca0b": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-13364. RBF: Support NamenodeProtocol in the Router. Contributed by Inigo Goiri.\n",
      "commitDate": "03/04/18 12:08 AM",
      "commitName": "2be64eb201134502a92f7239bef8aa780771ca0b",
      "commitAuthor": "Yiqun Lin",
      "diff": "@@ -0,0 +1,33 @@\n+  public BlocksWithLocations getBlocks(DatanodeInfo datanode, long size,\n+      long minBlockSize) throws IOException {\n+    rpcServer.checkOperation(OperationCategory.READ);\n+\n+    // Get the namespace where the datanode is located\n+    Map\u003cString, DatanodeStorageReport[]\u003e map \u003d\n+        rpcServer.getDatanodeStorageReportMap(DatanodeReportType.ALL);\n+    String nsId \u003d null;\n+    for (Entry\u003cString, DatanodeStorageReport[]\u003e entry : map.entrySet()) {\n+      DatanodeStorageReport[] dns \u003d entry.getValue();\n+      for (DatanodeStorageReport dn : dns) {\n+        DatanodeInfo dnInfo \u003d dn.getDatanodeInfo();\n+        if (dnInfo.getDatanodeUuid().equals(datanode.getDatanodeUuid())) {\n+          nsId \u003d entry.getKey();\n+          break;\n+        }\n+      }\n+      // Break the loop if already found\n+      if (nsId !\u003d null) {\n+        break;\n+      }\n+    }\n+\n+    // Forward to the proper namenode\n+    if (nsId !\u003d null) {\n+      RemoteMethod method \u003d new RemoteMethod(\n+          NamenodeProtocol.class, \"getBlocks\",\n+          new Class\u003c?\u003e[] {DatanodeInfo.class, long.class, long.class},\n+          datanode, size, minBlockSize);\n+      return rpcClient.invokeSingle(nsId, method, BlocksWithLocations.class);\n+    }\n+    return null;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public BlocksWithLocations getBlocks(DatanodeInfo datanode, long size,\n      long minBlockSize) throws IOException {\n    rpcServer.checkOperation(OperationCategory.READ);\n\n    // Get the namespace where the datanode is located\n    Map\u003cString, DatanodeStorageReport[]\u003e map \u003d\n        rpcServer.getDatanodeStorageReportMap(DatanodeReportType.ALL);\n    String nsId \u003d null;\n    for (Entry\u003cString, DatanodeStorageReport[]\u003e entry : map.entrySet()) {\n      DatanodeStorageReport[] dns \u003d entry.getValue();\n      for (DatanodeStorageReport dn : dns) {\n        DatanodeInfo dnInfo \u003d dn.getDatanodeInfo();\n        if (dnInfo.getDatanodeUuid().equals(datanode.getDatanodeUuid())) {\n          nsId \u003d entry.getKey();\n          break;\n        }\n      }\n      // Break the loop if already found\n      if (nsId !\u003d null) {\n        break;\n      }\n    }\n\n    // Forward to the proper namenode\n    if (nsId !\u003d null) {\n      RemoteMethod method \u003d new RemoteMethod(\n          NamenodeProtocol.class, \"getBlocks\",\n          new Class\u003c?\u003e[] {DatanodeInfo.class, long.class, long.class},\n          datanode, size, minBlockSize);\n      return rpcClient.invokeSingle(nsId, method, BlocksWithLocations.class);\n    }\n    return null;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterNamenodeProtocol.java"
    }
  }
}