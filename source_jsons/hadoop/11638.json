{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockPoolSlice.java",
  "functionName": "saveReplicas",
  "functionId": "saveReplicas___blocksListToPersist-BlockListAsLongs",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/BlockPoolSlice.java",
  "functionStartLine": 972,
  "functionEndLine": 1001,
  "numCommitsSeen": 58,
  "timeTaken": 3093,
  "changeHistory": [
    "1a636da041f2d4f2541a2da9c87f94c3ed234fb0",
    "6ba9587d370fbf39c129c08c00ebbb894ccc1389",
    "fc1031af749435dc95efea6745b1b2300ce29446"
  ],
  "changeHistoryShort": {
    "1a636da041f2d4f2541a2da9c87f94c3ed234fb0": "Ybodychange",
    "6ba9587d370fbf39c129c08c00ebbb894ccc1389": "Ybodychange",
    "fc1031af749435dc95efea6745b1b2300ce29446": "Yintroduced"
  },
  "changeHistoryDetails": {
    "1a636da041f2d4f2541a2da9c87f94c3ed234fb0": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-15033. Support to save replica cached files to other place and make expired time configurable. Contributed by Yang Yun.\n",
      "commitDate": "28/02/20 8:25 PM",
      "commitName": "1a636da041f2d4f2541a2da9c87f94c3ed234fb0",
      "commitAuthor": "Ayush Saxena",
      "commitDateOld": "11/02/20 8:00 AM",
      "commitNameOld": "d7c136b9ed6d99e1b03f5b89723b3a20df359ba8",
      "commitAuthorOld": "Stephen O\u0027Donnell",
      "daysBetweenCommits": 17.52,
      "commitsBetweenForRepo": 72,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,30 +1,30 @@\n   private void saveReplicas(BlockListAsLongs blocksListToPersist) {\n     if (blocksListToPersist \u003d\u003d null ||\n         blocksListToPersist.getNumberOfBlocks()\u003d\u003d 0) {\n       return;\n     }\n-    final File tmpFile \u003d new File(currentDir, REPLICA_CACHE_FILE + \".tmp\");\n-    final File replicaCacheFile \u003d new File(currentDir, REPLICA_CACHE_FILE);\n+    final File tmpFile \u003d new File(replicaCacheDir, REPLICA_CACHE_FILE + \".tmp\");\n+    final File replicaCacheFile \u003d new File(replicaCacheDir, REPLICA_CACHE_FILE);\n     if (!fileIoProvider.deleteWithExistsCheck(volume, tmpFile) ||\n         !fileIoProvider.deleteWithExistsCheck(volume, replicaCacheFile)) {\n       return;\n     }\n \n     FileOutputStream out \u003d null;\n     try {\n       out \u003d fileIoProvider.getFileOutputStream(volume, tmpFile);\n       blocksListToPersist.writeTo(out);\n       out.close();\n       // Renaming the tmp file to replicas\n       fileIoProvider.moveFile(volume, tmpFile, replicaCacheFile);\n     } catch (Exception e) {\n       // If write failed, the volume might be bad. Since the cache file is\n       // not critical, log the error, delete both the files (tmp and cache)\n       // and continue.\n       LOG.warn(\"Failed to write replicas to cache \", e);\n       fileIoProvider.deleteWithExistsCheck(volume, replicaCacheFile);\n     } finally {\n       IOUtils.closeStream(out);\n       fileIoProvider.deleteWithExistsCheck(volume, tmpFile);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void saveReplicas(BlockListAsLongs blocksListToPersist) {\n    if (blocksListToPersist \u003d\u003d null ||\n        blocksListToPersist.getNumberOfBlocks()\u003d\u003d 0) {\n      return;\n    }\n    final File tmpFile \u003d new File(replicaCacheDir, REPLICA_CACHE_FILE + \".tmp\");\n    final File replicaCacheFile \u003d new File(replicaCacheDir, REPLICA_CACHE_FILE);\n    if (!fileIoProvider.deleteWithExistsCheck(volume, tmpFile) ||\n        !fileIoProvider.deleteWithExistsCheck(volume, replicaCacheFile)) {\n      return;\n    }\n\n    FileOutputStream out \u003d null;\n    try {\n      out \u003d fileIoProvider.getFileOutputStream(volume, tmpFile);\n      blocksListToPersist.writeTo(out);\n      out.close();\n      // Renaming the tmp file to replicas\n      fileIoProvider.moveFile(volume, tmpFile, replicaCacheFile);\n    } catch (Exception e) {\n      // If write failed, the volume might be bad. Since the cache file is\n      // not critical, log the error, delete both the files (tmp and cache)\n      // and continue.\n      LOG.warn(\"Failed to write replicas to cache \", e);\n      fileIoProvider.deleteWithExistsCheck(volume, replicaCacheFile);\n    } finally {\n      IOUtils.closeStream(out);\n      fileIoProvider.deleteWithExistsCheck(volume, tmpFile);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/BlockPoolSlice.java",
      "extendedDetails": {}
    },
    "6ba9587d370fbf39c129c08c00ebbb894ccc1389": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10958. Add instrumentation hooks around Datanode disk IO.\n",
      "commitDate": "14/12/16 11:18 AM",
      "commitName": "6ba9587d370fbf39c129c08c00ebbb894ccc1389",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "06/12/16 11:05 AM",
      "commitNameOld": "df983b524ab68ea0c70cee9033bfff2d28052cbf",
      "commitAuthorOld": "Xiaoyu Yao",
      "daysBetweenCommits": 8.01,
      "commitsBetweenForRepo": 51,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,42 +1,30 @@\n   private void saveReplicas(BlockListAsLongs blocksListToPersist) {\n     if (blocksListToPersist \u003d\u003d null ||\n         blocksListToPersist.getNumberOfBlocks()\u003d\u003d 0) {\n       return;\n     }\n-    File tmpFile \u003d new File(currentDir, REPLICA_CACHE_FILE + \".tmp\");\n-    if (tmpFile.exists() \u0026\u0026 !tmpFile.delete()) {\n-      LOG.warn(\"Failed to delete tmp replicas file in \" +\n-        tmpFile.getPath());\n-      return;\n-    }\n-    File replicaCacheFile \u003d new File(currentDir, REPLICA_CACHE_FILE);\n-    if (replicaCacheFile.exists() \u0026\u0026 !replicaCacheFile.delete()) {\n-      LOG.warn(\"Failed to delete replicas file in \" +\n-          replicaCacheFile.getPath());\n+    final File tmpFile \u003d new File(currentDir, REPLICA_CACHE_FILE + \".tmp\");\n+    final File replicaCacheFile \u003d new File(currentDir, REPLICA_CACHE_FILE);\n+    if (!fileIoProvider.deleteWithExistsCheck(volume, tmpFile) ||\n+        !fileIoProvider.deleteWithExistsCheck(volume, replicaCacheFile)) {\n       return;\n     }\n \n     FileOutputStream out \u003d null;\n     try {\n-      out \u003d new FileOutputStream(tmpFile);\n+      out \u003d fileIoProvider.getFileOutputStream(volume, tmpFile);\n       blocksListToPersist.writeTo(out);\n       out.close();\n       // Renaming the tmp file to replicas\n-      Files.move(tmpFile, replicaCacheFile);\n+      fileIoProvider.moveFile(volume, tmpFile, replicaCacheFile);\n     } catch (Exception e) {\n       // If write failed, the volume might be bad. Since the cache file is\n       // not critical, log the error, delete both the files (tmp and cache)\n       // and continue.\n       LOG.warn(\"Failed to write replicas to cache \", e);\n-      if (replicaCacheFile.exists() \u0026\u0026 !replicaCacheFile.delete()) {\n-        LOG.warn(\"Failed to delete replicas file: \" +\n-            replicaCacheFile.getPath());\n-      }\n+      fileIoProvider.deleteWithExistsCheck(volume, replicaCacheFile);\n     } finally {\n       IOUtils.closeStream(out);\n-      if (tmpFile.exists() \u0026\u0026 !tmpFile.delete()) {\n-        LOG.warn(\"Failed to delete tmp file in \" +\n-            tmpFile.getPath());\n-      }\n+      fileIoProvider.deleteWithExistsCheck(volume, tmpFile);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void saveReplicas(BlockListAsLongs blocksListToPersist) {\n    if (blocksListToPersist \u003d\u003d null ||\n        blocksListToPersist.getNumberOfBlocks()\u003d\u003d 0) {\n      return;\n    }\n    final File tmpFile \u003d new File(currentDir, REPLICA_CACHE_FILE + \".tmp\");\n    final File replicaCacheFile \u003d new File(currentDir, REPLICA_CACHE_FILE);\n    if (!fileIoProvider.deleteWithExistsCheck(volume, tmpFile) ||\n        !fileIoProvider.deleteWithExistsCheck(volume, replicaCacheFile)) {\n      return;\n    }\n\n    FileOutputStream out \u003d null;\n    try {\n      out \u003d fileIoProvider.getFileOutputStream(volume, tmpFile);\n      blocksListToPersist.writeTo(out);\n      out.close();\n      // Renaming the tmp file to replicas\n      fileIoProvider.moveFile(volume, tmpFile, replicaCacheFile);\n    } catch (Exception e) {\n      // If write failed, the volume might be bad. Since the cache file is\n      // not critical, log the error, delete both the files (tmp and cache)\n      // and continue.\n      LOG.warn(\"Failed to write replicas to cache \", e);\n      fileIoProvider.deleteWithExistsCheck(volume, replicaCacheFile);\n    } finally {\n      IOUtils.closeStream(out);\n      fileIoProvider.deleteWithExistsCheck(volume, tmpFile);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/BlockPoolSlice.java",
      "extendedDetails": {}
    },
    "fc1031af749435dc95efea6745b1b2300ce29446": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-7928. Scanning blocks from disk during rolling upgrade startup takes a lot of time if disks are busy. Contributed by Rushabh Shah.\n",
      "commitDate": "25/03/15 12:42 PM",
      "commitName": "fc1031af749435dc95efea6745b1b2300ce29446",
      "commitAuthor": "Kihwal Lee",
      "diff": "@@ -0,0 +1,42 @@\n+  private void saveReplicas(BlockListAsLongs blocksListToPersist) {\n+    if (blocksListToPersist \u003d\u003d null || \n+        blocksListToPersist.getNumberOfBlocks()\u003d\u003d 0) {\n+      return;\n+    }\n+    File tmpFile \u003d new File(currentDir, REPLICA_CACHE_FILE + \".tmp\");\n+    if (tmpFile.exists() \u0026\u0026 !tmpFile.delete()) {\n+      LOG.warn(\"Failed to delete tmp replicas file in \" +\n+        tmpFile.getPath());\n+      return;\n+    }\n+    File replicaCacheFile \u003d new File(currentDir, REPLICA_CACHE_FILE);\n+    if (replicaCacheFile.exists() \u0026\u0026 !replicaCacheFile.delete()) {\n+      LOG.warn(\"Failed to delete replicas file in \" +\n+          replicaCacheFile.getPath());\n+      return;\n+    }\n+    \n+    FileOutputStream out \u003d null;\n+    try {\n+      out \u003d new FileOutputStream(tmpFile);\n+      blocksListToPersist.writeTo(out);\n+      out.close();\n+      // Renaming the tmp file to replicas\n+      Files.move(tmpFile, replicaCacheFile);\n+    } catch (Exception e) {\n+      // If write failed, the volume might be bad. Since the cache file is\n+      // not critical, log the error, delete both the files (tmp and cache)\n+      // and continue.\n+      LOG.warn(\"Failed to write replicas to cache \", e);\n+      if (replicaCacheFile.exists() \u0026\u0026 !replicaCacheFile.delete()) {\n+        LOG.warn(\"Failed to delete replicas file: \" + \n+            replicaCacheFile.getPath());\n+      }\n+    } finally {\n+      IOUtils.closeStream(out);\n+      if (tmpFile.exists() \u0026\u0026 !tmpFile.delete()) {\n+        LOG.warn(\"Failed to delete tmp file in \" +\n+            tmpFile.getPath());\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void saveReplicas(BlockListAsLongs blocksListToPersist) {\n    if (blocksListToPersist \u003d\u003d null || \n        blocksListToPersist.getNumberOfBlocks()\u003d\u003d 0) {\n      return;\n    }\n    File tmpFile \u003d new File(currentDir, REPLICA_CACHE_FILE + \".tmp\");\n    if (tmpFile.exists() \u0026\u0026 !tmpFile.delete()) {\n      LOG.warn(\"Failed to delete tmp replicas file in \" +\n        tmpFile.getPath());\n      return;\n    }\n    File replicaCacheFile \u003d new File(currentDir, REPLICA_CACHE_FILE);\n    if (replicaCacheFile.exists() \u0026\u0026 !replicaCacheFile.delete()) {\n      LOG.warn(\"Failed to delete replicas file in \" +\n          replicaCacheFile.getPath());\n      return;\n    }\n    \n    FileOutputStream out \u003d null;\n    try {\n      out \u003d new FileOutputStream(tmpFile);\n      blocksListToPersist.writeTo(out);\n      out.close();\n      // Renaming the tmp file to replicas\n      Files.move(tmpFile, replicaCacheFile);\n    } catch (Exception e) {\n      // If write failed, the volume might be bad. Since the cache file is\n      // not critical, log the error, delete both the files (tmp and cache)\n      // and continue.\n      LOG.warn(\"Failed to write replicas to cache \", e);\n      if (replicaCacheFile.exists() \u0026\u0026 !replicaCacheFile.delete()) {\n        LOG.warn(\"Failed to delete replicas file: \" + \n            replicaCacheFile.getPath());\n      }\n    } finally {\n      IOUtils.closeStream(out);\n      if (tmpFile.exists() \u0026\u0026 !tmpFile.delete()) {\n        LOG.warn(\"Failed to delete tmp file in \" +\n            tmpFile.getPath());\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/BlockPoolSlice.java"
    }
  }
}