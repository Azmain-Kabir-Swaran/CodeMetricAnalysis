{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "NameNode.java",
  "functionName": "startHttpServer",
  "functionId": "startHttpServer___conf-Configuration(modifiers-final)",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java",
  "functionStartLine": 944,
  "functionEndLine": 948,
  "numCommitsSeen": 231,
  "timeTaken": 7629,
  "changeHistory": [
    "cf4bc7fdd49974324b177c99b820587cc5854adb",
    "d02baff9a0d8cec92bde751777f3e575da2339c8",
    "da8e962e39bd41b73b53966826c82e741b08010b",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "01cd616d170d5d26a539e51e731e8e73b789b360",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "cf4bc7fdd49974324b177c99b820587cc5854adb": "Ybodychange",
    "d02baff9a0d8cec92bde751777f3e575da2339c8": "Ybodychange",
    "da8e962e39bd41b73b53966826c82e741b08010b": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "01cd616d170d5d26a539e51e731e8e73b789b360": "Ybodychange",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "cf4bc7fdd49974324b177c99b820587cc5854adb": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6273. Config options to allow wildcard endpoints for namenode HTTP and HTTPS servers. (Contributed by Arpit Agarwal)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1589803 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/04/14 10:40 AM",
      "commitName": "cf4bc7fdd49974324b177c99b820587cc5854adb",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "23/04/14 1:13 PM",
      "commitNameOld": "876fd8ab7913a259ff9f69c16cc2d9af46ad3f9b",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 0.89,
      "commitsBetweenForRepo": 12,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,5 +1,5 @@\n   private void startHttpServer(final Configuration conf) throws IOException {\n-    httpServer \u003d new NameNodeHttpServer(conf, this, getHttpServerAddress(conf));\n+    httpServer \u003d new NameNodeHttpServer(conf, this, getHttpServerBindAddress(conf));\n     httpServer.start();\n     httpServer.setStartupProgress(startupProgress);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void startHttpServer(final Configuration conf) throws IOException {\n    httpServer \u003d new NameNodeHttpServer(conf, this, getHttpServerBindAddress(conf));\n    httpServer.start();\n    httpServer.setStartupProgress(startupProgress);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java",
      "extendedDetails": {}
    },
    "d02baff9a0d8cec92bde751777f3e575da2339c8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5536. Implement HTTP policy for Namenode and DataNode. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1547925 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/12/13 1:40 PM",
      "commitName": "d02baff9a0d8cec92bde751777f3e575da2339c8",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "27/11/13 10:20 AM",
      "commitNameOld": "2214871d916fdcae62aa51afbb5fd571f2808745",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 7.14,
      "commitsBetweenForRepo": 29,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,6 +1,5 @@\n   private void startHttpServer(final Configuration conf) throws IOException {\n     httpServer \u003d new NameNodeHttpServer(conf, this, getHttpServerAddress(conf));\n     httpServer.start();\n     httpServer.setStartupProgress(startupProgress);\n-    setHttpServerAddress(conf);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void startHttpServer(final Configuration conf) throws IOException {\n    httpServer \u003d new NameNodeHttpServer(conf, this, getHttpServerAddress(conf));\n    httpServer.start();\n    httpServer.setStartupProgress(startupProgress);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java",
      "extendedDetails": {}
    },
    "da8e962e39bd41b73b53966826c82e741b08010b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4372. Track NameNode startup progress. Contributed by Chris Nauroth.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1502120 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/07/13 10:35 PM",
      "commitName": "da8e962e39bd41b73b53966826c82e741b08010b",
      "commitAuthor": "Chris Nauroth",
      "commitDateOld": "22/04/13 6:18 PM",
      "commitNameOld": "fd24c6e83357d4d3c937e112328a1eb378327eb0",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 79.18,
      "commitsBetweenForRepo": 494,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,5 +1,6 @@\n   private void startHttpServer(final Configuration conf) throws IOException {\n     httpServer \u003d new NameNodeHttpServer(conf, this, getHttpServerAddress(conf));\n     httpServer.start();\n+    httpServer.setStartupProgress(startupProgress);\n     setHttpServerAddress(conf);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void startHttpServer(final Configuration conf) throws IOException {\n    httpServer \u003d new NameNodeHttpServer(conf, this, getHttpServerAddress(conf));\n    httpServer.start();\n    httpServer.setStartupProgress(startupProgress);\n    setHttpServerAddress(conf);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private void startHttpServer(final Configuration conf) throws IOException {\n    httpServer \u003d new NameNodeHttpServer(conf, this, getHttpServerAddress(conf));\n    httpServer.start();\n    setHttpServerAddress(conf);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private void startHttpServer(final Configuration conf) throws IOException {\n    httpServer \u003d new NameNodeHttpServer(conf, this, getHttpServerAddress(conf));\n    httpServer.start();\n    setHttpServerAddress(conf);\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java"
      }
    },
    "01cd616d170d5d26a539e51e731e8e73b789b360": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2180. Refactor NameNode HTTP server into new class. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1150960 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "25/07/11 5:04 PM",
      "commitName": "01cd616d170d5d26a539e51e731e8e73b789b360",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "18/07/11 6:32 PM",
      "commitNameOld": "6c0cb4d15179103d4f83fe5b2f8d8f6a05f3a789",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 6.94,
      "commitsBetweenForRepo": 24,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,104 +1,5 @@\n   private void startHttpServer(final Configuration conf) throws IOException {\n-    final InetSocketAddress infoSocAddr \u003d getHttpServerAddress(conf);\n-    final String infoHost \u003d infoSocAddr.getHostName();\n-    if(UserGroupInformation.isSecurityEnabled()) {\n-      String httpsUser \u003d SecurityUtil.getServerPrincipal(conf\n-          .get(DFSConfigKeys.DFS_NAMENODE_KRB_HTTPS_USER_NAME_KEY), infoHost);\n-      if (httpsUser \u003d\u003d null) {\n-        LOG.warn(DFSConfigKeys.DFS_NAMENODE_KRB_HTTPS_USER_NAME_KEY\n-            + \" not defined in config. Starting http server as \"\n-            + SecurityUtil.getServerPrincipal(conf\n-                .get(DFSConfigKeys.DFS_NAMENODE_USER_NAME_KEY), rpcAddress\n-                .getHostName())\n-            + \": Kerberized SSL may be not function correctly.\");\n-      } else {\n-        // Kerberized SSL servers must be run from the host principal...\n-        LOG.info(\"Logging in as \" + httpsUser + \" to start http server.\");\n-        SecurityUtil.login(conf, DFSConfigKeys.DFS_NAMENODE_KEYTAB_FILE_KEY,\n-            DFSConfigKeys.DFS_NAMENODE_KRB_HTTPS_USER_NAME_KEY, infoHost);\n-      }\n-    }\n-    UserGroupInformation ugi \u003d UserGroupInformation.getLoginUser();\n-    try {\n-      this.httpServer \u003d ugi.doAs(new PrivilegedExceptionAction\u003cHttpServer\u003e() {\n-        @Override\n-        public HttpServer run() throws IOException, InterruptedException {\n-          int infoPort \u003d infoSocAddr.getPort();\n-          httpServer \u003d new HttpServer(\"hdfs\", infoHost, infoPort,\n-              infoPort \u003d\u003d 0, conf, \n-              new AccessControlList(conf.get(DFSConfigKeys.DFS_ADMIN, \" \")));\n-\n-          boolean certSSL \u003d conf.getBoolean(\"dfs.https.enable\", false);\n-          boolean useKrb \u003d UserGroupInformation.isSecurityEnabled();\n-          if (certSSL || useKrb) {\n-            boolean needClientAuth \u003d conf.getBoolean(\n-                DFSConfigKeys.DFS_CLIENT_HTTPS_NEED_AUTH_KEY,\n-                DFSConfigKeys.DFS_CLIENT_HTTPS_NEED_AUTH_DEFAULT);\n-            InetSocketAddress secInfoSocAddr \u003d NetUtils.createSocketAddr(conf\n-                .get(DFSConfigKeys.DFS_NAMENODE_HTTPS_ADDRESS_KEY,\n-                    DFSConfigKeys.DFS_NAMENODE_HTTPS_ADDRESS_DEFAULT));\n-            Configuration sslConf \u003d new HdfsConfiguration(false);\n-            if (certSSL) {\n-              sslConf.addResource(conf.get(\n-                  \"dfs.https.server.keystore.resource\", \"ssl-server.xml\"));\n-            }\n-            httpServer.addSslListener(secInfoSocAddr, sslConf, needClientAuth,\n-                useKrb);\n-            // assume same ssl port for all datanodes\n-            InetSocketAddress datanodeSslPort \u003d NetUtils.createSocketAddr(conf\n-                .get(\"dfs.datanode.https.address\", infoHost + \":\" + 50475));\n-            httpServer.setAttribute(\"datanode.https.port\", datanodeSslPort\n-                .getPort());\n-          }\n-          httpServer.setAttribute(\"name.node\", NameNode.this);\n-          httpServer.setAttribute(NAMENODE_ADDRESS_ATTRIBUTE_KEY,\n-              getNameNodeAddress());\n-          httpServer.setAttribute(\"name.system.image\", getFSImage());\n-          httpServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n-          httpServer.addInternalServlet(\"getDelegationToken\",\n-              GetDelegationTokenServlet.PATH_SPEC, \n-              GetDelegationTokenServlet.class, true);\n-          httpServer.addInternalServlet(\"renewDelegationToken\", \n-              RenewDelegationTokenServlet.PATH_SPEC, \n-              RenewDelegationTokenServlet.class, true);\n-          httpServer.addInternalServlet(\"cancelDelegationToken\", \n-              CancelDelegationTokenServlet.PATH_SPEC, \n-              CancelDelegationTokenServlet.class, true);\n-          httpServer.addInternalServlet(\"fsck\", \"/fsck\", FsckServlet.class,\n-              true);\n-          httpServer.addInternalServlet(\"getimage\", \"/getimage\",\n-              GetImageServlet.class, true);\n-          httpServer.addInternalServlet(\"listPaths\", \"/listPaths/*\",\n-              ListPathsServlet.class, false);\n-          httpServer.addInternalServlet(\"data\", \"/data/*\",\n-              FileDataServlet.class, false);\n-          httpServer.addInternalServlet(\"checksum\", \"/fileChecksum/*\",\n-              FileChecksumServlets.RedirectServlet.class, false);\n-          httpServer.addInternalServlet(\"contentSummary\", \"/contentSummary/*\",\n-              ContentSummaryServlet.class, false);\n-          httpServer.start();\n-\n-          // The web-server port can be ephemeral... ensure we have the correct\n-          // info\n-          infoPort \u003d httpServer.getPort();\n-          httpAddress \u003d new InetSocketAddress(infoHost, infoPort);\n-          setHttpServerAddress(conf);\n-          LOG.info(getRole() + \" Web-server up at: \" + httpAddress);\n-          return httpServer;\n-        }\n-      });\n-    } catch (InterruptedException e) {\n-      throw new IOException(e);\n-    } finally {\n-      if(UserGroupInformation.isSecurityEnabled() \u0026\u0026 \n-          conf.get(DFSConfigKeys.DFS_NAMENODE_KRB_HTTPS_USER_NAME_KEY) !\u003d null) {\n-        // Go back to being the correct Namenode principal\n-        LOG.info(\"Logging back in as \"\n-            + SecurityUtil.getServerPrincipal(conf\n-                .get(DFSConfigKeys.DFS_NAMENODE_USER_NAME_KEY), rpcAddress\n-                .getHostName()) + \" following http server start.\");\n-        SecurityUtil.login(conf, DFSConfigKeys.DFS_NAMENODE_KEYTAB_FILE_KEY,\n-            DFSConfigKeys.DFS_NAMENODE_USER_NAME_KEY, rpcAddress.getHostName());\n-      }\n-    }\n+    httpServer \u003d new NameNodeHttpServer(conf, this, getHttpServerAddress(conf));\n+    httpServer.start();\n+    setHttpServerAddress(conf);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void startHttpServer(final Configuration conf) throws IOException {\n    httpServer \u003d new NameNodeHttpServer(conf, this, getHttpServerAddress(conf));\n    httpServer.start();\n    setHttpServerAddress(conf);\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java",
      "extendedDetails": {}
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,104 @@\n+  private void startHttpServer(final Configuration conf) throws IOException {\n+    final InetSocketAddress infoSocAddr \u003d getHttpServerAddress(conf);\n+    final String infoHost \u003d infoSocAddr.getHostName();\n+    if(UserGroupInformation.isSecurityEnabled()) {\n+      String httpsUser \u003d SecurityUtil.getServerPrincipal(conf\n+          .get(DFSConfigKeys.DFS_NAMENODE_KRB_HTTPS_USER_NAME_KEY), infoHost);\n+      if (httpsUser \u003d\u003d null) {\n+        LOG.warn(DFSConfigKeys.DFS_NAMENODE_KRB_HTTPS_USER_NAME_KEY\n+            + \" not defined in config. Starting http server as \"\n+            + SecurityUtil.getServerPrincipal(conf\n+                .get(DFSConfigKeys.DFS_NAMENODE_USER_NAME_KEY), rpcAddress\n+                .getHostName())\n+            + \": Kerberized SSL may be not function correctly.\");\n+      } else {\n+        // Kerberized SSL servers must be run from the host principal...\n+        LOG.info(\"Logging in as \" + httpsUser + \" to start http server.\");\n+        SecurityUtil.login(conf, DFSConfigKeys.DFS_NAMENODE_KEYTAB_FILE_KEY,\n+            DFSConfigKeys.DFS_NAMENODE_KRB_HTTPS_USER_NAME_KEY, infoHost);\n+      }\n+    }\n+    UserGroupInformation ugi \u003d UserGroupInformation.getLoginUser();\n+    try {\n+      this.httpServer \u003d ugi.doAs(new PrivilegedExceptionAction\u003cHttpServer\u003e() {\n+        @Override\n+        public HttpServer run() throws IOException, InterruptedException {\n+          int infoPort \u003d infoSocAddr.getPort();\n+          httpServer \u003d new HttpServer(\"hdfs\", infoHost, infoPort,\n+              infoPort \u003d\u003d 0, conf, \n+              new AccessControlList(conf.get(DFSConfigKeys.DFS_ADMIN, \" \")));\n+\n+          boolean certSSL \u003d conf.getBoolean(\"dfs.https.enable\", false);\n+          boolean useKrb \u003d UserGroupInformation.isSecurityEnabled();\n+          if (certSSL || useKrb) {\n+            boolean needClientAuth \u003d conf.getBoolean(\n+                DFSConfigKeys.DFS_CLIENT_HTTPS_NEED_AUTH_KEY,\n+                DFSConfigKeys.DFS_CLIENT_HTTPS_NEED_AUTH_DEFAULT);\n+            InetSocketAddress secInfoSocAddr \u003d NetUtils.createSocketAddr(conf\n+                .get(DFSConfigKeys.DFS_NAMENODE_HTTPS_ADDRESS_KEY,\n+                    DFSConfigKeys.DFS_NAMENODE_HTTPS_ADDRESS_DEFAULT));\n+            Configuration sslConf \u003d new HdfsConfiguration(false);\n+            if (certSSL) {\n+              sslConf.addResource(conf.get(\n+                  \"dfs.https.server.keystore.resource\", \"ssl-server.xml\"));\n+            }\n+            httpServer.addSslListener(secInfoSocAddr, sslConf, needClientAuth,\n+                useKrb);\n+            // assume same ssl port for all datanodes\n+            InetSocketAddress datanodeSslPort \u003d NetUtils.createSocketAddr(conf\n+                .get(\"dfs.datanode.https.address\", infoHost + \":\" + 50475));\n+            httpServer.setAttribute(\"datanode.https.port\", datanodeSslPort\n+                .getPort());\n+          }\n+          httpServer.setAttribute(\"name.node\", NameNode.this);\n+          httpServer.setAttribute(NAMENODE_ADDRESS_ATTRIBUTE_KEY,\n+              getNameNodeAddress());\n+          httpServer.setAttribute(\"name.system.image\", getFSImage());\n+          httpServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n+          httpServer.addInternalServlet(\"getDelegationToken\",\n+              GetDelegationTokenServlet.PATH_SPEC, \n+              GetDelegationTokenServlet.class, true);\n+          httpServer.addInternalServlet(\"renewDelegationToken\", \n+              RenewDelegationTokenServlet.PATH_SPEC, \n+              RenewDelegationTokenServlet.class, true);\n+          httpServer.addInternalServlet(\"cancelDelegationToken\", \n+              CancelDelegationTokenServlet.PATH_SPEC, \n+              CancelDelegationTokenServlet.class, true);\n+          httpServer.addInternalServlet(\"fsck\", \"/fsck\", FsckServlet.class,\n+              true);\n+          httpServer.addInternalServlet(\"getimage\", \"/getimage\",\n+              GetImageServlet.class, true);\n+          httpServer.addInternalServlet(\"listPaths\", \"/listPaths/*\",\n+              ListPathsServlet.class, false);\n+          httpServer.addInternalServlet(\"data\", \"/data/*\",\n+              FileDataServlet.class, false);\n+          httpServer.addInternalServlet(\"checksum\", \"/fileChecksum/*\",\n+              FileChecksumServlets.RedirectServlet.class, false);\n+          httpServer.addInternalServlet(\"contentSummary\", \"/contentSummary/*\",\n+              ContentSummaryServlet.class, false);\n+          httpServer.start();\n+\n+          // The web-server port can be ephemeral... ensure we have the correct\n+          // info\n+          infoPort \u003d httpServer.getPort();\n+          httpAddress \u003d new InetSocketAddress(infoHost, infoPort);\n+          setHttpServerAddress(conf);\n+          LOG.info(getRole() + \" Web-server up at: \" + httpAddress);\n+          return httpServer;\n+        }\n+      });\n+    } catch (InterruptedException e) {\n+      throw new IOException(e);\n+    } finally {\n+      if(UserGroupInformation.isSecurityEnabled() \u0026\u0026 \n+          conf.get(DFSConfigKeys.DFS_NAMENODE_KRB_HTTPS_USER_NAME_KEY) !\u003d null) {\n+        // Go back to being the correct Namenode principal\n+        LOG.info(\"Logging back in as \"\n+            + SecurityUtil.getServerPrincipal(conf\n+                .get(DFSConfigKeys.DFS_NAMENODE_USER_NAME_KEY), rpcAddress\n+                .getHostName()) + \" following http server start.\");\n+        SecurityUtil.login(conf, DFSConfigKeys.DFS_NAMENODE_KEYTAB_FILE_KEY,\n+            DFSConfigKeys.DFS_NAMENODE_USER_NAME_KEY, rpcAddress.getHostName());\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void startHttpServer(final Configuration conf) throws IOException {\n    final InetSocketAddress infoSocAddr \u003d getHttpServerAddress(conf);\n    final String infoHost \u003d infoSocAddr.getHostName();\n    if(UserGroupInformation.isSecurityEnabled()) {\n      String httpsUser \u003d SecurityUtil.getServerPrincipal(conf\n          .get(DFSConfigKeys.DFS_NAMENODE_KRB_HTTPS_USER_NAME_KEY), infoHost);\n      if (httpsUser \u003d\u003d null) {\n        LOG.warn(DFSConfigKeys.DFS_NAMENODE_KRB_HTTPS_USER_NAME_KEY\n            + \" not defined in config. Starting http server as \"\n            + SecurityUtil.getServerPrincipal(conf\n                .get(DFSConfigKeys.DFS_NAMENODE_USER_NAME_KEY), rpcAddress\n                .getHostName())\n            + \": Kerberized SSL may be not function correctly.\");\n      } else {\n        // Kerberized SSL servers must be run from the host principal...\n        LOG.info(\"Logging in as \" + httpsUser + \" to start http server.\");\n        SecurityUtil.login(conf, DFSConfigKeys.DFS_NAMENODE_KEYTAB_FILE_KEY,\n            DFSConfigKeys.DFS_NAMENODE_KRB_HTTPS_USER_NAME_KEY, infoHost);\n      }\n    }\n    UserGroupInformation ugi \u003d UserGroupInformation.getLoginUser();\n    try {\n      this.httpServer \u003d ugi.doAs(new PrivilegedExceptionAction\u003cHttpServer\u003e() {\n        @Override\n        public HttpServer run() throws IOException, InterruptedException {\n          int infoPort \u003d infoSocAddr.getPort();\n          httpServer \u003d new HttpServer(\"hdfs\", infoHost, infoPort,\n              infoPort \u003d\u003d 0, conf, \n              new AccessControlList(conf.get(DFSConfigKeys.DFS_ADMIN, \" \")));\n\n          boolean certSSL \u003d conf.getBoolean(\"dfs.https.enable\", false);\n          boolean useKrb \u003d UserGroupInformation.isSecurityEnabled();\n          if (certSSL || useKrb) {\n            boolean needClientAuth \u003d conf.getBoolean(\n                DFSConfigKeys.DFS_CLIENT_HTTPS_NEED_AUTH_KEY,\n                DFSConfigKeys.DFS_CLIENT_HTTPS_NEED_AUTH_DEFAULT);\n            InetSocketAddress secInfoSocAddr \u003d NetUtils.createSocketAddr(conf\n                .get(DFSConfigKeys.DFS_NAMENODE_HTTPS_ADDRESS_KEY,\n                    DFSConfigKeys.DFS_NAMENODE_HTTPS_ADDRESS_DEFAULT));\n            Configuration sslConf \u003d new HdfsConfiguration(false);\n            if (certSSL) {\n              sslConf.addResource(conf.get(\n                  \"dfs.https.server.keystore.resource\", \"ssl-server.xml\"));\n            }\n            httpServer.addSslListener(secInfoSocAddr, sslConf, needClientAuth,\n                useKrb);\n            // assume same ssl port for all datanodes\n            InetSocketAddress datanodeSslPort \u003d NetUtils.createSocketAddr(conf\n                .get(\"dfs.datanode.https.address\", infoHost + \":\" + 50475));\n            httpServer.setAttribute(\"datanode.https.port\", datanodeSslPort\n                .getPort());\n          }\n          httpServer.setAttribute(\"name.node\", NameNode.this);\n          httpServer.setAttribute(NAMENODE_ADDRESS_ATTRIBUTE_KEY,\n              getNameNodeAddress());\n          httpServer.setAttribute(\"name.system.image\", getFSImage());\n          httpServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n          httpServer.addInternalServlet(\"getDelegationToken\",\n              GetDelegationTokenServlet.PATH_SPEC, \n              GetDelegationTokenServlet.class, true);\n          httpServer.addInternalServlet(\"renewDelegationToken\", \n              RenewDelegationTokenServlet.PATH_SPEC, \n              RenewDelegationTokenServlet.class, true);\n          httpServer.addInternalServlet(\"cancelDelegationToken\", \n              CancelDelegationTokenServlet.PATH_SPEC, \n              CancelDelegationTokenServlet.class, true);\n          httpServer.addInternalServlet(\"fsck\", \"/fsck\", FsckServlet.class,\n              true);\n          httpServer.addInternalServlet(\"getimage\", \"/getimage\",\n              GetImageServlet.class, true);\n          httpServer.addInternalServlet(\"listPaths\", \"/listPaths/*\",\n              ListPathsServlet.class, false);\n          httpServer.addInternalServlet(\"data\", \"/data/*\",\n              FileDataServlet.class, false);\n          httpServer.addInternalServlet(\"checksum\", \"/fileChecksum/*\",\n              FileChecksumServlets.RedirectServlet.class, false);\n          httpServer.addInternalServlet(\"contentSummary\", \"/contentSummary/*\",\n              ContentSummaryServlet.class, false);\n          httpServer.start();\n\n          // The web-server port can be ephemeral... ensure we have the correct\n          // info\n          infoPort \u003d httpServer.getPort();\n          httpAddress \u003d new InetSocketAddress(infoHost, infoPort);\n          setHttpServerAddress(conf);\n          LOG.info(getRole() + \" Web-server up at: \" + httpAddress);\n          return httpServer;\n        }\n      });\n    } catch (InterruptedException e) {\n      throw new IOException(e);\n    } finally {\n      if(UserGroupInformation.isSecurityEnabled() \u0026\u0026 \n          conf.get(DFSConfigKeys.DFS_NAMENODE_KRB_HTTPS_USER_NAME_KEY) !\u003d null) {\n        // Go back to being the correct Namenode principal\n        LOG.info(\"Logging back in as \"\n            + SecurityUtil.getServerPrincipal(conf\n                .get(DFSConfigKeys.DFS_NAMENODE_USER_NAME_KEY), rpcAddress\n                .getHostName()) + \" following http server start.\");\n        SecurityUtil.login(conf, DFSConfigKeys.DFS_NAMENODE_KEYTAB_FILE_KEY,\n            DFSConfigKeys.DFS_NAMENODE_USER_NAME_KEY, rpcAddress.getHostName());\n      }\n    }\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java"
    }
  }
}