{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DiskChecker.java",
  "functionName": "diskIoCheckWithoutNativeIo",
  "functionId": "diskIoCheckWithoutNativeIo___file-File",
  "sourceFilePath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/DiskChecker.java",
  "functionStartLine": 283,
  "functionEndLine": 302,
  "numCommitsSeen": 12,
  "timeTaken": 1113,
  "changeHistory": [
    "4050471b45da569d7dc4f724b613ee2879c0ec2a",
    "1b6ecaf016aaf7f6a09a4d576294b5e0a6850a1f"
  ],
  "changeHistoryShort": {
    "4050471b45da569d7dc4f724b613ee2879c0ec2a": "Ybodychange",
    "1b6ecaf016aaf7f6a09a4d576294b5e0a6850a1f": "Yintroduced"
  },
  "changeHistoryDetails": {
    "4050471b45da569d7dc4f724b613ee2879c0ec2a": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-16657. Move remaining log4j APIs over to slf4j in hadoop-common. Contributed by Minni Mittal.\n",
      "commitDate": "18/11/19 6:31 PM",
      "commitName": "4050471b45da569d7dc4f724b613ee2879c0ec2a",
      "commitAuthor": "Abhishek Modi",
      "commitDateOld": "22/05/18 9:20 AM",
      "commitNameOld": "bcc8e76badc1341a6cf995c8e44fa5e422158de8",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 545.42,
      "commitsBetweenForRepo": 4096,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,20 @@\n   private static void diskIoCheckWithoutNativeIo(File file)\n       throws IOException {\n     FileOutputStream fos \u003d null;\n \n     try {\n       final FileIoProvider provider \u003d fileIoProvider.get();\n       fos \u003d provider.get(file);\n       provider.write(fos, new byte[1]);\n       fos.getFD().sync();\n       fos.close();\n       fos \u003d null;\n       if (!file.delete() \u0026\u0026 file.exists()) {\n         throw new IOException(\"Failed to delete \" + file);\n       }\n       file \u003d null;\n     } finally {\n-      IOUtils.cleanup(null, fos);\n+      IOUtils.cleanupWithLogger(LOG, fos);\n       FileUtils.deleteQuietly(file);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private static void diskIoCheckWithoutNativeIo(File file)\n      throws IOException {\n    FileOutputStream fos \u003d null;\n\n    try {\n      final FileIoProvider provider \u003d fileIoProvider.get();\n      fos \u003d provider.get(file);\n      provider.write(fos, new byte[1]);\n      fos.getFD().sync();\n      fos.close();\n      fos \u003d null;\n      if (!file.delete() \u0026\u0026 file.exists()) {\n        throw new IOException(\"Failed to delete \" + file);\n      }\n      file \u003d null;\n    } finally {\n      IOUtils.cleanupWithLogger(LOG, fos);\n      FileUtils.deleteQuietly(file);\n    }\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/DiskChecker.java",
      "extendedDetails": {}
    },
    "1b6ecaf016aaf7f6a09a4d576294b5e0a6850a1f": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-13738. DiskChecker should perform some disk IO.\n",
      "commitDate": "01/11/16 6:02 PM",
      "commitName": "1b6ecaf016aaf7f6a09a4d576294b5e0a6850a1f",
      "commitAuthor": "Arpit Agarwal",
      "diff": "@@ -0,0 +1,20 @@\n+  private static void diskIoCheckWithoutNativeIo(File file)\n+      throws IOException {\n+    FileOutputStream fos \u003d null;\n+\n+    try {\n+      final FileIoProvider provider \u003d fileIoProvider.get();\n+      fos \u003d provider.get(file);\n+      provider.write(fos, new byte[1]);\n+      fos.getFD().sync();\n+      fos.close();\n+      fos \u003d null;\n+      if (!file.delete() \u0026\u0026 file.exists()) {\n+        throw new IOException(\"Failed to delete \" + file);\n+      }\n+      file \u003d null;\n+    } finally {\n+      IOUtils.cleanup(null, fos);\n+      FileUtils.deleteQuietly(file);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private static void diskIoCheckWithoutNativeIo(File file)\n      throws IOException {\n    FileOutputStream fos \u003d null;\n\n    try {\n      final FileIoProvider provider \u003d fileIoProvider.get();\n      fos \u003d provider.get(file);\n      provider.write(fos, new byte[1]);\n      fos.getFD().sync();\n      fos.close();\n      fos \u003d null;\n      if (!file.delete() \u0026\u0026 file.exists()) {\n        throw new IOException(\"Failed to delete \" + file);\n      }\n      file \u003d null;\n    } finally {\n      IOUtils.cleanup(null, fos);\n      FileUtils.deleteQuietly(file);\n    }\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/DiskChecker.java"
    }
  }
}