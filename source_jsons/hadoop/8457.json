{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "SecondaryNameNode.java",
  "functionName": "getInfoServer",
  "functionId": "getInfoServer",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
  "functionStartLine": 453,
  "functionEndLine": 464,
  "numCommitsSeen": 98,
  "timeTaken": 5956,
  "changeHistory": [
    "045dc880e13271737b3cf316296e92fb95806663",
    "5dbbe0e0a5d31689d3425e490865f95057dc051c",
    "32c313d51cd2483ea510afe044c55eeaed7c2b2d",
    "8ae98a9d1ca4725e28783370517cb3a3ecda7324",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "045dc880e13271737b3cf316296e92fb95806663": "Ymultichange(Yreturntypechange,Ybodychange)",
    "5dbbe0e0a5d31689d3425e490865f95057dc051c": "Ybodychange",
    "32c313d51cd2483ea510afe044c55eeaed7c2b2d": "Ybodychange",
    "8ae98a9d1ca4725e28783370517cb3a3ecda7324": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "045dc880e13271737b3cf316296e92fb95806663": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-5312. Generate HTTP/HTTPS URL in DFSUtil#getInfoServer() based on the configured http policy. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1548629 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "06/12/13 10:01 AM",
      "commitName": "045dc880e13271737b3cf316296e92fb95806663",
      "commitAuthor": "Jing Zhao",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-5312. Generate HTTP/HTTPS URL in DFSUtil#getInfoServer() based on the configured http policy. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1548629 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "06/12/13 10:01 AM",
          "commitName": "045dc880e13271737b3cf316296e92fb95806663",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "04/12/13 1:40 PM",
          "commitNameOld": "d02baff9a0d8cec92bde751777f3e575da2339c8",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 1.85,
          "commitsBetweenForRepo": 23,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,12 +1,12 @@\n-  private String getInfoServer() throws IOException {\n+  private URL getInfoServer() throws IOException {\n     URI fsName \u003d FileSystem.getDefaultUri(conf);\n     if (!HdfsConstants.HDFS_URI_SCHEME.equalsIgnoreCase(fsName.getScheme())) {\n       throw new IOException(\"This is not a DFS\");\n     }\n \n-    String configuredAddress \u003d DFSUtil.getInfoServer(null, conf, false);\n-    String address \u003d DFSUtil.substituteForWildcardAddress(configuredAddress,\n-        fsName.getHost());\n-    LOG.debug(\"Will connect to NameNode at HTTP address: \" + address);\n-    return address;\n+    final String scheme \u003d DFSUtil.getHttpClientScheme(conf);\n+    URI address \u003d DFSUtil.getInfoServerWithDefaultHost(fsName.getHost(), conf,\n+        scheme);\n+    LOG.debug(\"Will connect to NameNode at \" + address);\n+    return address.toURL();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private URL getInfoServer() throws IOException {\n    URI fsName \u003d FileSystem.getDefaultUri(conf);\n    if (!HdfsConstants.HDFS_URI_SCHEME.equalsIgnoreCase(fsName.getScheme())) {\n      throw new IOException(\"This is not a DFS\");\n    }\n\n    final String scheme \u003d DFSUtil.getHttpClientScheme(conf);\n    URI address \u003d DFSUtil.getInfoServerWithDefaultHost(fsName.getHost(), conf,\n        scheme);\n    LOG.debug(\"Will connect to NameNode at \" + address);\n    return address.toURL();\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
          "extendedDetails": {
            "oldValue": "String",
            "newValue": "URL"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5312. Generate HTTP/HTTPS URL in DFSUtil#getInfoServer() based on the configured http policy. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1548629 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "06/12/13 10:01 AM",
          "commitName": "045dc880e13271737b3cf316296e92fb95806663",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "04/12/13 1:40 PM",
          "commitNameOld": "d02baff9a0d8cec92bde751777f3e575da2339c8",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 1.85,
          "commitsBetweenForRepo": 23,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,12 +1,12 @@\n-  private String getInfoServer() throws IOException {\n+  private URL getInfoServer() throws IOException {\n     URI fsName \u003d FileSystem.getDefaultUri(conf);\n     if (!HdfsConstants.HDFS_URI_SCHEME.equalsIgnoreCase(fsName.getScheme())) {\n       throw new IOException(\"This is not a DFS\");\n     }\n \n-    String configuredAddress \u003d DFSUtil.getInfoServer(null, conf, false);\n-    String address \u003d DFSUtil.substituteForWildcardAddress(configuredAddress,\n-        fsName.getHost());\n-    LOG.debug(\"Will connect to NameNode at HTTP address: \" + address);\n-    return address;\n+    final String scheme \u003d DFSUtil.getHttpClientScheme(conf);\n+    URI address \u003d DFSUtil.getInfoServerWithDefaultHost(fsName.getHost(), conf,\n+        scheme);\n+    LOG.debug(\"Will connect to NameNode at \" + address);\n+    return address.toURL();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private URL getInfoServer() throws IOException {\n    URI fsName \u003d FileSystem.getDefaultUri(conf);\n    if (!HdfsConstants.HDFS_URI_SCHEME.equalsIgnoreCase(fsName.getScheme())) {\n      throw new IOException(\"This is not a DFS\");\n    }\n\n    final String scheme \u003d DFSUtil.getHttpClientScheme(conf);\n    URI address \u003d DFSUtil.getInfoServerWithDefaultHost(fsName.getHost(), conf,\n        scheme);\n    LOG.debug(\"Will connect to NameNode at \" + address);\n    return address.toURL();\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
          "extendedDetails": {}
        }
      ]
    },
    "5dbbe0e0a5d31689d3425e490865f95057dc051c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2617. Replaced Kerberized SSL for image transfer and fsck with SPNEGO-based solution. Contributed by Jakob Homan, Alejandro Abdelnur, and Aaron T. Myers\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1334216 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/05/12 2:58 PM",
      "commitName": "5dbbe0e0a5d31689d3425e490865f95057dc051c",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "02/05/12 6:44 PM",
      "commitNameOld": "cbc242429093ccabf76248f857de5e587a9682b0",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 1.84,
      "commitsBetweenForRepo": 18,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,12 @@\n   private String getInfoServer() throws IOException {\n     URI fsName \u003d FileSystem.getDefaultUri(conf);\n     if (!HdfsConstants.HDFS_URI_SCHEME.equalsIgnoreCase(fsName.getScheme())) {\n       throw new IOException(\"This is not a DFS\");\n     }\n \n-    String configuredAddress \u003d DFSUtil.getInfoServer(null, conf, true);\n+    String configuredAddress \u003d DFSUtil.getInfoServer(null, conf, false);\n     String address \u003d DFSUtil.substituteForWildcardAddress(configuredAddress,\n         fsName.getHost());\n     LOG.debug(\"Will connect to NameNode at HTTP address: \" + address);\n     return address;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private String getInfoServer() throws IOException {\n    URI fsName \u003d FileSystem.getDefaultUri(conf);\n    if (!HdfsConstants.HDFS_URI_SCHEME.equalsIgnoreCase(fsName.getScheme())) {\n      throw new IOException(\"This is not a DFS\");\n    }\n\n    String configuredAddress \u003d DFSUtil.getInfoServer(null, conf, false);\n    String address \u003d DFSUtil.substituteForWildcardAddress(configuredAddress,\n        fsName.getHost());\n    LOG.debug(\"Will connect to NameNode at HTTP address: \" + address);\n    return address;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
      "extendedDetails": {}
    },
    "32c313d51cd2483ea510afe044c55eeaed7c2b2d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2861. checkpointing should verify that the dfs.http.address has been configured to a non-loopback for peer NN. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1239886 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/02/12 2:21 PM",
      "commitName": "32c313d51cd2483ea510afe044c55eeaed7c2b2d",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "24/01/12 9:59 AM",
      "commitNameOld": "83bcb1bbf487a343d00327b32b37ba7101a75cfc",
      "commitAuthorOld": "",
      "daysBetweenCommits": 9.18,
      "commitsBetweenForRepo": 57,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,12 @@\n   private String getInfoServer() throws IOException {\n     URI fsName \u003d FileSystem.getDefaultUri(conf);\n     if (!HdfsConstants.HDFS_URI_SCHEME.equalsIgnoreCase(fsName.getScheme())) {\n       throw new IOException(\"This is not a DFS\");\n     }\n \n     String configuredAddress \u003d DFSUtil.getInfoServer(null, conf, true);\n-    InetSocketAddress sockAddr \u003d NetUtils.createSocketAddr(configuredAddress);\n-    if (sockAddr.getAddress().isAnyLocalAddress()) {\n-      if(UserGroupInformation.isSecurityEnabled()) {\n-        throw new IOException(\"Cannot use a wildcard address with security. \" +\n-                              \"Must explicitly set bind address for Kerberos\");\n-      }\n-      return fsName.getHost() + \":\" + sockAddr.getPort();\n-    } else {\n-      if(LOG.isDebugEnabled()) {\n-        LOG.debug(\"configuredAddress \u003d \" + configuredAddress);\n-      }\n-      return configuredAddress;\n-    }\n+    String address \u003d DFSUtil.substituteForWildcardAddress(configuredAddress,\n+        fsName.getHost());\n+    LOG.debug(\"Will connect to NameNode at HTTP address: \" + address);\n+    return address;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private String getInfoServer() throws IOException {\n    URI fsName \u003d FileSystem.getDefaultUri(conf);\n    if (!HdfsConstants.HDFS_URI_SCHEME.equalsIgnoreCase(fsName.getScheme())) {\n      throw new IOException(\"This is not a DFS\");\n    }\n\n    String configuredAddress \u003d DFSUtil.getInfoServer(null, conf, true);\n    String address \u003d DFSUtil.substituteForWildcardAddress(configuredAddress,\n        fsName.getHost());\n    LOG.debug(\"Will connect to NameNode at HTTP address: \" + address);\n    return address;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
      "extendedDetails": {}
    },
    "8ae98a9d1ca4725e28783370517cb3a3ecda7324": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-1620. Rename HdfsConstants -\u003e HdfsServerConstants, FSConstants -\u003e HdfsConstants. (Harsh J Chouraria via atm)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1165096 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/09/11 12:30 PM",
      "commitName": "8ae98a9d1ca4725e28783370517cb3a3ecda7324",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "24/08/11 5:14 PM",
      "commitNameOld": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 10.8,
      "commitsBetweenForRepo": 53,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,21 @@\n   private String getInfoServer() throws IOException {\n     URI fsName \u003d FileSystem.getDefaultUri(conf);\n-    if (!FSConstants.HDFS_URI_SCHEME.equalsIgnoreCase(fsName.getScheme())) {\n+    if (!HdfsConstants.HDFS_URI_SCHEME.equalsIgnoreCase(fsName.getScheme())) {\n       throw new IOException(\"This is not a DFS\");\n     }\n \n     String configuredAddress \u003d DFSUtil.getInfoServer(null, conf, true);\n     InetSocketAddress sockAddr \u003d NetUtils.createSocketAddr(configuredAddress);\n     if (sockAddr.getAddress().isAnyLocalAddress()) {\n       if(UserGroupInformation.isSecurityEnabled()) {\n         throw new IOException(\"Cannot use a wildcard address with security. \" +\n                               \"Must explicitly set bind address for Kerberos\");\n       }\n       return fsName.getHost() + \":\" + sockAddr.getPort();\n     } else {\n       if(LOG.isDebugEnabled()) {\n         LOG.debug(\"configuredAddress \u003d \" + configuredAddress);\n       }\n       return configuredAddress;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private String getInfoServer() throws IOException {\n    URI fsName \u003d FileSystem.getDefaultUri(conf);\n    if (!HdfsConstants.HDFS_URI_SCHEME.equalsIgnoreCase(fsName.getScheme())) {\n      throw new IOException(\"This is not a DFS\");\n    }\n\n    String configuredAddress \u003d DFSUtil.getInfoServer(null, conf, true);\n    InetSocketAddress sockAddr \u003d NetUtils.createSocketAddr(configuredAddress);\n    if (sockAddr.getAddress().isAnyLocalAddress()) {\n      if(UserGroupInformation.isSecurityEnabled()) {\n        throw new IOException(\"Cannot use a wildcard address with security. \" +\n                              \"Must explicitly set bind address for Kerberos\");\n      }\n      return fsName.getHost() + \":\" + sockAddr.getPort();\n    } else {\n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"configuredAddress \u003d \" + configuredAddress);\n      }\n      return configuredAddress;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private String getInfoServer() throws IOException {\n    URI fsName \u003d FileSystem.getDefaultUri(conf);\n    if (!FSConstants.HDFS_URI_SCHEME.equalsIgnoreCase(fsName.getScheme())) {\n      throw new IOException(\"This is not a DFS\");\n    }\n\n    String configuredAddress \u003d DFSUtil.getInfoServer(null, conf, true);\n    InetSocketAddress sockAddr \u003d NetUtils.createSocketAddr(configuredAddress);\n    if (sockAddr.getAddress().isAnyLocalAddress()) {\n      if(UserGroupInformation.isSecurityEnabled()) {\n        throw new IOException(\"Cannot use a wildcard address with security. \" +\n                              \"Must explicitly set bind address for Kerberos\");\n      }\n      return fsName.getHost() + \":\" + sockAddr.getPort();\n    } else {\n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"configuredAddress \u003d \" + configuredAddress);\n      }\n      return configuredAddress;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private String getInfoServer() throws IOException {\n    URI fsName \u003d FileSystem.getDefaultUri(conf);\n    if (!FSConstants.HDFS_URI_SCHEME.equalsIgnoreCase(fsName.getScheme())) {\n      throw new IOException(\"This is not a DFS\");\n    }\n\n    String configuredAddress \u003d DFSUtil.getInfoServer(null, conf, true);\n    InetSocketAddress sockAddr \u003d NetUtils.createSocketAddr(configuredAddress);\n    if (sockAddr.getAddress().isAnyLocalAddress()) {\n      if(UserGroupInformation.isSecurityEnabled()) {\n        throw new IOException(\"Cannot use a wildcard address with security. \" +\n                              \"Must explicitly set bind address for Kerberos\");\n      }\n      return fsName.getHost() + \":\" + sockAddr.getPort();\n    } else {\n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"configuredAddress \u003d \" + configuredAddress);\n      }\n      return configuredAddress;\n    }\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,21 @@\n+  private String getInfoServer() throws IOException {\n+    URI fsName \u003d FileSystem.getDefaultUri(conf);\n+    if (!FSConstants.HDFS_URI_SCHEME.equalsIgnoreCase(fsName.getScheme())) {\n+      throw new IOException(\"This is not a DFS\");\n+    }\n+\n+    String configuredAddress \u003d DFSUtil.getInfoServer(null, conf, true);\n+    InetSocketAddress sockAddr \u003d NetUtils.createSocketAddr(configuredAddress);\n+    if (sockAddr.getAddress().isAnyLocalAddress()) {\n+      if(UserGroupInformation.isSecurityEnabled()) {\n+        throw new IOException(\"Cannot use a wildcard address with security. \" +\n+                              \"Must explicitly set bind address for Kerberos\");\n+      }\n+      return fsName.getHost() + \":\" + sockAddr.getPort();\n+    } else {\n+      if(LOG.isDebugEnabled()) {\n+        LOG.debug(\"configuredAddress \u003d \" + configuredAddress);\n+      }\n+      return configuredAddress;\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private String getInfoServer() throws IOException {\n    URI fsName \u003d FileSystem.getDefaultUri(conf);\n    if (!FSConstants.HDFS_URI_SCHEME.equalsIgnoreCase(fsName.getScheme())) {\n      throw new IOException(\"This is not a DFS\");\n    }\n\n    String configuredAddress \u003d DFSUtil.getInfoServer(null, conf, true);\n    InetSocketAddress sockAddr \u003d NetUtils.createSocketAddr(configuredAddress);\n    if (sockAddr.getAddress().isAnyLocalAddress()) {\n      if(UserGroupInformation.isSecurityEnabled()) {\n        throw new IOException(\"Cannot use a wildcard address with security. \" +\n                              \"Must explicitly set bind address for Kerberos\");\n      }\n      return fsName.getHost() + \":\" + sockAddr.getPort();\n    } else {\n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"configuredAddress \u003d \" + configuredAddress);\n      }\n      return configuredAddress;\n    }\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java"
    }
  }
}