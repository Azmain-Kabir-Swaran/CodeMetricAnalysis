{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "Hdfs.java",
  "functionName": "createInternal",
  "functionId": "createInternal___f-Path__createFlag-EnumSet__CreateFlag____absolutePermission-FsPermission__bufferSize-int__replication-short__blockSize-long__progress-Progressable__checksumOpt-ChecksumOpt__createParent-boolean",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/fs/Hdfs.java",
  "functionStartLine": 100,
  "functionEndLine": 110,
  "numCommitsSeen": 47,
  "timeTaken": 6031,
  "changeHistory": [
    "77f7ca3e94ecaa442c007b12d4ad773b37da097c",
    "2efea952139b30dd1c881eed0b443ffa72be6dce",
    "bdee397e95e98ece071345822e2e4d3f690f09c3",
    "b0ea77303ba62a400376ca32c63c5b138f32cbe7",
    "1a76c82a31958aeb549b544fe81960a59b2a9d0b",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "77f7ca3e94ecaa442c007b12d4ad773b37da097c": "Yfilerename",
    "2efea952139b30dd1c881eed0b443ffa72be6dce": "Ybodychange",
    "bdee397e95e98ece071345822e2e4d3f690f09c3": "Ybodychange",
    "b0ea77303ba62a400376ca32c63c5b138f32cbe7": "Ymultichange(Yparameterchange,Ybodychange)",
    "1a76c82a31958aeb549b544fe81960a59b2a9d0b": "Ymultichange(Yreturntypechange,Ybodychange)",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "77f7ca3e94ecaa442c007b12d4ad773b37da097c": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-9815. Move o.a.h.fs.Hdfs to hadoop-hdfs-client. Contributed by Vinayakumar B.\n",
      "commitDate": "17/02/16 10:56 AM",
      "commitName": "77f7ca3e94ecaa442c007b12d4ad773b37da097c",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "17/02/16 8:27 AM",
      "commitNameOld": "fd1befb6ba450e45b1fcb3fb28b0da6c48daf6b3",
      "commitAuthorOld": "Xiaoyu Yao",
      "daysBetweenCommits": 0.1,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public HdfsDataOutputStream createInternal(Path f,\n      EnumSet\u003cCreateFlag\u003e createFlag, FsPermission absolutePermission,\n      int bufferSize, short replication, long blockSize, Progressable progress,\n      ChecksumOpt checksumOpt, boolean createParent) throws IOException {\n\n    final DFSOutputStream dfsos \u003d dfs.primitiveCreate(getUriPath(f),\n      absolutePermission, createFlag, createParent, replication, blockSize,\n      progress, bufferSize, checksumOpt);\n    return dfs.createWrappedOutputStream(dfsos, statistics,\n        dfsos.getInitialLen());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/fs/Hdfs.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/fs/Hdfs.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/fs/Hdfs.java"
      }
    },
    "2efea952139b30dd1c881eed0b443ffa72be6dce": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6391. Get the Key/IV from the NameNode for encrypted files in DFSClient. Contributed by Charles Lamb and Andrew Wang.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/fs-encryption@1606220 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/06/14 1:43 PM",
      "commitName": "2efea952139b30dd1c881eed0b443ffa72be6dce",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "16/06/14 11:13 AM",
      "commitNameOld": "c5b7236d9c3240f6cefc1782bc7926a678d104f4",
      "commitAuthorOld": "",
      "daysBetweenCommits": 11.1,
      "commitsBetweenForRepo": 39,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,26 +1,11 @@\n   public HdfsDataOutputStream createInternal(Path f,\n       EnumSet\u003cCreateFlag\u003e createFlag, FsPermission absolutePermission,\n       int bufferSize, short replication, long blockSize, Progressable progress,\n       ChecksumOpt checksumOpt, boolean createParent) throws IOException {\n \n     final DFSOutputStream dfsos \u003d dfs.primitiveCreate(getUriPath(f),\n       absolutePermission, createFlag, createParent, replication, blockSize,\n       progress, bufferSize, checksumOpt);\n-    final byte[] key \u003d dfsos.getKey();\n-    final byte[] iv \u003d dfsos.getIv();\n-    Preconditions.checkState(!(key \u003d\u003d null ^ iv \u003d\u003d null),\n-      \"Only one of the Key and IV were found.\");\n-    if (false \u0026\u0026 key !\u003d null) {\n-\n-      /*\n-       * The Key and IV were found. Wrap up the output stream with an encryption\n-       * wrapper.\n-       */\n-      final CryptoOutputStream cbos \u003d\n-        new CryptoOutputStream(dfsos, factory, key, iv);\n-      return new HdfsDataOutputStream(cbos, getStatistics());\n-    } else {\n-      /* No key/IV present so no encryption. */\n-      return new HdfsDataOutputStream(dfsos, getStatistics());\n-    }\n+    return dfs.createWrappedOutputStream(dfsos, statistics,\n+        dfsos.getInitialLen());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public HdfsDataOutputStream createInternal(Path f,\n      EnumSet\u003cCreateFlag\u003e createFlag, FsPermission absolutePermission,\n      int bufferSize, short replication, long blockSize, Progressable progress,\n      ChecksumOpt checksumOpt, boolean createParent) throws IOException {\n\n    final DFSOutputStream dfsos \u003d dfs.primitiveCreate(getUriPath(f),\n      absolutePermission, createFlag, createParent, replication, blockSize,\n      progress, bufferSize, checksumOpt);\n    return dfs.createWrappedOutputStream(dfsos, statistics,\n        dfsos.getInitialLen());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/fs/Hdfs.java",
      "extendedDetails": {}
    },
    "bdee397e95e98ece071345822e2e4d3f690f09c3": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-6392. Wire crypto streams for encrypted files in DFSClient. (clamb and yliu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/fs-encryption@1600582 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "05/06/14 3:10 AM",
      "commitName": "bdee397e95e98ece071345822e2e4d3f690f09c3",
      "commitAuthor": "Charles Lamb",
      "commitDateOld": "22/05/14 11:17 AM",
      "commitNameOld": "3671a5e16fbddbe5a0516289ce98e1305e02291c",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 13.66,
      "commitsBetweenForRepo": 53,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,8 +1,26 @@\n   public HdfsDataOutputStream createInternal(Path f,\n       EnumSet\u003cCreateFlag\u003e createFlag, FsPermission absolutePermission,\n       int bufferSize, short replication, long blockSize, Progressable progress,\n       ChecksumOpt checksumOpt, boolean createParent) throws IOException {\n-    return new HdfsDataOutputStream(dfs.primitiveCreate(getUriPath(f),\n-        absolutePermission, createFlag, createParent, replication, blockSize,\n-        progress, bufferSize, checksumOpt), getStatistics());\n+\n+    final DFSOutputStream dfsos \u003d dfs.primitiveCreate(getUriPath(f),\n+      absolutePermission, createFlag, createParent, replication, blockSize,\n+      progress, bufferSize, checksumOpt);\n+    final byte[] key \u003d dfsos.getKey();\n+    final byte[] iv \u003d dfsos.getIv();\n+    Preconditions.checkState(!(key \u003d\u003d null ^ iv \u003d\u003d null),\n+      \"Only one of the Key and IV were found.\");\n+    if (false \u0026\u0026 key !\u003d null) {\n+\n+      /*\n+       * The Key and IV were found. Wrap up the output stream with an encryption\n+       * wrapper.\n+       */\n+      final CryptoOutputStream cbos \u003d\n+        new CryptoOutputStream(dfsos, factory, key, iv);\n+      return new HdfsDataOutputStream(cbos, getStatistics());\n+    } else {\n+      /* No key/IV present so no encryption. */\n+      return new HdfsDataOutputStream(dfsos, getStatistics());\n+    }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public HdfsDataOutputStream createInternal(Path f,\n      EnumSet\u003cCreateFlag\u003e createFlag, FsPermission absolutePermission,\n      int bufferSize, short replication, long blockSize, Progressable progress,\n      ChecksumOpt checksumOpt, boolean createParent) throws IOException {\n\n    final DFSOutputStream dfsos \u003d dfs.primitiveCreate(getUriPath(f),\n      absolutePermission, createFlag, createParent, replication, blockSize,\n      progress, bufferSize, checksumOpt);\n    final byte[] key \u003d dfsos.getKey();\n    final byte[] iv \u003d dfsos.getIv();\n    Preconditions.checkState(!(key \u003d\u003d null ^ iv \u003d\u003d null),\n      \"Only one of the Key and IV were found.\");\n    if (false \u0026\u0026 key !\u003d null) {\n\n      /*\n       * The Key and IV were found. Wrap up the output stream with an encryption\n       * wrapper.\n       */\n      final CryptoOutputStream cbos \u003d\n        new CryptoOutputStream(dfsos, factory, key, iv);\n      return new HdfsDataOutputStream(cbos, getStatistics());\n    } else {\n      /* No key/IV present so no encryption. */\n      return new HdfsDataOutputStream(dfsos, getStatistics());\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/fs/Hdfs.java",
      "extendedDetails": {}
    },
    "b0ea77303ba62a400376ca32c63c5b138f32cbe7": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HADOOP-8240. Add a new API to allow users to specify a checksum type on FileSystem.create(..).  Contributed by Kihwal Lee\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1374696 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/12 10:46 PM",
      "commitName": "b0ea77303ba62a400376ca32c63c5b138f32cbe7",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HADOOP-8240. Add a new API to allow users to specify a checksum type on FileSystem.create(..).  Contributed by Kihwal Lee\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1374696 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/08/12 10:46 PM",
          "commitName": "b0ea77303ba62a400376ca32c63c5b138f32cbe7",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "27/06/12 6:25 PM",
          "commitNameOld": "f105784d6a28d2a0cedb619f0951de93d995e9da",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 52.18,
          "commitsBetweenForRepo": 293,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,8 +1,8 @@\n   public HdfsDataOutputStream createInternal(Path f,\n       EnumSet\u003cCreateFlag\u003e createFlag, FsPermission absolutePermission,\n       int bufferSize, short replication, long blockSize, Progressable progress,\n-      int bytesPerChecksum, boolean createParent) throws IOException {\n+      ChecksumOpt checksumOpt, boolean createParent) throws IOException {\n     return new HdfsDataOutputStream(dfs.primitiveCreate(getUriPath(f),\n         absolutePermission, createFlag, createParent, replication, blockSize,\n-        progress, bufferSize, bytesPerChecksum), getStatistics());\n+        progress, bufferSize, checksumOpt), getStatistics());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public HdfsDataOutputStream createInternal(Path f,\n      EnumSet\u003cCreateFlag\u003e createFlag, FsPermission absolutePermission,\n      int bufferSize, short replication, long blockSize, Progressable progress,\n      ChecksumOpt checksumOpt, boolean createParent) throws IOException {\n    return new HdfsDataOutputStream(dfs.primitiveCreate(getUriPath(f),\n        absolutePermission, createFlag, createParent, replication, blockSize,\n        progress, bufferSize, checksumOpt), getStatistics());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/fs/Hdfs.java",
          "extendedDetails": {
            "oldValue": "[f-Path, createFlag-EnumSet\u003cCreateFlag\u003e, absolutePermission-FsPermission, bufferSize-int, replication-short, blockSize-long, progress-Progressable, bytesPerChecksum-int, createParent-boolean]",
            "newValue": "[f-Path, createFlag-EnumSet\u003cCreateFlag\u003e, absolutePermission-FsPermission, bufferSize-int, replication-short, blockSize-long, progress-Progressable, checksumOpt-ChecksumOpt, createParent-boolean]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HADOOP-8240. Add a new API to allow users to specify a checksum type on FileSystem.create(..).  Contributed by Kihwal Lee\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1374696 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/08/12 10:46 PM",
          "commitName": "b0ea77303ba62a400376ca32c63c5b138f32cbe7",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "27/06/12 6:25 PM",
          "commitNameOld": "f105784d6a28d2a0cedb619f0951de93d995e9da",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 52.18,
          "commitsBetweenForRepo": 293,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,8 +1,8 @@\n   public HdfsDataOutputStream createInternal(Path f,\n       EnumSet\u003cCreateFlag\u003e createFlag, FsPermission absolutePermission,\n       int bufferSize, short replication, long blockSize, Progressable progress,\n-      int bytesPerChecksum, boolean createParent) throws IOException {\n+      ChecksumOpt checksumOpt, boolean createParent) throws IOException {\n     return new HdfsDataOutputStream(dfs.primitiveCreate(getUriPath(f),\n         absolutePermission, createFlag, createParent, replication, blockSize,\n-        progress, bufferSize, bytesPerChecksum), getStatistics());\n+        progress, bufferSize, checksumOpt), getStatistics());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public HdfsDataOutputStream createInternal(Path f,\n      EnumSet\u003cCreateFlag\u003e createFlag, FsPermission absolutePermission,\n      int bufferSize, short replication, long blockSize, Progressable progress,\n      ChecksumOpt checksumOpt, boolean createParent) throws IOException {\n    return new HdfsDataOutputStream(dfs.primitiveCreate(getUriPath(f),\n        absolutePermission, createFlag, createParent, replication, blockSize,\n        progress, bufferSize, checksumOpt), getStatistics());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/fs/Hdfs.java",
          "extendedDetails": {}
        }
      ]
    },
    "1a76c82a31958aeb549b544fe81960a59b2a9d0b": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-3322. Use HdfsDataInputStream and HdfsDataOutputStream in Hdfs.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1331114 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "26/04/12 2:50 PM",
      "commitName": "1a76c82a31958aeb549b544fe81960a59b2a9d0b",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-3322. Use HdfsDataInputStream and HdfsDataOutputStream in Hdfs.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1331114 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "26/04/12 2:50 PM",
          "commitName": "1a76c82a31958aeb549b544fe81960a59b2a9d0b",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "16/04/12 12:08 PM",
          "commitNameOld": "258da66cc7c74e48fe4224ac8552bf8ce8c68e2c",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 10.11,
          "commitsBetweenForRepo": 77,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,8 +1,8 @@\n-  public FSDataOutputStream createInternal(Path f,\n+  public HdfsDataOutputStream createInternal(Path f,\n       EnumSet\u003cCreateFlag\u003e createFlag, FsPermission absolutePermission,\n       int bufferSize, short replication, long blockSize, Progressable progress,\n       int bytesPerChecksum, boolean createParent) throws IOException {\n-    return new FSDataOutputStream(dfs.primitiveCreate(getUriPath(f),\n+    return new HdfsDataOutputStream(dfs.primitiveCreate(getUriPath(f),\n         absolutePermission, createFlag, createParent, replication, blockSize,\n         progress, bufferSize, bytesPerChecksum), getStatistics());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public HdfsDataOutputStream createInternal(Path f,\n      EnumSet\u003cCreateFlag\u003e createFlag, FsPermission absolutePermission,\n      int bufferSize, short replication, long blockSize, Progressable progress,\n      int bytesPerChecksum, boolean createParent) throws IOException {\n    return new HdfsDataOutputStream(dfs.primitiveCreate(getUriPath(f),\n        absolutePermission, createFlag, createParent, replication, blockSize,\n        progress, bufferSize, bytesPerChecksum), getStatistics());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/fs/Hdfs.java",
          "extendedDetails": {
            "oldValue": "FSDataOutputStream",
            "newValue": "HdfsDataOutputStream"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-3322. Use HdfsDataInputStream and HdfsDataOutputStream in Hdfs.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1331114 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "26/04/12 2:50 PM",
          "commitName": "1a76c82a31958aeb549b544fe81960a59b2a9d0b",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "16/04/12 12:08 PM",
          "commitNameOld": "258da66cc7c74e48fe4224ac8552bf8ce8c68e2c",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 10.11,
          "commitsBetweenForRepo": 77,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,8 +1,8 @@\n-  public FSDataOutputStream createInternal(Path f,\n+  public HdfsDataOutputStream createInternal(Path f,\n       EnumSet\u003cCreateFlag\u003e createFlag, FsPermission absolutePermission,\n       int bufferSize, short replication, long blockSize, Progressable progress,\n       int bytesPerChecksum, boolean createParent) throws IOException {\n-    return new FSDataOutputStream(dfs.primitiveCreate(getUriPath(f),\n+    return new HdfsDataOutputStream(dfs.primitiveCreate(getUriPath(f),\n         absolutePermission, createFlag, createParent, replication, blockSize,\n         progress, bufferSize, bytesPerChecksum), getStatistics());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public HdfsDataOutputStream createInternal(Path f,\n      EnumSet\u003cCreateFlag\u003e createFlag, FsPermission absolutePermission,\n      int bufferSize, short replication, long blockSize, Progressable progress,\n      int bytesPerChecksum, boolean createParent) throws IOException {\n    return new HdfsDataOutputStream(dfs.primitiveCreate(getUriPath(f),\n        absolutePermission, createFlag, createParent, replication, blockSize,\n        progress, bufferSize, bytesPerChecksum), getStatistics());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/fs/Hdfs.java",
          "extendedDetails": {}
        }
      ]
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public FSDataOutputStream createInternal(Path f,\n      EnumSet\u003cCreateFlag\u003e createFlag, FsPermission absolutePermission,\n      int bufferSize, short replication, long blockSize, Progressable progress,\n      int bytesPerChecksum, boolean createParent) throws IOException {\n    return new FSDataOutputStream(dfs.primitiveCreate(getUriPath(f),\n        absolutePermission, createFlag, createParent, replication, blockSize,\n        progress, bufferSize, bytesPerChecksum), getStatistics());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/fs/Hdfs.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/fs/Hdfs.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/fs/Hdfs.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public FSDataOutputStream createInternal(Path f,\n      EnumSet\u003cCreateFlag\u003e createFlag, FsPermission absolutePermission,\n      int bufferSize, short replication, long blockSize, Progressable progress,\n      int bytesPerChecksum, boolean createParent) throws IOException {\n    return new FSDataOutputStream(dfs.primitiveCreate(getUriPath(f),\n        absolutePermission, createFlag, createParent, replication, blockSize,\n        progress, bufferSize, bytesPerChecksum), getStatistics());\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/fs/Hdfs.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/fs/Hdfs.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/fs/Hdfs.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,8 @@\n+  public FSDataOutputStream createInternal(Path f,\n+      EnumSet\u003cCreateFlag\u003e createFlag, FsPermission absolutePermission,\n+      int bufferSize, short replication, long blockSize, Progressable progress,\n+      int bytesPerChecksum, boolean createParent) throws IOException {\n+    return new FSDataOutputStream(dfs.primitiveCreate(getUriPath(f),\n+        absolutePermission, createFlag, createParent, replication, blockSize,\n+        progress, bufferSize, bytesPerChecksum), getStatistics());\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public FSDataOutputStream createInternal(Path f,\n      EnumSet\u003cCreateFlag\u003e createFlag, FsPermission absolutePermission,\n      int bufferSize, short replication, long blockSize, Progressable progress,\n      int bytesPerChecksum, boolean createParent) throws IOException {\n    return new FSDataOutputStream(dfs.primitiveCreate(getUriPath(f),\n        absolutePermission, createFlag, createParent, replication, blockSize,\n        progress, bufferSize, bytesPerChecksum), getStatistics());\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/fs/Hdfs.java"
    }
  }
}