{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ClientNamenodeProtocolTranslatorPB.java",
  "functionName": "listOpenFiles",
  "functionId": "listOpenFiles___prevId-long__openFilesTypes-EnumSet__OpenFilesType____path-String",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolTranslatorPB.java",
  "functionStartLine": 2005,
  "functionEndLine": 2026,
  "numCommitsSeen": 101,
  "timeTaken": 3087,
  "changeHistory": [
    "bf5c94899537011465350d5d999fad9ffaeb605d",
    "42a1c98597e6dba2e371510a6b2b6b1fb94e4090"
  ],
  "changeHistoryShort": {
    "bf5c94899537011465350d5d999fad9ffaeb605d": "Ymultichange(Yparameterchange,Ybodychange)",
    "42a1c98597e6dba2e371510a6b2b6b1fb94e4090": "Yintroduced"
  },
  "changeHistoryDetails": {
    "bf5c94899537011465350d5d999fad9ffaeb605d": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-11848. Enhance dfsadmin listOpenFiles command to list files under a given path. Contributed by Yiqun Lin.\n",
      "commitDate": "05/01/18 10:31 PM",
      "commitName": "bf5c94899537011465350d5d999fad9ffaeb605d",
      "commitAuthor": "Yiqun Lin",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-11848. Enhance dfsadmin listOpenFiles command to list files under a given path. Contributed by Yiqun Lin.\n",
          "commitDate": "05/01/18 10:31 PM",
          "commitName": "bf5c94899537011465350d5d999fad9ffaeb605d",
          "commitAuthor": "Yiqun Lin",
          "commitDateOld": "02/01/18 2:59 PM",
          "commitNameOld": "42a1c98597e6dba2e371510a6b2b6b1fb94e4090",
          "commitAuthorOld": "Manoj Govindassamy",
          "daysBetweenCommits": 3.31,
          "commitsBetweenForRepo": 26,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,20 +1,22 @@\n   public BatchedEntries\u003cOpenFileEntry\u003e listOpenFiles(long prevId,\n-      EnumSet\u003cOpenFilesType\u003e openFilesTypes) throws IOException {\n+      EnumSet\u003cOpenFilesType\u003e openFilesTypes, String path) throws IOException {\n     ListOpenFilesRequestProto.Builder req \u003d\n         ListOpenFilesRequestProto.newBuilder().setId(prevId);\n     if (openFilesTypes !\u003d null) {\n       req.addAllTypes(PBHelperClient.convertOpenFileTypes(openFilesTypes));\n     }\n+    req.setPath(path);\n+\n     try {\n       ListOpenFilesResponseProto response \u003d\n           rpcProxy.listOpenFiles(null, req.build());\n       List\u003cOpenFileEntry\u003e openFileEntries \u003d\n           Lists.newArrayListWithCapacity(response.getEntriesCount());\n       for (OpenFilesBatchResponseProto p : response.getEntriesList()) {\n         openFileEntries.add(PBHelperClient.convert(p));\n       }\n       return new BatchedListEntries\u003c\u003e(openFileEntries, response.getHasMore());\n     } catch (ServiceException e) {\n       throw ProtobufHelper.getRemoteException(e);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public BatchedEntries\u003cOpenFileEntry\u003e listOpenFiles(long prevId,\n      EnumSet\u003cOpenFilesType\u003e openFilesTypes, String path) throws IOException {\n    ListOpenFilesRequestProto.Builder req \u003d\n        ListOpenFilesRequestProto.newBuilder().setId(prevId);\n    if (openFilesTypes !\u003d null) {\n      req.addAllTypes(PBHelperClient.convertOpenFileTypes(openFilesTypes));\n    }\n    req.setPath(path);\n\n    try {\n      ListOpenFilesResponseProto response \u003d\n          rpcProxy.listOpenFiles(null, req.build());\n      List\u003cOpenFileEntry\u003e openFileEntries \u003d\n          Lists.newArrayListWithCapacity(response.getEntriesCount());\n      for (OpenFilesBatchResponseProto p : response.getEntriesList()) {\n        openFileEntries.add(PBHelperClient.convert(p));\n      }\n      return new BatchedListEntries\u003c\u003e(openFileEntries, response.getHasMore());\n    } catch (ServiceException e) {\n      throw ProtobufHelper.getRemoteException(e);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolTranslatorPB.java",
          "extendedDetails": {
            "oldValue": "[prevId-long, openFilesTypes-EnumSet\u003cOpenFilesType\u003e]",
            "newValue": "[prevId-long, openFilesTypes-EnumSet\u003cOpenFilesType\u003e, path-String]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-11848. Enhance dfsadmin listOpenFiles command to list files under a given path. Contributed by Yiqun Lin.\n",
          "commitDate": "05/01/18 10:31 PM",
          "commitName": "bf5c94899537011465350d5d999fad9ffaeb605d",
          "commitAuthor": "Yiqun Lin",
          "commitDateOld": "02/01/18 2:59 PM",
          "commitNameOld": "42a1c98597e6dba2e371510a6b2b6b1fb94e4090",
          "commitAuthorOld": "Manoj Govindassamy",
          "daysBetweenCommits": 3.31,
          "commitsBetweenForRepo": 26,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,20 +1,22 @@\n   public BatchedEntries\u003cOpenFileEntry\u003e listOpenFiles(long prevId,\n-      EnumSet\u003cOpenFilesType\u003e openFilesTypes) throws IOException {\n+      EnumSet\u003cOpenFilesType\u003e openFilesTypes, String path) throws IOException {\n     ListOpenFilesRequestProto.Builder req \u003d\n         ListOpenFilesRequestProto.newBuilder().setId(prevId);\n     if (openFilesTypes !\u003d null) {\n       req.addAllTypes(PBHelperClient.convertOpenFileTypes(openFilesTypes));\n     }\n+    req.setPath(path);\n+\n     try {\n       ListOpenFilesResponseProto response \u003d\n           rpcProxy.listOpenFiles(null, req.build());\n       List\u003cOpenFileEntry\u003e openFileEntries \u003d\n           Lists.newArrayListWithCapacity(response.getEntriesCount());\n       for (OpenFilesBatchResponseProto p : response.getEntriesList()) {\n         openFileEntries.add(PBHelperClient.convert(p));\n       }\n       return new BatchedListEntries\u003c\u003e(openFileEntries, response.getHasMore());\n     } catch (ServiceException e) {\n       throw ProtobufHelper.getRemoteException(e);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public BatchedEntries\u003cOpenFileEntry\u003e listOpenFiles(long prevId,\n      EnumSet\u003cOpenFilesType\u003e openFilesTypes, String path) throws IOException {\n    ListOpenFilesRequestProto.Builder req \u003d\n        ListOpenFilesRequestProto.newBuilder().setId(prevId);\n    if (openFilesTypes !\u003d null) {\n      req.addAllTypes(PBHelperClient.convertOpenFileTypes(openFilesTypes));\n    }\n    req.setPath(path);\n\n    try {\n      ListOpenFilesResponseProto response \u003d\n          rpcProxy.listOpenFiles(null, req.build());\n      List\u003cOpenFileEntry\u003e openFileEntries \u003d\n          Lists.newArrayListWithCapacity(response.getEntriesCount());\n      for (OpenFilesBatchResponseProto p : response.getEntriesList()) {\n        openFileEntries.add(PBHelperClient.convert(p));\n      }\n      return new BatchedListEntries\u003c\u003e(openFileEntries, response.getHasMore());\n    } catch (ServiceException e) {\n      throw ProtobufHelper.getRemoteException(e);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolTranslatorPB.java",
          "extendedDetails": {}
        }
      ]
    },
    "42a1c98597e6dba2e371510a6b2b6b1fb94e4090": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-11847. Enhance dfsadmin listOpenFiles command to list files blocking datanode decommissioning.\n",
      "commitDate": "02/01/18 2:59 PM",
      "commitName": "42a1c98597e6dba2e371510a6b2b6b1fb94e4090",
      "commitAuthor": "Manoj Govindassamy",
      "diff": "@@ -0,0 +1,20 @@\n+  public BatchedEntries\u003cOpenFileEntry\u003e listOpenFiles(long prevId,\n+      EnumSet\u003cOpenFilesType\u003e openFilesTypes) throws IOException {\n+    ListOpenFilesRequestProto.Builder req \u003d\n+        ListOpenFilesRequestProto.newBuilder().setId(prevId);\n+    if (openFilesTypes !\u003d null) {\n+      req.addAllTypes(PBHelperClient.convertOpenFileTypes(openFilesTypes));\n+    }\n+    try {\n+      ListOpenFilesResponseProto response \u003d\n+          rpcProxy.listOpenFiles(null, req.build());\n+      List\u003cOpenFileEntry\u003e openFileEntries \u003d\n+          Lists.newArrayListWithCapacity(response.getEntriesCount());\n+      for (OpenFilesBatchResponseProto p : response.getEntriesList()) {\n+        openFileEntries.add(PBHelperClient.convert(p));\n+      }\n+      return new BatchedListEntries\u003c\u003e(openFileEntries, response.getHasMore());\n+    } catch (ServiceException e) {\n+      throw ProtobufHelper.getRemoteException(e);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public BatchedEntries\u003cOpenFileEntry\u003e listOpenFiles(long prevId,\n      EnumSet\u003cOpenFilesType\u003e openFilesTypes) throws IOException {\n    ListOpenFilesRequestProto.Builder req \u003d\n        ListOpenFilesRequestProto.newBuilder().setId(prevId);\n    if (openFilesTypes !\u003d null) {\n      req.addAllTypes(PBHelperClient.convertOpenFileTypes(openFilesTypes));\n    }\n    try {\n      ListOpenFilesResponseProto response \u003d\n          rpcProxy.listOpenFiles(null, req.build());\n      List\u003cOpenFileEntry\u003e openFileEntries \u003d\n          Lists.newArrayListWithCapacity(response.getEntriesCount());\n      for (OpenFilesBatchResponseProto p : response.getEntriesList()) {\n        openFileEntries.add(PBHelperClient.convert(p));\n      }\n      return new BatchedListEntries\u003c\u003e(openFileEntries, response.getHasMore());\n    } catch (ServiceException e) {\n      throw ProtobufHelper.getRemoteException(e);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolTranslatorPB.java"
    }
  }
}