{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DistributedFileSystem.java",
  "functionName": "listLocatedStatus",
  "functionId": "listLocatedStatus___p-Path(modifiers-final)__filter-PathFilter(modifiers-final)",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java",
  "functionStartLine": 1175,
  "functionEndLine": 1198,
  "numCommitsSeen": 214,
  "timeTaken": 8429,
  "changeHistory": [
    "7136e8c5582dc4061b566cb9f11a0d6a6d08bb93",
    "1c030c6e58dc83152f933323bb7743ad47f5af27",
    "67f13b58e4d41879845aa118186d984de2e312ed",
    "34f08944b7c8d58f531a3f3bf3d4ee4cd3fa643a",
    "8767e4cde172b6e6070e3fd45325ede617b99343",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "7136e8c5582dc4061b566cb9f11a0d6a6d08bb93": "Ybodychange",
    "1c030c6e58dc83152f933323bb7743ad47f5af27": "Yfilerename",
    "67f13b58e4d41879845aa118186d984de2e312ed": "Ybodychange",
    "34f08944b7c8d58f531a3f3bf3d4ee4cd3fa643a": "Ybodychange",
    "8767e4cde172b6e6070e3fd45325ede617b99343": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "7136e8c5582dc4061b566cb9f11a0d6a6d08bb93": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8979. Clean up checkstyle warnings in hadoop-hdfs-client module. Contributed by Mingliang Liu.\n",
      "commitDate": "03/10/15 11:38 AM",
      "commitName": "7136e8c5582dc4061b566cb9f11a0d6a6d08bb93",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "29/09/15 1:39 AM",
      "commitNameOld": "8fd55202468b28422b0df888641c9b08906fe4a7",
      "commitAuthorOld": "",
      "daysBetweenCommits": 4.42,
      "commitsBetweenForRepo": 29,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,24 @@\n   protected RemoteIterator\u003cLocatedFileStatus\u003e listLocatedStatus(final Path p,\n       final PathFilter filter)\n-  throws IOException {\n+      throws IOException {\n     Path absF \u003d fixRelativePart(p);\n     return new FileSystemLinkResolver\u003cRemoteIterator\u003cLocatedFileStatus\u003e\u003e() {\n       @Override\n       public RemoteIterator\u003cLocatedFileStatus\u003e doCall(final Path p)\n-          throws IOException, UnresolvedLinkException {\n-        return new DirListingIterator\u003cLocatedFileStatus\u003e(p, filter, true);\n+          throws IOException {\n+        return new DirListingIterator\u003c\u003e(p, filter, true);\n       }\n \n       @Override\n-      public RemoteIterator\u003cLocatedFileStatus\u003e next(final FileSystem fs, final Path p)\n-          throws IOException {\n+      public RemoteIterator\u003cLocatedFileStatus\u003e next(final FileSystem fs,\n+          final Path p) throws IOException {\n         if (fs instanceof DistributedFileSystem) {\n           return ((DistributedFileSystem)fs).listLocatedStatus(p, filter);\n         }\n         // symlink resolution for this methos does not work cross file systems\n         // because it is a protected method.\n         throw new IOException(\"Link resolution does not work with multiple \" +\n             \"file systems for listLocatedStatus(): \" + p);\n       }\n     }.resolve(this, absF);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected RemoteIterator\u003cLocatedFileStatus\u003e listLocatedStatus(final Path p,\n      final PathFilter filter)\n      throws IOException {\n    Path absF \u003d fixRelativePart(p);\n    return new FileSystemLinkResolver\u003cRemoteIterator\u003cLocatedFileStatus\u003e\u003e() {\n      @Override\n      public RemoteIterator\u003cLocatedFileStatus\u003e doCall(final Path p)\n          throws IOException {\n        return new DirListingIterator\u003c\u003e(p, filter, true);\n      }\n\n      @Override\n      public RemoteIterator\u003cLocatedFileStatus\u003e next(final FileSystem fs,\n          final Path p) throws IOException {\n        if (fs instanceof DistributedFileSystem) {\n          return ((DistributedFileSystem)fs).listLocatedStatus(p, filter);\n        }\n        // symlink resolution for this methos does not work cross file systems\n        // because it is a protected method.\n        throw new IOException(\"Link resolution does not work with multiple \" +\n            \"file systems for listLocatedStatus(): \" + p);\n      }\n    }.resolve(this, absF);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java",
      "extendedDetails": {}
    },
    "1c030c6e58dc83152f933323bb7743ad47f5af27": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8740. Move DistributedFileSystem to hadoop-hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "27/09/15 10:54 AM",
      "commitName": "1c030c6e58dc83152f933323bb7743ad47f5af27",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "27/09/15 1:42 AM",
      "commitNameOld": "f0f984e4e63d0dbafe93062a122ee051330db301",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 0.38,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  protected RemoteIterator\u003cLocatedFileStatus\u003e listLocatedStatus(final Path p,\n      final PathFilter filter)\n  throws IOException {\n    Path absF \u003d fixRelativePart(p);\n    return new FileSystemLinkResolver\u003cRemoteIterator\u003cLocatedFileStatus\u003e\u003e() {\n      @Override\n      public RemoteIterator\u003cLocatedFileStatus\u003e doCall(final Path p)\n          throws IOException, UnresolvedLinkException {\n        return new DirListingIterator\u003cLocatedFileStatus\u003e(p, filter, true);\n      }\n\n      @Override\n      public RemoteIterator\u003cLocatedFileStatus\u003e next(final FileSystem fs, final Path p)\n          throws IOException {\n        if (fs instanceof DistributedFileSystem) {\n          return ((DistributedFileSystem)fs).listLocatedStatus(p, filter);\n        }\n        // symlink resolution for this methos does not work cross file systems\n        // because it is a protected method.\n        throw new IOException(\"Link resolution does not work with multiple \" +\n            \"file systems for listLocatedStatus(): \" + p);\n      }\n    }.resolve(this, absF);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java"
      }
    },
    "67f13b58e4d41879845aa118186d984de2e312ed": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-10987. Provide an iterator-based listing API for FileSystem. Contributed by Kihwal Lee.\n",
      "commitDate": "03/11/14 6:20 AM",
      "commitName": "67f13b58e4d41879845aa118186d984de2e312ed",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "23/10/14 12:28 PM",
      "commitNameOld": "8c5b23b5473e447384f818d69d907d5c35ed6d6a",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 10.79,
      "commitsBetweenForRepo": 110,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,64 +1,24 @@\n   protected RemoteIterator\u003cLocatedFileStatus\u003e listLocatedStatus(final Path p,\n       final PathFilter filter)\n   throws IOException {\n-    final Path absF \u003d fixRelativePart(p);\n-    return new RemoteIterator\u003cLocatedFileStatus\u003e() {\n-      private DirectoryListing thisListing;\n-      private int i;\n-      private String src;\n-      private LocatedFileStatus curStat \u003d null;\n-\n-      { // initializer\n-        // Fully resolve symlinks in path first to avoid additional resolution\n-        // round-trips as we fetch more batches of listings\n-        src \u003d getPathName(resolvePath(absF));\n-        // fetch the first batch of entries in the directory\n-        thisListing \u003d dfs.listPaths(src, HdfsFileStatus.EMPTY_NAME, true);\n-        statistics.incrementReadOps(1);\n-        if (thisListing \u003d\u003d null) { // the directory does not exist\n-          throw new FileNotFoundException(\"File \" + p + \" does not exist.\");\n-        }\n+    Path absF \u003d fixRelativePart(p);\n+    return new FileSystemLinkResolver\u003cRemoteIterator\u003cLocatedFileStatus\u003e\u003e() {\n+      @Override\n+      public RemoteIterator\u003cLocatedFileStatus\u003e doCall(final Path p)\n+          throws IOException, UnresolvedLinkException {\n+        return new DirListingIterator\u003cLocatedFileStatus\u003e(p, filter, true);\n       }\n \n       @Override\n-      public boolean hasNext() throws IOException {\n-        while (curStat \u003d\u003d null \u0026\u0026 hasNextNoFilter()) {\n-          LocatedFileStatus next \u003d \n-              ((HdfsLocatedFileStatus)thisListing.getPartialListing()[i++])\n-              .makeQualifiedLocated(getUri(), absF);\n-          if (filter.accept(next.getPath())) {\n-            curStat \u003d next;\n-          }\n+      public RemoteIterator\u003cLocatedFileStatus\u003e next(final FileSystem fs, final Path p)\n+          throws IOException {\n+        if (fs instanceof DistributedFileSystem) {\n+          return ((DistributedFileSystem)fs).listLocatedStatus(p, filter);\n         }\n-        return curStat !\u003d null;\n+        // symlink resolution for this methos does not work cross file systems\n+        // because it is a protected method.\n+        throw new IOException(\"Link resolution does not work with multiple \" +\n+            \"file systems for listLocatedStatus(): \" + p);\n       }\n-      \n-      /** Check if there is a next item before applying the given filter */\n-      private boolean hasNextNoFilter() throws IOException {\n-        if (thisListing \u003d\u003d null) {\n-          return false;\n-        }\n-        if (i\u003e\u003dthisListing.getPartialListing().length\n-            \u0026\u0026 thisListing.hasMore()) { \n-          // current listing is exhausted \u0026 fetch a new listing\n-          thisListing \u003d dfs.listPaths(src, thisListing.getLastName(), true);\n-          statistics.incrementReadOps(1);\n-          if (thisListing \u003d\u003d null) {\n-            return false;\n-          }\n-          i \u003d 0;\n-        }\n-        return (i\u003cthisListing.getPartialListing().length);\n-      }\n-\n-      @Override\n-      public LocatedFileStatus next() throws IOException {\n-        if (hasNext()) {\n-          LocatedFileStatus tmp \u003d curStat;\n-          curStat \u003d null;\n-          return tmp;\n-        } \n-        throw new java.util.NoSuchElementException(\"No more entry in \" + p);\n-      }\n-    };\n+    }.resolve(this, absF);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected RemoteIterator\u003cLocatedFileStatus\u003e listLocatedStatus(final Path p,\n      final PathFilter filter)\n  throws IOException {\n    Path absF \u003d fixRelativePart(p);\n    return new FileSystemLinkResolver\u003cRemoteIterator\u003cLocatedFileStatus\u003e\u003e() {\n      @Override\n      public RemoteIterator\u003cLocatedFileStatus\u003e doCall(final Path p)\n          throws IOException, UnresolvedLinkException {\n        return new DirListingIterator\u003cLocatedFileStatus\u003e(p, filter, true);\n      }\n\n      @Override\n      public RemoteIterator\u003cLocatedFileStatus\u003e next(final FileSystem fs, final Path p)\n          throws IOException {\n        if (fs instanceof DistributedFileSystem) {\n          return ((DistributedFileSystem)fs).listLocatedStatus(p, filter);\n        }\n        // symlink resolution for this methos does not work cross file systems\n        // because it is a protected method.\n        throw new IOException(\"Link resolution does not work with multiple \" +\n            \"file systems for listLocatedStatus(): \" + p);\n      }\n    }.resolve(this, absF);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java",
      "extendedDetails": {}
    },
    "34f08944b7c8d58f531a3f3bf3d4ee4cd3fa643a": {
      "type": "Ybodychange",
      "commitMessage": "merge trunk to branch HDFS-4949\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1532952 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/10/13 7:14 PM",
      "commitName": "34f08944b7c8d58f531a3f3bf3d4ee4cd3fa643a",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "14/10/13 3:56 PM",
      "commitNameOld": "efe545b0c219eeba61ac5259aee4d518beb74316",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 2.14,
      "commitsBetweenForRepo": 6,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,63 +1,64 @@\n   protected RemoteIterator\u003cLocatedFileStatus\u003e listLocatedStatus(final Path p,\n       final PathFilter filter)\n   throws IOException {\n+    final Path absF \u003d fixRelativePart(p);\n     return new RemoteIterator\u003cLocatedFileStatus\u003e() {\n       private DirectoryListing thisListing;\n       private int i;\n       private String src;\n       private LocatedFileStatus curStat \u003d null;\n \n       { // initializer\n         // Fully resolve symlinks in path first to avoid additional resolution\n         // round-trips as we fetch more batches of listings\n-        src \u003d getPathName(resolvePath(p));\n+        src \u003d getPathName(resolvePath(absF));\n         // fetch the first batch of entries in the directory\n         thisListing \u003d dfs.listPaths(src, HdfsFileStatus.EMPTY_NAME, true);\n         statistics.incrementReadOps(1);\n         if (thisListing \u003d\u003d null) { // the directory does not exist\n           throw new FileNotFoundException(\"File \" + p + \" does not exist.\");\n         }\n       }\n \n       @Override\n       public boolean hasNext() throws IOException {\n         while (curStat \u003d\u003d null \u0026\u0026 hasNextNoFilter()) {\n           LocatedFileStatus next \u003d \n               ((HdfsLocatedFileStatus)thisListing.getPartialListing()[i++])\n-              .makeQualifiedLocated(getUri(), p);\n+              .makeQualifiedLocated(getUri(), absF);\n           if (filter.accept(next.getPath())) {\n             curStat \u003d next;\n           }\n         }\n         return curStat !\u003d null;\n       }\n       \n       /** Check if there is a next item before applying the given filter */\n       private boolean hasNextNoFilter() throws IOException {\n         if (thisListing \u003d\u003d null) {\n           return false;\n         }\n         if (i\u003e\u003dthisListing.getPartialListing().length\n             \u0026\u0026 thisListing.hasMore()) { \n           // current listing is exhausted \u0026 fetch a new listing\n           thisListing \u003d dfs.listPaths(src, thisListing.getLastName(), true);\n           statistics.incrementReadOps(1);\n           if (thisListing \u003d\u003d null) {\n             return false;\n           }\n           i \u003d 0;\n         }\n         return (i\u003cthisListing.getPartialListing().length);\n       }\n \n       @Override\n       public LocatedFileStatus next() throws IOException {\n         if (hasNext()) {\n           LocatedFileStatus tmp \u003d curStat;\n           curStat \u003d null;\n           return tmp;\n         } \n         throw new java.util.NoSuchElementException(\"No more entry in \" + p);\n       }\n     };\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected RemoteIterator\u003cLocatedFileStatus\u003e listLocatedStatus(final Path p,\n      final PathFilter filter)\n  throws IOException {\n    final Path absF \u003d fixRelativePart(p);\n    return new RemoteIterator\u003cLocatedFileStatus\u003e() {\n      private DirectoryListing thisListing;\n      private int i;\n      private String src;\n      private LocatedFileStatus curStat \u003d null;\n\n      { // initializer\n        // Fully resolve symlinks in path first to avoid additional resolution\n        // round-trips as we fetch more batches of listings\n        src \u003d getPathName(resolvePath(absF));\n        // fetch the first batch of entries in the directory\n        thisListing \u003d dfs.listPaths(src, HdfsFileStatus.EMPTY_NAME, true);\n        statistics.incrementReadOps(1);\n        if (thisListing \u003d\u003d null) { // the directory does not exist\n          throw new FileNotFoundException(\"File \" + p + \" does not exist.\");\n        }\n      }\n\n      @Override\n      public boolean hasNext() throws IOException {\n        while (curStat \u003d\u003d null \u0026\u0026 hasNextNoFilter()) {\n          LocatedFileStatus next \u003d \n              ((HdfsLocatedFileStatus)thisListing.getPartialListing()[i++])\n              .makeQualifiedLocated(getUri(), absF);\n          if (filter.accept(next.getPath())) {\n            curStat \u003d next;\n          }\n        }\n        return curStat !\u003d null;\n      }\n      \n      /** Check if there is a next item before applying the given filter */\n      private boolean hasNextNoFilter() throws IOException {\n        if (thisListing \u003d\u003d null) {\n          return false;\n        }\n        if (i\u003e\u003dthisListing.getPartialListing().length\n            \u0026\u0026 thisListing.hasMore()) { \n          // current listing is exhausted \u0026 fetch a new listing\n          thisListing \u003d dfs.listPaths(src, thisListing.getLastName(), true);\n          statistics.incrementReadOps(1);\n          if (thisListing \u003d\u003d null) {\n            return false;\n          }\n          i \u003d 0;\n        }\n        return (i\u003cthisListing.getPartialListing().length);\n      }\n\n      @Override\n      public LocatedFileStatus next() throws IOException {\n        if (hasNext()) {\n          LocatedFileStatus tmp \u003d curStat;\n          curStat \u003d null;\n          return tmp;\n        } \n        throw new java.util.NoSuchElementException(\"No more entry in \" + p);\n      }\n    };\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java",
      "extendedDetails": {}
    },
    "8767e4cde172b6e6070e3fd45325ede617b99343": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-9418.  Add symlink support to DistributedFileSystem (Andrew Wang via Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1502373 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/07/13 2:31 PM",
      "commitName": "8767e4cde172b6e6070e3fd45325ede617b99343",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "13/06/13 11:11 AM",
      "commitNameOld": "7e1744ccf9a9b5b035afbb182aad123a1d1d357f",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 28.14,
      "commitsBetweenForRepo": 172,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,60 +1,63 @@\n   protected RemoteIterator\u003cLocatedFileStatus\u003e listLocatedStatus(final Path p,\n       final PathFilter filter)\n   throws IOException {\n     return new RemoteIterator\u003cLocatedFileStatus\u003e() {\n       private DirectoryListing thisListing;\n       private int i;\n       private String src;\n       private LocatedFileStatus curStat \u003d null;\n \n       { // initializer\n-        src \u003d getPathName(p);\n+        // Fully resolve symlinks in path first to avoid additional resolution\n+        // round-trips as we fetch more batches of listings\n+        src \u003d getPathName(resolvePath(p));\n         // fetch the first batch of entries in the directory\n         thisListing \u003d dfs.listPaths(src, HdfsFileStatus.EMPTY_NAME, true);\n         statistics.incrementReadOps(1);\n         if (thisListing \u003d\u003d null) { // the directory does not exist\n           throw new FileNotFoundException(\"File \" + p + \" does not exist.\");\n         }\n       }\n \n       @Override\n       public boolean hasNext() throws IOException {\n         while (curStat \u003d\u003d null \u0026\u0026 hasNextNoFilter()) {\n-          LocatedFileStatus next \u003d makeQualifiedLocated(\n-              (HdfsLocatedFileStatus)thisListing.getPartialListing()[i++], p);\n+          LocatedFileStatus next \u003d \n+              ((HdfsLocatedFileStatus)thisListing.getPartialListing()[i++])\n+              .makeQualifiedLocated(getUri(), p);\n           if (filter.accept(next.getPath())) {\n             curStat \u003d next;\n           }\n         }\n         return curStat !\u003d null;\n       }\n       \n       /** Check if there is a next item before applying the given filter */\n       private boolean hasNextNoFilter() throws IOException {\n         if (thisListing \u003d\u003d null) {\n           return false;\n         }\n         if (i\u003e\u003dthisListing.getPartialListing().length\n             \u0026\u0026 thisListing.hasMore()) { \n           // current listing is exhausted \u0026 fetch a new listing\n           thisListing \u003d dfs.listPaths(src, thisListing.getLastName(), true);\n           statistics.incrementReadOps(1);\n           if (thisListing \u003d\u003d null) {\n             return false;\n           }\n           i \u003d 0;\n         }\n         return (i\u003cthisListing.getPartialListing().length);\n       }\n \n       @Override\n       public LocatedFileStatus next() throws IOException {\n         if (hasNext()) {\n           LocatedFileStatus tmp \u003d curStat;\n           curStat \u003d null;\n           return tmp;\n         } \n         throw new java.util.NoSuchElementException(\"No more entry in \" + p);\n       }\n     };\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected RemoteIterator\u003cLocatedFileStatus\u003e listLocatedStatus(final Path p,\n      final PathFilter filter)\n  throws IOException {\n    return new RemoteIterator\u003cLocatedFileStatus\u003e() {\n      private DirectoryListing thisListing;\n      private int i;\n      private String src;\n      private LocatedFileStatus curStat \u003d null;\n\n      { // initializer\n        // Fully resolve symlinks in path first to avoid additional resolution\n        // round-trips as we fetch more batches of listings\n        src \u003d getPathName(resolvePath(p));\n        // fetch the first batch of entries in the directory\n        thisListing \u003d dfs.listPaths(src, HdfsFileStatus.EMPTY_NAME, true);\n        statistics.incrementReadOps(1);\n        if (thisListing \u003d\u003d null) { // the directory does not exist\n          throw new FileNotFoundException(\"File \" + p + \" does not exist.\");\n        }\n      }\n\n      @Override\n      public boolean hasNext() throws IOException {\n        while (curStat \u003d\u003d null \u0026\u0026 hasNextNoFilter()) {\n          LocatedFileStatus next \u003d \n              ((HdfsLocatedFileStatus)thisListing.getPartialListing()[i++])\n              .makeQualifiedLocated(getUri(), p);\n          if (filter.accept(next.getPath())) {\n            curStat \u003d next;\n          }\n        }\n        return curStat !\u003d null;\n      }\n      \n      /** Check if there is a next item before applying the given filter */\n      private boolean hasNextNoFilter() throws IOException {\n        if (thisListing \u003d\u003d null) {\n          return false;\n        }\n        if (i\u003e\u003dthisListing.getPartialListing().length\n            \u0026\u0026 thisListing.hasMore()) { \n          // current listing is exhausted \u0026 fetch a new listing\n          thisListing \u003d dfs.listPaths(src, thisListing.getLastName(), true);\n          statistics.incrementReadOps(1);\n          if (thisListing \u003d\u003d null) {\n            return false;\n          }\n          i \u003d 0;\n        }\n        return (i\u003cthisListing.getPartialListing().length);\n      }\n\n      @Override\n      public LocatedFileStatus next() throws IOException {\n        if (hasNext()) {\n          LocatedFileStatus tmp \u003d curStat;\n          curStat \u003d null;\n          return tmp;\n        } \n        throw new java.util.NoSuchElementException(\"No more entry in \" + p);\n      }\n    };\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  protected RemoteIterator\u003cLocatedFileStatus\u003e listLocatedStatus(final Path p,\n      final PathFilter filter)\n  throws IOException {\n    return new RemoteIterator\u003cLocatedFileStatus\u003e() {\n      private DirectoryListing thisListing;\n      private int i;\n      private String src;\n      private LocatedFileStatus curStat \u003d null;\n\n      { // initializer\n        src \u003d getPathName(p);\n        // fetch the first batch of entries in the directory\n        thisListing \u003d dfs.listPaths(src, HdfsFileStatus.EMPTY_NAME, true);\n        statistics.incrementReadOps(1);\n        if (thisListing \u003d\u003d null) { // the directory does not exist\n          throw new FileNotFoundException(\"File \" + p + \" does not exist.\");\n        }\n      }\n\n      @Override\n      public boolean hasNext() throws IOException {\n        while (curStat \u003d\u003d null \u0026\u0026 hasNextNoFilter()) {\n          LocatedFileStatus next \u003d makeQualifiedLocated(\n              (HdfsLocatedFileStatus)thisListing.getPartialListing()[i++], p);\n          if (filter.accept(next.getPath())) {\n            curStat \u003d next;\n          }\n        }\n        return curStat !\u003d null;\n      }\n      \n      /** Check if there is a next item before applying the given filter */\n      private boolean hasNextNoFilter() throws IOException {\n        if (thisListing \u003d\u003d null) {\n          return false;\n        }\n        if (i\u003e\u003dthisListing.getPartialListing().length\n            \u0026\u0026 thisListing.hasMore()) { \n          // current listing is exhausted \u0026 fetch a new listing\n          thisListing \u003d dfs.listPaths(src, thisListing.getLastName(), true);\n          statistics.incrementReadOps(1);\n          if (thisListing \u003d\u003d null) {\n            return false;\n          }\n          i \u003d 0;\n        }\n        return (i\u003cthisListing.getPartialListing().length);\n      }\n\n      @Override\n      public LocatedFileStatus next() throws IOException {\n        if (hasNext()) {\n          LocatedFileStatus tmp \u003d curStat;\n          curStat \u003d null;\n          return tmp;\n        } \n        throw new java.util.NoSuchElementException(\"No more entry in \" + p);\n      }\n    };\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  protected RemoteIterator\u003cLocatedFileStatus\u003e listLocatedStatus(final Path p,\n      final PathFilter filter)\n  throws IOException {\n    return new RemoteIterator\u003cLocatedFileStatus\u003e() {\n      private DirectoryListing thisListing;\n      private int i;\n      private String src;\n      private LocatedFileStatus curStat \u003d null;\n\n      { // initializer\n        src \u003d getPathName(p);\n        // fetch the first batch of entries in the directory\n        thisListing \u003d dfs.listPaths(src, HdfsFileStatus.EMPTY_NAME, true);\n        statistics.incrementReadOps(1);\n        if (thisListing \u003d\u003d null) { // the directory does not exist\n          throw new FileNotFoundException(\"File \" + p + \" does not exist.\");\n        }\n      }\n\n      @Override\n      public boolean hasNext() throws IOException {\n        while (curStat \u003d\u003d null \u0026\u0026 hasNextNoFilter()) {\n          LocatedFileStatus next \u003d makeQualifiedLocated(\n              (HdfsLocatedFileStatus)thisListing.getPartialListing()[i++], p);\n          if (filter.accept(next.getPath())) {\n            curStat \u003d next;\n          }\n        }\n        return curStat !\u003d null;\n      }\n      \n      /** Check if there is a next item before applying the given filter */\n      private boolean hasNextNoFilter() throws IOException {\n        if (thisListing \u003d\u003d null) {\n          return false;\n        }\n        if (i\u003e\u003dthisListing.getPartialListing().length\n            \u0026\u0026 thisListing.hasMore()) { \n          // current listing is exhausted \u0026 fetch a new listing\n          thisListing \u003d dfs.listPaths(src, thisListing.getLastName(), true);\n          statistics.incrementReadOps(1);\n          if (thisListing \u003d\u003d null) {\n            return false;\n          }\n          i \u003d 0;\n        }\n        return (i\u003cthisListing.getPartialListing().length);\n      }\n\n      @Override\n      public LocatedFileStatus next() throws IOException {\n        if (hasNext()) {\n          LocatedFileStatus tmp \u003d curStat;\n          curStat \u003d null;\n          return tmp;\n        } \n        throw new java.util.NoSuchElementException(\"No more entry in \" + p);\n      }\n    };\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/DistributedFileSystem.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,60 @@\n+  protected RemoteIterator\u003cLocatedFileStatus\u003e listLocatedStatus(final Path p,\n+      final PathFilter filter)\n+  throws IOException {\n+    return new RemoteIterator\u003cLocatedFileStatus\u003e() {\n+      private DirectoryListing thisListing;\n+      private int i;\n+      private String src;\n+      private LocatedFileStatus curStat \u003d null;\n+\n+      { // initializer\n+        src \u003d getPathName(p);\n+        // fetch the first batch of entries in the directory\n+        thisListing \u003d dfs.listPaths(src, HdfsFileStatus.EMPTY_NAME, true);\n+        statistics.incrementReadOps(1);\n+        if (thisListing \u003d\u003d null) { // the directory does not exist\n+          throw new FileNotFoundException(\"File \" + p + \" does not exist.\");\n+        }\n+      }\n+\n+      @Override\n+      public boolean hasNext() throws IOException {\n+        while (curStat \u003d\u003d null \u0026\u0026 hasNextNoFilter()) {\n+          LocatedFileStatus next \u003d makeQualifiedLocated(\n+              (HdfsLocatedFileStatus)thisListing.getPartialListing()[i++], p);\n+          if (filter.accept(next.getPath())) {\n+            curStat \u003d next;\n+          }\n+        }\n+        return curStat !\u003d null;\n+      }\n+      \n+      /** Check if there is a next item before applying the given filter */\n+      private boolean hasNextNoFilter() throws IOException {\n+        if (thisListing \u003d\u003d null) {\n+          return false;\n+        }\n+        if (i\u003e\u003dthisListing.getPartialListing().length\n+            \u0026\u0026 thisListing.hasMore()) { \n+          // current listing is exhausted \u0026 fetch a new listing\n+          thisListing \u003d dfs.listPaths(src, thisListing.getLastName(), true);\n+          statistics.incrementReadOps(1);\n+          if (thisListing \u003d\u003d null) {\n+            return false;\n+          }\n+          i \u003d 0;\n+        }\n+        return (i\u003cthisListing.getPartialListing().length);\n+      }\n+\n+      @Override\n+      public LocatedFileStatus next() throws IOException {\n+        if (hasNext()) {\n+          LocatedFileStatus tmp \u003d curStat;\n+          curStat \u003d null;\n+          return tmp;\n+        } \n+        throw new java.util.NoSuchElementException(\"No more entry in \" + p);\n+      }\n+    };\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  protected RemoteIterator\u003cLocatedFileStatus\u003e listLocatedStatus(final Path p,\n      final PathFilter filter)\n  throws IOException {\n    return new RemoteIterator\u003cLocatedFileStatus\u003e() {\n      private DirectoryListing thisListing;\n      private int i;\n      private String src;\n      private LocatedFileStatus curStat \u003d null;\n\n      { // initializer\n        src \u003d getPathName(p);\n        // fetch the first batch of entries in the directory\n        thisListing \u003d dfs.listPaths(src, HdfsFileStatus.EMPTY_NAME, true);\n        statistics.incrementReadOps(1);\n        if (thisListing \u003d\u003d null) { // the directory does not exist\n          throw new FileNotFoundException(\"File \" + p + \" does not exist.\");\n        }\n      }\n\n      @Override\n      public boolean hasNext() throws IOException {\n        while (curStat \u003d\u003d null \u0026\u0026 hasNextNoFilter()) {\n          LocatedFileStatus next \u003d makeQualifiedLocated(\n              (HdfsLocatedFileStatus)thisListing.getPartialListing()[i++], p);\n          if (filter.accept(next.getPath())) {\n            curStat \u003d next;\n          }\n        }\n        return curStat !\u003d null;\n      }\n      \n      /** Check if there is a next item before applying the given filter */\n      private boolean hasNextNoFilter() throws IOException {\n        if (thisListing \u003d\u003d null) {\n          return false;\n        }\n        if (i\u003e\u003dthisListing.getPartialListing().length\n            \u0026\u0026 thisListing.hasMore()) { \n          // current listing is exhausted \u0026 fetch a new listing\n          thisListing \u003d dfs.listPaths(src, thisListing.getLastName(), true);\n          statistics.incrementReadOps(1);\n          if (thisListing \u003d\u003d null) {\n            return false;\n          }\n          i \u003d 0;\n        }\n        return (i\u003cthisListing.getPartialListing().length);\n      }\n\n      @Override\n      public LocatedFileStatus next() throws IOException {\n        if (hasNext()) {\n          LocatedFileStatus tmp \u003d curStat;\n          curStat \u003d null;\n          return tmp;\n        } \n        throw new java.util.NoSuchElementException(\"No more entry in \" + p);\n      }\n    };\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/DistributedFileSystem.java"
    }
  }
}