{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockMetadataHeader.java",
  "functionName": "readHeader",
  "functionId": "readHeader___raf-RandomAccessFile",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockMetadataHeader.java",
  "functionStartLine": 176,
  "functionEndLine": 182,
  "numCommitsSeen": 18,
  "timeTaken": 1723,
  "changeHistory": [
    "c992bcf9c136d3df686655a80e636bb7bb0664da",
    "4a4450836c8972480b9387b5e31bab57ae2b5baa",
    "f84552ac35bb5221290be68fece9c779ebeaf4bc"
  ],
  "changeHistoryShort": {
    "c992bcf9c136d3df686655a80e636bb7bb0664da": "Yfilerename",
    "4a4450836c8972480b9387b5e31bab57ae2b5baa": "Ymodifierchange",
    "f84552ac35bb5221290be68fece9c779ebeaf4bc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "c992bcf9c136d3df686655a80e636bb7bb0664da": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8951. Move the shortcircuit package to hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "26/08/15 2:02 PM",
      "commitName": "c992bcf9c136d3df686655a80e636bb7bb0664da",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "25/08/15 2:29 PM",
      "commitNameOld": "a4d9acc51d1a977bc333da17780c00c72e8546f1",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 0.98,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public static BlockMetadataHeader readHeader(RandomAccessFile raf) throws IOException {\n    byte[] buf \u003d new byte[getHeaderSize()];\n    raf.seek(0);\n    raf.readFully(buf, 0, buf.length);\n    return readHeader(new DataInputStream(new ByteArrayInputStream(buf)));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockMetadataHeader.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockMetadataHeader.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockMetadataHeader.java"
      }
    },
    "4a4450836c8972480b9387b5e31bab57ae2b5baa": {
      "type": "Ymodifierchange",
      "commitMessage": "HDFS-5631. Change BlockMetadataHeader.readHeader(..), ChunkChecksum class and constructor to public; and fix FsDatasetSpi to use generic type instead of FsVolumeImpl.  Contributed by David Powell and Joe Pallas\n",
      "commitDate": "19/01/15 1:49 PM",
      "commitName": "4a4450836c8972480b9387b5e31bab57ae2b5baa",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "27/10/14 9:38 AM",
      "commitNameOld": "463aec11718e47d4aabb86a7a539cb973460aae6",
      "commitAuthorOld": "cnauroth",
      "daysBetweenCommits": 84.22,
      "commitsBetweenForRepo": 589,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,6 +1,6 @@\n-  static BlockMetadataHeader readHeader(RandomAccessFile raf) throws IOException {\n+  public static BlockMetadataHeader readHeader(RandomAccessFile raf) throws IOException {\n     byte[] buf \u003d new byte[getHeaderSize()];\n     raf.seek(0);\n     raf.readFully(buf, 0, buf.length);\n     return readHeader(new DataInputStream(new ByteArrayInputStream(buf)));\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static BlockMetadataHeader readHeader(RandomAccessFile raf) throws IOException {\n    byte[] buf \u003d new byte[getHeaderSize()];\n    raf.seek(0);\n    raf.readFully(buf, 0, buf.length);\n    return readHeader(new DataInputStream(new ByteArrayInputStream(buf)));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockMetadataHeader.java",
      "extendedDetails": {
        "oldValue": "[static]",
        "newValue": "[public, static]"
      }
    },
    "f84552ac35bb5221290be68fece9c779ebeaf4bc": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-2130. Switch default checksum to CRC32C. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1196889 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/11/11 5:35 PM",
      "commitName": "f84552ac35bb5221290be68fece9c779ebeaf4bc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,6 @@\n+  static BlockMetadataHeader readHeader(RandomAccessFile raf) throws IOException {\n+    byte[] buf \u003d new byte[getHeaderSize()];\n+    raf.seek(0);\n+    raf.readFully(buf, 0, buf.length);\n+    return readHeader(new DataInputStream(new ByteArrayInputStream(buf)));\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  static BlockMetadataHeader readHeader(RandomAccessFile raf) throws IOException {\n    byte[] buf \u003d new byte[getHeaderSize()];\n    raf.seek(0);\n    raf.readFully(buf, 0, buf.length);\n    return readHeader(new DataInputStream(new ByteArrayInputStream(buf)));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockMetadataHeader.java"
    }
  }
}