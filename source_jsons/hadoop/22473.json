{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "CompressedSplitLineReader.java",
  "functionName": "fillBuffer",
  "functionId": "fillBuffer___in-InputStream__buffer-byte[]__inDelimiter-boolean",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/input/CompressedSplitLineReader.java",
  "functionStartLine": 128,
  "functionEndLine": 146,
  "numCommitsSeen": 2,
  "timeTaken": 525,
  "changeHistory": [
    "18d99c12c371cfd7b9604e321d8bd6a7be9c4977"
  ],
  "changeHistoryShort": {
    "18d99c12c371cfd7b9604e321d8bd6a7be9c4977": "Yintroduced"
  },
  "changeHistoryDetails": {
    "18d99c12c371cfd7b9604e321d8bd6a7be9c4977": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-5656. bzip2 codec can drop records when reading data in splits. Contributed by Jason Lowe\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1549705 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/12/13 3:31 PM",
      "commitName": "18d99c12c371cfd7b9604e321d8bd6a7be9c4977",
      "commitAuthor": "Jason Darrell Lowe",
      "diff": "@@ -0,0 +1,19 @@\n+  protected int fillBuffer(InputStream in, byte[] buffer, boolean inDelimiter)\n+      throws IOException {\n+    int bytesRead \u003d in.read(buffer);\n+\n+    // If the split ended in the middle of a record delimiter then we need\n+    // to read one additional record, as the consumer of the next split will\n+    // not recognize the partial delimiter as a record.\n+    // However if using the default delimiter and the next character is a\n+    // linefeed then next split will treat it as a delimiter all by itself\n+    // and the additional record read should not be performed.\n+    if (inDelimiter \u0026\u0026 bytesRead \u003e 0) {\n+      if (usingCRLF) {\n+        needAdditionalRecord \u003d (buffer[0] !\u003d \u0027\\n\u0027);\n+      } else {\n+        needAdditionalRecord \u003d true;\n+      }\n+    }\n+    return bytesRead;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  protected int fillBuffer(InputStream in, byte[] buffer, boolean inDelimiter)\n      throws IOException {\n    int bytesRead \u003d in.read(buffer);\n\n    // If the split ended in the middle of a record delimiter then we need\n    // to read one additional record, as the consumer of the next split will\n    // not recognize the partial delimiter as a record.\n    // However if using the default delimiter and the next character is a\n    // linefeed then next split will treat it as a delimiter all by itself\n    // and the additional record read should not be performed.\n    if (inDelimiter \u0026\u0026 bytesRead \u003e 0) {\n      if (usingCRLF) {\n        needAdditionalRecord \u003d (buffer[0] !\u003d \u0027\\n\u0027);\n      } else {\n        needAdditionalRecord \u003d true;\n      }\n    }\n    return bytesRead;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/input/CompressedSplitLineReader.java"
    }
  }
}