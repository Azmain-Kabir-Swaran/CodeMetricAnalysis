{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "PeerCache.java",
  "functionName": "getInternal",
  "functionId": "getInternal___dnId-DatanodeID__isDomain-boolean",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/PeerCache.java",
  "functionStartLine": 156,
  "functionEndLine": 180,
  "numCommitsSeen": 14,
  "timeTaken": 1258,
  "changeHistory": [
    "e2c9b288b223b9fd82dc12018936e13128413492",
    "4799570dfdb7987c2ac39716143341e9a3d9b7d2"
  ],
  "changeHistoryShort": {
    "e2c9b288b223b9fd82dc12018936e13128413492": "Yfilerename",
    "4799570dfdb7987c2ac39716143341e9a3d9b7d2": "Yintroduced"
  },
  "changeHistoryDetails": {
    "e2c9b288b223b9fd82dc12018936e13128413492": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8925. Move BlockReaderLocal to hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "28/08/15 2:38 PM",
      "commitName": "e2c9b288b223b9fd82dc12018936e13128413492",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "28/08/15 2:21 PM",
      "commitNameOld": "b94b56806d3d6e04984e229b479f7ac15b62bbfa",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private synchronized Peer getInternal(DatanodeID dnId, boolean isDomain) {\n    List\u003cValue\u003e sockStreamList \u003d multimap.get(new Key(dnId, isDomain));\n    if (sockStreamList \u003d\u003d null) {\n      return null;\n    }\n\n    Iterator\u003cValue\u003e iter \u003d sockStreamList.iterator();\n    while (iter.hasNext()) {\n      Value candidate \u003d iter.next();\n      iter.remove();\n      long ageMs \u003d Time.monotonicNow() - candidate.getTime();\n      Peer peer \u003d candidate.getPeer();\n      if (ageMs \u003e\u003d expiryPeriod) {\n        try {\n          peer.close();\n        } catch (IOException e) {\n          LOG.warn(\"got IOException closing stale peer \" + peer +\n                \", which is \" + ageMs + \" ms old\");\n        }\n      } else if (!peer.isClosed()) {\n        return peer;\n      }\n    }\n    return null;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/PeerCache.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/PeerCache.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/PeerCache.java"
      }
    },
    "4799570dfdb7987c2ac39716143341e9a3d9b7d2": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-7266. HDFS Peercache enabled check should not lock on object (awang via cmccabe)\n",
      "commitDate": "20/10/14 6:24 PM",
      "commitName": "4799570dfdb7987c2ac39716143341e9a3d9b7d2",
      "commitAuthor": "Colin Patrick Mccabe",
      "diff": "@@ -0,0 +1,25 @@\n+  private synchronized Peer getInternal(DatanodeID dnId, boolean isDomain) {\n+    List\u003cValue\u003e sockStreamList \u003d multimap.get(new Key(dnId, isDomain));\n+    if (sockStreamList \u003d\u003d null) {\n+      return null;\n+    }\n+\n+    Iterator\u003cValue\u003e iter \u003d sockStreamList.iterator();\n+    while (iter.hasNext()) {\n+      Value candidate \u003d iter.next();\n+      iter.remove();\n+      long ageMs \u003d Time.monotonicNow() - candidate.getTime();\n+      Peer peer \u003d candidate.getPeer();\n+      if (ageMs \u003e\u003d expiryPeriod) {\n+        try {\n+          peer.close();\n+        } catch (IOException e) {\n+          LOG.warn(\"got IOException closing stale peer \" + peer +\n+                \", which is \" + ageMs + \" ms old\");\n+        }\n+      } else if (!peer.isClosed()) {\n+        return peer;\n+      }\n+    }\n+    return null;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized Peer getInternal(DatanodeID dnId, boolean isDomain) {\n    List\u003cValue\u003e sockStreamList \u003d multimap.get(new Key(dnId, isDomain));\n    if (sockStreamList \u003d\u003d null) {\n      return null;\n    }\n\n    Iterator\u003cValue\u003e iter \u003d sockStreamList.iterator();\n    while (iter.hasNext()) {\n      Value candidate \u003d iter.next();\n      iter.remove();\n      long ageMs \u003d Time.monotonicNow() - candidate.getTime();\n      Peer peer \u003d candidate.getPeer();\n      if (ageMs \u003e\u003d expiryPeriod) {\n        try {\n          peer.close();\n        } catch (IOException e) {\n          LOG.warn(\"got IOException closing stale peer \" + peer +\n                \", which is \" + ageMs + \" ms old\");\n        }\n      } else if (!peer.isClosed()) {\n        return peer;\n      }\n    }\n    return null;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/PeerCache.java"
    }
  }
}