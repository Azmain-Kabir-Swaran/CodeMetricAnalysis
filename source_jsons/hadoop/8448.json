{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "SecondaryNameNode.java",
  "functionName": "initialize",
  "functionId": "initialize___conf-Configuration(modifiers-final)__commandLineOpts-CommandLineOpts",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
  "functionStartLine": 213,
  "functionEndLine": 264,
  "numCommitsSeen": 104,
  "timeTaken": 10031,
  "changeHistory": [
    "65a941008d4bbf906772399d3f035f2a0da5abfa",
    "aa4b6fbe754ab7e3cf8ee106598d550f6e14783e",
    "6c8b6f3646b31a3e028704bc7fd78bf319f89f0a",
    "46b6d23e8fbed4c2ba537dd752116c173805bca7",
    "97f58955a6045b373ab73653bf26ab5922b00cf3",
    "140f4542b68787e87fa26ea82a82a5bc4aa93b0b",
    "a5b37c6ed14e92f5a7f7dd76a9a82b3f859fb6dd",
    "fe328621d4a84ae99efcb6394a910009b4e1761f",
    "94a1632fcb677fda6f4d812614026417f1d0a360",
    "dbd22b23c2d68b97b4da47215897906f06f978e3",
    "0f595915a388305edbb3ce928415571811d304e8",
    "33a47743a5f4263bc21b345587370c5ecf43f5b4",
    "87a6db45b70a1a07165e0773c4452d1327258bfa",
    "d02baff9a0d8cec92bde751777f3e575da2339c8",
    "2214871d916fdcae62aa51afbb5fd571f2808745",
    "782191f1ba27e0ff0acf3c6cf8a88df00274d308",
    "8c7a7e619699386f9e6991842558d78aa0c8053d",
    "09593530fb6ccb93fd123f9497b93f7ec733210f",
    "301079b4bfa1853f48ec0d118f2dd48f96d5d41b",
    "1cbc38a8783c1abe49dc6e076cb865642ca753ee",
    "5770a453f304d83463879db6101da1f1e81e5563",
    "5dbbe0e0a5d31689d3425e490865f95057dc051c",
    "65425b0961d6634f0fc0d798bbd12f02d40a8578",
    "1a75ec82885e45baf4d5cd56d6c738d8e68d8bc7",
    "c69dfdd5e14af490790dff8227b11962ec816577",
    "3bd230af1199ad741518c2359618bb8fb93e6d2a",
    "8faf7e8fb6e4024b03ce5f938daba626f2f5357c",
    "5b8dcb20a2fad2e7e9dee56c451f68f9d865b5ae",
    "2740112bb64e1cc8132a1dc450d9e461c2e4729e",
    "06e84a1bca19bd01568a3095e33944d4d6387fd3",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "28e6a4e44a3e920dcaf858f9a74a6358226b3a63",
    "b60772c47ddaefbeffd72bb9dce2a98117538dbc",
    "4c4eed13d5c3155e6a45fb06422e0f9059abfa9c",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "65a941008d4bbf906772399d3f035f2a0da5abfa": "Ybodychange",
    "aa4b6fbe754ab7e3cf8ee106598d550f6e14783e": "Ybodychange",
    "6c8b6f3646b31a3e028704bc7fd78bf319f89f0a": "Ybodychange",
    "46b6d23e8fbed4c2ba537dd752116c173805bca7": "Ybodychange",
    "97f58955a6045b373ab73653bf26ab5922b00cf3": "Ybodychange",
    "140f4542b68787e87fa26ea82a82a5bc4aa93b0b": "Ybodychange",
    "a5b37c6ed14e92f5a7f7dd76a9a82b3f859fb6dd": "Ybodychange",
    "fe328621d4a84ae99efcb6394a910009b4e1761f": "Ybodychange",
    "94a1632fcb677fda6f4d812614026417f1d0a360": "Ybodychange",
    "dbd22b23c2d68b97b4da47215897906f06f978e3": "Ybodychange",
    "0f595915a388305edbb3ce928415571811d304e8": "Ybodychange",
    "33a47743a5f4263bc21b345587370c5ecf43f5b4": "Ybodychange",
    "87a6db45b70a1a07165e0773c4452d1327258bfa": "Ybodychange",
    "d02baff9a0d8cec92bde751777f3e575da2339c8": "Ybodychange",
    "2214871d916fdcae62aa51afbb5fd571f2808745": "Ybodychange",
    "782191f1ba27e0ff0acf3c6cf8a88df00274d308": "Ybodychange",
    "8c7a7e619699386f9e6991842558d78aa0c8053d": "Ybodychange",
    "09593530fb6ccb93fd123f9497b93f7ec733210f": "Ybodychange",
    "301079b4bfa1853f48ec0d118f2dd48f96d5d41b": "Ybodychange",
    "1cbc38a8783c1abe49dc6e076cb865642ca753ee": "Ybodychange",
    "5770a453f304d83463879db6101da1f1e81e5563": "Ybodychange",
    "5dbbe0e0a5d31689d3425e490865f95057dc051c": "Ybodychange",
    "65425b0961d6634f0fc0d798bbd12f02d40a8578": "Ybodychange",
    "1a75ec82885e45baf4d5cd56d6c738d8e68d8bc7": "Ybodychange",
    "c69dfdd5e14af490790dff8227b11962ec816577": "Ybodychange",
    "3bd230af1199ad741518c2359618bb8fb93e6d2a": "Ybodychange",
    "8faf7e8fb6e4024b03ce5f938daba626f2f5357c": "Ybodychange",
    "5b8dcb20a2fad2e7e9dee56c451f68f9d865b5ae": "Ybodychange",
    "2740112bb64e1cc8132a1dc450d9e461c2e4729e": "Ybodychange",
    "06e84a1bca19bd01568a3095e33944d4d6387fd3": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "28e6a4e44a3e920dcaf858f9a74a6358226b3a63": "Ymultichange(Yparameterchange,Ybodychange)",
    "b60772c47ddaefbeffd72bb9dce2a98117538dbc": "Ybodychange",
    "4c4eed13d5c3155e6a45fb06422e0f9059abfa9c": "Ybodychange",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "65a941008d4bbf906772399d3f035f2a0da5abfa": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-10391. Always enable NameNode service RPC port. Contributed by Gergely Novak.\"\n\nThis reverts commit aa4b6fbe754ab7e3cf8ee106598d550f6e14783e.\n",
      "commitDate": "14/09/17 11:17 AM",
      "commitName": "65a941008d4bbf906772399d3f035f2a0da5abfa",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "09/09/17 8:40 AM",
      "commitNameOld": "aa4b6fbe754ab7e3cf8ee106598d550f6e14783e",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 5.11,
      "commitsBetweenForRepo": 81,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,52 +1,52 @@\n   private void initialize(final Configuration conf,\n       CommandLineOpts commandLineOpts) throws IOException {\n     final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n     final String infoBindAddress \u003d infoSocAddr.getHostName();\n     UserGroupInformation.setConfiguration(conf);\n     if (UserGroupInformation.isSecurityEnabled()) {\n       SecurityUtil.login(conf,\n           DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n           DFSConfigKeys.DFS_SECONDARY_NAMENODE_KERBEROS_PRINCIPAL_KEY, infoBindAddress);\n     }\n     // initiate Java VM metrics\n     DefaultMetricsSystem.initialize(\"SecondaryNameNode\");\n     JvmMetrics.create(\"SecondaryNameNode\",\n         conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n         DefaultMetricsSystem.instance());\n \n     // Create connection to the namenode.\n     shouldRun \u003d true;\n-    nameNodeAddr \u003d NameNode.getServiceAddress(conf);\n+    nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n \n     this.conf \u003d conf;\n     this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n         NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n         true).getProxy();\n \n     // initialize checkpoint directories\n     fsName \u003d getInfoServer();\n     checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                   \"/tmp/hadoop/dfs/namesecondary\");\n     checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                   \"/tmp/hadoop/dfs/namesecondary\");    \n     checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n     checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n     checkpointImage.deleteTempEdits();\n     \n     namesystem \u003d new FSNamesystem(conf, checkpointImage, true);\n \n     // Disable quota checks\n     namesystem.dir.disableQuotaChecks();\n \n     // Initialize other scheduling parameters from the configuration\n     checkpointConf \u003d new CheckpointConf(conf);\n     nameNodeStatusBeanName \u003d MBeans.register(\"SecondaryNameNode\",\n             \"SecondaryNameNodeInfo\", this);\n \n     legacyOivImageDir \u003d conf.get(\n         DFSConfigKeys.DFS_NAMENODE_LEGACY_OIV_IMAGE_DIR_KEY);\n \n     LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \"\n         + \"(\" + checkpointConf.getPeriod() / 60 + \" min)\");\n     LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void initialize(final Configuration conf,\n      CommandLineOpts commandLineOpts) throws IOException {\n    final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n    final String infoBindAddress \u003d infoSocAddr.getHostName();\n    UserGroupInformation.setConfiguration(conf);\n    if (UserGroupInformation.isSecurityEnabled()) {\n      SecurityUtil.login(conf,\n          DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n          DFSConfigKeys.DFS_SECONDARY_NAMENODE_KERBEROS_PRINCIPAL_KEY, infoBindAddress);\n    }\n    // initiate Java VM metrics\n    DefaultMetricsSystem.initialize(\"SecondaryNameNode\");\n    JvmMetrics.create(\"SecondaryNameNode\",\n        conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n        DefaultMetricsSystem.instance());\n\n    // Create connection to the namenode.\n    shouldRun \u003d true;\n    nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n\n    this.conf \u003d conf;\n    this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n        NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n        true).getProxy();\n\n    // initialize checkpoint directories\n    fsName \u003d getInfoServer();\n    checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                  \"/tmp/hadoop/dfs/namesecondary\");\n    checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                  \"/tmp/hadoop/dfs/namesecondary\");    \n    checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n    checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n    checkpointImage.deleteTempEdits();\n    \n    namesystem \u003d new FSNamesystem(conf, checkpointImage, true);\n\n    // Disable quota checks\n    namesystem.dir.disableQuotaChecks();\n\n    // Initialize other scheduling parameters from the configuration\n    checkpointConf \u003d new CheckpointConf(conf);\n    nameNodeStatusBeanName \u003d MBeans.register(\"SecondaryNameNode\",\n            \"SecondaryNameNodeInfo\", this);\n\n    legacyOivImageDir \u003d conf.get(\n        DFSConfigKeys.DFS_NAMENODE_LEGACY_OIV_IMAGE_DIR_KEY);\n\n    LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \"\n        + \"(\" + checkpointConf.getPeriod() / 60 + \" min)\");\n    LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
      "extendedDetails": {}
    },
    "aa4b6fbe754ab7e3cf8ee106598d550f6e14783e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10391. Always enable NameNode service RPC port. Contributed by Gergely Novak.\n",
      "commitDate": "09/09/17 8:40 AM",
      "commitName": "aa4b6fbe754ab7e3cf8ee106598d550f6e14783e",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "19/07/17 10:29 AM",
      "commitNameOld": "413b23eb04eee24275257ab462133e0818f87449",
      "commitAuthorOld": "Anu Engineer",
      "daysBetweenCommits": 51.92,
      "commitsBetweenForRepo": 436,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,52 +1,52 @@\n   private void initialize(final Configuration conf,\n       CommandLineOpts commandLineOpts) throws IOException {\n     final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n     final String infoBindAddress \u003d infoSocAddr.getHostName();\n     UserGroupInformation.setConfiguration(conf);\n     if (UserGroupInformation.isSecurityEnabled()) {\n       SecurityUtil.login(conf,\n           DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n           DFSConfigKeys.DFS_SECONDARY_NAMENODE_KERBEROS_PRINCIPAL_KEY, infoBindAddress);\n     }\n     // initiate Java VM metrics\n     DefaultMetricsSystem.initialize(\"SecondaryNameNode\");\n     JvmMetrics.create(\"SecondaryNameNode\",\n         conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n         DefaultMetricsSystem.instance());\n \n     // Create connection to the namenode.\n     shouldRun \u003d true;\n-    nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n+    nameNodeAddr \u003d NameNode.getServiceAddress(conf);\n \n     this.conf \u003d conf;\n     this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n         NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n         true).getProxy();\n \n     // initialize checkpoint directories\n     fsName \u003d getInfoServer();\n     checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                   \"/tmp/hadoop/dfs/namesecondary\");\n     checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                   \"/tmp/hadoop/dfs/namesecondary\");    \n     checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n     checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n     checkpointImage.deleteTempEdits();\n     \n     namesystem \u003d new FSNamesystem(conf, checkpointImage, true);\n \n     // Disable quota checks\n     namesystem.dir.disableQuotaChecks();\n \n     // Initialize other scheduling parameters from the configuration\n     checkpointConf \u003d new CheckpointConf(conf);\n     nameNodeStatusBeanName \u003d MBeans.register(\"SecondaryNameNode\",\n             \"SecondaryNameNodeInfo\", this);\n \n     legacyOivImageDir \u003d conf.get(\n         DFSConfigKeys.DFS_NAMENODE_LEGACY_OIV_IMAGE_DIR_KEY);\n \n     LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \"\n         + \"(\" + checkpointConf.getPeriod() / 60 + \" min)\");\n     LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void initialize(final Configuration conf,\n      CommandLineOpts commandLineOpts) throws IOException {\n    final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n    final String infoBindAddress \u003d infoSocAddr.getHostName();\n    UserGroupInformation.setConfiguration(conf);\n    if (UserGroupInformation.isSecurityEnabled()) {\n      SecurityUtil.login(conf,\n          DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n          DFSConfigKeys.DFS_SECONDARY_NAMENODE_KERBEROS_PRINCIPAL_KEY, infoBindAddress);\n    }\n    // initiate Java VM metrics\n    DefaultMetricsSystem.initialize(\"SecondaryNameNode\");\n    JvmMetrics.create(\"SecondaryNameNode\",\n        conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n        DefaultMetricsSystem.instance());\n\n    // Create connection to the namenode.\n    shouldRun \u003d true;\n    nameNodeAddr \u003d NameNode.getServiceAddress(conf);\n\n    this.conf \u003d conf;\n    this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n        NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n        true).getProxy();\n\n    // initialize checkpoint directories\n    fsName \u003d getInfoServer();\n    checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                  \"/tmp/hadoop/dfs/namesecondary\");\n    checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                  \"/tmp/hadoop/dfs/namesecondary\");    \n    checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n    checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n    checkpointImage.deleteTempEdits();\n    \n    namesystem \u003d new FSNamesystem(conf, checkpointImage, true);\n\n    // Disable quota checks\n    namesystem.dir.disableQuotaChecks();\n\n    // Initialize other scheduling parameters from the configuration\n    checkpointConf \u003d new CheckpointConf(conf);\n    nameNodeStatusBeanName \u003d MBeans.register(\"SecondaryNameNode\",\n            \"SecondaryNameNodeInfo\", this);\n\n    legacyOivImageDir \u003d conf.get(\n        DFSConfigKeys.DFS_NAMENODE_LEGACY_OIV_IMAGE_DIR_KEY);\n\n    LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \"\n        + \"(\" + checkpointConf.getPeriod() / 60 + \" min)\");\n    LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
      "extendedDetails": {}
    },
    "6c8b6f3646b31a3e028704bc7fd78bf319f89f0a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3059. ssl-server.xml causes NullPointer. Contributed by Xiao Chen.\n",
      "commitDate": "20/10/15 1:44 PM",
      "commitName": "6c8b6f3646b31a3e028704bc7fd78bf319f89f0a",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "03/09/15 11:22 AM",
      "commitNameOld": "53c38cc89ab979ec47557dcfa7affbad20578c0a",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 47.1,
      "commitsBetweenForRepo": 339,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,90 +1,52 @@\n   private void initialize(final Configuration conf,\n       CommandLineOpts commandLineOpts) throws IOException {\n     final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n     final String infoBindAddress \u003d infoSocAddr.getHostName();\n     UserGroupInformation.setConfiguration(conf);\n     if (UserGroupInformation.isSecurityEnabled()) {\n       SecurityUtil.login(conf,\n           DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n           DFSConfigKeys.DFS_SECONDARY_NAMENODE_KERBEROS_PRINCIPAL_KEY, infoBindAddress);\n     }\n     // initiate Java VM metrics\n     DefaultMetricsSystem.initialize(\"SecondaryNameNode\");\n     JvmMetrics.create(\"SecondaryNameNode\",\n         conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n         DefaultMetricsSystem.instance());\n \n     // Create connection to the namenode.\n     shouldRun \u003d true;\n     nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n \n     this.conf \u003d conf;\n     this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n         NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n         true).getProxy();\n \n     // initialize checkpoint directories\n     fsName \u003d getInfoServer();\n     checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                   \"/tmp/hadoop/dfs/namesecondary\");\n     checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                   \"/tmp/hadoop/dfs/namesecondary\");    \n     checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n     checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n     checkpointImage.deleteTempEdits();\n     \n     namesystem \u003d new FSNamesystem(conf, checkpointImage, true);\n \n     // Disable quota checks\n     namesystem.dir.disableQuotaChecks();\n \n     // Initialize other scheduling parameters from the configuration\n     checkpointConf \u003d new CheckpointConf(conf);\n-\n-    final InetSocketAddress httpAddr \u003d infoSocAddr;\n-\n-    final String httpsAddrString \u003d conf.getTrimmed(\n-        DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_KEY,\n-        DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_DEFAULT);\n-    InetSocketAddress httpsAddr \u003d NetUtils.createSocketAddr(httpsAddrString);\n-\n-    HttpServer2.Builder builder \u003d DFSUtil.httpServerTemplateForNNAndJN(conf,\n-        httpAddr, httpsAddr, \"secondary\",\n-        DFSConfigKeys.DFS_SECONDARY_NAMENODE_KERBEROS_INTERNAL_SPNEGO_PRINCIPAL_KEY,\n-        DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY);\n-\n     nameNodeStatusBeanName \u003d MBeans.register(\"SecondaryNameNode\",\n             \"SecondaryNameNodeInfo\", this);\n \n-    infoServer \u003d builder.build();\n-\n-    infoServer.setAttribute(\"secondary.name.node\", this);\n-    infoServer.setAttribute(\"name.system.image\", checkpointImage);\n-    infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n-    infoServer.addInternalServlet(\"imagetransfer\", ImageServlet.PATH_SPEC,\n-        ImageServlet.class, true);\n-    infoServer.start();\n-\n-    LOG.info(\"Web server init done\");\n-\n-    HttpConfig.Policy policy \u003d DFSUtil.getHttpPolicy(conf);\n-    int connIdx \u003d 0;\n-    if (policy.isHttpEnabled()) {\n-      InetSocketAddress httpAddress \u003d infoServer.getConnectorAddress(connIdx++);\n-      conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY,\n-          NetUtils.getHostPortString(httpAddress));\n-    }\n-\n-    if (policy.isHttpsEnabled()) {\n-      InetSocketAddress httpsAddress \u003d infoServer.getConnectorAddress(connIdx);\n-      conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_KEY,\n-          NetUtils.getHostPortString(httpsAddress));\n-    }\n-\n     legacyOivImageDir \u003d conf.get(\n         DFSConfigKeys.DFS_NAMENODE_LEGACY_OIV_IMAGE_DIR_KEY);\n \n     LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \"\n         + \"(\" + checkpointConf.getPeriod() / 60 + \" min)\");\n     LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void initialize(final Configuration conf,\n      CommandLineOpts commandLineOpts) throws IOException {\n    final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n    final String infoBindAddress \u003d infoSocAddr.getHostName();\n    UserGroupInformation.setConfiguration(conf);\n    if (UserGroupInformation.isSecurityEnabled()) {\n      SecurityUtil.login(conf,\n          DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n          DFSConfigKeys.DFS_SECONDARY_NAMENODE_KERBEROS_PRINCIPAL_KEY, infoBindAddress);\n    }\n    // initiate Java VM metrics\n    DefaultMetricsSystem.initialize(\"SecondaryNameNode\");\n    JvmMetrics.create(\"SecondaryNameNode\",\n        conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n        DefaultMetricsSystem.instance());\n\n    // Create connection to the namenode.\n    shouldRun \u003d true;\n    nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n\n    this.conf \u003d conf;\n    this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n        NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n        true).getProxy();\n\n    // initialize checkpoint directories\n    fsName \u003d getInfoServer();\n    checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                  \"/tmp/hadoop/dfs/namesecondary\");\n    checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                  \"/tmp/hadoop/dfs/namesecondary\");    \n    checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n    checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n    checkpointImage.deleteTempEdits();\n    \n    namesystem \u003d new FSNamesystem(conf, checkpointImage, true);\n\n    // Disable quota checks\n    namesystem.dir.disableQuotaChecks();\n\n    // Initialize other scheduling parameters from the configuration\n    checkpointConf \u003d new CheckpointConf(conf);\n    nameNodeStatusBeanName \u003d MBeans.register(\"SecondaryNameNode\",\n            \"SecondaryNameNodeInfo\", this);\n\n    legacyOivImageDir \u003d conf.get(\n        DFSConfigKeys.DFS_NAMENODE_LEGACY_OIV_IMAGE_DIR_KEY);\n\n    LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \"\n        + \"(\" + checkpointConf.getPeriod() / 60 + \" min)\");\n    LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
      "extendedDetails": {}
    },
    "46b6d23e8fbed4c2ba537dd752116c173805bca7": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7684. The host:port settings of the deamons should be trimmed before use. Contributed by Anu Engineer.\n",
      "commitDate": "12/02/15 5:40 PM",
      "commitName": "46b6d23e8fbed4c2ba537dd752116c173805bca7",
      "commitAuthor": "Akira Ajisaka",
      "commitDateOld": "18/06/14 9:13 PM",
      "commitNameOld": "a4e0ff5e052abad498595ee198b49c5310c9ec0d",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 238.89,
      "commitsBetweenForRepo": 2048,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,90 +1,90 @@\n   private void initialize(final Configuration conf,\n       CommandLineOpts commandLineOpts) throws IOException {\n     final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n     final String infoBindAddress \u003d infoSocAddr.getHostName();\n     UserGroupInformation.setConfiguration(conf);\n     if (UserGroupInformation.isSecurityEnabled()) {\n       SecurityUtil.login(conf,\n           DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n           DFSConfigKeys.DFS_SECONDARY_NAMENODE_KERBEROS_PRINCIPAL_KEY, infoBindAddress);\n     }\n     // initiate Java VM metrics\n     DefaultMetricsSystem.initialize(\"SecondaryNameNode\");\n     JvmMetrics.create(\"SecondaryNameNode\",\n         conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n         DefaultMetricsSystem.instance());\n \n     // Create connection to the namenode.\n     shouldRun \u003d true;\n     nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n \n     this.conf \u003d conf;\n     this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n         NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n         true).getProxy();\n \n     // initialize checkpoint directories\n     fsName \u003d getInfoServer();\n     checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                   \"/tmp/hadoop/dfs/namesecondary\");\n     checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                   \"/tmp/hadoop/dfs/namesecondary\");    \n     checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n     checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n     checkpointImage.deleteTempEdits();\n     \n     namesystem \u003d new FSNamesystem(conf, checkpointImage, true);\n \n     // Disable quota checks\n     namesystem.dir.disableQuotaChecks();\n \n     // Initialize other scheduling parameters from the configuration\n     checkpointConf \u003d new CheckpointConf(conf);\n \n     final InetSocketAddress httpAddr \u003d infoSocAddr;\n \n-    final String httpsAddrString \u003d conf.get(\n+    final String httpsAddrString \u003d conf.getTrimmed(\n         DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_KEY,\n         DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_DEFAULT);\n     InetSocketAddress httpsAddr \u003d NetUtils.createSocketAddr(httpsAddrString);\n \n     HttpServer2.Builder builder \u003d DFSUtil.httpServerTemplateForNNAndJN(conf,\n         httpAddr, httpsAddr, \"secondary\",\n         DFSConfigKeys.DFS_SECONDARY_NAMENODE_KERBEROS_INTERNAL_SPNEGO_PRINCIPAL_KEY,\n         DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY);\n \n     nameNodeStatusBeanName \u003d MBeans.register(\"SecondaryNameNode\",\n             \"SecondaryNameNodeInfo\", this);\n \n     infoServer \u003d builder.build();\n \n     infoServer.setAttribute(\"secondary.name.node\", this);\n     infoServer.setAttribute(\"name.system.image\", checkpointImage);\n     infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n     infoServer.addInternalServlet(\"imagetransfer\", ImageServlet.PATH_SPEC,\n         ImageServlet.class, true);\n     infoServer.start();\n \n     LOG.info(\"Web server init done\");\n \n     HttpConfig.Policy policy \u003d DFSUtil.getHttpPolicy(conf);\n     int connIdx \u003d 0;\n     if (policy.isHttpEnabled()) {\n       InetSocketAddress httpAddress \u003d infoServer.getConnectorAddress(connIdx++);\n       conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY,\n           NetUtils.getHostPortString(httpAddress));\n     }\n \n     if (policy.isHttpsEnabled()) {\n       InetSocketAddress httpsAddress \u003d infoServer.getConnectorAddress(connIdx);\n       conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_KEY,\n           NetUtils.getHostPortString(httpsAddress));\n     }\n \n     legacyOivImageDir \u003d conf.get(\n         DFSConfigKeys.DFS_NAMENODE_LEGACY_OIV_IMAGE_DIR_KEY);\n \n     LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \"\n         + \"(\" + checkpointConf.getPeriod() / 60 + \" min)\");\n     LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void initialize(final Configuration conf,\n      CommandLineOpts commandLineOpts) throws IOException {\n    final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n    final String infoBindAddress \u003d infoSocAddr.getHostName();\n    UserGroupInformation.setConfiguration(conf);\n    if (UserGroupInformation.isSecurityEnabled()) {\n      SecurityUtil.login(conf,\n          DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n          DFSConfigKeys.DFS_SECONDARY_NAMENODE_KERBEROS_PRINCIPAL_KEY, infoBindAddress);\n    }\n    // initiate Java VM metrics\n    DefaultMetricsSystem.initialize(\"SecondaryNameNode\");\n    JvmMetrics.create(\"SecondaryNameNode\",\n        conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n        DefaultMetricsSystem.instance());\n\n    // Create connection to the namenode.\n    shouldRun \u003d true;\n    nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n\n    this.conf \u003d conf;\n    this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n        NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n        true).getProxy();\n\n    // initialize checkpoint directories\n    fsName \u003d getInfoServer();\n    checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                  \"/tmp/hadoop/dfs/namesecondary\");\n    checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                  \"/tmp/hadoop/dfs/namesecondary\");    \n    checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n    checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n    checkpointImage.deleteTempEdits();\n    \n    namesystem \u003d new FSNamesystem(conf, checkpointImage, true);\n\n    // Disable quota checks\n    namesystem.dir.disableQuotaChecks();\n\n    // Initialize other scheduling parameters from the configuration\n    checkpointConf \u003d new CheckpointConf(conf);\n\n    final InetSocketAddress httpAddr \u003d infoSocAddr;\n\n    final String httpsAddrString \u003d conf.getTrimmed(\n        DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_KEY,\n        DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_DEFAULT);\n    InetSocketAddress httpsAddr \u003d NetUtils.createSocketAddr(httpsAddrString);\n\n    HttpServer2.Builder builder \u003d DFSUtil.httpServerTemplateForNNAndJN(conf,\n        httpAddr, httpsAddr, \"secondary\",\n        DFSConfigKeys.DFS_SECONDARY_NAMENODE_KERBEROS_INTERNAL_SPNEGO_PRINCIPAL_KEY,\n        DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY);\n\n    nameNodeStatusBeanName \u003d MBeans.register(\"SecondaryNameNode\",\n            \"SecondaryNameNodeInfo\", this);\n\n    infoServer \u003d builder.build();\n\n    infoServer.setAttribute(\"secondary.name.node\", this);\n    infoServer.setAttribute(\"name.system.image\", checkpointImage);\n    infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n    infoServer.addInternalServlet(\"imagetransfer\", ImageServlet.PATH_SPEC,\n        ImageServlet.class, true);\n    infoServer.start();\n\n    LOG.info(\"Web server init done\");\n\n    HttpConfig.Policy policy \u003d DFSUtil.getHttpPolicy(conf);\n    int connIdx \u003d 0;\n    if (policy.isHttpEnabled()) {\n      InetSocketAddress httpAddress \u003d infoServer.getConnectorAddress(connIdx++);\n      conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY,\n          NetUtils.getHostPortString(httpAddress));\n    }\n\n    if (policy.isHttpsEnabled()) {\n      InetSocketAddress httpsAddress \u003d infoServer.getConnectorAddress(connIdx);\n      conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_KEY,\n          NetUtils.getHostPortString(httpsAddress));\n    }\n\n    legacyOivImageDir \u003d conf.get(\n        DFSConfigKeys.DFS_NAMENODE_LEGACY_OIV_IMAGE_DIR_KEY);\n\n    LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \"\n        + \"(\" + checkpointConf.getPeriod() / 60 + \" min)\");\n    LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
      "extendedDetails": {}
    },
    "97f58955a6045b373ab73653bf26ab5922b00cf3": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6293. Issues with OIV processing PB-based fsimages. Contributed by Kihwal Lee.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1594439 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/05/14 6:15 PM",
      "commitName": "97f58955a6045b373ab73653bf26ab5922b00cf3",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "25/04/14 4:49 PM",
      "commitNameOld": "b8a3e2bb20674b81215ae6d038053e2cd716e7e5",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 18.06,
      "commitsBetweenForRepo": 87,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,87 +1,90 @@\n   private void initialize(final Configuration conf,\n       CommandLineOpts commandLineOpts) throws IOException {\n     final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n     final String infoBindAddress \u003d infoSocAddr.getHostName();\n     UserGroupInformation.setConfiguration(conf);\n     if (UserGroupInformation.isSecurityEnabled()) {\n       SecurityUtil.login(conf,\n           DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n           DFSConfigKeys.DFS_SECONDARY_NAMENODE_KERBEROS_PRINCIPAL_KEY, infoBindAddress);\n     }\n     // initiate Java VM metrics\n     DefaultMetricsSystem.initialize(\"SecondaryNameNode\");\n     JvmMetrics.create(\"SecondaryNameNode\",\n         conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n         DefaultMetricsSystem.instance());\n \n     // Create connection to the namenode.\n     shouldRun \u003d true;\n     nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n \n     this.conf \u003d conf;\n     this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n         NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n         true).getProxy();\n \n     // initialize checkpoint directories\n     fsName \u003d getInfoServer();\n     checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                   \"/tmp/hadoop/dfs/namesecondary\");\n     checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                   \"/tmp/hadoop/dfs/namesecondary\");    \n     checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n     checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n     checkpointImage.deleteTempEdits();\n     \n     namesystem \u003d new FSNamesystem(conf, checkpointImage, true);\n \n     // Disable quota checks\n     namesystem.dir.disableQuotaChecks();\n \n     // Initialize other scheduling parameters from the configuration\n     checkpointConf \u003d new CheckpointConf(conf);\n \n     final InetSocketAddress httpAddr \u003d infoSocAddr;\n \n     final String httpsAddrString \u003d conf.get(\n         DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_KEY,\n         DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_DEFAULT);\n     InetSocketAddress httpsAddr \u003d NetUtils.createSocketAddr(httpsAddrString);\n \n     HttpServer2.Builder builder \u003d DFSUtil.httpServerTemplateForNNAndJN(conf,\n         httpAddr, httpsAddr, \"secondary\",\n         DFSConfigKeys.DFS_SECONDARY_NAMENODE_KERBEROS_INTERNAL_SPNEGO_PRINCIPAL_KEY,\n         DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY);\n \n     nameNodeStatusBeanName \u003d MBeans.register(\"SecondaryNameNode\",\n             \"SecondaryNameNodeInfo\", this);\n \n     infoServer \u003d builder.build();\n \n     infoServer.setAttribute(\"secondary.name.node\", this);\n     infoServer.setAttribute(\"name.system.image\", checkpointImage);\n     infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n     infoServer.addInternalServlet(\"imagetransfer\", ImageServlet.PATH_SPEC,\n         ImageServlet.class, true);\n     infoServer.start();\n \n     LOG.info(\"Web server init done\");\n \n     HttpConfig.Policy policy \u003d DFSUtil.getHttpPolicy(conf);\n     int connIdx \u003d 0;\n     if (policy.isHttpEnabled()) {\n       InetSocketAddress httpAddress \u003d infoServer.getConnectorAddress(connIdx++);\n       conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY,\n           NetUtils.getHostPortString(httpAddress));\n     }\n \n     if (policy.isHttpsEnabled()) {\n       InetSocketAddress httpsAddress \u003d infoServer.getConnectorAddress(connIdx);\n       conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_KEY,\n           NetUtils.getHostPortString(httpsAddress));\n     }\n \n+    legacyOivImageDir \u003d conf.get(\n+        DFSConfigKeys.DFS_NAMENODE_LEGACY_OIV_IMAGE_DIR_KEY);\n+\n     LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \"\n         + \"(\" + checkpointConf.getPeriod() / 60 + \" min)\");\n     LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void initialize(final Configuration conf,\n      CommandLineOpts commandLineOpts) throws IOException {\n    final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n    final String infoBindAddress \u003d infoSocAddr.getHostName();\n    UserGroupInformation.setConfiguration(conf);\n    if (UserGroupInformation.isSecurityEnabled()) {\n      SecurityUtil.login(conf,\n          DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n          DFSConfigKeys.DFS_SECONDARY_NAMENODE_KERBEROS_PRINCIPAL_KEY, infoBindAddress);\n    }\n    // initiate Java VM metrics\n    DefaultMetricsSystem.initialize(\"SecondaryNameNode\");\n    JvmMetrics.create(\"SecondaryNameNode\",\n        conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n        DefaultMetricsSystem.instance());\n\n    // Create connection to the namenode.\n    shouldRun \u003d true;\n    nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n\n    this.conf \u003d conf;\n    this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n        NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n        true).getProxy();\n\n    // initialize checkpoint directories\n    fsName \u003d getInfoServer();\n    checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                  \"/tmp/hadoop/dfs/namesecondary\");\n    checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                  \"/tmp/hadoop/dfs/namesecondary\");    \n    checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n    checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n    checkpointImage.deleteTempEdits();\n    \n    namesystem \u003d new FSNamesystem(conf, checkpointImage, true);\n\n    // Disable quota checks\n    namesystem.dir.disableQuotaChecks();\n\n    // Initialize other scheduling parameters from the configuration\n    checkpointConf \u003d new CheckpointConf(conf);\n\n    final InetSocketAddress httpAddr \u003d infoSocAddr;\n\n    final String httpsAddrString \u003d conf.get(\n        DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_KEY,\n        DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_DEFAULT);\n    InetSocketAddress httpsAddr \u003d NetUtils.createSocketAddr(httpsAddrString);\n\n    HttpServer2.Builder builder \u003d DFSUtil.httpServerTemplateForNNAndJN(conf,\n        httpAddr, httpsAddr, \"secondary\",\n        DFSConfigKeys.DFS_SECONDARY_NAMENODE_KERBEROS_INTERNAL_SPNEGO_PRINCIPAL_KEY,\n        DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY);\n\n    nameNodeStatusBeanName \u003d MBeans.register(\"SecondaryNameNode\",\n            \"SecondaryNameNodeInfo\", this);\n\n    infoServer \u003d builder.build();\n\n    infoServer.setAttribute(\"secondary.name.node\", this);\n    infoServer.setAttribute(\"name.system.image\", checkpointImage);\n    infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n    infoServer.addInternalServlet(\"imagetransfer\", ImageServlet.PATH_SPEC,\n        ImageServlet.class, true);\n    infoServer.start();\n\n    LOG.info(\"Web server init done\");\n\n    HttpConfig.Policy policy \u003d DFSUtil.getHttpPolicy(conf);\n    int connIdx \u003d 0;\n    if (policy.isHttpEnabled()) {\n      InetSocketAddress httpAddress \u003d infoServer.getConnectorAddress(connIdx++);\n      conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY,\n          NetUtils.getHostPortString(httpAddress));\n    }\n\n    if (policy.isHttpsEnabled()) {\n      InetSocketAddress httpsAddress \u003d infoServer.getConnectorAddress(connIdx);\n      conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_KEY,\n          NetUtils.getHostPortString(httpsAddress));\n    }\n\n    legacyOivImageDir \u003d conf.get(\n        DFSConfigKeys.DFS_NAMENODE_LEGACY_OIV_IMAGE_DIR_KEY);\n\n    LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \"\n        + \"(\" + checkpointConf.getPeriod() / 60 + \" min)\");\n    LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
      "extendedDetails": {}
    },
    "140f4542b68787e87fa26ea82a82a5bc4aa93b0b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6278. Create HTML5-based UI for SNN. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1589613 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/04/14 12:15 AM",
      "commitName": "140f4542b68787e87fa26ea82a82a5bc4aa93b0b",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "23/04/14 1:13 PM",
      "commitNameOld": "876fd8ab7913a259ff9f69c16cc2d9af46ad3f9b",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 0.46,
      "commitsBetweenForRepo": 8,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,84 +1,87 @@\n   private void initialize(final Configuration conf,\n       CommandLineOpts commandLineOpts) throws IOException {\n     final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n     final String infoBindAddress \u003d infoSocAddr.getHostName();\n     UserGroupInformation.setConfiguration(conf);\n     if (UserGroupInformation.isSecurityEnabled()) {\n       SecurityUtil.login(conf,\n           DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n           DFSConfigKeys.DFS_SECONDARY_NAMENODE_KERBEROS_PRINCIPAL_KEY, infoBindAddress);\n     }\n     // initiate Java VM metrics\n     DefaultMetricsSystem.initialize(\"SecondaryNameNode\");\n     JvmMetrics.create(\"SecondaryNameNode\",\n         conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n         DefaultMetricsSystem.instance());\n \n     // Create connection to the namenode.\n     shouldRun \u003d true;\n     nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n \n     this.conf \u003d conf;\n     this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n         NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n         true).getProxy();\n \n     // initialize checkpoint directories\n     fsName \u003d getInfoServer();\n     checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                   \"/tmp/hadoop/dfs/namesecondary\");\n     checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                   \"/tmp/hadoop/dfs/namesecondary\");    \n     checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n     checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n     checkpointImage.deleteTempEdits();\n     \n     namesystem \u003d new FSNamesystem(conf, checkpointImage, true);\n \n     // Disable quota checks\n     namesystem.dir.disableQuotaChecks();\n \n     // Initialize other scheduling parameters from the configuration\n     checkpointConf \u003d new CheckpointConf(conf);\n \n     final InetSocketAddress httpAddr \u003d infoSocAddr;\n \n     final String httpsAddrString \u003d conf.get(\n         DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_KEY,\n         DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_DEFAULT);\n     InetSocketAddress httpsAddr \u003d NetUtils.createSocketAddr(httpsAddrString);\n \n     HttpServer2.Builder builder \u003d DFSUtil.httpServerTemplateForNNAndJN(conf,\n         httpAddr, httpsAddr, \"secondary\",\n         DFSConfigKeys.DFS_SECONDARY_NAMENODE_KERBEROS_INTERNAL_SPNEGO_PRINCIPAL_KEY,\n         DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY);\n \n+    nameNodeStatusBeanName \u003d MBeans.register(\"SecondaryNameNode\",\n+            \"SecondaryNameNodeInfo\", this);\n+\n     infoServer \u003d builder.build();\n \n     infoServer.setAttribute(\"secondary.name.node\", this);\n     infoServer.setAttribute(\"name.system.image\", checkpointImage);\n     infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n     infoServer.addInternalServlet(\"imagetransfer\", ImageServlet.PATH_SPEC,\n         ImageServlet.class, true);\n     infoServer.start();\n \n     LOG.info(\"Web server init done\");\n \n     HttpConfig.Policy policy \u003d DFSUtil.getHttpPolicy(conf);\n     int connIdx \u003d 0;\n     if (policy.isHttpEnabled()) {\n       InetSocketAddress httpAddress \u003d infoServer.getConnectorAddress(connIdx++);\n       conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY,\n           NetUtils.getHostPortString(httpAddress));\n     }\n \n     if (policy.isHttpsEnabled()) {\n       InetSocketAddress httpsAddress \u003d infoServer.getConnectorAddress(connIdx);\n       conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_KEY,\n           NetUtils.getHostPortString(httpsAddress));\n     }\n \n     LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \"\n         + \"(\" + checkpointConf.getPeriod() / 60 + \" min)\");\n     LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void initialize(final Configuration conf,\n      CommandLineOpts commandLineOpts) throws IOException {\n    final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n    final String infoBindAddress \u003d infoSocAddr.getHostName();\n    UserGroupInformation.setConfiguration(conf);\n    if (UserGroupInformation.isSecurityEnabled()) {\n      SecurityUtil.login(conf,\n          DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n          DFSConfigKeys.DFS_SECONDARY_NAMENODE_KERBEROS_PRINCIPAL_KEY, infoBindAddress);\n    }\n    // initiate Java VM metrics\n    DefaultMetricsSystem.initialize(\"SecondaryNameNode\");\n    JvmMetrics.create(\"SecondaryNameNode\",\n        conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n        DefaultMetricsSystem.instance());\n\n    // Create connection to the namenode.\n    shouldRun \u003d true;\n    nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n\n    this.conf \u003d conf;\n    this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n        NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n        true).getProxy();\n\n    // initialize checkpoint directories\n    fsName \u003d getInfoServer();\n    checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                  \"/tmp/hadoop/dfs/namesecondary\");\n    checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                  \"/tmp/hadoop/dfs/namesecondary\");    \n    checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n    checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n    checkpointImage.deleteTempEdits();\n    \n    namesystem \u003d new FSNamesystem(conf, checkpointImage, true);\n\n    // Disable quota checks\n    namesystem.dir.disableQuotaChecks();\n\n    // Initialize other scheduling parameters from the configuration\n    checkpointConf \u003d new CheckpointConf(conf);\n\n    final InetSocketAddress httpAddr \u003d infoSocAddr;\n\n    final String httpsAddrString \u003d conf.get(\n        DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_KEY,\n        DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_DEFAULT);\n    InetSocketAddress httpsAddr \u003d NetUtils.createSocketAddr(httpsAddrString);\n\n    HttpServer2.Builder builder \u003d DFSUtil.httpServerTemplateForNNAndJN(conf,\n        httpAddr, httpsAddr, \"secondary\",\n        DFSConfigKeys.DFS_SECONDARY_NAMENODE_KERBEROS_INTERNAL_SPNEGO_PRINCIPAL_KEY,\n        DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY);\n\n    nameNodeStatusBeanName \u003d MBeans.register(\"SecondaryNameNode\",\n            \"SecondaryNameNodeInfo\", this);\n\n    infoServer \u003d builder.build();\n\n    infoServer.setAttribute(\"secondary.name.node\", this);\n    infoServer.setAttribute(\"name.system.image\", checkpointImage);\n    infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n    infoServer.addInternalServlet(\"imagetransfer\", ImageServlet.PATH_SPEC,\n        ImageServlet.class, true);\n    infoServer.start();\n\n    LOG.info(\"Web server init done\");\n\n    HttpConfig.Policy policy \u003d DFSUtil.getHttpPolicy(conf);\n    int connIdx \u003d 0;\n    if (policy.isHttpEnabled()) {\n      InetSocketAddress httpAddress \u003d infoServer.getConnectorAddress(connIdx++);\n      conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY,\n          NetUtils.getHostPortString(httpAddress));\n    }\n\n    if (policy.isHttpsEnabled()) {\n      InetSocketAddress httpsAddress \u003d infoServer.getConnectorAddress(connIdx);\n      conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_KEY,\n          NetUtils.getHostPortString(httpsAddress));\n    }\n\n    LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \"\n        + \"(\" + checkpointConf.getPeriod() / 60 + \" min)\");\n    LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
      "extendedDetails": {}
    },
    "a5b37c6ed14e92f5a7f7dd76a9a82b3f859fb6dd": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6181. Fix the wrong property names in NFS user guide. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1585563 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/04/14 11:55 AM",
      "commitName": "a5b37c6ed14e92f5a7f7dd76a9a82b3f859fb6dd",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "07/04/14 11:25 AM",
      "commitNameOld": "fe328621d4a84ae99efcb6394a910009b4e1761f",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 0.02,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,84 +1,84 @@\n   private void initialize(final Configuration conf,\n       CommandLineOpts commandLineOpts) throws IOException {\n     final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n     final String infoBindAddress \u003d infoSocAddr.getHostName();\n     UserGroupInformation.setConfiguration(conf);\n     if (UserGroupInformation.isSecurityEnabled()) {\n       SecurityUtil.login(conf,\n           DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n-          DFSConfigKeys.DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n+          DFSConfigKeys.DFS_SECONDARY_NAMENODE_KERBEROS_PRINCIPAL_KEY, infoBindAddress);\n     }\n     // initiate Java VM metrics\n     DefaultMetricsSystem.initialize(\"SecondaryNameNode\");\n     JvmMetrics.create(\"SecondaryNameNode\",\n         conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n         DefaultMetricsSystem.instance());\n \n     // Create connection to the namenode.\n     shouldRun \u003d true;\n     nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n \n     this.conf \u003d conf;\n     this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n         NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n         true).getProxy();\n \n     // initialize checkpoint directories\n     fsName \u003d getInfoServer();\n     checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                   \"/tmp/hadoop/dfs/namesecondary\");\n     checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                   \"/tmp/hadoop/dfs/namesecondary\");    \n     checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n     checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n     checkpointImage.deleteTempEdits();\n     \n     namesystem \u003d new FSNamesystem(conf, checkpointImage, true);\n \n     // Disable quota checks\n     namesystem.dir.disableQuotaChecks();\n \n     // Initialize other scheduling parameters from the configuration\n     checkpointConf \u003d new CheckpointConf(conf);\n \n     final InetSocketAddress httpAddr \u003d infoSocAddr;\n \n     final String httpsAddrString \u003d conf.get(\n         DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_KEY,\n         DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_DEFAULT);\n     InetSocketAddress httpsAddr \u003d NetUtils.createSocketAddr(httpsAddrString);\n \n     HttpServer2.Builder builder \u003d DFSUtil.httpServerTemplateForNNAndJN(conf,\n         httpAddr, httpsAddr, \"secondary\",\n-        DFSConfigKeys.DFS_SECONDARY_NAMENODE_INTERNAL_SPNEGO_USER_NAME_KEY,\n+        DFSConfigKeys.DFS_SECONDARY_NAMENODE_KERBEROS_INTERNAL_SPNEGO_PRINCIPAL_KEY,\n         DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY);\n \n     infoServer \u003d builder.build();\n \n     infoServer.setAttribute(\"secondary.name.node\", this);\n     infoServer.setAttribute(\"name.system.image\", checkpointImage);\n     infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n     infoServer.addInternalServlet(\"imagetransfer\", ImageServlet.PATH_SPEC,\n         ImageServlet.class, true);\n     infoServer.start();\n \n     LOG.info(\"Web server init done\");\n \n     HttpConfig.Policy policy \u003d DFSUtil.getHttpPolicy(conf);\n     int connIdx \u003d 0;\n     if (policy.isHttpEnabled()) {\n       InetSocketAddress httpAddress \u003d infoServer.getConnectorAddress(connIdx++);\n       conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY,\n           NetUtils.getHostPortString(httpAddress));\n     }\n \n     if (policy.isHttpsEnabled()) {\n       InetSocketAddress httpsAddress \u003d infoServer.getConnectorAddress(connIdx);\n       conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_KEY,\n           NetUtils.getHostPortString(httpsAddress));\n     }\n \n     LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \"\n         + \"(\" + checkpointConf.getPeriod() / 60 + \" min)\");\n     LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void initialize(final Configuration conf,\n      CommandLineOpts commandLineOpts) throws IOException {\n    final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n    final String infoBindAddress \u003d infoSocAddr.getHostName();\n    UserGroupInformation.setConfiguration(conf);\n    if (UserGroupInformation.isSecurityEnabled()) {\n      SecurityUtil.login(conf,\n          DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n          DFSConfigKeys.DFS_SECONDARY_NAMENODE_KERBEROS_PRINCIPAL_KEY, infoBindAddress);\n    }\n    // initiate Java VM metrics\n    DefaultMetricsSystem.initialize(\"SecondaryNameNode\");\n    JvmMetrics.create(\"SecondaryNameNode\",\n        conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n        DefaultMetricsSystem.instance());\n\n    // Create connection to the namenode.\n    shouldRun \u003d true;\n    nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n\n    this.conf \u003d conf;\n    this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n        NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n        true).getProxy();\n\n    // initialize checkpoint directories\n    fsName \u003d getInfoServer();\n    checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                  \"/tmp/hadoop/dfs/namesecondary\");\n    checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                  \"/tmp/hadoop/dfs/namesecondary\");    \n    checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n    checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n    checkpointImage.deleteTempEdits();\n    \n    namesystem \u003d new FSNamesystem(conf, checkpointImage, true);\n\n    // Disable quota checks\n    namesystem.dir.disableQuotaChecks();\n\n    // Initialize other scheduling parameters from the configuration\n    checkpointConf \u003d new CheckpointConf(conf);\n\n    final InetSocketAddress httpAddr \u003d infoSocAddr;\n\n    final String httpsAddrString \u003d conf.get(\n        DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_KEY,\n        DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_DEFAULT);\n    InetSocketAddress httpsAddr \u003d NetUtils.createSocketAddr(httpsAddrString);\n\n    HttpServer2.Builder builder \u003d DFSUtil.httpServerTemplateForNNAndJN(conf,\n        httpAddr, httpsAddr, \"secondary\",\n        DFSConfigKeys.DFS_SECONDARY_NAMENODE_KERBEROS_INTERNAL_SPNEGO_PRINCIPAL_KEY,\n        DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY);\n\n    infoServer \u003d builder.build();\n\n    infoServer.setAttribute(\"secondary.name.node\", this);\n    infoServer.setAttribute(\"name.system.image\", checkpointImage);\n    infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n    infoServer.addInternalServlet(\"imagetransfer\", ImageServlet.PATH_SPEC,\n        ImageServlet.class, true);\n    infoServer.start();\n\n    LOG.info(\"Web server init done\");\n\n    HttpConfig.Policy policy \u003d DFSUtil.getHttpPolicy(conf);\n    int connIdx \u003d 0;\n    if (policy.isHttpEnabled()) {\n      InetSocketAddress httpAddress \u003d infoServer.getConnectorAddress(connIdx++);\n      conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY,\n          NetUtils.getHostPortString(httpAddress));\n    }\n\n    if (policy.isHttpsEnabled()) {\n      InetSocketAddress httpsAddress \u003d infoServer.getConnectorAddress(connIdx);\n      conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_KEY,\n          NetUtils.getHostPortString(httpsAddress));\n    }\n\n    LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \"\n        + \"(\" + checkpointConf.getPeriod() / 60 + \" min)\");\n    LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
      "extendedDetails": {}
    },
    "fe328621d4a84ae99efcb6394a910009b4e1761f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6191. Disable quota checks when replaying edit log.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1585544 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/04/14 11:25 AM",
      "commitName": "fe328621d4a84ae99efcb6394a910009b4e1761f",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "02/04/14 1:33 AM",
      "commitNameOld": "64c50d9dfb2247852b9e03fd3e41ce426f872e94",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 5.41,
      "commitsBetweenForRepo": 18,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,81 +1,84 @@\n   private void initialize(final Configuration conf,\n       CommandLineOpts commandLineOpts) throws IOException {\n     final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n     final String infoBindAddress \u003d infoSocAddr.getHostName();\n     UserGroupInformation.setConfiguration(conf);\n     if (UserGroupInformation.isSecurityEnabled()) {\n       SecurityUtil.login(conf,\n           DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n           DFSConfigKeys.DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n     }\n     // initiate Java VM metrics\n     DefaultMetricsSystem.initialize(\"SecondaryNameNode\");\n     JvmMetrics.create(\"SecondaryNameNode\",\n         conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n         DefaultMetricsSystem.instance());\n \n     // Create connection to the namenode.\n     shouldRun \u003d true;\n     nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n \n     this.conf \u003d conf;\n     this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n         NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n         true).getProxy();\n \n     // initialize checkpoint directories\n     fsName \u003d getInfoServer();\n     checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                   \"/tmp/hadoop/dfs/namesecondary\");\n     checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                   \"/tmp/hadoop/dfs/namesecondary\");    \n     checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n     checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n     checkpointImage.deleteTempEdits();\n     \n     namesystem \u003d new FSNamesystem(conf, checkpointImage, true);\n \n+    // Disable quota checks\n+    namesystem.dir.disableQuotaChecks();\n+\n     // Initialize other scheduling parameters from the configuration\n     checkpointConf \u003d new CheckpointConf(conf);\n \n     final InetSocketAddress httpAddr \u003d infoSocAddr;\n \n     final String httpsAddrString \u003d conf.get(\n         DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_KEY,\n         DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_DEFAULT);\n     InetSocketAddress httpsAddr \u003d NetUtils.createSocketAddr(httpsAddrString);\n \n     HttpServer2.Builder builder \u003d DFSUtil.httpServerTemplateForNNAndJN(conf,\n         httpAddr, httpsAddr, \"secondary\",\n         DFSConfigKeys.DFS_SECONDARY_NAMENODE_INTERNAL_SPNEGO_USER_NAME_KEY,\n         DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY);\n \n     infoServer \u003d builder.build();\n \n     infoServer.setAttribute(\"secondary.name.node\", this);\n     infoServer.setAttribute(\"name.system.image\", checkpointImage);\n     infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n     infoServer.addInternalServlet(\"imagetransfer\", ImageServlet.PATH_SPEC,\n         ImageServlet.class, true);\n     infoServer.start();\n \n     LOG.info(\"Web server init done\");\n \n     HttpConfig.Policy policy \u003d DFSUtil.getHttpPolicy(conf);\n     int connIdx \u003d 0;\n     if (policy.isHttpEnabled()) {\n       InetSocketAddress httpAddress \u003d infoServer.getConnectorAddress(connIdx++);\n       conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY,\n           NetUtils.getHostPortString(httpAddress));\n     }\n \n     if (policy.isHttpsEnabled()) {\n       InetSocketAddress httpsAddress \u003d infoServer.getConnectorAddress(connIdx);\n       conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_KEY,\n           NetUtils.getHostPortString(httpsAddress));\n     }\n \n     LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \"\n         + \"(\" + checkpointConf.getPeriod() / 60 + \" min)\");\n     LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void initialize(final Configuration conf,\n      CommandLineOpts commandLineOpts) throws IOException {\n    final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n    final String infoBindAddress \u003d infoSocAddr.getHostName();\n    UserGroupInformation.setConfiguration(conf);\n    if (UserGroupInformation.isSecurityEnabled()) {\n      SecurityUtil.login(conf,\n          DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n          DFSConfigKeys.DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n    }\n    // initiate Java VM metrics\n    DefaultMetricsSystem.initialize(\"SecondaryNameNode\");\n    JvmMetrics.create(\"SecondaryNameNode\",\n        conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n        DefaultMetricsSystem.instance());\n\n    // Create connection to the namenode.\n    shouldRun \u003d true;\n    nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n\n    this.conf \u003d conf;\n    this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n        NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n        true).getProxy();\n\n    // initialize checkpoint directories\n    fsName \u003d getInfoServer();\n    checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                  \"/tmp/hadoop/dfs/namesecondary\");\n    checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                  \"/tmp/hadoop/dfs/namesecondary\");    \n    checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n    checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n    checkpointImage.deleteTempEdits();\n    \n    namesystem \u003d new FSNamesystem(conf, checkpointImage, true);\n\n    // Disable quota checks\n    namesystem.dir.disableQuotaChecks();\n\n    // Initialize other scheduling parameters from the configuration\n    checkpointConf \u003d new CheckpointConf(conf);\n\n    final InetSocketAddress httpAddr \u003d infoSocAddr;\n\n    final String httpsAddrString \u003d conf.get(\n        DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_KEY,\n        DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_DEFAULT);\n    InetSocketAddress httpsAddr \u003d NetUtils.createSocketAddr(httpsAddrString);\n\n    HttpServer2.Builder builder \u003d DFSUtil.httpServerTemplateForNNAndJN(conf,\n        httpAddr, httpsAddr, \"secondary\",\n        DFSConfigKeys.DFS_SECONDARY_NAMENODE_INTERNAL_SPNEGO_USER_NAME_KEY,\n        DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY);\n\n    infoServer \u003d builder.build();\n\n    infoServer.setAttribute(\"secondary.name.node\", this);\n    infoServer.setAttribute(\"name.system.image\", checkpointImage);\n    infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n    infoServer.addInternalServlet(\"imagetransfer\", ImageServlet.PATH_SPEC,\n        ImageServlet.class, true);\n    infoServer.start();\n\n    LOG.info(\"Web server init done\");\n\n    HttpConfig.Policy policy \u003d DFSUtil.getHttpPolicy(conf);\n    int connIdx \u003d 0;\n    if (policy.isHttpEnabled()) {\n      InetSocketAddress httpAddress \u003d infoServer.getConnectorAddress(connIdx++);\n      conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY,\n          NetUtils.getHostPortString(httpAddress));\n    }\n\n    if (policy.isHttpsEnabled()) {\n      InetSocketAddress httpsAddress \u003d infoServer.getConnectorAddress(connIdx);\n      conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_KEY,\n          NetUtils.getHostPortString(httpsAddress));\n    }\n\n    LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \"\n        + \"(\" + checkpointConf.getPeriod() / 60 + \" min)\");\n    LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
      "extendedDetails": {}
    },
    "94a1632fcb677fda6f4d812614026417f1d0a360": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3405. Checkpointing should use HTTP POST or PUT instead of GET-GET to send merged fsimages. Contributed by Vinayakumar B.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1575611 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/03/14 1:25 PM",
      "commitName": "94a1632fcb677fda6f4d812614026417f1d0a360",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "08/03/14 1:15 PM",
      "commitNameOld": "dbd22b23c2d68b97b4da47215897906f06f978e3",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,83 +1,81 @@\n   private void initialize(final Configuration conf,\n       CommandLineOpts commandLineOpts) throws IOException {\n     final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n     final String infoBindAddress \u003d infoSocAddr.getHostName();\n     UserGroupInformation.setConfiguration(conf);\n     if (UserGroupInformation.isSecurityEnabled()) {\n       SecurityUtil.login(conf,\n           DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n           DFSConfigKeys.DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n     }\n     // initiate Java VM metrics\n     DefaultMetricsSystem.initialize(\"SecondaryNameNode\");\n     JvmMetrics.create(\"SecondaryNameNode\",\n         conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n         DefaultMetricsSystem.instance());\n \n     // Create connection to the namenode.\n     shouldRun \u003d true;\n     nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n \n     this.conf \u003d conf;\n     this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n         NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n         true).getProxy();\n \n     // initialize checkpoint directories\n     fsName \u003d getInfoServer();\n     checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                   \"/tmp/hadoop/dfs/namesecondary\");\n     checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                   \"/tmp/hadoop/dfs/namesecondary\");    \n     checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n     checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n     checkpointImage.deleteTempEdits();\n     \n     namesystem \u003d new FSNamesystem(conf, checkpointImage, true);\n \n     // Initialize other scheduling parameters from the configuration\n     checkpointConf \u003d new CheckpointConf(conf);\n \n     final InetSocketAddress httpAddr \u003d infoSocAddr;\n \n     final String httpsAddrString \u003d conf.get(\n         DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_KEY,\n         DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_DEFAULT);\n     InetSocketAddress httpsAddr \u003d NetUtils.createSocketAddr(httpsAddrString);\n \n     HttpServer2.Builder builder \u003d DFSUtil.httpServerTemplateForNNAndJN(conf,\n         httpAddr, httpsAddr, \"secondary\",\n         DFSConfigKeys.DFS_SECONDARY_NAMENODE_INTERNAL_SPNEGO_USER_NAME_KEY,\n         DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY);\n \n     infoServer \u003d builder.build();\n \n     infoServer.setAttribute(\"secondary.name.node\", this);\n     infoServer.setAttribute(\"name.system.image\", checkpointImage);\n     infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n-    infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n-                                  GetImageServlet.class, true);\n+    infoServer.addInternalServlet(\"imagetransfer\", ImageServlet.PATH_SPEC,\n+        ImageServlet.class, true);\n     infoServer.start();\n \n     LOG.info(\"Web server init done\");\n-    imageListenURL \u003d new URL(DFSUtil.getHttpClientScheme(conf) + \"://\"\n-        + NetUtils.getHostPortString(infoServer.getConnectorAddress(0)));\n \n     HttpConfig.Policy policy \u003d DFSUtil.getHttpPolicy(conf);\n     int connIdx \u003d 0;\n     if (policy.isHttpEnabled()) {\n       InetSocketAddress httpAddress \u003d infoServer.getConnectorAddress(connIdx++);\n       conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY,\n           NetUtils.getHostPortString(httpAddress));\n     }\n \n     if (policy.isHttpsEnabled()) {\n       InetSocketAddress httpsAddress \u003d infoServer.getConnectorAddress(connIdx);\n       conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_KEY,\n           NetUtils.getHostPortString(httpsAddress));\n     }\n \n     LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \"\n         + \"(\" + checkpointConf.getPeriod() / 60 + \" min)\");\n     LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void initialize(final Configuration conf,\n      CommandLineOpts commandLineOpts) throws IOException {\n    final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n    final String infoBindAddress \u003d infoSocAddr.getHostName();\n    UserGroupInformation.setConfiguration(conf);\n    if (UserGroupInformation.isSecurityEnabled()) {\n      SecurityUtil.login(conf,\n          DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n          DFSConfigKeys.DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n    }\n    // initiate Java VM metrics\n    DefaultMetricsSystem.initialize(\"SecondaryNameNode\");\n    JvmMetrics.create(\"SecondaryNameNode\",\n        conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n        DefaultMetricsSystem.instance());\n\n    // Create connection to the namenode.\n    shouldRun \u003d true;\n    nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n\n    this.conf \u003d conf;\n    this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n        NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n        true).getProxy();\n\n    // initialize checkpoint directories\n    fsName \u003d getInfoServer();\n    checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                  \"/tmp/hadoop/dfs/namesecondary\");\n    checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                  \"/tmp/hadoop/dfs/namesecondary\");    \n    checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n    checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n    checkpointImage.deleteTempEdits();\n    \n    namesystem \u003d new FSNamesystem(conf, checkpointImage, true);\n\n    // Initialize other scheduling parameters from the configuration\n    checkpointConf \u003d new CheckpointConf(conf);\n\n    final InetSocketAddress httpAddr \u003d infoSocAddr;\n\n    final String httpsAddrString \u003d conf.get(\n        DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_KEY,\n        DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_DEFAULT);\n    InetSocketAddress httpsAddr \u003d NetUtils.createSocketAddr(httpsAddrString);\n\n    HttpServer2.Builder builder \u003d DFSUtil.httpServerTemplateForNNAndJN(conf,\n        httpAddr, httpsAddr, \"secondary\",\n        DFSConfigKeys.DFS_SECONDARY_NAMENODE_INTERNAL_SPNEGO_USER_NAME_KEY,\n        DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY);\n\n    infoServer \u003d builder.build();\n\n    infoServer.setAttribute(\"secondary.name.node\", this);\n    infoServer.setAttribute(\"name.system.image\", checkpointImage);\n    infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n    infoServer.addInternalServlet(\"imagetransfer\", ImageServlet.PATH_SPEC,\n        ImageServlet.class, true);\n    infoServer.start();\n\n    LOG.info(\"Web server init done\");\n\n    HttpConfig.Policy policy \u003d DFSUtil.getHttpPolicy(conf);\n    int connIdx \u003d 0;\n    if (policy.isHttpEnabled()) {\n      InetSocketAddress httpAddress \u003d infoServer.getConnectorAddress(connIdx++);\n      conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY,\n          NetUtils.getHostPortString(httpAddress));\n    }\n\n    if (policy.isHttpsEnabled()) {\n      InetSocketAddress httpsAddress \u003d infoServer.getConnectorAddress(connIdx);\n      conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_KEY,\n          NetUtils.getHostPortString(httpsAddress));\n    }\n\n    LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \"\n        + \"(\" + checkpointConf.getPeriod() / 60 + \" min)\");\n    LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
      "extendedDetails": {}
    },
    "dbd22b23c2d68b97b4da47215897906f06f978e3": {
      "type": "Ybodychange",
      "commitMessage": "Revert HDFS-3405 for recommit with correct renamed files\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1575610 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/03/14 1:15 PM",
      "commitName": "dbd22b23c2d68b97b4da47215897906f06f978e3",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "07/03/14 4:39 PM",
      "commitNameOld": "0f595915a388305edbb3ce928415571811d304e8",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 0.86,
      "commitsBetweenForRepo": 8,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,81 +1,83 @@\n   private void initialize(final Configuration conf,\n       CommandLineOpts commandLineOpts) throws IOException {\n     final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n     final String infoBindAddress \u003d infoSocAddr.getHostName();\n     UserGroupInformation.setConfiguration(conf);\n     if (UserGroupInformation.isSecurityEnabled()) {\n       SecurityUtil.login(conf,\n           DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n           DFSConfigKeys.DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n     }\n     // initiate Java VM metrics\n     DefaultMetricsSystem.initialize(\"SecondaryNameNode\");\n     JvmMetrics.create(\"SecondaryNameNode\",\n         conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n         DefaultMetricsSystem.instance());\n \n     // Create connection to the namenode.\n     shouldRun \u003d true;\n     nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n \n     this.conf \u003d conf;\n     this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n         NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n         true).getProxy();\n \n     // initialize checkpoint directories\n     fsName \u003d getInfoServer();\n     checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                   \"/tmp/hadoop/dfs/namesecondary\");\n     checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                   \"/tmp/hadoop/dfs/namesecondary\");    \n     checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n     checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n     checkpointImage.deleteTempEdits();\n     \n     namesystem \u003d new FSNamesystem(conf, checkpointImage, true);\n \n     // Initialize other scheduling parameters from the configuration\n     checkpointConf \u003d new CheckpointConf(conf);\n \n     final InetSocketAddress httpAddr \u003d infoSocAddr;\n \n     final String httpsAddrString \u003d conf.get(\n         DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_KEY,\n         DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_DEFAULT);\n     InetSocketAddress httpsAddr \u003d NetUtils.createSocketAddr(httpsAddrString);\n \n     HttpServer2.Builder builder \u003d DFSUtil.httpServerTemplateForNNAndJN(conf,\n         httpAddr, httpsAddr, \"secondary\",\n         DFSConfigKeys.DFS_SECONDARY_NAMENODE_INTERNAL_SPNEGO_USER_NAME_KEY,\n         DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY);\n \n     infoServer \u003d builder.build();\n \n     infoServer.setAttribute(\"secondary.name.node\", this);\n     infoServer.setAttribute(\"name.system.image\", checkpointImage);\n     infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n-    infoServer.addInternalServlet(\"imagetransfer\", ImageServlet.PATH_SPEC,\n-        ImageServlet.class, true);\n+    infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n+                                  GetImageServlet.class, true);\n     infoServer.start();\n \n     LOG.info(\"Web server init done\");\n+    imageListenURL \u003d new URL(DFSUtil.getHttpClientScheme(conf) + \"://\"\n+        + NetUtils.getHostPortString(infoServer.getConnectorAddress(0)));\n \n     HttpConfig.Policy policy \u003d DFSUtil.getHttpPolicy(conf);\n     int connIdx \u003d 0;\n     if (policy.isHttpEnabled()) {\n       InetSocketAddress httpAddress \u003d infoServer.getConnectorAddress(connIdx++);\n       conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY,\n           NetUtils.getHostPortString(httpAddress));\n     }\n \n     if (policy.isHttpsEnabled()) {\n       InetSocketAddress httpsAddress \u003d infoServer.getConnectorAddress(connIdx);\n       conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_KEY,\n           NetUtils.getHostPortString(httpsAddress));\n     }\n \n     LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \"\n         + \"(\" + checkpointConf.getPeriod() / 60 + \" min)\");\n     LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void initialize(final Configuration conf,\n      CommandLineOpts commandLineOpts) throws IOException {\n    final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n    final String infoBindAddress \u003d infoSocAddr.getHostName();\n    UserGroupInformation.setConfiguration(conf);\n    if (UserGroupInformation.isSecurityEnabled()) {\n      SecurityUtil.login(conf,\n          DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n          DFSConfigKeys.DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n    }\n    // initiate Java VM metrics\n    DefaultMetricsSystem.initialize(\"SecondaryNameNode\");\n    JvmMetrics.create(\"SecondaryNameNode\",\n        conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n        DefaultMetricsSystem.instance());\n\n    // Create connection to the namenode.\n    shouldRun \u003d true;\n    nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n\n    this.conf \u003d conf;\n    this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n        NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n        true).getProxy();\n\n    // initialize checkpoint directories\n    fsName \u003d getInfoServer();\n    checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                  \"/tmp/hadoop/dfs/namesecondary\");\n    checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                  \"/tmp/hadoop/dfs/namesecondary\");    \n    checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n    checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n    checkpointImage.deleteTempEdits();\n    \n    namesystem \u003d new FSNamesystem(conf, checkpointImage, true);\n\n    // Initialize other scheduling parameters from the configuration\n    checkpointConf \u003d new CheckpointConf(conf);\n\n    final InetSocketAddress httpAddr \u003d infoSocAddr;\n\n    final String httpsAddrString \u003d conf.get(\n        DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_KEY,\n        DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_DEFAULT);\n    InetSocketAddress httpsAddr \u003d NetUtils.createSocketAddr(httpsAddrString);\n\n    HttpServer2.Builder builder \u003d DFSUtil.httpServerTemplateForNNAndJN(conf,\n        httpAddr, httpsAddr, \"secondary\",\n        DFSConfigKeys.DFS_SECONDARY_NAMENODE_INTERNAL_SPNEGO_USER_NAME_KEY,\n        DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY);\n\n    infoServer \u003d builder.build();\n\n    infoServer.setAttribute(\"secondary.name.node\", this);\n    infoServer.setAttribute(\"name.system.image\", checkpointImage);\n    infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n    infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n                                  GetImageServlet.class, true);\n    infoServer.start();\n\n    LOG.info(\"Web server init done\");\n    imageListenURL \u003d new URL(DFSUtil.getHttpClientScheme(conf) + \"://\"\n        + NetUtils.getHostPortString(infoServer.getConnectorAddress(0)));\n\n    HttpConfig.Policy policy \u003d DFSUtil.getHttpPolicy(conf);\n    int connIdx \u003d 0;\n    if (policy.isHttpEnabled()) {\n      InetSocketAddress httpAddress \u003d infoServer.getConnectorAddress(connIdx++);\n      conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY,\n          NetUtils.getHostPortString(httpAddress));\n    }\n\n    if (policy.isHttpsEnabled()) {\n      InetSocketAddress httpsAddress \u003d infoServer.getConnectorAddress(connIdx);\n      conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_KEY,\n          NetUtils.getHostPortString(httpsAddress));\n    }\n\n    LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \"\n        + \"(\" + checkpointConf.getPeriod() / 60 + \" min)\");\n    LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
      "extendedDetails": {}
    },
    "0f595915a388305edbb3ce928415571811d304e8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3405. Checkpointing should use HTTP POST or PUT instead of GET-GET to send merged fsimages. Contributed by Vinayakumar B.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1575457 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/03/14 4:39 PM",
      "commitName": "0f595915a388305edbb3ce928415571811d304e8",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "27/02/14 5:21 PM",
      "commitNameOld": "e9a17c8ce0656a4e5d47401ca22a575c5f5f66db",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 7.97,
      "commitsBetweenForRepo": 73,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,83 +1,81 @@\n   private void initialize(final Configuration conf,\n       CommandLineOpts commandLineOpts) throws IOException {\n     final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n     final String infoBindAddress \u003d infoSocAddr.getHostName();\n     UserGroupInformation.setConfiguration(conf);\n     if (UserGroupInformation.isSecurityEnabled()) {\n       SecurityUtil.login(conf,\n           DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n           DFSConfigKeys.DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n     }\n     // initiate Java VM metrics\n     DefaultMetricsSystem.initialize(\"SecondaryNameNode\");\n     JvmMetrics.create(\"SecondaryNameNode\",\n         conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n         DefaultMetricsSystem.instance());\n \n     // Create connection to the namenode.\n     shouldRun \u003d true;\n     nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n \n     this.conf \u003d conf;\n     this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n         NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n         true).getProxy();\n \n     // initialize checkpoint directories\n     fsName \u003d getInfoServer();\n     checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                   \"/tmp/hadoop/dfs/namesecondary\");\n     checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                   \"/tmp/hadoop/dfs/namesecondary\");    \n     checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n     checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n     checkpointImage.deleteTempEdits();\n     \n     namesystem \u003d new FSNamesystem(conf, checkpointImage, true);\n \n     // Initialize other scheduling parameters from the configuration\n     checkpointConf \u003d new CheckpointConf(conf);\n \n     final InetSocketAddress httpAddr \u003d infoSocAddr;\n \n     final String httpsAddrString \u003d conf.get(\n         DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_KEY,\n         DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_DEFAULT);\n     InetSocketAddress httpsAddr \u003d NetUtils.createSocketAddr(httpsAddrString);\n \n     HttpServer2.Builder builder \u003d DFSUtil.httpServerTemplateForNNAndJN(conf,\n         httpAddr, httpsAddr, \"secondary\",\n         DFSConfigKeys.DFS_SECONDARY_NAMENODE_INTERNAL_SPNEGO_USER_NAME_KEY,\n         DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY);\n \n     infoServer \u003d builder.build();\n \n     infoServer.setAttribute(\"secondary.name.node\", this);\n     infoServer.setAttribute(\"name.system.image\", checkpointImage);\n     infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n-    infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n-                                  GetImageServlet.class, true);\n+    infoServer.addInternalServlet(\"imagetransfer\", ImageServlet.PATH_SPEC,\n+        ImageServlet.class, true);\n     infoServer.start();\n \n     LOG.info(\"Web server init done\");\n-    imageListenURL \u003d new URL(DFSUtil.getHttpClientScheme(conf) + \"://\"\n-        + NetUtils.getHostPortString(infoServer.getConnectorAddress(0)));\n \n     HttpConfig.Policy policy \u003d DFSUtil.getHttpPolicy(conf);\n     int connIdx \u003d 0;\n     if (policy.isHttpEnabled()) {\n       InetSocketAddress httpAddress \u003d infoServer.getConnectorAddress(connIdx++);\n       conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY,\n           NetUtils.getHostPortString(httpAddress));\n     }\n \n     if (policy.isHttpsEnabled()) {\n       InetSocketAddress httpsAddress \u003d infoServer.getConnectorAddress(connIdx);\n       conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_KEY,\n           NetUtils.getHostPortString(httpsAddress));\n     }\n \n     LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \"\n         + \"(\" + checkpointConf.getPeriod() / 60 + \" min)\");\n     LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void initialize(final Configuration conf,\n      CommandLineOpts commandLineOpts) throws IOException {\n    final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n    final String infoBindAddress \u003d infoSocAddr.getHostName();\n    UserGroupInformation.setConfiguration(conf);\n    if (UserGroupInformation.isSecurityEnabled()) {\n      SecurityUtil.login(conf,\n          DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n          DFSConfigKeys.DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n    }\n    // initiate Java VM metrics\n    DefaultMetricsSystem.initialize(\"SecondaryNameNode\");\n    JvmMetrics.create(\"SecondaryNameNode\",\n        conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n        DefaultMetricsSystem.instance());\n\n    // Create connection to the namenode.\n    shouldRun \u003d true;\n    nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n\n    this.conf \u003d conf;\n    this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n        NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n        true).getProxy();\n\n    // initialize checkpoint directories\n    fsName \u003d getInfoServer();\n    checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                  \"/tmp/hadoop/dfs/namesecondary\");\n    checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                  \"/tmp/hadoop/dfs/namesecondary\");    \n    checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n    checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n    checkpointImage.deleteTempEdits();\n    \n    namesystem \u003d new FSNamesystem(conf, checkpointImage, true);\n\n    // Initialize other scheduling parameters from the configuration\n    checkpointConf \u003d new CheckpointConf(conf);\n\n    final InetSocketAddress httpAddr \u003d infoSocAddr;\n\n    final String httpsAddrString \u003d conf.get(\n        DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_KEY,\n        DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_DEFAULT);\n    InetSocketAddress httpsAddr \u003d NetUtils.createSocketAddr(httpsAddrString);\n\n    HttpServer2.Builder builder \u003d DFSUtil.httpServerTemplateForNNAndJN(conf,\n        httpAddr, httpsAddr, \"secondary\",\n        DFSConfigKeys.DFS_SECONDARY_NAMENODE_INTERNAL_SPNEGO_USER_NAME_KEY,\n        DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY);\n\n    infoServer \u003d builder.build();\n\n    infoServer.setAttribute(\"secondary.name.node\", this);\n    infoServer.setAttribute(\"name.system.image\", checkpointImage);\n    infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n    infoServer.addInternalServlet(\"imagetransfer\", ImageServlet.PATH_SPEC,\n        ImageServlet.class, true);\n    infoServer.start();\n\n    LOG.info(\"Web server init done\");\n\n    HttpConfig.Policy policy \u003d DFSUtil.getHttpPolicy(conf);\n    int connIdx \u003d 0;\n    if (policy.isHttpEnabled()) {\n      InetSocketAddress httpAddress \u003d infoServer.getConnectorAddress(connIdx++);\n      conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY,\n          NetUtils.getHostPortString(httpAddress));\n    }\n\n    if (policy.isHttpsEnabled()) {\n      InetSocketAddress httpsAddress \u003d infoServer.getConnectorAddress(connIdx);\n      conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_KEY,\n          NetUtils.getHostPortString(httpsAddress));\n    }\n\n    LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \"\n        + \"(\" + checkpointConf.getPeriod() / 60 + \" min)\");\n    LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
      "extendedDetails": {}
    },
    "33a47743a5f4263bc21b345587370c5ecf43f5b4": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-10255. Rename HttpServer to HttpServer2 to retain older HttpServer in branch-2 for compatibility. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1561959 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/01/14 11:32 PM",
      "commitName": "33a47743a5f4263bc21b345587370c5ecf43f5b4",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "27/01/14 9:09 PM",
      "commitNameOld": "b8776ee65b5b2d57b1904caf0c79840123eba48b",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 0.1,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,83 +1,83 @@\n   private void initialize(final Configuration conf,\n       CommandLineOpts commandLineOpts) throws IOException {\n     final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n     final String infoBindAddress \u003d infoSocAddr.getHostName();\n     UserGroupInformation.setConfiguration(conf);\n     if (UserGroupInformation.isSecurityEnabled()) {\n       SecurityUtil.login(conf,\n           DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n           DFSConfigKeys.DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n     }\n     // initiate Java VM metrics\n     DefaultMetricsSystem.initialize(\"SecondaryNameNode\");\n     JvmMetrics.create(\"SecondaryNameNode\",\n         conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n         DefaultMetricsSystem.instance());\n \n     // Create connection to the namenode.\n     shouldRun \u003d true;\n     nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n \n     this.conf \u003d conf;\n     this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n         NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n         true).getProxy();\n \n     // initialize checkpoint directories\n     fsName \u003d getInfoServer();\n     checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                   \"/tmp/hadoop/dfs/namesecondary\");\n     checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                   \"/tmp/hadoop/dfs/namesecondary\");    \n     checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n     checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n     checkpointImage.deleteTempEdits();\n     \n     namesystem \u003d new FSNamesystem(conf, checkpointImage, true);\n \n     // Initialize other scheduling parameters from the configuration\n     checkpointConf \u003d new CheckpointConf(conf);\n \n     final InetSocketAddress httpAddr \u003d infoSocAddr;\n \n     final String httpsAddrString \u003d conf.get(\n         DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_KEY,\n         DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_DEFAULT);\n     InetSocketAddress httpsAddr \u003d NetUtils.createSocketAddr(httpsAddrString);\n \n-    HttpServer.Builder builder \u003d DFSUtil.httpServerTemplateForNNAndJN(conf,\n+    HttpServer2.Builder builder \u003d DFSUtil.httpServerTemplateForNNAndJN(conf,\n         httpAddr, httpsAddr, \"secondary\",\n         DFSConfigKeys.DFS_SECONDARY_NAMENODE_INTERNAL_SPNEGO_USER_NAME_KEY,\n         DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY);\n \n     infoServer \u003d builder.build();\n \n     infoServer.setAttribute(\"secondary.name.node\", this);\n     infoServer.setAttribute(\"name.system.image\", checkpointImage);\n     infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n     infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n                                   GetImageServlet.class, true);\n     infoServer.start();\n \n     LOG.info(\"Web server init done\");\n     imageListenURL \u003d new URL(DFSUtil.getHttpClientScheme(conf) + \"://\"\n         + NetUtils.getHostPortString(infoServer.getConnectorAddress(0)));\n \n     HttpConfig.Policy policy \u003d DFSUtil.getHttpPolicy(conf);\n     int connIdx \u003d 0;\n     if (policy.isHttpEnabled()) {\n       InetSocketAddress httpAddress \u003d infoServer.getConnectorAddress(connIdx++);\n       conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY,\n           NetUtils.getHostPortString(httpAddress));\n     }\n \n     if (policy.isHttpsEnabled()) {\n       InetSocketAddress httpsAddress \u003d infoServer.getConnectorAddress(connIdx);\n       conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_KEY,\n           NetUtils.getHostPortString(httpsAddress));\n     }\n \n     LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \"\n         + \"(\" + checkpointConf.getPeriod() / 60 + \" min)\");\n     LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void initialize(final Configuration conf,\n      CommandLineOpts commandLineOpts) throws IOException {\n    final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n    final String infoBindAddress \u003d infoSocAddr.getHostName();\n    UserGroupInformation.setConfiguration(conf);\n    if (UserGroupInformation.isSecurityEnabled()) {\n      SecurityUtil.login(conf,\n          DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n          DFSConfigKeys.DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n    }\n    // initiate Java VM metrics\n    DefaultMetricsSystem.initialize(\"SecondaryNameNode\");\n    JvmMetrics.create(\"SecondaryNameNode\",\n        conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n        DefaultMetricsSystem.instance());\n\n    // Create connection to the namenode.\n    shouldRun \u003d true;\n    nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n\n    this.conf \u003d conf;\n    this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n        NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n        true).getProxy();\n\n    // initialize checkpoint directories\n    fsName \u003d getInfoServer();\n    checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                  \"/tmp/hadoop/dfs/namesecondary\");\n    checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                  \"/tmp/hadoop/dfs/namesecondary\");    \n    checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n    checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n    checkpointImage.deleteTempEdits();\n    \n    namesystem \u003d new FSNamesystem(conf, checkpointImage, true);\n\n    // Initialize other scheduling parameters from the configuration\n    checkpointConf \u003d new CheckpointConf(conf);\n\n    final InetSocketAddress httpAddr \u003d infoSocAddr;\n\n    final String httpsAddrString \u003d conf.get(\n        DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_KEY,\n        DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_DEFAULT);\n    InetSocketAddress httpsAddr \u003d NetUtils.createSocketAddr(httpsAddrString);\n\n    HttpServer2.Builder builder \u003d DFSUtil.httpServerTemplateForNNAndJN(conf,\n        httpAddr, httpsAddr, \"secondary\",\n        DFSConfigKeys.DFS_SECONDARY_NAMENODE_INTERNAL_SPNEGO_USER_NAME_KEY,\n        DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY);\n\n    infoServer \u003d builder.build();\n\n    infoServer.setAttribute(\"secondary.name.node\", this);\n    infoServer.setAttribute(\"name.system.image\", checkpointImage);\n    infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n    infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n                                  GetImageServlet.class, true);\n    infoServer.start();\n\n    LOG.info(\"Web server init done\");\n    imageListenURL \u003d new URL(DFSUtil.getHttpClientScheme(conf) + \"://\"\n        + NetUtils.getHostPortString(infoServer.getConnectorAddress(0)));\n\n    HttpConfig.Policy policy \u003d DFSUtil.getHttpPolicy(conf);\n    int connIdx \u003d 0;\n    if (policy.isHttpEnabled()) {\n      InetSocketAddress httpAddress \u003d infoServer.getConnectorAddress(connIdx++);\n      conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY,\n          NetUtils.getHostPortString(httpAddress));\n    }\n\n    if (policy.isHttpsEnabled()) {\n      InetSocketAddress httpsAddress \u003d infoServer.getConnectorAddress(connIdx);\n      conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_KEY,\n          NetUtils.getHostPortString(httpsAddress));\n    }\n\n    LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \"\n        + \"(\" + checkpointConf.getPeriod() / 60 + \" min)\");\n    LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
      "extendedDetails": {}
    },
    "87a6db45b70a1a07165e0773c4452d1327258bfa": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5629. Support HTTPS in JournalNode and SecondaryNameNode. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1549692 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/12/13 1:58 PM",
      "commitName": "87a6db45b70a1a07165e0773c4452d1327258bfa",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "06/12/13 10:01 AM",
      "commitNameOld": "045dc880e13271737b3cf316296e92fb95806663",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 3.16,
      "commitsBetweenForRepo": 9,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,70 +1,83 @@\n   private void initialize(final Configuration conf,\n       CommandLineOpts commandLineOpts) throws IOException {\n     final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n-    infoBindAddress \u003d infoSocAddr.getHostName();\n+    final String infoBindAddress \u003d infoSocAddr.getHostName();\n     UserGroupInformation.setConfiguration(conf);\n     if (UserGroupInformation.isSecurityEnabled()) {\n-      SecurityUtil.login(conf, DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n-          DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n+      SecurityUtil.login(conf,\n+          DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n+          DFSConfigKeys.DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n     }\n     // initiate Java VM metrics\n     DefaultMetricsSystem.initialize(\"SecondaryNameNode\");\n     JvmMetrics.create(\"SecondaryNameNode\",\n-        conf.get(DFS_METRICS_SESSION_ID_KEY), DefaultMetricsSystem.instance());\n-    \n+        conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n+        DefaultMetricsSystem.instance());\n+\n     // Create connection to the namenode.\n     shouldRun \u003d true;\n     nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n \n     this.conf \u003d conf;\n     this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n         NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n         true).getProxy();\n \n     // initialize checkpoint directories\n     fsName \u003d getInfoServer();\n     checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                   \"/tmp/hadoop/dfs/namesecondary\");\n     checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                   \"/tmp/hadoop/dfs/namesecondary\");    \n     checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n     checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n     checkpointImage.deleteTempEdits();\n     \n     namesystem \u003d new FSNamesystem(conf, checkpointImage, true);\n \n     // Initialize other scheduling parameters from the configuration\n     checkpointConf \u003d new CheckpointConf(conf);\n \n-    // initialize the webserver for uploading files.\n-    int tmpInfoPort \u003d infoSocAddr.getPort();\n-    URI httpEndpoint \u003d URI.create(\"http://\" + NetUtils.getHostPortString(infoSocAddr));\n+    final InetSocketAddress httpAddr \u003d infoSocAddr;\n \n-    infoServer \u003d new HttpServer.Builder().setName(\"secondary\")\n-        .addEndpoint(httpEndpoint)\n-        .setFindPort(tmpInfoPort \u003d\u003d 0).setConf(conf).setACL(\n-            new AccessControlList(conf.get(DFS_ADMIN, \" \")))\n-        .setSecurityEnabled(UserGroupInformation.isSecurityEnabled())\n-        .setUsernameConfKey(\n-            DFSConfigKeys.DFS_SECONDARY_NAMENODE_INTERNAL_SPNEGO_USER_NAME_KEY)\n-        .setKeytabConfKey(DFSUtil.getSpnegoKeytabKey(conf,\n-            DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY)).build();\n+    final String httpsAddrString \u003d conf.get(\n+        DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_KEY,\n+        DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_DEFAULT);\n+    InetSocketAddress httpsAddr \u003d NetUtils.createSocketAddr(httpsAddrString);\n+\n+    HttpServer.Builder builder \u003d DFSUtil.httpServerTemplateForNNAndJN(conf,\n+        httpAddr, httpsAddr, \"secondary\",\n+        DFSConfigKeys.DFS_SECONDARY_NAMENODE_INTERNAL_SPNEGO_USER_NAME_KEY,\n+        DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY);\n+\n+    infoServer \u003d builder.build();\n \n     infoServer.setAttribute(\"secondary.name.node\", this);\n     infoServer.setAttribute(\"name.system.image\", checkpointImage);\n     infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n     infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n                                   GetImageServlet.class, true);\n     infoServer.start();\n \n     LOG.info(\"Web server init done\");\n+    imageListenURL \u003d new URL(DFSUtil.getHttpClientScheme(conf) + \"://\"\n+        + NetUtils.getHostPortString(infoServer.getConnectorAddress(0)));\n \n-    // The web-server port can be ephemeral... ensure we have the correct info\n-    infoPort \u003d infoServer.getConnectorAddress(0).getPort();\n+    HttpConfig.Policy policy \u003d DFSUtil.getHttpPolicy(conf);\n+    int connIdx \u003d 0;\n+    if (policy.isHttpEnabled()) {\n+      InetSocketAddress httpAddress \u003d infoServer.getConnectorAddress(connIdx++);\n+      conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY,\n+          NetUtils.getHostPortString(httpAddress));\n+    }\n \n-    conf.set(DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, infoBindAddress + \":\" + infoPort);\n-    LOG.info(\"Secondary Web-server up at: \" + infoBindAddress + \":\" + infoPort);\n-    LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \" +\n-             \"(\" + checkpointConf.getPeriod() / 60 + \" min)\");\n+    if (policy.isHttpsEnabled()) {\n+      InetSocketAddress httpsAddress \u003d infoServer.getConnectorAddress(connIdx);\n+      conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_KEY,\n+          NetUtils.getHostPortString(httpsAddress));\n+    }\n+\n+    LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \"\n+        + \"(\" + checkpointConf.getPeriod() / 60 + \" min)\");\n     LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void initialize(final Configuration conf,\n      CommandLineOpts commandLineOpts) throws IOException {\n    final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n    final String infoBindAddress \u003d infoSocAddr.getHostName();\n    UserGroupInformation.setConfiguration(conf);\n    if (UserGroupInformation.isSecurityEnabled()) {\n      SecurityUtil.login(conf,\n          DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n          DFSConfigKeys.DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n    }\n    // initiate Java VM metrics\n    DefaultMetricsSystem.initialize(\"SecondaryNameNode\");\n    JvmMetrics.create(\"SecondaryNameNode\",\n        conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n        DefaultMetricsSystem.instance());\n\n    // Create connection to the namenode.\n    shouldRun \u003d true;\n    nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n\n    this.conf \u003d conf;\n    this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n        NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n        true).getProxy();\n\n    // initialize checkpoint directories\n    fsName \u003d getInfoServer();\n    checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                  \"/tmp/hadoop/dfs/namesecondary\");\n    checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                  \"/tmp/hadoop/dfs/namesecondary\");    \n    checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n    checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n    checkpointImage.deleteTempEdits();\n    \n    namesystem \u003d new FSNamesystem(conf, checkpointImage, true);\n\n    // Initialize other scheduling parameters from the configuration\n    checkpointConf \u003d new CheckpointConf(conf);\n\n    final InetSocketAddress httpAddr \u003d infoSocAddr;\n\n    final String httpsAddrString \u003d conf.get(\n        DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_KEY,\n        DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_DEFAULT);\n    InetSocketAddress httpsAddr \u003d NetUtils.createSocketAddr(httpsAddrString);\n\n    HttpServer.Builder builder \u003d DFSUtil.httpServerTemplateForNNAndJN(conf,\n        httpAddr, httpsAddr, \"secondary\",\n        DFSConfigKeys.DFS_SECONDARY_NAMENODE_INTERNAL_SPNEGO_USER_NAME_KEY,\n        DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY);\n\n    infoServer \u003d builder.build();\n\n    infoServer.setAttribute(\"secondary.name.node\", this);\n    infoServer.setAttribute(\"name.system.image\", checkpointImage);\n    infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n    infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n                                  GetImageServlet.class, true);\n    infoServer.start();\n\n    LOG.info(\"Web server init done\");\n    imageListenURL \u003d new URL(DFSUtil.getHttpClientScheme(conf) + \"://\"\n        + NetUtils.getHostPortString(infoServer.getConnectorAddress(0)));\n\n    HttpConfig.Policy policy \u003d DFSUtil.getHttpPolicy(conf);\n    int connIdx \u003d 0;\n    if (policy.isHttpEnabled()) {\n      InetSocketAddress httpAddress \u003d infoServer.getConnectorAddress(connIdx++);\n      conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY,\n          NetUtils.getHostPortString(httpAddress));\n    }\n\n    if (policy.isHttpsEnabled()) {\n      InetSocketAddress httpsAddress \u003d infoServer.getConnectorAddress(connIdx);\n      conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTPS_ADDRESS_KEY,\n          NetUtils.getHostPortString(httpsAddress));\n    }\n\n    LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \"\n        + \"(\" + checkpointConf.getPeriod() / 60 + \" min)\");\n    LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
      "extendedDetails": {}
    },
    "d02baff9a0d8cec92bde751777f3e575da2339c8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5536. Implement HTTP policy for Namenode and DataNode. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1547925 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/12/13 1:40 PM",
      "commitName": "d02baff9a0d8cec92bde751777f3e575da2339c8",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "27/11/13 10:20 AM",
      "commitNameOld": "2214871d916fdcae62aa51afbb5fd571f2808745",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 7.14,
      "commitsBetweenForRepo": 29,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,74 +1,70 @@\n   private void initialize(final Configuration conf,\n       CommandLineOpts commandLineOpts) throws IOException {\n     final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n     infoBindAddress \u003d infoSocAddr.getHostName();\n     UserGroupInformation.setConfiguration(conf);\n     if (UserGroupInformation.isSecurityEnabled()) {\n       SecurityUtil.login(conf, DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n           DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n     }\n     // initiate Java VM metrics\n     DefaultMetricsSystem.initialize(\"SecondaryNameNode\");\n     JvmMetrics.create(\"SecondaryNameNode\",\n         conf.get(DFS_METRICS_SESSION_ID_KEY), DefaultMetricsSystem.instance());\n     \n     // Create connection to the namenode.\n     shouldRun \u003d true;\n     nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n \n     this.conf \u003d conf;\n     this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n         NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n         true).getProxy();\n \n     // initialize checkpoint directories\n     fsName \u003d getInfoServer();\n     checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                   \"/tmp/hadoop/dfs/namesecondary\");\n     checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                   \"/tmp/hadoop/dfs/namesecondary\");    \n     checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n     checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n     checkpointImage.deleteTempEdits();\n     \n     namesystem \u003d new FSNamesystem(conf, checkpointImage, true);\n \n     // Initialize other scheduling parameters from the configuration\n     checkpointConf \u003d new CheckpointConf(conf);\n \n     // initialize the webserver for uploading files.\n     int tmpInfoPort \u003d infoSocAddr.getPort();\n-    URI httpEndpoint;\n-    try {\n-      httpEndpoint \u003d new URI(\"http://\" + NetUtils.getHostPortString(infoSocAddr));\n-    } catch (URISyntaxException e) {\n-      throw new IOException(e);\n-    }\n+    URI httpEndpoint \u003d URI.create(\"http://\" + NetUtils.getHostPortString(infoSocAddr));\n \n     infoServer \u003d new HttpServer.Builder().setName(\"secondary\")\n         .addEndpoint(httpEndpoint)\n         .setFindPort(tmpInfoPort \u003d\u003d 0).setConf(conf).setACL(\n             new AccessControlList(conf.get(DFS_ADMIN, \" \")))\n         .setSecurityEnabled(UserGroupInformation.isSecurityEnabled())\n         .setUsernameConfKey(\n             DFSConfigKeys.DFS_SECONDARY_NAMENODE_INTERNAL_SPNEGO_USER_NAME_KEY)\n         .setKeytabConfKey(DFSUtil.getSpnegoKeytabKey(conf,\n             DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY)).build();\n+\n     infoServer.setAttribute(\"secondary.name.node\", this);\n     infoServer.setAttribute(\"name.system.image\", checkpointImage);\n     infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n     infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n                                   GetImageServlet.class, true);\n     infoServer.start();\n \n     LOG.info(\"Web server init done\");\n \n     // The web-server port can be ephemeral... ensure we have the correct info\n     infoPort \u003d infoServer.getConnectorAddress(0).getPort();\n \n     conf.set(DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, infoBindAddress + \":\" + infoPort);\n     LOG.info(\"Secondary Web-server up at: \" + infoBindAddress + \":\" + infoPort);\n     LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \" +\n              \"(\" + checkpointConf.getPeriod() / 60 + \" min)\");\n     LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void initialize(final Configuration conf,\n      CommandLineOpts commandLineOpts) throws IOException {\n    final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n    infoBindAddress \u003d infoSocAddr.getHostName();\n    UserGroupInformation.setConfiguration(conf);\n    if (UserGroupInformation.isSecurityEnabled()) {\n      SecurityUtil.login(conf, DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n          DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n    }\n    // initiate Java VM metrics\n    DefaultMetricsSystem.initialize(\"SecondaryNameNode\");\n    JvmMetrics.create(\"SecondaryNameNode\",\n        conf.get(DFS_METRICS_SESSION_ID_KEY), DefaultMetricsSystem.instance());\n    \n    // Create connection to the namenode.\n    shouldRun \u003d true;\n    nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n\n    this.conf \u003d conf;\n    this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n        NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n        true).getProxy();\n\n    // initialize checkpoint directories\n    fsName \u003d getInfoServer();\n    checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                  \"/tmp/hadoop/dfs/namesecondary\");\n    checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                  \"/tmp/hadoop/dfs/namesecondary\");    \n    checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n    checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n    checkpointImage.deleteTempEdits();\n    \n    namesystem \u003d new FSNamesystem(conf, checkpointImage, true);\n\n    // Initialize other scheduling parameters from the configuration\n    checkpointConf \u003d new CheckpointConf(conf);\n\n    // initialize the webserver for uploading files.\n    int tmpInfoPort \u003d infoSocAddr.getPort();\n    URI httpEndpoint \u003d URI.create(\"http://\" + NetUtils.getHostPortString(infoSocAddr));\n\n    infoServer \u003d new HttpServer.Builder().setName(\"secondary\")\n        .addEndpoint(httpEndpoint)\n        .setFindPort(tmpInfoPort \u003d\u003d 0).setConf(conf).setACL(\n            new AccessControlList(conf.get(DFS_ADMIN, \" \")))\n        .setSecurityEnabled(UserGroupInformation.isSecurityEnabled())\n        .setUsernameConfKey(\n            DFSConfigKeys.DFS_SECONDARY_NAMENODE_INTERNAL_SPNEGO_USER_NAME_KEY)\n        .setKeytabConfKey(DFSUtil.getSpnegoKeytabKey(conf,\n            DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY)).build();\n\n    infoServer.setAttribute(\"secondary.name.node\", this);\n    infoServer.setAttribute(\"name.system.image\", checkpointImage);\n    infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n    infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n                                  GetImageServlet.class, true);\n    infoServer.start();\n\n    LOG.info(\"Web server init done\");\n\n    // The web-server port can be ephemeral... ensure we have the correct info\n    infoPort \u003d infoServer.getConnectorAddress(0).getPort();\n\n    conf.set(DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, infoBindAddress + \":\" + infoPort);\n    LOG.info(\"Secondary Web-server up at: \" + infoBindAddress + \":\" + infoPort);\n    LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \" +\n             \"(\" + checkpointConf.getPeriod() / 60 + \" min)\");\n    LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
      "extendedDetails": {}
    },
    "2214871d916fdcae62aa51afbb5fd571f2808745": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5545. Allow specifying endpoints for listeners in HttpServer. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1546151 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/11/13 10:20 AM",
      "commitName": "2214871d916fdcae62aa51afbb5fd571f2808745",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "30/10/13 10:27 AM",
      "commitNameOld": "75a162ff92d365d88ed253335b52aaa3709f6365",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 28.04,
      "commitsBetweenForRepo": 158,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,67 +1,74 @@\n   private void initialize(final Configuration conf,\n       CommandLineOpts commandLineOpts) throws IOException {\n     final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n     infoBindAddress \u003d infoSocAddr.getHostName();\n     UserGroupInformation.setConfiguration(conf);\n     if (UserGroupInformation.isSecurityEnabled()) {\n       SecurityUtil.login(conf, DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n           DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n     }\n     // initiate Java VM metrics\n     DefaultMetricsSystem.initialize(\"SecondaryNameNode\");\n     JvmMetrics.create(\"SecondaryNameNode\",\n         conf.get(DFS_METRICS_SESSION_ID_KEY), DefaultMetricsSystem.instance());\n     \n     // Create connection to the namenode.\n     shouldRun \u003d true;\n     nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n \n     this.conf \u003d conf;\n     this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n         NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n         true).getProxy();\n \n     // initialize checkpoint directories\n     fsName \u003d getInfoServer();\n     checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                   \"/tmp/hadoop/dfs/namesecondary\");\n     checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                   \"/tmp/hadoop/dfs/namesecondary\");    \n     checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n     checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n     checkpointImage.deleteTempEdits();\n     \n     namesystem \u003d new FSNamesystem(conf, checkpointImage, true);\n \n     // Initialize other scheduling parameters from the configuration\n     checkpointConf \u003d new CheckpointConf(conf);\n \n     // initialize the webserver for uploading files.\n     int tmpInfoPort \u003d infoSocAddr.getPort();\n+    URI httpEndpoint;\n+    try {\n+      httpEndpoint \u003d new URI(\"http://\" + NetUtils.getHostPortString(infoSocAddr));\n+    } catch (URISyntaxException e) {\n+      throw new IOException(e);\n+    }\n+\n     infoServer \u003d new HttpServer.Builder().setName(\"secondary\")\n-        .setBindAddress(infoBindAddress).setPort(tmpInfoPort)\n+        .addEndpoint(httpEndpoint)\n         .setFindPort(tmpInfoPort \u003d\u003d 0).setConf(conf).setACL(\n             new AccessControlList(conf.get(DFS_ADMIN, \" \")))\n         .setSecurityEnabled(UserGroupInformation.isSecurityEnabled())\n         .setUsernameConfKey(\n             DFSConfigKeys.DFS_SECONDARY_NAMENODE_INTERNAL_SPNEGO_USER_NAME_KEY)\n         .setKeytabConfKey(DFSUtil.getSpnegoKeytabKey(conf,\n             DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY)).build();\n     infoServer.setAttribute(\"secondary.name.node\", this);\n     infoServer.setAttribute(\"name.system.image\", checkpointImage);\n     infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n     infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n                                   GetImageServlet.class, true);\n     infoServer.start();\n \n     LOG.info(\"Web server init done\");\n \n     // The web-server port can be ephemeral... ensure we have the correct info\n-    infoPort \u003d infoServer.getPort();\n+    infoPort \u003d infoServer.getConnectorAddress(0).getPort();\n \n     conf.set(DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, infoBindAddress + \":\" + infoPort);\n     LOG.info(\"Secondary Web-server up at: \" + infoBindAddress + \":\" + infoPort);\n     LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \" +\n              \"(\" + checkpointConf.getPeriod() / 60 + \" min)\");\n     LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void initialize(final Configuration conf,\n      CommandLineOpts commandLineOpts) throws IOException {\n    final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n    infoBindAddress \u003d infoSocAddr.getHostName();\n    UserGroupInformation.setConfiguration(conf);\n    if (UserGroupInformation.isSecurityEnabled()) {\n      SecurityUtil.login(conf, DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n          DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n    }\n    // initiate Java VM metrics\n    DefaultMetricsSystem.initialize(\"SecondaryNameNode\");\n    JvmMetrics.create(\"SecondaryNameNode\",\n        conf.get(DFS_METRICS_SESSION_ID_KEY), DefaultMetricsSystem.instance());\n    \n    // Create connection to the namenode.\n    shouldRun \u003d true;\n    nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n\n    this.conf \u003d conf;\n    this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n        NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n        true).getProxy();\n\n    // initialize checkpoint directories\n    fsName \u003d getInfoServer();\n    checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                  \"/tmp/hadoop/dfs/namesecondary\");\n    checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                  \"/tmp/hadoop/dfs/namesecondary\");    \n    checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n    checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n    checkpointImage.deleteTempEdits();\n    \n    namesystem \u003d new FSNamesystem(conf, checkpointImage, true);\n\n    // Initialize other scheduling parameters from the configuration\n    checkpointConf \u003d new CheckpointConf(conf);\n\n    // initialize the webserver for uploading files.\n    int tmpInfoPort \u003d infoSocAddr.getPort();\n    URI httpEndpoint;\n    try {\n      httpEndpoint \u003d new URI(\"http://\" + NetUtils.getHostPortString(infoSocAddr));\n    } catch (URISyntaxException e) {\n      throw new IOException(e);\n    }\n\n    infoServer \u003d new HttpServer.Builder().setName(\"secondary\")\n        .addEndpoint(httpEndpoint)\n        .setFindPort(tmpInfoPort \u003d\u003d 0).setConf(conf).setACL(\n            new AccessControlList(conf.get(DFS_ADMIN, \" \")))\n        .setSecurityEnabled(UserGroupInformation.isSecurityEnabled())\n        .setUsernameConfKey(\n            DFSConfigKeys.DFS_SECONDARY_NAMENODE_INTERNAL_SPNEGO_USER_NAME_KEY)\n        .setKeytabConfKey(DFSUtil.getSpnegoKeytabKey(conf,\n            DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY)).build();\n    infoServer.setAttribute(\"secondary.name.node\", this);\n    infoServer.setAttribute(\"name.system.image\", checkpointImage);\n    infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n    infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n                                  GetImageServlet.class, true);\n    infoServer.start();\n\n    LOG.info(\"Web server init done\");\n\n    // The web-server port can be ephemeral... ensure we have the correct info\n    infoPort \u003d infoServer.getConnectorAddress(0).getPort();\n\n    conf.set(DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, infoBindAddress + \":\" + infoPort);\n    LOG.info(\"Secondary Web-server up at: \" + infoBindAddress + \":\" + infoPort);\n    LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \" +\n             \"(\" + checkpointConf.getPeriod() / 60 + \" min)\");\n    LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
      "extendedDetails": {}
    },
    "782191f1ba27e0ff0acf3c6cf8a88df00274d308": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-9784. Add a builder for HttpServer. (Junping Du via llu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1516128 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/08/13 3:12 AM",
      "commitName": "782191f1ba27e0ff0acf3c6cf8a88df00274d308",
      "commitAuthor": "Luke Lu",
      "commitDateOld": "30/07/13 12:51 AM",
      "commitNameOld": "8c7a7e619699386f9e6991842558d78aa0c8053d",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 22.1,
      "commitsBetweenForRepo": 136,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,71 +1,67 @@\n   private void initialize(final Configuration conf,\n       CommandLineOpts commandLineOpts) throws IOException {\n     final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n     infoBindAddress \u003d infoSocAddr.getHostName();\n     UserGroupInformation.setConfiguration(conf);\n     if (UserGroupInformation.isSecurityEnabled()) {\n       SecurityUtil.login(conf, DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n           DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n     }\n     // initiate Java VM metrics\n     DefaultMetricsSystem.initialize(\"SecondaryNameNode\");\n     JvmMetrics.create(\"SecondaryNameNode\",\n         conf.get(DFS_METRICS_SESSION_ID_KEY), DefaultMetricsSystem.instance());\n     \n     // Create connection to the namenode.\n     shouldRun \u003d true;\n     nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n \n     this.conf \u003d conf;\n     this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n         NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n         true).getProxy();\n \n     // initialize checkpoint directories\n     fsName \u003d getInfoServer();\n     checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                   \"/tmp/hadoop/dfs/namesecondary\");\n     checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                   \"/tmp/hadoop/dfs/namesecondary\");    \n     checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n     checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n     checkpointImage.deleteTempEdits();\n     \n     namesystem \u003d new FSNamesystem(conf, checkpointImage, true);\n \n     // Initialize other scheduling parameters from the configuration\n     checkpointConf \u003d new CheckpointConf(conf);\n \n     // initialize the webserver for uploading files.\n     int tmpInfoPort \u003d infoSocAddr.getPort();\n-    infoServer \u003d new HttpServer(\"secondary\", infoBindAddress, tmpInfoPort,\n-                                tmpInfoPort \u003d\u003d 0, conf,\n-                                new AccessControlList(conf.get(DFS_ADMIN, \" \"))) {\n-      {\n-        if (UserGroupInformation.isSecurityEnabled()) {\n-          initSpnego(\n-              conf,\n-              DFSConfigKeys.DFS_SECONDARY_NAMENODE_INTERNAL_SPNEGO_USER_NAME_KEY,\n-              DFSUtil.getSpnegoKeytabKey(conf,\n-                  DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY));\n-        }\n-      }\n-    };\n+    infoServer \u003d new HttpServer.Builder().setName(\"secondary\")\n+        .setBindAddress(infoBindAddress).setPort(tmpInfoPort)\n+        .setFindPort(tmpInfoPort \u003d\u003d 0).setConf(conf).setACL(\n+            new AccessControlList(conf.get(DFS_ADMIN, \" \")))\n+        .setSecurityEnabled(UserGroupInformation.isSecurityEnabled())\n+        .setUsernameConfKey(\n+            DFSConfigKeys.DFS_SECONDARY_NAMENODE_INTERNAL_SPNEGO_USER_NAME_KEY)\n+        .setKeytabConfKey(DFSUtil.getSpnegoKeytabKey(conf,\n+            DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY)).build();\n     infoServer.setAttribute(\"secondary.name.node\", this);\n     infoServer.setAttribute(\"name.system.image\", checkpointImage);\n     infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n     infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n                                   GetImageServlet.class, true);\n     infoServer.start();\n \n     LOG.info(\"Web server init done\");\n \n     // The web-server port can be ephemeral... ensure we have the correct info\n     infoPort \u003d infoServer.getPort();\n \n     conf.set(DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, infoBindAddress + \":\" + infoPort);\n     LOG.info(\"Secondary Web-server up at: \" + infoBindAddress + \":\" + infoPort);\n     LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \" +\n              \"(\" + checkpointConf.getPeriod() / 60 + \" min)\");\n     LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void initialize(final Configuration conf,\n      CommandLineOpts commandLineOpts) throws IOException {\n    final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n    infoBindAddress \u003d infoSocAddr.getHostName();\n    UserGroupInformation.setConfiguration(conf);\n    if (UserGroupInformation.isSecurityEnabled()) {\n      SecurityUtil.login(conf, DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n          DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n    }\n    // initiate Java VM metrics\n    DefaultMetricsSystem.initialize(\"SecondaryNameNode\");\n    JvmMetrics.create(\"SecondaryNameNode\",\n        conf.get(DFS_METRICS_SESSION_ID_KEY), DefaultMetricsSystem.instance());\n    \n    // Create connection to the namenode.\n    shouldRun \u003d true;\n    nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n\n    this.conf \u003d conf;\n    this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n        NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n        true).getProxy();\n\n    // initialize checkpoint directories\n    fsName \u003d getInfoServer();\n    checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                  \"/tmp/hadoop/dfs/namesecondary\");\n    checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                  \"/tmp/hadoop/dfs/namesecondary\");    \n    checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n    checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n    checkpointImage.deleteTempEdits();\n    \n    namesystem \u003d new FSNamesystem(conf, checkpointImage, true);\n\n    // Initialize other scheduling parameters from the configuration\n    checkpointConf \u003d new CheckpointConf(conf);\n\n    // initialize the webserver for uploading files.\n    int tmpInfoPort \u003d infoSocAddr.getPort();\n    infoServer \u003d new HttpServer.Builder().setName(\"secondary\")\n        .setBindAddress(infoBindAddress).setPort(tmpInfoPort)\n        .setFindPort(tmpInfoPort \u003d\u003d 0).setConf(conf).setACL(\n            new AccessControlList(conf.get(DFS_ADMIN, \" \")))\n        .setSecurityEnabled(UserGroupInformation.isSecurityEnabled())\n        .setUsernameConfKey(\n            DFSConfigKeys.DFS_SECONDARY_NAMENODE_INTERNAL_SPNEGO_USER_NAME_KEY)\n        .setKeytabConfKey(DFSUtil.getSpnegoKeytabKey(conf,\n            DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY)).build();\n    infoServer.setAttribute(\"secondary.name.node\", this);\n    infoServer.setAttribute(\"name.system.image\", checkpointImage);\n    infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n    infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n                                  GetImageServlet.class, true);\n    infoServer.start();\n\n    LOG.info(\"Web server init done\");\n\n    // The web-server port can be ephemeral... ensure we have the correct info\n    infoPort \u003d infoServer.getPort();\n\n    conf.set(DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, infoBindAddress + \":\" + infoPort);\n    LOG.info(\"Secondary Web-server up at: \" + infoBindAddress + \":\" + infoPort);\n    LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \" +\n             \"(\" + checkpointConf.getPeriod() / 60 + \" min)\");\n    LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
      "extendedDetails": {}
    },
    "8c7a7e619699386f9e6991842558d78aa0c8053d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5025. Record ClientId and CallId in EditLog to enable rebuilding retry cache in case of HA failover. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1508332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "30/07/13 12:51 AM",
      "commitName": "8c7a7e619699386f9e6991842558d78aa0c8053d",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "28/05/13 8:47 AM",
      "commitNameOld": "45b9d19f9d2b14e4d3c386af9de3df817da3c9df",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 62.67,
      "commitsBetweenForRepo": 420,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,71 +1,71 @@\n   private void initialize(final Configuration conf,\n       CommandLineOpts commandLineOpts) throws IOException {\n     final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n     infoBindAddress \u003d infoSocAddr.getHostName();\n     UserGroupInformation.setConfiguration(conf);\n     if (UserGroupInformation.isSecurityEnabled()) {\n       SecurityUtil.login(conf, DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n           DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n     }\n     // initiate Java VM metrics\n     DefaultMetricsSystem.initialize(\"SecondaryNameNode\");\n     JvmMetrics.create(\"SecondaryNameNode\",\n         conf.get(DFS_METRICS_SESSION_ID_KEY), DefaultMetricsSystem.instance());\n     \n     // Create connection to the namenode.\n     shouldRun \u003d true;\n     nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n \n     this.conf \u003d conf;\n     this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n         NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n         true).getProxy();\n \n     // initialize checkpoint directories\n     fsName \u003d getInfoServer();\n     checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                   \"/tmp/hadoop/dfs/namesecondary\");\n     checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                   \"/tmp/hadoop/dfs/namesecondary\");    \n     checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n     checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n     checkpointImage.deleteTempEdits();\n     \n-    namesystem \u003d new FSNamesystem(conf, checkpointImage);\n+    namesystem \u003d new FSNamesystem(conf, checkpointImage, true);\n \n     // Initialize other scheduling parameters from the configuration\n     checkpointConf \u003d new CheckpointConf(conf);\n \n     // initialize the webserver for uploading files.\n     int tmpInfoPort \u003d infoSocAddr.getPort();\n     infoServer \u003d new HttpServer(\"secondary\", infoBindAddress, tmpInfoPort,\n                                 tmpInfoPort \u003d\u003d 0, conf,\n                                 new AccessControlList(conf.get(DFS_ADMIN, \" \"))) {\n       {\n         if (UserGroupInformation.isSecurityEnabled()) {\n           initSpnego(\n               conf,\n               DFSConfigKeys.DFS_SECONDARY_NAMENODE_INTERNAL_SPNEGO_USER_NAME_KEY,\n               DFSUtil.getSpnegoKeytabKey(conf,\n                   DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY));\n         }\n       }\n     };\n     infoServer.setAttribute(\"secondary.name.node\", this);\n     infoServer.setAttribute(\"name.system.image\", checkpointImage);\n     infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n     infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n                                   GetImageServlet.class, true);\n     infoServer.start();\n \n     LOG.info(\"Web server init done\");\n \n     // The web-server port can be ephemeral... ensure we have the correct info\n     infoPort \u003d infoServer.getPort();\n \n     conf.set(DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, infoBindAddress + \":\" + infoPort);\n     LOG.info(\"Secondary Web-server up at: \" + infoBindAddress + \":\" + infoPort);\n     LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \" +\n              \"(\" + checkpointConf.getPeriod() / 60 + \" min)\");\n     LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void initialize(final Configuration conf,\n      CommandLineOpts commandLineOpts) throws IOException {\n    final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n    infoBindAddress \u003d infoSocAddr.getHostName();\n    UserGroupInformation.setConfiguration(conf);\n    if (UserGroupInformation.isSecurityEnabled()) {\n      SecurityUtil.login(conf, DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n          DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n    }\n    // initiate Java VM metrics\n    DefaultMetricsSystem.initialize(\"SecondaryNameNode\");\n    JvmMetrics.create(\"SecondaryNameNode\",\n        conf.get(DFS_METRICS_SESSION_ID_KEY), DefaultMetricsSystem.instance());\n    \n    // Create connection to the namenode.\n    shouldRun \u003d true;\n    nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n\n    this.conf \u003d conf;\n    this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n        NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n        true).getProxy();\n\n    // initialize checkpoint directories\n    fsName \u003d getInfoServer();\n    checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                  \"/tmp/hadoop/dfs/namesecondary\");\n    checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                  \"/tmp/hadoop/dfs/namesecondary\");    \n    checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n    checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n    checkpointImage.deleteTempEdits();\n    \n    namesystem \u003d new FSNamesystem(conf, checkpointImage, true);\n\n    // Initialize other scheduling parameters from the configuration\n    checkpointConf \u003d new CheckpointConf(conf);\n\n    // initialize the webserver for uploading files.\n    int tmpInfoPort \u003d infoSocAddr.getPort();\n    infoServer \u003d new HttpServer(\"secondary\", infoBindAddress, tmpInfoPort,\n                                tmpInfoPort \u003d\u003d 0, conf,\n                                new AccessControlList(conf.get(DFS_ADMIN, \" \"))) {\n      {\n        if (UserGroupInformation.isSecurityEnabled()) {\n          initSpnego(\n              conf,\n              DFSConfigKeys.DFS_SECONDARY_NAMENODE_INTERNAL_SPNEGO_USER_NAME_KEY,\n              DFSUtil.getSpnegoKeytabKey(conf,\n                  DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY));\n        }\n      }\n    };\n    infoServer.setAttribute(\"secondary.name.node\", this);\n    infoServer.setAttribute(\"name.system.image\", checkpointImage);\n    infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n    infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n                                  GetImageServlet.class, true);\n    infoServer.start();\n\n    LOG.info(\"Web server init done\");\n\n    // The web-server port can be ephemeral... ensure we have the correct info\n    infoPort \u003d infoServer.getPort();\n\n    conf.set(DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, infoBindAddress + \":\" + infoPort);\n    LOG.info(\"Secondary Web-server up at: \" + infoBindAddress + \":\" + infoPort);\n    LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \" +\n             \"(\" + checkpointConf.getPeriod() / 60 + \" min)\");\n    LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
      "extendedDetails": {}
    },
    "09593530fb6ccb93fd123f9497b93f7ec733210f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4300. TransferFsImage.downloadEditsToStorage should use a tmp file for destination. Contributed by Andrew Wang.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1481987 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/05/13 10:47 AM",
      "commitName": "09593530fb6ccb93fd123f9497b93f7ec733210f",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "16/04/13 8:10 AM",
      "commitNameOld": "1822529e88831545d10d307c227d8c264d796ed6",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 27.11,
      "commitsBetweenForRepo": 189,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,70 +1,71 @@\n   private void initialize(final Configuration conf,\n       CommandLineOpts commandLineOpts) throws IOException {\n     final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n     infoBindAddress \u003d infoSocAddr.getHostName();\n     UserGroupInformation.setConfiguration(conf);\n     if (UserGroupInformation.isSecurityEnabled()) {\n       SecurityUtil.login(conf, DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n           DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n     }\n     // initiate Java VM metrics\n     DefaultMetricsSystem.initialize(\"SecondaryNameNode\");\n     JvmMetrics.create(\"SecondaryNameNode\",\n         conf.get(DFS_METRICS_SESSION_ID_KEY), DefaultMetricsSystem.instance());\n     \n     // Create connection to the namenode.\n     shouldRun \u003d true;\n     nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n \n     this.conf \u003d conf;\n     this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n         NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n         true).getProxy();\n \n     // initialize checkpoint directories\n     fsName \u003d getInfoServer();\n     checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                   \"/tmp/hadoop/dfs/namesecondary\");\n     checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                   \"/tmp/hadoop/dfs/namesecondary\");    \n     checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n     checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n+    checkpointImage.deleteTempEdits();\n     \n     namesystem \u003d new FSNamesystem(conf, checkpointImage);\n \n     // Initialize other scheduling parameters from the configuration\n     checkpointConf \u003d new CheckpointConf(conf);\n \n     // initialize the webserver for uploading files.\n     int tmpInfoPort \u003d infoSocAddr.getPort();\n     infoServer \u003d new HttpServer(\"secondary\", infoBindAddress, tmpInfoPort,\n                                 tmpInfoPort \u003d\u003d 0, conf,\n                                 new AccessControlList(conf.get(DFS_ADMIN, \" \"))) {\n       {\n         if (UserGroupInformation.isSecurityEnabled()) {\n           initSpnego(\n               conf,\n               DFSConfigKeys.DFS_SECONDARY_NAMENODE_INTERNAL_SPNEGO_USER_NAME_KEY,\n               DFSUtil.getSpnegoKeytabKey(conf,\n                   DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY));\n         }\n       }\n     };\n     infoServer.setAttribute(\"secondary.name.node\", this);\n     infoServer.setAttribute(\"name.system.image\", checkpointImage);\n     infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n     infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n                                   GetImageServlet.class, true);\n     infoServer.start();\n \n     LOG.info(\"Web server init done\");\n \n     // The web-server port can be ephemeral... ensure we have the correct info\n     infoPort \u003d infoServer.getPort();\n \n     conf.set(DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, infoBindAddress + \":\" + infoPort);\n     LOG.info(\"Secondary Web-server up at: \" + infoBindAddress + \":\" + infoPort);\n     LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \" +\n              \"(\" + checkpointConf.getPeriod() / 60 + \" min)\");\n     LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void initialize(final Configuration conf,\n      CommandLineOpts commandLineOpts) throws IOException {\n    final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n    infoBindAddress \u003d infoSocAddr.getHostName();\n    UserGroupInformation.setConfiguration(conf);\n    if (UserGroupInformation.isSecurityEnabled()) {\n      SecurityUtil.login(conf, DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n          DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n    }\n    // initiate Java VM metrics\n    DefaultMetricsSystem.initialize(\"SecondaryNameNode\");\n    JvmMetrics.create(\"SecondaryNameNode\",\n        conf.get(DFS_METRICS_SESSION_ID_KEY), DefaultMetricsSystem.instance());\n    \n    // Create connection to the namenode.\n    shouldRun \u003d true;\n    nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n\n    this.conf \u003d conf;\n    this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n        NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n        true).getProxy();\n\n    // initialize checkpoint directories\n    fsName \u003d getInfoServer();\n    checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                  \"/tmp/hadoop/dfs/namesecondary\");\n    checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                  \"/tmp/hadoop/dfs/namesecondary\");    \n    checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n    checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n    checkpointImage.deleteTempEdits();\n    \n    namesystem \u003d new FSNamesystem(conf, checkpointImage);\n\n    // Initialize other scheduling parameters from the configuration\n    checkpointConf \u003d new CheckpointConf(conf);\n\n    // initialize the webserver for uploading files.\n    int tmpInfoPort \u003d infoSocAddr.getPort();\n    infoServer \u003d new HttpServer(\"secondary\", infoBindAddress, tmpInfoPort,\n                                tmpInfoPort \u003d\u003d 0, conf,\n                                new AccessControlList(conf.get(DFS_ADMIN, \" \"))) {\n      {\n        if (UserGroupInformation.isSecurityEnabled()) {\n          initSpnego(\n              conf,\n              DFSConfigKeys.DFS_SECONDARY_NAMENODE_INTERNAL_SPNEGO_USER_NAME_KEY,\n              DFSUtil.getSpnegoKeytabKey(conf,\n                  DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY));\n        }\n      }\n    };\n    infoServer.setAttribute(\"secondary.name.node\", this);\n    infoServer.setAttribute(\"name.system.image\", checkpointImage);\n    infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n    infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n                                  GetImageServlet.class, true);\n    infoServer.start();\n\n    LOG.info(\"Web server init done\");\n\n    // The web-server port can be ephemeral... ensure we have the correct info\n    infoPort \u003d infoServer.getPort();\n\n    conf.set(DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, infoBindAddress + \":\" + infoPort);\n    LOG.info(\"Secondary Web-server up at: \" + infoBindAddress + \":\" + infoPort);\n    LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \" +\n             \"(\" + checkpointConf.getPeriod() / 60 + \" min)\");\n    LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
      "extendedDetails": {}
    },
    "301079b4bfa1853f48ec0d118f2dd48f96d5d41b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4546. Use DFSUtil.getSpnegoKeytabKey() to get the spnego keytab key in secondary namenode and namenode http server. Contributed by Arpit Agarwal.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1454021 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/03/13 11:23 AM",
      "commitName": "301079b4bfa1853f48ec0d118f2dd48f96d5d41b",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "04/03/13 8:44 AM",
      "commitNameOld": "cfa86e611077e19064568a35a191250a57c75db7",
      "commitAuthorOld": "Daryn Sharp",
      "daysBetweenCommits": 3.11,
      "commitsBetweenForRepo": 27,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,74 +1,70 @@\n   private void initialize(final Configuration conf,\n       CommandLineOpts commandLineOpts) throws IOException {\n     final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n     infoBindAddress \u003d infoSocAddr.getHostName();\n     UserGroupInformation.setConfiguration(conf);\n     if (UserGroupInformation.isSecurityEnabled()) {\n       SecurityUtil.login(conf, DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n           DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n     }\n     // initiate Java VM metrics\n     DefaultMetricsSystem.initialize(\"SecondaryNameNode\");\n     JvmMetrics.create(\"SecondaryNameNode\",\n         conf.get(DFS_METRICS_SESSION_ID_KEY), DefaultMetricsSystem.instance());\n     \n     // Create connection to the namenode.\n     shouldRun \u003d true;\n     nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n \n     this.conf \u003d conf;\n     this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n         NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n         true).getProxy();\n \n     // initialize checkpoint directories\n     fsName \u003d getInfoServer();\n     checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                   \"/tmp/hadoop/dfs/namesecondary\");\n     checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                   \"/tmp/hadoop/dfs/namesecondary\");    \n     checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n     checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n     \n     namesystem \u003d new FSNamesystem(conf, checkpointImage);\n \n     // Initialize other scheduling parameters from the configuration\n     checkpointConf \u003d new CheckpointConf(conf);\n \n     // initialize the webserver for uploading files.\n     int tmpInfoPort \u003d infoSocAddr.getPort();\n     infoServer \u003d new HttpServer(\"secondary\", infoBindAddress, tmpInfoPort,\n                                 tmpInfoPort \u003d\u003d 0, conf,\n                                 new AccessControlList(conf.get(DFS_ADMIN, \" \"))) {\n       {\n         if (UserGroupInformation.isSecurityEnabled()) {\n-          String httpKeytabKey \u003d DFSConfigKeys.\n-              DFS_WEB_AUTHENTICATION_KERBEROS_KEYTAB_KEY;\n-          if (null \u003d\u003d conf.get(httpKeytabKey)) {\n-            httpKeytabKey \u003d DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY;\n-          }\n           initSpnego(\n               conf,\n               DFSConfigKeys.DFS_SECONDARY_NAMENODE_INTERNAL_SPNEGO_USER_NAME_KEY,\n-              httpKeytabKey);\n+              DFSUtil.getSpnegoKeytabKey(conf,\n+                  DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY));\n         }\n       }\n     };\n     infoServer.setAttribute(\"secondary.name.node\", this);\n     infoServer.setAttribute(\"name.system.image\", checkpointImage);\n     infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n     infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n                                   GetImageServlet.class, true);\n     infoServer.start();\n \n     LOG.info(\"Web server init done\");\n \n     // The web-server port can be ephemeral... ensure we have the correct info\n     infoPort \u003d infoServer.getPort();\n \n     conf.set(DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, infoBindAddress + \":\" + infoPort);\n     LOG.info(\"Secondary Web-server up at: \" + infoBindAddress + \":\" + infoPort);\n     LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \" +\n              \"(\" + checkpointConf.getPeriod() / 60 + \" min)\");\n     LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void initialize(final Configuration conf,\n      CommandLineOpts commandLineOpts) throws IOException {\n    final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n    infoBindAddress \u003d infoSocAddr.getHostName();\n    UserGroupInformation.setConfiguration(conf);\n    if (UserGroupInformation.isSecurityEnabled()) {\n      SecurityUtil.login(conf, DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n          DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n    }\n    // initiate Java VM metrics\n    DefaultMetricsSystem.initialize(\"SecondaryNameNode\");\n    JvmMetrics.create(\"SecondaryNameNode\",\n        conf.get(DFS_METRICS_SESSION_ID_KEY), DefaultMetricsSystem.instance());\n    \n    // Create connection to the namenode.\n    shouldRun \u003d true;\n    nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n\n    this.conf \u003d conf;\n    this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n        NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n        true).getProxy();\n\n    // initialize checkpoint directories\n    fsName \u003d getInfoServer();\n    checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                  \"/tmp/hadoop/dfs/namesecondary\");\n    checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                  \"/tmp/hadoop/dfs/namesecondary\");    \n    checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n    checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n    \n    namesystem \u003d new FSNamesystem(conf, checkpointImage);\n\n    // Initialize other scheduling parameters from the configuration\n    checkpointConf \u003d new CheckpointConf(conf);\n\n    // initialize the webserver for uploading files.\n    int tmpInfoPort \u003d infoSocAddr.getPort();\n    infoServer \u003d new HttpServer(\"secondary\", infoBindAddress, tmpInfoPort,\n                                tmpInfoPort \u003d\u003d 0, conf,\n                                new AccessControlList(conf.get(DFS_ADMIN, \" \"))) {\n      {\n        if (UserGroupInformation.isSecurityEnabled()) {\n          initSpnego(\n              conf,\n              DFSConfigKeys.DFS_SECONDARY_NAMENODE_INTERNAL_SPNEGO_USER_NAME_KEY,\n              DFSUtil.getSpnegoKeytabKey(conf,\n                  DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY));\n        }\n      }\n    };\n    infoServer.setAttribute(\"secondary.name.node\", this);\n    infoServer.setAttribute(\"name.system.image\", checkpointImage);\n    infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n    infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n                                  GetImageServlet.class, true);\n    infoServer.start();\n\n    LOG.info(\"Web server init done\");\n\n    // The web-server port can be ephemeral... ensure we have the correct info\n    infoPort \u003d infoServer.getPort();\n\n    conf.set(DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, infoBindAddress + \":\" + infoPort);\n    LOG.info(\"Secondary Web-server up at: \" + infoBindAddress + \":\" + infoPort);\n    LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \" +\n             \"(\" + checkpointConf.getPeriod() / 60 + \" min)\");\n    LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
      "extendedDetails": {}
    },
    "1cbc38a8783c1abe49dc6e076cb865642ca753ee": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4105. The SPNEGO user for secondary namenode should use the web keytab. Contributed by Arpit Gupta.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1410691 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/11/12 7:30 PM",
      "commitName": "1cbc38a8783c1abe49dc6e076cb865642ca753ee",
      "commitAuthor": "Jitendra Nath Pandey",
      "commitDateOld": "14/11/12 11:21 AM",
      "commitNameOld": "59e4199d842d8590d2c73c6dba805a9746e1ef4a",
      "commitAuthorOld": "Robert Joseph Evans",
      "daysBetweenCommits": 2.34,
      "commitsBetweenForRepo": 21,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,67 +1,74 @@\n   private void initialize(final Configuration conf,\n       CommandLineOpts commandLineOpts) throws IOException {\n     final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n     infoBindAddress \u003d infoSocAddr.getHostName();\n     UserGroupInformation.setConfiguration(conf);\n     if (UserGroupInformation.isSecurityEnabled()) {\n       SecurityUtil.login(conf, DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n           DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n     }\n     // initiate Java VM metrics\n     DefaultMetricsSystem.initialize(\"SecondaryNameNode\");\n     JvmMetrics.create(\"SecondaryNameNode\",\n         conf.get(DFS_METRICS_SESSION_ID_KEY), DefaultMetricsSystem.instance());\n     \n     // Create connection to the namenode.\n     shouldRun \u003d true;\n     nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n \n     this.conf \u003d conf;\n     this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n         NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n         true).getProxy();\n \n     // initialize checkpoint directories\n     fsName \u003d getInfoServer();\n     checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                   \"/tmp/hadoop/dfs/namesecondary\");\n     checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                   \"/tmp/hadoop/dfs/namesecondary\");    \n     checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n     checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n     \n     namesystem \u003d new FSNamesystem(conf, checkpointImage);\n \n     // Initialize other scheduling parameters from the configuration\n     checkpointConf \u003d new CheckpointConf(conf);\n \n     // initialize the webserver for uploading files.\n     int tmpInfoPort \u003d infoSocAddr.getPort();\n     infoServer \u003d new HttpServer(\"secondary\", infoBindAddress, tmpInfoPort,\n                                 tmpInfoPort \u003d\u003d 0, conf,\n                                 new AccessControlList(conf.get(DFS_ADMIN, \" \"))) {\n       {\n         if (UserGroupInformation.isSecurityEnabled()) {\n-          initSpnego(conf, DFSConfigKeys.DFS_SECONDARY_NAMENODE_INTERNAL_SPNEGO_USER_NAME_KEY,\n-              DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY);\n+          String httpKeytabKey \u003d DFSConfigKeys.\n+              DFS_WEB_AUTHENTICATION_KERBEROS_KEYTAB_KEY;\n+          if (null \u003d\u003d conf.get(httpKeytabKey)) {\n+            httpKeytabKey \u003d DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY;\n+          }\n+          initSpnego(\n+              conf,\n+              DFSConfigKeys.DFS_SECONDARY_NAMENODE_INTERNAL_SPNEGO_USER_NAME_KEY,\n+              httpKeytabKey);\n         }\n       }\n     };\n     infoServer.setAttribute(\"secondary.name.node\", this);\n     infoServer.setAttribute(\"name.system.image\", checkpointImage);\n     infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n     infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n                                   GetImageServlet.class, true);\n     infoServer.start();\n \n     LOG.info(\"Web server init done\");\n \n     // The web-server port can be ephemeral... ensure we have the correct info\n     infoPort \u003d infoServer.getPort();\n \n     conf.set(DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, infoBindAddress + \":\" + infoPort);\n     LOG.info(\"Secondary Web-server up at: \" + infoBindAddress + \":\" + infoPort);\n     LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \" +\n              \"(\" + checkpointConf.getPeriod() / 60 + \" min)\");\n     LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void initialize(final Configuration conf,\n      CommandLineOpts commandLineOpts) throws IOException {\n    final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n    infoBindAddress \u003d infoSocAddr.getHostName();\n    UserGroupInformation.setConfiguration(conf);\n    if (UserGroupInformation.isSecurityEnabled()) {\n      SecurityUtil.login(conf, DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n          DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n    }\n    // initiate Java VM metrics\n    DefaultMetricsSystem.initialize(\"SecondaryNameNode\");\n    JvmMetrics.create(\"SecondaryNameNode\",\n        conf.get(DFS_METRICS_SESSION_ID_KEY), DefaultMetricsSystem.instance());\n    \n    // Create connection to the namenode.\n    shouldRun \u003d true;\n    nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n\n    this.conf \u003d conf;\n    this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n        NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n        true).getProxy();\n\n    // initialize checkpoint directories\n    fsName \u003d getInfoServer();\n    checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                  \"/tmp/hadoop/dfs/namesecondary\");\n    checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                  \"/tmp/hadoop/dfs/namesecondary\");    \n    checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n    checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n    \n    namesystem \u003d new FSNamesystem(conf, checkpointImage);\n\n    // Initialize other scheduling parameters from the configuration\n    checkpointConf \u003d new CheckpointConf(conf);\n\n    // initialize the webserver for uploading files.\n    int tmpInfoPort \u003d infoSocAddr.getPort();\n    infoServer \u003d new HttpServer(\"secondary\", infoBindAddress, tmpInfoPort,\n                                tmpInfoPort \u003d\u003d 0, conf,\n                                new AccessControlList(conf.get(DFS_ADMIN, \" \"))) {\n      {\n        if (UserGroupInformation.isSecurityEnabled()) {\n          String httpKeytabKey \u003d DFSConfigKeys.\n              DFS_WEB_AUTHENTICATION_KERBEROS_KEYTAB_KEY;\n          if (null \u003d\u003d conf.get(httpKeytabKey)) {\n            httpKeytabKey \u003d DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY;\n          }\n          initSpnego(\n              conf,\n              DFSConfigKeys.DFS_SECONDARY_NAMENODE_INTERNAL_SPNEGO_USER_NAME_KEY,\n              httpKeytabKey);\n        }\n      }\n    };\n    infoServer.setAttribute(\"secondary.name.node\", this);\n    infoServer.setAttribute(\"name.system.image\", checkpointImage);\n    infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n    infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n                                  GetImageServlet.class, true);\n    infoServer.start();\n\n    LOG.info(\"Web server init done\");\n\n    // The web-server port can be ephemeral... ensure we have the correct info\n    infoPort \u003d infoServer.getPort();\n\n    conf.set(DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, infoBindAddress + \":\" + infoPort);\n    LOG.info(\"Secondary Web-server up at: \" + infoBindAddress + \":\" + infoPort);\n    LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \" +\n             \"(\" + checkpointConf.getPeriod() / 60 + \" min)\");\n    LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
      "extendedDetails": {}
    },
    "5770a453f304d83463879db6101da1f1e81e5563": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3572. Cleanup code which inits SPNEGO in HttpServer. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1354767 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/06/12 3:41 PM",
      "commitName": "5770a453f304d83463879db6101da1f1e81e5563",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "04/05/12 2:58 PM",
      "commitNameOld": "5dbbe0e0a5d31689d3425e490865f95057dc051c",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 54.03,
      "commitsBetweenForRepo": 254,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,79 +1,67 @@\n   private void initialize(final Configuration conf,\n       CommandLineOpts commandLineOpts) throws IOException {\n     final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n     infoBindAddress \u003d infoSocAddr.getHostName();\n     UserGroupInformation.setConfiguration(conf);\n     if (UserGroupInformation.isSecurityEnabled()) {\n       SecurityUtil.login(conf, DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n           DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n     }\n     // initiate Java VM metrics\n     DefaultMetricsSystem.initialize(\"SecondaryNameNode\");\n     JvmMetrics.create(\"SecondaryNameNode\",\n         conf.get(DFS_METRICS_SESSION_ID_KEY), DefaultMetricsSystem.instance());\n     \n     // Create connection to the namenode.\n     shouldRun \u003d true;\n     nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n \n     this.conf \u003d conf;\n     this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n         NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n         true).getProxy();\n \n     // initialize checkpoint directories\n     fsName \u003d getInfoServer();\n     checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                   \"/tmp/hadoop/dfs/namesecondary\");\n     checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                   \"/tmp/hadoop/dfs/namesecondary\");    \n     checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n     checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n     \n     namesystem \u003d new FSNamesystem(conf, checkpointImage);\n \n     // Initialize other scheduling parameters from the configuration\n     checkpointConf \u003d new CheckpointConf(conf);\n \n     // initialize the webserver for uploading files.\n     int tmpInfoPort \u003d infoSocAddr.getPort();\n     infoServer \u003d new HttpServer(\"secondary\", infoBindAddress, tmpInfoPort,\n                                 tmpInfoPort \u003d\u003d 0, conf,\n                                 new AccessControlList(conf.get(DFS_ADMIN, \" \"))) {\n       {\n         if (UserGroupInformation.isSecurityEnabled()) {\n-          Map\u003cString, String\u003e params \u003d new HashMap\u003cString, String\u003e();\n-          String principalInConf \u003d conf.get(DFSConfigKeys.DFS_SECONDARY_NAMENODE_INTERNAL_SPENGO_USER_NAME_KEY);\n-          if (principalInConf !\u003d null \u0026\u0026 !principalInConf.isEmpty()) {\n-            params.put(\"kerberos.principal\",\n-                       SecurityUtil.getServerPrincipal(principalInConf, infoSocAddr.getHostName()));\n-          }\n-          String httpKeytab \u003d conf.get(DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY);\n-          if (httpKeytab !\u003d null \u0026\u0026 !httpKeytab.isEmpty()) {\n-            params.put(\"kerberos.keytab\", httpKeytab);\n-          }\n-          params.put(AuthenticationFilter.AUTH_TYPE, \"kerberos\");\n-\n-          defineFilter(webAppContext, SPNEGO_FILTER, AuthenticationFilter.class.getName(),\n-                       params, null);\n+          initSpnego(conf, DFSConfigKeys.DFS_SECONDARY_NAMENODE_INTERNAL_SPNEGO_USER_NAME_KEY,\n+              DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY);\n         }\n       }\n     };\n     infoServer.setAttribute(\"secondary.name.node\", this);\n     infoServer.setAttribute(\"name.system.image\", checkpointImage);\n     infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n     infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n                                   GetImageServlet.class, true);\n     infoServer.start();\n \n     LOG.info(\"Web server init done\");\n \n     // The web-server port can be ephemeral... ensure we have the correct info\n     infoPort \u003d infoServer.getPort();\n \n     conf.set(DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, infoBindAddress + \":\" + infoPort);\n     LOG.info(\"Secondary Web-server up at: \" + infoBindAddress + \":\" + infoPort);\n     LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \" +\n              \"(\" + checkpointConf.getPeriod() / 60 + \" min)\");\n     LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void initialize(final Configuration conf,\n      CommandLineOpts commandLineOpts) throws IOException {\n    final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n    infoBindAddress \u003d infoSocAddr.getHostName();\n    UserGroupInformation.setConfiguration(conf);\n    if (UserGroupInformation.isSecurityEnabled()) {\n      SecurityUtil.login(conf, DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n          DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n    }\n    // initiate Java VM metrics\n    DefaultMetricsSystem.initialize(\"SecondaryNameNode\");\n    JvmMetrics.create(\"SecondaryNameNode\",\n        conf.get(DFS_METRICS_SESSION_ID_KEY), DefaultMetricsSystem.instance());\n    \n    // Create connection to the namenode.\n    shouldRun \u003d true;\n    nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n\n    this.conf \u003d conf;\n    this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n        NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n        true).getProxy();\n\n    // initialize checkpoint directories\n    fsName \u003d getInfoServer();\n    checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                  \"/tmp/hadoop/dfs/namesecondary\");\n    checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                  \"/tmp/hadoop/dfs/namesecondary\");    \n    checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n    checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n    \n    namesystem \u003d new FSNamesystem(conf, checkpointImage);\n\n    // Initialize other scheduling parameters from the configuration\n    checkpointConf \u003d new CheckpointConf(conf);\n\n    // initialize the webserver for uploading files.\n    int tmpInfoPort \u003d infoSocAddr.getPort();\n    infoServer \u003d new HttpServer(\"secondary\", infoBindAddress, tmpInfoPort,\n                                tmpInfoPort \u003d\u003d 0, conf,\n                                new AccessControlList(conf.get(DFS_ADMIN, \" \"))) {\n      {\n        if (UserGroupInformation.isSecurityEnabled()) {\n          initSpnego(conf, DFSConfigKeys.DFS_SECONDARY_NAMENODE_INTERNAL_SPNEGO_USER_NAME_KEY,\n              DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY);\n        }\n      }\n    };\n    infoServer.setAttribute(\"secondary.name.node\", this);\n    infoServer.setAttribute(\"name.system.image\", checkpointImage);\n    infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n    infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n                                  GetImageServlet.class, true);\n    infoServer.start();\n\n    LOG.info(\"Web server init done\");\n\n    // The web-server port can be ephemeral... ensure we have the correct info\n    infoPort \u003d infoServer.getPort();\n\n    conf.set(DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, infoBindAddress + \":\" + infoPort);\n    LOG.info(\"Secondary Web-server up at: \" + infoBindAddress + \":\" + infoPort);\n    LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \" +\n             \"(\" + checkpointConf.getPeriod() / 60 + \" min)\");\n    LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
      "extendedDetails": {}
    },
    "5dbbe0e0a5d31689d3425e490865f95057dc051c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2617. Replaced Kerberized SSL for image transfer and fsck with SPNEGO-based solution. Contributed by Jakob Homan, Alejandro Abdelnur, and Aaron T. Myers\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1334216 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/05/12 2:58 PM",
      "commitName": "5dbbe0e0a5d31689d3425e490865f95057dc051c",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "02/05/12 6:44 PM",
      "commitNameOld": "cbc242429093ccabf76248f857de5e587a9682b0",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 1.84,
      "commitsBetweenForRepo": 18,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,95 +1,79 @@\n   private void initialize(final Configuration conf,\n       CommandLineOpts commandLineOpts) throws IOException {\n     final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n     infoBindAddress \u003d infoSocAddr.getHostName();\n     UserGroupInformation.setConfiguration(conf);\n     if (UserGroupInformation.isSecurityEnabled()) {\n       SecurityUtil.login(conf, DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n           DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n     }\n     // initiate Java VM metrics\n     DefaultMetricsSystem.initialize(\"SecondaryNameNode\");\n     JvmMetrics.create(\"SecondaryNameNode\",\n         conf.get(DFS_METRICS_SESSION_ID_KEY), DefaultMetricsSystem.instance());\n     \n     // Create connection to the namenode.\n     shouldRun \u003d true;\n     nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n \n     this.conf \u003d conf;\n     this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n         NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n         true).getProxy();\n \n     // initialize checkpoint directories\n     fsName \u003d getInfoServer();\n     checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                   \"/tmp/hadoop/dfs/namesecondary\");\n     checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                   \"/tmp/hadoop/dfs/namesecondary\");    \n     checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n     checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n     \n     namesystem \u003d new FSNamesystem(conf, checkpointImage);\n \n     // Initialize other scheduling parameters from the configuration\n     checkpointConf \u003d new CheckpointConf(conf);\n-    \n-    // initialize the webserver for uploading files.\n-    // Kerberized SSL servers must be run from the host principal...\n-    UserGroupInformation httpUGI \u003d \n-      UserGroupInformation.loginUserFromKeytabAndReturnUGI(\n-          SecurityUtil.getServerPrincipal(conf\n-              .get(DFS_SECONDARY_NAMENODE_KRB_HTTPS_USER_NAME_KEY),\n-              infoBindAddress),\n-          conf.get(DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY));\n-    try {\n-      infoServer \u003d httpUGI.doAs(new PrivilegedExceptionAction\u003cHttpServer\u003e() {\n-        @Override\n-        public HttpServer run() throws IOException, InterruptedException {\n-          LOG.info(\"Starting web server as: \" +\n-              UserGroupInformation.getCurrentUser().getUserName());\n \n-          int tmpInfoPort \u003d infoSocAddr.getPort();\n-          infoServer \u003d new HttpServer(\"secondary\", infoBindAddress, tmpInfoPort,\n-              tmpInfoPort \u003d\u003d 0, conf, \n-              new AccessControlList(conf.get(DFS_ADMIN, \" \")));\n-          \n-          if(UserGroupInformation.isSecurityEnabled()) {\n-            SecurityUtil.initKrb5CipherSuites();\n-            InetSocketAddress secInfoSocAddr \u003d \n-              NetUtils.createSocketAddr(infoBindAddress + \":\"+ conf.getInt(\n-                DFS_NAMENODE_SECONDARY_HTTPS_PORT_KEY,\n-                DFS_NAMENODE_SECONDARY_HTTPS_PORT_DEFAULT));\n-            imagePort \u003d secInfoSocAddr.getPort();\n-            infoServer.addSslListener(secInfoSocAddr, conf, false, true);\n+    // initialize the webserver for uploading files.\n+    int tmpInfoPort \u003d infoSocAddr.getPort();\n+    infoServer \u003d new HttpServer(\"secondary\", infoBindAddress, tmpInfoPort,\n+                                tmpInfoPort \u003d\u003d 0, conf,\n+                                new AccessControlList(conf.get(DFS_ADMIN, \" \"))) {\n+      {\n+        if (UserGroupInformation.isSecurityEnabled()) {\n+          Map\u003cString, String\u003e params \u003d new HashMap\u003cString, String\u003e();\n+          String principalInConf \u003d conf.get(DFSConfigKeys.DFS_SECONDARY_NAMENODE_INTERNAL_SPENGO_USER_NAME_KEY);\n+          if (principalInConf !\u003d null \u0026\u0026 !principalInConf.isEmpty()) {\n+            params.put(\"kerberos.principal\",\n+                       SecurityUtil.getServerPrincipal(principalInConf, infoSocAddr.getHostName()));\n           }\n-          \n-          infoServer.setAttribute(\"secondary.name.node\", SecondaryNameNode.this);\n-          infoServer.setAttribute(\"name.system.image\", checkpointImage);\n-          infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n-          infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n-              GetImageServlet.class, true);\n-          infoServer.start();\n-          return infoServer;\n+          String httpKeytab \u003d conf.get(DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY);\n+          if (httpKeytab !\u003d null \u0026\u0026 !httpKeytab.isEmpty()) {\n+            params.put(\"kerberos.keytab\", httpKeytab);\n+          }\n+          params.put(AuthenticationFilter.AUTH_TYPE, \"kerberos\");\n+\n+          defineFilter(webAppContext, SPNEGO_FILTER, AuthenticationFilter.class.getName(),\n+                       params, null);\n         }\n-      });\n-    } catch (InterruptedException e) {\n-      throw new RuntimeException(e);\n-    } \n-    \n+      }\n+    };\n+    infoServer.setAttribute(\"secondary.name.node\", this);\n+    infoServer.setAttribute(\"name.system.image\", checkpointImage);\n+    infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n+    infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n+                                  GetImageServlet.class, true);\n+    infoServer.start();\n+\n     LOG.info(\"Web server init done\");\n \n     // The web-server port can be ephemeral... ensure we have the correct info\n     infoPort \u003d infoServer.getPort();\n-    if (!UserGroupInformation.isSecurityEnabled()) {\n-      imagePort \u003d infoPort;\n-    }\n-    \n-    conf.set(DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, infoBindAddress + \":\" +infoPort); \n-    LOG.info(\"Secondary Web-server up at: \" + infoBindAddress + \":\" +infoPort);\n-    LOG.info(\"Secondary image servlet up at: \" + infoBindAddress + \":\" + imagePort);\n+\n+    conf.set(DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, infoBindAddress + \":\" + infoPort);\n+    LOG.info(\"Secondary Web-server up at: \" + infoBindAddress + \":\" + infoPort);\n     LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \" +\n-             \"(\" + checkpointConf.getPeriod()/60 + \" min)\");\n+             \"(\" + checkpointConf.getPeriod() / 60 + \" min)\");\n     LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void initialize(final Configuration conf,\n      CommandLineOpts commandLineOpts) throws IOException {\n    final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n    infoBindAddress \u003d infoSocAddr.getHostName();\n    UserGroupInformation.setConfiguration(conf);\n    if (UserGroupInformation.isSecurityEnabled()) {\n      SecurityUtil.login(conf, DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n          DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n    }\n    // initiate Java VM metrics\n    DefaultMetricsSystem.initialize(\"SecondaryNameNode\");\n    JvmMetrics.create(\"SecondaryNameNode\",\n        conf.get(DFS_METRICS_SESSION_ID_KEY), DefaultMetricsSystem.instance());\n    \n    // Create connection to the namenode.\n    shouldRun \u003d true;\n    nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n\n    this.conf \u003d conf;\n    this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n        NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n        true).getProxy();\n\n    // initialize checkpoint directories\n    fsName \u003d getInfoServer();\n    checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                  \"/tmp/hadoop/dfs/namesecondary\");\n    checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                  \"/tmp/hadoop/dfs/namesecondary\");    \n    checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n    checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n    \n    namesystem \u003d new FSNamesystem(conf, checkpointImage);\n\n    // Initialize other scheduling parameters from the configuration\n    checkpointConf \u003d new CheckpointConf(conf);\n\n    // initialize the webserver for uploading files.\n    int tmpInfoPort \u003d infoSocAddr.getPort();\n    infoServer \u003d new HttpServer(\"secondary\", infoBindAddress, tmpInfoPort,\n                                tmpInfoPort \u003d\u003d 0, conf,\n                                new AccessControlList(conf.get(DFS_ADMIN, \" \"))) {\n      {\n        if (UserGroupInformation.isSecurityEnabled()) {\n          Map\u003cString, String\u003e params \u003d new HashMap\u003cString, String\u003e();\n          String principalInConf \u003d conf.get(DFSConfigKeys.DFS_SECONDARY_NAMENODE_INTERNAL_SPENGO_USER_NAME_KEY);\n          if (principalInConf !\u003d null \u0026\u0026 !principalInConf.isEmpty()) {\n            params.put(\"kerberos.principal\",\n                       SecurityUtil.getServerPrincipal(principalInConf, infoSocAddr.getHostName()));\n          }\n          String httpKeytab \u003d conf.get(DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY);\n          if (httpKeytab !\u003d null \u0026\u0026 !httpKeytab.isEmpty()) {\n            params.put(\"kerberos.keytab\", httpKeytab);\n          }\n          params.put(AuthenticationFilter.AUTH_TYPE, \"kerberos\");\n\n          defineFilter(webAppContext, SPNEGO_FILTER, AuthenticationFilter.class.getName(),\n                       params, null);\n        }\n      }\n    };\n    infoServer.setAttribute(\"secondary.name.node\", this);\n    infoServer.setAttribute(\"name.system.image\", checkpointImage);\n    infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n    infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n                                  GetImageServlet.class, true);\n    infoServer.start();\n\n    LOG.info(\"Web server init done\");\n\n    // The web-server port can be ephemeral... ensure we have the correct info\n    infoPort \u003d infoServer.getPort();\n\n    conf.set(DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, infoBindAddress + \":\" + infoPort);\n    LOG.info(\"Secondary Web-server up at: \" + infoBindAddress + \":\" + infoPort);\n    LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \" +\n             \"(\" + checkpointConf.getPeriod() / 60 + \" min)\");\n    LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
      "extendedDetails": {}
    },
    "65425b0961d6634f0fc0d798bbd12f02d40a8578": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3099. SecondaryNameNode does not properly initialize metrics system. Contributed by Aaron T. Myers.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1301222 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "15/03/12 2:51 PM",
      "commitName": "65425b0961d6634f0fc0d798bbd12f02d40a8578",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "12/03/12 12:41 PM",
      "commitNameOld": "1a75ec82885e45baf4d5cd56d6c738d8e68d8bc7",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 3.09,
      "commitsBetweenForRepo": 13,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,94 +1,95 @@\n   private void initialize(final Configuration conf,\n       CommandLineOpts commandLineOpts) throws IOException {\n     final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n     infoBindAddress \u003d infoSocAddr.getHostName();\n     UserGroupInformation.setConfiguration(conf);\n     if (UserGroupInformation.isSecurityEnabled()) {\n       SecurityUtil.login(conf, DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n           DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n     }\n     // initiate Java VM metrics\n+    DefaultMetricsSystem.initialize(\"SecondaryNameNode\");\n     JvmMetrics.create(\"SecondaryNameNode\",\n         conf.get(DFS_METRICS_SESSION_ID_KEY), DefaultMetricsSystem.instance());\n     \n     // Create connection to the namenode.\n     shouldRun \u003d true;\n     nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n \n     this.conf \u003d conf;\n     this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n         NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n         true).getProxy();\n \n     // initialize checkpoint directories\n     fsName \u003d getInfoServer();\n     checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                   \"/tmp/hadoop/dfs/namesecondary\");\n     checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                   \"/tmp/hadoop/dfs/namesecondary\");    \n     checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n     checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n     \n     namesystem \u003d new FSNamesystem(conf, checkpointImage);\n \n     // Initialize other scheduling parameters from the configuration\n     checkpointConf \u003d new CheckpointConf(conf);\n     \n     // initialize the webserver for uploading files.\n     // Kerberized SSL servers must be run from the host principal...\n     UserGroupInformation httpUGI \u003d \n       UserGroupInformation.loginUserFromKeytabAndReturnUGI(\n           SecurityUtil.getServerPrincipal(conf\n               .get(DFS_SECONDARY_NAMENODE_KRB_HTTPS_USER_NAME_KEY),\n               infoBindAddress),\n           conf.get(DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY));\n     try {\n       infoServer \u003d httpUGI.doAs(new PrivilegedExceptionAction\u003cHttpServer\u003e() {\n         @Override\n         public HttpServer run() throws IOException, InterruptedException {\n           LOG.info(\"Starting web server as: \" +\n               UserGroupInformation.getCurrentUser().getUserName());\n \n           int tmpInfoPort \u003d infoSocAddr.getPort();\n           infoServer \u003d new HttpServer(\"secondary\", infoBindAddress, tmpInfoPort,\n               tmpInfoPort \u003d\u003d 0, conf, \n               new AccessControlList(conf.get(DFS_ADMIN, \" \")));\n           \n           if(UserGroupInformation.isSecurityEnabled()) {\n             SecurityUtil.initKrb5CipherSuites();\n             InetSocketAddress secInfoSocAddr \u003d \n               NetUtils.createSocketAddr(infoBindAddress + \":\"+ conf.getInt(\n                 DFS_NAMENODE_SECONDARY_HTTPS_PORT_KEY,\n                 DFS_NAMENODE_SECONDARY_HTTPS_PORT_DEFAULT));\n             imagePort \u003d secInfoSocAddr.getPort();\n             infoServer.addSslListener(secInfoSocAddr, conf, false, true);\n           }\n           \n           infoServer.setAttribute(\"secondary.name.node\", SecondaryNameNode.this);\n           infoServer.setAttribute(\"name.system.image\", checkpointImage);\n           infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n           infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n               GetImageServlet.class, true);\n           infoServer.start();\n           return infoServer;\n         }\n       });\n     } catch (InterruptedException e) {\n       throw new RuntimeException(e);\n     } \n     \n     LOG.info(\"Web server init done\");\n \n     // The web-server port can be ephemeral... ensure we have the correct info\n     infoPort \u003d infoServer.getPort();\n     if (!UserGroupInformation.isSecurityEnabled()) {\n       imagePort \u003d infoPort;\n     }\n     \n     conf.set(DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, infoBindAddress + \":\" +infoPort); \n     LOG.info(\"Secondary Web-server up at: \" + infoBindAddress + \":\" +infoPort);\n     LOG.info(\"Secondary image servlet up at: \" + infoBindAddress + \":\" + imagePort);\n     LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \" +\n              \"(\" + checkpointConf.getPeriod()/60 + \" min)\");\n     LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void initialize(final Configuration conf,\n      CommandLineOpts commandLineOpts) throws IOException {\n    final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n    infoBindAddress \u003d infoSocAddr.getHostName();\n    UserGroupInformation.setConfiguration(conf);\n    if (UserGroupInformation.isSecurityEnabled()) {\n      SecurityUtil.login(conf, DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n          DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n    }\n    // initiate Java VM metrics\n    DefaultMetricsSystem.initialize(\"SecondaryNameNode\");\n    JvmMetrics.create(\"SecondaryNameNode\",\n        conf.get(DFS_METRICS_SESSION_ID_KEY), DefaultMetricsSystem.instance());\n    \n    // Create connection to the namenode.\n    shouldRun \u003d true;\n    nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n\n    this.conf \u003d conf;\n    this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n        NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n        true).getProxy();\n\n    // initialize checkpoint directories\n    fsName \u003d getInfoServer();\n    checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                  \"/tmp/hadoop/dfs/namesecondary\");\n    checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                  \"/tmp/hadoop/dfs/namesecondary\");    \n    checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n    checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n    \n    namesystem \u003d new FSNamesystem(conf, checkpointImage);\n\n    // Initialize other scheduling parameters from the configuration\n    checkpointConf \u003d new CheckpointConf(conf);\n    \n    // initialize the webserver for uploading files.\n    // Kerberized SSL servers must be run from the host principal...\n    UserGroupInformation httpUGI \u003d \n      UserGroupInformation.loginUserFromKeytabAndReturnUGI(\n          SecurityUtil.getServerPrincipal(conf\n              .get(DFS_SECONDARY_NAMENODE_KRB_HTTPS_USER_NAME_KEY),\n              infoBindAddress),\n          conf.get(DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY));\n    try {\n      infoServer \u003d httpUGI.doAs(new PrivilegedExceptionAction\u003cHttpServer\u003e() {\n        @Override\n        public HttpServer run() throws IOException, InterruptedException {\n          LOG.info(\"Starting web server as: \" +\n              UserGroupInformation.getCurrentUser().getUserName());\n\n          int tmpInfoPort \u003d infoSocAddr.getPort();\n          infoServer \u003d new HttpServer(\"secondary\", infoBindAddress, tmpInfoPort,\n              tmpInfoPort \u003d\u003d 0, conf, \n              new AccessControlList(conf.get(DFS_ADMIN, \" \")));\n          \n          if(UserGroupInformation.isSecurityEnabled()) {\n            SecurityUtil.initKrb5CipherSuites();\n            InetSocketAddress secInfoSocAddr \u003d \n              NetUtils.createSocketAddr(infoBindAddress + \":\"+ conf.getInt(\n                DFS_NAMENODE_SECONDARY_HTTPS_PORT_KEY,\n                DFS_NAMENODE_SECONDARY_HTTPS_PORT_DEFAULT));\n            imagePort \u003d secInfoSocAddr.getPort();\n            infoServer.addSslListener(secInfoSocAddr, conf, false, true);\n          }\n          \n          infoServer.setAttribute(\"secondary.name.node\", SecondaryNameNode.this);\n          infoServer.setAttribute(\"name.system.image\", checkpointImage);\n          infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n          infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n              GetImageServlet.class, true);\n          infoServer.start();\n          return infoServer;\n        }\n      });\n    } catch (InterruptedException e) {\n      throw new RuntimeException(e);\n    } \n    \n    LOG.info(\"Web server init done\");\n\n    // The web-server port can be ephemeral... ensure we have the correct info\n    infoPort \u003d infoServer.getPort();\n    if (!UserGroupInformation.isSecurityEnabled()) {\n      imagePort \u003d infoPort;\n    }\n    \n    conf.set(DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, infoBindAddress + \":\" +infoPort); \n    LOG.info(\"Secondary Web-server up at: \" + infoBindAddress + \":\" +infoPort);\n    LOG.info(\"Secondary image servlet up at: \" + infoBindAddress + \":\" + imagePort);\n    LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \" +\n             \"(\" + checkpointConf.getPeriod()/60 + \" min)\");\n    LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
      "extendedDetails": {}
    },
    "1a75ec82885e45baf4d5cd56d6c738d8e68d8bc7": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2731. Add command to bootstrap the Standby Node\u0027s name directories from the Active NameNode. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1299807 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/03/12 12:41 PM",
      "commitName": "1a75ec82885e45baf4d5cd56d6c738d8e68d8bc7",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "28/02/12 12:09 PM",
      "commitNameOld": "c69dfdd5e14af490790dff8227b11962ec816577",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 12.98,
      "commitsBetweenForRepo": 92,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,95 +1,94 @@\n   private void initialize(final Configuration conf,\n       CommandLineOpts commandLineOpts) throws IOException {\n     final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n     infoBindAddress \u003d infoSocAddr.getHostName();\n     UserGroupInformation.setConfiguration(conf);\n     if (UserGroupInformation.isSecurityEnabled()) {\n       SecurityUtil.login(conf, DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n           DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n     }\n     // initiate Java VM metrics\n     JvmMetrics.create(\"SecondaryNameNode\",\n         conf.get(DFS_METRICS_SESSION_ID_KEY), DefaultMetricsSystem.instance());\n     \n     // Create connection to the namenode.\n     shouldRun \u003d true;\n     nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n \n     this.conf \u003d conf;\n     this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n         NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n         true).getProxy();\n \n     // initialize checkpoint directories\n     fsName \u003d getInfoServer();\n     checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                   \"/tmp/hadoop/dfs/namesecondary\");\n     checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                   \"/tmp/hadoop/dfs/namesecondary\");    \n     checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n     checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n     \n     namesystem \u003d new FSNamesystem(conf, checkpointImage);\n \n     // Initialize other scheduling parameters from the configuration\n     checkpointConf \u003d new CheckpointConf(conf);\n     \n     // initialize the webserver for uploading files.\n     // Kerberized SSL servers must be run from the host principal...\n     UserGroupInformation httpUGI \u003d \n       UserGroupInformation.loginUserFromKeytabAndReturnUGI(\n           SecurityUtil.getServerPrincipal(conf\n               .get(DFS_SECONDARY_NAMENODE_KRB_HTTPS_USER_NAME_KEY),\n               infoBindAddress),\n           conf.get(DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY));\n     try {\n       infoServer \u003d httpUGI.doAs(new PrivilegedExceptionAction\u003cHttpServer\u003e() {\n         @Override\n         public HttpServer run() throws IOException, InterruptedException {\n           LOG.info(\"Starting web server as: \" +\n               UserGroupInformation.getCurrentUser().getUserName());\n \n           int tmpInfoPort \u003d infoSocAddr.getPort();\n           infoServer \u003d new HttpServer(\"secondary\", infoBindAddress, tmpInfoPort,\n               tmpInfoPort \u003d\u003d 0, conf, \n               new AccessControlList(conf.get(DFS_ADMIN, \" \")));\n           \n           if(UserGroupInformation.isSecurityEnabled()) {\n-            System.setProperty(\"https.cipherSuites\", \n-                Krb5AndCertsSslSocketConnector.KRB5_CIPHER_SUITES.get(0));\n+            SecurityUtil.initKrb5CipherSuites();\n             InetSocketAddress secInfoSocAddr \u003d \n               NetUtils.createSocketAddr(infoBindAddress + \":\"+ conf.getInt(\n                 DFS_NAMENODE_SECONDARY_HTTPS_PORT_KEY,\n                 DFS_NAMENODE_SECONDARY_HTTPS_PORT_DEFAULT));\n             imagePort \u003d secInfoSocAddr.getPort();\n             infoServer.addSslListener(secInfoSocAddr, conf, false, true);\n           }\n           \n           infoServer.setAttribute(\"secondary.name.node\", SecondaryNameNode.this);\n           infoServer.setAttribute(\"name.system.image\", checkpointImage);\n           infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n           infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n               GetImageServlet.class, true);\n           infoServer.start();\n           return infoServer;\n         }\n       });\n     } catch (InterruptedException e) {\n       throw new RuntimeException(e);\n     } \n     \n     LOG.info(\"Web server init done\");\n \n     // The web-server port can be ephemeral... ensure we have the correct info\n     infoPort \u003d infoServer.getPort();\n     if (!UserGroupInformation.isSecurityEnabled()) {\n       imagePort \u003d infoPort;\n     }\n     \n     conf.set(DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, infoBindAddress + \":\" +infoPort); \n     LOG.info(\"Secondary Web-server up at: \" + infoBindAddress + \":\" +infoPort);\n     LOG.info(\"Secondary image servlet up at: \" + infoBindAddress + \":\" + imagePort);\n     LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \" +\n              \"(\" + checkpointConf.getPeriod()/60 + \" min)\");\n     LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void initialize(final Configuration conf,\n      CommandLineOpts commandLineOpts) throws IOException {\n    final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n    infoBindAddress \u003d infoSocAddr.getHostName();\n    UserGroupInformation.setConfiguration(conf);\n    if (UserGroupInformation.isSecurityEnabled()) {\n      SecurityUtil.login(conf, DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n          DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n    }\n    // initiate Java VM metrics\n    JvmMetrics.create(\"SecondaryNameNode\",\n        conf.get(DFS_METRICS_SESSION_ID_KEY), DefaultMetricsSystem.instance());\n    \n    // Create connection to the namenode.\n    shouldRun \u003d true;\n    nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n\n    this.conf \u003d conf;\n    this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n        NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n        true).getProxy();\n\n    // initialize checkpoint directories\n    fsName \u003d getInfoServer();\n    checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                  \"/tmp/hadoop/dfs/namesecondary\");\n    checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                  \"/tmp/hadoop/dfs/namesecondary\");    \n    checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n    checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n    \n    namesystem \u003d new FSNamesystem(conf, checkpointImage);\n\n    // Initialize other scheduling parameters from the configuration\n    checkpointConf \u003d new CheckpointConf(conf);\n    \n    // initialize the webserver for uploading files.\n    // Kerberized SSL servers must be run from the host principal...\n    UserGroupInformation httpUGI \u003d \n      UserGroupInformation.loginUserFromKeytabAndReturnUGI(\n          SecurityUtil.getServerPrincipal(conf\n              .get(DFS_SECONDARY_NAMENODE_KRB_HTTPS_USER_NAME_KEY),\n              infoBindAddress),\n          conf.get(DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY));\n    try {\n      infoServer \u003d httpUGI.doAs(new PrivilegedExceptionAction\u003cHttpServer\u003e() {\n        @Override\n        public HttpServer run() throws IOException, InterruptedException {\n          LOG.info(\"Starting web server as: \" +\n              UserGroupInformation.getCurrentUser().getUserName());\n\n          int tmpInfoPort \u003d infoSocAddr.getPort();\n          infoServer \u003d new HttpServer(\"secondary\", infoBindAddress, tmpInfoPort,\n              tmpInfoPort \u003d\u003d 0, conf, \n              new AccessControlList(conf.get(DFS_ADMIN, \" \")));\n          \n          if(UserGroupInformation.isSecurityEnabled()) {\n            SecurityUtil.initKrb5CipherSuites();\n            InetSocketAddress secInfoSocAddr \u003d \n              NetUtils.createSocketAddr(infoBindAddress + \":\"+ conf.getInt(\n                DFS_NAMENODE_SECONDARY_HTTPS_PORT_KEY,\n                DFS_NAMENODE_SECONDARY_HTTPS_PORT_DEFAULT));\n            imagePort \u003d secInfoSocAddr.getPort();\n            infoServer.addSslListener(secInfoSocAddr, conf, false, true);\n          }\n          \n          infoServer.setAttribute(\"secondary.name.node\", SecondaryNameNode.this);\n          infoServer.setAttribute(\"name.system.image\", checkpointImage);\n          infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n          infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n              GetImageServlet.class, true);\n          infoServer.start();\n          return infoServer;\n        }\n      });\n    } catch (InterruptedException e) {\n      throw new RuntimeException(e);\n    } \n    \n    LOG.info(\"Web server init done\");\n\n    // The web-server port can be ephemeral... ensure we have the correct info\n    infoPort \u003d infoServer.getPort();\n    if (!UserGroupInformation.isSecurityEnabled()) {\n      imagePort \u003d infoPort;\n    }\n    \n    conf.set(DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, infoBindAddress + \":\" +infoPort); \n    LOG.info(\"Secondary Web-server up at: \" + infoBindAddress + \":\" +infoPort);\n    LOG.info(\"Secondary image servlet up at: \" + infoBindAddress + \":\" + imagePort);\n    LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \" +\n             \"(\" + checkpointConf.getPeriod()/60 + \" min)\");\n    LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
      "extendedDetails": {}
    },
    "c69dfdd5e14af490790dff8227b11962ec816577": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2958. Sweep for remaining proxy construction which doesn\u0027t go through failover path.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1294811 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/02/12 12:09 PM",
      "commitName": "c69dfdd5e14af490790dff8227b11962ec816577",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "15/02/12 11:04 AM",
      "commitNameOld": "1fb0ab92f828c8b3da6db527bcce1b71b7d2563c",
      "commitAuthorOld": "",
      "daysBetweenCommits": 13.05,
      "commitsBetweenForRepo": 93,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,94 +1,95 @@\n   private void initialize(final Configuration conf,\n       CommandLineOpts commandLineOpts) throws IOException {\n     final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n     infoBindAddress \u003d infoSocAddr.getHostName();\n     UserGroupInformation.setConfiguration(conf);\n     if (UserGroupInformation.isSecurityEnabled()) {\n       SecurityUtil.login(conf, DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n           DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n     }\n     // initiate Java VM metrics\n     JvmMetrics.create(\"SecondaryNameNode\",\n         conf.get(DFS_METRICS_SESSION_ID_KEY), DefaultMetricsSystem.instance());\n     \n     // Create connection to the namenode.\n     shouldRun \u003d true;\n     nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n \n     this.conf \u003d conf;\n-    this.namenode \u003d new NamenodeProtocolTranslatorPB(nameNodeAddr, conf,\n-        UserGroupInformation.getCurrentUser());\n+    this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n+        NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n+        true).getProxy();\n \n     // initialize checkpoint directories\n     fsName \u003d getInfoServer();\n     checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                   \"/tmp/hadoop/dfs/namesecondary\");\n     checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                   \"/tmp/hadoop/dfs/namesecondary\");    \n     checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n     checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n     \n     namesystem \u003d new FSNamesystem(conf, checkpointImage);\n \n     // Initialize other scheduling parameters from the configuration\n     checkpointConf \u003d new CheckpointConf(conf);\n     \n     // initialize the webserver for uploading files.\n     // Kerberized SSL servers must be run from the host principal...\n     UserGroupInformation httpUGI \u003d \n       UserGroupInformation.loginUserFromKeytabAndReturnUGI(\n           SecurityUtil.getServerPrincipal(conf\n               .get(DFS_SECONDARY_NAMENODE_KRB_HTTPS_USER_NAME_KEY),\n               infoBindAddress),\n           conf.get(DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY));\n     try {\n       infoServer \u003d httpUGI.doAs(new PrivilegedExceptionAction\u003cHttpServer\u003e() {\n         @Override\n         public HttpServer run() throws IOException, InterruptedException {\n           LOG.info(\"Starting web server as: \" +\n               UserGroupInformation.getCurrentUser().getUserName());\n \n           int tmpInfoPort \u003d infoSocAddr.getPort();\n           infoServer \u003d new HttpServer(\"secondary\", infoBindAddress, tmpInfoPort,\n               tmpInfoPort \u003d\u003d 0, conf, \n               new AccessControlList(conf.get(DFS_ADMIN, \" \")));\n           \n           if(UserGroupInformation.isSecurityEnabled()) {\n             System.setProperty(\"https.cipherSuites\", \n                 Krb5AndCertsSslSocketConnector.KRB5_CIPHER_SUITES.get(0));\n             InetSocketAddress secInfoSocAddr \u003d \n               NetUtils.createSocketAddr(infoBindAddress + \":\"+ conf.getInt(\n                 DFS_NAMENODE_SECONDARY_HTTPS_PORT_KEY,\n                 DFS_NAMENODE_SECONDARY_HTTPS_PORT_DEFAULT));\n             imagePort \u003d secInfoSocAddr.getPort();\n             infoServer.addSslListener(secInfoSocAddr, conf, false, true);\n           }\n           \n           infoServer.setAttribute(\"secondary.name.node\", SecondaryNameNode.this);\n           infoServer.setAttribute(\"name.system.image\", checkpointImage);\n           infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n           infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n               GetImageServlet.class, true);\n           infoServer.start();\n           return infoServer;\n         }\n       });\n     } catch (InterruptedException e) {\n       throw new RuntimeException(e);\n     } \n     \n     LOG.info(\"Web server init done\");\n \n     // The web-server port can be ephemeral... ensure we have the correct info\n     infoPort \u003d infoServer.getPort();\n     if (!UserGroupInformation.isSecurityEnabled()) {\n       imagePort \u003d infoPort;\n     }\n     \n     conf.set(DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, infoBindAddress + \":\" +infoPort); \n     LOG.info(\"Secondary Web-server up at: \" + infoBindAddress + \":\" +infoPort);\n     LOG.info(\"Secondary image servlet up at: \" + infoBindAddress + \":\" + imagePort);\n     LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \" +\n              \"(\" + checkpointConf.getPeriod()/60 + \" min)\");\n     LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void initialize(final Configuration conf,\n      CommandLineOpts commandLineOpts) throws IOException {\n    final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n    infoBindAddress \u003d infoSocAddr.getHostName();\n    UserGroupInformation.setConfiguration(conf);\n    if (UserGroupInformation.isSecurityEnabled()) {\n      SecurityUtil.login(conf, DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n          DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n    }\n    // initiate Java VM metrics\n    JvmMetrics.create(\"SecondaryNameNode\",\n        conf.get(DFS_METRICS_SESSION_ID_KEY), DefaultMetricsSystem.instance());\n    \n    // Create connection to the namenode.\n    shouldRun \u003d true;\n    nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n\n    this.conf \u003d conf;\n    this.namenode \u003d NameNodeProxies.createNonHAProxy(conf, nameNodeAddr, \n        NamenodeProtocol.class, UserGroupInformation.getCurrentUser(),\n        true).getProxy();\n\n    // initialize checkpoint directories\n    fsName \u003d getInfoServer();\n    checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                  \"/tmp/hadoop/dfs/namesecondary\");\n    checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                  \"/tmp/hadoop/dfs/namesecondary\");    \n    checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n    checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n    \n    namesystem \u003d new FSNamesystem(conf, checkpointImage);\n\n    // Initialize other scheduling parameters from the configuration\n    checkpointConf \u003d new CheckpointConf(conf);\n    \n    // initialize the webserver for uploading files.\n    // Kerberized SSL servers must be run from the host principal...\n    UserGroupInformation httpUGI \u003d \n      UserGroupInformation.loginUserFromKeytabAndReturnUGI(\n          SecurityUtil.getServerPrincipal(conf\n              .get(DFS_SECONDARY_NAMENODE_KRB_HTTPS_USER_NAME_KEY),\n              infoBindAddress),\n          conf.get(DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY));\n    try {\n      infoServer \u003d httpUGI.doAs(new PrivilegedExceptionAction\u003cHttpServer\u003e() {\n        @Override\n        public HttpServer run() throws IOException, InterruptedException {\n          LOG.info(\"Starting web server as: \" +\n              UserGroupInformation.getCurrentUser().getUserName());\n\n          int tmpInfoPort \u003d infoSocAddr.getPort();\n          infoServer \u003d new HttpServer(\"secondary\", infoBindAddress, tmpInfoPort,\n              tmpInfoPort \u003d\u003d 0, conf, \n              new AccessControlList(conf.get(DFS_ADMIN, \" \")));\n          \n          if(UserGroupInformation.isSecurityEnabled()) {\n            System.setProperty(\"https.cipherSuites\", \n                Krb5AndCertsSslSocketConnector.KRB5_CIPHER_SUITES.get(0));\n            InetSocketAddress secInfoSocAddr \u003d \n              NetUtils.createSocketAddr(infoBindAddress + \":\"+ conf.getInt(\n                DFS_NAMENODE_SECONDARY_HTTPS_PORT_KEY,\n                DFS_NAMENODE_SECONDARY_HTTPS_PORT_DEFAULT));\n            imagePort \u003d secInfoSocAddr.getPort();\n            infoServer.addSslListener(secInfoSocAddr, conf, false, true);\n          }\n          \n          infoServer.setAttribute(\"secondary.name.node\", SecondaryNameNode.this);\n          infoServer.setAttribute(\"name.system.image\", checkpointImage);\n          infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n          infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n              GetImageServlet.class, true);\n          infoServer.start();\n          return infoServer;\n        }\n      });\n    } catch (InterruptedException e) {\n      throw new RuntimeException(e);\n    } \n    \n    LOG.info(\"Web server init done\");\n\n    // The web-server port can be ephemeral... ensure we have the correct info\n    infoPort \u003d infoServer.getPort();\n    if (!UserGroupInformation.isSecurityEnabled()) {\n      imagePort \u003d infoPort;\n    }\n    \n    conf.set(DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, infoBindAddress + \":\" +infoPort); \n    LOG.info(\"Secondary Web-server up at: \" + infoBindAddress + \":\" +infoPort);\n    LOG.info(\"Secondary image servlet up at: \" + infoBindAddress + \":\" + imagePort);\n    LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \" +\n             \"(\" + checkpointConf.getPeriod()/60 + \" min)\");\n    LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
      "extendedDetails": {}
    },
    "3bd230af1199ad741518c2359618bb8fb93e6d2a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2950. Secondary NN HTTPS address should be listed as a NAMESERVICE_SPECIFIC_KEY. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1244635 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "15/02/12 10:27 AM",
      "commitName": "3bd230af1199ad741518c2359618bb8fb93e6d2a",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "23/01/12 10:05 PM",
      "commitNameOld": "5dfe62d845424e688c144fc10446ff6392e54ae4",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 22.52,
      "commitsBetweenForRepo": 176,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,101 +1,102 @@\n   private void initialize(final Configuration conf,\n       CommandLineOpts commandLineOpts) throws IOException {\n     final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n     infoBindAddress \u003d infoSocAddr.getHostName();\n     UserGroupInformation.setConfiguration(conf);\n     if (UserGroupInformation.isSecurityEnabled()) {\n       SecurityUtil.login(conf, DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n           DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n     }\n     // initiate Java VM metrics\n     JvmMetrics.create(\"SecondaryNameNode\",\n         conf.get(DFS_METRICS_SESSION_ID_KEY), DefaultMetricsSystem.instance());\n     \n     // Create connection to the namenode.\n     shouldRun \u003d true;\n     nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n \n     this.conf \u003d conf;\n     this.namenode \u003d new NamenodeProtocolTranslatorPB(nameNodeAddr, conf,\n         UserGroupInformation.getCurrentUser());\n \n     // initialize checkpoint directories\n     fsName \u003d getInfoServer();\n     checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                   \"/tmp/hadoop/dfs/namesecondary\");\n     checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                   \"/tmp/hadoop/dfs/namesecondary\");    \n     checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n     checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n     \n     namesystem \u003d new FSNamesystem(conf, checkpointImage);\n \n     // Initialize other scheduling parameters from the configuration\n     checkpointCheckPeriod \u003d conf.getLong(\n         DFS_NAMENODE_CHECKPOINT_CHECK_PERIOD_KEY,\n         DFS_NAMENODE_CHECKPOINT_CHECK_PERIOD_DEFAULT);\n         \n     checkpointPeriod \u003d conf.getLong(DFS_NAMENODE_CHECKPOINT_PERIOD_KEY, \n                                     DFS_NAMENODE_CHECKPOINT_PERIOD_DEFAULT);\n     checkpointTxnCount \u003d conf.getLong(DFS_NAMENODE_CHECKPOINT_TXNS_KEY, \n                                   DFS_NAMENODE_CHECKPOINT_TXNS_DEFAULT);\n     warnForDeprecatedConfigs(conf);\n \n     // initialize the webserver for uploading files.\n     // Kerberized SSL servers must be run from the host principal...\n     UserGroupInformation httpUGI \u003d \n       UserGroupInformation.loginUserFromKeytabAndReturnUGI(\n           SecurityUtil.getServerPrincipal(conf\n               .get(DFS_SECONDARY_NAMENODE_KRB_HTTPS_USER_NAME_KEY),\n               infoBindAddress),\n           conf.get(DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY));\n     try {\n       infoServer \u003d httpUGI.doAs(new PrivilegedExceptionAction\u003cHttpServer\u003e() {\n         @Override\n         public HttpServer run() throws IOException, InterruptedException {\n           LOG.info(\"Starting web server as: \" +\n               UserGroupInformation.getCurrentUser().getUserName());\n \n           int tmpInfoPort \u003d infoSocAddr.getPort();\n           infoServer \u003d new HttpServer(\"secondary\", infoBindAddress, tmpInfoPort,\n               tmpInfoPort \u003d\u003d 0, conf, \n               new AccessControlList(conf.get(DFS_ADMIN, \" \")));\n           \n           if(UserGroupInformation.isSecurityEnabled()) {\n             System.setProperty(\"https.cipherSuites\", \n                 Krb5AndCertsSslSocketConnector.KRB5_CIPHER_SUITES.get(0));\n             InetSocketAddress secInfoSocAddr \u003d \n               NetUtils.createSocketAddr(infoBindAddress + \":\"+ conf.getInt(\n-                \"dfs.secondary.https.port\", 443));\n+                DFS_NAMENODE_SECONDARY_HTTPS_PORT_KEY,\n+                DFS_NAMENODE_SECONDARY_HTTPS_PORT_DEFAULT));\n             imagePort \u003d secInfoSocAddr.getPort();\n             infoServer.addSslListener(secInfoSocAddr, conf, false, true);\n           }\n           \n           infoServer.setAttribute(\"secondary.name.node\", SecondaryNameNode.this);\n           infoServer.setAttribute(\"name.system.image\", checkpointImage);\n           infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n           infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n               GetImageServlet.class, true);\n           infoServer.start();\n           return infoServer;\n         }\n       });\n     } catch (InterruptedException e) {\n       throw new RuntimeException(e);\n     } \n     \n     LOG.info(\"Web server init done\");\n \n     // The web-server port can be ephemeral... ensure we have the correct info\n     infoPort \u003d infoServer.getPort();\n     if (!UserGroupInformation.isSecurityEnabled()) {\n       imagePort \u003d infoPort;\n     }\n     \n     conf.set(DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, infoBindAddress + \":\" +infoPort); \n     LOG.info(\"Secondary Web-server up at: \" + infoBindAddress + \":\" +infoPort);\n     LOG.info(\"Secondary image servlet up at: \" + infoBindAddress + \":\" + imagePort);\n     LOG.info(\"Checkpoint Period   :\" + checkpointPeriod + \" secs \" +\n              \"(\" + checkpointPeriod/60 + \" min)\");\n     LOG.info(\"Log Size Trigger    :\" + checkpointTxnCount + \" txns\");\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void initialize(final Configuration conf,\n      CommandLineOpts commandLineOpts) throws IOException {\n    final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n    infoBindAddress \u003d infoSocAddr.getHostName();\n    UserGroupInformation.setConfiguration(conf);\n    if (UserGroupInformation.isSecurityEnabled()) {\n      SecurityUtil.login(conf, DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n          DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n    }\n    // initiate Java VM metrics\n    JvmMetrics.create(\"SecondaryNameNode\",\n        conf.get(DFS_METRICS_SESSION_ID_KEY), DefaultMetricsSystem.instance());\n    \n    // Create connection to the namenode.\n    shouldRun \u003d true;\n    nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n\n    this.conf \u003d conf;\n    this.namenode \u003d new NamenodeProtocolTranslatorPB(nameNodeAddr, conf,\n        UserGroupInformation.getCurrentUser());\n\n    // initialize checkpoint directories\n    fsName \u003d getInfoServer();\n    checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                  \"/tmp/hadoop/dfs/namesecondary\");\n    checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                  \"/tmp/hadoop/dfs/namesecondary\");    \n    checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n    checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n    \n    namesystem \u003d new FSNamesystem(conf, checkpointImage);\n\n    // Initialize other scheduling parameters from the configuration\n    checkpointCheckPeriod \u003d conf.getLong(\n        DFS_NAMENODE_CHECKPOINT_CHECK_PERIOD_KEY,\n        DFS_NAMENODE_CHECKPOINT_CHECK_PERIOD_DEFAULT);\n        \n    checkpointPeriod \u003d conf.getLong(DFS_NAMENODE_CHECKPOINT_PERIOD_KEY, \n                                    DFS_NAMENODE_CHECKPOINT_PERIOD_DEFAULT);\n    checkpointTxnCount \u003d conf.getLong(DFS_NAMENODE_CHECKPOINT_TXNS_KEY, \n                                  DFS_NAMENODE_CHECKPOINT_TXNS_DEFAULT);\n    warnForDeprecatedConfigs(conf);\n\n    // initialize the webserver for uploading files.\n    // Kerberized SSL servers must be run from the host principal...\n    UserGroupInformation httpUGI \u003d \n      UserGroupInformation.loginUserFromKeytabAndReturnUGI(\n          SecurityUtil.getServerPrincipal(conf\n              .get(DFS_SECONDARY_NAMENODE_KRB_HTTPS_USER_NAME_KEY),\n              infoBindAddress),\n          conf.get(DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY));\n    try {\n      infoServer \u003d httpUGI.doAs(new PrivilegedExceptionAction\u003cHttpServer\u003e() {\n        @Override\n        public HttpServer run() throws IOException, InterruptedException {\n          LOG.info(\"Starting web server as: \" +\n              UserGroupInformation.getCurrentUser().getUserName());\n\n          int tmpInfoPort \u003d infoSocAddr.getPort();\n          infoServer \u003d new HttpServer(\"secondary\", infoBindAddress, tmpInfoPort,\n              tmpInfoPort \u003d\u003d 0, conf, \n              new AccessControlList(conf.get(DFS_ADMIN, \" \")));\n          \n          if(UserGroupInformation.isSecurityEnabled()) {\n            System.setProperty(\"https.cipherSuites\", \n                Krb5AndCertsSslSocketConnector.KRB5_CIPHER_SUITES.get(0));\n            InetSocketAddress secInfoSocAddr \u003d \n              NetUtils.createSocketAddr(infoBindAddress + \":\"+ conf.getInt(\n                DFS_NAMENODE_SECONDARY_HTTPS_PORT_KEY,\n                DFS_NAMENODE_SECONDARY_HTTPS_PORT_DEFAULT));\n            imagePort \u003d secInfoSocAddr.getPort();\n            infoServer.addSslListener(secInfoSocAddr, conf, false, true);\n          }\n          \n          infoServer.setAttribute(\"secondary.name.node\", SecondaryNameNode.this);\n          infoServer.setAttribute(\"name.system.image\", checkpointImage);\n          infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n          infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n              GetImageServlet.class, true);\n          infoServer.start();\n          return infoServer;\n        }\n      });\n    } catch (InterruptedException e) {\n      throw new RuntimeException(e);\n    } \n    \n    LOG.info(\"Web server init done\");\n\n    // The web-server port can be ephemeral... ensure we have the correct info\n    infoPort \u003d infoServer.getPort();\n    if (!UserGroupInformation.isSecurityEnabled()) {\n      imagePort \u003d infoPort;\n    }\n    \n    conf.set(DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, infoBindAddress + \":\" +infoPort); \n    LOG.info(\"Secondary Web-server up at: \" + infoBindAddress + \":\" +infoPort);\n    LOG.info(\"Secondary image servlet up at: \" + infoBindAddress + \":\" + imagePort);\n    LOG.info(\"Checkpoint Period   :\" + checkpointPeriod + \" secs \" +\n             \"(\" + checkpointPeriod/60 + \" min)\");\n    LOG.info(\"Log Size Trigger    :\" + checkpointTxnCount + \" txns\");\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
      "extendedDetails": {}
    },
    "8faf7e8fb6e4024b03ce5f938daba626f2f5357c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2739. SecondaryNameNode doesn\u0027t start up.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1229877 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/01/12 6:54 PM",
      "commitName": "8faf7e8fb6e4024b03ce5f938daba626f2f5357c",
      "commitAuthor": "Jitendra Nath Pandey",
      "commitDateOld": "13/12/11 10:07 AM",
      "commitNameOld": "f2f4e9341387199e04679ebc8de5e05c0fdbd437",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 28.37,
      "commitsBetweenForRepo": 127,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,103 +1,101 @@\n   private void initialize(final Configuration conf,\n       CommandLineOpts commandLineOpts) throws IOException {\n     final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n     infoBindAddress \u003d infoSocAddr.getHostName();\n     UserGroupInformation.setConfiguration(conf);\n     if (UserGroupInformation.isSecurityEnabled()) {\n       SecurityUtil.login(conf, DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n           DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n     }\n     // initiate Java VM metrics\n     JvmMetrics.create(\"SecondaryNameNode\",\n         conf.get(DFS_METRICS_SESSION_ID_KEY), DefaultMetricsSystem.instance());\n     \n     // Create connection to the namenode.\n     shouldRun \u003d true;\n     nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n \n     this.conf \u003d conf;\n-    NamenodeProtocolPB proxy \u003d \n-        RPC.waitForProxy(NamenodeProtocolPB.class,\n-            RPC.getProtocolVersion(NamenodeProtocolPB.class), nameNodeAddr, conf);\n-    this.namenode \u003d new NamenodeProtocolTranslatorPB(proxy);\n+    this.namenode \u003d new NamenodeProtocolTranslatorPB(nameNodeAddr, conf,\n+        UserGroupInformation.getCurrentUser());\n \n     // initialize checkpoint directories\n     fsName \u003d getInfoServer();\n     checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                   \"/tmp/hadoop/dfs/namesecondary\");\n     checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                   \"/tmp/hadoop/dfs/namesecondary\");    \n     checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n     checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n     \n     namesystem \u003d new FSNamesystem(conf, checkpointImage);\n \n     // Initialize other scheduling parameters from the configuration\n     checkpointCheckPeriod \u003d conf.getLong(\n         DFS_NAMENODE_CHECKPOINT_CHECK_PERIOD_KEY,\n         DFS_NAMENODE_CHECKPOINT_CHECK_PERIOD_DEFAULT);\n         \n     checkpointPeriod \u003d conf.getLong(DFS_NAMENODE_CHECKPOINT_PERIOD_KEY, \n                                     DFS_NAMENODE_CHECKPOINT_PERIOD_DEFAULT);\n     checkpointTxnCount \u003d conf.getLong(DFS_NAMENODE_CHECKPOINT_TXNS_KEY, \n                                   DFS_NAMENODE_CHECKPOINT_TXNS_DEFAULT);\n     warnForDeprecatedConfigs(conf);\n \n     // initialize the webserver for uploading files.\n     // Kerberized SSL servers must be run from the host principal...\n     UserGroupInformation httpUGI \u003d \n       UserGroupInformation.loginUserFromKeytabAndReturnUGI(\n           SecurityUtil.getServerPrincipal(conf\n               .get(DFS_SECONDARY_NAMENODE_KRB_HTTPS_USER_NAME_KEY),\n               infoBindAddress),\n           conf.get(DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY));\n     try {\n       infoServer \u003d httpUGI.doAs(new PrivilegedExceptionAction\u003cHttpServer\u003e() {\n         @Override\n         public HttpServer run() throws IOException, InterruptedException {\n           LOG.info(\"Starting web server as: \" +\n               UserGroupInformation.getCurrentUser().getUserName());\n \n           int tmpInfoPort \u003d infoSocAddr.getPort();\n           infoServer \u003d new HttpServer(\"secondary\", infoBindAddress, tmpInfoPort,\n               tmpInfoPort \u003d\u003d 0, conf, \n               new AccessControlList(conf.get(DFS_ADMIN, \" \")));\n           \n           if(UserGroupInformation.isSecurityEnabled()) {\n             System.setProperty(\"https.cipherSuites\", \n                 Krb5AndCertsSslSocketConnector.KRB5_CIPHER_SUITES.get(0));\n             InetSocketAddress secInfoSocAddr \u003d \n               NetUtils.createSocketAddr(infoBindAddress + \":\"+ conf.getInt(\n                 \"dfs.secondary.https.port\", 443));\n             imagePort \u003d secInfoSocAddr.getPort();\n             infoServer.addSslListener(secInfoSocAddr, conf, false, true);\n           }\n           \n           infoServer.setAttribute(\"secondary.name.node\", SecondaryNameNode.this);\n           infoServer.setAttribute(\"name.system.image\", checkpointImage);\n           infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n           infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n               GetImageServlet.class, true);\n           infoServer.start();\n           return infoServer;\n         }\n       });\n     } catch (InterruptedException e) {\n       throw new RuntimeException(e);\n     } \n     \n     LOG.info(\"Web server init done\");\n \n     // The web-server port can be ephemeral... ensure we have the correct info\n     infoPort \u003d infoServer.getPort();\n     if (!UserGroupInformation.isSecurityEnabled()) {\n       imagePort \u003d infoPort;\n     }\n     \n     conf.set(DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, infoBindAddress + \":\" +infoPort); \n     LOG.info(\"Secondary Web-server up at: \" + infoBindAddress + \":\" +infoPort);\n     LOG.info(\"Secondary image servlet up at: \" + infoBindAddress + \":\" + imagePort);\n     LOG.info(\"Checkpoint Period   :\" + checkpointPeriod + \" secs \" +\n              \"(\" + checkpointPeriod/60 + \" min)\");\n     LOG.info(\"Log Size Trigger    :\" + checkpointTxnCount + \" txns\");\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void initialize(final Configuration conf,\n      CommandLineOpts commandLineOpts) throws IOException {\n    final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n    infoBindAddress \u003d infoSocAddr.getHostName();\n    UserGroupInformation.setConfiguration(conf);\n    if (UserGroupInformation.isSecurityEnabled()) {\n      SecurityUtil.login(conf, DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n          DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n    }\n    // initiate Java VM metrics\n    JvmMetrics.create(\"SecondaryNameNode\",\n        conf.get(DFS_METRICS_SESSION_ID_KEY), DefaultMetricsSystem.instance());\n    \n    // Create connection to the namenode.\n    shouldRun \u003d true;\n    nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n\n    this.conf \u003d conf;\n    this.namenode \u003d new NamenodeProtocolTranslatorPB(nameNodeAddr, conf,\n        UserGroupInformation.getCurrentUser());\n\n    // initialize checkpoint directories\n    fsName \u003d getInfoServer();\n    checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                  \"/tmp/hadoop/dfs/namesecondary\");\n    checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                  \"/tmp/hadoop/dfs/namesecondary\");    \n    checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n    checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n    \n    namesystem \u003d new FSNamesystem(conf, checkpointImage);\n\n    // Initialize other scheduling parameters from the configuration\n    checkpointCheckPeriod \u003d conf.getLong(\n        DFS_NAMENODE_CHECKPOINT_CHECK_PERIOD_KEY,\n        DFS_NAMENODE_CHECKPOINT_CHECK_PERIOD_DEFAULT);\n        \n    checkpointPeriod \u003d conf.getLong(DFS_NAMENODE_CHECKPOINT_PERIOD_KEY, \n                                    DFS_NAMENODE_CHECKPOINT_PERIOD_DEFAULT);\n    checkpointTxnCount \u003d conf.getLong(DFS_NAMENODE_CHECKPOINT_TXNS_KEY, \n                                  DFS_NAMENODE_CHECKPOINT_TXNS_DEFAULT);\n    warnForDeprecatedConfigs(conf);\n\n    // initialize the webserver for uploading files.\n    // Kerberized SSL servers must be run from the host principal...\n    UserGroupInformation httpUGI \u003d \n      UserGroupInformation.loginUserFromKeytabAndReturnUGI(\n          SecurityUtil.getServerPrincipal(conf\n              .get(DFS_SECONDARY_NAMENODE_KRB_HTTPS_USER_NAME_KEY),\n              infoBindAddress),\n          conf.get(DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY));\n    try {\n      infoServer \u003d httpUGI.doAs(new PrivilegedExceptionAction\u003cHttpServer\u003e() {\n        @Override\n        public HttpServer run() throws IOException, InterruptedException {\n          LOG.info(\"Starting web server as: \" +\n              UserGroupInformation.getCurrentUser().getUserName());\n\n          int tmpInfoPort \u003d infoSocAddr.getPort();\n          infoServer \u003d new HttpServer(\"secondary\", infoBindAddress, tmpInfoPort,\n              tmpInfoPort \u003d\u003d 0, conf, \n              new AccessControlList(conf.get(DFS_ADMIN, \" \")));\n          \n          if(UserGroupInformation.isSecurityEnabled()) {\n            System.setProperty(\"https.cipherSuites\", \n                Krb5AndCertsSslSocketConnector.KRB5_CIPHER_SUITES.get(0));\n            InetSocketAddress secInfoSocAddr \u003d \n              NetUtils.createSocketAddr(infoBindAddress + \":\"+ conf.getInt(\n                \"dfs.secondary.https.port\", 443));\n            imagePort \u003d secInfoSocAddr.getPort();\n            infoServer.addSslListener(secInfoSocAddr, conf, false, true);\n          }\n          \n          infoServer.setAttribute(\"secondary.name.node\", SecondaryNameNode.this);\n          infoServer.setAttribute(\"name.system.image\", checkpointImage);\n          infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n          infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n              GetImageServlet.class, true);\n          infoServer.start();\n          return infoServer;\n        }\n      });\n    } catch (InterruptedException e) {\n      throw new RuntimeException(e);\n    } \n    \n    LOG.info(\"Web server init done\");\n\n    // The web-server port can be ephemeral... ensure we have the correct info\n    infoPort \u003d infoServer.getPort();\n    if (!UserGroupInformation.isSecurityEnabled()) {\n      imagePort \u003d infoPort;\n    }\n    \n    conf.set(DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, infoBindAddress + \":\" +infoPort); \n    LOG.info(\"Secondary Web-server up at: \" + infoBindAddress + \":\" +infoPort);\n    LOG.info(\"Secondary image servlet up at: \" + infoBindAddress + \":\" + imagePort);\n    LOG.info(\"Checkpoint Period   :\" + checkpointPeriod + \" secs \" +\n             \"(\" + checkpointPeriod/60 + \" min)\");\n    LOG.info(\"Log Size Trigger    :\" + checkpointTxnCount + \" txns\");\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
      "extendedDetails": {}
    },
    "5b8dcb20a2fad2e7e9dee56c451f68f9d865b5ae": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2291. Allow the StandbyNode to make checkpoints in an HA setup. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1227411 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/01/12 4:22 PM",
      "commitName": "5b8dcb20a2fad2e7e9dee56c451f68f9d865b5ae",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "30/12/11 5:53 PM",
      "commitNameOld": "737df8b67b972155b12ed615e23f3f1e8e4e9ca9",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 4.94,
      "commitsBetweenForRepo": 14,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,103 +1,95 @@\n   private void initialize(final Configuration conf,\n       CommandLineOpts commandLineOpts) throws IOException {\n     final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n     infoBindAddress \u003d infoSocAddr.getHostName();\n     UserGroupInformation.setConfiguration(conf);\n     if (UserGroupInformation.isSecurityEnabled()) {\n       SecurityUtil.login(conf, DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n           DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n     }\n     // initiate Java VM metrics\n     JvmMetrics.create(\"SecondaryNameNode\",\n         conf.get(DFS_METRICS_SESSION_ID_KEY), DefaultMetricsSystem.instance());\n     \n     // Create connection to the namenode.\n     shouldRun \u003d true;\n     nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n \n     this.conf \u003d conf;\n     NamenodeProtocolPB proxy \u003d \n         RPC.waitForProxy(NamenodeProtocolPB.class,\n             RPC.getProtocolVersion(NamenodeProtocolPB.class), nameNodeAddr, conf);\n     this.namenode \u003d new NamenodeProtocolTranslatorPB(proxy);\n \n     // initialize checkpoint directories\n     fsName \u003d getInfoServer();\n     checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                   \"/tmp/hadoop/dfs/namesecondary\");\n     checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                   \"/tmp/hadoop/dfs/namesecondary\");    \n     checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n     checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n     \n     namesystem \u003d new FSNamesystem(conf, checkpointImage);\n \n     // Initialize other scheduling parameters from the configuration\n-    checkpointCheckPeriod \u003d conf.getLong(\n-        DFS_NAMENODE_CHECKPOINT_CHECK_PERIOD_KEY,\n-        DFS_NAMENODE_CHECKPOINT_CHECK_PERIOD_DEFAULT);\n-        \n-    checkpointPeriod \u003d conf.getLong(DFS_NAMENODE_CHECKPOINT_PERIOD_KEY, \n-                                    DFS_NAMENODE_CHECKPOINT_PERIOD_DEFAULT);\n-    checkpointTxnCount \u003d conf.getLong(DFS_NAMENODE_CHECKPOINT_TXNS_KEY, \n-                                  DFS_NAMENODE_CHECKPOINT_TXNS_DEFAULT);\n-    warnForDeprecatedConfigs(conf);\n-\n+    checkpointConf \u003d new CheckpointConf(conf);\n+    \n     // initialize the webserver for uploading files.\n     // Kerberized SSL servers must be run from the host principal...\n     UserGroupInformation httpUGI \u003d \n       UserGroupInformation.loginUserFromKeytabAndReturnUGI(\n           SecurityUtil.getServerPrincipal(conf\n               .get(DFS_SECONDARY_NAMENODE_KRB_HTTPS_USER_NAME_KEY),\n               infoBindAddress),\n           conf.get(DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY));\n     try {\n       infoServer \u003d httpUGI.doAs(new PrivilegedExceptionAction\u003cHttpServer\u003e() {\n         @Override\n         public HttpServer run() throws IOException, InterruptedException {\n           LOG.info(\"Starting web server as: \" +\n               UserGroupInformation.getCurrentUser().getUserName());\n \n           int tmpInfoPort \u003d infoSocAddr.getPort();\n           infoServer \u003d new HttpServer(\"secondary\", infoBindAddress, tmpInfoPort,\n               tmpInfoPort \u003d\u003d 0, conf, \n               new AccessControlList(conf.get(DFS_ADMIN, \" \")));\n           \n           if(UserGroupInformation.isSecurityEnabled()) {\n             System.setProperty(\"https.cipherSuites\", \n                 Krb5AndCertsSslSocketConnector.KRB5_CIPHER_SUITES.get(0));\n             InetSocketAddress secInfoSocAddr \u003d \n               NetUtils.createSocketAddr(infoBindAddress + \":\"+ conf.getInt(\n                 \"dfs.secondary.https.port\", 443));\n             imagePort \u003d secInfoSocAddr.getPort();\n             infoServer.addSslListener(secInfoSocAddr, conf, false, true);\n           }\n           \n           infoServer.setAttribute(\"secondary.name.node\", SecondaryNameNode.this);\n           infoServer.setAttribute(\"name.system.image\", checkpointImage);\n           infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n           infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n               GetImageServlet.class, true);\n           infoServer.start();\n           return infoServer;\n         }\n       });\n     } catch (InterruptedException e) {\n       throw new RuntimeException(e);\n     } \n     \n     LOG.info(\"Web server init done\");\n \n     // The web-server port can be ephemeral... ensure we have the correct info\n     infoPort \u003d infoServer.getPort();\n     if (!UserGroupInformation.isSecurityEnabled()) {\n       imagePort \u003d infoPort;\n     }\n     \n     conf.set(DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, infoBindAddress + \":\" +infoPort); \n     LOG.info(\"Secondary Web-server up at: \" + infoBindAddress + \":\" +infoPort);\n     LOG.info(\"Secondary image servlet up at: \" + infoBindAddress + \":\" + imagePort);\n-    LOG.info(\"Checkpoint Period   :\" + checkpointPeriod + \" secs \" +\n-             \"(\" + checkpointPeriod/60 + \" min)\");\n-    LOG.info(\"Log Size Trigger    :\" + checkpointTxnCount + \" txns\");\n+    LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \" +\n+             \"(\" + checkpointConf.getPeriod()/60 + \" min)\");\n+    LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void initialize(final Configuration conf,\n      CommandLineOpts commandLineOpts) throws IOException {\n    final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n    infoBindAddress \u003d infoSocAddr.getHostName();\n    UserGroupInformation.setConfiguration(conf);\n    if (UserGroupInformation.isSecurityEnabled()) {\n      SecurityUtil.login(conf, DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n          DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n    }\n    // initiate Java VM metrics\n    JvmMetrics.create(\"SecondaryNameNode\",\n        conf.get(DFS_METRICS_SESSION_ID_KEY), DefaultMetricsSystem.instance());\n    \n    // Create connection to the namenode.\n    shouldRun \u003d true;\n    nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n\n    this.conf \u003d conf;\n    NamenodeProtocolPB proxy \u003d \n        RPC.waitForProxy(NamenodeProtocolPB.class,\n            RPC.getProtocolVersion(NamenodeProtocolPB.class), nameNodeAddr, conf);\n    this.namenode \u003d new NamenodeProtocolTranslatorPB(proxy);\n\n    // initialize checkpoint directories\n    fsName \u003d getInfoServer();\n    checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                  \"/tmp/hadoop/dfs/namesecondary\");\n    checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                  \"/tmp/hadoop/dfs/namesecondary\");    \n    checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n    checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n    \n    namesystem \u003d new FSNamesystem(conf, checkpointImage);\n\n    // Initialize other scheduling parameters from the configuration\n    checkpointConf \u003d new CheckpointConf(conf);\n    \n    // initialize the webserver for uploading files.\n    // Kerberized SSL servers must be run from the host principal...\n    UserGroupInformation httpUGI \u003d \n      UserGroupInformation.loginUserFromKeytabAndReturnUGI(\n          SecurityUtil.getServerPrincipal(conf\n              .get(DFS_SECONDARY_NAMENODE_KRB_HTTPS_USER_NAME_KEY),\n              infoBindAddress),\n          conf.get(DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY));\n    try {\n      infoServer \u003d httpUGI.doAs(new PrivilegedExceptionAction\u003cHttpServer\u003e() {\n        @Override\n        public HttpServer run() throws IOException, InterruptedException {\n          LOG.info(\"Starting web server as: \" +\n              UserGroupInformation.getCurrentUser().getUserName());\n\n          int tmpInfoPort \u003d infoSocAddr.getPort();\n          infoServer \u003d new HttpServer(\"secondary\", infoBindAddress, tmpInfoPort,\n              tmpInfoPort \u003d\u003d 0, conf, \n              new AccessControlList(conf.get(DFS_ADMIN, \" \")));\n          \n          if(UserGroupInformation.isSecurityEnabled()) {\n            System.setProperty(\"https.cipherSuites\", \n                Krb5AndCertsSslSocketConnector.KRB5_CIPHER_SUITES.get(0));\n            InetSocketAddress secInfoSocAddr \u003d \n              NetUtils.createSocketAddr(infoBindAddress + \":\"+ conf.getInt(\n                \"dfs.secondary.https.port\", 443));\n            imagePort \u003d secInfoSocAddr.getPort();\n            infoServer.addSslListener(secInfoSocAddr, conf, false, true);\n          }\n          \n          infoServer.setAttribute(\"secondary.name.node\", SecondaryNameNode.this);\n          infoServer.setAttribute(\"name.system.image\", checkpointImage);\n          infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n          infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n              GetImageServlet.class, true);\n          infoServer.start();\n          return infoServer;\n        }\n      });\n    } catch (InterruptedException e) {\n      throw new RuntimeException(e);\n    } \n    \n    LOG.info(\"Web server init done\");\n\n    // The web-server port can be ephemeral... ensure we have the correct info\n    infoPort \u003d infoServer.getPort();\n    if (!UserGroupInformation.isSecurityEnabled()) {\n      imagePort \u003d infoPort;\n    }\n    \n    conf.set(DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, infoBindAddress + \":\" +infoPort); \n    LOG.info(\"Secondary Web-server up at: \" + infoBindAddress + \":\" +infoPort);\n    LOG.info(\"Secondary image servlet up at: \" + infoBindAddress + \":\" + imagePort);\n    LOG.info(\"Checkpoint Period   :\" + checkpointConf.getPeriod() + \" secs \" +\n             \"(\" + checkpointConf.getPeriod()/60 + \" min)\");\n    LOG.info(\"Log Size Trigger    :\" + checkpointConf.getTxnCount() + \" txns\");\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
      "extendedDetails": {}
    },
    "2740112bb64e1cc8132a1dc450d9e461c2e4729e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2647. Used protobuf based RPC for InterDatanodeProtocol, ClientDatanodeProtocol, JournalProtocol, NamenodeProtocol. Contributed by Suresh Srinivas.\n\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1213040 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/12/11 10:53 AM",
      "commitName": "2740112bb64e1cc8132a1dc450d9e461c2e4729e",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "28/09/11 3:58 PM",
      "commitNameOld": "e9dd78d9fede044101627786d991bec3265205a4",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 73.83,
      "commitsBetweenForRepo": 503,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,102 +1,103 @@\n   private void initialize(final Configuration conf,\n       CommandLineOpts commandLineOpts) throws IOException {\n     final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n     infoBindAddress \u003d infoSocAddr.getHostName();\n     UserGroupInformation.setConfiguration(conf);\n     if (UserGroupInformation.isSecurityEnabled()) {\n       SecurityUtil.login(conf, DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n           DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n     }\n     // initiate Java VM metrics\n     JvmMetrics.create(\"SecondaryNameNode\",\n         conf.get(DFS_METRICS_SESSION_ID_KEY), DefaultMetricsSystem.instance());\n     \n     // Create connection to the namenode.\n     shouldRun \u003d true;\n     nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n \n     this.conf \u003d conf;\n-    this.namenode \u003d\n-        (NamenodeProtocol) RPC.waitForProxy(NamenodeProtocol.class,\n-            NamenodeProtocol.versionID, nameNodeAddr, conf);\n+    NamenodeProtocolPB proxy \u003d \n+        RPC.waitForProxy(NamenodeProtocolPB.class,\n+            RPC.getProtocolVersion(NamenodeProtocolPB.class), nameNodeAddr, conf);\n+    this.namenode \u003d new NamenodeProtocolTranslatorPB(proxy);\n \n     // initialize checkpoint directories\n     fsName \u003d getInfoServer();\n     checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                   \"/tmp/hadoop/dfs/namesecondary\");\n     checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                   \"/tmp/hadoop/dfs/namesecondary\");    \n     checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n     checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n     \n     namesystem \u003d new FSNamesystem(conf, checkpointImage);\n \n     // Initialize other scheduling parameters from the configuration\n     checkpointCheckPeriod \u003d conf.getLong(\n         DFS_NAMENODE_CHECKPOINT_CHECK_PERIOD_KEY,\n         DFS_NAMENODE_CHECKPOINT_CHECK_PERIOD_DEFAULT);\n         \n     checkpointPeriod \u003d conf.getLong(DFS_NAMENODE_CHECKPOINT_PERIOD_KEY, \n                                     DFS_NAMENODE_CHECKPOINT_PERIOD_DEFAULT);\n     checkpointTxnCount \u003d conf.getLong(DFS_NAMENODE_CHECKPOINT_TXNS_KEY, \n                                   DFS_NAMENODE_CHECKPOINT_TXNS_DEFAULT);\n     warnForDeprecatedConfigs(conf);\n \n     // initialize the webserver for uploading files.\n     // Kerberized SSL servers must be run from the host principal...\n     UserGroupInformation httpUGI \u003d \n       UserGroupInformation.loginUserFromKeytabAndReturnUGI(\n           SecurityUtil.getServerPrincipal(conf\n               .get(DFS_SECONDARY_NAMENODE_KRB_HTTPS_USER_NAME_KEY),\n               infoBindAddress),\n           conf.get(DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY));\n     try {\n       infoServer \u003d httpUGI.doAs(new PrivilegedExceptionAction\u003cHttpServer\u003e() {\n         @Override\n         public HttpServer run() throws IOException, InterruptedException {\n           LOG.info(\"Starting web server as: \" +\n               UserGroupInformation.getCurrentUser().getUserName());\n \n           int tmpInfoPort \u003d infoSocAddr.getPort();\n           infoServer \u003d new HttpServer(\"secondary\", infoBindAddress, tmpInfoPort,\n               tmpInfoPort \u003d\u003d 0, conf, \n               new AccessControlList(conf.get(DFS_ADMIN, \" \")));\n           \n           if(UserGroupInformation.isSecurityEnabled()) {\n             System.setProperty(\"https.cipherSuites\", \n                 Krb5AndCertsSslSocketConnector.KRB5_CIPHER_SUITES.get(0));\n             InetSocketAddress secInfoSocAddr \u003d \n               NetUtils.createSocketAddr(infoBindAddress + \":\"+ conf.getInt(\n                 \"dfs.secondary.https.port\", 443));\n             imagePort \u003d secInfoSocAddr.getPort();\n             infoServer.addSslListener(secInfoSocAddr, conf, false, true);\n           }\n           \n           infoServer.setAttribute(\"secondary.name.node\", SecondaryNameNode.this);\n           infoServer.setAttribute(\"name.system.image\", checkpointImage);\n           infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n           infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n               GetImageServlet.class, true);\n           infoServer.start();\n           return infoServer;\n         }\n       });\n     } catch (InterruptedException e) {\n       throw new RuntimeException(e);\n     } \n     \n     LOG.info(\"Web server init done\");\n \n     // The web-server port can be ephemeral... ensure we have the correct info\n     infoPort \u003d infoServer.getPort();\n     if (!UserGroupInformation.isSecurityEnabled()) {\n       imagePort \u003d infoPort;\n     }\n     \n     conf.set(DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, infoBindAddress + \":\" +infoPort); \n     LOG.info(\"Secondary Web-server up at: \" + infoBindAddress + \":\" +infoPort);\n     LOG.info(\"Secondary image servlet up at: \" + infoBindAddress + \":\" + imagePort);\n     LOG.info(\"Checkpoint Period   :\" + checkpointPeriod + \" secs \" +\n              \"(\" + checkpointPeriod/60 + \" min)\");\n     LOG.info(\"Log Size Trigger    :\" + checkpointTxnCount + \" txns\");\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void initialize(final Configuration conf,\n      CommandLineOpts commandLineOpts) throws IOException {\n    final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n    infoBindAddress \u003d infoSocAddr.getHostName();\n    UserGroupInformation.setConfiguration(conf);\n    if (UserGroupInformation.isSecurityEnabled()) {\n      SecurityUtil.login(conf, DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n          DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n    }\n    // initiate Java VM metrics\n    JvmMetrics.create(\"SecondaryNameNode\",\n        conf.get(DFS_METRICS_SESSION_ID_KEY), DefaultMetricsSystem.instance());\n    \n    // Create connection to the namenode.\n    shouldRun \u003d true;\n    nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n\n    this.conf \u003d conf;\n    NamenodeProtocolPB proxy \u003d \n        RPC.waitForProxy(NamenodeProtocolPB.class,\n            RPC.getProtocolVersion(NamenodeProtocolPB.class), nameNodeAddr, conf);\n    this.namenode \u003d new NamenodeProtocolTranslatorPB(proxy);\n\n    // initialize checkpoint directories\n    fsName \u003d getInfoServer();\n    checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                  \"/tmp/hadoop/dfs/namesecondary\");\n    checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                  \"/tmp/hadoop/dfs/namesecondary\");    \n    checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n    checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n    \n    namesystem \u003d new FSNamesystem(conf, checkpointImage);\n\n    // Initialize other scheduling parameters from the configuration\n    checkpointCheckPeriod \u003d conf.getLong(\n        DFS_NAMENODE_CHECKPOINT_CHECK_PERIOD_KEY,\n        DFS_NAMENODE_CHECKPOINT_CHECK_PERIOD_DEFAULT);\n        \n    checkpointPeriod \u003d conf.getLong(DFS_NAMENODE_CHECKPOINT_PERIOD_KEY, \n                                    DFS_NAMENODE_CHECKPOINT_PERIOD_DEFAULT);\n    checkpointTxnCount \u003d conf.getLong(DFS_NAMENODE_CHECKPOINT_TXNS_KEY, \n                                  DFS_NAMENODE_CHECKPOINT_TXNS_DEFAULT);\n    warnForDeprecatedConfigs(conf);\n\n    // initialize the webserver for uploading files.\n    // Kerberized SSL servers must be run from the host principal...\n    UserGroupInformation httpUGI \u003d \n      UserGroupInformation.loginUserFromKeytabAndReturnUGI(\n          SecurityUtil.getServerPrincipal(conf\n              .get(DFS_SECONDARY_NAMENODE_KRB_HTTPS_USER_NAME_KEY),\n              infoBindAddress),\n          conf.get(DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY));\n    try {\n      infoServer \u003d httpUGI.doAs(new PrivilegedExceptionAction\u003cHttpServer\u003e() {\n        @Override\n        public HttpServer run() throws IOException, InterruptedException {\n          LOG.info(\"Starting web server as: \" +\n              UserGroupInformation.getCurrentUser().getUserName());\n\n          int tmpInfoPort \u003d infoSocAddr.getPort();\n          infoServer \u003d new HttpServer(\"secondary\", infoBindAddress, tmpInfoPort,\n              tmpInfoPort \u003d\u003d 0, conf, \n              new AccessControlList(conf.get(DFS_ADMIN, \" \")));\n          \n          if(UserGroupInformation.isSecurityEnabled()) {\n            System.setProperty(\"https.cipherSuites\", \n                Krb5AndCertsSslSocketConnector.KRB5_CIPHER_SUITES.get(0));\n            InetSocketAddress secInfoSocAddr \u003d \n              NetUtils.createSocketAddr(infoBindAddress + \":\"+ conf.getInt(\n                \"dfs.secondary.https.port\", 443));\n            imagePort \u003d secInfoSocAddr.getPort();\n            infoServer.addSslListener(secInfoSocAddr, conf, false, true);\n          }\n          \n          infoServer.setAttribute(\"secondary.name.node\", SecondaryNameNode.this);\n          infoServer.setAttribute(\"name.system.image\", checkpointImage);\n          infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n          infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n              GetImageServlet.class, true);\n          infoServer.start();\n          return infoServer;\n        }\n      });\n    } catch (InterruptedException e) {\n      throw new RuntimeException(e);\n    } \n    \n    LOG.info(\"Web server init done\");\n\n    // The web-server port can be ephemeral... ensure we have the correct info\n    infoPort \u003d infoServer.getPort();\n    if (!UserGroupInformation.isSecurityEnabled()) {\n      imagePort \u003d infoPort;\n    }\n    \n    conf.set(DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, infoBindAddress + \":\" +infoPort); \n    LOG.info(\"Secondary Web-server up at: \" + infoBindAddress + \":\" +infoPort);\n    LOG.info(\"Secondary image servlet up at: \" + infoBindAddress + \":\" + imagePort);\n    LOG.info(\"Checkpoint Period   :\" + checkpointPeriod + \" secs \" +\n             \"(\" + checkpointPeriod/60 + \" min)\");\n    LOG.info(\"Log Size Trigger    :\" + checkpointTxnCount + \" txns\");\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
      "extendedDetails": {}
    },
    "06e84a1bca19bd01568a3095e33944d4d6387fd3": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2223. Untangle depencencies between NN components. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1166466 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/09/11 4:23 PM",
      "commitName": "06e84a1bca19bd01568a3095e33944d4d6387fd3",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "04/09/11 12:30 PM",
      "commitNameOld": "8ae98a9d1ca4725e28783370517cb3a3ecda7324",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 3.16,
      "commitsBetweenForRepo": 22,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,100 +1,102 @@\n   private void initialize(final Configuration conf,\n       CommandLineOpts commandLineOpts) throws IOException {\n     final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n     infoBindAddress \u003d infoSocAddr.getHostName();\n     UserGroupInformation.setConfiguration(conf);\n     if (UserGroupInformation.isSecurityEnabled()) {\n       SecurityUtil.login(conf, DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n           DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n     }\n     // initiate Java VM metrics\n     JvmMetrics.create(\"SecondaryNameNode\",\n         conf.get(DFS_METRICS_SESSION_ID_KEY), DefaultMetricsSystem.instance());\n     \n     // Create connection to the namenode.\n     shouldRun \u003d true;\n     nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n \n     this.conf \u003d conf;\n     this.namenode \u003d\n         (NamenodeProtocol) RPC.waitForProxy(NamenodeProtocol.class,\n             NamenodeProtocol.versionID, nameNodeAddr, conf);\n \n     // initialize checkpoint directories\n     fsName \u003d getInfoServer();\n     checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                   \"/tmp/hadoop/dfs/namesecondary\");\n     checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                   \"/tmp/hadoop/dfs/namesecondary\");    \n     checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n     checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n+    \n+    namesystem \u003d new FSNamesystem(conf, checkpointImage);\n \n     // Initialize other scheduling parameters from the configuration\n     checkpointCheckPeriod \u003d conf.getLong(\n         DFS_NAMENODE_CHECKPOINT_CHECK_PERIOD_KEY,\n         DFS_NAMENODE_CHECKPOINT_CHECK_PERIOD_DEFAULT);\n         \n     checkpointPeriod \u003d conf.getLong(DFS_NAMENODE_CHECKPOINT_PERIOD_KEY, \n                                     DFS_NAMENODE_CHECKPOINT_PERIOD_DEFAULT);\n     checkpointTxnCount \u003d conf.getLong(DFS_NAMENODE_CHECKPOINT_TXNS_KEY, \n                                   DFS_NAMENODE_CHECKPOINT_TXNS_DEFAULT);\n     warnForDeprecatedConfigs(conf);\n \n     // initialize the webserver for uploading files.\n     // Kerberized SSL servers must be run from the host principal...\n     UserGroupInformation httpUGI \u003d \n       UserGroupInformation.loginUserFromKeytabAndReturnUGI(\n           SecurityUtil.getServerPrincipal(conf\n               .get(DFS_SECONDARY_NAMENODE_KRB_HTTPS_USER_NAME_KEY),\n               infoBindAddress),\n           conf.get(DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY));\n     try {\n       infoServer \u003d httpUGI.doAs(new PrivilegedExceptionAction\u003cHttpServer\u003e() {\n         @Override\n         public HttpServer run() throws IOException, InterruptedException {\n           LOG.info(\"Starting web server as: \" +\n               UserGroupInformation.getCurrentUser().getUserName());\n \n           int tmpInfoPort \u003d infoSocAddr.getPort();\n           infoServer \u003d new HttpServer(\"secondary\", infoBindAddress, tmpInfoPort,\n               tmpInfoPort \u003d\u003d 0, conf, \n               new AccessControlList(conf.get(DFS_ADMIN, \" \")));\n           \n           if(UserGroupInformation.isSecurityEnabled()) {\n             System.setProperty(\"https.cipherSuites\", \n                 Krb5AndCertsSslSocketConnector.KRB5_CIPHER_SUITES.get(0));\n             InetSocketAddress secInfoSocAddr \u003d \n               NetUtils.createSocketAddr(infoBindAddress + \":\"+ conf.getInt(\n                 \"dfs.secondary.https.port\", 443));\n             imagePort \u003d secInfoSocAddr.getPort();\n             infoServer.addSslListener(secInfoSocAddr, conf, false, true);\n           }\n           \n           infoServer.setAttribute(\"secondary.name.node\", SecondaryNameNode.this);\n           infoServer.setAttribute(\"name.system.image\", checkpointImage);\n           infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n           infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n               GetImageServlet.class, true);\n           infoServer.start();\n           return infoServer;\n         }\n       });\n     } catch (InterruptedException e) {\n       throw new RuntimeException(e);\n     } \n     \n     LOG.info(\"Web server init done\");\n \n     // The web-server port can be ephemeral... ensure we have the correct info\n     infoPort \u003d infoServer.getPort();\n     if (!UserGroupInformation.isSecurityEnabled()) {\n       imagePort \u003d infoPort;\n     }\n     \n     conf.set(DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, infoBindAddress + \":\" +infoPort); \n     LOG.info(\"Secondary Web-server up at: \" + infoBindAddress + \":\" +infoPort);\n     LOG.info(\"Secondary image servlet up at: \" + infoBindAddress + \":\" + imagePort);\n     LOG.info(\"Checkpoint Period   :\" + checkpointPeriod + \" secs \" +\n              \"(\" + checkpointPeriod/60 + \" min)\");\n     LOG.info(\"Log Size Trigger    :\" + checkpointTxnCount + \" txns\");\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void initialize(final Configuration conf,\n      CommandLineOpts commandLineOpts) throws IOException {\n    final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n    infoBindAddress \u003d infoSocAddr.getHostName();\n    UserGroupInformation.setConfiguration(conf);\n    if (UserGroupInformation.isSecurityEnabled()) {\n      SecurityUtil.login(conf, DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n          DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n    }\n    // initiate Java VM metrics\n    JvmMetrics.create(\"SecondaryNameNode\",\n        conf.get(DFS_METRICS_SESSION_ID_KEY), DefaultMetricsSystem.instance());\n    \n    // Create connection to the namenode.\n    shouldRun \u003d true;\n    nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n\n    this.conf \u003d conf;\n    this.namenode \u003d\n        (NamenodeProtocol) RPC.waitForProxy(NamenodeProtocol.class,\n            NamenodeProtocol.versionID, nameNodeAddr, conf);\n\n    // initialize checkpoint directories\n    fsName \u003d getInfoServer();\n    checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                  \"/tmp/hadoop/dfs/namesecondary\");\n    checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                  \"/tmp/hadoop/dfs/namesecondary\");    \n    checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n    checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n    \n    namesystem \u003d new FSNamesystem(conf, checkpointImage);\n\n    // Initialize other scheduling parameters from the configuration\n    checkpointCheckPeriod \u003d conf.getLong(\n        DFS_NAMENODE_CHECKPOINT_CHECK_PERIOD_KEY,\n        DFS_NAMENODE_CHECKPOINT_CHECK_PERIOD_DEFAULT);\n        \n    checkpointPeriod \u003d conf.getLong(DFS_NAMENODE_CHECKPOINT_PERIOD_KEY, \n                                    DFS_NAMENODE_CHECKPOINT_PERIOD_DEFAULT);\n    checkpointTxnCount \u003d conf.getLong(DFS_NAMENODE_CHECKPOINT_TXNS_KEY, \n                                  DFS_NAMENODE_CHECKPOINT_TXNS_DEFAULT);\n    warnForDeprecatedConfigs(conf);\n\n    // initialize the webserver for uploading files.\n    // Kerberized SSL servers must be run from the host principal...\n    UserGroupInformation httpUGI \u003d \n      UserGroupInformation.loginUserFromKeytabAndReturnUGI(\n          SecurityUtil.getServerPrincipal(conf\n              .get(DFS_SECONDARY_NAMENODE_KRB_HTTPS_USER_NAME_KEY),\n              infoBindAddress),\n          conf.get(DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY));\n    try {\n      infoServer \u003d httpUGI.doAs(new PrivilegedExceptionAction\u003cHttpServer\u003e() {\n        @Override\n        public HttpServer run() throws IOException, InterruptedException {\n          LOG.info(\"Starting web server as: \" +\n              UserGroupInformation.getCurrentUser().getUserName());\n\n          int tmpInfoPort \u003d infoSocAddr.getPort();\n          infoServer \u003d new HttpServer(\"secondary\", infoBindAddress, tmpInfoPort,\n              tmpInfoPort \u003d\u003d 0, conf, \n              new AccessControlList(conf.get(DFS_ADMIN, \" \")));\n          \n          if(UserGroupInformation.isSecurityEnabled()) {\n            System.setProperty(\"https.cipherSuites\", \n                Krb5AndCertsSslSocketConnector.KRB5_CIPHER_SUITES.get(0));\n            InetSocketAddress secInfoSocAddr \u003d \n              NetUtils.createSocketAddr(infoBindAddress + \":\"+ conf.getInt(\n                \"dfs.secondary.https.port\", 443));\n            imagePort \u003d secInfoSocAddr.getPort();\n            infoServer.addSslListener(secInfoSocAddr, conf, false, true);\n          }\n          \n          infoServer.setAttribute(\"secondary.name.node\", SecondaryNameNode.this);\n          infoServer.setAttribute(\"name.system.image\", checkpointImage);\n          infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n          infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n              GetImageServlet.class, true);\n          infoServer.start();\n          return infoServer;\n        }\n      });\n    } catch (InterruptedException e) {\n      throw new RuntimeException(e);\n    } \n    \n    LOG.info(\"Web server init done\");\n\n    // The web-server port can be ephemeral... ensure we have the correct info\n    infoPort \u003d infoServer.getPort();\n    if (!UserGroupInformation.isSecurityEnabled()) {\n      imagePort \u003d infoPort;\n    }\n    \n    conf.set(DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, infoBindAddress + \":\" +infoPort); \n    LOG.info(\"Secondary Web-server up at: \" + infoBindAddress + \":\" +infoPort);\n    LOG.info(\"Secondary image servlet up at: \" + infoBindAddress + \":\" + imagePort);\n    LOG.info(\"Checkpoint Period   :\" + checkpointPeriod + \" secs \" +\n             \"(\" + checkpointPeriod/60 + \" min)\");\n    LOG.info(\"Log Size Trigger    :\" + checkpointTxnCount + \" txns\");\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private void initialize(final Configuration conf,\n      CommandLineOpts commandLineOpts) throws IOException {\n    final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n    infoBindAddress \u003d infoSocAddr.getHostName();\n    UserGroupInformation.setConfiguration(conf);\n    if (UserGroupInformation.isSecurityEnabled()) {\n      SecurityUtil.login(conf, DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n          DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n    }\n    // initiate Java VM metrics\n    JvmMetrics.create(\"SecondaryNameNode\",\n        conf.get(DFS_METRICS_SESSION_ID_KEY), DefaultMetricsSystem.instance());\n    \n    // Create connection to the namenode.\n    shouldRun \u003d true;\n    nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n\n    this.conf \u003d conf;\n    this.namenode \u003d\n        (NamenodeProtocol) RPC.waitForProxy(NamenodeProtocol.class,\n            NamenodeProtocol.versionID, nameNodeAddr, conf);\n\n    // initialize checkpoint directories\n    fsName \u003d getInfoServer();\n    checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                  \"/tmp/hadoop/dfs/namesecondary\");\n    checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                  \"/tmp/hadoop/dfs/namesecondary\");    \n    checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n    checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n\n    // Initialize other scheduling parameters from the configuration\n    checkpointCheckPeriod \u003d conf.getLong(\n        DFS_NAMENODE_CHECKPOINT_CHECK_PERIOD_KEY,\n        DFS_NAMENODE_CHECKPOINT_CHECK_PERIOD_DEFAULT);\n        \n    checkpointPeriod \u003d conf.getLong(DFS_NAMENODE_CHECKPOINT_PERIOD_KEY, \n                                    DFS_NAMENODE_CHECKPOINT_PERIOD_DEFAULT);\n    checkpointTxnCount \u003d conf.getLong(DFS_NAMENODE_CHECKPOINT_TXNS_KEY, \n                                  DFS_NAMENODE_CHECKPOINT_TXNS_DEFAULT);\n    warnForDeprecatedConfigs(conf);\n\n    // initialize the webserver for uploading files.\n    // Kerberized SSL servers must be run from the host principal...\n    UserGroupInformation httpUGI \u003d \n      UserGroupInformation.loginUserFromKeytabAndReturnUGI(\n          SecurityUtil.getServerPrincipal(conf\n              .get(DFS_SECONDARY_NAMENODE_KRB_HTTPS_USER_NAME_KEY),\n              infoBindAddress),\n          conf.get(DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY));\n    try {\n      infoServer \u003d httpUGI.doAs(new PrivilegedExceptionAction\u003cHttpServer\u003e() {\n        @Override\n        public HttpServer run() throws IOException, InterruptedException {\n          LOG.info(\"Starting web server as: \" +\n              UserGroupInformation.getCurrentUser().getUserName());\n\n          int tmpInfoPort \u003d infoSocAddr.getPort();\n          infoServer \u003d new HttpServer(\"secondary\", infoBindAddress, tmpInfoPort,\n              tmpInfoPort \u003d\u003d 0, conf, \n              new AccessControlList(conf.get(DFS_ADMIN, \" \")));\n          \n          if(UserGroupInformation.isSecurityEnabled()) {\n            System.setProperty(\"https.cipherSuites\", \n                Krb5AndCertsSslSocketConnector.KRB5_CIPHER_SUITES.get(0));\n            InetSocketAddress secInfoSocAddr \u003d \n              NetUtils.createSocketAddr(infoBindAddress + \":\"+ conf.getInt(\n                \"dfs.secondary.https.port\", 443));\n            imagePort \u003d secInfoSocAddr.getPort();\n            infoServer.addSslListener(secInfoSocAddr, conf, false, true);\n          }\n          \n          infoServer.setAttribute(\"secondary.name.node\", SecondaryNameNode.this);\n          infoServer.setAttribute(\"name.system.image\", checkpointImage);\n          infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n          infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n              GetImageServlet.class, true);\n          infoServer.start();\n          return infoServer;\n        }\n      });\n    } catch (InterruptedException e) {\n      throw new RuntimeException(e);\n    } \n    \n    LOG.info(\"Web server init done\");\n\n    // The web-server port can be ephemeral... ensure we have the correct info\n    infoPort \u003d infoServer.getPort();\n    if (!UserGroupInformation.isSecurityEnabled()) {\n      imagePort \u003d infoPort;\n    }\n    \n    conf.set(DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, infoBindAddress + \":\" +infoPort); \n    LOG.info(\"Secondary Web-server up at: \" + infoBindAddress + \":\" +infoPort);\n    LOG.info(\"Secondary image servlet up at: \" + infoBindAddress + \":\" + imagePort);\n    LOG.info(\"Checkpoint Period   :\" + checkpointPeriod + \" secs \" +\n             \"(\" + checkpointPeriod/60 + \" min)\");\n    LOG.info(\"Log Size Trigger    :\" + checkpointTxnCount + \" txns\");\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private void initialize(final Configuration conf,\n      CommandLineOpts commandLineOpts) throws IOException {\n    final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n    infoBindAddress \u003d infoSocAddr.getHostName();\n    UserGroupInformation.setConfiguration(conf);\n    if (UserGroupInformation.isSecurityEnabled()) {\n      SecurityUtil.login(conf, DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n          DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n    }\n    // initiate Java VM metrics\n    JvmMetrics.create(\"SecondaryNameNode\",\n        conf.get(DFS_METRICS_SESSION_ID_KEY), DefaultMetricsSystem.instance());\n    \n    // Create connection to the namenode.\n    shouldRun \u003d true;\n    nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n\n    this.conf \u003d conf;\n    this.namenode \u003d\n        (NamenodeProtocol) RPC.waitForProxy(NamenodeProtocol.class,\n            NamenodeProtocol.versionID, nameNodeAddr, conf);\n\n    // initialize checkpoint directories\n    fsName \u003d getInfoServer();\n    checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                  \"/tmp/hadoop/dfs/namesecondary\");\n    checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                  \"/tmp/hadoop/dfs/namesecondary\");    \n    checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n    checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n\n    // Initialize other scheduling parameters from the configuration\n    checkpointCheckPeriod \u003d conf.getLong(\n        DFS_NAMENODE_CHECKPOINT_CHECK_PERIOD_KEY,\n        DFS_NAMENODE_CHECKPOINT_CHECK_PERIOD_DEFAULT);\n        \n    checkpointPeriod \u003d conf.getLong(DFS_NAMENODE_CHECKPOINT_PERIOD_KEY, \n                                    DFS_NAMENODE_CHECKPOINT_PERIOD_DEFAULT);\n    checkpointTxnCount \u003d conf.getLong(DFS_NAMENODE_CHECKPOINT_TXNS_KEY, \n                                  DFS_NAMENODE_CHECKPOINT_TXNS_DEFAULT);\n    warnForDeprecatedConfigs(conf);\n\n    // initialize the webserver for uploading files.\n    // Kerberized SSL servers must be run from the host principal...\n    UserGroupInformation httpUGI \u003d \n      UserGroupInformation.loginUserFromKeytabAndReturnUGI(\n          SecurityUtil.getServerPrincipal(conf\n              .get(DFS_SECONDARY_NAMENODE_KRB_HTTPS_USER_NAME_KEY),\n              infoBindAddress),\n          conf.get(DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY));\n    try {\n      infoServer \u003d httpUGI.doAs(new PrivilegedExceptionAction\u003cHttpServer\u003e() {\n        @Override\n        public HttpServer run() throws IOException, InterruptedException {\n          LOG.info(\"Starting web server as: \" +\n              UserGroupInformation.getCurrentUser().getUserName());\n\n          int tmpInfoPort \u003d infoSocAddr.getPort();\n          infoServer \u003d new HttpServer(\"secondary\", infoBindAddress, tmpInfoPort,\n              tmpInfoPort \u003d\u003d 0, conf, \n              new AccessControlList(conf.get(DFS_ADMIN, \" \")));\n          \n          if(UserGroupInformation.isSecurityEnabled()) {\n            System.setProperty(\"https.cipherSuites\", \n                Krb5AndCertsSslSocketConnector.KRB5_CIPHER_SUITES.get(0));\n            InetSocketAddress secInfoSocAddr \u003d \n              NetUtils.createSocketAddr(infoBindAddress + \":\"+ conf.getInt(\n                \"dfs.secondary.https.port\", 443));\n            imagePort \u003d secInfoSocAddr.getPort();\n            infoServer.addSslListener(secInfoSocAddr, conf, false, true);\n          }\n          \n          infoServer.setAttribute(\"secondary.name.node\", SecondaryNameNode.this);\n          infoServer.setAttribute(\"name.system.image\", checkpointImage);\n          infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n          infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n              GetImageServlet.class, true);\n          infoServer.start();\n          return infoServer;\n        }\n      });\n    } catch (InterruptedException e) {\n      throw new RuntimeException(e);\n    } \n    \n    LOG.info(\"Web server init done\");\n\n    // The web-server port can be ephemeral... ensure we have the correct info\n    infoPort \u003d infoServer.getPort();\n    if (!UserGroupInformation.isSecurityEnabled()) {\n      imagePort \u003d infoPort;\n    }\n    \n    conf.set(DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, infoBindAddress + \":\" +infoPort); \n    LOG.info(\"Secondary Web-server up at: \" + infoBindAddress + \":\" +infoPort);\n    LOG.info(\"Secondary image servlet up at: \" + infoBindAddress + \":\" + imagePort);\n    LOG.info(\"Checkpoint Period   :\" + checkpointPeriod + \" secs \" +\n             \"(\" + checkpointPeriod/60 + \" min)\");\n    LOG.info(\"Log Size Trigger    :\" + checkpointTxnCount + \" txns\");\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java"
      }
    },
    "28e6a4e44a3e920dcaf858f9a74a6358226b3a63": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-1073. Redesign the NameNode\u0027s storage layout for image checkpoints and edit logs to introduce transaction IDs and be more robust. Contributed by Todd Lipcon and Ivan Kelly.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1152295 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "29/07/11 9:28 AM",
      "commitName": "28e6a4e44a3e920dcaf858f9a74a6358226b3a63",
      "commitAuthor": "Todd Lipcon",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-1073. Redesign the NameNode\u0027s storage layout for image checkpoints and edit logs to introduce transaction IDs and be more robust. Contributed by Todd Lipcon and Ivan Kelly.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1152295 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "29/07/11 9:28 AM",
          "commitName": "28e6a4e44a3e920dcaf858f9a74a6358226b3a63",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "27/07/11 8:19 PM",
          "commitNameOld": "ffbe9e5972bf3eee9037e2602c1330e0dc744646",
          "commitAuthorOld": "Eli Collins",
          "daysBetweenCommits": 1.55,
          "commitsBetweenForRepo": 6,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,93 +1,100 @@\n-  private void initialize(final Configuration conf) throws IOException {\n+  private void initialize(final Configuration conf,\n+      CommandLineOpts commandLineOpts) throws IOException {\n     final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n     infoBindAddress \u003d infoSocAddr.getHostName();\n     UserGroupInformation.setConfiguration(conf);\n     if (UserGroupInformation.isSecurityEnabled()) {\n       SecurityUtil.login(conf, DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n           DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n     }\n     // initiate Java VM metrics\n     JvmMetrics.create(\"SecondaryNameNode\",\n         conf.get(DFS_METRICS_SESSION_ID_KEY), DefaultMetricsSystem.instance());\n     \n     // Create connection to the namenode.\n     shouldRun \u003d true;\n     nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n \n     this.conf \u003d conf;\n     this.namenode \u003d\n         (NamenodeProtocol) RPC.waitForProxy(NamenodeProtocol.class,\n             NamenodeProtocol.versionID, nameNodeAddr, conf);\n \n     // initialize checkpoint directories\n     fsName \u003d getInfoServer();\n     checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                   \"/tmp/hadoop/dfs/namesecondary\");\n     checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                   \"/tmp/hadoop/dfs/namesecondary\");    \n-    checkpointImage \u003d new CheckpointStorage(conf);\n-    checkpointImage.recoverCreate(checkpointDirs, checkpointEditsDirs);\n+    checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n+    checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n \n     // Initialize other scheduling parameters from the configuration\n+    checkpointCheckPeriod \u003d conf.getLong(\n+        DFS_NAMENODE_CHECKPOINT_CHECK_PERIOD_KEY,\n+        DFS_NAMENODE_CHECKPOINT_CHECK_PERIOD_DEFAULT);\n+        \n     checkpointPeriod \u003d conf.getLong(DFS_NAMENODE_CHECKPOINT_PERIOD_KEY, \n                                     DFS_NAMENODE_CHECKPOINT_PERIOD_DEFAULT);\n-    checkpointSize \u003d conf.getLong(DFS_NAMENODE_CHECKPOINT_SIZE_KEY, \n-                                  DFS_NAMENODE_CHECKPOINT_SIZE_DEFAULT);\n+    checkpointTxnCount \u003d conf.getLong(DFS_NAMENODE_CHECKPOINT_TXNS_KEY, \n+                                  DFS_NAMENODE_CHECKPOINT_TXNS_DEFAULT);\n+    warnForDeprecatedConfigs(conf);\n \n     // initialize the webserver for uploading files.\n     // Kerberized SSL servers must be run from the host principal...\n     UserGroupInformation httpUGI \u003d \n       UserGroupInformation.loginUserFromKeytabAndReturnUGI(\n           SecurityUtil.getServerPrincipal(conf\n               .get(DFS_SECONDARY_NAMENODE_KRB_HTTPS_USER_NAME_KEY),\n               infoBindAddress),\n           conf.get(DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY));\n     try {\n       infoServer \u003d httpUGI.doAs(new PrivilegedExceptionAction\u003cHttpServer\u003e() {\n         @Override\n         public HttpServer run() throws IOException, InterruptedException {\n           LOG.info(\"Starting web server as: \" +\n               UserGroupInformation.getCurrentUser().getUserName());\n \n           int tmpInfoPort \u003d infoSocAddr.getPort();\n           infoServer \u003d new HttpServer(\"secondary\", infoBindAddress, tmpInfoPort,\n               tmpInfoPort \u003d\u003d 0, conf, \n               new AccessControlList(conf.get(DFS_ADMIN, \" \")));\n           \n           if(UserGroupInformation.isSecurityEnabled()) {\n             System.setProperty(\"https.cipherSuites\", \n                 Krb5AndCertsSslSocketConnector.KRB5_CIPHER_SUITES.get(0));\n             InetSocketAddress secInfoSocAddr \u003d \n-              NetUtils.createSocketAddr(infoBindAddress + \":\"+ conf.get(\n-                \"dfs.secondary.https.port\", infoBindAddress + \":\" + 0));\n+              NetUtils.createSocketAddr(infoBindAddress + \":\"+ conf.getInt(\n+                \"dfs.secondary.https.port\", 443));\n             imagePort \u003d secInfoSocAddr.getPort();\n             infoServer.addSslListener(secInfoSocAddr, conf, false, true);\n           }\n           \n           infoServer.setAttribute(\"secondary.name.node\", SecondaryNameNode.this);\n           infoServer.setAttribute(\"name.system.image\", checkpointImage);\n           infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n           infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n               GetImageServlet.class, true);\n           infoServer.start();\n           return infoServer;\n         }\n       });\n     } catch (InterruptedException e) {\n       throw new RuntimeException(e);\n     } \n     \n     LOG.info(\"Web server init done\");\n \n     // The web-server port can be ephemeral... ensure we have the correct info\n     infoPort \u003d infoServer.getPort();\n-    if(!UserGroupInformation.isSecurityEnabled())\n+    if (!UserGroupInformation.isSecurityEnabled()) {\n       imagePort \u003d infoPort;\n+    }\n+    \n     conf.set(DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, infoBindAddress + \":\" +infoPort); \n     LOG.info(\"Secondary Web-server up at: \" + infoBindAddress + \":\" +infoPort);\n     LOG.info(\"Secondary image servlet up at: \" + infoBindAddress + \":\" + imagePort);\n-    LOG.warn(\"Checkpoint Period   :\" + checkpointPeriod + \" secs \" +\n+    LOG.info(\"Checkpoint Period   :\" + checkpointPeriod + \" secs \" +\n              \"(\" + checkpointPeriod/60 + \" min)\");\n-    LOG.warn(\"Log Size Trigger    :\" + checkpointSize + \" bytes \" +\n-             \"(\" + checkpointSize/1024 + \" KB)\");\n+    LOG.info(\"Log Size Trigger    :\" + checkpointTxnCount + \" txns\");\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void initialize(final Configuration conf,\n      CommandLineOpts commandLineOpts) throws IOException {\n    final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n    infoBindAddress \u003d infoSocAddr.getHostName();\n    UserGroupInformation.setConfiguration(conf);\n    if (UserGroupInformation.isSecurityEnabled()) {\n      SecurityUtil.login(conf, DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n          DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n    }\n    // initiate Java VM metrics\n    JvmMetrics.create(\"SecondaryNameNode\",\n        conf.get(DFS_METRICS_SESSION_ID_KEY), DefaultMetricsSystem.instance());\n    \n    // Create connection to the namenode.\n    shouldRun \u003d true;\n    nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n\n    this.conf \u003d conf;\n    this.namenode \u003d\n        (NamenodeProtocol) RPC.waitForProxy(NamenodeProtocol.class,\n            NamenodeProtocol.versionID, nameNodeAddr, conf);\n\n    // initialize checkpoint directories\n    fsName \u003d getInfoServer();\n    checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                  \"/tmp/hadoop/dfs/namesecondary\");\n    checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                  \"/tmp/hadoop/dfs/namesecondary\");    \n    checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n    checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n\n    // Initialize other scheduling parameters from the configuration\n    checkpointCheckPeriod \u003d conf.getLong(\n        DFS_NAMENODE_CHECKPOINT_CHECK_PERIOD_KEY,\n        DFS_NAMENODE_CHECKPOINT_CHECK_PERIOD_DEFAULT);\n        \n    checkpointPeriod \u003d conf.getLong(DFS_NAMENODE_CHECKPOINT_PERIOD_KEY, \n                                    DFS_NAMENODE_CHECKPOINT_PERIOD_DEFAULT);\n    checkpointTxnCount \u003d conf.getLong(DFS_NAMENODE_CHECKPOINT_TXNS_KEY, \n                                  DFS_NAMENODE_CHECKPOINT_TXNS_DEFAULT);\n    warnForDeprecatedConfigs(conf);\n\n    // initialize the webserver for uploading files.\n    // Kerberized SSL servers must be run from the host principal...\n    UserGroupInformation httpUGI \u003d \n      UserGroupInformation.loginUserFromKeytabAndReturnUGI(\n          SecurityUtil.getServerPrincipal(conf\n              .get(DFS_SECONDARY_NAMENODE_KRB_HTTPS_USER_NAME_KEY),\n              infoBindAddress),\n          conf.get(DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY));\n    try {\n      infoServer \u003d httpUGI.doAs(new PrivilegedExceptionAction\u003cHttpServer\u003e() {\n        @Override\n        public HttpServer run() throws IOException, InterruptedException {\n          LOG.info(\"Starting web server as: \" +\n              UserGroupInformation.getCurrentUser().getUserName());\n\n          int tmpInfoPort \u003d infoSocAddr.getPort();\n          infoServer \u003d new HttpServer(\"secondary\", infoBindAddress, tmpInfoPort,\n              tmpInfoPort \u003d\u003d 0, conf, \n              new AccessControlList(conf.get(DFS_ADMIN, \" \")));\n          \n          if(UserGroupInformation.isSecurityEnabled()) {\n            System.setProperty(\"https.cipherSuites\", \n                Krb5AndCertsSslSocketConnector.KRB5_CIPHER_SUITES.get(0));\n            InetSocketAddress secInfoSocAddr \u003d \n              NetUtils.createSocketAddr(infoBindAddress + \":\"+ conf.getInt(\n                \"dfs.secondary.https.port\", 443));\n            imagePort \u003d secInfoSocAddr.getPort();\n            infoServer.addSslListener(secInfoSocAddr, conf, false, true);\n          }\n          \n          infoServer.setAttribute(\"secondary.name.node\", SecondaryNameNode.this);\n          infoServer.setAttribute(\"name.system.image\", checkpointImage);\n          infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n          infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n              GetImageServlet.class, true);\n          infoServer.start();\n          return infoServer;\n        }\n      });\n    } catch (InterruptedException e) {\n      throw new RuntimeException(e);\n    } \n    \n    LOG.info(\"Web server init done\");\n\n    // The web-server port can be ephemeral... ensure we have the correct info\n    infoPort \u003d infoServer.getPort();\n    if (!UserGroupInformation.isSecurityEnabled()) {\n      imagePort \u003d infoPort;\n    }\n    \n    conf.set(DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, infoBindAddress + \":\" +infoPort); \n    LOG.info(\"Secondary Web-server up at: \" + infoBindAddress + \":\" +infoPort);\n    LOG.info(\"Secondary image servlet up at: \" + infoBindAddress + \":\" + imagePort);\n    LOG.info(\"Checkpoint Period   :\" + checkpointPeriod + \" secs \" +\n             \"(\" + checkpointPeriod/60 + \" min)\");\n    LOG.info(\"Log Size Trigger    :\" + checkpointTxnCount + \" txns\");\n  }",
          "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
          "extendedDetails": {
            "oldValue": "[conf-Configuration(modifiers-final)]",
            "newValue": "[conf-Configuration(modifiers-final), commandLineOpts-CommandLineOpts]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-1073. Redesign the NameNode\u0027s storage layout for image checkpoints and edit logs to introduce transaction IDs and be more robust. Contributed by Todd Lipcon and Ivan Kelly.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1152295 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "29/07/11 9:28 AM",
          "commitName": "28e6a4e44a3e920dcaf858f9a74a6358226b3a63",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "27/07/11 8:19 PM",
          "commitNameOld": "ffbe9e5972bf3eee9037e2602c1330e0dc744646",
          "commitAuthorOld": "Eli Collins",
          "daysBetweenCommits": 1.55,
          "commitsBetweenForRepo": 6,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,93 +1,100 @@\n-  private void initialize(final Configuration conf) throws IOException {\n+  private void initialize(final Configuration conf,\n+      CommandLineOpts commandLineOpts) throws IOException {\n     final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n     infoBindAddress \u003d infoSocAddr.getHostName();\n     UserGroupInformation.setConfiguration(conf);\n     if (UserGroupInformation.isSecurityEnabled()) {\n       SecurityUtil.login(conf, DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n           DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n     }\n     // initiate Java VM metrics\n     JvmMetrics.create(\"SecondaryNameNode\",\n         conf.get(DFS_METRICS_SESSION_ID_KEY), DefaultMetricsSystem.instance());\n     \n     // Create connection to the namenode.\n     shouldRun \u003d true;\n     nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n \n     this.conf \u003d conf;\n     this.namenode \u003d\n         (NamenodeProtocol) RPC.waitForProxy(NamenodeProtocol.class,\n             NamenodeProtocol.versionID, nameNodeAddr, conf);\n \n     // initialize checkpoint directories\n     fsName \u003d getInfoServer();\n     checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                   \"/tmp/hadoop/dfs/namesecondary\");\n     checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                   \"/tmp/hadoop/dfs/namesecondary\");    \n-    checkpointImage \u003d new CheckpointStorage(conf);\n-    checkpointImage.recoverCreate(checkpointDirs, checkpointEditsDirs);\n+    checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n+    checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n \n     // Initialize other scheduling parameters from the configuration\n+    checkpointCheckPeriod \u003d conf.getLong(\n+        DFS_NAMENODE_CHECKPOINT_CHECK_PERIOD_KEY,\n+        DFS_NAMENODE_CHECKPOINT_CHECK_PERIOD_DEFAULT);\n+        \n     checkpointPeriod \u003d conf.getLong(DFS_NAMENODE_CHECKPOINT_PERIOD_KEY, \n                                     DFS_NAMENODE_CHECKPOINT_PERIOD_DEFAULT);\n-    checkpointSize \u003d conf.getLong(DFS_NAMENODE_CHECKPOINT_SIZE_KEY, \n-                                  DFS_NAMENODE_CHECKPOINT_SIZE_DEFAULT);\n+    checkpointTxnCount \u003d conf.getLong(DFS_NAMENODE_CHECKPOINT_TXNS_KEY, \n+                                  DFS_NAMENODE_CHECKPOINT_TXNS_DEFAULT);\n+    warnForDeprecatedConfigs(conf);\n \n     // initialize the webserver for uploading files.\n     // Kerberized SSL servers must be run from the host principal...\n     UserGroupInformation httpUGI \u003d \n       UserGroupInformation.loginUserFromKeytabAndReturnUGI(\n           SecurityUtil.getServerPrincipal(conf\n               .get(DFS_SECONDARY_NAMENODE_KRB_HTTPS_USER_NAME_KEY),\n               infoBindAddress),\n           conf.get(DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY));\n     try {\n       infoServer \u003d httpUGI.doAs(new PrivilegedExceptionAction\u003cHttpServer\u003e() {\n         @Override\n         public HttpServer run() throws IOException, InterruptedException {\n           LOG.info(\"Starting web server as: \" +\n               UserGroupInformation.getCurrentUser().getUserName());\n \n           int tmpInfoPort \u003d infoSocAddr.getPort();\n           infoServer \u003d new HttpServer(\"secondary\", infoBindAddress, tmpInfoPort,\n               tmpInfoPort \u003d\u003d 0, conf, \n               new AccessControlList(conf.get(DFS_ADMIN, \" \")));\n           \n           if(UserGroupInformation.isSecurityEnabled()) {\n             System.setProperty(\"https.cipherSuites\", \n                 Krb5AndCertsSslSocketConnector.KRB5_CIPHER_SUITES.get(0));\n             InetSocketAddress secInfoSocAddr \u003d \n-              NetUtils.createSocketAddr(infoBindAddress + \":\"+ conf.get(\n-                \"dfs.secondary.https.port\", infoBindAddress + \":\" + 0));\n+              NetUtils.createSocketAddr(infoBindAddress + \":\"+ conf.getInt(\n+                \"dfs.secondary.https.port\", 443));\n             imagePort \u003d secInfoSocAddr.getPort();\n             infoServer.addSslListener(secInfoSocAddr, conf, false, true);\n           }\n           \n           infoServer.setAttribute(\"secondary.name.node\", SecondaryNameNode.this);\n           infoServer.setAttribute(\"name.system.image\", checkpointImage);\n           infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n           infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n               GetImageServlet.class, true);\n           infoServer.start();\n           return infoServer;\n         }\n       });\n     } catch (InterruptedException e) {\n       throw new RuntimeException(e);\n     } \n     \n     LOG.info(\"Web server init done\");\n \n     // The web-server port can be ephemeral... ensure we have the correct info\n     infoPort \u003d infoServer.getPort();\n-    if(!UserGroupInformation.isSecurityEnabled())\n+    if (!UserGroupInformation.isSecurityEnabled()) {\n       imagePort \u003d infoPort;\n+    }\n+    \n     conf.set(DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, infoBindAddress + \":\" +infoPort); \n     LOG.info(\"Secondary Web-server up at: \" + infoBindAddress + \":\" +infoPort);\n     LOG.info(\"Secondary image servlet up at: \" + infoBindAddress + \":\" + imagePort);\n-    LOG.warn(\"Checkpoint Period   :\" + checkpointPeriod + \" secs \" +\n+    LOG.info(\"Checkpoint Period   :\" + checkpointPeriod + \" secs \" +\n              \"(\" + checkpointPeriod/60 + \" min)\");\n-    LOG.warn(\"Log Size Trigger    :\" + checkpointSize + \" bytes \" +\n-             \"(\" + checkpointSize/1024 + \" KB)\");\n+    LOG.info(\"Log Size Trigger    :\" + checkpointTxnCount + \" txns\");\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void initialize(final Configuration conf,\n      CommandLineOpts commandLineOpts) throws IOException {\n    final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n    infoBindAddress \u003d infoSocAddr.getHostName();\n    UserGroupInformation.setConfiguration(conf);\n    if (UserGroupInformation.isSecurityEnabled()) {\n      SecurityUtil.login(conf, DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n          DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n    }\n    // initiate Java VM metrics\n    JvmMetrics.create(\"SecondaryNameNode\",\n        conf.get(DFS_METRICS_SESSION_ID_KEY), DefaultMetricsSystem.instance());\n    \n    // Create connection to the namenode.\n    shouldRun \u003d true;\n    nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n\n    this.conf \u003d conf;\n    this.namenode \u003d\n        (NamenodeProtocol) RPC.waitForProxy(NamenodeProtocol.class,\n            NamenodeProtocol.versionID, nameNodeAddr, conf);\n\n    // initialize checkpoint directories\n    fsName \u003d getInfoServer();\n    checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                  \"/tmp/hadoop/dfs/namesecondary\");\n    checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                  \"/tmp/hadoop/dfs/namesecondary\");    \n    checkpointImage \u003d new CheckpointStorage(conf, checkpointDirs, checkpointEditsDirs);\n    checkpointImage.recoverCreate(commandLineOpts.shouldFormat());\n\n    // Initialize other scheduling parameters from the configuration\n    checkpointCheckPeriod \u003d conf.getLong(\n        DFS_NAMENODE_CHECKPOINT_CHECK_PERIOD_KEY,\n        DFS_NAMENODE_CHECKPOINT_CHECK_PERIOD_DEFAULT);\n        \n    checkpointPeriod \u003d conf.getLong(DFS_NAMENODE_CHECKPOINT_PERIOD_KEY, \n                                    DFS_NAMENODE_CHECKPOINT_PERIOD_DEFAULT);\n    checkpointTxnCount \u003d conf.getLong(DFS_NAMENODE_CHECKPOINT_TXNS_KEY, \n                                  DFS_NAMENODE_CHECKPOINT_TXNS_DEFAULT);\n    warnForDeprecatedConfigs(conf);\n\n    // initialize the webserver for uploading files.\n    // Kerberized SSL servers must be run from the host principal...\n    UserGroupInformation httpUGI \u003d \n      UserGroupInformation.loginUserFromKeytabAndReturnUGI(\n          SecurityUtil.getServerPrincipal(conf\n              .get(DFS_SECONDARY_NAMENODE_KRB_HTTPS_USER_NAME_KEY),\n              infoBindAddress),\n          conf.get(DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY));\n    try {\n      infoServer \u003d httpUGI.doAs(new PrivilegedExceptionAction\u003cHttpServer\u003e() {\n        @Override\n        public HttpServer run() throws IOException, InterruptedException {\n          LOG.info(\"Starting web server as: \" +\n              UserGroupInformation.getCurrentUser().getUserName());\n\n          int tmpInfoPort \u003d infoSocAddr.getPort();\n          infoServer \u003d new HttpServer(\"secondary\", infoBindAddress, tmpInfoPort,\n              tmpInfoPort \u003d\u003d 0, conf, \n              new AccessControlList(conf.get(DFS_ADMIN, \" \")));\n          \n          if(UserGroupInformation.isSecurityEnabled()) {\n            System.setProperty(\"https.cipherSuites\", \n                Krb5AndCertsSslSocketConnector.KRB5_CIPHER_SUITES.get(0));\n            InetSocketAddress secInfoSocAddr \u003d \n              NetUtils.createSocketAddr(infoBindAddress + \":\"+ conf.getInt(\n                \"dfs.secondary.https.port\", 443));\n            imagePort \u003d secInfoSocAddr.getPort();\n            infoServer.addSslListener(secInfoSocAddr, conf, false, true);\n          }\n          \n          infoServer.setAttribute(\"secondary.name.node\", SecondaryNameNode.this);\n          infoServer.setAttribute(\"name.system.image\", checkpointImage);\n          infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n          infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n              GetImageServlet.class, true);\n          infoServer.start();\n          return infoServer;\n        }\n      });\n    } catch (InterruptedException e) {\n      throw new RuntimeException(e);\n    } \n    \n    LOG.info(\"Web server init done\");\n\n    // The web-server port can be ephemeral... ensure we have the correct info\n    infoPort \u003d infoServer.getPort();\n    if (!UserGroupInformation.isSecurityEnabled()) {\n      imagePort \u003d infoPort;\n    }\n    \n    conf.set(DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, infoBindAddress + \":\" +infoPort); \n    LOG.info(\"Secondary Web-server up at: \" + infoBindAddress + \":\" +infoPort);\n    LOG.info(\"Secondary image servlet up at: \" + infoBindAddress + \":\" + imagePort);\n    LOG.info(\"Checkpoint Period   :\" + checkpointPeriod + \" secs \" +\n             \"(\" + checkpointPeriod/60 + \" min)\");\n    LOG.info(\"Log Size Trigger    :\" + checkpointTxnCount + \" txns\");\n  }",
          "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
          "extendedDetails": {}
        }
      ]
    },
    "b60772c47ddaefbeffd72bb9dce2a98117538dbc": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2198. Remove hardcoded configuration keys. Contributed by Suresh Srinivas.\n\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1151501 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/07/11 8:29 AM",
      "commitName": "b60772c47ddaefbeffd72bb9dce2a98117538dbc",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "25/07/11 2:44 PM",
      "commitNameOld": "d2b31fe25f34ca0c6b4edc250e3b25cce04583e6",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 1.74,
      "commitsBetweenForRepo": 9,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,96 +1,93 @@\n   private void initialize(final Configuration conf) throws IOException {\n     final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n     infoBindAddress \u003d infoSocAddr.getHostName();\n     UserGroupInformation.setConfiguration(conf);\n     if (UserGroupInformation.isSecurityEnabled()) {\n-      SecurityUtil.login(conf, \n-          DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n-          DFSConfigKeys.DFS_SECONDARY_NAMENODE_USER_NAME_KEY,\n-          infoBindAddress);\n+      SecurityUtil.login(conf, DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n+          DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n     }\n     // initiate Java VM metrics\n     JvmMetrics.create(\"SecondaryNameNode\",\n-        conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n-        DefaultMetricsSystem.instance());\n+        conf.get(DFS_METRICS_SESSION_ID_KEY), DefaultMetricsSystem.instance());\n     \n     // Create connection to the namenode.\n     shouldRun \u003d true;\n     nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n \n     this.conf \u003d conf;\n     this.namenode \u003d\n         (NamenodeProtocol) RPC.waitForProxy(NamenodeProtocol.class,\n             NamenodeProtocol.versionID, nameNodeAddr, conf);\n \n     // initialize checkpoint directories\n     fsName \u003d getInfoServer();\n     checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                   \"/tmp/hadoop/dfs/namesecondary\");\n     checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                   \"/tmp/hadoop/dfs/namesecondary\");    \n     checkpointImage \u003d new CheckpointStorage(conf);\n     checkpointImage.recoverCreate(checkpointDirs, checkpointEditsDirs);\n \n     // Initialize other scheduling parameters from the configuration\n-    checkpointPeriod \u003d conf.getLong(DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_PERIOD_KEY, \n-                                    DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_PERIOD_DEFAULT);\n-    checkpointSize \u003d conf.getLong(DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_SIZE_KEY, \n-                                  DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_SIZE_DEFAULT);\n+    checkpointPeriod \u003d conf.getLong(DFS_NAMENODE_CHECKPOINT_PERIOD_KEY, \n+                                    DFS_NAMENODE_CHECKPOINT_PERIOD_DEFAULT);\n+    checkpointSize \u003d conf.getLong(DFS_NAMENODE_CHECKPOINT_SIZE_KEY, \n+                                  DFS_NAMENODE_CHECKPOINT_SIZE_DEFAULT);\n \n     // initialize the webserver for uploading files.\n     // Kerberized SSL servers must be run from the host principal...\n     UserGroupInformation httpUGI \u003d \n       UserGroupInformation.loginUserFromKeytabAndReturnUGI(\n           SecurityUtil.getServerPrincipal(conf\n-              .get(DFSConfigKeys.DFS_SECONDARY_NAMENODE_KRB_HTTPS_USER_NAME_KEY),\n+              .get(DFS_SECONDARY_NAMENODE_KRB_HTTPS_USER_NAME_KEY),\n               infoBindAddress),\n-          conf.get(DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY));\n+          conf.get(DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY));\n     try {\n       infoServer \u003d httpUGI.doAs(new PrivilegedExceptionAction\u003cHttpServer\u003e() {\n         @Override\n         public HttpServer run() throws IOException, InterruptedException {\n           LOG.info(\"Starting web server as: \" +\n               UserGroupInformation.getCurrentUser().getUserName());\n \n           int tmpInfoPort \u003d infoSocAddr.getPort();\n           infoServer \u003d new HttpServer(\"secondary\", infoBindAddress, tmpInfoPort,\n               tmpInfoPort \u003d\u003d 0, conf, \n-              new AccessControlList(conf.get(DFSConfigKeys.DFS_ADMIN, \" \")));\n+              new AccessControlList(conf.get(DFS_ADMIN, \" \")));\n           \n           if(UserGroupInformation.isSecurityEnabled()) {\n             System.setProperty(\"https.cipherSuites\", \n                 Krb5AndCertsSslSocketConnector.KRB5_CIPHER_SUITES.get(0));\n             InetSocketAddress secInfoSocAddr \u003d \n               NetUtils.createSocketAddr(infoBindAddress + \":\"+ conf.get(\n                 \"dfs.secondary.https.port\", infoBindAddress + \":\" + 0));\n             imagePort \u003d secInfoSocAddr.getPort();\n             infoServer.addSslListener(secInfoSocAddr, conf, false, true);\n           }\n           \n           infoServer.setAttribute(\"secondary.name.node\", SecondaryNameNode.this);\n           infoServer.setAttribute(\"name.system.image\", checkpointImage);\n           infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n           infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n               GetImageServlet.class, true);\n           infoServer.start();\n           return infoServer;\n         }\n       });\n     } catch (InterruptedException e) {\n       throw new RuntimeException(e);\n     } \n     \n     LOG.info(\"Web server init done\");\n \n     // The web-server port can be ephemeral... ensure we have the correct info\n     infoPort \u003d infoServer.getPort();\n     if(!UserGroupInformation.isSecurityEnabled())\n       imagePort \u003d infoPort;\n-    conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, infoBindAddress + \":\" +infoPort); \n+    conf.set(DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, infoBindAddress + \":\" +infoPort); \n     LOG.info(\"Secondary Web-server up at: \" + infoBindAddress + \":\" +infoPort);\n     LOG.info(\"Secondary image servlet up at: \" + infoBindAddress + \":\" + imagePort);\n     LOG.warn(\"Checkpoint Period   :\" + checkpointPeriod + \" secs \" +\n              \"(\" + checkpointPeriod/60 + \" min)\");\n     LOG.warn(\"Log Size Trigger    :\" + checkpointSize + \" bytes \" +\n              \"(\" + checkpointSize/1024 + \" KB)\");\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void initialize(final Configuration conf) throws IOException {\n    final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n    infoBindAddress \u003d infoSocAddr.getHostName();\n    UserGroupInformation.setConfiguration(conf);\n    if (UserGroupInformation.isSecurityEnabled()) {\n      SecurityUtil.login(conf, DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n          DFS_SECONDARY_NAMENODE_USER_NAME_KEY, infoBindAddress);\n    }\n    // initiate Java VM metrics\n    JvmMetrics.create(\"SecondaryNameNode\",\n        conf.get(DFS_METRICS_SESSION_ID_KEY), DefaultMetricsSystem.instance());\n    \n    // Create connection to the namenode.\n    shouldRun \u003d true;\n    nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n\n    this.conf \u003d conf;\n    this.namenode \u003d\n        (NamenodeProtocol) RPC.waitForProxy(NamenodeProtocol.class,\n            NamenodeProtocol.versionID, nameNodeAddr, conf);\n\n    // initialize checkpoint directories\n    fsName \u003d getInfoServer();\n    checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                  \"/tmp/hadoop/dfs/namesecondary\");\n    checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                  \"/tmp/hadoop/dfs/namesecondary\");    \n    checkpointImage \u003d new CheckpointStorage(conf);\n    checkpointImage.recoverCreate(checkpointDirs, checkpointEditsDirs);\n\n    // Initialize other scheduling parameters from the configuration\n    checkpointPeriod \u003d conf.getLong(DFS_NAMENODE_CHECKPOINT_PERIOD_KEY, \n                                    DFS_NAMENODE_CHECKPOINT_PERIOD_DEFAULT);\n    checkpointSize \u003d conf.getLong(DFS_NAMENODE_CHECKPOINT_SIZE_KEY, \n                                  DFS_NAMENODE_CHECKPOINT_SIZE_DEFAULT);\n\n    // initialize the webserver for uploading files.\n    // Kerberized SSL servers must be run from the host principal...\n    UserGroupInformation httpUGI \u003d \n      UserGroupInformation.loginUserFromKeytabAndReturnUGI(\n          SecurityUtil.getServerPrincipal(conf\n              .get(DFS_SECONDARY_NAMENODE_KRB_HTTPS_USER_NAME_KEY),\n              infoBindAddress),\n          conf.get(DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY));\n    try {\n      infoServer \u003d httpUGI.doAs(new PrivilegedExceptionAction\u003cHttpServer\u003e() {\n        @Override\n        public HttpServer run() throws IOException, InterruptedException {\n          LOG.info(\"Starting web server as: \" +\n              UserGroupInformation.getCurrentUser().getUserName());\n\n          int tmpInfoPort \u003d infoSocAddr.getPort();\n          infoServer \u003d new HttpServer(\"secondary\", infoBindAddress, tmpInfoPort,\n              tmpInfoPort \u003d\u003d 0, conf, \n              new AccessControlList(conf.get(DFS_ADMIN, \" \")));\n          \n          if(UserGroupInformation.isSecurityEnabled()) {\n            System.setProperty(\"https.cipherSuites\", \n                Krb5AndCertsSslSocketConnector.KRB5_CIPHER_SUITES.get(0));\n            InetSocketAddress secInfoSocAddr \u003d \n              NetUtils.createSocketAddr(infoBindAddress + \":\"+ conf.get(\n                \"dfs.secondary.https.port\", infoBindAddress + \":\" + 0));\n            imagePort \u003d secInfoSocAddr.getPort();\n            infoServer.addSslListener(secInfoSocAddr, conf, false, true);\n          }\n          \n          infoServer.setAttribute(\"secondary.name.node\", SecondaryNameNode.this);\n          infoServer.setAttribute(\"name.system.image\", checkpointImage);\n          infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n          infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n              GetImageServlet.class, true);\n          infoServer.start();\n          return infoServer;\n        }\n      });\n    } catch (InterruptedException e) {\n      throw new RuntimeException(e);\n    } \n    \n    LOG.info(\"Web server init done\");\n\n    // The web-server port can be ephemeral... ensure we have the correct info\n    infoPort \u003d infoServer.getPort();\n    if(!UserGroupInformation.isSecurityEnabled())\n      imagePort \u003d infoPort;\n    conf.set(DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, infoBindAddress + \":\" +infoPort); \n    LOG.info(\"Secondary Web-server up at: \" + infoBindAddress + \":\" +infoPort);\n    LOG.info(\"Secondary image servlet up at: \" + infoBindAddress + \":\" + imagePort);\n    LOG.warn(\"Checkpoint Period   :\" + checkpointPeriod + \" secs \" +\n             \"(\" + checkpointPeriod/60 + \" min)\");\n    LOG.warn(\"Log Size Trigger    :\" + checkpointSize + \" bytes \" +\n             \"(\" + checkpointSize/1024 + \" KB)\");\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
      "extendedDetails": {}
    },
    "4c4eed13d5c3155e6a45fb06422e0f9059abfa9c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2082. SecondaryNameNode web interface doesn\u0027t show the right info. Contributed by Aaron T. Myers.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1139397 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/06/11 11:18 AM",
      "commitName": "4c4eed13d5c3155e6a45fb06422e0f9059abfa9c",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "12/06/11 3:00 PM",
      "commitNameOld": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 11.85,
      "commitsBetweenForRepo": 41,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,96 +1,96 @@\n   private void initialize(final Configuration conf) throws IOException {\n     final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n     infoBindAddress \u003d infoSocAddr.getHostName();\n     UserGroupInformation.setConfiguration(conf);\n     if (UserGroupInformation.isSecurityEnabled()) {\n       SecurityUtil.login(conf, \n           DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n           DFSConfigKeys.DFS_SECONDARY_NAMENODE_USER_NAME_KEY,\n           infoBindAddress);\n     }\n     // initiate Java VM metrics\n     JvmMetrics.create(\"SecondaryNameNode\",\n         conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n         DefaultMetricsSystem.instance());\n     \n     // Create connection to the namenode.\n     shouldRun \u003d true;\n     nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n \n     this.conf \u003d conf;\n     this.namenode \u003d\n         (NamenodeProtocol) RPC.waitForProxy(NamenodeProtocol.class,\n             NamenodeProtocol.versionID, nameNodeAddr, conf);\n \n     // initialize checkpoint directories\n     fsName \u003d getInfoServer();\n     checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                   \"/tmp/hadoop/dfs/namesecondary\");\n     checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                   \"/tmp/hadoop/dfs/namesecondary\");    \n     checkpointImage \u003d new CheckpointStorage(conf);\n     checkpointImage.recoverCreate(checkpointDirs, checkpointEditsDirs);\n \n     // Initialize other scheduling parameters from the configuration\n     checkpointPeriod \u003d conf.getLong(DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_PERIOD_KEY, \n                                     DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_PERIOD_DEFAULT);\n     checkpointSize \u003d conf.getLong(DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_SIZE_KEY, \n                                   DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_SIZE_DEFAULT);\n \n     // initialize the webserver for uploading files.\n     // Kerberized SSL servers must be run from the host principal...\n     UserGroupInformation httpUGI \u003d \n       UserGroupInformation.loginUserFromKeytabAndReturnUGI(\n           SecurityUtil.getServerPrincipal(conf\n               .get(DFSConfigKeys.DFS_SECONDARY_NAMENODE_KRB_HTTPS_USER_NAME_KEY),\n               infoBindAddress),\n           conf.get(DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY));\n     try {\n       infoServer \u003d httpUGI.doAs(new PrivilegedExceptionAction\u003cHttpServer\u003e() {\n         @Override\n         public HttpServer run() throws IOException, InterruptedException {\n           LOG.info(\"Starting web server as: \" +\n               UserGroupInformation.getCurrentUser().getUserName());\n \n           int tmpInfoPort \u003d infoSocAddr.getPort();\n           infoServer \u003d new HttpServer(\"secondary\", infoBindAddress, tmpInfoPort,\n               tmpInfoPort \u003d\u003d 0, conf, \n               new AccessControlList(conf.get(DFSConfigKeys.DFS_ADMIN, \" \")));\n           \n           if(UserGroupInformation.isSecurityEnabled()) {\n             System.setProperty(\"https.cipherSuites\", \n                 Krb5AndCertsSslSocketConnector.KRB5_CIPHER_SUITES.get(0));\n             InetSocketAddress secInfoSocAddr \u003d \n               NetUtils.createSocketAddr(infoBindAddress + \":\"+ conf.get(\n                 \"dfs.secondary.https.port\", infoBindAddress + \":\" + 0));\n             imagePort \u003d secInfoSocAddr.getPort();\n             infoServer.addSslListener(secInfoSocAddr, conf, false, true);\n           }\n           \n-          infoServer.setAttribute(\"secondary.name.node\", this);\n+          infoServer.setAttribute(\"secondary.name.node\", SecondaryNameNode.this);\n           infoServer.setAttribute(\"name.system.image\", checkpointImage);\n           infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n           infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n               GetImageServlet.class, true);\n           infoServer.start();\n           return infoServer;\n         }\n       });\n     } catch (InterruptedException e) {\n       throw new RuntimeException(e);\n     } \n     \n     LOG.info(\"Web server init done\");\n \n     // The web-server port can be ephemeral... ensure we have the correct info\n     infoPort \u003d infoServer.getPort();\n     if(!UserGroupInformation.isSecurityEnabled())\n       imagePort \u003d infoPort;\n     conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, infoBindAddress + \":\" +infoPort); \n     LOG.info(\"Secondary Web-server up at: \" + infoBindAddress + \":\" +infoPort);\n     LOG.info(\"Secondary image servlet up at: \" + infoBindAddress + \":\" + imagePort);\n     LOG.warn(\"Checkpoint Period   :\" + checkpointPeriod + \" secs \" +\n              \"(\" + checkpointPeriod/60 + \" min)\");\n     LOG.warn(\"Log Size Trigger    :\" + checkpointSize + \" bytes \" +\n              \"(\" + checkpointSize/1024 + \" KB)\");\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void initialize(final Configuration conf) throws IOException {\n    final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n    infoBindAddress \u003d infoSocAddr.getHostName();\n    UserGroupInformation.setConfiguration(conf);\n    if (UserGroupInformation.isSecurityEnabled()) {\n      SecurityUtil.login(conf, \n          DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n          DFSConfigKeys.DFS_SECONDARY_NAMENODE_USER_NAME_KEY,\n          infoBindAddress);\n    }\n    // initiate Java VM metrics\n    JvmMetrics.create(\"SecondaryNameNode\",\n        conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n        DefaultMetricsSystem.instance());\n    \n    // Create connection to the namenode.\n    shouldRun \u003d true;\n    nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n\n    this.conf \u003d conf;\n    this.namenode \u003d\n        (NamenodeProtocol) RPC.waitForProxy(NamenodeProtocol.class,\n            NamenodeProtocol.versionID, nameNodeAddr, conf);\n\n    // initialize checkpoint directories\n    fsName \u003d getInfoServer();\n    checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                  \"/tmp/hadoop/dfs/namesecondary\");\n    checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                  \"/tmp/hadoop/dfs/namesecondary\");    \n    checkpointImage \u003d new CheckpointStorage(conf);\n    checkpointImage.recoverCreate(checkpointDirs, checkpointEditsDirs);\n\n    // Initialize other scheduling parameters from the configuration\n    checkpointPeriod \u003d conf.getLong(DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_PERIOD_KEY, \n                                    DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_PERIOD_DEFAULT);\n    checkpointSize \u003d conf.getLong(DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_SIZE_KEY, \n                                  DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_SIZE_DEFAULT);\n\n    // initialize the webserver for uploading files.\n    // Kerberized SSL servers must be run from the host principal...\n    UserGroupInformation httpUGI \u003d \n      UserGroupInformation.loginUserFromKeytabAndReturnUGI(\n          SecurityUtil.getServerPrincipal(conf\n              .get(DFSConfigKeys.DFS_SECONDARY_NAMENODE_KRB_HTTPS_USER_NAME_KEY),\n              infoBindAddress),\n          conf.get(DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY));\n    try {\n      infoServer \u003d httpUGI.doAs(new PrivilegedExceptionAction\u003cHttpServer\u003e() {\n        @Override\n        public HttpServer run() throws IOException, InterruptedException {\n          LOG.info(\"Starting web server as: \" +\n              UserGroupInformation.getCurrentUser().getUserName());\n\n          int tmpInfoPort \u003d infoSocAddr.getPort();\n          infoServer \u003d new HttpServer(\"secondary\", infoBindAddress, tmpInfoPort,\n              tmpInfoPort \u003d\u003d 0, conf, \n              new AccessControlList(conf.get(DFSConfigKeys.DFS_ADMIN, \" \")));\n          \n          if(UserGroupInformation.isSecurityEnabled()) {\n            System.setProperty(\"https.cipherSuites\", \n                Krb5AndCertsSslSocketConnector.KRB5_CIPHER_SUITES.get(0));\n            InetSocketAddress secInfoSocAddr \u003d \n              NetUtils.createSocketAddr(infoBindAddress + \":\"+ conf.get(\n                \"dfs.secondary.https.port\", infoBindAddress + \":\" + 0));\n            imagePort \u003d secInfoSocAddr.getPort();\n            infoServer.addSslListener(secInfoSocAddr, conf, false, true);\n          }\n          \n          infoServer.setAttribute(\"secondary.name.node\", SecondaryNameNode.this);\n          infoServer.setAttribute(\"name.system.image\", checkpointImage);\n          infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n          infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n              GetImageServlet.class, true);\n          infoServer.start();\n          return infoServer;\n        }\n      });\n    } catch (InterruptedException e) {\n      throw new RuntimeException(e);\n    } \n    \n    LOG.info(\"Web server init done\");\n\n    // The web-server port can be ephemeral... ensure we have the correct info\n    infoPort \u003d infoServer.getPort();\n    if(!UserGroupInformation.isSecurityEnabled())\n      imagePort \u003d infoPort;\n    conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, infoBindAddress + \":\" +infoPort); \n    LOG.info(\"Secondary Web-server up at: \" + infoBindAddress + \":\" +infoPort);\n    LOG.info(\"Secondary image servlet up at: \" + infoBindAddress + \":\" + imagePort);\n    LOG.warn(\"Checkpoint Period   :\" + checkpointPeriod + \" secs \" +\n             \"(\" + checkpointPeriod/60 + \" min)\");\n    LOG.warn(\"Log Size Trigger    :\" + checkpointSize + \" bytes \" +\n             \"(\" + checkpointSize/1024 + \" KB)\");\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java",
      "extendedDetails": {}
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,96 @@\n+  private void initialize(final Configuration conf) throws IOException {\n+    final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n+    infoBindAddress \u003d infoSocAddr.getHostName();\n+    UserGroupInformation.setConfiguration(conf);\n+    if (UserGroupInformation.isSecurityEnabled()) {\n+      SecurityUtil.login(conf, \n+          DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n+          DFSConfigKeys.DFS_SECONDARY_NAMENODE_USER_NAME_KEY,\n+          infoBindAddress);\n+    }\n+    // initiate Java VM metrics\n+    JvmMetrics.create(\"SecondaryNameNode\",\n+        conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n+        DefaultMetricsSystem.instance());\n+    \n+    // Create connection to the namenode.\n+    shouldRun \u003d true;\n+    nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n+\n+    this.conf \u003d conf;\n+    this.namenode \u003d\n+        (NamenodeProtocol) RPC.waitForProxy(NamenodeProtocol.class,\n+            NamenodeProtocol.versionID, nameNodeAddr, conf);\n+\n+    // initialize checkpoint directories\n+    fsName \u003d getInfoServer();\n+    checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n+                                  \"/tmp/hadoop/dfs/namesecondary\");\n+    checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n+                                  \"/tmp/hadoop/dfs/namesecondary\");    \n+    checkpointImage \u003d new CheckpointStorage(conf);\n+    checkpointImage.recoverCreate(checkpointDirs, checkpointEditsDirs);\n+\n+    // Initialize other scheduling parameters from the configuration\n+    checkpointPeriod \u003d conf.getLong(DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_PERIOD_KEY, \n+                                    DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_PERIOD_DEFAULT);\n+    checkpointSize \u003d conf.getLong(DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_SIZE_KEY, \n+                                  DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_SIZE_DEFAULT);\n+\n+    // initialize the webserver for uploading files.\n+    // Kerberized SSL servers must be run from the host principal...\n+    UserGroupInformation httpUGI \u003d \n+      UserGroupInformation.loginUserFromKeytabAndReturnUGI(\n+          SecurityUtil.getServerPrincipal(conf\n+              .get(DFSConfigKeys.DFS_SECONDARY_NAMENODE_KRB_HTTPS_USER_NAME_KEY),\n+              infoBindAddress),\n+          conf.get(DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY));\n+    try {\n+      infoServer \u003d httpUGI.doAs(new PrivilegedExceptionAction\u003cHttpServer\u003e() {\n+        @Override\n+        public HttpServer run() throws IOException, InterruptedException {\n+          LOG.info(\"Starting web server as: \" +\n+              UserGroupInformation.getCurrentUser().getUserName());\n+\n+          int tmpInfoPort \u003d infoSocAddr.getPort();\n+          infoServer \u003d new HttpServer(\"secondary\", infoBindAddress, tmpInfoPort,\n+              tmpInfoPort \u003d\u003d 0, conf, \n+              new AccessControlList(conf.get(DFSConfigKeys.DFS_ADMIN, \" \")));\n+          \n+          if(UserGroupInformation.isSecurityEnabled()) {\n+            System.setProperty(\"https.cipherSuites\", \n+                Krb5AndCertsSslSocketConnector.KRB5_CIPHER_SUITES.get(0));\n+            InetSocketAddress secInfoSocAddr \u003d \n+              NetUtils.createSocketAddr(infoBindAddress + \":\"+ conf.get(\n+                \"dfs.secondary.https.port\", infoBindAddress + \":\" + 0));\n+            imagePort \u003d secInfoSocAddr.getPort();\n+            infoServer.addSslListener(secInfoSocAddr, conf, false, true);\n+          }\n+          \n+          infoServer.setAttribute(\"secondary.name.node\", this);\n+          infoServer.setAttribute(\"name.system.image\", checkpointImage);\n+          infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n+          infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n+              GetImageServlet.class, true);\n+          infoServer.start();\n+          return infoServer;\n+        }\n+      });\n+    } catch (InterruptedException e) {\n+      throw new RuntimeException(e);\n+    } \n+    \n+    LOG.info(\"Web server init done\");\n+\n+    // The web-server port can be ephemeral... ensure we have the correct info\n+    infoPort \u003d infoServer.getPort();\n+    if(!UserGroupInformation.isSecurityEnabled())\n+      imagePort \u003d infoPort;\n+    conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, infoBindAddress + \":\" +infoPort); \n+    LOG.info(\"Secondary Web-server up at: \" + infoBindAddress + \":\" +infoPort);\n+    LOG.info(\"Secondary image servlet up at: \" + infoBindAddress + \":\" + imagePort);\n+    LOG.warn(\"Checkpoint Period   :\" + checkpointPeriod + \" secs \" +\n+             \"(\" + checkpointPeriod/60 + \" min)\");\n+    LOG.warn(\"Log Size Trigger    :\" + checkpointSize + \" bytes \" +\n+             \"(\" + checkpointSize/1024 + \" KB)\");\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void initialize(final Configuration conf) throws IOException {\n    final InetSocketAddress infoSocAddr \u003d getHttpAddress(conf);\n    infoBindAddress \u003d infoSocAddr.getHostName();\n    UserGroupInformation.setConfiguration(conf);\n    if (UserGroupInformation.isSecurityEnabled()) {\n      SecurityUtil.login(conf, \n          DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY,\n          DFSConfigKeys.DFS_SECONDARY_NAMENODE_USER_NAME_KEY,\n          infoBindAddress);\n    }\n    // initiate Java VM metrics\n    JvmMetrics.create(\"SecondaryNameNode\",\n        conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n        DefaultMetricsSystem.instance());\n    \n    // Create connection to the namenode.\n    shouldRun \u003d true;\n    nameNodeAddr \u003d NameNode.getServiceAddress(conf, true);\n\n    this.conf \u003d conf;\n    this.namenode \u003d\n        (NamenodeProtocol) RPC.waitForProxy(NamenodeProtocol.class,\n            NamenodeProtocol.versionID, nameNodeAddr, conf);\n\n    // initialize checkpoint directories\n    fsName \u003d getInfoServer();\n    checkpointDirs \u003d FSImage.getCheckpointDirs(conf,\n                                  \"/tmp/hadoop/dfs/namesecondary\");\n    checkpointEditsDirs \u003d FSImage.getCheckpointEditsDirs(conf, \n                                  \"/tmp/hadoop/dfs/namesecondary\");    \n    checkpointImage \u003d new CheckpointStorage(conf);\n    checkpointImage.recoverCreate(checkpointDirs, checkpointEditsDirs);\n\n    // Initialize other scheduling parameters from the configuration\n    checkpointPeriod \u003d conf.getLong(DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_PERIOD_KEY, \n                                    DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_PERIOD_DEFAULT);\n    checkpointSize \u003d conf.getLong(DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_SIZE_KEY, \n                                  DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_SIZE_DEFAULT);\n\n    // initialize the webserver for uploading files.\n    // Kerberized SSL servers must be run from the host principal...\n    UserGroupInformation httpUGI \u003d \n      UserGroupInformation.loginUserFromKeytabAndReturnUGI(\n          SecurityUtil.getServerPrincipal(conf\n              .get(DFSConfigKeys.DFS_SECONDARY_NAMENODE_KRB_HTTPS_USER_NAME_KEY),\n              infoBindAddress),\n          conf.get(DFSConfigKeys.DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY));\n    try {\n      infoServer \u003d httpUGI.doAs(new PrivilegedExceptionAction\u003cHttpServer\u003e() {\n        @Override\n        public HttpServer run() throws IOException, InterruptedException {\n          LOG.info(\"Starting web server as: \" +\n              UserGroupInformation.getCurrentUser().getUserName());\n\n          int tmpInfoPort \u003d infoSocAddr.getPort();\n          infoServer \u003d new HttpServer(\"secondary\", infoBindAddress, tmpInfoPort,\n              tmpInfoPort \u003d\u003d 0, conf, \n              new AccessControlList(conf.get(DFSConfigKeys.DFS_ADMIN, \" \")));\n          \n          if(UserGroupInformation.isSecurityEnabled()) {\n            System.setProperty(\"https.cipherSuites\", \n                Krb5AndCertsSslSocketConnector.KRB5_CIPHER_SUITES.get(0));\n            InetSocketAddress secInfoSocAddr \u003d \n              NetUtils.createSocketAddr(infoBindAddress + \":\"+ conf.get(\n                \"dfs.secondary.https.port\", infoBindAddress + \":\" + 0));\n            imagePort \u003d secInfoSocAddr.getPort();\n            infoServer.addSslListener(secInfoSocAddr, conf, false, true);\n          }\n          \n          infoServer.setAttribute(\"secondary.name.node\", this);\n          infoServer.setAttribute(\"name.system.image\", checkpointImage);\n          infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n          infoServer.addInternalServlet(\"getimage\", \"/getimage\",\n              GetImageServlet.class, true);\n          infoServer.start();\n          return infoServer;\n        }\n      });\n    } catch (InterruptedException e) {\n      throw new RuntimeException(e);\n    } \n    \n    LOG.info(\"Web server init done\");\n\n    // The web-server port can be ephemeral... ensure we have the correct info\n    infoPort \u003d infoServer.getPort();\n    if(!UserGroupInformation.isSecurityEnabled())\n      imagePort \u003d infoPort;\n    conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, infoBindAddress + \":\" +infoPort); \n    LOG.info(\"Secondary Web-server up at: \" + infoBindAddress + \":\" +infoPort);\n    LOG.info(\"Secondary image servlet up at: \" + infoBindAddress + \":\" + imagePort);\n    LOG.warn(\"Checkpoint Period   :\" + checkpointPeriod + \" secs \" +\n             \"(\" + checkpointPeriod/60 + \" min)\");\n    LOG.warn(\"Log Size Trigger    :\" + checkpointSize + \" bytes \" +\n             \"(\" + checkpointSize/1024 + \" KB)\");\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java"
    }
  }
}