{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "RumenToSLSConverter.java",
  "functionName": "main",
  "functionId": "main___args-String[]",
  "sourceFilePath": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/RumenToSLSConverter.java",
  "functionStartLine": 57,
  "functionEndLine": 119,
  "numCommitsSeen": 6,
  "timeTaken": 698,
  "changeHistory": [
    "355eaaa33d01f06e9efe960b8888fb925e03ffb9",
    "58b08e11b9f04c9190ab4a07473f0ee04e01ec6b"
  ],
  "changeHistoryShort": {
    "355eaaa33d01f06e9efe960b8888fb925e03ffb9": "Ybodychange",
    "58b08e11b9f04c9190ab4a07473f0ee04e01ec6b": "Yintroduced"
  },
  "changeHistoryDetails": {
    "355eaaa33d01f06e9efe960b8888fb925e03ffb9": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-10318. Incorrect reference to nodeFile in RumenToSLSConverter error message. Contributed by Wei Yan.\n",
      "commitDate": "03/09/15 6:48 AM",
      "commitName": "355eaaa33d01f06e9efe960b8888fb925e03ffb9",
      "commitAuthor": "Tsuyoshi Ozawa",
      "commitDateOld": "30/04/15 3:34 AM",
      "commitNameOld": "f384a063a653b33d69f7d2c7d4fd45c24b5aa46a",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 126.13,
      "commitsBetweenForRepo": 909,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,63 +1,63 @@\n   public static void main(String args[]) throws Exception {\n     Options options \u003d new Options();\n     options.addOption(\"input\", true, \"input rumen json file\");\n     options.addOption(\"outputJobs\", true, \"output jobs file\");\n     options.addOption(\"outputNodes\", true, \"output nodes file\");\n \n     CommandLineParser parser \u003d new GnuParser();\n     CommandLine cmd \u003d parser.parse(options, args);\n \n     if (! cmd.hasOption(\"input\") ||\n             ! cmd.hasOption(\"outputJobs\") ||\n             ! cmd.hasOption(\"outputNodes\")) {\n       System.err.println();\n       System.err.println(\"ERROR: Missing input or output file\");\n       System.err.println();\n       System.err.println(\"LoadGenerator creates a SLS script \" +\n               \"from a Hadoop Rumen output\");\n       System.err.println();\n       System.err.println(\"Options: -input FILE -outputJobs FILE \" +\n               \"-outputNodes FILE\");\n       System.err.println();\n       System.exit(1);\n     }\n \n     String inputFile \u003d cmd.getOptionValue(\"input\");\n     String outputJsonFile \u003d cmd.getOptionValue(\"outputJobs\");\n     String outputNodeFile \u003d cmd.getOptionValue(\"outputNodes\");\n \n     // check existing\n     if (! new File(inputFile).exists()) {\n       System.err.println();\n       System.err.println(\"ERROR: input does not exist\");\n       System.exit(1);\n     }\n     if (new File(outputJsonFile).exists()) {\n       System.err.println();\n       System.err.println(\"ERROR: output job file is existing\");\n       System.exit(1);\n     }\n     if (new File(outputNodeFile).exists()) {\n       System.err.println();\n       System.err.println(\"ERROR: output node file is existing\");\n       System.exit(1);\n     }\n \n     File jsonFile \u003d new File(outputJsonFile);\n     if (! jsonFile.getParentFile().exists()\n             \u0026\u0026 ! jsonFile.getParentFile().mkdirs()) {\n       System.err.println(\"ERROR: Cannot create output directory in path: \"\n               + jsonFile.getParentFile().getAbsoluteFile());\n       System.exit(1);\n     }\n     File nodeFile \u003d new File(outputNodeFile);\n     if (! nodeFile.getParentFile().exists()\n             \u0026\u0026 ! nodeFile.getParentFile().mkdirs()) {\n       System.err.println(\"ERROR: Cannot create output directory in path: \"\n-              + jsonFile.getParentFile().getAbsoluteFile());\n+              + nodeFile.getParentFile().getAbsoluteFile());\n       System.exit(1);\n     }\n \n     generateSLSLoadFile(inputFile, outputJsonFile);\n     generateSLSNodeFile(outputNodeFile);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static void main(String args[]) throws Exception {\n    Options options \u003d new Options();\n    options.addOption(\"input\", true, \"input rumen json file\");\n    options.addOption(\"outputJobs\", true, \"output jobs file\");\n    options.addOption(\"outputNodes\", true, \"output nodes file\");\n\n    CommandLineParser parser \u003d new GnuParser();\n    CommandLine cmd \u003d parser.parse(options, args);\n\n    if (! cmd.hasOption(\"input\") ||\n            ! cmd.hasOption(\"outputJobs\") ||\n            ! cmd.hasOption(\"outputNodes\")) {\n      System.err.println();\n      System.err.println(\"ERROR: Missing input or output file\");\n      System.err.println();\n      System.err.println(\"LoadGenerator creates a SLS script \" +\n              \"from a Hadoop Rumen output\");\n      System.err.println();\n      System.err.println(\"Options: -input FILE -outputJobs FILE \" +\n              \"-outputNodes FILE\");\n      System.err.println();\n      System.exit(1);\n    }\n\n    String inputFile \u003d cmd.getOptionValue(\"input\");\n    String outputJsonFile \u003d cmd.getOptionValue(\"outputJobs\");\n    String outputNodeFile \u003d cmd.getOptionValue(\"outputNodes\");\n\n    // check existing\n    if (! new File(inputFile).exists()) {\n      System.err.println();\n      System.err.println(\"ERROR: input does not exist\");\n      System.exit(1);\n    }\n    if (new File(outputJsonFile).exists()) {\n      System.err.println();\n      System.err.println(\"ERROR: output job file is existing\");\n      System.exit(1);\n    }\n    if (new File(outputNodeFile).exists()) {\n      System.err.println();\n      System.err.println(\"ERROR: output node file is existing\");\n      System.exit(1);\n    }\n\n    File jsonFile \u003d new File(outputJsonFile);\n    if (! jsonFile.getParentFile().exists()\n            \u0026\u0026 ! jsonFile.getParentFile().mkdirs()) {\n      System.err.println(\"ERROR: Cannot create output directory in path: \"\n              + jsonFile.getParentFile().getAbsoluteFile());\n      System.exit(1);\n    }\n    File nodeFile \u003d new File(outputNodeFile);\n    if (! nodeFile.getParentFile().exists()\n            \u0026\u0026 ! nodeFile.getParentFile().mkdirs()) {\n      System.err.println(\"ERROR: Cannot create output directory in path: \"\n              + nodeFile.getParentFile().getAbsoluteFile());\n      System.exit(1);\n    }\n\n    generateSLSLoadFile(inputFile, outputJsonFile);\n    generateSLSNodeFile(outputNodeFile);\n  }",
      "path": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/RumenToSLSConverter.java",
      "extendedDetails": {}
    },
    "58b08e11b9f04c9190ab4a07473f0ee04e01ec6b": {
      "type": "Yintroduced",
      "commitMessage": "YARN-1021. Yarn Scheduler Load Simulator. (ywskycn via tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1527059 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/09/13 1:23 PM",
      "commitName": "58b08e11b9f04c9190ab4a07473f0ee04e01ec6b",
      "commitAuthor": "Alejandro Abdelnur",
      "diff": "@@ -0,0 +1,63 @@\n+  public static void main(String args[]) throws Exception {\n+    Options options \u003d new Options();\n+    options.addOption(\"input\", true, \"input rumen json file\");\n+    options.addOption(\"outputJobs\", true, \"output jobs file\");\n+    options.addOption(\"outputNodes\", true, \"output nodes file\");\n+\n+    CommandLineParser parser \u003d new GnuParser();\n+    CommandLine cmd \u003d parser.parse(options, args);\n+\n+    if (! cmd.hasOption(\"input\") ||\n+            ! cmd.hasOption(\"outputJobs\") ||\n+            ! cmd.hasOption(\"outputNodes\")) {\n+      System.err.println();\n+      System.err.println(\"ERROR: Missing input or output file\");\n+      System.err.println();\n+      System.err.println(\"LoadGenerator creates a SLS script \" +\n+              \"from a Hadoop Rumen output\");\n+      System.err.println();\n+      System.err.println(\"Options: -input FILE -outputJobs FILE \" +\n+              \"-outputNodes FILE\");\n+      System.err.println();\n+      System.exit(1);\n+    }\n+\n+    String inputFile \u003d cmd.getOptionValue(\"input\");\n+    String outputJsonFile \u003d cmd.getOptionValue(\"outputJobs\");\n+    String outputNodeFile \u003d cmd.getOptionValue(\"outputNodes\");\n+\n+    // check existing\n+    if (! new File(inputFile).exists()) {\n+      System.err.println();\n+      System.err.println(\"ERROR: input does not exist\");\n+      System.exit(1);\n+    }\n+    if (new File(outputJsonFile).exists()) {\n+      System.err.println();\n+      System.err.println(\"ERROR: output job file is existing\");\n+      System.exit(1);\n+    }\n+    if (new File(outputNodeFile).exists()) {\n+      System.err.println();\n+      System.err.println(\"ERROR: output node file is existing\");\n+      System.exit(1);\n+    }\n+\n+    File jsonFile \u003d new File(outputJsonFile);\n+    if (! jsonFile.getParentFile().exists()\n+            \u0026\u0026 ! jsonFile.getParentFile().mkdirs()) {\n+      System.err.println(\"ERROR: Cannot create output directory in path: \"\n+              + jsonFile.getParentFile().getAbsoluteFile());\n+      System.exit(1);\n+    }\n+    File nodeFile \u003d new File(outputNodeFile);\n+    if (! nodeFile.getParentFile().exists()\n+            \u0026\u0026 ! nodeFile.getParentFile().mkdirs()) {\n+      System.err.println(\"ERROR: Cannot create output directory in path: \"\n+              + jsonFile.getParentFile().getAbsoluteFile());\n+      System.exit(1);\n+    }\n+\n+    generateSLSLoadFile(inputFile, outputJsonFile);\n+    generateSLSNodeFile(outputNodeFile);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public static void main(String args[]) throws Exception {\n    Options options \u003d new Options();\n    options.addOption(\"input\", true, \"input rumen json file\");\n    options.addOption(\"outputJobs\", true, \"output jobs file\");\n    options.addOption(\"outputNodes\", true, \"output nodes file\");\n\n    CommandLineParser parser \u003d new GnuParser();\n    CommandLine cmd \u003d parser.parse(options, args);\n\n    if (! cmd.hasOption(\"input\") ||\n            ! cmd.hasOption(\"outputJobs\") ||\n            ! cmd.hasOption(\"outputNodes\")) {\n      System.err.println();\n      System.err.println(\"ERROR: Missing input or output file\");\n      System.err.println();\n      System.err.println(\"LoadGenerator creates a SLS script \" +\n              \"from a Hadoop Rumen output\");\n      System.err.println();\n      System.err.println(\"Options: -input FILE -outputJobs FILE \" +\n              \"-outputNodes FILE\");\n      System.err.println();\n      System.exit(1);\n    }\n\n    String inputFile \u003d cmd.getOptionValue(\"input\");\n    String outputJsonFile \u003d cmd.getOptionValue(\"outputJobs\");\n    String outputNodeFile \u003d cmd.getOptionValue(\"outputNodes\");\n\n    // check existing\n    if (! new File(inputFile).exists()) {\n      System.err.println();\n      System.err.println(\"ERROR: input does not exist\");\n      System.exit(1);\n    }\n    if (new File(outputJsonFile).exists()) {\n      System.err.println();\n      System.err.println(\"ERROR: output job file is existing\");\n      System.exit(1);\n    }\n    if (new File(outputNodeFile).exists()) {\n      System.err.println();\n      System.err.println(\"ERROR: output node file is existing\");\n      System.exit(1);\n    }\n\n    File jsonFile \u003d new File(outputJsonFile);\n    if (! jsonFile.getParentFile().exists()\n            \u0026\u0026 ! jsonFile.getParentFile().mkdirs()) {\n      System.err.println(\"ERROR: Cannot create output directory in path: \"\n              + jsonFile.getParentFile().getAbsoluteFile());\n      System.exit(1);\n    }\n    File nodeFile \u003d new File(outputNodeFile);\n    if (! nodeFile.getParentFile().exists()\n            \u0026\u0026 ! nodeFile.getParentFile().mkdirs()) {\n      System.err.println(\"ERROR: Cannot create output directory in path: \"\n              + jsonFile.getParentFile().getAbsoluteFile());\n      System.exit(1);\n    }\n\n    generateSLSLoadFile(inputFile, outputJsonFile);\n    generateSLSNodeFile(outputNodeFile);\n  }",
      "path": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/RumenToSLSConverter.java"
    }
  }
}