{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DatanodeHttpServer.java",
  "functionName": "initChannel",
  "functionId": "initChannel___ch-SocketChannel",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/web/DatanodeHttpServer.java",
  "functionStartLine": 216,
  "functionEndLine": 230,
  "numCommitsSeen": 18,
  "timeTaken": 1980,
  "changeHistory": [
    "101d5b5f865f94e4772051ea8ce4ee0f92ddedca",
    "5d1889a66d91608d34ca9411fb6e9161e637e9d3",
    "bf8e4332cb4c33d0287ae6ecca61b335402ac1c4"
  ],
  "changeHistoryShort": {
    "101d5b5f865f94e4772051ea8ce4ee0f92ddedca": "Ybodychange",
    "5d1889a66d91608d34ca9411fb6e9161e637e9d3": "Ybodychange",
    "bf8e4332cb4c33d0287ae6ecca61b335402ac1c4": "Yintroduced"
  },
  "changeHistoryDetails": {
    "101d5b5f865f94e4772051ea8ce4ee0f92ddedca": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14234. Limit WebHDFS to specifc user, host, directory triples.\nContributed by Clay B.\n",
      "commitDate": "10/06/19 5:55 PM",
      "commitName": "101d5b5f865f94e4772051ea8ce4ee0f92ddedca",
      "commitAuthor": "Anu Engineer",
      "commitDateOld": "06/09/18 2:48 PM",
      "commitNameOld": "eca1a4bfe952fc184fe90dde50bac9b0e5293568",
      "commitAuthorOld": "Giovanni Matteo Fumarola",
      "daysBetweenCommits": 277.13,
      "commitsBetweenForRepo": 2099,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,15 @@\n-          protected void initChannel(SocketChannel ch) throws Exception {\n-            ChannelPipeline p \u003d ch.pipeline();\n-            p.addLast(\n-                new SslHandler(sslFactory.createSSLEngine()),\n-                new HttpRequestDecoder(),\n-                new HttpResponseEncoder());\n-            if (restCsrfPreventionFilter !\u003d null) {\n-              p.addLast(new RestCsrfPreventionFilterHandler(\n-                  restCsrfPreventionFilter));\n-            }\n-            p.addLast(\n-                new ChunkedWriteHandler(),\n-                new URLDispatcher(jettyAddr, conf, confForCreate));\n-          }\n\\ No newline at end of file\n+            protected void initChannel(SocketChannel ch) throws Exception {\n+              ChannelPipeline p \u003d ch.pipeline();\n+              p.addLast(\n+                  new SslHandler(sslFactory.createSSLEngine()),\n+                  new HttpRequestDecoder(),\n+                  new HttpResponseEncoder());\n+              if (handlers !\u003d null) {\n+                for (ChannelHandler c : handlers) {\n+                  p.addLast(c);\n+                }\n+              }\n+              p.addLast(\n+                  new ChunkedWriteHandler(),\n+                  new URLDispatcher(jettyAddr, conf, confForCreate));\n+            }\n\\ No newline at end of file\n",
      "actualSource": "            protected void initChannel(SocketChannel ch) throws Exception {\n              ChannelPipeline p \u003d ch.pipeline();\n              p.addLast(\n                  new SslHandler(sslFactory.createSSLEngine()),\n                  new HttpRequestDecoder(),\n                  new HttpResponseEncoder());\n              if (handlers !\u003d null) {\n                for (ChannelHandler c : handlers) {\n                  p.addLast(c);\n                }\n              }\n              p.addLast(\n                  new ChunkedWriteHandler(),\n                  new URLDispatcher(jettyAddr, conf, confForCreate));\n            }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/web/DatanodeHttpServer.java",
      "extendedDetails": {}
    },
    "5d1889a66d91608d34ca9411fb6e9161e637e9d3": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9711. Integrate CSRF prevention filter in WebHDFS. Contributed by Chris Nauroth.\n",
      "commitDate": "18/02/16 10:07 AM",
      "commitName": "5d1889a66d91608d34ca9411fb6e9161e637e9d3",
      "commitAuthor": "cnauroth",
      "commitDateOld": "24/11/15 12:47 PM",
      "commitNameOld": "fe5624b85d71720ae9da90a01cad9a3d1ea41160",
      "commitAuthorOld": "Xiaoyu Yao",
      "daysBetweenCommits": 85.89,
      "commitsBetweenForRepo": 527,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,9 +1,14 @@\n           protected void initChannel(SocketChannel ch) throws Exception {\n             ChannelPipeline p \u003d ch.pipeline();\n             p.addLast(\n-              new SslHandler(sslFactory.createSSLEngine()),\n-              new HttpRequestDecoder(),\n-              new HttpResponseEncoder(),\n-              new ChunkedWriteHandler(),\n-              new URLDispatcher(jettyAddr, conf, confForCreate));\n+                new SslHandler(sslFactory.createSSLEngine()),\n+                new HttpRequestDecoder(),\n+                new HttpResponseEncoder());\n+            if (restCsrfPreventionFilter !\u003d null) {\n+              p.addLast(new RestCsrfPreventionFilterHandler(\n+                  restCsrfPreventionFilter));\n+            }\n+            p.addLast(\n+                new ChunkedWriteHandler(),\n+                new URLDispatcher(jettyAddr, conf, confForCreate));\n           }\n\\ No newline at end of file\n",
      "actualSource": "          protected void initChannel(SocketChannel ch) throws Exception {\n            ChannelPipeline p \u003d ch.pipeline();\n            p.addLast(\n                new SslHandler(sslFactory.createSSLEngine()),\n                new HttpRequestDecoder(),\n                new HttpResponseEncoder());\n            if (restCsrfPreventionFilter !\u003d null) {\n              p.addLast(new RestCsrfPreventionFilterHandler(\n                  restCsrfPreventionFilter));\n            }\n            p.addLast(\n                new ChunkedWriteHandler(),\n                new URLDispatcher(jettyAddr, conf, confForCreate));\n          }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/web/DatanodeHttpServer.java",
      "extendedDetails": {}
    },
    "bf8e4332cb4c33d0287ae6ecca61b335402ac1c4": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-7279. Use netty to implement DatanodeWebHdfsMethods. Contributed by Haohui Mai.\n",
      "commitDate": "17/11/14 11:42 AM",
      "commitName": "bf8e4332cb4c33d0287ae6ecca61b335402ac1c4",
      "commitAuthor": "Haohui Mai",
      "diff": "@@ -0,0 +1,9 @@\n+          protected void initChannel(SocketChannel ch) throws Exception {\n+            ChannelPipeline p \u003d ch.pipeline();\n+            p.addLast(\n+              new SslHandler(sslFactory.createSSLEngine()),\n+              new HttpRequestDecoder(),\n+              new HttpResponseEncoder(),\n+              new ChunkedWriteHandler(),\n+              new URLDispatcher(jettyAddr, conf, confForCreate));\n+          }\n\\ No newline at end of file\n",
      "actualSource": "          protected void initChannel(SocketChannel ch) throws Exception {\n            ChannelPipeline p \u003d ch.pipeline();\n            p.addLast(\n              new SslHandler(sslFactory.createSSLEngine()),\n              new HttpRequestDecoder(),\n              new HttpResponseEncoder(),\n              new ChunkedWriteHandler(),\n              new URLDispatcher(jettyAddr, conf, confForCreate));\n          }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/web/DatanodeHttpServer.java"
    }
  }
}