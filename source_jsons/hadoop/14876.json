{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ECAdmin.java",
  "functionName": "run",
  "functionId": "run___conf-Configuration__args-List__String__",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/ECAdmin.java",
  "functionStartLine": 521,
  "functionEndLine": 551,
  "numCommitsSeen": 25,
  "timeTaken": 3968,
  "changeHistory": [
    "92c58901d767f4fea571274544a590608c911cb8",
    "14282e311be6ffcaddd2f74fa8e67c4e98a32291",
    "951cdd7e4cbe68284620f6805f85c51301150c58",
    "dd5e7c6b7239a93f2391beaa11181e442a387db4",
    "f99b6d19de77c6e730fed8444f8848a7e63d6130",
    "1b5451bf054c335188e4cd66f7b4a1d80013e86d",
    "132f758e3dbe3a3f11c0d9b2de8edbee594fb475"
  ],
  "changeHistoryShort": {
    "92c58901d767f4fea571274544a590608c911cb8": "Ybodychange",
    "14282e311be6ffcaddd2f74fa8e67c4e98a32291": "Ybodychange",
    "951cdd7e4cbe68284620f6805f85c51301150c58": "Ybodychange",
    "dd5e7c6b7239a93f2391beaa11181e442a387db4": "Ybodychange",
    "f99b6d19de77c6e730fed8444f8848a7e63d6130": "Ybodychange",
    "1b5451bf054c335188e4cd66f7b4a1d80013e86d": "Ybodychange",
    "132f758e3dbe3a3f11c0d9b2de8edbee594fb475": "Yintroduced"
  },
  "changeHistoryDetails": {
    "92c58901d767f4fea571274544a590608c911cb8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-15117. EC: Add getECTopologyResultForPolicies to DistributedFileSystem. Contributed by Ayush Saxena\n",
      "commitDate": "23/01/20 4:48 AM",
      "commitName": "92c58901d767f4fea571274544a590608c911cb8",
      "commitAuthor": "Ayush Saxena",
      "commitDateOld": "10/11/19 9:35 PM",
      "commitNameOld": "77934bc07b9bef3e129826e93e1c1e8a47c00c95",
      "commitAuthorOld": "Ayush Saxena",
      "daysBetweenCommits": 73.3,
      "commitsBetweenForRepo": 270,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,18 +1,25 @@\n     public int run(Configuration conf, List\u003cString\u003e args) throws IOException {\n       boolean isPolicyOption \u003d StringUtils.popOption(\"-policy\", args);\n       final DistributedFileSystem dfs \u003d AdminHelper.getDFS(conf);\n-      ECTopologyVerifierResult result;\n+      ECTopologyVerifierResult result \u003d null;\n       if (isPolicyOption) {\n         CommandFormat c \u003d new CommandFormat(1, Integer.MAX_VALUE);\n         c.parse(args);\n         String[] parameters \u003d args.toArray(new String[args.size()]);\n-        result \u003d getECTopologyResultForPolicies(dfs, parameters);\n+        try {\n+          result \u003d dfs.getECTopologyResultForPolicies(parameters);\n+        } catch (RemoteException e) {\n+          if (e.getClassName().contains(\"HadoopIllegalArgumentException\")) {\n+            throw new HadoopIllegalArgumentException(e.getMessage());\n+          }\n+          throw e;\n+        }\n       } else {\n-        result \u003d getECTopologyVerifierResult(dfs);\n+        result \u003d dfs.getECTopologyResultForPolicies();\n       }\n       System.out.println(result.getResultMessage());\n       if (result.isSupported()) {\n         return 0;\n       }\n       return 2;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public int run(Configuration conf, List\u003cString\u003e args) throws IOException {\n      boolean isPolicyOption \u003d StringUtils.popOption(\"-policy\", args);\n      final DistributedFileSystem dfs \u003d AdminHelper.getDFS(conf);\n      ECTopologyVerifierResult result \u003d null;\n      if (isPolicyOption) {\n        CommandFormat c \u003d new CommandFormat(1, Integer.MAX_VALUE);\n        c.parse(args);\n        String[] parameters \u003d args.toArray(new String[args.size()]);\n        try {\n          result \u003d dfs.getECTopologyResultForPolicies(parameters);\n        } catch (RemoteException e) {\n          if (e.getClassName().contains(\"HadoopIllegalArgumentException\")) {\n            throw new HadoopIllegalArgumentException(e.getMessage());\n          }\n          throw e;\n        }\n      } else {\n        result \u003d dfs.getECTopologyResultForPolicies();\n      }\n      System.out.println(result.getResultMessage());\n      if (result.isSupported()) {\n        return 0;\n      }\n      return 2;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/ECAdmin.java",
      "extendedDetails": {}
    },
    "14282e311be6ffcaddd2f74fa8e67c4e98a32291": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14188. Make hdfs ec -verifyClusterSetup command accept an erasure coding policy as a parameter. Contributed by Kitti Nanasi.\n\nSigned-off-by: Wei-Chiu Chuang \u003cweichiu@apache.org\u003e\n",
      "commitDate": "19/02/19 12:04 PM",
      "commitName": "14282e311be6ffcaddd2f74fa8e67c4e98a32291",
      "commitAuthor": "Kitti Nanasi",
      "commitDateOld": "23/01/19 2:40 PM",
      "commitNameOld": "951cdd7e4cbe68284620f6805f85c51301150c58",
      "commitAuthorOld": "Kitti Nanasi",
      "daysBetweenCommits": 26.89,
      "commitsBetweenForRepo": 190,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,18 @@\n     public int run(Configuration conf, List\u003cString\u003e args) throws IOException {\n-      if (args.size() \u003e 0) {\n-        System.err.println(getName() + \": Too many arguments\");\n-        return 1;\n-      }\n+      boolean isPolicyOption \u003d StringUtils.popOption(\"-policy\", args);\n       final DistributedFileSystem dfs \u003d AdminHelper.getDFS(conf);\n-      ECTopologyVerifierResult result \u003d getECTopologyVerifierResult(dfs);\n+      ECTopologyVerifierResult result;\n+      if (isPolicyOption) {\n+        CommandFormat c \u003d new CommandFormat(1, Integer.MAX_VALUE);\n+        c.parse(args);\n+        String[] parameters \u003d args.toArray(new String[args.size()]);\n+        result \u003d getECTopologyResultForPolicies(dfs, parameters);\n+      } else {\n+        result \u003d getECTopologyVerifierResult(dfs);\n+      }\n       System.out.println(result.getResultMessage());\n       if (result.isSupported()) {\n         return 0;\n       }\n       return 2;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public int run(Configuration conf, List\u003cString\u003e args) throws IOException {\n      boolean isPolicyOption \u003d StringUtils.popOption(\"-policy\", args);\n      final DistributedFileSystem dfs \u003d AdminHelper.getDFS(conf);\n      ECTopologyVerifierResult result;\n      if (isPolicyOption) {\n        CommandFormat c \u003d new CommandFormat(1, Integer.MAX_VALUE);\n        c.parse(args);\n        String[] parameters \u003d args.toArray(new String[args.size()]);\n        result \u003d getECTopologyResultForPolicies(dfs, parameters);\n      } else {\n        result \u003d getECTopologyVerifierResult(dfs);\n      }\n      System.out.println(result.getResultMessage());\n      if (result.isSupported()) {\n        return 0;\n      }\n      return 2;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/ECAdmin.java",
      "extendedDetails": {}
    },
    "951cdd7e4cbe68284620f6805f85c51301150c58": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14061. Check if the cluster topology supports the EC policy before setting, enabling or adding it. Contributed by Kitti Nanasi.\n\nSigned-off-by: Wei-Chiu Chuang \u003cweichiu@apache.org\u003e\n",
      "commitDate": "23/01/19 2:40 PM",
      "commitName": "951cdd7e4cbe68284620f6805f85c51301150c58",
      "commitAuthor": "Kitti Nanasi",
      "commitDateOld": "03/12/18 10:01 AM",
      "commitNameOld": "dd5e7c6b7239a93f2391beaa11181e442a387db4",
      "commitAuthorOld": "Kitti Nanasi",
      "daysBetweenCommits": 51.19,
      "commitsBetweenForRepo": 330,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,19 +1,13 @@\n     public int run(Configuration conf, List\u003cString\u003e args) throws IOException {\n       if (args.size() \u003e 0) {\n         System.err.println(getName() + \": Too many arguments\");\n         return 1;\n       }\n       final DistributedFileSystem dfs \u003d AdminHelper.getDFS(conf);\n-      final ErasureCodingPolicyInfo[] policies \u003d\n-          dfs.getClient().getNamenode().getErasureCodingPolicies();\n-      final DatanodeInfo[] report \u003d dfs.getClient().getNamenode()\n-          .getDatanodeReport(HdfsConstants.DatanodeReportType.ALL);\n-\n-      ECTopologyVerifierResult result \u003d ECTopologyVerifier\n-          .getECTopologyVerifierResult(report, policies);\n+      ECTopologyVerifierResult result \u003d getECTopologyVerifierResult(dfs);\n       System.out.println(result.getResultMessage());\n       if (result.isSupported()) {\n         return 0;\n       }\n       return 2;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public int run(Configuration conf, List\u003cString\u003e args) throws IOException {\n      if (args.size() \u003e 0) {\n        System.err.println(getName() + \": Too many arguments\");\n        return 1;\n      }\n      final DistributedFileSystem dfs \u003d AdminHelper.getDFS(conf);\n      ECTopologyVerifierResult result \u003d getECTopologyVerifierResult(dfs);\n      System.out.println(result.getResultMessage());\n      if (result.isSupported()) {\n        return 0;\n      }\n      return 2;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/ECAdmin.java",
      "extendedDetails": {}
    },
    "dd5e7c6b7239a93f2391beaa11181e442a387db4": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12946. Add a tool to check rack configuration against EC policies. Contributed by Kitti Nanasi.\n\nSigned-off-by: Wei-Chiu Chuang \u003cweichiu@apache.org\u003e\n",
      "commitDate": "03/12/18 10:01 AM",
      "commitName": "dd5e7c6b7239a93f2391beaa11181e442a387db4",
      "commitAuthor": "Kitti Nanasi",
      "commitDateOld": "13/11/18 12:44 PM",
      "commitNameOld": "9da6054ca4ff6f8bb19506d877770685b17d2c79",
      "commitAuthorOld": "Xiao Chen",
      "daysBetweenCommits": 19.89,
      "commitsBetweenForRepo": 138,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,19 @@\n     public int run(Configuration conf, List\u003cString\u003e args) throws IOException {\n-      final String ecPolicyName \u003d StringUtils.popOptionWithArgument(\"-policy\",\n-          args);\n-      if (ecPolicyName \u003d\u003d null) {\n-        System.err.println(\"Please specify the policy name.\\nUsage: \" +\n-            getLongUsage());\n-        return 1;\n-      }\n       if (args.size() \u003e 0) {\n         System.err.println(getName() + \": Too many arguments\");\n         return 1;\n       }\n-\n       final DistributedFileSystem dfs \u003d AdminHelper.getDFS(conf);\n-      try {\n-        dfs.disableErasureCodingPolicy(ecPolicyName);\n-        System.out.println(\"Erasure coding policy \" + ecPolicyName +\n-            \" is disabled\");\n-      } catch (IOException e) {\n-        System.err.println(AdminHelper.prettifyException(e));\n-        return 2;\n+      final ErasureCodingPolicyInfo[] policies \u003d\n+          dfs.getClient().getNamenode().getErasureCodingPolicies();\n+      final DatanodeInfo[] report \u003d dfs.getClient().getNamenode()\n+          .getDatanodeReport(HdfsConstants.DatanodeReportType.ALL);\n+\n+      ECTopologyVerifierResult result \u003d ECTopologyVerifier\n+          .getECTopologyVerifierResult(report, policies);\n+      System.out.println(result.getResultMessage());\n+      if (result.isSupported()) {\n+        return 0;\n       }\n-      return 0;\n+      return 2;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public int run(Configuration conf, List\u003cString\u003e args) throws IOException {\n      if (args.size() \u003e 0) {\n        System.err.println(getName() + \": Too many arguments\");\n        return 1;\n      }\n      final DistributedFileSystem dfs \u003d AdminHelper.getDFS(conf);\n      final ErasureCodingPolicyInfo[] policies \u003d\n          dfs.getClient().getNamenode().getErasureCodingPolicies();\n      final DatanodeInfo[] report \u003d dfs.getClient().getNamenode()\n          .getDatanodeReport(HdfsConstants.DatanodeReportType.ALL);\n\n      ECTopologyVerifierResult result \u003d ECTopologyVerifier\n          .getECTopologyVerifierResult(report, policies);\n      System.out.println(result.getResultMessage());\n      if (result.isSupported()) {\n        return 0;\n      }\n      return 2;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/ECAdmin.java",
      "extendedDetails": {}
    },
    "f99b6d19de77c6e730fed8444f8848a7e63d6130": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11870. Add CLI cmd to enable/disable an erasure code policy. Contributed by lufei.\n",
      "commitDate": "28/06/17 10:54 AM",
      "commitName": "f99b6d19de77c6e730fed8444f8848a7e63d6130",
      "commitAuthor": "Wei-Chiu Chuang",
      "commitDateOld": "20/06/17 11:01 PM",
      "commitNameOld": "5db3f9846882c51991d16853a5c431664f3f801f",
      "commitAuthorOld": "Kai Zheng",
      "daysBetweenCommits": 7.49,
      "commitsBetweenForRepo": 36,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,28 +1,24 @@\n     public int run(Configuration conf, List\u003cString\u003e args) throws IOException {\n+      final String ecPolicyName \u003d StringUtils.popOptionWithArgument(\"-policy\",\n+          args);\n+      if (ecPolicyName \u003d\u003d null) {\n+        System.err.println(\"Please specify the policy name.\\nUsage: \" +\n+            getLongUsage());\n+        return 1;\n+      }\n       if (args.size() \u003e 0) {\n         System.err.println(getName() + \": Too many arguments\");\n         return 1;\n       }\n \n       final DistributedFileSystem dfs \u003d AdminHelper.getDFS(conf);\n       try {\n-        HashMap\u003cString, String\u003e codecs \u003d\n-            dfs.getAllErasureCodingCodecs();\n-        if (codecs.isEmpty()) {\n-          System.out.println(\"No erasure coding codecs are supported on the \" +\n-              \"cluster.\");\n-        } else {\n-          System.out.println(\"Erasure Coding Codecs: Codec [Coder List]\");\n-          for (Map.Entry\u003cString, String\u003e codec : codecs.entrySet()) {\n-            if (codec !\u003d null) {\n-              System.out.println(\"\\t\" + codec.getKey().toUpperCase() + \" [\"\n-                  + codec.getValue().toUpperCase() +\"]\");\n-            }\n-          }\n-        }\n+        dfs.disableErasureCodingPolicy(ecPolicyName);\n+        System.out.println(\"Erasure coding policy \" + ecPolicyName +\n+            \" is disabled\");\n       } catch (IOException e) {\n         System.err.println(AdminHelper.prettifyException(e));\n         return 2;\n       }\n       return 0;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public int run(Configuration conf, List\u003cString\u003e args) throws IOException {\n      final String ecPolicyName \u003d StringUtils.popOptionWithArgument(\"-policy\",\n          args);\n      if (ecPolicyName \u003d\u003d null) {\n        System.err.println(\"Please specify the policy name.\\nUsage: \" +\n            getLongUsage());\n        return 1;\n      }\n      if (args.size() \u003e 0) {\n        System.err.println(getName() + \": Too many arguments\");\n        return 1;\n      }\n\n      final DistributedFileSystem dfs \u003d AdminHelper.getDFS(conf);\n      try {\n        dfs.disableErasureCodingPolicy(ecPolicyName);\n        System.out.println(\"Erasure coding policy \" + ecPolicyName +\n            \" is disabled\");\n      } catch (IOException e) {\n        System.err.println(AdminHelper.prettifyException(e));\n        return 2;\n      }\n      return 0;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/ECAdmin.java",
      "extendedDetails": {}
    },
    "1b5451bf054c335188e4cd66f7b4a1d80013e86d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11794. Add ec sub command -listCodec to show currently supported ec codecs. Contributed by SammiChen.\n",
      "commitDate": "23/05/17 4:33 AM",
      "commitName": "1b5451bf054c335188e4cd66f7b4a1d80013e86d",
      "commitAuthor": "Rakesh Radhakrishnan",
      "commitDateOld": "27/04/17 10:18 PM",
      "commitNameOld": "cb672a45a0bbd8950b9b5e304c2e03f516945903",
      "commitAuthorOld": "Kai Zheng",
      "daysBetweenCommits": 25.26,
      "commitsBetweenForRepo": 133,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,28 @@\n     public int run(Configuration conf, List\u003cString\u003e args) throws IOException {\n-      final String path \u003d StringUtils.popOptionWithArgument(\"-path\", args);\n-      if (path \u003d\u003d null) {\n-        System.err.println(\"Please specify a path.\\nUsage: \" + getLongUsage());\n-        return 1;\n-      }\n-\n       if (args.size() \u003e 0) {\n         System.err.println(getName() + \": Too many arguments\");\n         return 1;\n       }\n \n-      final Path p \u003d new Path(path);\n-      final DistributedFileSystem dfs \u003d AdminHelper.getDFS(p.toUri(), conf);\n+      final DistributedFileSystem dfs \u003d AdminHelper.getDFS(conf);\n       try {\n-        dfs.unsetErasureCodingPolicy(p);\n-        System.out.println(\"Unset erasure coding policy from \" + path);\n-      } catch (Exception e) {\n+        HashMap\u003cString, String\u003e codecs \u003d\n+            dfs.getAllErasureCodingCodecs();\n+        if (codecs.isEmpty()) {\n+          System.out.println(\"No erasure coding codecs are supported on the \" +\n+              \"cluster.\");\n+        } else {\n+          System.out.println(\"Erasure Coding Codecs: Codec [Coder List]\");\n+          for (Map.Entry\u003cString, String\u003e codec : codecs.entrySet()) {\n+            if (codec !\u003d null) {\n+              System.out.println(\"\\t\" + codec.getKey().toUpperCase() + \" [\"\n+                  + codec.getValue().toUpperCase() +\"]\");\n+            }\n+          }\n+        }\n+      } catch (IOException e) {\n         System.err.println(AdminHelper.prettifyException(e));\n         return 2;\n       }\n       return 0;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public int run(Configuration conf, List\u003cString\u003e args) throws IOException {\n      if (args.size() \u003e 0) {\n        System.err.println(getName() + \": Too many arguments\");\n        return 1;\n      }\n\n      final DistributedFileSystem dfs \u003d AdminHelper.getDFS(conf);\n      try {\n        HashMap\u003cString, String\u003e codecs \u003d\n            dfs.getAllErasureCodingCodecs();\n        if (codecs.isEmpty()) {\n          System.out.println(\"No erasure coding codecs are supported on the \" +\n              \"cluster.\");\n        } else {\n          System.out.println(\"Erasure Coding Codecs: Codec [Coder List]\");\n          for (Map.Entry\u003cString, String\u003e codec : codecs.entrySet()) {\n            if (codec !\u003d null) {\n              System.out.println(\"\\t\" + codec.getKey().toUpperCase() + \" [\"\n                  + codec.getValue().toUpperCase() +\"]\");\n            }\n          }\n        }\n      } catch (IOException e) {\n        System.err.println(AdminHelper.prettifyException(e));\n        return 2;\n      }\n      return 0;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/ECAdmin.java",
      "extendedDetails": {}
    },
    "132f758e3dbe3a3f11c0d9b2de8edbee594fb475": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-11426. Refactor EC CLI to be similar to storage policies CLI.\n",
      "commitDate": "23/02/17 4:00 PM",
      "commitName": "132f758e3dbe3a3f11c0d9b2de8edbee594fb475",
      "commitAuthor": "Andrew Wang",
      "diff": "@@ -0,0 +1,23 @@\n+    public int run(Configuration conf, List\u003cString\u003e args) throws IOException {\n+      final String path \u003d StringUtils.popOptionWithArgument(\"-path\", args);\n+      if (path \u003d\u003d null) {\n+        System.err.println(\"Please specify a path.\\nUsage: \" + getLongUsage());\n+        return 1;\n+      }\n+\n+      if (args.size() \u003e 0) {\n+        System.err.println(getName() + \": Too many arguments\");\n+        return 1;\n+      }\n+\n+      final Path p \u003d new Path(path);\n+      final DistributedFileSystem dfs \u003d AdminHelper.getDFS(p.toUri(), conf);\n+      try {\n+        dfs.unsetErasureCodingPolicy(p);\n+        System.out.println(\"Unset erasure coding policy from \" + path);\n+      } catch (Exception e) {\n+        System.err.println(AdminHelper.prettifyException(e));\n+        return 2;\n+      }\n+      return 0;\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    public int run(Configuration conf, List\u003cString\u003e args) throws IOException {\n      final String path \u003d StringUtils.popOptionWithArgument(\"-path\", args);\n      if (path \u003d\u003d null) {\n        System.err.println(\"Please specify a path.\\nUsage: \" + getLongUsage());\n        return 1;\n      }\n\n      if (args.size() \u003e 0) {\n        System.err.println(getName() + \": Too many arguments\");\n        return 1;\n      }\n\n      final Path p \u003d new Path(path);\n      final DistributedFileSystem dfs \u003d AdminHelper.getDFS(p.toUri(), conf);\n      try {\n        dfs.unsetErasureCodingPolicy(p);\n        System.out.println(\"Unset erasure coding policy from \" + path);\n      } catch (Exception e) {\n        System.err.println(AdminHelper.prettifyException(e));\n        return 2;\n      }\n      return 0;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/ECAdmin.java"
    }
  }
}