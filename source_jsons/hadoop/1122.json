{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DfsClientShmManager.java",
  "functionName": "allocSlotFromExistingShm",
  "functionId": "allocSlotFromExistingShm___blockId-ExtendedBlockId",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/shortcircuit/DfsClientShmManager.java",
  "functionStartLine": 121,
  "functionEndLine": 139,
  "numCommitsSeen": 15,
  "timeTaken": 2645,
  "changeHistory": [
    "39285e6a1978ea5e53bdc1b0aef62421382124a8",
    "6ee0539ede78b640f01c5eac18ded161182a7835",
    "d5a9a3daa0224249221ffa7b8bd5751ab2feca56",
    "490bb5ebd6c6d6f9c08fcad167f976687fc3aa42",
    "f93d99990a9a02ce693cd74466c2e5f127c1f560",
    "dd049a2f6097da189ccce2f5890a2b9bc77fa73f"
  ],
  "changeHistoryShort": {
    "39285e6a1978ea5e53bdc1b0aef62421382124a8": "Ybodychange",
    "6ee0539ede78b640f01c5eac18ded161182a7835": "Ybodychange",
    "d5a9a3daa0224249221ffa7b8bd5751ab2feca56": "Ybodychange",
    "490bb5ebd6c6d6f9c08fcad167f976687fc3aa42": "Yfilerename",
    "f93d99990a9a02ce693cd74466c2e5f127c1f560": "Yfilerename",
    "dd049a2f6097da189ccce2f5890a2b9bc77fa73f": "Yintroduced"
  },
  "changeHistoryDetails": {
    "39285e6a1978ea5e53bdc1b0aef62421382124a8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8971. Remove guards when calling LOG.debug() and LOG.trace() in client package. Contributed by Mingliang Liu.\n",
      "commitDate": "29/09/15 5:52 PM",
      "commitName": "39285e6a1978ea5e53bdc1b0aef62421382124a8",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "29/09/15 5:51 PM",
      "commitNameOld": "6ee0539ede78b640f01c5eac18ded161182a7835",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,19 @@\n     private Slot allocSlotFromExistingShm(ExtendedBlockId blockId) {\n       if (notFull.isEmpty()) {\n         return null;\n       }\n       Entry\u003cShmId, DfsClientShm\u003e entry \u003d notFull.firstEntry();\n       DfsClientShm shm \u003d entry.getValue();\n       ShmId shmId \u003d shm.getShmId();\n       Slot slot \u003d shm.allocAndRegisterSlot(blockId);\n       if (shm.isFull()) {\n-        if (LOG.isTraceEnabled()) {\n-          LOG.trace(this + \": pulled the last slot \" + slot.getSlotIdx() +\n-              \" out of \" + shm);\n-        }\n+        LOG.trace(\"{}: pulled the last slot {} out of {}\",\n+            this, slot.getSlotIdx(), shm);\n         DfsClientShm removedShm \u003d notFull.remove(shmId);\n         Preconditions.checkState(removedShm \u003d\u003d shm);\n         full.put(shmId, shm);\n       } else {\n-        if (LOG.isTraceEnabled()) {\n-          LOG.trace(this + \": pulled slot \" + slot.getSlotIdx() +\n-              \" out of \" + shm);\n-        }\n+        LOG.trace(\"{}: pulled slot {} out of {}\", this, slot.getSlotIdx(), shm);\n       }\n       return slot;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private Slot allocSlotFromExistingShm(ExtendedBlockId blockId) {\n      if (notFull.isEmpty()) {\n        return null;\n      }\n      Entry\u003cShmId, DfsClientShm\u003e entry \u003d notFull.firstEntry();\n      DfsClientShm shm \u003d entry.getValue();\n      ShmId shmId \u003d shm.getShmId();\n      Slot slot \u003d shm.allocAndRegisterSlot(blockId);\n      if (shm.isFull()) {\n        LOG.trace(\"{}: pulled the last slot {} out of {}\",\n            this, slot.getSlotIdx(), shm);\n        DfsClientShm removedShm \u003d notFull.remove(shmId);\n        Preconditions.checkState(removedShm \u003d\u003d shm);\n        full.put(shmId, shm);\n      } else {\n        LOG.trace(\"{}: pulled slot {} out of {}\", this, slot.getSlotIdx(), shm);\n      }\n      return slot;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/shortcircuit/DfsClientShmManager.java",
      "extendedDetails": {}
    },
    "6ee0539ede78b640f01c5eac18ded161182a7835": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-9170. Move libhdfs / fuse-dfs / libwebhdfs to hdfs-client. Contributed by Haohui Mai.\"\n\nThis reverts commit d5a9a3daa0224249221ffa7b8bd5751ab2feca56.\n",
      "commitDate": "29/09/15 5:51 PM",
      "commitName": "6ee0539ede78b640f01c5eac18ded161182a7835",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "29/09/15 5:48 PM",
      "commitNameOld": "d5a9a3daa0224249221ffa7b8bd5751ab2feca56",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,19 +1,24 @@\n     private Slot allocSlotFromExistingShm(ExtendedBlockId blockId) {\n       if (notFull.isEmpty()) {\n         return null;\n       }\n       Entry\u003cShmId, DfsClientShm\u003e entry \u003d notFull.firstEntry();\n       DfsClientShm shm \u003d entry.getValue();\n       ShmId shmId \u003d shm.getShmId();\n       Slot slot \u003d shm.allocAndRegisterSlot(blockId);\n       if (shm.isFull()) {\n-        LOG.trace(\"{}: pulled the last slot {} out of {}\",\n-            this, slot.getSlotIdx(), shm);\n+        if (LOG.isTraceEnabled()) {\n+          LOG.trace(this + \": pulled the last slot \" + slot.getSlotIdx() +\n+              \" out of \" + shm);\n+        }\n         DfsClientShm removedShm \u003d notFull.remove(shmId);\n         Preconditions.checkState(removedShm \u003d\u003d shm);\n         full.put(shmId, shm);\n       } else {\n-        LOG.trace(\"{}: pulled slot {} out of {}\", this, slot.getSlotIdx(), shm);\n+        if (LOG.isTraceEnabled()) {\n+          LOG.trace(this + \": pulled slot \" + slot.getSlotIdx() +\n+              \" out of \" + shm);\n+        }\n       }\n       return slot;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private Slot allocSlotFromExistingShm(ExtendedBlockId blockId) {\n      if (notFull.isEmpty()) {\n        return null;\n      }\n      Entry\u003cShmId, DfsClientShm\u003e entry \u003d notFull.firstEntry();\n      DfsClientShm shm \u003d entry.getValue();\n      ShmId shmId \u003d shm.getShmId();\n      Slot slot \u003d shm.allocAndRegisterSlot(blockId);\n      if (shm.isFull()) {\n        if (LOG.isTraceEnabled()) {\n          LOG.trace(this + \": pulled the last slot \" + slot.getSlotIdx() +\n              \" out of \" + shm);\n        }\n        DfsClientShm removedShm \u003d notFull.remove(shmId);\n        Preconditions.checkState(removedShm \u003d\u003d shm);\n        full.put(shmId, shm);\n      } else {\n        if (LOG.isTraceEnabled()) {\n          LOG.trace(this + \": pulled slot \" + slot.getSlotIdx() +\n              \" out of \" + shm);\n        }\n      }\n      return slot;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/shortcircuit/DfsClientShmManager.java",
      "extendedDetails": {}
    },
    "d5a9a3daa0224249221ffa7b8bd5751ab2feca56": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9170. Move libhdfs / fuse-dfs / libwebhdfs to hdfs-client. Contributed by Haohui Mai.\n",
      "commitDate": "29/09/15 5:48 PM",
      "commitName": "d5a9a3daa0224249221ffa7b8bd5751ab2feca56",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "22/08/15 1:31 PM",
      "commitNameOld": "490bb5ebd6c6d6f9c08fcad167f976687fc3aa42",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 38.18,
      "commitsBetweenForRepo": 247,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,19 @@\n     private Slot allocSlotFromExistingShm(ExtendedBlockId blockId) {\n       if (notFull.isEmpty()) {\n         return null;\n       }\n       Entry\u003cShmId, DfsClientShm\u003e entry \u003d notFull.firstEntry();\n       DfsClientShm shm \u003d entry.getValue();\n       ShmId shmId \u003d shm.getShmId();\n       Slot slot \u003d shm.allocAndRegisterSlot(blockId);\n       if (shm.isFull()) {\n-        if (LOG.isTraceEnabled()) {\n-          LOG.trace(this + \": pulled the last slot \" + slot.getSlotIdx() +\n-              \" out of \" + shm);\n-        }\n+        LOG.trace(\"{}: pulled the last slot {} out of {}\",\n+            this, slot.getSlotIdx(), shm);\n         DfsClientShm removedShm \u003d notFull.remove(shmId);\n         Preconditions.checkState(removedShm \u003d\u003d shm);\n         full.put(shmId, shm);\n       } else {\n-        if (LOG.isTraceEnabled()) {\n-          LOG.trace(this + \": pulled slot \" + slot.getSlotIdx() +\n-              \" out of \" + shm);\n-        }\n+        LOG.trace(\"{}: pulled slot {} out of {}\", this, slot.getSlotIdx(), shm);\n       }\n       return slot;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private Slot allocSlotFromExistingShm(ExtendedBlockId blockId) {\n      if (notFull.isEmpty()) {\n        return null;\n      }\n      Entry\u003cShmId, DfsClientShm\u003e entry \u003d notFull.firstEntry();\n      DfsClientShm shm \u003d entry.getValue();\n      ShmId shmId \u003d shm.getShmId();\n      Slot slot \u003d shm.allocAndRegisterSlot(blockId);\n      if (shm.isFull()) {\n        LOG.trace(\"{}: pulled the last slot {} out of {}\",\n            this, slot.getSlotIdx(), shm);\n        DfsClientShm removedShm \u003d notFull.remove(shmId);\n        Preconditions.checkState(removedShm \u003d\u003d shm);\n        full.put(shmId, shm);\n      } else {\n        LOG.trace(\"{}: pulled slot {} out of {}\", this, slot.getSlotIdx(), shm);\n      }\n      return slot;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/shortcircuit/DfsClientShmManager.java",
      "extendedDetails": {}
    },
    "490bb5ebd6c6d6f9c08fcad167f976687fc3aa42": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8934. Move ShortCircuitShm to hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "22/08/15 1:31 PM",
      "commitName": "490bb5ebd6c6d6f9c08fcad167f976687fc3aa42",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "22/08/15 12:39 AM",
      "commitNameOld": "61bf9cae6f3882c6e9a9222f59457b9be91e3018",
      "commitAuthorOld": "Karthik Kambatla",
      "daysBetweenCommits": 0.54,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    private Slot allocSlotFromExistingShm(ExtendedBlockId blockId) {\n      if (notFull.isEmpty()) {\n        return null;\n      }\n      Entry\u003cShmId, DfsClientShm\u003e entry \u003d notFull.firstEntry();\n      DfsClientShm shm \u003d entry.getValue();\n      ShmId shmId \u003d shm.getShmId();\n      Slot slot \u003d shm.allocAndRegisterSlot(blockId);\n      if (shm.isFull()) {\n        if (LOG.isTraceEnabled()) {\n          LOG.trace(this + \": pulled the last slot \" + slot.getSlotIdx() +\n              \" out of \" + shm);\n        }\n        DfsClientShm removedShm \u003d notFull.remove(shmId);\n        Preconditions.checkState(removedShm \u003d\u003d shm);\n        full.put(shmId, shm);\n      } else {\n        if (LOG.isTraceEnabled()) {\n          LOG.trace(this + \": pulled slot \" + slot.getSlotIdx() +\n              \" out of \" + shm);\n        }\n      }\n      return slot;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/shortcircuit/DfsClientShmManager.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/shortcircuit/DfsClientShmManager.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/shortcircuit/DfsClientShmManager.java"
      }
    },
    "f93d99990a9a02ce693cd74466c2e5f127c1f560": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-6167. Relocate the non-public API classes in the hdfs.client package.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1583878 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "01/04/14 10:09 PM",
      "commitName": "f93d99990a9a02ce693cd74466c2e5f127c1f560",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "01/04/14 6:00 PM",
      "commitNameOld": "5c7cb51775bd3d4a6e3e1bd501b3a8d747733fe3",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 0.17,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    private Slot allocSlotFromExistingShm(ExtendedBlockId blockId) {\n      if (notFull.isEmpty()) {\n        return null;\n      }\n      Entry\u003cShmId, DfsClientShm\u003e entry \u003d notFull.firstEntry();\n      DfsClientShm shm \u003d entry.getValue();\n      ShmId shmId \u003d shm.getShmId();\n      Slot slot \u003d shm.allocAndRegisterSlot(blockId);\n      if (shm.isFull()) {\n        if (LOG.isTraceEnabled()) {\n          LOG.trace(this + \": pulled the last slot \" + slot.getSlotIdx() +\n              \" out of \" + shm);\n        }\n        DfsClientShm removedShm \u003d notFull.remove(shmId);\n        Preconditions.checkState(removedShm \u003d\u003d shm);\n        full.put(shmId, shm);\n      } else {\n        if (LOG.isTraceEnabled()) {\n          LOG.trace(this + \": pulled slot \" + slot.getSlotIdx() +\n              \" out of \" + shm);\n        }\n      }\n      return slot;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/shortcircuit/DfsClientShmManager.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/client/DfsClientShmManager.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/shortcircuit/DfsClientShmManager.java"
      }
    },
    "dd049a2f6097da189ccce2f5890a2b9bc77fa73f": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-5950. The DFSClient and DataNode should use shared memory segments to communicate short-circuit information (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1573433 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/03/14 7:58 PM",
      "commitName": "dd049a2f6097da189ccce2f5890a2b9bc77fa73f",
      "commitAuthor": "Colin McCabe",
      "diff": "@@ -0,0 +1,24 @@\n+    private Slot allocSlotFromExistingShm(ExtendedBlockId blockId) {\n+      if (notFull.isEmpty()) {\n+        return null;\n+      }\n+      Entry\u003cShmId, DfsClientShm\u003e entry \u003d notFull.firstEntry();\n+      DfsClientShm shm \u003d entry.getValue();\n+      ShmId shmId \u003d shm.getShmId();\n+      Slot slot \u003d shm.allocAndRegisterSlot(blockId);\n+      if (shm.isFull()) {\n+        if (LOG.isTraceEnabled()) {\n+          LOG.trace(this + \": pulled the last slot \" + slot.getSlotIdx() +\n+              \" out of \" + shm);\n+        }\n+        DfsClientShm removedShm \u003d notFull.remove(shmId);\n+        Preconditions.checkState(removedShm \u003d\u003d shm);\n+        full.put(shmId, shm);\n+      } else {\n+        if (LOG.isTraceEnabled()) {\n+          LOG.trace(this + \": pulled slot \" + slot.getSlotIdx() +\n+              \" out of \" + shm);\n+        }\n+      }\n+      return slot;\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    private Slot allocSlotFromExistingShm(ExtendedBlockId blockId) {\n      if (notFull.isEmpty()) {\n        return null;\n      }\n      Entry\u003cShmId, DfsClientShm\u003e entry \u003d notFull.firstEntry();\n      DfsClientShm shm \u003d entry.getValue();\n      ShmId shmId \u003d shm.getShmId();\n      Slot slot \u003d shm.allocAndRegisterSlot(blockId);\n      if (shm.isFull()) {\n        if (LOG.isTraceEnabled()) {\n          LOG.trace(this + \": pulled the last slot \" + slot.getSlotIdx() +\n              \" out of \" + shm);\n        }\n        DfsClientShm removedShm \u003d notFull.remove(shmId);\n        Preconditions.checkState(removedShm \u003d\u003d shm);\n        full.put(shmId, shm);\n      } else {\n        if (LOG.isTraceEnabled()) {\n          LOG.trace(this + \": pulled slot \" + slot.getSlotIdx() +\n              \" out of \" + shm);\n        }\n      }\n      return slot;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/client/DfsClientShmManager.java"
    }
  }
}