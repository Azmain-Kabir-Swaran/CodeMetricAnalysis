{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "NameDistributionVisitor.java",
  "functionName": "finish",
  "functionId": "finish",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/NameDistributionVisitor.java",
  "functionStartLine": 47,
  "functionEndLine": 90,
  "numCommitsSeen": 5,
  "timeTaken": 1812,
  "changeHistory": [
    "97f58955a6045b373ab73653bf26ab5922b00cf3"
  ],
  "changeHistoryShort": {
    "97f58955a6045b373ab73653bf26ab5922b00cf3": "Yintroduced"
  },
  "changeHistoryDetails": {
    "97f58955a6045b373ab73653bf26ab5922b00cf3": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-6293. Issues with OIV processing PB-based fsimages. Contributed by Kihwal Lee.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1594439 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/05/14 6:15 PM",
      "commitName": "97f58955a6045b373ab73653bf26ab5922b00cf3",
      "commitAuthor": "Kihwal Lee",
      "diff": "@@ -0,0 +1,44 @@\n+  void finish() throws IOException {\n+    final int BYTEARRAY_OVERHEAD \u003d 24;\n+\n+    write(\"Total unique file names \" + counts.size());\n+    // Columns: Frequency of file occurrence, savings in heap, total files using\n+    // the name and number of file names\n+    final long stats[][] \u003d { { 100000, 0, 0, 0 },\n+                             { 10000, 0, 0, 0 },\n+                             { 1000, 0, 0, 0 },\n+                             { 100, 0, 0, 0 },\n+                             { 10, 0, 0, 0 },\n+                             { 5, 0, 0, 0 },\n+                             { 4, 0, 0, 0 },\n+                             { 3, 0, 0, 0 },\n+                             { 2, 0, 0, 0 }};\n+\n+    int highbound \u003d Integer.MIN_VALUE;\n+    for (Entry\u003cString, Integer\u003e entry : counts.entrySet()) {\n+      highbound \u003d Math.max(highbound, entry.getValue());\n+      for (int i \u003d 0; i \u003c stats.length; i++) {\n+        if (entry.getValue() \u003e\u003d stats[i][0]) {\n+          stats[i][1] +\u003d (BYTEARRAY_OVERHEAD + entry.getKey().length())\n+              * (entry.getValue() - 1);\n+          stats[i][2] +\u003d entry.getValue();\n+          stats[i][3]++;\n+          break;\n+        }\n+      }\n+    }\n+\n+    long lowbound \u003d 0;\n+    long totalsavings \u003d 0;\n+    for (long[] stat : stats) {\n+      lowbound \u003d stat[0];\n+      totalsavings +\u003d stat[1];\n+      String range \u003d lowbound \u003d\u003d highbound ? \" \" + lowbound :\n+          \" between \" + lowbound + \"-\" + highbound;\n+      write(\"\\n\" + stat[3] + \" names are used by \" + stat[2] + \" files\"\n+          + range + \" times. Heap savings ~\" + stat[1] + \" bytes.\");\n+      highbound \u003d (int) stat[0] - 1;\n+    }\n+    write(\"\\n\\nTotal saved heap ~\" + totalsavings + \"bytes.\\n\");\n+    super.finish();\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  void finish() throws IOException {\n    final int BYTEARRAY_OVERHEAD \u003d 24;\n\n    write(\"Total unique file names \" + counts.size());\n    // Columns: Frequency of file occurrence, savings in heap, total files using\n    // the name and number of file names\n    final long stats[][] \u003d { { 100000, 0, 0, 0 },\n                             { 10000, 0, 0, 0 },\n                             { 1000, 0, 0, 0 },\n                             { 100, 0, 0, 0 },\n                             { 10, 0, 0, 0 },\n                             { 5, 0, 0, 0 },\n                             { 4, 0, 0, 0 },\n                             { 3, 0, 0, 0 },\n                             { 2, 0, 0, 0 }};\n\n    int highbound \u003d Integer.MIN_VALUE;\n    for (Entry\u003cString, Integer\u003e entry : counts.entrySet()) {\n      highbound \u003d Math.max(highbound, entry.getValue());\n      for (int i \u003d 0; i \u003c stats.length; i++) {\n        if (entry.getValue() \u003e\u003d stats[i][0]) {\n          stats[i][1] +\u003d (BYTEARRAY_OVERHEAD + entry.getKey().length())\n              * (entry.getValue() - 1);\n          stats[i][2] +\u003d entry.getValue();\n          stats[i][3]++;\n          break;\n        }\n      }\n    }\n\n    long lowbound \u003d 0;\n    long totalsavings \u003d 0;\n    for (long[] stat : stats) {\n      lowbound \u003d stat[0];\n      totalsavings +\u003d stat[1];\n      String range \u003d lowbound \u003d\u003d highbound ? \" \" + lowbound :\n          \" between \" + lowbound + \"-\" + highbound;\n      write(\"\\n\" + stat[3] + \" names are used by \" + stat[2] + \" files\"\n          + range + \" times. Heap savings ~\" + stat[1] + \" bytes.\");\n      highbound \u003d (int) stat[0] - 1;\n    }\n    write(\"\\n\\nTotal saved heap ~\" + totalsavings + \"bytes.\\n\");\n    super.finish();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/NameDistributionVisitor.java"
    }
  }
}