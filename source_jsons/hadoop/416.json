{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockReaderRemote.java",
  "functionName": "writeReadResult",
  "functionId": "writeReadResult___out-OutputStream__statusCode-Status",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/client/impl/BlockReaderRemote.java",
  "functionStartLine": 341,
  "functionEndLine": 350,
  "numCommitsSeen": 50,
  "timeTaken": 2982,
  "changeHistory": [
    "8b281bce85474501868d68f8d5590a6086abb7b7",
    "f308561f1d885491b88db73ac63003202056d661",
    "826ae1c26d31f87d88efc920b271bec7eec2e17a",
    "9b4a7900c7dfc0590316eedaa97144f938885651",
    "40fe96546fcd68696076db67053f30d38a39a0d5"
  ],
  "changeHistoryShort": {
    "8b281bce85474501868d68f8d5590a6086abb7b7": "Ymovefromfile",
    "f308561f1d885491b88db73ac63003202056d661": "Yfilerename",
    "826ae1c26d31f87d88efc920b271bec7eec2e17a": "Yfilerename",
    "9b4a7900c7dfc0590316eedaa97144f938885651": "Ymultichange(Yparameterchange,Ybodychange)",
    "40fe96546fcd68696076db67053f30d38a39a0d5": "Yintroduced"
  },
  "changeHistoryDetails": {
    "8b281bce85474501868d68f8d5590a6086abb7b7": {
      "type": "Ymovefromfile",
      "commitMessage": "HDFS-10548. Remove the long deprecated BlockReaderRemote. Contributed by Kai Zheng\n",
      "commitDate": "02/07/16 8:56 PM",
      "commitName": "8b281bce85474501868d68f8d5590a6086abb7b7",
      "commitAuthor": "Kai Zheng",
      "commitDateOld": "01/07/16 3:53 PM",
      "commitNameOld": "0a5def155eff4564b5dc7685e7460952f51bbd24",
      "commitAuthorOld": "Ray Chiang",
      "daysBetweenCommits": 1.21,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  static void writeReadResult(OutputStream out, Status statusCode)\n      throws IOException {\n\n    ClientReadStatusProto.newBuilder()\n        .setStatus(statusCode)\n        .build()\n        .writeDelimitedTo(out);\n\n    out.flush();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/client/impl/BlockReaderRemote.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/client/impl/BlockReaderRemote2.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/client/impl/BlockReaderRemote.java",
        "oldMethodName": "writeReadResult",
        "newMethodName": "writeReadResult"
      }
    },
    "f308561f1d885491b88db73ac63003202056d661": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8057 Move BlockReader implementation to the client implementation package.  Contributed by Takanobu Asanuma\n",
      "commitDate": "25/04/16 12:01 PM",
      "commitName": "f308561f1d885491b88db73ac63003202056d661",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "25/04/16 9:38 AM",
      "commitNameOld": "10f0f7851a3255caab775777e8fb6c2781d97062",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 0.1,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  static void writeReadResult(OutputStream out, Status statusCode)\n      throws IOException {\n\n    ClientReadStatusProto.newBuilder()\n        .setStatus(statusCode)\n        .build()\n        .writeDelimitedTo(out);\n\n    out.flush();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/client/impl/BlockReaderRemote2.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/RemoteBlockReader2.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/client/impl/BlockReaderRemote2.java"
      }
    },
    "826ae1c26d31f87d88efc920b271bec7eec2e17a": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8990. Move RemoteBlockReader to hdfs-client module. Contributed by Mingliang Liu.\n",
      "commitDate": "31/08/15 1:54 PM",
      "commitName": "826ae1c26d31f87d88efc920b271bec7eec2e17a",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "31/08/15 11:48 AM",
      "commitNameOld": "caa04de149030691b7bc952b534c6128db217ed2",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 0.09,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  static void writeReadResult(OutputStream out, Status statusCode)\n      throws IOException {\n    \n    ClientReadStatusProto.newBuilder()\n      .setStatus(statusCode)\n      .build()\n      .writeDelimitedTo(out);\n\n    out.flush();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/RemoteBlockReader2.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/RemoteBlockReader2.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/RemoteBlockReader2.java"
      }
    },
    "9b4a7900c7dfc0590316eedaa97144f938885651": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-3637. Add support for encrypting the DataTransferProtocol. Contributed by Aaron T. Myers.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1370354 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/08/12 9:40 AM",
      "commitName": "9b4a7900c7dfc0590316eedaa97144f938885651",
      "commitAuthor": "Aaron Myers",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-3637. Add support for encrypting the DataTransferProtocol. Contributed by Aaron T. Myers.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1370354 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "07/08/12 9:40 AM",
          "commitName": "9b4a7900c7dfc0590316eedaa97144f938885651",
          "commitAuthor": "Aaron Myers",
          "commitDateOld": "03/05/12 2:57 PM",
          "commitNameOld": "03181022ab238b2d4f59932eb8eadbe7cb52a669",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 95.78,
          "commitsBetweenForRepo": 490,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,10 @@\n-  static void writeReadResult(Socket sock, Status statusCode)\n+  static void writeReadResult(OutputStream out, Status statusCode)\n       throws IOException {\n-    OutputStream out \u003d NetUtils.getOutputStream(sock, HdfsServerConstants.WRITE_TIMEOUT);\n     \n     ClientReadStatusProto.newBuilder()\n       .setStatus(statusCode)\n       .build()\n       .writeDelimitedTo(out);\n \n     out.flush();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static void writeReadResult(OutputStream out, Status statusCode)\n      throws IOException {\n    \n    ClientReadStatusProto.newBuilder()\n      .setStatus(statusCode)\n      .build()\n      .writeDelimitedTo(out);\n\n    out.flush();\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/RemoteBlockReader2.java",
          "extendedDetails": {
            "oldValue": "[sock-Socket, statusCode-Status]",
            "newValue": "[out-OutputStream, statusCode-Status]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-3637. Add support for encrypting the DataTransferProtocol. Contributed by Aaron T. Myers.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1370354 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "07/08/12 9:40 AM",
          "commitName": "9b4a7900c7dfc0590316eedaa97144f938885651",
          "commitAuthor": "Aaron Myers",
          "commitDateOld": "03/05/12 2:57 PM",
          "commitNameOld": "03181022ab238b2d4f59932eb8eadbe7cb52a669",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 95.78,
          "commitsBetweenForRepo": 490,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,10 @@\n-  static void writeReadResult(Socket sock, Status statusCode)\n+  static void writeReadResult(OutputStream out, Status statusCode)\n       throws IOException {\n-    OutputStream out \u003d NetUtils.getOutputStream(sock, HdfsServerConstants.WRITE_TIMEOUT);\n     \n     ClientReadStatusProto.newBuilder()\n       .setStatus(statusCode)\n       .build()\n       .writeDelimitedTo(out);\n \n     out.flush();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static void writeReadResult(OutputStream out, Status statusCode)\n      throws IOException {\n    \n    ClientReadStatusProto.newBuilder()\n      .setStatus(statusCode)\n      .build()\n      .writeDelimitedTo(out);\n\n    out.flush();\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/RemoteBlockReader2.java",
          "extendedDetails": {}
        }
      ]
    },
    "40fe96546fcd68696076db67053f30d38a39a0d5": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-2129. Simplify BlockReader to not inherit from FSInputChecker. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1196976 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/11/11 11:54 PM",
      "commitName": "40fe96546fcd68696076db67053f30d38a39a0d5",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,11 @@\n+  static void writeReadResult(Socket sock, Status statusCode)\n+      throws IOException {\n+    OutputStream out \u003d NetUtils.getOutputStream(sock, HdfsServerConstants.WRITE_TIMEOUT);\n+    \n+    ClientReadStatusProto.newBuilder()\n+      .setStatus(statusCode)\n+      .build()\n+      .writeDelimitedTo(out);\n+\n+    out.flush();\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  static void writeReadResult(Socket sock, Status statusCode)\n      throws IOException {\n    OutputStream out \u003d NetUtils.getOutputStream(sock, HdfsServerConstants.WRITE_TIMEOUT);\n    \n    ClientReadStatusProto.newBuilder()\n      .setStatus(statusCode)\n      .build()\n      .writeDelimitedTo(out);\n\n    out.flush();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/RemoteBlockReader2.java"
    }
  }
}