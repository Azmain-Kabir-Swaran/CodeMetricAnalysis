{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "HistoryFileManager.java",
  "functionName": "initExisting",
  "functionId": "initExisting",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/HistoryFileManager.java",
  "functionStartLine": 784,
  "functionEndLine": 812,
  "numCommitsSeen": 57,
  "timeTaken": 8476,
  "changeHistory": [
    "0d6778d800ff16366911e3b064f3af6162dee2e4",
    "fd57ab2002f97dcc83d455a5e0c770c8efde77a4",
    "7d04a96027ad75877b41b7cd8f67455dd13159d7",
    "cbb5f6109097a77f18f5fb0ba62ac132b8fa980f",
    "be32d25c546a7d4f98604e142940c483213b485b",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517"
  ],
  "changeHistoryShort": {
    "0d6778d800ff16366911e3b064f3af6162dee2e4": "Ybodychange",
    "fd57ab2002f97dcc83d455a5e0c770c8efde77a4": "Ybodychange",
    "7d04a96027ad75877b41b7cd8f67455dd13159d7": "Ybodychange",
    "cbb5f6109097a77f18f5fb0ba62ac132b8fa980f": "Ymultichange(Ymovefromfile,Ymodifierchange)",
    "be32d25c546a7d4f98604e142940c483213b485b": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yintroduced"
  },
  "changeHistoryDetails": {
    "0d6778d800ff16366911e3b064f3af6162dee2e4": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6718. add progress log to JHS during startup (haibochen via rkanter)\n",
      "commitDate": "28/09/16 3:41 PM",
      "commitName": "0d6778d800ff16366911e3b064f3af6162dee2e4",
      "commitAuthor": "Robert Kanter",
      "commitDateOld": "15/07/16 1:30 PM",
      "commitNameOld": "0881ed3fc313abda2896d3f26769690f5ba37346",
      "commitAuthorOld": "Robert Kanter",
      "daysBetweenCommits": 75.09,
      "commitsBetweenForRepo": 465,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,15 +1,29 @@\n   void initExisting() throws IOException {\n     LOG.info(\"Initializing Existing Jobs...\");\n     List\u003cFileStatus\u003e timestampedDirList \u003d findTimestampedDirectories();\n     // Sort first just so insertion is in a consistent order\n     Collections.sort(timestampedDirList);\n+    LOG.info(\"Found \" + timestampedDirList.size() + \" directories to load\");\n     for (FileStatus fs : timestampedDirList) {\n       // TODO Could verify the correct format for these directories.\n       addDirectoryToSerialNumberIndex(fs.getPath());\n     }\n+    final double maxCacheSize \u003d (double) jobListCache.maxSize;\n+    int prevCacheSize \u003d jobListCache.size();\n     for (int i\u003d timestampedDirList.size() - 1;\n         i \u003e\u003d 0 \u0026\u0026 !jobListCache.isFull(); i--) {\n       FileStatus fs \u003d timestampedDirList.get(i); \n       addDirectoryToJobListCache(fs.getPath());\n+\n+      int currCacheSize \u003d jobListCache.size();\n+      if((currCacheSize - prevCacheSize)/maxCacheSize \u003e\u003d 0.05) {\n+        LOG.info(currCacheSize * 100.0 / maxCacheSize +\n+            \"% of cache is loaded.\");\n+      }\n+      prevCacheSize \u003d currCacheSize;\n     }\n+    final double loadedPercent \u003d maxCacheSize \u003d\u003d 0.0 ?\n+        100 : prevCacheSize * 100.0 / maxCacheSize;\n+    LOG.info(\"Existing job initialization finished. \" +\n+        loadedPercent + \"% of cache is occupied.\");\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void initExisting() throws IOException {\n    LOG.info(\"Initializing Existing Jobs...\");\n    List\u003cFileStatus\u003e timestampedDirList \u003d findTimestampedDirectories();\n    // Sort first just so insertion is in a consistent order\n    Collections.sort(timestampedDirList);\n    LOG.info(\"Found \" + timestampedDirList.size() + \" directories to load\");\n    for (FileStatus fs : timestampedDirList) {\n      // TODO Could verify the correct format for these directories.\n      addDirectoryToSerialNumberIndex(fs.getPath());\n    }\n    final double maxCacheSize \u003d (double) jobListCache.maxSize;\n    int prevCacheSize \u003d jobListCache.size();\n    for (int i\u003d timestampedDirList.size() - 1;\n        i \u003e\u003d 0 \u0026\u0026 !jobListCache.isFull(); i--) {\n      FileStatus fs \u003d timestampedDirList.get(i); \n      addDirectoryToJobListCache(fs.getPath());\n\n      int currCacheSize \u003d jobListCache.size();\n      if((currCacheSize - prevCacheSize)/maxCacheSize \u003e\u003d 0.05) {\n        LOG.info(currCacheSize * 100.0 / maxCacheSize +\n            \"% of cache is loaded.\");\n      }\n      prevCacheSize \u003d currCacheSize;\n    }\n    final double loadedPercent \u003d maxCacheSize \u003d\u003d 0.0 ?\n        100 : prevCacheSize * 100.0 / maxCacheSize;\n    LOG.info(\"Existing job initialization finished. \" +\n        loadedPercent + \"% of cache is occupied.\");\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/HistoryFileManager.java",
      "extendedDetails": {}
    },
    "fd57ab2002f97dcc83d455a5e0c770c8efde77a4": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6059. Speed up history server startup time (Siqi Li via aw)\n",
      "commitDate": "04/02/15 5:36 PM",
      "commitName": "fd57ab2002f97dcc83d455a5e0c770c8efde77a4",
      "commitAuthor": "Allen Wittenauer",
      "commitDateOld": "09/12/14 10:46 AM",
      "commitNameOld": "d777a1e4ca8e7cf0ce8967f79dd475468906c733",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 57.28,
      "commitsBetweenForRepo": 369,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,11 +1,15 @@\n   void initExisting() throws IOException {\n     LOG.info(\"Initializing Existing Jobs...\");\n     List\u003cFileStatus\u003e timestampedDirList \u003d findTimestampedDirectories();\n     // Sort first just so insertion is in a consistent order\n     Collections.sort(timestampedDirList);\n     for (FileStatus fs : timestampedDirList) {\n       // TODO Could verify the correct format for these directories.\n       addDirectoryToSerialNumberIndex(fs.getPath());\n+    }\n+    for (int i\u003d timestampedDirList.size() - 1;\n+        i \u003e\u003d 0 \u0026\u0026 !jobListCache.isFull(); i--) {\n+      FileStatus fs \u003d timestampedDirList.get(i); \n       addDirectoryToJobListCache(fs.getPath());\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void initExisting() throws IOException {\n    LOG.info(\"Initializing Existing Jobs...\");\n    List\u003cFileStatus\u003e timestampedDirList \u003d findTimestampedDirectories();\n    // Sort first just so insertion is in a consistent order\n    Collections.sort(timestampedDirList);\n    for (FileStatus fs : timestampedDirList) {\n      // TODO Could verify the correct format for these directories.\n      addDirectoryToSerialNumberIndex(fs.getPath());\n    }\n    for (int i\u003d timestampedDirList.size() - 1;\n        i \u003e\u003d 0 \u0026\u0026 !jobListCache.isFull(); i--) {\n      FileStatus fs \u003d timestampedDirList.get(i); \n      addDirectoryToJobListCache(fs.getPath());\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/HistoryFileManager.java",
      "extendedDetails": {}
    },
    "7d04a96027ad75877b41b7cd8f67455dd13159d7": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3972. Fix locking and exception issues in JobHistory server. (Contributed by Robert Joseph Evans)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1327354 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/04/12 6:59 PM",
      "commitName": "7d04a96027ad75877b41b7cd8f67455dd13159d7",
      "commitAuthor": "Siddharth Seth",
      "commitDateOld": "10/04/12 11:11 AM",
      "commitNameOld": "cbb5f6109097a77f18f5fb0ba62ac132b8fa980f",
      "commitAuthorOld": "Thomas Graves",
      "daysBetweenCommits": 7.32,
      "commitsBetweenForRepo": 59,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,10 +1,11 @@\n   void initExisting() throws IOException {\n     LOG.info(\"Initializing Existing Jobs...\");\n     List\u003cFileStatus\u003e timestampedDirList \u003d findTimestampedDirectories();\n+    // Sort first just so insertion is in a consistent order\n     Collections.sort(timestampedDirList);\n     for (FileStatus fs : timestampedDirList) {\n       // TODO Could verify the correct format for these directories.\n       addDirectoryToSerialNumberIndex(fs.getPath());\n       addDirectoryToJobListCache(fs.getPath());\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void initExisting() throws IOException {\n    LOG.info(\"Initializing Existing Jobs...\");\n    List\u003cFileStatus\u003e timestampedDirList \u003d findTimestampedDirectories();\n    // Sort first just so insertion is in a consistent order\n    Collections.sort(timestampedDirList);\n    for (FileStatus fs : timestampedDirList) {\n      // TODO Could verify the correct format for these directories.\n      addDirectoryToSerialNumberIndex(fs.getPath());\n      addDirectoryToJobListCache(fs.getPath());\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/HistoryFileManager.java",
      "extendedDetails": {}
    },
    "cbb5f6109097a77f18f5fb0ba62ac132b8fa980f": {
      "type": "Ymultichange(Ymovefromfile,Ymodifierchange)",
      "commitMessage": "MAPREDUCE-4059. The history server should have a separate pluggable storage/query interface. (Robert Evans via tgraves).\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1311896 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/04/12 11:11 AM",
      "commitName": "cbb5f6109097a77f18f5fb0ba62ac132b8fa980f",
      "commitAuthor": "Thomas Graves",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "MAPREDUCE-4059. The history server should have a separate pluggable storage/query interface. (Robert Evans via tgraves).\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1311896 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "10/04/12 11:11 AM",
          "commitName": "cbb5f6109097a77f18f5fb0ba62ac132b8fa980f",
          "commitAuthor": "Thomas Graves",
          "commitDateOld": "10/04/12 9:13 AM",
          "commitNameOld": "000859a534f4cc6a57524a676805d8af6ad199de",
          "commitAuthorOld": "Robert Joseph Evans",
          "daysBetweenCommits": 0.08,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,10 +1,10 @@\n-  private void initExisting() throws IOException {\n+  void initExisting() throws IOException {\n     LOG.info(\"Initializing Existing Jobs...\");\n     List\u003cFileStatus\u003e timestampedDirList \u003d findTimestampedDirectories();\n     Collections.sort(timestampedDirList);\n     for (FileStatus fs : timestampedDirList) {\n-      //TODO Could verify the correct format for these directories.\n+      // TODO Could verify the correct format for these directories.\n       addDirectoryToSerialNumberIndex(fs.getPath());\n       addDirectoryToJobListCache(fs.getPath());\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  void initExisting() throws IOException {\n    LOG.info(\"Initializing Existing Jobs...\");\n    List\u003cFileStatus\u003e timestampedDirList \u003d findTimestampedDirectories();\n    Collections.sort(timestampedDirList);\n    for (FileStatus fs : timestampedDirList) {\n      // TODO Could verify the correct format for these directories.\n      addDirectoryToSerialNumberIndex(fs.getPath());\n      addDirectoryToJobListCache(fs.getPath());\n    }\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/HistoryFileManager.java",
          "extendedDetails": {
            "oldPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java",
            "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/HistoryFileManager.java",
            "oldMethodName": "initExisting",
            "newMethodName": "initExisting"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "MAPREDUCE-4059. The history server should have a separate pluggable storage/query interface. (Robert Evans via tgraves).\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1311896 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "10/04/12 11:11 AM",
          "commitName": "cbb5f6109097a77f18f5fb0ba62ac132b8fa980f",
          "commitAuthor": "Thomas Graves",
          "commitDateOld": "10/04/12 9:13 AM",
          "commitNameOld": "000859a534f4cc6a57524a676805d8af6ad199de",
          "commitAuthorOld": "Robert Joseph Evans",
          "daysBetweenCommits": 0.08,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,10 +1,10 @@\n-  private void initExisting() throws IOException {\n+  void initExisting() throws IOException {\n     LOG.info(\"Initializing Existing Jobs...\");\n     List\u003cFileStatus\u003e timestampedDirList \u003d findTimestampedDirectories();\n     Collections.sort(timestampedDirList);\n     for (FileStatus fs : timestampedDirList) {\n-      //TODO Could verify the correct format for these directories.\n+      // TODO Could verify the correct format for these directories.\n       addDirectoryToSerialNumberIndex(fs.getPath());\n       addDirectoryToJobListCache(fs.getPath());\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  void initExisting() throws IOException {\n    LOG.info(\"Initializing Existing Jobs...\");\n    List\u003cFileStatus\u003e timestampedDirList \u003d findTimestampedDirectories();\n    Collections.sort(timestampedDirList);\n    for (FileStatus fs : timestampedDirList) {\n      // TODO Could verify the correct format for these directories.\n      addDirectoryToSerialNumberIndex(fs.getPath());\n      addDirectoryToJobListCache(fs.getPath());\n    }\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/HistoryFileManager.java",
          "extendedDetails": {
            "oldValue": "[private]",
            "newValue": "[]"
          }
        }
      ]
    },
    "be32d25c546a7d4f98604e142940c483213b485b": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-2675. Reformat JobHistory Server main page to be more useful. Contributed by Robert Joseph Evans.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1169763 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/09/11 7:24 AM",
      "commitName": "be32d25c546a7d4f98604e142940c483213b485b",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "08/09/11 6:44 PM",
      "commitNameOld": "fafe8cd28e726566509c679e19d7da622f29f90d",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 3.53,
      "commitsBetweenForRepo": 19,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,9 +1,10 @@\n   private void initExisting() throws IOException {\n+    LOG.info(\"Initializing Existing Jobs...\");\n     List\u003cFileStatus\u003e timestampedDirList \u003d findTimestampedDirectories();\n     Collections.sort(timestampedDirList);\n     for (FileStatus fs : timestampedDirList) {\n       //TODO Could verify the correct format for these directories.\n       addDirectoryToSerialNumberIndex(fs.getPath());\n       addDirectoryToJobListCache(fs.getPath());\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void initExisting() throws IOException {\n    LOG.info(\"Initializing Existing Jobs...\");\n    List\u003cFileStatus\u003e timestampedDirList \u003d findTimestampedDirectories();\n    Collections.sort(timestampedDirList);\n    for (FileStatus fs : timestampedDirList) {\n      //TODO Could verify the correct format for these directories.\n      addDirectoryToSerialNumberIndex(fs.getPath());\n      addDirectoryToJobListCache(fs.getPath());\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private void initExisting() throws IOException {\n    List\u003cFileStatus\u003e timestampedDirList \u003d findTimestampedDirectories();\n    Collections.sort(timestampedDirList);\n    for (FileStatus fs : timestampedDirList) {\n      //TODO Could verify the correct format for these directories.\n      addDirectoryToSerialNumberIndex(fs.getPath());\n      addDirectoryToJobListCache(fs.getPath());\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java",
        "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "diff": "@@ -0,0 +1,9 @@\n+  private void initExisting() throws IOException {\n+    List\u003cFileStatus\u003e timestampedDirList \u003d findTimestampedDirectories();\n+    Collections.sort(timestampedDirList);\n+    for (FileStatus fs : timestampedDirList) {\n+      //TODO Could verify the correct format for these directories.\n+      addDirectoryToSerialNumberIndex(fs.getPath());\n+      addDirectoryToJobListCache(fs.getPath());\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void initExisting() throws IOException {\n    List\u003cFileStatus\u003e timestampedDirList \u003d findTimestampedDirectories();\n    Collections.sort(timestampedDirList);\n    for (FileStatus fs : timestampedDirList) {\n      //TODO Could verify the correct format for these directories.\n      addDirectoryToSerialNumberIndex(fs.getPath());\n      addDirectoryToJobListCache(fs.getPath());\n    }\n  }",
      "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java"
    }
  }
}