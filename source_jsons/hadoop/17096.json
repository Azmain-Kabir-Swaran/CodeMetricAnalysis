{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "RBFMetrics.java",
  "functionName": "getNodeUsage",
  "functionId": "getNodeUsage",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/metrics/RBFMetrics.java",
  "functionStartLine": 495,
  "functionEndLine": 538,
  "numCommitsSeen": 21,
  "timeTaken": 4206,
  "changeHistory": [
    "ade8d3b60ecdab55bd61a71905ea3dbba0922f3e",
    "04caaba4884cdea9f3b97f819fe6599ab3d6f151",
    "c4d3636c21acaeb2b7d56d19cd4996aa25151bd1",
    "a71656c1c1bf6c680f1382a76ddcac870061f320",
    "6e2b5fa493ff8e8c2bb28e6f6f4c19347bc9b99d",
    "81601dac8ec7650bec14700b174910390a92fe1f",
    "bc9e588a19c0aaf518de8dab719362be4a8d6a54"
  ],
  "changeHistoryShort": {
    "ade8d3b60ecdab55bd61a71905ea3dbba0922f3e": "Yfilerename",
    "04caaba4884cdea9f3b97f819fe6599ab3d6f151": "Ybodychange",
    "c4d3636c21acaeb2b7d56d19cd4996aa25151bd1": "Ybodychange",
    "a71656c1c1bf6c680f1382a76ddcac870061f320": "Ybodychange",
    "6e2b5fa493ff8e8c2bb28e6f6f4c19347bc9b99d": "Yfilerename",
    "81601dac8ec7650bec14700b174910390a92fe1f": "Ybodychange",
    "bc9e588a19c0aaf518de8dab719362be4a8d6a54": "Yintroduced"
  },
  "changeHistoryDetails": {
    "ade8d3b60ecdab55bd61a71905ea3dbba0922f3e": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-14508. RBF: Clean-up and refactor UI components. Contributed by Takanobu Asanuma.\n",
      "commitDate": "24/06/19 9:33 AM",
      "commitName": "ade8d3b60ecdab55bd61a71905ea3dbba0922f3e",
      "commitAuthor": "Ayush Saxena",
      "commitDateOld": "24/06/19 9:33 AM",
      "commitNameOld": "6915d7e13c2afbb2738176ba55ea0774f25e1264",
      "commitAuthorOld": "Ayush Saxena",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public String getNodeUsage() {\n    float median \u003d 0;\n    float max \u003d 0;\n    float min \u003d 0;\n    float dev \u003d 0;\n\n    final Map\u003cString, Map\u003cString, Object\u003e\u003e info \u003d new HashMap\u003c\u003e();\n    try {\n      RouterRpcServer rpcServer \u003d this.router.getRpcServer();\n      DatanodeInfo[] live \u003d rpcServer.getDatanodeReport(\n          DatanodeReportType.LIVE, false, timeOut);\n\n      if (live.length \u003e 0) {\n        float totalDfsUsed \u003d 0;\n        float[] usages \u003d new float[live.length];\n        int i \u003d 0;\n        for (DatanodeInfo dn : live) {\n          usages[i++] \u003d dn.getDfsUsedPercent();\n          totalDfsUsed +\u003d dn.getDfsUsedPercent();\n        }\n        totalDfsUsed /\u003d live.length;\n        Arrays.sort(usages);\n        median \u003d usages[usages.length / 2];\n        max \u003d usages[usages.length - 1];\n        min \u003d usages[0];\n\n        for (i \u003d 0; i \u003c usages.length; i++) {\n          dev +\u003d (usages[i] - totalDfsUsed) * (usages[i] - totalDfsUsed);\n        }\n        dev \u003d (float) Math.sqrt(dev / usages.length);\n      }\n    } catch (IOException e) {\n      LOG.error(\"Cannot get the live nodes: {}\", e.getMessage());\n    }\n\n    final Map\u003cString, Object\u003e innerInfo \u003d new HashMap\u003c\u003e();\n    innerInfo.put(\"min\", StringUtils.format(\"%.2f%%\", min));\n    innerInfo.put(\"median\", StringUtils.format(\"%.2f%%\", median));\n    innerInfo.put(\"max\", StringUtils.format(\"%.2f%%\", max));\n    innerInfo.put(\"stdDev\", StringUtils.format(\"%.2f%%\", dev));\n    info.put(\"nodeUsage\", innerInfo);\n\n    return JSON.toString(info);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/metrics/RBFMetrics.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/metrics/FederationMetrics.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/metrics/RBFMetrics.java"
      }
    },
    "04caaba4884cdea9f3b97f819fe6599ab3d6f151": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13852. RBF: The DN_REPORT_TIME_OUT and DN_REPORT_CACHE_EXPIRE should be configured in RBFConfigKeys. Contributed by yanghuafeng.\n",
      "commitDate": "24/06/19 9:33 AM",
      "commitName": "04caaba4884cdea9f3b97f819fe6599ab3d6f151",
      "commitAuthor": "Inigo Goiri",
      "commitDateOld": "26/04/18 1:54 PM",
      "commitNameOld": "48269c370c8981244b9d3d5cf1c82a2897ca502e",
      "commitAuthorOld": "Yiqun Lin",
      "daysBetweenCommits": 423.82,
      "commitsBetweenForRepo": 3189,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,44 +1,44 @@\n   public String getNodeUsage() {\n     float median \u003d 0;\n     float max \u003d 0;\n     float min \u003d 0;\n     float dev \u003d 0;\n \n     final Map\u003cString, Map\u003cString, Object\u003e\u003e info \u003d new HashMap\u003c\u003e();\n     try {\n       RouterRpcServer rpcServer \u003d this.router.getRpcServer();\n       DatanodeInfo[] live \u003d rpcServer.getDatanodeReport(\n-          DatanodeReportType.LIVE, false, TIME_OUT);\n+          DatanodeReportType.LIVE, false, timeOut);\n \n       if (live.length \u003e 0) {\n         float totalDfsUsed \u003d 0;\n         float[] usages \u003d new float[live.length];\n         int i \u003d 0;\n         for (DatanodeInfo dn : live) {\n           usages[i++] \u003d dn.getDfsUsedPercent();\n           totalDfsUsed +\u003d dn.getDfsUsedPercent();\n         }\n         totalDfsUsed /\u003d live.length;\n         Arrays.sort(usages);\n         median \u003d usages[usages.length / 2];\n         max \u003d usages[usages.length - 1];\n         min \u003d usages[0];\n \n         for (i \u003d 0; i \u003c usages.length; i++) {\n           dev +\u003d (usages[i] - totalDfsUsed) * (usages[i] - totalDfsUsed);\n         }\n         dev \u003d (float) Math.sqrt(dev / usages.length);\n       }\n     } catch (IOException e) {\n       LOG.error(\"Cannot get the live nodes: {}\", e.getMessage());\n     }\n \n     final Map\u003cString, Object\u003e innerInfo \u003d new HashMap\u003c\u003e();\n     innerInfo.put(\"min\", StringUtils.format(\"%.2f%%\", min));\n     innerInfo.put(\"median\", StringUtils.format(\"%.2f%%\", median));\n     innerInfo.put(\"max\", StringUtils.format(\"%.2f%%\", max));\n     innerInfo.put(\"stdDev\", StringUtils.format(\"%.2f%%\", dev));\n     info.put(\"nodeUsage\", innerInfo);\n \n     return JSON.toString(info);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public String getNodeUsage() {\n    float median \u003d 0;\n    float max \u003d 0;\n    float min \u003d 0;\n    float dev \u003d 0;\n\n    final Map\u003cString, Map\u003cString, Object\u003e\u003e info \u003d new HashMap\u003c\u003e();\n    try {\n      RouterRpcServer rpcServer \u003d this.router.getRpcServer();\n      DatanodeInfo[] live \u003d rpcServer.getDatanodeReport(\n          DatanodeReportType.LIVE, false, timeOut);\n\n      if (live.length \u003e 0) {\n        float totalDfsUsed \u003d 0;\n        float[] usages \u003d new float[live.length];\n        int i \u003d 0;\n        for (DatanodeInfo dn : live) {\n          usages[i++] \u003d dn.getDfsUsedPercent();\n          totalDfsUsed +\u003d dn.getDfsUsedPercent();\n        }\n        totalDfsUsed /\u003d live.length;\n        Arrays.sort(usages);\n        median \u003d usages[usages.length / 2];\n        max \u003d usages[usages.length - 1];\n        min \u003d usages[0];\n\n        for (i \u003d 0; i \u003c usages.length; i++) {\n          dev +\u003d (usages[i] - totalDfsUsed) * (usages[i] - totalDfsUsed);\n        }\n        dev \u003d (float) Math.sqrt(dev / usages.length);\n      }\n    } catch (IOException e) {\n      LOG.error(\"Cannot get the live nodes: {}\", e.getMessage());\n    }\n\n    final Map\u003cString, Object\u003e innerInfo \u003d new HashMap\u003c\u003e();\n    innerInfo.put(\"min\", StringUtils.format(\"%.2f%%\", min));\n    innerInfo.put(\"median\", StringUtils.format(\"%.2f%%\", median));\n    innerInfo.put(\"max\", StringUtils.format(\"%.2f%%\", max));\n    innerInfo.put(\"stdDev\", StringUtils.format(\"%.2f%%\", dev));\n    info.put(\"nodeUsage\", innerInfo);\n\n    return JSON.toString(info);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/metrics/FederationMetrics.java",
      "extendedDetails": {}
    },
    "c4d3636c21acaeb2b7d56d19cd4996aa25151bd1": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13435. RBF: Improve the error loggings for printing the stack trace.\n",
      "commitDate": "16/04/18 8:23 PM",
      "commitName": "c4d3636c21acaeb2b7d56d19cd4996aa25151bd1",
      "commitAuthor": "Yiqun Lin",
      "commitDateOld": "27/03/18 8:00 PM",
      "commitNameOld": "a71656c1c1bf6c680f1382a76ddcac870061f320",
      "commitAuthorOld": "Yiqun Lin",
      "daysBetweenCommits": 20.02,
      "commitsBetweenForRepo": 120,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,44 +1,44 @@\n   public String getNodeUsage() {\n     float median \u003d 0;\n     float max \u003d 0;\n     float min \u003d 0;\n     float dev \u003d 0;\n \n     final Map\u003cString, Map\u003cString, Object\u003e\u003e info \u003d new HashMap\u003c\u003e();\n     try {\n       RouterRpcServer rpcServer \u003d this.router.getRpcServer();\n       DatanodeInfo[] live \u003d rpcServer.getDatanodeReport(\n           DatanodeReportType.LIVE, false, TIME_OUT);\n \n       if (live.length \u003e 0) {\n         float totalDfsUsed \u003d 0;\n         float[] usages \u003d new float[live.length];\n         int i \u003d 0;\n         for (DatanodeInfo dn : live) {\n           usages[i++] \u003d dn.getDfsUsedPercent();\n           totalDfsUsed +\u003d dn.getDfsUsedPercent();\n         }\n         totalDfsUsed /\u003d live.length;\n         Arrays.sort(usages);\n         median \u003d usages[usages.length / 2];\n         max \u003d usages[usages.length - 1];\n         min \u003d usages[0];\n \n         for (i \u003d 0; i \u003c usages.length; i++) {\n           dev +\u003d (usages[i] - totalDfsUsed) * (usages[i] - totalDfsUsed);\n         }\n         dev \u003d (float) Math.sqrt(dev / usages.length);\n       }\n     } catch (IOException e) {\n-      LOG.info(\"Cannot get the live nodes: {}\", e.getMessage());\n+      LOG.error(\"Cannot get the live nodes: {}\", e.getMessage());\n     }\n \n     final Map\u003cString, Object\u003e innerInfo \u003d new HashMap\u003c\u003e();\n     innerInfo.put(\"min\", StringUtils.format(\"%.2f%%\", min));\n     innerInfo.put(\"median\", StringUtils.format(\"%.2f%%\", median));\n     innerInfo.put(\"max\", StringUtils.format(\"%.2f%%\", max));\n     innerInfo.put(\"stdDev\", StringUtils.format(\"%.2f%%\", dev));\n     info.put(\"nodeUsage\", innerInfo);\n \n     return JSON.toString(info);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public String getNodeUsage() {\n    float median \u003d 0;\n    float max \u003d 0;\n    float min \u003d 0;\n    float dev \u003d 0;\n\n    final Map\u003cString, Map\u003cString, Object\u003e\u003e info \u003d new HashMap\u003c\u003e();\n    try {\n      RouterRpcServer rpcServer \u003d this.router.getRpcServer();\n      DatanodeInfo[] live \u003d rpcServer.getDatanodeReport(\n          DatanodeReportType.LIVE, false, TIME_OUT);\n\n      if (live.length \u003e 0) {\n        float totalDfsUsed \u003d 0;\n        float[] usages \u003d new float[live.length];\n        int i \u003d 0;\n        for (DatanodeInfo dn : live) {\n          usages[i++] \u003d dn.getDfsUsedPercent();\n          totalDfsUsed +\u003d dn.getDfsUsedPercent();\n        }\n        totalDfsUsed /\u003d live.length;\n        Arrays.sort(usages);\n        median \u003d usages[usages.length / 2];\n        max \u003d usages[usages.length - 1];\n        min \u003d usages[0];\n\n        for (i \u003d 0; i \u003c usages.length; i++) {\n          dev +\u003d (usages[i] - totalDfsUsed) * (usages[i] - totalDfsUsed);\n        }\n        dev \u003d (float) Math.sqrt(dev / usages.length);\n      }\n    } catch (IOException e) {\n      LOG.error(\"Cannot get the live nodes: {}\", e.getMessage());\n    }\n\n    final Map\u003cString, Object\u003e innerInfo \u003d new HashMap\u003c\u003e();\n    innerInfo.put(\"min\", StringUtils.format(\"%.2f%%\", min));\n    innerInfo.put(\"median\", StringUtils.format(\"%.2f%%\", median));\n    innerInfo.put(\"max\", StringUtils.format(\"%.2f%%\", max));\n    innerInfo.put(\"stdDev\", StringUtils.format(\"%.2f%%\", dev));\n    info.put(\"nodeUsage\", innerInfo);\n\n    return JSON.toString(info);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/metrics/FederationMetrics.java",
      "extendedDetails": {}
    },
    "a71656c1c1bf6c680f1382a76ddcac870061f320": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13347. RBF: Cache datanode reports. Contributed by Inigo Goiri.\n",
      "commitDate": "27/03/18 8:00 PM",
      "commitName": "a71656c1c1bf6c680f1382a76ddcac870061f320",
      "commitAuthor": "Yiqun Lin",
      "commitDateOld": "19/03/18 10:13 PM",
      "commitNameOld": "6e2b5fa493ff8e8c2bb28e6f6f4c19347bc9b99d",
      "commitAuthorOld": "weiy",
      "daysBetweenCommits": 7.91,
      "commitsBetweenForRepo": 186,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,44 +1,44 @@\n   public String getNodeUsage() {\n     float median \u003d 0;\n     float max \u003d 0;\n     float min \u003d 0;\n     float dev \u003d 0;\n \n     final Map\u003cString, Map\u003cString, Object\u003e\u003e info \u003d new HashMap\u003c\u003e();\n     try {\n       RouterRpcServer rpcServer \u003d this.router.getRpcServer();\n       DatanodeInfo[] live \u003d rpcServer.getDatanodeReport(\n-          DatanodeReportType.LIVE, TIME_OUT);\n+          DatanodeReportType.LIVE, false, TIME_OUT);\n \n       if (live.length \u003e 0) {\n         float totalDfsUsed \u003d 0;\n         float[] usages \u003d new float[live.length];\n         int i \u003d 0;\n         for (DatanodeInfo dn : live) {\n           usages[i++] \u003d dn.getDfsUsedPercent();\n           totalDfsUsed +\u003d dn.getDfsUsedPercent();\n         }\n         totalDfsUsed /\u003d live.length;\n         Arrays.sort(usages);\n         median \u003d usages[usages.length / 2];\n         max \u003d usages[usages.length - 1];\n         min \u003d usages[0];\n \n         for (i \u003d 0; i \u003c usages.length; i++) {\n           dev +\u003d (usages[i] - totalDfsUsed) * (usages[i] - totalDfsUsed);\n         }\n         dev \u003d (float) Math.sqrt(dev / usages.length);\n       }\n     } catch (IOException e) {\n       LOG.info(\"Cannot get the live nodes: {}\", e.getMessage());\n     }\n \n     final Map\u003cString, Object\u003e innerInfo \u003d new HashMap\u003c\u003e();\n     innerInfo.put(\"min\", StringUtils.format(\"%.2f%%\", min));\n     innerInfo.put(\"median\", StringUtils.format(\"%.2f%%\", median));\n     innerInfo.put(\"max\", StringUtils.format(\"%.2f%%\", max));\n     innerInfo.put(\"stdDev\", StringUtils.format(\"%.2f%%\", dev));\n     info.put(\"nodeUsage\", innerInfo);\n \n     return JSON.toString(info);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public String getNodeUsage() {\n    float median \u003d 0;\n    float max \u003d 0;\n    float min \u003d 0;\n    float dev \u003d 0;\n\n    final Map\u003cString, Map\u003cString, Object\u003e\u003e info \u003d new HashMap\u003c\u003e();\n    try {\n      RouterRpcServer rpcServer \u003d this.router.getRpcServer();\n      DatanodeInfo[] live \u003d rpcServer.getDatanodeReport(\n          DatanodeReportType.LIVE, false, TIME_OUT);\n\n      if (live.length \u003e 0) {\n        float totalDfsUsed \u003d 0;\n        float[] usages \u003d new float[live.length];\n        int i \u003d 0;\n        for (DatanodeInfo dn : live) {\n          usages[i++] \u003d dn.getDfsUsedPercent();\n          totalDfsUsed +\u003d dn.getDfsUsedPercent();\n        }\n        totalDfsUsed /\u003d live.length;\n        Arrays.sort(usages);\n        median \u003d usages[usages.length / 2];\n        max \u003d usages[usages.length - 1];\n        min \u003d usages[0];\n\n        for (i \u003d 0; i \u003c usages.length; i++) {\n          dev +\u003d (usages[i] - totalDfsUsed) * (usages[i] - totalDfsUsed);\n        }\n        dev \u003d (float) Math.sqrt(dev / usages.length);\n      }\n    } catch (IOException e) {\n      LOG.info(\"Cannot get the live nodes: {}\", e.getMessage());\n    }\n\n    final Map\u003cString, Object\u003e innerInfo \u003d new HashMap\u003c\u003e();\n    innerInfo.put(\"min\", StringUtils.format(\"%.2f%%\", min));\n    innerInfo.put(\"median\", StringUtils.format(\"%.2f%%\", median));\n    innerInfo.put(\"max\", StringUtils.format(\"%.2f%%\", max));\n    innerInfo.put(\"stdDev\", StringUtils.format(\"%.2f%%\", dev));\n    info.put(\"nodeUsage\", innerInfo);\n\n    return JSON.toString(info);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/metrics/FederationMetrics.java",
      "extendedDetails": {}
    },
    "6e2b5fa493ff8e8c2bb28e6f6f4c19347bc9b99d": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-13215. RBF: Move Router to its own module. Contributed by Wei Yan\n",
      "commitDate": "19/03/18 10:13 PM",
      "commitName": "6e2b5fa493ff8e8c2bb28e6f6f4c19347bc9b99d",
      "commitAuthor": "weiy",
      "commitDateOld": "19/03/18 5:19 PM",
      "commitNameOld": "e65ff1c8be48ef4f04ed96f96ac4caef4974944d",
      "commitAuthorOld": "Inigo Goiri",
      "daysBetweenCommits": 0.2,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public String getNodeUsage() {\n    float median \u003d 0;\n    float max \u003d 0;\n    float min \u003d 0;\n    float dev \u003d 0;\n\n    final Map\u003cString, Map\u003cString, Object\u003e\u003e info \u003d new HashMap\u003c\u003e();\n    try {\n      RouterRpcServer rpcServer \u003d this.router.getRpcServer();\n      DatanodeInfo[] live \u003d rpcServer.getDatanodeReport(\n          DatanodeReportType.LIVE, TIME_OUT);\n\n      if (live.length \u003e 0) {\n        float totalDfsUsed \u003d 0;\n        float[] usages \u003d new float[live.length];\n        int i \u003d 0;\n        for (DatanodeInfo dn : live) {\n          usages[i++] \u003d dn.getDfsUsedPercent();\n          totalDfsUsed +\u003d dn.getDfsUsedPercent();\n        }\n        totalDfsUsed /\u003d live.length;\n        Arrays.sort(usages);\n        median \u003d usages[usages.length / 2];\n        max \u003d usages[usages.length - 1];\n        min \u003d usages[0];\n\n        for (i \u003d 0; i \u003c usages.length; i++) {\n          dev +\u003d (usages[i] - totalDfsUsed) * (usages[i] - totalDfsUsed);\n        }\n        dev \u003d (float) Math.sqrt(dev / usages.length);\n      }\n    } catch (IOException e) {\n      LOG.info(\"Cannot get the live nodes: {}\", e.getMessage());\n    }\n\n    final Map\u003cString, Object\u003e innerInfo \u003d new HashMap\u003c\u003e();\n    innerInfo.put(\"min\", StringUtils.format(\"%.2f%%\", min));\n    innerInfo.put(\"median\", StringUtils.format(\"%.2f%%\", median));\n    innerInfo.put(\"max\", StringUtils.format(\"%.2f%%\", max));\n    innerInfo.put(\"stdDev\", StringUtils.format(\"%.2f%%\", dev));\n    info.put(\"nodeUsage\", innerInfo);\n\n    return JSON.toString(info);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/metrics/FederationMetrics.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/federation/metrics/FederationMetrics.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/metrics/FederationMetrics.java"
      }
    },
    "81601dac8ec7650bec14700b174910390a92fe1f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12273. Federation UI. Contributed by Inigo Goiri.\n\n(cherry picked from commit adbb2e00c7b85524fd43bd68895d49814c16680a)\n",
      "commitDate": "06/10/17 6:50 PM",
      "commitName": "81601dac8ec7650bec14700b174910390a92fe1f",
      "commitAuthor": "Inigo Goiri",
      "commitDateOld": "06/10/17 6:50 PM",
      "commitNameOld": "bc9e588a19c0aaf518de8dab719362be4a8d6a54",
      "commitAuthorOld": "Inigo Goiri",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,44 +1,44 @@\n   public String getNodeUsage() {\n     float median \u003d 0;\n     float max \u003d 0;\n     float min \u003d 0;\n     float dev \u003d 0;\n \n     final Map\u003cString, Map\u003cString, Object\u003e\u003e info \u003d new HashMap\u003c\u003e();\n     try {\n       RouterRpcServer rpcServer \u003d this.router.getRpcServer();\n-      DatanodeInfo[] live \u003d\n-          rpcServer.getDatanodeReport(DatanodeReportType.LIVE);\n+      DatanodeInfo[] live \u003d rpcServer.getDatanodeReport(\n+          DatanodeReportType.LIVE, TIME_OUT);\n \n       if (live.length \u003e 0) {\n         float totalDfsUsed \u003d 0;\n         float[] usages \u003d new float[live.length];\n         int i \u003d 0;\n         for (DatanodeInfo dn : live) {\n           usages[i++] \u003d dn.getDfsUsedPercent();\n           totalDfsUsed +\u003d dn.getDfsUsedPercent();\n         }\n         totalDfsUsed /\u003d live.length;\n         Arrays.sort(usages);\n         median \u003d usages[usages.length / 2];\n         max \u003d usages[usages.length - 1];\n         min \u003d usages[0];\n \n         for (i \u003d 0; i \u003c usages.length; i++) {\n           dev +\u003d (usages[i] - totalDfsUsed) * (usages[i] - totalDfsUsed);\n         }\n         dev \u003d (float) Math.sqrt(dev / usages.length);\n       }\n     } catch (IOException e) {\n       LOG.info(\"Cannot get the live nodes: {}\", e.getMessage());\n     }\n \n     final Map\u003cString, Object\u003e innerInfo \u003d new HashMap\u003c\u003e();\n     innerInfo.put(\"min\", StringUtils.format(\"%.2f%%\", min));\n     innerInfo.put(\"median\", StringUtils.format(\"%.2f%%\", median));\n     innerInfo.put(\"max\", StringUtils.format(\"%.2f%%\", max));\n     innerInfo.put(\"stdDev\", StringUtils.format(\"%.2f%%\", dev));\n     info.put(\"nodeUsage\", innerInfo);\n \n     return JSON.toString(info);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public String getNodeUsage() {\n    float median \u003d 0;\n    float max \u003d 0;\n    float min \u003d 0;\n    float dev \u003d 0;\n\n    final Map\u003cString, Map\u003cString, Object\u003e\u003e info \u003d new HashMap\u003c\u003e();\n    try {\n      RouterRpcServer rpcServer \u003d this.router.getRpcServer();\n      DatanodeInfo[] live \u003d rpcServer.getDatanodeReport(\n          DatanodeReportType.LIVE, TIME_OUT);\n\n      if (live.length \u003e 0) {\n        float totalDfsUsed \u003d 0;\n        float[] usages \u003d new float[live.length];\n        int i \u003d 0;\n        for (DatanodeInfo dn : live) {\n          usages[i++] \u003d dn.getDfsUsedPercent();\n          totalDfsUsed +\u003d dn.getDfsUsedPercent();\n        }\n        totalDfsUsed /\u003d live.length;\n        Arrays.sort(usages);\n        median \u003d usages[usages.length / 2];\n        max \u003d usages[usages.length - 1];\n        min \u003d usages[0];\n\n        for (i \u003d 0; i \u003c usages.length; i++) {\n          dev +\u003d (usages[i] - totalDfsUsed) * (usages[i] - totalDfsUsed);\n        }\n        dev \u003d (float) Math.sqrt(dev / usages.length);\n      }\n    } catch (IOException e) {\n      LOG.info(\"Cannot get the live nodes: {}\", e.getMessage());\n    }\n\n    final Map\u003cString, Object\u003e innerInfo \u003d new HashMap\u003c\u003e();\n    innerInfo.put(\"min\", StringUtils.format(\"%.2f%%\", min));\n    innerInfo.put(\"median\", StringUtils.format(\"%.2f%%\", median));\n    innerInfo.put(\"max\", StringUtils.format(\"%.2f%%\", max));\n    innerInfo.put(\"stdDev\", StringUtils.format(\"%.2f%%\", dev));\n    info.put(\"nodeUsage\", innerInfo);\n\n    return JSON.toString(info);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/federation/metrics/FederationMetrics.java",
      "extendedDetails": {}
    },
    "bc9e588a19c0aaf518de8dab719362be4a8d6a54": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-12335. Federation Metrics. Contributed by Inigo Goiri.\n\n(cherry picked from commit 3b19e77752afce87936f5c0d1e6d272fba798d7b)\n",
      "commitDate": "06/10/17 6:50 PM",
      "commitName": "bc9e588a19c0aaf518de8dab719362be4a8d6a54",
      "commitAuthor": "Inigo Goiri",
      "diff": "@@ -0,0 +1,44 @@\n+  public String getNodeUsage() {\n+    float median \u003d 0;\n+    float max \u003d 0;\n+    float min \u003d 0;\n+    float dev \u003d 0;\n+\n+    final Map\u003cString, Map\u003cString, Object\u003e\u003e info \u003d new HashMap\u003c\u003e();\n+    try {\n+      RouterRpcServer rpcServer \u003d this.router.getRpcServer();\n+      DatanodeInfo[] live \u003d\n+          rpcServer.getDatanodeReport(DatanodeReportType.LIVE);\n+\n+      if (live.length \u003e 0) {\n+        float totalDfsUsed \u003d 0;\n+        float[] usages \u003d new float[live.length];\n+        int i \u003d 0;\n+        for (DatanodeInfo dn : live) {\n+          usages[i++] \u003d dn.getDfsUsedPercent();\n+          totalDfsUsed +\u003d dn.getDfsUsedPercent();\n+        }\n+        totalDfsUsed /\u003d live.length;\n+        Arrays.sort(usages);\n+        median \u003d usages[usages.length / 2];\n+        max \u003d usages[usages.length - 1];\n+        min \u003d usages[0];\n+\n+        for (i \u003d 0; i \u003c usages.length; i++) {\n+          dev +\u003d (usages[i] - totalDfsUsed) * (usages[i] - totalDfsUsed);\n+        }\n+        dev \u003d (float) Math.sqrt(dev / usages.length);\n+      }\n+    } catch (IOException e) {\n+      LOG.info(\"Cannot get the live nodes: {}\", e.getMessage());\n+    }\n+\n+    final Map\u003cString, Object\u003e innerInfo \u003d new HashMap\u003c\u003e();\n+    innerInfo.put(\"min\", StringUtils.format(\"%.2f%%\", min));\n+    innerInfo.put(\"median\", StringUtils.format(\"%.2f%%\", median));\n+    innerInfo.put(\"max\", StringUtils.format(\"%.2f%%\", max));\n+    innerInfo.put(\"stdDev\", StringUtils.format(\"%.2f%%\", dev));\n+    info.put(\"nodeUsage\", innerInfo);\n+\n+    return JSON.toString(info);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public String getNodeUsage() {\n    float median \u003d 0;\n    float max \u003d 0;\n    float min \u003d 0;\n    float dev \u003d 0;\n\n    final Map\u003cString, Map\u003cString, Object\u003e\u003e info \u003d new HashMap\u003c\u003e();\n    try {\n      RouterRpcServer rpcServer \u003d this.router.getRpcServer();\n      DatanodeInfo[] live \u003d\n          rpcServer.getDatanodeReport(DatanodeReportType.LIVE);\n\n      if (live.length \u003e 0) {\n        float totalDfsUsed \u003d 0;\n        float[] usages \u003d new float[live.length];\n        int i \u003d 0;\n        for (DatanodeInfo dn : live) {\n          usages[i++] \u003d dn.getDfsUsedPercent();\n          totalDfsUsed +\u003d dn.getDfsUsedPercent();\n        }\n        totalDfsUsed /\u003d live.length;\n        Arrays.sort(usages);\n        median \u003d usages[usages.length / 2];\n        max \u003d usages[usages.length - 1];\n        min \u003d usages[0];\n\n        for (i \u003d 0; i \u003c usages.length; i++) {\n          dev +\u003d (usages[i] - totalDfsUsed) * (usages[i] - totalDfsUsed);\n        }\n        dev \u003d (float) Math.sqrt(dev / usages.length);\n      }\n    } catch (IOException e) {\n      LOG.info(\"Cannot get the live nodes: {}\", e.getMessage());\n    }\n\n    final Map\u003cString, Object\u003e innerInfo \u003d new HashMap\u003c\u003e();\n    innerInfo.put(\"min\", StringUtils.format(\"%.2f%%\", min));\n    innerInfo.put(\"median\", StringUtils.format(\"%.2f%%\", median));\n    innerInfo.put(\"max\", StringUtils.format(\"%.2f%%\", max));\n    innerInfo.put(\"stdDev\", StringUtils.format(\"%.2f%%\", dev));\n    info.put(\"nodeUsage\", innerInfo);\n\n    return JSON.toString(info);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/federation/metrics/FederationMetrics.java"
    }
  }
}