{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DFSInputStream.java",
  "functionName": "readBlockLength",
  "functionId": "readBlockLength___locatedblock-LocatedBlock",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
  "functionStartLine": 378,
  "functionEndLine": 460,
  "numCommitsSeen": 143,
  "timeTaken": 9634,
  "changeHistory": [
    "0e28cd8f63615dddded2f1183f27efb5c2aaf6aa",
    "774c1f199e11d886d0c0a1069325f0284da35deb",
    "8ea9bbce2614e8eb499af73589f021ed1789e78f",
    "be34e85e682880f46eee0310bf00ecc7d39cd5bd",
    "38c4c14472996562eb3d610649246770c2888c6b",
    "39285e6a1978ea5e53bdc1b0aef62421382124a8",
    "6ee0539ede78b640f01c5eac18ded161182a7835",
    "d5a9a3daa0224249221ffa7b8bd5751ab2feca56",
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c",
    "e2c9b288b223b9fd82dc12018936e13128413492",
    "2cc9514ad643ae49d30524743420ee9744e571bd",
    "c68b1d1b31e304c27e419e810ded0fc97e435ea6",
    "f98d8eb291be364102b5c3011ce72e8f43eab389",
    "d28b98242854ff7f9d615e1c9d6a5b7584ce2498",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "710e5a960e8af1d4c73e386041096aacfee8b828",
    "fd9997989c1f1c6f806c57a806e7225ca599fc0c",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "0e28cd8f63615dddded2f1183f27efb5c2aaf6aa": "Ybodychange",
    "774c1f199e11d886d0c0a1069325f0284da35deb": "Ybodychange",
    "8ea9bbce2614e8eb499af73589f021ed1789e78f": "Ybodychange",
    "be34e85e682880f46eee0310bf00ecc7d39cd5bd": "Ybodychange",
    "38c4c14472996562eb3d610649246770c2888c6b": "Ybodychange",
    "39285e6a1978ea5e53bdc1b0aef62421382124a8": "Ybodychange",
    "6ee0539ede78b640f01c5eac18ded161182a7835": "Ybodychange",
    "d5a9a3daa0224249221ffa7b8bd5751ab2feca56": "Ybodychange",
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c": "Yfilerename",
    "e2c9b288b223b9fd82dc12018936e13128413492": "Ybodychange",
    "2cc9514ad643ae49d30524743420ee9744e571bd": "Ybodychange",
    "c68b1d1b31e304c27e419e810ded0fc97e435ea6": "Ybodychange",
    "f98d8eb291be364102b5c3011ce72e8f43eab389": "Ybodychange",
    "d28b98242854ff7f9d615e1c9d6a5b7584ce2498": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "710e5a960e8af1d4c73e386041096aacfee8b828": "Ybodychange",
    "fd9997989c1f1c6f806c57a806e7225ca599fc0c": "Ybodychange",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "0e28cd8f63615dddded2f1183f27efb5c2aaf6aa": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-15050. Optimize log information when DFSInputStream meet CannotObtainBlockLengthException. Contributed by Xiaoqiao He.\n\nSigned-off-by: Wei-Chiu Chuang \u003cweichiu@apache.org\u003e\n",
      "commitDate": "12/12/19 2:23 AM",
      "commitName": "0e28cd8f63615dddded2f1183f27efb5c2aaf6aa",
      "commitAuthor": "He Xiaoqiao",
      "commitDateOld": "15/11/19 7:32 PM",
      "commitNameOld": "b3119b9ab60a19d624db476c4e1c53410870c7a6",
      "commitAuthorOld": "Yiqun Lin",
      "daysBetweenCommits": 26.29,
      "commitsBetweenForRepo": 112,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,83 +1,83 @@\n   private long readBlockLength(LocatedBlock locatedblock) throws IOException {\n     assert locatedblock !\u003d null : \"LocatedBlock cannot be null\";\n     int replicaNotFoundCount \u003d locatedblock.getLocations().length;\n \n     final DfsClientConf conf \u003d dfsClient.getConf();\n     final int timeout \u003d conf.getSocketTimeout();\n     LinkedList\u003cDatanodeInfo\u003e nodeList \u003d new LinkedList\u003cDatanodeInfo\u003e(\n         Arrays.asList(locatedblock.getLocations()));\n     LinkedList\u003cDatanodeInfo\u003e retryList \u003d new LinkedList\u003cDatanodeInfo\u003e();\n     boolean isRetry \u003d false;\n     StopWatch sw \u003d new StopWatch();\n     while (nodeList.size() \u003e 0) {\n       DatanodeInfo datanode \u003d nodeList.pop();\n       ClientDatanodeProtocol cdp \u003d null;\n       try {\n         cdp \u003d DFSUtilClient.createClientDatanodeProtocolProxy(datanode,\n             dfsClient.getConfiguration(), timeout,\n             conf.isConnectToDnViaHostname(), locatedblock);\n \n         final long n \u003d cdp.getReplicaVisibleLength(locatedblock.getBlock());\n \n         if (n \u003e\u003d 0) {\n           return n;\n         }\n       } catch (IOException ioe) {\n         checkInterrupted(ioe);\n         if (ioe instanceof RemoteException) {\n           if (((RemoteException) ioe).unwrapRemoteException() instanceof\n               ReplicaNotFoundException) {\n             // replica is not on the DN. We will treat it as 0 length\n             // if no one actually has a replica.\n             replicaNotFoundCount--;\n           } else if (((RemoteException) ioe).unwrapRemoteException() instanceof\n               RetriableException) {\n             // add to the list to be retried if necessary.\n             retryList.add(datanode);\n           }\n         }\n         DFSClient.LOG.debug(\"Failed to getReplicaVisibleLength from datanode {}\"\n               + \" for block {}\", datanode, locatedblock.getBlock(), ioe);\n       } finally {\n         if (cdp !\u003d null) {\n           RPC.stopProxy(cdp);\n         }\n       }\n \n       // Ran out of nodes, but there are retriable nodes.\n       if (nodeList.size() \u003d\u003d 0 \u0026\u0026 retryList.size() \u003e 0) {\n         nodeList.addAll(retryList);\n         retryList.clear();\n         isRetry \u003d true;\n       }\n \n       if (isRetry) {\n         // start the stop watch if not already running.\n         if (!sw.isRunning()) {\n           sw.start();\n         }\n         try {\n           Thread.sleep(500); // delay between retries.\n         } catch (InterruptedException e) {\n           Thread.currentThread().interrupt();\n           throw new InterruptedIOException(\n               \"Interrupted while getting the length.\");\n         }\n       }\n \n       // see if we ran out of retry time\n       if (sw.isRunning() \u0026\u0026 sw.now(TimeUnit.MILLISECONDS) \u003e timeout) {\n         break;\n       }\n     }\n \n     // Namenode told us about these locations, but none know about the replica\n     // means that we hit the race between pipeline creation start and end.\n     // we require all 3 because some other exception could have happened\n     // on a DN that has it.  we want to report that error\n     if (replicaNotFoundCount \u003d\u003d 0) {\n       return 0;\n     }\n \n-    throw new CannotObtainBlockLengthException(locatedblock);\n+    throw new CannotObtainBlockLengthException(locatedblock, src);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private long readBlockLength(LocatedBlock locatedblock) throws IOException {\n    assert locatedblock !\u003d null : \"LocatedBlock cannot be null\";\n    int replicaNotFoundCount \u003d locatedblock.getLocations().length;\n\n    final DfsClientConf conf \u003d dfsClient.getConf();\n    final int timeout \u003d conf.getSocketTimeout();\n    LinkedList\u003cDatanodeInfo\u003e nodeList \u003d new LinkedList\u003cDatanodeInfo\u003e(\n        Arrays.asList(locatedblock.getLocations()));\n    LinkedList\u003cDatanodeInfo\u003e retryList \u003d new LinkedList\u003cDatanodeInfo\u003e();\n    boolean isRetry \u003d false;\n    StopWatch sw \u003d new StopWatch();\n    while (nodeList.size() \u003e 0) {\n      DatanodeInfo datanode \u003d nodeList.pop();\n      ClientDatanodeProtocol cdp \u003d null;\n      try {\n        cdp \u003d DFSUtilClient.createClientDatanodeProtocolProxy(datanode,\n            dfsClient.getConfiguration(), timeout,\n            conf.isConnectToDnViaHostname(), locatedblock);\n\n        final long n \u003d cdp.getReplicaVisibleLength(locatedblock.getBlock());\n\n        if (n \u003e\u003d 0) {\n          return n;\n        }\n      } catch (IOException ioe) {\n        checkInterrupted(ioe);\n        if (ioe instanceof RemoteException) {\n          if (((RemoteException) ioe).unwrapRemoteException() instanceof\n              ReplicaNotFoundException) {\n            // replica is not on the DN. We will treat it as 0 length\n            // if no one actually has a replica.\n            replicaNotFoundCount--;\n          } else if (((RemoteException) ioe).unwrapRemoteException() instanceof\n              RetriableException) {\n            // add to the list to be retried if necessary.\n            retryList.add(datanode);\n          }\n        }\n        DFSClient.LOG.debug(\"Failed to getReplicaVisibleLength from datanode {}\"\n              + \" for block {}\", datanode, locatedblock.getBlock(), ioe);\n      } finally {\n        if (cdp !\u003d null) {\n          RPC.stopProxy(cdp);\n        }\n      }\n\n      // Ran out of nodes, but there are retriable nodes.\n      if (nodeList.size() \u003d\u003d 0 \u0026\u0026 retryList.size() \u003e 0) {\n        nodeList.addAll(retryList);\n        retryList.clear();\n        isRetry \u003d true;\n      }\n\n      if (isRetry) {\n        // start the stop watch if not already running.\n        if (!sw.isRunning()) {\n          sw.start();\n        }\n        try {\n          Thread.sleep(500); // delay between retries.\n        } catch (InterruptedException e) {\n          Thread.currentThread().interrupt();\n          throw new InterruptedIOException(\n              \"Interrupted while getting the length.\");\n        }\n      }\n\n      // see if we ran out of retry time\n      if (sw.isRunning() \u0026\u0026 sw.now(TimeUnit.MILLISECONDS) \u003e timeout) {\n        break;\n      }\n    }\n\n    // Namenode told us about these locations, but none know about the replica\n    // means that we hit the race between pipeline creation start and end.\n    // we require all 3 because some other exception could have happened\n    // on a DN that has it.  we want to report that error\n    if (replicaNotFoundCount \u003d\u003d 0) {\n      return 0;\n    }\n\n    throw new CannotObtainBlockLengthException(locatedblock, src);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "774c1f199e11d886d0c0a1069325f0284da35deb": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13511. Provide specialized exception when block length cannot be obtained. Contributed by Gabor Bota.\n",
      "commitDate": "05/06/18 9:25 PM",
      "commitName": "774c1f199e11d886d0c0a1069325f0284da35deb",
      "commitAuthor": "Xiao Chen",
      "commitDateOld": "04/06/18 9:13 PM",
      "commitNameOld": "6d5e87aec2f615ed265dc495873bf53ee7d2ace2",
      "commitAuthorOld": "Xiao Chen",
      "daysBetweenCommits": 1.01,
      "commitsBetweenForRepo": 8,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,83 +1,83 @@\n   private long readBlockLength(LocatedBlock locatedblock) throws IOException {\n     assert locatedblock !\u003d null : \"LocatedBlock cannot be null\";\n     int replicaNotFoundCount \u003d locatedblock.getLocations().length;\n \n     final DfsClientConf conf \u003d dfsClient.getConf();\n     final int timeout \u003d conf.getSocketTimeout();\n     LinkedList\u003cDatanodeInfo\u003e nodeList \u003d new LinkedList\u003cDatanodeInfo\u003e(\n         Arrays.asList(locatedblock.getLocations()));\n     LinkedList\u003cDatanodeInfo\u003e retryList \u003d new LinkedList\u003cDatanodeInfo\u003e();\n     boolean isRetry \u003d false;\n     StopWatch sw \u003d new StopWatch();\n     while (nodeList.size() \u003e 0) {\n       DatanodeInfo datanode \u003d nodeList.pop();\n       ClientDatanodeProtocol cdp \u003d null;\n       try {\n         cdp \u003d DFSUtilClient.createClientDatanodeProtocolProxy(datanode,\n             dfsClient.getConfiguration(), timeout,\n             conf.isConnectToDnViaHostname(), locatedblock);\n \n         final long n \u003d cdp.getReplicaVisibleLength(locatedblock.getBlock());\n \n         if (n \u003e\u003d 0) {\n           return n;\n         }\n       } catch (IOException ioe) {\n         checkInterrupted(ioe);\n         if (ioe instanceof RemoteException) {\n           if (((RemoteException) ioe).unwrapRemoteException() instanceof\n               ReplicaNotFoundException) {\n             // replica is not on the DN. We will treat it as 0 length\n             // if no one actually has a replica.\n             replicaNotFoundCount--;\n           } else if (((RemoteException) ioe).unwrapRemoteException() instanceof\n               RetriableException) {\n             // add to the list to be retried if necessary.\n             retryList.add(datanode);\n           }\n         }\n         DFSClient.LOG.debug(\"Failed to getReplicaVisibleLength from datanode {}\"\n               + \" for block {}\", datanode, locatedblock.getBlock(), ioe);\n       } finally {\n         if (cdp !\u003d null) {\n           RPC.stopProxy(cdp);\n         }\n       }\n \n       // Ran out of nodes, but there are retriable nodes.\n       if (nodeList.size() \u003d\u003d 0 \u0026\u0026 retryList.size() \u003e 0) {\n         nodeList.addAll(retryList);\n         retryList.clear();\n         isRetry \u003d true;\n       }\n \n       if (isRetry) {\n         // start the stop watch if not already running.\n         if (!sw.isRunning()) {\n           sw.start();\n         }\n         try {\n           Thread.sleep(500); // delay between retries.\n         } catch (InterruptedException e) {\n           Thread.currentThread().interrupt();\n           throw new InterruptedIOException(\n               \"Interrupted while getting the length.\");\n         }\n       }\n \n       // see if we ran out of retry time\n       if (sw.isRunning() \u0026\u0026 sw.now(TimeUnit.MILLISECONDS) \u003e timeout) {\n         break;\n       }\n     }\n \n     // Namenode told us about these locations, but none know about the replica\n     // means that we hit the race between pipeline creation start and end.\n     // we require all 3 because some other exception could have happened\n     // on a DN that has it.  we want to report that error\n     if (replicaNotFoundCount \u003d\u003d 0) {\n       return 0;\n     }\n \n-    throw new IOException(\"Cannot obtain block length for \" + locatedblock);\n+    throw new CannotObtainBlockLengthException(locatedblock);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private long readBlockLength(LocatedBlock locatedblock) throws IOException {\n    assert locatedblock !\u003d null : \"LocatedBlock cannot be null\";\n    int replicaNotFoundCount \u003d locatedblock.getLocations().length;\n\n    final DfsClientConf conf \u003d dfsClient.getConf();\n    final int timeout \u003d conf.getSocketTimeout();\n    LinkedList\u003cDatanodeInfo\u003e nodeList \u003d new LinkedList\u003cDatanodeInfo\u003e(\n        Arrays.asList(locatedblock.getLocations()));\n    LinkedList\u003cDatanodeInfo\u003e retryList \u003d new LinkedList\u003cDatanodeInfo\u003e();\n    boolean isRetry \u003d false;\n    StopWatch sw \u003d new StopWatch();\n    while (nodeList.size() \u003e 0) {\n      DatanodeInfo datanode \u003d nodeList.pop();\n      ClientDatanodeProtocol cdp \u003d null;\n      try {\n        cdp \u003d DFSUtilClient.createClientDatanodeProtocolProxy(datanode,\n            dfsClient.getConfiguration(), timeout,\n            conf.isConnectToDnViaHostname(), locatedblock);\n\n        final long n \u003d cdp.getReplicaVisibleLength(locatedblock.getBlock());\n\n        if (n \u003e\u003d 0) {\n          return n;\n        }\n      } catch (IOException ioe) {\n        checkInterrupted(ioe);\n        if (ioe instanceof RemoteException) {\n          if (((RemoteException) ioe).unwrapRemoteException() instanceof\n              ReplicaNotFoundException) {\n            // replica is not on the DN. We will treat it as 0 length\n            // if no one actually has a replica.\n            replicaNotFoundCount--;\n          } else if (((RemoteException) ioe).unwrapRemoteException() instanceof\n              RetriableException) {\n            // add to the list to be retried if necessary.\n            retryList.add(datanode);\n          }\n        }\n        DFSClient.LOG.debug(\"Failed to getReplicaVisibleLength from datanode {}\"\n              + \" for block {}\", datanode, locatedblock.getBlock(), ioe);\n      } finally {\n        if (cdp !\u003d null) {\n          RPC.stopProxy(cdp);\n        }\n      }\n\n      // Ran out of nodes, but there are retriable nodes.\n      if (nodeList.size() \u003d\u003d 0 \u0026\u0026 retryList.size() \u003e 0) {\n        nodeList.addAll(retryList);\n        retryList.clear();\n        isRetry \u003d true;\n      }\n\n      if (isRetry) {\n        // start the stop watch if not already running.\n        if (!sw.isRunning()) {\n          sw.start();\n        }\n        try {\n          Thread.sleep(500); // delay between retries.\n        } catch (InterruptedException e) {\n          Thread.currentThread().interrupt();\n          throw new InterruptedIOException(\n              \"Interrupted while getting the length.\");\n        }\n      }\n\n      // see if we ran out of retry time\n      if (sw.isRunning() \u0026\u0026 sw.now(TimeUnit.MILLISECONDS) \u003e timeout) {\n        break;\n      }\n    }\n\n    // Namenode told us about these locations, but none know about the replica\n    // means that we hit the race between pipeline creation start and end.\n    // we require all 3 because some other exception could have happened\n    // on a DN that has it.  we want to report that error\n    if (replicaNotFoundCount \u003d\u003d 0) {\n      return 0;\n    }\n\n    throw new CannotObtainBlockLengthException(locatedblock);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "8ea9bbce2614e8eb499af73589f021ed1789e78f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10508. DFSInputStream should set thread\u0027s interrupt status after catching InterruptException from sleep. Contributed by Jing Zhao.\n",
      "commitDate": "08/06/16 10:52 PM",
      "commitName": "8ea9bbce2614e8eb499af73589f021ed1789e78f",
      "commitAuthor": "Masatake Iwasaki",
      "commitDateOld": "07/06/16 10:48 AM",
      "commitNameOld": "be34e85e682880f46eee0310bf00ecc7d39cd5bd",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 1.5,
      "commitsBetweenForRepo": 14,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,82 +1,83 @@\n   private long readBlockLength(LocatedBlock locatedblock) throws IOException {\n     assert locatedblock !\u003d null : \"LocatedBlock cannot be null\";\n     int replicaNotFoundCount \u003d locatedblock.getLocations().length;\n \n     final DfsClientConf conf \u003d dfsClient.getConf();\n     final int timeout \u003d conf.getSocketTimeout();\n     LinkedList\u003cDatanodeInfo\u003e nodeList \u003d new LinkedList\u003cDatanodeInfo\u003e(\n         Arrays.asList(locatedblock.getLocations()));\n     LinkedList\u003cDatanodeInfo\u003e retryList \u003d new LinkedList\u003cDatanodeInfo\u003e();\n     boolean isRetry \u003d false;\n     StopWatch sw \u003d new StopWatch();\n     while (nodeList.size() \u003e 0) {\n       DatanodeInfo datanode \u003d nodeList.pop();\n       ClientDatanodeProtocol cdp \u003d null;\n       try {\n         cdp \u003d DFSUtilClient.createClientDatanodeProtocolProxy(datanode,\n             dfsClient.getConfiguration(), timeout,\n             conf.isConnectToDnViaHostname(), locatedblock);\n \n         final long n \u003d cdp.getReplicaVisibleLength(locatedblock.getBlock());\n \n         if (n \u003e\u003d 0) {\n           return n;\n         }\n       } catch (IOException ioe) {\n         checkInterrupted(ioe);\n         if (ioe instanceof RemoteException) {\n           if (((RemoteException) ioe).unwrapRemoteException() instanceof\n               ReplicaNotFoundException) {\n             // replica is not on the DN. We will treat it as 0 length\n             // if no one actually has a replica.\n             replicaNotFoundCount--;\n           } else if (((RemoteException) ioe).unwrapRemoteException() instanceof\n               RetriableException) {\n             // add to the list to be retried if necessary.\n             retryList.add(datanode);\n           }\n         }\n         DFSClient.LOG.debug(\"Failed to getReplicaVisibleLength from datanode {}\"\n               + \" for block {}\", datanode, locatedblock.getBlock(), ioe);\n       } finally {\n         if (cdp !\u003d null) {\n           RPC.stopProxy(cdp);\n         }\n       }\n \n       // Ran out of nodes, but there are retriable nodes.\n       if (nodeList.size() \u003d\u003d 0 \u0026\u0026 retryList.size() \u003e 0) {\n         nodeList.addAll(retryList);\n         retryList.clear();\n         isRetry \u003d true;\n       }\n \n       if (isRetry) {\n         // start the stop watch if not already running.\n         if (!sw.isRunning()) {\n           sw.start();\n         }\n         try {\n           Thread.sleep(500); // delay between retries.\n         } catch (InterruptedException e) {\n+          Thread.currentThread().interrupt();\n           throw new InterruptedIOException(\n               \"Interrupted while getting the length.\");\n         }\n       }\n \n       // see if we ran out of retry time\n       if (sw.isRunning() \u0026\u0026 sw.now(TimeUnit.MILLISECONDS) \u003e timeout) {\n         break;\n       }\n     }\n \n     // Namenode told us about these locations, but none know about the replica\n     // means that we hit the race between pipeline creation start and end.\n     // we require all 3 because some other exception could have happened\n     // on a DN that has it.  we want to report that error\n     if (replicaNotFoundCount \u003d\u003d 0) {\n       return 0;\n     }\n \n     throw new IOException(\"Cannot obtain block length for \" + locatedblock);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private long readBlockLength(LocatedBlock locatedblock) throws IOException {\n    assert locatedblock !\u003d null : \"LocatedBlock cannot be null\";\n    int replicaNotFoundCount \u003d locatedblock.getLocations().length;\n\n    final DfsClientConf conf \u003d dfsClient.getConf();\n    final int timeout \u003d conf.getSocketTimeout();\n    LinkedList\u003cDatanodeInfo\u003e nodeList \u003d new LinkedList\u003cDatanodeInfo\u003e(\n        Arrays.asList(locatedblock.getLocations()));\n    LinkedList\u003cDatanodeInfo\u003e retryList \u003d new LinkedList\u003cDatanodeInfo\u003e();\n    boolean isRetry \u003d false;\n    StopWatch sw \u003d new StopWatch();\n    while (nodeList.size() \u003e 0) {\n      DatanodeInfo datanode \u003d nodeList.pop();\n      ClientDatanodeProtocol cdp \u003d null;\n      try {\n        cdp \u003d DFSUtilClient.createClientDatanodeProtocolProxy(datanode,\n            dfsClient.getConfiguration(), timeout,\n            conf.isConnectToDnViaHostname(), locatedblock);\n\n        final long n \u003d cdp.getReplicaVisibleLength(locatedblock.getBlock());\n\n        if (n \u003e\u003d 0) {\n          return n;\n        }\n      } catch (IOException ioe) {\n        checkInterrupted(ioe);\n        if (ioe instanceof RemoteException) {\n          if (((RemoteException) ioe).unwrapRemoteException() instanceof\n              ReplicaNotFoundException) {\n            // replica is not on the DN. We will treat it as 0 length\n            // if no one actually has a replica.\n            replicaNotFoundCount--;\n          } else if (((RemoteException) ioe).unwrapRemoteException() instanceof\n              RetriableException) {\n            // add to the list to be retried if necessary.\n            retryList.add(datanode);\n          }\n        }\n        DFSClient.LOG.debug(\"Failed to getReplicaVisibleLength from datanode {}\"\n              + \" for block {}\", datanode, locatedblock.getBlock(), ioe);\n      } finally {\n        if (cdp !\u003d null) {\n          RPC.stopProxy(cdp);\n        }\n      }\n\n      // Ran out of nodes, but there are retriable nodes.\n      if (nodeList.size() \u003d\u003d 0 \u0026\u0026 retryList.size() \u003e 0) {\n        nodeList.addAll(retryList);\n        retryList.clear();\n        isRetry \u003d true;\n      }\n\n      if (isRetry) {\n        // start the stop watch if not already running.\n        if (!sw.isRunning()) {\n          sw.start();\n        }\n        try {\n          Thread.sleep(500); // delay between retries.\n        } catch (InterruptedException e) {\n          Thread.currentThread().interrupt();\n          throw new InterruptedIOException(\n              \"Interrupted while getting the length.\");\n        }\n      }\n\n      // see if we ran out of retry time\n      if (sw.isRunning() \u0026\u0026 sw.now(TimeUnit.MILLISECONDS) \u003e timeout) {\n        break;\n      }\n    }\n\n    // Namenode told us about these locations, but none know about the replica\n    // means that we hit the race between pipeline creation start and end.\n    // we require all 3 because some other exception could have happened\n    // on a DN that has it.  we want to report that error\n    if (replicaNotFoundCount \u003d\u003d 0) {\n      return 0;\n    }\n\n    throw new IOException(\"Cannot obtain block length for \" + locatedblock);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "be34e85e682880f46eee0310bf00ecc7d39cd5bd": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10468. HDFS read ends up ignoring an interrupt. Contributed by Jing Zhao\n",
      "commitDate": "07/06/16 10:48 AM",
      "commitName": "be34e85e682880f46eee0310bf00ecc7d39cd5bd",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "25/04/16 12:01 PM",
      "commitNameOld": "f308561f1d885491b88db73ac63003202056d661",
      "commitAuthorOld": "Tsz-Wo Nicholas Sze",
      "daysBetweenCommits": 42.95,
      "commitsBetweenForRepo": 291,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,80 +1,82 @@\n   private long readBlockLength(LocatedBlock locatedblock) throws IOException {\n     assert locatedblock !\u003d null : \"LocatedBlock cannot be null\";\n     int replicaNotFoundCount \u003d locatedblock.getLocations().length;\n \n     final DfsClientConf conf \u003d dfsClient.getConf();\n     final int timeout \u003d conf.getSocketTimeout();\n     LinkedList\u003cDatanodeInfo\u003e nodeList \u003d new LinkedList\u003cDatanodeInfo\u003e(\n         Arrays.asList(locatedblock.getLocations()));\n     LinkedList\u003cDatanodeInfo\u003e retryList \u003d new LinkedList\u003cDatanodeInfo\u003e();\n     boolean isRetry \u003d false;\n     StopWatch sw \u003d new StopWatch();\n     while (nodeList.size() \u003e 0) {\n       DatanodeInfo datanode \u003d nodeList.pop();\n       ClientDatanodeProtocol cdp \u003d null;\n       try {\n         cdp \u003d DFSUtilClient.createClientDatanodeProtocolProxy(datanode,\n             dfsClient.getConfiguration(), timeout,\n             conf.isConnectToDnViaHostname(), locatedblock);\n \n         final long n \u003d cdp.getReplicaVisibleLength(locatedblock.getBlock());\n \n         if (n \u003e\u003d 0) {\n           return n;\n         }\n       } catch (IOException ioe) {\n+        checkInterrupted(ioe);\n         if (ioe instanceof RemoteException) {\n           if (((RemoteException) ioe).unwrapRemoteException() instanceof\n               ReplicaNotFoundException) {\n             // replica is not on the DN. We will treat it as 0 length\n             // if no one actually has a replica.\n             replicaNotFoundCount--;\n           } else if (((RemoteException) ioe).unwrapRemoteException() instanceof\n               RetriableException) {\n             // add to the list to be retried if necessary.\n             retryList.add(datanode);\n           }\n         }\n         DFSClient.LOG.debug(\"Failed to getReplicaVisibleLength from datanode {}\"\n               + \" for block {}\", datanode, locatedblock.getBlock(), ioe);\n       } finally {\n         if (cdp !\u003d null) {\n           RPC.stopProxy(cdp);\n         }\n       }\n \n       // Ran out of nodes, but there are retriable nodes.\n       if (nodeList.size() \u003d\u003d 0 \u0026\u0026 retryList.size() \u003e 0) {\n         nodeList.addAll(retryList);\n         retryList.clear();\n         isRetry \u003d true;\n       }\n \n       if (isRetry) {\n         // start the stop watch if not already running.\n         if (!sw.isRunning()) {\n           sw.start();\n         }\n         try {\n           Thread.sleep(500); // delay between retries.\n         } catch (InterruptedException e) {\n-          throw new IOException(\"Interrupted while getting the length.\");\n+          throw new InterruptedIOException(\n+              \"Interrupted while getting the length.\");\n         }\n       }\n \n       // see if we ran out of retry time\n       if (sw.isRunning() \u0026\u0026 sw.now(TimeUnit.MILLISECONDS) \u003e timeout) {\n         break;\n       }\n     }\n \n     // Namenode told us about these locations, but none know about the replica\n     // means that we hit the race between pipeline creation start and end.\n     // we require all 3 because some other exception could have happened\n     // on a DN that has it.  we want to report that error\n     if (replicaNotFoundCount \u003d\u003d 0) {\n       return 0;\n     }\n \n     throw new IOException(\"Cannot obtain block length for \" + locatedblock);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private long readBlockLength(LocatedBlock locatedblock) throws IOException {\n    assert locatedblock !\u003d null : \"LocatedBlock cannot be null\";\n    int replicaNotFoundCount \u003d locatedblock.getLocations().length;\n\n    final DfsClientConf conf \u003d dfsClient.getConf();\n    final int timeout \u003d conf.getSocketTimeout();\n    LinkedList\u003cDatanodeInfo\u003e nodeList \u003d new LinkedList\u003cDatanodeInfo\u003e(\n        Arrays.asList(locatedblock.getLocations()));\n    LinkedList\u003cDatanodeInfo\u003e retryList \u003d new LinkedList\u003cDatanodeInfo\u003e();\n    boolean isRetry \u003d false;\n    StopWatch sw \u003d new StopWatch();\n    while (nodeList.size() \u003e 0) {\n      DatanodeInfo datanode \u003d nodeList.pop();\n      ClientDatanodeProtocol cdp \u003d null;\n      try {\n        cdp \u003d DFSUtilClient.createClientDatanodeProtocolProxy(datanode,\n            dfsClient.getConfiguration(), timeout,\n            conf.isConnectToDnViaHostname(), locatedblock);\n\n        final long n \u003d cdp.getReplicaVisibleLength(locatedblock.getBlock());\n\n        if (n \u003e\u003d 0) {\n          return n;\n        }\n      } catch (IOException ioe) {\n        checkInterrupted(ioe);\n        if (ioe instanceof RemoteException) {\n          if (((RemoteException) ioe).unwrapRemoteException() instanceof\n              ReplicaNotFoundException) {\n            // replica is not on the DN. We will treat it as 0 length\n            // if no one actually has a replica.\n            replicaNotFoundCount--;\n          } else if (((RemoteException) ioe).unwrapRemoteException() instanceof\n              RetriableException) {\n            // add to the list to be retried if necessary.\n            retryList.add(datanode);\n          }\n        }\n        DFSClient.LOG.debug(\"Failed to getReplicaVisibleLength from datanode {}\"\n              + \" for block {}\", datanode, locatedblock.getBlock(), ioe);\n      } finally {\n        if (cdp !\u003d null) {\n          RPC.stopProxy(cdp);\n        }\n      }\n\n      // Ran out of nodes, but there are retriable nodes.\n      if (nodeList.size() \u003d\u003d 0 \u0026\u0026 retryList.size() \u003e 0) {\n        nodeList.addAll(retryList);\n        retryList.clear();\n        isRetry \u003d true;\n      }\n\n      if (isRetry) {\n        // start the stop watch if not already running.\n        if (!sw.isRunning()) {\n          sw.start();\n        }\n        try {\n          Thread.sleep(500); // delay between retries.\n        } catch (InterruptedException e) {\n          throw new InterruptedIOException(\n              \"Interrupted while getting the length.\");\n        }\n      }\n\n      // see if we ran out of retry time\n      if (sw.isRunning() \u0026\u0026 sw.now(TimeUnit.MILLISECONDS) \u003e timeout) {\n        break;\n      }\n    }\n\n    // Namenode told us about these locations, but none know about the replica\n    // means that we hit the race between pipeline creation start and end.\n    // we require all 3 because some other exception could have happened\n    // on a DN that has it.  we want to report that error\n    if (replicaNotFoundCount \u003d\u003d 0) {\n      return 0;\n    }\n\n    throw new IOException(\"Cannot obtain block length for \" + locatedblock);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "38c4c14472996562eb3d610649246770c2888c6b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9574. Reduce client failures during datanode restart. Contributed by Kihwal Lee.\n",
      "commitDate": "08/01/16 9:13 AM",
      "commitName": "38c4c14472996562eb3d610649246770c2888c6b",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "03/10/15 11:38 AM",
      "commitNameOld": "7136e8c5582dc4061b566cb9f11a0d6a6d08bb93",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 96.94,
      "commitsBetweenForRepo": 651,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,46 +1,80 @@\n   private long readBlockLength(LocatedBlock locatedblock) throws IOException {\n     assert locatedblock !\u003d null : \"LocatedBlock cannot be null\";\n     int replicaNotFoundCount \u003d locatedblock.getLocations().length;\n \n     final DfsClientConf conf \u003d dfsClient.getConf();\n-    for(DatanodeInfo datanode : locatedblock.getLocations()) {\n+    final int timeout \u003d conf.getSocketTimeout();\n+    LinkedList\u003cDatanodeInfo\u003e nodeList \u003d new LinkedList\u003cDatanodeInfo\u003e(\n+        Arrays.asList(locatedblock.getLocations()));\n+    LinkedList\u003cDatanodeInfo\u003e retryList \u003d new LinkedList\u003cDatanodeInfo\u003e();\n+    boolean isRetry \u003d false;\n+    StopWatch sw \u003d new StopWatch();\n+    while (nodeList.size() \u003e 0) {\n+      DatanodeInfo datanode \u003d nodeList.pop();\n       ClientDatanodeProtocol cdp \u003d null;\n-\n       try {\n         cdp \u003d DFSUtilClient.createClientDatanodeProtocolProxy(datanode,\n-            dfsClient.getConfiguration(), conf.getSocketTimeout(),\n+            dfsClient.getConfiguration(), timeout,\n             conf.isConnectToDnViaHostname(), locatedblock);\n \n         final long n \u003d cdp.getReplicaVisibleLength(locatedblock.getBlock());\n \n         if (n \u003e\u003d 0) {\n           return n;\n         }\n-      }\n-      catch(IOException ioe) {\n-        if (ioe instanceof RemoteException \u0026\u0026\n-            (((RemoteException) ioe).unwrapRemoteException() instanceof\n-                ReplicaNotFoundException)) {\n-          // special case : replica might not be on the DN, treat as 0 length\n-          replicaNotFoundCount--;\n+      } catch (IOException ioe) {\n+        if (ioe instanceof RemoteException) {\n+          if (((RemoteException) ioe).unwrapRemoteException() instanceof\n+              ReplicaNotFoundException) {\n+            // replica is not on the DN. We will treat it as 0 length\n+            // if no one actually has a replica.\n+            replicaNotFoundCount--;\n+          } else if (((RemoteException) ioe).unwrapRemoteException() instanceof\n+              RetriableException) {\n+            // add to the list to be retried if necessary.\n+            retryList.add(datanode);\n+          }\n         }\n-\n         DFSClient.LOG.debug(\"Failed to getReplicaVisibleLength from datanode {}\"\n               + \" for block {}\", datanode, locatedblock.getBlock(), ioe);\n       } finally {\n         if (cdp !\u003d null) {\n           RPC.stopProxy(cdp);\n         }\n       }\n+\n+      // Ran out of nodes, but there are retriable nodes.\n+      if (nodeList.size() \u003d\u003d 0 \u0026\u0026 retryList.size() \u003e 0) {\n+        nodeList.addAll(retryList);\n+        retryList.clear();\n+        isRetry \u003d true;\n+      }\n+\n+      if (isRetry) {\n+        // start the stop watch if not already running.\n+        if (!sw.isRunning()) {\n+          sw.start();\n+        }\n+        try {\n+          Thread.sleep(500); // delay between retries.\n+        } catch (InterruptedException e) {\n+          throw new IOException(\"Interrupted while getting the length.\");\n+        }\n+      }\n+\n+      // see if we ran out of retry time\n+      if (sw.isRunning() \u0026\u0026 sw.now(TimeUnit.MILLISECONDS) \u003e timeout) {\n+        break;\n+      }\n     }\n \n     // Namenode told us about these locations, but none know about the replica\n     // means that we hit the race between pipeline creation start and end.\n     // we require all 3 because some other exception could have happened\n     // on a DN that has it.  we want to report that error\n     if (replicaNotFoundCount \u003d\u003d 0) {\n       return 0;\n     }\n \n     throw new IOException(\"Cannot obtain block length for \" + locatedblock);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private long readBlockLength(LocatedBlock locatedblock) throws IOException {\n    assert locatedblock !\u003d null : \"LocatedBlock cannot be null\";\n    int replicaNotFoundCount \u003d locatedblock.getLocations().length;\n\n    final DfsClientConf conf \u003d dfsClient.getConf();\n    final int timeout \u003d conf.getSocketTimeout();\n    LinkedList\u003cDatanodeInfo\u003e nodeList \u003d new LinkedList\u003cDatanodeInfo\u003e(\n        Arrays.asList(locatedblock.getLocations()));\n    LinkedList\u003cDatanodeInfo\u003e retryList \u003d new LinkedList\u003cDatanodeInfo\u003e();\n    boolean isRetry \u003d false;\n    StopWatch sw \u003d new StopWatch();\n    while (nodeList.size() \u003e 0) {\n      DatanodeInfo datanode \u003d nodeList.pop();\n      ClientDatanodeProtocol cdp \u003d null;\n      try {\n        cdp \u003d DFSUtilClient.createClientDatanodeProtocolProxy(datanode,\n            dfsClient.getConfiguration(), timeout,\n            conf.isConnectToDnViaHostname(), locatedblock);\n\n        final long n \u003d cdp.getReplicaVisibleLength(locatedblock.getBlock());\n\n        if (n \u003e\u003d 0) {\n          return n;\n        }\n      } catch (IOException ioe) {\n        if (ioe instanceof RemoteException) {\n          if (((RemoteException) ioe).unwrapRemoteException() instanceof\n              ReplicaNotFoundException) {\n            // replica is not on the DN. We will treat it as 0 length\n            // if no one actually has a replica.\n            replicaNotFoundCount--;\n          } else if (((RemoteException) ioe).unwrapRemoteException() instanceof\n              RetriableException) {\n            // add to the list to be retried if necessary.\n            retryList.add(datanode);\n          }\n        }\n        DFSClient.LOG.debug(\"Failed to getReplicaVisibleLength from datanode {}\"\n              + \" for block {}\", datanode, locatedblock.getBlock(), ioe);\n      } finally {\n        if (cdp !\u003d null) {\n          RPC.stopProxy(cdp);\n        }\n      }\n\n      // Ran out of nodes, but there are retriable nodes.\n      if (nodeList.size() \u003d\u003d 0 \u0026\u0026 retryList.size() \u003e 0) {\n        nodeList.addAll(retryList);\n        retryList.clear();\n        isRetry \u003d true;\n      }\n\n      if (isRetry) {\n        // start the stop watch if not already running.\n        if (!sw.isRunning()) {\n          sw.start();\n        }\n        try {\n          Thread.sleep(500); // delay between retries.\n        } catch (InterruptedException e) {\n          throw new IOException(\"Interrupted while getting the length.\");\n        }\n      }\n\n      // see if we ran out of retry time\n      if (sw.isRunning() \u0026\u0026 sw.now(TimeUnit.MILLISECONDS) \u003e timeout) {\n        break;\n      }\n    }\n\n    // Namenode told us about these locations, but none know about the replica\n    // means that we hit the race between pipeline creation start and end.\n    // we require all 3 because some other exception could have happened\n    // on a DN that has it.  we want to report that error\n    if (replicaNotFoundCount \u003d\u003d 0) {\n      return 0;\n    }\n\n    throw new IOException(\"Cannot obtain block length for \" + locatedblock);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "39285e6a1978ea5e53bdc1b0aef62421382124a8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8971. Remove guards when calling LOG.debug() and LOG.trace() in client package. Contributed by Mingliang Liu.\n",
      "commitDate": "29/09/15 5:52 PM",
      "commitName": "39285e6a1978ea5e53bdc1b0aef62421382124a8",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "29/09/15 5:51 PM",
      "commitNameOld": "6ee0539ede78b640f01c5eac18ded161182a7835",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,48 +1,46 @@\n   private long readBlockLength(LocatedBlock locatedblock) throws IOException {\n     assert locatedblock !\u003d null : \"LocatedBlock cannot be null\";\n     int replicaNotFoundCount \u003d locatedblock.getLocations().length;\n     \n     final DfsClientConf conf \u003d dfsClient.getConf();\n     for(DatanodeInfo datanode : locatedblock.getLocations()) {\n       ClientDatanodeProtocol cdp \u003d null;\n       \n       try {\n         cdp \u003d DFSUtilClient.createClientDatanodeProtocolProxy(datanode,\n             dfsClient.getConfiguration(), conf.getSocketTimeout(),\n             conf.isConnectToDnViaHostname(), locatedblock);\n         \n         final long n \u003d cdp.getReplicaVisibleLength(locatedblock.getBlock());\n         \n         if (n \u003e\u003d 0) {\n           return n;\n         }\n       }\n       catch(IOException ioe) {\n         if (ioe instanceof RemoteException \u0026\u0026\n           (((RemoteException) ioe).unwrapRemoteException() instanceof\n             ReplicaNotFoundException)) {\n           // special case : replica might not be on the DN, treat as 0 length\n           replicaNotFoundCount--;\n         }\n         \n-        if (DFSClient.LOG.isDebugEnabled()) {\n-          DFSClient.LOG.debug(\"Failed to getReplicaVisibleLength from datanode \"\n-              + datanode + \" for block \" + locatedblock.getBlock(), ioe);\n-        }\n+        DFSClient.LOG.debug(\"Failed to getReplicaVisibleLength from datanode {}\"\n+              + \" for block {}\", datanode, locatedblock.getBlock(), ioe);\n       } finally {\n         if (cdp !\u003d null) {\n           RPC.stopProxy(cdp);\n         }\n       }\n     }\n \n     // Namenode told us about these locations, but none know about the replica\n     // means that we hit the race between pipeline creation start and end.\n     // we require all 3 because some other exception could have happened\n     // on a DN that has it.  we want to report that error\n     if (replicaNotFoundCount \u003d\u003d 0) {\n       return 0;\n     }\n \n     throw new IOException(\"Cannot obtain block length for \" + locatedblock);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private long readBlockLength(LocatedBlock locatedblock) throws IOException {\n    assert locatedblock !\u003d null : \"LocatedBlock cannot be null\";\n    int replicaNotFoundCount \u003d locatedblock.getLocations().length;\n    \n    final DfsClientConf conf \u003d dfsClient.getConf();\n    for(DatanodeInfo datanode : locatedblock.getLocations()) {\n      ClientDatanodeProtocol cdp \u003d null;\n      \n      try {\n        cdp \u003d DFSUtilClient.createClientDatanodeProtocolProxy(datanode,\n            dfsClient.getConfiguration(), conf.getSocketTimeout(),\n            conf.isConnectToDnViaHostname(), locatedblock);\n        \n        final long n \u003d cdp.getReplicaVisibleLength(locatedblock.getBlock());\n        \n        if (n \u003e\u003d 0) {\n          return n;\n        }\n      }\n      catch(IOException ioe) {\n        if (ioe instanceof RemoteException \u0026\u0026\n          (((RemoteException) ioe).unwrapRemoteException() instanceof\n            ReplicaNotFoundException)) {\n          // special case : replica might not be on the DN, treat as 0 length\n          replicaNotFoundCount--;\n        }\n        \n        DFSClient.LOG.debug(\"Failed to getReplicaVisibleLength from datanode {}\"\n              + \" for block {}\", datanode, locatedblock.getBlock(), ioe);\n      } finally {\n        if (cdp !\u003d null) {\n          RPC.stopProxy(cdp);\n        }\n      }\n    }\n\n    // Namenode told us about these locations, but none know about the replica\n    // means that we hit the race between pipeline creation start and end.\n    // we require all 3 because some other exception could have happened\n    // on a DN that has it.  we want to report that error\n    if (replicaNotFoundCount \u003d\u003d 0) {\n      return 0;\n    }\n\n    throw new IOException(\"Cannot obtain block length for \" + locatedblock);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "6ee0539ede78b640f01c5eac18ded161182a7835": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-9170. Move libhdfs / fuse-dfs / libwebhdfs to hdfs-client. Contributed by Haohui Mai.\"\n\nThis reverts commit d5a9a3daa0224249221ffa7b8bd5751ab2feca56.\n",
      "commitDate": "29/09/15 5:51 PM",
      "commitName": "6ee0539ede78b640f01c5eac18ded161182a7835",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "29/09/15 5:48 PM",
      "commitNameOld": "d5a9a3daa0224249221ffa7b8bd5751ab2feca56",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,46 +1,48 @@\n   private long readBlockLength(LocatedBlock locatedblock) throws IOException {\n     assert locatedblock !\u003d null : \"LocatedBlock cannot be null\";\n     int replicaNotFoundCount \u003d locatedblock.getLocations().length;\n     \n     final DfsClientConf conf \u003d dfsClient.getConf();\n     for(DatanodeInfo datanode : locatedblock.getLocations()) {\n       ClientDatanodeProtocol cdp \u003d null;\n       \n       try {\n         cdp \u003d DFSUtilClient.createClientDatanodeProtocolProxy(datanode,\n             dfsClient.getConfiguration(), conf.getSocketTimeout(),\n             conf.isConnectToDnViaHostname(), locatedblock);\n         \n         final long n \u003d cdp.getReplicaVisibleLength(locatedblock.getBlock());\n         \n         if (n \u003e\u003d 0) {\n           return n;\n         }\n       }\n       catch(IOException ioe) {\n         if (ioe instanceof RemoteException \u0026\u0026\n           (((RemoteException) ioe).unwrapRemoteException() instanceof\n             ReplicaNotFoundException)) {\n           // special case : replica might not be on the DN, treat as 0 length\n           replicaNotFoundCount--;\n         }\n         \n-        DFSClient.LOG.debug(\"Failed to getReplicaVisibleLength from datanode {}\"\n-              + \" for block {}\", datanode, locatedblock.getBlock(), ioe);\n+        if (DFSClient.LOG.isDebugEnabled()) {\n+          DFSClient.LOG.debug(\"Failed to getReplicaVisibleLength from datanode \"\n+              + datanode + \" for block \" + locatedblock.getBlock(), ioe);\n+        }\n       } finally {\n         if (cdp !\u003d null) {\n           RPC.stopProxy(cdp);\n         }\n       }\n     }\n \n     // Namenode told us about these locations, but none know about the replica\n     // means that we hit the race between pipeline creation start and end.\n     // we require all 3 because some other exception could have happened\n     // on a DN that has it.  we want to report that error\n     if (replicaNotFoundCount \u003d\u003d 0) {\n       return 0;\n     }\n \n     throw new IOException(\"Cannot obtain block length for \" + locatedblock);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private long readBlockLength(LocatedBlock locatedblock) throws IOException {\n    assert locatedblock !\u003d null : \"LocatedBlock cannot be null\";\n    int replicaNotFoundCount \u003d locatedblock.getLocations().length;\n    \n    final DfsClientConf conf \u003d dfsClient.getConf();\n    for(DatanodeInfo datanode : locatedblock.getLocations()) {\n      ClientDatanodeProtocol cdp \u003d null;\n      \n      try {\n        cdp \u003d DFSUtilClient.createClientDatanodeProtocolProxy(datanode,\n            dfsClient.getConfiguration(), conf.getSocketTimeout(),\n            conf.isConnectToDnViaHostname(), locatedblock);\n        \n        final long n \u003d cdp.getReplicaVisibleLength(locatedblock.getBlock());\n        \n        if (n \u003e\u003d 0) {\n          return n;\n        }\n      }\n      catch(IOException ioe) {\n        if (ioe instanceof RemoteException \u0026\u0026\n          (((RemoteException) ioe).unwrapRemoteException() instanceof\n            ReplicaNotFoundException)) {\n          // special case : replica might not be on the DN, treat as 0 length\n          replicaNotFoundCount--;\n        }\n        \n        if (DFSClient.LOG.isDebugEnabled()) {\n          DFSClient.LOG.debug(\"Failed to getReplicaVisibleLength from datanode \"\n              + datanode + \" for block \" + locatedblock.getBlock(), ioe);\n        }\n      } finally {\n        if (cdp !\u003d null) {\n          RPC.stopProxy(cdp);\n        }\n      }\n    }\n\n    // Namenode told us about these locations, but none know about the replica\n    // means that we hit the race between pipeline creation start and end.\n    // we require all 3 because some other exception could have happened\n    // on a DN that has it.  we want to report that error\n    if (replicaNotFoundCount \u003d\u003d 0) {\n      return 0;\n    }\n\n    throw new IOException(\"Cannot obtain block length for \" + locatedblock);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "d5a9a3daa0224249221ffa7b8bd5751ab2feca56": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9170. Move libhdfs / fuse-dfs / libwebhdfs to hdfs-client. Contributed by Haohui Mai.\n",
      "commitDate": "29/09/15 5:48 PM",
      "commitName": "d5a9a3daa0224249221ffa7b8bd5751ab2feca56",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "28/09/15 7:42 AM",
      "commitNameOld": "892ade689f9bcce76daae8f66fc00a49bee8548e",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 1.42,
      "commitsBetweenForRepo": 19,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,48 +1,46 @@\n   private long readBlockLength(LocatedBlock locatedblock) throws IOException {\n     assert locatedblock !\u003d null : \"LocatedBlock cannot be null\";\n     int replicaNotFoundCount \u003d locatedblock.getLocations().length;\n     \n     final DfsClientConf conf \u003d dfsClient.getConf();\n     for(DatanodeInfo datanode : locatedblock.getLocations()) {\n       ClientDatanodeProtocol cdp \u003d null;\n       \n       try {\n         cdp \u003d DFSUtilClient.createClientDatanodeProtocolProxy(datanode,\n             dfsClient.getConfiguration(), conf.getSocketTimeout(),\n             conf.isConnectToDnViaHostname(), locatedblock);\n         \n         final long n \u003d cdp.getReplicaVisibleLength(locatedblock.getBlock());\n         \n         if (n \u003e\u003d 0) {\n           return n;\n         }\n       }\n       catch(IOException ioe) {\n         if (ioe instanceof RemoteException \u0026\u0026\n           (((RemoteException) ioe).unwrapRemoteException() instanceof\n             ReplicaNotFoundException)) {\n           // special case : replica might not be on the DN, treat as 0 length\n           replicaNotFoundCount--;\n         }\n         \n-        if (DFSClient.LOG.isDebugEnabled()) {\n-          DFSClient.LOG.debug(\"Failed to getReplicaVisibleLength from datanode \"\n-              + datanode + \" for block \" + locatedblock.getBlock(), ioe);\n-        }\n+        DFSClient.LOG.debug(\"Failed to getReplicaVisibleLength from datanode {}\"\n+              + \" for block {}\", datanode, locatedblock.getBlock(), ioe);\n       } finally {\n         if (cdp !\u003d null) {\n           RPC.stopProxy(cdp);\n         }\n       }\n     }\n \n     // Namenode told us about these locations, but none know about the replica\n     // means that we hit the race between pipeline creation start and end.\n     // we require all 3 because some other exception could have happened\n     // on a DN that has it.  we want to report that error\n     if (replicaNotFoundCount \u003d\u003d 0) {\n       return 0;\n     }\n \n     throw new IOException(\"Cannot obtain block length for \" + locatedblock);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private long readBlockLength(LocatedBlock locatedblock) throws IOException {\n    assert locatedblock !\u003d null : \"LocatedBlock cannot be null\";\n    int replicaNotFoundCount \u003d locatedblock.getLocations().length;\n    \n    final DfsClientConf conf \u003d dfsClient.getConf();\n    for(DatanodeInfo datanode : locatedblock.getLocations()) {\n      ClientDatanodeProtocol cdp \u003d null;\n      \n      try {\n        cdp \u003d DFSUtilClient.createClientDatanodeProtocolProxy(datanode,\n            dfsClient.getConfiguration(), conf.getSocketTimeout(),\n            conf.isConnectToDnViaHostname(), locatedblock);\n        \n        final long n \u003d cdp.getReplicaVisibleLength(locatedblock.getBlock());\n        \n        if (n \u003e\u003d 0) {\n          return n;\n        }\n      }\n      catch(IOException ioe) {\n        if (ioe instanceof RemoteException \u0026\u0026\n          (((RemoteException) ioe).unwrapRemoteException() instanceof\n            ReplicaNotFoundException)) {\n          // special case : replica might not be on the DN, treat as 0 length\n          replicaNotFoundCount--;\n        }\n        \n        DFSClient.LOG.debug(\"Failed to getReplicaVisibleLength from datanode {}\"\n              + \" for block {}\", datanode, locatedblock.getBlock(), ioe);\n      } finally {\n        if (cdp !\u003d null) {\n          RPC.stopProxy(cdp);\n        }\n      }\n    }\n\n    // Namenode told us about these locations, but none know about the replica\n    // means that we hit the race between pipeline creation start and end.\n    // we require all 3 because some other exception could have happened\n    // on a DN that has it.  we want to report that error\n    if (replicaNotFoundCount \u003d\u003d 0) {\n      return 0;\n    }\n\n    throw new IOException(\"Cannot obtain block length for \" + locatedblock);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8053. Move DFSIn/OutputStream and related classes to hadoop-hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "26/09/15 11:08 AM",
      "commitName": "bf37d3d80e5179dea27e5bd5aea804a38aa9934c",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "26/09/15 9:06 AM",
      "commitNameOld": "861b52db242f238d7e36ad75c158025be959a696",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 0.08,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private long readBlockLength(LocatedBlock locatedblock) throws IOException {\n    assert locatedblock !\u003d null : \"LocatedBlock cannot be null\";\n    int replicaNotFoundCount \u003d locatedblock.getLocations().length;\n    \n    final DfsClientConf conf \u003d dfsClient.getConf();\n    for(DatanodeInfo datanode : locatedblock.getLocations()) {\n      ClientDatanodeProtocol cdp \u003d null;\n      \n      try {\n        cdp \u003d DFSUtilClient.createClientDatanodeProtocolProxy(datanode,\n            dfsClient.getConfiguration(), conf.getSocketTimeout(),\n            conf.isConnectToDnViaHostname(), locatedblock);\n        \n        final long n \u003d cdp.getReplicaVisibleLength(locatedblock.getBlock());\n        \n        if (n \u003e\u003d 0) {\n          return n;\n        }\n      }\n      catch(IOException ioe) {\n        if (ioe instanceof RemoteException \u0026\u0026\n          (((RemoteException) ioe).unwrapRemoteException() instanceof\n            ReplicaNotFoundException)) {\n          // special case : replica might not be on the DN, treat as 0 length\n          replicaNotFoundCount--;\n        }\n        \n        if (DFSClient.LOG.isDebugEnabled()) {\n          DFSClient.LOG.debug(\"Failed to getReplicaVisibleLength from datanode \"\n              + datanode + \" for block \" + locatedblock.getBlock(), ioe);\n        }\n      } finally {\n        if (cdp !\u003d null) {\n          RPC.stopProxy(cdp);\n        }\n      }\n    }\n\n    // Namenode told us about these locations, but none know about the replica\n    // means that we hit the race between pipeline creation start and end.\n    // we require all 3 because some other exception could have happened\n    // on a DN that has it.  we want to report that error\n    if (replicaNotFoundCount \u003d\u003d 0) {\n      return 0;\n    }\n\n    throw new IOException(\"Cannot obtain block length for \" + locatedblock);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java"
      }
    },
    "e2c9b288b223b9fd82dc12018936e13128413492": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8925. Move BlockReaderLocal to hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "28/08/15 2:38 PM",
      "commitName": "e2c9b288b223b9fd82dc12018936e13128413492",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "02/07/15 3:41 AM",
      "commitNameOld": "bff5999d07e9416a22846c849487e509ede55040",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 57.46,
      "commitsBetweenForRepo": 313,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,48 +1,48 @@\n   private long readBlockLength(LocatedBlock locatedblock) throws IOException {\n     assert locatedblock !\u003d null : \"LocatedBlock cannot be null\";\n     int replicaNotFoundCount \u003d locatedblock.getLocations().length;\n     \n     final DfsClientConf conf \u003d dfsClient.getConf();\n     for(DatanodeInfo datanode : locatedblock.getLocations()) {\n       ClientDatanodeProtocol cdp \u003d null;\n       \n       try {\n-        cdp \u003d DFSUtil.createClientDatanodeProtocolProxy(datanode,\n+        cdp \u003d DFSUtilClient.createClientDatanodeProtocolProxy(datanode,\n             dfsClient.getConfiguration(), conf.getSocketTimeout(),\n             conf.isConnectToDnViaHostname(), locatedblock);\n         \n         final long n \u003d cdp.getReplicaVisibleLength(locatedblock.getBlock());\n         \n         if (n \u003e\u003d 0) {\n           return n;\n         }\n       }\n       catch(IOException ioe) {\n         if (ioe instanceof RemoteException \u0026\u0026\n           (((RemoteException) ioe).unwrapRemoteException() instanceof\n             ReplicaNotFoundException)) {\n           // special case : replica might not be on the DN, treat as 0 length\n           replicaNotFoundCount--;\n         }\n         \n         if (DFSClient.LOG.isDebugEnabled()) {\n           DFSClient.LOG.debug(\"Failed to getReplicaVisibleLength from datanode \"\n               + datanode + \" for block \" + locatedblock.getBlock(), ioe);\n         }\n       } finally {\n         if (cdp !\u003d null) {\n           RPC.stopProxy(cdp);\n         }\n       }\n     }\n \n     // Namenode told us about these locations, but none know about the replica\n     // means that we hit the race between pipeline creation start and end.\n     // we require all 3 because some other exception could have happened\n     // on a DN that has it.  we want to report that error\n     if (replicaNotFoundCount \u003d\u003d 0) {\n       return 0;\n     }\n \n     throw new IOException(\"Cannot obtain block length for \" + locatedblock);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private long readBlockLength(LocatedBlock locatedblock) throws IOException {\n    assert locatedblock !\u003d null : \"LocatedBlock cannot be null\";\n    int replicaNotFoundCount \u003d locatedblock.getLocations().length;\n    \n    final DfsClientConf conf \u003d dfsClient.getConf();\n    for(DatanodeInfo datanode : locatedblock.getLocations()) {\n      ClientDatanodeProtocol cdp \u003d null;\n      \n      try {\n        cdp \u003d DFSUtilClient.createClientDatanodeProtocolProxy(datanode,\n            dfsClient.getConfiguration(), conf.getSocketTimeout(),\n            conf.isConnectToDnViaHostname(), locatedblock);\n        \n        final long n \u003d cdp.getReplicaVisibleLength(locatedblock.getBlock());\n        \n        if (n \u003e\u003d 0) {\n          return n;\n        }\n      }\n      catch(IOException ioe) {\n        if (ioe instanceof RemoteException \u0026\u0026\n          (((RemoteException) ioe).unwrapRemoteException() instanceof\n            ReplicaNotFoundException)) {\n          // special case : replica might not be on the DN, treat as 0 length\n          replicaNotFoundCount--;\n        }\n        \n        if (DFSClient.LOG.isDebugEnabled()) {\n          DFSClient.LOG.debug(\"Failed to getReplicaVisibleLength from datanode \"\n              + datanode + \" for block \" + locatedblock.getBlock(), ioe);\n        }\n      } finally {\n        if (cdp !\u003d null) {\n          RPC.stopProxy(cdp);\n        }\n      }\n    }\n\n    // Namenode told us about these locations, but none know about the replica\n    // means that we hit the race between pipeline creation start and end.\n    // we require all 3 because some other exception could have happened\n    // on a DN that has it.  we want to report that error\n    if (replicaNotFoundCount \u003d\u003d 0) {\n      return 0;\n    }\n\n    throw new IOException(\"Cannot obtain block length for \" + locatedblock);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "2cc9514ad643ae49d30524743420ee9744e571bd": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8100. Refactor DFSClient.Conf to a standalone class and separates short-circuit related conf to ShortCircuitConf.\n",
      "commitDate": "10/04/15 2:48 PM",
      "commitName": "2cc9514ad643ae49d30524743420ee9744e571bd",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "09/04/15 11:22 AM",
      "commitNameOld": "30acb7372ab97adf9bc86ead529c96cfe36e2396",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 1.14,
      "commitsBetweenForRepo": 18,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,47 +1,48 @@\n   private long readBlockLength(LocatedBlock locatedblock) throws IOException {\n     assert locatedblock !\u003d null : \"LocatedBlock cannot be null\";\n     int replicaNotFoundCount \u003d locatedblock.getLocations().length;\n     \n+    final DfsClientConf conf \u003d dfsClient.getConf();\n     for(DatanodeInfo datanode : locatedblock.getLocations()) {\n       ClientDatanodeProtocol cdp \u003d null;\n       \n       try {\n         cdp \u003d DFSUtil.createClientDatanodeProtocolProxy(datanode,\n-            dfsClient.getConfiguration(), dfsClient.getConf().socketTimeout,\n-            dfsClient.getConf().connectToDnViaHostname, locatedblock);\n+            dfsClient.getConfiguration(), conf.getSocketTimeout(),\n+            conf.isConnectToDnViaHostname(), locatedblock);\n         \n         final long n \u003d cdp.getReplicaVisibleLength(locatedblock.getBlock());\n         \n         if (n \u003e\u003d 0) {\n           return n;\n         }\n       }\n       catch(IOException ioe) {\n         if (ioe instanceof RemoteException \u0026\u0026\n           (((RemoteException) ioe).unwrapRemoteException() instanceof\n             ReplicaNotFoundException)) {\n           // special case : replica might not be on the DN, treat as 0 length\n           replicaNotFoundCount--;\n         }\n         \n         if (DFSClient.LOG.isDebugEnabled()) {\n           DFSClient.LOG.debug(\"Failed to getReplicaVisibleLength from datanode \"\n               + datanode + \" for block \" + locatedblock.getBlock(), ioe);\n         }\n       } finally {\n         if (cdp !\u003d null) {\n           RPC.stopProxy(cdp);\n         }\n       }\n     }\n \n     // Namenode told us about these locations, but none know about the replica\n     // means that we hit the race between pipeline creation start and end.\n     // we require all 3 because some other exception could have happened\n     // on a DN that has it.  we want to report that error\n     if (replicaNotFoundCount \u003d\u003d 0) {\n       return 0;\n     }\n \n     throw new IOException(\"Cannot obtain block length for \" + locatedblock);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private long readBlockLength(LocatedBlock locatedblock) throws IOException {\n    assert locatedblock !\u003d null : \"LocatedBlock cannot be null\";\n    int replicaNotFoundCount \u003d locatedblock.getLocations().length;\n    \n    final DfsClientConf conf \u003d dfsClient.getConf();\n    for(DatanodeInfo datanode : locatedblock.getLocations()) {\n      ClientDatanodeProtocol cdp \u003d null;\n      \n      try {\n        cdp \u003d DFSUtil.createClientDatanodeProtocolProxy(datanode,\n            dfsClient.getConfiguration(), conf.getSocketTimeout(),\n            conf.isConnectToDnViaHostname(), locatedblock);\n        \n        final long n \u003d cdp.getReplicaVisibleLength(locatedblock.getBlock());\n        \n        if (n \u003e\u003d 0) {\n          return n;\n        }\n      }\n      catch(IOException ioe) {\n        if (ioe instanceof RemoteException \u0026\u0026\n          (((RemoteException) ioe).unwrapRemoteException() instanceof\n            ReplicaNotFoundException)) {\n          // special case : replica might not be on the DN, treat as 0 length\n          replicaNotFoundCount--;\n        }\n        \n        if (DFSClient.LOG.isDebugEnabled()) {\n          DFSClient.LOG.debug(\"Failed to getReplicaVisibleLength from datanode \"\n              + datanode + \" for block \" + locatedblock.getBlock(), ioe);\n        }\n      } finally {\n        if (cdp !\u003d null) {\n          RPC.stopProxy(cdp);\n        }\n      }\n    }\n\n    // Namenode told us about these locations, but none know about the replica\n    // means that we hit the race between pipeline creation start and end.\n    // we require all 3 because some other exception could have happened\n    // on a DN that has it.  we want to report that error\n    if (replicaNotFoundCount \u003d\u003d 0) {\n      return 0;\n    }\n\n    throw new IOException(\"Cannot obtain block length for \" + locatedblock);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "c68b1d1b31e304c27e419e810ded0fc97e435ea6": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4914. Use DFSClient.Conf instead of Configuration.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1494854 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/06/13 9:43 PM",
      "commitName": "c68b1d1b31e304c27e419e810ded0fc97e435ea6",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "10/05/13 10:58 AM",
      "commitNameOld": "4ed1fc58c0683bbcd5c4c211ea162ed37bf7dc4f",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 40.45,
      "commitsBetweenForRepo": 278,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,47 +1,47 @@\n   private long readBlockLength(LocatedBlock locatedblock) throws IOException {\n     assert locatedblock !\u003d null : \"LocatedBlock cannot be null\";\n     int replicaNotFoundCount \u003d locatedblock.getLocations().length;\n     \n     for(DatanodeInfo datanode : locatedblock.getLocations()) {\n       ClientDatanodeProtocol cdp \u003d null;\n       \n       try {\n-        cdp \u003d DFSUtil.createClientDatanodeProtocolProxy(\n-            datanode, dfsClient.conf, dfsClient.getConf().socketTimeout,\n+        cdp \u003d DFSUtil.createClientDatanodeProtocolProxy(datanode,\n+            dfsClient.getConfiguration(), dfsClient.getConf().socketTimeout,\n             dfsClient.getConf().connectToDnViaHostname, locatedblock);\n         \n         final long n \u003d cdp.getReplicaVisibleLength(locatedblock.getBlock());\n         \n         if (n \u003e\u003d 0) {\n           return n;\n         }\n       }\n       catch(IOException ioe) {\n         if (ioe instanceof RemoteException \u0026\u0026\n           (((RemoteException) ioe).unwrapRemoteException() instanceof\n             ReplicaNotFoundException)) {\n           // special case : replica might not be on the DN, treat as 0 length\n           replicaNotFoundCount--;\n         }\n         \n         if (DFSClient.LOG.isDebugEnabled()) {\n           DFSClient.LOG.debug(\"Failed to getReplicaVisibleLength from datanode \"\n               + datanode + \" for block \" + locatedblock.getBlock(), ioe);\n         }\n       } finally {\n         if (cdp !\u003d null) {\n           RPC.stopProxy(cdp);\n         }\n       }\n     }\n \n     // Namenode told us about these locations, but none know about the replica\n     // means that we hit the race between pipeline creation start and end.\n     // we require all 3 because some other exception could have happened\n     // on a DN that has it.  we want to report that error\n     if (replicaNotFoundCount \u003d\u003d 0) {\n       return 0;\n     }\n \n     throw new IOException(\"Cannot obtain block length for \" + locatedblock);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private long readBlockLength(LocatedBlock locatedblock) throws IOException {\n    assert locatedblock !\u003d null : \"LocatedBlock cannot be null\";\n    int replicaNotFoundCount \u003d locatedblock.getLocations().length;\n    \n    for(DatanodeInfo datanode : locatedblock.getLocations()) {\n      ClientDatanodeProtocol cdp \u003d null;\n      \n      try {\n        cdp \u003d DFSUtil.createClientDatanodeProtocolProxy(datanode,\n            dfsClient.getConfiguration(), dfsClient.getConf().socketTimeout,\n            dfsClient.getConf().connectToDnViaHostname, locatedblock);\n        \n        final long n \u003d cdp.getReplicaVisibleLength(locatedblock.getBlock());\n        \n        if (n \u003e\u003d 0) {\n          return n;\n        }\n      }\n      catch(IOException ioe) {\n        if (ioe instanceof RemoteException \u0026\u0026\n          (((RemoteException) ioe).unwrapRemoteException() instanceof\n            ReplicaNotFoundException)) {\n          // special case : replica might not be on the DN, treat as 0 length\n          replicaNotFoundCount--;\n        }\n        \n        if (DFSClient.LOG.isDebugEnabled()) {\n          DFSClient.LOG.debug(\"Failed to getReplicaVisibleLength from datanode \"\n              + datanode + \" for block \" + locatedblock.getBlock(), ioe);\n        }\n      } finally {\n        if (cdp !\u003d null) {\n          RPC.stopProxy(cdp);\n        }\n      }\n    }\n\n    // Namenode told us about these locations, but none know about the replica\n    // means that we hit the race between pipeline creation start and end.\n    // we require all 3 because some other exception could have happened\n    // on a DN that has it.  we want to report that error\n    if (replicaNotFoundCount \u003d\u003d 0) {\n      return 0;\n    }\n\n    throw new IOException(\"Cannot obtain block length for \" + locatedblock);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "f98d8eb291be364102b5c3011ce72e8f43eab389": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3150. Add option for clients to contact DNs via hostname. Contributed by Eli Collins\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1373094 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/08/12 1:59 PM",
      "commitName": "f98d8eb291be364102b5c3011ce72e8f43eab389",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "07/08/12 9:40 AM",
      "commitNameOld": "9b4a7900c7dfc0590316eedaa97144f938885651",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 7.18,
      "commitsBetweenForRepo": 33,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,46 +1,47 @@\n   private long readBlockLength(LocatedBlock locatedblock) throws IOException {\n     assert locatedblock !\u003d null : \"LocatedBlock cannot be null\";\n     int replicaNotFoundCount \u003d locatedblock.getLocations().length;\n     \n     for(DatanodeInfo datanode : locatedblock.getLocations()) {\n       ClientDatanodeProtocol cdp \u003d null;\n       \n       try {\n         cdp \u003d DFSUtil.createClientDatanodeProtocolProxy(\n-        datanode, dfsClient.conf, dfsClient.getConf().socketTimeout, locatedblock);\n+            datanode, dfsClient.conf, dfsClient.getConf().socketTimeout,\n+            dfsClient.getConf().connectToDnViaHostname, locatedblock);\n         \n         final long n \u003d cdp.getReplicaVisibleLength(locatedblock.getBlock());\n         \n         if (n \u003e\u003d 0) {\n           return n;\n         }\n       }\n       catch(IOException ioe) {\n         if (ioe instanceof RemoteException \u0026\u0026\n           (((RemoteException) ioe).unwrapRemoteException() instanceof\n             ReplicaNotFoundException)) {\n           // special case : replica might not be on the DN, treat as 0 length\n           replicaNotFoundCount--;\n         }\n         \n         if (DFSClient.LOG.isDebugEnabled()) {\n           DFSClient.LOG.debug(\"Failed to getReplicaVisibleLength from datanode \"\n               + datanode + \" for block \" + locatedblock.getBlock(), ioe);\n         }\n       } finally {\n         if (cdp !\u003d null) {\n           RPC.stopProxy(cdp);\n         }\n       }\n     }\n \n     // Namenode told us about these locations, but none know about the replica\n     // means that we hit the race between pipeline creation start and end.\n     // we require all 3 because some other exception could have happened\n     // on a DN that has it.  we want to report that error\n     if (replicaNotFoundCount \u003d\u003d 0) {\n       return 0;\n     }\n \n     throw new IOException(\"Cannot obtain block length for \" + locatedblock);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private long readBlockLength(LocatedBlock locatedblock) throws IOException {\n    assert locatedblock !\u003d null : \"LocatedBlock cannot be null\";\n    int replicaNotFoundCount \u003d locatedblock.getLocations().length;\n    \n    for(DatanodeInfo datanode : locatedblock.getLocations()) {\n      ClientDatanodeProtocol cdp \u003d null;\n      \n      try {\n        cdp \u003d DFSUtil.createClientDatanodeProtocolProxy(\n            datanode, dfsClient.conf, dfsClient.getConf().socketTimeout,\n            dfsClient.getConf().connectToDnViaHostname, locatedblock);\n        \n        final long n \u003d cdp.getReplicaVisibleLength(locatedblock.getBlock());\n        \n        if (n \u003e\u003d 0) {\n          return n;\n        }\n      }\n      catch(IOException ioe) {\n        if (ioe instanceof RemoteException \u0026\u0026\n          (((RemoteException) ioe).unwrapRemoteException() instanceof\n            ReplicaNotFoundException)) {\n          // special case : replica might not be on the DN, treat as 0 length\n          replicaNotFoundCount--;\n        }\n        \n        if (DFSClient.LOG.isDebugEnabled()) {\n          DFSClient.LOG.debug(\"Failed to getReplicaVisibleLength from datanode \"\n              + datanode + \" for block \" + locatedblock.getBlock(), ioe);\n        }\n      } finally {\n        if (cdp !\u003d null) {\n          RPC.stopProxy(cdp);\n        }\n      }\n    }\n\n    // Namenode told us about these locations, but none know about the replica\n    // means that we hit the race between pipeline creation start and end.\n    // we require all 3 because some other exception could have happened\n    // on a DN that has it.  we want to report that error\n    if (replicaNotFoundCount \u003d\u003d 0) {\n      return 0;\n    }\n\n    throw new IOException(\"Cannot obtain block length for \" + locatedblock);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "d28b98242854ff7f9d615e1c9d6a5b7584ce2498": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3222. DFSInputStream#openInfo should not silently get the length as 0 when locations length is zero for last partial block. Contributed by Uma Maheswara Rao G.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1331061 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "26/04/12 1:18 PM",
      "commitName": "d28b98242854ff7f9d615e1c9d6a5b7584ce2498",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "18/04/12 7:34 PM",
      "commitNameOld": "c6d3537d337d71a3e566bcae824cc2377e9a9ed2",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 7.74,
      "commitsBetweenForRepo": 43,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,48 +1,46 @@\n   private long readBlockLength(LocatedBlock locatedblock) throws IOException {\n-    if (locatedblock \u003d\u003d null || locatedblock.getLocations().length \u003d\u003d 0) {\n-      return 0;\n-    }\n+    assert locatedblock !\u003d null : \"LocatedBlock cannot be null\";\n     int replicaNotFoundCount \u003d locatedblock.getLocations().length;\n     \n     for(DatanodeInfo datanode : locatedblock.getLocations()) {\n       ClientDatanodeProtocol cdp \u003d null;\n       \n       try {\n         cdp \u003d DFSUtil.createClientDatanodeProtocolProxy(\n         datanode, dfsClient.conf, dfsClient.getConf().socketTimeout, locatedblock);\n         \n         final long n \u003d cdp.getReplicaVisibleLength(locatedblock.getBlock());\n         \n         if (n \u003e\u003d 0) {\n           return n;\n         }\n       }\n       catch(IOException ioe) {\n         if (ioe instanceof RemoteException \u0026\u0026\n           (((RemoteException) ioe).unwrapRemoteException() instanceof\n             ReplicaNotFoundException)) {\n           // special case : replica might not be on the DN, treat as 0 length\n           replicaNotFoundCount--;\n         }\n         \n         if (DFSClient.LOG.isDebugEnabled()) {\n           DFSClient.LOG.debug(\"Failed to getReplicaVisibleLength from datanode \"\n               + datanode + \" for block \" + locatedblock.getBlock(), ioe);\n         }\n       } finally {\n         if (cdp !\u003d null) {\n           RPC.stopProxy(cdp);\n         }\n       }\n     }\n \n     // Namenode told us about these locations, but none know about the replica\n     // means that we hit the race between pipeline creation start and end.\n     // we require all 3 because some other exception could have happened\n     // on a DN that has it.  we want to report that error\n     if (replicaNotFoundCount \u003d\u003d 0) {\n       return 0;\n     }\n \n     throw new IOException(\"Cannot obtain block length for \" + locatedblock);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private long readBlockLength(LocatedBlock locatedblock) throws IOException {\n    assert locatedblock !\u003d null : \"LocatedBlock cannot be null\";\n    int replicaNotFoundCount \u003d locatedblock.getLocations().length;\n    \n    for(DatanodeInfo datanode : locatedblock.getLocations()) {\n      ClientDatanodeProtocol cdp \u003d null;\n      \n      try {\n        cdp \u003d DFSUtil.createClientDatanodeProtocolProxy(\n        datanode, dfsClient.conf, dfsClient.getConf().socketTimeout, locatedblock);\n        \n        final long n \u003d cdp.getReplicaVisibleLength(locatedblock.getBlock());\n        \n        if (n \u003e\u003d 0) {\n          return n;\n        }\n      }\n      catch(IOException ioe) {\n        if (ioe instanceof RemoteException \u0026\u0026\n          (((RemoteException) ioe).unwrapRemoteException() instanceof\n            ReplicaNotFoundException)) {\n          // special case : replica might not be on the DN, treat as 0 length\n          replicaNotFoundCount--;\n        }\n        \n        if (DFSClient.LOG.isDebugEnabled()) {\n          DFSClient.LOG.debug(\"Failed to getReplicaVisibleLength from datanode \"\n              + datanode + \" for block \" + locatedblock.getBlock(), ioe);\n        }\n      } finally {\n        if (cdp !\u003d null) {\n          RPC.stopProxy(cdp);\n        }\n      }\n    }\n\n    // Namenode told us about these locations, but none know about the replica\n    // means that we hit the race between pipeline creation start and end.\n    // we require all 3 because some other exception could have happened\n    // on a DN that has it.  we want to report that error\n    if (replicaNotFoundCount \u003d\u003d 0) {\n      return 0;\n    }\n\n    throw new IOException(\"Cannot obtain block length for \" + locatedblock);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private long readBlockLength(LocatedBlock locatedblock) throws IOException {\n    if (locatedblock \u003d\u003d null || locatedblock.getLocations().length \u003d\u003d 0) {\n      return 0;\n    }\n    int replicaNotFoundCount \u003d locatedblock.getLocations().length;\n    \n    for(DatanodeInfo datanode : locatedblock.getLocations()) {\n      ClientDatanodeProtocol cdp \u003d null;\n      \n      try {\n        cdp \u003d DFSUtil.createClientDatanodeProtocolProxy(\n        datanode, dfsClient.conf, dfsClient.getConf().socketTimeout, locatedblock);\n        \n        final long n \u003d cdp.getReplicaVisibleLength(locatedblock.getBlock());\n        \n        if (n \u003e\u003d 0) {\n          return n;\n        }\n      }\n      catch(IOException ioe) {\n        if (ioe instanceof RemoteException \u0026\u0026\n          (((RemoteException) ioe).unwrapRemoteException() instanceof\n            ReplicaNotFoundException)) {\n          // special case : replica might not be on the DN, treat as 0 length\n          replicaNotFoundCount--;\n        }\n        \n        if (DFSClient.LOG.isDebugEnabled()) {\n          DFSClient.LOG.debug(\"Failed to getReplicaVisibleLength from datanode \"\n              + datanode + \" for block \" + locatedblock.getBlock(), ioe);\n        }\n      } finally {\n        if (cdp !\u003d null) {\n          RPC.stopProxy(cdp);\n        }\n      }\n    }\n\n    // Namenode told us about these locations, but none know about the replica\n    // means that we hit the race between pipeline creation start and end.\n    // we require all 3 because some other exception could have happened\n    // on a DN that has it.  we want to report that error\n    if (replicaNotFoundCount \u003d\u003d 0) {\n      return 0;\n    }\n\n    throw new IOException(\"Cannot obtain block length for \" + locatedblock);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private long readBlockLength(LocatedBlock locatedblock) throws IOException {\n    if (locatedblock \u003d\u003d null || locatedblock.getLocations().length \u003d\u003d 0) {\n      return 0;\n    }\n    int replicaNotFoundCount \u003d locatedblock.getLocations().length;\n    \n    for(DatanodeInfo datanode : locatedblock.getLocations()) {\n      ClientDatanodeProtocol cdp \u003d null;\n      \n      try {\n        cdp \u003d DFSUtil.createClientDatanodeProtocolProxy(\n        datanode, dfsClient.conf, dfsClient.getConf().socketTimeout, locatedblock);\n        \n        final long n \u003d cdp.getReplicaVisibleLength(locatedblock.getBlock());\n        \n        if (n \u003e\u003d 0) {\n          return n;\n        }\n      }\n      catch(IOException ioe) {\n        if (ioe instanceof RemoteException \u0026\u0026\n          (((RemoteException) ioe).unwrapRemoteException() instanceof\n            ReplicaNotFoundException)) {\n          // special case : replica might not be on the DN, treat as 0 length\n          replicaNotFoundCount--;\n        }\n        \n        if (DFSClient.LOG.isDebugEnabled()) {\n          DFSClient.LOG.debug(\"Failed to getReplicaVisibleLength from datanode \"\n              + datanode + \" for block \" + locatedblock.getBlock(), ioe);\n        }\n      } finally {\n        if (cdp !\u003d null) {\n          RPC.stopProxy(cdp);\n        }\n      }\n    }\n\n    // Namenode told us about these locations, but none know about the replica\n    // means that we hit the race between pipeline creation start and end.\n    // we require all 3 because some other exception could have happened\n    // on a DN that has it.  we want to report that error\n    if (replicaNotFoundCount \u003d\u003d 0) {\n      return 0;\n    }\n\n    throw new IOException(\"Cannot obtain block length for \" + locatedblock);\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/DFSInputStream.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java"
      }
    },
    "710e5a960e8af1d4c73e386041096aacfee8b828": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2161. Move createNamenode(..), createClientDatanodeProtocolProxy(..) and Random object creation to DFSUtil; move DFSClient.stringifyToken(..) to DelegationTokenIdentifier.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1148348 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/07/11 7:23 AM",
      "commitName": "710e5a960e8af1d4c73e386041096aacfee8b828",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "12/07/11 6:11 PM",
      "commitNameOld": "2c5dd549e31aa5d3377ff2619ede8e92b8dc5d0f",
      "commitAuthorOld": "Jitendra Nath Pandey",
      "daysBetweenCommits": 6.55,
      "commitsBetweenForRepo": 28,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,48 +1,48 @@\n   private long readBlockLength(LocatedBlock locatedblock) throws IOException {\n     if (locatedblock \u003d\u003d null || locatedblock.getLocations().length \u003d\u003d 0) {\n       return 0;\n     }\n     int replicaNotFoundCount \u003d locatedblock.getLocations().length;\n     \n     for(DatanodeInfo datanode : locatedblock.getLocations()) {\n       ClientDatanodeProtocol cdp \u003d null;\n       \n       try {\n-        cdp \u003d DFSClient.createClientDatanodeProtocolProxy(\n+        cdp \u003d DFSUtil.createClientDatanodeProtocolProxy(\n         datanode, dfsClient.conf, dfsClient.getConf().socketTimeout, locatedblock);\n         \n         final long n \u003d cdp.getReplicaVisibleLength(locatedblock.getBlock());\n         \n         if (n \u003e\u003d 0) {\n           return n;\n         }\n       }\n       catch(IOException ioe) {\n         if (ioe instanceof RemoteException \u0026\u0026\n           (((RemoteException) ioe).unwrapRemoteException() instanceof\n             ReplicaNotFoundException)) {\n           // special case : replica might not be on the DN, treat as 0 length\n           replicaNotFoundCount--;\n         }\n         \n         if (DFSClient.LOG.isDebugEnabled()) {\n           DFSClient.LOG.debug(\"Failed to getReplicaVisibleLength from datanode \"\n               + datanode + \" for block \" + locatedblock.getBlock(), ioe);\n         }\n       } finally {\n         if (cdp !\u003d null) {\n           RPC.stopProxy(cdp);\n         }\n       }\n     }\n \n     // Namenode told us about these locations, but none know about the replica\n     // means that we hit the race between pipeline creation start and end.\n     // we require all 3 because some other exception could have happened\n     // on a DN that has it.  we want to report that error\n     if (replicaNotFoundCount \u003d\u003d 0) {\n       return 0;\n     }\n \n     throw new IOException(\"Cannot obtain block length for \" + locatedblock);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private long readBlockLength(LocatedBlock locatedblock) throws IOException {\n    if (locatedblock \u003d\u003d null || locatedblock.getLocations().length \u003d\u003d 0) {\n      return 0;\n    }\n    int replicaNotFoundCount \u003d locatedblock.getLocations().length;\n    \n    for(DatanodeInfo datanode : locatedblock.getLocations()) {\n      ClientDatanodeProtocol cdp \u003d null;\n      \n      try {\n        cdp \u003d DFSUtil.createClientDatanodeProtocolProxy(\n        datanode, dfsClient.conf, dfsClient.getConf().socketTimeout, locatedblock);\n        \n        final long n \u003d cdp.getReplicaVisibleLength(locatedblock.getBlock());\n        \n        if (n \u003e\u003d 0) {\n          return n;\n        }\n      }\n      catch(IOException ioe) {\n        if (ioe instanceof RemoteException \u0026\u0026\n          (((RemoteException) ioe).unwrapRemoteException() instanceof\n            ReplicaNotFoundException)) {\n          // special case : replica might not be on the DN, treat as 0 length\n          replicaNotFoundCount--;\n        }\n        \n        if (DFSClient.LOG.isDebugEnabled()) {\n          DFSClient.LOG.debug(\"Failed to getReplicaVisibleLength from datanode \"\n              + datanode + \" for block \" + locatedblock.getBlock(), ioe);\n        }\n      } finally {\n        if (cdp !\u003d null) {\n          RPC.stopProxy(cdp);\n        }\n      }\n    }\n\n    // Namenode told us about these locations, but none know about the replica\n    // means that we hit the race between pipeline creation start and end.\n    // we require all 3 because some other exception could have happened\n    // on a DN that has it.  we want to report that error\n    if (replicaNotFoundCount \u003d\u003d 0) {\n      return 0;\n    }\n\n    throw new IOException(\"Cannot obtain block length for \" + locatedblock);\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "fd9997989c1f1c6f806c57a806e7225ca599fc0c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2092. Remove some object references to Configuration in DFSClient.  Contributed by Bharath Mundlapudi\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1139097 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "23/06/11 3:24 PM",
      "commitName": "fd9997989c1f1c6f806c57a806e7225ca599fc0c",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "12/06/11 3:00 PM",
      "commitNameOld": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 11.02,
      "commitsBetweenForRepo": 36,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,48 +1,48 @@\n   private long readBlockLength(LocatedBlock locatedblock) throws IOException {\n     if (locatedblock \u003d\u003d null || locatedblock.getLocations().length \u003d\u003d 0) {\n       return 0;\n     }\n     int replicaNotFoundCount \u003d locatedblock.getLocations().length;\n     \n     for(DatanodeInfo datanode : locatedblock.getLocations()) {\n       ClientDatanodeProtocol cdp \u003d null;\n       \n       try {\n         cdp \u003d DFSClient.createClientDatanodeProtocolProxy(\n-        datanode, dfsClient.conf, dfsClient.socketTimeout, locatedblock);\n+        datanode, dfsClient.conf, dfsClient.getConf().socketTimeout, locatedblock);\n         \n         final long n \u003d cdp.getReplicaVisibleLength(locatedblock.getBlock());\n         \n         if (n \u003e\u003d 0) {\n           return n;\n         }\n       }\n       catch(IOException ioe) {\n         if (ioe instanceof RemoteException \u0026\u0026\n           (((RemoteException) ioe).unwrapRemoteException() instanceof\n             ReplicaNotFoundException)) {\n           // special case : replica might not be on the DN, treat as 0 length\n           replicaNotFoundCount--;\n         }\n         \n         if (DFSClient.LOG.isDebugEnabled()) {\n           DFSClient.LOG.debug(\"Failed to getReplicaVisibleLength from datanode \"\n               + datanode + \" for block \" + locatedblock.getBlock(), ioe);\n         }\n       } finally {\n         if (cdp !\u003d null) {\n           RPC.stopProxy(cdp);\n         }\n       }\n     }\n \n     // Namenode told us about these locations, but none know about the replica\n     // means that we hit the race between pipeline creation start and end.\n     // we require all 3 because some other exception could have happened\n     // on a DN that has it.  we want to report that error\n     if (replicaNotFoundCount \u003d\u003d 0) {\n       return 0;\n     }\n \n     throw new IOException(\"Cannot obtain block length for \" + locatedblock);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private long readBlockLength(LocatedBlock locatedblock) throws IOException {\n    if (locatedblock \u003d\u003d null || locatedblock.getLocations().length \u003d\u003d 0) {\n      return 0;\n    }\n    int replicaNotFoundCount \u003d locatedblock.getLocations().length;\n    \n    for(DatanodeInfo datanode : locatedblock.getLocations()) {\n      ClientDatanodeProtocol cdp \u003d null;\n      \n      try {\n        cdp \u003d DFSClient.createClientDatanodeProtocolProxy(\n        datanode, dfsClient.conf, dfsClient.getConf().socketTimeout, locatedblock);\n        \n        final long n \u003d cdp.getReplicaVisibleLength(locatedblock.getBlock());\n        \n        if (n \u003e\u003d 0) {\n          return n;\n        }\n      }\n      catch(IOException ioe) {\n        if (ioe instanceof RemoteException \u0026\u0026\n          (((RemoteException) ioe).unwrapRemoteException() instanceof\n            ReplicaNotFoundException)) {\n          // special case : replica might not be on the DN, treat as 0 length\n          replicaNotFoundCount--;\n        }\n        \n        if (DFSClient.LOG.isDebugEnabled()) {\n          DFSClient.LOG.debug(\"Failed to getReplicaVisibleLength from datanode \"\n              + datanode + \" for block \" + locatedblock.getBlock(), ioe);\n        }\n      } finally {\n        if (cdp !\u003d null) {\n          RPC.stopProxy(cdp);\n        }\n      }\n    }\n\n    // Namenode told us about these locations, but none know about the replica\n    // means that we hit the race between pipeline creation start and end.\n    // we require all 3 because some other exception could have happened\n    // on a DN that has it.  we want to report that error\n    if (replicaNotFoundCount \u003d\u003d 0) {\n      return 0;\n    }\n\n    throw new IOException(\"Cannot obtain block length for \" + locatedblock);\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,48 @@\n+  private long readBlockLength(LocatedBlock locatedblock) throws IOException {\n+    if (locatedblock \u003d\u003d null || locatedblock.getLocations().length \u003d\u003d 0) {\n+      return 0;\n+    }\n+    int replicaNotFoundCount \u003d locatedblock.getLocations().length;\n+    \n+    for(DatanodeInfo datanode : locatedblock.getLocations()) {\n+      ClientDatanodeProtocol cdp \u003d null;\n+      \n+      try {\n+        cdp \u003d DFSClient.createClientDatanodeProtocolProxy(\n+        datanode, dfsClient.conf, dfsClient.socketTimeout, locatedblock);\n+        \n+        final long n \u003d cdp.getReplicaVisibleLength(locatedblock.getBlock());\n+        \n+        if (n \u003e\u003d 0) {\n+          return n;\n+        }\n+      }\n+      catch(IOException ioe) {\n+        if (ioe instanceof RemoteException \u0026\u0026\n+          (((RemoteException) ioe).unwrapRemoteException() instanceof\n+            ReplicaNotFoundException)) {\n+          // special case : replica might not be on the DN, treat as 0 length\n+          replicaNotFoundCount--;\n+        }\n+        \n+        if (DFSClient.LOG.isDebugEnabled()) {\n+          DFSClient.LOG.debug(\"Failed to getReplicaVisibleLength from datanode \"\n+              + datanode + \" for block \" + locatedblock.getBlock(), ioe);\n+        }\n+      } finally {\n+        if (cdp !\u003d null) {\n+          RPC.stopProxy(cdp);\n+        }\n+      }\n+    }\n+\n+    // Namenode told us about these locations, but none know about the replica\n+    // means that we hit the race between pipeline creation start and end.\n+    // we require all 3 because some other exception could have happened\n+    // on a DN that has it.  we want to report that error\n+    if (replicaNotFoundCount \u003d\u003d 0) {\n+      return 0;\n+    }\n+\n+    throw new IOException(\"Cannot obtain block length for \" + locatedblock);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private long readBlockLength(LocatedBlock locatedblock) throws IOException {\n    if (locatedblock \u003d\u003d null || locatedblock.getLocations().length \u003d\u003d 0) {\n      return 0;\n    }\n    int replicaNotFoundCount \u003d locatedblock.getLocations().length;\n    \n    for(DatanodeInfo datanode : locatedblock.getLocations()) {\n      ClientDatanodeProtocol cdp \u003d null;\n      \n      try {\n        cdp \u003d DFSClient.createClientDatanodeProtocolProxy(\n        datanode, dfsClient.conf, dfsClient.socketTimeout, locatedblock);\n        \n        final long n \u003d cdp.getReplicaVisibleLength(locatedblock.getBlock());\n        \n        if (n \u003e\u003d 0) {\n          return n;\n        }\n      }\n      catch(IOException ioe) {\n        if (ioe instanceof RemoteException \u0026\u0026\n          (((RemoteException) ioe).unwrapRemoteException() instanceof\n            ReplicaNotFoundException)) {\n          // special case : replica might not be on the DN, treat as 0 length\n          replicaNotFoundCount--;\n        }\n        \n        if (DFSClient.LOG.isDebugEnabled()) {\n          DFSClient.LOG.debug(\"Failed to getReplicaVisibleLength from datanode \"\n              + datanode + \" for block \" + locatedblock.getBlock(), ioe);\n        }\n      } finally {\n        if (cdp !\u003d null) {\n          RPC.stopProxy(cdp);\n        }\n      }\n    }\n\n    // Namenode told us about these locations, but none know about the replica\n    // means that we hit the race between pipeline creation start and end.\n    // we require all 3 because some other exception could have happened\n    // on a DN that has it.  we want to report that error\n    if (replicaNotFoundCount \u003d\u003d 0) {\n      return 0;\n    }\n\n    throw new IOException(\"Cannot obtain block length for \" + locatedblock);\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/DFSInputStream.java"
    }
  }
}