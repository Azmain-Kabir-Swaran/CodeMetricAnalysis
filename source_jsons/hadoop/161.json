{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "RpcProgramNfs3.java",
  "functionName": "readdir",
  "functionId": "readdir___xdr-XDR__info-RpcInfo",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
  "functionStartLine": 1524,
  "functionEndLine": 1526,
  "numCommitsSeen": 105,
  "timeTaken": 3833,
  "changeHistory": [
    "c9aa74743773c61be938cc1a6ea811ae1404bca2",
    "2ecab65e3e290a1ee192b39ec70868863853543a",
    "05f35518f19d48890770128727289582cca3457b",
    "a9befa6f0a8a27b49b1e6483e749661f493f06cf",
    "613979c8fdacf25fd563395ecc399c4de94d3ee7",
    "15632cd76f12c2f7df50d0df4865fbe3d8261597",
    "37f587563a943a827fbff865f5302bac6d202415"
  ],
  "changeHistoryShort": {
    "c9aa74743773c61be938cc1a6ea811ae1404bca2": "Ybodychange",
    "2ecab65e3e290a1ee192b39ec70868863853543a": "Ymultichange(Yparameterchange,Ybodychange)",
    "05f35518f19d48890770128727289582cca3457b": "Ybodychange",
    "a9befa6f0a8a27b49b1e6483e749661f493f06cf": "Ybodychange",
    "613979c8fdacf25fd563395ecc399c4de94d3ee7": "Ymultichange(Yparameterchange,Ybodychange)",
    "15632cd76f12c2f7df50d0df4865fbe3d8261597": "Ymultichange(Yparameterchange,Ybodychange)",
    "37f587563a943a827fbff865f5302bac6d202415": "Yintroduced"
  },
  "changeHistoryDetails": {
    "c9aa74743773c61be938cc1a6ea811ae1404bca2": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6451. NFS should not return NFS3ERR_IO for AccessControlException. Contributed by Abhiraj Butala\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1615702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/08/14 10:40 AM",
      "commitName": "c9aa74743773c61be938cc1a6ea811ae1404bca2",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "23/07/14 2:22 PM",
      "commitNameOld": "2a5f1029a5221c42ab61b22f99d79251ed069ca4",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 11.85,
      "commitsBetweenForRepo": 69,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,5 +1,3 @@\n   public READDIR3Response readdir(XDR xdr, RpcInfo info) {\n-    SecurityHandler securityHandler \u003d getSecurityHandler(info);\n-    SocketAddress remoteAddress \u003d info.remoteAddress();\n-    return readdir(xdr, securityHandler, remoteAddress);\n+    return readdir(xdr, getSecurityHandler(info), info.remoteAddress());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public READDIR3Response readdir(XDR xdr, RpcInfo info) {\n    return readdir(xdr, getSecurityHandler(info), info.remoteAddress());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
      "extendedDetails": {}
    },
    "2ecab65e3e290a1ee192b39ec70868863853543a": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-6439. NFS should not reject NFS requests to the NULL procedure whether port monitoring is enabled or not. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1603622 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/06/14 1:45 PM",
      "commitName": "2ecab65e3e290a1ee192b39ec70868863853543a",
      "commitAuthor": "Brandon Li",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-6439. NFS should not reject NFS requests to the NULL procedure whether port monitoring is enabled or not. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1603622 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/06/14 1:45 PM",
          "commitName": "2ecab65e3e290a1ee192b39ec70868863853543a",
          "commitAuthor": "Brandon Li",
          "commitDateOld": "30/05/14 4:53 PM",
          "commitNameOld": "42391d260da400593812396c1ffd45d1a371d3cb",
          "commitAuthorOld": "Brandon Li",
          "daysBetweenCommits": 18.87,
          "commitsBetweenForRepo": 106,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,139 +1,5 @@\n-  public READDIR3Response readdir(XDR xdr, SecurityHandler securityHandler,\n-      InetAddress client) {\n-    READDIR3Response response \u003d new READDIR3Response(Nfs3Status.NFS3_OK);\n-    \n-    if (!checkAccessPrivilege(client, AccessPrivilege.READ_ONLY)) {\n-      response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n-      return response;\n-    }\n-    \n-    DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n-    if (dfsClient \u003d\u003d null) {\n-      response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n-      return response;\n-    }\n-    \n-    READDIR3Request request \u003d null;\n-    try {\n-      request \u003d new READDIR3Request(xdr);\n-    } catch (IOException e) {\n-      LOG.error(\"Invalid READDIR request\");\n-      return new READDIR3Response(Nfs3Status.NFS3ERR_INVAL);\n-    }\n-    FileHandle handle \u003d request.getHandle();\n-    long cookie \u003d request.getCookie();\n-    if (cookie \u003c 0) {\n-      LOG.error(\"Invalid READDIR request, with negitve cookie:\" + cookie);\n-      return new READDIR3Response(Nfs3Status.NFS3ERR_INVAL);\n-    }\n-    long count \u003d request.getCount();\n-    if (count \u003c\u003d 0) {\n-      LOG.info(\"Nonpositive count in invalid READDIR request:\" + count);\n-      return new READDIR3Response(Nfs3Status.NFS3_OK);\n-    }\n-    \n-    if (LOG.isDebugEnabled()) {\n-      LOG.debug(\"NFS READDIR fileId: \" + handle.getFileId() + \" cookie: \"\n-          + cookie + \" count: \" + count);\n-    }\n-\n-    HdfsFileStatus dirStatus \u003d null;\n-    DirectoryListing dlisting \u003d null;\n-    Nfs3FileAttributes postOpAttr \u003d null;\n-    long dotdotFileId \u003d 0;\n-    try {\n-      String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n-      dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n-      if (dirStatus \u003d\u003d null) {\n-        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n-        return new READDIR3Response(Nfs3Status.NFS3ERR_STALE);\n-      }\n-      if (!dirStatus.isDir()) {\n-        LOG.error(\"Can\u0027t readdir for regular file, fileId:\"\n-            + handle.getFileId());\n-        return new READDIR3Response(Nfs3Status.NFS3ERR_NOTDIR);\n-      }\n-      long cookieVerf \u003d request.getCookieVerf();\n-      if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n-        LOG.error(\"CookierVerf mismatch. request cookierVerf:\" + cookieVerf\n-            + \" dir cookieVerf:\" + dirStatus.getModificationTime());\n-        return new READDIR3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n-      }\n-\n-      if (cookie \u003d\u003d 0) {\n-        // Get dotdot fileId\n-        String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n-        HdfsFileStatus dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n-\n-        if (dotdotStatus \u003d\u003d null) {\n-          // This should not happen\n-          throw new IOException(\"Can\u0027t get path for handle path:\"\n-              + dotdotFileIdPath);\n-        }\n-        dotdotFileId \u003d dotdotStatus.getFileId();\n-      }\n-\n-      // Get the list from the resume point\n-      byte[] startAfter;\n-      if(cookie \u003d\u003d 0 ) {\n-        startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n-      } else {\n-        String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n-        startAfter \u003d inodeIdPath.getBytes();\n-      }\n-      \n-      dlisting \u003d listPaths(dfsClient, dirFileIdPath, startAfter);\n-      postOpAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n-      if (postOpAttr \u003d\u003d null) {\n-        LOG.error(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n-        return new READDIR3Response(Nfs3Status.NFS3ERR_STALE);\n-      }\n-    } catch (IOException e) {\n-      LOG.warn(\"Exception \", e);\n-      return new READDIR3Response(Nfs3Status.NFS3ERR_IO);\n-    }\n-\n-    /**\n-     * Set up the dirents in the response. fileId is used as the cookie with one\n-     * exception. Linux client can either be stuck with \"ls\" command (on REHL)\n-     * or report \"Too many levels of symbolic links\" (Ubuntu).\n-     * \n-     * The problem is that, only two items returned, \".\" and \"..\" when the\n-     * namespace is empty. Both of them are \"/\" with the same cookie(root\n-     * fileId). Linux client doesn\u0027t think such a directory is a real directory.\n-     * Even though NFS protocol specifies cookie is an opaque data, Linux client\n-     * somehow doesn\u0027t like an empty dir returns same cookie for both \".\" and\n-     * \"..\".\n-     * \n-     * The workaround is to use 0 as the cookie for \".\" and always return \".\" as\n-     * the first entry in readdir/readdirplus response.\n-     */\n-    HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();    \n-    int n \u003d (int) Math.min(fstatus.length, count-2);\n-    boolean eof \u003d (n \u003c fstatus.length) ? false : (dlisting\n-        .getRemainingEntries() \u003d\u003d 0);\n-    \n-    Entry3[] entries;\n-    if (cookie \u003d\u003d 0) {\n-      entries \u003d new Entry3[n + 2];\n-      entries[0] \u003d new READDIR3Response.Entry3(postOpAttr.getFileId(), \".\", 0);\n-      entries[1] \u003d new READDIR3Response.Entry3(dotdotFileId, \"..\", dotdotFileId);\n-\n-      for (int i \u003d 2; i \u003c n + 2; i++) {\n-        entries[i] \u003d new READDIR3Response.Entry3(fstatus[i - 2].getFileId(),\n-            fstatus[i - 2].getLocalName(), fstatus[i - 2].getFileId());\n-      }\n-    } else {\n-      // Resume from last readdirplus. If the cookie is \"..\", the result\n-      // list is up the directory content since HDFS uses name as resume point.    \n-      entries \u003d new Entry3[n];    \n-      for (int i \u003d 0; i \u003c n; i++) {\n-        entries[i] \u003d new READDIR3Response.Entry3(fstatus[i].getFileId(),\n-            fstatus[i].getLocalName(), fstatus[i].getFileId());\n-      }\n-    }\n-    \n-    DirList3 dirList \u003d new READDIR3Response.DirList3(entries, eof);\n-    return new READDIR3Response(Nfs3Status.NFS3_OK, postOpAttr,\n-        dirStatus.getModificationTime(), dirList);\n+  public READDIR3Response readdir(XDR xdr, RpcInfo info) {\n+    SecurityHandler securityHandler \u003d getSecurityHandler(info);\n+    SocketAddress remoteAddress \u003d info.remoteAddress();\n+    return readdir(xdr, securityHandler, remoteAddress);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public READDIR3Response readdir(XDR xdr, RpcInfo info) {\n    SecurityHandler securityHandler \u003d getSecurityHandler(info);\n    SocketAddress remoteAddress \u003d info.remoteAddress();\n    return readdir(xdr, securityHandler, remoteAddress);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
          "extendedDetails": {
            "oldValue": "[xdr-XDR, securityHandler-SecurityHandler, client-InetAddress]",
            "newValue": "[xdr-XDR, info-RpcInfo]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-6439. NFS should not reject NFS requests to the NULL procedure whether port monitoring is enabled or not. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1603622 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/06/14 1:45 PM",
          "commitName": "2ecab65e3e290a1ee192b39ec70868863853543a",
          "commitAuthor": "Brandon Li",
          "commitDateOld": "30/05/14 4:53 PM",
          "commitNameOld": "42391d260da400593812396c1ffd45d1a371d3cb",
          "commitAuthorOld": "Brandon Li",
          "daysBetweenCommits": 18.87,
          "commitsBetweenForRepo": 106,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,139 +1,5 @@\n-  public READDIR3Response readdir(XDR xdr, SecurityHandler securityHandler,\n-      InetAddress client) {\n-    READDIR3Response response \u003d new READDIR3Response(Nfs3Status.NFS3_OK);\n-    \n-    if (!checkAccessPrivilege(client, AccessPrivilege.READ_ONLY)) {\n-      response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n-      return response;\n-    }\n-    \n-    DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n-    if (dfsClient \u003d\u003d null) {\n-      response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n-      return response;\n-    }\n-    \n-    READDIR3Request request \u003d null;\n-    try {\n-      request \u003d new READDIR3Request(xdr);\n-    } catch (IOException e) {\n-      LOG.error(\"Invalid READDIR request\");\n-      return new READDIR3Response(Nfs3Status.NFS3ERR_INVAL);\n-    }\n-    FileHandle handle \u003d request.getHandle();\n-    long cookie \u003d request.getCookie();\n-    if (cookie \u003c 0) {\n-      LOG.error(\"Invalid READDIR request, with negitve cookie:\" + cookie);\n-      return new READDIR3Response(Nfs3Status.NFS3ERR_INVAL);\n-    }\n-    long count \u003d request.getCount();\n-    if (count \u003c\u003d 0) {\n-      LOG.info(\"Nonpositive count in invalid READDIR request:\" + count);\n-      return new READDIR3Response(Nfs3Status.NFS3_OK);\n-    }\n-    \n-    if (LOG.isDebugEnabled()) {\n-      LOG.debug(\"NFS READDIR fileId: \" + handle.getFileId() + \" cookie: \"\n-          + cookie + \" count: \" + count);\n-    }\n-\n-    HdfsFileStatus dirStatus \u003d null;\n-    DirectoryListing dlisting \u003d null;\n-    Nfs3FileAttributes postOpAttr \u003d null;\n-    long dotdotFileId \u003d 0;\n-    try {\n-      String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n-      dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n-      if (dirStatus \u003d\u003d null) {\n-        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n-        return new READDIR3Response(Nfs3Status.NFS3ERR_STALE);\n-      }\n-      if (!dirStatus.isDir()) {\n-        LOG.error(\"Can\u0027t readdir for regular file, fileId:\"\n-            + handle.getFileId());\n-        return new READDIR3Response(Nfs3Status.NFS3ERR_NOTDIR);\n-      }\n-      long cookieVerf \u003d request.getCookieVerf();\n-      if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n-        LOG.error(\"CookierVerf mismatch. request cookierVerf:\" + cookieVerf\n-            + \" dir cookieVerf:\" + dirStatus.getModificationTime());\n-        return new READDIR3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n-      }\n-\n-      if (cookie \u003d\u003d 0) {\n-        // Get dotdot fileId\n-        String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n-        HdfsFileStatus dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n-\n-        if (dotdotStatus \u003d\u003d null) {\n-          // This should not happen\n-          throw new IOException(\"Can\u0027t get path for handle path:\"\n-              + dotdotFileIdPath);\n-        }\n-        dotdotFileId \u003d dotdotStatus.getFileId();\n-      }\n-\n-      // Get the list from the resume point\n-      byte[] startAfter;\n-      if(cookie \u003d\u003d 0 ) {\n-        startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n-      } else {\n-        String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n-        startAfter \u003d inodeIdPath.getBytes();\n-      }\n-      \n-      dlisting \u003d listPaths(dfsClient, dirFileIdPath, startAfter);\n-      postOpAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n-      if (postOpAttr \u003d\u003d null) {\n-        LOG.error(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n-        return new READDIR3Response(Nfs3Status.NFS3ERR_STALE);\n-      }\n-    } catch (IOException e) {\n-      LOG.warn(\"Exception \", e);\n-      return new READDIR3Response(Nfs3Status.NFS3ERR_IO);\n-    }\n-\n-    /**\n-     * Set up the dirents in the response. fileId is used as the cookie with one\n-     * exception. Linux client can either be stuck with \"ls\" command (on REHL)\n-     * or report \"Too many levels of symbolic links\" (Ubuntu).\n-     * \n-     * The problem is that, only two items returned, \".\" and \"..\" when the\n-     * namespace is empty. Both of them are \"/\" with the same cookie(root\n-     * fileId). Linux client doesn\u0027t think such a directory is a real directory.\n-     * Even though NFS protocol specifies cookie is an opaque data, Linux client\n-     * somehow doesn\u0027t like an empty dir returns same cookie for both \".\" and\n-     * \"..\".\n-     * \n-     * The workaround is to use 0 as the cookie for \".\" and always return \".\" as\n-     * the first entry in readdir/readdirplus response.\n-     */\n-    HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();    \n-    int n \u003d (int) Math.min(fstatus.length, count-2);\n-    boolean eof \u003d (n \u003c fstatus.length) ? false : (dlisting\n-        .getRemainingEntries() \u003d\u003d 0);\n-    \n-    Entry3[] entries;\n-    if (cookie \u003d\u003d 0) {\n-      entries \u003d new Entry3[n + 2];\n-      entries[0] \u003d new READDIR3Response.Entry3(postOpAttr.getFileId(), \".\", 0);\n-      entries[1] \u003d new READDIR3Response.Entry3(dotdotFileId, \"..\", dotdotFileId);\n-\n-      for (int i \u003d 2; i \u003c n + 2; i++) {\n-        entries[i] \u003d new READDIR3Response.Entry3(fstatus[i - 2].getFileId(),\n-            fstatus[i - 2].getLocalName(), fstatus[i - 2].getFileId());\n-      }\n-    } else {\n-      // Resume from last readdirplus. If the cookie is \"..\", the result\n-      // list is up the directory content since HDFS uses name as resume point.    \n-      entries \u003d new Entry3[n];    \n-      for (int i \u003d 0; i \u003c n; i++) {\n-        entries[i] \u003d new READDIR3Response.Entry3(fstatus[i].getFileId(),\n-            fstatus[i].getLocalName(), fstatus[i].getFileId());\n-      }\n-    }\n-    \n-    DirList3 dirList \u003d new READDIR3Response.DirList3(entries, eof);\n-    return new READDIR3Response(Nfs3Status.NFS3_OK, postOpAttr,\n-        dirStatus.getModificationTime(), dirList);\n+  public READDIR3Response readdir(XDR xdr, RpcInfo info) {\n+    SecurityHandler securityHandler \u003d getSecurityHandler(info);\n+    SocketAddress remoteAddress \u003d info.remoteAddress();\n+    return readdir(xdr, securityHandler, remoteAddress);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public READDIR3Response readdir(XDR xdr, RpcInfo info) {\n    SecurityHandler securityHandler \u003d getSecurityHandler(info);\n    SocketAddress remoteAddress \u003d info.remoteAddress();\n    return readdir(xdr, securityHandler, remoteAddress);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
          "extendedDetails": {}
        }
      ]
    },
    "05f35518f19d48890770128727289582cca3457b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5171. NFS should create input stream for a file and try to share it with multiple read requests. Contributed by Haohui Mai\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1535586 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/10/13 4:40 PM",
      "commitName": "05f35518f19d48890770128727289582cca3457b",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "15/10/13 2:23 PM",
      "commitNameOld": "a9befa6f0a8a27b49b1e6483e749661f493f06cf",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 9.1,
      "commitsBetweenForRepo": 50,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,139 +1,139 @@\n   public READDIR3Response readdir(XDR xdr, SecurityHandler securityHandler,\n       InetAddress client) {\n     READDIR3Response response \u003d new READDIR3Response(Nfs3Status.NFS3_OK);\n     \n     if (!checkAccessPrivilege(client, AccessPrivilege.READ_ONLY)) {\n       response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n       return response;\n     }\n     \n-    DFSClient dfsClient \u003d clientCache.get(securityHandler.getUser());\n+    DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n     if (dfsClient \u003d\u003d null) {\n       response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n       return response;\n     }\n     \n     READDIR3Request request \u003d null;\n     try {\n       request \u003d new READDIR3Request(xdr);\n     } catch (IOException e) {\n       LOG.error(\"Invalid READDIR request\");\n       return new READDIR3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     FileHandle handle \u003d request.getHandle();\n     long cookie \u003d request.getCookie();\n     if (cookie \u003c 0) {\n       LOG.error(\"Invalid READDIR request, with negitve cookie:\" + cookie);\n       return new READDIR3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     long count \u003d request.getCount();\n     if (count \u003c\u003d 0) {\n       LOG.info(\"Nonpositive count in invalid READDIR request:\" + count);\n       return new READDIR3Response(Nfs3Status.NFS3_OK);\n     }\n     \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"NFS READDIR fileId: \" + handle.getFileId() + \" cookie: \"\n           + cookie + \" count: \" + count);\n     }\n \n     HdfsFileStatus dirStatus \u003d null;\n     DirectoryListing dlisting \u003d null;\n     Nfs3FileAttributes postOpAttr \u003d null;\n     long dotdotFileId \u003d 0;\n     try {\n       String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n       dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n       if (dirStatus \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new READDIR3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n       if (!dirStatus.isDir()) {\n         LOG.error(\"Can\u0027t readdir for regular file, fileId:\"\n             + handle.getFileId());\n         return new READDIR3Response(Nfs3Status.NFS3ERR_NOTDIR);\n       }\n       long cookieVerf \u003d request.getCookieVerf();\n       if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n         LOG.error(\"CookierVerf mismatch. request cookierVerf:\" + cookieVerf\n             + \" dir cookieVerf:\" + dirStatus.getModificationTime());\n         return new READDIR3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n       }\n \n       if (cookie \u003d\u003d 0) {\n         // Get dotdot fileId\n         String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n         HdfsFileStatus dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n \n         if (dotdotStatus \u003d\u003d null) {\n           // This should not happen\n           throw new IOException(\"Can\u0027t get path for handle path:\"\n               + dotdotFileIdPath);\n         }\n         dotdotFileId \u003d dotdotStatus.getFileId();\n       }\n \n       // Get the list from the resume point\n       byte[] startAfter;\n       if(cookie \u003d\u003d 0 ) {\n         startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n       } else {\n         String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n         startAfter \u003d inodeIdPath.getBytes();\n       }\n       \n       dlisting \u003d listPaths(dfsClient, dirFileIdPath, startAfter);\n       postOpAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n       if (postOpAttr \u003d\u003d null) {\n         LOG.error(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new READDIR3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n     } catch (IOException e) {\n       LOG.warn(\"Exception \", e);\n       return new READDIR3Response(Nfs3Status.NFS3ERR_IO);\n     }\n \n     /**\n      * Set up the dirents in the response. fileId is used as the cookie with one\n      * exception. Linux client can either be stuck with \"ls\" command (on REHL)\n      * or report \"Too many levels of symbolic links\" (Ubuntu).\n      * \n      * The problem is that, only two items returned, \".\" and \"..\" when the\n      * namespace is empty. Both of them are \"/\" with the same cookie(root\n      * fileId). Linux client doesn\u0027t think such a directory is a real directory.\n      * Even though NFS protocol specifies cookie is an opaque data, Linux client\n      * somehow doesn\u0027t like an empty dir returns same cookie for both \".\" and\n      * \"..\".\n      * \n      * The workaround is to use 0 as the cookie for \".\" and always return \".\" as\n      * the first entry in readdir/readdirplus response.\n      */\n     HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();    \n     int n \u003d (int) Math.min(fstatus.length, count-2);\n     boolean eof \u003d (n \u003c fstatus.length) ? false : (dlisting\n         .getRemainingEntries() \u003d\u003d 0);\n     \n     Entry3[] entries;\n     if (cookie \u003d\u003d 0) {\n       entries \u003d new Entry3[n + 2];\n       entries[0] \u003d new READDIR3Response.Entry3(postOpAttr.getFileId(), \".\", 0);\n       entries[1] \u003d new READDIR3Response.Entry3(dotdotFileId, \"..\", dotdotFileId);\n \n       for (int i \u003d 2; i \u003c n + 2; i++) {\n         entries[i] \u003d new READDIR3Response.Entry3(fstatus[i - 2].getFileId(),\n             fstatus[i - 2].getLocalName(), fstatus[i - 2].getFileId());\n       }\n     } else {\n       // Resume from last readdirplus. If the cookie is \"..\", the result\n       // list is up the directory content since HDFS uses name as resume point.    \n       entries \u003d new Entry3[n];    \n       for (int i \u003d 0; i \u003c n; i++) {\n         entries[i] \u003d new READDIR3Response.Entry3(fstatus[i].getFileId(),\n             fstatus[i].getLocalName(), fstatus[i].getFileId());\n       }\n     }\n     \n     DirList3 dirList \u003d new READDIR3Response.DirList3(entries, eof);\n     return new READDIR3Response(Nfs3Status.NFS3_OK, postOpAttr,\n         dirStatus.getModificationTime(), dirList);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public READDIR3Response readdir(XDR xdr, SecurityHandler securityHandler,\n      InetAddress client) {\n    READDIR3Response response \u003d new READDIR3Response(Nfs3Status.NFS3_OK);\n    \n    if (!checkAccessPrivilege(client, AccessPrivilege.READ_ONLY)) {\n      response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n      return response;\n    }\n    \n    DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n    if (dfsClient \u003d\u003d null) {\n      response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n      return response;\n    }\n    \n    READDIR3Request request \u003d null;\n    try {\n      request \u003d new READDIR3Request(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid READDIR request\");\n      return new READDIR3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    FileHandle handle \u003d request.getHandle();\n    long cookie \u003d request.getCookie();\n    if (cookie \u003c 0) {\n      LOG.error(\"Invalid READDIR request, with negitve cookie:\" + cookie);\n      return new READDIR3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    long count \u003d request.getCount();\n    if (count \u003c\u003d 0) {\n      LOG.info(\"Nonpositive count in invalid READDIR request:\" + count);\n      return new READDIR3Response(Nfs3Status.NFS3_OK);\n    }\n    \n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS READDIR fileId: \" + handle.getFileId() + \" cookie: \"\n          + cookie + \" count: \" + count);\n    }\n\n    HdfsFileStatus dirStatus \u003d null;\n    DirectoryListing dlisting \u003d null;\n    Nfs3FileAttributes postOpAttr \u003d null;\n    long dotdotFileId \u003d 0;\n    try {\n      String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n      dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n      if (dirStatus \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIR3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n      if (!dirStatus.isDir()) {\n        LOG.error(\"Can\u0027t readdir for regular file, fileId:\"\n            + handle.getFileId());\n        return new READDIR3Response(Nfs3Status.NFS3ERR_NOTDIR);\n      }\n      long cookieVerf \u003d request.getCookieVerf();\n      if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n        LOG.error(\"CookierVerf mismatch. request cookierVerf:\" + cookieVerf\n            + \" dir cookieVerf:\" + dirStatus.getModificationTime());\n        return new READDIR3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n      }\n\n      if (cookie \u003d\u003d 0) {\n        // Get dotdot fileId\n        String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n        HdfsFileStatus dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n\n        if (dotdotStatus \u003d\u003d null) {\n          // This should not happen\n          throw new IOException(\"Can\u0027t get path for handle path:\"\n              + dotdotFileIdPath);\n        }\n        dotdotFileId \u003d dotdotStatus.getFileId();\n      }\n\n      // Get the list from the resume point\n      byte[] startAfter;\n      if(cookie \u003d\u003d 0 ) {\n        startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n      } else {\n        String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n        startAfter \u003d inodeIdPath.getBytes();\n      }\n      \n      dlisting \u003d listPaths(dfsClient, dirFileIdPath, startAfter);\n      postOpAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n      if (postOpAttr \u003d\u003d null) {\n        LOG.error(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIR3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n    } catch (IOException e) {\n      LOG.warn(\"Exception \", e);\n      return new READDIR3Response(Nfs3Status.NFS3ERR_IO);\n    }\n\n    /**\n     * Set up the dirents in the response. fileId is used as the cookie with one\n     * exception. Linux client can either be stuck with \"ls\" command (on REHL)\n     * or report \"Too many levels of symbolic links\" (Ubuntu).\n     * \n     * The problem is that, only two items returned, \".\" and \"..\" when the\n     * namespace is empty. Both of them are \"/\" with the same cookie(root\n     * fileId). Linux client doesn\u0027t think such a directory is a real directory.\n     * Even though NFS protocol specifies cookie is an opaque data, Linux client\n     * somehow doesn\u0027t like an empty dir returns same cookie for both \".\" and\n     * \"..\".\n     * \n     * The workaround is to use 0 as the cookie for \".\" and always return \".\" as\n     * the first entry in readdir/readdirplus response.\n     */\n    HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();    \n    int n \u003d (int) Math.min(fstatus.length, count-2);\n    boolean eof \u003d (n \u003c fstatus.length) ? false : (dlisting\n        .getRemainingEntries() \u003d\u003d 0);\n    \n    Entry3[] entries;\n    if (cookie \u003d\u003d 0) {\n      entries \u003d new Entry3[n + 2];\n      entries[0] \u003d new READDIR3Response.Entry3(postOpAttr.getFileId(), \".\", 0);\n      entries[1] \u003d new READDIR3Response.Entry3(dotdotFileId, \"..\", dotdotFileId);\n\n      for (int i \u003d 2; i \u003c n + 2; i++) {\n        entries[i] \u003d new READDIR3Response.Entry3(fstatus[i - 2].getFileId(),\n            fstatus[i - 2].getLocalName(), fstatus[i - 2].getFileId());\n      }\n    } else {\n      // Resume from last readdirplus. If the cookie is \"..\", the result\n      // list is up the directory content since HDFS uses name as resume point.    \n      entries \u003d new Entry3[n];    \n      for (int i \u003d 0; i \u003c n; i++) {\n        entries[i] \u003d new READDIR3Response.Entry3(fstatus[i].getFileId(),\n            fstatus[i].getLocalName(), fstatus[i].getFileId());\n      }\n    }\n    \n    DirList3 dirList \u003d new READDIR3Response.DirList3(entries, eof);\n    return new READDIR3Response(Nfs3Status.NFS3_OK, postOpAttr,\n        dirStatus.getModificationTime(), dirList);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
      "extendedDetails": {}
    },
    "a9befa6f0a8a27b49b1e6483e749661f493f06cf": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5330. fix readdir and readdirplus for large directories. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1532539 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "15/10/13 2:23 PM",
      "commitName": "a9befa6f0a8a27b49b1e6483e749661f493f06cf",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "08/10/13 4:40 PM",
      "commitNameOld": "5c02d2f6225144772dcb975d3144b057b71d6476",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 6.9,
      "commitsBetweenForRepo": 49,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,139 +1,139 @@\n   public READDIR3Response readdir(XDR xdr, SecurityHandler securityHandler,\n       InetAddress client) {\n     READDIR3Response response \u003d new READDIR3Response(Nfs3Status.NFS3_OK);\n     \n     if (!checkAccessPrivilege(client, AccessPrivilege.READ_ONLY)) {\n       response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n       return response;\n     }\n     \n     DFSClient dfsClient \u003d clientCache.get(securityHandler.getUser());\n     if (dfsClient \u003d\u003d null) {\n       response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n       return response;\n     }\n     \n     READDIR3Request request \u003d null;\n     try {\n       request \u003d new READDIR3Request(xdr);\n     } catch (IOException e) {\n       LOG.error(\"Invalid READDIR request\");\n       return new READDIR3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     FileHandle handle \u003d request.getHandle();\n     long cookie \u003d request.getCookie();\n     if (cookie \u003c 0) {\n       LOG.error(\"Invalid READDIR request, with negitve cookie:\" + cookie);\n       return new READDIR3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     long count \u003d request.getCount();\n     if (count \u003c\u003d 0) {\n       LOG.info(\"Nonpositive count in invalid READDIR request:\" + count);\n       return new READDIR3Response(Nfs3Status.NFS3_OK);\n     }\n     \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"NFS READDIR fileId: \" + handle.getFileId() + \" cookie: \"\n           + cookie + \" count: \" + count);\n     }\n \n-    HdfsFileStatus dirStatus;\n+    HdfsFileStatus dirStatus \u003d null;\n     DirectoryListing dlisting \u003d null;\n     Nfs3FileAttributes postOpAttr \u003d null;\n     long dotdotFileId \u003d 0;\n     try {\n       String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n       dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n       if (dirStatus \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new READDIR3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n       if (!dirStatus.isDir()) {\n         LOG.error(\"Can\u0027t readdir for regular file, fileId:\"\n             + handle.getFileId());\n         return new READDIR3Response(Nfs3Status.NFS3ERR_NOTDIR);\n       }\n       long cookieVerf \u003d request.getCookieVerf();\n       if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n         LOG.error(\"CookierVerf mismatch. request cookierVerf:\" + cookieVerf\n             + \" dir cookieVerf:\" + dirStatus.getModificationTime());\n         return new READDIR3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n       }\n \n       if (cookie \u003d\u003d 0) {\n         // Get dotdot fileId\n         String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n         HdfsFileStatus dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n \n         if (dotdotStatus \u003d\u003d null) {\n           // This should not happen\n           throw new IOException(\"Can\u0027t get path for handle path:\"\n               + dotdotFileIdPath);\n         }\n         dotdotFileId \u003d dotdotStatus.getFileId();\n       }\n \n       // Get the list from the resume point\n       byte[] startAfter;\n       if(cookie \u003d\u003d 0 ) {\n         startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n       } else {\n         String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n         startAfter \u003d inodeIdPath.getBytes();\n       }\n-      dlisting \u003d dfsClient.listPaths(dirFileIdPath, startAfter);\n-\n+      \n+      dlisting \u003d listPaths(dfsClient, dirFileIdPath, startAfter);\n       postOpAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n       if (postOpAttr \u003d\u003d null) {\n         LOG.error(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new READDIR3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n     } catch (IOException e) {\n       LOG.warn(\"Exception \", e);\n       return new READDIR3Response(Nfs3Status.NFS3ERR_IO);\n     }\n \n     /**\n      * Set up the dirents in the response. fileId is used as the cookie with one\n      * exception. Linux client can either be stuck with \"ls\" command (on REHL)\n      * or report \"Too many levels of symbolic links\" (Ubuntu).\n      * \n      * The problem is that, only two items returned, \".\" and \"..\" when the\n      * namespace is empty. Both of them are \"/\" with the same cookie(root\n      * fileId). Linux client doesn\u0027t think such a directory is a real directory.\n      * Even though NFS protocol specifies cookie is an opaque data, Linux client\n      * somehow doesn\u0027t like an empty dir returns same cookie for both \".\" and\n      * \"..\".\n      * \n      * The workaround is to use 0 as the cookie for \".\" and always return \".\" as\n      * the first entry in readdir/readdirplus response.\n      */\n     HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();    \n     int n \u003d (int) Math.min(fstatus.length, count-2);\n     boolean eof \u003d (n \u003c fstatus.length) ? false : (dlisting\n         .getRemainingEntries() \u003d\u003d 0);\n     \n     Entry3[] entries;\n     if (cookie \u003d\u003d 0) {\n       entries \u003d new Entry3[n + 2];\n       entries[0] \u003d new READDIR3Response.Entry3(postOpAttr.getFileId(), \".\", 0);\n       entries[1] \u003d new READDIR3Response.Entry3(dotdotFileId, \"..\", dotdotFileId);\n \n       for (int i \u003d 2; i \u003c n + 2; i++) {\n         entries[i] \u003d new READDIR3Response.Entry3(fstatus[i - 2].getFileId(),\n             fstatus[i - 2].getLocalName(), fstatus[i - 2].getFileId());\n       }\n     } else {\n       // Resume from last readdirplus. If the cookie is \"..\", the result\n       // list is up the directory content since HDFS uses name as resume point.    \n       entries \u003d new Entry3[n];    \n       for (int i \u003d 0; i \u003c n; i++) {\n         entries[i] \u003d new READDIR3Response.Entry3(fstatus[i].getFileId(),\n             fstatus[i].getLocalName(), fstatus[i].getFileId());\n       }\n     }\n     \n     DirList3 dirList \u003d new READDIR3Response.DirList3(entries, eof);\n     return new READDIR3Response(Nfs3Status.NFS3_OK, postOpAttr,\n         dirStatus.getModificationTime(), dirList);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public READDIR3Response readdir(XDR xdr, SecurityHandler securityHandler,\n      InetAddress client) {\n    READDIR3Response response \u003d new READDIR3Response(Nfs3Status.NFS3_OK);\n    \n    if (!checkAccessPrivilege(client, AccessPrivilege.READ_ONLY)) {\n      response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n      return response;\n    }\n    \n    DFSClient dfsClient \u003d clientCache.get(securityHandler.getUser());\n    if (dfsClient \u003d\u003d null) {\n      response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n      return response;\n    }\n    \n    READDIR3Request request \u003d null;\n    try {\n      request \u003d new READDIR3Request(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid READDIR request\");\n      return new READDIR3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    FileHandle handle \u003d request.getHandle();\n    long cookie \u003d request.getCookie();\n    if (cookie \u003c 0) {\n      LOG.error(\"Invalid READDIR request, with negitve cookie:\" + cookie);\n      return new READDIR3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    long count \u003d request.getCount();\n    if (count \u003c\u003d 0) {\n      LOG.info(\"Nonpositive count in invalid READDIR request:\" + count);\n      return new READDIR3Response(Nfs3Status.NFS3_OK);\n    }\n    \n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS READDIR fileId: \" + handle.getFileId() + \" cookie: \"\n          + cookie + \" count: \" + count);\n    }\n\n    HdfsFileStatus dirStatus \u003d null;\n    DirectoryListing dlisting \u003d null;\n    Nfs3FileAttributes postOpAttr \u003d null;\n    long dotdotFileId \u003d 0;\n    try {\n      String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n      dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n      if (dirStatus \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIR3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n      if (!dirStatus.isDir()) {\n        LOG.error(\"Can\u0027t readdir for regular file, fileId:\"\n            + handle.getFileId());\n        return new READDIR3Response(Nfs3Status.NFS3ERR_NOTDIR);\n      }\n      long cookieVerf \u003d request.getCookieVerf();\n      if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n        LOG.error(\"CookierVerf mismatch. request cookierVerf:\" + cookieVerf\n            + \" dir cookieVerf:\" + dirStatus.getModificationTime());\n        return new READDIR3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n      }\n\n      if (cookie \u003d\u003d 0) {\n        // Get dotdot fileId\n        String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n        HdfsFileStatus dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n\n        if (dotdotStatus \u003d\u003d null) {\n          // This should not happen\n          throw new IOException(\"Can\u0027t get path for handle path:\"\n              + dotdotFileIdPath);\n        }\n        dotdotFileId \u003d dotdotStatus.getFileId();\n      }\n\n      // Get the list from the resume point\n      byte[] startAfter;\n      if(cookie \u003d\u003d 0 ) {\n        startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n      } else {\n        String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n        startAfter \u003d inodeIdPath.getBytes();\n      }\n      \n      dlisting \u003d listPaths(dfsClient, dirFileIdPath, startAfter);\n      postOpAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n      if (postOpAttr \u003d\u003d null) {\n        LOG.error(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIR3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n    } catch (IOException e) {\n      LOG.warn(\"Exception \", e);\n      return new READDIR3Response(Nfs3Status.NFS3ERR_IO);\n    }\n\n    /**\n     * Set up the dirents in the response. fileId is used as the cookie with one\n     * exception. Linux client can either be stuck with \"ls\" command (on REHL)\n     * or report \"Too many levels of symbolic links\" (Ubuntu).\n     * \n     * The problem is that, only two items returned, \".\" and \"..\" when the\n     * namespace is empty. Both of them are \"/\" with the same cookie(root\n     * fileId). Linux client doesn\u0027t think such a directory is a real directory.\n     * Even though NFS protocol specifies cookie is an opaque data, Linux client\n     * somehow doesn\u0027t like an empty dir returns same cookie for both \".\" and\n     * \"..\".\n     * \n     * The workaround is to use 0 as the cookie for \".\" and always return \".\" as\n     * the first entry in readdir/readdirplus response.\n     */\n    HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();    \n    int n \u003d (int) Math.min(fstatus.length, count-2);\n    boolean eof \u003d (n \u003c fstatus.length) ? false : (dlisting\n        .getRemainingEntries() \u003d\u003d 0);\n    \n    Entry3[] entries;\n    if (cookie \u003d\u003d 0) {\n      entries \u003d new Entry3[n + 2];\n      entries[0] \u003d new READDIR3Response.Entry3(postOpAttr.getFileId(), \".\", 0);\n      entries[1] \u003d new READDIR3Response.Entry3(dotdotFileId, \"..\", dotdotFileId);\n\n      for (int i \u003d 2; i \u003c n + 2; i++) {\n        entries[i] \u003d new READDIR3Response.Entry3(fstatus[i - 2].getFileId(),\n            fstatus[i - 2].getLocalName(), fstatus[i - 2].getFileId());\n      }\n    } else {\n      // Resume from last readdirplus. If the cookie is \"..\", the result\n      // list is up the directory content since HDFS uses name as resume point.    \n      entries \u003d new Entry3[n];    \n      for (int i \u003d 0; i \u003c n; i++) {\n        entries[i] \u003d new READDIR3Response.Entry3(fstatus[i].getFileId(),\n            fstatus[i].getLocalName(), fstatus[i].getFileId());\n      }\n    }\n    \n    DirList3 dirList \u003d new READDIR3Response.DirList3(entries, eof);\n    return new READDIR3Response(Nfs3Status.NFS3_OK, postOpAttr,\n        dirStatus.getModificationTime(), dirList);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
      "extendedDetails": {}
    },
    "613979c8fdacf25fd563395ecc399c4de94d3ee7": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-5085. Refactor o.a.h.nfs to support different types of authentications. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1521601 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/09/13 12:29 PM",
      "commitName": "613979c8fdacf25fd563395ecc399c4de94d3ee7",
      "commitAuthor": "Jing Zhao",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-5085. Refactor o.a.h.nfs to support different types of authentications. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1521601 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "10/09/13 12:29 PM",
          "commitName": "613979c8fdacf25fd563395ecc399c4de94d3ee7",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "31/08/13 2:12 PM",
          "commitNameOld": "cbca1668317f3f2d295eea53d7bd020bda4a810f",
          "commitAuthorOld": "Brandon Li",
          "daysBetweenCommits": 9.93,
          "commitsBetweenForRepo": 38,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,140 +1,139 @@\n-  public READDIR3Response readdir(XDR xdr, RpcAuthSys authSys,\n-      InetAddress client) {\n+  public READDIR3Response readdir(XDR xdr,\n+      SecurityHandler securityHandler, InetAddress client) {\n     READDIR3Response response \u003d new READDIR3Response(Nfs3Status.NFS3_OK);\n     \n     if (!checkAccessPrivilege(client, AccessPrivilege.READ_ONLY)) {\n       response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n       return response;\n     }\n     \n-    String uname \u003d authSysCheck(authSys);\n-    DFSClient dfsClient \u003d clientCache.get(uname);\n+    DFSClient dfsClient \u003d clientCache.get(securityHandler.getUser());\n     if (dfsClient \u003d\u003d null) {\n       response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n       return response;\n     }\n     \n     READDIR3Request request \u003d null;\n     try {\n       request \u003d new READDIR3Request(xdr);\n     } catch (IOException e) {\n       LOG.error(\"Invalid READDIR request\");\n       return new READDIR3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     FileHandle handle \u003d request.getHandle();\n     long cookie \u003d request.getCookie();\n     if (cookie \u003c 0) {\n       LOG.error(\"Invalid READDIR request, with negitve cookie:\" + cookie);\n       return new READDIR3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     long count \u003d request.getCount();\n     if (count \u003c\u003d 0) {\n       LOG.info(\"Nonpositive count in invalid READDIR request:\" + count);\n       return new READDIR3Response(Nfs3Status.NFS3_OK);\n     }\n     \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"NFS READDIR fileId: \" + handle.getFileId() + \" cookie: \"\n           + cookie + \" count: \" + count);\n     }\n \n     HdfsFileStatus dirStatus;\n     DirectoryListing dlisting \u003d null;\n     Nfs3FileAttributes postOpAttr \u003d null;\n     long dotdotFileId \u003d 0;\n     try {\n       String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n       dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n       if (dirStatus \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new READDIR3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n       if (!dirStatus.isDir()) {\n         LOG.error(\"Can\u0027t readdir for regular file, fileId:\"\n             + handle.getFileId());\n         return new READDIR3Response(Nfs3Status.NFS3ERR_NOTDIR);\n       }\n       long cookieVerf \u003d request.getCookieVerf();\n       if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n         LOG.error(\"CookierVerf mismatch. request cookierVerf:\" + cookieVerf\n             + \" dir cookieVerf:\" + dirStatus.getModificationTime());\n         return new READDIR3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n       }\n \n       if (cookie \u003d\u003d 0) {\n         // Get dotdot fileId\n         String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n         HdfsFileStatus dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n \n         if (dotdotStatus \u003d\u003d null) {\n           // This should not happen\n           throw new IOException(\"Can\u0027t get path for handle path:\"\n               + dotdotFileIdPath);\n         }\n         dotdotFileId \u003d dotdotStatus.getFileId();\n       }\n \n       // Get the list from the resume point\n       byte[] startAfter;\n       if(cookie \u003d\u003d 0 ) {\n         startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n       } else {\n         String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n         startAfter \u003d inodeIdPath.getBytes();\n       }\n       dlisting \u003d dfsClient.listPaths(dirFileIdPath, startAfter);\n \n       postOpAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n       if (postOpAttr \u003d\u003d null) {\n         LOG.error(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new READDIR3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n     } catch (IOException e) {\n       LOG.warn(\"Exception \", e);\n       return new READDIR3Response(Nfs3Status.NFS3ERR_IO);\n     }\n \n     /**\n      * Set up the dirents in the response. fileId is used as the cookie with one\n      * exception. Linux client can either be stuck with \"ls\" command (on REHL)\n      * or report \"Too many levels of symbolic links\" (Ubuntu).\n      * \n      * The problem is that, only two items returned, \".\" and \"..\" when the\n      * namespace is empty. Both of them are \"/\" with the same cookie(root\n      * fileId). Linux client doesn\u0027t think such a directory is a real directory.\n      * Even though NFS protocol specifies cookie is an opaque data, Linux client\n      * somehow doesn\u0027t like an empty dir returns same cookie for both \".\" and\n      * \"..\".\n      * \n      * The workaround is to use 0 as the cookie for \".\" and always return \".\" as\n      * the first entry in readdir/readdirplus response.\n      */\n     HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();    \n     int n \u003d (int) Math.min(fstatus.length, count-2);\n     boolean eof \u003d (n \u003c fstatus.length) ? false : (dlisting\n         .getRemainingEntries() \u003d\u003d 0);\n     \n     Entry3[] entries;\n     if (cookie \u003d\u003d 0) {\n       entries \u003d new Entry3[n + 2];\n       entries[0] \u003d new READDIR3Response.Entry3(postOpAttr.getFileId(), \".\", 0);\n       entries[1] \u003d new READDIR3Response.Entry3(dotdotFileId, \"..\", dotdotFileId);\n \n       for (int i \u003d 2; i \u003c n + 2; i++) {\n         entries[i] \u003d new READDIR3Response.Entry3(fstatus[i - 2].getFileId(),\n             fstatus[i - 2].getLocalName(), fstatus[i - 2].getFileId());\n       }\n     } else {\n       // Resume from last readdirplus. If the cookie is \"..\", the result\n       // list is up the directory content since HDFS uses name as resume point.    \n       entries \u003d new Entry3[n];    \n       for (int i \u003d 0; i \u003c n; i++) {\n         entries[i] \u003d new READDIR3Response.Entry3(fstatus[i].getFileId(),\n             fstatus[i].getLocalName(), fstatus[i].getFileId());\n       }\n     }\n     \n     DirList3 dirList \u003d new READDIR3Response.DirList3(entries, eof);\n     return new READDIR3Response(Nfs3Status.NFS3_OK, postOpAttr,\n         dirStatus.getModificationTime(), dirList);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public READDIR3Response readdir(XDR xdr,\n      SecurityHandler securityHandler, InetAddress client) {\n    READDIR3Response response \u003d new READDIR3Response(Nfs3Status.NFS3_OK);\n    \n    if (!checkAccessPrivilege(client, AccessPrivilege.READ_ONLY)) {\n      response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n      return response;\n    }\n    \n    DFSClient dfsClient \u003d clientCache.get(securityHandler.getUser());\n    if (dfsClient \u003d\u003d null) {\n      response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n      return response;\n    }\n    \n    READDIR3Request request \u003d null;\n    try {\n      request \u003d new READDIR3Request(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid READDIR request\");\n      return new READDIR3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    FileHandle handle \u003d request.getHandle();\n    long cookie \u003d request.getCookie();\n    if (cookie \u003c 0) {\n      LOG.error(\"Invalid READDIR request, with negitve cookie:\" + cookie);\n      return new READDIR3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    long count \u003d request.getCount();\n    if (count \u003c\u003d 0) {\n      LOG.info(\"Nonpositive count in invalid READDIR request:\" + count);\n      return new READDIR3Response(Nfs3Status.NFS3_OK);\n    }\n    \n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS READDIR fileId: \" + handle.getFileId() + \" cookie: \"\n          + cookie + \" count: \" + count);\n    }\n\n    HdfsFileStatus dirStatus;\n    DirectoryListing dlisting \u003d null;\n    Nfs3FileAttributes postOpAttr \u003d null;\n    long dotdotFileId \u003d 0;\n    try {\n      String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n      dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n      if (dirStatus \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIR3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n      if (!dirStatus.isDir()) {\n        LOG.error(\"Can\u0027t readdir for regular file, fileId:\"\n            + handle.getFileId());\n        return new READDIR3Response(Nfs3Status.NFS3ERR_NOTDIR);\n      }\n      long cookieVerf \u003d request.getCookieVerf();\n      if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n        LOG.error(\"CookierVerf mismatch. request cookierVerf:\" + cookieVerf\n            + \" dir cookieVerf:\" + dirStatus.getModificationTime());\n        return new READDIR3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n      }\n\n      if (cookie \u003d\u003d 0) {\n        // Get dotdot fileId\n        String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n        HdfsFileStatus dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n\n        if (dotdotStatus \u003d\u003d null) {\n          // This should not happen\n          throw new IOException(\"Can\u0027t get path for handle path:\"\n              + dotdotFileIdPath);\n        }\n        dotdotFileId \u003d dotdotStatus.getFileId();\n      }\n\n      // Get the list from the resume point\n      byte[] startAfter;\n      if(cookie \u003d\u003d 0 ) {\n        startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n      } else {\n        String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n        startAfter \u003d inodeIdPath.getBytes();\n      }\n      dlisting \u003d dfsClient.listPaths(dirFileIdPath, startAfter);\n\n      postOpAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n      if (postOpAttr \u003d\u003d null) {\n        LOG.error(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIR3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n    } catch (IOException e) {\n      LOG.warn(\"Exception \", e);\n      return new READDIR3Response(Nfs3Status.NFS3ERR_IO);\n    }\n\n    /**\n     * Set up the dirents in the response. fileId is used as the cookie with one\n     * exception. Linux client can either be stuck with \"ls\" command (on REHL)\n     * or report \"Too many levels of symbolic links\" (Ubuntu).\n     * \n     * The problem is that, only two items returned, \".\" and \"..\" when the\n     * namespace is empty. Both of them are \"/\" with the same cookie(root\n     * fileId). Linux client doesn\u0027t think such a directory is a real directory.\n     * Even though NFS protocol specifies cookie is an opaque data, Linux client\n     * somehow doesn\u0027t like an empty dir returns same cookie for both \".\" and\n     * \"..\".\n     * \n     * The workaround is to use 0 as the cookie for \".\" and always return \".\" as\n     * the first entry in readdir/readdirplus response.\n     */\n    HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();    \n    int n \u003d (int) Math.min(fstatus.length, count-2);\n    boolean eof \u003d (n \u003c fstatus.length) ? false : (dlisting\n        .getRemainingEntries() \u003d\u003d 0);\n    \n    Entry3[] entries;\n    if (cookie \u003d\u003d 0) {\n      entries \u003d new Entry3[n + 2];\n      entries[0] \u003d new READDIR3Response.Entry3(postOpAttr.getFileId(), \".\", 0);\n      entries[1] \u003d new READDIR3Response.Entry3(dotdotFileId, \"..\", dotdotFileId);\n\n      for (int i \u003d 2; i \u003c n + 2; i++) {\n        entries[i] \u003d new READDIR3Response.Entry3(fstatus[i - 2].getFileId(),\n            fstatus[i - 2].getLocalName(), fstatus[i - 2].getFileId());\n      }\n    } else {\n      // Resume from last readdirplus. If the cookie is \"..\", the result\n      // list is up the directory content since HDFS uses name as resume point.    \n      entries \u003d new Entry3[n];    \n      for (int i \u003d 0; i \u003c n; i++) {\n        entries[i] \u003d new READDIR3Response.Entry3(fstatus[i].getFileId(),\n            fstatus[i].getLocalName(), fstatus[i].getFileId());\n      }\n    }\n    \n    DirList3 dirList \u003d new READDIR3Response.DirList3(entries, eof);\n    return new READDIR3Response(Nfs3Status.NFS3_OK, postOpAttr,\n        dirStatus.getModificationTime(), dirList);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
          "extendedDetails": {
            "oldValue": "[xdr-XDR, authSys-RpcAuthSys, client-InetAddress]",
            "newValue": "[xdr-XDR, securityHandler-SecurityHandler, client-InetAddress]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5085. Refactor o.a.h.nfs to support different types of authentications. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1521601 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "10/09/13 12:29 PM",
          "commitName": "613979c8fdacf25fd563395ecc399c4de94d3ee7",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "31/08/13 2:12 PM",
          "commitNameOld": "cbca1668317f3f2d295eea53d7bd020bda4a810f",
          "commitAuthorOld": "Brandon Li",
          "daysBetweenCommits": 9.93,
          "commitsBetweenForRepo": 38,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,140 +1,139 @@\n-  public READDIR3Response readdir(XDR xdr, RpcAuthSys authSys,\n-      InetAddress client) {\n+  public READDIR3Response readdir(XDR xdr,\n+      SecurityHandler securityHandler, InetAddress client) {\n     READDIR3Response response \u003d new READDIR3Response(Nfs3Status.NFS3_OK);\n     \n     if (!checkAccessPrivilege(client, AccessPrivilege.READ_ONLY)) {\n       response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n       return response;\n     }\n     \n-    String uname \u003d authSysCheck(authSys);\n-    DFSClient dfsClient \u003d clientCache.get(uname);\n+    DFSClient dfsClient \u003d clientCache.get(securityHandler.getUser());\n     if (dfsClient \u003d\u003d null) {\n       response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n       return response;\n     }\n     \n     READDIR3Request request \u003d null;\n     try {\n       request \u003d new READDIR3Request(xdr);\n     } catch (IOException e) {\n       LOG.error(\"Invalid READDIR request\");\n       return new READDIR3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     FileHandle handle \u003d request.getHandle();\n     long cookie \u003d request.getCookie();\n     if (cookie \u003c 0) {\n       LOG.error(\"Invalid READDIR request, with negitve cookie:\" + cookie);\n       return new READDIR3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     long count \u003d request.getCount();\n     if (count \u003c\u003d 0) {\n       LOG.info(\"Nonpositive count in invalid READDIR request:\" + count);\n       return new READDIR3Response(Nfs3Status.NFS3_OK);\n     }\n     \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"NFS READDIR fileId: \" + handle.getFileId() + \" cookie: \"\n           + cookie + \" count: \" + count);\n     }\n \n     HdfsFileStatus dirStatus;\n     DirectoryListing dlisting \u003d null;\n     Nfs3FileAttributes postOpAttr \u003d null;\n     long dotdotFileId \u003d 0;\n     try {\n       String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n       dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n       if (dirStatus \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new READDIR3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n       if (!dirStatus.isDir()) {\n         LOG.error(\"Can\u0027t readdir for regular file, fileId:\"\n             + handle.getFileId());\n         return new READDIR3Response(Nfs3Status.NFS3ERR_NOTDIR);\n       }\n       long cookieVerf \u003d request.getCookieVerf();\n       if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n         LOG.error(\"CookierVerf mismatch. request cookierVerf:\" + cookieVerf\n             + \" dir cookieVerf:\" + dirStatus.getModificationTime());\n         return new READDIR3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n       }\n \n       if (cookie \u003d\u003d 0) {\n         // Get dotdot fileId\n         String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n         HdfsFileStatus dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n \n         if (dotdotStatus \u003d\u003d null) {\n           // This should not happen\n           throw new IOException(\"Can\u0027t get path for handle path:\"\n               + dotdotFileIdPath);\n         }\n         dotdotFileId \u003d dotdotStatus.getFileId();\n       }\n \n       // Get the list from the resume point\n       byte[] startAfter;\n       if(cookie \u003d\u003d 0 ) {\n         startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n       } else {\n         String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n         startAfter \u003d inodeIdPath.getBytes();\n       }\n       dlisting \u003d dfsClient.listPaths(dirFileIdPath, startAfter);\n \n       postOpAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n       if (postOpAttr \u003d\u003d null) {\n         LOG.error(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new READDIR3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n     } catch (IOException e) {\n       LOG.warn(\"Exception \", e);\n       return new READDIR3Response(Nfs3Status.NFS3ERR_IO);\n     }\n \n     /**\n      * Set up the dirents in the response. fileId is used as the cookie with one\n      * exception. Linux client can either be stuck with \"ls\" command (on REHL)\n      * or report \"Too many levels of symbolic links\" (Ubuntu).\n      * \n      * The problem is that, only two items returned, \".\" and \"..\" when the\n      * namespace is empty. Both of them are \"/\" with the same cookie(root\n      * fileId). Linux client doesn\u0027t think such a directory is a real directory.\n      * Even though NFS protocol specifies cookie is an opaque data, Linux client\n      * somehow doesn\u0027t like an empty dir returns same cookie for both \".\" and\n      * \"..\".\n      * \n      * The workaround is to use 0 as the cookie for \".\" and always return \".\" as\n      * the first entry in readdir/readdirplus response.\n      */\n     HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();    \n     int n \u003d (int) Math.min(fstatus.length, count-2);\n     boolean eof \u003d (n \u003c fstatus.length) ? false : (dlisting\n         .getRemainingEntries() \u003d\u003d 0);\n     \n     Entry3[] entries;\n     if (cookie \u003d\u003d 0) {\n       entries \u003d new Entry3[n + 2];\n       entries[0] \u003d new READDIR3Response.Entry3(postOpAttr.getFileId(), \".\", 0);\n       entries[1] \u003d new READDIR3Response.Entry3(dotdotFileId, \"..\", dotdotFileId);\n \n       for (int i \u003d 2; i \u003c n + 2; i++) {\n         entries[i] \u003d new READDIR3Response.Entry3(fstatus[i - 2].getFileId(),\n             fstatus[i - 2].getLocalName(), fstatus[i - 2].getFileId());\n       }\n     } else {\n       // Resume from last readdirplus. If the cookie is \"..\", the result\n       // list is up the directory content since HDFS uses name as resume point.    \n       entries \u003d new Entry3[n];    \n       for (int i \u003d 0; i \u003c n; i++) {\n         entries[i] \u003d new READDIR3Response.Entry3(fstatus[i].getFileId(),\n             fstatus[i].getLocalName(), fstatus[i].getFileId());\n       }\n     }\n     \n     DirList3 dirList \u003d new READDIR3Response.DirList3(entries, eof);\n     return new READDIR3Response(Nfs3Status.NFS3_OK, postOpAttr,\n         dirStatus.getModificationTime(), dirList);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public READDIR3Response readdir(XDR xdr,\n      SecurityHandler securityHandler, InetAddress client) {\n    READDIR3Response response \u003d new READDIR3Response(Nfs3Status.NFS3_OK);\n    \n    if (!checkAccessPrivilege(client, AccessPrivilege.READ_ONLY)) {\n      response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n      return response;\n    }\n    \n    DFSClient dfsClient \u003d clientCache.get(securityHandler.getUser());\n    if (dfsClient \u003d\u003d null) {\n      response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n      return response;\n    }\n    \n    READDIR3Request request \u003d null;\n    try {\n      request \u003d new READDIR3Request(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid READDIR request\");\n      return new READDIR3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    FileHandle handle \u003d request.getHandle();\n    long cookie \u003d request.getCookie();\n    if (cookie \u003c 0) {\n      LOG.error(\"Invalid READDIR request, with negitve cookie:\" + cookie);\n      return new READDIR3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    long count \u003d request.getCount();\n    if (count \u003c\u003d 0) {\n      LOG.info(\"Nonpositive count in invalid READDIR request:\" + count);\n      return new READDIR3Response(Nfs3Status.NFS3_OK);\n    }\n    \n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS READDIR fileId: \" + handle.getFileId() + \" cookie: \"\n          + cookie + \" count: \" + count);\n    }\n\n    HdfsFileStatus dirStatus;\n    DirectoryListing dlisting \u003d null;\n    Nfs3FileAttributes postOpAttr \u003d null;\n    long dotdotFileId \u003d 0;\n    try {\n      String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n      dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n      if (dirStatus \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIR3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n      if (!dirStatus.isDir()) {\n        LOG.error(\"Can\u0027t readdir for regular file, fileId:\"\n            + handle.getFileId());\n        return new READDIR3Response(Nfs3Status.NFS3ERR_NOTDIR);\n      }\n      long cookieVerf \u003d request.getCookieVerf();\n      if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n        LOG.error(\"CookierVerf mismatch. request cookierVerf:\" + cookieVerf\n            + \" dir cookieVerf:\" + dirStatus.getModificationTime());\n        return new READDIR3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n      }\n\n      if (cookie \u003d\u003d 0) {\n        // Get dotdot fileId\n        String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n        HdfsFileStatus dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n\n        if (dotdotStatus \u003d\u003d null) {\n          // This should not happen\n          throw new IOException(\"Can\u0027t get path for handle path:\"\n              + dotdotFileIdPath);\n        }\n        dotdotFileId \u003d dotdotStatus.getFileId();\n      }\n\n      // Get the list from the resume point\n      byte[] startAfter;\n      if(cookie \u003d\u003d 0 ) {\n        startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n      } else {\n        String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n        startAfter \u003d inodeIdPath.getBytes();\n      }\n      dlisting \u003d dfsClient.listPaths(dirFileIdPath, startAfter);\n\n      postOpAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n      if (postOpAttr \u003d\u003d null) {\n        LOG.error(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIR3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n    } catch (IOException e) {\n      LOG.warn(\"Exception \", e);\n      return new READDIR3Response(Nfs3Status.NFS3ERR_IO);\n    }\n\n    /**\n     * Set up the dirents in the response. fileId is used as the cookie with one\n     * exception. Linux client can either be stuck with \"ls\" command (on REHL)\n     * or report \"Too many levels of symbolic links\" (Ubuntu).\n     * \n     * The problem is that, only two items returned, \".\" and \"..\" when the\n     * namespace is empty. Both of them are \"/\" with the same cookie(root\n     * fileId). Linux client doesn\u0027t think such a directory is a real directory.\n     * Even though NFS protocol specifies cookie is an opaque data, Linux client\n     * somehow doesn\u0027t like an empty dir returns same cookie for both \".\" and\n     * \"..\".\n     * \n     * The workaround is to use 0 as the cookie for \".\" and always return \".\" as\n     * the first entry in readdir/readdirplus response.\n     */\n    HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();    \n    int n \u003d (int) Math.min(fstatus.length, count-2);\n    boolean eof \u003d (n \u003c fstatus.length) ? false : (dlisting\n        .getRemainingEntries() \u003d\u003d 0);\n    \n    Entry3[] entries;\n    if (cookie \u003d\u003d 0) {\n      entries \u003d new Entry3[n + 2];\n      entries[0] \u003d new READDIR3Response.Entry3(postOpAttr.getFileId(), \".\", 0);\n      entries[1] \u003d new READDIR3Response.Entry3(dotdotFileId, \"..\", dotdotFileId);\n\n      for (int i \u003d 2; i \u003c n + 2; i++) {\n        entries[i] \u003d new READDIR3Response.Entry3(fstatus[i - 2].getFileId(),\n            fstatus[i - 2].getLocalName(), fstatus[i - 2].getFileId());\n      }\n    } else {\n      // Resume from last readdirplus. If the cookie is \"..\", the result\n      // list is up the directory content since HDFS uses name as resume point.    \n      entries \u003d new Entry3[n];    \n      for (int i \u003d 0; i \u003c n; i++) {\n        entries[i] \u003d new READDIR3Response.Entry3(fstatus[i].getFileId(),\n            fstatus[i].getLocalName(), fstatus[i].getFileId());\n      }\n    }\n    \n    DirList3 dirList \u003d new READDIR3Response.DirList3(entries, eof);\n    return new READDIR3Response(Nfs3Status.NFS3_OK, postOpAttr,\n        dirStatus.getModificationTime(), dirList);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
          "extendedDetails": {}
        }
      ]
    },
    "15632cd76f12c2f7df50d0df4865fbe3d8261597": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-4947 Add NFS server export table to control export by hostname or IP range. Contributed by Jing Zhao\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1517040 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "23/08/13 2:14 PM",
      "commitName": "15632cd76f12c2f7df50d0df4865fbe3d8261597",
      "commitAuthor": "Brandon Li",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-4947 Add NFS server export table to control export by hostname or IP range. Contributed by Jing Zhao\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1517040 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "23/08/13 2:14 PM",
          "commitName": "15632cd76f12c2f7df50d0df4865fbe3d8261597",
          "commitAuthor": "Brandon Li",
          "commitDateOld": "19/08/13 2:54 PM",
          "commitNameOld": "c9b89de0eacf15f21faa3a7ba30d4773f571c9a4",
          "commitAuthorOld": "Brandon Li",
          "daysBetweenCommits": 3.97,
          "commitsBetweenForRepo": 30,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,133 +1,140 @@\n-  public READDIR3Response readdir(XDR xdr, RpcAuthSys authSys) {\n+  public READDIR3Response readdir(XDR xdr, RpcAuthSys authSys,\n+      InetAddress client) {\n     READDIR3Response response \u003d new READDIR3Response(Nfs3Status.NFS3_OK);\n+    \n+    if (!checkAccessPrivilege(client, AccessPrivilege.READ_ONLY)) {\n+      response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n+      return response;\n+    }\n+    \n     String uname \u003d authSysCheck(authSys);\n     DFSClient dfsClient \u003d clientCache.get(uname);\n     if (dfsClient \u003d\u003d null) {\n       response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n       return response;\n     }\n     \n     READDIR3Request request \u003d null;\n     try {\n       request \u003d new READDIR3Request(xdr);\n     } catch (IOException e) {\n       LOG.error(\"Invalid READDIR request\");\n       return new READDIR3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     FileHandle handle \u003d request.getHandle();\n     long cookie \u003d request.getCookie();\n     if (cookie \u003c 0) {\n       LOG.error(\"Invalid READDIR request, with negitve cookie:\" + cookie);\n       return new READDIR3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     long count \u003d request.getCount();\n     if (count \u003c\u003d 0) {\n       LOG.info(\"Nonpositive count in invalid READDIR request:\" + count);\n       return new READDIR3Response(Nfs3Status.NFS3_OK);\n     }\n     \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"NFS READDIR fileId: \" + handle.getFileId() + \" cookie: \"\n           + cookie + \" count: \" + count);\n     }\n \n     HdfsFileStatus dirStatus;\n     DirectoryListing dlisting \u003d null;\n     Nfs3FileAttributes postOpAttr \u003d null;\n     long dotdotFileId \u003d 0;\n     try {\n       String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n       dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n       if (dirStatus \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new READDIR3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n       if (!dirStatus.isDir()) {\n         LOG.error(\"Can\u0027t readdir for regular file, fileId:\"\n             + handle.getFileId());\n         return new READDIR3Response(Nfs3Status.NFS3ERR_NOTDIR);\n       }\n       long cookieVerf \u003d request.getCookieVerf();\n       if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n         LOG.error(\"CookierVerf mismatch. request cookierVerf:\" + cookieVerf\n             + \" dir cookieVerf:\" + dirStatus.getModificationTime());\n         return new READDIR3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n       }\n \n       if (cookie \u003d\u003d 0) {\n         // Get dotdot fileId\n         String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n         HdfsFileStatus dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n \n         if (dotdotStatus \u003d\u003d null) {\n           // This should not happen\n           throw new IOException(\"Can\u0027t get path for handle path:\"\n               + dotdotFileIdPath);\n         }\n         dotdotFileId \u003d dotdotStatus.getFileId();\n       }\n \n       // Get the list from the resume point\n       byte[] startAfter;\n       if(cookie \u003d\u003d 0 ) {\n         startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n       } else {\n         String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n         startAfter \u003d inodeIdPath.getBytes();\n       }\n       dlisting \u003d dfsClient.listPaths(dirFileIdPath, startAfter);\n \n       postOpAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n       if (postOpAttr \u003d\u003d null) {\n         LOG.error(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new READDIR3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n     } catch (IOException e) {\n       LOG.warn(\"Exception \", e);\n       return new READDIR3Response(Nfs3Status.NFS3ERR_IO);\n     }\n \n     /**\n      * Set up the dirents in the response. fileId is used as the cookie with one\n      * exception. Linux client can either be stuck with \"ls\" command (on REHL)\n      * or report \"Too many levels of symbolic links\" (Ubuntu).\n      * \n      * The problem is that, only two items returned, \".\" and \"..\" when the\n      * namespace is empty. Both of them are \"/\" with the same cookie(root\n      * fileId). Linux client doesn\u0027t think such a directory is a real directory.\n      * Even though NFS protocol specifies cookie is an opaque data, Linux client\n      * somehow doesn\u0027t like an empty dir returns same cookie for both \".\" and\n      * \"..\".\n      * \n      * The workaround is to use 0 as the cookie for \".\" and always return \".\" as\n      * the first entry in readdir/readdirplus response.\n      */\n     HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();    \n     int n \u003d (int) Math.min(fstatus.length, count-2);\n     boolean eof \u003d (n \u003c fstatus.length) ? false : (dlisting\n         .getRemainingEntries() \u003d\u003d 0);\n     \n     Entry3[] entries;\n     if (cookie \u003d\u003d 0) {\n       entries \u003d new Entry3[n + 2];\n       entries[0] \u003d new READDIR3Response.Entry3(postOpAttr.getFileId(), \".\", 0);\n       entries[1] \u003d new READDIR3Response.Entry3(dotdotFileId, \"..\", dotdotFileId);\n \n       for (int i \u003d 2; i \u003c n + 2; i++) {\n         entries[i] \u003d new READDIR3Response.Entry3(fstatus[i - 2].getFileId(),\n             fstatus[i - 2].getLocalName(), fstatus[i - 2].getFileId());\n       }\n     } else {\n       // Resume from last readdirplus. If the cookie is \"..\", the result\n       // list is up the directory content since HDFS uses name as resume point.    \n       entries \u003d new Entry3[n];    \n       for (int i \u003d 0; i \u003c n; i++) {\n         entries[i] \u003d new READDIR3Response.Entry3(fstatus[i].getFileId(),\n             fstatus[i].getLocalName(), fstatus[i].getFileId());\n       }\n     }\n     \n     DirList3 dirList \u003d new READDIR3Response.DirList3(entries, eof);\n     return new READDIR3Response(Nfs3Status.NFS3_OK, postOpAttr,\n         dirStatus.getModificationTime(), dirList);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public READDIR3Response readdir(XDR xdr, RpcAuthSys authSys,\n      InetAddress client) {\n    READDIR3Response response \u003d new READDIR3Response(Nfs3Status.NFS3_OK);\n    \n    if (!checkAccessPrivilege(client, AccessPrivilege.READ_ONLY)) {\n      response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n      return response;\n    }\n    \n    String uname \u003d authSysCheck(authSys);\n    DFSClient dfsClient \u003d clientCache.get(uname);\n    if (dfsClient \u003d\u003d null) {\n      response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n      return response;\n    }\n    \n    READDIR3Request request \u003d null;\n    try {\n      request \u003d new READDIR3Request(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid READDIR request\");\n      return new READDIR3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    FileHandle handle \u003d request.getHandle();\n    long cookie \u003d request.getCookie();\n    if (cookie \u003c 0) {\n      LOG.error(\"Invalid READDIR request, with negitve cookie:\" + cookie);\n      return new READDIR3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    long count \u003d request.getCount();\n    if (count \u003c\u003d 0) {\n      LOG.info(\"Nonpositive count in invalid READDIR request:\" + count);\n      return new READDIR3Response(Nfs3Status.NFS3_OK);\n    }\n    \n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS READDIR fileId: \" + handle.getFileId() + \" cookie: \"\n          + cookie + \" count: \" + count);\n    }\n\n    HdfsFileStatus dirStatus;\n    DirectoryListing dlisting \u003d null;\n    Nfs3FileAttributes postOpAttr \u003d null;\n    long dotdotFileId \u003d 0;\n    try {\n      String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n      dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n      if (dirStatus \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIR3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n      if (!dirStatus.isDir()) {\n        LOG.error(\"Can\u0027t readdir for regular file, fileId:\"\n            + handle.getFileId());\n        return new READDIR3Response(Nfs3Status.NFS3ERR_NOTDIR);\n      }\n      long cookieVerf \u003d request.getCookieVerf();\n      if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n        LOG.error(\"CookierVerf mismatch. request cookierVerf:\" + cookieVerf\n            + \" dir cookieVerf:\" + dirStatus.getModificationTime());\n        return new READDIR3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n      }\n\n      if (cookie \u003d\u003d 0) {\n        // Get dotdot fileId\n        String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n        HdfsFileStatus dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n\n        if (dotdotStatus \u003d\u003d null) {\n          // This should not happen\n          throw new IOException(\"Can\u0027t get path for handle path:\"\n              + dotdotFileIdPath);\n        }\n        dotdotFileId \u003d dotdotStatus.getFileId();\n      }\n\n      // Get the list from the resume point\n      byte[] startAfter;\n      if(cookie \u003d\u003d 0 ) {\n        startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n      } else {\n        String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n        startAfter \u003d inodeIdPath.getBytes();\n      }\n      dlisting \u003d dfsClient.listPaths(dirFileIdPath, startAfter);\n\n      postOpAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n      if (postOpAttr \u003d\u003d null) {\n        LOG.error(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIR3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n    } catch (IOException e) {\n      LOG.warn(\"Exception \", e);\n      return new READDIR3Response(Nfs3Status.NFS3ERR_IO);\n    }\n\n    /**\n     * Set up the dirents in the response. fileId is used as the cookie with one\n     * exception. Linux client can either be stuck with \"ls\" command (on REHL)\n     * or report \"Too many levels of symbolic links\" (Ubuntu).\n     * \n     * The problem is that, only two items returned, \".\" and \"..\" when the\n     * namespace is empty. Both of them are \"/\" with the same cookie(root\n     * fileId). Linux client doesn\u0027t think such a directory is a real directory.\n     * Even though NFS protocol specifies cookie is an opaque data, Linux client\n     * somehow doesn\u0027t like an empty dir returns same cookie for both \".\" and\n     * \"..\".\n     * \n     * The workaround is to use 0 as the cookie for \".\" and always return \".\" as\n     * the first entry in readdir/readdirplus response.\n     */\n    HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();    \n    int n \u003d (int) Math.min(fstatus.length, count-2);\n    boolean eof \u003d (n \u003c fstatus.length) ? false : (dlisting\n        .getRemainingEntries() \u003d\u003d 0);\n    \n    Entry3[] entries;\n    if (cookie \u003d\u003d 0) {\n      entries \u003d new Entry3[n + 2];\n      entries[0] \u003d new READDIR3Response.Entry3(postOpAttr.getFileId(), \".\", 0);\n      entries[1] \u003d new READDIR3Response.Entry3(dotdotFileId, \"..\", dotdotFileId);\n\n      for (int i \u003d 2; i \u003c n + 2; i++) {\n        entries[i] \u003d new READDIR3Response.Entry3(fstatus[i - 2].getFileId(),\n            fstatus[i - 2].getLocalName(), fstatus[i - 2].getFileId());\n      }\n    } else {\n      // Resume from last readdirplus. If the cookie is \"..\", the result\n      // list is up the directory content since HDFS uses name as resume point.    \n      entries \u003d new Entry3[n];    \n      for (int i \u003d 0; i \u003c n; i++) {\n        entries[i] \u003d new READDIR3Response.Entry3(fstatus[i].getFileId(),\n            fstatus[i].getLocalName(), fstatus[i].getFileId());\n      }\n    }\n    \n    DirList3 dirList \u003d new READDIR3Response.DirList3(entries, eof);\n    return new READDIR3Response(Nfs3Status.NFS3_OK, postOpAttr,\n        dirStatus.getModificationTime(), dirList);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
          "extendedDetails": {
            "oldValue": "[xdr-XDR, authSys-RpcAuthSys]",
            "newValue": "[xdr-XDR, authSys-RpcAuthSys, client-InetAddress]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-4947 Add NFS server export table to control export by hostname or IP range. Contributed by Jing Zhao\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1517040 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "23/08/13 2:14 PM",
          "commitName": "15632cd76f12c2f7df50d0df4865fbe3d8261597",
          "commitAuthor": "Brandon Li",
          "commitDateOld": "19/08/13 2:54 PM",
          "commitNameOld": "c9b89de0eacf15f21faa3a7ba30d4773f571c9a4",
          "commitAuthorOld": "Brandon Li",
          "daysBetweenCommits": 3.97,
          "commitsBetweenForRepo": 30,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,133 +1,140 @@\n-  public READDIR3Response readdir(XDR xdr, RpcAuthSys authSys) {\n+  public READDIR3Response readdir(XDR xdr, RpcAuthSys authSys,\n+      InetAddress client) {\n     READDIR3Response response \u003d new READDIR3Response(Nfs3Status.NFS3_OK);\n+    \n+    if (!checkAccessPrivilege(client, AccessPrivilege.READ_ONLY)) {\n+      response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n+      return response;\n+    }\n+    \n     String uname \u003d authSysCheck(authSys);\n     DFSClient dfsClient \u003d clientCache.get(uname);\n     if (dfsClient \u003d\u003d null) {\n       response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n       return response;\n     }\n     \n     READDIR3Request request \u003d null;\n     try {\n       request \u003d new READDIR3Request(xdr);\n     } catch (IOException e) {\n       LOG.error(\"Invalid READDIR request\");\n       return new READDIR3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     FileHandle handle \u003d request.getHandle();\n     long cookie \u003d request.getCookie();\n     if (cookie \u003c 0) {\n       LOG.error(\"Invalid READDIR request, with negitve cookie:\" + cookie);\n       return new READDIR3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     long count \u003d request.getCount();\n     if (count \u003c\u003d 0) {\n       LOG.info(\"Nonpositive count in invalid READDIR request:\" + count);\n       return new READDIR3Response(Nfs3Status.NFS3_OK);\n     }\n     \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"NFS READDIR fileId: \" + handle.getFileId() + \" cookie: \"\n           + cookie + \" count: \" + count);\n     }\n \n     HdfsFileStatus dirStatus;\n     DirectoryListing dlisting \u003d null;\n     Nfs3FileAttributes postOpAttr \u003d null;\n     long dotdotFileId \u003d 0;\n     try {\n       String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n       dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n       if (dirStatus \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new READDIR3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n       if (!dirStatus.isDir()) {\n         LOG.error(\"Can\u0027t readdir for regular file, fileId:\"\n             + handle.getFileId());\n         return new READDIR3Response(Nfs3Status.NFS3ERR_NOTDIR);\n       }\n       long cookieVerf \u003d request.getCookieVerf();\n       if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n         LOG.error(\"CookierVerf mismatch. request cookierVerf:\" + cookieVerf\n             + \" dir cookieVerf:\" + dirStatus.getModificationTime());\n         return new READDIR3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n       }\n \n       if (cookie \u003d\u003d 0) {\n         // Get dotdot fileId\n         String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n         HdfsFileStatus dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n \n         if (dotdotStatus \u003d\u003d null) {\n           // This should not happen\n           throw new IOException(\"Can\u0027t get path for handle path:\"\n               + dotdotFileIdPath);\n         }\n         dotdotFileId \u003d dotdotStatus.getFileId();\n       }\n \n       // Get the list from the resume point\n       byte[] startAfter;\n       if(cookie \u003d\u003d 0 ) {\n         startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n       } else {\n         String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n         startAfter \u003d inodeIdPath.getBytes();\n       }\n       dlisting \u003d dfsClient.listPaths(dirFileIdPath, startAfter);\n \n       postOpAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n       if (postOpAttr \u003d\u003d null) {\n         LOG.error(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new READDIR3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n     } catch (IOException e) {\n       LOG.warn(\"Exception \", e);\n       return new READDIR3Response(Nfs3Status.NFS3ERR_IO);\n     }\n \n     /**\n      * Set up the dirents in the response. fileId is used as the cookie with one\n      * exception. Linux client can either be stuck with \"ls\" command (on REHL)\n      * or report \"Too many levels of symbolic links\" (Ubuntu).\n      * \n      * The problem is that, only two items returned, \".\" and \"..\" when the\n      * namespace is empty. Both of them are \"/\" with the same cookie(root\n      * fileId). Linux client doesn\u0027t think such a directory is a real directory.\n      * Even though NFS protocol specifies cookie is an opaque data, Linux client\n      * somehow doesn\u0027t like an empty dir returns same cookie for both \".\" and\n      * \"..\".\n      * \n      * The workaround is to use 0 as the cookie for \".\" and always return \".\" as\n      * the first entry in readdir/readdirplus response.\n      */\n     HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();    \n     int n \u003d (int) Math.min(fstatus.length, count-2);\n     boolean eof \u003d (n \u003c fstatus.length) ? false : (dlisting\n         .getRemainingEntries() \u003d\u003d 0);\n     \n     Entry3[] entries;\n     if (cookie \u003d\u003d 0) {\n       entries \u003d new Entry3[n + 2];\n       entries[0] \u003d new READDIR3Response.Entry3(postOpAttr.getFileId(), \".\", 0);\n       entries[1] \u003d new READDIR3Response.Entry3(dotdotFileId, \"..\", dotdotFileId);\n \n       for (int i \u003d 2; i \u003c n + 2; i++) {\n         entries[i] \u003d new READDIR3Response.Entry3(fstatus[i - 2].getFileId(),\n             fstatus[i - 2].getLocalName(), fstatus[i - 2].getFileId());\n       }\n     } else {\n       // Resume from last readdirplus. If the cookie is \"..\", the result\n       // list is up the directory content since HDFS uses name as resume point.    \n       entries \u003d new Entry3[n];    \n       for (int i \u003d 0; i \u003c n; i++) {\n         entries[i] \u003d new READDIR3Response.Entry3(fstatus[i].getFileId(),\n             fstatus[i].getLocalName(), fstatus[i].getFileId());\n       }\n     }\n     \n     DirList3 dirList \u003d new READDIR3Response.DirList3(entries, eof);\n     return new READDIR3Response(Nfs3Status.NFS3_OK, postOpAttr,\n         dirStatus.getModificationTime(), dirList);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public READDIR3Response readdir(XDR xdr, RpcAuthSys authSys,\n      InetAddress client) {\n    READDIR3Response response \u003d new READDIR3Response(Nfs3Status.NFS3_OK);\n    \n    if (!checkAccessPrivilege(client, AccessPrivilege.READ_ONLY)) {\n      response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n      return response;\n    }\n    \n    String uname \u003d authSysCheck(authSys);\n    DFSClient dfsClient \u003d clientCache.get(uname);\n    if (dfsClient \u003d\u003d null) {\n      response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n      return response;\n    }\n    \n    READDIR3Request request \u003d null;\n    try {\n      request \u003d new READDIR3Request(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid READDIR request\");\n      return new READDIR3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    FileHandle handle \u003d request.getHandle();\n    long cookie \u003d request.getCookie();\n    if (cookie \u003c 0) {\n      LOG.error(\"Invalid READDIR request, with negitve cookie:\" + cookie);\n      return new READDIR3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    long count \u003d request.getCount();\n    if (count \u003c\u003d 0) {\n      LOG.info(\"Nonpositive count in invalid READDIR request:\" + count);\n      return new READDIR3Response(Nfs3Status.NFS3_OK);\n    }\n    \n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS READDIR fileId: \" + handle.getFileId() + \" cookie: \"\n          + cookie + \" count: \" + count);\n    }\n\n    HdfsFileStatus dirStatus;\n    DirectoryListing dlisting \u003d null;\n    Nfs3FileAttributes postOpAttr \u003d null;\n    long dotdotFileId \u003d 0;\n    try {\n      String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n      dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n      if (dirStatus \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIR3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n      if (!dirStatus.isDir()) {\n        LOG.error(\"Can\u0027t readdir for regular file, fileId:\"\n            + handle.getFileId());\n        return new READDIR3Response(Nfs3Status.NFS3ERR_NOTDIR);\n      }\n      long cookieVerf \u003d request.getCookieVerf();\n      if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n        LOG.error(\"CookierVerf mismatch. request cookierVerf:\" + cookieVerf\n            + \" dir cookieVerf:\" + dirStatus.getModificationTime());\n        return new READDIR3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n      }\n\n      if (cookie \u003d\u003d 0) {\n        // Get dotdot fileId\n        String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n        HdfsFileStatus dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n\n        if (dotdotStatus \u003d\u003d null) {\n          // This should not happen\n          throw new IOException(\"Can\u0027t get path for handle path:\"\n              + dotdotFileIdPath);\n        }\n        dotdotFileId \u003d dotdotStatus.getFileId();\n      }\n\n      // Get the list from the resume point\n      byte[] startAfter;\n      if(cookie \u003d\u003d 0 ) {\n        startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n      } else {\n        String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n        startAfter \u003d inodeIdPath.getBytes();\n      }\n      dlisting \u003d dfsClient.listPaths(dirFileIdPath, startAfter);\n\n      postOpAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n      if (postOpAttr \u003d\u003d null) {\n        LOG.error(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIR3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n    } catch (IOException e) {\n      LOG.warn(\"Exception \", e);\n      return new READDIR3Response(Nfs3Status.NFS3ERR_IO);\n    }\n\n    /**\n     * Set up the dirents in the response. fileId is used as the cookie with one\n     * exception. Linux client can either be stuck with \"ls\" command (on REHL)\n     * or report \"Too many levels of symbolic links\" (Ubuntu).\n     * \n     * The problem is that, only two items returned, \".\" and \"..\" when the\n     * namespace is empty. Both of them are \"/\" with the same cookie(root\n     * fileId). Linux client doesn\u0027t think such a directory is a real directory.\n     * Even though NFS protocol specifies cookie is an opaque data, Linux client\n     * somehow doesn\u0027t like an empty dir returns same cookie for both \".\" and\n     * \"..\".\n     * \n     * The workaround is to use 0 as the cookie for \".\" and always return \".\" as\n     * the first entry in readdir/readdirplus response.\n     */\n    HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();    \n    int n \u003d (int) Math.min(fstatus.length, count-2);\n    boolean eof \u003d (n \u003c fstatus.length) ? false : (dlisting\n        .getRemainingEntries() \u003d\u003d 0);\n    \n    Entry3[] entries;\n    if (cookie \u003d\u003d 0) {\n      entries \u003d new Entry3[n + 2];\n      entries[0] \u003d new READDIR3Response.Entry3(postOpAttr.getFileId(), \".\", 0);\n      entries[1] \u003d new READDIR3Response.Entry3(dotdotFileId, \"..\", dotdotFileId);\n\n      for (int i \u003d 2; i \u003c n + 2; i++) {\n        entries[i] \u003d new READDIR3Response.Entry3(fstatus[i - 2].getFileId(),\n            fstatus[i - 2].getLocalName(), fstatus[i - 2].getFileId());\n      }\n    } else {\n      // Resume from last readdirplus. If the cookie is \"..\", the result\n      // list is up the directory content since HDFS uses name as resume point.    \n      entries \u003d new Entry3[n];    \n      for (int i \u003d 0; i \u003c n; i++) {\n        entries[i] \u003d new READDIR3Response.Entry3(fstatus[i].getFileId(),\n            fstatus[i].getLocalName(), fstatus[i].getFileId());\n      }\n    }\n    \n    DirList3 dirList \u003d new READDIR3Response.DirList3(entries, eof);\n    return new READDIR3Response(Nfs3Status.NFS3_OK, postOpAttr,\n        dirStatus.getModificationTime(), dirList);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
          "extendedDetails": {}
        }
      ]
    },
    "37f587563a943a827fbff865f5302bac6d202415": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-4762 Provide HDFS based NFSv3 and Mountd implementation. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1499029 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/07/13 10:31 AM",
      "commitName": "37f587563a943a827fbff865f5302bac6d202415",
      "commitAuthor": "Brandon Li",
      "diff": "@@ -0,0 +1,133 @@\n+  public READDIR3Response readdir(XDR xdr, RpcAuthSys authSys) {\n+    READDIR3Response response \u003d new READDIR3Response(Nfs3Status.NFS3_OK);\n+    String uname \u003d authSysCheck(authSys);\n+    DFSClient dfsClient \u003d clientCache.get(uname);\n+    if (dfsClient \u003d\u003d null) {\n+      response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n+      return response;\n+    }\n+    \n+    READDIR3Request request \u003d null;\n+    try {\n+      request \u003d new READDIR3Request(xdr);\n+    } catch (IOException e) {\n+      LOG.error(\"Invalid READDIR request\");\n+      return new READDIR3Response(Nfs3Status.NFS3ERR_INVAL);\n+    }\n+    FileHandle handle \u003d request.getHandle();\n+    long cookie \u003d request.getCookie();\n+    if (cookie \u003c 0) {\n+      LOG.error(\"Invalid READDIR request, with negitve cookie:\" + cookie);\n+      return new READDIR3Response(Nfs3Status.NFS3ERR_INVAL);\n+    }\n+    long count \u003d request.getCount();\n+    if (count \u003c\u003d 0) {\n+      LOG.info(\"Nonpositive count in invalid READDIR request:\" + count);\n+      return new READDIR3Response(Nfs3Status.NFS3_OK);\n+    }\n+    \n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"NFS READDIR fileId: \" + handle.getFileId() + \" cookie: \"\n+          + cookie + \" count: \" + count);\n+    }\n+\n+    HdfsFileStatus dirStatus;\n+    DirectoryListing dlisting \u003d null;\n+    Nfs3FileAttributes postOpAttr \u003d null;\n+    long dotdotFileId \u003d 0;\n+    try {\n+      String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n+      dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n+      if (dirStatus \u003d\u003d null) {\n+        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n+        return new READDIR3Response(Nfs3Status.NFS3ERR_STALE);\n+      }\n+      if (!dirStatus.isDir()) {\n+        LOG.error(\"Can\u0027t readdir for regular file, fileId:\"\n+            + handle.getFileId());\n+        return new READDIR3Response(Nfs3Status.NFS3ERR_NOTDIR);\n+      }\n+      long cookieVerf \u003d request.getCookieVerf();\n+      if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n+        LOG.error(\"CookierVerf mismatch. request cookierVerf:\" + cookieVerf\n+            + \" dir cookieVerf:\" + dirStatus.getModificationTime());\n+        return new READDIR3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n+      }\n+\n+      if (cookie \u003d\u003d 0) {\n+        // Get dotdot fileId\n+        String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n+        HdfsFileStatus dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n+\n+        if (dotdotStatus \u003d\u003d null) {\n+          // This should not happen\n+          throw new IOException(\"Can\u0027t get path for handle path:\"\n+              + dotdotFileIdPath);\n+        }\n+        dotdotFileId \u003d dotdotStatus.getFileId();\n+      }\n+\n+      // Get the list from the resume point\n+      byte[] startAfter;\n+      if(cookie \u003d\u003d 0 ) {\n+        startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n+      } else {\n+        String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n+        startAfter \u003d inodeIdPath.getBytes();\n+      }\n+      dlisting \u003d dfsClient.listPaths(dirFileIdPath, startAfter);\n+\n+      postOpAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n+      if (postOpAttr \u003d\u003d null) {\n+        LOG.error(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n+        return new READDIR3Response(Nfs3Status.NFS3ERR_STALE);\n+      }\n+    } catch (IOException e) {\n+      LOG.warn(\"Exception \", e);\n+      return new READDIR3Response(Nfs3Status.NFS3ERR_IO);\n+    }\n+\n+    /**\n+     * Set up the dirents in the response. fileId is used as the cookie with one\n+     * exception. Linux client can either be stuck with \"ls\" command (on REHL)\n+     * or report \"Too many levels of symbolic links\" (Ubuntu).\n+     * \n+     * The problem is that, only two items returned, \".\" and \"..\" when the\n+     * namespace is empty. Both of them are \"/\" with the same cookie(root\n+     * fileId). Linux client doesn\u0027t think such a directory is a real directory.\n+     * Even though NFS protocol specifies cookie is an opaque data, Linux client\n+     * somehow doesn\u0027t like an empty dir returns same cookie for both \".\" and\n+     * \"..\".\n+     * \n+     * The workaround is to use 0 as the cookie for \".\" and always return \".\" as\n+     * the first entry in readdir/readdirplus response.\n+     */\n+    HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();    \n+    int n \u003d (int) Math.min(fstatus.length, count-2);\n+    boolean eof \u003d (n \u003c fstatus.length) ? false : (dlisting\n+        .getRemainingEntries() \u003d\u003d 0);\n+    \n+    Entry3[] entries;\n+    if (cookie \u003d\u003d 0) {\n+      entries \u003d new Entry3[n + 2];\n+      entries[0] \u003d new READDIR3Response.Entry3(postOpAttr.getFileId(), \".\", 0);\n+      entries[1] \u003d new READDIR3Response.Entry3(dotdotFileId, \"..\", dotdotFileId);\n+\n+      for (int i \u003d 2; i \u003c n + 2; i++) {\n+        entries[i] \u003d new READDIR3Response.Entry3(fstatus[i - 2].getFileId(),\n+            fstatus[i - 2].getLocalName(), fstatus[i - 2].getFileId());\n+      }\n+    } else {\n+      // Resume from last readdirplus. If the cookie is \"..\", the result\n+      // list is up the directory content since HDFS uses name as resume point.    \n+      entries \u003d new Entry3[n];    \n+      for (int i \u003d 0; i \u003c n; i++) {\n+        entries[i] \u003d new READDIR3Response.Entry3(fstatus[i].getFileId(),\n+            fstatus[i].getLocalName(), fstatus[i].getFileId());\n+      }\n+    }\n+    \n+    DirList3 dirList \u003d new READDIR3Response.DirList3(entries, eof);\n+    return new READDIR3Response(Nfs3Status.NFS3_OK, postOpAttr,\n+        dirStatus.getModificationTime(), dirList);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public READDIR3Response readdir(XDR xdr, RpcAuthSys authSys) {\n    READDIR3Response response \u003d new READDIR3Response(Nfs3Status.NFS3_OK);\n    String uname \u003d authSysCheck(authSys);\n    DFSClient dfsClient \u003d clientCache.get(uname);\n    if (dfsClient \u003d\u003d null) {\n      response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n      return response;\n    }\n    \n    READDIR3Request request \u003d null;\n    try {\n      request \u003d new READDIR3Request(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid READDIR request\");\n      return new READDIR3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    FileHandle handle \u003d request.getHandle();\n    long cookie \u003d request.getCookie();\n    if (cookie \u003c 0) {\n      LOG.error(\"Invalid READDIR request, with negitve cookie:\" + cookie);\n      return new READDIR3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    long count \u003d request.getCount();\n    if (count \u003c\u003d 0) {\n      LOG.info(\"Nonpositive count in invalid READDIR request:\" + count);\n      return new READDIR3Response(Nfs3Status.NFS3_OK);\n    }\n    \n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS READDIR fileId: \" + handle.getFileId() + \" cookie: \"\n          + cookie + \" count: \" + count);\n    }\n\n    HdfsFileStatus dirStatus;\n    DirectoryListing dlisting \u003d null;\n    Nfs3FileAttributes postOpAttr \u003d null;\n    long dotdotFileId \u003d 0;\n    try {\n      String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n      dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n      if (dirStatus \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIR3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n      if (!dirStatus.isDir()) {\n        LOG.error(\"Can\u0027t readdir for regular file, fileId:\"\n            + handle.getFileId());\n        return new READDIR3Response(Nfs3Status.NFS3ERR_NOTDIR);\n      }\n      long cookieVerf \u003d request.getCookieVerf();\n      if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n        LOG.error(\"CookierVerf mismatch. request cookierVerf:\" + cookieVerf\n            + \" dir cookieVerf:\" + dirStatus.getModificationTime());\n        return new READDIR3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n      }\n\n      if (cookie \u003d\u003d 0) {\n        // Get dotdot fileId\n        String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n        HdfsFileStatus dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n\n        if (dotdotStatus \u003d\u003d null) {\n          // This should not happen\n          throw new IOException(\"Can\u0027t get path for handle path:\"\n              + dotdotFileIdPath);\n        }\n        dotdotFileId \u003d dotdotStatus.getFileId();\n      }\n\n      // Get the list from the resume point\n      byte[] startAfter;\n      if(cookie \u003d\u003d 0 ) {\n        startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n      } else {\n        String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n        startAfter \u003d inodeIdPath.getBytes();\n      }\n      dlisting \u003d dfsClient.listPaths(dirFileIdPath, startAfter);\n\n      postOpAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n      if (postOpAttr \u003d\u003d null) {\n        LOG.error(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIR3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n    } catch (IOException e) {\n      LOG.warn(\"Exception \", e);\n      return new READDIR3Response(Nfs3Status.NFS3ERR_IO);\n    }\n\n    /**\n     * Set up the dirents in the response. fileId is used as the cookie with one\n     * exception. Linux client can either be stuck with \"ls\" command (on REHL)\n     * or report \"Too many levels of symbolic links\" (Ubuntu).\n     * \n     * The problem is that, only two items returned, \".\" and \"..\" when the\n     * namespace is empty. Both of them are \"/\" with the same cookie(root\n     * fileId). Linux client doesn\u0027t think such a directory is a real directory.\n     * Even though NFS protocol specifies cookie is an opaque data, Linux client\n     * somehow doesn\u0027t like an empty dir returns same cookie for both \".\" and\n     * \"..\".\n     * \n     * The workaround is to use 0 as the cookie for \".\" and always return \".\" as\n     * the first entry in readdir/readdirplus response.\n     */\n    HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();    \n    int n \u003d (int) Math.min(fstatus.length, count-2);\n    boolean eof \u003d (n \u003c fstatus.length) ? false : (dlisting\n        .getRemainingEntries() \u003d\u003d 0);\n    \n    Entry3[] entries;\n    if (cookie \u003d\u003d 0) {\n      entries \u003d new Entry3[n + 2];\n      entries[0] \u003d new READDIR3Response.Entry3(postOpAttr.getFileId(), \".\", 0);\n      entries[1] \u003d new READDIR3Response.Entry3(dotdotFileId, \"..\", dotdotFileId);\n\n      for (int i \u003d 2; i \u003c n + 2; i++) {\n        entries[i] \u003d new READDIR3Response.Entry3(fstatus[i - 2].getFileId(),\n            fstatus[i - 2].getLocalName(), fstatus[i - 2].getFileId());\n      }\n    } else {\n      // Resume from last readdirplus. If the cookie is \"..\", the result\n      // list is up the directory content since HDFS uses name as resume point.    \n      entries \u003d new Entry3[n];    \n      for (int i \u003d 0; i \u003c n; i++) {\n        entries[i] \u003d new READDIR3Response.Entry3(fstatus[i].getFileId(),\n            fstatus[i].getLocalName(), fstatus[i].getFileId());\n      }\n    }\n    \n    DirList3 dirList \u003d new READDIR3Response.DirList3(entries, eof);\n    return new READDIR3Response(Nfs3Status.NFS3_OK, postOpAttr,\n        dirStatus.getModificationTime(), dirList);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java"
    }
  }
}