{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "RouterClientProtocol.java",
  "functionName": "create",
  "functionId": "create___src-String__masked-FsPermission__clientName-String__flag-EnumSetWritable__CreateFlag____createParent-boolean__replication-short__blockSize-long__supportedVersions-CryptoProtocolVersion[]__ecPolicyName-String__storagePolicy-String",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterClientProtocol.java",
  "functionStartLine": 259,
  "functionEndLine": 299,
  "numCommitsSeen": 44,
  "timeTaken": 4132,
  "changeHistory": [
    "48cb58390655b87506fb8b620e4aafd11e38bb34",
    "6c42d4050461ab71c88f123569649793dc53aebd",
    "e2a3c4494ba27a7b82117dac275b9d115aee7f95",
    "0d7a5ac5f526801367a9ec963e6d72783b637d55",
    "6425ed27ea638da75f656204d6df4adad1d91fe1"
  ],
  "changeHistoryShort": {
    "48cb58390655b87506fb8b620e4aafd11e38bb34": "Ybodychange",
    "6c42d4050461ab71c88f123569649793dc53aebd": "Ybodychange",
    "e2a3c4494ba27a7b82117dac275b9d115aee7f95": "Ybodychange",
    "0d7a5ac5f526801367a9ec963e6d72783b637d55": "Ymultichange(Yparameterchange,Ybodychange)",
    "6425ed27ea638da75f656204d6df4adad1d91fe1": "Yintroduced"
  },
  "changeHistoryDetails": {
    "48cb58390655b87506fb8b620e4aafd11e38bb34": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14710. RBF: Improve some RPC performance by using previous block. Contributed by xuzq.\n",
      "commitDate": "28/08/19 10:48 AM",
      "commitName": "48cb58390655b87506fb8b620e4aafd11e38bb34",
      "commitAuthor": "Inigo Goiri",
      "commitDateOld": "23/08/19 8:17 PM",
      "commitNameOld": "d2225c8ca8f9bdc5cef7266697518394d8763c88",
      "commitAuthorOld": "Ayush Saxena",
      "daysBetweenCommits": 4.6,
      "commitsBetweenForRepo": 31,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,40 +1,41 @@\n   public HdfsFileStatus create(String src, FsPermission masked,\n       String clientName, EnumSetWritable\u003cCreateFlag\u003e flag,\n       boolean createParent, short replication, long blockSize,\n       CryptoProtocolVersion[] supportedVersions, String ecPolicyName,\n       String storagePolicy)\n       throws IOException {\n     rpcServer.checkOperation(NameNode.OperationCategory.WRITE);\n \n     if (createParent \u0026\u0026 rpcServer.isPathAll(src)) {\n       int index \u003d src.lastIndexOf(Path.SEPARATOR);\n       String parent \u003d src.substring(0, index);\n       LOG.debug(\"Creating {} requires creating parent {}\", src, parent);\n       FsPermission parentPermissions \u003d getParentPermission(masked);\n       boolean success \u003d mkdirs(parent, parentPermissions, createParent);\n       if (!success) {\n         // This shouldn\u0027t happen as mkdirs returns true or exception\n         LOG.error(\"Couldn\u0027t create parents for {}\", src);\n       }\n     }\n \n     RemoteMethod method \u003d new RemoteMethod(\"create\",\n         new Class\u003c?\u003e[] {String.class, FsPermission.class, String.class,\n             EnumSetWritable.class, boolean.class, short.class,\n             long.class, CryptoProtocolVersion[].class,\n             String.class, String.class},\n         new RemoteParam(), masked, clientName, flag, createParent,\n         replication, blockSize, supportedVersions, ecPolicyName, storagePolicy);\n     final List\u003cRemoteLocation\u003e locations \u003d\n         rpcServer.getLocationsForPath(src, true);\n     RemoteLocation createLocation \u003d null;\n     try {\n       createLocation \u003d rpcServer.getCreateLocation(src);\n-      return (HdfsFileStatus) rpcClient.invokeSingle(createLocation, method);\n+      return rpcClient.invokeSingle(createLocation, method,\n+          HdfsFileStatus.class);\n     } catch (IOException ioe) {\n       final List\u003cRemoteLocation\u003e newLocations \u003d checkFaultTolerantRetry(\n           method, src, ioe, createLocation, locations);\n       return rpcClient.invokeSequential(\n           newLocations, method, HdfsFileStatus.class, null);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public HdfsFileStatus create(String src, FsPermission masked,\n      String clientName, EnumSetWritable\u003cCreateFlag\u003e flag,\n      boolean createParent, short replication, long blockSize,\n      CryptoProtocolVersion[] supportedVersions, String ecPolicyName,\n      String storagePolicy)\n      throws IOException {\n    rpcServer.checkOperation(NameNode.OperationCategory.WRITE);\n\n    if (createParent \u0026\u0026 rpcServer.isPathAll(src)) {\n      int index \u003d src.lastIndexOf(Path.SEPARATOR);\n      String parent \u003d src.substring(0, index);\n      LOG.debug(\"Creating {} requires creating parent {}\", src, parent);\n      FsPermission parentPermissions \u003d getParentPermission(masked);\n      boolean success \u003d mkdirs(parent, parentPermissions, createParent);\n      if (!success) {\n        // This shouldn\u0027t happen as mkdirs returns true or exception\n        LOG.error(\"Couldn\u0027t create parents for {}\", src);\n      }\n    }\n\n    RemoteMethod method \u003d new RemoteMethod(\"create\",\n        new Class\u003c?\u003e[] {String.class, FsPermission.class, String.class,\n            EnumSetWritable.class, boolean.class, short.class,\n            long.class, CryptoProtocolVersion[].class,\n            String.class, String.class},\n        new RemoteParam(), masked, clientName, flag, createParent,\n        replication, blockSize, supportedVersions, ecPolicyName, storagePolicy);\n    final List\u003cRemoteLocation\u003e locations \u003d\n        rpcServer.getLocationsForPath(src, true);\n    RemoteLocation createLocation \u003d null;\n    try {\n      createLocation \u003d rpcServer.getCreateLocation(src);\n      return rpcClient.invokeSingle(createLocation, method,\n          HdfsFileStatus.class);\n    } catch (IOException ioe) {\n      final List\u003cRemoteLocation\u003e newLocations \u003d checkFaultTolerantRetry(\n          method, src, ioe, createLocation, locations);\n      return rpcClient.invokeSequential(\n          newLocations, method, HdfsFileStatus.class, null);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterClientProtocol.java",
      "extendedDetails": {}
    },
    "6c42d4050461ab71c88f123569649793dc53aebd": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14316. RBF: Support unavailable subclusters for mount points with multiple destinations. Contributed by Inigo Goiri.\n",
      "commitDate": "24/06/19 9:33 AM",
      "commitName": "6c42d4050461ab71c88f123569649793dc53aebd",
      "commitAuthor": "Ayush Saxena",
      "commitDateOld": "24/06/19 9:33 AM",
      "commitNameOld": "f539e2a4ee93c4ee479fe25e8062c8ab4c7f8ba8",
      "commitAuthorOld": "Giovanni Matteo Fumarola",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,30 +1,40 @@\n   public HdfsFileStatus create(String src, FsPermission masked,\n       String clientName, EnumSetWritable\u003cCreateFlag\u003e flag,\n       boolean createParent, short replication, long blockSize,\n       CryptoProtocolVersion[] supportedVersions, String ecPolicyName,\n       String storagePolicy)\n       throws IOException {\n     rpcServer.checkOperation(NameNode.OperationCategory.WRITE);\n \n     if (createParent \u0026\u0026 rpcServer.isPathAll(src)) {\n       int index \u003d src.lastIndexOf(Path.SEPARATOR);\n       String parent \u003d src.substring(0, index);\n       LOG.debug(\"Creating {} requires creating parent {}\", src, parent);\n       FsPermission parentPermissions \u003d getParentPermission(masked);\n       boolean success \u003d mkdirs(parent, parentPermissions, createParent);\n       if (!success) {\n         // This shouldn\u0027t happen as mkdirs returns true or exception\n         LOG.error(\"Couldn\u0027t create parents for {}\", src);\n       }\n     }\n \n-    RemoteLocation createLocation \u003d rpcServer.getCreateLocation(src);\n     RemoteMethod method \u003d new RemoteMethod(\"create\",\n         new Class\u003c?\u003e[] {String.class, FsPermission.class, String.class,\n             EnumSetWritable.class, boolean.class, short.class,\n             long.class, CryptoProtocolVersion[].class,\n             String.class, String.class},\n-        createLocation.getDest(), masked, clientName, flag, createParent,\n+        new RemoteParam(), masked, clientName, flag, createParent,\n         replication, blockSize, supportedVersions, ecPolicyName, storagePolicy);\n-    return (HdfsFileStatus) rpcClient.invokeSingle(createLocation, method);\n+    final List\u003cRemoteLocation\u003e locations \u003d\n+        rpcServer.getLocationsForPath(src, true);\n+    RemoteLocation createLocation \u003d null;\n+    try {\n+      createLocation \u003d rpcServer.getCreateLocation(src);\n+      return (HdfsFileStatus) rpcClient.invokeSingle(createLocation, method);\n+    } catch (IOException ioe) {\n+      final List\u003cRemoteLocation\u003e newLocations \u003d checkFaultTolerantRetry(\n+          method, src, ioe, createLocation, locations);\n+      return rpcClient.invokeSequential(\n+          newLocations, method, HdfsFileStatus.class, null);\n+    }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public HdfsFileStatus create(String src, FsPermission masked,\n      String clientName, EnumSetWritable\u003cCreateFlag\u003e flag,\n      boolean createParent, short replication, long blockSize,\n      CryptoProtocolVersion[] supportedVersions, String ecPolicyName,\n      String storagePolicy)\n      throws IOException {\n    rpcServer.checkOperation(NameNode.OperationCategory.WRITE);\n\n    if (createParent \u0026\u0026 rpcServer.isPathAll(src)) {\n      int index \u003d src.lastIndexOf(Path.SEPARATOR);\n      String parent \u003d src.substring(0, index);\n      LOG.debug(\"Creating {} requires creating parent {}\", src, parent);\n      FsPermission parentPermissions \u003d getParentPermission(masked);\n      boolean success \u003d mkdirs(parent, parentPermissions, createParent);\n      if (!success) {\n        // This shouldn\u0027t happen as mkdirs returns true or exception\n        LOG.error(\"Couldn\u0027t create parents for {}\", src);\n      }\n    }\n\n    RemoteMethod method \u003d new RemoteMethod(\"create\",\n        new Class\u003c?\u003e[] {String.class, FsPermission.class, String.class,\n            EnumSetWritable.class, boolean.class, short.class,\n            long.class, CryptoProtocolVersion[].class,\n            String.class, String.class},\n        new RemoteParam(), masked, clientName, flag, createParent,\n        replication, blockSize, supportedVersions, ecPolicyName, storagePolicy);\n    final List\u003cRemoteLocation\u003e locations \u003d\n        rpcServer.getLocationsForPath(src, true);\n    RemoteLocation createLocation \u003d null;\n    try {\n      createLocation \u003d rpcServer.getCreateLocation(src);\n      return (HdfsFileStatus) rpcClient.invokeSingle(createLocation, method);\n    } catch (IOException ioe) {\n      final List\u003cRemoteLocation\u003e newLocations \u003d checkFaultTolerantRetry(\n          method, src, ioe, createLocation, locations);\n      return rpcClient.invokeSequential(\n          newLocations, method, HdfsFileStatus.class, null);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterClientProtocol.java",
      "extendedDetails": {}
    },
    "e2a3c4494ba27a7b82117dac275b9d115aee7f95": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14226. RBF: Setting attributes should set on all subclusters\u0027 directories. Contributed by Ayush Saxena.\n",
      "commitDate": "24/06/19 9:33 AM",
      "commitName": "e2a3c4494ba27a7b82117dac275b9d115aee7f95",
      "commitAuthor": "Inigo Goiri",
      "commitDateOld": "24/06/19 9:33 AM",
      "commitNameOld": "75f8b6ccfa6160e695ce8f7ad13c6e3624e9e7aa",
      "commitAuthorOld": "Brahma Reddy Battula",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,30 +1,30 @@\n   public HdfsFileStatus create(String src, FsPermission masked,\n       String clientName, EnumSetWritable\u003cCreateFlag\u003e flag,\n       boolean createParent, short replication, long blockSize,\n       CryptoProtocolVersion[] supportedVersions, String ecPolicyName,\n       String storagePolicy)\n       throws IOException {\n     rpcServer.checkOperation(NameNode.OperationCategory.WRITE);\n \n-    if (createParent \u0026\u0026 isPathAll(src)) {\n+    if (createParent \u0026\u0026 rpcServer.isPathAll(src)) {\n       int index \u003d src.lastIndexOf(Path.SEPARATOR);\n       String parent \u003d src.substring(0, index);\n       LOG.debug(\"Creating {} requires creating parent {}\", src, parent);\n       FsPermission parentPermissions \u003d getParentPermission(masked);\n       boolean success \u003d mkdirs(parent, parentPermissions, createParent);\n       if (!success) {\n         // This shouldn\u0027t happen as mkdirs returns true or exception\n         LOG.error(\"Couldn\u0027t create parents for {}\", src);\n       }\n     }\n \n     RemoteLocation createLocation \u003d rpcServer.getCreateLocation(src);\n     RemoteMethod method \u003d new RemoteMethod(\"create\",\n         new Class\u003c?\u003e[] {String.class, FsPermission.class, String.class,\n             EnumSetWritable.class, boolean.class, short.class,\n             long.class, CryptoProtocolVersion[].class,\n             String.class, String.class},\n         createLocation.getDest(), masked, clientName, flag, createParent,\n         replication, blockSize, supportedVersions, ecPolicyName, storagePolicy);\n     return (HdfsFileStatus) rpcClient.invokeSingle(createLocation, method);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public HdfsFileStatus create(String src, FsPermission masked,\n      String clientName, EnumSetWritable\u003cCreateFlag\u003e flag,\n      boolean createParent, short replication, long blockSize,\n      CryptoProtocolVersion[] supportedVersions, String ecPolicyName,\n      String storagePolicy)\n      throws IOException {\n    rpcServer.checkOperation(NameNode.OperationCategory.WRITE);\n\n    if (createParent \u0026\u0026 rpcServer.isPathAll(src)) {\n      int index \u003d src.lastIndexOf(Path.SEPARATOR);\n      String parent \u003d src.substring(0, index);\n      LOG.debug(\"Creating {} requires creating parent {}\", src, parent);\n      FsPermission parentPermissions \u003d getParentPermission(masked);\n      boolean success \u003d mkdirs(parent, parentPermissions, createParent);\n      if (!success) {\n        // This shouldn\u0027t happen as mkdirs returns true or exception\n        LOG.error(\"Couldn\u0027t create parents for {}\", src);\n      }\n    }\n\n    RemoteLocation createLocation \u003d rpcServer.getCreateLocation(src);\n    RemoteMethod method \u003d new RemoteMethod(\"create\",\n        new Class\u003c?\u003e[] {String.class, FsPermission.class, String.class,\n            EnumSetWritable.class, boolean.class, short.class,\n            long.class, CryptoProtocolVersion[].class,\n            String.class, String.class},\n        createLocation.getDest(), masked, clientName, flag, createParent,\n        replication, blockSize, supportedVersions, ecPolicyName, storagePolicy);\n    return (HdfsFileStatus) rpcClient.invokeSingle(createLocation, method);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterClientProtocol.java",
      "extendedDetails": {}
    },
    "0d7a5ac5f526801367a9ec963e6d72783b637d55": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-13209. DistributedFileSystem.create should allow an option to provide StoragePolicy. Contributed by Ayush Saxena.\n",
      "commitDate": "14/02/19 8:43 AM",
      "commitName": "0d7a5ac5f526801367a9ec963e6d72783b637d55",
      "commitAuthor": "Surendra Singh Lilhore",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-13209. DistributedFileSystem.create should allow an option to provide StoragePolicy. Contributed by Ayush Saxena.\n",
          "commitDate": "14/02/19 8:43 AM",
          "commitName": "0d7a5ac5f526801367a9ec963e6d72783b637d55",
          "commitAuthor": "Surendra Singh Lilhore",
          "commitDateOld": "24/12/18 9:34 AM",
          "commitNameOld": "652b257478f723a9e119e5e9181f3c7450ac92b5",
          "commitAuthorOld": "Chen Liang",
          "daysBetweenCommits": 51.96,
          "commitsBetweenForRepo": 332,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,29 +1,30 @@\n   public HdfsFileStatus create(String src, FsPermission masked,\n       String clientName, EnumSetWritable\u003cCreateFlag\u003e flag,\n       boolean createParent, short replication, long blockSize,\n-      CryptoProtocolVersion[] supportedVersions, String ecPolicyName)\n+      CryptoProtocolVersion[] supportedVersions, String ecPolicyName,\n+      String storagePolicy)\n       throws IOException {\n     rpcServer.checkOperation(NameNode.OperationCategory.WRITE);\n \n     if (createParent \u0026\u0026 isPathAll(src)) {\n       int index \u003d src.lastIndexOf(Path.SEPARATOR);\n       String parent \u003d src.substring(0, index);\n       LOG.debug(\"Creating {} requires creating parent {}\", src, parent);\n       FsPermission parentPermissions \u003d getParentPermission(masked);\n       boolean success \u003d mkdirs(parent, parentPermissions, createParent);\n       if (!success) {\n         // This shouldn\u0027t happen as mkdirs returns true or exception\n         LOG.error(\"Couldn\u0027t create parents for {}\", src);\n       }\n     }\n \n     RemoteLocation createLocation \u003d rpcServer.getCreateLocation(src);\n     RemoteMethod method \u003d new RemoteMethod(\"create\",\n         new Class\u003c?\u003e[] {String.class, FsPermission.class, String.class,\n             EnumSetWritable.class, boolean.class, short.class,\n             long.class, CryptoProtocolVersion[].class,\n-            String.class},\n+            String.class, String.class},\n         createLocation.getDest(), masked, clientName, flag, createParent,\n-        replication, blockSize, supportedVersions, ecPolicyName);\n+        replication, blockSize, supportedVersions, ecPolicyName, storagePolicy);\n     return (HdfsFileStatus) rpcClient.invokeSingle(createLocation, method);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public HdfsFileStatus create(String src, FsPermission masked,\n      String clientName, EnumSetWritable\u003cCreateFlag\u003e flag,\n      boolean createParent, short replication, long blockSize,\n      CryptoProtocolVersion[] supportedVersions, String ecPolicyName,\n      String storagePolicy)\n      throws IOException {\n    rpcServer.checkOperation(NameNode.OperationCategory.WRITE);\n\n    if (createParent \u0026\u0026 isPathAll(src)) {\n      int index \u003d src.lastIndexOf(Path.SEPARATOR);\n      String parent \u003d src.substring(0, index);\n      LOG.debug(\"Creating {} requires creating parent {}\", src, parent);\n      FsPermission parentPermissions \u003d getParentPermission(masked);\n      boolean success \u003d mkdirs(parent, parentPermissions, createParent);\n      if (!success) {\n        // This shouldn\u0027t happen as mkdirs returns true or exception\n        LOG.error(\"Couldn\u0027t create parents for {}\", src);\n      }\n    }\n\n    RemoteLocation createLocation \u003d rpcServer.getCreateLocation(src);\n    RemoteMethod method \u003d new RemoteMethod(\"create\",\n        new Class\u003c?\u003e[] {String.class, FsPermission.class, String.class,\n            EnumSetWritable.class, boolean.class, short.class,\n            long.class, CryptoProtocolVersion[].class,\n            String.class, String.class},\n        createLocation.getDest(), masked, clientName, flag, createParent,\n        replication, blockSize, supportedVersions, ecPolicyName, storagePolicy);\n    return (HdfsFileStatus) rpcClient.invokeSingle(createLocation, method);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterClientProtocol.java",
          "extendedDetails": {
            "oldValue": "[src-String, masked-FsPermission, clientName-String, flag-EnumSetWritable\u003cCreateFlag\u003e, createParent-boolean, replication-short, blockSize-long, supportedVersions-CryptoProtocolVersion[], ecPolicyName-String]",
            "newValue": "[src-String, masked-FsPermission, clientName-String, flag-EnumSetWritable\u003cCreateFlag\u003e, createParent-boolean, replication-short, blockSize-long, supportedVersions-CryptoProtocolVersion[], ecPolicyName-String, storagePolicy-String]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-13209. DistributedFileSystem.create should allow an option to provide StoragePolicy. Contributed by Ayush Saxena.\n",
          "commitDate": "14/02/19 8:43 AM",
          "commitName": "0d7a5ac5f526801367a9ec963e6d72783b637d55",
          "commitAuthor": "Surendra Singh Lilhore",
          "commitDateOld": "24/12/18 9:34 AM",
          "commitNameOld": "652b257478f723a9e119e5e9181f3c7450ac92b5",
          "commitAuthorOld": "Chen Liang",
          "daysBetweenCommits": 51.96,
          "commitsBetweenForRepo": 332,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,29 +1,30 @@\n   public HdfsFileStatus create(String src, FsPermission masked,\n       String clientName, EnumSetWritable\u003cCreateFlag\u003e flag,\n       boolean createParent, short replication, long blockSize,\n-      CryptoProtocolVersion[] supportedVersions, String ecPolicyName)\n+      CryptoProtocolVersion[] supportedVersions, String ecPolicyName,\n+      String storagePolicy)\n       throws IOException {\n     rpcServer.checkOperation(NameNode.OperationCategory.WRITE);\n \n     if (createParent \u0026\u0026 isPathAll(src)) {\n       int index \u003d src.lastIndexOf(Path.SEPARATOR);\n       String parent \u003d src.substring(0, index);\n       LOG.debug(\"Creating {} requires creating parent {}\", src, parent);\n       FsPermission parentPermissions \u003d getParentPermission(masked);\n       boolean success \u003d mkdirs(parent, parentPermissions, createParent);\n       if (!success) {\n         // This shouldn\u0027t happen as mkdirs returns true or exception\n         LOG.error(\"Couldn\u0027t create parents for {}\", src);\n       }\n     }\n \n     RemoteLocation createLocation \u003d rpcServer.getCreateLocation(src);\n     RemoteMethod method \u003d new RemoteMethod(\"create\",\n         new Class\u003c?\u003e[] {String.class, FsPermission.class, String.class,\n             EnumSetWritable.class, boolean.class, short.class,\n             long.class, CryptoProtocolVersion[].class,\n-            String.class},\n+            String.class, String.class},\n         createLocation.getDest(), masked, clientName, flag, createParent,\n-        replication, blockSize, supportedVersions, ecPolicyName);\n+        replication, blockSize, supportedVersions, ecPolicyName, storagePolicy);\n     return (HdfsFileStatus) rpcClient.invokeSingle(createLocation, method);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public HdfsFileStatus create(String src, FsPermission masked,\n      String clientName, EnumSetWritable\u003cCreateFlag\u003e flag,\n      boolean createParent, short replication, long blockSize,\n      CryptoProtocolVersion[] supportedVersions, String ecPolicyName,\n      String storagePolicy)\n      throws IOException {\n    rpcServer.checkOperation(NameNode.OperationCategory.WRITE);\n\n    if (createParent \u0026\u0026 isPathAll(src)) {\n      int index \u003d src.lastIndexOf(Path.SEPARATOR);\n      String parent \u003d src.substring(0, index);\n      LOG.debug(\"Creating {} requires creating parent {}\", src, parent);\n      FsPermission parentPermissions \u003d getParentPermission(masked);\n      boolean success \u003d mkdirs(parent, parentPermissions, createParent);\n      if (!success) {\n        // This shouldn\u0027t happen as mkdirs returns true or exception\n        LOG.error(\"Couldn\u0027t create parents for {}\", src);\n      }\n    }\n\n    RemoteLocation createLocation \u003d rpcServer.getCreateLocation(src);\n    RemoteMethod method \u003d new RemoteMethod(\"create\",\n        new Class\u003c?\u003e[] {String.class, FsPermission.class, String.class,\n            EnumSetWritable.class, boolean.class, short.class,\n            long.class, CryptoProtocolVersion[].class,\n            String.class, String.class},\n        createLocation.getDest(), masked, clientName, flag, createParent,\n        replication, blockSize, supportedVersions, ecPolicyName, storagePolicy);\n    return (HdfsFileStatus) rpcClient.invokeSingle(createLocation, method);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterClientProtocol.java",
          "extendedDetails": {}
        }
      ]
    },
    "6425ed27ea638da75f656204d6df4adad1d91fe1": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-13790. RBF: Move ClientProtocol APIs to its own module. Contributed by Chao Sun.\n",
      "commitDate": "19/08/18 11:50 PM",
      "commitName": "6425ed27ea638da75f656204d6df4adad1d91fe1",
      "commitAuthor": "Brahma Reddy Battula",
      "diff": "@@ -0,0 +1,29 @@\n+  public HdfsFileStatus create(String src, FsPermission masked,\n+      String clientName, EnumSetWritable\u003cCreateFlag\u003e flag,\n+      boolean createParent, short replication, long blockSize,\n+      CryptoProtocolVersion[] supportedVersions, String ecPolicyName)\n+      throws IOException {\n+    rpcServer.checkOperation(NameNode.OperationCategory.WRITE);\n+\n+    if (createParent \u0026\u0026 isPathAll(src)) {\n+      int index \u003d src.lastIndexOf(Path.SEPARATOR);\n+      String parent \u003d src.substring(0, index);\n+      LOG.debug(\"Creating {} requires creating parent {}\", src, parent);\n+      FsPermission parentPermissions \u003d getParentPermission(masked);\n+      boolean success \u003d mkdirs(parent, parentPermissions, createParent);\n+      if (!success) {\n+        // This shouldn\u0027t happen as mkdirs returns true or exception\n+        LOG.error(\"Couldn\u0027t create parents for {}\", src);\n+      }\n+    }\n+\n+    RemoteLocation createLocation \u003d rpcServer.getCreateLocation(src);\n+    RemoteMethod method \u003d new RemoteMethod(\"create\",\n+        new Class\u003c?\u003e[] {String.class, FsPermission.class, String.class,\n+            EnumSetWritable.class, boolean.class, short.class,\n+            long.class, CryptoProtocolVersion[].class,\n+            String.class},\n+        createLocation.getDest(), masked, clientName, flag, createParent,\n+        replication, blockSize, supportedVersions, ecPolicyName);\n+    return (HdfsFileStatus) rpcClient.invokeSingle(createLocation, method);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public HdfsFileStatus create(String src, FsPermission masked,\n      String clientName, EnumSetWritable\u003cCreateFlag\u003e flag,\n      boolean createParent, short replication, long blockSize,\n      CryptoProtocolVersion[] supportedVersions, String ecPolicyName)\n      throws IOException {\n    rpcServer.checkOperation(NameNode.OperationCategory.WRITE);\n\n    if (createParent \u0026\u0026 isPathAll(src)) {\n      int index \u003d src.lastIndexOf(Path.SEPARATOR);\n      String parent \u003d src.substring(0, index);\n      LOG.debug(\"Creating {} requires creating parent {}\", src, parent);\n      FsPermission parentPermissions \u003d getParentPermission(masked);\n      boolean success \u003d mkdirs(parent, parentPermissions, createParent);\n      if (!success) {\n        // This shouldn\u0027t happen as mkdirs returns true or exception\n        LOG.error(\"Couldn\u0027t create parents for {}\", src);\n      }\n    }\n\n    RemoteLocation createLocation \u003d rpcServer.getCreateLocation(src);\n    RemoteMethod method \u003d new RemoteMethod(\"create\",\n        new Class\u003c?\u003e[] {String.class, FsPermission.class, String.class,\n            EnumSetWritable.class, boolean.class, short.class,\n            long.class, CryptoProtocolVersion[].class,\n            String.class},\n        createLocation.getDest(), masked, clientName, flag, createParent,\n        replication, blockSize, supportedVersions, ecPolicyName);\n    return (HdfsFileStatus) rpcClient.invokeSingle(createLocation, method);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterClientProtocol.java"
    }
  }
}