{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "Journal.java",
  "functionName": "acceptRecovery",
  "functionId": "acceptRecovery___reqInfo-RequestInfo__segment-SegmentStateProto__fromUrl-URL",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java",
  "functionStartLine": 858,
  "functionEndLine": 973,
  "numCommitsSeen": 64,
  "timeTaken": 3776,
  "changeHistory": [
    "fba9d7cd746cd7b659d2fd9d2bfa23266be9009b",
    "6beb25ab7e4f5454dba0315a296081e61753f301",
    "53c38cc89ab979ec47557dcfa7affbad20578c0a",
    "ae91b13a4b1896b893268253104f935c3078d345",
    "3ccd905d8a0fe5e3a206ac955b689a6f02b25e67",
    "663e7484c04c197eed53f10a7808140f1c955277",
    "c5199cace63f11c3f46b4067032afad82ee4aef6",
    "959afc0fd3bdd4fa366fbec97ffa6b96d4528e53",
    "8021d9199f278345aca6211f318145342ad036f4",
    "c95a1674b61ef2a6963dc64604986ef90a8c636d",
    "f765fdb65701e61887daedb2b369af4be12cb432",
    "74d4573a23db5586c6e47ff2277aa7c35237da34"
  ],
  "changeHistoryShort": {
    "fba9d7cd746cd7b659d2fd9d2bfa23266be9009b": "Ybodychange",
    "6beb25ab7e4f5454dba0315a296081e61753f301": "Ybodychange",
    "53c38cc89ab979ec47557dcfa7affbad20578c0a": "Ybodychange",
    "ae91b13a4b1896b893268253104f935c3078d345": "Ybodychange",
    "3ccd905d8a0fe5e3a206ac955b689a6f02b25e67": "Ybodychange",
    "663e7484c04c197eed53f10a7808140f1c955277": "Ybodychange",
    "c5199cace63f11c3f46b4067032afad82ee4aef6": "Ybodychange",
    "959afc0fd3bdd4fa366fbec97ffa6b96d4528e53": "Ybodychange",
    "8021d9199f278345aca6211f318145342ad036f4": "Ybodychange",
    "c95a1674b61ef2a6963dc64604986ef90a8c636d": "Ybodychange",
    "f765fdb65701e61887daedb2b369af4be12cb432": "Ybodychange",
    "74d4573a23db5586c6e47ff2277aa7c35237da34": "Yintroduced"
  },
  "changeHistoryDetails": {
    "fba9d7cd746cd7b659d2fd9d2bfa23266be9009b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13621. Upgrade commons-lang version to 3.7 in hadoop-hdfs-project. Contributed by Takanobu Asanuma.\n",
      "commitDate": "18/06/18 10:17 AM",
      "commitName": "fba9d7cd746cd7b659d2fd9d2bfa23266be9009b",
      "commitAuthor": "Akira Ajisaka",
      "commitDateOld": "14/05/18 10:12 AM",
      "commitNameOld": "6beb25ab7e4f5454dba0315a296081e61753f301",
      "commitAuthorOld": "Hanisha Koneru",
      "daysBetweenCommits": 35.0,
      "commitsBetweenForRepo": 277,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,116 +1,116 @@\n   public synchronized void acceptRecovery(RequestInfo reqInfo,\n       SegmentStateProto segment, URL fromUrl)\n       throws IOException {\n     checkFormatted();\n     checkRequest(reqInfo);\n     \n     abortCurSegment();\n \n     long segmentTxId \u003d segment.getStartTxId();\n \n     // Basic sanity checks that the segment is well-formed and contains\n     // at least one transaction.\n     Preconditions.checkArgument(segment.getEndTxId() \u003e 0 \u0026\u0026\n         segment.getEndTxId() \u003e\u003d segmentTxId,\n         \"bad recovery state for segment %s: %s ; journal id: %s\",\n         segmentTxId, TextFormat.shortDebugString(segment), journalId);\n     \n     PersistedRecoveryPaxosData oldData \u003d getPersistedPaxosData(segmentTxId);\n     PersistedRecoveryPaxosData newData \u003d PersistedRecoveryPaxosData.newBuilder()\n         .setAcceptedInEpoch(reqInfo.getEpoch())\n         .setSegmentState(segment)\n         .build();\n     \n     // If we previously acted on acceptRecovery() from a higher-numbered writer,\n     // this call is out of sync. We should never actually trigger this, since the\n     // checkRequest() call above should filter non-increasing epoch numbers.\n     if (oldData !\u003d null) {\n       alwaysAssert(oldData.getAcceptedInEpoch() \u003c\u003d reqInfo.getEpoch(),\n           \"Bad paxos transition, out-of-order epochs.\\nOld: %s\\nNew: \" +\n               \"%s\\nJournalId: %s\\n\",\n           oldData, newData, journalId);\n     }\n     \n     File syncedFile \u003d null;\n     \n     SegmentStateProto currentSegment \u003d getSegmentInfo(segmentTxId);\n     if (currentSegment \u003d\u003d null ||\n         currentSegment.getEndTxId() !\u003d segment.getEndTxId()) {\n       if (currentSegment \u003d\u003d null) {\n         LOG.info(\"Synchronizing log \" + TextFormat.shortDebugString(segment) +\n             \": no current segment in place ; journal id: \" + journalId);\n         \n         // Update the highest txid for lag metrics\n         updateHighestWrittenTxId(Math.max(segment.getEndTxId(),\n             highestWrittenTxId));\n       } else {\n         LOG.info(\"Synchronizing log \" + TextFormat.shortDebugString(segment) +\n             \": old segment \" + TextFormat.shortDebugString(currentSegment) +\n             \" is not the right length ; journal id: \" + journalId);\n         \n         // Paranoid sanity check: if the new log is shorter than the log we\n         // currently have, we should not end up discarding any transactions\n         // which are already Committed.\n-        if (txnRange(currentSegment).containsLong(committedTxnId.get()) \u0026\u0026\n-            !txnRange(segment).containsLong(committedTxnId.get())) {\n+        if (txnRange(currentSegment).contains(committedTxnId.get()) \u0026\u0026\n+            !txnRange(segment).contains(committedTxnId.get())) {\n           throw new AssertionError(\n               \"Cannot replace segment \" +\n               TextFormat.shortDebugString(currentSegment) +\n               \" with new segment \" +\n               TextFormat.shortDebugString(segment) + \n               \": would discard already-committed txn \" +\n               committedTxnId.get() +\n               \" ; journal id: \" + journalId);\n         }\n         \n         // Another paranoid check: we should not be asked to synchronize a log\n         // on top of a finalized segment.\n         alwaysAssert(currentSegment.getIsInProgress(),\n             \"Should never be asked to synchronize a different log on top of \" +\n             \"an already-finalized segment ; journal id: \" + journalId);\n         \n         // If we\u0027re shortening the log, update our highest txid\n         // used for lag metrics.\n-        if (txnRange(currentSegment).containsLong(highestWrittenTxId)) {\n+        if (txnRange(currentSegment).contains(highestWrittenTxId)) {\n           updateHighestWrittenTxId(segment.getEndTxId());\n         }\n       }\n       syncedFile \u003d syncLog(reqInfo, segment, fromUrl);\n       \n     } else {\n       LOG.info(\"Skipping download of log \" +\n           TextFormat.shortDebugString(segment) +\n           \": already have up-to-date logs ; journal id: \" + journalId);\n     }\n     \n     // This is one of the few places in the protocol where we have a single\n     // RPC that results in two distinct actions:\n     //\n     // - 1) Downloads the new log segment data (above)\n     // - 2) Records the new Paxos data about the synchronized segment (below)\n     //\n     // These need to be treated as a transaction from the perspective\n     // of any external process. We do this by treating the persistPaxosData()\n     // success as the \"commit\" of an atomic transaction. If we fail before\n     // this point, the downloaded edit log will only exist at a temporary\n     // path, and thus not change any externally visible state. If we fail\n     // after this point, then any future prepareRecovery() call will see\n     // the Paxos data, and by calling completeHalfDoneAcceptRecovery() will\n     // roll forward the rename of the referenced log file.\n     //\n     // See also: HDFS-3955\n     //\n     // The fault points here are exercised by the randomized fault injection\n     // test case to ensure that this atomic \"transaction\" operates correctly.\n     JournalFaultInjector.get().beforePersistPaxosData();\n     persistPaxosData(segmentTxId, newData);\n     JournalFaultInjector.get().afterPersistPaxosData();\n \n     if (syncedFile !\u003d null) {\n       FileUtil.replaceFile(syncedFile,\n           storage.getInProgressEditLog(segmentTxId));\n     }\n \n     LOG.info(\"Accepted recovery for segment \" + segmentTxId + \": \" +\n         TextFormat.shortDebugString(newData) + \" ; journal id: \" + journalId);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void acceptRecovery(RequestInfo reqInfo,\n      SegmentStateProto segment, URL fromUrl)\n      throws IOException {\n    checkFormatted();\n    checkRequest(reqInfo);\n    \n    abortCurSegment();\n\n    long segmentTxId \u003d segment.getStartTxId();\n\n    // Basic sanity checks that the segment is well-formed and contains\n    // at least one transaction.\n    Preconditions.checkArgument(segment.getEndTxId() \u003e 0 \u0026\u0026\n        segment.getEndTxId() \u003e\u003d segmentTxId,\n        \"bad recovery state for segment %s: %s ; journal id: %s\",\n        segmentTxId, TextFormat.shortDebugString(segment), journalId);\n    \n    PersistedRecoveryPaxosData oldData \u003d getPersistedPaxosData(segmentTxId);\n    PersistedRecoveryPaxosData newData \u003d PersistedRecoveryPaxosData.newBuilder()\n        .setAcceptedInEpoch(reqInfo.getEpoch())\n        .setSegmentState(segment)\n        .build();\n    \n    // If we previously acted on acceptRecovery() from a higher-numbered writer,\n    // this call is out of sync. We should never actually trigger this, since the\n    // checkRequest() call above should filter non-increasing epoch numbers.\n    if (oldData !\u003d null) {\n      alwaysAssert(oldData.getAcceptedInEpoch() \u003c\u003d reqInfo.getEpoch(),\n          \"Bad paxos transition, out-of-order epochs.\\nOld: %s\\nNew: \" +\n              \"%s\\nJournalId: %s\\n\",\n          oldData, newData, journalId);\n    }\n    \n    File syncedFile \u003d null;\n    \n    SegmentStateProto currentSegment \u003d getSegmentInfo(segmentTxId);\n    if (currentSegment \u003d\u003d null ||\n        currentSegment.getEndTxId() !\u003d segment.getEndTxId()) {\n      if (currentSegment \u003d\u003d null) {\n        LOG.info(\"Synchronizing log \" + TextFormat.shortDebugString(segment) +\n            \": no current segment in place ; journal id: \" + journalId);\n        \n        // Update the highest txid for lag metrics\n        updateHighestWrittenTxId(Math.max(segment.getEndTxId(),\n            highestWrittenTxId));\n      } else {\n        LOG.info(\"Synchronizing log \" + TextFormat.shortDebugString(segment) +\n            \": old segment \" + TextFormat.shortDebugString(currentSegment) +\n            \" is not the right length ; journal id: \" + journalId);\n        \n        // Paranoid sanity check: if the new log is shorter than the log we\n        // currently have, we should not end up discarding any transactions\n        // which are already Committed.\n        if (txnRange(currentSegment).contains(committedTxnId.get()) \u0026\u0026\n            !txnRange(segment).contains(committedTxnId.get())) {\n          throw new AssertionError(\n              \"Cannot replace segment \" +\n              TextFormat.shortDebugString(currentSegment) +\n              \" with new segment \" +\n              TextFormat.shortDebugString(segment) + \n              \": would discard already-committed txn \" +\n              committedTxnId.get() +\n              \" ; journal id: \" + journalId);\n        }\n        \n        // Another paranoid check: we should not be asked to synchronize a log\n        // on top of a finalized segment.\n        alwaysAssert(currentSegment.getIsInProgress(),\n            \"Should never be asked to synchronize a different log on top of \" +\n            \"an already-finalized segment ; journal id: \" + journalId);\n        \n        // If we\u0027re shortening the log, update our highest txid\n        // used for lag metrics.\n        if (txnRange(currentSegment).contains(highestWrittenTxId)) {\n          updateHighestWrittenTxId(segment.getEndTxId());\n        }\n      }\n      syncedFile \u003d syncLog(reqInfo, segment, fromUrl);\n      \n    } else {\n      LOG.info(\"Skipping download of log \" +\n          TextFormat.shortDebugString(segment) +\n          \": already have up-to-date logs ; journal id: \" + journalId);\n    }\n    \n    // This is one of the few places in the protocol where we have a single\n    // RPC that results in two distinct actions:\n    //\n    // - 1) Downloads the new log segment data (above)\n    // - 2) Records the new Paxos data about the synchronized segment (below)\n    //\n    // These need to be treated as a transaction from the perspective\n    // of any external process. We do this by treating the persistPaxosData()\n    // success as the \"commit\" of an atomic transaction. If we fail before\n    // this point, the downloaded edit log will only exist at a temporary\n    // path, and thus not change any externally visible state. If we fail\n    // after this point, then any future prepareRecovery() call will see\n    // the Paxos data, and by calling completeHalfDoneAcceptRecovery() will\n    // roll forward the rename of the referenced log file.\n    //\n    // See also: HDFS-3955\n    //\n    // The fault points here are exercised by the randomized fault injection\n    // test case to ensure that this atomic \"transaction\" operates correctly.\n    JournalFaultInjector.get().beforePersistPaxosData();\n    persistPaxosData(segmentTxId, newData);\n    JournalFaultInjector.get().afterPersistPaxosData();\n\n    if (syncedFile !\u003d null) {\n      FileUtil.replaceFile(syncedFile,\n          storage.getInProgressEditLog(segmentTxId));\n    }\n\n    LOG.info(\"Accepted recovery for segment \" + segmentTxId + \": \" +\n        TextFormat.shortDebugString(newData) + \" ; journal id: \" + journalId);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java",
      "extendedDetails": {}
    },
    "6beb25ab7e4f5454dba0315a296081e61753f301": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13544. Improve logging for JournalNode in federated cluster.\n",
      "commitDate": "14/05/18 10:12 AM",
      "commitName": "6beb25ab7e4f5454dba0315a296081e61753f301",
      "commitAuthor": "Hanisha Koneru",
      "commitDateOld": "13/10/17 2:22 PM",
      "commitNameOld": "8dd1eeb94fef59feaf19182dd8f1fcf1389c7f34",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 212.83,
      "commitsBetweenForRepo": 2051,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,114 +1,116 @@\n   public synchronized void acceptRecovery(RequestInfo reqInfo,\n       SegmentStateProto segment, URL fromUrl)\n       throws IOException {\n     checkFormatted();\n     checkRequest(reqInfo);\n     \n     abortCurSegment();\n \n     long segmentTxId \u003d segment.getStartTxId();\n \n     // Basic sanity checks that the segment is well-formed and contains\n     // at least one transaction.\n     Preconditions.checkArgument(segment.getEndTxId() \u003e 0 \u0026\u0026\n         segment.getEndTxId() \u003e\u003d segmentTxId,\n-        \"bad recovery state for segment %s: %s\",\n-        segmentTxId, TextFormat.shortDebugString(segment));\n+        \"bad recovery state for segment %s: %s ; journal id: %s\",\n+        segmentTxId, TextFormat.shortDebugString(segment), journalId);\n     \n     PersistedRecoveryPaxosData oldData \u003d getPersistedPaxosData(segmentTxId);\n     PersistedRecoveryPaxosData newData \u003d PersistedRecoveryPaxosData.newBuilder()\n         .setAcceptedInEpoch(reqInfo.getEpoch())\n         .setSegmentState(segment)\n         .build();\n     \n     // If we previously acted on acceptRecovery() from a higher-numbered writer,\n     // this call is out of sync. We should never actually trigger this, since the\n     // checkRequest() call above should filter non-increasing epoch numbers.\n     if (oldData !\u003d null) {\n       alwaysAssert(oldData.getAcceptedInEpoch() \u003c\u003d reqInfo.getEpoch(),\n-          \"Bad paxos transition, out-of-order epochs.\\nOld: %s\\nNew: %s\\n\",\n-          oldData, newData);\n+          \"Bad paxos transition, out-of-order epochs.\\nOld: %s\\nNew: \" +\n+              \"%s\\nJournalId: %s\\n\",\n+          oldData, newData, journalId);\n     }\n     \n     File syncedFile \u003d null;\n     \n     SegmentStateProto currentSegment \u003d getSegmentInfo(segmentTxId);\n     if (currentSegment \u003d\u003d null ||\n         currentSegment.getEndTxId() !\u003d segment.getEndTxId()) {\n       if (currentSegment \u003d\u003d null) {\n         LOG.info(\"Synchronizing log \" + TextFormat.shortDebugString(segment) +\n-            \": no current segment in place\");\n+            \": no current segment in place ; journal id: \" + journalId);\n         \n         // Update the highest txid for lag metrics\n         updateHighestWrittenTxId(Math.max(segment.getEndTxId(),\n             highestWrittenTxId));\n       } else {\n         LOG.info(\"Synchronizing log \" + TextFormat.shortDebugString(segment) +\n             \": old segment \" + TextFormat.shortDebugString(currentSegment) +\n-            \" is not the right length\");\n+            \" is not the right length ; journal id: \" + journalId);\n         \n         // Paranoid sanity check: if the new log is shorter than the log we\n         // currently have, we should not end up discarding any transactions\n         // which are already Committed.\n         if (txnRange(currentSegment).containsLong(committedTxnId.get()) \u0026\u0026\n             !txnRange(segment).containsLong(committedTxnId.get())) {\n           throw new AssertionError(\n               \"Cannot replace segment \" +\n               TextFormat.shortDebugString(currentSegment) +\n               \" with new segment \" +\n               TextFormat.shortDebugString(segment) + \n               \": would discard already-committed txn \" +\n-              committedTxnId.get());\n+              committedTxnId.get() +\n+              \" ; journal id: \" + journalId);\n         }\n         \n         // Another paranoid check: we should not be asked to synchronize a log\n         // on top of a finalized segment.\n         alwaysAssert(currentSegment.getIsInProgress(),\n-            \"Should never be asked to synchronize a different log on top of an \" +\n-            \"already-finalized segment\");\n+            \"Should never be asked to synchronize a different log on top of \" +\n+            \"an already-finalized segment ; journal id: \" + journalId);\n         \n         // If we\u0027re shortening the log, update our highest txid\n         // used for lag metrics.\n         if (txnRange(currentSegment).containsLong(highestWrittenTxId)) {\n           updateHighestWrittenTxId(segment.getEndTxId());\n         }\n       }\n       syncedFile \u003d syncLog(reqInfo, segment, fromUrl);\n       \n     } else {\n       LOG.info(\"Skipping download of log \" +\n           TextFormat.shortDebugString(segment) +\n-          \": already have up-to-date logs\");\n+          \": already have up-to-date logs ; journal id: \" + journalId);\n     }\n     \n     // This is one of the few places in the protocol where we have a single\n     // RPC that results in two distinct actions:\n     //\n     // - 1) Downloads the new log segment data (above)\n     // - 2) Records the new Paxos data about the synchronized segment (below)\n     //\n     // These need to be treated as a transaction from the perspective\n     // of any external process. We do this by treating the persistPaxosData()\n     // success as the \"commit\" of an atomic transaction. If we fail before\n     // this point, the downloaded edit log will only exist at a temporary\n     // path, and thus not change any externally visible state. If we fail\n     // after this point, then any future prepareRecovery() call will see\n     // the Paxos data, and by calling completeHalfDoneAcceptRecovery() will\n     // roll forward the rename of the referenced log file.\n     //\n     // See also: HDFS-3955\n     //\n     // The fault points here are exercised by the randomized fault injection\n     // test case to ensure that this atomic \"transaction\" operates correctly.\n     JournalFaultInjector.get().beforePersistPaxosData();\n     persistPaxosData(segmentTxId, newData);\n     JournalFaultInjector.get().afterPersistPaxosData();\n \n     if (syncedFile !\u003d null) {\n       FileUtil.replaceFile(syncedFile,\n           storage.getInProgressEditLog(segmentTxId));\n     }\n \n     LOG.info(\"Accepted recovery for segment \" + segmentTxId + \": \" +\n-        TextFormat.shortDebugString(newData));\n+        TextFormat.shortDebugString(newData) + \" ; journal id: \" + journalId);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void acceptRecovery(RequestInfo reqInfo,\n      SegmentStateProto segment, URL fromUrl)\n      throws IOException {\n    checkFormatted();\n    checkRequest(reqInfo);\n    \n    abortCurSegment();\n\n    long segmentTxId \u003d segment.getStartTxId();\n\n    // Basic sanity checks that the segment is well-formed and contains\n    // at least one transaction.\n    Preconditions.checkArgument(segment.getEndTxId() \u003e 0 \u0026\u0026\n        segment.getEndTxId() \u003e\u003d segmentTxId,\n        \"bad recovery state for segment %s: %s ; journal id: %s\",\n        segmentTxId, TextFormat.shortDebugString(segment), journalId);\n    \n    PersistedRecoveryPaxosData oldData \u003d getPersistedPaxosData(segmentTxId);\n    PersistedRecoveryPaxosData newData \u003d PersistedRecoveryPaxosData.newBuilder()\n        .setAcceptedInEpoch(reqInfo.getEpoch())\n        .setSegmentState(segment)\n        .build();\n    \n    // If we previously acted on acceptRecovery() from a higher-numbered writer,\n    // this call is out of sync. We should never actually trigger this, since the\n    // checkRequest() call above should filter non-increasing epoch numbers.\n    if (oldData !\u003d null) {\n      alwaysAssert(oldData.getAcceptedInEpoch() \u003c\u003d reqInfo.getEpoch(),\n          \"Bad paxos transition, out-of-order epochs.\\nOld: %s\\nNew: \" +\n              \"%s\\nJournalId: %s\\n\",\n          oldData, newData, journalId);\n    }\n    \n    File syncedFile \u003d null;\n    \n    SegmentStateProto currentSegment \u003d getSegmentInfo(segmentTxId);\n    if (currentSegment \u003d\u003d null ||\n        currentSegment.getEndTxId() !\u003d segment.getEndTxId()) {\n      if (currentSegment \u003d\u003d null) {\n        LOG.info(\"Synchronizing log \" + TextFormat.shortDebugString(segment) +\n            \": no current segment in place ; journal id: \" + journalId);\n        \n        // Update the highest txid for lag metrics\n        updateHighestWrittenTxId(Math.max(segment.getEndTxId(),\n            highestWrittenTxId));\n      } else {\n        LOG.info(\"Synchronizing log \" + TextFormat.shortDebugString(segment) +\n            \": old segment \" + TextFormat.shortDebugString(currentSegment) +\n            \" is not the right length ; journal id: \" + journalId);\n        \n        // Paranoid sanity check: if the new log is shorter than the log we\n        // currently have, we should not end up discarding any transactions\n        // which are already Committed.\n        if (txnRange(currentSegment).containsLong(committedTxnId.get()) \u0026\u0026\n            !txnRange(segment).containsLong(committedTxnId.get())) {\n          throw new AssertionError(\n              \"Cannot replace segment \" +\n              TextFormat.shortDebugString(currentSegment) +\n              \" with new segment \" +\n              TextFormat.shortDebugString(segment) + \n              \": would discard already-committed txn \" +\n              committedTxnId.get() +\n              \" ; journal id: \" + journalId);\n        }\n        \n        // Another paranoid check: we should not be asked to synchronize a log\n        // on top of a finalized segment.\n        alwaysAssert(currentSegment.getIsInProgress(),\n            \"Should never be asked to synchronize a different log on top of \" +\n            \"an already-finalized segment ; journal id: \" + journalId);\n        \n        // If we\u0027re shortening the log, update our highest txid\n        // used for lag metrics.\n        if (txnRange(currentSegment).containsLong(highestWrittenTxId)) {\n          updateHighestWrittenTxId(segment.getEndTxId());\n        }\n      }\n      syncedFile \u003d syncLog(reqInfo, segment, fromUrl);\n      \n    } else {\n      LOG.info(\"Skipping download of log \" +\n          TextFormat.shortDebugString(segment) +\n          \": already have up-to-date logs ; journal id: \" + journalId);\n    }\n    \n    // This is one of the few places in the protocol where we have a single\n    // RPC that results in two distinct actions:\n    //\n    // - 1) Downloads the new log segment data (above)\n    // - 2) Records the new Paxos data about the synchronized segment (below)\n    //\n    // These need to be treated as a transaction from the perspective\n    // of any external process. We do this by treating the persistPaxosData()\n    // success as the \"commit\" of an atomic transaction. If we fail before\n    // this point, the downloaded edit log will only exist at a temporary\n    // path, and thus not change any externally visible state. If we fail\n    // after this point, then any future prepareRecovery() call will see\n    // the Paxos data, and by calling completeHalfDoneAcceptRecovery() will\n    // roll forward the rename of the referenced log file.\n    //\n    // See also: HDFS-3955\n    //\n    // The fault points here are exercised by the randomized fault injection\n    // test case to ensure that this atomic \"transaction\" operates correctly.\n    JournalFaultInjector.get().beforePersistPaxosData();\n    persistPaxosData(segmentTxId, newData);\n    JournalFaultInjector.get().afterPersistPaxosData();\n\n    if (syncedFile !\u003d null) {\n      FileUtil.replaceFile(syncedFile,\n          storage.getInProgressEditLog(segmentTxId));\n    }\n\n    LOG.info(\"Accepted recovery for segment \" + segmentTxId + \": \" +\n        TextFormat.shortDebugString(newData) + \" ; journal id: \" + journalId);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java",
      "extendedDetails": {}
    },
    "53c38cc89ab979ec47557dcfa7affbad20578c0a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8964. When validating the edit log, do not read at or beyond the file offset that is being written (Zhe Zhang via Colin P. McCabe)\n",
      "commitDate": "03/09/15 11:22 AM",
      "commitName": "53c38cc89ab979ec47557dcfa7affbad20578c0a",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "02/05/15 10:03 AM",
      "commitNameOld": "6ae2a0d048e133b43249c248a75a4d77d9abb80d",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 124.06,
      "commitsBetweenForRepo": 888,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,114 +1,114 @@\n   public synchronized void acceptRecovery(RequestInfo reqInfo,\n       SegmentStateProto segment, URL fromUrl)\n       throws IOException {\n     checkFormatted();\n     checkRequest(reqInfo);\n     \n     abortCurSegment();\n \n     long segmentTxId \u003d segment.getStartTxId();\n \n     // Basic sanity checks that the segment is well-formed and contains\n     // at least one transaction.\n     Preconditions.checkArgument(segment.getEndTxId() \u003e 0 \u0026\u0026\n         segment.getEndTxId() \u003e\u003d segmentTxId,\n         \"bad recovery state for segment %s: %s\",\n         segmentTxId, TextFormat.shortDebugString(segment));\n     \n     PersistedRecoveryPaxosData oldData \u003d getPersistedPaxosData(segmentTxId);\n     PersistedRecoveryPaxosData newData \u003d PersistedRecoveryPaxosData.newBuilder()\n         .setAcceptedInEpoch(reqInfo.getEpoch())\n         .setSegmentState(segment)\n         .build();\n     \n     // If we previously acted on acceptRecovery() from a higher-numbered writer,\n     // this call is out of sync. We should never actually trigger this, since the\n     // checkRequest() call above should filter non-increasing epoch numbers.\n     if (oldData !\u003d null) {\n       alwaysAssert(oldData.getAcceptedInEpoch() \u003c\u003d reqInfo.getEpoch(),\n           \"Bad paxos transition, out-of-order epochs.\\nOld: %s\\nNew: %s\\n\",\n           oldData, newData);\n     }\n     \n     File syncedFile \u003d null;\n     \n     SegmentStateProto currentSegment \u003d getSegmentInfo(segmentTxId);\n     if (currentSegment \u003d\u003d null ||\n         currentSegment.getEndTxId() !\u003d segment.getEndTxId()) {\n       if (currentSegment \u003d\u003d null) {\n         LOG.info(\"Synchronizing log \" + TextFormat.shortDebugString(segment) +\n             \": no current segment in place\");\n         \n         // Update the highest txid for lag metrics\n-        highestWrittenTxId \u003d Math.max(segment.getEndTxId(),\n-            highestWrittenTxId);\n+        updateHighestWrittenTxId(Math.max(segment.getEndTxId(),\n+            highestWrittenTxId));\n       } else {\n         LOG.info(\"Synchronizing log \" + TextFormat.shortDebugString(segment) +\n             \": old segment \" + TextFormat.shortDebugString(currentSegment) +\n             \" is not the right length\");\n         \n         // Paranoid sanity check: if the new log is shorter than the log we\n         // currently have, we should not end up discarding any transactions\n         // which are already Committed.\n         if (txnRange(currentSegment).containsLong(committedTxnId.get()) \u0026\u0026\n             !txnRange(segment).containsLong(committedTxnId.get())) {\n           throw new AssertionError(\n               \"Cannot replace segment \" +\n               TextFormat.shortDebugString(currentSegment) +\n               \" with new segment \" +\n               TextFormat.shortDebugString(segment) + \n               \": would discard already-committed txn \" +\n               committedTxnId.get());\n         }\n         \n         // Another paranoid check: we should not be asked to synchronize a log\n         // on top of a finalized segment.\n         alwaysAssert(currentSegment.getIsInProgress(),\n             \"Should never be asked to synchronize a different log on top of an \" +\n             \"already-finalized segment\");\n         \n         // If we\u0027re shortening the log, update our highest txid\n         // used for lag metrics.\n         if (txnRange(currentSegment).containsLong(highestWrittenTxId)) {\n-          highestWrittenTxId \u003d segment.getEndTxId();\n+          updateHighestWrittenTxId(segment.getEndTxId());\n         }\n       }\n       syncedFile \u003d syncLog(reqInfo, segment, fromUrl);\n       \n     } else {\n       LOG.info(\"Skipping download of log \" +\n           TextFormat.shortDebugString(segment) +\n           \": already have up-to-date logs\");\n     }\n     \n     // This is one of the few places in the protocol where we have a single\n     // RPC that results in two distinct actions:\n     //\n     // - 1) Downloads the new log segment data (above)\n     // - 2) Records the new Paxos data about the synchronized segment (below)\n     //\n     // These need to be treated as a transaction from the perspective\n     // of any external process. We do this by treating the persistPaxosData()\n     // success as the \"commit\" of an atomic transaction. If we fail before\n     // this point, the downloaded edit log will only exist at a temporary\n     // path, and thus not change any externally visible state. If we fail\n     // after this point, then any future prepareRecovery() call will see\n     // the Paxos data, and by calling completeHalfDoneAcceptRecovery() will\n     // roll forward the rename of the referenced log file.\n     //\n     // See also: HDFS-3955\n     //\n     // The fault points here are exercised by the randomized fault injection\n     // test case to ensure that this atomic \"transaction\" operates correctly.\n     JournalFaultInjector.get().beforePersistPaxosData();\n     persistPaxosData(segmentTxId, newData);\n     JournalFaultInjector.get().afterPersistPaxosData();\n \n     if (syncedFile !\u003d null) {\n       FileUtil.replaceFile(syncedFile,\n           storage.getInProgressEditLog(segmentTxId));\n     }\n \n     LOG.info(\"Accepted recovery for segment \" + segmentTxId + \": \" +\n         TextFormat.shortDebugString(newData));\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void acceptRecovery(RequestInfo reqInfo,\n      SegmentStateProto segment, URL fromUrl)\n      throws IOException {\n    checkFormatted();\n    checkRequest(reqInfo);\n    \n    abortCurSegment();\n\n    long segmentTxId \u003d segment.getStartTxId();\n\n    // Basic sanity checks that the segment is well-formed and contains\n    // at least one transaction.\n    Preconditions.checkArgument(segment.getEndTxId() \u003e 0 \u0026\u0026\n        segment.getEndTxId() \u003e\u003d segmentTxId,\n        \"bad recovery state for segment %s: %s\",\n        segmentTxId, TextFormat.shortDebugString(segment));\n    \n    PersistedRecoveryPaxosData oldData \u003d getPersistedPaxosData(segmentTxId);\n    PersistedRecoveryPaxosData newData \u003d PersistedRecoveryPaxosData.newBuilder()\n        .setAcceptedInEpoch(reqInfo.getEpoch())\n        .setSegmentState(segment)\n        .build();\n    \n    // If we previously acted on acceptRecovery() from a higher-numbered writer,\n    // this call is out of sync. We should never actually trigger this, since the\n    // checkRequest() call above should filter non-increasing epoch numbers.\n    if (oldData !\u003d null) {\n      alwaysAssert(oldData.getAcceptedInEpoch() \u003c\u003d reqInfo.getEpoch(),\n          \"Bad paxos transition, out-of-order epochs.\\nOld: %s\\nNew: %s\\n\",\n          oldData, newData);\n    }\n    \n    File syncedFile \u003d null;\n    \n    SegmentStateProto currentSegment \u003d getSegmentInfo(segmentTxId);\n    if (currentSegment \u003d\u003d null ||\n        currentSegment.getEndTxId() !\u003d segment.getEndTxId()) {\n      if (currentSegment \u003d\u003d null) {\n        LOG.info(\"Synchronizing log \" + TextFormat.shortDebugString(segment) +\n            \": no current segment in place\");\n        \n        // Update the highest txid for lag metrics\n        updateHighestWrittenTxId(Math.max(segment.getEndTxId(),\n            highestWrittenTxId));\n      } else {\n        LOG.info(\"Synchronizing log \" + TextFormat.shortDebugString(segment) +\n            \": old segment \" + TextFormat.shortDebugString(currentSegment) +\n            \" is not the right length\");\n        \n        // Paranoid sanity check: if the new log is shorter than the log we\n        // currently have, we should not end up discarding any transactions\n        // which are already Committed.\n        if (txnRange(currentSegment).containsLong(committedTxnId.get()) \u0026\u0026\n            !txnRange(segment).containsLong(committedTxnId.get())) {\n          throw new AssertionError(\n              \"Cannot replace segment \" +\n              TextFormat.shortDebugString(currentSegment) +\n              \" with new segment \" +\n              TextFormat.shortDebugString(segment) + \n              \": would discard already-committed txn \" +\n              committedTxnId.get());\n        }\n        \n        // Another paranoid check: we should not be asked to synchronize a log\n        // on top of a finalized segment.\n        alwaysAssert(currentSegment.getIsInProgress(),\n            \"Should never be asked to synchronize a different log on top of an \" +\n            \"already-finalized segment\");\n        \n        // If we\u0027re shortening the log, update our highest txid\n        // used for lag metrics.\n        if (txnRange(currentSegment).containsLong(highestWrittenTxId)) {\n          updateHighestWrittenTxId(segment.getEndTxId());\n        }\n      }\n      syncedFile \u003d syncLog(reqInfo, segment, fromUrl);\n      \n    } else {\n      LOG.info(\"Skipping download of log \" +\n          TextFormat.shortDebugString(segment) +\n          \": already have up-to-date logs\");\n    }\n    \n    // This is one of the few places in the protocol where we have a single\n    // RPC that results in two distinct actions:\n    //\n    // - 1) Downloads the new log segment data (above)\n    // - 2) Records the new Paxos data about the synchronized segment (below)\n    //\n    // These need to be treated as a transaction from the perspective\n    // of any external process. We do this by treating the persistPaxosData()\n    // success as the \"commit\" of an atomic transaction. If we fail before\n    // this point, the downloaded edit log will only exist at a temporary\n    // path, and thus not change any externally visible state. If we fail\n    // after this point, then any future prepareRecovery() call will see\n    // the Paxos data, and by calling completeHalfDoneAcceptRecovery() will\n    // roll forward the rename of the referenced log file.\n    //\n    // See also: HDFS-3955\n    //\n    // The fault points here are exercised by the randomized fault injection\n    // test case to ensure that this atomic \"transaction\" operates correctly.\n    JournalFaultInjector.get().beforePersistPaxosData();\n    persistPaxosData(segmentTxId, newData);\n    JournalFaultInjector.get().afterPersistPaxosData();\n\n    if (syncedFile !\u003d null) {\n      FileUtil.replaceFile(syncedFile,\n          storage.getInProgressEditLog(segmentTxId));\n    }\n\n    LOG.info(\"Accepted recovery for segment \" + segmentTxId + \": \" +\n        TextFormat.shortDebugString(newData));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java",
      "extendedDetails": {}
    },
    "ae91b13a4b1896b893268253104f935c3078d345": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-11470. Remove some uses of obsolete guava APIs from the hadoop codebase (Sangjin Lee via Colin P. McCabe)\n",
      "commitDate": "08/01/15 4:09 PM",
      "commitName": "ae91b13a4b1896b893268253104f935c3078d345",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "07/01/15 9:51 PM",
      "commitNameOld": "a6ed4894b518351bf1b3290e725a475570a21296",
      "commitAuthorOld": "Tsuyoshi Ozawa",
      "daysBetweenCommits": 0.76,
      "commitsBetweenForRepo": 6,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,114 +1,114 @@\n   public synchronized void acceptRecovery(RequestInfo reqInfo,\n       SegmentStateProto segment, URL fromUrl)\n       throws IOException {\n     checkFormatted();\n     checkRequest(reqInfo);\n     \n     abortCurSegment();\n \n     long segmentTxId \u003d segment.getStartTxId();\n \n     // Basic sanity checks that the segment is well-formed and contains\n     // at least one transaction.\n     Preconditions.checkArgument(segment.getEndTxId() \u003e 0 \u0026\u0026\n         segment.getEndTxId() \u003e\u003d segmentTxId,\n         \"bad recovery state for segment %s: %s\",\n         segmentTxId, TextFormat.shortDebugString(segment));\n     \n     PersistedRecoveryPaxosData oldData \u003d getPersistedPaxosData(segmentTxId);\n     PersistedRecoveryPaxosData newData \u003d PersistedRecoveryPaxosData.newBuilder()\n         .setAcceptedInEpoch(reqInfo.getEpoch())\n         .setSegmentState(segment)\n         .build();\n     \n     // If we previously acted on acceptRecovery() from a higher-numbered writer,\n     // this call is out of sync. We should never actually trigger this, since the\n     // checkRequest() call above should filter non-increasing epoch numbers.\n     if (oldData !\u003d null) {\n       alwaysAssert(oldData.getAcceptedInEpoch() \u003c\u003d reqInfo.getEpoch(),\n           \"Bad paxos transition, out-of-order epochs.\\nOld: %s\\nNew: %s\\n\",\n           oldData, newData);\n     }\n     \n     File syncedFile \u003d null;\n     \n     SegmentStateProto currentSegment \u003d getSegmentInfo(segmentTxId);\n     if (currentSegment \u003d\u003d null ||\n         currentSegment.getEndTxId() !\u003d segment.getEndTxId()) {\n       if (currentSegment \u003d\u003d null) {\n         LOG.info(\"Synchronizing log \" + TextFormat.shortDebugString(segment) +\n             \": no current segment in place\");\n         \n         // Update the highest txid for lag metrics\n         highestWrittenTxId \u003d Math.max(segment.getEndTxId(),\n             highestWrittenTxId);\n       } else {\n         LOG.info(\"Synchronizing log \" + TextFormat.shortDebugString(segment) +\n             \": old segment \" + TextFormat.shortDebugString(currentSegment) +\n             \" is not the right length\");\n         \n         // Paranoid sanity check: if the new log is shorter than the log we\n         // currently have, we should not end up discarding any transactions\n         // which are already Committed.\n-        if (txnRange(currentSegment).contains(committedTxnId.get()) \u0026\u0026\n-            !txnRange(segment).contains(committedTxnId.get())) {\n+        if (txnRange(currentSegment).containsLong(committedTxnId.get()) \u0026\u0026\n+            !txnRange(segment).containsLong(committedTxnId.get())) {\n           throw new AssertionError(\n               \"Cannot replace segment \" +\n               TextFormat.shortDebugString(currentSegment) +\n               \" with new segment \" +\n               TextFormat.shortDebugString(segment) + \n               \": would discard already-committed txn \" +\n               committedTxnId.get());\n         }\n         \n         // Another paranoid check: we should not be asked to synchronize a log\n         // on top of a finalized segment.\n         alwaysAssert(currentSegment.getIsInProgress(),\n             \"Should never be asked to synchronize a different log on top of an \" +\n             \"already-finalized segment\");\n         \n         // If we\u0027re shortening the log, update our highest txid\n         // used for lag metrics.\n-        if (txnRange(currentSegment).contains(highestWrittenTxId)) {\n+        if (txnRange(currentSegment).containsLong(highestWrittenTxId)) {\n           highestWrittenTxId \u003d segment.getEndTxId();\n         }\n       }\n       syncedFile \u003d syncLog(reqInfo, segment, fromUrl);\n       \n     } else {\n       LOG.info(\"Skipping download of log \" +\n           TextFormat.shortDebugString(segment) +\n           \": already have up-to-date logs\");\n     }\n     \n     // This is one of the few places in the protocol where we have a single\n     // RPC that results in two distinct actions:\n     //\n     // - 1) Downloads the new log segment data (above)\n     // - 2) Records the new Paxos data about the synchronized segment (below)\n     //\n     // These need to be treated as a transaction from the perspective\n     // of any external process. We do this by treating the persistPaxosData()\n     // success as the \"commit\" of an atomic transaction. If we fail before\n     // this point, the downloaded edit log will only exist at a temporary\n     // path, and thus not change any externally visible state. If we fail\n     // after this point, then any future prepareRecovery() call will see\n     // the Paxos data, and by calling completeHalfDoneAcceptRecovery() will\n     // roll forward the rename of the referenced log file.\n     //\n     // See also: HDFS-3955\n     //\n     // The fault points here are exercised by the randomized fault injection\n     // test case to ensure that this atomic \"transaction\" operates correctly.\n     JournalFaultInjector.get().beforePersistPaxosData();\n     persistPaxosData(segmentTxId, newData);\n     JournalFaultInjector.get().afterPersistPaxosData();\n \n     if (syncedFile !\u003d null) {\n       FileUtil.replaceFile(syncedFile,\n           storage.getInProgressEditLog(segmentTxId));\n     }\n \n     LOG.info(\"Accepted recovery for segment \" + segmentTxId + \": \" +\n         TextFormat.shortDebugString(newData));\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void acceptRecovery(RequestInfo reqInfo,\n      SegmentStateProto segment, URL fromUrl)\n      throws IOException {\n    checkFormatted();\n    checkRequest(reqInfo);\n    \n    abortCurSegment();\n\n    long segmentTxId \u003d segment.getStartTxId();\n\n    // Basic sanity checks that the segment is well-formed and contains\n    // at least one transaction.\n    Preconditions.checkArgument(segment.getEndTxId() \u003e 0 \u0026\u0026\n        segment.getEndTxId() \u003e\u003d segmentTxId,\n        \"bad recovery state for segment %s: %s\",\n        segmentTxId, TextFormat.shortDebugString(segment));\n    \n    PersistedRecoveryPaxosData oldData \u003d getPersistedPaxosData(segmentTxId);\n    PersistedRecoveryPaxosData newData \u003d PersistedRecoveryPaxosData.newBuilder()\n        .setAcceptedInEpoch(reqInfo.getEpoch())\n        .setSegmentState(segment)\n        .build();\n    \n    // If we previously acted on acceptRecovery() from a higher-numbered writer,\n    // this call is out of sync. We should never actually trigger this, since the\n    // checkRequest() call above should filter non-increasing epoch numbers.\n    if (oldData !\u003d null) {\n      alwaysAssert(oldData.getAcceptedInEpoch() \u003c\u003d reqInfo.getEpoch(),\n          \"Bad paxos transition, out-of-order epochs.\\nOld: %s\\nNew: %s\\n\",\n          oldData, newData);\n    }\n    \n    File syncedFile \u003d null;\n    \n    SegmentStateProto currentSegment \u003d getSegmentInfo(segmentTxId);\n    if (currentSegment \u003d\u003d null ||\n        currentSegment.getEndTxId() !\u003d segment.getEndTxId()) {\n      if (currentSegment \u003d\u003d null) {\n        LOG.info(\"Synchronizing log \" + TextFormat.shortDebugString(segment) +\n            \": no current segment in place\");\n        \n        // Update the highest txid for lag metrics\n        highestWrittenTxId \u003d Math.max(segment.getEndTxId(),\n            highestWrittenTxId);\n      } else {\n        LOG.info(\"Synchronizing log \" + TextFormat.shortDebugString(segment) +\n            \": old segment \" + TextFormat.shortDebugString(currentSegment) +\n            \" is not the right length\");\n        \n        // Paranoid sanity check: if the new log is shorter than the log we\n        // currently have, we should not end up discarding any transactions\n        // which are already Committed.\n        if (txnRange(currentSegment).containsLong(committedTxnId.get()) \u0026\u0026\n            !txnRange(segment).containsLong(committedTxnId.get())) {\n          throw new AssertionError(\n              \"Cannot replace segment \" +\n              TextFormat.shortDebugString(currentSegment) +\n              \" with new segment \" +\n              TextFormat.shortDebugString(segment) + \n              \": would discard already-committed txn \" +\n              committedTxnId.get());\n        }\n        \n        // Another paranoid check: we should not be asked to synchronize a log\n        // on top of a finalized segment.\n        alwaysAssert(currentSegment.getIsInProgress(),\n            \"Should never be asked to synchronize a different log on top of an \" +\n            \"already-finalized segment\");\n        \n        // If we\u0027re shortening the log, update our highest txid\n        // used for lag metrics.\n        if (txnRange(currentSegment).containsLong(highestWrittenTxId)) {\n          highestWrittenTxId \u003d segment.getEndTxId();\n        }\n      }\n      syncedFile \u003d syncLog(reqInfo, segment, fromUrl);\n      \n    } else {\n      LOG.info(\"Skipping download of log \" +\n          TextFormat.shortDebugString(segment) +\n          \": already have up-to-date logs\");\n    }\n    \n    // This is one of the few places in the protocol where we have a single\n    // RPC that results in two distinct actions:\n    //\n    // - 1) Downloads the new log segment data (above)\n    // - 2) Records the new Paxos data about the synchronized segment (below)\n    //\n    // These need to be treated as a transaction from the perspective\n    // of any external process. We do this by treating the persistPaxosData()\n    // success as the \"commit\" of an atomic transaction. If we fail before\n    // this point, the downloaded edit log will only exist at a temporary\n    // path, and thus not change any externally visible state. If we fail\n    // after this point, then any future prepareRecovery() call will see\n    // the Paxos data, and by calling completeHalfDoneAcceptRecovery() will\n    // roll forward the rename of the referenced log file.\n    //\n    // See also: HDFS-3955\n    //\n    // The fault points here are exercised by the randomized fault injection\n    // test case to ensure that this atomic \"transaction\" operates correctly.\n    JournalFaultInjector.get().beforePersistPaxosData();\n    persistPaxosData(segmentTxId, newData);\n    JournalFaultInjector.get().afterPersistPaxosData();\n\n    if (syncedFile !\u003d null) {\n      FileUtil.replaceFile(syncedFile,\n          storage.getInProgressEditLog(segmentTxId));\n    }\n\n    LOG.info(\"Accepted recovery for segment \" + segmentTxId + \": \" +\n        TextFormat.shortDebugString(newData));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java",
      "extendedDetails": {}
    },
    "3ccd905d8a0fe5e3a206ac955b689a6f02b25e67": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3955. QJM: Make acceptRecovery() atomic. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1387706 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/09/12 11:57 AM",
      "commitName": "3ccd905d8a0fe5e3a206ac955b689a6f02b25e67",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "19/09/12 11:52 AM",
      "commitNameOld": "663e7484c04c197eed53f10a7808140f1c955277",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,88 +1,114 @@\n   public synchronized void acceptRecovery(RequestInfo reqInfo,\n       SegmentStateProto segment, URL fromUrl)\n       throws IOException {\n     checkFormatted();\n     checkRequest(reqInfo);\n     \n     abortCurSegment();\n \n     long segmentTxId \u003d segment.getStartTxId();\n \n     // Basic sanity checks that the segment is well-formed and contains\n     // at least one transaction.\n     Preconditions.checkArgument(segment.getEndTxId() \u003e 0 \u0026\u0026\n         segment.getEndTxId() \u003e\u003d segmentTxId,\n         \"bad recovery state for segment %s: %s\",\n         segmentTxId, TextFormat.shortDebugString(segment));\n     \n     PersistedRecoveryPaxosData oldData \u003d getPersistedPaxosData(segmentTxId);\n     PersistedRecoveryPaxosData newData \u003d PersistedRecoveryPaxosData.newBuilder()\n         .setAcceptedInEpoch(reqInfo.getEpoch())\n         .setSegmentState(segment)\n         .build();\n     \n     // If we previously acted on acceptRecovery() from a higher-numbered writer,\n     // this call is out of sync. We should never actually trigger this, since the\n     // checkRequest() call above should filter non-increasing epoch numbers.\n     if (oldData !\u003d null) {\n       alwaysAssert(oldData.getAcceptedInEpoch() \u003c\u003d reqInfo.getEpoch(),\n           \"Bad paxos transition, out-of-order epochs.\\nOld: %s\\nNew: %s\\n\",\n           oldData, newData);\n     }\n-\n+    \n+    File syncedFile \u003d null;\n+    \n     SegmentStateProto currentSegment \u003d getSegmentInfo(segmentTxId);\n     if (currentSegment \u003d\u003d null ||\n         currentSegment.getEndTxId() !\u003d segment.getEndTxId()) {\n       if (currentSegment \u003d\u003d null) {\n         LOG.info(\"Synchronizing log \" + TextFormat.shortDebugString(segment) +\n             \": no current segment in place\");\n         \n         // Update the highest txid for lag metrics\n         highestWrittenTxId \u003d Math.max(segment.getEndTxId(),\n             highestWrittenTxId);\n       } else {\n         LOG.info(\"Synchronizing log \" + TextFormat.shortDebugString(segment) +\n             \": old segment \" + TextFormat.shortDebugString(currentSegment) +\n             \" is not the right length\");\n         \n         // Paranoid sanity check: if the new log is shorter than the log we\n         // currently have, we should not end up discarding any transactions\n         // which are already Committed.\n         if (txnRange(currentSegment).contains(committedTxnId.get()) \u0026\u0026\n             !txnRange(segment).contains(committedTxnId.get())) {\n           throw new AssertionError(\n               \"Cannot replace segment \" +\n               TextFormat.shortDebugString(currentSegment) +\n               \" with new segment \" +\n               TextFormat.shortDebugString(segment) + \n               \": would discard already-committed txn \" +\n               committedTxnId.get());\n         }\n         \n         // Another paranoid check: we should not be asked to synchronize a log\n         // on top of a finalized segment.\n         alwaysAssert(currentSegment.getIsInProgress(),\n             \"Should never be asked to synchronize a different log on top of an \" +\n             \"already-finalized segment\");\n         \n         // If we\u0027re shortening the log, update our highest txid\n         // used for lag metrics.\n         if (txnRange(currentSegment).contains(highestWrittenTxId)) {\n           highestWrittenTxId \u003d segment.getEndTxId();\n         }\n       }\n-      syncLog(reqInfo, segment, fromUrl);\n+      syncedFile \u003d syncLog(reqInfo, segment, fromUrl);\n       \n     } else {\n       LOG.info(\"Skipping download of log \" +\n           TextFormat.shortDebugString(segment) +\n           \": already have up-to-date logs\");\n     }\n     \n-    // TODO: is it OK that this is non-atomic?\n-    // we might be left with an older epoch recorded, but a newer log\n-    \n+    // This is one of the few places in the protocol where we have a single\n+    // RPC that results in two distinct actions:\n+    //\n+    // - 1) Downloads the new log segment data (above)\n+    // - 2) Records the new Paxos data about the synchronized segment (below)\n+    //\n+    // These need to be treated as a transaction from the perspective\n+    // of any external process. We do this by treating the persistPaxosData()\n+    // success as the \"commit\" of an atomic transaction. If we fail before\n+    // this point, the downloaded edit log will only exist at a temporary\n+    // path, and thus not change any externally visible state. If we fail\n+    // after this point, then any future prepareRecovery() call will see\n+    // the Paxos data, and by calling completeHalfDoneAcceptRecovery() will\n+    // roll forward the rename of the referenced log file.\n+    //\n+    // See also: HDFS-3955\n+    //\n+    // The fault points here are exercised by the randomized fault injection\n+    // test case to ensure that this atomic \"transaction\" operates correctly.\n+    JournalFaultInjector.get().beforePersistPaxosData();\n     persistPaxosData(segmentTxId, newData);\n+    JournalFaultInjector.get().afterPersistPaxosData();\n+\n+    if (syncedFile !\u003d null) {\n+      FileUtil.replaceFile(syncedFile,\n+          storage.getInProgressEditLog(segmentTxId));\n+    }\n+\n     LOG.info(\"Accepted recovery for segment \" + segmentTxId + \": \" +\n         TextFormat.shortDebugString(newData));\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void acceptRecovery(RequestInfo reqInfo,\n      SegmentStateProto segment, URL fromUrl)\n      throws IOException {\n    checkFormatted();\n    checkRequest(reqInfo);\n    \n    abortCurSegment();\n\n    long segmentTxId \u003d segment.getStartTxId();\n\n    // Basic sanity checks that the segment is well-formed and contains\n    // at least one transaction.\n    Preconditions.checkArgument(segment.getEndTxId() \u003e 0 \u0026\u0026\n        segment.getEndTxId() \u003e\u003d segmentTxId,\n        \"bad recovery state for segment %s: %s\",\n        segmentTxId, TextFormat.shortDebugString(segment));\n    \n    PersistedRecoveryPaxosData oldData \u003d getPersistedPaxosData(segmentTxId);\n    PersistedRecoveryPaxosData newData \u003d PersistedRecoveryPaxosData.newBuilder()\n        .setAcceptedInEpoch(reqInfo.getEpoch())\n        .setSegmentState(segment)\n        .build();\n    \n    // If we previously acted on acceptRecovery() from a higher-numbered writer,\n    // this call is out of sync. We should never actually trigger this, since the\n    // checkRequest() call above should filter non-increasing epoch numbers.\n    if (oldData !\u003d null) {\n      alwaysAssert(oldData.getAcceptedInEpoch() \u003c\u003d reqInfo.getEpoch(),\n          \"Bad paxos transition, out-of-order epochs.\\nOld: %s\\nNew: %s\\n\",\n          oldData, newData);\n    }\n    \n    File syncedFile \u003d null;\n    \n    SegmentStateProto currentSegment \u003d getSegmentInfo(segmentTxId);\n    if (currentSegment \u003d\u003d null ||\n        currentSegment.getEndTxId() !\u003d segment.getEndTxId()) {\n      if (currentSegment \u003d\u003d null) {\n        LOG.info(\"Synchronizing log \" + TextFormat.shortDebugString(segment) +\n            \": no current segment in place\");\n        \n        // Update the highest txid for lag metrics\n        highestWrittenTxId \u003d Math.max(segment.getEndTxId(),\n            highestWrittenTxId);\n      } else {\n        LOG.info(\"Synchronizing log \" + TextFormat.shortDebugString(segment) +\n            \": old segment \" + TextFormat.shortDebugString(currentSegment) +\n            \" is not the right length\");\n        \n        // Paranoid sanity check: if the new log is shorter than the log we\n        // currently have, we should not end up discarding any transactions\n        // which are already Committed.\n        if (txnRange(currentSegment).contains(committedTxnId.get()) \u0026\u0026\n            !txnRange(segment).contains(committedTxnId.get())) {\n          throw new AssertionError(\n              \"Cannot replace segment \" +\n              TextFormat.shortDebugString(currentSegment) +\n              \" with new segment \" +\n              TextFormat.shortDebugString(segment) + \n              \": would discard already-committed txn \" +\n              committedTxnId.get());\n        }\n        \n        // Another paranoid check: we should not be asked to synchronize a log\n        // on top of a finalized segment.\n        alwaysAssert(currentSegment.getIsInProgress(),\n            \"Should never be asked to synchronize a different log on top of an \" +\n            \"already-finalized segment\");\n        \n        // If we\u0027re shortening the log, update our highest txid\n        // used for lag metrics.\n        if (txnRange(currentSegment).contains(highestWrittenTxId)) {\n          highestWrittenTxId \u003d segment.getEndTxId();\n        }\n      }\n      syncedFile \u003d syncLog(reqInfo, segment, fromUrl);\n      \n    } else {\n      LOG.info(\"Skipping download of log \" +\n          TextFormat.shortDebugString(segment) +\n          \": already have up-to-date logs\");\n    }\n    \n    // This is one of the few places in the protocol where we have a single\n    // RPC that results in two distinct actions:\n    //\n    // - 1) Downloads the new log segment data (above)\n    // - 2) Records the new Paxos data about the synchronized segment (below)\n    //\n    // These need to be treated as a transaction from the perspective\n    // of any external process. We do this by treating the persistPaxosData()\n    // success as the \"commit\" of an atomic transaction. If we fail before\n    // this point, the downloaded edit log will only exist at a temporary\n    // path, and thus not change any externally visible state. If we fail\n    // after this point, then any future prepareRecovery() call will see\n    // the Paxos data, and by calling completeHalfDoneAcceptRecovery() will\n    // roll forward the rename of the referenced log file.\n    //\n    // See also: HDFS-3955\n    //\n    // The fault points here are exercised by the randomized fault injection\n    // test case to ensure that this atomic \"transaction\" operates correctly.\n    JournalFaultInjector.get().beforePersistPaxosData();\n    persistPaxosData(segmentTxId, newData);\n    JournalFaultInjector.get().afterPersistPaxosData();\n\n    if (syncedFile !\u003d null) {\n      FileUtil.replaceFile(syncedFile,\n          storage.getInProgressEditLog(segmentTxId));\n    }\n\n    LOG.info(\"Accepted recovery for segment \" + segmentTxId + \": \" +\n        TextFormat.shortDebugString(newData));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java",
      "extendedDetails": {}
    },
    "663e7484c04c197eed53f10a7808140f1c955277": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3950. QJM: misc TODO cleanup, improved log messages, etc. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1387704 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/09/12 11:52 AM",
      "commitName": "663e7484c04c197eed53f10a7808140f1c955277",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "17/09/12 2:51 PM",
      "commitNameOld": "83c14fbd24353b5e882f065faec81e58449afed3",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 1.88,
      "commitsBetweenForRepo": 7,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,79 +1,88 @@\n   public synchronized void acceptRecovery(RequestInfo reqInfo,\n       SegmentStateProto segment, URL fromUrl)\n       throws IOException {\n     checkFormatted();\n     checkRequest(reqInfo);\n     \n     abortCurSegment();\n \n     long segmentTxId \u003d segment.getStartTxId();\n \n-    // TODO: right now, a recovery of a segment when the log is\n-    // completely emtpy (ie startLogSegment() but no txns)\n-    // will fail this assertion here, since endTxId \u003c startTxId\n+    // Basic sanity checks that the segment is well-formed and contains\n+    // at least one transaction.\n     Preconditions.checkArgument(segment.getEndTxId() \u003e 0 \u0026\u0026\n         segment.getEndTxId() \u003e\u003d segmentTxId,\n         \"bad recovery state for segment %s: %s\",\n         segmentTxId, TextFormat.shortDebugString(segment));\n     \n     PersistedRecoveryPaxosData oldData \u003d getPersistedPaxosData(segmentTxId);\n     PersistedRecoveryPaxosData newData \u003d PersistedRecoveryPaxosData.newBuilder()\n         .setAcceptedInEpoch(reqInfo.getEpoch())\n         .setSegmentState(segment)\n         .build();\n+    \n+    // If we previously acted on acceptRecovery() from a higher-numbered writer,\n+    // this call is out of sync. We should never actually trigger this, since the\n+    // checkRequest() call above should filter non-increasing epoch numbers.\n     if (oldData !\u003d null) {\n-      Preconditions.checkState(oldData.getAcceptedInEpoch() \u003c\u003d reqInfo.getEpoch(),\n+      alwaysAssert(oldData.getAcceptedInEpoch() \u003c\u003d reqInfo.getEpoch(),\n           \"Bad paxos transition, out-of-order epochs.\\nOld: %s\\nNew: %s\\n\",\n           oldData, newData);\n     }\n \n     SegmentStateProto currentSegment \u003d getSegmentInfo(segmentTxId);\n     if (currentSegment \u003d\u003d null ||\n         currentSegment.getEndTxId() !\u003d segment.getEndTxId()) {\n       if (currentSegment \u003d\u003d null) {\n         LOG.info(\"Synchronizing log \" + TextFormat.shortDebugString(segment) +\n             \": no current segment in place\");\n         \n         // Update the highest txid for lag metrics\n         highestWrittenTxId \u003d Math.max(segment.getEndTxId(),\n             highestWrittenTxId);\n       } else {\n         LOG.info(\"Synchronizing log \" + TextFormat.shortDebugString(segment) +\n             \": old segment \" + TextFormat.shortDebugString(currentSegment) +\n             \" is not the right length\");\n         \n         // Paranoid sanity check: if the new log is shorter than the log we\n         // currently have, we should not end up discarding any transactions\n         // which are already Committed.\n         if (txnRange(currentSegment).contains(committedTxnId.get()) \u0026\u0026\n             !txnRange(segment).contains(committedTxnId.get())) {\n           throw new AssertionError(\n               \"Cannot replace segment \" +\n               TextFormat.shortDebugString(currentSegment) +\n               \" with new segment \" +\n               TextFormat.shortDebugString(segment) + \n               \": would discard already-committed txn \" +\n               committedTxnId.get());\n         }\n         \n+        // Another paranoid check: we should not be asked to synchronize a log\n+        // on top of a finalized segment.\n+        alwaysAssert(currentSegment.getIsInProgress(),\n+            \"Should never be asked to synchronize a different log on top of an \" +\n+            \"already-finalized segment\");\n+        \n         // If we\u0027re shortening the log, update our highest txid\n         // used for lag metrics.\n         if (txnRange(currentSegment).contains(highestWrittenTxId)) {\n           highestWrittenTxId \u003d segment.getEndTxId();\n         }\n       }\n       syncLog(reqInfo, segment, fromUrl);\n       \n     } else {\n       LOG.info(\"Skipping download of log \" +\n           TextFormat.shortDebugString(segment) +\n           \": already have up-to-date logs\");\n     }\n     \n     // TODO: is it OK that this is non-atomic?\n     // we might be left with an older epoch recorded, but a newer log\n     \n     persistPaxosData(segmentTxId, newData);\n     LOG.info(\"Accepted recovery for segment \" + segmentTxId + \": \" +\n         TextFormat.shortDebugString(newData));\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void acceptRecovery(RequestInfo reqInfo,\n      SegmentStateProto segment, URL fromUrl)\n      throws IOException {\n    checkFormatted();\n    checkRequest(reqInfo);\n    \n    abortCurSegment();\n\n    long segmentTxId \u003d segment.getStartTxId();\n\n    // Basic sanity checks that the segment is well-formed and contains\n    // at least one transaction.\n    Preconditions.checkArgument(segment.getEndTxId() \u003e 0 \u0026\u0026\n        segment.getEndTxId() \u003e\u003d segmentTxId,\n        \"bad recovery state for segment %s: %s\",\n        segmentTxId, TextFormat.shortDebugString(segment));\n    \n    PersistedRecoveryPaxosData oldData \u003d getPersistedPaxosData(segmentTxId);\n    PersistedRecoveryPaxosData newData \u003d PersistedRecoveryPaxosData.newBuilder()\n        .setAcceptedInEpoch(reqInfo.getEpoch())\n        .setSegmentState(segment)\n        .build();\n    \n    // If we previously acted on acceptRecovery() from a higher-numbered writer,\n    // this call is out of sync. We should never actually trigger this, since the\n    // checkRequest() call above should filter non-increasing epoch numbers.\n    if (oldData !\u003d null) {\n      alwaysAssert(oldData.getAcceptedInEpoch() \u003c\u003d reqInfo.getEpoch(),\n          \"Bad paxos transition, out-of-order epochs.\\nOld: %s\\nNew: %s\\n\",\n          oldData, newData);\n    }\n\n    SegmentStateProto currentSegment \u003d getSegmentInfo(segmentTxId);\n    if (currentSegment \u003d\u003d null ||\n        currentSegment.getEndTxId() !\u003d segment.getEndTxId()) {\n      if (currentSegment \u003d\u003d null) {\n        LOG.info(\"Synchronizing log \" + TextFormat.shortDebugString(segment) +\n            \": no current segment in place\");\n        \n        // Update the highest txid for lag metrics\n        highestWrittenTxId \u003d Math.max(segment.getEndTxId(),\n            highestWrittenTxId);\n      } else {\n        LOG.info(\"Synchronizing log \" + TextFormat.shortDebugString(segment) +\n            \": old segment \" + TextFormat.shortDebugString(currentSegment) +\n            \" is not the right length\");\n        \n        // Paranoid sanity check: if the new log is shorter than the log we\n        // currently have, we should not end up discarding any transactions\n        // which are already Committed.\n        if (txnRange(currentSegment).contains(committedTxnId.get()) \u0026\u0026\n            !txnRange(segment).contains(committedTxnId.get())) {\n          throw new AssertionError(\n              \"Cannot replace segment \" +\n              TextFormat.shortDebugString(currentSegment) +\n              \" with new segment \" +\n              TextFormat.shortDebugString(segment) + \n              \": would discard already-committed txn \" +\n              committedTxnId.get());\n        }\n        \n        // Another paranoid check: we should not be asked to synchronize a log\n        // on top of a finalized segment.\n        alwaysAssert(currentSegment.getIsInProgress(),\n            \"Should never be asked to synchronize a different log on top of an \" +\n            \"already-finalized segment\");\n        \n        // If we\u0027re shortening the log, update our highest txid\n        // used for lag metrics.\n        if (txnRange(currentSegment).contains(highestWrittenTxId)) {\n          highestWrittenTxId \u003d segment.getEndTxId();\n        }\n      }\n      syncLog(reqInfo, segment, fromUrl);\n      \n    } else {\n      LOG.info(\"Skipping download of log \" +\n          TextFormat.shortDebugString(segment) +\n          \": already have up-to-date logs\");\n    }\n    \n    // TODO: is it OK that this is non-atomic?\n    // we might be left with an older epoch recorded, but a newer log\n    \n    persistPaxosData(segmentTxId, newData);\n    LOG.info(\"Accepted recovery for segment \" + segmentTxId + \": \" +\n        TextFormat.shortDebugString(newData));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java",
      "extendedDetails": {}
    },
    "c5199cace63f11c3f46b4067032afad82ee4aef6": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3914. QJM: acceptRecovery should abort current segment. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1383148 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/09/12 4:20 PM",
      "commitName": "c5199cace63f11c3f46b4067032afad82ee4aef6",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "10/09/12 3:30 PM",
      "commitNameOld": "959afc0fd3bdd4fa366fbec97ffa6b96d4528e53",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 0.03,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,76 +1,79 @@\n   public synchronized void acceptRecovery(RequestInfo reqInfo,\n       SegmentStateProto segment, URL fromUrl)\n       throws IOException {\n     checkFormatted();\n     checkRequest(reqInfo);\n+    \n+    abortCurSegment();\n+\n     long segmentTxId \u003d segment.getStartTxId();\n \n     // TODO: right now, a recovery of a segment when the log is\n     // completely emtpy (ie startLogSegment() but no txns)\n     // will fail this assertion here, since endTxId \u003c startTxId\n     Preconditions.checkArgument(segment.getEndTxId() \u003e 0 \u0026\u0026\n         segment.getEndTxId() \u003e\u003d segmentTxId,\n         \"bad recovery state for segment %s: %s\",\n         segmentTxId, TextFormat.shortDebugString(segment));\n     \n     PersistedRecoveryPaxosData oldData \u003d getPersistedPaxosData(segmentTxId);\n     PersistedRecoveryPaxosData newData \u003d PersistedRecoveryPaxosData.newBuilder()\n         .setAcceptedInEpoch(reqInfo.getEpoch())\n         .setSegmentState(segment)\n         .build();\n     if (oldData !\u003d null) {\n       Preconditions.checkState(oldData.getAcceptedInEpoch() \u003c\u003d reqInfo.getEpoch(),\n           \"Bad paxos transition, out-of-order epochs.\\nOld: %s\\nNew: %s\\n\",\n           oldData, newData);\n     }\n \n     SegmentStateProto currentSegment \u003d getSegmentInfo(segmentTxId);\n     if (currentSegment \u003d\u003d null ||\n         currentSegment.getEndTxId() !\u003d segment.getEndTxId()) {\n       if (currentSegment \u003d\u003d null) {\n         LOG.info(\"Synchronizing log \" + TextFormat.shortDebugString(segment) +\n             \": no current segment in place\");\n         \n         // Update the highest txid for lag metrics\n         highestWrittenTxId \u003d Math.max(segment.getEndTxId(),\n             highestWrittenTxId);\n       } else {\n         LOG.info(\"Synchronizing log \" + TextFormat.shortDebugString(segment) +\n             \": old segment \" + TextFormat.shortDebugString(currentSegment) +\n             \" is not the right length\");\n         \n         // Paranoid sanity check: if the new log is shorter than the log we\n         // currently have, we should not end up discarding any transactions\n         // which are already Committed.\n         if (txnRange(currentSegment).contains(committedTxnId.get()) \u0026\u0026\n             !txnRange(segment).contains(committedTxnId.get())) {\n           throw new AssertionError(\n               \"Cannot replace segment \" +\n               TextFormat.shortDebugString(currentSegment) +\n               \" with new segment \" +\n               TextFormat.shortDebugString(segment) + \n               \": would discard already-committed txn \" +\n               committedTxnId.get());\n         }\n         \n         // If we\u0027re shortening the log, update our highest txid\n         // used for lag metrics.\n         if (txnRange(currentSegment).contains(highestWrittenTxId)) {\n           highestWrittenTxId \u003d segment.getEndTxId();\n         }\n       }\n       syncLog(reqInfo, segment, fromUrl);\n       \n     } else {\n       LOG.info(\"Skipping download of log \" +\n           TextFormat.shortDebugString(segment) +\n           \": already have up-to-date logs\");\n     }\n     \n     // TODO: is it OK that this is non-atomic?\n     // we might be left with an older epoch recorded, but a newer log\n     \n     persistPaxosData(segmentTxId, newData);\n     LOG.info(\"Accepted recovery for segment \" + segmentTxId + \": \" +\n         TextFormat.shortDebugString(newData));\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void acceptRecovery(RequestInfo reqInfo,\n      SegmentStateProto segment, URL fromUrl)\n      throws IOException {\n    checkFormatted();\n    checkRequest(reqInfo);\n    \n    abortCurSegment();\n\n    long segmentTxId \u003d segment.getStartTxId();\n\n    // TODO: right now, a recovery of a segment when the log is\n    // completely emtpy (ie startLogSegment() but no txns)\n    // will fail this assertion here, since endTxId \u003c startTxId\n    Preconditions.checkArgument(segment.getEndTxId() \u003e 0 \u0026\u0026\n        segment.getEndTxId() \u003e\u003d segmentTxId,\n        \"bad recovery state for segment %s: %s\",\n        segmentTxId, TextFormat.shortDebugString(segment));\n    \n    PersistedRecoveryPaxosData oldData \u003d getPersistedPaxosData(segmentTxId);\n    PersistedRecoveryPaxosData newData \u003d PersistedRecoveryPaxosData.newBuilder()\n        .setAcceptedInEpoch(reqInfo.getEpoch())\n        .setSegmentState(segment)\n        .build();\n    if (oldData !\u003d null) {\n      Preconditions.checkState(oldData.getAcceptedInEpoch() \u003c\u003d reqInfo.getEpoch(),\n          \"Bad paxos transition, out-of-order epochs.\\nOld: %s\\nNew: %s\\n\",\n          oldData, newData);\n    }\n\n    SegmentStateProto currentSegment \u003d getSegmentInfo(segmentTxId);\n    if (currentSegment \u003d\u003d null ||\n        currentSegment.getEndTxId() !\u003d segment.getEndTxId()) {\n      if (currentSegment \u003d\u003d null) {\n        LOG.info(\"Synchronizing log \" + TextFormat.shortDebugString(segment) +\n            \": no current segment in place\");\n        \n        // Update the highest txid for lag metrics\n        highestWrittenTxId \u003d Math.max(segment.getEndTxId(),\n            highestWrittenTxId);\n      } else {\n        LOG.info(\"Synchronizing log \" + TextFormat.shortDebugString(segment) +\n            \": old segment \" + TextFormat.shortDebugString(currentSegment) +\n            \" is not the right length\");\n        \n        // Paranoid sanity check: if the new log is shorter than the log we\n        // currently have, we should not end up discarding any transactions\n        // which are already Committed.\n        if (txnRange(currentSegment).contains(committedTxnId.get()) \u0026\u0026\n            !txnRange(segment).contains(committedTxnId.get())) {\n          throw new AssertionError(\n              \"Cannot replace segment \" +\n              TextFormat.shortDebugString(currentSegment) +\n              \" with new segment \" +\n              TextFormat.shortDebugString(segment) + \n              \": would discard already-committed txn \" +\n              committedTxnId.get());\n        }\n        \n        // If we\u0027re shortening the log, update our highest txid\n        // used for lag metrics.\n        if (txnRange(currentSegment).contains(highestWrittenTxId)) {\n          highestWrittenTxId \u003d segment.getEndTxId();\n        }\n      }\n      syncLog(reqInfo, segment, fromUrl);\n      \n    } else {\n      LOG.info(\"Skipping download of log \" +\n          TextFormat.shortDebugString(segment) +\n          \": already have up-to-date logs\");\n    }\n    \n    // TODO: is it OK that this is non-atomic?\n    // we might be left with an older epoch recorded, but a newer log\n    \n    persistPaxosData(segmentTxId, newData);\n    LOG.info(\"Accepted recovery for segment \" + segmentTxId + \": \" +\n        TextFormat.shortDebugString(newData));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java",
      "extendedDetails": {}
    },
    "959afc0fd3bdd4fa366fbec97ffa6b96d4528e53": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3901. QJM: send \u0027heartbeat\u0027 messages to JNs even when they are out-of-sync. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1383137 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/09/12 3:30 PM",
      "commitName": "959afc0fd3bdd4fa366fbec97ffa6b96d4528e53",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "10/09/12 11:53 AM",
      "commitNameOld": "60c20e559b8036410e2d9081b9c60d1e04e56253",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 0.15,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,65 +1,76 @@\n   public synchronized void acceptRecovery(RequestInfo reqInfo,\n       SegmentStateProto segment, URL fromUrl)\n       throws IOException {\n     checkFormatted();\n     checkRequest(reqInfo);\n     long segmentTxId \u003d segment.getStartTxId();\n \n     // TODO: right now, a recovery of a segment when the log is\n     // completely emtpy (ie startLogSegment() but no txns)\n     // will fail this assertion here, since endTxId \u003c startTxId\n     Preconditions.checkArgument(segment.getEndTxId() \u003e 0 \u0026\u0026\n         segment.getEndTxId() \u003e\u003d segmentTxId,\n         \"bad recovery state for segment %s: %s\",\n         segmentTxId, TextFormat.shortDebugString(segment));\n     \n     PersistedRecoveryPaxosData oldData \u003d getPersistedPaxosData(segmentTxId);\n     PersistedRecoveryPaxosData newData \u003d PersistedRecoveryPaxosData.newBuilder()\n         .setAcceptedInEpoch(reqInfo.getEpoch())\n         .setSegmentState(segment)\n         .build();\n     if (oldData !\u003d null) {\n       Preconditions.checkState(oldData.getAcceptedInEpoch() \u003c\u003d reqInfo.getEpoch(),\n           \"Bad paxos transition, out-of-order epochs.\\nOld: %s\\nNew: %s\\n\",\n           oldData, newData);\n     }\n \n     SegmentStateProto currentSegment \u003d getSegmentInfo(segmentTxId);\n     if (currentSegment \u003d\u003d null ||\n         currentSegment.getEndTxId() !\u003d segment.getEndTxId()) {\n       if (currentSegment \u003d\u003d null) {\n         LOG.info(\"Synchronizing log \" + TextFormat.shortDebugString(segment) +\n             \": no current segment in place\");\n+        \n+        // Update the highest txid for lag metrics\n+        highestWrittenTxId \u003d Math.max(segment.getEndTxId(),\n+            highestWrittenTxId);\n       } else {\n         LOG.info(\"Synchronizing log \" + TextFormat.shortDebugString(segment) +\n             \": old segment \" + TextFormat.shortDebugString(currentSegment) +\n             \" is not the right length\");\n         \n         // Paranoid sanity check: if the new log is shorter than the log we\n         // currently have, we should not end up discarding any transactions\n         // which are already Committed.\n         if (txnRange(currentSegment).contains(committedTxnId.get()) \u0026\u0026\n             !txnRange(segment).contains(committedTxnId.get())) {\n           throw new AssertionError(\n               \"Cannot replace segment \" +\n               TextFormat.shortDebugString(currentSegment) +\n               \" with new segment \" +\n               TextFormat.shortDebugString(segment) + \n               \": would discard already-committed txn \" +\n               committedTxnId.get());\n         }\n+        \n+        // If we\u0027re shortening the log, update our highest txid\n+        // used for lag metrics.\n+        if (txnRange(currentSegment).contains(highestWrittenTxId)) {\n+          highestWrittenTxId \u003d segment.getEndTxId();\n+        }\n       }\n       syncLog(reqInfo, segment, fromUrl);\n+      \n     } else {\n       LOG.info(\"Skipping download of log \" +\n           TextFormat.shortDebugString(segment) +\n           \": already have up-to-date logs\");\n     }\n     \n     // TODO: is it OK that this is non-atomic?\n     // we might be left with an older epoch recorded, but a newer log\n     \n     persistPaxosData(segmentTxId, newData);\n     LOG.info(\"Accepted recovery for segment \" + segmentTxId + \": \" +\n         TextFormat.shortDebugString(newData));\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void acceptRecovery(RequestInfo reqInfo,\n      SegmentStateProto segment, URL fromUrl)\n      throws IOException {\n    checkFormatted();\n    checkRequest(reqInfo);\n    long segmentTxId \u003d segment.getStartTxId();\n\n    // TODO: right now, a recovery of a segment when the log is\n    // completely emtpy (ie startLogSegment() but no txns)\n    // will fail this assertion here, since endTxId \u003c startTxId\n    Preconditions.checkArgument(segment.getEndTxId() \u003e 0 \u0026\u0026\n        segment.getEndTxId() \u003e\u003d segmentTxId,\n        \"bad recovery state for segment %s: %s\",\n        segmentTxId, TextFormat.shortDebugString(segment));\n    \n    PersistedRecoveryPaxosData oldData \u003d getPersistedPaxosData(segmentTxId);\n    PersistedRecoveryPaxosData newData \u003d PersistedRecoveryPaxosData.newBuilder()\n        .setAcceptedInEpoch(reqInfo.getEpoch())\n        .setSegmentState(segment)\n        .build();\n    if (oldData !\u003d null) {\n      Preconditions.checkState(oldData.getAcceptedInEpoch() \u003c\u003d reqInfo.getEpoch(),\n          \"Bad paxos transition, out-of-order epochs.\\nOld: %s\\nNew: %s\\n\",\n          oldData, newData);\n    }\n\n    SegmentStateProto currentSegment \u003d getSegmentInfo(segmentTxId);\n    if (currentSegment \u003d\u003d null ||\n        currentSegment.getEndTxId() !\u003d segment.getEndTxId()) {\n      if (currentSegment \u003d\u003d null) {\n        LOG.info(\"Synchronizing log \" + TextFormat.shortDebugString(segment) +\n            \": no current segment in place\");\n        \n        // Update the highest txid for lag metrics\n        highestWrittenTxId \u003d Math.max(segment.getEndTxId(),\n            highestWrittenTxId);\n      } else {\n        LOG.info(\"Synchronizing log \" + TextFormat.shortDebugString(segment) +\n            \": old segment \" + TextFormat.shortDebugString(currentSegment) +\n            \" is not the right length\");\n        \n        // Paranoid sanity check: if the new log is shorter than the log we\n        // currently have, we should not end up discarding any transactions\n        // which are already Committed.\n        if (txnRange(currentSegment).contains(committedTxnId.get()) \u0026\u0026\n            !txnRange(segment).contains(committedTxnId.get())) {\n          throw new AssertionError(\n              \"Cannot replace segment \" +\n              TextFormat.shortDebugString(currentSegment) +\n              \" with new segment \" +\n              TextFormat.shortDebugString(segment) + \n              \": would discard already-committed txn \" +\n              committedTxnId.get());\n        }\n        \n        // If we\u0027re shortening the log, update our highest txid\n        // used for lag metrics.\n        if (txnRange(currentSegment).contains(highestWrittenTxId)) {\n          highestWrittenTxId \u003d segment.getEndTxId();\n        }\n      }\n      syncLog(reqInfo, segment, fromUrl);\n      \n    } else {\n      LOG.info(\"Skipping download of log \" +\n          TextFormat.shortDebugString(segment) +\n          \": already have up-to-date logs\");\n    }\n    \n    // TODO: is it OK that this is non-atomic?\n    // we might be left with an older epoch recorded, but a newer log\n    \n    persistPaxosData(segmentTxId, newData);\n    LOG.info(\"Accepted recovery for segment \" + segmentTxId + \": \" +\n        TextFormat.shortDebugString(newData));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java",
      "extendedDetails": {}
    },
    "8021d9199f278345aca6211f318145342ad036f4": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3863. Track last \"committed\" txid in QJM. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1380976 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/09/12 9:13 PM",
      "commitName": "8021d9199f278345aca6211f318145342ad036f4",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "27/08/12 12:55 PM",
      "commitNameOld": "1e68d4726b225fb4a62eb8d79a3160dd03059ccb",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 8.35,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,51 +1,65 @@\n   public synchronized void acceptRecovery(RequestInfo reqInfo,\n       SegmentStateProto segment, URL fromUrl)\n       throws IOException {\n-    checkRequest(reqInfo);\n     checkFormatted();\n+    checkRequest(reqInfo);\n     long segmentTxId \u003d segment.getStartTxId();\n \n     // TODO: right now, a recovery of a segment when the log is\n     // completely emtpy (ie startLogSegment() but no txns)\n     // will fail this assertion here, since endTxId \u003c startTxId\n     Preconditions.checkArgument(segment.getEndTxId() \u003e 0 \u0026\u0026\n         segment.getEndTxId() \u003e\u003d segmentTxId,\n         \"bad recovery state for segment %s: %s\",\n         segmentTxId, TextFormat.shortDebugString(segment));\n     \n     PersistedRecoveryPaxosData oldData \u003d getPersistedPaxosData(segmentTxId);\n     PersistedRecoveryPaxosData newData \u003d PersistedRecoveryPaxosData.newBuilder()\n         .setAcceptedInEpoch(reqInfo.getEpoch())\n         .setSegmentState(segment)\n         .build();\n     if (oldData !\u003d null) {\n       Preconditions.checkState(oldData.getAcceptedInEpoch() \u003c\u003d reqInfo.getEpoch(),\n           \"Bad paxos transition, out-of-order epochs.\\nOld: %s\\nNew: %s\\n\",\n           oldData, newData);\n     }\n \n     SegmentStateProto currentSegment \u003d getSegmentInfo(segmentTxId);\n     if (currentSegment \u003d\u003d null ||\n         currentSegment.getEndTxId() !\u003d segment.getEndTxId()) {\n       if (currentSegment \u003d\u003d null) {\n         LOG.info(\"Synchronizing log \" + TextFormat.shortDebugString(segment) +\n             \": no current segment in place\");\n       } else {\n         LOG.info(\"Synchronizing log \" + TextFormat.shortDebugString(segment) +\n-            \": old segment \" + TextFormat.shortDebugString(segment) + \" is \" +\n-            \"not the right length\");\n+            \": old segment \" + TextFormat.shortDebugString(currentSegment) +\n+            \" is not the right length\");\n+        \n+        // Paranoid sanity check: if the new log is shorter than the log we\n+        // currently have, we should not end up discarding any transactions\n+        // which are already Committed.\n+        if (txnRange(currentSegment).contains(committedTxnId.get()) \u0026\u0026\n+            !txnRange(segment).contains(committedTxnId.get())) {\n+          throw new AssertionError(\n+              \"Cannot replace segment \" +\n+              TextFormat.shortDebugString(currentSegment) +\n+              \" with new segment \" +\n+              TextFormat.shortDebugString(segment) + \n+              \": would discard already-committed txn \" +\n+              committedTxnId.get());\n+        }\n       }\n       syncLog(reqInfo, segment, fromUrl);\n     } else {\n       LOG.info(\"Skipping download of log \" +\n           TextFormat.shortDebugString(segment) +\n           \": already have up-to-date logs\");\n     }\n     \n     // TODO: is it OK that this is non-atomic?\n     // we might be left with an older epoch recorded, but a newer log\n     \n     persistPaxosData(segmentTxId, newData);\n     LOG.info(\"Accepted recovery for segment \" + segmentTxId + \": \" +\n         TextFormat.shortDebugString(newData));\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void acceptRecovery(RequestInfo reqInfo,\n      SegmentStateProto segment, URL fromUrl)\n      throws IOException {\n    checkFormatted();\n    checkRequest(reqInfo);\n    long segmentTxId \u003d segment.getStartTxId();\n\n    // TODO: right now, a recovery of a segment when the log is\n    // completely emtpy (ie startLogSegment() but no txns)\n    // will fail this assertion here, since endTxId \u003c startTxId\n    Preconditions.checkArgument(segment.getEndTxId() \u003e 0 \u0026\u0026\n        segment.getEndTxId() \u003e\u003d segmentTxId,\n        \"bad recovery state for segment %s: %s\",\n        segmentTxId, TextFormat.shortDebugString(segment));\n    \n    PersistedRecoveryPaxosData oldData \u003d getPersistedPaxosData(segmentTxId);\n    PersistedRecoveryPaxosData newData \u003d PersistedRecoveryPaxosData.newBuilder()\n        .setAcceptedInEpoch(reqInfo.getEpoch())\n        .setSegmentState(segment)\n        .build();\n    if (oldData !\u003d null) {\n      Preconditions.checkState(oldData.getAcceptedInEpoch() \u003c\u003d reqInfo.getEpoch(),\n          \"Bad paxos transition, out-of-order epochs.\\nOld: %s\\nNew: %s\\n\",\n          oldData, newData);\n    }\n\n    SegmentStateProto currentSegment \u003d getSegmentInfo(segmentTxId);\n    if (currentSegment \u003d\u003d null ||\n        currentSegment.getEndTxId() !\u003d segment.getEndTxId()) {\n      if (currentSegment \u003d\u003d null) {\n        LOG.info(\"Synchronizing log \" + TextFormat.shortDebugString(segment) +\n            \": no current segment in place\");\n      } else {\n        LOG.info(\"Synchronizing log \" + TextFormat.shortDebugString(segment) +\n            \": old segment \" + TextFormat.shortDebugString(currentSegment) +\n            \" is not the right length\");\n        \n        // Paranoid sanity check: if the new log is shorter than the log we\n        // currently have, we should not end up discarding any transactions\n        // which are already Committed.\n        if (txnRange(currentSegment).contains(committedTxnId.get()) \u0026\u0026\n            !txnRange(segment).contains(committedTxnId.get())) {\n          throw new AssertionError(\n              \"Cannot replace segment \" +\n              TextFormat.shortDebugString(currentSegment) +\n              \" with new segment \" +\n              TextFormat.shortDebugString(segment) + \n              \": would discard already-committed txn \" +\n              committedTxnId.get());\n        }\n      }\n      syncLog(reqInfo, segment, fromUrl);\n    } else {\n      LOG.info(\"Skipping download of log \" +\n          TextFormat.shortDebugString(segment) +\n          \": already have up-to-date logs\");\n    }\n    \n    // TODO: is it OK that this is non-atomic?\n    // we might be left with an older epoch recorded, but a newer log\n    \n    persistPaxosData(segmentTxId, newData);\n    LOG.info(\"Accepted recovery for segment \" + segmentTxId + \": \" +\n        TextFormat.shortDebugString(newData));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java",
      "extendedDetails": {}
    },
    "c95a1674b61ef2a6963dc64604986ef90a8c636d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3799. QJM: handle empty log segments during recovery. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1373183 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/08/12 5:57 PM",
      "commitName": "c95a1674b61ef2a6963dc64604986ef90a8c636d",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "14/08/12 5:54 PM",
      "commitNameOld": "4a9b3c693def87579298fb59b7df0b8892a3508e",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,48 +1,51 @@\n   public synchronized void acceptRecovery(RequestInfo reqInfo,\n       SegmentStateProto segment, URL fromUrl)\n       throws IOException {\n     checkRequest(reqInfo);\n     checkFormatted();\n     long segmentTxId \u003d segment.getStartTxId();\n \n     // TODO: right now, a recovery of a segment when the log is\n     // completely emtpy (ie startLogSegment() but no txns)\n     // will fail this assertion here, since endTxId \u003c startTxId\n     Preconditions.checkArgument(segment.getEndTxId() \u003e 0 \u0026\u0026\n         segment.getEndTxId() \u003e\u003d segmentTxId,\n         \"bad recovery state for segment %s: %s\",\n         segmentTxId, TextFormat.shortDebugString(segment));\n     \n     PersistedRecoveryPaxosData oldData \u003d getPersistedPaxosData(segmentTxId);\n     PersistedRecoveryPaxosData newData \u003d PersistedRecoveryPaxosData.newBuilder()\n         .setAcceptedInEpoch(reqInfo.getEpoch())\n         .setSegmentState(segment)\n         .build();\n     if (oldData !\u003d null) {\n       Preconditions.checkState(oldData.getAcceptedInEpoch() \u003c\u003d reqInfo.getEpoch(),\n           \"Bad paxos transition, out-of-order epochs.\\nOld: %s\\nNew: %s\\n\",\n           oldData, newData);\n     }\n \n     SegmentStateProto currentSegment \u003d getSegmentInfo(segmentTxId);\n-    // TODO: this can be null, in the case that one of the loggers started\n-    // the next segment, but others did not! add regression test and null\n-    // check in next condition below.\n-    \n-    // TODO: what if they have the same length but one is finalized and the\n-    // other isn\u0027t! cover that case.\n-    if (currentSegment.getEndTxId() !\u003d segment.getEndTxId()) {\n+    if (currentSegment \u003d\u003d null ||\n+        currentSegment.getEndTxId() !\u003d segment.getEndTxId()) {\n+      if (currentSegment \u003d\u003d null) {\n+        LOG.info(\"Synchronizing log \" + TextFormat.shortDebugString(segment) +\n+            \": no current segment in place\");\n+      } else {\n+        LOG.info(\"Synchronizing log \" + TextFormat.shortDebugString(segment) +\n+            \": old segment \" + TextFormat.shortDebugString(segment) + \" is \" +\n+            \"not the right length\");\n+      }\n       syncLog(reqInfo, segment, fromUrl);\n     } else {\n       LOG.info(\"Skipping download of log \" +\n           TextFormat.shortDebugString(segment) +\n           \": already have up-to-date logs\");\n     }\n     \n     // TODO: is it OK that this is non-atomic?\n     // we might be left with an older epoch recorded, but a newer log\n     \n     persistPaxosData(segmentTxId, newData);\n     LOG.info(\"Accepted recovery for segment \" + segmentTxId + \": \" +\n         TextFormat.shortDebugString(newData));\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void acceptRecovery(RequestInfo reqInfo,\n      SegmentStateProto segment, URL fromUrl)\n      throws IOException {\n    checkRequest(reqInfo);\n    checkFormatted();\n    long segmentTxId \u003d segment.getStartTxId();\n\n    // TODO: right now, a recovery of a segment when the log is\n    // completely emtpy (ie startLogSegment() but no txns)\n    // will fail this assertion here, since endTxId \u003c startTxId\n    Preconditions.checkArgument(segment.getEndTxId() \u003e 0 \u0026\u0026\n        segment.getEndTxId() \u003e\u003d segmentTxId,\n        \"bad recovery state for segment %s: %s\",\n        segmentTxId, TextFormat.shortDebugString(segment));\n    \n    PersistedRecoveryPaxosData oldData \u003d getPersistedPaxosData(segmentTxId);\n    PersistedRecoveryPaxosData newData \u003d PersistedRecoveryPaxosData.newBuilder()\n        .setAcceptedInEpoch(reqInfo.getEpoch())\n        .setSegmentState(segment)\n        .build();\n    if (oldData !\u003d null) {\n      Preconditions.checkState(oldData.getAcceptedInEpoch() \u003c\u003d reqInfo.getEpoch(),\n          \"Bad paxos transition, out-of-order epochs.\\nOld: %s\\nNew: %s\\n\",\n          oldData, newData);\n    }\n\n    SegmentStateProto currentSegment \u003d getSegmentInfo(segmentTxId);\n    if (currentSegment \u003d\u003d null ||\n        currentSegment.getEndTxId() !\u003d segment.getEndTxId()) {\n      if (currentSegment \u003d\u003d null) {\n        LOG.info(\"Synchronizing log \" + TextFormat.shortDebugString(segment) +\n            \": no current segment in place\");\n      } else {\n        LOG.info(\"Synchronizing log \" + TextFormat.shortDebugString(segment) +\n            \": old segment \" + TextFormat.shortDebugString(segment) + \" is \" +\n            \"not the right length\");\n      }\n      syncLog(reqInfo, segment, fromUrl);\n    } else {\n      LOG.info(\"Skipping download of log \" +\n          TextFormat.shortDebugString(segment) +\n          \": already have up-to-date logs\");\n    }\n    \n    // TODO: is it OK that this is non-atomic?\n    // we might be left with an older epoch recorded, but a newer log\n    \n    persistPaxosData(segmentTxId, newData);\n    LOG.info(\"Accepted recovery for segment \" + segmentTxId + \": \" +\n        TextFormat.shortDebugString(newData));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java",
      "extendedDetails": {}
    },
    "f765fdb65701e61887daedb2b369af4be12cb432": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3793. Implement genericized format() in QJM. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1373177 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/08/12 5:48 PM",
      "commitName": "f765fdb65701e61887daedb2b369af4be12cb432",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "25/07/12 2:47 PM",
      "commitNameOld": "b17018e4b821ec860144d8bd38bc1fcb0d7eeaa5",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 20.13,
      "commitsBetweenForRepo": 82,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,47 +1,48 @@\n   public synchronized void acceptRecovery(RequestInfo reqInfo,\n       SegmentStateProto segment, URL fromUrl)\n       throws IOException {\n     checkRequest(reqInfo);\n+    checkFormatted();\n     long segmentTxId \u003d segment.getStartTxId();\n \n     // TODO: right now, a recovery of a segment when the log is\n     // completely emtpy (ie startLogSegment() but no txns)\n     // will fail this assertion here, since endTxId \u003c startTxId\n     Preconditions.checkArgument(segment.getEndTxId() \u003e 0 \u0026\u0026\n         segment.getEndTxId() \u003e\u003d segmentTxId,\n         \"bad recovery state for segment %s: %s\",\n         segmentTxId, TextFormat.shortDebugString(segment));\n     \n     PersistedRecoveryPaxosData oldData \u003d getPersistedPaxosData(segmentTxId);\n     PersistedRecoveryPaxosData newData \u003d PersistedRecoveryPaxosData.newBuilder()\n         .setAcceptedInEpoch(reqInfo.getEpoch())\n         .setSegmentState(segment)\n         .build();\n     if (oldData !\u003d null) {\n       Preconditions.checkState(oldData.getAcceptedInEpoch() \u003c\u003d reqInfo.getEpoch(),\n           \"Bad paxos transition, out-of-order epochs.\\nOld: %s\\nNew: %s\\n\",\n           oldData, newData);\n     }\n \n     SegmentStateProto currentSegment \u003d getSegmentInfo(segmentTxId);\n     // TODO: this can be null, in the case that one of the loggers started\n     // the next segment, but others did not! add regression test and null\n     // check in next condition below.\n     \n     // TODO: what if they have the same length but one is finalized and the\n     // other isn\u0027t! cover that case.\n     if (currentSegment.getEndTxId() !\u003d segment.getEndTxId()) {\n       syncLog(reqInfo, segment, fromUrl);\n     } else {\n       LOG.info(\"Skipping download of log \" +\n           TextFormat.shortDebugString(segment) +\n           \": already have up-to-date logs\");\n     }\n     \n     // TODO: is it OK that this is non-atomic?\n     // we might be left with an older epoch recorded, but a newer log\n     \n     persistPaxosData(segmentTxId, newData);\n     LOG.info(\"Accepted recovery for segment \" + segmentTxId + \": \" +\n         TextFormat.shortDebugString(newData));\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void acceptRecovery(RequestInfo reqInfo,\n      SegmentStateProto segment, URL fromUrl)\n      throws IOException {\n    checkRequest(reqInfo);\n    checkFormatted();\n    long segmentTxId \u003d segment.getStartTxId();\n\n    // TODO: right now, a recovery of a segment when the log is\n    // completely emtpy (ie startLogSegment() but no txns)\n    // will fail this assertion here, since endTxId \u003c startTxId\n    Preconditions.checkArgument(segment.getEndTxId() \u003e 0 \u0026\u0026\n        segment.getEndTxId() \u003e\u003d segmentTxId,\n        \"bad recovery state for segment %s: %s\",\n        segmentTxId, TextFormat.shortDebugString(segment));\n    \n    PersistedRecoveryPaxosData oldData \u003d getPersistedPaxosData(segmentTxId);\n    PersistedRecoveryPaxosData newData \u003d PersistedRecoveryPaxosData.newBuilder()\n        .setAcceptedInEpoch(reqInfo.getEpoch())\n        .setSegmentState(segment)\n        .build();\n    if (oldData !\u003d null) {\n      Preconditions.checkState(oldData.getAcceptedInEpoch() \u003c\u003d reqInfo.getEpoch(),\n          \"Bad paxos transition, out-of-order epochs.\\nOld: %s\\nNew: %s\\n\",\n          oldData, newData);\n    }\n\n    SegmentStateProto currentSegment \u003d getSegmentInfo(segmentTxId);\n    // TODO: this can be null, in the case that one of the loggers started\n    // the next segment, but others did not! add regression test and null\n    // check in next condition below.\n    \n    // TODO: what if they have the same length but one is finalized and the\n    // other isn\u0027t! cover that case.\n    if (currentSegment.getEndTxId() !\u003d segment.getEndTxId()) {\n      syncLog(reqInfo, segment, fromUrl);\n    } else {\n      LOG.info(\"Skipping download of log \" +\n          TextFormat.shortDebugString(segment) +\n          \": already have up-to-date logs\");\n    }\n    \n    // TODO: is it OK that this is non-atomic?\n    // we might be left with an older epoch recorded, but a newer log\n    \n    persistPaxosData(segmentTxId, newData);\n    LOG.info(\"Accepted recovery for segment \" + segmentTxId + \": \" +\n        TextFormat.shortDebugString(newData));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java",
      "extendedDetails": {}
    },
    "74d4573a23db5586c6e47ff2277aa7c35237da34": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-3077. Quorum-based protocol for reading and writing edit logs. Contributed by Todd Lipcon based on initial work from Brandon Li and Hari Mankude.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1363596 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/07/12 5:25 PM",
      "commitName": "74d4573a23db5586c6e47ff2277aa7c35237da34",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,47 @@\n+  public synchronized void acceptRecovery(RequestInfo reqInfo,\n+      SegmentStateProto segment, URL fromUrl)\n+      throws IOException {\n+    checkRequest(reqInfo);\n+    long segmentTxId \u003d segment.getStartTxId();\n+\n+    // TODO: right now, a recovery of a segment when the log is\n+    // completely emtpy (ie startLogSegment() but no txns)\n+    // will fail this assertion here, since endTxId \u003c startTxId\n+    Preconditions.checkArgument(segment.getEndTxId() \u003e 0 \u0026\u0026\n+        segment.getEndTxId() \u003e\u003d segmentTxId,\n+        \"bad recovery state for segment %s: %s\",\n+        segmentTxId, TextFormat.shortDebugString(segment));\n+    \n+    PersistedRecoveryPaxosData oldData \u003d getPersistedPaxosData(segmentTxId);\n+    PersistedRecoveryPaxosData newData \u003d PersistedRecoveryPaxosData.newBuilder()\n+        .setAcceptedInEpoch(reqInfo.getEpoch())\n+        .setSegmentState(segment)\n+        .build();\n+    if (oldData !\u003d null) {\n+      Preconditions.checkState(oldData.getAcceptedInEpoch() \u003c\u003d reqInfo.getEpoch(),\n+          \"Bad paxos transition, out-of-order epochs.\\nOld: %s\\nNew: %s\\n\",\n+          oldData, newData);\n+    }\n+\n+    SegmentStateProto currentSegment \u003d getSegmentInfo(segmentTxId);\n+    // TODO: this can be null, in the case that one of the loggers started\n+    // the next segment, but others did not! add regression test and null\n+    // check in next condition below.\n+    \n+    // TODO: what if they have the same length but one is finalized and the\n+    // other isn\u0027t! cover that case.\n+    if (currentSegment.getEndTxId() !\u003d segment.getEndTxId()) {\n+      syncLog(reqInfo, segment, fromUrl);\n+    } else {\n+      LOG.info(\"Skipping download of log \" +\n+          TextFormat.shortDebugString(segment) +\n+          \": already have up-to-date logs\");\n+    }\n+    \n+    // TODO: is it OK that this is non-atomic?\n+    // we might be left with an older epoch recorded, but a newer log\n+    \n+    persistPaxosData(segmentTxId, newData);\n+    LOG.info(\"Accepted recovery for segment \" + segmentTxId + \": \" +\n+        TextFormat.shortDebugString(newData));\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void acceptRecovery(RequestInfo reqInfo,\n      SegmentStateProto segment, URL fromUrl)\n      throws IOException {\n    checkRequest(reqInfo);\n    long segmentTxId \u003d segment.getStartTxId();\n\n    // TODO: right now, a recovery of a segment when the log is\n    // completely emtpy (ie startLogSegment() but no txns)\n    // will fail this assertion here, since endTxId \u003c startTxId\n    Preconditions.checkArgument(segment.getEndTxId() \u003e 0 \u0026\u0026\n        segment.getEndTxId() \u003e\u003d segmentTxId,\n        \"bad recovery state for segment %s: %s\",\n        segmentTxId, TextFormat.shortDebugString(segment));\n    \n    PersistedRecoveryPaxosData oldData \u003d getPersistedPaxosData(segmentTxId);\n    PersistedRecoveryPaxosData newData \u003d PersistedRecoveryPaxosData.newBuilder()\n        .setAcceptedInEpoch(reqInfo.getEpoch())\n        .setSegmentState(segment)\n        .build();\n    if (oldData !\u003d null) {\n      Preconditions.checkState(oldData.getAcceptedInEpoch() \u003c\u003d reqInfo.getEpoch(),\n          \"Bad paxos transition, out-of-order epochs.\\nOld: %s\\nNew: %s\\n\",\n          oldData, newData);\n    }\n\n    SegmentStateProto currentSegment \u003d getSegmentInfo(segmentTxId);\n    // TODO: this can be null, in the case that one of the loggers started\n    // the next segment, but others did not! add regression test and null\n    // check in next condition below.\n    \n    // TODO: what if they have the same length but one is finalized and the\n    // other isn\u0027t! cover that case.\n    if (currentSegment.getEndTxId() !\u003d segment.getEndTxId()) {\n      syncLog(reqInfo, segment, fromUrl);\n    } else {\n      LOG.info(\"Skipping download of log \" +\n          TextFormat.shortDebugString(segment) +\n          \": already have up-to-date logs\");\n    }\n    \n    // TODO: is it OK that this is non-atomic?\n    // we might be left with an older epoch recorded, but a newer log\n    \n    persistPaxosData(segmentTxId, newData);\n    LOG.info(\"Accepted recovery for segment \" + segmentTxId + \": \" +\n        TextFormat.shortDebugString(newData));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java"
    }
  }
}