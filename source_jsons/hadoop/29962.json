{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "LogInfo.java",
  "functionName": "parseForStore",
  "functionId": "parseForStore___tdm-TimelineDataManager__appDirPath-Path__appCompleted-boolean__jsonFactory-JsonFactory__objMapper-ObjectMapper__fs-FileSystem",
  "sourceFilePath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timeline-pluginstorage/src/main/java/org/apache/hadoop/yarn/server/timeline/LogInfo.java",
  "functionStartLine": 102,
  "functionEndLine": 132,
  "numCommitsSeen": 5,
  "timeTaken": 1571,
  "changeHistory": [
    "06413da72efed9a50e49efaf7110c220c88a7f4a",
    "d49cfb350454c2dfa2f3eb70f79b6d5030ce7bec",
    "02f597c5db36ded385413958bdee793ad7eda40e"
  ],
  "changeHistoryShort": {
    "06413da72efed9a50e49efaf7110c220c88a7f4a": "Ymultichange(Yreturntypechange,Ybodychange)",
    "d49cfb350454c2dfa2f3eb70f79b6d5030ce7bec": "Ybodychange",
    "02f597c5db36ded385413958bdee793ad7eda40e": "Yintroduced"
  },
  "changeHistoryDetails": {
    "06413da72efed9a50e49efaf7110c220c88a7f4a": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": "YARN-4851. Metric improvements for ATS v1.5 storage components. Li Lu via junping_du.\n",
      "commitDate": "03/05/16 4:16 AM",
      "commitName": "06413da72efed9a50e49efaf7110c220c88a7f4a",
      "commitAuthor": "Junping Du",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "YARN-4851. Metric improvements for ATS v1.5 storage components. Li Lu via junping_du.\n",
          "commitDate": "03/05/16 4:16 AM",
          "commitName": "06413da72efed9a50e49efaf7110c220c88a7f4a",
          "commitAuthor": "Junping Du",
          "commitDateOld": "10/03/16 10:51 AM",
          "commitNameOld": "d49cfb350454c2dfa2f3eb70f79b6d5030ce7bec",
          "commitAuthorOld": "Li Lu",
          "daysBetweenCommits": 53.68,
          "commitsBetweenForRepo": 312,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,28 +1,31 @@\n-  public void parseForStore(TimelineDataManager tdm, Path appDirPath,\n+  public long parseForStore(TimelineDataManager tdm, Path appDirPath,\n       boolean appCompleted, JsonFactory jsonFactory, ObjectMapper objMapper,\n       FileSystem fs) throws IOException {\n     LOG.debug(\"Parsing for log dir {} on attempt {}\", appDirPath,\n         attemptDirName);\n     Path logPath \u003d getPath(appDirPath);\n     FileStatus status \u003d fs.getFileStatus(logPath);\n+    long numParsed \u003d 0;\n     if (status !\u003d null) {\n       long startTime \u003d Time.monotonicNow();\n       try {\n         LOG.debug(\"Parsing {} at offset {}\", logPath, offset);\n         long count \u003d parsePath(tdm, logPath, appCompleted, jsonFactory,\n             objMapper, fs);\n         LOG.info(\"Parsed {} entities from {} in {} msec\",\n             count, logPath, Time.monotonicNow() - startTime);\n+        numParsed +\u003d count;\n       } catch (RuntimeException e) {\n         // If AppLogs cannot parse this log, it may be corrupted or just empty\n         if (e.getCause() instanceof JsonParseException \u0026\u0026\n             (status.getLen() \u003e 0 || offset \u003e 0)) {\n           // log on parse problems if the file as been read in the past or\n           // is visibly non-empty\n           LOG.info(\"Log {} appears to be corrupted. Skip. \", logPath);\n         }\n       }\n     } else {\n       LOG.warn(\"{} no longer exists. Skip for scanning. \", logPath);\n     }\n+    return numParsed;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public long parseForStore(TimelineDataManager tdm, Path appDirPath,\n      boolean appCompleted, JsonFactory jsonFactory, ObjectMapper objMapper,\n      FileSystem fs) throws IOException {\n    LOG.debug(\"Parsing for log dir {} on attempt {}\", appDirPath,\n        attemptDirName);\n    Path logPath \u003d getPath(appDirPath);\n    FileStatus status \u003d fs.getFileStatus(logPath);\n    long numParsed \u003d 0;\n    if (status !\u003d null) {\n      long startTime \u003d Time.monotonicNow();\n      try {\n        LOG.debug(\"Parsing {} at offset {}\", logPath, offset);\n        long count \u003d parsePath(tdm, logPath, appCompleted, jsonFactory,\n            objMapper, fs);\n        LOG.info(\"Parsed {} entities from {} in {} msec\",\n            count, logPath, Time.monotonicNow() - startTime);\n        numParsed +\u003d count;\n      } catch (RuntimeException e) {\n        // If AppLogs cannot parse this log, it may be corrupted or just empty\n        if (e.getCause() instanceof JsonParseException \u0026\u0026\n            (status.getLen() \u003e 0 || offset \u003e 0)) {\n          // log on parse problems if the file as been read in the past or\n          // is visibly non-empty\n          LOG.info(\"Log {} appears to be corrupted. Skip. \", logPath);\n        }\n      }\n    } else {\n      LOG.warn(\"{} no longer exists. Skip for scanning. \", logPath);\n    }\n    return numParsed;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timeline-pluginstorage/src/main/java/org/apache/hadoop/yarn/server/timeline/LogInfo.java",
          "extendedDetails": {
            "oldValue": "void",
            "newValue": "long"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-4851. Metric improvements for ATS v1.5 storage components. Li Lu via junping_du.\n",
          "commitDate": "03/05/16 4:16 AM",
          "commitName": "06413da72efed9a50e49efaf7110c220c88a7f4a",
          "commitAuthor": "Junping Du",
          "commitDateOld": "10/03/16 10:51 AM",
          "commitNameOld": "d49cfb350454c2dfa2f3eb70f79b6d5030ce7bec",
          "commitAuthorOld": "Li Lu",
          "daysBetweenCommits": 53.68,
          "commitsBetweenForRepo": 312,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,28 +1,31 @@\n-  public void parseForStore(TimelineDataManager tdm, Path appDirPath,\n+  public long parseForStore(TimelineDataManager tdm, Path appDirPath,\n       boolean appCompleted, JsonFactory jsonFactory, ObjectMapper objMapper,\n       FileSystem fs) throws IOException {\n     LOG.debug(\"Parsing for log dir {} on attempt {}\", appDirPath,\n         attemptDirName);\n     Path logPath \u003d getPath(appDirPath);\n     FileStatus status \u003d fs.getFileStatus(logPath);\n+    long numParsed \u003d 0;\n     if (status !\u003d null) {\n       long startTime \u003d Time.monotonicNow();\n       try {\n         LOG.debug(\"Parsing {} at offset {}\", logPath, offset);\n         long count \u003d parsePath(tdm, logPath, appCompleted, jsonFactory,\n             objMapper, fs);\n         LOG.info(\"Parsed {} entities from {} in {} msec\",\n             count, logPath, Time.monotonicNow() - startTime);\n+        numParsed +\u003d count;\n       } catch (RuntimeException e) {\n         // If AppLogs cannot parse this log, it may be corrupted or just empty\n         if (e.getCause() instanceof JsonParseException \u0026\u0026\n             (status.getLen() \u003e 0 || offset \u003e 0)) {\n           // log on parse problems if the file as been read in the past or\n           // is visibly non-empty\n           LOG.info(\"Log {} appears to be corrupted. Skip. \", logPath);\n         }\n       }\n     } else {\n       LOG.warn(\"{} no longer exists. Skip for scanning. \", logPath);\n     }\n+    return numParsed;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public long parseForStore(TimelineDataManager tdm, Path appDirPath,\n      boolean appCompleted, JsonFactory jsonFactory, ObjectMapper objMapper,\n      FileSystem fs) throws IOException {\n    LOG.debug(\"Parsing for log dir {} on attempt {}\", appDirPath,\n        attemptDirName);\n    Path logPath \u003d getPath(appDirPath);\n    FileStatus status \u003d fs.getFileStatus(logPath);\n    long numParsed \u003d 0;\n    if (status !\u003d null) {\n      long startTime \u003d Time.monotonicNow();\n      try {\n        LOG.debug(\"Parsing {} at offset {}\", logPath, offset);\n        long count \u003d parsePath(tdm, logPath, appCompleted, jsonFactory,\n            objMapper, fs);\n        LOG.info(\"Parsed {} entities from {} in {} msec\",\n            count, logPath, Time.monotonicNow() - startTime);\n        numParsed +\u003d count;\n      } catch (RuntimeException e) {\n        // If AppLogs cannot parse this log, it may be corrupted or just empty\n        if (e.getCause() instanceof JsonParseException \u0026\u0026\n            (status.getLen() \u003e 0 || offset \u003e 0)) {\n          // log on parse problems if the file as been read in the past or\n          // is visibly non-empty\n          LOG.info(\"Log {} appears to be corrupted. Skip. \", logPath);\n        }\n      }\n    } else {\n      LOG.warn(\"{} no longer exists. Skip for scanning. \", logPath);\n    }\n    return numParsed;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timeline-pluginstorage/src/main/java/org/apache/hadoop/yarn/server/timeline/LogInfo.java",
          "extendedDetails": {}
        }
      ]
    },
    "d49cfb350454c2dfa2f3eb70f79b6d5030ce7bec": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4696. Improving EntityGroupFSTimelineStore on exception handling, test setup, and concurrency. (Steve Loughran via gtcarrera9)\n",
      "commitDate": "10/03/16 10:51 AM",
      "commitName": "d49cfb350454c2dfa2f3eb70f79b6d5030ce7bec",
      "commitAuthor": "Li Lu",
      "commitDateOld": "17/01/16 5:37 PM",
      "commitNameOld": "02f597c5db36ded385413958bdee793ad7eda40e",
      "commitAuthorOld": "Junping Du",
      "daysBetweenCommits": 52.72,
      "commitsBetweenForRepo": 371,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,28 @@\n   public void parseForStore(TimelineDataManager tdm, Path appDirPath,\n       boolean appCompleted, JsonFactory jsonFactory, ObjectMapper objMapper,\n       FileSystem fs) throws IOException {\n     LOG.debug(\"Parsing for log dir {} on attempt {}\", appDirPath,\n         attemptDirName);\n     Path logPath \u003d getPath(appDirPath);\n-    if (fs.exists(logPath)) {\n+    FileStatus status \u003d fs.getFileStatus(logPath);\n+    if (status !\u003d null) {\n       long startTime \u003d Time.monotonicNow();\n       try {\n         LOG.debug(\"Parsing {} at offset {}\", logPath, offset);\n         long count \u003d parsePath(tdm, logPath, appCompleted, jsonFactory,\n             objMapper, fs);\n         LOG.info(\"Parsed {} entities from {} in {} msec\",\n             count, logPath, Time.monotonicNow() - startTime);\n       } catch (RuntimeException e) {\n-        if (e.getCause() instanceof JsonParseException) {\n-          // If AppLogs cannot parse this log, it may be corrupted\n+        // If AppLogs cannot parse this log, it may be corrupted or just empty\n+        if (e.getCause() instanceof JsonParseException \u0026\u0026\n+            (status.getLen() \u003e 0 || offset \u003e 0)) {\n+          // log on parse problems if the file as been read in the past or\n+          // is visibly non-empty\n           LOG.info(\"Log {} appears to be corrupted. Skip. \", logPath);\n         }\n       }\n     } else {\n       LOG.warn(\"{} no longer exists. Skip for scanning. \", logPath);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void parseForStore(TimelineDataManager tdm, Path appDirPath,\n      boolean appCompleted, JsonFactory jsonFactory, ObjectMapper objMapper,\n      FileSystem fs) throws IOException {\n    LOG.debug(\"Parsing for log dir {} on attempt {}\", appDirPath,\n        attemptDirName);\n    Path logPath \u003d getPath(appDirPath);\n    FileStatus status \u003d fs.getFileStatus(logPath);\n    if (status !\u003d null) {\n      long startTime \u003d Time.monotonicNow();\n      try {\n        LOG.debug(\"Parsing {} at offset {}\", logPath, offset);\n        long count \u003d parsePath(tdm, logPath, appCompleted, jsonFactory,\n            objMapper, fs);\n        LOG.info(\"Parsed {} entities from {} in {} msec\",\n            count, logPath, Time.monotonicNow() - startTime);\n      } catch (RuntimeException e) {\n        // If AppLogs cannot parse this log, it may be corrupted or just empty\n        if (e.getCause() instanceof JsonParseException \u0026\u0026\n            (status.getLen() \u003e 0 || offset \u003e 0)) {\n          // log on parse problems if the file as been read in the past or\n          // is visibly non-empty\n          LOG.info(\"Log {} appears to be corrupted. Skip. \", logPath);\n        }\n      }\n    } else {\n      LOG.warn(\"{} no longer exists. Skip for scanning. \", logPath);\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timeline-pluginstorage/src/main/java/org/apache/hadoop/yarn/server/timeline/LogInfo.java",
      "extendedDetails": {}
    },
    "02f597c5db36ded385413958bdee793ad7eda40e": {
      "type": "Yintroduced",
      "commitMessage": "YARN-4265. Provide new timeline plugin storage to support fine-grained entity caching. Contributed by Li Lu and Jason Lowe\n",
      "commitDate": "17/01/16 5:37 PM",
      "commitName": "02f597c5db36ded385413958bdee793ad7eda40e",
      "commitAuthor": "Junping Du",
      "diff": "@@ -0,0 +1,24 @@\n+  public void parseForStore(TimelineDataManager tdm, Path appDirPath,\n+      boolean appCompleted, JsonFactory jsonFactory, ObjectMapper objMapper,\n+      FileSystem fs) throws IOException {\n+    LOG.debug(\"Parsing for log dir {} on attempt {}\", appDirPath,\n+        attemptDirName);\n+    Path logPath \u003d getPath(appDirPath);\n+    if (fs.exists(logPath)) {\n+      long startTime \u003d Time.monotonicNow();\n+      try {\n+        LOG.debug(\"Parsing {} at offset {}\", logPath, offset);\n+        long count \u003d parsePath(tdm, logPath, appCompleted, jsonFactory,\n+            objMapper, fs);\n+        LOG.info(\"Parsed {} entities from {} in {} msec\",\n+            count, logPath, Time.monotonicNow() - startTime);\n+      } catch (RuntimeException e) {\n+        if (e.getCause() instanceof JsonParseException) {\n+          // If AppLogs cannot parse this log, it may be corrupted\n+          LOG.info(\"Log {} appears to be corrupted. Skip. \", logPath);\n+        }\n+      }\n+    } else {\n+      LOG.warn(\"{} no longer exists. Skip for scanning. \", logPath);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void parseForStore(TimelineDataManager tdm, Path appDirPath,\n      boolean appCompleted, JsonFactory jsonFactory, ObjectMapper objMapper,\n      FileSystem fs) throws IOException {\n    LOG.debug(\"Parsing for log dir {} on attempt {}\", appDirPath,\n        attemptDirName);\n    Path logPath \u003d getPath(appDirPath);\n    if (fs.exists(logPath)) {\n      long startTime \u003d Time.monotonicNow();\n      try {\n        LOG.debug(\"Parsing {} at offset {}\", logPath, offset);\n        long count \u003d parsePath(tdm, logPath, appCompleted, jsonFactory,\n            objMapper, fs);\n        LOG.info(\"Parsed {} entities from {} in {} msec\",\n            count, logPath, Time.monotonicNow() - startTime);\n      } catch (RuntimeException e) {\n        if (e.getCause() instanceof JsonParseException) {\n          // If AppLogs cannot parse this log, it may be corrupted\n          LOG.info(\"Log {} appears to be corrupted. Skip. \", logPath);\n        }\n      }\n    } else {\n      LOG.warn(\"{} no longer exists. Skip for scanning. \", logPath);\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timeline-pluginstorage/src/main/java/org/apache/hadoop/yarn/server/timeline/LogInfo.java"
    }
  }
}