{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "CacheManager.java",
  "functionName": "addCachePool",
  "functionId": "addCachePool___info-CachePoolInfo",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
  "functionStartLine": 787,
  "functionEndLine": 807,
  "numCommitsSeen": 56,
  "timeTaken": 3807,
  "changeHistory": [
    "93e23a99157c30b51752fc49748c3c210745a187",
    "991c453ca3ac141a3f286f74af8401f83c38b230",
    "13edb391d06c479720202eb5ac81f1c71fe64748",
    "ce35e0950cef9250ce2ceffb3b8bfcff533c6b92",
    "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a",
    "b60e18db743b8933d96384942046ea57e725855d",
    "af1ac9a5e8d8d97a855940d853dd59ab4666f6e2",
    "a0d9a155a4a4258f628e927e096ecf6673f788ec",
    "3a9cd79e9ddd5a9499e28633ccccdc9eef22b813",
    "f41f8b8842c3f26d19f7fa928070c7c07f760e4c",
    "d56d0b46e1b82ae068083ddb99872d314684dc82",
    "97b7267977ef42201e5844df49bc37ec3d10ce16"
  ],
  "changeHistoryShort": {
    "93e23a99157c30b51752fc49748c3c210745a187": "Ybodychange",
    "991c453ca3ac141a3f286f74af8401f83c38b230": "Ybodychange",
    "13edb391d06c479720202eb5ac81f1c71fe64748": "Ybodychange",
    "ce35e0950cef9250ce2ceffb3b8bfcff533c6b92": "Ybodychange",
    "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a": "Ymultichange(Ymodifierchange,Ybodychange)",
    "b60e18db743b8933d96384942046ea57e725855d": "Ymultichange(Yreturntypechange,Ybodychange)",
    "af1ac9a5e8d8d97a855940d853dd59ab4666f6e2": "Ymultichange(Yreturntypechange,Ybodychange)",
    "a0d9a155a4a4258f628e927e096ecf6673f788ec": "Ybodychange",
    "3a9cd79e9ddd5a9499e28633ccccdc9eef22b813": "Ybodychange",
    "f41f8b8842c3f26d19f7fa928070c7c07f760e4c": "Ymultichange(Yreturntypechange,Ybodychange)",
    "d56d0b46e1b82ae068083ddb99872d314684dc82": "Ymultichange(Yreturntypechange,Ybodychange)",
    "97b7267977ef42201e5844df49bc37ec3d10ce16": "Yintroduced"
  },
  "changeHistoryDetails": {
    "93e23a99157c30b51752fc49748c3c210745a187": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6613. Improve logging in caching classes. (wang)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1607697 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "03/07/14 10:13 AM",
      "commitName": "93e23a99157c30b51752fc49748c3c210745a187",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "15/05/14 6:18 PM",
      "commitNameOld": "8f48760663070529ff09927d1772010fffe5f438",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 48.66,
      "commitsBetweenForRepo": 297,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,21 @@\n   public CachePoolInfo addCachePool(CachePoolInfo info)\n       throws IOException {\n     assert namesystem.hasWriteLock();\n     CachePool pool;\n     try {\n       CachePoolInfo.validate(info);\n       String poolName \u003d info.getPoolName();\n       pool \u003d cachePools.get(poolName);\n       if (pool !\u003d null) {\n         throw new InvalidRequestException(\"Cache pool \" + poolName\n             + \" already exists.\");\n       }\n       pool \u003d CachePool.createFromInfoAndDefaults(info);\n       cachePools.put(pool.getPoolName(), pool);\n     } catch (IOException e) {\n       LOG.info(\"addCachePool of \" + info + \" failed: \", e);\n       throw e;\n     }\n-    LOG.info(\"addCachePool of \" + info + \" successful.\");\n+    LOG.info(\"addCachePool of {} successful.\", info);\n     return pool.getInfo(true);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public CachePoolInfo addCachePool(CachePoolInfo info)\n      throws IOException {\n    assert namesystem.hasWriteLock();\n    CachePool pool;\n    try {\n      CachePoolInfo.validate(info);\n      String poolName \u003d info.getPoolName();\n      pool \u003d cachePools.get(poolName);\n      if (pool !\u003d null) {\n        throw new InvalidRequestException(\"Cache pool \" + poolName\n            + \" already exists.\");\n      }\n      pool \u003d CachePool.createFromInfoAndDefaults(info);\n      cachePools.put(pool.getPoolName(), pool);\n    } catch (IOException e) {\n      LOG.info(\"addCachePool of \" + info + \" failed: \", e);\n      throw e;\n    }\n    LOG.info(\"addCachePool of {} successful.\", info);\n    return pool.getInfo(true);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
      "extendedDetails": {}
    },
    "991c453ca3ac141a3f286f74af8401f83c38b230": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5431. Support cachepool-based limit management in path-based caching. (awang via cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1551651 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/12/13 10:47 AM",
      "commitName": "991c453ca3ac141a3f286f74af8401f83c38b230",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "05/12/13 1:09 PM",
      "commitNameOld": "55e5b0653c34a5f4146ce5a97a5b4a88a976d88a",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 11.9,
      "commitsBetweenForRepo": 67,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,15 +1,21 @@\n   public CachePoolInfo addCachePool(CachePoolInfo info)\n       throws IOException {\n     assert namesystem.hasWriteLock();\n-    CachePoolInfo.validate(info);\n-    String poolName \u003d info.getPoolName();\n-    CachePool pool \u003d cachePools.get(poolName);\n-    if (pool !\u003d null) {\n-      throw new InvalidRequestException(\"Cache pool \" + poolName\n-          + \" already exists.\");\n+    CachePool pool;\n+    try {\n+      CachePoolInfo.validate(info);\n+      String poolName \u003d info.getPoolName();\n+      pool \u003d cachePools.get(poolName);\n+      if (pool !\u003d null) {\n+        throw new InvalidRequestException(\"Cache pool \" + poolName\n+            + \" already exists.\");\n+      }\n+      pool \u003d CachePool.createFromInfoAndDefaults(info);\n+      cachePools.put(pool.getPoolName(), pool);\n+    } catch (IOException e) {\n+      LOG.info(\"addCachePool of \" + info + \" failed: \", e);\n+      throw e;\n     }\n-    pool \u003d CachePool.createFromInfoAndDefaults(info);\n-    cachePools.put(pool.getPoolName(), pool);\n-    LOG.info(\"Created new cache pool \" + pool);\n+    LOG.info(\"addCachePool of \" + info + \" successful.\");\n     return pool.getInfo(true);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public CachePoolInfo addCachePool(CachePoolInfo info)\n      throws IOException {\n    assert namesystem.hasWriteLock();\n    CachePool pool;\n    try {\n      CachePoolInfo.validate(info);\n      String poolName \u003d info.getPoolName();\n      pool \u003d cachePools.get(poolName);\n      if (pool !\u003d null) {\n        throw new InvalidRequestException(\"Cache pool \" + poolName\n            + \" already exists.\");\n      }\n      pool \u003d CachePool.createFromInfoAndDefaults(info);\n      cachePools.put(pool.getPoolName(), pool);\n    } catch (IOException e) {\n      LOG.info(\"addCachePool of \" + info + \" failed: \", e);\n      throw e;\n    }\n    LOG.info(\"addCachePool of \" + info + \" successful.\");\n    return pool.getInfo(true);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
      "extendedDetails": {}
    },
    "13edb391d06c479720202eb5ac81f1c71fe64748": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5556. Add some more NameNode cache statistics, cache pool stats (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1546143 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/11/13 9:55 AM",
      "commitName": "13edb391d06c479720202eb5ac81f1c71fe64748",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "21/11/13 9:12 AM",
      "commitNameOld": "f91a45a96c21db9e5d40097c7d3f5d005ae10dde",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 6.03,
      "commitsBetweenForRepo": 22,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,15 +1,15 @@\n   public CachePoolInfo addCachePool(CachePoolInfo info)\n       throws IOException {\n     assert namesystem.hasWriteLock();\n     CachePoolInfo.validate(info);\n     String poolName \u003d info.getPoolName();\n     CachePool pool \u003d cachePools.get(poolName);\n     if (pool !\u003d null) {\n       throw new InvalidRequestException(\"Cache pool \" + poolName\n           + \" already exists.\");\n     }\n     pool \u003d CachePool.createFromInfoAndDefaults(info);\n     cachePools.put(pool.getPoolName(), pool);\n     LOG.info(\"Created new cache pool \" + pool);\n-    return pool.getInfo(null);\n+    return pool.getInfo(true);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public CachePoolInfo addCachePool(CachePoolInfo info)\n      throws IOException {\n    assert namesystem.hasWriteLock();\n    CachePoolInfo.validate(info);\n    String poolName \u003d info.getPoolName();\n    CachePool pool \u003d cachePools.get(poolName);\n    if (pool !\u003d null) {\n      throw new InvalidRequestException(\"Cache pool \" + poolName\n          + \" already exists.\");\n    }\n    pool \u003d CachePool.createFromInfoAndDefaults(info);\n    cachePools.put(pool.getPoolName(), pool);\n    LOG.info(\"Created new cache pool \" + pool);\n    return pool.getInfo(true);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
      "extendedDetails": {}
    },
    "ce35e0950cef9250ce2ceffb3b8bfcff533c6b92": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5471. CacheAdmin -listPools fails when user lacks permissions to view all pools (Andrew Wang via Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1541323 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/11/13 3:52 PM",
      "commitName": "ce35e0950cef9250ce2ceffb3b8bfcff533c6b92",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "07/11/13 2:07 PM",
      "commitNameOld": "f79b3e6b17450e9d34c483046b7437b09dd72016",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 5.07,
      "commitsBetweenForRepo": 20,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,15 @@\n   public CachePoolInfo addCachePool(CachePoolInfo info)\n       throws IOException {\n     assert namesystem.hasWriteLock();\n     CachePoolInfo.validate(info);\n     String poolName \u003d info.getPoolName();\n     CachePool pool \u003d cachePools.get(poolName);\n     if (pool !\u003d null) {\n-      throw new IOException(\"cache pool \" + poolName + \" already exists.\");\n+      throw new InvalidRequestException(\"Cache pool \" + poolName\n+          + \" already exists.\");\n     }\n     pool \u003d CachePool.createFromInfoAndDefaults(info);\n     cachePools.put(pool.getPoolName(), pool);\n-    LOG.info(\"created new cache pool \" + pool);\n-    return pool.getInfo(true);\n+    LOG.info(\"Created new cache pool \" + pool);\n+    return pool.getInfo(null);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public CachePoolInfo addCachePool(CachePoolInfo info)\n      throws IOException {\n    assert namesystem.hasWriteLock();\n    CachePoolInfo.validate(info);\n    String poolName \u003d info.getPoolName();\n    CachePool pool \u003d cachePools.get(poolName);\n    if (pool !\u003d null) {\n      throw new InvalidRequestException(\"Cache pool \" + poolName\n          + \" already exists.\");\n    }\n    pool \u003d CachePool.createFromInfoAndDefaults(info);\n    cachePools.put(pool.getPoolName(), pool);\n    LOG.info(\"Created new cache pool \" + pool);\n    return pool.getInfo(null);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
      "extendedDetails": {}
    },
    "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a": {
      "type": "Ymultichange(Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-5096. Automatically cache new data added to a cached path (contributed by Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1532924 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/10/13 3:15 PM",
      "commitName": "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a",
      "commitAuthor": "Colin McCabe",
      "subchanges": [
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-5096. Automatically cache new data added to a cached path (contributed by Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1532924 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "16/10/13 3:15 PM",
          "commitName": "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "14/10/13 3:56 PM",
          "commitNameOld": "efe545b0c219eeba61ac5259aee4d518beb74316",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 1.97,
          "commitsBetweenForRepo": 4,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,12 +1,14 @@\n-  public synchronized CachePoolInfo addCachePool(CachePoolInfo info)\n+  public CachePoolInfo addCachePool(CachePoolInfo info)\n       throws IOException {\n+    assert namesystem.hasWriteLock();\n     CachePoolInfo.validate(info);\n     String poolName \u003d info.getPoolName();\n     CachePool pool \u003d cachePools.get(poolName);\n     if (pool !\u003d null) {\n       throw new IOException(\"cache pool \" + poolName + \" already exists.\");\n     }\n     pool \u003d CachePool.createFromInfoAndDefaults(info);\n     cachePools.put(pool.getPoolName(), pool);\n+    LOG.info(\"created new cache pool \" + pool);\n     return pool.getInfo(true);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public CachePoolInfo addCachePool(CachePoolInfo info)\n      throws IOException {\n    assert namesystem.hasWriteLock();\n    CachePoolInfo.validate(info);\n    String poolName \u003d info.getPoolName();\n    CachePool pool \u003d cachePools.get(poolName);\n    if (pool !\u003d null) {\n      throw new IOException(\"cache pool \" + poolName + \" already exists.\");\n    }\n    pool \u003d CachePool.createFromInfoAndDefaults(info);\n    cachePools.put(pool.getPoolName(), pool);\n    LOG.info(\"created new cache pool \" + pool);\n    return pool.getInfo(true);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
          "extendedDetails": {
            "oldValue": "[public, synchronized]",
            "newValue": "[public]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5096. Automatically cache new data added to a cached path (contributed by Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1532924 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "16/10/13 3:15 PM",
          "commitName": "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "14/10/13 3:56 PM",
          "commitNameOld": "efe545b0c219eeba61ac5259aee4d518beb74316",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 1.97,
          "commitsBetweenForRepo": 4,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,12 +1,14 @@\n-  public synchronized CachePoolInfo addCachePool(CachePoolInfo info)\n+  public CachePoolInfo addCachePool(CachePoolInfo info)\n       throws IOException {\n+    assert namesystem.hasWriteLock();\n     CachePoolInfo.validate(info);\n     String poolName \u003d info.getPoolName();\n     CachePool pool \u003d cachePools.get(poolName);\n     if (pool !\u003d null) {\n       throw new IOException(\"cache pool \" + poolName + \" already exists.\");\n     }\n     pool \u003d CachePool.createFromInfoAndDefaults(info);\n     cachePools.put(pool.getPoolName(), pool);\n+    LOG.info(\"created new cache pool \" + pool);\n     return pool.getInfo(true);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public CachePoolInfo addCachePool(CachePoolInfo info)\n      throws IOException {\n    assert namesystem.hasWriteLock();\n    CachePoolInfo.validate(info);\n    String poolName \u003d info.getPoolName();\n    CachePool pool \u003d cachePools.get(poolName);\n    if (pool !\u003d null) {\n      throw new IOException(\"cache pool \" + poolName + \" already exists.\");\n    }\n    pool \u003d CachePool.createFromInfoAndDefaults(info);\n    cachePools.put(pool.getPoolName(), pool);\n    LOG.info(\"created new cache pool \" + pool);\n    return pool.getInfo(true);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "b60e18db743b8933d96384942046ea57e725855d": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-5314.  Do not expose CachePool type in AddCachePoolOp (Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1530073 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/10/13 2:26 PM",
      "commitName": "b60e18db743b8933d96384942046ea57e725855d",
      "commitAuthor": "Colin McCabe",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-5314.  Do not expose CachePool type in AddCachePoolOp (Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1530073 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "07/10/13 2:26 PM",
          "commitName": "b60e18db743b8933d96384942046ea57e725855d",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "04/10/13 3:28 PM",
          "commitNameOld": "eb2175db1a99348c80457e3ffda172cc461de8bc",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 2.96,
          "commitsBetweenForRepo": 2,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,14 +1,12 @@\n-  public synchronized CachePool addCachePool(CachePoolInfo info)\n+  public synchronized CachePoolInfo addCachePool(CachePoolInfo info)\n       throws IOException {\n     CachePoolInfo.validate(info);\n     String poolName \u003d info.getPoolName();\n     CachePool pool \u003d cachePools.get(poolName);\n     if (pool !\u003d null) {\n       throw new IOException(\"cache pool \" + poolName + \" already exists.\");\n     }\n-    CachePool cachePool \u003d new CachePool(poolName,\n-      info.getOwnerName(), info.getGroupName(), info.getMode(),\n-      info.getWeight());\n-    unprotectedAddCachePool(cachePool);\n-    return cachePool;\n+    pool \u003d CachePool.createFromInfoAndDefaults(info);\n+    cachePools.put(pool.getPoolName(), pool);\n+    return pool.getInfo(true);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public synchronized CachePoolInfo addCachePool(CachePoolInfo info)\n      throws IOException {\n    CachePoolInfo.validate(info);\n    String poolName \u003d info.getPoolName();\n    CachePool pool \u003d cachePools.get(poolName);\n    if (pool !\u003d null) {\n      throw new IOException(\"cache pool \" + poolName + \" already exists.\");\n    }\n    pool \u003d CachePool.createFromInfoAndDefaults(info);\n    cachePools.put(pool.getPoolName(), pool);\n    return pool.getInfo(true);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
          "extendedDetails": {
            "oldValue": "CachePool",
            "newValue": "CachePoolInfo"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5314.  Do not expose CachePool type in AddCachePoolOp (Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1530073 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "07/10/13 2:26 PM",
          "commitName": "b60e18db743b8933d96384942046ea57e725855d",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "04/10/13 3:28 PM",
          "commitNameOld": "eb2175db1a99348c80457e3ffda172cc461de8bc",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 2.96,
          "commitsBetweenForRepo": 2,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,14 +1,12 @@\n-  public synchronized CachePool addCachePool(CachePoolInfo info)\n+  public synchronized CachePoolInfo addCachePool(CachePoolInfo info)\n       throws IOException {\n     CachePoolInfo.validate(info);\n     String poolName \u003d info.getPoolName();\n     CachePool pool \u003d cachePools.get(poolName);\n     if (pool !\u003d null) {\n       throw new IOException(\"cache pool \" + poolName + \" already exists.\");\n     }\n-    CachePool cachePool \u003d new CachePool(poolName,\n-      info.getOwnerName(), info.getGroupName(), info.getMode(),\n-      info.getWeight());\n-    unprotectedAddCachePool(cachePool);\n-    return cachePool;\n+    pool \u003d CachePool.createFromInfoAndDefaults(info);\n+    cachePools.put(pool.getPoolName(), pool);\n+    return pool.getInfo(true);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public synchronized CachePoolInfo addCachePool(CachePoolInfo info)\n      throws IOException {\n    CachePoolInfo.validate(info);\n    String poolName \u003d info.getPoolName();\n    CachePool pool \u003d cachePools.get(poolName);\n    if (pool !\u003d null) {\n      throw new IOException(\"cache pool \" + poolName + \" already exists.\");\n    }\n    pool \u003d CachePool.createFromInfoAndDefaults(info);\n    cachePools.put(pool.getPoolName(), pool);\n    return pool.getInfo(true);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "af1ac9a5e8d8d97a855940d853dd59ab4666f6e2": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-5119. Persist CacheManager state in the edit log. (Contributed by Andrew Wang)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1529238 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/10/13 10:46 AM",
      "commitName": "af1ac9a5e8d8d97a855940d853dd59ab4666f6e2",
      "commitAuthor": "Andrew Wang",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-5119. Persist CacheManager state in the edit log. (Contributed by Andrew Wang)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1529238 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "04/10/13 10:46 AM",
          "commitName": "af1ac9a5e8d8d97a855940d853dd59ab4666f6e2",
          "commitAuthor": "Andrew Wang",
          "commitDateOld": "20/09/13 5:20 PM",
          "commitNameOld": "a0d9a155a4a4258f628e927e096ecf6673f788ec",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 13.73,
          "commitsBetweenForRepo": 5,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,14 +1,14 @@\n-  public synchronized void addCachePool(CachePoolInfo info)\n+  public synchronized CachePool addCachePool(CachePoolInfo info)\n       throws IOException {\n     CachePoolInfo.validate(info);\n     String poolName \u003d info.getPoolName();\n     CachePool pool \u003d cachePools.get(poolName);\n     if (pool !\u003d null) {\n       throw new IOException(\"cache pool \" + poolName + \" already exists.\");\n     }\n     CachePool cachePool \u003d new CachePool(poolName,\n       info.getOwnerName(), info.getGroupName(), info.getMode(),\n       info.getWeight());\n-    cachePools.put(poolName, cachePool);\n-    LOG.info(\"created new cache pool \" + cachePool);\n+    unprotectedAddCachePool(cachePool);\n+    return cachePool;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public synchronized CachePool addCachePool(CachePoolInfo info)\n      throws IOException {\n    CachePoolInfo.validate(info);\n    String poolName \u003d info.getPoolName();\n    CachePool pool \u003d cachePools.get(poolName);\n    if (pool !\u003d null) {\n      throw new IOException(\"cache pool \" + poolName + \" already exists.\");\n    }\n    CachePool cachePool \u003d new CachePool(poolName,\n      info.getOwnerName(), info.getGroupName(), info.getMode(),\n      info.getWeight());\n    unprotectedAddCachePool(cachePool);\n    return cachePool;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
          "extendedDetails": {
            "oldValue": "void",
            "newValue": "CachePool"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5119. Persist CacheManager state in the edit log. (Contributed by Andrew Wang)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1529238 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "04/10/13 10:46 AM",
          "commitName": "af1ac9a5e8d8d97a855940d853dd59ab4666f6e2",
          "commitAuthor": "Andrew Wang",
          "commitDateOld": "20/09/13 5:20 PM",
          "commitNameOld": "a0d9a155a4a4258f628e927e096ecf6673f788ec",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 13.73,
          "commitsBetweenForRepo": 5,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,14 +1,14 @@\n-  public synchronized void addCachePool(CachePoolInfo info)\n+  public synchronized CachePool addCachePool(CachePoolInfo info)\n       throws IOException {\n     CachePoolInfo.validate(info);\n     String poolName \u003d info.getPoolName();\n     CachePool pool \u003d cachePools.get(poolName);\n     if (pool !\u003d null) {\n       throw new IOException(\"cache pool \" + poolName + \" already exists.\");\n     }\n     CachePool cachePool \u003d new CachePool(poolName,\n       info.getOwnerName(), info.getGroupName(), info.getMode(),\n       info.getWeight());\n-    cachePools.put(poolName, cachePool);\n-    LOG.info(\"created new cache pool \" + cachePool);\n+    unprotectedAddCachePool(cachePool);\n+    return cachePool;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public synchronized CachePool addCachePool(CachePoolInfo info)\n      throws IOException {\n    CachePoolInfo.validate(info);\n    String poolName \u003d info.getPoolName();\n    CachePool pool \u003d cachePools.get(poolName);\n    if (pool !\u003d null) {\n      throw new IOException(\"cache pool \" + poolName + \" already exists.\");\n    }\n    CachePool cachePool \u003d new CachePool(poolName,\n      info.getOwnerName(), info.getGroupName(), info.getMode(),\n      info.getWeight());\n    unprotectedAddCachePool(cachePool);\n    return cachePool;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "a0d9a155a4a4258f628e927e096ecf6673f788ec": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5236. Change PathBasedCacheDirective APIs to be a single value rather than batch. (Contributed by Andrew Wang)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1525183 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/09/13 5:20 PM",
      "commitName": "a0d9a155a4a4258f628e927e096ecf6673f788ec",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "18/09/13 1:43 PM",
      "commitNameOld": "e202d4d1548a0be2f5c61ff82be8b52bd0cfce04",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 2.15,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,14 @@\n   public synchronized void addCachePool(CachePoolInfo info)\n       throws IOException {\n+    CachePoolInfo.validate(info);\n     String poolName \u003d info.getPoolName();\n-    CachePool.validateName(poolName);\n     CachePool pool \u003d cachePools.get(poolName);\n     if (pool !\u003d null) {\n       throw new IOException(\"cache pool \" + poolName + \" already exists.\");\n     }\n     CachePool cachePool \u003d new CachePool(poolName,\n       info.getOwnerName(), info.getGroupName(), info.getMode(),\n       info.getWeight());\n     cachePools.put(poolName, cachePool);\n     LOG.info(\"created new cache pool \" + cachePool);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void addCachePool(CachePoolInfo info)\n      throws IOException {\n    CachePoolInfo.validate(info);\n    String poolName \u003d info.getPoolName();\n    CachePool pool \u003d cachePools.get(poolName);\n    if (pool !\u003d null) {\n      throw new IOException(\"cache pool \" + poolName + \" already exists.\");\n    }\n    CachePool cachePool \u003d new CachePool(poolName,\n      info.getOwnerName(), info.getGroupName(), info.getMode(),\n      info.getWeight());\n    cachePools.put(poolName, cachePool);\n    LOG.info(\"created new cache pool \" + cachePool);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
      "extendedDetails": {}
    },
    "3a9cd79e9ddd5a9499e28633ccccdc9eef22b813": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5120. Add command-line support for manipulating cache pools.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1521240 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/09/13 11:53 AM",
      "commitName": "3a9cd79e9ddd5a9499e28633ccccdc9eef22b813",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "06/09/13 11:52 AM",
      "commitNameOld": "f41f8b8842c3f26d19f7fa928070c7c07f760e4c",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 3.0,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,14 @@\n   public synchronized void addCachePool(CachePoolInfo info)\n       throws IOException {\n     String poolName \u003d info.getPoolName();\n-    if (poolName.isEmpty()) {\n-      throw new IOException(\"invalid empty cache pool name\");\n-    }\n+    CachePool.validateName(poolName);\n     CachePool pool \u003d cachePools.get(poolName);\n     if (pool !\u003d null) {\n       throw new IOException(\"cache pool \" + poolName + \" already exists.\");\n     }\n     CachePool cachePool \u003d new CachePool(poolName,\n       info.getOwnerName(), info.getGroupName(), info.getMode(),\n       info.getWeight());\n     cachePools.put(poolName, cachePool);\n     LOG.info(\"created new cache pool \" + cachePool);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void addCachePool(CachePoolInfo info)\n      throws IOException {\n    String poolName \u003d info.getPoolName();\n    CachePool.validateName(poolName);\n    CachePool pool \u003d cachePools.get(poolName);\n    if (pool !\u003d null) {\n      throw new IOException(\"cache pool \" + poolName + \" already exists.\");\n    }\n    CachePool cachePool \u003d new CachePool(poolName,\n      info.getOwnerName(), info.getGroupName(), info.getMode(),\n      info.getWeight());\n    cachePools.put(poolName, cachePool);\n    LOG.info(\"created new cache pool \" + cachePool);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
      "extendedDetails": {}
    },
    "f41f8b8842c3f26d19f7fa928070c7c07f760e4c": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-5163. Miscellaneous cache pool RPC fixes (Contributed by Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1520665 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "06/09/13 11:52 AM",
      "commitName": "f41f8b8842c3f26d19f7fa928070c7c07f760e4c",
      "commitAuthor": "Colin McCabe",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-5163. Miscellaneous cache pool RPC fixes (Contributed by Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1520665 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "06/09/13 11:52 AM",
          "commitName": "f41f8b8842c3f26d19f7fa928070c7c07f760e4c",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "04/09/13 11:23 AM",
          "commitNameOld": "d56d0b46e1b82ae068083ddb99872d314684dc82",
          "commitAuthorOld": "Colin McCabe",
          "daysBetweenCommits": 2.02,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,17 +1,16 @@\n-  public synchronized CachePool addCachePool(CachePoolInfo info)\n+  public synchronized void addCachePool(CachePoolInfo info)\n       throws IOException {\n     String poolName \u003d info.getPoolName();\n-    if (poolName \u003d\u003d null || poolName.isEmpty()) {\n+    if (poolName.isEmpty()) {\n       throw new IOException(\"invalid empty cache pool name\");\n     }\n-    if (cachePoolsByName.containsKey(poolName)) {\n+    CachePool pool \u003d cachePools.get(poolName);\n+    if (pool !\u003d null) {\n       throw new IOException(\"cache pool \" + poolName + \" already exists.\");\n     }\n-    CachePool cachePool \u003d new CachePool(getNextPoolId(), poolName,\n+    CachePool cachePool \u003d new CachePool(poolName,\n       info.getOwnerName(), info.getGroupName(), info.getMode(),\n       info.getWeight());\n-    cachePoolsById.put(cachePool.getId(), cachePool);\n-    cachePoolsByName.put(poolName, cachePool);\n+    cachePools.put(poolName, cachePool);\n     LOG.info(\"created new cache pool \" + cachePool);\n-    return cachePool;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public synchronized void addCachePool(CachePoolInfo info)\n      throws IOException {\n    String poolName \u003d info.getPoolName();\n    if (poolName.isEmpty()) {\n      throw new IOException(\"invalid empty cache pool name\");\n    }\n    CachePool pool \u003d cachePools.get(poolName);\n    if (pool !\u003d null) {\n      throw new IOException(\"cache pool \" + poolName + \" already exists.\");\n    }\n    CachePool cachePool \u003d new CachePool(poolName,\n      info.getOwnerName(), info.getGroupName(), info.getMode(),\n      info.getWeight());\n    cachePools.put(poolName, cachePool);\n    LOG.info(\"created new cache pool \" + cachePool);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
          "extendedDetails": {
            "oldValue": "CachePool",
            "newValue": "void"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5163. Miscellaneous cache pool RPC fixes (Contributed by Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1520665 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "06/09/13 11:52 AM",
          "commitName": "f41f8b8842c3f26d19f7fa928070c7c07f760e4c",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "04/09/13 11:23 AM",
          "commitNameOld": "d56d0b46e1b82ae068083ddb99872d314684dc82",
          "commitAuthorOld": "Colin McCabe",
          "daysBetweenCommits": 2.02,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,17 +1,16 @@\n-  public synchronized CachePool addCachePool(CachePoolInfo info)\n+  public synchronized void addCachePool(CachePoolInfo info)\n       throws IOException {\n     String poolName \u003d info.getPoolName();\n-    if (poolName \u003d\u003d null || poolName.isEmpty()) {\n+    if (poolName.isEmpty()) {\n       throw new IOException(\"invalid empty cache pool name\");\n     }\n-    if (cachePoolsByName.containsKey(poolName)) {\n+    CachePool pool \u003d cachePools.get(poolName);\n+    if (pool !\u003d null) {\n       throw new IOException(\"cache pool \" + poolName + \" already exists.\");\n     }\n-    CachePool cachePool \u003d new CachePool(getNextPoolId(), poolName,\n+    CachePool cachePool \u003d new CachePool(poolName,\n       info.getOwnerName(), info.getGroupName(), info.getMode(),\n       info.getWeight());\n-    cachePoolsById.put(cachePool.getId(), cachePool);\n-    cachePoolsByName.put(poolName, cachePool);\n+    cachePools.put(poolName, cachePool);\n     LOG.info(\"created new cache pool \" + cachePool);\n-    return cachePool;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public synchronized void addCachePool(CachePoolInfo info)\n      throws IOException {\n    String poolName \u003d info.getPoolName();\n    if (poolName.isEmpty()) {\n      throw new IOException(\"invalid empty cache pool name\");\n    }\n    CachePool pool \u003d cachePools.get(poolName);\n    if (pool !\u003d null) {\n      throw new IOException(\"cache pool \" + poolName + \" already exists.\");\n    }\n    CachePool cachePool \u003d new CachePool(poolName,\n      info.getOwnerName(), info.getGroupName(), info.getMode(),\n      info.getWeight());\n    cachePools.put(poolName, cachePool);\n    LOG.info(\"created new cache pool \" + cachePool);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "d56d0b46e1b82ae068083ddb99872d314684dc82": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": "commit correct version of HDFS-5121\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1520090 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/09/13 11:23 AM",
      "commitName": "d56d0b46e1b82ae068083ddb99872d314684dc82",
      "commitAuthor": "Colin McCabe",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "commit correct version of HDFS-5121\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1520090 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "04/09/13 11:23 AM",
          "commitName": "d56d0b46e1b82ae068083ddb99872d314684dc82",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "03/09/13 1:38 PM",
          "commitNameOld": "97b7267977ef42201e5844df49bc37ec3d10ce16",
          "commitAuthorOld": "Colin McCabe",
          "daysBetweenCommits": 0.91,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,16 +1,17 @@\n-  public synchronized void addCachePool(CachePoolInfo info)\n+  public synchronized CachePool addCachePool(CachePoolInfo info)\n       throws IOException {\n     String poolName \u003d info.getPoolName();\n-    if (poolName.isEmpty()) {\n+    if (poolName \u003d\u003d null || poolName.isEmpty()) {\n       throw new IOException(\"invalid empty cache pool name\");\n     }\n-    CachePool pool \u003d cachePools.get(poolName);\n-    if (pool !\u003d null) {\n+    if (cachePoolsByName.containsKey(poolName)) {\n       throw new IOException(\"cache pool \" + poolName + \" already exists.\");\n     }\n-    CachePool cachePool \u003d new CachePool(poolName,\n+    CachePool cachePool \u003d new CachePool(getNextPoolId(), poolName,\n       info.getOwnerName(), info.getGroupName(), info.getMode(),\n       info.getWeight());\n-    cachePools.put(poolName, cachePool);\n+    cachePoolsById.put(cachePool.getId(), cachePool);\n+    cachePoolsByName.put(poolName, cachePool);\n     LOG.info(\"created new cache pool \" + cachePool);\n+    return cachePool;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public synchronized CachePool addCachePool(CachePoolInfo info)\n      throws IOException {\n    String poolName \u003d info.getPoolName();\n    if (poolName \u003d\u003d null || poolName.isEmpty()) {\n      throw new IOException(\"invalid empty cache pool name\");\n    }\n    if (cachePoolsByName.containsKey(poolName)) {\n      throw new IOException(\"cache pool \" + poolName + \" already exists.\");\n    }\n    CachePool cachePool \u003d new CachePool(getNextPoolId(), poolName,\n      info.getOwnerName(), info.getGroupName(), info.getMode(),\n      info.getWeight());\n    cachePoolsById.put(cachePool.getId(), cachePool);\n    cachePoolsByName.put(poolName, cachePool);\n    LOG.info(\"created new cache pool \" + cachePool);\n    return cachePool;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
          "extendedDetails": {
            "oldValue": "void",
            "newValue": "CachePool"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "commit correct version of HDFS-5121\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1520090 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "04/09/13 11:23 AM",
          "commitName": "d56d0b46e1b82ae068083ddb99872d314684dc82",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "03/09/13 1:38 PM",
          "commitNameOld": "97b7267977ef42201e5844df49bc37ec3d10ce16",
          "commitAuthorOld": "Colin McCabe",
          "daysBetweenCommits": 0.91,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,16 +1,17 @@\n-  public synchronized void addCachePool(CachePoolInfo info)\n+  public synchronized CachePool addCachePool(CachePoolInfo info)\n       throws IOException {\n     String poolName \u003d info.getPoolName();\n-    if (poolName.isEmpty()) {\n+    if (poolName \u003d\u003d null || poolName.isEmpty()) {\n       throw new IOException(\"invalid empty cache pool name\");\n     }\n-    CachePool pool \u003d cachePools.get(poolName);\n-    if (pool !\u003d null) {\n+    if (cachePoolsByName.containsKey(poolName)) {\n       throw new IOException(\"cache pool \" + poolName + \" already exists.\");\n     }\n-    CachePool cachePool \u003d new CachePool(poolName,\n+    CachePool cachePool \u003d new CachePool(getNextPoolId(), poolName,\n       info.getOwnerName(), info.getGroupName(), info.getMode(),\n       info.getWeight());\n-    cachePools.put(poolName, cachePool);\n+    cachePoolsById.put(cachePool.getId(), cachePool);\n+    cachePoolsByName.put(poolName, cachePool);\n     LOG.info(\"created new cache pool \" + cachePool);\n+    return cachePool;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public synchronized CachePool addCachePool(CachePoolInfo info)\n      throws IOException {\n    String poolName \u003d info.getPoolName();\n    if (poolName \u003d\u003d null || poolName.isEmpty()) {\n      throw new IOException(\"invalid empty cache pool name\");\n    }\n    if (cachePoolsByName.containsKey(poolName)) {\n      throw new IOException(\"cache pool \" + poolName + \" already exists.\");\n    }\n    CachePool cachePool \u003d new CachePool(getNextPoolId(), poolName,\n      info.getOwnerName(), info.getGroupName(), info.getMode(),\n      info.getWeight());\n    cachePoolsById.put(cachePool.getId(), cachePool);\n    cachePoolsByName.put(poolName, cachePool);\n    LOG.info(\"created new cache pool \" + cachePool);\n    return cachePool;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "97b7267977ef42201e5844df49bc37ec3d10ce16": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-5121.  Add RPCs for creating and manipulating cache pools.  (Contributed by Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1519841 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "03/09/13 1:38 PM",
      "commitName": "97b7267977ef42201e5844df49bc37ec3d10ce16",
      "commitAuthor": "Colin McCabe",
      "diff": "@@ -0,0 +1,16 @@\n+  public synchronized void addCachePool(CachePoolInfo info)\n+      throws IOException {\n+    String poolName \u003d info.getPoolName();\n+    if (poolName.isEmpty()) {\n+      throw new IOException(\"invalid empty cache pool name\");\n+    }\n+    CachePool pool \u003d cachePools.get(poolName);\n+    if (pool !\u003d null) {\n+      throw new IOException(\"cache pool \" + poolName + \" already exists.\");\n+    }\n+    CachePool cachePool \u003d new CachePool(poolName,\n+      info.getOwnerName(), info.getGroupName(), info.getMode(),\n+      info.getWeight());\n+    cachePools.put(poolName, cachePool);\n+    LOG.info(\"created new cache pool \" + cachePool);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void addCachePool(CachePoolInfo info)\n      throws IOException {\n    String poolName \u003d info.getPoolName();\n    if (poolName.isEmpty()) {\n      throw new IOException(\"invalid empty cache pool name\");\n    }\n    CachePool pool \u003d cachePools.get(poolName);\n    if (pool !\u003d null) {\n      throw new IOException(\"cache pool \" + poolName + \" already exists.\");\n    }\n    CachePool cachePool \u003d new CachePool(poolName,\n      info.getOwnerName(), info.getGroupName(), info.getMode(),\n      info.getWeight());\n    cachePools.put(poolName, cachePool);\n    LOG.info(\"created new cache pool \" + cachePool);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java"
    }
  }
}