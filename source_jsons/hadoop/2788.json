{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DataNodeUsageReportUtil.java",
  "functionName": "getUsageReport",
  "functionId": "getUsageReport___bWritten-long__bRead-long__wTime-long__rTime-long__wBlockOp-long__rBlockOp-long__timeSinceLastReport-long",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/server/protocol/DataNodeUsageReportUtil.java",
  "functionStartLine": 41,
  "functionEndLine": 70,
  "numCommitsSeen": 2,
  "timeTaken": 453,
  "changeHistory": [
    "1c1ce63cda9216ea4343bb5f3f2a21af49a9574d"
  ],
  "changeHistoryShort": {
    "1c1ce63cda9216ea4343bb5f3f2a21af49a9574d": "Yintroduced"
  },
  "changeHistoryDetails": {
    "1c1ce63cda9216ea4343bb5f3f2a21af49a9574d": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-13055. Aggregate usage statistics from datanodes. Contributed by Ajay Kumar.\n",
      "commitDate": "22/04/18 8:07 AM",
      "commitName": "1c1ce63cda9216ea4343bb5f3f2a21af49a9574d",
      "commitAuthor": "Arpit Agarwal",
      "diff": "@@ -0,0 +1,30 @@\n+  public DataNodeUsageReport getUsageReport(long bWritten, long\n+      bRead, long wTime, long rTime, long wBlockOp, long\n+      rBlockOp, long timeSinceLastReport) {\n+    if (timeSinceLastReport \u003d\u003d 0) {\n+      if (lastReport \u003d\u003d null) {\n+        lastReport \u003d DataNodeUsageReport.EMPTY_REPORT;\n+      }\n+      return lastReport;\n+    }\n+    DataNodeUsageReport.Builder builder \u003d new DataNodeUsageReport.Builder();\n+    DataNodeUsageReport report \u003d builder.setBytesWrittenPerSec(\n+        getBytesWrittenPerSec(bWritten, timeSinceLastReport))\n+        .setBytesReadPerSec(getBytesReadPerSec(bRead, timeSinceLastReport))\n+        .setWriteTime(getWriteTime(wTime))\n+        .setReadTime(getReadTime(rTime)).setBlocksWrittenPerSec(\n+            getWriteBlockOpPerSec(wBlockOp, timeSinceLastReport))\n+        .setBlocksReadPerSec(\n+            getReadBlockOpPerSec(rBlockOp, timeSinceLastReport))\n+        .setTimestamp(Time.monotonicNow()).build();\n+\n+    // Save raw metrics\n+    this.bytesRead \u003d bRead;\n+    this.bytesWritten \u003d bWritten;\n+    this.blocksWritten \u003d wBlockOp;\n+    this.blocksRead \u003d rBlockOp;\n+    this.readTime \u003d rTime;\n+    this.writeTime \u003d wTime;\n+    lastReport \u003d report;\n+    return report;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public DataNodeUsageReport getUsageReport(long bWritten, long\n      bRead, long wTime, long rTime, long wBlockOp, long\n      rBlockOp, long timeSinceLastReport) {\n    if (timeSinceLastReport \u003d\u003d 0) {\n      if (lastReport \u003d\u003d null) {\n        lastReport \u003d DataNodeUsageReport.EMPTY_REPORT;\n      }\n      return lastReport;\n    }\n    DataNodeUsageReport.Builder builder \u003d new DataNodeUsageReport.Builder();\n    DataNodeUsageReport report \u003d builder.setBytesWrittenPerSec(\n        getBytesWrittenPerSec(bWritten, timeSinceLastReport))\n        .setBytesReadPerSec(getBytesReadPerSec(bRead, timeSinceLastReport))\n        .setWriteTime(getWriteTime(wTime))\n        .setReadTime(getReadTime(rTime)).setBlocksWrittenPerSec(\n            getWriteBlockOpPerSec(wBlockOp, timeSinceLastReport))\n        .setBlocksReadPerSec(\n            getReadBlockOpPerSec(rBlockOp, timeSinceLastReport))\n        .setTimestamp(Time.monotonicNow()).build();\n\n    // Save raw metrics\n    this.bytesRead \u003d bRead;\n    this.bytesWritten \u003d bWritten;\n    this.blocksWritten \u003d wBlockOp;\n    this.blocksRead \u003d rBlockOp;\n    this.readTime \u003d rTime;\n    this.writeTime \u003d wTime;\n    lastReport \u003d report;\n    return report;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/server/protocol/DataNodeUsageReportUtil.java"
    }
  }
}