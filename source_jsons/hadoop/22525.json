{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "CombineFileInputFormat.java",
  "functionName": "createSplits",
  "functionId": "createSplits___nodeToBlocks-Map__String,Set__OneBlockInfo______blockToNodes-Map__OneBlockInfo,String[]____rackToBlocks-Map__String,List__OneBlockInfo______totLength-long__maxSize-long__minSizeNode-long__minSizeRack-long__splits-List__InputSplit__",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/input/CombineFileInputFormat.java",
  "functionStartLine": 313,
  "functionEndLine": 536,
  "numCommitsSeen": 21,
  "timeTaken": 2195,
  "changeHistory": [
    "1e94e5977f9075af2f74e30a3b8e52f7ded67863",
    "551615fa13f65ae996bae9c1bacff189539b6557",
    "381a4c42135916245c8992daa3d03f38e282108d",
    "0b9ed2364a0690d62a0d51d636027acb984e3e91"
  ],
  "changeHistoryShort": {
    "1e94e5977f9075af2f74e30a3b8e52f7ded67863": "Ybodychange",
    "551615fa13f65ae996bae9c1bacff189539b6557": "Ybodychange",
    "381a4c42135916245c8992daa3d03f38e282108d": "Ymultichange(Yparameterchange,Ybodychange)",
    "0b9ed2364a0690d62a0d51d636027acb984e3e91": "Yintroduced"
  },
  "changeHistoryDetails": {
    "1e94e5977f9075af2f74e30a3b8e52f7ded67863": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-7063. Fix log level inconsistency in CombineFileInputFormat.java\n\nSigned-off-by: Akira Ajisaka \u003caajisaka@apache.org\u003e\n",
      "commitDate": "18/06/18 2:25 PM",
      "commitName": "1e94e5977f9075af2f74e30a3b8e52f7ded67863",
      "commitAuthor": "Vidura Mudalige",
      "commitDateOld": "02/11/17 1:43 AM",
      "commitNameOld": "178751ed8c9d47038acf8616c226f1f52e884feb",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 228.53,
      "commitsBetweenForRepo": 2210,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,224 +1,224 @@\n   void createSplits(Map\u003cString, Set\u003cOneBlockInfo\u003e\u003e nodeToBlocks,\n                      Map\u003cOneBlockInfo, String[]\u003e blockToNodes,\n                      Map\u003cString, List\u003cOneBlockInfo\u003e\u003e rackToBlocks,\n                      long totLength,\n                      long maxSize,\n                      long minSizeNode,\n                      long minSizeRack,\n                      List\u003cInputSplit\u003e splits                     \n                     ) {\n     ArrayList\u003cOneBlockInfo\u003e validBlocks \u003d new ArrayList\u003cOneBlockInfo\u003e();\n     long curSplitSize \u003d 0;\n     \n     int totalNodes \u003d nodeToBlocks.size();\n     long totalLength \u003d totLength;\n \n     Multiset\u003cString\u003e splitsPerNode \u003d HashMultiset.create();\n     Set\u003cString\u003e completedNodes \u003d new HashSet\u003cString\u003e();\n     \n     while(true) {\n       for (Iterator\u003cMap.Entry\u003cString, Set\u003cOneBlockInfo\u003e\u003e\u003e iter \u003d nodeToBlocks\n           .entrySet().iterator(); iter.hasNext();) {\n         Map.Entry\u003cString, Set\u003cOneBlockInfo\u003e\u003e one \u003d iter.next();\n         \n         String node \u003d one.getKey();\n         \n         // Skip the node if it has previously been marked as completed.\n         if (completedNodes.contains(node)) {\n           continue;\n         }\n \n         Set\u003cOneBlockInfo\u003e blocksInCurrentNode \u003d one.getValue();\n \n         // for each block, copy it into validBlocks. Delete it from\n         // blockToNodes so that the same block does not appear in\n         // two different splits.\n         Iterator\u003cOneBlockInfo\u003e oneBlockIter \u003d blocksInCurrentNode.iterator();\n         while (oneBlockIter.hasNext()) {\n           OneBlockInfo oneblock \u003d oneBlockIter.next();\n           \n           // Remove all blocks which may already have been assigned to other\n           // splits.\n           if(!blockToNodes.containsKey(oneblock)) {\n             oneBlockIter.remove();\n             continue;\n           }\n         \n           validBlocks.add(oneblock);\n           blockToNodes.remove(oneblock);\n           curSplitSize +\u003d oneblock.length;\n \n           // if the accumulated split size exceeds the maximum, then\n           // create this split.\n           if (maxSize !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d maxSize) {\n             // create an input split and add it to the splits array\n             addCreatedSplit(splits, Collections.singleton(node), validBlocks);\n             totalLength -\u003d curSplitSize;\n             curSplitSize \u003d 0;\n \n             splitsPerNode.add(node);\n \n             // Remove entries from blocksInNode so that we don\u0027t walk these\n             // again.\n             blocksInCurrentNode.removeAll(validBlocks);\n             validBlocks.clear();\n \n             // Done creating a single split for this node. Move on to the next\n             // node so that splits are distributed across nodes.\n             break;\n           }\n \n         }\n         if (validBlocks.size() !\u003d 0) {\n           // This implies that the last few blocks (or all in case maxSize\u003d0)\n           // were not part of a split. The node is complete.\n           \n           // if there were any blocks left over and their combined size is\n           // larger than minSplitNode, then combine them into one split.\n           // Otherwise add them back to the unprocessed pool. It is likely\n           // that they will be combined with other blocks from the\n           // same rack later on.\n           // This condition also kicks in when max split size is not set. All\n           // blocks on a node will be grouped together into a single split.\n           if (minSizeNode !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d minSizeNode\n               \u0026\u0026 splitsPerNode.count(node) \u003d\u003d 0) {\n             // haven\u0027t created any split on this machine. so its ok to add a\n             // smaller one for parallelism. Otherwise group it in the rack for\n             // balanced size create an input split and add it to the splits\n             // array\n             addCreatedSplit(splits, Collections.singleton(node), validBlocks);\n             totalLength -\u003d curSplitSize;\n             splitsPerNode.add(node);\n             // Remove entries from blocksInNode so that we don\u0027t walk this again.\n             blocksInCurrentNode.removeAll(validBlocks);\n             // The node is done. This was the last set of blocks for this node.\n           } else {\n             // Put the unplaced blocks back into the pool for later rack-allocation.\n             for (OneBlockInfo oneblock : validBlocks) {\n               blockToNodes.put(oneblock, oneblock.hosts);\n             }\n           }\n           validBlocks.clear();\n           curSplitSize \u003d 0;\n           completedNodes.add(node);\n         } else { // No in-flight blocks.\n           if (blocksInCurrentNode.size() \u003d\u003d 0) {\n             // Node is done. All blocks were fit into node-local splits.\n             completedNodes.add(node);\n           } // else Run through the node again.\n         }\n       }\n \n       // Check if node-local assignments are complete.\n       if (completedNodes.size() \u003d\u003d totalNodes || totalLength \u003d\u003d 0) {\n         // All nodes have been walked over and marked as completed or all blocks\n         // have been assigned. The rest should be handled via rackLock assignment.\n-        LOG.info(\"DEBUG: Terminated node allocation with : CompletedNodes: \"\n-            + completedNodes.size() + \", size left: \" + totalLength);\n+        LOG.debug(\"Terminated node allocation with : CompletedNodes: {}, size left: {}\",\n+            completedNodes.size(), totalLength);\n         break;\n       }\n     }\n \n     // if blocks in a rack are below the specified minimum size, then keep them\n     // in \u0027overflow\u0027. After the processing of all racks is complete, these \n     // overflow blocks will be combined into splits.\n     ArrayList\u003cOneBlockInfo\u003e overflowBlocks \u003d new ArrayList\u003cOneBlockInfo\u003e();\n     Set\u003cString\u003e racks \u003d new HashSet\u003cString\u003e();\n \n     // Process all racks over and over again until there is no more work to do.\n     while (blockToNodes.size() \u003e 0) {\n \n       // Create one split for this rack before moving over to the next rack. \n       // Come back to this rack after creating a single split for each of the \n       // remaining racks.\n       // Process one rack location at a time, Combine all possible blocks that\n       // reside on this rack as one split. (constrained by minimum and maximum\n       // split size).\n \n       // iterate over all racks \n       for (Iterator\u003cMap.Entry\u003cString, List\u003cOneBlockInfo\u003e\u003e\u003e iter \u003d \n            rackToBlocks.entrySet().iterator(); iter.hasNext();) {\n \n         Map.Entry\u003cString, List\u003cOneBlockInfo\u003e\u003e one \u003d iter.next();\n         racks.add(one.getKey());\n         List\u003cOneBlockInfo\u003e blocks \u003d one.getValue();\n \n         // for each block, copy it into validBlocks. Delete it from \n         // blockToNodes so that the same block does not appear in \n         // two different splits.\n         boolean createdSplit \u003d false;\n         for (OneBlockInfo oneblock : blocks) {\n           if (blockToNodes.containsKey(oneblock)) {\n             validBlocks.add(oneblock);\n             blockToNodes.remove(oneblock);\n             curSplitSize +\u003d oneblock.length;\n       \n             // if the accumulated split size exceeds the maximum, then \n             // create this split.\n             if (maxSize !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d maxSize) {\n               // create an input split and add it to the splits array\n               addCreatedSplit(splits, getHosts(racks), validBlocks);\n               createdSplit \u003d true;\n               break;\n             }\n           }\n         }\n \n         // if we created a split, then just go to the next rack\n         if (createdSplit) {\n           curSplitSize \u003d 0;\n           validBlocks.clear();\n           racks.clear();\n           continue;\n         }\n \n         if (!validBlocks.isEmpty()) {\n           if (minSizeRack !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d minSizeRack) {\n             // if there is a minimum size specified, then create a single split\n             // otherwise, store these blocks into overflow data structure\n             addCreatedSplit(splits, getHosts(racks), validBlocks);\n           } else {\n             // There were a few blocks in this rack that \n         \t// remained to be processed. Keep them in \u0027overflow\u0027 block list. \n         \t// These will be combined later.\n             overflowBlocks.addAll(validBlocks);\n           }\n         }\n         curSplitSize \u003d 0;\n         validBlocks.clear();\n         racks.clear();\n       }\n     }\n \n     assert blockToNodes.isEmpty();\n     assert curSplitSize \u003d\u003d 0;\n     assert validBlocks.isEmpty();\n     assert racks.isEmpty();\n \n     // Process all overflow blocks\n     for (OneBlockInfo oneblock : overflowBlocks) {\n       validBlocks.add(oneblock);\n       curSplitSize +\u003d oneblock.length;\n \n       // This might cause an exiting rack location to be re-added,\n       // but it should be ok.\n       for (int i \u003d 0; i \u003c oneblock.racks.length; i++) {\n         racks.add(oneblock.racks[i]);\n       }\n \n       // if the accumulated split size exceeds the maximum, then \n       // create this split.\n       if (maxSize !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d maxSize) {\n         // create an input split and add it to the splits array\n         addCreatedSplit(splits, getHosts(racks), validBlocks);\n         curSplitSize \u003d 0;\n         validBlocks.clear();\n         racks.clear();\n       }\n     }\n \n     // Process any remaining blocks, if any.\n     if (!validBlocks.isEmpty()) {\n       addCreatedSplit(splits, getHosts(racks), validBlocks);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void createSplits(Map\u003cString, Set\u003cOneBlockInfo\u003e\u003e nodeToBlocks,\n                     Map\u003cOneBlockInfo, String[]\u003e blockToNodes,\n                     Map\u003cString, List\u003cOneBlockInfo\u003e\u003e rackToBlocks,\n                     long totLength,\n                     long maxSize,\n                     long minSizeNode,\n                     long minSizeRack,\n                     List\u003cInputSplit\u003e splits                     \n                    ) {\n    ArrayList\u003cOneBlockInfo\u003e validBlocks \u003d new ArrayList\u003cOneBlockInfo\u003e();\n    long curSplitSize \u003d 0;\n    \n    int totalNodes \u003d nodeToBlocks.size();\n    long totalLength \u003d totLength;\n\n    Multiset\u003cString\u003e splitsPerNode \u003d HashMultiset.create();\n    Set\u003cString\u003e completedNodes \u003d new HashSet\u003cString\u003e();\n    \n    while(true) {\n      for (Iterator\u003cMap.Entry\u003cString, Set\u003cOneBlockInfo\u003e\u003e\u003e iter \u003d nodeToBlocks\n          .entrySet().iterator(); iter.hasNext();) {\n        Map.Entry\u003cString, Set\u003cOneBlockInfo\u003e\u003e one \u003d iter.next();\n        \n        String node \u003d one.getKey();\n        \n        // Skip the node if it has previously been marked as completed.\n        if (completedNodes.contains(node)) {\n          continue;\n        }\n\n        Set\u003cOneBlockInfo\u003e blocksInCurrentNode \u003d one.getValue();\n\n        // for each block, copy it into validBlocks. Delete it from\n        // blockToNodes so that the same block does not appear in\n        // two different splits.\n        Iterator\u003cOneBlockInfo\u003e oneBlockIter \u003d blocksInCurrentNode.iterator();\n        while (oneBlockIter.hasNext()) {\n          OneBlockInfo oneblock \u003d oneBlockIter.next();\n          \n          // Remove all blocks which may already have been assigned to other\n          // splits.\n          if(!blockToNodes.containsKey(oneblock)) {\n            oneBlockIter.remove();\n            continue;\n          }\n        \n          validBlocks.add(oneblock);\n          blockToNodes.remove(oneblock);\n          curSplitSize +\u003d oneblock.length;\n\n          // if the accumulated split size exceeds the maximum, then\n          // create this split.\n          if (maxSize !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d maxSize) {\n            // create an input split and add it to the splits array\n            addCreatedSplit(splits, Collections.singleton(node), validBlocks);\n            totalLength -\u003d curSplitSize;\n            curSplitSize \u003d 0;\n\n            splitsPerNode.add(node);\n\n            // Remove entries from blocksInNode so that we don\u0027t walk these\n            // again.\n            blocksInCurrentNode.removeAll(validBlocks);\n            validBlocks.clear();\n\n            // Done creating a single split for this node. Move on to the next\n            // node so that splits are distributed across nodes.\n            break;\n          }\n\n        }\n        if (validBlocks.size() !\u003d 0) {\n          // This implies that the last few blocks (or all in case maxSize\u003d0)\n          // were not part of a split. The node is complete.\n          \n          // if there were any blocks left over and their combined size is\n          // larger than minSplitNode, then combine them into one split.\n          // Otherwise add them back to the unprocessed pool. It is likely\n          // that they will be combined with other blocks from the\n          // same rack later on.\n          // This condition also kicks in when max split size is not set. All\n          // blocks on a node will be grouped together into a single split.\n          if (minSizeNode !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d minSizeNode\n              \u0026\u0026 splitsPerNode.count(node) \u003d\u003d 0) {\n            // haven\u0027t created any split on this machine. so its ok to add a\n            // smaller one for parallelism. Otherwise group it in the rack for\n            // balanced size create an input split and add it to the splits\n            // array\n            addCreatedSplit(splits, Collections.singleton(node), validBlocks);\n            totalLength -\u003d curSplitSize;\n            splitsPerNode.add(node);\n            // Remove entries from blocksInNode so that we don\u0027t walk this again.\n            blocksInCurrentNode.removeAll(validBlocks);\n            // The node is done. This was the last set of blocks for this node.\n          } else {\n            // Put the unplaced blocks back into the pool for later rack-allocation.\n            for (OneBlockInfo oneblock : validBlocks) {\n              blockToNodes.put(oneblock, oneblock.hosts);\n            }\n          }\n          validBlocks.clear();\n          curSplitSize \u003d 0;\n          completedNodes.add(node);\n        } else { // No in-flight blocks.\n          if (blocksInCurrentNode.size() \u003d\u003d 0) {\n            // Node is done. All blocks were fit into node-local splits.\n            completedNodes.add(node);\n          } // else Run through the node again.\n        }\n      }\n\n      // Check if node-local assignments are complete.\n      if (completedNodes.size() \u003d\u003d totalNodes || totalLength \u003d\u003d 0) {\n        // All nodes have been walked over and marked as completed or all blocks\n        // have been assigned. The rest should be handled via rackLock assignment.\n        LOG.debug(\"Terminated node allocation with : CompletedNodes: {}, size left: {}\",\n            completedNodes.size(), totalLength);\n        break;\n      }\n    }\n\n    // if blocks in a rack are below the specified minimum size, then keep them\n    // in \u0027overflow\u0027. After the processing of all racks is complete, these \n    // overflow blocks will be combined into splits.\n    ArrayList\u003cOneBlockInfo\u003e overflowBlocks \u003d new ArrayList\u003cOneBlockInfo\u003e();\n    Set\u003cString\u003e racks \u003d new HashSet\u003cString\u003e();\n\n    // Process all racks over and over again until there is no more work to do.\n    while (blockToNodes.size() \u003e 0) {\n\n      // Create one split for this rack before moving over to the next rack. \n      // Come back to this rack after creating a single split for each of the \n      // remaining racks.\n      // Process one rack location at a time, Combine all possible blocks that\n      // reside on this rack as one split. (constrained by minimum and maximum\n      // split size).\n\n      // iterate over all racks \n      for (Iterator\u003cMap.Entry\u003cString, List\u003cOneBlockInfo\u003e\u003e\u003e iter \u003d \n           rackToBlocks.entrySet().iterator(); iter.hasNext();) {\n\n        Map.Entry\u003cString, List\u003cOneBlockInfo\u003e\u003e one \u003d iter.next();\n        racks.add(one.getKey());\n        List\u003cOneBlockInfo\u003e blocks \u003d one.getValue();\n\n        // for each block, copy it into validBlocks. Delete it from \n        // blockToNodes so that the same block does not appear in \n        // two different splits.\n        boolean createdSplit \u003d false;\n        for (OneBlockInfo oneblock : blocks) {\n          if (blockToNodes.containsKey(oneblock)) {\n            validBlocks.add(oneblock);\n            blockToNodes.remove(oneblock);\n            curSplitSize +\u003d oneblock.length;\n      \n            // if the accumulated split size exceeds the maximum, then \n            // create this split.\n            if (maxSize !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d maxSize) {\n              // create an input split and add it to the splits array\n              addCreatedSplit(splits, getHosts(racks), validBlocks);\n              createdSplit \u003d true;\n              break;\n            }\n          }\n        }\n\n        // if we created a split, then just go to the next rack\n        if (createdSplit) {\n          curSplitSize \u003d 0;\n          validBlocks.clear();\n          racks.clear();\n          continue;\n        }\n\n        if (!validBlocks.isEmpty()) {\n          if (minSizeRack !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d minSizeRack) {\n            // if there is a minimum size specified, then create a single split\n            // otherwise, store these blocks into overflow data structure\n            addCreatedSplit(splits, getHosts(racks), validBlocks);\n          } else {\n            // There were a few blocks in this rack that \n        \t// remained to be processed. Keep them in \u0027overflow\u0027 block list. \n        \t// These will be combined later.\n            overflowBlocks.addAll(validBlocks);\n          }\n        }\n        curSplitSize \u003d 0;\n        validBlocks.clear();\n        racks.clear();\n      }\n    }\n\n    assert blockToNodes.isEmpty();\n    assert curSplitSize \u003d\u003d 0;\n    assert validBlocks.isEmpty();\n    assert racks.isEmpty();\n\n    // Process all overflow blocks\n    for (OneBlockInfo oneblock : overflowBlocks) {\n      validBlocks.add(oneblock);\n      curSplitSize +\u003d oneblock.length;\n\n      // This might cause an exiting rack location to be re-added,\n      // but it should be ok.\n      for (int i \u003d 0; i \u003c oneblock.racks.length; i++) {\n        racks.add(oneblock.racks[i]);\n      }\n\n      // if the accumulated split size exceeds the maximum, then \n      // create this split.\n      if (maxSize !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d maxSize) {\n        // create an input split and add it to the splits array\n        addCreatedSplit(splits, getHosts(racks), validBlocks);\n        curSplitSize \u003d 0;\n        validBlocks.clear();\n        racks.clear();\n      }\n    }\n\n    // Process any remaining blocks, if any.\n    if (!validBlocks.isEmpty()) {\n      addCreatedSplit(splits, getHosts(racks), validBlocks);\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/input/CombineFileInputFormat.java",
      "extendedDetails": {}
    },
    "551615fa13f65ae996bae9c1bacff189539b6557": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6165. [JDK8] TestCombineFileInputFormat failed on JDK8. Contributed by Akira AJISAKA.\n",
      "commitDate": "04/05/15 6:23 PM",
      "commitName": "551615fa13f65ae996bae9c1bacff189539b6557",
      "commitAuthor": "Tsuyoshi Ozawa",
      "commitDateOld": "21/07/14 2:24 PM",
      "commitNameOld": "c2174a55363e8f52acbe21319f072f6678441d47",
      "commitAuthorOld": "Jason Darrell Lowe",
      "daysBetweenCommits": 287.17,
      "commitsBetweenForRepo": 2501,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,229 +1,224 @@\n   void createSplits(Map\u003cString, Set\u003cOneBlockInfo\u003e\u003e nodeToBlocks,\n                      Map\u003cOneBlockInfo, String[]\u003e blockToNodes,\n                      Map\u003cString, List\u003cOneBlockInfo\u003e\u003e rackToBlocks,\n                      long totLength,\n                      long maxSize,\n                      long minSizeNode,\n                      long minSizeRack,\n                      List\u003cInputSplit\u003e splits                     \n                     ) {\n     ArrayList\u003cOneBlockInfo\u003e validBlocks \u003d new ArrayList\u003cOneBlockInfo\u003e();\n     long curSplitSize \u003d 0;\n     \n     int totalNodes \u003d nodeToBlocks.size();\n     long totalLength \u003d totLength;\n \n     Multiset\u003cString\u003e splitsPerNode \u003d HashMultiset.create();\n     Set\u003cString\u003e completedNodes \u003d new HashSet\u003cString\u003e();\n     \n     while(true) {\n-      // it is allowed for maxSize to be 0. Disable smoothing load for such cases\n-\n-      // process all nodes and create splits that are local to a node. Generate\n-      // one split per node iteration, and walk over nodes multiple times to\n-      // distribute the splits across nodes. \n       for (Iterator\u003cMap.Entry\u003cString, Set\u003cOneBlockInfo\u003e\u003e\u003e iter \u003d nodeToBlocks\n           .entrySet().iterator(); iter.hasNext();) {\n         Map.Entry\u003cString, Set\u003cOneBlockInfo\u003e\u003e one \u003d iter.next();\n         \n         String node \u003d one.getKey();\n         \n         // Skip the node if it has previously been marked as completed.\n         if (completedNodes.contains(node)) {\n           continue;\n         }\n \n         Set\u003cOneBlockInfo\u003e blocksInCurrentNode \u003d one.getValue();\n \n         // for each block, copy it into validBlocks. Delete it from\n         // blockToNodes so that the same block does not appear in\n         // two different splits.\n         Iterator\u003cOneBlockInfo\u003e oneBlockIter \u003d blocksInCurrentNode.iterator();\n         while (oneBlockIter.hasNext()) {\n           OneBlockInfo oneblock \u003d oneBlockIter.next();\n           \n           // Remove all blocks which may already have been assigned to other\n           // splits.\n           if(!blockToNodes.containsKey(oneblock)) {\n             oneBlockIter.remove();\n             continue;\n           }\n         \n           validBlocks.add(oneblock);\n           blockToNodes.remove(oneblock);\n           curSplitSize +\u003d oneblock.length;\n \n           // if the accumulated split size exceeds the maximum, then\n           // create this split.\n           if (maxSize !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d maxSize) {\n             // create an input split and add it to the splits array\n             addCreatedSplit(splits, Collections.singleton(node), validBlocks);\n             totalLength -\u003d curSplitSize;\n             curSplitSize \u003d 0;\n \n             splitsPerNode.add(node);\n \n             // Remove entries from blocksInNode so that we don\u0027t walk these\n             // again.\n             blocksInCurrentNode.removeAll(validBlocks);\n             validBlocks.clear();\n \n             // Done creating a single split for this node. Move on to the next\n             // node so that splits are distributed across nodes.\n             break;\n           }\n \n         }\n         if (validBlocks.size() !\u003d 0) {\n           // This implies that the last few blocks (or all in case maxSize\u003d0)\n           // were not part of a split. The node is complete.\n           \n           // if there were any blocks left over and their combined size is\n           // larger than minSplitNode, then combine them into one split.\n           // Otherwise add them back to the unprocessed pool. It is likely\n           // that they will be combined with other blocks from the\n           // same rack later on.\n           // This condition also kicks in when max split size is not set. All\n           // blocks on a node will be grouped together into a single split.\n           if (minSizeNode !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d minSizeNode\n               \u0026\u0026 splitsPerNode.count(node) \u003d\u003d 0) {\n             // haven\u0027t created any split on this machine. so its ok to add a\n             // smaller one for parallelism. Otherwise group it in the rack for\n             // balanced size create an input split and add it to the splits\n             // array\n             addCreatedSplit(splits, Collections.singleton(node), validBlocks);\n             totalLength -\u003d curSplitSize;\n             splitsPerNode.add(node);\n             // Remove entries from blocksInNode so that we don\u0027t walk this again.\n             blocksInCurrentNode.removeAll(validBlocks);\n             // The node is done. This was the last set of blocks for this node.\n           } else {\n             // Put the unplaced blocks back into the pool for later rack-allocation.\n             for (OneBlockInfo oneblock : validBlocks) {\n               blockToNodes.put(oneblock, oneblock.hosts);\n             }\n           }\n           validBlocks.clear();\n           curSplitSize \u003d 0;\n           completedNodes.add(node);\n         } else { // No in-flight blocks.\n           if (blocksInCurrentNode.size() \u003d\u003d 0) {\n             // Node is done. All blocks were fit into node-local splits.\n             completedNodes.add(node);\n           } // else Run through the node again.\n         }\n       }\n \n       // Check if node-local assignments are complete.\n       if (completedNodes.size() \u003d\u003d totalNodes || totalLength \u003d\u003d 0) {\n         // All nodes have been walked over and marked as completed or all blocks\n         // have been assigned. The rest should be handled via rackLock assignment.\n         LOG.info(\"DEBUG: Terminated node allocation with : CompletedNodes: \"\n             + completedNodes.size() + \", size left: \" + totalLength);\n         break;\n       }\n     }\n \n     // if blocks in a rack are below the specified minimum size, then keep them\n     // in \u0027overflow\u0027. After the processing of all racks is complete, these \n     // overflow blocks will be combined into splits.\n     ArrayList\u003cOneBlockInfo\u003e overflowBlocks \u003d new ArrayList\u003cOneBlockInfo\u003e();\n     Set\u003cString\u003e racks \u003d new HashSet\u003cString\u003e();\n \n     // Process all racks over and over again until there is no more work to do.\n     while (blockToNodes.size() \u003e 0) {\n \n       // Create one split for this rack before moving over to the next rack. \n       // Come back to this rack after creating a single split for each of the \n       // remaining racks.\n       // Process one rack location at a time, Combine all possible blocks that\n       // reside on this rack as one split. (constrained by minimum and maximum\n       // split size).\n \n       // iterate over all racks \n       for (Iterator\u003cMap.Entry\u003cString, List\u003cOneBlockInfo\u003e\u003e\u003e iter \u003d \n            rackToBlocks.entrySet().iterator(); iter.hasNext();) {\n \n         Map.Entry\u003cString, List\u003cOneBlockInfo\u003e\u003e one \u003d iter.next();\n         racks.add(one.getKey());\n         List\u003cOneBlockInfo\u003e blocks \u003d one.getValue();\n \n         // for each block, copy it into validBlocks. Delete it from \n         // blockToNodes so that the same block does not appear in \n         // two different splits.\n         boolean createdSplit \u003d false;\n         for (OneBlockInfo oneblock : blocks) {\n           if (blockToNodes.containsKey(oneblock)) {\n             validBlocks.add(oneblock);\n             blockToNodes.remove(oneblock);\n             curSplitSize +\u003d oneblock.length;\n       \n             // if the accumulated split size exceeds the maximum, then \n             // create this split.\n             if (maxSize !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d maxSize) {\n               // create an input split and add it to the splits array\n               addCreatedSplit(splits, getHosts(racks), validBlocks);\n               createdSplit \u003d true;\n               break;\n             }\n           }\n         }\n \n         // if we created a split, then just go to the next rack\n         if (createdSplit) {\n           curSplitSize \u003d 0;\n           validBlocks.clear();\n           racks.clear();\n           continue;\n         }\n \n         if (!validBlocks.isEmpty()) {\n           if (minSizeRack !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d minSizeRack) {\n             // if there is a minimum size specified, then create a single split\n             // otherwise, store these blocks into overflow data structure\n             addCreatedSplit(splits, getHosts(racks), validBlocks);\n           } else {\n             // There were a few blocks in this rack that \n         \t// remained to be processed. Keep them in \u0027overflow\u0027 block list. \n         \t// These will be combined later.\n             overflowBlocks.addAll(validBlocks);\n           }\n         }\n         curSplitSize \u003d 0;\n         validBlocks.clear();\n         racks.clear();\n       }\n     }\n \n     assert blockToNodes.isEmpty();\n     assert curSplitSize \u003d\u003d 0;\n     assert validBlocks.isEmpty();\n     assert racks.isEmpty();\n \n     // Process all overflow blocks\n     for (OneBlockInfo oneblock : overflowBlocks) {\n       validBlocks.add(oneblock);\n       curSplitSize +\u003d oneblock.length;\n \n       // This might cause an exiting rack location to be re-added,\n       // but it should be ok.\n       for (int i \u003d 0; i \u003c oneblock.racks.length; i++) {\n         racks.add(oneblock.racks[i]);\n       }\n \n       // if the accumulated split size exceeds the maximum, then \n       // create this split.\n       if (maxSize !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d maxSize) {\n         // create an input split and add it to the splits array\n         addCreatedSplit(splits, getHosts(racks), validBlocks);\n         curSplitSize \u003d 0;\n         validBlocks.clear();\n         racks.clear();\n       }\n     }\n \n     // Process any remaining blocks, if any.\n     if (!validBlocks.isEmpty()) {\n       addCreatedSplit(splits, getHosts(racks), validBlocks);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void createSplits(Map\u003cString, Set\u003cOneBlockInfo\u003e\u003e nodeToBlocks,\n                     Map\u003cOneBlockInfo, String[]\u003e blockToNodes,\n                     Map\u003cString, List\u003cOneBlockInfo\u003e\u003e rackToBlocks,\n                     long totLength,\n                     long maxSize,\n                     long minSizeNode,\n                     long minSizeRack,\n                     List\u003cInputSplit\u003e splits                     \n                    ) {\n    ArrayList\u003cOneBlockInfo\u003e validBlocks \u003d new ArrayList\u003cOneBlockInfo\u003e();\n    long curSplitSize \u003d 0;\n    \n    int totalNodes \u003d nodeToBlocks.size();\n    long totalLength \u003d totLength;\n\n    Multiset\u003cString\u003e splitsPerNode \u003d HashMultiset.create();\n    Set\u003cString\u003e completedNodes \u003d new HashSet\u003cString\u003e();\n    \n    while(true) {\n      for (Iterator\u003cMap.Entry\u003cString, Set\u003cOneBlockInfo\u003e\u003e\u003e iter \u003d nodeToBlocks\n          .entrySet().iterator(); iter.hasNext();) {\n        Map.Entry\u003cString, Set\u003cOneBlockInfo\u003e\u003e one \u003d iter.next();\n        \n        String node \u003d one.getKey();\n        \n        // Skip the node if it has previously been marked as completed.\n        if (completedNodes.contains(node)) {\n          continue;\n        }\n\n        Set\u003cOneBlockInfo\u003e blocksInCurrentNode \u003d one.getValue();\n\n        // for each block, copy it into validBlocks. Delete it from\n        // blockToNodes so that the same block does not appear in\n        // two different splits.\n        Iterator\u003cOneBlockInfo\u003e oneBlockIter \u003d blocksInCurrentNode.iterator();\n        while (oneBlockIter.hasNext()) {\n          OneBlockInfo oneblock \u003d oneBlockIter.next();\n          \n          // Remove all blocks which may already have been assigned to other\n          // splits.\n          if(!blockToNodes.containsKey(oneblock)) {\n            oneBlockIter.remove();\n            continue;\n          }\n        \n          validBlocks.add(oneblock);\n          blockToNodes.remove(oneblock);\n          curSplitSize +\u003d oneblock.length;\n\n          // if the accumulated split size exceeds the maximum, then\n          // create this split.\n          if (maxSize !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d maxSize) {\n            // create an input split and add it to the splits array\n            addCreatedSplit(splits, Collections.singleton(node), validBlocks);\n            totalLength -\u003d curSplitSize;\n            curSplitSize \u003d 0;\n\n            splitsPerNode.add(node);\n\n            // Remove entries from blocksInNode so that we don\u0027t walk these\n            // again.\n            blocksInCurrentNode.removeAll(validBlocks);\n            validBlocks.clear();\n\n            // Done creating a single split for this node. Move on to the next\n            // node so that splits are distributed across nodes.\n            break;\n          }\n\n        }\n        if (validBlocks.size() !\u003d 0) {\n          // This implies that the last few blocks (or all in case maxSize\u003d0)\n          // were not part of a split. The node is complete.\n          \n          // if there were any blocks left over and their combined size is\n          // larger than minSplitNode, then combine them into one split.\n          // Otherwise add them back to the unprocessed pool. It is likely\n          // that they will be combined with other blocks from the\n          // same rack later on.\n          // This condition also kicks in when max split size is not set. All\n          // blocks on a node will be grouped together into a single split.\n          if (minSizeNode !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d minSizeNode\n              \u0026\u0026 splitsPerNode.count(node) \u003d\u003d 0) {\n            // haven\u0027t created any split on this machine. so its ok to add a\n            // smaller one for parallelism. Otherwise group it in the rack for\n            // balanced size create an input split and add it to the splits\n            // array\n            addCreatedSplit(splits, Collections.singleton(node), validBlocks);\n            totalLength -\u003d curSplitSize;\n            splitsPerNode.add(node);\n            // Remove entries from blocksInNode so that we don\u0027t walk this again.\n            blocksInCurrentNode.removeAll(validBlocks);\n            // The node is done. This was the last set of blocks for this node.\n          } else {\n            // Put the unplaced blocks back into the pool for later rack-allocation.\n            for (OneBlockInfo oneblock : validBlocks) {\n              blockToNodes.put(oneblock, oneblock.hosts);\n            }\n          }\n          validBlocks.clear();\n          curSplitSize \u003d 0;\n          completedNodes.add(node);\n        } else { // No in-flight blocks.\n          if (blocksInCurrentNode.size() \u003d\u003d 0) {\n            // Node is done. All blocks were fit into node-local splits.\n            completedNodes.add(node);\n          } // else Run through the node again.\n        }\n      }\n\n      // Check if node-local assignments are complete.\n      if (completedNodes.size() \u003d\u003d totalNodes || totalLength \u003d\u003d 0) {\n        // All nodes have been walked over and marked as completed or all blocks\n        // have been assigned. The rest should be handled via rackLock assignment.\n        LOG.info(\"DEBUG: Terminated node allocation with : CompletedNodes: \"\n            + completedNodes.size() + \", size left: \" + totalLength);\n        break;\n      }\n    }\n\n    // if blocks in a rack are below the specified minimum size, then keep them\n    // in \u0027overflow\u0027. After the processing of all racks is complete, these \n    // overflow blocks will be combined into splits.\n    ArrayList\u003cOneBlockInfo\u003e overflowBlocks \u003d new ArrayList\u003cOneBlockInfo\u003e();\n    Set\u003cString\u003e racks \u003d new HashSet\u003cString\u003e();\n\n    // Process all racks over and over again until there is no more work to do.\n    while (blockToNodes.size() \u003e 0) {\n\n      // Create one split for this rack before moving over to the next rack. \n      // Come back to this rack after creating a single split for each of the \n      // remaining racks.\n      // Process one rack location at a time, Combine all possible blocks that\n      // reside on this rack as one split. (constrained by minimum and maximum\n      // split size).\n\n      // iterate over all racks \n      for (Iterator\u003cMap.Entry\u003cString, List\u003cOneBlockInfo\u003e\u003e\u003e iter \u003d \n           rackToBlocks.entrySet().iterator(); iter.hasNext();) {\n\n        Map.Entry\u003cString, List\u003cOneBlockInfo\u003e\u003e one \u003d iter.next();\n        racks.add(one.getKey());\n        List\u003cOneBlockInfo\u003e blocks \u003d one.getValue();\n\n        // for each block, copy it into validBlocks. Delete it from \n        // blockToNodes so that the same block does not appear in \n        // two different splits.\n        boolean createdSplit \u003d false;\n        for (OneBlockInfo oneblock : blocks) {\n          if (blockToNodes.containsKey(oneblock)) {\n            validBlocks.add(oneblock);\n            blockToNodes.remove(oneblock);\n            curSplitSize +\u003d oneblock.length;\n      \n            // if the accumulated split size exceeds the maximum, then \n            // create this split.\n            if (maxSize !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d maxSize) {\n              // create an input split and add it to the splits array\n              addCreatedSplit(splits, getHosts(racks), validBlocks);\n              createdSplit \u003d true;\n              break;\n            }\n          }\n        }\n\n        // if we created a split, then just go to the next rack\n        if (createdSplit) {\n          curSplitSize \u003d 0;\n          validBlocks.clear();\n          racks.clear();\n          continue;\n        }\n\n        if (!validBlocks.isEmpty()) {\n          if (minSizeRack !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d minSizeRack) {\n            // if there is a minimum size specified, then create a single split\n            // otherwise, store these blocks into overflow data structure\n            addCreatedSplit(splits, getHosts(racks), validBlocks);\n          } else {\n            // There were a few blocks in this rack that \n        \t// remained to be processed. Keep them in \u0027overflow\u0027 block list. \n        \t// These will be combined later.\n            overflowBlocks.addAll(validBlocks);\n          }\n        }\n        curSplitSize \u003d 0;\n        validBlocks.clear();\n        racks.clear();\n      }\n    }\n\n    assert blockToNodes.isEmpty();\n    assert curSplitSize \u003d\u003d 0;\n    assert validBlocks.isEmpty();\n    assert racks.isEmpty();\n\n    // Process all overflow blocks\n    for (OneBlockInfo oneblock : overflowBlocks) {\n      validBlocks.add(oneblock);\n      curSplitSize +\u003d oneblock.length;\n\n      // This might cause an exiting rack location to be re-added,\n      // but it should be ok.\n      for (int i \u003d 0; i \u003c oneblock.racks.length; i++) {\n        racks.add(oneblock.racks[i]);\n      }\n\n      // if the accumulated split size exceeds the maximum, then \n      // create this split.\n      if (maxSize !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d maxSize) {\n        // create an input split and add it to the splits array\n        addCreatedSplit(splits, getHosts(racks), validBlocks);\n        curSplitSize \u003d 0;\n        validBlocks.clear();\n        racks.clear();\n      }\n    }\n\n    // Process any remaining blocks, if any.\n    if (!validBlocks.isEmpty()) {\n      addCreatedSplit(splits, getHosts(racks), validBlocks);\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/input/CombineFileInputFormat.java",
      "extendedDetails": {}
    },
    "381a4c42135916245c8992daa3d03f38e282108d": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "MAPREDUCE-5352. Optimize node local splits generated by CombineFileInputFormat. (sseth)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1509345 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "01/08/13 10:42 AM",
      "commitName": "381a4c42135916245c8992daa3d03f38e282108d",
      "commitAuthor": "Siddharth Seth",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "MAPREDUCE-5352. Optimize node local splits generated by CombineFileInputFormat. (sseth)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1509345 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "01/08/13 10:42 AM",
          "commitName": "381a4c42135916245c8992daa3d03f38e282108d",
          "commitAuthor": "Siddharth Seth",
          "commitDateOld": "26/07/13 11:16 AM",
          "commitNameOld": "ec18984252731089ab5af12b3603dcfc3d4f4593",
          "commitAuthorOld": "Jason Darrell Lowe",
          "daysBetweenCommits": 5.98,
          "commitsBetweenForRepo": 41,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,194 +1,229 @@\n-  void createSplits(HashMap\u003cString, List\u003cOneBlockInfo\u003e\u003e nodeToBlocks,\n-                     HashMap\u003cOneBlockInfo, String[]\u003e blockToNodes,\n-                     HashMap\u003cString, List\u003cOneBlockInfo\u003e\u003e rackToBlocks,\n+  void createSplits(Map\u003cString, Set\u003cOneBlockInfo\u003e\u003e nodeToBlocks,\n+                     Map\u003cOneBlockInfo, String[]\u003e blockToNodes,\n+                     Map\u003cString, List\u003cOneBlockInfo\u003e\u003e rackToBlocks,\n                      long totLength,\n                      long maxSize,\n                      long minSizeNode,\n                      long minSizeRack,\n                      List\u003cInputSplit\u003e splits                     \n                     ) {\n     ArrayList\u003cOneBlockInfo\u003e validBlocks \u003d new ArrayList\u003cOneBlockInfo\u003e();\n-    Set\u003cString\u003e nodes \u003d new HashSet\u003cString\u003e();\n     long curSplitSize \u003d 0;\n     \n-    int numNodes \u003d nodeToBlocks.size();\n+    int totalNodes \u003d nodeToBlocks.size();\n     long totalLength \u003d totLength;\n \n+    Multiset\u003cString\u003e splitsPerNode \u003d HashMultiset.create();\n+    Set\u003cString\u003e completedNodes \u003d new HashSet\u003cString\u003e();\n+    \n     while(true) {\n       // it is allowed for maxSize to be 0. Disable smoothing load for such cases\n-      int avgSplitsPerNode \u003d maxSize \u003e 0 \u0026\u0026 numNodes \u003e 0 ?\n-                                        ((int) (totalLength/maxSize))/numNodes\n-                                        : Integer.MAX_VALUE;\n-      int maxSplitsByNodeOnly \u003d (avgSplitsPerNode \u003e 0) ? avgSplitsPerNode : 1;\n-      numNodes \u003d 0;\n \n-      // process all nodes and create splits that are local to a node.\n-      for (Iterator\u003cMap.Entry\u003cString, List\u003cOneBlockInfo\u003e\u003e\u003e iter \u003d nodeToBlocks\n+      // process all nodes and create splits that are local to a node. Generate\n+      // one split per node iteration, and walk over nodes multiple times to\n+      // distribute the splits across nodes. \n+      for (Iterator\u003cMap.Entry\u003cString, Set\u003cOneBlockInfo\u003e\u003e\u003e iter \u003d nodeToBlocks\n           .entrySet().iterator(); iter.hasNext();) {\n-        Map.Entry\u003cString, List\u003cOneBlockInfo\u003e\u003e one \u003d iter.next();\n-        nodes.add(one.getKey());\n-        List\u003cOneBlockInfo\u003e blocksInNode \u003d one.getValue();\n+        Map.Entry\u003cString, Set\u003cOneBlockInfo\u003e\u003e one \u003d iter.next();\n+        \n+        String node \u003d one.getKey();\n+        \n+        // Skip the node if it has previously been marked as completed.\n+        if (completedNodes.contains(node)) {\n+          continue;\n+        }\n+\n+        Set\u003cOneBlockInfo\u003e blocksInCurrentNode \u003d one.getValue();\n \n         // for each block, copy it into validBlocks. Delete it from\n         // blockToNodes so that the same block does not appear in\n         // two different splits.\n-        int splitsInNode \u003d 0;\n-        for (OneBlockInfo oneblock : blocksInNode) {\n-          if (blockToNodes.containsKey(oneblock)) {\n-            validBlocks.add(oneblock);\n-            blockToNodes.remove(oneblock);\n-            curSplitSize +\u003d oneblock.length;\n+        Iterator\u003cOneBlockInfo\u003e oneBlockIter \u003d blocksInCurrentNode.iterator();\n+        while (oneBlockIter.hasNext()) {\n+          OneBlockInfo oneblock \u003d oneBlockIter.next();\n+          \n+          // Remove all blocks which may already have been assigned to other\n+          // splits.\n+          if(!blockToNodes.containsKey(oneblock)) {\n+            oneBlockIter.remove();\n+            continue;\n+          }\n+        \n+          validBlocks.add(oneblock);\n+          blockToNodes.remove(oneblock);\n+          curSplitSize +\u003d oneblock.length;\n \n-            // if the accumulated split size exceeds the maximum, then\n-            // create this split.\n-            if (maxSize !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d maxSize) {\n-              // create an input split and add it to the splits array\n-              addCreatedSplit(splits, nodes, validBlocks);\n-              totalLength -\u003d curSplitSize;\n-              curSplitSize \u003d 0;\n-              validBlocks.clear();\n-              splitsInNode++;\n-              if (splitsInNode \u003d\u003d maxSplitsByNodeOnly) {\n-                // stop grouping on a node so as not to create\n-                // disproportionately more splits on a node because it happens\n-                // to have many blocks\n-                // consider only these nodes in next round of grouping because\n-                // they have leftover blocks that may need to be grouped\n-                numNodes++;\n-                break;\n-              }\n+          // if the accumulated split size exceeds the maximum, then\n+          // create this split.\n+          if (maxSize !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d maxSize) {\n+            // create an input split and add it to the splits array\n+            addCreatedSplit(splits, Collections.singleton(node), validBlocks);\n+            totalLength -\u003d curSplitSize;\n+            curSplitSize \u003d 0;\n+\n+            splitsPerNode.add(node);\n+\n+            // Remove entries from blocksInNode so that we don\u0027t walk these\n+            // again.\n+            blocksInCurrentNode.removeAll(validBlocks);\n+            validBlocks.clear();\n+\n+            // Done creating a single split for this node. Move on to the next\n+            // node so that splits are distributed across nodes.\n+            break;\n+          }\n+\n+        }\n+        if (validBlocks.size() !\u003d 0) {\n+          // This implies that the last few blocks (or all in case maxSize\u003d0)\n+          // were not part of a split. The node is complete.\n+          \n+          // if there were any blocks left over and their combined size is\n+          // larger than minSplitNode, then combine them into one split.\n+          // Otherwise add them back to the unprocessed pool. It is likely\n+          // that they will be combined with other blocks from the\n+          // same rack later on.\n+          // This condition also kicks in when max split size is not set. All\n+          // blocks on a node will be grouped together into a single split.\n+          if (minSizeNode !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d minSizeNode\n+              \u0026\u0026 splitsPerNode.count(node) \u003d\u003d 0) {\n+            // haven\u0027t created any split on this machine. so its ok to add a\n+            // smaller one for parallelism. Otherwise group it in the rack for\n+            // balanced size create an input split and add it to the splits\n+            // array\n+            addCreatedSplit(splits, Collections.singleton(node), validBlocks);\n+            totalLength -\u003d curSplitSize;\n+            splitsPerNode.add(node);\n+            // Remove entries from blocksInNode so that we don\u0027t walk this again.\n+            blocksInCurrentNode.removeAll(validBlocks);\n+            // The node is done. This was the last set of blocks for this node.\n+          } else {\n+            // Put the unplaced blocks back into the pool for later rack-allocation.\n+            for (OneBlockInfo oneblock : validBlocks) {\n+              blockToNodes.put(oneblock, oneblock.hosts);\n             }\n           }\n+          validBlocks.clear();\n+          curSplitSize \u003d 0;\n+          completedNodes.add(node);\n+        } else { // No in-flight blocks.\n+          if (blocksInCurrentNode.size() \u003d\u003d 0) {\n+            // Node is done. All blocks were fit into node-local splits.\n+            completedNodes.add(node);\n+          } // else Run through the node again.\n         }\n-        // if there were any blocks left over and their combined size is\n-        // larger than minSplitNode, then combine them into one split.\n-        // Otherwise add them back to the unprocessed pool. It is likely\n-        // that they will be combined with other blocks from the\n-        // same rack later on.\n-        if (minSizeNode !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d minSizeNode\n-            \u0026\u0026 splitsInNode \u003d\u003d 0) {\n-          // haven\u0027t created any split on this machine. so its ok to add a\n-          // smaller\n-          // one for parallelism. Otherwise group it in the rack for balanced\n-          // size\n-          // create an input split and add it to the splits array\n-          addCreatedSplit(splits, nodes, validBlocks);\n-          totalLength -\u003d curSplitSize;\n-        } else {\n-          for (OneBlockInfo oneblock : validBlocks) {\n-            blockToNodes.put(oneblock, oneblock.hosts);\n-          }\n-        }\n-        validBlocks.clear();\n-        nodes.clear();\n-        curSplitSize \u003d 0;\n       }\n-      \n-      if(!(numNodes\u003e0 \u0026\u0026 totalLength\u003e0)) {\n+\n+      // Check if node-local assignments are complete.\n+      if (completedNodes.size() \u003d\u003d totalNodes || totalLength \u003d\u003d 0) {\n+        // All nodes have been walked over and marked as completed or all blocks\n+        // have been assigned. The rest should be handled via rackLock assignment.\n+        LOG.info(\"DEBUG: Terminated node allocation with : CompletedNodes: \"\n+            + completedNodes.size() + \", size left: \" + totalLength);\n         break;\n       }\n     }\n \n     // if blocks in a rack are below the specified minimum size, then keep them\n     // in \u0027overflow\u0027. After the processing of all racks is complete, these \n     // overflow blocks will be combined into splits.\n     ArrayList\u003cOneBlockInfo\u003e overflowBlocks \u003d new ArrayList\u003cOneBlockInfo\u003e();\n     Set\u003cString\u003e racks \u003d new HashSet\u003cString\u003e();\n \n     // Process all racks over and over again until there is no more work to do.\n     while (blockToNodes.size() \u003e 0) {\n \n       // Create one split for this rack before moving over to the next rack. \n       // Come back to this rack after creating a single split for each of the \n       // remaining racks.\n       // Process one rack location at a time, Combine all possible blocks that\n       // reside on this rack as one split. (constrained by minimum and maximum\n       // split size).\n \n       // iterate over all racks \n       for (Iterator\u003cMap.Entry\u003cString, List\u003cOneBlockInfo\u003e\u003e\u003e iter \u003d \n            rackToBlocks.entrySet().iterator(); iter.hasNext();) {\n \n         Map.Entry\u003cString, List\u003cOneBlockInfo\u003e\u003e one \u003d iter.next();\n         racks.add(one.getKey());\n         List\u003cOneBlockInfo\u003e blocks \u003d one.getValue();\n \n         // for each block, copy it into validBlocks. Delete it from \n         // blockToNodes so that the same block does not appear in \n         // two different splits.\n         boolean createdSplit \u003d false;\n         for (OneBlockInfo oneblock : blocks) {\n           if (blockToNodes.containsKey(oneblock)) {\n             validBlocks.add(oneblock);\n             blockToNodes.remove(oneblock);\n             curSplitSize +\u003d oneblock.length;\n       \n             // if the accumulated split size exceeds the maximum, then \n             // create this split.\n             if (maxSize !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d maxSize) {\n               // create an input split and add it to the splits array\n               addCreatedSplit(splits, getHosts(racks), validBlocks);\n               createdSplit \u003d true;\n               break;\n             }\n           }\n         }\n \n         // if we created a split, then just go to the next rack\n         if (createdSplit) {\n           curSplitSize \u003d 0;\n           validBlocks.clear();\n           racks.clear();\n           continue;\n         }\n \n         if (!validBlocks.isEmpty()) {\n           if (minSizeRack !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d minSizeRack) {\n             // if there is a minimum size specified, then create a single split\n             // otherwise, store these blocks into overflow data structure\n             addCreatedSplit(splits, getHosts(racks), validBlocks);\n           } else {\n             // There were a few blocks in this rack that \n         \t// remained to be processed. Keep them in \u0027overflow\u0027 block list. \n         \t// These will be combined later.\n             overflowBlocks.addAll(validBlocks);\n           }\n         }\n         curSplitSize \u003d 0;\n         validBlocks.clear();\n         racks.clear();\n       }\n     }\n \n     assert blockToNodes.isEmpty();\n     assert curSplitSize \u003d\u003d 0;\n     assert validBlocks.isEmpty();\n     assert racks.isEmpty();\n \n     // Process all overflow blocks\n     for (OneBlockInfo oneblock : overflowBlocks) {\n       validBlocks.add(oneblock);\n       curSplitSize +\u003d oneblock.length;\n \n       // This might cause an exiting rack location to be re-added,\n       // but it should be ok.\n       for (int i \u003d 0; i \u003c oneblock.racks.length; i++) {\n         racks.add(oneblock.racks[i]);\n       }\n \n       // if the accumulated split size exceeds the maximum, then \n       // create this split.\n       if (maxSize !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d maxSize) {\n         // create an input split and add it to the splits array\n         addCreatedSplit(splits, getHosts(racks), validBlocks);\n         curSplitSize \u003d 0;\n         validBlocks.clear();\n         racks.clear();\n       }\n     }\n \n     // Process any remaining blocks, if any.\n     if (!validBlocks.isEmpty()) {\n       addCreatedSplit(splits, getHosts(racks), validBlocks);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  void createSplits(Map\u003cString, Set\u003cOneBlockInfo\u003e\u003e nodeToBlocks,\n                     Map\u003cOneBlockInfo, String[]\u003e blockToNodes,\n                     Map\u003cString, List\u003cOneBlockInfo\u003e\u003e rackToBlocks,\n                     long totLength,\n                     long maxSize,\n                     long minSizeNode,\n                     long minSizeRack,\n                     List\u003cInputSplit\u003e splits                     \n                    ) {\n    ArrayList\u003cOneBlockInfo\u003e validBlocks \u003d new ArrayList\u003cOneBlockInfo\u003e();\n    long curSplitSize \u003d 0;\n    \n    int totalNodes \u003d nodeToBlocks.size();\n    long totalLength \u003d totLength;\n\n    Multiset\u003cString\u003e splitsPerNode \u003d HashMultiset.create();\n    Set\u003cString\u003e completedNodes \u003d new HashSet\u003cString\u003e();\n    \n    while(true) {\n      // it is allowed for maxSize to be 0. Disable smoothing load for such cases\n\n      // process all nodes and create splits that are local to a node. Generate\n      // one split per node iteration, and walk over nodes multiple times to\n      // distribute the splits across nodes. \n      for (Iterator\u003cMap.Entry\u003cString, Set\u003cOneBlockInfo\u003e\u003e\u003e iter \u003d nodeToBlocks\n          .entrySet().iterator(); iter.hasNext();) {\n        Map.Entry\u003cString, Set\u003cOneBlockInfo\u003e\u003e one \u003d iter.next();\n        \n        String node \u003d one.getKey();\n        \n        // Skip the node if it has previously been marked as completed.\n        if (completedNodes.contains(node)) {\n          continue;\n        }\n\n        Set\u003cOneBlockInfo\u003e blocksInCurrentNode \u003d one.getValue();\n\n        // for each block, copy it into validBlocks. Delete it from\n        // blockToNodes so that the same block does not appear in\n        // two different splits.\n        Iterator\u003cOneBlockInfo\u003e oneBlockIter \u003d blocksInCurrentNode.iterator();\n        while (oneBlockIter.hasNext()) {\n          OneBlockInfo oneblock \u003d oneBlockIter.next();\n          \n          // Remove all blocks which may already have been assigned to other\n          // splits.\n          if(!blockToNodes.containsKey(oneblock)) {\n            oneBlockIter.remove();\n            continue;\n          }\n        \n          validBlocks.add(oneblock);\n          blockToNodes.remove(oneblock);\n          curSplitSize +\u003d oneblock.length;\n\n          // if the accumulated split size exceeds the maximum, then\n          // create this split.\n          if (maxSize !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d maxSize) {\n            // create an input split and add it to the splits array\n            addCreatedSplit(splits, Collections.singleton(node), validBlocks);\n            totalLength -\u003d curSplitSize;\n            curSplitSize \u003d 0;\n\n            splitsPerNode.add(node);\n\n            // Remove entries from blocksInNode so that we don\u0027t walk these\n            // again.\n            blocksInCurrentNode.removeAll(validBlocks);\n            validBlocks.clear();\n\n            // Done creating a single split for this node. Move on to the next\n            // node so that splits are distributed across nodes.\n            break;\n          }\n\n        }\n        if (validBlocks.size() !\u003d 0) {\n          // This implies that the last few blocks (or all in case maxSize\u003d0)\n          // were not part of a split. The node is complete.\n          \n          // if there were any blocks left over and their combined size is\n          // larger than minSplitNode, then combine them into one split.\n          // Otherwise add them back to the unprocessed pool. It is likely\n          // that they will be combined with other blocks from the\n          // same rack later on.\n          // This condition also kicks in when max split size is not set. All\n          // blocks on a node will be grouped together into a single split.\n          if (minSizeNode !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d minSizeNode\n              \u0026\u0026 splitsPerNode.count(node) \u003d\u003d 0) {\n            // haven\u0027t created any split on this machine. so its ok to add a\n            // smaller one for parallelism. Otherwise group it in the rack for\n            // balanced size create an input split and add it to the splits\n            // array\n            addCreatedSplit(splits, Collections.singleton(node), validBlocks);\n            totalLength -\u003d curSplitSize;\n            splitsPerNode.add(node);\n            // Remove entries from blocksInNode so that we don\u0027t walk this again.\n            blocksInCurrentNode.removeAll(validBlocks);\n            // The node is done. This was the last set of blocks for this node.\n          } else {\n            // Put the unplaced blocks back into the pool for later rack-allocation.\n            for (OneBlockInfo oneblock : validBlocks) {\n              blockToNodes.put(oneblock, oneblock.hosts);\n            }\n          }\n          validBlocks.clear();\n          curSplitSize \u003d 0;\n          completedNodes.add(node);\n        } else { // No in-flight blocks.\n          if (blocksInCurrentNode.size() \u003d\u003d 0) {\n            // Node is done. All blocks were fit into node-local splits.\n            completedNodes.add(node);\n          } // else Run through the node again.\n        }\n      }\n\n      // Check if node-local assignments are complete.\n      if (completedNodes.size() \u003d\u003d totalNodes || totalLength \u003d\u003d 0) {\n        // All nodes have been walked over and marked as completed or all blocks\n        // have been assigned. The rest should be handled via rackLock assignment.\n        LOG.info(\"DEBUG: Terminated node allocation with : CompletedNodes: \"\n            + completedNodes.size() + \", size left: \" + totalLength);\n        break;\n      }\n    }\n\n    // if blocks in a rack are below the specified minimum size, then keep them\n    // in \u0027overflow\u0027. After the processing of all racks is complete, these \n    // overflow blocks will be combined into splits.\n    ArrayList\u003cOneBlockInfo\u003e overflowBlocks \u003d new ArrayList\u003cOneBlockInfo\u003e();\n    Set\u003cString\u003e racks \u003d new HashSet\u003cString\u003e();\n\n    // Process all racks over and over again until there is no more work to do.\n    while (blockToNodes.size() \u003e 0) {\n\n      // Create one split for this rack before moving over to the next rack. \n      // Come back to this rack after creating a single split for each of the \n      // remaining racks.\n      // Process one rack location at a time, Combine all possible blocks that\n      // reside on this rack as one split. (constrained by minimum and maximum\n      // split size).\n\n      // iterate over all racks \n      for (Iterator\u003cMap.Entry\u003cString, List\u003cOneBlockInfo\u003e\u003e\u003e iter \u003d \n           rackToBlocks.entrySet().iterator(); iter.hasNext();) {\n\n        Map.Entry\u003cString, List\u003cOneBlockInfo\u003e\u003e one \u003d iter.next();\n        racks.add(one.getKey());\n        List\u003cOneBlockInfo\u003e blocks \u003d one.getValue();\n\n        // for each block, copy it into validBlocks. Delete it from \n        // blockToNodes so that the same block does not appear in \n        // two different splits.\n        boolean createdSplit \u003d false;\n        for (OneBlockInfo oneblock : blocks) {\n          if (blockToNodes.containsKey(oneblock)) {\n            validBlocks.add(oneblock);\n            blockToNodes.remove(oneblock);\n            curSplitSize +\u003d oneblock.length;\n      \n            // if the accumulated split size exceeds the maximum, then \n            // create this split.\n            if (maxSize !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d maxSize) {\n              // create an input split and add it to the splits array\n              addCreatedSplit(splits, getHosts(racks), validBlocks);\n              createdSplit \u003d true;\n              break;\n            }\n          }\n        }\n\n        // if we created a split, then just go to the next rack\n        if (createdSplit) {\n          curSplitSize \u003d 0;\n          validBlocks.clear();\n          racks.clear();\n          continue;\n        }\n\n        if (!validBlocks.isEmpty()) {\n          if (minSizeRack !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d minSizeRack) {\n            // if there is a minimum size specified, then create a single split\n            // otherwise, store these blocks into overflow data structure\n            addCreatedSplit(splits, getHosts(racks), validBlocks);\n          } else {\n            // There were a few blocks in this rack that \n        \t// remained to be processed. Keep them in \u0027overflow\u0027 block list. \n        \t// These will be combined later.\n            overflowBlocks.addAll(validBlocks);\n          }\n        }\n        curSplitSize \u003d 0;\n        validBlocks.clear();\n        racks.clear();\n      }\n    }\n\n    assert blockToNodes.isEmpty();\n    assert curSplitSize \u003d\u003d 0;\n    assert validBlocks.isEmpty();\n    assert racks.isEmpty();\n\n    // Process all overflow blocks\n    for (OneBlockInfo oneblock : overflowBlocks) {\n      validBlocks.add(oneblock);\n      curSplitSize +\u003d oneblock.length;\n\n      // This might cause an exiting rack location to be re-added,\n      // but it should be ok.\n      for (int i \u003d 0; i \u003c oneblock.racks.length; i++) {\n        racks.add(oneblock.racks[i]);\n      }\n\n      // if the accumulated split size exceeds the maximum, then \n      // create this split.\n      if (maxSize !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d maxSize) {\n        // create an input split and add it to the splits array\n        addCreatedSplit(splits, getHosts(racks), validBlocks);\n        curSplitSize \u003d 0;\n        validBlocks.clear();\n        racks.clear();\n      }\n    }\n\n    // Process any remaining blocks, if any.\n    if (!validBlocks.isEmpty()) {\n      addCreatedSplit(splits, getHosts(racks), validBlocks);\n    }\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/input/CombineFileInputFormat.java",
          "extendedDetails": {
            "oldValue": "[nodeToBlocks-HashMap\u003cString,List\u003cOneBlockInfo\u003e\u003e, blockToNodes-HashMap\u003cOneBlockInfo,String[]\u003e, rackToBlocks-HashMap\u003cString,List\u003cOneBlockInfo\u003e\u003e, totLength-long, maxSize-long, minSizeNode-long, minSizeRack-long, splits-List\u003cInputSplit\u003e]",
            "newValue": "[nodeToBlocks-Map\u003cString,Set\u003cOneBlockInfo\u003e\u003e, blockToNodes-Map\u003cOneBlockInfo,String[]\u003e, rackToBlocks-Map\u003cString,List\u003cOneBlockInfo\u003e\u003e, totLength-long, maxSize-long, minSizeNode-long, minSizeRack-long, splits-List\u003cInputSplit\u003e]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "MAPREDUCE-5352. Optimize node local splits generated by CombineFileInputFormat. (sseth)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1509345 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "01/08/13 10:42 AM",
          "commitName": "381a4c42135916245c8992daa3d03f38e282108d",
          "commitAuthor": "Siddharth Seth",
          "commitDateOld": "26/07/13 11:16 AM",
          "commitNameOld": "ec18984252731089ab5af12b3603dcfc3d4f4593",
          "commitAuthorOld": "Jason Darrell Lowe",
          "daysBetweenCommits": 5.98,
          "commitsBetweenForRepo": 41,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,194 +1,229 @@\n-  void createSplits(HashMap\u003cString, List\u003cOneBlockInfo\u003e\u003e nodeToBlocks,\n-                     HashMap\u003cOneBlockInfo, String[]\u003e blockToNodes,\n-                     HashMap\u003cString, List\u003cOneBlockInfo\u003e\u003e rackToBlocks,\n+  void createSplits(Map\u003cString, Set\u003cOneBlockInfo\u003e\u003e nodeToBlocks,\n+                     Map\u003cOneBlockInfo, String[]\u003e blockToNodes,\n+                     Map\u003cString, List\u003cOneBlockInfo\u003e\u003e rackToBlocks,\n                      long totLength,\n                      long maxSize,\n                      long minSizeNode,\n                      long minSizeRack,\n                      List\u003cInputSplit\u003e splits                     \n                     ) {\n     ArrayList\u003cOneBlockInfo\u003e validBlocks \u003d new ArrayList\u003cOneBlockInfo\u003e();\n-    Set\u003cString\u003e nodes \u003d new HashSet\u003cString\u003e();\n     long curSplitSize \u003d 0;\n     \n-    int numNodes \u003d nodeToBlocks.size();\n+    int totalNodes \u003d nodeToBlocks.size();\n     long totalLength \u003d totLength;\n \n+    Multiset\u003cString\u003e splitsPerNode \u003d HashMultiset.create();\n+    Set\u003cString\u003e completedNodes \u003d new HashSet\u003cString\u003e();\n+    \n     while(true) {\n       // it is allowed for maxSize to be 0. Disable smoothing load for such cases\n-      int avgSplitsPerNode \u003d maxSize \u003e 0 \u0026\u0026 numNodes \u003e 0 ?\n-                                        ((int) (totalLength/maxSize))/numNodes\n-                                        : Integer.MAX_VALUE;\n-      int maxSplitsByNodeOnly \u003d (avgSplitsPerNode \u003e 0) ? avgSplitsPerNode : 1;\n-      numNodes \u003d 0;\n \n-      // process all nodes and create splits that are local to a node.\n-      for (Iterator\u003cMap.Entry\u003cString, List\u003cOneBlockInfo\u003e\u003e\u003e iter \u003d nodeToBlocks\n+      // process all nodes and create splits that are local to a node. Generate\n+      // one split per node iteration, and walk over nodes multiple times to\n+      // distribute the splits across nodes. \n+      for (Iterator\u003cMap.Entry\u003cString, Set\u003cOneBlockInfo\u003e\u003e\u003e iter \u003d nodeToBlocks\n           .entrySet().iterator(); iter.hasNext();) {\n-        Map.Entry\u003cString, List\u003cOneBlockInfo\u003e\u003e one \u003d iter.next();\n-        nodes.add(one.getKey());\n-        List\u003cOneBlockInfo\u003e blocksInNode \u003d one.getValue();\n+        Map.Entry\u003cString, Set\u003cOneBlockInfo\u003e\u003e one \u003d iter.next();\n+        \n+        String node \u003d one.getKey();\n+        \n+        // Skip the node if it has previously been marked as completed.\n+        if (completedNodes.contains(node)) {\n+          continue;\n+        }\n+\n+        Set\u003cOneBlockInfo\u003e blocksInCurrentNode \u003d one.getValue();\n \n         // for each block, copy it into validBlocks. Delete it from\n         // blockToNodes so that the same block does not appear in\n         // two different splits.\n-        int splitsInNode \u003d 0;\n-        for (OneBlockInfo oneblock : blocksInNode) {\n-          if (blockToNodes.containsKey(oneblock)) {\n-            validBlocks.add(oneblock);\n-            blockToNodes.remove(oneblock);\n-            curSplitSize +\u003d oneblock.length;\n+        Iterator\u003cOneBlockInfo\u003e oneBlockIter \u003d blocksInCurrentNode.iterator();\n+        while (oneBlockIter.hasNext()) {\n+          OneBlockInfo oneblock \u003d oneBlockIter.next();\n+          \n+          // Remove all blocks which may already have been assigned to other\n+          // splits.\n+          if(!blockToNodes.containsKey(oneblock)) {\n+            oneBlockIter.remove();\n+            continue;\n+          }\n+        \n+          validBlocks.add(oneblock);\n+          blockToNodes.remove(oneblock);\n+          curSplitSize +\u003d oneblock.length;\n \n-            // if the accumulated split size exceeds the maximum, then\n-            // create this split.\n-            if (maxSize !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d maxSize) {\n-              // create an input split and add it to the splits array\n-              addCreatedSplit(splits, nodes, validBlocks);\n-              totalLength -\u003d curSplitSize;\n-              curSplitSize \u003d 0;\n-              validBlocks.clear();\n-              splitsInNode++;\n-              if (splitsInNode \u003d\u003d maxSplitsByNodeOnly) {\n-                // stop grouping on a node so as not to create\n-                // disproportionately more splits on a node because it happens\n-                // to have many blocks\n-                // consider only these nodes in next round of grouping because\n-                // they have leftover blocks that may need to be grouped\n-                numNodes++;\n-                break;\n-              }\n+          // if the accumulated split size exceeds the maximum, then\n+          // create this split.\n+          if (maxSize !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d maxSize) {\n+            // create an input split and add it to the splits array\n+            addCreatedSplit(splits, Collections.singleton(node), validBlocks);\n+            totalLength -\u003d curSplitSize;\n+            curSplitSize \u003d 0;\n+\n+            splitsPerNode.add(node);\n+\n+            // Remove entries from blocksInNode so that we don\u0027t walk these\n+            // again.\n+            blocksInCurrentNode.removeAll(validBlocks);\n+            validBlocks.clear();\n+\n+            // Done creating a single split for this node. Move on to the next\n+            // node so that splits are distributed across nodes.\n+            break;\n+          }\n+\n+        }\n+        if (validBlocks.size() !\u003d 0) {\n+          // This implies that the last few blocks (or all in case maxSize\u003d0)\n+          // were not part of a split. The node is complete.\n+          \n+          // if there were any blocks left over and their combined size is\n+          // larger than minSplitNode, then combine them into one split.\n+          // Otherwise add them back to the unprocessed pool. It is likely\n+          // that they will be combined with other blocks from the\n+          // same rack later on.\n+          // This condition also kicks in when max split size is not set. All\n+          // blocks on a node will be grouped together into a single split.\n+          if (minSizeNode !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d minSizeNode\n+              \u0026\u0026 splitsPerNode.count(node) \u003d\u003d 0) {\n+            // haven\u0027t created any split on this machine. so its ok to add a\n+            // smaller one for parallelism. Otherwise group it in the rack for\n+            // balanced size create an input split and add it to the splits\n+            // array\n+            addCreatedSplit(splits, Collections.singleton(node), validBlocks);\n+            totalLength -\u003d curSplitSize;\n+            splitsPerNode.add(node);\n+            // Remove entries from blocksInNode so that we don\u0027t walk this again.\n+            blocksInCurrentNode.removeAll(validBlocks);\n+            // The node is done. This was the last set of blocks for this node.\n+          } else {\n+            // Put the unplaced blocks back into the pool for later rack-allocation.\n+            for (OneBlockInfo oneblock : validBlocks) {\n+              blockToNodes.put(oneblock, oneblock.hosts);\n             }\n           }\n+          validBlocks.clear();\n+          curSplitSize \u003d 0;\n+          completedNodes.add(node);\n+        } else { // No in-flight blocks.\n+          if (blocksInCurrentNode.size() \u003d\u003d 0) {\n+            // Node is done. All blocks were fit into node-local splits.\n+            completedNodes.add(node);\n+          } // else Run through the node again.\n         }\n-        // if there were any blocks left over and their combined size is\n-        // larger than minSplitNode, then combine them into one split.\n-        // Otherwise add them back to the unprocessed pool. It is likely\n-        // that they will be combined with other blocks from the\n-        // same rack later on.\n-        if (minSizeNode !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d minSizeNode\n-            \u0026\u0026 splitsInNode \u003d\u003d 0) {\n-          // haven\u0027t created any split on this machine. so its ok to add a\n-          // smaller\n-          // one for parallelism. Otherwise group it in the rack for balanced\n-          // size\n-          // create an input split and add it to the splits array\n-          addCreatedSplit(splits, nodes, validBlocks);\n-          totalLength -\u003d curSplitSize;\n-        } else {\n-          for (OneBlockInfo oneblock : validBlocks) {\n-            blockToNodes.put(oneblock, oneblock.hosts);\n-          }\n-        }\n-        validBlocks.clear();\n-        nodes.clear();\n-        curSplitSize \u003d 0;\n       }\n-      \n-      if(!(numNodes\u003e0 \u0026\u0026 totalLength\u003e0)) {\n+\n+      // Check if node-local assignments are complete.\n+      if (completedNodes.size() \u003d\u003d totalNodes || totalLength \u003d\u003d 0) {\n+        // All nodes have been walked over and marked as completed or all blocks\n+        // have been assigned. The rest should be handled via rackLock assignment.\n+        LOG.info(\"DEBUG: Terminated node allocation with : CompletedNodes: \"\n+            + completedNodes.size() + \", size left: \" + totalLength);\n         break;\n       }\n     }\n \n     // if blocks in a rack are below the specified minimum size, then keep them\n     // in \u0027overflow\u0027. After the processing of all racks is complete, these \n     // overflow blocks will be combined into splits.\n     ArrayList\u003cOneBlockInfo\u003e overflowBlocks \u003d new ArrayList\u003cOneBlockInfo\u003e();\n     Set\u003cString\u003e racks \u003d new HashSet\u003cString\u003e();\n \n     // Process all racks over and over again until there is no more work to do.\n     while (blockToNodes.size() \u003e 0) {\n \n       // Create one split for this rack before moving over to the next rack. \n       // Come back to this rack after creating a single split for each of the \n       // remaining racks.\n       // Process one rack location at a time, Combine all possible blocks that\n       // reside on this rack as one split. (constrained by minimum and maximum\n       // split size).\n \n       // iterate over all racks \n       for (Iterator\u003cMap.Entry\u003cString, List\u003cOneBlockInfo\u003e\u003e\u003e iter \u003d \n            rackToBlocks.entrySet().iterator(); iter.hasNext();) {\n \n         Map.Entry\u003cString, List\u003cOneBlockInfo\u003e\u003e one \u003d iter.next();\n         racks.add(one.getKey());\n         List\u003cOneBlockInfo\u003e blocks \u003d one.getValue();\n \n         // for each block, copy it into validBlocks. Delete it from \n         // blockToNodes so that the same block does not appear in \n         // two different splits.\n         boolean createdSplit \u003d false;\n         for (OneBlockInfo oneblock : blocks) {\n           if (blockToNodes.containsKey(oneblock)) {\n             validBlocks.add(oneblock);\n             blockToNodes.remove(oneblock);\n             curSplitSize +\u003d oneblock.length;\n       \n             // if the accumulated split size exceeds the maximum, then \n             // create this split.\n             if (maxSize !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d maxSize) {\n               // create an input split and add it to the splits array\n               addCreatedSplit(splits, getHosts(racks), validBlocks);\n               createdSplit \u003d true;\n               break;\n             }\n           }\n         }\n \n         // if we created a split, then just go to the next rack\n         if (createdSplit) {\n           curSplitSize \u003d 0;\n           validBlocks.clear();\n           racks.clear();\n           continue;\n         }\n \n         if (!validBlocks.isEmpty()) {\n           if (minSizeRack !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d minSizeRack) {\n             // if there is a minimum size specified, then create a single split\n             // otherwise, store these blocks into overflow data structure\n             addCreatedSplit(splits, getHosts(racks), validBlocks);\n           } else {\n             // There were a few blocks in this rack that \n         \t// remained to be processed. Keep them in \u0027overflow\u0027 block list. \n         \t// These will be combined later.\n             overflowBlocks.addAll(validBlocks);\n           }\n         }\n         curSplitSize \u003d 0;\n         validBlocks.clear();\n         racks.clear();\n       }\n     }\n \n     assert blockToNodes.isEmpty();\n     assert curSplitSize \u003d\u003d 0;\n     assert validBlocks.isEmpty();\n     assert racks.isEmpty();\n \n     // Process all overflow blocks\n     for (OneBlockInfo oneblock : overflowBlocks) {\n       validBlocks.add(oneblock);\n       curSplitSize +\u003d oneblock.length;\n \n       // This might cause an exiting rack location to be re-added,\n       // but it should be ok.\n       for (int i \u003d 0; i \u003c oneblock.racks.length; i++) {\n         racks.add(oneblock.racks[i]);\n       }\n \n       // if the accumulated split size exceeds the maximum, then \n       // create this split.\n       if (maxSize !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d maxSize) {\n         // create an input split and add it to the splits array\n         addCreatedSplit(splits, getHosts(racks), validBlocks);\n         curSplitSize \u003d 0;\n         validBlocks.clear();\n         racks.clear();\n       }\n     }\n \n     // Process any remaining blocks, if any.\n     if (!validBlocks.isEmpty()) {\n       addCreatedSplit(splits, getHosts(racks), validBlocks);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  void createSplits(Map\u003cString, Set\u003cOneBlockInfo\u003e\u003e nodeToBlocks,\n                     Map\u003cOneBlockInfo, String[]\u003e blockToNodes,\n                     Map\u003cString, List\u003cOneBlockInfo\u003e\u003e rackToBlocks,\n                     long totLength,\n                     long maxSize,\n                     long minSizeNode,\n                     long minSizeRack,\n                     List\u003cInputSplit\u003e splits                     \n                    ) {\n    ArrayList\u003cOneBlockInfo\u003e validBlocks \u003d new ArrayList\u003cOneBlockInfo\u003e();\n    long curSplitSize \u003d 0;\n    \n    int totalNodes \u003d nodeToBlocks.size();\n    long totalLength \u003d totLength;\n\n    Multiset\u003cString\u003e splitsPerNode \u003d HashMultiset.create();\n    Set\u003cString\u003e completedNodes \u003d new HashSet\u003cString\u003e();\n    \n    while(true) {\n      // it is allowed for maxSize to be 0. Disable smoothing load for such cases\n\n      // process all nodes and create splits that are local to a node. Generate\n      // one split per node iteration, and walk over nodes multiple times to\n      // distribute the splits across nodes. \n      for (Iterator\u003cMap.Entry\u003cString, Set\u003cOneBlockInfo\u003e\u003e\u003e iter \u003d nodeToBlocks\n          .entrySet().iterator(); iter.hasNext();) {\n        Map.Entry\u003cString, Set\u003cOneBlockInfo\u003e\u003e one \u003d iter.next();\n        \n        String node \u003d one.getKey();\n        \n        // Skip the node if it has previously been marked as completed.\n        if (completedNodes.contains(node)) {\n          continue;\n        }\n\n        Set\u003cOneBlockInfo\u003e blocksInCurrentNode \u003d one.getValue();\n\n        // for each block, copy it into validBlocks. Delete it from\n        // blockToNodes so that the same block does not appear in\n        // two different splits.\n        Iterator\u003cOneBlockInfo\u003e oneBlockIter \u003d blocksInCurrentNode.iterator();\n        while (oneBlockIter.hasNext()) {\n          OneBlockInfo oneblock \u003d oneBlockIter.next();\n          \n          // Remove all blocks which may already have been assigned to other\n          // splits.\n          if(!blockToNodes.containsKey(oneblock)) {\n            oneBlockIter.remove();\n            continue;\n          }\n        \n          validBlocks.add(oneblock);\n          blockToNodes.remove(oneblock);\n          curSplitSize +\u003d oneblock.length;\n\n          // if the accumulated split size exceeds the maximum, then\n          // create this split.\n          if (maxSize !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d maxSize) {\n            // create an input split and add it to the splits array\n            addCreatedSplit(splits, Collections.singleton(node), validBlocks);\n            totalLength -\u003d curSplitSize;\n            curSplitSize \u003d 0;\n\n            splitsPerNode.add(node);\n\n            // Remove entries from blocksInNode so that we don\u0027t walk these\n            // again.\n            blocksInCurrentNode.removeAll(validBlocks);\n            validBlocks.clear();\n\n            // Done creating a single split for this node. Move on to the next\n            // node so that splits are distributed across nodes.\n            break;\n          }\n\n        }\n        if (validBlocks.size() !\u003d 0) {\n          // This implies that the last few blocks (or all in case maxSize\u003d0)\n          // were not part of a split. The node is complete.\n          \n          // if there were any blocks left over and their combined size is\n          // larger than minSplitNode, then combine them into one split.\n          // Otherwise add them back to the unprocessed pool. It is likely\n          // that they will be combined with other blocks from the\n          // same rack later on.\n          // This condition also kicks in when max split size is not set. All\n          // blocks on a node will be grouped together into a single split.\n          if (minSizeNode !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d minSizeNode\n              \u0026\u0026 splitsPerNode.count(node) \u003d\u003d 0) {\n            // haven\u0027t created any split on this machine. so its ok to add a\n            // smaller one for parallelism. Otherwise group it in the rack for\n            // balanced size create an input split and add it to the splits\n            // array\n            addCreatedSplit(splits, Collections.singleton(node), validBlocks);\n            totalLength -\u003d curSplitSize;\n            splitsPerNode.add(node);\n            // Remove entries from blocksInNode so that we don\u0027t walk this again.\n            blocksInCurrentNode.removeAll(validBlocks);\n            // The node is done. This was the last set of blocks for this node.\n          } else {\n            // Put the unplaced blocks back into the pool for later rack-allocation.\n            for (OneBlockInfo oneblock : validBlocks) {\n              blockToNodes.put(oneblock, oneblock.hosts);\n            }\n          }\n          validBlocks.clear();\n          curSplitSize \u003d 0;\n          completedNodes.add(node);\n        } else { // No in-flight blocks.\n          if (blocksInCurrentNode.size() \u003d\u003d 0) {\n            // Node is done. All blocks were fit into node-local splits.\n            completedNodes.add(node);\n          } // else Run through the node again.\n        }\n      }\n\n      // Check if node-local assignments are complete.\n      if (completedNodes.size() \u003d\u003d totalNodes || totalLength \u003d\u003d 0) {\n        // All nodes have been walked over and marked as completed or all blocks\n        // have been assigned. The rest should be handled via rackLock assignment.\n        LOG.info(\"DEBUG: Terminated node allocation with : CompletedNodes: \"\n            + completedNodes.size() + \", size left: \" + totalLength);\n        break;\n      }\n    }\n\n    // if blocks in a rack are below the specified minimum size, then keep them\n    // in \u0027overflow\u0027. After the processing of all racks is complete, these \n    // overflow blocks will be combined into splits.\n    ArrayList\u003cOneBlockInfo\u003e overflowBlocks \u003d new ArrayList\u003cOneBlockInfo\u003e();\n    Set\u003cString\u003e racks \u003d new HashSet\u003cString\u003e();\n\n    // Process all racks over and over again until there is no more work to do.\n    while (blockToNodes.size() \u003e 0) {\n\n      // Create one split for this rack before moving over to the next rack. \n      // Come back to this rack after creating a single split for each of the \n      // remaining racks.\n      // Process one rack location at a time, Combine all possible blocks that\n      // reside on this rack as one split. (constrained by minimum and maximum\n      // split size).\n\n      // iterate over all racks \n      for (Iterator\u003cMap.Entry\u003cString, List\u003cOneBlockInfo\u003e\u003e\u003e iter \u003d \n           rackToBlocks.entrySet().iterator(); iter.hasNext();) {\n\n        Map.Entry\u003cString, List\u003cOneBlockInfo\u003e\u003e one \u003d iter.next();\n        racks.add(one.getKey());\n        List\u003cOneBlockInfo\u003e blocks \u003d one.getValue();\n\n        // for each block, copy it into validBlocks. Delete it from \n        // blockToNodes so that the same block does not appear in \n        // two different splits.\n        boolean createdSplit \u003d false;\n        for (OneBlockInfo oneblock : blocks) {\n          if (blockToNodes.containsKey(oneblock)) {\n            validBlocks.add(oneblock);\n            blockToNodes.remove(oneblock);\n            curSplitSize +\u003d oneblock.length;\n      \n            // if the accumulated split size exceeds the maximum, then \n            // create this split.\n            if (maxSize !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d maxSize) {\n              // create an input split and add it to the splits array\n              addCreatedSplit(splits, getHosts(racks), validBlocks);\n              createdSplit \u003d true;\n              break;\n            }\n          }\n        }\n\n        // if we created a split, then just go to the next rack\n        if (createdSplit) {\n          curSplitSize \u003d 0;\n          validBlocks.clear();\n          racks.clear();\n          continue;\n        }\n\n        if (!validBlocks.isEmpty()) {\n          if (minSizeRack !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d minSizeRack) {\n            // if there is a minimum size specified, then create a single split\n            // otherwise, store these blocks into overflow data structure\n            addCreatedSplit(splits, getHosts(racks), validBlocks);\n          } else {\n            // There were a few blocks in this rack that \n        \t// remained to be processed. Keep them in \u0027overflow\u0027 block list. \n        \t// These will be combined later.\n            overflowBlocks.addAll(validBlocks);\n          }\n        }\n        curSplitSize \u003d 0;\n        validBlocks.clear();\n        racks.clear();\n      }\n    }\n\n    assert blockToNodes.isEmpty();\n    assert curSplitSize \u003d\u003d 0;\n    assert validBlocks.isEmpty();\n    assert racks.isEmpty();\n\n    // Process all overflow blocks\n    for (OneBlockInfo oneblock : overflowBlocks) {\n      validBlocks.add(oneblock);\n      curSplitSize +\u003d oneblock.length;\n\n      // This might cause an exiting rack location to be re-added,\n      // but it should be ok.\n      for (int i \u003d 0; i \u003c oneblock.racks.length; i++) {\n        racks.add(oneblock.racks[i]);\n      }\n\n      // if the accumulated split size exceeds the maximum, then \n      // create this split.\n      if (maxSize !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d maxSize) {\n        // create an input split and add it to the splits array\n        addCreatedSplit(splits, getHosts(racks), validBlocks);\n        curSplitSize \u003d 0;\n        validBlocks.clear();\n        racks.clear();\n      }\n    }\n\n    // Process any remaining blocks, if any.\n    if (!validBlocks.isEmpty()) {\n      addCreatedSplit(splits, getHosts(racks), validBlocks);\n    }\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/input/CombineFileInputFormat.java",
          "extendedDetails": {}
        }
      ]
    },
    "0b9ed2364a0690d62a0d51d636027acb984e3e91": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-4892. Modify CombineFileInputFormat to not skew input slits\u0027 allocation on small clusters. Contributed by Bikas Saha.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1450912 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/02/13 10:49 AM",
      "commitName": "0b9ed2364a0690d62a0d51d636027acb984e3e91",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "diff": "@@ -0,0 +1,194 @@\n+  void createSplits(HashMap\u003cString, List\u003cOneBlockInfo\u003e\u003e nodeToBlocks,\n+                     HashMap\u003cOneBlockInfo, String[]\u003e blockToNodes,\n+                     HashMap\u003cString, List\u003cOneBlockInfo\u003e\u003e rackToBlocks,\n+                     long totLength,\n+                     long maxSize,\n+                     long minSizeNode,\n+                     long minSizeRack,\n+                     List\u003cInputSplit\u003e splits                     \n+                    ) {\n+    ArrayList\u003cOneBlockInfo\u003e validBlocks \u003d new ArrayList\u003cOneBlockInfo\u003e();\n+    Set\u003cString\u003e nodes \u003d new HashSet\u003cString\u003e();\n+    long curSplitSize \u003d 0;\n+    \n+    int numNodes \u003d nodeToBlocks.size();\n+    long totalLength \u003d totLength;\n+\n+    while(true) {\n+      // it is allowed for maxSize to be 0. Disable smoothing load for such cases\n+      int avgSplitsPerNode \u003d maxSize \u003e 0 \u0026\u0026 numNodes \u003e 0 ?\n+                                        ((int) (totalLength/maxSize))/numNodes\n+                                        : Integer.MAX_VALUE;\n+      int maxSplitsByNodeOnly \u003d (avgSplitsPerNode \u003e 0) ? avgSplitsPerNode : 1;\n+      numNodes \u003d 0;\n+\n+      // process all nodes and create splits that are local to a node.\n+      for (Iterator\u003cMap.Entry\u003cString, List\u003cOneBlockInfo\u003e\u003e\u003e iter \u003d nodeToBlocks\n+          .entrySet().iterator(); iter.hasNext();) {\n+        Map.Entry\u003cString, List\u003cOneBlockInfo\u003e\u003e one \u003d iter.next();\n+        nodes.add(one.getKey());\n+        List\u003cOneBlockInfo\u003e blocksInNode \u003d one.getValue();\n+\n+        // for each block, copy it into validBlocks. Delete it from\n+        // blockToNodes so that the same block does not appear in\n+        // two different splits.\n+        int splitsInNode \u003d 0;\n+        for (OneBlockInfo oneblock : blocksInNode) {\n+          if (blockToNodes.containsKey(oneblock)) {\n+            validBlocks.add(oneblock);\n+            blockToNodes.remove(oneblock);\n+            curSplitSize +\u003d oneblock.length;\n+\n+            // if the accumulated split size exceeds the maximum, then\n+            // create this split.\n+            if (maxSize !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d maxSize) {\n+              // create an input split and add it to the splits array\n+              addCreatedSplit(splits, nodes, validBlocks);\n+              totalLength -\u003d curSplitSize;\n+              curSplitSize \u003d 0;\n+              validBlocks.clear();\n+              splitsInNode++;\n+              if (splitsInNode \u003d\u003d maxSplitsByNodeOnly) {\n+                // stop grouping on a node so as not to create\n+                // disproportionately more splits on a node because it happens\n+                // to have many blocks\n+                // consider only these nodes in next round of grouping because\n+                // they have leftover blocks that may need to be grouped\n+                numNodes++;\n+                break;\n+              }\n+            }\n+          }\n+        }\n+        // if there were any blocks left over and their combined size is\n+        // larger than minSplitNode, then combine them into one split.\n+        // Otherwise add them back to the unprocessed pool. It is likely\n+        // that they will be combined with other blocks from the\n+        // same rack later on.\n+        if (minSizeNode !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d minSizeNode\n+            \u0026\u0026 splitsInNode \u003d\u003d 0) {\n+          // haven\u0027t created any split on this machine. so its ok to add a\n+          // smaller\n+          // one for parallelism. Otherwise group it in the rack for balanced\n+          // size\n+          // create an input split and add it to the splits array\n+          addCreatedSplit(splits, nodes, validBlocks);\n+          totalLength -\u003d curSplitSize;\n+        } else {\n+          for (OneBlockInfo oneblock : validBlocks) {\n+            blockToNodes.put(oneblock, oneblock.hosts);\n+          }\n+        }\n+        validBlocks.clear();\n+        nodes.clear();\n+        curSplitSize \u003d 0;\n+      }\n+      \n+      if(!(numNodes\u003e0 \u0026\u0026 totalLength\u003e0)) {\n+        break;\n+      }\n+    }\n+\n+    // if blocks in a rack are below the specified minimum size, then keep them\n+    // in \u0027overflow\u0027. After the processing of all racks is complete, these \n+    // overflow blocks will be combined into splits.\n+    ArrayList\u003cOneBlockInfo\u003e overflowBlocks \u003d new ArrayList\u003cOneBlockInfo\u003e();\n+    Set\u003cString\u003e racks \u003d new HashSet\u003cString\u003e();\n+\n+    // Process all racks over and over again until there is no more work to do.\n+    while (blockToNodes.size() \u003e 0) {\n+\n+      // Create one split for this rack before moving over to the next rack. \n+      // Come back to this rack after creating a single split for each of the \n+      // remaining racks.\n+      // Process one rack location at a time, Combine all possible blocks that\n+      // reside on this rack as one split. (constrained by minimum and maximum\n+      // split size).\n+\n+      // iterate over all racks \n+      for (Iterator\u003cMap.Entry\u003cString, List\u003cOneBlockInfo\u003e\u003e\u003e iter \u003d \n+           rackToBlocks.entrySet().iterator(); iter.hasNext();) {\n+\n+        Map.Entry\u003cString, List\u003cOneBlockInfo\u003e\u003e one \u003d iter.next();\n+        racks.add(one.getKey());\n+        List\u003cOneBlockInfo\u003e blocks \u003d one.getValue();\n+\n+        // for each block, copy it into validBlocks. Delete it from \n+        // blockToNodes so that the same block does not appear in \n+        // two different splits.\n+        boolean createdSplit \u003d false;\n+        for (OneBlockInfo oneblock : blocks) {\n+          if (blockToNodes.containsKey(oneblock)) {\n+            validBlocks.add(oneblock);\n+            blockToNodes.remove(oneblock);\n+            curSplitSize +\u003d oneblock.length;\n+      \n+            // if the accumulated split size exceeds the maximum, then \n+            // create this split.\n+            if (maxSize !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d maxSize) {\n+              // create an input split and add it to the splits array\n+              addCreatedSplit(splits, getHosts(racks), validBlocks);\n+              createdSplit \u003d true;\n+              break;\n+            }\n+          }\n+        }\n+\n+        // if we created a split, then just go to the next rack\n+        if (createdSplit) {\n+          curSplitSize \u003d 0;\n+          validBlocks.clear();\n+          racks.clear();\n+          continue;\n+        }\n+\n+        if (!validBlocks.isEmpty()) {\n+          if (minSizeRack !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d minSizeRack) {\n+            // if there is a minimum size specified, then create a single split\n+            // otherwise, store these blocks into overflow data structure\n+            addCreatedSplit(splits, getHosts(racks), validBlocks);\n+          } else {\n+            // There were a few blocks in this rack that \n+        \t// remained to be processed. Keep them in \u0027overflow\u0027 block list. \n+        \t// These will be combined later.\n+            overflowBlocks.addAll(validBlocks);\n+          }\n+        }\n+        curSplitSize \u003d 0;\n+        validBlocks.clear();\n+        racks.clear();\n+      }\n+    }\n+\n+    assert blockToNodes.isEmpty();\n+    assert curSplitSize \u003d\u003d 0;\n+    assert validBlocks.isEmpty();\n+    assert racks.isEmpty();\n+\n+    // Process all overflow blocks\n+    for (OneBlockInfo oneblock : overflowBlocks) {\n+      validBlocks.add(oneblock);\n+      curSplitSize +\u003d oneblock.length;\n+\n+      // This might cause an exiting rack location to be re-added,\n+      // but it should be ok.\n+      for (int i \u003d 0; i \u003c oneblock.racks.length; i++) {\n+        racks.add(oneblock.racks[i]);\n+      }\n+\n+      // if the accumulated split size exceeds the maximum, then \n+      // create this split.\n+      if (maxSize !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d maxSize) {\n+        // create an input split and add it to the splits array\n+        addCreatedSplit(splits, getHosts(racks), validBlocks);\n+        curSplitSize \u003d 0;\n+        validBlocks.clear();\n+        racks.clear();\n+      }\n+    }\n+\n+    // Process any remaining blocks, if any.\n+    if (!validBlocks.isEmpty()) {\n+      addCreatedSplit(splits, getHosts(racks), validBlocks);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  void createSplits(HashMap\u003cString, List\u003cOneBlockInfo\u003e\u003e nodeToBlocks,\n                     HashMap\u003cOneBlockInfo, String[]\u003e blockToNodes,\n                     HashMap\u003cString, List\u003cOneBlockInfo\u003e\u003e rackToBlocks,\n                     long totLength,\n                     long maxSize,\n                     long minSizeNode,\n                     long minSizeRack,\n                     List\u003cInputSplit\u003e splits                     \n                    ) {\n    ArrayList\u003cOneBlockInfo\u003e validBlocks \u003d new ArrayList\u003cOneBlockInfo\u003e();\n    Set\u003cString\u003e nodes \u003d new HashSet\u003cString\u003e();\n    long curSplitSize \u003d 0;\n    \n    int numNodes \u003d nodeToBlocks.size();\n    long totalLength \u003d totLength;\n\n    while(true) {\n      // it is allowed for maxSize to be 0. Disable smoothing load for such cases\n      int avgSplitsPerNode \u003d maxSize \u003e 0 \u0026\u0026 numNodes \u003e 0 ?\n                                        ((int) (totalLength/maxSize))/numNodes\n                                        : Integer.MAX_VALUE;\n      int maxSplitsByNodeOnly \u003d (avgSplitsPerNode \u003e 0) ? avgSplitsPerNode : 1;\n      numNodes \u003d 0;\n\n      // process all nodes and create splits that are local to a node.\n      for (Iterator\u003cMap.Entry\u003cString, List\u003cOneBlockInfo\u003e\u003e\u003e iter \u003d nodeToBlocks\n          .entrySet().iterator(); iter.hasNext();) {\n        Map.Entry\u003cString, List\u003cOneBlockInfo\u003e\u003e one \u003d iter.next();\n        nodes.add(one.getKey());\n        List\u003cOneBlockInfo\u003e blocksInNode \u003d one.getValue();\n\n        // for each block, copy it into validBlocks. Delete it from\n        // blockToNodes so that the same block does not appear in\n        // two different splits.\n        int splitsInNode \u003d 0;\n        for (OneBlockInfo oneblock : blocksInNode) {\n          if (blockToNodes.containsKey(oneblock)) {\n            validBlocks.add(oneblock);\n            blockToNodes.remove(oneblock);\n            curSplitSize +\u003d oneblock.length;\n\n            // if the accumulated split size exceeds the maximum, then\n            // create this split.\n            if (maxSize !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d maxSize) {\n              // create an input split and add it to the splits array\n              addCreatedSplit(splits, nodes, validBlocks);\n              totalLength -\u003d curSplitSize;\n              curSplitSize \u003d 0;\n              validBlocks.clear();\n              splitsInNode++;\n              if (splitsInNode \u003d\u003d maxSplitsByNodeOnly) {\n                // stop grouping on a node so as not to create\n                // disproportionately more splits on a node because it happens\n                // to have many blocks\n                // consider only these nodes in next round of grouping because\n                // they have leftover blocks that may need to be grouped\n                numNodes++;\n                break;\n              }\n            }\n          }\n        }\n        // if there were any blocks left over and their combined size is\n        // larger than minSplitNode, then combine them into one split.\n        // Otherwise add them back to the unprocessed pool. It is likely\n        // that they will be combined with other blocks from the\n        // same rack later on.\n        if (minSizeNode !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d minSizeNode\n            \u0026\u0026 splitsInNode \u003d\u003d 0) {\n          // haven\u0027t created any split on this machine. so its ok to add a\n          // smaller\n          // one for parallelism. Otherwise group it in the rack for balanced\n          // size\n          // create an input split and add it to the splits array\n          addCreatedSplit(splits, nodes, validBlocks);\n          totalLength -\u003d curSplitSize;\n        } else {\n          for (OneBlockInfo oneblock : validBlocks) {\n            blockToNodes.put(oneblock, oneblock.hosts);\n          }\n        }\n        validBlocks.clear();\n        nodes.clear();\n        curSplitSize \u003d 0;\n      }\n      \n      if(!(numNodes\u003e0 \u0026\u0026 totalLength\u003e0)) {\n        break;\n      }\n    }\n\n    // if blocks in a rack are below the specified minimum size, then keep them\n    // in \u0027overflow\u0027. After the processing of all racks is complete, these \n    // overflow blocks will be combined into splits.\n    ArrayList\u003cOneBlockInfo\u003e overflowBlocks \u003d new ArrayList\u003cOneBlockInfo\u003e();\n    Set\u003cString\u003e racks \u003d new HashSet\u003cString\u003e();\n\n    // Process all racks over and over again until there is no more work to do.\n    while (blockToNodes.size() \u003e 0) {\n\n      // Create one split for this rack before moving over to the next rack. \n      // Come back to this rack after creating a single split for each of the \n      // remaining racks.\n      // Process one rack location at a time, Combine all possible blocks that\n      // reside on this rack as one split. (constrained by minimum and maximum\n      // split size).\n\n      // iterate over all racks \n      for (Iterator\u003cMap.Entry\u003cString, List\u003cOneBlockInfo\u003e\u003e\u003e iter \u003d \n           rackToBlocks.entrySet().iterator(); iter.hasNext();) {\n\n        Map.Entry\u003cString, List\u003cOneBlockInfo\u003e\u003e one \u003d iter.next();\n        racks.add(one.getKey());\n        List\u003cOneBlockInfo\u003e blocks \u003d one.getValue();\n\n        // for each block, copy it into validBlocks. Delete it from \n        // blockToNodes so that the same block does not appear in \n        // two different splits.\n        boolean createdSplit \u003d false;\n        for (OneBlockInfo oneblock : blocks) {\n          if (blockToNodes.containsKey(oneblock)) {\n            validBlocks.add(oneblock);\n            blockToNodes.remove(oneblock);\n            curSplitSize +\u003d oneblock.length;\n      \n            // if the accumulated split size exceeds the maximum, then \n            // create this split.\n            if (maxSize !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d maxSize) {\n              // create an input split and add it to the splits array\n              addCreatedSplit(splits, getHosts(racks), validBlocks);\n              createdSplit \u003d true;\n              break;\n            }\n          }\n        }\n\n        // if we created a split, then just go to the next rack\n        if (createdSplit) {\n          curSplitSize \u003d 0;\n          validBlocks.clear();\n          racks.clear();\n          continue;\n        }\n\n        if (!validBlocks.isEmpty()) {\n          if (minSizeRack !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d minSizeRack) {\n            // if there is a minimum size specified, then create a single split\n            // otherwise, store these blocks into overflow data structure\n            addCreatedSplit(splits, getHosts(racks), validBlocks);\n          } else {\n            // There were a few blocks in this rack that \n        \t// remained to be processed. Keep them in \u0027overflow\u0027 block list. \n        \t// These will be combined later.\n            overflowBlocks.addAll(validBlocks);\n          }\n        }\n        curSplitSize \u003d 0;\n        validBlocks.clear();\n        racks.clear();\n      }\n    }\n\n    assert blockToNodes.isEmpty();\n    assert curSplitSize \u003d\u003d 0;\n    assert validBlocks.isEmpty();\n    assert racks.isEmpty();\n\n    // Process all overflow blocks\n    for (OneBlockInfo oneblock : overflowBlocks) {\n      validBlocks.add(oneblock);\n      curSplitSize +\u003d oneblock.length;\n\n      // This might cause an exiting rack location to be re-added,\n      // but it should be ok.\n      for (int i \u003d 0; i \u003c oneblock.racks.length; i++) {\n        racks.add(oneblock.racks[i]);\n      }\n\n      // if the accumulated split size exceeds the maximum, then \n      // create this split.\n      if (maxSize !\u003d 0 \u0026\u0026 curSplitSize \u003e\u003d maxSize) {\n        // create an input split and add it to the splits array\n        addCreatedSplit(splits, getHosts(racks), validBlocks);\n        curSplitSize \u003d 0;\n        validBlocks.clear();\n        racks.clear();\n      }\n    }\n\n    // Process any remaining blocks, if any.\n    if (!validBlocks.isEmpty()) {\n      addCreatedSplit(splits, getHosts(racks), validBlocks);\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/input/CombineFileInputFormat.java"
    }
  }
}