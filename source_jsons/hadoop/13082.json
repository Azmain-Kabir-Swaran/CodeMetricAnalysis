{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockIdManager.java",
  "functionName": "getNextLegacyGenerationStamp",
  "functionId": "getNextLegacyGenerationStamp",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockIdManager.java",
  "functionStartLine": 224,
  "functionEndLine": 236,
  "numCommitsSeen": 767,
  "timeTaken": 33326,
  "changeHistory": [
    "ec25c7f9c7e60c077d8c4143253c20445fcdaecf",
    "3a9571308e99cc374681bbc451a517d41a150aa0",
    "8a91109d16394310f2568717f103e6fff7cbddb0",
    "571e9c623241106dad5521a870fb8daef3f2b00a",
    "6770de7ec4f73e16740f1723f4e35d2fef2c22c8",
    "36c5fe9961a905385282d1a05ced08c83684dd02",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "ec25c7f9c7e60c077d8c4143253c20445fcdaecf": "Ymultichange(Yrename,Ybodychange)",
    "3a9571308e99cc374681bbc451a517d41a150aa0": "Ymultichange(Yrename,Ybodychange)",
    "8a91109d16394310f2568717f103e6fff7cbddb0": "Ymultichange(Yrename,Ybodychange)",
    "571e9c623241106dad5521a870fb8daef3f2b00a": "Ymovefromfile",
    "6770de7ec4f73e16740f1723f4e35d2fef2c22c8": "Ymultichange(Yrename,Ymodifierchange,Yexceptionschange,Ybodychange)",
    "36c5fe9961a905385282d1a05ced08c83684dd02": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "ec25c7f9c7e60c077d8c4143253c20445fcdaecf": {
      "type": "Ymultichange(Yrename,Ybodychange)",
      "commitMessage": "HDFS-9677. Rename generationStampV1/generationStampV2 to legacyGenerationStamp/generationStamp. Contributed by Mingliang Liu.\n",
      "commitDate": "27/01/16 4:34 PM",
      "commitName": "ec25c7f9c7e60c077d8c4143253c20445fcdaecf",
      "commitAuthor": "Jing Zhao",
      "subchanges": [
        {
          "type": "Yrename",
          "commitMessage": "HDFS-9677. Rename generationStampV1/generationStampV2 to legacyGenerationStamp/generationStamp. Contributed by Mingliang Liu.\n",
          "commitDate": "27/01/16 4:34 PM",
          "commitName": "ec25c7f9c7e60c077d8c4143253c20445fcdaecf",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "27/01/16 4:31 PM",
          "commitNameOld": "3a9571308e99cc374681bbc451a517d41a150aa0",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,13 +1,13 @@\n-  long getNextGenerationStampV1() throws IOException {\n-    long genStampV1 \u003d generationStampV1.nextValue();\n+  long getNextLegacyGenerationStamp() throws IOException {\n+    long legacyGenStamp \u003d legacyGenerationStamp.nextValue();\n \n-    if (genStampV1 \u003e\u003d generationStampV1Limit) {\n+    if (legacyGenStamp \u003e\u003d legacyGenerationStampLimit) {\n       // We ran out of generation stamps for legacy blocks. In practice, it\n-      // is extremely unlikely as we reserved 1T v1 generation stamps. The\n+      // is extremely unlikely as we reserved 1T legacy generation stamps. The\n       // result is that we can no longer append to the legacy blocks that\n       // were created before the upgrade to sequential block IDs.\n-      throw new OutOfV1GenerationStampsException();\n+      throw new OutOfLegacyGenerationStampsException();\n     }\n \n-    return genStampV1;\n+    return legacyGenStamp;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  long getNextLegacyGenerationStamp() throws IOException {\n    long legacyGenStamp \u003d legacyGenerationStamp.nextValue();\n\n    if (legacyGenStamp \u003e\u003d legacyGenerationStampLimit) {\n      // We ran out of generation stamps for legacy blocks. In practice, it\n      // is extremely unlikely as we reserved 1T legacy generation stamps. The\n      // result is that we can no longer append to the legacy blocks that\n      // were created before the upgrade to sequential block IDs.\n      throw new OutOfLegacyGenerationStampsException();\n    }\n\n    return legacyGenStamp;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockIdManager.java",
          "extendedDetails": {
            "oldValue": "getNextGenerationStampV1",
            "newValue": "getNextLegacyGenerationStamp"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-9677. Rename generationStampV1/generationStampV2 to legacyGenerationStamp/generationStamp. Contributed by Mingliang Liu.\n",
          "commitDate": "27/01/16 4:34 PM",
          "commitName": "ec25c7f9c7e60c077d8c4143253c20445fcdaecf",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "27/01/16 4:31 PM",
          "commitNameOld": "3a9571308e99cc374681bbc451a517d41a150aa0",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,13 +1,13 @@\n-  long getNextGenerationStampV1() throws IOException {\n-    long genStampV1 \u003d generationStampV1.nextValue();\n+  long getNextLegacyGenerationStamp() throws IOException {\n+    long legacyGenStamp \u003d legacyGenerationStamp.nextValue();\n \n-    if (genStampV1 \u003e\u003d generationStampV1Limit) {\n+    if (legacyGenStamp \u003e\u003d legacyGenerationStampLimit) {\n       // We ran out of generation stamps for legacy blocks. In practice, it\n-      // is extremely unlikely as we reserved 1T v1 generation stamps. The\n+      // is extremely unlikely as we reserved 1T legacy generation stamps. The\n       // result is that we can no longer append to the legacy blocks that\n       // were created before the upgrade to sequential block IDs.\n-      throw new OutOfV1GenerationStampsException();\n+      throw new OutOfLegacyGenerationStampsException();\n     }\n \n-    return genStampV1;\n+    return legacyGenStamp;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  long getNextLegacyGenerationStamp() throws IOException {\n    long legacyGenStamp \u003d legacyGenerationStamp.nextValue();\n\n    if (legacyGenStamp \u003e\u003d legacyGenerationStampLimit) {\n      // We ran out of generation stamps for legacy blocks. In practice, it\n      // is extremely unlikely as we reserved 1T legacy generation stamps. The\n      // result is that we can no longer append to the legacy blocks that\n      // were created before the upgrade to sequential block IDs.\n      throw new OutOfLegacyGenerationStampsException();\n    }\n\n    return legacyGenStamp;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockIdManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "3a9571308e99cc374681bbc451a517d41a150aa0": {
      "type": "Ymultichange(Yrename,Ybodychange)",
      "commitMessage": "Revert \"HDFS-9677. Rename generationStampV1/generationStampV2 to legacyGenerationStamp/generationStamp. Contributed by Mingliang Liu.\"\n\nThis reverts commit 8a91109d16394310f2568717f103e6fff7cbddb0.\n",
      "commitDate": "27/01/16 4:31 PM",
      "commitName": "3a9571308e99cc374681bbc451a517d41a150aa0",
      "commitAuthor": "Jing Zhao",
      "subchanges": [
        {
          "type": "Yrename",
          "commitMessage": "Revert \"HDFS-9677. Rename generationStampV1/generationStampV2 to legacyGenerationStamp/generationStamp. Contributed by Mingliang Liu.\"\n\nThis reverts commit 8a91109d16394310f2568717f103e6fff7cbddb0.\n",
          "commitDate": "27/01/16 4:31 PM",
          "commitName": "3a9571308e99cc374681bbc451a517d41a150aa0",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "27/01/16 3:48 PM",
          "commitNameOld": "8a91109d16394310f2568717f103e6fff7cbddb0",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 0.03,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,13 +1,13 @@\n-  long getNextLegacyGenerationStamp() throws IOException {\n-    long legacyGenStamp \u003d legacyGenerationStamp.nextValue();\n+  long getNextGenerationStampV1() throws IOException {\n+    long genStampV1 \u003d generationStampV1.nextValue();\n \n-    if (legacyGenStamp \u003e\u003d legacyGenerationStampLimit) {\n+    if (genStampV1 \u003e\u003d generationStampV1Limit) {\n       // We ran out of generation stamps for legacy blocks. In practice, it\n-      // is extremely unlikely as we reserved 1T legacy generation stamps. The\n+      // is extremely unlikely as we reserved 1T v1 generation stamps. The\n       // result is that we can no longer append to the legacy blocks that\n       // were created before the upgrade to sequential block IDs.\n-      throw new OutOfLegacyGenerationStampsException();\n+      throw new OutOfV1GenerationStampsException();\n     }\n \n-    return legacyGenStamp;\n+    return genStampV1;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  long getNextGenerationStampV1() throws IOException {\n    long genStampV1 \u003d generationStampV1.nextValue();\n\n    if (genStampV1 \u003e\u003d generationStampV1Limit) {\n      // We ran out of generation stamps for legacy blocks. In practice, it\n      // is extremely unlikely as we reserved 1T v1 generation stamps. The\n      // result is that we can no longer append to the legacy blocks that\n      // were created before the upgrade to sequential block IDs.\n      throw new OutOfV1GenerationStampsException();\n    }\n\n    return genStampV1;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockIdManager.java",
          "extendedDetails": {
            "oldValue": "getNextLegacyGenerationStamp",
            "newValue": "getNextGenerationStampV1"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "Revert \"HDFS-9677. Rename generationStampV1/generationStampV2 to legacyGenerationStamp/generationStamp. Contributed by Mingliang Liu.\"\n\nThis reverts commit 8a91109d16394310f2568717f103e6fff7cbddb0.\n",
          "commitDate": "27/01/16 4:31 PM",
          "commitName": "3a9571308e99cc374681bbc451a517d41a150aa0",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "27/01/16 3:48 PM",
          "commitNameOld": "8a91109d16394310f2568717f103e6fff7cbddb0",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 0.03,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,13 +1,13 @@\n-  long getNextLegacyGenerationStamp() throws IOException {\n-    long legacyGenStamp \u003d legacyGenerationStamp.nextValue();\n+  long getNextGenerationStampV1() throws IOException {\n+    long genStampV1 \u003d generationStampV1.nextValue();\n \n-    if (legacyGenStamp \u003e\u003d legacyGenerationStampLimit) {\n+    if (genStampV1 \u003e\u003d generationStampV1Limit) {\n       // We ran out of generation stamps for legacy blocks. In practice, it\n-      // is extremely unlikely as we reserved 1T legacy generation stamps. The\n+      // is extremely unlikely as we reserved 1T v1 generation stamps. The\n       // result is that we can no longer append to the legacy blocks that\n       // were created before the upgrade to sequential block IDs.\n-      throw new OutOfLegacyGenerationStampsException();\n+      throw new OutOfV1GenerationStampsException();\n     }\n \n-    return legacyGenStamp;\n+    return genStampV1;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  long getNextGenerationStampV1() throws IOException {\n    long genStampV1 \u003d generationStampV1.nextValue();\n\n    if (genStampV1 \u003e\u003d generationStampV1Limit) {\n      // We ran out of generation stamps for legacy blocks. In practice, it\n      // is extremely unlikely as we reserved 1T v1 generation stamps. The\n      // result is that we can no longer append to the legacy blocks that\n      // were created before the upgrade to sequential block IDs.\n      throw new OutOfV1GenerationStampsException();\n    }\n\n    return genStampV1;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockIdManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "8a91109d16394310f2568717f103e6fff7cbddb0": {
      "type": "Ymultichange(Yrename,Ybodychange)",
      "commitMessage": "HDFS-9677. Rename generationStampV1/generationStampV2 to legacyGenerationStamp/generationStamp. Contributed by Mingliang Liu.\n",
      "commitDate": "27/01/16 3:48 PM",
      "commitName": "8a91109d16394310f2568717f103e6fff7cbddb0",
      "commitAuthor": "Jing Zhao",
      "subchanges": [
        {
          "type": "Yrename",
          "commitMessage": "HDFS-9677. Rename generationStampV1/generationStampV2 to legacyGenerationStamp/generationStamp. Contributed by Mingliang Liu.\n",
          "commitDate": "27/01/16 3:48 PM",
          "commitName": "8a91109d16394310f2568717f103e6fff7cbddb0",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "21/01/16 11:13 AM",
          "commitNameOld": "c304890c8c7782d835896859f5b7f60b96c306c0",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 6.19,
          "commitsBetweenForRepo": 45,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,13 +1,13 @@\n-  long getNextGenerationStampV1() throws IOException {\n-    long genStampV1 \u003d generationStampV1.nextValue();\n+  long getNextLegacyGenerationStamp() throws IOException {\n+    long legacyGenStamp \u003d legacyGenerationStamp.nextValue();\n \n-    if (genStampV1 \u003e\u003d generationStampV1Limit) {\n+    if (legacyGenStamp \u003e\u003d legacyGenerationStampLimit) {\n       // We ran out of generation stamps for legacy blocks. In practice, it\n-      // is extremely unlikely as we reserved 1T v1 generation stamps. The\n+      // is extremely unlikely as we reserved 1T legacy generation stamps. The\n       // result is that we can no longer append to the legacy blocks that\n       // were created before the upgrade to sequential block IDs.\n-      throw new OutOfV1GenerationStampsException();\n+      throw new OutOfLegacyGenerationStampsException();\n     }\n \n-    return genStampV1;\n+    return legacyGenStamp;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  long getNextLegacyGenerationStamp() throws IOException {\n    long legacyGenStamp \u003d legacyGenerationStamp.nextValue();\n\n    if (legacyGenStamp \u003e\u003d legacyGenerationStampLimit) {\n      // We ran out of generation stamps for legacy blocks. In practice, it\n      // is extremely unlikely as we reserved 1T legacy generation stamps. The\n      // result is that we can no longer append to the legacy blocks that\n      // were created before the upgrade to sequential block IDs.\n      throw new OutOfLegacyGenerationStampsException();\n    }\n\n    return legacyGenStamp;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockIdManager.java",
          "extendedDetails": {
            "oldValue": "getNextGenerationStampV1",
            "newValue": "getNextLegacyGenerationStamp"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-9677. Rename generationStampV1/generationStampV2 to legacyGenerationStamp/generationStamp. Contributed by Mingliang Liu.\n",
          "commitDate": "27/01/16 3:48 PM",
          "commitName": "8a91109d16394310f2568717f103e6fff7cbddb0",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "21/01/16 11:13 AM",
          "commitNameOld": "c304890c8c7782d835896859f5b7f60b96c306c0",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 6.19,
          "commitsBetweenForRepo": 45,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,13 +1,13 @@\n-  long getNextGenerationStampV1() throws IOException {\n-    long genStampV1 \u003d generationStampV1.nextValue();\n+  long getNextLegacyGenerationStamp() throws IOException {\n+    long legacyGenStamp \u003d legacyGenerationStamp.nextValue();\n \n-    if (genStampV1 \u003e\u003d generationStampV1Limit) {\n+    if (legacyGenStamp \u003e\u003d legacyGenerationStampLimit) {\n       // We ran out of generation stamps for legacy blocks. In practice, it\n-      // is extremely unlikely as we reserved 1T v1 generation stamps. The\n+      // is extremely unlikely as we reserved 1T legacy generation stamps. The\n       // result is that we can no longer append to the legacy blocks that\n       // were created before the upgrade to sequential block IDs.\n-      throw new OutOfV1GenerationStampsException();\n+      throw new OutOfLegacyGenerationStampsException();\n     }\n \n-    return genStampV1;\n+    return legacyGenStamp;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  long getNextLegacyGenerationStamp() throws IOException {\n    long legacyGenStamp \u003d legacyGenerationStamp.nextValue();\n\n    if (legacyGenStamp \u003e\u003d legacyGenerationStampLimit) {\n      // We ran out of generation stamps for legacy blocks. In practice, it\n      // is extremely unlikely as we reserved 1T legacy generation stamps. The\n      // result is that we can no longer append to the legacy blocks that\n      // were created before the upgrade to sequential block IDs.\n      throw new OutOfLegacyGenerationStampsException();\n    }\n\n    return legacyGenStamp;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockIdManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "571e9c623241106dad5521a870fb8daef3f2b00a": {
      "type": "Ymovefromfile",
      "commitMessage": "HDFS-7381. Decouple the management of block id and gen stamps from FSNamesystem. Contributed by Haohui Mai.\n",
      "commitDate": "11/11/14 12:42 PM",
      "commitName": "571e9c623241106dad5521a870fb8daef3f2b00a",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "11/11/14 12:33 PM",
      "commitNameOld": "0fd97f9c1989a793b882e6678285607472a3f75a",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  long getNextGenerationStampV1() throws IOException {\n    long genStampV1 \u003d generationStampV1.nextValue();\n\n    if (genStampV1 \u003e\u003d generationStampV1Limit) {\n      // We ran out of generation stamps for legacy blocks. In practice, it\n      // is extremely unlikely as we reserved 1T v1 generation stamps. The\n      // result is that we can no longer append to the legacy blocks that\n      // were created before the upgrade to sequential block IDs.\n      throw new OutOfV1GenerationStampsException();\n    }\n\n    return genStampV1;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockIdManager.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockIdManager.java",
        "oldMethodName": "getNextGenerationStampV1",
        "newMethodName": "getNextGenerationStampV1"
      }
    },
    "6770de7ec4f73e16740f1723f4e35d2fef2c22c8": {
      "type": "Ymultichange(Yrename,Ymodifierchange,Yexceptionschange,Ybodychange)",
      "commitMessage": "HDFS-4645.  Move from randomly generated block ID to sequentially generated block ID.  Contributed by Arpit Agarwal\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1500580 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/07/13 10:29 PM",
      "commitName": "6770de7ec4f73e16740f1723f4e35d2fef2c22c8",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Yrename",
          "commitMessage": "HDFS-4645.  Move from randomly generated block ID to sequentially generated block ID.  Contributed by Arpit Agarwal\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1500580 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "07/07/13 10:29 PM",
          "commitName": "6770de7ec4f73e16740f1723f4e35d2fef2c22c8",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "05/07/13 2:36 PM",
          "commitNameOld": "ed70fb1608e6c81314da83daddadd756394fb87e",
          "commitAuthorOld": "Konstantin Boudnik",
          "daysBetweenCommits": 2.33,
          "commitsBetweenForRepo": 3,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,13 @@\n-  private long nextGenerationStamp() throws SafeModeException {\n-    assert hasWriteLock();\n-    if (isInSafeMode()) {\n-      throw new SafeModeException(\n-          \"Cannot get next generation stamp\", safeMode);\n+  long getNextGenerationStampV1() throws IOException {\n+    long genStampV1 \u003d generationStampV1.nextValue();\n+\n+    if (genStampV1 \u003e\u003d generationStampV1Limit) {\n+      // We ran out of generation stamps for legacy blocks. In practice, it\n+      // is extremely unlikely as we reserved 1T v1 generation stamps. The\n+      // result is that we can no longer append to the legacy blocks that\n+      // were created before the upgrade to sequential block IDs.\n+      throw new OutOfV1GenerationStampsException();\n     }\n-    final long gs \u003d generationStamp.nextValue();\n-    getEditLog().logGenerationStamp(gs);\n-    // NB: callers sync the log\n-    return gs;\n+\n+    return genStampV1;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  long getNextGenerationStampV1() throws IOException {\n    long genStampV1 \u003d generationStampV1.nextValue();\n\n    if (genStampV1 \u003e\u003d generationStampV1Limit) {\n      // We ran out of generation stamps for legacy blocks. In practice, it\n      // is extremely unlikely as we reserved 1T v1 generation stamps. The\n      // result is that we can no longer append to the legacy blocks that\n      // were created before the upgrade to sequential block IDs.\n      throw new OutOfV1GenerationStampsException();\n    }\n\n    return genStampV1;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {
            "oldValue": "nextGenerationStamp",
            "newValue": "getNextGenerationStampV1"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-4645.  Move from randomly generated block ID to sequentially generated block ID.  Contributed by Arpit Agarwal\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1500580 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "07/07/13 10:29 PM",
          "commitName": "6770de7ec4f73e16740f1723f4e35d2fef2c22c8",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "05/07/13 2:36 PM",
          "commitNameOld": "ed70fb1608e6c81314da83daddadd756394fb87e",
          "commitAuthorOld": "Konstantin Boudnik",
          "daysBetweenCommits": 2.33,
          "commitsBetweenForRepo": 3,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,13 @@\n-  private long nextGenerationStamp() throws SafeModeException {\n-    assert hasWriteLock();\n-    if (isInSafeMode()) {\n-      throw new SafeModeException(\n-          \"Cannot get next generation stamp\", safeMode);\n+  long getNextGenerationStampV1() throws IOException {\n+    long genStampV1 \u003d generationStampV1.nextValue();\n+\n+    if (genStampV1 \u003e\u003d generationStampV1Limit) {\n+      // We ran out of generation stamps for legacy blocks. In practice, it\n+      // is extremely unlikely as we reserved 1T v1 generation stamps. The\n+      // result is that we can no longer append to the legacy blocks that\n+      // were created before the upgrade to sequential block IDs.\n+      throw new OutOfV1GenerationStampsException();\n     }\n-    final long gs \u003d generationStamp.nextValue();\n-    getEditLog().logGenerationStamp(gs);\n-    // NB: callers sync the log\n-    return gs;\n+\n+    return genStampV1;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  long getNextGenerationStampV1() throws IOException {\n    long genStampV1 \u003d generationStampV1.nextValue();\n\n    if (genStampV1 \u003e\u003d generationStampV1Limit) {\n      // We ran out of generation stamps for legacy blocks. In practice, it\n      // is extremely unlikely as we reserved 1T v1 generation stamps. The\n      // result is that we can no longer append to the legacy blocks that\n      // were created before the upgrade to sequential block IDs.\n      throw new OutOfV1GenerationStampsException();\n    }\n\n    return genStampV1;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {
            "oldValue": "[private]",
            "newValue": "[]"
          }
        },
        {
          "type": "Yexceptionschange",
          "commitMessage": "HDFS-4645.  Move from randomly generated block ID to sequentially generated block ID.  Contributed by Arpit Agarwal\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1500580 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "07/07/13 10:29 PM",
          "commitName": "6770de7ec4f73e16740f1723f4e35d2fef2c22c8",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "05/07/13 2:36 PM",
          "commitNameOld": "ed70fb1608e6c81314da83daddadd756394fb87e",
          "commitAuthorOld": "Konstantin Boudnik",
          "daysBetweenCommits": 2.33,
          "commitsBetweenForRepo": 3,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,13 @@\n-  private long nextGenerationStamp() throws SafeModeException {\n-    assert hasWriteLock();\n-    if (isInSafeMode()) {\n-      throw new SafeModeException(\n-          \"Cannot get next generation stamp\", safeMode);\n+  long getNextGenerationStampV1() throws IOException {\n+    long genStampV1 \u003d generationStampV1.nextValue();\n+\n+    if (genStampV1 \u003e\u003d generationStampV1Limit) {\n+      // We ran out of generation stamps for legacy blocks. In practice, it\n+      // is extremely unlikely as we reserved 1T v1 generation stamps. The\n+      // result is that we can no longer append to the legacy blocks that\n+      // were created before the upgrade to sequential block IDs.\n+      throw new OutOfV1GenerationStampsException();\n     }\n-    final long gs \u003d generationStamp.nextValue();\n-    getEditLog().logGenerationStamp(gs);\n-    // NB: callers sync the log\n-    return gs;\n+\n+    return genStampV1;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  long getNextGenerationStampV1() throws IOException {\n    long genStampV1 \u003d generationStampV1.nextValue();\n\n    if (genStampV1 \u003e\u003d generationStampV1Limit) {\n      // We ran out of generation stamps for legacy blocks. In practice, it\n      // is extremely unlikely as we reserved 1T v1 generation stamps. The\n      // result is that we can no longer append to the legacy blocks that\n      // were created before the upgrade to sequential block IDs.\n      throw new OutOfV1GenerationStampsException();\n    }\n\n    return genStampV1;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {
            "oldValue": "[SafeModeException]",
            "newValue": "[IOException]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-4645.  Move from randomly generated block ID to sequentially generated block ID.  Contributed by Arpit Agarwal\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1500580 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "07/07/13 10:29 PM",
          "commitName": "6770de7ec4f73e16740f1723f4e35d2fef2c22c8",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "05/07/13 2:36 PM",
          "commitNameOld": "ed70fb1608e6c81314da83daddadd756394fb87e",
          "commitAuthorOld": "Konstantin Boudnik",
          "daysBetweenCommits": 2.33,
          "commitsBetweenForRepo": 3,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,13 @@\n-  private long nextGenerationStamp() throws SafeModeException {\n-    assert hasWriteLock();\n-    if (isInSafeMode()) {\n-      throw new SafeModeException(\n-          \"Cannot get next generation stamp\", safeMode);\n+  long getNextGenerationStampV1() throws IOException {\n+    long genStampV1 \u003d generationStampV1.nextValue();\n+\n+    if (genStampV1 \u003e\u003d generationStampV1Limit) {\n+      // We ran out of generation stamps for legacy blocks. In practice, it\n+      // is extremely unlikely as we reserved 1T v1 generation stamps. The\n+      // result is that we can no longer append to the legacy blocks that\n+      // were created before the upgrade to sequential block IDs.\n+      throw new OutOfV1GenerationStampsException();\n     }\n-    final long gs \u003d generationStamp.nextValue();\n-    getEditLog().logGenerationStamp(gs);\n-    // NB: callers sync the log\n-    return gs;\n+\n+    return genStampV1;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  long getNextGenerationStampV1() throws IOException {\n    long genStampV1 \u003d generationStampV1.nextValue();\n\n    if (genStampV1 \u003e\u003d generationStampV1Limit) {\n      // We ran out of generation stamps for legacy blocks. In practice, it\n      // is extremely unlikely as we reserved 1T v1 generation stamps. The\n      // result is that we can no longer append to the legacy blocks that\n      // were created before the upgrade to sequential block IDs.\n      throw new OutOfV1GenerationStampsException();\n    }\n\n    return genStampV1;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {}
        }
      ]
    },
    "36c5fe9961a905385282d1a05ced08c83684dd02": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4346. Add SequentialNumber as a base class for INodeId and GenerationStamp.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1428167 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/01/13 9:12 PM",
      "commitName": "36c5fe9961a905385282d1a05ced08c83684dd02",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "28/12/12 12:26 AM",
      "commitNameOld": "0fa9c7a825f444d50c89b986bacea7a547e4ab8b",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 5.87,
      "commitsBetweenForRepo": 9,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,11 +1,11 @@\n   private long nextGenerationStamp() throws SafeModeException {\n     assert hasWriteLock();\n     if (isInSafeMode()) {\n       throw new SafeModeException(\n           \"Cannot get next generation stamp\", safeMode);\n     }\n-    long gs \u003d generationStamp.nextStamp();\n+    final long gs \u003d generationStamp.nextValue();\n     getEditLog().logGenerationStamp(gs);\n     // NB: callers sync the log\n     return gs;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private long nextGenerationStamp() throws SafeModeException {\n    assert hasWriteLock();\n    if (isInSafeMode()) {\n      throw new SafeModeException(\n          \"Cannot get next generation stamp\", safeMode);\n    }\n    final long gs \u003d generationStamp.nextValue();\n    getEditLog().logGenerationStamp(gs);\n    // NB: callers sync the log\n    return gs;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private long nextGenerationStamp() throws SafeModeException {\n    assert hasWriteLock();\n    if (isInSafeMode()) {\n      throw new SafeModeException(\n          \"Cannot get next generation stamp\", safeMode);\n    }\n    long gs \u003d generationStamp.nextStamp();\n    getEditLog().logGenerationStamp(gs);\n    // NB: callers sync the log\n    return gs;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private long nextGenerationStamp() throws SafeModeException {\n    assert hasWriteLock();\n    if (isInSafeMode()) {\n      throw new SafeModeException(\n          \"Cannot get next generation stamp\", safeMode);\n    }\n    long gs \u003d generationStamp.nextStamp();\n    getEditLog().logGenerationStamp(gs);\n    // NB: callers sync the log\n    return gs;\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,11 @@\n+  private long nextGenerationStamp() throws SafeModeException {\n+    assert hasWriteLock();\n+    if (isInSafeMode()) {\n+      throw new SafeModeException(\n+          \"Cannot get next generation stamp\", safeMode);\n+    }\n+    long gs \u003d generationStamp.nextStamp();\n+    getEditLog().logGenerationStamp(gs);\n+    // NB: callers sync the log\n+    return gs;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private long nextGenerationStamp() throws SafeModeException {\n    assert hasWriteLock();\n    if (isInSafeMode()) {\n      throw new SafeModeException(\n          \"Cannot get next generation stamp\", safeMode);\n    }\n    long gs \u003d generationStamp.nextStamp();\n    getEditLog().logGenerationStamp(gs);\n    // NB: callers sync the log\n    return gs;\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java"
    }
  }
}