{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "StoragePolicySatisfier.java",
  "functionName": "computeBlockMovingInfos",
  "functionId": "computeBlockMovingInfos___blockMovingInfos-List__BlockMovingInfo____blockInfo-LocatedBlock__expectedStorageTypes-List__StorageType____existing-List__StorageType____storages-DatanodeInfo[]__liveDns-DatanodeMap__ecPolicy-ErasureCodingPolicy",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/StoragePolicySatisfier.java",
  "functionStartLine": 510,
  "functionEndLine": 567,
  "numCommitsSeen": 77,
  "timeTaken": 8573,
  "changeHistory": [
    "2acc50b826fa8b00f2b09d9546c4b3215b89d46d",
    "75ccc1396b677777cdc0d4992a4af3911f9f88c2",
    "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52",
    "05d4daf6ba3e5bd40f46e8003ee12fc7c613453d",
    "78420719eb1f138c6f10558befb7bc8ebcc28a54",
    "6fe6c549e8226b4893f502186f52452dcd9408a2",
    "df2b551e79c9e5d8bdd981c48be52bae5f0d9a82",
    "b7bed9f00a25bcad6f9c3543f5a1fb0a1f23b0e9"
  ],
  "changeHistoryShort": {
    "2acc50b826fa8b00f2b09d9546c4b3215b89d46d": "Ybodychange",
    "75ccc1396b677777cdc0d4992a4af3911f9f88c2": "Ymultichange(Yparameterchange,Ybodychange)",
    "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52": "Ybodychange",
    "05d4daf6ba3e5bd40f46e8003ee12fc7c613453d": "Ymultichange(Yparameterchange,Ybodychange)",
    "78420719eb1f138c6f10558befb7bc8ebcc28a54": "Yfilerename",
    "6fe6c549e8226b4893f502186f52452dcd9408a2": "Ymultichange(Yparameterchange,Ybodychange)",
    "df2b551e79c9e5d8bdd981c48be52bae5f0d9a82": "Ybodychange",
    "b7bed9f00a25bcad6f9c3543f5a1fb0a1f23b0e9": "Yintroduced"
  },
  "changeHistoryDetails": {
    "2acc50b826fa8b00f2b09d9546c4b3215b89d46d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13165: [SPS]: Collects successfully moved block details via IBR. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "2acc50b826fa8b00f2b09d9546c4b3215b89d46d",
      "commitAuthor": "Rakesh Radhakrishnan",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "75ccc1396b677777cdc0d4992a4af3911f9f88c2",
      "commitAuthorOld": "Surendra Singh Lilhore",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,53 +1,58 @@\n   private boolean computeBlockMovingInfos(\n       List\u003cBlockMovingInfo\u003e blockMovingInfos, LocatedBlock blockInfo,\n       List\u003cStorageType\u003e expectedStorageTypes, List\u003cStorageType\u003e existing,\n       DatanodeInfo[] storages, DatanodeMap liveDns,\n       ErasureCodingPolicy ecPolicy) {\n     boolean foundMatchingTargetNodesForBlock \u003d true;\n     if (!removeOverlapBetweenStorageTypes(expectedStorageTypes,\n         existing, true)) {\n       List\u003cStorageTypeNodePair\u003e sourceWithStorageMap \u003d\n           new ArrayList\u003cStorageTypeNodePair\u003e();\n       List\u003cDatanodeInfo\u003e existingBlockStorages \u003d new ArrayList\u003cDatanodeInfo\u003e(\n           Arrays.asList(storages));\n+\n+      // Add existing storages into exclude nodes to avoid choosing this as\n+      // remote target later.\n+      List\u003cDatanodeInfo\u003e excludeNodes \u003d new ArrayList\u003c\u003e(existingBlockStorages);\n+\n       // if expected type exists in source node already, local movement would be\n       // possible, so lets find such sources first.\n       Iterator\u003cDatanodeInfo\u003e iterator \u003d existingBlockStorages.iterator();\n       while (iterator.hasNext()) {\n         DatanodeInfoWithStorage dnInfo \u003d (DatanodeInfoWithStorage) iterator\n             .next();\n         if (checkSourceAndTargetTypeExists(dnInfo, existing,\n             expectedStorageTypes, liveDns)) {\n           sourceWithStorageMap\n               .add(new StorageTypeNodePair(dnInfo.getStorageType(), dnInfo));\n           iterator.remove();\n           existing.remove(dnInfo.getStorageType());\n         }\n       }\n \n       // Let\u0027s find sources for existing types left.\n       for (StorageType existingType : existing) {\n         iterator \u003d existingBlockStorages.iterator();\n         while (iterator.hasNext()) {\n           DatanodeInfoWithStorage dnStorageInfo \u003d\n               (DatanodeInfoWithStorage) iterator.next();\n           StorageType storageType \u003d dnStorageInfo.getStorageType();\n           if (storageType \u003d\u003d existingType) {\n             iterator.remove();\n             sourceWithStorageMap.add(new StorageTypeNodePair(storageType,\n                 dnStorageInfo));\n             break;\n           }\n         }\n       }\n \n       EnumMap\u003cStorageType, List\u003cDatanodeWithStorage.StorageDetails\u003e\u003e targetDns \u003d\n           findTargetsForExpectedStorageTypes(expectedStorageTypes, liveDns);\n \n       foundMatchingTargetNodesForBlock |\u003d findSourceAndTargetToMove(\n           blockMovingInfos, blockInfo, sourceWithStorageMap,\n           expectedStorageTypes, targetDns,\n-          ecPolicy);\n+          ecPolicy, excludeNodes);\n     }\n     return foundMatchingTargetNodesForBlock;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean computeBlockMovingInfos(\n      List\u003cBlockMovingInfo\u003e blockMovingInfos, LocatedBlock blockInfo,\n      List\u003cStorageType\u003e expectedStorageTypes, List\u003cStorageType\u003e existing,\n      DatanodeInfo[] storages, DatanodeMap liveDns,\n      ErasureCodingPolicy ecPolicy) {\n    boolean foundMatchingTargetNodesForBlock \u003d true;\n    if (!removeOverlapBetweenStorageTypes(expectedStorageTypes,\n        existing, true)) {\n      List\u003cStorageTypeNodePair\u003e sourceWithStorageMap \u003d\n          new ArrayList\u003cStorageTypeNodePair\u003e();\n      List\u003cDatanodeInfo\u003e existingBlockStorages \u003d new ArrayList\u003cDatanodeInfo\u003e(\n          Arrays.asList(storages));\n\n      // Add existing storages into exclude nodes to avoid choosing this as\n      // remote target later.\n      List\u003cDatanodeInfo\u003e excludeNodes \u003d new ArrayList\u003c\u003e(existingBlockStorages);\n\n      // if expected type exists in source node already, local movement would be\n      // possible, so lets find such sources first.\n      Iterator\u003cDatanodeInfo\u003e iterator \u003d existingBlockStorages.iterator();\n      while (iterator.hasNext()) {\n        DatanodeInfoWithStorage dnInfo \u003d (DatanodeInfoWithStorage) iterator\n            .next();\n        if (checkSourceAndTargetTypeExists(dnInfo, existing,\n            expectedStorageTypes, liveDns)) {\n          sourceWithStorageMap\n              .add(new StorageTypeNodePair(dnInfo.getStorageType(), dnInfo));\n          iterator.remove();\n          existing.remove(dnInfo.getStorageType());\n        }\n      }\n\n      // Let\u0027s find sources for existing types left.\n      for (StorageType existingType : existing) {\n        iterator \u003d existingBlockStorages.iterator();\n        while (iterator.hasNext()) {\n          DatanodeInfoWithStorage dnStorageInfo \u003d\n              (DatanodeInfoWithStorage) iterator.next();\n          StorageType storageType \u003d dnStorageInfo.getStorageType();\n          if (storageType \u003d\u003d existingType) {\n            iterator.remove();\n            sourceWithStorageMap.add(new StorageTypeNodePair(storageType,\n                dnStorageInfo));\n            break;\n          }\n        }\n      }\n\n      EnumMap\u003cStorageType, List\u003cDatanodeWithStorage.StorageDetails\u003e\u003e targetDns \u003d\n          findTargetsForExpectedStorageTypes(expectedStorageTypes, liveDns);\n\n      foundMatchingTargetNodesForBlock |\u003d findSourceAndTargetToMove(\n          blockMovingInfos, blockInfo, sourceWithStorageMap,\n          expectedStorageTypes, targetDns,\n          ecPolicy, excludeNodes);\n    }\n    return foundMatchingTargetNodesForBlock;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/StoragePolicySatisfier.java",
      "extendedDetails": {}
    },
    "75ccc1396b677777cdc0d4992a4af3911f9f88c2": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-13166: [SPS]: Implement caching mechanism to keep LIVE datanodes to minimize costly getLiveDatanodeStorageReport() calls. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "75ccc1396b677777cdc0d4992a4af3911f9f88c2",
      "commitAuthor": "Surendra Singh Lilhore",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-13166: [SPS]: Implement caching mechanism to keep LIVE datanodes to minimize costly getLiveDatanodeStorageReport() calls. Contributed by Rakesh R.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "75ccc1396b677777cdc0d4992a4af3911f9f88c2",
          "commitAuthor": "Surendra Singh Lilhore",
          "commitDateOld": "12/08/18 3:06 AM",
          "commitNameOld": "8467ec24fb74f30371d5a13e893fc56309ee9372",
          "commitAuthorOld": "Rakesh Radhakrishnan",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,53 +1,53 @@\n   private boolean computeBlockMovingInfos(\n       List\u003cBlockMovingInfo\u003e blockMovingInfos, LocatedBlock blockInfo,\n       List\u003cStorageType\u003e expectedStorageTypes, List\u003cStorageType\u003e existing,\n-      DatanodeInfo[] storages, DatanodeStorageReport[] liveDns,\n+      DatanodeInfo[] storages, DatanodeMap liveDns,\n       ErasureCodingPolicy ecPolicy) {\n     boolean foundMatchingTargetNodesForBlock \u003d true;\n     if (!removeOverlapBetweenStorageTypes(expectedStorageTypes,\n         existing, true)) {\n       List\u003cStorageTypeNodePair\u003e sourceWithStorageMap \u003d\n           new ArrayList\u003cStorageTypeNodePair\u003e();\n       List\u003cDatanodeInfo\u003e existingBlockStorages \u003d new ArrayList\u003cDatanodeInfo\u003e(\n           Arrays.asList(storages));\n       // if expected type exists in source node already, local movement would be\n       // possible, so lets find such sources first.\n       Iterator\u003cDatanodeInfo\u003e iterator \u003d existingBlockStorages.iterator();\n       while (iterator.hasNext()) {\n         DatanodeInfoWithStorage dnInfo \u003d (DatanodeInfoWithStorage) iterator\n             .next();\n         if (checkSourceAndTargetTypeExists(dnInfo, existing,\n             expectedStorageTypes, liveDns)) {\n           sourceWithStorageMap\n               .add(new StorageTypeNodePair(dnInfo.getStorageType(), dnInfo));\n           iterator.remove();\n           existing.remove(dnInfo.getStorageType());\n         }\n       }\n \n       // Let\u0027s find sources for existing types left.\n       for (StorageType existingType : existing) {\n         iterator \u003d existingBlockStorages.iterator();\n         while (iterator.hasNext()) {\n           DatanodeInfoWithStorage dnStorageInfo \u003d\n               (DatanodeInfoWithStorage) iterator.next();\n           StorageType storageType \u003d dnStorageInfo.getStorageType();\n           if (storageType \u003d\u003d existingType) {\n             iterator.remove();\n             sourceWithStorageMap.add(new StorageTypeNodePair(storageType,\n                 dnStorageInfo));\n             break;\n           }\n         }\n       }\n \n-      StorageTypeNodeMap locsForExpectedStorageTypes \u003d\n+      EnumMap\u003cStorageType, List\u003cDatanodeWithStorage.StorageDetails\u003e\u003e targetDns \u003d\n           findTargetsForExpectedStorageTypes(expectedStorageTypes, liveDns);\n \n       foundMatchingTargetNodesForBlock |\u003d findSourceAndTargetToMove(\n           blockMovingInfos, blockInfo, sourceWithStorageMap,\n-          expectedStorageTypes, locsForExpectedStorageTypes,\n+          expectedStorageTypes, targetDns,\n           ecPolicy);\n     }\n     return foundMatchingTargetNodesForBlock;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private boolean computeBlockMovingInfos(\n      List\u003cBlockMovingInfo\u003e blockMovingInfos, LocatedBlock blockInfo,\n      List\u003cStorageType\u003e expectedStorageTypes, List\u003cStorageType\u003e existing,\n      DatanodeInfo[] storages, DatanodeMap liveDns,\n      ErasureCodingPolicy ecPolicy) {\n    boolean foundMatchingTargetNodesForBlock \u003d true;\n    if (!removeOverlapBetweenStorageTypes(expectedStorageTypes,\n        existing, true)) {\n      List\u003cStorageTypeNodePair\u003e sourceWithStorageMap \u003d\n          new ArrayList\u003cStorageTypeNodePair\u003e();\n      List\u003cDatanodeInfo\u003e existingBlockStorages \u003d new ArrayList\u003cDatanodeInfo\u003e(\n          Arrays.asList(storages));\n      // if expected type exists in source node already, local movement would be\n      // possible, so lets find such sources first.\n      Iterator\u003cDatanodeInfo\u003e iterator \u003d existingBlockStorages.iterator();\n      while (iterator.hasNext()) {\n        DatanodeInfoWithStorage dnInfo \u003d (DatanodeInfoWithStorage) iterator\n            .next();\n        if (checkSourceAndTargetTypeExists(dnInfo, existing,\n            expectedStorageTypes, liveDns)) {\n          sourceWithStorageMap\n              .add(new StorageTypeNodePair(dnInfo.getStorageType(), dnInfo));\n          iterator.remove();\n          existing.remove(dnInfo.getStorageType());\n        }\n      }\n\n      // Let\u0027s find sources for existing types left.\n      for (StorageType existingType : existing) {\n        iterator \u003d existingBlockStorages.iterator();\n        while (iterator.hasNext()) {\n          DatanodeInfoWithStorage dnStorageInfo \u003d\n              (DatanodeInfoWithStorage) iterator.next();\n          StorageType storageType \u003d dnStorageInfo.getStorageType();\n          if (storageType \u003d\u003d existingType) {\n            iterator.remove();\n            sourceWithStorageMap.add(new StorageTypeNodePair(storageType,\n                dnStorageInfo));\n            break;\n          }\n        }\n      }\n\n      EnumMap\u003cStorageType, List\u003cDatanodeWithStorage.StorageDetails\u003e\u003e targetDns \u003d\n          findTargetsForExpectedStorageTypes(expectedStorageTypes, liveDns);\n\n      foundMatchingTargetNodesForBlock |\u003d findSourceAndTargetToMove(\n          blockMovingInfos, blockInfo, sourceWithStorageMap,\n          expectedStorageTypes, targetDns,\n          ecPolicy);\n    }\n    return foundMatchingTargetNodesForBlock;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/StoragePolicySatisfier.java",
          "extendedDetails": {
            "oldValue": "[blockMovingInfos-List\u003cBlockMovingInfo\u003e, blockInfo-LocatedBlock, expectedStorageTypes-List\u003cStorageType\u003e, existing-List\u003cStorageType\u003e, storages-DatanodeInfo[], liveDns-DatanodeStorageReport[], ecPolicy-ErasureCodingPolicy]",
            "newValue": "[blockMovingInfos-List\u003cBlockMovingInfo\u003e, blockInfo-LocatedBlock, expectedStorageTypes-List\u003cStorageType\u003e, existing-List\u003cStorageType\u003e, storages-DatanodeInfo[], liveDns-DatanodeMap, ecPolicy-ErasureCodingPolicy]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-13166: [SPS]: Implement caching mechanism to keep LIVE datanodes to minimize costly getLiveDatanodeStorageReport() calls. Contributed by Rakesh R.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "75ccc1396b677777cdc0d4992a4af3911f9f88c2",
          "commitAuthor": "Surendra Singh Lilhore",
          "commitDateOld": "12/08/18 3:06 AM",
          "commitNameOld": "8467ec24fb74f30371d5a13e893fc56309ee9372",
          "commitAuthorOld": "Rakesh Radhakrishnan",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,53 +1,53 @@\n   private boolean computeBlockMovingInfos(\n       List\u003cBlockMovingInfo\u003e blockMovingInfos, LocatedBlock blockInfo,\n       List\u003cStorageType\u003e expectedStorageTypes, List\u003cStorageType\u003e existing,\n-      DatanodeInfo[] storages, DatanodeStorageReport[] liveDns,\n+      DatanodeInfo[] storages, DatanodeMap liveDns,\n       ErasureCodingPolicy ecPolicy) {\n     boolean foundMatchingTargetNodesForBlock \u003d true;\n     if (!removeOverlapBetweenStorageTypes(expectedStorageTypes,\n         existing, true)) {\n       List\u003cStorageTypeNodePair\u003e sourceWithStorageMap \u003d\n           new ArrayList\u003cStorageTypeNodePair\u003e();\n       List\u003cDatanodeInfo\u003e existingBlockStorages \u003d new ArrayList\u003cDatanodeInfo\u003e(\n           Arrays.asList(storages));\n       // if expected type exists in source node already, local movement would be\n       // possible, so lets find such sources first.\n       Iterator\u003cDatanodeInfo\u003e iterator \u003d existingBlockStorages.iterator();\n       while (iterator.hasNext()) {\n         DatanodeInfoWithStorage dnInfo \u003d (DatanodeInfoWithStorage) iterator\n             .next();\n         if (checkSourceAndTargetTypeExists(dnInfo, existing,\n             expectedStorageTypes, liveDns)) {\n           sourceWithStorageMap\n               .add(new StorageTypeNodePair(dnInfo.getStorageType(), dnInfo));\n           iterator.remove();\n           existing.remove(dnInfo.getStorageType());\n         }\n       }\n \n       // Let\u0027s find sources for existing types left.\n       for (StorageType existingType : existing) {\n         iterator \u003d existingBlockStorages.iterator();\n         while (iterator.hasNext()) {\n           DatanodeInfoWithStorage dnStorageInfo \u003d\n               (DatanodeInfoWithStorage) iterator.next();\n           StorageType storageType \u003d dnStorageInfo.getStorageType();\n           if (storageType \u003d\u003d existingType) {\n             iterator.remove();\n             sourceWithStorageMap.add(new StorageTypeNodePair(storageType,\n                 dnStorageInfo));\n             break;\n           }\n         }\n       }\n \n-      StorageTypeNodeMap locsForExpectedStorageTypes \u003d\n+      EnumMap\u003cStorageType, List\u003cDatanodeWithStorage.StorageDetails\u003e\u003e targetDns \u003d\n           findTargetsForExpectedStorageTypes(expectedStorageTypes, liveDns);\n \n       foundMatchingTargetNodesForBlock |\u003d findSourceAndTargetToMove(\n           blockMovingInfos, blockInfo, sourceWithStorageMap,\n-          expectedStorageTypes, locsForExpectedStorageTypes,\n+          expectedStorageTypes, targetDns,\n           ecPolicy);\n     }\n     return foundMatchingTargetNodesForBlock;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private boolean computeBlockMovingInfos(\n      List\u003cBlockMovingInfo\u003e blockMovingInfos, LocatedBlock blockInfo,\n      List\u003cStorageType\u003e expectedStorageTypes, List\u003cStorageType\u003e existing,\n      DatanodeInfo[] storages, DatanodeMap liveDns,\n      ErasureCodingPolicy ecPolicy) {\n    boolean foundMatchingTargetNodesForBlock \u003d true;\n    if (!removeOverlapBetweenStorageTypes(expectedStorageTypes,\n        existing, true)) {\n      List\u003cStorageTypeNodePair\u003e sourceWithStorageMap \u003d\n          new ArrayList\u003cStorageTypeNodePair\u003e();\n      List\u003cDatanodeInfo\u003e existingBlockStorages \u003d new ArrayList\u003cDatanodeInfo\u003e(\n          Arrays.asList(storages));\n      // if expected type exists in source node already, local movement would be\n      // possible, so lets find such sources first.\n      Iterator\u003cDatanodeInfo\u003e iterator \u003d existingBlockStorages.iterator();\n      while (iterator.hasNext()) {\n        DatanodeInfoWithStorage dnInfo \u003d (DatanodeInfoWithStorage) iterator\n            .next();\n        if (checkSourceAndTargetTypeExists(dnInfo, existing,\n            expectedStorageTypes, liveDns)) {\n          sourceWithStorageMap\n              .add(new StorageTypeNodePair(dnInfo.getStorageType(), dnInfo));\n          iterator.remove();\n          existing.remove(dnInfo.getStorageType());\n        }\n      }\n\n      // Let\u0027s find sources for existing types left.\n      for (StorageType existingType : existing) {\n        iterator \u003d existingBlockStorages.iterator();\n        while (iterator.hasNext()) {\n          DatanodeInfoWithStorage dnStorageInfo \u003d\n              (DatanodeInfoWithStorage) iterator.next();\n          StorageType storageType \u003d dnStorageInfo.getStorageType();\n          if (storageType \u003d\u003d existingType) {\n            iterator.remove();\n            sourceWithStorageMap.add(new StorageTypeNodePair(storageType,\n                dnStorageInfo));\n            break;\n          }\n        }\n      }\n\n      EnumMap\u003cStorageType, List\u003cDatanodeWithStorage.StorageDetails\u003e\u003e targetDns \u003d\n          findTargetsForExpectedStorageTypes(expectedStorageTypes, liveDns);\n\n      foundMatchingTargetNodesForBlock |\u003d findSourceAndTargetToMove(\n          blockMovingInfos, blockInfo, sourceWithStorageMap,\n          expectedStorageTypes, targetDns,\n          ecPolicy);\n    }\n    return foundMatchingTargetNodesForBlock;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/StoragePolicySatisfier.java",
          "extendedDetails": {}
        }
      ]
    },
    "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13097: [SPS]: Fix the branch review comments(Part1). Contributed by Surendra Singh.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "d3de4fb2a084cbadab8ef91f11aa7732d3b0f308",
      "commitAuthorOld": "Surendra Singh Lilhore",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,53 +1,53 @@\n   private boolean computeBlockMovingInfos(\n       List\u003cBlockMovingInfo\u003e blockMovingInfos, LocatedBlock blockInfo,\n       List\u003cStorageType\u003e expectedStorageTypes, List\u003cStorageType\u003e existing,\n       DatanodeInfo[] storages, DatanodeStorageReport[] liveDns,\n       ErasureCodingPolicy ecPolicy) {\n     boolean foundMatchingTargetNodesForBlock \u003d true;\n-    if (!DFSUtil.removeOverlapBetweenStorageTypes(expectedStorageTypes,\n+    if (!removeOverlapBetweenStorageTypes(expectedStorageTypes,\n         existing, true)) {\n       List\u003cStorageTypeNodePair\u003e sourceWithStorageMap \u003d\n           new ArrayList\u003cStorageTypeNodePair\u003e();\n       List\u003cDatanodeInfo\u003e existingBlockStorages \u003d new ArrayList\u003cDatanodeInfo\u003e(\n           Arrays.asList(storages));\n       // if expected type exists in source node already, local movement would be\n       // possible, so lets find such sources first.\n       Iterator\u003cDatanodeInfo\u003e iterator \u003d existingBlockStorages.iterator();\n       while (iterator.hasNext()) {\n         DatanodeInfoWithStorage dnInfo \u003d (DatanodeInfoWithStorage) iterator\n             .next();\n         if (checkSourceAndTargetTypeExists(dnInfo, existing,\n             expectedStorageTypes, liveDns)) {\n           sourceWithStorageMap\n               .add(new StorageTypeNodePair(dnInfo.getStorageType(), dnInfo));\n           iterator.remove();\n           existing.remove(dnInfo.getStorageType());\n         }\n       }\n \n       // Let\u0027s find sources for existing types left.\n       for (StorageType existingType : existing) {\n         iterator \u003d existingBlockStorages.iterator();\n         while (iterator.hasNext()) {\n           DatanodeInfoWithStorage dnStorageInfo \u003d\n               (DatanodeInfoWithStorage) iterator.next();\n           StorageType storageType \u003d dnStorageInfo.getStorageType();\n           if (storageType \u003d\u003d existingType) {\n             iterator.remove();\n             sourceWithStorageMap.add(new StorageTypeNodePair(storageType,\n                 dnStorageInfo));\n             break;\n           }\n         }\n       }\n \n       StorageTypeNodeMap locsForExpectedStorageTypes \u003d\n           findTargetsForExpectedStorageTypes(expectedStorageTypes, liveDns);\n \n       foundMatchingTargetNodesForBlock |\u003d findSourceAndTargetToMove(\n           blockMovingInfos, blockInfo, sourceWithStorageMap,\n           expectedStorageTypes, locsForExpectedStorageTypes,\n           ecPolicy);\n     }\n     return foundMatchingTargetNodesForBlock;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean computeBlockMovingInfos(\n      List\u003cBlockMovingInfo\u003e blockMovingInfos, LocatedBlock blockInfo,\n      List\u003cStorageType\u003e expectedStorageTypes, List\u003cStorageType\u003e existing,\n      DatanodeInfo[] storages, DatanodeStorageReport[] liveDns,\n      ErasureCodingPolicy ecPolicy) {\n    boolean foundMatchingTargetNodesForBlock \u003d true;\n    if (!removeOverlapBetweenStorageTypes(expectedStorageTypes,\n        existing, true)) {\n      List\u003cStorageTypeNodePair\u003e sourceWithStorageMap \u003d\n          new ArrayList\u003cStorageTypeNodePair\u003e();\n      List\u003cDatanodeInfo\u003e existingBlockStorages \u003d new ArrayList\u003cDatanodeInfo\u003e(\n          Arrays.asList(storages));\n      // if expected type exists in source node already, local movement would be\n      // possible, so lets find such sources first.\n      Iterator\u003cDatanodeInfo\u003e iterator \u003d existingBlockStorages.iterator();\n      while (iterator.hasNext()) {\n        DatanodeInfoWithStorage dnInfo \u003d (DatanodeInfoWithStorage) iterator\n            .next();\n        if (checkSourceAndTargetTypeExists(dnInfo, existing,\n            expectedStorageTypes, liveDns)) {\n          sourceWithStorageMap\n              .add(new StorageTypeNodePair(dnInfo.getStorageType(), dnInfo));\n          iterator.remove();\n          existing.remove(dnInfo.getStorageType());\n        }\n      }\n\n      // Let\u0027s find sources for existing types left.\n      for (StorageType existingType : existing) {\n        iterator \u003d existingBlockStorages.iterator();\n        while (iterator.hasNext()) {\n          DatanodeInfoWithStorage dnStorageInfo \u003d\n              (DatanodeInfoWithStorage) iterator.next();\n          StorageType storageType \u003d dnStorageInfo.getStorageType();\n          if (storageType \u003d\u003d existingType) {\n            iterator.remove();\n            sourceWithStorageMap.add(new StorageTypeNodePair(storageType,\n                dnStorageInfo));\n            break;\n          }\n        }\n      }\n\n      StorageTypeNodeMap locsForExpectedStorageTypes \u003d\n          findTargetsForExpectedStorageTypes(expectedStorageTypes, liveDns);\n\n      foundMatchingTargetNodesForBlock |\u003d findSourceAndTargetToMove(\n          blockMovingInfos, blockInfo, sourceWithStorageMap,\n          expectedStorageTypes, locsForExpectedStorageTypes,\n          ecPolicy);\n    }\n    return foundMatchingTargetNodesForBlock;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/StoragePolicySatisfier.java",
      "extendedDetails": {}
    },
    "05d4daf6ba3e5bd40f46e8003ee12fc7c613453d": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-12982 : [SPS]: Reduce the locking and cleanup the Namesystem access. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "05d4daf6ba3e5bd40f46e8003ee12fc7c613453d",
      "commitAuthor": "Surendra Singh Lilhore",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-12982 : [SPS]: Reduce the locking and cleanup the Namesystem access. Contributed by Rakesh R.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "05d4daf6ba3e5bd40f46e8003ee12fc7c613453d",
          "commitAuthor": "Surendra Singh Lilhore",
          "commitDateOld": "12/08/18 3:06 AM",
          "commitNameOld": "78420719eb1f138c6f10558befb7bc8ebcc28a54",
          "commitAuthorOld": "Uma Maheswara Rao G",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,51 +1,53 @@\n   private boolean computeBlockMovingInfos(\n-      List\u003cBlockMovingInfo\u003e blockMovingInfos, BlockInfo blockInfo,\n+      List\u003cBlockMovingInfo\u003e blockMovingInfos, LocatedBlock blockInfo,\n       List\u003cStorageType\u003e expectedStorageTypes, List\u003cStorageType\u003e existing,\n-      DatanodeStorageInfo[] storages) {\n+      DatanodeInfo[] storages, DatanodeStorageReport[] liveDns,\n+      ErasureCodingPolicy ecPolicy) {\n     boolean foundMatchingTargetNodesForBlock \u003d true;\n     if (!DFSUtil.removeOverlapBetweenStorageTypes(expectedStorageTypes,\n         existing, true)) {\n       List\u003cStorageTypeNodePair\u003e sourceWithStorageMap \u003d\n           new ArrayList\u003cStorageTypeNodePair\u003e();\n-      List\u003cDatanodeStorageInfo\u003e existingBlockStorages \u003d\n-          new ArrayList\u003cDatanodeStorageInfo\u003e(Arrays.asList(storages));\n+      List\u003cDatanodeInfo\u003e existingBlockStorages \u003d new ArrayList\u003cDatanodeInfo\u003e(\n+          Arrays.asList(storages));\n       // if expected type exists in source node already, local movement would be\n       // possible, so lets find such sources first.\n-      Iterator\u003cDatanodeStorageInfo\u003e iterator \u003d existingBlockStorages.iterator();\n+      Iterator\u003cDatanodeInfo\u003e iterator \u003d existingBlockStorages.iterator();\n       while (iterator.hasNext()) {\n-        DatanodeStorageInfo datanodeStorageInfo \u003d iterator.next();\n-        if (checkSourceAndTargetTypeExists(\n-            datanodeStorageInfo.getDatanodeDescriptor(), existing,\n-            expectedStorageTypes)) {\n+        DatanodeInfoWithStorage dnInfo \u003d (DatanodeInfoWithStorage) iterator\n+            .next();\n+        if (checkSourceAndTargetTypeExists(dnInfo, existing,\n+            expectedStorageTypes, liveDns)) {\n           sourceWithStorageMap\n-              .add(new StorageTypeNodePair(datanodeStorageInfo.getStorageType(),\n-                  datanodeStorageInfo.getDatanodeDescriptor()));\n+              .add(new StorageTypeNodePair(dnInfo.getStorageType(), dnInfo));\n           iterator.remove();\n-          existing.remove(datanodeStorageInfo.getStorageType());\n+          existing.remove(dnInfo.getStorageType());\n         }\n       }\n \n       // Let\u0027s find sources for existing types left.\n       for (StorageType existingType : existing) {\n         iterator \u003d existingBlockStorages.iterator();\n         while (iterator.hasNext()) {\n-          DatanodeStorageInfo datanodeStorageInfo \u003d iterator.next();\n-          StorageType storageType \u003d datanodeStorageInfo.getStorageType();\n+          DatanodeInfoWithStorage dnStorageInfo \u003d\n+              (DatanodeInfoWithStorage) iterator.next();\n+          StorageType storageType \u003d dnStorageInfo.getStorageType();\n           if (storageType \u003d\u003d existingType) {\n             iterator.remove();\n             sourceWithStorageMap.add(new StorageTypeNodePair(storageType,\n-                datanodeStorageInfo.getDatanodeDescriptor()));\n+                dnStorageInfo));\n             break;\n           }\n         }\n       }\n \n       StorageTypeNodeMap locsForExpectedStorageTypes \u003d\n-          findTargetsForExpectedStorageTypes(expectedStorageTypes);\n+          findTargetsForExpectedStorageTypes(expectedStorageTypes, liveDns);\n \n       foundMatchingTargetNodesForBlock |\u003d findSourceAndTargetToMove(\n           blockMovingInfos, blockInfo, sourceWithStorageMap,\n-          expectedStorageTypes, locsForExpectedStorageTypes);\n+          expectedStorageTypes, locsForExpectedStorageTypes,\n+          ecPolicy);\n     }\n     return foundMatchingTargetNodesForBlock;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private boolean computeBlockMovingInfos(\n      List\u003cBlockMovingInfo\u003e blockMovingInfos, LocatedBlock blockInfo,\n      List\u003cStorageType\u003e expectedStorageTypes, List\u003cStorageType\u003e existing,\n      DatanodeInfo[] storages, DatanodeStorageReport[] liveDns,\n      ErasureCodingPolicy ecPolicy) {\n    boolean foundMatchingTargetNodesForBlock \u003d true;\n    if (!DFSUtil.removeOverlapBetweenStorageTypes(expectedStorageTypes,\n        existing, true)) {\n      List\u003cStorageTypeNodePair\u003e sourceWithStorageMap \u003d\n          new ArrayList\u003cStorageTypeNodePair\u003e();\n      List\u003cDatanodeInfo\u003e existingBlockStorages \u003d new ArrayList\u003cDatanodeInfo\u003e(\n          Arrays.asList(storages));\n      // if expected type exists in source node already, local movement would be\n      // possible, so lets find such sources first.\n      Iterator\u003cDatanodeInfo\u003e iterator \u003d existingBlockStorages.iterator();\n      while (iterator.hasNext()) {\n        DatanodeInfoWithStorage dnInfo \u003d (DatanodeInfoWithStorage) iterator\n            .next();\n        if (checkSourceAndTargetTypeExists(dnInfo, existing,\n            expectedStorageTypes, liveDns)) {\n          sourceWithStorageMap\n              .add(new StorageTypeNodePair(dnInfo.getStorageType(), dnInfo));\n          iterator.remove();\n          existing.remove(dnInfo.getStorageType());\n        }\n      }\n\n      // Let\u0027s find sources for existing types left.\n      for (StorageType existingType : existing) {\n        iterator \u003d existingBlockStorages.iterator();\n        while (iterator.hasNext()) {\n          DatanodeInfoWithStorage dnStorageInfo \u003d\n              (DatanodeInfoWithStorage) iterator.next();\n          StorageType storageType \u003d dnStorageInfo.getStorageType();\n          if (storageType \u003d\u003d existingType) {\n            iterator.remove();\n            sourceWithStorageMap.add(new StorageTypeNodePair(storageType,\n                dnStorageInfo));\n            break;\n          }\n        }\n      }\n\n      StorageTypeNodeMap locsForExpectedStorageTypes \u003d\n          findTargetsForExpectedStorageTypes(expectedStorageTypes, liveDns);\n\n      foundMatchingTargetNodesForBlock |\u003d findSourceAndTargetToMove(\n          blockMovingInfos, blockInfo, sourceWithStorageMap,\n          expectedStorageTypes, locsForExpectedStorageTypes,\n          ecPolicy);\n    }\n    return foundMatchingTargetNodesForBlock;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/StoragePolicySatisfier.java",
          "extendedDetails": {
            "oldValue": "[blockMovingInfos-List\u003cBlockMovingInfo\u003e, blockInfo-BlockInfo, expectedStorageTypes-List\u003cStorageType\u003e, existing-List\u003cStorageType\u003e, storages-DatanodeStorageInfo[]]",
            "newValue": "[blockMovingInfos-List\u003cBlockMovingInfo\u003e, blockInfo-LocatedBlock, expectedStorageTypes-List\u003cStorageType\u003e, existing-List\u003cStorageType\u003e, storages-DatanodeInfo[], liveDns-DatanodeStorageReport[], ecPolicy-ErasureCodingPolicy]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-12982 : [SPS]: Reduce the locking and cleanup the Namesystem access. Contributed by Rakesh R.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "05d4daf6ba3e5bd40f46e8003ee12fc7c613453d",
          "commitAuthor": "Surendra Singh Lilhore",
          "commitDateOld": "12/08/18 3:06 AM",
          "commitNameOld": "78420719eb1f138c6f10558befb7bc8ebcc28a54",
          "commitAuthorOld": "Uma Maheswara Rao G",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,51 +1,53 @@\n   private boolean computeBlockMovingInfos(\n-      List\u003cBlockMovingInfo\u003e blockMovingInfos, BlockInfo blockInfo,\n+      List\u003cBlockMovingInfo\u003e blockMovingInfos, LocatedBlock blockInfo,\n       List\u003cStorageType\u003e expectedStorageTypes, List\u003cStorageType\u003e existing,\n-      DatanodeStorageInfo[] storages) {\n+      DatanodeInfo[] storages, DatanodeStorageReport[] liveDns,\n+      ErasureCodingPolicy ecPolicy) {\n     boolean foundMatchingTargetNodesForBlock \u003d true;\n     if (!DFSUtil.removeOverlapBetweenStorageTypes(expectedStorageTypes,\n         existing, true)) {\n       List\u003cStorageTypeNodePair\u003e sourceWithStorageMap \u003d\n           new ArrayList\u003cStorageTypeNodePair\u003e();\n-      List\u003cDatanodeStorageInfo\u003e existingBlockStorages \u003d\n-          new ArrayList\u003cDatanodeStorageInfo\u003e(Arrays.asList(storages));\n+      List\u003cDatanodeInfo\u003e existingBlockStorages \u003d new ArrayList\u003cDatanodeInfo\u003e(\n+          Arrays.asList(storages));\n       // if expected type exists in source node already, local movement would be\n       // possible, so lets find such sources first.\n-      Iterator\u003cDatanodeStorageInfo\u003e iterator \u003d existingBlockStorages.iterator();\n+      Iterator\u003cDatanodeInfo\u003e iterator \u003d existingBlockStorages.iterator();\n       while (iterator.hasNext()) {\n-        DatanodeStorageInfo datanodeStorageInfo \u003d iterator.next();\n-        if (checkSourceAndTargetTypeExists(\n-            datanodeStorageInfo.getDatanodeDescriptor(), existing,\n-            expectedStorageTypes)) {\n+        DatanodeInfoWithStorage dnInfo \u003d (DatanodeInfoWithStorage) iterator\n+            .next();\n+        if (checkSourceAndTargetTypeExists(dnInfo, existing,\n+            expectedStorageTypes, liveDns)) {\n           sourceWithStorageMap\n-              .add(new StorageTypeNodePair(datanodeStorageInfo.getStorageType(),\n-                  datanodeStorageInfo.getDatanodeDescriptor()));\n+              .add(new StorageTypeNodePair(dnInfo.getStorageType(), dnInfo));\n           iterator.remove();\n-          existing.remove(datanodeStorageInfo.getStorageType());\n+          existing.remove(dnInfo.getStorageType());\n         }\n       }\n \n       // Let\u0027s find sources for existing types left.\n       for (StorageType existingType : existing) {\n         iterator \u003d existingBlockStorages.iterator();\n         while (iterator.hasNext()) {\n-          DatanodeStorageInfo datanodeStorageInfo \u003d iterator.next();\n-          StorageType storageType \u003d datanodeStorageInfo.getStorageType();\n+          DatanodeInfoWithStorage dnStorageInfo \u003d\n+              (DatanodeInfoWithStorage) iterator.next();\n+          StorageType storageType \u003d dnStorageInfo.getStorageType();\n           if (storageType \u003d\u003d existingType) {\n             iterator.remove();\n             sourceWithStorageMap.add(new StorageTypeNodePair(storageType,\n-                datanodeStorageInfo.getDatanodeDescriptor()));\n+                dnStorageInfo));\n             break;\n           }\n         }\n       }\n \n       StorageTypeNodeMap locsForExpectedStorageTypes \u003d\n-          findTargetsForExpectedStorageTypes(expectedStorageTypes);\n+          findTargetsForExpectedStorageTypes(expectedStorageTypes, liveDns);\n \n       foundMatchingTargetNodesForBlock |\u003d findSourceAndTargetToMove(\n           blockMovingInfos, blockInfo, sourceWithStorageMap,\n-          expectedStorageTypes, locsForExpectedStorageTypes);\n+          expectedStorageTypes, locsForExpectedStorageTypes,\n+          ecPolicy);\n     }\n     return foundMatchingTargetNodesForBlock;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private boolean computeBlockMovingInfos(\n      List\u003cBlockMovingInfo\u003e blockMovingInfos, LocatedBlock blockInfo,\n      List\u003cStorageType\u003e expectedStorageTypes, List\u003cStorageType\u003e existing,\n      DatanodeInfo[] storages, DatanodeStorageReport[] liveDns,\n      ErasureCodingPolicy ecPolicy) {\n    boolean foundMatchingTargetNodesForBlock \u003d true;\n    if (!DFSUtil.removeOverlapBetweenStorageTypes(expectedStorageTypes,\n        existing, true)) {\n      List\u003cStorageTypeNodePair\u003e sourceWithStorageMap \u003d\n          new ArrayList\u003cStorageTypeNodePair\u003e();\n      List\u003cDatanodeInfo\u003e existingBlockStorages \u003d new ArrayList\u003cDatanodeInfo\u003e(\n          Arrays.asList(storages));\n      // if expected type exists in source node already, local movement would be\n      // possible, so lets find such sources first.\n      Iterator\u003cDatanodeInfo\u003e iterator \u003d existingBlockStorages.iterator();\n      while (iterator.hasNext()) {\n        DatanodeInfoWithStorage dnInfo \u003d (DatanodeInfoWithStorage) iterator\n            .next();\n        if (checkSourceAndTargetTypeExists(dnInfo, existing,\n            expectedStorageTypes, liveDns)) {\n          sourceWithStorageMap\n              .add(new StorageTypeNodePair(dnInfo.getStorageType(), dnInfo));\n          iterator.remove();\n          existing.remove(dnInfo.getStorageType());\n        }\n      }\n\n      // Let\u0027s find sources for existing types left.\n      for (StorageType existingType : existing) {\n        iterator \u003d existingBlockStorages.iterator();\n        while (iterator.hasNext()) {\n          DatanodeInfoWithStorage dnStorageInfo \u003d\n              (DatanodeInfoWithStorage) iterator.next();\n          StorageType storageType \u003d dnStorageInfo.getStorageType();\n          if (storageType \u003d\u003d existingType) {\n            iterator.remove();\n            sourceWithStorageMap.add(new StorageTypeNodePair(storageType,\n                dnStorageInfo));\n            break;\n          }\n        }\n      }\n\n      StorageTypeNodeMap locsForExpectedStorageTypes \u003d\n          findTargetsForExpectedStorageTypes(expectedStorageTypes, liveDns);\n\n      foundMatchingTargetNodesForBlock |\u003d findSourceAndTargetToMove(\n          blockMovingInfos, blockInfo, sourceWithStorageMap,\n          expectedStorageTypes, locsForExpectedStorageTypes,\n          ecPolicy);\n    }\n    return foundMatchingTargetNodesForBlock;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/StoragePolicySatisfier.java",
          "extendedDetails": {}
        }
      ]
    },
    "78420719eb1f138c6f10558befb7bc8ebcc28a54": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-12955: [SPS]: Move SPS classes to a separate package. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "78420719eb1f138c6f10558befb7bc8ebcc28a54",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "c561cb316e365ef674784cd6cf0b12c0fbc271a3",
      "commitAuthorOld": "Surendra Singh Lilhore",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private boolean computeBlockMovingInfos(\n      List\u003cBlockMovingInfo\u003e blockMovingInfos, BlockInfo blockInfo,\n      List\u003cStorageType\u003e expectedStorageTypes, List\u003cStorageType\u003e existing,\n      DatanodeStorageInfo[] storages) {\n    boolean foundMatchingTargetNodesForBlock \u003d true;\n    if (!DFSUtil.removeOverlapBetweenStorageTypes(expectedStorageTypes,\n        existing, true)) {\n      List\u003cStorageTypeNodePair\u003e sourceWithStorageMap \u003d\n          new ArrayList\u003cStorageTypeNodePair\u003e();\n      List\u003cDatanodeStorageInfo\u003e existingBlockStorages \u003d\n          new ArrayList\u003cDatanodeStorageInfo\u003e(Arrays.asList(storages));\n      // if expected type exists in source node already, local movement would be\n      // possible, so lets find such sources first.\n      Iterator\u003cDatanodeStorageInfo\u003e iterator \u003d existingBlockStorages.iterator();\n      while (iterator.hasNext()) {\n        DatanodeStorageInfo datanodeStorageInfo \u003d iterator.next();\n        if (checkSourceAndTargetTypeExists(\n            datanodeStorageInfo.getDatanodeDescriptor(), existing,\n            expectedStorageTypes)) {\n          sourceWithStorageMap\n              .add(new StorageTypeNodePair(datanodeStorageInfo.getStorageType(),\n                  datanodeStorageInfo.getDatanodeDescriptor()));\n          iterator.remove();\n          existing.remove(datanodeStorageInfo.getStorageType());\n        }\n      }\n\n      // Let\u0027s find sources for existing types left.\n      for (StorageType existingType : existing) {\n        iterator \u003d existingBlockStorages.iterator();\n        while (iterator.hasNext()) {\n          DatanodeStorageInfo datanodeStorageInfo \u003d iterator.next();\n          StorageType storageType \u003d datanodeStorageInfo.getStorageType();\n          if (storageType \u003d\u003d existingType) {\n            iterator.remove();\n            sourceWithStorageMap.add(new StorageTypeNodePair(storageType,\n                datanodeStorageInfo.getDatanodeDescriptor()));\n            break;\n          }\n        }\n      }\n\n      StorageTypeNodeMap locsForExpectedStorageTypes \u003d\n          findTargetsForExpectedStorageTypes(expectedStorageTypes);\n\n      foundMatchingTargetNodesForBlock |\u003d findSourceAndTargetToMove(\n          blockMovingInfos, blockInfo, sourceWithStorageMap,\n          expectedStorageTypes, locsForExpectedStorageTypes);\n    }\n    return foundMatchingTargetNodesForBlock;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/StoragePolicySatisfier.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/StoragePolicySatisfier.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/StoragePolicySatisfier.java"
      }
    },
    "6fe6c549e8226b4893f502186f52452dcd9408a2": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-11572. [SPS]: SPS should clean Xattrs when no blocks required to satisfy for a file. Contributed by Uma Maheswara Rao G\n",
      "commitDate": "12/08/18 3:05 AM",
      "commitName": "6fe6c549e8226b4893f502186f52452dcd9408a2",
      "commitAuthor": "Rakesh Radhakrishnan",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-11572. [SPS]: SPS should clean Xattrs when no blocks required to satisfy for a file. Contributed by Uma Maheswara Rao G\n",
          "commitDate": "12/08/18 3:05 AM",
          "commitName": "6fe6c549e8226b4893f502186f52452dcd9408a2",
          "commitAuthor": "Rakesh Radhakrishnan",
          "commitDateOld": "12/08/18 3:05 AM",
          "commitNameOld": "695a402fcad20c711c5d845e0664c43fd6b06286",
          "commitAuthorOld": "Uma Maheswara Rao G",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,59 +1,51 @@\n   private boolean computeBlockMovingInfos(\n       List\u003cBlockMovingInfo\u003e blockMovingInfos, BlockInfo blockInfo,\n-      List\u003cStorageType\u003e expectedStorageTypes) {\n+      List\u003cStorageType\u003e expectedStorageTypes, List\u003cStorageType\u003e existing,\n+      DatanodeStorageInfo[] storages) {\n     boolean foundMatchingTargetNodesForBlock \u003d true;\n-    DatanodeStorageInfo[] storages \u003d blockManager.getStorages(blockInfo);\n-    StorageType[] storageTypes \u003d new StorageType[storages.length];\n-    for (int j \u003d 0; j \u003c storages.length; j++) {\n-      DatanodeStorageInfo datanodeStorageInfo \u003d storages[j];\n-      StorageType storageType \u003d datanodeStorageInfo.getStorageType();\n-      storageTypes[j] \u003d storageType;\n-    }\n-    List\u003cStorageType\u003e existing \u003d\n-        new LinkedList\u003cStorageType\u003e(Arrays.asList(storageTypes));\n     if (!DFSUtil.removeOverlapBetweenStorageTypes(expectedStorageTypes,\n         existing, true)) {\n       List\u003cStorageTypeNodePair\u003e sourceWithStorageMap \u003d\n           new ArrayList\u003cStorageTypeNodePair\u003e();\n       List\u003cDatanodeStorageInfo\u003e existingBlockStorages \u003d\n           new ArrayList\u003cDatanodeStorageInfo\u003e(Arrays.asList(storages));\n       // if expected type exists in source node already, local movement would be\n       // possible, so lets find such sources first.\n       Iterator\u003cDatanodeStorageInfo\u003e iterator \u003d existingBlockStorages.iterator();\n       while (iterator.hasNext()) {\n         DatanodeStorageInfo datanodeStorageInfo \u003d iterator.next();\n         if (checkSourceAndTargetTypeExists(\n             datanodeStorageInfo.getDatanodeDescriptor(), existing,\n             expectedStorageTypes)) {\n           sourceWithStorageMap\n               .add(new StorageTypeNodePair(datanodeStorageInfo.getStorageType(),\n                   datanodeStorageInfo.getDatanodeDescriptor()));\n           iterator.remove();\n           existing.remove(datanodeStorageInfo.getStorageType());\n         }\n       }\n \n       // Let\u0027s find sources for existing types left.\n       for (StorageType existingType : existing) {\n         iterator \u003d existingBlockStorages.iterator();\n         while (iterator.hasNext()) {\n           DatanodeStorageInfo datanodeStorageInfo \u003d iterator.next();\n           StorageType storageType \u003d datanodeStorageInfo.getStorageType();\n           if (storageType \u003d\u003d existingType) {\n             iterator.remove();\n             sourceWithStorageMap.add(new StorageTypeNodePair(storageType,\n                 datanodeStorageInfo.getDatanodeDescriptor()));\n             break;\n           }\n         }\n       }\n \n       StorageTypeNodeMap locsForExpectedStorageTypes \u003d\n           findTargetsForExpectedStorageTypes(expectedStorageTypes);\n \n       foundMatchingTargetNodesForBlock |\u003d findSourceAndTargetToMove(\n           blockMovingInfos, blockInfo, sourceWithStorageMap,\n           expectedStorageTypes, locsForExpectedStorageTypes);\n     }\n     return foundMatchingTargetNodesForBlock;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private boolean computeBlockMovingInfos(\n      List\u003cBlockMovingInfo\u003e blockMovingInfos, BlockInfo blockInfo,\n      List\u003cStorageType\u003e expectedStorageTypes, List\u003cStorageType\u003e existing,\n      DatanodeStorageInfo[] storages) {\n    boolean foundMatchingTargetNodesForBlock \u003d true;\n    if (!DFSUtil.removeOverlapBetweenStorageTypes(expectedStorageTypes,\n        existing, true)) {\n      List\u003cStorageTypeNodePair\u003e sourceWithStorageMap \u003d\n          new ArrayList\u003cStorageTypeNodePair\u003e();\n      List\u003cDatanodeStorageInfo\u003e existingBlockStorages \u003d\n          new ArrayList\u003cDatanodeStorageInfo\u003e(Arrays.asList(storages));\n      // if expected type exists in source node already, local movement would be\n      // possible, so lets find such sources first.\n      Iterator\u003cDatanodeStorageInfo\u003e iterator \u003d existingBlockStorages.iterator();\n      while (iterator.hasNext()) {\n        DatanodeStorageInfo datanodeStorageInfo \u003d iterator.next();\n        if (checkSourceAndTargetTypeExists(\n            datanodeStorageInfo.getDatanodeDescriptor(), existing,\n            expectedStorageTypes)) {\n          sourceWithStorageMap\n              .add(new StorageTypeNodePair(datanodeStorageInfo.getStorageType(),\n                  datanodeStorageInfo.getDatanodeDescriptor()));\n          iterator.remove();\n          existing.remove(datanodeStorageInfo.getStorageType());\n        }\n      }\n\n      // Let\u0027s find sources for existing types left.\n      for (StorageType existingType : existing) {\n        iterator \u003d existingBlockStorages.iterator();\n        while (iterator.hasNext()) {\n          DatanodeStorageInfo datanodeStorageInfo \u003d iterator.next();\n          StorageType storageType \u003d datanodeStorageInfo.getStorageType();\n          if (storageType \u003d\u003d existingType) {\n            iterator.remove();\n            sourceWithStorageMap.add(new StorageTypeNodePair(storageType,\n                datanodeStorageInfo.getDatanodeDescriptor()));\n            break;\n          }\n        }\n      }\n\n      StorageTypeNodeMap locsForExpectedStorageTypes \u003d\n          findTargetsForExpectedStorageTypes(expectedStorageTypes);\n\n      foundMatchingTargetNodesForBlock |\u003d findSourceAndTargetToMove(\n          blockMovingInfos, blockInfo, sourceWithStorageMap,\n          expectedStorageTypes, locsForExpectedStorageTypes);\n    }\n    return foundMatchingTargetNodesForBlock;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/StoragePolicySatisfier.java",
          "extendedDetails": {
            "oldValue": "[blockMovingInfos-List\u003cBlockMovingInfo\u003e, blockInfo-BlockInfo, expectedStorageTypes-List\u003cStorageType\u003e]",
            "newValue": "[blockMovingInfos-List\u003cBlockMovingInfo\u003e, blockInfo-BlockInfo, expectedStorageTypes-List\u003cStorageType\u003e, existing-List\u003cStorageType\u003e, storages-DatanodeStorageInfo[]]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-11572. [SPS]: SPS should clean Xattrs when no blocks required to satisfy for a file. Contributed by Uma Maheswara Rao G\n",
          "commitDate": "12/08/18 3:05 AM",
          "commitName": "6fe6c549e8226b4893f502186f52452dcd9408a2",
          "commitAuthor": "Rakesh Radhakrishnan",
          "commitDateOld": "12/08/18 3:05 AM",
          "commitNameOld": "695a402fcad20c711c5d845e0664c43fd6b06286",
          "commitAuthorOld": "Uma Maheswara Rao G",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,59 +1,51 @@\n   private boolean computeBlockMovingInfos(\n       List\u003cBlockMovingInfo\u003e blockMovingInfos, BlockInfo blockInfo,\n-      List\u003cStorageType\u003e expectedStorageTypes) {\n+      List\u003cStorageType\u003e expectedStorageTypes, List\u003cStorageType\u003e existing,\n+      DatanodeStorageInfo[] storages) {\n     boolean foundMatchingTargetNodesForBlock \u003d true;\n-    DatanodeStorageInfo[] storages \u003d blockManager.getStorages(blockInfo);\n-    StorageType[] storageTypes \u003d new StorageType[storages.length];\n-    for (int j \u003d 0; j \u003c storages.length; j++) {\n-      DatanodeStorageInfo datanodeStorageInfo \u003d storages[j];\n-      StorageType storageType \u003d datanodeStorageInfo.getStorageType();\n-      storageTypes[j] \u003d storageType;\n-    }\n-    List\u003cStorageType\u003e existing \u003d\n-        new LinkedList\u003cStorageType\u003e(Arrays.asList(storageTypes));\n     if (!DFSUtil.removeOverlapBetweenStorageTypes(expectedStorageTypes,\n         existing, true)) {\n       List\u003cStorageTypeNodePair\u003e sourceWithStorageMap \u003d\n           new ArrayList\u003cStorageTypeNodePair\u003e();\n       List\u003cDatanodeStorageInfo\u003e existingBlockStorages \u003d\n           new ArrayList\u003cDatanodeStorageInfo\u003e(Arrays.asList(storages));\n       // if expected type exists in source node already, local movement would be\n       // possible, so lets find such sources first.\n       Iterator\u003cDatanodeStorageInfo\u003e iterator \u003d existingBlockStorages.iterator();\n       while (iterator.hasNext()) {\n         DatanodeStorageInfo datanodeStorageInfo \u003d iterator.next();\n         if (checkSourceAndTargetTypeExists(\n             datanodeStorageInfo.getDatanodeDescriptor(), existing,\n             expectedStorageTypes)) {\n           sourceWithStorageMap\n               .add(new StorageTypeNodePair(datanodeStorageInfo.getStorageType(),\n                   datanodeStorageInfo.getDatanodeDescriptor()));\n           iterator.remove();\n           existing.remove(datanodeStorageInfo.getStorageType());\n         }\n       }\n \n       // Let\u0027s find sources for existing types left.\n       for (StorageType existingType : existing) {\n         iterator \u003d existingBlockStorages.iterator();\n         while (iterator.hasNext()) {\n           DatanodeStorageInfo datanodeStorageInfo \u003d iterator.next();\n           StorageType storageType \u003d datanodeStorageInfo.getStorageType();\n           if (storageType \u003d\u003d existingType) {\n             iterator.remove();\n             sourceWithStorageMap.add(new StorageTypeNodePair(storageType,\n                 datanodeStorageInfo.getDatanodeDescriptor()));\n             break;\n           }\n         }\n       }\n \n       StorageTypeNodeMap locsForExpectedStorageTypes \u003d\n           findTargetsForExpectedStorageTypes(expectedStorageTypes);\n \n       foundMatchingTargetNodesForBlock |\u003d findSourceAndTargetToMove(\n           blockMovingInfos, blockInfo, sourceWithStorageMap,\n           expectedStorageTypes, locsForExpectedStorageTypes);\n     }\n     return foundMatchingTargetNodesForBlock;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private boolean computeBlockMovingInfos(\n      List\u003cBlockMovingInfo\u003e blockMovingInfos, BlockInfo blockInfo,\n      List\u003cStorageType\u003e expectedStorageTypes, List\u003cStorageType\u003e existing,\n      DatanodeStorageInfo[] storages) {\n    boolean foundMatchingTargetNodesForBlock \u003d true;\n    if (!DFSUtil.removeOverlapBetweenStorageTypes(expectedStorageTypes,\n        existing, true)) {\n      List\u003cStorageTypeNodePair\u003e sourceWithStorageMap \u003d\n          new ArrayList\u003cStorageTypeNodePair\u003e();\n      List\u003cDatanodeStorageInfo\u003e existingBlockStorages \u003d\n          new ArrayList\u003cDatanodeStorageInfo\u003e(Arrays.asList(storages));\n      // if expected type exists in source node already, local movement would be\n      // possible, so lets find such sources first.\n      Iterator\u003cDatanodeStorageInfo\u003e iterator \u003d existingBlockStorages.iterator();\n      while (iterator.hasNext()) {\n        DatanodeStorageInfo datanodeStorageInfo \u003d iterator.next();\n        if (checkSourceAndTargetTypeExists(\n            datanodeStorageInfo.getDatanodeDescriptor(), existing,\n            expectedStorageTypes)) {\n          sourceWithStorageMap\n              .add(new StorageTypeNodePair(datanodeStorageInfo.getStorageType(),\n                  datanodeStorageInfo.getDatanodeDescriptor()));\n          iterator.remove();\n          existing.remove(datanodeStorageInfo.getStorageType());\n        }\n      }\n\n      // Let\u0027s find sources for existing types left.\n      for (StorageType existingType : existing) {\n        iterator \u003d existingBlockStorages.iterator();\n        while (iterator.hasNext()) {\n          DatanodeStorageInfo datanodeStorageInfo \u003d iterator.next();\n          StorageType storageType \u003d datanodeStorageInfo.getStorageType();\n          if (storageType \u003d\u003d existingType) {\n            iterator.remove();\n            sourceWithStorageMap.add(new StorageTypeNodePair(storageType,\n                datanodeStorageInfo.getDatanodeDescriptor()));\n            break;\n          }\n        }\n      }\n\n      StorageTypeNodeMap locsForExpectedStorageTypes \u003d\n          findTargetsForExpectedStorageTypes(expectedStorageTypes);\n\n      foundMatchingTargetNodesForBlock |\u003d findSourceAndTargetToMove(\n          blockMovingInfos, blockInfo, sourceWithStorageMap,\n          expectedStorageTypes, locsForExpectedStorageTypes);\n    }\n    return foundMatchingTargetNodesForBlock;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/StoragePolicySatisfier.java",
          "extendedDetails": {}
        }
      ]
    },
    "df2b551e79c9e5d8bdd981c48be52bae5f0d9a82": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11293: [SPS]: Local DN should be given preference as source node, when target available in same node. Contributed by Yuanbo Liu and Uma Maheswara Rao G\n",
      "commitDate": "12/08/18 3:05 AM",
      "commitName": "df2b551e79c9e5d8bdd981c48be52bae5f0d9a82",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:05 AM",
      "commitNameOld": "422f870607effd88b704c93783220bcedf9ddfb1",
      "commitAuthorOld": "Rakesh Radhakrishnan",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,43 +1,59 @@\n   private boolean computeBlockMovingInfos(\n       List\u003cBlockMovingInfo\u003e blockMovingInfos, BlockInfo blockInfo,\n       List\u003cStorageType\u003e expectedStorageTypes) {\n     boolean foundMatchingTargetNodesForBlock \u003d true;\n     DatanodeStorageInfo[] storages \u003d blockManager.getStorages(blockInfo);\n     StorageType[] storageTypes \u003d new StorageType[storages.length];\n     for (int j \u003d 0; j \u003c storages.length; j++) {\n       DatanodeStorageInfo datanodeStorageInfo \u003d storages[j];\n       StorageType storageType \u003d datanodeStorageInfo.getStorageType();\n       storageTypes[j] \u003d storageType;\n     }\n     List\u003cStorageType\u003e existing \u003d\n         new LinkedList\u003cStorageType\u003e(Arrays.asList(storageTypes));\n     if (!DFSUtil.removeOverlapBetweenStorageTypes(expectedStorageTypes,\n         existing, true)) {\n       List\u003cStorageTypeNodePair\u003e sourceWithStorageMap \u003d\n           new ArrayList\u003cStorageTypeNodePair\u003e();\n       List\u003cDatanodeStorageInfo\u003e existingBlockStorages \u003d\n           new ArrayList\u003cDatanodeStorageInfo\u003e(Arrays.asList(storages));\n+      // if expected type exists in source node already, local movement would be\n+      // possible, so lets find such sources first.\n+      Iterator\u003cDatanodeStorageInfo\u003e iterator \u003d existingBlockStorages.iterator();\n+      while (iterator.hasNext()) {\n+        DatanodeStorageInfo datanodeStorageInfo \u003d iterator.next();\n+        if (checkSourceAndTargetTypeExists(\n+            datanodeStorageInfo.getDatanodeDescriptor(), existing,\n+            expectedStorageTypes)) {\n+          sourceWithStorageMap\n+              .add(new StorageTypeNodePair(datanodeStorageInfo.getStorageType(),\n+                  datanodeStorageInfo.getDatanodeDescriptor()));\n+          iterator.remove();\n+          existing.remove(datanodeStorageInfo.getStorageType());\n+        }\n+      }\n+\n+      // Let\u0027s find sources for existing types left.\n       for (StorageType existingType : existing) {\n-        Iterator\u003cDatanodeStorageInfo\u003e iterator \u003d\n-            existingBlockStorages.iterator();\n+        iterator \u003d existingBlockStorages.iterator();\n         while (iterator.hasNext()) {\n           DatanodeStorageInfo datanodeStorageInfo \u003d iterator.next();\n           StorageType storageType \u003d datanodeStorageInfo.getStorageType();\n           if (storageType \u003d\u003d existingType) {\n             iterator.remove();\n             sourceWithStorageMap.add(new StorageTypeNodePair(storageType,\n                 datanodeStorageInfo.getDatanodeDescriptor()));\n             break;\n           }\n         }\n       }\n \n       StorageTypeNodeMap locsForExpectedStorageTypes \u003d\n           findTargetsForExpectedStorageTypes(expectedStorageTypes);\n \n       foundMatchingTargetNodesForBlock |\u003d findSourceAndTargetToMove(\n-          blockMovingInfos, blockInfo, existing, sourceWithStorageMap,\n+          blockMovingInfos, blockInfo, sourceWithStorageMap,\n           expectedStorageTypes, locsForExpectedStorageTypes);\n     }\n     return foundMatchingTargetNodesForBlock;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean computeBlockMovingInfos(\n      List\u003cBlockMovingInfo\u003e blockMovingInfos, BlockInfo blockInfo,\n      List\u003cStorageType\u003e expectedStorageTypes) {\n    boolean foundMatchingTargetNodesForBlock \u003d true;\n    DatanodeStorageInfo[] storages \u003d blockManager.getStorages(blockInfo);\n    StorageType[] storageTypes \u003d new StorageType[storages.length];\n    for (int j \u003d 0; j \u003c storages.length; j++) {\n      DatanodeStorageInfo datanodeStorageInfo \u003d storages[j];\n      StorageType storageType \u003d datanodeStorageInfo.getStorageType();\n      storageTypes[j] \u003d storageType;\n    }\n    List\u003cStorageType\u003e existing \u003d\n        new LinkedList\u003cStorageType\u003e(Arrays.asList(storageTypes));\n    if (!DFSUtil.removeOverlapBetweenStorageTypes(expectedStorageTypes,\n        existing, true)) {\n      List\u003cStorageTypeNodePair\u003e sourceWithStorageMap \u003d\n          new ArrayList\u003cStorageTypeNodePair\u003e();\n      List\u003cDatanodeStorageInfo\u003e existingBlockStorages \u003d\n          new ArrayList\u003cDatanodeStorageInfo\u003e(Arrays.asList(storages));\n      // if expected type exists in source node already, local movement would be\n      // possible, so lets find such sources first.\n      Iterator\u003cDatanodeStorageInfo\u003e iterator \u003d existingBlockStorages.iterator();\n      while (iterator.hasNext()) {\n        DatanodeStorageInfo datanodeStorageInfo \u003d iterator.next();\n        if (checkSourceAndTargetTypeExists(\n            datanodeStorageInfo.getDatanodeDescriptor(), existing,\n            expectedStorageTypes)) {\n          sourceWithStorageMap\n              .add(new StorageTypeNodePair(datanodeStorageInfo.getStorageType(),\n                  datanodeStorageInfo.getDatanodeDescriptor()));\n          iterator.remove();\n          existing.remove(datanodeStorageInfo.getStorageType());\n        }\n      }\n\n      // Let\u0027s find sources for existing types left.\n      for (StorageType existingType : existing) {\n        iterator \u003d existingBlockStorages.iterator();\n        while (iterator.hasNext()) {\n          DatanodeStorageInfo datanodeStorageInfo \u003d iterator.next();\n          StorageType storageType \u003d datanodeStorageInfo.getStorageType();\n          if (storageType \u003d\u003d existingType) {\n            iterator.remove();\n            sourceWithStorageMap.add(new StorageTypeNodePair(storageType,\n                datanodeStorageInfo.getDatanodeDescriptor()));\n            break;\n          }\n        }\n      }\n\n      StorageTypeNodeMap locsForExpectedStorageTypes \u003d\n          findTargetsForExpectedStorageTypes(expectedStorageTypes);\n\n      foundMatchingTargetNodesForBlock |\u003d findSourceAndTargetToMove(\n          blockMovingInfos, blockInfo, sourceWithStorageMap,\n          expectedStorageTypes, locsForExpectedStorageTypes);\n    }\n    return foundMatchingTargetNodesForBlock;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/StoragePolicySatisfier.java",
      "extendedDetails": {}
    },
    "b7bed9f00a25bcad6f9c3543f5a1fb0a1f23b0e9": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-11248: [SPS]: Handle partial block location movements. Contributed by Rakesh R\n",
      "commitDate": "12/08/18 3:05 AM",
      "commitName": "b7bed9f00a25bcad6f9c3543f5a1fb0a1f23b0e9",
      "commitAuthor": "Uma Maheswara Rao G",
      "diff": "@@ -0,0 +1,43 @@\n+  private boolean computeBlockMovingInfos(\n+      List\u003cBlockMovingInfo\u003e blockMovingInfos, BlockInfo blockInfo,\n+      List\u003cStorageType\u003e expectedStorageTypes) {\n+    boolean foundMatchingTargetNodesForBlock \u003d true;\n+    DatanodeStorageInfo[] storages \u003d blockManager.getStorages(blockInfo);\n+    StorageType[] storageTypes \u003d new StorageType[storages.length];\n+    for (int j \u003d 0; j \u003c storages.length; j++) {\n+      DatanodeStorageInfo datanodeStorageInfo \u003d storages[j];\n+      StorageType storageType \u003d datanodeStorageInfo.getStorageType();\n+      storageTypes[j] \u003d storageType;\n+    }\n+    List\u003cStorageType\u003e existing \u003d\n+        new LinkedList\u003cStorageType\u003e(Arrays.asList(storageTypes));\n+    if (!DFSUtil.removeOverlapBetweenStorageTypes(expectedStorageTypes,\n+        existing, true)) {\n+      List\u003cStorageTypeNodePair\u003e sourceWithStorageMap \u003d\n+          new ArrayList\u003cStorageTypeNodePair\u003e();\n+      List\u003cDatanodeStorageInfo\u003e existingBlockStorages \u003d\n+          new ArrayList\u003cDatanodeStorageInfo\u003e(Arrays.asList(storages));\n+      for (StorageType existingType : existing) {\n+        Iterator\u003cDatanodeStorageInfo\u003e iterator \u003d\n+            existingBlockStorages.iterator();\n+        while (iterator.hasNext()) {\n+          DatanodeStorageInfo datanodeStorageInfo \u003d iterator.next();\n+          StorageType storageType \u003d datanodeStorageInfo.getStorageType();\n+          if (storageType \u003d\u003d existingType) {\n+            iterator.remove();\n+            sourceWithStorageMap.add(new StorageTypeNodePair(storageType,\n+                datanodeStorageInfo.getDatanodeDescriptor()));\n+            break;\n+          }\n+        }\n+      }\n+\n+      StorageTypeNodeMap locsForExpectedStorageTypes \u003d\n+          findTargetsForExpectedStorageTypes(expectedStorageTypes);\n+\n+      foundMatchingTargetNodesForBlock |\u003d findSourceAndTargetToMove(\n+          blockMovingInfos, blockInfo, existing, sourceWithStorageMap,\n+          expectedStorageTypes, locsForExpectedStorageTypes);\n+    }\n+    return foundMatchingTargetNodesForBlock;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean computeBlockMovingInfos(\n      List\u003cBlockMovingInfo\u003e blockMovingInfos, BlockInfo blockInfo,\n      List\u003cStorageType\u003e expectedStorageTypes) {\n    boolean foundMatchingTargetNodesForBlock \u003d true;\n    DatanodeStorageInfo[] storages \u003d blockManager.getStorages(blockInfo);\n    StorageType[] storageTypes \u003d new StorageType[storages.length];\n    for (int j \u003d 0; j \u003c storages.length; j++) {\n      DatanodeStorageInfo datanodeStorageInfo \u003d storages[j];\n      StorageType storageType \u003d datanodeStorageInfo.getStorageType();\n      storageTypes[j] \u003d storageType;\n    }\n    List\u003cStorageType\u003e existing \u003d\n        new LinkedList\u003cStorageType\u003e(Arrays.asList(storageTypes));\n    if (!DFSUtil.removeOverlapBetweenStorageTypes(expectedStorageTypes,\n        existing, true)) {\n      List\u003cStorageTypeNodePair\u003e sourceWithStorageMap \u003d\n          new ArrayList\u003cStorageTypeNodePair\u003e();\n      List\u003cDatanodeStorageInfo\u003e existingBlockStorages \u003d\n          new ArrayList\u003cDatanodeStorageInfo\u003e(Arrays.asList(storages));\n      for (StorageType existingType : existing) {\n        Iterator\u003cDatanodeStorageInfo\u003e iterator \u003d\n            existingBlockStorages.iterator();\n        while (iterator.hasNext()) {\n          DatanodeStorageInfo datanodeStorageInfo \u003d iterator.next();\n          StorageType storageType \u003d datanodeStorageInfo.getStorageType();\n          if (storageType \u003d\u003d existingType) {\n            iterator.remove();\n            sourceWithStorageMap.add(new StorageTypeNodePair(storageType,\n                datanodeStorageInfo.getDatanodeDescriptor()));\n            break;\n          }\n        }\n      }\n\n      StorageTypeNodeMap locsForExpectedStorageTypes \u003d\n          findTargetsForExpectedStorageTypes(expectedStorageTypes);\n\n      foundMatchingTargetNodesForBlock |\u003d findSourceAndTargetToMove(\n          blockMovingInfos, blockInfo, existing, sourceWithStorageMap,\n          expectedStorageTypes, locsForExpectedStorageTypes);\n    }\n    return foundMatchingTargetNodesForBlock;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/StoragePolicySatisfier.java"
    }
  }
}