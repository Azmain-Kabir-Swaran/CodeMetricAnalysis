{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSImageFormatPBSnapshot.java",
  "functionName": "serializeSnapshotDiffSection",
  "functionId": "serializeSnapshotDiffSection___out-OutputStream",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/FSImageFormatPBSnapshot.java",
  "functionStartLine": 514,
  "functionEndLine": 540,
  "numCommitsSeen": 34,
  "timeTaken": 2863,
  "changeHistory": [
    "b67812ea2111fa11bdd76096b923c93e1bdf2923",
    "2624b20291629b4565ea45590b66f2c38f96df67",
    "a2edb11b68ae01a44092cb14ac2717a6aad93305"
  ],
  "changeHistoryShort": {
    "b67812ea2111fa11bdd76096b923c93e1bdf2923": "Ybodychange",
    "2624b20291629b4565ea45590b66f2c38f96df67": "Ybodychange",
    "a2edb11b68ae01a44092cb14ac2717a6aad93305": "Yintroduced"
  },
  "changeHistoryDetails": {
    "b67812ea2111fa11bdd76096b923c93e1bdf2923": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14617. Improve fsimage load time by writing sub-sections to the fsimage index (#1028). Contributed by  Stephen O\u0027Donnell.\n\nReviewed-by: He Xiaoqiao \u003chexiaoqiao@apache.org\u003e",
      "commitDate": "22/08/19 5:09 PM",
      "commitName": "b67812ea2111fa11bdd76096b923c93e1bdf2923",
      "commitAuthor": "Stephen O\u0027Donnell",
      "commitDateOld": "28/03/18 12:49 PM",
      "commitNameOld": "a991e899fb9f98d2089f37ac9ac7c485d3bbb959",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 512.18,
      "commitsBetweenForRepo": 4413,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,27 @@\n     public void serializeSnapshotDiffSection(OutputStream out)\n         throws IOException {\n       INodeMap inodesMap \u003d fsn.getFSDirectory().getINodeMap();\n       final List\u003cINodeReference\u003e refList \u003d parent.getSaverContext()\n           .getRefList();\n       int i \u003d 0;\n       Iterator\u003cINodeWithAdditionalFields\u003e iter \u003d inodesMap.getMapIterator();\n       while (iter.hasNext()) {\n         INodeWithAdditionalFields inode \u003d iter.next();\n         if (inode.isFile()) {\n           serializeFileDiffList(inode.asFile(), out);\n         } else if (inode.isDirectory()) {\n           serializeDirDiffList(inode.asDirectory(), refList, out);\n         }\n         ++i;\n         if (i % FSImageFormatProtobuf.Saver.CHECK_CANCEL_INTERVAL \u003d\u003d 0) {\n           context.checkCancelled();\n         }\n+        if (i % parent.getInodesPerSubSection() \u003d\u003d 0) {\n+          parent.commitSubSection(headers,\n+              FSImageFormatProtobuf.SectionName.SNAPSHOT_DIFF_SUB);\n+        }\n       }\n-      parent.commitSection(headers,\n-          FSImageFormatProtobuf.SectionName.SNAPSHOT_DIFF);\n+      parent.commitSectionAndSubSection(headers,\n+          FSImageFormatProtobuf.SectionName.SNAPSHOT_DIFF,\n+          FSImageFormatProtobuf.SectionName.SNAPSHOT_DIFF_SUB);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void serializeSnapshotDiffSection(OutputStream out)\n        throws IOException {\n      INodeMap inodesMap \u003d fsn.getFSDirectory().getINodeMap();\n      final List\u003cINodeReference\u003e refList \u003d parent.getSaverContext()\n          .getRefList();\n      int i \u003d 0;\n      Iterator\u003cINodeWithAdditionalFields\u003e iter \u003d inodesMap.getMapIterator();\n      while (iter.hasNext()) {\n        INodeWithAdditionalFields inode \u003d iter.next();\n        if (inode.isFile()) {\n          serializeFileDiffList(inode.asFile(), out);\n        } else if (inode.isDirectory()) {\n          serializeDirDiffList(inode.asDirectory(), refList, out);\n        }\n        ++i;\n        if (i % FSImageFormatProtobuf.Saver.CHECK_CANCEL_INTERVAL \u003d\u003d 0) {\n          context.checkCancelled();\n        }\n        if (i % parent.getInodesPerSubSection() \u003d\u003d 0) {\n          parent.commitSubSection(headers,\n              FSImageFormatProtobuf.SectionName.SNAPSHOT_DIFF_SUB);\n        }\n      }\n      parent.commitSectionAndSubSection(headers,\n          FSImageFormatProtobuf.SectionName.SNAPSHOT_DIFF,\n          FSImageFormatProtobuf.SectionName.SNAPSHOT_DIFF_SUB);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/FSImageFormatPBSnapshot.java",
      "extendedDetails": {}
    },
    "2624b20291629b4565ea45590b66f2c38f96df67": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5847. Consolidate INodeReference into a separate section. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1567812 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/02/14 4:00 PM",
      "commitName": "2624b20291629b4565ea45590b66f2c38f96df67",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "10/02/14 3:13 PM",
      "commitNameOld": "5c978a43c3052cc1466b23653c354399186b4e10",
      "commitAuthorOld": "Chris Nauroth",
      "daysBetweenCommits": 2.03,
      "commitsBetweenForRepo": 23,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,22 @@\n     public void serializeSnapshotDiffSection(OutputStream out)\n         throws IOException {\n       INodeMap inodesMap \u003d fsn.getFSDirectory().getINodeMap();\n+      final List\u003cINodeReference\u003e refList \u003d parent.getSaverContext()\n+          .getRefList();\n       int i \u003d 0;\n       Iterator\u003cINodeWithAdditionalFields\u003e iter \u003d inodesMap.getMapIterator();\n       while (iter.hasNext()) {\n         INodeWithAdditionalFields inode \u003d iter.next();\n         if (inode.isFile()) {\n           serializeFileDiffList(inode.asFile(), out);\n         } else if (inode.isDirectory()) {\n-          serializeDirDiffList(inode.asDirectory(), out);\n+          serializeDirDiffList(inode.asDirectory(), refList, out);\n         }\n         ++i;\n         if (i % FSImageFormatProtobuf.Saver.CHECK_CANCEL_INTERVAL \u003d\u003d 0) {\n           context.checkCancelled();\n         }\n       }\n       parent.commitSection(headers,\n           FSImageFormatProtobuf.SectionName.SNAPSHOT_DIFF);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void serializeSnapshotDiffSection(OutputStream out)\n        throws IOException {\n      INodeMap inodesMap \u003d fsn.getFSDirectory().getINodeMap();\n      final List\u003cINodeReference\u003e refList \u003d parent.getSaverContext()\n          .getRefList();\n      int i \u003d 0;\n      Iterator\u003cINodeWithAdditionalFields\u003e iter \u003d inodesMap.getMapIterator();\n      while (iter.hasNext()) {\n        INodeWithAdditionalFields inode \u003d iter.next();\n        if (inode.isFile()) {\n          serializeFileDiffList(inode.asFile(), out);\n        } else if (inode.isDirectory()) {\n          serializeDirDiffList(inode.asDirectory(), refList, out);\n        }\n        ++i;\n        if (i % FSImageFormatProtobuf.Saver.CHECK_CANCEL_INTERVAL \u003d\u003d 0) {\n          context.checkCancelled();\n        }\n      }\n      parent.commitSection(headers,\n          FSImageFormatProtobuf.SectionName.SNAPSHOT_DIFF);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/FSImageFormatPBSnapshot.java",
      "extendedDetails": {}
    },
    "a2edb11b68ae01a44092cb14ac2717a6aad93305": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-5698. Use protobuf to serialize / deserialize FSImage. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1566359 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/02/14 11:18 AM",
      "commitName": "a2edb11b68ae01a44092cb14ac2717a6aad93305",
      "commitAuthor": "Jing Zhao",
      "diff": "@@ -0,0 +1,20 @@\n+    public void serializeSnapshotDiffSection(OutputStream out)\n+        throws IOException {\n+      INodeMap inodesMap \u003d fsn.getFSDirectory().getINodeMap();\n+      int i \u003d 0;\n+      Iterator\u003cINodeWithAdditionalFields\u003e iter \u003d inodesMap.getMapIterator();\n+      while (iter.hasNext()) {\n+        INodeWithAdditionalFields inode \u003d iter.next();\n+        if (inode.isFile()) {\n+          serializeFileDiffList(inode.asFile(), out);\n+        } else if (inode.isDirectory()) {\n+          serializeDirDiffList(inode.asDirectory(), out);\n+        }\n+        ++i;\n+        if (i % FSImageFormatProtobuf.Saver.CHECK_CANCEL_INTERVAL \u003d\u003d 0) {\n+          context.checkCancelled();\n+        }\n+      }\n+      parent.commitSection(headers,\n+          FSImageFormatProtobuf.SectionName.SNAPSHOT_DIFF);\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    public void serializeSnapshotDiffSection(OutputStream out)\n        throws IOException {\n      INodeMap inodesMap \u003d fsn.getFSDirectory().getINodeMap();\n      int i \u003d 0;\n      Iterator\u003cINodeWithAdditionalFields\u003e iter \u003d inodesMap.getMapIterator();\n      while (iter.hasNext()) {\n        INodeWithAdditionalFields inode \u003d iter.next();\n        if (inode.isFile()) {\n          serializeFileDiffList(inode.asFile(), out);\n        } else if (inode.isDirectory()) {\n          serializeDirDiffList(inode.asDirectory(), out);\n        }\n        ++i;\n        if (i % FSImageFormatProtobuf.Saver.CHECK_CANCEL_INTERVAL \u003d\u003d 0) {\n          context.checkCancelled();\n        }\n      }\n      parent.commitSection(headers,\n          FSImageFormatProtobuf.SectionName.SNAPSHOT_DIFF);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/FSImageFormatPBSnapshot.java"
    }
  }
}