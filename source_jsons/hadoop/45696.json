{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "LogAggregationIndexedFileController.java",
  "functionName": "initializeWriter",
  "functionId": "initializeWriter___context-LogAggregationFileControllerContext(modifiers-final)",
  "sourceFilePath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/filecontroller/ifile/LogAggregationIndexedFileController.java",
  "functionStartLine": 155,
  "functionEndLine": 239,
  "numCommitsSeen": 18,
  "timeTaken": 1979,
  "changeHistory": [
    "6d52bbbfcfd7750b7e547abdcd0d14632d6ed9b6",
    "280080fad01304c85a9ede4d4f7b707eb36c0155",
    "3fddabc2fe4fbdb8ef3f9ce7558955c4f0794dcc"
  ],
  "changeHistoryShort": {
    "6d52bbbfcfd7750b7e547abdcd0d14632d6ed9b6": "Ybodychange",
    "280080fad01304c85a9ede4d4f7b707eb36c0155": "Ybodychange",
    "3fddabc2fe4fbdb8ef3f9ce7558955c4f0794dcc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "6d52bbbfcfd7750b7e547abdcd0d14632d6ed9b6": {
      "type": "Ybodychange",
      "commitMessage": "YARN-9525. IFile format is not working against s3a remote folder. Contributed by Adam Antal\n",
      "commitDate": "20/01/20 3:36 AM",
      "commitName": "6d52bbbfcfd7750b7e547abdcd0d14632d6ed9b6",
      "commitAuthor": "Szilard Nemeth",
      "commitDateOld": "05/12/19 12:49 PM",
      "commitNameOld": "4f758dd4c682bacbb110c51a96079a6c5d103c95",
      "commitAuthorOld": "Szilard Nemeth",
      "daysBetweenCommits": 45.62,
      "commitsBetweenForRepo": 149,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,70 +1,85 @@\n   public void initializeWriter(\n       final LogAggregationFileControllerContext context)\n       throws IOException {\n     final UserGroupInformation userUgi \u003d context.getUserUgi();\n     final Map\u003cApplicationAccessType, String\u003e appAcls \u003d context.getAppAcls();\n     final String nodeId \u003d context.getNodeId().toString();\n     final ApplicationId appId \u003d context.getAppId();\n     final Path remoteLogFile \u003d context.getRemoteNodeLogFileForApp();\n     this.ugi \u003d userUgi;\n     logAggregationSuccessfullyInThisCyCle \u003d false;\n     logsMetaInThisCycle \u003d new IndexedPerAggregationLogMeta();\n     logAggregationTimeInThisCycle \u003d this.sysClock.getTime();\n     logsMetaInThisCycle.setUploadTimeStamp(logAggregationTimeInThisCycle);\n     logsMetaInThisCycle.setRemoteNodeFile(remoteLogFile.getName());\n     try {\n       userUgi.doAs(new PrivilegedExceptionAction\u003cObject\u003e() {\n         @Override\n         public Object run() throws Exception {\n           fc \u003d FileContext.getFileContext(\n               remoteRootLogDir.toUri(), conf);\n           fc.setUMask(APP_LOG_FILE_UMASK);\n           if (indexedLogsMeta \u003d\u003d null) {\n             indexedLogsMeta \u003d new IndexedLogsMeta();\n             indexedLogsMeta.setVersion(VERSION);\n             indexedLogsMeta.setUser(userUgi.getShortUserName());\n             indexedLogsMeta.setAcls(appAcls);\n             indexedLogsMeta.setNodeId(nodeId);\n             String compressName \u003d conf.get(\n                 YarnConfiguration.NM_LOG_AGG_COMPRESSION_TYPE,\n                 YarnConfiguration.DEFAULT_NM_LOG_AGG_COMPRESSION_TYPE);\n             indexedLogsMeta.setCompressName(compressName);\n           }\n           Path aggregatedLogFile \u003d null;\n+          Pair\u003cPath, Boolean\u003e initializationResult \u003d null;\n+          boolean createdNew;\n+\n           if (context.isLogAggregationInRolling()) {\n-            aggregatedLogFile \u003d initializeWriterInRolling(\n+            // In rolling log aggregation we need special initialization\n+            // done in initializeWriterInRolling.\n+            initializationResult \u003d initializeWriterInRolling(\n                 remoteLogFile, appId, nodeId);\n+            aggregatedLogFile \u003d initializationResult.getLeft();\n+            createdNew \u003d initializationResult.getRight();\n           } else {\n             aggregatedLogFile \u003d remoteLogFile;\n             fsDataOStream \u003d fc.create(remoteLogFile,\n                 EnumSet.of(CreateFlag.CREATE, CreateFlag.OVERWRITE),\n                 new Options.CreateOpts[] {});\n             if (uuid \u003d\u003d null) {\n               uuid \u003d createUUID(appId);\n             }\n             fsDataOStream.write(uuid);\n             fsDataOStream.flush();\n+            createdNew \u003d true;\n           }\n \n-          long aggregatedLogFileLength \u003d fc.getFileStatus(\n-              aggregatedLogFile).getLen();\n-          // append a simple character(\"\\n\") to move the writer cursor, so\n-          // we could get the correct position when we call\n-          // fsOutputStream.getStartPos()\n-          final byte[] dummyBytes \u003d \"\\n\".getBytes(Charset.forName(\"UTF-8\"));\n-          fsDataOStream.write(dummyBytes);\n-          fsDataOStream.flush();\n-\n-          if (fsDataOStream.getPos() \u003e\u003d (aggregatedLogFileLength\n-              + dummyBytes.length)) {\n+          // If we have created a new file, we know that the offset is zero.\n+          // Otherwise we should get this information through getFileStatus.\n+          if (createdNew) {\n             currentOffSet \u003d 0;\n           } else {\n-            currentOffSet \u003d aggregatedLogFileLength;\n+            long aggregatedLogFileLength \u003d fc.getFileStatus(\n+                aggregatedLogFile).getLen();\n+            // append a simple character(\"\\n\") to move the writer cursor, so\n+            // we could get the correct position when we call\n+            // fsOutputStream.getStartPos()\n+            final byte[] dummyBytes \u003d \"\\n\".getBytes(Charset.forName(\"UTF-8\"));\n+            fsDataOStream.write(dummyBytes);\n+            fsDataOStream.flush();\n+\n+            if (fsDataOStream.getPos() \u003c (aggregatedLogFileLength\n+                + dummyBytes.length)) {\n+              currentOffSet \u003d fc.getFileStatus(\n+                      aggregatedLogFile).getLen();\n+            } else {\n+              currentOffSet \u003d 0;\n+            }\n           }\n           return null;\n         }\n       });\n     } catch (Exception e) {\n       throw new IOException(e);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void initializeWriter(\n      final LogAggregationFileControllerContext context)\n      throws IOException {\n    final UserGroupInformation userUgi \u003d context.getUserUgi();\n    final Map\u003cApplicationAccessType, String\u003e appAcls \u003d context.getAppAcls();\n    final String nodeId \u003d context.getNodeId().toString();\n    final ApplicationId appId \u003d context.getAppId();\n    final Path remoteLogFile \u003d context.getRemoteNodeLogFileForApp();\n    this.ugi \u003d userUgi;\n    logAggregationSuccessfullyInThisCyCle \u003d false;\n    logsMetaInThisCycle \u003d new IndexedPerAggregationLogMeta();\n    logAggregationTimeInThisCycle \u003d this.sysClock.getTime();\n    logsMetaInThisCycle.setUploadTimeStamp(logAggregationTimeInThisCycle);\n    logsMetaInThisCycle.setRemoteNodeFile(remoteLogFile.getName());\n    try {\n      userUgi.doAs(new PrivilegedExceptionAction\u003cObject\u003e() {\n        @Override\n        public Object run() throws Exception {\n          fc \u003d FileContext.getFileContext(\n              remoteRootLogDir.toUri(), conf);\n          fc.setUMask(APP_LOG_FILE_UMASK);\n          if (indexedLogsMeta \u003d\u003d null) {\n            indexedLogsMeta \u003d new IndexedLogsMeta();\n            indexedLogsMeta.setVersion(VERSION);\n            indexedLogsMeta.setUser(userUgi.getShortUserName());\n            indexedLogsMeta.setAcls(appAcls);\n            indexedLogsMeta.setNodeId(nodeId);\n            String compressName \u003d conf.get(\n                YarnConfiguration.NM_LOG_AGG_COMPRESSION_TYPE,\n                YarnConfiguration.DEFAULT_NM_LOG_AGG_COMPRESSION_TYPE);\n            indexedLogsMeta.setCompressName(compressName);\n          }\n          Path aggregatedLogFile \u003d null;\n          Pair\u003cPath, Boolean\u003e initializationResult \u003d null;\n          boolean createdNew;\n\n          if (context.isLogAggregationInRolling()) {\n            // In rolling log aggregation we need special initialization\n            // done in initializeWriterInRolling.\n            initializationResult \u003d initializeWriterInRolling(\n                remoteLogFile, appId, nodeId);\n            aggregatedLogFile \u003d initializationResult.getLeft();\n            createdNew \u003d initializationResult.getRight();\n          } else {\n            aggregatedLogFile \u003d remoteLogFile;\n            fsDataOStream \u003d fc.create(remoteLogFile,\n                EnumSet.of(CreateFlag.CREATE, CreateFlag.OVERWRITE),\n                new Options.CreateOpts[] {});\n            if (uuid \u003d\u003d null) {\n              uuid \u003d createUUID(appId);\n            }\n            fsDataOStream.write(uuid);\n            fsDataOStream.flush();\n            createdNew \u003d true;\n          }\n\n          // If we have created a new file, we know that the offset is zero.\n          // Otherwise we should get this information through getFileStatus.\n          if (createdNew) {\n            currentOffSet \u003d 0;\n          } else {\n            long aggregatedLogFileLength \u003d fc.getFileStatus(\n                aggregatedLogFile).getLen();\n            // append a simple character(\"\\n\") to move the writer cursor, so\n            // we could get the correct position when we call\n            // fsOutputStream.getStartPos()\n            final byte[] dummyBytes \u003d \"\\n\".getBytes(Charset.forName(\"UTF-8\"));\n            fsDataOStream.write(dummyBytes);\n            fsDataOStream.flush();\n\n            if (fsDataOStream.getPos() \u003c (aggregatedLogFileLength\n                + dummyBytes.length)) {\n              currentOffSet \u003d fc.getFileStatus(\n                      aggregatedLogFile).getLen();\n            } else {\n              currentOffSet \u003d 0;\n            }\n          }\n          return null;\n        }\n      });\n    } catch (Exception e) {\n      throw new IOException(e);\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/filecontroller/ifile/LogAggregationIndexedFileController.java",
      "extendedDetails": {}
    },
    "280080fad01304c85a9ede4d4f7b707eb36c0155": {
      "type": "Ybodychange",
      "commitMessage": "YARN-7259. Add size-based rolling policy to LogAggregationIndexedFileController. (xgong via wangda)\n\nChange-Id: Ifaf82c0aee6b73b9b6ebf103aa72e131e3942f31\n",
      "commitDate": "02/10/17 3:30 PM",
      "commitName": "280080fad01304c85a9ede4d4f7b707eb36c0155",
      "commitAuthor": "Wangda Tan",
      "commitDateOld": "13/09/17 10:16 PM",
      "commitNameOld": "c92c1d521eadfd8a4cd8205cc6aee74816f353f4",
      "commitAuthorOld": "Junping Du",
      "daysBetweenCommits": 18.72,
      "commitsBetweenForRepo": 136,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,140 +1,70 @@\n   public void initializeWriter(\n       final LogAggregationFileControllerContext context)\n       throws IOException {\n     final UserGroupInformation userUgi \u003d context.getUserUgi();\n     final Map\u003cApplicationAccessType, String\u003e appAcls \u003d context.getAppAcls();\n     final String nodeId \u003d context.getNodeId().toString();\n+    final ApplicationId appId \u003d context.getAppId();\n     final Path remoteLogFile \u003d context.getRemoteNodeLogFileForApp();\n     this.ugi \u003d userUgi;\n     logAggregationSuccessfullyInThisCyCle \u003d false;\n     logsMetaInThisCycle \u003d new IndexedPerAggregationLogMeta();\n-    logAggregationTimeInThisCycle \u003d System.currentTimeMillis();\n+    logAggregationTimeInThisCycle \u003d this.sysClock.getTime();\n     logsMetaInThisCycle.setUploadTimeStamp(logAggregationTimeInThisCycle);\n     logsMetaInThisCycle.setRemoteNodeFile(remoteLogFile.getName());\n     try {\n       userUgi.doAs(new PrivilegedExceptionAction\u003cObject\u003e() {\n         @Override\n         public Object run() throws Exception {\n           fc \u003d FileContext.getFileContext(\n               remoteRootLogDir.toUri(), conf);\n           fc.setUMask(APP_LOG_FILE_UMASK);\n-          boolean fileExist \u003d fc.util().exists(remoteLogFile);\n-          if (fileExist \u0026\u0026 context.isLogAggregationInRolling()) {\n-            fsDataOStream \u003d fc.create(remoteLogFile,\n-                EnumSet.of(CreateFlag.APPEND),\n-                new Options.CreateOpts[] {});\n-            if (uuid \u003d\u003d null) {\n-              FSDataInputStream fsDataInputStream \u003d null;\n-              try {\n-                fsDataInputStream \u003d fc.open(remoteLogFile);\n-                byte[] b \u003d new byte[UUID_LENGTH];\n-                int actual \u003d fsDataInputStream.read(b);\n-                if (actual !\u003d UUID_LENGTH) {\n-                  // Get an error when parse the UUID from existed log file.\n-                  // Simply OverWrite the existed log file and re-create the\n-                  // UUID.\n-                  fsDataOStream \u003d fc.create(remoteLogFile,\n-                      EnumSet.of(CreateFlag.OVERWRITE),\n-                          new Options.CreateOpts[] {});\n-                  uuid \u003d UUID.randomUUID().toString();\n-                  fsDataOStream.write(uuid.getBytes(Charset.forName(\"UTF-8\")));\n-                  fsDataOStream.flush();\n-                } else {\n-                  uuid \u003d new String(b, Charset.forName(\"UTF-8\"));\n-                }\n-              } finally {\n-                IOUtils.cleanupWithLogger(LOG, fsDataInputStream);\n-              }\n-            }\n-            // if the remote log file exists, but we do not have any\n-            // indexedLogsMeta. We need to re-load indexedLogsMeta from\n-            // the existing remote log file. If the re-load fails, we simply\n-            // re-create a new indexedLogsMeta object. And will re-load\n-            // the indexedLogsMeta from checksum file later.\n-            if (indexedLogsMeta \u003d\u003d null) {\n-              try {\n-                indexedLogsMeta \u003d loadIndexedLogsMeta(remoteLogFile);\n-              } catch (IOException ex) {\n-                // DO NOTHING\n-              }\n-            }\n-          } else {\n-            fsDataOStream \u003d fc.create(remoteLogFile,\n-                EnumSet.of(CreateFlag.CREATE, CreateFlag.OVERWRITE),\n-                new Options.CreateOpts[] {});\n-            if (uuid \u003d\u003d null) {\n-              uuid \u003d UUID.randomUUID().toString();\n-            }\n-            byte[] b \u003d uuid.getBytes(Charset.forName(\"UTF-8\"));\n-            fsDataOStream.write(b);\n-            fsDataOStream.flush();\n-          }\n           if (indexedLogsMeta \u003d\u003d null) {\n             indexedLogsMeta \u003d new IndexedLogsMeta();\n             indexedLogsMeta.setVersion(VERSION);\n             indexedLogsMeta.setUser(userUgi.getShortUserName());\n             indexedLogsMeta.setAcls(appAcls);\n             indexedLogsMeta.setNodeId(nodeId);\n             String compressName \u003d conf.get(\n                 YarnConfiguration.NM_LOG_AGG_COMPRESSION_TYPE,\n                 YarnConfiguration.DEFAULT_NM_LOG_AGG_COMPRESSION_TYPE);\n             indexedLogsMeta.setCompressName(compressName);\n           }\n-          final long currentAggregatedLogFileLength \u003d fc\n-              .getFileStatus(remoteLogFile).getLen();\n-          // only check the check-sum file when we are in append mode\n+          Path aggregatedLogFile \u003d null;\n           if (context.isLogAggregationInRolling()) {\n-            // check whether the checksum file exists to figure out\n-            // whether the previous log aggregation process is successful\n-            // and the aggregated log file is corrupted or not.\n-            remoteLogCheckSumFile \u003d new Path(remoteLogFile.getParent(),\n-                (remoteLogFile.getName() + CHECK_SUM_FILE_SUFFIX));\n-            boolean exist \u003d fc.util().exists(remoteLogCheckSumFile);\n-            if (!exist) {\n-              FSDataOutputStream checksumFileOutputStream \u003d null;\n-              try {\n-                checksumFileOutputStream \u003d fc.create(remoteLogCheckSumFile,\n-                    EnumSet.of(CreateFlag.CREATE, CreateFlag.OVERWRITE),\n-                    new Options.CreateOpts[] {});\n-                checksumFileOutputStream.writeLong(\n-                    currentAggregatedLogFileLength);\n-              } finally {\n-                IOUtils.cleanupWithLogger(LOG, checksumFileOutputStream);\n-              }\n-            } else {\n-              FSDataInputStream checksumFileInputStream \u003d null;\n-              try {\n-                checksumFileInputStream \u003d fc.open(remoteLogCheckSumFile);\n-                long endIndex \u003d checksumFileInputStream.readLong();\n-                IndexedLogsMeta recoveredLogsMeta \u003d loadIndexedLogsMeta(\n-                    remoteLogFile, endIndex);\n-                if (recoveredLogsMeta \u003d\u003d null) {\n-                  indexedLogsMeta.getLogMetas().clear();\n-                } else {\n-                  indexedLogsMeta \u003d recoveredLogsMeta;\n-                }\n-              } finally {\n-                IOUtils.cleanupWithLogger(LOG, checksumFileInputStream);\n-              }\n+            aggregatedLogFile \u003d initializeWriterInRolling(\n+                remoteLogFile, appId, nodeId);\n+          } else {\n+            aggregatedLogFile \u003d remoteLogFile;\n+            fsDataOStream \u003d fc.create(remoteLogFile,\n+                EnumSet.of(CreateFlag.CREATE, CreateFlag.OVERWRITE),\n+                new Options.CreateOpts[] {});\n+            if (uuid \u003d\u003d null) {\n+              uuid \u003d createUUID(appId);\n             }\n+            fsDataOStream.write(uuid);\n+            fsDataOStream.flush();\n           }\n+\n+          long aggregatedLogFileLength \u003d fc.getFileStatus(\n+              aggregatedLogFile).getLen();\n           // append a simple character(\"\\n\") to move the writer cursor, so\n           // we could get the correct position when we call\n           // fsOutputStream.getStartPos()\n           final byte[] dummyBytes \u003d \"\\n\".getBytes(Charset.forName(\"UTF-8\"));\n           fsDataOStream.write(dummyBytes);\n           fsDataOStream.flush();\n \n-          if (fsDataOStream.getPos() \u003e\u003d (currentAggregatedLogFileLength\n+          if (fsDataOStream.getPos() \u003e\u003d (aggregatedLogFileLength\n               + dummyBytes.length)) {\n             currentOffSet \u003d 0;\n           } else {\n-            currentOffSet \u003d currentAggregatedLogFileLength;\n+            currentOffSet \u003d aggregatedLogFileLength;\n           }\n           return null;\n         }\n       });\n     } catch (Exception e) {\n       throw new IOException(e);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void initializeWriter(\n      final LogAggregationFileControllerContext context)\n      throws IOException {\n    final UserGroupInformation userUgi \u003d context.getUserUgi();\n    final Map\u003cApplicationAccessType, String\u003e appAcls \u003d context.getAppAcls();\n    final String nodeId \u003d context.getNodeId().toString();\n    final ApplicationId appId \u003d context.getAppId();\n    final Path remoteLogFile \u003d context.getRemoteNodeLogFileForApp();\n    this.ugi \u003d userUgi;\n    logAggregationSuccessfullyInThisCyCle \u003d false;\n    logsMetaInThisCycle \u003d new IndexedPerAggregationLogMeta();\n    logAggregationTimeInThisCycle \u003d this.sysClock.getTime();\n    logsMetaInThisCycle.setUploadTimeStamp(logAggregationTimeInThisCycle);\n    logsMetaInThisCycle.setRemoteNodeFile(remoteLogFile.getName());\n    try {\n      userUgi.doAs(new PrivilegedExceptionAction\u003cObject\u003e() {\n        @Override\n        public Object run() throws Exception {\n          fc \u003d FileContext.getFileContext(\n              remoteRootLogDir.toUri(), conf);\n          fc.setUMask(APP_LOG_FILE_UMASK);\n          if (indexedLogsMeta \u003d\u003d null) {\n            indexedLogsMeta \u003d new IndexedLogsMeta();\n            indexedLogsMeta.setVersion(VERSION);\n            indexedLogsMeta.setUser(userUgi.getShortUserName());\n            indexedLogsMeta.setAcls(appAcls);\n            indexedLogsMeta.setNodeId(nodeId);\n            String compressName \u003d conf.get(\n                YarnConfiguration.NM_LOG_AGG_COMPRESSION_TYPE,\n                YarnConfiguration.DEFAULT_NM_LOG_AGG_COMPRESSION_TYPE);\n            indexedLogsMeta.setCompressName(compressName);\n          }\n          Path aggregatedLogFile \u003d null;\n          if (context.isLogAggregationInRolling()) {\n            aggregatedLogFile \u003d initializeWriterInRolling(\n                remoteLogFile, appId, nodeId);\n          } else {\n            aggregatedLogFile \u003d remoteLogFile;\n            fsDataOStream \u003d fc.create(remoteLogFile,\n                EnumSet.of(CreateFlag.CREATE, CreateFlag.OVERWRITE),\n                new Options.CreateOpts[] {});\n            if (uuid \u003d\u003d null) {\n              uuid \u003d createUUID(appId);\n            }\n            fsDataOStream.write(uuid);\n            fsDataOStream.flush();\n          }\n\n          long aggregatedLogFileLength \u003d fc.getFileStatus(\n              aggregatedLogFile).getLen();\n          // append a simple character(\"\\n\") to move the writer cursor, so\n          // we could get the correct position when we call\n          // fsOutputStream.getStartPos()\n          final byte[] dummyBytes \u003d \"\\n\".getBytes(Charset.forName(\"UTF-8\"));\n          fsDataOStream.write(dummyBytes);\n          fsDataOStream.flush();\n\n          if (fsDataOStream.getPos() \u003e\u003d (aggregatedLogFileLength\n              + dummyBytes.length)) {\n            currentOffSet \u003d 0;\n          } else {\n            currentOffSet \u003d aggregatedLogFileLength;\n          }\n          return null;\n        }\n      });\n    } catch (Exception e) {\n      throw new IOException(e);\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/filecontroller/ifile/LogAggregationIndexedFileController.java",
      "extendedDetails": {}
    },
    "3fddabc2fe4fbdb8ef3f9ce7558955c4f0794dcc": {
      "type": "Yintroduced",
      "commitMessage": "YARN-7072. Add a new log aggregation file format controller. Contributed by Xuan Gong.\n",
      "commitDate": "08/09/17 3:16 PM",
      "commitName": "3fddabc2fe4fbdb8ef3f9ce7558955c4f0794dcc",
      "commitAuthor": "Junping Du",
      "diff": "@@ -0,0 +1,140 @@\n+  public void initializeWriter(\n+      final LogAggregationFileControllerContext context)\n+      throws IOException {\n+    final UserGroupInformation userUgi \u003d context.getUserUgi();\n+    final Map\u003cApplicationAccessType, String\u003e appAcls \u003d context.getAppAcls();\n+    final String nodeId \u003d context.getNodeId().toString();\n+    final Path remoteLogFile \u003d context.getRemoteNodeLogFileForApp();\n+    this.ugi \u003d userUgi;\n+    logAggregationSuccessfullyInThisCyCle \u003d false;\n+    logsMetaInThisCycle \u003d new IndexedPerAggregationLogMeta();\n+    logAggregationTimeInThisCycle \u003d System.currentTimeMillis();\n+    logsMetaInThisCycle.setUploadTimeStamp(logAggregationTimeInThisCycle);\n+    logsMetaInThisCycle.setRemoteNodeFile(remoteLogFile.getName());\n+    try {\n+      userUgi.doAs(new PrivilegedExceptionAction\u003cObject\u003e() {\n+        @Override\n+        public Object run() throws Exception {\n+          fc \u003d FileContext.getFileContext(\n+              remoteRootLogDir.toUri(), conf);\n+          fc.setUMask(APP_LOG_FILE_UMASK);\n+          boolean fileExist \u003d fc.util().exists(remoteLogFile);\n+          if (fileExist \u0026\u0026 context.isLogAggregationInRolling()) {\n+            fsDataOStream \u003d fc.create(remoteLogFile,\n+                EnumSet.of(CreateFlag.APPEND),\n+                new Options.CreateOpts[] {});\n+            if (uuid \u003d\u003d null) {\n+              FSDataInputStream fsDataInputStream \u003d null;\n+              try {\n+                fsDataInputStream \u003d fc.open(remoteLogFile);\n+                byte[] b \u003d new byte[UUID_LENGTH];\n+                int actual \u003d fsDataInputStream.read(b);\n+                if (actual !\u003d UUID_LENGTH) {\n+                  // Get an error when parse the UUID from existed log file.\n+                  // Simply OverWrite the existed log file and re-create the\n+                  // UUID.\n+                  fsDataOStream \u003d fc.create(remoteLogFile,\n+                      EnumSet.of(CreateFlag.OVERWRITE),\n+                          new Options.CreateOpts[] {});\n+                  uuid \u003d UUID.randomUUID().toString();\n+                  fsDataOStream.write(uuid.getBytes(Charset.forName(\"UTF-8\")));\n+                  fsDataOStream.flush();\n+                } else {\n+                  uuid \u003d new String(b, Charset.forName(\"UTF-8\"));\n+                }\n+              } finally {\n+                IOUtils.cleanupWithLogger(LOG, fsDataInputStream);\n+              }\n+            }\n+            // if the remote log file exists, but we do not have any\n+            // indexedLogsMeta. We need to re-load indexedLogsMeta from\n+            // the existing remote log file. If the re-load fails, we simply\n+            // re-create a new indexedLogsMeta object. And will re-load\n+            // the indexedLogsMeta from checksum file later.\n+            if (indexedLogsMeta \u003d\u003d null) {\n+              try {\n+                indexedLogsMeta \u003d loadIndexedLogsMeta(remoteLogFile);\n+              } catch (IOException ex) {\n+                // DO NOTHING\n+              }\n+            }\n+          } else {\n+            fsDataOStream \u003d fc.create(remoteLogFile,\n+                EnumSet.of(CreateFlag.CREATE, CreateFlag.OVERWRITE),\n+                new Options.CreateOpts[] {});\n+            if (uuid \u003d\u003d null) {\n+              uuid \u003d UUID.randomUUID().toString();\n+            }\n+            byte[] b \u003d uuid.getBytes(Charset.forName(\"UTF-8\"));\n+            fsDataOStream.write(b);\n+            fsDataOStream.flush();\n+          }\n+          if (indexedLogsMeta \u003d\u003d null) {\n+            indexedLogsMeta \u003d new IndexedLogsMeta();\n+            indexedLogsMeta.setVersion(VERSION);\n+            indexedLogsMeta.setUser(userUgi.getShortUserName());\n+            indexedLogsMeta.setAcls(appAcls);\n+            indexedLogsMeta.setNodeId(nodeId);\n+            String compressName \u003d conf.get(\n+                YarnConfiguration.NM_LOG_AGG_COMPRESSION_TYPE,\n+                YarnConfiguration.DEFAULT_NM_LOG_AGG_COMPRESSION_TYPE);\n+            indexedLogsMeta.setCompressName(compressName);\n+          }\n+          final long currentAggregatedLogFileLength \u003d fc\n+              .getFileStatus(remoteLogFile).getLen();\n+          // only check the check-sum file when we are in append mode\n+          if (context.isLogAggregationInRolling()) {\n+            // check whether the checksum file exists to figure out\n+            // whether the previous log aggregation process is successful\n+            // and the aggregated log file is corrupted or not.\n+            remoteLogCheckSumFile \u003d new Path(remoteLogFile.getParent(),\n+                (remoteLogFile.getName() + CHECK_SUM_FILE_SUFFIX));\n+            boolean exist \u003d fc.util().exists(remoteLogCheckSumFile);\n+            if (!exist) {\n+              FSDataOutputStream checksumFileOutputStream \u003d null;\n+              try {\n+                checksumFileOutputStream \u003d fc.create(remoteLogCheckSumFile,\n+                    EnumSet.of(CreateFlag.CREATE, CreateFlag.OVERWRITE),\n+                    new Options.CreateOpts[] {});\n+                checksumFileOutputStream.writeLong(\n+                    currentAggregatedLogFileLength);\n+              } finally {\n+                IOUtils.cleanupWithLogger(LOG, checksumFileOutputStream);\n+              }\n+            } else {\n+              FSDataInputStream checksumFileInputStream \u003d null;\n+              try {\n+                checksumFileInputStream \u003d fc.open(remoteLogCheckSumFile);\n+                long endIndex \u003d checksumFileInputStream.readLong();\n+                IndexedLogsMeta recoveredLogsMeta \u003d loadIndexedLogsMeta(\n+                    remoteLogFile, endIndex);\n+                if (recoveredLogsMeta \u003d\u003d null) {\n+                  indexedLogsMeta.getLogMetas().clear();\n+                } else {\n+                  indexedLogsMeta \u003d recoveredLogsMeta;\n+                }\n+              } finally {\n+                IOUtils.cleanupWithLogger(LOG, checksumFileInputStream);\n+              }\n+            }\n+          }\n+          // append a simple character(\"\\n\") to move the writer cursor, so\n+          // we could get the correct position when we call\n+          // fsOutputStream.getStartPos()\n+          final byte[] dummyBytes \u003d \"\\n\".getBytes(Charset.forName(\"UTF-8\"));\n+          fsDataOStream.write(dummyBytes);\n+          fsDataOStream.flush();\n+\n+          if (fsDataOStream.getPos() \u003e\u003d (currentAggregatedLogFileLength\n+              + dummyBytes.length)) {\n+            currentOffSet \u003d 0;\n+          } else {\n+            currentOffSet \u003d currentAggregatedLogFileLength;\n+          }\n+          return null;\n+        }\n+      });\n+    } catch (Exception e) {\n+      throw new IOException(e);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void initializeWriter(\n      final LogAggregationFileControllerContext context)\n      throws IOException {\n    final UserGroupInformation userUgi \u003d context.getUserUgi();\n    final Map\u003cApplicationAccessType, String\u003e appAcls \u003d context.getAppAcls();\n    final String nodeId \u003d context.getNodeId().toString();\n    final Path remoteLogFile \u003d context.getRemoteNodeLogFileForApp();\n    this.ugi \u003d userUgi;\n    logAggregationSuccessfullyInThisCyCle \u003d false;\n    logsMetaInThisCycle \u003d new IndexedPerAggregationLogMeta();\n    logAggregationTimeInThisCycle \u003d System.currentTimeMillis();\n    logsMetaInThisCycle.setUploadTimeStamp(logAggregationTimeInThisCycle);\n    logsMetaInThisCycle.setRemoteNodeFile(remoteLogFile.getName());\n    try {\n      userUgi.doAs(new PrivilegedExceptionAction\u003cObject\u003e() {\n        @Override\n        public Object run() throws Exception {\n          fc \u003d FileContext.getFileContext(\n              remoteRootLogDir.toUri(), conf);\n          fc.setUMask(APP_LOG_FILE_UMASK);\n          boolean fileExist \u003d fc.util().exists(remoteLogFile);\n          if (fileExist \u0026\u0026 context.isLogAggregationInRolling()) {\n            fsDataOStream \u003d fc.create(remoteLogFile,\n                EnumSet.of(CreateFlag.APPEND),\n                new Options.CreateOpts[] {});\n            if (uuid \u003d\u003d null) {\n              FSDataInputStream fsDataInputStream \u003d null;\n              try {\n                fsDataInputStream \u003d fc.open(remoteLogFile);\n                byte[] b \u003d new byte[UUID_LENGTH];\n                int actual \u003d fsDataInputStream.read(b);\n                if (actual !\u003d UUID_LENGTH) {\n                  // Get an error when parse the UUID from existed log file.\n                  // Simply OverWrite the existed log file and re-create the\n                  // UUID.\n                  fsDataOStream \u003d fc.create(remoteLogFile,\n                      EnumSet.of(CreateFlag.OVERWRITE),\n                          new Options.CreateOpts[] {});\n                  uuid \u003d UUID.randomUUID().toString();\n                  fsDataOStream.write(uuid.getBytes(Charset.forName(\"UTF-8\")));\n                  fsDataOStream.flush();\n                } else {\n                  uuid \u003d new String(b, Charset.forName(\"UTF-8\"));\n                }\n              } finally {\n                IOUtils.cleanupWithLogger(LOG, fsDataInputStream);\n              }\n            }\n            // if the remote log file exists, but we do not have any\n            // indexedLogsMeta. We need to re-load indexedLogsMeta from\n            // the existing remote log file. If the re-load fails, we simply\n            // re-create a new indexedLogsMeta object. And will re-load\n            // the indexedLogsMeta from checksum file later.\n            if (indexedLogsMeta \u003d\u003d null) {\n              try {\n                indexedLogsMeta \u003d loadIndexedLogsMeta(remoteLogFile);\n              } catch (IOException ex) {\n                // DO NOTHING\n              }\n            }\n          } else {\n            fsDataOStream \u003d fc.create(remoteLogFile,\n                EnumSet.of(CreateFlag.CREATE, CreateFlag.OVERWRITE),\n                new Options.CreateOpts[] {});\n            if (uuid \u003d\u003d null) {\n              uuid \u003d UUID.randomUUID().toString();\n            }\n            byte[] b \u003d uuid.getBytes(Charset.forName(\"UTF-8\"));\n            fsDataOStream.write(b);\n            fsDataOStream.flush();\n          }\n          if (indexedLogsMeta \u003d\u003d null) {\n            indexedLogsMeta \u003d new IndexedLogsMeta();\n            indexedLogsMeta.setVersion(VERSION);\n            indexedLogsMeta.setUser(userUgi.getShortUserName());\n            indexedLogsMeta.setAcls(appAcls);\n            indexedLogsMeta.setNodeId(nodeId);\n            String compressName \u003d conf.get(\n                YarnConfiguration.NM_LOG_AGG_COMPRESSION_TYPE,\n                YarnConfiguration.DEFAULT_NM_LOG_AGG_COMPRESSION_TYPE);\n            indexedLogsMeta.setCompressName(compressName);\n          }\n          final long currentAggregatedLogFileLength \u003d fc\n              .getFileStatus(remoteLogFile).getLen();\n          // only check the check-sum file when we are in append mode\n          if (context.isLogAggregationInRolling()) {\n            // check whether the checksum file exists to figure out\n            // whether the previous log aggregation process is successful\n            // and the aggregated log file is corrupted or not.\n            remoteLogCheckSumFile \u003d new Path(remoteLogFile.getParent(),\n                (remoteLogFile.getName() + CHECK_SUM_FILE_SUFFIX));\n            boolean exist \u003d fc.util().exists(remoteLogCheckSumFile);\n            if (!exist) {\n              FSDataOutputStream checksumFileOutputStream \u003d null;\n              try {\n                checksumFileOutputStream \u003d fc.create(remoteLogCheckSumFile,\n                    EnumSet.of(CreateFlag.CREATE, CreateFlag.OVERWRITE),\n                    new Options.CreateOpts[] {});\n                checksumFileOutputStream.writeLong(\n                    currentAggregatedLogFileLength);\n              } finally {\n                IOUtils.cleanupWithLogger(LOG, checksumFileOutputStream);\n              }\n            } else {\n              FSDataInputStream checksumFileInputStream \u003d null;\n              try {\n                checksumFileInputStream \u003d fc.open(remoteLogCheckSumFile);\n                long endIndex \u003d checksumFileInputStream.readLong();\n                IndexedLogsMeta recoveredLogsMeta \u003d loadIndexedLogsMeta(\n                    remoteLogFile, endIndex);\n                if (recoveredLogsMeta \u003d\u003d null) {\n                  indexedLogsMeta.getLogMetas().clear();\n                } else {\n                  indexedLogsMeta \u003d recoveredLogsMeta;\n                }\n              } finally {\n                IOUtils.cleanupWithLogger(LOG, checksumFileInputStream);\n              }\n            }\n          }\n          // append a simple character(\"\\n\") to move the writer cursor, so\n          // we could get the correct position when we call\n          // fsOutputStream.getStartPos()\n          final byte[] dummyBytes \u003d \"\\n\".getBytes(Charset.forName(\"UTF-8\"));\n          fsDataOStream.write(dummyBytes);\n          fsDataOStream.flush();\n\n          if (fsDataOStream.getPos() \u003e\u003d (currentAggregatedLogFileLength\n              + dummyBytes.length)) {\n            currentOffSet \u003d 0;\n          } else {\n            currentOffSet \u003d currentAggregatedLogFileLength;\n          }\n          return null;\n        }\n      });\n    } catch (Exception e) {\n      throw new IOException(e);\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/filecontroller/ifile/LogAggregationIndexedFileController.java"
    }
  }
}