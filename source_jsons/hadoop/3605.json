{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DFSInputStream.java",
  "functionName": "getBestNodeDNAddrPairErrorString",
  "functionId": "getBestNodeDNAddrPairErrorString___nodes-DatanodeInfo[]__deadNodes-AbstractMap__DatanodeInfo,DatanodeInfo____ignoredNodes-Collection__DatanodeInfo__",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
  "functionStartLine": 1113,
  "functionEndLine": 1136,
  "numCommitsSeen": 136,
  "timeTaken": 3540,
  "changeHistory": [
    "fb8932a727f757b2e9c1c61a18145878d0eb77bd",
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c",
    "17db74a1c1972392a5aba48a3e0334dcd6c76487"
  ],
  "changeHistoryShort": {
    "fb8932a727f757b2e9c1c61a18145878d0eb77bd": "Ybodychange",
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c": "Yfilerename",
    "17db74a1c1972392a5aba48a3e0334dcd6c76487": "Yintroduced"
  },
  "changeHistoryDetails": {
    "fb8932a727f757b2e9c1c61a18145878d0eb77bd": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-16029. Consecutive StringBuilder.append can be reused. Contributed by Ayush Saxena.\n",
      "commitDate": "11/01/19 10:54 AM",
      "commitName": "fb8932a727f757b2e9c1c61a18145878d0eb77bd",
      "commitAuthor": "Giovanni Matteo Fumarola",
      "commitDateOld": "08/10/18 8:31 PM",
      "commitNameOld": "08bb6c49a5aec32b7d9f29238560f947420405d6",
      "commitAuthorOld": "Hrishikesh Gadre",
      "daysBetweenCommits": 94.64,
      "commitsBetweenForRepo": 719,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,24 @@\n   private static String getBestNodeDNAddrPairErrorString(\n       DatanodeInfo nodes[], AbstractMap\u003cDatanodeInfo,\n       DatanodeInfo\u003e deadNodes, Collection\u003cDatanodeInfo\u003e ignoredNodes) {\n     StringBuilder errMsgr \u003d new StringBuilder(\n         \" No live nodes contain current block \");\n     errMsgr.append(\"Block locations:\");\n     for (DatanodeInfo datanode : nodes) {\n-      errMsgr.append(\" \");\n-      errMsgr.append(datanode.toString());\n+      errMsgr.append(\" \")\n+          .append(datanode.toString());\n     }\n     errMsgr.append(\" Dead nodes: \");\n     for (DatanodeInfo datanode : deadNodes.keySet()) {\n-      errMsgr.append(\" \");\n-      errMsgr.append(datanode.toString());\n+      errMsgr.append(\" \")\n+          .append(datanode.toString());\n     }\n     if (ignoredNodes !\u003d null) {\n       errMsgr.append(\" Ignored nodes: \");\n       for (DatanodeInfo datanode : ignoredNodes) {\n-        errMsgr.append(\" \");\n-        errMsgr.append(datanode.toString());\n+        errMsgr.append(\" \")\n+            .append(datanode.toString());\n       }\n     }\n     return errMsgr.toString();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private static String getBestNodeDNAddrPairErrorString(\n      DatanodeInfo nodes[], AbstractMap\u003cDatanodeInfo,\n      DatanodeInfo\u003e deadNodes, Collection\u003cDatanodeInfo\u003e ignoredNodes) {\n    StringBuilder errMsgr \u003d new StringBuilder(\n        \" No live nodes contain current block \");\n    errMsgr.append(\"Block locations:\");\n    for (DatanodeInfo datanode : nodes) {\n      errMsgr.append(\" \")\n          .append(datanode.toString());\n    }\n    errMsgr.append(\" Dead nodes: \");\n    for (DatanodeInfo datanode : deadNodes.keySet()) {\n      errMsgr.append(\" \")\n          .append(datanode.toString());\n    }\n    if (ignoredNodes !\u003d null) {\n      errMsgr.append(\" Ignored nodes: \");\n      for (DatanodeInfo datanode : ignoredNodes) {\n        errMsgr.append(\" \")\n            .append(datanode.toString());\n      }\n    }\n    return errMsgr.toString();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8053. Move DFSIn/OutputStream and related classes to hadoop-hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "26/09/15 11:08 AM",
      "commitName": "bf37d3d80e5179dea27e5bd5aea804a38aa9934c",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "26/09/15 9:06 AM",
      "commitNameOld": "861b52db242f238d7e36ad75c158025be959a696",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 0.08,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private static String getBestNodeDNAddrPairErrorString(\n      DatanodeInfo nodes[], AbstractMap\u003cDatanodeInfo,\n      DatanodeInfo\u003e deadNodes, Collection\u003cDatanodeInfo\u003e ignoredNodes) {\n    StringBuilder errMsgr \u003d new StringBuilder(\n        \" No live nodes contain current block \");\n    errMsgr.append(\"Block locations:\");\n    for (DatanodeInfo datanode : nodes) {\n      errMsgr.append(\" \");\n      errMsgr.append(datanode.toString());\n    }\n    errMsgr.append(\" Dead nodes: \");\n    for (DatanodeInfo datanode : deadNodes.keySet()) {\n      errMsgr.append(\" \");\n      errMsgr.append(datanode.toString());\n    }\n    if (ignoredNodes !\u003d null) {\n      errMsgr.append(\" Ignored nodes: \");\n      for (DatanodeInfo datanode : ignoredNodes) {\n        errMsgr.append(\" \");\n        errMsgr.append(datanode.toString());\n      }\n    }\n    return errMsgr.toString();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java"
      }
    },
    "17db74a1c1972392a5aba48a3e0334dcd6c76487": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-5776 Support \u0027hedged\u0027 reads in DFSClient\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1571466 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/02/14 2:34 PM",
      "commitName": "17db74a1c1972392a5aba48a3e0334dcd6c76487",
      "commitAuthor": "Michael Stack",
      "diff": "@@ -0,0 +1,24 @@\n+  private static String getBestNodeDNAddrPairErrorString(\n+      DatanodeInfo nodes[], AbstractMap\u003cDatanodeInfo,\n+      DatanodeInfo\u003e deadNodes, Collection\u003cDatanodeInfo\u003e ignoredNodes) {\n+    StringBuilder errMsgr \u003d new StringBuilder(\n+        \" No live nodes contain current block \");\n+    errMsgr.append(\"Block locations:\");\n+    for (DatanodeInfo datanode : nodes) {\n+      errMsgr.append(\" \");\n+      errMsgr.append(datanode.toString());\n+    }\n+    errMsgr.append(\" Dead nodes: \");\n+    for (DatanodeInfo datanode : deadNodes.keySet()) {\n+      errMsgr.append(\" \");\n+      errMsgr.append(datanode.toString());\n+    }\n+    if (ignoredNodes !\u003d null) {\n+      errMsgr.append(\" Ignored nodes: \");\n+      for (DatanodeInfo datanode : ignoredNodes) {\n+        errMsgr.append(\" \");\n+        errMsgr.append(datanode.toString());\n+      }\n+    }\n+    return errMsgr.toString();\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private static String getBestNodeDNAddrPairErrorString(\n      DatanodeInfo nodes[], AbstractMap\u003cDatanodeInfo,\n      DatanodeInfo\u003e deadNodes, Collection\u003cDatanodeInfo\u003e ignoredNodes) {\n    StringBuilder errMsgr \u003d new StringBuilder(\n        \" No live nodes contain current block \");\n    errMsgr.append(\"Block locations:\");\n    for (DatanodeInfo datanode : nodes) {\n      errMsgr.append(\" \");\n      errMsgr.append(datanode.toString());\n    }\n    errMsgr.append(\" Dead nodes: \");\n    for (DatanodeInfo datanode : deadNodes.keySet()) {\n      errMsgr.append(\" \");\n      errMsgr.append(datanode.toString());\n    }\n    if (ignoredNodes !\u003d null) {\n      errMsgr.append(\" Ignored nodes: \");\n      for (DatanodeInfo datanode : ignoredNodes) {\n        errMsgr.append(\" \");\n        errMsgr.append(datanode.toString());\n      }\n    }\n    return errMsgr.toString();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java"
    }
  }
}