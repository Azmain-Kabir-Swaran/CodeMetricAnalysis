{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockReaderLocal.java",
  "functionName": "getClientMmap",
  "functionId": "getClientMmap___opts-EnumSet__ReadOption__",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/client/impl/BlockReaderLocal.java",
  "functionStartLine": 677,
  "functionEndLine": 697,
  "numCommitsSeen": 93,
  "timeTaken": 4153,
  "changeHistory": [
    "f308561f1d885491b88db73ac63003202056d661",
    "7136e8c5582dc4061b566cb9f11a0d6a6d08bb93",
    "39285e6a1978ea5e53bdc1b0aef62421382124a8",
    "6ee0539ede78b640f01c5eac18ded161182a7835",
    "d5a9a3daa0224249221ffa7b8bd5751ab2feca56",
    "e2c9b288b223b9fd82dc12018936e13128413492",
    "dd049a2f6097da189ccce2f5890a2b9bc77fa73f",
    "beb0d25d2a7ba5004c6aabd105546ba9a9fec9be",
    "124e507674c0d396f8494585e64226957199097b",
    "eccdb9aa8bcdee750583d16a1253f1c5faabd036"
  ],
  "changeHistoryShort": {
    "f308561f1d885491b88db73ac63003202056d661": "Yfilerename",
    "7136e8c5582dc4061b566cb9f11a0d6a6d08bb93": "Ybodychange",
    "39285e6a1978ea5e53bdc1b0aef62421382124a8": "Ybodychange",
    "6ee0539ede78b640f01c5eac18ded161182a7835": "Ybodychange",
    "d5a9a3daa0224249221ffa7b8bd5751ab2feca56": "Ybodychange",
    "e2c9b288b223b9fd82dc12018936e13128413492": "Yfilerename",
    "dd049a2f6097da189ccce2f5890a2b9bc77fa73f": "Ybodychange",
    "beb0d25d2a7ba5004c6aabd105546ba9a9fec9be": "Ymultichange(Yparameterchange,Ymodifierchange,Ybodychange)",
    "124e507674c0d396f8494585e64226957199097b": "Ymultichange(Yparameterchange,Ymodifierchange,Ybodychange)",
    "eccdb9aa8bcdee750583d16a1253f1c5faabd036": "Yintroduced"
  },
  "changeHistoryDetails": {
    "f308561f1d885491b88db73ac63003202056d661": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8057 Move BlockReader implementation to the client implementation package.  Contributed by Takanobu Asanuma\n",
      "commitDate": "25/04/16 12:01 PM",
      "commitName": "f308561f1d885491b88db73ac63003202056d661",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "25/04/16 9:38 AM",
      "commitNameOld": "10f0f7851a3255caab775777e8fb6c2781d97062",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 0.1,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public ClientMmap getClientMmap(EnumSet\u003cReadOption\u003e opts) {\n    boolean anchor \u003d verifyChecksum \u0026\u0026\n        !opts.contains(ReadOption.SKIP_CHECKSUMS);\n    if (anchor) {\n      if (!createNoChecksumContext()) {\n        LOG.trace(\"can\u0027t get an mmap for {} of {} since SKIP_CHECKSUMS was not \"\n            + \"given, we aren\u0027t skipping checksums, and the block is not \"\n            + \"mlocked.\", block, filename);\n        return null;\n      }\n    }\n    ClientMmap clientMmap \u003d null;\n    try {\n      clientMmap \u003d replica.getOrCreateClientMmap(anchor);\n    } finally {\n      if ((clientMmap \u003d\u003d null) \u0026\u0026 anchor) {\n        releaseNoChecksumContext();\n      }\n    }\n    return clientMmap;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/client/impl/BlockReaderLocal.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocal.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/client/impl/BlockReaderLocal.java"
      }
    },
    "7136e8c5582dc4061b566cb9f11a0d6a6d08bb93": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8979. Clean up checkstyle warnings in hadoop-hdfs-client module. Contributed by Mingliang Liu.\n",
      "commitDate": "03/10/15 11:38 AM",
      "commitName": "7136e8c5582dc4061b566cb9f11a0d6a6d08bb93",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "30/09/15 8:39 AM",
      "commitNameOld": "6c17d315287020368689fa078a40a1eaedf89d5b",
      "commitAuthorOld": "",
      "daysBetweenCommits": 3.12,
      "commitsBetweenForRepo": 16,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,21 @@\n   public ClientMmap getClientMmap(EnumSet\u003cReadOption\u003e opts) {\n     boolean anchor \u003d verifyChecksum \u0026\u0026\n-        (opts.contains(ReadOption.SKIP_CHECKSUMS) \u003d\u003d false);\n+        !opts.contains(ReadOption.SKIP_CHECKSUMS);\n     if (anchor) {\n       if (!createNoChecksumContext()) {\n         LOG.trace(\"can\u0027t get an mmap for {} of {} since SKIP_CHECKSUMS was not \"\n             + \"given, we aren\u0027t skipping checksums, and the block is not \"\n             + \"mlocked.\", block, filename);\n         return null;\n       }\n     }\n     ClientMmap clientMmap \u003d null;\n     try {\n       clientMmap \u003d replica.getOrCreateClientMmap(anchor);\n     } finally {\n       if ((clientMmap \u003d\u003d null) \u0026\u0026 anchor) {\n         releaseNoChecksumContext();\n       }\n     }\n     return clientMmap;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ClientMmap getClientMmap(EnumSet\u003cReadOption\u003e opts) {\n    boolean anchor \u003d verifyChecksum \u0026\u0026\n        !opts.contains(ReadOption.SKIP_CHECKSUMS);\n    if (anchor) {\n      if (!createNoChecksumContext()) {\n        LOG.trace(\"can\u0027t get an mmap for {} of {} since SKIP_CHECKSUMS was not \"\n            + \"given, we aren\u0027t skipping checksums, and the block is not \"\n            + \"mlocked.\", block, filename);\n        return null;\n      }\n    }\n    ClientMmap clientMmap \u003d null;\n    try {\n      clientMmap \u003d replica.getOrCreateClientMmap(anchor);\n    } finally {\n      if ((clientMmap \u003d\u003d null) \u0026\u0026 anchor) {\n        releaseNoChecksumContext();\n      }\n    }\n    return clientMmap;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocal.java",
      "extendedDetails": {}
    },
    "39285e6a1978ea5e53bdc1b0aef62421382124a8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8971. Remove guards when calling LOG.debug() and LOG.trace() in client package. Contributed by Mingliang Liu.\n",
      "commitDate": "29/09/15 5:52 PM",
      "commitName": "39285e6a1978ea5e53bdc1b0aef62421382124a8",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "29/09/15 5:51 PM",
      "commitNameOld": "6ee0539ede78b640f01c5eac18ded161182a7835",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,21 @@\n   public ClientMmap getClientMmap(EnumSet\u003cReadOption\u003e opts) {\n     boolean anchor \u003d verifyChecksum \u0026\u0026\n         (opts.contains(ReadOption.SKIP_CHECKSUMS) \u003d\u003d false);\n     if (anchor) {\n       if (!createNoChecksumContext()) {\n-        if (LOG.isTraceEnabled()) {\n-          LOG.trace(\"can\u0027t get an mmap for \" + block + \" of \" + filename + \n-              \" since SKIP_CHECKSUMS was not given, \" +\n-              \"we aren\u0027t skipping checksums, and the block is not mlocked.\");\n-        }\n+        LOG.trace(\"can\u0027t get an mmap for {} of {} since SKIP_CHECKSUMS was not \"\n+            + \"given, we aren\u0027t skipping checksums, and the block is not \"\n+            + \"mlocked.\", block, filename);\n         return null;\n       }\n     }\n     ClientMmap clientMmap \u003d null;\n     try {\n       clientMmap \u003d replica.getOrCreateClientMmap(anchor);\n     } finally {\n       if ((clientMmap \u003d\u003d null) \u0026\u0026 anchor) {\n         releaseNoChecksumContext();\n       }\n     }\n     return clientMmap;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ClientMmap getClientMmap(EnumSet\u003cReadOption\u003e opts) {\n    boolean anchor \u003d verifyChecksum \u0026\u0026\n        (opts.contains(ReadOption.SKIP_CHECKSUMS) \u003d\u003d false);\n    if (anchor) {\n      if (!createNoChecksumContext()) {\n        LOG.trace(\"can\u0027t get an mmap for {} of {} since SKIP_CHECKSUMS was not \"\n            + \"given, we aren\u0027t skipping checksums, and the block is not \"\n            + \"mlocked.\", block, filename);\n        return null;\n      }\n    }\n    ClientMmap clientMmap \u003d null;\n    try {\n      clientMmap \u003d replica.getOrCreateClientMmap(anchor);\n    } finally {\n      if ((clientMmap \u003d\u003d null) \u0026\u0026 anchor) {\n        releaseNoChecksumContext();\n      }\n    }\n    return clientMmap;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocal.java",
      "extendedDetails": {}
    },
    "6ee0539ede78b640f01c5eac18ded161182a7835": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-9170. Move libhdfs / fuse-dfs / libwebhdfs to hdfs-client. Contributed by Haohui Mai.\"\n\nThis reverts commit d5a9a3daa0224249221ffa7b8bd5751ab2feca56.\n",
      "commitDate": "29/09/15 5:51 PM",
      "commitName": "6ee0539ede78b640f01c5eac18ded161182a7835",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "29/09/15 5:48 PM",
      "commitNameOld": "d5a9a3daa0224249221ffa7b8bd5751ab2feca56",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,23 @@\n   public ClientMmap getClientMmap(EnumSet\u003cReadOption\u003e opts) {\n     boolean anchor \u003d verifyChecksum \u0026\u0026\n         (opts.contains(ReadOption.SKIP_CHECKSUMS) \u003d\u003d false);\n     if (anchor) {\n       if (!createNoChecksumContext()) {\n-        LOG.trace(\"can\u0027t get an mmap for {} of {} since SKIP_CHECKSUMS was not \"\n-            + \"given, we aren\u0027t skipping checksums, and the block is not \"\n-            + \"mlocked.\", block, filename);\n+        if (LOG.isTraceEnabled()) {\n+          LOG.trace(\"can\u0027t get an mmap for \" + block + \" of \" + filename + \n+              \" since SKIP_CHECKSUMS was not given, \" +\n+              \"we aren\u0027t skipping checksums, and the block is not mlocked.\");\n+        }\n         return null;\n       }\n     }\n     ClientMmap clientMmap \u003d null;\n     try {\n       clientMmap \u003d replica.getOrCreateClientMmap(anchor);\n     } finally {\n       if ((clientMmap \u003d\u003d null) \u0026\u0026 anchor) {\n         releaseNoChecksumContext();\n       }\n     }\n     return clientMmap;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ClientMmap getClientMmap(EnumSet\u003cReadOption\u003e opts) {\n    boolean anchor \u003d verifyChecksum \u0026\u0026\n        (opts.contains(ReadOption.SKIP_CHECKSUMS) \u003d\u003d false);\n    if (anchor) {\n      if (!createNoChecksumContext()) {\n        if (LOG.isTraceEnabled()) {\n          LOG.trace(\"can\u0027t get an mmap for \" + block + \" of \" + filename + \n              \" since SKIP_CHECKSUMS was not given, \" +\n              \"we aren\u0027t skipping checksums, and the block is not mlocked.\");\n        }\n        return null;\n      }\n    }\n    ClientMmap clientMmap \u003d null;\n    try {\n      clientMmap \u003d replica.getOrCreateClientMmap(anchor);\n    } finally {\n      if ((clientMmap \u003d\u003d null) \u0026\u0026 anchor) {\n        releaseNoChecksumContext();\n      }\n    }\n    return clientMmap;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocal.java",
      "extendedDetails": {}
    },
    "d5a9a3daa0224249221ffa7b8bd5751ab2feca56": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9170. Move libhdfs / fuse-dfs / libwebhdfs to hdfs-client. Contributed by Haohui Mai.\n",
      "commitDate": "29/09/15 5:48 PM",
      "commitName": "d5a9a3daa0224249221ffa7b8bd5751ab2feca56",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "28/09/15 7:42 AM",
      "commitNameOld": "892ade689f9bcce76daae8f66fc00a49bee8548e",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 1.42,
      "commitsBetweenForRepo": 19,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,21 @@\n   public ClientMmap getClientMmap(EnumSet\u003cReadOption\u003e opts) {\n     boolean anchor \u003d verifyChecksum \u0026\u0026\n         (opts.contains(ReadOption.SKIP_CHECKSUMS) \u003d\u003d false);\n     if (anchor) {\n       if (!createNoChecksumContext()) {\n-        if (LOG.isTraceEnabled()) {\n-          LOG.trace(\"can\u0027t get an mmap for \" + block + \" of \" + filename + \n-              \" since SKIP_CHECKSUMS was not given, \" +\n-              \"we aren\u0027t skipping checksums, and the block is not mlocked.\");\n-        }\n+        LOG.trace(\"can\u0027t get an mmap for {} of {} since SKIP_CHECKSUMS was not \"\n+            + \"given, we aren\u0027t skipping checksums, and the block is not \"\n+            + \"mlocked.\", block, filename);\n         return null;\n       }\n     }\n     ClientMmap clientMmap \u003d null;\n     try {\n       clientMmap \u003d replica.getOrCreateClientMmap(anchor);\n     } finally {\n       if ((clientMmap \u003d\u003d null) \u0026\u0026 anchor) {\n         releaseNoChecksumContext();\n       }\n     }\n     return clientMmap;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ClientMmap getClientMmap(EnumSet\u003cReadOption\u003e opts) {\n    boolean anchor \u003d verifyChecksum \u0026\u0026\n        (opts.contains(ReadOption.SKIP_CHECKSUMS) \u003d\u003d false);\n    if (anchor) {\n      if (!createNoChecksumContext()) {\n        LOG.trace(\"can\u0027t get an mmap for {} of {} since SKIP_CHECKSUMS was not \"\n            + \"given, we aren\u0027t skipping checksums, and the block is not \"\n            + \"mlocked.\", block, filename);\n        return null;\n      }\n    }\n    ClientMmap clientMmap \u003d null;\n    try {\n      clientMmap \u003d replica.getOrCreateClientMmap(anchor);\n    } finally {\n      if ((clientMmap \u003d\u003d null) \u0026\u0026 anchor) {\n        releaseNoChecksumContext();\n      }\n    }\n    return clientMmap;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocal.java",
      "extendedDetails": {}
    },
    "e2c9b288b223b9fd82dc12018936e13128413492": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8925. Move BlockReaderLocal to hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "28/08/15 2:38 PM",
      "commitName": "e2c9b288b223b9fd82dc12018936e13128413492",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "28/08/15 2:21 PM",
      "commitNameOld": "b94b56806d3d6e04984e229b479f7ac15b62bbfa",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public ClientMmap getClientMmap(EnumSet\u003cReadOption\u003e opts) {\n    boolean anchor \u003d verifyChecksum \u0026\u0026\n        (opts.contains(ReadOption.SKIP_CHECKSUMS) \u003d\u003d false);\n    if (anchor) {\n      if (!createNoChecksumContext()) {\n        if (LOG.isTraceEnabled()) {\n          LOG.trace(\"can\u0027t get an mmap for \" + block + \" of \" + filename + \n              \" since SKIP_CHECKSUMS was not given, \" +\n              \"we aren\u0027t skipping checksums, and the block is not mlocked.\");\n        }\n        return null;\n      }\n    }\n    ClientMmap clientMmap \u003d null;\n    try {\n      clientMmap \u003d replica.getOrCreateClientMmap(anchor);\n    } finally {\n      if ((clientMmap \u003d\u003d null) \u0026\u0026 anchor) {\n        releaseNoChecksumContext();\n      }\n    }\n    return clientMmap;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocal.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocal.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocal.java"
      }
    },
    "dd049a2f6097da189ccce2f5890a2b9bc77fa73f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5950. The DFSClient and DataNode should use shared memory segments to communicate short-circuit information (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1573433 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/03/14 7:58 PM",
      "commitName": "dd049a2f6097da189ccce2f5890a2b9bc77fa73f",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "12/02/14 11:08 AM",
      "commitNameOld": "beb0d25d2a7ba5004c6aabd105546ba9a9fec9be",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 18.37,
      "commitsBetweenForRepo": 140,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,23 @@\n   public ClientMmap getClientMmap(EnumSet\u003cReadOption\u003e opts) {\n-    if ((!opts.contains(ReadOption.SKIP_CHECKSUMS)) \u0026\u0026\n-          verifyChecksum \u0026\u0026 (!mlocked.get())) {\n-      if (LOG.isTraceEnabled()) {\n-        LOG.trace(\"can\u0027t get an mmap for \" + block + \" of \" + filename + \n-            \" since SKIP_CHECKSUMS was not given, \" +\n-            \"we aren\u0027t skipping checksums, and the block is not mlocked.\");\n+    boolean anchor \u003d verifyChecksum \u0026\u0026\n+        (opts.contains(ReadOption.SKIP_CHECKSUMS) \u003d\u003d false);\n+    if (anchor) {\n+      if (!createNoChecksumContext()) {\n+        if (LOG.isTraceEnabled()) {\n+          LOG.trace(\"can\u0027t get an mmap for \" + block + \" of \" + filename + \n+              \" since SKIP_CHECKSUMS was not given, \" +\n+              \"we aren\u0027t skipping checksums, and the block is not mlocked.\");\n+        }\n+        return null;\n       }\n-      return null;\n     }\n-    return replica.getOrCreateClientMmap();\n+    ClientMmap clientMmap \u003d null;\n+    try {\n+      clientMmap \u003d replica.getOrCreateClientMmap(anchor);\n+    } finally {\n+      if ((clientMmap \u003d\u003d null) \u0026\u0026 anchor) {\n+        releaseNoChecksumContext();\n+      }\n+    }\n+    return clientMmap;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ClientMmap getClientMmap(EnumSet\u003cReadOption\u003e opts) {\n    boolean anchor \u003d verifyChecksum \u0026\u0026\n        (opts.contains(ReadOption.SKIP_CHECKSUMS) \u003d\u003d false);\n    if (anchor) {\n      if (!createNoChecksumContext()) {\n        if (LOG.isTraceEnabled()) {\n          LOG.trace(\"can\u0027t get an mmap for \" + block + \" of \" + filename + \n              \" since SKIP_CHECKSUMS was not given, \" +\n              \"we aren\u0027t skipping checksums, and the block is not mlocked.\");\n        }\n        return null;\n      }\n    }\n    ClientMmap clientMmap \u003d null;\n    try {\n      clientMmap \u003d replica.getOrCreateClientMmap(anchor);\n    } finally {\n      if ((clientMmap \u003d\u003d null) \u0026\u0026 anchor) {\n        releaseNoChecksumContext();\n      }\n    }\n    return clientMmap;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocal.java",
      "extendedDetails": {}
    },
    "beb0d25d2a7ba5004c6aabd105546ba9a9fec9be": {
      "type": "Ymultichange(Yparameterchange,Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-5810. Unify mmap cache and short-circuit file descriptor cache (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1567720 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/02/14 11:08 AM",
      "commitName": "beb0d25d2a7ba5004c6aabd105546ba9a9fec9be",
      "commitAuthor": "Colin McCabe",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-5810. Unify mmap cache and short-circuit file descriptor cache (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1567720 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "12/02/14 11:08 AM",
          "commitName": "beb0d25d2a7ba5004c6aabd105546ba9a9fec9be",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "15/01/14 11:17 AM",
          "commitNameOld": "037a89abc5cc5ea6b983b21c568a50bc729aa194",
          "commitAuthorOld": "Colin McCabe",
          "daysBetweenCommits": 27.99,
          "commitsBetweenForRepo": 191,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,33 +1,12 @@\n-  public synchronized ClientMmap getClientMmap(EnumSet\u003cReadOption\u003e opts,\n-        ClientMmapManager mmapManager) {\n+  public ClientMmap getClientMmap(EnumSet\u003cReadOption\u003e opts) {\n     if ((!opts.contains(ReadOption.SKIP_CHECKSUMS)) \u0026\u0026\n           verifyChecksum \u0026\u0026 (!mlocked.get())) {\n       if (LOG.isTraceEnabled()) {\n         LOG.trace(\"can\u0027t get an mmap for \" + block + \" of \" + filename + \n             \" since SKIP_CHECKSUMS was not given, \" +\n             \"we aren\u0027t skipping checksums, and the block is not mlocked.\");\n       }\n       return null;\n     }\n-    if (clientMmap \u003d\u003d null) {\n-      if (mmapDisabled) {\n-        return null;\n-      }\n-      try {\n-        clientMmap \u003d mmapManager.fetch(datanodeID, block, streams[0]);\n-        if (clientMmap \u003d\u003d null) {\n-          mmapDisabled \u003d true;\n-          return null;\n-        }\n-      } catch (InterruptedException e) {\n-        LOG.error(\"Interrupted while setting up mmap for \" + filename, e);\n-        Thread.currentThread().interrupt();\n-        return null;\n-      } catch (IOException e) {\n-        LOG.error(\"unable to set up mmap for \" + filename, e);\n-        mmapDisabled \u003d true;\n-        return null;\n-      }\n-    }\n-    return clientMmap;\n+    return replica.getOrCreateClientMmap();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public ClientMmap getClientMmap(EnumSet\u003cReadOption\u003e opts) {\n    if ((!opts.contains(ReadOption.SKIP_CHECKSUMS)) \u0026\u0026\n          verifyChecksum \u0026\u0026 (!mlocked.get())) {\n      if (LOG.isTraceEnabled()) {\n        LOG.trace(\"can\u0027t get an mmap for \" + block + \" of \" + filename + \n            \" since SKIP_CHECKSUMS was not given, \" +\n            \"we aren\u0027t skipping checksums, and the block is not mlocked.\");\n      }\n      return null;\n    }\n    return replica.getOrCreateClientMmap();\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocal.java",
          "extendedDetails": {
            "oldValue": "[opts-EnumSet\u003cReadOption\u003e, mmapManager-ClientMmapManager]",
            "newValue": "[opts-EnumSet\u003cReadOption\u003e]"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-5810. Unify mmap cache and short-circuit file descriptor cache (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1567720 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "12/02/14 11:08 AM",
          "commitName": "beb0d25d2a7ba5004c6aabd105546ba9a9fec9be",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "15/01/14 11:17 AM",
          "commitNameOld": "037a89abc5cc5ea6b983b21c568a50bc729aa194",
          "commitAuthorOld": "Colin McCabe",
          "daysBetweenCommits": 27.99,
          "commitsBetweenForRepo": 191,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,33 +1,12 @@\n-  public synchronized ClientMmap getClientMmap(EnumSet\u003cReadOption\u003e opts,\n-        ClientMmapManager mmapManager) {\n+  public ClientMmap getClientMmap(EnumSet\u003cReadOption\u003e opts) {\n     if ((!opts.contains(ReadOption.SKIP_CHECKSUMS)) \u0026\u0026\n           verifyChecksum \u0026\u0026 (!mlocked.get())) {\n       if (LOG.isTraceEnabled()) {\n         LOG.trace(\"can\u0027t get an mmap for \" + block + \" of \" + filename + \n             \" since SKIP_CHECKSUMS was not given, \" +\n             \"we aren\u0027t skipping checksums, and the block is not mlocked.\");\n       }\n       return null;\n     }\n-    if (clientMmap \u003d\u003d null) {\n-      if (mmapDisabled) {\n-        return null;\n-      }\n-      try {\n-        clientMmap \u003d mmapManager.fetch(datanodeID, block, streams[0]);\n-        if (clientMmap \u003d\u003d null) {\n-          mmapDisabled \u003d true;\n-          return null;\n-        }\n-      } catch (InterruptedException e) {\n-        LOG.error(\"Interrupted while setting up mmap for \" + filename, e);\n-        Thread.currentThread().interrupt();\n-        return null;\n-      } catch (IOException e) {\n-        LOG.error(\"unable to set up mmap for \" + filename, e);\n-        mmapDisabled \u003d true;\n-        return null;\n-      }\n-    }\n-    return clientMmap;\n+    return replica.getOrCreateClientMmap();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public ClientMmap getClientMmap(EnumSet\u003cReadOption\u003e opts) {\n    if ((!opts.contains(ReadOption.SKIP_CHECKSUMS)) \u0026\u0026\n          verifyChecksum \u0026\u0026 (!mlocked.get())) {\n      if (LOG.isTraceEnabled()) {\n        LOG.trace(\"can\u0027t get an mmap for \" + block + \" of \" + filename + \n            \" since SKIP_CHECKSUMS was not given, \" +\n            \"we aren\u0027t skipping checksums, and the block is not mlocked.\");\n      }\n      return null;\n    }\n    return replica.getOrCreateClientMmap();\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocal.java",
          "extendedDetails": {
            "oldValue": "[public, synchronized]",
            "newValue": "[public]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5810. Unify mmap cache and short-circuit file descriptor cache (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1567720 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "12/02/14 11:08 AM",
          "commitName": "beb0d25d2a7ba5004c6aabd105546ba9a9fec9be",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "15/01/14 11:17 AM",
          "commitNameOld": "037a89abc5cc5ea6b983b21c568a50bc729aa194",
          "commitAuthorOld": "Colin McCabe",
          "daysBetweenCommits": 27.99,
          "commitsBetweenForRepo": 191,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,33 +1,12 @@\n-  public synchronized ClientMmap getClientMmap(EnumSet\u003cReadOption\u003e opts,\n-        ClientMmapManager mmapManager) {\n+  public ClientMmap getClientMmap(EnumSet\u003cReadOption\u003e opts) {\n     if ((!opts.contains(ReadOption.SKIP_CHECKSUMS)) \u0026\u0026\n           verifyChecksum \u0026\u0026 (!mlocked.get())) {\n       if (LOG.isTraceEnabled()) {\n         LOG.trace(\"can\u0027t get an mmap for \" + block + \" of \" + filename + \n             \" since SKIP_CHECKSUMS was not given, \" +\n             \"we aren\u0027t skipping checksums, and the block is not mlocked.\");\n       }\n       return null;\n     }\n-    if (clientMmap \u003d\u003d null) {\n-      if (mmapDisabled) {\n-        return null;\n-      }\n-      try {\n-        clientMmap \u003d mmapManager.fetch(datanodeID, block, streams[0]);\n-        if (clientMmap \u003d\u003d null) {\n-          mmapDisabled \u003d true;\n-          return null;\n-        }\n-      } catch (InterruptedException e) {\n-        LOG.error(\"Interrupted while setting up mmap for \" + filename, e);\n-        Thread.currentThread().interrupt();\n-        return null;\n-      } catch (IOException e) {\n-        LOG.error(\"unable to set up mmap for \" + filename, e);\n-        mmapDisabled \u003d true;\n-        return null;\n-      }\n-    }\n-    return clientMmap;\n+    return replica.getOrCreateClientMmap();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public ClientMmap getClientMmap(EnumSet\u003cReadOption\u003e opts) {\n    if ((!opts.contains(ReadOption.SKIP_CHECKSUMS)) \u0026\u0026\n          verifyChecksum \u0026\u0026 (!mlocked.get())) {\n      if (LOG.isTraceEnabled()) {\n        LOG.trace(\"can\u0027t get an mmap for \" + block + \" of \" + filename + \n            \" since SKIP_CHECKSUMS was not given, \" +\n            \"we aren\u0027t skipping checksums, and the block is not mlocked.\");\n      }\n      return null;\n    }\n    return replica.getOrCreateClientMmap();\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocal.java",
          "extendedDetails": {}
        }
      ]
    },
    "124e507674c0d396f8494585e64226957199097b": {
      "type": "Ymultichange(Yparameterchange,Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-5634. Allow BlockReaderLocal to switch between checksumming and not (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1551701 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/12/13 12:57 PM",
      "commitName": "124e507674c0d396f8494585e64226957199097b",
      "commitAuthor": "Colin McCabe",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-5634. Allow BlockReaderLocal to switch between checksumming and not (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1551701 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "17/12/13 12:57 PM",
          "commitName": "124e507674c0d396f8494585e64226957199097b",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "27/09/13 3:51 PM",
          "commitNameOld": "eccdb9aa8bcdee750583d16a1253f1c5faabd036",
          "commitAuthorOld": "Chris Nauroth",
          "daysBetweenCommits": 80.92,
          "commitsBetweenForRepo": 532,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,33 @@\n-  public ClientMmap getClientMmap(LocatedBlock curBlock,\n-      ClientMmapManager mmapManager) {\n+  public synchronized ClientMmap getClientMmap(EnumSet\u003cReadOption\u003e opts,\n+        ClientMmapManager mmapManager) {\n+    if ((!opts.contains(ReadOption.SKIP_CHECKSUMS)) \u0026\u0026\n+          verifyChecksum \u0026\u0026 (!mlocked.get())) {\n+      if (LOG.isTraceEnabled()) {\n+        LOG.trace(\"can\u0027t get an mmap for \" + block + \" of \" + filename + \n+            \" since SKIP_CHECKSUMS was not given, \" +\n+            \"we aren\u0027t skipping checksums, and the block is not mlocked.\");\n+      }\n+      return null;\n+    }\n     if (clientMmap \u003d\u003d null) {\n       if (mmapDisabled) {\n         return null;\n       }\n       try {\n-        clientMmap \u003d mmapManager.fetch(datanodeID, block, dataIn);\n+        clientMmap \u003d mmapManager.fetch(datanodeID, block, streams[0]);\n         if (clientMmap \u003d\u003d null) {\n           mmapDisabled \u003d true;\n           return null;\n         }\n       } catch (InterruptedException e) {\n         LOG.error(\"Interrupted while setting up mmap for \" + filename, e);\n         Thread.currentThread().interrupt();\n         return null;\n       } catch (IOException e) {\n         LOG.error(\"unable to set up mmap for \" + filename, e);\n         mmapDisabled \u003d true;\n         return null;\n       }\n     }\n     return clientMmap;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public synchronized ClientMmap getClientMmap(EnumSet\u003cReadOption\u003e opts,\n        ClientMmapManager mmapManager) {\n    if ((!opts.contains(ReadOption.SKIP_CHECKSUMS)) \u0026\u0026\n          verifyChecksum \u0026\u0026 (!mlocked.get())) {\n      if (LOG.isTraceEnabled()) {\n        LOG.trace(\"can\u0027t get an mmap for \" + block + \" of \" + filename + \n            \" since SKIP_CHECKSUMS was not given, \" +\n            \"we aren\u0027t skipping checksums, and the block is not mlocked.\");\n      }\n      return null;\n    }\n    if (clientMmap \u003d\u003d null) {\n      if (mmapDisabled) {\n        return null;\n      }\n      try {\n        clientMmap \u003d mmapManager.fetch(datanodeID, block, streams[0]);\n        if (clientMmap \u003d\u003d null) {\n          mmapDisabled \u003d true;\n          return null;\n        }\n      } catch (InterruptedException e) {\n        LOG.error(\"Interrupted while setting up mmap for \" + filename, e);\n        Thread.currentThread().interrupt();\n        return null;\n      } catch (IOException e) {\n        LOG.error(\"unable to set up mmap for \" + filename, e);\n        mmapDisabled \u003d true;\n        return null;\n      }\n    }\n    return clientMmap;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocal.java",
          "extendedDetails": {
            "oldValue": "[curBlock-LocatedBlock, mmapManager-ClientMmapManager]",
            "newValue": "[opts-EnumSet\u003cReadOption\u003e, mmapManager-ClientMmapManager]"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-5634. Allow BlockReaderLocal to switch between checksumming and not (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1551701 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "17/12/13 12:57 PM",
          "commitName": "124e507674c0d396f8494585e64226957199097b",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "27/09/13 3:51 PM",
          "commitNameOld": "eccdb9aa8bcdee750583d16a1253f1c5faabd036",
          "commitAuthorOld": "Chris Nauroth",
          "daysBetweenCommits": 80.92,
          "commitsBetweenForRepo": 532,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,33 @@\n-  public ClientMmap getClientMmap(LocatedBlock curBlock,\n-      ClientMmapManager mmapManager) {\n+  public synchronized ClientMmap getClientMmap(EnumSet\u003cReadOption\u003e opts,\n+        ClientMmapManager mmapManager) {\n+    if ((!opts.contains(ReadOption.SKIP_CHECKSUMS)) \u0026\u0026\n+          verifyChecksum \u0026\u0026 (!mlocked.get())) {\n+      if (LOG.isTraceEnabled()) {\n+        LOG.trace(\"can\u0027t get an mmap for \" + block + \" of \" + filename + \n+            \" since SKIP_CHECKSUMS was not given, \" +\n+            \"we aren\u0027t skipping checksums, and the block is not mlocked.\");\n+      }\n+      return null;\n+    }\n     if (clientMmap \u003d\u003d null) {\n       if (mmapDisabled) {\n         return null;\n       }\n       try {\n-        clientMmap \u003d mmapManager.fetch(datanodeID, block, dataIn);\n+        clientMmap \u003d mmapManager.fetch(datanodeID, block, streams[0]);\n         if (clientMmap \u003d\u003d null) {\n           mmapDisabled \u003d true;\n           return null;\n         }\n       } catch (InterruptedException e) {\n         LOG.error(\"Interrupted while setting up mmap for \" + filename, e);\n         Thread.currentThread().interrupt();\n         return null;\n       } catch (IOException e) {\n         LOG.error(\"unable to set up mmap for \" + filename, e);\n         mmapDisabled \u003d true;\n         return null;\n       }\n     }\n     return clientMmap;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public synchronized ClientMmap getClientMmap(EnumSet\u003cReadOption\u003e opts,\n        ClientMmapManager mmapManager) {\n    if ((!opts.contains(ReadOption.SKIP_CHECKSUMS)) \u0026\u0026\n          verifyChecksum \u0026\u0026 (!mlocked.get())) {\n      if (LOG.isTraceEnabled()) {\n        LOG.trace(\"can\u0027t get an mmap for \" + block + \" of \" + filename + \n            \" since SKIP_CHECKSUMS was not given, \" +\n            \"we aren\u0027t skipping checksums, and the block is not mlocked.\");\n      }\n      return null;\n    }\n    if (clientMmap \u003d\u003d null) {\n      if (mmapDisabled) {\n        return null;\n      }\n      try {\n        clientMmap \u003d mmapManager.fetch(datanodeID, block, streams[0]);\n        if (clientMmap \u003d\u003d null) {\n          mmapDisabled \u003d true;\n          return null;\n        }\n      } catch (InterruptedException e) {\n        LOG.error(\"Interrupted while setting up mmap for \" + filename, e);\n        Thread.currentThread().interrupt();\n        return null;\n      } catch (IOException e) {\n        LOG.error(\"unable to set up mmap for \" + filename, e);\n        mmapDisabled \u003d true;\n        return null;\n      }\n    }\n    return clientMmap;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocal.java",
          "extendedDetails": {
            "oldValue": "[public]",
            "newValue": "[public, synchronized]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5634. Allow BlockReaderLocal to switch between checksumming and not (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1551701 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "17/12/13 12:57 PM",
          "commitName": "124e507674c0d396f8494585e64226957199097b",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "27/09/13 3:51 PM",
          "commitNameOld": "eccdb9aa8bcdee750583d16a1253f1c5faabd036",
          "commitAuthorOld": "Chris Nauroth",
          "daysBetweenCommits": 80.92,
          "commitsBetweenForRepo": 532,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,33 @@\n-  public ClientMmap getClientMmap(LocatedBlock curBlock,\n-      ClientMmapManager mmapManager) {\n+  public synchronized ClientMmap getClientMmap(EnumSet\u003cReadOption\u003e opts,\n+        ClientMmapManager mmapManager) {\n+    if ((!opts.contains(ReadOption.SKIP_CHECKSUMS)) \u0026\u0026\n+          verifyChecksum \u0026\u0026 (!mlocked.get())) {\n+      if (LOG.isTraceEnabled()) {\n+        LOG.trace(\"can\u0027t get an mmap for \" + block + \" of \" + filename + \n+            \" since SKIP_CHECKSUMS was not given, \" +\n+            \"we aren\u0027t skipping checksums, and the block is not mlocked.\");\n+      }\n+      return null;\n+    }\n     if (clientMmap \u003d\u003d null) {\n       if (mmapDisabled) {\n         return null;\n       }\n       try {\n-        clientMmap \u003d mmapManager.fetch(datanodeID, block, dataIn);\n+        clientMmap \u003d mmapManager.fetch(datanodeID, block, streams[0]);\n         if (clientMmap \u003d\u003d null) {\n           mmapDisabled \u003d true;\n           return null;\n         }\n       } catch (InterruptedException e) {\n         LOG.error(\"Interrupted while setting up mmap for \" + filename, e);\n         Thread.currentThread().interrupt();\n         return null;\n       } catch (IOException e) {\n         LOG.error(\"unable to set up mmap for \" + filename, e);\n         mmapDisabled \u003d true;\n         return null;\n       }\n     }\n     return clientMmap;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public synchronized ClientMmap getClientMmap(EnumSet\u003cReadOption\u003e opts,\n        ClientMmapManager mmapManager) {\n    if ((!opts.contains(ReadOption.SKIP_CHECKSUMS)) \u0026\u0026\n          verifyChecksum \u0026\u0026 (!mlocked.get())) {\n      if (LOG.isTraceEnabled()) {\n        LOG.trace(\"can\u0027t get an mmap for \" + block + \" of \" + filename + \n            \" since SKIP_CHECKSUMS was not given, \" +\n            \"we aren\u0027t skipping checksums, and the block is not mlocked.\");\n      }\n      return null;\n    }\n    if (clientMmap \u003d\u003d null) {\n      if (mmapDisabled) {\n        return null;\n      }\n      try {\n        clientMmap \u003d mmapManager.fetch(datanodeID, block, streams[0]);\n        if (clientMmap \u003d\u003d null) {\n          mmapDisabled \u003d true;\n          return null;\n        }\n      } catch (InterruptedException e) {\n        LOG.error(\"Interrupted while setting up mmap for \" + filename, e);\n        Thread.currentThread().interrupt();\n        return null;\n      } catch (IOException e) {\n        LOG.error(\"unable to set up mmap for \" + filename, e);\n        mmapDisabled \u003d true;\n        return null;\n      }\n    }\n    return clientMmap;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocal.java",
          "extendedDetails": {}
        }
      ]
    },
    "eccdb9aa8bcdee750583d16a1253f1c5faabd036": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-5260. Merge zero-copy memory-mapped HDFS client reads to trunk and branch-2. Contributed by Chris Nauroth.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1527113 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/09/13 3:51 PM",
      "commitName": "eccdb9aa8bcdee750583d16a1253f1c5faabd036",
      "commitAuthor": "Chris Nauroth",
      "diff": "@@ -0,0 +1,24 @@\n+  public ClientMmap getClientMmap(LocatedBlock curBlock,\n+      ClientMmapManager mmapManager) {\n+    if (clientMmap \u003d\u003d null) {\n+      if (mmapDisabled) {\n+        return null;\n+      }\n+      try {\n+        clientMmap \u003d mmapManager.fetch(datanodeID, block, dataIn);\n+        if (clientMmap \u003d\u003d null) {\n+          mmapDisabled \u003d true;\n+          return null;\n+        }\n+      } catch (InterruptedException e) {\n+        LOG.error(\"Interrupted while setting up mmap for \" + filename, e);\n+        Thread.currentThread().interrupt();\n+        return null;\n+      } catch (IOException e) {\n+        LOG.error(\"unable to set up mmap for \" + filename, e);\n+        mmapDisabled \u003d true;\n+        return null;\n+      }\n+    }\n+    return clientMmap;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public ClientMmap getClientMmap(LocatedBlock curBlock,\n      ClientMmapManager mmapManager) {\n    if (clientMmap \u003d\u003d null) {\n      if (mmapDisabled) {\n        return null;\n      }\n      try {\n        clientMmap \u003d mmapManager.fetch(datanodeID, block, dataIn);\n        if (clientMmap \u003d\u003d null) {\n          mmapDisabled \u003d true;\n          return null;\n        }\n      } catch (InterruptedException e) {\n        LOG.error(\"Interrupted while setting up mmap for \" + filename, e);\n        Thread.currentThread().interrupt();\n        return null;\n      } catch (IOException e) {\n        LOG.error(\"unable to set up mmap for \" + filename, e);\n        mmapDisabled \u003d true;\n        return null;\n      }\n    }\n    return clientMmap;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocal.java"
    }
  }
}