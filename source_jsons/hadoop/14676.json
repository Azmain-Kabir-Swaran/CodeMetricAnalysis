{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "JsonUtil.java",
  "functionName": "toJsonString",
  "functionId": "toJsonString___contentsummary-ContentSummary(modifiers-final)",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java",
  "functionStartLine": 348,
  "functionEndLine": 367,
  "numCommitsSeen": 79,
  "timeTaken": 4036,
  "changeHistory": [
    "b74e47e31abd31617c0cdc648a3b1d48bb311d65",
    "99bf1dc9eb18f9b4d0338986d1b8fd2232f1232f",
    "3ae775d74029b6ae82263739f598ceb25c597dcd",
    "41d3f8899d8b96568f56331eaf598bb356ecdae0",
    "1b1016beeb716bef8dad93bb2c7c4631a14b3d57",
    "dc8464f943b61b795df0cc8baec171bf07355763"
  ],
  "changeHistoryShort": {
    "b74e47e31abd31617c0cdc648a3b1d48bb311d65": "Ybodychange",
    "99bf1dc9eb18f9b4d0338986d1b8fd2232f1232f": "Ybodychange",
    "3ae775d74029b6ae82263739f598ceb25c597dcd": "Ybodychange",
    "41d3f8899d8b96568f56331eaf598bb356ecdae0": "Ybodychange",
    "1b1016beeb716bef8dad93bb2c7c4631a14b3d57": "Ymultichange(Yexceptionschange,Ybodychange)",
    "dc8464f943b61b795df0cc8baec171bf07355763": "Yintroduced"
  },
  "changeHistoryDetails": {
    "b74e47e31abd31617c0cdc648a3b1d48bb311d65": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-15214. WebHDFS: Add snapshot counts to Content Summary. Contributed by hemanthboyina.\n",
      "commitDate": "21/03/20 9:44 AM",
      "commitName": "b74e47e31abd31617c0cdc648a3b1d48bb311d65",
      "commitAuthor": "Takanobu Asanuma",
      "commitDateOld": "31/12/19 6:26 PM",
      "commitNameOld": "074050ca595a81927c867951e48cef132a0284be",
      "commitAuthorOld": "Takanobu Asanuma",
      "daysBetweenCommits": 80.6,
      "commitsBetweenForRepo": 277,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,15 +1,20 @@\n   public static String toJsonString(final ContentSummary contentsummary) {\n     if (contentsummary \u003d\u003d null) {\n       return null;\n     }\n \n     final Map\u003cString, Object\u003e m \u003d new TreeMap\u003cString, Object\u003e();\n     m.put(\"length\", contentsummary.getLength());\n     m.put(\"fileCount\", contentsummary.getFileCount());\n     m.put(\"directoryCount\", contentsummary.getDirectoryCount());\n     m.put(\"ecPolicy\", contentsummary.getErasureCodingPolicy());\n     // For ContentSummary we don\u0027t need this since we already have\n     // separate count for file and directory.\n     m.putAll(toJsonMap(contentsummary, false));\n+    m.put(\"snapshotLength\", contentsummary.getSnapshotLength());\n+    m.put(\"snapshotFileCount\", contentsummary.getSnapshotFileCount());\n+    m.put(\"snapshotDirectoryCount\",\n+        contentsummary.getSnapshotDirectoryCount());\n+    m.put(\"snapshotSpaceConsumed\", contentsummary.getSnapshotSpaceConsumed());\n     return toJsonString(ContentSummary.class, m);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static String toJsonString(final ContentSummary contentsummary) {\n    if (contentsummary \u003d\u003d null) {\n      return null;\n    }\n\n    final Map\u003cString, Object\u003e m \u003d new TreeMap\u003cString, Object\u003e();\n    m.put(\"length\", contentsummary.getLength());\n    m.put(\"fileCount\", contentsummary.getFileCount());\n    m.put(\"directoryCount\", contentsummary.getDirectoryCount());\n    m.put(\"ecPolicy\", contentsummary.getErasureCodingPolicy());\n    // For ContentSummary we don\u0027t need this since we already have\n    // separate count for file and directory.\n    m.putAll(toJsonMap(contentsummary, false));\n    m.put(\"snapshotLength\", contentsummary.getSnapshotLength());\n    m.put(\"snapshotFileCount\", contentsummary.getSnapshotFileCount());\n    m.put(\"snapshotDirectoryCount\",\n        contentsummary.getSnapshotDirectoryCount());\n    m.put(\"snapshotSpaceConsumed\", contentsummary.getSnapshotSpaceConsumed());\n    return toJsonString(ContentSummary.class, m);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java",
      "extendedDetails": {}
    },
    "99bf1dc9eb18f9b4d0338986d1b8fd2232f1232f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14683. WebHDFS: Add erasureCodingPolicy field to GETCONTENTSUMMARY response (#1189) Contributed by Siyao Meng.\n\n",
      "commitDate": "01/08/19 5:14 PM",
      "commitName": "99bf1dc9eb18f9b4d0338986d1b8fd2232f1232f",
      "commitAuthor": "Siyao Meng",
      "commitDateOld": "30/07/19 4:01 PM",
      "commitNameOld": "3ae775d74029b6ae82263739f598ceb25c597dcd",
      "commitAuthorOld": "Chao Sun",
      "daysBetweenCommits": 2.05,
      "commitsBetweenForRepo": 18,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,15 @@\n   public static String toJsonString(final ContentSummary contentsummary) {\n     if (contentsummary \u003d\u003d null) {\n       return null;\n     }\n \n     final Map\u003cString, Object\u003e m \u003d new TreeMap\u003cString, Object\u003e();\n     m.put(\"length\", contentsummary.getLength());\n     m.put(\"fileCount\", contentsummary.getFileCount());\n     m.put(\"directoryCount\", contentsummary.getDirectoryCount());\n+    m.put(\"ecPolicy\", contentsummary.getErasureCodingPolicy());\n     // For ContentSummary we don\u0027t need this since we already have\n     // separate count for file and directory.\n     m.putAll(toJsonMap(contentsummary, false));\n     return toJsonString(ContentSummary.class, m);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static String toJsonString(final ContentSummary contentsummary) {\n    if (contentsummary \u003d\u003d null) {\n      return null;\n    }\n\n    final Map\u003cString, Object\u003e m \u003d new TreeMap\u003cString, Object\u003e();\n    m.put(\"length\", contentsummary.getLength());\n    m.put(\"fileCount\", contentsummary.getFileCount());\n    m.put(\"directoryCount\", contentsummary.getDirectoryCount());\n    m.put(\"ecPolicy\", contentsummary.getErasureCodingPolicy());\n    // For ContentSummary we don\u0027t need this since we already have\n    // separate count for file and directory.\n    m.putAll(toJsonMap(contentsummary, false));\n    return toJsonString(ContentSummary.class, m);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java",
      "extendedDetails": {}
    },
    "3ae775d74029b6ae82263739f598ceb25c597dcd": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14034. Support getQuotaUsage API in WebHDFS. Contributed by Chao Sun.\n\nSigned-off-by: Wei-Chiu Chuang \u003cweichiu@apache.org\u003e\n",
      "commitDate": "30/07/19 4:01 PM",
      "commitName": "3ae775d74029b6ae82263739f598ceb25c597dcd",
      "commitAuthor": "Chao Sun",
      "commitDateOld": "10/10/18 10:11 AM",
      "commitNameOld": "3ead525c71cba068e7abf1c76ad629bfeec10852",
      "commitAuthorOld": "Weiwei Yang",
      "daysBetweenCommits": 293.24,
      "commitsBetweenForRepo": 2159,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,29 +1,14 @@\n   public static String toJsonString(final ContentSummary contentsummary) {\n     if (contentsummary \u003d\u003d null) {\n       return null;\n     }\n \n     final Map\u003cString, Object\u003e m \u003d new TreeMap\u003cString, Object\u003e();\n     m.put(\"length\", contentsummary.getLength());\n     m.put(\"fileCount\", contentsummary.getFileCount());\n     m.put(\"directoryCount\", contentsummary.getDirectoryCount());\n-    m.put(\"quota\", contentsummary.getQuota());\n-    m.put(\"spaceConsumed\", contentsummary.getSpaceConsumed());\n-    m.put(\"spaceQuota\", contentsummary.getSpaceQuota());\n-    final Map\u003cString, Map\u003cString, Long\u003e\u003e typeQuota \u003d\n-        new TreeMap\u003cString, Map\u003cString, Long\u003e\u003e();\n-    for (StorageType t : StorageType.getTypesSupportingQuota()) {\n-      long tQuota \u003d contentsummary.getTypeQuota(t);\n-      if (tQuota !\u003d HdfsConstants.QUOTA_RESET) {\n-        Map\u003cString, Long\u003e type \u003d typeQuota.get(t.toString());\n-        if (type \u003d\u003d null) {\n-          type \u003d new TreeMap\u003cString, Long\u003e();\n-          typeQuota.put(t.toString(), type);\n-        }\n-        type.put(\"quota\", contentsummary.getTypeQuota(t));\n-        type.put(\"consumed\", contentsummary.getTypeConsumed(t));\n-      }\n-    }\n-    m.put(\"typeQuota\", typeQuota);\n+    // For ContentSummary we don\u0027t need this since we already have\n+    // separate count for file and directory.\n+    m.putAll(toJsonMap(contentsummary, false));\n     return toJsonString(ContentSummary.class, m);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static String toJsonString(final ContentSummary contentsummary) {\n    if (contentsummary \u003d\u003d null) {\n      return null;\n    }\n\n    final Map\u003cString, Object\u003e m \u003d new TreeMap\u003cString, Object\u003e();\n    m.put(\"length\", contentsummary.getLength());\n    m.put(\"fileCount\", contentsummary.getFileCount());\n    m.put(\"directoryCount\", contentsummary.getDirectoryCount());\n    // For ContentSummary we don\u0027t need this since we already have\n    // separate count for file and directory.\n    m.putAll(toJsonMap(contentsummary, false));\n    return toJsonString(ContentSummary.class, m);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java",
      "extendedDetails": {}
    },
    "41d3f8899d8b96568f56331eaf598bb356ecdae0": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9234. WebHdfs: getContentSummary() should give quota for storage types. Contributed by Surendra Singh Lilhore.\n",
      "commitDate": "09/11/15 9:57 AM",
      "commitName": "41d3f8899d8b96568f56331eaf598bb356ecdae0",
      "commitAuthor": "Xiaoyu Yao",
      "commitDateOld": "19/09/15 6:08 PM",
      "commitNameOld": "3a9c7076e81c1cc47c0ecf30c60abd9a65d8a501",
      "commitAuthorOld": "Lei Xu",
      "daysBetweenCommits": 50.7,
      "commitsBetweenForRepo": 410,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,29 @@\n   public static String toJsonString(final ContentSummary contentsummary) {\n     if (contentsummary \u003d\u003d null) {\n       return null;\n     }\n \n     final Map\u003cString, Object\u003e m \u003d new TreeMap\u003cString, Object\u003e();\n     m.put(\"length\", contentsummary.getLength());\n     m.put(\"fileCount\", contentsummary.getFileCount());\n     m.put(\"directoryCount\", contentsummary.getDirectoryCount());\n     m.put(\"quota\", contentsummary.getQuota());\n     m.put(\"spaceConsumed\", contentsummary.getSpaceConsumed());\n     m.put(\"spaceQuota\", contentsummary.getSpaceQuota());\n+    final Map\u003cString, Map\u003cString, Long\u003e\u003e typeQuota \u003d\n+        new TreeMap\u003cString, Map\u003cString, Long\u003e\u003e();\n+    for (StorageType t : StorageType.getTypesSupportingQuota()) {\n+      long tQuota \u003d contentsummary.getTypeQuota(t);\n+      if (tQuota !\u003d HdfsConstants.QUOTA_RESET) {\n+        Map\u003cString, Long\u003e type \u003d typeQuota.get(t.toString());\n+        if (type \u003d\u003d null) {\n+          type \u003d new TreeMap\u003cString, Long\u003e();\n+          typeQuota.put(t.toString(), type);\n+        }\n+        type.put(\"quota\", contentsummary.getTypeQuota(t));\n+        type.put(\"consumed\", contentsummary.getTypeConsumed(t));\n+      }\n+    }\n+    m.put(\"typeQuota\", typeQuota);\n     return toJsonString(ContentSummary.class, m);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static String toJsonString(final ContentSummary contentsummary) {\n    if (contentsummary \u003d\u003d null) {\n      return null;\n    }\n\n    final Map\u003cString, Object\u003e m \u003d new TreeMap\u003cString, Object\u003e();\n    m.put(\"length\", contentsummary.getLength());\n    m.put(\"fileCount\", contentsummary.getFileCount());\n    m.put(\"directoryCount\", contentsummary.getDirectoryCount());\n    m.put(\"quota\", contentsummary.getQuota());\n    m.put(\"spaceConsumed\", contentsummary.getSpaceConsumed());\n    m.put(\"spaceQuota\", contentsummary.getSpaceQuota());\n    final Map\u003cString, Map\u003cString, Long\u003e\u003e typeQuota \u003d\n        new TreeMap\u003cString, Map\u003cString, Long\u003e\u003e();\n    for (StorageType t : StorageType.getTypesSupportingQuota()) {\n      long tQuota \u003d contentsummary.getTypeQuota(t);\n      if (tQuota !\u003d HdfsConstants.QUOTA_RESET) {\n        Map\u003cString, Long\u003e type \u003d typeQuota.get(t.toString());\n        if (type \u003d\u003d null) {\n          type \u003d new TreeMap\u003cString, Long\u003e();\n          typeQuota.put(t.toString(), type);\n        }\n        type.put(\"quota\", contentsummary.getTypeQuota(t));\n        type.put(\"consumed\", contentsummary.getTypeConsumed(t));\n      }\n    }\n    m.put(\"typeQuota\", typeQuota);\n    return toJsonString(ContentSummary.class, m);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java",
      "extendedDetails": {}
    },
    "1b1016beeb716bef8dad93bb2c7c4631a14b3d57": {
      "type": "Ymultichange(Yexceptionschange,Ybodychange)",
      "commitMessage": "HDFS-2395. Add a root element in the JSON responses of webhdfs.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1179169 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "05/10/11 4:29 AM",
      "commitName": "1b1016beeb716bef8dad93bb2c7c4631a14b3d57",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Yexceptionschange",
          "commitMessage": "HDFS-2395. Add a root element in the JSON responses of webhdfs.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1179169 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "05/10/11 4:29 AM",
          "commitName": "1b1016beeb716bef8dad93bb2c7c4631a14b3d57",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "30/09/11 9:49 PM",
          "commitNameOld": "dc8464f943b61b795df0cc8baec171bf07355763",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 4.28,
          "commitsBetweenForRepo": 25,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,15 +1,14 @@\n-  public static String toJsonString(final ContentSummary contentsummary\n-      ) throws IOException {\n+  public static String toJsonString(final ContentSummary contentsummary) {\n     if (contentsummary \u003d\u003d null) {\n       return null;\n     }\n \n-    final Map\u003cString, Object\u003e m \u003d jsonMap.get();\n+    final Map\u003cString, Object\u003e m \u003d new TreeMap\u003cString, Object\u003e();\n     m.put(\"length\", contentsummary.getLength());\n     m.put(\"fileCount\", contentsummary.getFileCount());\n     m.put(\"directoryCount\", contentsummary.getDirectoryCount());\n     m.put(\"quota\", contentsummary.getQuota());\n     m.put(\"spaceConsumed\", contentsummary.getSpaceConsumed());\n     m.put(\"spaceQuota\", contentsummary.getSpaceQuota());\n-    return JSON.toString(m);\n+    return toJsonString(ContentSummary.class, m);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static String toJsonString(final ContentSummary contentsummary) {\n    if (contentsummary \u003d\u003d null) {\n      return null;\n    }\n\n    final Map\u003cString, Object\u003e m \u003d new TreeMap\u003cString, Object\u003e();\n    m.put(\"length\", contentsummary.getLength());\n    m.put(\"fileCount\", contentsummary.getFileCount());\n    m.put(\"directoryCount\", contentsummary.getDirectoryCount());\n    m.put(\"quota\", contentsummary.getQuota());\n    m.put(\"spaceConsumed\", contentsummary.getSpaceConsumed());\n    m.put(\"spaceQuota\", contentsummary.getSpaceQuota());\n    return toJsonString(ContentSummary.class, m);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java",
          "extendedDetails": {
            "oldValue": "[IOException]",
            "newValue": "[]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-2395. Add a root element in the JSON responses of webhdfs.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1179169 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "05/10/11 4:29 AM",
          "commitName": "1b1016beeb716bef8dad93bb2c7c4631a14b3d57",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "30/09/11 9:49 PM",
          "commitNameOld": "dc8464f943b61b795df0cc8baec171bf07355763",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 4.28,
          "commitsBetweenForRepo": 25,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,15 +1,14 @@\n-  public static String toJsonString(final ContentSummary contentsummary\n-      ) throws IOException {\n+  public static String toJsonString(final ContentSummary contentsummary) {\n     if (contentsummary \u003d\u003d null) {\n       return null;\n     }\n \n-    final Map\u003cString, Object\u003e m \u003d jsonMap.get();\n+    final Map\u003cString, Object\u003e m \u003d new TreeMap\u003cString, Object\u003e();\n     m.put(\"length\", contentsummary.getLength());\n     m.put(\"fileCount\", contentsummary.getFileCount());\n     m.put(\"directoryCount\", contentsummary.getDirectoryCount());\n     m.put(\"quota\", contentsummary.getQuota());\n     m.put(\"spaceConsumed\", contentsummary.getSpaceConsumed());\n     m.put(\"spaceQuota\", contentsummary.getSpaceQuota());\n-    return JSON.toString(m);\n+    return toJsonString(ContentSummary.class, m);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static String toJsonString(final ContentSummary contentsummary) {\n    if (contentsummary \u003d\u003d null) {\n      return null;\n    }\n\n    final Map\u003cString, Object\u003e m \u003d new TreeMap\u003cString, Object\u003e();\n    m.put(\"length\", contentsummary.getLength());\n    m.put(\"fileCount\", contentsummary.getFileCount());\n    m.put(\"directoryCount\", contentsummary.getDirectoryCount());\n    m.put(\"quota\", contentsummary.getQuota());\n    m.put(\"spaceConsumed\", contentsummary.getSpaceConsumed());\n    m.put(\"spaceQuota\", contentsummary.getSpaceQuota());\n    return toJsonString(ContentSummary.class, m);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java",
          "extendedDetails": {}
        }
      ]
    },
    "dc8464f943b61b795df0cc8baec171bf07355763": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-2348. Support getContentSummary and getFileChecksum in webhdfs.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1177905 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "30/09/11 9:49 PM",
      "commitName": "dc8464f943b61b795df0cc8baec171bf07355763",
      "commitAuthor": "Tsz-wo Sze",
      "diff": "@@ -0,0 +1,15 @@\n+  public static String toJsonString(final ContentSummary contentsummary\n+      ) throws IOException {\n+    if (contentsummary \u003d\u003d null) {\n+      return null;\n+    }\n+\n+    final Map\u003cString, Object\u003e m \u003d jsonMap.get();\n+    m.put(\"length\", contentsummary.getLength());\n+    m.put(\"fileCount\", contentsummary.getFileCount());\n+    m.put(\"directoryCount\", contentsummary.getDirectoryCount());\n+    m.put(\"quota\", contentsummary.getQuota());\n+    m.put(\"spaceConsumed\", contentsummary.getSpaceConsumed());\n+    m.put(\"spaceQuota\", contentsummary.getSpaceQuota());\n+    return JSON.toString(m);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public static String toJsonString(final ContentSummary contentsummary\n      ) throws IOException {\n    if (contentsummary \u003d\u003d null) {\n      return null;\n    }\n\n    final Map\u003cString, Object\u003e m \u003d jsonMap.get();\n    m.put(\"length\", contentsummary.getLength());\n    m.put(\"fileCount\", contentsummary.getFileCount());\n    m.put(\"directoryCount\", contentsummary.getDirectoryCount());\n    m.put(\"quota\", contentsummary.getQuota());\n    m.put(\"spaceConsumed\", contentsummary.getSpaceConsumed());\n    m.put(\"spaceQuota\", contentsummary.getSpaceQuota());\n    return JSON.toString(m);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java"
    }
  }
}