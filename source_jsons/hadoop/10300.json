{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "LocalReplica.java",
  "functionName": "breakHardlinks",
  "functionId": "breakHardlinks___file-File__b-Block",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/LocalReplica.java",
  "functionStartLine": 190,
  "functionEndLine": 215,
  "numCommitsSeen": 29,
  "timeTaken": 5168,
  "changeHistory": [
    "eb7fe1d588de903be2ff6e20384c25c184881532",
    "6ba9587d370fbf39c129c08c00ebbb894ccc1389",
    "df983b524ab68ea0c70cee9033bfff2d28052cbf",
    "dcedb72af468128458e597f08d22f5c34b744ae5",
    "aeecfa24f4fb6af289920cbf8830c394e66bd78e",
    "86c9862bec0248d671e657aa56094a2919b8ac14",
    "bb540ba85aa37d9fe31e640665158afe8a936230"
  ],
  "changeHistoryShort": {
    "eb7fe1d588de903be2ff6e20384c25c184881532": "Ybodychange",
    "6ba9587d370fbf39c129c08c00ebbb894ccc1389": "Ybodychange",
    "df983b524ab68ea0c70cee9033bfff2d28052cbf": "Ybodychange",
    "dcedb72af468128458e597f08d22f5c34b744ae5": "Ybodychange",
    "aeecfa24f4fb6af289920cbf8830c394e66bd78e": "Ybodychange",
    "86c9862bec0248d671e657aa56094a2919b8ac14": "Ymultichange(Ymovefromfile,Ybodychange)",
    "bb540ba85aa37d9fe31e640665158afe8a936230": "Yintroduced"
  },
  "changeHistoryDetails": {
    "eb7fe1d588de903be2ff6e20384c25c184881532": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13509. Bug fix for breakHardlinks() of ReplicaInfo/LocalReplica, and fix TestFileAppend failures on Windows. Contributed by Xiao Liang.\n",
      "commitDate": "28/04/18 9:05 AM",
      "commitName": "eb7fe1d588de903be2ff6e20384c25c184881532",
      "commitAuthor": "Inigo Goiri",
      "commitDateOld": "31/05/17 8:55 AM",
      "commitNameOld": "1543d0f5be6a02ad00e7a33e35d78af8516043e3",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 332.01,
      "commitsBetweenForRepo": 2930,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,26 @@\n   private void breakHardlinks(File file, Block b) throws IOException {\n     final FileIoProvider fileIoProvider \u003d getFileIoProvider();\n     final File tmpFile \u003d DatanodeUtil.createFileWithExistsCheck(\n         getVolume(), b, DatanodeUtil.getUnlinkTmpFile(file), fileIoProvider);\n-    try (FileInputStream in \u003d fileIoProvider.getFileInputStream(\n-        getVolume(), file)) {\n-      try (FileOutputStream out \u003d fileIoProvider.getFileOutputStream(\n-          getVolume(), tmpFile)) {\n-        IOUtils.copyBytes(in, out, 16 * 1024);\n+    try {\n+      try (FileInputStream in \u003d fileIoProvider.getFileInputStream(\n+          getVolume(), file)) {\n+        try (FileOutputStream out \u003d fileIoProvider.getFileOutputStream(\n+            getVolume(), tmpFile)) {\n+          IOUtils.copyBytes(in, out, 16 * 1024);\n+        }\n       }\n       if (file.length() !\u003d tmpFile.length()) {\n-        throw new IOException(\"Copy of file \" + file + \" size \" + file.length()+\n-                              \" into file \" + tmpFile +\n-                              \" resulted in a size of \" + tmpFile.length());\n+        throw new IOException(\"Copy of file \" + file + \" size \" + file.length()\n+            + \" into file \" + tmpFile + \" resulted in a size of \"\n+            + tmpFile.length());\n       }\n       fileIoProvider.replaceFile(getVolume(), tmpFile, file);\n     } catch (IOException e) {\n       if (!fileIoProvider.delete(getVolume(), tmpFile)) {\n         DataNode.LOG.info(\"detachFile failed to delete temporary file \" +\n                           tmpFile);\n       }\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void breakHardlinks(File file, Block b) throws IOException {\n    final FileIoProvider fileIoProvider \u003d getFileIoProvider();\n    final File tmpFile \u003d DatanodeUtil.createFileWithExistsCheck(\n        getVolume(), b, DatanodeUtil.getUnlinkTmpFile(file), fileIoProvider);\n    try {\n      try (FileInputStream in \u003d fileIoProvider.getFileInputStream(\n          getVolume(), file)) {\n        try (FileOutputStream out \u003d fileIoProvider.getFileOutputStream(\n            getVolume(), tmpFile)) {\n          IOUtils.copyBytes(in, out, 16 * 1024);\n        }\n      }\n      if (file.length() !\u003d tmpFile.length()) {\n        throw new IOException(\"Copy of file \" + file + \" size \" + file.length()\n            + \" into file \" + tmpFile + \" resulted in a size of \"\n            + tmpFile.length());\n      }\n      fileIoProvider.replaceFile(getVolume(), tmpFile, file);\n    } catch (IOException e) {\n      if (!fileIoProvider.delete(getVolume(), tmpFile)) {\n        DataNode.LOG.info(\"detachFile failed to delete temporary file \" +\n                          tmpFile);\n      }\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/LocalReplica.java",
      "extendedDetails": {}
    },
    "6ba9587d370fbf39c129c08c00ebbb894ccc1389": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10958. Add instrumentation hooks around Datanode disk IO.\n",
      "commitDate": "14/12/16 11:18 AM",
      "commitName": "6ba9587d370fbf39c129c08c00ebbb894ccc1389",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "06/12/16 11:05 AM",
      "commitNameOld": "df983b524ab68ea0c70cee9033bfff2d28052cbf",
      "commitAuthorOld": "Xiaoyu Yao",
      "daysBetweenCommits": 8.01,
      "commitsBetweenForRepo": 51,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,24 @@\n   private void breakHardlinks(File file, Block b) throws IOException {\n-    File tmpFile \u003d DatanodeUtil.createTmpFile(b, DatanodeUtil.getUnlinkTmpFile(file));\n-    try (FileInputStream in \u003d new FileInputStream(file)) {\n-      try (FileOutputStream out \u003d new FileOutputStream(tmpFile)){\n-        copyBytes(in, out, 16 * 1024);\n+    final FileIoProvider fileIoProvider \u003d getFileIoProvider();\n+    final File tmpFile \u003d DatanodeUtil.createFileWithExistsCheck(\n+        getVolume(), b, DatanodeUtil.getUnlinkTmpFile(file), fileIoProvider);\n+    try (FileInputStream in \u003d fileIoProvider.getFileInputStream(\n+        getVolume(), file)) {\n+      try (FileOutputStream out \u003d fileIoProvider.getFileOutputStream(\n+          getVolume(), tmpFile)) {\n+        IOUtils.copyBytes(in, out, 16 * 1024);\n       }\n       if (file.length() !\u003d tmpFile.length()) {\n         throw new IOException(\"Copy of file \" + file + \" size \" + file.length()+\n                               \" into file \" + tmpFile +\n                               \" resulted in a size of \" + tmpFile.length());\n       }\n-      replaceFile(tmpFile, file);\n+      fileIoProvider.replaceFile(getVolume(), tmpFile, file);\n     } catch (IOException e) {\n-      boolean done \u003d tmpFile.delete();\n-      if (!done) {\n+      if (!fileIoProvider.delete(getVolume(), tmpFile)) {\n         DataNode.LOG.info(\"detachFile failed to delete temporary file \" +\n                           tmpFile);\n       }\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void breakHardlinks(File file, Block b) throws IOException {\n    final FileIoProvider fileIoProvider \u003d getFileIoProvider();\n    final File tmpFile \u003d DatanodeUtil.createFileWithExistsCheck(\n        getVolume(), b, DatanodeUtil.getUnlinkTmpFile(file), fileIoProvider);\n    try (FileInputStream in \u003d fileIoProvider.getFileInputStream(\n        getVolume(), file)) {\n      try (FileOutputStream out \u003d fileIoProvider.getFileOutputStream(\n          getVolume(), tmpFile)) {\n        IOUtils.copyBytes(in, out, 16 * 1024);\n      }\n      if (file.length() !\u003d tmpFile.length()) {\n        throw new IOException(\"Copy of file \" + file + \" size \" + file.length()+\n                              \" into file \" + tmpFile +\n                              \" resulted in a size of \" + tmpFile.length());\n      }\n      fileIoProvider.replaceFile(getVolume(), tmpFile, file);\n    } catch (IOException e) {\n      if (!fileIoProvider.delete(getVolume(), tmpFile)) {\n        DataNode.LOG.info(\"detachFile failed to delete temporary file \" +\n                          tmpFile);\n      }\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/LocalReplica.java",
      "extendedDetails": {}
    },
    "df983b524ab68ea0c70cee9033bfff2d28052cbf": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10930. Refactor: Wrap Datanode IO related operations. Contributed by Xiaoyu Yao.\n",
      "commitDate": "06/12/16 11:05 AM",
      "commitName": "df983b524ab68ea0c70cee9033bfff2d28052cbf",
      "commitAuthor": "Xiaoyu Yao",
      "commitDateOld": "05/12/16 12:44 PM",
      "commitNameOld": "dcedb72af468128458e597f08d22f5c34b744ae5",
      "commitAuthorOld": "Xiaoyu Yao",
      "daysBetweenCommits": 0.93,
      "commitsBetweenForRepo": 10,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,21 @@\n   private void breakHardlinks(File file, Block b) throws IOException {\n     File tmpFile \u003d DatanodeUtil.createTmpFile(b, DatanodeUtil.getUnlinkTmpFile(file));\n     try (FileInputStream in \u003d new FileInputStream(file)) {\n       try (FileOutputStream out \u003d new FileOutputStream(tmpFile)){\n-        IOUtils.copyBytes(in, out, 16 * 1024);\n+        copyBytes(in, out, 16 * 1024);\n       }\n       if (file.length() !\u003d tmpFile.length()) {\n         throw new IOException(\"Copy of file \" + file + \" size \" + file.length()+\n                               \" into file \" + tmpFile +\n                               \" resulted in a size of \" + tmpFile.length());\n       }\n-      FileUtil.replaceFile(tmpFile, file);\n+      replaceFile(tmpFile, file);\n     } catch (IOException e) {\n       boolean done \u003d tmpFile.delete();\n       if (!done) {\n         DataNode.LOG.info(\"detachFile failed to delete temporary file \" +\n                           tmpFile);\n       }\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void breakHardlinks(File file, Block b) throws IOException {\n    File tmpFile \u003d DatanodeUtil.createTmpFile(b, DatanodeUtil.getUnlinkTmpFile(file));\n    try (FileInputStream in \u003d new FileInputStream(file)) {\n      try (FileOutputStream out \u003d new FileOutputStream(tmpFile)){\n        copyBytes(in, out, 16 * 1024);\n      }\n      if (file.length() !\u003d tmpFile.length()) {\n        throw new IOException(\"Copy of file \" + file + \" size \" + file.length()+\n                              \" into file \" + tmpFile +\n                              \" resulted in a size of \" + tmpFile.length());\n      }\n      replaceFile(tmpFile, file);\n    } catch (IOException e) {\n      boolean done \u003d tmpFile.delete();\n      if (!done) {\n        DataNode.LOG.info(\"detachFile failed to delete temporary file \" +\n                          tmpFile);\n      }\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/LocalReplica.java",
      "extendedDetails": {}
    },
    "dcedb72af468128458e597f08d22f5c34b744ae5": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HADOOP-10930. Refactor: Wrap Datanode IO related operations. Contributed by Xiaoyu Yao.\"\n\nThis reverts commit aeecfa24f4fb6af289920cbf8830c394e66bd78e.\n",
      "commitDate": "05/12/16 12:44 PM",
      "commitName": "dcedb72af468128458e597f08d22f5c34b744ae5",
      "commitAuthor": "Xiaoyu Yao",
      "commitDateOld": "29/11/16 8:52 PM",
      "commitNameOld": "aeecfa24f4fb6af289920cbf8830c394e66bd78e",
      "commitAuthorOld": "Xiaoyu Yao",
      "daysBetweenCommits": 5.66,
      "commitsBetweenForRepo": 32,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,21 @@\n   private void breakHardlinks(File file, Block b) throws IOException {\n     File tmpFile \u003d DatanodeUtil.createTmpFile(b, DatanodeUtil.getUnlinkTmpFile(file));\n     try (FileInputStream in \u003d new FileInputStream(file)) {\n       try (FileOutputStream out \u003d new FileOutputStream(tmpFile)){\n-        copyBytes(in, out, 16 * 1024);\n+        IOUtils.copyBytes(in, out, 16 * 1024);\n       }\n       if (file.length() !\u003d tmpFile.length()) {\n         throw new IOException(\"Copy of file \" + file + \" size \" + file.length()+\n                               \" into file \" + tmpFile +\n                               \" resulted in a size of \" + tmpFile.length());\n       }\n-      replaceFile(tmpFile, file);\n+      FileUtil.replaceFile(tmpFile, file);\n     } catch (IOException e) {\n       boolean done \u003d tmpFile.delete();\n       if (!done) {\n         DataNode.LOG.info(\"detachFile failed to delete temporary file \" +\n                           tmpFile);\n       }\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void breakHardlinks(File file, Block b) throws IOException {\n    File tmpFile \u003d DatanodeUtil.createTmpFile(b, DatanodeUtil.getUnlinkTmpFile(file));\n    try (FileInputStream in \u003d new FileInputStream(file)) {\n      try (FileOutputStream out \u003d new FileOutputStream(tmpFile)){\n        IOUtils.copyBytes(in, out, 16 * 1024);\n      }\n      if (file.length() !\u003d tmpFile.length()) {\n        throw new IOException(\"Copy of file \" + file + \" size \" + file.length()+\n                              \" into file \" + tmpFile +\n                              \" resulted in a size of \" + tmpFile.length());\n      }\n      FileUtil.replaceFile(tmpFile, file);\n    } catch (IOException e) {\n      boolean done \u003d tmpFile.delete();\n      if (!done) {\n        DataNode.LOG.info(\"detachFile failed to delete temporary file \" +\n                          tmpFile);\n      }\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/LocalReplica.java",
      "extendedDetails": {}
    },
    "aeecfa24f4fb6af289920cbf8830c394e66bd78e": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-10930. Refactor: Wrap Datanode IO related operations. Contributed by Xiaoyu Yao.\n",
      "commitDate": "29/11/16 8:52 PM",
      "commitName": "aeecfa24f4fb6af289920cbf8830c394e66bd78e",
      "commitAuthor": "Xiaoyu Yao",
      "commitDateOld": "26/10/16 10:32 AM",
      "commitNameOld": "f209e93566b159c22054dcb276e45f23a2b7b7d1",
      "commitAuthorOld": "Lei Xu",
      "daysBetweenCommits": 34.47,
      "commitsBetweenForRepo": 293,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,21 @@\n   private void breakHardlinks(File file, Block b) throws IOException {\n     File tmpFile \u003d DatanodeUtil.createTmpFile(b, DatanodeUtil.getUnlinkTmpFile(file));\n     try (FileInputStream in \u003d new FileInputStream(file)) {\n       try (FileOutputStream out \u003d new FileOutputStream(tmpFile)){\n-        IOUtils.copyBytes(in, out, 16 * 1024);\n+        copyBytes(in, out, 16 * 1024);\n       }\n       if (file.length() !\u003d tmpFile.length()) {\n         throw new IOException(\"Copy of file \" + file + \" size \" + file.length()+\n                               \" into file \" + tmpFile +\n                               \" resulted in a size of \" + tmpFile.length());\n       }\n-      FileUtil.replaceFile(tmpFile, file);\n+      replaceFile(tmpFile, file);\n     } catch (IOException e) {\n       boolean done \u003d tmpFile.delete();\n       if (!done) {\n         DataNode.LOG.info(\"detachFile failed to delete temporary file \" +\n                           tmpFile);\n       }\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void breakHardlinks(File file, Block b) throws IOException {\n    File tmpFile \u003d DatanodeUtil.createTmpFile(b, DatanodeUtil.getUnlinkTmpFile(file));\n    try (FileInputStream in \u003d new FileInputStream(file)) {\n      try (FileOutputStream out \u003d new FileOutputStream(tmpFile)){\n        copyBytes(in, out, 16 * 1024);\n      }\n      if (file.length() !\u003d tmpFile.length()) {\n        throw new IOException(\"Copy of file \" + file + \" size \" + file.length()+\n                              \" into file \" + tmpFile +\n                              \" resulted in a size of \" + tmpFile.length());\n      }\n      replaceFile(tmpFile, file);\n    } catch (IOException e) {\n      boolean done \u003d tmpFile.delete();\n      if (!done) {\n        DataNode.LOG.info(\"detachFile failed to delete temporary file \" +\n                          tmpFile);\n      }\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/LocalReplica.java",
      "extendedDetails": {}
    },
    "86c9862bec0248d671e657aa56094a2919b8ac14": {
      "type": "Ymultichange(Ymovefromfile,Ybodychange)",
      "commitMessage": "HDFS-10636. Modify ReplicaInfo to remove the assumption that replica metadata and data are stored in java.io.File. (Virajith Jalaparti via lei)\n",
      "commitDate": "13/09/16 12:54 PM",
      "commitName": "86c9862bec0248d671e657aa56094a2919b8ac14",
      "commitAuthor": "Lei Xu",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-10636. Modify ReplicaInfo to remove the assumption that replica metadata and data are stored in java.io.File. (Virajith Jalaparti via lei)\n",
          "commitDate": "13/09/16 12:54 PM",
          "commitName": "86c9862bec0248d671e657aa56094a2919b8ac14",
          "commitAuthor": "Lei Xu",
          "commitDateOld": "13/09/16 12:42 PM",
          "commitNameOld": "1c0d18f32289837b8981aed80e7bdcd360adfb85",
          "commitAuthorOld": "Anu Engineer",
          "daysBetweenCommits": 0.01,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,29 +1,21 @@\n   private void breakHardlinks(File file, Block b) throws IOException {\n     File tmpFile \u003d DatanodeUtil.createTmpFile(b, DatanodeUtil.getUnlinkTmpFile(file));\n-    try {\n-      FileInputStream in \u003d new FileInputStream(file);\n-      try {\n-        FileOutputStream out \u003d new FileOutputStream(tmpFile);\n-        try {\n-          IOUtils.copyBytes(in, out, 16 * 1024);\n-        } finally {\n-          out.close();\n-        }\n-      } finally {\n-        in.close();\n+    try (FileInputStream in \u003d new FileInputStream(file)) {\n+      try (FileOutputStream out \u003d new FileOutputStream(tmpFile)){\n+        IOUtils.copyBytes(in, out, 16 * 1024);\n       }\n       if (file.length() !\u003d tmpFile.length()) {\n         throw new IOException(\"Copy of file \" + file + \" size \" + file.length()+\n                               \" into file \" + tmpFile +\n                               \" resulted in a size of \" + tmpFile.length());\n       }\n       FileUtil.replaceFile(tmpFile, file);\n     } catch (IOException e) {\n       boolean done \u003d tmpFile.delete();\n       if (!done) {\n         DataNode.LOG.info(\"detachFile failed to delete temporary file \" +\n                           tmpFile);\n       }\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void breakHardlinks(File file, Block b) throws IOException {\n    File tmpFile \u003d DatanodeUtil.createTmpFile(b, DatanodeUtil.getUnlinkTmpFile(file));\n    try (FileInputStream in \u003d new FileInputStream(file)) {\n      try (FileOutputStream out \u003d new FileOutputStream(tmpFile)){\n        IOUtils.copyBytes(in, out, 16 * 1024);\n      }\n      if (file.length() !\u003d tmpFile.length()) {\n        throw new IOException(\"Copy of file \" + file + \" size \" + file.length()+\n                              \" into file \" + tmpFile +\n                              \" resulted in a size of \" + tmpFile.length());\n      }\n      FileUtil.replaceFile(tmpFile, file);\n    } catch (IOException e) {\n      boolean done \u003d tmpFile.delete();\n      if (!done) {\n        DataNode.LOG.info(\"detachFile failed to delete temporary file \" +\n                          tmpFile);\n      }\n      throw e;\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/LocalReplica.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/ReplicaInfo.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/LocalReplica.java",
            "oldMethodName": "breakHardlinks",
            "newMethodName": "breakHardlinks"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-10636. Modify ReplicaInfo to remove the assumption that replica metadata and data are stored in java.io.File. (Virajith Jalaparti via lei)\n",
          "commitDate": "13/09/16 12:54 PM",
          "commitName": "86c9862bec0248d671e657aa56094a2919b8ac14",
          "commitAuthor": "Lei Xu",
          "commitDateOld": "13/09/16 12:42 PM",
          "commitNameOld": "1c0d18f32289837b8981aed80e7bdcd360adfb85",
          "commitAuthorOld": "Anu Engineer",
          "daysBetweenCommits": 0.01,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,29 +1,21 @@\n   private void breakHardlinks(File file, Block b) throws IOException {\n     File tmpFile \u003d DatanodeUtil.createTmpFile(b, DatanodeUtil.getUnlinkTmpFile(file));\n-    try {\n-      FileInputStream in \u003d new FileInputStream(file);\n-      try {\n-        FileOutputStream out \u003d new FileOutputStream(tmpFile);\n-        try {\n-          IOUtils.copyBytes(in, out, 16 * 1024);\n-        } finally {\n-          out.close();\n-        }\n-      } finally {\n-        in.close();\n+    try (FileInputStream in \u003d new FileInputStream(file)) {\n+      try (FileOutputStream out \u003d new FileOutputStream(tmpFile)){\n+        IOUtils.copyBytes(in, out, 16 * 1024);\n       }\n       if (file.length() !\u003d tmpFile.length()) {\n         throw new IOException(\"Copy of file \" + file + \" size \" + file.length()+\n                               \" into file \" + tmpFile +\n                               \" resulted in a size of \" + tmpFile.length());\n       }\n       FileUtil.replaceFile(tmpFile, file);\n     } catch (IOException e) {\n       boolean done \u003d tmpFile.delete();\n       if (!done) {\n         DataNode.LOG.info(\"detachFile failed to delete temporary file \" +\n                           tmpFile);\n       }\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void breakHardlinks(File file, Block b) throws IOException {\n    File tmpFile \u003d DatanodeUtil.createTmpFile(b, DatanodeUtil.getUnlinkTmpFile(file));\n    try (FileInputStream in \u003d new FileInputStream(file)) {\n      try (FileOutputStream out \u003d new FileOutputStream(tmpFile)){\n        IOUtils.copyBytes(in, out, 16 * 1024);\n      }\n      if (file.length() !\u003d tmpFile.length()) {\n        throw new IOException(\"Copy of file \" + file + \" size \" + file.length()+\n                              \" into file \" + tmpFile +\n                              \" resulted in a size of \" + tmpFile.length());\n      }\n      FileUtil.replaceFile(tmpFile, file);\n    } catch (IOException e) {\n      boolean done \u003d tmpFile.delete();\n      if (!done) {\n        DataNode.LOG.info(\"detachFile failed to delete temporary file \" +\n                          tmpFile);\n      }\n      throw e;\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/LocalReplica.java",
          "extendedDetails": {}
        }
      ]
    },
    "bb540ba85aa37d9fe31e640665158afe8a936230": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-9589. Block files which have been hardlinked should be duplicated before the DataNode appends to the them (cmccabe)\n",
      "commitDate": "22/12/15 9:36 AM",
      "commitName": "bb540ba85aa37d9fe31e640665158afe8a936230",
      "commitAuthor": "Colin Patrick Mccabe",
      "diff": "@@ -0,0 +1,29 @@\n+  private void breakHardlinks(File file, Block b) throws IOException {\n+    File tmpFile \u003d DatanodeUtil.createTmpFile(b, DatanodeUtil.getUnlinkTmpFile(file));\n+    try {\n+      FileInputStream in \u003d new FileInputStream(file);\n+      try {\n+        FileOutputStream out \u003d new FileOutputStream(tmpFile);\n+        try {\n+          IOUtils.copyBytes(in, out, 16 * 1024);\n+        } finally {\n+          out.close();\n+        }\n+      } finally {\n+        in.close();\n+      }\n+      if (file.length() !\u003d tmpFile.length()) {\n+        throw new IOException(\"Copy of file \" + file + \" size \" + file.length()+\n+                              \" into file \" + tmpFile +\n+                              \" resulted in a size of \" + tmpFile.length());\n+      }\n+      FileUtil.replaceFile(tmpFile, file);\n+    } catch (IOException e) {\n+      boolean done \u003d tmpFile.delete();\n+      if (!done) {\n+        DataNode.LOG.info(\"detachFile failed to delete temporary file \" +\n+                          tmpFile);\n+      }\n+      throw e;\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void breakHardlinks(File file, Block b) throws IOException {\n    File tmpFile \u003d DatanodeUtil.createTmpFile(b, DatanodeUtil.getUnlinkTmpFile(file));\n    try {\n      FileInputStream in \u003d new FileInputStream(file);\n      try {\n        FileOutputStream out \u003d new FileOutputStream(tmpFile);\n        try {\n          IOUtils.copyBytes(in, out, 16 * 1024);\n        } finally {\n          out.close();\n        }\n      } finally {\n        in.close();\n      }\n      if (file.length() !\u003d tmpFile.length()) {\n        throw new IOException(\"Copy of file \" + file + \" size \" + file.length()+\n                              \" into file \" + tmpFile +\n                              \" resulted in a size of \" + tmpFile.length());\n      }\n      FileUtil.replaceFile(tmpFile, file);\n    } catch (IOException e) {\n      boolean done \u003d tmpFile.delete();\n      if (!done) {\n        DataNode.LOG.info(\"detachFile failed to delete temporary file \" +\n                          tmpFile);\n      }\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/ReplicaInfo.java"
    }
  }
}