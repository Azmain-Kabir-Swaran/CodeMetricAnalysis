{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "S3AInputStream.java",
  "functionName": "setReadahead",
  "functionId": "setReadahead___readahead-Long",
  "sourceFilePath": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AInputStream.java",
  "functionStartLine": 755,
  "functionEndLine": 757,
  "numCommitsSeen": 28,
  "timeTaken": 1830,
  "changeHistory": [
    "f365957c6326f88734bc0a5d01cfb7eac713db20",
    "4ee3543625c77c06d566fe81644d21c607d6d74d",
    "27c4e90efce04e1b1302f668b5eb22412e00d033"
  ],
  "changeHistoryShort": {
    "f365957c6326f88734bc0a5d01cfb7eac713db20": "Ybodychange",
    "4ee3543625c77c06d566fe81644d21c607d6d74d": "Ymodifierchange",
    "27c4e90efce04e1b1302f668b5eb22412e00d033": "Yintroduced"
  },
  "changeHistoryDetails": {
    "f365957c6326f88734bc0a5d01cfb7eac713db20": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-15229. Add FileSystem builder-based openFile() API to match createFile();\nS3A to implement S3 Select through this API.\n\nThe new openFile() API is asynchronous, and implemented across FileSystem and FileContext.\n\nThe MapReduce V2 inputs are moved to this API, and you can actually set must/may\noptions to pass in.\n\nThis is more useful for setting things like s3a seek policy than for S3 select,\nas the existing input format/record readers can\u0027t handle S3 select output where\nthe stream is shorter than the file length, and splitting plain text is suboptimal.\nFuture work is needed there.\n\nIn the meantime, any/all filesystem connectors are now free to add their own filesystem-specific\nconfiguration parameters which can be set in jobs and used to set filesystem input stream\noptions (seek policy, retry, encryption secrets, etc).\n\nContributed by Steve Loughran\n",
      "commitDate": "05/02/19 3:51 AM",
      "commitName": "f365957c6326f88734bc0a5d01cfb7eac713db20",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "10/07/18 8:52 AM",
      "commitNameOld": "d503f65b6689b19278ec2a0cf9da5a8762539de8",
      "commitAuthorOld": "Sean Mackrory",
      "daysBetweenCommits": 209.83,
      "commitsBetweenForRepo": 1641,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,8 +1,3 @@\n   public synchronized void setReadahead(Long readahead) {\n-    if (readahead \u003d\u003d null) {\n-      this.readahead \u003d Constants.DEFAULT_READAHEAD_RANGE;\n-    } else {\n-      Preconditions.checkArgument(readahead \u003e\u003d 0, \"Negative readahead value\");\n-      this.readahead \u003d readahead;\n-    }\n+    this.readahead \u003d validateReadahead(readahead);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void setReadahead(Long readahead) {\n    this.readahead \u003d validateReadahead(readahead);\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AInputStream.java",
      "extendedDetails": {}
    },
    "4ee3543625c77c06d566fe81644d21c607d6d74d": {
      "type": "Ymodifierchange",
      "commitMessage": "HADOOP-13203 S3A: Support fadvise \"random\" mode for high performance readPositioned() reads. Contributed by Rajesh Balamohan and stevel.\n",
      "commitDate": "22/06/16 7:45 AM",
      "commitName": "4ee3543625c77c06d566fe81644d21c607d6d74d",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "21/05/16 8:39 AM",
      "commitNameOld": "39ec1515a205952eda7e171408a8b83eceb4abde",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 31.96,
      "commitsBetweenForRepo": 198,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,8 +1,8 @@\n-  public void setReadahead(Long readahead) {\n+  public synchronized void setReadahead(Long readahead) {\n     if (readahead \u003d\u003d null) {\n       this.readahead \u003d Constants.DEFAULT_READAHEAD_RANGE;\n     } else {\n       Preconditions.checkArgument(readahead \u003e\u003d 0, \"Negative readahead value\");\n       this.readahead \u003d readahead;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void setReadahead(Long readahead) {\n    if (readahead \u003d\u003d null) {\n      this.readahead \u003d Constants.DEFAULT_READAHEAD_RANGE;\n    } else {\n      Preconditions.checkArgument(readahead \u003e\u003d 0, \"Negative readahead value\");\n      this.readahead \u003d readahead;\n    }\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AInputStream.java",
      "extendedDetails": {
        "oldValue": "[public]",
        "newValue": "[public, synchronized]"
      }
    },
    "27c4e90efce04e1b1302f668b5eb22412e00d033": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-13028 add low level counter metrics for S3A; use in read performance tests. contributed by: stevel\npatch includes\nHADOOP-12844 Recover when S3A fails on IOException in read()\nHADOOP-13058 S3A FS fails during init against a read-only FS if multipart purge\nHADOOP-13047 S3a Forward seek in stream length to be configurable\n",
      "commitDate": "12/05/16 11:24 AM",
      "commitName": "27c4e90efce04e1b1302f668b5eb22412e00d033",
      "commitAuthor": "Steve Loughran",
      "diff": "@@ -0,0 +1,8 @@\n+  public void setReadahead(Long readahead) {\n+    if (readahead \u003d\u003d null) {\n+      this.readahead \u003d Constants.DEFAULT_READAHEAD_RANGE;\n+    } else {\n+      Preconditions.checkArgument(readahead \u003e\u003d 0, \"Negative readahead value\");\n+      this.readahead \u003d readahead;\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void setReadahead(Long readahead) {\n    if (readahead \u003d\u003d null) {\n      this.readahead \u003d Constants.DEFAULT_READAHEAD_RANGE;\n    } else {\n      Preconditions.checkArgument(readahead \u003e\u003d 0, \"Negative readahead value\");\n      this.readahead \u003d readahead;\n    }\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AInputStream.java"
    }
  }
}