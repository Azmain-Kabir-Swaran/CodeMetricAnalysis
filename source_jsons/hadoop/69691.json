{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "AbfsOutputStream.java",
  "functionName": "shrinkWriteOperationQueue",
  "functionId": "shrinkWriteOperationQueue",
  "sourceFilePath": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java",
  "functionStartLine": 413,
  "functionEndLine": 430,
  "numCommitsSeen": 19,
  "timeTaken": 2503,
  "changeHistory": [
    "459eb2ad6d5bc6b21462e728fb334c6e30e14c39",
    "745a6c1e69b3699f6496a146afc48824dd735461",
    "3612317038196ee0cb6d7204056d54b7a7ed8bf7",
    "ce03a93f78c4d97ccb48a3906fcd77ad0ac756be",
    "f044deedbbfee0812316d587139cb828f27172e9"
  ],
  "changeHistoryShort": {
    "459eb2ad6d5bc6b21462e728fb334c6e30e14c39": "Ybodychange",
    "745a6c1e69b3699f6496a146afc48824dd735461": "Ybodychange",
    "3612317038196ee0cb6d7204056d54b7a7ed8bf7": "Ybodychange",
    "ce03a93f78c4d97ccb48a3906fcd77ad0ac756be": "Ybodychange",
    "f044deedbbfee0812316d587139cb828f27172e9": "Yintroduced"
  },
  "changeHistoryDetails": {
    "459eb2ad6d5bc6b21462e728fb334c6e30e14c39": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-16914 Adding Output Stream Counters in ABFS (#1899)\n\n\r\nContributed by Mehakmeet Singh.There",
      "commitDate": "23/04/20 5:35 AM",
      "commitName": "459eb2ad6d5bc6b21462e728fb334c6e30e14c39",
      "commitAuthor": "Mehakmeet Singh",
      "commitDateOld": "21/04/20 9:27 AM",
      "commitNameOld": "8031c66295b530dcaae9e00d4f656330bc3b3952",
      "commitAuthorOld": "Mukund Thakur",
      "daysBetweenCommits": 1.84,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,18 @@\n   private synchronized void shrinkWriteOperationQueue() throws IOException {\n     try {\n       while (writeOperations.peek() !\u003d null \u0026\u0026 writeOperations.peek().task.isDone()) {\n         writeOperations.peek().task.get();\n         lastTotalAppendOffset +\u003d writeOperations.peek().length;\n         writeOperations.remove();\n+        // Incrementing statistics to indicate queue has been shrunk.\n+        outputStreamStatistics.queueShrunk();\n       }\n     } catch (Exception e) {\n       if (e.getCause() instanceof AzureBlobFileSystemException) {\n         lastError \u003d (AzureBlobFileSystemException) e.getCause();\n       } else {\n         lastError \u003d new IOException(e);\n       }\n       throw lastError;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void shrinkWriteOperationQueue() throws IOException {\n    try {\n      while (writeOperations.peek() !\u003d null \u0026\u0026 writeOperations.peek().task.isDone()) {\n        writeOperations.peek().task.get();\n        lastTotalAppendOffset +\u003d writeOperations.peek().length;\n        writeOperations.remove();\n        // Incrementing statistics to indicate queue has been shrunk.\n        outputStreamStatistics.queueShrunk();\n      }\n    } catch (Exception e) {\n      if (e.getCause() instanceof AzureBlobFileSystemException) {\n        lastError \u003d (AzureBlobFileSystemException) e.getCause();\n      } else {\n        lastError \u003d new IOException(e);\n      }\n      throw lastError;\n    }\n  }",
      "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java",
      "extendedDetails": {}
    },
    "745a6c1e69b3699f6496a146afc48824dd735461": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HADOOP-16818. ABFS: Combine append+flush calls for blockblob \u0026 appendblob\"\n\nThis reverts commit 3612317038196ee0cb6d7204056d54b7a7ed8bf7.\n\nChange-Id: Ie0d36f25de0b55a937894f4d9963c495bae0576a\n",
      "commitDate": "26/03/20 8:24 AM",
      "commitName": "745a6c1e69b3699f6496a146afc48824dd735461",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "24/03/20 5:11 AM",
      "commitNameOld": "28afdce00955a51bbea9bf46aa0f784764ec1329",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 2.13,
      "commitsBetweenForRepo": 18,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,19 +1,16 @@\n   private synchronized void shrinkWriteOperationQueue() throws IOException {\n     try {\n       while (writeOperations.peek() !\u003d null \u0026\u0026 writeOperations.peek().task.isDone()) {\n         writeOperations.peek().task.get();\n         lastTotalAppendOffset +\u003d writeOperations.peek().length;\n-        if (writeOperations.peek().isFlush) {\n-          lastFlushOffset \u003d lastTotalAppendOffset;\n-        }\n         writeOperations.remove();\n       }\n     } catch (Exception e) {\n       if (e.getCause() instanceof AzureBlobFileSystemException) {\n         lastError \u003d (AzureBlobFileSystemException) e.getCause();\n       } else {\n         lastError \u003d new IOException(e);\n       }\n       throw lastError;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void shrinkWriteOperationQueue() throws IOException {\n    try {\n      while (writeOperations.peek() !\u003d null \u0026\u0026 writeOperations.peek().task.isDone()) {\n        writeOperations.peek().task.get();\n        lastTotalAppendOffset +\u003d writeOperations.peek().length;\n        writeOperations.remove();\n      }\n    } catch (Exception e) {\n      if (e.getCause() instanceof AzureBlobFileSystemException) {\n        lastError \u003d (AzureBlobFileSystemException) e.getCause();\n      } else {\n        lastError \u003d new IOException(e);\n      }\n      throw lastError;\n    }\n  }",
      "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java",
      "extendedDetails": {}
    },
    "3612317038196ee0cb6d7204056d54b7a7ed8bf7": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-16818. ABFS: Combine append+flush calls for blockblob \u0026 appendblob\n\n\r\nContributed by Ishani Ahuja.",
      "commitDate": "20/03/20 3:27 AM",
      "commitName": "3612317038196ee0cb6d7204056d54b7a7ed8bf7",
      "commitAuthor": "ishaniahuja",
      "commitDateOld": "08/01/20 3:46 AM",
      "commitNameOld": "17aa8f6764262767b42717cf190a53e2c1795507",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 71.94,
      "commitsBetweenForRepo": 247,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,19 @@\n   private synchronized void shrinkWriteOperationQueue() throws IOException {\n     try {\n       while (writeOperations.peek() !\u003d null \u0026\u0026 writeOperations.peek().task.isDone()) {\n         writeOperations.peek().task.get();\n         lastTotalAppendOffset +\u003d writeOperations.peek().length;\n+        if (writeOperations.peek().isFlush) {\n+          lastFlushOffset \u003d lastTotalAppendOffset;\n+        }\n         writeOperations.remove();\n       }\n     } catch (Exception e) {\n       if (e.getCause() instanceof AzureBlobFileSystemException) {\n         lastError \u003d (AzureBlobFileSystemException) e.getCause();\n       } else {\n         lastError \u003d new IOException(e);\n       }\n       throw lastError;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void shrinkWriteOperationQueue() throws IOException {\n    try {\n      while (writeOperations.peek() !\u003d null \u0026\u0026 writeOperations.peek().task.isDone()) {\n        writeOperations.peek().task.get();\n        lastTotalAppendOffset +\u003d writeOperations.peek().length;\n        if (writeOperations.peek().isFlush) {\n          lastFlushOffset \u003d lastTotalAppendOffset;\n        }\n        writeOperations.remove();\n      }\n    } catch (Exception e) {\n      if (e.getCause() instanceof AzureBlobFileSystemException) {\n        lastError \u003d (AzureBlobFileSystemException) e.getCause();\n      } else {\n        lastError \u003d new IOException(e);\n      }\n      throw lastError;\n    }\n  }",
      "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java",
      "extendedDetails": {}
    },
    "ce03a93f78c4d97ccb48a3906fcd77ad0ac756be": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-15446. ABFS: tune imports \u0026 javadocs; stabilise tests.\nContributed by Steve Loughran and Da Zhou.\n",
      "commitDate": "17/09/18 12:54 PM",
      "commitName": "ce03a93f78c4d97ccb48a3906fcd77ad0ac756be",
      "commitAuthor": "Thomas Marquardt",
      "commitDateOld": "17/09/18 12:54 PM",
      "commitNameOld": "f044deedbbfee0812316d587139cb828f27172e9",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,16 @@\n   private synchronized void shrinkWriteOperationQueue() throws IOException {\n     try {\n-      while (this.writeOperations.peek() !\u003d null \u0026\u0026 this.writeOperations.peek().task.isDone()) {\n-        this.writeOperations.peek().task.get();\n-        this.lastTotalAppendOffset +\u003d this.writeOperations.peek().length;\n-        this.writeOperations.remove();\n+      while (writeOperations.peek() !\u003d null \u0026\u0026 writeOperations.peek().task.isDone()) {\n+        writeOperations.peek().task.get();\n+        lastTotalAppendOffset +\u003d writeOperations.peek().length;\n+        writeOperations.remove();\n       }\n     } catch (Exception e) {\n-      if (AzureBlobFileSystemException.class.isInstance(e.getCause())) {\n-        this.lastError \u003d IOException.class.cast(e.getCause());\n+      if (e.getCause() instanceof AzureBlobFileSystemException) {\n+        lastError \u003d (AzureBlobFileSystemException)e.getCause();\n       } else {\n-        this.lastError \u003d new IOException(e);\n+        lastError \u003d new IOException(e);\n       }\n-      throw this.lastError;\n+      throw lastError;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void shrinkWriteOperationQueue() throws IOException {\n    try {\n      while (writeOperations.peek() !\u003d null \u0026\u0026 writeOperations.peek().task.isDone()) {\n        writeOperations.peek().task.get();\n        lastTotalAppendOffset +\u003d writeOperations.peek().length;\n        writeOperations.remove();\n      }\n    } catch (Exception e) {\n      if (e.getCause() instanceof AzureBlobFileSystemException) {\n        lastError \u003d (AzureBlobFileSystemException)e.getCause();\n      } else {\n        lastError \u003d new IOException(e);\n      }\n      throw lastError;\n    }\n  }",
      "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java",
      "extendedDetails": {}
    },
    "f044deedbbfee0812316d587139cb828f27172e9": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-15407. HADOOP-15540. Support Windows Azure Storage - Blob file system \"ABFS\" in Hadoop: Core Commit.\n\nContributed by Shane Mainali, Thomas Marquardt, Zichen Sun, Georgi Chalakov, Esfandiar Manii, Amit Singh, Dana Kaban, Da Zhou, Junhua Gu, Saher Ahwal, Saurabh Pant, James Baker, Shaoyu Zhang, Lawrence Chen, Kevin Chen and Steve Loughran\n",
      "commitDate": "17/09/18 12:54 PM",
      "commitName": "f044deedbbfee0812316d587139cb828f27172e9",
      "commitAuthor": "Steve Loughran",
      "diff": "@@ -0,0 +1,16 @@\n+  private synchronized void shrinkWriteOperationQueue() throws IOException {\n+    try {\n+      while (this.writeOperations.peek() !\u003d null \u0026\u0026 this.writeOperations.peek().task.isDone()) {\n+        this.writeOperations.peek().task.get();\n+        this.lastTotalAppendOffset +\u003d this.writeOperations.peek().length;\n+        this.writeOperations.remove();\n+      }\n+    } catch (Exception e) {\n+      if (AzureBlobFileSystemException.class.isInstance(e.getCause())) {\n+        this.lastError \u003d IOException.class.cast(e.getCause());\n+      } else {\n+        this.lastError \u003d new IOException(e);\n+      }\n+      throw this.lastError;\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void shrinkWriteOperationQueue() throws IOException {\n    try {\n      while (this.writeOperations.peek() !\u003d null \u0026\u0026 this.writeOperations.peek().task.isDone()) {\n        this.writeOperations.peek().task.get();\n        this.lastTotalAppendOffset +\u003d this.writeOperations.peek().length;\n        this.writeOperations.remove();\n      }\n    } catch (Exception e) {\n      if (AzureBlobFileSystemException.class.isInstance(e.getCause())) {\n        this.lastError \u003d IOException.class.cast(e.getCause());\n      } else {\n        this.lastError \u003d new IOException(e);\n      }\n      throw this.lastError;\n    }\n  }",
      "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java"
    }
  }
}