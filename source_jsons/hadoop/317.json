{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DFSStripedInputStream.java",
  "functionName": "resetCurStripeBuffer",
  "functionId": "resetCurStripeBuffer___shouldAllocateBuf-boolean",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSStripedInputStream.java",
  "functionStartLine": 122,
  "functionEndLine": 131,
  "numCommitsSeen": 46,
  "timeTaken": 2067,
  "changeHistory": [
    "34e8b9f9a86fb03156861482643fba11bdee1dd4",
    "734d54c1a8950446e68098f62d8964e02ecc2890",
    "b5af9be72c72734d668f817c99d889031922a951"
  ],
  "changeHistoryShort": {
    "34e8b9f9a86fb03156861482643fba11bdee1dd4": "Ymultichange(Yparameterchange,Ymodifierchange,Ybodychange)",
    "734d54c1a8950446e68098f62d8964e02ecc2890": "Ymodifierchange",
    "b5af9be72c72734d668f817c99d889031922a951": "Ybodychange"
  },
  "changeHistoryDetails": {
    "34e8b9f9a86fb03156861482643fba11bdee1dd4": {
      "type": "Ymultichange(Yparameterchange,Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-13540. DFSStripedInputStream should only allocate new buffers when reading. Contributed by Xiao Chen.\n",
      "commitDate": "23/05/18 4:10 AM",
      "commitName": "34e8b9f9a86fb03156861482643fba11bdee1dd4",
      "commitAuthor": "Sammi Chen",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-13540. DFSStripedInputStream should only allocate new buffers when reading. Contributed by Xiao Chen.\n",
          "commitDate": "23/05/18 4:10 AM",
          "commitName": "34e8b9f9a86fb03156861482643fba11bdee1dd4",
          "commitAuthor": "Sammi Chen",
          "commitDateOld": "14/05/18 9:28 AM",
          "commitNameOld": "960940e0e08f7839775f2d8a352b444d104d36b4",
          "commitAuthorOld": "Xiao Chen",
          "daysBetweenCommits": 8.78,
          "commitsBetweenForRepo": 76,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,8 +1,10 @@\n-  void resetCurStripeBuffer() {\n-    if (curStripeBuf \u003d\u003d null) {\n+  private void resetCurStripeBuffer(boolean shouldAllocateBuf) {\n+    if (shouldAllocateBuf \u0026\u0026 curStripeBuf \u003d\u003d null) {\n       curStripeBuf \u003d BUFFER_POOL.getBuffer(useDirectBuffer(),\n           cellSize * dataBlkNum);\n     }\n-    curStripeBuf.clear();\n+    if (curStripeBuf !\u003d null) {\n+      curStripeBuf.clear();\n+    }\n     curStripeRange \u003d new StripeRange(0, 0);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void resetCurStripeBuffer(boolean shouldAllocateBuf) {\n    if (shouldAllocateBuf \u0026\u0026 curStripeBuf \u003d\u003d null) {\n      curStripeBuf \u003d BUFFER_POOL.getBuffer(useDirectBuffer(),\n          cellSize * dataBlkNum);\n    }\n    if (curStripeBuf !\u003d null) {\n      curStripeBuf.clear();\n    }\n    curStripeRange \u003d new StripeRange(0, 0);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSStripedInputStream.java",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[shouldAllocateBuf-boolean]"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-13540. DFSStripedInputStream should only allocate new buffers when reading. Contributed by Xiao Chen.\n",
          "commitDate": "23/05/18 4:10 AM",
          "commitName": "34e8b9f9a86fb03156861482643fba11bdee1dd4",
          "commitAuthor": "Sammi Chen",
          "commitDateOld": "14/05/18 9:28 AM",
          "commitNameOld": "960940e0e08f7839775f2d8a352b444d104d36b4",
          "commitAuthorOld": "Xiao Chen",
          "daysBetweenCommits": 8.78,
          "commitsBetweenForRepo": 76,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,8 +1,10 @@\n-  void resetCurStripeBuffer() {\n-    if (curStripeBuf \u003d\u003d null) {\n+  private void resetCurStripeBuffer(boolean shouldAllocateBuf) {\n+    if (shouldAllocateBuf \u0026\u0026 curStripeBuf \u003d\u003d null) {\n       curStripeBuf \u003d BUFFER_POOL.getBuffer(useDirectBuffer(),\n           cellSize * dataBlkNum);\n     }\n-    curStripeBuf.clear();\n+    if (curStripeBuf !\u003d null) {\n+      curStripeBuf.clear();\n+    }\n     curStripeRange \u003d new StripeRange(0, 0);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void resetCurStripeBuffer(boolean shouldAllocateBuf) {\n    if (shouldAllocateBuf \u0026\u0026 curStripeBuf \u003d\u003d null) {\n      curStripeBuf \u003d BUFFER_POOL.getBuffer(useDirectBuffer(),\n          cellSize * dataBlkNum);\n    }\n    if (curStripeBuf !\u003d null) {\n      curStripeBuf.clear();\n    }\n    curStripeRange \u003d new StripeRange(0, 0);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSStripedInputStream.java",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[private]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-13540. DFSStripedInputStream should only allocate new buffers when reading. Contributed by Xiao Chen.\n",
          "commitDate": "23/05/18 4:10 AM",
          "commitName": "34e8b9f9a86fb03156861482643fba11bdee1dd4",
          "commitAuthor": "Sammi Chen",
          "commitDateOld": "14/05/18 9:28 AM",
          "commitNameOld": "960940e0e08f7839775f2d8a352b444d104d36b4",
          "commitAuthorOld": "Xiao Chen",
          "daysBetweenCommits": 8.78,
          "commitsBetweenForRepo": 76,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,8 +1,10 @@\n-  void resetCurStripeBuffer() {\n-    if (curStripeBuf \u003d\u003d null) {\n+  private void resetCurStripeBuffer(boolean shouldAllocateBuf) {\n+    if (shouldAllocateBuf \u0026\u0026 curStripeBuf \u003d\u003d null) {\n       curStripeBuf \u003d BUFFER_POOL.getBuffer(useDirectBuffer(),\n           cellSize * dataBlkNum);\n     }\n-    curStripeBuf.clear();\n+    if (curStripeBuf !\u003d null) {\n+      curStripeBuf.clear();\n+    }\n     curStripeRange \u003d new StripeRange(0, 0);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void resetCurStripeBuffer(boolean shouldAllocateBuf) {\n    if (shouldAllocateBuf \u0026\u0026 curStripeBuf \u003d\u003d null) {\n      curStripeBuf \u003d BUFFER_POOL.getBuffer(useDirectBuffer(),\n          cellSize * dataBlkNum);\n    }\n    if (curStripeBuf !\u003d null) {\n      curStripeBuf.clear();\n    }\n    curStripeRange \u003d new StripeRange(0, 0);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSStripedInputStream.java",
          "extendedDetails": {}
        }
      ]
    },
    "734d54c1a8950446e68098f62d8964e02ecc2890": {
      "type": "Ymodifierchange",
      "commitMessage": "HDFS-10861. Refactor StripeReaders and use ECChunk version decode API. Contributed by Sammi Chen\n",
      "commitDate": "21/09/16 6:34 AM",
      "commitName": "734d54c1a8950446e68098f62d8964e02ecc2890",
      "commitAuthor": "Kai Zheng",
      "commitDateOld": "08/09/16 11:54 AM",
      "commitNameOld": "401db4fc65140979fe7665983e36905e886df971",
      "commitAuthorOld": "Zhe Zhang",
      "daysBetweenCommits": 12.78,
      "commitsBetweenForRepo": 59,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,8 +1,8 @@\n-  private void resetCurStripeBuffer() {\n+  void resetCurStripeBuffer() {\n     if (curStripeBuf \u003d\u003d null) {\n       curStripeBuf \u003d BUFFER_POOL.getBuffer(useDirectBuffer(),\n           cellSize * dataBlkNum);\n     }\n     curStripeBuf.clear();\n     curStripeRange \u003d new StripeRange(0, 0);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void resetCurStripeBuffer() {\n    if (curStripeBuf \u003d\u003d null) {\n      curStripeBuf \u003d BUFFER_POOL.getBuffer(useDirectBuffer(),\n          cellSize * dataBlkNum);\n    }\n    curStripeBuf.clear();\n    curStripeRange \u003d new StripeRange(0, 0);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSStripedInputStream.java",
      "extendedDetails": {
        "oldValue": "[private]",
        "newValue": "[]"
      }
    },
    "b5af9be72c72734d668f817c99d889031922a951": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8668. Erasure Coding: revisit buffer used for encoding and decoding. Contributed by Sammi Chen\n",
      "commitDate": "12/08/16 10:52 PM",
      "commitName": "b5af9be72c72734d668f817c99d889031922a951",
      "commitAuthor": "Kai Zheng",
      "commitDateOld": "26/05/16 10:23 PM",
      "commitNameOld": "77202fa1035a54496d11d07472fbc399148ff630",
      "commitAuthorOld": "Kai Zheng",
      "daysBetweenCommits": 78.02,
      "commitsBetweenForRepo": 643,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,7 +1,8 @@\n   private void resetCurStripeBuffer() {\n     if (curStripeBuf \u003d\u003d null) {\n-      curStripeBuf \u003d bufferPool.getBuffer(cellSize * dataBlkNum);\n+      curStripeBuf \u003d BUFFER_POOL.getBuffer(useDirectBuffer(),\n+          cellSize * dataBlkNum);\n     }\n     curStripeBuf.clear();\n     curStripeRange \u003d new StripeRange(0, 0);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void resetCurStripeBuffer() {\n    if (curStripeBuf \u003d\u003d null) {\n      curStripeBuf \u003d BUFFER_POOL.getBuffer(useDirectBuffer(),\n          cellSize * dataBlkNum);\n    }\n    curStripeBuf.clear();\n    curStripeRange \u003d new StripeRange(0, 0);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSStripedInputStream.java",
      "extendedDetails": {}
    }
  }
}