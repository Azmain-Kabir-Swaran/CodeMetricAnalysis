{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "SlowDiskTracker.java",
  "functionName": "getSlowDiskReportAsJsonString",
  "functionId": "getSlowDiskReportAsJsonString",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/SlowDiskTracker.java",
  "functionStartLine": 261,
  "functionEndLine": 272,
  "numCommitsSeen": 5,
  "timeTaken": 1640,
  "changeHistory": [
    "36fb90c93982a22df7177809c3b0ddae455ebc07",
    "73835c73e2d34b3854a71dd29d88c8303d698ac8",
    "28cdc5a8dc37ade1f45bda3aede589ee8593945e"
  ],
  "changeHistoryShort": {
    "36fb90c93982a22df7177809c3b0ddae455ebc07": "Ybodychange",
    "73835c73e2d34b3854a71dd29d88c8303d698ac8": "Ybodychange",
    "28cdc5a8dc37ade1f45bda3aede589ee8593945e": "Yintroduced"
  },
  "changeHistoryDetails": {
    "36fb90c93982a22df7177809c3b0ddae455ebc07": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12064. Reuse object mapper in HDFS. Contributed by Hanisha Koneru.\n",
      "commitDate": "23/09/17 10:11 AM",
      "commitName": "36fb90c93982a22df7177809c3b0ddae455ebc07",
      "commitAuthor": "Anu Engineer",
      "commitDateOld": "31/03/17 1:50 PM",
      "commitNameOld": "73835c73e2d34b3854a71dd29d88c8303d698ac8",
      "commitAuthorOld": "Hanisha Koneru",
      "daysBetweenCommits": 175.85,
      "commitsBetweenForRepo": 1149,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,12 @@\n   public String getSlowDiskReportAsJsonString() {\n-    ObjectMapper objectMapper \u003d new ObjectMapper();\n     try {\n       if (slowDisksReport.isEmpty()) {\n         return null;\n       }\n-      return objectMapper.writeValueAsString(slowDisksReport);\n+      return WRITER.writeValueAsString(slowDisksReport);\n     } catch (JsonProcessingException e) {\n       // Failed to serialize. Don\u0027t log the exception call stack.\n       LOG.debug(\"Failed to serialize statistics\" + e);\n       return null;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public String getSlowDiskReportAsJsonString() {\n    try {\n      if (slowDisksReport.isEmpty()) {\n        return null;\n      }\n      return WRITER.writeValueAsString(slowDisksReport);\n    } catch (JsonProcessingException e) {\n      // Failed to serialize. Don\u0027t log the exception call stack.\n      LOG.debug(\"Failed to serialize statistics\" + e);\n      return null;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/SlowDiskTracker.java",
      "extendedDetails": {}
    },
    "73835c73e2d34b3854a71dd29d88c8303d698ac8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11560. Expose slow disks via NameNode JMX. Contributed by Hanisha Koneru.\n",
      "commitDate": "31/03/17 1:50 PM",
      "commitName": "73835c73e2d34b3854a71dd29d88c8303d698ac8",
      "commitAuthor": "Hanisha Koneru",
      "commitDateOld": "30/03/17 10:41 PM",
      "commitNameOld": "28cdc5a8dc37ade1f45bda3aede589ee8593945e",
      "commitAuthorOld": "Hanisha Koneru",
      "daysBetweenCommits": 0.63,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,10 +1,13 @@\n   public String getSlowDiskReportAsJsonString() {\n     ObjectMapper objectMapper \u003d new ObjectMapper();\n     try {\n+      if (slowDisksReport.isEmpty()) {\n+        return null;\n+      }\n       return objectMapper.writeValueAsString(slowDisksReport);\n     } catch (JsonProcessingException e) {\n       // Failed to serialize. Don\u0027t log the exception call stack.\n       LOG.debug(\"Failed to serialize statistics\" + e);\n       return null;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public String getSlowDiskReportAsJsonString() {\n    ObjectMapper objectMapper \u003d new ObjectMapper();\n    try {\n      if (slowDisksReport.isEmpty()) {\n        return null;\n      }\n      return objectMapper.writeValueAsString(slowDisksReport);\n    } catch (JsonProcessingException e) {\n      // Failed to serialize. Don\u0027t log the exception call stack.\n      LOG.debug(\"Failed to serialize statistics\" + e);\n      return null;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/SlowDiskTracker.java",
      "extendedDetails": {}
    },
    "28cdc5a8dc37ade1f45bda3aede589ee8593945e": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-11551. Handle SlowDiskReport from DataNode at the NameNode. Contributed by Hanisha Koneru.\n",
      "commitDate": "30/03/17 10:41 PM",
      "commitName": "28cdc5a8dc37ade1f45bda3aede589ee8593945e",
      "commitAuthor": "Hanisha Koneru",
      "diff": "@@ -0,0 +1,10 @@\n+  public String getSlowDiskReportAsJsonString() {\n+    ObjectMapper objectMapper \u003d new ObjectMapper();\n+    try {\n+      return objectMapper.writeValueAsString(slowDisksReport);\n+    } catch (JsonProcessingException e) {\n+      // Failed to serialize. Don\u0027t log the exception call stack.\n+      LOG.debug(\"Failed to serialize statistics\" + e);\n+      return null;\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public String getSlowDiskReportAsJsonString() {\n    ObjectMapper objectMapper \u003d new ObjectMapper();\n    try {\n      return objectMapper.writeValueAsString(slowDisksReport);\n    } catch (JsonProcessingException e) {\n      // Failed to serialize. Don\u0027t log the exception call stack.\n      LOG.debug(\"Failed to serialize statistics\" + e);\n      return null;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/SlowDiskTracker.java"
    }
  }
}