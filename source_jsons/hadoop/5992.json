{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "NamenodeFsck.java",
  "functionName": "listCorruptFileBlocks",
  "functionId": "listCorruptFileBlocks",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java",
  "functionStartLine": 481,
  "functionEndLine": 501,
  "numCommitsSeen": 128,
  "timeTaken": 6231,
  "changeHistory": [
    "97913f430cbe3f82ac866ae6ab8f42754102f6c0",
    "9a3f147fdd5421460889b266ead3a2300323cda2",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "97913f430cbe3f82ac866ae6ab8f42754102f6c0": "Ybodychange",
    "9a3f147fdd5421460889b266ead3a2300323cda2": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "97913f430cbe3f82ac866ae6ab8f42754102f6c0": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9231. fsck doesn\u0027t list correct file path when Bad Replicas/Blocks are in a snapshot. (Xiao Chen via Yongjun Zhang)\n",
      "commitDate": "27/10/15 11:31 PM",
      "commitName": "97913f430cbe3f82ac866ae6ab8f42754102f6c0",
      "commitAuthor": "Yongjun Zhang",
      "commitDateOld": "21/10/15 2:44 PM",
      "commitNameOld": "d806a5bf079bf136114520c5a3a9d1f16ecf2eda",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 6.37,
      "commitsBetweenForRepo": 74,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,21 @@\n   private void listCorruptFileBlocks() throws IOException {\n-    Collection\u003cFSNamesystem.CorruptFileBlockInfo\u003e corruptFiles \u003d namenode.\n-      getNamesystem().listCorruptFileBlocks(path, currentCookie);\n-    int numCorruptFiles \u003d corruptFiles.size();\n+    final List\u003cString\u003e corrputBlocksFiles \u003d namenode.getNamesystem()\n+        .listCorruptFileBlocksWithSnapshot(path, snapshottableDirs,\n+            currentCookie);\n+    int numCorruptFiles \u003d corrputBlocksFiles.size();\n     String filler;\n     if (numCorruptFiles \u003e 0) {\n       filler \u003d Integer.toString(numCorruptFiles);\n     } else if (currentCookie[0].equals(\"0\")) {\n       filler \u003d \"no\";\n     } else {\n       filler \u003d \"no more\";\n     }\n     out.println(\"Cookie:\\t\" + currentCookie[0]);\n-    for (FSNamesystem.CorruptFileBlockInfo c : corruptFiles) {\n-      out.println(c.toString());\n+    for (String s : corrputBlocksFiles) {\n+      out.println(s);\n     }\n     out.println(\"\\n\\nThe filesystem under path \u0027\" + path + \"\u0027 has \" + filler\n         + \" CORRUPT files\");\n     out.println();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void listCorruptFileBlocks() throws IOException {\n    final List\u003cString\u003e corrputBlocksFiles \u003d namenode.getNamesystem()\n        .listCorruptFileBlocksWithSnapshot(path, snapshottableDirs,\n            currentCookie);\n    int numCorruptFiles \u003d corrputBlocksFiles.size();\n    String filler;\n    if (numCorruptFiles \u003e 0) {\n      filler \u003d Integer.toString(numCorruptFiles);\n    } else if (currentCookie[0].equals(\"0\")) {\n      filler \u003d \"no\";\n    } else {\n      filler \u003d \"no more\";\n    }\n    out.println(\"Cookie:\\t\" + currentCookie[0]);\n    for (String s : corrputBlocksFiles) {\n      out.println(s);\n    }\n    out.println(\"\\n\\nThe filesystem under path \u0027\" + path + \"\u0027 has \" + filler\n        + \" CORRUPT files\");\n    out.println();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java",
      "extendedDetails": {}
    },
    "9a3f147fdd5421460889b266ead3a2300323cda2": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2476. More CPU efficient data structure for under-replicated, over-replicated, and invalidated blocks. Contributed by Tomasz Nykiel.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1201991 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/11/11 5:13 PM",
      "commitName": "9a3f147fdd5421460889b266ead3a2300323cda2",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "02/11/11 11:54 PM",
      "commitNameOld": "40fe96546fcd68696076db67053f30d38a39a0d5",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 11.76,
      "commitsBetweenForRepo": 36,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,19 +1,20 @@\n   private void listCorruptFileBlocks() throws IOException {\n     Collection\u003cFSNamesystem.CorruptFileBlockInfo\u003e corruptFiles \u003d namenode.\n-      getNamesystem().listCorruptFileBlocks(path, startBlockAfter);\n+      getNamesystem().listCorruptFileBlocks(path, currentCookie);\n     int numCorruptFiles \u003d corruptFiles.size();\n     String filler;\n     if (numCorruptFiles \u003e 0) {\n       filler \u003d Integer.toString(numCorruptFiles);\n-    } else if (startBlockAfter \u003d\u003d null) {\n+    } else if (currentCookie[0].equals(\"0\")) {\n       filler \u003d \"no\";\n     } else {\n       filler \u003d \"no more\";\n     }\n+    out.println(\"Cookie:\\t\" + currentCookie[0]);\n     for (FSNamesystem.CorruptFileBlockInfo c : corruptFiles) {\n       out.println(c.toString());\n     }\n     out.println(\"\\n\\nThe filesystem under path \u0027\" + path + \"\u0027 has \" + filler\n         + \" CORRUPT files\");\n     out.println();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void listCorruptFileBlocks() throws IOException {\n    Collection\u003cFSNamesystem.CorruptFileBlockInfo\u003e corruptFiles \u003d namenode.\n      getNamesystem().listCorruptFileBlocks(path, currentCookie);\n    int numCorruptFiles \u003d corruptFiles.size();\n    String filler;\n    if (numCorruptFiles \u003e 0) {\n      filler \u003d Integer.toString(numCorruptFiles);\n    } else if (currentCookie[0].equals(\"0\")) {\n      filler \u003d \"no\";\n    } else {\n      filler \u003d \"no more\";\n    }\n    out.println(\"Cookie:\\t\" + currentCookie[0]);\n    for (FSNamesystem.CorruptFileBlockInfo c : corruptFiles) {\n      out.println(c.toString());\n    }\n    out.println(\"\\n\\nThe filesystem under path \u0027\" + path + \"\u0027 has \" + filler\n        + \" CORRUPT files\");\n    out.println();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private void listCorruptFileBlocks() throws IOException {\n    Collection\u003cFSNamesystem.CorruptFileBlockInfo\u003e corruptFiles \u003d namenode.\n      getNamesystem().listCorruptFileBlocks(path, startBlockAfter);\n    int numCorruptFiles \u003d corruptFiles.size();\n    String filler;\n    if (numCorruptFiles \u003e 0) {\n      filler \u003d Integer.toString(numCorruptFiles);\n    } else if (startBlockAfter \u003d\u003d null) {\n      filler \u003d \"no\";\n    } else {\n      filler \u003d \"no more\";\n    }\n    for (FSNamesystem.CorruptFileBlockInfo c : corruptFiles) {\n      out.println(c.toString());\n    }\n    out.println(\"\\n\\nThe filesystem under path \u0027\" + path + \"\u0027 has \" + filler\n        + \" CORRUPT files\");\n    out.println();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private void listCorruptFileBlocks() throws IOException {\n    Collection\u003cFSNamesystem.CorruptFileBlockInfo\u003e corruptFiles \u003d namenode.\n      getNamesystem().listCorruptFileBlocks(path, startBlockAfter);\n    int numCorruptFiles \u003d corruptFiles.size();\n    String filler;\n    if (numCorruptFiles \u003e 0) {\n      filler \u003d Integer.toString(numCorruptFiles);\n    } else if (startBlockAfter \u003d\u003d null) {\n      filler \u003d \"no\";\n    } else {\n      filler \u003d \"no more\";\n    }\n    for (FSNamesystem.CorruptFileBlockInfo c : corruptFiles) {\n      out.println(c.toString());\n    }\n    out.println(\"\\n\\nThe filesystem under path \u0027\" + path + \"\u0027 has \" + filler\n        + \" CORRUPT files\");\n    out.println();\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,19 @@\n+  private void listCorruptFileBlocks() throws IOException {\n+    Collection\u003cFSNamesystem.CorruptFileBlockInfo\u003e corruptFiles \u003d namenode.\n+      getNamesystem().listCorruptFileBlocks(path, startBlockAfter);\n+    int numCorruptFiles \u003d corruptFiles.size();\n+    String filler;\n+    if (numCorruptFiles \u003e 0) {\n+      filler \u003d Integer.toString(numCorruptFiles);\n+    } else if (startBlockAfter \u003d\u003d null) {\n+      filler \u003d \"no\";\n+    } else {\n+      filler \u003d \"no more\";\n+    }\n+    for (FSNamesystem.CorruptFileBlockInfo c : corruptFiles) {\n+      out.println(c.toString());\n+    }\n+    out.println(\"\\n\\nThe filesystem under path \u0027\" + path + \"\u0027 has \" + filler\n+        + \" CORRUPT files\");\n+    out.println();\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void listCorruptFileBlocks() throws IOException {\n    Collection\u003cFSNamesystem.CorruptFileBlockInfo\u003e corruptFiles \u003d namenode.\n      getNamesystem().listCorruptFileBlocks(path, startBlockAfter);\n    int numCorruptFiles \u003d corruptFiles.size();\n    String filler;\n    if (numCorruptFiles \u003e 0) {\n      filler \u003d Integer.toString(numCorruptFiles);\n    } else if (startBlockAfter \u003d\u003d null) {\n      filler \u003d \"no\";\n    } else {\n      filler \u003d \"no more\";\n    }\n    for (FSNamesystem.CorruptFileBlockInfo c : corruptFiles) {\n      out.println(c.toString());\n    }\n    out.println(\"\\n\\nThe filesystem under path \u0027\" + path + \"\u0027 has \" + filler\n        + \" CORRUPT files\");\n    out.println();\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java"
    }
  }
}