{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "MultiObjectDeleteSupport.java",
  "functionName": "processDeleteFailure",
  "functionId": "processDeleteFailure___deleteException-MultiObjectDeleteException(modifiers-final)__keysToDelete-List__DeleteObjectsRequest.KeyVersion__(modifiers-final)",
  "sourceFilePath": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/impl/MultiObjectDeleteSupport.java",
  "functionStartLine": 170,
  "functionEndLine": 200,
  "numCommitsSeen": 3,
  "timeTaken": 2268,
  "changeHistory": [
    "511df1e837b19ccb9271520589452d82d50ac69d",
    "c58e11bf521d746842ce16724211a2a0339d7b61",
    "e02eb24e0a9139418120027b694492e0738df20a"
  ],
  "changeHistoryShort": {
    "511df1e837b19ccb9271520589452d82d50ac69d": "Ybodychange",
    "c58e11bf521d746842ce16724211a2a0339d7b61": "Ybodychange",
    "e02eb24e0a9139418120027b694492e0738df20a": "Yintroduced"
  },
  "changeHistoryDetails": {
    "511df1e837b19ccb9271520589452d82d50ac69d": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-16430. S3AFilesystem.delete to incrementally update s3guard with deletions\n\nContributed by Steve Loughran.\n\nThis overlaps the scanning for directory entries with batched calls to S3 DELETE and updates of the S3Guard tables.\nIt also uses S3Guard to list the files to delete, so find newly created files even when S3 listings are not use consistent.\n\nFor path which the client considers S3Guard to be authoritative, we also do a recursive LIST of the store and delete files; this is to find unindexed files and do guarantee that the delete(path, true) call really does delete everything underneath.\n\nChange-Id: Ice2f6e940c506e0b3a78fa534a99721b1698708e\n",
      "commitDate": "05/09/19 6:25 AM",
      "commitName": "511df1e837b19ccb9271520589452d82d50ac69d",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "17/07/19 7:24 AM",
      "commitNameOld": "c58e11bf521d746842ce16724211a2a0339d7b61",
      "commitAuthorOld": "Gabor Bota",
      "daysBetweenCommits": 49.96,
      "commitsBetweenForRepo": 456,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,31 +1,31 @@\n       processDeleteFailure(\n       final MultiObjectDeleteException deleteException,\n       final List\u003cDeleteObjectsRequest.KeyVersion\u003e keysToDelete) {\n     final MetadataStore metadataStore \u003d\n         checkNotNull(getStoreContext().getMetadataStore(),\n             \"context metadatastore\");\n     final List\u003cPair\u003cPath, IOException\u003e\u003e failures \u003d new ArrayList\u003c\u003e();\n     final Pair\u003cList\u003cPath\u003e, List\u003cPath\u003e\u003e outcome \u003d\n         splitUndeletedKeys(deleteException, keysToDelete);\n     List\u003cPath\u003e deleted \u003d outcome.getRight();\n     List\u003cPath\u003e undeleted \u003d outcome.getLeft();\n     // delete the paths but recover\n     // TODO: handle the case where a parent path is deleted but not a child.\n     // TODO: in a fake object delete, we don\u0027t actually want to delete\n     //  metastore entries\n     deleted.forEach(path -\u003e {\n       try {\n-        metadataStore.delete(path);\n+        metadataStore.delete(path, operationState);\n       } catch (IOException e) {\n         // trouble: we failed to delete the far end entry\n         // try with the next one.\n         // if this is a big network failure, this is going to be noisy.\n         LOG.warn(\"Failed to update S3Guard store with deletion of {}\", path);\n         failures.add(Pair.of(path, e));\n       }\n     });\n     if (LOG.isDebugEnabled()) {\n       undeleted.forEach(p -\u003e LOG.debug(\"Deleted {}\", p));\n     }\n     return Triple.of(undeleted, deleted, failures);\n   }\n\\ No newline at end of file\n",
      "actualSource": "      processDeleteFailure(\n      final MultiObjectDeleteException deleteException,\n      final List\u003cDeleteObjectsRequest.KeyVersion\u003e keysToDelete) {\n    final MetadataStore metadataStore \u003d\n        checkNotNull(getStoreContext().getMetadataStore(),\n            \"context metadatastore\");\n    final List\u003cPair\u003cPath, IOException\u003e\u003e failures \u003d new ArrayList\u003c\u003e();\n    final Pair\u003cList\u003cPath\u003e, List\u003cPath\u003e\u003e outcome \u003d\n        splitUndeletedKeys(deleteException, keysToDelete);\n    List\u003cPath\u003e deleted \u003d outcome.getRight();\n    List\u003cPath\u003e undeleted \u003d outcome.getLeft();\n    // delete the paths but recover\n    // TODO: handle the case where a parent path is deleted but not a child.\n    // TODO: in a fake object delete, we don\u0027t actually want to delete\n    //  metastore entries\n    deleted.forEach(path -\u003e {\n      try {\n        metadataStore.delete(path, operationState);\n      } catch (IOException e) {\n        // trouble: we failed to delete the far end entry\n        // try with the next one.\n        // if this is a big network failure, this is going to be noisy.\n        LOG.warn(\"Failed to update S3Guard store with deletion of {}\", path);\n        failures.add(Pair.of(path, e));\n      }\n    });\n    if (LOG.isDebugEnabled()) {\n      undeleted.forEach(p -\u003e LOG.debug(\"Deleted {}\", p));\n    }\n    return Triple.of(undeleted, deleted, failures);\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/impl/MultiObjectDeleteSupport.java",
      "extendedDetails": {}
    },
    "c58e11bf521d746842ce16724211a2a0339d7b61": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-16383. Pass ITtlTimeProvider instance in initialize method in MetadataStore interface.  Contributed by Gabor Bota. (#1009) \n\n\r\n",
      "commitDate": "17/07/19 7:24 AM",
      "commitName": "c58e11bf521d746842ce16724211a2a0339d7b61",
      "commitAuthor": "Gabor Bota",
      "commitDateOld": "20/06/19 1:56 AM",
      "commitNameOld": "e02eb24e0a9139418120027b694492e0738df20a",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 27.23,
      "commitsBetweenForRepo": 235,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,31 +1,31 @@\n       processDeleteFailure(\n       final MultiObjectDeleteException deleteException,\n       final List\u003cDeleteObjectsRequest.KeyVersion\u003e keysToDelete) {\n     final MetadataStore metadataStore \u003d\n         checkNotNull(getStoreContext().getMetadataStore(),\n             \"context metadatastore\");\n     final List\u003cPair\u003cPath, IOException\u003e\u003e failures \u003d new ArrayList\u003c\u003e();\n     final Pair\u003cList\u003cPath\u003e, List\u003cPath\u003e\u003e outcome \u003d\n         splitUndeletedKeys(deleteException, keysToDelete);\n     List\u003cPath\u003e deleted \u003d outcome.getRight();\n     List\u003cPath\u003e undeleted \u003d outcome.getLeft();\n     // delete the paths but recover\n     // TODO: handle the case where a parent path is deleted but not a child.\n     // TODO: in a fake object delete, we don\u0027t actually want to delete\n     //  metastore entries\n     deleted.forEach(path -\u003e {\n       try {\n-        metadataStore.delete(path, getStoreContext().getTimeProvider());\n+        metadataStore.delete(path);\n       } catch (IOException e) {\n         // trouble: we failed to delete the far end entry\n         // try with the next one.\n         // if this is a big network failure, this is going to be noisy.\n         LOG.warn(\"Failed to update S3Guard store with deletion of {}\", path);\n         failures.add(Pair.of(path, e));\n       }\n     });\n     if (LOG.isDebugEnabled()) {\n       undeleted.forEach(p -\u003e LOG.debug(\"Deleted {}\", p));\n     }\n     return Triple.of(undeleted, deleted, failures);\n   }\n\\ No newline at end of file\n",
      "actualSource": "      processDeleteFailure(\n      final MultiObjectDeleteException deleteException,\n      final List\u003cDeleteObjectsRequest.KeyVersion\u003e keysToDelete) {\n    final MetadataStore metadataStore \u003d\n        checkNotNull(getStoreContext().getMetadataStore(),\n            \"context metadatastore\");\n    final List\u003cPair\u003cPath, IOException\u003e\u003e failures \u003d new ArrayList\u003c\u003e();\n    final Pair\u003cList\u003cPath\u003e, List\u003cPath\u003e\u003e outcome \u003d\n        splitUndeletedKeys(deleteException, keysToDelete);\n    List\u003cPath\u003e deleted \u003d outcome.getRight();\n    List\u003cPath\u003e undeleted \u003d outcome.getLeft();\n    // delete the paths but recover\n    // TODO: handle the case where a parent path is deleted but not a child.\n    // TODO: in a fake object delete, we don\u0027t actually want to delete\n    //  metastore entries\n    deleted.forEach(path -\u003e {\n      try {\n        metadataStore.delete(path);\n      } catch (IOException e) {\n        // trouble: we failed to delete the far end entry\n        // try with the next one.\n        // if this is a big network failure, this is going to be noisy.\n        LOG.warn(\"Failed to update S3Guard store with deletion of {}\", path);\n        failures.add(Pair.of(path, e));\n      }\n    });\n    if (LOG.isDebugEnabled()) {\n      undeleted.forEach(p -\u003e LOG.debug(\"Deleted {}\", p));\n    }\n    return Triple.of(undeleted, deleted, failures);\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/impl/MultiObjectDeleteSupport.java",
      "extendedDetails": {}
    },
    "e02eb24e0a9139418120027b694492e0738df20a": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-15183. S3Guard store becomes inconsistent after partial failure of rename.\n\nContributed by Steve Loughran.\n\nChange-Id: I825b0bc36be960475d2d259b1cdab45ae1bb78eb\n",
      "commitDate": "20/06/19 1:56 AM",
      "commitName": "e02eb24e0a9139418120027b694492e0738df20a",
      "commitAuthor": "Steve Loughran",
      "diff": "@@ -0,0 +1,31 @@\n+      processDeleteFailure(\n+      final MultiObjectDeleteException deleteException,\n+      final List\u003cDeleteObjectsRequest.KeyVersion\u003e keysToDelete) {\n+    final MetadataStore metadataStore \u003d\n+        checkNotNull(getStoreContext().getMetadataStore(),\n+            \"context metadatastore\");\n+    final List\u003cPair\u003cPath, IOException\u003e\u003e failures \u003d new ArrayList\u003c\u003e();\n+    final Pair\u003cList\u003cPath\u003e, List\u003cPath\u003e\u003e outcome \u003d\n+        splitUndeletedKeys(deleteException, keysToDelete);\n+    List\u003cPath\u003e deleted \u003d outcome.getRight();\n+    List\u003cPath\u003e undeleted \u003d outcome.getLeft();\n+    // delete the paths but recover\n+    // TODO: handle the case where a parent path is deleted but not a child.\n+    // TODO: in a fake object delete, we don\u0027t actually want to delete\n+    //  metastore entries\n+    deleted.forEach(path -\u003e {\n+      try {\n+        metadataStore.delete(path, getStoreContext().getTimeProvider());\n+      } catch (IOException e) {\n+        // trouble: we failed to delete the far end entry\n+        // try with the next one.\n+        // if this is a big network failure, this is going to be noisy.\n+        LOG.warn(\"Failed to update S3Guard store with deletion of {}\", path);\n+        failures.add(Pair.of(path, e));\n+      }\n+    });\n+    if (LOG.isDebugEnabled()) {\n+      undeleted.forEach(p -\u003e LOG.debug(\"Deleted {}\", p));\n+    }\n+    return Triple.of(undeleted, deleted, failures);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "      processDeleteFailure(\n      final MultiObjectDeleteException deleteException,\n      final List\u003cDeleteObjectsRequest.KeyVersion\u003e keysToDelete) {\n    final MetadataStore metadataStore \u003d\n        checkNotNull(getStoreContext().getMetadataStore(),\n            \"context metadatastore\");\n    final List\u003cPair\u003cPath, IOException\u003e\u003e failures \u003d new ArrayList\u003c\u003e();\n    final Pair\u003cList\u003cPath\u003e, List\u003cPath\u003e\u003e outcome \u003d\n        splitUndeletedKeys(deleteException, keysToDelete);\n    List\u003cPath\u003e deleted \u003d outcome.getRight();\n    List\u003cPath\u003e undeleted \u003d outcome.getLeft();\n    // delete the paths but recover\n    // TODO: handle the case where a parent path is deleted but not a child.\n    // TODO: in a fake object delete, we don\u0027t actually want to delete\n    //  metastore entries\n    deleted.forEach(path -\u003e {\n      try {\n        metadataStore.delete(path, getStoreContext().getTimeProvider());\n      } catch (IOException e) {\n        // trouble: we failed to delete the far end entry\n        // try with the next one.\n        // if this is a big network failure, this is going to be noisy.\n        LOG.warn(\"Failed to update S3Guard store with deletion of {}\", path);\n        failures.add(Pair.of(path, e));\n      }\n    });\n    if (LOG.isDebugEnabled()) {\n      undeleted.forEach(p -\u003e LOG.debug(\"Deleted {}\", p));\n    }\n    return Triple.of(undeleted, deleted, failures);\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/impl/MultiObjectDeleteSupport.java"
    }
  }
}