{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "Util.java",
  "functionName": "doGetUrl",
  "functionId": "doGetUrl___url-URL__localPaths-List__File____dstStorage-Storage__getChecksum-boolean__timeout-int__throttler-DataTransferThrottler",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/common/Util.java",
  "functionStartLine": 152,
  "functionEndLine": 188,
  "numCommitsSeen": 20,
  "timeTaken": 2496,
  "changeHistory": [
    "13d4bcfe3535a2df79c2a56e7578716d15497ff4",
    "7ec609b28989303fe0cc36812f225028b0251b32"
  ],
  "changeHistoryShort": {
    "13d4bcfe3535a2df79c2a56e7578716d15497ff4": "Ymultichange(Yparameterchange,Ybodychange)",
    "7ec609b28989303fe0cc36812f225028b0251b32": "Yintroduced"
  },
  "changeHistoryDetails": {
    "13d4bcfe3535a2df79c2a56e7578716d15497ff4": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-4025. QJM: Sychronize past log segments to JNs that missed them. Contributed by Hanisha Koneru.\n",
      "commitDate": "22/02/17 4:33 PM",
      "commitName": "13d4bcfe3535a2df79c2a56e7578716d15497ff4",
      "commitAuthor": "Jing Zhao",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-4025. QJM: Sychronize past log segments to JNs that missed them. Contributed by Hanisha Koneru.\n",
          "commitDate": "22/02/17 4:33 PM",
          "commitName": "13d4bcfe3535a2df79c2a56e7578716d15497ff4",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "09/01/17 6:05 PM",
          "commitNameOld": "7ec609b28989303fe0cc36812f225028b0251b32",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 43.94,
          "commitsBetweenForRepo": 221,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,36 +1,37 @@\n   public static MD5Hash doGetUrl(URL url, List\u003cFile\u003e localPaths,\n-      Storage dstStorage, boolean getChecksum, int timeout) throws IOException {\n+      Storage dstStorage, boolean getChecksum, int timeout,\n+      DataTransferThrottler throttler) throws IOException {\n     HttpURLConnection connection;\n     try {\n       connection \u003d (HttpURLConnection)\n           connectionFactory.openConnection(url, isSpnegoEnabled);\n     } catch (AuthenticationException e) {\n       throw new IOException(e);\n     }\n \n     setTimeout(connection, timeout);\n \n     if (connection.getResponseCode() !\u003d HttpURLConnection.HTTP_OK) {\n       throw new HttpGetFailedException(\"Image transfer servlet at \" + url +\n               \" failed with status code \" + connection.getResponseCode() +\n               \"\\nResponse message:\\n\" + connection.getResponseMessage(),\n           connection);\n     }\n \n     long advertisedSize;\n     String contentLength \u003d connection.getHeaderField(CONTENT_LENGTH);\n     if (contentLength !\u003d null) {\n       advertisedSize \u003d Long.parseLong(contentLength);\n     } else {\n       throw new IOException(CONTENT_LENGTH + \" header is not provided \" +\n           \"by the namenode when trying to fetch \" + url);\n     }\n     MD5Hash advertisedDigest \u003d parseMD5Header(connection);\n     String fsImageName \u003d connection\n         .getHeaderField(ImageServlet.HADOOP_IMAGE_EDITS_HEADER);\n     InputStream stream \u003d connection.getInputStream();\n \n     return receiveFile(url.toExternalForm(), localPaths, dstStorage,\n         getChecksum, advertisedSize, advertisedDigest, fsImageName, stream,\n-        null);\n+        throttler);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static MD5Hash doGetUrl(URL url, List\u003cFile\u003e localPaths,\n      Storage dstStorage, boolean getChecksum, int timeout,\n      DataTransferThrottler throttler) throws IOException {\n    HttpURLConnection connection;\n    try {\n      connection \u003d (HttpURLConnection)\n          connectionFactory.openConnection(url, isSpnegoEnabled);\n    } catch (AuthenticationException e) {\n      throw new IOException(e);\n    }\n\n    setTimeout(connection, timeout);\n\n    if (connection.getResponseCode() !\u003d HttpURLConnection.HTTP_OK) {\n      throw new HttpGetFailedException(\"Image transfer servlet at \" + url +\n              \" failed with status code \" + connection.getResponseCode() +\n              \"\\nResponse message:\\n\" + connection.getResponseMessage(),\n          connection);\n    }\n\n    long advertisedSize;\n    String contentLength \u003d connection.getHeaderField(CONTENT_LENGTH);\n    if (contentLength !\u003d null) {\n      advertisedSize \u003d Long.parseLong(contentLength);\n    } else {\n      throw new IOException(CONTENT_LENGTH + \" header is not provided \" +\n          \"by the namenode when trying to fetch \" + url);\n    }\n    MD5Hash advertisedDigest \u003d parseMD5Header(connection);\n    String fsImageName \u003d connection\n        .getHeaderField(ImageServlet.HADOOP_IMAGE_EDITS_HEADER);\n    InputStream stream \u003d connection.getInputStream();\n\n    return receiveFile(url.toExternalForm(), localPaths, dstStorage,\n        getChecksum, advertisedSize, advertisedDigest, fsImageName, stream,\n        throttler);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/common/Util.java",
          "extendedDetails": {
            "oldValue": "[url-URL, localPaths-List\u003cFile\u003e, dstStorage-Storage, getChecksum-boolean, timeout-int]",
            "newValue": "[url-URL, localPaths-List\u003cFile\u003e, dstStorage-Storage, getChecksum-boolean, timeout-int, throttler-DataTransferThrottler]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-4025. QJM: Sychronize past log segments to JNs that missed them. Contributed by Hanisha Koneru.\n",
          "commitDate": "22/02/17 4:33 PM",
          "commitName": "13d4bcfe3535a2df79c2a56e7578716d15497ff4",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "09/01/17 6:05 PM",
          "commitNameOld": "7ec609b28989303fe0cc36812f225028b0251b32",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 43.94,
          "commitsBetweenForRepo": 221,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,36 +1,37 @@\n   public static MD5Hash doGetUrl(URL url, List\u003cFile\u003e localPaths,\n-      Storage dstStorage, boolean getChecksum, int timeout) throws IOException {\n+      Storage dstStorage, boolean getChecksum, int timeout,\n+      DataTransferThrottler throttler) throws IOException {\n     HttpURLConnection connection;\n     try {\n       connection \u003d (HttpURLConnection)\n           connectionFactory.openConnection(url, isSpnegoEnabled);\n     } catch (AuthenticationException e) {\n       throw new IOException(e);\n     }\n \n     setTimeout(connection, timeout);\n \n     if (connection.getResponseCode() !\u003d HttpURLConnection.HTTP_OK) {\n       throw new HttpGetFailedException(\"Image transfer servlet at \" + url +\n               \" failed with status code \" + connection.getResponseCode() +\n               \"\\nResponse message:\\n\" + connection.getResponseMessage(),\n           connection);\n     }\n \n     long advertisedSize;\n     String contentLength \u003d connection.getHeaderField(CONTENT_LENGTH);\n     if (contentLength !\u003d null) {\n       advertisedSize \u003d Long.parseLong(contentLength);\n     } else {\n       throw new IOException(CONTENT_LENGTH + \" header is not provided \" +\n           \"by the namenode when trying to fetch \" + url);\n     }\n     MD5Hash advertisedDigest \u003d parseMD5Header(connection);\n     String fsImageName \u003d connection\n         .getHeaderField(ImageServlet.HADOOP_IMAGE_EDITS_HEADER);\n     InputStream stream \u003d connection.getInputStream();\n \n     return receiveFile(url.toExternalForm(), localPaths, dstStorage,\n         getChecksum, advertisedSize, advertisedDigest, fsImageName, stream,\n-        null);\n+        throttler);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static MD5Hash doGetUrl(URL url, List\u003cFile\u003e localPaths,\n      Storage dstStorage, boolean getChecksum, int timeout,\n      DataTransferThrottler throttler) throws IOException {\n    HttpURLConnection connection;\n    try {\n      connection \u003d (HttpURLConnection)\n          connectionFactory.openConnection(url, isSpnegoEnabled);\n    } catch (AuthenticationException e) {\n      throw new IOException(e);\n    }\n\n    setTimeout(connection, timeout);\n\n    if (connection.getResponseCode() !\u003d HttpURLConnection.HTTP_OK) {\n      throw new HttpGetFailedException(\"Image transfer servlet at \" + url +\n              \" failed with status code \" + connection.getResponseCode() +\n              \"\\nResponse message:\\n\" + connection.getResponseMessage(),\n          connection);\n    }\n\n    long advertisedSize;\n    String contentLength \u003d connection.getHeaderField(CONTENT_LENGTH);\n    if (contentLength !\u003d null) {\n      advertisedSize \u003d Long.parseLong(contentLength);\n    } else {\n      throw new IOException(CONTENT_LENGTH + \" header is not provided \" +\n          \"by the namenode when trying to fetch \" + url);\n    }\n    MD5Hash advertisedDigest \u003d parseMD5Header(connection);\n    String fsImageName \u003d connection\n        .getHeaderField(ImageServlet.HADOOP_IMAGE_EDITS_HEADER);\n    InputStream stream \u003d connection.getInputStream();\n\n    return receiveFile(url.toExternalForm(), localPaths, dstStorage,\n        getChecksum, advertisedSize, advertisedDigest, fsImageName, stream,\n        throttler);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/common/Util.java",
          "extendedDetails": {}
        }
      ]
    },
    "7ec609b28989303fe0cc36812f225028b0251b32": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-11273. Move TransferFsImage#doGetUrl function to a Util class. Contributed by Hanisha Koneru.\n",
      "commitDate": "09/01/17 6:05 PM",
      "commitName": "7ec609b28989303fe0cc36812f225028b0251b32",
      "commitAuthor": "Jing Zhao",
      "diff": "@@ -0,0 +1,36 @@\n+  public static MD5Hash doGetUrl(URL url, List\u003cFile\u003e localPaths,\n+      Storage dstStorage, boolean getChecksum, int timeout) throws IOException {\n+    HttpURLConnection connection;\n+    try {\n+      connection \u003d (HttpURLConnection)\n+          connectionFactory.openConnection(url, isSpnegoEnabled);\n+    } catch (AuthenticationException e) {\n+      throw new IOException(e);\n+    }\n+\n+    setTimeout(connection, timeout);\n+\n+    if (connection.getResponseCode() !\u003d HttpURLConnection.HTTP_OK) {\n+      throw new HttpGetFailedException(\"Image transfer servlet at \" + url +\n+              \" failed with status code \" + connection.getResponseCode() +\n+              \"\\nResponse message:\\n\" + connection.getResponseMessage(),\n+          connection);\n+    }\n+\n+    long advertisedSize;\n+    String contentLength \u003d connection.getHeaderField(CONTENT_LENGTH);\n+    if (contentLength !\u003d null) {\n+      advertisedSize \u003d Long.parseLong(contentLength);\n+    } else {\n+      throw new IOException(CONTENT_LENGTH + \" header is not provided \" +\n+          \"by the namenode when trying to fetch \" + url);\n+    }\n+    MD5Hash advertisedDigest \u003d parseMD5Header(connection);\n+    String fsImageName \u003d connection\n+        .getHeaderField(ImageServlet.HADOOP_IMAGE_EDITS_HEADER);\n+    InputStream stream \u003d connection.getInputStream();\n+\n+    return receiveFile(url.toExternalForm(), localPaths, dstStorage,\n+        getChecksum, advertisedSize, advertisedDigest, fsImageName, stream,\n+        null);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public static MD5Hash doGetUrl(URL url, List\u003cFile\u003e localPaths,\n      Storage dstStorage, boolean getChecksum, int timeout) throws IOException {\n    HttpURLConnection connection;\n    try {\n      connection \u003d (HttpURLConnection)\n          connectionFactory.openConnection(url, isSpnegoEnabled);\n    } catch (AuthenticationException e) {\n      throw new IOException(e);\n    }\n\n    setTimeout(connection, timeout);\n\n    if (connection.getResponseCode() !\u003d HttpURLConnection.HTTP_OK) {\n      throw new HttpGetFailedException(\"Image transfer servlet at \" + url +\n              \" failed with status code \" + connection.getResponseCode() +\n              \"\\nResponse message:\\n\" + connection.getResponseMessage(),\n          connection);\n    }\n\n    long advertisedSize;\n    String contentLength \u003d connection.getHeaderField(CONTENT_LENGTH);\n    if (contentLength !\u003d null) {\n      advertisedSize \u003d Long.parseLong(contentLength);\n    } else {\n      throw new IOException(CONTENT_LENGTH + \" header is not provided \" +\n          \"by the namenode when trying to fetch \" + url);\n    }\n    MD5Hash advertisedDigest \u003d parseMD5Header(connection);\n    String fsImageName \u003d connection\n        .getHeaderField(ImageServlet.HADOOP_IMAGE_EDITS_HEADER);\n    InputStream stream \u003d connection.getInputStream();\n\n    return receiveFile(url.toExternalForm(), localPaths, dstStorage,\n        getChecksum, advertisedSize, advertisedDigest, fsImageName, stream,\n        null);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/common/Util.java"
    }
  }
}