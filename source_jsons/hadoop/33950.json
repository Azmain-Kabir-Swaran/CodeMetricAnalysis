{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "CGroupsBlkioResourceHandlerImpl.java",
  "functionName": "checkDiskScheduler",
  "functionId": "checkDiskScheduler",
  "sourceFilePath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/resources/CGroupsBlkioResourceHandlerImpl.java",
  "functionStartLine": 69,
  "functionEndLine": 115,
  "numCommitsSeen": 5,
  "timeTaken": 747,
  "changeHistory": [
    "1b3b9e5c31c38388c1ce4208c65e8dd5f956da82"
  ],
  "changeHistoryShort": {
    "1b3b9e5c31c38388c1ce4208c65e8dd5f956da82": "Yintroduced"
  },
  "changeHistoryDetails": {
    "1b3b9e5c31c38388c1ce4208c65e8dd5f956da82": {
      "type": "Yintroduced",
      "commitMessage": "YARN-2619. Added NodeManager support for disk io isolation through cgroups. Contributed by Varun Vasudev and Wei Yan.\n",
      "commitDate": "30/04/15 9:41 PM",
      "commitName": "1b3b9e5c31c38388c1ce4208c65e8dd5f956da82",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "diff": "@@ -0,0 +1,47 @@\n+  private void checkDiskScheduler() {\n+    String data;\n+\n+    // read /proc/partitions and check to make sure that sd* and hd*\n+    // are using the CFQ scheduler. If they aren\u0027t print a warning\n+    try {\n+      byte[] contents \u003d Files.readAllBytes(Paths.get(PARTITIONS_FILE));\n+      data \u003d new String(contents, \"UTF-8\").trim();\n+    } catch (IOException e) {\n+      String msg \u003d \"Couldn\u0027t read \" + PARTITIONS_FILE +\n+          \"; can\u0027t determine disk scheduler type\";\n+      LOG.warn(msg, e);\n+      return;\n+    }\n+    String[] lines \u003d data.split(System.lineSeparator());\n+    if (lines.length \u003e 0) {\n+      for (String line : lines) {\n+        String[] columns \u003d line.split(\"\\\\s+\");\n+        if (columns.length \u003e 4) {\n+          String partition \u003d columns[4];\n+          // check some known partitions to make sure  the disk scheduler\n+          // is cfq - not meant to be comprehensive, more a sanity check\n+          if (partition.startsWith(\"sd\") || partition.startsWith(\"hd\")\n+              || partition.startsWith(\"vd\") || partition.startsWith(\"xvd\")) {\n+            String schedulerPath \u003d\n+                \"/sys/block/\" + partition + \"/queue/scheduler\";\n+            File schedulerFile \u003d new File(schedulerPath);\n+            if (schedulerFile.exists()) {\n+              try {\n+                byte[] contents \u003d Files.readAllBytes(Paths.get(schedulerPath));\n+                String schedulerString \u003d new String(contents, \"UTF-8\").trim();\n+                if (!schedulerString.contains(\"[cfq]\")) {\n+                  LOG.warn(\"Device \" + partition + \" does not use the CFQ\"\n+                      + \" scheduler; disk isolation using \"\n+                      + \"CGroups will not work on this partition.\");\n+                }\n+              } catch (IOException ie) {\n+                LOG.warn(\n+                    \"Unable to determine disk scheduler type for partition \"\n+                      + partition, ie);\n+              }\n+            }\n+          }\n+        }\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void checkDiskScheduler() {\n    String data;\n\n    // read /proc/partitions and check to make sure that sd* and hd*\n    // are using the CFQ scheduler. If they aren\u0027t print a warning\n    try {\n      byte[] contents \u003d Files.readAllBytes(Paths.get(PARTITIONS_FILE));\n      data \u003d new String(contents, \"UTF-8\").trim();\n    } catch (IOException e) {\n      String msg \u003d \"Couldn\u0027t read \" + PARTITIONS_FILE +\n          \"; can\u0027t determine disk scheduler type\";\n      LOG.warn(msg, e);\n      return;\n    }\n    String[] lines \u003d data.split(System.lineSeparator());\n    if (lines.length \u003e 0) {\n      for (String line : lines) {\n        String[] columns \u003d line.split(\"\\\\s+\");\n        if (columns.length \u003e 4) {\n          String partition \u003d columns[4];\n          // check some known partitions to make sure  the disk scheduler\n          // is cfq - not meant to be comprehensive, more a sanity check\n          if (partition.startsWith(\"sd\") || partition.startsWith(\"hd\")\n              || partition.startsWith(\"vd\") || partition.startsWith(\"xvd\")) {\n            String schedulerPath \u003d\n                \"/sys/block/\" + partition + \"/queue/scheduler\";\n            File schedulerFile \u003d new File(schedulerPath);\n            if (schedulerFile.exists()) {\n              try {\n                byte[] contents \u003d Files.readAllBytes(Paths.get(schedulerPath));\n                String schedulerString \u003d new String(contents, \"UTF-8\").trim();\n                if (!schedulerString.contains(\"[cfq]\")) {\n                  LOG.warn(\"Device \" + partition + \" does not use the CFQ\"\n                      + \" scheduler; disk isolation using \"\n                      + \"CGroups will not work on this partition.\");\n                }\n              } catch (IOException ie) {\n                LOG.warn(\n                    \"Unable to determine disk scheduler type for partition \"\n                      + partition, ie);\n              }\n            }\n          }\n        }\n      }\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/resources/CGroupsBlkioResourceHandlerImpl.java"
    }
  }
}