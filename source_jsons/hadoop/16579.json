{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "RouterRpcServer.java",
  "functionName": "getExistingLocation",
  "functionId": "getExistingLocation___src-String__locations-List__RemoteLocation__",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcServer.java",
  "functionStartLine": 669,
  "functionEndLine": 681,
  "numCommitsSeen": 53,
  "timeTaken": 1390,
  "changeHistory": [
    "3df0adaaea485bcbd4ae1a04fe160f3148c14437",
    "8e4267650fe52eb6b6d4466fc006e7af4a1326d0"
  ],
  "changeHistoryShort": {
    "3df0adaaea485bcbd4ae1a04fe160f3148c14437": "Ybodychange",
    "8e4267650fe52eb6b6d4466fc006e7af4a1326d0": "Yintroduced"
  },
  "changeHistoryDetails": {
    "3df0adaaea485bcbd4ae1a04fe160f3148c14437": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-15127. RBF: Do not allow writes when a subcluster is unavailable for HASH_ALL mount points. Contributed by Inigo Goiri\n",
      "commitDate": "12/02/20 6:11 AM",
      "commitName": "3df0adaaea485bcbd4ae1a04fe160f3148c14437",
      "commitAuthor": "Ayush Saxena",
      "commitDateOld": "07/02/20 1:21 AM",
      "commitNameOld": "7dac7e1d13eaf0eac04fe805c7502dcecd597979",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 5.2,
      "commitsBetweenForRepo": 16,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,13 @@\n   private RemoteLocation getExistingLocation(String src,\n       List\u003cRemoteLocation\u003e locations) throws IOException {\n     RemoteMethod method \u003d new RemoteMethod(\"getFileInfo\",\n         new Class\u003c?\u003e[] {String.class}, new RemoteParam());\n     Map\u003cRemoteLocation, HdfsFileStatus\u003e results \u003d rpcClient.invokeConcurrent(\n-        locations, method, false, false, HdfsFileStatus.class);\n+        locations, method, true, false, HdfsFileStatus.class);\n     for (RemoteLocation loc : locations) {\n       if (results.get(loc) !\u003d null) {\n         return loc;\n       }\n     }\n     return null;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private RemoteLocation getExistingLocation(String src,\n      List\u003cRemoteLocation\u003e locations) throws IOException {\n    RemoteMethod method \u003d new RemoteMethod(\"getFileInfo\",\n        new Class\u003c?\u003e[] {String.class}, new RemoteParam());\n    Map\u003cRemoteLocation, HdfsFileStatus\u003e results \u003d rpcClient.invokeConcurrent(\n        locations, method, true, false, HdfsFileStatus.class);\n    for (RemoteLocation loc : locations) {\n      if (results.get(loc) !\u003d null) {\n        return loc;\n      }\n    }\n    return null;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcServer.java",
      "extendedDetails": {}
    },
    "8e4267650fe52eb6b6d4466fc006e7af4a1326d0": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-14440. RBF: Optimize the file write process in case of multiple destinations. Contributed by Ayush Saxena.\n",
      "commitDate": "24/06/19 9:33 AM",
      "commitName": "8e4267650fe52eb6b6d4466fc006e7af4a1326d0",
      "commitAuthor": "Ayush Saxena",
      "diff": "@@ -0,0 +1,13 @@\n+  private RemoteLocation getExistingLocation(String src,\n+      List\u003cRemoteLocation\u003e locations) throws IOException {\n+    RemoteMethod method \u003d new RemoteMethod(\"getFileInfo\",\n+        new Class\u003c?\u003e[] {String.class}, new RemoteParam());\n+    Map\u003cRemoteLocation, HdfsFileStatus\u003e results \u003d rpcClient.invokeConcurrent(\n+        locations, method, false, false, HdfsFileStatus.class);\n+    for (RemoteLocation loc : locations) {\n+      if (results.get(loc) !\u003d null) {\n+        return loc;\n+      }\n+    }\n+    return null;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private RemoteLocation getExistingLocation(String src,\n      List\u003cRemoteLocation\u003e locations) throws IOException {\n    RemoteMethod method \u003d new RemoteMethod(\"getFileInfo\",\n        new Class\u003c?\u003e[] {String.class}, new RemoteParam());\n    Map\u003cRemoteLocation, HdfsFileStatus\u003e results \u003d rpcClient.invokeConcurrent(\n        locations, method, false, false, HdfsFileStatus.class);\n    for (RemoteLocation loc : locations) {\n      if (results.get(loc) !\u003d null) {\n        return loc;\n      }\n    }\n    return null;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcServer.java"
    }
  }
}