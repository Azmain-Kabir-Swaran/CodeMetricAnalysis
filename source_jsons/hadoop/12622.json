{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ExternalSPSContext.java",
  "functionName": "getNetworkTopology",
  "functionId": "getNetworkTopology___datanodeMap-DatanodeMap",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/sps/ExternalSPSContext.java",
  "functionStartLine": 92,
  "functionEndLine": 100,
  "numCommitsSeen": 12,
  "timeTaken": 2742,
  "changeHistory": [
    "75ccc1396b677777cdc0d4992a4af3911f9f88c2",
    "99594b48b8e040ab5a0939d7c3dbcfb34400e6fc"
  ],
  "changeHistoryShort": {
    "75ccc1396b677777cdc0d4992a4af3911f9f88c2": "Ymultichange(Yparameterchange,Ybodychange)",
    "99594b48b8e040ab5a0939d7c3dbcfb34400e6fc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "75ccc1396b677777cdc0d4992a4af3911f9f88c2": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-13166: [SPS]: Implement caching mechanism to keep LIVE datanodes to minimize costly getLiveDatanodeStorageReport() calls. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "75ccc1396b677777cdc0d4992a4af3911f9f88c2",
      "commitAuthor": "Surendra Singh Lilhore",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-13166: [SPS]: Implement caching mechanism to keep LIVE datanodes to minimize costly getLiveDatanodeStorageReport() calls. Contributed by Rakesh R.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "75ccc1396b677777cdc0d4992a4af3911f9f88c2",
          "commitAuthor": "Surendra Singh Lilhore",
          "commitDateOld": "12/08/18 3:06 AM",
          "commitNameOld": "8467ec24fb74f30371d5a13e893fc56309ee9372",
          "commitAuthorOld": "Rakesh Radhakrishnan",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,3 +1,9 @@\n-  public NetworkTopology getNetworkTopology() {\n-    return NetworkTopology.getInstance(service.getConf());\n+  public NetworkTopology getNetworkTopology(DatanodeMap datanodeMap) {\n+    // create network topology.\n+    NetworkTopology cluster \u003d NetworkTopology.getInstance(service.getConf());\n+    List\u003cDatanodeWithStorage\u003e targets \u003d datanodeMap.getTargets();\n+    for (DatanodeWithStorage node : targets) {\n+      cluster.add(node.getDatanodeInfo());\n+    }\n+    return cluster;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public NetworkTopology getNetworkTopology(DatanodeMap datanodeMap) {\n    // create network topology.\n    NetworkTopology cluster \u003d NetworkTopology.getInstance(service.getConf());\n    List\u003cDatanodeWithStorage\u003e targets \u003d datanodeMap.getTargets();\n    for (DatanodeWithStorage node : targets) {\n      cluster.add(node.getDatanodeInfo());\n    }\n    return cluster;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/sps/ExternalSPSContext.java",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[datanodeMap-DatanodeMap]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-13166: [SPS]: Implement caching mechanism to keep LIVE datanodes to minimize costly getLiveDatanodeStorageReport() calls. Contributed by Rakesh R.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "75ccc1396b677777cdc0d4992a4af3911f9f88c2",
          "commitAuthor": "Surendra Singh Lilhore",
          "commitDateOld": "12/08/18 3:06 AM",
          "commitNameOld": "8467ec24fb74f30371d5a13e893fc56309ee9372",
          "commitAuthorOld": "Rakesh Radhakrishnan",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,3 +1,9 @@\n-  public NetworkTopology getNetworkTopology() {\n-    return NetworkTopology.getInstance(service.getConf());\n+  public NetworkTopology getNetworkTopology(DatanodeMap datanodeMap) {\n+    // create network topology.\n+    NetworkTopology cluster \u003d NetworkTopology.getInstance(service.getConf());\n+    List\u003cDatanodeWithStorage\u003e targets \u003d datanodeMap.getTargets();\n+    for (DatanodeWithStorage node : targets) {\n+      cluster.add(node.getDatanodeInfo());\n+    }\n+    return cluster;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public NetworkTopology getNetworkTopology(DatanodeMap datanodeMap) {\n    // create network topology.\n    NetworkTopology cluster \u003d NetworkTopology.getInstance(service.getConf());\n    List\u003cDatanodeWithStorage\u003e targets \u003d datanodeMap.getTargets();\n    for (DatanodeWithStorage node : targets) {\n      cluster.add(node.getDatanodeInfo());\n    }\n    return cluster;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/sps/ExternalSPSContext.java",
          "extendedDetails": {}
        }
      ]
    },
    "99594b48b8e040ab5a0939d7c3dbcfb34400e6fc": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-13075. [SPS]: Provide External Context implementation. Contributed by Uma Maheswara Rao G.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "99594b48b8e040ab5a0939d7c3dbcfb34400e6fc",
      "commitAuthor": "Surendra Singh Lilhore",
      "diff": "@@ -0,0 +1,3 @@\n+  public NetworkTopology getNetworkTopology() {\n+    return NetworkTopology.getInstance(service.getConf());\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public NetworkTopology getNetworkTopology() {\n    return NetworkTopology.getInstance(service.getConf());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/sps/ExternalSPSContext.java"
    }
  }
}