{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "WebHdfsFileSystem.java",
  "functionName": "read",
  "functionId": "read___b-byte[]__off-int__len-int",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
  "functionStartLine": 2142,
  "functionEndLine": 2144,
  "numCommitsSeen": 73,
  "timeTaken": 3047,
  "changeHistory": [
    "fde95d463c3123b315b3d07cb5b7b7dc19f7cb73",
    "0bdd263d82a4510f16df49238d57c9f78ac28ae7",
    "867048c3e4b20ece0039a876def129fa5eb9234f"
  ],
  "changeHistoryShort": {
    "fde95d463c3123b315b3d07cb5b7b7dc19f7cb73": "Ybodychange",
    "0bdd263d82a4510f16df49238d57c9f78ac28ae7": "Ybodychange",
    "867048c3e4b20ece0039a876def129fa5eb9234f": "Yintroduced"
  },
  "changeHistoryDetails": {
    "fde95d463c3123b315b3d07cb5b7b7dc19f7cb73": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12574. Add CryptoInputStream to WebHdfsFileSystem read call. Contributed by Rushabh S Shah\n",
      "commitDate": "29/01/18 3:23 PM",
      "commitName": "fde95d463c3123b315b3d07cb5b7b7dc19f7cb73",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "04/12/17 10:40 AM",
      "commitNameOld": "404eab4dc0582e0384b93664ea6ee77ccd5eeebc",
      "commitAuthorOld": "Xiao Chen",
      "daysBetweenCommits": 56.2,
      "commitsBetweenForRepo": 316,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,51 +1,52 @@\n     int read(byte[] b, int off, int len) throws IOException {\n       if (runnerState \u003d\u003d RunnerState.CLOSED) {\n         throw new IOException(\"Stream closed\");\n       }\n       if (len \u003d\u003d 0) {\n         return 0;\n       }\n \n       // Before the first read, pos and fileLength will be 0 and readBuffer\n       // will all be null. They will be initialized once the first connection\n       // is made. Only after that it makes sense to compare pos and fileLength.\n       if (pos \u003e\u003d fileLength \u0026\u0026 readBuffer !\u003d null) {\n         return -1;\n       }\n \n       // If a seek is occurring, the input stream will have been closed, so it\n       // needs to be reopened. Use the URLRunner to call AbstractRunner#connect\n       // with the previously-cached resolved URL and with the \u0027redirected\u0027 flag\n       // set to \u0027true\u0027. The resolved URL contains the URL of the previously\n       // opened DN as opposed to the NN. It is preferable to use the resolved\n       // URL when creating a connection because it does not hit the NN or every\n       // seek, nor does it open a connection to a new DN after every seek.\n       // The redirect flag is needed so that AbstractRunner#connect knows the\n       // URL is already resolved.\n       // Note that when the redirected flag is set, retries are not attempted.\n       // So, if the connection fails using URLRunner, clear out the connection\n       // and fall through to establish the connection using ReadRunner.\n       if (runnerState \u003d\u003d RunnerState.SEEK) {\n         try {\n           final URL rurl \u003d new URL(resolvedUrl + \"\u0026\" + new OffsetParam(pos));\n-          cachedConnection \u003d new URLRunner(GetOpParam.Op.OPEN, rurl, true).run();\n+          cachedConnection \u003d new URLRunner(GetOpParam.Op.OPEN, rurl, true,\n+              false).run();\n         } catch (IOException ioe) {\n           closeInputStream(RunnerState.DISCONNECTED);\n         }\n       }\n \n       readBuffer \u003d b;\n       readOffset \u003d off;\n       readLength \u003d len;\n \n       int count \u003d -1;\n       count \u003d this.run();\n       if (count \u003e\u003d 0) {\n         statistics.incrementBytesRead(count);\n         pos +\u003d count;\n       } else if (pos \u003c fileLength) {\n         throw new EOFException(\n                   \"Premature EOF: pos\u003d\" + pos + \" \u003c filelength\u003d\" + fileLength);\n       }\n       return count;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    int read(byte[] b, int off, int len) throws IOException {\n      if (runnerState \u003d\u003d RunnerState.CLOSED) {\n        throw new IOException(\"Stream closed\");\n      }\n      if (len \u003d\u003d 0) {\n        return 0;\n      }\n\n      // Before the first read, pos and fileLength will be 0 and readBuffer\n      // will all be null. They will be initialized once the first connection\n      // is made. Only after that it makes sense to compare pos and fileLength.\n      if (pos \u003e\u003d fileLength \u0026\u0026 readBuffer !\u003d null) {\n        return -1;\n      }\n\n      // If a seek is occurring, the input stream will have been closed, so it\n      // needs to be reopened. Use the URLRunner to call AbstractRunner#connect\n      // with the previously-cached resolved URL and with the \u0027redirected\u0027 flag\n      // set to \u0027true\u0027. The resolved URL contains the URL of the previously\n      // opened DN as opposed to the NN. It is preferable to use the resolved\n      // URL when creating a connection because it does not hit the NN or every\n      // seek, nor does it open a connection to a new DN after every seek.\n      // The redirect flag is needed so that AbstractRunner#connect knows the\n      // URL is already resolved.\n      // Note that when the redirected flag is set, retries are not attempted.\n      // So, if the connection fails using URLRunner, clear out the connection\n      // and fall through to establish the connection using ReadRunner.\n      if (runnerState \u003d\u003d RunnerState.SEEK) {\n        try {\n          final URL rurl \u003d new URL(resolvedUrl + \"\u0026\" + new OffsetParam(pos));\n          cachedConnection \u003d new URLRunner(GetOpParam.Op.OPEN, rurl, true,\n              false).run();\n        } catch (IOException ioe) {\n          closeInputStream(RunnerState.DISCONNECTED);\n        }\n      }\n\n      readBuffer \u003d b;\n      readOffset \u003d off;\n      readLength \u003d len;\n\n      int count \u003d -1;\n      count \u003d this.run();\n      if (count \u003e\u003d 0) {\n        statistics.incrementBytesRead(count);\n        pos +\u003d count;\n      } else if (pos \u003c fileLength) {\n        throw new EOFException(\n                  \"Premature EOF: pos\u003d\" + pos + \" \u003c filelength\u003d\" + fileLength);\n      }\n      return count;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
      "extendedDetails": {}
    },
    "0bdd263d82a4510f16df49238d57c9f78ac28ae7": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-13017. Implementations of InputStream.read(buffer, offset, bytes) to exit 0 if bytes\u003d\u003d0. Contributed by Steve Loughran.\n",
      "commitDate": "26/10/16 11:46 PM",
      "commitName": "0bdd263d82a4510f16df49238d57c9f78ac28ae7",
      "commitAuthor": "Masatake Iwasaki",
      "commitDateOld": "14/10/16 10:26 AM",
      "commitNameOld": "701c27a7762294e1a5fb2b3ac81f5534aa37f667",
      "commitAuthorOld": "Benoy Antony",
      "daysBetweenCommits": 12.56,
      "commitsBetweenForRepo": 99,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,48 +1,51 @@\n     int read(byte[] b, int off, int len) throws IOException {\n       if (runnerState \u003d\u003d RunnerState.CLOSED) {\n         throw new IOException(\"Stream closed\");\n       }\n+      if (len \u003d\u003d 0) {\n+        return 0;\n+      }\n \n       // Before the first read, pos and fileLength will be 0 and readBuffer\n       // will all be null. They will be initialized once the first connection\n       // is made. Only after that it makes sense to compare pos and fileLength.\n       if (pos \u003e\u003d fileLength \u0026\u0026 readBuffer !\u003d null) {\n         return -1;\n       }\n \n       // If a seek is occurring, the input stream will have been closed, so it\n       // needs to be reopened. Use the URLRunner to call AbstractRunner#connect\n       // with the previously-cached resolved URL and with the \u0027redirected\u0027 flag\n       // set to \u0027true\u0027. The resolved URL contains the URL of the previously\n       // opened DN as opposed to the NN. It is preferable to use the resolved\n       // URL when creating a connection because it does not hit the NN or every\n       // seek, nor does it open a connection to a new DN after every seek.\n       // The redirect flag is needed so that AbstractRunner#connect knows the\n       // URL is already resolved.\n       // Note that when the redirected flag is set, retries are not attempted.\n       // So, if the connection fails using URLRunner, clear out the connection\n       // and fall through to establish the connection using ReadRunner.\n       if (runnerState \u003d\u003d RunnerState.SEEK) {\n         try {\n           final URL rurl \u003d new URL(resolvedUrl + \"\u0026\" + new OffsetParam(pos));\n           cachedConnection \u003d new URLRunner(GetOpParam.Op.OPEN, rurl, true).run();\n         } catch (IOException ioe) {\n           closeInputStream(RunnerState.DISCONNECTED);\n         }\n       }\n \n       readBuffer \u003d b;\n       readOffset \u003d off;\n       readLength \u003d len;\n \n       int count \u003d -1;\n       count \u003d this.run();\n       if (count \u003e\u003d 0) {\n         statistics.incrementBytesRead(count);\n         pos +\u003d count;\n       } else if (pos \u003c fileLength) {\n         throw new EOFException(\n                   \"Premature EOF: pos\u003d\" + pos + \" \u003c filelength\u003d\" + fileLength);\n       }\n       return count;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    int read(byte[] b, int off, int len) throws IOException {\n      if (runnerState \u003d\u003d RunnerState.CLOSED) {\n        throw new IOException(\"Stream closed\");\n      }\n      if (len \u003d\u003d 0) {\n        return 0;\n      }\n\n      // Before the first read, pos and fileLength will be 0 and readBuffer\n      // will all be null. They will be initialized once the first connection\n      // is made. Only after that it makes sense to compare pos and fileLength.\n      if (pos \u003e\u003d fileLength \u0026\u0026 readBuffer !\u003d null) {\n        return -1;\n      }\n\n      // If a seek is occurring, the input stream will have been closed, so it\n      // needs to be reopened. Use the URLRunner to call AbstractRunner#connect\n      // with the previously-cached resolved URL and with the \u0027redirected\u0027 flag\n      // set to \u0027true\u0027. The resolved URL contains the URL of the previously\n      // opened DN as opposed to the NN. It is preferable to use the resolved\n      // URL when creating a connection because it does not hit the NN or every\n      // seek, nor does it open a connection to a new DN after every seek.\n      // The redirect flag is needed so that AbstractRunner#connect knows the\n      // URL is already resolved.\n      // Note that when the redirected flag is set, retries are not attempted.\n      // So, if the connection fails using URLRunner, clear out the connection\n      // and fall through to establish the connection using ReadRunner.\n      if (runnerState \u003d\u003d RunnerState.SEEK) {\n        try {\n          final URL rurl \u003d new URL(resolvedUrl + \"\u0026\" + new OffsetParam(pos));\n          cachedConnection \u003d new URLRunner(GetOpParam.Op.OPEN, rurl, true).run();\n        } catch (IOException ioe) {\n          closeInputStream(RunnerState.DISCONNECTED);\n        }\n      }\n\n      readBuffer \u003d b;\n      readOffset \u003d off;\n      readLength \u003d len;\n\n      int count \u003d -1;\n      count \u003d this.run();\n      if (count \u003e\u003d 0) {\n        statistics.incrementBytesRead(count);\n        pos +\u003d count;\n      } else if (pos \u003c fileLength) {\n        throw new EOFException(\n                  \"Premature EOF: pos\u003d\" + pos + \" \u003c filelength\u003d\" + fileLength);\n      }\n      return count;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
      "extendedDetails": {}
    },
    "867048c3e4b20ece0039a876def129fa5eb9234f": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-7163. WebHdfsFileSystem should retry reads according to the configured retry policy. Contributed by Eric Payne.\n",
      "commitDate": "22/12/15 12:08 PM",
      "commitName": "867048c3e4b20ece0039a876def129fa5eb9234f",
      "commitAuthor": "Kihwal Lee",
      "diff": "@@ -0,0 +1,48 @@\n+    int read(byte[] b, int off, int len) throws IOException {\n+      if (runnerState \u003d\u003d RunnerState.CLOSED) {\n+        throw new IOException(\"Stream closed\");\n+      }\n+\n+      // Before the first read, pos and fileLength will be 0 and readBuffer\n+      // will all be null. They will be initialized once the first connection\n+      // is made. Only after that it makes sense to compare pos and fileLength.\n+      if (pos \u003e\u003d fileLength \u0026\u0026 readBuffer !\u003d null) {\n+        return -1;\n+      }\n+\n+      // If a seek is occurring, the input stream will have been closed, so it\n+      // needs to be reopened. Use the URLRunner to call AbstractRunner#connect\n+      // with the previously-cached resolved URL and with the \u0027redirected\u0027 flag\n+      // set to \u0027true\u0027. The resolved URL contains the URL of the previously\n+      // opened DN as opposed to the NN. It is preferable to use the resolved\n+      // URL when creating a connection because it does not hit the NN or every\n+      // seek, nor does it open a connection to a new DN after every seek.\n+      // The redirect flag is needed so that AbstractRunner#connect knows the\n+      // URL is already resolved.\n+      // Note that when the redirected flag is set, retries are not attempted.\n+      // So, if the connection fails using URLRunner, clear out the connection\n+      // and fall through to establish the connection using ReadRunner.\n+      if (runnerState \u003d\u003d RunnerState.SEEK) {\n+        try {\n+          final URL rurl \u003d new URL(resolvedUrl + \"\u0026\" + new OffsetParam(pos));\n+          cachedConnection \u003d new URLRunner(GetOpParam.Op.OPEN, rurl, true).run();\n+        } catch (IOException ioe) {\n+          closeInputStream(RunnerState.DISCONNECTED);\n+        }\n+      }\n+\n+      readBuffer \u003d b;\n+      readOffset \u003d off;\n+      readLength \u003d len;\n+\n+      int count \u003d -1;\n+      count \u003d this.run();\n+      if (count \u003e\u003d 0) {\n+        statistics.incrementBytesRead(count);\n+        pos +\u003d count;\n+      } else if (pos \u003c fileLength) {\n+        throw new EOFException(\n+                  \"Premature EOF: pos\u003d\" + pos + \" \u003c filelength\u003d\" + fileLength);\n+      }\n+      return count;\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    int read(byte[] b, int off, int len) throws IOException {\n      if (runnerState \u003d\u003d RunnerState.CLOSED) {\n        throw new IOException(\"Stream closed\");\n      }\n\n      // Before the first read, pos and fileLength will be 0 and readBuffer\n      // will all be null. They will be initialized once the first connection\n      // is made. Only after that it makes sense to compare pos and fileLength.\n      if (pos \u003e\u003d fileLength \u0026\u0026 readBuffer !\u003d null) {\n        return -1;\n      }\n\n      // If a seek is occurring, the input stream will have been closed, so it\n      // needs to be reopened. Use the URLRunner to call AbstractRunner#connect\n      // with the previously-cached resolved URL and with the \u0027redirected\u0027 flag\n      // set to \u0027true\u0027. The resolved URL contains the URL of the previously\n      // opened DN as opposed to the NN. It is preferable to use the resolved\n      // URL when creating a connection because it does not hit the NN or every\n      // seek, nor does it open a connection to a new DN after every seek.\n      // The redirect flag is needed so that AbstractRunner#connect knows the\n      // URL is already resolved.\n      // Note that when the redirected flag is set, retries are not attempted.\n      // So, if the connection fails using URLRunner, clear out the connection\n      // and fall through to establish the connection using ReadRunner.\n      if (runnerState \u003d\u003d RunnerState.SEEK) {\n        try {\n          final URL rurl \u003d new URL(resolvedUrl + \"\u0026\" + new OffsetParam(pos));\n          cachedConnection \u003d new URLRunner(GetOpParam.Op.OPEN, rurl, true).run();\n        } catch (IOException ioe) {\n          closeInputStream(RunnerState.DISCONNECTED);\n        }\n      }\n\n      readBuffer \u003d b;\n      readOffset \u003d off;\n      readLength \u003d len;\n\n      int count \u003d -1;\n      count \u003d this.run();\n      if (count \u003e\u003d 0) {\n        statistics.incrementBytesRead(count);\n        pos +\u003d count;\n      } else if (pos \u003c fileLength) {\n        throw new EOFException(\n                  \"Premature EOF: pos\u003d\" + pos + \" \u003c filelength\u003d\" + fileLength);\n      }\n      return count;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java"
    }
  }
}