{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ExternalSPSFilePathCollector.java",
  "functionName": "scanAndCollectFiles",
  "functionId": "scanAndCollectFiles___pathId-long",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/sps/ExternalSPSFilePathCollector.java",
  "functionStartLine": 154,
  "functionEndLine": 172,
  "numCommitsSeen": 3,
  "timeTaken": 1943,
  "changeHistory": [
    "66e8f9b31529226309c924226a53dead3e6fcf11",
    "8467ec24fb74f30371d5a13e893fc56309ee9372"
  ],
  "changeHistoryShort": {
    "66e8f9b31529226309c924226a53dead3e6fcf11": "Ymultichange(Yparameterchange,Ybodychange)",
    "8467ec24fb74f30371d5a13e893fc56309ee9372": "Yintroduced"
  },
  "changeHistoryDetails": {
    "66e8f9b31529226309c924226a53dead3e6fcf11": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-13381 : [SPS]: Use DFSUtilClient#makePathFromFileId() to prepare satisfier file path. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "66e8f9b31529226309c924226a53dead3e6fcf11",
      "commitAuthor": "Uma Maheswara Rao G",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-13381 : [SPS]: Use DFSUtilClient#makePathFromFileId() to prepare satisfier file path. Contributed by Rakesh R.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "66e8f9b31529226309c924226a53dead3e6fcf11",
          "commitAuthor": "Uma Maheswara Rao G",
          "commitDateOld": "12/08/18 3:06 AM",
          "commitNameOld": "8467ec24fb74f30371d5a13e893fc56309ee9372",
          "commitAuthorOld": "Rakesh Radhakrishnan",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 3,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,18 +1,19 @@\n-  public void scanAndCollectFiles(String path) throws IOException {\n+  public void scanAndCollectFiles(long pathId) throws IOException {\n     if (dfs \u003d\u003d null) {\n       dfs \u003d getFS(service.getConf());\n     }\n-    long pendingSatisfyItemsCount \u003d processPath(path, path);\n+    Path filePath \u003d DFSUtilClient.makePathFromFileId(pathId);\n+    long pendingSatisfyItemsCount \u003d processPath(pathId, filePath.toString());\n     // Check whether the given path contains any item to be tracked\n     // or the no to be satisfied paths. In case of empty list, add the given\n     // inodeId to the \u0027pendingWorkForDirectory\u0027 with empty list so that later\n     // SPSPathIdProcessor#run function will remove the SPS hint considering that\n     // this path is already satisfied the storage policy.\n     if (pendingSatisfyItemsCount \u003c\u003d 0) {\n       LOG.debug(\"There is no pending items to satisfy the given path \"\n-          + \"inodeId:{}\", path);\n-      service.addAllFilesToProcess(path, new ArrayList\u003c\u003e(), true);\n+          + \"inodeId:{}\", pathId);\n+      service.addAllFilesToProcess(pathId, new ArrayList\u003c\u003e(), true);\n     } else {\n-      service.markScanCompletedForPath(path);\n+      service.markScanCompletedForPath(pathId);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void scanAndCollectFiles(long pathId) throws IOException {\n    if (dfs \u003d\u003d null) {\n      dfs \u003d getFS(service.getConf());\n    }\n    Path filePath \u003d DFSUtilClient.makePathFromFileId(pathId);\n    long pendingSatisfyItemsCount \u003d processPath(pathId, filePath.toString());\n    // Check whether the given path contains any item to be tracked\n    // or the no to be satisfied paths. In case of empty list, add the given\n    // inodeId to the \u0027pendingWorkForDirectory\u0027 with empty list so that later\n    // SPSPathIdProcessor#run function will remove the SPS hint considering that\n    // this path is already satisfied the storage policy.\n    if (pendingSatisfyItemsCount \u003c\u003d 0) {\n      LOG.debug(\"There is no pending items to satisfy the given path \"\n          + \"inodeId:{}\", pathId);\n      service.addAllFilesToProcess(pathId, new ArrayList\u003c\u003e(), true);\n    } else {\n      service.markScanCompletedForPath(pathId);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/sps/ExternalSPSFilePathCollector.java",
          "extendedDetails": {
            "oldValue": "[path-String]",
            "newValue": "[pathId-long]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-13381 : [SPS]: Use DFSUtilClient#makePathFromFileId() to prepare satisfier file path. Contributed by Rakesh R.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "66e8f9b31529226309c924226a53dead3e6fcf11",
          "commitAuthor": "Uma Maheswara Rao G",
          "commitDateOld": "12/08/18 3:06 AM",
          "commitNameOld": "8467ec24fb74f30371d5a13e893fc56309ee9372",
          "commitAuthorOld": "Rakesh Radhakrishnan",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 3,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,18 +1,19 @@\n-  public void scanAndCollectFiles(String path) throws IOException {\n+  public void scanAndCollectFiles(long pathId) throws IOException {\n     if (dfs \u003d\u003d null) {\n       dfs \u003d getFS(service.getConf());\n     }\n-    long pendingSatisfyItemsCount \u003d processPath(path, path);\n+    Path filePath \u003d DFSUtilClient.makePathFromFileId(pathId);\n+    long pendingSatisfyItemsCount \u003d processPath(pathId, filePath.toString());\n     // Check whether the given path contains any item to be tracked\n     // or the no to be satisfied paths. In case of empty list, add the given\n     // inodeId to the \u0027pendingWorkForDirectory\u0027 with empty list so that later\n     // SPSPathIdProcessor#run function will remove the SPS hint considering that\n     // this path is already satisfied the storage policy.\n     if (pendingSatisfyItemsCount \u003c\u003d 0) {\n       LOG.debug(\"There is no pending items to satisfy the given path \"\n-          + \"inodeId:{}\", path);\n-      service.addAllFilesToProcess(path, new ArrayList\u003c\u003e(), true);\n+          + \"inodeId:{}\", pathId);\n+      service.addAllFilesToProcess(pathId, new ArrayList\u003c\u003e(), true);\n     } else {\n-      service.markScanCompletedForPath(path);\n+      service.markScanCompletedForPath(pathId);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void scanAndCollectFiles(long pathId) throws IOException {\n    if (dfs \u003d\u003d null) {\n      dfs \u003d getFS(service.getConf());\n    }\n    Path filePath \u003d DFSUtilClient.makePathFromFileId(pathId);\n    long pendingSatisfyItemsCount \u003d processPath(pathId, filePath.toString());\n    // Check whether the given path contains any item to be tracked\n    // or the no to be satisfied paths. In case of empty list, add the given\n    // inodeId to the \u0027pendingWorkForDirectory\u0027 with empty list so that later\n    // SPSPathIdProcessor#run function will remove the SPS hint considering that\n    // this path is already satisfied the storage policy.\n    if (pendingSatisfyItemsCount \u003c\u003d 0) {\n      LOG.debug(\"There is no pending items to satisfy the given path \"\n          + \"inodeId:{}\", pathId);\n      service.addAllFilesToProcess(pathId, new ArrayList\u003c\u003e(), true);\n    } else {\n      service.markScanCompletedForPath(pathId);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/sps/ExternalSPSFilePathCollector.java",
          "extendedDetails": {}
        }
      ]
    },
    "8467ec24fb74f30371d5a13e893fc56309ee9372": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-13110: [SPS]: Reduce the number of APIs in NamenodeProtocol used by external satisfier. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "8467ec24fb74f30371d5a13e893fc56309ee9372",
      "commitAuthor": "Rakesh Radhakrishnan",
      "diff": "@@ -0,0 +1,18 @@\n+  public void scanAndCollectFiles(String path) throws IOException {\n+    if (dfs \u003d\u003d null) {\n+      dfs \u003d getFS(service.getConf());\n+    }\n+    long pendingSatisfyItemsCount \u003d processPath(path, path);\n+    // Check whether the given path contains any item to be tracked\n+    // or the no to be satisfied paths. In case of empty list, add the given\n+    // inodeId to the \u0027pendingWorkForDirectory\u0027 with empty list so that later\n+    // SPSPathIdProcessor#run function will remove the SPS hint considering that\n+    // this path is already satisfied the storage policy.\n+    if (pendingSatisfyItemsCount \u003c\u003d 0) {\n+      LOG.debug(\"There is no pending items to satisfy the given path \"\n+          + \"inodeId:{}\", path);\n+      service.addAllFilesToProcess(path, new ArrayList\u003c\u003e(), true);\n+    } else {\n+      service.markScanCompletedForPath(path);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void scanAndCollectFiles(String path) throws IOException {\n    if (dfs \u003d\u003d null) {\n      dfs \u003d getFS(service.getConf());\n    }\n    long pendingSatisfyItemsCount \u003d processPath(path, path);\n    // Check whether the given path contains any item to be tracked\n    // or the no to be satisfied paths. In case of empty list, add the given\n    // inodeId to the \u0027pendingWorkForDirectory\u0027 with empty list so that later\n    // SPSPathIdProcessor#run function will remove the SPS hint considering that\n    // this path is already satisfied the storage policy.\n    if (pendingSatisfyItemsCount \u003c\u003d 0) {\n      LOG.debug(\"There is no pending items to satisfy the given path \"\n          + \"inodeId:{}\", path);\n      service.addAllFilesToProcess(path, new ArrayList\u003c\u003e(), true);\n    } else {\n      service.markScanCompletedForPath(path);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/sps/ExternalSPSFilePathCollector.java"
    }
  }
}