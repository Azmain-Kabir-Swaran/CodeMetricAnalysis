{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "S3AInstrumentation.java",
  "functionName": "toString",
  "functionId": "toString",
  "sourceFilePath": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AInstrumentation.java",
  "functionStartLine": 804,
  "functionEndLine": 832,
  "numCommitsSeen": 27,
  "timeTaken": 1692,
  "changeHistory": [
    "dab00da19f25619ccc71c7f803a235b21766bf1e",
    "6c348c56918973fd988b110e79231324a8befe12",
    "4ee3543625c77c06d566fe81644d21c607d6d74d",
    "27c4e90efce04e1b1302f668b5eb22412e00d033"
  ],
  "changeHistoryShort": {
    "dab00da19f25619ccc71c7f803a235b21766bf1e": "Ybodychange",
    "6c348c56918973fd988b110e79231324a8befe12": "Ybodychange",
    "4ee3543625c77c06d566fe81644d21c607d6d74d": "Ybodychange",
    "27c4e90efce04e1b1302f668b5eb22412e00d033": "Yintroduced"
  },
  "changeHistoryDetails": {
    "dab00da19f25619ccc71c7f803a235b21766bf1e": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-14028. S3A BlockOutputStreams doesn\u0027t delete temporary files in multipart uploads or handle part upload failures.\nContributed by Steve Loughran.\n\n(cherry picked from commit 29fe5af017b945d8750c074ca39031b5b777eddd)\n",
      "commitDate": "25/02/17 7:35 AM",
      "commitName": "dab00da19f25619ccc71c7f803a235b21766bf1e",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "20/10/16 6:50 AM",
      "commitNameOld": "9ae270af02c243993f853513c731cb268430e492",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 128.07,
      "commitsBetweenForRepo": 788,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,25 @@\n     public String toString() {\n       final StringBuilder sb \u003d new StringBuilder(\n           \"OutputStreamStatistics{\");\n       sb.append(\"blocksSubmitted\u003d\").append(blocksSubmitted);\n       sb.append(\", blocksInQueue\u003d\").append(blocksInQueue);\n       sb.append(\", blocksActive\u003d\").append(blocksActive);\n       sb.append(\", blockUploadsCompleted\u003d\").append(blockUploadsCompleted);\n       sb.append(\", blockUploadsFailed\u003d\").append(blockUploadsFailed);\n       sb.append(\", bytesPendingUpload\u003d\").append(bytesPendingUpload);\n       sb.append(\", bytesUploaded\u003d\").append(bytesUploaded);\n+      sb.append(\", blocksAllocated\u003d\").append(blocksAllocated);\n+      sb.append(\", blocksReleased\u003d\").append(blocksReleased);\n+      sb.append(\", blocksActivelyAllocated\u003d\").append(blocksActivelyAllocated());\n       sb.append(\", exceptionsInMultipartFinalize\u003d\").append(\n           exceptionsInMultipartFinalize);\n       sb.append(\", transferDuration\u003d\").append(transferDuration).append(\" ms\");\n       sb.append(\", queueDuration\u003d\").append(queueDuration).append(\" ms\");\n       sb.append(\", averageQueueTime\u003d\").append(averageQueueTime()).append(\" ms\");\n       sb.append(\", totalUploadDuration\u003d\").append(totalUploadDuration())\n           .append(\" ms\");\n       sb.append(\", effectiveBandwidth\u003d\").append(effectiveBandwidth())\n           .append(\" bytes/s\");\n       sb.append(\u0027}\u0027);\n       return sb.toString();\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public String toString() {\n      final StringBuilder sb \u003d new StringBuilder(\n          \"OutputStreamStatistics{\");\n      sb.append(\"blocksSubmitted\u003d\").append(blocksSubmitted);\n      sb.append(\", blocksInQueue\u003d\").append(blocksInQueue);\n      sb.append(\", blocksActive\u003d\").append(blocksActive);\n      sb.append(\", blockUploadsCompleted\u003d\").append(blockUploadsCompleted);\n      sb.append(\", blockUploadsFailed\u003d\").append(blockUploadsFailed);\n      sb.append(\", bytesPendingUpload\u003d\").append(bytesPendingUpload);\n      sb.append(\", bytesUploaded\u003d\").append(bytesUploaded);\n      sb.append(\", blocksAllocated\u003d\").append(blocksAllocated);\n      sb.append(\", blocksReleased\u003d\").append(blocksReleased);\n      sb.append(\", blocksActivelyAllocated\u003d\").append(blocksActivelyAllocated());\n      sb.append(\", exceptionsInMultipartFinalize\u003d\").append(\n          exceptionsInMultipartFinalize);\n      sb.append(\", transferDuration\u003d\").append(transferDuration).append(\" ms\");\n      sb.append(\", queueDuration\u003d\").append(queueDuration).append(\" ms\");\n      sb.append(\", averageQueueTime\u003d\").append(averageQueueTime()).append(\" ms\");\n      sb.append(\", totalUploadDuration\u003d\").append(totalUploadDuration())\n          .append(\" ms\");\n      sb.append(\", effectiveBandwidth\u003d\").append(effectiveBandwidth())\n          .append(\" bytes/s\");\n      sb.append(\u0027}\u0027);\n      return sb.toString();\n    }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AInstrumentation.java",
      "extendedDetails": {}
    },
    "6c348c56918973fd988b110e79231324a8befe12": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-13560. S3ABlockOutputStream to support huge (many GB) file writes. Contributed by Steve Loughran\n",
      "commitDate": "18/10/16 1:16 PM",
      "commitName": "6c348c56918973fd988b110e79231324a8befe12",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "29/09/16 9:01 AM",
      "commitNameOld": "ee0c722dc8fb81ec902cd1da5958ce5adb0ab08f",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 19.18,
      "commitsBetweenForRepo": 137,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,26 +1,22 @@\n     public String toString() {\n       final StringBuilder sb \u003d new StringBuilder(\n-          \"StreamStatistics{\");\n-      sb.append(\"OpenOperations\u003d\").append(openOperations);\n-      sb.append(\", CloseOperations\u003d\").append(closeOperations);\n-      sb.append(\", Closed\u003d\").append(closed);\n-      sb.append(\", Aborted\u003d\").append(aborted);\n-      sb.append(\", SeekOperations\u003d\").append(seekOperations);\n-      sb.append(\", ReadExceptions\u003d\").append(readExceptions);\n-      sb.append(\", ForwardSeekOperations\u003d\")\n-          .append(forwardSeekOperations);\n-      sb.append(\", BackwardSeekOperations\u003d\")\n-          .append(backwardSeekOperations);\n-      sb.append(\", BytesSkippedOnSeek\u003d\").append(bytesSkippedOnSeek);\n-      sb.append(\", BytesBackwardsOnSeek\u003d\").append(bytesBackwardsOnSeek);\n-      sb.append(\", BytesRead\u003d\").append(bytesRead);\n-      sb.append(\", BytesRead excluding skipped\u003d\")\n-          .append(bytesRead - bytesSkippedOnSeek);\n-      sb.append(\", ReadOperations\u003d\").append(readOperations);\n-      sb.append(\", ReadFullyOperations\u003d\").append(readFullyOperations);\n-      sb.append(\", ReadsIncomplete\u003d\").append(readsIncomplete);\n-      sb.append(\", BytesReadInClose\u003d\").append(bytesReadInClose);\n-      sb.append(\", BytesDiscardedInAbort\u003d\").append(bytesDiscardedInAbort);\n+          \"OutputStreamStatistics{\");\n+      sb.append(\"blocksSubmitted\u003d\").append(blocksSubmitted);\n+      sb.append(\", blocksInQueue\u003d\").append(blocksInQueue);\n+      sb.append(\", blocksActive\u003d\").append(blocksActive);\n+      sb.append(\", blockUploadsCompleted\u003d\").append(blockUploadsCompleted);\n+      sb.append(\", blockUploadsFailed\u003d\").append(blockUploadsFailed);\n+      sb.append(\", bytesPendingUpload\u003d\").append(bytesPendingUpload);\n+      sb.append(\", bytesUploaded\u003d\").append(bytesUploaded);\n+      sb.append(\", exceptionsInMultipartFinalize\u003d\").append(\n+          exceptionsInMultipartFinalize);\n+      sb.append(\", transferDuration\u003d\").append(transferDuration).append(\" ms\");\n+      sb.append(\", queueDuration\u003d\").append(queueDuration).append(\" ms\");\n+      sb.append(\", averageQueueTime\u003d\").append(averageQueueTime()).append(\" ms\");\n+      sb.append(\", totalUploadDuration\u003d\").append(totalUploadDuration())\n+          .append(\" ms\");\n+      sb.append(\", effectiveBandwidth\u003d\").append(effectiveBandwidth())\n+          .append(\" bytes/s\");\n       sb.append(\u0027}\u0027);\n       return sb.toString();\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public String toString() {\n      final StringBuilder sb \u003d new StringBuilder(\n          \"OutputStreamStatistics{\");\n      sb.append(\"blocksSubmitted\u003d\").append(blocksSubmitted);\n      sb.append(\", blocksInQueue\u003d\").append(blocksInQueue);\n      sb.append(\", blocksActive\u003d\").append(blocksActive);\n      sb.append(\", blockUploadsCompleted\u003d\").append(blockUploadsCompleted);\n      sb.append(\", blockUploadsFailed\u003d\").append(blockUploadsFailed);\n      sb.append(\", bytesPendingUpload\u003d\").append(bytesPendingUpload);\n      sb.append(\", bytesUploaded\u003d\").append(bytesUploaded);\n      sb.append(\", exceptionsInMultipartFinalize\u003d\").append(\n          exceptionsInMultipartFinalize);\n      sb.append(\", transferDuration\u003d\").append(transferDuration).append(\" ms\");\n      sb.append(\", queueDuration\u003d\").append(queueDuration).append(\" ms\");\n      sb.append(\", averageQueueTime\u003d\").append(averageQueueTime()).append(\" ms\");\n      sb.append(\", totalUploadDuration\u003d\").append(totalUploadDuration())\n          .append(\" ms\");\n      sb.append(\", effectiveBandwidth\u003d\").append(effectiveBandwidth())\n          .append(\" bytes/s\");\n      sb.append(\u0027}\u0027);\n      return sb.toString();\n    }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AInstrumentation.java",
      "extendedDetails": {}
    },
    "4ee3543625c77c06d566fe81644d21c607d6d74d": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-13203 S3A: Support fadvise \"random\" mode for high performance readPositioned() reads. Contributed by Rajesh Balamohan and stevel.\n",
      "commitDate": "22/06/16 7:45 AM",
      "commitName": "4ee3543625c77c06d566fe81644d21c607d6d74d",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "03/06/16 8:55 AM",
      "commitNameOld": "c58a59f7081d55dd2108545ebf9ee48cf43ca944",
      "commitAuthorOld": "Chris Nauroth",
      "daysBetweenCommits": 18.95,
      "commitsBetweenForRepo": 123,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,26 @@\n     public String toString() {\n       final StringBuilder sb \u003d new StringBuilder(\n           \"StreamStatistics{\");\n       sb.append(\"OpenOperations\u003d\").append(openOperations);\n       sb.append(\", CloseOperations\u003d\").append(closeOperations);\n       sb.append(\", Closed\u003d\").append(closed);\n       sb.append(\", Aborted\u003d\").append(aborted);\n       sb.append(\", SeekOperations\u003d\").append(seekOperations);\n       sb.append(\", ReadExceptions\u003d\").append(readExceptions);\n       sb.append(\", ForwardSeekOperations\u003d\")\n           .append(forwardSeekOperations);\n       sb.append(\", BackwardSeekOperations\u003d\")\n           .append(backwardSeekOperations);\n       sb.append(\", BytesSkippedOnSeek\u003d\").append(bytesSkippedOnSeek);\n       sb.append(\", BytesBackwardsOnSeek\u003d\").append(bytesBackwardsOnSeek);\n       sb.append(\", BytesRead\u003d\").append(bytesRead);\n       sb.append(\", BytesRead excluding skipped\u003d\")\n           .append(bytesRead - bytesSkippedOnSeek);\n       sb.append(\", ReadOperations\u003d\").append(readOperations);\n       sb.append(\", ReadFullyOperations\u003d\").append(readFullyOperations);\n       sb.append(\", ReadsIncomplete\u003d\").append(readsIncomplete);\n+      sb.append(\", BytesReadInClose\u003d\").append(bytesReadInClose);\n+      sb.append(\", BytesDiscardedInAbort\u003d\").append(bytesDiscardedInAbort);\n       sb.append(\u0027}\u0027);\n       return sb.toString();\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public String toString() {\n      final StringBuilder sb \u003d new StringBuilder(\n          \"StreamStatistics{\");\n      sb.append(\"OpenOperations\u003d\").append(openOperations);\n      sb.append(\", CloseOperations\u003d\").append(closeOperations);\n      sb.append(\", Closed\u003d\").append(closed);\n      sb.append(\", Aborted\u003d\").append(aborted);\n      sb.append(\", SeekOperations\u003d\").append(seekOperations);\n      sb.append(\", ReadExceptions\u003d\").append(readExceptions);\n      sb.append(\", ForwardSeekOperations\u003d\")\n          .append(forwardSeekOperations);\n      sb.append(\", BackwardSeekOperations\u003d\")\n          .append(backwardSeekOperations);\n      sb.append(\", BytesSkippedOnSeek\u003d\").append(bytesSkippedOnSeek);\n      sb.append(\", BytesBackwardsOnSeek\u003d\").append(bytesBackwardsOnSeek);\n      sb.append(\", BytesRead\u003d\").append(bytesRead);\n      sb.append(\", BytesRead excluding skipped\u003d\")\n          .append(bytesRead - bytesSkippedOnSeek);\n      sb.append(\", ReadOperations\u003d\").append(readOperations);\n      sb.append(\", ReadFullyOperations\u003d\").append(readFullyOperations);\n      sb.append(\", ReadsIncomplete\u003d\").append(readsIncomplete);\n      sb.append(\", BytesReadInClose\u003d\").append(bytesReadInClose);\n      sb.append(\", BytesDiscardedInAbort\u003d\").append(bytesDiscardedInAbort);\n      sb.append(\u0027}\u0027);\n      return sb.toString();\n    }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AInstrumentation.java",
      "extendedDetails": {}
    },
    "27c4e90efce04e1b1302f668b5eb22412e00d033": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-13028 add low level counter metrics for S3A; use in read performance tests. contributed by: stevel\npatch includes\nHADOOP-12844 Recover when S3A fails on IOException in read()\nHADOOP-13058 S3A FS fails during init against a read-only FS if multipart purge\nHADOOP-13047 S3a Forward seek in stream length to be configurable\n",
      "commitDate": "12/05/16 11:24 AM",
      "commitName": "27c4e90efce04e1b1302f668b5eb22412e00d033",
      "commitAuthor": "Steve Loughran",
      "diff": "@@ -0,0 +1,24 @@\n+    public String toString() {\n+      final StringBuilder sb \u003d new StringBuilder(\n+          \"StreamStatistics{\");\n+      sb.append(\"OpenOperations\u003d\").append(openOperations);\n+      sb.append(\", CloseOperations\u003d\").append(closeOperations);\n+      sb.append(\", Closed\u003d\").append(closed);\n+      sb.append(\", Aborted\u003d\").append(aborted);\n+      sb.append(\", SeekOperations\u003d\").append(seekOperations);\n+      sb.append(\", ReadExceptions\u003d\").append(readExceptions);\n+      sb.append(\", ForwardSeekOperations\u003d\")\n+          .append(forwardSeekOperations);\n+      sb.append(\", BackwardSeekOperations\u003d\")\n+          .append(backwardSeekOperations);\n+      sb.append(\", BytesSkippedOnSeek\u003d\").append(bytesSkippedOnSeek);\n+      sb.append(\", BytesBackwardsOnSeek\u003d\").append(bytesBackwardsOnSeek);\n+      sb.append(\", BytesRead\u003d\").append(bytesRead);\n+      sb.append(\", BytesRead excluding skipped\u003d\")\n+          .append(bytesRead - bytesSkippedOnSeek);\n+      sb.append(\", ReadOperations\u003d\").append(readOperations);\n+      sb.append(\", ReadFullyOperations\u003d\").append(readFullyOperations);\n+      sb.append(\", ReadsIncomplete\u003d\").append(readsIncomplete);\n+      sb.append(\u0027}\u0027);\n+      return sb.toString();\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    public String toString() {\n      final StringBuilder sb \u003d new StringBuilder(\n          \"StreamStatistics{\");\n      sb.append(\"OpenOperations\u003d\").append(openOperations);\n      sb.append(\", CloseOperations\u003d\").append(closeOperations);\n      sb.append(\", Closed\u003d\").append(closed);\n      sb.append(\", Aborted\u003d\").append(aborted);\n      sb.append(\", SeekOperations\u003d\").append(seekOperations);\n      sb.append(\", ReadExceptions\u003d\").append(readExceptions);\n      sb.append(\", ForwardSeekOperations\u003d\")\n          .append(forwardSeekOperations);\n      sb.append(\", BackwardSeekOperations\u003d\")\n          .append(backwardSeekOperations);\n      sb.append(\", BytesSkippedOnSeek\u003d\").append(bytesSkippedOnSeek);\n      sb.append(\", BytesBackwardsOnSeek\u003d\").append(bytesBackwardsOnSeek);\n      sb.append(\", BytesRead\u003d\").append(bytesRead);\n      sb.append(\", BytesRead excluding skipped\u003d\")\n          .append(bytesRead - bytesSkippedOnSeek);\n      sb.append(\", ReadOperations\u003d\").append(readOperations);\n      sb.append(\", ReadFullyOperations\u003d\").append(readFullyOperations);\n      sb.append(\", ReadsIncomplete\u003d\").append(readsIncomplete);\n      sb.append(\u0027}\u0027);\n      return sb.toString();\n    }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AInstrumentation.java"
    }
  }
}