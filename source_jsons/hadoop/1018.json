{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FileChecksumHelper.java",
  "functionName": "checksumBlocks",
  "functionId": "checksumBlocks",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/FileChecksumHelper.java",
  "functionStartLine": 494,
  "functionEndLine": 510,
  "numCommitsSeen": 9,
  "timeTaken": 1938,
  "changeHistory": [
    "7c9cdad6d04c98db5a83e2108219bf6e6c903daf",
    "3a4ff7776e8fab6cc87932b9aa8fb48f7b69c720",
    "a337ceb74e984991dbf976236d2e785cf5921b16",
    "e5ff0ea7ba087984262f1f27200ae5bb40d9b838",
    "307ec80acae3b4a41d21b2d4b3a55032e55fcdc6"
  ],
  "changeHistoryShort": {
    "7c9cdad6d04c98db5a83e2108219bf6e6c903daf": "Ybodychange",
    "3a4ff7776e8fab6cc87932b9aa8fb48f7b69c720": "Ybodychange",
    "a337ceb74e984991dbf976236d2e785cf5921b16": "Ybodychange",
    "e5ff0ea7ba087984262f1f27200ae5bb40d9b838": "Ybodychange",
    "307ec80acae3b4a41d21b2d4b3a55032e55fcdc6": "Yintroduced"
  },
  "changeHistoryDetails": {
    "7c9cdad6d04c98db5a83e2108219bf6e6c903daf": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13056. Expose file-level composite CRCs in HDFS which are comparable across different instances/layouts. Contributed by Dennis Huo.\n",
      "commitDate": "10/04/18 9:31 PM",
      "commitName": "7c9cdad6d04c98db5a83e2108219bf6e6c903daf",
      "commitAuthor": "Xiao Chen",
      "commitDateOld": "03/01/18 2:54 PM",
      "commitNameOld": "3ba985997d1dc37e5ba017dd0ab1d36083b5f77b",
      "commitAuthorOld": "Xiaoyu Yao",
      "daysBetweenCommits": 97.23,
      "commitsBetweenForRepo": 742,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,18 +1,19 @@\n     void checksumBlocks() throws IOException {\n       int tmpTimeout \u003d 3000 * 1 + getClient().getConf().getSocketTimeout();\n       setTimeout(tmpTimeout);\n \n       for (bgIdx \u003d 0;\n            bgIdx \u003c getLocatedBlocks().size() \u0026\u0026 getRemaining() \u003e\u003d 0; bgIdx++) {\n         if (isRefetchBlocks()) {  // refetch to get fresh tokens\n           refetchBlocks();\n         }\n \n         LocatedBlock locatedBlock \u003d getLocatedBlocks().get(bgIdx);\n         LocatedStripedBlock blockGroup \u003d (LocatedStripedBlock) locatedBlock;\n \n         if (!checksumBlockGroup(blockGroup)) {\n-          throw new IOException(\"Fail to get block MD5 for \" + locatedBlock);\n+          throw new PathIOException(\n+              getSrc(), \"Fail to get block checksum for \" + locatedBlock);\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void checksumBlocks() throws IOException {\n      int tmpTimeout \u003d 3000 * 1 + getClient().getConf().getSocketTimeout();\n      setTimeout(tmpTimeout);\n\n      for (bgIdx \u003d 0;\n           bgIdx \u003c getLocatedBlocks().size() \u0026\u0026 getRemaining() \u003e\u003d 0; bgIdx++) {\n        if (isRefetchBlocks()) {  // refetch to get fresh tokens\n          refetchBlocks();\n        }\n\n        LocatedBlock locatedBlock \u003d getLocatedBlocks().get(bgIdx);\n        LocatedStripedBlock blockGroup \u003d (LocatedStripedBlock) locatedBlock;\n\n        if (!checksumBlockGroup(blockGroup)) {\n          throw new PathIOException(\n              getSrc(), \"Fail to get block checksum for \" + locatedBlock);\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/FileChecksumHelper.java",
      "extendedDetails": {}
    },
    "3a4ff7776e8fab6cc87932b9aa8fb48f7b69c720": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9694. Make existing DFSClient#getFileChecksum() work for striped blocks. Contributed by Kai Zheng\n",
      "commitDate": "26/03/16 7:58 PM",
      "commitName": "3a4ff7776e8fab6cc87932b9aa8fb48f7b69c720",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "26/03/16 9:20 AM",
      "commitNameOld": "a337ceb74e984991dbf976236d2e785cf5921b16",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 0.44,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,19 +1,18 @@\n     void checksumBlocks() throws IOException {\n-      // get block checksum for each block\n-      for (blockIdx \u003d 0;\n-           blockIdx \u003c getLocatedBlocks().size() \u0026\u0026 getRemaining() \u003e\u003d 0;\n-           blockIdx++) {\n+      int tmpTimeout \u003d 3000 * 1 + getClient().getConf().getSocketTimeout();\n+      setTimeout(tmpTimeout);\n+\n+      for (bgIdx \u003d 0;\n+           bgIdx \u003c getLocatedBlocks().size() \u0026\u0026 getRemaining() \u003e\u003d 0; bgIdx++) {\n         if (isRefetchBlocks()) {  // refetch to get fresh tokens\n-          setBlockLocations(getClient().getBlockLocations(getSrc(),\n-              getLength()));\n-          setLocatedBlocks(getBlockLocations().getLocatedBlocks());\n-          setRefetchBlocks(false);\n+          refetchBlocks();\n         }\n \n-        LocatedBlock locatedBlock \u003d getLocatedBlocks().get(blockIdx);\n+        LocatedBlock locatedBlock \u003d getLocatedBlocks().get(bgIdx);\n+        LocatedStripedBlock blockGroup \u003d (LocatedStripedBlock) locatedBlock;\n \n-        if (!checksumBlock(locatedBlock)) {\n+        if (!checksumBlockGroup(blockGroup)) {\n           throw new IOException(\"Fail to get block MD5 for \" + locatedBlock);\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void checksumBlocks() throws IOException {\n      int tmpTimeout \u003d 3000 * 1 + getClient().getConf().getSocketTimeout();\n      setTimeout(tmpTimeout);\n\n      for (bgIdx \u003d 0;\n           bgIdx \u003c getLocatedBlocks().size() \u0026\u0026 getRemaining() \u003e\u003d 0; bgIdx++) {\n        if (isRefetchBlocks()) {  // refetch to get fresh tokens\n          refetchBlocks();\n        }\n\n        LocatedBlock locatedBlock \u003d getLocatedBlocks().get(bgIdx);\n        LocatedStripedBlock blockGroup \u003d (LocatedStripedBlock) locatedBlock;\n\n        if (!checksumBlockGroup(blockGroup)) {\n          throw new IOException(\"Fail to get block MD5 for \" + locatedBlock);\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/FileChecksumHelper.java",
      "extendedDetails": {}
    },
    "a337ceb74e984991dbf976236d2e785cf5921b16": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-9694. Make existing DFSClient#getFileChecksum() work for striped blocks. Contributed by Kai Zheng\"\n\nThis reverts commit e5ff0ea7ba087984262f1f27200ae5bb40d9b838.\n",
      "commitDate": "26/03/16 9:20 AM",
      "commitName": "a337ceb74e984991dbf976236d2e785cf5921b16",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "26/03/16 12:52 AM",
      "commitNameOld": "e5ff0ea7ba087984262f1f27200ae5bb40d9b838",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.35,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,18 +1,19 @@\n     void checksumBlocks() throws IOException {\n-      int tmpTimeout \u003d 3000 * 1 + getClient().getConf().getSocketTimeout();\n-      setTimeout(tmpTimeout);\n-\n-      for (bgIdx \u003d 0;\n-           bgIdx \u003c getLocatedBlocks().size() \u0026\u0026 getRemaining() \u003e\u003d 0; bgIdx++) {\n+      // get block checksum for each block\n+      for (blockIdx \u003d 0;\n+           blockIdx \u003c getLocatedBlocks().size() \u0026\u0026 getRemaining() \u003e\u003d 0;\n+           blockIdx++) {\n         if (isRefetchBlocks()) {  // refetch to get fresh tokens\n-          refetchBlocks();\n+          setBlockLocations(getClient().getBlockLocations(getSrc(),\n+              getLength()));\n+          setLocatedBlocks(getBlockLocations().getLocatedBlocks());\n+          setRefetchBlocks(false);\n         }\n \n-        LocatedBlock locatedBlock \u003d getLocatedBlocks().get(bgIdx);\n-        LocatedStripedBlock blockGroup \u003d (LocatedStripedBlock) locatedBlock;\n+        LocatedBlock locatedBlock \u003d getLocatedBlocks().get(blockIdx);\n \n-        if (!checksumBlockGroup(blockGroup)) {\n+        if (!checksumBlock(locatedBlock)) {\n           throw new IOException(\"Fail to get block MD5 for \" + locatedBlock);\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void checksumBlocks() throws IOException {\n      // get block checksum for each block\n      for (blockIdx \u003d 0;\n           blockIdx \u003c getLocatedBlocks().size() \u0026\u0026 getRemaining() \u003e\u003d 0;\n           blockIdx++) {\n        if (isRefetchBlocks()) {  // refetch to get fresh tokens\n          setBlockLocations(getClient().getBlockLocations(getSrc(),\n              getLength()));\n          setLocatedBlocks(getBlockLocations().getLocatedBlocks());\n          setRefetchBlocks(false);\n        }\n\n        LocatedBlock locatedBlock \u003d getLocatedBlocks().get(blockIdx);\n\n        if (!checksumBlock(locatedBlock)) {\n          throw new IOException(\"Fail to get block MD5 for \" + locatedBlock);\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/FileChecksumHelper.java",
      "extendedDetails": {}
    },
    "e5ff0ea7ba087984262f1f27200ae5bb40d9b838": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9694. Make existing DFSClient#getFileChecksum() work for striped blocks. Contributed by Kai Zheng\n",
      "commitDate": "26/03/16 12:52 AM",
      "commitName": "e5ff0ea7ba087984262f1f27200ae5bb40d9b838",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "29/02/16 9:52 PM",
      "commitNameOld": "307ec80acae3b4a41d21b2d4b3a55032e55fcdc6",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 25.08,
      "commitsBetweenForRepo": 134,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,19 +1,18 @@\n     void checksumBlocks() throws IOException {\n-      // get block checksum for each block\n-      for (blockIdx \u003d 0;\n-           blockIdx \u003c getLocatedBlocks().size() \u0026\u0026 getRemaining() \u003e\u003d 0;\n-           blockIdx++) {\n+      int tmpTimeout \u003d 3000 * 1 + getClient().getConf().getSocketTimeout();\n+      setTimeout(tmpTimeout);\n+\n+      for (bgIdx \u003d 0;\n+           bgIdx \u003c getLocatedBlocks().size() \u0026\u0026 getRemaining() \u003e\u003d 0; bgIdx++) {\n         if (isRefetchBlocks()) {  // refetch to get fresh tokens\n-          setBlockLocations(getClient().getBlockLocations(getSrc(),\n-              getLength()));\n-          setLocatedBlocks(getBlockLocations().getLocatedBlocks());\n-          setRefetchBlocks(false);\n+          refetchBlocks();\n         }\n \n-        LocatedBlock locatedBlock \u003d getLocatedBlocks().get(blockIdx);\n+        LocatedBlock locatedBlock \u003d getLocatedBlocks().get(bgIdx);\n+        LocatedStripedBlock blockGroup \u003d (LocatedStripedBlock) locatedBlock;\n \n-        if (!checksumBlock(locatedBlock)) {\n+        if (!checksumBlockGroup(blockGroup)) {\n           throw new IOException(\"Fail to get block MD5 for \" + locatedBlock);\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void checksumBlocks() throws IOException {\n      int tmpTimeout \u003d 3000 * 1 + getClient().getConf().getSocketTimeout();\n      setTimeout(tmpTimeout);\n\n      for (bgIdx \u003d 0;\n           bgIdx \u003c getLocatedBlocks().size() \u0026\u0026 getRemaining() \u003e\u003d 0; bgIdx++) {\n        if (isRefetchBlocks()) {  // refetch to get fresh tokens\n          refetchBlocks();\n        }\n\n        LocatedBlock locatedBlock \u003d getLocatedBlocks().get(bgIdx);\n        LocatedStripedBlock blockGroup \u003d (LocatedStripedBlock) locatedBlock;\n\n        if (!checksumBlockGroup(blockGroup)) {\n          throw new IOException(\"Fail to get block MD5 for \" + locatedBlock);\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/FileChecksumHelper.java",
      "extendedDetails": {}
    },
    "307ec80acae3b4a41d21b2d4b3a55032e55fcdc6": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-9733. Refactor DFSClient#getFileChecksum and DataXceiver#blockChecksum. Contributed by Kai Zheng\n",
      "commitDate": "29/02/16 9:52 PM",
      "commitName": "307ec80acae3b4a41d21b2d4b3a55032e55fcdc6",
      "commitAuthor": "Uma Maheswara Rao G",
      "diff": "@@ -0,0 +1,19 @@\n+    void checksumBlocks() throws IOException {\n+      // get block checksum for each block\n+      for (blockIdx \u003d 0;\n+           blockIdx \u003c getLocatedBlocks().size() \u0026\u0026 getRemaining() \u003e\u003d 0;\n+           blockIdx++) {\n+        if (isRefetchBlocks()) {  // refetch to get fresh tokens\n+          setBlockLocations(getClient().getBlockLocations(getSrc(),\n+              getLength()));\n+          setLocatedBlocks(getBlockLocations().getLocatedBlocks());\n+          setRefetchBlocks(false);\n+        }\n+\n+        LocatedBlock locatedBlock \u003d getLocatedBlocks().get(blockIdx);\n+\n+        if (!checksumBlock(locatedBlock)) {\n+          throw new IOException(\"Fail to get block MD5 for \" + locatedBlock);\n+        }\n+      }\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    void checksumBlocks() throws IOException {\n      // get block checksum for each block\n      for (blockIdx \u003d 0;\n           blockIdx \u003c getLocatedBlocks().size() \u0026\u0026 getRemaining() \u003e\u003d 0;\n           blockIdx++) {\n        if (isRefetchBlocks()) {  // refetch to get fresh tokens\n          setBlockLocations(getClient().getBlockLocations(getSrc(),\n              getLength()));\n          setLocatedBlocks(getBlockLocations().getLocatedBlocks());\n          setRefetchBlocks(false);\n        }\n\n        LocatedBlock locatedBlock \u003d getLocatedBlocks().get(blockIdx);\n\n        if (!checksumBlock(locatedBlock)) {\n          throw new IOException(\"Fail to get block MD5 for \" + locatedBlock);\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/FileChecksumHelper.java"
    }
  }
}