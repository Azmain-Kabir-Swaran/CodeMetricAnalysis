{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DiskBalancer.java",
  "functionName": "getBlockToCopy",
  "functionId": "getBlockToCopy___iter-FsVolumeSpi.BlockIterator__item-DiskBalancerWorkItem",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DiskBalancer.java",
  "functionStartLine": 903,
  "functionEndLine": 932,
  "numCommitsSeen": 32,
  "timeTaken": 2315,
  "changeHistory": [
    "4a212242d99071d028b40c2f5d40afb7f337e471",
    "041e7a7dee4a17714f31952dc6364c77a65b1b73",
    "1524e2e6c52aba966cbbf1d8025ba165688ab9bb",
    "59a3038bc3d7913dca3de971026bc32cef536a2d",
    "1594b472bb9df7537dbc001411c99058cc11ba41"
  ],
  "changeHistoryShort": {
    "4a212242d99071d028b40c2f5d40afb7f337e471": "Ybodychange",
    "041e7a7dee4a17714f31952dc6364c77a65b1b73": "Ybodychange",
    "1524e2e6c52aba966cbbf1d8025ba165688ab9bb": "Ybodychange",
    "59a3038bc3d7913dca3de971026bc32cef536a2d": "Ybodychange",
    "1594b472bb9df7537dbc001411c99058cc11ba41": "Yintroduced"
  },
  "changeHistoryDetails": {
    "4a212242d99071d028b40c2f5d40afb7f337e471": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14599. HDFS-12487 breaks test TestDiskBalancer.testDiskBalancerWithFedClusterWithOneNameServiceEmpty. Contributed by He Xiaoqiao.\n",
      "commitDate": "27/06/19 10:00 AM",
      "commitName": "4a212242d99071d028b40c2f5d40afb7f337e471",
      "commitAuthor": "Inigo Goiri",
      "commitDateOld": "24/06/19 7:07 PM",
      "commitNameOld": "041e7a7dee4a17714f31952dc6364c77a65b1b73",
      "commitAuthorOld": "Anu Engineer",
      "daysBetweenCommits": 2.62,
      "commitsBetweenForRepo": 13,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,32 +1,30 @@\n     private ExtendedBlock getBlockToCopy(FsVolumeSpi.BlockIterator iter,\n                                          DiskBalancerWorkItem item) {\n       while (!iter.atEnd() \u0026\u0026 item.getErrorCount() \u003c getMaxError(item)) {\n         try {\n           ExtendedBlock block \u003d iter.nextBlock();\n           if(null \u003d\u003d block){\n-            LOG.info(\"NextBlock call returned null.No valid block to copy. {}\",\n-                    item.toJson());\n+            LOG.info(\"NextBlock call returned null. No valid block to copy. {}\",\n+                item.toJson());\n             return null;\n           }\n           // A valid block is a finalized block, we iterate until we get\n           // finalized blocks\n           if (!this.dataset.isValidBlock(block)) {\n             continue;\n           }\n           // We don\u0027t look for the best, we just do first fit\n           if (isLessThanNeeded(block.getNumBytes(), item)) {\n             return block;\n           }\n         } catch (IOException e) {\n           item.incErrorCount();\n         }\n       }\n-\n       if (item.getErrorCount() \u003e\u003d getMaxError(item)) {\n         item.setErrMsg(\"Error count exceeded.\");\n         LOG.info(\"Maximum error count exceeded. Error count: {} Max error:{} \",\n             item.getErrorCount(), item.getMaxDiskErrors());\n       }\n-\n       return null;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private ExtendedBlock getBlockToCopy(FsVolumeSpi.BlockIterator iter,\n                                         DiskBalancerWorkItem item) {\n      while (!iter.atEnd() \u0026\u0026 item.getErrorCount() \u003c getMaxError(item)) {\n        try {\n          ExtendedBlock block \u003d iter.nextBlock();\n          if(null \u003d\u003d block){\n            LOG.info(\"NextBlock call returned null. No valid block to copy. {}\",\n                item.toJson());\n            return null;\n          }\n          // A valid block is a finalized block, we iterate until we get\n          // finalized blocks\n          if (!this.dataset.isValidBlock(block)) {\n            continue;\n          }\n          // We don\u0027t look for the best, we just do first fit\n          if (isLessThanNeeded(block.getNumBytes(), item)) {\n            return block;\n          }\n        } catch (IOException e) {\n          item.incErrorCount();\n        }\n      }\n      if (item.getErrorCount() \u003e\u003d getMaxError(item)) {\n        item.setErrMsg(\"Error count exceeded.\");\n        LOG.info(\"Maximum error count exceeded. Error count: {} Max error:{} \",\n            item.getErrorCount(), item.getMaxDiskErrors());\n      }\n      return null;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DiskBalancer.java",
      "extendedDetails": {}
    },
    "041e7a7dee4a17714f31952dc6364c77a65b1b73": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14598. Findbugs warning caused by HDFS-12487.\nContributed by He Xiaoqiao.\n",
      "commitDate": "24/06/19 7:07 PM",
      "commitName": "041e7a7dee4a17714f31952dc6364c77a65b1b73",
      "commitAuthor": "Anu Engineer",
      "commitDateOld": "21/06/19 6:17 PM",
      "commitNameOld": "1524e2e6c52aba966cbbf1d8025ba165688ab9bb",
      "commitAuthorOld": "Wei-Chiu Chuang",
      "daysBetweenCommits": 3.03,
      "commitsBetweenForRepo": 89,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,39 +1,32 @@\n     private ExtendedBlock getBlockToCopy(FsVolumeSpi.BlockIterator iter,\n                                          DiskBalancerWorkItem item) {\n       while (!iter.atEnd() \u0026\u0026 item.getErrorCount() \u003c getMaxError(item)) {\n         try {\n           ExtendedBlock block \u003d iter.nextBlock();\n           if(null \u003d\u003d block){\n             LOG.info(\"NextBlock call returned null.No valid block to copy. {}\",\n                     item.toJson());\n+            return null;\n+          }\n+          // A valid block is a finalized block, we iterate until we get\n+          // finalized blocks\n+          if (!this.dataset.isValidBlock(block)) {\n+            continue;\n+          }\n+          // We don\u0027t look for the best, we just do first fit\n+          if (isLessThanNeeded(block.getNumBytes(), item)) {\n             return block;\n           }\n-\n-          if (block !\u003d null) {\n-            // A valid block is a finalized block, we iterate until we get\n-            // finalized blocks\n-            if (!this.dataset.isValidBlock(block)) {\n-              continue;\n-            }\n-\n-            // We don\u0027t look for the best, we just do first fit\n-            if (isLessThanNeeded(block.getNumBytes(), item)) {\n-              return block;\n-            }\n-          } else {\n-            LOG.info(\"There are no blocks in the blockPool {}\", iter.getBlockPoolId());\n-          }\n-\n         } catch (IOException e) {\n           item.incErrorCount();\n         }\n       }\n \n       if (item.getErrorCount() \u003e\u003d getMaxError(item)) {\n         item.setErrMsg(\"Error count exceeded.\");\n         LOG.info(\"Maximum error count exceeded. Error count: {} Max error:{} \",\n             item.getErrorCount(), item.getMaxDiskErrors());\n       }\n \n       return null;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private ExtendedBlock getBlockToCopy(FsVolumeSpi.BlockIterator iter,\n                                         DiskBalancerWorkItem item) {\n      while (!iter.atEnd() \u0026\u0026 item.getErrorCount() \u003c getMaxError(item)) {\n        try {\n          ExtendedBlock block \u003d iter.nextBlock();\n          if(null \u003d\u003d block){\n            LOG.info(\"NextBlock call returned null.No valid block to copy. {}\",\n                    item.toJson());\n            return null;\n          }\n          // A valid block is a finalized block, we iterate until we get\n          // finalized blocks\n          if (!this.dataset.isValidBlock(block)) {\n            continue;\n          }\n          // We don\u0027t look for the best, we just do first fit\n          if (isLessThanNeeded(block.getNumBytes(), item)) {\n            return block;\n          }\n        } catch (IOException e) {\n          item.incErrorCount();\n        }\n      }\n\n      if (item.getErrorCount() \u003e\u003d getMaxError(item)) {\n        item.setErrMsg(\"Error count exceeded.\");\n        LOG.info(\"Maximum error count exceeded. Error count: {} Max error:{} \",\n            item.getErrorCount(), item.getMaxDiskErrors());\n      }\n\n      return null;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DiskBalancer.java",
      "extendedDetails": {}
    },
    "1524e2e6c52aba966cbbf1d8025ba165688ab9bb": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12487. FsDatasetSpi.isValidBlock() lacks null pointer check inside and neither do the callers. Contributed by liumi.\n",
      "commitDate": "21/06/19 6:17 PM",
      "commitName": "1524e2e6c52aba966cbbf1d8025ba165688ab9bb",
      "commitAuthor": "Wei-Chiu Chuang",
      "commitDateOld": "04/02/19 11:59 AM",
      "commitNameOld": "0e79a865822eed05f3f8433976b2cfef8f427f25",
      "commitAuthorOld": "Inigo Goiri",
      "daysBetweenCommits": 137.22,
      "commitsBetweenForRepo": 992,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,34 +1,39 @@\n     private ExtendedBlock getBlockToCopy(FsVolumeSpi.BlockIterator iter,\n                                          DiskBalancerWorkItem item) {\n       while (!iter.atEnd() \u0026\u0026 item.getErrorCount() \u003c getMaxError(item)) {\n         try {\n           ExtendedBlock block \u003d iter.nextBlock();\n+          if(null \u003d\u003d block){\n+            LOG.info(\"NextBlock call returned null.No valid block to copy. {}\",\n+                    item.toJson());\n+            return block;\n+          }\n \n           if (block !\u003d null) {\n             // A valid block is a finalized block, we iterate until we get\n             // finalized blocks\n             if (!this.dataset.isValidBlock(block)) {\n               continue;\n             }\n \n             // We don\u0027t look for the best, we just do first fit\n             if (isLessThanNeeded(block.getNumBytes(), item)) {\n               return block;\n             }\n           } else {\n             LOG.info(\"There are no blocks in the blockPool {}\", iter.getBlockPoolId());\n           }\n \n         } catch (IOException e) {\n           item.incErrorCount();\n         }\n       }\n \n       if (item.getErrorCount() \u003e\u003d getMaxError(item)) {\n         item.setErrMsg(\"Error count exceeded.\");\n         LOG.info(\"Maximum error count exceeded. Error count: {} Max error:{} \",\n             item.getErrorCount(), item.getMaxDiskErrors());\n       }\n \n       return null;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private ExtendedBlock getBlockToCopy(FsVolumeSpi.BlockIterator iter,\n                                         DiskBalancerWorkItem item) {\n      while (!iter.atEnd() \u0026\u0026 item.getErrorCount() \u003c getMaxError(item)) {\n        try {\n          ExtendedBlock block \u003d iter.nextBlock();\n          if(null \u003d\u003d block){\n            LOG.info(\"NextBlock call returned null.No valid block to copy. {}\",\n                    item.toJson());\n            return block;\n          }\n\n          if (block !\u003d null) {\n            // A valid block is a finalized block, we iterate until we get\n            // finalized blocks\n            if (!this.dataset.isValidBlock(block)) {\n              continue;\n            }\n\n            // We don\u0027t look for the best, we just do first fit\n            if (isLessThanNeeded(block.getNumBytes(), item)) {\n              return block;\n            }\n          } else {\n            LOG.info(\"There are no blocks in the blockPool {}\", iter.getBlockPoolId());\n          }\n\n        } catch (IOException e) {\n          item.incErrorCount();\n        }\n      }\n\n      if (item.getErrorCount() \u003e\u003d getMaxError(item)) {\n        item.setErrMsg(\"Error count exceeded.\");\n        LOG.info(\"Maximum error count exceeded. Error count: {} Max error:{} \",\n            item.getErrorCount(), item.getMaxDiskErrors());\n      }\n\n      return null;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DiskBalancer.java",
      "extendedDetails": {}
    },
    "59a3038bc3d7913dca3de971026bc32cef536a2d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13715:diskbalancer does not work if one of the blockpools are empty on a Federated cluster. Contributed by Bharat Viswanadham\n",
      "commitDate": "02/07/18 9:43 PM",
      "commitName": "59a3038bc3d7913dca3de971026bc32cef536a2d",
      "commitAuthor": "Bharat Viswanadham",
      "commitDateOld": "06/03/18 9:09 AM",
      "commitNameOld": "7060725662cb3317ff2f0fcc38f965fd23e8e6aa",
      "commitAuthorOld": "Inigo Goiri",
      "daysBetweenCommits": 118.48,
      "commitsBetweenForRepo": 1461,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,30 +1,34 @@\n     private ExtendedBlock getBlockToCopy(FsVolumeSpi.BlockIterator iter,\n                                          DiskBalancerWorkItem item) {\n       while (!iter.atEnd() \u0026\u0026 item.getErrorCount() \u003c getMaxError(item)) {\n         try {\n           ExtendedBlock block \u003d iter.nextBlock();\n \n-          // A valid block is a finalized block, we iterate until we get\n-          // finalized blocks\n-          if (!this.dataset.isValidBlock(block)) {\n-            continue;\n-          }\n+          if (block !\u003d null) {\n+            // A valid block is a finalized block, we iterate until we get\n+            // finalized blocks\n+            if (!this.dataset.isValidBlock(block)) {\n+              continue;\n+            }\n \n-          // We don\u0027t look for the best, we just do first fit\n-          if (isLessThanNeeded(block.getNumBytes(), item)) {\n-            return block;\n+            // We don\u0027t look for the best, we just do first fit\n+            if (isLessThanNeeded(block.getNumBytes(), item)) {\n+              return block;\n+            }\n+          } else {\n+            LOG.info(\"There are no blocks in the blockPool {}\", iter.getBlockPoolId());\n           }\n \n         } catch (IOException e) {\n           item.incErrorCount();\n         }\n       }\n \n       if (item.getErrorCount() \u003e\u003d getMaxError(item)) {\n         item.setErrMsg(\"Error count exceeded.\");\n         LOG.info(\"Maximum error count exceeded. Error count: {} Max error:{} \",\n             item.getErrorCount(), item.getMaxDiskErrors());\n       }\n \n       return null;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private ExtendedBlock getBlockToCopy(FsVolumeSpi.BlockIterator iter,\n                                         DiskBalancerWorkItem item) {\n      while (!iter.atEnd() \u0026\u0026 item.getErrorCount() \u003c getMaxError(item)) {\n        try {\n          ExtendedBlock block \u003d iter.nextBlock();\n\n          if (block !\u003d null) {\n            // A valid block is a finalized block, we iterate until we get\n            // finalized blocks\n            if (!this.dataset.isValidBlock(block)) {\n              continue;\n            }\n\n            // We don\u0027t look for the best, we just do first fit\n            if (isLessThanNeeded(block.getNumBytes(), item)) {\n              return block;\n            }\n          } else {\n            LOG.info(\"There are no blocks in the blockPool {}\", iter.getBlockPoolId());\n          }\n\n        } catch (IOException e) {\n          item.incErrorCount();\n        }\n      }\n\n      if (item.getErrorCount() \u003e\u003d getMaxError(item)) {\n        item.setErrMsg(\"Error count exceeded.\");\n        LOG.info(\"Maximum error count exceeded. Error count: {} Max error:{} \",\n            item.getErrorCount(), item.getMaxDiskErrors());\n      }\n\n      return null;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DiskBalancer.java",
      "extendedDetails": {}
    },
    "1594b472bb9df7537dbc001411c99058cc11ba41": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-9543. DiskBalancer: Add Data mover. Contributed by Anu Engineer.\n",
      "commitDate": "23/06/16 6:20 PM",
      "commitName": "1594b472bb9df7537dbc001411c99058cc11ba41",
      "commitAuthor": "Anu Engineer",
      "diff": "@@ -0,0 +1,30 @@\n+    private ExtendedBlock getBlockToCopy(FsVolumeSpi.BlockIterator iter,\n+                                         DiskBalancerWorkItem item) {\n+      while (!iter.atEnd() \u0026\u0026 item.getErrorCount() \u003c getMaxError(item)) {\n+        try {\n+          ExtendedBlock block \u003d iter.nextBlock();\n+\n+          // A valid block is a finalized block, we iterate until we get\n+          // finalized blocks\n+          if (!this.dataset.isValidBlock(block)) {\n+            continue;\n+          }\n+\n+          // We don\u0027t look for the best, we just do first fit\n+          if (isLessThanNeeded(block.getNumBytes(), item)) {\n+            return block;\n+          }\n+\n+        } catch (IOException e) {\n+          item.incErrorCount();\n+        }\n+      }\n+\n+      if (item.getErrorCount() \u003e\u003d getMaxError(item)) {\n+        item.setErrMsg(\"Error count exceeded.\");\n+        LOG.info(\"Maximum error count exceeded. Error count: {} Max error:{} \"\n+            , item.getErrorCount(), item.getMaxDiskErrors());\n+      }\n+\n+      return null;\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    private ExtendedBlock getBlockToCopy(FsVolumeSpi.BlockIterator iter,\n                                         DiskBalancerWorkItem item) {\n      while (!iter.atEnd() \u0026\u0026 item.getErrorCount() \u003c getMaxError(item)) {\n        try {\n          ExtendedBlock block \u003d iter.nextBlock();\n\n          // A valid block is a finalized block, we iterate until we get\n          // finalized blocks\n          if (!this.dataset.isValidBlock(block)) {\n            continue;\n          }\n\n          // We don\u0027t look for the best, we just do first fit\n          if (isLessThanNeeded(block.getNumBytes(), item)) {\n            return block;\n          }\n\n        } catch (IOException e) {\n          item.incErrorCount();\n        }\n      }\n\n      if (item.getErrorCount() \u003e\u003d getMaxError(item)) {\n        item.setErrMsg(\"Error count exceeded.\");\n        LOG.info(\"Maximum error count exceeded. Error count: {} Max error:{} \"\n            , item.getErrorCount(), item.getMaxDiskErrors());\n      }\n\n      return null;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DiskBalancer.java"
    }
  }
}