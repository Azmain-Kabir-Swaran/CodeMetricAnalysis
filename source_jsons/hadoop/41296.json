{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSAppAttempt.java",
  "functionName": "allocate",
  "functionId": "allocate___type-NodeType__node-FSSchedulerNode__schedulerKey-SchedulerRequestKey__pendingAsk-PendingAsk__reservedContainer-Container",
  "sourceFilePath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FSAppAttempt.java",
  "functionStartLine": 422,
  "functionEndLine": 489,
  "numCommitsSeen": 173,
  "timeTaken": 9252,
  "changeHistory": [
    "c30c23cb665761e997bcfc1dc00908f70b069fa2",
    "39b4a37e02e929a698fcf9e32f1f71bb6b977635",
    "2ab611d48b7669b31bd2c9b918f47251da77d0f6",
    "a957f1c60e1308d1d70a1803381994f59949c5f8",
    "1f4cdf10681b6903207a63fb5c306c9665ed9464",
    "2977bc6a141041ef7579efc416e93fc55e0c2a1a",
    "0a55bd841ec0f2eb89a0383f4c589526e8b138d4",
    "b8a30f2f170ffbd590e7366c3c944ab4919e40df",
    "5aace38b748ba71aaadd2c4d64eba8dc1f816828",
    "5279af7cd4afb090da742a96b5786d9dee6224bc",
    "bb62e0592566b2fcae7136b30972aad2d3ac55b0",
    "ed54f5f1ff7862f8216f77d5ea8f9ccea674ccd1",
    "586348e4cbf197188057d6b843a6701cfffdaff3",
    "486e718fc1f5befd231494e2ec06bb360484f191"
  ],
  "changeHistoryShort": {
    "c30c23cb665761e997bcfc1dc00908f70b069fa2": "Ybodychange",
    "39b4a37e02e929a698fcf9e32f1f71bb6b977635": "Ybodychange",
    "2ab611d48b7669b31bd2c9b918f47251da77d0f6": "Ybodychange",
    "a957f1c60e1308d1d70a1803381994f59949c5f8": "Ybodychange",
    "1f4cdf10681b6903207a63fb5c306c9665ed9464": "Ybodychange",
    "2977bc6a141041ef7579efc416e93fc55e0c2a1a": "Ymultichange(Yparameterchange,Ybodychange)",
    "0a55bd841ec0f2eb89a0383f4c589526e8b138d4": "Ybodychange",
    "b8a30f2f170ffbd590e7366c3c944ab4919e40df": "Ymultichange(Ymodifierchange,Ybodychange)",
    "5aace38b748ba71aaadd2c4d64eba8dc1f816828": "Ymultichange(Yparameterchange,Ybodychange)",
    "5279af7cd4afb090da742a96b5786d9dee6224bc": "Ymultichange(Yparameterchange,Ybodychange)",
    "bb62e0592566b2fcae7136b30972aad2d3ac55b0": "Ybodychange",
    "ed54f5f1ff7862f8216f77d5ea8f9ccea674ccd1": "Ybodychange",
    "586348e4cbf197188057d6b843a6701cfffdaff3": "Ybodychange",
    "486e718fc1f5befd231494e2ec06bb360484f191": "Yintroduced"
  },
  "changeHistoryDetails": {
    "c30c23cb665761e997bcfc1dc00908f70b069fa2": {
      "type": "Ybodychange",
      "commitMessage": "YARN-6492. Generate queue metrics for each partition. Contributed by Manikandan R\n",
      "commitDate": "26/05/20 4:29 PM",
      "commitName": "c30c23cb665761e997bcfc1dc00908f70b069fa2",
      "commitAuthor": "Jonathan Hung",
      "commitDateOld": "12/11/19 9:40 AM",
      "commitNameOld": "b83b9ab41874646e92eb28b7f9153eaba858f4d0",
      "commitAuthorOld": "Yufei Gu",
      "daysBetweenCommits": 196.24,
      "commitsBetweenForRepo": 676,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,68 +1,68 @@\n   public RMContainer allocate(NodeType type, FSSchedulerNode node,\n       SchedulerRequestKey schedulerKey, PendingAsk pendingAsk,\n       Container reservedContainer) {\n     RMContainer rmContainer;\n     Container container;\n \n     writeLock.lock();\n     try {\n       // Update allowed locality level\n       NodeType allowed \u003d allowedLocalityLevel.get(schedulerKey);\n       if (allowed !\u003d null) {\n         if (allowed.equals(NodeType.OFF_SWITCH) \u0026\u0026 (type.equals(\n             NodeType.NODE_LOCAL) || type.equals(NodeType.RACK_LOCAL))) {\n           this.resetAllowedLocalityLevel(schedulerKey, type);\n         } else if (allowed.equals(NodeType.RACK_LOCAL) \u0026\u0026 type.equals(\n             NodeType.NODE_LOCAL)) {\n           this.resetAllowedLocalityLevel(schedulerKey, type);\n         }\n       }\n \n       // Required sanity check - AM can call \u0027allocate\u0027 to update resource\n       // request without locking the scheduler, hence we need to check\n       if (getOutstandingAsksCount(schedulerKey) \u003c\u003d 0) {\n         return null;\n       }\n \n       container \u003d reservedContainer;\n       if (container \u003d\u003d null) {\n         container \u003d createContainer(node, pendingAsk.getPerAllocationResource(),\n             schedulerKey);\n       }\n \n       // Create RMContainer\n       rmContainer \u003d new RMContainerImpl(container, schedulerKey,\n           getApplicationAttemptId(), node.getNodeID(),\n           appSchedulingInfo.getUser(), rmContext);\n       ((RMContainerImpl) rmContainer).setQueueName(this.getQueueName());\n \n       // Add it to allContainers list.\n       addToNewlyAllocatedContainers(node, rmContainer);\n       liveContainers.put(container.getId(), rmContainer);\n       // Update consumption and track allocations\n       ContainerRequest containerRequest \u003d appSchedulingInfo.allocate(\n-          type, node, schedulerKey, container);\n+            type, node, schedulerKey, rmContainer);\n       this.attemptResourceUsage.incUsed(container.getResource());\n       getQueue().incUsedResource(container.getResource());\n \n       // Update resource requests related to \"request\" and store in RMContainer\n       ((RMContainerImpl) rmContainer).setContainerRequest(containerRequest);\n \n       // Inform the container\n       rmContainer.handle(\n           new RMContainerEvent(container.getId(), RMContainerEventType.START));\n \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"allocate: applicationAttemptId\u003d\" + container.getId()\n             .getApplicationAttemptId() + \" container\u003d\" + container.getId()\n             + \" host\u003d\" + container.getNodeId().getHost() + \" type\u003d\" + type);\n       }\n       RMAuditLogger.logSuccess(getUser(), AuditConstants.ALLOC_CONTAINER,\n           \"SchedulerApp\", getApplicationId(), container.getId(),\n           container.getResource(), getQueueName(), null);\n     } finally {\n       writeLock.unlock();\n     }\n \n     return rmContainer;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public RMContainer allocate(NodeType type, FSSchedulerNode node,\n      SchedulerRequestKey schedulerKey, PendingAsk pendingAsk,\n      Container reservedContainer) {\n    RMContainer rmContainer;\n    Container container;\n\n    writeLock.lock();\n    try {\n      // Update allowed locality level\n      NodeType allowed \u003d allowedLocalityLevel.get(schedulerKey);\n      if (allowed !\u003d null) {\n        if (allowed.equals(NodeType.OFF_SWITCH) \u0026\u0026 (type.equals(\n            NodeType.NODE_LOCAL) || type.equals(NodeType.RACK_LOCAL))) {\n          this.resetAllowedLocalityLevel(schedulerKey, type);\n        } else if (allowed.equals(NodeType.RACK_LOCAL) \u0026\u0026 type.equals(\n            NodeType.NODE_LOCAL)) {\n          this.resetAllowedLocalityLevel(schedulerKey, type);\n        }\n      }\n\n      // Required sanity check - AM can call \u0027allocate\u0027 to update resource\n      // request without locking the scheduler, hence we need to check\n      if (getOutstandingAsksCount(schedulerKey) \u003c\u003d 0) {\n        return null;\n      }\n\n      container \u003d reservedContainer;\n      if (container \u003d\u003d null) {\n        container \u003d createContainer(node, pendingAsk.getPerAllocationResource(),\n            schedulerKey);\n      }\n\n      // Create RMContainer\n      rmContainer \u003d new RMContainerImpl(container, schedulerKey,\n          getApplicationAttemptId(), node.getNodeID(),\n          appSchedulingInfo.getUser(), rmContext);\n      ((RMContainerImpl) rmContainer).setQueueName(this.getQueueName());\n\n      // Add it to allContainers list.\n      addToNewlyAllocatedContainers(node, rmContainer);\n      liveContainers.put(container.getId(), rmContainer);\n      // Update consumption and track allocations\n      ContainerRequest containerRequest \u003d appSchedulingInfo.allocate(\n            type, node, schedulerKey, rmContainer);\n      this.attemptResourceUsage.incUsed(container.getResource());\n      getQueue().incUsedResource(container.getResource());\n\n      // Update resource requests related to \"request\" and store in RMContainer\n      ((RMContainerImpl) rmContainer).setContainerRequest(containerRequest);\n\n      // Inform the container\n      rmContainer.handle(\n          new RMContainerEvent(container.getId(), RMContainerEventType.START));\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"allocate: applicationAttemptId\u003d\" + container.getId()\n            .getApplicationAttemptId() + \" container\u003d\" + container.getId()\n            + \" host\u003d\" + container.getNodeId().getHost() + \" type\u003d\" + type);\n      }\n      RMAuditLogger.logSuccess(getUser(), AuditConstants.ALLOC_CONTAINER,\n          \"SchedulerApp\", getApplicationId(), container.getId(),\n          container.getResource(), getQueueName(), null);\n    } finally {\n      writeLock.unlock();\n    }\n\n    return rmContainer;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FSAppAttempt.java",
      "extendedDetails": {}
    },
    "39b4a37e02e929a698fcf9e32f1f71bb6b977635": {
      "type": "Ybodychange",
      "commitMessage": "YARN-9341.  Fixed enentrant lock usage in YARN project.\n            Contributed by Prabhu Joseph\n",
      "commitDate": "07/03/19 1:47 PM",
      "commitName": "39b4a37e02e929a698fcf9e32f1f71bb6b977635",
      "commitAuthor": "Eric Yang",
      "commitDateOld": "04/03/19 9:10 PM",
      "commitNameOld": "e40e2d6ad5cbe782c3a067229270738b501ed27e",
      "commitAuthorOld": "Prabhu Joseph",
      "daysBetweenCommits": 2.69,
      "commitsBetweenForRepo": 39,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,68 +1,68 @@\n   public RMContainer allocate(NodeType type, FSSchedulerNode node,\n       SchedulerRequestKey schedulerKey, PendingAsk pendingAsk,\n       Container reservedContainer) {\n     RMContainer rmContainer;\n     Container container;\n \n+    writeLock.lock();\n     try {\n-      writeLock.lock();\n       // Update allowed locality level\n       NodeType allowed \u003d allowedLocalityLevel.get(schedulerKey);\n       if (allowed !\u003d null) {\n         if (allowed.equals(NodeType.OFF_SWITCH) \u0026\u0026 (type.equals(\n             NodeType.NODE_LOCAL) || type.equals(NodeType.RACK_LOCAL))) {\n           this.resetAllowedLocalityLevel(schedulerKey, type);\n         } else if (allowed.equals(NodeType.RACK_LOCAL) \u0026\u0026 type.equals(\n             NodeType.NODE_LOCAL)) {\n           this.resetAllowedLocalityLevel(schedulerKey, type);\n         }\n       }\n \n       // Required sanity check - AM can call \u0027allocate\u0027 to update resource\n       // request without locking the scheduler, hence we need to check\n       if (getOutstandingAsksCount(schedulerKey) \u003c\u003d 0) {\n         return null;\n       }\n \n       container \u003d reservedContainer;\n       if (container \u003d\u003d null) {\n         container \u003d createContainer(node, pendingAsk.getPerAllocationResource(),\n             schedulerKey);\n       }\n \n       // Create RMContainer\n       rmContainer \u003d new RMContainerImpl(container, schedulerKey,\n           getApplicationAttemptId(), node.getNodeID(),\n           appSchedulingInfo.getUser(), rmContext);\n       ((RMContainerImpl) rmContainer).setQueueName(this.getQueueName());\n \n       // Add it to allContainers list.\n       addToNewlyAllocatedContainers(node, rmContainer);\n       liveContainers.put(container.getId(), rmContainer);\n       // Update consumption and track allocations\n       ContainerRequest containerRequest \u003d appSchedulingInfo.allocate(\n           type, node, schedulerKey, container);\n       this.attemptResourceUsage.incUsed(container.getResource());\n       getQueue().incUsedResource(container.getResource());\n \n       // Update resource requests related to \"request\" and store in RMContainer\n       ((RMContainerImpl) rmContainer).setContainerRequest(containerRequest);\n \n       // Inform the container\n       rmContainer.handle(\n           new RMContainerEvent(container.getId(), RMContainerEventType.START));\n \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"allocate: applicationAttemptId\u003d\" + container.getId()\n             .getApplicationAttemptId() + \" container\u003d\" + container.getId()\n             + \" host\u003d\" + container.getNodeId().getHost() + \" type\u003d\" + type);\n       }\n       RMAuditLogger.logSuccess(getUser(), AuditConstants.ALLOC_CONTAINER,\n           \"SchedulerApp\", getApplicationId(), container.getId(),\n           container.getResource(), getQueueName(), null);\n     } finally {\n       writeLock.unlock();\n     }\n \n     return rmContainer;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public RMContainer allocate(NodeType type, FSSchedulerNode node,\n      SchedulerRequestKey schedulerKey, PendingAsk pendingAsk,\n      Container reservedContainer) {\n    RMContainer rmContainer;\n    Container container;\n\n    writeLock.lock();\n    try {\n      // Update allowed locality level\n      NodeType allowed \u003d allowedLocalityLevel.get(schedulerKey);\n      if (allowed !\u003d null) {\n        if (allowed.equals(NodeType.OFF_SWITCH) \u0026\u0026 (type.equals(\n            NodeType.NODE_LOCAL) || type.equals(NodeType.RACK_LOCAL))) {\n          this.resetAllowedLocalityLevel(schedulerKey, type);\n        } else if (allowed.equals(NodeType.RACK_LOCAL) \u0026\u0026 type.equals(\n            NodeType.NODE_LOCAL)) {\n          this.resetAllowedLocalityLevel(schedulerKey, type);\n        }\n      }\n\n      // Required sanity check - AM can call \u0027allocate\u0027 to update resource\n      // request without locking the scheduler, hence we need to check\n      if (getOutstandingAsksCount(schedulerKey) \u003c\u003d 0) {\n        return null;\n      }\n\n      container \u003d reservedContainer;\n      if (container \u003d\u003d null) {\n        container \u003d createContainer(node, pendingAsk.getPerAllocationResource(),\n            schedulerKey);\n      }\n\n      // Create RMContainer\n      rmContainer \u003d new RMContainerImpl(container, schedulerKey,\n          getApplicationAttemptId(), node.getNodeID(),\n          appSchedulingInfo.getUser(), rmContext);\n      ((RMContainerImpl) rmContainer).setQueueName(this.getQueueName());\n\n      // Add it to allContainers list.\n      addToNewlyAllocatedContainers(node, rmContainer);\n      liveContainers.put(container.getId(), rmContainer);\n      // Update consumption and track allocations\n      ContainerRequest containerRequest \u003d appSchedulingInfo.allocate(\n          type, node, schedulerKey, container);\n      this.attemptResourceUsage.incUsed(container.getResource());\n      getQueue().incUsedResource(container.getResource());\n\n      // Update resource requests related to \"request\" and store in RMContainer\n      ((RMContainerImpl) rmContainer).setContainerRequest(containerRequest);\n\n      // Inform the container\n      rmContainer.handle(\n          new RMContainerEvent(container.getId(), RMContainerEventType.START));\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"allocate: applicationAttemptId\u003d\" + container.getId()\n            .getApplicationAttemptId() + \" container\u003d\" + container.getId()\n            + \" host\u003d\" + container.getNodeId().getHost() + \" type\u003d\" + type);\n      }\n      RMAuditLogger.logSuccess(getUser(), AuditConstants.ALLOC_CONTAINER,\n          \"SchedulerApp\", getApplicationId(), container.getId(),\n          container.getResource(), getQueueName(), null);\n    } finally {\n      writeLock.unlock();\n    }\n\n    return rmContainer;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FSAppAttempt.java",
      "extendedDetails": {}
    },
    "2ab611d48b7669b31bd2c9b918f47251da77d0f6": {
      "type": "Ybodychange",
      "commitMessage": "YARN-7225. Add queue and partition info to RM audit log. Contributed by Eric Payne\n",
      "commitDate": "01/11/18 2:22 PM",
      "commitName": "2ab611d48b7669b31bd2c9b918f47251da77d0f6",
      "commitAuthor": "Jonathan Hung",
      "commitDateOld": "20/07/18 10:46 AM",
      "commitNameOld": "8a6bb8409c2dc695c0ffc70df0528d7f8bd5d795",
      "commitAuthorOld": "Haibo Chen",
      "daysBetweenCommits": 104.15,
      "commitsBetweenForRepo": 957,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,68 +1,68 @@\n   public RMContainer allocate(NodeType type, FSSchedulerNode node,\n       SchedulerRequestKey schedulerKey, PendingAsk pendingAsk,\n       Container reservedContainer) {\n     RMContainer rmContainer;\n     Container container;\n \n     try {\n       writeLock.lock();\n       // Update allowed locality level\n       NodeType allowed \u003d allowedLocalityLevel.get(schedulerKey);\n       if (allowed !\u003d null) {\n         if (allowed.equals(NodeType.OFF_SWITCH) \u0026\u0026 (type.equals(\n             NodeType.NODE_LOCAL) || type.equals(NodeType.RACK_LOCAL))) {\n           this.resetAllowedLocalityLevel(schedulerKey, type);\n         } else if (allowed.equals(NodeType.RACK_LOCAL) \u0026\u0026 type.equals(\n             NodeType.NODE_LOCAL)) {\n           this.resetAllowedLocalityLevel(schedulerKey, type);\n         }\n       }\n \n       // Required sanity check - AM can call \u0027allocate\u0027 to update resource\n       // request without locking the scheduler, hence we need to check\n       if (getOutstandingAsksCount(schedulerKey) \u003c\u003d 0) {\n         return null;\n       }\n \n       container \u003d reservedContainer;\n       if (container \u003d\u003d null) {\n         container \u003d createContainer(node, pendingAsk.getPerAllocationResource(),\n             schedulerKey);\n       }\n \n       // Create RMContainer\n       rmContainer \u003d new RMContainerImpl(container, schedulerKey,\n           getApplicationAttemptId(), node.getNodeID(),\n           appSchedulingInfo.getUser(), rmContext);\n       ((RMContainerImpl) rmContainer).setQueueName(this.getQueueName());\n \n       // Add it to allContainers list.\n       addToNewlyAllocatedContainers(node, rmContainer);\n       liveContainers.put(container.getId(), rmContainer);\n       // Update consumption and track allocations\n       ContainerRequest containerRequest \u003d appSchedulingInfo.allocate(\n           type, node, schedulerKey, container);\n       this.attemptResourceUsage.incUsed(container.getResource());\n       getQueue().incUsedResource(container.getResource());\n \n       // Update resource requests related to \"request\" and store in RMContainer\n       ((RMContainerImpl) rmContainer).setContainerRequest(containerRequest);\n \n       // Inform the container\n       rmContainer.handle(\n           new RMContainerEvent(container.getId(), RMContainerEventType.START));\n \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"allocate: applicationAttemptId\u003d\" + container.getId()\n             .getApplicationAttemptId() + \" container\u003d\" + container.getId()\n             + \" host\u003d\" + container.getNodeId().getHost() + \" type\u003d\" + type);\n       }\n       RMAuditLogger.logSuccess(getUser(), AuditConstants.ALLOC_CONTAINER,\n           \"SchedulerApp\", getApplicationId(), container.getId(),\n-          container.getResource());\n+          container.getResource(), getQueueName(), null);\n     } finally {\n       writeLock.unlock();\n     }\n \n     return rmContainer;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public RMContainer allocate(NodeType type, FSSchedulerNode node,\n      SchedulerRequestKey schedulerKey, PendingAsk pendingAsk,\n      Container reservedContainer) {\n    RMContainer rmContainer;\n    Container container;\n\n    try {\n      writeLock.lock();\n      // Update allowed locality level\n      NodeType allowed \u003d allowedLocalityLevel.get(schedulerKey);\n      if (allowed !\u003d null) {\n        if (allowed.equals(NodeType.OFF_SWITCH) \u0026\u0026 (type.equals(\n            NodeType.NODE_LOCAL) || type.equals(NodeType.RACK_LOCAL))) {\n          this.resetAllowedLocalityLevel(schedulerKey, type);\n        } else if (allowed.equals(NodeType.RACK_LOCAL) \u0026\u0026 type.equals(\n            NodeType.NODE_LOCAL)) {\n          this.resetAllowedLocalityLevel(schedulerKey, type);\n        }\n      }\n\n      // Required sanity check - AM can call \u0027allocate\u0027 to update resource\n      // request without locking the scheduler, hence we need to check\n      if (getOutstandingAsksCount(schedulerKey) \u003c\u003d 0) {\n        return null;\n      }\n\n      container \u003d reservedContainer;\n      if (container \u003d\u003d null) {\n        container \u003d createContainer(node, pendingAsk.getPerAllocationResource(),\n            schedulerKey);\n      }\n\n      // Create RMContainer\n      rmContainer \u003d new RMContainerImpl(container, schedulerKey,\n          getApplicationAttemptId(), node.getNodeID(),\n          appSchedulingInfo.getUser(), rmContext);\n      ((RMContainerImpl) rmContainer).setQueueName(this.getQueueName());\n\n      // Add it to allContainers list.\n      addToNewlyAllocatedContainers(node, rmContainer);\n      liveContainers.put(container.getId(), rmContainer);\n      // Update consumption and track allocations\n      ContainerRequest containerRequest \u003d appSchedulingInfo.allocate(\n          type, node, schedulerKey, container);\n      this.attemptResourceUsage.incUsed(container.getResource());\n      getQueue().incUsedResource(container.getResource());\n\n      // Update resource requests related to \"request\" and store in RMContainer\n      ((RMContainerImpl) rmContainer).setContainerRequest(containerRequest);\n\n      // Inform the container\n      rmContainer.handle(\n          new RMContainerEvent(container.getId(), RMContainerEventType.START));\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"allocate: applicationAttemptId\u003d\" + container.getId()\n            .getApplicationAttemptId() + \" container\u003d\" + container.getId()\n            + \" host\u003d\" + container.getNodeId().getHost() + \" type\u003d\" + type);\n      }\n      RMAuditLogger.logSuccess(getUser(), AuditConstants.ALLOC_CONTAINER,\n          \"SchedulerApp\", getApplicationId(), container.getId(),\n          container.getResource(), getQueueName(), null);\n    } finally {\n      writeLock.unlock();\n    }\n\n    return rmContainer;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FSAppAttempt.java",
      "extendedDetails": {}
    },
    "a957f1c60e1308d1d70a1803381994f59949c5f8": {
      "type": "Ybodychange",
      "commitMessage": "YARN-7438. Additional changes to make SchedulingPlacementSet agnostic to ResourceRequest / placement algorithm. Contributed by Wangda Tan\n",
      "commitDate": "05/12/17 9:20 AM",
      "commitName": "a957f1c60e1308d1d70a1803381994f59949c5f8",
      "commitAuthor": "Sunil G",
      "commitDateOld": "24/11/17 11:32 PM",
      "commitNameOld": "2bde3aedf139368fc71f053d8dd6580b498ff46d",
      "commitAuthorOld": "Yufei Gu",
      "daysBetweenCommits": 10.41,
      "commitsBetweenForRepo": 51,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,69 +1,69 @@\n   public RMContainer allocate(NodeType type, FSSchedulerNode node,\n       SchedulerRequestKey schedulerKey, PendingAsk pendingAsk,\n       Container reservedContainer) {\n     RMContainer rmContainer;\n     Container container;\n \n     try {\n       writeLock.lock();\n       // Update allowed locality level\n       NodeType allowed \u003d allowedLocalityLevel.get(schedulerKey);\n       if (allowed !\u003d null) {\n         if (allowed.equals(NodeType.OFF_SWITCH) \u0026\u0026 (type.equals(\n             NodeType.NODE_LOCAL) || type.equals(NodeType.RACK_LOCAL))) {\n           this.resetAllowedLocalityLevel(schedulerKey, type);\n         } else if (allowed.equals(NodeType.RACK_LOCAL) \u0026\u0026 type.equals(\n             NodeType.NODE_LOCAL)) {\n           this.resetAllowedLocalityLevel(schedulerKey, type);\n         }\n       }\n \n       // Required sanity check - AM can call \u0027allocate\u0027 to update resource\n       // request without locking the scheduler, hence we need to check\n       if (getOutstandingAsksCount(schedulerKey) \u003c\u003d 0) {\n         return null;\n       }\n \n       container \u003d reservedContainer;\n       if (container \u003d\u003d null) {\n         container \u003d createContainer(node, pendingAsk.getPerAllocationResource(),\n             schedulerKey);\n       }\n \n       // Create RMContainer\n       rmContainer \u003d new RMContainerImpl(container, schedulerKey,\n           getApplicationAttemptId(), node.getNodeID(),\n           appSchedulingInfo.getUser(), rmContext);\n       ((RMContainerImpl) rmContainer).setQueueName(this.getQueueName());\n \n       // Add it to allContainers list.\n       addToNewlyAllocatedContainers(node, rmContainer);\n       liveContainers.put(container.getId(), rmContainer);\n \n       // Update consumption and track allocations\n-      List\u003cResourceRequest\u003e resourceRequestList \u003d appSchedulingInfo.allocate(\n+      ContainerRequest containerRequest \u003d appSchedulingInfo.allocate(\n           type, node, schedulerKey, container);\n       this.attemptResourceUsage.incUsed(container.getResource());\n       getQueue().incUsedResource(container.getResource());\n \n       // Update resource requests related to \"request\" and store in RMContainer\n-      ((RMContainerImpl) rmContainer).setResourceRequests(resourceRequestList);\n+      ((RMContainerImpl) rmContainer).setContainerRequest(containerRequest);\n \n       // Inform the container\n       rmContainer.handle(\n           new RMContainerEvent(container.getId(), RMContainerEventType.START));\n \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"allocate: applicationAttemptId\u003d\" + container.getId()\n             .getApplicationAttemptId() + \" container\u003d\" + container.getId()\n             + \" host\u003d\" + container.getNodeId().getHost() + \" type\u003d\" + type);\n       }\n       RMAuditLogger.logSuccess(getUser(), AuditConstants.ALLOC_CONTAINER,\n           \"SchedulerApp\", getApplicationId(), container.getId(),\n           container.getResource());\n     } finally {\n       writeLock.unlock();\n     }\n \n     return rmContainer;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public RMContainer allocate(NodeType type, FSSchedulerNode node,\n      SchedulerRequestKey schedulerKey, PendingAsk pendingAsk,\n      Container reservedContainer) {\n    RMContainer rmContainer;\n    Container container;\n\n    try {\n      writeLock.lock();\n      // Update allowed locality level\n      NodeType allowed \u003d allowedLocalityLevel.get(schedulerKey);\n      if (allowed !\u003d null) {\n        if (allowed.equals(NodeType.OFF_SWITCH) \u0026\u0026 (type.equals(\n            NodeType.NODE_LOCAL) || type.equals(NodeType.RACK_LOCAL))) {\n          this.resetAllowedLocalityLevel(schedulerKey, type);\n        } else if (allowed.equals(NodeType.RACK_LOCAL) \u0026\u0026 type.equals(\n            NodeType.NODE_LOCAL)) {\n          this.resetAllowedLocalityLevel(schedulerKey, type);\n        }\n      }\n\n      // Required sanity check - AM can call \u0027allocate\u0027 to update resource\n      // request without locking the scheduler, hence we need to check\n      if (getOutstandingAsksCount(schedulerKey) \u003c\u003d 0) {\n        return null;\n      }\n\n      container \u003d reservedContainer;\n      if (container \u003d\u003d null) {\n        container \u003d createContainer(node, pendingAsk.getPerAllocationResource(),\n            schedulerKey);\n      }\n\n      // Create RMContainer\n      rmContainer \u003d new RMContainerImpl(container, schedulerKey,\n          getApplicationAttemptId(), node.getNodeID(),\n          appSchedulingInfo.getUser(), rmContext);\n      ((RMContainerImpl) rmContainer).setQueueName(this.getQueueName());\n\n      // Add it to allContainers list.\n      addToNewlyAllocatedContainers(node, rmContainer);\n      liveContainers.put(container.getId(), rmContainer);\n\n      // Update consumption and track allocations\n      ContainerRequest containerRequest \u003d appSchedulingInfo.allocate(\n          type, node, schedulerKey, container);\n      this.attemptResourceUsage.incUsed(container.getResource());\n      getQueue().incUsedResource(container.getResource());\n\n      // Update resource requests related to \"request\" and store in RMContainer\n      ((RMContainerImpl) rmContainer).setContainerRequest(containerRequest);\n\n      // Inform the container\n      rmContainer.handle(\n          new RMContainerEvent(container.getId(), RMContainerEventType.START));\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"allocate: applicationAttemptId\u003d\" + container.getId()\n            .getApplicationAttemptId() + \" container\u003d\" + container.getId()\n            + \" host\u003d\" + container.getNodeId().getHost() + \" type\u003d\" + type);\n      }\n      RMAuditLogger.logSuccess(getUser(), AuditConstants.ALLOC_CONTAINER,\n          \"SchedulerApp\", getApplicationId(), container.getId(),\n          container.getResource());\n    } finally {\n      writeLock.unlock();\n    }\n\n    return rmContainer;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FSAppAttempt.java",
      "extendedDetails": {}
    },
    "1f4cdf10681b6903207a63fb5c306c9665ed9464": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4090. Make Collections.sort() more efficient by caching resource usage. (Contributed by Yufei Gu, Shilong Zhang and Xianyin Xin)\n",
      "commitDate": "20/10/17 1:32 AM",
      "commitName": "1f4cdf10681b6903207a63fb5c306c9665ed9464",
      "commitAuthor": "Yufei Gu",
      "commitDateOld": "14/09/17 11:23 AM",
      "commitNameOld": "09b476e6dabe8039a41dde7930c8a9c0d14bb750",
      "commitAuthorOld": "Yufei Gu",
      "daysBetweenCommits": 35.59,
      "commitsBetweenForRepo": 277,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,68 +1,69 @@\n   public RMContainer allocate(NodeType type, FSSchedulerNode node,\n       SchedulerRequestKey schedulerKey, PendingAsk pendingAsk,\n       Container reservedContainer) {\n     RMContainer rmContainer;\n     Container container;\n \n     try {\n       writeLock.lock();\n       // Update allowed locality level\n       NodeType allowed \u003d allowedLocalityLevel.get(schedulerKey);\n       if (allowed !\u003d null) {\n         if (allowed.equals(NodeType.OFF_SWITCH) \u0026\u0026 (type.equals(\n             NodeType.NODE_LOCAL) || type.equals(NodeType.RACK_LOCAL))) {\n           this.resetAllowedLocalityLevel(schedulerKey, type);\n         } else if (allowed.equals(NodeType.RACK_LOCAL) \u0026\u0026 type.equals(\n             NodeType.NODE_LOCAL)) {\n           this.resetAllowedLocalityLevel(schedulerKey, type);\n         }\n       }\n \n       // Required sanity check - AM can call \u0027allocate\u0027 to update resource\n       // request without locking the scheduler, hence we need to check\n       if (getOutstandingAsksCount(schedulerKey) \u003c\u003d 0) {\n         return null;\n       }\n \n       container \u003d reservedContainer;\n       if (container \u003d\u003d null) {\n         container \u003d createContainer(node, pendingAsk.getPerAllocationResource(),\n             schedulerKey);\n       }\n \n       // Create RMContainer\n       rmContainer \u003d new RMContainerImpl(container, schedulerKey,\n           getApplicationAttemptId(), node.getNodeID(),\n           appSchedulingInfo.getUser(), rmContext);\n       ((RMContainerImpl) rmContainer).setQueueName(this.getQueueName());\n \n       // Add it to allContainers list.\n       addToNewlyAllocatedContainers(node, rmContainer);\n       liveContainers.put(container.getId(), rmContainer);\n \n       // Update consumption and track allocations\n       List\u003cResourceRequest\u003e resourceRequestList \u003d appSchedulingInfo.allocate(\n           type, node, schedulerKey, container);\n       this.attemptResourceUsage.incUsed(container.getResource());\n+      getQueue().incUsedResource(container.getResource());\n \n       // Update resource requests related to \"request\" and store in RMContainer\n       ((RMContainerImpl) rmContainer).setResourceRequests(resourceRequestList);\n \n       // Inform the container\n       rmContainer.handle(\n           new RMContainerEvent(container.getId(), RMContainerEventType.START));\n \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"allocate: applicationAttemptId\u003d\" + container.getId()\n             .getApplicationAttemptId() + \" container\u003d\" + container.getId()\n             + \" host\u003d\" + container.getNodeId().getHost() + \" type\u003d\" + type);\n       }\n       RMAuditLogger.logSuccess(getUser(), AuditConstants.ALLOC_CONTAINER,\n           \"SchedulerApp\", getApplicationId(), container.getId(),\n           container.getResource());\n     } finally {\n       writeLock.unlock();\n     }\n \n     return rmContainer;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public RMContainer allocate(NodeType type, FSSchedulerNode node,\n      SchedulerRequestKey schedulerKey, PendingAsk pendingAsk,\n      Container reservedContainer) {\n    RMContainer rmContainer;\n    Container container;\n\n    try {\n      writeLock.lock();\n      // Update allowed locality level\n      NodeType allowed \u003d allowedLocalityLevel.get(schedulerKey);\n      if (allowed !\u003d null) {\n        if (allowed.equals(NodeType.OFF_SWITCH) \u0026\u0026 (type.equals(\n            NodeType.NODE_LOCAL) || type.equals(NodeType.RACK_LOCAL))) {\n          this.resetAllowedLocalityLevel(schedulerKey, type);\n        } else if (allowed.equals(NodeType.RACK_LOCAL) \u0026\u0026 type.equals(\n            NodeType.NODE_LOCAL)) {\n          this.resetAllowedLocalityLevel(schedulerKey, type);\n        }\n      }\n\n      // Required sanity check - AM can call \u0027allocate\u0027 to update resource\n      // request without locking the scheduler, hence we need to check\n      if (getOutstandingAsksCount(schedulerKey) \u003c\u003d 0) {\n        return null;\n      }\n\n      container \u003d reservedContainer;\n      if (container \u003d\u003d null) {\n        container \u003d createContainer(node, pendingAsk.getPerAllocationResource(),\n            schedulerKey);\n      }\n\n      // Create RMContainer\n      rmContainer \u003d new RMContainerImpl(container, schedulerKey,\n          getApplicationAttemptId(), node.getNodeID(),\n          appSchedulingInfo.getUser(), rmContext);\n      ((RMContainerImpl) rmContainer).setQueueName(this.getQueueName());\n\n      // Add it to allContainers list.\n      addToNewlyAllocatedContainers(node, rmContainer);\n      liveContainers.put(container.getId(), rmContainer);\n\n      // Update consumption and track allocations\n      List\u003cResourceRequest\u003e resourceRequestList \u003d appSchedulingInfo.allocate(\n          type, node, schedulerKey, container);\n      this.attemptResourceUsage.incUsed(container.getResource());\n      getQueue().incUsedResource(container.getResource());\n\n      // Update resource requests related to \"request\" and store in RMContainer\n      ((RMContainerImpl) rmContainer).setResourceRequests(resourceRequestList);\n\n      // Inform the container\n      rmContainer.handle(\n          new RMContainerEvent(container.getId(), RMContainerEventType.START));\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"allocate: applicationAttemptId\u003d\" + container.getId()\n            .getApplicationAttemptId() + \" container\u003d\" + container.getId()\n            + \" host\u003d\" + container.getNodeId().getHost() + \" type\u003d\" + type);\n      }\n      RMAuditLogger.logSuccess(getUser(), AuditConstants.ALLOC_CONTAINER,\n          \"SchedulerApp\", getApplicationId(), container.getId(),\n          container.getResource());\n    } finally {\n      writeLock.unlock();\n    }\n\n    return rmContainer;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FSAppAttempt.java",
      "extendedDetails": {}
    },
    "2977bc6a141041ef7579efc416e93fc55e0c2a1a": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "YARN-6040. Introduce api independent PendingAsk to replace usage of ResourceRequest within Scheduler classes. (Wangda Tan via asuresh)\n",
      "commitDate": "06/01/17 9:59 AM",
      "commitName": "2977bc6a141041ef7579efc416e93fc55e0c2a1a",
      "commitAuthor": "Arun Suresh",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "YARN-6040. Introduce api independent PendingAsk to replace usage of ResourceRequest within Scheduler classes. (Wangda Tan via asuresh)\n",
          "commitDate": "06/01/17 9:59 AM",
          "commitName": "2977bc6a141041ef7579efc416e93fc55e0c2a1a",
          "commitAuthor": "Arun Suresh",
          "commitDateOld": "05/01/17 10:31 AM",
          "commitNameOld": "0a55bd841ec0f2eb89a0383f4c589526e8b138d4",
          "commitAuthorOld": "Wangda Tan",
          "daysBetweenCommits": 0.98,
          "commitsBetweenForRepo": 7,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,68 +1,68 @@\n   public RMContainer allocate(NodeType type, FSSchedulerNode node,\n-      SchedulerRequestKey schedulerKey, ResourceRequest request,\n+      SchedulerRequestKey schedulerKey, PendingAsk pendingAsk,\n       Container reservedContainer) {\n     RMContainer rmContainer;\n     Container container;\n \n     try {\n       writeLock.lock();\n       // Update allowed locality level\n       NodeType allowed \u003d allowedLocalityLevel.get(schedulerKey);\n       if (allowed !\u003d null) {\n         if (allowed.equals(NodeType.OFF_SWITCH) \u0026\u0026 (type.equals(\n             NodeType.NODE_LOCAL) || type.equals(NodeType.RACK_LOCAL))) {\n           this.resetAllowedLocalityLevel(schedulerKey, type);\n         } else if (allowed.equals(NodeType.RACK_LOCAL) \u0026\u0026 type.equals(\n             NodeType.NODE_LOCAL)) {\n           this.resetAllowedLocalityLevel(schedulerKey, type);\n         }\n       }\n \n       // Required sanity check - AM can call \u0027allocate\u0027 to update resource\n       // request without locking the scheduler, hence we need to check\n-      if (getTotalRequiredResources(schedulerKey) \u003c\u003d 0) {\n+      if (getOutstandingAsksCount(schedulerKey) \u003c\u003d 0) {\n         return null;\n       }\n \n       container \u003d reservedContainer;\n       if (container \u003d\u003d null) {\n-        container \u003d createContainer(node, request.getCapability(),\n+        container \u003d createContainer(node, pendingAsk.getPerAllocationResource(),\n             schedulerKey);\n       }\n \n       // Create RMContainer\n       rmContainer \u003d new RMContainerImpl(container, schedulerKey,\n           getApplicationAttemptId(), node.getNodeID(),\n           appSchedulingInfo.getUser(), rmContext);\n       ((RMContainerImpl) rmContainer).setQueueName(this.getQueueName());\n \n       // Add it to allContainers list.\n       addToNewlyAllocatedContainers(node, rmContainer);\n       liveContainers.put(container.getId(), rmContainer);\n \n       // Update consumption and track allocations\n       List\u003cResourceRequest\u003e resourceRequestList \u003d appSchedulingInfo.allocate(\n-          type, node, schedulerKey, request, container);\n+          type, node, schedulerKey, container);\n       this.attemptResourceUsage.incUsed(container.getResource());\n \n       // Update resource requests related to \"request\" and store in RMContainer\n       ((RMContainerImpl) rmContainer).setResourceRequests(resourceRequestList);\n \n       // Inform the container\n       rmContainer.handle(\n           new RMContainerEvent(container.getId(), RMContainerEventType.START));\n \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"allocate: applicationAttemptId\u003d\" + container.getId()\n             .getApplicationAttemptId() + \" container\u003d\" + container.getId()\n             + \" host\u003d\" + container.getNodeId().getHost() + \" type\u003d\" + type);\n       }\n       RMAuditLogger.logSuccess(getUser(), AuditConstants.ALLOC_CONTAINER,\n           \"SchedulerApp\", getApplicationId(), container.getId(),\n           container.getResource());\n     } finally {\n       writeLock.unlock();\n     }\n \n     return rmContainer;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public RMContainer allocate(NodeType type, FSSchedulerNode node,\n      SchedulerRequestKey schedulerKey, PendingAsk pendingAsk,\n      Container reservedContainer) {\n    RMContainer rmContainer;\n    Container container;\n\n    try {\n      writeLock.lock();\n      // Update allowed locality level\n      NodeType allowed \u003d allowedLocalityLevel.get(schedulerKey);\n      if (allowed !\u003d null) {\n        if (allowed.equals(NodeType.OFF_SWITCH) \u0026\u0026 (type.equals(\n            NodeType.NODE_LOCAL) || type.equals(NodeType.RACK_LOCAL))) {\n          this.resetAllowedLocalityLevel(schedulerKey, type);\n        } else if (allowed.equals(NodeType.RACK_LOCAL) \u0026\u0026 type.equals(\n            NodeType.NODE_LOCAL)) {\n          this.resetAllowedLocalityLevel(schedulerKey, type);\n        }\n      }\n\n      // Required sanity check - AM can call \u0027allocate\u0027 to update resource\n      // request without locking the scheduler, hence we need to check\n      if (getOutstandingAsksCount(schedulerKey) \u003c\u003d 0) {\n        return null;\n      }\n\n      container \u003d reservedContainer;\n      if (container \u003d\u003d null) {\n        container \u003d createContainer(node, pendingAsk.getPerAllocationResource(),\n            schedulerKey);\n      }\n\n      // Create RMContainer\n      rmContainer \u003d new RMContainerImpl(container, schedulerKey,\n          getApplicationAttemptId(), node.getNodeID(),\n          appSchedulingInfo.getUser(), rmContext);\n      ((RMContainerImpl) rmContainer).setQueueName(this.getQueueName());\n\n      // Add it to allContainers list.\n      addToNewlyAllocatedContainers(node, rmContainer);\n      liveContainers.put(container.getId(), rmContainer);\n\n      // Update consumption and track allocations\n      List\u003cResourceRequest\u003e resourceRequestList \u003d appSchedulingInfo.allocate(\n          type, node, schedulerKey, container);\n      this.attemptResourceUsage.incUsed(container.getResource());\n\n      // Update resource requests related to \"request\" and store in RMContainer\n      ((RMContainerImpl) rmContainer).setResourceRequests(resourceRequestList);\n\n      // Inform the container\n      rmContainer.handle(\n          new RMContainerEvent(container.getId(), RMContainerEventType.START));\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"allocate: applicationAttemptId\u003d\" + container.getId()\n            .getApplicationAttemptId() + \" container\u003d\" + container.getId()\n            + \" host\u003d\" + container.getNodeId().getHost() + \" type\u003d\" + type);\n      }\n      RMAuditLogger.logSuccess(getUser(), AuditConstants.ALLOC_CONTAINER,\n          \"SchedulerApp\", getApplicationId(), container.getId(),\n          container.getResource());\n    } finally {\n      writeLock.unlock();\n    }\n\n    return rmContainer;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FSAppAttempt.java",
          "extendedDetails": {
            "oldValue": "[type-NodeType, node-FSSchedulerNode, schedulerKey-SchedulerRequestKey, request-ResourceRequest, reservedContainer-Container]",
            "newValue": "[type-NodeType, node-FSSchedulerNode, schedulerKey-SchedulerRequestKey, pendingAsk-PendingAsk, reservedContainer-Container]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-6040. Introduce api independent PendingAsk to replace usage of ResourceRequest within Scheduler classes. (Wangda Tan via asuresh)\n",
          "commitDate": "06/01/17 9:59 AM",
          "commitName": "2977bc6a141041ef7579efc416e93fc55e0c2a1a",
          "commitAuthor": "Arun Suresh",
          "commitDateOld": "05/01/17 10:31 AM",
          "commitNameOld": "0a55bd841ec0f2eb89a0383f4c589526e8b138d4",
          "commitAuthorOld": "Wangda Tan",
          "daysBetweenCommits": 0.98,
          "commitsBetweenForRepo": 7,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,68 +1,68 @@\n   public RMContainer allocate(NodeType type, FSSchedulerNode node,\n-      SchedulerRequestKey schedulerKey, ResourceRequest request,\n+      SchedulerRequestKey schedulerKey, PendingAsk pendingAsk,\n       Container reservedContainer) {\n     RMContainer rmContainer;\n     Container container;\n \n     try {\n       writeLock.lock();\n       // Update allowed locality level\n       NodeType allowed \u003d allowedLocalityLevel.get(schedulerKey);\n       if (allowed !\u003d null) {\n         if (allowed.equals(NodeType.OFF_SWITCH) \u0026\u0026 (type.equals(\n             NodeType.NODE_LOCAL) || type.equals(NodeType.RACK_LOCAL))) {\n           this.resetAllowedLocalityLevel(schedulerKey, type);\n         } else if (allowed.equals(NodeType.RACK_LOCAL) \u0026\u0026 type.equals(\n             NodeType.NODE_LOCAL)) {\n           this.resetAllowedLocalityLevel(schedulerKey, type);\n         }\n       }\n \n       // Required sanity check - AM can call \u0027allocate\u0027 to update resource\n       // request without locking the scheduler, hence we need to check\n-      if (getTotalRequiredResources(schedulerKey) \u003c\u003d 0) {\n+      if (getOutstandingAsksCount(schedulerKey) \u003c\u003d 0) {\n         return null;\n       }\n \n       container \u003d reservedContainer;\n       if (container \u003d\u003d null) {\n-        container \u003d createContainer(node, request.getCapability(),\n+        container \u003d createContainer(node, pendingAsk.getPerAllocationResource(),\n             schedulerKey);\n       }\n \n       // Create RMContainer\n       rmContainer \u003d new RMContainerImpl(container, schedulerKey,\n           getApplicationAttemptId(), node.getNodeID(),\n           appSchedulingInfo.getUser(), rmContext);\n       ((RMContainerImpl) rmContainer).setQueueName(this.getQueueName());\n \n       // Add it to allContainers list.\n       addToNewlyAllocatedContainers(node, rmContainer);\n       liveContainers.put(container.getId(), rmContainer);\n \n       // Update consumption and track allocations\n       List\u003cResourceRequest\u003e resourceRequestList \u003d appSchedulingInfo.allocate(\n-          type, node, schedulerKey, request, container);\n+          type, node, schedulerKey, container);\n       this.attemptResourceUsage.incUsed(container.getResource());\n \n       // Update resource requests related to \"request\" and store in RMContainer\n       ((RMContainerImpl) rmContainer).setResourceRequests(resourceRequestList);\n \n       // Inform the container\n       rmContainer.handle(\n           new RMContainerEvent(container.getId(), RMContainerEventType.START));\n \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"allocate: applicationAttemptId\u003d\" + container.getId()\n             .getApplicationAttemptId() + \" container\u003d\" + container.getId()\n             + \" host\u003d\" + container.getNodeId().getHost() + \" type\u003d\" + type);\n       }\n       RMAuditLogger.logSuccess(getUser(), AuditConstants.ALLOC_CONTAINER,\n           \"SchedulerApp\", getApplicationId(), container.getId(),\n           container.getResource());\n     } finally {\n       writeLock.unlock();\n     }\n \n     return rmContainer;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public RMContainer allocate(NodeType type, FSSchedulerNode node,\n      SchedulerRequestKey schedulerKey, PendingAsk pendingAsk,\n      Container reservedContainer) {\n    RMContainer rmContainer;\n    Container container;\n\n    try {\n      writeLock.lock();\n      // Update allowed locality level\n      NodeType allowed \u003d allowedLocalityLevel.get(schedulerKey);\n      if (allowed !\u003d null) {\n        if (allowed.equals(NodeType.OFF_SWITCH) \u0026\u0026 (type.equals(\n            NodeType.NODE_LOCAL) || type.equals(NodeType.RACK_LOCAL))) {\n          this.resetAllowedLocalityLevel(schedulerKey, type);\n        } else if (allowed.equals(NodeType.RACK_LOCAL) \u0026\u0026 type.equals(\n            NodeType.NODE_LOCAL)) {\n          this.resetAllowedLocalityLevel(schedulerKey, type);\n        }\n      }\n\n      // Required sanity check - AM can call \u0027allocate\u0027 to update resource\n      // request without locking the scheduler, hence we need to check\n      if (getOutstandingAsksCount(schedulerKey) \u003c\u003d 0) {\n        return null;\n      }\n\n      container \u003d reservedContainer;\n      if (container \u003d\u003d null) {\n        container \u003d createContainer(node, pendingAsk.getPerAllocationResource(),\n            schedulerKey);\n      }\n\n      // Create RMContainer\n      rmContainer \u003d new RMContainerImpl(container, schedulerKey,\n          getApplicationAttemptId(), node.getNodeID(),\n          appSchedulingInfo.getUser(), rmContext);\n      ((RMContainerImpl) rmContainer).setQueueName(this.getQueueName());\n\n      // Add it to allContainers list.\n      addToNewlyAllocatedContainers(node, rmContainer);\n      liveContainers.put(container.getId(), rmContainer);\n\n      // Update consumption and track allocations\n      List\u003cResourceRequest\u003e resourceRequestList \u003d appSchedulingInfo.allocate(\n          type, node, schedulerKey, container);\n      this.attemptResourceUsage.incUsed(container.getResource());\n\n      // Update resource requests related to \"request\" and store in RMContainer\n      ((RMContainerImpl) rmContainer).setResourceRequests(resourceRequestList);\n\n      // Inform the container\n      rmContainer.handle(\n          new RMContainerEvent(container.getId(), RMContainerEventType.START));\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"allocate: applicationAttemptId\u003d\" + container.getId()\n            .getApplicationAttemptId() + \" container\u003d\" + container.getId()\n            + \" host\u003d\" + container.getNodeId().getHost() + \" type\u003d\" + type);\n      }\n      RMAuditLogger.logSuccess(getUser(), AuditConstants.ALLOC_CONTAINER,\n          \"SchedulerApp\", getApplicationId(), container.getId(),\n          container.getResource());\n    } finally {\n      writeLock.unlock();\n    }\n\n    return rmContainer;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FSAppAttempt.java",
          "extendedDetails": {}
        }
      ]
    },
    "0a55bd841ec0f2eb89a0383f4c589526e8b138d4": {
      "type": "Ybodychange",
      "commitMessage": "YARN-5959. RM changes to support change of container ExecutionType. (Arun Suresh via wangda)\n",
      "commitDate": "05/01/17 10:31 AM",
      "commitName": "0a55bd841ec0f2eb89a0383f4c589526e8b138d4",
      "commitAuthor": "Wangda Tan",
      "commitDateOld": "27/12/16 12:40 PM",
      "commitNameOld": "ac1e5d4f77e3b9df8dcacb0b1f72eecc27931eb8",
      "commitAuthorOld": "Arun Suresh",
      "daysBetweenCommits": 8.91,
      "commitsBetweenForRepo": 37,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,68 +1,68 @@\n   public RMContainer allocate(NodeType type, FSSchedulerNode node,\n       SchedulerRequestKey schedulerKey, ResourceRequest request,\n       Container reservedContainer) {\n     RMContainer rmContainer;\n     Container container;\n \n     try {\n       writeLock.lock();\n       // Update allowed locality level\n       NodeType allowed \u003d allowedLocalityLevel.get(schedulerKey);\n       if (allowed !\u003d null) {\n         if (allowed.equals(NodeType.OFF_SWITCH) \u0026\u0026 (type.equals(\n             NodeType.NODE_LOCAL) || type.equals(NodeType.RACK_LOCAL))) {\n           this.resetAllowedLocalityLevel(schedulerKey, type);\n         } else if (allowed.equals(NodeType.RACK_LOCAL) \u0026\u0026 type.equals(\n             NodeType.NODE_LOCAL)) {\n           this.resetAllowedLocalityLevel(schedulerKey, type);\n         }\n       }\n \n       // Required sanity check - AM can call \u0027allocate\u0027 to update resource\n       // request without locking the scheduler, hence we need to check\n       if (getTotalRequiredResources(schedulerKey) \u003c\u003d 0) {\n         return null;\n       }\n \n       container \u003d reservedContainer;\n       if (container \u003d\u003d null) {\n         container \u003d createContainer(node, request.getCapability(),\n             schedulerKey);\n       }\n \n       // Create RMContainer\n-      rmContainer \u003d new RMContainerImpl(container,\n+      rmContainer \u003d new RMContainerImpl(container, schedulerKey,\n           getApplicationAttemptId(), node.getNodeID(),\n           appSchedulingInfo.getUser(), rmContext);\n       ((RMContainerImpl) rmContainer).setQueueName(this.getQueueName());\n \n       // Add it to allContainers list.\n-      newlyAllocatedContainers.add(rmContainer);\n+      addToNewlyAllocatedContainers(node, rmContainer);\n       liveContainers.put(container.getId(), rmContainer);\n \n       // Update consumption and track allocations\n       List\u003cResourceRequest\u003e resourceRequestList \u003d appSchedulingInfo.allocate(\n           type, node, schedulerKey, request, container);\n       this.attemptResourceUsage.incUsed(container.getResource());\n \n       // Update resource requests related to \"request\" and store in RMContainer\n       ((RMContainerImpl) rmContainer).setResourceRequests(resourceRequestList);\n \n       // Inform the container\n       rmContainer.handle(\n           new RMContainerEvent(container.getId(), RMContainerEventType.START));\n \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"allocate: applicationAttemptId\u003d\" + container.getId()\n             .getApplicationAttemptId() + \" container\u003d\" + container.getId()\n             + \" host\u003d\" + container.getNodeId().getHost() + \" type\u003d\" + type);\n       }\n       RMAuditLogger.logSuccess(getUser(), AuditConstants.ALLOC_CONTAINER,\n           \"SchedulerApp\", getApplicationId(), container.getId(),\n           container.getResource());\n     } finally {\n       writeLock.unlock();\n     }\n \n     return rmContainer;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public RMContainer allocate(NodeType type, FSSchedulerNode node,\n      SchedulerRequestKey schedulerKey, ResourceRequest request,\n      Container reservedContainer) {\n    RMContainer rmContainer;\n    Container container;\n\n    try {\n      writeLock.lock();\n      // Update allowed locality level\n      NodeType allowed \u003d allowedLocalityLevel.get(schedulerKey);\n      if (allowed !\u003d null) {\n        if (allowed.equals(NodeType.OFF_SWITCH) \u0026\u0026 (type.equals(\n            NodeType.NODE_LOCAL) || type.equals(NodeType.RACK_LOCAL))) {\n          this.resetAllowedLocalityLevel(schedulerKey, type);\n        } else if (allowed.equals(NodeType.RACK_LOCAL) \u0026\u0026 type.equals(\n            NodeType.NODE_LOCAL)) {\n          this.resetAllowedLocalityLevel(schedulerKey, type);\n        }\n      }\n\n      // Required sanity check - AM can call \u0027allocate\u0027 to update resource\n      // request without locking the scheduler, hence we need to check\n      if (getTotalRequiredResources(schedulerKey) \u003c\u003d 0) {\n        return null;\n      }\n\n      container \u003d reservedContainer;\n      if (container \u003d\u003d null) {\n        container \u003d createContainer(node, request.getCapability(),\n            schedulerKey);\n      }\n\n      // Create RMContainer\n      rmContainer \u003d new RMContainerImpl(container, schedulerKey,\n          getApplicationAttemptId(), node.getNodeID(),\n          appSchedulingInfo.getUser(), rmContext);\n      ((RMContainerImpl) rmContainer).setQueueName(this.getQueueName());\n\n      // Add it to allContainers list.\n      addToNewlyAllocatedContainers(node, rmContainer);\n      liveContainers.put(container.getId(), rmContainer);\n\n      // Update consumption and track allocations\n      List\u003cResourceRequest\u003e resourceRequestList \u003d appSchedulingInfo.allocate(\n          type, node, schedulerKey, request, container);\n      this.attemptResourceUsage.incUsed(container.getResource());\n\n      // Update resource requests related to \"request\" and store in RMContainer\n      ((RMContainerImpl) rmContainer).setResourceRequests(resourceRequestList);\n\n      // Inform the container\n      rmContainer.handle(\n          new RMContainerEvent(container.getId(), RMContainerEventType.START));\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"allocate: applicationAttemptId\u003d\" + container.getId()\n            .getApplicationAttemptId() + \" container\u003d\" + container.getId()\n            + \" host\u003d\" + container.getNodeId().getHost() + \" type\u003d\" + type);\n      }\n      RMAuditLogger.logSuccess(getUser(), AuditConstants.ALLOC_CONTAINER,\n          \"SchedulerApp\", getApplicationId(), container.getId(),\n          container.getResource());\n    } finally {\n      writeLock.unlock();\n    }\n\n    return rmContainer;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FSAppAttempt.java",
      "extendedDetails": {}
    },
    "b8a30f2f170ffbd590e7366c3c944ab4919e40df": {
      "type": "Ymultichange(Ymodifierchange,Ybodychange)",
      "commitMessage": "YARN-3141. Improve locks in SchedulerApplicationAttempt/FSAppAttempt/FiCaSchedulerApp. Contributed by Wangda Tan\n",
      "commitDate": "19/09/16 2:08 AM",
      "commitName": "b8a30f2f170ffbd590e7366c3c944ab4919e40df",
      "commitAuthor": "Jian He",
      "subchanges": [
        {
          "type": "Ymodifierchange",
          "commitMessage": "YARN-3141. Improve locks in SchedulerApplicationAttempt/FSAppAttempt/FiCaSchedulerApp. Contributed by Wangda Tan\n",
          "commitDate": "19/09/16 2:08 AM",
          "commitName": "b8a30f2f170ffbd590e7366c3c944ab4919e40df",
          "commitAuthor": "Jian He",
          "commitDateOld": "05/08/16 10:43 AM",
          "commitNameOld": "3f100d76ff5df020dbb8ecd4f5b4f9736a0a8270",
          "commitAuthorOld": "Wangda Tan",
          "daysBetweenCommits": 44.64,
          "commitsBetweenForRepo": 264,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,63 +1,68 @@\n-  synchronized public RMContainer allocate(NodeType type, FSSchedulerNode node,\n+  public RMContainer allocate(NodeType type, FSSchedulerNode node,\n       SchedulerRequestKey schedulerKey, ResourceRequest request,\n       Container reservedContainer) {\n-    // Update allowed locality level\n-    NodeType allowed \u003d allowedLocalityLevel.get(schedulerKey);\n-    if (allowed !\u003d null) {\n-      if (allowed.equals(NodeType.OFF_SWITCH) \u0026\u0026\n-          (type.equals(NodeType.NODE_LOCAL) ||\n-              type.equals(NodeType.RACK_LOCAL))) {\n-        this.resetAllowedLocalityLevel(schedulerKey, type);\n+    RMContainer rmContainer;\n+    Container container;\n+\n+    try {\n+      writeLock.lock();\n+      // Update allowed locality level\n+      NodeType allowed \u003d allowedLocalityLevel.get(schedulerKey);\n+      if (allowed !\u003d null) {\n+        if (allowed.equals(NodeType.OFF_SWITCH) \u0026\u0026 (type.equals(\n+            NodeType.NODE_LOCAL) || type.equals(NodeType.RACK_LOCAL))) {\n+          this.resetAllowedLocalityLevel(schedulerKey, type);\n+        } else if (allowed.equals(NodeType.RACK_LOCAL) \u0026\u0026 type.equals(\n+            NodeType.NODE_LOCAL)) {\n+          this.resetAllowedLocalityLevel(schedulerKey, type);\n+        }\n       }\n-      else if (allowed.equals(NodeType.RACK_LOCAL) \u0026\u0026\n-          type.equals(NodeType.NODE_LOCAL)) {\n-        this.resetAllowedLocalityLevel(schedulerKey, type);\n+\n+      // Required sanity check - AM can call \u0027allocate\u0027 to update resource\n+      // request without locking the scheduler, hence we need to check\n+      if (getTotalRequiredResources(schedulerKey) \u003c\u003d 0) {\n+        return null;\n       }\n+\n+      container \u003d reservedContainer;\n+      if (container \u003d\u003d null) {\n+        container \u003d createContainer(node, request.getCapability(),\n+            schedulerKey);\n+      }\n+\n+      // Create RMContainer\n+      rmContainer \u003d new RMContainerImpl(container,\n+          getApplicationAttemptId(), node.getNodeID(),\n+          appSchedulingInfo.getUser(), rmContext);\n+      ((RMContainerImpl) rmContainer).setQueueName(this.getQueueName());\n+\n+      // Add it to allContainers list.\n+      newlyAllocatedContainers.add(rmContainer);\n+      liveContainers.put(container.getId(), rmContainer);\n+\n+      // Update consumption and track allocations\n+      List\u003cResourceRequest\u003e resourceRequestList \u003d appSchedulingInfo.allocate(\n+          type, node, schedulerKey, request, container);\n+      this.attemptResourceUsage.incUsed(container.getResource());\n+\n+      // Update resource requests related to \"request\" and store in RMContainer\n+      ((RMContainerImpl) rmContainer).setResourceRequests(resourceRequestList);\n+\n+      // Inform the container\n+      rmContainer.handle(\n+          new RMContainerEvent(container.getId(), RMContainerEventType.START));\n+\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(\"allocate: applicationAttemptId\u003d\" + container.getId()\n+            .getApplicationAttemptId() + \" container\u003d\" + container.getId()\n+            + \" host\u003d\" + container.getNodeId().getHost() + \" type\u003d\" + type);\n+      }\n+      RMAuditLogger.logSuccess(getUser(), AuditConstants.ALLOC_CONTAINER,\n+          \"SchedulerApp\", getApplicationId(), container.getId(),\n+          container.getResource());\n+    } finally {\n+      writeLock.unlock();\n     }\n \n-    // Required sanity check - AM can call \u0027allocate\u0027 to update resource \n-    // request without locking the scheduler, hence we need to check\n-    if (getTotalRequiredResources(schedulerKey) \u003c\u003d 0) {\n-      return null;\n-    }\n-\n-    Container container \u003d reservedContainer;\n-    if (container \u003d\u003d null) {\n-      container \u003d\n-          createContainer(node, request.getCapability(), schedulerKey);\n-    }\n-    \n-    // Create RMContainer\n-    RMContainer rmContainer \u003d new RMContainerImpl(container,\n-        getApplicationAttemptId(), node.getNodeID(),\n-        appSchedulingInfo.getUser(), rmContext);\n-    ((RMContainerImpl)rmContainer).setQueueName(this.getQueueName());\n-\n-    // Add it to allContainers list.\n-    newlyAllocatedContainers.add(rmContainer);\n-    liveContainers.put(container.getId(), rmContainer);    \n-\n-    // Update consumption and track allocations\n-    List\u003cResourceRequest\u003e resourceRequestList \u003d appSchedulingInfo.allocate(\n-        type, node, schedulerKey, request, container);\n-    this.attemptResourceUsage.incUsed(container.getResource());\n-\n-    // Update resource requests related to \"request\" and store in RMContainer\n-    ((RMContainerImpl) rmContainer).setResourceRequests(resourceRequestList);\n-\n-    // Inform the container\n-    rmContainer.handle(\n-        new RMContainerEvent(container.getId(), RMContainerEventType.START));\n-\n-    if (LOG.isDebugEnabled()) {\n-      LOG.debug(\"allocate: applicationAttemptId\u003d\" \n-          + container.getId().getApplicationAttemptId() \n-          + \" container\u003d\" + container.getId() + \" host\u003d\"\n-          + container.getNodeId().getHost() + \" type\u003d\" + type);\n-    }\n-    RMAuditLogger.logSuccess(getUser(), \n-        AuditConstants.ALLOC_CONTAINER, \"SchedulerApp\", \n-        getApplicationId(), container.getId(), container.getResource());\n-    \n     return rmContainer;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public RMContainer allocate(NodeType type, FSSchedulerNode node,\n      SchedulerRequestKey schedulerKey, ResourceRequest request,\n      Container reservedContainer) {\n    RMContainer rmContainer;\n    Container container;\n\n    try {\n      writeLock.lock();\n      // Update allowed locality level\n      NodeType allowed \u003d allowedLocalityLevel.get(schedulerKey);\n      if (allowed !\u003d null) {\n        if (allowed.equals(NodeType.OFF_SWITCH) \u0026\u0026 (type.equals(\n            NodeType.NODE_LOCAL) || type.equals(NodeType.RACK_LOCAL))) {\n          this.resetAllowedLocalityLevel(schedulerKey, type);\n        } else if (allowed.equals(NodeType.RACK_LOCAL) \u0026\u0026 type.equals(\n            NodeType.NODE_LOCAL)) {\n          this.resetAllowedLocalityLevel(schedulerKey, type);\n        }\n      }\n\n      // Required sanity check - AM can call \u0027allocate\u0027 to update resource\n      // request without locking the scheduler, hence we need to check\n      if (getTotalRequiredResources(schedulerKey) \u003c\u003d 0) {\n        return null;\n      }\n\n      container \u003d reservedContainer;\n      if (container \u003d\u003d null) {\n        container \u003d createContainer(node, request.getCapability(),\n            schedulerKey);\n      }\n\n      // Create RMContainer\n      rmContainer \u003d new RMContainerImpl(container,\n          getApplicationAttemptId(), node.getNodeID(),\n          appSchedulingInfo.getUser(), rmContext);\n      ((RMContainerImpl) rmContainer).setQueueName(this.getQueueName());\n\n      // Add it to allContainers list.\n      newlyAllocatedContainers.add(rmContainer);\n      liveContainers.put(container.getId(), rmContainer);\n\n      // Update consumption and track allocations\n      List\u003cResourceRequest\u003e resourceRequestList \u003d appSchedulingInfo.allocate(\n          type, node, schedulerKey, request, container);\n      this.attemptResourceUsage.incUsed(container.getResource());\n\n      // Update resource requests related to \"request\" and store in RMContainer\n      ((RMContainerImpl) rmContainer).setResourceRequests(resourceRequestList);\n\n      // Inform the container\n      rmContainer.handle(\n          new RMContainerEvent(container.getId(), RMContainerEventType.START));\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"allocate: applicationAttemptId\u003d\" + container.getId()\n            .getApplicationAttemptId() + \" container\u003d\" + container.getId()\n            + \" host\u003d\" + container.getNodeId().getHost() + \" type\u003d\" + type);\n      }\n      RMAuditLogger.logSuccess(getUser(), AuditConstants.ALLOC_CONTAINER,\n          \"SchedulerApp\", getApplicationId(), container.getId(),\n          container.getResource());\n    } finally {\n      writeLock.unlock();\n    }\n\n    return rmContainer;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FSAppAttempt.java",
          "extendedDetails": {
            "oldValue": "[public, synchronized]",
            "newValue": "[public]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-3141. Improve locks in SchedulerApplicationAttempt/FSAppAttempt/FiCaSchedulerApp. Contributed by Wangda Tan\n",
          "commitDate": "19/09/16 2:08 AM",
          "commitName": "b8a30f2f170ffbd590e7366c3c944ab4919e40df",
          "commitAuthor": "Jian He",
          "commitDateOld": "05/08/16 10:43 AM",
          "commitNameOld": "3f100d76ff5df020dbb8ecd4f5b4f9736a0a8270",
          "commitAuthorOld": "Wangda Tan",
          "daysBetweenCommits": 44.64,
          "commitsBetweenForRepo": 264,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,63 +1,68 @@\n-  synchronized public RMContainer allocate(NodeType type, FSSchedulerNode node,\n+  public RMContainer allocate(NodeType type, FSSchedulerNode node,\n       SchedulerRequestKey schedulerKey, ResourceRequest request,\n       Container reservedContainer) {\n-    // Update allowed locality level\n-    NodeType allowed \u003d allowedLocalityLevel.get(schedulerKey);\n-    if (allowed !\u003d null) {\n-      if (allowed.equals(NodeType.OFF_SWITCH) \u0026\u0026\n-          (type.equals(NodeType.NODE_LOCAL) ||\n-              type.equals(NodeType.RACK_LOCAL))) {\n-        this.resetAllowedLocalityLevel(schedulerKey, type);\n+    RMContainer rmContainer;\n+    Container container;\n+\n+    try {\n+      writeLock.lock();\n+      // Update allowed locality level\n+      NodeType allowed \u003d allowedLocalityLevel.get(schedulerKey);\n+      if (allowed !\u003d null) {\n+        if (allowed.equals(NodeType.OFF_SWITCH) \u0026\u0026 (type.equals(\n+            NodeType.NODE_LOCAL) || type.equals(NodeType.RACK_LOCAL))) {\n+          this.resetAllowedLocalityLevel(schedulerKey, type);\n+        } else if (allowed.equals(NodeType.RACK_LOCAL) \u0026\u0026 type.equals(\n+            NodeType.NODE_LOCAL)) {\n+          this.resetAllowedLocalityLevel(schedulerKey, type);\n+        }\n       }\n-      else if (allowed.equals(NodeType.RACK_LOCAL) \u0026\u0026\n-          type.equals(NodeType.NODE_LOCAL)) {\n-        this.resetAllowedLocalityLevel(schedulerKey, type);\n+\n+      // Required sanity check - AM can call \u0027allocate\u0027 to update resource\n+      // request without locking the scheduler, hence we need to check\n+      if (getTotalRequiredResources(schedulerKey) \u003c\u003d 0) {\n+        return null;\n       }\n+\n+      container \u003d reservedContainer;\n+      if (container \u003d\u003d null) {\n+        container \u003d createContainer(node, request.getCapability(),\n+            schedulerKey);\n+      }\n+\n+      // Create RMContainer\n+      rmContainer \u003d new RMContainerImpl(container,\n+          getApplicationAttemptId(), node.getNodeID(),\n+          appSchedulingInfo.getUser(), rmContext);\n+      ((RMContainerImpl) rmContainer).setQueueName(this.getQueueName());\n+\n+      // Add it to allContainers list.\n+      newlyAllocatedContainers.add(rmContainer);\n+      liveContainers.put(container.getId(), rmContainer);\n+\n+      // Update consumption and track allocations\n+      List\u003cResourceRequest\u003e resourceRequestList \u003d appSchedulingInfo.allocate(\n+          type, node, schedulerKey, request, container);\n+      this.attemptResourceUsage.incUsed(container.getResource());\n+\n+      // Update resource requests related to \"request\" and store in RMContainer\n+      ((RMContainerImpl) rmContainer).setResourceRequests(resourceRequestList);\n+\n+      // Inform the container\n+      rmContainer.handle(\n+          new RMContainerEvent(container.getId(), RMContainerEventType.START));\n+\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(\"allocate: applicationAttemptId\u003d\" + container.getId()\n+            .getApplicationAttemptId() + \" container\u003d\" + container.getId()\n+            + \" host\u003d\" + container.getNodeId().getHost() + \" type\u003d\" + type);\n+      }\n+      RMAuditLogger.logSuccess(getUser(), AuditConstants.ALLOC_CONTAINER,\n+          \"SchedulerApp\", getApplicationId(), container.getId(),\n+          container.getResource());\n+    } finally {\n+      writeLock.unlock();\n     }\n \n-    // Required sanity check - AM can call \u0027allocate\u0027 to update resource \n-    // request without locking the scheduler, hence we need to check\n-    if (getTotalRequiredResources(schedulerKey) \u003c\u003d 0) {\n-      return null;\n-    }\n-\n-    Container container \u003d reservedContainer;\n-    if (container \u003d\u003d null) {\n-      container \u003d\n-          createContainer(node, request.getCapability(), schedulerKey);\n-    }\n-    \n-    // Create RMContainer\n-    RMContainer rmContainer \u003d new RMContainerImpl(container,\n-        getApplicationAttemptId(), node.getNodeID(),\n-        appSchedulingInfo.getUser(), rmContext);\n-    ((RMContainerImpl)rmContainer).setQueueName(this.getQueueName());\n-\n-    // Add it to allContainers list.\n-    newlyAllocatedContainers.add(rmContainer);\n-    liveContainers.put(container.getId(), rmContainer);    \n-\n-    // Update consumption and track allocations\n-    List\u003cResourceRequest\u003e resourceRequestList \u003d appSchedulingInfo.allocate(\n-        type, node, schedulerKey, request, container);\n-    this.attemptResourceUsage.incUsed(container.getResource());\n-\n-    // Update resource requests related to \"request\" and store in RMContainer\n-    ((RMContainerImpl) rmContainer).setResourceRequests(resourceRequestList);\n-\n-    // Inform the container\n-    rmContainer.handle(\n-        new RMContainerEvent(container.getId(), RMContainerEventType.START));\n-\n-    if (LOG.isDebugEnabled()) {\n-      LOG.debug(\"allocate: applicationAttemptId\u003d\" \n-          + container.getId().getApplicationAttemptId() \n-          + \" container\u003d\" + container.getId() + \" host\u003d\"\n-          + container.getNodeId().getHost() + \" type\u003d\" + type);\n-    }\n-    RMAuditLogger.logSuccess(getUser(), \n-        AuditConstants.ALLOC_CONTAINER, \"SchedulerApp\", \n-        getApplicationId(), container.getId(), container.getResource());\n-    \n     return rmContainer;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public RMContainer allocate(NodeType type, FSSchedulerNode node,\n      SchedulerRequestKey schedulerKey, ResourceRequest request,\n      Container reservedContainer) {\n    RMContainer rmContainer;\n    Container container;\n\n    try {\n      writeLock.lock();\n      // Update allowed locality level\n      NodeType allowed \u003d allowedLocalityLevel.get(schedulerKey);\n      if (allowed !\u003d null) {\n        if (allowed.equals(NodeType.OFF_SWITCH) \u0026\u0026 (type.equals(\n            NodeType.NODE_LOCAL) || type.equals(NodeType.RACK_LOCAL))) {\n          this.resetAllowedLocalityLevel(schedulerKey, type);\n        } else if (allowed.equals(NodeType.RACK_LOCAL) \u0026\u0026 type.equals(\n            NodeType.NODE_LOCAL)) {\n          this.resetAllowedLocalityLevel(schedulerKey, type);\n        }\n      }\n\n      // Required sanity check - AM can call \u0027allocate\u0027 to update resource\n      // request without locking the scheduler, hence we need to check\n      if (getTotalRequiredResources(schedulerKey) \u003c\u003d 0) {\n        return null;\n      }\n\n      container \u003d reservedContainer;\n      if (container \u003d\u003d null) {\n        container \u003d createContainer(node, request.getCapability(),\n            schedulerKey);\n      }\n\n      // Create RMContainer\n      rmContainer \u003d new RMContainerImpl(container,\n          getApplicationAttemptId(), node.getNodeID(),\n          appSchedulingInfo.getUser(), rmContext);\n      ((RMContainerImpl) rmContainer).setQueueName(this.getQueueName());\n\n      // Add it to allContainers list.\n      newlyAllocatedContainers.add(rmContainer);\n      liveContainers.put(container.getId(), rmContainer);\n\n      // Update consumption and track allocations\n      List\u003cResourceRequest\u003e resourceRequestList \u003d appSchedulingInfo.allocate(\n          type, node, schedulerKey, request, container);\n      this.attemptResourceUsage.incUsed(container.getResource());\n\n      // Update resource requests related to \"request\" and store in RMContainer\n      ((RMContainerImpl) rmContainer).setResourceRequests(resourceRequestList);\n\n      // Inform the container\n      rmContainer.handle(\n          new RMContainerEvent(container.getId(), RMContainerEventType.START));\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"allocate: applicationAttemptId\u003d\" + container.getId()\n            .getApplicationAttemptId() + \" container\u003d\" + container.getId()\n            + \" host\u003d\" + container.getNodeId().getHost() + \" type\u003d\" + type);\n      }\n      RMAuditLogger.logSuccess(getUser(), AuditConstants.ALLOC_CONTAINER,\n          \"SchedulerApp\", getApplicationId(), container.getId(),\n          container.getResource());\n    } finally {\n      writeLock.unlock();\n    }\n\n    return rmContainer;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FSAppAttempt.java",
          "extendedDetails": {}
        }
      ]
    },
    "5aace38b748ba71aaadd2c4d64eba8dc1f816828": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "YARN-5392. Replace use of Priority in the Scheduling infrastructure with an opaque ShedulerRequestKey. (asuresh and subru)\n",
      "commitDate": "26/07/16 2:54 PM",
      "commitName": "5aace38b748ba71aaadd2c4d64eba8dc1f816828",
      "commitAuthor": "Arun Suresh",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "YARN-5392. Replace use of Priority in the Scheduling infrastructure with an opaque ShedulerRequestKey. (asuresh and subru)\n",
          "commitDate": "26/07/16 2:54 PM",
          "commitName": "5aace38b748ba71aaadd2c4d64eba8dc1f816828",
          "commitAuthor": "Arun Suresh",
          "commitDateOld": "11/07/16 10:36 PM",
          "commitNameOld": "819224dcf9c683aa52f58633ac8e13663f1916d8",
          "commitAuthorOld": "Jian He",
          "daysBetweenCommits": 14.68,
          "commitsBetweenForRepo": 98,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,63 +1,63 @@\n   synchronized public RMContainer allocate(NodeType type, FSSchedulerNode node,\n-      Priority priority, ResourceRequest request,\n+      SchedulerRequestKey schedulerKey, ResourceRequest request,\n       Container reservedContainer) {\n     // Update allowed locality level\n-    NodeType allowed \u003d allowedLocalityLevel.get(priority);\n+    NodeType allowed \u003d allowedLocalityLevel.get(schedulerKey);\n     if (allowed !\u003d null) {\n       if (allowed.equals(NodeType.OFF_SWITCH) \u0026\u0026\n           (type.equals(NodeType.NODE_LOCAL) ||\n               type.equals(NodeType.RACK_LOCAL))) {\n-        this.resetAllowedLocalityLevel(priority, type);\n+        this.resetAllowedLocalityLevel(schedulerKey, type);\n       }\n       else if (allowed.equals(NodeType.RACK_LOCAL) \u0026\u0026\n           type.equals(NodeType.NODE_LOCAL)) {\n-        this.resetAllowedLocalityLevel(priority, type);\n+        this.resetAllowedLocalityLevel(schedulerKey, type);\n       }\n     }\n \n     // Required sanity check - AM can call \u0027allocate\u0027 to update resource \n     // request without locking the scheduler, hence we need to check\n-    if (getTotalRequiredResources(priority) \u003c\u003d 0) {\n+    if (getTotalRequiredResources(schedulerKey) \u003c\u003d 0) {\n       return null;\n     }\n \n     Container container \u003d reservedContainer;\n     if (container \u003d\u003d null) {\n       container \u003d\n-          createContainer(node, request.getCapability(), request.getPriority());\n+          createContainer(node, request.getCapability(), schedulerKey);\n     }\n     \n     // Create RMContainer\n     RMContainer rmContainer \u003d new RMContainerImpl(container,\n         getApplicationAttemptId(), node.getNodeID(),\n         appSchedulingInfo.getUser(), rmContext);\n     ((RMContainerImpl)rmContainer).setQueueName(this.getQueueName());\n \n     // Add it to allContainers list.\n     newlyAllocatedContainers.add(rmContainer);\n     liveContainers.put(container.getId(), rmContainer);    \n \n     // Update consumption and track allocations\n     List\u003cResourceRequest\u003e resourceRequestList \u003d appSchedulingInfo.allocate(\n-        type, node, priority, request, container);\n+        type, node, schedulerKey, request, container);\n     this.attemptResourceUsage.incUsed(container.getResource());\n \n     // Update resource requests related to \"request\" and store in RMContainer\n     ((RMContainerImpl) rmContainer).setResourceRequests(resourceRequestList);\n \n     // Inform the container\n     rmContainer.handle(\n         new RMContainerEvent(container.getId(), RMContainerEventType.START));\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"allocate: applicationAttemptId\u003d\" \n           + container.getId().getApplicationAttemptId() \n           + \" container\u003d\" + container.getId() + \" host\u003d\"\n           + container.getNodeId().getHost() + \" type\u003d\" + type);\n     }\n     RMAuditLogger.logSuccess(getUser(), \n         AuditConstants.ALLOC_CONTAINER, \"SchedulerApp\", \n         getApplicationId(), container.getId(), container.getResource());\n     \n     return rmContainer;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  synchronized public RMContainer allocate(NodeType type, FSSchedulerNode node,\n      SchedulerRequestKey schedulerKey, ResourceRequest request,\n      Container reservedContainer) {\n    // Update allowed locality level\n    NodeType allowed \u003d allowedLocalityLevel.get(schedulerKey);\n    if (allowed !\u003d null) {\n      if (allowed.equals(NodeType.OFF_SWITCH) \u0026\u0026\n          (type.equals(NodeType.NODE_LOCAL) ||\n              type.equals(NodeType.RACK_LOCAL))) {\n        this.resetAllowedLocalityLevel(schedulerKey, type);\n      }\n      else if (allowed.equals(NodeType.RACK_LOCAL) \u0026\u0026\n          type.equals(NodeType.NODE_LOCAL)) {\n        this.resetAllowedLocalityLevel(schedulerKey, type);\n      }\n    }\n\n    // Required sanity check - AM can call \u0027allocate\u0027 to update resource \n    // request without locking the scheduler, hence we need to check\n    if (getTotalRequiredResources(schedulerKey) \u003c\u003d 0) {\n      return null;\n    }\n\n    Container container \u003d reservedContainer;\n    if (container \u003d\u003d null) {\n      container \u003d\n          createContainer(node, request.getCapability(), schedulerKey);\n    }\n    \n    // Create RMContainer\n    RMContainer rmContainer \u003d new RMContainerImpl(container,\n        getApplicationAttemptId(), node.getNodeID(),\n        appSchedulingInfo.getUser(), rmContext);\n    ((RMContainerImpl)rmContainer).setQueueName(this.getQueueName());\n\n    // Add it to allContainers list.\n    newlyAllocatedContainers.add(rmContainer);\n    liveContainers.put(container.getId(), rmContainer);    \n\n    // Update consumption and track allocations\n    List\u003cResourceRequest\u003e resourceRequestList \u003d appSchedulingInfo.allocate(\n        type, node, schedulerKey, request, container);\n    this.attemptResourceUsage.incUsed(container.getResource());\n\n    // Update resource requests related to \"request\" and store in RMContainer\n    ((RMContainerImpl) rmContainer).setResourceRequests(resourceRequestList);\n\n    // Inform the container\n    rmContainer.handle(\n        new RMContainerEvent(container.getId(), RMContainerEventType.START));\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"allocate: applicationAttemptId\u003d\" \n          + container.getId().getApplicationAttemptId() \n          + \" container\u003d\" + container.getId() + \" host\u003d\"\n          + container.getNodeId().getHost() + \" type\u003d\" + type);\n    }\n    RMAuditLogger.logSuccess(getUser(), \n        AuditConstants.ALLOC_CONTAINER, \"SchedulerApp\", \n        getApplicationId(), container.getId(), container.getResource());\n    \n    return rmContainer;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FSAppAttempt.java",
          "extendedDetails": {
            "oldValue": "[type-NodeType, node-FSSchedulerNode, priority-Priority, request-ResourceRequest, reservedContainer-Container]",
            "newValue": "[type-NodeType, node-FSSchedulerNode, schedulerKey-SchedulerRequestKey, request-ResourceRequest, reservedContainer-Container]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-5392. Replace use of Priority in the Scheduling infrastructure with an opaque ShedulerRequestKey. (asuresh and subru)\n",
          "commitDate": "26/07/16 2:54 PM",
          "commitName": "5aace38b748ba71aaadd2c4d64eba8dc1f816828",
          "commitAuthor": "Arun Suresh",
          "commitDateOld": "11/07/16 10:36 PM",
          "commitNameOld": "819224dcf9c683aa52f58633ac8e13663f1916d8",
          "commitAuthorOld": "Jian He",
          "daysBetweenCommits": 14.68,
          "commitsBetweenForRepo": 98,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,63 +1,63 @@\n   synchronized public RMContainer allocate(NodeType type, FSSchedulerNode node,\n-      Priority priority, ResourceRequest request,\n+      SchedulerRequestKey schedulerKey, ResourceRequest request,\n       Container reservedContainer) {\n     // Update allowed locality level\n-    NodeType allowed \u003d allowedLocalityLevel.get(priority);\n+    NodeType allowed \u003d allowedLocalityLevel.get(schedulerKey);\n     if (allowed !\u003d null) {\n       if (allowed.equals(NodeType.OFF_SWITCH) \u0026\u0026\n           (type.equals(NodeType.NODE_LOCAL) ||\n               type.equals(NodeType.RACK_LOCAL))) {\n-        this.resetAllowedLocalityLevel(priority, type);\n+        this.resetAllowedLocalityLevel(schedulerKey, type);\n       }\n       else if (allowed.equals(NodeType.RACK_LOCAL) \u0026\u0026\n           type.equals(NodeType.NODE_LOCAL)) {\n-        this.resetAllowedLocalityLevel(priority, type);\n+        this.resetAllowedLocalityLevel(schedulerKey, type);\n       }\n     }\n \n     // Required sanity check - AM can call \u0027allocate\u0027 to update resource \n     // request without locking the scheduler, hence we need to check\n-    if (getTotalRequiredResources(priority) \u003c\u003d 0) {\n+    if (getTotalRequiredResources(schedulerKey) \u003c\u003d 0) {\n       return null;\n     }\n \n     Container container \u003d reservedContainer;\n     if (container \u003d\u003d null) {\n       container \u003d\n-          createContainer(node, request.getCapability(), request.getPriority());\n+          createContainer(node, request.getCapability(), schedulerKey);\n     }\n     \n     // Create RMContainer\n     RMContainer rmContainer \u003d new RMContainerImpl(container,\n         getApplicationAttemptId(), node.getNodeID(),\n         appSchedulingInfo.getUser(), rmContext);\n     ((RMContainerImpl)rmContainer).setQueueName(this.getQueueName());\n \n     // Add it to allContainers list.\n     newlyAllocatedContainers.add(rmContainer);\n     liveContainers.put(container.getId(), rmContainer);    \n \n     // Update consumption and track allocations\n     List\u003cResourceRequest\u003e resourceRequestList \u003d appSchedulingInfo.allocate(\n-        type, node, priority, request, container);\n+        type, node, schedulerKey, request, container);\n     this.attemptResourceUsage.incUsed(container.getResource());\n \n     // Update resource requests related to \"request\" and store in RMContainer\n     ((RMContainerImpl) rmContainer).setResourceRequests(resourceRequestList);\n \n     // Inform the container\n     rmContainer.handle(\n         new RMContainerEvent(container.getId(), RMContainerEventType.START));\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"allocate: applicationAttemptId\u003d\" \n           + container.getId().getApplicationAttemptId() \n           + \" container\u003d\" + container.getId() + \" host\u003d\"\n           + container.getNodeId().getHost() + \" type\u003d\" + type);\n     }\n     RMAuditLogger.logSuccess(getUser(), \n         AuditConstants.ALLOC_CONTAINER, \"SchedulerApp\", \n         getApplicationId(), container.getId(), container.getResource());\n     \n     return rmContainer;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  synchronized public RMContainer allocate(NodeType type, FSSchedulerNode node,\n      SchedulerRequestKey schedulerKey, ResourceRequest request,\n      Container reservedContainer) {\n    // Update allowed locality level\n    NodeType allowed \u003d allowedLocalityLevel.get(schedulerKey);\n    if (allowed !\u003d null) {\n      if (allowed.equals(NodeType.OFF_SWITCH) \u0026\u0026\n          (type.equals(NodeType.NODE_LOCAL) ||\n              type.equals(NodeType.RACK_LOCAL))) {\n        this.resetAllowedLocalityLevel(schedulerKey, type);\n      }\n      else if (allowed.equals(NodeType.RACK_LOCAL) \u0026\u0026\n          type.equals(NodeType.NODE_LOCAL)) {\n        this.resetAllowedLocalityLevel(schedulerKey, type);\n      }\n    }\n\n    // Required sanity check - AM can call \u0027allocate\u0027 to update resource \n    // request without locking the scheduler, hence we need to check\n    if (getTotalRequiredResources(schedulerKey) \u003c\u003d 0) {\n      return null;\n    }\n\n    Container container \u003d reservedContainer;\n    if (container \u003d\u003d null) {\n      container \u003d\n          createContainer(node, request.getCapability(), schedulerKey);\n    }\n    \n    // Create RMContainer\n    RMContainer rmContainer \u003d new RMContainerImpl(container,\n        getApplicationAttemptId(), node.getNodeID(),\n        appSchedulingInfo.getUser(), rmContext);\n    ((RMContainerImpl)rmContainer).setQueueName(this.getQueueName());\n\n    // Add it to allContainers list.\n    newlyAllocatedContainers.add(rmContainer);\n    liveContainers.put(container.getId(), rmContainer);    \n\n    // Update consumption and track allocations\n    List\u003cResourceRequest\u003e resourceRequestList \u003d appSchedulingInfo.allocate(\n        type, node, schedulerKey, request, container);\n    this.attemptResourceUsage.incUsed(container.getResource());\n\n    // Update resource requests related to \"request\" and store in RMContainer\n    ((RMContainerImpl) rmContainer).setResourceRequests(resourceRequestList);\n\n    // Inform the container\n    rmContainer.handle(\n        new RMContainerEvent(container.getId(), RMContainerEventType.START));\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"allocate: applicationAttemptId\u003d\" \n          + container.getId().getApplicationAttemptId() \n          + \" container\u003d\" + container.getId() + \" host\u003d\"\n          + container.getNodeId().getHost() + \" type\u003d\" + type);\n    }\n    RMAuditLogger.logSuccess(getUser(), \n        AuditConstants.ALLOC_CONTAINER, \"SchedulerApp\", \n        getApplicationId(), container.getId(), container.getResource());\n    \n    return rmContainer;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FSAppAttempt.java",
          "extendedDetails": {}
        }
      ]
    },
    "5279af7cd4afb090da742a96b5786d9dee6224bc": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "YARN-5082. Limit ContainerId increase in fair scheduler if the num of node app reserved reached the limit (sandflee via asuresh)\n",
      "commitDate": "10/06/16 10:33 PM",
      "commitName": "5279af7cd4afb090da742a96b5786d9dee6224bc",
      "commitAuthor": "Arun Suresh",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "YARN-5082. Limit ContainerId increase in fair scheduler if the num of node app reserved reached the limit (sandflee via asuresh)\n",
          "commitDate": "10/06/16 10:33 PM",
          "commitName": "5279af7cd4afb090da742a96b5786d9dee6224bc",
          "commitAuthor": "Arun Suresh",
          "commitDateOld": "29/05/16 8:54 AM",
          "commitNameOld": "42f90ab885d9693fcc1e52f9637f7de4111110ae",
          "commitAuthorOld": "Varun Vasudev",
          "daysBetweenCommits": 12.57,
          "commitsBetweenForRepo": 84,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,57 +1,63 @@\n   synchronized public RMContainer allocate(NodeType type, FSSchedulerNode node,\n       Priority priority, ResourceRequest request,\n-      Container container) {\n+      Container reservedContainer) {\n     // Update allowed locality level\n     NodeType allowed \u003d allowedLocalityLevel.get(priority);\n     if (allowed !\u003d null) {\n       if (allowed.equals(NodeType.OFF_SWITCH) \u0026\u0026\n           (type.equals(NodeType.NODE_LOCAL) ||\n               type.equals(NodeType.RACK_LOCAL))) {\n         this.resetAllowedLocalityLevel(priority, type);\n       }\n       else if (allowed.equals(NodeType.RACK_LOCAL) \u0026\u0026\n           type.equals(NodeType.NODE_LOCAL)) {\n         this.resetAllowedLocalityLevel(priority, type);\n       }\n     }\n \n     // Required sanity check - AM can call \u0027allocate\u0027 to update resource \n     // request without locking the scheduler, hence we need to check\n     if (getTotalRequiredResources(priority) \u003c\u003d 0) {\n       return null;\n     }\n+\n+    Container container \u003d reservedContainer;\n+    if (container \u003d\u003d null) {\n+      container \u003d\n+          createContainer(node, request.getCapability(), request.getPriority());\n+    }\n     \n     // Create RMContainer\n-    RMContainer rmContainer \u003d new RMContainerImpl(container, \n+    RMContainer rmContainer \u003d new RMContainerImpl(container,\n         getApplicationAttemptId(), node.getNodeID(),\n         appSchedulingInfo.getUser(), rmContext);\n     ((RMContainerImpl)rmContainer).setQueueName(this.getQueueName());\n \n     // Add it to allContainers list.\n     newlyAllocatedContainers.add(rmContainer);\n     liveContainers.put(container.getId(), rmContainer);    \n \n     // Update consumption and track allocations\n     List\u003cResourceRequest\u003e resourceRequestList \u003d appSchedulingInfo.allocate(\n         type, node, priority, request, container);\n     this.attemptResourceUsage.incUsed(container.getResource());\n \n     // Update resource requests related to \"request\" and store in RMContainer\n     ((RMContainerImpl) rmContainer).setResourceRequests(resourceRequestList);\n \n     // Inform the container\n     rmContainer.handle(\n         new RMContainerEvent(container.getId(), RMContainerEventType.START));\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"allocate: applicationAttemptId\u003d\" \n           + container.getId().getApplicationAttemptId() \n           + \" container\u003d\" + container.getId() + \" host\u003d\"\n           + container.getNodeId().getHost() + \" type\u003d\" + type);\n     }\n     RMAuditLogger.logSuccess(getUser(), \n         AuditConstants.ALLOC_CONTAINER, \"SchedulerApp\", \n         getApplicationId(), container.getId(), container.getResource());\n     \n     return rmContainer;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  synchronized public RMContainer allocate(NodeType type, FSSchedulerNode node,\n      Priority priority, ResourceRequest request,\n      Container reservedContainer) {\n    // Update allowed locality level\n    NodeType allowed \u003d allowedLocalityLevel.get(priority);\n    if (allowed !\u003d null) {\n      if (allowed.equals(NodeType.OFF_SWITCH) \u0026\u0026\n          (type.equals(NodeType.NODE_LOCAL) ||\n              type.equals(NodeType.RACK_LOCAL))) {\n        this.resetAllowedLocalityLevel(priority, type);\n      }\n      else if (allowed.equals(NodeType.RACK_LOCAL) \u0026\u0026\n          type.equals(NodeType.NODE_LOCAL)) {\n        this.resetAllowedLocalityLevel(priority, type);\n      }\n    }\n\n    // Required sanity check - AM can call \u0027allocate\u0027 to update resource \n    // request without locking the scheduler, hence we need to check\n    if (getTotalRequiredResources(priority) \u003c\u003d 0) {\n      return null;\n    }\n\n    Container container \u003d reservedContainer;\n    if (container \u003d\u003d null) {\n      container \u003d\n          createContainer(node, request.getCapability(), request.getPriority());\n    }\n    \n    // Create RMContainer\n    RMContainer rmContainer \u003d new RMContainerImpl(container,\n        getApplicationAttemptId(), node.getNodeID(),\n        appSchedulingInfo.getUser(), rmContext);\n    ((RMContainerImpl)rmContainer).setQueueName(this.getQueueName());\n\n    // Add it to allContainers list.\n    newlyAllocatedContainers.add(rmContainer);\n    liveContainers.put(container.getId(), rmContainer);    \n\n    // Update consumption and track allocations\n    List\u003cResourceRequest\u003e resourceRequestList \u003d appSchedulingInfo.allocate(\n        type, node, priority, request, container);\n    this.attemptResourceUsage.incUsed(container.getResource());\n\n    // Update resource requests related to \"request\" and store in RMContainer\n    ((RMContainerImpl) rmContainer).setResourceRequests(resourceRequestList);\n\n    // Inform the container\n    rmContainer.handle(\n        new RMContainerEvent(container.getId(), RMContainerEventType.START));\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"allocate: applicationAttemptId\u003d\" \n          + container.getId().getApplicationAttemptId() \n          + \" container\u003d\" + container.getId() + \" host\u003d\"\n          + container.getNodeId().getHost() + \" type\u003d\" + type);\n    }\n    RMAuditLogger.logSuccess(getUser(), \n        AuditConstants.ALLOC_CONTAINER, \"SchedulerApp\", \n        getApplicationId(), container.getId(), container.getResource());\n    \n    return rmContainer;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FSAppAttempt.java",
          "extendedDetails": {
            "oldValue": "[type-NodeType, node-FSSchedulerNode, priority-Priority, request-ResourceRequest, container-Container]",
            "newValue": "[type-NodeType, node-FSSchedulerNode, priority-Priority, request-ResourceRequest, reservedContainer-Container]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-5082. Limit ContainerId increase in fair scheduler if the num of node app reserved reached the limit (sandflee via asuresh)\n",
          "commitDate": "10/06/16 10:33 PM",
          "commitName": "5279af7cd4afb090da742a96b5786d9dee6224bc",
          "commitAuthor": "Arun Suresh",
          "commitDateOld": "29/05/16 8:54 AM",
          "commitNameOld": "42f90ab885d9693fcc1e52f9637f7de4111110ae",
          "commitAuthorOld": "Varun Vasudev",
          "daysBetweenCommits": 12.57,
          "commitsBetweenForRepo": 84,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,57 +1,63 @@\n   synchronized public RMContainer allocate(NodeType type, FSSchedulerNode node,\n       Priority priority, ResourceRequest request,\n-      Container container) {\n+      Container reservedContainer) {\n     // Update allowed locality level\n     NodeType allowed \u003d allowedLocalityLevel.get(priority);\n     if (allowed !\u003d null) {\n       if (allowed.equals(NodeType.OFF_SWITCH) \u0026\u0026\n           (type.equals(NodeType.NODE_LOCAL) ||\n               type.equals(NodeType.RACK_LOCAL))) {\n         this.resetAllowedLocalityLevel(priority, type);\n       }\n       else if (allowed.equals(NodeType.RACK_LOCAL) \u0026\u0026\n           type.equals(NodeType.NODE_LOCAL)) {\n         this.resetAllowedLocalityLevel(priority, type);\n       }\n     }\n \n     // Required sanity check - AM can call \u0027allocate\u0027 to update resource \n     // request without locking the scheduler, hence we need to check\n     if (getTotalRequiredResources(priority) \u003c\u003d 0) {\n       return null;\n     }\n+\n+    Container container \u003d reservedContainer;\n+    if (container \u003d\u003d null) {\n+      container \u003d\n+          createContainer(node, request.getCapability(), request.getPriority());\n+    }\n     \n     // Create RMContainer\n-    RMContainer rmContainer \u003d new RMContainerImpl(container, \n+    RMContainer rmContainer \u003d new RMContainerImpl(container,\n         getApplicationAttemptId(), node.getNodeID(),\n         appSchedulingInfo.getUser(), rmContext);\n     ((RMContainerImpl)rmContainer).setQueueName(this.getQueueName());\n \n     // Add it to allContainers list.\n     newlyAllocatedContainers.add(rmContainer);\n     liveContainers.put(container.getId(), rmContainer);    \n \n     // Update consumption and track allocations\n     List\u003cResourceRequest\u003e resourceRequestList \u003d appSchedulingInfo.allocate(\n         type, node, priority, request, container);\n     this.attemptResourceUsage.incUsed(container.getResource());\n \n     // Update resource requests related to \"request\" and store in RMContainer\n     ((RMContainerImpl) rmContainer).setResourceRequests(resourceRequestList);\n \n     // Inform the container\n     rmContainer.handle(\n         new RMContainerEvent(container.getId(), RMContainerEventType.START));\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"allocate: applicationAttemptId\u003d\" \n           + container.getId().getApplicationAttemptId() \n           + \" container\u003d\" + container.getId() + \" host\u003d\"\n           + container.getNodeId().getHost() + \" type\u003d\" + type);\n     }\n     RMAuditLogger.logSuccess(getUser(), \n         AuditConstants.ALLOC_CONTAINER, \"SchedulerApp\", \n         getApplicationId(), container.getId(), container.getResource());\n     \n     return rmContainer;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  synchronized public RMContainer allocate(NodeType type, FSSchedulerNode node,\n      Priority priority, ResourceRequest request,\n      Container reservedContainer) {\n    // Update allowed locality level\n    NodeType allowed \u003d allowedLocalityLevel.get(priority);\n    if (allowed !\u003d null) {\n      if (allowed.equals(NodeType.OFF_SWITCH) \u0026\u0026\n          (type.equals(NodeType.NODE_LOCAL) ||\n              type.equals(NodeType.RACK_LOCAL))) {\n        this.resetAllowedLocalityLevel(priority, type);\n      }\n      else if (allowed.equals(NodeType.RACK_LOCAL) \u0026\u0026\n          type.equals(NodeType.NODE_LOCAL)) {\n        this.resetAllowedLocalityLevel(priority, type);\n      }\n    }\n\n    // Required sanity check - AM can call \u0027allocate\u0027 to update resource \n    // request without locking the scheduler, hence we need to check\n    if (getTotalRequiredResources(priority) \u003c\u003d 0) {\n      return null;\n    }\n\n    Container container \u003d reservedContainer;\n    if (container \u003d\u003d null) {\n      container \u003d\n          createContainer(node, request.getCapability(), request.getPriority());\n    }\n    \n    // Create RMContainer\n    RMContainer rmContainer \u003d new RMContainerImpl(container,\n        getApplicationAttemptId(), node.getNodeID(),\n        appSchedulingInfo.getUser(), rmContext);\n    ((RMContainerImpl)rmContainer).setQueueName(this.getQueueName());\n\n    // Add it to allContainers list.\n    newlyAllocatedContainers.add(rmContainer);\n    liveContainers.put(container.getId(), rmContainer);    \n\n    // Update consumption and track allocations\n    List\u003cResourceRequest\u003e resourceRequestList \u003d appSchedulingInfo.allocate(\n        type, node, priority, request, container);\n    this.attemptResourceUsage.incUsed(container.getResource());\n\n    // Update resource requests related to \"request\" and store in RMContainer\n    ((RMContainerImpl) rmContainer).setResourceRequests(resourceRequestList);\n\n    // Inform the container\n    rmContainer.handle(\n        new RMContainerEvent(container.getId(), RMContainerEventType.START));\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"allocate: applicationAttemptId\u003d\" \n          + container.getId().getApplicationAttemptId() \n          + \" container\u003d\" + container.getId() + \" host\u003d\"\n          + container.getNodeId().getHost() + \" type\u003d\" + type);\n    }\n    RMAuditLogger.logSuccess(getUser(), \n        AuditConstants.ALLOC_CONTAINER, \"SchedulerApp\", \n        getApplicationId(), container.getId(), container.getResource());\n    \n    return rmContainer;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FSAppAttempt.java",
          "extendedDetails": {}
        }
      ]
    },
    "bb62e0592566b2fcae7136b30972aad2d3ac55b0": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4390. Do surgical preemption based on reserved container in CapacityScheduler. Contributed by Wangda Tan\n",
      "commitDate": "05/05/16 12:56 PM",
      "commitName": "bb62e0592566b2fcae7136b30972aad2d3ac55b0",
      "commitAuthor": "Jian He",
      "commitDateOld": "03/05/16 1:03 PM",
      "commitNameOld": "ed54f5f1ff7862f8216f77d5ea8f9ccea674ccd1",
      "commitAuthorOld": "Jason Lowe",
      "daysBetweenCommits": 1.99,
      "commitsBetweenForRepo": 16,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,56 +1,57 @@\n   synchronized public RMContainer allocate(NodeType type, FSSchedulerNode node,\n       Priority priority, ResourceRequest request,\n       Container container) {\n     // Update allowed locality level\n     NodeType allowed \u003d allowedLocalityLevel.get(priority);\n     if (allowed !\u003d null) {\n       if (allowed.equals(NodeType.OFF_SWITCH) \u0026\u0026\n           (type.equals(NodeType.NODE_LOCAL) ||\n               type.equals(NodeType.RACK_LOCAL))) {\n         this.resetAllowedLocalityLevel(priority, type);\n       }\n       else if (allowed.equals(NodeType.RACK_LOCAL) \u0026\u0026\n           type.equals(NodeType.NODE_LOCAL)) {\n         this.resetAllowedLocalityLevel(priority, type);\n       }\n     }\n \n     // Required sanity check - AM can call \u0027allocate\u0027 to update resource \n     // request without locking the scheduler, hence we need to check\n     if (getTotalRequiredResources(priority) \u003c\u003d 0) {\n       return null;\n     }\n     \n     // Create RMContainer\n     RMContainer rmContainer \u003d new RMContainerImpl(container, \n         getApplicationAttemptId(), node.getNodeID(),\n         appSchedulingInfo.getUser(), rmContext);\n+    ((RMContainerImpl)rmContainer).setQueueName(this.getQueueName());\n \n     // Add it to allContainers list.\n     newlyAllocatedContainers.add(rmContainer);\n     liveContainers.put(container.getId(), rmContainer);    \n \n     // Update consumption and track allocations\n     List\u003cResourceRequest\u003e resourceRequestList \u003d appSchedulingInfo.allocate(\n         type, node, priority, request, container);\n     this.attemptResourceUsage.incUsed(container.getResource());\n \n     // Update resource requests related to \"request\" and store in RMContainer\n     ((RMContainerImpl) rmContainer).setResourceRequests(resourceRequestList);\n \n     // Inform the container\n     rmContainer.handle(\n         new RMContainerEvent(container.getId(), RMContainerEventType.START));\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"allocate: applicationAttemptId\u003d\" \n           + container.getId().getApplicationAttemptId() \n           + \" container\u003d\" + container.getId() + \" host\u003d\"\n           + container.getNodeId().getHost() + \" type\u003d\" + type);\n     }\n     RMAuditLogger.logSuccess(getUser(), \n         AuditConstants.ALLOC_CONTAINER, \"SchedulerApp\", \n         getApplicationId(), container.getId(), container.getResource());\n     \n     return rmContainer;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  synchronized public RMContainer allocate(NodeType type, FSSchedulerNode node,\n      Priority priority, ResourceRequest request,\n      Container container) {\n    // Update allowed locality level\n    NodeType allowed \u003d allowedLocalityLevel.get(priority);\n    if (allowed !\u003d null) {\n      if (allowed.equals(NodeType.OFF_SWITCH) \u0026\u0026\n          (type.equals(NodeType.NODE_LOCAL) ||\n              type.equals(NodeType.RACK_LOCAL))) {\n        this.resetAllowedLocalityLevel(priority, type);\n      }\n      else if (allowed.equals(NodeType.RACK_LOCAL) \u0026\u0026\n          type.equals(NodeType.NODE_LOCAL)) {\n        this.resetAllowedLocalityLevel(priority, type);\n      }\n    }\n\n    // Required sanity check - AM can call \u0027allocate\u0027 to update resource \n    // request without locking the scheduler, hence we need to check\n    if (getTotalRequiredResources(priority) \u003c\u003d 0) {\n      return null;\n    }\n    \n    // Create RMContainer\n    RMContainer rmContainer \u003d new RMContainerImpl(container, \n        getApplicationAttemptId(), node.getNodeID(),\n        appSchedulingInfo.getUser(), rmContext);\n    ((RMContainerImpl)rmContainer).setQueueName(this.getQueueName());\n\n    // Add it to allContainers list.\n    newlyAllocatedContainers.add(rmContainer);\n    liveContainers.put(container.getId(), rmContainer);    \n\n    // Update consumption and track allocations\n    List\u003cResourceRequest\u003e resourceRequestList \u003d appSchedulingInfo.allocate(\n        type, node, priority, request, container);\n    this.attemptResourceUsage.incUsed(container.getResource());\n\n    // Update resource requests related to \"request\" and store in RMContainer\n    ((RMContainerImpl) rmContainer).setResourceRequests(resourceRequestList);\n\n    // Inform the container\n    rmContainer.handle(\n        new RMContainerEvent(container.getId(), RMContainerEventType.START));\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"allocate: applicationAttemptId\u003d\" \n          + container.getId().getApplicationAttemptId() \n          + \" container\u003d\" + container.getId() + \" host\u003d\"\n          + container.getNodeId().getHost() + \" type\u003d\" + type);\n    }\n    RMAuditLogger.logSuccess(getUser(), \n        AuditConstants.ALLOC_CONTAINER, \"SchedulerApp\", \n        getApplicationId(), container.getId(), container.getResource());\n    \n    return rmContainer;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FSAppAttempt.java",
      "extendedDetails": {}
    },
    "ed54f5f1ff7862f8216f77d5ea8f9ccea674ccd1": {
      "type": "Ybodychange",
      "commitMessage": "YARN-5003. Add container resource to RM audit log. Contributed by Nathan Roberts\n",
      "commitDate": "03/05/16 1:03 PM",
      "commitName": "ed54f5f1ff7862f8216f77d5ea8f9ccea674ccd1",
      "commitAuthor": "Jason Lowe",
      "commitDateOld": "26/04/16 5:10 AM",
      "commitNameOld": "4b1dcbbe0c1d0036f65283be4b25d9b2211abed3",
      "commitAuthorOld": "Karthik Kambatla",
      "daysBetweenCommits": 7.33,
      "commitsBetweenForRepo": 42,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,56 +1,56 @@\n   synchronized public RMContainer allocate(NodeType type, FSSchedulerNode node,\n       Priority priority, ResourceRequest request,\n       Container container) {\n     // Update allowed locality level\n     NodeType allowed \u003d allowedLocalityLevel.get(priority);\n     if (allowed !\u003d null) {\n       if (allowed.equals(NodeType.OFF_SWITCH) \u0026\u0026\n           (type.equals(NodeType.NODE_LOCAL) ||\n               type.equals(NodeType.RACK_LOCAL))) {\n         this.resetAllowedLocalityLevel(priority, type);\n       }\n       else if (allowed.equals(NodeType.RACK_LOCAL) \u0026\u0026\n           type.equals(NodeType.NODE_LOCAL)) {\n         this.resetAllowedLocalityLevel(priority, type);\n       }\n     }\n \n     // Required sanity check - AM can call \u0027allocate\u0027 to update resource \n     // request without locking the scheduler, hence we need to check\n     if (getTotalRequiredResources(priority) \u003c\u003d 0) {\n       return null;\n     }\n     \n     // Create RMContainer\n     RMContainer rmContainer \u003d new RMContainerImpl(container, \n         getApplicationAttemptId(), node.getNodeID(),\n         appSchedulingInfo.getUser(), rmContext);\n \n     // Add it to allContainers list.\n     newlyAllocatedContainers.add(rmContainer);\n     liveContainers.put(container.getId(), rmContainer);    \n \n     // Update consumption and track allocations\n     List\u003cResourceRequest\u003e resourceRequestList \u003d appSchedulingInfo.allocate(\n         type, node, priority, request, container);\n     this.attemptResourceUsage.incUsed(container.getResource());\n \n     // Update resource requests related to \"request\" and store in RMContainer\n     ((RMContainerImpl) rmContainer).setResourceRequests(resourceRequestList);\n \n     // Inform the container\n     rmContainer.handle(\n         new RMContainerEvent(container.getId(), RMContainerEventType.START));\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"allocate: applicationAttemptId\u003d\" \n           + container.getId().getApplicationAttemptId() \n           + \" container\u003d\" + container.getId() + \" host\u003d\"\n           + container.getNodeId().getHost() + \" type\u003d\" + type);\n     }\n     RMAuditLogger.logSuccess(getUser(), \n         AuditConstants.ALLOC_CONTAINER, \"SchedulerApp\", \n-        getApplicationId(), container.getId());\n+        getApplicationId(), container.getId(), container.getResource());\n     \n     return rmContainer;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  synchronized public RMContainer allocate(NodeType type, FSSchedulerNode node,\n      Priority priority, ResourceRequest request,\n      Container container) {\n    // Update allowed locality level\n    NodeType allowed \u003d allowedLocalityLevel.get(priority);\n    if (allowed !\u003d null) {\n      if (allowed.equals(NodeType.OFF_SWITCH) \u0026\u0026\n          (type.equals(NodeType.NODE_LOCAL) ||\n              type.equals(NodeType.RACK_LOCAL))) {\n        this.resetAllowedLocalityLevel(priority, type);\n      }\n      else if (allowed.equals(NodeType.RACK_LOCAL) \u0026\u0026\n          type.equals(NodeType.NODE_LOCAL)) {\n        this.resetAllowedLocalityLevel(priority, type);\n      }\n    }\n\n    // Required sanity check - AM can call \u0027allocate\u0027 to update resource \n    // request without locking the scheduler, hence we need to check\n    if (getTotalRequiredResources(priority) \u003c\u003d 0) {\n      return null;\n    }\n    \n    // Create RMContainer\n    RMContainer rmContainer \u003d new RMContainerImpl(container, \n        getApplicationAttemptId(), node.getNodeID(),\n        appSchedulingInfo.getUser(), rmContext);\n\n    // Add it to allContainers list.\n    newlyAllocatedContainers.add(rmContainer);\n    liveContainers.put(container.getId(), rmContainer);    \n\n    // Update consumption and track allocations\n    List\u003cResourceRequest\u003e resourceRequestList \u003d appSchedulingInfo.allocate(\n        type, node, priority, request, container);\n    this.attemptResourceUsage.incUsed(container.getResource());\n\n    // Update resource requests related to \"request\" and store in RMContainer\n    ((RMContainerImpl) rmContainer).setResourceRequests(resourceRequestList);\n\n    // Inform the container\n    rmContainer.handle(\n        new RMContainerEvent(container.getId(), RMContainerEventType.START));\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"allocate: applicationAttemptId\u003d\" \n          + container.getId().getApplicationAttemptId() \n          + \" container\u003d\" + container.getId() + \" host\u003d\"\n          + container.getNodeId().getHost() + \" type\u003d\" + type);\n    }\n    RMAuditLogger.logSuccess(getUser(), \n        AuditConstants.ALLOC_CONTAINER, \"SchedulerApp\", \n        getApplicationId(), container.getId(), container.getResource());\n    \n    return rmContainer;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FSAppAttempt.java",
      "extendedDetails": {}
    },
    "586348e4cbf197188057d6b843a6701cfffdaff3": {
      "type": "Ybodychange",
      "commitMessage": "YARN-3356. Capacity Scheduler FiCaSchedulerApp should use ResourceUsage to track used-resources-by-label. Contributed by Wangda Tan\n",
      "commitDate": "20/03/15 1:54 PM",
      "commitName": "586348e4cbf197188057d6b843a6701cfffdaff3",
      "commitAuthor": "Jian He",
      "commitDateOld": "18/02/15 5:24 PM",
      "commitNameOld": "b8a14efdf535d42bcafa58d380bd2c7f4d36f8cb",
      "commitAuthorOld": "Tsuyoshi Ozawa",
      "daysBetweenCommits": 29.81,
      "commitsBetweenForRepo": 250,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,56 +1,56 @@\n   synchronized public RMContainer allocate(NodeType type, FSSchedulerNode node,\n       Priority priority, ResourceRequest request,\n       Container container) {\n     // Update allowed locality level\n     NodeType allowed \u003d allowedLocalityLevel.get(priority);\n     if (allowed !\u003d null) {\n       if (allowed.equals(NodeType.OFF_SWITCH) \u0026\u0026\n           (type.equals(NodeType.NODE_LOCAL) ||\n               type.equals(NodeType.RACK_LOCAL))) {\n         this.resetAllowedLocalityLevel(priority, type);\n       }\n       else if (allowed.equals(NodeType.RACK_LOCAL) \u0026\u0026\n           type.equals(NodeType.NODE_LOCAL)) {\n         this.resetAllowedLocalityLevel(priority, type);\n       }\n     }\n \n     // Required sanity check - AM can call \u0027allocate\u0027 to update resource \n     // request without locking the scheduler, hence we need to check\n     if (getTotalRequiredResources(priority) \u003c\u003d 0) {\n       return null;\n     }\n     \n     // Create RMContainer\n     RMContainer rmContainer \u003d new RMContainerImpl(container, \n         getApplicationAttemptId(), node.getNodeID(),\n         appSchedulingInfo.getUser(), rmContext);\n \n     // Add it to allContainers list.\n     newlyAllocatedContainers.add(rmContainer);\n     liveContainers.put(container.getId(), rmContainer);    \n \n     // Update consumption and track allocations\n     List\u003cResourceRequest\u003e resourceRequestList \u003d appSchedulingInfo.allocate(\n         type, node, priority, request, container);\n-    Resources.addTo(currentConsumption, container.getResource());\n+    this.attemptResourceUsage.incUsed(container.getResource());\n \n     // Update resource requests related to \"request\" and store in RMContainer\n     ((RMContainerImpl) rmContainer).setResourceRequests(resourceRequestList);\n \n     // Inform the container\n     rmContainer.handle(\n         new RMContainerEvent(container.getId(), RMContainerEventType.START));\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"allocate: applicationAttemptId\u003d\" \n           + container.getId().getApplicationAttemptId() \n           + \" container\u003d\" + container.getId() + \" host\u003d\"\n           + container.getNodeId().getHost() + \" type\u003d\" + type);\n     }\n     RMAuditLogger.logSuccess(getUser(), \n         AuditConstants.ALLOC_CONTAINER, \"SchedulerApp\", \n         getApplicationId(), container.getId());\n     \n     return rmContainer;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  synchronized public RMContainer allocate(NodeType type, FSSchedulerNode node,\n      Priority priority, ResourceRequest request,\n      Container container) {\n    // Update allowed locality level\n    NodeType allowed \u003d allowedLocalityLevel.get(priority);\n    if (allowed !\u003d null) {\n      if (allowed.equals(NodeType.OFF_SWITCH) \u0026\u0026\n          (type.equals(NodeType.NODE_LOCAL) ||\n              type.equals(NodeType.RACK_LOCAL))) {\n        this.resetAllowedLocalityLevel(priority, type);\n      }\n      else if (allowed.equals(NodeType.RACK_LOCAL) \u0026\u0026\n          type.equals(NodeType.NODE_LOCAL)) {\n        this.resetAllowedLocalityLevel(priority, type);\n      }\n    }\n\n    // Required sanity check - AM can call \u0027allocate\u0027 to update resource \n    // request without locking the scheduler, hence we need to check\n    if (getTotalRequiredResources(priority) \u003c\u003d 0) {\n      return null;\n    }\n    \n    // Create RMContainer\n    RMContainer rmContainer \u003d new RMContainerImpl(container, \n        getApplicationAttemptId(), node.getNodeID(),\n        appSchedulingInfo.getUser(), rmContext);\n\n    // Add it to allContainers list.\n    newlyAllocatedContainers.add(rmContainer);\n    liveContainers.put(container.getId(), rmContainer);    \n\n    // Update consumption and track allocations\n    List\u003cResourceRequest\u003e resourceRequestList \u003d appSchedulingInfo.allocate(\n        type, node, priority, request, container);\n    this.attemptResourceUsage.incUsed(container.getResource());\n\n    // Update resource requests related to \"request\" and store in RMContainer\n    ((RMContainerImpl) rmContainer).setResourceRequests(resourceRequestList);\n\n    // Inform the container\n    rmContainer.handle(\n        new RMContainerEvent(container.getId(), RMContainerEventType.START));\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"allocate: applicationAttemptId\u003d\" \n          + container.getId().getApplicationAttemptId() \n          + \" container\u003d\" + container.getId() + \" host\u003d\"\n          + container.getNodeId().getHost() + \" type\u003d\" + type);\n    }\n    RMAuditLogger.logSuccess(getUser(), \n        AuditConstants.ALLOC_CONTAINER, \"SchedulerApp\", \n        getApplicationId(), container.getId());\n    \n    return rmContainer;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FSAppAttempt.java",
      "extendedDetails": {}
    },
    "486e718fc1f5befd231494e2ec06bb360484f191": {
      "type": "Yintroduced",
      "commitMessage": "YARN-2399. FairScheduler: Merge AppSchedulable and FSSchedulerApp into FSAppAttempt. (kasha)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1617600 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/08/14 2:43 PM",
      "commitName": "486e718fc1f5befd231494e2ec06bb360484f191",
      "commitAuthor": "Karthik Kambatla",
      "diff": "@@ -0,0 +1,56 @@\n+  synchronized public RMContainer allocate(NodeType type, FSSchedulerNode node,\n+      Priority priority, ResourceRequest request,\n+      Container container) {\n+    // Update allowed locality level\n+    NodeType allowed \u003d allowedLocalityLevel.get(priority);\n+    if (allowed !\u003d null) {\n+      if (allowed.equals(NodeType.OFF_SWITCH) \u0026\u0026\n+          (type.equals(NodeType.NODE_LOCAL) ||\n+              type.equals(NodeType.RACK_LOCAL))) {\n+        this.resetAllowedLocalityLevel(priority, type);\n+      }\n+      else if (allowed.equals(NodeType.RACK_LOCAL) \u0026\u0026\n+          type.equals(NodeType.NODE_LOCAL)) {\n+        this.resetAllowedLocalityLevel(priority, type);\n+      }\n+    }\n+\n+    // Required sanity check - AM can call \u0027allocate\u0027 to update resource \n+    // request without locking the scheduler, hence we need to check\n+    if (getTotalRequiredResources(priority) \u003c\u003d 0) {\n+      return null;\n+    }\n+    \n+    // Create RMContainer\n+    RMContainer rmContainer \u003d new RMContainerImpl(container, \n+        getApplicationAttemptId(), node.getNodeID(),\n+        appSchedulingInfo.getUser(), rmContext);\n+\n+    // Add it to allContainers list.\n+    newlyAllocatedContainers.add(rmContainer);\n+    liveContainers.put(container.getId(), rmContainer);    \n+\n+    // Update consumption and track allocations\n+    List\u003cResourceRequest\u003e resourceRequestList \u003d appSchedulingInfo.allocate(\n+        type, node, priority, request, container);\n+    Resources.addTo(currentConsumption, container.getResource());\n+\n+    // Update resource requests related to \"request\" and store in RMContainer\n+    ((RMContainerImpl) rmContainer).setResourceRequests(resourceRequestList);\n+\n+    // Inform the container\n+    rmContainer.handle(\n+        new RMContainerEvent(container.getId(), RMContainerEventType.START));\n+\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"allocate: applicationAttemptId\u003d\" \n+          + container.getId().getApplicationAttemptId() \n+          + \" container\u003d\" + container.getId() + \" host\u003d\"\n+          + container.getNodeId().getHost() + \" type\u003d\" + type);\n+    }\n+    RMAuditLogger.logSuccess(getUser(), \n+        AuditConstants.ALLOC_CONTAINER, \"SchedulerApp\", \n+        getApplicationId(), container.getId());\n+    \n+    return rmContainer;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  synchronized public RMContainer allocate(NodeType type, FSSchedulerNode node,\n      Priority priority, ResourceRequest request,\n      Container container) {\n    // Update allowed locality level\n    NodeType allowed \u003d allowedLocalityLevel.get(priority);\n    if (allowed !\u003d null) {\n      if (allowed.equals(NodeType.OFF_SWITCH) \u0026\u0026\n          (type.equals(NodeType.NODE_LOCAL) ||\n              type.equals(NodeType.RACK_LOCAL))) {\n        this.resetAllowedLocalityLevel(priority, type);\n      }\n      else if (allowed.equals(NodeType.RACK_LOCAL) \u0026\u0026\n          type.equals(NodeType.NODE_LOCAL)) {\n        this.resetAllowedLocalityLevel(priority, type);\n      }\n    }\n\n    // Required sanity check - AM can call \u0027allocate\u0027 to update resource \n    // request without locking the scheduler, hence we need to check\n    if (getTotalRequiredResources(priority) \u003c\u003d 0) {\n      return null;\n    }\n    \n    // Create RMContainer\n    RMContainer rmContainer \u003d new RMContainerImpl(container, \n        getApplicationAttemptId(), node.getNodeID(),\n        appSchedulingInfo.getUser(), rmContext);\n\n    // Add it to allContainers list.\n    newlyAllocatedContainers.add(rmContainer);\n    liveContainers.put(container.getId(), rmContainer);    \n\n    // Update consumption and track allocations\n    List\u003cResourceRequest\u003e resourceRequestList \u003d appSchedulingInfo.allocate(\n        type, node, priority, request, container);\n    Resources.addTo(currentConsumption, container.getResource());\n\n    // Update resource requests related to \"request\" and store in RMContainer\n    ((RMContainerImpl) rmContainer).setResourceRequests(resourceRequestList);\n\n    // Inform the container\n    rmContainer.handle(\n        new RMContainerEvent(container.getId(), RMContainerEventType.START));\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"allocate: applicationAttemptId\u003d\" \n          + container.getId().getApplicationAttemptId() \n          + \" container\u003d\" + container.getId() + \" host\u003d\"\n          + container.getNodeId().getHost() + \" type\u003d\" + type);\n    }\n    RMAuditLogger.logSuccess(getUser(), \n        AuditConstants.ALLOC_CONTAINER, \"SchedulerApp\", \n        getApplicationId(), container.getId());\n    \n    return rmContainer;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FSAppAttempt.java"
    }
  }
}