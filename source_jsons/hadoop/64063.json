{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "S3ADataBlocks.java",
  "functionName": "toString",
  "functionId": "toString",
  "sourceFilePath": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ADataBlocks.java",
  "functionStartLine": 539,
  "functionEndLine": 543,
  "numCommitsSeen": 5,
  "timeTaken": 1119,
  "changeHistory": [
    "dab00da19f25619ccc71c7f803a235b21766bf1e",
    "6c348c56918973fd988b110e79231324a8befe12"
  ],
  "changeHistoryShort": {
    "dab00da19f25619ccc71c7f803a235b21766bf1e": "Ybodychange",
    "6c348c56918973fd988b110e79231324a8befe12": "Yintroduced"
  },
  "changeHistoryDetails": {
    "dab00da19f25619ccc71c7f803a235b21766bf1e": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-14028. S3A BlockOutputStreams doesn\u0027t delete temporary files in multipart uploads or handle part upload failures.\nContributed by Steve Loughran.\n\n(cherry picked from commit 29fe5af017b945d8750c074ca39031b5b777eddd)\n",
      "commitDate": "25/02/17 7:35 AM",
      "commitName": "dab00da19f25619ccc71c7f803a235b21766bf1e",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "20/02/17 8:21 AM",
      "commitNameOld": "8035749c26947dc641ef87dac041050d439a16d1",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 4.97,
      "commitsBetweenForRepo": 37,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,9 +1,10 @@\n     public String toString() {\n       String sb \u003d \"FileBlock{\"\n-          + \"destFile\u003d\" + bufferFile +\n+          + \"index\u003d\" + index\n+          + \", destFile\u003d\" + bufferFile +\n           \", state\u003d\" + getState() +\n           \", dataSize\u003d\" + dataSize() +\n           \", limit\u003d\" + limit +\n           \u0027}\u0027;\n       return sb;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public String toString() {\n      String sb \u003d \"FileBlock{\"\n          + \"index\u003d\" + index\n          + \", destFile\u003d\" + bufferFile +\n          \", state\u003d\" + getState() +\n          \", dataSize\u003d\" + dataSize() +\n          \", limit\u003d\" + limit +\n          \u0027}\u0027;\n      return sb;\n    }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ADataBlocks.java",
      "extendedDetails": {}
    },
    "6c348c56918973fd988b110e79231324a8befe12": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-13560. S3ABlockOutputStream to support huge (many GB) file writes. Contributed by Steve Loughran\n",
      "commitDate": "18/10/16 1:16 PM",
      "commitName": "6c348c56918973fd988b110e79231324a8befe12",
      "commitAuthor": "Steve Loughran",
      "diff": "@@ -0,0 +1,9 @@\n+    public String toString() {\n+      String sb \u003d \"FileBlock{\"\n+          + \"destFile\u003d\" + bufferFile +\n+          \", state\u003d\" + getState() +\n+          \", dataSize\u003d\" + dataSize() +\n+          \", limit\u003d\" + limit +\n+          \u0027}\u0027;\n+      return sb;\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    public String toString() {\n      String sb \u003d \"FileBlock{\"\n          + \"destFile\u003d\" + bufferFile +\n          \", state\u003d\" + getState() +\n          \", dataSize\u003d\" + dataSize() +\n          \", limit\u003d\" + limit +\n          \u0027}\u0027;\n      return sb;\n    }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ADataBlocks.java"
    }
  }
}