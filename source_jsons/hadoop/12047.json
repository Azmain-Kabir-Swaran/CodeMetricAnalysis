{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FsDatasetImpl.java",
  "functionName": "setupAsyncLazyPersistThreads",
  "functionId": "setupAsyncLazyPersistThreads",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
  "functionStartLine": 3138,
  "functionEndLine": 3142,
  "numCommitsSeen": 197,
  "timeTaken": 5498,
  "changeHistory": [
    "24d3a2d4fdd836ac9a5bc755a7fb9354f7a582b1",
    "a9331fe9b071fdcdae0c6c747d7b6b306142e671",
    "1efd9c98258fbb973d2058dcf0850042e53bd02f"
  ],
  "changeHistoryShort": {
    "24d3a2d4fdd836ac9a5bc755a7fb9354f7a582b1": "Ybodychange",
    "a9331fe9b071fdcdae0c6c747d7b6b306142e671": "Ybodychange",
    "1efd9c98258fbb973d2058dcf0850042e53bd02f": "Yintroduced"
  },
  "changeHistoryDetails": {
    "24d3a2d4fdd836ac9a5bc755a7fb9354f7a582b1": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7758. Retire FsDatasetSpi#getVolumes() and use FsDatasetSpi#getVolumeRefs() instead (Lei (Eddy) Xu via Colin P. McCabe)\n",
      "commitDate": "05/05/15 11:08 AM",
      "commitName": "24d3a2d4fdd836ac9a5bc755a7fb9354f7a582b1",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "02/05/15 10:03 AM",
      "commitNameOld": "6ae2a0d048e133b43249c248a75a4d77d9abb80d",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 3.05,
      "commitsBetweenForRepo": 25,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,5 +1,5 @@\n   private void setupAsyncLazyPersistThreads() {\n-    for (FsVolumeImpl v: getVolumes()){\n+    for (FsVolumeImpl v: volumes.getVolumes()){\n       setupAsyncLazyPersistThread(v);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void setupAsyncLazyPersistThreads() {\n    for (FsVolumeImpl v: volumes.getVolumes()){\n      setupAsyncLazyPersistThread(v);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "a9331fe9b071fdcdae0c6c747d7b6b306142e671": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7035. Make adding a new data directory to the DataNode an atomic operation and improve error handling (Lei Xu via Colin P. McCabe)\n",
      "commitDate": "30/10/14 5:31 PM",
      "commitName": "a9331fe9b071fdcdae0c6c747d7b6b306142e671",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "28/10/14 4:41 PM",
      "commitNameOld": "ac9ab037e9a9b03e4fa9bd471d3ab9940beb53fb",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 2.03,
      "commitsBetweenForRepo": 30,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,5 @@\n   private void setupAsyncLazyPersistThreads() {\n-    boolean ramDiskConfigured \u003d ramDiskConfigured();\n     for (FsVolumeImpl v: getVolumes()){\n-      // Skip transient volumes\n-      if (v.isTransientStorage()) {\n-        continue;\n-      }\n-\n-      // Add thread for DISK volume if RamDisk is configured\n-      if (ramDiskConfigured \u0026\u0026\n-          !asyncLazyPersistService.queryVolume(v.getCurrentDir())) {\n-        asyncLazyPersistService.addVolume(v.getCurrentDir());\n-      }\n-\n-      // Remove thread for DISK volume if RamDisk is not configured\n-      if (!ramDiskConfigured \u0026\u0026\n-          asyncLazyPersistService.queryVolume(v.getCurrentDir())) {\n-        asyncLazyPersistService.removeVolume(v.getCurrentDir());\n-      }\n+      setupAsyncLazyPersistThread(v);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void setupAsyncLazyPersistThreads() {\n    for (FsVolumeImpl v: getVolumes()){\n      setupAsyncLazyPersistThread(v);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "1efd9c98258fbb973d2058dcf0850042e53bd02f": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-7112. LazyWriter should use either async IO or one thread per physical disk. Contributed by Xiaoyu Yao.\n",
      "commitDate": "07/10/14 8:25 PM",
      "commitName": "1efd9c98258fbb973d2058dcf0850042e53bd02f",
      "commitAuthor": "cnauroth",
      "diff": "@@ -0,0 +1,21 @@\n+  private void setupAsyncLazyPersistThreads() {\n+    boolean ramDiskConfigured \u003d ramDiskConfigured();\n+    for (FsVolumeImpl v: getVolumes()){\n+      // Skip transient volumes\n+      if (v.isTransientStorage()) {\n+        continue;\n+      }\n+\n+      // Add thread for DISK volume if RamDisk is configured\n+      if (ramDiskConfigured \u0026\u0026\n+          !asyncLazyPersistService.queryVolume(v.getCurrentDir())) {\n+        asyncLazyPersistService.addVolume(v.getCurrentDir());\n+      }\n+\n+      // Remove thread for DISK volume if RamDisk is not configured\n+      if (!ramDiskConfigured \u0026\u0026\n+          asyncLazyPersistService.queryVolume(v.getCurrentDir())) {\n+        asyncLazyPersistService.removeVolume(v.getCurrentDir());\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void setupAsyncLazyPersistThreads() {\n    boolean ramDiskConfigured \u003d ramDiskConfigured();\n    for (FsVolumeImpl v: getVolumes()){\n      // Skip transient volumes\n      if (v.isTransientStorage()) {\n        continue;\n      }\n\n      // Add thread for DISK volume if RamDisk is configured\n      if (ramDiskConfigured \u0026\u0026\n          !asyncLazyPersistService.queryVolume(v.getCurrentDir())) {\n        asyncLazyPersistService.addVolume(v.getCurrentDir());\n      }\n\n      // Remove thread for DISK volume if RamDisk is not configured\n      if (!ramDiskConfigured \u0026\u0026\n          asyncLazyPersistService.queryVolume(v.getCurrentDir())) {\n        asyncLazyPersistService.removeVolume(v.getCurrentDir());\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java"
    }
  }
}