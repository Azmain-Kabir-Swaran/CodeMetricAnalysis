{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "SimpleHttpProxyHandler.java",
  "functionName": "operationComplete",
  "functionId": "operationComplete___future-ChannelFuture",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/web/SimpleHttpProxyHandler.java",
  "functionStartLine": 80,
  "functionEndLine": 87,
  "numCommitsSeen": 6,
  "timeTaken": 1947,
  "changeHistory": [
    "88da9f6b6782423acd8ab7eb7d938720de7f3c0f",
    "ada233b7cd7db39e609bb57e487fee8cec59cd48",
    "fbf81fbd1ca83c6695dee4f8b87c4b790461166b",
    "bf8e4332cb4c33d0287ae6ecca61b335402ac1c4"
  ],
  "changeHistoryShort": {
    "88da9f6b6782423acd8ab7eb7d938720de7f3c0f": "Ybodychange",
    "ada233b7cd7db39e609bb57e487fee8cec59cd48": "Ybodychange",
    "fbf81fbd1ca83c6695dee4f8b87c4b790461166b": "Ybodychange",
    "bf8e4332cb4c33d0287ae6ecca61b335402ac1c4": "Yintroduced"
  },
  "changeHistoryDetails": {
    "88da9f6b6782423acd8ab7eb7d938720de7f3c0f": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-8377. Support HTTP/2 in datanode. Contributed by Duo Zhang.\"\n\nThis reverts commit ada233b7cd7db39e609bb57e487fee8cec59cd48.\n",
      "commitDate": "26/01/17 1:42 PM",
      "commitName": "88da9f6b6782423acd8ab7eb7d938720de7f3c0f",
      "commitAuthor": "Xiao Chen",
      "commitDateOld": "24/05/15 10:30 PM",
      "commitNameOld": "ada233b7cd7db39e609bb57e487fee8cec59cd48",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 612.68,
      "commitsBetweenForRepo": 4350,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,17 @@\n       public void operationComplete(ChannelFuture future) throws Exception {\n         if (future.isSuccess()) {\n           ctx.channel().pipeline().remove(HttpResponseEncoder.class);\n           HttpRequest newReq \u003d new DefaultFullHttpRequest(HTTP_1_1,\n-            req.method(), req.uri());\n+            req.getMethod(), req.getUri());\n           newReq.headers().add(req.headers());\n-          newReq.headers().set(CONNECTION, HttpHeaderValues.CLOSE);\n+          newReq.headers().set(CONNECTION, Values.CLOSE);\n           future.channel().writeAndFlush(newReq);\n         } else {\n           DefaultHttpResponse resp \u003d new DefaultHttpResponse(HTTP_1_1,\n             INTERNAL_SERVER_ERROR);\n-          resp.headers().set(CONNECTION, HttpHeaderValues.CLOSE);\n+          resp.headers().set(CONNECTION, Values.CLOSE);\n           LOG.info(\"Proxy \" + uri + \" failed. Cause: \", future.cause());\n           ctx.writeAndFlush(resp).addListener(ChannelFutureListener.CLOSE);\n           client.close();\n         }\n       }\n\\ No newline at end of file\n",
      "actualSource": "      public void operationComplete(ChannelFuture future) throws Exception {\n        if (future.isSuccess()) {\n          ctx.channel().pipeline().remove(HttpResponseEncoder.class);\n          HttpRequest newReq \u003d new DefaultFullHttpRequest(HTTP_1_1,\n            req.getMethod(), req.getUri());\n          newReq.headers().add(req.headers());\n          newReq.headers().set(CONNECTION, Values.CLOSE);\n          future.channel().writeAndFlush(newReq);\n        } else {\n          DefaultHttpResponse resp \u003d new DefaultHttpResponse(HTTP_1_1,\n            INTERNAL_SERVER_ERROR);\n          resp.headers().set(CONNECTION, Values.CLOSE);\n          LOG.info(\"Proxy \" + uri + \" failed. Cause: \", future.cause());\n          ctx.writeAndFlush(resp).addListener(ChannelFutureListener.CLOSE);\n          client.close();\n        }\n      }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/web/SimpleHttpProxyHandler.java",
      "extendedDetails": {}
    },
    "ada233b7cd7db39e609bb57e487fee8cec59cd48": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8377. Support HTTP/2 in datanode. Contributed by Duo Zhang.\n",
      "commitDate": "24/05/15 10:30 PM",
      "commitName": "ada233b7cd7db39e609bb57e487fee8cec59cd48",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "18/11/14 2:52 PM",
      "commitNameOld": "fbf81fbd1ca83c6695dee4f8b87c4b790461166b",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 187.28,
      "commitsBetweenForRepo": 1557,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,17 @@\n       public void operationComplete(ChannelFuture future) throws Exception {\n         if (future.isSuccess()) {\n           ctx.channel().pipeline().remove(HttpResponseEncoder.class);\n           HttpRequest newReq \u003d new DefaultFullHttpRequest(HTTP_1_1,\n-            req.getMethod(), req.getUri());\n+            req.method(), req.uri());\n           newReq.headers().add(req.headers());\n-          newReq.headers().set(CONNECTION, Values.CLOSE);\n+          newReq.headers().set(CONNECTION, HttpHeaderValues.CLOSE);\n           future.channel().writeAndFlush(newReq);\n         } else {\n           DefaultHttpResponse resp \u003d new DefaultHttpResponse(HTTP_1_1,\n             INTERNAL_SERVER_ERROR);\n-          resp.headers().set(CONNECTION, Values.CLOSE);\n+          resp.headers().set(CONNECTION, HttpHeaderValues.CLOSE);\n           LOG.info(\"Proxy \" + uri + \" failed. Cause: \", future.cause());\n           ctx.writeAndFlush(resp).addListener(ChannelFutureListener.CLOSE);\n           client.close();\n         }\n       }\n\\ No newline at end of file\n",
      "actualSource": "      public void operationComplete(ChannelFuture future) throws Exception {\n        if (future.isSuccess()) {\n          ctx.channel().pipeline().remove(HttpResponseEncoder.class);\n          HttpRequest newReq \u003d new DefaultFullHttpRequest(HTTP_1_1,\n            req.method(), req.uri());\n          newReq.headers().add(req.headers());\n          newReq.headers().set(CONNECTION, HttpHeaderValues.CLOSE);\n          future.channel().writeAndFlush(newReq);\n        } else {\n          DefaultHttpResponse resp \u003d new DefaultHttpResponse(HTTP_1_1,\n            INTERNAL_SERVER_ERROR);\n          resp.headers().set(CONNECTION, HttpHeaderValues.CLOSE);\n          LOG.info(\"Proxy \" + uri + \" failed. Cause: \", future.cause());\n          ctx.writeAndFlush(resp).addListener(ChannelFutureListener.CLOSE);\n          client.close();\n        }\n      }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/web/SimpleHttpProxyHandler.java",
      "extendedDetails": {}
    },
    "fbf81fbd1ca83c6695dee4f8b87c4b790461166b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7406. SimpleHttpProxyHandler puts incorrect \"Connection: Close\" header. Contributed by Haohui Mai.\n",
      "commitDate": "18/11/14 2:52 PM",
      "commitName": "fbf81fbd1ca83c6695dee4f8b87c4b790461166b",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "17/11/14 11:42 AM",
      "commitNameOld": "bf8e4332cb4c33d0287ae6ecca61b335402ac1c4",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 1.13,
      "commitsBetweenForRepo": 12,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,17 @@\n       public void operationComplete(ChannelFuture future) throws Exception {\n         if (future.isSuccess()) {\n           ctx.channel().pipeline().remove(HttpResponseEncoder.class);\n           HttpRequest newReq \u003d new DefaultFullHttpRequest(HTTP_1_1,\n             req.getMethod(), req.getUri());\n           newReq.headers().add(req.headers());\n-          newReq.headers().set(CONNECTION, CLOSE);\n+          newReq.headers().set(CONNECTION, Values.CLOSE);\n           future.channel().writeAndFlush(newReq);\n         } else {\n           DefaultHttpResponse resp \u003d new DefaultHttpResponse(HTTP_1_1,\n             INTERNAL_SERVER_ERROR);\n-          resp.headers().set(CONNECTION, CLOSE);\n+          resp.headers().set(CONNECTION, Values.CLOSE);\n           LOG.info(\"Proxy \" + uri + \" failed. Cause: \", future.cause());\n           ctx.writeAndFlush(resp).addListener(ChannelFutureListener.CLOSE);\n           client.close();\n         }\n       }\n\\ No newline at end of file\n",
      "actualSource": "      public void operationComplete(ChannelFuture future) throws Exception {\n        if (future.isSuccess()) {\n          ctx.channel().pipeline().remove(HttpResponseEncoder.class);\n          HttpRequest newReq \u003d new DefaultFullHttpRequest(HTTP_1_1,\n            req.getMethod(), req.getUri());\n          newReq.headers().add(req.headers());\n          newReq.headers().set(CONNECTION, Values.CLOSE);\n          future.channel().writeAndFlush(newReq);\n        } else {\n          DefaultHttpResponse resp \u003d new DefaultHttpResponse(HTTP_1_1,\n            INTERNAL_SERVER_ERROR);\n          resp.headers().set(CONNECTION, Values.CLOSE);\n          LOG.info(\"Proxy \" + uri + \" failed. Cause: \", future.cause());\n          ctx.writeAndFlush(resp).addListener(ChannelFutureListener.CLOSE);\n          client.close();\n        }\n      }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/web/SimpleHttpProxyHandler.java",
      "extendedDetails": {}
    },
    "bf8e4332cb4c33d0287ae6ecca61b335402ac1c4": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-7279. Use netty to implement DatanodeWebHdfsMethods. Contributed by Haohui Mai.\n",
      "commitDate": "17/11/14 11:42 AM",
      "commitName": "bf8e4332cb4c33d0287ae6ecca61b335402ac1c4",
      "commitAuthor": "Haohui Mai",
      "diff": "@@ -0,0 +1,17 @@\n+      public void operationComplete(ChannelFuture future) throws Exception {\n+        if (future.isSuccess()) {\n+          ctx.channel().pipeline().remove(HttpResponseEncoder.class);\n+          HttpRequest newReq \u003d new DefaultFullHttpRequest(HTTP_1_1,\n+            req.getMethod(), req.getUri());\n+          newReq.headers().add(req.headers());\n+          newReq.headers().set(CONNECTION, CLOSE);\n+          future.channel().writeAndFlush(newReq);\n+        } else {\n+          DefaultHttpResponse resp \u003d new DefaultHttpResponse(HTTP_1_1,\n+            INTERNAL_SERVER_ERROR);\n+          resp.headers().set(CONNECTION, CLOSE);\n+          LOG.info(\"Proxy \" + uri + \" failed. Cause: \", future.cause());\n+          ctx.writeAndFlush(resp).addListener(ChannelFutureListener.CLOSE);\n+          client.close();\n+        }\n+      }\n\\ No newline at end of file\n",
      "actualSource": "      public void operationComplete(ChannelFuture future) throws Exception {\n        if (future.isSuccess()) {\n          ctx.channel().pipeline().remove(HttpResponseEncoder.class);\n          HttpRequest newReq \u003d new DefaultFullHttpRequest(HTTP_1_1,\n            req.getMethod(), req.getUri());\n          newReq.headers().add(req.headers());\n          newReq.headers().set(CONNECTION, CLOSE);\n          future.channel().writeAndFlush(newReq);\n        } else {\n          DefaultHttpResponse resp \u003d new DefaultHttpResponse(HTTP_1_1,\n            INTERNAL_SERVER_ERROR);\n          resp.headers().set(CONNECTION, CLOSE);\n          LOG.info(\"Proxy \" + uri + \" failed. Cause: \", future.cause());\n          ctx.writeAndFlush(resp).addListener(ChannelFutureListener.CLOSE);\n          client.close();\n        }\n      }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/web/SimpleHttpProxyHandler.java"
    }
  }
}