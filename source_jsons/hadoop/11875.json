{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "PmemMappableBlockLoader.java",
  "functionName": "initialize",
  "functionId": "initialize___dnConf-DNConf",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/PmemMappableBlockLoader.java",
  "functionStartLine": 47,
  "functionEndLine": 59,
  "numCommitsSeen": 10,
  "timeTaken": 5335,
  "changeHistory": [
    "d79cce20abbbf321f6dcce03f4087544124a7cd2",
    "e98adb00b7da8fa913b86ecf2049444b1d8617d4",
    "d1aad444907e1fc5314e8e64529e57c51ed7561c",
    "9b0aace1e6c54f201784912c0b623707aa82b761",
    "35ff31dd9462cf4fb4ebf5556ee8ae6bcd7c5c3a"
  ],
  "changeHistoryShort": {
    "d79cce20abbbf321f6dcce03f4087544124a7cd2": "Ybodychange",
    "e98adb00b7da8fa913b86ecf2049444b1d8617d4": "Ymultichange(Yparameterchange,Yreturntypechange,Ybodychange)",
    "d1aad444907e1fc5314e8e64529e57c51ed7561c": "Ybodychange",
    "9b0aace1e6c54f201784912c0b623707aa82b761": "Ybodychange",
    "35ff31dd9462cf4fb4ebf5556ee8ae6bcd7c5c3a": "Yintroduced"
  },
  "changeHistoryDetails": {
    "d79cce20abbbf321f6dcce03f4087544124a7cd2": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14740. Recover data blocks from persistent memory read cache during datanode restarts. Contributed by Feilong He.\n",
      "commitDate": "01/01/20 10:14 PM",
      "commitName": "d79cce20abbbf321f6dcce03f4087544124a7cd2",
      "commitAuthor": "Rakesh Radhakrishnan",
      "commitDateOld": "15/07/19 12:32 AM",
      "commitNameOld": "e98adb00b7da8fa913b86ecf2049444b1d8617d4",
      "commitAuthorOld": "Rakesh Radhakrishnan",
      "daysBetweenCommits": 170.95,
      "commitsBetweenForRepo": 1070,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,11 +1,13 @@\n   CacheStats initialize(DNConf dnConf) throws IOException {\n     LOG.info(\"Initializing cache loader: \" + this.getClass().getName());\n-    PmemVolumeManager.init(dnConf.getPmemVolumes());\n+    PmemVolumeManager.init(dnConf.getPmemVolumes(),\n+        dnConf.getPmemCacheRecoveryEnabled());\n     pmemVolumeManager \u003d PmemVolumeManager.getInstance();\n+    cacheRecoveryEnabled \u003d dnConf.getPmemCacheRecoveryEnabled();\n     // The configuration for max locked memory is shaded.\n     LOG.info(\"Persistent memory is used for caching data instead of \" +\n         \"DRAM. Max locked memory is set to zero to disable DRAM cache\");\n     // TODO: PMem is not supporting Lazy Writer now, will refine this stats\n     // while implementing it.\n     return new CacheStats(0L);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  CacheStats initialize(DNConf dnConf) throws IOException {\n    LOG.info(\"Initializing cache loader: \" + this.getClass().getName());\n    PmemVolumeManager.init(dnConf.getPmemVolumes(),\n        dnConf.getPmemCacheRecoveryEnabled());\n    pmemVolumeManager \u003d PmemVolumeManager.getInstance();\n    cacheRecoveryEnabled \u003d dnConf.getPmemCacheRecoveryEnabled();\n    // The configuration for max locked memory is shaded.\n    LOG.info(\"Persistent memory is used for caching data instead of \" +\n        \"DRAM. Max locked memory is set to zero to disable DRAM cache\");\n    // TODO: PMem is not supporting Lazy Writer now, will refine this stats\n    // while implementing it.\n    return new CacheStats(0L);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/PmemMappableBlockLoader.java",
      "extendedDetails": {}
    },
    "e98adb00b7da8fa913b86ecf2049444b1d8617d4": {
      "type": "Ymultichange(Yparameterchange,Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-14458. Report pmem stats to namenode. Contributed by Feilong He.\n",
      "commitDate": "15/07/19 12:32 AM",
      "commitName": "e98adb00b7da8fa913b86ecf2049444b1d8617d4",
      "commitAuthor": "Rakesh Radhakrishnan",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-14458. Report pmem stats to namenode. Contributed by Feilong He.\n",
          "commitDate": "15/07/19 12:32 AM",
          "commitName": "e98adb00b7da8fa913b86ecf2049444b1d8617d4",
          "commitAuthor": "Rakesh Radhakrishnan",
          "commitDateOld": "05/06/19 6:33 AM",
          "commitNameOld": "d1aad444907e1fc5314e8e64529e57c51ed7561c",
          "commitAuthorOld": "Sammi Chen",
          "daysBetweenCommits": 39.75,
          "commitsBetweenForRepo": 327,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,6 +1,11 @@\n-  void initialize(FsDatasetCache cacheManager) throws IOException {\n+  CacheStats initialize(DNConf dnConf) throws IOException {\n     LOG.info(\"Initializing cache loader: \" + this.getClass().getName());\n-    DNConf dnConf \u003d cacheManager.getDnConf();\n     PmemVolumeManager.init(dnConf.getPmemVolumes());\n     pmemVolumeManager \u003d PmemVolumeManager.getInstance();\n+    // The configuration for max locked memory is shaded.\n+    LOG.info(\"Persistent memory is used for caching data instead of \" +\n+        \"DRAM. Max locked memory is set to zero to disable DRAM cache\");\n+    // TODO: PMem is not supporting Lazy Writer now, will refine this stats\n+    // while implementing it.\n+    return new CacheStats(0L);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  CacheStats initialize(DNConf dnConf) throws IOException {\n    LOG.info(\"Initializing cache loader: \" + this.getClass().getName());\n    PmemVolumeManager.init(dnConf.getPmemVolumes());\n    pmemVolumeManager \u003d PmemVolumeManager.getInstance();\n    // The configuration for max locked memory is shaded.\n    LOG.info(\"Persistent memory is used for caching data instead of \" +\n        \"DRAM. Max locked memory is set to zero to disable DRAM cache\");\n    // TODO: PMem is not supporting Lazy Writer now, will refine this stats\n    // while implementing it.\n    return new CacheStats(0L);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/PmemMappableBlockLoader.java",
          "extendedDetails": {
            "oldValue": "[cacheManager-FsDatasetCache]",
            "newValue": "[dnConf-DNConf]"
          }
        },
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-14458. Report pmem stats to namenode. Contributed by Feilong He.\n",
          "commitDate": "15/07/19 12:32 AM",
          "commitName": "e98adb00b7da8fa913b86ecf2049444b1d8617d4",
          "commitAuthor": "Rakesh Radhakrishnan",
          "commitDateOld": "05/06/19 6:33 AM",
          "commitNameOld": "d1aad444907e1fc5314e8e64529e57c51ed7561c",
          "commitAuthorOld": "Sammi Chen",
          "daysBetweenCommits": 39.75,
          "commitsBetweenForRepo": 327,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,6 +1,11 @@\n-  void initialize(FsDatasetCache cacheManager) throws IOException {\n+  CacheStats initialize(DNConf dnConf) throws IOException {\n     LOG.info(\"Initializing cache loader: \" + this.getClass().getName());\n-    DNConf dnConf \u003d cacheManager.getDnConf();\n     PmemVolumeManager.init(dnConf.getPmemVolumes());\n     pmemVolumeManager \u003d PmemVolumeManager.getInstance();\n+    // The configuration for max locked memory is shaded.\n+    LOG.info(\"Persistent memory is used for caching data instead of \" +\n+        \"DRAM. Max locked memory is set to zero to disable DRAM cache\");\n+    // TODO: PMem is not supporting Lazy Writer now, will refine this stats\n+    // while implementing it.\n+    return new CacheStats(0L);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  CacheStats initialize(DNConf dnConf) throws IOException {\n    LOG.info(\"Initializing cache loader: \" + this.getClass().getName());\n    PmemVolumeManager.init(dnConf.getPmemVolumes());\n    pmemVolumeManager \u003d PmemVolumeManager.getInstance();\n    // The configuration for max locked memory is shaded.\n    LOG.info(\"Persistent memory is used for caching data instead of \" +\n        \"DRAM. Max locked memory is set to zero to disable DRAM cache\");\n    // TODO: PMem is not supporting Lazy Writer now, will refine this stats\n    // while implementing it.\n    return new CacheStats(0L);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/PmemMappableBlockLoader.java",
          "extendedDetails": {
            "oldValue": "void",
            "newValue": "CacheStats"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-14458. Report pmem stats to namenode. Contributed by Feilong He.\n",
          "commitDate": "15/07/19 12:32 AM",
          "commitName": "e98adb00b7da8fa913b86ecf2049444b1d8617d4",
          "commitAuthor": "Rakesh Radhakrishnan",
          "commitDateOld": "05/06/19 6:33 AM",
          "commitNameOld": "d1aad444907e1fc5314e8e64529e57c51ed7561c",
          "commitAuthorOld": "Sammi Chen",
          "daysBetweenCommits": 39.75,
          "commitsBetweenForRepo": 327,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,6 +1,11 @@\n-  void initialize(FsDatasetCache cacheManager) throws IOException {\n+  CacheStats initialize(DNConf dnConf) throws IOException {\n     LOG.info(\"Initializing cache loader: \" + this.getClass().getName());\n-    DNConf dnConf \u003d cacheManager.getDnConf();\n     PmemVolumeManager.init(dnConf.getPmemVolumes());\n     pmemVolumeManager \u003d PmemVolumeManager.getInstance();\n+    // The configuration for max locked memory is shaded.\n+    LOG.info(\"Persistent memory is used for caching data instead of \" +\n+        \"DRAM. Max locked memory is set to zero to disable DRAM cache\");\n+    // TODO: PMem is not supporting Lazy Writer now, will refine this stats\n+    // while implementing it.\n+    return new CacheStats(0L);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  CacheStats initialize(DNConf dnConf) throws IOException {\n    LOG.info(\"Initializing cache loader: \" + this.getClass().getName());\n    PmemVolumeManager.init(dnConf.getPmemVolumes());\n    pmemVolumeManager \u003d PmemVolumeManager.getInstance();\n    // The configuration for max locked memory is shaded.\n    LOG.info(\"Persistent memory is used for caching data instead of \" +\n        \"DRAM. Max locked memory is set to zero to disable DRAM cache\");\n    // TODO: PMem is not supporting Lazy Writer now, will refine this stats\n    // while implementing it.\n    return new CacheStats(0L);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/PmemMappableBlockLoader.java",
          "extendedDetails": {}
        }
      ]
    },
    "d1aad444907e1fc5314e8e64529e57c51ed7561c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14356. Implement HDFS cache on SCM with native PMDK libs. Contributed by Feilong He.\n",
      "commitDate": "05/06/19 6:33 AM",
      "commitName": "d1aad444907e1fc5314e8e64529e57c51ed7561c",
      "commitAuthor": "Sammi Chen",
      "commitDateOld": "26/05/19 2:00 AM",
      "commitNameOld": "37900c5639f8ba8d41b9fedc3d41ee0fbda7d5db",
      "commitAuthorOld": "Rakesh Radhakrishnan",
      "daysBetweenCommits": 10.19,
      "commitsBetweenForRepo": 84,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,6 +1,6 @@\n   void initialize(FsDatasetCache cacheManager) throws IOException {\n-    LOG.info(\"Initializing cache loader: PmemMappableBlockLoader.\");\n+    LOG.info(\"Initializing cache loader: \" + this.getClass().getName());\n     DNConf dnConf \u003d cacheManager.getDnConf();\n     PmemVolumeManager.init(dnConf.getPmemVolumes());\n     pmemVolumeManager \u003d PmemVolumeManager.getInstance();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void initialize(FsDatasetCache cacheManager) throws IOException {\n    LOG.info(\"Initializing cache loader: \" + this.getClass().getName());\n    DNConf dnConf \u003d cacheManager.getDnConf();\n    PmemVolumeManager.init(dnConf.getPmemVolumes());\n    pmemVolumeManager \u003d PmemVolumeManager.getInstance();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/PmemMappableBlockLoader.java",
      "extendedDetails": {}
    },
    "9b0aace1e6c54f201784912c0b623707aa82b761": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14401. Refine the implementation for HDFS cache on SCM. Contributed by Feilong He.\n",
      "commitDate": "08/05/19 4:50 AM",
      "commitName": "9b0aace1e6c54f201784912c0b623707aa82b761",
      "commitAuthor": "Rakesh Radhakrishnan",
      "commitDateOld": "30/03/19 11:33 PM",
      "commitNameOld": "35ff31dd9462cf4fb4ebf5556ee8ae6bcd7c5c3a",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 38.22,
      "commitsBetweenForRepo": 236,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,5 +1,6 @@\n   void initialize(FsDatasetCache cacheManager) throws IOException {\n+    LOG.info(\"Initializing cache loader: PmemMappableBlockLoader.\");\n     DNConf dnConf \u003d cacheManager.getDnConf();\n-    this.pmemVolumeManager \u003d new PmemVolumeManager(dnConf.getMaxLockedPmem(),\n-        dnConf.getPmemVolumes());\n+    PmemVolumeManager.init(dnConf.getPmemVolumes());\n+    pmemVolumeManager \u003d PmemVolumeManager.getInstance();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void initialize(FsDatasetCache cacheManager) throws IOException {\n    LOG.info(\"Initializing cache loader: PmemMappableBlockLoader.\");\n    DNConf dnConf \u003d cacheManager.getDnConf();\n    PmemVolumeManager.init(dnConf.getPmemVolumes());\n    pmemVolumeManager \u003d PmemVolumeManager.getInstance();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/PmemMappableBlockLoader.java",
      "extendedDetails": {}
    },
    "35ff31dd9462cf4fb4ebf5556ee8ae6bcd7c5c3a": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-14355 : Implement HDFS cache on SCM by using pure java mapped byte buffer. Contributed by Feilong He.\n",
      "commitDate": "30/03/19 11:33 PM",
      "commitName": "35ff31dd9462cf4fb4ebf5556ee8ae6bcd7c5c3a",
      "commitAuthor": "Uma Maheswara Rao G",
      "diff": "@@ -0,0 +1,5 @@\n+  void initialize(FsDatasetCache cacheManager) throws IOException {\n+    DNConf dnConf \u003d cacheManager.getDnConf();\n+    this.pmemVolumeManager \u003d new PmemVolumeManager(dnConf.getMaxLockedPmem(),\n+        dnConf.getPmemVolumes());\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  void initialize(FsDatasetCache cacheManager) throws IOException {\n    DNConf dnConf \u003d cacheManager.getDnConf();\n    this.pmemVolumeManager \u003d new PmemVolumeManager(dnConf.getMaxLockedPmem(),\n        dnConf.getPmemVolumes());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/PmemMappableBlockLoader.java"
    }
  }
}