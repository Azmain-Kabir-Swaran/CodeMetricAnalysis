{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DFSClient.java",
  "functionName": "newConnectedPeer",
  "functionId": "newConnectedPeer___addr-InetSocketAddress__blockToken-Token__BlockTokenIdentifier____datanodeId-DatanodeID",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSClient.java",
  "functionStartLine": 3007,
  "functionEndLine": 3028,
  "numCommitsSeen": 534,
  "timeTaken": 10648,
  "changeHistory": [
    "eca1a4bfe952fc184fe90dde50bac9b0e5293568",
    "37e23ce45c592f3c9c48a08a52a5f46787f6c0e9",
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c",
    "ed78b14ebc9a21bb57ccd088e8b49bfa457a396f",
    "1d74ccececaefffaa90c0c18b40a3645dbc819d9",
    "2cc9514ad643ae49d30524743420ee9744e571bd",
    "6a84f88c1190a8fecadd81deb6e7b8a69675fa91",
    "3b54223c0f32d42a84436c670d80b791a8e9696d",
    "beb0d25d2a7ba5004c6aabd105546ba9a9fec9be",
    "d12f465c674b3bb5102671b6d6c2746261602d7e",
    "9a4030e0e84a688c12daa21fe9a165808c3eca70",
    "c9db06f2e4d1c1f71f021d5070323f9fc194cdd7"
  ],
  "changeHistoryShort": {
    "eca1a4bfe952fc184fe90dde50bac9b0e5293568": "Ybodychange",
    "37e23ce45c592f3c9c48a08a52a5f46787f6c0e9": "Ybodychange",
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c": "Ymultichange(Yfilerename,Ybodychange)",
    "ed78b14ebc9a21bb57ccd088e8b49bfa457a396f": "Ybodychange",
    "1d74ccececaefffaa90c0c18b40a3645dbc819d9": "Ybodychange",
    "2cc9514ad643ae49d30524743420ee9744e571bd": "Ybodychange",
    "6a84f88c1190a8fecadd81deb6e7b8a69675fa91": "Ybodychange",
    "3b54223c0f32d42a84436c670d80b791a8e9696d": "Ymultichange(Yparameterchange,Ybodychange)",
    "beb0d25d2a7ba5004c6aabd105546ba9a9fec9be": "Ymultichange(Ymovefromfile,Ymodifierchange,Ybodychange,Yrename)",
    "d12f465c674b3bb5102671b6d6c2746261602d7e": "Ymultichange(Yrename,Ybodychange)",
    "9a4030e0e84a688c12daa21fe9a165808c3eca70": "Ybodychange",
    "c9db06f2e4d1c1f71f021d5070323f9fc194cdd7": "Yintroduced"
  },
  "changeHistoryDetails": {
    "eca1a4bfe952fc184fe90dde50bac9b0e5293568": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13695. Move logging to slf4j in HDFS package. Contributed by Ian Pickering.\n",
      "commitDate": "06/09/18 2:48 PM",
      "commitName": "eca1a4bfe952fc184fe90dde50bac9b0e5293568",
      "commitAuthor": "Giovanni Matteo Fumarola",
      "commitDateOld": "03/09/18 10:37 PM",
      "commitNameOld": "6e5ffb74dd678ddc3392ae2f251c80fc5cc8c62f",
      "commitAuthorOld": "Kitti Nanasi",
      "daysBetweenCommits": 2.67,
      "commitsBetweenForRepo": 23,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,22 @@\n   public Peer newConnectedPeer(InetSocketAddress addr,\n       Token\u003cBlockTokenIdentifier\u003e blockToken, DatanodeID datanodeId)\n       throws IOException {\n     Peer peer \u003d null;\n     boolean success \u003d false;\n     Socket sock \u003d null;\n     final int socketTimeout \u003d dfsClientConf.getSocketTimeout();\n     try {\n       sock \u003d socketFactory.createSocket();\n       NetUtils.connect(sock, addr, getRandomLocalInterfaceAddr(),\n           socketTimeout);\n       peer \u003d DFSUtilClient.peerFromSocketAndKey(saslClient, sock, this,\n           blockToken, datanodeId, socketTimeout);\n       success \u003d true;\n       return peer;\n     } finally {\n       if (!success) {\n-        IOUtilsClient.cleanup(LOG, peer);\n+        IOUtilsClient.cleanupWithLogger(LOG, peer);\n         IOUtils.closeSocket(sock);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public Peer newConnectedPeer(InetSocketAddress addr,\n      Token\u003cBlockTokenIdentifier\u003e blockToken, DatanodeID datanodeId)\n      throws IOException {\n    Peer peer \u003d null;\n    boolean success \u003d false;\n    Socket sock \u003d null;\n    final int socketTimeout \u003d dfsClientConf.getSocketTimeout();\n    try {\n      sock \u003d socketFactory.createSocket();\n      NetUtils.connect(sock, addr, getRandomLocalInterfaceAddr(),\n          socketTimeout);\n      peer \u003d DFSUtilClient.peerFromSocketAndKey(saslClient, sock, this,\n          blockToken, datanodeId, socketTimeout);\n      success \u003d true;\n      return peer;\n    } finally {\n      if (!success) {\n        IOUtilsClient.cleanupWithLogger(LOG, peer);\n        IOUtils.closeSocket(sock);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSClient.java",
      "extendedDetails": {}
    },
    "37e23ce45c592f3c9c48a08a52a5f46787f6c0e9": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10223. peerFromSocketAndKey performs SASL exchange before setting connection timeouts (cmccabe)\n",
      "commitDate": "30/03/16 1:37 PM",
      "commitName": "37e23ce45c592f3c9c48a08a52a5f46787f6c0e9",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "26/03/16 7:58 PM",
      "commitNameOld": "3a4ff7776e8fab6cc87932b9aa8fb48f7b69c720",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 3.74,
      "commitsBetweenForRepo": 27,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,22 @@\n   public Peer newConnectedPeer(InetSocketAddress addr,\n       Token\u003cBlockTokenIdentifier\u003e blockToken, DatanodeID datanodeId)\n       throws IOException {\n     Peer peer \u003d null;\n     boolean success \u003d false;\n     Socket sock \u003d null;\n     final int socketTimeout \u003d dfsClientConf.getSocketTimeout();\n     try {\n       sock \u003d socketFactory.createSocket();\n       NetUtils.connect(sock, addr, getRandomLocalInterfaceAddr(),\n           socketTimeout);\n       peer \u003d DFSUtilClient.peerFromSocketAndKey(saslClient, sock, this,\n-          blockToken, datanodeId);\n-      peer.setReadTimeout(socketTimeout);\n-      peer.setWriteTimeout(socketTimeout);\n+          blockToken, datanodeId, socketTimeout);\n       success \u003d true;\n       return peer;\n     } finally {\n       if (!success) {\n         IOUtilsClient.cleanup(LOG, peer);\n         IOUtils.closeSocket(sock);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public Peer newConnectedPeer(InetSocketAddress addr,\n      Token\u003cBlockTokenIdentifier\u003e blockToken, DatanodeID datanodeId)\n      throws IOException {\n    Peer peer \u003d null;\n    boolean success \u003d false;\n    Socket sock \u003d null;\n    final int socketTimeout \u003d dfsClientConf.getSocketTimeout();\n    try {\n      sock \u003d socketFactory.createSocket();\n      NetUtils.connect(sock, addr, getRandomLocalInterfaceAddr(),\n          socketTimeout);\n      peer \u003d DFSUtilClient.peerFromSocketAndKey(saslClient, sock, this,\n          blockToken, datanodeId, socketTimeout);\n      success \u003d true;\n      return peer;\n    } finally {\n      if (!success) {\n        IOUtilsClient.cleanup(LOG, peer);\n        IOUtils.closeSocket(sock);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSClient.java",
      "extendedDetails": {}
    },
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c": {
      "type": "Ymultichange(Yfilerename,Ybodychange)",
      "commitMessage": "HDFS-8053. Move DFSIn/OutputStream and related classes to hadoop-hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "26/09/15 11:08 AM",
      "commitName": "bf37d3d80e5179dea27e5bd5aea804a38aa9934c",
      "commitAuthor": "Haohui Mai",
      "subchanges": [
        {
          "type": "Yfilerename",
          "commitMessage": "HDFS-8053. Move DFSIn/OutputStream and related classes to hadoop-hdfs-client. Contributed by Mingliang Liu.\n",
          "commitDate": "26/09/15 11:08 AM",
          "commitName": "bf37d3d80e5179dea27e5bd5aea804a38aa9934c",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "26/09/15 9:06 AM",
          "commitNameOld": "861b52db242f238d7e36ad75c158025be959a696",
          "commitAuthorOld": "Vinayakumar B",
          "daysBetweenCommits": 0.08,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,23 +1,23 @@\n   public Peer newConnectedPeer(InetSocketAddress addr,\n       Token\u003cBlockTokenIdentifier\u003e blockToken, DatanodeID datanodeId)\n       throws IOException {\n     Peer peer \u003d null;\n     boolean success \u003d false;\n     Socket sock \u003d null;\n     final int socketTimeout \u003d dfsClientConf.getSocketTimeout(); \n     try {\n       sock \u003d socketFactory.createSocket();\n       NetUtils.connect(sock, addr, getRandomLocalInterfaceAddr(), socketTimeout);\n       peer \u003d DFSUtilClient.peerFromSocketAndKey(saslClient, sock, this,\n           blockToken, datanodeId);\n       peer.setReadTimeout(socketTimeout);\n       peer.setWriteTimeout(socketTimeout);\n       success \u003d true;\n       return peer;\n     } finally {\n       if (!success) {\n-        IOUtils.cleanup(LOG, peer);\n+        IOUtilsClient.cleanup(LOG, peer);\n         IOUtils.closeSocket(sock);\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public Peer newConnectedPeer(InetSocketAddress addr,\n      Token\u003cBlockTokenIdentifier\u003e blockToken, DatanodeID datanodeId)\n      throws IOException {\n    Peer peer \u003d null;\n    boolean success \u003d false;\n    Socket sock \u003d null;\n    final int socketTimeout \u003d dfsClientConf.getSocketTimeout(); \n    try {\n      sock \u003d socketFactory.createSocket();\n      NetUtils.connect(sock, addr, getRandomLocalInterfaceAddr(), socketTimeout);\n      peer \u003d DFSUtilClient.peerFromSocketAndKey(saslClient, sock, this,\n          blockToken, datanodeId);\n      peer.setReadTimeout(socketTimeout);\n      peer.setWriteTimeout(socketTimeout);\n      success \u003d true;\n      return peer;\n    } finally {\n      if (!success) {\n        IOUtilsClient.cleanup(LOG, peer);\n        IOUtils.closeSocket(sock);\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSClient.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSClient.java"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-8053. Move DFSIn/OutputStream and related classes to hadoop-hdfs-client. Contributed by Mingliang Liu.\n",
          "commitDate": "26/09/15 11:08 AM",
          "commitName": "bf37d3d80e5179dea27e5bd5aea804a38aa9934c",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "26/09/15 9:06 AM",
          "commitNameOld": "861b52db242f238d7e36ad75c158025be959a696",
          "commitAuthorOld": "Vinayakumar B",
          "daysBetweenCommits": 0.08,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,23 +1,23 @@\n   public Peer newConnectedPeer(InetSocketAddress addr,\n       Token\u003cBlockTokenIdentifier\u003e blockToken, DatanodeID datanodeId)\n       throws IOException {\n     Peer peer \u003d null;\n     boolean success \u003d false;\n     Socket sock \u003d null;\n     final int socketTimeout \u003d dfsClientConf.getSocketTimeout(); \n     try {\n       sock \u003d socketFactory.createSocket();\n       NetUtils.connect(sock, addr, getRandomLocalInterfaceAddr(), socketTimeout);\n       peer \u003d DFSUtilClient.peerFromSocketAndKey(saslClient, sock, this,\n           blockToken, datanodeId);\n       peer.setReadTimeout(socketTimeout);\n       peer.setWriteTimeout(socketTimeout);\n       success \u003d true;\n       return peer;\n     } finally {\n       if (!success) {\n-        IOUtils.cleanup(LOG, peer);\n+        IOUtilsClient.cleanup(LOG, peer);\n         IOUtils.closeSocket(sock);\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public Peer newConnectedPeer(InetSocketAddress addr,\n      Token\u003cBlockTokenIdentifier\u003e blockToken, DatanodeID datanodeId)\n      throws IOException {\n    Peer peer \u003d null;\n    boolean success \u003d false;\n    Socket sock \u003d null;\n    final int socketTimeout \u003d dfsClientConf.getSocketTimeout(); \n    try {\n      sock \u003d socketFactory.createSocket();\n      NetUtils.connect(sock, addr, getRandomLocalInterfaceAddr(), socketTimeout);\n      peer \u003d DFSUtilClient.peerFromSocketAndKey(saslClient, sock, this,\n          blockToken, datanodeId);\n      peer.setReadTimeout(socketTimeout);\n      peer.setWriteTimeout(socketTimeout);\n      success \u003d true;\n      return peer;\n    } finally {\n      if (!success) {\n        IOUtilsClient.cleanup(LOG, peer);\n        IOUtils.closeSocket(sock);\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSClient.java",
          "extendedDetails": {}
        }
      ]
    },
    "ed78b14ebc9a21bb57ccd088e8b49bfa457a396f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9002. Move o.a.h.hdfs.net/*Peer classes to hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "03/09/15 3:32 PM",
      "commitName": "ed78b14ebc9a21bb57ccd088e8b49bfa457a396f",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "31/08/15 1:54 PM",
      "commitNameOld": "826ae1c26d31f87d88efc920b271bec7eec2e17a",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 3.07,
      "commitsBetweenForRepo": 31,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,23 @@\n   public Peer newConnectedPeer(InetSocketAddress addr,\n       Token\u003cBlockTokenIdentifier\u003e blockToken, DatanodeID datanodeId)\n       throws IOException {\n     Peer peer \u003d null;\n     boolean success \u003d false;\n     Socket sock \u003d null;\n     final int socketTimeout \u003d dfsClientConf.getSocketTimeout(); \n     try {\n       sock \u003d socketFactory.createSocket();\n       NetUtils.connect(sock, addr, getRandomLocalInterfaceAddr(), socketTimeout);\n-      peer \u003d TcpPeerServer.peerFromSocketAndKey(saslClient, sock, this,\n+      peer \u003d DFSUtilClient.peerFromSocketAndKey(saslClient, sock, this,\n           blockToken, datanodeId);\n       peer.setReadTimeout(socketTimeout);\n       peer.setWriteTimeout(socketTimeout);\n       success \u003d true;\n       return peer;\n     } finally {\n       if (!success) {\n         IOUtils.cleanup(LOG, peer);\n         IOUtils.closeSocket(sock);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public Peer newConnectedPeer(InetSocketAddress addr,\n      Token\u003cBlockTokenIdentifier\u003e blockToken, DatanodeID datanodeId)\n      throws IOException {\n    Peer peer \u003d null;\n    boolean success \u003d false;\n    Socket sock \u003d null;\n    final int socketTimeout \u003d dfsClientConf.getSocketTimeout(); \n    try {\n      sock \u003d socketFactory.createSocket();\n      NetUtils.connect(sock, addr, getRandomLocalInterfaceAddr(), socketTimeout);\n      peer \u003d DFSUtilClient.peerFromSocketAndKey(saslClient, sock, this,\n          blockToken, datanodeId);\n      peer.setReadTimeout(socketTimeout);\n      peer.setWriteTimeout(socketTimeout);\n      success \u003d true;\n      return peer;\n    } finally {\n      if (!success) {\n        IOUtils.cleanup(LOG, peer);\n        IOUtils.closeSocket(sock);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java",
      "extendedDetails": {}
    },
    "1d74ccececaefffaa90c0c18b40a3645dbc819d9": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7608: hdfs dfsclient newConnectedPeer has no write timeout (Xiaoyu Yao via Colin P. McCabe)\n",
      "commitDate": "14/07/15 10:57 AM",
      "commitName": "1d74ccececaefffaa90c0c18b40a3645dbc819d9",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "02/07/15 3:41 AM",
      "commitNameOld": "bff5999d07e9416a22846c849487e509ede55040",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 12.3,
      "commitsBetweenForRepo": 60,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,23 @@\n   public Peer newConnectedPeer(InetSocketAddress addr,\n       Token\u003cBlockTokenIdentifier\u003e blockToken, DatanodeID datanodeId)\n       throws IOException {\n     Peer peer \u003d null;\n     boolean success \u003d false;\n     Socket sock \u003d null;\n     final int socketTimeout \u003d dfsClientConf.getSocketTimeout(); \n     try {\n       sock \u003d socketFactory.createSocket();\n       NetUtils.connect(sock, addr, getRandomLocalInterfaceAddr(), socketTimeout);\n       peer \u003d TcpPeerServer.peerFromSocketAndKey(saslClient, sock, this,\n           blockToken, datanodeId);\n       peer.setReadTimeout(socketTimeout);\n+      peer.setWriteTimeout(socketTimeout);\n       success \u003d true;\n       return peer;\n     } finally {\n       if (!success) {\n         IOUtils.cleanup(LOG, peer);\n         IOUtils.closeSocket(sock);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public Peer newConnectedPeer(InetSocketAddress addr,\n      Token\u003cBlockTokenIdentifier\u003e blockToken, DatanodeID datanodeId)\n      throws IOException {\n    Peer peer \u003d null;\n    boolean success \u003d false;\n    Socket sock \u003d null;\n    final int socketTimeout \u003d dfsClientConf.getSocketTimeout(); \n    try {\n      sock \u003d socketFactory.createSocket();\n      NetUtils.connect(sock, addr, getRandomLocalInterfaceAddr(), socketTimeout);\n      peer \u003d TcpPeerServer.peerFromSocketAndKey(saslClient, sock, this,\n          blockToken, datanodeId);\n      peer.setReadTimeout(socketTimeout);\n      peer.setWriteTimeout(socketTimeout);\n      success \u003d true;\n      return peer;\n    } finally {\n      if (!success) {\n        IOUtils.cleanup(LOG, peer);\n        IOUtils.closeSocket(sock);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java",
      "extendedDetails": {}
    },
    "2cc9514ad643ae49d30524743420ee9744e571bd": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8100. Refactor DFSClient.Conf to a standalone class and separates short-circuit related conf to ShortCircuitConf.\n",
      "commitDate": "10/04/15 2:48 PM",
      "commitName": "2cc9514ad643ae49d30524743420ee9744e571bd",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "10/04/15 11:40 AM",
      "commitNameOld": "7660da95cb67cbfe034aa8fa2a5bf0f8c9fdf41a",
      "commitAuthorOld": "Arun Suresh",
      "daysBetweenCommits": 0.13,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,22 @@\n   public Peer newConnectedPeer(InetSocketAddress addr,\n       Token\u003cBlockTokenIdentifier\u003e blockToken, DatanodeID datanodeId)\n       throws IOException {\n     Peer peer \u003d null;\n     boolean success \u003d false;\n     Socket sock \u003d null;\n+    final int socketTimeout \u003d dfsClientConf.getSocketTimeout(); \n     try {\n       sock \u003d socketFactory.createSocket();\n-      NetUtils.connect(sock, addr,\n-        getRandomLocalInterfaceAddr(),\n-        dfsClientConf.socketTimeout);\n+      NetUtils.connect(sock, addr, getRandomLocalInterfaceAddr(), socketTimeout);\n       peer \u003d TcpPeerServer.peerFromSocketAndKey(saslClient, sock, this,\n           blockToken, datanodeId);\n-      peer.setReadTimeout(dfsClientConf.socketTimeout);\n+      peer.setReadTimeout(socketTimeout);\n       success \u003d true;\n       return peer;\n     } finally {\n       if (!success) {\n         IOUtils.cleanup(LOG, peer);\n         IOUtils.closeSocket(sock);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public Peer newConnectedPeer(InetSocketAddress addr,\n      Token\u003cBlockTokenIdentifier\u003e blockToken, DatanodeID datanodeId)\n      throws IOException {\n    Peer peer \u003d null;\n    boolean success \u003d false;\n    Socket sock \u003d null;\n    final int socketTimeout \u003d dfsClientConf.getSocketTimeout(); \n    try {\n      sock \u003d socketFactory.createSocket();\n      NetUtils.connect(sock, addr, getRandomLocalInterfaceAddr(), socketTimeout);\n      peer \u003d TcpPeerServer.peerFromSocketAndKey(saslClient, sock, this,\n          blockToken, datanodeId);\n      peer.setReadTimeout(socketTimeout);\n      success \u003d true;\n      return peer;\n    } finally {\n      if (!success) {\n        IOUtils.cleanup(LOG, peer);\n        IOUtils.closeSocket(sock);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java",
      "extendedDetails": {}
    },
    "6a84f88c1190a8fecadd81deb6e7b8a69675fa91": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7005. DFS input streams do not timeout. Contributed by Daryn Sharp.\n",
      "commitDate": "08/09/14 12:41 PM",
      "commitName": "6a84f88c1190a8fecadd81deb6e7b8a69675fa91",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "05/09/14 10:33 PM",
      "commitNameOld": "3b35f81603bbfae119762b50bcb46de70a421368",
      "commitAuthorOld": "Alejandro Abdelnur",
      "daysBetweenCommits": 2.59,
      "commitsBetweenForRepo": 11,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,23 @@\n   public Peer newConnectedPeer(InetSocketAddress addr,\n       Token\u003cBlockTokenIdentifier\u003e blockToken, DatanodeID datanodeId)\n       throws IOException {\n     Peer peer \u003d null;\n     boolean success \u003d false;\n     Socket sock \u003d null;\n     try {\n       sock \u003d socketFactory.createSocket();\n       NetUtils.connect(sock, addr,\n         getRandomLocalInterfaceAddr(),\n         dfsClientConf.socketTimeout);\n       peer \u003d TcpPeerServer.peerFromSocketAndKey(saslClient, sock, this,\n           blockToken, datanodeId);\n+      peer.setReadTimeout(dfsClientConf.socketTimeout);\n       success \u003d true;\n       return peer;\n     } finally {\n       if (!success) {\n         IOUtils.cleanup(LOG, peer);\n         IOUtils.closeSocket(sock);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public Peer newConnectedPeer(InetSocketAddress addr,\n      Token\u003cBlockTokenIdentifier\u003e blockToken, DatanodeID datanodeId)\n      throws IOException {\n    Peer peer \u003d null;\n    boolean success \u003d false;\n    Socket sock \u003d null;\n    try {\n      sock \u003d socketFactory.createSocket();\n      NetUtils.connect(sock, addr,\n        getRandomLocalInterfaceAddr(),\n        dfsClientConf.socketTimeout);\n      peer \u003d TcpPeerServer.peerFromSocketAndKey(saslClient, sock, this,\n          blockToken, datanodeId);\n      peer.setReadTimeout(dfsClientConf.socketTimeout);\n      success \u003d true;\n      return peer;\n    } finally {\n      if (!success) {\n        IOUtils.cleanup(LOG, peer);\n        IOUtils.closeSocket(sock);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java",
      "extendedDetails": {}
    },
    "3b54223c0f32d42a84436c670d80b791a8e9696d": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-2856. Fix block protocol so that Datanodes don\u0027t require root or jsvc. Contributed by Chris Nauroth.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1610474 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/07/14 11:10 AM",
      "commitName": "3b54223c0f32d42a84436c670d80b791a8e9696d",
      "commitAuthor": "Chris Nauroth",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-2856. Fix block protocol so that Datanodes don\u0027t require root or jsvc. Contributed by Chris Nauroth.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1610474 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "14/07/14 11:10 AM",
          "commitName": "3b54223c0f32d42a84436c670d80b791a8e9696d",
          "commitAuthor": "Chris Nauroth",
          "commitDateOld": "30/05/14 5:12 PM",
          "commitNameOld": "880a0c673c74a128a01c72b60695f05327f5e961",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 44.75,
          "commitsBetweenForRepo": 266,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,20 +1,22 @@\n-  public Peer newConnectedPeer(InetSocketAddress addr) throws IOException {\n+  public Peer newConnectedPeer(InetSocketAddress addr,\n+      Token\u003cBlockTokenIdentifier\u003e blockToken, DatanodeID datanodeId)\n+      throws IOException {\n     Peer peer \u003d null;\n     boolean success \u003d false;\n     Socket sock \u003d null;\n     try {\n       sock \u003d socketFactory.createSocket();\n       NetUtils.connect(sock, addr,\n         getRandomLocalInterfaceAddr(),\n         dfsClientConf.socketTimeout);\n-      peer \u003d TcpPeerServer.peerFromSocketAndKey(sock, \n-          getDataEncryptionKey());\n+      peer \u003d TcpPeerServer.peerFromSocketAndKey(saslClient, sock, this,\n+          blockToken, datanodeId);\n       success \u003d true;\n       return peer;\n     } finally {\n       if (!success) {\n         IOUtils.cleanup(LOG, peer);\n         IOUtils.closeSocket(sock);\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public Peer newConnectedPeer(InetSocketAddress addr,\n      Token\u003cBlockTokenIdentifier\u003e blockToken, DatanodeID datanodeId)\n      throws IOException {\n    Peer peer \u003d null;\n    boolean success \u003d false;\n    Socket sock \u003d null;\n    try {\n      sock \u003d socketFactory.createSocket();\n      NetUtils.connect(sock, addr,\n        getRandomLocalInterfaceAddr(),\n        dfsClientConf.socketTimeout);\n      peer \u003d TcpPeerServer.peerFromSocketAndKey(saslClient, sock, this,\n          blockToken, datanodeId);\n      success \u003d true;\n      return peer;\n    } finally {\n      if (!success) {\n        IOUtils.cleanup(LOG, peer);\n        IOUtils.closeSocket(sock);\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java",
          "extendedDetails": {
            "oldValue": "[addr-InetSocketAddress]",
            "newValue": "[addr-InetSocketAddress, blockToken-Token\u003cBlockTokenIdentifier\u003e, datanodeId-DatanodeID]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-2856. Fix block protocol so that Datanodes don\u0027t require root or jsvc. Contributed by Chris Nauroth.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1610474 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "14/07/14 11:10 AM",
          "commitName": "3b54223c0f32d42a84436c670d80b791a8e9696d",
          "commitAuthor": "Chris Nauroth",
          "commitDateOld": "30/05/14 5:12 PM",
          "commitNameOld": "880a0c673c74a128a01c72b60695f05327f5e961",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 44.75,
          "commitsBetweenForRepo": 266,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,20 +1,22 @@\n-  public Peer newConnectedPeer(InetSocketAddress addr) throws IOException {\n+  public Peer newConnectedPeer(InetSocketAddress addr,\n+      Token\u003cBlockTokenIdentifier\u003e blockToken, DatanodeID datanodeId)\n+      throws IOException {\n     Peer peer \u003d null;\n     boolean success \u003d false;\n     Socket sock \u003d null;\n     try {\n       sock \u003d socketFactory.createSocket();\n       NetUtils.connect(sock, addr,\n         getRandomLocalInterfaceAddr(),\n         dfsClientConf.socketTimeout);\n-      peer \u003d TcpPeerServer.peerFromSocketAndKey(sock, \n-          getDataEncryptionKey());\n+      peer \u003d TcpPeerServer.peerFromSocketAndKey(saslClient, sock, this,\n+          blockToken, datanodeId);\n       success \u003d true;\n       return peer;\n     } finally {\n       if (!success) {\n         IOUtils.cleanup(LOG, peer);\n         IOUtils.closeSocket(sock);\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public Peer newConnectedPeer(InetSocketAddress addr,\n      Token\u003cBlockTokenIdentifier\u003e blockToken, DatanodeID datanodeId)\n      throws IOException {\n    Peer peer \u003d null;\n    boolean success \u003d false;\n    Socket sock \u003d null;\n    try {\n      sock \u003d socketFactory.createSocket();\n      NetUtils.connect(sock, addr,\n        getRandomLocalInterfaceAddr(),\n        dfsClientConf.socketTimeout);\n      peer \u003d TcpPeerServer.peerFromSocketAndKey(saslClient, sock, this,\n          blockToken, datanodeId);\n      success \u003d true;\n      return peer;\n    } finally {\n      if (!success) {\n        IOUtils.cleanup(LOG, peer);\n        IOUtils.closeSocket(sock);\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java",
          "extendedDetails": {}
        }
      ]
    },
    "beb0d25d2a7ba5004c6aabd105546ba9a9fec9be": {
      "type": "Ymultichange(Ymovefromfile,Ymodifierchange,Ybodychange,Yrename)",
      "commitMessage": "HDFS-5810. Unify mmap cache and short-circuit file descriptor cache (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1567720 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/02/14 11:08 AM",
      "commitName": "beb0d25d2a7ba5004c6aabd105546ba9a9fec9be",
      "commitAuthor": "Colin McCabe",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-5810. Unify mmap cache and short-circuit file descriptor cache (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1567720 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "12/02/14 11:08 AM",
          "commitName": "beb0d25d2a7ba5004c6aabd105546ba9a9fec9be",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "12/02/14 10:02 AM",
          "commitNameOld": "5efc9978ddf35f8f4e194e34a102a729dae69992",
          "commitAuthorOld": "Suresh Srinivas",
          "daysBetweenCommits": 0.05,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,20 +1,20 @@\n-  private Peer newTcpPeer(InetSocketAddress addr) throws IOException {\n+  public Peer newConnectedPeer(InetSocketAddress addr) throws IOException {\n     Peer peer \u003d null;\n     boolean success \u003d false;\n     Socket sock \u003d null;\n     try {\n-      sock \u003d dfsClient.socketFactory.createSocket();\n+      sock \u003d socketFactory.createSocket();\n       NetUtils.connect(sock, addr,\n-        dfsClient.getRandomLocalInterfaceAddr(),\n-        dfsClient.getConf().socketTimeout);\n+        getRandomLocalInterfaceAddr(),\n+        dfsClientConf.socketTimeout);\n       peer \u003d TcpPeerServer.peerFromSocketAndKey(sock, \n-          dfsClient.getDataEncryptionKey());\n+          getDataEncryptionKey());\n       success \u003d true;\n       return peer;\n     } finally {\n       if (!success) {\n-        IOUtils.closeQuietly(peer);\n-        IOUtils.closeQuietly(sock);\n+        IOUtils.cleanup(LOG, peer);\n+        IOUtils.closeSocket(sock);\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public Peer newConnectedPeer(InetSocketAddress addr) throws IOException {\n    Peer peer \u003d null;\n    boolean success \u003d false;\n    Socket sock \u003d null;\n    try {\n      sock \u003d socketFactory.createSocket();\n      NetUtils.connect(sock, addr,\n        getRandomLocalInterfaceAddr(),\n        dfsClientConf.socketTimeout);\n      peer \u003d TcpPeerServer.peerFromSocketAndKey(sock, \n          getDataEncryptionKey());\n      success \u003d true;\n      return peer;\n    } finally {\n      if (!success) {\n        IOUtils.cleanup(LOG, peer);\n        IOUtils.closeSocket(sock);\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java",
            "oldMethodName": "newTcpPeer",
            "newMethodName": "newConnectedPeer"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-5810. Unify mmap cache and short-circuit file descriptor cache (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1567720 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "12/02/14 11:08 AM",
          "commitName": "beb0d25d2a7ba5004c6aabd105546ba9a9fec9be",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "12/02/14 10:02 AM",
          "commitNameOld": "5efc9978ddf35f8f4e194e34a102a729dae69992",
          "commitAuthorOld": "Suresh Srinivas",
          "daysBetweenCommits": 0.05,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,20 +1,20 @@\n-  private Peer newTcpPeer(InetSocketAddress addr) throws IOException {\n+  public Peer newConnectedPeer(InetSocketAddress addr) throws IOException {\n     Peer peer \u003d null;\n     boolean success \u003d false;\n     Socket sock \u003d null;\n     try {\n-      sock \u003d dfsClient.socketFactory.createSocket();\n+      sock \u003d socketFactory.createSocket();\n       NetUtils.connect(sock, addr,\n-        dfsClient.getRandomLocalInterfaceAddr(),\n-        dfsClient.getConf().socketTimeout);\n+        getRandomLocalInterfaceAddr(),\n+        dfsClientConf.socketTimeout);\n       peer \u003d TcpPeerServer.peerFromSocketAndKey(sock, \n-          dfsClient.getDataEncryptionKey());\n+          getDataEncryptionKey());\n       success \u003d true;\n       return peer;\n     } finally {\n       if (!success) {\n-        IOUtils.closeQuietly(peer);\n-        IOUtils.closeQuietly(sock);\n+        IOUtils.cleanup(LOG, peer);\n+        IOUtils.closeSocket(sock);\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public Peer newConnectedPeer(InetSocketAddress addr) throws IOException {\n    Peer peer \u003d null;\n    boolean success \u003d false;\n    Socket sock \u003d null;\n    try {\n      sock \u003d socketFactory.createSocket();\n      NetUtils.connect(sock, addr,\n        getRandomLocalInterfaceAddr(),\n        dfsClientConf.socketTimeout);\n      peer \u003d TcpPeerServer.peerFromSocketAndKey(sock, \n          getDataEncryptionKey());\n      success \u003d true;\n      return peer;\n    } finally {\n      if (!success) {\n        IOUtils.cleanup(LOG, peer);\n        IOUtils.closeSocket(sock);\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java",
          "extendedDetails": {
            "oldValue": "[private]",
            "newValue": "[public]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5810. Unify mmap cache and short-circuit file descriptor cache (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1567720 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "12/02/14 11:08 AM",
          "commitName": "beb0d25d2a7ba5004c6aabd105546ba9a9fec9be",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "12/02/14 10:02 AM",
          "commitNameOld": "5efc9978ddf35f8f4e194e34a102a729dae69992",
          "commitAuthorOld": "Suresh Srinivas",
          "daysBetweenCommits": 0.05,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,20 +1,20 @@\n-  private Peer newTcpPeer(InetSocketAddress addr) throws IOException {\n+  public Peer newConnectedPeer(InetSocketAddress addr) throws IOException {\n     Peer peer \u003d null;\n     boolean success \u003d false;\n     Socket sock \u003d null;\n     try {\n-      sock \u003d dfsClient.socketFactory.createSocket();\n+      sock \u003d socketFactory.createSocket();\n       NetUtils.connect(sock, addr,\n-        dfsClient.getRandomLocalInterfaceAddr(),\n-        dfsClient.getConf().socketTimeout);\n+        getRandomLocalInterfaceAddr(),\n+        dfsClientConf.socketTimeout);\n       peer \u003d TcpPeerServer.peerFromSocketAndKey(sock, \n-          dfsClient.getDataEncryptionKey());\n+          getDataEncryptionKey());\n       success \u003d true;\n       return peer;\n     } finally {\n       if (!success) {\n-        IOUtils.closeQuietly(peer);\n-        IOUtils.closeQuietly(sock);\n+        IOUtils.cleanup(LOG, peer);\n+        IOUtils.closeSocket(sock);\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public Peer newConnectedPeer(InetSocketAddress addr) throws IOException {\n    Peer peer \u003d null;\n    boolean success \u003d false;\n    Socket sock \u003d null;\n    try {\n      sock \u003d socketFactory.createSocket();\n      NetUtils.connect(sock, addr,\n        getRandomLocalInterfaceAddr(),\n        dfsClientConf.socketTimeout);\n      peer \u003d TcpPeerServer.peerFromSocketAndKey(sock, \n          getDataEncryptionKey());\n      success \u003d true;\n      return peer;\n    } finally {\n      if (!success) {\n        IOUtils.cleanup(LOG, peer);\n        IOUtils.closeSocket(sock);\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java",
          "extendedDetails": {}
        },
        {
          "type": "Yrename",
          "commitMessage": "HDFS-5810. Unify mmap cache and short-circuit file descriptor cache (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1567720 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "12/02/14 11:08 AM",
          "commitName": "beb0d25d2a7ba5004c6aabd105546ba9a9fec9be",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "12/02/14 10:02 AM",
          "commitNameOld": "5efc9978ddf35f8f4e194e34a102a729dae69992",
          "commitAuthorOld": "Suresh Srinivas",
          "daysBetweenCommits": 0.05,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,20 +1,20 @@\n-  private Peer newTcpPeer(InetSocketAddress addr) throws IOException {\n+  public Peer newConnectedPeer(InetSocketAddress addr) throws IOException {\n     Peer peer \u003d null;\n     boolean success \u003d false;\n     Socket sock \u003d null;\n     try {\n-      sock \u003d dfsClient.socketFactory.createSocket();\n+      sock \u003d socketFactory.createSocket();\n       NetUtils.connect(sock, addr,\n-        dfsClient.getRandomLocalInterfaceAddr(),\n-        dfsClient.getConf().socketTimeout);\n+        getRandomLocalInterfaceAddr(),\n+        dfsClientConf.socketTimeout);\n       peer \u003d TcpPeerServer.peerFromSocketAndKey(sock, \n-          dfsClient.getDataEncryptionKey());\n+          getDataEncryptionKey());\n       success \u003d true;\n       return peer;\n     } finally {\n       if (!success) {\n-        IOUtils.closeQuietly(peer);\n-        IOUtils.closeQuietly(sock);\n+        IOUtils.cleanup(LOG, peer);\n+        IOUtils.closeSocket(sock);\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public Peer newConnectedPeer(InetSocketAddress addr) throws IOException {\n    Peer peer \u003d null;\n    boolean success \u003d false;\n    Socket sock \u003d null;\n    try {\n      sock \u003d socketFactory.createSocket();\n      NetUtils.connect(sock, addr,\n        getRandomLocalInterfaceAddr(),\n        dfsClientConf.socketTimeout);\n      peer \u003d TcpPeerServer.peerFromSocketAndKey(sock, \n          getDataEncryptionKey());\n      success \u003d true;\n      return peer;\n    } finally {\n      if (!success) {\n        IOUtils.cleanup(LOG, peer);\n        IOUtils.closeSocket(sock);\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java",
          "extendedDetails": {
            "oldValue": "newTcpPeer",
            "newValue": "newConnectedPeer"
          }
        }
      ]
    },
    "d12f465c674b3bb5102671b6d6c2746261602d7e": {
      "type": "Ymultichange(Yrename,Ybodychange)",
      "commitMessage": "HDFS-4417. Fix case where local reads get disabled incorrectly. Contributed by Colin Patrick McCabe.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-347@1437616 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "23/01/13 10:38 AM",
      "commitName": "d12f465c674b3bb5102671b6d6c2746261602d7e",
      "commitAuthor": "Todd Lipcon",
      "subchanges": [
        {
          "type": "Yrename",
          "commitMessage": "HDFS-4417. Fix case where local reads get disabled incorrectly. Contributed by Colin Patrick McCabe.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-347@1437616 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "23/01/13 10:38 AM",
          "commitName": "d12f465c674b3bb5102671b6d6c2746261602d7e",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "14/01/13 1:34 PM",
          "commitNameOld": "d08b1af26a56b096c7087b46a3ccd4417f4cc7ef",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 8.88,
          "commitsBetweenForRepo": 12,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,30 +1,20 @@\n-  private Peer newPeer(InetSocketAddress addr) throws IOException {\n+  private Peer newTcpPeer(InetSocketAddress addr) throws IOException {\n     Peer peer \u003d null;\n     boolean success \u003d false;\n     Socket sock \u003d null;\n-    DomainSocket domSock \u003d null;\n-\n     try {\n-      domSock \u003d dfsClient.getDomainSocketFactory().create(addr, this);\n-      if (domSock !\u003d null) {\n-        // Create a UNIX Domain peer.\n-        peer \u003d new DomainPeer(domSock);\n-      } else {\n-        // Create a conventional TCP-based Peer.\n-        sock \u003d dfsClient.socketFactory.createSocket();\n-        NetUtils.connect(sock, addr,\n-          dfsClient.getRandomLocalInterfaceAddr(),\n-          dfsClient.getConf().socketTimeout);\n-        peer \u003d TcpPeerServer.peerFromSocketAndKey(sock, \n-            dfsClient.getDataEncryptionKey());\n-      }\n+      sock \u003d dfsClient.socketFactory.createSocket();\n+      NetUtils.connect(sock, addr,\n+        dfsClient.getRandomLocalInterfaceAddr(),\n+        dfsClient.getConf().socketTimeout);\n+      peer \u003d TcpPeerServer.peerFromSocketAndKey(sock, \n+          dfsClient.getDataEncryptionKey());\n       success \u003d true;\n       return peer;\n     } finally {\n       if (!success) {\n         IOUtils.closeQuietly(peer);\n         IOUtils.closeQuietly(sock);\n-        IOUtils.closeQuietly(domSock);\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private Peer newTcpPeer(InetSocketAddress addr) throws IOException {\n    Peer peer \u003d null;\n    boolean success \u003d false;\n    Socket sock \u003d null;\n    try {\n      sock \u003d dfsClient.socketFactory.createSocket();\n      NetUtils.connect(sock, addr,\n        dfsClient.getRandomLocalInterfaceAddr(),\n        dfsClient.getConf().socketTimeout);\n      peer \u003d TcpPeerServer.peerFromSocketAndKey(sock, \n          dfsClient.getDataEncryptionKey());\n      success \u003d true;\n      return peer;\n    } finally {\n      if (!success) {\n        IOUtils.closeQuietly(peer);\n        IOUtils.closeQuietly(sock);\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
          "extendedDetails": {
            "oldValue": "newPeer",
            "newValue": "newTcpPeer"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-4417. Fix case where local reads get disabled incorrectly. Contributed by Colin Patrick McCabe.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-347@1437616 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "23/01/13 10:38 AM",
          "commitName": "d12f465c674b3bb5102671b6d6c2746261602d7e",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "14/01/13 1:34 PM",
          "commitNameOld": "d08b1af26a56b096c7087b46a3ccd4417f4cc7ef",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 8.88,
          "commitsBetweenForRepo": 12,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,30 +1,20 @@\n-  private Peer newPeer(InetSocketAddress addr) throws IOException {\n+  private Peer newTcpPeer(InetSocketAddress addr) throws IOException {\n     Peer peer \u003d null;\n     boolean success \u003d false;\n     Socket sock \u003d null;\n-    DomainSocket domSock \u003d null;\n-\n     try {\n-      domSock \u003d dfsClient.getDomainSocketFactory().create(addr, this);\n-      if (domSock !\u003d null) {\n-        // Create a UNIX Domain peer.\n-        peer \u003d new DomainPeer(domSock);\n-      } else {\n-        // Create a conventional TCP-based Peer.\n-        sock \u003d dfsClient.socketFactory.createSocket();\n-        NetUtils.connect(sock, addr,\n-          dfsClient.getRandomLocalInterfaceAddr(),\n-          dfsClient.getConf().socketTimeout);\n-        peer \u003d TcpPeerServer.peerFromSocketAndKey(sock, \n-            dfsClient.getDataEncryptionKey());\n-      }\n+      sock \u003d dfsClient.socketFactory.createSocket();\n+      NetUtils.connect(sock, addr,\n+        dfsClient.getRandomLocalInterfaceAddr(),\n+        dfsClient.getConf().socketTimeout);\n+      peer \u003d TcpPeerServer.peerFromSocketAndKey(sock, \n+          dfsClient.getDataEncryptionKey());\n       success \u003d true;\n       return peer;\n     } finally {\n       if (!success) {\n         IOUtils.closeQuietly(peer);\n         IOUtils.closeQuietly(sock);\n-        IOUtils.closeQuietly(domSock);\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private Peer newTcpPeer(InetSocketAddress addr) throws IOException {\n    Peer peer \u003d null;\n    boolean success \u003d false;\n    Socket sock \u003d null;\n    try {\n      sock \u003d dfsClient.socketFactory.createSocket();\n      NetUtils.connect(sock, addr,\n        dfsClient.getRandomLocalInterfaceAddr(),\n        dfsClient.getConf().socketTimeout);\n      peer \u003d TcpPeerServer.peerFromSocketAndKey(sock, \n          dfsClient.getDataEncryptionKey());\n      success \u003d true;\n      return peer;\n    } finally {\n      if (!success) {\n        IOUtils.closeQuietly(peer);\n        IOUtils.closeQuietly(sock);\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
          "extendedDetails": {}
        }
      ]
    },
    "9a4030e0e84a688c12daa21fe9a165808c3eca70": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4356. BlockReaderLocal should use passed file descriptors rather than paths. Contributed by Colin Patrick McCabe.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-347@1432335 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/01/13 3:52 PM",
      "commitName": "9a4030e0e84a688c12daa21fe9a165808c3eca70",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "09/01/13 1:34 PM",
      "commitNameOld": "c9db06f2e4d1c1f71f021d5070323f9fc194cdd7",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 2.1,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,30 @@\n   private Peer newPeer(InetSocketAddress addr) throws IOException {\n     Peer peer \u003d null;\n     boolean success \u003d false;\n     Socket sock \u003d null;\n+    DomainSocket domSock \u003d null;\n+\n     try {\n-      sock \u003d dfsClient.socketFactory.createSocket();\n-      NetUtils.connect(sock, addr,\n-        dfsClient.getRandomLocalInterfaceAddr(),\n-        dfsClient.getConf().socketTimeout);\n-      peer \u003d TcpPeerServer.peerFromSocketAndKey(sock, \n-          dfsClient.getDataEncryptionKey());\n+      domSock \u003d dfsClient.getDomainSocketFactory().create(addr, this);\n+      if (domSock !\u003d null) {\n+        // Create a UNIX Domain peer.\n+        peer \u003d new DomainPeer(domSock);\n+      } else {\n+        // Create a conventional TCP-based Peer.\n+        sock \u003d dfsClient.socketFactory.createSocket();\n+        NetUtils.connect(sock, addr,\n+          dfsClient.getRandomLocalInterfaceAddr(),\n+          dfsClient.getConf().socketTimeout);\n+        peer \u003d TcpPeerServer.peerFromSocketAndKey(sock, \n+            dfsClient.getDataEncryptionKey());\n+      }\n       success \u003d true;\n       return peer;\n     } finally {\n       if (!success) {\n         IOUtils.closeQuietly(peer);\n         IOUtils.closeQuietly(sock);\n+        IOUtils.closeQuietly(domSock);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private Peer newPeer(InetSocketAddress addr) throws IOException {\n    Peer peer \u003d null;\n    boolean success \u003d false;\n    Socket sock \u003d null;\n    DomainSocket domSock \u003d null;\n\n    try {\n      domSock \u003d dfsClient.getDomainSocketFactory().create(addr, this);\n      if (domSock !\u003d null) {\n        // Create a UNIX Domain peer.\n        peer \u003d new DomainPeer(domSock);\n      } else {\n        // Create a conventional TCP-based Peer.\n        sock \u003d dfsClient.socketFactory.createSocket();\n        NetUtils.connect(sock, addr,\n          dfsClient.getRandomLocalInterfaceAddr(),\n          dfsClient.getConf().socketTimeout);\n        peer \u003d TcpPeerServer.peerFromSocketAndKey(sock, \n            dfsClient.getDataEncryptionKey());\n      }\n      success \u003d true;\n      return peer;\n    } finally {\n      if (!success) {\n        IOUtils.closeQuietly(peer);\n        IOUtils.closeQuietly(sock);\n        IOUtils.closeQuietly(domSock);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "c9db06f2e4d1c1f71f021d5070323f9fc194cdd7": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-4353. Encapsulate connections to peers in Peer and PeerServer classes. Contributed by Colin Patrick McCabe.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-347@1431097 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/01/13 1:34 PM",
      "commitName": "c9db06f2e4d1c1f71f021d5070323f9fc194cdd7",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,20 @@\n+  private Peer newPeer(InetSocketAddress addr) throws IOException {\n+    Peer peer \u003d null;\n+    boolean success \u003d false;\n+    Socket sock \u003d null;\n+    try {\n+      sock \u003d dfsClient.socketFactory.createSocket();\n+      NetUtils.connect(sock, addr,\n+        dfsClient.getRandomLocalInterfaceAddr(),\n+        dfsClient.getConf().socketTimeout);\n+      peer \u003d TcpPeerServer.peerFromSocketAndKey(sock, \n+          dfsClient.getDataEncryptionKey());\n+      success \u003d true;\n+      return peer;\n+    } finally {\n+      if (!success) {\n+        IOUtils.closeQuietly(peer);\n+        IOUtils.closeQuietly(sock);\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private Peer newPeer(InetSocketAddress addr) throws IOException {\n    Peer peer \u003d null;\n    boolean success \u003d false;\n    Socket sock \u003d null;\n    try {\n      sock \u003d dfsClient.socketFactory.createSocket();\n      NetUtils.connect(sock, addr,\n        dfsClient.getRandomLocalInterfaceAddr(),\n        dfsClient.getConf().socketTimeout);\n      peer \u003d TcpPeerServer.peerFromSocketAndKey(sock, \n          dfsClient.getDataEncryptionKey());\n      success \u003d true;\n      return peer;\n    } finally {\n      if (!success) {\n        IOUtils.closeQuietly(peer);\n        IOUtils.closeQuietly(sock);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java"
    }
  }
}