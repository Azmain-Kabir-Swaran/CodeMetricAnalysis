{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "Server.java",
  "functionName": "doRead",
  "functionId": "doRead___key-SelectionKey",
  "sourceFilePath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
  "functionStartLine": 1413,
  "functionEndLine": 1443,
  "numCommitsSeen": 205,
  "timeTaken": 6698,
  "changeHistory": [
    "b6bb99c18a772d2179d5cc6757cddf141e8d39c0",
    "2e040d31c7bba021576e6baf267d937da7ff814a",
    "763f073f41e3eaa9ecd11c6ec0b76234739272aa",
    "1da81363fac49152ef34d2fcc536935bda0ba990",
    "65be21267587f04a2c33af65b951211cc9085b15",
    "a3a9d72e98a9cc0f94af7c832dd13c408856636d",
    "4a5ba3b7bd2360fd9605863630b477d362874e1e",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "0f6dfeeacbab65a31a33927a4eb84871d371fe52",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
    "69fe37a007045c3a3cf3b2b410e1ad14717fdb76",
    "940389afce6a1b9b9e1519aed528cbc444786756",
    "5128a9a453d64bfe1ed978cf9ffed27985eeef36"
  ],
  "changeHistoryShort": {
    "b6bb99c18a772d2179d5cc6757cddf141e8d39c0": "Ybodychange",
    "2e040d31c7bba021576e6baf267d937da7ff814a": "Ybodychange",
    "763f073f41e3eaa9ecd11c6ec0b76234739272aa": "Ybodychange",
    "1da81363fac49152ef34d2fcc536935bda0ba990": "Ybodychange",
    "65be21267587f04a2c33af65b951211cc9085b15": "Ybodychange",
    "a3a9d72e98a9cc0f94af7c832dd13c408856636d": "Ybodychange",
    "4a5ba3b7bd2360fd9605863630b477d362874e1e": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "0f6dfeeacbab65a31a33927a4eb84871d371fe52": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yfilerename",
    "69fe37a007045c3a3cf3b2b410e1ad14717fdb76": "Ybodychange",
    "940389afce6a1b9b9e1519aed528cbc444786756": "Ybodychange",
    "5128a9a453d64bfe1ed978cf9ffed27985eeef36": "Yintroduced"
  },
  "changeHistoryDetails": {
    "b6bb99c18a772d2179d5cc6757cddf141e8d39c0": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-14034. Allow ipc layer exceptions to selectively close connections. Contributed by Daryn Sharp.\n",
      "commitDate": "09/02/17 8:47 AM",
      "commitName": "b6bb99c18a772d2179d5cc6757cddf141e8d39c0",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "28/11/16 9:07 PM",
      "commitNameOld": "67d9f2808efb34b9a7b0b824cb4033b95ad33474",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 72.49,
      "commitsBetweenForRepo": 352,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,35 +1,31 @@\n     void doRead(SelectionKey key) throws InterruptedException {\n       int count;\n       Connection c \u003d (Connection)key.attachment();\n       if (c \u003d\u003d null) {\n         return;  \n       }\n       c.setLastContact(Time.now());\n       \n       try {\n         count \u003d c.readAndProcess();\n       } catch (InterruptedException ieo) {\n         LOG.info(Thread.currentThread().getName() + \": readAndProcess caught InterruptedException\", ieo);\n         throw ieo;\n       } catch (Exception e) {\n-        // Do not log WrappedRpcServerExceptionSuppressed.\n-        if (!(e instanceof WrappedRpcServerExceptionSuppressed)) {\n-          // A WrappedRpcServerException is an exception that has been sent\n-          // to the client, so the stacktrace is unnecessary; any other\n-          // exceptions are unexpected internal server errors and thus the\n-          // stacktrace should be logged.\n-          LOG.info(Thread.currentThread().getName() +\n-              \": readAndProcess from client \" + c.getHostAddress() +\n-              \" threw exception [\" + e + \"]\",\n-              (e instanceof WrappedRpcServerException) ? null : e);\n-        }\n+        // Any exceptions that reach here are fatal unexpected internal errors\n+        // that could not be sent to the client.\n+        LOG.info(Thread.currentThread().getName() +\n+            \": readAndProcess from client \" + c +\n+            \" threw exception [\" + e + \"]\", e);\n         count \u003d -1; //so that the (count \u003c 0) block is executed\n       }\n-      if (count \u003c 0) {\n+      // setupResponse will signal the connection should be closed when a\n+      // fatal response is sent.\n+      if (count \u003c 0 || c.shouldClose()) {\n         closeConnection(c);\n         c \u003d null;\n       }\n       else {\n         c.setLastContact(Time.now());\n       }\n     }   \n\\ No newline at end of file\n",
      "actualSource": "    void doRead(SelectionKey key) throws InterruptedException {\n      int count;\n      Connection c \u003d (Connection)key.attachment();\n      if (c \u003d\u003d null) {\n        return;  \n      }\n      c.setLastContact(Time.now());\n      \n      try {\n        count \u003d c.readAndProcess();\n      } catch (InterruptedException ieo) {\n        LOG.info(Thread.currentThread().getName() + \": readAndProcess caught InterruptedException\", ieo);\n        throw ieo;\n      } catch (Exception e) {\n        // Any exceptions that reach here are fatal unexpected internal errors\n        // that could not be sent to the client.\n        LOG.info(Thread.currentThread().getName() +\n            \": readAndProcess from client \" + c +\n            \" threw exception [\" + e + \"]\", e);\n        count \u003d -1; //so that the (count \u003c 0) block is executed\n      }\n      // setupResponse will signal the connection should be closed when a\n      // fatal response is sent.\n      if (count \u003c 0 || c.shouldClose()) {\n        closeConnection(c);\n        c \u003d null;\n      }\n      else {\n        c.setLastContact(Time.now());\n      }\n    }   ",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {}
    },
    "2e040d31c7bba021576e6baf267d937da7ff814a": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-12903. IPC Server should allow suppressing exception logging by type, not log \u0027server too busy\u0027 messages. (Arpit Agarwal)\n",
      "commitDate": "08/03/16 11:29 PM",
      "commitName": "2e040d31c7bba021576e6baf267d937da7ff814a",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "26/10/15 6:57 PM",
      "commitNameOld": "ea6b183a1a649ad2874050ade8856286728c654c",
      "commitAuthorOld": "Tsuyoshi Ozawa",
      "daysBetweenCommits": 134.23,
      "commitsBetweenForRepo": 893,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,31 +1,35 @@\n     void doRead(SelectionKey key) throws InterruptedException {\n-      int count \u003d 0;\n+      int count;\n       Connection c \u003d (Connection)key.attachment();\n       if (c \u003d\u003d null) {\n         return;  \n       }\n       c.setLastContact(Time.now());\n       \n       try {\n         count \u003d c.readAndProcess();\n       } catch (InterruptedException ieo) {\n         LOG.info(Thread.currentThread().getName() + \": readAndProcess caught InterruptedException\", ieo);\n         throw ieo;\n       } catch (Exception e) {\n-        // a WrappedRpcServerException is an exception that has been sent\n-        // to the client, so the stacktrace is unnecessary; any other\n-        // exceptions are unexpected internal server errors and thus the\n-        // stacktrace should be logged\n-        LOG.info(Thread.currentThread().getName() + \": readAndProcess from client \" +\n-            c.getHostAddress() + \" threw exception [\" + e + \"]\",\n-            (e instanceof WrappedRpcServerException) ? null : e);\n+        // Do not log WrappedRpcServerExceptionSuppressed.\n+        if (!(e instanceof WrappedRpcServerExceptionSuppressed)) {\n+          // A WrappedRpcServerException is an exception that has been sent\n+          // to the client, so the stacktrace is unnecessary; any other\n+          // exceptions are unexpected internal server errors and thus the\n+          // stacktrace should be logged.\n+          LOG.info(Thread.currentThread().getName() +\n+              \": readAndProcess from client \" + c.getHostAddress() +\n+              \" threw exception [\" + e + \"]\",\n+              (e instanceof WrappedRpcServerException) ? null : e);\n+        }\n         count \u003d -1; //so that the (count \u003c 0) block is executed\n       }\n       if (count \u003c 0) {\n         closeConnection(c);\n         c \u003d null;\n       }\n       else {\n         c.setLastContact(Time.now());\n       }\n     }   \n\\ No newline at end of file\n",
      "actualSource": "    void doRead(SelectionKey key) throws InterruptedException {\n      int count;\n      Connection c \u003d (Connection)key.attachment();\n      if (c \u003d\u003d null) {\n        return;  \n      }\n      c.setLastContact(Time.now());\n      \n      try {\n        count \u003d c.readAndProcess();\n      } catch (InterruptedException ieo) {\n        LOG.info(Thread.currentThread().getName() + \": readAndProcess caught InterruptedException\", ieo);\n        throw ieo;\n      } catch (Exception e) {\n        // Do not log WrappedRpcServerExceptionSuppressed.\n        if (!(e instanceof WrappedRpcServerExceptionSuppressed)) {\n          // A WrappedRpcServerException is an exception that has been sent\n          // to the client, so the stacktrace is unnecessary; any other\n          // exceptions are unexpected internal server errors and thus the\n          // stacktrace should be logged.\n          LOG.info(Thread.currentThread().getName() +\n              \": readAndProcess from client \" + c.getHostAddress() +\n              \" threw exception [\" + e + \"]\",\n              (e instanceof WrappedRpcServerException) ? null : e);\n        }\n        count \u003d -1; //so that the (count \u003c 0) block is executed\n      }\n      if (count \u003c 0) {\n        closeConnection(c);\n        c \u003d null;\n      }\n      else {\n        c.setLastContact(Time.now());\n      }\n    }   ",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {}
    },
    "763f073f41e3eaa9ecd11c6ec0b76234739272aa": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-10106. Incorrect thread name in RPC log messages. Contributed by Ming Ma.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1551369 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/12/13 1:57 PM",
      "commitName": "763f073f41e3eaa9ecd11c6ec0b76234739272aa",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "12/12/13 10:56 AM",
      "commitNameOld": "a4819e70dbf88b0905a6669078afa1ff0924ad4f",
      "commitAuthorOld": "Sanjay Radia",
      "daysBetweenCommits": 4.13,
      "commitsBetweenForRepo": 20,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,31 +1,31 @@\n     void doRead(SelectionKey key) throws InterruptedException {\n       int count \u003d 0;\n       Connection c \u003d (Connection)key.attachment();\n       if (c \u003d\u003d null) {\n         return;  \n       }\n       c.setLastContact(Time.now());\n       \n       try {\n         count \u003d c.readAndProcess();\n       } catch (InterruptedException ieo) {\n-        LOG.info(getName() + \": readAndProcess caught InterruptedException\", ieo);\n+        LOG.info(Thread.currentThread().getName() + \": readAndProcess caught InterruptedException\", ieo);\n         throw ieo;\n       } catch (Exception e) {\n         // a WrappedRpcServerException is an exception that has been sent\n         // to the client, so the stacktrace is unnecessary; any other\n         // exceptions are unexpected internal server errors and thus the\n         // stacktrace should be logged\n-        LOG.info(getName() + \": readAndProcess from client \" +\n+        LOG.info(Thread.currentThread().getName() + \": readAndProcess from client \" +\n             c.getHostAddress() + \" threw exception [\" + e + \"]\",\n             (e instanceof WrappedRpcServerException) ? null : e);\n         count \u003d -1; //so that the (count \u003c 0) block is executed\n       }\n       if (count \u003c 0) {\n         closeConnection(c);\n         c \u003d null;\n       }\n       else {\n         c.setLastContact(Time.now());\n       }\n     }   \n\\ No newline at end of file\n",
      "actualSource": "    void doRead(SelectionKey key) throws InterruptedException {\n      int count \u003d 0;\n      Connection c \u003d (Connection)key.attachment();\n      if (c \u003d\u003d null) {\n        return;  \n      }\n      c.setLastContact(Time.now());\n      \n      try {\n        count \u003d c.readAndProcess();\n      } catch (InterruptedException ieo) {\n        LOG.info(Thread.currentThread().getName() + \": readAndProcess caught InterruptedException\", ieo);\n        throw ieo;\n      } catch (Exception e) {\n        // a WrappedRpcServerException is an exception that has been sent\n        // to the client, so the stacktrace is unnecessary; any other\n        // exceptions are unexpected internal server errors and thus the\n        // stacktrace should be logged\n        LOG.info(Thread.currentThread().getName() + \": readAndProcess from client \" +\n            c.getHostAddress() + \" threw exception [\" + e + \"]\",\n            (e instanceof WrappedRpcServerException) ? null : e);\n        count \u003d -1; //so that the (count \u003c 0) block is executed\n      }\n      if (count \u003c 0) {\n        closeConnection(c);\n        c \u003d null;\n      }\n      else {\n        c.setLastContact(Time.now());\n      }\n    }   ",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {}
    },
    "1da81363fac49152ef34d2fcc536935bda0ba990": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-9955. RPC idle connection closing is extremely inefficient (daryn)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1542111 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/11/13 2:55 PM",
      "commitName": "1da81363fac49152ef34d2fcc536935bda0ba990",
      "commitAuthor": "Daryn Sharp",
      "commitDateOld": "13/11/13 1:37 PM",
      "commitNameOld": "e43255302aa7c5a493a3795ec40832994a2dfb19",
      "commitAuthorOld": "Daryn Sharp",
      "daysBetweenCommits": 1.05,
      "commitsBetweenForRepo": 18,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,35 +1,31 @@\n     void doRead(SelectionKey key) throws InterruptedException {\n       int count \u003d 0;\n       Connection c \u003d (Connection)key.attachment();\n       if (c \u003d\u003d null) {\n         return;  \n       }\n       c.setLastContact(Time.now());\n       \n       try {\n         count \u003d c.readAndProcess();\n       } catch (InterruptedException ieo) {\n         LOG.info(getName() + \": readAndProcess caught InterruptedException\", ieo);\n         throw ieo;\n       } catch (Exception e) {\n         // a WrappedRpcServerException is an exception that has been sent\n         // to the client, so the stacktrace is unnecessary; any other\n         // exceptions are unexpected internal server errors and thus the\n         // stacktrace should be logged\n         LOG.info(getName() + \": readAndProcess from client \" +\n             c.getHostAddress() + \" threw exception [\" + e + \"]\",\n             (e instanceof WrappedRpcServerException) ? null : e);\n         count \u003d -1; //so that the (count \u003c 0) block is executed\n       }\n       if (count \u003c 0) {\n-        if (LOG.isDebugEnabled())\n-          LOG.debug(getName() + \": disconnecting client \" + \n-                    c + \". Number of active connections: \"+\n-                    numConnections);\n         closeConnection(c);\n         c \u003d null;\n       }\n       else {\n         c.setLastContact(Time.now());\n       }\n     }   \n\\ No newline at end of file\n",
      "actualSource": "    void doRead(SelectionKey key) throws InterruptedException {\n      int count \u003d 0;\n      Connection c \u003d (Connection)key.attachment();\n      if (c \u003d\u003d null) {\n        return;  \n      }\n      c.setLastContact(Time.now());\n      \n      try {\n        count \u003d c.readAndProcess();\n      } catch (InterruptedException ieo) {\n        LOG.info(getName() + \": readAndProcess caught InterruptedException\", ieo);\n        throw ieo;\n      } catch (Exception e) {\n        // a WrappedRpcServerException is an exception that has been sent\n        // to the client, so the stacktrace is unnecessary; any other\n        // exceptions are unexpected internal server errors and thus the\n        // stacktrace should be logged\n        LOG.info(getName() + \": readAndProcess from client \" +\n            c.getHostAddress() + \" threw exception [\" + e + \"]\",\n            (e instanceof WrappedRpcServerException) ? null : e);\n        count \u003d -1; //so that the (count \u003c 0) block is executed\n      }\n      if (count \u003c 0) {\n        closeConnection(c);\n        c \u003d null;\n      }\n      else {\n        c.setLastContact(Time.now());\n      }\n    }   ",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {}
    },
    "65be21267587f04a2c33af65b951211cc9085b15": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-9698. [RPC v9] Client must honor server\u0027s SASL negotiate response (daryn)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1508086 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "29/07/13 7:44 AM",
      "commitName": "65be21267587f04a2c33af65b951211cc9085b15",
      "commitAuthor": "Daryn Sharp",
      "commitDateOld": "24/07/13 12:48 AM",
      "commitNameOld": "a0a986dda77ea03dac9cfc7e0631bae611034ef4",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 5.29,
      "commitsBetweenForRepo": 31,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,32 +1,35 @@\n     void doRead(SelectionKey key) throws InterruptedException {\n       int count \u003d 0;\n       Connection c \u003d (Connection)key.attachment();\n       if (c \u003d\u003d null) {\n         return;  \n       }\n       c.setLastContact(Time.now());\n       \n       try {\n         count \u003d c.readAndProcess();\n       } catch (InterruptedException ieo) {\n         LOG.info(getName() + \": readAndProcess caught InterruptedException\", ieo);\n         throw ieo;\n       } catch (Exception e) {\n-        // log stack trace for \"interesting\" exceptions not sent to client\n+        // a WrappedRpcServerException is an exception that has been sent\n+        // to the client, so the stacktrace is unnecessary; any other\n+        // exceptions are unexpected internal server errors and thus the\n+        // stacktrace should be logged\n         LOG.info(getName() + \": readAndProcess from client \" +\n             c.getHostAddress() + \" threw exception [\" + e + \"]\",\n             (e instanceof WrappedRpcServerException) ? null : e);\n         count \u003d -1; //so that the (count \u003c 0) block is executed\n       }\n       if (count \u003c 0) {\n         if (LOG.isDebugEnabled())\n           LOG.debug(getName() + \": disconnecting client \" + \n                     c + \". Number of active connections: \"+\n                     numConnections);\n         closeConnection(c);\n         c \u003d null;\n       }\n       else {\n         c.setLastContact(Time.now());\n       }\n     }   \n\\ No newline at end of file\n",
      "actualSource": "    void doRead(SelectionKey key) throws InterruptedException {\n      int count \u003d 0;\n      Connection c \u003d (Connection)key.attachment();\n      if (c \u003d\u003d null) {\n        return;  \n      }\n      c.setLastContact(Time.now());\n      \n      try {\n        count \u003d c.readAndProcess();\n      } catch (InterruptedException ieo) {\n        LOG.info(getName() + \": readAndProcess caught InterruptedException\", ieo);\n        throw ieo;\n      } catch (Exception e) {\n        // a WrappedRpcServerException is an exception that has been sent\n        // to the client, so the stacktrace is unnecessary; any other\n        // exceptions are unexpected internal server errors and thus the\n        // stacktrace should be logged\n        LOG.info(getName() + \": readAndProcess from client \" +\n            c.getHostAddress() + \" threw exception [\" + e + \"]\",\n            (e instanceof WrappedRpcServerException) ? null : e);\n        count \u003d -1; //so that the (count \u003c 0) block is executed\n      }\n      if (count \u003c 0) {\n        if (LOG.isDebugEnabled())\n          LOG.debug(getName() + \": disconnecting client \" + \n                    c + \". Number of active connections: \"+\n                    numConnections);\n        closeConnection(c);\n        c \u003d null;\n      }\n      else {\n        c.setLastContact(Time.now());\n      }\n    }   ",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {}
    },
    "a3a9d72e98a9cc0f94af7c832dd13c408856636d": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-9683. [RPC v9] Wrap IpcConnectionContext in RPC headers (daryn)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1503811 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/07/13 10:59 AM",
      "commitName": "a3a9d72e98a9cc0f94af7c832dd13c408856636d",
      "commitAuthor": "Daryn Sharp",
      "commitDateOld": "09/07/13 4:45 PM",
      "commitNameOld": "0a5f16a89e3942953d7d6c2d26542764298c6430",
      "commitAuthorOld": "Chris Nauroth",
      "daysBetweenCommits": 6.76,
      "commitsBetweenForRepo": 40,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,31 +1,32 @@\n     void doRead(SelectionKey key) throws InterruptedException {\n       int count \u003d 0;\n       Connection c \u003d (Connection)key.attachment();\n       if (c \u003d\u003d null) {\n         return;  \n       }\n       c.setLastContact(Time.now());\n       \n       try {\n         count \u003d c.readAndProcess();\n       } catch (InterruptedException ieo) {\n         LOG.info(getName() + \": readAndProcess caught InterruptedException\", ieo);\n         throw ieo;\n       } catch (Exception e) {\n-        LOG.info(getName() + \": readAndProcess threw exception \" + e +\n-            \" from client \" + c.getHostAddress() +\n-            \". Count of bytes read: \" + count, e);\n+        // log stack trace for \"interesting\" exceptions not sent to client\n+        LOG.info(getName() + \": readAndProcess from client \" +\n+            c.getHostAddress() + \" threw exception [\" + e + \"]\",\n+            (e instanceof WrappedRpcServerException) ? null : e);\n         count \u003d -1; //so that the (count \u003c 0) block is executed\n       }\n       if (count \u003c 0) {\n         if (LOG.isDebugEnabled())\n           LOG.debug(getName() + \": disconnecting client \" + \n                     c + \". Number of active connections: \"+\n                     numConnections);\n         closeConnection(c);\n         c \u003d null;\n       }\n       else {\n         c.setLastContact(Time.now());\n       }\n     }   \n\\ No newline at end of file\n",
      "actualSource": "    void doRead(SelectionKey key) throws InterruptedException {\n      int count \u003d 0;\n      Connection c \u003d (Connection)key.attachment();\n      if (c \u003d\u003d null) {\n        return;  \n      }\n      c.setLastContact(Time.now());\n      \n      try {\n        count \u003d c.readAndProcess();\n      } catch (InterruptedException ieo) {\n        LOG.info(getName() + \": readAndProcess caught InterruptedException\", ieo);\n        throw ieo;\n      } catch (Exception e) {\n        // log stack trace for \"interesting\" exceptions not sent to client\n        LOG.info(getName() + \": readAndProcess from client \" +\n            c.getHostAddress() + \" threw exception [\" + e + \"]\",\n            (e instanceof WrappedRpcServerException) ? null : e);\n        count \u003d -1; //so that the (count \u003c 0) block is executed\n      }\n      if (count \u003c 0) {\n        if (LOG.isDebugEnabled())\n          LOG.debug(getName() + \": disconnecting client \" + \n                    c + \". Number of active connections: \"+\n                    numConnections);\n        closeConnection(c);\n        c \u003d null;\n      }\n      else {\n        c.setLastContact(Time.now());\n      }\n    }   ",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {}
    },
    "4a5ba3b7bd2360fd9605863630b477d362874e1e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3641. Move server Util time methods to common and use now instead of System#currentTimeMillis. Contributed by Eli Collins\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1360858 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/07/12 12:01 PM",
      "commitName": "4a5ba3b7bd2360fd9605863630b477d362874e1e",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "11/05/12 9:56 AM",
      "commitNameOld": "2116f28d9e95896b54f4dc60336dc3f6ac7d64f3",
      "commitAuthorOld": "Sanjay Radia",
      "daysBetweenCommits": 62.09,
      "commitsBetweenForRepo": 300,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,31 +1,31 @@\n     void doRead(SelectionKey key) throws InterruptedException {\n       int count \u003d 0;\n       Connection c \u003d (Connection)key.attachment();\n       if (c \u003d\u003d null) {\n         return;  \n       }\n-      c.setLastContact(System.currentTimeMillis());\n+      c.setLastContact(Time.now());\n       \n       try {\n         count \u003d c.readAndProcess();\n       } catch (InterruptedException ieo) {\n         LOG.info(getName() + \": readAndProcess caught InterruptedException\", ieo);\n         throw ieo;\n       } catch (Exception e) {\n         LOG.info(getName() + \": readAndProcess threw exception \" + e +\n             \" from client \" + c.getHostAddress() +\n             \". Count of bytes read: \" + count, e);\n         count \u003d -1; //so that the (count \u003c 0) block is executed\n       }\n       if (count \u003c 0) {\n         if (LOG.isDebugEnabled())\n           LOG.debug(getName() + \": disconnecting client \" + \n                     c + \". Number of active connections: \"+\n                     numConnections);\n         closeConnection(c);\n         c \u003d null;\n       }\n       else {\n-        c.setLastContact(System.currentTimeMillis());\n+        c.setLastContact(Time.now());\n       }\n     }   \n\\ No newline at end of file\n",
      "actualSource": "    void doRead(SelectionKey key) throws InterruptedException {\n      int count \u003d 0;\n      Connection c \u003d (Connection)key.attachment();\n      if (c \u003d\u003d null) {\n        return;  \n      }\n      c.setLastContact(Time.now());\n      \n      try {\n        count \u003d c.readAndProcess();\n      } catch (InterruptedException ieo) {\n        LOG.info(getName() + \": readAndProcess caught InterruptedException\", ieo);\n        throw ieo;\n      } catch (Exception e) {\n        LOG.info(getName() + \": readAndProcess threw exception \" + e +\n            \" from client \" + c.getHostAddress() +\n            \". Count of bytes read: \" + count, e);\n        count \u003d -1; //so that the (count \u003c 0) block is executed\n      }\n      if (count \u003c 0) {\n        if (LOG.isDebugEnabled())\n          LOG.debug(getName() + \": disconnecting client \" + \n                    c + \". Number of active connections: \"+\n                    numConnections);\n        closeConnection(c);\n        c \u003d null;\n      }\n      else {\n        c.setLastContact(Time.now());\n      }\n    }   ",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    void doRead(SelectionKey key) throws InterruptedException {\n      int count \u003d 0;\n      Connection c \u003d (Connection)key.attachment();\n      if (c \u003d\u003d null) {\n        return;  \n      }\n      c.setLastContact(System.currentTimeMillis());\n      \n      try {\n        count \u003d c.readAndProcess();\n      } catch (InterruptedException ieo) {\n        LOG.info(getName() + \": readAndProcess caught InterruptedException\", ieo);\n        throw ieo;\n      } catch (Exception e) {\n        LOG.info(getName() + \": readAndProcess threw exception \" + e +\n            \" from client \" + c.getHostAddress() +\n            \". Count of bytes read: \" + count, e);\n        count \u003d -1; //so that the (count \u003c 0) block is executed\n      }\n      if (count \u003c 0) {\n        if (LOG.isDebugEnabled())\n          LOG.debug(getName() + \": disconnecting client \" + \n                    c + \". Number of active connections: \"+\n                    numConnections);\n        closeConnection(c);\n        c \u003d null;\n      }\n      else {\n        c.setLastContact(System.currentTimeMillis());\n      }\n    }   ",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {
        "oldPath": "hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
        "newPath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java"
      }
    },
    "0f6dfeeacbab65a31a33927a4eb84871d371fe52": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-6671. Use maven for hadoop common builds. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1153184 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/08/11 9:37 AM",
      "commitName": "0f6dfeeacbab65a31a33927a4eb84871d371fe52",
      "commitAuthor": "Thomas White",
      "commitDateOld": "01/08/11 3:53 PM",
      "commitNameOld": "9bac807cedbcff34e1a144fb475eff267e5ed86d",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.74,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    void doRead(SelectionKey key) throws InterruptedException {\n      int count \u003d 0;\n      Connection c \u003d (Connection)key.attachment();\n      if (c \u003d\u003d null) {\n        return;  \n      }\n      c.setLastContact(System.currentTimeMillis());\n      \n      try {\n        count \u003d c.readAndProcess();\n      } catch (InterruptedException ieo) {\n        LOG.info(getName() + \": readAndProcess caught InterruptedException\", ieo);\n        throw ieo;\n      } catch (Exception e) {\n        LOG.info(getName() + \": readAndProcess threw exception \" + e +\n            \" from client \" + c.getHostAddress() +\n            \". Count of bytes read: \" + count, e);\n        count \u003d -1; //so that the (count \u003c 0) block is executed\n      }\n      if (count \u003c 0) {\n        if (LOG.isDebugEnabled())\n          LOG.debug(getName() + \": disconnecting client \" + \n                    c + \". Number of active connections: \"+\n                    numConnections);\n        closeConnection(c);\n        c \u003d null;\n      }\n      else {\n        c.setLastContact(System.currentTimeMillis());\n      }\n    }   ",
      "path": "hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {
        "oldPath": "common/src/java/org/apache/hadoop/ipc/Server.java",
        "newPath": "hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "11/06/11 9:13 PM",
      "commitNameOld": "a285fb5effe9ba3be4ec5f942afaf5ddd1186151",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 0.74,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    void doRead(SelectionKey key) throws InterruptedException {\n      int count \u003d 0;\n      Connection c \u003d (Connection)key.attachment();\n      if (c \u003d\u003d null) {\n        return;  \n      }\n      c.setLastContact(System.currentTimeMillis());\n      \n      try {\n        count \u003d c.readAndProcess();\n      } catch (InterruptedException ieo) {\n        LOG.info(getName() + \": readAndProcess caught InterruptedException\", ieo);\n        throw ieo;\n      } catch (Exception e) {\n        LOG.info(getName() + \": readAndProcess threw exception \" + e +\n            \" from client \" + c.getHostAddress() +\n            \". Count of bytes read: \" + count, e);\n        count \u003d -1; //so that the (count \u003c 0) block is executed\n      }\n      if (count \u003c 0) {\n        if (LOG.isDebugEnabled())\n          LOG.debug(getName() + \": disconnecting client \" + \n                    c + \". Number of active connections: \"+\n                    numConnections);\n        closeConnection(c);\n        c \u003d null;\n      }\n      else {\n        c.setLastContact(System.currentTimeMillis());\n      }\n    }   ",
      "path": "common/src/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {
        "oldPath": "src/java/org/apache/hadoop/ipc/Server.java",
        "newPath": "common/src/java/org/apache/hadoop/ipc/Server.java"
      }
    },
    "69fe37a007045c3a3cf3b2b410e1ad14717fdb76": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-7159. RPC server should log the client hostname when read exception happened. Contributed by Scott Chen.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1078669 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "06/03/11 7:44 PM",
      "commitName": "69fe37a007045c3a3cf3b2b410e1ad14717fdb76",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "14/02/11 11:16 PM",
      "commitNameOld": "ae8b2310d83726503f006359a87ab1c77699c3ec",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 19.85,
      "commitsBetweenForRepo": 15,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,29 +1,31 @@\n     void doRead(SelectionKey key) throws InterruptedException {\n       int count \u003d 0;\n       Connection c \u003d (Connection)key.attachment();\n       if (c \u003d\u003d null) {\n         return;  \n       }\n       c.setLastContact(System.currentTimeMillis());\n       \n       try {\n         count \u003d c.readAndProcess();\n       } catch (InterruptedException ieo) {\n         LOG.info(getName() + \": readAndProcess caught InterruptedException\", ieo);\n         throw ieo;\n       } catch (Exception e) {\n-        LOG.info(getName() + \": readAndProcess threw exception \" + e + \". Count of bytes read: \" + count, e);\n+        LOG.info(getName() + \": readAndProcess threw exception \" + e +\n+            \" from client \" + c.getHostAddress() +\n+            \". Count of bytes read: \" + count, e);\n         count \u003d -1; //so that the (count \u003c 0) block is executed\n       }\n       if (count \u003c 0) {\n         if (LOG.isDebugEnabled())\n           LOG.debug(getName() + \": disconnecting client \" + \n                     c + \". Number of active connections: \"+\n                     numConnections);\n         closeConnection(c);\n         c \u003d null;\n       }\n       else {\n         c.setLastContact(System.currentTimeMillis());\n       }\n     }   \n\\ No newline at end of file\n",
      "actualSource": "    void doRead(SelectionKey key) throws InterruptedException {\n      int count \u003d 0;\n      Connection c \u003d (Connection)key.attachment();\n      if (c \u003d\u003d null) {\n        return;  \n      }\n      c.setLastContact(System.currentTimeMillis());\n      \n      try {\n        count \u003d c.readAndProcess();\n      } catch (InterruptedException ieo) {\n        LOG.info(getName() + \": readAndProcess caught InterruptedException\", ieo);\n        throw ieo;\n      } catch (Exception e) {\n        LOG.info(getName() + \": readAndProcess threw exception \" + e +\n            \" from client \" + c.getHostAddress() +\n            \". Count of bytes read: \" + count, e);\n        count \u003d -1; //so that the (count \u003c 0) block is executed\n      }\n      if (count \u003c 0) {\n        if (LOG.isDebugEnabled())\n          LOG.debug(getName() + \": disconnecting client \" + \n                    c + \". Number of active connections: \"+\n                    numConnections);\n        closeConnection(c);\n        c \u003d null;\n      }\n      else {\n        c.setLastContact(System.currentTimeMillis());\n      }\n    }   ",
      "path": "src/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {}
    },
    "940389afce6a1b9b9e1519aed528cbc444786756": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-6419. Adds SASL based authentication to RPC. Contributed by Kan Zhang.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@905860 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/02/10 5:30 PM",
      "commitName": "940389afce6a1b9b9e1519aed528cbc444786756",
      "commitAuthor": "Devaraj Das",
      "commitDateOld": "27/01/10 12:08 AM",
      "commitNameOld": "0c5734e4aca873f405fbf994e5fe7061e31731c8",
      "commitAuthorOld": "Owen O\u0027Malley",
      "daysBetweenCommits": 6.72,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,29 +1,29 @@\n     void doRead(SelectionKey key) throws InterruptedException {\n       int count \u003d 0;\n       Connection c \u003d (Connection)key.attachment();\n       if (c \u003d\u003d null) {\n         return;  \n       }\n       c.setLastContact(System.currentTimeMillis());\n       \n       try {\n         count \u003d c.readAndProcess();\n       } catch (InterruptedException ieo) {\n         LOG.info(getName() + \": readAndProcess caught InterruptedException\", ieo);\n         throw ieo;\n       } catch (Exception e) {\n         LOG.info(getName() + \": readAndProcess threw exception \" + e + \". Count of bytes read: \" + count, e);\n         count \u003d -1; //so that the (count \u003c 0) block is executed\n       }\n       if (count \u003c 0) {\n         if (LOG.isDebugEnabled())\n           LOG.debug(getName() + \": disconnecting client \" + \n-                    c.getHostAddress() + \". Number of active connections: \"+\n+                    c + \". Number of active connections: \"+\n                     numConnections);\n         closeConnection(c);\n         c \u003d null;\n       }\n       else {\n         c.setLastContact(System.currentTimeMillis());\n       }\n     }   \n\\ No newline at end of file\n",
      "actualSource": "    void doRead(SelectionKey key) throws InterruptedException {\n      int count \u003d 0;\n      Connection c \u003d (Connection)key.attachment();\n      if (c \u003d\u003d null) {\n        return;  \n      }\n      c.setLastContact(System.currentTimeMillis());\n      \n      try {\n        count \u003d c.readAndProcess();\n      } catch (InterruptedException ieo) {\n        LOG.info(getName() + \": readAndProcess caught InterruptedException\", ieo);\n        throw ieo;\n      } catch (Exception e) {\n        LOG.info(getName() + \": readAndProcess threw exception \" + e + \". Count of bytes read: \" + count, e);\n        count \u003d -1; //so that the (count \u003c 0) block is executed\n      }\n      if (count \u003c 0) {\n        if (LOG.isDebugEnabled())\n          LOG.debug(getName() + \": disconnecting client \" + \n                    c + \". Number of active connections: \"+\n                    numConnections);\n        closeConnection(c);\n        c \u003d null;\n      }\n      else {\n        c.setLastContact(System.currentTimeMillis());\n      }\n    }   ",
      "path": "src/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {}
    },
    "5128a9a453d64bfe1ed978cf9ffed27985eeef36": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-4687 Moving src directories on branch\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/core/branches/HADOOP-4687/core@776174 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/05/09 9:20 PM",
      "commitName": "5128a9a453d64bfe1ed978cf9ffed27985eeef36",
      "commitAuthor": "Owen O\u0027Malley",
      "diff": "@@ -0,0 +1,29 @@\n+    void doRead(SelectionKey key) throws InterruptedException {\n+      int count \u003d 0;\n+      Connection c \u003d (Connection)key.attachment();\n+      if (c \u003d\u003d null) {\n+        return;  \n+      }\n+      c.setLastContact(System.currentTimeMillis());\n+      \n+      try {\n+        count \u003d c.readAndProcess();\n+      } catch (InterruptedException ieo) {\n+        LOG.info(getName() + \": readAndProcess caught InterruptedException\", ieo);\n+        throw ieo;\n+      } catch (Exception e) {\n+        LOG.info(getName() + \": readAndProcess threw exception \" + e + \". Count of bytes read: \" + count, e);\n+        count \u003d -1; //so that the (count \u003c 0) block is executed\n+      }\n+      if (count \u003c 0) {\n+        if (LOG.isDebugEnabled())\n+          LOG.debug(getName() + \": disconnecting client \" + \n+                    c.getHostAddress() + \". Number of active connections: \"+\n+                    numConnections);\n+        closeConnection(c);\n+        c \u003d null;\n+      }\n+      else {\n+        c.setLastContact(System.currentTimeMillis());\n+      }\n+    }   \n\\ No newline at end of file\n",
      "actualSource": "    void doRead(SelectionKey key) throws InterruptedException {\n      int count \u003d 0;\n      Connection c \u003d (Connection)key.attachment();\n      if (c \u003d\u003d null) {\n        return;  \n      }\n      c.setLastContact(System.currentTimeMillis());\n      \n      try {\n        count \u003d c.readAndProcess();\n      } catch (InterruptedException ieo) {\n        LOG.info(getName() + \": readAndProcess caught InterruptedException\", ieo);\n        throw ieo;\n      } catch (Exception e) {\n        LOG.info(getName() + \": readAndProcess threw exception \" + e + \". Count of bytes read: \" + count, e);\n        count \u003d -1; //so that the (count \u003c 0) block is executed\n      }\n      if (count \u003c 0) {\n        if (LOG.isDebugEnabled())\n          LOG.debug(getName() + \": disconnecting client \" + \n                    c.getHostAddress() + \". Number of active connections: \"+\n                    numConnections);\n        closeConnection(c);\n        c \u003d null;\n      }\n      else {\n        c.setLastContact(System.currentTimeMillis());\n      }\n    }   ",
      "path": "src/java/org/apache/hadoop/ipc/Server.java"
    }
  }
}