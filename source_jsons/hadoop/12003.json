{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FsDatasetImpl.java",
  "functionName": "checkBlock",
  "functionId": "checkBlock___b-ExtendedBlock__minLength-long__state-ReplicaState",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
  "functionStartLine": 2024,
  "functionEndLine": 2043,
  "numCommitsSeen": 197,
  "timeTaken": 5517,
  "changeHistory": [
    "86c9862bec0248d671e657aa56094a2919b8ac14",
    "ac9ab037e9a9b03e4fa9bd471d3ab9940beb53fb"
  ],
  "changeHistoryShort": {
    "86c9862bec0248d671e657aa56094a2919b8ac14": "Ybodychange",
    "ac9ab037e9a9b03e4fa9bd471d3ab9940beb53fb": "Yintroduced"
  },
  "changeHistoryDetails": {
    "86c9862bec0248d671e657aa56094a2919b8ac14": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10636. Modify ReplicaInfo to remove the assumption that replica metadata and data are stored in java.io.File. (Virajith Jalaparti via lei)\n",
      "commitDate": "13/09/16 12:54 PM",
      "commitName": "86c9862bec0248d671e657aa56094a2919b8ac14",
      "commitAuthor": "Lei Xu",
      "commitDateOld": "10/09/16 6:22 PM",
      "commitNameOld": "a99bf26a0899bcc4307c3a242c8414eaef555aa7",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 2.77,
      "commitsBetweenForRepo": 15,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,20 @@\n   public void checkBlock(ExtendedBlock b, long minLength, ReplicaState state)\n       throws ReplicaNotFoundException, UnexpectedReplicaStateException,\n       FileNotFoundException, EOFException, IOException {\n     final ReplicaInfo replicaInfo \u003d volumeMap.get(b.getBlockPoolId(), \n         b.getLocalBlock());\n     if (replicaInfo \u003d\u003d null) {\n       throw new ReplicaNotFoundException(b);\n     }\n     if (replicaInfo.getState() !\u003d state) {\n       throw new UnexpectedReplicaStateException(b,state);\n     }\n-    if (!replicaInfo.getBlockFile().exists()) {\n-      throw new FileNotFoundException(replicaInfo.getBlockFile().getPath());\n+    if (!replicaInfo.blockDataExists()) {\n+      throw new FileNotFoundException(replicaInfo.getBlockURI().toString());\n     }\n     long onDiskLength \u003d getLength(b);\n     if (onDiskLength \u003c minLength) {\n       throw new EOFException(b + \"\u0027s on-disk length \" + onDiskLength\n           + \" is shorter than minLength \" + minLength);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void checkBlock(ExtendedBlock b, long minLength, ReplicaState state)\n      throws ReplicaNotFoundException, UnexpectedReplicaStateException,\n      FileNotFoundException, EOFException, IOException {\n    final ReplicaInfo replicaInfo \u003d volumeMap.get(b.getBlockPoolId(), \n        b.getLocalBlock());\n    if (replicaInfo \u003d\u003d null) {\n      throw new ReplicaNotFoundException(b);\n    }\n    if (replicaInfo.getState() !\u003d state) {\n      throw new UnexpectedReplicaStateException(b,state);\n    }\n    if (!replicaInfo.blockDataExists()) {\n      throw new FileNotFoundException(replicaInfo.getBlockURI().toString());\n    }\n    long onDiskLength \u003d getLength(b);\n    if (onDiskLength \u003c minLength) {\n      throw new EOFException(b + \"\u0027s on-disk length \" + onDiskLength\n          + \" is shorter than minLength \" + minLength);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "ac9ab037e9a9b03e4fa9bd471d3ab9940beb53fb": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-7235. DataNode#transferBlock should report blocks that don\u0027t exist using reportBadBlock (yzhang via cmccabe)\n",
      "commitDate": "28/10/14 4:41 PM",
      "commitName": "ac9ab037e9a9b03e4fa9bd471d3ab9940beb53fb",
      "commitAuthor": "Colin Patrick Mccabe",
      "diff": "@@ -0,0 +1,20 @@\n+  public void checkBlock(ExtendedBlock b, long minLength, ReplicaState state)\n+      throws ReplicaNotFoundException, UnexpectedReplicaStateException,\n+      FileNotFoundException, EOFException, IOException {\n+    final ReplicaInfo replicaInfo \u003d volumeMap.get(b.getBlockPoolId(), \n+        b.getLocalBlock());\n+    if (replicaInfo \u003d\u003d null) {\n+      throw new ReplicaNotFoundException(b);\n+    }\n+    if (replicaInfo.getState() !\u003d state) {\n+      throw new UnexpectedReplicaStateException(b,state);\n+    }\n+    if (!replicaInfo.getBlockFile().exists()) {\n+      throw new FileNotFoundException(replicaInfo.getBlockFile().getPath());\n+    }\n+    long onDiskLength \u003d getLength(b);\n+    if (onDiskLength \u003c minLength) {\n+      throw new EOFException(b + \"\u0027s on-disk length \" + onDiskLength\n+          + \" is shorter than minLength \" + minLength);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void checkBlock(ExtendedBlock b, long minLength, ReplicaState state)\n      throws ReplicaNotFoundException, UnexpectedReplicaStateException,\n      FileNotFoundException, EOFException, IOException {\n    final ReplicaInfo replicaInfo \u003d volumeMap.get(b.getBlockPoolId(), \n        b.getLocalBlock());\n    if (replicaInfo \u003d\u003d null) {\n      throw new ReplicaNotFoundException(b);\n    }\n    if (replicaInfo.getState() !\u003d state) {\n      throw new UnexpectedReplicaStateException(b,state);\n    }\n    if (!replicaInfo.getBlockFile().exists()) {\n      throw new FileNotFoundException(replicaInfo.getBlockFile().getPath());\n    }\n    long onDiskLength \u003d getLength(b);\n    if (onDiskLength \u003c minLength) {\n      throw new EOFException(b + \"\u0027s on-disk length \" + onDiskLength\n          + \" is shorter than minLength \" + minLength);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java"
    }
  }
}