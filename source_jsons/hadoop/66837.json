{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "TraceBuilder.java",
  "functionName": "run",
  "functionId": "run___args-String[]",
  "sourceFilePath": "hadoop-tools/hadoop-rumen/src/main/java/org/apache/hadoop/tools/rumen/TraceBuilder.java",
  "functionStartLine": 205,
  "functionEndLine": 294,
  "numCommitsSeen": 7,
  "timeTaken": 5872,
  "changeHistory": [
    "10325d97329c214bb3899c8535df5a366bc86d2f",
    "efb3cd64a28d9425f0bbbac97fb085c525bc92ea",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "10325d97329c214bb3899c8535df5a366bc86d2f": "Yfilerename",
    "efb3cd64a28d9425f0bbbac97fb085c525bc92ea": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "10325d97329c214bb3899c8535df5a366bc86d2f": {
      "type": "Yfilerename",
      "commitMessage": "MAPREDUCE-3582. Move successfully passing MR1 tests to MR2 maven tree.(ahmed via tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1233090 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/01/12 2:10 PM",
      "commitName": "10325d97329c214bb3899c8535df5a366bc86d2f",
      "commitAuthor": "Alejandro Abdelnur",
      "commitDateOld": "18/01/12 10:20 AM",
      "commitNameOld": "8b2f6909ec7df5cffb5ef417f5c9cffdee43e38a",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.16,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public int run(String[] args) throws Exception {\n    MyOptions options \u003d new MyOptions(args, getConf());\n    traceWriter \u003d options.clazzTraceOutputter.newInstance();\n    traceWriter.init(options.traceOutput, getConf());\n    topologyWriter \u003d new DefaultOutputter\u003cLoggedNetworkTopology\u003e();\n    topologyWriter.init(options.topologyOutput, getConf());\n\n    try {\n      JobBuilder jobBuilder \u003d null;\n\n      for (Path p : options.inputs) {\n        InputDemuxer inputDemuxer \u003d options.inputDemuxerClass.newInstance();\n\n        try {\n          inputDemuxer.bindTo(p, getConf());\n        } catch (IOException e) {\n          LOG.warn(\"Unable to bind Path \" + p + \" .  Skipping...\", e);\n\n          continue;\n        }\n\n        Pair\u003cString, InputStream\u003e filePair \u003d null;\n\n        try {\n          while ((filePair \u003d inputDemuxer.getNext()) !\u003d null) {\n            RewindableInputStream ris \u003d\n                new RewindableInputStream(filePair.second());\n\n            JobHistoryParser parser \u003d null;\n\n            try {\n              String jobID \u003d JobHistoryUtils.extractJobID(filePair.first());\n              if (jobID \u003d\u003d null) {\n                LOG.warn(\"File skipped: Invalid file name: \"\n                    + filePair.first());\n                continue;\n              }\n              if ((jobBuilder \u003d\u003d null)\n                  || (!jobBuilder.getJobID().equals(jobID))) {\n                if (jobBuilder !\u003d null) {\n                  traceWriter.output(jobBuilder.build());\n                }\n                jobBuilder \u003d new JobBuilder(jobID);\n              }\n\n              if (JobHistoryUtils.isJobConfXml(filePair.first())) {\n                processJobConf(JobConfigurationParser.parse(ris.rewind()),\n                               jobBuilder);\n              } else {\n                parser \u003d JobHistoryParserFactory.getParser(ris);\n                if (parser \u003d\u003d null) {\n                  LOG.warn(\"File skipped: Cannot find suitable parser: \"\n                      + filePair.first());\n                } else {\n                  processJobHistory(parser, jobBuilder);\n                }\n              }\n            } finally {\n              if (parser \u003d\u003d null) {\n                ris.close();\n              } else {\n                parser.close();\n                parser \u003d null;\n              }\n            }\n          }\n        } catch (Throwable t) {\n          if (filePair !\u003d null) {\n            LOG.warn(\"TraceBuilder got an error while processing the [possibly virtual] file \"\n                + filePair.first() + \" within Path \" + p , t);\n          }\n        } finally {\n          inputDemuxer.close();\n        }\n      }\n      if (jobBuilder !\u003d null) {\n        traceWriter.output(jobBuilder.build());\n        jobBuilder \u003d null;\n      } else {\n        LOG.warn(\"No job found in traces: \");\n      }\n\n      topologyWriter.output(topologyBuilder.build());\n    } finally {\n      traceWriter.close();\n      topologyWriter.close();\n    }\n\n    return 0;\n  }",
      "path": "hadoop-tools/hadoop-rumen/src/main/java/org/apache/hadoop/tools/rumen/TraceBuilder.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce-project/src/tools/org/apache/hadoop/tools/rumen/TraceBuilder.java",
        "newPath": "hadoop-tools/hadoop-rumen/src/main/java/org/apache/hadoop/tools/rumen/TraceBuilder.java"
      }
    },
    "efb3cd64a28d9425f0bbbac97fb085c525bc92ea": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3157. [Rumen] Fix TraceBuilder to handle 0.20 history file names also.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1182293 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/10/11 2:58 AM",
      "commitName": "efb3cd64a28d9425f0bbbac97fb085c525bc92ea",
      "commitAuthor": "Ravi Gummadi",
      "commitDateOld": "24/08/11 5:14 PM",
      "commitNameOld": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 48.41,
      "commitsBetweenForRepo": 324,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,89 +1,90 @@\n   public int run(String[] args) throws Exception {\n     MyOptions options \u003d new MyOptions(args, getConf());\n     traceWriter \u003d options.clazzTraceOutputter.newInstance();\n     traceWriter.init(options.traceOutput, getConf());\n     topologyWriter \u003d new DefaultOutputter\u003cLoggedNetworkTopology\u003e();\n     topologyWriter.init(options.topologyOutput, getConf());\n \n     try {\n       JobBuilder jobBuilder \u003d null;\n \n       for (Path p : options.inputs) {\n         InputDemuxer inputDemuxer \u003d options.inputDemuxerClass.newInstance();\n \n         try {\n           inputDemuxer.bindTo(p, getConf());\n         } catch (IOException e) {\n           LOG.warn(\"Unable to bind Path \" + p + \" .  Skipping...\", e);\n \n           continue;\n         }\n \n         Pair\u003cString, InputStream\u003e filePair \u003d null;\n \n         try {\n           while ((filePair \u003d inputDemuxer.getNext()) !\u003d null) {\n             RewindableInputStream ris \u003d\n                 new RewindableInputStream(filePair.second());\n \n             JobHistoryParser parser \u003d null;\n \n             try {\n-              String jobID \u003d extractJobID(filePair.first());\n+              String jobID \u003d JobHistoryUtils.extractJobID(filePair.first());\n               if (jobID \u003d\u003d null) {\n                 LOG.warn(\"File skipped: Invalid file name: \"\n                     + filePair.first());\n                 continue;\n               }\n               if ((jobBuilder \u003d\u003d null)\n                   || (!jobBuilder.getJobID().equals(jobID))) {\n                 if (jobBuilder !\u003d null) {\n                   traceWriter.output(jobBuilder.build());\n                 }\n                 jobBuilder \u003d new JobBuilder(jobID);\n               }\n \n-              if (isJobConfXml(filePair.first(), ris)) {\n-            \tprocessJobConf(JobConfigurationParser.parse(ris.rewind()), jobBuilder);\n+              if (JobHistoryUtils.isJobConfXml(filePair.first())) {\n+                processJobConf(JobConfigurationParser.parse(ris.rewind()),\n+                               jobBuilder);\n               } else {\n                 parser \u003d JobHistoryParserFactory.getParser(ris);\n                 if (parser \u003d\u003d null) {\n                   LOG.warn(\"File skipped: Cannot find suitable parser: \"\n                       + filePair.first());\n                 } else {\n                   processJobHistory(parser, jobBuilder);\n                 }\n               }\n             } finally {\n               if (parser \u003d\u003d null) {\n                 ris.close();\n               } else {\n                 parser.close();\n                 parser \u003d null;\n               }\n             }\n           }\n         } catch (Throwable t) {\n           if (filePair !\u003d null) {\n             LOG.warn(\"TraceBuilder got an error while processing the [possibly virtual] file \"\n                 + filePair.first() + \" within Path \" + p , t);\n           }\n         } finally {\n           inputDemuxer.close();\n         }\n       }\n       if (jobBuilder !\u003d null) {\n         traceWriter.output(jobBuilder.build());\n         jobBuilder \u003d null;\n       } else {\n         LOG.warn(\"No job found in traces: \");\n       }\n \n       topologyWriter.output(topologyBuilder.build());\n     } finally {\n       traceWriter.close();\n       topologyWriter.close();\n     }\n \n     return 0;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int run(String[] args) throws Exception {\n    MyOptions options \u003d new MyOptions(args, getConf());\n    traceWriter \u003d options.clazzTraceOutputter.newInstance();\n    traceWriter.init(options.traceOutput, getConf());\n    topologyWriter \u003d new DefaultOutputter\u003cLoggedNetworkTopology\u003e();\n    topologyWriter.init(options.topologyOutput, getConf());\n\n    try {\n      JobBuilder jobBuilder \u003d null;\n\n      for (Path p : options.inputs) {\n        InputDemuxer inputDemuxer \u003d options.inputDemuxerClass.newInstance();\n\n        try {\n          inputDemuxer.bindTo(p, getConf());\n        } catch (IOException e) {\n          LOG.warn(\"Unable to bind Path \" + p + \" .  Skipping...\", e);\n\n          continue;\n        }\n\n        Pair\u003cString, InputStream\u003e filePair \u003d null;\n\n        try {\n          while ((filePair \u003d inputDemuxer.getNext()) !\u003d null) {\n            RewindableInputStream ris \u003d\n                new RewindableInputStream(filePair.second());\n\n            JobHistoryParser parser \u003d null;\n\n            try {\n              String jobID \u003d JobHistoryUtils.extractJobID(filePair.first());\n              if (jobID \u003d\u003d null) {\n                LOG.warn(\"File skipped: Invalid file name: \"\n                    + filePair.first());\n                continue;\n              }\n              if ((jobBuilder \u003d\u003d null)\n                  || (!jobBuilder.getJobID().equals(jobID))) {\n                if (jobBuilder !\u003d null) {\n                  traceWriter.output(jobBuilder.build());\n                }\n                jobBuilder \u003d new JobBuilder(jobID);\n              }\n\n              if (JobHistoryUtils.isJobConfXml(filePair.first())) {\n                processJobConf(JobConfigurationParser.parse(ris.rewind()),\n                               jobBuilder);\n              } else {\n                parser \u003d JobHistoryParserFactory.getParser(ris);\n                if (parser \u003d\u003d null) {\n                  LOG.warn(\"File skipped: Cannot find suitable parser: \"\n                      + filePair.first());\n                } else {\n                  processJobHistory(parser, jobBuilder);\n                }\n              }\n            } finally {\n              if (parser \u003d\u003d null) {\n                ris.close();\n              } else {\n                parser.close();\n                parser \u003d null;\n              }\n            }\n          }\n        } catch (Throwable t) {\n          if (filePair !\u003d null) {\n            LOG.warn(\"TraceBuilder got an error while processing the [possibly virtual] file \"\n                + filePair.first() + \" within Path \" + p , t);\n          }\n        } finally {\n          inputDemuxer.close();\n        }\n      }\n      if (jobBuilder !\u003d null) {\n        traceWriter.output(jobBuilder.build());\n        jobBuilder \u003d null;\n      } else {\n        LOG.warn(\"No job found in traces: \");\n      }\n\n      topologyWriter.output(topologyBuilder.build());\n    } finally {\n      traceWriter.close();\n      topologyWriter.close();\n    }\n\n    return 0;\n  }",
      "path": "hadoop-mapreduce-project/src/tools/org/apache/hadoop/tools/rumen/TraceBuilder.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public int run(String[] args) throws Exception {\n    MyOptions options \u003d new MyOptions(args, getConf());\n    traceWriter \u003d options.clazzTraceOutputter.newInstance();\n    traceWriter.init(options.traceOutput, getConf());\n    topologyWriter \u003d new DefaultOutputter\u003cLoggedNetworkTopology\u003e();\n    topologyWriter.init(options.topologyOutput, getConf());\n\n    try {\n      JobBuilder jobBuilder \u003d null;\n\n      for (Path p : options.inputs) {\n        InputDemuxer inputDemuxer \u003d options.inputDemuxerClass.newInstance();\n\n        try {\n          inputDemuxer.bindTo(p, getConf());\n        } catch (IOException e) {\n          LOG.warn(\"Unable to bind Path \" + p + \" .  Skipping...\", e);\n\n          continue;\n        }\n\n        Pair\u003cString, InputStream\u003e filePair \u003d null;\n\n        try {\n          while ((filePair \u003d inputDemuxer.getNext()) !\u003d null) {\n            RewindableInputStream ris \u003d\n                new RewindableInputStream(filePair.second());\n\n            JobHistoryParser parser \u003d null;\n\n            try {\n              String jobID \u003d extractJobID(filePair.first());\n              if (jobID \u003d\u003d null) {\n                LOG.warn(\"File skipped: Invalid file name: \"\n                    + filePair.first());\n                continue;\n              }\n              if ((jobBuilder \u003d\u003d null)\n                  || (!jobBuilder.getJobID().equals(jobID))) {\n                if (jobBuilder !\u003d null) {\n                  traceWriter.output(jobBuilder.build());\n                }\n                jobBuilder \u003d new JobBuilder(jobID);\n              }\n\n              if (isJobConfXml(filePair.first(), ris)) {\n            \tprocessJobConf(JobConfigurationParser.parse(ris.rewind()), jobBuilder);\n              } else {\n                parser \u003d JobHistoryParserFactory.getParser(ris);\n                if (parser \u003d\u003d null) {\n                  LOG.warn(\"File skipped: Cannot find suitable parser: \"\n                      + filePair.first());\n                } else {\n                  processJobHistory(parser, jobBuilder);\n                }\n              }\n            } finally {\n              if (parser \u003d\u003d null) {\n                ris.close();\n              } else {\n                parser.close();\n                parser \u003d null;\n              }\n            }\n          }\n        } catch (Throwable t) {\n          if (filePair !\u003d null) {\n            LOG.warn(\"TraceBuilder got an error while processing the [possibly virtual] file \"\n                + filePair.first() + \" within Path \" + p , t);\n          }\n        } finally {\n          inputDemuxer.close();\n        }\n      }\n      if (jobBuilder !\u003d null) {\n        traceWriter.output(jobBuilder.build());\n        jobBuilder \u003d null;\n      } else {\n        LOG.warn(\"No job found in traces: \");\n      }\n\n      topologyWriter.output(topologyBuilder.build());\n    } finally {\n      traceWriter.close();\n      topologyWriter.close();\n    }\n\n    return 0;\n  }",
      "path": "hadoop-mapreduce-project/src/tools/org/apache/hadoop/tools/rumen/TraceBuilder.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/src/tools/org/apache/hadoop/tools/rumen/TraceBuilder.java",
        "newPath": "hadoop-mapreduce-project/src/tools/org/apache/hadoop/tools/rumen/TraceBuilder.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yfilerename",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "17/08/11 8:02 PM",
      "commitNameOld": "dd86860633d2ed64705b669a75bf318442ed6225",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 0.34,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public int run(String[] args) throws Exception {\n    MyOptions options \u003d new MyOptions(args, getConf());\n    traceWriter \u003d options.clazzTraceOutputter.newInstance();\n    traceWriter.init(options.traceOutput, getConf());\n    topologyWriter \u003d new DefaultOutputter\u003cLoggedNetworkTopology\u003e();\n    topologyWriter.init(options.topologyOutput, getConf());\n\n    try {\n      JobBuilder jobBuilder \u003d null;\n\n      for (Path p : options.inputs) {\n        InputDemuxer inputDemuxer \u003d options.inputDemuxerClass.newInstance();\n\n        try {\n          inputDemuxer.bindTo(p, getConf());\n        } catch (IOException e) {\n          LOG.warn(\"Unable to bind Path \" + p + \" .  Skipping...\", e);\n\n          continue;\n        }\n\n        Pair\u003cString, InputStream\u003e filePair \u003d null;\n\n        try {\n          while ((filePair \u003d inputDemuxer.getNext()) !\u003d null) {\n            RewindableInputStream ris \u003d\n                new RewindableInputStream(filePair.second());\n\n            JobHistoryParser parser \u003d null;\n\n            try {\n              String jobID \u003d extractJobID(filePair.first());\n              if (jobID \u003d\u003d null) {\n                LOG.warn(\"File skipped: Invalid file name: \"\n                    + filePair.first());\n                continue;\n              }\n              if ((jobBuilder \u003d\u003d null)\n                  || (!jobBuilder.getJobID().equals(jobID))) {\n                if (jobBuilder !\u003d null) {\n                  traceWriter.output(jobBuilder.build());\n                }\n                jobBuilder \u003d new JobBuilder(jobID);\n              }\n\n              if (isJobConfXml(filePair.first(), ris)) {\n            \tprocessJobConf(JobConfigurationParser.parse(ris.rewind()), jobBuilder);\n              } else {\n                parser \u003d JobHistoryParserFactory.getParser(ris);\n                if (parser \u003d\u003d null) {\n                  LOG.warn(\"File skipped: Cannot find suitable parser: \"\n                      + filePair.first());\n                } else {\n                  processJobHistory(parser, jobBuilder);\n                }\n              }\n            } finally {\n              if (parser \u003d\u003d null) {\n                ris.close();\n              } else {\n                parser.close();\n                parser \u003d null;\n              }\n            }\n          }\n        } catch (Throwable t) {\n          if (filePair !\u003d null) {\n            LOG.warn(\"TraceBuilder got an error while processing the [possibly virtual] file \"\n                + filePair.first() + \" within Path \" + p , t);\n          }\n        } finally {\n          inputDemuxer.close();\n        }\n      }\n      if (jobBuilder !\u003d null) {\n        traceWriter.output(jobBuilder.build());\n        jobBuilder \u003d null;\n      } else {\n        LOG.warn(\"No job found in traces: \");\n      }\n\n      topologyWriter.output(topologyBuilder.build());\n    } finally {\n      traceWriter.close();\n      topologyWriter.close();\n    }\n\n    return 0;\n  }",
      "path": "hadoop-mapreduce/src/tools/org/apache/hadoop/tools/rumen/TraceBuilder.java",
      "extendedDetails": {
        "oldPath": "mapreduce/src/tools/org/apache/hadoop/tools/rumen/TraceBuilder.java",
        "newPath": "hadoop-mapreduce/src/tools/org/apache/hadoop/tools/rumen/TraceBuilder.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,89 @@\n+  public int run(String[] args) throws Exception {\n+    MyOptions options \u003d new MyOptions(args, getConf());\n+    traceWriter \u003d options.clazzTraceOutputter.newInstance();\n+    traceWriter.init(options.traceOutput, getConf());\n+    topologyWriter \u003d new DefaultOutputter\u003cLoggedNetworkTopology\u003e();\n+    topologyWriter.init(options.topologyOutput, getConf());\n+\n+    try {\n+      JobBuilder jobBuilder \u003d null;\n+\n+      for (Path p : options.inputs) {\n+        InputDemuxer inputDemuxer \u003d options.inputDemuxerClass.newInstance();\n+\n+        try {\n+          inputDemuxer.bindTo(p, getConf());\n+        } catch (IOException e) {\n+          LOG.warn(\"Unable to bind Path \" + p + \" .  Skipping...\", e);\n+\n+          continue;\n+        }\n+\n+        Pair\u003cString, InputStream\u003e filePair \u003d null;\n+\n+        try {\n+          while ((filePair \u003d inputDemuxer.getNext()) !\u003d null) {\n+            RewindableInputStream ris \u003d\n+                new RewindableInputStream(filePair.second());\n+\n+            JobHistoryParser parser \u003d null;\n+\n+            try {\n+              String jobID \u003d extractJobID(filePair.first());\n+              if (jobID \u003d\u003d null) {\n+                LOG.warn(\"File skipped: Invalid file name: \"\n+                    + filePair.first());\n+                continue;\n+              }\n+              if ((jobBuilder \u003d\u003d null)\n+                  || (!jobBuilder.getJobID().equals(jobID))) {\n+                if (jobBuilder !\u003d null) {\n+                  traceWriter.output(jobBuilder.build());\n+                }\n+                jobBuilder \u003d new JobBuilder(jobID);\n+              }\n+\n+              if (isJobConfXml(filePair.first(), ris)) {\n+            \tprocessJobConf(JobConfigurationParser.parse(ris.rewind()), jobBuilder);\n+              } else {\n+                parser \u003d JobHistoryParserFactory.getParser(ris);\n+                if (parser \u003d\u003d null) {\n+                  LOG.warn(\"File skipped: Cannot find suitable parser: \"\n+                      + filePair.first());\n+                } else {\n+                  processJobHistory(parser, jobBuilder);\n+                }\n+              }\n+            } finally {\n+              if (parser \u003d\u003d null) {\n+                ris.close();\n+              } else {\n+                parser.close();\n+                parser \u003d null;\n+              }\n+            }\n+          }\n+        } catch (Throwable t) {\n+          if (filePair !\u003d null) {\n+            LOG.warn(\"TraceBuilder got an error while processing the [possibly virtual] file \"\n+                + filePair.first() + \" within Path \" + p , t);\n+          }\n+        } finally {\n+          inputDemuxer.close();\n+        }\n+      }\n+      if (jobBuilder !\u003d null) {\n+        traceWriter.output(jobBuilder.build());\n+        jobBuilder \u003d null;\n+      } else {\n+        LOG.warn(\"No job found in traces: \");\n+      }\n+\n+      topologyWriter.output(topologyBuilder.build());\n+    } finally {\n+      traceWriter.close();\n+      topologyWriter.close();\n+    }\n+\n+    return 0;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public int run(String[] args) throws Exception {\n    MyOptions options \u003d new MyOptions(args, getConf());\n    traceWriter \u003d options.clazzTraceOutputter.newInstance();\n    traceWriter.init(options.traceOutput, getConf());\n    topologyWriter \u003d new DefaultOutputter\u003cLoggedNetworkTopology\u003e();\n    topologyWriter.init(options.topologyOutput, getConf());\n\n    try {\n      JobBuilder jobBuilder \u003d null;\n\n      for (Path p : options.inputs) {\n        InputDemuxer inputDemuxer \u003d options.inputDemuxerClass.newInstance();\n\n        try {\n          inputDemuxer.bindTo(p, getConf());\n        } catch (IOException e) {\n          LOG.warn(\"Unable to bind Path \" + p + \" .  Skipping...\", e);\n\n          continue;\n        }\n\n        Pair\u003cString, InputStream\u003e filePair \u003d null;\n\n        try {\n          while ((filePair \u003d inputDemuxer.getNext()) !\u003d null) {\n            RewindableInputStream ris \u003d\n                new RewindableInputStream(filePair.second());\n\n            JobHistoryParser parser \u003d null;\n\n            try {\n              String jobID \u003d extractJobID(filePair.first());\n              if (jobID \u003d\u003d null) {\n                LOG.warn(\"File skipped: Invalid file name: \"\n                    + filePair.first());\n                continue;\n              }\n              if ((jobBuilder \u003d\u003d null)\n                  || (!jobBuilder.getJobID().equals(jobID))) {\n                if (jobBuilder !\u003d null) {\n                  traceWriter.output(jobBuilder.build());\n                }\n                jobBuilder \u003d new JobBuilder(jobID);\n              }\n\n              if (isJobConfXml(filePair.first(), ris)) {\n            \tprocessJobConf(JobConfigurationParser.parse(ris.rewind()), jobBuilder);\n              } else {\n                parser \u003d JobHistoryParserFactory.getParser(ris);\n                if (parser \u003d\u003d null) {\n                  LOG.warn(\"File skipped: Cannot find suitable parser: \"\n                      + filePair.first());\n                } else {\n                  processJobHistory(parser, jobBuilder);\n                }\n              }\n            } finally {\n              if (parser \u003d\u003d null) {\n                ris.close();\n              } else {\n                parser.close();\n                parser \u003d null;\n              }\n            }\n          }\n        } catch (Throwable t) {\n          if (filePair !\u003d null) {\n            LOG.warn(\"TraceBuilder got an error while processing the [possibly virtual] file \"\n                + filePair.first() + \" within Path \" + p , t);\n          }\n        } finally {\n          inputDemuxer.close();\n        }\n      }\n      if (jobBuilder !\u003d null) {\n        traceWriter.output(jobBuilder.build());\n        jobBuilder \u003d null;\n      } else {\n        LOG.warn(\"No job found in traces: \");\n      }\n\n      topologyWriter.output(topologyBuilder.build());\n    } finally {\n      traceWriter.close();\n      topologyWriter.close();\n    }\n\n    return 0;\n  }",
      "path": "mapreduce/src/tools/org/apache/hadoop/tools/rumen/TraceBuilder.java"
    }
  }
}