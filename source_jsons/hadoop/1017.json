{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FileChecksumHelper.java",
  "functionName": "populateBlockChecksumBuf",
  "functionId": "populateBlockChecksumBuf___checksumData-OpBlockChecksumResponseProto",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/FileChecksumHelper.java",
  "functionStartLine": 443,
  "functionEndLine": 475,
  "numCommitsSeen": 9,
  "timeTaken": 1431,
  "changeHistory": [
    "7c9cdad6d04c98db5a83e2108219bf6e6c903daf"
  ],
  "changeHistoryShort": {
    "7c9cdad6d04c98db5a83e2108219bf6e6c903daf": "Yintroduced"
  },
  "changeHistoryDetails": {
    "7c9cdad6d04c98db5a83e2108219bf6e6c903daf": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-13056. Expose file-level composite CRCs in HDFS which are comparable across different instances/layouts. Contributed by Dennis Huo.\n",
      "commitDate": "10/04/18 9:31 PM",
      "commitName": "7c9cdad6d04c98db5a83e2108219bf6e6c903daf",
      "commitAuthor": "Xiao Chen",
      "diff": "@@ -0,0 +1,33 @@\n+    String populateBlockChecksumBuf(OpBlockChecksumResponseProto checksumData)\n+        throws IOException {\n+      String blockChecksumForDebug \u003d null;\n+      switch (getBlockChecksumType()) {\n+      case MD5CRC:\n+        //read md5\n+        final MD5Hash md5 \u003d new MD5Hash(\n+            checksumData.getBlockChecksum().toByteArray());\n+        md5.write(getBlockChecksumBuf());\n+        if (LOG.isDebugEnabled()) {\n+          blockChecksumForDebug \u003d md5.toString();\n+        }\n+        break;\n+      case COMPOSITE_CRC:\n+        BlockChecksumType returnedType \u003d PBHelperClient.convert(\n+            checksumData.getBlockChecksumOptions().getBlockChecksumType());\n+        if (returnedType !\u003d BlockChecksumType.COMPOSITE_CRC) {\n+          throw new IOException(String.format(\n+              \"Unexpected blockChecksumType \u0027%s\u0027, expecting COMPOSITE_CRC\",\n+              returnedType));\n+        }\n+        byte[] crcBytes \u003d checksumData.getBlockChecksum().toByteArray();\n+        if (LOG.isDebugEnabled()) {\n+          blockChecksumForDebug \u003d CrcUtil.toSingleCrcString(crcBytes);\n+        }\n+        getBlockChecksumBuf().write(crcBytes);\n+        break;\n+      default:\n+        throw new IOException(\n+            \"Unknown BlockChecksumType: \" + getBlockChecksumType());\n+      }\n+      return blockChecksumForDebug;\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    String populateBlockChecksumBuf(OpBlockChecksumResponseProto checksumData)\n        throws IOException {\n      String blockChecksumForDebug \u003d null;\n      switch (getBlockChecksumType()) {\n      case MD5CRC:\n        //read md5\n        final MD5Hash md5 \u003d new MD5Hash(\n            checksumData.getBlockChecksum().toByteArray());\n        md5.write(getBlockChecksumBuf());\n        if (LOG.isDebugEnabled()) {\n          blockChecksumForDebug \u003d md5.toString();\n        }\n        break;\n      case COMPOSITE_CRC:\n        BlockChecksumType returnedType \u003d PBHelperClient.convert(\n            checksumData.getBlockChecksumOptions().getBlockChecksumType());\n        if (returnedType !\u003d BlockChecksumType.COMPOSITE_CRC) {\n          throw new IOException(String.format(\n              \"Unexpected blockChecksumType \u0027%s\u0027, expecting COMPOSITE_CRC\",\n              returnedType));\n        }\n        byte[] crcBytes \u003d checksumData.getBlockChecksum().toByteArray();\n        if (LOG.isDebugEnabled()) {\n          blockChecksumForDebug \u003d CrcUtil.toSingleCrcString(crcBytes);\n        }\n        getBlockChecksumBuf().write(crcBytes);\n        break;\n      default:\n        throw new IOException(\n            \"Unknown BlockChecksumType: \" + getBlockChecksumType());\n      }\n      return blockChecksumForDebug;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/FileChecksumHelper.java"
    }
  }
}