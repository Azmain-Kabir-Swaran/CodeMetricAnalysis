{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "LocalJobRunner.java",
  "functionName": "createOutputCommitter",
  "functionId": "createOutputCommitter___newApiCommitter-boolean__jobId-JobID__conf-Configuration",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common/src/main/java/org/apache/hadoop/mapred/LocalJobRunner.java",
  "functionStartLine": 498,
  "functionEndLine": 521,
  "numCommitsSeen": 17,
  "timeTaken": 1045,
  "changeHistory": [
    "a61a18cc098591eacd998e4a2f61babe27353a31"
  ],
  "changeHistoryShort": {
    "a61a18cc098591eacd998e4a2f61babe27353a31": "Yintroduced"
  },
  "changeHistoryDetails": {
    "a61a18cc098591eacd998e4a2f61babe27353a31": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-3563. Fixed LocalJobRunner to work correctly with new mapreduce apis.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1220996 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/12/11 3:07 PM",
      "commitName": "a61a18cc098591eacd998e4a2f61babe27353a31",
      "commitAuthor": "Arun Murthy",
      "diff": "@@ -0,0 +1,24 @@\n+    createOutputCommitter(boolean newApiCommitter, JobID jobId, Configuration conf) throws Exception {\n+      org.apache.hadoop.mapreduce.OutputCommitter committer \u003d null;\n+\n+      LOG.info(\"OutputCommitter set in config \"\n+          + conf.get(\"mapred.output.committer.class\"));\n+\n+      if (newApiCommitter) {\n+        org.apache.hadoop.mapreduce.TaskID taskId \u003d\n+            new org.apache.hadoop.mapreduce.TaskID(jobId, TaskType.MAP, 0);\n+        org.apache.hadoop.mapreduce.TaskAttemptID taskAttemptID \u003d\n+            new org.apache.hadoop.mapreduce.TaskAttemptID(taskId, 0);\n+        org.apache.hadoop.mapreduce.TaskAttemptContext taskContext \u003d \n+            new TaskAttemptContextImpl(conf, taskAttemptID);\n+        OutputFormat outputFormat \u003d\n+          ReflectionUtils.newInstance(taskContext.getOutputFormatClass(), conf);\n+        committer \u003d outputFormat.getOutputCommitter(taskContext);\n+      } else {\n+        committer \u003d ReflectionUtils.newInstance(conf.getClass(\n+            \"mapred.output.committer.class\", FileOutputCommitter.class,\n+            org.apache.hadoop.mapred.OutputCommitter.class), conf);\n+      }\n+      LOG.info(\"OutputCommitter is \" + committer.getClass().getName());\n+      return committer;\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    createOutputCommitter(boolean newApiCommitter, JobID jobId, Configuration conf) throws Exception {\n      org.apache.hadoop.mapreduce.OutputCommitter committer \u003d null;\n\n      LOG.info(\"OutputCommitter set in config \"\n          + conf.get(\"mapred.output.committer.class\"));\n\n      if (newApiCommitter) {\n        org.apache.hadoop.mapreduce.TaskID taskId \u003d\n            new org.apache.hadoop.mapreduce.TaskID(jobId, TaskType.MAP, 0);\n        org.apache.hadoop.mapreduce.TaskAttemptID taskAttemptID \u003d\n            new org.apache.hadoop.mapreduce.TaskAttemptID(taskId, 0);\n        org.apache.hadoop.mapreduce.TaskAttemptContext taskContext \u003d \n            new TaskAttemptContextImpl(conf, taskAttemptID);\n        OutputFormat outputFormat \u003d\n          ReflectionUtils.newInstance(taskContext.getOutputFormatClass(), conf);\n        committer \u003d outputFormat.getOutputCommitter(taskContext);\n      } else {\n        committer \u003d ReflectionUtils.newInstance(conf.getClass(\n            \"mapred.output.committer.class\", FileOutputCommitter.class,\n            org.apache.hadoop.mapred.OutputCommitter.class), conf);\n      }\n      LOG.info(\"OutputCommitter is \" + committer.getClass().getName());\n      return committer;\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common/src/main/java/org/apache/hadoop/mapred/LocalJobRunner.java"
    }
  }
}