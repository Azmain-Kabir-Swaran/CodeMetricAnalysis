{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "AclEntryStatusFormat.java",
  "functionName": "toInt",
  "functionId": "toInt___aclEntry-AclEntry",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/AclEntryStatusFormat.java",
  "functionStartLine": 87,
  "functionEndLine": 100,
  "numCommitsSeen": 3,
  "timeTaken": 1494,
  "changeHistory": [
    "b60ca37914b22550e3630fa02742d40697decb31",
    "0653918dad855b394e8e3b8b3f512f474d872ee9"
  ],
  "changeHistoryShort": {
    "b60ca37914b22550e3630fa02742d40697decb31": "Ybodychange",
    "0653918dad855b394e8e3b8b3f512f474d872ee9": "Yintroduced"
  },
  "changeHistoryDetails": {
    "b60ca37914b22550e3630fa02742d40697decb31": {
      "type": "Ybodychange",
      "commitMessage": "Fix potential FSImage corruption. Contributed by Daryn Sharp.\n",
      "commitDate": "15/10/18 3:18 AM",
      "commitName": "b60ca37914b22550e3630fa02742d40697decb31",
      "commitAuthor": "Vinayakumar B",
      "commitDateOld": "16/07/18 6:24 PM",
      "commitNameOld": "0a1e922f3d8eca4e852be57124ec1bcafaadb289",
      "commitAuthorOld": "Konstantin V Shvachko",
      "daysBetweenCommits": 90.37,
      "commitsBetweenForRepo": 802,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,14 @@\n   static int toInt(AclEntry aclEntry) {\n     long aclEntryInt \u003d 0;\n     aclEntryInt \u003d SCOPE.BITS\n         .combine(aclEntry.getScope().ordinal(), aclEntryInt);\n     aclEntryInt \u003d TYPE.BITS.combine(aclEntry.getType().ordinal(), aclEntryInt);\n     aclEntryInt \u003d PERMISSION.BITS.combine(aclEntry.getPermission().ordinal(),\n         aclEntryInt);\n-    if (aclEntry.getName() !\u003d null) {\n-      aclEntryInt \u003d NAMED_ENTRY_CHECK.BITS.combine(1, aclEntryInt);\n-      if (aclEntry.getType() \u003d\u003d AclEntryType.USER) {\n-        int userId \u003d SerialNumberManager.INSTANCE.getUserSerialNumber(aclEntry\n-            .getName());\n-        aclEntryInt \u003d NAME.BITS.combine(userId, aclEntryInt);\n-      } else if (aclEntry.getType() \u003d\u003d AclEntryType.GROUP) {\n-        int groupId \u003d SerialNumberManager.INSTANCE\n-            .getGroupSerialNumber(aclEntry.getName());\n-        aclEntryInt \u003d NAME.BITS.combine(groupId, aclEntryInt);\n-      }\n+    SerialNumberManager snm \u003d getSerialNumberManager(aclEntry.getType());\n+    if (snm !\u003d null) {\n+      int nid \u003d snm.getSerialNumber(aclEntry.getName());\n+      aclEntryInt \u003d NAME.BITS.combine(nid, aclEntryInt);\n     }\n     return (int) aclEntryInt;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static int toInt(AclEntry aclEntry) {\n    long aclEntryInt \u003d 0;\n    aclEntryInt \u003d SCOPE.BITS\n        .combine(aclEntry.getScope().ordinal(), aclEntryInt);\n    aclEntryInt \u003d TYPE.BITS.combine(aclEntry.getType().ordinal(), aclEntryInt);\n    aclEntryInt \u003d PERMISSION.BITS.combine(aclEntry.getPermission().ordinal(),\n        aclEntryInt);\n    SerialNumberManager snm \u003d getSerialNumberManager(aclEntry.getType());\n    if (snm !\u003d null) {\n      int nid \u003d snm.getSerialNumber(aclEntry.getName());\n      aclEntryInt \u003d NAME.BITS.combine(nid, aclEntryInt);\n    }\n    return (int) aclEntryInt;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/AclEntryStatusFormat.java",
      "extendedDetails": {}
    },
    "0653918dad855b394e8e3b8b3f512f474d872ee9": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-7454. Reduce memory footprint for AclEntries in NameNode. Contributed by Vinayakumar B.\n",
      "commitDate": "04/12/14 8:49 PM",
      "commitName": "0653918dad855b394e8e3b8b3f512f474d872ee9",
      "commitAuthor": "Haohui Mai",
      "diff": "@@ -0,0 +1,21 @@\n+  static int toInt(AclEntry aclEntry) {\n+    long aclEntryInt \u003d 0;\n+    aclEntryInt \u003d SCOPE.BITS\n+        .combine(aclEntry.getScope().ordinal(), aclEntryInt);\n+    aclEntryInt \u003d TYPE.BITS.combine(aclEntry.getType().ordinal(), aclEntryInt);\n+    aclEntryInt \u003d PERMISSION.BITS.combine(aclEntry.getPermission().ordinal(),\n+        aclEntryInt);\n+    if (aclEntry.getName() !\u003d null) {\n+      aclEntryInt \u003d NAMED_ENTRY_CHECK.BITS.combine(1, aclEntryInt);\n+      if (aclEntry.getType() \u003d\u003d AclEntryType.USER) {\n+        int userId \u003d SerialNumberManager.INSTANCE.getUserSerialNumber(aclEntry\n+            .getName());\n+        aclEntryInt \u003d NAME.BITS.combine(userId, aclEntryInt);\n+      } else if (aclEntry.getType() \u003d\u003d AclEntryType.GROUP) {\n+        int groupId \u003d SerialNumberManager.INSTANCE\n+            .getGroupSerialNumber(aclEntry.getName());\n+        aclEntryInt \u003d NAME.BITS.combine(groupId, aclEntryInt);\n+      }\n+    }\n+    return (int) aclEntryInt;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  static int toInt(AclEntry aclEntry) {\n    long aclEntryInt \u003d 0;\n    aclEntryInt \u003d SCOPE.BITS\n        .combine(aclEntry.getScope().ordinal(), aclEntryInt);\n    aclEntryInt \u003d TYPE.BITS.combine(aclEntry.getType().ordinal(), aclEntryInt);\n    aclEntryInt \u003d PERMISSION.BITS.combine(aclEntry.getPermission().ordinal(),\n        aclEntryInt);\n    if (aclEntry.getName() !\u003d null) {\n      aclEntryInt \u003d NAMED_ENTRY_CHECK.BITS.combine(1, aclEntryInt);\n      if (aclEntry.getType() \u003d\u003d AclEntryType.USER) {\n        int userId \u003d SerialNumberManager.INSTANCE.getUserSerialNumber(aclEntry\n            .getName());\n        aclEntryInt \u003d NAME.BITS.combine(userId, aclEntryInt);\n      } else if (aclEntry.getType() \u003d\u003d AclEntryType.GROUP) {\n        int groupId \u003d SerialNumberManager.INSTANCE\n            .getGroupSerialNumber(aclEntry.getName());\n        aclEntryInt \u003d NAME.BITS.combine(groupId, aclEntryInt);\n      }\n    }\n    return (int) aclEntryInt;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/AclEntryStatusFormat.java"
    }
  }
}