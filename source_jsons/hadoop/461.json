{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockReaderLocal.java",
  "functionName": "read",
  "functionId": "read___buf-ByteBuffer",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/client/impl/BlockReaderLocal.java",
  "functionStartLine": 412,
  "functionEndLine": 437,
  "numCommitsSeen": 47,
  "timeTaken": 2921,
  "changeHistory": [
    "f308561f1d885491b88db73ac63003202056d661",
    "39285e6a1978ea5e53bdc1b0aef62421382124a8",
    "6ee0539ede78b640f01c5eac18ded161182a7835",
    "d5a9a3daa0224249221ffa7b8bd5751ab2feca56",
    "e2c9b288b223b9fd82dc12018936e13128413492",
    "dd049a2f6097da189ccce2f5890a2b9bc77fa73f",
    "124e507674c0d396f8494585e64226957199097b",
    "f55a1c08763e5f865fd9193d640c89a06ab49c4a"
  ],
  "changeHistoryShort": {
    "f308561f1d885491b88db73ac63003202056d661": "Yfilerename",
    "39285e6a1978ea5e53bdc1b0aef62421382124a8": "Ybodychange",
    "6ee0539ede78b640f01c5eac18ded161182a7835": "Ybodychange",
    "d5a9a3daa0224249221ffa7b8bd5751ab2feca56": "Ybodychange",
    "e2c9b288b223b9fd82dc12018936e13128413492": "Yfilerename",
    "dd049a2f6097da189ccce2f5890a2b9bc77fa73f": "Ybodychange",
    "124e507674c0d396f8494585e64226957199097b": "Ybodychange",
    "f55a1c08763e5f865fd9193d640c89a06ab49c4a": "Yintroduced"
  },
  "changeHistoryDetails": {
    "f308561f1d885491b88db73ac63003202056d661": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8057 Move BlockReader implementation to the client implementation package.  Contributed by Takanobu Asanuma\n",
      "commitDate": "25/04/16 12:01 PM",
      "commitName": "f308561f1d885491b88db73ac63003202056d661",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "25/04/16 9:38 AM",
      "commitNameOld": "10f0f7851a3255caab775777e8fb6c2781d97062",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 0.1,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public synchronized int read(ByteBuffer buf) throws IOException {\n    boolean canSkipChecksum \u003d createNoChecksumContext();\n    try {\n      String traceFormatStr \u003d \"read(buf.remaining\u003d{}, block\u003d{}, filename\u003d{}, \"\n          + \"canSkipChecksum\u003d{})\";\n      LOG.trace(traceFormatStr + \": starting\",\n          buf.remaining(), block, filename, canSkipChecksum);\n      int nRead;\n      try {\n        if (canSkipChecksum \u0026\u0026 zeroReadaheadRequested) {\n          nRead \u003d readWithoutBounceBuffer(buf);\n        } else {\n          nRead \u003d readWithBounceBuffer(buf, canSkipChecksum);\n        }\n      } catch (IOException e) {\n        LOG.trace(traceFormatStr + \": I/O error\",\n            buf.remaining(), block, filename, canSkipChecksum, e);\n        throw e;\n      }\n      LOG.trace(traceFormatStr + \": returning {}\",\n          buf.remaining(), block, filename, canSkipChecksum, nRead);\n      return nRead;\n    } finally {\n      if (canSkipChecksum) releaseNoChecksumContext();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/client/impl/BlockReaderLocal.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocal.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/client/impl/BlockReaderLocal.java"
      }
    },
    "39285e6a1978ea5e53bdc1b0aef62421382124a8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8971. Remove guards when calling LOG.debug() and LOG.trace() in client package. Contributed by Mingliang Liu.\n",
      "commitDate": "29/09/15 5:52 PM",
      "commitName": "39285e6a1978ea5e53bdc1b0aef62421382124a8",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "29/09/15 5:51 PM",
      "commitNameOld": "6ee0539ede78b640f01c5eac18ded161182a7835",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,35 +1,26 @@\n   public synchronized int read(ByteBuffer buf) throws IOException {\n     boolean canSkipChecksum \u003d createNoChecksumContext();\n     try {\n-      String traceString \u003d null;\n-      if (LOG.isTraceEnabled()) {\n-        traceString \u003d new StringBuilder().\n-            append(\"read(\").\n-            append(\"buf.remaining\u003d\").append(buf.remaining()).\n-            append(\", block\u003d\").append(block).\n-            append(\", filename\u003d\").append(filename).\n-            append(\", canSkipChecksum\u003d\").append(canSkipChecksum).\n-            append(\")\").toString();\n-        LOG.info(traceString + \": starting\");\n-      }\n+      String traceFormatStr \u003d \"read(buf.remaining\u003d{}, block\u003d{}, filename\u003d{}, \"\n+          + \"canSkipChecksum\u003d{})\";\n+      LOG.trace(traceFormatStr + \": starting\",\n+          buf.remaining(), block, filename, canSkipChecksum);\n       int nRead;\n       try {\n         if (canSkipChecksum \u0026\u0026 zeroReadaheadRequested) {\n           nRead \u003d readWithoutBounceBuffer(buf);\n         } else {\n           nRead \u003d readWithBounceBuffer(buf, canSkipChecksum);\n         }\n       } catch (IOException e) {\n-        if (LOG.isTraceEnabled()) {\n-          LOG.info(traceString + \": I/O error\", e);\n-        }\n+        LOG.trace(traceFormatStr + \": I/O error\",\n+            buf.remaining(), block, filename, canSkipChecksum, e);\n         throw e;\n       }\n-      if (LOG.isTraceEnabled()) {\n-        LOG.info(traceString + \": returning \" + nRead);\n-      }\n+      LOG.trace(traceFormatStr + \": returning {}\",\n+          buf.remaining(), block, filename, canSkipChecksum, nRead);\n       return nRead;\n     } finally {\n       if (canSkipChecksum) releaseNoChecksumContext();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized int read(ByteBuffer buf) throws IOException {\n    boolean canSkipChecksum \u003d createNoChecksumContext();\n    try {\n      String traceFormatStr \u003d \"read(buf.remaining\u003d{}, block\u003d{}, filename\u003d{}, \"\n          + \"canSkipChecksum\u003d{})\";\n      LOG.trace(traceFormatStr + \": starting\",\n          buf.remaining(), block, filename, canSkipChecksum);\n      int nRead;\n      try {\n        if (canSkipChecksum \u0026\u0026 zeroReadaheadRequested) {\n          nRead \u003d readWithoutBounceBuffer(buf);\n        } else {\n          nRead \u003d readWithBounceBuffer(buf, canSkipChecksum);\n        }\n      } catch (IOException e) {\n        LOG.trace(traceFormatStr + \": I/O error\",\n            buf.remaining(), block, filename, canSkipChecksum, e);\n        throw e;\n      }\n      LOG.trace(traceFormatStr + \": returning {}\",\n          buf.remaining(), block, filename, canSkipChecksum, nRead);\n      return nRead;\n    } finally {\n      if (canSkipChecksum) releaseNoChecksumContext();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocal.java",
      "extendedDetails": {}
    },
    "6ee0539ede78b640f01c5eac18ded161182a7835": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-9170. Move libhdfs / fuse-dfs / libwebhdfs to hdfs-client. Contributed by Haohui Mai.\"\n\nThis reverts commit d5a9a3daa0224249221ffa7b8bd5751ab2feca56.\n",
      "commitDate": "29/09/15 5:51 PM",
      "commitName": "6ee0539ede78b640f01c5eac18ded161182a7835",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "29/09/15 5:48 PM",
      "commitNameOld": "d5a9a3daa0224249221ffa7b8bd5751ab2feca56",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,26 +1,35 @@\n   public synchronized int read(ByteBuffer buf) throws IOException {\n     boolean canSkipChecksum \u003d createNoChecksumContext();\n     try {\n-      String traceFormatStr \u003d \"read(buf.remaining\u003d{}, block\u003d{}, filename\u003d{}, \"\n-          + \"canSkipChecksum\u003d{})\";\n-      LOG.trace(traceFormatStr + \": starting\",\n-          buf.remaining(), block, filename, canSkipChecksum);\n+      String traceString \u003d null;\n+      if (LOG.isTraceEnabled()) {\n+        traceString \u003d new StringBuilder().\n+            append(\"read(\").\n+            append(\"buf.remaining\u003d\").append(buf.remaining()).\n+            append(\", block\u003d\").append(block).\n+            append(\", filename\u003d\").append(filename).\n+            append(\", canSkipChecksum\u003d\").append(canSkipChecksum).\n+            append(\")\").toString();\n+        LOG.info(traceString + \": starting\");\n+      }\n       int nRead;\n       try {\n         if (canSkipChecksum \u0026\u0026 zeroReadaheadRequested) {\n           nRead \u003d readWithoutBounceBuffer(buf);\n         } else {\n           nRead \u003d readWithBounceBuffer(buf, canSkipChecksum);\n         }\n       } catch (IOException e) {\n-        LOG.trace(traceFormatStr + \": I/O error\",\n-            buf.remaining(), block, filename, canSkipChecksum, e);\n+        if (LOG.isTraceEnabled()) {\n+          LOG.info(traceString + \": I/O error\", e);\n+        }\n         throw e;\n       }\n-      LOG.trace(traceFormatStr + \": returning {}\",\n-          buf.remaining(), block, filename, canSkipChecksum, nRead);\n+      if (LOG.isTraceEnabled()) {\n+        LOG.info(traceString + \": returning \" + nRead);\n+      }\n       return nRead;\n     } finally {\n       if (canSkipChecksum) releaseNoChecksumContext();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized int read(ByteBuffer buf) throws IOException {\n    boolean canSkipChecksum \u003d createNoChecksumContext();\n    try {\n      String traceString \u003d null;\n      if (LOG.isTraceEnabled()) {\n        traceString \u003d new StringBuilder().\n            append(\"read(\").\n            append(\"buf.remaining\u003d\").append(buf.remaining()).\n            append(\", block\u003d\").append(block).\n            append(\", filename\u003d\").append(filename).\n            append(\", canSkipChecksum\u003d\").append(canSkipChecksum).\n            append(\")\").toString();\n        LOG.info(traceString + \": starting\");\n      }\n      int nRead;\n      try {\n        if (canSkipChecksum \u0026\u0026 zeroReadaheadRequested) {\n          nRead \u003d readWithoutBounceBuffer(buf);\n        } else {\n          nRead \u003d readWithBounceBuffer(buf, canSkipChecksum);\n        }\n      } catch (IOException e) {\n        if (LOG.isTraceEnabled()) {\n          LOG.info(traceString + \": I/O error\", e);\n        }\n        throw e;\n      }\n      if (LOG.isTraceEnabled()) {\n        LOG.info(traceString + \": returning \" + nRead);\n      }\n      return nRead;\n    } finally {\n      if (canSkipChecksum) releaseNoChecksumContext();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocal.java",
      "extendedDetails": {}
    },
    "d5a9a3daa0224249221ffa7b8bd5751ab2feca56": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9170. Move libhdfs / fuse-dfs / libwebhdfs to hdfs-client. Contributed by Haohui Mai.\n",
      "commitDate": "29/09/15 5:48 PM",
      "commitName": "d5a9a3daa0224249221ffa7b8bd5751ab2feca56",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "28/09/15 7:42 AM",
      "commitNameOld": "892ade689f9bcce76daae8f66fc00a49bee8548e",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 1.42,
      "commitsBetweenForRepo": 19,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,35 +1,26 @@\n   public synchronized int read(ByteBuffer buf) throws IOException {\n     boolean canSkipChecksum \u003d createNoChecksumContext();\n     try {\n-      String traceString \u003d null;\n-      if (LOG.isTraceEnabled()) {\n-        traceString \u003d new StringBuilder().\n-            append(\"read(\").\n-            append(\"buf.remaining\u003d\").append(buf.remaining()).\n-            append(\", block\u003d\").append(block).\n-            append(\", filename\u003d\").append(filename).\n-            append(\", canSkipChecksum\u003d\").append(canSkipChecksum).\n-            append(\")\").toString();\n-        LOG.info(traceString + \": starting\");\n-      }\n+      String traceFormatStr \u003d \"read(buf.remaining\u003d{}, block\u003d{}, filename\u003d{}, \"\n+          + \"canSkipChecksum\u003d{})\";\n+      LOG.trace(traceFormatStr + \": starting\",\n+          buf.remaining(), block, filename, canSkipChecksum);\n       int nRead;\n       try {\n         if (canSkipChecksum \u0026\u0026 zeroReadaheadRequested) {\n           nRead \u003d readWithoutBounceBuffer(buf);\n         } else {\n           nRead \u003d readWithBounceBuffer(buf, canSkipChecksum);\n         }\n       } catch (IOException e) {\n-        if (LOG.isTraceEnabled()) {\n-          LOG.info(traceString + \": I/O error\", e);\n-        }\n+        LOG.trace(traceFormatStr + \": I/O error\",\n+            buf.remaining(), block, filename, canSkipChecksum, e);\n         throw e;\n       }\n-      if (LOG.isTraceEnabled()) {\n-        LOG.info(traceString + \": returning \" + nRead);\n-      }\n+      LOG.trace(traceFormatStr + \": returning {}\",\n+          buf.remaining(), block, filename, canSkipChecksum, nRead);\n       return nRead;\n     } finally {\n       if (canSkipChecksum) releaseNoChecksumContext();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized int read(ByteBuffer buf) throws IOException {\n    boolean canSkipChecksum \u003d createNoChecksumContext();\n    try {\n      String traceFormatStr \u003d \"read(buf.remaining\u003d{}, block\u003d{}, filename\u003d{}, \"\n          + \"canSkipChecksum\u003d{})\";\n      LOG.trace(traceFormatStr + \": starting\",\n          buf.remaining(), block, filename, canSkipChecksum);\n      int nRead;\n      try {\n        if (canSkipChecksum \u0026\u0026 zeroReadaheadRequested) {\n          nRead \u003d readWithoutBounceBuffer(buf);\n        } else {\n          nRead \u003d readWithBounceBuffer(buf, canSkipChecksum);\n        }\n      } catch (IOException e) {\n        LOG.trace(traceFormatStr + \": I/O error\",\n            buf.remaining(), block, filename, canSkipChecksum, e);\n        throw e;\n      }\n      LOG.trace(traceFormatStr + \": returning {}\",\n          buf.remaining(), block, filename, canSkipChecksum, nRead);\n      return nRead;\n    } finally {\n      if (canSkipChecksum) releaseNoChecksumContext();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocal.java",
      "extendedDetails": {}
    },
    "e2c9b288b223b9fd82dc12018936e13128413492": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8925. Move BlockReaderLocal to hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "28/08/15 2:38 PM",
      "commitName": "e2c9b288b223b9fd82dc12018936e13128413492",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "28/08/15 2:21 PM",
      "commitNameOld": "b94b56806d3d6e04984e229b479f7ac15b62bbfa",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public synchronized int read(ByteBuffer buf) throws IOException {\n    boolean canSkipChecksum \u003d createNoChecksumContext();\n    try {\n      String traceString \u003d null;\n      if (LOG.isTraceEnabled()) {\n        traceString \u003d new StringBuilder().\n            append(\"read(\").\n            append(\"buf.remaining\u003d\").append(buf.remaining()).\n            append(\", block\u003d\").append(block).\n            append(\", filename\u003d\").append(filename).\n            append(\", canSkipChecksum\u003d\").append(canSkipChecksum).\n            append(\")\").toString();\n        LOG.info(traceString + \": starting\");\n      }\n      int nRead;\n      try {\n        if (canSkipChecksum \u0026\u0026 zeroReadaheadRequested) {\n          nRead \u003d readWithoutBounceBuffer(buf);\n        } else {\n          nRead \u003d readWithBounceBuffer(buf, canSkipChecksum);\n        }\n      } catch (IOException e) {\n        if (LOG.isTraceEnabled()) {\n          LOG.info(traceString + \": I/O error\", e);\n        }\n        throw e;\n      }\n      if (LOG.isTraceEnabled()) {\n        LOG.info(traceString + \": returning \" + nRead);\n      }\n      return nRead;\n    } finally {\n      if (canSkipChecksum) releaseNoChecksumContext();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocal.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocal.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocal.java"
      }
    },
    "dd049a2f6097da189ccce2f5890a2b9bc77fa73f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5950. The DFSClient and DataNode should use shared memory segments to communicate short-circuit information (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1573433 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/03/14 7:58 PM",
      "commitName": "dd049a2f6097da189ccce2f5890a2b9bc77fa73f",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "12/02/14 11:08 AM",
      "commitNameOld": "beb0d25d2a7ba5004c6aabd105546ba9a9fec9be",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 18.37,
      "commitsBetweenForRepo": 140,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,32 +1,35 @@\n   public synchronized int read(ByteBuffer buf) throws IOException {\n-    boolean canSkipChecksum \u003d getCanSkipChecksum();\n-    \n-    String traceString \u003d null;\n-    if (LOG.isTraceEnabled()) {\n-      traceString \u003d new StringBuilder().\n-          append(\"read(\").\n-          append(\"buf.remaining\u003d\").append(buf.remaining()).\n-          append(\", block\u003d\").append(block).\n-          append(\", filename\u003d\").append(filename).\n-          append(\", canSkipChecksum\u003d\").append(canSkipChecksum).\n-          append(\")\").toString();\n-      LOG.info(traceString + \": starting\");\n-    }\n-    int nRead;\n+    boolean canSkipChecksum \u003d createNoChecksumContext();\n     try {\n-      if (canSkipChecksum \u0026\u0026 zeroReadaheadRequested) {\n-        nRead \u003d readWithoutBounceBuffer(buf);\n-      } else {\n-        nRead \u003d readWithBounceBuffer(buf, canSkipChecksum);\n-      }\n-    } catch (IOException e) {\n+      String traceString \u003d null;\n       if (LOG.isTraceEnabled()) {\n-        LOG.info(traceString + \": I/O error\", e);\n+        traceString \u003d new StringBuilder().\n+            append(\"read(\").\n+            append(\"buf.remaining\u003d\").append(buf.remaining()).\n+            append(\", block\u003d\").append(block).\n+            append(\", filename\u003d\").append(filename).\n+            append(\", canSkipChecksum\u003d\").append(canSkipChecksum).\n+            append(\")\").toString();\n+        LOG.info(traceString + \": starting\");\n       }\n-      throw e;\n+      int nRead;\n+      try {\n+        if (canSkipChecksum \u0026\u0026 zeroReadaheadRequested) {\n+          nRead \u003d readWithoutBounceBuffer(buf);\n+        } else {\n+          nRead \u003d readWithBounceBuffer(buf, canSkipChecksum);\n+        }\n+      } catch (IOException e) {\n+        if (LOG.isTraceEnabled()) {\n+          LOG.info(traceString + \": I/O error\", e);\n+        }\n+        throw e;\n+      }\n+      if (LOG.isTraceEnabled()) {\n+        LOG.info(traceString + \": returning \" + nRead);\n+      }\n+      return nRead;\n+    } finally {\n+      if (canSkipChecksum) releaseNoChecksumContext();\n     }\n-    if (LOG.isTraceEnabled()) {\n-      LOG.info(traceString + \": returning \" + nRead);\n-    }\n-    return nRead;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized int read(ByteBuffer buf) throws IOException {\n    boolean canSkipChecksum \u003d createNoChecksumContext();\n    try {\n      String traceString \u003d null;\n      if (LOG.isTraceEnabled()) {\n        traceString \u003d new StringBuilder().\n            append(\"read(\").\n            append(\"buf.remaining\u003d\").append(buf.remaining()).\n            append(\", block\u003d\").append(block).\n            append(\", filename\u003d\").append(filename).\n            append(\", canSkipChecksum\u003d\").append(canSkipChecksum).\n            append(\")\").toString();\n        LOG.info(traceString + \": starting\");\n      }\n      int nRead;\n      try {\n        if (canSkipChecksum \u0026\u0026 zeroReadaheadRequested) {\n          nRead \u003d readWithoutBounceBuffer(buf);\n        } else {\n          nRead \u003d readWithBounceBuffer(buf, canSkipChecksum);\n        }\n      } catch (IOException e) {\n        if (LOG.isTraceEnabled()) {\n          LOG.info(traceString + \": I/O error\", e);\n        }\n        throw e;\n      }\n      if (LOG.isTraceEnabled()) {\n        LOG.info(traceString + \": returning \" + nRead);\n      }\n      return nRead;\n    } finally {\n      if (canSkipChecksum) releaseNoChecksumContext();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocal.java",
      "extendedDetails": {}
    },
    "124e507674c0d396f8494585e64226957199097b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5634. Allow BlockReaderLocal to switch between checksumming and not (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1551701 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/12/13 12:57 PM",
      "commitName": "124e507674c0d396f8494585e64226957199097b",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "27/09/13 3:51 PM",
      "commitNameOld": "eccdb9aa8bcdee750583d16a1253f1c5faabd036",
      "commitAuthorOld": "Chris Nauroth",
      "daysBetweenCommits": 80.92,
      "commitsBetweenForRepo": 532,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,70 +1,32 @@\n   public synchronized int read(ByteBuffer buf) throws IOException {\n-    int nRead \u003d 0;\n-    if (verifyChecksum) {\n-      // A \u0027direct\u0027 read actually has three phases. The first drains any\n-      // remaining bytes from the slow read buffer. After this the read is\n-      // guaranteed to be on a checksum chunk boundary. If there are still bytes\n-      // to read, the fast direct path is used for as many remaining bytes as\n-      // possible, up to a multiple of the checksum chunk size. Finally, any\n-      // \u0027odd\u0027 bytes remaining at the end of the read cause another slow read to\n-      // be issued, which involves an extra copy.\n-\n-      // Every \u0027slow\u0027 read tries to fill the slow read buffer in one go for\n-      // efficiency\u0027s sake. As described above, all non-checksum-chunk-aligned\n-      // reads will be served from the slower read path.\n-\n-      if (slowReadBuff.hasRemaining()) {\n-        // There are remaining bytes from a small read available. This usually\n-        // means this read is unaligned, which falls back to the slow path.\n-        int fromSlowReadBuff \u003d Math.min(buf.remaining(), slowReadBuff.remaining());\n-        writeSlice(slowReadBuff, buf, fromSlowReadBuff);\n-        nRead +\u003d fromSlowReadBuff;\n+    boolean canSkipChecksum \u003d getCanSkipChecksum();\n+    \n+    String traceString \u003d null;\n+    if (LOG.isTraceEnabled()) {\n+      traceString \u003d new StringBuilder().\n+          append(\"read(\").\n+          append(\"buf.remaining\u003d\").append(buf.remaining()).\n+          append(\", block\u003d\").append(block).\n+          append(\", filename\u003d\").append(filename).\n+          append(\", canSkipChecksum\u003d\").append(canSkipChecksum).\n+          append(\")\").toString();\n+      LOG.info(traceString + \": starting\");\n+    }\n+    int nRead;\n+    try {\n+      if (canSkipChecksum \u0026\u0026 zeroReadaheadRequested) {\n+        nRead \u003d readWithoutBounceBuffer(buf);\n+      } else {\n+        nRead \u003d readWithBounceBuffer(buf, canSkipChecksum);\n       }\n-\n-      if (buf.remaining() \u003e\u003d bytesPerChecksum \u0026\u0026 offsetFromChunkBoundary \u003d\u003d 0) {\n-        // Since we have drained the \u0027small read\u0027 buffer, we are guaranteed to\n-        // be chunk-aligned\n-        int len \u003d buf.remaining() - (buf.remaining() % bytesPerChecksum);\n-\n-        // There\u0027s only enough checksum buffer space available to checksum one\n-        // entire slow read buffer. This saves keeping the number of checksum\n-        // chunks around.\n-        len \u003d Math.min(len, slowReadBuff.capacity());\n-        int oldlimit \u003d buf.limit();\n-        buf.limit(buf.position() + len);\n-        int readResult \u003d 0;\n-        try {\n-          readResult \u003d doByteBufferRead(buf);\n-        } finally {\n-          buf.limit(oldlimit);\n-        }\n-        if (readResult \u003d\u003d -1) {\n-          return nRead;\n-        } else {\n-          nRead +\u003d readResult;\n-          buf.position(buf.position() + readResult);\n-        }\n+    } catch (IOException e) {\n+      if (LOG.isTraceEnabled()) {\n+        LOG.info(traceString + \": I/O error\", e);\n       }\n-\n-      // offsetFromChunkBoundary \u003e 0 \u003d\u003e unaligned read, use slow path to read\n-      // until chunk boundary\n-      if ((buf.remaining() \u003e 0 \u0026\u0026 buf.remaining() \u003c bytesPerChecksum) || offsetFromChunkBoundary \u003e 0) {\n-        int toRead \u003d Math.min(buf.remaining(), bytesPerChecksum - offsetFromChunkBoundary);\n-        int readResult \u003d fillSlowReadBuffer(toRead);\n-        if (readResult \u003d\u003d -1) {\n-          return nRead;\n-        } else {\n-          int fromSlowReadBuff \u003d Math.min(readResult, buf.remaining());\n-          writeSlice(slowReadBuff, buf, fromSlowReadBuff);\n-          nRead +\u003d fromSlowReadBuff;\n-        }\n-      }\n-    } else {\n-      // Non-checksummed reads are much easier; we can just fill the buffer directly.\n-      nRead \u003d doByteBufferRead(buf);\n-      if (nRead \u003e 0) {\n-        buf.position(buf.position() + nRead);\n-      }\n+      throw e;\n+    }\n+    if (LOG.isTraceEnabled()) {\n+      LOG.info(traceString + \": returning \" + nRead);\n     }\n     return nRead;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized int read(ByteBuffer buf) throws IOException {\n    boolean canSkipChecksum \u003d getCanSkipChecksum();\n    \n    String traceString \u003d null;\n    if (LOG.isTraceEnabled()) {\n      traceString \u003d new StringBuilder().\n          append(\"read(\").\n          append(\"buf.remaining\u003d\").append(buf.remaining()).\n          append(\", block\u003d\").append(block).\n          append(\", filename\u003d\").append(filename).\n          append(\", canSkipChecksum\u003d\").append(canSkipChecksum).\n          append(\")\").toString();\n      LOG.info(traceString + \": starting\");\n    }\n    int nRead;\n    try {\n      if (canSkipChecksum \u0026\u0026 zeroReadaheadRequested) {\n        nRead \u003d readWithoutBounceBuffer(buf);\n      } else {\n        nRead \u003d readWithBounceBuffer(buf, canSkipChecksum);\n      }\n    } catch (IOException e) {\n      if (LOG.isTraceEnabled()) {\n        LOG.info(traceString + \": I/O error\", e);\n      }\n      throw e;\n    }\n    if (LOG.isTraceEnabled()) {\n      LOG.info(traceString + \": returning \" + nRead);\n    }\n    return nRead;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocal.java",
      "extendedDetails": {}
    },
    "f55a1c08763e5f865fd9193d640c89a06ab49c4a": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-2834. Add a ByteBuffer-based read API to DFSInputStream. Contributed by Henry Robinson.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1303474 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/03/12 10:30 AM",
      "commitName": "f55a1c08763e5f865fd9193d640c89a06ab49c4a",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,70 @@\n+  public synchronized int read(ByteBuffer buf) throws IOException {\n+    int nRead \u003d 0;\n+    if (verifyChecksum) {\n+      // A \u0027direct\u0027 read actually has three phases. The first drains any\n+      // remaining bytes from the slow read buffer. After this the read is\n+      // guaranteed to be on a checksum chunk boundary. If there are still bytes\n+      // to read, the fast direct path is used for as many remaining bytes as\n+      // possible, up to a multiple of the checksum chunk size. Finally, any\n+      // \u0027odd\u0027 bytes remaining at the end of the read cause another slow read to\n+      // be issued, which involves an extra copy.\n+\n+      // Every \u0027slow\u0027 read tries to fill the slow read buffer in one go for\n+      // efficiency\u0027s sake. As described above, all non-checksum-chunk-aligned\n+      // reads will be served from the slower read path.\n+\n+      if (slowReadBuff.hasRemaining()) {\n+        // There are remaining bytes from a small read available. This usually\n+        // means this read is unaligned, which falls back to the slow path.\n+        int fromSlowReadBuff \u003d Math.min(buf.remaining(), slowReadBuff.remaining());\n+        writeSlice(slowReadBuff, buf, fromSlowReadBuff);\n+        nRead +\u003d fromSlowReadBuff;\n+      }\n+\n+      if (buf.remaining() \u003e\u003d bytesPerChecksum \u0026\u0026 offsetFromChunkBoundary \u003d\u003d 0) {\n+        // Since we have drained the \u0027small read\u0027 buffer, we are guaranteed to\n+        // be chunk-aligned\n+        int len \u003d buf.remaining() - (buf.remaining() % bytesPerChecksum);\n+\n+        // There\u0027s only enough checksum buffer space available to checksum one\n+        // entire slow read buffer. This saves keeping the number of checksum\n+        // chunks around.\n+        len \u003d Math.min(len, slowReadBuff.capacity());\n+        int oldlimit \u003d buf.limit();\n+        buf.limit(buf.position() + len);\n+        int readResult \u003d 0;\n+        try {\n+          readResult \u003d doByteBufferRead(buf);\n+        } finally {\n+          buf.limit(oldlimit);\n+        }\n+        if (readResult \u003d\u003d -1) {\n+          return nRead;\n+        } else {\n+          nRead +\u003d readResult;\n+          buf.position(buf.position() + readResult);\n+        }\n+      }\n+\n+      // offsetFromChunkBoundary \u003e 0 \u003d\u003e unaligned read, use slow path to read\n+      // until chunk boundary\n+      if ((buf.remaining() \u003e 0 \u0026\u0026 buf.remaining() \u003c bytesPerChecksum) || offsetFromChunkBoundary \u003e 0) {\n+        int toRead \u003d Math.min(buf.remaining(), bytesPerChecksum - offsetFromChunkBoundary);\n+        int readResult \u003d fillSlowReadBuffer(toRead);\n+        if (readResult \u003d\u003d -1) {\n+          return nRead;\n+        } else {\n+          int fromSlowReadBuff \u003d Math.min(readResult, buf.remaining());\n+          writeSlice(slowReadBuff, buf, fromSlowReadBuff);\n+          nRead +\u003d fromSlowReadBuff;\n+        }\n+      }\n+    } else {\n+      // Non-checksummed reads are much easier; we can just fill the buffer directly.\n+      nRead \u003d doByteBufferRead(buf);\n+      if (nRead \u003e 0) {\n+        buf.position(buf.position() + nRead);\n+      }\n+    }\n+    return nRead;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized int read(ByteBuffer buf) throws IOException {\n    int nRead \u003d 0;\n    if (verifyChecksum) {\n      // A \u0027direct\u0027 read actually has three phases. The first drains any\n      // remaining bytes from the slow read buffer. After this the read is\n      // guaranteed to be on a checksum chunk boundary. If there are still bytes\n      // to read, the fast direct path is used for as many remaining bytes as\n      // possible, up to a multiple of the checksum chunk size. Finally, any\n      // \u0027odd\u0027 bytes remaining at the end of the read cause another slow read to\n      // be issued, which involves an extra copy.\n\n      // Every \u0027slow\u0027 read tries to fill the slow read buffer in one go for\n      // efficiency\u0027s sake. As described above, all non-checksum-chunk-aligned\n      // reads will be served from the slower read path.\n\n      if (slowReadBuff.hasRemaining()) {\n        // There are remaining bytes from a small read available. This usually\n        // means this read is unaligned, which falls back to the slow path.\n        int fromSlowReadBuff \u003d Math.min(buf.remaining(), slowReadBuff.remaining());\n        writeSlice(slowReadBuff, buf, fromSlowReadBuff);\n        nRead +\u003d fromSlowReadBuff;\n      }\n\n      if (buf.remaining() \u003e\u003d bytesPerChecksum \u0026\u0026 offsetFromChunkBoundary \u003d\u003d 0) {\n        // Since we have drained the \u0027small read\u0027 buffer, we are guaranteed to\n        // be chunk-aligned\n        int len \u003d buf.remaining() - (buf.remaining() % bytesPerChecksum);\n\n        // There\u0027s only enough checksum buffer space available to checksum one\n        // entire slow read buffer. This saves keeping the number of checksum\n        // chunks around.\n        len \u003d Math.min(len, slowReadBuff.capacity());\n        int oldlimit \u003d buf.limit();\n        buf.limit(buf.position() + len);\n        int readResult \u003d 0;\n        try {\n          readResult \u003d doByteBufferRead(buf);\n        } finally {\n          buf.limit(oldlimit);\n        }\n        if (readResult \u003d\u003d -1) {\n          return nRead;\n        } else {\n          nRead +\u003d readResult;\n          buf.position(buf.position() + readResult);\n        }\n      }\n\n      // offsetFromChunkBoundary \u003e 0 \u003d\u003e unaligned read, use slow path to read\n      // until chunk boundary\n      if ((buf.remaining() \u003e 0 \u0026\u0026 buf.remaining() \u003c bytesPerChecksum) || offsetFromChunkBoundary \u003e 0) {\n        int toRead \u003d Math.min(buf.remaining(), bytesPerChecksum - offsetFromChunkBoundary);\n        int readResult \u003d fillSlowReadBuffer(toRead);\n        if (readResult \u003d\u003d -1) {\n          return nRead;\n        } else {\n          int fromSlowReadBuff \u003d Math.min(readResult, buf.remaining());\n          writeSlice(slowReadBuff, buf, fromSlowReadBuff);\n          nRead +\u003d fromSlowReadBuff;\n        }\n      }\n    } else {\n      // Non-checksummed reads are much easier; we can just fill the buffer directly.\n      nRead \u003d doByteBufferRead(buf);\n      if (nRead \u003e 0) {\n        buf.position(buf.position() + nRead);\n      }\n    }\n    return nRead;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocal.java"
    }
  }
}