{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FsVolumeImpl.java",
  "functionName": "getSubdirEntries",
  "functionId": "getSubdirEntries",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsVolumeImpl.java",
  "functionStartLine": 720,
  "functionEndLine": 751,
  "numCommitsSeen": 71,
  "timeTaken": 3282,
  "changeHistory": [
    "73c660b43f3d5311947d2acc9488f17c1caf4de0",
    "6ba9587d370fbf39c129c08c00ebbb894ccc1389",
    "6e62a1a6728b1f782f64065424f92b292c3f163a"
  ],
  "changeHistoryShort": {
    "73c660b43f3d5311947d2acc9488f17c1caf4de0": "Ybodychange",
    "6ba9587d370fbf39c129c08c00ebbb894ccc1389": "Ybodychange",
    "6e62a1a6728b1f782f64065424f92b292c3f163a": "Yintroduced"
  },
  "changeHistoryDetails": {
    "73c660b43f3d5311947d2acc9488f17c1caf4de0": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13958. Miscellaneous Improvements for FsVolumeSpi. Contributed by BELUGA BEHR.\n",
      "commitDate": "05/10/18 9:32 AM",
      "commitName": "73c660b43f3d5311947d2acc9488f17c1caf4de0",
      "commitAuthor": "Inigo Goiri",
      "commitDateOld": "30/04/18 1:28 PM",
      "commitNameOld": "fc074a359c44e84dd9612be2bd772763f943eb04",
      "commitAuthorOld": "Inigo Goiri",
      "daysBetweenCommits": 157.84,
      "commitsBetweenForRepo": 1255,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,35 +1,32 @@\n     private List\u003cString\u003e getSubdirEntries() throws IOException {\n       if (state.curFinalizedSubDir \u003d\u003d null) {\n         return null; // There are no entries in the null subdir.\n       }\n       long now \u003d Time.monotonicNow();\n       if (cache !\u003d null) {\n         long delta \u003d now - cacheMs;\n         if (delta \u003c maxStalenessMs) {\n           return cache;\n         } else {\n           LOG.trace(\"getSubdirEntries({}, {}): purging entries cache for {} \" +\n             \"after {} ms.\", storageID, bpid, state.curFinalizedSubDir, delta);\n           cache \u003d null;\n         }\n       }\n       File dir \u003d Paths.get(bpidDir.getAbsolutePath(), \"current\", \"finalized\",\n                     state.curFinalizedDir, state.curFinalizedSubDir).toFile();\n       List\u003cString\u003e entries \u003d fileIoProvider.listDirectory(\n           FsVolumeImpl.this, dir, BlockFileFilter.INSTANCE);\n-      if (entries.size() \u003d\u003d 0) {\n+      if (entries.isEmpty()) {\n         entries \u003d null;\n+        LOG.trace(\"getSubdirEntries({}, {}): no entries found in {}\", storageID,\n+            bpid, dir.getAbsolutePath());\n       } else {\n         Collections.sort(entries);\n-      }\n-      if (entries \u003d\u003d null) {\n-        LOG.trace(\"getSubdirEntries({}, {}): no entries found in {}\",\n-            storageID, bpid, dir.getAbsolutePath());\n-      } else {\n-        LOG.trace(\"getSubdirEntries({}, {}): listed {} entries in {}\", \n+        LOG.trace(\"getSubdirEntries({}, {}): listed {} entries in {}\",\n             storageID, bpid, entries.size(), dir.getAbsolutePath());\n       }\n       cache \u003d entries;\n       cacheMs \u003d now;\n       return cache;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private List\u003cString\u003e getSubdirEntries() throws IOException {\n      if (state.curFinalizedSubDir \u003d\u003d null) {\n        return null; // There are no entries in the null subdir.\n      }\n      long now \u003d Time.monotonicNow();\n      if (cache !\u003d null) {\n        long delta \u003d now - cacheMs;\n        if (delta \u003c maxStalenessMs) {\n          return cache;\n        } else {\n          LOG.trace(\"getSubdirEntries({}, {}): purging entries cache for {} \" +\n            \"after {} ms.\", storageID, bpid, state.curFinalizedSubDir, delta);\n          cache \u003d null;\n        }\n      }\n      File dir \u003d Paths.get(bpidDir.getAbsolutePath(), \"current\", \"finalized\",\n                    state.curFinalizedDir, state.curFinalizedSubDir).toFile();\n      List\u003cString\u003e entries \u003d fileIoProvider.listDirectory(\n          FsVolumeImpl.this, dir, BlockFileFilter.INSTANCE);\n      if (entries.isEmpty()) {\n        entries \u003d null;\n        LOG.trace(\"getSubdirEntries({}, {}): no entries found in {}\", storageID,\n            bpid, dir.getAbsolutePath());\n      } else {\n        Collections.sort(entries);\n        LOG.trace(\"getSubdirEntries({}, {}): listed {} entries in {}\",\n            storageID, bpid, entries.size(), dir.getAbsolutePath());\n      }\n      cache \u003d entries;\n      cacheMs \u003d now;\n      return cache;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsVolumeImpl.java",
      "extendedDetails": {}
    },
    "6ba9587d370fbf39c129c08c00ebbb894ccc1389": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10958. Add instrumentation hooks around Datanode disk IO.\n",
      "commitDate": "14/12/16 11:18 AM",
      "commitName": "6ba9587d370fbf39c129c08c00ebbb894ccc1389",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "12/12/16 6:11 PM",
      "commitNameOld": "2d4731c067ff64cd88f496eac8faaf302faa2ccc",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 1.71,
      "commitsBetweenForRepo": 10,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,35 +1,35 @@\n     private List\u003cString\u003e getSubdirEntries() throws IOException {\n       if (state.curFinalizedSubDir \u003d\u003d null) {\n         return null; // There are no entries in the null subdir.\n       }\n       long now \u003d Time.monotonicNow();\n       if (cache !\u003d null) {\n         long delta \u003d now - cacheMs;\n         if (delta \u003c maxStalenessMs) {\n           return cache;\n         } else {\n           LOG.trace(\"getSubdirEntries({}, {}): purging entries cache for {} \" +\n             \"after {} ms.\", storageID, bpid, state.curFinalizedSubDir, delta);\n           cache \u003d null;\n         }\n       }\n       File dir \u003d Paths.get(bpidDir.getAbsolutePath(), \"current\", \"finalized\",\n                     state.curFinalizedDir, state.curFinalizedSubDir).toFile();\n-      List\u003cString\u003e entries \u003d\n-          IOUtils.listDirectory(dir, BlockFileFilter.INSTANCE);\n+      List\u003cString\u003e entries \u003d fileIoProvider.listDirectory(\n+          FsVolumeImpl.this, dir, BlockFileFilter.INSTANCE);\n       if (entries.size() \u003d\u003d 0) {\n         entries \u003d null;\n       } else {\n         Collections.sort(entries);\n       }\n       if (entries \u003d\u003d null) {\n         LOG.trace(\"getSubdirEntries({}, {}): no entries found in {}\",\n             storageID, bpid, dir.getAbsolutePath());\n       } else {\n         LOG.trace(\"getSubdirEntries({}, {}): listed {} entries in {}\", \n             storageID, bpid, entries.size(), dir.getAbsolutePath());\n       }\n       cache \u003d entries;\n       cacheMs \u003d now;\n       return cache;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private List\u003cString\u003e getSubdirEntries() throws IOException {\n      if (state.curFinalizedSubDir \u003d\u003d null) {\n        return null; // There are no entries in the null subdir.\n      }\n      long now \u003d Time.monotonicNow();\n      if (cache !\u003d null) {\n        long delta \u003d now - cacheMs;\n        if (delta \u003c maxStalenessMs) {\n          return cache;\n        } else {\n          LOG.trace(\"getSubdirEntries({}, {}): purging entries cache for {} \" +\n            \"after {} ms.\", storageID, bpid, state.curFinalizedSubDir, delta);\n          cache \u003d null;\n        }\n      }\n      File dir \u003d Paths.get(bpidDir.getAbsolutePath(), \"current\", \"finalized\",\n                    state.curFinalizedDir, state.curFinalizedSubDir).toFile();\n      List\u003cString\u003e entries \u003d fileIoProvider.listDirectory(\n          FsVolumeImpl.this, dir, BlockFileFilter.INSTANCE);\n      if (entries.size() \u003d\u003d 0) {\n        entries \u003d null;\n      } else {\n        Collections.sort(entries);\n      }\n      if (entries \u003d\u003d null) {\n        LOG.trace(\"getSubdirEntries({}, {}): no entries found in {}\",\n            storageID, bpid, dir.getAbsolutePath());\n      } else {\n        LOG.trace(\"getSubdirEntries({}, {}): listed {} entries in {}\", \n            storageID, bpid, entries.size(), dir.getAbsolutePath());\n      }\n      cache \u003d entries;\n      cacheMs \u003d now;\n      return cache;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsVolumeImpl.java",
      "extendedDetails": {}
    },
    "6e62a1a6728b1f782f64065424f92b292c3f163a": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-7430. Refactor the BlockScanner to use O(1) memory and use multiple threads (cmccabe)\n",
      "commitDate": "21/01/15 7:00 PM",
      "commitName": "6e62a1a6728b1f782f64065424f92b292c3f163a",
      "commitAuthor": "Colin Patrick Mccabe",
      "diff": "@@ -0,0 +1,35 @@\n+    private List\u003cString\u003e getSubdirEntries() throws IOException {\n+      if (state.curFinalizedSubDir \u003d\u003d null) {\n+        return null; // There are no entries in the null subdir.\n+      }\n+      long now \u003d Time.monotonicNow();\n+      if (cache !\u003d null) {\n+        long delta \u003d now - cacheMs;\n+        if (delta \u003c maxStalenessMs) {\n+          return cache;\n+        } else {\n+          LOG.trace(\"getSubdirEntries({}, {}): purging entries cache for {} \" +\n+            \"after {} ms.\", storageID, bpid, state.curFinalizedSubDir, delta);\n+          cache \u003d null;\n+        }\n+      }\n+      File dir \u003d Paths.get(bpidDir.getAbsolutePath(), \"current\", \"finalized\",\n+                    state.curFinalizedDir, state.curFinalizedSubDir).toFile();\n+      List\u003cString\u003e entries \u003d\n+          IOUtils.listDirectory(dir, BlockFileFilter.INSTANCE);\n+      if (entries.size() \u003d\u003d 0) {\n+        entries \u003d null;\n+      } else {\n+        Collections.sort(entries);\n+      }\n+      if (entries \u003d\u003d null) {\n+        LOG.trace(\"getSubdirEntries({}, {}): no entries found in {}\",\n+            storageID, bpid, dir.getAbsolutePath());\n+      } else {\n+        LOG.trace(\"getSubdirEntries({}, {}): listed {} entries in {}\", \n+            storageID, bpid, entries.size(), dir.getAbsolutePath());\n+      }\n+      cache \u003d entries;\n+      cacheMs \u003d now;\n+      return cache;\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    private List\u003cString\u003e getSubdirEntries() throws IOException {\n      if (state.curFinalizedSubDir \u003d\u003d null) {\n        return null; // There are no entries in the null subdir.\n      }\n      long now \u003d Time.monotonicNow();\n      if (cache !\u003d null) {\n        long delta \u003d now - cacheMs;\n        if (delta \u003c maxStalenessMs) {\n          return cache;\n        } else {\n          LOG.trace(\"getSubdirEntries({}, {}): purging entries cache for {} \" +\n            \"after {} ms.\", storageID, bpid, state.curFinalizedSubDir, delta);\n          cache \u003d null;\n        }\n      }\n      File dir \u003d Paths.get(bpidDir.getAbsolutePath(), \"current\", \"finalized\",\n                    state.curFinalizedDir, state.curFinalizedSubDir).toFile();\n      List\u003cString\u003e entries \u003d\n          IOUtils.listDirectory(dir, BlockFileFilter.INSTANCE);\n      if (entries.size() \u003d\u003d 0) {\n        entries \u003d null;\n      } else {\n        Collections.sort(entries);\n      }\n      if (entries \u003d\u003d null) {\n        LOG.trace(\"getSubdirEntries({}, {}): no entries found in {}\",\n            storageID, bpid, dir.getAbsolutePath());\n      } else {\n        LOG.trace(\"getSubdirEntries({}, {}): listed {} entries in {}\", \n            storageID, bpid, entries.size(), dir.getAbsolutePath());\n      }\n      cache \u003d entries;\n      cacheMs \u003d now;\n      return cache;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsVolumeImpl.java"
    }
  }
}