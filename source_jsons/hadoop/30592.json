{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "LeveldbTimelineStore.java",
  "functionName": "getEntityTimelines",
  "functionId": "getEntityTimelines___entityType-String__entityIds-SortedSet__String____limit-Long__windowStart-Long__windowEnd-Long__eventType-Set__String__",
  "sourceFilePath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/timeline/LeveldbTimelineStore.java",
  "functionStartLine": 492,
  "functionEndLine": 575,
  "numCommitsSeen": 26,
  "timeTaken": 3425,
  "changeHistory": [
    "839e077faf4019d6efdcd89d95930023cd0b0a08",
    "a4aa1cb40504299d3401008fdabc795eafb28713",
    "1a78c0ff016097930edf68e8278f826b637e918c",
    "1ce4d33c2dc86d711b227a04d2f9a2ab696a24a1",
    "001078e0677e39b962ca1da81fc34d7ac9a7e65c",
    "b3ea4aebff42131642af0393748dc751cb3fc31e",
    "40464fba22bac99d0e5b79674152aa5dfba99483",
    "84425fb435cb603fd8adcc2f76631c0244175310",
    "23b2e43f5d678517e33590d15dec73225b9c5682"
  ],
  "changeHistoryShort": {
    "839e077faf4019d6efdcd89d95930023cd0b0a08": "Ybodychange",
    "a4aa1cb40504299d3401008fdabc795eafb28713": "Ybodychange",
    "1a78c0ff016097930edf68e8278f826b637e918c": "Ybodychange",
    "1ce4d33c2dc86d711b227a04d2f9a2ab696a24a1": "Ybodychange",
    "001078e0677e39b962ca1da81fc34d7ac9a7e65c": "Yfilerename",
    "b3ea4aebff42131642af0393748dc751cb3fc31e": "Ybodychange",
    "40464fba22bac99d0e5b79674152aa5dfba99483": "Ybodychange",
    "84425fb435cb603fd8adcc2f76631c0244175310": "Ymultichange(Yfilerename,Yreturntypechange,Ybodychange)",
    "23b2e43f5d678517e33590d15dec73225b9c5682": "Yintroduced"
  },
  "changeHistoryDetails": {
    "839e077faf4019d6efdcd89d95930023cd0b0a08": {
      "type": "Ybodychange",
      "commitMessage": "YARN-6873. Moving logging APIs over to slf4j in hadoop-yarn-server-applicationhistoryservice. Contributed by Yeliang Cang.\n",
      "commitDate": "07/08/17 2:56 AM",
      "commitName": "839e077faf4019d6efdcd89d95930023cd0b0a08",
      "commitAuthor": "Akira Ajisaka",
      "commitDateOld": "31/07/17 8:15 PM",
      "commitNameOld": "a4aa1cb40504299d3401008fdabc795eafb28713",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 6.28,
      "commitsBetweenForRepo": 91,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,84 +1,84 @@\n   public TimelineEvents getEntityTimelines(String entityType,\n       SortedSet\u003cString\u003e entityIds, Long limit, Long windowStart,\n       Long windowEnd, Set\u003cString\u003e eventType) throws IOException {\n     TimelineEvents events \u003d new TimelineEvents();\n     if (entityIds \u003d\u003d null || entityIds.isEmpty()) {\n       return events;\n     }\n     // create a lexicographically-ordered map from start time to entities\n     Map\u003cbyte[], List\u003cEntityIdentifier\u003e\u003e startTimeMap \u003d new TreeMap\u003cbyte[],\n         List\u003cEntityIdentifier\u003e\u003e(new Comparator\u003cbyte[]\u003e() {\n           @Override\n           public int compare(byte[] o1, byte[] o2) {\n             return WritableComparator.compareBytes(o1, 0, o1.length, o2, 0,\n                 o2.length);\n           }\n         });\n     LeveldbIterator iterator \u003d null;\n     try {\n       // look up start times for the specified entities\n       // skip entities with no start time\n       for (String entityId : entityIds) {\n         byte[] startTime \u003d getStartTime(entityId, entityType);\n         if (startTime !\u003d null) {\n           List\u003cEntityIdentifier\u003e entities \u003d startTimeMap.get(startTime);\n           if (entities \u003d\u003d null) {\n             entities \u003d new ArrayList\u003cEntityIdentifier\u003e();\n             startTimeMap.put(startTime, entities);\n           }\n           entities.add(new EntityIdentifier(entityId, entityType));\n         }\n       }\n       for (Entry\u003cbyte[], List\u003cEntityIdentifier\u003e\u003e entry :\n           startTimeMap.entrySet()) {\n         // look up the events matching the given parameters (limit,\n         // start time, end time, event types) for entities whose start times\n         // were found and add the entities to the return list\n         byte[] revStartTime \u003d entry.getKey();\n         for (EntityIdentifier entityIdentifier : entry.getValue()) {\n           EventsOfOneEntity entity \u003d new EventsOfOneEntity();\n           entity.setEntityId(entityIdentifier.getId());\n           entity.setEntityType(entityType);\n           events.addEvent(entity);\n           KeyBuilder kb \u003d KeyBuilder.newInstance().add(ENTITY_ENTRY_PREFIX)\n               .add(entityType).add(revStartTime).add(entityIdentifier.getId())\n               .add(EVENTS_COLUMN);\n           byte[] prefix \u003d kb.getBytesForLookup();\n           if (windowEnd \u003d\u003d null) {\n             windowEnd \u003d Long.MAX_VALUE;\n           }\n           byte[] revts \u003d writeReverseOrderedLong(windowEnd);\n           kb.add(revts);\n           byte[] first \u003d kb.getBytesForLookup();\n           byte[] last \u003d null;\n           if (windowStart !\u003d null) {\n             last \u003d KeyBuilder.newInstance().add(prefix)\n                 .add(writeReverseOrderedLong(windowStart)).getBytesForLookup();\n           }\n           if (limit \u003d\u003d null) {\n             limit \u003d DEFAULT_LIMIT;\n           }\n           iterator \u003d new LeveldbIterator(db);\n           for (iterator.seek(first); entity.getEvents().size() \u003c limit \u0026\u0026\n               iterator.hasNext(); iterator.next()) {\n             byte[] key \u003d iterator.peekNext().getKey();\n             if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n                 WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                     last.length) \u003e 0)) {\n               break;\n             }\n             TimelineEvent event \u003d getEntityEvent(eventType, key, prefix.length,\n                 iterator.peekNext().getValue());\n             if (event !\u003d null) {\n               entity.addEvent(event);\n             }\n           }\n         }\n       }\n     } catch(DBException e) {\n       throw new IOException(e);            \t\n     } finally {\n-      IOUtils.cleanup(LOG, iterator);\n+      IOUtils.cleanupWithLogger(LOG, iterator);\n     }\n     return events;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public TimelineEvents getEntityTimelines(String entityType,\n      SortedSet\u003cString\u003e entityIds, Long limit, Long windowStart,\n      Long windowEnd, Set\u003cString\u003e eventType) throws IOException {\n    TimelineEvents events \u003d new TimelineEvents();\n    if (entityIds \u003d\u003d null || entityIds.isEmpty()) {\n      return events;\n    }\n    // create a lexicographically-ordered map from start time to entities\n    Map\u003cbyte[], List\u003cEntityIdentifier\u003e\u003e startTimeMap \u003d new TreeMap\u003cbyte[],\n        List\u003cEntityIdentifier\u003e\u003e(new Comparator\u003cbyte[]\u003e() {\n          @Override\n          public int compare(byte[] o1, byte[] o2) {\n            return WritableComparator.compareBytes(o1, 0, o1.length, o2, 0,\n                o2.length);\n          }\n        });\n    LeveldbIterator iterator \u003d null;\n    try {\n      // look up start times for the specified entities\n      // skip entities with no start time\n      for (String entityId : entityIds) {\n        byte[] startTime \u003d getStartTime(entityId, entityType);\n        if (startTime !\u003d null) {\n          List\u003cEntityIdentifier\u003e entities \u003d startTimeMap.get(startTime);\n          if (entities \u003d\u003d null) {\n            entities \u003d new ArrayList\u003cEntityIdentifier\u003e();\n            startTimeMap.put(startTime, entities);\n          }\n          entities.add(new EntityIdentifier(entityId, entityType));\n        }\n      }\n      for (Entry\u003cbyte[], List\u003cEntityIdentifier\u003e\u003e entry :\n          startTimeMap.entrySet()) {\n        // look up the events matching the given parameters (limit,\n        // start time, end time, event types) for entities whose start times\n        // were found and add the entities to the return list\n        byte[] revStartTime \u003d entry.getKey();\n        for (EntityIdentifier entityIdentifier : entry.getValue()) {\n          EventsOfOneEntity entity \u003d new EventsOfOneEntity();\n          entity.setEntityId(entityIdentifier.getId());\n          entity.setEntityType(entityType);\n          events.addEvent(entity);\n          KeyBuilder kb \u003d KeyBuilder.newInstance().add(ENTITY_ENTRY_PREFIX)\n              .add(entityType).add(revStartTime).add(entityIdentifier.getId())\n              .add(EVENTS_COLUMN);\n          byte[] prefix \u003d kb.getBytesForLookup();\n          if (windowEnd \u003d\u003d null) {\n            windowEnd \u003d Long.MAX_VALUE;\n          }\n          byte[] revts \u003d writeReverseOrderedLong(windowEnd);\n          kb.add(revts);\n          byte[] first \u003d kb.getBytesForLookup();\n          byte[] last \u003d null;\n          if (windowStart !\u003d null) {\n            last \u003d KeyBuilder.newInstance().add(prefix)\n                .add(writeReverseOrderedLong(windowStart)).getBytesForLookup();\n          }\n          if (limit \u003d\u003d null) {\n            limit \u003d DEFAULT_LIMIT;\n          }\n          iterator \u003d new LeveldbIterator(db);\n          for (iterator.seek(first); entity.getEvents().size() \u003c limit \u0026\u0026\n              iterator.hasNext(); iterator.next()) {\n            byte[] key \u003d iterator.peekNext().getKey();\n            if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n                WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                    last.length) \u003e 0)) {\n              break;\n            }\n            TimelineEvent event \u003d getEntityEvent(eventType, key, prefix.length,\n                iterator.peekNext().getValue());\n            if (event !\u003d null) {\n              entity.addEvent(event);\n            }\n          }\n        }\n      }\n    } catch(DBException e) {\n      throw new IOException(e);            \t\n    } finally {\n      IOUtils.cleanupWithLogger(LOG, iterator);\n    }\n    return events;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/timeline/LeveldbTimelineStore.java",
      "extendedDetails": {}
    },
    "a4aa1cb40504299d3401008fdabc795eafb28713": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"YARN-6873. Moving logging APIs over to slf4j in hadoop-yarn-server-applicationhistoryservice. Contributed by Yeliang Cang.\"\n\nThis reverts commit 1a78c0ff016097930edf68e8278f826b637e918c.\n",
      "commitDate": "31/07/17 8:15 PM",
      "commitName": "a4aa1cb40504299d3401008fdabc795eafb28713",
      "commitAuthor": "Akira Ajisaka",
      "commitDateOld": "31/07/17 6:53 PM",
      "commitNameOld": "1a78c0ff016097930edf68e8278f826b637e918c",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 0.06,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,84 +1,84 @@\n   public TimelineEvents getEntityTimelines(String entityType,\n       SortedSet\u003cString\u003e entityIds, Long limit, Long windowStart,\n       Long windowEnd, Set\u003cString\u003e eventType) throws IOException {\n     TimelineEvents events \u003d new TimelineEvents();\n     if (entityIds \u003d\u003d null || entityIds.isEmpty()) {\n       return events;\n     }\n     // create a lexicographically-ordered map from start time to entities\n     Map\u003cbyte[], List\u003cEntityIdentifier\u003e\u003e startTimeMap \u003d new TreeMap\u003cbyte[],\n         List\u003cEntityIdentifier\u003e\u003e(new Comparator\u003cbyte[]\u003e() {\n           @Override\n           public int compare(byte[] o1, byte[] o2) {\n             return WritableComparator.compareBytes(o1, 0, o1.length, o2, 0,\n                 o2.length);\n           }\n         });\n     LeveldbIterator iterator \u003d null;\n     try {\n       // look up start times for the specified entities\n       // skip entities with no start time\n       for (String entityId : entityIds) {\n         byte[] startTime \u003d getStartTime(entityId, entityType);\n         if (startTime !\u003d null) {\n           List\u003cEntityIdentifier\u003e entities \u003d startTimeMap.get(startTime);\n           if (entities \u003d\u003d null) {\n             entities \u003d new ArrayList\u003cEntityIdentifier\u003e();\n             startTimeMap.put(startTime, entities);\n           }\n           entities.add(new EntityIdentifier(entityId, entityType));\n         }\n       }\n       for (Entry\u003cbyte[], List\u003cEntityIdentifier\u003e\u003e entry :\n           startTimeMap.entrySet()) {\n         // look up the events matching the given parameters (limit,\n         // start time, end time, event types) for entities whose start times\n         // were found and add the entities to the return list\n         byte[] revStartTime \u003d entry.getKey();\n         for (EntityIdentifier entityIdentifier : entry.getValue()) {\n           EventsOfOneEntity entity \u003d new EventsOfOneEntity();\n           entity.setEntityId(entityIdentifier.getId());\n           entity.setEntityType(entityType);\n           events.addEvent(entity);\n           KeyBuilder kb \u003d KeyBuilder.newInstance().add(ENTITY_ENTRY_PREFIX)\n               .add(entityType).add(revStartTime).add(entityIdentifier.getId())\n               .add(EVENTS_COLUMN);\n           byte[] prefix \u003d kb.getBytesForLookup();\n           if (windowEnd \u003d\u003d null) {\n             windowEnd \u003d Long.MAX_VALUE;\n           }\n           byte[] revts \u003d writeReverseOrderedLong(windowEnd);\n           kb.add(revts);\n           byte[] first \u003d kb.getBytesForLookup();\n           byte[] last \u003d null;\n           if (windowStart !\u003d null) {\n             last \u003d KeyBuilder.newInstance().add(prefix)\n                 .add(writeReverseOrderedLong(windowStart)).getBytesForLookup();\n           }\n           if (limit \u003d\u003d null) {\n             limit \u003d DEFAULT_LIMIT;\n           }\n           iterator \u003d new LeveldbIterator(db);\n           for (iterator.seek(first); entity.getEvents().size() \u003c limit \u0026\u0026\n               iterator.hasNext(); iterator.next()) {\n             byte[] key \u003d iterator.peekNext().getKey();\n             if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n                 WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                     last.length) \u003e 0)) {\n               break;\n             }\n             TimelineEvent event \u003d getEntityEvent(eventType, key, prefix.length,\n                 iterator.peekNext().getValue());\n             if (event !\u003d null) {\n               entity.addEvent(event);\n             }\n           }\n         }\n       }\n     } catch(DBException e) {\n       throw new IOException(e);            \t\n     } finally {\n-      IOUtils.cleanupWithLogger(LOG, iterator);\n+      IOUtils.cleanup(LOG, iterator);\n     }\n     return events;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public TimelineEvents getEntityTimelines(String entityType,\n      SortedSet\u003cString\u003e entityIds, Long limit, Long windowStart,\n      Long windowEnd, Set\u003cString\u003e eventType) throws IOException {\n    TimelineEvents events \u003d new TimelineEvents();\n    if (entityIds \u003d\u003d null || entityIds.isEmpty()) {\n      return events;\n    }\n    // create a lexicographically-ordered map from start time to entities\n    Map\u003cbyte[], List\u003cEntityIdentifier\u003e\u003e startTimeMap \u003d new TreeMap\u003cbyte[],\n        List\u003cEntityIdentifier\u003e\u003e(new Comparator\u003cbyte[]\u003e() {\n          @Override\n          public int compare(byte[] o1, byte[] o2) {\n            return WritableComparator.compareBytes(o1, 0, o1.length, o2, 0,\n                o2.length);\n          }\n        });\n    LeveldbIterator iterator \u003d null;\n    try {\n      // look up start times for the specified entities\n      // skip entities with no start time\n      for (String entityId : entityIds) {\n        byte[] startTime \u003d getStartTime(entityId, entityType);\n        if (startTime !\u003d null) {\n          List\u003cEntityIdentifier\u003e entities \u003d startTimeMap.get(startTime);\n          if (entities \u003d\u003d null) {\n            entities \u003d new ArrayList\u003cEntityIdentifier\u003e();\n            startTimeMap.put(startTime, entities);\n          }\n          entities.add(new EntityIdentifier(entityId, entityType));\n        }\n      }\n      for (Entry\u003cbyte[], List\u003cEntityIdentifier\u003e\u003e entry :\n          startTimeMap.entrySet()) {\n        // look up the events matching the given parameters (limit,\n        // start time, end time, event types) for entities whose start times\n        // were found and add the entities to the return list\n        byte[] revStartTime \u003d entry.getKey();\n        for (EntityIdentifier entityIdentifier : entry.getValue()) {\n          EventsOfOneEntity entity \u003d new EventsOfOneEntity();\n          entity.setEntityId(entityIdentifier.getId());\n          entity.setEntityType(entityType);\n          events.addEvent(entity);\n          KeyBuilder kb \u003d KeyBuilder.newInstance().add(ENTITY_ENTRY_PREFIX)\n              .add(entityType).add(revStartTime).add(entityIdentifier.getId())\n              .add(EVENTS_COLUMN);\n          byte[] prefix \u003d kb.getBytesForLookup();\n          if (windowEnd \u003d\u003d null) {\n            windowEnd \u003d Long.MAX_VALUE;\n          }\n          byte[] revts \u003d writeReverseOrderedLong(windowEnd);\n          kb.add(revts);\n          byte[] first \u003d kb.getBytesForLookup();\n          byte[] last \u003d null;\n          if (windowStart !\u003d null) {\n            last \u003d KeyBuilder.newInstance().add(prefix)\n                .add(writeReverseOrderedLong(windowStart)).getBytesForLookup();\n          }\n          if (limit \u003d\u003d null) {\n            limit \u003d DEFAULT_LIMIT;\n          }\n          iterator \u003d new LeveldbIterator(db);\n          for (iterator.seek(first); entity.getEvents().size() \u003c limit \u0026\u0026\n              iterator.hasNext(); iterator.next()) {\n            byte[] key \u003d iterator.peekNext().getKey();\n            if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n                WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                    last.length) \u003e 0)) {\n              break;\n            }\n            TimelineEvent event \u003d getEntityEvent(eventType, key, prefix.length,\n                iterator.peekNext().getValue());\n            if (event !\u003d null) {\n              entity.addEvent(event);\n            }\n          }\n        }\n      }\n    } catch(DBException e) {\n      throw new IOException(e);            \t\n    } finally {\n      IOUtils.cleanup(LOG, iterator);\n    }\n    return events;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/timeline/LeveldbTimelineStore.java",
      "extendedDetails": {}
    },
    "1a78c0ff016097930edf68e8278f826b637e918c": {
      "type": "Ybodychange",
      "commitMessage": "YARN-6873. Moving logging APIs over to slf4j in hadoop-yarn-server-applicationhistoryservice. Contributed by Yeliang Cang.\n",
      "commitDate": "31/07/17 6:53 PM",
      "commitName": "1a78c0ff016097930edf68e8278f826b637e918c",
      "commitAuthor": "Akira Ajisaka",
      "commitDateOld": "10/01/17 2:24 AM",
      "commitNameOld": "4c431a694059e40e78365b02a1497a6c7e479a70",
      "commitAuthorOld": "Naganarasimha",
      "daysBetweenCommits": 202.65,
      "commitsBetweenForRepo": 1063,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,84 +1,84 @@\n   public TimelineEvents getEntityTimelines(String entityType,\n       SortedSet\u003cString\u003e entityIds, Long limit, Long windowStart,\n       Long windowEnd, Set\u003cString\u003e eventType) throws IOException {\n     TimelineEvents events \u003d new TimelineEvents();\n     if (entityIds \u003d\u003d null || entityIds.isEmpty()) {\n       return events;\n     }\n     // create a lexicographically-ordered map from start time to entities\n     Map\u003cbyte[], List\u003cEntityIdentifier\u003e\u003e startTimeMap \u003d new TreeMap\u003cbyte[],\n         List\u003cEntityIdentifier\u003e\u003e(new Comparator\u003cbyte[]\u003e() {\n           @Override\n           public int compare(byte[] o1, byte[] o2) {\n             return WritableComparator.compareBytes(o1, 0, o1.length, o2, 0,\n                 o2.length);\n           }\n         });\n     LeveldbIterator iterator \u003d null;\n     try {\n       // look up start times for the specified entities\n       // skip entities with no start time\n       for (String entityId : entityIds) {\n         byte[] startTime \u003d getStartTime(entityId, entityType);\n         if (startTime !\u003d null) {\n           List\u003cEntityIdentifier\u003e entities \u003d startTimeMap.get(startTime);\n           if (entities \u003d\u003d null) {\n             entities \u003d new ArrayList\u003cEntityIdentifier\u003e();\n             startTimeMap.put(startTime, entities);\n           }\n           entities.add(new EntityIdentifier(entityId, entityType));\n         }\n       }\n       for (Entry\u003cbyte[], List\u003cEntityIdentifier\u003e\u003e entry :\n           startTimeMap.entrySet()) {\n         // look up the events matching the given parameters (limit,\n         // start time, end time, event types) for entities whose start times\n         // were found and add the entities to the return list\n         byte[] revStartTime \u003d entry.getKey();\n         for (EntityIdentifier entityIdentifier : entry.getValue()) {\n           EventsOfOneEntity entity \u003d new EventsOfOneEntity();\n           entity.setEntityId(entityIdentifier.getId());\n           entity.setEntityType(entityType);\n           events.addEvent(entity);\n           KeyBuilder kb \u003d KeyBuilder.newInstance().add(ENTITY_ENTRY_PREFIX)\n               .add(entityType).add(revStartTime).add(entityIdentifier.getId())\n               .add(EVENTS_COLUMN);\n           byte[] prefix \u003d kb.getBytesForLookup();\n           if (windowEnd \u003d\u003d null) {\n             windowEnd \u003d Long.MAX_VALUE;\n           }\n           byte[] revts \u003d writeReverseOrderedLong(windowEnd);\n           kb.add(revts);\n           byte[] first \u003d kb.getBytesForLookup();\n           byte[] last \u003d null;\n           if (windowStart !\u003d null) {\n             last \u003d KeyBuilder.newInstance().add(prefix)\n                 .add(writeReverseOrderedLong(windowStart)).getBytesForLookup();\n           }\n           if (limit \u003d\u003d null) {\n             limit \u003d DEFAULT_LIMIT;\n           }\n           iterator \u003d new LeveldbIterator(db);\n           for (iterator.seek(first); entity.getEvents().size() \u003c limit \u0026\u0026\n               iterator.hasNext(); iterator.next()) {\n             byte[] key \u003d iterator.peekNext().getKey();\n             if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n                 WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                     last.length) \u003e 0)) {\n               break;\n             }\n             TimelineEvent event \u003d getEntityEvent(eventType, key, prefix.length,\n                 iterator.peekNext().getValue());\n             if (event !\u003d null) {\n               entity.addEvent(event);\n             }\n           }\n         }\n       }\n     } catch(DBException e) {\n       throw new IOException(e);            \t\n     } finally {\n-      IOUtils.cleanup(LOG, iterator);\n+      IOUtils.cleanupWithLogger(LOG, iterator);\n     }\n     return events;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public TimelineEvents getEntityTimelines(String entityType,\n      SortedSet\u003cString\u003e entityIds, Long limit, Long windowStart,\n      Long windowEnd, Set\u003cString\u003e eventType) throws IOException {\n    TimelineEvents events \u003d new TimelineEvents();\n    if (entityIds \u003d\u003d null || entityIds.isEmpty()) {\n      return events;\n    }\n    // create a lexicographically-ordered map from start time to entities\n    Map\u003cbyte[], List\u003cEntityIdentifier\u003e\u003e startTimeMap \u003d new TreeMap\u003cbyte[],\n        List\u003cEntityIdentifier\u003e\u003e(new Comparator\u003cbyte[]\u003e() {\n          @Override\n          public int compare(byte[] o1, byte[] o2) {\n            return WritableComparator.compareBytes(o1, 0, o1.length, o2, 0,\n                o2.length);\n          }\n        });\n    LeveldbIterator iterator \u003d null;\n    try {\n      // look up start times for the specified entities\n      // skip entities with no start time\n      for (String entityId : entityIds) {\n        byte[] startTime \u003d getStartTime(entityId, entityType);\n        if (startTime !\u003d null) {\n          List\u003cEntityIdentifier\u003e entities \u003d startTimeMap.get(startTime);\n          if (entities \u003d\u003d null) {\n            entities \u003d new ArrayList\u003cEntityIdentifier\u003e();\n            startTimeMap.put(startTime, entities);\n          }\n          entities.add(new EntityIdentifier(entityId, entityType));\n        }\n      }\n      for (Entry\u003cbyte[], List\u003cEntityIdentifier\u003e\u003e entry :\n          startTimeMap.entrySet()) {\n        // look up the events matching the given parameters (limit,\n        // start time, end time, event types) for entities whose start times\n        // were found and add the entities to the return list\n        byte[] revStartTime \u003d entry.getKey();\n        for (EntityIdentifier entityIdentifier : entry.getValue()) {\n          EventsOfOneEntity entity \u003d new EventsOfOneEntity();\n          entity.setEntityId(entityIdentifier.getId());\n          entity.setEntityType(entityType);\n          events.addEvent(entity);\n          KeyBuilder kb \u003d KeyBuilder.newInstance().add(ENTITY_ENTRY_PREFIX)\n              .add(entityType).add(revStartTime).add(entityIdentifier.getId())\n              .add(EVENTS_COLUMN);\n          byte[] prefix \u003d kb.getBytesForLookup();\n          if (windowEnd \u003d\u003d null) {\n            windowEnd \u003d Long.MAX_VALUE;\n          }\n          byte[] revts \u003d writeReverseOrderedLong(windowEnd);\n          kb.add(revts);\n          byte[] first \u003d kb.getBytesForLookup();\n          byte[] last \u003d null;\n          if (windowStart !\u003d null) {\n            last \u003d KeyBuilder.newInstance().add(prefix)\n                .add(writeReverseOrderedLong(windowStart)).getBytesForLookup();\n          }\n          if (limit \u003d\u003d null) {\n            limit \u003d DEFAULT_LIMIT;\n          }\n          iterator \u003d new LeveldbIterator(db);\n          for (iterator.seek(first); entity.getEvents().size() \u003c limit \u0026\u0026\n              iterator.hasNext(); iterator.next()) {\n            byte[] key \u003d iterator.peekNext().getKey();\n            if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n                WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                    last.length) \u003e 0)) {\n              break;\n            }\n            TimelineEvent event \u003d getEntityEvent(eventType, key, prefix.length,\n                iterator.peekNext().getValue());\n            if (event !\u003d null) {\n              entity.addEvent(event);\n            }\n          }\n        }\n      }\n    } catch(DBException e) {\n      throw new IOException(e);            \t\n    } finally {\n      IOUtils.cleanupWithLogger(LOG, iterator);\n    }\n    return events;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/timeline/LeveldbTimelineStore.java",
      "extendedDetails": {}
    },
    "1ce4d33c2dc86d711b227a04d2f9a2ab696a24a1": {
      "type": "Ybodychange",
      "commitMessage": "YARN-1984. LeveldbTimelineStore does not handle db exceptions properly. Contributed by Varun Saxena\n",
      "commitDate": "24/11/14 2:36 PM",
      "commitName": "1ce4d33c2dc86d711b227a04d2f9a2ab696a24a1",
      "commitAuthor": "Jason Lowe",
      "commitDateOld": "07/11/14 4:11 PM",
      "commitNameOld": "4a114dd67aae83e5bb2d65470166de954acf36a2",
      "commitAuthorOld": "Xuan",
      "daysBetweenCommits": 16.93,
      "commitsBetweenForRepo": 118,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,82 +1,84 @@\n   public TimelineEvents getEntityTimelines(String entityType,\n       SortedSet\u003cString\u003e entityIds, Long limit, Long windowStart,\n       Long windowEnd, Set\u003cString\u003e eventType) throws IOException {\n     TimelineEvents events \u003d new TimelineEvents();\n     if (entityIds \u003d\u003d null || entityIds.isEmpty()) {\n       return events;\n     }\n     // create a lexicographically-ordered map from start time to entities\n     Map\u003cbyte[], List\u003cEntityIdentifier\u003e\u003e startTimeMap \u003d new TreeMap\u003cbyte[],\n         List\u003cEntityIdentifier\u003e\u003e(new Comparator\u003cbyte[]\u003e() {\n           @Override\n           public int compare(byte[] o1, byte[] o2) {\n             return WritableComparator.compareBytes(o1, 0, o1.length, o2, 0,\n                 o2.length);\n           }\n         });\n-    DBIterator iterator \u003d null;\n+    LeveldbIterator iterator \u003d null;\n     try {\n       // look up start times for the specified entities\n       // skip entities with no start time\n       for (String entityId : entityIds) {\n         byte[] startTime \u003d getStartTime(entityId, entityType);\n         if (startTime !\u003d null) {\n           List\u003cEntityIdentifier\u003e entities \u003d startTimeMap.get(startTime);\n           if (entities \u003d\u003d null) {\n             entities \u003d new ArrayList\u003cEntityIdentifier\u003e();\n             startTimeMap.put(startTime, entities);\n           }\n           entities.add(new EntityIdentifier(entityId, entityType));\n         }\n       }\n       for (Entry\u003cbyte[], List\u003cEntityIdentifier\u003e\u003e entry :\n           startTimeMap.entrySet()) {\n         // look up the events matching the given parameters (limit,\n         // start time, end time, event types) for entities whose start times\n         // were found and add the entities to the return list\n         byte[] revStartTime \u003d entry.getKey();\n         for (EntityIdentifier entityIdentifier : entry.getValue()) {\n           EventsOfOneEntity entity \u003d new EventsOfOneEntity();\n           entity.setEntityId(entityIdentifier.getId());\n           entity.setEntityType(entityType);\n           events.addEvent(entity);\n           KeyBuilder kb \u003d KeyBuilder.newInstance().add(ENTITY_ENTRY_PREFIX)\n               .add(entityType).add(revStartTime).add(entityIdentifier.getId())\n               .add(EVENTS_COLUMN);\n           byte[] prefix \u003d kb.getBytesForLookup();\n           if (windowEnd \u003d\u003d null) {\n             windowEnd \u003d Long.MAX_VALUE;\n           }\n           byte[] revts \u003d writeReverseOrderedLong(windowEnd);\n           kb.add(revts);\n           byte[] first \u003d kb.getBytesForLookup();\n           byte[] last \u003d null;\n           if (windowStart !\u003d null) {\n             last \u003d KeyBuilder.newInstance().add(prefix)\n                 .add(writeReverseOrderedLong(windowStart)).getBytesForLookup();\n           }\n           if (limit \u003d\u003d null) {\n             limit \u003d DEFAULT_LIMIT;\n           }\n-          iterator \u003d db.iterator();\n+          iterator \u003d new LeveldbIterator(db);\n           for (iterator.seek(first); entity.getEvents().size() \u003c limit \u0026\u0026\n               iterator.hasNext(); iterator.next()) {\n             byte[] key \u003d iterator.peekNext().getKey();\n             if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n                 WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                     last.length) \u003e 0)) {\n               break;\n             }\n             TimelineEvent event \u003d getEntityEvent(eventType, key, prefix.length,\n                 iterator.peekNext().getValue());\n             if (event !\u003d null) {\n               entity.addEvent(event);\n             }\n           }\n         }\n       }\n+    } catch(DBException e) {\n+      throw new IOException(e);            \t\n     } finally {\n       IOUtils.cleanup(LOG, iterator);\n     }\n     return events;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public TimelineEvents getEntityTimelines(String entityType,\n      SortedSet\u003cString\u003e entityIds, Long limit, Long windowStart,\n      Long windowEnd, Set\u003cString\u003e eventType) throws IOException {\n    TimelineEvents events \u003d new TimelineEvents();\n    if (entityIds \u003d\u003d null || entityIds.isEmpty()) {\n      return events;\n    }\n    // create a lexicographically-ordered map from start time to entities\n    Map\u003cbyte[], List\u003cEntityIdentifier\u003e\u003e startTimeMap \u003d new TreeMap\u003cbyte[],\n        List\u003cEntityIdentifier\u003e\u003e(new Comparator\u003cbyte[]\u003e() {\n          @Override\n          public int compare(byte[] o1, byte[] o2) {\n            return WritableComparator.compareBytes(o1, 0, o1.length, o2, 0,\n                o2.length);\n          }\n        });\n    LeveldbIterator iterator \u003d null;\n    try {\n      // look up start times for the specified entities\n      // skip entities with no start time\n      for (String entityId : entityIds) {\n        byte[] startTime \u003d getStartTime(entityId, entityType);\n        if (startTime !\u003d null) {\n          List\u003cEntityIdentifier\u003e entities \u003d startTimeMap.get(startTime);\n          if (entities \u003d\u003d null) {\n            entities \u003d new ArrayList\u003cEntityIdentifier\u003e();\n            startTimeMap.put(startTime, entities);\n          }\n          entities.add(new EntityIdentifier(entityId, entityType));\n        }\n      }\n      for (Entry\u003cbyte[], List\u003cEntityIdentifier\u003e\u003e entry :\n          startTimeMap.entrySet()) {\n        // look up the events matching the given parameters (limit,\n        // start time, end time, event types) for entities whose start times\n        // were found and add the entities to the return list\n        byte[] revStartTime \u003d entry.getKey();\n        for (EntityIdentifier entityIdentifier : entry.getValue()) {\n          EventsOfOneEntity entity \u003d new EventsOfOneEntity();\n          entity.setEntityId(entityIdentifier.getId());\n          entity.setEntityType(entityType);\n          events.addEvent(entity);\n          KeyBuilder kb \u003d KeyBuilder.newInstance().add(ENTITY_ENTRY_PREFIX)\n              .add(entityType).add(revStartTime).add(entityIdentifier.getId())\n              .add(EVENTS_COLUMN);\n          byte[] prefix \u003d kb.getBytesForLookup();\n          if (windowEnd \u003d\u003d null) {\n            windowEnd \u003d Long.MAX_VALUE;\n          }\n          byte[] revts \u003d writeReverseOrderedLong(windowEnd);\n          kb.add(revts);\n          byte[] first \u003d kb.getBytesForLookup();\n          byte[] last \u003d null;\n          if (windowStart !\u003d null) {\n            last \u003d KeyBuilder.newInstance().add(prefix)\n                .add(writeReverseOrderedLong(windowStart)).getBytesForLookup();\n          }\n          if (limit \u003d\u003d null) {\n            limit \u003d DEFAULT_LIMIT;\n          }\n          iterator \u003d new LeveldbIterator(db);\n          for (iterator.seek(first); entity.getEvents().size() \u003c limit \u0026\u0026\n              iterator.hasNext(); iterator.next()) {\n            byte[] key \u003d iterator.peekNext().getKey();\n            if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n                WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                    last.length) \u003e 0)) {\n              break;\n            }\n            TimelineEvent event \u003d getEntityEvent(eventType, key, prefix.length,\n                iterator.peekNext().getValue());\n            if (event !\u003d null) {\n              entity.addEvent(event);\n            }\n          }\n        }\n      }\n    } catch(DBException e) {\n      throw new IOException(e);            \t\n    } finally {\n      IOUtils.cleanup(LOG, iterator);\n    }\n    return events;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/timeline/LeveldbTimelineStore.java",
      "extendedDetails": {}
    },
    "001078e0677e39b962ca1da81fc34d7ac9a7e65c": {
      "type": "Yfilerename",
      "commitMessage": "YARN-2107. Refactored timeline classes into o.a.h.y.s.timeline package. Contributed by Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1598094 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/05/14 11:09 AM",
      "commitName": "001078e0677e39b962ca1da81fc34d7ac9a7e65c",
      "commitAuthor": "Zhijie Shen",
      "commitDateOld": "28/05/14 10:44 AM",
      "commitNameOld": "cfd8647d0f20c08761f908be1f5b718c1c372498",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 0.02,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public TimelineEvents getEntityTimelines(String entityType,\n      SortedSet\u003cString\u003e entityIds, Long limit, Long windowStart,\n      Long windowEnd, Set\u003cString\u003e eventType) throws IOException {\n    TimelineEvents events \u003d new TimelineEvents();\n    if (entityIds \u003d\u003d null || entityIds.isEmpty()) {\n      return events;\n    }\n    // create a lexicographically-ordered map from start time to entities\n    Map\u003cbyte[], List\u003cEntityIdentifier\u003e\u003e startTimeMap \u003d new TreeMap\u003cbyte[],\n        List\u003cEntityIdentifier\u003e\u003e(new Comparator\u003cbyte[]\u003e() {\n          @Override\n          public int compare(byte[] o1, byte[] o2) {\n            return WritableComparator.compareBytes(o1, 0, o1.length, o2, 0,\n                o2.length);\n          }\n        });\n    DBIterator iterator \u003d null;\n    try {\n      // look up start times for the specified entities\n      // skip entities with no start time\n      for (String entityId : entityIds) {\n        byte[] startTime \u003d getStartTime(entityId, entityType);\n        if (startTime !\u003d null) {\n          List\u003cEntityIdentifier\u003e entities \u003d startTimeMap.get(startTime);\n          if (entities \u003d\u003d null) {\n            entities \u003d new ArrayList\u003cEntityIdentifier\u003e();\n            startTimeMap.put(startTime, entities);\n          }\n          entities.add(new EntityIdentifier(entityId, entityType));\n        }\n      }\n      for (Entry\u003cbyte[], List\u003cEntityIdentifier\u003e\u003e entry :\n          startTimeMap.entrySet()) {\n        // look up the events matching the given parameters (limit,\n        // start time, end time, event types) for entities whose start times\n        // were found and add the entities to the return list\n        byte[] revStartTime \u003d entry.getKey();\n        for (EntityIdentifier entityIdentifier : entry.getValue()) {\n          EventsOfOneEntity entity \u003d new EventsOfOneEntity();\n          entity.setEntityId(entityIdentifier.getId());\n          entity.setEntityType(entityType);\n          events.addEvent(entity);\n          KeyBuilder kb \u003d KeyBuilder.newInstance().add(ENTITY_ENTRY_PREFIX)\n              .add(entityType).add(revStartTime).add(entityIdentifier.getId())\n              .add(EVENTS_COLUMN);\n          byte[] prefix \u003d kb.getBytesForLookup();\n          if (windowEnd \u003d\u003d null) {\n            windowEnd \u003d Long.MAX_VALUE;\n          }\n          byte[] revts \u003d writeReverseOrderedLong(windowEnd);\n          kb.add(revts);\n          byte[] first \u003d kb.getBytesForLookup();\n          byte[] last \u003d null;\n          if (windowStart !\u003d null) {\n            last \u003d KeyBuilder.newInstance().add(prefix)\n                .add(writeReverseOrderedLong(windowStart)).getBytesForLookup();\n          }\n          if (limit \u003d\u003d null) {\n            limit \u003d DEFAULT_LIMIT;\n          }\n          iterator \u003d db.iterator();\n          for (iterator.seek(first); entity.getEvents().size() \u003c limit \u0026\u0026\n              iterator.hasNext(); iterator.next()) {\n            byte[] key \u003d iterator.peekNext().getKey();\n            if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n                WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                    last.length) \u003e 0)) {\n              break;\n            }\n            TimelineEvent event \u003d getEntityEvent(eventType, key, prefix.length,\n                iterator.peekNext().getValue());\n            if (event !\u003d null) {\n              entity.addEvent(event);\n            }\n          }\n        }\n      }\n    } finally {\n      IOUtils.cleanup(LOG, iterator);\n    }\n    return events;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/timeline/LeveldbTimelineStore.java",
      "extendedDetails": {
        "oldPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/applicationhistoryservice/timeline/LeveldbTimelineStore.java",
        "newPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/timeline/LeveldbTimelineStore.java"
      }
    },
    "b3ea4aebff42131642af0393748dc751cb3fc31e": {
      "type": "Ybodychange",
      "commitMessage": "YARN-1717. Enabled periodically discarding old data in LeveldbTimelineStore. Contributed by Billie Rinaldi.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1577693 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/03/14 1:35 PM",
      "commitName": "b3ea4aebff42131642af0393748dc751cb3fc31e",
      "commitAuthor": "Zhijie Shen",
      "commitDateOld": "04/03/14 9:32 AM",
      "commitNameOld": "40464fba22bac99d0e5b79674152aa5dfba99483",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 10.13,
      "commitsBetweenForRepo": 99,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,79 +1,82 @@\n   public TimelineEvents getEntityTimelines(String entityType,\n       SortedSet\u003cString\u003e entityIds, Long limit, Long windowStart,\n       Long windowEnd, Set\u003cString\u003e eventType) throws IOException {\n     TimelineEvents events \u003d new TimelineEvents();\n-    if (entityIds \u003d\u003d null || entityIds.isEmpty())\n+    if (entityIds \u003d\u003d null || entityIds.isEmpty()) {\n       return events;\n+    }\n     // create a lexicographically-ordered map from start time to entities\n     Map\u003cbyte[], List\u003cEntityIdentifier\u003e\u003e startTimeMap \u003d new TreeMap\u003cbyte[],\n         List\u003cEntityIdentifier\u003e\u003e(new Comparator\u003cbyte[]\u003e() {\n           @Override\n           public int compare(byte[] o1, byte[] o2) {\n             return WritableComparator.compareBytes(o1, 0, o1.length, o2, 0,\n                 o2.length);\n           }\n         });\n     DBIterator iterator \u003d null;\n     try {\n       // look up start times for the specified entities\n       // skip entities with no start time\n-      for (String entity : entityIds) {\n-        byte[] startTime \u003d getStartTime(entity, entityType);\n+      for (String entityId : entityIds) {\n+        byte[] startTime \u003d getStartTime(entityId, entityType);\n         if (startTime !\u003d null) {\n           List\u003cEntityIdentifier\u003e entities \u003d startTimeMap.get(startTime);\n           if (entities \u003d\u003d null) {\n             entities \u003d new ArrayList\u003cEntityIdentifier\u003e();\n             startTimeMap.put(startTime, entities);\n           }\n-          entities.add(new EntityIdentifier(entity, entityType));\n+          entities.add(new EntityIdentifier(entityId, entityType));\n         }\n       }\n       for (Entry\u003cbyte[], List\u003cEntityIdentifier\u003e\u003e entry :\n           startTimeMap.entrySet()) {\n         // look up the events matching the given parameters (limit,\n         // start time, end time, event types) for entities whose start times\n         // were found and add the entities to the return list\n         byte[] revStartTime \u003d entry.getKey();\n-        for (EntityIdentifier entityID : entry.getValue()) {\n+        for (EntityIdentifier entityIdentifier : entry.getValue()) {\n           EventsOfOneEntity entity \u003d new EventsOfOneEntity();\n-          entity.setEntityId(entityID.getId());\n+          entity.setEntityId(entityIdentifier.getId());\n           entity.setEntityType(entityType);\n           events.addEvent(entity);\n           KeyBuilder kb \u003d KeyBuilder.newInstance().add(ENTITY_ENTRY_PREFIX)\n-              .add(entityType).add(revStartTime).add(entityID.getId())\n-              .add(TIME_COLUMN);\n+              .add(entityType).add(revStartTime).add(entityIdentifier.getId())\n+              .add(EVENTS_COLUMN);\n           byte[] prefix \u003d kb.getBytesForLookup();\n           if (windowEnd \u003d\u003d null) {\n             windowEnd \u003d Long.MAX_VALUE;\n           }\n           byte[] revts \u003d writeReverseOrderedLong(windowEnd);\n           kb.add(revts);\n           byte[] first \u003d kb.getBytesForLookup();\n           byte[] last \u003d null;\n           if (windowStart !\u003d null) {\n             last \u003d KeyBuilder.newInstance().add(prefix)\n                 .add(writeReverseOrderedLong(windowStart)).getBytesForLookup();\n           }\n           if (limit \u003d\u003d null) {\n             limit \u003d DEFAULT_LIMIT;\n           }\n           iterator \u003d db.iterator();\n           for (iterator.seek(first); entity.getEvents().size() \u003c limit \u0026\u0026\n               iterator.hasNext(); iterator.next()) {\n             byte[] key \u003d iterator.peekNext().getKey();\n             if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n                 WritableComparator.compareBytes(key, 0, key.length, last, 0,\n-                    last.length) \u003e 0))\n+                    last.length) \u003e 0)) {\n               break;\n+            }\n             TimelineEvent event \u003d getEntityEvent(eventType, key, prefix.length,\n                 iterator.peekNext().getValue());\n-            if (event !\u003d null)\n+            if (event !\u003d null) {\n               entity.addEvent(event);\n+            }\n           }\n         }\n       }\n     } finally {\n       IOUtils.cleanup(LOG, iterator);\n     }\n     return events;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public TimelineEvents getEntityTimelines(String entityType,\n      SortedSet\u003cString\u003e entityIds, Long limit, Long windowStart,\n      Long windowEnd, Set\u003cString\u003e eventType) throws IOException {\n    TimelineEvents events \u003d new TimelineEvents();\n    if (entityIds \u003d\u003d null || entityIds.isEmpty()) {\n      return events;\n    }\n    // create a lexicographically-ordered map from start time to entities\n    Map\u003cbyte[], List\u003cEntityIdentifier\u003e\u003e startTimeMap \u003d new TreeMap\u003cbyte[],\n        List\u003cEntityIdentifier\u003e\u003e(new Comparator\u003cbyte[]\u003e() {\n          @Override\n          public int compare(byte[] o1, byte[] o2) {\n            return WritableComparator.compareBytes(o1, 0, o1.length, o2, 0,\n                o2.length);\n          }\n        });\n    DBIterator iterator \u003d null;\n    try {\n      // look up start times for the specified entities\n      // skip entities with no start time\n      for (String entityId : entityIds) {\n        byte[] startTime \u003d getStartTime(entityId, entityType);\n        if (startTime !\u003d null) {\n          List\u003cEntityIdentifier\u003e entities \u003d startTimeMap.get(startTime);\n          if (entities \u003d\u003d null) {\n            entities \u003d new ArrayList\u003cEntityIdentifier\u003e();\n            startTimeMap.put(startTime, entities);\n          }\n          entities.add(new EntityIdentifier(entityId, entityType));\n        }\n      }\n      for (Entry\u003cbyte[], List\u003cEntityIdentifier\u003e\u003e entry :\n          startTimeMap.entrySet()) {\n        // look up the events matching the given parameters (limit,\n        // start time, end time, event types) for entities whose start times\n        // were found and add the entities to the return list\n        byte[] revStartTime \u003d entry.getKey();\n        for (EntityIdentifier entityIdentifier : entry.getValue()) {\n          EventsOfOneEntity entity \u003d new EventsOfOneEntity();\n          entity.setEntityId(entityIdentifier.getId());\n          entity.setEntityType(entityType);\n          events.addEvent(entity);\n          KeyBuilder kb \u003d KeyBuilder.newInstance().add(ENTITY_ENTRY_PREFIX)\n              .add(entityType).add(revStartTime).add(entityIdentifier.getId())\n              .add(EVENTS_COLUMN);\n          byte[] prefix \u003d kb.getBytesForLookup();\n          if (windowEnd \u003d\u003d null) {\n            windowEnd \u003d Long.MAX_VALUE;\n          }\n          byte[] revts \u003d writeReverseOrderedLong(windowEnd);\n          kb.add(revts);\n          byte[] first \u003d kb.getBytesForLookup();\n          byte[] last \u003d null;\n          if (windowStart !\u003d null) {\n            last \u003d KeyBuilder.newInstance().add(prefix)\n                .add(writeReverseOrderedLong(windowStart)).getBytesForLookup();\n          }\n          if (limit \u003d\u003d null) {\n            limit \u003d DEFAULT_LIMIT;\n          }\n          iterator \u003d db.iterator();\n          for (iterator.seek(first); entity.getEvents().size() \u003c limit \u0026\u0026\n              iterator.hasNext(); iterator.next()) {\n            byte[] key \u003d iterator.peekNext().getKey();\n            if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n                WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                    last.length) \u003e 0)) {\n              break;\n            }\n            TimelineEvent event \u003d getEntityEvent(eventType, key, prefix.length,\n                iterator.peekNext().getValue());\n            if (event !\u003d null) {\n              entity.addEvent(event);\n            }\n          }\n        }\n      }\n    } finally {\n      IOUtils.cleanup(LOG, iterator);\n    }\n    return events;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/applicationhistoryservice/timeline/LeveldbTimelineStore.java",
      "extendedDetails": {}
    },
    "40464fba22bac99d0e5b79674152aa5dfba99483": {
      "type": "Ybodychange",
      "commitMessage": "YARN-1730. Implemented simple write-locking in the LevelDB based timeline-store. Contributed by Billie Rinaldi.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1574145 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/03/14 9:32 AM",
      "commitName": "40464fba22bac99d0e5b79674152aa5dfba99483",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "22/02/14 12:55 PM",
      "commitNameOld": "84425fb435cb603fd8adcc2f76631c0244175310",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 9.86,
      "commitsBetweenForRepo": 64,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,79 +1,79 @@\n   public TimelineEvents getEntityTimelines(String entityType,\n       SortedSet\u003cString\u003e entityIds, Long limit, Long windowStart,\n       Long windowEnd, Set\u003cString\u003e eventType) throws IOException {\n     TimelineEvents events \u003d new TimelineEvents();\n     if (entityIds \u003d\u003d null || entityIds.isEmpty())\n       return events;\n     // create a lexicographically-ordered map from start time to entities\n     Map\u003cbyte[], List\u003cEntityIdentifier\u003e\u003e startTimeMap \u003d new TreeMap\u003cbyte[],\n         List\u003cEntityIdentifier\u003e\u003e(new Comparator\u003cbyte[]\u003e() {\n           @Override\n           public int compare(byte[] o1, byte[] o2) {\n             return WritableComparator.compareBytes(o1, 0, o1.length, o2, 0,\n                 o2.length);\n           }\n         });\n     DBIterator iterator \u003d null;\n     try {\n       // look up start times for the specified entities\n       // skip entities with no start time\n       for (String entity : entityIds) {\n-        byte[] startTime \u003d getStartTime(entity, entityType, null, null, null);\n+        byte[] startTime \u003d getStartTime(entity, entityType);\n         if (startTime !\u003d null) {\n           List\u003cEntityIdentifier\u003e entities \u003d startTimeMap.get(startTime);\n           if (entities \u003d\u003d null) {\n             entities \u003d new ArrayList\u003cEntityIdentifier\u003e();\n             startTimeMap.put(startTime, entities);\n           }\n           entities.add(new EntityIdentifier(entity, entityType));\n         }\n       }\n       for (Entry\u003cbyte[], List\u003cEntityIdentifier\u003e\u003e entry :\n           startTimeMap.entrySet()) {\n         // look up the events matching the given parameters (limit,\n         // start time, end time, event types) for entities whose start times\n         // were found and add the entities to the return list\n         byte[] revStartTime \u003d entry.getKey();\n         for (EntityIdentifier entityID : entry.getValue()) {\n           EventsOfOneEntity entity \u003d new EventsOfOneEntity();\n           entity.setEntityId(entityID.getId());\n           entity.setEntityType(entityType);\n           events.addEvent(entity);\n           KeyBuilder kb \u003d KeyBuilder.newInstance().add(ENTITY_ENTRY_PREFIX)\n               .add(entityType).add(revStartTime).add(entityID.getId())\n               .add(TIME_COLUMN);\n           byte[] prefix \u003d kb.getBytesForLookup();\n           if (windowEnd \u003d\u003d null) {\n             windowEnd \u003d Long.MAX_VALUE;\n           }\n           byte[] revts \u003d writeReverseOrderedLong(windowEnd);\n           kb.add(revts);\n           byte[] first \u003d kb.getBytesForLookup();\n           byte[] last \u003d null;\n           if (windowStart !\u003d null) {\n             last \u003d KeyBuilder.newInstance().add(prefix)\n                 .add(writeReverseOrderedLong(windowStart)).getBytesForLookup();\n           }\n           if (limit \u003d\u003d null) {\n             limit \u003d DEFAULT_LIMIT;\n           }\n           iterator \u003d db.iterator();\n           for (iterator.seek(first); entity.getEvents().size() \u003c limit \u0026\u0026\n               iterator.hasNext(); iterator.next()) {\n             byte[] key \u003d iterator.peekNext().getKey();\n             if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n                 WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                     last.length) \u003e 0))\n               break;\n             TimelineEvent event \u003d getEntityEvent(eventType, key, prefix.length,\n                 iterator.peekNext().getValue());\n             if (event !\u003d null)\n               entity.addEvent(event);\n           }\n         }\n       }\n     } finally {\n       IOUtils.cleanup(LOG, iterator);\n     }\n     return events;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public TimelineEvents getEntityTimelines(String entityType,\n      SortedSet\u003cString\u003e entityIds, Long limit, Long windowStart,\n      Long windowEnd, Set\u003cString\u003e eventType) throws IOException {\n    TimelineEvents events \u003d new TimelineEvents();\n    if (entityIds \u003d\u003d null || entityIds.isEmpty())\n      return events;\n    // create a lexicographically-ordered map from start time to entities\n    Map\u003cbyte[], List\u003cEntityIdentifier\u003e\u003e startTimeMap \u003d new TreeMap\u003cbyte[],\n        List\u003cEntityIdentifier\u003e\u003e(new Comparator\u003cbyte[]\u003e() {\n          @Override\n          public int compare(byte[] o1, byte[] o2) {\n            return WritableComparator.compareBytes(o1, 0, o1.length, o2, 0,\n                o2.length);\n          }\n        });\n    DBIterator iterator \u003d null;\n    try {\n      // look up start times for the specified entities\n      // skip entities with no start time\n      for (String entity : entityIds) {\n        byte[] startTime \u003d getStartTime(entity, entityType);\n        if (startTime !\u003d null) {\n          List\u003cEntityIdentifier\u003e entities \u003d startTimeMap.get(startTime);\n          if (entities \u003d\u003d null) {\n            entities \u003d new ArrayList\u003cEntityIdentifier\u003e();\n            startTimeMap.put(startTime, entities);\n          }\n          entities.add(new EntityIdentifier(entity, entityType));\n        }\n      }\n      for (Entry\u003cbyte[], List\u003cEntityIdentifier\u003e\u003e entry :\n          startTimeMap.entrySet()) {\n        // look up the events matching the given parameters (limit,\n        // start time, end time, event types) for entities whose start times\n        // were found and add the entities to the return list\n        byte[] revStartTime \u003d entry.getKey();\n        for (EntityIdentifier entityID : entry.getValue()) {\n          EventsOfOneEntity entity \u003d new EventsOfOneEntity();\n          entity.setEntityId(entityID.getId());\n          entity.setEntityType(entityType);\n          events.addEvent(entity);\n          KeyBuilder kb \u003d KeyBuilder.newInstance().add(ENTITY_ENTRY_PREFIX)\n              .add(entityType).add(revStartTime).add(entityID.getId())\n              .add(TIME_COLUMN);\n          byte[] prefix \u003d kb.getBytesForLookup();\n          if (windowEnd \u003d\u003d null) {\n            windowEnd \u003d Long.MAX_VALUE;\n          }\n          byte[] revts \u003d writeReverseOrderedLong(windowEnd);\n          kb.add(revts);\n          byte[] first \u003d kb.getBytesForLookup();\n          byte[] last \u003d null;\n          if (windowStart !\u003d null) {\n            last \u003d KeyBuilder.newInstance().add(prefix)\n                .add(writeReverseOrderedLong(windowStart)).getBytesForLookup();\n          }\n          if (limit \u003d\u003d null) {\n            limit \u003d DEFAULT_LIMIT;\n          }\n          iterator \u003d db.iterator();\n          for (iterator.seek(first); entity.getEvents().size() \u003c limit \u0026\u0026\n              iterator.hasNext(); iterator.next()) {\n            byte[] key \u003d iterator.peekNext().getKey();\n            if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n                WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                    last.length) \u003e 0))\n              break;\n            TimelineEvent event \u003d getEntityEvent(eventType, key, prefix.length,\n                iterator.peekNext().getValue());\n            if (event !\u003d null)\n              entity.addEvent(event);\n          }\n        }\n      }\n    } finally {\n      IOUtils.cleanup(LOG, iterator);\n    }\n    return events;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/applicationhistoryservice/timeline/LeveldbTimelineStore.java",
      "extendedDetails": {}
    },
    "84425fb435cb603fd8adcc2f76631c0244175310": {
      "type": "Ymultichange(Yfilerename,Yreturntypechange,Ybodychange)",
      "commitMessage": "YARN-1687. Renamed user-facing records for the timeline-service to be simply named after \u0027timeline\u0027 instead of \u0027apptimeline\u0027. Contributed by Zhijie Shen.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1570922 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "22/02/14 12:55 PM",
      "commitName": "84425fb435cb603fd8adcc2f76631c0244175310",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "subchanges": [
        {
          "type": "Yfilerename",
          "commitMessage": "YARN-1687. Renamed user-facing records for the timeline-service to be simply named after \u0027timeline\u0027 instead of \u0027apptimeline\u0027. Contributed by Zhijie Shen.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1570922 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "22/02/14 12:55 PM",
          "commitName": "84425fb435cb603fd8adcc2f76631c0244175310",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "22/02/14 12:46 PM",
          "commitNameOld": "e06226126cd89d0cf8b4ef80a88659b248579231",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 0.01,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,79 +1,79 @@\n-  public ATSEvents getEntityTimelines(String entityType,\n+  public TimelineEvents getEntityTimelines(String entityType,\n       SortedSet\u003cString\u003e entityIds, Long limit, Long windowStart,\n       Long windowEnd, Set\u003cString\u003e eventType) throws IOException {\n-    ATSEvents atsEvents \u003d new ATSEvents();\n+    TimelineEvents events \u003d new TimelineEvents();\n     if (entityIds \u003d\u003d null || entityIds.isEmpty())\n-      return atsEvents;\n+      return events;\n     // create a lexicographically-ordered map from start time to entities\n     Map\u003cbyte[], List\u003cEntityIdentifier\u003e\u003e startTimeMap \u003d new TreeMap\u003cbyte[],\n         List\u003cEntityIdentifier\u003e\u003e(new Comparator\u003cbyte[]\u003e() {\n           @Override\n           public int compare(byte[] o1, byte[] o2) {\n             return WritableComparator.compareBytes(o1, 0, o1.length, o2, 0,\n                 o2.length);\n           }\n         });\n     DBIterator iterator \u003d null;\n     try {\n       // look up start times for the specified entities\n       // skip entities with no start time\n       for (String entity : entityIds) {\n         byte[] startTime \u003d getStartTime(entity, entityType, null, null, null);\n         if (startTime !\u003d null) {\n           List\u003cEntityIdentifier\u003e entities \u003d startTimeMap.get(startTime);\n           if (entities \u003d\u003d null) {\n             entities \u003d new ArrayList\u003cEntityIdentifier\u003e();\n             startTimeMap.put(startTime, entities);\n           }\n           entities.add(new EntityIdentifier(entity, entityType));\n         }\n       }\n       for (Entry\u003cbyte[], List\u003cEntityIdentifier\u003e\u003e entry :\n           startTimeMap.entrySet()) {\n         // look up the events matching the given parameters (limit,\n         // start time, end time, event types) for entities whose start times\n         // were found and add the entities to the return list\n         byte[] revStartTime \u003d entry.getKey();\n-        for (EntityIdentifier entity : entry.getValue()) {\n-          ATSEventsOfOneEntity atsEntity \u003d new ATSEventsOfOneEntity();\n-          atsEntity.setEntityId(entity.getId());\n-          atsEntity.setEntityType(entityType);\n-          atsEvents.addEvent(atsEntity);\n+        for (EntityIdentifier entityID : entry.getValue()) {\n+          EventsOfOneEntity entity \u003d new EventsOfOneEntity();\n+          entity.setEntityId(entityID.getId());\n+          entity.setEntityType(entityType);\n+          events.addEvent(entity);\n           KeyBuilder kb \u003d KeyBuilder.newInstance().add(ENTITY_ENTRY_PREFIX)\n-              .add(entityType).add(revStartTime).add(entity.getId())\n+              .add(entityType).add(revStartTime).add(entityID.getId())\n               .add(TIME_COLUMN);\n           byte[] prefix \u003d kb.getBytesForLookup();\n           if (windowEnd \u003d\u003d null) {\n             windowEnd \u003d Long.MAX_VALUE;\n           }\n           byte[] revts \u003d writeReverseOrderedLong(windowEnd);\n           kb.add(revts);\n           byte[] first \u003d kb.getBytesForLookup();\n           byte[] last \u003d null;\n           if (windowStart !\u003d null) {\n             last \u003d KeyBuilder.newInstance().add(prefix)\n                 .add(writeReverseOrderedLong(windowStart)).getBytesForLookup();\n           }\n           if (limit \u003d\u003d null) {\n             limit \u003d DEFAULT_LIMIT;\n           }\n           iterator \u003d db.iterator();\n-          for (iterator.seek(first); atsEntity.getEvents().size() \u003c limit \u0026\u0026\n+          for (iterator.seek(first); entity.getEvents().size() \u003c limit \u0026\u0026\n               iterator.hasNext(); iterator.next()) {\n             byte[] key \u003d iterator.peekNext().getKey();\n             if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n                 WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                     last.length) \u003e 0))\n               break;\n-            ATSEvent event \u003d getEntityEvent(eventType, key, prefix.length,\n+            TimelineEvent event \u003d getEntityEvent(eventType, key, prefix.length,\n                 iterator.peekNext().getValue());\n             if (event !\u003d null)\n-              atsEntity.addEvent(event);\n+              entity.addEvent(event);\n           }\n         }\n       }\n     } finally {\n       IOUtils.cleanup(LOG, iterator);\n     }\n-    return atsEvents;\n+    return events;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public TimelineEvents getEntityTimelines(String entityType,\n      SortedSet\u003cString\u003e entityIds, Long limit, Long windowStart,\n      Long windowEnd, Set\u003cString\u003e eventType) throws IOException {\n    TimelineEvents events \u003d new TimelineEvents();\n    if (entityIds \u003d\u003d null || entityIds.isEmpty())\n      return events;\n    // create a lexicographically-ordered map from start time to entities\n    Map\u003cbyte[], List\u003cEntityIdentifier\u003e\u003e startTimeMap \u003d new TreeMap\u003cbyte[],\n        List\u003cEntityIdentifier\u003e\u003e(new Comparator\u003cbyte[]\u003e() {\n          @Override\n          public int compare(byte[] o1, byte[] o2) {\n            return WritableComparator.compareBytes(o1, 0, o1.length, o2, 0,\n                o2.length);\n          }\n        });\n    DBIterator iterator \u003d null;\n    try {\n      // look up start times for the specified entities\n      // skip entities with no start time\n      for (String entity : entityIds) {\n        byte[] startTime \u003d getStartTime(entity, entityType, null, null, null);\n        if (startTime !\u003d null) {\n          List\u003cEntityIdentifier\u003e entities \u003d startTimeMap.get(startTime);\n          if (entities \u003d\u003d null) {\n            entities \u003d new ArrayList\u003cEntityIdentifier\u003e();\n            startTimeMap.put(startTime, entities);\n          }\n          entities.add(new EntityIdentifier(entity, entityType));\n        }\n      }\n      for (Entry\u003cbyte[], List\u003cEntityIdentifier\u003e\u003e entry :\n          startTimeMap.entrySet()) {\n        // look up the events matching the given parameters (limit,\n        // start time, end time, event types) for entities whose start times\n        // were found and add the entities to the return list\n        byte[] revStartTime \u003d entry.getKey();\n        for (EntityIdentifier entityID : entry.getValue()) {\n          EventsOfOneEntity entity \u003d new EventsOfOneEntity();\n          entity.setEntityId(entityID.getId());\n          entity.setEntityType(entityType);\n          events.addEvent(entity);\n          KeyBuilder kb \u003d KeyBuilder.newInstance().add(ENTITY_ENTRY_PREFIX)\n              .add(entityType).add(revStartTime).add(entityID.getId())\n              .add(TIME_COLUMN);\n          byte[] prefix \u003d kb.getBytesForLookup();\n          if (windowEnd \u003d\u003d null) {\n            windowEnd \u003d Long.MAX_VALUE;\n          }\n          byte[] revts \u003d writeReverseOrderedLong(windowEnd);\n          kb.add(revts);\n          byte[] first \u003d kb.getBytesForLookup();\n          byte[] last \u003d null;\n          if (windowStart !\u003d null) {\n            last \u003d KeyBuilder.newInstance().add(prefix)\n                .add(writeReverseOrderedLong(windowStart)).getBytesForLookup();\n          }\n          if (limit \u003d\u003d null) {\n            limit \u003d DEFAULT_LIMIT;\n          }\n          iterator \u003d db.iterator();\n          for (iterator.seek(first); entity.getEvents().size() \u003c limit \u0026\u0026\n              iterator.hasNext(); iterator.next()) {\n            byte[] key \u003d iterator.peekNext().getKey();\n            if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n                WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                    last.length) \u003e 0))\n              break;\n            TimelineEvent event \u003d getEntityEvent(eventType, key, prefix.length,\n                iterator.peekNext().getValue());\n            if (event !\u003d null)\n              entity.addEvent(event);\n          }\n        }\n      }\n    } finally {\n      IOUtils.cleanup(LOG, iterator);\n    }\n    return events;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/applicationhistoryservice/timeline/LeveldbTimelineStore.java",
          "extendedDetails": {
            "oldPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/applicationhistoryservice/apptimeline/LeveldbApplicationTimelineStore.java",
            "newPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/applicationhistoryservice/timeline/LeveldbTimelineStore.java"
          }
        },
        {
          "type": "Yreturntypechange",
          "commitMessage": "YARN-1687. Renamed user-facing records for the timeline-service to be simply named after \u0027timeline\u0027 instead of \u0027apptimeline\u0027. Contributed by Zhijie Shen.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1570922 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "22/02/14 12:55 PM",
          "commitName": "84425fb435cb603fd8adcc2f76631c0244175310",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "22/02/14 12:46 PM",
          "commitNameOld": "e06226126cd89d0cf8b4ef80a88659b248579231",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 0.01,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,79 +1,79 @@\n-  public ATSEvents getEntityTimelines(String entityType,\n+  public TimelineEvents getEntityTimelines(String entityType,\n       SortedSet\u003cString\u003e entityIds, Long limit, Long windowStart,\n       Long windowEnd, Set\u003cString\u003e eventType) throws IOException {\n-    ATSEvents atsEvents \u003d new ATSEvents();\n+    TimelineEvents events \u003d new TimelineEvents();\n     if (entityIds \u003d\u003d null || entityIds.isEmpty())\n-      return atsEvents;\n+      return events;\n     // create a lexicographically-ordered map from start time to entities\n     Map\u003cbyte[], List\u003cEntityIdentifier\u003e\u003e startTimeMap \u003d new TreeMap\u003cbyte[],\n         List\u003cEntityIdentifier\u003e\u003e(new Comparator\u003cbyte[]\u003e() {\n           @Override\n           public int compare(byte[] o1, byte[] o2) {\n             return WritableComparator.compareBytes(o1, 0, o1.length, o2, 0,\n                 o2.length);\n           }\n         });\n     DBIterator iterator \u003d null;\n     try {\n       // look up start times for the specified entities\n       // skip entities with no start time\n       for (String entity : entityIds) {\n         byte[] startTime \u003d getStartTime(entity, entityType, null, null, null);\n         if (startTime !\u003d null) {\n           List\u003cEntityIdentifier\u003e entities \u003d startTimeMap.get(startTime);\n           if (entities \u003d\u003d null) {\n             entities \u003d new ArrayList\u003cEntityIdentifier\u003e();\n             startTimeMap.put(startTime, entities);\n           }\n           entities.add(new EntityIdentifier(entity, entityType));\n         }\n       }\n       for (Entry\u003cbyte[], List\u003cEntityIdentifier\u003e\u003e entry :\n           startTimeMap.entrySet()) {\n         // look up the events matching the given parameters (limit,\n         // start time, end time, event types) for entities whose start times\n         // were found and add the entities to the return list\n         byte[] revStartTime \u003d entry.getKey();\n-        for (EntityIdentifier entity : entry.getValue()) {\n-          ATSEventsOfOneEntity atsEntity \u003d new ATSEventsOfOneEntity();\n-          atsEntity.setEntityId(entity.getId());\n-          atsEntity.setEntityType(entityType);\n-          atsEvents.addEvent(atsEntity);\n+        for (EntityIdentifier entityID : entry.getValue()) {\n+          EventsOfOneEntity entity \u003d new EventsOfOneEntity();\n+          entity.setEntityId(entityID.getId());\n+          entity.setEntityType(entityType);\n+          events.addEvent(entity);\n           KeyBuilder kb \u003d KeyBuilder.newInstance().add(ENTITY_ENTRY_PREFIX)\n-              .add(entityType).add(revStartTime).add(entity.getId())\n+              .add(entityType).add(revStartTime).add(entityID.getId())\n               .add(TIME_COLUMN);\n           byte[] prefix \u003d kb.getBytesForLookup();\n           if (windowEnd \u003d\u003d null) {\n             windowEnd \u003d Long.MAX_VALUE;\n           }\n           byte[] revts \u003d writeReverseOrderedLong(windowEnd);\n           kb.add(revts);\n           byte[] first \u003d kb.getBytesForLookup();\n           byte[] last \u003d null;\n           if (windowStart !\u003d null) {\n             last \u003d KeyBuilder.newInstance().add(prefix)\n                 .add(writeReverseOrderedLong(windowStart)).getBytesForLookup();\n           }\n           if (limit \u003d\u003d null) {\n             limit \u003d DEFAULT_LIMIT;\n           }\n           iterator \u003d db.iterator();\n-          for (iterator.seek(first); atsEntity.getEvents().size() \u003c limit \u0026\u0026\n+          for (iterator.seek(first); entity.getEvents().size() \u003c limit \u0026\u0026\n               iterator.hasNext(); iterator.next()) {\n             byte[] key \u003d iterator.peekNext().getKey();\n             if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n                 WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                     last.length) \u003e 0))\n               break;\n-            ATSEvent event \u003d getEntityEvent(eventType, key, prefix.length,\n+            TimelineEvent event \u003d getEntityEvent(eventType, key, prefix.length,\n                 iterator.peekNext().getValue());\n             if (event !\u003d null)\n-              atsEntity.addEvent(event);\n+              entity.addEvent(event);\n           }\n         }\n       }\n     } finally {\n       IOUtils.cleanup(LOG, iterator);\n     }\n-    return atsEvents;\n+    return events;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public TimelineEvents getEntityTimelines(String entityType,\n      SortedSet\u003cString\u003e entityIds, Long limit, Long windowStart,\n      Long windowEnd, Set\u003cString\u003e eventType) throws IOException {\n    TimelineEvents events \u003d new TimelineEvents();\n    if (entityIds \u003d\u003d null || entityIds.isEmpty())\n      return events;\n    // create a lexicographically-ordered map from start time to entities\n    Map\u003cbyte[], List\u003cEntityIdentifier\u003e\u003e startTimeMap \u003d new TreeMap\u003cbyte[],\n        List\u003cEntityIdentifier\u003e\u003e(new Comparator\u003cbyte[]\u003e() {\n          @Override\n          public int compare(byte[] o1, byte[] o2) {\n            return WritableComparator.compareBytes(o1, 0, o1.length, o2, 0,\n                o2.length);\n          }\n        });\n    DBIterator iterator \u003d null;\n    try {\n      // look up start times for the specified entities\n      // skip entities with no start time\n      for (String entity : entityIds) {\n        byte[] startTime \u003d getStartTime(entity, entityType, null, null, null);\n        if (startTime !\u003d null) {\n          List\u003cEntityIdentifier\u003e entities \u003d startTimeMap.get(startTime);\n          if (entities \u003d\u003d null) {\n            entities \u003d new ArrayList\u003cEntityIdentifier\u003e();\n            startTimeMap.put(startTime, entities);\n          }\n          entities.add(new EntityIdentifier(entity, entityType));\n        }\n      }\n      for (Entry\u003cbyte[], List\u003cEntityIdentifier\u003e\u003e entry :\n          startTimeMap.entrySet()) {\n        // look up the events matching the given parameters (limit,\n        // start time, end time, event types) for entities whose start times\n        // were found and add the entities to the return list\n        byte[] revStartTime \u003d entry.getKey();\n        for (EntityIdentifier entityID : entry.getValue()) {\n          EventsOfOneEntity entity \u003d new EventsOfOneEntity();\n          entity.setEntityId(entityID.getId());\n          entity.setEntityType(entityType);\n          events.addEvent(entity);\n          KeyBuilder kb \u003d KeyBuilder.newInstance().add(ENTITY_ENTRY_PREFIX)\n              .add(entityType).add(revStartTime).add(entityID.getId())\n              .add(TIME_COLUMN);\n          byte[] prefix \u003d kb.getBytesForLookup();\n          if (windowEnd \u003d\u003d null) {\n            windowEnd \u003d Long.MAX_VALUE;\n          }\n          byte[] revts \u003d writeReverseOrderedLong(windowEnd);\n          kb.add(revts);\n          byte[] first \u003d kb.getBytesForLookup();\n          byte[] last \u003d null;\n          if (windowStart !\u003d null) {\n            last \u003d KeyBuilder.newInstance().add(prefix)\n                .add(writeReverseOrderedLong(windowStart)).getBytesForLookup();\n          }\n          if (limit \u003d\u003d null) {\n            limit \u003d DEFAULT_LIMIT;\n          }\n          iterator \u003d db.iterator();\n          for (iterator.seek(first); entity.getEvents().size() \u003c limit \u0026\u0026\n              iterator.hasNext(); iterator.next()) {\n            byte[] key \u003d iterator.peekNext().getKey();\n            if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n                WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                    last.length) \u003e 0))\n              break;\n            TimelineEvent event \u003d getEntityEvent(eventType, key, prefix.length,\n                iterator.peekNext().getValue());\n            if (event !\u003d null)\n              entity.addEvent(event);\n          }\n        }\n      }\n    } finally {\n      IOUtils.cleanup(LOG, iterator);\n    }\n    return events;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/applicationhistoryservice/timeline/LeveldbTimelineStore.java",
          "extendedDetails": {
            "oldValue": "ATSEvents",
            "newValue": "TimelineEvents"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-1687. Renamed user-facing records for the timeline-service to be simply named after \u0027timeline\u0027 instead of \u0027apptimeline\u0027. Contributed by Zhijie Shen.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1570922 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "22/02/14 12:55 PM",
          "commitName": "84425fb435cb603fd8adcc2f76631c0244175310",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "22/02/14 12:46 PM",
          "commitNameOld": "e06226126cd89d0cf8b4ef80a88659b248579231",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 0.01,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,79 +1,79 @@\n-  public ATSEvents getEntityTimelines(String entityType,\n+  public TimelineEvents getEntityTimelines(String entityType,\n       SortedSet\u003cString\u003e entityIds, Long limit, Long windowStart,\n       Long windowEnd, Set\u003cString\u003e eventType) throws IOException {\n-    ATSEvents atsEvents \u003d new ATSEvents();\n+    TimelineEvents events \u003d new TimelineEvents();\n     if (entityIds \u003d\u003d null || entityIds.isEmpty())\n-      return atsEvents;\n+      return events;\n     // create a lexicographically-ordered map from start time to entities\n     Map\u003cbyte[], List\u003cEntityIdentifier\u003e\u003e startTimeMap \u003d new TreeMap\u003cbyte[],\n         List\u003cEntityIdentifier\u003e\u003e(new Comparator\u003cbyte[]\u003e() {\n           @Override\n           public int compare(byte[] o1, byte[] o2) {\n             return WritableComparator.compareBytes(o1, 0, o1.length, o2, 0,\n                 o2.length);\n           }\n         });\n     DBIterator iterator \u003d null;\n     try {\n       // look up start times for the specified entities\n       // skip entities with no start time\n       for (String entity : entityIds) {\n         byte[] startTime \u003d getStartTime(entity, entityType, null, null, null);\n         if (startTime !\u003d null) {\n           List\u003cEntityIdentifier\u003e entities \u003d startTimeMap.get(startTime);\n           if (entities \u003d\u003d null) {\n             entities \u003d new ArrayList\u003cEntityIdentifier\u003e();\n             startTimeMap.put(startTime, entities);\n           }\n           entities.add(new EntityIdentifier(entity, entityType));\n         }\n       }\n       for (Entry\u003cbyte[], List\u003cEntityIdentifier\u003e\u003e entry :\n           startTimeMap.entrySet()) {\n         // look up the events matching the given parameters (limit,\n         // start time, end time, event types) for entities whose start times\n         // were found and add the entities to the return list\n         byte[] revStartTime \u003d entry.getKey();\n-        for (EntityIdentifier entity : entry.getValue()) {\n-          ATSEventsOfOneEntity atsEntity \u003d new ATSEventsOfOneEntity();\n-          atsEntity.setEntityId(entity.getId());\n-          atsEntity.setEntityType(entityType);\n-          atsEvents.addEvent(atsEntity);\n+        for (EntityIdentifier entityID : entry.getValue()) {\n+          EventsOfOneEntity entity \u003d new EventsOfOneEntity();\n+          entity.setEntityId(entityID.getId());\n+          entity.setEntityType(entityType);\n+          events.addEvent(entity);\n           KeyBuilder kb \u003d KeyBuilder.newInstance().add(ENTITY_ENTRY_PREFIX)\n-              .add(entityType).add(revStartTime).add(entity.getId())\n+              .add(entityType).add(revStartTime).add(entityID.getId())\n               .add(TIME_COLUMN);\n           byte[] prefix \u003d kb.getBytesForLookup();\n           if (windowEnd \u003d\u003d null) {\n             windowEnd \u003d Long.MAX_VALUE;\n           }\n           byte[] revts \u003d writeReverseOrderedLong(windowEnd);\n           kb.add(revts);\n           byte[] first \u003d kb.getBytesForLookup();\n           byte[] last \u003d null;\n           if (windowStart !\u003d null) {\n             last \u003d KeyBuilder.newInstance().add(prefix)\n                 .add(writeReverseOrderedLong(windowStart)).getBytesForLookup();\n           }\n           if (limit \u003d\u003d null) {\n             limit \u003d DEFAULT_LIMIT;\n           }\n           iterator \u003d db.iterator();\n-          for (iterator.seek(first); atsEntity.getEvents().size() \u003c limit \u0026\u0026\n+          for (iterator.seek(first); entity.getEvents().size() \u003c limit \u0026\u0026\n               iterator.hasNext(); iterator.next()) {\n             byte[] key \u003d iterator.peekNext().getKey();\n             if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n                 WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                     last.length) \u003e 0))\n               break;\n-            ATSEvent event \u003d getEntityEvent(eventType, key, prefix.length,\n+            TimelineEvent event \u003d getEntityEvent(eventType, key, prefix.length,\n                 iterator.peekNext().getValue());\n             if (event !\u003d null)\n-              atsEntity.addEvent(event);\n+              entity.addEvent(event);\n           }\n         }\n       }\n     } finally {\n       IOUtils.cleanup(LOG, iterator);\n     }\n-    return atsEvents;\n+    return events;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public TimelineEvents getEntityTimelines(String entityType,\n      SortedSet\u003cString\u003e entityIds, Long limit, Long windowStart,\n      Long windowEnd, Set\u003cString\u003e eventType) throws IOException {\n    TimelineEvents events \u003d new TimelineEvents();\n    if (entityIds \u003d\u003d null || entityIds.isEmpty())\n      return events;\n    // create a lexicographically-ordered map from start time to entities\n    Map\u003cbyte[], List\u003cEntityIdentifier\u003e\u003e startTimeMap \u003d new TreeMap\u003cbyte[],\n        List\u003cEntityIdentifier\u003e\u003e(new Comparator\u003cbyte[]\u003e() {\n          @Override\n          public int compare(byte[] o1, byte[] o2) {\n            return WritableComparator.compareBytes(o1, 0, o1.length, o2, 0,\n                o2.length);\n          }\n        });\n    DBIterator iterator \u003d null;\n    try {\n      // look up start times for the specified entities\n      // skip entities with no start time\n      for (String entity : entityIds) {\n        byte[] startTime \u003d getStartTime(entity, entityType, null, null, null);\n        if (startTime !\u003d null) {\n          List\u003cEntityIdentifier\u003e entities \u003d startTimeMap.get(startTime);\n          if (entities \u003d\u003d null) {\n            entities \u003d new ArrayList\u003cEntityIdentifier\u003e();\n            startTimeMap.put(startTime, entities);\n          }\n          entities.add(new EntityIdentifier(entity, entityType));\n        }\n      }\n      for (Entry\u003cbyte[], List\u003cEntityIdentifier\u003e\u003e entry :\n          startTimeMap.entrySet()) {\n        // look up the events matching the given parameters (limit,\n        // start time, end time, event types) for entities whose start times\n        // were found and add the entities to the return list\n        byte[] revStartTime \u003d entry.getKey();\n        for (EntityIdentifier entityID : entry.getValue()) {\n          EventsOfOneEntity entity \u003d new EventsOfOneEntity();\n          entity.setEntityId(entityID.getId());\n          entity.setEntityType(entityType);\n          events.addEvent(entity);\n          KeyBuilder kb \u003d KeyBuilder.newInstance().add(ENTITY_ENTRY_PREFIX)\n              .add(entityType).add(revStartTime).add(entityID.getId())\n              .add(TIME_COLUMN);\n          byte[] prefix \u003d kb.getBytesForLookup();\n          if (windowEnd \u003d\u003d null) {\n            windowEnd \u003d Long.MAX_VALUE;\n          }\n          byte[] revts \u003d writeReverseOrderedLong(windowEnd);\n          kb.add(revts);\n          byte[] first \u003d kb.getBytesForLookup();\n          byte[] last \u003d null;\n          if (windowStart !\u003d null) {\n            last \u003d KeyBuilder.newInstance().add(prefix)\n                .add(writeReverseOrderedLong(windowStart)).getBytesForLookup();\n          }\n          if (limit \u003d\u003d null) {\n            limit \u003d DEFAULT_LIMIT;\n          }\n          iterator \u003d db.iterator();\n          for (iterator.seek(first); entity.getEvents().size() \u003c limit \u0026\u0026\n              iterator.hasNext(); iterator.next()) {\n            byte[] key \u003d iterator.peekNext().getKey();\n            if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n                WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                    last.length) \u003e 0))\n              break;\n            TimelineEvent event \u003d getEntityEvent(eventType, key, prefix.length,\n                iterator.peekNext().getValue());\n            if (event !\u003d null)\n              entity.addEvent(event);\n          }\n        }\n      }\n    } finally {\n      IOUtils.cleanup(LOG, iterator);\n    }\n    return events;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/applicationhistoryservice/timeline/LeveldbTimelineStore.java",
          "extendedDetails": {}
        }
      ]
    },
    "23b2e43f5d678517e33590d15dec73225b9c5682": {
      "type": "Yintroduced",
      "commitMessage": "YARN-1635. Implemented a Leveldb based ApplicationTimelineStore. Contributed by Billie Rinaldi.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1565868 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/02/14 6:15 PM",
      "commitName": "23b2e43f5d678517e33590d15dec73225b9c5682",
      "commitAuthor": "Zhijie Shen",
      "diff": "@@ -0,0 +1,79 @@\n+  public ATSEvents getEntityTimelines(String entityType,\n+      SortedSet\u003cString\u003e entityIds, Long limit, Long windowStart,\n+      Long windowEnd, Set\u003cString\u003e eventType) throws IOException {\n+    ATSEvents atsEvents \u003d new ATSEvents();\n+    if (entityIds \u003d\u003d null || entityIds.isEmpty())\n+      return atsEvents;\n+    // create a lexicographically-ordered map from start time to entities\n+    Map\u003cbyte[], List\u003cEntityIdentifier\u003e\u003e startTimeMap \u003d new TreeMap\u003cbyte[],\n+        List\u003cEntityIdentifier\u003e\u003e(new Comparator\u003cbyte[]\u003e() {\n+          @Override\n+          public int compare(byte[] o1, byte[] o2) {\n+            return WritableComparator.compareBytes(o1, 0, o1.length, o2, 0,\n+                o2.length);\n+          }\n+        });\n+    DBIterator iterator \u003d null;\n+    try {\n+      // look up start times for the specified entities\n+      // skip entities with no start time\n+      for (String entity : entityIds) {\n+        byte[] startTime \u003d getStartTime(entity, entityType, null, null, null);\n+        if (startTime !\u003d null) {\n+          List\u003cEntityIdentifier\u003e entities \u003d startTimeMap.get(startTime);\n+          if (entities \u003d\u003d null) {\n+            entities \u003d new ArrayList\u003cEntityIdentifier\u003e();\n+            startTimeMap.put(startTime, entities);\n+          }\n+          entities.add(new EntityIdentifier(entity, entityType));\n+        }\n+      }\n+      for (Entry\u003cbyte[], List\u003cEntityIdentifier\u003e\u003e entry :\n+          startTimeMap.entrySet()) {\n+        // look up the events matching the given parameters (limit,\n+        // start time, end time, event types) for entities whose start times\n+        // were found and add the entities to the return list\n+        byte[] revStartTime \u003d entry.getKey();\n+        for (EntityIdentifier entity : entry.getValue()) {\n+          ATSEventsOfOneEntity atsEntity \u003d new ATSEventsOfOneEntity();\n+          atsEntity.setEntityId(entity.getId());\n+          atsEntity.setEntityType(entityType);\n+          atsEvents.addEvent(atsEntity);\n+          KeyBuilder kb \u003d KeyBuilder.newInstance().add(ENTITY_ENTRY_PREFIX)\n+              .add(entityType).add(revStartTime).add(entity.getId())\n+              .add(TIME_COLUMN);\n+          byte[] prefix \u003d kb.getBytesForLookup();\n+          if (windowEnd \u003d\u003d null) {\n+            windowEnd \u003d Long.MAX_VALUE;\n+          }\n+          byte[] revts \u003d writeReverseOrderedLong(windowEnd);\n+          kb.add(revts);\n+          byte[] first \u003d kb.getBytesForLookup();\n+          byte[] last \u003d null;\n+          if (windowStart !\u003d null) {\n+            last \u003d KeyBuilder.newInstance().add(prefix)\n+                .add(writeReverseOrderedLong(windowStart)).getBytesForLookup();\n+          }\n+          if (limit \u003d\u003d null) {\n+            limit \u003d DEFAULT_LIMIT;\n+          }\n+          iterator \u003d db.iterator();\n+          for (iterator.seek(first); atsEntity.getEvents().size() \u003c limit \u0026\u0026\n+              iterator.hasNext(); iterator.next()) {\n+            byte[] key \u003d iterator.peekNext().getKey();\n+            if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n+                WritableComparator.compareBytes(key, 0, key.length, last, 0,\n+                    last.length) \u003e 0))\n+              break;\n+            ATSEvent event \u003d getEntityEvent(eventType, key, prefix.length,\n+                iterator.peekNext().getValue());\n+            if (event !\u003d null)\n+              atsEntity.addEvent(event);\n+          }\n+        }\n+      }\n+    } finally {\n+      IOUtils.cleanup(LOG, iterator);\n+    }\n+    return atsEvents;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public ATSEvents getEntityTimelines(String entityType,\n      SortedSet\u003cString\u003e entityIds, Long limit, Long windowStart,\n      Long windowEnd, Set\u003cString\u003e eventType) throws IOException {\n    ATSEvents atsEvents \u003d new ATSEvents();\n    if (entityIds \u003d\u003d null || entityIds.isEmpty())\n      return atsEvents;\n    // create a lexicographically-ordered map from start time to entities\n    Map\u003cbyte[], List\u003cEntityIdentifier\u003e\u003e startTimeMap \u003d new TreeMap\u003cbyte[],\n        List\u003cEntityIdentifier\u003e\u003e(new Comparator\u003cbyte[]\u003e() {\n          @Override\n          public int compare(byte[] o1, byte[] o2) {\n            return WritableComparator.compareBytes(o1, 0, o1.length, o2, 0,\n                o2.length);\n          }\n        });\n    DBIterator iterator \u003d null;\n    try {\n      // look up start times for the specified entities\n      // skip entities with no start time\n      for (String entity : entityIds) {\n        byte[] startTime \u003d getStartTime(entity, entityType, null, null, null);\n        if (startTime !\u003d null) {\n          List\u003cEntityIdentifier\u003e entities \u003d startTimeMap.get(startTime);\n          if (entities \u003d\u003d null) {\n            entities \u003d new ArrayList\u003cEntityIdentifier\u003e();\n            startTimeMap.put(startTime, entities);\n          }\n          entities.add(new EntityIdentifier(entity, entityType));\n        }\n      }\n      for (Entry\u003cbyte[], List\u003cEntityIdentifier\u003e\u003e entry :\n          startTimeMap.entrySet()) {\n        // look up the events matching the given parameters (limit,\n        // start time, end time, event types) for entities whose start times\n        // were found and add the entities to the return list\n        byte[] revStartTime \u003d entry.getKey();\n        for (EntityIdentifier entity : entry.getValue()) {\n          ATSEventsOfOneEntity atsEntity \u003d new ATSEventsOfOneEntity();\n          atsEntity.setEntityId(entity.getId());\n          atsEntity.setEntityType(entityType);\n          atsEvents.addEvent(atsEntity);\n          KeyBuilder kb \u003d KeyBuilder.newInstance().add(ENTITY_ENTRY_PREFIX)\n              .add(entityType).add(revStartTime).add(entity.getId())\n              .add(TIME_COLUMN);\n          byte[] prefix \u003d kb.getBytesForLookup();\n          if (windowEnd \u003d\u003d null) {\n            windowEnd \u003d Long.MAX_VALUE;\n          }\n          byte[] revts \u003d writeReverseOrderedLong(windowEnd);\n          kb.add(revts);\n          byte[] first \u003d kb.getBytesForLookup();\n          byte[] last \u003d null;\n          if (windowStart !\u003d null) {\n            last \u003d KeyBuilder.newInstance().add(prefix)\n                .add(writeReverseOrderedLong(windowStart)).getBytesForLookup();\n          }\n          if (limit \u003d\u003d null) {\n            limit \u003d DEFAULT_LIMIT;\n          }\n          iterator \u003d db.iterator();\n          for (iterator.seek(first); atsEntity.getEvents().size() \u003c limit \u0026\u0026\n              iterator.hasNext(); iterator.next()) {\n            byte[] key \u003d iterator.peekNext().getKey();\n            if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n                WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                    last.length) \u003e 0))\n              break;\n            ATSEvent event \u003d getEntityEvent(eventType, key, prefix.length,\n                iterator.peekNext().getValue());\n            if (event !\u003d null)\n              atsEntity.addEvent(event);\n          }\n        }\n      }\n    } finally {\n      IOUtils.cleanup(LOG, iterator);\n    }\n    return atsEvents;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/applicationhistoryservice/apptimeline/LeveldbApplicationTimelineStore.java"
    }
  }
}