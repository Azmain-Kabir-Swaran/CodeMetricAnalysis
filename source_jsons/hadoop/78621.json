{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "NflyFSystem.java",
  "functionName": "commit",
  "functionId": "commit",
  "sourceFilePath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/viewfs/NflyFSystem.java",
  "functionStartLine": 409,
  "functionEndLine": 444,
  "numCommitsSeen": 3,
  "timeTaken": 735,
  "changeHistory": [
    "1f3bc63e6772be81bc9a6a7d93ed81d2a9e066c0"
  ],
  "changeHistoryShort": {
    "1f3bc63e6772be81bc9a6a7d93ed81d2a9e066c0": "Yintroduced"
  },
  "changeHistoryDetails": {
    "1f3bc63e6772be81bc9a6a7d93ed81d2a9e066c0": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-12077. Provide a multi-URI replication Inode for ViewFs. Contributed by Gera Shegalov\n",
      "commitDate": "05/09/17 11:51 PM",
      "commitName": "1f3bc63e6772be81bc9a6a7d93ed81d2a9e066c0",
      "commitAuthor": "Chris Douglas",
      "diff": "@@ -0,0 +1,36 @@\n+    private void commit() throws IOException {\n+      final List\u003cIOException\u003e ioExceptions \u003d new ArrayList\u003cIOException\u003e();\n+      for (int i \u003d opSet.nextSetBit(0);\n+           i \u003e\u003d 0;\n+           i \u003d opSet.nextSetBit(i + 1)) {\n+        final NflyNode nflyNode \u003d nodes[i];\n+        try {\n+          if (useOverwrite) {\n+            nflyNode.fs.delete(nflyPath);\n+          }\n+          nflyNode.fs.rename(tmpPath, nflyPath);\n+\n+        } catch (Throwable t) {\n+          osException(i, \"commit\", t, ioExceptions);\n+        }\n+      }\n+\n+      if (opSet.cardinality() \u003c minReplication) {\n+        // cleanup should be done outside. If rename failed, it\u0027s unlikely that\n+        // delete will work either. It\u0027s the same kind of metadata-only op\n+        //\n+        throw MultipleIOException.createIOException(ioExceptions);\n+      }\n+\n+      // best effort to have a consistent timestamp\n+      final long commitTime \u003d System.currentTimeMillis();\n+      for (int i \u003d opSet.nextSetBit(0);\n+          i \u003e\u003d 0;\n+          i \u003d opSet.nextSetBit(i + 1)) {\n+        try {\n+          nodes[i].fs.setTimes(nflyPath, commitTime, commitTime);\n+        } catch (Throwable t) {\n+          LOG.info(\"Failed to set timestamp: \" + nodes[i] + \" \" + nflyPath);\n+        }\n+      }\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    private void commit() throws IOException {\n      final List\u003cIOException\u003e ioExceptions \u003d new ArrayList\u003cIOException\u003e();\n      for (int i \u003d opSet.nextSetBit(0);\n           i \u003e\u003d 0;\n           i \u003d opSet.nextSetBit(i + 1)) {\n        final NflyNode nflyNode \u003d nodes[i];\n        try {\n          if (useOverwrite) {\n            nflyNode.fs.delete(nflyPath);\n          }\n          nflyNode.fs.rename(tmpPath, nflyPath);\n\n        } catch (Throwable t) {\n          osException(i, \"commit\", t, ioExceptions);\n        }\n      }\n\n      if (opSet.cardinality() \u003c minReplication) {\n        // cleanup should be done outside. If rename failed, it\u0027s unlikely that\n        // delete will work either. It\u0027s the same kind of metadata-only op\n        //\n        throw MultipleIOException.createIOException(ioExceptions);\n      }\n\n      // best effort to have a consistent timestamp\n      final long commitTime \u003d System.currentTimeMillis();\n      for (int i \u003d opSet.nextSetBit(0);\n          i \u003e\u003d 0;\n          i \u003d opSet.nextSetBit(i + 1)) {\n        try {\n          nodes[i].fs.setTimes(nflyPath, commitTime, commitTime);\n        } catch (Throwable t) {\n          LOG.info(\"Failed to set timestamp: \" + nodes[i] + \" \" + nflyPath);\n        }\n      }\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/viewfs/NflyFSystem.java"
    }
  }
}