{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "RunJar.java",
  "functionName": "main",
  "functionId": "main___args-String[]",
  "sourceFilePath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/RunJar.java",
  "functionStartLine": 235,
  "functionEndLine": 237,
  "numCommitsSeen": 29,
  "timeTaken": 1390,
  "changeHistory": [
    "da4ba50269254456650c08c739f2b394d1182ee4",
    "0dc26819001474272cc044dd1fdb495aeaba8cac",
    "8a0c7323ce36032a56c228fc8076d9d3214274ba",
    "eec27822879dd151c6489771a717efdeaed6198e",
    "5760d03c87cf00c9086b1f07a7b57d756ac47aad",
    "9c2f4f634db124282f114a44b2e7dfc899693c1d",
    "07c5741c9a5ebec78a0db046e7fefcae2ca4b6af",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "0f6dfeeacbab65a31a33927a4eb84871d371fe52",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
    "a473f3773342695cdb47e3ae4fe432b81e7787fd",
    "bcd64325a11cb0dd5096ffc093d0ffa68c4fcc58",
    "5128a9a453d64bfe1ed978cf9ffed27985eeef36"
  ],
  "changeHistoryShort": {
    "da4ba50269254456650c08c739f2b394d1182ee4": "Ybodychange",
    "0dc26819001474272cc044dd1fdb495aeaba8cac": "Ybodychange",
    "8a0c7323ce36032a56c228fc8076d9d3214274ba": "Ybodychange",
    "eec27822879dd151c6489771a717efdeaed6198e": "Ybodychange",
    "5760d03c87cf00c9086b1f07a7b57d756ac47aad": "Ybodychange",
    "9c2f4f634db124282f114a44b2e7dfc899693c1d": "Ybodychange",
    "07c5741c9a5ebec78a0db046e7fefcae2ca4b6af": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "0f6dfeeacbab65a31a33927a4eb84871d371fe52": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yfilerename",
    "a473f3773342695cdb47e3ae4fe432b81e7787fd": "Ybodychange",
    "bcd64325a11cb0dd5096ffc093d0ffa68c4fcc58": "Ybodychange",
    "5128a9a453d64bfe1ed978cf9ffed27985eeef36": "Yintroduced"
  },
  "changeHistoryDetails": {
    "da4ba50269254456650c08c739f2b394d1182ee4": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-10893. isolated classloader on the client side. Contributed by Sangjin Lee\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1619604 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/08/14 2:38 PM",
      "commitName": "da4ba50269254456650c08c739f2b394d1182ee4",
      "commitAuthor": "Jason Darrell Lowe",
      "commitDateOld": "26/03/14 12:03 PM",
      "commitNameOld": "a126a01fa197beebe955837c8f2efbd3257f7aa5",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 148.11,
      "commitsBetweenForRepo": 1029,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,99 +1,3 @@\n   public static void main(String[] args) throws Throwable {\n-    String usage \u003d \"RunJar jarFile [mainClass] args...\";\n-\n-    if (args.length \u003c 1) {\n-      System.err.println(usage);\n-      System.exit(-1);\n-    }\n-\n-    int firstArg \u003d 0;\n-    String fileName \u003d args[firstArg++];\n-    File file \u003d new File(fileName);\n-    if (!file.exists() || !file.isFile()) {\n-      System.err.println(\"Not a valid JAR: \" + file.getCanonicalPath());\n-      System.exit(-1);\n-    }\n-    String mainClassName \u003d null;\n-\n-    JarFile jarFile;\n-    try {\n-      jarFile \u003d new JarFile(fileName);\n-    } catch(IOException io) {\n-      throw new IOException(\"Error opening job jar: \" + fileName)\n-        .initCause(io);\n-    }\n-\n-    Manifest manifest \u003d jarFile.getManifest();\n-    if (manifest !\u003d null) {\n-      mainClassName \u003d manifest.getMainAttributes().getValue(\"Main-Class\");\n-    }\n-    jarFile.close();\n-\n-    if (mainClassName \u003d\u003d null) {\n-      if (args.length \u003c 2) {\n-        System.err.println(usage);\n-        System.exit(-1);\n-      }\n-      mainClassName \u003d args[firstArg++];\n-    }\n-    mainClassName \u003d mainClassName.replaceAll(\"/\", \".\");\n-\n-    File tmpDir \u003d new File(new Configuration().get(\"hadoop.tmp.dir\"));\n-    ensureDirectory(tmpDir);\n-\n-    final File workDir;\n-    try { \n-      workDir \u003d File.createTempFile(\"hadoop-unjar\", \"\", tmpDir);\n-    } catch (IOException ioe) {\n-      // If user has insufficient perms to write to tmpDir, default  \n-      // \"Permission denied\" message doesn\u0027t specify a filename. \n-      System.err.println(\"Error creating temp dir in hadoop.tmp.dir \"\n-                         + tmpDir + \" due to \" + ioe.getMessage());\n-      System.exit(-1);\n-      return;\n-    }\n-\n-    if (!workDir.delete()) {\n-      System.err.println(\"Delete failed for \" + workDir);\n-      System.exit(-1);\n-    }\n-    ensureDirectory(workDir);\n-\n-    ShutdownHookManager.get().addShutdownHook(\n-      new Runnable() {\n-        @Override\n-        public void run() {\n-          FileUtil.fullyDelete(workDir);\n-        }\n-      }, SHUTDOWN_HOOK_PRIORITY);\n-\n-\n-    unJar(file, workDir);\n-\n-    ArrayList\u003cURL\u003e classPath \u003d new ArrayList\u003cURL\u003e();\n-    classPath.add(new File(workDir+\"/\").toURI().toURL());\n-    classPath.add(file.toURI().toURL());\n-    classPath.add(new File(workDir, \"classes/\").toURI().toURL());\n-    File[] libs \u003d new File(workDir, \"lib\").listFiles();\n-    if (libs !\u003d null) {\n-      for (int i \u003d 0; i \u003c libs.length; i++) {\n-        classPath.add(libs[i].toURI().toURL());\n-      }\n-    }\n-    \n-    ClassLoader loader \u003d\n-      new URLClassLoader(classPath.toArray(new URL[0]));\n-\n-    Thread.currentThread().setContextClassLoader(loader);\n-    Class\u003c?\u003e mainClass \u003d Class.forName(mainClassName, true, loader);\n-    Method main \u003d mainClass.getMethod(\"main\", new Class[] {\n-      Array.newInstance(String.class, 0).getClass()\n-    });\n-    String[] newArgs \u003d Arrays.asList(args)\n-      .subList(firstArg, args.length).toArray(new String[0]);\n-    try {\n-      main.invoke(null, new Object[] { newArgs });\n-    } catch (InvocationTargetException e) {\n-      throw e.getTargetException();\n-    }\n+    new RunJar().run(args);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static void main(String[] args) throws Throwable {\n    new RunJar().run(args);\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/RunJar.java",
      "extendedDetails": {}
    },
    "0dc26819001474272cc044dd1fdb495aeaba8cac": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-8951. RunJar to fail with user-comprehensible error message if jar missing. Contributed by Steve Loughran.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1400921 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "22/10/12 8:55 AM",
      "commitName": "0dc26819001474272cc044dd1fdb495aeaba8cac",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "30/04/12 12:21 PM",
      "commitNameOld": "8a0c7323ce36032a56c228fc8076d9d3214274ba",
      "commitAuthorOld": "Alejandro Abdelnur",
      "daysBetweenCommits": 174.86,
      "commitsBetweenForRepo": 1004,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,95 +1,99 @@\n   public static void main(String[] args) throws Throwable {\n     String usage \u003d \"RunJar jarFile [mainClass] args...\";\n \n     if (args.length \u003c 1) {\n       System.err.println(usage);\n       System.exit(-1);\n     }\n \n     int firstArg \u003d 0;\n     String fileName \u003d args[firstArg++];\n     File file \u003d new File(fileName);\n+    if (!file.exists() || !file.isFile()) {\n+      System.err.println(\"Not a valid JAR: \" + file.getCanonicalPath());\n+      System.exit(-1);\n+    }\n     String mainClassName \u003d null;\n \n     JarFile jarFile;\n     try {\n       jarFile \u003d new JarFile(fileName);\n     } catch(IOException io) {\n       throw new IOException(\"Error opening job jar: \" + fileName)\n         .initCause(io);\n     }\n \n     Manifest manifest \u003d jarFile.getManifest();\n     if (manifest !\u003d null) {\n       mainClassName \u003d manifest.getMainAttributes().getValue(\"Main-Class\");\n     }\n     jarFile.close();\n \n     if (mainClassName \u003d\u003d null) {\n       if (args.length \u003c 2) {\n         System.err.println(usage);\n         System.exit(-1);\n       }\n       mainClassName \u003d args[firstArg++];\n     }\n     mainClassName \u003d mainClassName.replaceAll(\"/\", \".\");\n \n     File tmpDir \u003d new File(new Configuration().get(\"hadoop.tmp.dir\"));\n     ensureDirectory(tmpDir);\n \n     final File workDir;\n     try { \n       workDir \u003d File.createTempFile(\"hadoop-unjar\", \"\", tmpDir);\n     } catch (IOException ioe) {\n       // If user has insufficient perms to write to tmpDir, default  \n       // \"Permission denied\" message doesn\u0027t specify a filename. \n       System.err.println(\"Error creating temp dir in hadoop.tmp.dir \"\n                          + tmpDir + \" due to \" + ioe.getMessage());\n       System.exit(-1);\n       return;\n     }\n \n     if (!workDir.delete()) {\n       System.err.println(\"Delete failed for \" + workDir);\n       System.exit(-1);\n     }\n     ensureDirectory(workDir);\n \n     ShutdownHookManager.get().addShutdownHook(\n       new Runnable() {\n         @Override\n         public void run() {\n           FileUtil.fullyDelete(workDir);\n         }\n       }, SHUTDOWN_HOOK_PRIORITY);\n \n \n     unJar(file, workDir);\n \n     ArrayList\u003cURL\u003e classPath \u003d new ArrayList\u003cURL\u003e();\n     classPath.add(new File(workDir+\"/\").toURI().toURL());\n     classPath.add(file.toURI().toURL());\n     classPath.add(new File(workDir, \"classes/\").toURI().toURL());\n     File[] libs \u003d new File(workDir, \"lib\").listFiles();\n     if (libs !\u003d null) {\n       for (int i \u003d 0; i \u003c libs.length; i++) {\n         classPath.add(libs[i].toURI().toURL());\n       }\n     }\n     \n     ClassLoader loader \u003d\n       new URLClassLoader(classPath.toArray(new URL[0]));\n \n     Thread.currentThread().setContextClassLoader(loader);\n     Class\u003c?\u003e mainClass \u003d Class.forName(mainClassName, true, loader);\n     Method main \u003d mainClass.getMethod(\"main\", new Class[] {\n       Array.newInstance(String.class, 0).getClass()\n     });\n     String[] newArgs \u003d Arrays.asList(args)\n       .subList(firstArg, args.length).toArray(new String[0]);\n     try {\n       main.invoke(null, new Object[] { newArgs });\n     } catch (InvocationTargetException e) {\n       throw e.getTargetException();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static void main(String[] args) throws Throwable {\n    String usage \u003d \"RunJar jarFile [mainClass] args...\";\n\n    if (args.length \u003c 1) {\n      System.err.println(usage);\n      System.exit(-1);\n    }\n\n    int firstArg \u003d 0;\n    String fileName \u003d args[firstArg++];\n    File file \u003d new File(fileName);\n    if (!file.exists() || !file.isFile()) {\n      System.err.println(\"Not a valid JAR: \" + file.getCanonicalPath());\n      System.exit(-1);\n    }\n    String mainClassName \u003d null;\n\n    JarFile jarFile;\n    try {\n      jarFile \u003d new JarFile(fileName);\n    } catch(IOException io) {\n      throw new IOException(\"Error opening job jar: \" + fileName)\n        .initCause(io);\n    }\n\n    Manifest manifest \u003d jarFile.getManifest();\n    if (manifest !\u003d null) {\n      mainClassName \u003d manifest.getMainAttributes().getValue(\"Main-Class\");\n    }\n    jarFile.close();\n\n    if (mainClassName \u003d\u003d null) {\n      if (args.length \u003c 2) {\n        System.err.println(usage);\n        System.exit(-1);\n      }\n      mainClassName \u003d args[firstArg++];\n    }\n    mainClassName \u003d mainClassName.replaceAll(\"/\", \".\");\n\n    File tmpDir \u003d new File(new Configuration().get(\"hadoop.tmp.dir\"));\n    ensureDirectory(tmpDir);\n\n    final File workDir;\n    try { \n      workDir \u003d File.createTempFile(\"hadoop-unjar\", \"\", tmpDir);\n    } catch (IOException ioe) {\n      // If user has insufficient perms to write to tmpDir, default  \n      // \"Permission denied\" message doesn\u0027t specify a filename. \n      System.err.println(\"Error creating temp dir in hadoop.tmp.dir \"\n                         + tmpDir + \" due to \" + ioe.getMessage());\n      System.exit(-1);\n      return;\n    }\n\n    if (!workDir.delete()) {\n      System.err.println(\"Delete failed for \" + workDir);\n      System.exit(-1);\n    }\n    ensureDirectory(workDir);\n\n    ShutdownHookManager.get().addShutdownHook(\n      new Runnable() {\n        @Override\n        public void run() {\n          FileUtil.fullyDelete(workDir);\n        }\n      }, SHUTDOWN_HOOK_PRIORITY);\n\n\n    unJar(file, workDir);\n\n    ArrayList\u003cURL\u003e classPath \u003d new ArrayList\u003cURL\u003e();\n    classPath.add(new File(workDir+\"/\").toURI().toURL());\n    classPath.add(file.toURI().toURL());\n    classPath.add(new File(workDir, \"classes/\").toURI().toURL());\n    File[] libs \u003d new File(workDir, \"lib\").listFiles();\n    if (libs !\u003d null) {\n      for (int i \u003d 0; i \u003c libs.length; i++) {\n        classPath.add(libs[i].toURI().toURL());\n      }\n    }\n    \n    ClassLoader loader \u003d\n      new URLClassLoader(classPath.toArray(new URL[0]));\n\n    Thread.currentThread().setContextClassLoader(loader);\n    Class\u003c?\u003e mainClass \u003d Class.forName(mainClassName, true, loader);\n    Method main \u003d mainClass.getMethod(\"main\", new Class[] {\n      Array.newInstance(String.class, 0).getClass()\n    });\n    String[] newArgs \u003d Arrays.asList(args)\n      .subList(firstArg, args.length).toArray(new String[0]);\n    try {\n      main.invoke(null, new Object[] { newArgs });\n    } catch (InvocationTargetException e) {\n      throw e.getTargetException();\n    }\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/RunJar.java",
      "extendedDetails": {}
    },
    "8a0c7323ce36032a56c228fc8076d9d3214274ba": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-8325. Add a ShutdownHookManager to be used by different components instead of the JVM shutdownhook (tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1332345 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "30/04/12 12:21 PM",
      "commitName": "8a0c7323ce36032a56c228fc8076d9d3214274ba",
      "commitAuthor": "Alejandro Abdelnur",
      "commitDateOld": "21/11/11 12:00 AM",
      "commitNameOld": "eec27822879dd151c6489771a717efdeaed6198e",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 161.47,
      "commitsBetweenForRepo": 1146,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,92 +1,95 @@\n   public static void main(String[] args) throws Throwable {\n     String usage \u003d \"RunJar jarFile [mainClass] args...\";\n \n     if (args.length \u003c 1) {\n       System.err.println(usage);\n       System.exit(-1);\n     }\n \n     int firstArg \u003d 0;\n     String fileName \u003d args[firstArg++];\n     File file \u003d new File(fileName);\n     String mainClassName \u003d null;\n \n     JarFile jarFile;\n     try {\n       jarFile \u003d new JarFile(fileName);\n     } catch(IOException io) {\n       throw new IOException(\"Error opening job jar: \" + fileName)\n         .initCause(io);\n     }\n \n     Manifest manifest \u003d jarFile.getManifest();\n     if (manifest !\u003d null) {\n       mainClassName \u003d manifest.getMainAttributes().getValue(\"Main-Class\");\n     }\n     jarFile.close();\n \n     if (mainClassName \u003d\u003d null) {\n       if (args.length \u003c 2) {\n         System.err.println(usage);\n         System.exit(-1);\n       }\n       mainClassName \u003d args[firstArg++];\n     }\n     mainClassName \u003d mainClassName.replaceAll(\"/\", \".\");\n \n     File tmpDir \u003d new File(new Configuration().get(\"hadoop.tmp.dir\"));\n     ensureDirectory(tmpDir);\n \n     final File workDir;\n     try { \n       workDir \u003d File.createTempFile(\"hadoop-unjar\", \"\", tmpDir);\n     } catch (IOException ioe) {\n       // If user has insufficient perms to write to tmpDir, default  \n       // \"Permission denied\" message doesn\u0027t specify a filename. \n       System.err.println(\"Error creating temp dir in hadoop.tmp.dir \"\n                          + tmpDir + \" due to \" + ioe.getMessage());\n       System.exit(-1);\n       return;\n     }\n \n     if (!workDir.delete()) {\n       System.err.println(\"Delete failed for \" + workDir);\n       System.exit(-1);\n     }\n     ensureDirectory(workDir);\n \n-    Runtime.getRuntime().addShutdownHook(new Thread() {\n+    ShutdownHookManager.get().addShutdownHook(\n+      new Runnable() {\n+        @Override\n         public void run() {\n           FileUtil.fullyDelete(workDir);\n         }\n-      });\n+      }, SHUTDOWN_HOOK_PRIORITY);\n+\n \n     unJar(file, workDir);\n \n     ArrayList\u003cURL\u003e classPath \u003d new ArrayList\u003cURL\u003e();\n     classPath.add(new File(workDir+\"/\").toURI().toURL());\n     classPath.add(file.toURI().toURL());\n     classPath.add(new File(workDir, \"classes/\").toURI().toURL());\n     File[] libs \u003d new File(workDir, \"lib\").listFiles();\n     if (libs !\u003d null) {\n       for (int i \u003d 0; i \u003c libs.length; i++) {\n         classPath.add(libs[i].toURI().toURL());\n       }\n     }\n     \n     ClassLoader loader \u003d\n       new URLClassLoader(classPath.toArray(new URL[0]));\n \n     Thread.currentThread().setContextClassLoader(loader);\n     Class\u003c?\u003e mainClass \u003d Class.forName(mainClassName, true, loader);\n     Method main \u003d mainClass.getMethod(\"main\", new Class[] {\n       Array.newInstance(String.class, 0).getClass()\n     });\n     String[] newArgs \u003d Arrays.asList(args)\n       .subList(firstArg, args.length).toArray(new String[0]);\n     try {\n       main.invoke(null, new Object[] { newArgs });\n     } catch (InvocationTargetException e) {\n       throw e.getTargetException();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static void main(String[] args) throws Throwable {\n    String usage \u003d \"RunJar jarFile [mainClass] args...\";\n\n    if (args.length \u003c 1) {\n      System.err.println(usage);\n      System.exit(-1);\n    }\n\n    int firstArg \u003d 0;\n    String fileName \u003d args[firstArg++];\n    File file \u003d new File(fileName);\n    String mainClassName \u003d null;\n\n    JarFile jarFile;\n    try {\n      jarFile \u003d new JarFile(fileName);\n    } catch(IOException io) {\n      throw new IOException(\"Error opening job jar: \" + fileName)\n        .initCause(io);\n    }\n\n    Manifest manifest \u003d jarFile.getManifest();\n    if (manifest !\u003d null) {\n      mainClassName \u003d manifest.getMainAttributes().getValue(\"Main-Class\");\n    }\n    jarFile.close();\n\n    if (mainClassName \u003d\u003d null) {\n      if (args.length \u003c 2) {\n        System.err.println(usage);\n        System.exit(-1);\n      }\n      mainClassName \u003d args[firstArg++];\n    }\n    mainClassName \u003d mainClassName.replaceAll(\"/\", \".\");\n\n    File tmpDir \u003d new File(new Configuration().get(\"hadoop.tmp.dir\"));\n    ensureDirectory(tmpDir);\n\n    final File workDir;\n    try { \n      workDir \u003d File.createTempFile(\"hadoop-unjar\", \"\", tmpDir);\n    } catch (IOException ioe) {\n      // If user has insufficient perms to write to tmpDir, default  \n      // \"Permission denied\" message doesn\u0027t specify a filename. \n      System.err.println(\"Error creating temp dir in hadoop.tmp.dir \"\n                         + tmpDir + \" due to \" + ioe.getMessage());\n      System.exit(-1);\n      return;\n    }\n\n    if (!workDir.delete()) {\n      System.err.println(\"Delete failed for \" + workDir);\n      System.exit(-1);\n    }\n    ensureDirectory(workDir);\n\n    ShutdownHookManager.get().addShutdownHook(\n      new Runnable() {\n        @Override\n        public void run() {\n          FileUtil.fullyDelete(workDir);\n        }\n      }, SHUTDOWN_HOOK_PRIORITY);\n\n\n    unJar(file, workDir);\n\n    ArrayList\u003cURL\u003e classPath \u003d new ArrayList\u003cURL\u003e();\n    classPath.add(new File(workDir+\"/\").toURI().toURL());\n    classPath.add(file.toURI().toURL());\n    classPath.add(new File(workDir, \"classes/\").toURI().toURL());\n    File[] libs \u003d new File(workDir, \"lib\").listFiles();\n    if (libs !\u003d null) {\n      for (int i \u003d 0; i \u003c libs.length; i++) {\n        classPath.add(libs[i].toURI().toURL());\n      }\n    }\n    \n    ClassLoader loader \u003d\n      new URLClassLoader(classPath.toArray(new URL[0]));\n\n    Thread.currentThread().setContextClassLoader(loader);\n    Class\u003c?\u003e mainClass \u003d Class.forName(mainClassName, true, loader);\n    Method main \u003d mainClass.getMethod(\"main\", new Class[] {\n      Array.newInstance(String.class, 0).getClass()\n    });\n    String[] newArgs \u003d Arrays.asList(args)\n      .subList(firstArg, args.length).toArray(new String[0]);\n    try {\n      main.invoke(null, new Object[] { newArgs });\n    } catch (InvocationTargetException e) {\n      throw e.getTargetException();\n    }\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/RunJar.java",
      "extendedDetails": {}
    },
    "eec27822879dd151c6489771a717efdeaed6198e": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-6614. RunJar should provide more diags when it can\u0027t create a temp file. Contributed by Jonathan Hsieh\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1204388 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/11/11 12:00 AM",
      "commitName": "eec27822879dd151c6489771a717efdeaed6198e",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "20/11/11 11:06 PM",
      "commitNameOld": "5760d03c87cf00c9086b1f07a7b57d756ac47aad",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 0.04,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,81 +1,92 @@\n   public static void main(String[] args) throws Throwable {\n     String usage \u003d \"RunJar jarFile [mainClass] args...\";\n \n     if (args.length \u003c 1) {\n       System.err.println(usage);\n       System.exit(-1);\n     }\n \n     int firstArg \u003d 0;\n     String fileName \u003d args[firstArg++];\n     File file \u003d new File(fileName);\n     String mainClassName \u003d null;\n \n     JarFile jarFile;\n     try {\n       jarFile \u003d new JarFile(fileName);\n     } catch(IOException io) {\n       throw new IOException(\"Error opening job jar: \" + fileName)\n         .initCause(io);\n     }\n \n     Manifest manifest \u003d jarFile.getManifest();\n     if (manifest !\u003d null) {\n       mainClassName \u003d manifest.getMainAttributes().getValue(\"Main-Class\");\n     }\n     jarFile.close();\n \n     if (mainClassName \u003d\u003d null) {\n       if (args.length \u003c 2) {\n         System.err.println(usage);\n         System.exit(-1);\n       }\n       mainClassName \u003d args[firstArg++];\n     }\n     mainClassName \u003d mainClassName.replaceAll(\"/\", \".\");\n \n     File tmpDir \u003d new File(new Configuration().get(\"hadoop.tmp.dir\"));\n     ensureDirectory(tmpDir);\n \n-    final File workDir \u003d File.createTempFile(\"hadoop-unjar\", \"\", tmpDir);\n+    final File workDir;\n+    try { \n+      workDir \u003d File.createTempFile(\"hadoop-unjar\", \"\", tmpDir);\n+    } catch (IOException ioe) {\n+      // If user has insufficient perms to write to tmpDir, default  \n+      // \"Permission denied\" message doesn\u0027t specify a filename. \n+      System.err.println(\"Error creating temp dir in hadoop.tmp.dir \"\n+                         + tmpDir + \" due to \" + ioe.getMessage());\n+      System.exit(-1);\n+      return;\n+    }\n+\n     if (!workDir.delete()) {\n       System.err.println(\"Delete failed for \" + workDir);\n       System.exit(-1);\n     }\n     ensureDirectory(workDir);\n \n     Runtime.getRuntime().addShutdownHook(new Thread() {\n         public void run() {\n           FileUtil.fullyDelete(workDir);\n         }\n       });\n \n     unJar(file, workDir);\n \n     ArrayList\u003cURL\u003e classPath \u003d new ArrayList\u003cURL\u003e();\n     classPath.add(new File(workDir+\"/\").toURI().toURL());\n     classPath.add(file.toURI().toURL());\n     classPath.add(new File(workDir, \"classes/\").toURI().toURL());\n     File[] libs \u003d new File(workDir, \"lib\").listFiles();\n     if (libs !\u003d null) {\n       for (int i \u003d 0; i \u003c libs.length; i++) {\n         classPath.add(libs[i].toURI().toURL());\n       }\n     }\n     \n     ClassLoader loader \u003d\n       new URLClassLoader(classPath.toArray(new URL[0]));\n \n     Thread.currentThread().setContextClassLoader(loader);\n     Class\u003c?\u003e mainClass \u003d Class.forName(mainClassName, true, loader);\n     Method main \u003d mainClass.getMethod(\"main\", new Class[] {\n       Array.newInstance(String.class, 0).getClass()\n     });\n     String[] newArgs \u003d Arrays.asList(args)\n       .subList(firstArg, args.length).toArray(new String[0]);\n     try {\n       main.invoke(null, new Object[] { newArgs });\n     } catch (InvocationTargetException e) {\n       throw e.getTargetException();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static void main(String[] args) throws Throwable {\n    String usage \u003d \"RunJar jarFile [mainClass] args...\";\n\n    if (args.length \u003c 1) {\n      System.err.println(usage);\n      System.exit(-1);\n    }\n\n    int firstArg \u003d 0;\n    String fileName \u003d args[firstArg++];\n    File file \u003d new File(fileName);\n    String mainClassName \u003d null;\n\n    JarFile jarFile;\n    try {\n      jarFile \u003d new JarFile(fileName);\n    } catch(IOException io) {\n      throw new IOException(\"Error opening job jar: \" + fileName)\n        .initCause(io);\n    }\n\n    Manifest manifest \u003d jarFile.getManifest();\n    if (manifest !\u003d null) {\n      mainClassName \u003d manifest.getMainAttributes().getValue(\"Main-Class\");\n    }\n    jarFile.close();\n\n    if (mainClassName \u003d\u003d null) {\n      if (args.length \u003c 2) {\n        System.err.println(usage);\n        System.exit(-1);\n      }\n      mainClassName \u003d args[firstArg++];\n    }\n    mainClassName \u003d mainClassName.replaceAll(\"/\", \".\");\n\n    File tmpDir \u003d new File(new Configuration().get(\"hadoop.tmp.dir\"));\n    ensureDirectory(tmpDir);\n\n    final File workDir;\n    try { \n      workDir \u003d File.createTempFile(\"hadoop-unjar\", \"\", tmpDir);\n    } catch (IOException ioe) {\n      // If user has insufficient perms to write to tmpDir, default  \n      // \"Permission denied\" message doesn\u0027t specify a filename. \n      System.err.println(\"Error creating temp dir in hadoop.tmp.dir \"\n                         + tmpDir + \" due to \" + ioe.getMessage());\n      System.exit(-1);\n      return;\n    }\n\n    if (!workDir.delete()) {\n      System.err.println(\"Delete failed for \" + workDir);\n      System.exit(-1);\n    }\n    ensureDirectory(workDir);\n\n    Runtime.getRuntime().addShutdownHook(new Thread() {\n        public void run() {\n          FileUtil.fullyDelete(workDir);\n        }\n      });\n\n    unJar(file, workDir);\n\n    ArrayList\u003cURL\u003e classPath \u003d new ArrayList\u003cURL\u003e();\n    classPath.add(new File(workDir+\"/\").toURI().toURL());\n    classPath.add(file.toURI().toURL());\n    classPath.add(new File(workDir, \"classes/\").toURI().toURL());\n    File[] libs \u003d new File(workDir, \"lib\").listFiles();\n    if (libs !\u003d null) {\n      for (int i \u003d 0; i \u003c libs.length; i++) {\n        classPath.add(libs[i].toURI().toURL());\n      }\n    }\n    \n    ClassLoader loader \u003d\n      new URLClassLoader(classPath.toArray(new URL[0]));\n\n    Thread.currentThread().setContextClassLoader(loader);\n    Class\u003c?\u003e mainClass \u003d Class.forName(mainClassName, true, loader);\n    Method main \u003d mainClass.getMethod(\"main\", new Class[] {\n      Array.newInstance(String.class, 0).getClass()\n    });\n    String[] newArgs \u003d Arrays.asList(args)\n      .subList(firstArg, args.length).toArray(new String[0]);\n    try {\n      main.invoke(null, new Object[] { newArgs });\n    } catch (InvocationTargetException e) {\n      throw e.getTargetException();\n    }\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/RunJar.java",
      "extendedDetails": {}
    },
    "5760d03c87cf00c9086b1f07a7b57d756ac47aad": {
      "type": "Ybodychange",
      "commitMessage": "Revert accidental change in previous commit.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1204372 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/11/11 11:06 PM",
      "commitName": "5760d03c87cf00c9086b1f07a7b57d756ac47aad",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "20/11/11 11:01 PM",
      "commitNameOld": "9c2f4f634db124282f114a44b2e7dfc899693c1d",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,92 +1,81 @@\n   public static void main(String[] args) throws Throwable {\n     String usage \u003d \"RunJar jarFile [mainClass] args...\";\n \n     if (args.length \u003c 1) {\n       System.err.println(usage);\n       System.exit(-1);\n     }\n \n     int firstArg \u003d 0;\n     String fileName \u003d args[firstArg++];\n     File file \u003d new File(fileName);\n     String mainClassName \u003d null;\n \n     JarFile jarFile;\n     try {\n       jarFile \u003d new JarFile(fileName);\n     } catch(IOException io) {\n       throw new IOException(\"Error opening job jar: \" + fileName)\n         .initCause(io);\n     }\n \n     Manifest manifest \u003d jarFile.getManifest();\n     if (manifest !\u003d null) {\n       mainClassName \u003d manifest.getMainAttributes().getValue(\"Main-Class\");\n     }\n     jarFile.close();\n \n     if (mainClassName \u003d\u003d null) {\n       if (args.length \u003c 2) {\n         System.err.println(usage);\n         System.exit(-1);\n       }\n       mainClassName \u003d args[firstArg++];\n     }\n     mainClassName \u003d mainClassName.replaceAll(\"/\", \".\");\n \n     File tmpDir \u003d new File(new Configuration().get(\"hadoop.tmp.dir\"));\n     ensureDirectory(tmpDir);\n \n-    final File workDir;\n-    try { \n-      workDir \u003d File.createTempFile(\"hadoop-unjar\", \"\", tmpDir);\n-    } catch (IOException ioe) {\n-      // If user has insufficient perms to write to tmpDir, default  \n-      // \"Permission denied\" message doesn\u0027t specify a filename. \n-      System.err.println(\"Error creating temp dir in hadoop.tmp.dir \"\n-                         + tmpDir + \" due to \" + ioe.getMessage());\n-      System.exit(-1);\n-      return;\n-    }\n-\n+    final File workDir \u003d File.createTempFile(\"hadoop-unjar\", \"\", tmpDir);\n     if (!workDir.delete()) {\n       System.err.println(\"Delete failed for \" + workDir);\n       System.exit(-1);\n     }\n     ensureDirectory(workDir);\n \n     Runtime.getRuntime().addShutdownHook(new Thread() {\n         public void run() {\n           FileUtil.fullyDelete(workDir);\n         }\n       });\n \n     unJar(file, workDir);\n \n     ArrayList\u003cURL\u003e classPath \u003d new ArrayList\u003cURL\u003e();\n     classPath.add(new File(workDir+\"/\").toURI().toURL());\n     classPath.add(file.toURI().toURL());\n     classPath.add(new File(workDir, \"classes/\").toURI().toURL());\n     File[] libs \u003d new File(workDir, \"lib\").listFiles();\n     if (libs !\u003d null) {\n       for (int i \u003d 0; i \u003c libs.length; i++) {\n         classPath.add(libs[i].toURI().toURL());\n       }\n     }\n     \n     ClassLoader loader \u003d\n       new URLClassLoader(classPath.toArray(new URL[0]));\n \n     Thread.currentThread().setContextClassLoader(loader);\n     Class\u003c?\u003e mainClass \u003d Class.forName(mainClassName, true, loader);\n     Method main \u003d mainClass.getMethod(\"main\", new Class[] {\n       Array.newInstance(String.class, 0).getClass()\n     });\n     String[] newArgs \u003d Arrays.asList(args)\n       .subList(firstArg, args.length).toArray(new String[0]);\n     try {\n       main.invoke(null, new Object[] { newArgs });\n     } catch (InvocationTargetException e) {\n       throw e.getTargetException();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static void main(String[] args) throws Throwable {\n    String usage \u003d \"RunJar jarFile [mainClass] args...\";\n\n    if (args.length \u003c 1) {\n      System.err.println(usage);\n      System.exit(-1);\n    }\n\n    int firstArg \u003d 0;\n    String fileName \u003d args[firstArg++];\n    File file \u003d new File(fileName);\n    String mainClassName \u003d null;\n\n    JarFile jarFile;\n    try {\n      jarFile \u003d new JarFile(fileName);\n    } catch(IOException io) {\n      throw new IOException(\"Error opening job jar: \" + fileName)\n        .initCause(io);\n    }\n\n    Manifest manifest \u003d jarFile.getManifest();\n    if (manifest !\u003d null) {\n      mainClassName \u003d manifest.getMainAttributes().getValue(\"Main-Class\");\n    }\n    jarFile.close();\n\n    if (mainClassName \u003d\u003d null) {\n      if (args.length \u003c 2) {\n        System.err.println(usage);\n        System.exit(-1);\n      }\n      mainClassName \u003d args[firstArg++];\n    }\n    mainClassName \u003d mainClassName.replaceAll(\"/\", \".\");\n\n    File tmpDir \u003d new File(new Configuration().get(\"hadoop.tmp.dir\"));\n    ensureDirectory(tmpDir);\n\n    final File workDir \u003d File.createTempFile(\"hadoop-unjar\", \"\", tmpDir);\n    if (!workDir.delete()) {\n      System.err.println(\"Delete failed for \" + workDir);\n      System.exit(-1);\n    }\n    ensureDirectory(workDir);\n\n    Runtime.getRuntime().addShutdownHook(new Thread() {\n        public void run() {\n          FileUtil.fullyDelete(workDir);\n        }\n      });\n\n    unJar(file, workDir);\n\n    ArrayList\u003cURL\u003e classPath \u003d new ArrayList\u003cURL\u003e();\n    classPath.add(new File(workDir+\"/\").toURI().toURL());\n    classPath.add(file.toURI().toURL());\n    classPath.add(new File(workDir, \"classes/\").toURI().toURL());\n    File[] libs \u003d new File(workDir, \"lib\").listFiles();\n    if (libs !\u003d null) {\n      for (int i \u003d 0; i \u003c libs.length; i++) {\n        classPath.add(libs[i].toURI().toURL());\n      }\n    }\n    \n    ClassLoader loader \u003d\n      new URLClassLoader(classPath.toArray(new URL[0]));\n\n    Thread.currentThread().setContextClassLoader(loader);\n    Class\u003c?\u003e mainClass \u003d Class.forName(mainClassName, true, loader);\n    Method main \u003d mainClass.getMethod(\"main\", new Class[] {\n      Array.newInstance(String.class, 0).getClass()\n    });\n    String[] newArgs \u003d Arrays.asList(args)\n      .subList(firstArg, args.length).toArray(new String[0]);\n    try {\n      main.invoke(null, new Object[] { newArgs });\n    } catch (InvocationTargetException e) {\n      throw e.getTargetException();\n    }\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/RunJar.java",
      "extendedDetails": {}
    },
    "9c2f4f634db124282f114a44b2e7dfc899693c1d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2514. Link resolution bug for intermediate symlinks with relative targets. Contributed by Eli Collins\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1204370 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/11/11 11:01 PM",
      "commitName": "9c2f4f634db124282f114a44b2e7dfc899693c1d",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "01/09/11 8:20 PM",
      "commitNameOld": "07c5741c9a5ebec78a0db046e7fefcae2ca4b6af",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 80.15,
      "commitsBetweenForRepo": 570,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,81 +1,92 @@\n   public static void main(String[] args) throws Throwable {\n     String usage \u003d \"RunJar jarFile [mainClass] args...\";\n \n     if (args.length \u003c 1) {\n       System.err.println(usage);\n       System.exit(-1);\n     }\n \n     int firstArg \u003d 0;\n     String fileName \u003d args[firstArg++];\n     File file \u003d new File(fileName);\n     String mainClassName \u003d null;\n \n     JarFile jarFile;\n     try {\n       jarFile \u003d new JarFile(fileName);\n     } catch(IOException io) {\n       throw new IOException(\"Error opening job jar: \" + fileName)\n         .initCause(io);\n     }\n \n     Manifest manifest \u003d jarFile.getManifest();\n     if (manifest !\u003d null) {\n       mainClassName \u003d manifest.getMainAttributes().getValue(\"Main-Class\");\n     }\n     jarFile.close();\n \n     if (mainClassName \u003d\u003d null) {\n       if (args.length \u003c 2) {\n         System.err.println(usage);\n         System.exit(-1);\n       }\n       mainClassName \u003d args[firstArg++];\n     }\n     mainClassName \u003d mainClassName.replaceAll(\"/\", \".\");\n \n     File tmpDir \u003d new File(new Configuration().get(\"hadoop.tmp.dir\"));\n     ensureDirectory(tmpDir);\n \n-    final File workDir \u003d File.createTempFile(\"hadoop-unjar\", \"\", tmpDir);\n+    final File workDir;\n+    try { \n+      workDir \u003d File.createTempFile(\"hadoop-unjar\", \"\", tmpDir);\n+    } catch (IOException ioe) {\n+      // If user has insufficient perms to write to tmpDir, default  \n+      // \"Permission denied\" message doesn\u0027t specify a filename. \n+      System.err.println(\"Error creating temp dir in hadoop.tmp.dir \"\n+                         + tmpDir + \" due to \" + ioe.getMessage());\n+      System.exit(-1);\n+      return;\n+    }\n+\n     if (!workDir.delete()) {\n       System.err.println(\"Delete failed for \" + workDir);\n       System.exit(-1);\n     }\n     ensureDirectory(workDir);\n \n     Runtime.getRuntime().addShutdownHook(new Thread() {\n         public void run() {\n           FileUtil.fullyDelete(workDir);\n         }\n       });\n \n     unJar(file, workDir);\n \n     ArrayList\u003cURL\u003e classPath \u003d new ArrayList\u003cURL\u003e();\n     classPath.add(new File(workDir+\"/\").toURI().toURL());\n     classPath.add(file.toURI().toURL());\n     classPath.add(new File(workDir, \"classes/\").toURI().toURL());\n     File[] libs \u003d new File(workDir, \"lib\").listFiles();\n     if (libs !\u003d null) {\n       for (int i \u003d 0; i \u003c libs.length; i++) {\n         classPath.add(libs[i].toURI().toURL());\n       }\n     }\n     \n     ClassLoader loader \u003d\n       new URLClassLoader(classPath.toArray(new URL[0]));\n \n     Thread.currentThread().setContextClassLoader(loader);\n     Class\u003c?\u003e mainClass \u003d Class.forName(mainClassName, true, loader);\n     Method main \u003d mainClass.getMethod(\"main\", new Class[] {\n       Array.newInstance(String.class, 0).getClass()\n     });\n     String[] newArgs \u003d Arrays.asList(args)\n       .subList(firstArg, args.length).toArray(new String[0]);\n     try {\n       main.invoke(null, new Object[] { newArgs });\n     } catch (InvocationTargetException e) {\n       throw e.getTargetException();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static void main(String[] args) throws Throwable {\n    String usage \u003d \"RunJar jarFile [mainClass] args...\";\n\n    if (args.length \u003c 1) {\n      System.err.println(usage);\n      System.exit(-1);\n    }\n\n    int firstArg \u003d 0;\n    String fileName \u003d args[firstArg++];\n    File file \u003d new File(fileName);\n    String mainClassName \u003d null;\n\n    JarFile jarFile;\n    try {\n      jarFile \u003d new JarFile(fileName);\n    } catch(IOException io) {\n      throw new IOException(\"Error opening job jar: \" + fileName)\n        .initCause(io);\n    }\n\n    Manifest manifest \u003d jarFile.getManifest();\n    if (manifest !\u003d null) {\n      mainClassName \u003d manifest.getMainAttributes().getValue(\"Main-Class\");\n    }\n    jarFile.close();\n\n    if (mainClassName \u003d\u003d null) {\n      if (args.length \u003c 2) {\n        System.err.println(usage);\n        System.exit(-1);\n      }\n      mainClassName \u003d args[firstArg++];\n    }\n    mainClassName \u003d mainClassName.replaceAll(\"/\", \".\");\n\n    File tmpDir \u003d new File(new Configuration().get(\"hadoop.tmp.dir\"));\n    ensureDirectory(tmpDir);\n\n    final File workDir;\n    try { \n      workDir \u003d File.createTempFile(\"hadoop-unjar\", \"\", tmpDir);\n    } catch (IOException ioe) {\n      // If user has insufficient perms to write to tmpDir, default  \n      // \"Permission denied\" message doesn\u0027t specify a filename. \n      System.err.println(\"Error creating temp dir in hadoop.tmp.dir \"\n                         + tmpDir + \" due to \" + ioe.getMessage());\n      System.exit(-1);\n      return;\n    }\n\n    if (!workDir.delete()) {\n      System.err.println(\"Delete failed for \" + workDir);\n      System.exit(-1);\n    }\n    ensureDirectory(workDir);\n\n    Runtime.getRuntime().addShutdownHook(new Thread() {\n        public void run() {\n          FileUtil.fullyDelete(workDir);\n        }\n      });\n\n    unJar(file, workDir);\n\n    ArrayList\u003cURL\u003e classPath \u003d new ArrayList\u003cURL\u003e();\n    classPath.add(new File(workDir+\"/\").toURI().toURL());\n    classPath.add(file.toURI().toURL());\n    classPath.add(new File(workDir, \"classes/\").toURI().toURL());\n    File[] libs \u003d new File(workDir, \"lib\").listFiles();\n    if (libs !\u003d null) {\n      for (int i \u003d 0; i \u003c libs.length; i++) {\n        classPath.add(libs[i].toURI().toURL());\n      }\n    }\n    \n    ClassLoader loader \u003d\n      new URLClassLoader(classPath.toArray(new URL[0]));\n\n    Thread.currentThread().setContextClassLoader(loader);\n    Class\u003c?\u003e mainClass \u003d Class.forName(mainClassName, true, loader);\n    Method main \u003d mainClass.getMethod(\"main\", new Class[] {\n      Array.newInstance(String.class, 0).getClass()\n    });\n    String[] newArgs \u003d Arrays.asList(args)\n      .subList(firstArg, args.length).toArray(new String[0]);\n    try {\n      main.invoke(null, new Object[] { newArgs });\n    } catch (InvocationTargetException e) {\n      throw e.getTargetException();\n    }\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/RunJar.java",
      "extendedDetails": {}
    },
    "07c5741c9a5ebec78a0db046e7fefcae2ca4b6af": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-7552. FileUtil#fullyDelete doesn\u0027t throw IOE but lists it in the throws clause. Contributed by Eli Collins\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1164339 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "01/09/11 8:20 PM",
      "commitName": "07c5741c9a5ebec78a0db046e7fefcae2ca4b6af",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "24/08/11 5:14 PM",
      "commitNameOld": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 8.13,
      "commitsBetweenForRepo": 48,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,84 +1,81 @@\n   public static void main(String[] args) throws Throwable {\n     String usage \u003d \"RunJar jarFile [mainClass] args...\";\n \n     if (args.length \u003c 1) {\n       System.err.println(usage);\n       System.exit(-1);\n     }\n \n     int firstArg \u003d 0;\n     String fileName \u003d args[firstArg++];\n     File file \u003d new File(fileName);\n     String mainClassName \u003d null;\n \n     JarFile jarFile;\n     try {\n       jarFile \u003d new JarFile(fileName);\n     } catch(IOException io) {\n       throw new IOException(\"Error opening job jar: \" + fileName)\n         .initCause(io);\n     }\n \n     Manifest manifest \u003d jarFile.getManifest();\n     if (manifest !\u003d null) {\n       mainClassName \u003d manifest.getMainAttributes().getValue(\"Main-Class\");\n     }\n     jarFile.close();\n \n     if (mainClassName \u003d\u003d null) {\n       if (args.length \u003c 2) {\n         System.err.println(usage);\n         System.exit(-1);\n       }\n       mainClassName \u003d args[firstArg++];\n     }\n     mainClassName \u003d mainClassName.replaceAll(\"/\", \".\");\n \n     File tmpDir \u003d new File(new Configuration().get(\"hadoop.tmp.dir\"));\n     ensureDirectory(tmpDir);\n \n     final File workDir \u003d File.createTempFile(\"hadoop-unjar\", \"\", tmpDir);\n     if (!workDir.delete()) {\n       System.err.println(\"Delete failed for \" + workDir);\n       System.exit(-1);\n     }\n     ensureDirectory(workDir);\n \n     Runtime.getRuntime().addShutdownHook(new Thread() {\n         public void run() {\n-          try {\n-            FileUtil.fullyDelete(workDir);\n-          } catch (IOException e) {\n-          }\n+          FileUtil.fullyDelete(workDir);\n         }\n       });\n \n     unJar(file, workDir);\n \n     ArrayList\u003cURL\u003e classPath \u003d new ArrayList\u003cURL\u003e();\n     classPath.add(new File(workDir+\"/\").toURI().toURL());\n     classPath.add(file.toURI().toURL());\n     classPath.add(new File(workDir, \"classes/\").toURI().toURL());\n     File[] libs \u003d new File(workDir, \"lib\").listFiles();\n     if (libs !\u003d null) {\n       for (int i \u003d 0; i \u003c libs.length; i++) {\n         classPath.add(libs[i].toURI().toURL());\n       }\n     }\n     \n     ClassLoader loader \u003d\n       new URLClassLoader(classPath.toArray(new URL[0]));\n \n     Thread.currentThread().setContextClassLoader(loader);\n     Class\u003c?\u003e mainClass \u003d Class.forName(mainClassName, true, loader);\n     Method main \u003d mainClass.getMethod(\"main\", new Class[] {\n       Array.newInstance(String.class, 0).getClass()\n     });\n     String[] newArgs \u003d Arrays.asList(args)\n       .subList(firstArg, args.length).toArray(new String[0]);\n     try {\n       main.invoke(null, new Object[] { newArgs });\n     } catch (InvocationTargetException e) {\n       throw e.getTargetException();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static void main(String[] args) throws Throwable {\n    String usage \u003d \"RunJar jarFile [mainClass] args...\";\n\n    if (args.length \u003c 1) {\n      System.err.println(usage);\n      System.exit(-1);\n    }\n\n    int firstArg \u003d 0;\n    String fileName \u003d args[firstArg++];\n    File file \u003d new File(fileName);\n    String mainClassName \u003d null;\n\n    JarFile jarFile;\n    try {\n      jarFile \u003d new JarFile(fileName);\n    } catch(IOException io) {\n      throw new IOException(\"Error opening job jar: \" + fileName)\n        .initCause(io);\n    }\n\n    Manifest manifest \u003d jarFile.getManifest();\n    if (manifest !\u003d null) {\n      mainClassName \u003d manifest.getMainAttributes().getValue(\"Main-Class\");\n    }\n    jarFile.close();\n\n    if (mainClassName \u003d\u003d null) {\n      if (args.length \u003c 2) {\n        System.err.println(usage);\n        System.exit(-1);\n      }\n      mainClassName \u003d args[firstArg++];\n    }\n    mainClassName \u003d mainClassName.replaceAll(\"/\", \".\");\n\n    File tmpDir \u003d new File(new Configuration().get(\"hadoop.tmp.dir\"));\n    ensureDirectory(tmpDir);\n\n    final File workDir \u003d File.createTempFile(\"hadoop-unjar\", \"\", tmpDir);\n    if (!workDir.delete()) {\n      System.err.println(\"Delete failed for \" + workDir);\n      System.exit(-1);\n    }\n    ensureDirectory(workDir);\n\n    Runtime.getRuntime().addShutdownHook(new Thread() {\n        public void run() {\n          FileUtil.fullyDelete(workDir);\n        }\n      });\n\n    unJar(file, workDir);\n\n    ArrayList\u003cURL\u003e classPath \u003d new ArrayList\u003cURL\u003e();\n    classPath.add(new File(workDir+\"/\").toURI().toURL());\n    classPath.add(file.toURI().toURL());\n    classPath.add(new File(workDir, \"classes/\").toURI().toURL());\n    File[] libs \u003d new File(workDir, \"lib\").listFiles();\n    if (libs !\u003d null) {\n      for (int i \u003d 0; i \u003c libs.length; i++) {\n        classPath.add(libs[i].toURI().toURL());\n      }\n    }\n    \n    ClassLoader loader \u003d\n      new URLClassLoader(classPath.toArray(new URL[0]));\n\n    Thread.currentThread().setContextClassLoader(loader);\n    Class\u003c?\u003e mainClass \u003d Class.forName(mainClassName, true, loader);\n    Method main \u003d mainClass.getMethod(\"main\", new Class[] {\n      Array.newInstance(String.class, 0).getClass()\n    });\n    String[] newArgs \u003d Arrays.asList(args)\n      .subList(firstArg, args.length).toArray(new String[0]);\n    try {\n      main.invoke(null, new Object[] { newArgs });\n    } catch (InvocationTargetException e) {\n      throw e.getTargetException();\n    }\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/RunJar.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public static void main(String[] args) throws Throwable {\n    String usage \u003d \"RunJar jarFile [mainClass] args...\";\n\n    if (args.length \u003c 1) {\n      System.err.println(usage);\n      System.exit(-1);\n    }\n\n    int firstArg \u003d 0;\n    String fileName \u003d args[firstArg++];\n    File file \u003d new File(fileName);\n    String mainClassName \u003d null;\n\n    JarFile jarFile;\n    try {\n      jarFile \u003d new JarFile(fileName);\n    } catch(IOException io) {\n      throw new IOException(\"Error opening job jar: \" + fileName)\n        .initCause(io);\n    }\n\n    Manifest manifest \u003d jarFile.getManifest();\n    if (manifest !\u003d null) {\n      mainClassName \u003d manifest.getMainAttributes().getValue(\"Main-Class\");\n    }\n    jarFile.close();\n\n    if (mainClassName \u003d\u003d null) {\n      if (args.length \u003c 2) {\n        System.err.println(usage);\n        System.exit(-1);\n      }\n      mainClassName \u003d args[firstArg++];\n    }\n    mainClassName \u003d mainClassName.replaceAll(\"/\", \".\");\n\n    File tmpDir \u003d new File(new Configuration().get(\"hadoop.tmp.dir\"));\n    ensureDirectory(tmpDir);\n\n    final File workDir \u003d File.createTempFile(\"hadoop-unjar\", \"\", tmpDir);\n    if (!workDir.delete()) {\n      System.err.println(\"Delete failed for \" + workDir);\n      System.exit(-1);\n    }\n    ensureDirectory(workDir);\n\n    Runtime.getRuntime().addShutdownHook(new Thread() {\n        public void run() {\n          try {\n            FileUtil.fullyDelete(workDir);\n          } catch (IOException e) {\n          }\n        }\n      });\n\n    unJar(file, workDir);\n\n    ArrayList\u003cURL\u003e classPath \u003d new ArrayList\u003cURL\u003e();\n    classPath.add(new File(workDir+\"/\").toURI().toURL());\n    classPath.add(file.toURI().toURL());\n    classPath.add(new File(workDir, \"classes/\").toURI().toURL());\n    File[] libs \u003d new File(workDir, \"lib\").listFiles();\n    if (libs !\u003d null) {\n      for (int i \u003d 0; i \u003c libs.length; i++) {\n        classPath.add(libs[i].toURI().toURL());\n      }\n    }\n    \n    ClassLoader loader \u003d\n      new URLClassLoader(classPath.toArray(new URL[0]));\n\n    Thread.currentThread().setContextClassLoader(loader);\n    Class\u003c?\u003e mainClass \u003d Class.forName(mainClassName, true, loader);\n    Method main \u003d mainClass.getMethod(\"main\", new Class[] {\n      Array.newInstance(String.class, 0).getClass()\n    });\n    String[] newArgs \u003d Arrays.asList(args)\n      .subList(firstArg, args.length).toArray(new String[0]);\n    try {\n      main.invoke(null, new Object[] { newArgs });\n    } catch (InvocationTargetException e) {\n      throw e.getTargetException();\n    }\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/RunJar.java",
      "extendedDetails": {
        "oldPath": "hadoop-common/src/main/java/org/apache/hadoop/util/RunJar.java",
        "newPath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/RunJar.java"
      }
    },
    "0f6dfeeacbab65a31a33927a4eb84871d371fe52": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-6671. Use maven for hadoop common builds. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1153184 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/08/11 9:37 AM",
      "commitName": "0f6dfeeacbab65a31a33927a4eb84871d371fe52",
      "commitAuthor": "Thomas White",
      "commitDateOld": "01/08/11 3:53 PM",
      "commitNameOld": "9bac807cedbcff34e1a144fb475eff267e5ed86d",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.74,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public static void main(String[] args) throws Throwable {\n    String usage \u003d \"RunJar jarFile [mainClass] args...\";\n\n    if (args.length \u003c 1) {\n      System.err.println(usage);\n      System.exit(-1);\n    }\n\n    int firstArg \u003d 0;\n    String fileName \u003d args[firstArg++];\n    File file \u003d new File(fileName);\n    String mainClassName \u003d null;\n\n    JarFile jarFile;\n    try {\n      jarFile \u003d new JarFile(fileName);\n    } catch(IOException io) {\n      throw new IOException(\"Error opening job jar: \" + fileName)\n        .initCause(io);\n    }\n\n    Manifest manifest \u003d jarFile.getManifest();\n    if (manifest !\u003d null) {\n      mainClassName \u003d manifest.getMainAttributes().getValue(\"Main-Class\");\n    }\n    jarFile.close();\n\n    if (mainClassName \u003d\u003d null) {\n      if (args.length \u003c 2) {\n        System.err.println(usage);\n        System.exit(-1);\n      }\n      mainClassName \u003d args[firstArg++];\n    }\n    mainClassName \u003d mainClassName.replaceAll(\"/\", \".\");\n\n    File tmpDir \u003d new File(new Configuration().get(\"hadoop.tmp.dir\"));\n    ensureDirectory(tmpDir);\n\n    final File workDir \u003d File.createTempFile(\"hadoop-unjar\", \"\", tmpDir);\n    if (!workDir.delete()) {\n      System.err.println(\"Delete failed for \" + workDir);\n      System.exit(-1);\n    }\n    ensureDirectory(workDir);\n\n    Runtime.getRuntime().addShutdownHook(new Thread() {\n        public void run() {\n          try {\n            FileUtil.fullyDelete(workDir);\n          } catch (IOException e) {\n          }\n        }\n      });\n\n    unJar(file, workDir);\n\n    ArrayList\u003cURL\u003e classPath \u003d new ArrayList\u003cURL\u003e();\n    classPath.add(new File(workDir+\"/\").toURI().toURL());\n    classPath.add(file.toURI().toURL());\n    classPath.add(new File(workDir, \"classes/\").toURI().toURL());\n    File[] libs \u003d new File(workDir, \"lib\").listFiles();\n    if (libs !\u003d null) {\n      for (int i \u003d 0; i \u003c libs.length; i++) {\n        classPath.add(libs[i].toURI().toURL());\n      }\n    }\n    \n    ClassLoader loader \u003d\n      new URLClassLoader(classPath.toArray(new URL[0]));\n\n    Thread.currentThread().setContextClassLoader(loader);\n    Class\u003c?\u003e mainClass \u003d Class.forName(mainClassName, true, loader);\n    Method main \u003d mainClass.getMethod(\"main\", new Class[] {\n      Array.newInstance(String.class, 0).getClass()\n    });\n    String[] newArgs \u003d Arrays.asList(args)\n      .subList(firstArg, args.length).toArray(new String[0]);\n    try {\n      main.invoke(null, new Object[] { newArgs });\n    } catch (InvocationTargetException e) {\n      throw e.getTargetException();\n    }\n  }",
      "path": "hadoop-common/src/main/java/org/apache/hadoop/util/RunJar.java",
      "extendedDetails": {
        "oldPath": "common/src/java/org/apache/hadoop/util/RunJar.java",
        "newPath": "hadoop-common/src/main/java/org/apache/hadoop/util/RunJar.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "11/06/11 9:13 PM",
      "commitNameOld": "a285fb5effe9ba3be4ec5f942afaf5ddd1186151",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 0.74,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public static void main(String[] args) throws Throwable {\n    String usage \u003d \"RunJar jarFile [mainClass] args...\";\n\n    if (args.length \u003c 1) {\n      System.err.println(usage);\n      System.exit(-1);\n    }\n\n    int firstArg \u003d 0;\n    String fileName \u003d args[firstArg++];\n    File file \u003d new File(fileName);\n    String mainClassName \u003d null;\n\n    JarFile jarFile;\n    try {\n      jarFile \u003d new JarFile(fileName);\n    } catch(IOException io) {\n      throw new IOException(\"Error opening job jar: \" + fileName)\n        .initCause(io);\n    }\n\n    Manifest manifest \u003d jarFile.getManifest();\n    if (manifest !\u003d null) {\n      mainClassName \u003d manifest.getMainAttributes().getValue(\"Main-Class\");\n    }\n    jarFile.close();\n\n    if (mainClassName \u003d\u003d null) {\n      if (args.length \u003c 2) {\n        System.err.println(usage);\n        System.exit(-1);\n      }\n      mainClassName \u003d args[firstArg++];\n    }\n    mainClassName \u003d mainClassName.replaceAll(\"/\", \".\");\n\n    File tmpDir \u003d new File(new Configuration().get(\"hadoop.tmp.dir\"));\n    ensureDirectory(tmpDir);\n\n    final File workDir \u003d File.createTempFile(\"hadoop-unjar\", \"\", tmpDir);\n    if (!workDir.delete()) {\n      System.err.println(\"Delete failed for \" + workDir);\n      System.exit(-1);\n    }\n    ensureDirectory(workDir);\n\n    Runtime.getRuntime().addShutdownHook(new Thread() {\n        public void run() {\n          try {\n            FileUtil.fullyDelete(workDir);\n          } catch (IOException e) {\n          }\n        }\n      });\n\n    unJar(file, workDir);\n\n    ArrayList\u003cURL\u003e classPath \u003d new ArrayList\u003cURL\u003e();\n    classPath.add(new File(workDir+\"/\").toURI().toURL());\n    classPath.add(file.toURI().toURL());\n    classPath.add(new File(workDir, \"classes/\").toURI().toURL());\n    File[] libs \u003d new File(workDir, \"lib\").listFiles();\n    if (libs !\u003d null) {\n      for (int i \u003d 0; i \u003c libs.length; i++) {\n        classPath.add(libs[i].toURI().toURL());\n      }\n    }\n    \n    ClassLoader loader \u003d\n      new URLClassLoader(classPath.toArray(new URL[0]));\n\n    Thread.currentThread().setContextClassLoader(loader);\n    Class\u003c?\u003e mainClass \u003d Class.forName(mainClassName, true, loader);\n    Method main \u003d mainClass.getMethod(\"main\", new Class[] {\n      Array.newInstance(String.class, 0).getClass()\n    });\n    String[] newArgs \u003d Arrays.asList(args)\n      .subList(firstArg, args.length).toArray(new String[0]);\n    try {\n      main.invoke(null, new Object[] { newArgs });\n    } catch (InvocationTargetException e) {\n      throw e.getTargetException();\n    }\n  }",
      "path": "common/src/java/org/apache/hadoop/util/RunJar.java",
      "extendedDetails": {
        "oldPath": "src/java/org/apache/hadoop/util/RunJar.java",
        "newPath": "common/src/java/org/apache/hadoop/util/RunJar.java"
      }
    },
    "a473f3773342695cdb47e3ae4fe432b81e7787fd": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-6346. Add support for specifying unpack pattern regex to RunJar.unJar. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@889018 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/12/09 3:25 PM",
      "commitName": "a473f3773342695cdb47e3ae4fe432b81e7787fd",
      "commitAuthor": "Thomas White",
      "commitDateOld": "15/06/09 1:28 PM",
      "commitNameOld": "bcd64325a11cb0dd5096ffc093d0ffa68c4fcc58",
      "commitAuthorOld": "Owen O\u0027Malley",
      "daysBetweenCommits": 177.12,
      "commitsBetweenForRepo": 159,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,92 +1,84 @@\n   public static void main(String[] args) throws Throwable {\n     String usage \u003d \"RunJar jarFile [mainClass] args...\";\n \n     if (args.length \u003c 1) {\n       System.err.println(usage);\n       System.exit(-1);\n     }\n \n     int firstArg \u003d 0;\n     String fileName \u003d args[firstArg++];\n     File file \u003d new File(fileName);\n     String mainClassName \u003d null;\n \n     JarFile jarFile;\n     try {\n       jarFile \u003d new JarFile(fileName);\n     } catch(IOException io) {\n       throw new IOException(\"Error opening job jar: \" + fileName)\n         .initCause(io);\n     }\n \n     Manifest manifest \u003d jarFile.getManifest();\n     if (manifest !\u003d null) {\n       mainClassName \u003d manifest.getMainAttributes().getValue(\"Main-Class\");\n     }\n     jarFile.close();\n \n     if (mainClassName \u003d\u003d null) {\n       if (args.length \u003c 2) {\n         System.err.println(usage);\n         System.exit(-1);\n       }\n       mainClassName \u003d args[firstArg++];\n     }\n     mainClassName \u003d mainClassName.replaceAll(\"/\", \".\");\n \n     File tmpDir \u003d new File(new Configuration().get(\"hadoop.tmp.dir\"));\n-    boolean b \u003d tmpDir.mkdirs();\n-    if (!b \u0026\u0026 !tmpDir.isDirectory()) { \n-      System.err.println(\"Mkdirs failed to create \" + tmpDir);\n-      System.exit(-1);\n-    }\n+    ensureDirectory(tmpDir);\n+\n     final File workDir \u003d File.createTempFile(\"hadoop-unjar\", \"\", tmpDir);\n-    b \u003d workDir.delete();\n-    if (!b) {\n+    if (!workDir.delete()) {\n       System.err.println(\"Delete failed for \" + workDir);\n       System.exit(-1);\n     }\n-    b \u003d workDir.mkdirs();\n-    if (!b \u0026\u0026 !workDir.isDirectory()) {\n-      System.err.println(\"Mkdirs failed to create \" + workDir);\n-      System.exit(-1);\n-    }\n+    ensureDirectory(workDir);\n \n     Runtime.getRuntime().addShutdownHook(new Thread() {\n         public void run() {\n           try {\n             FileUtil.fullyDelete(workDir);\n           } catch (IOException e) {\n           }\n         }\n       });\n \n     unJar(file, workDir);\n-    \n+\n     ArrayList\u003cURL\u003e classPath \u003d new ArrayList\u003cURL\u003e();\n-    classPath.add(new File(workDir+\"/\").toURL());\n-    classPath.add(file.toURL());\n-    classPath.add(new File(workDir, \"classes/\").toURL());\n+    classPath.add(new File(workDir+\"/\").toURI().toURL());\n+    classPath.add(file.toURI().toURL());\n+    classPath.add(new File(workDir, \"classes/\").toURI().toURL());\n     File[] libs \u003d new File(workDir, \"lib\").listFiles();\n     if (libs !\u003d null) {\n       for (int i \u003d 0; i \u003c libs.length; i++) {\n-        classPath.add(libs[i].toURL());\n+        classPath.add(libs[i].toURI().toURL());\n       }\n     }\n     \n     ClassLoader loader \u003d\n       new URLClassLoader(classPath.toArray(new URL[0]));\n \n     Thread.currentThread().setContextClassLoader(loader);\n     Class\u003c?\u003e mainClass \u003d Class.forName(mainClassName, true, loader);\n     Method main \u003d mainClass.getMethod(\"main\", new Class[] {\n       Array.newInstance(String.class, 0).getClass()\n     });\n     String[] newArgs \u003d Arrays.asList(args)\n       .subList(firstArg, args.length).toArray(new String[0]);\n     try {\n       main.invoke(null, new Object[] { newArgs });\n     } catch (InvocationTargetException e) {\n       throw e.getTargetException();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static void main(String[] args) throws Throwable {\n    String usage \u003d \"RunJar jarFile [mainClass] args...\";\n\n    if (args.length \u003c 1) {\n      System.err.println(usage);\n      System.exit(-1);\n    }\n\n    int firstArg \u003d 0;\n    String fileName \u003d args[firstArg++];\n    File file \u003d new File(fileName);\n    String mainClassName \u003d null;\n\n    JarFile jarFile;\n    try {\n      jarFile \u003d new JarFile(fileName);\n    } catch(IOException io) {\n      throw new IOException(\"Error opening job jar: \" + fileName)\n        .initCause(io);\n    }\n\n    Manifest manifest \u003d jarFile.getManifest();\n    if (manifest !\u003d null) {\n      mainClassName \u003d manifest.getMainAttributes().getValue(\"Main-Class\");\n    }\n    jarFile.close();\n\n    if (mainClassName \u003d\u003d null) {\n      if (args.length \u003c 2) {\n        System.err.println(usage);\n        System.exit(-1);\n      }\n      mainClassName \u003d args[firstArg++];\n    }\n    mainClassName \u003d mainClassName.replaceAll(\"/\", \".\");\n\n    File tmpDir \u003d new File(new Configuration().get(\"hadoop.tmp.dir\"));\n    ensureDirectory(tmpDir);\n\n    final File workDir \u003d File.createTempFile(\"hadoop-unjar\", \"\", tmpDir);\n    if (!workDir.delete()) {\n      System.err.println(\"Delete failed for \" + workDir);\n      System.exit(-1);\n    }\n    ensureDirectory(workDir);\n\n    Runtime.getRuntime().addShutdownHook(new Thread() {\n        public void run() {\n          try {\n            FileUtil.fullyDelete(workDir);\n          } catch (IOException e) {\n          }\n        }\n      });\n\n    unJar(file, workDir);\n\n    ArrayList\u003cURL\u003e classPath \u003d new ArrayList\u003cURL\u003e();\n    classPath.add(new File(workDir+\"/\").toURI().toURL());\n    classPath.add(file.toURI().toURL());\n    classPath.add(new File(workDir, \"classes/\").toURI().toURL());\n    File[] libs \u003d new File(workDir, \"lib\").listFiles();\n    if (libs !\u003d null) {\n      for (int i \u003d 0; i \u003c libs.length; i++) {\n        classPath.add(libs[i].toURI().toURL());\n      }\n    }\n    \n    ClassLoader loader \u003d\n      new URLClassLoader(classPath.toArray(new URL[0]));\n\n    Thread.currentThread().setContextClassLoader(loader);\n    Class\u003c?\u003e mainClass \u003d Class.forName(mainClassName, true, loader);\n    Method main \u003d mainClass.getMethod(\"main\", new Class[] {\n      Array.newInstance(String.class, 0).getClass()\n    });\n    String[] newArgs \u003d Arrays.asList(args)\n      .subList(firstArg, args.length).toArray(new String[0]);\n    try {\n      main.invoke(null, new Object[] { newArgs });\n    } catch (InvocationTargetException e) {\n      throw e.getTargetException();\n    }\n  }",
      "path": "src/java/org/apache/hadoop/util/RunJar.java",
      "extendedDetails": {}
    },
    "bcd64325a11cb0dd5096ffc093d0ffa68c4fcc58": {
      "type": "Ybodychange",
      "commitMessage": "Merged src/core, src/test/core, src/contrib/eclipse-plugin, and\nsrc/contrib/ec2 from trunk 776174:784663\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/core/branches/HADOOP-4687/core@784965 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "15/06/09 1:28 PM",
      "commitName": "bcd64325a11cb0dd5096ffc093d0ffa68c4fcc58",
      "commitAuthor": "Owen O\u0027Malley",
      "commitDateOld": "18/05/09 9:20 PM",
      "commitNameOld": "5128a9a453d64bfe1ed978cf9ffed27985eeef36",
      "commitAuthorOld": "Owen O\u0027Malley",
      "daysBetweenCommits": 27.67,
      "commitsBetweenForRepo": 16,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,92 +1,92 @@\n   public static void main(String[] args) throws Throwable {\n     String usage \u003d \"RunJar jarFile [mainClass] args...\";\n \n     if (args.length \u003c 1) {\n       System.err.println(usage);\n       System.exit(-1);\n     }\n \n     int firstArg \u003d 0;\n     String fileName \u003d args[firstArg++];\n     File file \u003d new File(fileName);\n     String mainClassName \u003d null;\n \n     JarFile jarFile;\n     try {\n       jarFile \u003d new JarFile(fileName);\n     } catch(IOException io) {\n       throw new IOException(\"Error opening job jar: \" + fileName)\n         .initCause(io);\n     }\n \n     Manifest manifest \u003d jarFile.getManifest();\n     if (manifest !\u003d null) {\n       mainClassName \u003d manifest.getMainAttributes().getValue(\"Main-Class\");\n     }\n     jarFile.close();\n \n     if (mainClassName \u003d\u003d null) {\n       if (args.length \u003c 2) {\n         System.err.println(usage);\n         System.exit(-1);\n       }\n       mainClassName \u003d args[firstArg++];\n     }\n     mainClassName \u003d mainClassName.replaceAll(\"/\", \".\");\n \n     File tmpDir \u003d new File(new Configuration().get(\"hadoop.tmp.dir\"));\n     boolean b \u003d tmpDir.mkdirs();\n-    if (!b || !tmpDir.isDirectory()) { \n+    if (!b \u0026\u0026 !tmpDir.isDirectory()) { \n       System.err.println(\"Mkdirs failed to create \" + tmpDir);\n       System.exit(-1);\n     }\n     final File workDir \u003d File.createTempFile(\"hadoop-unjar\", \"\", tmpDir);\n     b \u003d workDir.delete();\n     if (!b) {\n       System.err.println(\"Delete failed for \" + workDir);\n       System.exit(-1);\n     }\n     b \u003d workDir.mkdirs();\n-    if (!b || !workDir.isDirectory()) {\n+    if (!b \u0026\u0026 !workDir.isDirectory()) {\n       System.err.println(\"Mkdirs failed to create \" + workDir);\n       System.exit(-1);\n     }\n \n     Runtime.getRuntime().addShutdownHook(new Thread() {\n         public void run() {\n           try {\n             FileUtil.fullyDelete(workDir);\n           } catch (IOException e) {\n           }\n         }\n       });\n \n     unJar(file, workDir);\n     \n     ArrayList\u003cURL\u003e classPath \u003d new ArrayList\u003cURL\u003e();\n     classPath.add(new File(workDir+\"/\").toURL());\n     classPath.add(file.toURL());\n     classPath.add(new File(workDir, \"classes/\").toURL());\n     File[] libs \u003d new File(workDir, \"lib\").listFiles();\n     if (libs !\u003d null) {\n       for (int i \u003d 0; i \u003c libs.length; i++) {\n         classPath.add(libs[i].toURL());\n       }\n     }\n     \n     ClassLoader loader \u003d\n       new URLClassLoader(classPath.toArray(new URL[0]));\n \n     Thread.currentThread().setContextClassLoader(loader);\n     Class\u003c?\u003e mainClass \u003d Class.forName(mainClassName, true, loader);\n     Method main \u003d mainClass.getMethod(\"main\", new Class[] {\n       Array.newInstance(String.class, 0).getClass()\n     });\n     String[] newArgs \u003d Arrays.asList(args)\n       .subList(firstArg, args.length).toArray(new String[0]);\n     try {\n       main.invoke(null, new Object[] { newArgs });\n     } catch (InvocationTargetException e) {\n       throw e.getTargetException();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static void main(String[] args) throws Throwable {\n    String usage \u003d \"RunJar jarFile [mainClass] args...\";\n\n    if (args.length \u003c 1) {\n      System.err.println(usage);\n      System.exit(-1);\n    }\n\n    int firstArg \u003d 0;\n    String fileName \u003d args[firstArg++];\n    File file \u003d new File(fileName);\n    String mainClassName \u003d null;\n\n    JarFile jarFile;\n    try {\n      jarFile \u003d new JarFile(fileName);\n    } catch(IOException io) {\n      throw new IOException(\"Error opening job jar: \" + fileName)\n        .initCause(io);\n    }\n\n    Manifest manifest \u003d jarFile.getManifest();\n    if (manifest !\u003d null) {\n      mainClassName \u003d manifest.getMainAttributes().getValue(\"Main-Class\");\n    }\n    jarFile.close();\n\n    if (mainClassName \u003d\u003d null) {\n      if (args.length \u003c 2) {\n        System.err.println(usage);\n        System.exit(-1);\n      }\n      mainClassName \u003d args[firstArg++];\n    }\n    mainClassName \u003d mainClassName.replaceAll(\"/\", \".\");\n\n    File tmpDir \u003d new File(new Configuration().get(\"hadoop.tmp.dir\"));\n    boolean b \u003d tmpDir.mkdirs();\n    if (!b \u0026\u0026 !tmpDir.isDirectory()) { \n      System.err.println(\"Mkdirs failed to create \" + tmpDir);\n      System.exit(-1);\n    }\n    final File workDir \u003d File.createTempFile(\"hadoop-unjar\", \"\", tmpDir);\n    b \u003d workDir.delete();\n    if (!b) {\n      System.err.println(\"Delete failed for \" + workDir);\n      System.exit(-1);\n    }\n    b \u003d workDir.mkdirs();\n    if (!b \u0026\u0026 !workDir.isDirectory()) {\n      System.err.println(\"Mkdirs failed to create \" + workDir);\n      System.exit(-1);\n    }\n\n    Runtime.getRuntime().addShutdownHook(new Thread() {\n        public void run() {\n          try {\n            FileUtil.fullyDelete(workDir);\n          } catch (IOException e) {\n          }\n        }\n      });\n\n    unJar(file, workDir);\n    \n    ArrayList\u003cURL\u003e classPath \u003d new ArrayList\u003cURL\u003e();\n    classPath.add(new File(workDir+\"/\").toURL());\n    classPath.add(file.toURL());\n    classPath.add(new File(workDir, \"classes/\").toURL());\n    File[] libs \u003d new File(workDir, \"lib\").listFiles();\n    if (libs !\u003d null) {\n      for (int i \u003d 0; i \u003c libs.length; i++) {\n        classPath.add(libs[i].toURL());\n      }\n    }\n    \n    ClassLoader loader \u003d\n      new URLClassLoader(classPath.toArray(new URL[0]));\n\n    Thread.currentThread().setContextClassLoader(loader);\n    Class\u003c?\u003e mainClass \u003d Class.forName(mainClassName, true, loader);\n    Method main \u003d mainClass.getMethod(\"main\", new Class[] {\n      Array.newInstance(String.class, 0).getClass()\n    });\n    String[] newArgs \u003d Arrays.asList(args)\n      .subList(firstArg, args.length).toArray(new String[0]);\n    try {\n      main.invoke(null, new Object[] { newArgs });\n    } catch (InvocationTargetException e) {\n      throw e.getTargetException();\n    }\n  }",
      "path": "src/java/org/apache/hadoop/util/RunJar.java",
      "extendedDetails": {}
    },
    "5128a9a453d64bfe1ed978cf9ffed27985eeef36": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-4687 Moving src directories on branch\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/core/branches/HADOOP-4687/core@776174 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/05/09 9:20 PM",
      "commitName": "5128a9a453d64bfe1ed978cf9ffed27985eeef36",
      "commitAuthor": "Owen O\u0027Malley",
      "diff": "@@ -0,0 +1,92 @@\n+  public static void main(String[] args) throws Throwable {\n+    String usage \u003d \"RunJar jarFile [mainClass] args...\";\n+\n+    if (args.length \u003c 1) {\n+      System.err.println(usage);\n+      System.exit(-1);\n+    }\n+\n+    int firstArg \u003d 0;\n+    String fileName \u003d args[firstArg++];\n+    File file \u003d new File(fileName);\n+    String mainClassName \u003d null;\n+\n+    JarFile jarFile;\n+    try {\n+      jarFile \u003d new JarFile(fileName);\n+    } catch(IOException io) {\n+      throw new IOException(\"Error opening job jar: \" + fileName)\n+        .initCause(io);\n+    }\n+\n+    Manifest manifest \u003d jarFile.getManifest();\n+    if (manifest !\u003d null) {\n+      mainClassName \u003d manifest.getMainAttributes().getValue(\"Main-Class\");\n+    }\n+    jarFile.close();\n+\n+    if (mainClassName \u003d\u003d null) {\n+      if (args.length \u003c 2) {\n+        System.err.println(usage);\n+        System.exit(-1);\n+      }\n+      mainClassName \u003d args[firstArg++];\n+    }\n+    mainClassName \u003d mainClassName.replaceAll(\"/\", \".\");\n+\n+    File tmpDir \u003d new File(new Configuration().get(\"hadoop.tmp.dir\"));\n+    boolean b \u003d tmpDir.mkdirs();\n+    if (!b || !tmpDir.isDirectory()) { \n+      System.err.println(\"Mkdirs failed to create \" + tmpDir);\n+      System.exit(-1);\n+    }\n+    final File workDir \u003d File.createTempFile(\"hadoop-unjar\", \"\", tmpDir);\n+    b \u003d workDir.delete();\n+    if (!b) {\n+      System.err.println(\"Delete failed for \" + workDir);\n+      System.exit(-1);\n+    }\n+    b \u003d workDir.mkdirs();\n+    if (!b || !workDir.isDirectory()) {\n+      System.err.println(\"Mkdirs failed to create \" + workDir);\n+      System.exit(-1);\n+    }\n+\n+    Runtime.getRuntime().addShutdownHook(new Thread() {\n+        public void run() {\n+          try {\n+            FileUtil.fullyDelete(workDir);\n+          } catch (IOException e) {\n+          }\n+        }\n+      });\n+\n+    unJar(file, workDir);\n+    \n+    ArrayList\u003cURL\u003e classPath \u003d new ArrayList\u003cURL\u003e();\n+    classPath.add(new File(workDir+\"/\").toURL());\n+    classPath.add(file.toURL());\n+    classPath.add(new File(workDir, \"classes/\").toURL());\n+    File[] libs \u003d new File(workDir, \"lib\").listFiles();\n+    if (libs !\u003d null) {\n+      for (int i \u003d 0; i \u003c libs.length; i++) {\n+        classPath.add(libs[i].toURL());\n+      }\n+    }\n+    \n+    ClassLoader loader \u003d\n+      new URLClassLoader(classPath.toArray(new URL[0]));\n+\n+    Thread.currentThread().setContextClassLoader(loader);\n+    Class\u003c?\u003e mainClass \u003d Class.forName(mainClassName, true, loader);\n+    Method main \u003d mainClass.getMethod(\"main\", new Class[] {\n+      Array.newInstance(String.class, 0).getClass()\n+    });\n+    String[] newArgs \u003d Arrays.asList(args)\n+      .subList(firstArg, args.length).toArray(new String[0]);\n+    try {\n+      main.invoke(null, new Object[] { newArgs });\n+    } catch (InvocationTargetException e) {\n+      throw e.getTargetException();\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public static void main(String[] args) throws Throwable {\n    String usage \u003d \"RunJar jarFile [mainClass] args...\";\n\n    if (args.length \u003c 1) {\n      System.err.println(usage);\n      System.exit(-1);\n    }\n\n    int firstArg \u003d 0;\n    String fileName \u003d args[firstArg++];\n    File file \u003d new File(fileName);\n    String mainClassName \u003d null;\n\n    JarFile jarFile;\n    try {\n      jarFile \u003d new JarFile(fileName);\n    } catch(IOException io) {\n      throw new IOException(\"Error opening job jar: \" + fileName)\n        .initCause(io);\n    }\n\n    Manifest manifest \u003d jarFile.getManifest();\n    if (manifest !\u003d null) {\n      mainClassName \u003d manifest.getMainAttributes().getValue(\"Main-Class\");\n    }\n    jarFile.close();\n\n    if (mainClassName \u003d\u003d null) {\n      if (args.length \u003c 2) {\n        System.err.println(usage);\n        System.exit(-1);\n      }\n      mainClassName \u003d args[firstArg++];\n    }\n    mainClassName \u003d mainClassName.replaceAll(\"/\", \".\");\n\n    File tmpDir \u003d new File(new Configuration().get(\"hadoop.tmp.dir\"));\n    boolean b \u003d tmpDir.mkdirs();\n    if (!b || !tmpDir.isDirectory()) { \n      System.err.println(\"Mkdirs failed to create \" + tmpDir);\n      System.exit(-1);\n    }\n    final File workDir \u003d File.createTempFile(\"hadoop-unjar\", \"\", tmpDir);\n    b \u003d workDir.delete();\n    if (!b) {\n      System.err.println(\"Delete failed for \" + workDir);\n      System.exit(-1);\n    }\n    b \u003d workDir.mkdirs();\n    if (!b || !workDir.isDirectory()) {\n      System.err.println(\"Mkdirs failed to create \" + workDir);\n      System.exit(-1);\n    }\n\n    Runtime.getRuntime().addShutdownHook(new Thread() {\n        public void run() {\n          try {\n            FileUtil.fullyDelete(workDir);\n          } catch (IOException e) {\n          }\n        }\n      });\n\n    unJar(file, workDir);\n    \n    ArrayList\u003cURL\u003e classPath \u003d new ArrayList\u003cURL\u003e();\n    classPath.add(new File(workDir+\"/\").toURL());\n    classPath.add(file.toURL());\n    classPath.add(new File(workDir, \"classes/\").toURL());\n    File[] libs \u003d new File(workDir, \"lib\").listFiles();\n    if (libs !\u003d null) {\n      for (int i \u003d 0; i \u003c libs.length; i++) {\n        classPath.add(libs[i].toURL());\n      }\n    }\n    \n    ClassLoader loader \u003d\n      new URLClassLoader(classPath.toArray(new URL[0]));\n\n    Thread.currentThread().setContextClassLoader(loader);\n    Class\u003c?\u003e mainClass \u003d Class.forName(mainClassName, true, loader);\n    Method main \u003d mainClass.getMethod(\"main\", new Class[] {\n      Array.newInstance(String.class, 0).getClass()\n    });\n    String[] newArgs \u003d Arrays.asList(args)\n      .subList(firstArg, args.length).toArray(new String[0]);\n    try {\n      main.invoke(null, new Object[] { newArgs });\n    } catch (InvocationTargetException e) {\n      throw e.getTargetException();\n    }\n  }",
      "path": "src/java/org/apache/hadoop/util/RunJar.java"
    }
  }
}