{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "QuorumOutputStream.java",
  "functionName": "flushAndSync",
  "functionId": "flushAndSync___durable-boolean",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/QuorumOutputStream.java",
  "functionStartLine": 89,
  "functionEndLine": 120,
  "numCommitsSeen": 17,
  "timeTaken": 2488,
  "changeHistory": [
    "1e22f2bfbb1d9a29f5d4fa641b7a0dabd5b1dbf5",
    "098ec2b11ff3f677eb823f75b147a1ac8dbf959e",
    "663e7484c04c197eed53f10a7808140f1c955277",
    "8a8c9c18d37f0c8b219264796c0df4bcae6f4e38",
    "ca4582222e89114e4c61d38fbf973a66d2867abf",
    "8021d9199f278345aca6211f318145342ad036f4",
    "42cdc1b0835abb4a331d40f30f2c210143b747bc",
    "74d4573a23db5586c6e47ff2277aa7c35237da34"
  ],
  "changeHistoryShort": {
    "1e22f2bfbb1d9a29f5d4fa641b7a0dabd5b1dbf5": "Ybodychange",
    "098ec2b11ff3f677eb823f75b147a1ac8dbf959e": "Ybodychange",
    "663e7484c04c197eed53f10a7808140f1c955277": "Ybodychange",
    "8a8c9c18d37f0c8b219264796c0df4bcae6f4e38": "Ybodychange",
    "ca4582222e89114e4c61d38fbf973a66d2867abf": "Yparameterchange",
    "8021d9199f278345aca6211f318145342ad036f4": "Ybodychange",
    "42cdc1b0835abb4a331d40f30f2c210143b747bc": "Ybodychange",
    "74d4573a23db5586c6e47ff2277aa7c35237da34": "Yintroduced"
  },
  "changeHistoryDetails": {
    "1e22f2bfbb1d9a29f5d4fa641b7a0dabd5b1dbf5": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13610. [SBN read] Edit Tail Fast Path Part 4: Cleanup. Integration test, documentation, remove unnecessary dummy sync, minors fixups. Contributed by Erik Krogen.\n",
      "commitDate": "24/12/18 9:34 AM",
      "commitName": "1e22f2bfbb1d9a29f5d4fa641b7a0dabd5b1dbf5",
      "commitAuthor": "Erik Krogen",
      "commitDateOld": "27/07/16 5:55 PM",
      "commitNameOld": "098ec2b11ff3f677eb823f75b147a1ac8dbf959e",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 879.69,
      "commitsBetweenForRepo": 6703,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,41 +1,32 @@\n   protected void flushAndSync(boolean durable) throws IOException {\n     int numReadyBytes \u003d buf.countReadyBytes();\n     if (numReadyBytes \u003e 0) {\n       int numReadyTxns \u003d buf.countReadyTxns();\n       long firstTxToFlush \u003d buf.getFirstReadyTxId();\n \n       assert numReadyTxns \u003e 0;\n \n       // Copy from our double-buffer into a new byte array. This is for\n       // two reasons:\n       // 1) The IPC code has no way of specifying to send only a slice of\n       //    a larger array.\n       // 2) because the calls to the underlying nodes are asynchronous, we\n       //    need a defensive copy to avoid accidentally mutating the buffer\n       //    before it is sent.\n       DataOutputBuffer bufToSend \u003d new DataOutputBuffer(numReadyBytes);\n       buf.flushTo(bufToSend);\n       assert bufToSend.getLength() \u003d\u003d numReadyBytes;\n       byte[] data \u003d bufToSend.getData();\n       assert data.length \u003d\u003d bufToSend.getLength();\n \n       QuorumCall\u003cAsyncLogger, Void\u003e qcall \u003d loggers.sendEdits(\n           segmentTxId, firstTxToFlush,\n           numReadyTxns, data);\n       loggers.waitForWriteQuorum(qcall, writeTimeoutMs, \"sendEdits\");\n       \n       // Since we successfully wrote this batch, let the loggers know. Any future\n       // RPCs will thus let the loggers know of the most recent transaction, even\n       // if a logger has fallen behind.\n       loggers.setCommittedTxId(firstTxToFlush + numReadyTxns - 1);\n-\n-      // If we don\u0027t have this dummy send, committed TxId might be one-batch\n-      // stale on the Journal Nodes\n-      if (updateCommittedTxId) {\n-        QuorumCall\u003cAsyncLogger, Void\u003e fakeCall \u003d loggers.sendEdits(\n-            segmentTxId, firstTxToFlush,\n-            0, new byte[0]);\n-        loggers.waitForWriteQuorum(fakeCall, writeTimeoutMs, \"sendEdits\");\n-      }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void flushAndSync(boolean durable) throws IOException {\n    int numReadyBytes \u003d buf.countReadyBytes();\n    if (numReadyBytes \u003e 0) {\n      int numReadyTxns \u003d buf.countReadyTxns();\n      long firstTxToFlush \u003d buf.getFirstReadyTxId();\n\n      assert numReadyTxns \u003e 0;\n\n      // Copy from our double-buffer into a new byte array. This is for\n      // two reasons:\n      // 1) The IPC code has no way of specifying to send only a slice of\n      //    a larger array.\n      // 2) because the calls to the underlying nodes are asynchronous, we\n      //    need a defensive copy to avoid accidentally mutating the buffer\n      //    before it is sent.\n      DataOutputBuffer bufToSend \u003d new DataOutputBuffer(numReadyBytes);\n      buf.flushTo(bufToSend);\n      assert bufToSend.getLength() \u003d\u003d numReadyBytes;\n      byte[] data \u003d bufToSend.getData();\n      assert data.length \u003d\u003d bufToSend.getLength();\n\n      QuorumCall\u003cAsyncLogger, Void\u003e qcall \u003d loggers.sendEdits(\n          segmentTxId, firstTxToFlush,\n          numReadyTxns, data);\n      loggers.waitForWriteQuorum(qcall, writeTimeoutMs, \"sendEdits\");\n      \n      // Since we successfully wrote this batch, let the loggers know. Any future\n      // RPCs will thus let the loggers know of the most recent transaction, even\n      // if a logger has fallen behind.\n      loggers.setCommittedTxId(firstTxToFlush + numReadyTxns - 1);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/QuorumOutputStream.java",
      "extendedDetails": {}
    },
    "098ec2b11ff3f677eb823f75b147a1ac8dbf959e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10519. Add a configuration option to enable in-progress edit log tailing. Contributed by Jiayi Zhou.\n",
      "commitDate": "27/07/16 5:55 PM",
      "commitName": "098ec2b11ff3f677eb823f75b147a1ac8dbf959e",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "20/03/14 4:06 PM",
      "commitNameOld": "9dab514b22f49322738935cfd915c2b4eba50b88",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 860.08,
      "commitsBetweenForRepo": 6689,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,32 +1,41 @@\n   protected void flushAndSync(boolean durable) throws IOException {\n     int numReadyBytes \u003d buf.countReadyBytes();\n     if (numReadyBytes \u003e 0) {\n       int numReadyTxns \u003d buf.countReadyTxns();\n       long firstTxToFlush \u003d buf.getFirstReadyTxId();\n \n       assert numReadyTxns \u003e 0;\n \n       // Copy from our double-buffer into a new byte array. This is for\n       // two reasons:\n       // 1) The IPC code has no way of specifying to send only a slice of\n       //    a larger array.\n       // 2) because the calls to the underlying nodes are asynchronous, we\n       //    need a defensive copy to avoid accidentally mutating the buffer\n       //    before it is sent.\n       DataOutputBuffer bufToSend \u003d new DataOutputBuffer(numReadyBytes);\n       buf.flushTo(bufToSend);\n       assert bufToSend.getLength() \u003d\u003d numReadyBytes;\n       byte[] data \u003d bufToSend.getData();\n       assert data.length \u003d\u003d bufToSend.getLength();\n \n       QuorumCall\u003cAsyncLogger, Void\u003e qcall \u003d loggers.sendEdits(\n           segmentTxId, firstTxToFlush,\n           numReadyTxns, data);\n       loggers.waitForWriteQuorum(qcall, writeTimeoutMs, \"sendEdits\");\n       \n       // Since we successfully wrote this batch, let the loggers know. Any future\n       // RPCs will thus let the loggers know of the most recent transaction, even\n       // if a logger has fallen behind.\n       loggers.setCommittedTxId(firstTxToFlush + numReadyTxns - 1);\n+\n+      // If we don\u0027t have this dummy send, committed TxId might be one-batch\n+      // stale on the Journal Nodes\n+      if (updateCommittedTxId) {\n+        QuorumCall\u003cAsyncLogger, Void\u003e fakeCall \u003d loggers.sendEdits(\n+            segmentTxId, firstTxToFlush,\n+            0, new byte[0]);\n+        loggers.waitForWriteQuorum(fakeCall, writeTimeoutMs, \"sendEdits\");\n+      }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void flushAndSync(boolean durable) throws IOException {\n    int numReadyBytes \u003d buf.countReadyBytes();\n    if (numReadyBytes \u003e 0) {\n      int numReadyTxns \u003d buf.countReadyTxns();\n      long firstTxToFlush \u003d buf.getFirstReadyTxId();\n\n      assert numReadyTxns \u003e 0;\n\n      // Copy from our double-buffer into a new byte array. This is for\n      // two reasons:\n      // 1) The IPC code has no way of specifying to send only a slice of\n      //    a larger array.\n      // 2) because the calls to the underlying nodes are asynchronous, we\n      //    need a defensive copy to avoid accidentally mutating the buffer\n      //    before it is sent.\n      DataOutputBuffer bufToSend \u003d new DataOutputBuffer(numReadyBytes);\n      buf.flushTo(bufToSend);\n      assert bufToSend.getLength() \u003d\u003d numReadyBytes;\n      byte[] data \u003d bufToSend.getData();\n      assert data.length \u003d\u003d bufToSend.getLength();\n\n      QuorumCall\u003cAsyncLogger, Void\u003e qcall \u003d loggers.sendEdits(\n          segmentTxId, firstTxToFlush,\n          numReadyTxns, data);\n      loggers.waitForWriteQuorum(qcall, writeTimeoutMs, \"sendEdits\");\n      \n      // Since we successfully wrote this batch, let the loggers know. Any future\n      // RPCs will thus let the loggers know of the most recent transaction, even\n      // if a logger has fallen behind.\n      loggers.setCommittedTxId(firstTxToFlush + numReadyTxns - 1);\n\n      // If we don\u0027t have this dummy send, committed TxId might be one-batch\n      // stale on the Journal Nodes\n      if (updateCommittedTxId) {\n        QuorumCall\u003cAsyncLogger, Void\u003e fakeCall \u003d loggers.sendEdits(\n            segmentTxId, firstTxToFlush,\n            0, new byte[0]);\n        loggers.waitForWriteQuorum(fakeCall, writeTimeoutMs, \"sendEdits\");\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/QuorumOutputStream.java",
      "extendedDetails": {}
    },
    "663e7484c04c197eed53f10a7808140f1c955277": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3950. QJM: misc TODO cleanup, improved log messages, etc. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1387704 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/09/12 11:52 AM",
      "commitName": "663e7484c04c197eed53f10a7808140f1c955277",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "10/09/12 11:31 PM",
      "commitNameOld": "8a8c9c18d37f0c8b219264796c0df4bcae6f4e38",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 8.51,
      "commitsBetweenForRepo": 40,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,32 +1,32 @@\n   protected void flushAndSync(boolean durable) throws IOException {\n     int numReadyBytes \u003d buf.countReadyBytes();\n     if (numReadyBytes \u003e 0) {\n       int numReadyTxns \u003d buf.countReadyTxns();\n       long firstTxToFlush \u003d buf.getFirstReadyTxId();\n \n       assert numReadyTxns \u003e 0;\n \n       // Copy from our double-buffer into a new byte array. This is for\n       // two reasons:\n       // 1) The IPC code has no way of specifying to send only a slice of\n       //    a larger array.\n       // 2) because the calls to the underlying nodes are asynchronous, we\n       //    need a defensive copy to avoid accidentally mutating the buffer\n       //    before it is sent.\n       DataOutputBuffer bufToSend \u003d new DataOutputBuffer(numReadyBytes);\n       buf.flushTo(bufToSend);\n       assert bufToSend.getLength() \u003d\u003d numReadyBytes;\n       byte[] data \u003d bufToSend.getData();\n       assert data.length \u003d\u003d bufToSend.getLength();\n \n       QuorumCall\u003cAsyncLogger, Void\u003e qcall \u003d loggers.sendEdits(\n           segmentTxId, firstTxToFlush,\n           numReadyTxns, data);\n-      loggers.waitForWriteQuorum(qcall, 20000, \"sendEdits\"); // TODO: configurable timeout\n+      loggers.waitForWriteQuorum(qcall, writeTimeoutMs, \"sendEdits\");\n       \n       // Since we successfully wrote this batch, let the loggers know. Any future\n       // RPCs will thus let the loggers know of the most recent transaction, even\n       // if a logger has fallen behind.\n       loggers.setCommittedTxId(firstTxToFlush + numReadyTxns - 1);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void flushAndSync(boolean durable) throws IOException {\n    int numReadyBytes \u003d buf.countReadyBytes();\n    if (numReadyBytes \u003e 0) {\n      int numReadyTxns \u003d buf.countReadyTxns();\n      long firstTxToFlush \u003d buf.getFirstReadyTxId();\n\n      assert numReadyTxns \u003e 0;\n\n      // Copy from our double-buffer into a new byte array. This is for\n      // two reasons:\n      // 1) The IPC code has no way of specifying to send only a slice of\n      //    a larger array.\n      // 2) because the calls to the underlying nodes are asynchronous, we\n      //    need a defensive copy to avoid accidentally mutating the buffer\n      //    before it is sent.\n      DataOutputBuffer bufToSend \u003d new DataOutputBuffer(numReadyBytes);\n      buf.flushTo(bufToSend);\n      assert bufToSend.getLength() \u003d\u003d numReadyBytes;\n      byte[] data \u003d bufToSend.getData();\n      assert data.length \u003d\u003d bufToSend.getLength();\n\n      QuorumCall\u003cAsyncLogger, Void\u003e qcall \u003d loggers.sendEdits(\n          segmentTxId, firstTxToFlush,\n          numReadyTxns, data);\n      loggers.waitForWriteQuorum(qcall, writeTimeoutMs, \"sendEdits\");\n      \n      // Since we successfully wrote this batch, let the loggers know. Any future\n      // RPCs will thus let the loggers know of the most recent transaction, even\n      // if a logger has fallen behind.\n      loggers.setCommittedTxId(firstTxToFlush + numReadyTxns - 1);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/QuorumOutputStream.java",
      "extendedDetails": {}
    },
    "8a8c9c18d37f0c8b219264796c0df4bcae6f4e38": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3906. QJM: quorum timeout on failover with large log segment. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1383251 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/09/12 11:31 PM",
      "commitName": "8a8c9c18d37f0c8b219264796c0df4bcae6f4e38",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "10/09/12 11:51 AM",
      "commitNameOld": "ca4582222e89114e4c61d38fbf973a66d2867abf",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 0.49,
      "commitsBetweenForRepo": 6,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,32 +1,32 @@\n   protected void flushAndSync(boolean durable) throws IOException {\n     int numReadyBytes \u003d buf.countReadyBytes();\n     if (numReadyBytes \u003e 0) {\n       int numReadyTxns \u003d buf.countReadyTxns();\n       long firstTxToFlush \u003d buf.getFirstReadyTxId();\n \n       assert numReadyTxns \u003e 0;\n \n       // Copy from our double-buffer into a new byte array. This is for\n       // two reasons:\n       // 1) The IPC code has no way of specifying to send only a slice of\n       //    a larger array.\n       // 2) because the calls to the underlying nodes are asynchronous, we\n       //    need a defensive copy to avoid accidentally mutating the buffer\n       //    before it is sent.\n       DataOutputBuffer bufToSend \u003d new DataOutputBuffer(numReadyBytes);\n       buf.flushTo(bufToSend);\n       assert bufToSend.getLength() \u003d\u003d numReadyBytes;\n       byte[] data \u003d bufToSend.getData();\n       assert data.length \u003d\u003d bufToSend.getLength();\n \n       QuorumCall\u003cAsyncLogger, Void\u003e qcall \u003d loggers.sendEdits(\n           segmentTxId, firstTxToFlush,\n           numReadyTxns, data);\n-      loggers.waitForWriteQuorum(qcall, 20000); // TODO: configurable timeout\n+      loggers.waitForWriteQuorum(qcall, 20000, \"sendEdits\"); // TODO: configurable timeout\n       \n       // Since we successfully wrote this batch, let the loggers know. Any future\n       // RPCs will thus let the loggers know of the most recent transaction, even\n       // if a logger has fallen behind.\n       loggers.setCommittedTxId(firstTxToFlush + numReadyTxns - 1);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void flushAndSync(boolean durable) throws IOException {\n    int numReadyBytes \u003d buf.countReadyBytes();\n    if (numReadyBytes \u003e 0) {\n      int numReadyTxns \u003d buf.countReadyTxns();\n      long firstTxToFlush \u003d buf.getFirstReadyTxId();\n\n      assert numReadyTxns \u003e 0;\n\n      // Copy from our double-buffer into a new byte array. This is for\n      // two reasons:\n      // 1) The IPC code has no way of specifying to send only a slice of\n      //    a larger array.\n      // 2) because the calls to the underlying nodes are asynchronous, we\n      //    need a defensive copy to avoid accidentally mutating the buffer\n      //    before it is sent.\n      DataOutputBuffer bufToSend \u003d new DataOutputBuffer(numReadyBytes);\n      buf.flushTo(bufToSend);\n      assert bufToSend.getLength() \u003d\u003d numReadyBytes;\n      byte[] data \u003d bufToSend.getData();\n      assert data.length \u003d\u003d bufToSend.getLength();\n\n      QuorumCall\u003cAsyncLogger, Void\u003e qcall \u003d loggers.sendEdits(\n          segmentTxId, firstTxToFlush,\n          numReadyTxns, data);\n      loggers.waitForWriteQuorum(qcall, 20000, \"sendEdits\"); // TODO: configurable timeout\n      \n      // Since we successfully wrote this batch, let the loggers know. Any future\n      // RPCs will thus let the loggers know of the most recent transaction, even\n      // if a logger has fallen behind.\n      loggers.setCommittedTxId(firstTxToFlush + numReadyTxns - 1);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/QuorumOutputStream.java",
      "extendedDetails": {}
    },
    "ca4582222e89114e4c61d38fbf973a66d2867abf": {
      "type": "Yparameterchange",
      "commitMessage": "HDFS-3885. QJM: optimize log sync when JN is lagging behind. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1383039 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/09/12 11:51 AM",
      "commitName": "ca4582222e89114e4c61d38fbf973a66d2867abf",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "04/09/12 9:16 PM",
      "commitNameOld": "72485f3112832a6a32f912d59ecf303a0c7e919a",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 5.61,
      "commitsBetweenForRepo": 46,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,32 +1,32 @@\n-  protected void flushAndSync() throws IOException {\n+  protected void flushAndSync(boolean durable) throws IOException {\n     int numReadyBytes \u003d buf.countReadyBytes();\n     if (numReadyBytes \u003e 0) {\n       int numReadyTxns \u003d buf.countReadyTxns();\n       long firstTxToFlush \u003d buf.getFirstReadyTxId();\n \n       assert numReadyTxns \u003e 0;\n \n       // Copy from our double-buffer into a new byte array. This is for\n       // two reasons:\n       // 1) The IPC code has no way of specifying to send only a slice of\n       //    a larger array.\n       // 2) because the calls to the underlying nodes are asynchronous, we\n       //    need a defensive copy to avoid accidentally mutating the buffer\n       //    before it is sent.\n       DataOutputBuffer bufToSend \u003d new DataOutputBuffer(numReadyBytes);\n       buf.flushTo(bufToSend);\n       assert bufToSend.getLength() \u003d\u003d numReadyBytes;\n       byte[] data \u003d bufToSend.getData();\n       assert data.length \u003d\u003d bufToSend.getLength();\n \n       QuorumCall\u003cAsyncLogger, Void\u003e qcall \u003d loggers.sendEdits(\n           segmentTxId, firstTxToFlush,\n           numReadyTxns, data);\n       loggers.waitForWriteQuorum(qcall, 20000); // TODO: configurable timeout\n       \n       // Since we successfully wrote this batch, let the loggers know. Any future\n       // RPCs will thus let the loggers know of the most recent transaction, even\n       // if a logger has fallen behind.\n       loggers.setCommittedTxId(firstTxToFlush + numReadyTxns - 1);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void flushAndSync(boolean durable) throws IOException {\n    int numReadyBytes \u003d buf.countReadyBytes();\n    if (numReadyBytes \u003e 0) {\n      int numReadyTxns \u003d buf.countReadyTxns();\n      long firstTxToFlush \u003d buf.getFirstReadyTxId();\n\n      assert numReadyTxns \u003e 0;\n\n      // Copy from our double-buffer into a new byte array. This is for\n      // two reasons:\n      // 1) The IPC code has no way of specifying to send only a slice of\n      //    a larger array.\n      // 2) because the calls to the underlying nodes are asynchronous, we\n      //    need a defensive copy to avoid accidentally mutating the buffer\n      //    before it is sent.\n      DataOutputBuffer bufToSend \u003d new DataOutputBuffer(numReadyBytes);\n      buf.flushTo(bufToSend);\n      assert bufToSend.getLength() \u003d\u003d numReadyBytes;\n      byte[] data \u003d bufToSend.getData();\n      assert data.length \u003d\u003d bufToSend.getLength();\n\n      QuorumCall\u003cAsyncLogger, Void\u003e qcall \u003d loggers.sendEdits(\n          segmentTxId, firstTxToFlush,\n          numReadyTxns, data);\n      loggers.waitForWriteQuorum(qcall, 20000); // TODO: configurable timeout\n      \n      // Since we successfully wrote this batch, let the loggers know. Any future\n      // RPCs will thus let the loggers know of the most recent transaction, even\n      // if a logger has fallen behind.\n      loggers.setCommittedTxId(firstTxToFlush + numReadyTxns - 1);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/QuorumOutputStream.java",
      "extendedDetails": {
        "oldValue": "[]",
        "newValue": "[durable-boolean]"
      }
    },
    "8021d9199f278345aca6211f318145342ad036f4": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3863. Track last \"committed\" txid in QJM. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1380976 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/09/12 9:13 PM",
      "commitName": "8021d9199f278345aca6211f318145342ad036f4",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "15/08/12 11:58 AM",
      "commitNameOld": "42cdc1b0835abb4a331d40f30f2c210143b747bc",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 20.39,
      "commitsBetweenForRepo": 80,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,27 +1,32 @@\n   protected void flushAndSync() throws IOException {\n     int numReadyBytes \u003d buf.countReadyBytes();\n     if (numReadyBytes \u003e 0) {\n       int numReadyTxns \u003d buf.countReadyTxns();\n       long firstTxToFlush \u003d buf.getFirstReadyTxId();\n \n       assert numReadyTxns \u003e 0;\n \n       // Copy from our double-buffer into a new byte array. This is for\n       // two reasons:\n       // 1) The IPC code has no way of specifying to send only a slice of\n       //    a larger array.\n       // 2) because the calls to the underlying nodes are asynchronous, we\n       //    need a defensive copy to avoid accidentally mutating the buffer\n       //    before it is sent.\n       DataOutputBuffer bufToSend \u003d new DataOutputBuffer(numReadyBytes);\n       buf.flushTo(bufToSend);\n       assert bufToSend.getLength() \u003d\u003d numReadyBytes;\n       byte[] data \u003d bufToSend.getData();\n       assert data.length \u003d\u003d bufToSend.getLength();\n \n       QuorumCall\u003cAsyncLogger, Void\u003e qcall \u003d loggers.sendEdits(\n           segmentTxId, firstTxToFlush,\n           numReadyTxns, data);\n       loggers.waitForWriteQuorum(qcall, 20000); // TODO: configurable timeout\n+      \n+      // Since we successfully wrote this batch, let the loggers know. Any future\n+      // RPCs will thus let the loggers know of the most recent transaction, even\n+      // if a logger has fallen behind.\n+      loggers.setCommittedTxId(firstTxToFlush + numReadyTxns - 1);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void flushAndSync() throws IOException {\n    int numReadyBytes \u003d buf.countReadyBytes();\n    if (numReadyBytes \u003e 0) {\n      int numReadyTxns \u003d buf.countReadyTxns();\n      long firstTxToFlush \u003d buf.getFirstReadyTxId();\n\n      assert numReadyTxns \u003e 0;\n\n      // Copy from our double-buffer into a new byte array. This is for\n      // two reasons:\n      // 1) The IPC code has no way of specifying to send only a slice of\n      //    a larger array.\n      // 2) because the calls to the underlying nodes are asynchronous, we\n      //    need a defensive copy to avoid accidentally mutating the buffer\n      //    before it is sent.\n      DataOutputBuffer bufToSend \u003d new DataOutputBuffer(numReadyBytes);\n      buf.flushTo(bufToSend);\n      assert bufToSend.getLength() \u003d\u003d numReadyBytes;\n      byte[] data \u003d bufToSend.getData();\n      assert data.length \u003d\u003d bufToSend.getLength();\n\n      QuorumCall\u003cAsyncLogger, Void\u003e qcall \u003d loggers.sendEdits(\n          segmentTxId, firstTxToFlush,\n          numReadyTxns, data);\n      loggers.waitForWriteQuorum(qcall, 20000); // TODO: configurable timeout\n      \n      // Since we successfully wrote this batch, let the loggers know. Any future\n      // RPCs will thus let the loggers know of the most recent transaction, even\n      // if a logger has fallen behind.\n      loggers.setCommittedTxId(firstTxToFlush + numReadyTxns - 1);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/QuorumOutputStream.java",
      "extendedDetails": {}
    },
    "42cdc1b0835abb4a331d40f30f2c210143b747bc": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3797. QJM: add segment txid as a parameter to journal() RPC. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1373571 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "15/08/12 11:58 AM",
      "commitName": "42cdc1b0835abb4a331d40f30f2c210143b747bc",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "19/07/12 5:25 PM",
      "commitNameOld": "74d4573a23db5586c6e47ff2277aa7c35237da34",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 26.77,
      "commitsBetweenForRepo": 105,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,26 +1,27 @@\n   protected void flushAndSync() throws IOException {\n     int numReadyBytes \u003d buf.countReadyBytes();\n     if (numReadyBytes \u003e 0) {\n       int numReadyTxns \u003d buf.countReadyTxns();\n       long firstTxToFlush \u003d buf.getFirstReadyTxId();\n \n       assert numReadyTxns \u003e 0;\n \n       // Copy from our double-buffer into a new byte array. This is for\n       // two reasons:\n       // 1) The IPC code has no way of specifying to send only a slice of\n       //    a larger array.\n       // 2) because the calls to the underlying nodes are asynchronous, we\n       //    need a defensive copy to avoid accidentally mutating the buffer\n       //    before it is sent.\n       DataOutputBuffer bufToSend \u003d new DataOutputBuffer(numReadyBytes);\n       buf.flushTo(bufToSend);\n       assert bufToSend.getLength() \u003d\u003d numReadyBytes;\n       byte[] data \u003d bufToSend.getData();\n       assert data.length \u003d\u003d bufToSend.getLength();\n \n       QuorumCall\u003cAsyncLogger, Void\u003e qcall \u003d loggers.sendEdits(\n-          firstTxToFlush, numReadyTxns, data);\n+          segmentTxId, firstTxToFlush,\n+          numReadyTxns, data);\n       loggers.waitForWriteQuorum(qcall, 20000); // TODO: configurable timeout\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void flushAndSync() throws IOException {\n    int numReadyBytes \u003d buf.countReadyBytes();\n    if (numReadyBytes \u003e 0) {\n      int numReadyTxns \u003d buf.countReadyTxns();\n      long firstTxToFlush \u003d buf.getFirstReadyTxId();\n\n      assert numReadyTxns \u003e 0;\n\n      // Copy from our double-buffer into a new byte array. This is for\n      // two reasons:\n      // 1) The IPC code has no way of specifying to send only a slice of\n      //    a larger array.\n      // 2) because the calls to the underlying nodes are asynchronous, we\n      //    need a defensive copy to avoid accidentally mutating the buffer\n      //    before it is sent.\n      DataOutputBuffer bufToSend \u003d new DataOutputBuffer(numReadyBytes);\n      buf.flushTo(bufToSend);\n      assert bufToSend.getLength() \u003d\u003d numReadyBytes;\n      byte[] data \u003d bufToSend.getData();\n      assert data.length \u003d\u003d bufToSend.getLength();\n\n      QuorumCall\u003cAsyncLogger, Void\u003e qcall \u003d loggers.sendEdits(\n          segmentTxId, firstTxToFlush,\n          numReadyTxns, data);\n      loggers.waitForWriteQuorum(qcall, 20000); // TODO: configurable timeout\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/QuorumOutputStream.java",
      "extendedDetails": {}
    },
    "74d4573a23db5586c6e47ff2277aa7c35237da34": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-3077. Quorum-based protocol for reading and writing edit logs. Contributed by Todd Lipcon based on initial work from Brandon Li and Hari Mankude.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1363596 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/07/12 5:25 PM",
      "commitName": "74d4573a23db5586c6e47ff2277aa7c35237da34",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,26 @@\n+  protected void flushAndSync() throws IOException {\n+    int numReadyBytes \u003d buf.countReadyBytes();\n+    if (numReadyBytes \u003e 0) {\n+      int numReadyTxns \u003d buf.countReadyTxns();\n+      long firstTxToFlush \u003d buf.getFirstReadyTxId();\n+\n+      assert numReadyTxns \u003e 0;\n+\n+      // Copy from our double-buffer into a new byte array. This is for\n+      // two reasons:\n+      // 1) The IPC code has no way of specifying to send only a slice of\n+      //    a larger array.\n+      // 2) because the calls to the underlying nodes are asynchronous, we\n+      //    need a defensive copy to avoid accidentally mutating the buffer\n+      //    before it is sent.\n+      DataOutputBuffer bufToSend \u003d new DataOutputBuffer(numReadyBytes);\n+      buf.flushTo(bufToSend);\n+      assert bufToSend.getLength() \u003d\u003d numReadyBytes;\n+      byte[] data \u003d bufToSend.getData();\n+      assert data.length \u003d\u003d bufToSend.getLength();\n+\n+      QuorumCall\u003cAsyncLogger, Void\u003e qcall \u003d loggers.sendEdits(\n+          firstTxToFlush, numReadyTxns, data);\n+      loggers.waitForWriteQuorum(qcall, 20000); // TODO: configurable timeout\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  protected void flushAndSync() throws IOException {\n    int numReadyBytes \u003d buf.countReadyBytes();\n    if (numReadyBytes \u003e 0) {\n      int numReadyTxns \u003d buf.countReadyTxns();\n      long firstTxToFlush \u003d buf.getFirstReadyTxId();\n\n      assert numReadyTxns \u003e 0;\n\n      // Copy from our double-buffer into a new byte array. This is for\n      // two reasons:\n      // 1) The IPC code has no way of specifying to send only a slice of\n      //    a larger array.\n      // 2) because the calls to the underlying nodes are asynchronous, we\n      //    need a defensive copy to avoid accidentally mutating the buffer\n      //    before it is sent.\n      DataOutputBuffer bufToSend \u003d new DataOutputBuffer(numReadyBytes);\n      buf.flushTo(bufToSend);\n      assert bufToSend.getLength() \u003d\u003d numReadyBytes;\n      byte[] data \u003d bufToSend.getData();\n      assert data.length \u003d\u003d bufToSend.getLength();\n\n      QuorumCall\u003cAsyncLogger, Void\u003e qcall \u003d loggers.sendEdits(\n          firstTxToFlush, numReadyTxns, data);\n      loggers.waitForWriteQuorum(qcall, 20000); // TODO: configurable timeout\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/QuorumOutputStream.java"
    }
  }
}