{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DFSZKFailoverController.java",
  "functionName": "getLocalNNThreadDump",
  "functionId": "getLocalNNThreadDump",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSZKFailoverController.java",
  "functionStartLine": 239,
  "functionEndLine": 269,
  "numCommitsSeen": 24,
  "timeTaken": 1947,
  "changeHistory": [
    "fb8932a727f757b2e9c1c61a18145878d0eb77bd",
    "eca1a4bfe952fc184fe90dde50bac9b0e5293568",
    "2463666ecb553dbde1b8c540a21ad3d599239acf"
  ],
  "changeHistoryShort": {
    "fb8932a727f757b2e9c1c61a18145878d0eb77bd": "Ybodychange",
    "eca1a4bfe952fc184fe90dde50bac9b0e5293568": "Ybodychange",
    "2463666ecb553dbde1b8c540a21ad3d599239acf": "Yintroduced"
  },
  "changeHistoryDetails": {
    "fb8932a727f757b2e9c1c61a18145878d0eb77bd": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-16029. Consecutive StringBuilder.append can be reused. Contributed by Ayush Saxena.\n",
      "commitDate": "11/01/19 10:54 AM",
      "commitName": "fb8932a727f757b2e9c1c61a18145878d0eb77bd",
      "commitAuthor": "Giovanni Matteo Fumarola",
      "commitDateOld": "06/09/18 2:48 PM",
      "commitNameOld": "eca1a4bfe952fc184fe90dde50bac9b0e5293568",
      "commitAuthorOld": "Giovanni Matteo Fumarola",
      "daysBetweenCommits": 126.88,
      "commitsBetweenForRepo": 1038,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,31 +1,31 @@\n   private void getLocalNNThreadDump() {\n     isThreadDumpCaptured \u003d false;\n     // We use the same timeout value for both connection establishment\n     // timeout and read timeout.\n     int httpTimeOut \u003d conf.getInt(\n         DFSConfigKeys.DFS_HA_ZKFC_NN_HTTP_TIMEOUT_KEY,\n         DFSConfigKeys.DFS_HA_ZKFC_NN_HTTP_TIMEOUT_KEY_DEFAULT);\n     if (httpTimeOut \u003d\u003d 0) {\n       // If timeout value is set to zero, the feature is turned off.\n       return;\n     }\n     try {\n       String stacksUrl \u003d DFSUtil.getInfoServer(localNNTarget.getAddress(),\n           conf, DFSUtil.getHttpClientScheme(conf)) + \"/stacks\";\n       URL url \u003d new URL(stacksUrl);\n       HttpURLConnection conn \u003d (HttpURLConnection)url.openConnection();\n       conn.setReadTimeout(httpTimeOut);\n       conn.setConnectTimeout(httpTimeOut);\n       conn.connect();\n       ByteArrayOutputStream out \u003d new ByteArrayOutputStream();\n       IOUtils.copyBytes(conn.getInputStream(), out, 4096, true);\n       StringBuilder localNNThreadDumpContent \u003d\n           new StringBuilder(\"-- Local NN thread dump -- \\n\");\n-      localNNThreadDumpContent.append(out);\n-      localNNThreadDumpContent.append(\"\\n -- Local NN thread dump -- \");\n+      localNNThreadDumpContent.append(out)\n+          .append(\"\\n -- Local NN thread dump -- \");\n       LOG.info(\"{}\", localNNThreadDumpContent.toString());\n       isThreadDumpCaptured \u003d true;\n     } catch (IOException e) {\n       LOG.warn(\"Can\u0027t get local NN thread dump due to \" + e.getMessage());\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void getLocalNNThreadDump() {\n    isThreadDumpCaptured \u003d false;\n    // We use the same timeout value for both connection establishment\n    // timeout and read timeout.\n    int httpTimeOut \u003d conf.getInt(\n        DFSConfigKeys.DFS_HA_ZKFC_NN_HTTP_TIMEOUT_KEY,\n        DFSConfigKeys.DFS_HA_ZKFC_NN_HTTP_TIMEOUT_KEY_DEFAULT);\n    if (httpTimeOut \u003d\u003d 0) {\n      // If timeout value is set to zero, the feature is turned off.\n      return;\n    }\n    try {\n      String stacksUrl \u003d DFSUtil.getInfoServer(localNNTarget.getAddress(),\n          conf, DFSUtil.getHttpClientScheme(conf)) + \"/stacks\";\n      URL url \u003d new URL(stacksUrl);\n      HttpURLConnection conn \u003d (HttpURLConnection)url.openConnection();\n      conn.setReadTimeout(httpTimeOut);\n      conn.setConnectTimeout(httpTimeOut);\n      conn.connect();\n      ByteArrayOutputStream out \u003d new ByteArrayOutputStream();\n      IOUtils.copyBytes(conn.getInputStream(), out, 4096, true);\n      StringBuilder localNNThreadDumpContent \u003d\n          new StringBuilder(\"-- Local NN thread dump -- \\n\");\n      localNNThreadDumpContent.append(out)\n          .append(\"\\n -- Local NN thread dump -- \");\n      LOG.info(\"{}\", localNNThreadDumpContent.toString());\n      isThreadDumpCaptured \u003d true;\n    } catch (IOException e) {\n      LOG.warn(\"Can\u0027t get local NN thread dump due to \" + e.getMessage());\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSZKFailoverController.java",
      "extendedDetails": {}
    },
    "eca1a4bfe952fc184fe90dde50bac9b0e5293568": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13695. Move logging to slf4j in HDFS package. Contributed by Ian Pickering.\n",
      "commitDate": "06/09/18 2:48 PM",
      "commitName": "eca1a4bfe952fc184fe90dde50bac9b0e5293568",
      "commitAuthor": "Giovanni Matteo Fumarola",
      "commitDateOld": "05/12/17 6:23 AM",
      "commitNameOld": "6d16a99ae8821c13eec90132e2c63a96fce4b08a",
      "commitAuthorOld": "Brahma Reddy Battula",
      "daysBetweenCommits": 275.31,
      "commitsBetweenForRepo": 2504,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,31 +1,31 @@\n   private void getLocalNNThreadDump() {\n     isThreadDumpCaptured \u003d false;\n     // We use the same timeout value for both connection establishment\n     // timeout and read timeout.\n     int httpTimeOut \u003d conf.getInt(\n         DFSConfigKeys.DFS_HA_ZKFC_NN_HTTP_TIMEOUT_KEY,\n         DFSConfigKeys.DFS_HA_ZKFC_NN_HTTP_TIMEOUT_KEY_DEFAULT);\n     if (httpTimeOut \u003d\u003d 0) {\n       // If timeout value is set to zero, the feature is turned off.\n       return;\n     }\n     try {\n       String stacksUrl \u003d DFSUtil.getInfoServer(localNNTarget.getAddress(),\n           conf, DFSUtil.getHttpClientScheme(conf)) + \"/stacks\";\n       URL url \u003d new URL(stacksUrl);\n       HttpURLConnection conn \u003d (HttpURLConnection)url.openConnection();\n       conn.setReadTimeout(httpTimeOut);\n       conn.setConnectTimeout(httpTimeOut);\n       conn.connect();\n       ByteArrayOutputStream out \u003d new ByteArrayOutputStream();\n       IOUtils.copyBytes(conn.getInputStream(), out, 4096, true);\n       StringBuilder localNNThreadDumpContent \u003d\n           new StringBuilder(\"-- Local NN thread dump -- \\n\");\n       localNNThreadDumpContent.append(out);\n       localNNThreadDumpContent.append(\"\\n -- Local NN thread dump -- \");\n-      LOG.info(localNNThreadDumpContent);\n+      LOG.info(\"{}\", localNNThreadDumpContent.toString());\n       isThreadDumpCaptured \u003d true;\n     } catch (IOException e) {\n       LOG.warn(\"Can\u0027t get local NN thread dump due to \" + e.getMessage());\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void getLocalNNThreadDump() {\n    isThreadDumpCaptured \u003d false;\n    // We use the same timeout value for both connection establishment\n    // timeout and read timeout.\n    int httpTimeOut \u003d conf.getInt(\n        DFSConfigKeys.DFS_HA_ZKFC_NN_HTTP_TIMEOUT_KEY,\n        DFSConfigKeys.DFS_HA_ZKFC_NN_HTTP_TIMEOUT_KEY_DEFAULT);\n    if (httpTimeOut \u003d\u003d 0) {\n      // If timeout value is set to zero, the feature is turned off.\n      return;\n    }\n    try {\n      String stacksUrl \u003d DFSUtil.getInfoServer(localNNTarget.getAddress(),\n          conf, DFSUtil.getHttpClientScheme(conf)) + \"/stacks\";\n      URL url \u003d new URL(stacksUrl);\n      HttpURLConnection conn \u003d (HttpURLConnection)url.openConnection();\n      conn.setReadTimeout(httpTimeOut);\n      conn.setConnectTimeout(httpTimeOut);\n      conn.connect();\n      ByteArrayOutputStream out \u003d new ByteArrayOutputStream();\n      IOUtils.copyBytes(conn.getInputStream(), out, 4096, true);\n      StringBuilder localNNThreadDumpContent \u003d\n          new StringBuilder(\"-- Local NN thread dump -- \\n\");\n      localNNThreadDumpContent.append(out);\n      localNNThreadDumpContent.append(\"\\n -- Local NN thread dump -- \");\n      LOG.info(\"{}\", localNNThreadDumpContent.toString());\n      isThreadDumpCaptured \u003d true;\n    } catch (IOException e) {\n      LOG.warn(\"Can\u0027t get local NN thread dump due to \" + e.getMessage());\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSZKFailoverController.java",
      "extendedDetails": {}
    },
    "2463666ecb553dbde1b8c540a21ad3d599239acf": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-6184. Capture NN\u0027s thread dump when it fails over. Contributed by Ming Ma.\n",
      "commitDate": "12/05/15 7:37 PM",
      "commitName": "2463666ecb553dbde1b8c540a21ad3d599239acf",
      "commitAuthor": "Akira Ajisaka",
      "diff": "@@ -0,0 +1,31 @@\n+  private void getLocalNNThreadDump() {\n+    isThreadDumpCaptured \u003d false;\n+    // We use the same timeout value for both connection establishment\n+    // timeout and read timeout.\n+    int httpTimeOut \u003d conf.getInt(\n+        DFSConfigKeys.DFS_HA_ZKFC_NN_HTTP_TIMEOUT_KEY,\n+        DFSConfigKeys.DFS_HA_ZKFC_NN_HTTP_TIMEOUT_KEY_DEFAULT);\n+    if (httpTimeOut \u003d\u003d 0) {\n+      // If timeout value is set to zero, the feature is turned off.\n+      return;\n+    }\n+    try {\n+      String stacksUrl \u003d DFSUtil.getInfoServer(localNNTarget.getAddress(),\n+          conf, DFSUtil.getHttpClientScheme(conf)) + \"/stacks\";\n+      URL url \u003d new URL(stacksUrl);\n+      HttpURLConnection conn \u003d (HttpURLConnection)url.openConnection();\n+      conn.setReadTimeout(httpTimeOut);\n+      conn.setConnectTimeout(httpTimeOut);\n+      conn.connect();\n+      ByteArrayOutputStream out \u003d new ByteArrayOutputStream();\n+      IOUtils.copyBytes(conn.getInputStream(), out, 4096, true);\n+      StringBuilder localNNThreadDumpContent \u003d\n+          new StringBuilder(\"-- Local NN thread dump -- \\n\");\n+      localNNThreadDumpContent.append(out);\n+      localNNThreadDumpContent.append(\"\\n -- Local NN thread dump -- \");\n+      LOG.info(localNNThreadDumpContent);\n+      isThreadDumpCaptured \u003d true;\n+    } catch (IOException e) {\n+      LOG.warn(\"Can\u0027t get local NN thread dump due to \" + e.getMessage());\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void getLocalNNThreadDump() {\n    isThreadDumpCaptured \u003d false;\n    // We use the same timeout value for both connection establishment\n    // timeout and read timeout.\n    int httpTimeOut \u003d conf.getInt(\n        DFSConfigKeys.DFS_HA_ZKFC_NN_HTTP_TIMEOUT_KEY,\n        DFSConfigKeys.DFS_HA_ZKFC_NN_HTTP_TIMEOUT_KEY_DEFAULT);\n    if (httpTimeOut \u003d\u003d 0) {\n      // If timeout value is set to zero, the feature is turned off.\n      return;\n    }\n    try {\n      String stacksUrl \u003d DFSUtil.getInfoServer(localNNTarget.getAddress(),\n          conf, DFSUtil.getHttpClientScheme(conf)) + \"/stacks\";\n      URL url \u003d new URL(stacksUrl);\n      HttpURLConnection conn \u003d (HttpURLConnection)url.openConnection();\n      conn.setReadTimeout(httpTimeOut);\n      conn.setConnectTimeout(httpTimeOut);\n      conn.connect();\n      ByteArrayOutputStream out \u003d new ByteArrayOutputStream();\n      IOUtils.copyBytes(conn.getInputStream(), out, 4096, true);\n      StringBuilder localNNThreadDumpContent \u003d\n          new StringBuilder(\"-- Local NN thread dump -- \\n\");\n      localNNThreadDumpContent.append(out);\n      localNNThreadDumpContent.append(\"\\n -- Local NN thread dump -- \");\n      LOG.info(localNNThreadDumpContent);\n      isThreadDumpCaptured \u003d true;\n    } catch (IOException e) {\n      LOG.warn(\"Can\u0027t get local NN thread dump due to \" + e.getMessage());\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSZKFailoverController.java"
    }
  }
}