{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DynoInfraUtils.java",
  "functionName": "parseStaleDataNodeList",
  "functionId": "parseStaleDataNodeList___liveNodeJsonString-String__blockThreshold-int(modifiers-final)__log-Logger(modifiers-final)",
  "sourceFilePath": "hadoop-tools/hadoop-dynamometer/hadoop-dynamometer-infra/src/main/java/org/apache/hadoop/tools/dynamometer/DynoInfraUtils.java",
  "functionStartLine": 482,
  "functionEndLine": 527,
  "numCommitsSeen": 3,
  "timeTaken": 417,
  "changeHistory": [
    "ab0b180ddb5d0775a2452d5eeb7badd252aadb91"
  ],
  "changeHistoryShort": {
    "ab0b180ddb5d0775a2452d5eeb7badd252aadb91": "Yintroduced"
  },
  "changeHistoryDetails": {
    "ab0b180ddb5d0775a2452d5eeb7badd252aadb91": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-12345 Add Dynamometer to hadoop-tools, a tool for scale testing the HDFS NameNode with real metadata and workloads. Contributed by Erik Krogen.\n",
      "commitDate": "25/06/19 8:07 AM",
      "commitName": "ab0b180ddb5d0775a2452d5eeb7badd252aadb91",
      "commitAuthor": "Erik Krogen",
      "diff": "@@ -0,0 +1,46 @@\n+  static Set\u003cString\u003e parseStaleDataNodeList(String liveNodeJsonString,\n+      final int blockThreshold, final Logger log) throws IOException {\n+    final Set\u003cString\u003e dataNodesToReport \u003d new HashSet\u003c\u003e();\n+\n+    JsonFactory fac \u003d new JsonFactory();\n+    JsonParser parser \u003d fac.createJsonParser(IOUtils\n+        .toInputStream(liveNodeJsonString, StandardCharsets.UTF_8.name()));\n+\n+    int objectDepth \u003d 0;\n+    String currentNodeAddr \u003d null;\n+    for (JsonToken tok \u003d parser.nextToken(); tok !\u003d null; tok \u003d parser\n+        .nextToken()) {\n+      if (tok \u003d\u003d JsonToken.START_OBJECT) {\n+        objectDepth++;\n+      } else if (tok \u003d\u003d JsonToken.END_OBJECT) {\n+        objectDepth--;\n+      } else if (tok \u003d\u003d JsonToken.FIELD_NAME) {\n+        if (objectDepth \u003d\u003d 1) {\n+          // This is where the Datanode identifiers are stored\n+          currentNodeAddr \u003d parser.getCurrentName();\n+        } else if (objectDepth \u003d\u003d 2) {\n+          if (parser.getCurrentName().equals(\"numBlocks\")) {\n+            JsonToken valueToken \u003d parser.nextToken();\n+            if (valueToken !\u003d JsonToken.VALUE_NUMBER_INT\n+                || currentNodeAddr \u003d\u003d null) {\n+              throw new IOException(String.format(\"Malformed LiveNodes JSON; \"\n+                      + \"got token \u003d %s; currentNodeAddr \u003d %s: %s\",\n+                  valueToken, currentNodeAddr, liveNodeJsonString));\n+            }\n+            int numBlocks \u003d parser.getIntValue();\n+            if (numBlocks \u003c blockThreshold) {\n+              log.debug(String.format(\n+                  \"Queueing Datanode \u003c%s\u003e for block report; numBlocks \u003d %d\",\n+                  currentNodeAddr, numBlocks));\n+              dataNodesToReport.add(currentNodeAddr);\n+            } else {\n+              log.debug(String.format(\n+                  \"Not queueing Datanode \u003c%s\u003e for block report; numBlocks \u003d %d\",\n+                  currentNodeAddr, numBlocks));\n+            }\n+          }\n+        }\n+      }\n+    }\n+    return dataNodesToReport;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  static Set\u003cString\u003e parseStaleDataNodeList(String liveNodeJsonString,\n      final int blockThreshold, final Logger log) throws IOException {\n    final Set\u003cString\u003e dataNodesToReport \u003d new HashSet\u003c\u003e();\n\n    JsonFactory fac \u003d new JsonFactory();\n    JsonParser parser \u003d fac.createJsonParser(IOUtils\n        .toInputStream(liveNodeJsonString, StandardCharsets.UTF_8.name()));\n\n    int objectDepth \u003d 0;\n    String currentNodeAddr \u003d null;\n    for (JsonToken tok \u003d parser.nextToken(); tok !\u003d null; tok \u003d parser\n        .nextToken()) {\n      if (tok \u003d\u003d JsonToken.START_OBJECT) {\n        objectDepth++;\n      } else if (tok \u003d\u003d JsonToken.END_OBJECT) {\n        objectDepth--;\n      } else if (tok \u003d\u003d JsonToken.FIELD_NAME) {\n        if (objectDepth \u003d\u003d 1) {\n          // This is where the Datanode identifiers are stored\n          currentNodeAddr \u003d parser.getCurrentName();\n        } else if (objectDepth \u003d\u003d 2) {\n          if (parser.getCurrentName().equals(\"numBlocks\")) {\n            JsonToken valueToken \u003d parser.nextToken();\n            if (valueToken !\u003d JsonToken.VALUE_NUMBER_INT\n                || currentNodeAddr \u003d\u003d null) {\n              throw new IOException(String.format(\"Malformed LiveNodes JSON; \"\n                      + \"got token \u003d %s; currentNodeAddr \u003d %s: %s\",\n                  valueToken, currentNodeAddr, liveNodeJsonString));\n            }\n            int numBlocks \u003d parser.getIntValue();\n            if (numBlocks \u003c blockThreshold) {\n              log.debug(String.format(\n                  \"Queueing Datanode \u003c%s\u003e for block report; numBlocks \u003d %d\",\n                  currentNodeAddr, numBlocks));\n              dataNodesToReport.add(currentNodeAddr);\n            } else {\n              log.debug(String.format(\n                  \"Not queueing Datanode \u003c%s\u003e for block report; numBlocks \u003d %d\",\n                  currentNodeAddr, numBlocks));\n            }\n          }\n        }\n      }\n    }\n    return dataNodesToReport;\n  }",
      "path": "hadoop-tools/hadoop-dynamometer/hadoop-dynamometer-infra/src/main/java/org/apache/hadoop/tools/dynamometer/DynoInfraUtils.java"
    }
  }
}