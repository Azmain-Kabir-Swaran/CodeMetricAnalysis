{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "QueryCommand.java",
  "functionName": "execute",
  "functionId": "execute___cmd-CommandLine",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/diskbalancer/command/QueryCommand.java",
  "functionStartLine": 57,
  "functionEndLine": 90,
  "numCommitsSeen": 9,
  "timeTaken": 1338,
  "changeHistory": [
    "35c5943b8ba394191405555cdfc5e6127053ee97",
    "9c6a4383cac29b2893ce14e6c9a75705fabfd522",
    "8a6e3541226fb1b6798cedecc56f1f160012becf",
    "121142cf952a4f9af1eb2488fe1714b6b8e685b6",
    "9e5fcb5e40bb370e4579e6040c02e923c1a90427"
  ],
  "changeHistoryShort": {
    "35c5943b8ba394191405555cdfc5e6127053ee97": "Ybodychange",
    "9c6a4383cac29b2893ce14e6c9a75705fabfd522": "Ybodychange",
    "8a6e3541226fb1b6798cedecc56f1f160012becf": "Ybodychange",
    "121142cf952a4f9af1eb2488fe1714b6b8e685b6": "Ybodychange",
    "9e5fcb5e40bb370e4579e6040c02e923c1a90427": "Yintroduced"
  },
  "changeHistoryDetails": {
    "35c5943b8ba394191405555cdfc5e6127053ee97": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10553. DiskBalancer: Rename Tools/DiskBalancer class to Tools/DiskBalancerCLI. Contributed by Manoj Govindassamy.\n",
      "commitDate": "08/09/16 7:26 PM",
      "commitName": "35c5943b8ba394191405555cdfc5e6127053ee97",
      "commitAuthor": "Anu Engineer",
      "commitDateOld": "09/08/16 3:59 PM",
      "commitNameOld": "9c6a4383cac29b2893ce14e6c9a75705fabfd522",
      "commitAuthorOld": "Lei Xu",
      "daysBetweenCommits": 30.14,
      "commitsBetweenForRepo": 189,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,34 +1,34 @@\n   public void execute(CommandLine cmd) throws Exception {\n     LOG.info(\"Executing \\\"query plan\\\" command.\");\n-    Preconditions.checkState(cmd.hasOption(DiskBalancer.QUERY));\n-    verifyCommandOptions(DiskBalancer.QUERY, cmd);\n-    String nodeName \u003d cmd.getOptionValue(DiskBalancer.QUERY);\n+    Preconditions.checkState(cmd.hasOption(DiskBalancerCLI.QUERY));\n+    verifyCommandOptions(DiskBalancerCLI.QUERY, cmd);\n+    String nodeName \u003d cmd.getOptionValue(DiskBalancerCLI.QUERY);\n     Preconditions.checkNotNull(nodeName);\n     nodeName \u003d nodeName.trim();\n     String nodeAddress \u003d nodeName;\n \n     // if the string is not name:port format use the default port.\n     if (!nodeName.matches(\"[^\\\\:]+:[0-9]{2,5}\")) {\n       int defaultIPC \u003d NetUtils.createSocketAddr(\n           getConf().getTrimmed(DFSConfigKeys.DFS_DATANODE_IPC_ADDRESS_KEY,\n               DFSConfigKeys.DFS_DATANODE_IPC_ADDRESS_DEFAULT)).getPort();\n       nodeAddress \u003d nodeName + \":\" + defaultIPC;\n       LOG.debug(\"Using default data node port :  {}\", nodeAddress);\n     }\n \n     ClientDatanodeProtocol dataNode \u003d getDataNodeProxy(nodeAddress);\n     try {\n       DiskBalancerWorkStatus workStatus \u003d dataNode.queryDiskBalancerPlan();\n       System.out.printf(\"Plan File: %s%nPlan ID: %s%nResult: %s%n\",\n               workStatus.getPlanFile(),\n               workStatus.getPlanID(),\n               workStatus.getResult().toString());\n \n-      if (cmd.hasOption(DiskBalancer.VERBOSE)) {\n+      if (cmd.hasOption(DiskBalancerCLI.VERBOSE)) {\n         System.out.printf(\"%s\", workStatus.currentStateString());\n       }\n     } catch (DiskBalancerException ex) {\n       LOG.error(\"Query plan failed. ex: {}\", ex);\n       throw ex;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void execute(CommandLine cmd) throws Exception {\n    LOG.info(\"Executing \\\"query plan\\\" command.\");\n    Preconditions.checkState(cmd.hasOption(DiskBalancerCLI.QUERY));\n    verifyCommandOptions(DiskBalancerCLI.QUERY, cmd);\n    String nodeName \u003d cmd.getOptionValue(DiskBalancerCLI.QUERY);\n    Preconditions.checkNotNull(nodeName);\n    nodeName \u003d nodeName.trim();\n    String nodeAddress \u003d nodeName;\n\n    // if the string is not name:port format use the default port.\n    if (!nodeName.matches(\"[^\\\\:]+:[0-9]{2,5}\")) {\n      int defaultIPC \u003d NetUtils.createSocketAddr(\n          getConf().getTrimmed(DFSConfigKeys.DFS_DATANODE_IPC_ADDRESS_KEY,\n              DFSConfigKeys.DFS_DATANODE_IPC_ADDRESS_DEFAULT)).getPort();\n      nodeAddress \u003d nodeName + \":\" + defaultIPC;\n      LOG.debug(\"Using default data node port :  {}\", nodeAddress);\n    }\n\n    ClientDatanodeProtocol dataNode \u003d getDataNodeProxy(nodeAddress);\n    try {\n      DiskBalancerWorkStatus workStatus \u003d dataNode.queryDiskBalancerPlan();\n      System.out.printf(\"Plan File: %s%nPlan ID: %s%nResult: %s%n\",\n              workStatus.getPlanFile(),\n              workStatus.getPlanID(),\n              workStatus.getResult().toString());\n\n      if (cmd.hasOption(DiskBalancerCLI.VERBOSE)) {\n        System.out.printf(\"%s\", workStatus.currentStateString());\n      }\n    } catch (DiskBalancerException ex) {\n      LOG.error(\"Query plan failed. ex: {}\", ex);\n      throw ex;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/diskbalancer/command/QueryCommand.java",
      "extendedDetails": {}
    },
    "9c6a4383cac29b2893ce14e6c9a75705fabfd522": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10681. DiskBalancer: query command should report Plan file path apart from PlanID. (Manoj Govindassamy via lei)\n",
      "commitDate": "09/08/16 3:59 PM",
      "commitName": "9c6a4383cac29b2893ce14e6c9a75705fabfd522",
      "commitAuthor": "Lei Xu",
      "commitDateOld": "23/06/16 6:27 PM",
      "commitNameOld": "8a6e3541226fb1b6798cedecc56f1f160012becf",
      "commitAuthorOld": "Anu Engineer",
      "daysBetweenCommits": 46.9,
      "commitsBetweenForRepo": 403,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,32 +1,34 @@\n   public void execute(CommandLine cmd) throws Exception {\n     LOG.info(\"Executing \\\"query plan\\\" command.\");\n     Preconditions.checkState(cmd.hasOption(DiskBalancer.QUERY));\n     verifyCommandOptions(DiskBalancer.QUERY, cmd);\n     String nodeName \u003d cmd.getOptionValue(DiskBalancer.QUERY);\n     Preconditions.checkNotNull(nodeName);\n     nodeName \u003d nodeName.trim();\n     String nodeAddress \u003d nodeName;\n \n     // if the string is not name:port format use the default port.\n     if (!nodeName.matches(\"[^\\\\:]+:[0-9]{2,5}\")) {\n       int defaultIPC \u003d NetUtils.createSocketAddr(\n           getConf().getTrimmed(DFSConfigKeys.DFS_DATANODE_IPC_ADDRESS_KEY,\n               DFSConfigKeys.DFS_DATANODE_IPC_ADDRESS_DEFAULT)).getPort();\n       nodeAddress \u003d nodeName + \":\" + defaultIPC;\n       LOG.debug(\"Using default data node port :  {}\", nodeAddress);\n     }\n \n     ClientDatanodeProtocol dataNode \u003d getDataNodeProxy(nodeAddress);\n     try {\n       DiskBalancerWorkStatus workStatus \u003d dataNode.queryDiskBalancerPlan();\n-      System.out.printf(\"Plan ID: %s %nResult: %s%n\", workStatus.getPlanID(),\n-          workStatus.getResult().toString());\n+      System.out.printf(\"Plan File: %s%nPlan ID: %s%nResult: %s%n\",\n+              workStatus.getPlanFile(),\n+              workStatus.getPlanID(),\n+              workStatus.getResult().toString());\n \n       if (cmd.hasOption(DiskBalancer.VERBOSE)) {\n         System.out.printf(\"%s\", workStatus.currentStateString());\n       }\n     } catch (DiskBalancerException ex) {\n       LOG.error(\"Query plan failed. ex: {}\", ex);\n       throw ex;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void execute(CommandLine cmd) throws Exception {\n    LOG.info(\"Executing \\\"query plan\\\" command.\");\n    Preconditions.checkState(cmd.hasOption(DiskBalancer.QUERY));\n    verifyCommandOptions(DiskBalancer.QUERY, cmd);\n    String nodeName \u003d cmd.getOptionValue(DiskBalancer.QUERY);\n    Preconditions.checkNotNull(nodeName);\n    nodeName \u003d nodeName.trim();\n    String nodeAddress \u003d nodeName;\n\n    // if the string is not name:port format use the default port.\n    if (!nodeName.matches(\"[^\\\\:]+:[0-9]{2,5}\")) {\n      int defaultIPC \u003d NetUtils.createSocketAddr(\n          getConf().getTrimmed(DFSConfigKeys.DFS_DATANODE_IPC_ADDRESS_KEY,\n              DFSConfigKeys.DFS_DATANODE_IPC_ADDRESS_DEFAULT)).getPort();\n      nodeAddress \u003d nodeName + \":\" + defaultIPC;\n      LOG.debug(\"Using default data node port :  {}\", nodeAddress);\n    }\n\n    ClientDatanodeProtocol dataNode \u003d getDataNodeProxy(nodeAddress);\n    try {\n      DiskBalancerWorkStatus workStatus \u003d dataNode.queryDiskBalancerPlan();\n      System.out.printf(\"Plan File: %s%nPlan ID: %s%nResult: %s%n\",\n              workStatus.getPlanFile(),\n              workStatus.getPlanID(),\n              workStatus.getResult().toString());\n\n      if (cmd.hasOption(DiskBalancer.VERBOSE)) {\n        System.out.printf(\"%s\", workStatus.currentStateString());\n      }\n    } catch (DiskBalancerException ex) {\n      LOG.error(\"Query plan failed. ex: {}\", ex);\n      throw ex;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/diskbalancer/command/QueryCommand.java",
      "extendedDetails": {}
    },
    "8a6e3541226fb1b6798cedecc56f1f160012becf": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10552. DiskBalancer \"-query\" results in NPE if no plan for the node. Contributed by Anu Engineer.\n",
      "commitDate": "23/06/16 6:27 PM",
      "commitName": "8a6e3541226fb1b6798cedecc56f1f160012becf",
      "commitAuthor": "Anu Engineer",
      "commitDateOld": "23/06/16 6:21 PM",
      "commitNameOld": "7e2be5c4a0b68b556ec6afcb0e14e0ab5ef1a9b2",
      "commitAuthorOld": "Anu Engineer",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 9,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,32 +1,32 @@\n   public void execute(CommandLine cmd) throws Exception {\n     LOG.info(\"Executing \\\"query plan\\\" command.\");\n     Preconditions.checkState(cmd.hasOption(DiskBalancer.QUERY));\n     verifyCommandOptions(DiskBalancer.QUERY, cmd);\n     String nodeName \u003d cmd.getOptionValue(DiskBalancer.QUERY);\n     Preconditions.checkNotNull(nodeName);\n     nodeName \u003d nodeName.trim();\n     String nodeAddress \u003d nodeName;\n \n     // if the string is not name:port format use the default port.\n-    if (!nodeName.matches(\"^.*:\\\\d$\")) {\n+    if (!nodeName.matches(\"[^\\\\:]+:[0-9]{2,5}\")) {\n       int defaultIPC \u003d NetUtils.createSocketAddr(\n           getConf().getTrimmed(DFSConfigKeys.DFS_DATANODE_IPC_ADDRESS_KEY,\n               DFSConfigKeys.DFS_DATANODE_IPC_ADDRESS_DEFAULT)).getPort();\n       nodeAddress \u003d nodeName + \":\" + defaultIPC;\n       LOG.debug(\"Using default data node port :  {}\", nodeAddress);\n     }\n \n     ClientDatanodeProtocol dataNode \u003d getDataNodeProxy(nodeAddress);\n     try {\n       DiskBalancerWorkStatus workStatus \u003d dataNode.queryDiskBalancerPlan();\n       System.out.printf(\"Plan ID: %s %nResult: %s%n\", workStatus.getPlanID(),\n           workStatus.getResult().toString());\n \n       if (cmd.hasOption(DiskBalancer.VERBOSE)) {\n         System.out.printf(\"%s\", workStatus.currentStateString());\n       }\n     } catch (DiskBalancerException ex) {\n       LOG.error(\"Query plan failed. ex: {}\", ex);\n       throw ex;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void execute(CommandLine cmd) throws Exception {\n    LOG.info(\"Executing \\\"query plan\\\" command.\");\n    Preconditions.checkState(cmd.hasOption(DiskBalancer.QUERY));\n    verifyCommandOptions(DiskBalancer.QUERY, cmd);\n    String nodeName \u003d cmd.getOptionValue(DiskBalancer.QUERY);\n    Preconditions.checkNotNull(nodeName);\n    nodeName \u003d nodeName.trim();\n    String nodeAddress \u003d nodeName;\n\n    // if the string is not name:port format use the default port.\n    if (!nodeName.matches(\"[^\\\\:]+:[0-9]{2,5}\")) {\n      int defaultIPC \u003d NetUtils.createSocketAddr(\n          getConf().getTrimmed(DFSConfigKeys.DFS_DATANODE_IPC_ADDRESS_KEY,\n              DFSConfigKeys.DFS_DATANODE_IPC_ADDRESS_DEFAULT)).getPort();\n      nodeAddress \u003d nodeName + \":\" + defaultIPC;\n      LOG.debug(\"Using default data node port :  {}\", nodeAddress);\n    }\n\n    ClientDatanodeProtocol dataNode \u003d getDataNodeProxy(nodeAddress);\n    try {\n      DiskBalancerWorkStatus workStatus \u003d dataNode.queryDiskBalancerPlan();\n      System.out.printf(\"Plan ID: %s %nResult: %s%n\", workStatus.getPlanID(),\n          workStatus.getResult().toString());\n\n      if (cmd.hasOption(DiskBalancer.VERBOSE)) {\n        System.out.printf(\"%s\", workStatus.currentStateString());\n      }\n    } catch (DiskBalancerException ex) {\n      LOG.error(\"Query plan failed. ex: {}\", ex);\n      throw ex;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/diskbalancer/command/QueryCommand.java",
      "extendedDetails": {}
    },
    "121142cf952a4f9af1eb2488fe1714b6b8e685b6": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10501. DiskBalancer: Use the default datanode port if port is not provided. Contributed by Anu Engineer.\n",
      "commitDate": "23/06/16 6:21 PM",
      "commitName": "121142cf952a4f9af1eb2488fe1714b6b8e685b6",
      "commitAuthor": "Anu Engineer",
      "commitDateOld": "23/06/16 6:21 PM",
      "commitNameOld": "9e5fcb5e40bb370e4579e6040c02e923c1a90427",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 7,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,32 @@\n   public void execute(CommandLine cmd) throws Exception {\n     LOG.info(\"Executing \\\"query plan\\\" command.\");\n     Preconditions.checkState(cmd.hasOption(DiskBalancer.QUERY));\n     verifyCommandOptions(DiskBalancer.QUERY, cmd);\n     String nodeName \u003d cmd.getOptionValue(DiskBalancer.QUERY);\n     Preconditions.checkNotNull(nodeName);\n-    ClientDatanodeProtocol dataNode \u003d getDataNodeProxy(nodeName);\n+    nodeName \u003d nodeName.trim();\n+    String nodeAddress \u003d nodeName;\n+\n+    // if the string is not name:port format use the default port.\n+    if(!nodeName.matches(\"^.*:\\\\d$\")) {\n+      int defaultIPC \u003d NetUtils.createSocketAddr(\n+          getConf().getTrimmed(DFSConfigKeys.DFS_DATANODE_IPC_ADDRESS_KEY,\n+              DFSConfigKeys.DFS_DATANODE_IPC_ADDRESS_DEFAULT)).getPort();\n+      nodeAddress \u003d nodeName + \":\" + defaultIPC;\n+      LOG.debug(\"Using default data node port :  {}\", nodeAddress);\n+    }\n+\n+    ClientDatanodeProtocol dataNode \u003d getDataNodeProxy(nodeAddress);\n     try {\n       DiskBalancerWorkStatus workStatus \u003d dataNode.queryDiskBalancerPlan();\n-      System.out.printf(\"Plan ID: %s Result: %s%n\", workStatus.getPlanID(),\n+      System.out.printf(\"Plan ID: %s %nResult: %s%n\", workStatus.getPlanID(),\n           workStatus.getResult().toString());\n \n       if(cmd.hasOption(DiskBalancer.VERBOSE)) {\n         System.out.printf(\"%s\", workStatus.currentStateString());\n       }\n     } catch (DiskBalancerException ex) {\n       LOG.error(\"Query plan failed. ex: {}\", ex);\n       throw ex;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void execute(CommandLine cmd) throws Exception {\n    LOG.info(\"Executing \\\"query plan\\\" command.\");\n    Preconditions.checkState(cmd.hasOption(DiskBalancer.QUERY));\n    verifyCommandOptions(DiskBalancer.QUERY, cmd);\n    String nodeName \u003d cmd.getOptionValue(DiskBalancer.QUERY);\n    Preconditions.checkNotNull(nodeName);\n    nodeName \u003d nodeName.trim();\n    String nodeAddress \u003d nodeName;\n\n    // if the string is not name:port format use the default port.\n    if(!nodeName.matches(\"^.*:\\\\d$\")) {\n      int defaultIPC \u003d NetUtils.createSocketAddr(\n          getConf().getTrimmed(DFSConfigKeys.DFS_DATANODE_IPC_ADDRESS_KEY,\n              DFSConfigKeys.DFS_DATANODE_IPC_ADDRESS_DEFAULT)).getPort();\n      nodeAddress \u003d nodeName + \":\" + defaultIPC;\n      LOG.debug(\"Using default data node port :  {}\", nodeAddress);\n    }\n\n    ClientDatanodeProtocol dataNode \u003d getDataNodeProxy(nodeAddress);\n    try {\n      DiskBalancerWorkStatus workStatus \u003d dataNode.queryDiskBalancerPlan();\n      System.out.printf(\"Plan ID: %s %nResult: %s%n\", workStatus.getPlanID(),\n          workStatus.getResult().toString());\n\n      if(cmd.hasOption(DiskBalancer.VERBOSE)) {\n        System.out.printf(\"%s\", workStatus.currentStateString());\n      }\n    } catch (DiskBalancerException ex) {\n      LOG.error(\"Query plan failed. ex: {}\", ex);\n      throw ex;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/diskbalancer/command/QueryCommand.java",
      "extendedDetails": {}
    },
    "9e5fcb5e40bb370e4579e6040c02e923c1a90427": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-10402. DiskBalancer: Add QueryStatus command. (Contributed by Anu Engineer)\n",
      "commitDate": "23/06/16 6:21 PM",
      "commitName": "9e5fcb5e40bb370e4579e6040c02e923c1a90427",
      "commitAuthor": "Arpit Agarwal",
      "diff": "@@ -0,0 +1,20 @@\n+  public void execute(CommandLine cmd) throws Exception {\n+    LOG.info(\"Executing \\\"query plan\\\" command.\");\n+    Preconditions.checkState(cmd.hasOption(DiskBalancer.QUERY));\n+    verifyCommandOptions(DiskBalancer.QUERY, cmd);\n+    String nodeName \u003d cmd.getOptionValue(DiskBalancer.QUERY);\n+    Preconditions.checkNotNull(nodeName);\n+    ClientDatanodeProtocol dataNode \u003d getDataNodeProxy(nodeName);\n+    try {\n+      DiskBalancerWorkStatus workStatus \u003d dataNode.queryDiskBalancerPlan();\n+      System.out.printf(\"Plan ID: %s Result: %s%n\", workStatus.getPlanID(),\n+          workStatus.getResult().toString());\n+\n+      if(cmd.hasOption(DiskBalancer.VERBOSE)) {\n+        System.out.printf(\"%s\", workStatus.currentStateString());\n+      }\n+    } catch (DiskBalancerException ex) {\n+      LOG.error(\"Query plan failed. ex: {}\", ex);\n+      throw ex;\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void execute(CommandLine cmd) throws Exception {\n    LOG.info(\"Executing \\\"query plan\\\" command.\");\n    Preconditions.checkState(cmd.hasOption(DiskBalancer.QUERY));\n    verifyCommandOptions(DiskBalancer.QUERY, cmd);\n    String nodeName \u003d cmd.getOptionValue(DiskBalancer.QUERY);\n    Preconditions.checkNotNull(nodeName);\n    ClientDatanodeProtocol dataNode \u003d getDataNodeProxy(nodeName);\n    try {\n      DiskBalancerWorkStatus workStatus \u003d dataNode.queryDiskBalancerPlan();\n      System.out.printf(\"Plan ID: %s Result: %s%n\", workStatus.getPlanID(),\n          workStatus.getResult().toString());\n\n      if(cmd.hasOption(DiskBalancer.VERBOSE)) {\n        System.out.printf(\"%s\", workStatus.currentStateString());\n      }\n    } catch (DiskBalancerException ex) {\n      LOG.error(\"Query plan failed. ex: {}\", ex);\n      throw ex;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/diskbalancer/command/QueryCommand.java"
    }
  }
}