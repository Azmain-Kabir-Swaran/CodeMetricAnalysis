{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DFSOutputStream.java",
  "functionName": "getChecksum4Compute",
  "functionId": "getChecksum4Compute___checksum-DataChecksum__stat-HdfsFileStatus",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
  "functionStartLine": 178,
  "functionEndLine": 186,
  "numCommitsSeen": 139,
  "timeTaken": 3264,
  "changeHistory": [
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c",
    "a16bfff71bd7f00e06e1f59bfe5445a154bb8c66",
    "463aec11718e47d4aabb86a7a539cb973460aae6"
  ],
  "changeHistoryShort": {
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c": "Yfilerename",
    "a16bfff71bd7f00e06e1f59bfe5445a154bb8c66": "Ybodychange",
    "463aec11718e47d4aabb86a7a539cb973460aae6": "Yintroduced"
  },
  "changeHistoryDetails": {
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8053. Move DFSIn/OutputStream and related classes to hadoop-hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "26/09/15 11:08 AM",
      "commitName": "bf37d3d80e5179dea27e5bd5aea804a38aa9934c",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "26/09/15 9:06 AM",
      "commitNameOld": "861b52db242f238d7e36ad75c158025be959a696",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 0.08,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private static DataChecksum getChecksum4Compute(DataChecksum checksum,\n      HdfsFileStatus stat) {\n    if (DataStreamer.isLazyPersist(stat) \u0026\u0026 stat.getReplication() \u003d\u003d 1) {\n      // do not compute checksum for writing to single replica to memory\n      return DataChecksum.newDataChecksum(Type.NULL,\n          checksum.getBytesPerChecksum());\n    }\n    return checksum;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java"
      }
    },
    "a16bfff71bd7f00e06e1f59bfe5445a154bb8c66": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7854. Separate class DataStreamer out of DFSOutputStream. Contributed by Li Bo.\n",
      "commitDate": "24/03/15 11:06 AM",
      "commitName": "a16bfff71bd7f00e06e1f59bfe5445a154bb8c66",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "20/03/15 12:02 PM",
      "commitNameOld": "75ead273bea8a7dad61c4f99c3a16cab2697c498",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 3.96,
      "commitsBetweenForRepo": 37,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,9 +1,9 @@\n   private static DataChecksum getChecksum4Compute(DataChecksum checksum,\n       HdfsFileStatus stat) {\n-    if (isLazyPersist(stat) \u0026\u0026 stat.getReplication() \u003d\u003d 1) {\n+    if (DataStreamer.isLazyPersist(stat) \u0026\u0026 stat.getReplication() \u003d\u003d 1) {\n       // do not compute checksum for writing to single replica to memory\n       return DataChecksum.newDataChecksum(Type.NULL,\n           checksum.getBytesPerChecksum());\n     }\n     return checksum;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private static DataChecksum getChecksum4Compute(DataChecksum checksum,\n      HdfsFileStatus stat) {\n    if (DataStreamer.isLazyPersist(stat) \u0026\u0026 stat.getReplication() \u003d\u003d 1) {\n      // do not compute checksum for writing to single replica to memory\n      return DataChecksum.newDataChecksum(Type.NULL,\n          checksum.getBytesPerChecksum());\n    }\n    return checksum;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {}
    },
    "463aec11718e47d4aabb86a7a539cb973460aae6": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-6934. Move checksum computation off the hot path when writing to RAM disk. Contributed by Chris Nauroth.\n",
      "commitDate": "27/10/14 9:38 AM",
      "commitName": "463aec11718e47d4aabb86a7a539cb973460aae6",
      "commitAuthor": "cnauroth",
      "diff": "@@ -0,0 +1,9 @@\n+  private static DataChecksum getChecksum4Compute(DataChecksum checksum,\n+      HdfsFileStatus stat) {\n+    if (isLazyPersist(stat) \u0026\u0026 stat.getReplication() \u003d\u003d 1) {\n+      // do not compute checksum for writing to single replica to memory\n+      return DataChecksum.newDataChecksum(Type.NULL,\n+          checksum.getBytesPerChecksum());\n+    }\n+    return checksum;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private static DataChecksum getChecksum4Compute(DataChecksum checksum,\n      HdfsFileStatus stat) {\n    if (isLazyPersist(stat) \u0026\u0026 stat.getReplication() \u003d\u003d 1) {\n      // do not compute checksum for writing to single replica to memory\n      return DataChecksum.newDataChecksum(Type.NULL,\n          checksum.getBytesPerChecksum());\n    }\n    return checksum;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java"
    }
  }
}