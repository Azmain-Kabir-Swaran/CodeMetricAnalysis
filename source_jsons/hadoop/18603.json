{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "WordMean.java",
  "functionName": "readAndCalcMean",
  "functionId": "readAndCalcMean___path-Path__conf-Configuration",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-examples/src/main/java/org/apache/hadoop/examples/WordMean.java",
  "functionStartLine": 118,
  "functionEndLine": 160,
  "numCommitsSeen": 6,
  "timeTaken": 670,
  "changeHistory": [
    "905b17876c44634545a68300ff2f2d73fb86d3b7",
    "26447229ba2c3d43db978c1b3ce95613669182ee",
    "1c019512644cbd01fda43366db727887efb5ae7f"
  ],
  "changeHistoryShort": {
    "905b17876c44634545a68300ff2f2d73fb86d3b7": "Ybodychange",
    "26447229ba2c3d43db978c1b3ce95613669182ee": "Yfilerename",
    "1c019512644cbd01fda43366db727887efb5ae7f": "Yintroduced"
  },
  "changeHistoryDetails": {
    "905b17876c44634545a68300ff2f2d73fb86d3b7": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4723. Fix warnings found by findbugs 2. Contributed by Sandy Ryza\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1409601 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/11/12 4:16 PM",
      "commitName": "905b17876c44634545a68300ff2f2d73fb86d3b7",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "11/10/12 9:35 PM",
      "commitNameOld": "94ed14c48ccc9e752ec506d9ae8933518ca0a14b",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 33.82,
      "commitsBetweenForRepo": 197,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,41 +1,43 @@\n   private double readAndCalcMean(Path path, Configuration conf)\n       throws IOException {\n     FileSystem fs \u003d FileSystem.get(conf);\n     Path file \u003d new Path(path, \"part-r-00000\");\n \n     if (!fs.exists(file))\n       throw new IOException(\"Output not found!\");\n \n     BufferedReader br \u003d null;\n \n     // average \u003d total sum / number of elements;\n     try {\n-      br \u003d new BufferedReader(new InputStreamReader(fs.open(file)));\n+      br \u003d new BufferedReader(new InputStreamReader(fs.open(file), Charsets.UTF_8));\n \n       long count \u003d 0;\n       long length \u003d 0;\n \n       String line;\n       while ((line \u003d br.readLine()) !\u003d null) {\n         StringTokenizer st \u003d new StringTokenizer(line);\n \n         // grab type\n         String type \u003d st.nextToken();\n \n         // differentiate\n         if (type.equals(COUNT.toString())) {\n           String countLit \u003d st.nextToken();\n           count \u003d Long.parseLong(countLit);\n         } else if (type.equals(LENGTH.toString())) {\n           String lengthLit \u003d st.nextToken();\n           length \u003d Long.parseLong(lengthLit);\n         }\n       }\n \n       double theMean \u003d (((double) length) / ((double) count));\n       System.out.println(\"The mean is: \" + theMean);\n       return theMean;\n     } finally {\n-      br.close();\n+      if (br !\u003d null) {\n+        br.close();\n+      }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private double readAndCalcMean(Path path, Configuration conf)\n      throws IOException {\n    FileSystem fs \u003d FileSystem.get(conf);\n    Path file \u003d new Path(path, \"part-r-00000\");\n\n    if (!fs.exists(file))\n      throw new IOException(\"Output not found!\");\n\n    BufferedReader br \u003d null;\n\n    // average \u003d total sum / number of elements;\n    try {\n      br \u003d new BufferedReader(new InputStreamReader(fs.open(file), Charsets.UTF_8));\n\n      long count \u003d 0;\n      long length \u003d 0;\n\n      String line;\n      while ((line \u003d br.readLine()) !\u003d null) {\n        StringTokenizer st \u003d new StringTokenizer(line);\n\n        // grab type\n        String type \u003d st.nextToken();\n\n        // differentiate\n        if (type.equals(COUNT.toString())) {\n          String countLit \u003d st.nextToken();\n          count \u003d Long.parseLong(countLit);\n        } else if (type.equals(LENGTH.toString())) {\n          String lengthLit \u003d st.nextToken();\n          length \u003d Long.parseLong(lengthLit);\n        }\n      }\n\n      double theMean \u003d (((double) length) / ((double) count));\n      System.out.println(\"The mean is: \" + theMean);\n      return theMean;\n    } finally {\n      if (br !\u003d null) {\n        br.close();\n      }\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-examples/src/main/java/org/apache/hadoop/examples/WordMean.java",
      "extendedDetails": {}
    },
    "26447229ba2c3d43db978c1b3ce95613669182ee": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7590. Mavenize streaming and MR examples. (tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1203941 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/11/11 5:24 PM",
      "commitName": "26447229ba2c3d43db978c1b3ce95613669182ee",
      "commitAuthor": "Alejandro Abdelnur",
      "commitDateOld": "18/11/11 1:04 AM",
      "commitNameOld": "905a127850d5e0cba85c2e075f989fa0f5cf129a",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 0.68,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private double readAndCalcMean(Path path, Configuration conf)\n      throws IOException {\n    FileSystem fs \u003d FileSystem.get(conf);\n    Path file \u003d new Path(path, \"part-r-00000\");\n\n    if (!fs.exists(file))\n      throw new IOException(\"Output not found!\");\n\n    BufferedReader br \u003d null;\n\n    // average \u003d total sum / number of elements;\n    try {\n      br \u003d new BufferedReader(new InputStreamReader(fs.open(file)));\n\n      long count \u003d 0;\n      long length \u003d 0;\n\n      String line;\n      while ((line \u003d br.readLine()) !\u003d null) {\n        StringTokenizer st \u003d new StringTokenizer(line);\n\n        // grab type\n        String type \u003d st.nextToken();\n\n        // differentiate\n        if (type.equals(COUNT.toString())) {\n          String countLit \u003d st.nextToken();\n          count \u003d Long.parseLong(countLit);\n        } else if (type.equals(LENGTH.toString())) {\n          String lengthLit \u003d st.nextToken();\n          length \u003d Long.parseLong(lengthLit);\n        }\n      }\n\n      double theMean \u003d (((double) length) / ((double) count));\n      System.out.println(\"The mean is: \" + theMean);\n      return theMean;\n    } finally {\n      br.close();\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-examples/src/main/java/org/apache/hadoop/examples/WordMean.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce-project/src/examples/org/apache/hadoop/examples/WordMean.java",
        "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-examples/src/main/java/org/apache/hadoop/examples/WordMean.java"
      }
    },
    "1c019512644cbd01fda43366db727887efb5ae7f": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-2669. Add new examples for Mean, Median, and Standard Deviation. Contributed by Plamen Jeliazkov.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1169874 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/09/11 12:13 PM",
      "commitName": "1c019512644cbd01fda43366db727887efb5ae7f",
      "commitAuthor": "Konstantin Shvachko",
      "diff": "@@ -0,0 +1,41 @@\n+  private double readAndCalcMean(Path path, Configuration conf)\n+      throws IOException {\n+    FileSystem fs \u003d FileSystem.get(conf);\n+    Path file \u003d new Path(path, \"part-r-00000\");\n+\n+    if (!fs.exists(file))\n+      throw new IOException(\"Output not found!\");\n+\n+    BufferedReader br \u003d null;\n+\n+    // average \u003d total sum / number of elements;\n+    try {\n+      br \u003d new BufferedReader(new InputStreamReader(fs.open(file)));\n+\n+      long count \u003d 0;\n+      long length \u003d 0;\n+\n+      String line;\n+      while ((line \u003d br.readLine()) !\u003d null) {\n+        StringTokenizer st \u003d new StringTokenizer(line);\n+\n+        // grab type\n+        String type \u003d st.nextToken();\n+\n+        // differentiate\n+        if (type.equals(COUNT.toString())) {\n+          String countLit \u003d st.nextToken();\n+          count \u003d Long.parseLong(countLit);\n+        } else if (type.equals(LENGTH.toString())) {\n+          String lengthLit \u003d st.nextToken();\n+          length \u003d Long.parseLong(lengthLit);\n+        }\n+      }\n+\n+      double theMean \u003d (((double) length) / ((double) count));\n+      System.out.println(\"The mean is: \" + theMean);\n+      return theMean;\n+    } finally {\n+      br.close();\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private double readAndCalcMean(Path path, Configuration conf)\n      throws IOException {\n    FileSystem fs \u003d FileSystem.get(conf);\n    Path file \u003d new Path(path, \"part-r-00000\");\n\n    if (!fs.exists(file))\n      throw new IOException(\"Output not found!\");\n\n    BufferedReader br \u003d null;\n\n    // average \u003d total sum / number of elements;\n    try {\n      br \u003d new BufferedReader(new InputStreamReader(fs.open(file)));\n\n      long count \u003d 0;\n      long length \u003d 0;\n\n      String line;\n      while ((line \u003d br.readLine()) !\u003d null) {\n        StringTokenizer st \u003d new StringTokenizer(line);\n\n        // grab type\n        String type \u003d st.nextToken();\n\n        // differentiate\n        if (type.equals(COUNT.toString())) {\n          String countLit \u003d st.nextToken();\n          count \u003d Long.parseLong(countLit);\n        } else if (type.equals(LENGTH.toString())) {\n          String lengthLit \u003d st.nextToken();\n          length \u003d Long.parseLong(lengthLit);\n        }\n      }\n\n      double theMean \u003d (((double) length) / ((double) count));\n      System.out.println(\"The mean is: \" + theMean);\n      return theMean;\n    } finally {\n      br.close();\n    }\n  }",
      "path": "hadoop-mapreduce-project/src/examples/org/apache/hadoop/examples/WordMean.java"
    }
  }
}