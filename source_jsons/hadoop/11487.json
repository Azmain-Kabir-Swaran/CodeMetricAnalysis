{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FsVolumeList.java",
  "functionName": "removeVolume",
  "functionId": "removeVolume___target-FsVolumeImpl",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsVolumeList.java",
  "functionStartLine": 312,
  "functionEndLine": 332,
  "numCommitsSeen": 42,
  "timeTaken": 2265,
  "changeHistory": [
    "e50aa53eed3d0ff1bc8fe60381524bb3bbe53bc1",
    "533a2be5ac7c7f0473fdd24d6201582d08964e21",
    "6e62a1a6728b1f782f64065424f92b292c3f163a",
    "b7f4a3156c0f5c600816c469637237ba6c9b330c",
    "3b173d95171d01ab55042b1162569d1cf14a8d43"
  ],
  "changeHistoryShort": {
    "e50aa53eed3d0ff1bc8fe60381524bb3bbe53bc1": "Ybodychange",
    "533a2be5ac7c7f0473fdd24d6201582d08964e21": "Ybodychange",
    "6e62a1a6728b1f782f64065424f92b292c3f163a": "Ybodychange",
    "b7f4a3156c0f5c600816c469637237ba6c9b330c": "Ybodychange",
    "3b173d95171d01ab55042b1162569d1cf14a8d43": "Yintroduced"
  },
  "changeHistoryDetails": {
    "e50aa53eed3d0ff1bc8fe60381524bb3bbe53bc1": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9701. DN may deadlock when hot-swapping under load. (Xiao Chen via lei)\n",
      "commitDate": "01/02/16 12:56 PM",
      "commitName": "e50aa53eed3d0ff1bc8fe60381524bb3bbe53bc1",
      "commitAuthor": "Lei Xu",
      "commitDateOld": "23/10/15 1:52 PM",
      "commitNameOld": "533a2be5ac7c7f0473fdd24d6201582d08964e21",
      "commitAuthorOld": "Lei Xu",
      "daysBetweenCommits": 101.0,
      "commitsBetweenForRepo": 661,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,21 @@\n   private void removeVolume(FsVolumeImpl target) {\n     if (volumes.remove(target)) {\n       if (blockScanner !\u003d null) {\n         blockScanner.removeVolumeScanner(target);\n       }\n       try {\n-        target.closeAndWait();\n+        target.setClosed();\n       } catch (IOException e) {\n         FsDatasetImpl.LOG.warn(\n             \"Error occurs when waiting volume to close: \" + target, e);\n       }\n       target.shutdown();\n+      volumesBeingRemoved.add(target);\n       FsDatasetImpl.LOG.info(\"Removed volume: \" + target);\n     } else {\n       if (FsDatasetImpl.LOG.isDebugEnabled()) {\n         FsDatasetImpl.LOG.debug(\"Volume \" + target +\n             \" does not exist or is removed by others.\");\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void removeVolume(FsVolumeImpl target) {\n    if (volumes.remove(target)) {\n      if (blockScanner !\u003d null) {\n        blockScanner.removeVolumeScanner(target);\n      }\n      try {\n        target.setClosed();\n      } catch (IOException e) {\n        FsDatasetImpl.LOG.warn(\n            \"Error occurs when waiting volume to close: \" + target, e);\n      }\n      target.shutdown();\n      volumesBeingRemoved.add(target);\n      FsDatasetImpl.LOG.info(\"Removed volume: \" + target);\n    } else {\n      if (FsDatasetImpl.LOG.isDebugEnabled()) {\n        FsDatasetImpl.LOG.debug(\"Volume \" + target +\n            \" does not exist or is removed by others.\");\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsVolumeList.java",
      "extendedDetails": {}
    },
    "533a2be5ac7c7f0473fdd24d6201582d08964e21": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9264. Minor cleanup of operations on FsVolumeList#volumes.  (Walter Su via lei)\n",
      "commitDate": "23/10/15 1:52 PM",
      "commitName": "533a2be5ac7c7f0473fdd24d6201582d08964e21",
      "commitAuthor": "Lei Xu",
      "commitDateOld": "05/05/15 11:08 AM",
      "commitNameOld": "24d3a2d4fdd836ac9a5bc755a7fb9354f7a582b1",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 171.11,
      "commitsBetweenForRepo": 1435,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,35 +1,20 @@\n   private void removeVolume(FsVolumeImpl target) {\n-    while (true) {\n-      final FsVolumeImpl[] curVolumes \u003d volumes.get();\n-      final List\u003cFsVolumeImpl\u003e volumeList \u003d Lists.newArrayList(curVolumes);\n-      if (volumeList.remove(target)) {\n-        if (volumes.compareAndSet(curVolumes,\n-            volumeList.toArray(new FsVolumeImpl[volumeList.size()]))) {\n-          if (blockScanner !\u003d null) {\n-            blockScanner.removeVolumeScanner(target);\n-          }\n-          try {\n-            target.closeAndWait();\n-          } catch (IOException e) {\n-            FsDatasetImpl.LOG.warn(\n-                \"Error occurs when waiting volume to close: \" + target, e);\n-          }\n-          target.shutdown();\n-          FsDatasetImpl.LOG.info(\"Removed volume: \" + target);\n-          break;\n-        } else {\n-          if (FsDatasetImpl.LOG.isDebugEnabled()) {\n-            FsDatasetImpl.LOG.debug(\n-                \"The volume list has been changed concurrently, \" +\n-                \"retry to remove volume: \" + target);\n-          }\n-        }\n-      } else {\n-        if (FsDatasetImpl.LOG.isDebugEnabled()) {\n-          FsDatasetImpl.LOG.debug(\"Volume \" + target +\n-              \" does not exist or is removed by others.\");\n-        }\n-        break;\n+    if (volumes.remove(target)) {\n+      if (blockScanner !\u003d null) {\n+        blockScanner.removeVolumeScanner(target);\n+      }\n+      try {\n+        target.closeAndWait();\n+      } catch (IOException e) {\n+        FsDatasetImpl.LOG.warn(\n+            \"Error occurs when waiting volume to close: \" + target, e);\n+      }\n+      target.shutdown();\n+      FsDatasetImpl.LOG.info(\"Removed volume: \" + target);\n+    } else {\n+      if (FsDatasetImpl.LOG.isDebugEnabled()) {\n+        FsDatasetImpl.LOG.debug(\"Volume \" + target +\n+            \" does not exist or is removed by others.\");\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void removeVolume(FsVolumeImpl target) {\n    if (volumes.remove(target)) {\n      if (blockScanner !\u003d null) {\n        blockScanner.removeVolumeScanner(target);\n      }\n      try {\n        target.closeAndWait();\n      } catch (IOException e) {\n        FsDatasetImpl.LOG.warn(\n            \"Error occurs when waiting volume to close: \" + target, e);\n      }\n      target.shutdown();\n      FsDatasetImpl.LOG.info(\"Removed volume: \" + target);\n    } else {\n      if (FsDatasetImpl.LOG.isDebugEnabled()) {\n        FsDatasetImpl.LOG.debug(\"Volume \" + target +\n            \" does not exist or is removed by others.\");\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsVolumeList.java",
      "extendedDetails": {}
    },
    "6e62a1a6728b1f782f64065424f92b292c3f163a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7430. Refactor the BlockScanner to use O(1) memory and use multiple threads (cmccabe)\n",
      "commitDate": "21/01/15 7:00 PM",
      "commitName": "6e62a1a6728b1f782f64065424f92b292c3f163a",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "20/01/15 8:11 PM",
      "commitNameOld": "a17584936cc5141e3f5612ac3ecf35e27968e439",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 0.95,
      "commitsBetweenForRepo": 14,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,32 +1,35 @@\n   private void removeVolume(FsVolumeImpl target) {\n     while (true) {\n       final FsVolumeImpl[] curVolumes \u003d volumes.get();\n       final List\u003cFsVolumeImpl\u003e volumeList \u003d Lists.newArrayList(curVolumes);\n       if (volumeList.remove(target)) {\n         if (volumes.compareAndSet(curVolumes,\n             volumeList.toArray(new FsVolumeImpl[volumeList.size()]))) {\n+          if (blockScanner !\u003d null) {\n+            blockScanner.removeVolumeScanner(target);\n+          }\n           try {\n             target.closeAndWait();\n           } catch (IOException e) {\n             FsDatasetImpl.LOG.warn(\n                 \"Error occurs when waiting volume to close: \" + target, e);\n           }\n           target.shutdown();\n           FsDatasetImpl.LOG.info(\"Removed volume: \" + target);\n           break;\n         } else {\n           if (FsDatasetImpl.LOG.isDebugEnabled()) {\n             FsDatasetImpl.LOG.debug(\n                 \"The volume list has been changed concurrently, \" +\n                 \"retry to remove volume: \" + target);\n           }\n         }\n       } else {\n         if (FsDatasetImpl.LOG.isDebugEnabled()) {\n           FsDatasetImpl.LOG.debug(\"Volume \" + target +\n               \" does not exist or is removed by others.\");\n         }\n         break;\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void removeVolume(FsVolumeImpl target) {\n    while (true) {\n      final FsVolumeImpl[] curVolumes \u003d volumes.get();\n      final List\u003cFsVolumeImpl\u003e volumeList \u003d Lists.newArrayList(curVolumes);\n      if (volumeList.remove(target)) {\n        if (volumes.compareAndSet(curVolumes,\n            volumeList.toArray(new FsVolumeImpl[volumeList.size()]))) {\n          if (blockScanner !\u003d null) {\n            blockScanner.removeVolumeScanner(target);\n          }\n          try {\n            target.closeAndWait();\n          } catch (IOException e) {\n            FsDatasetImpl.LOG.warn(\n                \"Error occurs when waiting volume to close: \" + target, e);\n          }\n          target.shutdown();\n          FsDatasetImpl.LOG.info(\"Removed volume: \" + target);\n          break;\n        } else {\n          if (FsDatasetImpl.LOG.isDebugEnabled()) {\n            FsDatasetImpl.LOG.debug(\n                \"The volume list has been changed concurrently, \" +\n                \"retry to remove volume: \" + target);\n          }\n        }\n      } else {\n        if (FsDatasetImpl.LOG.isDebugEnabled()) {\n          FsDatasetImpl.LOG.debug(\"Volume \" + target +\n              \" does not exist or is removed by others.\");\n        }\n        break;\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsVolumeList.java",
      "extendedDetails": {}
    },
    "b7f4a3156c0f5c600816c469637237ba6c9b330c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7496. Fix FsVolume removal race conditions on the DataNode by reference-counting the volume instances (lei via cmccabe)\n",
      "commitDate": "20/01/15 7:05 PM",
      "commitName": "b7f4a3156c0f5c600816c469637237ba6c9b330c",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "19/12/14 11:13 AM",
      "commitNameOld": "a4876c130f1627e59ef055e586640d1933fc49af",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 32.33,
      "commitsBetweenForRepo": 151,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,26 +1,32 @@\n   private void removeVolume(FsVolumeImpl target) {\n     while (true) {\n       final FsVolumeImpl[] curVolumes \u003d volumes.get();\n       final List\u003cFsVolumeImpl\u003e volumeList \u003d Lists.newArrayList(curVolumes);\n       if (volumeList.remove(target)) {\n         if (volumes.compareAndSet(curVolumes,\n             volumeList.toArray(new FsVolumeImpl[volumeList.size()]))) {\n+          try {\n+            target.closeAndWait();\n+          } catch (IOException e) {\n+            FsDatasetImpl.LOG.warn(\n+                \"Error occurs when waiting volume to close: \" + target, e);\n+          }\n           target.shutdown();\n           FsDatasetImpl.LOG.info(\"Removed volume: \" + target);\n           break;\n         } else {\n           if (FsDatasetImpl.LOG.isDebugEnabled()) {\n             FsDatasetImpl.LOG.debug(\n                 \"The volume list has been changed concurrently, \" +\n                 \"retry to remove volume: \" + target);\n           }\n         }\n       } else {\n         if (FsDatasetImpl.LOG.isDebugEnabled()) {\n           FsDatasetImpl.LOG.debug(\"Volume \" + target +\n               \" does not exist or is removed by others.\");\n         }\n         break;\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void removeVolume(FsVolumeImpl target) {\n    while (true) {\n      final FsVolumeImpl[] curVolumes \u003d volumes.get();\n      final List\u003cFsVolumeImpl\u003e volumeList \u003d Lists.newArrayList(curVolumes);\n      if (volumeList.remove(target)) {\n        if (volumes.compareAndSet(curVolumes,\n            volumeList.toArray(new FsVolumeImpl[volumeList.size()]))) {\n          try {\n            target.closeAndWait();\n          } catch (IOException e) {\n            FsDatasetImpl.LOG.warn(\n                \"Error occurs when waiting volume to close: \" + target, e);\n          }\n          target.shutdown();\n          FsDatasetImpl.LOG.info(\"Removed volume: \" + target);\n          break;\n        } else {\n          if (FsDatasetImpl.LOG.isDebugEnabled()) {\n            FsDatasetImpl.LOG.debug(\n                \"The volume list has been changed concurrently, \" +\n                \"retry to remove volume: \" + target);\n          }\n        }\n      } else {\n        if (FsDatasetImpl.LOG.isDebugEnabled()) {\n          FsDatasetImpl.LOG.debug(\"Volume \" + target +\n              \" does not exist or is removed by others.\");\n        }\n        break;\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsVolumeList.java",
      "extendedDetails": {}
    },
    "3b173d95171d01ab55042b1162569d1cf14a8d43": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-7531. Improve the concurrent access on FsVolumeList (Lei Xu via Colin P. McCabe)\n",
      "commitDate": "17/12/14 4:41 PM",
      "commitName": "3b173d95171d01ab55042b1162569d1cf14a8d43",
      "commitAuthor": "Colin Patrick Mccabe",
      "diff": "@@ -0,0 +1,26 @@\n+  private void removeVolume(FsVolumeImpl target) {\n+    while (true) {\n+      final FsVolumeImpl[] curVolumes \u003d volumes.get();\n+      final List\u003cFsVolumeImpl\u003e volumeList \u003d Lists.newArrayList(curVolumes);\n+      if (volumeList.remove(target)) {\n+        if (volumes.compareAndSet(curVolumes,\n+            volumeList.toArray(new FsVolumeImpl[volumeList.size()]))) {\n+          target.shutdown();\n+          FsDatasetImpl.LOG.info(\"Removed volume: \" + target);\n+          break;\n+        } else {\n+          if (FsDatasetImpl.LOG.isDebugEnabled()) {\n+            FsDatasetImpl.LOG.debug(\n+                \"The volume list has been changed concurrently, \" +\n+                \"retry to remove volume: \" + target);\n+          }\n+        }\n+      } else {\n+        if (FsDatasetImpl.LOG.isDebugEnabled()) {\n+          FsDatasetImpl.LOG.debug(\"Volume \" + target +\n+              \" does not exist or is removed by others.\");\n+        }\n+        break;\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void removeVolume(FsVolumeImpl target) {\n    while (true) {\n      final FsVolumeImpl[] curVolumes \u003d volumes.get();\n      final List\u003cFsVolumeImpl\u003e volumeList \u003d Lists.newArrayList(curVolumes);\n      if (volumeList.remove(target)) {\n        if (volumes.compareAndSet(curVolumes,\n            volumeList.toArray(new FsVolumeImpl[volumeList.size()]))) {\n          target.shutdown();\n          FsDatasetImpl.LOG.info(\"Removed volume: \" + target);\n          break;\n        } else {\n          if (FsDatasetImpl.LOG.isDebugEnabled()) {\n            FsDatasetImpl.LOG.debug(\n                \"The volume list has been changed concurrently, \" +\n                \"retry to remove volume: \" + target);\n          }\n        }\n      } else {\n        if (FsDatasetImpl.LOG.isDebugEnabled()) {\n          FsDatasetImpl.LOG.debug(\"Volume \" + target +\n              \" does not exist or is removed by others.\");\n        }\n        break;\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsVolumeList.java"
    }
  }
}