{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "LocalContainerLauncher.java",
  "functionName": "runSubtask",
  "functionId": "runSubtask___task-org.apache.hadoop.mapred.Task__taskType-TaskType(modifiers-final)__attemptID-TaskAttemptId__numMapTasks-int(modifiers-final)__renameOutputs-boolean__localMapFiles-Map__TaskAttemptID,MapOutputFile__",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/LocalContainerLauncher.java",
  "functionStartLine": 392,
  "functionEndLine": 517,
  "numCommitsSeen": 41,
  "timeTaken": 8925,
  "changeHistory": [
    "a37e7f0ad8b68c7ed16c242bedf62f4cde48d6fd",
    "453d48bdfbb67ed3e66c33c4aef239c3d7bdd3bc",
    "6b710a42e00acca405e085724c89cda016cf7442",
    "549bcc2c02983086ee6694982d5f3503f5f4517f",
    "3d95049f79fe7edb92dd6d20c3a60ccdc46c4b0e",
    "27e8c86999bc6a972a99216060b11ef35b7de858",
    "905b17876c44634545a68300ff2f2d73fb86d3b7",
    "b7ae5a6cb7b2d3e3112ac53007e984caeb07de58",
    "42e93829e5310f3cbd905384cd0529f8fffa887f",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517"
  ],
  "changeHistoryShort": {
    "a37e7f0ad8b68c7ed16c242bedf62f4cde48d6fd": "Ybodychange",
    "453d48bdfbb67ed3e66c33c4aef239c3d7bdd3bc": "Ybodychange",
    "6b710a42e00acca405e085724c89cda016cf7442": "Ybodychange",
    "549bcc2c02983086ee6694982d5f3503f5f4517f": "Ybodychange",
    "3d95049f79fe7edb92dd6d20c3a60ccdc46c4b0e": "Ymultichange(Yparameterchange,Ybodychange)",
    "27e8c86999bc6a972a99216060b11ef35b7de858": "Ybodychange",
    "905b17876c44634545a68300ff2f2d73fb86d3b7": "Ybodychange",
    "b7ae5a6cb7b2d3e3112ac53007e984caeb07de58": "Ybodychange",
    "42e93829e5310f3cbd905384cd0529f8fffa887f": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yintroduced"
  },
  "changeHistoryDetails": {
    "a37e7f0ad8b68c7ed16c242bedf62f4cde48d6fd": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-7022. Fast fail rogue jobs based on task scratch dir size. Contributed by Johan Gustavsson\n",
      "commitDate": "26/01/18 12:36 PM",
      "commitName": "a37e7f0ad8b68c7ed16c242bedf62f4cde48d6fd",
      "commitAuthor": "Jason Lowe",
      "commitDateOld": "02/10/17 8:14 PM",
      "commitNameOld": "453d48bdfbb67ed3e66c33c4aef239c3d7bdd3bc",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 115.72,
      "commitsBetweenForRepo": 791,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,126 +1,126 @@\n     private void runSubtask(org.apache.hadoop.mapred.Task task,\n                             final TaskType taskType,\n                             TaskAttemptId attemptID,\n                             final int numMapTasks,\n                             boolean renameOutputs,\n                             Map\u003cTaskAttemptID, MapOutputFile\u003e localMapFiles)\n     throws RuntimeException, IOException {\n       org.apache.hadoop.mapred.TaskAttemptID classicAttemptID \u003d\n           TypeConverter.fromYarn(attemptID);\n \n       try {\n         JobConf conf \u003d new JobConf(getConfig());\n         conf.set(JobContext.TASK_ID, task.getTaskID().toString());\n         conf.set(JobContext.TASK_ATTEMPT_ID, classicAttemptID.toString());\n         conf.setBoolean(JobContext.TASK_ISMAP, (taskType \u003d\u003d TaskType.MAP));\n         conf.setInt(JobContext.TASK_PARTITION, task.getPartition());\n         conf.set(JobContext.ID, task.getJobID().toString());\n \n         // Use the AM\u0027s local dir env to generate the intermediate step \n         // output files\n         String[] localSysDirs \u003d StringUtils.getTrimmedStrings(\n             System.getenv(Environment.LOCAL_DIRS.name()));\n         conf.setStrings(MRConfig.LOCAL_DIR, localSysDirs);\n         LOG.info(MRConfig.LOCAL_DIR + \" for uber task: \"\n             + conf.get(MRConfig.LOCAL_DIR));\n \n         // mark this as an uberized subtask so it can set task counter\n         // (longer-term/FIXME:  could redefine as job counter and send\n         // \"JobCounterEvent\" to JobImpl on [successful] completion of subtask;\n         // will need new Job state-machine transition and JobImpl jobCounters\n         // map to handle)\n         conf.setBoolean(\"mapreduce.task.uberized\", true);\n \n         // Check and handle Encrypted spill key\n         task.setEncryptedSpillKey(encryptedSpillKey);\n         YarnChild.setEncryptedSpillKeyIfRequired(task);\n \n         // META-FIXME: do we want the extra sanity-checking (doneWithMaps,\n         // etc.), or just assume/hope the state machine(s) and uber-AM work\n         // as expected?\n         if (taskType \u003d\u003d TaskType.MAP) {\n           if (doneWithMaps) {\n             LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a map task (\"\n                       + attemptID + \"), but should be finished with maps\");\n             throw new RuntimeException();\n           }\n \n           MapTask map \u003d (MapTask)task;\n           map.setConf(conf);\n \n           map.run(conf, umbilical);\n \n           if (renameOutputs) {\n             MapOutputFile renamed \u003d renameMapOutputForReduce(conf, attemptID,\n                 map.getMapOutputFile());\n             localMapFiles.put(classicAttemptID, renamed);\n           }\n           relocalize();\n \n           if (++finishedSubMaps \u003d\u003d numMapTasks) {\n             doneWithMaps \u003d true;\n           }\n \n         } else /* TaskType.REDUCE */ {\n \n           if (!doneWithMaps) {\n             // check if event-queue empty?  whole idea of counting maps vs. \n             // checking event queue is a tad wacky...but could enforce ordering\n             // (assuming no \"lost events\") at LocalMRAppMaster [CURRENT BUG(?): \n             // doesn\u0027t send reduce event until maps all done]\n             LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a reduce task (\"\n                       + attemptID + \"), but not yet finished with maps\");\n             throw new RuntimeException();\n           }\n \n           // a.k.a. \"mapreduce.jobtracker.address\" in LocalJobRunner:\n           // set framework name to local to make task local\n           conf.set(MRConfig.FRAMEWORK_NAME, MRConfig.LOCAL_FRAMEWORK_NAME);\n           conf.set(MRConfig.MASTER_ADDRESS, \"local\");  // bypass shuffle\n \n           ReduceTask reduce \u003d (ReduceTask)task;\n           reduce.setLocalMapFiles(localMapFiles);\n           reduce.setConf(conf);          \n \n           reduce.run(conf, umbilical);\n           relocalize();\n         }\n \n       } catch (FSError e) {\n         LOG.error(\"FSError from child\", e);\n         // umbilical:  MRAppMaster creates (taskAttemptListener), passes to us\n         if (!ShutdownHookManager.get().isShutdownInProgress()) {\n           umbilical.fsError(classicAttemptID, e.getMessage());\n         }\n         throw new RuntimeException();\n \n       } catch (Exception exception) {\n         LOG.warn(\"Exception running local (uberized) \u0027child\u0027 : \"\n             + StringUtils.stringifyException(exception));\n         try {\n           if (task !\u003d null) {\n             // do cleanup for the task\n             task.taskCleanup(umbilical);\n           }\n         } catch (Exception e) {\n           LOG.info(\"Exception cleaning up: \"\n               + StringUtils.stringifyException(e));\n         }\n         // Report back any failures, for diagnostic purposes\n         umbilical.reportDiagnosticInfo(classicAttemptID, \n             StringUtils.stringifyException(exception));\n         throw new RuntimeException();\n \n       } catch (Throwable throwable) {\n         LOG.error(\"Error running local (uberized) \u0027child\u0027 : \"\n             + StringUtils.stringifyException(throwable));\n         if (!ShutdownHookManager.get().isShutdownInProgress()) {\n           Throwable tCause \u003d throwable.getCause();\n           String cause \u003d\n               (tCause \u003d\u003d null) ? throwable.getMessage() : StringUtils\n                   .stringifyException(tCause);\n-          umbilical.fatalError(classicAttemptID, cause);\n+          umbilical.fatalError(classicAttemptID, cause, false);\n         }\n         throw new RuntimeException();\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void runSubtask(org.apache.hadoop.mapred.Task task,\n                            final TaskType taskType,\n                            TaskAttemptId attemptID,\n                            final int numMapTasks,\n                            boolean renameOutputs,\n                            Map\u003cTaskAttemptID, MapOutputFile\u003e localMapFiles)\n    throws RuntimeException, IOException {\n      org.apache.hadoop.mapred.TaskAttemptID classicAttemptID \u003d\n          TypeConverter.fromYarn(attemptID);\n\n      try {\n        JobConf conf \u003d new JobConf(getConfig());\n        conf.set(JobContext.TASK_ID, task.getTaskID().toString());\n        conf.set(JobContext.TASK_ATTEMPT_ID, classicAttemptID.toString());\n        conf.setBoolean(JobContext.TASK_ISMAP, (taskType \u003d\u003d TaskType.MAP));\n        conf.setInt(JobContext.TASK_PARTITION, task.getPartition());\n        conf.set(JobContext.ID, task.getJobID().toString());\n\n        // Use the AM\u0027s local dir env to generate the intermediate step \n        // output files\n        String[] localSysDirs \u003d StringUtils.getTrimmedStrings(\n            System.getenv(Environment.LOCAL_DIRS.name()));\n        conf.setStrings(MRConfig.LOCAL_DIR, localSysDirs);\n        LOG.info(MRConfig.LOCAL_DIR + \" for uber task: \"\n            + conf.get(MRConfig.LOCAL_DIR));\n\n        // mark this as an uberized subtask so it can set task counter\n        // (longer-term/FIXME:  could redefine as job counter and send\n        // \"JobCounterEvent\" to JobImpl on [successful] completion of subtask;\n        // will need new Job state-machine transition and JobImpl jobCounters\n        // map to handle)\n        conf.setBoolean(\"mapreduce.task.uberized\", true);\n\n        // Check and handle Encrypted spill key\n        task.setEncryptedSpillKey(encryptedSpillKey);\n        YarnChild.setEncryptedSpillKeyIfRequired(task);\n\n        // META-FIXME: do we want the extra sanity-checking (doneWithMaps,\n        // etc.), or just assume/hope the state machine(s) and uber-AM work\n        // as expected?\n        if (taskType \u003d\u003d TaskType.MAP) {\n          if (doneWithMaps) {\n            LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a map task (\"\n                      + attemptID + \"), but should be finished with maps\");\n            throw new RuntimeException();\n          }\n\n          MapTask map \u003d (MapTask)task;\n          map.setConf(conf);\n\n          map.run(conf, umbilical);\n\n          if (renameOutputs) {\n            MapOutputFile renamed \u003d renameMapOutputForReduce(conf, attemptID,\n                map.getMapOutputFile());\n            localMapFiles.put(classicAttemptID, renamed);\n          }\n          relocalize();\n\n          if (++finishedSubMaps \u003d\u003d numMapTasks) {\n            doneWithMaps \u003d true;\n          }\n\n        } else /* TaskType.REDUCE */ {\n\n          if (!doneWithMaps) {\n            // check if event-queue empty?  whole idea of counting maps vs. \n            // checking event queue is a tad wacky...but could enforce ordering\n            // (assuming no \"lost events\") at LocalMRAppMaster [CURRENT BUG(?): \n            // doesn\u0027t send reduce event until maps all done]\n            LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a reduce task (\"\n                      + attemptID + \"), but not yet finished with maps\");\n            throw new RuntimeException();\n          }\n\n          // a.k.a. \"mapreduce.jobtracker.address\" in LocalJobRunner:\n          // set framework name to local to make task local\n          conf.set(MRConfig.FRAMEWORK_NAME, MRConfig.LOCAL_FRAMEWORK_NAME);\n          conf.set(MRConfig.MASTER_ADDRESS, \"local\");  // bypass shuffle\n\n          ReduceTask reduce \u003d (ReduceTask)task;\n          reduce.setLocalMapFiles(localMapFiles);\n          reduce.setConf(conf);          \n\n          reduce.run(conf, umbilical);\n          relocalize();\n        }\n\n      } catch (FSError e) {\n        LOG.error(\"FSError from child\", e);\n        // umbilical:  MRAppMaster creates (taskAttemptListener), passes to us\n        if (!ShutdownHookManager.get().isShutdownInProgress()) {\n          umbilical.fsError(classicAttemptID, e.getMessage());\n        }\n        throw new RuntimeException();\n\n      } catch (Exception exception) {\n        LOG.warn(\"Exception running local (uberized) \u0027child\u0027 : \"\n            + StringUtils.stringifyException(exception));\n        try {\n          if (task !\u003d null) {\n            // do cleanup for the task\n            task.taskCleanup(umbilical);\n          }\n        } catch (Exception e) {\n          LOG.info(\"Exception cleaning up: \"\n              + StringUtils.stringifyException(e));\n        }\n        // Report back any failures, for diagnostic purposes\n        umbilical.reportDiagnosticInfo(classicAttemptID, \n            StringUtils.stringifyException(exception));\n        throw new RuntimeException();\n\n      } catch (Throwable throwable) {\n        LOG.error(\"Error running local (uberized) \u0027child\u0027 : \"\n            + StringUtils.stringifyException(throwable));\n        if (!ShutdownHookManager.get().isShutdownInProgress()) {\n          Throwable tCause \u003d throwable.getCause();\n          String cause \u003d\n              (tCause \u003d\u003d null) ? throwable.getMessage() : StringUtils\n                  .stringifyException(tCause);\n          umbilical.fatalError(classicAttemptID, cause, false);\n        }\n        throw new RuntimeException();\n      }\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/LocalContainerLauncher.java",
      "extendedDetails": {}
    },
    "453d48bdfbb67ed3e66c33c4aef239c3d7bdd3bc": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6971. Moving logging APIs over to slf4j in hadoop-mapreduce-client-app. Contributed by Jinjiang Ling.\n",
      "commitDate": "02/10/17 8:14 PM",
      "commitName": "453d48bdfbb67ed3e66c33c4aef239c3d7bdd3bc",
      "commitAuthor": "Akira Ajisaka",
      "commitDateOld": "26/04/17 11:45 PM",
      "commitNameOld": "3ed3062fe3979ff55a411b730a8eee2b2c96d6b3",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 158.85,
      "commitsBetweenForRepo": 1073,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,126 +1,126 @@\n     private void runSubtask(org.apache.hadoop.mapred.Task task,\n                             final TaskType taskType,\n                             TaskAttemptId attemptID,\n                             final int numMapTasks,\n                             boolean renameOutputs,\n                             Map\u003cTaskAttemptID, MapOutputFile\u003e localMapFiles)\n     throws RuntimeException, IOException {\n       org.apache.hadoop.mapred.TaskAttemptID classicAttemptID \u003d\n           TypeConverter.fromYarn(attemptID);\n \n       try {\n         JobConf conf \u003d new JobConf(getConfig());\n         conf.set(JobContext.TASK_ID, task.getTaskID().toString());\n         conf.set(JobContext.TASK_ATTEMPT_ID, classicAttemptID.toString());\n         conf.setBoolean(JobContext.TASK_ISMAP, (taskType \u003d\u003d TaskType.MAP));\n         conf.setInt(JobContext.TASK_PARTITION, task.getPartition());\n         conf.set(JobContext.ID, task.getJobID().toString());\n \n         // Use the AM\u0027s local dir env to generate the intermediate step \n         // output files\n         String[] localSysDirs \u003d StringUtils.getTrimmedStrings(\n             System.getenv(Environment.LOCAL_DIRS.name()));\n         conf.setStrings(MRConfig.LOCAL_DIR, localSysDirs);\n         LOG.info(MRConfig.LOCAL_DIR + \" for uber task: \"\n             + conf.get(MRConfig.LOCAL_DIR));\n \n         // mark this as an uberized subtask so it can set task counter\n         // (longer-term/FIXME:  could redefine as job counter and send\n         // \"JobCounterEvent\" to JobImpl on [successful] completion of subtask;\n         // will need new Job state-machine transition and JobImpl jobCounters\n         // map to handle)\n         conf.setBoolean(\"mapreduce.task.uberized\", true);\n \n         // Check and handle Encrypted spill key\n         task.setEncryptedSpillKey(encryptedSpillKey);\n         YarnChild.setEncryptedSpillKeyIfRequired(task);\n \n         // META-FIXME: do we want the extra sanity-checking (doneWithMaps,\n         // etc.), or just assume/hope the state machine(s) and uber-AM work\n         // as expected?\n         if (taskType \u003d\u003d TaskType.MAP) {\n           if (doneWithMaps) {\n             LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a map task (\"\n                       + attemptID + \"), but should be finished with maps\");\n             throw new RuntimeException();\n           }\n \n           MapTask map \u003d (MapTask)task;\n           map.setConf(conf);\n \n           map.run(conf, umbilical);\n \n           if (renameOutputs) {\n             MapOutputFile renamed \u003d renameMapOutputForReduce(conf, attemptID,\n                 map.getMapOutputFile());\n             localMapFiles.put(classicAttemptID, renamed);\n           }\n           relocalize();\n \n           if (++finishedSubMaps \u003d\u003d numMapTasks) {\n             doneWithMaps \u003d true;\n           }\n \n         } else /* TaskType.REDUCE */ {\n \n           if (!doneWithMaps) {\n             // check if event-queue empty?  whole idea of counting maps vs. \n             // checking event queue is a tad wacky...but could enforce ordering\n             // (assuming no \"lost events\") at LocalMRAppMaster [CURRENT BUG(?): \n             // doesn\u0027t send reduce event until maps all done]\n             LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a reduce task (\"\n                       + attemptID + \"), but not yet finished with maps\");\n             throw new RuntimeException();\n           }\n \n           // a.k.a. \"mapreduce.jobtracker.address\" in LocalJobRunner:\n           // set framework name to local to make task local\n           conf.set(MRConfig.FRAMEWORK_NAME, MRConfig.LOCAL_FRAMEWORK_NAME);\n           conf.set(MRConfig.MASTER_ADDRESS, \"local\");  // bypass shuffle\n \n           ReduceTask reduce \u003d (ReduceTask)task;\n           reduce.setLocalMapFiles(localMapFiles);\n           reduce.setConf(conf);          \n \n           reduce.run(conf, umbilical);\n           relocalize();\n         }\n \n       } catch (FSError e) {\n-        LOG.fatal(\"FSError from child\", e);\n+        LOG.error(\"FSError from child\", e);\n         // umbilical:  MRAppMaster creates (taskAttemptListener), passes to us\n         if (!ShutdownHookManager.get().isShutdownInProgress()) {\n           umbilical.fsError(classicAttemptID, e.getMessage());\n         }\n         throw new RuntimeException();\n \n       } catch (Exception exception) {\n         LOG.warn(\"Exception running local (uberized) \u0027child\u0027 : \"\n             + StringUtils.stringifyException(exception));\n         try {\n           if (task !\u003d null) {\n             // do cleanup for the task\n             task.taskCleanup(umbilical);\n           }\n         } catch (Exception e) {\n           LOG.info(\"Exception cleaning up: \"\n               + StringUtils.stringifyException(e));\n         }\n         // Report back any failures, for diagnostic purposes\n         umbilical.reportDiagnosticInfo(classicAttemptID, \n             StringUtils.stringifyException(exception));\n         throw new RuntimeException();\n \n       } catch (Throwable throwable) {\n-        LOG.fatal(\"Error running local (uberized) \u0027child\u0027 : \"\n+        LOG.error(\"Error running local (uberized) \u0027child\u0027 : \"\n             + StringUtils.stringifyException(throwable));\n         if (!ShutdownHookManager.get().isShutdownInProgress()) {\n           Throwable tCause \u003d throwable.getCause();\n           String cause \u003d\n               (tCause \u003d\u003d null) ? throwable.getMessage() : StringUtils\n                   .stringifyException(tCause);\n           umbilical.fatalError(classicAttemptID, cause);\n         }\n         throw new RuntimeException();\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void runSubtask(org.apache.hadoop.mapred.Task task,\n                            final TaskType taskType,\n                            TaskAttemptId attemptID,\n                            final int numMapTasks,\n                            boolean renameOutputs,\n                            Map\u003cTaskAttemptID, MapOutputFile\u003e localMapFiles)\n    throws RuntimeException, IOException {\n      org.apache.hadoop.mapred.TaskAttemptID classicAttemptID \u003d\n          TypeConverter.fromYarn(attemptID);\n\n      try {\n        JobConf conf \u003d new JobConf(getConfig());\n        conf.set(JobContext.TASK_ID, task.getTaskID().toString());\n        conf.set(JobContext.TASK_ATTEMPT_ID, classicAttemptID.toString());\n        conf.setBoolean(JobContext.TASK_ISMAP, (taskType \u003d\u003d TaskType.MAP));\n        conf.setInt(JobContext.TASK_PARTITION, task.getPartition());\n        conf.set(JobContext.ID, task.getJobID().toString());\n\n        // Use the AM\u0027s local dir env to generate the intermediate step \n        // output files\n        String[] localSysDirs \u003d StringUtils.getTrimmedStrings(\n            System.getenv(Environment.LOCAL_DIRS.name()));\n        conf.setStrings(MRConfig.LOCAL_DIR, localSysDirs);\n        LOG.info(MRConfig.LOCAL_DIR + \" for uber task: \"\n            + conf.get(MRConfig.LOCAL_DIR));\n\n        // mark this as an uberized subtask so it can set task counter\n        // (longer-term/FIXME:  could redefine as job counter and send\n        // \"JobCounterEvent\" to JobImpl on [successful] completion of subtask;\n        // will need new Job state-machine transition and JobImpl jobCounters\n        // map to handle)\n        conf.setBoolean(\"mapreduce.task.uberized\", true);\n\n        // Check and handle Encrypted spill key\n        task.setEncryptedSpillKey(encryptedSpillKey);\n        YarnChild.setEncryptedSpillKeyIfRequired(task);\n\n        // META-FIXME: do we want the extra sanity-checking (doneWithMaps,\n        // etc.), or just assume/hope the state machine(s) and uber-AM work\n        // as expected?\n        if (taskType \u003d\u003d TaskType.MAP) {\n          if (doneWithMaps) {\n            LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a map task (\"\n                      + attemptID + \"), but should be finished with maps\");\n            throw new RuntimeException();\n          }\n\n          MapTask map \u003d (MapTask)task;\n          map.setConf(conf);\n\n          map.run(conf, umbilical);\n\n          if (renameOutputs) {\n            MapOutputFile renamed \u003d renameMapOutputForReduce(conf, attemptID,\n                map.getMapOutputFile());\n            localMapFiles.put(classicAttemptID, renamed);\n          }\n          relocalize();\n\n          if (++finishedSubMaps \u003d\u003d numMapTasks) {\n            doneWithMaps \u003d true;\n          }\n\n        } else /* TaskType.REDUCE */ {\n\n          if (!doneWithMaps) {\n            // check if event-queue empty?  whole idea of counting maps vs. \n            // checking event queue is a tad wacky...but could enforce ordering\n            // (assuming no \"lost events\") at LocalMRAppMaster [CURRENT BUG(?): \n            // doesn\u0027t send reduce event until maps all done]\n            LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a reduce task (\"\n                      + attemptID + \"), but not yet finished with maps\");\n            throw new RuntimeException();\n          }\n\n          // a.k.a. \"mapreduce.jobtracker.address\" in LocalJobRunner:\n          // set framework name to local to make task local\n          conf.set(MRConfig.FRAMEWORK_NAME, MRConfig.LOCAL_FRAMEWORK_NAME);\n          conf.set(MRConfig.MASTER_ADDRESS, \"local\");  // bypass shuffle\n\n          ReduceTask reduce \u003d (ReduceTask)task;\n          reduce.setLocalMapFiles(localMapFiles);\n          reduce.setConf(conf);          \n\n          reduce.run(conf, umbilical);\n          relocalize();\n        }\n\n      } catch (FSError e) {\n        LOG.error(\"FSError from child\", e);\n        // umbilical:  MRAppMaster creates (taskAttemptListener), passes to us\n        if (!ShutdownHookManager.get().isShutdownInProgress()) {\n          umbilical.fsError(classicAttemptID, e.getMessage());\n        }\n        throw new RuntimeException();\n\n      } catch (Exception exception) {\n        LOG.warn(\"Exception running local (uberized) \u0027child\u0027 : \"\n            + StringUtils.stringifyException(exception));\n        try {\n          if (task !\u003d null) {\n            // do cleanup for the task\n            task.taskCleanup(umbilical);\n          }\n        } catch (Exception e) {\n          LOG.info(\"Exception cleaning up: \"\n              + StringUtils.stringifyException(e));\n        }\n        // Report back any failures, for diagnostic purposes\n        umbilical.reportDiagnosticInfo(classicAttemptID, \n            StringUtils.stringifyException(exception));\n        throw new RuntimeException();\n\n      } catch (Throwable throwable) {\n        LOG.error(\"Error running local (uberized) \u0027child\u0027 : \"\n            + StringUtils.stringifyException(throwable));\n        if (!ShutdownHookManager.get().isShutdownInProgress()) {\n          Throwable tCause \u003d throwable.getCause();\n          String cause \u003d\n              (tCause \u003d\u003d null) ? throwable.getMessage() : StringUtils\n                  .stringifyException(tCause);\n          umbilical.fatalError(classicAttemptID, cause);\n        }\n        throw new RuntimeException();\n      }\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/LocalContainerLauncher.java",
      "extendedDetails": {}
    },
    "6b710a42e00acca405e085724c89cda016cf7442": {
      "type": "Ybodychange",
      "commitMessage": "Fixing MR intermediate spills. Contributed by Arun Suresh.\n",
      "commitDate": "14/05/15 4:07 PM",
      "commitName": "6b710a42e00acca405e085724c89cda016cf7442",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "11/05/15 3:37 PM",
      "commitNameOld": "444836b3dcd3ee28238af7b5e753d644e8095788",
      "commitAuthorOld": "Jason Lowe",
      "daysBetweenCommits": 3.02,
      "commitsBetweenForRepo": 38,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,122 +1,126 @@\n     private void runSubtask(org.apache.hadoop.mapred.Task task,\n                             final TaskType taskType,\n                             TaskAttemptId attemptID,\n                             final int numMapTasks,\n                             boolean renameOutputs,\n                             Map\u003cTaskAttemptID, MapOutputFile\u003e localMapFiles)\n     throws RuntimeException, IOException {\n       org.apache.hadoop.mapred.TaskAttemptID classicAttemptID \u003d\n           TypeConverter.fromYarn(attemptID);\n \n       try {\n         JobConf conf \u003d new JobConf(getConfig());\n         conf.set(JobContext.TASK_ID, task.getTaskID().toString());\n         conf.set(JobContext.TASK_ATTEMPT_ID, classicAttemptID.toString());\n         conf.setBoolean(JobContext.TASK_ISMAP, (taskType \u003d\u003d TaskType.MAP));\n         conf.setInt(JobContext.TASK_PARTITION, task.getPartition());\n         conf.set(JobContext.ID, task.getJobID().toString());\n \n         // Use the AM\u0027s local dir env to generate the intermediate step \n         // output files\n         String[] localSysDirs \u003d StringUtils.getTrimmedStrings(\n             System.getenv(Environment.LOCAL_DIRS.name()));\n         conf.setStrings(MRConfig.LOCAL_DIR, localSysDirs);\n         LOG.info(MRConfig.LOCAL_DIR + \" for uber task: \"\n             + conf.get(MRConfig.LOCAL_DIR));\n \n         // mark this as an uberized subtask so it can set task counter\n         // (longer-term/FIXME:  could redefine as job counter and send\n         // \"JobCounterEvent\" to JobImpl on [successful] completion of subtask;\n         // will need new Job state-machine transition and JobImpl jobCounters\n         // map to handle)\n         conf.setBoolean(\"mapreduce.task.uberized\", true);\n \n+        // Check and handle Encrypted spill key\n+        task.setEncryptedSpillKey(encryptedSpillKey);\n+        YarnChild.setEncryptedSpillKeyIfRequired(task);\n+\n         // META-FIXME: do we want the extra sanity-checking (doneWithMaps,\n         // etc.), or just assume/hope the state machine(s) and uber-AM work\n         // as expected?\n         if (taskType \u003d\u003d TaskType.MAP) {\n           if (doneWithMaps) {\n             LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a map task (\"\n                       + attemptID + \"), but should be finished with maps\");\n             throw new RuntimeException();\n           }\n \n           MapTask map \u003d (MapTask)task;\n           map.setConf(conf);\n \n           map.run(conf, umbilical);\n \n           if (renameOutputs) {\n             MapOutputFile renamed \u003d renameMapOutputForReduce(conf, attemptID,\n                 map.getMapOutputFile());\n             localMapFiles.put(classicAttemptID, renamed);\n           }\n           relocalize();\n \n           if (++finishedSubMaps \u003d\u003d numMapTasks) {\n             doneWithMaps \u003d true;\n           }\n \n         } else /* TaskType.REDUCE */ {\n \n           if (!doneWithMaps) {\n             // check if event-queue empty?  whole idea of counting maps vs. \n             // checking event queue is a tad wacky...but could enforce ordering\n             // (assuming no \"lost events\") at LocalMRAppMaster [CURRENT BUG(?): \n             // doesn\u0027t send reduce event until maps all done]\n             LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a reduce task (\"\n                       + attemptID + \"), but not yet finished with maps\");\n             throw new RuntimeException();\n           }\n \n           // a.k.a. \"mapreduce.jobtracker.address\" in LocalJobRunner:\n           // set framework name to local to make task local\n           conf.set(MRConfig.FRAMEWORK_NAME, MRConfig.LOCAL_FRAMEWORK_NAME);\n           conf.set(MRConfig.MASTER_ADDRESS, \"local\");  // bypass shuffle\n \n           ReduceTask reduce \u003d (ReduceTask)task;\n           reduce.setLocalMapFiles(localMapFiles);\n           reduce.setConf(conf);          \n \n           reduce.run(conf, umbilical);\n           relocalize();\n         }\n \n       } catch (FSError e) {\n         LOG.fatal(\"FSError from child\", e);\n         // umbilical:  MRAppMaster creates (taskAttemptListener), passes to us\n         if (!ShutdownHookManager.get().isShutdownInProgress()) {\n           umbilical.fsError(classicAttemptID, e.getMessage());\n         }\n         throw new RuntimeException();\n \n       } catch (Exception exception) {\n         LOG.warn(\"Exception running local (uberized) \u0027child\u0027 : \"\n             + StringUtils.stringifyException(exception));\n         try {\n           if (task !\u003d null) {\n             // do cleanup for the task\n             task.taskCleanup(umbilical);\n           }\n         } catch (Exception e) {\n           LOG.info(\"Exception cleaning up: \"\n               + StringUtils.stringifyException(e));\n         }\n         // Report back any failures, for diagnostic purposes\n         umbilical.reportDiagnosticInfo(classicAttemptID, \n             StringUtils.stringifyException(exception));\n         throw new RuntimeException();\n \n       } catch (Throwable throwable) {\n         LOG.fatal(\"Error running local (uberized) \u0027child\u0027 : \"\n             + StringUtils.stringifyException(throwable));\n         if (!ShutdownHookManager.get().isShutdownInProgress()) {\n           Throwable tCause \u003d throwable.getCause();\n           String cause \u003d\n               (tCause \u003d\u003d null) ? throwable.getMessage() : StringUtils\n                   .stringifyException(tCause);\n           umbilical.fatalError(classicAttemptID, cause);\n         }\n         throw new RuntimeException();\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void runSubtask(org.apache.hadoop.mapred.Task task,\n                            final TaskType taskType,\n                            TaskAttemptId attemptID,\n                            final int numMapTasks,\n                            boolean renameOutputs,\n                            Map\u003cTaskAttemptID, MapOutputFile\u003e localMapFiles)\n    throws RuntimeException, IOException {\n      org.apache.hadoop.mapred.TaskAttemptID classicAttemptID \u003d\n          TypeConverter.fromYarn(attemptID);\n\n      try {\n        JobConf conf \u003d new JobConf(getConfig());\n        conf.set(JobContext.TASK_ID, task.getTaskID().toString());\n        conf.set(JobContext.TASK_ATTEMPT_ID, classicAttemptID.toString());\n        conf.setBoolean(JobContext.TASK_ISMAP, (taskType \u003d\u003d TaskType.MAP));\n        conf.setInt(JobContext.TASK_PARTITION, task.getPartition());\n        conf.set(JobContext.ID, task.getJobID().toString());\n\n        // Use the AM\u0027s local dir env to generate the intermediate step \n        // output files\n        String[] localSysDirs \u003d StringUtils.getTrimmedStrings(\n            System.getenv(Environment.LOCAL_DIRS.name()));\n        conf.setStrings(MRConfig.LOCAL_DIR, localSysDirs);\n        LOG.info(MRConfig.LOCAL_DIR + \" for uber task: \"\n            + conf.get(MRConfig.LOCAL_DIR));\n\n        // mark this as an uberized subtask so it can set task counter\n        // (longer-term/FIXME:  could redefine as job counter and send\n        // \"JobCounterEvent\" to JobImpl on [successful] completion of subtask;\n        // will need new Job state-machine transition and JobImpl jobCounters\n        // map to handle)\n        conf.setBoolean(\"mapreduce.task.uberized\", true);\n\n        // Check and handle Encrypted spill key\n        task.setEncryptedSpillKey(encryptedSpillKey);\n        YarnChild.setEncryptedSpillKeyIfRequired(task);\n\n        // META-FIXME: do we want the extra sanity-checking (doneWithMaps,\n        // etc.), or just assume/hope the state machine(s) and uber-AM work\n        // as expected?\n        if (taskType \u003d\u003d TaskType.MAP) {\n          if (doneWithMaps) {\n            LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a map task (\"\n                      + attemptID + \"), but should be finished with maps\");\n            throw new RuntimeException();\n          }\n\n          MapTask map \u003d (MapTask)task;\n          map.setConf(conf);\n\n          map.run(conf, umbilical);\n\n          if (renameOutputs) {\n            MapOutputFile renamed \u003d renameMapOutputForReduce(conf, attemptID,\n                map.getMapOutputFile());\n            localMapFiles.put(classicAttemptID, renamed);\n          }\n          relocalize();\n\n          if (++finishedSubMaps \u003d\u003d numMapTasks) {\n            doneWithMaps \u003d true;\n          }\n\n        } else /* TaskType.REDUCE */ {\n\n          if (!doneWithMaps) {\n            // check if event-queue empty?  whole idea of counting maps vs. \n            // checking event queue is a tad wacky...but could enforce ordering\n            // (assuming no \"lost events\") at LocalMRAppMaster [CURRENT BUG(?): \n            // doesn\u0027t send reduce event until maps all done]\n            LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a reduce task (\"\n                      + attemptID + \"), but not yet finished with maps\");\n            throw new RuntimeException();\n          }\n\n          // a.k.a. \"mapreduce.jobtracker.address\" in LocalJobRunner:\n          // set framework name to local to make task local\n          conf.set(MRConfig.FRAMEWORK_NAME, MRConfig.LOCAL_FRAMEWORK_NAME);\n          conf.set(MRConfig.MASTER_ADDRESS, \"local\");  // bypass shuffle\n\n          ReduceTask reduce \u003d (ReduceTask)task;\n          reduce.setLocalMapFiles(localMapFiles);\n          reduce.setConf(conf);          \n\n          reduce.run(conf, umbilical);\n          relocalize();\n        }\n\n      } catch (FSError e) {\n        LOG.fatal(\"FSError from child\", e);\n        // umbilical:  MRAppMaster creates (taskAttemptListener), passes to us\n        if (!ShutdownHookManager.get().isShutdownInProgress()) {\n          umbilical.fsError(classicAttemptID, e.getMessage());\n        }\n        throw new RuntimeException();\n\n      } catch (Exception exception) {\n        LOG.warn(\"Exception running local (uberized) \u0027child\u0027 : \"\n            + StringUtils.stringifyException(exception));\n        try {\n          if (task !\u003d null) {\n            // do cleanup for the task\n            task.taskCleanup(umbilical);\n          }\n        } catch (Exception e) {\n          LOG.info(\"Exception cleaning up: \"\n              + StringUtils.stringifyException(e));\n        }\n        // Report back any failures, for diagnostic purposes\n        umbilical.reportDiagnosticInfo(classicAttemptID, \n            StringUtils.stringifyException(exception));\n        throw new RuntimeException();\n\n      } catch (Throwable throwable) {\n        LOG.fatal(\"Error running local (uberized) \u0027child\u0027 : \"\n            + StringUtils.stringifyException(throwable));\n        if (!ShutdownHookManager.get().isShutdownInProgress()) {\n          Throwable tCause \u003d throwable.getCause();\n          String cause \u003d\n              (tCause \u003d\u003d null) ? throwable.getMessage() : StringUtils\n                  .stringifyException(tCause);\n          umbilical.fatalError(classicAttemptID, cause);\n        }\n        throw new RuntimeException();\n      }\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/LocalContainerLauncher.java",
      "extendedDetails": {}
    },
    "549bcc2c02983086ee6694982d5f3503f5f4517f": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6002. Made MR task avoid reporting error to AM when the task process is shutting down. Contributed by Wangda Tan.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1613743 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "26/07/14 6:37 PM",
      "commitName": "549bcc2c02983086ee6694982d5f3503f5f4517f",
      "commitAuthor": "Zhijie Shen",
      "commitDateOld": "16/07/14 2:24 PM",
      "commitNameOld": "43a12f3c0119555eee919e2b12ecb6c836f05934",
      "commitAuthorOld": "Karthik Kambatla",
      "daysBetweenCommits": 10.18,
      "commitsBetweenForRepo": 94,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,118 +1,122 @@\n     private void runSubtask(org.apache.hadoop.mapred.Task task,\n                             final TaskType taskType,\n                             TaskAttemptId attemptID,\n                             final int numMapTasks,\n                             boolean renameOutputs,\n                             Map\u003cTaskAttemptID, MapOutputFile\u003e localMapFiles)\n     throws RuntimeException, IOException {\n       org.apache.hadoop.mapred.TaskAttemptID classicAttemptID \u003d\n           TypeConverter.fromYarn(attemptID);\n \n       try {\n         JobConf conf \u003d new JobConf(getConfig());\n         conf.set(JobContext.TASK_ID, task.getTaskID().toString());\n         conf.set(JobContext.TASK_ATTEMPT_ID, classicAttemptID.toString());\n         conf.setBoolean(JobContext.TASK_ISMAP, (taskType \u003d\u003d TaskType.MAP));\n         conf.setInt(JobContext.TASK_PARTITION, task.getPartition());\n         conf.set(JobContext.ID, task.getJobID().toString());\n \n         // Use the AM\u0027s local dir env to generate the intermediate step \n         // output files\n         String[] localSysDirs \u003d StringUtils.getTrimmedStrings(\n             System.getenv(Environment.LOCAL_DIRS.name()));\n         conf.setStrings(MRConfig.LOCAL_DIR, localSysDirs);\n         LOG.info(MRConfig.LOCAL_DIR + \" for uber task: \"\n             + conf.get(MRConfig.LOCAL_DIR));\n \n         // mark this as an uberized subtask so it can set task counter\n         // (longer-term/FIXME:  could redefine as job counter and send\n         // \"JobCounterEvent\" to JobImpl on [successful] completion of subtask;\n         // will need new Job state-machine transition and JobImpl jobCounters\n         // map to handle)\n         conf.setBoolean(\"mapreduce.task.uberized\", true);\n \n         // META-FIXME: do we want the extra sanity-checking (doneWithMaps,\n         // etc.), or just assume/hope the state machine(s) and uber-AM work\n         // as expected?\n         if (taskType \u003d\u003d TaskType.MAP) {\n           if (doneWithMaps) {\n             LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a map task (\"\n                       + attemptID + \"), but should be finished with maps\");\n             throw new RuntimeException();\n           }\n \n           MapTask map \u003d (MapTask)task;\n           map.setConf(conf);\n \n           map.run(conf, umbilical);\n \n           if (renameOutputs) {\n             MapOutputFile renamed \u003d renameMapOutputForReduce(conf, attemptID,\n                 map.getMapOutputFile());\n             localMapFiles.put(classicAttemptID, renamed);\n           }\n           relocalize();\n \n           if (++finishedSubMaps \u003d\u003d numMapTasks) {\n             doneWithMaps \u003d true;\n           }\n \n         } else /* TaskType.REDUCE */ {\n \n           if (!doneWithMaps) {\n             // check if event-queue empty?  whole idea of counting maps vs. \n             // checking event queue is a tad wacky...but could enforce ordering\n             // (assuming no \"lost events\") at LocalMRAppMaster [CURRENT BUG(?): \n             // doesn\u0027t send reduce event until maps all done]\n             LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a reduce task (\"\n                       + attemptID + \"), but not yet finished with maps\");\n             throw new RuntimeException();\n           }\n \n           // a.k.a. \"mapreduce.jobtracker.address\" in LocalJobRunner:\n           // set framework name to local to make task local\n           conf.set(MRConfig.FRAMEWORK_NAME, MRConfig.LOCAL_FRAMEWORK_NAME);\n           conf.set(MRConfig.MASTER_ADDRESS, \"local\");  // bypass shuffle\n \n           ReduceTask reduce \u003d (ReduceTask)task;\n           reduce.setLocalMapFiles(localMapFiles);\n           reduce.setConf(conf);          \n \n           reduce.run(conf, umbilical);\n           relocalize();\n         }\n \n       } catch (FSError e) {\n         LOG.fatal(\"FSError from child\", e);\n         // umbilical:  MRAppMaster creates (taskAttemptListener), passes to us\n-        umbilical.fsError(classicAttemptID, e.getMessage());\n+        if (!ShutdownHookManager.get().isShutdownInProgress()) {\n+          umbilical.fsError(classicAttemptID, e.getMessage());\n+        }\n         throw new RuntimeException();\n \n       } catch (Exception exception) {\n         LOG.warn(\"Exception running local (uberized) \u0027child\u0027 : \"\n             + StringUtils.stringifyException(exception));\n         try {\n           if (task !\u003d null) {\n             // do cleanup for the task\n             task.taskCleanup(umbilical);\n           }\n         } catch (Exception e) {\n           LOG.info(\"Exception cleaning up: \"\n               + StringUtils.stringifyException(e));\n         }\n         // Report back any failures, for diagnostic purposes\n         umbilical.reportDiagnosticInfo(classicAttemptID, \n             StringUtils.stringifyException(exception));\n         throw new RuntimeException();\n \n       } catch (Throwable throwable) {\n         LOG.fatal(\"Error running local (uberized) \u0027child\u0027 : \"\n             + StringUtils.stringifyException(throwable));\n-        Throwable tCause \u003d throwable.getCause();\n-        String cause \u003d (tCause \u003d\u003d null)\n-            ? throwable.getMessage()\n-                : StringUtils.stringifyException(tCause);\n-            umbilical.fatalError(classicAttemptID, cause);\n+        if (!ShutdownHookManager.get().isShutdownInProgress()) {\n+          Throwable tCause \u003d throwable.getCause();\n+          String cause \u003d\n+              (tCause \u003d\u003d null) ? throwable.getMessage() : StringUtils\n+                  .stringifyException(tCause);\n+          umbilical.fatalError(classicAttemptID, cause);\n+        }\n         throw new RuntimeException();\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void runSubtask(org.apache.hadoop.mapred.Task task,\n                            final TaskType taskType,\n                            TaskAttemptId attemptID,\n                            final int numMapTasks,\n                            boolean renameOutputs,\n                            Map\u003cTaskAttemptID, MapOutputFile\u003e localMapFiles)\n    throws RuntimeException, IOException {\n      org.apache.hadoop.mapred.TaskAttemptID classicAttemptID \u003d\n          TypeConverter.fromYarn(attemptID);\n\n      try {\n        JobConf conf \u003d new JobConf(getConfig());\n        conf.set(JobContext.TASK_ID, task.getTaskID().toString());\n        conf.set(JobContext.TASK_ATTEMPT_ID, classicAttemptID.toString());\n        conf.setBoolean(JobContext.TASK_ISMAP, (taskType \u003d\u003d TaskType.MAP));\n        conf.setInt(JobContext.TASK_PARTITION, task.getPartition());\n        conf.set(JobContext.ID, task.getJobID().toString());\n\n        // Use the AM\u0027s local dir env to generate the intermediate step \n        // output files\n        String[] localSysDirs \u003d StringUtils.getTrimmedStrings(\n            System.getenv(Environment.LOCAL_DIRS.name()));\n        conf.setStrings(MRConfig.LOCAL_DIR, localSysDirs);\n        LOG.info(MRConfig.LOCAL_DIR + \" for uber task: \"\n            + conf.get(MRConfig.LOCAL_DIR));\n\n        // mark this as an uberized subtask so it can set task counter\n        // (longer-term/FIXME:  could redefine as job counter and send\n        // \"JobCounterEvent\" to JobImpl on [successful] completion of subtask;\n        // will need new Job state-machine transition and JobImpl jobCounters\n        // map to handle)\n        conf.setBoolean(\"mapreduce.task.uberized\", true);\n\n        // META-FIXME: do we want the extra sanity-checking (doneWithMaps,\n        // etc.), or just assume/hope the state machine(s) and uber-AM work\n        // as expected?\n        if (taskType \u003d\u003d TaskType.MAP) {\n          if (doneWithMaps) {\n            LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a map task (\"\n                      + attemptID + \"), but should be finished with maps\");\n            throw new RuntimeException();\n          }\n\n          MapTask map \u003d (MapTask)task;\n          map.setConf(conf);\n\n          map.run(conf, umbilical);\n\n          if (renameOutputs) {\n            MapOutputFile renamed \u003d renameMapOutputForReduce(conf, attemptID,\n                map.getMapOutputFile());\n            localMapFiles.put(classicAttemptID, renamed);\n          }\n          relocalize();\n\n          if (++finishedSubMaps \u003d\u003d numMapTasks) {\n            doneWithMaps \u003d true;\n          }\n\n        } else /* TaskType.REDUCE */ {\n\n          if (!doneWithMaps) {\n            // check if event-queue empty?  whole idea of counting maps vs. \n            // checking event queue is a tad wacky...but could enforce ordering\n            // (assuming no \"lost events\") at LocalMRAppMaster [CURRENT BUG(?): \n            // doesn\u0027t send reduce event until maps all done]\n            LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a reduce task (\"\n                      + attemptID + \"), but not yet finished with maps\");\n            throw new RuntimeException();\n          }\n\n          // a.k.a. \"mapreduce.jobtracker.address\" in LocalJobRunner:\n          // set framework name to local to make task local\n          conf.set(MRConfig.FRAMEWORK_NAME, MRConfig.LOCAL_FRAMEWORK_NAME);\n          conf.set(MRConfig.MASTER_ADDRESS, \"local\");  // bypass shuffle\n\n          ReduceTask reduce \u003d (ReduceTask)task;\n          reduce.setLocalMapFiles(localMapFiles);\n          reduce.setConf(conf);          \n\n          reduce.run(conf, umbilical);\n          relocalize();\n        }\n\n      } catch (FSError e) {\n        LOG.fatal(\"FSError from child\", e);\n        // umbilical:  MRAppMaster creates (taskAttemptListener), passes to us\n        if (!ShutdownHookManager.get().isShutdownInProgress()) {\n          umbilical.fsError(classicAttemptID, e.getMessage());\n        }\n        throw new RuntimeException();\n\n      } catch (Exception exception) {\n        LOG.warn(\"Exception running local (uberized) \u0027child\u0027 : \"\n            + StringUtils.stringifyException(exception));\n        try {\n          if (task !\u003d null) {\n            // do cleanup for the task\n            task.taskCleanup(umbilical);\n          }\n        } catch (Exception e) {\n          LOG.info(\"Exception cleaning up: \"\n              + StringUtils.stringifyException(e));\n        }\n        // Report back any failures, for diagnostic purposes\n        umbilical.reportDiagnosticInfo(classicAttemptID, \n            StringUtils.stringifyException(exception));\n        throw new RuntimeException();\n\n      } catch (Throwable throwable) {\n        LOG.fatal(\"Error running local (uberized) \u0027child\u0027 : \"\n            + StringUtils.stringifyException(throwable));\n        if (!ShutdownHookManager.get().isShutdownInProgress()) {\n          Throwable tCause \u003d throwable.getCause();\n          String cause \u003d\n              (tCause \u003d\u003d null) ? throwable.getMessage() : StringUtils\n                  .stringifyException(tCause);\n          umbilical.fatalError(classicAttemptID, cause);\n        }\n        throw new RuntimeException();\n      }\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/LocalContainerLauncher.java",
      "extendedDetails": {}
    },
    "3d95049f79fe7edb92dd6d20c3a60ccdc46c4b0e": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "MAPREDUCE-5481. Enable uber jobs to have multiple reducers (Sandy Ryza)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1541844 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/11/13 11:56 PM",
      "commitName": "3d95049f79fe7edb92dd6d20c3a60ccdc46c4b0e",
      "commitAuthor": "Sanford Ryza",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "MAPREDUCE-5481. Enable uber jobs to have multiple reducers (Sandy Ryza)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1541844 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "13/11/13 11:56 PM",
          "commitName": "3d95049f79fe7edb92dd6d20c3a60ccdc46c4b0e",
          "commitAuthor": "Sanford Ryza",
          "commitDateOld": "16/06/13 11:39 PM",
          "commitNameOld": "b9efe6bd4a1277b4067ecde715a7713a85968886",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 150.05,
          "commitsBetweenForRepo": 919,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,114 +1,118 @@\n     private void runSubtask(org.apache.hadoop.mapred.Task task,\n                             final TaskType taskType,\n                             TaskAttemptId attemptID,\n                             final int numMapTasks,\n-                            boolean renameOutputs)\n+                            boolean renameOutputs,\n+                            Map\u003cTaskAttemptID, MapOutputFile\u003e localMapFiles)\n     throws RuntimeException, IOException {\n       org.apache.hadoop.mapred.TaskAttemptID classicAttemptID \u003d\n           TypeConverter.fromYarn(attemptID);\n \n       try {\n         JobConf conf \u003d new JobConf(getConfig());\n         conf.set(JobContext.TASK_ID, task.getTaskID().toString());\n         conf.set(JobContext.TASK_ATTEMPT_ID, classicAttemptID.toString());\n         conf.setBoolean(JobContext.TASK_ISMAP, (taskType \u003d\u003d TaskType.MAP));\n         conf.setInt(JobContext.TASK_PARTITION, task.getPartition());\n         conf.set(JobContext.ID, task.getJobID().toString());\n \n         // Use the AM\u0027s local dir env to generate the intermediate step \n         // output files\n         String[] localSysDirs \u003d StringUtils.getTrimmedStrings(\n             System.getenv(Environment.LOCAL_DIRS.name()));\n         conf.setStrings(MRConfig.LOCAL_DIR, localSysDirs);\n         LOG.info(MRConfig.LOCAL_DIR + \" for uber task: \"\n             + conf.get(MRConfig.LOCAL_DIR));\n \n         // mark this as an uberized subtask so it can set task counter\n         // (longer-term/FIXME:  could redefine as job counter and send\n         // \"JobCounterEvent\" to JobImpl on [successful] completion of subtask;\n         // will need new Job state-machine transition and JobImpl jobCounters\n         // map to handle)\n         conf.setBoolean(\"mapreduce.task.uberized\", true);\n \n         // META-FIXME: do we want the extra sanity-checking (doneWithMaps,\n         // etc.), or just assume/hope the state machine(s) and uber-AM work\n         // as expected?\n         if (taskType \u003d\u003d TaskType.MAP) {\n           if (doneWithMaps) {\n             LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a map task (\"\n                       + attemptID + \"), but should be finished with maps\");\n             throw new RuntimeException();\n           }\n \n           MapTask map \u003d (MapTask)task;\n           map.setConf(conf);\n \n           map.run(conf, umbilical);\n \n           if (renameOutputs) {\n-            renameMapOutputForReduce(conf, attemptID, map.getMapOutputFile());\n+            MapOutputFile renamed \u003d renameMapOutputForReduce(conf, attemptID,\n+                map.getMapOutputFile());\n+            localMapFiles.put(classicAttemptID, renamed);\n           }\n           relocalize();\n \n           if (++finishedSubMaps \u003d\u003d numMapTasks) {\n             doneWithMaps \u003d true;\n           }\n \n         } else /* TaskType.REDUCE */ {\n \n           if (!doneWithMaps) {\n             // check if event-queue empty?  whole idea of counting maps vs. \n             // checking event queue is a tad wacky...but could enforce ordering\n             // (assuming no \"lost events\") at LocalMRAppMaster [CURRENT BUG(?): \n             // doesn\u0027t send reduce event until maps all done]\n             LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a reduce task (\"\n                       + attemptID + \"), but not yet finished with maps\");\n             throw new RuntimeException();\n           }\n \n           // a.k.a. \"mapreduce.jobtracker.address\" in LocalJobRunner:\n           // set framework name to local to make task local\n           conf.set(MRConfig.FRAMEWORK_NAME, MRConfig.LOCAL_FRAMEWORK_NAME);\n           conf.set(MRConfig.MASTER_ADDRESS, \"local\");  // bypass shuffle\n \n           ReduceTask reduce \u003d (ReduceTask)task;\n+          reduce.setLocalMapFiles(localMapFiles);\n           reduce.setConf(conf);          \n \n           reduce.run(conf, umbilical);\n-          //relocalize();  // needed only if more than one reducer supported (is MAPREDUCE-434 fixed yet?)\n+          relocalize();\n         }\n \n       } catch (FSError e) {\n         LOG.fatal(\"FSError from child\", e);\n         // umbilical:  MRAppMaster creates (taskAttemptListener), passes to us\n         umbilical.fsError(classicAttemptID, e.getMessage());\n         throw new RuntimeException();\n \n       } catch (Exception exception) {\n         LOG.warn(\"Exception running local (uberized) \u0027child\u0027 : \"\n             + StringUtils.stringifyException(exception));\n         try {\n           if (task !\u003d null) {\n             // do cleanup for the task\n             task.taskCleanup(umbilical);\n           }\n         } catch (Exception e) {\n           LOG.info(\"Exception cleaning up: \"\n               + StringUtils.stringifyException(e));\n         }\n         // Report back any failures, for diagnostic purposes\n         umbilical.reportDiagnosticInfo(classicAttemptID, \n             StringUtils.stringifyException(exception));\n         throw new RuntimeException();\n \n       } catch (Throwable throwable) {\n         LOG.fatal(\"Error running local (uberized) \u0027child\u0027 : \"\n             + StringUtils.stringifyException(throwable));\n         Throwable tCause \u003d throwable.getCause();\n         String cause \u003d (tCause \u003d\u003d null)\n             ? throwable.getMessage()\n                 : StringUtils.stringifyException(tCause);\n             umbilical.fatalError(classicAttemptID, cause);\n         throw new RuntimeException();\n       }\n     }\n\\ No newline at end of file\n",
          "actualSource": "    private void runSubtask(org.apache.hadoop.mapred.Task task,\n                            final TaskType taskType,\n                            TaskAttemptId attemptID,\n                            final int numMapTasks,\n                            boolean renameOutputs,\n                            Map\u003cTaskAttemptID, MapOutputFile\u003e localMapFiles)\n    throws RuntimeException, IOException {\n      org.apache.hadoop.mapred.TaskAttemptID classicAttemptID \u003d\n          TypeConverter.fromYarn(attemptID);\n\n      try {\n        JobConf conf \u003d new JobConf(getConfig());\n        conf.set(JobContext.TASK_ID, task.getTaskID().toString());\n        conf.set(JobContext.TASK_ATTEMPT_ID, classicAttemptID.toString());\n        conf.setBoolean(JobContext.TASK_ISMAP, (taskType \u003d\u003d TaskType.MAP));\n        conf.setInt(JobContext.TASK_PARTITION, task.getPartition());\n        conf.set(JobContext.ID, task.getJobID().toString());\n\n        // Use the AM\u0027s local dir env to generate the intermediate step \n        // output files\n        String[] localSysDirs \u003d StringUtils.getTrimmedStrings(\n            System.getenv(Environment.LOCAL_DIRS.name()));\n        conf.setStrings(MRConfig.LOCAL_DIR, localSysDirs);\n        LOG.info(MRConfig.LOCAL_DIR + \" for uber task: \"\n            + conf.get(MRConfig.LOCAL_DIR));\n\n        // mark this as an uberized subtask so it can set task counter\n        // (longer-term/FIXME:  could redefine as job counter and send\n        // \"JobCounterEvent\" to JobImpl on [successful] completion of subtask;\n        // will need new Job state-machine transition and JobImpl jobCounters\n        // map to handle)\n        conf.setBoolean(\"mapreduce.task.uberized\", true);\n\n        // META-FIXME: do we want the extra sanity-checking (doneWithMaps,\n        // etc.), or just assume/hope the state machine(s) and uber-AM work\n        // as expected?\n        if (taskType \u003d\u003d TaskType.MAP) {\n          if (doneWithMaps) {\n            LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a map task (\"\n                      + attemptID + \"), but should be finished with maps\");\n            throw new RuntimeException();\n          }\n\n          MapTask map \u003d (MapTask)task;\n          map.setConf(conf);\n\n          map.run(conf, umbilical);\n\n          if (renameOutputs) {\n            MapOutputFile renamed \u003d renameMapOutputForReduce(conf, attemptID,\n                map.getMapOutputFile());\n            localMapFiles.put(classicAttemptID, renamed);\n          }\n          relocalize();\n\n          if (++finishedSubMaps \u003d\u003d numMapTasks) {\n            doneWithMaps \u003d true;\n          }\n\n        } else /* TaskType.REDUCE */ {\n\n          if (!doneWithMaps) {\n            // check if event-queue empty?  whole idea of counting maps vs. \n            // checking event queue is a tad wacky...but could enforce ordering\n            // (assuming no \"lost events\") at LocalMRAppMaster [CURRENT BUG(?): \n            // doesn\u0027t send reduce event until maps all done]\n            LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a reduce task (\"\n                      + attemptID + \"), but not yet finished with maps\");\n            throw new RuntimeException();\n          }\n\n          // a.k.a. \"mapreduce.jobtracker.address\" in LocalJobRunner:\n          // set framework name to local to make task local\n          conf.set(MRConfig.FRAMEWORK_NAME, MRConfig.LOCAL_FRAMEWORK_NAME);\n          conf.set(MRConfig.MASTER_ADDRESS, \"local\");  // bypass shuffle\n\n          ReduceTask reduce \u003d (ReduceTask)task;\n          reduce.setLocalMapFiles(localMapFiles);\n          reduce.setConf(conf);          \n\n          reduce.run(conf, umbilical);\n          relocalize();\n        }\n\n      } catch (FSError e) {\n        LOG.fatal(\"FSError from child\", e);\n        // umbilical:  MRAppMaster creates (taskAttemptListener), passes to us\n        umbilical.fsError(classicAttemptID, e.getMessage());\n        throw new RuntimeException();\n\n      } catch (Exception exception) {\n        LOG.warn(\"Exception running local (uberized) \u0027child\u0027 : \"\n            + StringUtils.stringifyException(exception));\n        try {\n          if (task !\u003d null) {\n            // do cleanup for the task\n            task.taskCleanup(umbilical);\n          }\n        } catch (Exception e) {\n          LOG.info(\"Exception cleaning up: \"\n              + StringUtils.stringifyException(e));\n        }\n        // Report back any failures, for diagnostic purposes\n        umbilical.reportDiagnosticInfo(classicAttemptID, \n            StringUtils.stringifyException(exception));\n        throw new RuntimeException();\n\n      } catch (Throwable throwable) {\n        LOG.fatal(\"Error running local (uberized) \u0027child\u0027 : \"\n            + StringUtils.stringifyException(throwable));\n        Throwable tCause \u003d throwable.getCause();\n        String cause \u003d (tCause \u003d\u003d null)\n            ? throwable.getMessage()\n                : StringUtils.stringifyException(tCause);\n            umbilical.fatalError(classicAttemptID, cause);\n        throw new RuntimeException();\n      }\n    }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/LocalContainerLauncher.java",
          "extendedDetails": {
            "oldValue": "[task-org.apache.hadoop.mapred.Task, taskType-TaskType(modifiers-final), attemptID-TaskAttemptId, numMapTasks-int(modifiers-final), renameOutputs-boolean]",
            "newValue": "[task-org.apache.hadoop.mapred.Task, taskType-TaskType(modifiers-final), attemptID-TaskAttemptId, numMapTasks-int(modifiers-final), renameOutputs-boolean, localMapFiles-Map\u003cTaskAttemptID,MapOutputFile\u003e]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "MAPREDUCE-5481. Enable uber jobs to have multiple reducers (Sandy Ryza)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1541844 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "13/11/13 11:56 PM",
          "commitName": "3d95049f79fe7edb92dd6d20c3a60ccdc46c4b0e",
          "commitAuthor": "Sanford Ryza",
          "commitDateOld": "16/06/13 11:39 PM",
          "commitNameOld": "b9efe6bd4a1277b4067ecde715a7713a85968886",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 150.05,
          "commitsBetweenForRepo": 919,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,114 +1,118 @@\n     private void runSubtask(org.apache.hadoop.mapred.Task task,\n                             final TaskType taskType,\n                             TaskAttemptId attemptID,\n                             final int numMapTasks,\n-                            boolean renameOutputs)\n+                            boolean renameOutputs,\n+                            Map\u003cTaskAttemptID, MapOutputFile\u003e localMapFiles)\n     throws RuntimeException, IOException {\n       org.apache.hadoop.mapred.TaskAttemptID classicAttemptID \u003d\n           TypeConverter.fromYarn(attemptID);\n \n       try {\n         JobConf conf \u003d new JobConf(getConfig());\n         conf.set(JobContext.TASK_ID, task.getTaskID().toString());\n         conf.set(JobContext.TASK_ATTEMPT_ID, classicAttemptID.toString());\n         conf.setBoolean(JobContext.TASK_ISMAP, (taskType \u003d\u003d TaskType.MAP));\n         conf.setInt(JobContext.TASK_PARTITION, task.getPartition());\n         conf.set(JobContext.ID, task.getJobID().toString());\n \n         // Use the AM\u0027s local dir env to generate the intermediate step \n         // output files\n         String[] localSysDirs \u003d StringUtils.getTrimmedStrings(\n             System.getenv(Environment.LOCAL_DIRS.name()));\n         conf.setStrings(MRConfig.LOCAL_DIR, localSysDirs);\n         LOG.info(MRConfig.LOCAL_DIR + \" for uber task: \"\n             + conf.get(MRConfig.LOCAL_DIR));\n \n         // mark this as an uberized subtask so it can set task counter\n         // (longer-term/FIXME:  could redefine as job counter and send\n         // \"JobCounterEvent\" to JobImpl on [successful] completion of subtask;\n         // will need new Job state-machine transition and JobImpl jobCounters\n         // map to handle)\n         conf.setBoolean(\"mapreduce.task.uberized\", true);\n \n         // META-FIXME: do we want the extra sanity-checking (doneWithMaps,\n         // etc.), or just assume/hope the state machine(s) and uber-AM work\n         // as expected?\n         if (taskType \u003d\u003d TaskType.MAP) {\n           if (doneWithMaps) {\n             LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a map task (\"\n                       + attemptID + \"), but should be finished with maps\");\n             throw new RuntimeException();\n           }\n \n           MapTask map \u003d (MapTask)task;\n           map.setConf(conf);\n \n           map.run(conf, umbilical);\n \n           if (renameOutputs) {\n-            renameMapOutputForReduce(conf, attemptID, map.getMapOutputFile());\n+            MapOutputFile renamed \u003d renameMapOutputForReduce(conf, attemptID,\n+                map.getMapOutputFile());\n+            localMapFiles.put(classicAttemptID, renamed);\n           }\n           relocalize();\n \n           if (++finishedSubMaps \u003d\u003d numMapTasks) {\n             doneWithMaps \u003d true;\n           }\n \n         } else /* TaskType.REDUCE */ {\n \n           if (!doneWithMaps) {\n             // check if event-queue empty?  whole idea of counting maps vs. \n             // checking event queue is a tad wacky...but could enforce ordering\n             // (assuming no \"lost events\") at LocalMRAppMaster [CURRENT BUG(?): \n             // doesn\u0027t send reduce event until maps all done]\n             LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a reduce task (\"\n                       + attemptID + \"), but not yet finished with maps\");\n             throw new RuntimeException();\n           }\n \n           // a.k.a. \"mapreduce.jobtracker.address\" in LocalJobRunner:\n           // set framework name to local to make task local\n           conf.set(MRConfig.FRAMEWORK_NAME, MRConfig.LOCAL_FRAMEWORK_NAME);\n           conf.set(MRConfig.MASTER_ADDRESS, \"local\");  // bypass shuffle\n \n           ReduceTask reduce \u003d (ReduceTask)task;\n+          reduce.setLocalMapFiles(localMapFiles);\n           reduce.setConf(conf);          \n \n           reduce.run(conf, umbilical);\n-          //relocalize();  // needed only if more than one reducer supported (is MAPREDUCE-434 fixed yet?)\n+          relocalize();\n         }\n \n       } catch (FSError e) {\n         LOG.fatal(\"FSError from child\", e);\n         // umbilical:  MRAppMaster creates (taskAttemptListener), passes to us\n         umbilical.fsError(classicAttemptID, e.getMessage());\n         throw new RuntimeException();\n \n       } catch (Exception exception) {\n         LOG.warn(\"Exception running local (uberized) \u0027child\u0027 : \"\n             + StringUtils.stringifyException(exception));\n         try {\n           if (task !\u003d null) {\n             // do cleanup for the task\n             task.taskCleanup(umbilical);\n           }\n         } catch (Exception e) {\n           LOG.info(\"Exception cleaning up: \"\n               + StringUtils.stringifyException(e));\n         }\n         // Report back any failures, for diagnostic purposes\n         umbilical.reportDiagnosticInfo(classicAttemptID, \n             StringUtils.stringifyException(exception));\n         throw new RuntimeException();\n \n       } catch (Throwable throwable) {\n         LOG.fatal(\"Error running local (uberized) \u0027child\u0027 : \"\n             + StringUtils.stringifyException(throwable));\n         Throwable tCause \u003d throwable.getCause();\n         String cause \u003d (tCause \u003d\u003d null)\n             ? throwable.getMessage()\n                 : StringUtils.stringifyException(tCause);\n             umbilical.fatalError(classicAttemptID, cause);\n         throw new RuntimeException();\n       }\n     }\n\\ No newline at end of file\n",
          "actualSource": "    private void runSubtask(org.apache.hadoop.mapred.Task task,\n                            final TaskType taskType,\n                            TaskAttemptId attemptID,\n                            final int numMapTasks,\n                            boolean renameOutputs,\n                            Map\u003cTaskAttemptID, MapOutputFile\u003e localMapFiles)\n    throws RuntimeException, IOException {\n      org.apache.hadoop.mapred.TaskAttemptID classicAttemptID \u003d\n          TypeConverter.fromYarn(attemptID);\n\n      try {\n        JobConf conf \u003d new JobConf(getConfig());\n        conf.set(JobContext.TASK_ID, task.getTaskID().toString());\n        conf.set(JobContext.TASK_ATTEMPT_ID, classicAttemptID.toString());\n        conf.setBoolean(JobContext.TASK_ISMAP, (taskType \u003d\u003d TaskType.MAP));\n        conf.setInt(JobContext.TASK_PARTITION, task.getPartition());\n        conf.set(JobContext.ID, task.getJobID().toString());\n\n        // Use the AM\u0027s local dir env to generate the intermediate step \n        // output files\n        String[] localSysDirs \u003d StringUtils.getTrimmedStrings(\n            System.getenv(Environment.LOCAL_DIRS.name()));\n        conf.setStrings(MRConfig.LOCAL_DIR, localSysDirs);\n        LOG.info(MRConfig.LOCAL_DIR + \" for uber task: \"\n            + conf.get(MRConfig.LOCAL_DIR));\n\n        // mark this as an uberized subtask so it can set task counter\n        // (longer-term/FIXME:  could redefine as job counter and send\n        // \"JobCounterEvent\" to JobImpl on [successful] completion of subtask;\n        // will need new Job state-machine transition and JobImpl jobCounters\n        // map to handle)\n        conf.setBoolean(\"mapreduce.task.uberized\", true);\n\n        // META-FIXME: do we want the extra sanity-checking (doneWithMaps,\n        // etc.), or just assume/hope the state machine(s) and uber-AM work\n        // as expected?\n        if (taskType \u003d\u003d TaskType.MAP) {\n          if (doneWithMaps) {\n            LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a map task (\"\n                      + attemptID + \"), but should be finished with maps\");\n            throw new RuntimeException();\n          }\n\n          MapTask map \u003d (MapTask)task;\n          map.setConf(conf);\n\n          map.run(conf, umbilical);\n\n          if (renameOutputs) {\n            MapOutputFile renamed \u003d renameMapOutputForReduce(conf, attemptID,\n                map.getMapOutputFile());\n            localMapFiles.put(classicAttemptID, renamed);\n          }\n          relocalize();\n\n          if (++finishedSubMaps \u003d\u003d numMapTasks) {\n            doneWithMaps \u003d true;\n          }\n\n        } else /* TaskType.REDUCE */ {\n\n          if (!doneWithMaps) {\n            // check if event-queue empty?  whole idea of counting maps vs. \n            // checking event queue is a tad wacky...but could enforce ordering\n            // (assuming no \"lost events\") at LocalMRAppMaster [CURRENT BUG(?): \n            // doesn\u0027t send reduce event until maps all done]\n            LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a reduce task (\"\n                      + attemptID + \"), but not yet finished with maps\");\n            throw new RuntimeException();\n          }\n\n          // a.k.a. \"mapreduce.jobtracker.address\" in LocalJobRunner:\n          // set framework name to local to make task local\n          conf.set(MRConfig.FRAMEWORK_NAME, MRConfig.LOCAL_FRAMEWORK_NAME);\n          conf.set(MRConfig.MASTER_ADDRESS, \"local\");  // bypass shuffle\n\n          ReduceTask reduce \u003d (ReduceTask)task;\n          reduce.setLocalMapFiles(localMapFiles);\n          reduce.setConf(conf);          \n\n          reduce.run(conf, umbilical);\n          relocalize();\n        }\n\n      } catch (FSError e) {\n        LOG.fatal(\"FSError from child\", e);\n        // umbilical:  MRAppMaster creates (taskAttemptListener), passes to us\n        umbilical.fsError(classicAttemptID, e.getMessage());\n        throw new RuntimeException();\n\n      } catch (Exception exception) {\n        LOG.warn(\"Exception running local (uberized) \u0027child\u0027 : \"\n            + StringUtils.stringifyException(exception));\n        try {\n          if (task !\u003d null) {\n            // do cleanup for the task\n            task.taskCleanup(umbilical);\n          }\n        } catch (Exception e) {\n          LOG.info(\"Exception cleaning up: \"\n              + StringUtils.stringifyException(e));\n        }\n        // Report back any failures, for diagnostic purposes\n        umbilical.reportDiagnosticInfo(classicAttemptID, \n            StringUtils.stringifyException(exception));\n        throw new RuntimeException();\n\n      } catch (Throwable throwable) {\n        LOG.fatal(\"Error running local (uberized) \u0027child\u0027 : \"\n            + StringUtils.stringifyException(throwable));\n        Throwable tCause \u003d throwable.getCause();\n        String cause \u003d (tCause \u003d\u003d null)\n            ? throwable.getMessage()\n                : StringUtils.stringifyException(tCause);\n            umbilical.fatalError(classicAttemptID, cause);\n        throw new RuntimeException();\n      }\n    }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/LocalContainerLauncher.java",
          "extendedDetails": {}
        }
      ]
    },
    "27e8c86999bc6a972a99216060b11ef35b7de858": {
      "type": "Ybodychange",
      "commitMessage": "YARN-561. Modified NodeManager to set key information into the environment of every container that it launches. Contributed by Xuan Gong.\nMAPREDUCE-5175. Updated MR App to not set envs that will be set by NMs anyways after YARN-561. Contributed by Xuan Gong.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1471156 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "23/04/13 2:39 PM",
      "commitName": "27e8c86999bc6a972a99216060b11ef35b7de858",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "14/11/12 4:16 PM",
      "commitNameOld": "905b17876c44634545a68300ff2f2d73fb86d3b7",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 159.89,
      "commitsBetweenForRepo": 742,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,114 +1,114 @@\n     private void runSubtask(org.apache.hadoop.mapred.Task task,\n                             final TaskType taskType,\n                             TaskAttemptId attemptID,\n                             final int numMapTasks,\n                             boolean renameOutputs)\n     throws RuntimeException, IOException {\n       org.apache.hadoop.mapred.TaskAttemptID classicAttemptID \u003d\n           TypeConverter.fromYarn(attemptID);\n \n       try {\n         JobConf conf \u003d new JobConf(getConfig());\n         conf.set(JobContext.TASK_ID, task.getTaskID().toString());\n         conf.set(JobContext.TASK_ATTEMPT_ID, classicAttemptID.toString());\n         conf.setBoolean(JobContext.TASK_ISMAP, (taskType \u003d\u003d TaskType.MAP));\n         conf.setInt(JobContext.TASK_PARTITION, task.getPartition());\n         conf.set(JobContext.ID, task.getJobID().toString());\n \n         // Use the AM\u0027s local dir env to generate the intermediate step \n         // output files\n         String[] localSysDirs \u003d StringUtils.getTrimmedStrings(\n-            System.getenv(ApplicationConstants.LOCAL_DIR_ENV));\n+            System.getenv(Environment.LOCAL_DIRS.name()));\n         conf.setStrings(MRConfig.LOCAL_DIR, localSysDirs);\n         LOG.info(MRConfig.LOCAL_DIR + \" for uber task: \"\n             + conf.get(MRConfig.LOCAL_DIR));\n \n         // mark this as an uberized subtask so it can set task counter\n         // (longer-term/FIXME:  could redefine as job counter and send\n         // \"JobCounterEvent\" to JobImpl on [successful] completion of subtask;\n         // will need new Job state-machine transition and JobImpl jobCounters\n         // map to handle)\n         conf.setBoolean(\"mapreduce.task.uberized\", true);\n \n         // META-FIXME: do we want the extra sanity-checking (doneWithMaps,\n         // etc.), or just assume/hope the state machine(s) and uber-AM work\n         // as expected?\n         if (taskType \u003d\u003d TaskType.MAP) {\n           if (doneWithMaps) {\n             LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a map task (\"\n                       + attemptID + \"), but should be finished with maps\");\n             throw new RuntimeException();\n           }\n \n           MapTask map \u003d (MapTask)task;\n           map.setConf(conf);\n \n           map.run(conf, umbilical);\n \n           if (renameOutputs) {\n             renameMapOutputForReduce(conf, attemptID, map.getMapOutputFile());\n           }\n           relocalize();\n \n           if (++finishedSubMaps \u003d\u003d numMapTasks) {\n             doneWithMaps \u003d true;\n           }\n \n         } else /* TaskType.REDUCE */ {\n \n           if (!doneWithMaps) {\n             // check if event-queue empty?  whole idea of counting maps vs. \n             // checking event queue is a tad wacky...but could enforce ordering\n             // (assuming no \"lost events\") at LocalMRAppMaster [CURRENT BUG(?): \n             // doesn\u0027t send reduce event until maps all done]\n             LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a reduce task (\"\n                       + attemptID + \"), but not yet finished with maps\");\n             throw new RuntimeException();\n           }\n \n           // a.k.a. \"mapreduce.jobtracker.address\" in LocalJobRunner:\n           // set framework name to local to make task local\n           conf.set(MRConfig.FRAMEWORK_NAME, MRConfig.LOCAL_FRAMEWORK_NAME);\n           conf.set(MRConfig.MASTER_ADDRESS, \"local\");  // bypass shuffle\n \n           ReduceTask reduce \u003d (ReduceTask)task;\n           reduce.setConf(conf);          \n \n           reduce.run(conf, umbilical);\n           //relocalize();  // needed only if more than one reducer supported (is MAPREDUCE-434 fixed yet?)\n         }\n \n       } catch (FSError e) {\n         LOG.fatal(\"FSError from child\", e);\n         // umbilical:  MRAppMaster creates (taskAttemptListener), passes to us\n         umbilical.fsError(classicAttemptID, e.getMessage());\n         throw new RuntimeException();\n \n       } catch (Exception exception) {\n         LOG.warn(\"Exception running local (uberized) \u0027child\u0027 : \"\n             + StringUtils.stringifyException(exception));\n         try {\n           if (task !\u003d null) {\n             // do cleanup for the task\n             task.taskCleanup(umbilical);\n           }\n         } catch (Exception e) {\n           LOG.info(\"Exception cleaning up: \"\n               + StringUtils.stringifyException(e));\n         }\n         // Report back any failures, for diagnostic purposes\n         umbilical.reportDiagnosticInfo(classicAttemptID, \n             StringUtils.stringifyException(exception));\n         throw new RuntimeException();\n \n       } catch (Throwable throwable) {\n         LOG.fatal(\"Error running local (uberized) \u0027child\u0027 : \"\n             + StringUtils.stringifyException(throwable));\n         Throwable tCause \u003d throwable.getCause();\n         String cause \u003d (tCause \u003d\u003d null)\n             ? throwable.getMessage()\n                 : StringUtils.stringifyException(tCause);\n             umbilical.fatalError(classicAttemptID, cause);\n         throw new RuntimeException();\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void runSubtask(org.apache.hadoop.mapred.Task task,\n                            final TaskType taskType,\n                            TaskAttemptId attemptID,\n                            final int numMapTasks,\n                            boolean renameOutputs)\n    throws RuntimeException, IOException {\n      org.apache.hadoop.mapred.TaskAttemptID classicAttemptID \u003d\n          TypeConverter.fromYarn(attemptID);\n\n      try {\n        JobConf conf \u003d new JobConf(getConfig());\n        conf.set(JobContext.TASK_ID, task.getTaskID().toString());\n        conf.set(JobContext.TASK_ATTEMPT_ID, classicAttemptID.toString());\n        conf.setBoolean(JobContext.TASK_ISMAP, (taskType \u003d\u003d TaskType.MAP));\n        conf.setInt(JobContext.TASK_PARTITION, task.getPartition());\n        conf.set(JobContext.ID, task.getJobID().toString());\n\n        // Use the AM\u0027s local dir env to generate the intermediate step \n        // output files\n        String[] localSysDirs \u003d StringUtils.getTrimmedStrings(\n            System.getenv(Environment.LOCAL_DIRS.name()));\n        conf.setStrings(MRConfig.LOCAL_DIR, localSysDirs);\n        LOG.info(MRConfig.LOCAL_DIR + \" for uber task: \"\n            + conf.get(MRConfig.LOCAL_DIR));\n\n        // mark this as an uberized subtask so it can set task counter\n        // (longer-term/FIXME:  could redefine as job counter and send\n        // \"JobCounterEvent\" to JobImpl on [successful] completion of subtask;\n        // will need new Job state-machine transition and JobImpl jobCounters\n        // map to handle)\n        conf.setBoolean(\"mapreduce.task.uberized\", true);\n\n        // META-FIXME: do we want the extra sanity-checking (doneWithMaps,\n        // etc.), or just assume/hope the state machine(s) and uber-AM work\n        // as expected?\n        if (taskType \u003d\u003d TaskType.MAP) {\n          if (doneWithMaps) {\n            LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a map task (\"\n                      + attemptID + \"), but should be finished with maps\");\n            throw new RuntimeException();\n          }\n\n          MapTask map \u003d (MapTask)task;\n          map.setConf(conf);\n\n          map.run(conf, umbilical);\n\n          if (renameOutputs) {\n            renameMapOutputForReduce(conf, attemptID, map.getMapOutputFile());\n          }\n          relocalize();\n\n          if (++finishedSubMaps \u003d\u003d numMapTasks) {\n            doneWithMaps \u003d true;\n          }\n\n        } else /* TaskType.REDUCE */ {\n\n          if (!doneWithMaps) {\n            // check if event-queue empty?  whole idea of counting maps vs. \n            // checking event queue is a tad wacky...but could enforce ordering\n            // (assuming no \"lost events\") at LocalMRAppMaster [CURRENT BUG(?): \n            // doesn\u0027t send reduce event until maps all done]\n            LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a reduce task (\"\n                      + attemptID + \"), but not yet finished with maps\");\n            throw new RuntimeException();\n          }\n\n          // a.k.a. \"mapreduce.jobtracker.address\" in LocalJobRunner:\n          // set framework name to local to make task local\n          conf.set(MRConfig.FRAMEWORK_NAME, MRConfig.LOCAL_FRAMEWORK_NAME);\n          conf.set(MRConfig.MASTER_ADDRESS, \"local\");  // bypass shuffle\n\n          ReduceTask reduce \u003d (ReduceTask)task;\n          reduce.setConf(conf);          \n\n          reduce.run(conf, umbilical);\n          //relocalize();  // needed only if more than one reducer supported (is MAPREDUCE-434 fixed yet?)\n        }\n\n      } catch (FSError e) {\n        LOG.fatal(\"FSError from child\", e);\n        // umbilical:  MRAppMaster creates (taskAttemptListener), passes to us\n        umbilical.fsError(classicAttemptID, e.getMessage());\n        throw new RuntimeException();\n\n      } catch (Exception exception) {\n        LOG.warn(\"Exception running local (uberized) \u0027child\u0027 : \"\n            + StringUtils.stringifyException(exception));\n        try {\n          if (task !\u003d null) {\n            // do cleanup for the task\n            task.taskCleanup(umbilical);\n          }\n        } catch (Exception e) {\n          LOG.info(\"Exception cleaning up: \"\n              + StringUtils.stringifyException(e));\n        }\n        // Report back any failures, for diagnostic purposes\n        umbilical.reportDiagnosticInfo(classicAttemptID, \n            StringUtils.stringifyException(exception));\n        throw new RuntimeException();\n\n      } catch (Throwable throwable) {\n        LOG.fatal(\"Error running local (uberized) \u0027child\u0027 : \"\n            + StringUtils.stringifyException(throwable));\n        Throwable tCause \u003d throwable.getCause();\n        String cause \u003d (tCause \u003d\u003d null)\n            ? throwable.getMessage()\n                : StringUtils.stringifyException(tCause);\n            umbilical.fatalError(classicAttemptID, cause);\n        throw new RuntimeException();\n      }\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/LocalContainerLauncher.java",
      "extendedDetails": {}
    },
    "905b17876c44634545a68300ff2f2d73fb86d3b7": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4723. Fix warnings found by findbugs 2. Contributed by Sandy Ryza\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1409601 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/11/12 4:16 PM",
      "commitName": "905b17876c44634545a68300ff2f2d73fb86d3b7",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "22/12/11 2:34 PM",
      "commitNameOld": "8fa0a3c737f27ff9d12fb657a7b22865754a5fd8",
      "commitAuthorOld": "Siddharth Seth",
      "daysBetweenCommits": 328.07,
      "commitsBetweenForRepo": 2076,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,115 +1,114 @@\n     private void runSubtask(org.apache.hadoop.mapred.Task task,\n                             final TaskType taskType,\n                             TaskAttemptId attemptID,\n                             final int numMapTasks,\n                             boolean renameOutputs)\n     throws RuntimeException, IOException {\n       org.apache.hadoop.mapred.TaskAttemptID classicAttemptID \u003d\n           TypeConverter.fromYarn(attemptID);\n \n       try {\n         JobConf conf \u003d new JobConf(getConfig());\n         conf.set(JobContext.TASK_ID, task.getTaskID().toString());\n         conf.set(JobContext.TASK_ATTEMPT_ID, classicAttemptID.toString());\n         conf.setBoolean(JobContext.TASK_ISMAP, (taskType \u003d\u003d TaskType.MAP));\n         conf.setInt(JobContext.TASK_PARTITION, task.getPartition());\n         conf.set(JobContext.ID, task.getJobID().toString());\n \n         // Use the AM\u0027s local dir env to generate the intermediate step \n         // output files\n         String[] localSysDirs \u003d StringUtils.getTrimmedStrings(\n             System.getenv(ApplicationConstants.LOCAL_DIR_ENV));\n         conf.setStrings(MRConfig.LOCAL_DIR, localSysDirs);\n         LOG.info(MRConfig.LOCAL_DIR + \" for uber task: \"\n             + conf.get(MRConfig.LOCAL_DIR));\n \n         // mark this as an uberized subtask so it can set task counter\n         // (longer-term/FIXME:  could redefine as job counter and send\n         // \"JobCounterEvent\" to JobImpl on [successful] completion of subtask;\n         // will need new Job state-machine transition and JobImpl jobCounters\n         // map to handle)\n         conf.setBoolean(\"mapreduce.task.uberized\", true);\n \n         // META-FIXME: do we want the extra sanity-checking (doneWithMaps,\n         // etc.), or just assume/hope the state machine(s) and uber-AM work\n         // as expected?\n         if (taskType \u003d\u003d TaskType.MAP) {\n           if (doneWithMaps) {\n             LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a map task (\"\n                       + attemptID + \"), but should be finished with maps\");\n             throw new RuntimeException();\n           }\n \n           MapTask map \u003d (MapTask)task;\n           map.setConf(conf);\n \n           map.run(conf, umbilical);\n \n           if (renameOutputs) {\n             renameMapOutputForReduce(conf, attemptID, map.getMapOutputFile());\n           }\n           relocalize();\n \n           if (++finishedSubMaps \u003d\u003d numMapTasks) {\n             doneWithMaps \u003d true;\n           }\n \n         } else /* TaskType.REDUCE */ {\n \n           if (!doneWithMaps) {\n             // check if event-queue empty?  whole idea of counting maps vs. \n             // checking event queue is a tad wacky...but could enforce ordering\n             // (assuming no \"lost events\") at LocalMRAppMaster [CURRENT BUG(?): \n             // doesn\u0027t send reduce event until maps all done]\n             LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a reduce task (\"\n                       + attemptID + \"), but not yet finished with maps\");\n             throw new RuntimeException();\n           }\n \n           // a.k.a. \"mapreduce.jobtracker.address\" in LocalJobRunner:\n           // set framework name to local to make task local\n           conf.set(MRConfig.FRAMEWORK_NAME, MRConfig.LOCAL_FRAMEWORK_NAME);\n           conf.set(MRConfig.MASTER_ADDRESS, \"local\");  // bypass shuffle\n \n           ReduceTask reduce \u003d (ReduceTask)task;\n           reduce.setConf(conf);          \n \n           reduce.run(conf, umbilical);\n           //relocalize();  // needed only if more than one reducer supported (is MAPREDUCE-434 fixed yet?)\n         }\n \n       } catch (FSError e) {\n         LOG.fatal(\"FSError from child\", e);\n         // umbilical:  MRAppMaster creates (taskAttemptListener), passes to us\n         umbilical.fsError(classicAttemptID, e.getMessage());\n         throw new RuntimeException();\n \n       } catch (Exception exception) {\n         LOG.warn(\"Exception running local (uberized) \u0027child\u0027 : \"\n             + StringUtils.stringifyException(exception));\n         try {\n           if (task !\u003d null) {\n             // do cleanup for the task\n             task.taskCleanup(umbilical);\n           }\n         } catch (Exception e) {\n           LOG.info(\"Exception cleaning up: \"\n               + StringUtils.stringifyException(e));\n         }\n         // Report back any failures, for diagnostic purposes\n-        ByteArrayOutputStream baos \u003d new ByteArrayOutputStream();\n-        exception.printStackTrace(new PrintStream(baos));\n-        umbilical.reportDiagnosticInfo(classicAttemptID, baos.toString());\n+        umbilical.reportDiagnosticInfo(classicAttemptID, \n+            StringUtils.stringifyException(exception));\n         throw new RuntimeException();\n \n       } catch (Throwable throwable) {\n         LOG.fatal(\"Error running local (uberized) \u0027child\u0027 : \"\n             + StringUtils.stringifyException(throwable));\n         Throwable tCause \u003d throwable.getCause();\n         String cause \u003d (tCause \u003d\u003d null)\n             ? throwable.getMessage()\n                 : StringUtils.stringifyException(tCause);\n             umbilical.fatalError(classicAttemptID, cause);\n         throw new RuntimeException();\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void runSubtask(org.apache.hadoop.mapred.Task task,\n                            final TaskType taskType,\n                            TaskAttemptId attemptID,\n                            final int numMapTasks,\n                            boolean renameOutputs)\n    throws RuntimeException, IOException {\n      org.apache.hadoop.mapred.TaskAttemptID classicAttemptID \u003d\n          TypeConverter.fromYarn(attemptID);\n\n      try {\n        JobConf conf \u003d new JobConf(getConfig());\n        conf.set(JobContext.TASK_ID, task.getTaskID().toString());\n        conf.set(JobContext.TASK_ATTEMPT_ID, classicAttemptID.toString());\n        conf.setBoolean(JobContext.TASK_ISMAP, (taskType \u003d\u003d TaskType.MAP));\n        conf.setInt(JobContext.TASK_PARTITION, task.getPartition());\n        conf.set(JobContext.ID, task.getJobID().toString());\n\n        // Use the AM\u0027s local dir env to generate the intermediate step \n        // output files\n        String[] localSysDirs \u003d StringUtils.getTrimmedStrings(\n            System.getenv(ApplicationConstants.LOCAL_DIR_ENV));\n        conf.setStrings(MRConfig.LOCAL_DIR, localSysDirs);\n        LOG.info(MRConfig.LOCAL_DIR + \" for uber task: \"\n            + conf.get(MRConfig.LOCAL_DIR));\n\n        // mark this as an uberized subtask so it can set task counter\n        // (longer-term/FIXME:  could redefine as job counter and send\n        // \"JobCounterEvent\" to JobImpl on [successful] completion of subtask;\n        // will need new Job state-machine transition and JobImpl jobCounters\n        // map to handle)\n        conf.setBoolean(\"mapreduce.task.uberized\", true);\n\n        // META-FIXME: do we want the extra sanity-checking (doneWithMaps,\n        // etc.), or just assume/hope the state machine(s) and uber-AM work\n        // as expected?\n        if (taskType \u003d\u003d TaskType.MAP) {\n          if (doneWithMaps) {\n            LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a map task (\"\n                      + attemptID + \"), but should be finished with maps\");\n            throw new RuntimeException();\n          }\n\n          MapTask map \u003d (MapTask)task;\n          map.setConf(conf);\n\n          map.run(conf, umbilical);\n\n          if (renameOutputs) {\n            renameMapOutputForReduce(conf, attemptID, map.getMapOutputFile());\n          }\n          relocalize();\n\n          if (++finishedSubMaps \u003d\u003d numMapTasks) {\n            doneWithMaps \u003d true;\n          }\n\n        } else /* TaskType.REDUCE */ {\n\n          if (!doneWithMaps) {\n            // check if event-queue empty?  whole idea of counting maps vs. \n            // checking event queue is a tad wacky...but could enforce ordering\n            // (assuming no \"lost events\") at LocalMRAppMaster [CURRENT BUG(?): \n            // doesn\u0027t send reduce event until maps all done]\n            LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a reduce task (\"\n                      + attemptID + \"), but not yet finished with maps\");\n            throw new RuntimeException();\n          }\n\n          // a.k.a. \"mapreduce.jobtracker.address\" in LocalJobRunner:\n          // set framework name to local to make task local\n          conf.set(MRConfig.FRAMEWORK_NAME, MRConfig.LOCAL_FRAMEWORK_NAME);\n          conf.set(MRConfig.MASTER_ADDRESS, \"local\");  // bypass shuffle\n\n          ReduceTask reduce \u003d (ReduceTask)task;\n          reduce.setConf(conf);          \n\n          reduce.run(conf, umbilical);\n          //relocalize();  // needed only if more than one reducer supported (is MAPREDUCE-434 fixed yet?)\n        }\n\n      } catch (FSError e) {\n        LOG.fatal(\"FSError from child\", e);\n        // umbilical:  MRAppMaster creates (taskAttemptListener), passes to us\n        umbilical.fsError(classicAttemptID, e.getMessage());\n        throw new RuntimeException();\n\n      } catch (Exception exception) {\n        LOG.warn(\"Exception running local (uberized) \u0027child\u0027 : \"\n            + StringUtils.stringifyException(exception));\n        try {\n          if (task !\u003d null) {\n            // do cleanup for the task\n            task.taskCleanup(umbilical);\n          }\n        } catch (Exception e) {\n          LOG.info(\"Exception cleaning up: \"\n              + StringUtils.stringifyException(e));\n        }\n        // Report back any failures, for diagnostic purposes\n        umbilical.reportDiagnosticInfo(classicAttemptID, \n            StringUtils.stringifyException(exception));\n        throw new RuntimeException();\n\n      } catch (Throwable throwable) {\n        LOG.fatal(\"Error running local (uberized) \u0027child\u0027 : \"\n            + StringUtils.stringifyException(throwable));\n        Throwable tCause \u003d throwable.getCause();\n        String cause \u003d (tCause \u003d\u003d null)\n            ? throwable.getMessage()\n                : StringUtils.stringifyException(tCause);\n            umbilical.fatalError(classicAttemptID, cause);\n        throw new RuntimeException();\n      }\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/LocalContainerLauncher.java",
      "extendedDetails": {}
    },
    "b7ae5a6cb7b2d3e3112ac53007e984caeb07de58": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3426. Fixed MR AM in uber mode to write map intermediate outputs in the correct directory to work properly in secure mode. Contributed by Hitesh Shah.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1213987 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/12/11 3:35 PM",
      "commitName": "b7ae5a6cb7b2d3e3112ac53007e984caeb07de58",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "24/10/11 10:09 AM",
      "commitNameOld": "7ce1c4ab352bca4b59ecbafdf237e5817cf833e5",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 50.27,
      "commitsBetweenForRepo": 346,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,124 +1,115 @@\n     private void runSubtask(org.apache.hadoop.mapred.Task task,\n                             final TaskType taskType,\n                             TaskAttemptId attemptID,\n                             final int numMapTasks,\n                             boolean renameOutputs)\n     throws RuntimeException, IOException {\n       org.apache.hadoop.mapred.TaskAttemptID classicAttemptID \u003d\n           TypeConverter.fromYarn(attemptID);\n \n       try {\n         JobConf conf \u003d new JobConf(getConfig());\n+        conf.set(JobContext.TASK_ID, task.getTaskID().toString());\n+        conf.set(JobContext.TASK_ATTEMPT_ID, classicAttemptID.toString());\n+        conf.setBoolean(JobContext.TASK_ISMAP, (taskType \u003d\u003d TaskType.MAP));\n+        conf.setInt(JobContext.TASK_PARTITION, task.getPartition());\n+        conf.set(JobContext.ID, task.getJobID().toString());\n+\n+        // Use the AM\u0027s local dir env to generate the intermediate step \n+        // output files\n+        String[] localSysDirs \u003d StringUtils.getTrimmedStrings(\n+            System.getenv(ApplicationConstants.LOCAL_DIR_ENV));\n+        conf.setStrings(MRConfig.LOCAL_DIR, localSysDirs);\n+        LOG.info(MRConfig.LOCAL_DIR + \" for uber task: \"\n+            + conf.get(MRConfig.LOCAL_DIR));\n \n         // mark this as an uberized subtask so it can set task counter\n         // (longer-term/FIXME:  could redefine as job counter and send\n         // \"JobCounterEvent\" to JobImpl on [successful] completion of subtask;\n         // will need new Job state-machine transition and JobImpl jobCounters\n         // map to handle)\n         conf.setBoolean(\"mapreduce.task.uberized\", true);\n \n         // META-FIXME: do we want the extra sanity-checking (doneWithMaps,\n         // etc.), or just assume/hope the state machine(s) and uber-AM work\n         // as expected?\n         if (taskType \u003d\u003d TaskType.MAP) {\n           if (doneWithMaps) {\n             LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a map task (\"\n                       + attemptID + \"), but should be finished with maps\");\n-            // throw new RuntimeException()  (FIXME: what\u0027s appropriate here?)\n+            throw new RuntimeException();\n           }\n \n           MapTask map \u003d (MapTask)task;\n+          map.setConf(conf);\n \n-          //CODE-REVIEWER QUESTION: why not task.getConf() or map.getConf() instead of conf? do we need Task\u0027s localizeConfiguration() run on this first?\n           map.run(conf, umbilical);\n \n           if (renameOutputs) {\n             renameMapOutputForReduce(conf, attemptID, map.getMapOutputFile());\n           }\n           relocalize();\n \n           if (++finishedSubMaps \u003d\u003d numMapTasks) {\n             doneWithMaps \u003d true;\n           }\n \n         } else /* TaskType.REDUCE */ {\n \n           if (!doneWithMaps) {\n-            //check if event-queue empty?  whole idea of counting maps vs. checking event queue is a tad wacky...but could enforce ordering (assuming no \"lost events\") at LocalMRAppMaster [CURRENT BUG(?):  doesn\u0027t send reduce event until maps all done]\n+            // check if event-queue empty?  whole idea of counting maps vs. \n+            // checking event queue is a tad wacky...but could enforce ordering\n+            // (assuming no \"lost events\") at LocalMRAppMaster [CURRENT BUG(?): \n+            // doesn\u0027t send reduce event until maps all done]\n             LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a reduce task (\"\n                       + attemptID + \"), but not yet finished with maps\");\n-            // throw new RuntimeException()  (FIXME) // or push reduce event back onto end of queue? (probably former)\n+            throw new RuntimeException();\n           }\n \n-          ReduceTask reduce \u003d (ReduceTask)task;\n-\n           // a.k.a. \"mapreduce.jobtracker.address\" in LocalJobRunner:\n           // set framework name to local to make task local\n           conf.set(MRConfig.FRAMEWORK_NAME, MRConfig.LOCAL_FRAMEWORK_NAME);\n           conf.set(MRConfig.MASTER_ADDRESS, \"local\");  // bypass shuffle\n \n+          ReduceTask reduce \u003d (ReduceTask)task;\n+          reduce.setConf(conf);          \n+\n           reduce.run(conf, umbilical);\n           //relocalize();  // needed only if more than one reducer supported (is MAPREDUCE-434 fixed yet?)\n         }\n \n       } catch (FSError e) {\n         LOG.fatal(\"FSError from child\", e);\n         // umbilical:  MRAppMaster creates (taskAttemptListener), passes to us\n         umbilical.fsError(classicAttemptID, e.getMessage());\n         throw new RuntimeException();\n \n       } catch (Exception exception) {\n         LOG.warn(\"Exception running local (uberized) \u0027child\u0027 : \"\n             + StringUtils.stringifyException(exception));\n         try {\n           if (task !\u003d null) {\n             // do cleanup for the task\n-//          if (childUGI \u003d\u003d null) { // no need to job into doAs block\n-              task.taskCleanup(umbilical);\n-//          } else {\n-//            final Task taskFinal \u003d task;\n-//            childUGI.doAs(new PrivilegedExceptionAction\u003cObject\u003e() {\n-//              @Override\n-//              public Object run() throws Exception {\n-//                taskFinal.taskCleanup(umbilical);\n-//                return null;\n-//              }\n-//            });\n-//          }\n+            task.taskCleanup(umbilical);\n           }\n         } catch (Exception e) {\n           LOG.info(\"Exception cleaning up: \"\n               + StringUtils.stringifyException(e));\n         }\n         // Report back any failures, for diagnostic purposes\n         ByteArrayOutputStream baos \u003d new ByteArrayOutputStream();\n         exception.printStackTrace(new PrintStream(baos));\n-//      if (classicAttemptID !\u003d null) {\n-          umbilical.reportDiagnosticInfo(classicAttemptID, baos.toString());\n-//      }\n+        umbilical.reportDiagnosticInfo(classicAttemptID, baos.toString());\n         throw new RuntimeException();\n \n       } catch (Throwable throwable) {\n         LOG.fatal(\"Error running local (uberized) \u0027child\u0027 : \"\n             + StringUtils.stringifyException(throwable));\n-//      if (classicAttemptID !\u003d null) {\n-          Throwable tCause \u003d throwable.getCause();\n-          String cause \u003d (tCause \u003d\u003d null)\n-              ? throwable.getMessage()\n-              : StringUtils.stringifyException(tCause);\n-          umbilical.fatalError(classicAttemptID, cause);\n-//      }\n+        Throwable tCause \u003d throwable.getCause();\n+        String cause \u003d (tCause \u003d\u003d null)\n+            ? throwable.getMessage()\n+                : StringUtils.stringifyException(tCause);\n+            umbilical.fatalError(classicAttemptID, cause);\n         throw new RuntimeException();\n-\n-      } finally {\n-/*\n-FIXME:  do we need to do any of this stuff?  (guessing not since not in own JVM)\n-        RPC.stopProxy(umbilical);\n-        DefaultMetricsSystem.shutdown();\n-        // Shutting down log4j of the child-vm...\n-        // This assumes that on return from Task.run()\n-        // there is no more logging done.\n-        LogManager.shutdown();\n- */\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void runSubtask(org.apache.hadoop.mapred.Task task,\n                            final TaskType taskType,\n                            TaskAttemptId attemptID,\n                            final int numMapTasks,\n                            boolean renameOutputs)\n    throws RuntimeException, IOException {\n      org.apache.hadoop.mapred.TaskAttemptID classicAttemptID \u003d\n          TypeConverter.fromYarn(attemptID);\n\n      try {\n        JobConf conf \u003d new JobConf(getConfig());\n        conf.set(JobContext.TASK_ID, task.getTaskID().toString());\n        conf.set(JobContext.TASK_ATTEMPT_ID, classicAttemptID.toString());\n        conf.setBoolean(JobContext.TASK_ISMAP, (taskType \u003d\u003d TaskType.MAP));\n        conf.setInt(JobContext.TASK_PARTITION, task.getPartition());\n        conf.set(JobContext.ID, task.getJobID().toString());\n\n        // Use the AM\u0027s local dir env to generate the intermediate step \n        // output files\n        String[] localSysDirs \u003d StringUtils.getTrimmedStrings(\n            System.getenv(ApplicationConstants.LOCAL_DIR_ENV));\n        conf.setStrings(MRConfig.LOCAL_DIR, localSysDirs);\n        LOG.info(MRConfig.LOCAL_DIR + \" for uber task: \"\n            + conf.get(MRConfig.LOCAL_DIR));\n\n        // mark this as an uberized subtask so it can set task counter\n        // (longer-term/FIXME:  could redefine as job counter and send\n        // \"JobCounterEvent\" to JobImpl on [successful] completion of subtask;\n        // will need new Job state-machine transition and JobImpl jobCounters\n        // map to handle)\n        conf.setBoolean(\"mapreduce.task.uberized\", true);\n\n        // META-FIXME: do we want the extra sanity-checking (doneWithMaps,\n        // etc.), or just assume/hope the state machine(s) and uber-AM work\n        // as expected?\n        if (taskType \u003d\u003d TaskType.MAP) {\n          if (doneWithMaps) {\n            LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a map task (\"\n                      + attemptID + \"), but should be finished with maps\");\n            throw new RuntimeException();\n          }\n\n          MapTask map \u003d (MapTask)task;\n          map.setConf(conf);\n\n          map.run(conf, umbilical);\n\n          if (renameOutputs) {\n            renameMapOutputForReduce(conf, attemptID, map.getMapOutputFile());\n          }\n          relocalize();\n\n          if (++finishedSubMaps \u003d\u003d numMapTasks) {\n            doneWithMaps \u003d true;\n          }\n\n        } else /* TaskType.REDUCE */ {\n\n          if (!doneWithMaps) {\n            // check if event-queue empty?  whole idea of counting maps vs. \n            // checking event queue is a tad wacky...but could enforce ordering\n            // (assuming no \"lost events\") at LocalMRAppMaster [CURRENT BUG(?): \n            // doesn\u0027t send reduce event until maps all done]\n            LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a reduce task (\"\n                      + attemptID + \"), but not yet finished with maps\");\n            throw new RuntimeException();\n          }\n\n          // a.k.a. \"mapreduce.jobtracker.address\" in LocalJobRunner:\n          // set framework name to local to make task local\n          conf.set(MRConfig.FRAMEWORK_NAME, MRConfig.LOCAL_FRAMEWORK_NAME);\n          conf.set(MRConfig.MASTER_ADDRESS, \"local\");  // bypass shuffle\n\n          ReduceTask reduce \u003d (ReduceTask)task;\n          reduce.setConf(conf);          \n\n          reduce.run(conf, umbilical);\n          //relocalize();  // needed only if more than one reducer supported (is MAPREDUCE-434 fixed yet?)\n        }\n\n      } catch (FSError e) {\n        LOG.fatal(\"FSError from child\", e);\n        // umbilical:  MRAppMaster creates (taskAttemptListener), passes to us\n        umbilical.fsError(classicAttemptID, e.getMessage());\n        throw new RuntimeException();\n\n      } catch (Exception exception) {\n        LOG.warn(\"Exception running local (uberized) \u0027child\u0027 : \"\n            + StringUtils.stringifyException(exception));\n        try {\n          if (task !\u003d null) {\n            // do cleanup for the task\n            task.taskCleanup(umbilical);\n          }\n        } catch (Exception e) {\n          LOG.info(\"Exception cleaning up: \"\n              + StringUtils.stringifyException(e));\n        }\n        // Report back any failures, for diagnostic purposes\n        ByteArrayOutputStream baos \u003d new ByteArrayOutputStream();\n        exception.printStackTrace(new PrintStream(baos));\n        umbilical.reportDiagnosticInfo(classicAttemptID, baos.toString());\n        throw new RuntimeException();\n\n      } catch (Throwable throwable) {\n        LOG.fatal(\"Error running local (uberized) \u0027child\u0027 : \"\n            + StringUtils.stringifyException(throwable));\n        Throwable tCause \u003d throwable.getCause();\n        String cause \u003d (tCause \u003d\u003d null)\n            ? throwable.getMessage()\n                : StringUtils.stringifyException(tCause);\n            umbilical.fatalError(classicAttemptID, cause);\n        throw new RuntimeException();\n      }\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/LocalContainerLauncher.java",
      "extendedDetails": {}
    },
    "42e93829e5310f3cbd905384cd0529f8fffa887f": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3158. Fix test failures in MRv1 due to default framework being set to yarn. Contributed by Hitesh Shah. \n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1181310 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/10/11 5:26 PM",
      "commitName": "42e93829e5310f3cbd905384cd0529f8fffa887f",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "08/09/11 6:44 PM",
      "commitNameOld": "fafe8cd28e726566509c679e19d7da622f29f90d",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 31.95,
      "commitsBetweenForRepo": 222,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,122 +1,124 @@\n     private void runSubtask(org.apache.hadoop.mapred.Task task,\n                             final TaskType taskType,\n                             TaskAttemptId attemptID,\n                             final int numMapTasks,\n                             boolean renameOutputs)\n     throws RuntimeException, IOException {\n       org.apache.hadoop.mapred.TaskAttemptID classicAttemptID \u003d\n           TypeConverter.fromYarn(attemptID);\n \n       try {\n         JobConf conf \u003d new JobConf(getConfig());\n \n         // mark this as an uberized subtask so it can set task counter\n         // (longer-term/FIXME:  could redefine as job counter and send\n         // \"JobCounterEvent\" to JobImpl on [successful] completion of subtask;\n         // will need new Job state-machine transition and JobImpl jobCounters\n         // map to handle)\n         conf.setBoolean(\"mapreduce.task.uberized\", true);\n \n         // META-FIXME: do we want the extra sanity-checking (doneWithMaps,\n         // etc.), or just assume/hope the state machine(s) and uber-AM work\n         // as expected?\n         if (taskType \u003d\u003d TaskType.MAP) {\n           if (doneWithMaps) {\n             LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a map task (\"\n                       + attemptID + \"), but should be finished with maps\");\n             // throw new RuntimeException()  (FIXME: what\u0027s appropriate here?)\n           }\n \n           MapTask map \u003d (MapTask)task;\n \n           //CODE-REVIEWER QUESTION: why not task.getConf() or map.getConf() instead of conf? do we need Task\u0027s localizeConfiguration() run on this first?\n           map.run(conf, umbilical);\n \n           if (renameOutputs) {\n             renameMapOutputForReduce(conf, attemptID, map.getMapOutputFile());\n           }\n           relocalize();\n \n           if (++finishedSubMaps \u003d\u003d numMapTasks) {\n             doneWithMaps \u003d true;\n           }\n \n         } else /* TaskType.REDUCE */ {\n \n           if (!doneWithMaps) {\n             //check if event-queue empty?  whole idea of counting maps vs. checking event queue is a tad wacky...but could enforce ordering (assuming no \"lost events\") at LocalMRAppMaster [CURRENT BUG(?):  doesn\u0027t send reduce event until maps all done]\n             LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a reduce task (\"\n                       + attemptID + \"), but not yet finished with maps\");\n             // throw new RuntimeException()  (FIXME) // or push reduce event back onto end of queue? (probably former)\n           }\n \n           ReduceTask reduce \u003d (ReduceTask)task;\n \n           // a.k.a. \"mapreduce.jobtracker.address\" in LocalJobRunner:\n+          // set framework name to local to make task local\n+          conf.set(MRConfig.FRAMEWORK_NAME, MRConfig.LOCAL_FRAMEWORK_NAME);\n           conf.set(MRConfig.MASTER_ADDRESS, \"local\");  // bypass shuffle\n \n           reduce.run(conf, umbilical);\n           //relocalize();  // needed only if more than one reducer supported (is MAPREDUCE-434 fixed yet?)\n         }\n \n       } catch (FSError e) {\n         LOG.fatal(\"FSError from child\", e);\n         // umbilical:  MRAppMaster creates (taskAttemptListener), passes to us\n         umbilical.fsError(classicAttemptID, e.getMessage());\n         throw new RuntimeException();\n \n       } catch (Exception exception) {\n         LOG.warn(\"Exception running local (uberized) \u0027child\u0027 : \"\n             + StringUtils.stringifyException(exception));\n         try {\n           if (task !\u003d null) {\n             // do cleanup for the task\n //          if (childUGI \u003d\u003d null) { // no need to job into doAs block\n               task.taskCleanup(umbilical);\n //          } else {\n //            final Task taskFinal \u003d task;\n //            childUGI.doAs(new PrivilegedExceptionAction\u003cObject\u003e() {\n //              @Override\n //              public Object run() throws Exception {\n //                taskFinal.taskCleanup(umbilical);\n //                return null;\n //              }\n //            });\n //          }\n           }\n         } catch (Exception e) {\n           LOG.info(\"Exception cleaning up: \"\n               + StringUtils.stringifyException(e));\n         }\n         // Report back any failures, for diagnostic purposes\n         ByteArrayOutputStream baos \u003d new ByteArrayOutputStream();\n         exception.printStackTrace(new PrintStream(baos));\n //      if (classicAttemptID !\u003d null) {\n           umbilical.reportDiagnosticInfo(classicAttemptID, baos.toString());\n //      }\n         throw new RuntimeException();\n \n       } catch (Throwable throwable) {\n         LOG.fatal(\"Error running local (uberized) \u0027child\u0027 : \"\n             + StringUtils.stringifyException(throwable));\n //      if (classicAttemptID !\u003d null) {\n           Throwable tCause \u003d throwable.getCause();\n           String cause \u003d (tCause \u003d\u003d null)\n               ? throwable.getMessage()\n               : StringUtils.stringifyException(tCause);\n           umbilical.fatalError(classicAttemptID, cause);\n //      }\n         throw new RuntimeException();\n \n       } finally {\n /*\n FIXME:  do we need to do any of this stuff?  (guessing not since not in own JVM)\n         RPC.stopProxy(umbilical);\n         DefaultMetricsSystem.shutdown();\n         // Shutting down log4j of the child-vm...\n         // This assumes that on return from Task.run()\n         // there is no more logging done.\n         LogManager.shutdown();\n  */\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void runSubtask(org.apache.hadoop.mapred.Task task,\n                            final TaskType taskType,\n                            TaskAttemptId attemptID,\n                            final int numMapTasks,\n                            boolean renameOutputs)\n    throws RuntimeException, IOException {\n      org.apache.hadoop.mapred.TaskAttemptID classicAttemptID \u003d\n          TypeConverter.fromYarn(attemptID);\n\n      try {\n        JobConf conf \u003d new JobConf(getConfig());\n\n        // mark this as an uberized subtask so it can set task counter\n        // (longer-term/FIXME:  could redefine as job counter and send\n        // \"JobCounterEvent\" to JobImpl on [successful] completion of subtask;\n        // will need new Job state-machine transition and JobImpl jobCounters\n        // map to handle)\n        conf.setBoolean(\"mapreduce.task.uberized\", true);\n\n        // META-FIXME: do we want the extra sanity-checking (doneWithMaps,\n        // etc.), or just assume/hope the state machine(s) and uber-AM work\n        // as expected?\n        if (taskType \u003d\u003d TaskType.MAP) {\n          if (doneWithMaps) {\n            LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a map task (\"\n                      + attemptID + \"), but should be finished with maps\");\n            // throw new RuntimeException()  (FIXME: what\u0027s appropriate here?)\n          }\n\n          MapTask map \u003d (MapTask)task;\n\n          //CODE-REVIEWER QUESTION: why not task.getConf() or map.getConf() instead of conf? do we need Task\u0027s localizeConfiguration() run on this first?\n          map.run(conf, umbilical);\n\n          if (renameOutputs) {\n            renameMapOutputForReduce(conf, attemptID, map.getMapOutputFile());\n          }\n          relocalize();\n\n          if (++finishedSubMaps \u003d\u003d numMapTasks) {\n            doneWithMaps \u003d true;\n          }\n\n        } else /* TaskType.REDUCE */ {\n\n          if (!doneWithMaps) {\n            //check if event-queue empty?  whole idea of counting maps vs. checking event queue is a tad wacky...but could enforce ordering (assuming no \"lost events\") at LocalMRAppMaster [CURRENT BUG(?):  doesn\u0027t send reduce event until maps all done]\n            LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a reduce task (\"\n                      + attemptID + \"), but not yet finished with maps\");\n            // throw new RuntimeException()  (FIXME) // or push reduce event back onto end of queue? (probably former)\n          }\n\n          ReduceTask reduce \u003d (ReduceTask)task;\n\n          // a.k.a. \"mapreduce.jobtracker.address\" in LocalJobRunner:\n          // set framework name to local to make task local\n          conf.set(MRConfig.FRAMEWORK_NAME, MRConfig.LOCAL_FRAMEWORK_NAME);\n          conf.set(MRConfig.MASTER_ADDRESS, \"local\");  // bypass shuffle\n\n          reduce.run(conf, umbilical);\n          //relocalize();  // needed only if more than one reducer supported (is MAPREDUCE-434 fixed yet?)\n        }\n\n      } catch (FSError e) {\n        LOG.fatal(\"FSError from child\", e);\n        // umbilical:  MRAppMaster creates (taskAttemptListener), passes to us\n        umbilical.fsError(classicAttemptID, e.getMessage());\n        throw new RuntimeException();\n\n      } catch (Exception exception) {\n        LOG.warn(\"Exception running local (uberized) \u0027child\u0027 : \"\n            + StringUtils.stringifyException(exception));\n        try {\n          if (task !\u003d null) {\n            // do cleanup for the task\n//          if (childUGI \u003d\u003d null) { // no need to job into doAs block\n              task.taskCleanup(umbilical);\n//          } else {\n//            final Task taskFinal \u003d task;\n//            childUGI.doAs(new PrivilegedExceptionAction\u003cObject\u003e() {\n//              @Override\n//              public Object run() throws Exception {\n//                taskFinal.taskCleanup(umbilical);\n//                return null;\n//              }\n//            });\n//          }\n          }\n        } catch (Exception e) {\n          LOG.info(\"Exception cleaning up: \"\n              + StringUtils.stringifyException(e));\n        }\n        // Report back any failures, for diagnostic purposes\n        ByteArrayOutputStream baos \u003d new ByteArrayOutputStream();\n        exception.printStackTrace(new PrintStream(baos));\n//      if (classicAttemptID !\u003d null) {\n          umbilical.reportDiagnosticInfo(classicAttemptID, baos.toString());\n//      }\n        throw new RuntimeException();\n\n      } catch (Throwable throwable) {\n        LOG.fatal(\"Error running local (uberized) \u0027child\u0027 : \"\n            + StringUtils.stringifyException(throwable));\n//      if (classicAttemptID !\u003d null) {\n          Throwable tCause \u003d throwable.getCause();\n          String cause \u003d (tCause \u003d\u003d null)\n              ? throwable.getMessage()\n              : StringUtils.stringifyException(tCause);\n          umbilical.fatalError(classicAttemptID, cause);\n//      }\n        throw new RuntimeException();\n\n      } finally {\n/*\nFIXME:  do we need to do any of this stuff?  (guessing not since not in own JVM)\n        RPC.stopProxy(umbilical);\n        DefaultMetricsSystem.shutdown();\n        // Shutting down log4j of the child-vm...\n        // This assumes that on return from Task.run()\n        // there is no more logging done.\n        LogManager.shutdown();\n */\n      }\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/LocalContainerLauncher.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    private void runSubtask(org.apache.hadoop.mapred.Task task,\n                            final TaskType taskType,\n                            TaskAttemptId attemptID,\n                            final int numMapTasks,\n                            boolean renameOutputs)\n    throws RuntimeException, IOException {\n      org.apache.hadoop.mapred.TaskAttemptID classicAttemptID \u003d\n          TypeConverter.fromYarn(attemptID);\n\n      try {\n        JobConf conf \u003d new JobConf(getConfig());\n\n        // mark this as an uberized subtask so it can set task counter\n        // (longer-term/FIXME:  could redefine as job counter and send\n        // \"JobCounterEvent\" to JobImpl on [successful] completion of subtask;\n        // will need new Job state-machine transition and JobImpl jobCounters\n        // map to handle)\n        conf.setBoolean(\"mapreduce.task.uberized\", true);\n\n        // META-FIXME: do we want the extra sanity-checking (doneWithMaps,\n        // etc.), or just assume/hope the state machine(s) and uber-AM work\n        // as expected?\n        if (taskType \u003d\u003d TaskType.MAP) {\n          if (doneWithMaps) {\n            LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a map task (\"\n                      + attemptID + \"), but should be finished with maps\");\n            // throw new RuntimeException()  (FIXME: what\u0027s appropriate here?)\n          }\n\n          MapTask map \u003d (MapTask)task;\n\n          //CODE-REVIEWER QUESTION: why not task.getConf() or map.getConf() instead of conf? do we need Task\u0027s localizeConfiguration() run on this first?\n          map.run(conf, umbilical);\n\n          if (renameOutputs) {\n            renameMapOutputForReduce(conf, attemptID, map.getMapOutputFile());\n          }\n          relocalize();\n\n          if (++finishedSubMaps \u003d\u003d numMapTasks) {\n            doneWithMaps \u003d true;\n          }\n\n        } else /* TaskType.REDUCE */ {\n\n          if (!doneWithMaps) {\n            //check if event-queue empty?  whole idea of counting maps vs. checking event queue is a tad wacky...but could enforce ordering (assuming no \"lost events\") at LocalMRAppMaster [CURRENT BUG(?):  doesn\u0027t send reduce event until maps all done]\n            LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a reduce task (\"\n                      + attemptID + \"), but not yet finished with maps\");\n            // throw new RuntimeException()  (FIXME) // or push reduce event back onto end of queue? (probably former)\n          }\n\n          ReduceTask reduce \u003d (ReduceTask)task;\n\n          // a.k.a. \"mapreduce.jobtracker.address\" in LocalJobRunner:\n          conf.set(MRConfig.MASTER_ADDRESS, \"local\");  // bypass shuffle\n\n          reduce.run(conf, umbilical);\n          //relocalize();  // needed only if more than one reducer supported (is MAPREDUCE-434 fixed yet?)\n        }\n\n      } catch (FSError e) {\n        LOG.fatal(\"FSError from child\", e);\n        // umbilical:  MRAppMaster creates (taskAttemptListener), passes to us\n        umbilical.fsError(classicAttemptID, e.getMessage());\n        throw new RuntimeException();\n\n      } catch (Exception exception) {\n        LOG.warn(\"Exception running local (uberized) \u0027child\u0027 : \"\n            + StringUtils.stringifyException(exception));\n        try {\n          if (task !\u003d null) {\n            // do cleanup for the task\n//          if (childUGI \u003d\u003d null) { // no need to job into doAs block\n              task.taskCleanup(umbilical);\n//          } else {\n//            final Task taskFinal \u003d task;\n//            childUGI.doAs(new PrivilegedExceptionAction\u003cObject\u003e() {\n//              @Override\n//              public Object run() throws Exception {\n//                taskFinal.taskCleanup(umbilical);\n//                return null;\n//              }\n//            });\n//          }\n          }\n        } catch (Exception e) {\n          LOG.info(\"Exception cleaning up: \"\n              + StringUtils.stringifyException(e));\n        }\n        // Report back any failures, for diagnostic purposes\n        ByteArrayOutputStream baos \u003d new ByteArrayOutputStream();\n        exception.printStackTrace(new PrintStream(baos));\n//      if (classicAttemptID !\u003d null) {\n          umbilical.reportDiagnosticInfo(classicAttemptID, baos.toString());\n//      }\n        throw new RuntimeException();\n\n      } catch (Throwable throwable) {\n        LOG.fatal(\"Error running local (uberized) \u0027child\u0027 : \"\n            + StringUtils.stringifyException(throwable));\n//      if (classicAttemptID !\u003d null) {\n          Throwable tCause \u003d throwable.getCause();\n          String cause \u003d (tCause \u003d\u003d null)\n              ? throwable.getMessage()\n              : StringUtils.stringifyException(tCause);\n          umbilical.fatalError(classicAttemptID, cause);\n//      }\n        throw new RuntimeException();\n\n      } finally {\n/*\nFIXME:  do we need to do any of this stuff?  (guessing not since not in own JVM)\n        RPC.stopProxy(umbilical);\n        DefaultMetricsSystem.shutdown();\n        // Shutting down log4j of the child-vm...\n        // This assumes that on return from Task.run()\n        // there is no more logging done.\n        LogManager.shutdown();\n */\n      }\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/LocalContainerLauncher.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/LocalContainerLauncher.java",
        "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/LocalContainerLauncher.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "diff": "@@ -0,0 +1,122 @@\n+    private void runSubtask(org.apache.hadoop.mapred.Task task,\n+                            final TaskType taskType,\n+                            TaskAttemptId attemptID,\n+                            final int numMapTasks,\n+                            boolean renameOutputs)\n+    throws RuntimeException, IOException {\n+      org.apache.hadoop.mapred.TaskAttemptID classicAttemptID \u003d\n+          TypeConverter.fromYarn(attemptID);\n+\n+      try {\n+        JobConf conf \u003d new JobConf(getConfig());\n+\n+        // mark this as an uberized subtask so it can set task counter\n+        // (longer-term/FIXME:  could redefine as job counter and send\n+        // \"JobCounterEvent\" to JobImpl on [successful] completion of subtask;\n+        // will need new Job state-machine transition and JobImpl jobCounters\n+        // map to handle)\n+        conf.setBoolean(\"mapreduce.task.uberized\", true);\n+\n+        // META-FIXME: do we want the extra sanity-checking (doneWithMaps,\n+        // etc.), or just assume/hope the state machine(s) and uber-AM work\n+        // as expected?\n+        if (taskType \u003d\u003d TaskType.MAP) {\n+          if (doneWithMaps) {\n+            LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a map task (\"\n+                      + attemptID + \"), but should be finished with maps\");\n+            // throw new RuntimeException()  (FIXME: what\u0027s appropriate here?)\n+          }\n+\n+          MapTask map \u003d (MapTask)task;\n+\n+          //CODE-REVIEWER QUESTION: why not task.getConf() or map.getConf() instead of conf? do we need Task\u0027s localizeConfiguration() run on this first?\n+          map.run(conf, umbilical);\n+\n+          if (renameOutputs) {\n+            renameMapOutputForReduce(conf, attemptID, map.getMapOutputFile());\n+          }\n+          relocalize();\n+\n+          if (++finishedSubMaps \u003d\u003d numMapTasks) {\n+            doneWithMaps \u003d true;\n+          }\n+\n+        } else /* TaskType.REDUCE */ {\n+\n+          if (!doneWithMaps) {\n+            //check if event-queue empty?  whole idea of counting maps vs. checking event queue is a tad wacky...but could enforce ordering (assuming no \"lost events\") at LocalMRAppMaster [CURRENT BUG(?):  doesn\u0027t send reduce event until maps all done]\n+            LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a reduce task (\"\n+                      + attemptID + \"), but not yet finished with maps\");\n+            // throw new RuntimeException()  (FIXME) // or push reduce event back onto end of queue? (probably former)\n+          }\n+\n+          ReduceTask reduce \u003d (ReduceTask)task;\n+\n+          // a.k.a. \"mapreduce.jobtracker.address\" in LocalJobRunner:\n+          conf.set(MRConfig.MASTER_ADDRESS, \"local\");  // bypass shuffle\n+\n+          reduce.run(conf, umbilical);\n+          //relocalize();  // needed only if more than one reducer supported (is MAPREDUCE-434 fixed yet?)\n+        }\n+\n+      } catch (FSError e) {\n+        LOG.fatal(\"FSError from child\", e);\n+        // umbilical:  MRAppMaster creates (taskAttemptListener), passes to us\n+        umbilical.fsError(classicAttemptID, e.getMessage());\n+        throw new RuntimeException();\n+\n+      } catch (Exception exception) {\n+        LOG.warn(\"Exception running local (uberized) \u0027child\u0027 : \"\n+            + StringUtils.stringifyException(exception));\n+        try {\n+          if (task !\u003d null) {\n+            // do cleanup for the task\n+//          if (childUGI \u003d\u003d null) { // no need to job into doAs block\n+              task.taskCleanup(umbilical);\n+//          } else {\n+//            final Task taskFinal \u003d task;\n+//            childUGI.doAs(new PrivilegedExceptionAction\u003cObject\u003e() {\n+//              @Override\n+//              public Object run() throws Exception {\n+//                taskFinal.taskCleanup(umbilical);\n+//                return null;\n+//              }\n+//            });\n+//          }\n+          }\n+        } catch (Exception e) {\n+          LOG.info(\"Exception cleaning up: \"\n+              + StringUtils.stringifyException(e));\n+        }\n+        // Report back any failures, for diagnostic purposes\n+        ByteArrayOutputStream baos \u003d new ByteArrayOutputStream();\n+        exception.printStackTrace(new PrintStream(baos));\n+//      if (classicAttemptID !\u003d null) {\n+          umbilical.reportDiagnosticInfo(classicAttemptID, baos.toString());\n+//      }\n+        throw new RuntimeException();\n+\n+      } catch (Throwable throwable) {\n+        LOG.fatal(\"Error running local (uberized) \u0027child\u0027 : \"\n+            + StringUtils.stringifyException(throwable));\n+//      if (classicAttemptID !\u003d null) {\n+          Throwable tCause \u003d throwable.getCause();\n+          String cause \u003d (tCause \u003d\u003d null)\n+              ? throwable.getMessage()\n+              : StringUtils.stringifyException(tCause);\n+          umbilical.fatalError(classicAttemptID, cause);\n+//      }\n+        throw new RuntimeException();\n+\n+      } finally {\n+/*\n+FIXME:  do we need to do any of this stuff?  (guessing not since not in own JVM)\n+        RPC.stopProxy(umbilical);\n+        DefaultMetricsSystem.shutdown();\n+        // Shutting down log4j of the child-vm...\n+        // This assumes that on return from Task.run()\n+        // there is no more logging done.\n+        LogManager.shutdown();\n+ */\n+      }\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    private void runSubtask(org.apache.hadoop.mapred.Task task,\n                            final TaskType taskType,\n                            TaskAttemptId attemptID,\n                            final int numMapTasks,\n                            boolean renameOutputs)\n    throws RuntimeException, IOException {\n      org.apache.hadoop.mapred.TaskAttemptID classicAttemptID \u003d\n          TypeConverter.fromYarn(attemptID);\n\n      try {\n        JobConf conf \u003d new JobConf(getConfig());\n\n        // mark this as an uberized subtask so it can set task counter\n        // (longer-term/FIXME:  could redefine as job counter and send\n        // \"JobCounterEvent\" to JobImpl on [successful] completion of subtask;\n        // will need new Job state-machine transition and JobImpl jobCounters\n        // map to handle)\n        conf.setBoolean(\"mapreduce.task.uberized\", true);\n\n        // META-FIXME: do we want the extra sanity-checking (doneWithMaps,\n        // etc.), or just assume/hope the state machine(s) and uber-AM work\n        // as expected?\n        if (taskType \u003d\u003d TaskType.MAP) {\n          if (doneWithMaps) {\n            LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a map task (\"\n                      + attemptID + \"), but should be finished with maps\");\n            // throw new RuntimeException()  (FIXME: what\u0027s appropriate here?)\n          }\n\n          MapTask map \u003d (MapTask)task;\n\n          //CODE-REVIEWER QUESTION: why not task.getConf() or map.getConf() instead of conf? do we need Task\u0027s localizeConfiguration() run on this first?\n          map.run(conf, umbilical);\n\n          if (renameOutputs) {\n            renameMapOutputForReduce(conf, attemptID, map.getMapOutputFile());\n          }\n          relocalize();\n\n          if (++finishedSubMaps \u003d\u003d numMapTasks) {\n            doneWithMaps \u003d true;\n          }\n\n        } else /* TaskType.REDUCE */ {\n\n          if (!doneWithMaps) {\n            //check if event-queue empty?  whole idea of counting maps vs. checking event queue is a tad wacky...but could enforce ordering (assuming no \"lost events\") at LocalMRAppMaster [CURRENT BUG(?):  doesn\u0027t send reduce event until maps all done]\n            LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a reduce task (\"\n                      + attemptID + \"), but not yet finished with maps\");\n            // throw new RuntimeException()  (FIXME) // or push reduce event back onto end of queue? (probably former)\n          }\n\n          ReduceTask reduce \u003d (ReduceTask)task;\n\n          // a.k.a. \"mapreduce.jobtracker.address\" in LocalJobRunner:\n          conf.set(MRConfig.MASTER_ADDRESS, \"local\");  // bypass shuffle\n\n          reduce.run(conf, umbilical);\n          //relocalize();  // needed only if more than one reducer supported (is MAPREDUCE-434 fixed yet?)\n        }\n\n      } catch (FSError e) {\n        LOG.fatal(\"FSError from child\", e);\n        // umbilical:  MRAppMaster creates (taskAttemptListener), passes to us\n        umbilical.fsError(classicAttemptID, e.getMessage());\n        throw new RuntimeException();\n\n      } catch (Exception exception) {\n        LOG.warn(\"Exception running local (uberized) \u0027child\u0027 : \"\n            + StringUtils.stringifyException(exception));\n        try {\n          if (task !\u003d null) {\n            // do cleanup for the task\n//          if (childUGI \u003d\u003d null) { // no need to job into doAs block\n              task.taskCleanup(umbilical);\n//          } else {\n//            final Task taskFinal \u003d task;\n//            childUGI.doAs(new PrivilegedExceptionAction\u003cObject\u003e() {\n//              @Override\n//              public Object run() throws Exception {\n//                taskFinal.taskCleanup(umbilical);\n//                return null;\n//              }\n//            });\n//          }\n          }\n        } catch (Exception e) {\n          LOG.info(\"Exception cleaning up: \"\n              + StringUtils.stringifyException(e));\n        }\n        // Report back any failures, for diagnostic purposes\n        ByteArrayOutputStream baos \u003d new ByteArrayOutputStream();\n        exception.printStackTrace(new PrintStream(baos));\n//      if (classicAttemptID !\u003d null) {\n          umbilical.reportDiagnosticInfo(classicAttemptID, baos.toString());\n//      }\n        throw new RuntimeException();\n\n      } catch (Throwable throwable) {\n        LOG.fatal(\"Error running local (uberized) \u0027child\u0027 : \"\n            + StringUtils.stringifyException(throwable));\n//      if (classicAttemptID !\u003d null) {\n          Throwable tCause \u003d throwable.getCause();\n          String cause \u003d (tCause \u003d\u003d null)\n              ? throwable.getMessage()\n              : StringUtils.stringifyException(tCause);\n          umbilical.fatalError(classicAttemptID, cause);\n//      }\n        throw new RuntimeException();\n\n      } finally {\n/*\nFIXME:  do we need to do any of this stuff?  (guessing not since not in own JVM)\n        RPC.stopProxy(umbilical);\n        DefaultMetricsSystem.shutdown();\n        // Shutting down log4j of the child-vm...\n        // This assumes that on return from Task.run()\n        // there is no more logging done.\n        LogManager.shutdown();\n */\n      }\n    }",
      "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/LocalContainerLauncher.java"
    }
  }
}