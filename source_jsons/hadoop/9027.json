{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSNamesystem.java",
  "functionName": "getBlockLocations",
  "functionId": "getBlockLocations___clientMachine-String__srcArg-String__offset-long__length-long",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
  "functionStartLine": 2079,
  "functionEndLine": 2159,
  "numCommitsSeen": 1437,
  "timeTaken": 66602,
  "changeHistory": [
    "1824aee9da4056de0fb638906b2172e486bbebe7",
    "4b95c242eca540455a4d5d0899aaf73b6064b5ea",
    "72003b19bf4c652b53625984d109542abd0cf20e",
    "f600fbb6c4987c69292faea6b5abf022bb213ffd",
    "8c491350789a676cc8fbefab6414773054b9b495",
    "b74a7dbf88fef0dd735921cff84f8025eac9503d",
    "ff013d2c952272f3176dcf624251b05d610503b5",
    "84a1321f6aa0af6895564a7c47f8f264656f0294",
    "ff0b99eafeda035ebe0dc82cfe689808047a8893",
    "9d175853b0170683ad5f21d9bcdeaac49fe89e04",
    "48b9d5fd2a96728b1118be217ca597c4098e99ca",
    "869393643de23dcb010cc33091c8eb398de0fd6c",
    "03dea65e0b17ca2f9460bb6110f6ab3a321b8bf2",
    "6ef42873a02bfcbff5521869f4d6f66539d1db41",
    "015535dc0ad00c2ba357afb3d1e283e56ddda0d6",
    "f05c21285ef23b6a973d69f045b1cb46c5abc039",
    "3dd6395bb2448e5b178a51c864e3c9a3d12e8bc9",
    "832ebd8cb63d91b4aa4bfed412b9799b3b9be4a7",
    "46612c7a5135d20b20403780b47dd00654aab057",
    "d693a252bd0041c2493e7e07a3bf8bcf28e1923c",
    "8e73084491c9f317bc8cc3590f93ca67a63687a8",
    "552b4fb9f9a76b18605322c0b0e8072613d67773",
    "c83c5b868ea34925ecb1597cf1ceb88524ded185",
    "02fcb6b6bae7c3fe2a10b00b2a563e4098ff225e",
    "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a",
    "3fc8792b5c75fca9fc4f6cf4b95fb2927c62e624",
    "d543140089690f4ec877d26981f4ad7908b33d1d",
    "543f86631bf07053a045d5dabcad16fb8f9eff97",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "c3f6575ca44e8ad803d0b46991472465b595cdeb",
    "8327e70be87990c37ac14dcc1cb1a4d209c65593",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "1824aee9da4056de0fb638906b2172e486bbebe7": "Ybodychange",
    "4b95c242eca540455a4d5d0899aaf73b6064b5ea": "Ybodychange",
    "72003b19bf4c652b53625984d109542abd0cf20e": "Ybodychange",
    "f600fbb6c4987c69292faea6b5abf022bb213ffd": "Ybodychange",
    "8c491350789a676cc8fbefab6414773054b9b495": "Ybodychange",
    "b74a7dbf88fef0dd735921cff84f8025eac9503d": "Ybodychange",
    "ff013d2c952272f3176dcf624251b05d610503b5": "Ybodychange",
    "84a1321f6aa0af6895564a7c47f8f264656f0294": "Ybodychange",
    "ff0b99eafeda035ebe0dc82cfe689808047a8893": "Ybodychange",
    "9d175853b0170683ad5f21d9bcdeaac49fe89e04": "Ybodychange",
    "48b9d5fd2a96728b1118be217ca597c4098e99ca": "Ybodychange",
    "869393643de23dcb010cc33091c8eb398de0fd6c": "Ybodychange",
    "03dea65e0b17ca2f9460bb6110f6ab3a321b8bf2": "Ybodychange",
    "6ef42873a02bfcbff5521869f4d6f66539d1db41": "Ybodychange",
    "015535dc0ad00c2ba357afb3d1e283e56ddda0d6": "Ybodychange",
    "f05c21285ef23b6a973d69f045b1cb46c5abc039": "Ybodychange",
    "3dd6395bb2448e5b178a51c864e3c9a3d12e8bc9": "Ymultichange(Yparameterchange,Ybodychange)",
    "832ebd8cb63d91b4aa4bfed412b9799b3b9be4a7": "Ybodychange",
    "46612c7a5135d20b20403780b47dd00654aab057": "Ybodychange",
    "d693a252bd0041c2493e7e07a3bf8bcf28e1923c": "Ymultichange(Yexceptionschange,Ybodychange)",
    "8e73084491c9f317bc8cc3590f93ca67a63687a8": "Ybodychange",
    "552b4fb9f9a76b18605322c0b0e8072613d67773": "Ybodychange",
    "c83c5b868ea34925ecb1597cf1ceb88524ded185": "Ybodychange",
    "02fcb6b6bae7c3fe2a10b00b2a563e4098ff225e": "Ybodychange",
    "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a": "Ybodychange",
    "3fc8792b5c75fca9fc4f6cf4b95fb2927c62e624": "Ybodychange",
    "d543140089690f4ec877d26981f4ad7908b33d1d": "Ybodychange",
    "543f86631bf07053a045d5dabcad16fb8f9eff97": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "c3f6575ca44e8ad803d0b46991472465b595cdeb": "Ybodychange",
    "8327e70be87990c37ac14dcc1cb1a4d209c65593": "Ybodychange",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "1824aee9da4056de0fb638906b2172e486bbebe7": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-15217 Add more information to longest write/read lock held log\n\n",
      "commitDate": "18/04/20 1:52 PM",
      "commitName": "1824aee9da4056de0fb638906b2172e486bbebe7",
      "commitAuthor": "Toshihiro Suzuki",
      "commitDateOld": "25/03/20 10:28 AM",
      "commitNameOld": "a700803a18fb957d2799001a2ce1dcb70f75c080",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 24.14,
      "commitsBetweenForRepo": 78,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,81 +1,81 @@\n   LocatedBlocks getBlockLocations(String clientMachine, String srcArg,\n       long offset, long length) throws IOException {\n     final String operationName \u003d \"open\";\n     checkOperation(OperationCategory.READ);\n     GetBlockLocationsResult res \u003d null;\n     final FSPermissionChecker pc \u003d getPermissionChecker();\n     FSPermissionChecker.setOperationType(operationName);\n     final INode inode;\n     try {\n       readLock();\n       try {\n         checkOperation(OperationCategory.READ);\n         res \u003d FSDirStatAndListingOp.getBlockLocations(\n             dir, pc, srcArg, offset, length, true);\n         inode \u003d res.getIIp().getLastINode();\n         if (isInSafeMode()) {\n           for (LocatedBlock b : res.blocks.getLocatedBlocks()) {\n             // if safemode \u0026 no block locations yet then throw safemodeException\n             if ((b.getLocations() \u003d\u003d null) || (b.getLocations().length \u003d\u003d 0)) {\n               SafeModeException se \u003d newSafemodeException(\n                   \"Zero blocklocations for \" + srcArg);\n               if (haEnabled \u0026\u0026 haContext !\u003d null \u0026\u0026\n                   (haContext.getState().getServiceState() \u003d\u003d ACTIVE ||\n                       haContext.getState().getServiceState() \u003d\u003d OBSERVER)) {\n                 throw new RetriableException(se);\n               } else {\n                 throw se;\n               }\n             }\n           }\n         } else if (haEnabled \u0026\u0026 haContext !\u003d null \u0026\u0026\n             haContext.getState().getServiceState() \u003d\u003d OBSERVER) {\n           for (LocatedBlock b : res.blocks.getLocatedBlocks()) {\n             if (b.getLocations() \u003d\u003d null || b.getLocations().length \u003d\u003d 0) {\n               throw new ObserverRetryOnActiveException(\"Zero blocklocations \"\n                   + \"for \" + srcArg);\n             }\n           }\n         }\n       } finally {\n-        readUnlock(operationName);\n+        readUnlock(operationName, getLockReportInfoSupplier(srcArg));\n       }\n     } catch (AccessControlException e) {\n       logAuditEvent(false, operationName, srcArg);\n       throw e;\n     }\n \n     logAuditEvent(true, operationName, srcArg);\n \n     if (!isInSafeMode() \u0026\u0026 res.updateAccessTime()) {\n       String src \u003d srcArg;\n       checkOperation(OperationCategory.WRITE);\n       try {\n         writeLock();\n         final long now \u003d now();\n         try {\n           checkOperation(OperationCategory.WRITE);\n           boolean updateAccessTime \u003d\n               now \u003e inode.getAccessTime() + dir.getAccessTimePrecision();\n           if (!isInSafeMode() \u0026\u0026 updateAccessTime) {\n             if (!inode.isDeleted()) {\n               src \u003d inode.getFullPathName();\n               final INodesInPath iip \u003d dir.resolvePath(pc, src, DirOp.READ);\n               boolean changed \u003d FSDirAttrOp.setTimes(dir, iip, -1, now, false);\n               if (changed) {\n                 getEditLog().logTimes(src, -1, now);\n               }\n             }\n           }\n         } finally {\n-          writeUnlock(operationName);\n+          writeUnlock(operationName, getLockReportInfoSupplier(srcArg));\n         }\n       } catch (Throwable e) {\n         LOG.warn(\"Failed to update the access time of \" + src, e);\n       }\n     }\n \n     LocatedBlocks blocks \u003d res.blocks;\n     sortLocatedBlocks(clientMachine, blocks);\n     return blocks;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlocks getBlockLocations(String clientMachine, String srcArg,\n      long offset, long length) throws IOException {\n    final String operationName \u003d \"open\";\n    checkOperation(OperationCategory.READ);\n    GetBlockLocationsResult res \u003d null;\n    final FSPermissionChecker pc \u003d getPermissionChecker();\n    FSPermissionChecker.setOperationType(operationName);\n    final INode inode;\n    try {\n      readLock();\n      try {\n        checkOperation(OperationCategory.READ);\n        res \u003d FSDirStatAndListingOp.getBlockLocations(\n            dir, pc, srcArg, offset, length, true);\n        inode \u003d res.getIIp().getLastINode();\n        if (isInSafeMode()) {\n          for (LocatedBlock b : res.blocks.getLocatedBlocks()) {\n            // if safemode \u0026 no block locations yet then throw safemodeException\n            if ((b.getLocations() \u003d\u003d null) || (b.getLocations().length \u003d\u003d 0)) {\n              SafeModeException se \u003d newSafemodeException(\n                  \"Zero blocklocations for \" + srcArg);\n              if (haEnabled \u0026\u0026 haContext !\u003d null \u0026\u0026\n                  (haContext.getState().getServiceState() \u003d\u003d ACTIVE ||\n                      haContext.getState().getServiceState() \u003d\u003d OBSERVER)) {\n                throw new RetriableException(se);\n              } else {\n                throw se;\n              }\n            }\n          }\n        } else if (haEnabled \u0026\u0026 haContext !\u003d null \u0026\u0026\n            haContext.getState().getServiceState() \u003d\u003d OBSERVER) {\n          for (LocatedBlock b : res.blocks.getLocatedBlocks()) {\n            if (b.getLocations() \u003d\u003d null || b.getLocations().length \u003d\u003d 0) {\n              throw new ObserverRetryOnActiveException(\"Zero blocklocations \"\n                  + \"for \" + srcArg);\n            }\n          }\n        }\n      } finally {\n        readUnlock(operationName, getLockReportInfoSupplier(srcArg));\n      }\n    } catch (AccessControlException e) {\n      logAuditEvent(false, operationName, srcArg);\n      throw e;\n    }\n\n    logAuditEvent(true, operationName, srcArg);\n\n    if (!isInSafeMode() \u0026\u0026 res.updateAccessTime()) {\n      String src \u003d srcArg;\n      checkOperation(OperationCategory.WRITE);\n      try {\n        writeLock();\n        final long now \u003d now();\n        try {\n          checkOperation(OperationCategory.WRITE);\n          boolean updateAccessTime \u003d\n              now \u003e inode.getAccessTime() + dir.getAccessTimePrecision();\n          if (!isInSafeMode() \u0026\u0026 updateAccessTime) {\n            if (!inode.isDeleted()) {\n              src \u003d inode.getFullPathName();\n              final INodesInPath iip \u003d dir.resolvePath(pc, src, DirOp.READ);\n              boolean changed \u003d FSDirAttrOp.setTimes(dir, iip, -1, now, false);\n              if (changed) {\n                getEditLog().logTimes(src, -1, now);\n              }\n            }\n          }\n        } finally {\n          writeUnlock(operationName, getLockReportInfoSupplier(srcArg));\n        }\n      } catch (Throwable e) {\n        LOG.warn(\"Failed to update the access time of \" + src, e);\n      }\n    }\n\n    LocatedBlocks blocks \u003d res.blocks;\n    sortLocatedBlocks(clientMachine, blocks);\n    return blocks;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "4b95c242eca540455a4d5d0899aaf73b6064b5ea": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14743. Enhance INodeAttributeProvider/ AccessControlEnforcer Interface in HDFS to support Authorization of mkdir, rm, rmdir, copy, move etc... (#1829)\n\nReviewed-by: Xiaoyu Yao \u003cxyao@apache.org\u003e",
      "commitDate": "13/03/20 11:29 AM",
      "commitName": "4b95c242eca540455a4d5d0899aaf73b6064b5ea",
      "commitAuthor": "Wei-Chiu Chuang",
      "commitDateOld": "27/02/20 8:49 AM",
      "commitNameOld": "cd2c6b1aac470991b9b90339ce2721ba179e7c48",
      "commitAuthorOld": "Ayush Saxena",
      "daysBetweenCommits": 15.07,
      "commitsBetweenForRepo": 51,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,80 +1,81 @@\n   LocatedBlocks getBlockLocations(String clientMachine, String srcArg,\n       long offset, long length) throws IOException {\n     final String operationName \u003d \"open\";\n     checkOperation(OperationCategory.READ);\n     GetBlockLocationsResult res \u003d null;\n     final FSPermissionChecker pc \u003d getPermissionChecker();\n+    FSPermissionChecker.setOperationType(operationName);\n     final INode inode;\n     try {\n       readLock();\n       try {\n         checkOperation(OperationCategory.READ);\n         res \u003d FSDirStatAndListingOp.getBlockLocations(\n             dir, pc, srcArg, offset, length, true);\n         inode \u003d res.getIIp().getLastINode();\n         if (isInSafeMode()) {\n           for (LocatedBlock b : res.blocks.getLocatedBlocks()) {\n             // if safemode \u0026 no block locations yet then throw safemodeException\n             if ((b.getLocations() \u003d\u003d null) || (b.getLocations().length \u003d\u003d 0)) {\n               SafeModeException se \u003d newSafemodeException(\n                   \"Zero blocklocations for \" + srcArg);\n               if (haEnabled \u0026\u0026 haContext !\u003d null \u0026\u0026\n                   (haContext.getState().getServiceState() \u003d\u003d ACTIVE ||\n                       haContext.getState().getServiceState() \u003d\u003d OBSERVER)) {\n                 throw new RetriableException(se);\n               } else {\n                 throw se;\n               }\n             }\n           }\n         } else if (haEnabled \u0026\u0026 haContext !\u003d null \u0026\u0026\n             haContext.getState().getServiceState() \u003d\u003d OBSERVER) {\n           for (LocatedBlock b : res.blocks.getLocatedBlocks()) {\n             if (b.getLocations() \u003d\u003d null || b.getLocations().length \u003d\u003d 0) {\n               throw new ObserverRetryOnActiveException(\"Zero blocklocations \"\n                   + \"for \" + srcArg);\n             }\n           }\n         }\n       } finally {\n         readUnlock(operationName);\n       }\n     } catch (AccessControlException e) {\n       logAuditEvent(false, operationName, srcArg);\n       throw e;\n     }\n \n     logAuditEvent(true, operationName, srcArg);\n \n     if (!isInSafeMode() \u0026\u0026 res.updateAccessTime()) {\n       String src \u003d srcArg;\n       checkOperation(OperationCategory.WRITE);\n       try {\n         writeLock();\n         final long now \u003d now();\n         try {\n           checkOperation(OperationCategory.WRITE);\n           boolean updateAccessTime \u003d\n               now \u003e inode.getAccessTime() + dir.getAccessTimePrecision();\n           if (!isInSafeMode() \u0026\u0026 updateAccessTime) {\n             if (!inode.isDeleted()) {\n               src \u003d inode.getFullPathName();\n               final INodesInPath iip \u003d dir.resolvePath(pc, src, DirOp.READ);\n               boolean changed \u003d FSDirAttrOp.setTimes(dir, iip, -1, now, false);\n               if (changed) {\n                 getEditLog().logTimes(src, -1, now);\n               }\n             }\n           }\n         } finally {\n           writeUnlock(operationName);\n         }\n       } catch (Throwable e) {\n         LOG.warn(\"Failed to update the access time of \" + src, e);\n       }\n     }\n \n     LocatedBlocks blocks \u003d res.blocks;\n     sortLocatedBlocks(clientMachine, blocks);\n     return blocks;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlocks getBlockLocations(String clientMachine, String srcArg,\n      long offset, long length) throws IOException {\n    final String operationName \u003d \"open\";\n    checkOperation(OperationCategory.READ);\n    GetBlockLocationsResult res \u003d null;\n    final FSPermissionChecker pc \u003d getPermissionChecker();\n    FSPermissionChecker.setOperationType(operationName);\n    final INode inode;\n    try {\n      readLock();\n      try {\n        checkOperation(OperationCategory.READ);\n        res \u003d FSDirStatAndListingOp.getBlockLocations(\n            dir, pc, srcArg, offset, length, true);\n        inode \u003d res.getIIp().getLastINode();\n        if (isInSafeMode()) {\n          for (LocatedBlock b : res.blocks.getLocatedBlocks()) {\n            // if safemode \u0026 no block locations yet then throw safemodeException\n            if ((b.getLocations() \u003d\u003d null) || (b.getLocations().length \u003d\u003d 0)) {\n              SafeModeException se \u003d newSafemodeException(\n                  \"Zero blocklocations for \" + srcArg);\n              if (haEnabled \u0026\u0026 haContext !\u003d null \u0026\u0026\n                  (haContext.getState().getServiceState() \u003d\u003d ACTIVE ||\n                      haContext.getState().getServiceState() \u003d\u003d OBSERVER)) {\n                throw new RetriableException(se);\n              } else {\n                throw se;\n              }\n            }\n          }\n        } else if (haEnabled \u0026\u0026 haContext !\u003d null \u0026\u0026\n            haContext.getState().getServiceState() \u003d\u003d OBSERVER) {\n          for (LocatedBlock b : res.blocks.getLocatedBlocks()) {\n            if (b.getLocations() \u003d\u003d null || b.getLocations().length \u003d\u003d 0) {\n              throw new ObserverRetryOnActiveException(\"Zero blocklocations \"\n                  + \"for \" + srcArg);\n            }\n          }\n        }\n      } finally {\n        readUnlock(operationName);\n      }\n    } catch (AccessControlException e) {\n      logAuditEvent(false, operationName, srcArg);\n      throw e;\n    }\n\n    logAuditEvent(true, operationName, srcArg);\n\n    if (!isInSafeMode() \u0026\u0026 res.updateAccessTime()) {\n      String src \u003d srcArg;\n      checkOperation(OperationCategory.WRITE);\n      try {\n        writeLock();\n        final long now \u003d now();\n        try {\n          checkOperation(OperationCategory.WRITE);\n          boolean updateAccessTime \u003d\n              now \u003e inode.getAccessTime() + dir.getAccessTimePrecision();\n          if (!isInSafeMode() \u0026\u0026 updateAccessTime) {\n            if (!inode.isDeleted()) {\n              src \u003d inode.getFullPathName();\n              final INodesInPath iip \u003d dir.resolvePath(pc, src, DirOp.READ);\n              boolean changed \u003d FSDirAttrOp.setTimes(dir, iip, -1, now, false);\n              if (changed) {\n                getEditLog().logTimes(src, -1, now);\n              }\n            }\n          }\n        } finally {\n          writeUnlock(operationName);\n        }\n      } catch (Throwable e) {\n        LOG.warn(\"Failed to update the access time of \" + src, e);\n      }\n    }\n\n    LocatedBlocks blocks \u003d res.blocks;\n    sortLocatedBlocks(clientMachine, blocks);\n    return blocks;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "72003b19bf4c652b53625984d109542abd0cf20e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13901. INode access time is ignored because of race between open and rename. Contributed by Jinglun.\n",
      "commitDate": "21/10/19 5:31 PM",
      "commitName": "72003b19bf4c652b53625984d109542abd0cf20e",
      "commitAuthor": "Wei-Chiu Chuang",
      "commitDateOld": "17/10/19 9:26 AM",
      "commitNameOld": "5527d79adb9b1e2f2779c283f81d6a3d5447babc",
      "commitAuthorOld": "Ayush Saxena",
      "daysBetweenCommits": 4.34,
      "commitsBetweenForRepo": 15,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,96 +1,80 @@\n   LocatedBlocks getBlockLocations(String clientMachine, String srcArg,\n       long offset, long length) throws IOException {\n     final String operationName \u003d \"open\";\n     checkOperation(OperationCategory.READ);\n     GetBlockLocationsResult res \u003d null;\n     final FSPermissionChecker pc \u003d getPermissionChecker();\n+    final INode inode;\n     try {\n       readLock();\n       try {\n         checkOperation(OperationCategory.READ);\n         res \u003d FSDirStatAndListingOp.getBlockLocations(\n             dir, pc, srcArg, offset, length, true);\n+        inode \u003d res.getIIp().getLastINode();\n         if (isInSafeMode()) {\n           for (LocatedBlock b : res.blocks.getLocatedBlocks()) {\n             // if safemode \u0026 no block locations yet then throw safemodeException\n             if ((b.getLocations() \u003d\u003d null) || (b.getLocations().length \u003d\u003d 0)) {\n               SafeModeException se \u003d newSafemodeException(\n                   \"Zero blocklocations for \" + srcArg);\n               if (haEnabled \u0026\u0026 haContext !\u003d null \u0026\u0026\n                   (haContext.getState().getServiceState() \u003d\u003d ACTIVE ||\n                       haContext.getState().getServiceState() \u003d\u003d OBSERVER)) {\n                 throw new RetriableException(se);\n               } else {\n                 throw se;\n               }\n             }\n           }\n         } else if (haEnabled \u0026\u0026 haContext !\u003d null \u0026\u0026\n             haContext.getState().getServiceState() \u003d\u003d OBSERVER) {\n           for (LocatedBlock b : res.blocks.getLocatedBlocks()) {\n             if (b.getLocations() \u003d\u003d null || b.getLocations().length \u003d\u003d 0) {\n               throw new ObserverRetryOnActiveException(\"Zero blocklocations \"\n                   + \"for \" + srcArg);\n             }\n           }\n         }\n       } finally {\n         readUnlock(operationName);\n       }\n     } catch (AccessControlException e) {\n       logAuditEvent(false, operationName, srcArg);\n       throw e;\n     }\n \n     logAuditEvent(true, operationName, srcArg);\n \n     if (!isInSafeMode() \u0026\u0026 res.updateAccessTime()) {\n       String src \u003d srcArg;\n       checkOperation(OperationCategory.WRITE);\n       try {\n         writeLock();\n         final long now \u003d now();\n         try {\n           checkOperation(OperationCategory.WRITE);\n-          /**\n-           * Resolve the path again and update the atime only when the file\n-           * exists.\n-           *\n-           * XXX: Races can still occur even after resolving the path again.\n-           * For example:\n-           *\n-           * \u003cul\u003e\n-           *   \u003cli\u003eGet the block location for \"/a/b\"\u003c/li\u003e\n-           *   \u003cli\u003eRename \"/a/b\" to \"/c/b\"\u003c/li\u003e\n-           *   \u003cli\u003eThe second resolution still points to \"/a/b\", which is\n-           *   wrong.\u003c/li\u003e\n-           * \u003c/ul\u003e\n-           *\n-           * The behavior is incorrect but consistent with the one before\n-           * HDFS-7463. A better fix is to change the edit log of SetTime to\n-           * use inode id instead of a path.\n-           */\n-          final INodesInPath iip \u003d dir.resolvePath(pc, srcArg, DirOp.READ);\n-          src \u003d iip.getPath();\n-\n-          INode inode \u003d iip.getLastINode();\n-          boolean updateAccessTime \u003d inode !\u003d null \u0026\u0026\n+          boolean updateAccessTime \u003d\n               now \u003e inode.getAccessTime() + dir.getAccessTimePrecision();\n           if (!isInSafeMode() \u0026\u0026 updateAccessTime) {\n-            boolean changed \u003d FSDirAttrOp.setTimes(dir, iip, -1, now, false);\n-            if (changed) {\n-              getEditLog().logTimes(src, -1, now);\n+            if (!inode.isDeleted()) {\n+              src \u003d inode.getFullPathName();\n+              final INodesInPath iip \u003d dir.resolvePath(pc, src, DirOp.READ);\n+              boolean changed \u003d FSDirAttrOp.setTimes(dir, iip, -1, now, false);\n+              if (changed) {\n+                getEditLog().logTimes(src, -1, now);\n+              }\n             }\n           }\n         } finally {\n           writeUnlock(operationName);\n         }\n       } catch (Throwable e) {\n         LOG.warn(\"Failed to update the access time of \" + src, e);\n       }\n     }\n \n     LocatedBlocks blocks \u003d res.blocks;\n     sortLocatedBlocks(clientMachine, blocks);\n     return blocks;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlocks getBlockLocations(String clientMachine, String srcArg,\n      long offset, long length) throws IOException {\n    final String operationName \u003d \"open\";\n    checkOperation(OperationCategory.READ);\n    GetBlockLocationsResult res \u003d null;\n    final FSPermissionChecker pc \u003d getPermissionChecker();\n    final INode inode;\n    try {\n      readLock();\n      try {\n        checkOperation(OperationCategory.READ);\n        res \u003d FSDirStatAndListingOp.getBlockLocations(\n            dir, pc, srcArg, offset, length, true);\n        inode \u003d res.getIIp().getLastINode();\n        if (isInSafeMode()) {\n          for (LocatedBlock b : res.blocks.getLocatedBlocks()) {\n            // if safemode \u0026 no block locations yet then throw safemodeException\n            if ((b.getLocations() \u003d\u003d null) || (b.getLocations().length \u003d\u003d 0)) {\n              SafeModeException se \u003d newSafemodeException(\n                  \"Zero blocklocations for \" + srcArg);\n              if (haEnabled \u0026\u0026 haContext !\u003d null \u0026\u0026\n                  (haContext.getState().getServiceState() \u003d\u003d ACTIVE ||\n                      haContext.getState().getServiceState() \u003d\u003d OBSERVER)) {\n                throw new RetriableException(se);\n              } else {\n                throw se;\n              }\n            }\n          }\n        } else if (haEnabled \u0026\u0026 haContext !\u003d null \u0026\u0026\n            haContext.getState().getServiceState() \u003d\u003d OBSERVER) {\n          for (LocatedBlock b : res.blocks.getLocatedBlocks()) {\n            if (b.getLocations() \u003d\u003d null || b.getLocations().length \u003d\u003d 0) {\n              throw new ObserverRetryOnActiveException(\"Zero blocklocations \"\n                  + \"for \" + srcArg);\n            }\n          }\n        }\n      } finally {\n        readUnlock(operationName);\n      }\n    } catch (AccessControlException e) {\n      logAuditEvent(false, operationName, srcArg);\n      throw e;\n    }\n\n    logAuditEvent(true, operationName, srcArg);\n\n    if (!isInSafeMode() \u0026\u0026 res.updateAccessTime()) {\n      String src \u003d srcArg;\n      checkOperation(OperationCategory.WRITE);\n      try {\n        writeLock();\n        final long now \u003d now();\n        try {\n          checkOperation(OperationCategory.WRITE);\n          boolean updateAccessTime \u003d\n              now \u003e inode.getAccessTime() + dir.getAccessTimePrecision();\n          if (!isInSafeMode() \u0026\u0026 updateAccessTime) {\n            if (!inode.isDeleted()) {\n              src \u003d inode.getFullPathName();\n              final INodesInPath iip \u003d dir.resolvePath(pc, src, DirOp.READ);\n              boolean changed \u003d FSDirAttrOp.setTimes(dir, iip, -1, now, false);\n              if (changed) {\n                getEditLog().logTimes(src, -1, now);\n              }\n            }\n          }\n        } finally {\n          writeUnlock(operationName);\n        }\n      } catch (Throwable e) {\n        LOG.warn(\"Failed to update the access time of \" + src, e);\n      }\n    }\n\n    LocatedBlocks blocks \u003d res.blocks;\n    sortLocatedBlocks(clientMachine, blocks);\n    return blocks;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "f600fbb6c4987c69292faea6b5abf022bb213ffd": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11246. FSNameSystem#logAuditEvent should be called outside the read or write locks. Contributed by He Xiaoqiao, Kuhu Shukla.\n\nSigned-off-by: Wei-Chiu Chuang \u003cweichiu@apache.org\u003e\nCo-authored-by: Kuhu Shukla \u003ckshukla@apache.org\u003e\n",
      "commitDate": "29/08/19 10:10 AM",
      "commitName": "f600fbb6c4987c69292faea6b5abf022bb213ffd",
      "commitAuthor": "He Xiaoqiao",
      "commitDateOld": "27/08/19 3:26 PM",
      "commitNameOld": "dde9399b37bffb77da17c025f0b9b673d7088bc6",
      "commitAuthorOld": "He Xiaoqiao",
      "daysBetweenCommits": 1.78,
      "commitsBetweenForRepo": 27,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,92 +1,96 @@\n   LocatedBlocks getBlockLocations(String clientMachine, String srcArg,\n       long offset, long length) throws IOException {\n     final String operationName \u003d \"open\";\n     checkOperation(OperationCategory.READ);\n     GetBlockLocationsResult res \u003d null;\n     final FSPermissionChecker pc \u003d getPermissionChecker();\n-    readLock();\n     try {\n-      checkOperation(OperationCategory.READ);\n-      res \u003d FSDirStatAndListingOp.getBlockLocations(\n-          dir, pc, srcArg, offset, length, true);\n-      if (isInSafeMode()) {\n-        for (LocatedBlock b : res.blocks.getLocatedBlocks()) {\n-          // if safemode \u0026 no block locations yet then throw safemodeException\n-          if ((b.getLocations() \u003d\u003d null) || (b.getLocations().length \u003d\u003d 0)) {\n-            SafeModeException se \u003d newSafemodeException(\n-                \"Zero blocklocations for \" + srcArg);\n-            if (haEnabled \u0026\u0026 haContext !\u003d null \u0026\u0026\n-                (haContext.getState().getServiceState() \u003d\u003d ACTIVE ||\n-                    haContext.getState().getServiceState() \u003d\u003d OBSERVER)) {\n-              throw new RetriableException(se);\n-            } else {\n-              throw se;\n+      readLock();\n+      try {\n+        checkOperation(OperationCategory.READ);\n+        res \u003d FSDirStatAndListingOp.getBlockLocations(\n+            dir, pc, srcArg, offset, length, true);\n+        if (isInSafeMode()) {\n+          for (LocatedBlock b : res.blocks.getLocatedBlocks()) {\n+            // if safemode \u0026 no block locations yet then throw safemodeException\n+            if ((b.getLocations() \u003d\u003d null) || (b.getLocations().length \u003d\u003d 0)) {\n+              SafeModeException se \u003d newSafemodeException(\n+                  \"Zero blocklocations for \" + srcArg);\n+              if (haEnabled \u0026\u0026 haContext !\u003d null \u0026\u0026\n+                  (haContext.getState().getServiceState() \u003d\u003d ACTIVE ||\n+                      haContext.getState().getServiceState() \u003d\u003d OBSERVER)) {\n+                throw new RetriableException(se);\n+              } else {\n+                throw se;\n+              }\n+            }\n+          }\n+        } else if (haEnabled \u0026\u0026 haContext !\u003d null \u0026\u0026\n+            haContext.getState().getServiceState() \u003d\u003d OBSERVER) {\n+          for (LocatedBlock b : res.blocks.getLocatedBlocks()) {\n+            if (b.getLocations() \u003d\u003d null || b.getLocations().length \u003d\u003d 0) {\n+              throw new ObserverRetryOnActiveException(\"Zero blocklocations \"\n+                  + \"for \" + srcArg);\n             }\n           }\n         }\n-      } else if (haEnabled \u0026\u0026 haContext !\u003d null \u0026\u0026\n-          haContext.getState().getServiceState() \u003d\u003d OBSERVER) {\n-        for (LocatedBlock b : res.blocks.getLocatedBlocks()) {\n-          if (b.getLocations() \u003d\u003d null || b.getLocations().length \u003d\u003d 0) {\n-            throw new ObserverRetryOnActiveException(\"Zero blocklocations for \"\n-                + srcArg);\n-          }\n-        }\n+      } finally {\n+        readUnlock(operationName);\n       }\n     } catch (AccessControlException e) {\n       logAuditEvent(false, operationName, srcArg);\n       throw e;\n-    } finally {\n-      readUnlock(operationName);\n     }\n \n     logAuditEvent(true, operationName, srcArg);\n \n     if (!isInSafeMode() \u0026\u0026 res.updateAccessTime()) {\n       String src \u003d srcArg;\n       checkOperation(OperationCategory.WRITE);\n-      writeLock();\n-      final long now \u003d now();\n       try {\n-        checkOperation(OperationCategory.WRITE);\n-        /**\n-         * Resolve the path again and update the atime only when the file\n-         * exists.\n-         *\n-         * XXX: Races can still occur even after resolving the path again.\n-         * For example:\n-         *\n-         * \u003cul\u003e\n-         *   \u003cli\u003eGet the block location for \"/a/b\"\u003c/li\u003e\n-         *   \u003cli\u003eRename \"/a/b\" to \"/c/b\"\u003c/li\u003e\n-         *   \u003cli\u003eThe second resolution still points to \"/a/b\", which is\n-         *   wrong.\u003c/li\u003e\n-         * \u003c/ul\u003e\n-         *\n-         * The behavior is incorrect but consistent with the one before\n-         * HDFS-7463. A better fix is to change the edit log of SetTime to\n-         * use inode id instead of a path.\n-         */\n-        final INodesInPath iip \u003d dir.resolvePath(pc, srcArg, DirOp.READ);\n-        src \u003d iip.getPath();\n+        writeLock();\n+        final long now \u003d now();\n+        try {\n+          checkOperation(OperationCategory.WRITE);\n+          /**\n+           * Resolve the path again and update the atime only when the file\n+           * exists.\n+           *\n+           * XXX: Races can still occur even after resolving the path again.\n+           * For example:\n+           *\n+           * \u003cul\u003e\n+           *   \u003cli\u003eGet the block location for \"/a/b\"\u003c/li\u003e\n+           *   \u003cli\u003eRename \"/a/b\" to \"/c/b\"\u003c/li\u003e\n+           *   \u003cli\u003eThe second resolution still points to \"/a/b\", which is\n+           *   wrong.\u003c/li\u003e\n+           * \u003c/ul\u003e\n+           *\n+           * The behavior is incorrect but consistent with the one before\n+           * HDFS-7463. A better fix is to change the edit log of SetTime to\n+           * use inode id instead of a path.\n+           */\n+          final INodesInPath iip \u003d dir.resolvePath(pc, srcArg, DirOp.READ);\n+          src \u003d iip.getPath();\n \n-        INode inode \u003d iip.getLastINode();\n-        boolean updateAccessTime \u003d inode !\u003d null \u0026\u0026\n-            now \u003e inode.getAccessTime() + dir.getAccessTimePrecision();\n-        if (!isInSafeMode() \u0026\u0026 updateAccessTime) {\n-          boolean changed \u003d FSDirAttrOp.setTimes(dir, iip, -1, now, false);\n-          if (changed) {\n-            getEditLog().logTimes(src, -1, now);\n+          INode inode \u003d iip.getLastINode();\n+          boolean updateAccessTime \u003d inode !\u003d null \u0026\u0026\n+              now \u003e inode.getAccessTime() + dir.getAccessTimePrecision();\n+          if (!isInSafeMode() \u0026\u0026 updateAccessTime) {\n+            boolean changed \u003d FSDirAttrOp.setTimes(dir, iip, -1, now, false);\n+            if (changed) {\n+              getEditLog().logTimes(src, -1, now);\n+            }\n           }\n+        } finally {\n+          writeUnlock(operationName);\n         }\n       } catch (Throwable e) {\n         LOG.warn(\"Failed to update the access time of \" + src, e);\n-      } finally {\n-        writeUnlock(operationName);\n       }\n     }\n \n     LocatedBlocks blocks \u003d res.blocks;\n     sortLocatedBlocks(clientMachine, blocks);\n     return blocks;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlocks getBlockLocations(String clientMachine, String srcArg,\n      long offset, long length) throws IOException {\n    final String operationName \u003d \"open\";\n    checkOperation(OperationCategory.READ);\n    GetBlockLocationsResult res \u003d null;\n    final FSPermissionChecker pc \u003d getPermissionChecker();\n    try {\n      readLock();\n      try {\n        checkOperation(OperationCategory.READ);\n        res \u003d FSDirStatAndListingOp.getBlockLocations(\n            dir, pc, srcArg, offset, length, true);\n        if (isInSafeMode()) {\n          for (LocatedBlock b : res.blocks.getLocatedBlocks()) {\n            // if safemode \u0026 no block locations yet then throw safemodeException\n            if ((b.getLocations() \u003d\u003d null) || (b.getLocations().length \u003d\u003d 0)) {\n              SafeModeException se \u003d newSafemodeException(\n                  \"Zero blocklocations for \" + srcArg);\n              if (haEnabled \u0026\u0026 haContext !\u003d null \u0026\u0026\n                  (haContext.getState().getServiceState() \u003d\u003d ACTIVE ||\n                      haContext.getState().getServiceState() \u003d\u003d OBSERVER)) {\n                throw new RetriableException(se);\n              } else {\n                throw se;\n              }\n            }\n          }\n        } else if (haEnabled \u0026\u0026 haContext !\u003d null \u0026\u0026\n            haContext.getState().getServiceState() \u003d\u003d OBSERVER) {\n          for (LocatedBlock b : res.blocks.getLocatedBlocks()) {\n            if (b.getLocations() \u003d\u003d null || b.getLocations().length \u003d\u003d 0) {\n              throw new ObserverRetryOnActiveException(\"Zero blocklocations \"\n                  + \"for \" + srcArg);\n            }\n          }\n        }\n      } finally {\n        readUnlock(operationName);\n      }\n    } catch (AccessControlException e) {\n      logAuditEvent(false, operationName, srcArg);\n      throw e;\n    }\n\n    logAuditEvent(true, operationName, srcArg);\n\n    if (!isInSafeMode() \u0026\u0026 res.updateAccessTime()) {\n      String src \u003d srcArg;\n      checkOperation(OperationCategory.WRITE);\n      try {\n        writeLock();\n        final long now \u003d now();\n        try {\n          checkOperation(OperationCategory.WRITE);\n          /**\n           * Resolve the path again and update the atime only when the file\n           * exists.\n           *\n           * XXX: Races can still occur even after resolving the path again.\n           * For example:\n           *\n           * \u003cul\u003e\n           *   \u003cli\u003eGet the block location for \"/a/b\"\u003c/li\u003e\n           *   \u003cli\u003eRename \"/a/b\" to \"/c/b\"\u003c/li\u003e\n           *   \u003cli\u003eThe second resolution still points to \"/a/b\", which is\n           *   wrong.\u003c/li\u003e\n           * \u003c/ul\u003e\n           *\n           * The behavior is incorrect but consistent with the one before\n           * HDFS-7463. A better fix is to change the edit log of SetTime to\n           * use inode id instead of a path.\n           */\n          final INodesInPath iip \u003d dir.resolvePath(pc, srcArg, DirOp.READ);\n          src \u003d iip.getPath();\n\n          INode inode \u003d iip.getLastINode();\n          boolean updateAccessTime \u003d inode !\u003d null \u0026\u0026\n              now \u003e inode.getAccessTime() + dir.getAccessTimePrecision();\n          if (!isInSafeMode() \u0026\u0026 updateAccessTime) {\n            boolean changed \u003d FSDirAttrOp.setTimes(dir, iip, -1, now, false);\n            if (changed) {\n              getEditLog().logTimes(src, -1, now);\n            }\n          }\n        } finally {\n          writeUnlock(operationName);\n        }\n      } catch (Throwable e) {\n        LOG.warn(\"Failed to update the access time of \" + src, e);\n      }\n    }\n\n    LocatedBlocks blocks \u003d res.blocks;\n    sortLocatedBlocks(clientMachine, blocks);\n    return blocks;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "8c491350789a676cc8fbefab6414773054b9b495": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13924. [SBN read] Handle BlockMissingException when reading from observer. Contributed by Chao Sun.\n",
      "commitDate": "24/12/18 9:34 AM",
      "commitName": "8c491350789a676cc8fbefab6414773054b9b495",
      "commitAuthor": "Chao Sun",
      "commitDateOld": "24/12/18 9:34 AM",
      "commitNameOld": "b74a7dbf88fef0dd735921cff84f8025eac9503d",
      "commitAuthorOld": "Erik Krogen",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,84 +1,92 @@\n   LocatedBlocks getBlockLocations(String clientMachine, String srcArg,\n       long offset, long length) throws IOException {\n     final String operationName \u003d \"open\";\n     checkOperation(OperationCategory.READ);\n     GetBlockLocationsResult res \u003d null;\n     final FSPermissionChecker pc \u003d getPermissionChecker();\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n       res \u003d FSDirStatAndListingOp.getBlockLocations(\n           dir, pc, srcArg, offset, length, true);\n       if (isInSafeMode()) {\n         for (LocatedBlock b : res.blocks.getLocatedBlocks()) {\n           // if safemode \u0026 no block locations yet then throw safemodeException\n           if ((b.getLocations() \u003d\u003d null) || (b.getLocations().length \u003d\u003d 0)) {\n             SafeModeException se \u003d newSafemodeException(\n                 \"Zero blocklocations for \" + srcArg);\n             if (haEnabled \u0026\u0026 haContext !\u003d null \u0026\u0026\n                 (haContext.getState().getServiceState() \u003d\u003d ACTIVE ||\n                     haContext.getState().getServiceState() \u003d\u003d OBSERVER)) {\n               throw new RetriableException(se);\n             } else {\n               throw se;\n             }\n           }\n         }\n+      } else if (haEnabled \u0026\u0026 haContext !\u003d null \u0026\u0026\n+          haContext.getState().getServiceState() \u003d\u003d OBSERVER) {\n+        for (LocatedBlock b : res.blocks.getLocatedBlocks()) {\n+          if (b.getLocations() \u003d\u003d null || b.getLocations().length \u003d\u003d 0) {\n+            throw new ObserverRetryOnActiveException(\"Zero blocklocations for \"\n+                + srcArg);\n+          }\n+        }\n       }\n     } catch (AccessControlException e) {\n       logAuditEvent(false, operationName, srcArg);\n       throw e;\n     } finally {\n       readUnlock(operationName);\n     }\n \n     logAuditEvent(true, operationName, srcArg);\n \n     if (!isInSafeMode() \u0026\u0026 res.updateAccessTime()) {\n       String src \u003d srcArg;\n       checkOperation(OperationCategory.WRITE);\n       writeLock();\n       final long now \u003d now();\n       try {\n         checkOperation(OperationCategory.WRITE);\n         /**\n          * Resolve the path again and update the atime only when the file\n          * exists.\n          *\n          * XXX: Races can still occur even after resolving the path again.\n          * For example:\n          *\n          * \u003cul\u003e\n          *   \u003cli\u003eGet the block location for \"/a/b\"\u003c/li\u003e\n          *   \u003cli\u003eRename \"/a/b\" to \"/c/b\"\u003c/li\u003e\n          *   \u003cli\u003eThe second resolution still points to \"/a/b\", which is\n          *   wrong.\u003c/li\u003e\n          * \u003c/ul\u003e\n          *\n          * The behavior is incorrect but consistent with the one before\n          * HDFS-7463. A better fix is to change the edit log of SetTime to\n          * use inode id instead of a path.\n          */\n         final INodesInPath iip \u003d dir.resolvePath(pc, srcArg, DirOp.READ);\n         src \u003d iip.getPath();\n \n         INode inode \u003d iip.getLastINode();\n         boolean updateAccessTime \u003d inode !\u003d null \u0026\u0026\n             now \u003e inode.getAccessTime() + dir.getAccessTimePrecision();\n         if (!isInSafeMode() \u0026\u0026 updateAccessTime) {\n           boolean changed \u003d FSDirAttrOp.setTimes(dir, iip, -1, now, false);\n           if (changed) {\n             getEditLog().logTimes(src, -1, now);\n           }\n         }\n       } catch (Throwable e) {\n         LOG.warn(\"Failed to update the access time of \" + src, e);\n       } finally {\n         writeUnlock(operationName);\n       }\n     }\n \n     LocatedBlocks blocks \u003d res.blocks;\n     sortLocatedBlocks(clientMachine, blocks);\n     return blocks;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlocks getBlockLocations(String clientMachine, String srcArg,\n      long offset, long length) throws IOException {\n    final String operationName \u003d \"open\";\n    checkOperation(OperationCategory.READ);\n    GetBlockLocationsResult res \u003d null;\n    final FSPermissionChecker pc \u003d getPermissionChecker();\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      res \u003d FSDirStatAndListingOp.getBlockLocations(\n          dir, pc, srcArg, offset, length, true);\n      if (isInSafeMode()) {\n        for (LocatedBlock b : res.blocks.getLocatedBlocks()) {\n          // if safemode \u0026 no block locations yet then throw safemodeException\n          if ((b.getLocations() \u003d\u003d null) || (b.getLocations().length \u003d\u003d 0)) {\n            SafeModeException se \u003d newSafemodeException(\n                \"Zero blocklocations for \" + srcArg);\n            if (haEnabled \u0026\u0026 haContext !\u003d null \u0026\u0026\n                (haContext.getState().getServiceState() \u003d\u003d ACTIVE ||\n                    haContext.getState().getServiceState() \u003d\u003d OBSERVER)) {\n              throw new RetriableException(se);\n            } else {\n              throw se;\n            }\n          }\n        }\n      } else if (haEnabled \u0026\u0026 haContext !\u003d null \u0026\u0026\n          haContext.getState().getServiceState() \u003d\u003d OBSERVER) {\n        for (LocatedBlock b : res.blocks.getLocatedBlocks()) {\n          if (b.getLocations() \u003d\u003d null || b.getLocations().length \u003d\u003d 0) {\n            throw new ObserverRetryOnActiveException(\"Zero blocklocations for \"\n                + srcArg);\n          }\n        }\n      }\n    } catch (AccessControlException e) {\n      logAuditEvent(false, operationName, srcArg);\n      throw e;\n    } finally {\n      readUnlock(operationName);\n    }\n\n    logAuditEvent(true, operationName, srcArg);\n\n    if (!isInSafeMode() \u0026\u0026 res.updateAccessTime()) {\n      String src \u003d srcArg;\n      checkOperation(OperationCategory.WRITE);\n      writeLock();\n      final long now \u003d now();\n      try {\n        checkOperation(OperationCategory.WRITE);\n        /**\n         * Resolve the path again and update the atime only when the file\n         * exists.\n         *\n         * XXX: Races can still occur even after resolving the path again.\n         * For example:\n         *\n         * \u003cul\u003e\n         *   \u003cli\u003eGet the block location for \"/a/b\"\u003c/li\u003e\n         *   \u003cli\u003eRename \"/a/b\" to \"/c/b\"\u003c/li\u003e\n         *   \u003cli\u003eThe second resolution still points to \"/a/b\", which is\n         *   wrong.\u003c/li\u003e\n         * \u003c/ul\u003e\n         *\n         * The behavior is incorrect but consistent with the one before\n         * HDFS-7463. A better fix is to change the edit log of SetTime to\n         * use inode id instead of a path.\n         */\n        final INodesInPath iip \u003d dir.resolvePath(pc, srcArg, DirOp.READ);\n        src \u003d iip.getPath();\n\n        INode inode \u003d iip.getLastINode();\n        boolean updateAccessTime \u003d inode !\u003d null \u0026\u0026\n            now \u003e inode.getAccessTime() + dir.getAccessTimePrecision();\n        if (!isInSafeMode() \u0026\u0026 updateAccessTime) {\n          boolean changed \u003d FSDirAttrOp.setTimes(dir, iip, -1, now, false);\n          if (changed) {\n            getEditLog().logTimes(src, -1, now);\n          }\n        }\n      } catch (Throwable e) {\n        LOG.warn(\"Failed to update the access time of \" + src, e);\n      } finally {\n        writeUnlock(operationName);\n      }\n    }\n\n    LocatedBlocks blocks \u003d res.blocks;\n    sortLocatedBlocks(clientMachine, blocks);\n    return blocks;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "b74a7dbf88fef0dd735921cff84f8025eac9503d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13898. [SBN read] Throw retriable exception for getBlockLocations when ObserverNameNode is in safemode. Contributed by Chao Sun.\n",
      "commitDate": "24/12/18 9:34 AM",
      "commitName": "b74a7dbf88fef0dd735921cff84f8025eac9503d",
      "commitAuthor": "Erik Krogen",
      "commitDateOld": "24/12/18 9:33 AM",
      "commitNameOld": "091ad974cd29fae0cf8fbc98ab84900a1a324839",
      "commitAuthorOld": "Erik Krogen",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 19,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,83 +1,84 @@\n   LocatedBlocks getBlockLocations(String clientMachine, String srcArg,\n       long offset, long length) throws IOException {\n     final String operationName \u003d \"open\";\n     checkOperation(OperationCategory.READ);\n     GetBlockLocationsResult res \u003d null;\n     final FSPermissionChecker pc \u003d getPermissionChecker();\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n       res \u003d FSDirStatAndListingOp.getBlockLocations(\n           dir, pc, srcArg, offset, length, true);\n       if (isInSafeMode()) {\n         for (LocatedBlock b : res.blocks.getLocatedBlocks()) {\n           // if safemode \u0026 no block locations yet then throw safemodeException\n           if ((b.getLocations() \u003d\u003d null) || (b.getLocations().length \u003d\u003d 0)) {\n             SafeModeException se \u003d newSafemodeException(\n                 \"Zero blocklocations for \" + srcArg);\n             if (haEnabled \u0026\u0026 haContext !\u003d null \u0026\u0026\n-                haContext.getState().getServiceState() \u003d\u003d HAServiceState.ACTIVE) {\n+                (haContext.getState().getServiceState() \u003d\u003d ACTIVE ||\n+                    haContext.getState().getServiceState() \u003d\u003d OBSERVER)) {\n               throw new RetriableException(se);\n             } else {\n               throw se;\n             }\n           }\n         }\n       }\n     } catch (AccessControlException e) {\n       logAuditEvent(false, operationName, srcArg);\n       throw e;\n     } finally {\n       readUnlock(operationName);\n     }\n \n     logAuditEvent(true, operationName, srcArg);\n \n     if (!isInSafeMode() \u0026\u0026 res.updateAccessTime()) {\n       String src \u003d srcArg;\n       checkOperation(OperationCategory.WRITE);\n       writeLock();\n       final long now \u003d now();\n       try {\n         checkOperation(OperationCategory.WRITE);\n         /**\n          * Resolve the path again and update the atime only when the file\n          * exists.\n          *\n          * XXX: Races can still occur even after resolving the path again.\n          * For example:\n          *\n          * \u003cul\u003e\n          *   \u003cli\u003eGet the block location for \"/a/b\"\u003c/li\u003e\n          *   \u003cli\u003eRename \"/a/b\" to \"/c/b\"\u003c/li\u003e\n          *   \u003cli\u003eThe second resolution still points to \"/a/b\", which is\n          *   wrong.\u003c/li\u003e\n          * \u003c/ul\u003e\n          *\n          * The behavior is incorrect but consistent with the one before\n          * HDFS-7463. A better fix is to change the edit log of SetTime to\n          * use inode id instead of a path.\n          */\n         final INodesInPath iip \u003d dir.resolvePath(pc, srcArg, DirOp.READ);\n         src \u003d iip.getPath();\n \n         INode inode \u003d iip.getLastINode();\n         boolean updateAccessTime \u003d inode !\u003d null \u0026\u0026\n             now \u003e inode.getAccessTime() + dir.getAccessTimePrecision();\n         if (!isInSafeMode() \u0026\u0026 updateAccessTime) {\n           boolean changed \u003d FSDirAttrOp.setTimes(dir, iip, -1, now, false);\n           if (changed) {\n             getEditLog().logTimes(src, -1, now);\n           }\n         }\n       } catch (Throwable e) {\n         LOG.warn(\"Failed to update the access time of \" + src, e);\n       } finally {\n         writeUnlock(operationName);\n       }\n     }\n \n     LocatedBlocks blocks \u003d res.blocks;\n     sortLocatedBlocks(clientMachine, blocks);\n     return blocks;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlocks getBlockLocations(String clientMachine, String srcArg,\n      long offset, long length) throws IOException {\n    final String operationName \u003d \"open\";\n    checkOperation(OperationCategory.READ);\n    GetBlockLocationsResult res \u003d null;\n    final FSPermissionChecker pc \u003d getPermissionChecker();\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      res \u003d FSDirStatAndListingOp.getBlockLocations(\n          dir, pc, srcArg, offset, length, true);\n      if (isInSafeMode()) {\n        for (LocatedBlock b : res.blocks.getLocatedBlocks()) {\n          // if safemode \u0026 no block locations yet then throw safemodeException\n          if ((b.getLocations() \u003d\u003d null) || (b.getLocations().length \u003d\u003d 0)) {\n            SafeModeException se \u003d newSafemodeException(\n                \"Zero blocklocations for \" + srcArg);\n            if (haEnabled \u0026\u0026 haContext !\u003d null \u0026\u0026\n                (haContext.getState().getServiceState() \u003d\u003d ACTIVE ||\n                    haContext.getState().getServiceState() \u003d\u003d OBSERVER)) {\n              throw new RetriableException(se);\n            } else {\n              throw se;\n            }\n          }\n        }\n      }\n    } catch (AccessControlException e) {\n      logAuditEvent(false, operationName, srcArg);\n      throw e;\n    } finally {\n      readUnlock(operationName);\n    }\n\n    logAuditEvent(true, operationName, srcArg);\n\n    if (!isInSafeMode() \u0026\u0026 res.updateAccessTime()) {\n      String src \u003d srcArg;\n      checkOperation(OperationCategory.WRITE);\n      writeLock();\n      final long now \u003d now();\n      try {\n        checkOperation(OperationCategory.WRITE);\n        /**\n         * Resolve the path again and update the atime only when the file\n         * exists.\n         *\n         * XXX: Races can still occur even after resolving the path again.\n         * For example:\n         *\n         * \u003cul\u003e\n         *   \u003cli\u003eGet the block location for \"/a/b\"\u003c/li\u003e\n         *   \u003cli\u003eRename \"/a/b\" to \"/c/b\"\u003c/li\u003e\n         *   \u003cli\u003eThe second resolution still points to \"/a/b\", which is\n         *   wrong.\u003c/li\u003e\n         * \u003c/ul\u003e\n         *\n         * The behavior is incorrect but consistent with the one before\n         * HDFS-7463. A better fix is to change the edit log of SetTime to\n         * use inode id instead of a path.\n         */\n        final INodesInPath iip \u003d dir.resolvePath(pc, srcArg, DirOp.READ);\n        src \u003d iip.getPath();\n\n        INode inode \u003d iip.getLastINode();\n        boolean updateAccessTime \u003d inode !\u003d null \u0026\u0026\n            now \u003e inode.getAccessTime() + dir.getAccessTimePrecision();\n        if (!isInSafeMode() \u0026\u0026 updateAccessTime) {\n          boolean changed \u003d FSDirAttrOp.setTimes(dir, iip, -1, now, false);\n          if (changed) {\n            getEditLog().logTimes(src, -1, now);\n          }\n        }\n      } catch (Throwable e) {\n        LOG.warn(\"Failed to update the access time of \" + src, e);\n      } finally {\n        writeUnlock(operationName);\n      }\n    }\n\n    LocatedBlocks blocks \u003d res.blocks;\n    sortLocatedBlocks(clientMachine, blocks);\n    return blocks;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "ff013d2c952272f3176dcf624251b05d610503b5": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13602. Add checkOperation(WRITE) checks in FSNamesystem. Contributed by Chao Sun.",
      "commitDate": "31/05/18 5:37 PM",
      "commitName": "ff013d2c952272f3176dcf624251b05d610503b5",
      "commitAuthor": "Chao Sun",
      "commitDateOld": "26/04/18 1:52 PM",
      "commitNameOld": "2adda92de1535c0472c0df33a145fa1814703f4f",
      "commitAuthorOld": "Owen O\u0027Malley",
      "daysBetweenCommits": 35.16,
      "commitsBetweenForRepo": 296,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,82 +1,83 @@\n   LocatedBlocks getBlockLocations(String clientMachine, String srcArg,\n       long offset, long length) throws IOException {\n     final String operationName \u003d \"open\";\n     checkOperation(OperationCategory.READ);\n     GetBlockLocationsResult res \u003d null;\n     final FSPermissionChecker pc \u003d getPermissionChecker();\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n       res \u003d FSDirStatAndListingOp.getBlockLocations(\n           dir, pc, srcArg, offset, length, true);\n       if (isInSafeMode()) {\n         for (LocatedBlock b : res.blocks.getLocatedBlocks()) {\n           // if safemode \u0026 no block locations yet then throw safemodeException\n           if ((b.getLocations() \u003d\u003d null) || (b.getLocations().length \u003d\u003d 0)) {\n             SafeModeException se \u003d newSafemodeException(\n                 \"Zero blocklocations for \" + srcArg);\n             if (haEnabled \u0026\u0026 haContext !\u003d null \u0026\u0026\n                 haContext.getState().getServiceState() \u003d\u003d HAServiceState.ACTIVE) {\n               throw new RetriableException(se);\n             } else {\n               throw se;\n             }\n           }\n         }\n       }\n     } catch (AccessControlException e) {\n       logAuditEvent(false, operationName, srcArg);\n       throw e;\n     } finally {\n       readUnlock(operationName);\n     }\n \n     logAuditEvent(true, operationName, srcArg);\n \n     if (!isInSafeMode() \u0026\u0026 res.updateAccessTime()) {\n       String src \u003d srcArg;\n+      checkOperation(OperationCategory.WRITE);\n       writeLock();\n       final long now \u003d now();\n       try {\n         checkOperation(OperationCategory.WRITE);\n         /**\n          * Resolve the path again and update the atime only when the file\n          * exists.\n          *\n          * XXX: Races can still occur even after resolving the path again.\n          * For example:\n          *\n          * \u003cul\u003e\n          *   \u003cli\u003eGet the block location for \"/a/b\"\u003c/li\u003e\n          *   \u003cli\u003eRename \"/a/b\" to \"/c/b\"\u003c/li\u003e\n          *   \u003cli\u003eThe second resolution still points to \"/a/b\", which is\n          *   wrong.\u003c/li\u003e\n          * \u003c/ul\u003e\n          *\n          * The behavior is incorrect but consistent with the one before\n          * HDFS-7463. A better fix is to change the edit log of SetTime to\n          * use inode id instead of a path.\n          */\n         final INodesInPath iip \u003d dir.resolvePath(pc, srcArg, DirOp.READ);\n         src \u003d iip.getPath();\n \n         INode inode \u003d iip.getLastINode();\n         boolean updateAccessTime \u003d inode !\u003d null \u0026\u0026\n             now \u003e inode.getAccessTime() + dir.getAccessTimePrecision();\n         if (!isInSafeMode() \u0026\u0026 updateAccessTime) {\n           boolean changed \u003d FSDirAttrOp.setTimes(dir, iip, -1, now, false);\n           if (changed) {\n             getEditLog().logTimes(src, -1, now);\n           }\n         }\n       } catch (Throwable e) {\n         LOG.warn(\"Failed to update the access time of \" + src, e);\n       } finally {\n         writeUnlock(operationName);\n       }\n     }\n \n     LocatedBlocks blocks \u003d res.blocks;\n     sortLocatedBlocks(clientMachine, blocks);\n     return blocks;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlocks getBlockLocations(String clientMachine, String srcArg,\n      long offset, long length) throws IOException {\n    final String operationName \u003d \"open\";\n    checkOperation(OperationCategory.READ);\n    GetBlockLocationsResult res \u003d null;\n    final FSPermissionChecker pc \u003d getPermissionChecker();\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      res \u003d FSDirStatAndListingOp.getBlockLocations(\n          dir, pc, srcArg, offset, length, true);\n      if (isInSafeMode()) {\n        for (LocatedBlock b : res.blocks.getLocatedBlocks()) {\n          // if safemode \u0026 no block locations yet then throw safemodeException\n          if ((b.getLocations() \u003d\u003d null) || (b.getLocations().length \u003d\u003d 0)) {\n            SafeModeException se \u003d newSafemodeException(\n                \"Zero blocklocations for \" + srcArg);\n            if (haEnabled \u0026\u0026 haContext !\u003d null \u0026\u0026\n                haContext.getState().getServiceState() \u003d\u003d HAServiceState.ACTIVE) {\n              throw new RetriableException(se);\n            } else {\n              throw se;\n            }\n          }\n        }\n      }\n    } catch (AccessControlException e) {\n      logAuditEvent(false, operationName, srcArg);\n      throw e;\n    } finally {\n      readUnlock(operationName);\n    }\n\n    logAuditEvent(true, operationName, srcArg);\n\n    if (!isInSafeMode() \u0026\u0026 res.updateAccessTime()) {\n      String src \u003d srcArg;\n      checkOperation(OperationCategory.WRITE);\n      writeLock();\n      final long now \u003d now();\n      try {\n        checkOperation(OperationCategory.WRITE);\n        /**\n         * Resolve the path again and update the atime only when the file\n         * exists.\n         *\n         * XXX: Races can still occur even after resolving the path again.\n         * For example:\n         *\n         * \u003cul\u003e\n         *   \u003cli\u003eGet the block location for \"/a/b\"\u003c/li\u003e\n         *   \u003cli\u003eRename \"/a/b\" to \"/c/b\"\u003c/li\u003e\n         *   \u003cli\u003eThe second resolution still points to \"/a/b\", which is\n         *   wrong.\u003c/li\u003e\n         * \u003c/ul\u003e\n         *\n         * The behavior is incorrect but consistent with the one before\n         * HDFS-7463. A better fix is to change the edit log of SetTime to\n         * use inode id instead of a path.\n         */\n        final INodesInPath iip \u003d dir.resolvePath(pc, srcArg, DirOp.READ);\n        src \u003d iip.getPath();\n\n        INode inode \u003d iip.getLastINode();\n        boolean updateAccessTime \u003d inode !\u003d null \u0026\u0026\n            now \u003e inode.getAccessTime() + dir.getAccessTimePrecision();\n        if (!isInSafeMode() \u0026\u0026 updateAccessTime) {\n          boolean changed \u003d FSDirAttrOp.setTimes(dir, iip, -1, now, false);\n          if (changed) {\n            getEditLog().logTimes(src, -1, now);\n          }\n        }\n      } catch (Throwable e) {\n        LOG.warn(\"Failed to update the access time of \" + src, e);\n      } finally {\n        writeUnlock(operationName);\n      }\n    }\n\n    LocatedBlocks blocks \u003d res.blocks;\n    sortLocatedBlocks(clientMachine, blocks);\n    return blocks;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "84a1321f6aa0af6895564a7c47f8f264656f0294": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13136. Avoid taking FSN lock while doing group member lookup for FSD permission check. Contributed by Xiaoyu Yao.\n",
      "commitDate": "22/02/18 11:32 AM",
      "commitName": "84a1321f6aa0af6895564a7c47f8f264656f0294",
      "commitAuthor": "Xiaoyu Yao",
      "commitDateOld": "15/02/18 1:32 PM",
      "commitNameOld": "47473952e56b0380147d42f4110ad03c2276c961",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 6.92,
      "commitsBetweenForRepo": 36,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,82 +1,82 @@\n   LocatedBlocks getBlockLocations(String clientMachine, String srcArg,\n       long offset, long length) throws IOException {\n     final String operationName \u003d \"open\";\n     checkOperation(OperationCategory.READ);\n     GetBlockLocationsResult res \u003d null;\n-    FSPermissionChecker pc \u003d getPermissionChecker();\n+    final FSPermissionChecker pc \u003d getPermissionChecker();\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n       res \u003d FSDirStatAndListingOp.getBlockLocations(\n           dir, pc, srcArg, offset, length, true);\n       if (isInSafeMode()) {\n         for (LocatedBlock b : res.blocks.getLocatedBlocks()) {\n           // if safemode \u0026 no block locations yet then throw safemodeException\n           if ((b.getLocations() \u003d\u003d null) || (b.getLocations().length \u003d\u003d 0)) {\n             SafeModeException se \u003d newSafemodeException(\n                 \"Zero blocklocations for \" + srcArg);\n             if (haEnabled \u0026\u0026 haContext !\u003d null \u0026\u0026\n                 haContext.getState().getServiceState() \u003d\u003d HAServiceState.ACTIVE) {\n               throw new RetriableException(se);\n             } else {\n               throw se;\n             }\n           }\n         }\n       }\n     } catch (AccessControlException e) {\n       logAuditEvent(false, operationName, srcArg);\n       throw e;\n     } finally {\n       readUnlock(operationName);\n     }\n \n     logAuditEvent(true, operationName, srcArg);\n \n     if (!isInSafeMode() \u0026\u0026 res.updateAccessTime()) {\n       String src \u003d srcArg;\n       writeLock();\n       final long now \u003d now();\n       try {\n         checkOperation(OperationCategory.WRITE);\n         /**\n          * Resolve the path again and update the atime only when the file\n          * exists.\n          *\n          * XXX: Races can still occur even after resolving the path again.\n          * For example:\n          *\n          * \u003cul\u003e\n          *   \u003cli\u003eGet the block location for \"/a/b\"\u003c/li\u003e\n          *   \u003cli\u003eRename \"/a/b\" to \"/c/b\"\u003c/li\u003e\n          *   \u003cli\u003eThe second resolution still points to \"/a/b\", which is\n          *   wrong.\u003c/li\u003e\n          * \u003c/ul\u003e\n          *\n          * The behavior is incorrect but consistent with the one before\n          * HDFS-7463. A better fix is to change the edit log of SetTime to\n          * use inode id instead of a path.\n          */\n         final INodesInPath iip \u003d dir.resolvePath(pc, srcArg, DirOp.READ);\n         src \u003d iip.getPath();\n \n         INode inode \u003d iip.getLastINode();\n         boolean updateAccessTime \u003d inode !\u003d null \u0026\u0026\n             now \u003e inode.getAccessTime() + dir.getAccessTimePrecision();\n         if (!isInSafeMode() \u0026\u0026 updateAccessTime) {\n           boolean changed \u003d FSDirAttrOp.setTimes(dir, iip, -1, now, false);\n           if (changed) {\n             getEditLog().logTimes(src, -1, now);\n           }\n         }\n       } catch (Throwable e) {\n         LOG.warn(\"Failed to update the access time of \" + src, e);\n       } finally {\n         writeUnlock(operationName);\n       }\n     }\n \n     LocatedBlocks blocks \u003d res.blocks;\n     sortLocatedBlocks(clientMachine, blocks);\n     return blocks;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlocks getBlockLocations(String clientMachine, String srcArg,\n      long offset, long length) throws IOException {\n    final String operationName \u003d \"open\";\n    checkOperation(OperationCategory.READ);\n    GetBlockLocationsResult res \u003d null;\n    final FSPermissionChecker pc \u003d getPermissionChecker();\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      res \u003d FSDirStatAndListingOp.getBlockLocations(\n          dir, pc, srcArg, offset, length, true);\n      if (isInSafeMode()) {\n        for (LocatedBlock b : res.blocks.getLocatedBlocks()) {\n          // if safemode \u0026 no block locations yet then throw safemodeException\n          if ((b.getLocations() \u003d\u003d null) || (b.getLocations().length \u003d\u003d 0)) {\n            SafeModeException se \u003d newSafemodeException(\n                \"Zero blocklocations for \" + srcArg);\n            if (haEnabled \u0026\u0026 haContext !\u003d null \u0026\u0026\n                haContext.getState().getServiceState() \u003d\u003d HAServiceState.ACTIVE) {\n              throw new RetriableException(se);\n            } else {\n              throw se;\n            }\n          }\n        }\n      }\n    } catch (AccessControlException e) {\n      logAuditEvent(false, operationName, srcArg);\n      throw e;\n    } finally {\n      readUnlock(operationName);\n    }\n\n    logAuditEvent(true, operationName, srcArg);\n\n    if (!isInSafeMode() \u0026\u0026 res.updateAccessTime()) {\n      String src \u003d srcArg;\n      writeLock();\n      final long now \u003d now();\n      try {\n        checkOperation(OperationCategory.WRITE);\n        /**\n         * Resolve the path again and update the atime only when the file\n         * exists.\n         *\n         * XXX: Races can still occur even after resolving the path again.\n         * For example:\n         *\n         * \u003cul\u003e\n         *   \u003cli\u003eGet the block location for \"/a/b\"\u003c/li\u003e\n         *   \u003cli\u003eRename \"/a/b\" to \"/c/b\"\u003c/li\u003e\n         *   \u003cli\u003eThe second resolution still points to \"/a/b\", which is\n         *   wrong.\u003c/li\u003e\n         * \u003c/ul\u003e\n         *\n         * The behavior is incorrect but consistent with the one before\n         * HDFS-7463. A better fix is to change the edit log of SetTime to\n         * use inode id instead of a path.\n         */\n        final INodesInPath iip \u003d dir.resolvePath(pc, srcArg, DirOp.READ);\n        src \u003d iip.getPath();\n\n        INode inode \u003d iip.getLastINode();\n        boolean updateAccessTime \u003d inode !\u003d null \u0026\u0026\n            now \u003e inode.getAccessTime() + dir.getAccessTimePrecision();\n        if (!isInSafeMode() \u0026\u0026 updateAccessTime) {\n          boolean changed \u003d FSDirAttrOp.setTimes(dir, iip, -1, now, false);\n          if (changed) {\n            getEditLog().logTimes(src, -1, now);\n          }\n        }\n      } catch (Throwable e) {\n        LOG.warn(\"Failed to update the access time of \" + src, e);\n      } finally {\n        writeUnlock(operationName);\n      }\n    }\n\n    LocatedBlocks blocks \u003d res.blocks;\n    sortLocatedBlocks(clientMachine, blocks);\n    return blocks;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "ff0b99eafeda035ebe0dc82cfe689808047a8893": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10872. Add MutableRate metrics for FSNamesystemLock operations. Contributed by Erik Krogen.\n",
      "commitDate": "14/11/16 11:05 AM",
      "commitName": "ff0b99eafeda035ebe0dc82cfe689808047a8893",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "08/11/16 6:17 PM",
      "commitNameOld": "ed0bebabaaf27cd730f7f8eb002d92c9c7db327d",
      "commitAuthorOld": "Brahma Reddy Battula",
      "daysBetweenCommits": 5.7,
      "commitsBetweenForRepo": 36,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,81 +1,82 @@\n   LocatedBlocks getBlockLocations(String clientMachine, String srcArg,\n       long offset, long length) throws IOException {\n+    final String operationName \u003d \"open\";\n     checkOperation(OperationCategory.READ);\n     GetBlockLocationsResult res \u003d null;\n     FSPermissionChecker pc \u003d getPermissionChecker();\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n       res \u003d FSDirStatAndListingOp.getBlockLocations(\n           dir, pc, srcArg, offset, length, true);\n       if (isInSafeMode()) {\n         for (LocatedBlock b : res.blocks.getLocatedBlocks()) {\n           // if safemode \u0026 no block locations yet then throw safemodeException\n           if ((b.getLocations() \u003d\u003d null) || (b.getLocations().length \u003d\u003d 0)) {\n             SafeModeException se \u003d newSafemodeException(\n                 \"Zero blocklocations for \" + srcArg);\n             if (haEnabled \u0026\u0026 haContext !\u003d null \u0026\u0026\n                 haContext.getState().getServiceState() \u003d\u003d HAServiceState.ACTIVE) {\n               throw new RetriableException(se);\n             } else {\n               throw se;\n             }\n           }\n         }\n       }\n     } catch (AccessControlException e) {\n-      logAuditEvent(false, \"open\", srcArg);\n+      logAuditEvent(false, operationName, srcArg);\n       throw e;\n     } finally {\n-      readUnlock();\n+      readUnlock(operationName);\n     }\n \n-    logAuditEvent(true, \"open\", srcArg);\n+    logAuditEvent(true, operationName, srcArg);\n \n     if (!isInSafeMode() \u0026\u0026 res.updateAccessTime()) {\n       String src \u003d srcArg;\n       writeLock();\n       final long now \u003d now();\n       try {\n         checkOperation(OperationCategory.WRITE);\n         /**\n          * Resolve the path again and update the atime only when the file\n          * exists.\n          *\n          * XXX: Races can still occur even after resolving the path again.\n          * For example:\n          *\n          * \u003cul\u003e\n          *   \u003cli\u003eGet the block location for \"/a/b\"\u003c/li\u003e\n          *   \u003cli\u003eRename \"/a/b\" to \"/c/b\"\u003c/li\u003e\n          *   \u003cli\u003eThe second resolution still points to \"/a/b\", which is\n          *   wrong.\u003c/li\u003e\n          * \u003c/ul\u003e\n          *\n          * The behavior is incorrect but consistent with the one before\n          * HDFS-7463. A better fix is to change the edit log of SetTime to\n          * use inode id instead of a path.\n          */\n         final INodesInPath iip \u003d dir.resolvePath(pc, srcArg, DirOp.READ);\n         src \u003d iip.getPath();\n \n         INode inode \u003d iip.getLastINode();\n         boolean updateAccessTime \u003d inode !\u003d null \u0026\u0026\n             now \u003e inode.getAccessTime() + dir.getAccessTimePrecision();\n         if (!isInSafeMode() \u0026\u0026 updateAccessTime) {\n           boolean changed \u003d FSDirAttrOp.setTimes(dir, iip, -1, now, false);\n           if (changed) {\n             getEditLog().logTimes(src, -1, now);\n           }\n         }\n       } catch (Throwable e) {\n         LOG.warn(\"Failed to update the access time of \" + src, e);\n       } finally {\n-        writeUnlock();\n+        writeUnlock(operationName);\n       }\n     }\n \n     LocatedBlocks blocks \u003d res.blocks;\n     sortLocatedBlocks(clientMachine, blocks);\n     return blocks;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlocks getBlockLocations(String clientMachine, String srcArg,\n      long offset, long length) throws IOException {\n    final String operationName \u003d \"open\";\n    checkOperation(OperationCategory.READ);\n    GetBlockLocationsResult res \u003d null;\n    FSPermissionChecker pc \u003d getPermissionChecker();\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      res \u003d FSDirStatAndListingOp.getBlockLocations(\n          dir, pc, srcArg, offset, length, true);\n      if (isInSafeMode()) {\n        for (LocatedBlock b : res.blocks.getLocatedBlocks()) {\n          // if safemode \u0026 no block locations yet then throw safemodeException\n          if ((b.getLocations() \u003d\u003d null) || (b.getLocations().length \u003d\u003d 0)) {\n            SafeModeException se \u003d newSafemodeException(\n                \"Zero blocklocations for \" + srcArg);\n            if (haEnabled \u0026\u0026 haContext !\u003d null \u0026\u0026\n                haContext.getState().getServiceState() \u003d\u003d HAServiceState.ACTIVE) {\n              throw new RetriableException(se);\n            } else {\n              throw se;\n            }\n          }\n        }\n      }\n    } catch (AccessControlException e) {\n      logAuditEvent(false, operationName, srcArg);\n      throw e;\n    } finally {\n      readUnlock(operationName);\n    }\n\n    logAuditEvent(true, operationName, srcArg);\n\n    if (!isInSafeMode() \u0026\u0026 res.updateAccessTime()) {\n      String src \u003d srcArg;\n      writeLock();\n      final long now \u003d now();\n      try {\n        checkOperation(OperationCategory.WRITE);\n        /**\n         * Resolve the path again and update the atime only when the file\n         * exists.\n         *\n         * XXX: Races can still occur even after resolving the path again.\n         * For example:\n         *\n         * \u003cul\u003e\n         *   \u003cli\u003eGet the block location for \"/a/b\"\u003c/li\u003e\n         *   \u003cli\u003eRename \"/a/b\" to \"/c/b\"\u003c/li\u003e\n         *   \u003cli\u003eThe second resolution still points to \"/a/b\", which is\n         *   wrong.\u003c/li\u003e\n         * \u003c/ul\u003e\n         *\n         * The behavior is incorrect but consistent with the one before\n         * HDFS-7463. A better fix is to change the edit log of SetTime to\n         * use inode id instead of a path.\n         */\n        final INodesInPath iip \u003d dir.resolvePath(pc, srcArg, DirOp.READ);\n        src \u003d iip.getPath();\n\n        INode inode \u003d iip.getLastINode();\n        boolean updateAccessTime \u003d inode !\u003d null \u0026\u0026\n            now \u003e inode.getAccessTime() + dir.getAccessTimePrecision();\n        if (!isInSafeMode() \u0026\u0026 updateAccessTime) {\n          boolean changed \u003d FSDirAttrOp.setTimes(dir, iip, -1, now, false);\n          if (changed) {\n            getEditLog().logTimes(src, -1, now);\n          }\n        }\n      } catch (Throwable e) {\n        LOG.warn(\"Failed to update the access time of \" + src, e);\n      } finally {\n        writeUnlock(operationName);\n      }\n    }\n\n    LocatedBlocks blocks \u003d res.blocks;\n    sortLocatedBlocks(clientMachine, blocks);\n    return blocks;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "9d175853b0170683ad5f21d9bcdeaac49fe89e04": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10997. Reduce number of path resolving methods. Contributed by Daryn Sharp.\n",
      "commitDate": "24/10/16 3:14 PM",
      "commitName": "9d175853b0170683ad5f21d9bcdeaac49fe89e04",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "17/10/16 5:45 PM",
      "commitNameOld": "b61fb267b92b2736920b4bd0c673d31e7632ebb9",
      "commitAuthorOld": "Ming Ma",
      "daysBetweenCommits": 6.9,
      "commitsBetweenForRepo": 44,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,81 +1,81 @@\n   LocatedBlocks getBlockLocations(String clientMachine, String srcArg,\n       long offset, long length) throws IOException {\n     checkOperation(OperationCategory.READ);\n     GetBlockLocationsResult res \u003d null;\n     FSPermissionChecker pc \u003d getPermissionChecker();\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n       res \u003d FSDirStatAndListingOp.getBlockLocations(\n           dir, pc, srcArg, offset, length, true);\n       if (isInSafeMode()) {\n         for (LocatedBlock b : res.blocks.getLocatedBlocks()) {\n           // if safemode \u0026 no block locations yet then throw safemodeException\n           if ((b.getLocations() \u003d\u003d null) || (b.getLocations().length \u003d\u003d 0)) {\n             SafeModeException se \u003d newSafemodeException(\n                 \"Zero blocklocations for \" + srcArg);\n             if (haEnabled \u0026\u0026 haContext !\u003d null \u0026\u0026\n                 haContext.getState().getServiceState() \u003d\u003d HAServiceState.ACTIVE) {\n               throw new RetriableException(se);\n             } else {\n               throw se;\n             }\n           }\n         }\n       }\n     } catch (AccessControlException e) {\n       logAuditEvent(false, \"open\", srcArg);\n       throw e;\n     } finally {\n       readUnlock();\n     }\n \n     logAuditEvent(true, \"open\", srcArg);\n \n     if (!isInSafeMode() \u0026\u0026 res.updateAccessTime()) {\n       String src \u003d srcArg;\n       writeLock();\n       final long now \u003d now();\n       try {\n         checkOperation(OperationCategory.WRITE);\n         /**\n          * Resolve the path again and update the atime only when the file\n          * exists.\n          *\n          * XXX: Races can still occur even after resolving the path again.\n          * For example:\n          *\n          * \u003cul\u003e\n          *   \u003cli\u003eGet the block location for \"/a/b\"\u003c/li\u003e\n          *   \u003cli\u003eRename \"/a/b\" to \"/c/b\"\u003c/li\u003e\n          *   \u003cli\u003eThe second resolution still points to \"/a/b\", which is\n          *   wrong.\u003c/li\u003e\n          * \u003c/ul\u003e\n          *\n          * The behavior is incorrect but consistent with the one before\n          * HDFS-7463. A better fix is to change the edit log of SetTime to\n          * use inode id instead of a path.\n          */\n-        final INodesInPath iip \u003d dir.resolvePath(pc, srcArg);\n+        final INodesInPath iip \u003d dir.resolvePath(pc, srcArg, DirOp.READ);\n         src \u003d iip.getPath();\n \n         INode inode \u003d iip.getLastINode();\n         boolean updateAccessTime \u003d inode !\u003d null \u0026\u0026\n             now \u003e inode.getAccessTime() + dir.getAccessTimePrecision();\n         if (!isInSafeMode() \u0026\u0026 updateAccessTime) {\n           boolean changed \u003d FSDirAttrOp.setTimes(dir, iip, -1, now, false);\n           if (changed) {\n             getEditLog().logTimes(src, -1, now);\n           }\n         }\n       } catch (Throwable e) {\n         LOG.warn(\"Failed to update the access time of \" + src, e);\n       } finally {\n         writeUnlock();\n       }\n     }\n \n     LocatedBlocks blocks \u003d res.blocks;\n     sortLocatedBlocks(clientMachine, blocks);\n     return blocks;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlocks getBlockLocations(String clientMachine, String srcArg,\n      long offset, long length) throws IOException {\n    checkOperation(OperationCategory.READ);\n    GetBlockLocationsResult res \u003d null;\n    FSPermissionChecker pc \u003d getPermissionChecker();\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      res \u003d FSDirStatAndListingOp.getBlockLocations(\n          dir, pc, srcArg, offset, length, true);\n      if (isInSafeMode()) {\n        for (LocatedBlock b : res.blocks.getLocatedBlocks()) {\n          // if safemode \u0026 no block locations yet then throw safemodeException\n          if ((b.getLocations() \u003d\u003d null) || (b.getLocations().length \u003d\u003d 0)) {\n            SafeModeException se \u003d newSafemodeException(\n                \"Zero blocklocations for \" + srcArg);\n            if (haEnabled \u0026\u0026 haContext !\u003d null \u0026\u0026\n                haContext.getState().getServiceState() \u003d\u003d HAServiceState.ACTIVE) {\n              throw new RetriableException(se);\n            } else {\n              throw se;\n            }\n          }\n        }\n      }\n    } catch (AccessControlException e) {\n      logAuditEvent(false, \"open\", srcArg);\n      throw e;\n    } finally {\n      readUnlock();\n    }\n\n    logAuditEvent(true, \"open\", srcArg);\n\n    if (!isInSafeMode() \u0026\u0026 res.updateAccessTime()) {\n      String src \u003d srcArg;\n      writeLock();\n      final long now \u003d now();\n      try {\n        checkOperation(OperationCategory.WRITE);\n        /**\n         * Resolve the path again and update the atime only when the file\n         * exists.\n         *\n         * XXX: Races can still occur even after resolving the path again.\n         * For example:\n         *\n         * \u003cul\u003e\n         *   \u003cli\u003eGet the block location for \"/a/b\"\u003c/li\u003e\n         *   \u003cli\u003eRename \"/a/b\" to \"/c/b\"\u003c/li\u003e\n         *   \u003cli\u003eThe second resolution still points to \"/a/b\", which is\n         *   wrong.\u003c/li\u003e\n         * \u003c/ul\u003e\n         *\n         * The behavior is incorrect but consistent with the one before\n         * HDFS-7463. A better fix is to change the edit log of SetTime to\n         * use inode id instead of a path.\n         */\n        final INodesInPath iip \u003d dir.resolvePath(pc, srcArg, DirOp.READ);\n        src \u003d iip.getPath();\n\n        INode inode \u003d iip.getLastINode();\n        boolean updateAccessTime \u003d inode !\u003d null \u0026\u0026\n            now \u003e inode.getAccessTime() + dir.getAccessTimePrecision();\n        if (!isInSafeMode() \u0026\u0026 updateAccessTime) {\n          boolean changed \u003d FSDirAttrOp.setTimes(dir, iip, -1, now, false);\n          if (changed) {\n            getEditLog().logTimes(src, -1, now);\n          }\n        }\n      } catch (Throwable e) {\n        LOG.warn(\"Failed to update the access time of \" + src, e);\n      } finally {\n        writeUnlock();\n      }\n    }\n\n    LocatedBlocks blocks \u003d res.blocks;\n    sortLocatedBlocks(clientMachine, blocks);\n    return blocks;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "48b9d5fd2a96728b1118be217ca597c4098e99ca": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10955. Pass IIP for FSDirAttr methods. Contributed by Daryn Sharp.\n",
      "commitDate": "06/10/16 2:33 PM",
      "commitName": "48b9d5fd2a96728b1118be217ca597c4098e99ca",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "06/10/16 1:11 PM",
      "commitNameOld": "f32e9fc8f7150f0e889c0774b3ad712af26fbd65",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 0.06,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,82 +1,81 @@\n   LocatedBlocks getBlockLocations(String clientMachine, String srcArg,\n       long offset, long length) throws IOException {\n     checkOperation(OperationCategory.READ);\n     GetBlockLocationsResult res \u003d null;\n     FSPermissionChecker pc \u003d getPermissionChecker();\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n       res \u003d FSDirStatAndListingOp.getBlockLocations(\n           dir, pc, srcArg, offset, length, true);\n       if (isInSafeMode()) {\n         for (LocatedBlock b : res.blocks.getLocatedBlocks()) {\n           // if safemode \u0026 no block locations yet then throw safemodeException\n           if ((b.getLocations() \u003d\u003d null) || (b.getLocations().length \u003d\u003d 0)) {\n             SafeModeException se \u003d newSafemodeException(\n                 \"Zero blocklocations for \" + srcArg);\n             if (haEnabled \u0026\u0026 haContext !\u003d null \u0026\u0026\n                 haContext.getState().getServiceState() \u003d\u003d HAServiceState.ACTIVE) {\n               throw new RetriableException(se);\n             } else {\n               throw se;\n             }\n           }\n         }\n       }\n     } catch (AccessControlException e) {\n       logAuditEvent(false, \"open\", srcArg);\n       throw e;\n     } finally {\n       readUnlock();\n     }\n \n     logAuditEvent(true, \"open\", srcArg);\n \n     if (!isInSafeMode() \u0026\u0026 res.updateAccessTime()) {\n       String src \u003d srcArg;\n       writeLock();\n       final long now \u003d now();\n       try {\n         checkOperation(OperationCategory.WRITE);\n         /**\n          * Resolve the path again and update the atime only when the file\n          * exists.\n          *\n          * XXX: Races can still occur even after resolving the path again.\n          * For example:\n          *\n          * \u003cul\u003e\n          *   \u003cli\u003eGet the block location for \"/a/b\"\u003c/li\u003e\n          *   \u003cli\u003eRename \"/a/b\" to \"/c/b\"\u003c/li\u003e\n          *   \u003cli\u003eThe second resolution still points to \"/a/b\", which is\n          *   wrong.\u003c/li\u003e\n          * \u003c/ul\u003e\n          *\n          * The behavior is incorrect but consistent with the one before\n          * HDFS-7463. A better fix is to change the edit log of SetTime to\n          * use inode id instead of a path.\n          */\n         final INodesInPath iip \u003d dir.resolvePath(pc, srcArg);\n         src \u003d iip.getPath();\n \n         INode inode \u003d iip.getLastINode();\n         boolean updateAccessTime \u003d inode !\u003d null \u0026\u0026\n             now \u003e inode.getAccessTime() + dir.getAccessTimePrecision();\n         if (!isInSafeMode() \u0026\u0026 updateAccessTime) {\n-          boolean changed \u003d FSDirAttrOp.setTimes(dir,\n-              inode, -1, now, false, iip.getLatestSnapshotId());\n+          boolean changed \u003d FSDirAttrOp.setTimes(dir, iip, -1, now, false);\n           if (changed) {\n             getEditLog().logTimes(src, -1, now);\n           }\n         }\n       } catch (Throwable e) {\n         LOG.warn(\"Failed to update the access time of \" + src, e);\n       } finally {\n         writeUnlock();\n       }\n     }\n \n     LocatedBlocks blocks \u003d res.blocks;\n     sortLocatedBlocks(clientMachine, blocks);\n     return blocks;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlocks getBlockLocations(String clientMachine, String srcArg,\n      long offset, long length) throws IOException {\n    checkOperation(OperationCategory.READ);\n    GetBlockLocationsResult res \u003d null;\n    FSPermissionChecker pc \u003d getPermissionChecker();\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      res \u003d FSDirStatAndListingOp.getBlockLocations(\n          dir, pc, srcArg, offset, length, true);\n      if (isInSafeMode()) {\n        for (LocatedBlock b : res.blocks.getLocatedBlocks()) {\n          // if safemode \u0026 no block locations yet then throw safemodeException\n          if ((b.getLocations() \u003d\u003d null) || (b.getLocations().length \u003d\u003d 0)) {\n            SafeModeException se \u003d newSafemodeException(\n                \"Zero blocklocations for \" + srcArg);\n            if (haEnabled \u0026\u0026 haContext !\u003d null \u0026\u0026\n                haContext.getState().getServiceState() \u003d\u003d HAServiceState.ACTIVE) {\n              throw new RetriableException(se);\n            } else {\n              throw se;\n            }\n          }\n        }\n      }\n    } catch (AccessControlException e) {\n      logAuditEvent(false, \"open\", srcArg);\n      throw e;\n    } finally {\n      readUnlock();\n    }\n\n    logAuditEvent(true, \"open\", srcArg);\n\n    if (!isInSafeMode() \u0026\u0026 res.updateAccessTime()) {\n      String src \u003d srcArg;\n      writeLock();\n      final long now \u003d now();\n      try {\n        checkOperation(OperationCategory.WRITE);\n        /**\n         * Resolve the path again and update the atime only when the file\n         * exists.\n         *\n         * XXX: Races can still occur even after resolving the path again.\n         * For example:\n         *\n         * \u003cul\u003e\n         *   \u003cli\u003eGet the block location for \"/a/b\"\u003c/li\u003e\n         *   \u003cli\u003eRename \"/a/b\" to \"/c/b\"\u003c/li\u003e\n         *   \u003cli\u003eThe second resolution still points to \"/a/b\", which is\n         *   wrong.\u003c/li\u003e\n         * \u003c/ul\u003e\n         *\n         * The behavior is incorrect but consistent with the one before\n         * HDFS-7463. A better fix is to change the edit log of SetTime to\n         * use inode id instead of a path.\n         */\n        final INodesInPath iip \u003d dir.resolvePath(pc, srcArg);\n        src \u003d iip.getPath();\n\n        INode inode \u003d iip.getLastINode();\n        boolean updateAccessTime \u003d inode !\u003d null \u0026\u0026\n            now \u003e inode.getAccessTime() + dir.getAccessTimePrecision();\n        if (!isInSafeMode() \u0026\u0026 updateAccessTime) {\n          boolean changed \u003d FSDirAttrOp.setTimes(dir, iip, -1, now, false);\n          if (changed) {\n            getEditLog().logTimes(src, -1, now);\n          }\n        }\n      } catch (Throwable e) {\n        LOG.warn(\"Failed to update the access time of \" + src, e);\n      } finally {\n        writeUnlock();\n      }\n    }\n\n    LocatedBlocks blocks \u003d res.blocks;\n    sortLocatedBlocks(clientMachine, blocks);\n    return blocks;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "869393643de23dcb010cc33091c8eb398de0fd6c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10745. Directly resolve paths into INodesInPath. Contributed by Daryn Sharp.\n",
      "commitDate": "17/08/16 1:53 PM",
      "commitName": "869393643de23dcb010cc33091c8eb398de0fd6c",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "15/08/16 3:28 PM",
      "commitNameOld": "864f878d5912c82f3204f1582cfb7eb7c9f1a1da",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 1.93,
      "commitsBetweenForRepo": 22,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,81 +1,82 @@\n   LocatedBlocks getBlockLocations(String clientMachine, String srcArg,\n       long offset, long length) throws IOException {\n     checkOperation(OperationCategory.READ);\n     GetBlockLocationsResult res \u003d null;\n     FSPermissionChecker pc \u003d getPermissionChecker();\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n       res \u003d FSDirStatAndListingOp.getBlockLocations(\n           dir, pc, srcArg, offset, length, true);\n       if (isInSafeMode()) {\n         for (LocatedBlock b : res.blocks.getLocatedBlocks()) {\n           // if safemode \u0026 no block locations yet then throw safemodeException\n           if ((b.getLocations() \u003d\u003d null) || (b.getLocations().length \u003d\u003d 0)) {\n             SafeModeException se \u003d newSafemodeException(\n                 \"Zero blocklocations for \" + srcArg);\n             if (haEnabled \u0026\u0026 haContext !\u003d null \u0026\u0026\n                 haContext.getState().getServiceState() \u003d\u003d HAServiceState.ACTIVE) {\n               throw new RetriableException(se);\n             } else {\n               throw se;\n             }\n           }\n         }\n       }\n     } catch (AccessControlException e) {\n       logAuditEvent(false, \"open\", srcArg);\n       throw e;\n     } finally {\n       readUnlock();\n     }\n \n     logAuditEvent(true, \"open\", srcArg);\n \n     if (!isInSafeMode() \u0026\u0026 res.updateAccessTime()) {\n       String src \u003d srcArg;\n       writeLock();\n       final long now \u003d now();\n       try {\n         checkOperation(OperationCategory.WRITE);\n         /**\n          * Resolve the path again and update the atime only when the file\n          * exists.\n          *\n          * XXX: Races can still occur even after resolving the path again.\n          * For example:\n          *\n          * \u003cul\u003e\n          *   \u003cli\u003eGet the block location for \"/a/b\"\u003c/li\u003e\n          *   \u003cli\u003eRename \"/a/b\" to \"/c/b\"\u003c/li\u003e\n          *   \u003cli\u003eThe second resolution still points to \"/a/b\", which is\n          *   wrong.\u003c/li\u003e\n          * \u003c/ul\u003e\n          *\n          * The behavior is incorrect but consistent with the one before\n          * HDFS-7463. A better fix is to change the edit log of SetTime to\n          * use inode id instead of a path.\n          */\n-        src \u003d dir.resolvePath(pc, srcArg);\n-        final INodesInPath iip \u003d dir.getINodesInPath(src, true);\n+        final INodesInPath iip \u003d dir.resolvePath(pc, srcArg);\n+        src \u003d iip.getPath();\n+\n         INode inode \u003d iip.getLastINode();\n         boolean updateAccessTime \u003d inode !\u003d null \u0026\u0026\n             now \u003e inode.getAccessTime() + dir.getAccessTimePrecision();\n         if (!isInSafeMode() \u0026\u0026 updateAccessTime) {\n           boolean changed \u003d FSDirAttrOp.setTimes(dir,\n               inode, -1, now, false, iip.getLatestSnapshotId());\n           if (changed) {\n             getEditLog().logTimes(src, -1, now);\n           }\n         }\n       } catch (Throwable e) {\n         LOG.warn(\"Failed to update the access time of \" + src, e);\n       } finally {\n         writeUnlock();\n       }\n     }\n \n     LocatedBlocks blocks \u003d res.blocks;\n     sortLocatedBlocks(clientMachine, blocks);\n     return blocks;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlocks getBlockLocations(String clientMachine, String srcArg,\n      long offset, long length) throws IOException {\n    checkOperation(OperationCategory.READ);\n    GetBlockLocationsResult res \u003d null;\n    FSPermissionChecker pc \u003d getPermissionChecker();\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      res \u003d FSDirStatAndListingOp.getBlockLocations(\n          dir, pc, srcArg, offset, length, true);\n      if (isInSafeMode()) {\n        for (LocatedBlock b : res.blocks.getLocatedBlocks()) {\n          // if safemode \u0026 no block locations yet then throw safemodeException\n          if ((b.getLocations() \u003d\u003d null) || (b.getLocations().length \u003d\u003d 0)) {\n            SafeModeException se \u003d newSafemodeException(\n                \"Zero blocklocations for \" + srcArg);\n            if (haEnabled \u0026\u0026 haContext !\u003d null \u0026\u0026\n                haContext.getState().getServiceState() \u003d\u003d HAServiceState.ACTIVE) {\n              throw new RetriableException(se);\n            } else {\n              throw se;\n            }\n          }\n        }\n      }\n    } catch (AccessControlException e) {\n      logAuditEvent(false, \"open\", srcArg);\n      throw e;\n    } finally {\n      readUnlock();\n    }\n\n    logAuditEvent(true, \"open\", srcArg);\n\n    if (!isInSafeMode() \u0026\u0026 res.updateAccessTime()) {\n      String src \u003d srcArg;\n      writeLock();\n      final long now \u003d now();\n      try {\n        checkOperation(OperationCategory.WRITE);\n        /**\n         * Resolve the path again and update the atime only when the file\n         * exists.\n         *\n         * XXX: Races can still occur even after resolving the path again.\n         * For example:\n         *\n         * \u003cul\u003e\n         *   \u003cli\u003eGet the block location for \"/a/b\"\u003c/li\u003e\n         *   \u003cli\u003eRename \"/a/b\" to \"/c/b\"\u003c/li\u003e\n         *   \u003cli\u003eThe second resolution still points to \"/a/b\", which is\n         *   wrong.\u003c/li\u003e\n         * \u003c/ul\u003e\n         *\n         * The behavior is incorrect but consistent with the one before\n         * HDFS-7463. A better fix is to change the edit log of SetTime to\n         * use inode id instead of a path.\n         */\n        final INodesInPath iip \u003d dir.resolvePath(pc, srcArg);\n        src \u003d iip.getPath();\n\n        INode inode \u003d iip.getLastINode();\n        boolean updateAccessTime \u003d inode !\u003d null \u0026\u0026\n            now \u003e inode.getAccessTime() + dir.getAccessTimePrecision();\n        if (!isInSafeMode() \u0026\u0026 updateAccessTime) {\n          boolean changed \u003d FSDirAttrOp.setTimes(dir,\n              inode, -1, now, false, iip.getLatestSnapshotId());\n          if (changed) {\n            getEditLog().logTimes(src, -1, now);\n          }\n        }\n      } catch (Throwable e) {\n        LOG.warn(\"Failed to update the access time of \" + src, e);\n      } finally {\n        writeUnlock();\n      }\n    }\n\n    LocatedBlocks blocks \u003d res.blocks;\n    sortLocatedBlocks(clientMachine, blocks);\n    return blocks;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "03dea65e0b17ca2f9460bb6110f6ab3a321b8bf2": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10744. Internally optimize path component resolution. Contributed by Daryn Sharp.\n",
      "commitDate": "15/08/16 2:45 PM",
      "commitName": "03dea65e0b17ca2f9460bb6110f6ab3a321b8bf2",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "03/08/16 11:12 AM",
      "commitNameOld": "22ef5286bc8511ddee9594b7cecc598bf41a850b",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 12.15,
      "commitsBetweenForRepo": 86,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,83 +1,81 @@\n   LocatedBlocks getBlockLocations(String clientMachine, String srcArg,\n       long offset, long length) throws IOException {\n     checkOperation(OperationCategory.READ);\n     GetBlockLocationsResult res \u003d null;\n     FSPermissionChecker pc \u003d getPermissionChecker();\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n       res \u003d FSDirStatAndListingOp.getBlockLocations(\n           dir, pc, srcArg, offset, length, true);\n       if (isInSafeMode()) {\n         for (LocatedBlock b : res.blocks.getLocatedBlocks()) {\n           // if safemode \u0026 no block locations yet then throw safemodeException\n           if ((b.getLocations() \u003d\u003d null) || (b.getLocations().length \u003d\u003d 0)) {\n             SafeModeException se \u003d newSafemodeException(\n                 \"Zero blocklocations for \" + srcArg);\n             if (haEnabled \u0026\u0026 haContext !\u003d null \u0026\u0026\n                 haContext.getState().getServiceState() \u003d\u003d HAServiceState.ACTIVE) {\n               throw new RetriableException(se);\n             } else {\n               throw se;\n             }\n           }\n         }\n       }\n     } catch (AccessControlException e) {\n       logAuditEvent(false, \"open\", srcArg);\n       throw e;\n     } finally {\n       readUnlock();\n     }\n \n     logAuditEvent(true, \"open\", srcArg);\n \n     if (!isInSafeMode() \u0026\u0026 res.updateAccessTime()) {\n-      byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(\n-          srcArg);\n       String src \u003d srcArg;\n       writeLock();\n       final long now \u003d now();\n       try {\n         checkOperation(OperationCategory.WRITE);\n         /**\n          * Resolve the path again and update the atime only when the file\n          * exists.\n          *\n          * XXX: Races can still occur even after resolving the path again.\n          * For example:\n          *\n          * \u003cul\u003e\n          *   \u003cli\u003eGet the block location for \"/a/b\"\u003c/li\u003e\n          *   \u003cli\u003eRename \"/a/b\" to \"/c/b\"\u003c/li\u003e\n          *   \u003cli\u003eThe second resolution still points to \"/a/b\", which is\n          *   wrong.\u003c/li\u003e\n          * \u003c/ul\u003e\n          *\n          * The behavior is incorrect but consistent with the one before\n          * HDFS-7463. A better fix is to change the edit log of SetTime to\n          * use inode id instead of a path.\n          */\n-        src \u003d dir.resolvePath(pc, srcArg, pathComponents);\n+        src \u003d dir.resolvePath(pc, srcArg);\n         final INodesInPath iip \u003d dir.getINodesInPath(src, true);\n         INode inode \u003d iip.getLastINode();\n         boolean updateAccessTime \u003d inode !\u003d null \u0026\u0026\n             now \u003e inode.getAccessTime() + dir.getAccessTimePrecision();\n         if (!isInSafeMode() \u0026\u0026 updateAccessTime) {\n           boolean changed \u003d FSDirAttrOp.setTimes(dir,\n               inode, -1, now, false, iip.getLatestSnapshotId());\n           if (changed) {\n             getEditLog().logTimes(src, -1, now);\n           }\n         }\n       } catch (Throwable e) {\n         LOG.warn(\"Failed to update the access time of \" + src, e);\n       } finally {\n         writeUnlock();\n       }\n     }\n \n     LocatedBlocks blocks \u003d res.blocks;\n     sortLocatedBlocks(clientMachine, blocks);\n     return blocks;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlocks getBlockLocations(String clientMachine, String srcArg,\n      long offset, long length) throws IOException {\n    checkOperation(OperationCategory.READ);\n    GetBlockLocationsResult res \u003d null;\n    FSPermissionChecker pc \u003d getPermissionChecker();\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      res \u003d FSDirStatAndListingOp.getBlockLocations(\n          dir, pc, srcArg, offset, length, true);\n      if (isInSafeMode()) {\n        for (LocatedBlock b : res.blocks.getLocatedBlocks()) {\n          // if safemode \u0026 no block locations yet then throw safemodeException\n          if ((b.getLocations() \u003d\u003d null) || (b.getLocations().length \u003d\u003d 0)) {\n            SafeModeException se \u003d newSafemodeException(\n                \"Zero blocklocations for \" + srcArg);\n            if (haEnabled \u0026\u0026 haContext !\u003d null \u0026\u0026\n                haContext.getState().getServiceState() \u003d\u003d HAServiceState.ACTIVE) {\n              throw new RetriableException(se);\n            } else {\n              throw se;\n            }\n          }\n        }\n      }\n    } catch (AccessControlException e) {\n      logAuditEvent(false, \"open\", srcArg);\n      throw e;\n    } finally {\n      readUnlock();\n    }\n\n    logAuditEvent(true, \"open\", srcArg);\n\n    if (!isInSafeMode() \u0026\u0026 res.updateAccessTime()) {\n      String src \u003d srcArg;\n      writeLock();\n      final long now \u003d now();\n      try {\n        checkOperation(OperationCategory.WRITE);\n        /**\n         * Resolve the path again and update the atime only when the file\n         * exists.\n         *\n         * XXX: Races can still occur even after resolving the path again.\n         * For example:\n         *\n         * \u003cul\u003e\n         *   \u003cli\u003eGet the block location for \"/a/b\"\u003c/li\u003e\n         *   \u003cli\u003eRename \"/a/b\" to \"/c/b\"\u003c/li\u003e\n         *   \u003cli\u003eThe second resolution still points to \"/a/b\", which is\n         *   wrong.\u003c/li\u003e\n         * \u003c/ul\u003e\n         *\n         * The behavior is incorrect but consistent with the one before\n         * HDFS-7463. A better fix is to change the edit log of SetTime to\n         * use inode id instead of a path.\n         */\n        src \u003d dir.resolvePath(pc, srcArg);\n        final INodesInPath iip \u003d dir.getINodesInPath(src, true);\n        INode inode \u003d iip.getLastINode();\n        boolean updateAccessTime \u003d inode !\u003d null \u0026\u0026\n            now \u003e inode.getAccessTime() + dir.getAccessTimePrecision();\n        if (!isInSafeMode() \u0026\u0026 updateAccessTime) {\n          boolean changed \u003d FSDirAttrOp.setTimes(dir,\n              inode, -1, now, false, iip.getLatestSnapshotId());\n          if (changed) {\n            getEditLog().logTimes(src, -1, now);\n          }\n        }\n      } catch (Throwable e) {\n        LOG.warn(\"Failed to update the access time of \" + src, e);\n      } finally {\n        writeUnlock();\n      }\n    }\n\n    LocatedBlocks blocks \u003d res.blocks;\n    sortLocatedBlocks(clientMachine, blocks);\n    return blocks;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "6ef42873a02bfcbff5521869f4d6f66539d1db41": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9918. Erasure Coding: Sort located striped blocks based on decommissioned states. Contributed by Rakesh R.\n",
      "commitDate": "12/04/16 1:38 PM",
      "commitName": "6ef42873a02bfcbff5521869f4d6f66539d1db41",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "12/04/16 10:52 AM",
      "commitNameOld": "600d129bb8d52ae820e7b74b8ce363aabd69d25c",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 0.12,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,100 +1,83 @@\n   LocatedBlocks getBlockLocations(String clientMachine, String srcArg,\n       long offset, long length) throws IOException {\n     checkOperation(OperationCategory.READ);\n     GetBlockLocationsResult res \u003d null;\n     FSPermissionChecker pc \u003d getPermissionChecker();\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n       res \u003d FSDirStatAndListingOp.getBlockLocations(\n           dir, pc, srcArg, offset, length, true);\n       if (isInSafeMode()) {\n         for (LocatedBlock b : res.blocks.getLocatedBlocks()) {\n           // if safemode \u0026 no block locations yet then throw safemodeException\n           if ((b.getLocations() \u003d\u003d null) || (b.getLocations().length \u003d\u003d 0)) {\n             SafeModeException se \u003d newSafemodeException(\n                 \"Zero blocklocations for \" + srcArg);\n             if (haEnabled \u0026\u0026 haContext !\u003d null \u0026\u0026\n                 haContext.getState().getServiceState() \u003d\u003d HAServiceState.ACTIVE) {\n               throw new RetriableException(se);\n             } else {\n               throw se;\n             }\n           }\n         }\n       }\n     } catch (AccessControlException e) {\n       logAuditEvent(false, \"open\", srcArg);\n       throw e;\n     } finally {\n       readUnlock();\n     }\n \n     logAuditEvent(true, \"open\", srcArg);\n \n     if (!isInSafeMode() \u0026\u0026 res.updateAccessTime()) {\n       byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(\n           srcArg);\n       String src \u003d srcArg;\n       writeLock();\n       final long now \u003d now();\n       try {\n         checkOperation(OperationCategory.WRITE);\n         /**\n          * Resolve the path again and update the atime only when the file\n          * exists.\n          *\n          * XXX: Races can still occur even after resolving the path again.\n          * For example:\n          *\n          * \u003cul\u003e\n          *   \u003cli\u003eGet the block location for \"/a/b\"\u003c/li\u003e\n          *   \u003cli\u003eRename \"/a/b\" to \"/c/b\"\u003c/li\u003e\n          *   \u003cli\u003eThe second resolution still points to \"/a/b\", which is\n          *   wrong.\u003c/li\u003e\n          * \u003c/ul\u003e\n          *\n          * The behavior is incorrect but consistent with the one before\n          * HDFS-7463. A better fix is to change the edit log of SetTime to\n          * use inode id instead of a path.\n          */\n         src \u003d dir.resolvePath(pc, srcArg, pathComponents);\n         final INodesInPath iip \u003d dir.getINodesInPath(src, true);\n         INode inode \u003d iip.getLastINode();\n         boolean updateAccessTime \u003d inode !\u003d null \u0026\u0026\n             now \u003e inode.getAccessTime() + dir.getAccessTimePrecision();\n         if (!isInSafeMode() \u0026\u0026 updateAccessTime) {\n           boolean changed \u003d FSDirAttrOp.setTimes(dir,\n               inode, -1, now, false, iip.getLatestSnapshotId());\n           if (changed) {\n             getEditLog().logTimes(src, -1, now);\n           }\n         }\n       } catch (Throwable e) {\n         LOG.warn(\"Failed to update the access time of \" + src, e);\n       } finally {\n         writeUnlock();\n       }\n     }\n \n     LocatedBlocks blocks \u003d res.blocks;\n-    if (blocks !\u003d null) {\n-      List\u003cLocatedBlock\u003e blkList \u003d blocks.getLocatedBlocks();\n-      if (blkList \u003d\u003d null || blkList.size() \u003d\u003d 0 ||\n-          blkList.get(0) instanceof LocatedStripedBlock) {\n-        // no need to sort locations for striped blocks\n-        return blocks;\n-      }\n-      blockManager.getDatanodeManager().sortLocatedBlocks(\n-          clientMachine, blkList);\n-\n-      // lastBlock is not part of getLocatedBlocks(), might need to sort it too\n-      LocatedBlock lastBlock \u003d blocks.getLastLocatedBlock();\n-      if (lastBlock !\u003d null) {\n-        ArrayList\u003cLocatedBlock\u003e lastBlockList \u003d Lists.newArrayList(lastBlock);\n-        blockManager.getDatanodeManager().sortLocatedBlocks(\n-            clientMachine, lastBlockList);\n-      }\n-    }\n+    sortLocatedBlocks(clientMachine, blocks);\n     return blocks;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlocks getBlockLocations(String clientMachine, String srcArg,\n      long offset, long length) throws IOException {\n    checkOperation(OperationCategory.READ);\n    GetBlockLocationsResult res \u003d null;\n    FSPermissionChecker pc \u003d getPermissionChecker();\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      res \u003d FSDirStatAndListingOp.getBlockLocations(\n          dir, pc, srcArg, offset, length, true);\n      if (isInSafeMode()) {\n        for (LocatedBlock b : res.blocks.getLocatedBlocks()) {\n          // if safemode \u0026 no block locations yet then throw safemodeException\n          if ((b.getLocations() \u003d\u003d null) || (b.getLocations().length \u003d\u003d 0)) {\n            SafeModeException se \u003d newSafemodeException(\n                \"Zero blocklocations for \" + srcArg);\n            if (haEnabled \u0026\u0026 haContext !\u003d null \u0026\u0026\n                haContext.getState().getServiceState() \u003d\u003d HAServiceState.ACTIVE) {\n              throw new RetriableException(se);\n            } else {\n              throw se;\n            }\n          }\n        }\n      }\n    } catch (AccessControlException e) {\n      logAuditEvent(false, \"open\", srcArg);\n      throw e;\n    } finally {\n      readUnlock();\n    }\n\n    logAuditEvent(true, \"open\", srcArg);\n\n    if (!isInSafeMode() \u0026\u0026 res.updateAccessTime()) {\n      byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(\n          srcArg);\n      String src \u003d srcArg;\n      writeLock();\n      final long now \u003d now();\n      try {\n        checkOperation(OperationCategory.WRITE);\n        /**\n         * Resolve the path again and update the atime only when the file\n         * exists.\n         *\n         * XXX: Races can still occur even after resolving the path again.\n         * For example:\n         *\n         * \u003cul\u003e\n         *   \u003cli\u003eGet the block location for \"/a/b\"\u003c/li\u003e\n         *   \u003cli\u003eRename \"/a/b\" to \"/c/b\"\u003c/li\u003e\n         *   \u003cli\u003eThe second resolution still points to \"/a/b\", which is\n         *   wrong.\u003c/li\u003e\n         * \u003c/ul\u003e\n         *\n         * The behavior is incorrect but consistent with the one before\n         * HDFS-7463. A better fix is to change the edit log of SetTime to\n         * use inode id instead of a path.\n         */\n        src \u003d dir.resolvePath(pc, srcArg, pathComponents);\n        final INodesInPath iip \u003d dir.getINodesInPath(src, true);\n        INode inode \u003d iip.getLastINode();\n        boolean updateAccessTime \u003d inode !\u003d null \u0026\u0026\n            now \u003e inode.getAccessTime() + dir.getAccessTimePrecision();\n        if (!isInSafeMode() \u0026\u0026 updateAccessTime) {\n          boolean changed \u003d FSDirAttrOp.setTimes(dir,\n              inode, -1, now, false, iip.getLatestSnapshotId());\n          if (changed) {\n            getEditLog().logTimes(src, -1, now);\n          }\n        }\n      } catch (Throwable e) {\n        LOG.warn(\"Failed to update the access time of \" + src, e);\n      } finally {\n        writeUnlock();\n      }\n    }\n\n    LocatedBlocks blocks \u003d res.blocks;\n    sortLocatedBlocks(clientMachine, blocks);\n    return blocks;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "015535dc0ad00c2ba357afb3d1e283e56ddda0d6": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8446. Separate safemode related operations in GetBlockLocations(). Contributed by Haohui Mai.\n",
      "commitDate": "17/06/15 4:38 PM",
      "commitName": "015535dc0ad00c2ba357afb3d1e283e56ddda0d6",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "17/06/15 8:05 AM",
      "commitNameOld": "6e3fcffe291faec40fa9214f4880a35a952836c4",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 0.36,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,78 +1,94 @@\n   LocatedBlocks getBlockLocations(String clientMachine, String srcArg,\n       long offset, long length) throws IOException {\n     checkOperation(OperationCategory.READ);\n     GetBlockLocationsResult res \u003d null;\n     FSPermissionChecker pc \u003d getPermissionChecker();\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n-      res \u003d getBlockLocations(pc, srcArg, offset, length, true, true);\n+      res \u003d FSDirStatAndListingOp.getBlockLocations(\n+          dir, pc, srcArg, offset, length, true);\n+      if (isInSafeMode()) {\n+        for (LocatedBlock b : res.blocks.getLocatedBlocks()) {\n+          // if safemode \u0026 no block locations yet then throw safemodeException\n+          if ((b.getLocations() \u003d\u003d null) || (b.getLocations().length \u003d\u003d 0)) {\n+            SafeModeException se \u003d newSafemodeException(\n+                \"Zero blocklocations for \" + srcArg);\n+            if (haEnabled \u0026\u0026 haContext !\u003d null \u0026\u0026\n+                haContext.getState().getServiceState() \u003d\u003d HAServiceState.ACTIVE) {\n+              throw new RetriableException(se);\n+            } else {\n+              throw se;\n+            }\n+          }\n+        }\n+      }\n     } catch (AccessControlException e) {\n       logAuditEvent(false, \"open\", srcArg);\n       throw e;\n     } finally {\n       readUnlock();\n     }\n \n     logAuditEvent(true, \"open\", srcArg);\n \n-    if (res.updateAccessTime()) {\n+    if (!isInSafeMode() \u0026\u0026 res.updateAccessTime()) {\n       byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(\n           srcArg);\n       String src \u003d srcArg;\n       writeLock();\n       final long now \u003d now();\n       try {\n         checkOperation(OperationCategory.WRITE);\n         /**\n          * Resolve the path again and update the atime only when the file\n          * exists.\n          *\n          * XXX: Races can still occur even after resolving the path again.\n          * For example:\n          *\n          * \u003cul\u003e\n          *   \u003cli\u003eGet the block location for \"/a/b\"\u003c/li\u003e\n          *   \u003cli\u003eRename \"/a/b\" to \"/c/b\"\u003c/li\u003e\n          *   \u003cli\u003eThe second resolution still points to \"/a/b\", which is\n          *   wrong.\u003c/li\u003e\n          * \u003c/ul\u003e\n          *\n          * The behavior is incorrect but consistent with the one before\n          * HDFS-7463. A better fix is to change the edit log of SetTime to\n          * use inode id instead of a path.\n          */\n         src \u003d dir.resolvePath(pc, srcArg, pathComponents);\n         final INodesInPath iip \u003d dir.getINodesInPath(src, true);\n         INode inode \u003d iip.getLastINode();\n         boolean updateAccessTime \u003d inode !\u003d null \u0026\u0026\n-            now \u003e inode.getAccessTime() + getAccessTimePrecision();\n+            now \u003e inode.getAccessTime() + dir.getAccessTimePrecision();\n         if (!isInSafeMode() \u0026\u0026 updateAccessTime) {\n           boolean changed \u003d FSDirAttrOp.setTimes(dir,\n               inode, -1, now, false, iip.getLatestSnapshotId());\n           if (changed) {\n             getEditLog().logTimes(src, -1, now);\n           }\n         }\n       } catch (Throwable e) {\n         LOG.warn(\"Failed to update the access time of \" + src, e);\n       } finally {\n         writeUnlock();\n       }\n     }\n \n     LocatedBlocks blocks \u003d res.blocks;\n     if (blocks !\u003d null) {\n       blockManager.getDatanodeManager().sortLocatedBlocks(\n           clientMachine, blocks.getLocatedBlocks());\n \n       // lastBlock is not part of getLocatedBlocks(), might need to sort it too\n       LocatedBlock lastBlock \u003d blocks.getLastLocatedBlock();\n       if (lastBlock !\u003d null) {\n         ArrayList\u003cLocatedBlock\u003e lastBlockList \u003d Lists.newArrayList(lastBlock);\n         blockManager.getDatanodeManager().sortLocatedBlocks(\n             clientMachine, lastBlockList);\n       }\n     }\n     return blocks;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlocks getBlockLocations(String clientMachine, String srcArg,\n      long offset, long length) throws IOException {\n    checkOperation(OperationCategory.READ);\n    GetBlockLocationsResult res \u003d null;\n    FSPermissionChecker pc \u003d getPermissionChecker();\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      res \u003d FSDirStatAndListingOp.getBlockLocations(\n          dir, pc, srcArg, offset, length, true);\n      if (isInSafeMode()) {\n        for (LocatedBlock b : res.blocks.getLocatedBlocks()) {\n          // if safemode \u0026 no block locations yet then throw safemodeException\n          if ((b.getLocations() \u003d\u003d null) || (b.getLocations().length \u003d\u003d 0)) {\n            SafeModeException se \u003d newSafemodeException(\n                \"Zero blocklocations for \" + srcArg);\n            if (haEnabled \u0026\u0026 haContext !\u003d null \u0026\u0026\n                haContext.getState().getServiceState() \u003d\u003d HAServiceState.ACTIVE) {\n              throw new RetriableException(se);\n            } else {\n              throw se;\n            }\n          }\n        }\n      }\n    } catch (AccessControlException e) {\n      logAuditEvent(false, \"open\", srcArg);\n      throw e;\n    } finally {\n      readUnlock();\n    }\n\n    logAuditEvent(true, \"open\", srcArg);\n\n    if (!isInSafeMode() \u0026\u0026 res.updateAccessTime()) {\n      byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(\n          srcArg);\n      String src \u003d srcArg;\n      writeLock();\n      final long now \u003d now();\n      try {\n        checkOperation(OperationCategory.WRITE);\n        /**\n         * Resolve the path again and update the atime only when the file\n         * exists.\n         *\n         * XXX: Races can still occur even after resolving the path again.\n         * For example:\n         *\n         * \u003cul\u003e\n         *   \u003cli\u003eGet the block location for \"/a/b\"\u003c/li\u003e\n         *   \u003cli\u003eRename \"/a/b\" to \"/c/b\"\u003c/li\u003e\n         *   \u003cli\u003eThe second resolution still points to \"/a/b\", which is\n         *   wrong.\u003c/li\u003e\n         * \u003c/ul\u003e\n         *\n         * The behavior is incorrect but consistent with the one before\n         * HDFS-7463. A better fix is to change the edit log of SetTime to\n         * use inode id instead of a path.\n         */\n        src \u003d dir.resolvePath(pc, srcArg, pathComponents);\n        final INodesInPath iip \u003d dir.getINodesInPath(src, true);\n        INode inode \u003d iip.getLastINode();\n        boolean updateAccessTime \u003d inode !\u003d null \u0026\u0026\n            now \u003e inode.getAccessTime() + dir.getAccessTimePrecision();\n        if (!isInSafeMode() \u0026\u0026 updateAccessTime) {\n          boolean changed \u003d FSDirAttrOp.setTimes(dir,\n              inode, -1, now, false, iip.getLatestSnapshotId());\n          if (changed) {\n            getEditLog().logTimes(src, -1, now);\n          }\n        }\n      } catch (Throwable e) {\n        LOG.warn(\"Failed to update the access time of \" + src, e);\n      } finally {\n        writeUnlock();\n      }\n    }\n\n    LocatedBlocks blocks \u003d res.blocks;\n    if (blocks !\u003d null) {\n      blockManager.getDatanodeManager().sortLocatedBlocks(\n          clientMachine, blocks.getLocatedBlocks());\n\n      // lastBlock is not part of getLocatedBlocks(), might need to sort it too\n      LocatedBlock lastBlock \u003d blocks.getLastLocatedBlock();\n      if (lastBlock !\u003d null) {\n        ArrayList\u003cLocatedBlock\u003e lastBlockList \u003d Lists.newArrayList(lastBlock);\n        blockManager.getDatanodeManager().sortLocatedBlocks(\n            clientMachine, lastBlockList);\n      }\n    }\n    return blocks;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "f05c21285ef23b6a973d69f045b1cb46c5abc039": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7853. Erasure coding: extend LocatedBlocks to support reading from striped files. Contributed by Jing Zhao.\n",
      "commitDate": "26/05/15 11:32 AM",
      "commitName": "f05c21285ef23b6a973d69f045b1cb46c5abc039",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "26/05/15 11:32 AM",
      "commitNameOld": "1e1e93040748231dc913190aec1e031c379d8271",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,78 +1,84 @@\n   LocatedBlocks getBlockLocations(String clientMachine, String srcArg,\n       long offset, long length) throws IOException {\n     checkOperation(OperationCategory.READ);\n     GetBlockLocationsResult res \u003d null;\n     FSPermissionChecker pc \u003d getPermissionChecker();\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n       res \u003d getBlockLocations(pc, srcArg, offset, length, true, true);\n     } catch (AccessControlException e) {\n       logAuditEvent(false, \"open\", srcArg);\n       throw e;\n     } finally {\n       readUnlock();\n     }\n \n     logAuditEvent(true, \"open\", srcArg);\n \n     if (res.updateAccessTime()) {\n       byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(\n           srcArg);\n       String src \u003d srcArg;\n       writeLock();\n       final long now \u003d now();\n       try {\n         checkOperation(OperationCategory.WRITE);\n         /**\n          * Resolve the path again and update the atime only when the file\n          * exists.\n          *\n          * XXX: Races can still occur even after resolving the path again.\n          * For example:\n          *\n          * \u003cul\u003e\n          *   \u003cli\u003eGet the block location for \"/a/b\"\u003c/li\u003e\n          *   \u003cli\u003eRename \"/a/b\" to \"/c/b\"\u003c/li\u003e\n          *   \u003cli\u003eThe second resolution still points to \"/a/b\", which is\n          *   wrong.\u003c/li\u003e\n          * \u003c/ul\u003e\n          *\n          * The behavior is incorrect but consistent with the one before\n          * HDFS-7463. A better fix is to change the edit log of SetTime to\n          * use inode id instead of a path.\n          */\n         src \u003d dir.resolvePath(pc, srcArg, pathComponents);\n         final INodesInPath iip \u003d dir.getINodesInPath(src, true);\n         INode inode \u003d iip.getLastINode();\n         boolean updateAccessTime \u003d inode !\u003d null \u0026\u0026\n             now \u003e inode.getAccessTime() + getAccessTimePrecision();\n         if (!isInSafeMode() \u0026\u0026 updateAccessTime) {\n           boolean changed \u003d FSDirAttrOp.setTimes(dir,\n               inode, -1, now, false, iip.getLatestSnapshotId());\n           if (changed) {\n             getEditLog().logTimes(src, -1, now);\n           }\n         }\n       } catch (Throwable e) {\n         LOG.warn(\"Failed to update the access time of \" + src, e);\n       } finally {\n         writeUnlock();\n       }\n     }\n \n     LocatedBlocks blocks \u003d res.blocks;\n     if (blocks !\u003d null) {\n+      List\u003cLocatedBlock\u003e blkList \u003d blocks.getLocatedBlocks();\n+      if (blkList \u003d\u003d null || blkList.size() \u003d\u003d 0 ||\n+          blkList.get(0) instanceof LocatedStripedBlock) {\n+        // no need to sort locations for striped blocks\n+        return blocks;\n+      }\n       blockManager.getDatanodeManager().sortLocatedBlocks(\n-          clientMachine, blocks.getLocatedBlocks());\n+          clientMachine, blkList);\n \n       // lastBlock is not part of getLocatedBlocks(), might need to sort it too\n       LocatedBlock lastBlock \u003d blocks.getLastLocatedBlock();\n       if (lastBlock !\u003d null) {\n         ArrayList\u003cLocatedBlock\u003e lastBlockList \u003d Lists.newArrayList(lastBlock);\n         blockManager.getDatanodeManager().sortLocatedBlocks(\n             clientMachine, lastBlockList);\n       }\n     }\n     return blocks;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlocks getBlockLocations(String clientMachine, String srcArg,\n      long offset, long length) throws IOException {\n    checkOperation(OperationCategory.READ);\n    GetBlockLocationsResult res \u003d null;\n    FSPermissionChecker pc \u003d getPermissionChecker();\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      res \u003d getBlockLocations(pc, srcArg, offset, length, true, true);\n    } catch (AccessControlException e) {\n      logAuditEvent(false, \"open\", srcArg);\n      throw e;\n    } finally {\n      readUnlock();\n    }\n\n    logAuditEvent(true, \"open\", srcArg);\n\n    if (res.updateAccessTime()) {\n      byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(\n          srcArg);\n      String src \u003d srcArg;\n      writeLock();\n      final long now \u003d now();\n      try {\n        checkOperation(OperationCategory.WRITE);\n        /**\n         * Resolve the path again and update the atime only when the file\n         * exists.\n         *\n         * XXX: Races can still occur even after resolving the path again.\n         * For example:\n         *\n         * \u003cul\u003e\n         *   \u003cli\u003eGet the block location for \"/a/b\"\u003c/li\u003e\n         *   \u003cli\u003eRename \"/a/b\" to \"/c/b\"\u003c/li\u003e\n         *   \u003cli\u003eThe second resolution still points to \"/a/b\", which is\n         *   wrong.\u003c/li\u003e\n         * \u003c/ul\u003e\n         *\n         * The behavior is incorrect but consistent with the one before\n         * HDFS-7463. A better fix is to change the edit log of SetTime to\n         * use inode id instead of a path.\n         */\n        src \u003d dir.resolvePath(pc, srcArg, pathComponents);\n        final INodesInPath iip \u003d dir.getINodesInPath(src, true);\n        INode inode \u003d iip.getLastINode();\n        boolean updateAccessTime \u003d inode !\u003d null \u0026\u0026\n            now \u003e inode.getAccessTime() + getAccessTimePrecision();\n        if (!isInSafeMode() \u0026\u0026 updateAccessTime) {\n          boolean changed \u003d FSDirAttrOp.setTimes(dir,\n              inode, -1, now, false, iip.getLatestSnapshotId());\n          if (changed) {\n            getEditLog().logTimes(src, -1, now);\n          }\n        }\n      } catch (Throwable e) {\n        LOG.warn(\"Failed to update the access time of \" + src, e);\n      } finally {\n        writeUnlock();\n      }\n    }\n\n    LocatedBlocks blocks \u003d res.blocks;\n    if (blocks !\u003d null) {\n      List\u003cLocatedBlock\u003e blkList \u003d blocks.getLocatedBlocks();\n      if (blkList \u003d\u003d null || blkList.size() \u003d\u003d 0 ||\n          blkList.get(0) instanceof LocatedStripedBlock) {\n        // no need to sort locations for striped blocks\n        return blocks;\n      }\n      blockManager.getDatanodeManager().sortLocatedBlocks(\n          clientMachine, blkList);\n\n      // lastBlock is not part of getLocatedBlocks(), might need to sort it too\n      LocatedBlock lastBlock \u003d blocks.getLastLocatedBlock();\n      if (lastBlock !\u003d null) {\n        ArrayList\u003cLocatedBlock\u003e lastBlockList \u003d Lists.newArrayList(lastBlock);\n        blockManager.getDatanodeManager().sortLocatedBlocks(\n            clientMachine, lastBlockList);\n      }\n    }\n    return blocks;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "3dd6395bb2448e5b178a51c864e3c9a3d12e8bc9": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-8269. getBlockLocations() does not resolve the .reserved path and generates incorrect edit logs when updating the atime. Contributed by Haohui Mai.\n",
      "commitDate": "29/04/15 11:12 AM",
      "commitName": "3dd6395bb2448e5b178a51c864e3c9a3d12e8bc9",
      "commitAuthor": "Haohui Mai",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-8269. getBlockLocations() does not resolve the .reserved path and generates incorrect edit logs when updating the atime. Contributed by Haohui Mai.\n",
          "commitDate": "29/04/15 11:12 AM",
          "commitName": "3dd6395bb2448e5b178a51c864e3c9a3d12e8bc9",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "28/04/15 6:05 PM",
          "commitNameOld": "c79e7f7d997596e0c38ae4cddff2bd0910581c16",
          "commitAuthorOld": "Haohui Mai",
          "daysBetweenCommits": 0.71,
          "commitsBetweenForRepo": 4,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,54 +1,78 @@\n-  LocatedBlocks getBlockLocations(String clientMachine, String src,\n+  LocatedBlocks getBlockLocations(String clientMachine, String srcArg,\n       long offset, long length) throws IOException {\n     checkOperation(OperationCategory.READ);\n     GetBlockLocationsResult res \u003d null;\n+    FSPermissionChecker pc \u003d getPermissionChecker();\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n-      res \u003d getBlockLocations(src, offset, length, true, true);\n+      res \u003d getBlockLocations(pc, srcArg, offset, length, true, true);\n     } catch (AccessControlException e) {\n-      logAuditEvent(false, \"open\", src);\n+      logAuditEvent(false, \"open\", srcArg);\n       throw e;\n     } finally {\n       readUnlock();\n     }\n \n-    logAuditEvent(true, \"open\", src);\n+    logAuditEvent(true, \"open\", srcArg);\n \n     if (res.updateAccessTime()) {\n+      byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(\n+          srcArg);\n+      String src \u003d srcArg;\n       writeLock();\n       final long now \u003d now();\n       try {\n         checkOperation(OperationCategory.WRITE);\n-        INode inode \u003d res.iip.getLastINode();\n-        boolean updateAccessTime \u003d now \u003e inode.getAccessTime() +\n-            getAccessTimePrecision();\n+        /**\n+         * Resolve the path again and update the atime only when the file\n+         * exists.\n+         *\n+         * XXX: Races can still occur even after resolving the path again.\n+         * For example:\n+         *\n+         * \u003cul\u003e\n+         *   \u003cli\u003eGet the block location for \"/a/b\"\u003c/li\u003e\n+         *   \u003cli\u003eRename \"/a/b\" to \"/c/b\"\u003c/li\u003e\n+         *   \u003cli\u003eThe second resolution still points to \"/a/b\", which is\n+         *   wrong.\u003c/li\u003e\n+         * \u003c/ul\u003e\n+         *\n+         * The behavior is incorrect but consistent with the one before\n+         * HDFS-7463. A better fix is to change the edit log of SetTime to\n+         * use inode id instead of a path.\n+         */\n+        src \u003d dir.resolvePath(pc, srcArg, pathComponents);\n+        final INodesInPath iip \u003d dir.getINodesInPath(src, true);\n+        INode inode \u003d iip.getLastINode();\n+        boolean updateAccessTime \u003d inode !\u003d null \u0026\u0026\n+            now \u003e inode.getAccessTime() + getAccessTimePrecision();\n         if (!isInSafeMode() \u0026\u0026 updateAccessTime) {\n           boolean changed \u003d FSDirAttrOp.setTimes(dir,\n-              inode, -1, now, false, res.iip.getLatestSnapshotId());\n+              inode, -1, now, false, iip.getLatestSnapshotId());\n           if (changed) {\n             getEditLog().logTimes(src, -1, now);\n           }\n         }\n       } catch (Throwable e) {\n         LOG.warn(\"Failed to update the access time of \" + src, e);\n       } finally {\n         writeUnlock();\n       }\n     }\n \n     LocatedBlocks blocks \u003d res.blocks;\n     if (blocks !\u003d null) {\n       blockManager.getDatanodeManager().sortLocatedBlocks(\n           clientMachine, blocks.getLocatedBlocks());\n \n       // lastBlock is not part of getLocatedBlocks(), might need to sort it too\n       LocatedBlock lastBlock \u003d blocks.getLastLocatedBlock();\n       if (lastBlock !\u003d null) {\n         ArrayList\u003cLocatedBlock\u003e lastBlockList \u003d Lists.newArrayList(lastBlock);\n         blockManager.getDatanodeManager().sortLocatedBlocks(\n             clientMachine, lastBlockList);\n       }\n     }\n     return blocks;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  LocatedBlocks getBlockLocations(String clientMachine, String srcArg,\n      long offset, long length) throws IOException {\n    checkOperation(OperationCategory.READ);\n    GetBlockLocationsResult res \u003d null;\n    FSPermissionChecker pc \u003d getPermissionChecker();\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      res \u003d getBlockLocations(pc, srcArg, offset, length, true, true);\n    } catch (AccessControlException e) {\n      logAuditEvent(false, \"open\", srcArg);\n      throw e;\n    } finally {\n      readUnlock();\n    }\n\n    logAuditEvent(true, \"open\", srcArg);\n\n    if (res.updateAccessTime()) {\n      byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(\n          srcArg);\n      String src \u003d srcArg;\n      writeLock();\n      final long now \u003d now();\n      try {\n        checkOperation(OperationCategory.WRITE);\n        /**\n         * Resolve the path again and update the atime only when the file\n         * exists.\n         *\n         * XXX: Races can still occur even after resolving the path again.\n         * For example:\n         *\n         * \u003cul\u003e\n         *   \u003cli\u003eGet the block location for \"/a/b\"\u003c/li\u003e\n         *   \u003cli\u003eRename \"/a/b\" to \"/c/b\"\u003c/li\u003e\n         *   \u003cli\u003eThe second resolution still points to \"/a/b\", which is\n         *   wrong.\u003c/li\u003e\n         * \u003c/ul\u003e\n         *\n         * The behavior is incorrect but consistent with the one before\n         * HDFS-7463. A better fix is to change the edit log of SetTime to\n         * use inode id instead of a path.\n         */\n        src \u003d dir.resolvePath(pc, srcArg, pathComponents);\n        final INodesInPath iip \u003d dir.getINodesInPath(src, true);\n        INode inode \u003d iip.getLastINode();\n        boolean updateAccessTime \u003d inode !\u003d null \u0026\u0026\n            now \u003e inode.getAccessTime() + getAccessTimePrecision();\n        if (!isInSafeMode() \u0026\u0026 updateAccessTime) {\n          boolean changed \u003d FSDirAttrOp.setTimes(dir,\n              inode, -1, now, false, iip.getLatestSnapshotId());\n          if (changed) {\n            getEditLog().logTimes(src, -1, now);\n          }\n        }\n      } catch (Throwable e) {\n        LOG.warn(\"Failed to update the access time of \" + src, e);\n      } finally {\n        writeUnlock();\n      }\n    }\n\n    LocatedBlocks blocks \u003d res.blocks;\n    if (blocks !\u003d null) {\n      blockManager.getDatanodeManager().sortLocatedBlocks(\n          clientMachine, blocks.getLocatedBlocks());\n\n      // lastBlock is not part of getLocatedBlocks(), might need to sort it too\n      LocatedBlock lastBlock \u003d blocks.getLastLocatedBlock();\n      if (lastBlock !\u003d null) {\n        ArrayList\u003cLocatedBlock\u003e lastBlockList \u003d Lists.newArrayList(lastBlock);\n        blockManager.getDatanodeManager().sortLocatedBlocks(\n            clientMachine, lastBlockList);\n      }\n    }\n    return blocks;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {
            "oldValue": "[clientMachine-String, src-String, offset-long, length-long]",
            "newValue": "[clientMachine-String, srcArg-String, offset-long, length-long]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-8269. getBlockLocations() does not resolve the .reserved path and generates incorrect edit logs when updating the atime. Contributed by Haohui Mai.\n",
          "commitDate": "29/04/15 11:12 AM",
          "commitName": "3dd6395bb2448e5b178a51c864e3c9a3d12e8bc9",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "28/04/15 6:05 PM",
          "commitNameOld": "c79e7f7d997596e0c38ae4cddff2bd0910581c16",
          "commitAuthorOld": "Haohui Mai",
          "daysBetweenCommits": 0.71,
          "commitsBetweenForRepo": 4,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,54 +1,78 @@\n-  LocatedBlocks getBlockLocations(String clientMachine, String src,\n+  LocatedBlocks getBlockLocations(String clientMachine, String srcArg,\n       long offset, long length) throws IOException {\n     checkOperation(OperationCategory.READ);\n     GetBlockLocationsResult res \u003d null;\n+    FSPermissionChecker pc \u003d getPermissionChecker();\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n-      res \u003d getBlockLocations(src, offset, length, true, true);\n+      res \u003d getBlockLocations(pc, srcArg, offset, length, true, true);\n     } catch (AccessControlException e) {\n-      logAuditEvent(false, \"open\", src);\n+      logAuditEvent(false, \"open\", srcArg);\n       throw e;\n     } finally {\n       readUnlock();\n     }\n \n-    logAuditEvent(true, \"open\", src);\n+    logAuditEvent(true, \"open\", srcArg);\n \n     if (res.updateAccessTime()) {\n+      byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(\n+          srcArg);\n+      String src \u003d srcArg;\n       writeLock();\n       final long now \u003d now();\n       try {\n         checkOperation(OperationCategory.WRITE);\n-        INode inode \u003d res.iip.getLastINode();\n-        boolean updateAccessTime \u003d now \u003e inode.getAccessTime() +\n-            getAccessTimePrecision();\n+        /**\n+         * Resolve the path again and update the atime only when the file\n+         * exists.\n+         *\n+         * XXX: Races can still occur even after resolving the path again.\n+         * For example:\n+         *\n+         * \u003cul\u003e\n+         *   \u003cli\u003eGet the block location for \"/a/b\"\u003c/li\u003e\n+         *   \u003cli\u003eRename \"/a/b\" to \"/c/b\"\u003c/li\u003e\n+         *   \u003cli\u003eThe second resolution still points to \"/a/b\", which is\n+         *   wrong.\u003c/li\u003e\n+         * \u003c/ul\u003e\n+         *\n+         * The behavior is incorrect but consistent with the one before\n+         * HDFS-7463. A better fix is to change the edit log of SetTime to\n+         * use inode id instead of a path.\n+         */\n+        src \u003d dir.resolvePath(pc, srcArg, pathComponents);\n+        final INodesInPath iip \u003d dir.getINodesInPath(src, true);\n+        INode inode \u003d iip.getLastINode();\n+        boolean updateAccessTime \u003d inode !\u003d null \u0026\u0026\n+            now \u003e inode.getAccessTime() + getAccessTimePrecision();\n         if (!isInSafeMode() \u0026\u0026 updateAccessTime) {\n           boolean changed \u003d FSDirAttrOp.setTimes(dir,\n-              inode, -1, now, false, res.iip.getLatestSnapshotId());\n+              inode, -1, now, false, iip.getLatestSnapshotId());\n           if (changed) {\n             getEditLog().logTimes(src, -1, now);\n           }\n         }\n       } catch (Throwable e) {\n         LOG.warn(\"Failed to update the access time of \" + src, e);\n       } finally {\n         writeUnlock();\n       }\n     }\n \n     LocatedBlocks blocks \u003d res.blocks;\n     if (blocks !\u003d null) {\n       blockManager.getDatanodeManager().sortLocatedBlocks(\n           clientMachine, blocks.getLocatedBlocks());\n \n       // lastBlock is not part of getLocatedBlocks(), might need to sort it too\n       LocatedBlock lastBlock \u003d blocks.getLastLocatedBlock();\n       if (lastBlock !\u003d null) {\n         ArrayList\u003cLocatedBlock\u003e lastBlockList \u003d Lists.newArrayList(lastBlock);\n         blockManager.getDatanodeManager().sortLocatedBlocks(\n             clientMachine, lastBlockList);\n       }\n     }\n     return blocks;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  LocatedBlocks getBlockLocations(String clientMachine, String srcArg,\n      long offset, long length) throws IOException {\n    checkOperation(OperationCategory.READ);\n    GetBlockLocationsResult res \u003d null;\n    FSPermissionChecker pc \u003d getPermissionChecker();\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      res \u003d getBlockLocations(pc, srcArg, offset, length, true, true);\n    } catch (AccessControlException e) {\n      logAuditEvent(false, \"open\", srcArg);\n      throw e;\n    } finally {\n      readUnlock();\n    }\n\n    logAuditEvent(true, \"open\", srcArg);\n\n    if (res.updateAccessTime()) {\n      byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(\n          srcArg);\n      String src \u003d srcArg;\n      writeLock();\n      final long now \u003d now();\n      try {\n        checkOperation(OperationCategory.WRITE);\n        /**\n         * Resolve the path again and update the atime only when the file\n         * exists.\n         *\n         * XXX: Races can still occur even after resolving the path again.\n         * For example:\n         *\n         * \u003cul\u003e\n         *   \u003cli\u003eGet the block location for \"/a/b\"\u003c/li\u003e\n         *   \u003cli\u003eRename \"/a/b\" to \"/c/b\"\u003c/li\u003e\n         *   \u003cli\u003eThe second resolution still points to \"/a/b\", which is\n         *   wrong.\u003c/li\u003e\n         * \u003c/ul\u003e\n         *\n         * The behavior is incorrect but consistent with the one before\n         * HDFS-7463. A better fix is to change the edit log of SetTime to\n         * use inode id instead of a path.\n         */\n        src \u003d dir.resolvePath(pc, srcArg, pathComponents);\n        final INodesInPath iip \u003d dir.getINodesInPath(src, true);\n        INode inode \u003d iip.getLastINode();\n        boolean updateAccessTime \u003d inode !\u003d null \u0026\u0026\n            now \u003e inode.getAccessTime() + getAccessTimePrecision();\n        if (!isInSafeMode() \u0026\u0026 updateAccessTime) {\n          boolean changed \u003d FSDirAttrOp.setTimes(dir,\n              inode, -1, now, false, iip.getLatestSnapshotId());\n          if (changed) {\n            getEditLog().logTimes(src, -1, now);\n          }\n        }\n      } catch (Throwable e) {\n        LOG.warn(\"Failed to update the access time of \" + src, e);\n      } finally {\n        writeUnlock();\n      }\n    }\n\n    LocatedBlocks blocks \u003d res.blocks;\n    if (blocks !\u003d null) {\n      blockManager.getDatanodeManager().sortLocatedBlocks(\n          clientMachine, blocks.getLocatedBlocks());\n\n      // lastBlock is not part of getLocatedBlocks(), might need to sort it too\n      LocatedBlock lastBlock \u003d blocks.getLastLocatedBlock();\n      if (lastBlock !\u003d null) {\n        ArrayList\u003cLocatedBlock\u003e lastBlockList \u003d Lists.newArrayList(lastBlock);\n        blockManager.getDatanodeManager().sortLocatedBlocks(\n            clientMachine, lastBlockList);\n      }\n    }\n    return blocks;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {}
        }
      ]
    },
    "832ebd8cb63d91b4aa4bfed412b9799b3b9be4a7": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7506. Consolidate implementation of setting inode attributes into a single class. Contributed by Haohui Mai.\n",
      "commitDate": "15/12/14 10:40 AM",
      "commitName": "832ebd8cb63d91b4aa4bfed412b9799b3b9be4a7",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "12/12/14 5:04 PM",
      "commitNameOld": "fa7b9248e415c04bb555772f44fadaf8d9f34974",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 2.73,
      "commitsBetweenForRepo": 8,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,54 +1,54 @@\n   LocatedBlocks getBlockLocations(String clientMachine, String src,\n       long offset, long length) throws IOException {\n     checkOperation(OperationCategory.READ);\n     GetBlockLocationsResult res \u003d null;\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n       res \u003d getBlockLocations(src, offset, length, true, true);\n     } catch (AccessControlException e) {\n       logAuditEvent(false, \"open\", src);\n       throw e;\n     } finally {\n       readUnlock();\n     }\n \n     logAuditEvent(true, \"open\", src);\n \n     if (res.updateAccessTime()) {\n       writeLock();\n       final long now \u003d now();\n       try {\n         checkOperation(OperationCategory.WRITE);\n         INode inode \u003d res.iip.getLastINode();\n         boolean updateAccessTime \u003d now \u003e inode.getAccessTime() +\n             getAccessTimePrecision();\n         if (!isInSafeMode() \u0026\u0026 updateAccessTime) {\n-          boolean changed \u003d dir.setTimes(\n+          boolean changed \u003d FSDirAttrOp.setTimes(dir,\n               inode, -1, now, false, res.iip.getLatestSnapshotId());\n           if (changed) {\n             getEditLog().logTimes(src, -1, now);\n           }\n         }\n       } catch (Throwable e) {\n         LOG.warn(\"Failed to update the access time of \" + src, e);\n       } finally {\n         writeUnlock();\n       }\n     }\n \n     LocatedBlocks blocks \u003d res.blocks;\n     if (blocks !\u003d null) {\n       blockManager.getDatanodeManager().sortLocatedBlocks(\n           clientMachine, blocks.getLocatedBlocks());\n \n       // lastBlock is not part of getLocatedBlocks(), might need to sort it too\n       LocatedBlock lastBlock \u003d blocks.getLastLocatedBlock();\n       if (lastBlock !\u003d null) {\n         ArrayList\u003cLocatedBlock\u003e lastBlockList \u003d Lists.newArrayList(lastBlock);\n         blockManager.getDatanodeManager().sortLocatedBlocks(\n             clientMachine, lastBlockList);\n       }\n     }\n     return blocks;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlocks getBlockLocations(String clientMachine, String src,\n      long offset, long length) throws IOException {\n    checkOperation(OperationCategory.READ);\n    GetBlockLocationsResult res \u003d null;\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      res \u003d getBlockLocations(src, offset, length, true, true);\n    } catch (AccessControlException e) {\n      logAuditEvent(false, \"open\", src);\n      throw e;\n    } finally {\n      readUnlock();\n    }\n\n    logAuditEvent(true, \"open\", src);\n\n    if (res.updateAccessTime()) {\n      writeLock();\n      final long now \u003d now();\n      try {\n        checkOperation(OperationCategory.WRITE);\n        INode inode \u003d res.iip.getLastINode();\n        boolean updateAccessTime \u003d now \u003e inode.getAccessTime() +\n            getAccessTimePrecision();\n        if (!isInSafeMode() \u0026\u0026 updateAccessTime) {\n          boolean changed \u003d FSDirAttrOp.setTimes(dir,\n              inode, -1, now, false, res.iip.getLatestSnapshotId());\n          if (changed) {\n            getEditLog().logTimes(src, -1, now);\n          }\n        }\n      } catch (Throwable e) {\n        LOG.warn(\"Failed to update the access time of \" + src, e);\n      } finally {\n        writeUnlock();\n      }\n    }\n\n    LocatedBlocks blocks \u003d res.blocks;\n    if (blocks !\u003d null) {\n      blockManager.getDatanodeManager().sortLocatedBlocks(\n          clientMachine, blocks.getLocatedBlocks());\n\n      // lastBlock is not part of getLocatedBlocks(), might need to sort it too\n      LocatedBlock lastBlock \u003d blocks.getLastLocatedBlock();\n      if (lastBlock !\u003d null) {\n        ArrayList\u003cLocatedBlock\u003e lastBlockList \u003d Lists.newArrayList(lastBlock);\n        blockManager.getDatanodeManager().sortLocatedBlocks(\n            clientMachine, lastBlockList);\n      }\n    }\n    return blocks;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "46612c7a5135d20b20403780b47dd00654aab057": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7517. Remove redundant non-null checks in FSNamesystem#getBlockLocations. Contributed by Haohui Mai.\n",
      "commitDate": "12/12/14 11:51 AM",
      "commitName": "46612c7a5135d20b20403780b47dd00654aab057",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "10/12/14 11:01 PM",
      "commitNameOld": "d693a252bd0041c2493e7e07a3bf8bcf28e1923c",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 1.53,
      "commitsBetweenForRepo": 12,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,58 +1,54 @@\n   LocatedBlocks getBlockLocations(String clientMachine, String src,\n       long offset, long length) throws IOException {\n     checkOperation(OperationCategory.READ);\n     GetBlockLocationsResult res \u003d null;\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n       res \u003d getBlockLocations(src, offset, length, true, true);\n     } catch (AccessControlException e) {\n       logAuditEvent(false, \"open\", src);\n       throw e;\n     } finally {\n       readUnlock();\n     }\n \n     logAuditEvent(true, \"open\", src);\n \n-    if (res \u003d\u003d null) {\n-      return null;\n-    }\n-\n     if (res.updateAccessTime()) {\n       writeLock();\n       final long now \u003d now();\n       try {\n         checkOperation(OperationCategory.WRITE);\n         INode inode \u003d res.iip.getLastINode();\n         boolean updateAccessTime \u003d now \u003e inode.getAccessTime() +\n             getAccessTimePrecision();\n         if (!isInSafeMode() \u0026\u0026 updateAccessTime) {\n           boolean changed \u003d dir.setTimes(\n               inode, -1, now, false, res.iip.getLatestSnapshotId());\n           if (changed) {\n             getEditLog().logTimes(src, -1, now);\n           }\n         }\n       } catch (Throwable e) {\n         LOG.warn(\"Failed to update the access time of \" + src, e);\n       } finally {\n         writeUnlock();\n       }\n     }\n \n     LocatedBlocks blocks \u003d res.blocks;\n     if (blocks !\u003d null) {\n       blockManager.getDatanodeManager().sortLocatedBlocks(\n           clientMachine, blocks.getLocatedBlocks());\n \n       // lastBlock is not part of getLocatedBlocks(), might need to sort it too\n       LocatedBlock lastBlock \u003d blocks.getLastLocatedBlock();\n       if (lastBlock !\u003d null) {\n         ArrayList\u003cLocatedBlock\u003e lastBlockList \u003d Lists.newArrayList(lastBlock);\n         blockManager.getDatanodeManager().sortLocatedBlocks(\n             clientMachine, lastBlockList);\n       }\n     }\n     return blocks;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlocks getBlockLocations(String clientMachine, String src,\n      long offset, long length) throws IOException {\n    checkOperation(OperationCategory.READ);\n    GetBlockLocationsResult res \u003d null;\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      res \u003d getBlockLocations(src, offset, length, true, true);\n    } catch (AccessControlException e) {\n      logAuditEvent(false, \"open\", src);\n      throw e;\n    } finally {\n      readUnlock();\n    }\n\n    logAuditEvent(true, \"open\", src);\n\n    if (res.updateAccessTime()) {\n      writeLock();\n      final long now \u003d now();\n      try {\n        checkOperation(OperationCategory.WRITE);\n        INode inode \u003d res.iip.getLastINode();\n        boolean updateAccessTime \u003d now \u003e inode.getAccessTime() +\n            getAccessTimePrecision();\n        if (!isInSafeMode() \u0026\u0026 updateAccessTime) {\n          boolean changed \u003d dir.setTimes(\n              inode, -1, now, false, res.iip.getLatestSnapshotId());\n          if (changed) {\n            getEditLog().logTimes(src, -1, now);\n          }\n        }\n      } catch (Throwable e) {\n        LOG.warn(\"Failed to update the access time of \" + src, e);\n      } finally {\n        writeUnlock();\n      }\n    }\n\n    LocatedBlocks blocks \u003d res.blocks;\n    if (blocks !\u003d null) {\n      blockManager.getDatanodeManager().sortLocatedBlocks(\n          clientMachine, blocks.getLocatedBlocks());\n\n      // lastBlock is not part of getLocatedBlocks(), might need to sort it too\n      LocatedBlock lastBlock \u003d blocks.getLastLocatedBlock();\n      if (lastBlock !\u003d null) {\n        ArrayList\u003cLocatedBlock\u003e lastBlockList \u003d Lists.newArrayList(lastBlock);\n        blockManager.getDatanodeManager().sortLocatedBlocks(\n            clientMachine, lastBlockList);\n      }\n    }\n    return blocks;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "d693a252bd0041c2493e7e07a3bf8bcf28e1923c": {
      "type": "Ymultichange(Yexceptionschange,Ybodychange)",
      "commitMessage": "HDFS-7463. Simplify FSNamesystem#getBlockLocationsUpdateTimes. Contributed by Haohui Mai.\n",
      "commitDate": "10/12/14 11:01 PM",
      "commitName": "d693a252bd0041c2493e7e07a3bf8bcf28e1923c",
      "commitAuthor": "Haohui Mai",
      "subchanges": [
        {
          "type": "Yexceptionschange",
          "commitMessage": "HDFS-7463. Simplify FSNamesystem#getBlockLocationsUpdateTimes. Contributed by Haohui Mai.\n",
          "commitDate": "10/12/14 11:01 PM",
          "commitName": "d693a252bd0041c2493e7e07a3bf8bcf28e1923c",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "09/12/14 11:37 AM",
          "commitNameOld": "5776a41da08af653206bb94d7c76c9c4dcce059a",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 1.47,
          "commitsBetweenForRepo": 19,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,21 +1,58 @@\n   LocatedBlocks getBlockLocations(String clientMachine, String src,\n-      long offset, long length) throws AccessControlException,\n-      FileNotFoundException, UnresolvedLinkException, IOException {\n-    LocatedBlocks blocks \u003d getBlockLocations(src, offset, length, true, true,\n-        true);\n+      long offset, long length) throws IOException {\n+    checkOperation(OperationCategory.READ);\n+    GetBlockLocationsResult res \u003d null;\n+    readLock();\n+    try {\n+      checkOperation(OperationCategory.READ);\n+      res \u003d getBlockLocations(src, offset, length, true, true);\n+    } catch (AccessControlException e) {\n+      logAuditEvent(false, \"open\", src);\n+      throw e;\n+    } finally {\n+      readUnlock();\n+    }\n+\n+    logAuditEvent(true, \"open\", src);\n+\n+    if (res \u003d\u003d null) {\n+      return null;\n+    }\n+\n+    if (res.updateAccessTime()) {\n+      writeLock();\n+      final long now \u003d now();\n+      try {\n+        checkOperation(OperationCategory.WRITE);\n+        INode inode \u003d res.iip.getLastINode();\n+        boolean updateAccessTime \u003d now \u003e inode.getAccessTime() +\n+            getAccessTimePrecision();\n+        if (!isInSafeMode() \u0026\u0026 updateAccessTime) {\n+          boolean changed \u003d dir.setTimes(\n+              inode, -1, now, false, res.iip.getLatestSnapshotId());\n+          if (changed) {\n+            getEditLog().logTimes(src, -1, now);\n+          }\n+        }\n+      } catch (Throwable e) {\n+        LOG.warn(\"Failed to update the access time of \" + src, e);\n+      } finally {\n+        writeUnlock();\n+      }\n+    }\n+\n+    LocatedBlocks blocks \u003d res.blocks;\n     if (blocks !\u003d null) {\n-      blockManager.getDatanodeManager().sortLocatedBlocks(clientMachine,\n-          blocks.getLocatedBlocks());\n+      blockManager.getDatanodeManager().sortLocatedBlocks(\n+          clientMachine, blocks.getLocatedBlocks());\n \n       // lastBlock is not part of getLocatedBlocks(), might need to sort it too\n       LocatedBlock lastBlock \u003d blocks.getLastLocatedBlock();\n       if (lastBlock !\u003d null) {\n-        ArrayList\u003cLocatedBlock\u003e lastBlockList \u003d\n-            Lists.newArrayListWithCapacity(1);\n-        lastBlockList.add(lastBlock);\n-        blockManager.getDatanodeManager().sortLocatedBlocks(clientMachine,\n-            lastBlockList);\n+        ArrayList\u003cLocatedBlock\u003e lastBlockList \u003d Lists.newArrayList(lastBlock);\n+        blockManager.getDatanodeManager().sortLocatedBlocks(\n+            clientMachine, lastBlockList);\n       }\n     }\n     return blocks;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  LocatedBlocks getBlockLocations(String clientMachine, String src,\n      long offset, long length) throws IOException {\n    checkOperation(OperationCategory.READ);\n    GetBlockLocationsResult res \u003d null;\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      res \u003d getBlockLocations(src, offset, length, true, true);\n    } catch (AccessControlException e) {\n      logAuditEvent(false, \"open\", src);\n      throw e;\n    } finally {\n      readUnlock();\n    }\n\n    logAuditEvent(true, \"open\", src);\n\n    if (res \u003d\u003d null) {\n      return null;\n    }\n\n    if (res.updateAccessTime()) {\n      writeLock();\n      final long now \u003d now();\n      try {\n        checkOperation(OperationCategory.WRITE);\n        INode inode \u003d res.iip.getLastINode();\n        boolean updateAccessTime \u003d now \u003e inode.getAccessTime() +\n            getAccessTimePrecision();\n        if (!isInSafeMode() \u0026\u0026 updateAccessTime) {\n          boolean changed \u003d dir.setTimes(\n              inode, -1, now, false, res.iip.getLatestSnapshotId());\n          if (changed) {\n            getEditLog().logTimes(src, -1, now);\n          }\n        }\n      } catch (Throwable e) {\n        LOG.warn(\"Failed to update the access time of \" + src, e);\n      } finally {\n        writeUnlock();\n      }\n    }\n\n    LocatedBlocks blocks \u003d res.blocks;\n    if (blocks !\u003d null) {\n      blockManager.getDatanodeManager().sortLocatedBlocks(\n          clientMachine, blocks.getLocatedBlocks());\n\n      // lastBlock is not part of getLocatedBlocks(), might need to sort it too\n      LocatedBlock lastBlock \u003d blocks.getLastLocatedBlock();\n      if (lastBlock !\u003d null) {\n        ArrayList\u003cLocatedBlock\u003e lastBlockList \u003d Lists.newArrayList(lastBlock);\n        blockManager.getDatanodeManager().sortLocatedBlocks(\n            clientMachine, lastBlockList);\n      }\n    }\n    return blocks;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {
            "oldValue": "[AccessControlException, FileNotFoundException, UnresolvedLinkException, IOException]",
            "newValue": "[IOException]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7463. Simplify FSNamesystem#getBlockLocationsUpdateTimes. Contributed by Haohui Mai.\n",
          "commitDate": "10/12/14 11:01 PM",
          "commitName": "d693a252bd0041c2493e7e07a3bf8bcf28e1923c",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "09/12/14 11:37 AM",
          "commitNameOld": "5776a41da08af653206bb94d7c76c9c4dcce059a",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 1.47,
          "commitsBetweenForRepo": 19,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,21 +1,58 @@\n   LocatedBlocks getBlockLocations(String clientMachine, String src,\n-      long offset, long length) throws AccessControlException,\n-      FileNotFoundException, UnresolvedLinkException, IOException {\n-    LocatedBlocks blocks \u003d getBlockLocations(src, offset, length, true, true,\n-        true);\n+      long offset, long length) throws IOException {\n+    checkOperation(OperationCategory.READ);\n+    GetBlockLocationsResult res \u003d null;\n+    readLock();\n+    try {\n+      checkOperation(OperationCategory.READ);\n+      res \u003d getBlockLocations(src, offset, length, true, true);\n+    } catch (AccessControlException e) {\n+      logAuditEvent(false, \"open\", src);\n+      throw e;\n+    } finally {\n+      readUnlock();\n+    }\n+\n+    logAuditEvent(true, \"open\", src);\n+\n+    if (res \u003d\u003d null) {\n+      return null;\n+    }\n+\n+    if (res.updateAccessTime()) {\n+      writeLock();\n+      final long now \u003d now();\n+      try {\n+        checkOperation(OperationCategory.WRITE);\n+        INode inode \u003d res.iip.getLastINode();\n+        boolean updateAccessTime \u003d now \u003e inode.getAccessTime() +\n+            getAccessTimePrecision();\n+        if (!isInSafeMode() \u0026\u0026 updateAccessTime) {\n+          boolean changed \u003d dir.setTimes(\n+              inode, -1, now, false, res.iip.getLatestSnapshotId());\n+          if (changed) {\n+            getEditLog().logTimes(src, -1, now);\n+          }\n+        }\n+      } catch (Throwable e) {\n+        LOG.warn(\"Failed to update the access time of \" + src, e);\n+      } finally {\n+        writeUnlock();\n+      }\n+    }\n+\n+    LocatedBlocks blocks \u003d res.blocks;\n     if (blocks !\u003d null) {\n-      blockManager.getDatanodeManager().sortLocatedBlocks(clientMachine,\n-          blocks.getLocatedBlocks());\n+      blockManager.getDatanodeManager().sortLocatedBlocks(\n+          clientMachine, blocks.getLocatedBlocks());\n \n       // lastBlock is not part of getLocatedBlocks(), might need to sort it too\n       LocatedBlock lastBlock \u003d blocks.getLastLocatedBlock();\n       if (lastBlock !\u003d null) {\n-        ArrayList\u003cLocatedBlock\u003e lastBlockList \u003d\n-            Lists.newArrayListWithCapacity(1);\n-        lastBlockList.add(lastBlock);\n-        blockManager.getDatanodeManager().sortLocatedBlocks(clientMachine,\n-            lastBlockList);\n+        ArrayList\u003cLocatedBlock\u003e lastBlockList \u003d Lists.newArrayList(lastBlock);\n+        blockManager.getDatanodeManager().sortLocatedBlocks(\n+            clientMachine, lastBlockList);\n       }\n     }\n     return blocks;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  LocatedBlocks getBlockLocations(String clientMachine, String src,\n      long offset, long length) throws IOException {\n    checkOperation(OperationCategory.READ);\n    GetBlockLocationsResult res \u003d null;\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      res \u003d getBlockLocations(src, offset, length, true, true);\n    } catch (AccessControlException e) {\n      logAuditEvent(false, \"open\", src);\n      throw e;\n    } finally {\n      readUnlock();\n    }\n\n    logAuditEvent(true, \"open\", src);\n\n    if (res \u003d\u003d null) {\n      return null;\n    }\n\n    if (res.updateAccessTime()) {\n      writeLock();\n      final long now \u003d now();\n      try {\n        checkOperation(OperationCategory.WRITE);\n        INode inode \u003d res.iip.getLastINode();\n        boolean updateAccessTime \u003d now \u003e inode.getAccessTime() +\n            getAccessTimePrecision();\n        if (!isInSafeMode() \u0026\u0026 updateAccessTime) {\n          boolean changed \u003d dir.setTimes(\n              inode, -1, now, false, res.iip.getLatestSnapshotId());\n          if (changed) {\n            getEditLog().logTimes(src, -1, now);\n          }\n        }\n      } catch (Throwable e) {\n        LOG.warn(\"Failed to update the access time of \" + src, e);\n      } finally {\n        writeUnlock();\n      }\n    }\n\n    LocatedBlocks blocks \u003d res.blocks;\n    if (blocks !\u003d null) {\n      blockManager.getDatanodeManager().sortLocatedBlocks(\n          clientMachine, blocks.getLocatedBlocks());\n\n      // lastBlock is not part of getLocatedBlocks(), might need to sort it too\n      LocatedBlock lastBlock \u003d blocks.getLastLocatedBlock();\n      if (lastBlock !\u003d null) {\n        ArrayList\u003cLocatedBlock\u003e lastBlockList \u003d Lists.newArrayList(lastBlock);\n        blockManager.getDatanodeManager().sortLocatedBlocks(\n            clientMachine, lastBlockList);\n      }\n    }\n    return blocks;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {}
        }
      ]
    },
    "8e73084491c9f317bc8cc3590f93ca67a63687a8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6840. Clients are always sent to the same datanode when read is off rack. (wang)\n",
      "commitDate": "18/09/14 5:49 PM",
      "commitName": "8e73084491c9f317bc8cc3590f93ca67a63687a8",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "18/09/14 5:35 PM",
      "commitNameOld": "20a076bafce548298729bab4fb81d12f829e8f7e",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,21 @@\n   LocatedBlocks getBlockLocations(String clientMachine, String src,\n       long offset, long length) throws AccessControlException,\n       FileNotFoundException, UnresolvedLinkException, IOException {\n     LocatedBlocks blocks \u003d getBlockLocations(src, offset, length, true, true,\n         true);\n     if (blocks !\u003d null) {\n       blockManager.getDatanodeManager().sortLocatedBlocks(clientMachine,\n-          blocks.getLocatedBlocks(), randomizeBlockLocationsPerBlock);\n+          blocks.getLocatedBlocks());\n \n       // lastBlock is not part of getLocatedBlocks(), might need to sort it too\n       LocatedBlock lastBlock \u003d blocks.getLastLocatedBlock();\n       if (lastBlock !\u003d null) {\n         ArrayList\u003cLocatedBlock\u003e lastBlockList \u003d\n             Lists.newArrayListWithCapacity(1);\n         lastBlockList.add(lastBlock);\n         blockManager.getDatanodeManager().sortLocatedBlocks(clientMachine,\n-            lastBlockList, randomizeBlockLocationsPerBlock);\n+            lastBlockList);\n       }\n     }\n     return blocks;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlocks getBlockLocations(String clientMachine, String src,\n      long offset, long length) throws AccessControlException,\n      FileNotFoundException, UnresolvedLinkException, IOException {\n    LocatedBlocks blocks \u003d getBlockLocations(src, offset, length, true, true,\n        true);\n    if (blocks !\u003d null) {\n      blockManager.getDatanodeManager().sortLocatedBlocks(clientMachine,\n          blocks.getLocatedBlocks());\n\n      // lastBlock is not part of getLocatedBlocks(), might need to sort it too\n      LocatedBlock lastBlock \u003d blocks.getLastLocatedBlock();\n      if (lastBlock !\u003d null) {\n        ArrayList\u003cLocatedBlock\u003e lastBlockList \u003d\n            Lists.newArrayListWithCapacity(1);\n        lastBlockList.add(lastBlock);\n        blockManager.getDatanodeManager().sortLocatedBlocks(clientMachine,\n            lastBlockList);\n      }\n    }\n    return blocks;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "552b4fb9f9a76b18605322c0b0e8072613d67773": {
      "type": "Ybodychange",
      "commitMessage": "Merge from trunk to branch\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/fs-encryption@1612928 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "23/07/14 12:26 PM",
      "commitName": "552b4fb9f9a76b18605322c0b0e8072613d67773",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "23/07/14 7:51 AM",
      "commitNameOld": "687ce1a5fca2d58a781e7382bf0333a16d39839d",
      "commitAuthorOld": "Charles Lamb",
      "daysBetweenCommits": 0.19,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,21 @@\n   LocatedBlocks getBlockLocations(String clientMachine, String src,\n       long offset, long length) throws AccessControlException,\n       FileNotFoundException, UnresolvedLinkException, IOException {\n     LocatedBlocks blocks \u003d getBlockLocations(src, offset, length, true, true,\n         true);\n     if (blocks !\u003d null) {\n-      blockManager.getDatanodeManager().sortLocatedBlocks(\n-          clientMachine, blocks.getLocatedBlocks());\n-      \n+      blockManager.getDatanodeManager().sortLocatedBlocks(clientMachine,\n+          blocks.getLocatedBlocks(), randomizeBlockLocationsPerBlock);\n+\n       // lastBlock is not part of getLocatedBlocks(), might need to sort it too\n       LocatedBlock lastBlock \u003d blocks.getLastLocatedBlock();\n       if (lastBlock !\u003d null) {\n         ArrayList\u003cLocatedBlock\u003e lastBlockList \u003d\n             Lists.newArrayListWithCapacity(1);\n         lastBlockList.add(lastBlock);\n-        blockManager.getDatanodeManager().sortLocatedBlocks(\n-                              clientMachine, lastBlockList);\n+        blockManager.getDatanodeManager().sortLocatedBlocks(clientMachine,\n+            lastBlockList, randomizeBlockLocationsPerBlock);\n       }\n     }\n     return blocks;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlocks getBlockLocations(String clientMachine, String src,\n      long offset, long length) throws AccessControlException,\n      FileNotFoundException, UnresolvedLinkException, IOException {\n    LocatedBlocks blocks \u003d getBlockLocations(src, offset, length, true, true,\n        true);\n    if (blocks !\u003d null) {\n      blockManager.getDatanodeManager().sortLocatedBlocks(clientMachine,\n          blocks.getLocatedBlocks(), randomizeBlockLocationsPerBlock);\n\n      // lastBlock is not part of getLocatedBlocks(), might need to sort it too\n      LocatedBlock lastBlock \u003d blocks.getLastLocatedBlock();\n      if (lastBlock !\u003d null) {\n        ArrayList\u003cLocatedBlock\u003e lastBlockList \u003d\n            Lists.newArrayListWithCapacity(1);\n        lastBlockList.add(lastBlock);\n        blockManager.getDatanodeManager().sortLocatedBlocks(clientMachine,\n            lastBlockList, randomizeBlockLocationsPerBlock);\n      }\n    }\n    return blocks;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "c83c5b868ea34925ecb1597cf1ceb88524ded185": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6701. Make seed optional in NetworkTopology#sortByDistance. Contributed by Ashwin Shankar.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1612625 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "22/07/14 10:47 AM",
      "commitName": "c83c5b868ea34925ecb1597cf1ceb88524ded185",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "18/07/14 10:58 AM",
      "commitNameOld": "551024915d487957d9e829493ab319c8e31dfa81",
      "commitAuthorOld": "Daryn Sharp",
      "daysBetweenCommits": 3.99,
      "commitsBetweenForRepo": 25,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,21 @@\n   LocatedBlocks getBlockLocations(String clientMachine, String src,\n       long offset, long length) throws AccessControlException,\n       FileNotFoundException, UnresolvedLinkException, IOException {\n     LocatedBlocks blocks \u003d getBlockLocations(src, offset, length, true, true,\n         true);\n     if (blocks !\u003d null) {\n-      blockManager.getDatanodeManager().sortLocatedBlocks(\n-          clientMachine, blocks.getLocatedBlocks());\n-      \n+      blockManager.getDatanodeManager().sortLocatedBlocks(clientMachine,\n+          blocks.getLocatedBlocks(), randomizeBlockLocationsPerBlock);\n+\n       // lastBlock is not part of getLocatedBlocks(), might need to sort it too\n       LocatedBlock lastBlock \u003d blocks.getLastLocatedBlock();\n       if (lastBlock !\u003d null) {\n         ArrayList\u003cLocatedBlock\u003e lastBlockList \u003d\n             Lists.newArrayListWithCapacity(1);\n         lastBlockList.add(lastBlock);\n-        blockManager.getDatanodeManager().sortLocatedBlocks(\n-                              clientMachine, lastBlockList);\n+        blockManager.getDatanodeManager().sortLocatedBlocks(clientMachine,\n+            lastBlockList, randomizeBlockLocationsPerBlock);\n       }\n     }\n     return blocks;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlocks getBlockLocations(String clientMachine, String src,\n      long offset, long length) throws AccessControlException,\n      FileNotFoundException, UnresolvedLinkException, IOException {\n    LocatedBlocks blocks \u003d getBlockLocations(src, offset, length, true, true,\n        true);\n    if (blocks !\u003d null) {\n      blockManager.getDatanodeManager().sortLocatedBlocks(clientMachine,\n          blocks.getLocatedBlocks(), randomizeBlockLocationsPerBlock);\n\n      // lastBlock is not part of getLocatedBlocks(), might need to sort it too\n      LocatedBlock lastBlock \u003d blocks.getLastLocatedBlock();\n      if (lastBlock !\u003d null) {\n        ArrayList\u003cLocatedBlock\u003e lastBlockList \u003d\n            Lists.newArrayListWithCapacity(1);\n        lastBlockList.add(lastBlock);\n        blockManager.getDatanodeManager().sortLocatedBlocks(clientMachine,\n            lastBlockList, randomizeBlockLocationsPerBlock);\n      }\n    }\n    return blocks;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "02fcb6b6bae7c3fe2a10b00b2a563e4098ff225e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6268. Better sorting in NetworkTopology#pseudoSortByDistance when no local node is found. (wang)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1599734 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "03/06/14 11:33 AM",
      "commitName": "02fcb6b6bae7c3fe2a10b00b2a563e4098ff225e",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "30/05/14 5:12 PM",
      "commitNameOld": "880a0c673c74a128a01c72b60695f05327f5e961",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 3.76,
      "commitsBetweenForRepo": 13,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,19 +1,21 @@\n   LocatedBlocks getBlockLocations(String clientMachine, String src,\n       long offset, long length) throws AccessControlException,\n       FileNotFoundException, UnresolvedLinkException, IOException {\n     LocatedBlocks blocks \u003d getBlockLocations(src, offset, length, true, true,\n         true);\n     if (blocks !\u003d null) {\n       blockManager.getDatanodeManager().sortLocatedBlocks(\n           clientMachine, blocks.getLocatedBlocks());\n       \n+      // lastBlock is not part of getLocatedBlocks(), might need to sort it too\n       LocatedBlock lastBlock \u003d blocks.getLastLocatedBlock();\n       if (lastBlock !\u003d null) {\n-        ArrayList\u003cLocatedBlock\u003e lastBlockList \u003d new ArrayList\u003cLocatedBlock\u003e();\n+        ArrayList\u003cLocatedBlock\u003e lastBlockList \u003d\n+            Lists.newArrayListWithCapacity(1);\n         lastBlockList.add(lastBlock);\n         blockManager.getDatanodeManager().sortLocatedBlocks(\n                               clientMachine, lastBlockList);\n       }\n     }\n     return blocks;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlocks getBlockLocations(String clientMachine, String src,\n      long offset, long length) throws AccessControlException,\n      FileNotFoundException, UnresolvedLinkException, IOException {\n    LocatedBlocks blocks \u003d getBlockLocations(src, offset, length, true, true,\n        true);\n    if (blocks !\u003d null) {\n      blockManager.getDatanodeManager().sortLocatedBlocks(\n          clientMachine, blocks.getLocatedBlocks());\n      \n      // lastBlock is not part of getLocatedBlocks(), might need to sort it too\n      LocatedBlock lastBlock \u003d blocks.getLastLocatedBlock();\n      if (lastBlock !\u003d null) {\n        ArrayList\u003cLocatedBlock\u003e lastBlockList \u003d\n            Lists.newArrayListWithCapacity(1);\n        lastBlockList.add(lastBlock);\n        blockManager.getDatanodeManager().sortLocatedBlocks(\n                              clientMachine, lastBlockList);\n      }\n    }\n    return blocks;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5096. Automatically cache new data added to a cached path (contributed by Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1532924 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/10/13 3:15 PM",
      "commitName": "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "09/10/13 2:30 PM",
      "commitNameOld": "3fc8792b5c75fca9fc4f6cf4b95fb2927c62e624",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 7.03,
      "commitsBetweenForRepo": 8,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,19 @@\n   LocatedBlocks getBlockLocations(String clientMachine, String src,\n       long offset, long length) throws AccessControlException,\n       FileNotFoundException, UnresolvedLinkException, IOException {\n     LocatedBlocks blocks \u003d getBlockLocations(src, offset, length, true, true,\n         true);\n     if (blocks !\u003d null) {\n       blockManager.getDatanodeManager().sortLocatedBlocks(\n           clientMachine, blocks.getLocatedBlocks());\n       \n       LocatedBlock lastBlock \u003d blocks.getLastLocatedBlock();\n       if (lastBlock !\u003d null) {\n         ArrayList\u003cLocatedBlock\u003e lastBlockList \u003d new ArrayList\u003cLocatedBlock\u003e();\n         lastBlockList.add(lastBlock);\n         blockManager.getDatanodeManager().sortLocatedBlocks(\n                               clientMachine, lastBlockList);\n       }\n-      // Set caching information for the block list\n-      for (LocatedBlock lb: blocks.getLocatedBlocks()) {\n-        cacheReplicationManager.setCachedLocations(lb);\n-      }\n     }\n     return blocks;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlocks getBlockLocations(String clientMachine, String src,\n      long offset, long length) throws AccessControlException,\n      FileNotFoundException, UnresolvedLinkException, IOException {\n    LocatedBlocks blocks \u003d getBlockLocations(src, offset, length, true, true,\n        true);\n    if (blocks !\u003d null) {\n      blockManager.getDatanodeManager().sortLocatedBlocks(\n          clientMachine, blocks.getLocatedBlocks());\n      \n      LocatedBlock lastBlock \u003d blocks.getLastLocatedBlock();\n      if (lastBlock !\u003d null) {\n        ArrayList\u003cLocatedBlock\u003e lastBlockList \u003d new ArrayList\u003cLocatedBlock\u003e();\n        lastBlockList.add(lastBlock);\n        blockManager.getDatanodeManager().sortLocatedBlocks(\n                              clientMachine, lastBlockList);\n      }\n    }\n    return blocks;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "3fc8792b5c75fca9fc4f6cf4b95fb2927c62e624": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5304. Expose if a block replica is cached in getFileBlockLocations. (Contributed by Andrew Wang)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1530802 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/10/13 2:30 PM",
      "commitName": "3fc8792b5c75fca9fc4f6cf4b95fb2927c62e624",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "07/10/13 2:26 PM",
      "commitNameOld": "b60e18db743b8933d96384942046ea57e725855d",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 2.0,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,19 +1,23 @@\n   LocatedBlocks getBlockLocations(String clientMachine, String src,\n       long offset, long length) throws AccessControlException,\n       FileNotFoundException, UnresolvedLinkException, IOException {\n     LocatedBlocks blocks \u003d getBlockLocations(src, offset, length, true, true,\n         true);\n     if (blocks !\u003d null) {\n       blockManager.getDatanodeManager().sortLocatedBlocks(\n           clientMachine, blocks.getLocatedBlocks());\n       \n       LocatedBlock lastBlock \u003d blocks.getLastLocatedBlock();\n       if (lastBlock !\u003d null) {\n         ArrayList\u003cLocatedBlock\u003e lastBlockList \u003d new ArrayList\u003cLocatedBlock\u003e();\n         lastBlockList.add(lastBlock);\n         blockManager.getDatanodeManager().sortLocatedBlocks(\n                               clientMachine, lastBlockList);\n       }\n+      // Set caching information for the block list\n+      for (LocatedBlock lb: blocks.getLocatedBlocks()) {\n+        cacheReplicationManager.setCachedLocations(lb);\n+      }\n     }\n     return blocks;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlocks getBlockLocations(String clientMachine, String src,\n      long offset, long length) throws AccessControlException,\n      FileNotFoundException, UnresolvedLinkException, IOException {\n    LocatedBlocks blocks \u003d getBlockLocations(src, offset, length, true, true,\n        true);\n    if (blocks !\u003d null) {\n      blockManager.getDatanodeManager().sortLocatedBlocks(\n          clientMachine, blocks.getLocatedBlocks());\n      \n      LocatedBlock lastBlock \u003d blocks.getLastLocatedBlock();\n      if (lastBlock !\u003d null) {\n        ArrayList\u003cLocatedBlock\u003e lastBlockList \u003d new ArrayList\u003cLocatedBlock\u003e();\n        lastBlockList.add(lastBlock);\n        blockManager.getDatanodeManager().sortLocatedBlocks(\n                              clientMachine, lastBlockList);\n      }\n      // Set caching information for the block list\n      for (LocatedBlock lb: blocks.getLocatedBlocks()) {\n        cacheReplicationManager.setCachedLocations(lb);\n      }\n    }\n    return blocks;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "d543140089690f4ec877d26981f4ad7908b33d1d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3703. Datanodes are marked stale if heartbeat is not received in configured timeout and are selected as the last location to read from. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1384209 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/09/12 10:46 PM",
      "commitName": "d543140089690f4ec877d26981f4ad7908b33d1d",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "04/09/12 9:40 PM",
      "commitNameOld": "c334cc89a8f42c98ab4dad02ae41c5a02a855974",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 8.05,
      "commitsBetweenForRepo": 54,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,11 +1,19 @@\n   LocatedBlocks getBlockLocations(String clientMachine, String src,\n       long offset, long length) throws AccessControlException,\n       FileNotFoundException, UnresolvedLinkException, IOException {\n     LocatedBlocks blocks \u003d getBlockLocations(src, offset, length, true, true,\n         true);\n     if (blocks !\u003d null) {\n       blockManager.getDatanodeManager().sortLocatedBlocks(\n           clientMachine, blocks.getLocatedBlocks());\n+      \n+      LocatedBlock lastBlock \u003d blocks.getLastLocatedBlock();\n+      if (lastBlock !\u003d null) {\n+        ArrayList\u003cLocatedBlock\u003e lastBlockList \u003d new ArrayList\u003cLocatedBlock\u003e();\n+        lastBlockList.add(lastBlock);\n+        blockManager.getDatanodeManager().sortLocatedBlocks(\n+                              clientMachine, lastBlockList);\n+      }\n     }\n     return blocks;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlocks getBlockLocations(String clientMachine, String src,\n      long offset, long length) throws AccessControlException,\n      FileNotFoundException, UnresolvedLinkException, IOException {\n    LocatedBlocks blocks \u003d getBlockLocations(src, offset, length, true, true,\n        true);\n    if (blocks !\u003d null) {\n      blockManager.getDatanodeManager().sortLocatedBlocks(\n          clientMachine, blocks.getLocatedBlocks());\n      \n      LocatedBlock lastBlock \u003d blocks.getLastLocatedBlock();\n      if (lastBlock !\u003d null) {\n        ArrayList\u003cLocatedBlock\u003e lastBlockList \u003d new ArrayList\u003cLocatedBlock\u003e();\n        lastBlockList.add(lastBlock);\n        blockManager.getDatanodeManager().sortLocatedBlocks(\n                              clientMachine, lastBlockList);\n      }\n    }\n    return blocks;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "543f86631bf07053a045d5dabcad16fb8f9eff97": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3522. If a namenode is in safemode, it should throw SafeModeException when getBlockLocations has zero locations.  Contributed by Brandon Li \n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1349088 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/06/12 6:55 PM",
      "commitName": "543f86631bf07053a045d5dabcad16fb8f9eff97",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "11/06/12 1:38 PM",
      "commitNameOld": "ca39e780c4fb6457a806153b9dabc138e269236d",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 0.22,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,10 +1,11 @@\n   LocatedBlocks getBlockLocations(String clientMachine, String src,\n       long offset, long length) throws AccessControlException,\n       FileNotFoundException, UnresolvedLinkException, IOException {\n-    LocatedBlocks blocks \u003d getBlockLocations(src, offset, length, true, true);\n+    LocatedBlocks blocks \u003d getBlockLocations(src, offset, length, true, true,\n+        true);\n     if (blocks !\u003d null) {\n       blockManager.getDatanodeManager().sortLocatedBlocks(\n           clientMachine, blocks.getLocatedBlocks());\n     }\n     return blocks;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlocks getBlockLocations(String clientMachine, String src,\n      long offset, long length) throws AccessControlException,\n      FileNotFoundException, UnresolvedLinkException, IOException {\n    LocatedBlocks blocks \u003d getBlockLocations(src, offset, length, true, true,\n        true);\n    if (blocks !\u003d null) {\n      blockManager.getDatanodeManager().sortLocatedBlocks(\n          clientMachine, blocks.getLocatedBlocks());\n    }\n    return blocks;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  LocatedBlocks getBlockLocations(String clientMachine, String src,\n      long offset, long length) throws AccessControlException,\n      FileNotFoundException, UnresolvedLinkException, IOException {\n    LocatedBlocks blocks \u003d getBlockLocations(src, offset, length, true, true);\n    if (blocks !\u003d null) {\n      blockManager.getDatanodeManager().sortLocatedBlocks(\n          clientMachine, blocks.getLocatedBlocks());\n    }\n    return blocks;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  LocatedBlocks getBlockLocations(String clientMachine, String src,\n      long offset, long length) throws AccessControlException,\n      FileNotFoundException, UnresolvedLinkException, IOException {\n    LocatedBlocks blocks \u003d getBlockLocations(src, offset, length, true, true);\n    if (blocks !\u003d null) {\n      blockManager.getDatanodeManager().sortLocatedBlocks(\n          clientMachine, blocks.getLocatedBlocks());\n    }\n    return blocks;\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java"
      }
    },
    "c3f6575ca44e8ad803d0b46991472465b595cdeb": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2147. Move cluster network topology to block management and fix some javac warnings.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1148112 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/07/11 5:26 PM",
      "commitName": "c3f6575ca44e8ad803d0b46991472465b595cdeb",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "13/07/11 4:24 PM",
      "commitNameOld": "8327e70be87990c37ac14dcc1cb1a4d209c65593",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 5.04,
      "commitsBetweenForRepo": 17,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,10 @@\n   LocatedBlocks getBlockLocations(String clientMachine, String src,\n       long offset, long length) throws AccessControlException,\n       FileNotFoundException, UnresolvedLinkException, IOException {\n     LocatedBlocks blocks \u003d getBlockLocations(src, offset, length, true, true);\n     if (blocks !\u003d null) {\n-      //sort the blocks\n-      final DatanodeDescriptor client \u003d \n-          blockManager.getDatanodeManager().getDatanodeByHost(clientMachine);\n-      for (LocatedBlock b : blocks.getLocatedBlocks()) {\n-        clusterMap.pseudoSortByDistance(client, b.getLocations());\n-        \n-        // Move decommissioned datanodes to the bottom\n-        Arrays.sort(b.getLocations(), DFSUtil.DECOM_COMPARATOR);\n-      }\n+      blockManager.getDatanodeManager().sortLocatedBlocks(\n+          clientMachine, blocks.getLocatedBlocks());\n     }\n     return blocks;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlocks getBlockLocations(String clientMachine, String src,\n      long offset, long length) throws AccessControlException,\n      FileNotFoundException, UnresolvedLinkException, IOException {\n    LocatedBlocks blocks \u003d getBlockLocations(src, offset, length, true, true);\n    if (blocks !\u003d null) {\n      blockManager.getDatanodeManager().sortLocatedBlocks(\n          clientMachine, blocks.getLocatedBlocks());\n    }\n    return blocks;\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "8327e70be87990c37ac14dcc1cb1a4d209c65593": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2140. Move Host2NodesMap to the blockmanagement package.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1146514 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/07/11 4:24 PM",
      "commitName": "8327e70be87990c37ac14dcc1cb1a4d209c65593",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "12/07/11 6:11 PM",
      "commitNameOld": "2c5dd549e31aa5d3377ff2619ede8e92b8dc5d0f",
      "commitAuthorOld": "Jitendra Nath Pandey",
      "daysBetweenCommits": 0.93,
      "commitsBetweenForRepo": 9,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,17 @@\n   LocatedBlocks getBlockLocations(String clientMachine, String src,\n       long offset, long length) throws AccessControlException,\n       FileNotFoundException, UnresolvedLinkException, IOException {\n     LocatedBlocks blocks \u003d getBlockLocations(src, offset, length, true, true);\n     if (blocks !\u003d null) {\n       //sort the blocks\n-      DatanodeDescriptor client \u003d host2DataNodeMap.getDatanodeByHost(\n-          clientMachine);\n+      final DatanodeDescriptor client \u003d \n+          blockManager.getDatanodeManager().getDatanodeByHost(clientMachine);\n       for (LocatedBlock b : blocks.getLocatedBlocks()) {\n         clusterMap.pseudoSortByDistance(client, b.getLocations());\n         \n         // Move decommissioned datanodes to the bottom\n         Arrays.sort(b.getLocations(), DFSUtil.DECOM_COMPARATOR);\n       }\n     }\n     return blocks;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlocks getBlockLocations(String clientMachine, String src,\n      long offset, long length) throws AccessControlException,\n      FileNotFoundException, UnresolvedLinkException, IOException {\n    LocatedBlocks blocks \u003d getBlockLocations(src, offset, length, true, true);\n    if (blocks !\u003d null) {\n      //sort the blocks\n      final DatanodeDescriptor client \u003d \n          blockManager.getDatanodeManager().getDatanodeByHost(clientMachine);\n      for (LocatedBlock b : blocks.getLocatedBlocks()) {\n        clusterMap.pseudoSortByDistance(client, b.getLocations());\n        \n        // Move decommissioned datanodes to the bottom\n        Arrays.sort(b.getLocations(), DFSUtil.DECOM_COMPARATOR);\n      }\n    }\n    return blocks;\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,17 @@\n+  LocatedBlocks getBlockLocations(String clientMachine, String src,\n+      long offset, long length) throws AccessControlException,\n+      FileNotFoundException, UnresolvedLinkException, IOException {\n+    LocatedBlocks blocks \u003d getBlockLocations(src, offset, length, true, true);\n+    if (blocks !\u003d null) {\n+      //sort the blocks\n+      DatanodeDescriptor client \u003d host2DataNodeMap.getDatanodeByHost(\n+          clientMachine);\n+      for (LocatedBlock b : blocks.getLocatedBlocks()) {\n+        clusterMap.pseudoSortByDistance(client, b.getLocations());\n+        \n+        // Move decommissioned datanodes to the bottom\n+        Arrays.sort(b.getLocations(), DFSUtil.DECOM_COMPARATOR);\n+      }\n+    }\n+    return blocks;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  LocatedBlocks getBlockLocations(String clientMachine, String src,\n      long offset, long length) throws AccessControlException,\n      FileNotFoundException, UnresolvedLinkException, IOException {\n    LocatedBlocks blocks \u003d getBlockLocations(src, offset, length, true, true);\n    if (blocks !\u003d null) {\n      //sort the blocks\n      DatanodeDescriptor client \u003d host2DataNodeMap.getDatanodeByHost(\n          clientMachine);\n      for (LocatedBlock b : blocks.getLocatedBlocks()) {\n        clusterMap.pseudoSortByDistance(client, b.getLocations());\n        \n        // Move decommissioned datanodes to the bottom\n        Arrays.sort(b.getLocations(), DFSUtil.DECOM_COMPARATOR);\n      }\n    }\n    return blocks;\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java"
    }
  }
}