{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "CBZip2OutputStream.java",
  "functionName": "mainSort",
  "functionId": "mainSort",
  "sourceFilePath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/bzip2/CBZip2OutputStream.java",
  "functionStartLine": 1736,
  "functionEndLine": 1899,
  "numCommitsSeen": 7,
  "timeTaken": 1050,
  "changeHistory": [
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "0f6dfeeacbab65a31a33927a4eb84871d371fe52",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
    "5128a9a453d64bfe1ed978cf9ffed27985eeef36"
  ],
  "changeHistoryShort": {
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "0f6dfeeacbab65a31a33927a4eb84871d371fe52": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yfilerename",
    "5128a9a453d64bfe1ed978cf9ffed27985eeef36": "Yintroduced"
  },
  "changeHistoryDetails": {
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private void mainSort() {\n    final Data dataShadow \u003d this.data;\n    final int[] runningOrder \u003d dataShadow.mainSort_runningOrder;\n    final int[] copy \u003d dataShadow.mainSort_copy;\n    final boolean[] bigDone \u003d dataShadow.mainSort_bigDone;\n    final int[] ftab \u003d dataShadow.ftab;\n    final byte[] block \u003d dataShadow.block;\n    final int[] fmap \u003d dataShadow.fmap;\n    final char[] quadrant \u003d dataShadow.quadrant;\n    final int lastShadow \u003d this.last;\n    final int workLimitShadow \u003d this.workLimit;\n    final boolean firstAttemptShadow \u003d this.firstAttempt;\n\n    // Set up the 2-byte frequency table\n    for (int i \u003d 65537; --i \u003e\u003d 0;) {\n      ftab[i] \u003d 0;\n    }\n\n    /*\n    * In the various block-sized structures, live data runs from 0 to\n    * last+NUM_OVERSHOOT_BYTES inclusive. First, set up the overshoot area\n    * for block.\n    */\n    for (int i \u003d 0; i \u003c NUM_OVERSHOOT_BYTES; i++) {\n      block[lastShadow + i + 2] \u003d block[(i % (lastShadow + 1)) + 1];\n    }\n    for (int i \u003d lastShadow + NUM_OVERSHOOT_BYTES +1; --i \u003e\u003d 0;) {\n      quadrant[i] \u003d 0;\n    }\n    block[0] \u003d block[lastShadow + 1];\n\n    // Complete the initial radix sort:\n\n    int c1 \u003d block[0] \u0026 0xff;\n    for (int i \u003d 0; i \u003c\u003d lastShadow; i++) {\n      final int c2 \u003d block[i + 1] \u0026 0xff;\n      ftab[(c1 \u003c\u003c 8) + c2]++;\n      c1 \u003d c2;\n    }\n\n    for (int i \u003d 1; i \u003c\u003d 65536; i++)\n      ftab[i] +\u003d ftab[i - 1];\n\n    c1 \u003d block[1] \u0026 0xff;\n    for (int i \u003d 0; i \u003c lastShadow; i++) {\n      final int c2 \u003d block[i + 2] \u0026 0xff;\n      fmap[--ftab[(c1 \u003c\u003c 8) + c2]] \u003d i;\n      c1 \u003d c2;\n    }\n\n    fmap[--ftab[((block[lastShadow + 1] \u0026 0xff) \u003c\u003c 8) + (block[1] \u0026 0xff)]] \u003d lastShadow;\n\n    /*\n    * Now ftab contains the first loc of every small bucket. Calculate the\n    * running order, from smallest to largest big bucket.\n    */\n    for (int i \u003d 256; --i \u003e\u003d 0;) {\n      bigDone[i] \u003d false;\n      runningOrder[i] \u003d i;\n    }\n\n    for (int h \u003d 364; h !\u003d 1;) {\n      h /\u003d 3;\n      for (int i \u003d h; i \u003c\u003d 255; i++) {\n        final int vv \u003d runningOrder[i];\n        final int a \u003d ftab[(vv + 1) \u003c\u003c 8] - ftab[vv \u003c\u003c 8];\n        final int b \u003d h - 1;\n        int j \u003d i;\n        for (int ro \u003d runningOrder[j - h]; (ftab[(ro + 1) \u003c\u003c 8] - ftab[ro \u003c\u003c 8]) \u003e a; ro \u003d runningOrder[j\n            - h]) {\n          runningOrder[j] \u003d ro;\n          j -\u003d h;\n          if (j \u003c\u003d b) {\n            break;\n          }\n        }\n        runningOrder[j] \u003d vv;\n      }\n    }\n\n    /*\n    * The main sorting loop.\n    */\n    for (int i \u003d 0; i \u003c\u003d 255; i++) {\n      /*\n      * Process big buckets, starting with the least full.\n      */\n      final int ss \u003d runningOrder[i];\n\n      // Step 1:\n      /*\n      * Complete the big bucket [ss] by quicksorting any unsorted small\n      * buckets [ss, j]. Hopefully previous pointer-scanning phases have\n      * already completed many of the small buckets [ss, j], so we don\u0027t\n      * have to sort them at all.\n      */\n      for (int j \u003d 0; j \u003c\u003d 255; j++) {\n        final int sb \u003d (ss \u003c\u003c 8) + j;\n        final int ftab_sb \u003d ftab[sb];\n        if ((ftab_sb \u0026 SETMASK) !\u003d SETMASK) {\n          final int lo \u003d ftab_sb \u0026 CLEARMASK;\n          final int hi \u003d (ftab[sb + 1] \u0026 CLEARMASK) - 1;\n          if (hi \u003e lo) {\n            mainQSort3(dataShadow, lo, hi, 2);\n            if (firstAttemptShadow\n                \u0026\u0026 (this.workDone \u003e workLimitShadow)) {\n              return;\n            }\n          }\n          ftab[sb] \u003d ftab_sb | SETMASK;\n        }\n      }\n\n      // Step 2:\n      // Now scan this big bucket so as to synthesise the\n      // sorted order for small buckets [t, ss] for all t !\u003d ss.\n\n      for (int j \u003d 0; j \u003c\u003d 255; j++) {\n        copy[j] \u003d ftab[(j \u003c\u003c 8) + ss] \u0026 CLEARMASK;\n      }\n\n      for (int j \u003d ftab[ss \u003c\u003c 8] \u0026 CLEARMASK, hj \u003d (ftab[(ss + 1) \u003c\u003c 8] \u0026 CLEARMASK); j \u003c hj; j++) {\n        final int fmap_j \u003d fmap[j];\n        c1 \u003d block[fmap_j] \u0026 0xff;\n        if (!bigDone[c1]) {\n          fmap[copy[c1]] \u003d (fmap_j \u003d\u003d 0) ? lastShadow : (fmap_j - 1);\n          copy[c1]++;\n        }\n      }\n\n      for (int j \u003d 256; --j \u003e\u003d 0;)\n        ftab[(j \u003c\u003c 8) + ss] |\u003d SETMASK;\n\n      // Step 3:\n      /*\n      * The ss big bucket is now done. Record this fact, and update the\n      * quadrant descriptors. Remember to update quadrants in the\n      * overshoot area too, if necessary. The \"if (i \u003c 255)\" test merely\n      * skips this updating for the last bucket processed, since updating\n      * for the last bucket is pointless.\n      */\n      bigDone[ss] \u003d true;\n\n      if (i \u003c 255) {\n        final int bbStart \u003d ftab[ss \u003c\u003c 8] \u0026 CLEARMASK;\n        final int bbSize \u003d (ftab[(ss + 1) \u003c\u003c 8] \u0026 CLEARMASK) - bbStart;\n        int shifts \u003d 0;\n\n        while ((bbSize \u003e\u003e shifts) \u003e 65534) {\n          shifts++;\n        }\n\n        for (int j \u003d 0; j \u003c bbSize; j++) {\n          final int a2update \u003d fmap[bbStart + j];\n          final char qVal \u003d (char) (j \u003e\u003e shifts);\n          quadrant[a2update] \u003d qVal;\n          if (a2update \u003c NUM_OVERSHOOT_BYTES) {\n            quadrant[a2update + lastShadow + 1] \u003d qVal;\n          }\n        }\n      }\n\n    }\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/bzip2/CBZip2OutputStream.java",
      "extendedDetails": {
        "oldPath": "hadoop-common/src/main/java/org/apache/hadoop/io/compress/bzip2/CBZip2OutputStream.java",
        "newPath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/bzip2/CBZip2OutputStream.java"
      }
    },
    "0f6dfeeacbab65a31a33927a4eb84871d371fe52": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-6671. Use maven for hadoop common builds. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1153184 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/08/11 9:37 AM",
      "commitName": "0f6dfeeacbab65a31a33927a4eb84871d371fe52",
      "commitAuthor": "Thomas White",
      "commitDateOld": "01/08/11 3:53 PM",
      "commitNameOld": "9bac807cedbcff34e1a144fb475eff267e5ed86d",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.74,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private void mainSort() {\n    final Data dataShadow \u003d this.data;\n    final int[] runningOrder \u003d dataShadow.mainSort_runningOrder;\n    final int[] copy \u003d dataShadow.mainSort_copy;\n    final boolean[] bigDone \u003d dataShadow.mainSort_bigDone;\n    final int[] ftab \u003d dataShadow.ftab;\n    final byte[] block \u003d dataShadow.block;\n    final int[] fmap \u003d dataShadow.fmap;\n    final char[] quadrant \u003d dataShadow.quadrant;\n    final int lastShadow \u003d this.last;\n    final int workLimitShadow \u003d this.workLimit;\n    final boolean firstAttemptShadow \u003d this.firstAttempt;\n\n    // Set up the 2-byte frequency table\n    for (int i \u003d 65537; --i \u003e\u003d 0;) {\n      ftab[i] \u003d 0;\n    }\n\n    /*\n    * In the various block-sized structures, live data runs from 0 to\n    * last+NUM_OVERSHOOT_BYTES inclusive. First, set up the overshoot area\n    * for block.\n    */\n    for (int i \u003d 0; i \u003c NUM_OVERSHOOT_BYTES; i++) {\n      block[lastShadow + i + 2] \u003d block[(i % (lastShadow + 1)) + 1];\n    }\n    for (int i \u003d lastShadow + NUM_OVERSHOOT_BYTES +1; --i \u003e\u003d 0;) {\n      quadrant[i] \u003d 0;\n    }\n    block[0] \u003d block[lastShadow + 1];\n\n    // Complete the initial radix sort:\n\n    int c1 \u003d block[0] \u0026 0xff;\n    for (int i \u003d 0; i \u003c\u003d lastShadow; i++) {\n      final int c2 \u003d block[i + 1] \u0026 0xff;\n      ftab[(c1 \u003c\u003c 8) + c2]++;\n      c1 \u003d c2;\n    }\n\n    for (int i \u003d 1; i \u003c\u003d 65536; i++)\n      ftab[i] +\u003d ftab[i - 1];\n\n    c1 \u003d block[1] \u0026 0xff;\n    for (int i \u003d 0; i \u003c lastShadow; i++) {\n      final int c2 \u003d block[i + 2] \u0026 0xff;\n      fmap[--ftab[(c1 \u003c\u003c 8) + c2]] \u003d i;\n      c1 \u003d c2;\n    }\n\n    fmap[--ftab[((block[lastShadow + 1] \u0026 0xff) \u003c\u003c 8) + (block[1] \u0026 0xff)]] \u003d lastShadow;\n\n    /*\n    * Now ftab contains the first loc of every small bucket. Calculate the\n    * running order, from smallest to largest big bucket.\n    */\n    for (int i \u003d 256; --i \u003e\u003d 0;) {\n      bigDone[i] \u003d false;\n      runningOrder[i] \u003d i;\n    }\n\n    for (int h \u003d 364; h !\u003d 1;) {\n      h /\u003d 3;\n      for (int i \u003d h; i \u003c\u003d 255; i++) {\n        final int vv \u003d runningOrder[i];\n        final int a \u003d ftab[(vv + 1) \u003c\u003c 8] - ftab[vv \u003c\u003c 8];\n        final int b \u003d h - 1;\n        int j \u003d i;\n        for (int ro \u003d runningOrder[j - h]; (ftab[(ro + 1) \u003c\u003c 8] - ftab[ro \u003c\u003c 8]) \u003e a; ro \u003d runningOrder[j\n            - h]) {\n          runningOrder[j] \u003d ro;\n          j -\u003d h;\n          if (j \u003c\u003d b) {\n            break;\n          }\n        }\n        runningOrder[j] \u003d vv;\n      }\n    }\n\n    /*\n    * The main sorting loop.\n    */\n    for (int i \u003d 0; i \u003c\u003d 255; i++) {\n      /*\n      * Process big buckets, starting with the least full.\n      */\n      final int ss \u003d runningOrder[i];\n\n      // Step 1:\n      /*\n      * Complete the big bucket [ss] by quicksorting any unsorted small\n      * buckets [ss, j]. Hopefully previous pointer-scanning phases have\n      * already completed many of the small buckets [ss, j], so we don\u0027t\n      * have to sort them at all.\n      */\n      for (int j \u003d 0; j \u003c\u003d 255; j++) {\n        final int sb \u003d (ss \u003c\u003c 8) + j;\n        final int ftab_sb \u003d ftab[sb];\n        if ((ftab_sb \u0026 SETMASK) !\u003d SETMASK) {\n          final int lo \u003d ftab_sb \u0026 CLEARMASK;\n          final int hi \u003d (ftab[sb + 1] \u0026 CLEARMASK) - 1;\n          if (hi \u003e lo) {\n            mainQSort3(dataShadow, lo, hi, 2);\n            if (firstAttemptShadow\n                \u0026\u0026 (this.workDone \u003e workLimitShadow)) {\n              return;\n            }\n          }\n          ftab[sb] \u003d ftab_sb | SETMASK;\n        }\n      }\n\n      // Step 2:\n      // Now scan this big bucket so as to synthesise the\n      // sorted order for small buckets [t, ss] for all t !\u003d ss.\n\n      for (int j \u003d 0; j \u003c\u003d 255; j++) {\n        copy[j] \u003d ftab[(j \u003c\u003c 8) + ss] \u0026 CLEARMASK;\n      }\n\n      for (int j \u003d ftab[ss \u003c\u003c 8] \u0026 CLEARMASK, hj \u003d (ftab[(ss + 1) \u003c\u003c 8] \u0026 CLEARMASK); j \u003c hj; j++) {\n        final int fmap_j \u003d fmap[j];\n        c1 \u003d block[fmap_j] \u0026 0xff;\n        if (!bigDone[c1]) {\n          fmap[copy[c1]] \u003d (fmap_j \u003d\u003d 0) ? lastShadow : (fmap_j - 1);\n          copy[c1]++;\n        }\n      }\n\n      for (int j \u003d 256; --j \u003e\u003d 0;)\n        ftab[(j \u003c\u003c 8) + ss] |\u003d SETMASK;\n\n      // Step 3:\n      /*\n      * The ss big bucket is now done. Record this fact, and update the\n      * quadrant descriptors. Remember to update quadrants in the\n      * overshoot area too, if necessary. The \"if (i \u003c 255)\" test merely\n      * skips this updating for the last bucket processed, since updating\n      * for the last bucket is pointless.\n      */\n      bigDone[ss] \u003d true;\n\n      if (i \u003c 255) {\n        final int bbStart \u003d ftab[ss \u003c\u003c 8] \u0026 CLEARMASK;\n        final int bbSize \u003d (ftab[(ss + 1) \u003c\u003c 8] \u0026 CLEARMASK) - bbStart;\n        int shifts \u003d 0;\n\n        while ((bbSize \u003e\u003e shifts) \u003e 65534) {\n          shifts++;\n        }\n\n        for (int j \u003d 0; j \u003c bbSize; j++) {\n          final int a2update \u003d fmap[bbStart + j];\n          final char qVal \u003d (char) (j \u003e\u003e shifts);\n          quadrant[a2update] \u003d qVal;\n          if (a2update \u003c NUM_OVERSHOOT_BYTES) {\n            quadrant[a2update + lastShadow + 1] \u003d qVal;\n          }\n        }\n      }\n\n    }\n  }",
      "path": "hadoop-common/src/main/java/org/apache/hadoop/io/compress/bzip2/CBZip2OutputStream.java",
      "extendedDetails": {
        "oldPath": "common/src/java/org/apache/hadoop/io/compress/bzip2/CBZip2OutputStream.java",
        "newPath": "hadoop-common/src/main/java/org/apache/hadoop/io/compress/bzip2/CBZip2OutputStream.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "11/06/11 9:13 PM",
      "commitNameOld": "a285fb5effe9ba3be4ec5f942afaf5ddd1186151",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 0.74,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private void mainSort() {\n    final Data dataShadow \u003d this.data;\n    final int[] runningOrder \u003d dataShadow.mainSort_runningOrder;\n    final int[] copy \u003d dataShadow.mainSort_copy;\n    final boolean[] bigDone \u003d dataShadow.mainSort_bigDone;\n    final int[] ftab \u003d dataShadow.ftab;\n    final byte[] block \u003d dataShadow.block;\n    final int[] fmap \u003d dataShadow.fmap;\n    final char[] quadrant \u003d dataShadow.quadrant;\n    final int lastShadow \u003d this.last;\n    final int workLimitShadow \u003d this.workLimit;\n    final boolean firstAttemptShadow \u003d this.firstAttempt;\n\n    // Set up the 2-byte frequency table\n    for (int i \u003d 65537; --i \u003e\u003d 0;) {\n      ftab[i] \u003d 0;\n    }\n\n    /*\n    * In the various block-sized structures, live data runs from 0 to\n    * last+NUM_OVERSHOOT_BYTES inclusive. First, set up the overshoot area\n    * for block.\n    */\n    for (int i \u003d 0; i \u003c NUM_OVERSHOOT_BYTES; i++) {\n      block[lastShadow + i + 2] \u003d block[(i % (lastShadow + 1)) + 1];\n    }\n    for (int i \u003d lastShadow + NUM_OVERSHOOT_BYTES +1; --i \u003e\u003d 0;) {\n      quadrant[i] \u003d 0;\n    }\n    block[0] \u003d block[lastShadow + 1];\n\n    // Complete the initial radix sort:\n\n    int c1 \u003d block[0] \u0026 0xff;\n    for (int i \u003d 0; i \u003c\u003d lastShadow; i++) {\n      final int c2 \u003d block[i + 1] \u0026 0xff;\n      ftab[(c1 \u003c\u003c 8) + c2]++;\n      c1 \u003d c2;\n    }\n\n    for (int i \u003d 1; i \u003c\u003d 65536; i++)\n      ftab[i] +\u003d ftab[i - 1];\n\n    c1 \u003d block[1] \u0026 0xff;\n    for (int i \u003d 0; i \u003c lastShadow; i++) {\n      final int c2 \u003d block[i + 2] \u0026 0xff;\n      fmap[--ftab[(c1 \u003c\u003c 8) + c2]] \u003d i;\n      c1 \u003d c2;\n    }\n\n    fmap[--ftab[((block[lastShadow + 1] \u0026 0xff) \u003c\u003c 8) + (block[1] \u0026 0xff)]] \u003d lastShadow;\n\n    /*\n    * Now ftab contains the first loc of every small bucket. Calculate the\n    * running order, from smallest to largest big bucket.\n    */\n    for (int i \u003d 256; --i \u003e\u003d 0;) {\n      bigDone[i] \u003d false;\n      runningOrder[i] \u003d i;\n    }\n\n    for (int h \u003d 364; h !\u003d 1;) {\n      h /\u003d 3;\n      for (int i \u003d h; i \u003c\u003d 255; i++) {\n        final int vv \u003d runningOrder[i];\n        final int a \u003d ftab[(vv + 1) \u003c\u003c 8] - ftab[vv \u003c\u003c 8];\n        final int b \u003d h - 1;\n        int j \u003d i;\n        for (int ro \u003d runningOrder[j - h]; (ftab[(ro + 1) \u003c\u003c 8] - ftab[ro \u003c\u003c 8]) \u003e a; ro \u003d runningOrder[j\n            - h]) {\n          runningOrder[j] \u003d ro;\n          j -\u003d h;\n          if (j \u003c\u003d b) {\n            break;\n          }\n        }\n        runningOrder[j] \u003d vv;\n      }\n    }\n\n    /*\n    * The main sorting loop.\n    */\n    for (int i \u003d 0; i \u003c\u003d 255; i++) {\n      /*\n      * Process big buckets, starting with the least full.\n      */\n      final int ss \u003d runningOrder[i];\n\n      // Step 1:\n      /*\n      * Complete the big bucket [ss] by quicksorting any unsorted small\n      * buckets [ss, j]. Hopefully previous pointer-scanning phases have\n      * already completed many of the small buckets [ss, j], so we don\u0027t\n      * have to sort them at all.\n      */\n      for (int j \u003d 0; j \u003c\u003d 255; j++) {\n        final int sb \u003d (ss \u003c\u003c 8) + j;\n        final int ftab_sb \u003d ftab[sb];\n        if ((ftab_sb \u0026 SETMASK) !\u003d SETMASK) {\n          final int lo \u003d ftab_sb \u0026 CLEARMASK;\n          final int hi \u003d (ftab[sb + 1] \u0026 CLEARMASK) - 1;\n          if (hi \u003e lo) {\n            mainQSort3(dataShadow, lo, hi, 2);\n            if (firstAttemptShadow\n                \u0026\u0026 (this.workDone \u003e workLimitShadow)) {\n              return;\n            }\n          }\n          ftab[sb] \u003d ftab_sb | SETMASK;\n        }\n      }\n\n      // Step 2:\n      // Now scan this big bucket so as to synthesise the\n      // sorted order for small buckets [t, ss] for all t !\u003d ss.\n\n      for (int j \u003d 0; j \u003c\u003d 255; j++) {\n        copy[j] \u003d ftab[(j \u003c\u003c 8) + ss] \u0026 CLEARMASK;\n      }\n\n      for (int j \u003d ftab[ss \u003c\u003c 8] \u0026 CLEARMASK, hj \u003d (ftab[(ss + 1) \u003c\u003c 8] \u0026 CLEARMASK); j \u003c hj; j++) {\n        final int fmap_j \u003d fmap[j];\n        c1 \u003d block[fmap_j] \u0026 0xff;\n        if (!bigDone[c1]) {\n          fmap[copy[c1]] \u003d (fmap_j \u003d\u003d 0) ? lastShadow : (fmap_j - 1);\n          copy[c1]++;\n        }\n      }\n\n      for (int j \u003d 256; --j \u003e\u003d 0;)\n        ftab[(j \u003c\u003c 8) + ss] |\u003d SETMASK;\n\n      // Step 3:\n      /*\n      * The ss big bucket is now done. Record this fact, and update the\n      * quadrant descriptors. Remember to update quadrants in the\n      * overshoot area too, if necessary. The \"if (i \u003c 255)\" test merely\n      * skips this updating for the last bucket processed, since updating\n      * for the last bucket is pointless.\n      */\n      bigDone[ss] \u003d true;\n\n      if (i \u003c 255) {\n        final int bbStart \u003d ftab[ss \u003c\u003c 8] \u0026 CLEARMASK;\n        final int bbSize \u003d (ftab[(ss + 1) \u003c\u003c 8] \u0026 CLEARMASK) - bbStart;\n        int shifts \u003d 0;\n\n        while ((bbSize \u003e\u003e shifts) \u003e 65534) {\n          shifts++;\n        }\n\n        for (int j \u003d 0; j \u003c bbSize; j++) {\n          final int a2update \u003d fmap[bbStart + j];\n          final char qVal \u003d (char) (j \u003e\u003e shifts);\n          quadrant[a2update] \u003d qVal;\n          if (a2update \u003c NUM_OVERSHOOT_BYTES) {\n            quadrant[a2update + lastShadow + 1] \u003d qVal;\n          }\n        }\n      }\n\n    }\n  }",
      "path": "common/src/java/org/apache/hadoop/io/compress/bzip2/CBZip2OutputStream.java",
      "extendedDetails": {
        "oldPath": "src/java/org/apache/hadoop/io/compress/bzip2/CBZip2OutputStream.java",
        "newPath": "common/src/java/org/apache/hadoop/io/compress/bzip2/CBZip2OutputStream.java"
      }
    },
    "5128a9a453d64bfe1ed978cf9ffed27985eeef36": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-4687 Moving src directories on branch\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/core/branches/HADOOP-4687/core@776174 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/05/09 9:20 PM",
      "commitName": "5128a9a453d64bfe1ed978cf9ffed27985eeef36",
      "commitAuthor": "Owen O\u0027Malley",
      "diff": "@@ -0,0 +1,164 @@\n+  private void mainSort() {\n+    final Data dataShadow \u003d this.data;\n+    final int[] runningOrder \u003d dataShadow.mainSort_runningOrder;\n+    final int[] copy \u003d dataShadow.mainSort_copy;\n+    final boolean[] bigDone \u003d dataShadow.mainSort_bigDone;\n+    final int[] ftab \u003d dataShadow.ftab;\n+    final byte[] block \u003d dataShadow.block;\n+    final int[] fmap \u003d dataShadow.fmap;\n+    final char[] quadrant \u003d dataShadow.quadrant;\n+    final int lastShadow \u003d this.last;\n+    final int workLimitShadow \u003d this.workLimit;\n+    final boolean firstAttemptShadow \u003d this.firstAttempt;\n+\n+    // Set up the 2-byte frequency table\n+    for (int i \u003d 65537; --i \u003e\u003d 0;) {\n+      ftab[i] \u003d 0;\n+    }\n+\n+    /*\n+    * In the various block-sized structures, live data runs from 0 to\n+    * last+NUM_OVERSHOOT_BYTES inclusive. First, set up the overshoot area\n+    * for block.\n+    */\n+    for (int i \u003d 0; i \u003c NUM_OVERSHOOT_BYTES; i++) {\n+      block[lastShadow + i + 2] \u003d block[(i % (lastShadow + 1)) + 1];\n+    }\n+    for (int i \u003d lastShadow + NUM_OVERSHOOT_BYTES +1; --i \u003e\u003d 0;) {\n+      quadrant[i] \u003d 0;\n+    }\n+    block[0] \u003d block[lastShadow + 1];\n+\n+    // Complete the initial radix sort:\n+\n+    int c1 \u003d block[0] \u0026 0xff;\n+    for (int i \u003d 0; i \u003c\u003d lastShadow; i++) {\n+      final int c2 \u003d block[i + 1] \u0026 0xff;\n+      ftab[(c1 \u003c\u003c 8) + c2]++;\n+      c1 \u003d c2;\n+    }\n+\n+    for (int i \u003d 1; i \u003c\u003d 65536; i++)\n+      ftab[i] +\u003d ftab[i - 1];\n+\n+    c1 \u003d block[1] \u0026 0xff;\n+    for (int i \u003d 0; i \u003c lastShadow; i++) {\n+      final int c2 \u003d block[i + 2] \u0026 0xff;\n+      fmap[--ftab[(c1 \u003c\u003c 8) + c2]] \u003d i;\n+      c1 \u003d c2;\n+    }\n+\n+    fmap[--ftab[((block[lastShadow + 1] \u0026 0xff) \u003c\u003c 8) + (block[1] \u0026 0xff)]] \u003d lastShadow;\n+\n+    /*\n+    * Now ftab contains the first loc of every small bucket. Calculate the\n+    * running order, from smallest to largest big bucket.\n+    */\n+    for (int i \u003d 256; --i \u003e\u003d 0;) {\n+      bigDone[i] \u003d false;\n+      runningOrder[i] \u003d i;\n+    }\n+\n+    for (int h \u003d 364; h !\u003d 1;) {\n+      h /\u003d 3;\n+      for (int i \u003d h; i \u003c\u003d 255; i++) {\n+        final int vv \u003d runningOrder[i];\n+        final int a \u003d ftab[(vv + 1) \u003c\u003c 8] - ftab[vv \u003c\u003c 8];\n+        final int b \u003d h - 1;\n+        int j \u003d i;\n+        for (int ro \u003d runningOrder[j - h]; (ftab[(ro + 1) \u003c\u003c 8] - ftab[ro \u003c\u003c 8]) \u003e a; ro \u003d runningOrder[j\n+            - h]) {\n+          runningOrder[j] \u003d ro;\n+          j -\u003d h;\n+          if (j \u003c\u003d b) {\n+            break;\n+          }\n+        }\n+        runningOrder[j] \u003d vv;\n+      }\n+    }\n+\n+    /*\n+    * The main sorting loop.\n+    */\n+    for (int i \u003d 0; i \u003c\u003d 255; i++) {\n+      /*\n+      * Process big buckets, starting with the least full.\n+      */\n+      final int ss \u003d runningOrder[i];\n+\n+      // Step 1:\n+      /*\n+      * Complete the big bucket [ss] by quicksorting any unsorted small\n+      * buckets [ss, j]. Hopefully previous pointer-scanning phases have\n+      * already completed many of the small buckets [ss, j], so we don\u0027t\n+      * have to sort them at all.\n+      */\n+      for (int j \u003d 0; j \u003c\u003d 255; j++) {\n+        final int sb \u003d (ss \u003c\u003c 8) + j;\n+        final int ftab_sb \u003d ftab[sb];\n+        if ((ftab_sb \u0026 SETMASK) !\u003d SETMASK) {\n+          final int lo \u003d ftab_sb \u0026 CLEARMASK;\n+          final int hi \u003d (ftab[sb + 1] \u0026 CLEARMASK) - 1;\n+          if (hi \u003e lo) {\n+            mainQSort3(dataShadow, lo, hi, 2);\n+            if (firstAttemptShadow\n+                \u0026\u0026 (this.workDone \u003e workLimitShadow)) {\n+              return;\n+            }\n+          }\n+          ftab[sb] \u003d ftab_sb | SETMASK;\n+        }\n+      }\n+\n+      // Step 2:\n+      // Now scan this big bucket so as to synthesise the\n+      // sorted order for small buckets [t, ss] for all t !\u003d ss.\n+\n+      for (int j \u003d 0; j \u003c\u003d 255; j++) {\n+        copy[j] \u003d ftab[(j \u003c\u003c 8) + ss] \u0026 CLEARMASK;\n+      }\n+\n+      for (int j \u003d ftab[ss \u003c\u003c 8] \u0026 CLEARMASK, hj \u003d (ftab[(ss + 1) \u003c\u003c 8] \u0026 CLEARMASK); j \u003c hj; j++) {\n+        final int fmap_j \u003d fmap[j];\n+        c1 \u003d block[fmap_j] \u0026 0xff;\n+        if (!bigDone[c1]) {\n+          fmap[copy[c1]] \u003d (fmap_j \u003d\u003d 0) ? lastShadow : (fmap_j - 1);\n+          copy[c1]++;\n+        }\n+      }\n+\n+      for (int j \u003d 256; --j \u003e\u003d 0;)\n+        ftab[(j \u003c\u003c 8) + ss] |\u003d SETMASK;\n+\n+      // Step 3:\n+      /*\n+      * The ss big bucket is now done. Record this fact, and update the\n+      * quadrant descriptors. Remember to update quadrants in the\n+      * overshoot area too, if necessary. The \"if (i \u003c 255)\" test merely\n+      * skips this updating for the last bucket processed, since updating\n+      * for the last bucket is pointless.\n+      */\n+      bigDone[ss] \u003d true;\n+\n+      if (i \u003c 255) {\n+        final int bbStart \u003d ftab[ss \u003c\u003c 8] \u0026 CLEARMASK;\n+        final int bbSize \u003d (ftab[(ss + 1) \u003c\u003c 8] \u0026 CLEARMASK) - bbStart;\n+        int shifts \u003d 0;\n+\n+        while ((bbSize \u003e\u003e shifts) \u003e 65534) {\n+          shifts++;\n+        }\n+\n+        for (int j \u003d 0; j \u003c bbSize; j++) {\n+          final int a2update \u003d fmap[bbStart + j];\n+          final char qVal \u003d (char) (j \u003e\u003e shifts);\n+          quadrant[a2update] \u003d qVal;\n+          if (a2update \u003c NUM_OVERSHOOT_BYTES) {\n+            quadrant[a2update + lastShadow + 1] \u003d qVal;\n+          }\n+        }\n+      }\n+\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void mainSort() {\n    final Data dataShadow \u003d this.data;\n    final int[] runningOrder \u003d dataShadow.mainSort_runningOrder;\n    final int[] copy \u003d dataShadow.mainSort_copy;\n    final boolean[] bigDone \u003d dataShadow.mainSort_bigDone;\n    final int[] ftab \u003d dataShadow.ftab;\n    final byte[] block \u003d dataShadow.block;\n    final int[] fmap \u003d dataShadow.fmap;\n    final char[] quadrant \u003d dataShadow.quadrant;\n    final int lastShadow \u003d this.last;\n    final int workLimitShadow \u003d this.workLimit;\n    final boolean firstAttemptShadow \u003d this.firstAttempt;\n\n    // Set up the 2-byte frequency table\n    for (int i \u003d 65537; --i \u003e\u003d 0;) {\n      ftab[i] \u003d 0;\n    }\n\n    /*\n    * In the various block-sized structures, live data runs from 0 to\n    * last+NUM_OVERSHOOT_BYTES inclusive. First, set up the overshoot area\n    * for block.\n    */\n    for (int i \u003d 0; i \u003c NUM_OVERSHOOT_BYTES; i++) {\n      block[lastShadow + i + 2] \u003d block[(i % (lastShadow + 1)) + 1];\n    }\n    for (int i \u003d lastShadow + NUM_OVERSHOOT_BYTES +1; --i \u003e\u003d 0;) {\n      quadrant[i] \u003d 0;\n    }\n    block[0] \u003d block[lastShadow + 1];\n\n    // Complete the initial radix sort:\n\n    int c1 \u003d block[0] \u0026 0xff;\n    for (int i \u003d 0; i \u003c\u003d lastShadow; i++) {\n      final int c2 \u003d block[i + 1] \u0026 0xff;\n      ftab[(c1 \u003c\u003c 8) + c2]++;\n      c1 \u003d c2;\n    }\n\n    for (int i \u003d 1; i \u003c\u003d 65536; i++)\n      ftab[i] +\u003d ftab[i - 1];\n\n    c1 \u003d block[1] \u0026 0xff;\n    for (int i \u003d 0; i \u003c lastShadow; i++) {\n      final int c2 \u003d block[i + 2] \u0026 0xff;\n      fmap[--ftab[(c1 \u003c\u003c 8) + c2]] \u003d i;\n      c1 \u003d c2;\n    }\n\n    fmap[--ftab[((block[lastShadow + 1] \u0026 0xff) \u003c\u003c 8) + (block[1] \u0026 0xff)]] \u003d lastShadow;\n\n    /*\n    * Now ftab contains the first loc of every small bucket. Calculate the\n    * running order, from smallest to largest big bucket.\n    */\n    for (int i \u003d 256; --i \u003e\u003d 0;) {\n      bigDone[i] \u003d false;\n      runningOrder[i] \u003d i;\n    }\n\n    for (int h \u003d 364; h !\u003d 1;) {\n      h /\u003d 3;\n      for (int i \u003d h; i \u003c\u003d 255; i++) {\n        final int vv \u003d runningOrder[i];\n        final int a \u003d ftab[(vv + 1) \u003c\u003c 8] - ftab[vv \u003c\u003c 8];\n        final int b \u003d h - 1;\n        int j \u003d i;\n        for (int ro \u003d runningOrder[j - h]; (ftab[(ro + 1) \u003c\u003c 8] - ftab[ro \u003c\u003c 8]) \u003e a; ro \u003d runningOrder[j\n            - h]) {\n          runningOrder[j] \u003d ro;\n          j -\u003d h;\n          if (j \u003c\u003d b) {\n            break;\n          }\n        }\n        runningOrder[j] \u003d vv;\n      }\n    }\n\n    /*\n    * The main sorting loop.\n    */\n    for (int i \u003d 0; i \u003c\u003d 255; i++) {\n      /*\n      * Process big buckets, starting with the least full.\n      */\n      final int ss \u003d runningOrder[i];\n\n      // Step 1:\n      /*\n      * Complete the big bucket [ss] by quicksorting any unsorted small\n      * buckets [ss, j]. Hopefully previous pointer-scanning phases have\n      * already completed many of the small buckets [ss, j], so we don\u0027t\n      * have to sort them at all.\n      */\n      for (int j \u003d 0; j \u003c\u003d 255; j++) {\n        final int sb \u003d (ss \u003c\u003c 8) + j;\n        final int ftab_sb \u003d ftab[sb];\n        if ((ftab_sb \u0026 SETMASK) !\u003d SETMASK) {\n          final int lo \u003d ftab_sb \u0026 CLEARMASK;\n          final int hi \u003d (ftab[sb + 1] \u0026 CLEARMASK) - 1;\n          if (hi \u003e lo) {\n            mainQSort3(dataShadow, lo, hi, 2);\n            if (firstAttemptShadow\n                \u0026\u0026 (this.workDone \u003e workLimitShadow)) {\n              return;\n            }\n          }\n          ftab[sb] \u003d ftab_sb | SETMASK;\n        }\n      }\n\n      // Step 2:\n      // Now scan this big bucket so as to synthesise the\n      // sorted order for small buckets [t, ss] for all t !\u003d ss.\n\n      for (int j \u003d 0; j \u003c\u003d 255; j++) {\n        copy[j] \u003d ftab[(j \u003c\u003c 8) + ss] \u0026 CLEARMASK;\n      }\n\n      for (int j \u003d ftab[ss \u003c\u003c 8] \u0026 CLEARMASK, hj \u003d (ftab[(ss + 1) \u003c\u003c 8] \u0026 CLEARMASK); j \u003c hj; j++) {\n        final int fmap_j \u003d fmap[j];\n        c1 \u003d block[fmap_j] \u0026 0xff;\n        if (!bigDone[c1]) {\n          fmap[copy[c1]] \u003d (fmap_j \u003d\u003d 0) ? lastShadow : (fmap_j - 1);\n          copy[c1]++;\n        }\n      }\n\n      for (int j \u003d 256; --j \u003e\u003d 0;)\n        ftab[(j \u003c\u003c 8) + ss] |\u003d SETMASK;\n\n      // Step 3:\n      /*\n      * The ss big bucket is now done. Record this fact, and update the\n      * quadrant descriptors. Remember to update quadrants in the\n      * overshoot area too, if necessary. The \"if (i \u003c 255)\" test merely\n      * skips this updating for the last bucket processed, since updating\n      * for the last bucket is pointless.\n      */\n      bigDone[ss] \u003d true;\n\n      if (i \u003c 255) {\n        final int bbStart \u003d ftab[ss \u003c\u003c 8] \u0026 CLEARMASK;\n        final int bbSize \u003d (ftab[(ss + 1) \u003c\u003c 8] \u0026 CLEARMASK) - bbStart;\n        int shifts \u003d 0;\n\n        while ((bbSize \u003e\u003e shifts) \u003e 65534) {\n          shifts++;\n        }\n\n        for (int j \u003d 0; j \u003c bbSize; j++) {\n          final int a2update \u003d fmap[bbStart + j];\n          final char qVal \u003d (char) (j \u003e\u003e shifts);\n          quadrant[a2update] \u003d qVal;\n          if (a2update \u003c NUM_OVERSHOOT_BYTES) {\n            quadrant[a2update + lastShadow + 1] \u003d qVal;\n          }\n        }\n      }\n\n    }\n  }",
      "path": "src/java/org/apache/hadoop/io/compress/bzip2/CBZip2OutputStream.java"
    }
  }
}