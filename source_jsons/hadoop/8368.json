{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSDirSnapshotOp.java",
  "functionName": "checkSnapshot",
  "functionId": "checkSnapshot___target-INode__snapshottableDirs-List__INodeDirectory__",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirSnapshotOp.java",
  "functionStartLine": 294,
  "functionEndLine": 317,
  "numCommitsSeen": 225,
  "timeTaken": 3826,
  "changeHistory": [
    "44f48ee96ee6b2a3909911c37bfddb0c963d5ffc",
    "4a3161182905afaf450a60d02528161ed1f97471"
  ],
  "changeHistoryShort": {
    "44f48ee96ee6b2a3909911c37bfddb0c963d5ffc": "Ymodifierchange",
    "4a3161182905afaf450a60d02528161ed1f97471": "Ymultichange(Ymovefromfile,Ymodifierchange)"
  },
  "changeHistoryDetails": {
    "44f48ee96ee6b2a3909911c37bfddb0c963d5ffc": {
      "type": "Ymodifierchange",
      "commitMessage": "HDFS-10956. Remove rename/delete performance penalty when not using snapshots. Contributed by Daryn Sharp.\n",
      "commitDate": "04/10/16 1:05 PM",
      "commitName": "44f48ee96ee6b2a3909911c37bfddb0c963d5ffc",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "05/11/15 2:36 PM",
      "commitNameOld": "286cc6483fe458894cdd22ff1d8822c304e0d94f",
      "commitAuthorOld": "Yongjun Zhang",
      "daysBetweenCommits": 333.9,
      "commitsBetweenForRepo": 2244,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,24 @@\n-  static void checkSnapshot(\n+  private static void checkSnapshot(\n       INode target, List\u003cINodeDirectory\u003e snapshottableDirs)\n       throws SnapshotException {\n     if (target.isDirectory()) {\n       INodeDirectory targetDir \u003d target.asDirectory();\n       DirectorySnapshottableFeature sf \u003d targetDir\n           .getDirectorySnapshottableFeature();\n       if (sf !\u003d null) {\n         if (sf.getNumSnapshots() \u003e 0) {\n           String fullPath \u003d targetDir.getFullPathName();\n           throw new SnapshotException(\"The directory \" + fullPath\n               + \" cannot be deleted since \" + fullPath\n               + \" is snapshottable and already has snapshots\");\n         } else {\n           if (snapshottableDirs !\u003d null) {\n             snapshottableDirs.add(targetDir);\n           }\n         }\n       }\n       for (INode child : targetDir.getChildrenList(Snapshot.CURRENT_STATE_ID)) {\n         checkSnapshot(child, snapshottableDirs);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private static void checkSnapshot(\n      INode target, List\u003cINodeDirectory\u003e snapshottableDirs)\n      throws SnapshotException {\n    if (target.isDirectory()) {\n      INodeDirectory targetDir \u003d target.asDirectory();\n      DirectorySnapshottableFeature sf \u003d targetDir\n          .getDirectorySnapshottableFeature();\n      if (sf !\u003d null) {\n        if (sf.getNumSnapshots() \u003e 0) {\n          String fullPath \u003d targetDir.getFullPathName();\n          throw new SnapshotException(\"The directory \" + fullPath\n              + \" cannot be deleted since \" + fullPath\n              + \" is snapshottable and already has snapshots\");\n        } else {\n          if (snapshottableDirs !\u003d null) {\n            snapshottableDirs.add(targetDir);\n          }\n        }\n      }\n      for (INode child : targetDir.getChildrenList(Snapshot.CURRENT_STATE_ID)) {\n        checkSnapshot(child, snapshottableDirs);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirSnapshotOp.java",
      "extendedDetails": {
        "oldValue": "[static]",
        "newValue": "[private, static]"
      }
    },
    "4a3161182905afaf450a60d02528161ed1f97471": {
      "type": "Ymultichange(Ymovefromfile,Ymodifierchange)",
      "commitMessage": "HDFS-7440. Consolidate snapshot related operations in a single class. Contributed by Haohui Mai.\n",
      "commitDate": "25/11/14 9:04 PM",
      "commitName": "4a3161182905afaf450a60d02528161ed1f97471",
      "commitAuthor": "Haohui Mai",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-7440. Consolidate snapshot related operations in a single class. Contributed by Haohui Mai.\n",
          "commitDate": "25/11/14 9:04 PM",
          "commitName": "4a3161182905afaf450a60d02528161ed1f97471",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "25/11/14 4:24 PM",
          "commitNameOld": "a655973e781caf662b360c96e0fa3f5a873cf676",
          "commitAuthorOld": "Karthik Kambatla",
          "daysBetweenCommits": 0.19,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,23 +1,24 @@\n-  private static void checkSnapshot(INode target,\n-      List\u003cINodeDirectory\u003e snapshottableDirs) throws SnapshotException {\n+  static void checkSnapshot(\n+      INode target, List\u003cINodeDirectory\u003e snapshottableDirs)\n+      throws SnapshotException {\n     if (target.isDirectory()) {\n       INodeDirectory targetDir \u003d target.asDirectory();\n       DirectorySnapshottableFeature sf \u003d targetDir\n           .getDirectorySnapshottableFeature();\n       if (sf !\u003d null) {\n         if (sf.getNumSnapshots() \u003e 0) {\n           String fullPath \u003d targetDir.getFullPathName();\n           throw new SnapshotException(\"The directory \" + fullPath\n               + \" cannot be deleted since \" + fullPath\n               + \" is snapshottable and already has snapshots\");\n         } else {\n           if (snapshottableDirs !\u003d null) {\n             snapshottableDirs.add(targetDir);\n           }\n         }\n-      } \n+      }\n       for (INode child : targetDir.getChildrenList(Snapshot.CURRENT_STATE_ID)) {\n         checkSnapshot(child, snapshottableDirs);\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static void checkSnapshot(\n      INode target, List\u003cINodeDirectory\u003e snapshottableDirs)\n      throws SnapshotException {\n    if (target.isDirectory()) {\n      INodeDirectory targetDir \u003d target.asDirectory();\n      DirectorySnapshottableFeature sf \u003d targetDir\n          .getDirectorySnapshottableFeature();\n      if (sf !\u003d null) {\n        if (sf.getNumSnapshots() \u003e 0) {\n          String fullPath \u003d targetDir.getFullPathName();\n          throw new SnapshotException(\"The directory \" + fullPath\n              + \" cannot be deleted since \" + fullPath\n              + \" is snapshottable and already has snapshots\");\n        } else {\n          if (snapshottableDirs !\u003d null) {\n            snapshottableDirs.add(targetDir);\n          }\n        }\n      }\n      for (INode child : targetDir.getChildrenList(Snapshot.CURRENT_STATE_ID)) {\n        checkSnapshot(child, snapshottableDirs);\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirSnapshotOp.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirSnapshotOp.java",
            "oldMethodName": "checkSnapshot",
            "newMethodName": "checkSnapshot"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-7440. Consolidate snapshot related operations in a single class. Contributed by Haohui Mai.\n",
          "commitDate": "25/11/14 9:04 PM",
          "commitName": "4a3161182905afaf450a60d02528161ed1f97471",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "25/11/14 4:24 PM",
          "commitNameOld": "a655973e781caf662b360c96e0fa3f5a873cf676",
          "commitAuthorOld": "Karthik Kambatla",
          "daysBetweenCommits": 0.19,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,23 +1,24 @@\n-  private static void checkSnapshot(INode target,\n-      List\u003cINodeDirectory\u003e snapshottableDirs) throws SnapshotException {\n+  static void checkSnapshot(\n+      INode target, List\u003cINodeDirectory\u003e snapshottableDirs)\n+      throws SnapshotException {\n     if (target.isDirectory()) {\n       INodeDirectory targetDir \u003d target.asDirectory();\n       DirectorySnapshottableFeature sf \u003d targetDir\n           .getDirectorySnapshottableFeature();\n       if (sf !\u003d null) {\n         if (sf.getNumSnapshots() \u003e 0) {\n           String fullPath \u003d targetDir.getFullPathName();\n           throw new SnapshotException(\"The directory \" + fullPath\n               + \" cannot be deleted since \" + fullPath\n               + \" is snapshottable and already has snapshots\");\n         } else {\n           if (snapshottableDirs !\u003d null) {\n             snapshottableDirs.add(targetDir);\n           }\n         }\n-      } \n+      }\n       for (INode child : targetDir.getChildrenList(Snapshot.CURRENT_STATE_ID)) {\n         checkSnapshot(child, snapshottableDirs);\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static void checkSnapshot(\n      INode target, List\u003cINodeDirectory\u003e snapshottableDirs)\n      throws SnapshotException {\n    if (target.isDirectory()) {\n      INodeDirectory targetDir \u003d target.asDirectory();\n      DirectorySnapshottableFeature sf \u003d targetDir\n          .getDirectorySnapshottableFeature();\n      if (sf !\u003d null) {\n        if (sf.getNumSnapshots() \u003e 0) {\n          String fullPath \u003d targetDir.getFullPathName();\n          throw new SnapshotException(\"The directory \" + fullPath\n              + \" cannot be deleted since \" + fullPath\n              + \" is snapshottable and already has snapshots\");\n        } else {\n          if (snapshottableDirs !\u003d null) {\n            snapshottableDirs.add(targetDir);\n          }\n        }\n      }\n      for (INode child : targetDir.getChildrenList(Snapshot.CURRENT_STATE_ID)) {\n        checkSnapshot(child, snapshottableDirs);\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirSnapshotOp.java",
          "extendedDetails": {
            "oldValue": "[private, static]",
            "newValue": "[static]"
          }
        }
      ]
    }
  }
}