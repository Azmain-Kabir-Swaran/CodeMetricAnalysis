{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "SLSRunner.java",
  "functionName": "startAMFromSLSTrace",
  "functionId": "startAMFromSLSTrace___inputTrace-String",
  "sourceFilePath": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java",
  "functionStartLine": 458,
  "functionEndLine": 475,
  "numCommitsSeen": 51,
  "timeTaken": 3865,
  "changeHistory": [
    "3369540653a41dd0194b65f5ef1d53225fb97ba8",
    "475f933b41276b1bdeeec09e30369120f7eccdb8",
    "de69d6e81128470dd5d2fd865d4b3a79188f740b",
    "2cc841f16ec9aa5336495fc20ee781a1276fddc5",
    "819224dcf9c683aa52f58633ac8e13663f1916d8",
    "996a210ab0131606639ba87fd5daab14bf05b35f",
    "f384a063a653b33d69f7d2c7d4fd45c24b5aa46a",
    "58b08e11b9f04c9190ab4a07473f0ee04e01ec6b"
  ],
  "changeHistoryShort": {
    "3369540653a41dd0194b65f5ef1d53225fb97ba8": "Ybodychange",
    "475f933b41276b1bdeeec09e30369120f7eccdb8": "Ymultichange(Yrename,Yparameterchange,Ybodychange)",
    "de69d6e81128470dd5d2fd865d4b3a79188f740b": "Ybodychange",
    "2cc841f16ec9aa5336495fc20ee781a1276fddc5": "Ybodychange",
    "819224dcf9c683aa52f58633ac8e13663f1916d8": "Ybodychange",
    "996a210ab0131606639ba87fd5daab14bf05b35f": "Ybodychange",
    "f384a063a653b33d69f7d2c7d4fd45c24b5aa46a": "Ybodychange",
    "58b08e11b9f04c9190ab4a07473f0ee04e01ec6b": "Yintroduced"
  },
  "changeHistoryDetails": {
    "3369540653a41dd0194b65f5ef1d53225fb97ba8": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-14296. Move logging APIs over to slf4j in hadoop-tools.\n",
      "commitDate": "19/06/17 9:18 PM",
      "commitName": "3369540653a41dd0194b65f5ef1d53225fb97ba8",
      "commitAuthor": "Akira Ajisaka",
      "commitDateOld": "06/06/17 5:19 PM",
      "commitNameOld": "b65100c14bf9134de2bd8248dc62735682bee26c",
      "commitAuthorOld": "Carlo Curino",
      "daysBetweenCommits": 13.17,
      "commitsBetweenForRepo": 53,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,18 +1,18 @@\n   private void startAMFromSLSTrace(String inputTrace) throws IOException {\n     JsonFactory jsonF \u003d new JsonFactory();\n     ObjectMapper mapper \u003d new ObjectMapper();\n \n     try (Reader input \u003d new InputStreamReader(\n         new FileInputStream(inputTrace), \"UTF-8\")) {\n       Iterator\u003cMap\u003e jobIter \u003d mapper.readValues(\n           jsonF.createParser(input), Map.class);\n \n       while (jobIter.hasNext()) {\n         try {\n           createAMForJob(jobIter.next());\n         } catch (Exception e) {\n-          LOG.error(\"Failed to create an AM: \" + e.getMessage());\n+          LOG.error(\"Failed to create an AM: {}\", e.getMessage());\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void startAMFromSLSTrace(String inputTrace) throws IOException {\n    JsonFactory jsonF \u003d new JsonFactory();\n    ObjectMapper mapper \u003d new ObjectMapper();\n\n    try (Reader input \u003d new InputStreamReader(\n        new FileInputStream(inputTrace), \"UTF-8\")) {\n      Iterator\u003cMap\u003e jobIter \u003d mapper.readValues(\n          jsonF.createParser(input), Map.class);\n\n      while (jobIter.hasNext()) {\n        try {\n          createAMForJob(jobIter.next());\n        } catch (Exception e) {\n          LOG.error(\"Failed to create an AM: {}\", e.getMessage());\n        }\n      }\n    }\n  }",
      "path": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java",
      "extendedDetails": {}
    },
    "475f933b41276b1bdeeec09e30369120f7eccdb8": {
      "type": "Ymultichange(Yrename,Yparameterchange,Ybodychange)",
      "commitMessage": "YARN-6423. Queue metrics doesn\u0027t work for Fair Scheduler in SLS (yufeigu via rkanter)\n",
      "commitDate": "25/04/17 4:26 PM",
      "commitName": "475f933b41276b1bdeeec09e30369120f7eccdb8",
      "commitAuthor": "Robert Kanter",
      "subchanges": [
        {
          "type": "Yrename",
          "commitMessage": "YARN-6423. Queue metrics doesn\u0027t work for Fair Scheduler in SLS (yufeigu via rkanter)\n",
          "commitDate": "25/04/17 4:26 PM",
          "commitName": "475f933b41276b1bdeeec09e30369120f7eccdb8",
          "commitAuthor": "Robert Kanter",
          "commitDateOld": "20/04/17 9:54 PM",
          "commitNameOld": "de69d6e81128470dd5d2fd865d4b3a79188f740b",
          "commitAuthorOld": "Wangda Tan",
          "daysBetweenCommits": 4.77,
          "commitsBetweenForRepo": 13,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,88 +1,18 @@\n-  private void startAMFromSLSTraces(Resource containerResource,\n-      int heartbeatInterval) throws IOException {\n-    // parse from sls traces\n+  private void startAMFromSLSTrace(String inputTrace) throws IOException {\n     JsonFactory jsonF \u003d new JsonFactory();\n     ObjectMapper mapper \u003d new ObjectMapper();\n-    for (String inputTrace : inputTraces) {\n-      Reader input \u003d\n-          new InputStreamReader(new FileInputStream(inputTrace), \"UTF-8\");\n-      try {\n-        Iterator\u003cMap\u003e i \u003d\n-            mapper.readValues(jsonF.createParser(input), Map.class);\n-        while (i.hasNext()) {\n-          Map jsonJob \u003d i.next();\n \n-          // load job information\n-          long jobStartTime \u003d\n-              Long.parseLong(jsonJob.get(\"job.start.ms\").toString());\n-          long jobFinishTime \u003d\n-              Long.parseLong(jsonJob.get(\"job.end.ms\").toString());\n+    try (Reader input \u003d new InputStreamReader(\n+        new FileInputStream(inputTrace), \"UTF-8\")) {\n+      Iterator\u003cMap\u003e jobIter \u003d mapper.readValues(\n+          jsonF.createParser(input), Map.class);\n \n-          String user \u003d (String) jsonJob.get(\"job.user\");\n-          if (user \u003d\u003d null) {\n-            user \u003d \"default\";\n-          }\n-          String queue \u003d jsonJob.get(\"job.queue.name\").toString();\n-\n-          String oldAppId \u003d jsonJob.get(\"job.id\").toString();\n-          boolean isTracked \u003d trackedApps.contains(oldAppId);\n-          int queueSize \u003d\n-              queueAppNumMap.containsKey(queue) ? queueAppNumMap.get(queue) : 0;\n-          queueSize++;\n-          queueAppNumMap.put(queue, queueSize);\n-          // tasks\n-          List tasks \u003d (List) jsonJob.get(\"job.tasks\");\n-          if (tasks \u003d\u003d null || tasks.size() \u003d\u003d 0) {\n-            continue;\n-          }\n-          List\u003cContainerSimulator\u003e containerList \u003d\n-              new ArrayList\u003cContainerSimulator\u003e();\n-          for (Object o : tasks) {\n-            Map jsonTask \u003d (Map) o;\n-            String hostname \u003d jsonTask.get(\"container.host\").toString();\n-            long taskStart \u003d\n-                Long.parseLong(jsonTask.get(\"container.start.ms\").toString());\n-            long taskFinish \u003d\n-                Long.parseLong(jsonTask.get(\"container.end.ms\").toString());\n-            long lifeTime \u003d taskFinish - taskStart;\n-\n-            // Set memory and vcores from job trace file\n-            Resource res \u003d Resources.clone(containerResource);\n-            if (jsonTask.containsKey(\"container.memory\")) {\n-              int containerMemory \u003d\n-                  Integer.parseInt(jsonTask.get(\"container.memory\").toString());\n-              res.setMemorySize(containerMemory);\n-            }\n-\n-            if (jsonTask.containsKey(\"container.vcores\")) {\n-              int containerVCores \u003d\n-                  Integer.parseInt(jsonTask.get(\"container.vcores\").toString());\n-              res.setVirtualCores(containerVCores);\n-            }\n-\n-            int priority \u003d\n-                Integer.parseInt(jsonTask.get(\"container.priority\").toString());\n-            String type \u003d jsonTask.get(\"container.type\").toString();\n-            containerList.add(new ContainerSimulator(res, lifeTime, hostname,\n-                priority, type));\n-          }\n-\n-          // create a new AM\n-          String amType \u003d jsonJob.get(\"am.type\").toString();\n-          AMSimulator amSim \u003d (AMSimulator) ReflectionUtils\n-              .newInstance(amClassMap.get(amType), new Configuration());\n-          if (amSim !\u003d null) {\n-            amSim.init(AM_ID++, heartbeatInterval, containerList, rm, this,\n-                jobStartTime, jobFinishTime, user, queue, isTracked, oldAppId,\n-                null, runner.getStartTimeMS());\n-            runner.schedule(amSim);\n-            maxRuntime \u003d Math.max(maxRuntime, jobFinishTime);\n-            numTasks +\u003d containerList.size();\n-            amMap.put(oldAppId, amSim);\n-          }\n+      while (jobIter.hasNext()) {\n+        try {\n+          createAMForJob(jobIter.next());\n+        } catch (Exception e) {\n+          LOG.error(\"Failed to create an AM: \" + e.getMessage());\n         }\n-      } finally {\n-        input.close();\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void startAMFromSLSTrace(String inputTrace) throws IOException {\n    JsonFactory jsonF \u003d new JsonFactory();\n    ObjectMapper mapper \u003d new ObjectMapper();\n\n    try (Reader input \u003d new InputStreamReader(\n        new FileInputStream(inputTrace), \"UTF-8\")) {\n      Iterator\u003cMap\u003e jobIter \u003d mapper.readValues(\n          jsonF.createParser(input), Map.class);\n\n      while (jobIter.hasNext()) {\n        try {\n          createAMForJob(jobIter.next());\n        } catch (Exception e) {\n          LOG.error(\"Failed to create an AM: \" + e.getMessage());\n        }\n      }\n    }\n  }",
          "path": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java",
          "extendedDetails": {
            "oldValue": "startAMFromSLSTraces",
            "newValue": "startAMFromSLSTrace"
          }
        },
        {
          "type": "Yparameterchange",
          "commitMessage": "YARN-6423. Queue metrics doesn\u0027t work for Fair Scheduler in SLS (yufeigu via rkanter)\n",
          "commitDate": "25/04/17 4:26 PM",
          "commitName": "475f933b41276b1bdeeec09e30369120f7eccdb8",
          "commitAuthor": "Robert Kanter",
          "commitDateOld": "20/04/17 9:54 PM",
          "commitNameOld": "de69d6e81128470dd5d2fd865d4b3a79188f740b",
          "commitAuthorOld": "Wangda Tan",
          "daysBetweenCommits": 4.77,
          "commitsBetweenForRepo": 13,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,88 +1,18 @@\n-  private void startAMFromSLSTraces(Resource containerResource,\n-      int heartbeatInterval) throws IOException {\n-    // parse from sls traces\n+  private void startAMFromSLSTrace(String inputTrace) throws IOException {\n     JsonFactory jsonF \u003d new JsonFactory();\n     ObjectMapper mapper \u003d new ObjectMapper();\n-    for (String inputTrace : inputTraces) {\n-      Reader input \u003d\n-          new InputStreamReader(new FileInputStream(inputTrace), \"UTF-8\");\n-      try {\n-        Iterator\u003cMap\u003e i \u003d\n-            mapper.readValues(jsonF.createParser(input), Map.class);\n-        while (i.hasNext()) {\n-          Map jsonJob \u003d i.next();\n \n-          // load job information\n-          long jobStartTime \u003d\n-              Long.parseLong(jsonJob.get(\"job.start.ms\").toString());\n-          long jobFinishTime \u003d\n-              Long.parseLong(jsonJob.get(\"job.end.ms\").toString());\n+    try (Reader input \u003d new InputStreamReader(\n+        new FileInputStream(inputTrace), \"UTF-8\")) {\n+      Iterator\u003cMap\u003e jobIter \u003d mapper.readValues(\n+          jsonF.createParser(input), Map.class);\n \n-          String user \u003d (String) jsonJob.get(\"job.user\");\n-          if (user \u003d\u003d null) {\n-            user \u003d \"default\";\n-          }\n-          String queue \u003d jsonJob.get(\"job.queue.name\").toString();\n-\n-          String oldAppId \u003d jsonJob.get(\"job.id\").toString();\n-          boolean isTracked \u003d trackedApps.contains(oldAppId);\n-          int queueSize \u003d\n-              queueAppNumMap.containsKey(queue) ? queueAppNumMap.get(queue) : 0;\n-          queueSize++;\n-          queueAppNumMap.put(queue, queueSize);\n-          // tasks\n-          List tasks \u003d (List) jsonJob.get(\"job.tasks\");\n-          if (tasks \u003d\u003d null || tasks.size() \u003d\u003d 0) {\n-            continue;\n-          }\n-          List\u003cContainerSimulator\u003e containerList \u003d\n-              new ArrayList\u003cContainerSimulator\u003e();\n-          for (Object o : tasks) {\n-            Map jsonTask \u003d (Map) o;\n-            String hostname \u003d jsonTask.get(\"container.host\").toString();\n-            long taskStart \u003d\n-                Long.parseLong(jsonTask.get(\"container.start.ms\").toString());\n-            long taskFinish \u003d\n-                Long.parseLong(jsonTask.get(\"container.end.ms\").toString());\n-            long lifeTime \u003d taskFinish - taskStart;\n-\n-            // Set memory and vcores from job trace file\n-            Resource res \u003d Resources.clone(containerResource);\n-            if (jsonTask.containsKey(\"container.memory\")) {\n-              int containerMemory \u003d\n-                  Integer.parseInt(jsonTask.get(\"container.memory\").toString());\n-              res.setMemorySize(containerMemory);\n-            }\n-\n-            if (jsonTask.containsKey(\"container.vcores\")) {\n-              int containerVCores \u003d\n-                  Integer.parseInt(jsonTask.get(\"container.vcores\").toString());\n-              res.setVirtualCores(containerVCores);\n-            }\n-\n-            int priority \u003d\n-                Integer.parseInt(jsonTask.get(\"container.priority\").toString());\n-            String type \u003d jsonTask.get(\"container.type\").toString();\n-            containerList.add(new ContainerSimulator(res, lifeTime, hostname,\n-                priority, type));\n-          }\n-\n-          // create a new AM\n-          String amType \u003d jsonJob.get(\"am.type\").toString();\n-          AMSimulator amSim \u003d (AMSimulator) ReflectionUtils\n-              .newInstance(amClassMap.get(amType), new Configuration());\n-          if (amSim !\u003d null) {\n-            amSim.init(AM_ID++, heartbeatInterval, containerList, rm, this,\n-                jobStartTime, jobFinishTime, user, queue, isTracked, oldAppId,\n-                null, runner.getStartTimeMS());\n-            runner.schedule(amSim);\n-            maxRuntime \u003d Math.max(maxRuntime, jobFinishTime);\n-            numTasks +\u003d containerList.size();\n-            amMap.put(oldAppId, amSim);\n-          }\n+      while (jobIter.hasNext()) {\n+        try {\n+          createAMForJob(jobIter.next());\n+        } catch (Exception e) {\n+          LOG.error(\"Failed to create an AM: \" + e.getMessage());\n         }\n-      } finally {\n-        input.close();\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void startAMFromSLSTrace(String inputTrace) throws IOException {\n    JsonFactory jsonF \u003d new JsonFactory();\n    ObjectMapper mapper \u003d new ObjectMapper();\n\n    try (Reader input \u003d new InputStreamReader(\n        new FileInputStream(inputTrace), \"UTF-8\")) {\n      Iterator\u003cMap\u003e jobIter \u003d mapper.readValues(\n          jsonF.createParser(input), Map.class);\n\n      while (jobIter.hasNext()) {\n        try {\n          createAMForJob(jobIter.next());\n        } catch (Exception e) {\n          LOG.error(\"Failed to create an AM: \" + e.getMessage());\n        }\n      }\n    }\n  }",
          "path": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java",
          "extendedDetails": {
            "oldValue": "[containerResource-Resource, heartbeatInterval-int]",
            "newValue": "[inputTrace-String]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-6423. Queue metrics doesn\u0027t work for Fair Scheduler in SLS (yufeigu via rkanter)\n",
          "commitDate": "25/04/17 4:26 PM",
          "commitName": "475f933b41276b1bdeeec09e30369120f7eccdb8",
          "commitAuthor": "Robert Kanter",
          "commitDateOld": "20/04/17 9:54 PM",
          "commitNameOld": "de69d6e81128470dd5d2fd865d4b3a79188f740b",
          "commitAuthorOld": "Wangda Tan",
          "daysBetweenCommits": 4.77,
          "commitsBetweenForRepo": 13,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,88 +1,18 @@\n-  private void startAMFromSLSTraces(Resource containerResource,\n-      int heartbeatInterval) throws IOException {\n-    // parse from sls traces\n+  private void startAMFromSLSTrace(String inputTrace) throws IOException {\n     JsonFactory jsonF \u003d new JsonFactory();\n     ObjectMapper mapper \u003d new ObjectMapper();\n-    for (String inputTrace : inputTraces) {\n-      Reader input \u003d\n-          new InputStreamReader(new FileInputStream(inputTrace), \"UTF-8\");\n-      try {\n-        Iterator\u003cMap\u003e i \u003d\n-            mapper.readValues(jsonF.createParser(input), Map.class);\n-        while (i.hasNext()) {\n-          Map jsonJob \u003d i.next();\n \n-          // load job information\n-          long jobStartTime \u003d\n-              Long.parseLong(jsonJob.get(\"job.start.ms\").toString());\n-          long jobFinishTime \u003d\n-              Long.parseLong(jsonJob.get(\"job.end.ms\").toString());\n+    try (Reader input \u003d new InputStreamReader(\n+        new FileInputStream(inputTrace), \"UTF-8\")) {\n+      Iterator\u003cMap\u003e jobIter \u003d mapper.readValues(\n+          jsonF.createParser(input), Map.class);\n \n-          String user \u003d (String) jsonJob.get(\"job.user\");\n-          if (user \u003d\u003d null) {\n-            user \u003d \"default\";\n-          }\n-          String queue \u003d jsonJob.get(\"job.queue.name\").toString();\n-\n-          String oldAppId \u003d jsonJob.get(\"job.id\").toString();\n-          boolean isTracked \u003d trackedApps.contains(oldAppId);\n-          int queueSize \u003d\n-              queueAppNumMap.containsKey(queue) ? queueAppNumMap.get(queue) : 0;\n-          queueSize++;\n-          queueAppNumMap.put(queue, queueSize);\n-          // tasks\n-          List tasks \u003d (List) jsonJob.get(\"job.tasks\");\n-          if (tasks \u003d\u003d null || tasks.size() \u003d\u003d 0) {\n-            continue;\n-          }\n-          List\u003cContainerSimulator\u003e containerList \u003d\n-              new ArrayList\u003cContainerSimulator\u003e();\n-          for (Object o : tasks) {\n-            Map jsonTask \u003d (Map) o;\n-            String hostname \u003d jsonTask.get(\"container.host\").toString();\n-            long taskStart \u003d\n-                Long.parseLong(jsonTask.get(\"container.start.ms\").toString());\n-            long taskFinish \u003d\n-                Long.parseLong(jsonTask.get(\"container.end.ms\").toString());\n-            long lifeTime \u003d taskFinish - taskStart;\n-\n-            // Set memory and vcores from job trace file\n-            Resource res \u003d Resources.clone(containerResource);\n-            if (jsonTask.containsKey(\"container.memory\")) {\n-              int containerMemory \u003d\n-                  Integer.parseInt(jsonTask.get(\"container.memory\").toString());\n-              res.setMemorySize(containerMemory);\n-            }\n-\n-            if (jsonTask.containsKey(\"container.vcores\")) {\n-              int containerVCores \u003d\n-                  Integer.parseInt(jsonTask.get(\"container.vcores\").toString());\n-              res.setVirtualCores(containerVCores);\n-            }\n-\n-            int priority \u003d\n-                Integer.parseInt(jsonTask.get(\"container.priority\").toString());\n-            String type \u003d jsonTask.get(\"container.type\").toString();\n-            containerList.add(new ContainerSimulator(res, lifeTime, hostname,\n-                priority, type));\n-          }\n-\n-          // create a new AM\n-          String amType \u003d jsonJob.get(\"am.type\").toString();\n-          AMSimulator amSim \u003d (AMSimulator) ReflectionUtils\n-              .newInstance(amClassMap.get(amType), new Configuration());\n-          if (amSim !\u003d null) {\n-            amSim.init(AM_ID++, heartbeatInterval, containerList, rm, this,\n-                jobStartTime, jobFinishTime, user, queue, isTracked, oldAppId,\n-                null, runner.getStartTimeMS());\n-            runner.schedule(amSim);\n-            maxRuntime \u003d Math.max(maxRuntime, jobFinishTime);\n-            numTasks +\u003d containerList.size();\n-            amMap.put(oldAppId, amSim);\n-          }\n+      while (jobIter.hasNext()) {\n+        try {\n+          createAMForJob(jobIter.next());\n+        } catch (Exception e) {\n+          LOG.error(\"Failed to create an AM: \" + e.getMessage());\n         }\n-      } finally {\n-        input.close();\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void startAMFromSLSTrace(String inputTrace) throws IOException {\n    JsonFactory jsonF \u003d new JsonFactory();\n    ObjectMapper mapper \u003d new ObjectMapper();\n\n    try (Reader input \u003d new InputStreamReader(\n        new FileInputStream(inputTrace), \"UTF-8\")) {\n      Iterator\u003cMap\u003e jobIter \u003d mapper.readValues(\n          jsonF.createParser(input), Map.class);\n\n      while (jobIter.hasNext()) {\n        try {\n          createAMForJob(jobIter.next());\n        } catch (Exception e) {\n          LOG.error(\"Failed to create an AM: \" + e.getMessage());\n        }\n      }\n    }\n  }",
          "path": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java",
          "extendedDetails": {}
        }
      ]
    },
    "de69d6e81128470dd5d2fd865d4b3a79188f740b": {
      "type": "Ybodychange",
      "commitMessage": "YARN-6363. Extending SLS: Synthetic Load Generator. (Carlo Curino via wangda)\n",
      "commitDate": "20/04/17 9:54 PM",
      "commitName": "de69d6e81128470dd5d2fd865d4b3a79188f740b",
      "commitAuthor": "Wangda Tan",
      "commitDateOld": "29/03/17 4:18 PM",
      "commitNameOld": "6a5516c2381f107d96b8326939514de3c6e53d3d",
      "commitAuthorOld": "Robert Kanter",
      "daysBetweenCommits": 22.23,
      "commitsBetweenForRepo": 128,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,86 +1,88 @@\n   private void startAMFromSLSTraces(Resource containerResource,\n-                                    int heartbeatInterval) throws IOException {\n+      int heartbeatInterval) throws IOException {\n     // parse from sls traces\n     JsonFactory jsonF \u003d new JsonFactory();\n     ObjectMapper mapper \u003d new ObjectMapper();\n     for (String inputTrace : inputTraces) {\n       Reader input \u003d\n           new InputStreamReader(new FileInputStream(inputTrace), \"UTF-8\");\n       try {\n-        Iterator\u003cMap\u003e i \u003d mapper.readValues(jsonF.createParser(input),\n-                Map.class);\n+        Iterator\u003cMap\u003e i \u003d\n+            mapper.readValues(jsonF.createParser(input), Map.class);\n         while (i.hasNext()) {\n           Map jsonJob \u003d i.next();\n \n           // load job information\n-          long jobStartTime \u003d Long.parseLong(\n-                  jsonJob.get(\"job.start.ms\").toString());\n-          long jobFinishTime \u003d Long.parseLong(\n-                  jsonJob.get(\"job.end.ms\").toString());\n+          long jobStartTime \u003d\n+              Long.parseLong(jsonJob.get(\"job.start.ms\").toString());\n+          long jobFinishTime \u003d\n+              Long.parseLong(jsonJob.get(\"job.end.ms\").toString());\n \n           String user \u003d (String) jsonJob.get(\"job.user\");\n-          if (user \u003d\u003d null)  user \u003d \"default\";\n+          if (user \u003d\u003d null) {\n+            user \u003d \"default\";\n+          }\n           String queue \u003d jsonJob.get(\"job.queue.name\").toString();\n \n           String oldAppId \u003d jsonJob.get(\"job.id\").toString();\n           boolean isTracked \u003d trackedApps.contains(oldAppId);\n-          int queueSize \u003d queueAppNumMap.containsKey(queue) ?\n-                  queueAppNumMap.get(queue) : 0;\n-          queueSize ++;\n+          int queueSize \u003d\n+              queueAppNumMap.containsKey(queue) ? queueAppNumMap.get(queue) : 0;\n+          queueSize++;\n           queueAppNumMap.put(queue, queueSize);\n           // tasks\n           List tasks \u003d (List) jsonJob.get(\"job.tasks\");\n           if (tasks \u003d\u003d null || tasks.size() \u003d\u003d 0) {\n             continue;\n           }\n           List\u003cContainerSimulator\u003e containerList \u003d\n-                  new ArrayList\u003cContainerSimulator\u003e();\n+              new ArrayList\u003cContainerSimulator\u003e();\n           for (Object o : tasks) {\n             Map jsonTask \u003d (Map) o;\n             String hostname \u003d jsonTask.get(\"container.host\").toString();\n-            long taskStart \u003d Long.parseLong(\n-                    jsonTask.get(\"container.start.ms\").toString());\n-            long taskFinish \u003d Long.parseLong(\n-                    jsonTask.get(\"container.end.ms\").toString());\n+            long taskStart \u003d\n+                Long.parseLong(jsonTask.get(\"container.start.ms\").toString());\n+            long taskFinish \u003d\n+                Long.parseLong(jsonTask.get(\"container.end.ms\").toString());\n             long lifeTime \u003d taskFinish - taskStart;\n \n             // Set memory and vcores from job trace file\n             Resource res \u003d Resources.clone(containerResource);\n             if (jsonTask.containsKey(\"container.memory\")) {\n-              int containerMemory \u003d Integer.parseInt(\n-                  jsonTask.get(\"container.memory\").toString());\n+              int containerMemory \u003d\n+                  Integer.parseInt(jsonTask.get(\"container.memory\").toString());\n               res.setMemorySize(containerMemory);\n             }\n \n             if (jsonTask.containsKey(\"container.vcores\")) {\n-              int containerVCores \u003d Integer.parseInt(\n-                  jsonTask.get(\"container.vcores\").toString());\n+              int containerVCores \u003d\n+                  Integer.parseInt(jsonTask.get(\"container.vcores\").toString());\n               res.setVirtualCores(containerVCores);\n             }\n \n-            int priority \u003d Integer.parseInt(\n-                    jsonTask.get(\"container.priority\").toString());\n+            int priority \u003d\n+                Integer.parseInt(jsonTask.get(\"container.priority\").toString());\n             String type \u003d jsonTask.get(\"container.type\").toString();\n-            containerList.add(new ContainerSimulator(res,\n-                    lifeTime, hostname, priority, type));\n+            containerList.add(new ContainerSimulator(res, lifeTime, hostname,\n+                priority, type));\n           }\n \n           // create a new AM\n           String amType \u003d jsonJob.get(\"am.type\").toString();\n-          AMSimulator amSim \u003d (AMSimulator) ReflectionUtils.newInstance(\n-                  amClassMap.get(amType), new Configuration());\n+          AMSimulator amSim \u003d (AMSimulator) ReflectionUtils\n+              .newInstance(amClassMap.get(amType), new Configuration());\n           if (amSim !\u003d null) {\n-            amSim.init(AM_ID++, heartbeatInterval, containerList, rm,\n-                    this, jobStartTime, jobFinishTime, user, queue,\n-                    isTracked, oldAppId);\n+            amSim.init(AM_ID++, heartbeatInterval, containerList, rm, this,\n+                jobStartTime, jobFinishTime, user, queue, isTracked, oldAppId,\n+                null, runner.getStartTimeMS());\n             runner.schedule(amSim);\n             maxRuntime \u003d Math.max(maxRuntime, jobFinishTime);\n             numTasks +\u003d containerList.size();\n             amMap.put(oldAppId, amSim);\n           }\n         }\n       } finally {\n         input.close();\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void startAMFromSLSTraces(Resource containerResource,\n      int heartbeatInterval) throws IOException {\n    // parse from sls traces\n    JsonFactory jsonF \u003d new JsonFactory();\n    ObjectMapper mapper \u003d new ObjectMapper();\n    for (String inputTrace : inputTraces) {\n      Reader input \u003d\n          new InputStreamReader(new FileInputStream(inputTrace), \"UTF-8\");\n      try {\n        Iterator\u003cMap\u003e i \u003d\n            mapper.readValues(jsonF.createParser(input), Map.class);\n        while (i.hasNext()) {\n          Map jsonJob \u003d i.next();\n\n          // load job information\n          long jobStartTime \u003d\n              Long.parseLong(jsonJob.get(\"job.start.ms\").toString());\n          long jobFinishTime \u003d\n              Long.parseLong(jsonJob.get(\"job.end.ms\").toString());\n\n          String user \u003d (String) jsonJob.get(\"job.user\");\n          if (user \u003d\u003d null) {\n            user \u003d \"default\";\n          }\n          String queue \u003d jsonJob.get(\"job.queue.name\").toString();\n\n          String oldAppId \u003d jsonJob.get(\"job.id\").toString();\n          boolean isTracked \u003d trackedApps.contains(oldAppId);\n          int queueSize \u003d\n              queueAppNumMap.containsKey(queue) ? queueAppNumMap.get(queue) : 0;\n          queueSize++;\n          queueAppNumMap.put(queue, queueSize);\n          // tasks\n          List tasks \u003d (List) jsonJob.get(\"job.tasks\");\n          if (tasks \u003d\u003d null || tasks.size() \u003d\u003d 0) {\n            continue;\n          }\n          List\u003cContainerSimulator\u003e containerList \u003d\n              new ArrayList\u003cContainerSimulator\u003e();\n          for (Object o : tasks) {\n            Map jsonTask \u003d (Map) o;\n            String hostname \u003d jsonTask.get(\"container.host\").toString();\n            long taskStart \u003d\n                Long.parseLong(jsonTask.get(\"container.start.ms\").toString());\n            long taskFinish \u003d\n                Long.parseLong(jsonTask.get(\"container.end.ms\").toString());\n            long lifeTime \u003d taskFinish - taskStart;\n\n            // Set memory and vcores from job trace file\n            Resource res \u003d Resources.clone(containerResource);\n            if (jsonTask.containsKey(\"container.memory\")) {\n              int containerMemory \u003d\n                  Integer.parseInt(jsonTask.get(\"container.memory\").toString());\n              res.setMemorySize(containerMemory);\n            }\n\n            if (jsonTask.containsKey(\"container.vcores\")) {\n              int containerVCores \u003d\n                  Integer.parseInt(jsonTask.get(\"container.vcores\").toString());\n              res.setVirtualCores(containerVCores);\n            }\n\n            int priority \u003d\n                Integer.parseInt(jsonTask.get(\"container.priority\").toString());\n            String type \u003d jsonTask.get(\"container.type\").toString();\n            containerList.add(new ContainerSimulator(res, lifeTime, hostname,\n                priority, type));\n          }\n\n          // create a new AM\n          String amType \u003d jsonJob.get(\"am.type\").toString();\n          AMSimulator amSim \u003d (AMSimulator) ReflectionUtils\n              .newInstance(amClassMap.get(amType), new Configuration());\n          if (amSim !\u003d null) {\n            amSim.init(AM_ID++, heartbeatInterval, containerList, rm, this,\n                jobStartTime, jobFinishTime, user, queue, isTracked, oldAppId,\n                null, runner.getStartTimeMS());\n            runner.schedule(amSim);\n            maxRuntime \u003d Math.max(maxRuntime, jobFinishTime);\n            numTasks +\u003d containerList.size();\n            amMap.put(oldAppId, amSim);\n          }\n        }\n      } finally {\n        input.close();\n      }\n    }\n  }",
      "path": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java",
      "extendedDetails": {}
    },
    "2cc841f16ec9aa5336495fc20ee781a1276fddc5": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-13678 Update jackson from 1.9.13 to 2.x in hadoop-tools. Contributed by Akira Ajisaka.\n",
      "commitDate": "06/10/16 8:31 AM",
      "commitName": "2cc841f16ec9aa5336495fc20ee781a1276fddc5",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "11/07/16 10:36 PM",
      "commitNameOld": "819224dcf9c683aa52f58633ac8e13663f1916d8",
      "commitAuthorOld": "Jian He",
      "daysBetweenCommits": 86.41,
      "commitsBetweenForRepo": 563,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,86 +1,86 @@\n   private void startAMFromSLSTraces(Resource containerResource,\n                                     int heartbeatInterval) throws IOException {\n     // parse from sls traces\n     JsonFactory jsonF \u003d new JsonFactory();\n     ObjectMapper mapper \u003d new ObjectMapper();\n     for (String inputTrace : inputTraces) {\n       Reader input \u003d\n           new InputStreamReader(new FileInputStream(inputTrace), \"UTF-8\");\n       try {\n-        Iterator\u003cMap\u003e i \u003d mapper.readValues(jsonF.createJsonParser(input),\n+        Iterator\u003cMap\u003e i \u003d mapper.readValues(jsonF.createParser(input),\n                 Map.class);\n         while (i.hasNext()) {\n           Map jsonJob \u003d i.next();\n \n           // load job information\n           long jobStartTime \u003d Long.parseLong(\n                   jsonJob.get(\"job.start.ms\").toString());\n           long jobFinishTime \u003d Long.parseLong(\n                   jsonJob.get(\"job.end.ms\").toString());\n \n           String user \u003d (String) jsonJob.get(\"job.user\");\n           if (user \u003d\u003d null)  user \u003d \"default\";\n           String queue \u003d jsonJob.get(\"job.queue.name\").toString();\n \n           String oldAppId \u003d jsonJob.get(\"job.id\").toString();\n           boolean isTracked \u003d trackedApps.contains(oldAppId);\n           int queueSize \u003d queueAppNumMap.containsKey(queue) ?\n                   queueAppNumMap.get(queue) : 0;\n           queueSize ++;\n           queueAppNumMap.put(queue, queueSize);\n           // tasks\n           List tasks \u003d (List) jsonJob.get(\"job.tasks\");\n           if (tasks \u003d\u003d null || tasks.size() \u003d\u003d 0) {\n             continue;\n           }\n           List\u003cContainerSimulator\u003e containerList \u003d\n                   new ArrayList\u003cContainerSimulator\u003e();\n           for (Object o : tasks) {\n             Map jsonTask \u003d (Map) o;\n             String hostname \u003d jsonTask.get(\"container.host\").toString();\n             long taskStart \u003d Long.parseLong(\n                     jsonTask.get(\"container.start.ms\").toString());\n             long taskFinish \u003d Long.parseLong(\n                     jsonTask.get(\"container.end.ms\").toString());\n             long lifeTime \u003d taskFinish - taskStart;\n \n             // Set memory and vcores from job trace file\n             Resource res \u003d Resources.clone(containerResource);\n             if (jsonTask.containsKey(\"container.memory\")) {\n               int containerMemory \u003d Integer.parseInt(\n                   jsonTask.get(\"container.memory\").toString());\n               res.setMemorySize(containerMemory);\n             }\n \n             if (jsonTask.containsKey(\"container.vcores\")) {\n               int containerVCores \u003d Integer.parseInt(\n                   jsonTask.get(\"container.vcores\").toString());\n               res.setVirtualCores(containerVCores);\n             }\n \n             int priority \u003d Integer.parseInt(\n                     jsonTask.get(\"container.priority\").toString());\n             String type \u003d jsonTask.get(\"container.type\").toString();\n             containerList.add(new ContainerSimulator(res,\n                     lifeTime, hostname, priority, type));\n           }\n \n           // create a new AM\n           String amType \u003d jsonJob.get(\"am.type\").toString();\n           AMSimulator amSim \u003d (AMSimulator) ReflectionUtils.newInstance(\n                   amClassMap.get(amType), new Configuration());\n           if (amSim !\u003d null) {\n             amSim.init(AM_ID++, heartbeatInterval, containerList, rm,\n                     this, jobStartTime, jobFinishTime, user, queue,\n                     isTracked, oldAppId);\n             runner.schedule(amSim);\n             maxRuntime \u003d Math.max(maxRuntime, jobFinishTime);\n             numTasks +\u003d containerList.size();\n             amMap.put(oldAppId, amSim);\n           }\n         }\n       } finally {\n         input.close();\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void startAMFromSLSTraces(Resource containerResource,\n                                    int heartbeatInterval) throws IOException {\n    // parse from sls traces\n    JsonFactory jsonF \u003d new JsonFactory();\n    ObjectMapper mapper \u003d new ObjectMapper();\n    for (String inputTrace : inputTraces) {\n      Reader input \u003d\n          new InputStreamReader(new FileInputStream(inputTrace), \"UTF-8\");\n      try {\n        Iterator\u003cMap\u003e i \u003d mapper.readValues(jsonF.createParser(input),\n                Map.class);\n        while (i.hasNext()) {\n          Map jsonJob \u003d i.next();\n\n          // load job information\n          long jobStartTime \u003d Long.parseLong(\n                  jsonJob.get(\"job.start.ms\").toString());\n          long jobFinishTime \u003d Long.parseLong(\n                  jsonJob.get(\"job.end.ms\").toString());\n\n          String user \u003d (String) jsonJob.get(\"job.user\");\n          if (user \u003d\u003d null)  user \u003d \"default\";\n          String queue \u003d jsonJob.get(\"job.queue.name\").toString();\n\n          String oldAppId \u003d jsonJob.get(\"job.id\").toString();\n          boolean isTracked \u003d trackedApps.contains(oldAppId);\n          int queueSize \u003d queueAppNumMap.containsKey(queue) ?\n                  queueAppNumMap.get(queue) : 0;\n          queueSize ++;\n          queueAppNumMap.put(queue, queueSize);\n          // tasks\n          List tasks \u003d (List) jsonJob.get(\"job.tasks\");\n          if (tasks \u003d\u003d null || tasks.size() \u003d\u003d 0) {\n            continue;\n          }\n          List\u003cContainerSimulator\u003e containerList \u003d\n                  new ArrayList\u003cContainerSimulator\u003e();\n          for (Object o : tasks) {\n            Map jsonTask \u003d (Map) o;\n            String hostname \u003d jsonTask.get(\"container.host\").toString();\n            long taskStart \u003d Long.parseLong(\n                    jsonTask.get(\"container.start.ms\").toString());\n            long taskFinish \u003d Long.parseLong(\n                    jsonTask.get(\"container.end.ms\").toString());\n            long lifeTime \u003d taskFinish - taskStart;\n\n            // Set memory and vcores from job trace file\n            Resource res \u003d Resources.clone(containerResource);\n            if (jsonTask.containsKey(\"container.memory\")) {\n              int containerMemory \u003d Integer.parseInt(\n                  jsonTask.get(\"container.memory\").toString());\n              res.setMemorySize(containerMemory);\n            }\n\n            if (jsonTask.containsKey(\"container.vcores\")) {\n              int containerVCores \u003d Integer.parseInt(\n                  jsonTask.get(\"container.vcores\").toString());\n              res.setVirtualCores(containerVCores);\n            }\n\n            int priority \u003d Integer.parseInt(\n                    jsonTask.get(\"container.priority\").toString());\n            String type \u003d jsonTask.get(\"container.type\").toString();\n            containerList.add(new ContainerSimulator(res,\n                    lifeTime, hostname, priority, type));\n          }\n\n          // create a new AM\n          String amType \u003d jsonJob.get(\"am.type\").toString();\n          AMSimulator amSim \u003d (AMSimulator) ReflectionUtils.newInstance(\n                  amClassMap.get(amType), new Configuration());\n          if (amSim !\u003d null) {\n            amSim.init(AM_ID++, heartbeatInterval, containerList, rm,\n                    this, jobStartTime, jobFinishTime, user, queue,\n                    isTracked, oldAppId);\n            runner.schedule(amSim);\n            maxRuntime \u003d Math.max(maxRuntime, jobFinishTime);\n            numTasks +\u003d containerList.size();\n            amMap.put(oldAppId, amSim);\n          }\n        }\n      } finally {\n        input.close();\n      }\n    }\n  }",
      "path": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java",
      "extendedDetails": {}
    },
    "819224dcf9c683aa52f58633ac8e13663f1916d8": {
      "type": "Ybodychange",
      "commitMessage": "YARN-5270. Solve miscellaneous issues caused by YARN-4844. Contributed by Wangda Tan\n",
      "commitDate": "11/07/16 10:36 PM",
      "commitName": "819224dcf9c683aa52f58633ac8e13663f1916d8",
      "commitAuthor": "Jian He",
      "commitDateOld": "09/05/16 2:49 PM",
      "commitNameOld": "996a210ab0131606639ba87fd5daab14bf05b35f",
      "commitAuthorOld": "Jian He",
      "daysBetweenCommits": 63.32,
      "commitsBetweenForRepo": 555,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,86 +1,86 @@\n   private void startAMFromSLSTraces(Resource containerResource,\n                                     int heartbeatInterval) throws IOException {\n     // parse from sls traces\n     JsonFactory jsonF \u003d new JsonFactory();\n     ObjectMapper mapper \u003d new ObjectMapper();\n     for (String inputTrace : inputTraces) {\n       Reader input \u003d\n           new InputStreamReader(new FileInputStream(inputTrace), \"UTF-8\");\n       try {\n         Iterator\u003cMap\u003e i \u003d mapper.readValues(jsonF.createJsonParser(input),\n                 Map.class);\n         while (i.hasNext()) {\n           Map jsonJob \u003d i.next();\n \n           // load job information\n           long jobStartTime \u003d Long.parseLong(\n                   jsonJob.get(\"job.start.ms\").toString());\n           long jobFinishTime \u003d Long.parseLong(\n                   jsonJob.get(\"job.end.ms\").toString());\n \n           String user \u003d (String) jsonJob.get(\"job.user\");\n           if (user \u003d\u003d null)  user \u003d \"default\";\n           String queue \u003d jsonJob.get(\"job.queue.name\").toString();\n \n           String oldAppId \u003d jsonJob.get(\"job.id\").toString();\n           boolean isTracked \u003d trackedApps.contains(oldAppId);\n           int queueSize \u003d queueAppNumMap.containsKey(queue) ?\n                   queueAppNumMap.get(queue) : 0;\n           queueSize ++;\n           queueAppNumMap.put(queue, queueSize);\n           // tasks\n           List tasks \u003d (List) jsonJob.get(\"job.tasks\");\n           if (tasks \u003d\u003d null || tasks.size() \u003d\u003d 0) {\n             continue;\n           }\n           List\u003cContainerSimulator\u003e containerList \u003d\n                   new ArrayList\u003cContainerSimulator\u003e();\n           for (Object o : tasks) {\n             Map jsonTask \u003d (Map) o;\n             String hostname \u003d jsonTask.get(\"container.host\").toString();\n             long taskStart \u003d Long.parseLong(\n                     jsonTask.get(\"container.start.ms\").toString());\n             long taskFinish \u003d Long.parseLong(\n                     jsonTask.get(\"container.end.ms\").toString());\n             long lifeTime \u003d taskFinish - taskStart;\n \n             // Set memory and vcores from job trace file\n             Resource res \u003d Resources.clone(containerResource);\n             if (jsonTask.containsKey(\"container.memory\")) {\n               int containerMemory \u003d Integer.parseInt(\n                   jsonTask.get(\"container.memory\").toString());\n-              res.setMemory(containerMemory);\n+              res.setMemorySize(containerMemory);\n             }\n \n             if (jsonTask.containsKey(\"container.vcores\")) {\n               int containerVCores \u003d Integer.parseInt(\n                   jsonTask.get(\"container.vcores\").toString());\n               res.setVirtualCores(containerVCores);\n             }\n \n             int priority \u003d Integer.parseInt(\n                     jsonTask.get(\"container.priority\").toString());\n             String type \u003d jsonTask.get(\"container.type\").toString();\n             containerList.add(new ContainerSimulator(res,\n                     lifeTime, hostname, priority, type));\n           }\n \n           // create a new AM\n           String amType \u003d jsonJob.get(\"am.type\").toString();\n           AMSimulator amSim \u003d (AMSimulator) ReflectionUtils.newInstance(\n                   amClassMap.get(amType), new Configuration());\n           if (amSim !\u003d null) {\n             amSim.init(AM_ID++, heartbeatInterval, containerList, rm,\n                     this, jobStartTime, jobFinishTime, user, queue,\n                     isTracked, oldAppId);\n             runner.schedule(amSim);\n             maxRuntime \u003d Math.max(maxRuntime, jobFinishTime);\n             numTasks +\u003d containerList.size();\n             amMap.put(oldAppId, amSim);\n           }\n         }\n       } finally {\n         input.close();\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void startAMFromSLSTraces(Resource containerResource,\n                                    int heartbeatInterval) throws IOException {\n    // parse from sls traces\n    JsonFactory jsonF \u003d new JsonFactory();\n    ObjectMapper mapper \u003d new ObjectMapper();\n    for (String inputTrace : inputTraces) {\n      Reader input \u003d\n          new InputStreamReader(new FileInputStream(inputTrace), \"UTF-8\");\n      try {\n        Iterator\u003cMap\u003e i \u003d mapper.readValues(jsonF.createJsonParser(input),\n                Map.class);\n        while (i.hasNext()) {\n          Map jsonJob \u003d i.next();\n\n          // load job information\n          long jobStartTime \u003d Long.parseLong(\n                  jsonJob.get(\"job.start.ms\").toString());\n          long jobFinishTime \u003d Long.parseLong(\n                  jsonJob.get(\"job.end.ms\").toString());\n\n          String user \u003d (String) jsonJob.get(\"job.user\");\n          if (user \u003d\u003d null)  user \u003d \"default\";\n          String queue \u003d jsonJob.get(\"job.queue.name\").toString();\n\n          String oldAppId \u003d jsonJob.get(\"job.id\").toString();\n          boolean isTracked \u003d trackedApps.contains(oldAppId);\n          int queueSize \u003d queueAppNumMap.containsKey(queue) ?\n                  queueAppNumMap.get(queue) : 0;\n          queueSize ++;\n          queueAppNumMap.put(queue, queueSize);\n          // tasks\n          List tasks \u003d (List) jsonJob.get(\"job.tasks\");\n          if (tasks \u003d\u003d null || tasks.size() \u003d\u003d 0) {\n            continue;\n          }\n          List\u003cContainerSimulator\u003e containerList \u003d\n                  new ArrayList\u003cContainerSimulator\u003e();\n          for (Object o : tasks) {\n            Map jsonTask \u003d (Map) o;\n            String hostname \u003d jsonTask.get(\"container.host\").toString();\n            long taskStart \u003d Long.parseLong(\n                    jsonTask.get(\"container.start.ms\").toString());\n            long taskFinish \u003d Long.parseLong(\n                    jsonTask.get(\"container.end.ms\").toString());\n            long lifeTime \u003d taskFinish - taskStart;\n\n            // Set memory and vcores from job trace file\n            Resource res \u003d Resources.clone(containerResource);\n            if (jsonTask.containsKey(\"container.memory\")) {\n              int containerMemory \u003d Integer.parseInt(\n                  jsonTask.get(\"container.memory\").toString());\n              res.setMemorySize(containerMemory);\n            }\n\n            if (jsonTask.containsKey(\"container.vcores\")) {\n              int containerVCores \u003d Integer.parseInt(\n                  jsonTask.get(\"container.vcores\").toString());\n              res.setVirtualCores(containerVCores);\n            }\n\n            int priority \u003d Integer.parseInt(\n                    jsonTask.get(\"container.priority\").toString());\n            String type \u003d jsonTask.get(\"container.type\").toString();\n            containerList.add(new ContainerSimulator(res,\n                    lifeTime, hostname, priority, type));\n          }\n\n          // create a new AM\n          String amType \u003d jsonJob.get(\"am.type\").toString();\n          AMSimulator amSim \u003d (AMSimulator) ReflectionUtils.newInstance(\n                  amClassMap.get(amType), new Configuration());\n          if (amSim !\u003d null) {\n            amSim.init(AM_ID++, heartbeatInterval, containerList, rm,\n                    this, jobStartTime, jobFinishTime, user, queue,\n                    isTracked, oldAppId);\n            runner.schedule(amSim);\n            maxRuntime \u003d Math.max(maxRuntime, jobFinishTime);\n            numTasks +\u003d containerList.size();\n            amMap.put(oldAppId, amSim);\n          }\n        }\n      } finally {\n        input.close();\n      }\n    }\n  }",
      "path": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java",
      "extendedDetails": {}
    },
    "996a210ab0131606639ba87fd5daab14bf05b35f": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4778. Support specifying resources for task containers in SLS. Contributed by Wangda Tan\n",
      "commitDate": "09/05/16 2:49 PM",
      "commitName": "996a210ab0131606639ba87fd5daab14bf05b35f",
      "commitAuthor": "Jian He",
      "commitDateOld": "26/01/16 6:17 PM",
      "commitNameOld": "4efdf3a979c361348612f817a3253be6d0de58f7",
      "commitAuthorOld": "Xuan",
      "daysBetweenCommits": 103.81,
      "commitsBetweenForRepo": 647,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,71 +1,86 @@\n   private void startAMFromSLSTraces(Resource containerResource,\n                                     int heartbeatInterval) throws IOException {\n     // parse from sls traces\n     JsonFactory jsonF \u003d new JsonFactory();\n     ObjectMapper mapper \u003d new ObjectMapper();\n     for (String inputTrace : inputTraces) {\n       Reader input \u003d\n           new InputStreamReader(new FileInputStream(inputTrace), \"UTF-8\");\n       try {\n         Iterator\u003cMap\u003e i \u003d mapper.readValues(jsonF.createJsonParser(input),\n                 Map.class);\n         while (i.hasNext()) {\n           Map jsonJob \u003d i.next();\n \n           // load job information\n           long jobStartTime \u003d Long.parseLong(\n                   jsonJob.get(\"job.start.ms\").toString());\n           long jobFinishTime \u003d Long.parseLong(\n                   jsonJob.get(\"job.end.ms\").toString());\n \n           String user \u003d (String) jsonJob.get(\"job.user\");\n           if (user \u003d\u003d null)  user \u003d \"default\";\n           String queue \u003d jsonJob.get(\"job.queue.name\").toString();\n \n           String oldAppId \u003d jsonJob.get(\"job.id\").toString();\n           boolean isTracked \u003d trackedApps.contains(oldAppId);\n           int queueSize \u003d queueAppNumMap.containsKey(queue) ?\n                   queueAppNumMap.get(queue) : 0;\n           queueSize ++;\n           queueAppNumMap.put(queue, queueSize);\n           // tasks\n           List tasks \u003d (List) jsonJob.get(\"job.tasks\");\n           if (tasks \u003d\u003d null || tasks.size() \u003d\u003d 0) {\n             continue;\n           }\n           List\u003cContainerSimulator\u003e containerList \u003d\n                   new ArrayList\u003cContainerSimulator\u003e();\n           for (Object o : tasks) {\n             Map jsonTask \u003d (Map) o;\n             String hostname \u003d jsonTask.get(\"container.host\").toString();\n             long taskStart \u003d Long.parseLong(\n                     jsonTask.get(\"container.start.ms\").toString());\n             long taskFinish \u003d Long.parseLong(\n                     jsonTask.get(\"container.end.ms\").toString());\n             long lifeTime \u003d taskFinish - taskStart;\n+\n+            // Set memory and vcores from job trace file\n+            Resource res \u003d Resources.clone(containerResource);\n+            if (jsonTask.containsKey(\"container.memory\")) {\n+              int containerMemory \u003d Integer.parseInt(\n+                  jsonTask.get(\"container.memory\").toString());\n+              res.setMemory(containerMemory);\n+            }\n+\n+            if (jsonTask.containsKey(\"container.vcores\")) {\n+              int containerVCores \u003d Integer.parseInt(\n+                  jsonTask.get(\"container.vcores\").toString());\n+              res.setVirtualCores(containerVCores);\n+            }\n+\n             int priority \u003d Integer.parseInt(\n                     jsonTask.get(\"container.priority\").toString());\n             String type \u003d jsonTask.get(\"container.type\").toString();\n-            containerList.add(new ContainerSimulator(containerResource,\n+            containerList.add(new ContainerSimulator(res,\n                     lifeTime, hostname, priority, type));\n           }\n \n           // create a new AM\n           String amType \u003d jsonJob.get(\"am.type\").toString();\n           AMSimulator amSim \u003d (AMSimulator) ReflectionUtils.newInstance(\n                   amClassMap.get(amType), new Configuration());\n           if (amSim !\u003d null) {\n             amSim.init(AM_ID++, heartbeatInterval, containerList, rm,\n                     this, jobStartTime, jobFinishTime, user, queue,\n                     isTracked, oldAppId);\n             runner.schedule(amSim);\n             maxRuntime \u003d Math.max(maxRuntime, jobFinishTime);\n             numTasks +\u003d containerList.size();\n             amMap.put(oldAppId, amSim);\n           }\n         }\n       } finally {\n         input.close();\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void startAMFromSLSTraces(Resource containerResource,\n                                    int heartbeatInterval) throws IOException {\n    // parse from sls traces\n    JsonFactory jsonF \u003d new JsonFactory();\n    ObjectMapper mapper \u003d new ObjectMapper();\n    for (String inputTrace : inputTraces) {\n      Reader input \u003d\n          new InputStreamReader(new FileInputStream(inputTrace), \"UTF-8\");\n      try {\n        Iterator\u003cMap\u003e i \u003d mapper.readValues(jsonF.createJsonParser(input),\n                Map.class);\n        while (i.hasNext()) {\n          Map jsonJob \u003d i.next();\n\n          // load job information\n          long jobStartTime \u003d Long.parseLong(\n                  jsonJob.get(\"job.start.ms\").toString());\n          long jobFinishTime \u003d Long.parseLong(\n                  jsonJob.get(\"job.end.ms\").toString());\n\n          String user \u003d (String) jsonJob.get(\"job.user\");\n          if (user \u003d\u003d null)  user \u003d \"default\";\n          String queue \u003d jsonJob.get(\"job.queue.name\").toString();\n\n          String oldAppId \u003d jsonJob.get(\"job.id\").toString();\n          boolean isTracked \u003d trackedApps.contains(oldAppId);\n          int queueSize \u003d queueAppNumMap.containsKey(queue) ?\n                  queueAppNumMap.get(queue) : 0;\n          queueSize ++;\n          queueAppNumMap.put(queue, queueSize);\n          // tasks\n          List tasks \u003d (List) jsonJob.get(\"job.tasks\");\n          if (tasks \u003d\u003d null || tasks.size() \u003d\u003d 0) {\n            continue;\n          }\n          List\u003cContainerSimulator\u003e containerList \u003d\n                  new ArrayList\u003cContainerSimulator\u003e();\n          for (Object o : tasks) {\n            Map jsonTask \u003d (Map) o;\n            String hostname \u003d jsonTask.get(\"container.host\").toString();\n            long taskStart \u003d Long.parseLong(\n                    jsonTask.get(\"container.start.ms\").toString());\n            long taskFinish \u003d Long.parseLong(\n                    jsonTask.get(\"container.end.ms\").toString());\n            long lifeTime \u003d taskFinish - taskStart;\n\n            // Set memory and vcores from job trace file\n            Resource res \u003d Resources.clone(containerResource);\n            if (jsonTask.containsKey(\"container.memory\")) {\n              int containerMemory \u003d Integer.parseInt(\n                  jsonTask.get(\"container.memory\").toString());\n              res.setMemory(containerMemory);\n            }\n\n            if (jsonTask.containsKey(\"container.vcores\")) {\n              int containerVCores \u003d Integer.parseInt(\n                  jsonTask.get(\"container.vcores\").toString());\n              res.setVirtualCores(containerVCores);\n            }\n\n            int priority \u003d Integer.parseInt(\n                    jsonTask.get(\"container.priority\").toString());\n            String type \u003d jsonTask.get(\"container.type\").toString();\n            containerList.add(new ContainerSimulator(res,\n                    lifeTime, hostname, priority, type));\n          }\n\n          // create a new AM\n          String amType \u003d jsonJob.get(\"am.type\").toString();\n          AMSimulator amSim \u003d (AMSimulator) ReflectionUtils.newInstance(\n                  amClassMap.get(amType), new Configuration());\n          if (amSim !\u003d null) {\n            amSim.init(AM_ID++, heartbeatInterval, containerList, rm,\n                    this, jobStartTime, jobFinishTime, user, queue,\n                    isTracked, oldAppId);\n            runner.schedule(amSim);\n            maxRuntime \u003d Math.max(maxRuntime, jobFinishTime);\n            numTasks +\u003d containerList.size();\n            amMap.put(oldAppId, amSim);\n          }\n        }\n      } finally {\n        input.close();\n      }\n    }\n  }",
      "path": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java",
      "extendedDetails": {}
    },
    "f384a063a653b33d69f7d2c7d4fd45c24b5aa46a": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-11821. Fix findbugs warnings in hadoop-sls. Contributed by Brahma Reddy Battula.\n",
      "commitDate": "30/04/15 3:34 AM",
      "commitName": "f384a063a653b33d69f7d2c7d4fd45c24b5aa46a",
      "commitAuthor": "Akira Ajisaka",
      "commitDateOld": "25/07/14 10:12 AM",
      "commitNameOld": "77363b9d839e47bef2325b8682eabe00d4c83354",
      "commitAuthorOld": "Karthik Kambatla",
      "daysBetweenCommits": 278.72,
      "commitsBetweenForRepo": 2401,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,70 +1,71 @@\n   private void startAMFromSLSTraces(Resource containerResource,\n                                     int heartbeatInterval) throws IOException {\n     // parse from sls traces\n     JsonFactory jsonF \u003d new JsonFactory();\n     ObjectMapper mapper \u003d new ObjectMapper();\n     for (String inputTrace : inputTraces) {\n-      Reader input \u003d new FileReader(inputTrace);\n+      Reader input \u003d\n+          new InputStreamReader(new FileInputStream(inputTrace), \"UTF-8\");\n       try {\n         Iterator\u003cMap\u003e i \u003d mapper.readValues(jsonF.createJsonParser(input),\n                 Map.class);\n         while (i.hasNext()) {\n           Map jsonJob \u003d i.next();\n \n           // load job information\n           long jobStartTime \u003d Long.parseLong(\n                   jsonJob.get(\"job.start.ms\").toString());\n           long jobFinishTime \u003d Long.parseLong(\n                   jsonJob.get(\"job.end.ms\").toString());\n \n           String user \u003d (String) jsonJob.get(\"job.user\");\n           if (user \u003d\u003d null)  user \u003d \"default\";\n           String queue \u003d jsonJob.get(\"job.queue.name\").toString();\n \n           String oldAppId \u003d jsonJob.get(\"job.id\").toString();\n           boolean isTracked \u003d trackedApps.contains(oldAppId);\n           int queueSize \u003d queueAppNumMap.containsKey(queue) ?\n                   queueAppNumMap.get(queue) : 0;\n           queueSize ++;\n           queueAppNumMap.put(queue, queueSize);\n           // tasks\n           List tasks \u003d (List) jsonJob.get(\"job.tasks\");\n           if (tasks \u003d\u003d null || tasks.size() \u003d\u003d 0) {\n             continue;\n           }\n           List\u003cContainerSimulator\u003e containerList \u003d\n                   new ArrayList\u003cContainerSimulator\u003e();\n           for (Object o : tasks) {\n             Map jsonTask \u003d (Map) o;\n             String hostname \u003d jsonTask.get(\"container.host\").toString();\n             long taskStart \u003d Long.parseLong(\n                     jsonTask.get(\"container.start.ms\").toString());\n             long taskFinish \u003d Long.parseLong(\n                     jsonTask.get(\"container.end.ms\").toString());\n             long lifeTime \u003d taskFinish - taskStart;\n             int priority \u003d Integer.parseInt(\n                     jsonTask.get(\"container.priority\").toString());\n             String type \u003d jsonTask.get(\"container.type\").toString();\n             containerList.add(new ContainerSimulator(containerResource,\n                     lifeTime, hostname, priority, type));\n           }\n \n           // create a new AM\n           String amType \u003d jsonJob.get(\"am.type\").toString();\n           AMSimulator amSim \u003d (AMSimulator) ReflectionUtils.newInstance(\n                   amClassMap.get(amType), new Configuration());\n           if (amSim !\u003d null) {\n             amSim.init(AM_ID++, heartbeatInterval, containerList, rm,\n                     this, jobStartTime, jobFinishTime, user, queue,\n                     isTracked, oldAppId);\n             runner.schedule(amSim);\n             maxRuntime \u003d Math.max(maxRuntime, jobFinishTime);\n             numTasks +\u003d containerList.size();\n             amMap.put(oldAppId, amSim);\n           }\n         }\n       } finally {\n         input.close();\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void startAMFromSLSTraces(Resource containerResource,\n                                    int heartbeatInterval) throws IOException {\n    // parse from sls traces\n    JsonFactory jsonF \u003d new JsonFactory();\n    ObjectMapper mapper \u003d new ObjectMapper();\n    for (String inputTrace : inputTraces) {\n      Reader input \u003d\n          new InputStreamReader(new FileInputStream(inputTrace), \"UTF-8\");\n      try {\n        Iterator\u003cMap\u003e i \u003d mapper.readValues(jsonF.createJsonParser(input),\n                Map.class);\n        while (i.hasNext()) {\n          Map jsonJob \u003d i.next();\n\n          // load job information\n          long jobStartTime \u003d Long.parseLong(\n                  jsonJob.get(\"job.start.ms\").toString());\n          long jobFinishTime \u003d Long.parseLong(\n                  jsonJob.get(\"job.end.ms\").toString());\n\n          String user \u003d (String) jsonJob.get(\"job.user\");\n          if (user \u003d\u003d null)  user \u003d \"default\";\n          String queue \u003d jsonJob.get(\"job.queue.name\").toString();\n\n          String oldAppId \u003d jsonJob.get(\"job.id\").toString();\n          boolean isTracked \u003d trackedApps.contains(oldAppId);\n          int queueSize \u003d queueAppNumMap.containsKey(queue) ?\n                  queueAppNumMap.get(queue) : 0;\n          queueSize ++;\n          queueAppNumMap.put(queue, queueSize);\n          // tasks\n          List tasks \u003d (List) jsonJob.get(\"job.tasks\");\n          if (tasks \u003d\u003d null || tasks.size() \u003d\u003d 0) {\n            continue;\n          }\n          List\u003cContainerSimulator\u003e containerList \u003d\n                  new ArrayList\u003cContainerSimulator\u003e();\n          for (Object o : tasks) {\n            Map jsonTask \u003d (Map) o;\n            String hostname \u003d jsonTask.get(\"container.host\").toString();\n            long taskStart \u003d Long.parseLong(\n                    jsonTask.get(\"container.start.ms\").toString());\n            long taskFinish \u003d Long.parseLong(\n                    jsonTask.get(\"container.end.ms\").toString());\n            long lifeTime \u003d taskFinish - taskStart;\n            int priority \u003d Integer.parseInt(\n                    jsonTask.get(\"container.priority\").toString());\n            String type \u003d jsonTask.get(\"container.type\").toString();\n            containerList.add(new ContainerSimulator(containerResource,\n                    lifeTime, hostname, priority, type));\n          }\n\n          // create a new AM\n          String amType \u003d jsonJob.get(\"am.type\").toString();\n          AMSimulator amSim \u003d (AMSimulator) ReflectionUtils.newInstance(\n                  amClassMap.get(amType), new Configuration());\n          if (amSim !\u003d null) {\n            amSim.init(AM_ID++, heartbeatInterval, containerList, rm,\n                    this, jobStartTime, jobFinishTime, user, queue,\n                    isTracked, oldAppId);\n            runner.schedule(amSim);\n            maxRuntime \u003d Math.max(maxRuntime, jobFinishTime);\n            numTasks +\u003d containerList.size();\n            amMap.put(oldAppId, amSim);\n          }\n        }\n      } finally {\n        input.close();\n      }\n    }\n  }",
      "path": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java",
      "extendedDetails": {}
    },
    "58b08e11b9f04c9190ab4a07473f0ee04e01ec6b": {
      "type": "Yintroduced",
      "commitMessage": "YARN-1021. Yarn Scheduler Load Simulator. (ywskycn via tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1527059 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/09/13 1:23 PM",
      "commitName": "58b08e11b9f04c9190ab4a07473f0ee04e01ec6b",
      "commitAuthor": "Alejandro Abdelnur",
      "diff": "@@ -0,0 +1,70 @@\n+  private void startAMFromSLSTraces(Resource containerResource,\n+                                    int heartbeatInterval) throws IOException {\n+    // parse from sls traces\n+    JsonFactory jsonF \u003d new JsonFactory();\n+    ObjectMapper mapper \u003d new ObjectMapper();\n+    for (String inputTrace : inputTraces) {\n+      Reader input \u003d new FileReader(inputTrace);\n+      try {\n+        Iterator\u003cMap\u003e i \u003d mapper.readValues(jsonF.createJsonParser(input),\n+                Map.class);\n+        while (i.hasNext()) {\n+          Map jsonJob \u003d i.next();\n+\n+          // load job information\n+          long jobStartTime \u003d Long.parseLong(\n+                  jsonJob.get(\"job.start.ms\").toString());\n+          long jobFinishTime \u003d Long.parseLong(\n+                  jsonJob.get(\"job.end.ms\").toString());\n+\n+          String user \u003d (String) jsonJob.get(\"job.user\");\n+          if (user \u003d\u003d null)  user \u003d \"default\";\n+          String queue \u003d jsonJob.get(\"job.queue.name\").toString();\n+\n+          String oldAppId \u003d jsonJob.get(\"job.id\").toString();\n+          boolean isTracked \u003d trackedApps.contains(oldAppId);\n+          int queueSize \u003d queueAppNumMap.containsKey(queue) ?\n+                  queueAppNumMap.get(queue) : 0;\n+          queueSize ++;\n+          queueAppNumMap.put(queue, queueSize);\n+          // tasks\n+          List tasks \u003d (List) jsonJob.get(\"job.tasks\");\n+          if (tasks \u003d\u003d null || tasks.size() \u003d\u003d 0) {\n+            continue;\n+          }\n+          List\u003cContainerSimulator\u003e containerList \u003d\n+                  new ArrayList\u003cContainerSimulator\u003e();\n+          for (Object o : tasks) {\n+            Map jsonTask \u003d (Map) o;\n+            String hostname \u003d jsonTask.get(\"container.host\").toString();\n+            long taskStart \u003d Long.parseLong(\n+                    jsonTask.get(\"container.start.ms\").toString());\n+            long taskFinish \u003d Long.parseLong(\n+                    jsonTask.get(\"container.end.ms\").toString());\n+            long lifeTime \u003d taskFinish - taskStart;\n+            int priority \u003d Integer.parseInt(\n+                    jsonTask.get(\"container.priority\").toString());\n+            String type \u003d jsonTask.get(\"container.type\").toString();\n+            containerList.add(new ContainerSimulator(containerResource,\n+                    lifeTime, hostname, priority, type));\n+          }\n+\n+          // create a new AM\n+          String amType \u003d jsonJob.get(\"am.type\").toString();\n+          AMSimulator amSim \u003d (AMSimulator) ReflectionUtils.newInstance(\n+                  amClassMap.get(amType), new Configuration());\n+          if (amSim !\u003d null) {\n+            amSim.init(AM_ID++, heartbeatInterval, containerList, rm,\n+                    this, jobStartTime, jobFinishTime, user, queue,\n+                    isTracked, oldAppId);\n+            runner.schedule(amSim);\n+            maxRuntime \u003d Math.max(maxRuntime, jobFinishTime);\n+            numTasks +\u003d containerList.size();\n+            amMap.put(oldAppId, amSim);\n+          }\n+        }\n+      } finally {\n+        input.close();\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void startAMFromSLSTraces(Resource containerResource,\n                                    int heartbeatInterval) throws IOException {\n    // parse from sls traces\n    JsonFactory jsonF \u003d new JsonFactory();\n    ObjectMapper mapper \u003d new ObjectMapper();\n    for (String inputTrace : inputTraces) {\n      Reader input \u003d new FileReader(inputTrace);\n      try {\n        Iterator\u003cMap\u003e i \u003d mapper.readValues(jsonF.createJsonParser(input),\n                Map.class);\n        while (i.hasNext()) {\n          Map jsonJob \u003d i.next();\n\n          // load job information\n          long jobStartTime \u003d Long.parseLong(\n                  jsonJob.get(\"job.start.ms\").toString());\n          long jobFinishTime \u003d Long.parseLong(\n                  jsonJob.get(\"job.end.ms\").toString());\n\n          String user \u003d (String) jsonJob.get(\"job.user\");\n          if (user \u003d\u003d null)  user \u003d \"default\";\n          String queue \u003d jsonJob.get(\"job.queue.name\").toString();\n\n          String oldAppId \u003d jsonJob.get(\"job.id\").toString();\n          boolean isTracked \u003d trackedApps.contains(oldAppId);\n          int queueSize \u003d queueAppNumMap.containsKey(queue) ?\n                  queueAppNumMap.get(queue) : 0;\n          queueSize ++;\n          queueAppNumMap.put(queue, queueSize);\n          // tasks\n          List tasks \u003d (List) jsonJob.get(\"job.tasks\");\n          if (tasks \u003d\u003d null || tasks.size() \u003d\u003d 0) {\n            continue;\n          }\n          List\u003cContainerSimulator\u003e containerList \u003d\n                  new ArrayList\u003cContainerSimulator\u003e();\n          for (Object o : tasks) {\n            Map jsonTask \u003d (Map) o;\n            String hostname \u003d jsonTask.get(\"container.host\").toString();\n            long taskStart \u003d Long.parseLong(\n                    jsonTask.get(\"container.start.ms\").toString());\n            long taskFinish \u003d Long.parseLong(\n                    jsonTask.get(\"container.end.ms\").toString());\n            long lifeTime \u003d taskFinish - taskStart;\n            int priority \u003d Integer.parseInt(\n                    jsonTask.get(\"container.priority\").toString());\n            String type \u003d jsonTask.get(\"container.type\").toString();\n            containerList.add(new ContainerSimulator(containerResource,\n                    lifeTime, hostname, priority, type));\n          }\n\n          // create a new AM\n          String amType \u003d jsonJob.get(\"am.type\").toString();\n          AMSimulator amSim \u003d (AMSimulator) ReflectionUtils.newInstance(\n                  amClassMap.get(amType), new Configuration());\n          if (amSim !\u003d null) {\n            amSim.init(AM_ID++, heartbeatInterval, containerList, rm,\n                    this, jobStartTime, jobFinishTime, user, queue,\n                    isTracked, oldAppId);\n            runner.schedule(amSim);\n            maxRuntime \u003d Math.max(maxRuntime, jobFinishTime);\n            numTasks +\u003d containerList.size();\n            amMap.put(oldAppId, amSim);\n          }\n        }\n      } finally {\n        input.close();\n      }\n    }\n  }",
      "path": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java"
    }
  }
}