{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ErasureCodingWork.java",
  "functionName": "findLeavingServiceSources",
  "functionId": "findLeavingServiceSources",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/ErasureCodingWork.java",
  "functionStartLine": 170,
  "functionEndLine": 192,
  "numCommitsSeen": 20,
  "timeTaken": 1906,
  "changeHistory": [
    "447f46d9628db54e77f88e2d109587cc7dfd6154",
    "b61fb267b92b2736920b4bd0c673d31e7632ebb9",
    "743a99f2dbc9a27e19f92ff3551937d90dba2e89"
  ],
  "changeHistoryShort": {
    "447f46d9628db54e77f88e2d109587cc7dfd6154": "Ybodychange",
    "b61fb267b92b2736920b4bd0c673d31e7632ebb9": "Ymultichange(Yrename,Ybodychange)",
    "743a99f2dbc9a27e19f92ff3551937d90dba2e89": "Yintroduced"
  },
  "changeHistoryDetails": {
    "447f46d9628db54e77f88e2d109587cc7dfd6154": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14847. Erasure Coding: Blocks are over-replicated while EC decommissioning. Contributed by Fei Hui.\n",
      "commitDate": "19/10/19 5:40 PM",
      "commitName": "447f46d9628db54e77f88e2d109587cc7dfd6154",
      "commitAuthor": "Ayush Saxena",
      "commitDateOld": "30/08/19 2:01 AM",
      "commitNameOld": "96f7dc1992246a16031f613e55dc39ea0d64acd1",
      "commitAuthorOld": "Surendra Singh Lilhore",
      "daysBetweenCommits": 50.65,
      "commitsBetweenForRepo": 381,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,11 +1,23 @@\n   private List\u003cInteger\u003e findLeavingServiceSources() {\n+    // Mark the block in normal node.\n+    BlockInfoStriped block \u003d (BlockInfoStriped)getBlock();\n+    BitSet bitSet \u003d new BitSet(block.getRealTotalBlockNum());\n+    for (int i \u003d 0; i \u003c getSrcNodes().length; i++) {\n+      if (getSrcNodes()[i].isInService()) {\n+        bitSet.set(liveBlockIndicies[i]);\n+      }\n+    }\n+    // If the block is on the node which is decommissioning or\n+    // entering_maintenance, and it doesn\u0027t exist on other normal nodes,\n+    // we just add the node into source list.\n     List\u003cInteger\u003e srcIndices \u003d new ArrayList\u003c\u003e();\n     for (int i \u003d 0; i \u003c getSrcNodes().length; i++) {\n-      if (getSrcNodes()[i].isDecommissionInProgress() ||\n+      if ((getSrcNodes()[i].isDecommissionInProgress() ||\n           (getSrcNodes()[i].isEnteringMaintenance() \u0026\u0026\n-          getSrcNodes()[i].isAlive())) {\n+          getSrcNodes()[i].isAlive())) \u0026\u0026\n+          !bitSet.get(liveBlockIndicies[i])) {\n         srcIndices.add(i);\n       }\n     }\n     return srcIndices;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private List\u003cInteger\u003e findLeavingServiceSources() {\n    // Mark the block in normal node.\n    BlockInfoStriped block \u003d (BlockInfoStriped)getBlock();\n    BitSet bitSet \u003d new BitSet(block.getRealTotalBlockNum());\n    for (int i \u003d 0; i \u003c getSrcNodes().length; i++) {\n      if (getSrcNodes()[i].isInService()) {\n        bitSet.set(liveBlockIndicies[i]);\n      }\n    }\n    // If the block is on the node which is decommissioning or\n    // entering_maintenance, and it doesn\u0027t exist on other normal nodes,\n    // we just add the node into source list.\n    List\u003cInteger\u003e srcIndices \u003d new ArrayList\u003c\u003e();\n    for (int i \u003d 0; i \u003c getSrcNodes().length; i++) {\n      if ((getSrcNodes()[i].isDecommissionInProgress() ||\n          (getSrcNodes()[i].isEnteringMaintenance() \u0026\u0026\n          getSrcNodes()[i].isAlive())) \u0026\u0026\n          !bitSet.get(liveBlockIndicies[i])) {\n        srcIndices.add(i);\n      }\n    }\n    return srcIndices;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/ErasureCodingWork.java",
      "extendedDetails": {}
    },
    "b61fb267b92b2736920b4bd0c673d31e7632ebb9": {
      "type": "Ymultichange(Yrename,Ybodychange)",
      "commitMessage": "HDFS-9390. Block management for maintenance states.\n",
      "commitDate": "17/10/16 5:45 PM",
      "commitName": "b61fb267b92b2736920b4bd0c673d31e7632ebb9",
      "commitAuthor": "Ming Ma",
      "subchanges": [
        {
          "type": "Yrename",
          "commitMessage": "HDFS-9390. Block management for maintenance states.\n",
          "commitDate": "17/10/16 5:45 PM",
          "commitName": "b61fb267b92b2736920b4bd0c673d31e7632ebb9",
          "commitAuthor": "Ming Ma",
          "commitDateOld": "27/04/16 2:22 PM",
          "commitNameOld": "0a152103f19a3e8e1b7f33aeb9dd115ba231d7b7",
          "commitAuthorOld": "Lei Xu",
          "daysBetweenCommits": 173.14,
          "commitsBetweenForRepo": 1270,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,9 +1,11 @@\n-  private List\u003cInteger\u003e findDecommissioningSources() {\n+  private List\u003cInteger\u003e findLeavingServiceSources() {\n     List\u003cInteger\u003e srcIndices \u003d new ArrayList\u003c\u003e();\n     for (int i \u003d 0; i \u003c getSrcNodes().length; i++) {\n-      if (getSrcNodes()[i].isDecommissionInProgress()) {\n+      if (getSrcNodes()[i].isDecommissionInProgress() ||\n+          (getSrcNodes()[i].isEnteringMaintenance() \u0026\u0026\n+          getSrcNodes()[i].isAlive())) {\n         srcIndices.add(i);\n       }\n     }\n     return srcIndices;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private List\u003cInteger\u003e findLeavingServiceSources() {\n    List\u003cInteger\u003e srcIndices \u003d new ArrayList\u003c\u003e();\n    for (int i \u003d 0; i \u003c getSrcNodes().length; i++) {\n      if (getSrcNodes()[i].isDecommissionInProgress() ||\n          (getSrcNodes()[i].isEnteringMaintenance() \u0026\u0026\n          getSrcNodes()[i].isAlive())) {\n        srcIndices.add(i);\n      }\n    }\n    return srcIndices;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/ErasureCodingWork.java",
          "extendedDetails": {
            "oldValue": "findDecommissioningSources",
            "newValue": "findLeavingServiceSources"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-9390. Block management for maintenance states.\n",
          "commitDate": "17/10/16 5:45 PM",
          "commitName": "b61fb267b92b2736920b4bd0c673d31e7632ebb9",
          "commitAuthor": "Ming Ma",
          "commitDateOld": "27/04/16 2:22 PM",
          "commitNameOld": "0a152103f19a3e8e1b7f33aeb9dd115ba231d7b7",
          "commitAuthorOld": "Lei Xu",
          "daysBetweenCommits": 173.14,
          "commitsBetweenForRepo": 1270,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,9 +1,11 @@\n-  private List\u003cInteger\u003e findDecommissioningSources() {\n+  private List\u003cInteger\u003e findLeavingServiceSources() {\n     List\u003cInteger\u003e srcIndices \u003d new ArrayList\u003c\u003e();\n     for (int i \u003d 0; i \u003c getSrcNodes().length; i++) {\n-      if (getSrcNodes()[i].isDecommissionInProgress()) {\n+      if (getSrcNodes()[i].isDecommissionInProgress() ||\n+          (getSrcNodes()[i].isEnteringMaintenance() \u0026\u0026\n+          getSrcNodes()[i].isAlive())) {\n         srcIndices.add(i);\n       }\n     }\n     return srcIndices;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private List\u003cInteger\u003e findLeavingServiceSources() {\n    List\u003cInteger\u003e srcIndices \u003d new ArrayList\u003c\u003e();\n    for (int i \u003d 0; i \u003c getSrcNodes().length; i++) {\n      if (getSrcNodes()[i].isDecommissionInProgress() ||\n          (getSrcNodes()[i].isEnteringMaintenance() \u0026\u0026\n          getSrcNodes()[i].isAlive())) {\n        srcIndices.add(i);\n      }\n    }\n    return srcIndices;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/ErasureCodingWork.java",
          "extendedDetails": {}
        }
      ]
    },
    "743a99f2dbc9a27e19f92ff3551937d90dba2e89": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-8786. Erasure coding: use simple replication for internal blocks on decommissioning datanodes. Contributed by Rakesh R.\n",
      "commitDate": "08/03/16 10:24 AM",
      "commitName": "743a99f2dbc9a27e19f92ff3551937d90dba2e89",
      "commitAuthor": "Jing Zhao",
      "diff": "@@ -0,0 +1,9 @@\n+  private List\u003cInteger\u003e findDecommissioningSources() {\n+    List\u003cInteger\u003e srcIndices \u003d new ArrayList\u003c\u003e();\n+    for (int i \u003d 0; i \u003c getSrcNodes().length; i++) {\n+      if (getSrcNodes()[i].isDecommissionInProgress()) {\n+        srcIndices.add(i);\n+      }\n+    }\n+    return srcIndices;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private List\u003cInteger\u003e findDecommissioningSources() {\n    List\u003cInteger\u003e srcIndices \u003d new ArrayList\u003c\u003e();\n    for (int i \u003d 0; i \u003c getSrcNodes().length; i++) {\n      if (getSrcNodes()[i].isDecommissionInProgress()) {\n        srcIndices.add(i);\n      }\n    }\n    return srcIndices;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/ErasureCodingWork.java"
    }
  }
}