{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DataNode.java",
  "functionName": "registerBlockPoolWithSecretManager",
  "functionId": "registerBlockPoolWithSecretManager___bpRegistration-DatanodeRegistration__blockPoolId-String",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java",
  "functionStartLine": 1620,
  "functionEndLine": 1651,
  "numCommitsSeen": 358,
  "timeTaken": 2091,
  "changeHistory": [
    "dfcb331ba3516264398121c9f23af3a79c0509cc"
  ],
  "changeHistoryShort": {
    "dfcb331ba3516264398121c9f23af3a79c0509cc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "dfcb331ba3516264398121c9f23af3a79c0509cc": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-13076: [SPS]: Addendum. Resolve conflicts after rebasing branch to trunk. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "dfcb331ba3516264398121c9f23af3a79c0509cc",
      "commitAuthor": "Rakesh Radhakrishnan",
      "diff": "@@ -0,0 +1,32 @@\n+  private synchronized void registerBlockPoolWithSecretManager(\n+      DatanodeRegistration bpRegistration, String blockPoolId) throws IOException {\n+    ExportedBlockKeys keys \u003d bpRegistration.getExportedKeys();\n+    if (!hasAnyBlockPoolRegistered) {\n+      hasAnyBlockPoolRegistered \u003d true;\n+      isBlockTokenEnabled \u003d keys.isBlockTokenEnabled();\n+    } else {\n+      if (isBlockTokenEnabled !\u003d keys.isBlockTokenEnabled()) {\n+        throw new RuntimeException(\"Inconsistent configuration of block access\"\n+            + \" tokens. Either all block pools must be configured to use block\"\n+            + \" tokens, or none may be.\");\n+      }\n+    }\n+    if (!isBlockTokenEnabled) return;\n+    \n+    if (!blockPoolTokenSecretManager.isBlockPoolRegistered(blockPoolId)) {\n+      long blockKeyUpdateInterval \u003d keys.getKeyUpdateInterval();\n+      long blockTokenLifetime \u003d keys.getTokenLifetime();\n+      LOG.info(\"Block token params received from NN: \" +\n+          \"for block pool {} keyUpdateInterval\u003d{} min(s), \" +\n+          \"tokenLifetime\u003d{} min(s)\",\n+          blockPoolId, blockKeyUpdateInterval / (60 * 1000),\n+          blockTokenLifetime / (60 * 1000));\n+      final boolean enableProtobuf \u003d getConf().getBoolean(\n+          DFSConfigKeys.DFS_BLOCK_ACCESS_TOKEN_PROTOBUF_ENABLE,\n+          DFSConfigKeys.DFS_BLOCK_ACCESS_TOKEN_PROTOBUF_ENABLE_DEFAULT);\n+      final BlockTokenSecretManager secretMgr \u003d \n+          new BlockTokenSecretManager(0, blockTokenLifetime, blockPoolId,\n+              dnConf.encryptionAlgorithm, enableProtobuf);\n+      blockPoolTokenSecretManager.addBlockPool(blockPoolId, secretMgr);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void registerBlockPoolWithSecretManager(\n      DatanodeRegistration bpRegistration, String blockPoolId) throws IOException {\n    ExportedBlockKeys keys \u003d bpRegistration.getExportedKeys();\n    if (!hasAnyBlockPoolRegistered) {\n      hasAnyBlockPoolRegistered \u003d true;\n      isBlockTokenEnabled \u003d keys.isBlockTokenEnabled();\n    } else {\n      if (isBlockTokenEnabled !\u003d keys.isBlockTokenEnabled()) {\n        throw new RuntimeException(\"Inconsistent configuration of block access\"\n            + \" tokens. Either all block pools must be configured to use block\"\n            + \" tokens, or none may be.\");\n      }\n    }\n    if (!isBlockTokenEnabled) return;\n    \n    if (!blockPoolTokenSecretManager.isBlockPoolRegistered(blockPoolId)) {\n      long blockKeyUpdateInterval \u003d keys.getKeyUpdateInterval();\n      long blockTokenLifetime \u003d keys.getTokenLifetime();\n      LOG.info(\"Block token params received from NN: \" +\n          \"for block pool {} keyUpdateInterval\u003d{} min(s), \" +\n          \"tokenLifetime\u003d{} min(s)\",\n          blockPoolId, blockKeyUpdateInterval / (60 * 1000),\n          blockTokenLifetime / (60 * 1000));\n      final boolean enableProtobuf \u003d getConf().getBoolean(\n          DFSConfigKeys.DFS_BLOCK_ACCESS_TOKEN_PROTOBUF_ENABLE,\n          DFSConfigKeys.DFS_BLOCK_ACCESS_TOKEN_PROTOBUF_ENABLE_DEFAULT);\n      final BlockTokenSecretManager secretMgr \u003d \n          new BlockTokenSecretManager(0, blockTokenLifetime, blockPoolId,\n              dnConf.encryptionAlgorithm, enableProtobuf);\n      blockPoolTokenSecretManager.addBlockPool(blockPoolId, secretMgr);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java"
    }
  }
}