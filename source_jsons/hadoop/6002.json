{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "NamenodeFsck.java",
  "functionName": "copyBlocksToLostFound",
  "functionId": "copyBlocksToLostFound___parent-String__file-HdfsFileStatus__blocks-LocatedBlocks",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java",
  "functionStartLine": 972,
  "functionEndLine": 1040,
  "numCommitsSeen": 135,
  "timeTaken": 6907,
  "changeHistory": [
    "9eee97508f350ed4629abb04e7781514ffa04070",
    "b9f6d0c956f0278c8b9b83e05b523a442a730ebb",
    "21fdf16b0d866dfd9eef22515be5da5f1cd9ac59",
    "4feef863721ba88c9cbf4557502e2082dfca7c40",
    "b0632df93ae5d00180b21983d960d50a45f8fb7a",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "9eee97508f350ed4629abb04e7781514ffa04070": "Ybodychange",
    "b9f6d0c956f0278c8b9b83e05b523a442a730ebb": "Ybodychange",
    "21fdf16b0d866dfd9eef22515be5da5f1cd9ac59": "Ybodychange",
    "4feef863721ba88c9cbf4557502e2082dfca7c40": "Ymultichange(Ymovefromfile,Ybodychange,Yrename)",
    "b0632df93ae5d00180b21983d960d50a45f8fb7a": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "9eee97508f350ed4629abb04e7781514ffa04070": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9022. Move NameNode.getAddress() and NameNode.getUri() to hadoop-hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "17/09/15 2:18 PM",
      "commitName": "9eee97508f350ed4629abb04e7781514ffa04070",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "03/09/15 3:32 PM",
      "commitNameOld": "ed78b14ebc9a21bb57ccd088e8b49bfa457a396f",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 13.95,
      "commitsBetweenForRepo": 82,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,69 +1,69 @@\n   private void copyBlocksToLostFound(String parent, HdfsFileStatus file,\n         LocatedBlocks blocks) throws IOException {\n-    final DFSClient dfs \u003d new DFSClient(NameNode.getAddress(conf), conf);\n+    final DFSClient dfs \u003d new DFSClient(DFSUtilClient.getNNAddress(conf), conf);\n     final String fullName \u003d file.getFullName(parent);\n     OutputStream fos \u003d null;\n     try {\n       if (!lfInited) {\n         lostFoundInit(dfs);\n       }\n       if (!lfInitedOk) {\n         throw new IOException(\"failed to initialize lost+found\");\n       }\n       String target \u003d lostFound + fullName;\n       if (hdfsPathExists(target)) {\n         LOG.warn(\"Fsck: can\u0027t copy the remains of \" + fullName + \" to \" +\n           \"lost+found, because \" + target + \" already exists.\");\n         return;\n       }\n       if (!namenode.getRpcServer().mkdirs(\n           target, file.getPermission(), true)) {\n         throw new IOException(\"failed to create directory \" + target);\n       }\n       // create chains\n       int chain \u003d 0;\n       boolean copyError \u003d false;\n       for (LocatedBlock lBlk : blocks.getLocatedBlocks()) {\n         LocatedBlock lblock \u003d lBlk;\n         DatanodeInfo[] locs \u003d lblock.getLocations();\n         if (locs \u003d\u003d null || locs.length \u003d\u003d 0) {\n           if (fos !\u003d null) {\n             fos.flush();\n             fos.close();\n             fos \u003d null;\n           }\n           continue;\n         }\n         if (fos \u003d\u003d null) {\n           fos \u003d dfs.create(target + \"/\" + chain, true);\n           chain++;\n         }\n \n         // copy the block. It\u0027s a pity it\u0027s not abstracted from DFSInputStream ...\n         try {\n           copyBlock(dfs, lblock, fos);\n         } catch (Exception e) {\n           LOG.error(\"Fsck: could not copy block \" + lblock.getBlock() +\n               \" to \" + target, e);\n           fos.flush();\n           fos.close();\n           fos \u003d null;\n           internalError \u003d true;\n           copyError \u003d true;\n         }\n       }\n       if (copyError) {\n         LOG.warn(\"Fsck: there were errors copying the remains of the \" +\n           \"corrupted file \" + fullName + \" to /lost+found\");\n       } else {\n         LOG.info(\"Fsck: copied the remains of the corrupted file \" +\n           fullName + \" to /lost+found\");\n       }\n     } catch (Exception e) {\n       LOG.error(\"copyBlocksToLostFound: error processing \" + fullName, e);\n       internalError \u003d true;\n     } finally {\n       if (fos !\u003d null) fos.close();\n       dfs.close();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void copyBlocksToLostFound(String parent, HdfsFileStatus file,\n        LocatedBlocks blocks) throws IOException {\n    final DFSClient dfs \u003d new DFSClient(DFSUtilClient.getNNAddress(conf), conf);\n    final String fullName \u003d file.getFullName(parent);\n    OutputStream fos \u003d null;\n    try {\n      if (!lfInited) {\n        lostFoundInit(dfs);\n      }\n      if (!lfInitedOk) {\n        throw new IOException(\"failed to initialize lost+found\");\n      }\n      String target \u003d lostFound + fullName;\n      if (hdfsPathExists(target)) {\n        LOG.warn(\"Fsck: can\u0027t copy the remains of \" + fullName + \" to \" +\n          \"lost+found, because \" + target + \" already exists.\");\n        return;\n      }\n      if (!namenode.getRpcServer().mkdirs(\n          target, file.getPermission(), true)) {\n        throw new IOException(\"failed to create directory \" + target);\n      }\n      // create chains\n      int chain \u003d 0;\n      boolean copyError \u003d false;\n      for (LocatedBlock lBlk : blocks.getLocatedBlocks()) {\n        LocatedBlock lblock \u003d lBlk;\n        DatanodeInfo[] locs \u003d lblock.getLocations();\n        if (locs \u003d\u003d null || locs.length \u003d\u003d 0) {\n          if (fos !\u003d null) {\n            fos.flush();\n            fos.close();\n            fos \u003d null;\n          }\n          continue;\n        }\n        if (fos \u003d\u003d null) {\n          fos \u003d dfs.create(target + \"/\" + chain, true);\n          chain++;\n        }\n\n        // copy the block. It\u0027s a pity it\u0027s not abstracted from DFSInputStream ...\n        try {\n          copyBlock(dfs, lblock, fos);\n        } catch (Exception e) {\n          LOG.error(\"Fsck: could not copy block \" + lblock.getBlock() +\n              \" to \" + target, e);\n          fos.flush();\n          fos.close();\n          fos \u003d null;\n          internalError \u003d true;\n          copyError \u003d true;\n        }\n      }\n      if (copyError) {\n        LOG.warn(\"Fsck: there were errors copying the remains of the \" +\n          \"corrupted file \" + fullName + \" to /lost+found\");\n      } else {\n        LOG.info(\"Fsck: copied the remains of the corrupted file \" +\n          fullName + \" to /lost+found\");\n      }\n    } catch (Exception e) {\n      LOG.error(\"copyBlocksToLostFound: error processing \" + fullName, e);\n      internalError \u003d true;\n    } finally {\n      if (fos !\u003d null) fos.close();\n      dfs.close();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java",
      "extendedDetails": {}
    },
    "b9f6d0c956f0278c8b9b83e05b523a442a730ebb": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7515. Fix new findbugs warnings in hadoop-hdfs. Contributed by Haohui Mai.\n",
      "commitDate": "11/12/14 12:36 PM",
      "commitName": "b9f6d0c956f0278c8b9b83e05b523a442a730ebb",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "10/12/14 11:01 PM",
      "commitNameOld": "d693a252bd0041c2493e7e07a3bf8bcf28e1923c",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 0.57,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,73 +1,69 @@\n   private void copyBlocksToLostFound(String parent, HdfsFileStatus file,\n         LocatedBlocks blocks) throws IOException {\n     final DFSClient dfs \u003d new DFSClient(NameNode.getAddress(conf), conf);\n     final String fullName \u003d file.getFullName(parent);\n     OutputStream fos \u003d null;\n     try {\n       if (!lfInited) {\n         lostFoundInit(dfs);\n       }\n       if (!lfInitedOk) {\n         throw new IOException(\"failed to initialize lost+found\");\n       }\n       String target \u003d lostFound + fullName;\n       if (hdfsPathExists(target)) {\n         LOG.warn(\"Fsck: can\u0027t copy the remains of \" + fullName + \" to \" +\n           \"lost+found, because \" + target + \" already exists.\");\n         return;\n       }\n       if (!namenode.getRpcServer().mkdirs(\n           target, file.getPermission(), true)) {\n         throw new IOException(\"failed to create directory \" + target);\n       }\n       // create chains\n       int chain \u003d 0;\n       boolean copyError \u003d false;\n       for (LocatedBlock lBlk : blocks.getLocatedBlocks()) {\n         LocatedBlock lblock \u003d lBlk;\n         DatanodeInfo[] locs \u003d lblock.getLocations();\n         if (locs \u003d\u003d null || locs.length \u003d\u003d 0) {\n           if (fos !\u003d null) {\n             fos.flush();\n             fos.close();\n             fos \u003d null;\n           }\n           continue;\n         }\n         if (fos \u003d\u003d null) {\n           fos \u003d dfs.create(target + \"/\" + chain, true);\n-          if (fos \u003d\u003d null) {\n-            throw new IOException(\"Failed to copy \" + fullName +\n-                \" to /lost+found: could not store chain \" + chain);\n-          }\n           chain++;\n         }\n         \n         // copy the block. It\u0027s a pity it\u0027s not abstracted from DFSInputStream ...\n         try {\n           copyBlock(dfs, lblock, fos);\n         } catch (Exception e) {\n           LOG.error(\"Fsck: could not copy block \" + lblock.getBlock() +\n               \" to \" + target, e);\n           fos.flush();\n           fos.close();\n           fos \u003d null;\n           internalError \u003d true;\n           copyError \u003d true;\n         }\n       }\n       if (copyError) {\n         LOG.warn(\"Fsck: there were errors copying the remains of the \" +\n           \"corrupted file \" + fullName + \" to /lost+found\");\n       } else {\n         LOG.info(\"Fsck: copied the remains of the corrupted file \" + \n           fullName + \" to /lost+found\");\n       }\n     } catch (Exception e) {\n       LOG.error(\"copyBlocksToLostFound: error processing \" + fullName, e);\n       internalError \u003d true;\n     } finally {\n       if (fos !\u003d null) fos.close();\n       dfs.close();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void copyBlocksToLostFound(String parent, HdfsFileStatus file,\n        LocatedBlocks blocks) throws IOException {\n    final DFSClient dfs \u003d new DFSClient(NameNode.getAddress(conf), conf);\n    final String fullName \u003d file.getFullName(parent);\n    OutputStream fos \u003d null;\n    try {\n      if (!lfInited) {\n        lostFoundInit(dfs);\n      }\n      if (!lfInitedOk) {\n        throw new IOException(\"failed to initialize lost+found\");\n      }\n      String target \u003d lostFound + fullName;\n      if (hdfsPathExists(target)) {\n        LOG.warn(\"Fsck: can\u0027t copy the remains of \" + fullName + \" to \" +\n          \"lost+found, because \" + target + \" already exists.\");\n        return;\n      }\n      if (!namenode.getRpcServer().mkdirs(\n          target, file.getPermission(), true)) {\n        throw new IOException(\"failed to create directory \" + target);\n      }\n      // create chains\n      int chain \u003d 0;\n      boolean copyError \u003d false;\n      for (LocatedBlock lBlk : blocks.getLocatedBlocks()) {\n        LocatedBlock lblock \u003d lBlk;\n        DatanodeInfo[] locs \u003d lblock.getLocations();\n        if (locs \u003d\u003d null || locs.length \u003d\u003d 0) {\n          if (fos !\u003d null) {\n            fos.flush();\n            fos.close();\n            fos \u003d null;\n          }\n          continue;\n        }\n        if (fos \u003d\u003d null) {\n          fos \u003d dfs.create(target + \"/\" + chain, true);\n          chain++;\n        }\n        \n        // copy the block. It\u0027s a pity it\u0027s not abstracted from DFSInputStream ...\n        try {\n          copyBlock(dfs, lblock, fos);\n        } catch (Exception e) {\n          LOG.error(\"Fsck: could not copy block \" + lblock.getBlock() +\n              \" to \" + target, e);\n          fos.flush();\n          fos.close();\n          fos \u003d null;\n          internalError \u003d true;\n          copyError \u003d true;\n        }\n      }\n      if (copyError) {\n        LOG.warn(\"Fsck: there were errors copying the remains of the \" +\n          \"corrupted file \" + fullName + \" to /lost+found\");\n      } else {\n        LOG.info(\"Fsck: copied the remains of the corrupted file \" + \n          fullName + \" to /lost+found\");\n      }\n    } catch (Exception e) {\n      LOG.error(\"copyBlocksToLostFound: error processing \" + fullName, e);\n      internalError \u003d true;\n    } finally {\n      if (fos !\u003d null) fos.close();\n      dfs.close();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java",
      "extendedDetails": {}
    },
    "21fdf16b0d866dfd9eef22515be5da5f1cd9ac59": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3548. NamenodeFsck.copyBlock fails to create a Block Reader. Contributed by Colin Patrick McCabe\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1358822 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/07/12 12:41 PM",
      "commitName": "21fdf16b0d866dfd9eef22515be5da5f1cd9ac59",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "11/06/12 6:55 PM",
      "commitNameOld": "543f86631bf07053a045d5dabcad16fb8f9eff97",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 26.74,
      "commitsBetweenForRepo": 119,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,64 +1,73 @@\n   private void copyBlocksToLostFound(String parent, HdfsFileStatus file,\n         LocatedBlocks blocks) throws IOException {\n     final DFSClient dfs \u003d new DFSClient(NameNode.getAddress(conf), conf);\n+    final String fullName \u003d file.getFullName(parent);\n+    OutputStream fos \u003d null;\n     try {\n-    if (!lfInited) {\n-      lostFoundInit(dfs);\n-    }\n-    if (!lfInitedOk) {\n-      return;\n-    }\n-    String fullName \u003d file.getFullName(parent);\n-    String target \u003d lostFound + fullName;\n-    String errmsg \u003d \"Failed to move \" + fullName + \" to /lost+found\";\n-    try {\n+      if (!lfInited) {\n+        lostFoundInit(dfs);\n+      }\n+      if (!lfInitedOk) {\n+        throw new IOException(\"failed to initialize lost+found\");\n+      }\n+      String target \u003d lostFound + fullName;\n+      if (hdfsPathExists(target)) {\n+        LOG.warn(\"Fsck: can\u0027t copy the remains of \" + fullName + \" to \" +\n+          \"lost+found, because \" + target + \" already exists.\");\n+        return;\n+      }\n       if (!namenode.getRpcServer().mkdirs(\n           target, file.getPermission(), true)) {\n-        LOG.warn(errmsg);\n-        return;\n+        throw new IOException(\"failed to create directory \" + target);\n       }\n       // create chains\n       int chain \u003d 0;\n-      OutputStream fos \u003d null;\n+      boolean copyError \u003d false;\n       for (LocatedBlock lBlk : blocks.getLocatedBlocks()) {\n         LocatedBlock lblock \u003d lBlk;\n         DatanodeInfo[] locs \u003d lblock.getLocations();\n         if (locs \u003d\u003d null || locs.length \u003d\u003d 0) {\n           if (fos !\u003d null) {\n             fos.flush();\n             fos.close();\n             fos \u003d null;\n           }\n           continue;\n         }\n         if (fos \u003d\u003d null) {\n           fos \u003d dfs.create(target + \"/\" + chain, true);\n-          if (fos !\u003d null)\n-            chain++;\n-          else {\n-            throw new IOException(errmsg + \": could not store chain \" + chain);\n+          if (fos \u003d\u003d null) {\n+            throw new IOException(\"Failed to copy \" + fullName +\n+                \" to /lost+found: could not store chain \" + chain);\n           }\n+          chain++;\n         }\n         \n         // copy the block. It\u0027s a pity it\u0027s not abstracted from DFSInputStream ...\n         try {\n           copyBlock(dfs, lblock, fos);\n         } catch (Exception e) {\n-          e.printStackTrace();\n-          // something went wrong copying this block...\n-          LOG.warn(\" - could not copy block \" + lblock.getBlock() + \" to \" + target);\n+          LOG.error(\"Fsck: could not copy block \" + lblock.getBlock() +\n+              \" to \" + target, e);\n           fos.flush();\n           fos.close();\n           fos \u003d null;\n+          internalError \u003d true;\n+          copyError \u003d true;\n         }\n       }\n-      if (fos !\u003d null) fos.close();\n-      LOG.warn(\"\\n - copied corrupted file \" + fullName + \" to /lost+found\");\n-    }  catch (Exception e) {\n-      e.printStackTrace();\n-      LOG.warn(errmsg + \": \" + e.getMessage());\n-    }\n+      if (copyError) {\n+        LOG.warn(\"Fsck: there were errors copying the remains of the \" +\n+          \"corrupted file \" + fullName + \" to /lost+found\");\n+      } else {\n+        LOG.info(\"Fsck: copied the remains of the corrupted file \" + \n+          fullName + \" to /lost+found\");\n+      }\n+    } catch (Exception e) {\n+      LOG.error(\"copyBlocksToLostFound: error processing \" + fullName, e);\n+      internalError \u003d true;\n     } finally {\n+      if (fos !\u003d null) fos.close();\n       dfs.close();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void copyBlocksToLostFound(String parent, HdfsFileStatus file,\n        LocatedBlocks blocks) throws IOException {\n    final DFSClient dfs \u003d new DFSClient(NameNode.getAddress(conf), conf);\n    final String fullName \u003d file.getFullName(parent);\n    OutputStream fos \u003d null;\n    try {\n      if (!lfInited) {\n        lostFoundInit(dfs);\n      }\n      if (!lfInitedOk) {\n        throw new IOException(\"failed to initialize lost+found\");\n      }\n      String target \u003d lostFound + fullName;\n      if (hdfsPathExists(target)) {\n        LOG.warn(\"Fsck: can\u0027t copy the remains of \" + fullName + \" to \" +\n          \"lost+found, because \" + target + \" already exists.\");\n        return;\n      }\n      if (!namenode.getRpcServer().mkdirs(\n          target, file.getPermission(), true)) {\n        throw new IOException(\"failed to create directory \" + target);\n      }\n      // create chains\n      int chain \u003d 0;\n      boolean copyError \u003d false;\n      for (LocatedBlock lBlk : blocks.getLocatedBlocks()) {\n        LocatedBlock lblock \u003d lBlk;\n        DatanodeInfo[] locs \u003d lblock.getLocations();\n        if (locs \u003d\u003d null || locs.length \u003d\u003d 0) {\n          if (fos !\u003d null) {\n            fos.flush();\n            fos.close();\n            fos \u003d null;\n          }\n          continue;\n        }\n        if (fos \u003d\u003d null) {\n          fos \u003d dfs.create(target + \"/\" + chain, true);\n          if (fos \u003d\u003d null) {\n            throw new IOException(\"Failed to copy \" + fullName +\n                \" to /lost+found: could not store chain \" + chain);\n          }\n          chain++;\n        }\n        \n        // copy the block. It\u0027s a pity it\u0027s not abstracted from DFSInputStream ...\n        try {\n          copyBlock(dfs, lblock, fos);\n        } catch (Exception e) {\n          LOG.error(\"Fsck: could not copy block \" + lblock.getBlock() +\n              \" to \" + target, e);\n          fos.flush();\n          fos.close();\n          fos \u003d null;\n          internalError \u003d true;\n          copyError \u003d true;\n        }\n      }\n      if (copyError) {\n        LOG.warn(\"Fsck: there were errors copying the remains of the \" +\n          \"corrupted file \" + fullName + \" to /lost+found\");\n      } else {\n        LOG.info(\"Fsck: copied the remains of the corrupted file \" + \n          fullName + \" to /lost+found\");\n      }\n    } catch (Exception e) {\n      LOG.error(\"copyBlocksToLostFound: error processing \" + fullName, e);\n      internalError \u003d true;\n    } finally {\n      if (fos !\u003d null) fos.close();\n      dfs.close();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java",
      "extendedDetails": {}
    },
    "4feef863721ba88c9cbf4557502e2082dfca7c40": {
      "type": "Ymultichange(Ymovefromfile,Ybodychange,Yrename)",
      "commitMessage": "HDFS-3044. fsck move should be non-destructive by default. Contributed by Colin Patrick McCabe\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1304063 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "22/03/12 2:11 PM",
      "commitName": "4feef863721ba88c9cbf4557502e2082dfca7c40",
      "commitAuthor": "Eli Collins",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-3044. fsck move should be non-destructive by default. Contributed by Colin Patrick McCabe\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1304063 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "22/03/12 2:11 PM",
          "commitName": "4feef863721ba88c9cbf4557502e2082dfca7c40",
          "commitAuthor": "Eli Collins",
          "commitDateOld": "22/03/12 9:46 AM",
          "commitNameOld": "a8ebdaeb088d53800e0397bd8a8460ca14516aa4",
          "commitAuthorOld": "Alejandro Abdelnur",
          "daysBetweenCommits": 0.18,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,67 +1,64 @@\n-  private void lostFoundMove(String parent, HdfsFileStatus file, LocatedBlocks blocks)\n-    throws IOException {\n+  private void copyBlocksToLostFound(String parent, HdfsFileStatus file,\n+        LocatedBlocks blocks) throws IOException {\n     final DFSClient dfs \u003d new DFSClient(NameNode.getAddress(conf), conf);\n     try {\n     if (!lfInited) {\n       lostFoundInit(dfs);\n     }\n     if (!lfInitedOk) {\n       return;\n     }\n     String fullName \u003d file.getFullName(parent);\n     String target \u003d lostFound + fullName;\n     String errmsg \u003d \"Failed to move \" + fullName + \" to /lost+found\";\n     try {\n       if (!namenode.getRpcServer().mkdirs(\n           target, file.getPermission(), true)) {\n         LOG.warn(errmsg);\n         return;\n       }\n       // create chains\n       int chain \u003d 0;\n       OutputStream fos \u003d null;\n       for (LocatedBlock lBlk : blocks.getLocatedBlocks()) {\n         LocatedBlock lblock \u003d lBlk;\n         DatanodeInfo[] locs \u003d lblock.getLocations();\n         if (locs \u003d\u003d null || locs.length \u003d\u003d 0) {\n           if (fos !\u003d null) {\n             fos.flush();\n             fos.close();\n             fos \u003d null;\n           }\n           continue;\n         }\n         if (fos \u003d\u003d null) {\n           fos \u003d dfs.create(target + \"/\" + chain, true);\n-          if (fos !\u003d null) chain++;\n+          if (fos !\u003d null)\n+            chain++;\n           else {\n-            LOG.warn(errmsg + \": could not store chain \" + chain);\n-            // perhaps we should bail out here...\n-            // return;\n-            continue;\n+            throw new IOException(errmsg + \": could not store chain \" + chain);\n           }\n         }\n         \n         // copy the block. It\u0027s a pity it\u0027s not abstracted from DFSInputStream ...\n         try {\n           copyBlock(dfs, lblock, fos);\n         } catch (Exception e) {\n           e.printStackTrace();\n           // something went wrong copying this block...\n           LOG.warn(\" - could not copy block \" + lblock.getBlock() + \" to \" + target);\n           fos.flush();\n           fos.close();\n           fos \u003d null;\n         }\n       }\n       if (fos !\u003d null) fos.close();\n-      LOG.warn(\"\\n - moved corrupted file \" + fullName + \" to /lost+found\");\n-      dfs.delete(fullName, true);\n+      LOG.warn(\"\\n - copied corrupted file \" + fullName + \" to /lost+found\");\n     }  catch (Exception e) {\n       e.printStackTrace();\n       LOG.warn(errmsg + \": \" + e.getMessage());\n     }\n     } finally {\n       dfs.close();\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void copyBlocksToLostFound(String parent, HdfsFileStatus file,\n        LocatedBlocks blocks) throws IOException {\n    final DFSClient dfs \u003d new DFSClient(NameNode.getAddress(conf), conf);\n    try {\n    if (!lfInited) {\n      lostFoundInit(dfs);\n    }\n    if (!lfInitedOk) {\n      return;\n    }\n    String fullName \u003d file.getFullName(parent);\n    String target \u003d lostFound + fullName;\n    String errmsg \u003d \"Failed to move \" + fullName + \" to /lost+found\";\n    try {\n      if (!namenode.getRpcServer().mkdirs(\n          target, file.getPermission(), true)) {\n        LOG.warn(errmsg);\n        return;\n      }\n      // create chains\n      int chain \u003d 0;\n      OutputStream fos \u003d null;\n      for (LocatedBlock lBlk : blocks.getLocatedBlocks()) {\n        LocatedBlock lblock \u003d lBlk;\n        DatanodeInfo[] locs \u003d lblock.getLocations();\n        if (locs \u003d\u003d null || locs.length \u003d\u003d 0) {\n          if (fos !\u003d null) {\n            fos.flush();\n            fos.close();\n            fos \u003d null;\n          }\n          continue;\n        }\n        if (fos \u003d\u003d null) {\n          fos \u003d dfs.create(target + \"/\" + chain, true);\n          if (fos !\u003d null)\n            chain++;\n          else {\n            throw new IOException(errmsg + \": could not store chain \" + chain);\n          }\n        }\n        \n        // copy the block. It\u0027s a pity it\u0027s not abstracted from DFSInputStream ...\n        try {\n          copyBlock(dfs, lblock, fos);\n        } catch (Exception e) {\n          e.printStackTrace();\n          // something went wrong copying this block...\n          LOG.warn(\" - could not copy block \" + lblock.getBlock() + \" to \" + target);\n          fos.flush();\n          fos.close();\n          fos \u003d null;\n        }\n      }\n      if (fos !\u003d null) fos.close();\n      LOG.warn(\"\\n - copied corrupted file \" + fullName + \" to /lost+found\");\n    }  catch (Exception e) {\n      e.printStackTrace();\n      LOG.warn(errmsg + \": \" + e.getMessage());\n    }\n    } finally {\n      dfs.close();\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java",
            "oldMethodName": "lostFoundMove",
            "newMethodName": "copyBlocksToLostFound"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-3044. fsck move should be non-destructive by default. Contributed by Colin Patrick McCabe\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1304063 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "22/03/12 2:11 PM",
          "commitName": "4feef863721ba88c9cbf4557502e2082dfca7c40",
          "commitAuthor": "Eli Collins",
          "commitDateOld": "22/03/12 9:46 AM",
          "commitNameOld": "a8ebdaeb088d53800e0397bd8a8460ca14516aa4",
          "commitAuthorOld": "Alejandro Abdelnur",
          "daysBetweenCommits": 0.18,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,67 +1,64 @@\n-  private void lostFoundMove(String parent, HdfsFileStatus file, LocatedBlocks blocks)\n-    throws IOException {\n+  private void copyBlocksToLostFound(String parent, HdfsFileStatus file,\n+        LocatedBlocks blocks) throws IOException {\n     final DFSClient dfs \u003d new DFSClient(NameNode.getAddress(conf), conf);\n     try {\n     if (!lfInited) {\n       lostFoundInit(dfs);\n     }\n     if (!lfInitedOk) {\n       return;\n     }\n     String fullName \u003d file.getFullName(parent);\n     String target \u003d lostFound + fullName;\n     String errmsg \u003d \"Failed to move \" + fullName + \" to /lost+found\";\n     try {\n       if (!namenode.getRpcServer().mkdirs(\n           target, file.getPermission(), true)) {\n         LOG.warn(errmsg);\n         return;\n       }\n       // create chains\n       int chain \u003d 0;\n       OutputStream fos \u003d null;\n       for (LocatedBlock lBlk : blocks.getLocatedBlocks()) {\n         LocatedBlock lblock \u003d lBlk;\n         DatanodeInfo[] locs \u003d lblock.getLocations();\n         if (locs \u003d\u003d null || locs.length \u003d\u003d 0) {\n           if (fos !\u003d null) {\n             fos.flush();\n             fos.close();\n             fos \u003d null;\n           }\n           continue;\n         }\n         if (fos \u003d\u003d null) {\n           fos \u003d dfs.create(target + \"/\" + chain, true);\n-          if (fos !\u003d null) chain++;\n+          if (fos !\u003d null)\n+            chain++;\n           else {\n-            LOG.warn(errmsg + \": could not store chain \" + chain);\n-            // perhaps we should bail out here...\n-            // return;\n-            continue;\n+            throw new IOException(errmsg + \": could not store chain \" + chain);\n           }\n         }\n         \n         // copy the block. It\u0027s a pity it\u0027s not abstracted from DFSInputStream ...\n         try {\n           copyBlock(dfs, lblock, fos);\n         } catch (Exception e) {\n           e.printStackTrace();\n           // something went wrong copying this block...\n           LOG.warn(\" - could not copy block \" + lblock.getBlock() + \" to \" + target);\n           fos.flush();\n           fos.close();\n           fos \u003d null;\n         }\n       }\n       if (fos !\u003d null) fos.close();\n-      LOG.warn(\"\\n - moved corrupted file \" + fullName + \" to /lost+found\");\n-      dfs.delete(fullName, true);\n+      LOG.warn(\"\\n - copied corrupted file \" + fullName + \" to /lost+found\");\n     }  catch (Exception e) {\n       e.printStackTrace();\n       LOG.warn(errmsg + \": \" + e.getMessage());\n     }\n     } finally {\n       dfs.close();\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void copyBlocksToLostFound(String parent, HdfsFileStatus file,\n        LocatedBlocks blocks) throws IOException {\n    final DFSClient dfs \u003d new DFSClient(NameNode.getAddress(conf), conf);\n    try {\n    if (!lfInited) {\n      lostFoundInit(dfs);\n    }\n    if (!lfInitedOk) {\n      return;\n    }\n    String fullName \u003d file.getFullName(parent);\n    String target \u003d lostFound + fullName;\n    String errmsg \u003d \"Failed to move \" + fullName + \" to /lost+found\";\n    try {\n      if (!namenode.getRpcServer().mkdirs(\n          target, file.getPermission(), true)) {\n        LOG.warn(errmsg);\n        return;\n      }\n      // create chains\n      int chain \u003d 0;\n      OutputStream fos \u003d null;\n      for (LocatedBlock lBlk : blocks.getLocatedBlocks()) {\n        LocatedBlock lblock \u003d lBlk;\n        DatanodeInfo[] locs \u003d lblock.getLocations();\n        if (locs \u003d\u003d null || locs.length \u003d\u003d 0) {\n          if (fos !\u003d null) {\n            fos.flush();\n            fos.close();\n            fos \u003d null;\n          }\n          continue;\n        }\n        if (fos \u003d\u003d null) {\n          fos \u003d dfs.create(target + \"/\" + chain, true);\n          if (fos !\u003d null)\n            chain++;\n          else {\n            throw new IOException(errmsg + \": could not store chain \" + chain);\n          }\n        }\n        \n        // copy the block. It\u0027s a pity it\u0027s not abstracted from DFSInputStream ...\n        try {\n          copyBlock(dfs, lblock, fos);\n        } catch (Exception e) {\n          e.printStackTrace();\n          // something went wrong copying this block...\n          LOG.warn(\" - could not copy block \" + lblock.getBlock() + \" to \" + target);\n          fos.flush();\n          fos.close();\n          fos \u003d null;\n        }\n      }\n      if (fos !\u003d null) fos.close();\n      LOG.warn(\"\\n - copied corrupted file \" + fullName + \" to /lost+found\");\n    }  catch (Exception e) {\n      e.printStackTrace();\n      LOG.warn(errmsg + \": \" + e.getMessage());\n    }\n    } finally {\n      dfs.close();\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java",
          "extendedDetails": {}
        },
        {
          "type": "Yrename",
          "commitMessage": "HDFS-3044. fsck move should be non-destructive by default. Contributed by Colin Patrick McCabe\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1304063 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "22/03/12 2:11 PM",
          "commitName": "4feef863721ba88c9cbf4557502e2082dfca7c40",
          "commitAuthor": "Eli Collins",
          "commitDateOld": "22/03/12 9:46 AM",
          "commitNameOld": "a8ebdaeb088d53800e0397bd8a8460ca14516aa4",
          "commitAuthorOld": "Alejandro Abdelnur",
          "daysBetweenCommits": 0.18,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,67 +1,64 @@\n-  private void lostFoundMove(String parent, HdfsFileStatus file, LocatedBlocks blocks)\n-    throws IOException {\n+  private void copyBlocksToLostFound(String parent, HdfsFileStatus file,\n+        LocatedBlocks blocks) throws IOException {\n     final DFSClient dfs \u003d new DFSClient(NameNode.getAddress(conf), conf);\n     try {\n     if (!lfInited) {\n       lostFoundInit(dfs);\n     }\n     if (!lfInitedOk) {\n       return;\n     }\n     String fullName \u003d file.getFullName(parent);\n     String target \u003d lostFound + fullName;\n     String errmsg \u003d \"Failed to move \" + fullName + \" to /lost+found\";\n     try {\n       if (!namenode.getRpcServer().mkdirs(\n           target, file.getPermission(), true)) {\n         LOG.warn(errmsg);\n         return;\n       }\n       // create chains\n       int chain \u003d 0;\n       OutputStream fos \u003d null;\n       for (LocatedBlock lBlk : blocks.getLocatedBlocks()) {\n         LocatedBlock lblock \u003d lBlk;\n         DatanodeInfo[] locs \u003d lblock.getLocations();\n         if (locs \u003d\u003d null || locs.length \u003d\u003d 0) {\n           if (fos !\u003d null) {\n             fos.flush();\n             fos.close();\n             fos \u003d null;\n           }\n           continue;\n         }\n         if (fos \u003d\u003d null) {\n           fos \u003d dfs.create(target + \"/\" + chain, true);\n-          if (fos !\u003d null) chain++;\n+          if (fos !\u003d null)\n+            chain++;\n           else {\n-            LOG.warn(errmsg + \": could not store chain \" + chain);\n-            // perhaps we should bail out here...\n-            // return;\n-            continue;\n+            throw new IOException(errmsg + \": could not store chain \" + chain);\n           }\n         }\n         \n         // copy the block. It\u0027s a pity it\u0027s not abstracted from DFSInputStream ...\n         try {\n           copyBlock(dfs, lblock, fos);\n         } catch (Exception e) {\n           e.printStackTrace();\n           // something went wrong copying this block...\n           LOG.warn(\" - could not copy block \" + lblock.getBlock() + \" to \" + target);\n           fos.flush();\n           fos.close();\n           fos \u003d null;\n         }\n       }\n       if (fos !\u003d null) fos.close();\n-      LOG.warn(\"\\n - moved corrupted file \" + fullName + \" to /lost+found\");\n-      dfs.delete(fullName, true);\n+      LOG.warn(\"\\n - copied corrupted file \" + fullName + \" to /lost+found\");\n     }  catch (Exception e) {\n       e.printStackTrace();\n       LOG.warn(errmsg + \": \" + e.getMessage());\n     }\n     } finally {\n       dfs.close();\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void copyBlocksToLostFound(String parent, HdfsFileStatus file,\n        LocatedBlocks blocks) throws IOException {\n    final DFSClient dfs \u003d new DFSClient(NameNode.getAddress(conf), conf);\n    try {\n    if (!lfInited) {\n      lostFoundInit(dfs);\n    }\n    if (!lfInitedOk) {\n      return;\n    }\n    String fullName \u003d file.getFullName(parent);\n    String target \u003d lostFound + fullName;\n    String errmsg \u003d \"Failed to move \" + fullName + \" to /lost+found\";\n    try {\n      if (!namenode.getRpcServer().mkdirs(\n          target, file.getPermission(), true)) {\n        LOG.warn(errmsg);\n        return;\n      }\n      // create chains\n      int chain \u003d 0;\n      OutputStream fos \u003d null;\n      for (LocatedBlock lBlk : blocks.getLocatedBlocks()) {\n        LocatedBlock lblock \u003d lBlk;\n        DatanodeInfo[] locs \u003d lblock.getLocations();\n        if (locs \u003d\u003d null || locs.length \u003d\u003d 0) {\n          if (fos !\u003d null) {\n            fos.flush();\n            fos.close();\n            fos \u003d null;\n          }\n          continue;\n        }\n        if (fos \u003d\u003d null) {\n          fos \u003d dfs.create(target + \"/\" + chain, true);\n          if (fos !\u003d null)\n            chain++;\n          else {\n            throw new IOException(errmsg + \": could not store chain \" + chain);\n          }\n        }\n        \n        // copy the block. It\u0027s a pity it\u0027s not abstracted from DFSInputStream ...\n        try {\n          copyBlock(dfs, lblock, fos);\n        } catch (Exception e) {\n          e.printStackTrace();\n          // something went wrong copying this block...\n          LOG.warn(\" - could not copy block \" + lblock.getBlock() + \" to \" + target);\n          fos.flush();\n          fos.close();\n          fos \u003d null;\n        }\n      }\n      if (fos !\u003d null) fos.close();\n      LOG.warn(\"\\n - copied corrupted file \" + fullName + \" to /lost+found\");\n    }  catch (Exception e) {\n      e.printStackTrace();\n      LOG.warn(errmsg + \": \" + e.getMessage());\n    }\n    } finally {\n      dfs.close();\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java",
          "extendedDetails": {
            "oldValue": "lostFoundMove",
            "newValue": "copyBlocksToLostFound"
          }
        }
      ]
    },
    "b0632df93ae5d00180b21983d960d50a45f8fb7a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2197. Refactor RPC call implementations out of NameNode class. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1165463 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "05/09/11 5:41 PM",
      "commitName": "b0632df93ae5d00180b21983d960d50a45f8fb7a",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "04/09/11 12:30 PM",
      "commitNameOld": "8ae98a9d1ca4725e28783370517cb3a3ecda7324",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 1.22,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,66 +1,67 @@\n   private void lostFoundMove(String parent, HdfsFileStatus file, LocatedBlocks blocks)\n     throws IOException {\n     final DFSClient dfs \u003d new DFSClient(NameNode.getAddress(conf), conf);\n     try {\n     if (!lfInited) {\n       lostFoundInit(dfs);\n     }\n     if (!lfInitedOk) {\n       return;\n     }\n     String fullName \u003d file.getFullName(parent);\n     String target \u003d lostFound + fullName;\n     String errmsg \u003d \"Failed to move \" + fullName + \" to /lost+found\";\n     try {\n-      if (!namenode.mkdirs(target, file.getPermission(), true)) {\n+      if (!namenode.getRpcServer().mkdirs(\n+          target, file.getPermission(), true)) {\n         LOG.warn(errmsg);\n         return;\n       }\n       // create chains\n       int chain \u003d 0;\n       OutputStream fos \u003d null;\n       for (LocatedBlock lBlk : blocks.getLocatedBlocks()) {\n         LocatedBlock lblock \u003d lBlk;\n         DatanodeInfo[] locs \u003d lblock.getLocations();\n         if (locs \u003d\u003d null || locs.length \u003d\u003d 0) {\n           if (fos !\u003d null) {\n             fos.flush();\n             fos.close();\n             fos \u003d null;\n           }\n           continue;\n         }\n         if (fos \u003d\u003d null) {\n           fos \u003d dfs.create(target + \"/\" + chain, true);\n           if (fos !\u003d null) chain++;\n           else {\n             LOG.warn(errmsg + \": could not store chain \" + chain);\n             // perhaps we should bail out here...\n             // return;\n             continue;\n           }\n         }\n         \n         // copy the block. It\u0027s a pity it\u0027s not abstracted from DFSInputStream ...\n         try {\n           copyBlock(dfs, lblock, fos);\n         } catch (Exception e) {\n           e.printStackTrace();\n           // something went wrong copying this block...\n           LOG.warn(\" - could not copy block \" + lblock.getBlock() + \" to \" + target);\n           fos.flush();\n           fos.close();\n           fos \u003d null;\n         }\n       }\n       if (fos !\u003d null) fos.close();\n       LOG.warn(\"\\n - moved corrupted file \" + fullName + \" to /lost+found\");\n       dfs.delete(fullName, true);\n     }  catch (Exception e) {\n       e.printStackTrace();\n       LOG.warn(errmsg + \": \" + e.getMessage());\n     }\n     } finally {\n       dfs.close();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void lostFoundMove(String parent, HdfsFileStatus file, LocatedBlocks blocks)\n    throws IOException {\n    final DFSClient dfs \u003d new DFSClient(NameNode.getAddress(conf), conf);\n    try {\n    if (!lfInited) {\n      lostFoundInit(dfs);\n    }\n    if (!lfInitedOk) {\n      return;\n    }\n    String fullName \u003d file.getFullName(parent);\n    String target \u003d lostFound + fullName;\n    String errmsg \u003d \"Failed to move \" + fullName + \" to /lost+found\";\n    try {\n      if (!namenode.getRpcServer().mkdirs(\n          target, file.getPermission(), true)) {\n        LOG.warn(errmsg);\n        return;\n      }\n      // create chains\n      int chain \u003d 0;\n      OutputStream fos \u003d null;\n      for (LocatedBlock lBlk : blocks.getLocatedBlocks()) {\n        LocatedBlock lblock \u003d lBlk;\n        DatanodeInfo[] locs \u003d lblock.getLocations();\n        if (locs \u003d\u003d null || locs.length \u003d\u003d 0) {\n          if (fos !\u003d null) {\n            fos.flush();\n            fos.close();\n            fos \u003d null;\n          }\n          continue;\n        }\n        if (fos \u003d\u003d null) {\n          fos \u003d dfs.create(target + \"/\" + chain, true);\n          if (fos !\u003d null) chain++;\n          else {\n            LOG.warn(errmsg + \": could not store chain \" + chain);\n            // perhaps we should bail out here...\n            // return;\n            continue;\n          }\n        }\n        \n        // copy the block. It\u0027s a pity it\u0027s not abstracted from DFSInputStream ...\n        try {\n          copyBlock(dfs, lblock, fos);\n        } catch (Exception e) {\n          e.printStackTrace();\n          // something went wrong copying this block...\n          LOG.warn(\" - could not copy block \" + lblock.getBlock() + \" to \" + target);\n          fos.flush();\n          fos.close();\n          fos \u003d null;\n        }\n      }\n      if (fos !\u003d null) fos.close();\n      LOG.warn(\"\\n - moved corrupted file \" + fullName + \" to /lost+found\");\n      dfs.delete(fullName, true);\n    }  catch (Exception e) {\n      e.printStackTrace();\n      LOG.warn(errmsg + \": \" + e.getMessage());\n    }\n    } finally {\n      dfs.close();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private void lostFoundMove(String parent, HdfsFileStatus file, LocatedBlocks blocks)\n    throws IOException {\n    final DFSClient dfs \u003d new DFSClient(NameNode.getAddress(conf), conf);\n    try {\n    if (!lfInited) {\n      lostFoundInit(dfs);\n    }\n    if (!lfInitedOk) {\n      return;\n    }\n    String fullName \u003d file.getFullName(parent);\n    String target \u003d lostFound + fullName;\n    String errmsg \u003d \"Failed to move \" + fullName + \" to /lost+found\";\n    try {\n      if (!namenode.mkdirs(target, file.getPermission(), true)) {\n        LOG.warn(errmsg);\n        return;\n      }\n      // create chains\n      int chain \u003d 0;\n      OutputStream fos \u003d null;\n      for (LocatedBlock lBlk : blocks.getLocatedBlocks()) {\n        LocatedBlock lblock \u003d lBlk;\n        DatanodeInfo[] locs \u003d lblock.getLocations();\n        if (locs \u003d\u003d null || locs.length \u003d\u003d 0) {\n          if (fos !\u003d null) {\n            fos.flush();\n            fos.close();\n            fos \u003d null;\n          }\n          continue;\n        }\n        if (fos \u003d\u003d null) {\n          fos \u003d dfs.create(target + \"/\" + chain, true);\n          if (fos !\u003d null) chain++;\n          else {\n            LOG.warn(errmsg + \": could not store chain \" + chain);\n            // perhaps we should bail out here...\n            // return;\n            continue;\n          }\n        }\n        \n        // copy the block. It\u0027s a pity it\u0027s not abstracted from DFSInputStream ...\n        try {\n          copyBlock(dfs, lblock, fos);\n        } catch (Exception e) {\n          e.printStackTrace();\n          // something went wrong copying this block...\n          LOG.warn(\" - could not copy block \" + lblock.getBlock() + \" to \" + target);\n          fos.flush();\n          fos.close();\n          fos \u003d null;\n        }\n      }\n      if (fos !\u003d null) fos.close();\n      LOG.warn(\"\\n - moved corrupted file \" + fullName + \" to /lost+found\");\n      dfs.delete(fullName, true);\n    }  catch (Exception e) {\n      e.printStackTrace();\n      LOG.warn(errmsg + \": \" + e.getMessage());\n    }\n    } finally {\n      dfs.close();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private void lostFoundMove(String parent, HdfsFileStatus file, LocatedBlocks blocks)\n    throws IOException {\n    final DFSClient dfs \u003d new DFSClient(NameNode.getAddress(conf), conf);\n    try {\n    if (!lfInited) {\n      lostFoundInit(dfs);\n    }\n    if (!lfInitedOk) {\n      return;\n    }\n    String fullName \u003d file.getFullName(parent);\n    String target \u003d lostFound + fullName;\n    String errmsg \u003d \"Failed to move \" + fullName + \" to /lost+found\";\n    try {\n      if (!namenode.mkdirs(target, file.getPermission(), true)) {\n        LOG.warn(errmsg);\n        return;\n      }\n      // create chains\n      int chain \u003d 0;\n      OutputStream fos \u003d null;\n      for (LocatedBlock lBlk : blocks.getLocatedBlocks()) {\n        LocatedBlock lblock \u003d lBlk;\n        DatanodeInfo[] locs \u003d lblock.getLocations();\n        if (locs \u003d\u003d null || locs.length \u003d\u003d 0) {\n          if (fos !\u003d null) {\n            fos.flush();\n            fos.close();\n            fos \u003d null;\n          }\n          continue;\n        }\n        if (fos \u003d\u003d null) {\n          fos \u003d dfs.create(target + \"/\" + chain, true);\n          if (fos !\u003d null) chain++;\n          else {\n            LOG.warn(errmsg + \": could not store chain \" + chain);\n            // perhaps we should bail out here...\n            // return;\n            continue;\n          }\n        }\n        \n        // copy the block. It\u0027s a pity it\u0027s not abstracted from DFSInputStream ...\n        try {\n          copyBlock(dfs, lblock, fos);\n        } catch (Exception e) {\n          e.printStackTrace();\n          // something went wrong copying this block...\n          LOG.warn(\" - could not copy block \" + lblock.getBlock() + \" to \" + target);\n          fos.flush();\n          fos.close();\n          fos \u003d null;\n        }\n      }\n      if (fos !\u003d null) fos.close();\n      LOG.warn(\"\\n - moved corrupted file \" + fullName + \" to /lost+found\");\n      dfs.delete(fullName, true);\n    }  catch (Exception e) {\n      e.printStackTrace();\n      LOG.warn(errmsg + \": \" + e.getMessage());\n    }\n    } finally {\n      dfs.close();\n    }\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,66 @@\n+  private void lostFoundMove(String parent, HdfsFileStatus file, LocatedBlocks blocks)\n+    throws IOException {\n+    final DFSClient dfs \u003d new DFSClient(NameNode.getAddress(conf), conf);\n+    try {\n+    if (!lfInited) {\n+      lostFoundInit(dfs);\n+    }\n+    if (!lfInitedOk) {\n+      return;\n+    }\n+    String fullName \u003d file.getFullName(parent);\n+    String target \u003d lostFound + fullName;\n+    String errmsg \u003d \"Failed to move \" + fullName + \" to /lost+found\";\n+    try {\n+      if (!namenode.mkdirs(target, file.getPermission(), true)) {\n+        LOG.warn(errmsg);\n+        return;\n+      }\n+      // create chains\n+      int chain \u003d 0;\n+      OutputStream fos \u003d null;\n+      for (LocatedBlock lBlk : blocks.getLocatedBlocks()) {\n+        LocatedBlock lblock \u003d lBlk;\n+        DatanodeInfo[] locs \u003d lblock.getLocations();\n+        if (locs \u003d\u003d null || locs.length \u003d\u003d 0) {\n+          if (fos !\u003d null) {\n+            fos.flush();\n+            fos.close();\n+            fos \u003d null;\n+          }\n+          continue;\n+        }\n+        if (fos \u003d\u003d null) {\n+          fos \u003d dfs.create(target + \"/\" + chain, true);\n+          if (fos !\u003d null) chain++;\n+          else {\n+            LOG.warn(errmsg + \": could not store chain \" + chain);\n+            // perhaps we should bail out here...\n+            // return;\n+            continue;\n+          }\n+        }\n+        \n+        // copy the block. It\u0027s a pity it\u0027s not abstracted from DFSInputStream ...\n+        try {\n+          copyBlock(dfs, lblock, fos);\n+        } catch (Exception e) {\n+          e.printStackTrace();\n+          // something went wrong copying this block...\n+          LOG.warn(\" - could not copy block \" + lblock.getBlock() + \" to \" + target);\n+          fos.flush();\n+          fos.close();\n+          fos \u003d null;\n+        }\n+      }\n+      if (fos !\u003d null) fos.close();\n+      LOG.warn(\"\\n - moved corrupted file \" + fullName + \" to /lost+found\");\n+      dfs.delete(fullName, true);\n+    }  catch (Exception e) {\n+      e.printStackTrace();\n+      LOG.warn(errmsg + \": \" + e.getMessage());\n+    }\n+    } finally {\n+      dfs.close();\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void lostFoundMove(String parent, HdfsFileStatus file, LocatedBlocks blocks)\n    throws IOException {\n    final DFSClient dfs \u003d new DFSClient(NameNode.getAddress(conf), conf);\n    try {\n    if (!lfInited) {\n      lostFoundInit(dfs);\n    }\n    if (!lfInitedOk) {\n      return;\n    }\n    String fullName \u003d file.getFullName(parent);\n    String target \u003d lostFound + fullName;\n    String errmsg \u003d \"Failed to move \" + fullName + \" to /lost+found\";\n    try {\n      if (!namenode.mkdirs(target, file.getPermission(), true)) {\n        LOG.warn(errmsg);\n        return;\n      }\n      // create chains\n      int chain \u003d 0;\n      OutputStream fos \u003d null;\n      for (LocatedBlock lBlk : blocks.getLocatedBlocks()) {\n        LocatedBlock lblock \u003d lBlk;\n        DatanodeInfo[] locs \u003d lblock.getLocations();\n        if (locs \u003d\u003d null || locs.length \u003d\u003d 0) {\n          if (fos !\u003d null) {\n            fos.flush();\n            fos.close();\n            fos \u003d null;\n          }\n          continue;\n        }\n        if (fos \u003d\u003d null) {\n          fos \u003d dfs.create(target + \"/\" + chain, true);\n          if (fos !\u003d null) chain++;\n          else {\n            LOG.warn(errmsg + \": could not store chain \" + chain);\n            // perhaps we should bail out here...\n            // return;\n            continue;\n          }\n        }\n        \n        // copy the block. It\u0027s a pity it\u0027s not abstracted from DFSInputStream ...\n        try {\n          copyBlock(dfs, lblock, fos);\n        } catch (Exception e) {\n          e.printStackTrace();\n          // something went wrong copying this block...\n          LOG.warn(\" - could not copy block \" + lblock.getBlock() + \" to \" + target);\n          fos.flush();\n          fos.close();\n          fos \u003d null;\n        }\n      }\n      if (fos !\u003d null) fos.close();\n      LOG.warn(\"\\n - moved corrupted file \" + fullName + \" to /lost+found\");\n      dfs.delete(fullName, true);\n    }  catch (Exception e) {\n      e.printStackTrace();\n      LOG.warn(errmsg + \": \" + e.getMessage());\n    }\n    } finally {\n      dfs.close();\n    }\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java"
    }
  }
}