{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSDirectory.java",
  "functionName": "resolvePath",
  "functionId": "resolvePath___pc-FSPermissionChecker__src-String__fileId-long",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
  "functionStartLine": 738,
  "functionEndLine": 756,
  "numCommitsSeen": 1344,
  "timeTaken": 12120,
  "changeHistory": [
    "9d175853b0170683ad5f21d9bcdeaac49fe89e04",
    "869393643de23dcb010cc33091c8eb398de0fd6c",
    "03dea65e0b17ca2f9460bb6110f6ab3a321b8bf2",
    "c95b878abf313507666ea018f9e6033c4c166e10"
  ],
  "changeHistoryShort": {
    "9d175853b0170683ad5f21d9bcdeaac49fe89e04": "Ymultichange(Yexceptionschange,Ybodychange)",
    "869393643de23dcb010cc33091c8eb398de0fd6c": "Ymultichange(Yparameterchange,Yreturntypechange,Yexceptionschange,Ybodychange)",
    "03dea65e0b17ca2f9460bb6110f6ab3a321b8bf2": "Ymultichange(Yparameterchange,Ybodychange)",
    "c95b878abf313507666ea018f9e6033c4c166e10": "Ymultichange(Ymovefromfile,Ymodifierchange,Ybodychange,Yparameterchange)"
  },
  "changeHistoryDetails": {
    "9d175853b0170683ad5f21d9bcdeaac49fe89e04": {
      "type": "Ymultichange(Yexceptionschange,Ybodychange)",
      "commitMessage": "HDFS-10997. Reduce number of path resolving methods. Contributed by Daryn Sharp.\n",
      "commitDate": "24/10/16 3:14 PM",
      "commitName": "9d175853b0170683ad5f21d9bcdeaac49fe89e04",
      "commitAuthor": "Kihwal Lee",
      "subchanges": [
        {
          "type": "Yexceptionschange",
          "commitMessage": "HDFS-10997. Reduce number of path resolving methods. Contributed by Daryn Sharp.\n",
          "commitDate": "24/10/16 3:14 PM",
          "commitName": "9d175853b0170683ad5f21d9bcdeaac49fe89e04",
          "commitAuthor": "Kihwal Lee",
          "commitDateOld": "07/10/16 3:20 PM",
          "commitNameOld": "e57fa81d9559a93d77fd724f7792326c31a490be",
          "commitAuthorOld": "Kihwal Lee",
          "daysBetweenCommits": 17.0,
          "commitsBetweenForRepo": 108,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,19 +1,19 @@\n   INodesInPath resolvePath(FSPermissionChecker pc, String src, long fileId)\n       throws UnresolvedLinkException, FileNotFoundException,\n-      AccessControlException {\n+      AccessControlException, ParentNotDirectoryException {\n     // Older clients may not have given us an inode ID to work with.\n     // In this case, we have to try to resolve the path and hope it\n     // hasn\u0027t changed or been deleted since the file was opened for write.\n     INodesInPath iip;\n     if (fileId \u003d\u003d HdfsConstants.GRANDFATHER_INODE_ID) {\n-      iip \u003d resolvePath(pc, src);\n+      iip \u003d resolvePath(pc, src, DirOp.WRITE);\n     } else {\n       INode inode \u003d getInode(fileId);\n       if (inode \u003d\u003d null) {\n         iip \u003d INodesInPath.fromComponents(INode.getPathComponents(src));\n       } else {\n         iip \u003d INodesInPath.fromINode(inode);\n       }\n     }\n     return iip;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  INodesInPath resolvePath(FSPermissionChecker pc, String src, long fileId)\n      throws UnresolvedLinkException, FileNotFoundException,\n      AccessControlException, ParentNotDirectoryException {\n    // Older clients may not have given us an inode ID to work with.\n    // In this case, we have to try to resolve the path and hope it\n    // hasn\u0027t changed or been deleted since the file was opened for write.\n    INodesInPath iip;\n    if (fileId \u003d\u003d HdfsConstants.GRANDFATHER_INODE_ID) {\n      iip \u003d resolvePath(pc, src, DirOp.WRITE);\n    } else {\n      INode inode \u003d getInode(fileId);\n      if (inode \u003d\u003d null) {\n        iip \u003d INodesInPath.fromComponents(INode.getPathComponents(src));\n      } else {\n        iip \u003d INodesInPath.fromINode(inode);\n      }\n    }\n    return iip;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
          "extendedDetails": {
            "oldValue": "[UnresolvedLinkException, FileNotFoundException, AccessControlException]",
            "newValue": "[UnresolvedLinkException, FileNotFoundException, AccessControlException, ParentNotDirectoryException]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-10997. Reduce number of path resolving methods. Contributed by Daryn Sharp.\n",
          "commitDate": "24/10/16 3:14 PM",
          "commitName": "9d175853b0170683ad5f21d9bcdeaac49fe89e04",
          "commitAuthor": "Kihwal Lee",
          "commitDateOld": "07/10/16 3:20 PM",
          "commitNameOld": "e57fa81d9559a93d77fd724f7792326c31a490be",
          "commitAuthorOld": "Kihwal Lee",
          "daysBetweenCommits": 17.0,
          "commitsBetweenForRepo": 108,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,19 +1,19 @@\n   INodesInPath resolvePath(FSPermissionChecker pc, String src, long fileId)\n       throws UnresolvedLinkException, FileNotFoundException,\n-      AccessControlException {\n+      AccessControlException, ParentNotDirectoryException {\n     // Older clients may not have given us an inode ID to work with.\n     // In this case, we have to try to resolve the path and hope it\n     // hasn\u0027t changed or been deleted since the file was opened for write.\n     INodesInPath iip;\n     if (fileId \u003d\u003d HdfsConstants.GRANDFATHER_INODE_ID) {\n-      iip \u003d resolvePath(pc, src);\n+      iip \u003d resolvePath(pc, src, DirOp.WRITE);\n     } else {\n       INode inode \u003d getInode(fileId);\n       if (inode \u003d\u003d null) {\n         iip \u003d INodesInPath.fromComponents(INode.getPathComponents(src));\n       } else {\n         iip \u003d INodesInPath.fromINode(inode);\n       }\n     }\n     return iip;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  INodesInPath resolvePath(FSPermissionChecker pc, String src, long fileId)\n      throws UnresolvedLinkException, FileNotFoundException,\n      AccessControlException, ParentNotDirectoryException {\n    // Older clients may not have given us an inode ID to work with.\n    // In this case, we have to try to resolve the path and hope it\n    // hasn\u0027t changed or been deleted since the file was opened for write.\n    INodesInPath iip;\n    if (fileId \u003d\u003d HdfsConstants.GRANDFATHER_INODE_ID) {\n      iip \u003d resolvePath(pc, src, DirOp.WRITE);\n    } else {\n      INode inode \u003d getInode(fileId);\n      if (inode \u003d\u003d null) {\n        iip \u003d INodesInPath.fromComponents(INode.getPathComponents(src));\n      } else {\n        iip \u003d INodesInPath.fromINode(inode);\n      }\n    }\n    return iip;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
          "extendedDetails": {}
        }
      ]
    },
    "869393643de23dcb010cc33091c8eb398de0fd6c": {
      "type": "Ymultichange(Yparameterchange,Yreturntypechange,Yexceptionschange,Ybodychange)",
      "commitMessage": "HDFS-10745. Directly resolve paths into INodesInPath. Contributed by Daryn Sharp.\n",
      "commitDate": "17/08/16 1:53 PM",
      "commitName": "869393643de23dcb010cc33091c8eb398de0fd6c",
      "commitAuthor": "Kihwal Lee",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-10745. Directly resolve paths into INodesInPath. Contributed by Daryn Sharp.\n",
          "commitDate": "17/08/16 1:53 PM",
          "commitName": "869393643de23dcb010cc33091c8eb398de0fd6c",
          "commitAuthor": "Kihwal Lee",
          "commitDateOld": "15/08/16 2:45 PM",
          "commitNameOld": "03dea65e0b17ca2f9460bb6110f6ab3a321b8bf2",
          "commitAuthorOld": "Kihwal Lee",
          "daysBetweenCommits": 1.96,
          "commitsBetweenForRepo": 23,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,7 +1,19 @@\n-  String resolvePath(FSPermissionChecker pc, String path)\n-      throws FileNotFoundException, AccessControlException {\n-    if (isReservedRawName(path) \u0026\u0026 isPermissionEnabled) {\n-      pc.checkSuperuserPrivilege();\n+  INodesInPath resolvePath(FSPermissionChecker pc, String src, long fileId)\n+      throws UnresolvedLinkException, FileNotFoundException,\n+      AccessControlException {\n+    // Older clients may not have given us an inode ID to work with.\n+    // In this case, we have to try to resolve the path and hope it\n+    // hasn\u0027t changed or been deleted since the file was opened for write.\n+    INodesInPath iip;\n+    if (fileId \u003d\u003d HdfsConstants.GRANDFATHER_INODE_ID) {\n+      iip \u003d resolvePath(pc, src);\n+    } else {\n+      INode inode \u003d getInode(fileId);\n+      if (inode \u003d\u003d null) {\n+        iip \u003d INodesInPath.fromComponents(INode.getPathComponents(src));\n+      } else {\n+        iip \u003d INodesInPath.fromINode(inode);\n+      }\n     }\n-    return resolvePath(path, this);\n+    return iip;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  INodesInPath resolvePath(FSPermissionChecker pc, String src, long fileId)\n      throws UnresolvedLinkException, FileNotFoundException,\n      AccessControlException {\n    // Older clients may not have given us an inode ID to work with.\n    // In this case, we have to try to resolve the path and hope it\n    // hasn\u0027t changed or been deleted since the file was opened for write.\n    INodesInPath iip;\n    if (fileId \u003d\u003d HdfsConstants.GRANDFATHER_INODE_ID) {\n      iip \u003d resolvePath(pc, src);\n    } else {\n      INode inode \u003d getInode(fileId);\n      if (inode \u003d\u003d null) {\n        iip \u003d INodesInPath.fromComponents(INode.getPathComponents(src));\n      } else {\n        iip \u003d INodesInPath.fromINode(inode);\n      }\n    }\n    return iip;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
          "extendedDetails": {
            "oldValue": "[pc-FSPermissionChecker, path-String]",
            "newValue": "[pc-FSPermissionChecker, src-String, fileId-long]"
          }
        },
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-10745. Directly resolve paths into INodesInPath. Contributed by Daryn Sharp.\n",
          "commitDate": "17/08/16 1:53 PM",
          "commitName": "869393643de23dcb010cc33091c8eb398de0fd6c",
          "commitAuthor": "Kihwal Lee",
          "commitDateOld": "15/08/16 2:45 PM",
          "commitNameOld": "03dea65e0b17ca2f9460bb6110f6ab3a321b8bf2",
          "commitAuthorOld": "Kihwal Lee",
          "daysBetweenCommits": 1.96,
          "commitsBetweenForRepo": 23,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,7 +1,19 @@\n-  String resolvePath(FSPermissionChecker pc, String path)\n-      throws FileNotFoundException, AccessControlException {\n-    if (isReservedRawName(path) \u0026\u0026 isPermissionEnabled) {\n-      pc.checkSuperuserPrivilege();\n+  INodesInPath resolvePath(FSPermissionChecker pc, String src, long fileId)\n+      throws UnresolvedLinkException, FileNotFoundException,\n+      AccessControlException {\n+    // Older clients may not have given us an inode ID to work with.\n+    // In this case, we have to try to resolve the path and hope it\n+    // hasn\u0027t changed or been deleted since the file was opened for write.\n+    INodesInPath iip;\n+    if (fileId \u003d\u003d HdfsConstants.GRANDFATHER_INODE_ID) {\n+      iip \u003d resolvePath(pc, src);\n+    } else {\n+      INode inode \u003d getInode(fileId);\n+      if (inode \u003d\u003d null) {\n+        iip \u003d INodesInPath.fromComponents(INode.getPathComponents(src));\n+      } else {\n+        iip \u003d INodesInPath.fromINode(inode);\n+      }\n     }\n-    return resolvePath(path, this);\n+    return iip;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  INodesInPath resolvePath(FSPermissionChecker pc, String src, long fileId)\n      throws UnresolvedLinkException, FileNotFoundException,\n      AccessControlException {\n    // Older clients may not have given us an inode ID to work with.\n    // In this case, we have to try to resolve the path and hope it\n    // hasn\u0027t changed or been deleted since the file was opened for write.\n    INodesInPath iip;\n    if (fileId \u003d\u003d HdfsConstants.GRANDFATHER_INODE_ID) {\n      iip \u003d resolvePath(pc, src);\n    } else {\n      INode inode \u003d getInode(fileId);\n      if (inode \u003d\u003d null) {\n        iip \u003d INodesInPath.fromComponents(INode.getPathComponents(src));\n      } else {\n        iip \u003d INodesInPath.fromINode(inode);\n      }\n    }\n    return iip;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
          "extendedDetails": {
            "oldValue": "String",
            "newValue": "INodesInPath"
          }
        },
        {
          "type": "Yexceptionschange",
          "commitMessage": "HDFS-10745. Directly resolve paths into INodesInPath. Contributed by Daryn Sharp.\n",
          "commitDate": "17/08/16 1:53 PM",
          "commitName": "869393643de23dcb010cc33091c8eb398de0fd6c",
          "commitAuthor": "Kihwal Lee",
          "commitDateOld": "15/08/16 2:45 PM",
          "commitNameOld": "03dea65e0b17ca2f9460bb6110f6ab3a321b8bf2",
          "commitAuthorOld": "Kihwal Lee",
          "daysBetweenCommits": 1.96,
          "commitsBetweenForRepo": 23,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,7 +1,19 @@\n-  String resolvePath(FSPermissionChecker pc, String path)\n-      throws FileNotFoundException, AccessControlException {\n-    if (isReservedRawName(path) \u0026\u0026 isPermissionEnabled) {\n-      pc.checkSuperuserPrivilege();\n+  INodesInPath resolvePath(FSPermissionChecker pc, String src, long fileId)\n+      throws UnresolvedLinkException, FileNotFoundException,\n+      AccessControlException {\n+    // Older clients may not have given us an inode ID to work with.\n+    // In this case, we have to try to resolve the path and hope it\n+    // hasn\u0027t changed or been deleted since the file was opened for write.\n+    INodesInPath iip;\n+    if (fileId \u003d\u003d HdfsConstants.GRANDFATHER_INODE_ID) {\n+      iip \u003d resolvePath(pc, src);\n+    } else {\n+      INode inode \u003d getInode(fileId);\n+      if (inode \u003d\u003d null) {\n+        iip \u003d INodesInPath.fromComponents(INode.getPathComponents(src));\n+      } else {\n+        iip \u003d INodesInPath.fromINode(inode);\n+      }\n     }\n-    return resolvePath(path, this);\n+    return iip;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  INodesInPath resolvePath(FSPermissionChecker pc, String src, long fileId)\n      throws UnresolvedLinkException, FileNotFoundException,\n      AccessControlException {\n    // Older clients may not have given us an inode ID to work with.\n    // In this case, we have to try to resolve the path and hope it\n    // hasn\u0027t changed or been deleted since the file was opened for write.\n    INodesInPath iip;\n    if (fileId \u003d\u003d HdfsConstants.GRANDFATHER_INODE_ID) {\n      iip \u003d resolvePath(pc, src);\n    } else {\n      INode inode \u003d getInode(fileId);\n      if (inode \u003d\u003d null) {\n        iip \u003d INodesInPath.fromComponents(INode.getPathComponents(src));\n      } else {\n        iip \u003d INodesInPath.fromINode(inode);\n      }\n    }\n    return iip;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
          "extendedDetails": {
            "oldValue": "[FileNotFoundException, AccessControlException]",
            "newValue": "[UnresolvedLinkException, FileNotFoundException, AccessControlException]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-10745. Directly resolve paths into INodesInPath. Contributed by Daryn Sharp.\n",
          "commitDate": "17/08/16 1:53 PM",
          "commitName": "869393643de23dcb010cc33091c8eb398de0fd6c",
          "commitAuthor": "Kihwal Lee",
          "commitDateOld": "15/08/16 2:45 PM",
          "commitNameOld": "03dea65e0b17ca2f9460bb6110f6ab3a321b8bf2",
          "commitAuthorOld": "Kihwal Lee",
          "daysBetweenCommits": 1.96,
          "commitsBetweenForRepo": 23,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,7 +1,19 @@\n-  String resolvePath(FSPermissionChecker pc, String path)\n-      throws FileNotFoundException, AccessControlException {\n-    if (isReservedRawName(path) \u0026\u0026 isPermissionEnabled) {\n-      pc.checkSuperuserPrivilege();\n+  INodesInPath resolvePath(FSPermissionChecker pc, String src, long fileId)\n+      throws UnresolvedLinkException, FileNotFoundException,\n+      AccessControlException {\n+    // Older clients may not have given us an inode ID to work with.\n+    // In this case, we have to try to resolve the path and hope it\n+    // hasn\u0027t changed or been deleted since the file was opened for write.\n+    INodesInPath iip;\n+    if (fileId \u003d\u003d HdfsConstants.GRANDFATHER_INODE_ID) {\n+      iip \u003d resolvePath(pc, src);\n+    } else {\n+      INode inode \u003d getInode(fileId);\n+      if (inode \u003d\u003d null) {\n+        iip \u003d INodesInPath.fromComponents(INode.getPathComponents(src));\n+      } else {\n+        iip \u003d INodesInPath.fromINode(inode);\n+      }\n     }\n-    return resolvePath(path, this);\n+    return iip;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  INodesInPath resolvePath(FSPermissionChecker pc, String src, long fileId)\n      throws UnresolvedLinkException, FileNotFoundException,\n      AccessControlException {\n    // Older clients may not have given us an inode ID to work with.\n    // In this case, we have to try to resolve the path and hope it\n    // hasn\u0027t changed or been deleted since the file was opened for write.\n    INodesInPath iip;\n    if (fileId \u003d\u003d HdfsConstants.GRANDFATHER_INODE_ID) {\n      iip \u003d resolvePath(pc, src);\n    } else {\n      INode inode \u003d getInode(fileId);\n      if (inode \u003d\u003d null) {\n        iip \u003d INodesInPath.fromComponents(INode.getPathComponents(src));\n      } else {\n        iip \u003d INodesInPath.fromINode(inode);\n      }\n    }\n    return iip;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
          "extendedDetails": {}
        }
      ]
    },
    "03dea65e0b17ca2f9460bb6110f6ab3a321b8bf2": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-10744. Internally optimize path component resolution. Contributed by Daryn Sharp.\n",
      "commitDate": "15/08/16 2:45 PM",
      "commitName": "03dea65e0b17ca2f9460bb6110f6ab3a321b8bf2",
      "commitAuthor": "Kihwal Lee",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-10744. Internally optimize path component resolution. Contributed by Daryn Sharp.\n",
          "commitDate": "15/08/16 2:45 PM",
          "commitName": "03dea65e0b17ca2f9460bb6110f6ab3a321b8bf2",
          "commitAuthor": "Kihwal Lee",
          "commitDateOld": "12/08/16 5:58 AM",
          "commitNameOld": "9019606b69bfb7019c8642b6cbcbb93645cc19e3",
          "commitAuthorOld": "Wei-Chiu Chuang",
          "daysBetweenCommits": 3.37,
          "commitsBetweenForRepo": 8,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,7 +1,7 @@\n-  String resolvePath(FSPermissionChecker pc, String path, byte[][] pathComponents)\n+  String resolvePath(FSPermissionChecker pc, String path)\n       throws FileNotFoundException, AccessControlException {\n     if (isReservedRawName(path) \u0026\u0026 isPermissionEnabled) {\n       pc.checkSuperuserPrivilege();\n     }\n-    return resolvePath(path, pathComponents, this);\n+    return resolvePath(path, this);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  String resolvePath(FSPermissionChecker pc, String path)\n      throws FileNotFoundException, AccessControlException {\n    if (isReservedRawName(path) \u0026\u0026 isPermissionEnabled) {\n      pc.checkSuperuserPrivilege();\n    }\n    return resolvePath(path, this);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
          "extendedDetails": {
            "oldValue": "[pc-FSPermissionChecker, path-String, pathComponents-byte[][]]",
            "newValue": "[pc-FSPermissionChecker, path-String]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-10744. Internally optimize path component resolution. Contributed by Daryn Sharp.\n",
          "commitDate": "15/08/16 2:45 PM",
          "commitName": "03dea65e0b17ca2f9460bb6110f6ab3a321b8bf2",
          "commitAuthor": "Kihwal Lee",
          "commitDateOld": "12/08/16 5:58 AM",
          "commitNameOld": "9019606b69bfb7019c8642b6cbcbb93645cc19e3",
          "commitAuthorOld": "Wei-Chiu Chuang",
          "daysBetweenCommits": 3.37,
          "commitsBetweenForRepo": 8,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,7 +1,7 @@\n-  String resolvePath(FSPermissionChecker pc, String path, byte[][] pathComponents)\n+  String resolvePath(FSPermissionChecker pc, String path)\n       throws FileNotFoundException, AccessControlException {\n     if (isReservedRawName(path) \u0026\u0026 isPermissionEnabled) {\n       pc.checkSuperuserPrivilege();\n     }\n-    return resolvePath(path, pathComponents, this);\n+    return resolvePath(path, this);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  String resolvePath(FSPermissionChecker pc, String path)\n      throws FileNotFoundException, AccessControlException {\n    if (isReservedRawName(path) \u0026\u0026 isPermissionEnabled) {\n      pc.checkSuperuserPrivilege();\n    }\n    return resolvePath(path, this);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
          "extendedDetails": {}
        }
      ]
    },
    "c95b878abf313507666ea018f9e6033c4c166e10": {
      "type": "Ymultichange(Ymovefromfile,Ymodifierchange,Ybodychange,Yparameterchange)",
      "commitMessage": "HDFS-7415. Move FSNameSystem.resolvePath() to FSDirectory. Contributed by Haohui Mai.\n",
      "commitDate": "20/11/14 7:23 PM",
      "commitName": "c95b878abf313507666ea018f9e6033c4c166e10",
      "commitAuthor": "Haohui Mai",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-7415. Move FSNameSystem.resolvePath() to FSDirectory. Contributed by Haohui Mai.\n",
          "commitDate": "20/11/14 7:23 PM",
          "commitName": "c95b878abf313507666ea018f9e6033c4c166e10",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "20/11/14 3:36 PM",
          "commitNameOld": "90194ca1cbd695d48c3705121c2ac9a8554578a2",
          "commitAuthorOld": "Karthik Kambatla",
          "daysBetweenCommits": 0.16,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,7 +1,7 @@\n-  private String resolvePath(String path, byte[][] pathComponents)\n+  String resolvePath(FSPermissionChecker pc, String path, byte[][] pathComponents)\n       throws FileNotFoundException, AccessControlException {\n-    if (FSDirectory.isReservedRawName(path)) {\n-      checkSuperuserPrivilege();\n+    if (isReservedRawName(path) \u0026\u0026 isPermissionEnabled) {\n+      pc.checkSuperuserPrivilege();\n     }\n-    return FSDirectory.resolvePath(path, pathComponents, dir);\n+    return resolvePath(path, pathComponents, this);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  String resolvePath(FSPermissionChecker pc, String path, byte[][] pathComponents)\n      throws FileNotFoundException, AccessControlException {\n    if (isReservedRawName(path) \u0026\u0026 isPermissionEnabled) {\n      pc.checkSuperuserPrivilege();\n    }\n    return resolvePath(path, pathComponents, this);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
            "oldMethodName": "resolvePath",
            "newMethodName": "resolvePath"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-7415. Move FSNameSystem.resolvePath() to FSDirectory. Contributed by Haohui Mai.\n",
          "commitDate": "20/11/14 7:23 PM",
          "commitName": "c95b878abf313507666ea018f9e6033c4c166e10",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "20/11/14 3:36 PM",
          "commitNameOld": "90194ca1cbd695d48c3705121c2ac9a8554578a2",
          "commitAuthorOld": "Karthik Kambatla",
          "daysBetweenCommits": 0.16,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,7 +1,7 @@\n-  private String resolvePath(String path, byte[][] pathComponents)\n+  String resolvePath(FSPermissionChecker pc, String path, byte[][] pathComponents)\n       throws FileNotFoundException, AccessControlException {\n-    if (FSDirectory.isReservedRawName(path)) {\n-      checkSuperuserPrivilege();\n+    if (isReservedRawName(path) \u0026\u0026 isPermissionEnabled) {\n+      pc.checkSuperuserPrivilege();\n     }\n-    return FSDirectory.resolvePath(path, pathComponents, dir);\n+    return resolvePath(path, pathComponents, this);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  String resolvePath(FSPermissionChecker pc, String path, byte[][] pathComponents)\n      throws FileNotFoundException, AccessControlException {\n    if (isReservedRawName(path) \u0026\u0026 isPermissionEnabled) {\n      pc.checkSuperuserPrivilege();\n    }\n    return resolvePath(path, pathComponents, this);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
          "extendedDetails": {
            "oldValue": "[private]",
            "newValue": "[]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7415. Move FSNameSystem.resolvePath() to FSDirectory. Contributed by Haohui Mai.\n",
          "commitDate": "20/11/14 7:23 PM",
          "commitName": "c95b878abf313507666ea018f9e6033c4c166e10",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "20/11/14 3:36 PM",
          "commitNameOld": "90194ca1cbd695d48c3705121c2ac9a8554578a2",
          "commitAuthorOld": "Karthik Kambatla",
          "daysBetweenCommits": 0.16,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,7 +1,7 @@\n-  private String resolvePath(String path, byte[][] pathComponents)\n+  String resolvePath(FSPermissionChecker pc, String path, byte[][] pathComponents)\n       throws FileNotFoundException, AccessControlException {\n-    if (FSDirectory.isReservedRawName(path)) {\n-      checkSuperuserPrivilege();\n+    if (isReservedRawName(path) \u0026\u0026 isPermissionEnabled) {\n+      pc.checkSuperuserPrivilege();\n     }\n-    return FSDirectory.resolvePath(path, pathComponents, dir);\n+    return resolvePath(path, pathComponents, this);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  String resolvePath(FSPermissionChecker pc, String path, byte[][] pathComponents)\n      throws FileNotFoundException, AccessControlException {\n    if (isReservedRawName(path) \u0026\u0026 isPermissionEnabled) {\n      pc.checkSuperuserPrivilege();\n    }\n    return resolvePath(path, pathComponents, this);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
          "extendedDetails": {}
        },
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-7415. Move FSNameSystem.resolvePath() to FSDirectory. Contributed by Haohui Mai.\n",
          "commitDate": "20/11/14 7:23 PM",
          "commitName": "c95b878abf313507666ea018f9e6033c4c166e10",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "20/11/14 3:36 PM",
          "commitNameOld": "90194ca1cbd695d48c3705121c2ac9a8554578a2",
          "commitAuthorOld": "Karthik Kambatla",
          "daysBetweenCommits": 0.16,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,7 +1,7 @@\n-  private String resolvePath(String path, byte[][] pathComponents)\n+  String resolvePath(FSPermissionChecker pc, String path, byte[][] pathComponents)\n       throws FileNotFoundException, AccessControlException {\n-    if (FSDirectory.isReservedRawName(path)) {\n-      checkSuperuserPrivilege();\n+    if (isReservedRawName(path) \u0026\u0026 isPermissionEnabled) {\n+      pc.checkSuperuserPrivilege();\n     }\n-    return FSDirectory.resolvePath(path, pathComponents, dir);\n+    return resolvePath(path, pathComponents, this);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  String resolvePath(FSPermissionChecker pc, String path, byte[][] pathComponents)\n      throws FileNotFoundException, AccessControlException {\n    if (isReservedRawName(path) \u0026\u0026 isPermissionEnabled) {\n      pc.checkSuperuserPrivilege();\n    }\n    return resolvePath(path, pathComponents, this);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
          "extendedDetails": {
            "oldValue": "[path-String, pathComponents-byte[][]]",
            "newValue": "[pc-FSPermissionChecker, path-String, pathComponents-byte[][]]"
          }
        }
      ]
    }
  }
}