{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "IOUtilsClient.java",
  "functionName": "updateReadStatistics",
  "functionId": "updateReadStatistics___readStatistics-ReadStatistics__nRead-int__blockReader-BlockReader",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/util/IOUtilsClient.java",
  "functionStartLine": 49,
  "functionEndLine": 53,
  "numCommitsSeen": 108,
  "timeTaken": 5668,
  "changeHistory": [
    "08bb6c49a5aec32b7d9f29238560f947420405d6",
    "793447f79924c97c2b562d5e41fa85adf19673fe",
    "cd8b6889a74a949e37f4b2eb664cdf3b59bfb93b",
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c",
    "bff5999d07e9416a22846c849487e509ede55040",
    "45ea53f9388e6bff1ac0aa3989a1dad56a611fd3",
    "daaa8f03f411652da7b7919e16e0fbe24367f106",
    "4ed1fc58c0683bbcd5c4c211ea162ed37bf7dc4f"
  ],
  "changeHistoryShort": {
    "08bb6c49a5aec32b7d9f29238560f947420405d6": "Ybodychange",
    "793447f79924c97c2b562d5e41fa85adf19673fe": "Ymultichange(Ymovefromfile,Ymodifierchange,Ybodychange)",
    "cd8b6889a74a949e37f4b2eb664cdf3b59bfb93b": "Ybodychange",
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c": "Yfilerename",
    "bff5999d07e9416a22846c849487e509ede55040": "Ymodifierchange",
    "45ea53f9388e6bff1ac0aa3989a1dad56a611fd3": "Ymultichange(Ymodifierchange,Ybodychange)",
    "daaa8f03f411652da7b7919e16e0fbe24367f106": "Ybodychange",
    "4ed1fc58c0683bbcd5c4c211ea162ed37bf7dc4f": "Yintroduced"
  },
  "changeHistoryDetails": {
    "08bb6c49a5aec32b7d9f29238560f947420405d6": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13926. ThreadLocal aggregations for FileSystem.Statistics are incorrect with striped reads.\nContributed by Xiao Chen, Hrishikesh Gadre.\n\nSigned-off-by: Xiao Chen \u003cxiao@apache.org\u003e\n",
      "commitDate": "08/10/18 8:31 PM",
      "commitName": "08bb6c49a5aec32b7d9f29238560f947420405d6",
      "commitAuthor": "Hrishikesh Gadre",
      "commitDateOld": "06/09/18 2:48 PM",
      "commitNameOld": "eca1a4bfe952fc184fe90dde50bac9b0e5293568",
      "commitAuthorOld": "Giovanni Matteo Fumarola",
      "daysBetweenCommits": 32.24,
      "commitsBetweenForRepo": 319,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,5 @@\n   public static void updateReadStatistics(ReadStatistics readStatistics,\n                                       int nRead, BlockReader blockReader) {\n-    if (nRead \u003c\u003d 0) {\n-      return;\n-    }\n-\n-    if (blockReader.isShortCircuit()) {\n-      readStatistics.addShortCircuitBytes(nRead);\n-    } else if (blockReader.getNetworkDistance() \u003d\u003d 0) {\n-      readStatistics.addLocalBytes(nRead);\n-    } else {\n-      readStatistics.addRemoteBytes(nRead);\n-    }\n+    updateReadStatistics(readStatistics, nRead, blockReader.isShortCircuit(),\n+        blockReader.getNetworkDistance());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static void updateReadStatistics(ReadStatistics readStatistics,\n                                      int nRead, BlockReader blockReader) {\n    updateReadStatistics(readStatistics, nRead, blockReader.isShortCircuit(),\n        blockReader.getNetworkDistance());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/util/IOUtilsClient.java",
      "extendedDetails": {}
    },
    "793447f79924c97c2b562d5e41fa85adf19673fe": {
      "type": "Ymultichange(Ymovefromfile,Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-8905. Refactor DFSInputStream#ReaderStrategy. Contributed by Kai Zheng and Sammi Chen\n",
      "commitDate": "24/08/16 6:57 AM",
      "commitName": "793447f79924c97c2b562d5e41fa85adf19673fe",
      "commitAuthor": "Kai Zheng",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-8905. Refactor DFSInputStream#ReaderStrategy. Contributed by Kai Zheng and Sammi Chen\n",
          "commitDate": "24/08/16 6:57 AM",
          "commitName": "793447f79924c97c2b562d5e41fa85adf19673fe",
          "commitAuthor": "Kai Zheng",
          "commitDateOld": "24/08/16 6:46 AM",
          "commitNameOld": "ec252ce0fc0998ce13f31af3440c08a236328e5a",
          "commitAuthorOld": "Daryn Sharp",
          "daysBetweenCommits": 0.01,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,13 +1,14 @@\n-  protected void updateReadStatistics(ReadStatistics readStatistics,\n-        int nRead, BlockReader blockReader) {\n-    if (nRead \u003c\u003d 0) return;\n-    synchronized(infoLock) {\n-      if (blockReader.isShortCircuit()) {\n-        readStatistics.addShortCircuitBytes(nRead);\n-      } else if (blockReader.getNetworkDistance() \u003d\u003d 0) {\n-        readStatistics.addLocalBytes(nRead);\n-      } else {\n-        readStatistics.addRemoteBytes(nRead);\n-      }\n+  public static void updateReadStatistics(ReadStatistics readStatistics,\n+                                      int nRead, BlockReader blockReader) {\n+    if (nRead \u003c\u003d 0) {\n+      return;\n+    }\n+\n+    if (blockReader.isShortCircuit()) {\n+      readStatistics.addShortCircuitBytes(nRead);\n+    } else if (blockReader.getNetworkDistance() \u003d\u003d 0) {\n+      readStatistics.addLocalBytes(nRead);\n+    } else {\n+      readStatistics.addRemoteBytes(nRead);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static void updateReadStatistics(ReadStatistics readStatistics,\n                                      int nRead, BlockReader blockReader) {\n    if (nRead \u003c\u003d 0) {\n      return;\n    }\n\n    if (blockReader.isShortCircuit()) {\n      readStatistics.addShortCircuitBytes(nRead);\n    } else if (blockReader.getNetworkDistance() \u003d\u003d 0) {\n      readStatistics.addLocalBytes(nRead);\n    } else {\n      readStatistics.addRemoteBytes(nRead);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/util/IOUtilsClient.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/util/IOUtilsClient.java",
            "oldMethodName": "updateReadStatistics",
            "newMethodName": "updateReadStatistics"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-8905. Refactor DFSInputStream#ReaderStrategy. Contributed by Kai Zheng and Sammi Chen\n",
          "commitDate": "24/08/16 6:57 AM",
          "commitName": "793447f79924c97c2b562d5e41fa85adf19673fe",
          "commitAuthor": "Kai Zheng",
          "commitDateOld": "24/08/16 6:46 AM",
          "commitNameOld": "ec252ce0fc0998ce13f31af3440c08a236328e5a",
          "commitAuthorOld": "Daryn Sharp",
          "daysBetweenCommits": 0.01,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,13 +1,14 @@\n-  protected void updateReadStatistics(ReadStatistics readStatistics,\n-        int nRead, BlockReader blockReader) {\n-    if (nRead \u003c\u003d 0) return;\n-    synchronized(infoLock) {\n-      if (blockReader.isShortCircuit()) {\n-        readStatistics.addShortCircuitBytes(nRead);\n-      } else if (blockReader.getNetworkDistance() \u003d\u003d 0) {\n-        readStatistics.addLocalBytes(nRead);\n-      } else {\n-        readStatistics.addRemoteBytes(nRead);\n-      }\n+  public static void updateReadStatistics(ReadStatistics readStatistics,\n+                                      int nRead, BlockReader blockReader) {\n+    if (nRead \u003c\u003d 0) {\n+      return;\n+    }\n+\n+    if (blockReader.isShortCircuit()) {\n+      readStatistics.addShortCircuitBytes(nRead);\n+    } else if (blockReader.getNetworkDistance() \u003d\u003d 0) {\n+      readStatistics.addLocalBytes(nRead);\n+    } else {\n+      readStatistics.addRemoteBytes(nRead);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static void updateReadStatistics(ReadStatistics readStatistics,\n                                      int nRead, BlockReader blockReader) {\n    if (nRead \u003c\u003d 0) {\n      return;\n    }\n\n    if (blockReader.isShortCircuit()) {\n      readStatistics.addShortCircuitBytes(nRead);\n    } else if (blockReader.getNetworkDistance() \u003d\u003d 0) {\n      readStatistics.addLocalBytes(nRead);\n    } else {\n      readStatistics.addRemoteBytes(nRead);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/util/IOUtilsClient.java",
          "extendedDetails": {
            "oldValue": "[protected]",
            "newValue": "[public, static]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-8905. Refactor DFSInputStream#ReaderStrategy. Contributed by Kai Zheng and Sammi Chen\n",
          "commitDate": "24/08/16 6:57 AM",
          "commitName": "793447f79924c97c2b562d5e41fa85adf19673fe",
          "commitAuthor": "Kai Zheng",
          "commitDateOld": "24/08/16 6:46 AM",
          "commitNameOld": "ec252ce0fc0998ce13f31af3440c08a236328e5a",
          "commitAuthorOld": "Daryn Sharp",
          "daysBetweenCommits": 0.01,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,13 +1,14 @@\n-  protected void updateReadStatistics(ReadStatistics readStatistics,\n-        int nRead, BlockReader blockReader) {\n-    if (nRead \u003c\u003d 0) return;\n-    synchronized(infoLock) {\n-      if (blockReader.isShortCircuit()) {\n-        readStatistics.addShortCircuitBytes(nRead);\n-      } else if (blockReader.getNetworkDistance() \u003d\u003d 0) {\n-        readStatistics.addLocalBytes(nRead);\n-      } else {\n-        readStatistics.addRemoteBytes(nRead);\n-      }\n+  public static void updateReadStatistics(ReadStatistics readStatistics,\n+                                      int nRead, BlockReader blockReader) {\n+    if (nRead \u003c\u003d 0) {\n+      return;\n+    }\n+\n+    if (blockReader.isShortCircuit()) {\n+      readStatistics.addShortCircuitBytes(nRead);\n+    } else if (blockReader.getNetworkDistance() \u003d\u003d 0) {\n+      readStatistics.addLocalBytes(nRead);\n+    } else {\n+      readStatistics.addRemoteBytes(nRead);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static void updateReadStatistics(ReadStatistics readStatistics,\n                                      int nRead, BlockReader blockReader) {\n    if (nRead \u003c\u003d 0) {\n      return;\n    }\n\n    if (blockReader.isShortCircuit()) {\n      readStatistics.addShortCircuitBytes(nRead);\n    } else if (blockReader.getNetworkDistance() \u003d\u003d 0) {\n      readStatistics.addLocalBytes(nRead);\n    } else {\n      readStatistics.addRemoteBytes(nRead);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/util/IOUtilsClient.java",
          "extendedDetails": {}
        }
      ]
    },
    "cd8b6889a74a949e37f4b2eb664cdf3b59bfb93b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9579. Provide bytes-read-by-network-distance metrics at FileSystem.Statistics level (Ming Ma via sjlee)\n",
      "commitDate": "19/03/16 2:02 PM",
      "commitName": "cd8b6889a74a949e37f4b2eb664cdf3b59bfb93b",
      "commitAuthor": "Sangjin Lee",
      "commitDateOld": "25/02/16 9:55 AM",
      "commitNameOld": "8808779db351fe444388d4acb3094766b5980718",
      "commitAuthorOld": "Zhe Zhang",
      "daysBetweenCommits": 23.13,
      "commitsBetweenForRepo": 135,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,13 @@\n   protected void updateReadStatistics(ReadStatistics readStatistics,\n         int nRead, BlockReader blockReader) {\n     if (nRead \u003c\u003d 0) return;\n     synchronized(infoLock) {\n       if (blockReader.isShortCircuit()) {\n         readStatistics.addShortCircuitBytes(nRead);\n-      } else if (blockReader.isLocal()) {\n+      } else if (blockReader.getNetworkDistance() \u003d\u003d 0) {\n         readStatistics.addLocalBytes(nRead);\n       } else {\n         readStatistics.addRemoteBytes(nRead);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void updateReadStatistics(ReadStatistics readStatistics,\n        int nRead, BlockReader blockReader) {\n    if (nRead \u003c\u003d 0) return;\n    synchronized(infoLock) {\n      if (blockReader.isShortCircuit()) {\n        readStatistics.addShortCircuitBytes(nRead);\n      } else if (blockReader.getNetworkDistance() \u003d\u003d 0) {\n        readStatistics.addLocalBytes(nRead);\n      } else {\n        readStatistics.addRemoteBytes(nRead);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8053. Move DFSIn/OutputStream and related classes to hadoop-hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "26/09/15 11:08 AM",
      "commitName": "bf37d3d80e5179dea27e5bd5aea804a38aa9934c",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "26/09/15 9:06 AM",
      "commitNameOld": "861b52db242f238d7e36ad75c158025be959a696",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 0.08,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  protected void updateReadStatistics(ReadStatistics readStatistics,\n        int nRead, BlockReader blockReader) {\n    if (nRead \u003c\u003d 0) return;\n    synchronized(infoLock) {\n      if (blockReader.isShortCircuit()) {\n        readStatistics.addShortCircuitBytes(nRead);\n      } else if (blockReader.isLocal()) {\n        readStatistics.addLocalBytes(nRead);\n      } else {\n        readStatistics.addRemoteBytes(nRead);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java"
      }
    },
    "bff5999d07e9416a22846c849487e509ede55040": {
      "type": "Ymodifierchange",
      "commitMessage": "HDFS-8703. Merge refactor of DFSInputStream from ErasureCoding branch (Contributed by Vinayakumar B)\n",
      "commitDate": "02/07/15 3:41 AM",
      "commitName": "bff5999d07e9416a22846c849487e509ede55040",
      "commitAuthor": "Vinayakumar B",
      "commitDateOld": "04/06/15 10:51 AM",
      "commitNameOld": "ade6d9a61eb2e57a975f0efcdf8828d51ffec5fd",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 27.7,
      "commitsBetweenForRepo": 196,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,13 @@\n-  private void updateReadStatistics(ReadStatistics readStatistics, \n+  protected void updateReadStatistics(ReadStatistics readStatistics,\n         int nRead, BlockReader blockReader) {\n     if (nRead \u003c\u003d 0) return;\n     synchronized(infoLock) {\n       if (blockReader.isShortCircuit()) {\n         readStatistics.addShortCircuitBytes(nRead);\n       } else if (blockReader.isLocal()) {\n         readStatistics.addLocalBytes(nRead);\n       } else {\n         readStatistics.addRemoteBytes(nRead);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void updateReadStatistics(ReadStatistics readStatistics,\n        int nRead, BlockReader blockReader) {\n    if (nRead \u003c\u003d 0) return;\n    synchronized(infoLock) {\n      if (blockReader.isShortCircuit()) {\n        readStatistics.addShortCircuitBytes(nRead);\n      } else if (blockReader.isLocal()) {\n        readStatistics.addLocalBytes(nRead);\n      } else {\n        readStatistics.addRemoteBytes(nRead);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {
        "oldValue": "[private]",
        "newValue": "[protected]"
      }
    },
    "45ea53f9388e6bff1ac0aa3989a1dad56a611fd3": {
      "type": "Ymultichange(Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-7698. Fix locking on HDFS read statistics and add a method for clearing them. (Colin P. McCabe via yliu)\n",
      "commitDate": "05/02/15 7:56 AM",
      "commitName": "45ea53f9388e6bff1ac0aa3989a1dad56a611fd3",
      "commitAuthor": "yliu",
      "subchanges": [
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-7698. Fix locking on HDFS read statistics and add a method for clearing them. (Colin P. McCabe via yliu)\n",
          "commitDate": "05/02/15 7:56 AM",
          "commitName": "45ea53f9388e6bff1ac0aa3989a1dad56a611fd3",
          "commitAuthor": "yliu",
          "commitDateOld": "30/01/15 4:01 PM",
          "commitNameOld": "09ad9a868a89922e9b55b3e7c5b9f41fa54d3770",
          "commitAuthorOld": "Colin Patrick Mccabe",
          "daysBetweenCommits": 5.66,
          "commitsBetweenForRepo": 61,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,13 @@\n-  private static void updateReadStatistics(ReadStatistics readStatistics, \n+  private void updateReadStatistics(ReadStatistics readStatistics, \n         int nRead, BlockReader blockReader) {\n     if (nRead \u003c\u003d 0) return;\n-    if (blockReader.isShortCircuit()) {\n-      readStatistics.addShortCircuitBytes(nRead);\n-    } else if (blockReader.isLocal()) {\n-      readStatistics.addLocalBytes(nRead);\n-    } else {\n-      readStatistics.addRemoteBytes(nRead);\n+    synchronized(infoLock) {\n+      if (blockReader.isShortCircuit()) {\n+        readStatistics.addShortCircuitBytes(nRead);\n+      } else if (blockReader.isLocal()) {\n+        readStatistics.addLocalBytes(nRead);\n+      } else {\n+        readStatistics.addRemoteBytes(nRead);\n+      }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void updateReadStatistics(ReadStatistics readStatistics, \n        int nRead, BlockReader blockReader) {\n    if (nRead \u003c\u003d 0) return;\n    synchronized(infoLock) {\n      if (blockReader.isShortCircuit()) {\n        readStatistics.addShortCircuitBytes(nRead);\n      } else if (blockReader.isLocal()) {\n        readStatistics.addLocalBytes(nRead);\n      } else {\n        readStatistics.addRemoteBytes(nRead);\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
          "extendedDetails": {
            "oldValue": "[private, static]",
            "newValue": "[private]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7698. Fix locking on HDFS read statistics and add a method for clearing them. (Colin P. McCabe via yliu)\n",
          "commitDate": "05/02/15 7:56 AM",
          "commitName": "45ea53f9388e6bff1ac0aa3989a1dad56a611fd3",
          "commitAuthor": "yliu",
          "commitDateOld": "30/01/15 4:01 PM",
          "commitNameOld": "09ad9a868a89922e9b55b3e7c5b9f41fa54d3770",
          "commitAuthorOld": "Colin Patrick Mccabe",
          "daysBetweenCommits": 5.66,
          "commitsBetweenForRepo": 61,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,13 @@\n-  private static void updateReadStatistics(ReadStatistics readStatistics, \n+  private void updateReadStatistics(ReadStatistics readStatistics, \n         int nRead, BlockReader blockReader) {\n     if (nRead \u003c\u003d 0) return;\n-    if (blockReader.isShortCircuit()) {\n-      readStatistics.addShortCircuitBytes(nRead);\n-    } else if (blockReader.isLocal()) {\n-      readStatistics.addLocalBytes(nRead);\n-    } else {\n-      readStatistics.addRemoteBytes(nRead);\n+    synchronized(infoLock) {\n+      if (blockReader.isShortCircuit()) {\n+        readStatistics.addShortCircuitBytes(nRead);\n+      } else if (blockReader.isLocal()) {\n+        readStatistics.addLocalBytes(nRead);\n+      } else {\n+        readStatistics.addRemoteBytes(nRead);\n+      }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void updateReadStatistics(ReadStatistics readStatistics, \n        int nRead, BlockReader blockReader) {\n    if (nRead \u003c\u003d 0) return;\n    synchronized(infoLock) {\n      if (blockReader.isShortCircuit()) {\n        readStatistics.addShortCircuitBytes(nRead);\n      } else if (blockReader.isLocal()) {\n        readStatistics.addLocalBytes(nRead);\n      } else {\n        readStatistics.addRemoteBytes(nRead);\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
          "extendedDetails": {}
        }
      ]
    },
    "daaa8f03f411652da7b7919e16e0fbe24367f106": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6070. Cleanup use of ReadStatistics in DFSInputStream.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1576047 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/03/14 12:04 PM",
      "commitName": "daaa8f03f411652da7b7919e16e0fbe24367f106",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "06/03/14 5:18 PM",
      "commitNameOld": "173c1159519b6a1885c604b9891a31011b0bcc85",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 3.74,
      "commitsBetweenForRepo": 24,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,11 @@\n   private static void updateReadStatistics(ReadStatistics readStatistics, \n         int nRead, BlockReader blockReader) {\n     if (nRead \u003c\u003d 0) return;\n     if (blockReader.isShortCircuit()) {\n-      readStatistics.totalBytesRead +\u003d nRead;\n-      readStatistics.totalLocalBytesRead +\u003d nRead;\n-      readStatistics.totalShortCircuitBytesRead +\u003d nRead;\n+      readStatistics.addShortCircuitBytes(nRead);\n     } else if (blockReader.isLocal()) {\n-      readStatistics.totalBytesRead +\u003d nRead;\n-      readStatistics.totalLocalBytesRead +\u003d nRead;\n+      readStatistics.addLocalBytes(nRead);\n     } else {\n-      readStatistics.totalBytesRead +\u003d nRead;\n+      readStatistics.addRemoteBytes(nRead);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private static void updateReadStatistics(ReadStatistics readStatistics, \n        int nRead, BlockReader blockReader) {\n    if (nRead \u003c\u003d 0) return;\n    if (blockReader.isShortCircuit()) {\n      readStatistics.addShortCircuitBytes(nRead);\n    } else if (blockReader.isLocal()) {\n      readStatistics.addLocalBytes(nRead);\n    } else {\n      readStatistics.addRemoteBytes(nRead);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "4ed1fc58c0683bbcd5c4c211ea162ed37bf7dc4f": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-4698. Provide client-side metrics for remote reads, local reads, and short-circuit reads. Contributed by Colin Patrick McCabe.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1481121 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/05/13 10:58 AM",
      "commitName": "4ed1fc58c0683bbcd5c4c211ea162ed37bf7dc4f",
      "commitAuthor": "Aaron Myers",
      "diff": "@@ -0,0 +1,14 @@\n+  private static void updateReadStatistics(ReadStatistics readStatistics, \n+        int nRead, BlockReader blockReader) {\n+    if (nRead \u003c\u003d 0) return;\n+    if (blockReader.isShortCircuit()) {\n+      readStatistics.totalBytesRead +\u003d nRead;\n+      readStatistics.totalLocalBytesRead +\u003d nRead;\n+      readStatistics.totalShortCircuitBytesRead +\u003d nRead;\n+    } else if (blockReader.isLocal()) {\n+      readStatistics.totalBytesRead +\u003d nRead;\n+      readStatistics.totalLocalBytesRead +\u003d nRead;\n+    } else {\n+      readStatistics.totalBytesRead +\u003d nRead;\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private static void updateReadStatistics(ReadStatistics readStatistics, \n        int nRead, BlockReader blockReader) {\n    if (nRead \u003c\u003d 0) return;\n    if (blockReader.isShortCircuit()) {\n      readStatistics.totalBytesRead +\u003d nRead;\n      readStatistics.totalLocalBytesRead +\u003d nRead;\n      readStatistics.totalShortCircuitBytesRead +\u003d nRead;\n    } else if (blockReader.isLocal()) {\n      readStatistics.totalBytesRead +\u003d nRead;\n      readStatistics.totalLocalBytesRead +\u003d nRead;\n    } else {\n      readStatistics.totalBytesRead +\u003d nRead;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java"
    }
  }
}