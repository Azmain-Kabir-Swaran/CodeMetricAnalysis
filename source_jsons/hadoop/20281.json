{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "Task.java",
  "functionName": "checkTaskLimits",
  "functionId": "checkTaskLimits",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/Task.java",
  "functionStartLine": 820,
  "functionEndLine": 843,
  "numCommitsSeen": 40,
  "timeTaken": 1748,
  "changeHistory": [
    "a37e7f0ad8b68c7ed16c242bedf62f4cde48d6fd",
    "cb26cd4bee8ab75b304ebad6dc7c77523d0e9ce5"
  ],
  "changeHistoryShort": {
    "a37e7f0ad8b68c7ed16c242bedf62f4cde48d6fd": "Ybodychange",
    "cb26cd4bee8ab75b304ebad6dc7c77523d0e9ce5": "Yintroduced"
  },
  "changeHistoryDetails": {
    "a37e7f0ad8b68c7ed16c242bedf62f4cde48d6fd": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-7022. Fast fail rogue jobs based on task scratch dir size. Contributed by Johan Gustavsson\n",
      "commitDate": "26/01/18 12:36 PM",
      "commitName": "a37e7f0ad8b68c7ed16c242bedf62f4cde48d6fd",
      "commitAuthor": "Jason Lowe",
      "commitDateOld": "05/11/17 11:28 PM",
      "commitNameOld": "61bbdc511e4e98c11a05d7c3bc01f3e971adbe13",
      "commitAuthorOld": "Naganarasimha",
      "daysBetweenCommits": 81.55,
      "commitsBetweenForRepo": 546,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,24 @@\n     protected void checkTaskLimits() throws TaskLimitException {\n       // check the limit for writing to local file system\n       long limit \u003d conf.getLong(MRJobConfig.TASK_LOCAL_WRITE_LIMIT_BYTES,\n               MRJobConfig.DEFAULT_TASK_LOCAL_WRITE_LIMIT_BYTES);\n       if (limit \u003e\u003d 0) {\n         Counters.Counter localWritesCounter \u003d null;\n         try {\n           LocalFileSystem localFS \u003d FileSystem.getLocal(conf);\n           localWritesCounter \u003d counters.findCounter(localFS.getScheme(),\n                   FileSystemCounter.BYTES_WRITTEN);\n         } catch (IOException e) {\n           LOG.warn(\"Could not get LocalFileSystem BYTES_WRITTEN counter\");\n         }\n         if (localWritesCounter !\u003d null\n                 \u0026\u0026 localWritesCounter.getCounter() \u003e limit) {\n           throw new TaskLimitException(\"too much write to local file system.\" +\n                   \" current value is \" + localWritesCounter.getCounter() +\n                   \" the limit is \" + limit);\n         }\n       }\n+      if (diskLimitCheckStatus !\u003d null) {\n+        throw new TaskLimitException(diskLimitCheckStatus);\n+      }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    protected void checkTaskLimits() throws TaskLimitException {\n      // check the limit for writing to local file system\n      long limit \u003d conf.getLong(MRJobConfig.TASK_LOCAL_WRITE_LIMIT_BYTES,\n              MRJobConfig.DEFAULT_TASK_LOCAL_WRITE_LIMIT_BYTES);\n      if (limit \u003e\u003d 0) {\n        Counters.Counter localWritesCounter \u003d null;\n        try {\n          LocalFileSystem localFS \u003d FileSystem.getLocal(conf);\n          localWritesCounter \u003d counters.findCounter(localFS.getScheme(),\n                  FileSystemCounter.BYTES_WRITTEN);\n        } catch (IOException e) {\n          LOG.warn(\"Could not get LocalFileSystem BYTES_WRITTEN counter\");\n        }\n        if (localWritesCounter !\u003d null\n                \u0026\u0026 localWritesCounter.getCounter() \u003e limit) {\n          throw new TaskLimitException(\"too much write to local file system.\" +\n                  \" current value is \" + localWritesCounter.getCounter() +\n                  \" the limit is \" + limit);\n        }\n      }\n      if (diskLimitCheckStatus !\u003d null) {\n        throw new TaskLimitException(diskLimitCheckStatus);\n      }\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/Task.java",
      "extendedDetails": {}
    },
    "cb26cd4bee8ab75b304ebad6dc7c77523d0e9ce5": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-6489. Fail fast rogue tasks that write too much to local disk. Contributed by Maysam Yabandeh\n",
      "commitDate": "21/10/15 7:01 AM",
      "commitName": "cb26cd4bee8ab75b304ebad6dc7c77523d0e9ce5",
      "commitAuthor": "Jason Lowe",
      "diff": "@@ -0,0 +1,21 @@\n+    protected void checkTaskLimits() throws TaskLimitException {\n+      // check the limit for writing to local file system\n+      long limit \u003d conf.getLong(MRJobConfig.TASK_LOCAL_WRITE_LIMIT_BYTES,\n+              MRJobConfig.DEFAULT_TASK_LOCAL_WRITE_LIMIT_BYTES);\n+      if (limit \u003e\u003d 0) {\n+        Counters.Counter localWritesCounter \u003d null;\n+        try {\n+          LocalFileSystem localFS \u003d FileSystem.getLocal(conf);\n+          localWritesCounter \u003d counters.findCounter(localFS.getScheme(),\n+                  FileSystemCounter.BYTES_WRITTEN);\n+        } catch (IOException e) {\n+          LOG.warn(\"Could not get LocalFileSystem BYTES_WRITTEN counter\");\n+        }\n+        if (localWritesCounter !\u003d null\n+                \u0026\u0026 localWritesCounter.getCounter() \u003e limit) {\n+          throw new TaskLimitException(\"too much write to local file system.\" +\n+                  \" current value is \" + localWritesCounter.getCounter() +\n+                  \" the limit is \" + limit);\n+        }\n+      }\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    protected void checkTaskLimits() throws TaskLimitException {\n      // check the limit for writing to local file system\n      long limit \u003d conf.getLong(MRJobConfig.TASK_LOCAL_WRITE_LIMIT_BYTES,\n              MRJobConfig.DEFAULT_TASK_LOCAL_WRITE_LIMIT_BYTES);\n      if (limit \u003e\u003d 0) {\n        Counters.Counter localWritesCounter \u003d null;\n        try {\n          LocalFileSystem localFS \u003d FileSystem.getLocal(conf);\n          localWritesCounter \u003d counters.findCounter(localFS.getScheme(),\n                  FileSystemCounter.BYTES_WRITTEN);\n        } catch (IOException e) {\n          LOG.warn(\"Could not get LocalFileSystem BYTES_WRITTEN counter\");\n        }\n        if (localWritesCounter !\u003d null\n                \u0026\u0026 localWritesCounter.getCounter() \u003e limit) {\n          throw new TaskLimitException(\"too much write to local file system.\" +\n                  \" current value is \" + localWritesCounter.getCounter() +\n                  \" the limit is \" + limit);\n        }\n      }\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/Task.java"
    }
  }
}