{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FlowScanner.java",
  "functionName": "emitCells",
  "functionId": "emitCells___cells-List__Cell____currentColumnCells-SortedSet__Cell____currentAggOp-AggregationOperation__converter-ValueConverter__currentTimestamp-long",
  "sourceFilePath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-server/hadoop-yarn-server-timelineservice-hbase-server-2/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/flow/FlowScanner.java",
  "functionStartLine": 341,
  "functionEndLine": 387,
  "numCommitsSeen": 4,
  "timeTaken": 774,
  "changeHistory": [
    "55ba49dd071b66e72c47a1c41e88b9a5feddf53b"
  ],
  "changeHistoryShort": {
    "55ba49dd071b66e72c47a1c41e88b9a5feddf53b": "Yintroduced"
  },
  "changeHistoryDetails": {
    "55ba49dd071b66e72c47a1c41e88b9a5feddf53b": {
      "type": "Yintroduced",
      "commitMessage": "YARN-7346. Add a profile to allow optional compilation for ATSv2 with HBase-2.0. Contributed by Haibo Chen and Rohith.\n",
      "commitDate": "05/03/18 10:25 PM",
      "commitName": "55ba49dd071b66e72c47a1c41e88b9a5feddf53b",
      "commitAuthor": "Rohith Sharma K S",
      "diff": "@@ -0,0 +1,47 @@\n+  private int emitCells(List\u003cCell\u003e cells, SortedSet\u003cCell\u003e currentColumnCells,\n+      AggregationOperation currentAggOp, ValueConverter converter,\n+      long currentTimestamp) throws IOException {\n+    if ((currentColumnCells \u003d\u003d null) || (currentColumnCells.size() \u003d\u003d 0)) {\n+      return 0;\n+    }\n+    if (currentAggOp \u003d\u003d null) {\n+      cells.addAll(currentColumnCells);\n+      return currentColumnCells.size();\n+    }\n+    if (LOG.isTraceEnabled()) {\n+      LOG.trace(\"In emitCells \" + this.action + \" currentColumnCells size\u003d \"\n+          + currentColumnCells.size() + \" currentAggOp\" + currentAggOp);\n+    }\n+\n+    switch (currentAggOp) {\n+    case GLOBAL_MIN:\n+    case GLOBAL_MAX:\n+      cells.addAll(currentColumnCells);\n+      return currentColumnCells.size();\n+    case SUM:\n+    case SUM_FINAL:\n+      switch (action) {\n+      case FLUSH:\n+      case MINOR_COMPACTION:\n+        cells.addAll(currentColumnCells);\n+        return currentColumnCells.size();\n+      case READ:\n+        Cell sumCell \u003d processSummation(currentColumnCells,\n+            (NumericValueConverter) converter);\n+        cells.add(sumCell);\n+        return 1;\n+      case MAJOR_COMPACTION:\n+        List\u003cCell\u003e finalCells \u003d processSummationMajorCompaction(\n+            currentColumnCells, (NumericValueConverter) converter,\n+            currentTimestamp);\n+        cells.addAll(finalCells);\n+        return finalCells.size();\n+      default:\n+        cells.addAll(currentColumnCells);\n+        return currentColumnCells.size();\n+      }\n+    default:\n+      cells.addAll(currentColumnCells);\n+      return currentColumnCells.size();\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private int emitCells(List\u003cCell\u003e cells, SortedSet\u003cCell\u003e currentColumnCells,\n      AggregationOperation currentAggOp, ValueConverter converter,\n      long currentTimestamp) throws IOException {\n    if ((currentColumnCells \u003d\u003d null) || (currentColumnCells.size() \u003d\u003d 0)) {\n      return 0;\n    }\n    if (currentAggOp \u003d\u003d null) {\n      cells.addAll(currentColumnCells);\n      return currentColumnCells.size();\n    }\n    if (LOG.isTraceEnabled()) {\n      LOG.trace(\"In emitCells \" + this.action + \" currentColumnCells size\u003d \"\n          + currentColumnCells.size() + \" currentAggOp\" + currentAggOp);\n    }\n\n    switch (currentAggOp) {\n    case GLOBAL_MIN:\n    case GLOBAL_MAX:\n      cells.addAll(currentColumnCells);\n      return currentColumnCells.size();\n    case SUM:\n    case SUM_FINAL:\n      switch (action) {\n      case FLUSH:\n      case MINOR_COMPACTION:\n        cells.addAll(currentColumnCells);\n        return currentColumnCells.size();\n      case READ:\n        Cell sumCell \u003d processSummation(currentColumnCells,\n            (NumericValueConverter) converter);\n        cells.add(sumCell);\n        return 1;\n      case MAJOR_COMPACTION:\n        List\u003cCell\u003e finalCells \u003d processSummationMajorCompaction(\n            currentColumnCells, (NumericValueConverter) converter,\n            currentTimestamp);\n        cells.addAll(finalCells);\n        return finalCells.size();\n      default:\n        cells.addAll(currentColumnCells);\n        return currentColumnCells.size();\n      }\n    default:\n      cells.addAll(currentColumnCells);\n      return currentColumnCells.size();\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-server/hadoop-yarn-server-timelineservice-hbase-server-2/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/flow/FlowScanner.java"
    }
  }
}