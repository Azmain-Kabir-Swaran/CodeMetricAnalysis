{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ReadBufferManager.java",
  "functionName": "getNextBlockToRead",
  "functionId": "getNextBlockToRead",
  "sourceFilePath": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ReadBufferManager.java",
  "functionStartLine": 381,
  "functionEndLine": 401,
  "numCommitsSeen": 3,
  "timeTaken": 910,
  "changeHistory": [
    "ce03a93f78c4d97ccb48a3906fcd77ad0ac756be",
    "f044deedbbfee0812316d587139cb828f27172e9"
  ],
  "changeHistoryShort": {
    "ce03a93f78c4d97ccb48a3906fcd77ad0ac756be": "Ybodychange",
    "f044deedbbfee0812316d587139cb828f27172e9": "Yintroduced"
  },
  "changeHistoryDetails": {
    "ce03a93f78c4d97ccb48a3906fcd77ad0ac756be": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-15446. ABFS: tune imports \u0026 javadocs; stabilise tests.\nContributed by Steve Loughran and Da Zhou.\n",
      "commitDate": "17/09/18 12:54 PM",
      "commitName": "ce03a93f78c4d97ccb48a3906fcd77ad0ac756be",
      "commitAuthor": "Thomas Marquardt",
      "commitDateOld": "17/09/18 12:54 PM",
      "commitNameOld": "f044deedbbfee0812316d587139cb828f27172e9",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,21 @@\n   ReadBuffer getNextBlockToRead() throws InterruptedException {\n     ReadBuffer buffer \u003d null;\n     synchronized (this) {\n       //buffer \u003d readAheadQueue.take();  // blocking method\n       while (readAheadQueue.size() \u003d\u003d 0) {\n         wait();\n       }\n       buffer \u003d readAheadQueue.remove();\n       notifyAll();\n       if (buffer \u003d\u003d null) {\n         return null;            // should never happen\n       }\n       buffer.setStatus(ReadBufferStatus.READING_IN_PROGRESS);\n       inProgressList.add(buffer);\n     }\n     if (LOGGER.isTraceEnabled()) {\n-      LOGGER.trace(\"ReadBufferWorker picked file \" + buffer.getStream().getPath() + \" for offset \" + buffer.getOffset());\n+      LOGGER.trace(\"ReadBufferWorker picked file {} for offset {}\",\n+          buffer.getStream().getPath(), buffer.getOffset());\n     }\n     return buffer;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  ReadBuffer getNextBlockToRead() throws InterruptedException {\n    ReadBuffer buffer \u003d null;\n    synchronized (this) {\n      //buffer \u003d readAheadQueue.take();  // blocking method\n      while (readAheadQueue.size() \u003d\u003d 0) {\n        wait();\n      }\n      buffer \u003d readAheadQueue.remove();\n      notifyAll();\n      if (buffer \u003d\u003d null) {\n        return null;            // should never happen\n      }\n      buffer.setStatus(ReadBufferStatus.READING_IN_PROGRESS);\n      inProgressList.add(buffer);\n    }\n    if (LOGGER.isTraceEnabled()) {\n      LOGGER.trace(\"ReadBufferWorker picked file {} for offset {}\",\n          buffer.getStream().getPath(), buffer.getOffset());\n    }\n    return buffer;\n  }",
      "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ReadBufferManager.java",
      "extendedDetails": {}
    },
    "f044deedbbfee0812316d587139cb828f27172e9": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-15407. HADOOP-15540. Support Windows Azure Storage - Blob file system \"ABFS\" in Hadoop: Core Commit.\n\nContributed by Shane Mainali, Thomas Marquardt, Zichen Sun, Georgi Chalakov, Esfandiar Manii, Amit Singh, Dana Kaban, Da Zhou, Junhua Gu, Saher Ahwal, Saurabh Pant, James Baker, Shaoyu Zhang, Lawrence Chen, Kevin Chen and Steve Loughran\n",
      "commitDate": "17/09/18 12:54 PM",
      "commitName": "f044deedbbfee0812316d587139cb828f27172e9",
      "commitAuthor": "Steve Loughran",
      "diff": "@@ -0,0 +1,20 @@\n+  ReadBuffer getNextBlockToRead() throws InterruptedException {\n+    ReadBuffer buffer \u003d null;\n+    synchronized (this) {\n+      //buffer \u003d readAheadQueue.take();  // blocking method\n+      while (readAheadQueue.size() \u003d\u003d 0) {\n+        wait();\n+      }\n+      buffer \u003d readAheadQueue.remove();\n+      notifyAll();\n+      if (buffer \u003d\u003d null) {\n+        return null;            // should never happen\n+      }\n+      buffer.setStatus(ReadBufferStatus.READING_IN_PROGRESS);\n+      inProgressList.add(buffer);\n+    }\n+    if (LOGGER.isTraceEnabled()) {\n+      LOGGER.trace(\"ReadBufferWorker picked file \" + buffer.getStream().getPath() + \" for offset \" + buffer.getOffset());\n+    }\n+    return buffer;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  ReadBuffer getNextBlockToRead() throws InterruptedException {\n    ReadBuffer buffer \u003d null;\n    synchronized (this) {\n      //buffer \u003d readAheadQueue.take();  // blocking method\n      while (readAheadQueue.size() \u003d\u003d 0) {\n        wait();\n      }\n      buffer \u003d readAheadQueue.remove();\n      notifyAll();\n      if (buffer \u003d\u003d null) {\n        return null;            // should never happen\n      }\n      buffer.setStatus(ReadBufferStatus.READING_IN_PROGRESS);\n      inProgressList.add(buffer);\n    }\n    if (LOGGER.isTraceEnabled()) {\n      LOGGER.trace(\"ReadBufferWorker picked file \" + buffer.getStream().getPath() + \" for offset \" + buffer.getOffset());\n    }\n    return buffer;\n  }",
      "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ReadBufferManager.java"
    }
  }
}