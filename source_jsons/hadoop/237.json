{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "WriteManager.java",
  "functionName": "handleWrite",
  "functionId": "handleWrite___dfsClient-DFSClient__request-WRITE3Request__channel-Channel__xid-int__preOpAttr-Nfs3FileAttributes",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/WriteManager.java",
  "functionStartLine": 122,
  "functionEndLine": 215,
  "numCommitsSeen": 21,
  "timeTaken": 2408,
  "changeHistory": [
    "d6602b5f39833611b4afa4581552f6c4c37e23a8",
    "f37849188b05a6251584de1aed5e66d5dfa7da4f",
    "2848db814a98b83e7546f65a2751e56fb5b2dbe0",
    "b6f9d5538cf2b425652687e99503f3d566b2056a",
    "875aa797caee96572162ff59bc50cf97d1195348",
    "9ff3836a367737d6dfcb12f50c8bd2f1b2233e37",
    "42391d260da400593812396c1ffd45d1a371d3cb",
    "3bfd18c6b0483ae27eff6d53bda934e67dda5464",
    "3fccdec6e0a8e9305fc75921211c3745eddb9c45",
    "5c02d2f6225144772dcb975d3144b057b71d6476",
    "5e18410e06dd63113c49029894007e0878312903",
    "a56a4b6ef06602312144783b7507bf2b82821e4f",
    "30b8ef91a32ddf1fe3756bae6d7dc538a150bdc4",
    "37f587563a943a827fbff865f5302bac6d202415"
  ],
  "changeHistoryShort": {
    "d6602b5f39833611b4afa4581552f6c4c37e23a8": "Ybodychange",
    "f37849188b05a6251584de1aed5e66d5dfa7da4f": "Ybodychange",
    "2848db814a98b83e7546f65a2751e56fb5b2dbe0": "Ybodychange",
    "b6f9d5538cf2b425652687e99503f3d566b2056a": "Ybodychange",
    "875aa797caee96572162ff59bc50cf97d1195348": "Ybodychange",
    "9ff3836a367737d6dfcb12f50c8bd2f1b2233e37": "Ybodychange",
    "42391d260da400593812396c1ffd45d1a371d3cb": "Ybodychange",
    "3bfd18c6b0483ae27eff6d53bda934e67dda5464": "Ybodychange",
    "3fccdec6e0a8e9305fc75921211c3745eddb9c45": "Ybodychange",
    "5c02d2f6225144772dcb975d3144b057b71d6476": "Ybodychange",
    "5e18410e06dd63113c49029894007e0878312903": "Ybodychange",
    "a56a4b6ef06602312144783b7507bf2b82821e4f": "Ybodychange",
    "30b8ef91a32ddf1fe3756bae6d7dc538a150bdc4": "Ybodychange",
    "37f587563a943a827fbff865f5302bac6d202415": "Yintroduced"
  },
  "changeHistoryDetails": {
    "d6602b5f39833611b4afa4581552f6c4c37e23a8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11575. Supporting HDFS NFS gateway with Federated HDFS. Contributed by Mukul Kumar Singh.\n",
      "commitDate": "10/10/17 10:38 AM",
      "commitName": "d6602b5f39833611b4afa4581552f6c4c37e23a8",
      "commitAuthor": "Jitendra Pandey",
      "commitDateOld": "28/01/15 12:56 PM",
      "commitNameOld": "f37849188b05a6251584de1aed5e66d5dfa7da4f",
      "commitAuthorOld": "yliu",
      "daysBetweenCommits": 985.86,
      "commitsBetweenForRepo": 7119,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,91 +1,94 @@\n   void handleWrite(DFSClient dfsClient, WRITE3Request request, Channel channel,\n       int xid, Nfs3FileAttributes preOpAttr) throws IOException {\n     int count \u003d request.getCount();\n     byte[] data \u003d request.getData().array();\n     if (data.length \u003c count) {\n       WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_INVAL);\n       Nfs3Utils.writeChannel(channel, response.serialize(\n           new XDR(), xid, new VerifierNone()), xid);\n       return;\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"handleWrite \" + request);\n     }\n \n     // Check if there is a stream to write\n     FileHandle fileHandle \u003d request.getHandle();\n     OpenFileCtx openFileCtx \u003d fileContextCache.get(fileHandle);\n     if (openFileCtx \u003d\u003d null) {\n-      LOG.info(\"No opened stream for fileId: \" + fileHandle.getFileId());\n+      LOG.info(\"No opened stream for fileHandle: \"\n+          + fileHandle.dumpFileHandle());\n \n       String fileIdPath \u003d Nfs3Utils.getFileIdPath(fileHandle.getFileId());\n       HdfsDataOutputStream fos \u003d null;\n       Nfs3FileAttributes latestAttr \u003d null;\n       try {\n         int bufferSize \u003d config.getInt(\n             CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_KEY,\n             CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_DEFAULT);\n         \n         fos \u003d dfsClient.append(fileIdPath, bufferSize,\n             EnumSet.of(CreateFlag.APPEND), null, null);\n \n         latestAttr \u003d Nfs3Utils.getFileAttr(dfsClient, fileIdPath, iug);\n       } catch (RemoteException e) {\n         IOException io \u003d e.unwrapRemoteException();\n         if (io instanceof AlreadyBeingCreatedException) {\n           LOG.warn(\"Can\u0027t append file: \" + fileIdPath\n               + \". Possibly the file is being closed. Drop the request: \"\n               + request + \", wait for the client to retry...\");\n           return;\n         }\n         throw e;\n       } catch (IOException e) {\n         LOG.error(\"Can\u0027t append to file: \" + fileIdPath, e);\n         if (fos !\u003d null) {\n           fos.close();\n         }\n         WccData fileWcc \u003d new WccData(Nfs3Utils.getWccAttr(preOpAttr),\n             preOpAttr);\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n             fileWcc, count, request.getStableHow(),\n             Nfs3Constant.WRITE_COMMIT_VERF);\n         Nfs3Utils.writeChannel(channel, response.serialize(\n             new XDR(), xid, new VerifierNone()), xid);\n         return;\n       }\n \n       // Add open stream\n       String writeDumpDir \u003d config.get(NfsConfigKeys.DFS_NFS_FILE_DUMP_DIR_KEY,\n           NfsConfigKeys.DFS_NFS_FILE_DUMP_DIR_DEFAULT);\n       openFileCtx \u003d new OpenFileCtx(fos, latestAttr, writeDumpDir + \"/\"\n           + fileHandle.getFileId(), dfsClient, iug, aixCompatMode, config);\n \n       if (!addOpenFileStream(fileHandle, openFileCtx)) {\n         LOG.info(\"Can\u0027t add new stream. Close it. Tell client to retry.\");\n         try {\n           fos.close();\n         } catch (IOException e) {\n-          LOG.error(\"Can\u0027t close stream for fileId: \" + handle.getFileId(), e);\n+          LOG.error(\"Can\u0027t close stream for fileHandle: \"\n+              + handle.dumpFileHandle(), e);\n         }\n         // Notify client to retry\n         WccData fileWcc \u003d new WccData(latestAttr.getWccAttr(), latestAttr);\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_JUKEBOX,\n             fileWcc, 0, request.getStableHow(), Nfs3Constant.WRITE_COMMIT_VERF);\n         Nfs3Utils.writeChannel(channel,\n             response.serialize(new XDR(), xid, new VerifierNone()),\n             xid);\n         return;\n       }\n \n       if (LOG.isDebugEnabled()) {\n-        LOG.debug(\"Opened stream for appending file: \" + fileHandle.getFileId());\n+        LOG.debug(\"Opened stream for appending file: \"\n+            + fileHandle.dumpFileHandle());\n       }\n     }\n \n     // Add write into the async job queue\n     openFileCtx.receivedNewWrite(dfsClient, request, channel, xid,\n         asyncDataService, iug);\n     return;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void handleWrite(DFSClient dfsClient, WRITE3Request request, Channel channel,\n      int xid, Nfs3FileAttributes preOpAttr) throws IOException {\n    int count \u003d request.getCount();\n    byte[] data \u003d request.getData().array();\n    if (data.length \u003c count) {\n      WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_INVAL);\n      Nfs3Utils.writeChannel(channel, response.serialize(\n          new XDR(), xid, new VerifierNone()), xid);\n      return;\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"handleWrite \" + request);\n    }\n\n    // Check if there is a stream to write\n    FileHandle fileHandle \u003d request.getHandle();\n    OpenFileCtx openFileCtx \u003d fileContextCache.get(fileHandle);\n    if (openFileCtx \u003d\u003d null) {\n      LOG.info(\"No opened stream for fileHandle: \"\n          + fileHandle.dumpFileHandle());\n\n      String fileIdPath \u003d Nfs3Utils.getFileIdPath(fileHandle.getFileId());\n      HdfsDataOutputStream fos \u003d null;\n      Nfs3FileAttributes latestAttr \u003d null;\n      try {\n        int bufferSize \u003d config.getInt(\n            CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_KEY,\n            CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_DEFAULT);\n        \n        fos \u003d dfsClient.append(fileIdPath, bufferSize,\n            EnumSet.of(CreateFlag.APPEND), null, null);\n\n        latestAttr \u003d Nfs3Utils.getFileAttr(dfsClient, fileIdPath, iug);\n      } catch (RemoteException e) {\n        IOException io \u003d e.unwrapRemoteException();\n        if (io instanceof AlreadyBeingCreatedException) {\n          LOG.warn(\"Can\u0027t append file: \" + fileIdPath\n              + \". Possibly the file is being closed. Drop the request: \"\n              + request + \", wait for the client to retry...\");\n          return;\n        }\n        throw e;\n      } catch (IOException e) {\n        LOG.error(\"Can\u0027t append to file: \" + fileIdPath, e);\n        if (fos !\u003d null) {\n          fos.close();\n        }\n        WccData fileWcc \u003d new WccData(Nfs3Utils.getWccAttr(preOpAttr),\n            preOpAttr);\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n            fileWcc, count, request.getStableHow(),\n            Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(channel, response.serialize(\n            new XDR(), xid, new VerifierNone()), xid);\n        return;\n      }\n\n      // Add open stream\n      String writeDumpDir \u003d config.get(NfsConfigKeys.DFS_NFS_FILE_DUMP_DIR_KEY,\n          NfsConfigKeys.DFS_NFS_FILE_DUMP_DIR_DEFAULT);\n      openFileCtx \u003d new OpenFileCtx(fos, latestAttr, writeDumpDir + \"/\"\n          + fileHandle.getFileId(), dfsClient, iug, aixCompatMode, config);\n\n      if (!addOpenFileStream(fileHandle, openFileCtx)) {\n        LOG.info(\"Can\u0027t add new stream. Close it. Tell client to retry.\");\n        try {\n          fos.close();\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t close stream for fileHandle: \"\n              + handle.dumpFileHandle(), e);\n        }\n        // Notify client to retry\n        WccData fileWcc \u003d new WccData(latestAttr.getWccAttr(), latestAttr);\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_JUKEBOX,\n            fileWcc, 0, request.getStableHow(), Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(channel,\n            response.serialize(new XDR(), xid, new VerifierNone()),\n            xid);\n        return;\n      }\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Opened stream for appending file: \"\n            + fileHandle.dumpFileHandle());\n      }\n    }\n\n    // Add write into the async job queue\n    openFileCtx.receivedNewWrite(dfsClient, request, channel, xid,\n        asyncDataService, iug);\n    return;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/WriteManager.java",
      "extendedDetails": {}
    },
    "f37849188b05a6251584de1aed5e66d5dfa7da4f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7423. various typos and message formatting fixes in nfs daemon and doc. (Charles Lamb via yliu)\n",
      "commitDate": "28/01/15 12:56 PM",
      "commitName": "f37849188b05a6251584de1aed5e66d5dfa7da4f",
      "commitAuthor": "yliu",
      "commitDateOld": "27/01/15 12:58 PM",
      "commitNameOld": "2848db814a98b83e7546f65a2751e56fb5b2dbe0",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 1.0,
      "commitsBetweenForRepo": 9,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,91 +1,91 @@\n   void handleWrite(DFSClient dfsClient, WRITE3Request request, Channel channel,\n       int xid, Nfs3FileAttributes preOpAttr) throws IOException {\n     int count \u003d request.getCount();\n     byte[] data \u003d request.getData().array();\n     if (data.length \u003c count) {\n       WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_INVAL);\n       Nfs3Utils.writeChannel(channel, response.serialize(\n           new XDR(), xid, new VerifierNone()), xid);\n       return;\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"handleWrite \" + request);\n     }\n \n     // Check if there is a stream to write\n     FileHandle fileHandle \u003d request.getHandle();\n     OpenFileCtx openFileCtx \u003d fileContextCache.get(fileHandle);\n     if (openFileCtx \u003d\u003d null) {\n-      LOG.info(\"No opened stream for fileId:\" + fileHandle.getFileId());\n+      LOG.info(\"No opened stream for fileId: \" + fileHandle.getFileId());\n \n       String fileIdPath \u003d Nfs3Utils.getFileIdPath(fileHandle.getFileId());\n       HdfsDataOutputStream fos \u003d null;\n       Nfs3FileAttributes latestAttr \u003d null;\n       try {\n         int bufferSize \u003d config.getInt(\n             CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_KEY,\n             CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_DEFAULT);\n         \n         fos \u003d dfsClient.append(fileIdPath, bufferSize,\n             EnumSet.of(CreateFlag.APPEND), null, null);\n \n         latestAttr \u003d Nfs3Utils.getFileAttr(dfsClient, fileIdPath, iug);\n       } catch (RemoteException e) {\n         IOException io \u003d e.unwrapRemoteException();\n         if (io instanceof AlreadyBeingCreatedException) {\n-          LOG.warn(\"Can\u0027t append file:\" + fileIdPath\n-              + \". Possibly the file is being closed. Drop the request:\"\n+          LOG.warn(\"Can\u0027t append file: \" + fileIdPath\n+              + \". Possibly the file is being closed. Drop the request: \"\n               + request + \", wait for the client to retry...\");\n           return;\n         }\n         throw e;\n       } catch (IOException e) {\n-        LOG.error(\"Can\u0027t apapend to file:\" + fileIdPath, e);\n+        LOG.error(\"Can\u0027t append to file: \" + fileIdPath, e);\n         if (fos !\u003d null) {\n           fos.close();\n         }\n         WccData fileWcc \u003d new WccData(Nfs3Utils.getWccAttr(preOpAttr),\n             preOpAttr);\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n             fileWcc, count, request.getStableHow(),\n             Nfs3Constant.WRITE_COMMIT_VERF);\n         Nfs3Utils.writeChannel(channel, response.serialize(\n             new XDR(), xid, new VerifierNone()), xid);\n         return;\n       }\n \n       // Add open stream\n       String writeDumpDir \u003d config.get(NfsConfigKeys.DFS_NFS_FILE_DUMP_DIR_KEY,\n           NfsConfigKeys.DFS_NFS_FILE_DUMP_DIR_DEFAULT);\n       openFileCtx \u003d new OpenFileCtx(fos, latestAttr, writeDumpDir + \"/\"\n           + fileHandle.getFileId(), dfsClient, iug, aixCompatMode, config);\n \n       if (!addOpenFileStream(fileHandle, openFileCtx)) {\n         LOG.info(\"Can\u0027t add new stream. Close it. Tell client to retry.\");\n         try {\n           fos.close();\n         } catch (IOException e) {\n-          LOG.error(\"Can\u0027t close stream for fileId:\" + handle.getFileId(), e);\n+          LOG.error(\"Can\u0027t close stream for fileId: \" + handle.getFileId(), e);\n         }\n         // Notify client to retry\n         WccData fileWcc \u003d new WccData(latestAttr.getWccAttr(), latestAttr);\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_JUKEBOX,\n             fileWcc, 0, request.getStableHow(), Nfs3Constant.WRITE_COMMIT_VERF);\n         Nfs3Utils.writeChannel(channel,\n             response.serialize(new XDR(), xid, new VerifierNone()),\n             xid);\n         return;\n       }\n \n       if (LOG.isDebugEnabled()) {\n-        LOG.debug(\"Opened stream for appending file:\" + fileHandle.getFileId());\n+        LOG.debug(\"Opened stream for appending file: \" + fileHandle.getFileId());\n       }\n     }\n \n     // Add write into the async job queue\n     openFileCtx.receivedNewWrite(dfsClient, request, channel, xid,\n         asyncDataService, iug);\n     return;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void handleWrite(DFSClient dfsClient, WRITE3Request request, Channel channel,\n      int xid, Nfs3FileAttributes preOpAttr) throws IOException {\n    int count \u003d request.getCount();\n    byte[] data \u003d request.getData().array();\n    if (data.length \u003c count) {\n      WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_INVAL);\n      Nfs3Utils.writeChannel(channel, response.serialize(\n          new XDR(), xid, new VerifierNone()), xid);\n      return;\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"handleWrite \" + request);\n    }\n\n    // Check if there is a stream to write\n    FileHandle fileHandle \u003d request.getHandle();\n    OpenFileCtx openFileCtx \u003d fileContextCache.get(fileHandle);\n    if (openFileCtx \u003d\u003d null) {\n      LOG.info(\"No opened stream for fileId: \" + fileHandle.getFileId());\n\n      String fileIdPath \u003d Nfs3Utils.getFileIdPath(fileHandle.getFileId());\n      HdfsDataOutputStream fos \u003d null;\n      Nfs3FileAttributes latestAttr \u003d null;\n      try {\n        int bufferSize \u003d config.getInt(\n            CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_KEY,\n            CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_DEFAULT);\n        \n        fos \u003d dfsClient.append(fileIdPath, bufferSize,\n            EnumSet.of(CreateFlag.APPEND), null, null);\n\n        latestAttr \u003d Nfs3Utils.getFileAttr(dfsClient, fileIdPath, iug);\n      } catch (RemoteException e) {\n        IOException io \u003d e.unwrapRemoteException();\n        if (io instanceof AlreadyBeingCreatedException) {\n          LOG.warn(\"Can\u0027t append file: \" + fileIdPath\n              + \". Possibly the file is being closed. Drop the request: \"\n              + request + \", wait for the client to retry...\");\n          return;\n        }\n        throw e;\n      } catch (IOException e) {\n        LOG.error(\"Can\u0027t append to file: \" + fileIdPath, e);\n        if (fos !\u003d null) {\n          fos.close();\n        }\n        WccData fileWcc \u003d new WccData(Nfs3Utils.getWccAttr(preOpAttr),\n            preOpAttr);\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n            fileWcc, count, request.getStableHow(),\n            Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(channel, response.serialize(\n            new XDR(), xid, new VerifierNone()), xid);\n        return;\n      }\n\n      // Add open stream\n      String writeDumpDir \u003d config.get(NfsConfigKeys.DFS_NFS_FILE_DUMP_DIR_KEY,\n          NfsConfigKeys.DFS_NFS_FILE_DUMP_DIR_DEFAULT);\n      openFileCtx \u003d new OpenFileCtx(fos, latestAttr, writeDumpDir + \"/\"\n          + fileHandle.getFileId(), dfsClient, iug, aixCompatMode, config);\n\n      if (!addOpenFileStream(fileHandle, openFileCtx)) {\n        LOG.info(\"Can\u0027t add new stream. Close it. Tell client to retry.\");\n        try {\n          fos.close();\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t close stream for fileId: \" + handle.getFileId(), e);\n        }\n        // Notify client to retry\n        WccData fileWcc \u003d new WccData(latestAttr.getWccAttr(), latestAttr);\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_JUKEBOX,\n            fileWcc, 0, request.getStableHow(), Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(channel,\n            response.serialize(new XDR(), xid, new VerifierNone()),\n            xid);\n        return;\n      }\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Opened stream for appending file: \" + fileHandle.getFileId());\n      }\n    }\n\n    // Add write into the async job queue\n    openFileCtx.receivedNewWrite(dfsClient, request, channel, xid,\n        asyncDataService, iug);\n    return;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/WriteManager.java",
      "extendedDetails": {}
    },
    "2848db814a98b83e7546f65a2751e56fb5b2dbe0": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3689. Add support for variable length block. Contributed by Jing Zhao.\n",
      "commitDate": "27/01/15 12:58 PM",
      "commitName": "2848db814a98b83e7546f65a2751e56fb5b2dbe0",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "11/12/14 3:40 PM",
      "commitNameOld": "f6f2a3f1c73266bfedd802eacde60d8b19b81015",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 46.89,
      "commitsBetweenForRepo": 262,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,90 +1,91 @@\n   void handleWrite(DFSClient dfsClient, WRITE3Request request, Channel channel,\n       int xid, Nfs3FileAttributes preOpAttr) throws IOException {\n     int count \u003d request.getCount();\n     byte[] data \u003d request.getData().array();\n     if (data.length \u003c count) {\n       WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_INVAL);\n       Nfs3Utils.writeChannel(channel, response.serialize(\n           new XDR(), xid, new VerifierNone()), xid);\n       return;\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"handleWrite \" + request);\n     }\n \n     // Check if there is a stream to write\n     FileHandle fileHandle \u003d request.getHandle();\n     OpenFileCtx openFileCtx \u003d fileContextCache.get(fileHandle);\n     if (openFileCtx \u003d\u003d null) {\n       LOG.info(\"No opened stream for fileId:\" + fileHandle.getFileId());\n \n       String fileIdPath \u003d Nfs3Utils.getFileIdPath(fileHandle.getFileId());\n       HdfsDataOutputStream fos \u003d null;\n       Nfs3FileAttributes latestAttr \u003d null;\n       try {\n         int bufferSize \u003d config.getInt(\n             CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_KEY,\n             CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_DEFAULT);\n         \n-        fos \u003d dfsClient.append(fileIdPath, bufferSize, null, null);\n+        fos \u003d dfsClient.append(fileIdPath, bufferSize,\n+            EnumSet.of(CreateFlag.APPEND), null, null);\n \n         latestAttr \u003d Nfs3Utils.getFileAttr(dfsClient, fileIdPath, iug);\n       } catch (RemoteException e) {\n         IOException io \u003d e.unwrapRemoteException();\n         if (io instanceof AlreadyBeingCreatedException) {\n           LOG.warn(\"Can\u0027t append file:\" + fileIdPath\n               + \". Possibly the file is being closed. Drop the request:\"\n               + request + \", wait for the client to retry...\");\n           return;\n         }\n         throw e;\n       } catch (IOException e) {\n         LOG.error(\"Can\u0027t apapend to file:\" + fileIdPath, e);\n         if (fos !\u003d null) {\n           fos.close();\n         }\n         WccData fileWcc \u003d new WccData(Nfs3Utils.getWccAttr(preOpAttr),\n             preOpAttr);\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n             fileWcc, count, request.getStableHow(),\n             Nfs3Constant.WRITE_COMMIT_VERF);\n         Nfs3Utils.writeChannel(channel, response.serialize(\n             new XDR(), xid, new VerifierNone()), xid);\n         return;\n       }\n \n       // Add open stream\n       String writeDumpDir \u003d config.get(NfsConfigKeys.DFS_NFS_FILE_DUMP_DIR_KEY,\n           NfsConfigKeys.DFS_NFS_FILE_DUMP_DIR_DEFAULT);\n       openFileCtx \u003d new OpenFileCtx(fos, latestAttr, writeDumpDir + \"/\"\n           + fileHandle.getFileId(), dfsClient, iug, aixCompatMode, config);\n \n       if (!addOpenFileStream(fileHandle, openFileCtx)) {\n         LOG.info(\"Can\u0027t add new stream. Close it. Tell client to retry.\");\n         try {\n           fos.close();\n         } catch (IOException e) {\n           LOG.error(\"Can\u0027t close stream for fileId:\" + handle.getFileId(), e);\n         }\n         // Notify client to retry\n         WccData fileWcc \u003d new WccData(latestAttr.getWccAttr(), latestAttr);\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_JUKEBOX,\n             fileWcc, 0, request.getStableHow(), Nfs3Constant.WRITE_COMMIT_VERF);\n         Nfs3Utils.writeChannel(channel,\n             response.serialize(new XDR(), xid, new VerifierNone()),\n             xid);\n         return;\n       }\n \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Opened stream for appending file:\" + fileHandle.getFileId());\n       }\n     }\n \n     // Add write into the async job queue\n     openFileCtx.receivedNewWrite(dfsClient, request, channel, xid,\n         asyncDataService, iug);\n     return;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void handleWrite(DFSClient dfsClient, WRITE3Request request, Channel channel,\n      int xid, Nfs3FileAttributes preOpAttr) throws IOException {\n    int count \u003d request.getCount();\n    byte[] data \u003d request.getData().array();\n    if (data.length \u003c count) {\n      WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_INVAL);\n      Nfs3Utils.writeChannel(channel, response.serialize(\n          new XDR(), xid, new VerifierNone()), xid);\n      return;\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"handleWrite \" + request);\n    }\n\n    // Check if there is a stream to write\n    FileHandle fileHandle \u003d request.getHandle();\n    OpenFileCtx openFileCtx \u003d fileContextCache.get(fileHandle);\n    if (openFileCtx \u003d\u003d null) {\n      LOG.info(\"No opened stream for fileId:\" + fileHandle.getFileId());\n\n      String fileIdPath \u003d Nfs3Utils.getFileIdPath(fileHandle.getFileId());\n      HdfsDataOutputStream fos \u003d null;\n      Nfs3FileAttributes latestAttr \u003d null;\n      try {\n        int bufferSize \u003d config.getInt(\n            CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_KEY,\n            CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_DEFAULT);\n        \n        fos \u003d dfsClient.append(fileIdPath, bufferSize,\n            EnumSet.of(CreateFlag.APPEND), null, null);\n\n        latestAttr \u003d Nfs3Utils.getFileAttr(dfsClient, fileIdPath, iug);\n      } catch (RemoteException e) {\n        IOException io \u003d e.unwrapRemoteException();\n        if (io instanceof AlreadyBeingCreatedException) {\n          LOG.warn(\"Can\u0027t append file:\" + fileIdPath\n              + \". Possibly the file is being closed. Drop the request:\"\n              + request + \", wait for the client to retry...\");\n          return;\n        }\n        throw e;\n      } catch (IOException e) {\n        LOG.error(\"Can\u0027t apapend to file:\" + fileIdPath, e);\n        if (fos !\u003d null) {\n          fos.close();\n        }\n        WccData fileWcc \u003d new WccData(Nfs3Utils.getWccAttr(preOpAttr),\n            preOpAttr);\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n            fileWcc, count, request.getStableHow(),\n            Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(channel, response.serialize(\n            new XDR(), xid, new VerifierNone()), xid);\n        return;\n      }\n\n      // Add open stream\n      String writeDumpDir \u003d config.get(NfsConfigKeys.DFS_NFS_FILE_DUMP_DIR_KEY,\n          NfsConfigKeys.DFS_NFS_FILE_DUMP_DIR_DEFAULT);\n      openFileCtx \u003d new OpenFileCtx(fos, latestAttr, writeDumpDir + \"/\"\n          + fileHandle.getFileId(), dfsClient, iug, aixCompatMode, config);\n\n      if (!addOpenFileStream(fileHandle, openFileCtx)) {\n        LOG.info(\"Can\u0027t add new stream. Close it. Tell client to retry.\");\n        try {\n          fos.close();\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t close stream for fileId:\" + handle.getFileId(), e);\n        }\n        // Notify client to retry\n        WccData fileWcc \u003d new WccData(latestAttr.getWccAttr(), latestAttr);\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_JUKEBOX,\n            fileWcc, 0, request.getStableHow(), Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(channel,\n            response.serialize(new XDR(), xid, new VerifierNone()),\n            xid);\n        return;\n      }\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Opened stream for appending file:\" + fileHandle.getFileId());\n      }\n    }\n\n    // Add write into the async job queue\n    openFileCtx.receivedNewWrite(dfsClient, request, channel, xid,\n        asyncDataService, iug);\n    return;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/WriteManager.java",
      "extendedDetails": {}
    },
    "b6f9d5538cf2b425652687e99503f3d566b2056a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7259. Unresponseive NFS mount point due to deferred COMMIT response. Contributed by Brandon Li\n",
      "commitDate": "21/10/14 10:20 AM",
      "commitName": "b6f9d5538cf2b425652687e99503f3d566b2056a",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "01/10/14 1:18 PM",
      "commitNameOld": "875aa797caee96572162ff59bc50cf97d1195348",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 19.88,
      "commitsBetweenForRepo": 154,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,90 +1,90 @@\n   void handleWrite(DFSClient dfsClient, WRITE3Request request, Channel channel,\n       int xid, Nfs3FileAttributes preOpAttr) throws IOException {\n     int count \u003d request.getCount();\n     byte[] data \u003d request.getData().array();\n     if (data.length \u003c count) {\n       WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_INVAL);\n       Nfs3Utils.writeChannel(channel, response.serialize(\n           new XDR(), xid, new VerifierNone()), xid);\n       return;\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"handleWrite \" + request);\n     }\n \n     // Check if there is a stream to write\n     FileHandle fileHandle \u003d request.getHandle();\n     OpenFileCtx openFileCtx \u003d fileContextCache.get(fileHandle);\n     if (openFileCtx \u003d\u003d null) {\n       LOG.info(\"No opened stream for fileId:\" + fileHandle.getFileId());\n \n       String fileIdPath \u003d Nfs3Utils.getFileIdPath(fileHandle.getFileId());\n       HdfsDataOutputStream fos \u003d null;\n       Nfs3FileAttributes latestAttr \u003d null;\n       try {\n         int bufferSize \u003d config.getInt(\n             CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_KEY,\n             CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_DEFAULT);\n         \n         fos \u003d dfsClient.append(fileIdPath, bufferSize, null, null);\n \n         latestAttr \u003d Nfs3Utils.getFileAttr(dfsClient, fileIdPath, iug);\n       } catch (RemoteException e) {\n         IOException io \u003d e.unwrapRemoteException();\n         if (io instanceof AlreadyBeingCreatedException) {\n           LOG.warn(\"Can\u0027t append file:\" + fileIdPath\n               + \". Possibly the file is being closed. Drop the request:\"\n               + request + \", wait for the client to retry...\");\n           return;\n         }\n         throw e;\n       } catch (IOException e) {\n         LOG.error(\"Can\u0027t apapend to file:\" + fileIdPath, e);\n         if (fos !\u003d null) {\n           fos.close();\n         }\n         WccData fileWcc \u003d new WccData(Nfs3Utils.getWccAttr(preOpAttr),\n             preOpAttr);\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n             fileWcc, count, request.getStableHow(),\n             Nfs3Constant.WRITE_COMMIT_VERF);\n         Nfs3Utils.writeChannel(channel, response.serialize(\n             new XDR(), xid, new VerifierNone()), xid);\n         return;\n       }\n \n       // Add open stream\n       String writeDumpDir \u003d config.get(NfsConfigKeys.DFS_NFS_FILE_DUMP_DIR_KEY,\n           NfsConfigKeys.DFS_NFS_FILE_DUMP_DIR_DEFAULT);\n       openFileCtx \u003d new OpenFileCtx(fos, latestAttr, writeDumpDir + \"/\"\n-          + fileHandle.getFileId(), dfsClient, iug, aixCompatMode);\n+          + fileHandle.getFileId(), dfsClient, iug, aixCompatMode, config);\n \n       if (!addOpenFileStream(fileHandle, openFileCtx)) {\n         LOG.info(\"Can\u0027t add new stream. Close it. Tell client to retry.\");\n         try {\n           fos.close();\n         } catch (IOException e) {\n           LOG.error(\"Can\u0027t close stream for fileId:\" + handle.getFileId(), e);\n         }\n         // Notify client to retry\n         WccData fileWcc \u003d new WccData(latestAttr.getWccAttr(), latestAttr);\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_JUKEBOX,\n             fileWcc, 0, request.getStableHow(), Nfs3Constant.WRITE_COMMIT_VERF);\n         Nfs3Utils.writeChannel(channel,\n             response.serialize(new XDR(), xid, new VerifierNone()),\n             xid);\n         return;\n       }\n \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Opened stream for appending file:\" + fileHandle.getFileId());\n       }\n     }\n \n     // Add write into the async job queue\n     openFileCtx.receivedNewWrite(dfsClient, request, channel, xid,\n         asyncDataService, iug);\n     return;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void handleWrite(DFSClient dfsClient, WRITE3Request request, Channel channel,\n      int xid, Nfs3FileAttributes preOpAttr) throws IOException {\n    int count \u003d request.getCount();\n    byte[] data \u003d request.getData().array();\n    if (data.length \u003c count) {\n      WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_INVAL);\n      Nfs3Utils.writeChannel(channel, response.serialize(\n          new XDR(), xid, new VerifierNone()), xid);\n      return;\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"handleWrite \" + request);\n    }\n\n    // Check if there is a stream to write\n    FileHandle fileHandle \u003d request.getHandle();\n    OpenFileCtx openFileCtx \u003d fileContextCache.get(fileHandle);\n    if (openFileCtx \u003d\u003d null) {\n      LOG.info(\"No opened stream for fileId:\" + fileHandle.getFileId());\n\n      String fileIdPath \u003d Nfs3Utils.getFileIdPath(fileHandle.getFileId());\n      HdfsDataOutputStream fos \u003d null;\n      Nfs3FileAttributes latestAttr \u003d null;\n      try {\n        int bufferSize \u003d config.getInt(\n            CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_KEY,\n            CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_DEFAULT);\n        \n        fos \u003d dfsClient.append(fileIdPath, bufferSize, null, null);\n\n        latestAttr \u003d Nfs3Utils.getFileAttr(dfsClient, fileIdPath, iug);\n      } catch (RemoteException e) {\n        IOException io \u003d e.unwrapRemoteException();\n        if (io instanceof AlreadyBeingCreatedException) {\n          LOG.warn(\"Can\u0027t append file:\" + fileIdPath\n              + \". Possibly the file is being closed. Drop the request:\"\n              + request + \", wait for the client to retry...\");\n          return;\n        }\n        throw e;\n      } catch (IOException e) {\n        LOG.error(\"Can\u0027t apapend to file:\" + fileIdPath, e);\n        if (fos !\u003d null) {\n          fos.close();\n        }\n        WccData fileWcc \u003d new WccData(Nfs3Utils.getWccAttr(preOpAttr),\n            preOpAttr);\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n            fileWcc, count, request.getStableHow(),\n            Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(channel, response.serialize(\n            new XDR(), xid, new VerifierNone()), xid);\n        return;\n      }\n\n      // Add open stream\n      String writeDumpDir \u003d config.get(NfsConfigKeys.DFS_NFS_FILE_DUMP_DIR_KEY,\n          NfsConfigKeys.DFS_NFS_FILE_DUMP_DIR_DEFAULT);\n      openFileCtx \u003d new OpenFileCtx(fos, latestAttr, writeDumpDir + \"/\"\n          + fileHandle.getFileId(), dfsClient, iug, aixCompatMode, config);\n\n      if (!addOpenFileStream(fileHandle, openFileCtx)) {\n        LOG.info(\"Can\u0027t add new stream. Close it. Tell client to retry.\");\n        try {\n          fos.close();\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t close stream for fileId:\" + handle.getFileId(), e);\n        }\n        // Notify client to retry\n        WccData fileWcc \u003d new WccData(latestAttr.getWccAttr(), latestAttr);\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_JUKEBOX,\n            fileWcc, 0, request.getStableHow(), Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(channel,\n            response.serialize(new XDR(), xid, new VerifierNone()),\n            xid);\n        return;\n      }\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Opened stream for appending file:\" + fileHandle.getFileId());\n      }\n    }\n\n    // Add write into the async job queue\n    openFileCtx.receivedNewWrite(dfsClient, request, channel, xid,\n        asyncDataService, iug);\n    return;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/WriteManager.java",
      "extendedDetails": {}
    },
    "875aa797caee96572162ff59bc50cf97d1195348": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6894. Add XDR parser method for each NFS response. Contributed by Brandon Li.\n",
      "commitDate": "01/10/14 1:18 PM",
      "commitName": "875aa797caee96572162ff59bc50cf97d1195348",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "19/06/14 12:39 PM",
      "commitNameOld": "9ff3836a367737d6dfcb12f50c8bd2f1b2233e37",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 104.03,
      "commitsBetweenForRepo": 982,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,90 +1,90 @@\n   void handleWrite(DFSClient dfsClient, WRITE3Request request, Channel channel,\n       int xid, Nfs3FileAttributes preOpAttr) throws IOException {\n     int count \u003d request.getCount();\n     byte[] data \u003d request.getData().array();\n     if (data.length \u003c count) {\n       WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_INVAL);\n-      Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n+      Nfs3Utils.writeChannel(channel, response.serialize(\n           new XDR(), xid, new VerifierNone()), xid);\n       return;\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"handleWrite \" + request);\n     }\n \n     // Check if there is a stream to write\n     FileHandle fileHandle \u003d request.getHandle();\n     OpenFileCtx openFileCtx \u003d fileContextCache.get(fileHandle);\n     if (openFileCtx \u003d\u003d null) {\n       LOG.info(\"No opened stream for fileId:\" + fileHandle.getFileId());\n \n       String fileIdPath \u003d Nfs3Utils.getFileIdPath(fileHandle.getFileId());\n       HdfsDataOutputStream fos \u003d null;\n       Nfs3FileAttributes latestAttr \u003d null;\n       try {\n         int bufferSize \u003d config.getInt(\n             CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_KEY,\n             CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_DEFAULT);\n         \n         fos \u003d dfsClient.append(fileIdPath, bufferSize, null, null);\n \n         latestAttr \u003d Nfs3Utils.getFileAttr(dfsClient, fileIdPath, iug);\n       } catch (RemoteException e) {\n         IOException io \u003d e.unwrapRemoteException();\n         if (io instanceof AlreadyBeingCreatedException) {\n           LOG.warn(\"Can\u0027t append file:\" + fileIdPath\n               + \". Possibly the file is being closed. Drop the request:\"\n               + request + \", wait for the client to retry...\");\n           return;\n         }\n         throw e;\n       } catch (IOException e) {\n         LOG.error(\"Can\u0027t apapend to file:\" + fileIdPath, e);\n         if (fos !\u003d null) {\n           fos.close();\n         }\n         WccData fileWcc \u003d new WccData(Nfs3Utils.getWccAttr(preOpAttr),\n             preOpAttr);\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n             fileWcc, count, request.getStableHow(),\n             Nfs3Constant.WRITE_COMMIT_VERF);\n-        Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n+        Nfs3Utils.writeChannel(channel, response.serialize(\n             new XDR(), xid, new VerifierNone()), xid);\n         return;\n       }\n \n       // Add open stream\n       String writeDumpDir \u003d config.get(NfsConfigKeys.DFS_NFS_FILE_DUMP_DIR_KEY,\n           NfsConfigKeys.DFS_NFS_FILE_DUMP_DIR_DEFAULT);\n       openFileCtx \u003d new OpenFileCtx(fos, latestAttr, writeDumpDir + \"/\"\n           + fileHandle.getFileId(), dfsClient, iug, aixCompatMode);\n \n       if (!addOpenFileStream(fileHandle, openFileCtx)) {\n         LOG.info(\"Can\u0027t add new stream. Close it. Tell client to retry.\");\n         try {\n           fos.close();\n         } catch (IOException e) {\n           LOG.error(\"Can\u0027t close stream for fileId:\" + handle.getFileId(), e);\n         }\n         // Notify client to retry\n         WccData fileWcc \u003d new WccData(latestAttr.getWccAttr(), latestAttr);\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_JUKEBOX,\n             fileWcc, 0, request.getStableHow(), Nfs3Constant.WRITE_COMMIT_VERF);\n         Nfs3Utils.writeChannel(channel,\n-            response.writeHeaderAndResponse(new XDR(), xid, new VerifierNone()),\n+            response.serialize(new XDR(), xid, new VerifierNone()),\n             xid);\n         return;\n       }\n \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Opened stream for appending file:\" + fileHandle.getFileId());\n       }\n     }\n \n     // Add write into the async job queue\n     openFileCtx.receivedNewWrite(dfsClient, request, channel, xid,\n         asyncDataService, iug);\n     return;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void handleWrite(DFSClient dfsClient, WRITE3Request request, Channel channel,\n      int xid, Nfs3FileAttributes preOpAttr) throws IOException {\n    int count \u003d request.getCount();\n    byte[] data \u003d request.getData().array();\n    if (data.length \u003c count) {\n      WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_INVAL);\n      Nfs3Utils.writeChannel(channel, response.serialize(\n          new XDR(), xid, new VerifierNone()), xid);\n      return;\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"handleWrite \" + request);\n    }\n\n    // Check if there is a stream to write\n    FileHandle fileHandle \u003d request.getHandle();\n    OpenFileCtx openFileCtx \u003d fileContextCache.get(fileHandle);\n    if (openFileCtx \u003d\u003d null) {\n      LOG.info(\"No opened stream for fileId:\" + fileHandle.getFileId());\n\n      String fileIdPath \u003d Nfs3Utils.getFileIdPath(fileHandle.getFileId());\n      HdfsDataOutputStream fos \u003d null;\n      Nfs3FileAttributes latestAttr \u003d null;\n      try {\n        int bufferSize \u003d config.getInt(\n            CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_KEY,\n            CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_DEFAULT);\n        \n        fos \u003d dfsClient.append(fileIdPath, bufferSize, null, null);\n\n        latestAttr \u003d Nfs3Utils.getFileAttr(dfsClient, fileIdPath, iug);\n      } catch (RemoteException e) {\n        IOException io \u003d e.unwrapRemoteException();\n        if (io instanceof AlreadyBeingCreatedException) {\n          LOG.warn(\"Can\u0027t append file:\" + fileIdPath\n              + \". Possibly the file is being closed. Drop the request:\"\n              + request + \", wait for the client to retry...\");\n          return;\n        }\n        throw e;\n      } catch (IOException e) {\n        LOG.error(\"Can\u0027t apapend to file:\" + fileIdPath, e);\n        if (fos !\u003d null) {\n          fos.close();\n        }\n        WccData fileWcc \u003d new WccData(Nfs3Utils.getWccAttr(preOpAttr),\n            preOpAttr);\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n            fileWcc, count, request.getStableHow(),\n            Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(channel, response.serialize(\n            new XDR(), xid, new VerifierNone()), xid);\n        return;\n      }\n\n      // Add open stream\n      String writeDumpDir \u003d config.get(NfsConfigKeys.DFS_NFS_FILE_DUMP_DIR_KEY,\n          NfsConfigKeys.DFS_NFS_FILE_DUMP_DIR_DEFAULT);\n      openFileCtx \u003d new OpenFileCtx(fos, latestAttr, writeDumpDir + \"/\"\n          + fileHandle.getFileId(), dfsClient, iug, aixCompatMode);\n\n      if (!addOpenFileStream(fileHandle, openFileCtx)) {\n        LOG.info(\"Can\u0027t add new stream. Close it. Tell client to retry.\");\n        try {\n          fos.close();\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t close stream for fileId:\" + handle.getFileId(), e);\n        }\n        // Notify client to retry\n        WccData fileWcc \u003d new WccData(latestAttr.getWccAttr(), latestAttr);\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_JUKEBOX,\n            fileWcc, 0, request.getStableHow(), Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(channel,\n            response.serialize(new XDR(), xid, new VerifierNone()),\n            xid);\n        return;\n      }\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Opened stream for appending file:\" + fileHandle.getFileId());\n      }\n    }\n\n    // Add write into the async job queue\n    openFileCtx.receivedNewWrite(dfsClient, request, channel, xid,\n        asyncDataService, iug);\n    return;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/WriteManager.java",
      "extendedDetails": {}
    },
    "9ff3836a367737d6dfcb12f50c8bd2f1b2233e37": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6549. Add support for accessing the NFS gateway from the AIX NFS client. Contributed by Aaron T. Myers.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1604022 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/06/14 12:39 PM",
      "commitName": "9ff3836a367737d6dfcb12f50c8bd2f1b2233e37",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "30/05/14 4:53 PM",
      "commitNameOld": "42391d260da400593812396c1ffd45d1a371d3cb",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 19.82,
      "commitsBetweenForRepo": 118,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,90 +1,90 @@\n   void handleWrite(DFSClient dfsClient, WRITE3Request request, Channel channel,\n       int xid, Nfs3FileAttributes preOpAttr) throws IOException {\n     int count \u003d request.getCount();\n     byte[] data \u003d request.getData().array();\n     if (data.length \u003c count) {\n       WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_INVAL);\n       Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n           new XDR(), xid, new VerifierNone()), xid);\n       return;\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"handleWrite \" + request);\n     }\n \n     // Check if there is a stream to write\n     FileHandle fileHandle \u003d request.getHandle();\n     OpenFileCtx openFileCtx \u003d fileContextCache.get(fileHandle);\n     if (openFileCtx \u003d\u003d null) {\n       LOG.info(\"No opened stream for fileId:\" + fileHandle.getFileId());\n \n       String fileIdPath \u003d Nfs3Utils.getFileIdPath(fileHandle.getFileId());\n       HdfsDataOutputStream fos \u003d null;\n       Nfs3FileAttributes latestAttr \u003d null;\n       try {\n         int bufferSize \u003d config.getInt(\n             CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_KEY,\n             CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_DEFAULT);\n         \n         fos \u003d dfsClient.append(fileIdPath, bufferSize, null, null);\n \n         latestAttr \u003d Nfs3Utils.getFileAttr(dfsClient, fileIdPath, iug);\n       } catch (RemoteException e) {\n         IOException io \u003d e.unwrapRemoteException();\n         if (io instanceof AlreadyBeingCreatedException) {\n           LOG.warn(\"Can\u0027t append file:\" + fileIdPath\n               + \". Possibly the file is being closed. Drop the request:\"\n               + request + \", wait for the client to retry...\");\n           return;\n         }\n         throw e;\n       } catch (IOException e) {\n         LOG.error(\"Can\u0027t apapend to file:\" + fileIdPath, e);\n         if (fos !\u003d null) {\n           fos.close();\n         }\n         WccData fileWcc \u003d new WccData(Nfs3Utils.getWccAttr(preOpAttr),\n             preOpAttr);\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n             fileWcc, count, request.getStableHow(),\n             Nfs3Constant.WRITE_COMMIT_VERF);\n         Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n             new XDR(), xid, new VerifierNone()), xid);\n         return;\n       }\n \n       // Add open stream\n       String writeDumpDir \u003d config.get(NfsConfigKeys.DFS_NFS_FILE_DUMP_DIR_KEY,\n           NfsConfigKeys.DFS_NFS_FILE_DUMP_DIR_DEFAULT);\n       openFileCtx \u003d new OpenFileCtx(fos, latestAttr, writeDumpDir + \"/\"\n-          + fileHandle.getFileId(), dfsClient, iug);\n+          + fileHandle.getFileId(), dfsClient, iug, aixCompatMode);\n \n       if (!addOpenFileStream(fileHandle, openFileCtx)) {\n         LOG.info(\"Can\u0027t add new stream. Close it. Tell client to retry.\");\n         try {\n           fos.close();\n         } catch (IOException e) {\n           LOG.error(\"Can\u0027t close stream for fileId:\" + handle.getFileId(), e);\n         }\n         // Notify client to retry\n         WccData fileWcc \u003d new WccData(latestAttr.getWccAttr(), latestAttr);\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_JUKEBOX,\n             fileWcc, 0, request.getStableHow(), Nfs3Constant.WRITE_COMMIT_VERF);\n         Nfs3Utils.writeChannel(channel,\n             response.writeHeaderAndResponse(new XDR(), xid, new VerifierNone()),\n             xid);\n         return;\n       }\n \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Opened stream for appending file:\" + fileHandle.getFileId());\n       }\n     }\n \n     // Add write into the async job queue\n     openFileCtx.receivedNewWrite(dfsClient, request, channel, xid,\n         asyncDataService, iug);\n     return;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void handleWrite(DFSClient dfsClient, WRITE3Request request, Channel channel,\n      int xid, Nfs3FileAttributes preOpAttr) throws IOException {\n    int count \u003d request.getCount();\n    byte[] data \u003d request.getData().array();\n    if (data.length \u003c count) {\n      WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_INVAL);\n      Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n          new XDR(), xid, new VerifierNone()), xid);\n      return;\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"handleWrite \" + request);\n    }\n\n    // Check if there is a stream to write\n    FileHandle fileHandle \u003d request.getHandle();\n    OpenFileCtx openFileCtx \u003d fileContextCache.get(fileHandle);\n    if (openFileCtx \u003d\u003d null) {\n      LOG.info(\"No opened stream for fileId:\" + fileHandle.getFileId());\n\n      String fileIdPath \u003d Nfs3Utils.getFileIdPath(fileHandle.getFileId());\n      HdfsDataOutputStream fos \u003d null;\n      Nfs3FileAttributes latestAttr \u003d null;\n      try {\n        int bufferSize \u003d config.getInt(\n            CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_KEY,\n            CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_DEFAULT);\n        \n        fos \u003d dfsClient.append(fileIdPath, bufferSize, null, null);\n\n        latestAttr \u003d Nfs3Utils.getFileAttr(dfsClient, fileIdPath, iug);\n      } catch (RemoteException e) {\n        IOException io \u003d e.unwrapRemoteException();\n        if (io instanceof AlreadyBeingCreatedException) {\n          LOG.warn(\"Can\u0027t append file:\" + fileIdPath\n              + \". Possibly the file is being closed. Drop the request:\"\n              + request + \", wait for the client to retry...\");\n          return;\n        }\n        throw e;\n      } catch (IOException e) {\n        LOG.error(\"Can\u0027t apapend to file:\" + fileIdPath, e);\n        if (fos !\u003d null) {\n          fos.close();\n        }\n        WccData fileWcc \u003d new WccData(Nfs3Utils.getWccAttr(preOpAttr),\n            preOpAttr);\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n            fileWcc, count, request.getStableHow(),\n            Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n            new XDR(), xid, new VerifierNone()), xid);\n        return;\n      }\n\n      // Add open stream\n      String writeDumpDir \u003d config.get(NfsConfigKeys.DFS_NFS_FILE_DUMP_DIR_KEY,\n          NfsConfigKeys.DFS_NFS_FILE_DUMP_DIR_DEFAULT);\n      openFileCtx \u003d new OpenFileCtx(fos, latestAttr, writeDumpDir + \"/\"\n          + fileHandle.getFileId(), dfsClient, iug, aixCompatMode);\n\n      if (!addOpenFileStream(fileHandle, openFileCtx)) {\n        LOG.info(\"Can\u0027t add new stream. Close it. Tell client to retry.\");\n        try {\n          fos.close();\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t close stream for fileId:\" + handle.getFileId(), e);\n        }\n        // Notify client to retry\n        WccData fileWcc \u003d new WccData(latestAttr.getWccAttr(), latestAttr);\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_JUKEBOX,\n            fileWcc, 0, request.getStableHow(), Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(channel,\n            response.writeHeaderAndResponse(new XDR(), xid, new VerifierNone()),\n            xid);\n        return;\n      }\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Opened stream for appending file:\" + fileHandle.getFileId());\n      }\n    }\n\n    // Add write into the async job queue\n    openFileCtx.receivedNewWrite(dfsClient, request, channel, xid,\n        asyncDataService, iug);\n    return;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/WriteManager.java",
      "extendedDetails": {}
    },
    "42391d260da400593812396c1ffd45d1a371d3cb": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6056. Clean up NFS config settings. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1598782 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "30/05/14 4:53 PM",
      "commitName": "42391d260da400593812396c1ffd45d1a371d3cb",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "24/03/14 1:49 PM",
      "commitNameOld": "3bfd18c6b0483ae27eff6d53bda934e67dda5464",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 67.13,
      "commitsBetweenForRepo": 407,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,90 +1,90 @@\n   void handleWrite(DFSClient dfsClient, WRITE3Request request, Channel channel,\n       int xid, Nfs3FileAttributes preOpAttr) throws IOException {\n     int count \u003d request.getCount();\n     byte[] data \u003d request.getData().array();\n     if (data.length \u003c count) {\n       WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_INVAL);\n       Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n           new XDR(), xid, new VerifierNone()), xid);\n       return;\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"handleWrite \" + request);\n     }\n \n     // Check if there is a stream to write\n     FileHandle fileHandle \u003d request.getHandle();\n     OpenFileCtx openFileCtx \u003d fileContextCache.get(fileHandle);\n     if (openFileCtx \u003d\u003d null) {\n       LOG.info(\"No opened stream for fileId:\" + fileHandle.getFileId());\n \n       String fileIdPath \u003d Nfs3Utils.getFileIdPath(fileHandle.getFileId());\n       HdfsDataOutputStream fos \u003d null;\n       Nfs3FileAttributes latestAttr \u003d null;\n       try {\n         int bufferSize \u003d config.getInt(\n             CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_KEY,\n             CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_DEFAULT);\n         \n         fos \u003d dfsClient.append(fileIdPath, bufferSize, null, null);\n \n         latestAttr \u003d Nfs3Utils.getFileAttr(dfsClient, fileIdPath, iug);\n       } catch (RemoteException e) {\n         IOException io \u003d e.unwrapRemoteException();\n         if (io instanceof AlreadyBeingCreatedException) {\n           LOG.warn(\"Can\u0027t append file:\" + fileIdPath\n               + \". Possibly the file is being closed. Drop the request:\"\n               + request + \", wait for the client to retry...\");\n           return;\n         }\n         throw e;\n       } catch (IOException e) {\n         LOG.error(\"Can\u0027t apapend to file:\" + fileIdPath, e);\n         if (fos !\u003d null) {\n           fos.close();\n         }\n         WccData fileWcc \u003d new WccData(Nfs3Utils.getWccAttr(preOpAttr),\n             preOpAttr);\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n             fileWcc, count, request.getStableHow(),\n             Nfs3Constant.WRITE_COMMIT_VERF);\n         Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n             new XDR(), xid, new VerifierNone()), xid);\n         return;\n       }\n \n       // Add open stream\n-      String writeDumpDir \u003d config.get(Nfs3Constant.FILE_DUMP_DIR_KEY,\n-          Nfs3Constant.FILE_DUMP_DIR_DEFAULT);\n+      String writeDumpDir \u003d config.get(NfsConfigKeys.DFS_NFS_FILE_DUMP_DIR_KEY,\n+          NfsConfigKeys.DFS_NFS_FILE_DUMP_DIR_DEFAULT);\n       openFileCtx \u003d new OpenFileCtx(fos, latestAttr, writeDumpDir + \"/\"\n           + fileHandle.getFileId(), dfsClient, iug);\n \n       if (!addOpenFileStream(fileHandle, openFileCtx)) {\n         LOG.info(\"Can\u0027t add new stream. Close it. Tell client to retry.\");\n         try {\n           fos.close();\n         } catch (IOException e) {\n           LOG.error(\"Can\u0027t close stream for fileId:\" + handle.getFileId(), e);\n         }\n         // Notify client to retry\n         WccData fileWcc \u003d new WccData(latestAttr.getWccAttr(), latestAttr);\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_JUKEBOX,\n             fileWcc, 0, request.getStableHow(), Nfs3Constant.WRITE_COMMIT_VERF);\n         Nfs3Utils.writeChannel(channel,\n             response.writeHeaderAndResponse(new XDR(), xid, new VerifierNone()),\n             xid);\n         return;\n       }\n \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Opened stream for appending file:\" + fileHandle.getFileId());\n       }\n     }\n \n     // Add write into the async job queue\n     openFileCtx.receivedNewWrite(dfsClient, request, channel, xid,\n         asyncDataService, iug);\n     return;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void handleWrite(DFSClient dfsClient, WRITE3Request request, Channel channel,\n      int xid, Nfs3FileAttributes preOpAttr) throws IOException {\n    int count \u003d request.getCount();\n    byte[] data \u003d request.getData().array();\n    if (data.length \u003c count) {\n      WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_INVAL);\n      Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n          new XDR(), xid, new VerifierNone()), xid);\n      return;\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"handleWrite \" + request);\n    }\n\n    // Check if there is a stream to write\n    FileHandle fileHandle \u003d request.getHandle();\n    OpenFileCtx openFileCtx \u003d fileContextCache.get(fileHandle);\n    if (openFileCtx \u003d\u003d null) {\n      LOG.info(\"No opened stream for fileId:\" + fileHandle.getFileId());\n\n      String fileIdPath \u003d Nfs3Utils.getFileIdPath(fileHandle.getFileId());\n      HdfsDataOutputStream fos \u003d null;\n      Nfs3FileAttributes latestAttr \u003d null;\n      try {\n        int bufferSize \u003d config.getInt(\n            CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_KEY,\n            CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_DEFAULT);\n        \n        fos \u003d dfsClient.append(fileIdPath, bufferSize, null, null);\n\n        latestAttr \u003d Nfs3Utils.getFileAttr(dfsClient, fileIdPath, iug);\n      } catch (RemoteException e) {\n        IOException io \u003d e.unwrapRemoteException();\n        if (io instanceof AlreadyBeingCreatedException) {\n          LOG.warn(\"Can\u0027t append file:\" + fileIdPath\n              + \". Possibly the file is being closed. Drop the request:\"\n              + request + \", wait for the client to retry...\");\n          return;\n        }\n        throw e;\n      } catch (IOException e) {\n        LOG.error(\"Can\u0027t apapend to file:\" + fileIdPath, e);\n        if (fos !\u003d null) {\n          fos.close();\n        }\n        WccData fileWcc \u003d new WccData(Nfs3Utils.getWccAttr(preOpAttr),\n            preOpAttr);\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n            fileWcc, count, request.getStableHow(),\n            Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n            new XDR(), xid, new VerifierNone()), xid);\n        return;\n      }\n\n      // Add open stream\n      String writeDumpDir \u003d config.get(NfsConfigKeys.DFS_NFS_FILE_DUMP_DIR_KEY,\n          NfsConfigKeys.DFS_NFS_FILE_DUMP_DIR_DEFAULT);\n      openFileCtx \u003d new OpenFileCtx(fos, latestAttr, writeDumpDir + \"/\"\n          + fileHandle.getFileId(), dfsClient, iug);\n\n      if (!addOpenFileStream(fileHandle, openFileCtx)) {\n        LOG.info(\"Can\u0027t add new stream. Close it. Tell client to retry.\");\n        try {\n          fos.close();\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t close stream for fileId:\" + handle.getFileId(), e);\n        }\n        // Notify client to retry\n        WccData fileWcc \u003d new WccData(latestAttr.getWccAttr(), latestAttr);\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_JUKEBOX,\n            fileWcc, 0, request.getStableHow(), Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(channel,\n            response.writeHeaderAndResponse(new XDR(), xid, new VerifierNone()),\n            xid);\n        return;\n      }\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Opened stream for appending file:\" + fileHandle.getFileId());\n      }\n    }\n\n    // Add write into the async job queue\n    openFileCtx.receivedNewWrite(dfsClient, request, channel, xid,\n        asyncDataService, iug);\n    return;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/WriteManager.java",
      "extendedDetails": {}
    },
    "3bfd18c6b0483ae27eff6d53bda934e67dda5464": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6050. NFS does not handle exceptions correctly in a few places. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1581055 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/03/14 1:49 PM",
      "commitName": "3bfd18c6b0483ae27eff6d53bda934e67dda5464",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "27/11/13 3:41 PM",
      "commitNameOld": "5ea533c2bfc72fd3adbfd972d18806fbc397e0f8",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 116.88,
      "commitsBetweenForRepo": 832,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,90 +1,90 @@\n   void handleWrite(DFSClient dfsClient, WRITE3Request request, Channel channel,\n       int xid, Nfs3FileAttributes preOpAttr) throws IOException {\n     int count \u003d request.getCount();\n     byte[] data \u003d request.getData().array();\n     if (data.length \u003c count) {\n       WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_INVAL);\n       Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n           new XDR(), xid, new VerifierNone()), xid);\n       return;\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"handleWrite \" + request);\n     }\n \n     // Check if there is a stream to write\n     FileHandle fileHandle \u003d request.getHandle();\n     OpenFileCtx openFileCtx \u003d fileContextCache.get(fileHandle);\n     if (openFileCtx \u003d\u003d null) {\n       LOG.info(\"No opened stream for fileId:\" + fileHandle.getFileId());\n \n       String fileIdPath \u003d Nfs3Utils.getFileIdPath(fileHandle.getFileId());\n       HdfsDataOutputStream fos \u003d null;\n       Nfs3FileAttributes latestAttr \u003d null;\n       try {\n         int bufferSize \u003d config.getInt(\n             CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_KEY,\n             CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_DEFAULT);\n         \n         fos \u003d dfsClient.append(fileIdPath, bufferSize, null, null);\n \n         latestAttr \u003d Nfs3Utils.getFileAttr(dfsClient, fileIdPath, iug);\n       } catch (RemoteException e) {\n         IOException io \u003d e.unwrapRemoteException();\n         if (io instanceof AlreadyBeingCreatedException) {\n           LOG.warn(\"Can\u0027t append file:\" + fileIdPath\n               + \". Possibly the file is being closed. Drop the request:\"\n               + request + \", wait for the client to retry...\");\n           return;\n         }\n         throw e;\n       } catch (IOException e) {\n-        LOG.error(\"Can\u0027t apapend to file:\" + fileIdPath + \", error:\" + e);\n+        LOG.error(\"Can\u0027t apapend to file:\" + fileIdPath, e);\n         if (fos !\u003d null) {\n           fos.close();\n         }\n         WccData fileWcc \u003d new WccData(Nfs3Utils.getWccAttr(preOpAttr),\n             preOpAttr);\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n             fileWcc, count, request.getStableHow(),\n             Nfs3Constant.WRITE_COMMIT_VERF);\n         Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n             new XDR(), xid, new VerifierNone()), xid);\n         return;\n       }\n \n       // Add open stream\n       String writeDumpDir \u003d config.get(Nfs3Constant.FILE_DUMP_DIR_KEY,\n           Nfs3Constant.FILE_DUMP_DIR_DEFAULT);\n       openFileCtx \u003d new OpenFileCtx(fos, latestAttr, writeDumpDir + \"/\"\n           + fileHandle.getFileId(), dfsClient, iug);\n \n       if (!addOpenFileStream(fileHandle, openFileCtx)) {\n         LOG.info(\"Can\u0027t add new stream. Close it. Tell client to retry.\");\n         try {\n           fos.close();\n         } catch (IOException e) {\n-          LOG.error(\"Can\u0027t close stream for fileId:\" + handle.getFileId());\n+          LOG.error(\"Can\u0027t close stream for fileId:\" + handle.getFileId(), e);\n         }\n         // Notify client to retry\n         WccData fileWcc \u003d new WccData(latestAttr.getWccAttr(), latestAttr);\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_JUKEBOX,\n             fileWcc, 0, request.getStableHow(), Nfs3Constant.WRITE_COMMIT_VERF);\n         Nfs3Utils.writeChannel(channel,\n             response.writeHeaderAndResponse(new XDR(), xid, new VerifierNone()),\n             xid);\n         return;\n       }\n \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Opened stream for appending file:\" + fileHandle.getFileId());\n       }\n     }\n \n     // Add write into the async job queue\n     openFileCtx.receivedNewWrite(dfsClient, request, channel, xid,\n         asyncDataService, iug);\n     return;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void handleWrite(DFSClient dfsClient, WRITE3Request request, Channel channel,\n      int xid, Nfs3FileAttributes preOpAttr) throws IOException {\n    int count \u003d request.getCount();\n    byte[] data \u003d request.getData().array();\n    if (data.length \u003c count) {\n      WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_INVAL);\n      Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n          new XDR(), xid, new VerifierNone()), xid);\n      return;\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"handleWrite \" + request);\n    }\n\n    // Check if there is a stream to write\n    FileHandle fileHandle \u003d request.getHandle();\n    OpenFileCtx openFileCtx \u003d fileContextCache.get(fileHandle);\n    if (openFileCtx \u003d\u003d null) {\n      LOG.info(\"No opened stream for fileId:\" + fileHandle.getFileId());\n\n      String fileIdPath \u003d Nfs3Utils.getFileIdPath(fileHandle.getFileId());\n      HdfsDataOutputStream fos \u003d null;\n      Nfs3FileAttributes latestAttr \u003d null;\n      try {\n        int bufferSize \u003d config.getInt(\n            CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_KEY,\n            CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_DEFAULT);\n        \n        fos \u003d dfsClient.append(fileIdPath, bufferSize, null, null);\n\n        latestAttr \u003d Nfs3Utils.getFileAttr(dfsClient, fileIdPath, iug);\n      } catch (RemoteException e) {\n        IOException io \u003d e.unwrapRemoteException();\n        if (io instanceof AlreadyBeingCreatedException) {\n          LOG.warn(\"Can\u0027t append file:\" + fileIdPath\n              + \". Possibly the file is being closed. Drop the request:\"\n              + request + \", wait for the client to retry...\");\n          return;\n        }\n        throw e;\n      } catch (IOException e) {\n        LOG.error(\"Can\u0027t apapend to file:\" + fileIdPath, e);\n        if (fos !\u003d null) {\n          fos.close();\n        }\n        WccData fileWcc \u003d new WccData(Nfs3Utils.getWccAttr(preOpAttr),\n            preOpAttr);\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n            fileWcc, count, request.getStableHow(),\n            Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n            new XDR(), xid, new VerifierNone()), xid);\n        return;\n      }\n\n      // Add open stream\n      String writeDumpDir \u003d config.get(Nfs3Constant.FILE_DUMP_DIR_KEY,\n          Nfs3Constant.FILE_DUMP_DIR_DEFAULT);\n      openFileCtx \u003d new OpenFileCtx(fos, latestAttr, writeDumpDir + \"/\"\n          + fileHandle.getFileId(), dfsClient, iug);\n\n      if (!addOpenFileStream(fileHandle, openFileCtx)) {\n        LOG.info(\"Can\u0027t add new stream. Close it. Tell client to retry.\");\n        try {\n          fos.close();\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t close stream for fileId:\" + handle.getFileId(), e);\n        }\n        // Notify client to retry\n        WccData fileWcc \u003d new WccData(latestAttr.getWccAttr(), latestAttr);\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_JUKEBOX,\n            fileWcc, 0, request.getStableHow(), Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(channel,\n            response.writeHeaderAndResponse(new XDR(), xid, new VerifierNone()),\n            xid);\n        return;\n      }\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Opened stream for appending file:\" + fileHandle.getFileId());\n      }\n    }\n\n    // Add write into the async job queue\n    openFileCtx.receivedNewWrite(dfsClient, request, channel, xid,\n        asyncDataService, iug);\n    return;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/WriteManager.java",
      "extendedDetails": {}
    },
    "3fccdec6e0a8e9305fc75921211c3745eddb9c45": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5364. Add OpenFileCtx cache. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1539834 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/11/13 1:49 PM",
      "commitName": "3fccdec6e0a8e9305fc75921211c3745eddb9c45",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "07/11/13 10:02 AM",
      "commitNameOld": "16c6755554cc5ecd9d4e0ba74b75b10c74bb0ab4",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 0.16,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,72 +1,90 @@\n   void handleWrite(DFSClient dfsClient, WRITE3Request request, Channel channel,\n       int xid, Nfs3FileAttributes preOpAttr) throws IOException {\n-    // First write request starts the async data service\n-    if (!asyncDataServiceStarted) {\n-      startAsyncDataSerivce();\n-    }\n-\n-    long offset \u003d request.getOffset();\n     int count \u003d request.getCount();\n-    WriteStableHow stableHow \u003d request.getStableHow();\n     byte[] data \u003d request.getData().array();\n     if (data.length \u003c count) {\n       WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_INVAL);\n       Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n           new XDR(), xid, new VerifierNone()), xid);\n       return;\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     if (LOG.isDebugEnabled()) {\n-      LOG.debug(\"handleWrite fileId: \" + handle.getFileId() + \" offset: \"\n-          + offset + \" length:\" + count + \" stableHow:\" + stableHow.getValue());\n+      LOG.debug(\"handleWrite \" + request);\n     }\n \n     // Check if there is a stream to write\n     FileHandle fileHandle \u003d request.getHandle();\n-    OpenFileCtx openFileCtx \u003d openFileMap.get(fileHandle);\n+    OpenFileCtx openFileCtx \u003d fileContextCache.get(fileHandle);\n     if (openFileCtx \u003d\u003d null) {\n       LOG.info(\"No opened stream for fileId:\" + fileHandle.getFileId());\n \n       String fileIdPath \u003d Nfs3Utils.getFileIdPath(fileHandle.getFileId());\n       HdfsDataOutputStream fos \u003d null;\n       Nfs3FileAttributes latestAttr \u003d null;\n       try {\n         int bufferSize \u003d config.getInt(\n             CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_KEY,\n             CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_DEFAULT);\n         \n         fos \u003d dfsClient.append(fileIdPath, bufferSize, null, null);\n \n         latestAttr \u003d Nfs3Utils.getFileAttr(dfsClient, fileIdPath, iug);\n+      } catch (RemoteException e) {\n+        IOException io \u003d e.unwrapRemoteException();\n+        if (io instanceof AlreadyBeingCreatedException) {\n+          LOG.warn(\"Can\u0027t append file:\" + fileIdPath\n+              + \". Possibly the file is being closed. Drop the request:\"\n+              + request + \", wait for the client to retry...\");\n+          return;\n+        }\n+        throw e;\n       } catch (IOException e) {\n         LOG.error(\"Can\u0027t apapend to file:\" + fileIdPath + \", error:\" + e);\n         if (fos !\u003d null) {\n           fos.close();\n         }\n         WccData fileWcc \u003d new WccData(Nfs3Utils.getWccAttr(preOpAttr),\n             preOpAttr);\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n             fileWcc, count, request.getStableHow(),\n             Nfs3Constant.WRITE_COMMIT_VERF);\n         Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n             new XDR(), xid, new VerifierNone()), xid);\n         return;\n       }\n \n       // Add open stream\n       String writeDumpDir \u003d config.get(Nfs3Constant.FILE_DUMP_DIR_KEY,\n           Nfs3Constant.FILE_DUMP_DIR_DEFAULT);\n       openFileCtx \u003d new OpenFileCtx(fos, latestAttr, writeDumpDir + \"/\"\n           + fileHandle.getFileId(), dfsClient, iug);\n-      addOpenFileStream(fileHandle, openFileCtx);\n+\n+      if (!addOpenFileStream(fileHandle, openFileCtx)) {\n+        LOG.info(\"Can\u0027t add new stream. Close it. Tell client to retry.\");\n+        try {\n+          fos.close();\n+        } catch (IOException e) {\n+          LOG.error(\"Can\u0027t close stream for fileId:\" + handle.getFileId());\n+        }\n+        // Notify client to retry\n+        WccData fileWcc \u003d new WccData(latestAttr.getWccAttr(), latestAttr);\n+        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_JUKEBOX,\n+            fileWcc, 0, request.getStableHow(), Nfs3Constant.WRITE_COMMIT_VERF);\n+        Nfs3Utils.writeChannel(channel,\n+            response.writeHeaderAndResponse(new XDR(), xid, new VerifierNone()),\n+            xid);\n+        return;\n+      }\n+\n       if (LOG.isDebugEnabled()) {\n-        LOG.debug(\"opened stream for file:\" + fileHandle.getFileId());\n+        LOG.debug(\"Opened stream for appending file:\" + fileHandle.getFileId());\n       }\n     }\n \n     // Add write into the async job queue\n     openFileCtx.receivedNewWrite(dfsClient, request, channel, xid,\n         asyncDataService, iug);\n     return;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void handleWrite(DFSClient dfsClient, WRITE3Request request, Channel channel,\n      int xid, Nfs3FileAttributes preOpAttr) throws IOException {\n    int count \u003d request.getCount();\n    byte[] data \u003d request.getData().array();\n    if (data.length \u003c count) {\n      WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_INVAL);\n      Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n          new XDR(), xid, new VerifierNone()), xid);\n      return;\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"handleWrite \" + request);\n    }\n\n    // Check if there is a stream to write\n    FileHandle fileHandle \u003d request.getHandle();\n    OpenFileCtx openFileCtx \u003d fileContextCache.get(fileHandle);\n    if (openFileCtx \u003d\u003d null) {\n      LOG.info(\"No opened stream for fileId:\" + fileHandle.getFileId());\n\n      String fileIdPath \u003d Nfs3Utils.getFileIdPath(fileHandle.getFileId());\n      HdfsDataOutputStream fos \u003d null;\n      Nfs3FileAttributes latestAttr \u003d null;\n      try {\n        int bufferSize \u003d config.getInt(\n            CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_KEY,\n            CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_DEFAULT);\n        \n        fos \u003d dfsClient.append(fileIdPath, bufferSize, null, null);\n\n        latestAttr \u003d Nfs3Utils.getFileAttr(dfsClient, fileIdPath, iug);\n      } catch (RemoteException e) {\n        IOException io \u003d e.unwrapRemoteException();\n        if (io instanceof AlreadyBeingCreatedException) {\n          LOG.warn(\"Can\u0027t append file:\" + fileIdPath\n              + \". Possibly the file is being closed. Drop the request:\"\n              + request + \", wait for the client to retry...\");\n          return;\n        }\n        throw e;\n      } catch (IOException e) {\n        LOG.error(\"Can\u0027t apapend to file:\" + fileIdPath + \", error:\" + e);\n        if (fos !\u003d null) {\n          fos.close();\n        }\n        WccData fileWcc \u003d new WccData(Nfs3Utils.getWccAttr(preOpAttr),\n            preOpAttr);\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n            fileWcc, count, request.getStableHow(),\n            Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n            new XDR(), xid, new VerifierNone()), xid);\n        return;\n      }\n\n      // Add open stream\n      String writeDumpDir \u003d config.get(Nfs3Constant.FILE_DUMP_DIR_KEY,\n          Nfs3Constant.FILE_DUMP_DIR_DEFAULT);\n      openFileCtx \u003d new OpenFileCtx(fos, latestAttr, writeDumpDir + \"/\"\n          + fileHandle.getFileId(), dfsClient, iug);\n\n      if (!addOpenFileStream(fileHandle, openFileCtx)) {\n        LOG.info(\"Can\u0027t add new stream. Close it. Tell client to retry.\");\n        try {\n          fos.close();\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t close stream for fileId:\" + handle.getFileId());\n        }\n        // Notify client to retry\n        WccData fileWcc \u003d new WccData(latestAttr.getWccAttr(), latestAttr);\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_JUKEBOX,\n            fileWcc, 0, request.getStableHow(), Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(channel,\n            response.writeHeaderAndResponse(new XDR(), xid, new VerifierNone()),\n            xid);\n        return;\n      }\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Opened stream for appending file:\" + fileHandle.getFileId());\n      }\n    }\n\n    // Add write into the async job queue\n    openFileCtx.receivedNewWrite(dfsClient, request, channel, xid,\n        asyncDataService, iug);\n    return;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/WriteManager.java",
      "extendedDetails": {}
    },
    "5c02d2f6225144772dcb975d3144b057b71d6476": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5281. COMMIT request should not block. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1530461 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/10/13 4:40 PM",
      "commitName": "5c02d2f6225144772dcb975d3144b057b71d6476",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "23/09/13 1:02 PM",
      "commitNameOld": "28e3d09230971b32f74284311931525cb7ad1b7c",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 15.15,
      "commitsBetweenForRepo": 122,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,90 +1,72 @@\n   void handleWrite(DFSClient dfsClient, WRITE3Request request, Channel channel,\n       int xid, Nfs3FileAttributes preOpAttr) throws IOException {\n     // First write request starts the async data service\n     if (!asyncDataServiceStarted) {\n       startAsyncDataSerivce();\n     }\n \n     long offset \u003d request.getOffset();\n     int count \u003d request.getCount();\n     WriteStableHow stableHow \u003d request.getStableHow();\n     byte[] data \u003d request.getData().array();\n     if (data.length \u003c count) {\n       WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_INVAL);\n       Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n           new XDR(), xid, new VerifierNone()), xid);\n       return;\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"handleWrite fileId: \" + handle.getFileId() + \" offset: \"\n           + offset + \" length:\" + count + \" stableHow:\" + stableHow.getValue());\n     }\n \n     // Check if there is a stream to write\n     FileHandle fileHandle \u003d request.getHandle();\n     OpenFileCtx openFileCtx \u003d openFileMap.get(fileHandle);\n     if (openFileCtx \u003d\u003d null) {\n       LOG.info(\"No opened stream for fileId:\" + fileHandle.getFileId());\n \n       String fileIdPath \u003d Nfs3Utils.getFileIdPath(fileHandle.getFileId());\n       HdfsDataOutputStream fos \u003d null;\n       Nfs3FileAttributes latestAttr \u003d null;\n       try {\n         int bufferSize \u003d config.getInt(\n             CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_KEY,\n             CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_DEFAULT);\n         \n         fos \u003d dfsClient.append(fileIdPath, bufferSize, null, null);\n \n         latestAttr \u003d Nfs3Utils.getFileAttr(dfsClient, fileIdPath, iug);\n       } catch (IOException e) {\n         LOG.error(\"Can\u0027t apapend to file:\" + fileIdPath + \", error:\" + e);\n         if (fos !\u003d null) {\n           fos.close();\n         }\n         WccData fileWcc \u003d new WccData(Nfs3Utils.getWccAttr(preOpAttr),\n             preOpAttr);\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n             fileWcc, count, request.getStableHow(),\n             Nfs3Constant.WRITE_COMMIT_VERF);\n         Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n             new XDR(), xid, new VerifierNone()), xid);\n         return;\n       }\n \n       // Add open stream\n       String writeDumpDir \u003d config.get(Nfs3Constant.FILE_DUMP_DIR_KEY,\n           Nfs3Constant.FILE_DUMP_DIR_DEFAULT);\n       openFileCtx \u003d new OpenFileCtx(fos, latestAttr, writeDumpDir + \"/\"\n-          + fileHandle.getFileId());\n+          + fileHandle.getFileId(), dfsClient, iug);\n       addOpenFileStream(fileHandle, openFileCtx);\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"opened stream for file:\" + fileHandle.getFileId());\n       }\n     }\n \n     // Add write into the async job queue\n     openFileCtx.receivedNewWrite(dfsClient, request, channel, xid,\n         asyncDataService, iug);\n-    // Block stable write\n-    if (request.getStableHow() !\u003d WriteStableHow.UNSTABLE) {\n-      if (handleCommit(fileHandle, offset + count)) {\n-        Nfs3FileAttributes postOpAttr \u003d getFileAttr(dfsClient, handle, iug);\n-        WccData fileWcc \u003d new WccData(Nfs3Utils.getWccAttr(preOpAttr),\n-            postOpAttr);\n-        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3_OK,\n-            fileWcc, count, request.getStableHow(),\n-            Nfs3Constant.WRITE_COMMIT_VERF);\n-        Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n-            new XDR(), xid, new VerifierNone()), xid);\n-      } else {\n-        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO);\n-        Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n-            new XDR(), xid, new VerifierNone()), xid);\n-      }\n-    }\n-\n     return;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void handleWrite(DFSClient dfsClient, WRITE3Request request, Channel channel,\n      int xid, Nfs3FileAttributes preOpAttr) throws IOException {\n    // First write request starts the async data service\n    if (!asyncDataServiceStarted) {\n      startAsyncDataSerivce();\n    }\n\n    long offset \u003d request.getOffset();\n    int count \u003d request.getCount();\n    WriteStableHow stableHow \u003d request.getStableHow();\n    byte[] data \u003d request.getData().array();\n    if (data.length \u003c count) {\n      WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_INVAL);\n      Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n          new XDR(), xid, new VerifierNone()), xid);\n      return;\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"handleWrite fileId: \" + handle.getFileId() + \" offset: \"\n          + offset + \" length:\" + count + \" stableHow:\" + stableHow.getValue());\n    }\n\n    // Check if there is a stream to write\n    FileHandle fileHandle \u003d request.getHandle();\n    OpenFileCtx openFileCtx \u003d openFileMap.get(fileHandle);\n    if (openFileCtx \u003d\u003d null) {\n      LOG.info(\"No opened stream for fileId:\" + fileHandle.getFileId());\n\n      String fileIdPath \u003d Nfs3Utils.getFileIdPath(fileHandle.getFileId());\n      HdfsDataOutputStream fos \u003d null;\n      Nfs3FileAttributes latestAttr \u003d null;\n      try {\n        int bufferSize \u003d config.getInt(\n            CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_KEY,\n            CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_DEFAULT);\n        \n        fos \u003d dfsClient.append(fileIdPath, bufferSize, null, null);\n\n        latestAttr \u003d Nfs3Utils.getFileAttr(dfsClient, fileIdPath, iug);\n      } catch (IOException e) {\n        LOG.error(\"Can\u0027t apapend to file:\" + fileIdPath + \", error:\" + e);\n        if (fos !\u003d null) {\n          fos.close();\n        }\n        WccData fileWcc \u003d new WccData(Nfs3Utils.getWccAttr(preOpAttr),\n            preOpAttr);\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n            fileWcc, count, request.getStableHow(),\n            Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n            new XDR(), xid, new VerifierNone()), xid);\n        return;\n      }\n\n      // Add open stream\n      String writeDumpDir \u003d config.get(Nfs3Constant.FILE_DUMP_DIR_KEY,\n          Nfs3Constant.FILE_DUMP_DIR_DEFAULT);\n      openFileCtx \u003d new OpenFileCtx(fos, latestAttr, writeDumpDir + \"/\"\n          + fileHandle.getFileId(), dfsClient, iug);\n      addOpenFileStream(fileHandle, openFileCtx);\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"opened stream for file:\" + fileHandle.getFileId());\n      }\n    }\n\n    // Add write into the async job queue\n    openFileCtx.receivedNewWrite(dfsClient, request, channel, xid,\n        asyncDataService, iug);\n    return;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/WriteManager.java",
      "extendedDetails": {}
    },
    "5e18410e06dd63113c49029894007e0878312903": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5212. Refactor RpcMessage and NFS3Response to support different types of authentication information. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1524298 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/09/13 11:08 PM",
      "commitName": "5e18410e06dd63113c49029894007e0878312903",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "13/09/13 4:14 PM",
      "commitNameOld": "a56a4b6ef06602312144783b7507bf2b82821e4f",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 4.29,
      "commitsBetweenForRepo": 26,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,86 +1,90 @@\n   void handleWrite(DFSClient dfsClient, WRITE3Request request, Channel channel,\n       int xid, Nfs3FileAttributes preOpAttr) throws IOException {\n     // First write request starts the async data service\n     if (!asyncDataServiceStarted) {\n       startAsyncDataSerivce();\n     }\n \n     long offset \u003d request.getOffset();\n     int count \u003d request.getCount();\n     WriteStableHow stableHow \u003d request.getStableHow();\n     byte[] data \u003d request.getData().array();\n     if (data.length \u003c count) {\n       WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_INVAL);\n-      Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid), xid);\n+      Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n+          new XDR(), xid, new VerifierNone()), xid);\n       return;\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"handleWrite fileId: \" + handle.getFileId() + \" offset: \"\n           + offset + \" length:\" + count + \" stableHow:\" + stableHow.getValue());\n     }\n \n     // Check if there is a stream to write\n     FileHandle fileHandle \u003d request.getHandle();\n     OpenFileCtx openFileCtx \u003d openFileMap.get(fileHandle);\n     if (openFileCtx \u003d\u003d null) {\n       LOG.info(\"No opened stream for fileId:\" + fileHandle.getFileId());\n \n       String fileIdPath \u003d Nfs3Utils.getFileIdPath(fileHandle.getFileId());\n       HdfsDataOutputStream fos \u003d null;\n       Nfs3FileAttributes latestAttr \u003d null;\n       try {\n         int bufferSize \u003d config.getInt(\n             CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_KEY,\n             CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_DEFAULT);\n         \n         fos \u003d dfsClient.append(fileIdPath, bufferSize, null, null);\n \n         latestAttr \u003d Nfs3Utils.getFileAttr(dfsClient, fileIdPath, iug);\n       } catch (IOException e) {\n         LOG.error(\"Can\u0027t apapend to file:\" + fileIdPath + \", error:\" + e);\n         if (fos !\u003d null) {\n           fos.close();\n         }\n         WccData fileWcc \u003d new WccData(Nfs3Utils.getWccAttr(preOpAttr),\n             preOpAttr);\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n             fileWcc, count, request.getStableHow(),\n             Nfs3Constant.WRITE_COMMIT_VERF);\n-        Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid), xid);\n+        Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n+            new XDR(), xid, new VerifierNone()), xid);\n         return;\n       }\n \n       // Add open stream\n       String writeDumpDir \u003d config.get(Nfs3Constant.FILE_DUMP_DIR_KEY,\n           Nfs3Constant.FILE_DUMP_DIR_DEFAULT);\n       openFileCtx \u003d new OpenFileCtx(fos, latestAttr, writeDumpDir + \"/\"\n           + fileHandle.getFileId());\n       addOpenFileStream(fileHandle, openFileCtx);\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"opened stream for file:\" + fileHandle.getFileId());\n       }\n     }\n \n     // Add write into the async job queue\n     openFileCtx.receivedNewWrite(dfsClient, request, channel, xid,\n         asyncDataService, iug);\n     // Block stable write\n     if (request.getStableHow() !\u003d WriteStableHow.UNSTABLE) {\n       if (handleCommit(fileHandle, offset + count)) {\n         Nfs3FileAttributes postOpAttr \u003d getFileAttr(dfsClient, handle, iug);\n         WccData fileWcc \u003d new WccData(Nfs3Utils.getWccAttr(preOpAttr),\n             postOpAttr);\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3_OK,\n             fileWcc, count, request.getStableHow(),\n             Nfs3Constant.WRITE_COMMIT_VERF);\n-        Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid), xid);\n+        Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n+            new XDR(), xid, new VerifierNone()), xid);\n       } else {\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO);\n-        Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid), xid);\n+        Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n+            new XDR(), xid, new VerifierNone()), xid);\n       }\n     }\n \n     return;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void handleWrite(DFSClient dfsClient, WRITE3Request request, Channel channel,\n      int xid, Nfs3FileAttributes preOpAttr) throws IOException {\n    // First write request starts the async data service\n    if (!asyncDataServiceStarted) {\n      startAsyncDataSerivce();\n    }\n\n    long offset \u003d request.getOffset();\n    int count \u003d request.getCount();\n    WriteStableHow stableHow \u003d request.getStableHow();\n    byte[] data \u003d request.getData().array();\n    if (data.length \u003c count) {\n      WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_INVAL);\n      Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n          new XDR(), xid, new VerifierNone()), xid);\n      return;\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"handleWrite fileId: \" + handle.getFileId() + \" offset: \"\n          + offset + \" length:\" + count + \" stableHow:\" + stableHow.getValue());\n    }\n\n    // Check if there is a stream to write\n    FileHandle fileHandle \u003d request.getHandle();\n    OpenFileCtx openFileCtx \u003d openFileMap.get(fileHandle);\n    if (openFileCtx \u003d\u003d null) {\n      LOG.info(\"No opened stream for fileId:\" + fileHandle.getFileId());\n\n      String fileIdPath \u003d Nfs3Utils.getFileIdPath(fileHandle.getFileId());\n      HdfsDataOutputStream fos \u003d null;\n      Nfs3FileAttributes latestAttr \u003d null;\n      try {\n        int bufferSize \u003d config.getInt(\n            CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_KEY,\n            CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_DEFAULT);\n        \n        fos \u003d dfsClient.append(fileIdPath, bufferSize, null, null);\n\n        latestAttr \u003d Nfs3Utils.getFileAttr(dfsClient, fileIdPath, iug);\n      } catch (IOException e) {\n        LOG.error(\"Can\u0027t apapend to file:\" + fileIdPath + \", error:\" + e);\n        if (fos !\u003d null) {\n          fos.close();\n        }\n        WccData fileWcc \u003d new WccData(Nfs3Utils.getWccAttr(preOpAttr),\n            preOpAttr);\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n            fileWcc, count, request.getStableHow(),\n            Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n            new XDR(), xid, new VerifierNone()), xid);\n        return;\n      }\n\n      // Add open stream\n      String writeDumpDir \u003d config.get(Nfs3Constant.FILE_DUMP_DIR_KEY,\n          Nfs3Constant.FILE_DUMP_DIR_DEFAULT);\n      openFileCtx \u003d new OpenFileCtx(fos, latestAttr, writeDumpDir + \"/\"\n          + fileHandle.getFileId());\n      addOpenFileStream(fileHandle, openFileCtx);\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"opened stream for file:\" + fileHandle.getFileId());\n      }\n    }\n\n    // Add write into the async job queue\n    openFileCtx.receivedNewWrite(dfsClient, request, channel, xid,\n        asyncDataService, iug);\n    // Block stable write\n    if (request.getStableHow() !\u003d WriteStableHow.UNSTABLE) {\n      if (handleCommit(fileHandle, offset + count)) {\n        Nfs3FileAttributes postOpAttr \u003d getFileAttr(dfsClient, handle, iug);\n        WccData fileWcc \u003d new WccData(Nfs3Utils.getWccAttr(preOpAttr),\n            postOpAttr);\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3_OK,\n            fileWcc, count, request.getStableHow(),\n            Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n            new XDR(), xid, new VerifierNone()), xid);\n      } else {\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO);\n        Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n            new XDR(), xid, new VerifierNone()), xid);\n      }\n    }\n\n    return;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/WriteManager.java",
      "extendedDetails": {}
    },
    "a56a4b6ef06602312144783b7507bf2b82821e4f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5199 Add more debug trace for NFS READ and WRITE. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1523140 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/09/13 4:14 PM",
      "commitName": "a56a4b6ef06602312144783b7507bf2b82821e4f",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "28/08/13 10:23 AM",
      "commitNameOld": "30b8ef91a32ddf1fe3756bae6d7dc538a150bdc4",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 16.24,
      "commitsBetweenForRepo": 77,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,86 +1,86 @@\n   void handleWrite(DFSClient dfsClient, WRITE3Request request, Channel channel,\n       int xid, Nfs3FileAttributes preOpAttr) throws IOException {\n     // First write request starts the async data service\n     if (!asyncDataServiceStarted) {\n       startAsyncDataSerivce();\n     }\n \n     long offset \u003d request.getOffset();\n     int count \u003d request.getCount();\n     WriteStableHow stableHow \u003d request.getStableHow();\n     byte[] data \u003d request.getData().array();\n     if (data.length \u003c count) {\n       WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_INVAL);\n-      Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid));\n+      Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid), xid);\n       return;\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"handleWrite fileId: \" + handle.getFileId() + \" offset: \"\n           + offset + \" length:\" + count + \" stableHow:\" + stableHow.getValue());\n     }\n \n     // Check if there is a stream to write\n     FileHandle fileHandle \u003d request.getHandle();\n     OpenFileCtx openFileCtx \u003d openFileMap.get(fileHandle);\n     if (openFileCtx \u003d\u003d null) {\n       LOG.info(\"No opened stream for fileId:\" + fileHandle.getFileId());\n \n       String fileIdPath \u003d Nfs3Utils.getFileIdPath(fileHandle.getFileId());\n       HdfsDataOutputStream fos \u003d null;\n       Nfs3FileAttributes latestAttr \u003d null;\n       try {\n         int bufferSize \u003d config.getInt(\n             CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_KEY,\n             CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_DEFAULT);\n         \n         fos \u003d dfsClient.append(fileIdPath, bufferSize, null, null);\n \n         latestAttr \u003d Nfs3Utils.getFileAttr(dfsClient, fileIdPath, iug);\n       } catch (IOException e) {\n         LOG.error(\"Can\u0027t apapend to file:\" + fileIdPath + \", error:\" + e);\n         if (fos !\u003d null) {\n           fos.close();\n         }\n         WccData fileWcc \u003d new WccData(Nfs3Utils.getWccAttr(preOpAttr),\n             preOpAttr);\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n             fileWcc, count, request.getStableHow(),\n             Nfs3Constant.WRITE_COMMIT_VERF);\n-        Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid));\n+        Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid), xid);\n         return;\n       }\n \n       // Add open stream\n       String writeDumpDir \u003d config.get(Nfs3Constant.FILE_DUMP_DIR_KEY,\n           Nfs3Constant.FILE_DUMP_DIR_DEFAULT);\n       openFileCtx \u003d new OpenFileCtx(fos, latestAttr, writeDumpDir + \"/\"\n           + fileHandle.getFileId());\n       addOpenFileStream(fileHandle, openFileCtx);\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"opened stream for file:\" + fileHandle.getFileId());\n       }\n     }\n \n     // Add write into the async job queue\n     openFileCtx.receivedNewWrite(dfsClient, request, channel, xid,\n         asyncDataService, iug);\n     // Block stable write\n     if (request.getStableHow() !\u003d WriteStableHow.UNSTABLE) {\n       if (handleCommit(fileHandle, offset + count)) {\n         Nfs3FileAttributes postOpAttr \u003d getFileAttr(dfsClient, handle, iug);\n         WccData fileWcc \u003d new WccData(Nfs3Utils.getWccAttr(preOpAttr),\n             postOpAttr);\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3_OK,\n             fileWcc, count, request.getStableHow(),\n             Nfs3Constant.WRITE_COMMIT_VERF);\n-        Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid));\n+        Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid), xid);\n       } else {\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO);\n-        Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid));\n+        Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid), xid);\n       }\n     }\n \n     return;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void handleWrite(DFSClient dfsClient, WRITE3Request request, Channel channel,\n      int xid, Nfs3FileAttributes preOpAttr) throws IOException {\n    // First write request starts the async data service\n    if (!asyncDataServiceStarted) {\n      startAsyncDataSerivce();\n    }\n\n    long offset \u003d request.getOffset();\n    int count \u003d request.getCount();\n    WriteStableHow stableHow \u003d request.getStableHow();\n    byte[] data \u003d request.getData().array();\n    if (data.length \u003c count) {\n      WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_INVAL);\n      Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid), xid);\n      return;\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"handleWrite fileId: \" + handle.getFileId() + \" offset: \"\n          + offset + \" length:\" + count + \" stableHow:\" + stableHow.getValue());\n    }\n\n    // Check if there is a stream to write\n    FileHandle fileHandle \u003d request.getHandle();\n    OpenFileCtx openFileCtx \u003d openFileMap.get(fileHandle);\n    if (openFileCtx \u003d\u003d null) {\n      LOG.info(\"No opened stream for fileId:\" + fileHandle.getFileId());\n\n      String fileIdPath \u003d Nfs3Utils.getFileIdPath(fileHandle.getFileId());\n      HdfsDataOutputStream fos \u003d null;\n      Nfs3FileAttributes latestAttr \u003d null;\n      try {\n        int bufferSize \u003d config.getInt(\n            CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_KEY,\n            CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_DEFAULT);\n        \n        fos \u003d dfsClient.append(fileIdPath, bufferSize, null, null);\n\n        latestAttr \u003d Nfs3Utils.getFileAttr(dfsClient, fileIdPath, iug);\n      } catch (IOException e) {\n        LOG.error(\"Can\u0027t apapend to file:\" + fileIdPath + \", error:\" + e);\n        if (fos !\u003d null) {\n          fos.close();\n        }\n        WccData fileWcc \u003d new WccData(Nfs3Utils.getWccAttr(preOpAttr),\n            preOpAttr);\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n            fileWcc, count, request.getStableHow(),\n            Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid), xid);\n        return;\n      }\n\n      // Add open stream\n      String writeDumpDir \u003d config.get(Nfs3Constant.FILE_DUMP_DIR_KEY,\n          Nfs3Constant.FILE_DUMP_DIR_DEFAULT);\n      openFileCtx \u003d new OpenFileCtx(fos, latestAttr, writeDumpDir + \"/\"\n          + fileHandle.getFileId());\n      addOpenFileStream(fileHandle, openFileCtx);\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"opened stream for file:\" + fileHandle.getFileId());\n      }\n    }\n\n    // Add write into the async job queue\n    openFileCtx.receivedNewWrite(dfsClient, request, channel, xid,\n        asyncDataService, iug);\n    // Block stable write\n    if (request.getStableHow() !\u003d WriteStableHow.UNSTABLE) {\n      if (handleCommit(fileHandle, offset + count)) {\n        Nfs3FileAttributes postOpAttr \u003d getFileAttr(dfsClient, handle, iug);\n        WccData fileWcc \u003d new WccData(Nfs3Utils.getWccAttr(preOpAttr),\n            postOpAttr);\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3_OK,\n            fileWcc, count, request.getStableHow(),\n            Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid), xid);\n      } else {\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO);\n        Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid), xid);\n      }\n    }\n\n    return;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/WriteManager.java",
      "extendedDetails": {}
    },
    "30b8ef91a32ddf1fe3756bae6d7dc538a150bdc4": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5078 Support file append in NFSv3 gateway to enable data streaming to HDFS. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1518292 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/08/13 10:23 AM",
      "commitName": "30b8ef91a32ddf1fe3756bae6d7dc538a150bdc4",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "02/07/13 10:31 AM",
      "commitNameOld": "37f587563a943a827fbff865f5302bac6d202415",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 56.99,
      "commitsBetweenForRepo": 339,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,57 +1,86 @@\n   void handleWrite(DFSClient dfsClient, WRITE3Request request, Channel channel,\n       int xid, Nfs3FileAttributes preOpAttr) throws IOException {\n     // First write request starts the async data service\n     if (!asyncDataServiceStarted) {\n       startAsyncDataSerivce();\n     }\n \n     long offset \u003d request.getOffset();\n     int count \u003d request.getCount();\n     WriteStableHow stableHow \u003d request.getStableHow();\n     byte[] data \u003d request.getData().array();\n     if (data.length \u003c count) {\n       WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_INVAL);\n       Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid));\n       return;\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"handleWrite fileId: \" + handle.getFileId() + \" offset: \"\n           + offset + \" length:\" + count + \" stableHow:\" + stableHow.getValue());\n     }\n \n     // Check if there is a stream to write\n     FileHandle fileHandle \u003d request.getHandle();\n     OpenFileCtx openFileCtx \u003d openFileMap.get(fileHandle);\n     if (openFileCtx \u003d\u003d null) {\n       LOG.info(\"No opened stream for fileId:\" + fileHandle.getFileId());\n-      WccData fileWcc \u003d new WccData(Nfs3Utils.getWccAttr(preOpAttr), preOpAttr);\n-      WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n-          fileWcc, count, request.getStableHow(),\n-          Nfs3Constant.WRITE_COMMIT_VERF);\n-      Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid));\n-      return;\n+\n+      String fileIdPath \u003d Nfs3Utils.getFileIdPath(fileHandle.getFileId());\n+      HdfsDataOutputStream fos \u003d null;\n+      Nfs3FileAttributes latestAttr \u003d null;\n+      try {\n+        int bufferSize \u003d config.getInt(\n+            CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_KEY,\n+            CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_DEFAULT);\n+        \n+        fos \u003d dfsClient.append(fileIdPath, bufferSize, null, null);\n+\n+        latestAttr \u003d Nfs3Utils.getFileAttr(dfsClient, fileIdPath, iug);\n+      } catch (IOException e) {\n+        LOG.error(\"Can\u0027t apapend to file:\" + fileIdPath + \", error:\" + e);\n+        if (fos !\u003d null) {\n+          fos.close();\n+        }\n+        WccData fileWcc \u003d new WccData(Nfs3Utils.getWccAttr(preOpAttr),\n+            preOpAttr);\n+        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n+            fileWcc, count, request.getStableHow(),\n+            Nfs3Constant.WRITE_COMMIT_VERF);\n+        Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid));\n+        return;\n+      }\n+\n+      // Add open stream\n+      String writeDumpDir \u003d config.get(Nfs3Constant.FILE_DUMP_DIR_KEY,\n+          Nfs3Constant.FILE_DUMP_DIR_DEFAULT);\n+      openFileCtx \u003d new OpenFileCtx(fos, latestAttr, writeDumpDir + \"/\"\n+          + fileHandle.getFileId());\n+      addOpenFileStream(fileHandle, openFileCtx);\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(\"opened stream for file:\" + fileHandle.getFileId());\n+      }\n     }\n \n     // Add write into the async job queue\n     openFileCtx.receivedNewWrite(dfsClient, request, channel, xid,\n         asyncDataService, iug);\n     // Block stable write\n     if (request.getStableHow() !\u003d WriteStableHow.UNSTABLE) {\n       if (handleCommit(fileHandle, offset + count)) {\n         Nfs3FileAttributes postOpAttr \u003d getFileAttr(dfsClient, handle, iug);\n         WccData fileWcc \u003d new WccData(Nfs3Utils.getWccAttr(preOpAttr),\n             postOpAttr);\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3_OK,\n             fileWcc, count, request.getStableHow(),\n             Nfs3Constant.WRITE_COMMIT_VERF);\n         Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid));\n       } else {\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO);\n         Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid));\n       }\n     }\n \n     return;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void handleWrite(DFSClient dfsClient, WRITE3Request request, Channel channel,\n      int xid, Nfs3FileAttributes preOpAttr) throws IOException {\n    // First write request starts the async data service\n    if (!asyncDataServiceStarted) {\n      startAsyncDataSerivce();\n    }\n\n    long offset \u003d request.getOffset();\n    int count \u003d request.getCount();\n    WriteStableHow stableHow \u003d request.getStableHow();\n    byte[] data \u003d request.getData().array();\n    if (data.length \u003c count) {\n      WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_INVAL);\n      Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid));\n      return;\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"handleWrite fileId: \" + handle.getFileId() + \" offset: \"\n          + offset + \" length:\" + count + \" stableHow:\" + stableHow.getValue());\n    }\n\n    // Check if there is a stream to write\n    FileHandle fileHandle \u003d request.getHandle();\n    OpenFileCtx openFileCtx \u003d openFileMap.get(fileHandle);\n    if (openFileCtx \u003d\u003d null) {\n      LOG.info(\"No opened stream for fileId:\" + fileHandle.getFileId());\n\n      String fileIdPath \u003d Nfs3Utils.getFileIdPath(fileHandle.getFileId());\n      HdfsDataOutputStream fos \u003d null;\n      Nfs3FileAttributes latestAttr \u003d null;\n      try {\n        int bufferSize \u003d config.getInt(\n            CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_KEY,\n            CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_DEFAULT);\n        \n        fos \u003d dfsClient.append(fileIdPath, bufferSize, null, null);\n\n        latestAttr \u003d Nfs3Utils.getFileAttr(dfsClient, fileIdPath, iug);\n      } catch (IOException e) {\n        LOG.error(\"Can\u0027t apapend to file:\" + fileIdPath + \", error:\" + e);\n        if (fos !\u003d null) {\n          fos.close();\n        }\n        WccData fileWcc \u003d new WccData(Nfs3Utils.getWccAttr(preOpAttr),\n            preOpAttr);\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n            fileWcc, count, request.getStableHow(),\n            Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid));\n        return;\n      }\n\n      // Add open stream\n      String writeDumpDir \u003d config.get(Nfs3Constant.FILE_DUMP_DIR_KEY,\n          Nfs3Constant.FILE_DUMP_DIR_DEFAULT);\n      openFileCtx \u003d new OpenFileCtx(fos, latestAttr, writeDumpDir + \"/\"\n          + fileHandle.getFileId());\n      addOpenFileStream(fileHandle, openFileCtx);\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"opened stream for file:\" + fileHandle.getFileId());\n      }\n    }\n\n    // Add write into the async job queue\n    openFileCtx.receivedNewWrite(dfsClient, request, channel, xid,\n        asyncDataService, iug);\n    // Block stable write\n    if (request.getStableHow() !\u003d WriteStableHow.UNSTABLE) {\n      if (handleCommit(fileHandle, offset + count)) {\n        Nfs3FileAttributes postOpAttr \u003d getFileAttr(dfsClient, handle, iug);\n        WccData fileWcc \u003d new WccData(Nfs3Utils.getWccAttr(preOpAttr),\n            postOpAttr);\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3_OK,\n            fileWcc, count, request.getStableHow(),\n            Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid));\n      } else {\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO);\n        Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid));\n      }\n    }\n\n    return;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/WriteManager.java",
      "extendedDetails": {}
    },
    "37f587563a943a827fbff865f5302bac6d202415": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-4762 Provide HDFS based NFSv3 and Mountd implementation. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1499029 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/07/13 10:31 AM",
      "commitName": "37f587563a943a827fbff865f5302bac6d202415",
      "commitAuthor": "Brandon Li",
      "diff": "@@ -0,0 +1,57 @@\n+  void handleWrite(DFSClient dfsClient, WRITE3Request request, Channel channel,\n+      int xid, Nfs3FileAttributes preOpAttr) throws IOException {\n+    // First write request starts the async data service\n+    if (!asyncDataServiceStarted) {\n+      startAsyncDataSerivce();\n+    }\n+\n+    long offset \u003d request.getOffset();\n+    int count \u003d request.getCount();\n+    WriteStableHow stableHow \u003d request.getStableHow();\n+    byte[] data \u003d request.getData().array();\n+    if (data.length \u003c count) {\n+      WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_INVAL);\n+      Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid));\n+      return;\n+    }\n+\n+    FileHandle handle \u003d request.getHandle();\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"handleWrite fileId: \" + handle.getFileId() + \" offset: \"\n+          + offset + \" length:\" + count + \" stableHow:\" + stableHow.getValue());\n+    }\n+\n+    // Check if there is a stream to write\n+    FileHandle fileHandle \u003d request.getHandle();\n+    OpenFileCtx openFileCtx \u003d openFileMap.get(fileHandle);\n+    if (openFileCtx \u003d\u003d null) {\n+      LOG.info(\"No opened stream for fileId:\" + fileHandle.getFileId());\n+      WccData fileWcc \u003d new WccData(Nfs3Utils.getWccAttr(preOpAttr), preOpAttr);\n+      WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n+          fileWcc, count, request.getStableHow(),\n+          Nfs3Constant.WRITE_COMMIT_VERF);\n+      Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid));\n+      return;\n+    }\n+\n+    // Add write into the async job queue\n+    openFileCtx.receivedNewWrite(dfsClient, request, channel, xid,\n+        asyncDataService, iug);\n+    // Block stable write\n+    if (request.getStableHow() !\u003d WriteStableHow.UNSTABLE) {\n+      if (handleCommit(fileHandle, offset + count)) {\n+        Nfs3FileAttributes postOpAttr \u003d getFileAttr(dfsClient, handle, iug);\n+        WccData fileWcc \u003d new WccData(Nfs3Utils.getWccAttr(preOpAttr),\n+            postOpAttr);\n+        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3_OK,\n+            fileWcc, count, request.getStableHow(),\n+            Nfs3Constant.WRITE_COMMIT_VERF);\n+        Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid));\n+      } else {\n+        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO);\n+        Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid));\n+      }\n+    }\n+\n+    return;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  void handleWrite(DFSClient dfsClient, WRITE3Request request, Channel channel,\n      int xid, Nfs3FileAttributes preOpAttr) throws IOException {\n    // First write request starts the async data service\n    if (!asyncDataServiceStarted) {\n      startAsyncDataSerivce();\n    }\n\n    long offset \u003d request.getOffset();\n    int count \u003d request.getCount();\n    WriteStableHow stableHow \u003d request.getStableHow();\n    byte[] data \u003d request.getData().array();\n    if (data.length \u003c count) {\n      WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_INVAL);\n      Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid));\n      return;\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"handleWrite fileId: \" + handle.getFileId() + \" offset: \"\n          + offset + \" length:\" + count + \" stableHow:\" + stableHow.getValue());\n    }\n\n    // Check if there is a stream to write\n    FileHandle fileHandle \u003d request.getHandle();\n    OpenFileCtx openFileCtx \u003d openFileMap.get(fileHandle);\n    if (openFileCtx \u003d\u003d null) {\n      LOG.info(\"No opened stream for fileId:\" + fileHandle.getFileId());\n      WccData fileWcc \u003d new WccData(Nfs3Utils.getWccAttr(preOpAttr), preOpAttr);\n      WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n          fileWcc, count, request.getStableHow(),\n          Nfs3Constant.WRITE_COMMIT_VERF);\n      Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid));\n      return;\n    }\n\n    // Add write into the async job queue\n    openFileCtx.receivedNewWrite(dfsClient, request, channel, xid,\n        asyncDataService, iug);\n    // Block stable write\n    if (request.getStableHow() !\u003d WriteStableHow.UNSTABLE) {\n      if (handleCommit(fileHandle, offset + count)) {\n        Nfs3FileAttributes postOpAttr \u003d getFileAttr(dfsClient, handle, iug);\n        WccData fileWcc \u003d new WccData(Nfs3Utils.getWccAttr(preOpAttr),\n            postOpAttr);\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3_OK,\n            fileWcc, count, request.getStableHow(),\n            Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid));\n      } else {\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO);\n        Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid));\n      }\n    }\n\n    return;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/WriteManager.java"
    }
  }
}