{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "SequenceFile.java",
  "functionName": "init",
  "functionId": "init___config-Configuration__outStream-FSDataOutputStream__ownStream-boolean__key-Class__val-Class__compCodec-CompressionCodec__meta-Metadata__syncIntervalVal-int",
  "sourceFilePath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/SequenceFile.java",
  "functionStartLine": 1265,
  "functionEndLine": 1326,
  "numCommitsSeen": 77,
  "timeTaken": 4393,
  "changeHistory": [
    "07825f2b49384dbec92bfae87ea661cef9ffab49",
    "295d678be8853a52c3ec3da43d9265478d6632b3",
    "0f122c209d7346e7913907dec86aa8cf221dd8f2",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "0f6dfeeacbab65a31a33927a4eb84871d371fe52",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
    "6333b3e485dc76a7505bf74e041e274e0a8e6faf",
    "750fb2dbc1c077c9ca7ce889332a597d4a65388f",
    "d6428581ff6ad7859d69b41318bd6fe4736d022d",
    "5128a9a453d64bfe1ed978cf9ffed27985eeef36"
  ],
  "changeHistoryShort": {
    "07825f2b49384dbec92bfae87ea661cef9ffab49": "Ymultichange(Yparameterchange,Ybodychange)",
    "295d678be8853a52c3ec3da43d9265478d6632b3": "Ybodychange",
    "0f122c209d7346e7913907dec86aa8cf221dd8f2": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "0f6dfeeacbab65a31a33927a4eb84871d371fe52": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yfilerename",
    "6333b3e485dc76a7505bf74e041e274e0a8e6faf": "Ymultichange(Yparameterchange,Ybodychange)",
    "750fb2dbc1c077c9ca7ce889332a597d4a65388f": "Ybodychange",
    "d6428581ff6ad7859d69b41318bd6fe4736d022d": "Ybodychange",
    "5128a9a453d64bfe1ed978cf9ffed27985eeef36": "Yintroduced"
  },
  "changeHistoryDetails": {
    "07825f2b49384dbec92bfae87ea661cef9ffab49": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HADOOP-1381. The distance between sync blocks in SequenceFiles should be configurable rather than hard coded to 2000 bytes. Contributed by Harsh J.\n",
      "commitDate": "25/11/16 8:52 AM",
      "commitName": "07825f2b49384dbec92bfae87ea661cef9ffab49",
      "commitAuthor": "Harsh J",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HADOOP-1381. The distance between sync blocks in SequenceFiles should be configurable rather than hard coded to 2000 bytes. Contributed by Harsh J.\n",
          "commitDate": "25/11/16 8:52 AM",
          "commitName": "07825f2b49384dbec92bfae87ea661cef9ffab49",
          "commitAuthor": "Harsh J",
          "commitDateOld": "27/09/16 5:36 PM",
          "commitNameOld": "9a44a832a99eb967aa4e34338dfa75baf35f9845",
          "commitAuthorOld": "Mingliang Liu",
          "daysBetweenCommits": 58.68,
          "commitsBetweenForRepo": 492,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,59 +1,62 @@\n-    void init(Configuration conf, FSDataOutputStream out, boolean ownStream,\n-              Class keyClass, Class valClass,\n-              CompressionCodec codec, Metadata metadata) \n+    void init(Configuration config, FSDataOutputStream outStream,\n+              boolean ownStream, Class key, Class val,\n+              CompressionCodec compCodec, Metadata meta,\n+              int syncIntervalVal)\n       throws IOException {\n-      this.conf \u003d conf;\n-      this.out \u003d out;\n+      this.conf \u003d config;\n+      this.out \u003d outStream;\n       this.ownOutputStream \u003d ownStream;\n-      this.keyClass \u003d keyClass;\n-      this.valClass \u003d valClass;\n-      this.codec \u003d codec;\n-      this.metadata \u003d metadata;\n-      SerializationFactory serializationFactory \u003d new SerializationFactory(conf);\n+      this.keyClass \u003d key;\n+      this.valClass \u003d val;\n+      this.codec \u003d compCodec;\n+      this.metadata \u003d meta;\n+      this.syncInterval \u003d syncIntervalVal;\n+      SerializationFactory serializationFactory \u003d\n+          new SerializationFactory(config);\n       this.keySerializer \u003d serializationFactory.getSerializer(keyClass);\n       if (this.keySerializer \u003d\u003d null) {\n         throw new IOException(\n             \"Could not find a serializer for the Key class: \u0027\"\n                 + keyClass.getCanonicalName() + \"\u0027. \"\n                 + \"Please ensure that the configuration \u0027\" +\n                 CommonConfigurationKeys.IO_SERIALIZATIONS_KEY + \"\u0027 is \"\n                 + \"properly configured, if you\u0027re using\"\n                 + \"custom serialization.\");\n       }\n       this.keySerializer.open(buffer);\n       this.uncompressedValSerializer \u003d serializationFactory.getSerializer(valClass);\n       if (this.uncompressedValSerializer \u003d\u003d null) {\n         throw new IOException(\n             \"Could not find a serializer for the Value class: \u0027\"\n                 + valClass.getCanonicalName() + \"\u0027. \"\n                 + \"Please ensure that the configuration \u0027\" +\n                 CommonConfigurationKeys.IO_SERIALIZATIONS_KEY + \"\u0027 is \"\n                 + \"properly configured, if you\u0027re using\"\n                 + \"custom serialization.\");\n       }\n       this.uncompressedValSerializer.open(buffer);\n       if (this.codec !\u003d null) {\n         ReflectionUtils.setConf(this.codec, this.conf);\n         this.compressor \u003d CodecPool.getCompressor(this.codec);\n         this.deflateFilter \u003d this.codec.createOutputStream(buffer, compressor);\n         this.deflateOut \u003d \n           new DataOutputStream(new BufferedOutputStream(deflateFilter));\n         this.compressedValSerializer \u003d serializationFactory.getSerializer(valClass);\n         if (this.compressedValSerializer \u003d\u003d null) {\n           throw new IOException(\n               \"Could not find a serializer for the Value class: \u0027\"\n                   + valClass.getCanonicalName() + \"\u0027. \"\n                   + \"Please ensure that the configuration \u0027\" +\n                   CommonConfigurationKeys.IO_SERIALIZATIONS_KEY + \"\u0027 is \"\n                   + \"properly configured, if you\u0027re using\"\n                   + \"custom serialization.\");\n         }\n         this.compressedValSerializer.open(deflateOut);\n       }\n \n       if (appendMode) {\n         sync();\n       } else {\n         writeFileHeader();\n       }\n     }\n\\ No newline at end of file\n",
          "actualSource": "    void init(Configuration config, FSDataOutputStream outStream,\n              boolean ownStream, Class key, Class val,\n              CompressionCodec compCodec, Metadata meta,\n              int syncIntervalVal)\n      throws IOException {\n      this.conf \u003d config;\n      this.out \u003d outStream;\n      this.ownOutputStream \u003d ownStream;\n      this.keyClass \u003d key;\n      this.valClass \u003d val;\n      this.codec \u003d compCodec;\n      this.metadata \u003d meta;\n      this.syncInterval \u003d syncIntervalVal;\n      SerializationFactory serializationFactory \u003d\n          new SerializationFactory(config);\n      this.keySerializer \u003d serializationFactory.getSerializer(keyClass);\n      if (this.keySerializer \u003d\u003d null) {\n        throw new IOException(\n            \"Could not find a serializer for the Key class: \u0027\"\n                + keyClass.getCanonicalName() + \"\u0027. \"\n                + \"Please ensure that the configuration \u0027\" +\n                CommonConfigurationKeys.IO_SERIALIZATIONS_KEY + \"\u0027 is \"\n                + \"properly configured, if you\u0027re using\"\n                + \"custom serialization.\");\n      }\n      this.keySerializer.open(buffer);\n      this.uncompressedValSerializer \u003d serializationFactory.getSerializer(valClass);\n      if (this.uncompressedValSerializer \u003d\u003d null) {\n        throw new IOException(\n            \"Could not find a serializer for the Value class: \u0027\"\n                + valClass.getCanonicalName() + \"\u0027. \"\n                + \"Please ensure that the configuration \u0027\" +\n                CommonConfigurationKeys.IO_SERIALIZATIONS_KEY + \"\u0027 is \"\n                + \"properly configured, if you\u0027re using\"\n                + \"custom serialization.\");\n      }\n      this.uncompressedValSerializer.open(buffer);\n      if (this.codec !\u003d null) {\n        ReflectionUtils.setConf(this.codec, this.conf);\n        this.compressor \u003d CodecPool.getCompressor(this.codec);\n        this.deflateFilter \u003d this.codec.createOutputStream(buffer, compressor);\n        this.deflateOut \u003d \n          new DataOutputStream(new BufferedOutputStream(deflateFilter));\n        this.compressedValSerializer \u003d serializationFactory.getSerializer(valClass);\n        if (this.compressedValSerializer \u003d\u003d null) {\n          throw new IOException(\n              \"Could not find a serializer for the Value class: \u0027\"\n                  + valClass.getCanonicalName() + \"\u0027. \"\n                  + \"Please ensure that the configuration \u0027\" +\n                  CommonConfigurationKeys.IO_SERIALIZATIONS_KEY + \"\u0027 is \"\n                  + \"properly configured, if you\u0027re using\"\n                  + \"custom serialization.\");\n        }\n        this.compressedValSerializer.open(deflateOut);\n      }\n\n      if (appendMode) {\n        sync();\n      } else {\n        writeFileHeader();\n      }\n    }",
          "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/SequenceFile.java",
          "extendedDetails": {
            "oldValue": "[conf-Configuration, out-FSDataOutputStream, ownStream-boolean, keyClass-Class, valClass-Class, codec-CompressionCodec, metadata-Metadata]",
            "newValue": "[config-Configuration, outStream-FSDataOutputStream, ownStream-boolean, key-Class, val-Class, compCodec-CompressionCodec, meta-Metadata, syncIntervalVal-int]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HADOOP-1381. The distance between sync blocks in SequenceFiles should be configurable rather than hard coded to 2000 bytes. Contributed by Harsh J.\n",
          "commitDate": "25/11/16 8:52 AM",
          "commitName": "07825f2b49384dbec92bfae87ea661cef9ffab49",
          "commitAuthor": "Harsh J",
          "commitDateOld": "27/09/16 5:36 PM",
          "commitNameOld": "9a44a832a99eb967aa4e34338dfa75baf35f9845",
          "commitAuthorOld": "Mingliang Liu",
          "daysBetweenCommits": 58.68,
          "commitsBetweenForRepo": 492,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,59 +1,62 @@\n-    void init(Configuration conf, FSDataOutputStream out, boolean ownStream,\n-              Class keyClass, Class valClass,\n-              CompressionCodec codec, Metadata metadata) \n+    void init(Configuration config, FSDataOutputStream outStream,\n+              boolean ownStream, Class key, Class val,\n+              CompressionCodec compCodec, Metadata meta,\n+              int syncIntervalVal)\n       throws IOException {\n-      this.conf \u003d conf;\n-      this.out \u003d out;\n+      this.conf \u003d config;\n+      this.out \u003d outStream;\n       this.ownOutputStream \u003d ownStream;\n-      this.keyClass \u003d keyClass;\n-      this.valClass \u003d valClass;\n-      this.codec \u003d codec;\n-      this.metadata \u003d metadata;\n-      SerializationFactory serializationFactory \u003d new SerializationFactory(conf);\n+      this.keyClass \u003d key;\n+      this.valClass \u003d val;\n+      this.codec \u003d compCodec;\n+      this.metadata \u003d meta;\n+      this.syncInterval \u003d syncIntervalVal;\n+      SerializationFactory serializationFactory \u003d\n+          new SerializationFactory(config);\n       this.keySerializer \u003d serializationFactory.getSerializer(keyClass);\n       if (this.keySerializer \u003d\u003d null) {\n         throw new IOException(\n             \"Could not find a serializer for the Key class: \u0027\"\n                 + keyClass.getCanonicalName() + \"\u0027. \"\n                 + \"Please ensure that the configuration \u0027\" +\n                 CommonConfigurationKeys.IO_SERIALIZATIONS_KEY + \"\u0027 is \"\n                 + \"properly configured, if you\u0027re using\"\n                 + \"custom serialization.\");\n       }\n       this.keySerializer.open(buffer);\n       this.uncompressedValSerializer \u003d serializationFactory.getSerializer(valClass);\n       if (this.uncompressedValSerializer \u003d\u003d null) {\n         throw new IOException(\n             \"Could not find a serializer for the Value class: \u0027\"\n                 + valClass.getCanonicalName() + \"\u0027. \"\n                 + \"Please ensure that the configuration \u0027\" +\n                 CommonConfigurationKeys.IO_SERIALIZATIONS_KEY + \"\u0027 is \"\n                 + \"properly configured, if you\u0027re using\"\n                 + \"custom serialization.\");\n       }\n       this.uncompressedValSerializer.open(buffer);\n       if (this.codec !\u003d null) {\n         ReflectionUtils.setConf(this.codec, this.conf);\n         this.compressor \u003d CodecPool.getCompressor(this.codec);\n         this.deflateFilter \u003d this.codec.createOutputStream(buffer, compressor);\n         this.deflateOut \u003d \n           new DataOutputStream(new BufferedOutputStream(deflateFilter));\n         this.compressedValSerializer \u003d serializationFactory.getSerializer(valClass);\n         if (this.compressedValSerializer \u003d\u003d null) {\n           throw new IOException(\n               \"Could not find a serializer for the Value class: \u0027\"\n                   + valClass.getCanonicalName() + \"\u0027. \"\n                   + \"Please ensure that the configuration \u0027\" +\n                   CommonConfigurationKeys.IO_SERIALIZATIONS_KEY + \"\u0027 is \"\n                   + \"properly configured, if you\u0027re using\"\n                   + \"custom serialization.\");\n         }\n         this.compressedValSerializer.open(deflateOut);\n       }\n \n       if (appendMode) {\n         sync();\n       } else {\n         writeFileHeader();\n       }\n     }\n\\ No newline at end of file\n",
          "actualSource": "    void init(Configuration config, FSDataOutputStream outStream,\n              boolean ownStream, Class key, Class val,\n              CompressionCodec compCodec, Metadata meta,\n              int syncIntervalVal)\n      throws IOException {\n      this.conf \u003d config;\n      this.out \u003d outStream;\n      this.ownOutputStream \u003d ownStream;\n      this.keyClass \u003d key;\n      this.valClass \u003d val;\n      this.codec \u003d compCodec;\n      this.metadata \u003d meta;\n      this.syncInterval \u003d syncIntervalVal;\n      SerializationFactory serializationFactory \u003d\n          new SerializationFactory(config);\n      this.keySerializer \u003d serializationFactory.getSerializer(keyClass);\n      if (this.keySerializer \u003d\u003d null) {\n        throw new IOException(\n            \"Could not find a serializer for the Key class: \u0027\"\n                + keyClass.getCanonicalName() + \"\u0027. \"\n                + \"Please ensure that the configuration \u0027\" +\n                CommonConfigurationKeys.IO_SERIALIZATIONS_KEY + \"\u0027 is \"\n                + \"properly configured, if you\u0027re using\"\n                + \"custom serialization.\");\n      }\n      this.keySerializer.open(buffer);\n      this.uncompressedValSerializer \u003d serializationFactory.getSerializer(valClass);\n      if (this.uncompressedValSerializer \u003d\u003d null) {\n        throw new IOException(\n            \"Could not find a serializer for the Value class: \u0027\"\n                + valClass.getCanonicalName() + \"\u0027. \"\n                + \"Please ensure that the configuration \u0027\" +\n                CommonConfigurationKeys.IO_SERIALIZATIONS_KEY + \"\u0027 is \"\n                + \"properly configured, if you\u0027re using\"\n                + \"custom serialization.\");\n      }\n      this.uncompressedValSerializer.open(buffer);\n      if (this.codec !\u003d null) {\n        ReflectionUtils.setConf(this.codec, this.conf);\n        this.compressor \u003d CodecPool.getCompressor(this.codec);\n        this.deflateFilter \u003d this.codec.createOutputStream(buffer, compressor);\n        this.deflateOut \u003d \n          new DataOutputStream(new BufferedOutputStream(deflateFilter));\n        this.compressedValSerializer \u003d serializationFactory.getSerializer(valClass);\n        if (this.compressedValSerializer \u003d\u003d null) {\n          throw new IOException(\n              \"Could not find a serializer for the Value class: \u0027\"\n                  + valClass.getCanonicalName() + \"\u0027. \"\n                  + \"Please ensure that the configuration \u0027\" +\n                  CommonConfigurationKeys.IO_SERIALIZATIONS_KEY + \"\u0027 is \"\n                  + \"properly configured, if you\u0027re using\"\n                  + \"custom serialization.\");\n        }\n        this.compressedValSerializer.open(deflateOut);\n      }\n\n      if (appendMode) {\n        sync();\n      } else {\n        writeFileHeader();\n      }\n    }",
          "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/SequenceFile.java",
          "extendedDetails": {}
        }
      ]
    },
    "295d678be8853a52c3ec3da43d9265478d6632b3": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-7139. Allow appending to existing SequenceFiles (Contributed by kanaka kumar avvaru)\n",
      "commitDate": "18/06/15 2:09 AM",
      "commitName": "295d678be8853a52c3ec3da43d9265478d6632b3",
      "commitAuthor": "Vinayakumar B",
      "commitDateOld": "11/12/14 4:42 PM",
      "commitNameOld": "5b9fcedb4d116d91d70aaad6cbf59093eeee36df",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 188.35,
      "commitsBetweenForRepo": 1579,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,54 +1,59 @@\n     void init(Configuration conf, FSDataOutputStream out, boolean ownStream,\n               Class keyClass, Class valClass,\n               CompressionCodec codec, Metadata metadata) \n       throws IOException {\n       this.conf \u003d conf;\n       this.out \u003d out;\n       this.ownOutputStream \u003d ownStream;\n       this.keyClass \u003d keyClass;\n       this.valClass \u003d valClass;\n       this.codec \u003d codec;\n       this.metadata \u003d metadata;\n       SerializationFactory serializationFactory \u003d new SerializationFactory(conf);\n       this.keySerializer \u003d serializationFactory.getSerializer(keyClass);\n       if (this.keySerializer \u003d\u003d null) {\n         throw new IOException(\n             \"Could not find a serializer for the Key class: \u0027\"\n                 + keyClass.getCanonicalName() + \"\u0027. \"\n                 + \"Please ensure that the configuration \u0027\" +\n                 CommonConfigurationKeys.IO_SERIALIZATIONS_KEY + \"\u0027 is \"\n                 + \"properly configured, if you\u0027re using\"\n                 + \"custom serialization.\");\n       }\n       this.keySerializer.open(buffer);\n       this.uncompressedValSerializer \u003d serializationFactory.getSerializer(valClass);\n       if (this.uncompressedValSerializer \u003d\u003d null) {\n         throw new IOException(\n             \"Could not find a serializer for the Value class: \u0027\"\n                 + valClass.getCanonicalName() + \"\u0027. \"\n                 + \"Please ensure that the configuration \u0027\" +\n                 CommonConfigurationKeys.IO_SERIALIZATIONS_KEY + \"\u0027 is \"\n                 + \"properly configured, if you\u0027re using\"\n                 + \"custom serialization.\");\n       }\n       this.uncompressedValSerializer.open(buffer);\n       if (this.codec !\u003d null) {\n         ReflectionUtils.setConf(this.codec, this.conf);\n         this.compressor \u003d CodecPool.getCompressor(this.codec);\n         this.deflateFilter \u003d this.codec.createOutputStream(buffer, compressor);\n         this.deflateOut \u003d \n           new DataOutputStream(new BufferedOutputStream(deflateFilter));\n         this.compressedValSerializer \u003d serializationFactory.getSerializer(valClass);\n         if (this.compressedValSerializer \u003d\u003d null) {\n           throw new IOException(\n               \"Could not find a serializer for the Value class: \u0027\"\n                   + valClass.getCanonicalName() + \"\u0027. \"\n                   + \"Please ensure that the configuration \u0027\" +\n                   CommonConfigurationKeys.IO_SERIALIZATIONS_KEY + \"\u0027 is \"\n                   + \"properly configured, if you\u0027re using\"\n                   + \"custom serialization.\");\n         }\n         this.compressedValSerializer.open(deflateOut);\n       }\n-      writeFileHeader();\n+\n+      if (appendMode) {\n+        sync();\n+      } else {\n+        writeFileHeader();\n+      }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void init(Configuration conf, FSDataOutputStream out, boolean ownStream,\n              Class keyClass, Class valClass,\n              CompressionCodec codec, Metadata metadata) \n      throws IOException {\n      this.conf \u003d conf;\n      this.out \u003d out;\n      this.ownOutputStream \u003d ownStream;\n      this.keyClass \u003d keyClass;\n      this.valClass \u003d valClass;\n      this.codec \u003d codec;\n      this.metadata \u003d metadata;\n      SerializationFactory serializationFactory \u003d new SerializationFactory(conf);\n      this.keySerializer \u003d serializationFactory.getSerializer(keyClass);\n      if (this.keySerializer \u003d\u003d null) {\n        throw new IOException(\n            \"Could not find a serializer for the Key class: \u0027\"\n                + keyClass.getCanonicalName() + \"\u0027. \"\n                + \"Please ensure that the configuration \u0027\" +\n                CommonConfigurationKeys.IO_SERIALIZATIONS_KEY + \"\u0027 is \"\n                + \"properly configured, if you\u0027re using\"\n                + \"custom serialization.\");\n      }\n      this.keySerializer.open(buffer);\n      this.uncompressedValSerializer \u003d serializationFactory.getSerializer(valClass);\n      if (this.uncompressedValSerializer \u003d\u003d null) {\n        throw new IOException(\n            \"Could not find a serializer for the Value class: \u0027\"\n                + valClass.getCanonicalName() + \"\u0027. \"\n                + \"Please ensure that the configuration \u0027\" +\n                CommonConfigurationKeys.IO_SERIALIZATIONS_KEY + \"\u0027 is \"\n                + \"properly configured, if you\u0027re using\"\n                + \"custom serialization.\");\n      }\n      this.uncompressedValSerializer.open(buffer);\n      if (this.codec !\u003d null) {\n        ReflectionUtils.setConf(this.codec, this.conf);\n        this.compressor \u003d CodecPool.getCompressor(this.codec);\n        this.deflateFilter \u003d this.codec.createOutputStream(buffer, compressor);\n        this.deflateOut \u003d \n          new DataOutputStream(new BufferedOutputStream(deflateFilter));\n        this.compressedValSerializer \u003d serializationFactory.getSerializer(valClass);\n        if (this.compressedValSerializer \u003d\u003d null) {\n          throw new IOException(\n              \"Could not find a serializer for the Value class: \u0027\"\n                  + valClass.getCanonicalName() + \"\u0027. \"\n                  + \"Please ensure that the configuration \u0027\" +\n                  CommonConfigurationKeys.IO_SERIALIZATIONS_KEY + \"\u0027 is \"\n                  + \"properly configured, if you\u0027re using\"\n                  + \"custom serialization.\");\n        }\n        this.compressedValSerializer.open(deflateOut);\n      }\n\n      if (appendMode) {\n        sync();\n      } else {\n        writeFileHeader();\n      }\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/SequenceFile.java",
      "extendedDetails": {}
    },
    "0f122c209d7346e7913907dec86aa8cf221dd8f2": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-8531. SequenceFile Writer can throw out a better error if a serializer or deserializer isn\u0027t available. Contributed by Madhukara Phatak. (harsh)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1361933 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/07/12 1:33 AM",
      "commitName": "0f122c209d7346e7913907dec86aa8cf221dd8f2",
      "commitAuthor": "Harsh J",
      "commitDateOld": "12/07/12 12:01 PM",
      "commitNameOld": "4a5ba3b7bd2360fd9605863630b477d362874e1e",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 3.56,
      "commitsBetweenForRepo": 28,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,27 +1,54 @@\n     void init(Configuration conf, FSDataOutputStream out, boolean ownStream,\n               Class keyClass, Class valClass,\n               CompressionCodec codec, Metadata metadata) \n       throws IOException {\n       this.conf \u003d conf;\n       this.out \u003d out;\n       this.ownOutputStream \u003d ownStream;\n       this.keyClass \u003d keyClass;\n       this.valClass \u003d valClass;\n       this.codec \u003d codec;\n       this.metadata \u003d metadata;\n       SerializationFactory serializationFactory \u003d new SerializationFactory(conf);\n       this.keySerializer \u003d serializationFactory.getSerializer(keyClass);\n+      if (this.keySerializer \u003d\u003d null) {\n+        throw new IOException(\n+            \"Could not find a serializer for the Key class: \u0027\"\n+                + keyClass.getCanonicalName() + \"\u0027. \"\n+                + \"Please ensure that the configuration \u0027\" +\n+                CommonConfigurationKeys.IO_SERIALIZATIONS_KEY + \"\u0027 is \"\n+                + \"properly configured, if you\u0027re using\"\n+                + \"custom serialization.\");\n+      }\n       this.keySerializer.open(buffer);\n       this.uncompressedValSerializer \u003d serializationFactory.getSerializer(valClass);\n+      if (this.uncompressedValSerializer \u003d\u003d null) {\n+        throw new IOException(\n+            \"Could not find a serializer for the Value class: \u0027\"\n+                + valClass.getCanonicalName() + \"\u0027. \"\n+                + \"Please ensure that the configuration \u0027\" +\n+                CommonConfigurationKeys.IO_SERIALIZATIONS_KEY + \"\u0027 is \"\n+                + \"properly configured, if you\u0027re using\"\n+                + \"custom serialization.\");\n+      }\n       this.uncompressedValSerializer.open(buffer);\n       if (this.codec !\u003d null) {\n         ReflectionUtils.setConf(this.codec, this.conf);\n         this.compressor \u003d CodecPool.getCompressor(this.codec);\n         this.deflateFilter \u003d this.codec.createOutputStream(buffer, compressor);\n         this.deflateOut \u003d \n           new DataOutputStream(new BufferedOutputStream(deflateFilter));\n         this.compressedValSerializer \u003d serializationFactory.getSerializer(valClass);\n+        if (this.compressedValSerializer \u003d\u003d null) {\n+          throw new IOException(\n+              \"Could not find a serializer for the Value class: \u0027\"\n+                  + valClass.getCanonicalName() + \"\u0027. \"\n+                  + \"Please ensure that the configuration \u0027\" +\n+                  CommonConfigurationKeys.IO_SERIALIZATIONS_KEY + \"\u0027 is \"\n+                  + \"properly configured, if you\u0027re using\"\n+                  + \"custom serialization.\");\n+        }\n         this.compressedValSerializer.open(deflateOut);\n       }\n       writeFileHeader();\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void init(Configuration conf, FSDataOutputStream out, boolean ownStream,\n              Class keyClass, Class valClass,\n              CompressionCodec codec, Metadata metadata) \n      throws IOException {\n      this.conf \u003d conf;\n      this.out \u003d out;\n      this.ownOutputStream \u003d ownStream;\n      this.keyClass \u003d keyClass;\n      this.valClass \u003d valClass;\n      this.codec \u003d codec;\n      this.metadata \u003d metadata;\n      SerializationFactory serializationFactory \u003d new SerializationFactory(conf);\n      this.keySerializer \u003d serializationFactory.getSerializer(keyClass);\n      if (this.keySerializer \u003d\u003d null) {\n        throw new IOException(\n            \"Could not find a serializer for the Key class: \u0027\"\n                + keyClass.getCanonicalName() + \"\u0027. \"\n                + \"Please ensure that the configuration \u0027\" +\n                CommonConfigurationKeys.IO_SERIALIZATIONS_KEY + \"\u0027 is \"\n                + \"properly configured, if you\u0027re using\"\n                + \"custom serialization.\");\n      }\n      this.keySerializer.open(buffer);\n      this.uncompressedValSerializer \u003d serializationFactory.getSerializer(valClass);\n      if (this.uncompressedValSerializer \u003d\u003d null) {\n        throw new IOException(\n            \"Could not find a serializer for the Value class: \u0027\"\n                + valClass.getCanonicalName() + \"\u0027. \"\n                + \"Please ensure that the configuration \u0027\" +\n                CommonConfigurationKeys.IO_SERIALIZATIONS_KEY + \"\u0027 is \"\n                + \"properly configured, if you\u0027re using\"\n                + \"custom serialization.\");\n      }\n      this.uncompressedValSerializer.open(buffer);\n      if (this.codec !\u003d null) {\n        ReflectionUtils.setConf(this.codec, this.conf);\n        this.compressor \u003d CodecPool.getCompressor(this.codec);\n        this.deflateFilter \u003d this.codec.createOutputStream(buffer, compressor);\n        this.deflateOut \u003d \n          new DataOutputStream(new BufferedOutputStream(deflateFilter));\n        this.compressedValSerializer \u003d serializationFactory.getSerializer(valClass);\n        if (this.compressedValSerializer \u003d\u003d null) {\n          throw new IOException(\n              \"Could not find a serializer for the Value class: \u0027\"\n                  + valClass.getCanonicalName() + \"\u0027. \"\n                  + \"Please ensure that the configuration \u0027\" +\n                  CommonConfigurationKeys.IO_SERIALIZATIONS_KEY + \"\u0027 is \"\n                  + \"properly configured, if you\u0027re using\"\n                  + \"custom serialization.\");\n        }\n        this.compressedValSerializer.open(deflateOut);\n      }\n      writeFileHeader();\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/SequenceFile.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    void init(Configuration conf, FSDataOutputStream out, boolean ownStream,\n              Class keyClass, Class valClass,\n              CompressionCodec codec, Metadata metadata) \n      throws IOException {\n      this.conf \u003d conf;\n      this.out \u003d out;\n      this.ownOutputStream \u003d ownStream;\n      this.keyClass \u003d keyClass;\n      this.valClass \u003d valClass;\n      this.codec \u003d codec;\n      this.metadata \u003d metadata;\n      SerializationFactory serializationFactory \u003d new SerializationFactory(conf);\n      this.keySerializer \u003d serializationFactory.getSerializer(keyClass);\n      this.keySerializer.open(buffer);\n      this.uncompressedValSerializer \u003d serializationFactory.getSerializer(valClass);\n      this.uncompressedValSerializer.open(buffer);\n      if (this.codec !\u003d null) {\n        ReflectionUtils.setConf(this.codec, this.conf);\n        this.compressor \u003d CodecPool.getCompressor(this.codec);\n        this.deflateFilter \u003d this.codec.createOutputStream(buffer, compressor);\n        this.deflateOut \u003d \n          new DataOutputStream(new BufferedOutputStream(deflateFilter));\n        this.compressedValSerializer \u003d serializationFactory.getSerializer(valClass);\n        this.compressedValSerializer.open(deflateOut);\n      }\n      writeFileHeader();\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/SequenceFile.java",
      "extendedDetails": {
        "oldPath": "hadoop-common/src/main/java/org/apache/hadoop/io/SequenceFile.java",
        "newPath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/SequenceFile.java"
      }
    },
    "0f6dfeeacbab65a31a33927a4eb84871d371fe52": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-6671. Use maven for hadoop common builds. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1153184 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/08/11 9:37 AM",
      "commitName": "0f6dfeeacbab65a31a33927a4eb84871d371fe52",
      "commitAuthor": "Thomas White",
      "commitDateOld": "01/08/11 3:53 PM",
      "commitNameOld": "9bac807cedbcff34e1a144fb475eff267e5ed86d",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.74,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    void init(Configuration conf, FSDataOutputStream out, boolean ownStream,\n              Class keyClass, Class valClass,\n              CompressionCodec codec, Metadata metadata) \n      throws IOException {\n      this.conf \u003d conf;\n      this.out \u003d out;\n      this.ownOutputStream \u003d ownStream;\n      this.keyClass \u003d keyClass;\n      this.valClass \u003d valClass;\n      this.codec \u003d codec;\n      this.metadata \u003d metadata;\n      SerializationFactory serializationFactory \u003d new SerializationFactory(conf);\n      this.keySerializer \u003d serializationFactory.getSerializer(keyClass);\n      this.keySerializer.open(buffer);\n      this.uncompressedValSerializer \u003d serializationFactory.getSerializer(valClass);\n      this.uncompressedValSerializer.open(buffer);\n      if (this.codec !\u003d null) {\n        ReflectionUtils.setConf(this.codec, this.conf);\n        this.compressor \u003d CodecPool.getCompressor(this.codec);\n        this.deflateFilter \u003d this.codec.createOutputStream(buffer, compressor);\n        this.deflateOut \u003d \n          new DataOutputStream(new BufferedOutputStream(deflateFilter));\n        this.compressedValSerializer \u003d serializationFactory.getSerializer(valClass);\n        this.compressedValSerializer.open(deflateOut);\n      }\n      writeFileHeader();\n    }",
      "path": "hadoop-common/src/main/java/org/apache/hadoop/io/SequenceFile.java",
      "extendedDetails": {
        "oldPath": "common/src/java/org/apache/hadoop/io/SequenceFile.java",
        "newPath": "hadoop-common/src/main/java/org/apache/hadoop/io/SequenceFile.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "11/06/11 9:13 PM",
      "commitNameOld": "a285fb5effe9ba3be4ec5f942afaf5ddd1186151",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 0.74,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    void init(Configuration conf, FSDataOutputStream out, boolean ownStream,\n              Class keyClass, Class valClass,\n              CompressionCodec codec, Metadata metadata) \n      throws IOException {\n      this.conf \u003d conf;\n      this.out \u003d out;\n      this.ownOutputStream \u003d ownStream;\n      this.keyClass \u003d keyClass;\n      this.valClass \u003d valClass;\n      this.codec \u003d codec;\n      this.metadata \u003d metadata;\n      SerializationFactory serializationFactory \u003d new SerializationFactory(conf);\n      this.keySerializer \u003d serializationFactory.getSerializer(keyClass);\n      this.keySerializer.open(buffer);\n      this.uncompressedValSerializer \u003d serializationFactory.getSerializer(valClass);\n      this.uncompressedValSerializer.open(buffer);\n      if (this.codec !\u003d null) {\n        ReflectionUtils.setConf(this.codec, this.conf);\n        this.compressor \u003d CodecPool.getCompressor(this.codec);\n        this.deflateFilter \u003d this.codec.createOutputStream(buffer, compressor);\n        this.deflateOut \u003d \n          new DataOutputStream(new BufferedOutputStream(deflateFilter));\n        this.compressedValSerializer \u003d serializationFactory.getSerializer(valClass);\n        this.compressedValSerializer.open(deflateOut);\n      }\n      writeFileHeader();\n    }",
      "path": "common/src/java/org/apache/hadoop/io/SequenceFile.java",
      "extendedDetails": {
        "oldPath": "src/java/org/apache/hadoop/io/SequenceFile.java",
        "newPath": "common/src/java/org/apache/hadoop/io/SequenceFile.java"
      }
    },
    "6333b3e485dc76a7505bf74e041e274e0a8e6faf": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HADOOP-6856. Simplify constructors for SequenceFile, and MapFile. (omalley)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1002937 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "29/09/10 7:59 PM",
      "commitName": "6333b3e485dc76a7505bf74e041e274e0a8e6faf",
      "commitAuthor": "Owen O\u0027Malley",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HADOOP-6856. Simplify constructors for SequenceFile, and MapFile. (omalley)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1002937 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "29/09/10 7:59 PM",
          "commitName": "6333b3e485dc76a7505bf74e041e274e0a8e6faf",
          "commitAuthor": "Owen O\u0027Malley",
          "commitDateOld": "28/08/10 3:44 PM",
          "commitNameOld": "7efb9640be26aabe3878310e82248a1b6b767a9a",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 32.18,
          "commitsBetweenForRepo": 15,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,26 +1,27 @@\n-    void init(Path name, Configuration conf, FSDataOutputStream out,\n+    void init(Configuration conf, FSDataOutputStream out, boolean ownStream,\n               Class keyClass, Class valClass,\n-              boolean compress, CompressionCodec codec, Metadata metadata) \n+              CompressionCodec codec, Metadata metadata) \n       throws IOException {\n       this.conf \u003d conf;\n       this.out \u003d out;\n+      this.ownOutputStream \u003d ownStream;\n       this.keyClass \u003d keyClass;\n       this.valClass \u003d valClass;\n-      this.compress \u003d compress;\n       this.codec \u003d codec;\n       this.metadata \u003d metadata;\n       SerializationFactory serializationFactory \u003d new SerializationFactory(conf);\n       this.keySerializer \u003d serializationFactory.getSerializer(keyClass);\n       this.keySerializer.open(buffer);\n       this.uncompressedValSerializer \u003d serializationFactory.getSerializer(valClass);\n       this.uncompressedValSerializer.open(buffer);\n       if (this.codec !\u003d null) {\n         ReflectionUtils.setConf(this.codec, this.conf);\n         this.compressor \u003d CodecPool.getCompressor(this.codec);\n         this.deflateFilter \u003d this.codec.createOutputStream(buffer, compressor);\n         this.deflateOut \u003d \n           new DataOutputStream(new BufferedOutputStream(deflateFilter));\n         this.compressedValSerializer \u003d serializationFactory.getSerializer(valClass);\n         this.compressedValSerializer.open(deflateOut);\n       }\n+      writeFileHeader();\n     }\n\\ No newline at end of file\n",
          "actualSource": "    void init(Configuration conf, FSDataOutputStream out, boolean ownStream,\n              Class keyClass, Class valClass,\n              CompressionCodec codec, Metadata metadata) \n      throws IOException {\n      this.conf \u003d conf;\n      this.out \u003d out;\n      this.ownOutputStream \u003d ownStream;\n      this.keyClass \u003d keyClass;\n      this.valClass \u003d valClass;\n      this.codec \u003d codec;\n      this.metadata \u003d metadata;\n      SerializationFactory serializationFactory \u003d new SerializationFactory(conf);\n      this.keySerializer \u003d serializationFactory.getSerializer(keyClass);\n      this.keySerializer.open(buffer);\n      this.uncompressedValSerializer \u003d serializationFactory.getSerializer(valClass);\n      this.uncompressedValSerializer.open(buffer);\n      if (this.codec !\u003d null) {\n        ReflectionUtils.setConf(this.codec, this.conf);\n        this.compressor \u003d CodecPool.getCompressor(this.codec);\n        this.deflateFilter \u003d this.codec.createOutputStream(buffer, compressor);\n        this.deflateOut \u003d \n          new DataOutputStream(new BufferedOutputStream(deflateFilter));\n        this.compressedValSerializer \u003d serializationFactory.getSerializer(valClass);\n        this.compressedValSerializer.open(deflateOut);\n      }\n      writeFileHeader();\n    }",
          "path": "src/java/org/apache/hadoop/io/SequenceFile.java",
          "extendedDetails": {
            "oldValue": "[name-Path, conf-Configuration, out-FSDataOutputStream, keyClass-Class, valClass-Class, compress-boolean, codec-CompressionCodec, metadata-Metadata]",
            "newValue": "[conf-Configuration, out-FSDataOutputStream, ownStream-boolean, keyClass-Class, valClass-Class, codec-CompressionCodec, metadata-Metadata]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HADOOP-6856. Simplify constructors for SequenceFile, and MapFile. (omalley)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1002937 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "29/09/10 7:59 PM",
          "commitName": "6333b3e485dc76a7505bf74e041e274e0a8e6faf",
          "commitAuthor": "Owen O\u0027Malley",
          "commitDateOld": "28/08/10 3:44 PM",
          "commitNameOld": "7efb9640be26aabe3878310e82248a1b6b767a9a",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 32.18,
          "commitsBetweenForRepo": 15,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,26 +1,27 @@\n-    void init(Path name, Configuration conf, FSDataOutputStream out,\n+    void init(Configuration conf, FSDataOutputStream out, boolean ownStream,\n               Class keyClass, Class valClass,\n-              boolean compress, CompressionCodec codec, Metadata metadata) \n+              CompressionCodec codec, Metadata metadata) \n       throws IOException {\n       this.conf \u003d conf;\n       this.out \u003d out;\n+      this.ownOutputStream \u003d ownStream;\n       this.keyClass \u003d keyClass;\n       this.valClass \u003d valClass;\n-      this.compress \u003d compress;\n       this.codec \u003d codec;\n       this.metadata \u003d metadata;\n       SerializationFactory serializationFactory \u003d new SerializationFactory(conf);\n       this.keySerializer \u003d serializationFactory.getSerializer(keyClass);\n       this.keySerializer.open(buffer);\n       this.uncompressedValSerializer \u003d serializationFactory.getSerializer(valClass);\n       this.uncompressedValSerializer.open(buffer);\n       if (this.codec !\u003d null) {\n         ReflectionUtils.setConf(this.codec, this.conf);\n         this.compressor \u003d CodecPool.getCompressor(this.codec);\n         this.deflateFilter \u003d this.codec.createOutputStream(buffer, compressor);\n         this.deflateOut \u003d \n           new DataOutputStream(new BufferedOutputStream(deflateFilter));\n         this.compressedValSerializer \u003d serializationFactory.getSerializer(valClass);\n         this.compressedValSerializer.open(deflateOut);\n       }\n+      writeFileHeader();\n     }\n\\ No newline at end of file\n",
          "actualSource": "    void init(Configuration conf, FSDataOutputStream out, boolean ownStream,\n              Class keyClass, Class valClass,\n              CompressionCodec codec, Metadata metadata) \n      throws IOException {\n      this.conf \u003d conf;\n      this.out \u003d out;\n      this.ownOutputStream \u003d ownStream;\n      this.keyClass \u003d keyClass;\n      this.valClass \u003d valClass;\n      this.codec \u003d codec;\n      this.metadata \u003d metadata;\n      SerializationFactory serializationFactory \u003d new SerializationFactory(conf);\n      this.keySerializer \u003d serializationFactory.getSerializer(keyClass);\n      this.keySerializer.open(buffer);\n      this.uncompressedValSerializer \u003d serializationFactory.getSerializer(valClass);\n      this.uncompressedValSerializer.open(buffer);\n      if (this.codec !\u003d null) {\n        ReflectionUtils.setConf(this.codec, this.conf);\n        this.compressor \u003d CodecPool.getCompressor(this.codec);\n        this.deflateFilter \u003d this.codec.createOutputStream(buffer, compressor);\n        this.deflateOut \u003d \n          new DataOutputStream(new BufferedOutputStream(deflateFilter));\n        this.compressedValSerializer \u003d serializationFactory.getSerializer(valClass);\n        this.compressedValSerializer.open(deflateOut);\n      }\n      writeFileHeader();\n    }",
          "path": "src/java/org/apache/hadoop/io/SequenceFile.java",
          "extendedDetails": {}
        }
      ]
    },
    "750fb2dbc1c077c9ca7ce889332a597d4a65388f": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-6698. Revert the io.serialization package to 0.20.2\u0027s api. Reverted HADOOP-6165, HADOOP-6443, HADOOP-6323, and HADOOP-6420.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@939412 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "29/04/10 11:09 AM",
      "commitName": "750fb2dbc1c077c9ca7ce889332a597d4a65388f",
      "commitAuthor": "Thomas White",
      "commitDateOld": "22/03/10 12:08 PM",
      "commitNameOld": "0485fe23ba76f7d96a198aed00f392fd571124bc",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 37.96,
      "commitsBetweenForRepo": 35,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,28 +1,26 @@\n     void init(Path name, Configuration conf, FSDataOutputStream out,\n               Class keyClass, Class valClass,\n               boolean compress, CompressionCodec codec, Metadata metadata) \n       throws IOException {\n       this.conf \u003d conf;\n       this.out \u003d out;\n       this.keyClass \u003d keyClass;\n       this.valClass \u003d valClass;\n       this.compress \u003d compress;\n       this.codec \u003d codec;\n       this.metadata \u003d metadata;\n       SerializationFactory serializationFactory \u003d new SerializationFactory(conf);\n-      this.keySerializer \u003d getSerializer(serializationFactory, keyClass, metadata);\n+      this.keySerializer \u003d serializationFactory.getSerializer(keyClass);\n       this.keySerializer.open(buffer);\n-      this.uncompressedValSerializer \u003d getSerializer(serializationFactory,\n-        valClass, metadata);\n+      this.uncompressedValSerializer \u003d serializationFactory.getSerializer(valClass);\n       this.uncompressedValSerializer.open(buffer);\n       if (this.codec !\u003d null) {\n         ReflectionUtils.setConf(this.codec, this.conf);\n         this.compressor \u003d CodecPool.getCompressor(this.codec);\n         this.deflateFilter \u003d this.codec.createOutputStream(buffer, compressor);\n         this.deflateOut \u003d \n           new DataOutputStream(new BufferedOutputStream(deflateFilter));\n-        this.compressedValSerializer \u003d getSerializer(serializationFactory,\n-          valClass, metadata);\n+        this.compressedValSerializer \u003d serializationFactory.getSerializer(valClass);\n         this.compressedValSerializer.open(deflateOut);\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void init(Path name, Configuration conf, FSDataOutputStream out,\n              Class keyClass, Class valClass,\n              boolean compress, CompressionCodec codec, Metadata metadata) \n      throws IOException {\n      this.conf \u003d conf;\n      this.out \u003d out;\n      this.keyClass \u003d keyClass;\n      this.valClass \u003d valClass;\n      this.compress \u003d compress;\n      this.codec \u003d codec;\n      this.metadata \u003d metadata;\n      SerializationFactory serializationFactory \u003d new SerializationFactory(conf);\n      this.keySerializer \u003d serializationFactory.getSerializer(keyClass);\n      this.keySerializer.open(buffer);\n      this.uncompressedValSerializer \u003d serializationFactory.getSerializer(valClass);\n      this.uncompressedValSerializer.open(buffer);\n      if (this.codec !\u003d null) {\n        ReflectionUtils.setConf(this.codec, this.conf);\n        this.compressor \u003d CodecPool.getCompressor(this.codec);\n        this.deflateFilter \u003d this.codec.createOutputStream(buffer, compressor);\n        this.deflateOut \u003d \n          new DataOutputStream(new BufferedOutputStream(deflateFilter));\n        this.compressedValSerializer \u003d serializationFactory.getSerializer(valClass);\n        this.compressedValSerializer.open(deflateOut);\n      }\n    }",
      "path": "src/java/org/apache/hadoop/io/SequenceFile.java",
      "extendedDetails": {}
    },
    "d6428581ff6ad7859d69b41318bd6fe4736d022d": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-6165. Add metadata to Serializations.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@810756 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/09/09 6:36 PM",
      "commitName": "d6428581ff6ad7859d69b41318bd6fe4736d022d",
      "commitAuthor": "Thomas White",
      "commitDateOld": "01/06/09 2:10 PM",
      "commitNameOld": "5c7b7adacb47242fe4c82e982cb06e6276f6f862",
      "commitAuthorOld": "Owen O\u0027Malley",
      "daysBetweenCommits": 93.18,
      "commitsBetweenForRepo": 75,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,26 +1,28 @@\n     void init(Path name, Configuration conf, FSDataOutputStream out,\n               Class keyClass, Class valClass,\n               boolean compress, CompressionCodec codec, Metadata metadata) \n       throws IOException {\n       this.conf \u003d conf;\n       this.out \u003d out;\n       this.keyClass \u003d keyClass;\n       this.valClass \u003d valClass;\n       this.compress \u003d compress;\n       this.codec \u003d codec;\n       this.metadata \u003d metadata;\n       SerializationFactory serializationFactory \u003d new SerializationFactory(conf);\n-      this.keySerializer \u003d serializationFactory.getSerializer(keyClass);\n+      this.keySerializer \u003d getSerializer(serializationFactory, keyClass, metadata);\n       this.keySerializer.open(buffer);\n-      this.uncompressedValSerializer \u003d serializationFactory.getSerializer(valClass);\n+      this.uncompressedValSerializer \u003d getSerializer(serializationFactory,\n+        valClass, metadata);\n       this.uncompressedValSerializer.open(buffer);\n       if (this.codec !\u003d null) {\n         ReflectionUtils.setConf(this.codec, this.conf);\n         this.compressor \u003d CodecPool.getCompressor(this.codec);\n         this.deflateFilter \u003d this.codec.createOutputStream(buffer, compressor);\n         this.deflateOut \u003d \n           new DataOutputStream(new BufferedOutputStream(deflateFilter));\n-        this.compressedValSerializer \u003d serializationFactory.getSerializer(valClass);\n+        this.compressedValSerializer \u003d getSerializer(serializationFactory,\n+          valClass, metadata);\n         this.compressedValSerializer.open(deflateOut);\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void init(Path name, Configuration conf, FSDataOutputStream out,\n              Class keyClass, Class valClass,\n              boolean compress, CompressionCodec codec, Metadata metadata) \n      throws IOException {\n      this.conf \u003d conf;\n      this.out \u003d out;\n      this.keyClass \u003d keyClass;\n      this.valClass \u003d valClass;\n      this.compress \u003d compress;\n      this.codec \u003d codec;\n      this.metadata \u003d metadata;\n      SerializationFactory serializationFactory \u003d new SerializationFactory(conf);\n      this.keySerializer \u003d getSerializer(serializationFactory, keyClass, metadata);\n      this.keySerializer.open(buffer);\n      this.uncompressedValSerializer \u003d getSerializer(serializationFactory,\n        valClass, metadata);\n      this.uncompressedValSerializer.open(buffer);\n      if (this.codec !\u003d null) {\n        ReflectionUtils.setConf(this.codec, this.conf);\n        this.compressor \u003d CodecPool.getCompressor(this.codec);\n        this.deflateFilter \u003d this.codec.createOutputStream(buffer, compressor);\n        this.deflateOut \u003d \n          new DataOutputStream(new BufferedOutputStream(deflateFilter));\n        this.compressedValSerializer \u003d getSerializer(serializationFactory,\n          valClass, metadata);\n        this.compressedValSerializer.open(deflateOut);\n      }\n    }",
      "path": "src/java/org/apache/hadoop/io/SequenceFile.java",
      "extendedDetails": {}
    },
    "5128a9a453d64bfe1ed978cf9ffed27985eeef36": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-4687 Moving src directories on branch\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/core/branches/HADOOP-4687/core@776174 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/05/09 9:20 PM",
      "commitName": "5128a9a453d64bfe1ed978cf9ffed27985eeef36",
      "commitAuthor": "Owen O\u0027Malley",
      "diff": "@@ -0,0 +1,26 @@\n+    void init(Path name, Configuration conf, FSDataOutputStream out,\n+              Class keyClass, Class valClass,\n+              boolean compress, CompressionCodec codec, Metadata metadata) \n+      throws IOException {\n+      this.conf \u003d conf;\n+      this.out \u003d out;\n+      this.keyClass \u003d keyClass;\n+      this.valClass \u003d valClass;\n+      this.compress \u003d compress;\n+      this.codec \u003d codec;\n+      this.metadata \u003d metadata;\n+      SerializationFactory serializationFactory \u003d new SerializationFactory(conf);\n+      this.keySerializer \u003d serializationFactory.getSerializer(keyClass);\n+      this.keySerializer.open(buffer);\n+      this.uncompressedValSerializer \u003d serializationFactory.getSerializer(valClass);\n+      this.uncompressedValSerializer.open(buffer);\n+      if (this.codec !\u003d null) {\n+        ReflectionUtils.setConf(this.codec, this.conf);\n+        this.compressor \u003d CodecPool.getCompressor(this.codec);\n+        this.deflateFilter \u003d this.codec.createOutputStream(buffer, compressor);\n+        this.deflateOut \u003d \n+          new DataOutputStream(new BufferedOutputStream(deflateFilter));\n+        this.compressedValSerializer \u003d serializationFactory.getSerializer(valClass);\n+        this.compressedValSerializer.open(deflateOut);\n+      }\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    void init(Path name, Configuration conf, FSDataOutputStream out,\n              Class keyClass, Class valClass,\n              boolean compress, CompressionCodec codec, Metadata metadata) \n      throws IOException {\n      this.conf \u003d conf;\n      this.out \u003d out;\n      this.keyClass \u003d keyClass;\n      this.valClass \u003d valClass;\n      this.compress \u003d compress;\n      this.codec \u003d codec;\n      this.metadata \u003d metadata;\n      SerializationFactory serializationFactory \u003d new SerializationFactory(conf);\n      this.keySerializer \u003d serializationFactory.getSerializer(keyClass);\n      this.keySerializer.open(buffer);\n      this.uncompressedValSerializer \u003d serializationFactory.getSerializer(valClass);\n      this.uncompressedValSerializer.open(buffer);\n      if (this.codec !\u003d null) {\n        ReflectionUtils.setConf(this.codec, this.conf);\n        this.compressor \u003d CodecPool.getCompressor(this.codec);\n        this.deflateFilter \u003d this.codec.createOutputStream(buffer, compressor);\n        this.deflateOut \u003d \n          new DataOutputStream(new BufferedOutputStream(deflateFilter));\n        this.compressedValSerializer \u003d serializationFactory.getSerializer(valClass);\n        this.compressedValSerializer.open(deflateOut);\n      }\n    }",
      "path": "src/java/org/apache/hadoop/io/SequenceFile.java"
    }
  }
}