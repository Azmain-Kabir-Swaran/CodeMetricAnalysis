{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSDirectory.java",
  "functionName": "isValidToCreate",
  "functionId": "isValidToCreate___src-String__iip-INodesInPath",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
  "functionStartLine": 788,
  "functionEndLine": 793,
  "numCommitsSeen": 547,
  "timeTaken": 11958,
  "changeHistory": [
    "c78e3a7cdd10c40454e9acb06986ba6d8573cb19",
    "ae9109b911b3d9e2d6ca50b400379fc31deeb0cf",
    "0689363343a281a6f7f6f395227668bddc2663eb",
    "2372e394dd99d69d396327d5a5e172953a8b8c6a",
    "2116d0520e528c44fa280f2a5b28594c6d6fc28a",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "c78e3a7cdd10c40454e9acb06986ba6d8573cb19": "Ymultichange(Yparameterchange,Yexceptionschange,Ybodychange)",
    "ae9109b911b3d9e2d6ca50b400379fc31deeb0cf": "Ybodychange",
    "0689363343a281a6f7f6f395227668bddc2663eb": "Ybodychange",
    "2372e394dd99d69d396327d5a5e172953a8b8c6a": "Ybodychange",
    "2116d0520e528c44fa280f2a5b28594c6d6fc28a": "Ymultichange(Yexceptionschange,Ybodychange)",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "c78e3a7cdd10c40454e9acb06986ba6d8573cb19": {
      "type": "Ymultichange(Yparameterchange,Yexceptionschange,Ybodychange)",
      "commitMessage": "HDFS-7059. Avoid resolving path multiple times. Contributed by Jing Zhao.\n",
      "commitDate": "12/12/14 3:13 PM",
      "commitName": "c78e3a7cdd10c40454e9acb06986ba6d8573cb19",
      "commitAuthor": "Jing Zhao",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-7059. Avoid resolving path multiple times. Contributed by Jing Zhao.\n",
          "commitDate": "12/12/14 3:13 PM",
          "commitName": "c78e3a7cdd10c40454e9acb06986ba6d8573cb19",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "09/12/14 11:37 AM",
          "commitNameOld": "5776a41da08af653206bb94d7c76c9c4dcce059a",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 3.15,
          "commitsBetweenForRepo": 33,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,6 @@\n-  boolean isValidToCreate(String src) throws UnresolvedLinkException,\n-      SnapshotAccessControlException {\n+  boolean isValidToCreate(String src, INodesInPath iip)\n+      throws SnapshotAccessControlException {\n     String srcs \u003d normalizePath(src);\n-    readLock();\n-    try {\n-      return srcs.startsWith(\"/\") \u0026\u0026 !srcs.endsWith(\"/\")\n-              \u0026\u0026 getINode4Write(srcs, false) \u003d\u003d null;\n-    } finally {\n-      readUnlock();\n-    }\n+    return srcs.startsWith(\"/\") \u0026\u0026 !srcs.endsWith(\"/\") \u0026\u0026\n+        iip.getLastINode() \u003d\u003d null;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  boolean isValidToCreate(String src, INodesInPath iip)\n      throws SnapshotAccessControlException {\n    String srcs \u003d normalizePath(src);\n    return srcs.startsWith(\"/\") \u0026\u0026 !srcs.endsWith(\"/\") \u0026\u0026\n        iip.getLastINode() \u003d\u003d null;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
          "extendedDetails": {
            "oldValue": "[src-String]",
            "newValue": "[src-String, iip-INodesInPath]"
          }
        },
        {
          "type": "Yexceptionschange",
          "commitMessage": "HDFS-7059. Avoid resolving path multiple times. Contributed by Jing Zhao.\n",
          "commitDate": "12/12/14 3:13 PM",
          "commitName": "c78e3a7cdd10c40454e9acb06986ba6d8573cb19",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "09/12/14 11:37 AM",
          "commitNameOld": "5776a41da08af653206bb94d7c76c9c4dcce059a",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 3.15,
          "commitsBetweenForRepo": 33,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,6 @@\n-  boolean isValidToCreate(String src) throws UnresolvedLinkException,\n-      SnapshotAccessControlException {\n+  boolean isValidToCreate(String src, INodesInPath iip)\n+      throws SnapshotAccessControlException {\n     String srcs \u003d normalizePath(src);\n-    readLock();\n-    try {\n-      return srcs.startsWith(\"/\") \u0026\u0026 !srcs.endsWith(\"/\")\n-              \u0026\u0026 getINode4Write(srcs, false) \u003d\u003d null;\n-    } finally {\n-      readUnlock();\n-    }\n+    return srcs.startsWith(\"/\") \u0026\u0026 !srcs.endsWith(\"/\") \u0026\u0026\n+        iip.getLastINode() \u003d\u003d null;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  boolean isValidToCreate(String src, INodesInPath iip)\n      throws SnapshotAccessControlException {\n    String srcs \u003d normalizePath(src);\n    return srcs.startsWith(\"/\") \u0026\u0026 !srcs.endsWith(\"/\") \u0026\u0026\n        iip.getLastINode() \u003d\u003d null;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
          "extendedDetails": {
            "oldValue": "[UnresolvedLinkException, SnapshotAccessControlException]",
            "newValue": "[SnapshotAccessControlException]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7059. Avoid resolving path multiple times. Contributed by Jing Zhao.\n",
          "commitDate": "12/12/14 3:13 PM",
          "commitName": "c78e3a7cdd10c40454e9acb06986ba6d8573cb19",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "09/12/14 11:37 AM",
          "commitNameOld": "5776a41da08af653206bb94d7c76c9c4dcce059a",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 3.15,
          "commitsBetweenForRepo": 33,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,6 @@\n-  boolean isValidToCreate(String src) throws UnresolvedLinkException,\n-      SnapshotAccessControlException {\n+  boolean isValidToCreate(String src, INodesInPath iip)\n+      throws SnapshotAccessControlException {\n     String srcs \u003d normalizePath(src);\n-    readLock();\n-    try {\n-      return srcs.startsWith(\"/\") \u0026\u0026 !srcs.endsWith(\"/\")\n-              \u0026\u0026 getINode4Write(srcs, false) \u003d\u003d null;\n-    } finally {\n-      readUnlock();\n-    }\n+    return srcs.startsWith(\"/\") \u0026\u0026 !srcs.endsWith(\"/\") \u0026\u0026\n+        iip.getLastINode() \u003d\u003d null;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  boolean isValidToCreate(String src, INodesInPath iip)\n      throws SnapshotAccessControlException {\n    String srcs \u003d normalizePath(src);\n    return srcs.startsWith(\"/\") \u0026\u0026 !srcs.endsWith(\"/\") \u0026\u0026\n        iip.getLastINode() \u003d\u003d null;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
          "extendedDetails": {}
        }
      ]
    },
    "ae9109b911b3d9e2d6ca50b400379fc31deeb0cf": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6328. Clean up dead code in FSDirectory. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1593755 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/05/14 10:06 PM",
      "commitName": "ae9109b911b3d9e2d6ca50b400379fc31deeb0cf",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "30/04/14 10:44 AM",
      "commitNameOld": "0689363343a281a6f7f6f395227668bddc2663eb",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 10.47,
      "commitsBetweenForRepo": 43,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,15 +1,11 @@\n   boolean isValidToCreate(String src) throws UnresolvedLinkException,\n       SnapshotAccessControlException {\n     String srcs \u003d normalizePath(src);\n     readLock();\n     try {\n-      if (srcs.startsWith(\"/\") \u0026\u0026 !srcs.endsWith(\"/\")\n-          \u0026\u0026 getINode4Write(srcs, false) \u003d\u003d null) {\n-        return true;\n-      } else {\n-        return false;\n-      }\n+      return srcs.startsWith(\"/\") \u0026\u0026 !srcs.endsWith(\"/\")\n+              \u0026\u0026 getINode4Write(srcs, false) \u003d\u003d null;\n     } finally {\n       readUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  boolean isValidToCreate(String src) throws UnresolvedLinkException,\n      SnapshotAccessControlException {\n    String srcs \u003d normalizePath(src);\n    readLock();\n    try {\n      return srcs.startsWith(\"/\") \u0026\u0026 !srcs.endsWith(\"/\")\n              \u0026\u0026 getINode4Write(srcs, false) \u003d\u003d null;\n    } finally {\n      readUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
      "extendedDetails": {}
    },
    "0689363343a281a6f7f6f395227668bddc2663eb": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6304. Consolidate the logic of path resolution in FSDirectory. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1591411 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "30/04/14 10:44 AM",
      "commitName": "0689363343a281a6f7f6f395227668bddc2663eb",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "24/04/14 7:05 PM",
      "commitNameOld": "10a037cccb00c9f791da394bf2dc05985fb80612",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 5.65,
      "commitsBetweenForRepo": 24,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,15 +1,15 @@\n   boolean isValidToCreate(String src) throws UnresolvedLinkException,\n       SnapshotAccessControlException {\n     String srcs \u003d normalizePath(src);\n     readLock();\n     try {\n       if (srcs.startsWith(\"/\") \u0026\u0026 !srcs.endsWith(\"/\")\n-          \u0026\u0026 rootDir.getINode4Write(srcs, false) \u003d\u003d null) {\n+          \u0026\u0026 getINode4Write(srcs, false) \u003d\u003d null) {\n         return true;\n       } else {\n         return false;\n       }\n     } finally {\n       readUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  boolean isValidToCreate(String src) throws UnresolvedLinkException,\n      SnapshotAccessControlException {\n    String srcs \u003d normalizePath(src);\n    readLock();\n    try {\n      if (srcs.startsWith(\"/\") \u0026\u0026 !srcs.endsWith(\"/\")\n          \u0026\u0026 getINode4Write(srcs, false) \u003d\u003d null) {\n        return true;\n      } else {\n        return false;\n      }\n    } finally {\n      readUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
      "extendedDetails": {}
    },
    "2372e394dd99d69d396327d5a5e172953a8b8c6a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4189. Renames the getMutableXxx methods to getXxx4Write and fix a bug that some getExistingPathINodes calls should be getINodesInPath4Write.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2802@1441193 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "31/01/13 1:13 PM",
      "commitName": "2372e394dd99d69d396327d5a5e172953a8b8c6a",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "25/01/13 4:01 PM",
      "commitNameOld": "a3bf2083867db5d848ea14f145d120f02b820af2",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 5.88,
      "commitsBetweenForRepo": 22,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,15 +1,15 @@\n   boolean isValidToCreate(String src) throws UnresolvedLinkException,\n       SnapshotAccessControlException {\n     String srcs \u003d normalizePath(src);\n     readLock();\n     try {\n       if (srcs.startsWith(\"/\") \u0026\u0026 !srcs.endsWith(\"/\")\n-          \u0026\u0026 rootDir.getMutableNode(srcs, false) \u003d\u003d null) {\n+          \u0026\u0026 rootDir.getINode4Write(srcs, false) \u003d\u003d null) {\n         return true;\n       } else {\n         return false;\n       }\n     } finally {\n       readUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  boolean isValidToCreate(String src) throws UnresolvedLinkException,\n      SnapshotAccessControlException {\n    String srcs \u003d normalizePath(src);\n    readLock();\n    try {\n      if (srcs.startsWith(\"/\") \u0026\u0026 !srcs.endsWith(\"/\")\n          \u0026\u0026 rootDir.getINode4Write(srcs, false) \u003d\u003d null) {\n        return true;\n      } else {\n        return false;\n      }\n    } finally {\n      readUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
      "extendedDetails": {}
    },
    "2116d0520e528c44fa280f2a5b28594c6d6fc28a": {
      "type": "Ymultichange(Yexceptionschange,Ybodychange)",
      "commitMessage": "HDFS-4148. Disallow write/modify operations on files and directories in a snapshot. Contributed by Brandon Li.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2802@1409023 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/11/12 3:26 PM",
      "commitName": "2116d0520e528c44fa280f2a5b28594c6d6fc28a",
      "commitAuthor": "Suresh Srinivas",
      "subchanges": [
        {
          "type": "Yexceptionschange",
          "commitMessage": "HDFS-4148. Disallow write/modify operations on files and directories in a snapshot. Contributed by Brandon Li.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2802@1409023 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "13/11/12 3:26 PM",
          "commitName": "2116d0520e528c44fa280f2a5b28594c6d6fc28a",
          "commitAuthor": "Suresh Srinivas",
          "commitDateOld": "13/11/12 11:59 AM",
          "commitNameOld": "099762a0bc960066f8157fdd1e495b6752a6f802",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 0.14,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,15 +1,15 @@\n-  boolean isValidToCreate(String src) throws UnresolvedLinkException {\n+  boolean isValidToCreate(String src) throws UnresolvedLinkException,\n+      SnapshotAccessControlException {\n     String srcs \u003d normalizePath(src);\n     readLock();\n     try {\n-      if (srcs.startsWith(\"/\") \u0026\u0026 \n-          !srcs.endsWith(\"/\") \u0026\u0026 \n-          rootDir.getNode(srcs, false) \u003d\u003d null) {\n+      if (srcs.startsWith(\"/\") \u0026\u0026 !srcs.endsWith(\"/\")\n+          \u0026\u0026 rootDir.getMutableNode(srcs, false) \u003d\u003d null) {\n         return true;\n       } else {\n         return false;\n       }\n     } finally {\n       readUnlock();\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  boolean isValidToCreate(String src) throws UnresolvedLinkException,\n      SnapshotAccessControlException {\n    String srcs \u003d normalizePath(src);\n    readLock();\n    try {\n      if (srcs.startsWith(\"/\") \u0026\u0026 !srcs.endsWith(\"/\")\n          \u0026\u0026 rootDir.getMutableNode(srcs, false) \u003d\u003d null) {\n        return true;\n      } else {\n        return false;\n      }\n    } finally {\n      readUnlock();\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
          "extendedDetails": {
            "oldValue": "[UnresolvedLinkException]",
            "newValue": "[UnresolvedLinkException, SnapshotAccessControlException]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-4148. Disallow write/modify operations on files and directories in a snapshot. Contributed by Brandon Li.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2802@1409023 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "13/11/12 3:26 PM",
          "commitName": "2116d0520e528c44fa280f2a5b28594c6d6fc28a",
          "commitAuthor": "Suresh Srinivas",
          "commitDateOld": "13/11/12 11:59 AM",
          "commitNameOld": "099762a0bc960066f8157fdd1e495b6752a6f802",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 0.14,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,15 +1,15 @@\n-  boolean isValidToCreate(String src) throws UnresolvedLinkException {\n+  boolean isValidToCreate(String src) throws UnresolvedLinkException,\n+      SnapshotAccessControlException {\n     String srcs \u003d normalizePath(src);\n     readLock();\n     try {\n-      if (srcs.startsWith(\"/\") \u0026\u0026 \n-          !srcs.endsWith(\"/\") \u0026\u0026 \n-          rootDir.getNode(srcs, false) \u003d\u003d null) {\n+      if (srcs.startsWith(\"/\") \u0026\u0026 !srcs.endsWith(\"/\")\n+          \u0026\u0026 rootDir.getMutableNode(srcs, false) \u003d\u003d null) {\n         return true;\n       } else {\n         return false;\n       }\n     } finally {\n       readUnlock();\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  boolean isValidToCreate(String src) throws UnresolvedLinkException,\n      SnapshotAccessControlException {\n    String srcs \u003d normalizePath(src);\n    readLock();\n    try {\n      if (srcs.startsWith(\"/\") \u0026\u0026 !srcs.endsWith(\"/\")\n          \u0026\u0026 rootDir.getMutableNode(srcs, false) \u003d\u003d null) {\n        return true;\n      } else {\n        return false;\n      }\n    } finally {\n      readUnlock();\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
          "extendedDetails": {}
        }
      ]
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  boolean isValidToCreate(String src) throws UnresolvedLinkException {\n    String srcs \u003d normalizePath(src);\n    readLock();\n    try {\n      if (srcs.startsWith(\"/\") \u0026\u0026 \n          !srcs.endsWith(\"/\") \u0026\u0026 \n          rootDir.getNode(srcs, false) \u003d\u003d null) {\n        return true;\n      } else {\n        return false;\n      }\n    } finally {\n      readUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  boolean isValidToCreate(String src) throws UnresolvedLinkException {\n    String srcs \u003d normalizePath(src);\n    readLock();\n    try {\n      if (srcs.startsWith(\"/\") \u0026\u0026 \n          !srcs.endsWith(\"/\") \u0026\u0026 \n          rootDir.getNode(srcs, false) \u003d\u003d null) {\n        return true;\n      } else {\n        return false;\n      }\n    } finally {\n      readUnlock();\n    }\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,15 @@\n+  boolean isValidToCreate(String src) throws UnresolvedLinkException {\n+    String srcs \u003d normalizePath(src);\n+    readLock();\n+    try {\n+      if (srcs.startsWith(\"/\") \u0026\u0026 \n+          !srcs.endsWith(\"/\") \u0026\u0026 \n+          rootDir.getNode(srcs, false) \u003d\u003d null) {\n+        return true;\n+      } else {\n+        return false;\n+      }\n+    } finally {\n+      readUnlock();\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  boolean isValidToCreate(String src) throws UnresolvedLinkException {\n    String srcs \u003d normalizePath(src);\n    readLock();\n    try {\n      if (srcs.startsWith(\"/\") \u0026\u0026 \n          !srcs.endsWith(\"/\") \u0026\u0026 \n          rootDir.getNode(srcs, false) \u003d\u003d null) {\n        return true;\n      } else {\n        return false;\n      }\n    } finally {\n      readUnlock();\n    }\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java"
    }
  }
}