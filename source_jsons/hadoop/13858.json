{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockManager.java",
  "functionName": "processQueuedMessages",
  "functionId": "processQueuedMessages___rbis-Iterable__ReportedBlockInfo__",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
  "functionStartLine": 3208,
  "functionEndLine": 3229,
  "numCommitsSeen": 477,
  "timeTaken": 17728,
  "changeHistory": [
    "7f8685f4760f1358bb30927a7da9a5041e8c39e1",
    "a7f085d6bf499edf23e650a4f7211c53a442da0e",
    "1b5cceaffbdde50a87ede81552dc380832db8e79",
    "b9522e86a55564c2ccb5ca3f1ca871965cbe74de",
    "663eba0ab1c73b45f98e46ffc87ad8fd91584046",
    "de480d6c8945bd8b5b00e8657b7a72ce8dd9b6b5",
    "6bacaa9a5233cbad7f311ccd9d8f8dc9375c732d",
    "2d4ae3d18bc530fa9f81ee616db8af3395705fb9",
    "45db4d204b796eee6dd0e39d3cc94b70c47028d4",
    "5d9d702607913685eab0d8ad077040ddc82bf085"
  ],
  "changeHistoryShort": {
    "7f8685f4760f1358bb30927a7da9a5041e8c39e1": "Ybodychange",
    "a7f085d6bf499edf23e650a4f7211c53a442da0e": "Ybodychange",
    "1b5cceaffbdde50a87ede81552dc380832db8e79": "Ybodychange",
    "b9522e86a55564c2ccb5ca3f1ca871965cbe74de": "Ybodychange",
    "663eba0ab1c73b45f98e46ffc87ad8fd91584046": "Ybodychange",
    "de480d6c8945bd8b5b00e8657b7a72ce8dd9b6b5": "Ybodychange",
    "6bacaa9a5233cbad7f311ccd9d8f8dc9375c732d": "Ybodychange",
    "2d4ae3d18bc530fa9f81ee616db8af3395705fb9": "Ybodychange",
    "45db4d204b796eee6dd0e39d3cc94b70c47028d4": "Ybodychange",
    "5d9d702607913685eab0d8ad077040ddc82bf085": "Ybodychange"
  },
  "changeHistoryDetails": {
    "7f8685f4760f1358bb30927a7da9a5041e8c39e1": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-15187. CORRUPT replica mismatch between namenodes after failover. Contributed by Ayush Saxena.\n",
      "commitDate": "24/02/20 7:08 AM",
      "commitName": "7f8685f4760f1358bb30927a7da9a5041e8c39e1",
      "commitAuthor": "Ayush Saxena",
      "commitDateOld": "23/02/20 12:55 AM",
      "commitNameOld": "9eb7a8bdf8f3b1dc76efc22db9651474303d309e",
      "commitAuthorOld": "Ayush Saxena",
      "daysBetweenCommits": 1.26,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,15 +1,22 @@\n   private void processQueuedMessages(Iterable\u003cReportedBlockInfo\u003e rbis)\n       throws IOException {\n+    boolean isPreviousMessageProcessed \u003d true;\n     for (ReportedBlockInfo rbi : rbis) {\n       LOG.debug(\"Processing previouly queued message {}\", rbi);\n       if (rbi.getReportedState() \u003d\u003d null) {\n         // This is a DELETE_BLOCK request\n         DatanodeStorageInfo storageInfo \u003d rbi.getStorageInfo();\n         removeStoredBlock(getStoredBlock(rbi.getBlock()),\n             storageInfo.getDatanodeDescriptor());\n+      } else if (!isPreviousMessageProcessed) {\n+        // if the previous IBR processing was skipped, skip processing all\n+        // further IBR\u0027s so as to ensure same sequence of processing.\n+        queueReportedBlock(rbi.getStorageInfo(), rbi.getBlock(),\n+            rbi.getReportedState(), QUEUE_REASON_FUTURE_GENSTAMP);\n       } else {\n-        processAndHandleReportedBlock(rbi.getStorageInfo(),\n-            rbi.getBlock(), rbi.getReportedState(), null);\n+        isPreviousMessageProcessed \u003d\n+            processAndHandleReportedBlock(rbi.getStorageInfo(), rbi.getBlock(),\n+                rbi.getReportedState(), null);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void processQueuedMessages(Iterable\u003cReportedBlockInfo\u003e rbis)\n      throws IOException {\n    boolean isPreviousMessageProcessed \u003d true;\n    for (ReportedBlockInfo rbi : rbis) {\n      LOG.debug(\"Processing previouly queued message {}\", rbi);\n      if (rbi.getReportedState() \u003d\u003d null) {\n        // This is a DELETE_BLOCK request\n        DatanodeStorageInfo storageInfo \u003d rbi.getStorageInfo();\n        removeStoredBlock(getStoredBlock(rbi.getBlock()),\n            storageInfo.getDatanodeDescriptor());\n      } else if (!isPreviousMessageProcessed) {\n        // if the previous IBR processing was skipped, skip processing all\n        // further IBR\u0027s so as to ensure same sequence of processing.\n        queueReportedBlock(rbi.getStorageInfo(), rbi.getBlock(),\n            rbi.getReportedState(), QUEUE_REASON_FUTURE_GENSTAMP);\n      } else {\n        isPreviousMessageProcessed \u003d\n            processAndHandleReportedBlock(rbi.getStorageInfo(), rbi.getBlock(),\n                rbi.getReportedState(), null);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "a7f085d6bf499edf23e650a4f7211c53a442da0e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11832. Switch leftover logs to slf4j format in BlockManager.java. Contributed by Hui Xu and Chen Liang.\n",
      "commitDate": "29/05/17 1:30 AM",
      "commitName": "a7f085d6bf499edf23e650a4f7211c53a442da0e",
      "commitAuthor": "Akira Ajisaka",
      "commitDateOld": "25/05/17 7:35 AM",
      "commitNameOld": "2e41f8803dd46d1bab16c1b206c71be72ea260a1",
      "commitAuthorOld": "Brahma Reddy Battula",
      "daysBetweenCommits": 3.75,
      "commitsBetweenForRepo": 17,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,15 @@\n   private void processQueuedMessages(Iterable\u003cReportedBlockInfo\u003e rbis)\n       throws IOException {\n     for (ReportedBlockInfo rbi : rbis) {\n-      if (LOG.isDebugEnabled()) {\n-        LOG.debug(\"Processing previouly queued message \" + rbi);\n-      }\n+      LOG.debug(\"Processing previouly queued message {}\", rbi);\n       if (rbi.getReportedState() \u003d\u003d null) {\n         // This is a DELETE_BLOCK request\n         DatanodeStorageInfo storageInfo \u003d rbi.getStorageInfo();\n         removeStoredBlock(getStoredBlock(rbi.getBlock()),\n             storageInfo.getDatanodeDescriptor());\n       } else {\n         processAndHandleReportedBlock(rbi.getStorageInfo(),\n             rbi.getBlock(), rbi.getReportedState(), null);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void processQueuedMessages(Iterable\u003cReportedBlockInfo\u003e rbis)\n      throws IOException {\n    for (ReportedBlockInfo rbi : rbis) {\n      LOG.debug(\"Processing previouly queued message {}\", rbi);\n      if (rbi.getReportedState() \u003d\u003d null) {\n        // This is a DELETE_BLOCK request\n        DatanodeStorageInfo storageInfo \u003d rbi.getStorageInfo();\n        removeStoredBlock(getStoredBlock(rbi.getBlock()),\n            storageInfo.getDatanodeDescriptor());\n      } else {\n        processAndHandleReportedBlock(rbi.getStorageInfo(),\n            rbi.getBlock(), rbi.getReportedState(), null);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "1b5cceaffbdde50a87ede81552dc380832db8e79": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-11201. Spelling errors in the logging, help, assertions and exception messages. Contributed by Grant Sohn.\"\n\nThis reverts commit b9522e86a55564c2ccb5ca3f1ca871965cbe74de.\n",
      "commitDate": "05/12/16 10:54 AM",
      "commitName": "1b5cceaffbdde50a87ede81552dc380832db8e79",
      "commitAuthor": "Wei-Chiu Chuang",
      "commitDateOld": "05/12/16 10:48 AM",
      "commitNameOld": "b9522e86a55564c2ccb5ca3f1ca871965cbe74de",
      "commitAuthorOld": "Wei-Chiu Chuang",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,17 @@\n   private void processQueuedMessages(Iterable\u003cReportedBlockInfo\u003e rbis)\n       throws IOException {\n     for (ReportedBlockInfo rbi : rbis) {\n       if (LOG.isDebugEnabled()) {\n-        LOG.debug(\"Processing previously queued message \" + rbi);\n+        LOG.debug(\"Processing previouly queued message \" + rbi);\n       }\n       if (rbi.getReportedState() \u003d\u003d null) {\n         // This is a DELETE_BLOCK request\n         DatanodeStorageInfo storageInfo \u003d rbi.getStorageInfo();\n         removeStoredBlock(getStoredBlock(rbi.getBlock()),\n             storageInfo.getDatanodeDescriptor());\n       } else {\n         processAndHandleReportedBlock(rbi.getStorageInfo(),\n             rbi.getBlock(), rbi.getReportedState(), null);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void processQueuedMessages(Iterable\u003cReportedBlockInfo\u003e rbis)\n      throws IOException {\n    for (ReportedBlockInfo rbi : rbis) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Processing previouly queued message \" + rbi);\n      }\n      if (rbi.getReportedState() \u003d\u003d null) {\n        // This is a DELETE_BLOCK request\n        DatanodeStorageInfo storageInfo \u003d rbi.getStorageInfo();\n        removeStoredBlock(getStoredBlock(rbi.getBlock()),\n            storageInfo.getDatanodeDescriptor());\n      } else {\n        processAndHandleReportedBlock(rbi.getStorageInfo(),\n            rbi.getBlock(), rbi.getReportedState(), null);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "b9522e86a55564c2ccb5ca3f1ca871965cbe74de": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11201. Spelling errors in the logging, help, assertions and exception messages. Contributed by Grant Sohn.\n",
      "commitDate": "05/12/16 10:48 AM",
      "commitName": "b9522e86a55564c2ccb5ca3f1ca871965cbe74de",
      "commitAuthor": "Wei-Chiu Chuang",
      "commitDateOld": "01/12/16 10:11 AM",
      "commitNameOld": "96c574927a600d15fab919df1fdc9e07887af6c5",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 4.03,
      "commitsBetweenForRepo": 14,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,17 @@\n   private void processQueuedMessages(Iterable\u003cReportedBlockInfo\u003e rbis)\n       throws IOException {\n     for (ReportedBlockInfo rbi : rbis) {\n       if (LOG.isDebugEnabled()) {\n-        LOG.debug(\"Processing previouly queued message \" + rbi);\n+        LOG.debug(\"Processing previously queued message \" + rbi);\n       }\n       if (rbi.getReportedState() \u003d\u003d null) {\n         // This is a DELETE_BLOCK request\n         DatanodeStorageInfo storageInfo \u003d rbi.getStorageInfo();\n         removeStoredBlock(getStoredBlock(rbi.getBlock()),\n             storageInfo.getDatanodeDescriptor());\n       } else {\n         processAndHandleReportedBlock(rbi.getStorageInfo(),\n             rbi.getBlock(), rbi.getReportedState(), null);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void processQueuedMessages(Iterable\u003cReportedBlockInfo\u003e rbis)\n      throws IOException {\n    for (ReportedBlockInfo rbi : rbis) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Processing previously queued message \" + rbi);\n      }\n      if (rbi.getReportedState() \u003d\u003d null) {\n        // This is a DELETE_BLOCK request\n        DatanodeStorageInfo storageInfo \u003d rbi.getStorageInfo();\n        removeStoredBlock(getStoredBlock(rbi.getBlock()),\n            storageInfo.getDatanodeDescriptor());\n      } else {\n        processAndHandleReportedBlock(rbi.getStorageInfo(),\n            rbi.getBlock(), rbi.getReportedState(), null);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "663eba0ab1c73b45f98e46ffc87ad8fd91584046": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-8623. Refactor NameNode handling of invalid, corrupt, and under-recovery blocks. Contributed by Zhe Zhang.\"\n\nThis reverts commit de480d6c8945bd8b5b00e8657b7a72ce8dd9b6b5.\n",
      "commitDate": "06/08/15 10:21 AM",
      "commitName": "663eba0ab1c73b45f98e46ffc87ad8fd91584046",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "31/07/15 4:15 PM",
      "commitNameOld": "d311a38a6b32bbb210bd8748cfb65463e9c0740e",
      "commitAuthorOld": "Xiaoyu Yao",
      "daysBetweenCommits": 5.75,
      "commitsBetweenForRepo": 23,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,17 @@\n   private void processQueuedMessages(Iterable\u003cReportedBlockInfo\u003e rbis)\n       throws IOException {\n     for (ReportedBlockInfo rbi : rbis) {\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Processing previouly queued message \" + rbi);\n       }\n       if (rbi.getReportedState() \u003d\u003d null) {\n         // This is a DELETE_BLOCK request\n         DatanodeStorageInfo storageInfo \u003d rbi.getStorageInfo();\n-        removeStoredBlock(getStoredBlock(rbi.getBlock()),\n+        removeStoredBlock(rbi.getBlock(),\n             storageInfo.getDatanodeDescriptor());\n       } else {\n         processAndHandleReportedBlock(rbi.getStorageInfo(),\n             rbi.getBlock(), rbi.getReportedState(), null);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void processQueuedMessages(Iterable\u003cReportedBlockInfo\u003e rbis)\n      throws IOException {\n    for (ReportedBlockInfo rbi : rbis) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Processing previouly queued message \" + rbi);\n      }\n      if (rbi.getReportedState() \u003d\u003d null) {\n        // This is a DELETE_BLOCK request\n        DatanodeStorageInfo storageInfo \u003d rbi.getStorageInfo();\n        removeStoredBlock(rbi.getBlock(),\n            storageInfo.getDatanodeDescriptor());\n      } else {\n        processAndHandleReportedBlock(rbi.getStorageInfo(),\n            rbi.getBlock(), rbi.getReportedState(), null);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "de480d6c8945bd8b5b00e8657b7a72ce8dd9b6b5": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8623. Refactor NameNode handling of invalid, corrupt, and under-recovery blocks. Contributed by Zhe Zhang.\n",
      "commitDate": "26/06/15 10:49 AM",
      "commitName": "de480d6c8945bd8b5b00e8657b7a72ce8dd9b6b5",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "24/06/15 2:42 PM",
      "commitNameOld": "afe9ea3c12e1f5a71922400eadb642960bc87ca1",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 1.84,
      "commitsBetweenForRepo": 12,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,17 @@\n   private void processQueuedMessages(Iterable\u003cReportedBlockInfo\u003e rbis)\n       throws IOException {\n     for (ReportedBlockInfo rbi : rbis) {\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Processing previouly queued message \" + rbi);\n       }\n       if (rbi.getReportedState() \u003d\u003d null) {\n         // This is a DELETE_BLOCK request\n         DatanodeStorageInfo storageInfo \u003d rbi.getStorageInfo();\n-        removeStoredBlock(rbi.getBlock(),\n+        removeStoredBlock(getStoredBlock(rbi.getBlock()),\n             storageInfo.getDatanodeDescriptor());\n       } else {\n         processAndHandleReportedBlock(rbi.getStorageInfo(),\n             rbi.getBlock(), rbi.getReportedState(), null);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void processQueuedMessages(Iterable\u003cReportedBlockInfo\u003e rbis)\n      throws IOException {\n    for (ReportedBlockInfo rbi : rbis) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Processing previouly queued message \" + rbi);\n      }\n      if (rbi.getReportedState() \u003d\u003d null) {\n        // This is a DELETE_BLOCK request\n        DatanodeStorageInfo storageInfo \u003d rbi.getStorageInfo();\n        removeStoredBlock(getStoredBlock(rbi.getBlock()),\n            storageInfo.getDatanodeDescriptor());\n      } else {\n        processAndHandleReportedBlock(rbi.getStorageInfo(),\n            rbi.getBlock(), rbi.getReportedState(), null);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "6bacaa9a5233cbad7f311ccd9d8f8dc9375c732d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7936. Erasure coding: resolving conflicts in the branch when merging trunk changes (this commit is for HDFS-8327 and HDFS-8357). Contributed by Zhe Zhang.\n",
      "commitDate": "26/05/15 12:01 PM",
      "commitName": "6bacaa9a5233cbad7f311ccd9d8f8dc9375c732d",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "26/05/15 12:01 PM",
      "commitNameOld": "51ea117f883f9c049de58987dc66e07e71a68ee4",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,17 @@\n   private void processQueuedMessages(Iterable\u003cReportedBlockInfo\u003e rbis)\n       throws IOException {\n     for (ReportedBlockInfo rbi : rbis) {\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Processing previouly queued message \" + rbi);\n       }\n       if (rbi.getReportedState() \u003d\u003d null) {\n         // This is a DELETE_BLOCK request\n         DatanodeStorageInfo storageInfo \u003d rbi.getStorageInfo();\n-        removeStoredBlock(rbi.getBlock(),\n+        removeStoredBlock(getStoredBlock(rbi.getBlock()),\n             storageInfo.getDatanodeDescriptor());\n       } else {\n         processAndHandleReportedBlock(rbi.getStorageInfo(),\n             rbi.getBlock(), rbi.getReportedState(), null);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void processQueuedMessages(Iterable\u003cReportedBlockInfo\u003e rbis)\n      throws IOException {\n    for (ReportedBlockInfo rbi : rbis) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Processing previouly queued message \" + rbi);\n      }\n      if (rbi.getReportedState() \u003d\u003d null) {\n        // This is a DELETE_BLOCK request\n        DatanodeStorageInfo storageInfo \u003d rbi.getStorageInfo();\n        removeStoredBlock(getStoredBlock(rbi.getBlock()),\n            storageInfo.getDatanodeDescriptor());\n      } else {\n        processAndHandleReportedBlock(rbi.getStorageInfo(),\n            rbi.getBlock(), rbi.getReportedState(), null);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "2d4ae3d18bc530fa9f81ee616db8af3395705fb9": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8245. Standby namenode doesn\u0027t process DELETED_BLOCK if the addblock request is in edit log. Contributed by Rushabh S Shah.\n",
      "commitDate": "08/05/15 2:36 PM",
      "commitName": "2d4ae3d18bc530fa9f81ee616db8af3395705fb9",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "07/05/15 11:36 AM",
      "commitNameOld": "f9427f1760cce7e0befc3e066cebd0912652a411",
      "commitAuthorOld": "Tsz-Wo Nicholas Sze",
      "daysBetweenCommits": 1.13,
      "commitsBetweenForRepo": 60,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,10 +1,17 @@\n   private void processQueuedMessages(Iterable\u003cReportedBlockInfo\u003e rbis)\n       throws IOException {\n     for (ReportedBlockInfo rbi : rbis) {\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Processing previouly queued message \" + rbi);\n       }\n-      processAndHandleReportedBlock(rbi.getStorageInfo(), \n-          rbi.getBlock(), rbi.getReportedState(), null);\n+      if (rbi.getReportedState() \u003d\u003d null) {\n+        // This is a DELETE_BLOCK request\n+        DatanodeStorageInfo storageInfo \u003d rbi.getStorageInfo();\n+        removeStoredBlock(rbi.getBlock(),\n+            storageInfo.getDatanodeDescriptor());\n+      } else {\n+        processAndHandleReportedBlock(rbi.getStorageInfo(),\n+            rbi.getBlock(), rbi.getReportedState(), null);\n+      }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void processQueuedMessages(Iterable\u003cReportedBlockInfo\u003e rbis)\n      throws IOException {\n    for (ReportedBlockInfo rbi : rbis) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Processing previouly queued message \" + rbi);\n      }\n      if (rbi.getReportedState() \u003d\u003d null) {\n        // This is a DELETE_BLOCK request\n        DatanodeStorageInfo storageInfo \u003d rbi.getStorageInfo();\n        removeStoredBlock(rbi.getBlock(),\n            storageInfo.getDatanodeDescriptor());\n      } else {\n        processAndHandleReportedBlock(rbi.getStorageInfo(),\n            rbi.getBlock(), rbi.getReportedState(), null);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "45db4d204b796eee6dd0e39d3cc94b70c47028d4": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6794. Update BlockManager methods to use DatanodeStorageInfo where possible. (Arpit Agarwal)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1615169 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "01/08/14 9:58 AM",
      "commitName": "45db4d204b796eee6dd0e39d3cc94b70c47028d4",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "31/07/14 6:05 PM",
      "commitNameOld": "b8597e6a10b2e8df1bee4e8ce0c8be345f7e007d",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 0.66,
      "commitsBetweenForRepo": 6,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,10 +1,10 @@\n   private void processQueuedMessages(Iterable\u003cReportedBlockInfo\u003e rbis)\n       throws IOException {\n     for (ReportedBlockInfo rbi : rbis) {\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Processing previouly queued message \" + rbi);\n       }\n-      processAndHandleReportedBlock(rbi.getNode(), rbi.getStorageID(), \n+      processAndHandleReportedBlock(rbi.getStorageInfo(), \n           rbi.getBlock(), rbi.getReportedState(), null);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void processQueuedMessages(Iterable\u003cReportedBlockInfo\u003e rbis)\n      throws IOException {\n    for (ReportedBlockInfo rbi : rbis) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Processing previouly queued message \" + rbi);\n      }\n      processAndHandleReportedBlock(rbi.getStorageInfo(), \n          rbi.getBlock(), rbi.getReportedState(), null);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "5d9d702607913685eab0d8ad077040ddc82bf085": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4987. Namenode changes to track multiple storages per datanode.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2832@1518087 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/08/13 11:30 PM",
      "commitName": "5d9d702607913685eab0d8ad077040ddc82bf085",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "05/08/13 1:48 PM",
      "commitNameOld": "ccdb978603696a91c4828a66aad27f585543b376",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 22.4,
      "commitsBetweenForRepo": 136,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,10 +1,10 @@\n   private void processQueuedMessages(Iterable\u003cReportedBlockInfo\u003e rbis)\n       throws IOException {\n     for (ReportedBlockInfo rbi : rbis) {\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Processing previouly queued message \" + rbi);\n       }\n-      processAndHandleReportedBlock(\n-          rbi.getNode(), rbi.getBlock(), rbi.getReportedState(), null);\n+      processAndHandleReportedBlock(rbi.getNode(), rbi.getStorageID(), \n+          rbi.getBlock(), rbi.getReportedState(), null);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void processQueuedMessages(Iterable\u003cReportedBlockInfo\u003e rbis)\n      throws IOException {\n    for (ReportedBlockInfo rbi : rbis) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Processing previouly queued message \" + rbi);\n      }\n      processAndHandleReportedBlock(rbi.getNode(), rbi.getStorageID(), \n          rbi.getBlock(), rbi.getReportedState(), null);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    }
  }
}