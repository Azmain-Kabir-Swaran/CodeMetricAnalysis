{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ClientServiceDelegate.java",
  "functionName": "getTaskDiagnostics",
  "functionId": "getTaskDiagnostics___arg0-org.apache.hadoop.mapreduce.TaskAttemptID",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/ClientServiceDelegate.java",
  "functionStartLine": 406,
  "functionEndLine": 422,
  "numCommitsSeen": 51,
  "timeTaken": 7560,
  "changeHistory": [
    "0d2bb0623696c2cc822cb44e431345b2c773dbff",
    "f2b91a8367a762091482074505618b570a520b19",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517"
  ],
  "changeHistoryShort": {
    "0d2bb0623696c2cc822cb44e431345b2c773dbff": "Ymodifierchange",
    "f2b91a8367a762091482074505618b570a520b19": "Ymultichange(Ymodifierchange,Ybodychange)",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yintroduced"
  },
  "changeHistoryDetails": {
    "0d2bb0623696c2cc822cb44e431345b2c773dbff": {
      "type": "Ymodifierchange",
      "commitMessage": "MAPREDUCE-3054. Unable to kill submitted jobs. (mahadev)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1176600 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/09/11 1:30 PM",
      "commitName": "0d2bb0623696c2cc822cb44e431345b2c773dbff",
      "commitAuthor": "Mahadev Konar",
      "commitDateOld": "25/09/11 7:46 AM",
      "commitNameOld": "a5c9ede1433871fcf4e2e802ee2a65950ecd1e72",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 2.24,
      "commitsBetweenForRepo": 13,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,17 @@\n-  String[] getTaskDiagnostics(org.apache.hadoop.mapreduce.TaskAttemptID arg0)\n+  public String[] getTaskDiagnostics(org.apache.hadoop.mapreduce.TaskAttemptID arg0)\n       throws IOException, InterruptedException {\n \n     org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId attemptID \u003d TypeConverter\n         .toYarn(arg0);\n     GetDiagnosticsRequest request \u003d recordFactory\n         .newRecordInstance(GetDiagnosticsRequest.class);\n     request.setTaskAttemptId(attemptID);\n     List\u003cString\u003e list \u003d ((GetDiagnosticsResponse) invoke(\"getDiagnostics\",\n         GetDiagnosticsRequest.class, request)).getDiagnosticsList();\n     String[] result \u003d new String[list.size()];\n     int i \u003d 0;\n     for (String c : list) {\n       result[i++] \u003d c.toString();\n     }\n     return result;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public String[] getTaskDiagnostics(org.apache.hadoop.mapreduce.TaskAttemptID arg0)\n      throws IOException, InterruptedException {\n\n    org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId attemptID \u003d TypeConverter\n        .toYarn(arg0);\n    GetDiagnosticsRequest request \u003d recordFactory\n        .newRecordInstance(GetDiagnosticsRequest.class);\n    request.setTaskAttemptId(attemptID);\n    List\u003cString\u003e list \u003d ((GetDiagnosticsResponse) invoke(\"getDiagnostics\",\n        GetDiagnosticsRequest.class, request)).getDiagnosticsList();\n    String[] result \u003d new String[list.size()];\n    int i \u003d 0;\n    for (String c : list) {\n      result[i++] \u003d c.toString();\n    }\n    return result;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/ClientServiceDelegate.java",
      "extendedDetails": {
        "oldValue": "[]",
        "newValue": "[public]"
      }
    },
    "f2b91a8367a762091482074505618b570a520b19": {
      "type": "Ymultichange(Ymodifierchange,Ybodychange)",
      "commitMessage": " MAPREDUCE-2807. Fix AM restart and client redirection. Contributed by Sharad Agarwal.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161408 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 11:35 PM",
      "commitName": "f2b91a8367a762091482074505618b570a520b19",
      "commitAuthor": "Sharad Agarwal",
      "subchanges": [
        {
          "type": "Ymodifierchange",
          "commitMessage": " MAPREDUCE-2807. Fix AM restart and client redirection. Contributed by Sharad Agarwal.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161408 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "24/08/11 11:35 PM",
          "commitName": "f2b91a8367a762091482074505618b570a520b19",
          "commitAuthor": "Sharad Agarwal",
          "commitDateOld": "24/08/11 5:14 PM",
          "commitNameOld": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
          "commitAuthorOld": "Arun Murthy",
          "daysBetweenCommits": 0.26,
          "commitsBetweenForRepo": 2,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,39 +1,17 @@\n-  public String[] getTaskDiagnostics(org.apache.hadoop.mapreduce.TaskAttemptID\n-      arg0)\n-  throws IOException,\n-  InterruptedException {\n+  String[] getTaskDiagnostics(org.apache.hadoop.mapreduce.TaskAttemptID arg0)\n+      throws IOException, InterruptedException {\n \n-    List\u003cString\u003e list \u003d null;\n-    org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId attemptID \u003d TypeConverter.toYarn(arg0);\n-    GetDiagnosticsRequest request \u003d recordFactory.newRecordInstance(GetDiagnosticsRequest.class);\n-    MRClientProtocol protocol;\n-    try {\n-      request.setTaskAttemptId(attemptID);\n-      protocol \u003d getProxy(arg0.getJobID());\n-      if (protocol \u003d\u003d null) {\n-        return new String[0];\n-      }\n-      list \u003d getProxy(arg0.getJobID()).getDiagnostics(request).getDiagnosticsList();\n-    } catch(YarnRemoteException yre) {//thrown by remote server, no need to redirect\n-      LOG.warn(RPCUtil.toString(yre));\n-      throw yre;\n-    } catch(Exception e) {\n-      LOG.debug(\"Failed to contact application master \", e);\n-      try {\n-        protocol \u003d getRefreshedProxy(arg0.getJobID());\n-        if (protocol \u003d\u003d null) {\n-          return new String[0];\n-        }\n-        list \u003d protocol.getDiagnostics(request).getDiagnosticsList();\n-      } catch(YarnRemoteException yre) {\n-        LOG.warn(RPCUtil.toString(yre));\n-        throw yre;\n-      }\n-    }\n+    org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId attemptID \u003d TypeConverter\n+        .toYarn(arg0);\n+    GetDiagnosticsRequest request \u003d recordFactory\n+        .newRecordInstance(GetDiagnosticsRequest.class);\n+    request.setTaskAttemptId(attemptID);\n+    List\u003cString\u003e list \u003d ((GetDiagnosticsResponse) invoke(\"getDiagnostics\",\n+        GetDiagnosticsRequest.class, request)).getDiagnosticsList();\n     String[] result \u003d new String[list.size()];\n     int i \u003d 0;\n     for (String c : list) {\n       result[i++] \u003d c.toString();\n     }\n     return result;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  String[] getTaskDiagnostics(org.apache.hadoop.mapreduce.TaskAttemptID arg0)\n      throws IOException, InterruptedException {\n\n    org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId attemptID \u003d TypeConverter\n        .toYarn(arg0);\n    GetDiagnosticsRequest request \u003d recordFactory\n        .newRecordInstance(GetDiagnosticsRequest.class);\n    request.setTaskAttemptId(attemptID);\n    List\u003cString\u003e list \u003d ((GetDiagnosticsResponse) invoke(\"getDiagnostics\",\n        GetDiagnosticsRequest.class, request)).getDiagnosticsList();\n    String[] result \u003d new String[list.size()];\n    int i \u003d 0;\n    for (String c : list) {\n      result[i++] \u003d c.toString();\n    }\n    return result;\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/ClientServiceDelegate.java",
          "extendedDetails": {
            "oldValue": "[public]",
            "newValue": "[]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": " MAPREDUCE-2807. Fix AM restart and client redirection. Contributed by Sharad Agarwal.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161408 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "24/08/11 11:35 PM",
          "commitName": "f2b91a8367a762091482074505618b570a520b19",
          "commitAuthor": "Sharad Agarwal",
          "commitDateOld": "24/08/11 5:14 PM",
          "commitNameOld": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
          "commitAuthorOld": "Arun Murthy",
          "daysBetweenCommits": 0.26,
          "commitsBetweenForRepo": 2,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,39 +1,17 @@\n-  public String[] getTaskDiagnostics(org.apache.hadoop.mapreduce.TaskAttemptID\n-      arg0)\n-  throws IOException,\n-  InterruptedException {\n+  String[] getTaskDiagnostics(org.apache.hadoop.mapreduce.TaskAttemptID arg0)\n+      throws IOException, InterruptedException {\n \n-    List\u003cString\u003e list \u003d null;\n-    org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId attemptID \u003d TypeConverter.toYarn(arg0);\n-    GetDiagnosticsRequest request \u003d recordFactory.newRecordInstance(GetDiagnosticsRequest.class);\n-    MRClientProtocol protocol;\n-    try {\n-      request.setTaskAttemptId(attemptID);\n-      protocol \u003d getProxy(arg0.getJobID());\n-      if (protocol \u003d\u003d null) {\n-        return new String[0];\n-      }\n-      list \u003d getProxy(arg0.getJobID()).getDiagnostics(request).getDiagnosticsList();\n-    } catch(YarnRemoteException yre) {//thrown by remote server, no need to redirect\n-      LOG.warn(RPCUtil.toString(yre));\n-      throw yre;\n-    } catch(Exception e) {\n-      LOG.debug(\"Failed to contact application master \", e);\n-      try {\n-        protocol \u003d getRefreshedProxy(arg0.getJobID());\n-        if (protocol \u003d\u003d null) {\n-          return new String[0];\n-        }\n-        list \u003d protocol.getDiagnostics(request).getDiagnosticsList();\n-      } catch(YarnRemoteException yre) {\n-        LOG.warn(RPCUtil.toString(yre));\n-        throw yre;\n-      }\n-    }\n+    org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId attemptID \u003d TypeConverter\n+        .toYarn(arg0);\n+    GetDiagnosticsRequest request \u003d recordFactory\n+        .newRecordInstance(GetDiagnosticsRequest.class);\n+    request.setTaskAttemptId(attemptID);\n+    List\u003cString\u003e list \u003d ((GetDiagnosticsResponse) invoke(\"getDiagnostics\",\n+        GetDiagnosticsRequest.class, request)).getDiagnosticsList();\n     String[] result \u003d new String[list.size()];\n     int i \u003d 0;\n     for (String c : list) {\n       result[i++] \u003d c.toString();\n     }\n     return result;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  String[] getTaskDiagnostics(org.apache.hadoop.mapreduce.TaskAttemptID arg0)\n      throws IOException, InterruptedException {\n\n    org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId attemptID \u003d TypeConverter\n        .toYarn(arg0);\n    GetDiagnosticsRequest request \u003d recordFactory\n        .newRecordInstance(GetDiagnosticsRequest.class);\n    request.setTaskAttemptId(attemptID);\n    List\u003cString\u003e list \u003d ((GetDiagnosticsResponse) invoke(\"getDiagnostics\",\n        GetDiagnosticsRequest.class, request)).getDiagnosticsList();\n    String[] result \u003d new String[list.size()];\n    int i \u003d 0;\n    for (String c : list) {\n      result[i++] \u003d c.toString();\n    }\n    return result;\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/ClientServiceDelegate.java",
          "extendedDetails": {}
        }
      ]
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public String[] getTaskDiagnostics(org.apache.hadoop.mapreduce.TaskAttemptID\n      arg0)\n  throws IOException,\n  InterruptedException {\n\n    List\u003cString\u003e list \u003d null;\n    org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId attemptID \u003d TypeConverter.toYarn(arg0);\n    GetDiagnosticsRequest request \u003d recordFactory.newRecordInstance(GetDiagnosticsRequest.class);\n    MRClientProtocol protocol;\n    try {\n      request.setTaskAttemptId(attemptID);\n      protocol \u003d getProxy(arg0.getJobID());\n      if (protocol \u003d\u003d null) {\n        return new String[0];\n      }\n      list \u003d getProxy(arg0.getJobID()).getDiagnostics(request).getDiagnosticsList();\n    } catch(YarnRemoteException yre) {//thrown by remote server, no need to redirect\n      LOG.warn(RPCUtil.toString(yre));\n      throw yre;\n    } catch(Exception e) {\n      LOG.debug(\"Failed to contact application master \", e);\n      try {\n        protocol \u003d getRefreshedProxy(arg0.getJobID());\n        if (protocol \u003d\u003d null) {\n          return new String[0];\n        }\n        list \u003d protocol.getDiagnostics(request).getDiagnosticsList();\n      } catch(YarnRemoteException yre) {\n        LOG.warn(RPCUtil.toString(yre));\n        throw yre;\n      }\n    }\n    String[] result \u003d new String[list.size()];\n    int i \u003d 0;\n    for (String c : list) {\n      result[i++] \u003d c.toString();\n    }\n    return result;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/ClientServiceDelegate.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/ClientServiceDelegate.java",
        "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/ClientServiceDelegate.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "diff": "@@ -0,0 +1,39 @@\n+  public String[] getTaskDiagnostics(org.apache.hadoop.mapreduce.TaskAttemptID\n+      arg0)\n+  throws IOException,\n+  InterruptedException {\n+\n+    List\u003cString\u003e list \u003d null;\n+    org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId attemptID \u003d TypeConverter.toYarn(arg0);\n+    GetDiagnosticsRequest request \u003d recordFactory.newRecordInstance(GetDiagnosticsRequest.class);\n+    MRClientProtocol protocol;\n+    try {\n+      request.setTaskAttemptId(attemptID);\n+      protocol \u003d getProxy(arg0.getJobID());\n+      if (protocol \u003d\u003d null) {\n+        return new String[0];\n+      }\n+      list \u003d getProxy(arg0.getJobID()).getDiagnostics(request).getDiagnosticsList();\n+    } catch(YarnRemoteException yre) {//thrown by remote server, no need to redirect\n+      LOG.warn(RPCUtil.toString(yre));\n+      throw yre;\n+    } catch(Exception e) {\n+      LOG.debug(\"Failed to contact application master \", e);\n+      try {\n+        protocol \u003d getRefreshedProxy(arg0.getJobID());\n+        if (protocol \u003d\u003d null) {\n+          return new String[0];\n+        }\n+        list \u003d protocol.getDiagnostics(request).getDiagnosticsList();\n+      } catch(YarnRemoteException yre) {\n+        LOG.warn(RPCUtil.toString(yre));\n+        throw yre;\n+      }\n+    }\n+    String[] result \u003d new String[list.size()];\n+    int i \u003d 0;\n+    for (String c : list) {\n+      result[i++] \u003d c.toString();\n+    }\n+    return result;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public String[] getTaskDiagnostics(org.apache.hadoop.mapreduce.TaskAttemptID\n      arg0)\n  throws IOException,\n  InterruptedException {\n\n    List\u003cString\u003e list \u003d null;\n    org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId attemptID \u003d TypeConverter.toYarn(arg0);\n    GetDiagnosticsRequest request \u003d recordFactory.newRecordInstance(GetDiagnosticsRequest.class);\n    MRClientProtocol protocol;\n    try {\n      request.setTaskAttemptId(attemptID);\n      protocol \u003d getProxy(arg0.getJobID());\n      if (protocol \u003d\u003d null) {\n        return new String[0];\n      }\n      list \u003d getProxy(arg0.getJobID()).getDiagnostics(request).getDiagnosticsList();\n    } catch(YarnRemoteException yre) {//thrown by remote server, no need to redirect\n      LOG.warn(RPCUtil.toString(yre));\n      throw yre;\n    } catch(Exception e) {\n      LOG.debug(\"Failed to contact application master \", e);\n      try {\n        protocol \u003d getRefreshedProxy(arg0.getJobID());\n        if (protocol \u003d\u003d null) {\n          return new String[0];\n        }\n        list \u003d protocol.getDiagnostics(request).getDiagnosticsList();\n      } catch(YarnRemoteException yre) {\n        LOG.warn(RPCUtil.toString(yre));\n        throw yre;\n      }\n    }\n    String[] result \u003d new String[list.size()];\n    int i \u003d 0;\n    for (String c : list) {\n      result[i++] \u003d c.toString();\n    }\n    return result;\n  }",
      "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/ClientServiceDelegate.java"
    }
  }
}