{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "StandbyCheckpointer.java",
  "functionName": "getHttpAddress",
  "functionId": "getHttpAddress___conf-Configuration",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ha/StandbyCheckpointer.java",
  "functionStartLine": 156,
  "functionEndLine": 161,
  "numCommitsSeen": 37,
  "timeTaken": 2749,
  "changeHistory": [
    "65a941008d4bbf906772399d3f035f2a0da5abfa",
    "aa4b6fbe754ab7e3cf8ee106598d550f6e14783e",
    "045dc880e13271737b3cf316296e92fb95806663",
    "675a7e4acba1417a80e1403b468c32efe597ba90",
    "5dbbe0e0a5d31689d3425e490865f95057dc051c",
    "32c313d51cd2483ea510afe044c55eeaed7c2b2d"
  ],
  "changeHistoryShort": {
    "65a941008d4bbf906772399d3f035f2a0da5abfa": "Ybodychange",
    "aa4b6fbe754ab7e3cf8ee106598d550f6e14783e": "Ybodychange",
    "045dc880e13271737b3cf316296e92fb95806663": "Ymultichange(Yreturntypechange,Ybodychange)",
    "675a7e4acba1417a80e1403b468c32efe597ba90": "Yexceptionschange",
    "5dbbe0e0a5d31689d3425e490865f95057dc051c": "Ybodychange",
    "32c313d51cd2483ea510afe044c55eeaed7c2b2d": "Yintroduced"
  },
  "changeHistoryDetails": {
    "65a941008d4bbf906772399d3f035f2a0da5abfa": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-10391. Always enable NameNode service RPC port. Contributed by Gergely Novak.\"\n\nThis reverts commit aa4b6fbe754ab7e3cf8ee106598d550f6e14783e.\n",
      "commitDate": "14/09/17 11:17 AM",
      "commitName": "65a941008d4bbf906772399d3f035f2a0da5abfa",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "09/09/17 8:40 AM",
      "commitNameOld": "aa4b6fbe754ab7e3cf8ee106598d550f6e14783e",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 5.11,
      "commitsBetweenForRepo": 81,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,6 +1,6 @@\n   private URL getHttpAddress(Configuration conf) throws IOException {\n     final String scheme \u003d DFSUtil.getHttpClientScheme(conf);\n-    String defaultHost \u003d NameNode.getServiceAddress(conf).getHostName();\n+    String defaultHost \u003d NameNode.getServiceAddress(conf, true).getHostName();\n     URI addr \u003d DFSUtil.getInfoServerWithDefaultHost(defaultHost, conf, scheme);\n     return addr.toURL();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private URL getHttpAddress(Configuration conf) throws IOException {\n    final String scheme \u003d DFSUtil.getHttpClientScheme(conf);\n    String defaultHost \u003d NameNode.getServiceAddress(conf, true).getHostName();\n    URI addr \u003d DFSUtil.getInfoServerWithDefaultHost(defaultHost, conf, scheme);\n    return addr.toURL();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ha/StandbyCheckpointer.java",
      "extendedDetails": {}
    },
    "aa4b6fbe754ab7e3cf8ee106598d550f6e14783e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10391. Always enable NameNode service RPC port. Contributed by Gergely Novak.\n",
      "commitDate": "09/09/17 8:40 AM",
      "commitName": "aa4b6fbe754ab7e3cf8ee106598d550f6e14783e",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "25/08/17 10:47 PM",
      "commitNameOld": "bb6a3c83305f97090f980c53adaaf37baf18c698",
      "commitAuthorOld": "Brahma Reddy Battula",
      "daysBetweenCommits": 14.41,
      "commitsBetweenForRepo": 159,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,6 +1,6 @@\n   private URL getHttpAddress(Configuration conf) throws IOException {\n     final String scheme \u003d DFSUtil.getHttpClientScheme(conf);\n-    String defaultHost \u003d NameNode.getServiceAddress(conf, true).getHostName();\n+    String defaultHost \u003d NameNode.getServiceAddress(conf).getHostName();\n     URI addr \u003d DFSUtil.getInfoServerWithDefaultHost(defaultHost, conf, scheme);\n     return addr.toURL();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private URL getHttpAddress(Configuration conf) throws IOException {\n    final String scheme \u003d DFSUtil.getHttpClientScheme(conf);\n    String defaultHost \u003d NameNode.getServiceAddress(conf).getHostName();\n    URI addr \u003d DFSUtil.getInfoServerWithDefaultHost(defaultHost, conf, scheme);\n    return addr.toURL();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ha/StandbyCheckpointer.java",
      "extendedDetails": {}
    },
    "045dc880e13271737b3cf316296e92fb95806663": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-5312. Generate HTTP/HTTPS URL in DFSUtil#getInfoServer() based on the configured http policy. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1548629 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "06/12/13 10:01 AM",
      "commitName": "045dc880e13271737b3cf316296e92fb95806663",
      "commitAuthor": "Jing Zhao",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-5312. Generate HTTP/HTTPS URL in DFSUtil#getInfoServer() based on the configured http policy. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1548629 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "06/12/13 10:01 AM",
          "commitName": "045dc880e13271737b3cf316296e92fb95806663",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "14/08/13 4:32 PM",
          "commitNameOld": "49a892056df7d73207f7a65ae5b4b905ba5e6ab8",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 113.77,
          "commitsBetweenForRepo": 707,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,14 +1,6 @@\n-  private String getHttpAddress(Configuration conf) throws IOException {\n-    String configuredAddr \u003d DFSUtil.getInfoServer(null, conf, false);\n-    \n-    // Use the hostname from the RPC address as a default, in case\n-    // the HTTP address is configured to 0.0.0.0.\n-    String hostnameFromRpc \u003d NameNode.getServiceAddress(\n-        conf, true).getHostName();\n-    try {\n-      return DFSUtil.substituteForWildcardAddress(\n-          configuredAddr, hostnameFromRpc);\n-    } catch (IOException e) {\n-      throw new IllegalArgumentException(e);\n-    }\n+  private URL getHttpAddress(Configuration conf) throws IOException {\n+    final String scheme \u003d DFSUtil.getHttpClientScheme(conf);\n+    String defaultHost \u003d NameNode.getServiceAddress(conf, true).getHostName();\n+    URI addr \u003d DFSUtil.getInfoServerWithDefaultHost(defaultHost, conf, scheme);\n+    return addr.toURL();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private URL getHttpAddress(Configuration conf) throws IOException {\n    final String scheme \u003d DFSUtil.getHttpClientScheme(conf);\n    String defaultHost \u003d NameNode.getServiceAddress(conf, true).getHostName();\n    URI addr \u003d DFSUtil.getInfoServerWithDefaultHost(defaultHost, conf, scheme);\n    return addr.toURL();\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ha/StandbyCheckpointer.java",
          "extendedDetails": {
            "oldValue": "String",
            "newValue": "URL"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5312. Generate HTTP/HTTPS URL in DFSUtil#getInfoServer() based on the configured http policy. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1548629 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "06/12/13 10:01 AM",
          "commitName": "045dc880e13271737b3cf316296e92fb95806663",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "14/08/13 4:32 PM",
          "commitNameOld": "49a892056df7d73207f7a65ae5b4b905ba5e6ab8",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 113.77,
          "commitsBetweenForRepo": 707,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,14 +1,6 @@\n-  private String getHttpAddress(Configuration conf) throws IOException {\n-    String configuredAddr \u003d DFSUtil.getInfoServer(null, conf, false);\n-    \n-    // Use the hostname from the RPC address as a default, in case\n-    // the HTTP address is configured to 0.0.0.0.\n-    String hostnameFromRpc \u003d NameNode.getServiceAddress(\n-        conf, true).getHostName();\n-    try {\n-      return DFSUtil.substituteForWildcardAddress(\n-          configuredAddr, hostnameFromRpc);\n-    } catch (IOException e) {\n-      throw new IllegalArgumentException(e);\n-    }\n+  private URL getHttpAddress(Configuration conf) throws IOException {\n+    final String scheme \u003d DFSUtil.getHttpClientScheme(conf);\n+    String defaultHost \u003d NameNode.getServiceAddress(conf, true).getHostName();\n+    URI addr \u003d DFSUtil.getInfoServerWithDefaultHost(defaultHost, conf, scheme);\n+    return addr.toURL();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private URL getHttpAddress(Configuration conf) throws IOException {\n    final String scheme \u003d DFSUtil.getHttpClientScheme(conf);\n    String defaultHost \u003d NameNode.getServiceAddress(conf, true).getHostName();\n    URI addr \u003d DFSUtil.getInfoServerWithDefaultHost(defaultHost, conf, scheme);\n    return addr.toURL();\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ha/StandbyCheckpointer.java",
          "extendedDetails": {}
        }
      ]
    },
    "675a7e4acba1417a80e1403b468c32efe597ba90": {
      "type": "Yexceptionschange",
      "commitMessage": "HDFS-3484. hdfs fsck doesn\u0027t work if NN HTTP address is set to 0.0.0.0 even if NN RPC address is configured. Contributed by Aaron T. Myers\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1344908 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "31/05/12 2:02 PM",
      "commitName": "675a7e4acba1417a80e1403b468c32efe597ba90",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "17/05/12 10:49 AM",
      "commitNameOld": "15ddb6634f8bdab37ce43f99f8338d84422c7232",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 14.13,
      "commitsBetweenForRepo": 58,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,14 @@\n-  private String getHttpAddress(Configuration conf) {\n+  private String getHttpAddress(Configuration conf) throws IOException {\n     String configuredAddr \u003d DFSUtil.getInfoServer(null, conf, false);\n     \n     // Use the hostname from the RPC address as a default, in case\n     // the HTTP address is configured to 0.0.0.0.\n     String hostnameFromRpc \u003d NameNode.getServiceAddress(\n         conf, true).getHostName();\n     try {\n       return DFSUtil.substituteForWildcardAddress(\n           configuredAddr, hostnameFromRpc);\n     } catch (IOException e) {\n       throw new IllegalArgumentException(e);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private String getHttpAddress(Configuration conf) throws IOException {\n    String configuredAddr \u003d DFSUtil.getInfoServer(null, conf, false);\n    \n    // Use the hostname from the RPC address as a default, in case\n    // the HTTP address is configured to 0.0.0.0.\n    String hostnameFromRpc \u003d NameNode.getServiceAddress(\n        conf, true).getHostName();\n    try {\n      return DFSUtil.substituteForWildcardAddress(\n          configuredAddr, hostnameFromRpc);\n    } catch (IOException e) {\n      throw new IllegalArgumentException(e);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ha/StandbyCheckpointer.java",
      "extendedDetails": {
        "oldValue": "[]",
        "newValue": "[IOException]"
      }
    },
    "5dbbe0e0a5d31689d3425e490865f95057dc051c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2617. Replaced Kerberized SSL for image transfer and fsck with SPNEGO-based solution. Contributed by Jakob Homan, Alejandro Abdelnur, and Aaron T. Myers\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1334216 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/05/12 2:58 PM",
      "commitName": "5dbbe0e0a5d31689d3425e490865f95057dc051c",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "28/02/12 5:09 PM",
      "commitNameOld": "978a8050e28b2afb193a3e00d82a8475fa4d2428",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 65.87,
      "commitsBetweenForRepo": 480,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,14 @@\n   private String getHttpAddress(Configuration conf) {\n-    String configuredAddr \u003d DFSUtil.getInfoServer(null, conf, true);\n+    String configuredAddr \u003d DFSUtil.getInfoServer(null, conf, false);\n     \n     // Use the hostname from the RPC address as a default, in case\n     // the HTTP address is configured to 0.0.0.0.\n     String hostnameFromRpc \u003d NameNode.getServiceAddress(\n         conf, true).getHostName();\n     try {\n       return DFSUtil.substituteForWildcardAddress(\n           configuredAddr, hostnameFromRpc);\n     } catch (IOException e) {\n       throw new IllegalArgumentException(e);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private String getHttpAddress(Configuration conf) {\n    String configuredAddr \u003d DFSUtil.getInfoServer(null, conf, false);\n    \n    // Use the hostname from the RPC address as a default, in case\n    // the HTTP address is configured to 0.0.0.0.\n    String hostnameFromRpc \u003d NameNode.getServiceAddress(\n        conf, true).getHostName();\n    try {\n      return DFSUtil.substituteForWildcardAddress(\n          configuredAddr, hostnameFromRpc);\n    } catch (IOException e) {\n      throw new IllegalArgumentException(e);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ha/StandbyCheckpointer.java",
      "extendedDetails": {}
    },
    "32c313d51cd2483ea510afe044c55eeaed7c2b2d": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-2861. checkpointing should verify that the dfs.http.address has been configured to a non-loopback for peer NN. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1239886 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/02/12 2:21 PM",
      "commitName": "32c313d51cd2483ea510afe044c55eeaed7c2b2d",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,14 @@\n+  private String getHttpAddress(Configuration conf) {\n+    String configuredAddr \u003d DFSUtil.getInfoServer(null, conf, true);\n+    \n+    // Use the hostname from the RPC address as a default, in case\n+    // the HTTP address is configured to 0.0.0.0.\n+    String hostnameFromRpc \u003d NameNode.getServiceAddress(\n+        conf, true).getHostName();\n+    try {\n+      return DFSUtil.substituteForWildcardAddress(\n+          configuredAddr, hostnameFromRpc);\n+    } catch (IOException e) {\n+      throw new IllegalArgumentException(e);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private String getHttpAddress(Configuration conf) {\n    String configuredAddr \u003d DFSUtil.getInfoServer(null, conf, true);\n    \n    // Use the hostname from the RPC address as a default, in case\n    // the HTTP address is configured to 0.0.0.0.\n    String hostnameFromRpc \u003d NameNode.getServiceAddress(\n        conf, true).getHostName();\n    try {\n      return DFSUtil.substituteForWildcardAddress(\n          configuredAddr, hostnameFromRpc);\n    } catch (IOException e) {\n      throw new IllegalArgumentException(e);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ha/StandbyCheckpointer.java"
    }
  }
}