{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FileSystemApplicationHistoryStore.java",
  "functionName": "getContainers",
  "functionId": "getContainers___appAttemptId-ApplicationAttemptId",
  "sourceFilePath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/applicationhistoryservice/FileSystemApplicationHistoryStore.java",
  "functionStartLine": 373,
  "functionEndLine": 413,
  "numCommitsSeen": 16,
  "timeTaken": 2202,
  "changeHistory": [
    "4174b9756c8c7877797545c4356b1f40df603ec5",
    "c77a1095dc556e8bea87df6d8ddf36e898f27e86",
    "8314674947ec087899d2515ae6b668c6c39cabbd",
    "0185a5784712d9b6e23d9d8c7624cd4e4886cab8",
    "cbee889711eddc5c67a61df4a6531b4ab3cd205a"
  ],
  "changeHistoryShort": {
    "4174b9756c8c7877797545c4356b1f40df603ec5": "Ybodychange",
    "c77a1095dc556e8bea87df6d8ddf36e898f27e86": "Ybodychange",
    "8314674947ec087899d2515ae6b668c6c39cabbd": "Ybodychange",
    "0185a5784712d9b6e23d9d8c7624cd4e4886cab8": "Ybodychange",
    "cbee889711eddc5c67a61df4a6531b4ab3cd205a": "Yintroduced"
  },
  "changeHistoryDetails": {
    "4174b9756c8c7877797545c4356b1f40df603ec5": {
      "type": "Ybodychange",
      "commitMessage": "YARN-5642. Typos in 9 log messages. Contributed by Mehran Hassani\n",
      "commitDate": "16/09/16 10:05 PM",
      "commitName": "4174b9756c8c7877797545c4356b1f40df603ec5",
      "commitAuthor": "Naganarasimha",
      "commitDateOld": "14/06/16 3:06 PM",
      "commitNameOld": "c77a1095dc556e8bea87df6d8ddf36e898f27e86",
      "commitAuthorOld": "Wangda Tan",
      "daysBetweenCommits": 94.29,
      "commitsBetweenForRepo": 741,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,41 +1,41 @@\n   public Map\u003cContainerId, ContainerHistoryData\u003e getContainers(\n       ApplicationAttemptId appAttemptId) throws IOException {\n     Map\u003cContainerId, ContainerHistoryData\u003e historyDataMap \u003d\n         new HashMap\u003cContainerId, ContainerHistoryData\u003e();\n     HistoryFileReader hfReader \u003d\n         getHistoryFileReader(appAttemptId.getApplicationId());\n     try {\n       while (hfReader.hasNext()) {\n         HistoryFileReader.Entry entry \u003d hfReader.next();\n         if (entry.key.id.startsWith(ConverterUtils.CONTAINER_PREFIX)) {\n           ContainerId containerId \u003d\n               ContainerId.fromString(entry.key.id);\n           if (containerId.getApplicationAttemptId().equals(appAttemptId)) {\n             ContainerHistoryData historyData \u003d\n                 historyDataMap.get(containerId);\n             if (historyData \u003d\u003d null) {\n               historyData \u003d ContainerHistoryData.newInstance(\n                   containerId, null, null, null, Long.MIN_VALUE,\n                   Long.MAX_VALUE, null, Integer.MAX_VALUE, null);\n               historyDataMap.put(containerId, historyData);\n             }\n             if (entry.key.suffix.equals(START_DATA_SUFFIX)) {\n               mergeContainerHistoryData(historyData,\n                   parseContainerStartData(entry.value));\n             } else if (entry.key.suffix.equals(FINISH_DATA_SUFFIX)) {\n               mergeContainerHistoryData(historyData,\n                   parseContainerFinishData(entry.value));\n             }\n           }\n         }\n       }\n-      LOG.info(\"Completed reading history information of all conatiners\"\n+      LOG.info(\"Completed reading history information of all containers\"\n           + \" of application attempt \" + appAttemptId);\n     } catch (IOException e) {\n       LOG.info(\"Error when reading history information of some containers\"\n           + \" of application attempt \" + appAttemptId);\n     } finally {\n       hfReader.close();\n     }\n     return historyDataMap;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public Map\u003cContainerId, ContainerHistoryData\u003e getContainers(\n      ApplicationAttemptId appAttemptId) throws IOException {\n    Map\u003cContainerId, ContainerHistoryData\u003e historyDataMap \u003d\n        new HashMap\u003cContainerId, ContainerHistoryData\u003e();\n    HistoryFileReader hfReader \u003d\n        getHistoryFileReader(appAttemptId.getApplicationId());\n    try {\n      while (hfReader.hasNext()) {\n        HistoryFileReader.Entry entry \u003d hfReader.next();\n        if (entry.key.id.startsWith(ConverterUtils.CONTAINER_PREFIX)) {\n          ContainerId containerId \u003d\n              ContainerId.fromString(entry.key.id);\n          if (containerId.getApplicationAttemptId().equals(appAttemptId)) {\n            ContainerHistoryData historyData \u003d\n                historyDataMap.get(containerId);\n            if (historyData \u003d\u003d null) {\n              historyData \u003d ContainerHistoryData.newInstance(\n                  containerId, null, null, null, Long.MIN_VALUE,\n                  Long.MAX_VALUE, null, Integer.MAX_VALUE, null);\n              historyDataMap.put(containerId, historyData);\n            }\n            if (entry.key.suffix.equals(START_DATA_SUFFIX)) {\n              mergeContainerHistoryData(historyData,\n                  parseContainerStartData(entry.value));\n            } else if (entry.key.suffix.equals(FINISH_DATA_SUFFIX)) {\n              mergeContainerHistoryData(historyData,\n                  parseContainerFinishData(entry.value));\n            }\n          }\n        }\n      }\n      LOG.info(\"Completed reading history information of all containers\"\n          + \" of application attempt \" + appAttemptId);\n    } catch (IOException e) {\n      LOG.info(\"Error when reading history information of some containers\"\n          + \" of application attempt \" + appAttemptId);\n    } finally {\n      hfReader.close();\n    }\n    return historyDataMap;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/applicationhistoryservice/FileSystemApplicationHistoryStore.java",
      "extendedDetails": {}
    },
    "c77a1095dc556e8bea87df6d8ddf36e898f27e86": {
      "type": "Ybodychange",
      "commitMessage": "YARN-1942. Deprecate toString/fromString methods from ConverterUtils and move them to records classes like ContainerId/ApplicationId, etc. (wangda)\n",
      "commitDate": "14/06/16 3:06 PM",
      "commitName": "c77a1095dc556e8bea87df6d8ddf36e898f27e86",
      "commitAuthor": "Wangda Tan",
      "commitDateOld": "15/01/16 8:40 AM",
      "commitNameOld": "fc6d3a3b234efff2b0b646c31a4e6ff0a5118ef9",
      "commitAuthorOld": "Junping Du",
      "daysBetweenCommits": 151.23,
      "commitsBetweenForRepo": 980,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,41 +1,41 @@\n   public Map\u003cContainerId, ContainerHistoryData\u003e getContainers(\n       ApplicationAttemptId appAttemptId) throws IOException {\n     Map\u003cContainerId, ContainerHistoryData\u003e historyDataMap \u003d\n         new HashMap\u003cContainerId, ContainerHistoryData\u003e();\n     HistoryFileReader hfReader \u003d\n         getHistoryFileReader(appAttemptId.getApplicationId());\n     try {\n       while (hfReader.hasNext()) {\n         HistoryFileReader.Entry entry \u003d hfReader.next();\n         if (entry.key.id.startsWith(ConverterUtils.CONTAINER_PREFIX)) {\n           ContainerId containerId \u003d\n-              ConverterUtils.toContainerId(entry.key.id);\n+              ContainerId.fromString(entry.key.id);\n           if (containerId.getApplicationAttemptId().equals(appAttemptId)) {\n             ContainerHistoryData historyData \u003d\n                 historyDataMap.get(containerId);\n             if (historyData \u003d\u003d null) {\n               historyData \u003d ContainerHistoryData.newInstance(\n                   containerId, null, null, null, Long.MIN_VALUE,\n                   Long.MAX_VALUE, null, Integer.MAX_VALUE, null);\n               historyDataMap.put(containerId, historyData);\n             }\n             if (entry.key.suffix.equals(START_DATA_SUFFIX)) {\n               mergeContainerHistoryData(historyData,\n                   parseContainerStartData(entry.value));\n             } else if (entry.key.suffix.equals(FINISH_DATA_SUFFIX)) {\n               mergeContainerHistoryData(historyData,\n                   parseContainerFinishData(entry.value));\n             }\n           }\n         }\n       }\n       LOG.info(\"Completed reading history information of all conatiners\"\n           + \" of application attempt \" + appAttemptId);\n     } catch (IOException e) {\n       LOG.info(\"Error when reading history information of some containers\"\n           + \" of application attempt \" + appAttemptId);\n     } finally {\n       hfReader.close();\n     }\n     return historyDataMap;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public Map\u003cContainerId, ContainerHistoryData\u003e getContainers(\n      ApplicationAttemptId appAttemptId) throws IOException {\n    Map\u003cContainerId, ContainerHistoryData\u003e historyDataMap \u003d\n        new HashMap\u003cContainerId, ContainerHistoryData\u003e();\n    HistoryFileReader hfReader \u003d\n        getHistoryFileReader(appAttemptId.getApplicationId());\n    try {\n      while (hfReader.hasNext()) {\n        HistoryFileReader.Entry entry \u003d hfReader.next();\n        if (entry.key.id.startsWith(ConverterUtils.CONTAINER_PREFIX)) {\n          ContainerId containerId \u003d\n              ContainerId.fromString(entry.key.id);\n          if (containerId.getApplicationAttemptId().equals(appAttemptId)) {\n            ContainerHistoryData historyData \u003d\n                historyDataMap.get(containerId);\n            if (historyData \u003d\u003d null) {\n              historyData \u003d ContainerHistoryData.newInstance(\n                  containerId, null, null, null, Long.MIN_VALUE,\n                  Long.MAX_VALUE, null, Integer.MAX_VALUE, null);\n              historyDataMap.put(containerId, historyData);\n            }\n            if (entry.key.suffix.equals(START_DATA_SUFFIX)) {\n              mergeContainerHistoryData(historyData,\n                  parseContainerStartData(entry.value));\n            } else if (entry.key.suffix.equals(FINISH_DATA_SUFFIX)) {\n              mergeContainerHistoryData(historyData,\n                  parseContainerFinishData(entry.value));\n            }\n          }\n        }\n      }\n      LOG.info(\"Completed reading history information of all conatiners\"\n          + \" of application attempt \" + appAttemptId);\n    } catch (IOException e) {\n      LOG.info(\"Error when reading history information of some containers\"\n          + \" of application attempt \" + appAttemptId);\n    } finally {\n      hfReader.close();\n    }\n    return historyDataMap;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/applicationhistoryservice/FileSystemApplicationHistoryStore.java",
      "extendedDetails": {}
    },
    "8314674947ec087899d2515ae6b668c6c39cabbd": {
      "type": "Ybodychange",
      "commitMessage": "YARN-1685. Fixed few bugs related to handling of containers\u0027 log-URLs on ResourceManager and history-service. Contributed by Zhijie Shen.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1578602 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/03/14 2:36 PM",
      "commitName": "8314674947ec087899d2515ae6b668c6c39cabbd",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "22/02/14 6:04 PM",
      "commitNameOld": "e167e585e9dd5c86ae763c257d62fdcc83260200",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 22.81,
      "commitsBetweenForRepo": 200,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,41 +1,41 @@\n   public Map\u003cContainerId, ContainerHistoryData\u003e getContainers(\n       ApplicationAttemptId appAttemptId) throws IOException {\n     Map\u003cContainerId, ContainerHistoryData\u003e historyDataMap \u003d\n         new HashMap\u003cContainerId, ContainerHistoryData\u003e();\n     HistoryFileReader hfReader \u003d\n         getHistoryFileReader(appAttemptId.getApplicationId());\n     try {\n       while (hfReader.hasNext()) {\n         HistoryFileReader.Entry entry \u003d hfReader.next();\n         if (entry.key.id.startsWith(ConverterUtils.CONTAINER_PREFIX)) {\n           ContainerId containerId \u003d\n               ConverterUtils.toContainerId(entry.key.id);\n           if (containerId.getApplicationAttemptId().equals(appAttemptId)) {\n             ContainerHistoryData historyData \u003d\n                 historyDataMap.get(containerId);\n             if (historyData \u003d\u003d null) {\n               historyData \u003d ContainerHistoryData.newInstance(\n                   containerId, null, null, null, Long.MIN_VALUE,\n-                  Long.MAX_VALUE, null, null, Integer.MAX_VALUE, null);\n+                  Long.MAX_VALUE, null, Integer.MAX_VALUE, null);\n               historyDataMap.put(containerId, historyData);\n             }\n             if (entry.key.suffix.equals(START_DATA_SUFFIX)) {\n               mergeContainerHistoryData(historyData,\n                   parseContainerStartData(entry.value));\n             } else if (entry.key.suffix.equals(FINISH_DATA_SUFFIX)) {\n               mergeContainerHistoryData(historyData,\n                   parseContainerFinishData(entry.value));\n             }\n           }\n         }\n       }\n       LOG.info(\"Completed reading history information of all conatiners\"\n           + \" of application attempt \" + appAttemptId);\n     } catch (IOException e) {\n       LOG.info(\"Error when reading history information of some containers\"\n           + \" of application attempt \" + appAttemptId);\n     } finally {\n       hfReader.close();\n     }\n     return historyDataMap;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public Map\u003cContainerId, ContainerHistoryData\u003e getContainers(\n      ApplicationAttemptId appAttemptId) throws IOException {\n    Map\u003cContainerId, ContainerHistoryData\u003e historyDataMap \u003d\n        new HashMap\u003cContainerId, ContainerHistoryData\u003e();\n    HistoryFileReader hfReader \u003d\n        getHistoryFileReader(appAttemptId.getApplicationId());\n    try {\n      while (hfReader.hasNext()) {\n        HistoryFileReader.Entry entry \u003d hfReader.next();\n        if (entry.key.id.startsWith(ConverterUtils.CONTAINER_PREFIX)) {\n          ContainerId containerId \u003d\n              ConverterUtils.toContainerId(entry.key.id);\n          if (containerId.getApplicationAttemptId().equals(appAttemptId)) {\n            ContainerHistoryData historyData \u003d\n                historyDataMap.get(containerId);\n            if (historyData \u003d\u003d null) {\n              historyData \u003d ContainerHistoryData.newInstance(\n                  containerId, null, null, null, Long.MIN_VALUE,\n                  Long.MAX_VALUE, null, Integer.MAX_VALUE, null);\n              historyDataMap.put(containerId, historyData);\n            }\n            if (entry.key.suffix.equals(START_DATA_SUFFIX)) {\n              mergeContainerHistoryData(historyData,\n                  parseContainerStartData(entry.value));\n            } else if (entry.key.suffix.equals(FINISH_DATA_SUFFIX)) {\n              mergeContainerHistoryData(historyData,\n                  parseContainerFinishData(entry.value));\n            }\n          }\n        }\n      }\n      LOG.info(\"Completed reading history information of all conatiners\"\n          + \" of application attempt \" + appAttemptId);\n    } catch (IOException e) {\n      LOG.info(\"Error when reading history information of some containers\"\n          + \" of application attempt \" + appAttemptId);\n    } finally {\n      hfReader.close();\n    }\n    return historyDataMap;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/applicationhistoryservice/FileSystemApplicationHistoryStore.java",
      "extendedDetails": {}
    },
    "0185a5784712d9b6e23d9d8c7624cd4e4886cab8": {
      "type": "Ybodychange",
      "commitMessage": "YARN-1578. Fixed reading incomplete application attempt and container data in FileSystemApplicationHistoryStore. Contributed by Shinichi Yamashita.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1567816 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/02/14 4:08 PM",
      "commitName": "0185a5784712d9b6e23d9d8c7624cd4e4886cab8",
      "commitAuthor": "Zhijie Shen",
      "commitDateOld": "25/01/14 8:51 PM",
      "commitNameOld": "cbee889711eddc5c67a61df4a6531b4ab3cd205a",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 17.8,
      "commitsBetweenForRepo": 145,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,41 +1,41 @@\n   public Map\u003cContainerId, ContainerHistoryData\u003e getContainers(\n       ApplicationAttemptId appAttemptId) throws IOException {\n     Map\u003cContainerId, ContainerHistoryData\u003e historyDataMap \u003d\n         new HashMap\u003cContainerId, ContainerHistoryData\u003e();\n-    Map\u003cContainerId, StartFinishDataPair\u003cContainerStartData, ContainerFinishData\u003e\u003e startFinshDataMap \u003d\n-        new HashMap\u003cContainerId, StartFinishDataPair\u003cContainerStartData, ContainerFinishData\u003e\u003e();\n     HistoryFileReader hfReader \u003d\n         getHistoryFileReader(appAttemptId.getApplicationId());\n     try {\n       while (hfReader.hasNext()) {\n         HistoryFileReader.Entry entry \u003d hfReader.next();\n         if (entry.key.id.startsWith(ConverterUtils.CONTAINER_PREFIX)) {\n-          if (entry.key.suffix.equals(START_DATA_SUFFIX)) {\n-            retrieveStartFinishData(appAttemptId, entry, startFinshDataMap,\n-              true);\n-          } else if (entry.key.suffix.equals(FINISH_DATA_SUFFIX)) {\n-            retrieveStartFinishData(appAttemptId, entry, startFinshDataMap,\n-              false);\n+          ContainerId containerId \u003d\n+              ConverterUtils.toContainerId(entry.key.id);\n+          if (containerId.getApplicationAttemptId().equals(appAttemptId)) {\n+            ContainerHistoryData historyData \u003d\n+                historyDataMap.get(containerId);\n+            if (historyData \u003d\u003d null) {\n+              historyData \u003d ContainerHistoryData.newInstance(\n+                  containerId, null, null, null, Long.MIN_VALUE,\n+                  Long.MAX_VALUE, null, null, Integer.MAX_VALUE, null);\n+              historyDataMap.put(containerId, historyData);\n+            }\n+            if (entry.key.suffix.equals(START_DATA_SUFFIX)) {\n+              mergeContainerHistoryData(historyData,\n+                  parseContainerStartData(entry.value));\n+            } else if (entry.key.suffix.equals(FINISH_DATA_SUFFIX)) {\n+              mergeContainerHistoryData(historyData,\n+                  parseContainerFinishData(entry.value));\n+            }\n           }\n         }\n       }\n       LOG.info(\"Completed reading history information of all conatiners\"\n           + \" of application attempt \" + appAttemptId);\n     } catch (IOException e) {\n       LOG.info(\"Error when reading history information of some containers\"\n           + \" of application attempt \" + appAttemptId);\n     } finally {\n       hfReader.close();\n     }\n-    for (Map.Entry\u003cContainerId, StartFinishDataPair\u003cContainerStartData, ContainerFinishData\u003e\u003e entry : startFinshDataMap\n-      .entrySet()) {\n-      ContainerHistoryData historyData \u003d\n-          ContainerHistoryData\n-            .newInstance(entry.getKey(), null, null, null, Long.MIN_VALUE,\n-              Long.MAX_VALUE, null, null, Integer.MAX_VALUE, null);\n-      mergeContainerHistoryData(historyData, entry.getValue().startData);\n-      mergeContainerHistoryData(historyData, entry.getValue().finishData);\n-      historyDataMap.put(entry.getKey(), historyData);\n-    }\n     return historyDataMap;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public Map\u003cContainerId, ContainerHistoryData\u003e getContainers(\n      ApplicationAttemptId appAttemptId) throws IOException {\n    Map\u003cContainerId, ContainerHistoryData\u003e historyDataMap \u003d\n        new HashMap\u003cContainerId, ContainerHistoryData\u003e();\n    HistoryFileReader hfReader \u003d\n        getHistoryFileReader(appAttemptId.getApplicationId());\n    try {\n      while (hfReader.hasNext()) {\n        HistoryFileReader.Entry entry \u003d hfReader.next();\n        if (entry.key.id.startsWith(ConverterUtils.CONTAINER_PREFIX)) {\n          ContainerId containerId \u003d\n              ConverterUtils.toContainerId(entry.key.id);\n          if (containerId.getApplicationAttemptId().equals(appAttemptId)) {\n            ContainerHistoryData historyData \u003d\n                historyDataMap.get(containerId);\n            if (historyData \u003d\u003d null) {\n              historyData \u003d ContainerHistoryData.newInstance(\n                  containerId, null, null, null, Long.MIN_VALUE,\n                  Long.MAX_VALUE, null, null, Integer.MAX_VALUE, null);\n              historyDataMap.put(containerId, historyData);\n            }\n            if (entry.key.suffix.equals(START_DATA_SUFFIX)) {\n              mergeContainerHistoryData(historyData,\n                  parseContainerStartData(entry.value));\n            } else if (entry.key.suffix.equals(FINISH_DATA_SUFFIX)) {\n              mergeContainerHistoryData(historyData,\n                  parseContainerFinishData(entry.value));\n            }\n          }\n        }\n      }\n      LOG.info(\"Completed reading history information of all conatiners\"\n          + \" of application attempt \" + appAttemptId);\n    } catch (IOException e) {\n      LOG.info(\"Error when reading history information of some containers\"\n          + \" of application attempt \" + appAttemptId);\n    } finally {\n      hfReader.close();\n    }\n    return historyDataMap;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/applicationhistoryservice/FileSystemApplicationHistoryStore.java",
      "extendedDetails": {}
    },
    "cbee889711eddc5c67a61df4a6531b4ab3cd205a": {
      "type": "Yintroduced",
      "commitMessage": "YARN-321. Merging YARN-321 branch to trunk.\nsvn merge ../branches/YARN-321\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1561452 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "25/01/14 8:51 PM",
      "commitName": "cbee889711eddc5c67a61df4a6531b4ab3cd205a",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "diff": "@@ -0,0 +1,41 @@\n+  public Map\u003cContainerId, ContainerHistoryData\u003e getContainers(\n+      ApplicationAttemptId appAttemptId) throws IOException {\n+    Map\u003cContainerId, ContainerHistoryData\u003e historyDataMap \u003d\n+        new HashMap\u003cContainerId, ContainerHistoryData\u003e();\n+    Map\u003cContainerId, StartFinishDataPair\u003cContainerStartData, ContainerFinishData\u003e\u003e startFinshDataMap \u003d\n+        new HashMap\u003cContainerId, StartFinishDataPair\u003cContainerStartData, ContainerFinishData\u003e\u003e();\n+    HistoryFileReader hfReader \u003d\n+        getHistoryFileReader(appAttemptId.getApplicationId());\n+    try {\n+      while (hfReader.hasNext()) {\n+        HistoryFileReader.Entry entry \u003d hfReader.next();\n+        if (entry.key.id.startsWith(ConverterUtils.CONTAINER_PREFIX)) {\n+          if (entry.key.suffix.equals(START_DATA_SUFFIX)) {\n+            retrieveStartFinishData(appAttemptId, entry, startFinshDataMap,\n+              true);\n+          } else if (entry.key.suffix.equals(FINISH_DATA_SUFFIX)) {\n+            retrieveStartFinishData(appAttemptId, entry, startFinshDataMap,\n+              false);\n+          }\n+        }\n+      }\n+      LOG.info(\"Completed reading history information of all conatiners\"\n+          + \" of application attempt \" + appAttemptId);\n+    } catch (IOException e) {\n+      LOG.info(\"Error when reading history information of some containers\"\n+          + \" of application attempt \" + appAttemptId);\n+    } finally {\n+      hfReader.close();\n+    }\n+    for (Map.Entry\u003cContainerId, StartFinishDataPair\u003cContainerStartData, ContainerFinishData\u003e\u003e entry : startFinshDataMap\n+      .entrySet()) {\n+      ContainerHistoryData historyData \u003d\n+          ContainerHistoryData\n+            .newInstance(entry.getKey(), null, null, null, Long.MIN_VALUE,\n+              Long.MAX_VALUE, null, null, Integer.MAX_VALUE, null);\n+      mergeContainerHistoryData(historyData, entry.getValue().startData);\n+      mergeContainerHistoryData(historyData, entry.getValue().finishData);\n+      historyDataMap.put(entry.getKey(), historyData);\n+    }\n+    return historyDataMap;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public Map\u003cContainerId, ContainerHistoryData\u003e getContainers(\n      ApplicationAttemptId appAttemptId) throws IOException {\n    Map\u003cContainerId, ContainerHistoryData\u003e historyDataMap \u003d\n        new HashMap\u003cContainerId, ContainerHistoryData\u003e();\n    Map\u003cContainerId, StartFinishDataPair\u003cContainerStartData, ContainerFinishData\u003e\u003e startFinshDataMap \u003d\n        new HashMap\u003cContainerId, StartFinishDataPair\u003cContainerStartData, ContainerFinishData\u003e\u003e();\n    HistoryFileReader hfReader \u003d\n        getHistoryFileReader(appAttemptId.getApplicationId());\n    try {\n      while (hfReader.hasNext()) {\n        HistoryFileReader.Entry entry \u003d hfReader.next();\n        if (entry.key.id.startsWith(ConverterUtils.CONTAINER_PREFIX)) {\n          if (entry.key.suffix.equals(START_DATA_SUFFIX)) {\n            retrieveStartFinishData(appAttemptId, entry, startFinshDataMap,\n              true);\n          } else if (entry.key.suffix.equals(FINISH_DATA_SUFFIX)) {\n            retrieveStartFinishData(appAttemptId, entry, startFinshDataMap,\n              false);\n          }\n        }\n      }\n      LOG.info(\"Completed reading history information of all conatiners\"\n          + \" of application attempt \" + appAttemptId);\n    } catch (IOException e) {\n      LOG.info(\"Error when reading history information of some containers\"\n          + \" of application attempt \" + appAttemptId);\n    } finally {\n      hfReader.close();\n    }\n    for (Map.Entry\u003cContainerId, StartFinishDataPair\u003cContainerStartData, ContainerFinishData\u003e\u003e entry : startFinshDataMap\n      .entrySet()) {\n      ContainerHistoryData historyData \u003d\n          ContainerHistoryData\n            .newInstance(entry.getKey(), null, null, null, Long.MIN_VALUE,\n              Long.MAX_VALUE, null, null, Integer.MAX_VALUE, null);\n      mergeContainerHistoryData(historyData, entry.getValue().startData);\n      mergeContainerHistoryData(historyData, entry.getValue().finishData);\n      historyDataMap.put(entry.getKey(), historyData);\n    }\n    return historyDataMap;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/applicationhistoryservice/FileSystemApplicationHistoryStore.java"
    }
  }
}