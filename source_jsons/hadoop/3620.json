{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DFSInputStream.java",
  "functionName": "seek",
  "functionId": "seek___targetPos-long",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
  "functionStartLine": 1591,
  "functionEndLine": 1634,
  "numCommitsSeen": 143,
  "timeTaken": 7960,
  "changeHistory": [
    "be34e85e682880f46eee0310bf00ecc7d39cd5bd",
    "39285e6a1978ea5e53bdc1b0aef62421382124a8",
    "6ee0539ede78b640f01c5eac18ded161182a7835",
    "d5a9a3daa0224249221ffa7b8bd5751ab2feca56",
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c",
    "a97a1e73177974cff8afafad6ca43a96563f3c61",
    "b6fbaba8e98d2da913cbe5474cab479cd4efd191",
    "ab96a0838dafbfea77382135914feadbfd03cf53",
    "9a4030e0e84a688c12daa21fe9a165808c3eca70",
    "ecbb41923cb4a51c09f346b39d554bb7bbc2384e",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "2c5dd549e31aa5d3377ff2619ede8e92b8dc5d0f",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "be34e85e682880f46eee0310bf00ecc7d39cd5bd": "Ybodychange",
    "39285e6a1978ea5e53bdc1b0aef62421382124a8": "Ybodychange",
    "6ee0539ede78b640f01c5eac18ded161182a7835": "Ybodychange",
    "d5a9a3daa0224249221ffa7b8bd5751ab2feca56": "Ybodychange",
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c": "Yfilerename",
    "a97a1e73177974cff8afafad6ca43a96563f3c61": "Ybodychange",
    "b6fbaba8e98d2da913cbe5474cab479cd4efd191": "Ybodychange",
    "ab96a0838dafbfea77382135914feadbfd03cf53": "Ybodychange",
    "9a4030e0e84a688c12daa21fe9a165808c3eca70": "Ybodychange",
    "ecbb41923cb4a51c09f346b39d554bb7bbc2384e": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "2c5dd549e31aa5d3377ff2619ede8e92b8dc5d0f": "Ybodychange",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "be34e85e682880f46eee0310bf00ecc7d39cd5bd": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10468. HDFS read ends up ignoring an interrupt. Contributed by Jing Zhao\n",
      "commitDate": "07/06/16 10:48 AM",
      "commitName": "be34e85e682880f46eee0310bf00ecc7d39cd5bd",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "25/04/16 12:01 PM",
      "commitNameOld": "f308561f1d885491b88db73ac63003202056d661",
      "commitAuthorOld": "Tsz-Wo Nicholas Sze",
      "daysBetweenCommits": 42.95,
      "commitsBetweenForRepo": 291,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,43 +1,44 @@\n   public synchronized void seek(long targetPos) throws IOException {\n     if (targetPos \u003e getFileLength()) {\n       throw new EOFException(\"Cannot seek after EOF\");\n     }\n     if (targetPos \u003c 0) {\n       throw new EOFException(\"Cannot seek to negative offset\");\n     }\n     if (closed.get()) {\n       throw new IOException(\"Stream is closed!\");\n     }\n     boolean done \u003d false;\n     if (pos \u003c\u003d targetPos \u0026\u0026 targetPos \u003c\u003d blockEnd) {\n       //\n       // If this seek is to a positive position in the current\n       // block, and this piece of data might already be lying in\n       // the TCP buffer, then just eat up the intervening data.\n       //\n       int diff \u003d (int)(targetPos - pos);\n       if (diff \u003c\u003d blockReader.available()) {\n         try {\n           pos +\u003d blockReader.skip(diff);\n           if (pos \u003d\u003d targetPos) {\n             done \u003d true;\n           } else {\n             // The range was already checked. If the block reader returns\n             // something unexpected instead of throwing an exception, it is\n             // most likely a bug.\n             String errMsg \u003d \"BlockReader failed to seek to \" +\n                 targetPos + \". Instead, it seeked to \" + pos + \".\";\n             DFSClient.LOG.warn(errMsg);\n             throw new IOException(errMsg);\n           }\n         } catch (IOException e) {//make following read to retry\n           DFSClient.LOG.debug(\"Exception while seek to {} from {} of {} from \"\n               + \"{}\", targetPos, getCurrentBlock(), src, currentNode, e);\n+          checkInterrupted(e);\n         }\n       }\n     }\n     if (!done) {\n       pos \u003d targetPos;\n       blockEnd \u003d -1;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void seek(long targetPos) throws IOException {\n    if (targetPos \u003e getFileLength()) {\n      throw new EOFException(\"Cannot seek after EOF\");\n    }\n    if (targetPos \u003c 0) {\n      throw new EOFException(\"Cannot seek to negative offset\");\n    }\n    if (closed.get()) {\n      throw new IOException(\"Stream is closed!\");\n    }\n    boolean done \u003d false;\n    if (pos \u003c\u003d targetPos \u0026\u0026 targetPos \u003c\u003d blockEnd) {\n      //\n      // If this seek is to a positive position in the current\n      // block, and this piece of data might already be lying in\n      // the TCP buffer, then just eat up the intervening data.\n      //\n      int diff \u003d (int)(targetPos - pos);\n      if (diff \u003c\u003d blockReader.available()) {\n        try {\n          pos +\u003d blockReader.skip(diff);\n          if (pos \u003d\u003d targetPos) {\n            done \u003d true;\n          } else {\n            // The range was already checked. If the block reader returns\n            // something unexpected instead of throwing an exception, it is\n            // most likely a bug.\n            String errMsg \u003d \"BlockReader failed to seek to \" +\n                targetPos + \". Instead, it seeked to \" + pos + \".\";\n            DFSClient.LOG.warn(errMsg);\n            throw new IOException(errMsg);\n          }\n        } catch (IOException e) {//make following read to retry\n          DFSClient.LOG.debug(\"Exception while seek to {} from {} of {} from \"\n              + \"{}\", targetPos, getCurrentBlock(), src, currentNode, e);\n          checkInterrupted(e);\n        }\n      }\n    }\n    if (!done) {\n      pos \u003d targetPos;\n      blockEnd \u003d -1;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "39285e6a1978ea5e53bdc1b0aef62421382124a8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8971. Remove guards when calling LOG.debug() and LOG.trace() in client package. Contributed by Mingliang Liu.\n",
      "commitDate": "29/09/15 5:52 PM",
      "commitName": "39285e6a1978ea5e53bdc1b0aef62421382124a8",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "29/09/15 5:51 PM",
      "commitNameOld": "6ee0539ede78b640f01c5eac18ded161182a7835",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,46 +1,43 @@\n   public synchronized void seek(long targetPos) throws IOException {\n     if (targetPos \u003e getFileLength()) {\n       throw new EOFException(\"Cannot seek after EOF\");\n     }\n     if (targetPos \u003c 0) {\n       throw new EOFException(\"Cannot seek to negative offset\");\n     }\n     if (closed.get()) {\n       throw new IOException(\"Stream is closed!\");\n     }\n     boolean done \u003d false;\n     if (pos \u003c\u003d targetPos \u0026\u0026 targetPos \u003c\u003d blockEnd) {\n       //\n       // If this seek is to a positive position in the current\n       // block, and this piece of data might already be lying in\n       // the TCP buffer, then just eat up the intervening data.\n       //\n       int diff \u003d (int)(targetPos - pos);\n       if (diff \u003c\u003d blockReader.available()) {\n         try {\n           pos +\u003d blockReader.skip(diff);\n           if (pos \u003d\u003d targetPos) {\n             done \u003d true;\n           } else {\n             // The range was already checked. If the block reader returns\n             // something unexpected instead of throwing an exception, it is\n             // most likely a bug. \n             String errMsg \u003d \"BlockReader failed to seek to \" + \n                 targetPos + \". Instead, it seeked to \" + pos + \".\";\n             DFSClient.LOG.warn(errMsg);\n             throw new IOException(errMsg);\n           }\n         } catch (IOException e) {//make following read to retry\n-          if(DFSClient.LOG.isDebugEnabled()) {\n-            DFSClient.LOG.debug(\"Exception while seek to \" + targetPos\n-                + \" from \" + getCurrentBlock() + \" of \" + src + \" from \"\n-                + currentNode, e);\n-          }\n+          DFSClient.LOG.debug(\"Exception while seek to {} from {} of {} from \"\n+              + \"{}\", targetPos, getCurrentBlock(), src, currentNode, e);\n         }\n       }\n     }\n     if (!done) {\n       pos \u003d targetPos;\n       blockEnd \u003d -1;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void seek(long targetPos) throws IOException {\n    if (targetPos \u003e getFileLength()) {\n      throw new EOFException(\"Cannot seek after EOF\");\n    }\n    if (targetPos \u003c 0) {\n      throw new EOFException(\"Cannot seek to negative offset\");\n    }\n    if (closed.get()) {\n      throw new IOException(\"Stream is closed!\");\n    }\n    boolean done \u003d false;\n    if (pos \u003c\u003d targetPos \u0026\u0026 targetPos \u003c\u003d blockEnd) {\n      //\n      // If this seek is to a positive position in the current\n      // block, and this piece of data might already be lying in\n      // the TCP buffer, then just eat up the intervening data.\n      //\n      int diff \u003d (int)(targetPos - pos);\n      if (diff \u003c\u003d blockReader.available()) {\n        try {\n          pos +\u003d blockReader.skip(diff);\n          if (pos \u003d\u003d targetPos) {\n            done \u003d true;\n          } else {\n            // The range was already checked. If the block reader returns\n            // something unexpected instead of throwing an exception, it is\n            // most likely a bug. \n            String errMsg \u003d \"BlockReader failed to seek to \" + \n                targetPos + \". Instead, it seeked to \" + pos + \".\";\n            DFSClient.LOG.warn(errMsg);\n            throw new IOException(errMsg);\n          }\n        } catch (IOException e) {//make following read to retry\n          DFSClient.LOG.debug(\"Exception while seek to {} from {} of {} from \"\n              + \"{}\", targetPos, getCurrentBlock(), src, currentNode, e);\n        }\n      }\n    }\n    if (!done) {\n      pos \u003d targetPos;\n      blockEnd \u003d -1;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "6ee0539ede78b640f01c5eac18ded161182a7835": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-9170. Move libhdfs / fuse-dfs / libwebhdfs to hdfs-client. Contributed by Haohui Mai.\"\n\nThis reverts commit d5a9a3daa0224249221ffa7b8bd5751ab2feca56.\n",
      "commitDate": "29/09/15 5:51 PM",
      "commitName": "6ee0539ede78b640f01c5eac18ded161182a7835",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "29/09/15 5:48 PM",
      "commitNameOld": "d5a9a3daa0224249221ffa7b8bd5751ab2feca56",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,43 +1,46 @@\n   public synchronized void seek(long targetPos) throws IOException {\n     if (targetPos \u003e getFileLength()) {\n       throw new EOFException(\"Cannot seek after EOF\");\n     }\n     if (targetPos \u003c 0) {\n       throw new EOFException(\"Cannot seek to negative offset\");\n     }\n     if (closed.get()) {\n       throw new IOException(\"Stream is closed!\");\n     }\n     boolean done \u003d false;\n     if (pos \u003c\u003d targetPos \u0026\u0026 targetPos \u003c\u003d blockEnd) {\n       //\n       // If this seek is to a positive position in the current\n       // block, and this piece of data might already be lying in\n       // the TCP buffer, then just eat up the intervening data.\n       //\n       int diff \u003d (int)(targetPos - pos);\n       if (diff \u003c\u003d blockReader.available()) {\n         try {\n           pos +\u003d blockReader.skip(diff);\n           if (pos \u003d\u003d targetPos) {\n             done \u003d true;\n           } else {\n             // The range was already checked. If the block reader returns\n             // something unexpected instead of throwing an exception, it is\n             // most likely a bug. \n             String errMsg \u003d \"BlockReader failed to seek to \" + \n                 targetPos + \". Instead, it seeked to \" + pos + \".\";\n             DFSClient.LOG.warn(errMsg);\n             throw new IOException(errMsg);\n           }\n         } catch (IOException e) {//make following read to retry\n-          DFSClient.LOG.debug(\"Exception while seek to {} from {} of {} from \"\n-              + \"{}\", targetPos, getCurrentBlock(), src, currentNode, e);\n+          if(DFSClient.LOG.isDebugEnabled()) {\n+            DFSClient.LOG.debug(\"Exception while seek to \" + targetPos\n+                + \" from \" + getCurrentBlock() + \" of \" + src + \" from \"\n+                + currentNode, e);\n+          }\n         }\n       }\n     }\n     if (!done) {\n       pos \u003d targetPos;\n       blockEnd \u003d -1;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void seek(long targetPos) throws IOException {\n    if (targetPos \u003e getFileLength()) {\n      throw new EOFException(\"Cannot seek after EOF\");\n    }\n    if (targetPos \u003c 0) {\n      throw new EOFException(\"Cannot seek to negative offset\");\n    }\n    if (closed.get()) {\n      throw new IOException(\"Stream is closed!\");\n    }\n    boolean done \u003d false;\n    if (pos \u003c\u003d targetPos \u0026\u0026 targetPos \u003c\u003d blockEnd) {\n      //\n      // If this seek is to a positive position in the current\n      // block, and this piece of data might already be lying in\n      // the TCP buffer, then just eat up the intervening data.\n      //\n      int diff \u003d (int)(targetPos - pos);\n      if (diff \u003c\u003d blockReader.available()) {\n        try {\n          pos +\u003d blockReader.skip(diff);\n          if (pos \u003d\u003d targetPos) {\n            done \u003d true;\n          } else {\n            // The range was already checked. If the block reader returns\n            // something unexpected instead of throwing an exception, it is\n            // most likely a bug. \n            String errMsg \u003d \"BlockReader failed to seek to \" + \n                targetPos + \". Instead, it seeked to \" + pos + \".\";\n            DFSClient.LOG.warn(errMsg);\n            throw new IOException(errMsg);\n          }\n        } catch (IOException e) {//make following read to retry\n          if(DFSClient.LOG.isDebugEnabled()) {\n            DFSClient.LOG.debug(\"Exception while seek to \" + targetPos\n                + \" from \" + getCurrentBlock() + \" of \" + src + \" from \"\n                + currentNode, e);\n          }\n        }\n      }\n    }\n    if (!done) {\n      pos \u003d targetPos;\n      blockEnd \u003d -1;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "d5a9a3daa0224249221ffa7b8bd5751ab2feca56": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9170. Move libhdfs / fuse-dfs / libwebhdfs to hdfs-client. Contributed by Haohui Mai.\n",
      "commitDate": "29/09/15 5:48 PM",
      "commitName": "d5a9a3daa0224249221ffa7b8bd5751ab2feca56",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "28/09/15 7:42 AM",
      "commitNameOld": "892ade689f9bcce76daae8f66fc00a49bee8548e",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 1.42,
      "commitsBetweenForRepo": 19,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,46 +1,43 @@\n   public synchronized void seek(long targetPos) throws IOException {\n     if (targetPos \u003e getFileLength()) {\n       throw new EOFException(\"Cannot seek after EOF\");\n     }\n     if (targetPos \u003c 0) {\n       throw new EOFException(\"Cannot seek to negative offset\");\n     }\n     if (closed.get()) {\n       throw new IOException(\"Stream is closed!\");\n     }\n     boolean done \u003d false;\n     if (pos \u003c\u003d targetPos \u0026\u0026 targetPos \u003c\u003d blockEnd) {\n       //\n       // If this seek is to a positive position in the current\n       // block, and this piece of data might already be lying in\n       // the TCP buffer, then just eat up the intervening data.\n       //\n       int diff \u003d (int)(targetPos - pos);\n       if (diff \u003c\u003d blockReader.available()) {\n         try {\n           pos +\u003d blockReader.skip(diff);\n           if (pos \u003d\u003d targetPos) {\n             done \u003d true;\n           } else {\n             // The range was already checked. If the block reader returns\n             // something unexpected instead of throwing an exception, it is\n             // most likely a bug. \n             String errMsg \u003d \"BlockReader failed to seek to \" + \n                 targetPos + \". Instead, it seeked to \" + pos + \".\";\n             DFSClient.LOG.warn(errMsg);\n             throw new IOException(errMsg);\n           }\n         } catch (IOException e) {//make following read to retry\n-          if(DFSClient.LOG.isDebugEnabled()) {\n-            DFSClient.LOG.debug(\"Exception while seek to \" + targetPos\n-                + \" from \" + getCurrentBlock() + \" of \" + src + \" from \"\n-                + currentNode, e);\n-          }\n+          DFSClient.LOG.debug(\"Exception while seek to {} from {} of {} from \"\n+              + \"{}\", targetPos, getCurrentBlock(), src, currentNode, e);\n         }\n       }\n     }\n     if (!done) {\n       pos \u003d targetPos;\n       blockEnd \u003d -1;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void seek(long targetPos) throws IOException {\n    if (targetPos \u003e getFileLength()) {\n      throw new EOFException(\"Cannot seek after EOF\");\n    }\n    if (targetPos \u003c 0) {\n      throw new EOFException(\"Cannot seek to negative offset\");\n    }\n    if (closed.get()) {\n      throw new IOException(\"Stream is closed!\");\n    }\n    boolean done \u003d false;\n    if (pos \u003c\u003d targetPos \u0026\u0026 targetPos \u003c\u003d blockEnd) {\n      //\n      // If this seek is to a positive position in the current\n      // block, and this piece of data might already be lying in\n      // the TCP buffer, then just eat up the intervening data.\n      //\n      int diff \u003d (int)(targetPos - pos);\n      if (diff \u003c\u003d blockReader.available()) {\n        try {\n          pos +\u003d blockReader.skip(diff);\n          if (pos \u003d\u003d targetPos) {\n            done \u003d true;\n          } else {\n            // The range was already checked. If the block reader returns\n            // something unexpected instead of throwing an exception, it is\n            // most likely a bug. \n            String errMsg \u003d \"BlockReader failed to seek to \" + \n                targetPos + \". Instead, it seeked to \" + pos + \".\";\n            DFSClient.LOG.warn(errMsg);\n            throw new IOException(errMsg);\n          }\n        } catch (IOException e) {//make following read to retry\n          DFSClient.LOG.debug(\"Exception while seek to {} from {} of {} from \"\n              + \"{}\", targetPos, getCurrentBlock(), src, currentNode, e);\n        }\n      }\n    }\n    if (!done) {\n      pos \u003d targetPos;\n      blockEnd \u003d -1;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8053. Move DFSIn/OutputStream and related classes to hadoop-hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "26/09/15 11:08 AM",
      "commitName": "bf37d3d80e5179dea27e5bd5aea804a38aa9934c",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "26/09/15 9:06 AM",
      "commitNameOld": "861b52db242f238d7e36ad75c158025be959a696",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 0.08,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public synchronized void seek(long targetPos) throws IOException {\n    if (targetPos \u003e getFileLength()) {\n      throw new EOFException(\"Cannot seek after EOF\");\n    }\n    if (targetPos \u003c 0) {\n      throw new EOFException(\"Cannot seek to negative offset\");\n    }\n    if (closed.get()) {\n      throw new IOException(\"Stream is closed!\");\n    }\n    boolean done \u003d false;\n    if (pos \u003c\u003d targetPos \u0026\u0026 targetPos \u003c\u003d blockEnd) {\n      //\n      // If this seek is to a positive position in the current\n      // block, and this piece of data might already be lying in\n      // the TCP buffer, then just eat up the intervening data.\n      //\n      int diff \u003d (int)(targetPos - pos);\n      if (diff \u003c\u003d blockReader.available()) {\n        try {\n          pos +\u003d blockReader.skip(diff);\n          if (pos \u003d\u003d targetPos) {\n            done \u003d true;\n          } else {\n            // The range was already checked. If the block reader returns\n            // something unexpected instead of throwing an exception, it is\n            // most likely a bug. \n            String errMsg \u003d \"BlockReader failed to seek to \" + \n                targetPos + \". Instead, it seeked to \" + pos + \".\";\n            DFSClient.LOG.warn(errMsg);\n            throw new IOException(errMsg);\n          }\n        } catch (IOException e) {//make following read to retry\n          if(DFSClient.LOG.isDebugEnabled()) {\n            DFSClient.LOG.debug(\"Exception while seek to \" + targetPos\n                + \" from \" + getCurrentBlock() + \" of \" + src + \" from \"\n                + currentNode, e);\n          }\n        }\n      }\n    }\n    if (!done) {\n      pos \u003d targetPos;\n      blockEnd \u003d -1;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java"
      }
    },
    "a97a1e73177974cff8afafad6ca43a96563f3c61": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7494. Checking of closed in DFSInputStream#pread() should be protected by synchronization (Ted Yu via Colin P. McCabe)\n",
      "commitDate": "16/12/14 11:07 AM",
      "commitName": "a97a1e73177974cff8afafad6ca43a96563f3c61",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "02/12/14 8:57 PM",
      "commitNameOld": "7caa3bc98e6880f98c5c32c486a0c539f9fd3f5f",
      "commitAuthorOld": "stack",
      "daysBetweenCommits": 13.59,
      "commitsBetweenForRepo": 103,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,46 +1,46 @@\n   public synchronized void seek(long targetPos) throws IOException {\n     if (targetPos \u003e getFileLength()) {\n       throw new EOFException(\"Cannot seek after EOF\");\n     }\n     if (targetPos \u003c 0) {\n       throw new EOFException(\"Cannot seek to negative offset\");\n     }\n-    if (closed) {\n+    if (closed.get()) {\n       throw new IOException(\"Stream is closed!\");\n     }\n     boolean done \u003d false;\n     if (pos \u003c\u003d targetPos \u0026\u0026 targetPos \u003c\u003d blockEnd) {\n       //\n       // If this seek is to a positive position in the current\n       // block, and this piece of data might already be lying in\n       // the TCP buffer, then just eat up the intervening data.\n       //\n       int diff \u003d (int)(targetPos - pos);\n       if (diff \u003c\u003d blockReader.available()) {\n         try {\n           pos +\u003d blockReader.skip(diff);\n           if (pos \u003d\u003d targetPos) {\n             done \u003d true;\n           } else {\n             // The range was already checked. If the block reader returns\n             // something unexpected instead of throwing an exception, it is\n             // most likely a bug. \n             String errMsg \u003d \"BlockReader failed to seek to \" + \n                 targetPos + \". Instead, it seeked to \" + pos + \".\";\n             DFSClient.LOG.warn(errMsg);\n             throw new IOException(errMsg);\n           }\n         } catch (IOException e) {//make following read to retry\n           if(DFSClient.LOG.isDebugEnabled()) {\n             DFSClient.LOG.debug(\"Exception while seek to \" + targetPos\n                 + \" from \" + getCurrentBlock() + \" of \" + src + \" from \"\n                 + currentNode, e);\n           }\n         }\n       }\n     }\n     if (!done) {\n       pos \u003d targetPos;\n       blockEnd \u003d -1;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void seek(long targetPos) throws IOException {\n    if (targetPos \u003e getFileLength()) {\n      throw new EOFException(\"Cannot seek after EOF\");\n    }\n    if (targetPos \u003c 0) {\n      throw new EOFException(\"Cannot seek to negative offset\");\n    }\n    if (closed.get()) {\n      throw new IOException(\"Stream is closed!\");\n    }\n    boolean done \u003d false;\n    if (pos \u003c\u003d targetPos \u0026\u0026 targetPos \u003c\u003d blockEnd) {\n      //\n      // If this seek is to a positive position in the current\n      // block, and this piece of data might already be lying in\n      // the TCP buffer, then just eat up the intervening data.\n      //\n      int diff \u003d (int)(targetPos - pos);\n      if (diff \u003c\u003d blockReader.available()) {\n        try {\n          pos +\u003d blockReader.skip(diff);\n          if (pos \u003d\u003d targetPos) {\n            done \u003d true;\n          } else {\n            // The range was already checked. If the block reader returns\n            // something unexpected instead of throwing an exception, it is\n            // most likely a bug. \n            String errMsg \u003d \"BlockReader failed to seek to \" + \n                targetPos + \". Instead, it seeked to \" + pos + \".\";\n            DFSClient.LOG.warn(errMsg);\n            throw new IOException(errMsg);\n          }\n        } catch (IOException e) {//make following read to retry\n          if(DFSClient.LOG.isDebugEnabled()) {\n            DFSClient.LOG.debug(\"Exception while seek to \" + targetPos\n                + \" from \" + getCurrentBlock() + \" of \" + src + \" from \"\n                + currentNode, e);\n          }\n        }\n      }\n    }\n    if (!done) {\n      pos \u003d targetPos;\n      blockEnd \u003d -1;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "b6fbaba8e98d2da913cbe5474cab479cd4efd191": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-9361: Strictly define FileSystem APIs - HDFS portion\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1607597 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "03/07/14 5:09 AM",
      "commitName": "b6fbaba8e98d2da913cbe5474cab479cd4efd191",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "30/06/14 1:46 PM",
      "commitNameOld": "0ca41a8f35e4f05bb04805a2e0a617850707b4db",
      "commitAuthorOld": "Chris Nauroth",
      "daysBetweenCommits": 2.64,
      "commitsBetweenForRepo": 19,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,46 +1,46 @@\n   public synchronized void seek(long targetPos) throws IOException {\n     if (targetPos \u003e getFileLength()) {\n-      throw new IOException(\"Cannot seek after EOF\");\n+      throw new EOFException(\"Cannot seek after EOF\");\n     }\n     if (targetPos \u003c 0) {\n-      throw new IOException(\"Cannot seek to negative offset\");\n+      throw new EOFException(\"Cannot seek to negative offset\");\n     }\n     if (closed) {\n       throw new IOException(\"Stream is closed!\");\n     }\n     boolean done \u003d false;\n     if (pos \u003c\u003d targetPos \u0026\u0026 targetPos \u003c\u003d blockEnd) {\n       //\n       // If this seek is to a positive position in the current\n       // block, and this piece of data might already be lying in\n       // the TCP buffer, then just eat up the intervening data.\n       //\n       int diff \u003d (int)(targetPos - pos);\n       if (diff \u003c\u003d blockReader.available()) {\n         try {\n           pos +\u003d blockReader.skip(diff);\n           if (pos \u003d\u003d targetPos) {\n             done \u003d true;\n           } else {\n             // The range was already checked. If the block reader returns\n             // something unexpected instead of throwing an exception, it is\n             // most likely a bug. \n             String errMsg \u003d \"BlockReader failed to seek to \" + \n                 targetPos + \". Instead, it seeked to \" + pos + \".\";\n             DFSClient.LOG.warn(errMsg);\n             throw new IOException(errMsg);\n           }\n         } catch (IOException e) {//make following read to retry\n           if(DFSClient.LOG.isDebugEnabled()) {\n             DFSClient.LOG.debug(\"Exception while seek to \" + targetPos\n                 + \" from \" + getCurrentBlock() + \" of \" + src + \" from \"\n                 + currentNode, e);\n           }\n         }\n       }\n     }\n     if (!done) {\n       pos \u003d targetPos;\n       blockEnd \u003d -1;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void seek(long targetPos) throws IOException {\n    if (targetPos \u003e getFileLength()) {\n      throw new EOFException(\"Cannot seek after EOF\");\n    }\n    if (targetPos \u003c 0) {\n      throw new EOFException(\"Cannot seek to negative offset\");\n    }\n    if (closed) {\n      throw new IOException(\"Stream is closed!\");\n    }\n    boolean done \u003d false;\n    if (pos \u003c\u003d targetPos \u0026\u0026 targetPos \u003c\u003d blockEnd) {\n      //\n      // If this seek is to a positive position in the current\n      // block, and this piece of data might already be lying in\n      // the TCP buffer, then just eat up the intervening data.\n      //\n      int diff \u003d (int)(targetPos - pos);\n      if (diff \u003c\u003d blockReader.available()) {\n        try {\n          pos +\u003d blockReader.skip(diff);\n          if (pos \u003d\u003d targetPos) {\n            done \u003d true;\n          } else {\n            // The range was already checked. If the block reader returns\n            // something unexpected instead of throwing an exception, it is\n            // most likely a bug. \n            String errMsg \u003d \"BlockReader failed to seek to \" + \n                targetPos + \". Instead, it seeked to \" + pos + \".\";\n            DFSClient.LOG.warn(errMsg);\n            throw new IOException(errMsg);\n          }\n        } catch (IOException e) {//make following read to retry\n          if(DFSClient.LOG.isDebugEnabled()) {\n            DFSClient.LOG.debug(\"Exception while seek to \" + targetPos\n                + \" from \" + getCurrentBlock() + \" of \" + src + \" from \"\n                + currentNode, e);\n          }\n        }\n      }\n    }\n    if (!done) {\n      pos \u003d targetPos;\n      blockEnd \u003d -1;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "ab96a0838dafbfea77382135914feadbfd03cf53": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5881. Fix skip() of the short-circuit local reader(legacy). Contributed by Kihwal Lee.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1565310 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "06/02/14 7:45 AM",
      "commitName": "ab96a0838dafbfea77382135914feadbfd03cf53",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "25/01/14 7:50 AM",
      "commitNameOld": "befb254e61a34352d146be79656d656044432dd1",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 12.0,
      "commitsBetweenForRepo": 95,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,38 +1,46 @@\n   public synchronized void seek(long targetPos) throws IOException {\n     if (targetPos \u003e getFileLength()) {\n       throw new IOException(\"Cannot seek after EOF\");\n     }\n     if (targetPos \u003c 0) {\n       throw new IOException(\"Cannot seek to negative offset\");\n     }\n     if (closed) {\n       throw new IOException(\"Stream is closed!\");\n     }\n     boolean done \u003d false;\n     if (pos \u003c\u003d targetPos \u0026\u0026 targetPos \u003c\u003d blockEnd) {\n       //\n       // If this seek is to a positive position in the current\n       // block, and this piece of data might already be lying in\n       // the TCP buffer, then just eat up the intervening data.\n       //\n       int diff \u003d (int)(targetPos - pos);\n       if (diff \u003c\u003d blockReader.available()) {\n         try {\n           pos +\u003d blockReader.skip(diff);\n           if (pos \u003d\u003d targetPos) {\n             done \u003d true;\n+          } else {\n+            // The range was already checked. If the block reader returns\n+            // something unexpected instead of throwing an exception, it is\n+            // most likely a bug. \n+            String errMsg \u003d \"BlockReader failed to seek to \" + \n+                targetPos + \". Instead, it seeked to \" + pos + \".\";\n+            DFSClient.LOG.warn(errMsg);\n+            throw new IOException(errMsg);\n           }\n         } catch (IOException e) {//make following read to retry\n           if(DFSClient.LOG.isDebugEnabled()) {\n             DFSClient.LOG.debug(\"Exception while seek to \" + targetPos\n                 + \" from \" + getCurrentBlock() + \" of \" + src + \" from \"\n                 + currentNode, e);\n           }\n         }\n       }\n     }\n     if (!done) {\n       pos \u003d targetPos;\n       blockEnd \u003d -1;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void seek(long targetPos) throws IOException {\n    if (targetPos \u003e getFileLength()) {\n      throw new IOException(\"Cannot seek after EOF\");\n    }\n    if (targetPos \u003c 0) {\n      throw new IOException(\"Cannot seek to negative offset\");\n    }\n    if (closed) {\n      throw new IOException(\"Stream is closed!\");\n    }\n    boolean done \u003d false;\n    if (pos \u003c\u003d targetPos \u0026\u0026 targetPos \u003c\u003d blockEnd) {\n      //\n      // If this seek is to a positive position in the current\n      // block, and this piece of data might already be lying in\n      // the TCP buffer, then just eat up the intervening data.\n      //\n      int diff \u003d (int)(targetPos - pos);\n      if (diff \u003c\u003d blockReader.available()) {\n        try {\n          pos +\u003d blockReader.skip(diff);\n          if (pos \u003d\u003d targetPos) {\n            done \u003d true;\n          } else {\n            // The range was already checked. If the block reader returns\n            // something unexpected instead of throwing an exception, it is\n            // most likely a bug. \n            String errMsg \u003d \"BlockReader failed to seek to \" + \n                targetPos + \". Instead, it seeked to \" + pos + \".\";\n            DFSClient.LOG.warn(errMsg);\n            throw new IOException(errMsg);\n          }\n        } catch (IOException e) {//make following read to retry\n          if(DFSClient.LOG.isDebugEnabled()) {\n            DFSClient.LOG.debug(\"Exception while seek to \" + targetPos\n                + \" from \" + getCurrentBlock() + \" of \" + src + \" from \"\n                + currentNode, e);\n          }\n        }\n      }\n    }\n    if (!done) {\n      pos \u003d targetPos;\n      blockEnd \u003d -1;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "9a4030e0e84a688c12daa21fe9a165808c3eca70": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4356. BlockReaderLocal should use passed file descriptors rather than paths. Contributed by Colin Patrick McCabe.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-347@1432335 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/01/13 3:52 PM",
      "commitName": "9a4030e0e84a688c12daa21fe9a165808c3eca70",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "09/01/13 1:34 PM",
      "commitNameOld": "c9db06f2e4d1c1f71f021d5070323f9fc194cdd7",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 2.1,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,38 +1,38 @@\n   public synchronized void seek(long targetPos) throws IOException {\n     if (targetPos \u003e getFileLength()) {\n       throw new IOException(\"Cannot seek after EOF\");\n     }\n     if (targetPos \u003c 0) {\n       throw new IOException(\"Cannot seek to negative offset\");\n     }\n     if (closed) {\n       throw new IOException(\"Stream is closed!\");\n     }\n     boolean done \u003d false;\n     if (pos \u003c\u003d targetPos \u0026\u0026 targetPos \u003c\u003d blockEnd) {\n       //\n       // If this seek is to a positive position in the current\n       // block, and this piece of data might already be lying in\n       // the TCP buffer, then just eat up the intervening data.\n       //\n       int diff \u003d (int)(targetPos - pos);\n-      if (diff \u003c\u003d DFSClient.TCP_WINDOW_SIZE) {\n+      if (diff \u003c\u003d blockReader.available()) {\n         try {\n           pos +\u003d blockReader.skip(diff);\n           if (pos \u003d\u003d targetPos) {\n             done \u003d true;\n           }\n         } catch (IOException e) {//make following read to retry\n           if(DFSClient.LOG.isDebugEnabled()) {\n             DFSClient.LOG.debug(\"Exception while seek to \" + targetPos\n                 + \" from \" + getCurrentBlock() + \" of \" + src + \" from \"\n                 + currentNode, e);\n           }\n         }\n       }\n     }\n     if (!done) {\n       pos \u003d targetPos;\n       blockEnd \u003d -1;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void seek(long targetPos) throws IOException {\n    if (targetPos \u003e getFileLength()) {\n      throw new IOException(\"Cannot seek after EOF\");\n    }\n    if (targetPos \u003c 0) {\n      throw new IOException(\"Cannot seek to negative offset\");\n    }\n    if (closed) {\n      throw new IOException(\"Stream is closed!\");\n    }\n    boolean done \u003d false;\n    if (pos \u003c\u003d targetPos \u0026\u0026 targetPos \u003c\u003d blockEnd) {\n      //\n      // If this seek is to a positive position in the current\n      // block, and this piece of data might already be lying in\n      // the TCP buffer, then just eat up the intervening data.\n      //\n      int diff \u003d (int)(targetPos - pos);\n      if (diff \u003c\u003d blockReader.available()) {\n        try {\n          pos +\u003d blockReader.skip(diff);\n          if (pos \u003d\u003d targetPos) {\n            done \u003d true;\n          }\n        } catch (IOException e) {//make following read to retry\n          if(DFSClient.LOG.isDebugEnabled()) {\n            DFSClient.LOG.debug(\"Exception while seek to \" + targetPos\n                + \" from \" + getCurrentBlock() + \" of \" + src + \" from \"\n                + currentNode, e);\n          }\n        }\n      }\n    }\n    if (!done) {\n      pos \u003d targetPos;\n      blockEnd \u003d -1;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "ecbb41923cb4a51c09f346b39d554bb7bbc2384e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4156. Seeking to a negative position should throw an IOE. Contributed by Eli Reisman\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1410812 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/11/12 6:11 PM",
      "commitName": "ecbb41923cb4a51c09f346b39d554bb7bbc2384e",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "28/10/12 4:10 PM",
      "commitNameOld": "cea7bbc630deede93dbe6a1bbda56ad49de4f3de",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 20.13,
      "commitsBetweenForRepo": 121,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,35 +1,38 @@\n   public synchronized void seek(long targetPos) throws IOException {\n     if (targetPos \u003e getFileLength()) {\n       throw new IOException(\"Cannot seek after EOF\");\n     }\n+    if (targetPos \u003c 0) {\n+      throw new IOException(\"Cannot seek to negative offset\");\n+    }\n     if (closed) {\n       throw new IOException(\"Stream is closed!\");\n     }\n     boolean done \u003d false;\n     if (pos \u003c\u003d targetPos \u0026\u0026 targetPos \u003c\u003d blockEnd) {\n       //\n       // If this seek is to a positive position in the current\n       // block, and this piece of data might already be lying in\n       // the TCP buffer, then just eat up the intervening data.\n       //\n       int diff \u003d (int)(targetPos - pos);\n       if (diff \u003c\u003d DFSClient.TCP_WINDOW_SIZE) {\n         try {\n           pos +\u003d blockReader.skip(diff);\n           if (pos \u003d\u003d targetPos) {\n             done \u003d true;\n           }\n         } catch (IOException e) {//make following read to retry\n           if(DFSClient.LOG.isDebugEnabled()) {\n             DFSClient.LOG.debug(\"Exception while seek to \" + targetPos\n                 + \" from \" + getCurrentBlock() + \" of \" + src + \" from \"\n                 + currentNode, e);\n           }\n         }\n       }\n     }\n     if (!done) {\n       pos \u003d targetPos;\n       blockEnd \u003d -1;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void seek(long targetPos) throws IOException {\n    if (targetPos \u003e getFileLength()) {\n      throw new IOException(\"Cannot seek after EOF\");\n    }\n    if (targetPos \u003c 0) {\n      throw new IOException(\"Cannot seek to negative offset\");\n    }\n    if (closed) {\n      throw new IOException(\"Stream is closed!\");\n    }\n    boolean done \u003d false;\n    if (pos \u003c\u003d targetPos \u0026\u0026 targetPos \u003c\u003d blockEnd) {\n      //\n      // If this seek is to a positive position in the current\n      // block, and this piece of data might already be lying in\n      // the TCP buffer, then just eat up the intervening data.\n      //\n      int diff \u003d (int)(targetPos - pos);\n      if (diff \u003c\u003d DFSClient.TCP_WINDOW_SIZE) {\n        try {\n          pos +\u003d blockReader.skip(diff);\n          if (pos \u003d\u003d targetPos) {\n            done \u003d true;\n          }\n        } catch (IOException e) {//make following read to retry\n          if(DFSClient.LOG.isDebugEnabled()) {\n            DFSClient.LOG.debug(\"Exception while seek to \" + targetPos\n                + \" from \" + getCurrentBlock() + \" of \" + src + \" from \"\n                + currentNode, e);\n          }\n        }\n      }\n    }\n    if (!done) {\n      pos \u003d targetPos;\n      blockEnd \u003d -1;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public synchronized void seek(long targetPos) throws IOException {\n    if (targetPos \u003e getFileLength()) {\n      throw new IOException(\"Cannot seek after EOF\");\n    }\n    if (closed) {\n      throw new IOException(\"Stream is closed!\");\n    }\n    boolean done \u003d false;\n    if (pos \u003c\u003d targetPos \u0026\u0026 targetPos \u003c\u003d blockEnd) {\n      //\n      // If this seek is to a positive position in the current\n      // block, and this piece of data might already be lying in\n      // the TCP buffer, then just eat up the intervening data.\n      //\n      int diff \u003d (int)(targetPos - pos);\n      if (diff \u003c\u003d DFSClient.TCP_WINDOW_SIZE) {\n        try {\n          pos +\u003d blockReader.skip(diff);\n          if (pos \u003d\u003d targetPos) {\n            done \u003d true;\n          }\n        } catch (IOException e) {//make following read to retry\n          if(DFSClient.LOG.isDebugEnabled()) {\n            DFSClient.LOG.debug(\"Exception while seek to \" + targetPos\n                + \" from \" + getCurrentBlock() + \" of \" + src + \" from \"\n                + currentNode, e);\n          }\n        }\n      }\n    }\n    if (!done) {\n      pos \u003d targetPos;\n      blockEnd \u003d -1;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public synchronized void seek(long targetPos) throws IOException {\n    if (targetPos \u003e getFileLength()) {\n      throw new IOException(\"Cannot seek after EOF\");\n    }\n    if (closed) {\n      throw new IOException(\"Stream is closed!\");\n    }\n    boolean done \u003d false;\n    if (pos \u003c\u003d targetPos \u0026\u0026 targetPos \u003c\u003d blockEnd) {\n      //\n      // If this seek is to a positive position in the current\n      // block, and this piece of data might already be lying in\n      // the TCP buffer, then just eat up the intervening data.\n      //\n      int diff \u003d (int)(targetPos - pos);\n      if (diff \u003c\u003d DFSClient.TCP_WINDOW_SIZE) {\n        try {\n          pos +\u003d blockReader.skip(diff);\n          if (pos \u003d\u003d targetPos) {\n            done \u003d true;\n          }\n        } catch (IOException e) {//make following read to retry\n          if(DFSClient.LOG.isDebugEnabled()) {\n            DFSClient.LOG.debug(\"Exception while seek to \" + targetPos\n                + \" from \" + getCurrentBlock() + \" of \" + src + \" from \"\n                + currentNode, e);\n          }\n        }\n      }\n    }\n    if (!done) {\n      pos \u003d targetPos;\n      blockEnd \u003d -1;\n    }\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/DFSInputStream.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java"
      }
    },
    "2c5dd549e31aa5d3377ff2619ede8e92b8dc5d0f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-1977. Stop using StringUtils.stringifyException(). Contributed by Bharath Mundlapudi.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1145834 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/07/11 6:11 PM",
      "commitName": "2c5dd549e31aa5d3377ff2619ede8e92b8dc5d0f",
      "commitAuthor": "Jitendra Nath Pandey",
      "commitDateOld": "08/07/11 1:13 PM",
      "commitNameOld": "6ec9b178c664796b44eab6c41f7216577d380f7c",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 4.21,
      "commitsBetweenForRepo": 12,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,36 +1,35 @@\n   public synchronized void seek(long targetPos) throws IOException {\n     if (targetPos \u003e getFileLength()) {\n       throw new IOException(\"Cannot seek after EOF\");\n     }\n     if (closed) {\n       throw new IOException(\"Stream is closed!\");\n     }\n     boolean done \u003d false;\n     if (pos \u003c\u003d targetPos \u0026\u0026 targetPos \u003c\u003d blockEnd) {\n       //\n       // If this seek is to a positive position in the current\n       // block, and this piece of data might already be lying in\n       // the TCP buffer, then just eat up the intervening data.\n       //\n       int diff \u003d (int)(targetPos - pos);\n       if (diff \u003c\u003d DFSClient.TCP_WINDOW_SIZE) {\n         try {\n           pos +\u003d blockReader.skip(diff);\n           if (pos \u003d\u003d targetPos) {\n             done \u003d true;\n           }\n         } catch (IOException e) {//make following read to retry\n           if(DFSClient.LOG.isDebugEnabled()) {\n             DFSClient.LOG.debug(\"Exception while seek to \" + targetPos\n-                + \" from \" + getCurrentBlock() + \" of \" + src\n-                + \" from \" + currentNode + \": \"\n-                + StringUtils.stringifyException(e));\n+                + \" from \" + getCurrentBlock() + \" of \" + src + \" from \"\n+                + currentNode, e);\n           }\n         }\n       }\n     }\n     if (!done) {\n       pos \u003d targetPos;\n       blockEnd \u003d -1;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void seek(long targetPos) throws IOException {\n    if (targetPos \u003e getFileLength()) {\n      throw new IOException(\"Cannot seek after EOF\");\n    }\n    if (closed) {\n      throw new IOException(\"Stream is closed!\");\n    }\n    boolean done \u003d false;\n    if (pos \u003c\u003d targetPos \u0026\u0026 targetPos \u003c\u003d blockEnd) {\n      //\n      // If this seek is to a positive position in the current\n      // block, and this piece of data might already be lying in\n      // the TCP buffer, then just eat up the intervening data.\n      //\n      int diff \u003d (int)(targetPos - pos);\n      if (diff \u003c\u003d DFSClient.TCP_WINDOW_SIZE) {\n        try {\n          pos +\u003d blockReader.skip(diff);\n          if (pos \u003d\u003d targetPos) {\n            done \u003d true;\n          }\n        } catch (IOException e) {//make following read to retry\n          if(DFSClient.LOG.isDebugEnabled()) {\n            DFSClient.LOG.debug(\"Exception while seek to \" + targetPos\n                + \" from \" + getCurrentBlock() + \" of \" + src + \" from \"\n                + currentNode, e);\n          }\n        }\n      }\n    }\n    if (!done) {\n      pos \u003d targetPos;\n      blockEnd \u003d -1;\n    }\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,36 @@\n+  public synchronized void seek(long targetPos) throws IOException {\n+    if (targetPos \u003e getFileLength()) {\n+      throw new IOException(\"Cannot seek after EOF\");\n+    }\n+    if (closed) {\n+      throw new IOException(\"Stream is closed!\");\n+    }\n+    boolean done \u003d false;\n+    if (pos \u003c\u003d targetPos \u0026\u0026 targetPos \u003c\u003d blockEnd) {\n+      //\n+      // If this seek is to a positive position in the current\n+      // block, and this piece of data might already be lying in\n+      // the TCP buffer, then just eat up the intervening data.\n+      //\n+      int diff \u003d (int)(targetPos - pos);\n+      if (diff \u003c\u003d DFSClient.TCP_WINDOW_SIZE) {\n+        try {\n+          pos +\u003d blockReader.skip(diff);\n+          if (pos \u003d\u003d targetPos) {\n+            done \u003d true;\n+          }\n+        } catch (IOException e) {//make following read to retry\n+          if(DFSClient.LOG.isDebugEnabled()) {\n+            DFSClient.LOG.debug(\"Exception while seek to \" + targetPos\n+                + \" from \" + getCurrentBlock() + \" of \" + src\n+                + \" from \" + currentNode + \": \"\n+                + StringUtils.stringifyException(e));\n+          }\n+        }\n+      }\n+    }\n+    if (!done) {\n+      pos \u003d targetPos;\n+      blockEnd \u003d -1;\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void seek(long targetPos) throws IOException {\n    if (targetPos \u003e getFileLength()) {\n      throw new IOException(\"Cannot seek after EOF\");\n    }\n    if (closed) {\n      throw new IOException(\"Stream is closed!\");\n    }\n    boolean done \u003d false;\n    if (pos \u003c\u003d targetPos \u0026\u0026 targetPos \u003c\u003d blockEnd) {\n      //\n      // If this seek is to a positive position in the current\n      // block, and this piece of data might already be lying in\n      // the TCP buffer, then just eat up the intervening data.\n      //\n      int diff \u003d (int)(targetPos - pos);\n      if (diff \u003c\u003d DFSClient.TCP_WINDOW_SIZE) {\n        try {\n          pos +\u003d blockReader.skip(diff);\n          if (pos \u003d\u003d targetPos) {\n            done \u003d true;\n          }\n        } catch (IOException e) {//make following read to retry\n          if(DFSClient.LOG.isDebugEnabled()) {\n            DFSClient.LOG.debug(\"Exception while seek to \" + targetPos\n                + \" from \" + getCurrentBlock() + \" of \" + src\n                + \" from \" + currentNode + \": \"\n                + StringUtils.stringifyException(e));\n          }\n        }\n      }\n    }\n    if (!done) {\n      pos \u003d targetPos;\n      blockEnd \u003d -1;\n    }\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/DFSInputStream.java"
    }
  }
}