{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSImageFormat.java",
  "functionName": "saveFilesUnderConstruction",
  "functionId": "saveFilesUnderConstruction___fsn-FSNamesystem__out-DataOutputStream__snapshotUCMap-Map__Long,INodeFile__",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
  "functionStartLine": 1459,
  "functionEndLine": 1495,
  "numCommitsSeen": 672,
  "timeTaken": 17384,
  "changeHistory": [
    "00fe1ed3a4b3ee35fe24be257ec36445d2f44d63",
    "97f58955a6045b373ab73653bf26ab5922b00cf3"
  ],
  "changeHistoryShort": {
    "00fe1ed3a4b3ee35fe24be257ec36445d2f44d63": "Ymultichange(Ymovefromfile,Ybodychange,Yparameterchange)",
    "97f58955a6045b373ab73653bf26ab5922b00cf3": "Yintroduced"
  },
  "changeHistoryDetails": {
    "00fe1ed3a4b3ee35fe24be257ec36445d2f44d63": {
      "type": "Ymultichange(Ymovefromfile,Ybodychange,Yparameterchange)",
      "commitMessage": "HDFS-6757. Simplify lease manager with INodeID. Contributed by Haohui Mai.\n",
      "commitDate": "08/05/15 11:04 PM",
      "commitName": "00fe1ed3a4b3ee35fe24be257ec36445d2f44d63",
      "commitAuthor": "Haohui Mai",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-6757. Simplify lease manager with INodeID. Contributed by Haohui Mai.\n",
          "commitDate": "08/05/15 11:04 PM",
          "commitName": "00fe1ed3a4b3ee35fe24be257ec36445d2f44d63",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "08/05/15 8:01 PM",
          "commitNameOld": "6471d18bc72bc6c83ce31a03b5c5f5737847bb6d",
          "commitAuthorOld": "Xuan",
          "daysBetweenCommits": 0.13,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,32 +1,37 @@\n-  void saveFilesUnderConstruction(DataOutputStream out,\n-      Map\u003cLong, INodeFile\u003e snapshotUCMap) throws IOException {\n-    // This is run by an inferior thread of saveNamespace, which holds a read\n-    // lock on our behalf. If we took the read lock here, we could block\n-    // for fairness if a writer is waiting on the lock.\n-    synchronized (leaseManager) {\n-      Map\u003cString, INodeFile\u003e nodes \u003d leaseManager.getINodesUnderConstruction();\n-      for (Map.Entry\u003cString, INodeFile\u003e entry : nodes.entrySet()) {\n-        // TODO: for HDFS-5428, because of rename operations, some\n-        // under-construction files that are\n-        // in the current fs directory can also be captured in the\n-        // snapshotUCMap. We should remove them from the snapshotUCMap.\n-        snapshotUCMap.remove(entry.getValue().getId());\n-      }\n+    void saveFilesUnderConstruction(FSNamesystem fsn, DataOutputStream out,\n+                                    Map\u003cLong, INodeFile\u003e snapshotUCMap) throws IOException {\n+      // This is run by an inferior thread of saveNamespace, which holds a read\n+      // lock on our behalf. If we took the read lock here, we could block\n+      // for fairness if a writer is waiting on the lock.\n+      final LeaseManager leaseManager \u003d fsn.getLeaseManager();\n+      final FSDirectory dir \u003d fsn.getFSDirectory();\n+      synchronized (leaseManager) {\n+        Collection\u003cLong\u003e filesWithUC \u003d leaseManager.getINodeIdWithLeases();\n+        for (Long id : filesWithUC) {\n+          // TODO: for HDFS-5428, because of rename operations, some\n+          // under-construction files that are\n+          // in the current fs directory can also be captured in the\n+          // snapshotUCMap. We should remove them from the snapshotUCMap.\n+          snapshotUCMap.remove(id);\n+        }\n+        out.writeInt(filesWithUC.size() + snapshotUCMap.size()); // write the size\n \n-      out.writeInt(nodes.size() + snapshotUCMap.size()); // write the size\n-      for (Map.Entry\u003cString, INodeFile\u003e entry : nodes.entrySet()) {\n-        FSImageSerialization.writeINodeUnderConstruction(\n-            out, entry.getValue(), entry.getKey());\n+        for (Long id : filesWithUC) {\n+          INodeFile file \u003d dir.getInode(id).asFile();\n+          String path \u003d file.getFullPathName();\n+          FSImageSerialization.writeINodeUnderConstruction(\n+                  out, file, path);\n+        }\n+\n+        for (Map.Entry\u003cLong, INodeFile\u003e entry : snapshotUCMap.entrySet()) {\n+          // for those snapshot INodeFileUC, we use \"/.reserved/.inodes/\u003cinodeid\u003e\"\n+          // as their paths\n+          StringBuilder b \u003d new StringBuilder();\n+          b.append(FSDirectory.DOT_RESERVED_PATH_PREFIX)\n+                  .append(Path.SEPARATOR).append(FSDirectory.DOT_INODES_STRING)\n+                  .append(Path.SEPARATOR).append(entry.getValue().getId());\n+          FSImageSerialization.writeINodeUnderConstruction(\n+                  out, entry.getValue(), b.toString());\n+        }\n       }\n-      for (Map.Entry\u003cLong, INodeFile\u003e entry : snapshotUCMap.entrySet()) {\n-        // for those snapshot INodeFileUC, we use \"/.reserved/.inodes/\u003cinodeid\u003e\"\n-        // as their paths\n-        StringBuilder b \u003d new StringBuilder();\n-        b.append(FSDirectory.DOT_RESERVED_PATH_PREFIX)\n-            .append(Path.SEPARATOR).append(FSDirectory.DOT_INODES_STRING)\n-            .append(Path.SEPARATOR).append(entry.getValue().getId());\n-        FSImageSerialization.writeINodeUnderConstruction(\n-            out, entry.getValue(), b.toString());\n-      }\n-    }\n-  }\n\\ No newline at end of file\n+    }\n\\ No newline at end of file\n",
          "actualSource": "    void saveFilesUnderConstruction(FSNamesystem fsn, DataOutputStream out,\n                                    Map\u003cLong, INodeFile\u003e snapshotUCMap) throws IOException {\n      // This is run by an inferior thread of saveNamespace, which holds a read\n      // lock on our behalf. If we took the read lock here, we could block\n      // for fairness if a writer is waiting on the lock.\n      final LeaseManager leaseManager \u003d fsn.getLeaseManager();\n      final FSDirectory dir \u003d fsn.getFSDirectory();\n      synchronized (leaseManager) {\n        Collection\u003cLong\u003e filesWithUC \u003d leaseManager.getINodeIdWithLeases();\n        for (Long id : filesWithUC) {\n          // TODO: for HDFS-5428, because of rename operations, some\n          // under-construction files that are\n          // in the current fs directory can also be captured in the\n          // snapshotUCMap. We should remove them from the snapshotUCMap.\n          snapshotUCMap.remove(id);\n        }\n        out.writeInt(filesWithUC.size() + snapshotUCMap.size()); // write the size\n\n        for (Long id : filesWithUC) {\n          INodeFile file \u003d dir.getInode(id).asFile();\n          String path \u003d file.getFullPathName();\n          FSImageSerialization.writeINodeUnderConstruction(\n                  out, file, path);\n        }\n\n        for (Map.Entry\u003cLong, INodeFile\u003e entry : snapshotUCMap.entrySet()) {\n          // for those snapshot INodeFileUC, we use \"/.reserved/.inodes/\u003cinodeid\u003e\"\n          // as their paths\n          StringBuilder b \u003d new StringBuilder();\n          b.append(FSDirectory.DOT_RESERVED_PATH_PREFIX)\n                  .append(Path.SEPARATOR).append(FSDirectory.DOT_INODES_STRING)\n                  .append(Path.SEPARATOR).append(entry.getValue().getId());\n          FSImageSerialization.writeINodeUnderConstruction(\n                  out, entry.getValue(), b.toString());\n        }\n      }\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
            "oldMethodName": "saveFilesUnderConstruction",
            "newMethodName": "saveFilesUnderConstruction"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-6757. Simplify lease manager with INodeID. Contributed by Haohui Mai.\n",
          "commitDate": "08/05/15 11:04 PM",
          "commitName": "00fe1ed3a4b3ee35fe24be257ec36445d2f44d63",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "08/05/15 8:01 PM",
          "commitNameOld": "6471d18bc72bc6c83ce31a03b5c5f5737847bb6d",
          "commitAuthorOld": "Xuan",
          "daysBetweenCommits": 0.13,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,32 +1,37 @@\n-  void saveFilesUnderConstruction(DataOutputStream out,\n-      Map\u003cLong, INodeFile\u003e snapshotUCMap) throws IOException {\n-    // This is run by an inferior thread of saveNamespace, which holds a read\n-    // lock on our behalf. If we took the read lock here, we could block\n-    // for fairness if a writer is waiting on the lock.\n-    synchronized (leaseManager) {\n-      Map\u003cString, INodeFile\u003e nodes \u003d leaseManager.getINodesUnderConstruction();\n-      for (Map.Entry\u003cString, INodeFile\u003e entry : nodes.entrySet()) {\n-        // TODO: for HDFS-5428, because of rename operations, some\n-        // under-construction files that are\n-        // in the current fs directory can also be captured in the\n-        // snapshotUCMap. We should remove them from the snapshotUCMap.\n-        snapshotUCMap.remove(entry.getValue().getId());\n-      }\n+    void saveFilesUnderConstruction(FSNamesystem fsn, DataOutputStream out,\n+                                    Map\u003cLong, INodeFile\u003e snapshotUCMap) throws IOException {\n+      // This is run by an inferior thread of saveNamespace, which holds a read\n+      // lock on our behalf. If we took the read lock here, we could block\n+      // for fairness if a writer is waiting on the lock.\n+      final LeaseManager leaseManager \u003d fsn.getLeaseManager();\n+      final FSDirectory dir \u003d fsn.getFSDirectory();\n+      synchronized (leaseManager) {\n+        Collection\u003cLong\u003e filesWithUC \u003d leaseManager.getINodeIdWithLeases();\n+        for (Long id : filesWithUC) {\n+          // TODO: for HDFS-5428, because of rename operations, some\n+          // under-construction files that are\n+          // in the current fs directory can also be captured in the\n+          // snapshotUCMap. We should remove them from the snapshotUCMap.\n+          snapshotUCMap.remove(id);\n+        }\n+        out.writeInt(filesWithUC.size() + snapshotUCMap.size()); // write the size\n \n-      out.writeInt(nodes.size() + snapshotUCMap.size()); // write the size\n-      for (Map.Entry\u003cString, INodeFile\u003e entry : nodes.entrySet()) {\n-        FSImageSerialization.writeINodeUnderConstruction(\n-            out, entry.getValue(), entry.getKey());\n+        for (Long id : filesWithUC) {\n+          INodeFile file \u003d dir.getInode(id).asFile();\n+          String path \u003d file.getFullPathName();\n+          FSImageSerialization.writeINodeUnderConstruction(\n+                  out, file, path);\n+        }\n+\n+        for (Map.Entry\u003cLong, INodeFile\u003e entry : snapshotUCMap.entrySet()) {\n+          // for those snapshot INodeFileUC, we use \"/.reserved/.inodes/\u003cinodeid\u003e\"\n+          // as their paths\n+          StringBuilder b \u003d new StringBuilder();\n+          b.append(FSDirectory.DOT_RESERVED_PATH_PREFIX)\n+                  .append(Path.SEPARATOR).append(FSDirectory.DOT_INODES_STRING)\n+                  .append(Path.SEPARATOR).append(entry.getValue().getId());\n+          FSImageSerialization.writeINodeUnderConstruction(\n+                  out, entry.getValue(), b.toString());\n+        }\n       }\n-      for (Map.Entry\u003cLong, INodeFile\u003e entry : snapshotUCMap.entrySet()) {\n-        // for those snapshot INodeFileUC, we use \"/.reserved/.inodes/\u003cinodeid\u003e\"\n-        // as their paths\n-        StringBuilder b \u003d new StringBuilder();\n-        b.append(FSDirectory.DOT_RESERVED_PATH_PREFIX)\n-            .append(Path.SEPARATOR).append(FSDirectory.DOT_INODES_STRING)\n-            .append(Path.SEPARATOR).append(entry.getValue().getId());\n-        FSImageSerialization.writeINodeUnderConstruction(\n-            out, entry.getValue(), b.toString());\n-      }\n-    }\n-  }\n\\ No newline at end of file\n+    }\n\\ No newline at end of file\n",
          "actualSource": "    void saveFilesUnderConstruction(FSNamesystem fsn, DataOutputStream out,\n                                    Map\u003cLong, INodeFile\u003e snapshotUCMap) throws IOException {\n      // This is run by an inferior thread of saveNamespace, which holds a read\n      // lock on our behalf. If we took the read lock here, we could block\n      // for fairness if a writer is waiting on the lock.\n      final LeaseManager leaseManager \u003d fsn.getLeaseManager();\n      final FSDirectory dir \u003d fsn.getFSDirectory();\n      synchronized (leaseManager) {\n        Collection\u003cLong\u003e filesWithUC \u003d leaseManager.getINodeIdWithLeases();\n        for (Long id : filesWithUC) {\n          // TODO: for HDFS-5428, because of rename operations, some\n          // under-construction files that are\n          // in the current fs directory can also be captured in the\n          // snapshotUCMap. We should remove them from the snapshotUCMap.\n          snapshotUCMap.remove(id);\n        }\n        out.writeInt(filesWithUC.size() + snapshotUCMap.size()); // write the size\n\n        for (Long id : filesWithUC) {\n          INodeFile file \u003d dir.getInode(id).asFile();\n          String path \u003d file.getFullPathName();\n          FSImageSerialization.writeINodeUnderConstruction(\n                  out, file, path);\n        }\n\n        for (Map.Entry\u003cLong, INodeFile\u003e entry : snapshotUCMap.entrySet()) {\n          // for those snapshot INodeFileUC, we use \"/.reserved/.inodes/\u003cinodeid\u003e\"\n          // as their paths\n          StringBuilder b \u003d new StringBuilder();\n          b.append(FSDirectory.DOT_RESERVED_PATH_PREFIX)\n                  .append(Path.SEPARATOR).append(FSDirectory.DOT_INODES_STRING)\n                  .append(Path.SEPARATOR).append(entry.getValue().getId());\n          FSImageSerialization.writeINodeUnderConstruction(\n                  out, entry.getValue(), b.toString());\n        }\n      }\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
          "extendedDetails": {}
        },
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-6757. Simplify lease manager with INodeID. Contributed by Haohui Mai.\n",
          "commitDate": "08/05/15 11:04 PM",
          "commitName": "00fe1ed3a4b3ee35fe24be257ec36445d2f44d63",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "08/05/15 8:01 PM",
          "commitNameOld": "6471d18bc72bc6c83ce31a03b5c5f5737847bb6d",
          "commitAuthorOld": "Xuan",
          "daysBetweenCommits": 0.13,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,32 +1,37 @@\n-  void saveFilesUnderConstruction(DataOutputStream out,\n-      Map\u003cLong, INodeFile\u003e snapshotUCMap) throws IOException {\n-    // This is run by an inferior thread of saveNamespace, which holds a read\n-    // lock on our behalf. If we took the read lock here, we could block\n-    // for fairness if a writer is waiting on the lock.\n-    synchronized (leaseManager) {\n-      Map\u003cString, INodeFile\u003e nodes \u003d leaseManager.getINodesUnderConstruction();\n-      for (Map.Entry\u003cString, INodeFile\u003e entry : nodes.entrySet()) {\n-        // TODO: for HDFS-5428, because of rename operations, some\n-        // under-construction files that are\n-        // in the current fs directory can also be captured in the\n-        // snapshotUCMap. We should remove them from the snapshotUCMap.\n-        snapshotUCMap.remove(entry.getValue().getId());\n-      }\n+    void saveFilesUnderConstruction(FSNamesystem fsn, DataOutputStream out,\n+                                    Map\u003cLong, INodeFile\u003e snapshotUCMap) throws IOException {\n+      // This is run by an inferior thread of saveNamespace, which holds a read\n+      // lock on our behalf. If we took the read lock here, we could block\n+      // for fairness if a writer is waiting on the lock.\n+      final LeaseManager leaseManager \u003d fsn.getLeaseManager();\n+      final FSDirectory dir \u003d fsn.getFSDirectory();\n+      synchronized (leaseManager) {\n+        Collection\u003cLong\u003e filesWithUC \u003d leaseManager.getINodeIdWithLeases();\n+        for (Long id : filesWithUC) {\n+          // TODO: for HDFS-5428, because of rename operations, some\n+          // under-construction files that are\n+          // in the current fs directory can also be captured in the\n+          // snapshotUCMap. We should remove them from the snapshotUCMap.\n+          snapshotUCMap.remove(id);\n+        }\n+        out.writeInt(filesWithUC.size() + snapshotUCMap.size()); // write the size\n \n-      out.writeInt(nodes.size() + snapshotUCMap.size()); // write the size\n-      for (Map.Entry\u003cString, INodeFile\u003e entry : nodes.entrySet()) {\n-        FSImageSerialization.writeINodeUnderConstruction(\n-            out, entry.getValue(), entry.getKey());\n+        for (Long id : filesWithUC) {\n+          INodeFile file \u003d dir.getInode(id).asFile();\n+          String path \u003d file.getFullPathName();\n+          FSImageSerialization.writeINodeUnderConstruction(\n+                  out, file, path);\n+        }\n+\n+        for (Map.Entry\u003cLong, INodeFile\u003e entry : snapshotUCMap.entrySet()) {\n+          // for those snapshot INodeFileUC, we use \"/.reserved/.inodes/\u003cinodeid\u003e\"\n+          // as their paths\n+          StringBuilder b \u003d new StringBuilder();\n+          b.append(FSDirectory.DOT_RESERVED_PATH_PREFIX)\n+                  .append(Path.SEPARATOR).append(FSDirectory.DOT_INODES_STRING)\n+                  .append(Path.SEPARATOR).append(entry.getValue().getId());\n+          FSImageSerialization.writeINodeUnderConstruction(\n+                  out, entry.getValue(), b.toString());\n+        }\n       }\n-      for (Map.Entry\u003cLong, INodeFile\u003e entry : snapshotUCMap.entrySet()) {\n-        // for those snapshot INodeFileUC, we use \"/.reserved/.inodes/\u003cinodeid\u003e\"\n-        // as their paths\n-        StringBuilder b \u003d new StringBuilder();\n-        b.append(FSDirectory.DOT_RESERVED_PATH_PREFIX)\n-            .append(Path.SEPARATOR).append(FSDirectory.DOT_INODES_STRING)\n-            .append(Path.SEPARATOR).append(entry.getValue().getId());\n-        FSImageSerialization.writeINodeUnderConstruction(\n-            out, entry.getValue(), b.toString());\n-      }\n-    }\n-  }\n\\ No newline at end of file\n+    }\n\\ No newline at end of file\n",
          "actualSource": "    void saveFilesUnderConstruction(FSNamesystem fsn, DataOutputStream out,\n                                    Map\u003cLong, INodeFile\u003e snapshotUCMap) throws IOException {\n      // This is run by an inferior thread of saveNamespace, which holds a read\n      // lock on our behalf. If we took the read lock here, we could block\n      // for fairness if a writer is waiting on the lock.\n      final LeaseManager leaseManager \u003d fsn.getLeaseManager();\n      final FSDirectory dir \u003d fsn.getFSDirectory();\n      synchronized (leaseManager) {\n        Collection\u003cLong\u003e filesWithUC \u003d leaseManager.getINodeIdWithLeases();\n        for (Long id : filesWithUC) {\n          // TODO: for HDFS-5428, because of rename operations, some\n          // under-construction files that are\n          // in the current fs directory can also be captured in the\n          // snapshotUCMap. We should remove them from the snapshotUCMap.\n          snapshotUCMap.remove(id);\n        }\n        out.writeInt(filesWithUC.size() + snapshotUCMap.size()); // write the size\n\n        for (Long id : filesWithUC) {\n          INodeFile file \u003d dir.getInode(id).asFile();\n          String path \u003d file.getFullPathName();\n          FSImageSerialization.writeINodeUnderConstruction(\n                  out, file, path);\n        }\n\n        for (Map.Entry\u003cLong, INodeFile\u003e entry : snapshotUCMap.entrySet()) {\n          // for those snapshot INodeFileUC, we use \"/.reserved/.inodes/\u003cinodeid\u003e\"\n          // as their paths\n          StringBuilder b \u003d new StringBuilder();\n          b.append(FSDirectory.DOT_RESERVED_PATH_PREFIX)\n                  .append(Path.SEPARATOR).append(FSDirectory.DOT_INODES_STRING)\n                  .append(Path.SEPARATOR).append(entry.getValue().getId());\n          FSImageSerialization.writeINodeUnderConstruction(\n                  out, entry.getValue(), b.toString());\n        }\n      }\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
          "extendedDetails": {
            "oldValue": "[out-DataOutputStream, snapshotUCMap-Map\u003cLong,INodeFile\u003e]",
            "newValue": "[fsn-FSNamesystem, out-DataOutputStream, snapshotUCMap-Map\u003cLong,INodeFile\u003e]"
          }
        }
      ]
    },
    "97f58955a6045b373ab73653bf26ab5922b00cf3": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-6293. Issues with OIV processing PB-based fsimages. Contributed by Kihwal Lee.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1594439 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/05/14 6:15 PM",
      "commitName": "97f58955a6045b373ab73653bf26ab5922b00cf3",
      "commitAuthor": "Kihwal Lee",
      "diff": "@@ -0,0 +1,32 @@\n+  void saveFilesUnderConstruction(DataOutputStream out,\n+      Map\u003cLong, INodeFile\u003e snapshotUCMap) throws IOException {\n+    // This is run by an inferior thread of saveNamespace, which holds a read\n+    // lock on our behalf. If we took the read lock here, we could block\n+    // for fairness if a writer is waiting on the lock.\n+    synchronized (leaseManager) {\n+      Map\u003cString, INodeFile\u003e nodes \u003d leaseManager.getINodesUnderConstruction();\n+      for (Map.Entry\u003cString, INodeFile\u003e entry : nodes.entrySet()) {\n+        // TODO: for HDFS-5428, because of rename operations, some\n+        // under-construction files that are\n+        // in the current fs directory can also be captured in the\n+        // snapshotUCMap. We should remove them from the snapshotUCMap.\n+        snapshotUCMap.remove(entry.getValue().getId());\n+      }\n+\n+      out.writeInt(nodes.size() + snapshotUCMap.size()); // write the size\n+      for (Map.Entry\u003cString, INodeFile\u003e entry : nodes.entrySet()) {\n+        FSImageSerialization.writeINodeUnderConstruction(\n+            out, entry.getValue(), entry.getKey());\n+      }\n+      for (Map.Entry\u003cLong, INodeFile\u003e entry : snapshotUCMap.entrySet()) {\n+        // for those snapshot INodeFileUC, we use \"/.reserved/.inodes/\u003cinodeid\u003e\"\n+        // as their paths\n+        StringBuilder b \u003d new StringBuilder();\n+        b.append(FSDirectory.DOT_RESERVED_PATH_PREFIX)\n+            .append(Path.SEPARATOR).append(FSDirectory.DOT_INODES_STRING)\n+            .append(Path.SEPARATOR).append(entry.getValue().getId());\n+        FSImageSerialization.writeINodeUnderConstruction(\n+            out, entry.getValue(), b.toString());\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  void saveFilesUnderConstruction(DataOutputStream out,\n      Map\u003cLong, INodeFile\u003e snapshotUCMap) throws IOException {\n    // This is run by an inferior thread of saveNamespace, which holds a read\n    // lock on our behalf. If we took the read lock here, we could block\n    // for fairness if a writer is waiting on the lock.\n    synchronized (leaseManager) {\n      Map\u003cString, INodeFile\u003e nodes \u003d leaseManager.getINodesUnderConstruction();\n      for (Map.Entry\u003cString, INodeFile\u003e entry : nodes.entrySet()) {\n        // TODO: for HDFS-5428, because of rename operations, some\n        // under-construction files that are\n        // in the current fs directory can also be captured in the\n        // snapshotUCMap. We should remove them from the snapshotUCMap.\n        snapshotUCMap.remove(entry.getValue().getId());\n      }\n\n      out.writeInt(nodes.size() + snapshotUCMap.size()); // write the size\n      for (Map.Entry\u003cString, INodeFile\u003e entry : nodes.entrySet()) {\n        FSImageSerialization.writeINodeUnderConstruction(\n            out, entry.getValue(), entry.getKey());\n      }\n      for (Map.Entry\u003cLong, INodeFile\u003e entry : snapshotUCMap.entrySet()) {\n        // for those snapshot INodeFileUC, we use \"/.reserved/.inodes/\u003cinodeid\u003e\"\n        // as their paths\n        StringBuilder b \u003d new StringBuilder();\n        b.append(FSDirectory.DOT_RESERVED_PATH_PREFIX)\n            .append(Path.SEPARATOR).append(FSDirectory.DOT_INODES_STRING)\n            .append(Path.SEPARATOR).append(entry.getValue().getId());\n        FSImageSerialization.writeINodeUnderConstruction(\n            out, entry.getValue(), b.toString());\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java"
    }
  }
}