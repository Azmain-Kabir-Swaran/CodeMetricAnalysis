{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "S3AFileSystem.java",
  "functionName": "finishedWrite",
  "functionId": "finishedWrite___key-String__length-long__eTag-String__versionId-String__operationState-BulkOperationState(annotations-@Nullable__modifiers-final)",
  "sourceFilePath": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java",
  "functionStartLine": 3648,
  "functionEndLine": 3719,
  "numCommitsSeen": 421,
  "timeTaken": 11110,
  "changeHistory": [
    "56dee667707926f3796c7757be1a133a362f05c9",
    "7f40e6688a5716fca53e1090d8347a43064d6d43",
    "49df83899543586bbcaf80f01399ade031cf68b0",
    "e02eb24e0a9139418120027b694492e0738df20a",
    "f9cc9e162175444efe9d5b07ecb9a795f750ca3c",
    "a36274d69947648dbe82721220cc5240ec5d396d",
    "0af4011580878566213016af0c32633eabd15100",
    "a0c71dcc33ca7c5539d0ab61c4a276c4f39e5744",
    "621b43e254afaff708cd6fc4698b29628f6abc33",
    "c58a59f7081d55dd2108545ebf9ee48cf43ca944",
    "39ec1515a205952eda7e171408a8b83eceb4abde",
    "24d920b80eb3626073925a1d0b6dcf148add8cc0"
  ],
  "changeHistoryShort": {
    "56dee667707926f3796c7757be1a133a362f05c9": "Ybodychange",
    "7f40e6688a5716fca53e1090d8347a43064d6d43": "Ybodychange",
    "49df83899543586bbcaf80f01399ade031cf68b0": "Ybodychange",
    "e02eb24e0a9139418120027b694492e0738df20a": "Ymultichange(Yparameterchange,Ybodychange)",
    "f9cc9e162175444efe9d5b07ecb9a795f750ca3c": "Ybodychange",
    "a36274d69947648dbe82721220cc5240ec5d396d": "Ymultichange(Yparameterchange,Ybodychange)",
    "0af4011580878566213016af0c32633eabd15100": "Ymultichange(Yexceptionschange,Ybodychange)",
    "a0c71dcc33ca7c5539d0ab61c4a276c4f39e5744": "Ybodychange",
    "621b43e254afaff708cd6fc4698b29628f6abc33": "Ymultichange(Yparameterchange,Ymodifierchange,Ybodychange)",
    "c58a59f7081d55dd2108545ebf9ee48cf43ca944": "Ybodychange",
    "39ec1515a205952eda7e171408a8b83eceb4abde": "Yexceptionschange",
    "24d920b80eb3626073925a1d0b6dcf148add8cc0": "Yintroduced"
  },
  "changeHistoryDetails": {
    "56dee667707926f3796c7757be1a133a362f05c9": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-16823. Large DeleteObject requests are their own Thundering Herd.\n\nContributed by Steve Loughran.\n\nDuring S3A rename() and delete() calls, the list of objects delete is\nbuilt up into batches of a thousand and then POSTed in a single large\nDeleteObjects request.\n\nBut as the IO capacity allowed on an S3 partition may only be 3500 writes\nper second *and* each entry in that POST counts as a single write, then\none of those posts alone can trigger throttling on an already loaded\nS3 directory tree. Which can trigger backoff and retry, with the same\nthousand entry post, and so recreate the exact same problem.\n\nFixes\n\n* Page size for delete object requests is set in\n  fs.s3a.bulk.delete.page.size; the default is 250.\n* The property fs.s3a.experimental.aws.s3.throttling (default\u003dtrue)\n  can be set to false to disable throttle retry logic in the AWS\n  client SDK -it is all handled in the S3A client. This\n  gives more visibility in to when operations are being throttled\n* Bulk delete throttling events are logged to the log\n  org.apache.hadoop.fs.s3a.throttled log at INFO; if this appears\n  often then choose a smaller page size.\n* The metric \"store_io_throttled\" adds the entire count of delete\n  requests when a single DeleteObjects request is throttled.\n* A new quantile, \"store_io_throttle_rate\" can track throttling\n  load over time.\n* DynamoDB metastore throttle resilience issues have also been\n  identified and fixed. Note: the fs.s3a.experimental.aws.s3.throttling\n  flag does not apply to DDB IO precisely because there may still be\n  lurking issues there and it safest to rely on the DynamoDB client\n  SDK.\n\nChange-Id: I00f85cdd94fc008864d060533f6bd4870263fd84\n",
      "commitDate": "13/02/20 11:09 AM",
      "commitName": "56dee667707926f3796c7757be1a133a362f05c9",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "30/01/20 2:16 AM",
      "commitNameOld": "5977360878e6780bd04842c8a2156f9848e1d088",
      "commitAuthorOld": "Mustafa Ä°man",
      "daysBetweenCommits": 14.37,
      "commitsBetweenForRepo": 35,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,62 +1,72 @@\n   void finishedWrite(String key, long length, String eTag, String versionId,\n       @Nullable final BulkOperationState operationState)\n       throws MetadataPersistenceException {\n     LOG.debug(\"Finished write to {}, len {}. etag {}, version {}\",\n         key, length, eTag, versionId);\n     Path p \u003d keyToQualifiedPath(key);\n     Preconditions.checkArgument(length \u003e\u003d 0, \"content length is negative\");\n-    deleteUnnecessaryFakeDirectories(p.getParent());\n+    final boolean isDir \u003d objectRepresentsDirectory(key, length);\n+    // kick off an async delete\n+    final CompletableFuture\u003c?\u003e deletion \u003d submit(\n+        unboundedThreadPool,\n+        () -\u003e {\n+          deleteUnnecessaryFakeDirectories(p.getParent());\n+          return null;\n+        });\n     // this is only set if there is a metastore to update and the\n     // operationState parameter passed in was null.\n     BulkOperationState stateToClose \u003d null;\n \n     // See note about failure semantics in S3Guard documentation\n     try {\n       if (hasMetadataStore()) {\n         BulkOperationState activeState \u003d operationState;\n         if (activeState \u003d\u003d null) {\n           // create an operation state if there was none, so that the\n           // information gleaned from addAncestors is preserved into the\n           // subsequent put.\n           stateToClose \u003d S3Guard.initiateBulkWrite(metadataStore,\n-              BulkOperationState.OperationType.Mkdir,\n+              isDir\n+                  ? BulkOperationState.OperationType.Mkdir\n+                  : BulkOperationState.OperationType.Put,\n               keyToPath(key));\n           activeState \u003d stateToClose;\n         }\n         S3Guard.addAncestors(metadataStore, p, ttlTimeProvider, activeState);\n-        final boolean isDir \u003d objectRepresentsDirectory(key, length);\n         S3AFileStatus status \u003d createUploadFileStatus(p,\n             isDir, length,\n             getDefaultBlockSize(p), username, eTag, versionId);\n         boolean authoritative \u003d false;\n         if (isDir) {\n           // this is a directory marker so put it as such.\n           status.setIsEmptyDirectory(Tristate.TRUE);\n           // and maybe mark as auth\n           authoritative \u003d allowAuthoritative(p);\n         }\n         if (!authoritative) {\n           // for files and non-auth directories\n           S3Guard.putAndReturn(metadataStore, status,\n               ttlTimeProvider,\n               activeState);\n         } else {\n           // authoritative directory\n           S3Guard.putAuthDirectoryMarker(metadataStore, status,\n               ttlTimeProvider,\n               activeState);\n         }\n       }\n+      // and catch up with any delete operation.\n+      waitForCompletionIgnoringExceptions(deletion);\n     } catch (IOException e) {\n       if (failOnMetadataWriteError) {\n         throw new MetadataPersistenceException(p.toString(), e);\n       } else {\n         LOG.error(\"S3Guard: Error updating MetadataStore for write to {}\",\n             p, e);\n       }\n       instrumentation.errorIgnored();\n     } finally {\n       // if a new operation state was created, close it.\n       IOUtils.cleanupWithLogger(LOG, stateToClose);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void finishedWrite(String key, long length, String eTag, String versionId,\n      @Nullable final BulkOperationState operationState)\n      throws MetadataPersistenceException {\n    LOG.debug(\"Finished write to {}, len {}. etag {}, version {}\",\n        key, length, eTag, versionId);\n    Path p \u003d keyToQualifiedPath(key);\n    Preconditions.checkArgument(length \u003e\u003d 0, \"content length is negative\");\n    final boolean isDir \u003d objectRepresentsDirectory(key, length);\n    // kick off an async delete\n    final CompletableFuture\u003c?\u003e deletion \u003d submit(\n        unboundedThreadPool,\n        () -\u003e {\n          deleteUnnecessaryFakeDirectories(p.getParent());\n          return null;\n        });\n    // this is only set if there is a metastore to update and the\n    // operationState parameter passed in was null.\n    BulkOperationState stateToClose \u003d null;\n\n    // See note about failure semantics in S3Guard documentation\n    try {\n      if (hasMetadataStore()) {\n        BulkOperationState activeState \u003d operationState;\n        if (activeState \u003d\u003d null) {\n          // create an operation state if there was none, so that the\n          // information gleaned from addAncestors is preserved into the\n          // subsequent put.\n          stateToClose \u003d S3Guard.initiateBulkWrite(metadataStore,\n              isDir\n                  ? BulkOperationState.OperationType.Mkdir\n                  : BulkOperationState.OperationType.Put,\n              keyToPath(key));\n          activeState \u003d stateToClose;\n        }\n        S3Guard.addAncestors(metadataStore, p, ttlTimeProvider, activeState);\n        S3AFileStatus status \u003d createUploadFileStatus(p,\n            isDir, length,\n            getDefaultBlockSize(p), username, eTag, versionId);\n        boolean authoritative \u003d false;\n        if (isDir) {\n          // this is a directory marker so put it as such.\n          status.setIsEmptyDirectory(Tristate.TRUE);\n          // and maybe mark as auth\n          authoritative \u003d allowAuthoritative(p);\n        }\n        if (!authoritative) {\n          // for files and non-auth directories\n          S3Guard.putAndReturn(metadataStore, status,\n              ttlTimeProvider,\n              activeState);\n        } else {\n          // authoritative directory\n          S3Guard.putAuthDirectoryMarker(metadataStore, status,\n              ttlTimeProvider,\n              activeState);\n        }\n      }\n      // and catch up with any delete operation.\n      waitForCompletionIgnoringExceptions(deletion);\n    } catch (IOException e) {\n      if (failOnMetadataWriteError) {\n        throw new MetadataPersistenceException(p.toString(), e);\n      } else {\n        LOG.error(\"S3Guard: Error updating MetadataStore for write to {}\",\n            p, e);\n      }\n      instrumentation.errorIgnored();\n    } finally {\n      // if a new operation state was created, close it.\n      IOUtils.cleanupWithLogger(LOG, stateToClose);\n    }\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java",
      "extendedDetails": {}
    },
    "7f40e6688a5716fca53e1090d8347a43064d6d43": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-16746. mkdirs and s3guard Authoritative mode.\n\nContributed by Steve Loughran.\n\nThis fixes two problems with S3Guard authoritative mode and\nthe auth directory flags which are stored in DynamoDB.\n\n1. mkdirs was creating dir markers without the auth bit,\n   forcing needless scans on newly created directories and\n   files subsequently added; it was only with the first listStatus call\n   on that directory that the dir would be marked as authoritative -even\n   though it would be complete already.\n\n2. listStatus(path) would reset the authoritative status bit of all\n   child directories even if they were already marked as authoritative.\n\nIssue #2 is possibly the most expensive, as any treewalk using listStatus\n(e.g globfiles) would clear the auth bit for all child directories before\nlisting them. And this would happen every single time...\nessentially you weren\u0027t getting authoritative directory listings.\n\nFor the curious, that the major bug was actually found during testing\n-we\u0027d all missed it during reviews.\n\nA lesson there: the better the tests the fewer the bugs.\n\nMaybe also: something obvious and significant can get by code reviews.\n\n\tmodified:   hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java\n\tmodified:   hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/s3guard/BulkOperationState.java\n\tmodified:   hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/s3guard/DynamoDBMetadataStore.java\n\tmodified:   hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/s3guard/LocalMetadataStore.java\n\tmodified:   hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/s3guard/MetadataStore.java\n\tmodified:   hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/s3guard/NullMetadataStore.java\n\tmodified:   hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/s3guard/S3Guard.java\n\tmodified:   hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3GuardWriteBack.java\n\tmodified:   hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/auth/ITestRestrictedReadAccess.java\n\tmodified:   hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/impl/TestPartialDeleteFailures.java\n\tmodified:   hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/s3guard/ITestDynamoDBMetadataStore.java\n\tmodified:   hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/s3guard/ITestDynamoDBMetadataStoreAuthoritativeMode.java\n\tmodified:   hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/s3guard/ITestDynamoDBMetadataStoreScale.java\n\tmodified:   hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/s3guard/ITestS3GuardFsck.java\n\tmodified:   hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/s3guard/MetadataStoreTestBase.java\n\tmodified:   hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/s3guard/TestS3Guard.java\n\nChange-Id: Ic3ffda13f2af2430afedd50fd657b595c83e90a7\n",
      "commitDate": "25/01/20 10:35 AM",
      "commitName": "7f40e6688a5716fca53e1090d8347a43064d6d43",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "21/01/20 2:31 PM",
      "commitNameOld": "5e2ce370a322a46b496541ccd17443197fcfeb5a",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 3.84,
      "commitsBetweenForRepo": 13,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,55 +1,62 @@\n   void finishedWrite(String key, long length, String eTag, String versionId,\n       @Nullable final BulkOperationState operationState)\n       throws MetadataPersistenceException {\n     LOG.debug(\"Finished write to {}, len {}. etag {}, version {}\",\n         key, length, eTag, versionId);\n     Path p \u003d keyToQualifiedPath(key);\n     Preconditions.checkArgument(length \u003e\u003d 0, \"content length is negative\");\n     deleteUnnecessaryFakeDirectories(p.getParent());\n     // this is only set if there is a metastore to update and the\n     // operationState parameter passed in was null.\n     BulkOperationState stateToClose \u003d null;\n \n     // See note about failure semantics in S3Guard documentation\n     try {\n       if (hasMetadataStore()) {\n         BulkOperationState activeState \u003d operationState;\n         if (activeState \u003d\u003d null) {\n           // create an operation state if there was none, so that the\n           // information gleaned from addAncestors is preserved into the\n           // subsequent put.\n           stateToClose \u003d S3Guard.initiateBulkWrite(metadataStore,\n-              BulkOperationState.OperationType.Put,\n+              BulkOperationState.OperationType.Mkdir,\n               keyToPath(key));\n           activeState \u003d stateToClose;\n         }\n         S3Guard.addAncestors(metadataStore, p, ttlTimeProvider, activeState);\n         final boolean isDir \u003d objectRepresentsDirectory(key, length);\n         S3AFileStatus status \u003d createUploadFileStatus(p,\n             isDir, length,\n             getDefaultBlockSize(p), username, eTag, versionId);\n-        if (!isDir) {\n+        boolean authoritative \u003d false;\n+        if (isDir) {\n+          // this is a directory marker so put it as such.\n+          status.setIsEmptyDirectory(Tristate.TRUE);\n+          // and maybe mark as auth\n+          authoritative \u003d allowAuthoritative(p);\n+        }\n+        if (!authoritative) {\n+          // for files and non-auth directories\n           S3Guard.putAndReturn(metadataStore, status,\n               ttlTimeProvider,\n               activeState);\n         } else {\n-          // this is a directory marker so put it as such.\n-          status.setIsEmptyDirectory(Tristate.TRUE);\n+          // authoritative directory\n           S3Guard.putAuthDirectoryMarker(metadataStore, status,\n               ttlTimeProvider,\n               activeState);\n         }\n       }\n     } catch (IOException e) {\n       if (failOnMetadataWriteError) {\n         throw new MetadataPersistenceException(p.toString(), e);\n       } else {\n         LOG.error(\"S3Guard: Error updating MetadataStore for write to {}\",\n             p, e);\n       }\n       instrumentation.errorIgnored();\n     } finally {\n       // if a new operation state was created, close it.\n       IOUtils.cleanupWithLogger(LOG, stateToClose);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void finishedWrite(String key, long length, String eTag, String versionId,\n      @Nullable final BulkOperationState operationState)\n      throws MetadataPersistenceException {\n    LOG.debug(\"Finished write to {}, len {}. etag {}, version {}\",\n        key, length, eTag, versionId);\n    Path p \u003d keyToQualifiedPath(key);\n    Preconditions.checkArgument(length \u003e\u003d 0, \"content length is negative\");\n    deleteUnnecessaryFakeDirectories(p.getParent());\n    // this is only set if there is a metastore to update and the\n    // operationState parameter passed in was null.\n    BulkOperationState stateToClose \u003d null;\n\n    // See note about failure semantics in S3Guard documentation\n    try {\n      if (hasMetadataStore()) {\n        BulkOperationState activeState \u003d operationState;\n        if (activeState \u003d\u003d null) {\n          // create an operation state if there was none, so that the\n          // information gleaned from addAncestors is preserved into the\n          // subsequent put.\n          stateToClose \u003d S3Guard.initiateBulkWrite(metadataStore,\n              BulkOperationState.OperationType.Mkdir,\n              keyToPath(key));\n          activeState \u003d stateToClose;\n        }\n        S3Guard.addAncestors(metadataStore, p, ttlTimeProvider, activeState);\n        final boolean isDir \u003d objectRepresentsDirectory(key, length);\n        S3AFileStatus status \u003d createUploadFileStatus(p,\n            isDir, length,\n            getDefaultBlockSize(p), username, eTag, versionId);\n        boolean authoritative \u003d false;\n        if (isDir) {\n          // this is a directory marker so put it as such.\n          status.setIsEmptyDirectory(Tristate.TRUE);\n          // and maybe mark as auth\n          authoritative \u003d allowAuthoritative(p);\n        }\n        if (!authoritative) {\n          // for files and non-auth directories\n          S3Guard.putAndReturn(metadataStore, status,\n              ttlTimeProvider,\n              activeState);\n        } else {\n          // authoritative directory\n          S3Guard.putAuthDirectoryMarker(metadataStore, status,\n              ttlTimeProvider,\n              activeState);\n        }\n      }\n    } catch (IOException e) {\n      if (failOnMetadataWriteError) {\n        throw new MetadataPersistenceException(p.toString(), e);\n      } else {\n        LOG.error(\"S3Guard: Error updating MetadataStore for write to {}\",\n            p, e);\n      }\n      instrumentation.errorIgnored();\n    } finally {\n      // if a new operation state was created, close it.\n      IOUtils.cleanupWithLogger(LOG, stateToClose);\n    }\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java",
      "extendedDetails": {}
    },
    "49df83899543586bbcaf80f01399ade031cf68b0": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-16697. Tune/audit S3A authoritative mode.\n\nContains:\n\nHADOOP-16474. S3Guard ProgressiveRenameTracker to mark destination\n              dirirectory as authoritative on success.\nHADOOP-16684. S3guard bucket info to list a bit more about\n              authoritative paths.\nHADOOP-16722. S3GuardTool to support FilterFileSystem.\n\nThis patch improves the marking of newly created/import directory\ntrees in S3Guard DynamoDB tables as authoritative.\n\nSpecific changes:\n\n * Renamed directories are marked as authoritative if the entire\n   operation succeeded (HADOOP-16474).\n * When updating parent table entries as part of any table write,\n   there\u0027s no overwriting of their authoritative flag.\n\ns3guard import changes:\n\n* new -verbose flag to print out what is going on.\n\n* The \"s3guard import\" command lets you declare that a directory tree\nis to be marked as authoritative\n\n  hadoop s3guard import -authoritative -verbose s3a://bucket/path\n\nWhen importing a listing and a file is found, the import tool queries\nthe metastore and only updates the entry if the file is different from\nbefore, where different \u003d\u003d new timestamp, etag, or length. S3Guard can get\ntimestamp differences due to clock skew in PUT operations.\n\nAs the recursive list performed by the import command doesn\u0027t retrieve the\nversionID, the existing entry may in fact be more complete.\nWhen updating an existing due to clock skew the existing version ID\nis propagated to the new entry (note: the etags must match; this is needed\nto deal with inconsistent listings).\n\nThere is a new s3guard command to audit a s3guard bucket/path\u0027s\nauthoritative state:\n\n  hadoop s3guard authoritative -check-config s3a://bucket/path\n\nThis is primarily for testing/auditing.\n\nThe s3guard bucket-info command also provides some more details on the\nauthoritative state of a store (HADOOP-16684).\n\nChange-Id: I58001341c04f6f3597fcb4fcb1581ccefeb77d91\n",
      "commitDate": "10/01/20 3:11 AM",
      "commitName": "49df83899543586bbcaf80f01399ade031cf68b0",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "07/01/20 3:17 AM",
      "commitNameOld": "2bbf73f1df96ebe7e6fcf64a724ae846230a8487",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 3.0,
      "commitsBetweenForRepo": 25,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,47 +1,55 @@\n   void finishedWrite(String key, long length, String eTag, String versionId,\n       @Nullable final BulkOperationState operationState)\n       throws MetadataPersistenceException {\n     LOG.debug(\"Finished write to {}, len {}. etag {}, version {}\",\n         key, length, eTag, versionId);\n     Path p \u003d keyToQualifiedPath(key);\n     Preconditions.checkArgument(length \u003e\u003d 0, \"content length is negative\");\n     deleteUnnecessaryFakeDirectories(p.getParent());\n     // this is only set if there is a metastore to update and the\n     // operationState parameter passed in was null.\n     BulkOperationState stateToClose \u003d null;\n \n     // See note about failure semantics in S3Guard documentation\n     try {\n       if (hasMetadataStore()) {\n         BulkOperationState activeState \u003d operationState;\n         if (activeState \u003d\u003d null) {\n           // create an operation state if there was none, so that the\n           // information gleaned from addAncestors is preserved into the\n           // subsequent put.\n           stateToClose \u003d S3Guard.initiateBulkWrite(metadataStore,\n               BulkOperationState.OperationType.Put,\n               keyToPath(key));\n           activeState \u003d stateToClose;\n         }\n         S3Guard.addAncestors(metadataStore, p, ttlTimeProvider, activeState);\n+        final boolean isDir \u003d objectRepresentsDirectory(key, length);\n         S3AFileStatus status \u003d createUploadFileStatus(p,\n-            S3AUtils.objectRepresentsDirectory(key, length), length,\n+            isDir, length,\n             getDefaultBlockSize(p), username, eTag, versionId);\n-        S3Guard.putAndReturn(metadataStore, status,\n-            instrumentation,\n-            ttlTimeProvider,\n-            activeState);\n+        if (!isDir) {\n+          S3Guard.putAndReturn(metadataStore, status,\n+              ttlTimeProvider,\n+              activeState);\n+        } else {\n+          // this is a directory marker so put it as such.\n+          status.setIsEmptyDirectory(Tristate.TRUE);\n+          S3Guard.putAuthDirectoryMarker(metadataStore, status,\n+              ttlTimeProvider,\n+              activeState);\n+        }\n       }\n     } catch (IOException e) {\n       if (failOnMetadataWriteError) {\n         throw new MetadataPersistenceException(p.toString(), e);\n       } else {\n         LOG.error(\"S3Guard: Error updating MetadataStore for write to {}\",\n             p, e);\n       }\n       instrumentation.errorIgnored();\n     } finally {\n       // if a new operation state was created, close it.\n       IOUtils.cleanupWithLogger(LOG, stateToClose);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void finishedWrite(String key, long length, String eTag, String versionId,\n      @Nullable final BulkOperationState operationState)\n      throws MetadataPersistenceException {\n    LOG.debug(\"Finished write to {}, len {}. etag {}, version {}\",\n        key, length, eTag, versionId);\n    Path p \u003d keyToQualifiedPath(key);\n    Preconditions.checkArgument(length \u003e\u003d 0, \"content length is negative\");\n    deleteUnnecessaryFakeDirectories(p.getParent());\n    // this is only set if there is a metastore to update and the\n    // operationState parameter passed in was null.\n    BulkOperationState stateToClose \u003d null;\n\n    // See note about failure semantics in S3Guard documentation\n    try {\n      if (hasMetadataStore()) {\n        BulkOperationState activeState \u003d operationState;\n        if (activeState \u003d\u003d null) {\n          // create an operation state if there was none, so that the\n          // information gleaned from addAncestors is preserved into the\n          // subsequent put.\n          stateToClose \u003d S3Guard.initiateBulkWrite(metadataStore,\n              BulkOperationState.OperationType.Put,\n              keyToPath(key));\n          activeState \u003d stateToClose;\n        }\n        S3Guard.addAncestors(metadataStore, p, ttlTimeProvider, activeState);\n        final boolean isDir \u003d objectRepresentsDirectory(key, length);\n        S3AFileStatus status \u003d createUploadFileStatus(p,\n            isDir, length,\n            getDefaultBlockSize(p), username, eTag, versionId);\n        if (!isDir) {\n          S3Guard.putAndReturn(metadataStore, status,\n              ttlTimeProvider,\n              activeState);\n        } else {\n          // this is a directory marker so put it as such.\n          status.setIsEmptyDirectory(Tristate.TRUE);\n          S3Guard.putAuthDirectoryMarker(metadataStore, status,\n              ttlTimeProvider,\n              activeState);\n        }\n      }\n    } catch (IOException e) {\n      if (failOnMetadataWriteError) {\n        throw new MetadataPersistenceException(p.toString(), e);\n      } else {\n        LOG.error(\"S3Guard: Error updating MetadataStore for write to {}\",\n            p, e);\n      }\n      instrumentation.errorIgnored();\n    } finally {\n      // if a new operation state was created, close it.\n      IOUtils.cleanupWithLogger(LOG, stateToClose);\n    }\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java",
      "extendedDetails": {}
    },
    "e02eb24e0a9139418120027b694492e0738df20a": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HADOOP-15183. S3Guard store becomes inconsistent after partial failure of rename.\n\nContributed by Steve Loughran.\n\nChange-Id: I825b0bc36be960475d2d259b1cdab45ae1bb78eb\n",
      "commitDate": "20/06/19 1:56 AM",
      "commitName": "e02eb24e0a9139418120027b694492e0738df20a",
      "commitAuthor": "Steve Loughran",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HADOOP-15183. S3Guard store becomes inconsistent after partial failure of rename.\n\nContributed by Steve Loughran.\n\nChange-Id: I825b0bc36be960475d2d259b1cdab45ae1bb78eb\n",
          "commitDate": "20/06/19 1:56 AM",
          "commitName": "e02eb24e0a9139418120027b694492e0738df20a",
          "commitAuthor": "Steve Loughran",
          "commitDateOld": "16/06/19 9:05 AM",
          "commitNameOld": "f9cc9e162175444efe9d5b07ecb9a795f750ca3c",
          "commitAuthorOld": "Gabor Bota",
          "daysBetweenCommits": 3.7,
          "commitsBetweenForRepo": 44,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,27 +1,47 @@\n-  void finishedWrite(String key, long length, String eTag, String versionId)\n+  void finishedWrite(String key, long length, String eTag, String versionId,\n+      @Nullable final BulkOperationState operationState)\n       throws MetadataPersistenceException {\n-    LOG.debug(\"Finished write to {}, len {}\", key, length);\n+    LOG.debug(\"Finished write to {}, len {}. etag {}, version {}\",\n+        key, length, eTag, versionId);\n     Path p \u003d keyToQualifiedPath(key);\n     Preconditions.checkArgument(length \u003e\u003d 0, \"content length is negative\");\n     deleteUnnecessaryFakeDirectories(p.getParent());\n+    // this is only set if there is a metastore to update and the\n+    // operationState parameter passed in was null.\n+    BulkOperationState stateToClose \u003d null;\n \n     // See note about failure semantics in S3Guard documentation\n     try {\n       if (hasMetadataStore()) {\n-        S3Guard.addAncestors(metadataStore, p, username, ttlTimeProvider);\n+        BulkOperationState activeState \u003d operationState;\n+        if (activeState \u003d\u003d null) {\n+          // create an operation state if there was none, so that the\n+          // information gleaned from addAncestors is preserved into the\n+          // subsequent put.\n+          stateToClose \u003d S3Guard.initiateBulkWrite(metadataStore,\n+              BulkOperationState.OperationType.Put,\n+              keyToPath(key));\n+          activeState \u003d stateToClose;\n+        }\n+        S3Guard.addAncestors(metadataStore, p, ttlTimeProvider, activeState);\n         S3AFileStatus status \u003d createUploadFileStatus(p,\n             S3AUtils.objectRepresentsDirectory(key, length), length,\n             getDefaultBlockSize(p), username, eTag, versionId);\n-        S3Guard.putAndReturn(metadataStore, status, instrumentation,\n-            ttlTimeProvider);\n+        S3Guard.putAndReturn(metadataStore, status,\n+            instrumentation,\n+            ttlTimeProvider,\n+            activeState);\n       }\n     } catch (IOException e) {\n       if (failOnMetadataWriteError) {\n         throw new MetadataPersistenceException(p.toString(), e);\n       } else {\n         LOG.error(\"S3Guard: Error updating MetadataStore for write to {}\",\n             p, e);\n       }\n       instrumentation.errorIgnored();\n+    } finally {\n+      // if a new operation state was created, close it.\n+      IOUtils.cleanupWithLogger(LOG, stateToClose);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  void finishedWrite(String key, long length, String eTag, String versionId,\n      @Nullable final BulkOperationState operationState)\n      throws MetadataPersistenceException {\n    LOG.debug(\"Finished write to {}, len {}. etag {}, version {}\",\n        key, length, eTag, versionId);\n    Path p \u003d keyToQualifiedPath(key);\n    Preconditions.checkArgument(length \u003e\u003d 0, \"content length is negative\");\n    deleteUnnecessaryFakeDirectories(p.getParent());\n    // this is only set if there is a metastore to update and the\n    // operationState parameter passed in was null.\n    BulkOperationState stateToClose \u003d null;\n\n    // See note about failure semantics in S3Guard documentation\n    try {\n      if (hasMetadataStore()) {\n        BulkOperationState activeState \u003d operationState;\n        if (activeState \u003d\u003d null) {\n          // create an operation state if there was none, so that the\n          // information gleaned from addAncestors is preserved into the\n          // subsequent put.\n          stateToClose \u003d S3Guard.initiateBulkWrite(metadataStore,\n              BulkOperationState.OperationType.Put,\n              keyToPath(key));\n          activeState \u003d stateToClose;\n        }\n        S3Guard.addAncestors(metadataStore, p, ttlTimeProvider, activeState);\n        S3AFileStatus status \u003d createUploadFileStatus(p,\n            S3AUtils.objectRepresentsDirectory(key, length), length,\n            getDefaultBlockSize(p), username, eTag, versionId);\n        S3Guard.putAndReturn(metadataStore, status,\n            instrumentation,\n            ttlTimeProvider,\n            activeState);\n      }\n    } catch (IOException e) {\n      if (failOnMetadataWriteError) {\n        throw new MetadataPersistenceException(p.toString(), e);\n      } else {\n        LOG.error(\"S3Guard: Error updating MetadataStore for write to {}\",\n            p, e);\n      }\n      instrumentation.errorIgnored();\n    } finally {\n      // if a new operation state was created, close it.\n      IOUtils.cleanupWithLogger(LOG, stateToClose);\n    }\n  }",
          "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java",
          "extendedDetails": {
            "oldValue": "[key-String, length-long, eTag-String, versionId-String]",
            "newValue": "[key-String, length-long, eTag-String, versionId-String, operationState-BulkOperationState(annotations-@Nullable__modifiers-final)]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HADOOP-15183. S3Guard store becomes inconsistent after partial failure of rename.\n\nContributed by Steve Loughran.\n\nChange-Id: I825b0bc36be960475d2d259b1cdab45ae1bb78eb\n",
          "commitDate": "20/06/19 1:56 AM",
          "commitName": "e02eb24e0a9139418120027b694492e0738df20a",
          "commitAuthor": "Steve Loughran",
          "commitDateOld": "16/06/19 9:05 AM",
          "commitNameOld": "f9cc9e162175444efe9d5b07ecb9a795f750ca3c",
          "commitAuthorOld": "Gabor Bota",
          "daysBetweenCommits": 3.7,
          "commitsBetweenForRepo": 44,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,27 +1,47 @@\n-  void finishedWrite(String key, long length, String eTag, String versionId)\n+  void finishedWrite(String key, long length, String eTag, String versionId,\n+      @Nullable final BulkOperationState operationState)\n       throws MetadataPersistenceException {\n-    LOG.debug(\"Finished write to {}, len {}\", key, length);\n+    LOG.debug(\"Finished write to {}, len {}. etag {}, version {}\",\n+        key, length, eTag, versionId);\n     Path p \u003d keyToQualifiedPath(key);\n     Preconditions.checkArgument(length \u003e\u003d 0, \"content length is negative\");\n     deleteUnnecessaryFakeDirectories(p.getParent());\n+    // this is only set if there is a metastore to update and the\n+    // operationState parameter passed in was null.\n+    BulkOperationState stateToClose \u003d null;\n \n     // See note about failure semantics in S3Guard documentation\n     try {\n       if (hasMetadataStore()) {\n-        S3Guard.addAncestors(metadataStore, p, username, ttlTimeProvider);\n+        BulkOperationState activeState \u003d operationState;\n+        if (activeState \u003d\u003d null) {\n+          // create an operation state if there was none, so that the\n+          // information gleaned from addAncestors is preserved into the\n+          // subsequent put.\n+          stateToClose \u003d S3Guard.initiateBulkWrite(metadataStore,\n+              BulkOperationState.OperationType.Put,\n+              keyToPath(key));\n+          activeState \u003d stateToClose;\n+        }\n+        S3Guard.addAncestors(metadataStore, p, ttlTimeProvider, activeState);\n         S3AFileStatus status \u003d createUploadFileStatus(p,\n             S3AUtils.objectRepresentsDirectory(key, length), length,\n             getDefaultBlockSize(p), username, eTag, versionId);\n-        S3Guard.putAndReturn(metadataStore, status, instrumentation,\n-            ttlTimeProvider);\n+        S3Guard.putAndReturn(metadataStore, status,\n+            instrumentation,\n+            ttlTimeProvider,\n+            activeState);\n       }\n     } catch (IOException e) {\n       if (failOnMetadataWriteError) {\n         throw new MetadataPersistenceException(p.toString(), e);\n       } else {\n         LOG.error(\"S3Guard: Error updating MetadataStore for write to {}\",\n             p, e);\n       }\n       instrumentation.errorIgnored();\n+    } finally {\n+      // if a new operation state was created, close it.\n+      IOUtils.cleanupWithLogger(LOG, stateToClose);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  void finishedWrite(String key, long length, String eTag, String versionId,\n      @Nullable final BulkOperationState operationState)\n      throws MetadataPersistenceException {\n    LOG.debug(\"Finished write to {}, len {}. etag {}, version {}\",\n        key, length, eTag, versionId);\n    Path p \u003d keyToQualifiedPath(key);\n    Preconditions.checkArgument(length \u003e\u003d 0, \"content length is negative\");\n    deleteUnnecessaryFakeDirectories(p.getParent());\n    // this is only set if there is a metastore to update and the\n    // operationState parameter passed in was null.\n    BulkOperationState stateToClose \u003d null;\n\n    // See note about failure semantics in S3Guard documentation\n    try {\n      if (hasMetadataStore()) {\n        BulkOperationState activeState \u003d operationState;\n        if (activeState \u003d\u003d null) {\n          // create an operation state if there was none, so that the\n          // information gleaned from addAncestors is preserved into the\n          // subsequent put.\n          stateToClose \u003d S3Guard.initiateBulkWrite(metadataStore,\n              BulkOperationState.OperationType.Put,\n              keyToPath(key));\n          activeState \u003d stateToClose;\n        }\n        S3Guard.addAncestors(metadataStore, p, ttlTimeProvider, activeState);\n        S3AFileStatus status \u003d createUploadFileStatus(p,\n            S3AUtils.objectRepresentsDirectory(key, length), length,\n            getDefaultBlockSize(p), username, eTag, versionId);\n        S3Guard.putAndReturn(metadataStore, status,\n            instrumentation,\n            ttlTimeProvider,\n            activeState);\n      }\n    } catch (IOException e) {\n      if (failOnMetadataWriteError) {\n        throw new MetadataPersistenceException(p.toString(), e);\n      } else {\n        LOG.error(\"S3Guard: Error updating MetadataStore for write to {}\",\n            p, e);\n      }\n      instrumentation.errorIgnored();\n    } finally {\n      // if a new operation state was created, close it.\n      IOUtils.cleanupWithLogger(LOG, stateToClose);\n    }\n  }",
          "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java",
          "extendedDetails": {}
        }
      ]
    },
    "f9cc9e162175444efe9d5b07ecb9a795f750ca3c": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-16279. S3Guard: Implement time-based (TTL) expiry for entries (and tombstones).\n\nContributed by Gabor Bota.\n\nChange-Id: I73a2d2861901dedfe7a0e783b310fbb95e7c1af9\n",
      "commitDate": "16/06/19 9:05 AM",
      "commitName": "f9cc9e162175444efe9d5b07ecb9a795f750ca3c",
      "commitAuthor": "Gabor Bota",
      "commitDateOld": "19/05/19 2:29 PM",
      "commitNameOld": "a36274d69947648dbe82721220cc5240ec5d396d",
      "commitAuthorOld": "Ben Roling",
      "daysBetweenCommits": 27.77,
      "commitsBetweenForRepo": 198,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,26 +1,27 @@\n   void finishedWrite(String key, long length, String eTag, String versionId)\n       throws MetadataPersistenceException {\n     LOG.debug(\"Finished write to {}, len {}\", key, length);\n     Path p \u003d keyToQualifiedPath(key);\n     Preconditions.checkArgument(length \u003e\u003d 0, \"content length is negative\");\n     deleteUnnecessaryFakeDirectories(p.getParent());\n \n     // See note about failure semantics in S3Guard documentation\n     try {\n       if (hasMetadataStore()) {\n-        S3Guard.addAncestors(metadataStore, p, username);\n+        S3Guard.addAncestors(metadataStore, p, username, ttlTimeProvider);\n         S3AFileStatus status \u003d createUploadFileStatus(p,\n             S3AUtils.objectRepresentsDirectory(key, length), length,\n             getDefaultBlockSize(p), username, eTag, versionId);\n-        S3Guard.putAndReturn(metadataStore, status, instrumentation);\n+        S3Guard.putAndReturn(metadataStore, status, instrumentation,\n+            ttlTimeProvider);\n       }\n     } catch (IOException e) {\n       if (failOnMetadataWriteError) {\n         throw new MetadataPersistenceException(p.toString(), e);\n       } else {\n         LOG.error(\"S3Guard: Error updating MetadataStore for write to {}\",\n             p, e);\n       }\n       instrumentation.errorIgnored();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void finishedWrite(String key, long length, String eTag, String versionId)\n      throws MetadataPersistenceException {\n    LOG.debug(\"Finished write to {}, len {}\", key, length);\n    Path p \u003d keyToQualifiedPath(key);\n    Preconditions.checkArgument(length \u003e\u003d 0, \"content length is negative\");\n    deleteUnnecessaryFakeDirectories(p.getParent());\n\n    // See note about failure semantics in S3Guard documentation\n    try {\n      if (hasMetadataStore()) {\n        S3Guard.addAncestors(metadataStore, p, username, ttlTimeProvider);\n        S3AFileStatus status \u003d createUploadFileStatus(p,\n            S3AUtils.objectRepresentsDirectory(key, length), length,\n            getDefaultBlockSize(p), username, eTag, versionId);\n        S3Guard.putAndReturn(metadataStore, status, instrumentation,\n            ttlTimeProvider);\n      }\n    } catch (IOException e) {\n      if (failOnMetadataWriteError) {\n        throw new MetadataPersistenceException(p.toString(), e);\n      } else {\n        LOG.error(\"S3Guard: Error updating MetadataStore for write to {}\",\n            p, e);\n      }\n      instrumentation.errorIgnored();\n    }\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java",
      "extendedDetails": {}
    },
    "a36274d69947648dbe82721220cc5240ec5d396d": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HADOOP-16085. S3Guard: use object version or etags to protect against inconsistent read after replace/overwrite.\n\nContributed by Ben Roling.\n\nS3Guard will now track the etag of uploaded files and, if an S3\nbucket is versioned, the object version.\n\nYou can then control how to react to a mismatch between the data\nin the DynamoDB table and that in the store: warn, fail, or, when\nusing versions, return the original value.\n\nThis adds two new columns to the table: etag and version.\nThis is transparent to older S3A clients -but when such clients\nadd/update data to the S3Guard table, they will not add these values.\nAs a result, the etag/version checks will not work with files uploaded by older clients.\n\nFor a consistent experience, upgrade all clients to use the latest hadoop version.\n",
      "commitDate": "19/05/19 2:29 PM",
      "commitName": "a36274d69947648dbe82721220cc5240ec5d396d",
      "commitAuthor": "Ben Roling",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HADOOP-16085. S3Guard: use object version or etags to protect against inconsistent read after replace/overwrite.\n\nContributed by Ben Roling.\n\nS3Guard will now track the etag of uploaded files and, if an S3\nbucket is versioned, the object version.\n\nYou can then control how to react to a mismatch between the data\nin the DynamoDB table and that in the store: warn, fail, or, when\nusing versions, return the original value.\n\nThis adds two new columns to the table: etag and version.\nThis is transparent to older S3A clients -but when such clients\nadd/update data to the S3Guard table, they will not add these values.\nAs a result, the etag/version checks will not work with files uploaded by older clients.\n\nFor a consistent experience, upgrade all clients to use the latest hadoop version.\n",
          "commitDate": "19/05/19 2:29 PM",
          "commitName": "a36274d69947648dbe82721220cc5240ec5d396d",
          "commitAuthor": "Ben Roling",
          "commitDateOld": "30/04/19 3:53 AM",
          "commitNameOld": "0af4011580878566213016af0c32633eabd15100",
          "commitAuthorOld": "Ben Roling",
          "daysBetweenCommits": 19.44,
          "commitsBetweenForRepo": 90,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,26 +1,26 @@\n-  void finishedWrite(String key, long length)\n+  void finishedWrite(String key, long length, String eTag, String versionId)\n       throws MetadataPersistenceException {\n     LOG.debug(\"Finished write to {}, len {}\", key, length);\n     Path p \u003d keyToQualifiedPath(key);\n     Preconditions.checkArgument(length \u003e\u003d 0, \"content length is negative\");\n     deleteUnnecessaryFakeDirectories(p.getParent());\n \n     // See note about failure semantics in S3Guard documentation\n     try {\n       if (hasMetadataStore()) {\n         S3Guard.addAncestors(metadataStore, p, username);\n         S3AFileStatus status \u003d createUploadFileStatus(p,\n             S3AUtils.objectRepresentsDirectory(key, length), length,\n-            getDefaultBlockSize(p), username);\n+            getDefaultBlockSize(p), username, eTag, versionId);\n         S3Guard.putAndReturn(metadataStore, status, instrumentation);\n       }\n     } catch (IOException e) {\n       if (failOnMetadataWriteError) {\n         throw new MetadataPersistenceException(p.toString(), e);\n       } else {\n         LOG.error(\"S3Guard: Error updating MetadataStore for write to {}\",\n             p, e);\n       }\n       instrumentation.errorIgnored();\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  void finishedWrite(String key, long length, String eTag, String versionId)\n      throws MetadataPersistenceException {\n    LOG.debug(\"Finished write to {}, len {}\", key, length);\n    Path p \u003d keyToQualifiedPath(key);\n    Preconditions.checkArgument(length \u003e\u003d 0, \"content length is negative\");\n    deleteUnnecessaryFakeDirectories(p.getParent());\n\n    // See note about failure semantics in S3Guard documentation\n    try {\n      if (hasMetadataStore()) {\n        S3Guard.addAncestors(metadataStore, p, username);\n        S3AFileStatus status \u003d createUploadFileStatus(p,\n            S3AUtils.objectRepresentsDirectory(key, length), length,\n            getDefaultBlockSize(p), username, eTag, versionId);\n        S3Guard.putAndReturn(metadataStore, status, instrumentation);\n      }\n    } catch (IOException e) {\n      if (failOnMetadataWriteError) {\n        throw new MetadataPersistenceException(p.toString(), e);\n      } else {\n        LOG.error(\"S3Guard: Error updating MetadataStore for write to {}\",\n            p, e);\n      }\n      instrumentation.errorIgnored();\n    }\n  }",
          "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java",
          "extendedDetails": {
            "oldValue": "[key-String, length-long]",
            "newValue": "[key-String, length-long, eTag-String, versionId-String]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HADOOP-16085. S3Guard: use object version or etags to protect against inconsistent read after replace/overwrite.\n\nContributed by Ben Roling.\n\nS3Guard will now track the etag of uploaded files and, if an S3\nbucket is versioned, the object version.\n\nYou can then control how to react to a mismatch between the data\nin the DynamoDB table and that in the store: warn, fail, or, when\nusing versions, return the original value.\n\nThis adds two new columns to the table: etag and version.\nThis is transparent to older S3A clients -but when such clients\nadd/update data to the S3Guard table, they will not add these values.\nAs a result, the etag/version checks will not work with files uploaded by older clients.\n\nFor a consistent experience, upgrade all clients to use the latest hadoop version.\n",
          "commitDate": "19/05/19 2:29 PM",
          "commitName": "a36274d69947648dbe82721220cc5240ec5d396d",
          "commitAuthor": "Ben Roling",
          "commitDateOld": "30/04/19 3:53 AM",
          "commitNameOld": "0af4011580878566213016af0c32633eabd15100",
          "commitAuthorOld": "Ben Roling",
          "daysBetweenCommits": 19.44,
          "commitsBetweenForRepo": 90,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,26 +1,26 @@\n-  void finishedWrite(String key, long length)\n+  void finishedWrite(String key, long length, String eTag, String versionId)\n       throws MetadataPersistenceException {\n     LOG.debug(\"Finished write to {}, len {}\", key, length);\n     Path p \u003d keyToQualifiedPath(key);\n     Preconditions.checkArgument(length \u003e\u003d 0, \"content length is negative\");\n     deleteUnnecessaryFakeDirectories(p.getParent());\n \n     // See note about failure semantics in S3Guard documentation\n     try {\n       if (hasMetadataStore()) {\n         S3Guard.addAncestors(metadataStore, p, username);\n         S3AFileStatus status \u003d createUploadFileStatus(p,\n             S3AUtils.objectRepresentsDirectory(key, length), length,\n-            getDefaultBlockSize(p), username);\n+            getDefaultBlockSize(p), username, eTag, versionId);\n         S3Guard.putAndReturn(metadataStore, status, instrumentation);\n       }\n     } catch (IOException e) {\n       if (failOnMetadataWriteError) {\n         throw new MetadataPersistenceException(p.toString(), e);\n       } else {\n         LOG.error(\"S3Guard: Error updating MetadataStore for write to {}\",\n             p, e);\n       }\n       instrumentation.errorIgnored();\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  void finishedWrite(String key, long length, String eTag, String versionId)\n      throws MetadataPersistenceException {\n    LOG.debug(\"Finished write to {}, len {}\", key, length);\n    Path p \u003d keyToQualifiedPath(key);\n    Preconditions.checkArgument(length \u003e\u003d 0, \"content length is negative\");\n    deleteUnnecessaryFakeDirectories(p.getParent());\n\n    // See note about failure semantics in S3Guard documentation\n    try {\n      if (hasMetadataStore()) {\n        S3Guard.addAncestors(metadataStore, p, username);\n        S3AFileStatus status \u003d createUploadFileStatus(p,\n            S3AUtils.objectRepresentsDirectory(key, length), length,\n            getDefaultBlockSize(p), username, eTag, versionId);\n        S3Guard.putAndReturn(metadataStore, status, instrumentation);\n      }\n    } catch (IOException e) {\n      if (failOnMetadataWriteError) {\n        throw new MetadataPersistenceException(p.toString(), e);\n      } else {\n        LOG.error(\"S3Guard: Error updating MetadataStore for write to {}\",\n            p, e);\n      }\n      instrumentation.errorIgnored();\n    }\n  }",
          "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java",
          "extendedDetails": {}
        }
      ]
    },
    "0af4011580878566213016af0c32633eabd15100": {
      "type": "Ymultichange(Yexceptionschange,Ybodychange)",
      "commitMessage": "HADOOP-16221. S3Guard: add option to fail operation on metadata write failure.\n",
      "commitDate": "30/04/19 3:53 AM",
      "commitName": "0af4011580878566213016af0c32633eabd15100",
      "commitAuthor": "Ben Roling",
      "subchanges": [
        {
          "type": "Yexceptionschange",
          "commitMessage": "HADOOP-16221. S3Guard: add option to fail operation on metadata write failure.\n",
          "commitDate": "30/04/19 3:53 AM",
          "commitName": "0af4011580878566213016af0c32633eabd15100",
          "commitAuthor": "Ben Roling",
          "commitDateOld": "28/03/19 8:59 AM",
          "commitNameOld": "b5db2383832881034d57d836a8135a07a2bd1cf4",
          "commitAuthorOld": "Gabor Bota",
          "daysBetweenCommits": 32.79,
          "commitsBetweenForRepo": 211,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,21 +1,26 @@\n-  void finishedWrite(String key, long length) {\n+  void finishedWrite(String key, long length)\n+      throws MetadataPersistenceException {\n     LOG.debug(\"Finished write to {}, len {}\", key, length);\n     Path p \u003d keyToQualifiedPath(key);\n     Preconditions.checkArgument(length \u003e\u003d 0, \"content length is negative\");\n     deleteUnnecessaryFakeDirectories(p.getParent());\n \n     // See note about failure semantics in S3Guard documentation\n     try {\n       if (hasMetadataStore()) {\n         S3Guard.addAncestors(metadataStore, p, username);\n         S3AFileStatus status \u003d createUploadFileStatus(p,\n             S3AUtils.objectRepresentsDirectory(key, length), length,\n             getDefaultBlockSize(p), username);\n         S3Guard.putAndReturn(metadataStore, status, instrumentation);\n       }\n     } catch (IOException e) {\n-      LOG.error(\"S3Guard: Error updating MetadataStore for write to {}:\",\n-          key, e);\n+      if (failOnMetadataWriteError) {\n+        throw new MetadataPersistenceException(p.toString(), e);\n+      } else {\n+        LOG.error(\"S3Guard: Error updating MetadataStore for write to {}\",\n+            p, e);\n+      }\n       instrumentation.errorIgnored();\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  void finishedWrite(String key, long length)\n      throws MetadataPersistenceException {\n    LOG.debug(\"Finished write to {}, len {}\", key, length);\n    Path p \u003d keyToQualifiedPath(key);\n    Preconditions.checkArgument(length \u003e\u003d 0, \"content length is negative\");\n    deleteUnnecessaryFakeDirectories(p.getParent());\n\n    // See note about failure semantics in S3Guard documentation\n    try {\n      if (hasMetadataStore()) {\n        S3Guard.addAncestors(metadataStore, p, username);\n        S3AFileStatus status \u003d createUploadFileStatus(p,\n            S3AUtils.objectRepresentsDirectory(key, length), length,\n            getDefaultBlockSize(p), username);\n        S3Guard.putAndReturn(metadataStore, status, instrumentation);\n      }\n    } catch (IOException e) {\n      if (failOnMetadataWriteError) {\n        throw new MetadataPersistenceException(p.toString(), e);\n      } else {\n        LOG.error(\"S3Guard: Error updating MetadataStore for write to {}\",\n            p, e);\n      }\n      instrumentation.errorIgnored();\n    }\n  }",
          "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[MetadataPersistenceException]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HADOOP-16221. S3Guard: add option to fail operation on metadata write failure.\n",
          "commitDate": "30/04/19 3:53 AM",
          "commitName": "0af4011580878566213016af0c32633eabd15100",
          "commitAuthor": "Ben Roling",
          "commitDateOld": "28/03/19 8:59 AM",
          "commitNameOld": "b5db2383832881034d57d836a8135a07a2bd1cf4",
          "commitAuthorOld": "Gabor Bota",
          "daysBetweenCommits": 32.79,
          "commitsBetweenForRepo": 211,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,21 +1,26 @@\n-  void finishedWrite(String key, long length) {\n+  void finishedWrite(String key, long length)\n+      throws MetadataPersistenceException {\n     LOG.debug(\"Finished write to {}, len {}\", key, length);\n     Path p \u003d keyToQualifiedPath(key);\n     Preconditions.checkArgument(length \u003e\u003d 0, \"content length is negative\");\n     deleteUnnecessaryFakeDirectories(p.getParent());\n \n     // See note about failure semantics in S3Guard documentation\n     try {\n       if (hasMetadataStore()) {\n         S3Guard.addAncestors(metadataStore, p, username);\n         S3AFileStatus status \u003d createUploadFileStatus(p,\n             S3AUtils.objectRepresentsDirectory(key, length), length,\n             getDefaultBlockSize(p), username);\n         S3Guard.putAndReturn(metadataStore, status, instrumentation);\n       }\n     } catch (IOException e) {\n-      LOG.error(\"S3Guard: Error updating MetadataStore for write to {}:\",\n-          key, e);\n+      if (failOnMetadataWriteError) {\n+        throw new MetadataPersistenceException(p.toString(), e);\n+      } else {\n+        LOG.error(\"S3Guard: Error updating MetadataStore for write to {}\",\n+            p, e);\n+      }\n       instrumentation.errorIgnored();\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  void finishedWrite(String key, long length)\n      throws MetadataPersistenceException {\n    LOG.debug(\"Finished write to {}, len {}\", key, length);\n    Path p \u003d keyToQualifiedPath(key);\n    Preconditions.checkArgument(length \u003e\u003d 0, \"content length is negative\");\n    deleteUnnecessaryFakeDirectories(p.getParent());\n\n    // See note about failure semantics in S3Guard documentation\n    try {\n      if (hasMetadataStore()) {\n        S3Guard.addAncestors(metadataStore, p, username);\n        S3AFileStatus status \u003d createUploadFileStatus(p,\n            S3AUtils.objectRepresentsDirectory(key, length), length,\n            getDefaultBlockSize(p), username);\n        S3Guard.putAndReturn(metadataStore, status, instrumentation);\n      }\n    } catch (IOException e) {\n      if (failOnMetadataWriteError) {\n        throw new MetadataPersistenceException(p.toString(), e);\n      } else {\n        LOG.error(\"S3Guard: Error updating MetadataStore for write to {}\",\n            p, e);\n      }\n      instrumentation.errorIgnored();\n    }\n  }",
          "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java",
          "extendedDetails": {}
        }
      ]
    },
    "a0c71dcc33ca7c5539d0ab61c4a276c4f39e5744": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-15079. ITestS3AFileOperationCost#testFakeDirectoryDeletion failing\nafter OutputCommitter patch.\nContributed by Steve Loughran\n",
      "commitDate": "15/01/18 3:33 AM",
      "commitName": "a0c71dcc33ca7c5539d0ab61c4a276c4f39e5744",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "09/01/18 10:46 AM",
      "commitNameOld": "b62a5ece95a6b5bbb17f273debd55bcbf0c5f28c",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 5.7,
      "commitsBetweenForRepo": 27,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,21 @@\n   void finishedWrite(String key, long length) {\n     LOG.debug(\"Finished write to {}, len {}\", key, length);\n     Path p \u003d keyToQualifiedPath(key);\n-    deleteUnnecessaryFakeDirectories(p.getParent());\n     Preconditions.checkArgument(length \u003e\u003d 0, \"content length is negative\");\n+    deleteUnnecessaryFakeDirectories(p.getParent());\n \n     // See note about failure semantics in S3Guard documentation\n     try {\n       if (hasMetadataStore()) {\n         S3Guard.addAncestors(metadataStore, p, username);\n         S3AFileStatus status \u003d createUploadFileStatus(p,\n             S3AUtils.objectRepresentsDirectory(key, length), length,\n             getDefaultBlockSize(p), username);\n         S3Guard.putAndReturn(metadataStore, status, instrumentation);\n       }\n     } catch (IOException e) {\n       LOG.error(\"S3Guard: Error updating MetadataStore for write to {}:\",\n           key, e);\n       instrumentation.errorIgnored();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void finishedWrite(String key, long length) {\n    LOG.debug(\"Finished write to {}, len {}\", key, length);\n    Path p \u003d keyToQualifiedPath(key);\n    Preconditions.checkArgument(length \u003e\u003d 0, \"content length is negative\");\n    deleteUnnecessaryFakeDirectories(p.getParent());\n\n    // See note about failure semantics in S3Guard documentation\n    try {\n      if (hasMetadataStore()) {\n        S3Guard.addAncestors(metadataStore, p, username);\n        S3AFileStatus status \u003d createUploadFileStatus(p,\n            S3AUtils.objectRepresentsDirectory(key, length), length,\n            getDefaultBlockSize(p), username);\n        S3Guard.putAndReturn(metadataStore, status, instrumentation);\n      }\n    } catch (IOException e) {\n      LOG.error(\"S3Guard: Error updating MetadataStore for write to {}:\",\n          key, e);\n      instrumentation.errorIgnored();\n    }\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java",
      "extendedDetails": {}
    },
    "621b43e254afaff708cd6fc4698b29628f6abc33": {
      "type": "Ymultichange(Yparameterchange,Ymodifierchange,Ybodychange)",
      "commitMessage": "HADOOP-13345 HS3Guard: Improved Consistency for S3A.\nContributed by: Chris Nauroth, Aaron Fabbri, Mingliang Liu, Lei (Eddy) Xu,\nSean Mackrory, Steve Loughran and others.\n",
      "commitDate": "01/09/17 6:13 AM",
      "commitName": "621b43e254afaff708cd6fc4698b29628f6abc33",
      "commitAuthor": "Steve Loughran",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HADOOP-13345 HS3Guard: Improved Consistency for S3A.\nContributed by: Chris Nauroth, Aaron Fabbri, Mingliang Liu, Lei (Eddy) Xu,\nSean Mackrory, Steve Loughran and others.\n",
          "commitDate": "01/09/17 6:13 AM",
          "commitName": "621b43e254afaff708cd6fc4698b29628f6abc33",
          "commitAuthor": "Steve Loughran",
          "commitDateOld": "05/06/17 11:26 AM",
          "commitNameOld": "6aeda55bb8f741d9dafd41f6dfbf1a88acdd4003",
          "commitAuthorOld": "Mingliang Liu",
          "daysBetweenCommits": 87.78,
          "commitsBetweenForRepo": 591,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,4 +1,21 @@\n-  public void finishedWrite(String key) {\n-    LOG.debug(\"Finished write to {}\", key);\n-    deleteUnnecessaryFakeDirectories(keyToPath(key).getParent());\n+  void finishedWrite(String key, long length) {\n+    LOG.debug(\"Finished write to {}, len {}\", key, length);\n+    Path p \u003d keyToQualifiedPath(key);\n+    deleteUnnecessaryFakeDirectories(p.getParent());\n+    Preconditions.checkArgument(length \u003e\u003d 0, \"content length is negative\");\n+\n+    // See note about failure semantics in S3Guard documentation\n+    try {\n+      if (hasMetadataStore()) {\n+        S3Guard.addAncestors(metadataStore, p, username);\n+        S3AFileStatus status \u003d createUploadFileStatus(p,\n+            S3AUtils.objectRepresentsDirectory(key, length), length,\n+            getDefaultBlockSize(p), username);\n+        S3Guard.putAndReturn(metadataStore, status, instrumentation);\n+      }\n+    } catch (IOException e) {\n+      LOG.error(\"S3Guard: Error updating MetadataStore for write to {}:\",\n+          key, e);\n+      instrumentation.errorIgnored();\n+    }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  void finishedWrite(String key, long length) {\n    LOG.debug(\"Finished write to {}, len {}\", key, length);\n    Path p \u003d keyToQualifiedPath(key);\n    deleteUnnecessaryFakeDirectories(p.getParent());\n    Preconditions.checkArgument(length \u003e\u003d 0, \"content length is negative\");\n\n    // See note about failure semantics in S3Guard documentation\n    try {\n      if (hasMetadataStore()) {\n        S3Guard.addAncestors(metadataStore, p, username);\n        S3AFileStatus status \u003d createUploadFileStatus(p,\n            S3AUtils.objectRepresentsDirectory(key, length), length,\n            getDefaultBlockSize(p), username);\n        S3Guard.putAndReturn(metadataStore, status, instrumentation);\n      }\n    } catch (IOException e) {\n      LOG.error(\"S3Guard: Error updating MetadataStore for write to {}:\",\n          key, e);\n      instrumentation.errorIgnored();\n    }\n  }",
          "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java",
          "extendedDetails": {
            "oldValue": "[key-String]",
            "newValue": "[key-String, length-long]"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HADOOP-13345 HS3Guard: Improved Consistency for S3A.\nContributed by: Chris Nauroth, Aaron Fabbri, Mingliang Liu, Lei (Eddy) Xu,\nSean Mackrory, Steve Loughran and others.\n",
          "commitDate": "01/09/17 6:13 AM",
          "commitName": "621b43e254afaff708cd6fc4698b29628f6abc33",
          "commitAuthor": "Steve Loughran",
          "commitDateOld": "05/06/17 11:26 AM",
          "commitNameOld": "6aeda55bb8f741d9dafd41f6dfbf1a88acdd4003",
          "commitAuthorOld": "Mingliang Liu",
          "daysBetweenCommits": 87.78,
          "commitsBetweenForRepo": 591,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,4 +1,21 @@\n-  public void finishedWrite(String key) {\n-    LOG.debug(\"Finished write to {}\", key);\n-    deleteUnnecessaryFakeDirectories(keyToPath(key).getParent());\n+  void finishedWrite(String key, long length) {\n+    LOG.debug(\"Finished write to {}, len {}\", key, length);\n+    Path p \u003d keyToQualifiedPath(key);\n+    deleteUnnecessaryFakeDirectories(p.getParent());\n+    Preconditions.checkArgument(length \u003e\u003d 0, \"content length is negative\");\n+\n+    // See note about failure semantics in S3Guard documentation\n+    try {\n+      if (hasMetadataStore()) {\n+        S3Guard.addAncestors(metadataStore, p, username);\n+        S3AFileStatus status \u003d createUploadFileStatus(p,\n+            S3AUtils.objectRepresentsDirectory(key, length), length,\n+            getDefaultBlockSize(p), username);\n+        S3Guard.putAndReturn(metadataStore, status, instrumentation);\n+      }\n+    } catch (IOException e) {\n+      LOG.error(\"S3Guard: Error updating MetadataStore for write to {}:\",\n+          key, e);\n+      instrumentation.errorIgnored();\n+    }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  void finishedWrite(String key, long length) {\n    LOG.debug(\"Finished write to {}, len {}\", key, length);\n    Path p \u003d keyToQualifiedPath(key);\n    deleteUnnecessaryFakeDirectories(p.getParent());\n    Preconditions.checkArgument(length \u003e\u003d 0, \"content length is negative\");\n\n    // See note about failure semantics in S3Guard documentation\n    try {\n      if (hasMetadataStore()) {\n        S3Guard.addAncestors(metadataStore, p, username);\n        S3AFileStatus status \u003d createUploadFileStatus(p,\n            S3AUtils.objectRepresentsDirectory(key, length), length,\n            getDefaultBlockSize(p), username);\n        S3Guard.putAndReturn(metadataStore, status, instrumentation);\n      }\n    } catch (IOException e) {\n      LOG.error(\"S3Guard: Error updating MetadataStore for write to {}:\",\n          key, e);\n      instrumentation.errorIgnored();\n    }\n  }",
          "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java",
          "extendedDetails": {
            "oldValue": "[public]",
            "newValue": "[]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HADOOP-13345 HS3Guard: Improved Consistency for S3A.\nContributed by: Chris Nauroth, Aaron Fabbri, Mingliang Liu, Lei (Eddy) Xu,\nSean Mackrory, Steve Loughran and others.\n",
          "commitDate": "01/09/17 6:13 AM",
          "commitName": "621b43e254afaff708cd6fc4698b29628f6abc33",
          "commitAuthor": "Steve Loughran",
          "commitDateOld": "05/06/17 11:26 AM",
          "commitNameOld": "6aeda55bb8f741d9dafd41f6dfbf1a88acdd4003",
          "commitAuthorOld": "Mingliang Liu",
          "daysBetweenCommits": 87.78,
          "commitsBetweenForRepo": 591,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,4 +1,21 @@\n-  public void finishedWrite(String key) {\n-    LOG.debug(\"Finished write to {}\", key);\n-    deleteUnnecessaryFakeDirectories(keyToPath(key).getParent());\n+  void finishedWrite(String key, long length) {\n+    LOG.debug(\"Finished write to {}, len {}\", key, length);\n+    Path p \u003d keyToQualifiedPath(key);\n+    deleteUnnecessaryFakeDirectories(p.getParent());\n+    Preconditions.checkArgument(length \u003e\u003d 0, \"content length is negative\");\n+\n+    // See note about failure semantics in S3Guard documentation\n+    try {\n+      if (hasMetadataStore()) {\n+        S3Guard.addAncestors(metadataStore, p, username);\n+        S3AFileStatus status \u003d createUploadFileStatus(p,\n+            S3AUtils.objectRepresentsDirectory(key, length), length,\n+            getDefaultBlockSize(p), username);\n+        S3Guard.putAndReturn(metadataStore, status, instrumentation);\n+      }\n+    } catch (IOException e) {\n+      LOG.error(\"S3Guard: Error updating MetadataStore for write to {}:\",\n+          key, e);\n+      instrumentation.errorIgnored();\n+    }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  void finishedWrite(String key, long length) {\n    LOG.debug(\"Finished write to {}, len {}\", key, length);\n    Path p \u003d keyToQualifiedPath(key);\n    deleteUnnecessaryFakeDirectories(p.getParent());\n    Preconditions.checkArgument(length \u003e\u003d 0, \"content length is negative\");\n\n    // See note about failure semantics in S3Guard documentation\n    try {\n      if (hasMetadataStore()) {\n        S3Guard.addAncestors(metadataStore, p, username);\n        S3AFileStatus status \u003d createUploadFileStatus(p,\n            S3AUtils.objectRepresentsDirectory(key, length), length,\n            getDefaultBlockSize(p), username);\n        S3Guard.putAndReturn(metadataStore, status, instrumentation);\n      }\n    } catch (IOException e) {\n      LOG.error(\"S3Guard: Error updating MetadataStore for write to {}:\",\n          key, e);\n      instrumentation.errorIgnored();\n    }\n  }",
          "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java",
          "extendedDetails": {}
        }
      ]
    },
    "c58a59f7081d55dd2108545ebf9ee48cf43ca944": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-13171. Add StorageStatistics to S3A; instrument some more operations. Contributed by Steve Loughran.\n",
      "commitDate": "03/06/16 8:55 AM",
      "commitName": "c58a59f7081d55dd2108545ebf9ee48cf43ca944",
      "commitAuthor": "Chris Nauroth",
      "commitDateOld": "01/06/16 2:49 PM",
      "commitNameOld": "16b1cc7af9bd63b65ef50e1056f275a7baf111a2",
      "commitAuthorOld": "Chris Nauroth",
      "daysBetweenCommits": 1.75,
      "commitsBetweenForRepo": 8,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,3 +1,4 @@\n   public void finishedWrite(String key) {\n+    LOG.debug(\"Finished write to {}\", key);\n     deleteUnnecessaryFakeDirectories(keyToPath(key).getParent());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void finishedWrite(String key) {\n    LOG.debug(\"Finished write to {}\", key);\n    deleteUnnecessaryFakeDirectories(keyToPath(key).getParent());\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java",
      "extendedDetails": {}
    },
    "39ec1515a205952eda7e171408a8b83eceb4abde": {
      "type": "Yexceptionschange",
      "commitMessage": "HADOOP-13130. s3a failures can surface as RTEs, not IOEs. (Steve Loughran)\n",
      "commitDate": "21/05/16 8:39 AM",
      "commitName": "39ec1515a205952eda7e171408a8b83eceb4abde",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "20/05/16 5:52 AM",
      "commitNameOld": "757050ff355d40bc28f9dbfd0c0083c5f337d270",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 1.12,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,3 +1,3 @@\n-  public void finishedWrite(String key) throws IOException {\n+  public void finishedWrite(String key) {\n     deleteUnnecessaryFakeDirectories(keyToPath(key).getParent());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void finishedWrite(String key) {\n    deleteUnnecessaryFakeDirectories(keyToPath(key).getParent());\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java",
      "extendedDetails": {
        "oldValue": "[IOException]",
        "newValue": "[]"
      }
    },
    "24d920b80eb3626073925a1d0b6dcf148add8cc0": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-10400. Incorporate new S3A FileSystem implementation. Contributed by Jordan Mendelson and Dave Wang.\n",
      "commitDate": "15/09/14 8:27 AM",
      "commitName": "24d920b80eb3626073925a1d0b6dcf148add8cc0",
      "commitAuthor": "Aaron T. Myers",
      "diff": "@@ -0,0 +1,3 @@\n+  public void finishedWrite(String key) throws IOException {\n+    deleteUnnecessaryFakeDirectories(keyToPath(key).getParent());\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void finishedWrite(String key) throws IOException {\n    deleteUnnecessaryFakeDirectories(keyToPath(key).getParent());\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java"
    }
  }
}