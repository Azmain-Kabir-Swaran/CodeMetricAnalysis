{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "PBHelper.java",
  "functionName": "convert",
  "functionId": "convert___key-BlockKey",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
  "functionStartLine": 242,
  "functionEndLine": 248,
  "numCommitsSeen": 195,
  "timeTaken": 6032,
  "changeHistory": [
    "c470c8953d4927043b6383fad8e792289c634c09",
    "0d6aa5d60948a7966da0ca1c3344a37c1d32f2e9",
    "d9e2514d21c2ae356ee7fe8d4a857748b5defa4c",
    "0a713035f2fb1a222291cfdb2cbde906814c2fd9"
  ],
  "changeHistoryShort": {
    "c470c8953d4927043b6383fad8e792289c634c09": "Ybodychange",
    "0d6aa5d60948a7966da0ca1c3344a37c1d32f2e9": "Ybodychange",
    "d9e2514d21c2ae356ee7fe8d4a857748b5defa4c": "Ybodychange",
    "0a713035f2fb1a222291cfdb2cbde906814c2fd9": "Yintroduced"
  },
  "changeHistoryDetails": {
    "c470c8953d4927043b6383fad8e792289c634c09": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9557. Reduce object allocation in PB conversion. Contributed by Daryn Sharp.\n",
      "commitDate": "16/12/15 11:10 AM",
      "commitName": "c470c8953d4927043b6383fad8e792289c634c09",
      "commitAuthor": "cnauroth",
      "commitDateOld": "28/10/15 7:34 AM",
      "commitNameOld": "e287e7d14b838a866ba03d895fa35819999d7c09",
      "commitAuthorOld": "Zhe Zhang",
      "daysBetweenCommits": 49.19,
      "commitsBetweenForRepo": 322,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,7 +1,7 @@\n   public static BlockKeyProto convert(BlockKey key) {\n     byte[] encodedKey \u003d key.getEncodedKey();\n-    ByteString keyBytes \u003d ByteString.copyFrom(encodedKey \u003d\u003d null ?\n+    ByteString keyBytes \u003d PBHelperClient.getByteString(encodedKey \u003d\u003d null ?\n         DFSUtilClient.EMPTY_BYTES : encodedKey);\n     return BlockKeyProto.newBuilder().setKeyId(key.getKeyId())\n         .setKeyBytes(keyBytes).setExpiryDate(key.getExpiryDate()).build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static BlockKeyProto convert(BlockKey key) {\n    byte[] encodedKey \u003d key.getEncodedKey();\n    ByteString keyBytes \u003d PBHelperClient.getByteString(encodedKey \u003d\u003d null ?\n        DFSUtilClient.EMPTY_BYTES : encodedKey);\n    return BlockKeyProto.newBuilder().setKeyId(key.getKeyId())\n        .setKeyBytes(keyBytes).setExpiryDate(key.getExpiryDate()).build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
      "extendedDetails": {}
    },
    "0d6aa5d60948a7966da0ca1c3344a37c1d32f2e9": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8237. Move all protocol classes used by ClientProtocol to hdfs-client. Contributed by Haohui Mai.\n",
      "commitDate": "04/05/15 3:00 PM",
      "commitName": "0d6aa5d60948a7966da0ca1c3344a37c1d32f2e9",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "02/05/15 10:03 AM",
      "commitNameOld": "6ae2a0d048e133b43249c248a75a4d77d9abb80d",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 2.21,
      "commitsBetweenForRepo": 12,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,7 +1,7 @@\n   public static BlockKeyProto convert(BlockKey key) {\n     byte[] encodedKey \u003d key.getEncodedKey();\n     ByteString keyBytes \u003d ByteString.copyFrom(encodedKey \u003d\u003d null ? \n-        DFSUtil.EMPTY_BYTES : encodedKey);\n+        DFSUtilClient.EMPTY_BYTES : encodedKey);\n     return BlockKeyProto.newBuilder().setKeyId(key.getKeyId())\n         .setKeyBytes(keyBytes).setExpiryDate(key.getExpiryDate()).build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static BlockKeyProto convert(BlockKey key) {\n    byte[] encodedKey \u003d key.getEncodedKey();\n    ByteString keyBytes \u003d ByteString.copyFrom(encodedKey \u003d\u003d null ? \n        DFSUtilClient.EMPTY_BYTES : encodedKey);\n    return BlockKeyProto.newBuilder().setKeyId(key.getKeyId())\n        .setKeyBytes(keyBytes).setExpiryDate(key.getExpiryDate()).build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
      "extendedDetails": {}
    },
    "d9e2514d21c2ae356ee7fe8d4a857748b5defa4c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4487. Fix snapshot diff report for HDFS-4446.  Contributed by Jing Zhao\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2802@1446385 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/02/13 3:07 PM",
      "commitName": "d9e2514d21c2ae356ee7fe8d4a857748b5defa4c",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "13/02/13 4:43 PM",
      "commitNameOld": "02e6b72ae148fc8c2ba02ef624536b9e48997b31",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 0.93,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,7 +1,7 @@\n   public static BlockKeyProto convert(BlockKey key) {\n     byte[] encodedKey \u003d key.getEncodedKey();\n-    ByteString keyBytes \u003d ByteString.copyFrom(encodedKey \u003d\u003d null ? new byte[0]\n-        : encodedKey);\n+    ByteString keyBytes \u003d ByteString.copyFrom(encodedKey \u003d\u003d null ? \n+        DFSUtil.EMPTY_BYTES : encodedKey);\n     return BlockKeyProto.newBuilder().setKeyId(key.getKeyId())\n         .setKeyBytes(keyBytes).setExpiryDate(key.getExpiryDate()).build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static BlockKeyProto convert(BlockKey key) {\n    byte[] encodedKey \u003d key.getEncodedKey();\n    ByteString keyBytes \u003d ByteString.copyFrom(encodedKey \u003d\u003d null ? \n        DFSUtil.EMPTY_BYTES : encodedKey);\n    return BlockKeyProto.newBuilder().setKeyId(key.getKeyId())\n        .setKeyBytes(keyBytes).setExpiryDate(key.getExpiryDate()).build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
      "extendedDetails": {}
    },
    "0a713035f2fb1a222291cfdb2cbde906814c2fd9": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-2618. Implement protobuf service for NamenodeProtocol. Contributed by Suresh Srinivas.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1210719 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "05/12/11 4:25 PM",
      "commitName": "0a713035f2fb1a222291cfdb2cbde906814c2fd9",
      "commitAuthor": "Suresh Srinivas",
      "diff": "@@ -0,0 +1,7 @@\n+  public static BlockKeyProto convert(BlockKey key) {\n+    byte[] encodedKey \u003d key.getEncodedKey();\n+    ByteString keyBytes \u003d ByteString.copyFrom(encodedKey \u003d\u003d null ? new byte[0]\n+        : encodedKey);\n+    return BlockKeyProto.newBuilder().setKeyId(key.getKeyId())\n+        .setKeyBytes(keyBytes).setExpiryDate(key.getExpiryDate()).build();\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public static BlockKeyProto convert(BlockKey key) {\n    byte[] encodedKey \u003d key.getEncodedKey();\n    ByteString keyBytes \u003d ByteString.copyFrom(encodedKey \u003d\u003d null ? new byte[0]\n        : encodedKey);\n    return BlockKeyProto.newBuilder().setKeyId(key.getKeyId())\n        .setKeyBytes(keyBytes).setExpiryDate(key.getExpiryDate()).build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java"
    }
  }
}