{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockReaderLocalLegacy.java",
  "functionName": "getDatanodeProxy",
  "functionId": "getDatanodeProxy___ugi-UserGroupInformation__node-DatanodeInfo(modifiers-final)__conf-Configuration(modifiers-final)__socketTimeout-int(modifiers-final)__connectToDnViaHostname-boolean(modifiers-final)",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/client/impl/BlockReaderLocalLegacy.java",
  "functionStartLine": 107,
  "functionEndLine": 125,
  "numCommitsSeen": 31,
  "timeTaken": 2653,
  "changeHistory": [
    "f308561f1d885491b88db73ac63003202056d661",
    "e2c9b288b223b9fd82dc12018936e13128413492",
    "bbb24fbf5d220fbe137d43651ba3802a9806b1a3",
    "694a6721316aea14c1244447974231abc8dff0cb"
  ],
  "changeHistoryShort": {
    "f308561f1d885491b88db73ac63003202056d661": "Yfilerename",
    "e2c9b288b223b9fd82dc12018936e13128413492": "Ymultichange(Yfilerename,Ybodychange)",
    "bbb24fbf5d220fbe137d43651ba3802a9806b1a3": "Ymultichange(Yparameterchange,Ybodychange,Yparametermetachange)",
    "694a6721316aea14c1244447974231abc8dff0cb": "Yintroduced"
  },
  "changeHistoryDetails": {
    "f308561f1d885491b88db73ac63003202056d661": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8057 Move BlockReader implementation to the client implementation package.  Contributed by Takanobu Asanuma\n",
      "commitDate": "25/04/16 12:01 PM",
      "commitName": "f308561f1d885491b88db73ac63003202056d661",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "25/04/16 9:38 AM",
      "commitNameOld": "10f0f7851a3255caab775777e8fb6c2781d97062",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 0.1,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    private synchronized ClientDatanodeProtocol getDatanodeProxy(\n        UserGroupInformation ugi, final DatanodeInfo node,\n        final Configuration conf, final int socketTimeout,\n        final boolean connectToDnViaHostname) throws IOException {\n      if (proxy \u003d\u003d null) {\n        try {\n          proxy \u003d ugi.doAs(new PrivilegedExceptionAction\u003cClientDatanodeProtocol\u003e() {\n            @Override\n            public ClientDatanodeProtocol run() throws Exception {\n              return DFSUtilClient.createClientDatanodeProtocolProxy(node, conf,\n                  socketTimeout, connectToDnViaHostname);\n            }\n          });\n        } catch (InterruptedException e) {\n          LOG.warn(\"encountered exception \", e);\n        }\n      }\n      return proxy;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/client/impl/BlockReaderLocalLegacy.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocalLegacy.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/client/impl/BlockReaderLocalLegacy.java"
      }
    },
    "e2c9b288b223b9fd82dc12018936e13128413492": {
      "type": "Ymultichange(Yfilerename,Ybodychange)",
      "commitMessage": "HDFS-8925. Move BlockReaderLocal to hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "28/08/15 2:38 PM",
      "commitName": "e2c9b288b223b9fd82dc12018936e13128413492",
      "commitAuthor": "Haohui Mai",
      "subchanges": [
        {
          "type": "Yfilerename",
          "commitMessage": "HDFS-8925. Move BlockReaderLocal to hdfs-client. Contributed by Mingliang Liu.\n",
          "commitDate": "28/08/15 2:38 PM",
          "commitName": "e2c9b288b223b9fd82dc12018936e13128413492",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "28/08/15 2:21 PM",
          "commitNameOld": "b94b56806d3d6e04984e229b479f7ac15b62bbfa",
          "commitAuthorOld": "Colin Patrick Mccabe",
          "daysBetweenCommits": 0.01,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,19 +1,19 @@\n     private synchronized ClientDatanodeProtocol getDatanodeProxy(\n         UserGroupInformation ugi, final DatanodeInfo node,\n         final Configuration conf, final int socketTimeout,\n         final boolean connectToDnViaHostname) throws IOException {\n       if (proxy \u003d\u003d null) {\n         try {\n           proxy \u003d ugi.doAs(new PrivilegedExceptionAction\u003cClientDatanodeProtocol\u003e() {\n             @Override\n             public ClientDatanodeProtocol run() throws Exception {\n-              return DFSUtil.createClientDatanodeProtocolProxy(node, conf,\n+              return DFSUtilClient.createClientDatanodeProtocolProxy(node, conf,\n                   socketTimeout, connectToDnViaHostname);\n             }\n           });\n         } catch (InterruptedException e) {\n           LOG.warn(\"encountered exception \", e);\n         }\n       }\n       return proxy;\n     }\n\\ No newline at end of file\n",
          "actualSource": "    private synchronized ClientDatanodeProtocol getDatanodeProxy(\n        UserGroupInformation ugi, final DatanodeInfo node,\n        final Configuration conf, final int socketTimeout,\n        final boolean connectToDnViaHostname) throws IOException {\n      if (proxy \u003d\u003d null) {\n        try {\n          proxy \u003d ugi.doAs(new PrivilegedExceptionAction\u003cClientDatanodeProtocol\u003e() {\n            @Override\n            public ClientDatanodeProtocol run() throws Exception {\n              return DFSUtilClient.createClientDatanodeProtocolProxy(node, conf,\n                  socketTimeout, connectToDnViaHostname);\n            }\n          });\n        } catch (InterruptedException e) {\n          LOG.warn(\"encountered exception \", e);\n        }\n      }\n      return proxy;\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocalLegacy.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocalLegacy.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocalLegacy.java"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-8925. Move BlockReaderLocal to hdfs-client. Contributed by Mingliang Liu.\n",
          "commitDate": "28/08/15 2:38 PM",
          "commitName": "e2c9b288b223b9fd82dc12018936e13128413492",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "28/08/15 2:21 PM",
          "commitNameOld": "b94b56806d3d6e04984e229b479f7ac15b62bbfa",
          "commitAuthorOld": "Colin Patrick Mccabe",
          "daysBetweenCommits": 0.01,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,19 +1,19 @@\n     private synchronized ClientDatanodeProtocol getDatanodeProxy(\n         UserGroupInformation ugi, final DatanodeInfo node,\n         final Configuration conf, final int socketTimeout,\n         final boolean connectToDnViaHostname) throws IOException {\n       if (proxy \u003d\u003d null) {\n         try {\n           proxy \u003d ugi.doAs(new PrivilegedExceptionAction\u003cClientDatanodeProtocol\u003e() {\n             @Override\n             public ClientDatanodeProtocol run() throws Exception {\n-              return DFSUtil.createClientDatanodeProtocolProxy(node, conf,\n+              return DFSUtilClient.createClientDatanodeProtocolProxy(node, conf,\n                   socketTimeout, connectToDnViaHostname);\n             }\n           });\n         } catch (InterruptedException e) {\n           LOG.warn(\"encountered exception \", e);\n         }\n       }\n       return proxy;\n     }\n\\ No newline at end of file\n",
          "actualSource": "    private synchronized ClientDatanodeProtocol getDatanodeProxy(\n        UserGroupInformation ugi, final DatanodeInfo node,\n        final Configuration conf, final int socketTimeout,\n        final boolean connectToDnViaHostname) throws IOException {\n      if (proxy \u003d\u003d null) {\n        try {\n          proxy \u003d ugi.doAs(new PrivilegedExceptionAction\u003cClientDatanodeProtocol\u003e() {\n            @Override\n            public ClientDatanodeProtocol run() throws Exception {\n              return DFSUtilClient.createClientDatanodeProtocolProxy(node, conf,\n                  socketTimeout, connectToDnViaHostname);\n            }\n          });\n        } catch (InterruptedException e) {\n          LOG.warn(\"encountered exception \", e);\n        }\n      }\n      return proxy;\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocalLegacy.java",
          "extendedDetails": {}
        }
      ]
    },
    "bbb24fbf5d220fbe137d43651ba3802a9806b1a3": {
      "type": "Ymultichange(Yparameterchange,Ybodychange,Yparametermetachange)",
      "commitMessage": "Merge trunk into branch.\n\nConflicts resolved:\nC       hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestShortCircuitLocalRead.java\n!     C hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/SocketCache.java\nC       hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java\nC       hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java\nC       hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java\nC       hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocal.java\n\n(thanks to Colin for help resolving)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-347@1462652 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "29/03/13 2:33 PM",
      "commitName": "bbb24fbf5d220fbe137d43651ba3802a9806b1a3",
      "commitAuthor": "Todd Lipcon",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "Merge trunk into branch.\n\nConflicts resolved:\nC       hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestShortCircuitLocalRead.java\n!     C hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/SocketCache.java\nC       hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java\nC       hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java\nC       hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java\nC       hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocal.java\n\n(thanks to Colin for help resolving)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-347@1462652 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "29/03/13 2:33 PM",
          "commitName": "bbb24fbf5d220fbe137d43651ba3802a9806b1a3",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "27/03/13 12:28 PM",
          "commitNameOld": "694a6721316aea14c1244447974231abc8dff0cb",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 2.09,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,9 +1,19 @@\n     private synchronized ClientDatanodeProtocol getDatanodeProxy(\n-        DatanodeInfo node, Configuration conf, int socketTimeout,\n-        boolean connectToDnViaHostname) throws IOException {\n+        UserGroupInformation ugi, final DatanodeInfo node,\n+        final Configuration conf, final int socketTimeout,\n+        final boolean connectToDnViaHostname) throws IOException {\n       if (proxy \u003d\u003d null) {\n-        proxy \u003d DFSUtil.createClientDatanodeProtocolProxy(node, conf,\n-            socketTimeout, connectToDnViaHostname);\n+        try {\n+          proxy \u003d ugi.doAs(new PrivilegedExceptionAction\u003cClientDatanodeProtocol\u003e() {\n+            @Override\n+            public ClientDatanodeProtocol run() throws Exception {\n+              return DFSUtil.createClientDatanodeProtocolProxy(node, conf,\n+                  socketTimeout, connectToDnViaHostname);\n+            }\n+          });\n+        } catch (InterruptedException e) {\n+          LOG.warn(\"encountered exception \", e);\n+        }\n       }\n       return proxy;\n     }\n\\ No newline at end of file\n",
          "actualSource": "    private synchronized ClientDatanodeProtocol getDatanodeProxy(\n        UserGroupInformation ugi, final DatanodeInfo node,\n        final Configuration conf, final int socketTimeout,\n        final boolean connectToDnViaHostname) throws IOException {\n      if (proxy \u003d\u003d null) {\n        try {\n          proxy \u003d ugi.doAs(new PrivilegedExceptionAction\u003cClientDatanodeProtocol\u003e() {\n            @Override\n            public ClientDatanodeProtocol run() throws Exception {\n              return DFSUtil.createClientDatanodeProtocolProxy(node, conf,\n                  socketTimeout, connectToDnViaHostname);\n            }\n          });\n        } catch (InterruptedException e) {\n          LOG.warn(\"encountered exception \", e);\n        }\n      }\n      return proxy;\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocalLegacy.java",
          "extendedDetails": {
            "oldValue": "[node-DatanodeInfo, conf-Configuration, socketTimeout-int, connectToDnViaHostname-boolean]",
            "newValue": "[ugi-UserGroupInformation, node-DatanodeInfo(modifiers-final), conf-Configuration(modifiers-final), socketTimeout-int(modifiers-final), connectToDnViaHostname-boolean(modifiers-final)]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "Merge trunk into branch.\n\nConflicts resolved:\nC       hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestShortCircuitLocalRead.java\n!     C hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/SocketCache.java\nC       hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java\nC       hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java\nC       hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java\nC       hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocal.java\n\n(thanks to Colin for help resolving)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-347@1462652 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "29/03/13 2:33 PM",
          "commitName": "bbb24fbf5d220fbe137d43651ba3802a9806b1a3",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "27/03/13 12:28 PM",
          "commitNameOld": "694a6721316aea14c1244447974231abc8dff0cb",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 2.09,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,9 +1,19 @@\n     private synchronized ClientDatanodeProtocol getDatanodeProxy(\n-        DatanodeInfo node, Configuration conf, int socketTimeout,\n-        boolean connectToDnViaHostname) throws IOException {\n+        UserGroupInformation ugi, final DatanodeInfo node,\n+        final Configuration conf, final int socketTimeout,\n+        final boolean connectToDnViaHostname) throws IOException {\n       if (proxy \u003d\u003d null) {\n-        proxy \u003d DFSUtil.createClientDatanodeProtocolProxy(node, conf,\n-            socketTimeout, connectToDnViaHostname);\n+        try {\n+          proxy \u003d ugi.doAs(new PrivilegedExceptionAction\u003cClientDatanodeProtocol\u003e() {\n+            @Override\n+            public ClientDatanodeProtocol run() throws Exception {\n+              return DFSUtil.createClientDatanodeProtocolProxy(node, conf,\n+                  socketTimeout, connectToDnViaHostname);\n+            }\n+          });\n+        } catch (InterruptedException e) {\n+          LOG.warn(\"encountered exception \", e);\n+        }\n       }\n       return proxy;\n     }\n\\ No newline at end of file\n",
          "actualSource": "    private synchronized ClientDatanodeProtocol getDatanodeProxy(\n        UserGroupInformation ugi, final DatanodeInfo node,\n        final Configuration conf, final int socketTimeout,\n        final boolean connectToDnViaHostname) throws IOException {\n      if (proxy \u003d\u003d null) {\n        try {\n          proxy \u003d ugi.doAs(new PrivilegedExceptionAction\u003cClientDatanodeProtocol\u003e() {\n            @Override\n            public ClientDatanodeProtocol run() throws Exception {\n              return DFSUtil.createClientDatanodeProtocolProxy(node, conf,\n                  socketTimeout, connectToDnViaHostname);\n            }\n          });\n        } catch (InterruptedException e) {\n          LOG.warn(\"encountered exception \", e);\n        }\n      }\n      return proxy;\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocalLegacy.java",
          "extendedDetails": {}
        },
        {
          "type": "Yparametermetachange",
          "commitMessage": "Merge trunk into branch.\n\nConflicts resolved:\nC       hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestShortCircuitLocalRead.java\n!     C hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/SocketCache.java\nC       hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java\nC       hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java\nC       hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java\nC       hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocal.java\n\n(thanks to Colin for help resolving)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-347@1462652 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "29/03/13 2:33 PM",
          "commitName": "bbb24fbf5d220fbe137d43651ba3802a9806b1a3",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "27/03/13 12:28 PM",
          "commitNameOld": "694a6721316aea14c1244447974231abc8dff0cb",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 2.09,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,9 +1,19 @@\n     private synchronized ClientDatanodeProtocol getDatanodeProxy(\n-        DatanodeInfo node, Configuration conf, int socketTimeout,\n-        boolean connectToDnViaHostname) throws IOException {\n+        UserGroupInformation ugi, final DatanodeInfo node,\n+        final Configuration conf, final int socketTimeout,\n+        final boolean connectToDnViaHostname) throws IOException {\n       if (proxy \u003d\u003d null) {\n-        proxy \u003d DFSUtil.createClientDatanodeProtocolProxy(node, conf,\n-            socketTimeout, connectToDnViaHostname);\n+        try {\n+          proxy \u003d ugi.doAs(new PrivilegedExceptionAction\u003cClientDatanodeProtocol\u003e() {\n+            @Override\n+            public ClientDatanodeProtocol run() throws Exception {\n+              return DFSUtil.createClientDatanodeProtocolProxy(node, conf,\n+                  socketTimeout, connectToDnViaHostname);\n+            }\n+          });\n+        } catch (InterruptedException e) {\n+          LOG.warn(\"encountered exception \", e);\n+        }\n       }\n       return proxy;\n     }\n\\ No newline at end of file\n",
          "actualSource": "    private synchronized ClientDatanodeProtocol getDatanodeProxy(\n        UserGroupInformation ugi, final DatanodeInfo node,\n        final Configuration conf, final int socketTimeout,\n        final boolean connectToDnViaHostname) throws IOException {\n      if (proxy \u003d\u003d null) {\n        try {\n          proxy \u003d ugi.doAs(new PrivilegedExceptionAction\u003cClientDatanodeProtocol\u003e() {\n            @Override\n            public ClientDatanodeProtocol run() throws Exception {\n              return DFSUtil.createClientDatanodeProtocolProxy(node, conf,\n                  socketTimeout, connectToDnViaHostname);\n            }\n          });\n        } catch (InterruptedException e) {\n          LOG.warn(\"encountered exception \", e);\n        }\n      }\n      return proxy;\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocalLegacy.java",
          "extendedDetails": {
            "oldValue": "[node-DatanodeInfo, conf-Configuration, socketTimeout-int, connectToDnViaHostname-boolean]",
            "newValue": "[ugi-UserGroupInformation, node-DatanodeInfo(modifiers-final), conf-Configuration(modifiers-final), socketTimeout-int(modifiers-final), connectToDnViaHostname-boolean(modifiers-final)]"
          }
        }
      ]
    },
    "694a6721316aea14c1244447974231abc8dff0cb": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-4538. Allow use of legacy blockreader. Contributed by Colin Patrick McCabe.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-347@1461818 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/03/13 12:28 PM",
      "commitName": "694a6721316aea14c1244447974231abc8dff0cb",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,9 @@\n+    private synchronized ClientDatanodeProtocol getDatanodeProxy(\n+        DatanodeInfo node, Configuration conf, int socketTimeout,\n+        boolean connectToDnViaHostname) throws IOException {\n+      if (proxy \u003d\u003d null) {\n+        proxy \u003d DFSUtil.createClientDatanodeProtocolProxy(node, conf,\n+            socketTimeout, connectToDnViaHostname);\n+      }\n+      return proxy;\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    private synchronized ClientDatanodeProtocol getDatanodeProxy(\n        DatanodeInfo node, Configuration conf, int socketTimeout,\n        boolean connectToDnViaHostname) throws IOException {\n      if (proxy \u003d\u003d null) {\n        proxy \u003d DFSUtil.createClientDatanodeProtocolProxy(node, conf,\n            socketTimeout, connectToDnViaHostname);\n      }\n      return proxy;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocalLegacy.java"
    }
  }
}