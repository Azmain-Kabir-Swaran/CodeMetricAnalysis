{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "TFileDumper.java",
  "functionName": "dumpInfo",
  "functionId": "dumpInfo___file-String__out-PrintStream__conf-Configuration",
  "sourceFilePath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/file/tfile/TFileDumper.java",
  "functionStartLine": 96,
  "functionEndLine": 295,
  "numCommitsSeen": 9,
  "timeTaken": 1913,
  "changeHistory": [
    "ccaf036662e22da14583942054898c99fa51dae5",
    "770b5eb2db686275df445be9280e76cc3710ffdc",
    "5b9fcedb4d116d91d70aaad6cbf59093eeee36df",
    "84d50003f6e46f9f9ac2b9d7bb937de757be161b",
    "0c53ed4cd122f87b2b041d670b9b59e27da5439c",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "0f6dfeeacbab65a31a33927a4eb84871d371fe52",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
    "8246aa28ff72e3ae81eb6ce59852abd5828fadc6"
  ],
  "changeHistoryShort": {
    "ccaf036662e22da14583942054898c99fa51dae5": "Ybodychange",
    "770b5eb2db686275df445be9280e76cc3710ffdc": "Ybodychange",
    "5b9fcedb4d116d91d70aaad6cbf59093eeee36df": "Ybodychange",
    "84d50003f6e46f9f9ac2b9d7bb937de757be161b": "Ybodychange",
    "0c53ed4cd122f87b2b041d670b9b59e27da5439c": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "0f6dfeeacbab65a31a33927a4eb84871d371fe52": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yfilerename",
    "8246aa28ff72e3ae81eb6ce59852abd5828fadc6": "Yintroduced"
  },
  "changeHistoryDetails": {
    "ccaf036662e22da14583942054898c99fa51dae5": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-14539. Move commons logging APIs over to slf4j in hadoop-common. Contributed by Wenxin He.\n",
      "commitDate": "17/07/17 9:32 PM",
      "commitName": "ccaf036662e22da14583942054898c99fa51dae5",
      "commitAuthor": "Akira Ajisaka",
      "commitDateOld": "01/08/16 1:35 AM",
      "commitNameOld": "770b5eb2db686275df445be9280e76cc3710ffdc",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 350.83,
      "commitsBetweenForRepo": 2088,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,200 +1,200 @@\n   static public void dumpInfo(String file, PrintStream out, Configuration conf)\n       throws IOException {\n     final int maxKeySampleLen \u003d 16;\n     Path path \u003d new Path(file);\n     FileSystem fs \u003d path.getFileSystem(conf);\n     long length \u003d fs.getFileStatus(path).getLen();\n     FSDataInputStream fsdis \u003d fs.open(path);\n     TFile.Reader reader \u003d new TFile.Reader(fsdis, length, conf);\n     try {\n       LinkedHashMap\u003cString, String\u003e properties \u003d\n           new LinkedHashMap\u003cString, String\u003e();\n       int blockCnt \u003d reader.readerBCF.getBlockCount();\n       int metaBlkCnt \u003d reader.readerBCF.metaIndex.index.size();\n       properties.put(\"BCFile Version\", reader.readerBCF.version.toString());\n       properties.put(\"TFile Version\", reader.tfileMeta.version.toString());\n       properties.put(\"File Length\", Long.toString(length));\n       properties.put(\"Data Compression\", reader.readerBCF\n           .getDefaultCompressionName());\n       properties.put(\"Record Count\", Long.toString(reader.getEntryCount()));\n       properties.put(\"Sorted\", Boolean.toString(reader.isSorted()));\n       if (reader.isSorted()) {\n         properties.put(\"Comparator\", reader.getComparatorName());\n       }\n       properties.put(\"Data Block Count\", Integer.toString(blockCnt));\n       long dataSize \u003d 0, dataSizeUncompressed \u003d 0;\n       if (blockCnt \u003e 0) {\n         for (int i \u003d 0; i \u003c blockCnt; ++i) {\n           BlockRegion region \u003d\n               reader.readerBCF.dataIndex.getBlockRegionList().get(i);\n           dataSize +\u003d region.getCompressedSize();\n           dataSizeUncompressed +\u003d region.getRawSize();\n         }\n         properties.put(\"Data Block Bytes\", Long.toString(dataSize));\n         if (!reader.readerBCF.getDefaultCompressionName().equals(\"none\")) {\n           properties.put(\"Data Block Uncompressed Bytes\", Long\n               .toString(dataSizeUncompressed));\n           properties.put(\"Data Block Compression Ratio\", String.format(\n               \"1:%.1f\", (double) dataSizeUncompressed / dataSize));\n         }\n       }\n \n       properties.put(\"Meta Block Count\", Integer.toString(metaBlkCnt));\n       long metaSize \u003d 0, metaSizeUncompressed \u003d 0;\n       if (metaBlkCnt \u003e 0) {\n         Collection\u003cMetaIndexEntry\u003e metaBlks \u003d\n             reader.readerBCF.metaIndex.index.values();\n         boolean calculateCompression \u003d false;\n         for (Iterator\u003cMetaIndexEntry\u003e it \u003d metaBlks.iterator(); it.hasNext();) {\n           MetaIndexEntry e \u003d it.next();\n           metaSize +\u003d e.getRegion().getCompressedSize();\n           metaSizeUncompressed +\u003d e.getRegion().getRawSize();\n           if (e.getCompressionAlgorithm() !\u003d Compression.Algorithm.NONE) {\n             calculateCompression \u003d true;\n           }\n         }\n         properties.put(\"Meta Block Bytes\", Long.toString(metaSize));\n         if (calculateCompression) {\n           properties.put(\"Meta Block Uncompressed Bytes\", Long\n               .toString(metaSizeUncompressed));\n           properties.put(\"Meta Block Compression Ratio\", String.format(\n               \"1:%.1f\", (double) metaSizeUncompressed / metaSize));\n         }\n       }\n       properties.put(\"Meta-Data Size Ratio\", String.format(\"1:%.1f\",\n           (double) dataSize / metaSize));\n       long leftOverBytes \u003d length - dataSize - metaSize;\n       long miscSize \u003d\n           BCFile.Magic.size() * 2 + Long.SIZE / Byte.SIZE + Version.size();\n       long metaIndexSize \u003d leftOverBytes - miscSize;\n       properties.put(\"Meta Block Index Bytes\", Long.toString(metaIndexSize));\n       properties.put(\"Headers Etc Bytes\", Long.toString(miscSize));\n       // Now output the properties table.\n       int maxKeyLength \u003d 0;\n       Set\u003cMap.Entry\u003cString, String\u003e\u003e entrySet \u003d properties.entrySet();\n       for (Iterator\u003cMap.Entry\u003cString, String\u003e\u003e it \u003d entrySet.iterator(); it\n           .hasNext();) {\n         Map.Entry\u003cString, String\u003e e \u003d it.next();\n         if (e.getKey().length() \u003e maxKeyLength) {\n           maxKeyLength \u003d e.getKey().length();\n         }\n       }\n       for (Iterator\u003cMap.Entry\u003cString, String\u003e\u003e it \u003d entrySet.iterator(); it\n           .hasNext();) {\n         Map.Entry\u003cString, String\u003e e \u003d it.next();\n         out.printf(\"%s : %s%n\", Align.format(e.getKey(), maxKeyLength,\n             Align.LEFT), e.getValue());\n       }\n       out.println();\n       reader.checkTFileDataIndex();\n       if (blockCnt \u003e 0) {\n         String blkID \u003d \"Data-Block\";\n         int blkIDWidth \u003d Align.calculateWidth(blkID, blockCnt);\n         int blkIDWidth2 \u003d Align.calculateWidth(\"\", blockCnt);\n         String offset \u003d \"Offset\";\n         int offsetWidth \u003d Align.calculateWidth(offset, length);\n         String blkLen \u003d \"Length\";\n         int blkLenWidth \u003d\n             Align.calculateWidth(blkLen, dataSize / blockCnt * 10);\n         String rawSize \u003d \"Raw-Size\";\n         int rawSizeWidth \u003d\n             Align.calculateWidth(rawSize, dataSizeUncompressed / blockCnt * 10);\n         String records \u003d \"Records\";\n         int recordsWidth \u003d\n             Align.calculateWidth(records, reader.getEntryCount() / blockCnt\n                 * 10);\n         String endKey \u003d \"End-Key\";\n         int endKeyWidth \u003d Math.max(endKey.length(), maxKeySampleLen * 2 + 5);\n \n         out.printf(\"%s %s %s %s %s %s%n\", Align.format(blkID, blkIDWidth,\n             Align.CENTER), Align.format(offset, offsetWidth, Align.CENTER),\n             Align.format(blkLen, blkLenWidth, Align.CENTER), Align.format(\n                 rawSize, rawSizeWidth, Align.CENTER), Align.format(records,\n                 recordsWidth, Align.CENTER), Align.format(endKey, endKeyWidth,\n                 Align.LEFT));\n \n         for (int i \u003d 0; i \u003c blockCnt; ++i) {\n           BlockRegion region \u003d\n               reader.readerBCF.dataIndex.getBlockRegionList().get(i);\n           TFileIndexEntry indexEntry \u003d reader.tfileIndex.getEntry(i);\n           out.printf(\"%s %s %s %s %s \", Align.format(Align.format(i,\n               blkIDWidth2, Align.ZERO_PADDED), blkIDWidth, Align.LEFT), Align\n               .format(region.getOffset(), offsetWidth, Align.LEFT), Align\n               .format(region.getCompressedSize(), blkLenWidth, Align.LEFT),\n               Align.format(region.getRawSize(), rawSizeWidth, Align.LEFT),\n               Align.format(indexEntry.kvEntries, recordsWidth, Align.LEFT));\n           byte[] key \u003d indexEntry.key;\n           boolean asAscii \u003d true;\n           int sampleLen \u003d Math.min(maxKeySampleLen, key.length);\n           for (int j \u003d 0; j \u003c sampleLen; ++j) {\n             byte b \u003d key[j];\n             if ((b \u003c 32 \u0026\u0026 b !\u003d 9) || (b \u003d\u003d 127)) {\n               asAscii \u003d false;\n             }\n           }\n           if (!asAscii) {\n             out.print(\"0X\");\n             for (int j \u003d 0; j \u003c sampleLen; ++j) {\n               byte b \u003d key[i];\n               out.printf(\"%X\", b);\n             }\n           } else {\n             out.print(new String(key, 0, sampleLen, StandardCharsets.UTF_8));\n           }\n           if (sampleLen \u003c key.length) {\n             out.print(\"...\");\n           }\n           out.println();\n         }\n       }\n \n       out.println();\n       if (metaBlkCnt \u003e 0) {\n         String name \u003d \"Meta-Block\";\n         int maxNameLen \u003d 0;\n         Set\u003cMap.Entry\u003cString, MetaIndexEntry\u003e\u003e metaBlkEntrySet \u003d\n             reader.readerBCF.metaIndex.index.entrySet();\n         for (Iterator\u003cMap.Entry\u003cString, MetaIndexEntry\u003e\u003e it \u003d\n             metaBlkEntrySet.iterator(); it.hasNext();) {\n           Map.Entry\u003cString, MetaIndexEntry\u003e e \u003d it.next();\n           if (e.getKey().length() \u003e maxNameLen) {\n             maxNameLen \u003d e.getKey().length();\n           }\n         }\n         int nameWidth \u003d Math.max(name.length(), maxNameLen);\n         String offset \u003d \"Offset\";\n         int offsetWidth \u003d Align.calculateWidth(offset, length);\n         String blkLen \u003d \"Length\";\n         int blkLenWidth \u003d\n             Align.calculateWidth(blkLen, metaSize / metaBlkCnt * 10);\n         String rawSize \u003d \"Raw-Size\";\n         int rawSizeWidth \u003d\n             Align.calculateWidth(rawSize, metaSizeUncompressed / metaBlkCnt\n                 * 10);\n         String compression \u003d \"Compression\";\n         int compressionWidth \u003d compression.length();\n         out.printf(\"%s %s %s %s %s%n\", Align.format(name, nameWidth,\n             Align.CENTER), Align.format(offset, offsetWidth, Align.CENTER),\n             Align.format(blkLen, blkLenWidth, Align.CENTER), Align.format(\n                 rawSize, rawSizeWidth, Align.CENTER), Align.format(compression,\n                 compressionWidth, Align.LEFT));\n \n         for (Iterator\u003cMap.Entry\u003cString, MetaIndexEntry\u003e\u003e it \u003d\n             metaBlkEntrySet.iterator(); it.hasNext();) {\n           Map.Entry\u003cString, MetaIndexEntry\u003e e \u003d it.next();\n           String blkName \u003d e.getValue().getMetaName();\n           BlockRegion region \u003d e.getValue().getRegion();\n           String blkCompression \u003d\n               e.getValue().getCompressionAlgorithm().getName();\n           out.printf(\"%s %s %s %s %s%n\", Align.format(blkName, nameWidth,\n               Align.LEFT), Align.format(region.getOffset(), offsetWidth,\n               Align.LEFT), Align.format(region.getCompressedSize(),\n               blkLenWidth, Align.LEFT), Align.format(region.getRawSize(),\n               rawSizeWidth, Align.LEFT), Align.format(blkCompression,\n               compressionWidth, Align.LEFT));\n         }\n       }\n     } finally {\n-      IOUtils.cleanup(LOG, reader, fsdis);\n+      IOUtils.cleanupWithLogger(LOG, reader, fsdis);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static public void dumpInfo(String file, PrintStream out, Configuration conf)\n      throws IOException {\n    final int maxKeySampleLen \u003d 16;\n    Path path \u003d new Path(file);\n    FileSystem fs \u003d path.getFileSystem(conf);\n    long length \u003d fs.getFileStatus(path).getLen();\n    FSDataInputStream fsdis \u003d fs.open(path);\n    TFile.Reader reader \u003d new TFile.Reader(fsdis, length, conf);\n    try {\n      LinkedHashMap\u003cString, String\u003e properties \u003d\n          new LinkedHashMap\u003cString, String\u003e();\n      int blockCnt \u003d reader.readerBCF.getBlockCount();\n      int metaBlkCnt \u003d reader.readerBCF.metaIndex.index.size();\n      properties.put(\"BCFile Version\", reader.readerBCF.version.toString());\n      properties.put(\"TFile Version\", reader.tfileMeta.version.toString());\n      properties.put(\"File Length\", Long.toString(length));\n      properties.put(\"Data Compression\", reader.readerBCF\n          .getDefaultCompressionName());\n      properties.put(\"Record Count\", Long.toString(reader.getEntryCount()));\n      properties.put(\"Sorted\", Boolean.toString(reader.isSorted()));\n      if (reader.isSorted()) {\n        properties.put(\"Comparator\", reader.getComparatorName());\n      }\n      properties.put(\"Data Block Count\", Integer.toString(blockCnt));\n      long dataSize \u003d 0, dataSizeUncompressed \u003d 0;\n      if (blockCnt \u003e 0) {\n        for (int i \u003d 0; i \u003c blockCnt; ++i) {\n          BlockRegion region \u003d\n              reader.readerBCF.dataIndex.getBlockRegionList().get(i);\n          dataSize +\u003d region.getCompressedSize();\n          dataSizeUncompressed +\u003d region.getRawSize();\n        }\n        properties.put(\"Data Block Bytes\", Long.toString(dataSize));\n        if (!reader.readerBCF.getDefaultCompressionName().equals(\"none\")) {\n          properties.put(\"Data Block Uncompressed Bytes\", Long\n              .toString(dataSizeUncompressed));\n          properties.put(\"Data Block Compression Ratio\", String.format(\n              \"1:%.1f\", (double) dataSizeUncompressed / dataSize));\n        }\n      }\n\n      properties.put(\"Meta Block Count\", Integer.toString(metaBlkCnt));\n      long metaSize \u003d 0, metaSizeUncompressed \u003d 0;\n      if (metaBlkCnt \u003e 0) {\n        Collection\u003cMetaIndexEntry\u003e metaBlks \u003d\n            reader.readerBCF.metaIndex.index.values();\n        boolean calculateCompression \u003d false;\n        for (Iterator\u003cMetaIndexEntry\u003e it \u003d metaBlks.iterator(); it.hasNext();) {\n          MetaIndexEntry e \u003d it.next();\n          metaSize +\u003d e.getRegion().getCompressedSize();\n          metaSizeUncompressed +\u003d e.getRegion().getRawSize();\n          if (e.getCompressionAlgorithm() !\u003d Compression.Algorithm.NONE) {\n            calculateCompression \u003d true;\n          }\n        }\n        properties.put(\"Meta Block Bytes\", Long.toString(metaSize));\n        if (calculateCompression) {\n          properties.put(\"Meta Block Uncompressed Bytes\", Long\n              .toString(metaSizeUncompressed));\n          properties.put(\"Meta Block Compression Ratio\", String.format(\n              \"1:%.1f\", (double) metaSizeUncompressed / metaSize));\n        }\n      }\n      properties.put(\"Meta-Data Size Ratio\", String.format(\"1:%.1f\",\n          (double) dataSize / metaSize));\n      long leftOverBytes \u003d length - dataSize - metaSize;\n      long miscSize \u003d\n          BCFile.Magic.size() * 2 + Long.SIZE / Byte.SIZE + Version.size();\n      long metaIndexSize \u003d leftOverBytes - miscSize;\n      properties.put(\"Meta Block Index Bytes\", Long.toString(metaIndexSize));\n      properties.put(\"Headers Etc Bytes\", Long.toString(miscSize));\n      // Now output the properties table.\n      int maxKeyLength \u003d 0;\n      Set\u003cMap.Entry\u003cString, String\u003e\u003e entrySet \u003d properties.entrySet();\n      for (Iterator\u003cMap.Entry\u003cString, String\u003e\u003e it \u003d entrySet.iterator(); it\n          .hasNext();) {\n        Map.Entry\u003cString, String\u003e e \u003d it.next();\n        if (e.getKey().length() \u003e maxKeyLength) {\n          maxKeyLength \u003d e.getKey().length();\n        }\n      }\n      for (Iterator\u003cMap.Entry\u003cString, String\u003e\u003e it \u003d entrySet.iterator(); it\n          .hasNext();) {\n        Map.Entry\u003cString, String\u003e e \u003d it.next();\n        out.printf(\"%s : %s%n\", Align.format(e.getKey(), maxKeyLength,\n            Align.LEFT), e.getValue());\n      }\n      out.println();\n      reader.checkTFileDataIndex();\n      if (blockCnt \u003e 0) {\n        String blkID \u003d \"Data-Block\";\n        int blkIDWidth \u003d Align.calculateWidth(blkID, blockCnt);\n        int blkIDWidth2 \u003d Align.calculateWidth(\"\", blockCnt);\n        String offset \u003d \"Offset\";\n        int offsetWidth \u003d Align.calculateWidth(offset, length);\n        String blkLen \u003d \"Length\";\n        int blkLenWidth \u003d\n            Align.calculateWidth(blkLen, dataSize / blockCnt * 10);\n        String rawSize \u003d \"Raw-Size\";\n        int rawSizeWidth \u003d\n            Align.calculateWidth(rawSize, dataSizeUncompressed / blockCnt * 10);\n        String records \u003d \"Records\";\n        int recordsWidth \u003d\n            Align.calculateWidth(records, reader.getEntryCount() / blockCnt\n                * 10);\n        String endKey \u003d \"End-Key\";\n        int endKeyWidth \u003d Math.max(endKey.length(), maxKeySampleLen * 2 + 5);\n\n        out.printf(\"%s %s %s %s %s %s%n\", Align.format(blkID, blkIDWidth,\n            Align.CENTER), Align.format(offset, offsetWidth, Align.CENTER),\n            Align.format(blkLen, blkLenWidth, Align.CENTER), Align.format(\n                rawSize, rawSizeWidth, Align.CENTER), Align.format(records,\n                recordsWidth, Align.CENTER), Align.format(endKey, endKeyWidth,\n                Align.LEFT));\n\n        for (int i \u003d 0; i \u003c blockCnt; ++i) {\n          BlockRegion region \u003d\n              reader.readerBCF.dataIndex.getBlockRegionList().get(i);\n          TFileIndexEntry indexEntry \u003d reader.tfileIndex.getEntry(i);\n          out.printf(\"%s %s %s %s %s \", Align.format(Align.format(i,\n              blkIDWidth2, Align.ZERO_PADDED), blkIDWidth, Align.LEFT), Align\n              .format(region.getOffset(), offsetWidth, Align.LEFT), Align\n              .format(region.getCompressedSize(), blkLenWidth, Align.LEFT),\n              Align.format(region.getRawSize(), rawSizeWidth, Align.LEFT),\n              Align.format(indexEntry.kvEntries, recordsWidth, Align.LEFT));\n          byte[] key \u003d indexEntry.key;\n          boolean asAscii \u003d true;\n          int sampleLen \u003d Math.min(maxKeySampleLen, key.length);\n          for (int j \u003d 0; j \u003c sampleLen; ++j) {\n            byte b \u003d key[j];\n            if ((b \u003c 32 \u0026\u0026 b !\u003d 9) || (b \u003d\u003d 127)) {\n              asAscii \u003d false;\n            }\n          }\n          if (!asAscii) {\n            out.print(\"0X\");\n            for (int j \u003d 0; j \u003c sampleLen; ++j) {\n              byte b \u003d key[i];\n              out.printf(\"%X\", b);\n            }\n          } else {\n            out.print(new String(key, 0, sampleLen, StandardCharsets.UTF_8));\n          }\n          if (sampleLen \u003c key.length) {\n            out.print(\"...\");\n          }\n          out.println();\n        }\n      }\n\n      out.println();\n      if (metaBlkCnt \u003e 0) {\n        String name \u003d \"Meta-Block\";\n        int maxNameLen \u003d 0;\n        Set\u003cMap.Entry\u003cString, MetaIndexEntry\u003e\u003e metaBlkEntrySet \u003d\n            reader.readerBCF.metaIndex.index.entrySet();\n        for (Iterator\u003cMap.Entry\u003cString, MetaIndexEntry\u003e\u003e it \u003d\n            metaBlkEntrySet.iterator(); it.hasNext();) {\n          Map.Entry\u003cString, MetaIndexEntry\u003e e \u003d it.next();\n          if (e.getKey().length() \u003e maxNameLen) {\n            maxNameLen \u003d e.getKey().length();\n          }\n        }\n        int nameWidth \u003d Math.max(name.length(), maxNameLen);\n        String offset \u003d \"Offset\";\n        int offsetWidth \u003d Align.calculateWidth(offset, length);\n        String blkLen \u003d \"Length\";\n        int blkLenWidth \u003d\n            Align.calculateWidth(blkLen, metaSize / metaBlkCnt * 10);\n        String rawSize \u003d \"Raw-Size\";\n        int rawSizeWidth \u003d\n            Align.calculateWidth(rawSize, metaSizeUncompressed / metaBlkCnt\n                * 10);\n        String compression \u003d \"Compression\";\n        int compressionWidth \u003d compression.length();\n        out.printf(\"%s %s %s %s %s%n\", Align.format(name, nameWidth,\n            Align.CENTER), Align.format(offset, offsetWidth, Align.CENTER),\n            Align.format(blkLen, blkLenWidth, Align.CENTER), Align.format(\n                rawSize, rawSizeWidth, Align.CENTER), Align.format(compression,\n                compressionWidth, Align.LEFT));\n\n        for (Iterator\u003cMap.Entry\u003cString, MetaIndexEntry\u003e\u003e it \u003d\n            metaBlkEntrySet.iterator(); it.hasNext();) {\n          Map.Entry\u003cString, MetaIndexEntry\u003e e \u003d it.next();\n          String blkName \u003d e.getValue().getMetaName();\n          BlockRegion region \u003d e.getValue().getRegion();\n          String blkCompression \u003d\n              e.getValue().getCompressionAlgorithm().getName();\n          out.printf(\"%s %s %s %s %s%n\", Align.format(blkName, nameWidth,\n              Align.LEFT), Align.format(region.getOffset(), offsetWidth,\n              Align.LEFT), Align.format(region.getCompressedSize(),\n              blkLenWidth, Align.LEFT), Align.format(region.getRawSize(),\n              rawSizeWidth, Align.LEFT), Align.format(blkCompression,\n              compressionWidth, Align.LEFT));\n        }\n      }\n    } finally {\n      IOUtils.cleanupWithLogger(LOG, reader, fsdis);\n    }\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/file/tfile/TFileDumper.java",
      "extendedDetails": {}
    },
    "770b5eb2db686275df445be9280e76cc3710ffdc": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-13444. Replace org.apache.commons.io.Charsets with java.nio.charset.StandardCharsets. Contributed by Vincent Poon.\n",
      "commitDate": "01/08/16 1:35 AM",
      "commitName": "770b5eb2db686275df445be9280e76cc3710ffdc",
      "commitAuthor": "Akira Ajisaka",
      "commitDateOld": "11/12/14 4:42 PM",
      "commitNameOld": "5b9fcedb4d116d91d70aaad6cbf59093eeee36df",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 598.33,
      "commitsBetweenForRepo": 4564,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,200 +1,200 @@\n   static public void dumpInfo(String file, PrintStream out, Configuration conf)\n       throws IOException {\n     final int maxKeySampleLen \u003d 16;\n     Path path \u003d new Path(file);\n     FileSystem fs \u003d path.getFileSystem(conf);\n     long length \u003d fs.getFileStatus(path).getLen();\n     FSDataInputStream fsdis \u003d fs.open(path);\n     TFile.Reader reader \u003d new TFile.Reader(fsdis, length, conf);\n     try {\n       LinkedHashMap\u003cString, String\u003e properties \u003d\n           new LinkedHashMap\u003cString, String\u003e();\n       int blockCnt \u003d reader.readerBCF.getBlockCount();\n       int metaBlkCnt \u003d reader.readerBCF.metaIndex.index.size();\n       properties.put(\"BCFile Version\", reader.readerBCF.version.toString());\n       properties.put(\"TFile Version\", reader.tfileMeta.version.toString());\n       properties.put(\"File Length\", Long.toString(length));\n       properties.put(\"Data Compression\", reader.readerBCF\n           .getDefaultCompressionName());\n       properties.put(\"Record Count\", Long.toString(reader.getEntryCount()));\n       properties.put(\"Sorted\", Boolean.toString(reader.isSorted()));\n       if (reader.isSorted()) {\n         properties.put(\"Comparator\", reader.getComparatorName());\n       }\n       properties.put(\"Data Block Count\", Integer.toString(blockCnt));\n       long dataSize \u003d 0, dataSizeUncompressed \u003d 0;\n       if (blockCnt \u003e 0) {\n         for (int i \u003d 0; i \u003c blockCnt; ++i) {\n           BlockRegion region \u003d\n               reader.readerBCF.dataIndex.getBlockRegionList().get(i);\n           dataSize +\u003d region.getCompressedSize();\n           dataSizeUncompressed +\u003d region.getRawSize();\n         }\n         properties.put(\"Data Block Bytes\", Long.toString(dataSize));\n         if (!reader.readerBCF.getDefaultCompressionName().equals(\"none\")) {\n           properties.put(\"Data Block Uncompressed Bytes\", Long\n               .toString(dataSizeUncompressed));\n           properties.put(\"Data Block Compression Ratio\", String.format(\n               \"1:%.1f\", (double) dataSizeUncompressed / dataSize));\n         }\n       }\n \n       properties.put(\"Meta Block Count\", Integer.toString(metaBlkCnt));\n       long metaSize \u003d 0, metaSizeUncompressed \u003d 0;\n       if (metaBlkCnt \u003e 0) {\n         Collection\u003cMetaIndexEntry\u003e metaBlks \u003d\n             reader.readerBCF.metaIndex.index.values();\n         boolean calculateCompression \u003d false;\n         for (Iterator\u003cMetaIndexEntry\u003e it \u003d metaBlks.iterator(); it.hasNext();) {\n           MetaIndexEntry e \u003d it.next();\n           metaSize +\u003d e.getRegion().getCompressedSize();\n           metaSizeUncompressed +\u003d e.getRegion().getRawSize();\n           if (e.getCompressionAlgorithm() !\u003d Compression.Algorithm.NONE) {\n             calculateCompression \u003d true;\n           }\n         }\n         properties.put(\"Meta Block Bytes\", Long.toString(metaSize));\n         if (calculateCompression) {\n           properties.put(\"Meta Block Uncompressed Bytes\", Long\n               .toString(metaSizeUncompressed));\n           properties.put(\"Meta Block Compression Ratio\", String.format(\n               \"1:%.1f\", (double) metaSizeUncompressed / metaSize));\n         }\n       }\n       properties.put(\"Meta-Data Size Ratio\", String.format(\"1:%.1f\",\n           (double) dataSize / metaSize));\n       long leftOverBytes \u003d length - dataSize - metaSize;\n       long miscSize \u003d\n           BCFile.Magic.size() * 2 + Long.SIZE / Byte.SIZE + Version.size();\n       long metaIndexSize \u003d leftOverBytes - miscSize;\n       properties.put(\"Meta Block Index Bytes\", Long.toString(metaIndexSize));\n       properties.put(\"Headers Etc Bytes\", Long.toString(miscSize));\n       // Now output the properties table.\n       int maxKeyLength \u003d 0;\n       Set\u003cMap.Entry\u003cString, String\u003e\u003e entrySet \u003d properties.entrySet();\n       for (Iterator\u003cMap.Entry\u003cString, String\u003e\u003e it \u003d entrySet.iterator(); it\n           .hasNext();) {\n         Map.Entry\u003cString, String\u003e e \u003d it.next();\n         if (e.getKey().length() \u003e maxKeyLength) {\n           maxKeyLength \u003d e.getKey().length();\n         }\n       }\n       for (Iterator\u003cMap.Entry\u003cString, String\u003e\u003e it \u003d entrySet.iterator(); it\n           .hasNext();) {\n         Map.Entry\u003cString, String\u003e e \u003d it.next();\n         out.printf(\"%s : %s%n\", Align.format(e.getKey(), maxKeyLength,\n             Align.LEFT), e.getValue());\n       }\n       out.println();\n       reader.checkTFileDataIndex();\n       if (blockCnt \u003e 0) {\n         String blkID \u003d \"Data-Block\";\n         int blkIDWidth \u003d Align.calculateWidth(blkID, blockCnt);\n         int blkIDWidth2 \u003d Align.calculateWidth(\"\", blockCnt);\n         String offset \u003d \"Offset\";\n         int offsetWidth \u003d Align.calculateWidth(offset, length);\n         String blkLen \u003d \"Length\";\n         int blkLenWidth \u003d\n             Align.calculateWidth(blkLen, dataSize / blockCnt * 10);\n         String rawSize \u003d \"Raw-Size\";\n         int rawSizeWidth \u003d\n             Align.calculateWidth(rawSize, dataSizeUncompressed / blockCnt * 10);\n         String records \u003d \"Records\";\n         int recordsWidth \u003d\n             Align.calculateWidth(records, reader.getEntryCount() / blockCnt\n                 * 10);\n         String endKey \u003d \"End-Key\";\n         int endKeyWidth \u003d Math.max(endKey.length(), maxKeySampleLen * 2 + 5);\n \n         out.printf(\"%s %s %s %s %s %s%n\", Align.format(blkID, blkIDWidth,\n             Align.CENTER), Align.format(offset, offsetWidth, Align.CENTER),\n             Align.format(blkLen, blkLenWidth, Align.CENTER), Align.format(\n                 rawSize, rawSizeWidth, Align.CENTER), Align.format(records,\n                 recordsWidth, Align.CENTER), Align.format(endKey, endKeyWidth,\n                 Align.LEFT));\n \n         for (int i \u003d 0; i \u003c blockCnt; ++i) {\n           BlockRegion region \u003d\n               reader.readerBCF.dataIndex.getBlockRegionList().get(i);\n           TFileIndexEntry indexEntry \u003d reader.tfileIndex.getEntry(i);\n           out.printf(\"%s %s %s %s %s \", Align.format(Align.format(i,\n               blkIDWidth2, Align.ZERO_PADDED), blkIDWidth, Align.LEFT), Align\n               .format(region.getOffset(), offsetWidth, Align.LEFT), Align\n               .format(region.getCompressedSize(), blkLenWidth, Align.LEFT),\n               Align.format(region.getRawSize(), rawSizeWidth, Align.LEFT),\n               Align.format(indexEntry.kvEntries, recordsWidth, Align.LEFT));\n           byte[] key \u003d indexEntry.key;\n           boolean asAscii \u003d true;\n           int sampleLen \u003d Math.min(maxKeySampleLen, key.length);\n           for (int j \u003d 0; j \u003c sampleLen; ++j) {\n             byte b \u003d key[j];\n             if ((b \u003c 32 \u0026\u0026 b !\u003d 9) || (b \u003d\u003d 127)) {\n               asAscii \u003d false;\n             }\n           }\n           if (!asAscii) {\n             out.print(\"0X\");\n             for (int j \u003d 0; j \u003c sampleLen; ++j) {\n               byte b \u003d key[i];\n               out.printf(\"%X\", b);\n             }\n           } else {\n-            out.print(new String(key, 0, sampleLen, Charsets.UTF_8));\n+            out.print(new String(key, 0, sampleLen, StandardCharsets.UTF_8));\n           }\n           if (sampleLen \u003c key.length) {\n             out.print(\"...\");\n           }\n           out.println();\n         }\n       }\n \n       out.println();\n       if (metaBlkCnt \u003e 0) {\n         String name \u003d \"Meta-Block\";\n         int maxNameLen \u003d 0;\n         Set\u003cMap.Entry\u003cString, MetaIndexEntry\u003e\u003e metaBlkEntrySet \u003d\n             reader.readerBCF.metaIndex.index.entrySet();\n         for (Iterator\u003cMap.Entry\u003cString, MetaIndexEntry\u003e\u003e it \u003d\n             metaBlkEntrySet.iterator(); it.hasNext();) {\n           Map.Entry\u003cString, MetaIndexEntry\u003e e \u003d it.next();\n           if (e.getKey().length() \u003e maxNameLen) {\n             maxNameLen \u003d e.getKey().length();\n           }\n         }\n         int nameWidth \u003d Math.max(name.length(), maxNameLen);\n         String offset \u003d \"Offset\";\n         int offsetWidth \u003d Align.calculateWidth(offset, length);\n         String blkLen \u003d \"Length\";\n         int blkLenWidth \u003d\n             Align.calculateWidth(blkLen, metaSize / metaBlkCnt * 10);\n         String rawSize \u003d \"Raw-Size\";\n         int rawSizeWidth \u003d\n             Align.calculateWidth(rawSize, metaSizeUncompressed / metaBlkCnt\n                 * 10);\n         String compression \u003d \"Compression\";\n         int compressionWidth \u003d compression.length();\n         out.printf(\"%s %s %s %s %s%n\", Align.format(name, nameWidth,\n             Align.CENTER), Align.format(offset, offsetWidth, Align.CENTER),\n             Align.format(blkLen, blkLenWidth, Align.CENTER), Align.format(\n                 rawSize, rawSizeWidth, Align.CENTER), Align.format(compression,\n                 compressionWidth, Align.LEFT));\n \n         for (Iterator\u003cMap.Entry\u003cString, MetaIndexEntry\u003e\u003e it \u003d\n             metaBlkEntrySet.iterator(); it.hasNext();) {\n           Map.Entry\u003cString, MetaIndexEntry\u003e e \u003d it.next();\n           String blkName \u003d e.getValue().getMetaName();\n           BlockRegion region \u003d e.getValue().getRegion();\n           String blkCompression \u003d\n               e.getValue().getCompressionAlgorithm().getName();\n           out.printf(\"%s %s %s %s %s%n\", Align.format(blkName, nameWidth,\n               Align.LEFT), Align.format(region.getOffset(), offsetWidth,\n               Align.LEFT), Align.format(region.getCompressedSize(),\n               blkLenWidth, Align.LEFT), Align.format(region.getRawSize(),\n               rawSizeWidth, Align.LEFT), Align.format(blkCompression,\n               compressionWidth, Align.LEFT));\n         }\n       }\n     } finally {\n       IOUtils.cleanup(LOG, reader, fsdis);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static public void dumpInfo(String file, PrintStream out, Configuration conf)\n      throws IOException {\n    final int maxKeySampleLen \u003d 16;\n    Path path \u003d new Path(file);\n    FileSystem fs \u003d path.getFileSystem(conf);\n    long length \u003d fs.getFileStatus(path).getLen();\n    FSDataInputStream fsdis \u003d fs.open(path);\n    TFile.Reader reader \u003d new TFile.Reader(fsdis, length, conf);\n    try {\n      LinkedHashMap\u003cString, String\u003e properties \u003d\n          new LinkedHashMap\u003cString, String\u003e();\n      int blockCnt \u003d reader.readerBCF.getBlockCount();\n      int metaBlkCnt \u003d reader.readerBCF.metaIndex.index.size();\n      properties.put(\"BCFile Version\", reader.readerBCF.version.toString());\n      properties.put(\"TFile Version\", reader.tfileMeta.version.toString());\n      properties.put(\"File Length\", Long.toString(length));\n      properties.put(\"Data Compression\", reader.readerBCF\n          .getDefaultCompressionName());\n      properties.put(\"Record Count\", Long.toString(reader.getEntryCount()));\n      properties.put(\"Sorted\", Boolean.toString(reader.isSorted()));\n      if (reader.isSorted()) {\n        properties.put(\"Comparator\", reader.getComparatorName());\n      }\n      properties.put(\"Data Block Count\", Integer.toString(blockCnt));\n      long dataSize \u003d 0, dataSizeUncompressed \u003d 0;\n      if (blockCnt \u003e 0) {\n        for (int i \u003d 0; i \u003c blockCnt; ++i) {\n          BlockRegion region \u003d\n              reader.readerBCF.dataIndex.getBlockRegionList().get(i);\n          dataSize +\u003d region.getCompressedSize();\n          dataSizeUncompressed +\u003d region.getRawSize();\n        }\n        properties.put(\"Data Block Bytes\", Long.toString(dataSize));\n        if (!reader.readerBCF.getDefaultCompressionName().equals(\"none\")) {\n          properties.put(\"Data Block Uncompressed Bytes\", Long\n              .toString(dataSizeUncompressed));\n          properties.put(\"Data Block Compression Ratio\", String.format(\n              \"1:%.1f\", (double) dataSizeUncompressed / dataSize));\n        }\n      }\n\n      properties.put(\"Meta Block Count\", Integer.toString(metaBlkCnt));\n      long metaSize \u003d 0, metaSizeUncompressed \u003d 0;\n      if (metaBlkCnt \u003e 0) {\n        Collection\u003cMetaIndexEntry\u003e metaBlks \u003d\n            reader.readerBCF.metaIndex.index.values();\n        boolean calculateCompression \u003d false;\n        for (Iterator\u003cMetaIndexEntry\u003e it \u003d metaBlks.iterator(); it.hasNext();) {\n          MetaIndexEntry e \u003d it.next();\n          metaSize +\u003d e.getRegion().getCompressedSize();\n          metaSizeUncompressed +\u003d e.getRegion().getRawSize();\n          if (e.getCompressionAlgorithm() !\u003d Compression.Algorithm.NONE) {\n            calculateCompression \u003d true;\n          }\n        }\n        properties.put(\"Meta Block Bytes\", Long.toString(metaSize));\n        if (calculateCompression) {\n          properties.put(\"Meta Block Uncompressed Bytes\", Long\n              .toString(metaSizeUncompressed));\n          properties.put(\"Meta Block Compression Ratio\", String.format(\n              \"1:%.1f\", (double) metaSizeUncompressed / metaSize));\n        }\n      }\n      properties.put(\"Meta-Data Size Ratio\", String.format(\"1:%.1f\",\n          (double) dataSize / metaSize));\n      long leftOverBytes \u003d length - dataSize - metaSize;\n      long miscSize \u003d\n          BCFile.Magic.size() * 2 + Long.SIZE / Byte.SIZE + Version.size();\n      long metaIndexSize \u003d leftOverBytes - miscSize;\n      properties.put(\"Meta Block Index Bytes\", Long.toString(metaIndexSize));\n      properties.put(\"Headers Etc Bytes\", Long.toString(miscSize));\n      // Now output the properties table.\n      int maxKeyLength \u003d 0;\n      Set\u003cMap.Entry\u003cString, String\u003e\u003e entrySet \u003d properties.entrySet();\n      for (Iterator\u003cMap.Entry\u003cString, String\u003e\u003e it \u003d entrySet.iterator(); it\n          .hasNext();) {\n        Map.Entry\u003cString, String\u003e e \u003d it.next();\n        if (e.getKey().length() \u003e maxKeyLength) {\n          maxKeyLength \u003d e.getKey().length();\n        }\n      }\n      for (Iterator\u003cMap.Entry\u003cString, String\u003e\u003e it \u003d entrySet.iterator(); it\n          .hasNext();) {\n        Map.Entry\u003cString, String\u003e e \u003d it.next();\n        out.printf(\"%s : %s%n\", Align.format(e.getKey(), maxKeyLength,\n            Align.LEFT), e.getValue());\n      }\n      out.println();\n      reader.checkTFileDataIndex();\n      if (blockCnt \u003e 0) {\n        String blkID \u003d \"Data-Block\";\n        int blkIDWidth \u003d Align.calculateWidth(blkID, blockCnt);\n        int blkIDWidth2 \u003d Align.calculateWidth(\"\", blockCnt);\n        String offset \u003d \"Offset\";\n        int offsetWidth \u003d Align.calculateWidth(offset, length);\n        String blkLen \u003d \"Length\";\n        int blkLenWidth \u003d\n            Align.calculateWidth(blkLen, dataSize / blockCnt * 10);\n        String rawSize \u003d \"Raw-Size\";\n        int rawSizeWidth \u003d\n            Align.calculateWidth(rawSize, dataSizeUncompressed / blockCnt * 10);\n        String records \u003d \"Records\";\n        int recordsWidth \u003d\n            Align.calculateWidth(records, reader.getEntryCount() / blockCnt\n                * 10);\n        String endKey \u003d \"End-Key\";\n        int endKeyWidth \u003d Math.max(endKey.length(), maxKeySampleLen * 2 + 5);\n\n        out.printf(\"%s %s %s %s %s %s%n\", Align.format(blkID, blkIDWidth,\n            Align.CENTER), Align.format(offset, offsetWidth, Align.CENTER),\n            Align.format(blkLen, blkLenWidth, Align.CENTER), Align.format(\n                rawSize, rawSizeWidth, Align.CENTER), Align.format(records,\n                recordsWidth, Align.CENTER), Align.format(endKey, endKeyWidth,\n                Align.LEFT));\n\n        for (int i \u003d 0; i \u003c blockCnt; ++i) {\n          BlockRegion region \u003d\n              reader.readerBCF.dataIndex.getBlockRegionList().get(i);\n          TFileIndexEntry indexEntry \u003d reader.tfileIndex.getEntry(i);\n          out.printf(\"%s %s %s %s %s \", Align.format(Align.format(i,\n              blkIDWidth2, Align.ZERO_PADDED), blkIDWidth, Align.LEFT), Align\n              .format(region.getOffset(), offsetWidth, Align.LEFT), Align\n              .format(region.getCompressedSize(), blkLenWidth, Align.LEFT),\n              Align.format(region.getRawSize(), rawSizeWidth, Align.LEFT),\n              Align.format(indexEntry.kvEntries, recordsWidth, Align.LEFT));\n          byte[] key \u003d indexEntry.key;\n          boolean asAscii \u003d true;\n          int sampleLen \u003d Math.min(maxKeySampleLen, key.length);\n          for (int j \u003d 0; j \u003c sampleLen; ++j) {\n            byte b \u003d key[j];\n            if ((b \u003c 32 \u0026\u0026 b !\u003d 9) || (b \u003d\u003d 127)) {\n              asAscii \u003d false;\n            }\n          }\n          if (!asAscii) {\n            out.print(\"0X\");\n            for (int j \u003d 0; j \u003c sampleLen; ++j) {\n              byte b \u003d key[i];\n              out.printf(\"%X\", b);\n            }\n          } else {\n            out.print(new String(key, 0, sampleLen, StandardCharsets.UTF_8));\n          }\n          if (sampleLen \u003c key.length) {\n            out.print(\"...\");\n          }\n          out.println();\n        }\n      }\n\n      out.println();\n      if (metaBlkCnt \u003e 0) {\n        String name \u003d \"Meta-Block\";\n        int maxNameLen \u003d 0;\n        Set\u003cMap.Entry\u003cString, MetaIndexEntry\u003e\u003e metaBlkEntrySet \u003d\n            reader.readerBCF.metaIndex.index.entrySet();\n        for (Iterator\u003cMap.Entry\u003cString, MetaIndexEntry\u003e\u003e it \u003d\n            metaBlkEntrySet.iterator(); it.hasNext();) {\n          Map.Entry\u003cString, MetaIndexEntry\u003e e \u003d it.next();\n          if (e.getKey().length() \u003e maxNameLen) {\n            maxNameLen \u003d e.getKey().length();\n          }\n        }\n        int nameWidth \u003d Math.max(name.length(), maxNameLen);\n        String offset \u003d \"Offset\";\n        int offsetWidth \u003d Align.calculateWidth(offset, length);\n        String blkLen \u003d \"Length\";\n        int blkLenWidth \u003d\n            Align.calculateWidth(blkLen, metaSize / metaBlkCnt * 10);\n        String rawSize \u003d \"Raw-Size\";\n        int rawSizeWidth \u003d\n            Align.calculateWidth(rawSize, metaSizeUncompressed / metaBlkCnt\n                * 10);\n        String compression \u003d \"Compression\";\n        int compressionWidth \u003d compression.length();\n        out.printf(\"%s %s %s %s %s%n\", Align.format(name, nameWidth,\n            Align.CENTER), Align.format(offset, offsetWidth, Align.CENTER),\n            Align.format(blkLen, blkLenWidth, Align.CENTER), Align.format(\n                rawSize, rawSizeWidth, Align.CENTER), Align.format(compression,\n                compressionWidth, Align.LEFT));\n\n        for (Iterator\u003cMap.Entry\u003cString, MetaIndexEntry\u003e\u003e it \u003d\n            metaBlkEntrySet.iterator(); it.hasNext();) {\n          Map.Entry\u003cString, MetaIndexEntry\u003e e \u003d it.next();\n          String blkName \u003d e.getValue().getMetaName();\n          BlockRegion region \u003d e.getValue().getRegion();\n          String blkCompression \u003d\n              e.getValue().getCompressionAlgorithm().getName();\n          out.printf(\"%s %s %s %s %s%n\", Align.format(blkName, nameWidth,\n              Align.LEFT), Align.format(region.getOffset(), offsetWidth,\n              Align.LEFT), Align.format(region.getCompressedSize(),\n              blkLenWidth, Align.LEFT), Align.format(region.getRawSize(),\n              rawSizeWidth, Align.LEFT), Align.format(blkCompression,\n              compressionWidth, Align.LEFT));\n        }\n      }\n    } finally {\n      IOUtils.cleanup(LOG, reader, fsdis);\n    }\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/file/tfile/TFileDumper.java",
      "extendedDetails": {}
    },
    "5b9fcedb4d116d91d70aaad6cbf59093eeee36df": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-11389. Clean up byte to string encoding issues in hadoop-common. Contributed by Haohui Mai.\n",
      "commitDate": "11/12/14 4:42 PM",
      "commitName": "5b9fcedb4d116d91d70aaad6cbf59093eeee36df",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "10/12/14 2:37 PM",
      "commitNameOld": "84d50003f6e46f9f9ac2b9d7bb937de757be161b",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 1.09,
      "commitsBetweenForRepo": 11,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,200 +1,200 @@\n   static public void dumpInfo(String file, PrintStream out, Configuration conf)\n       throws IOException {\n     final int maxKeySampleLen \u003d 16;\n     Path path \u003d new Path(file);\n     FileSystem fs \u003d path.getFileSystem(conf);\n     long length \u003d fs.getFileStatus(path).getLen();\n     FSDataInputStream fsdis \u003d fs.open(path);\n     TFile.Reader reader \u003d new TFile.Reader(fsdis, length, conf);\n     try {\n       LinkedHashMap\u003cString, String\u003e properties \u003d\n           new LinkedHashMap\u003cString, String\u003e();\n       int blockCnt \u003d reader.readerBCF.getBlockCount();\n       int metaBlkCnt \u003d reader.readerBCF.metaIndex.index.size();\n       properties.put(\"BCFile Version\", reader.readerBCF.version.toString());\n       properties.put(\"TFile Version\", reader.tfileMeta.version.toString());\n       properties.put(\"File Length\", Long.toString(length));\n       properties.put(\"Data Compression\", reader.readerBCF\n           .getDefaultCompressionName());\n       properties.put(\"Record Count\", Long.toString(reader.getEntryCount()));\n       properties.put(\"Sorted\", Boolean.toString(reader.isSorted()));\n       if (reader.isSorted()) {\n         properties.put(\"Comparator\", reader.getComparatorName());\n       }\n       properties.put(\"Data Block Count\", Integer.toString(blockCnt));\n       long dataSize \u003d 0, dataSizeUncompressed \u003d 0;\n       if (blockCnt \u003e 0) {\n         for (int i \u003d 0; i \u003c blockCnt; ++i) {\n           BlockRegion region \u003d\n               reader.readerBCF.dataIndex.getBlockRegionList().get(i);\n           dataSize +\u003d region.getCompressedSize();\n           dataSizeUncompressed +\u003d region.getRawSize();\n         }\n         properties.put(\"Data Block Bytes\", Long.toString(dataSize));\n         if (!reader.readerBCF.getDefaultCompressionName().equals(\"none\")) {\n           properties.put(\"Data Block Uncompressed Bytes\", Long\n               .toString(dataSizeUncompressed));\n           properties.put(\"Data Block Compression Ratio\", String.format(\n               \"1:%.1f\", (double) dataSizeUncompressed / dataSize));\n         }\n       }\n \n       properties.put(\"Meta Block Count\", Integer.toString(metaBlkCnt));\n       long metaSize \u003d 0, metaSizeUncompressed \u003d 0;\n       if (metaBlkCnt \u003e 0) {\n         Collection\u003cMetaIndexEntry\u003e metaBlks \u003d\n             reader.readerBCF.metaIndex.index.values();\n         boolean calculateCompression \u003d false;\n         for (Iterator\u003cMetaIndexEntry\u003e it \u003d metaBlks.iterator(); it.hasNext();) {\n           MetaIndexEntry e \u003d it.next();\n           metaSize +\u003d e.getRegion().getCompressedSize();\n           metaSizeUncompressed +\u003d e.getRegion().getRawSize();\n           if (e.getCompressionAlgorithm() !\u003d Compression.Algorithm.NONE) {\n             calculateCompression \u003d true;\n           }\n         }\n         properties.put(\"Meta Block Bytes\", Long.toString(metaSize));\n         if (calculateCompression) {\n           properties.put(\"Meta Block Uncompressed Bytes\", Long\n               .toString(metaSizeUncompressed));\n           properties.put(\"Meta Block Compression Ratio\", String.format(\n               \"1:%.1f\", (double) metaSizeUncompressed / metaSize));\n         }\n       }\n       properties.put(\"Meta-Data Size Ratio\", String.format(\"1:%.1f\",\n           (double) dataSize / metaSize));\n       long leftOverBytes \u003d length - dataSize - metaSize;\n       long miscSize \u003d\n           BCFile.Magic.size() * 2 + Long.SIZE / Byte.SIZE + Version.size();\n       long metaIndexSize \u003d leftOverBytes - miscSize;\n       properties.put(\"Meta Block Index Bytes\", Long.toString(metaIndexSize));\n       properties.put(\"Headers Etc Bytes\", Long.toString(miscSize));\n       // Now output the properties table.\n       int maxKeyLength \u003d 0;\n       Set\u003cMap.Entry\u003cString, String\u003e\u003e entrySet \u003d properties.entrySet();\n       for (Iterator\u003cMap.Entry\u003cString, String\u003e\u003e it \u003d entrySet.iterator(); it\n           .hasNext();) {\n         Map.Entry\u003cString, String\u003e e \u003d it.next();\n         if (e.getKey().length() \u003e maxKeyLength) {\n           maxKeyLength \u003d e.getKey().length();\n         }\n       }\n       for (Iterator\u003cMap.Entry\u003cString, String\u003e\u003e it \u003d entrySet.iterator(); it\n           .hasNext();) {\n         Map.Entry\u003cString, String\u003e e \u003d it.next();\n         out.printf(\"%s : %s%n\", Align.format(e.getKey(), maxKeyLength,\n             Align.LEFT), e.getValue());\n       }\n       out.println();\n       reader.checkTFileDataIndex();\n       if (blockCnt \u003e 0) {\n         String blkID \u003d \"Data-Block\";\n         int blkIDWidth \u003d Align.calculateWidth(blkID, blockCnt);\n         int blkIDWidth2 \u003d Align.calculateWidth(\"\", blockCnt);\n         String offset \u003d \"Offset\";\n         int offsetWidth \u003d Align.calculateWidth(offset, length);\n         String blkLen \u003d \"Length\";\n         int blkLenWidth \u003d\n             Align.calculateWidth(blkLen, dataSize / blockCnt * 10);\n         String rawSize \u003d \"Raw-Size\";\n         int rawSizeWidth \u003d\n             Align.calculateWidth(rawSize, dataSizeUncompressed / blockCnt * 10);\n         String records \u003d \"Records\";\n         int recordsWidth \u003d\n             Align.calculateWidth(records, reader.getEntryCount() / blockCnt\n                 * 10);\n         String endKey \u003d \"End-Key\";\n         int endKeyWidth \u003d Math.max(endKey.length(), maxKeySampleLen * 2 + 5);\n \n         out.printf(\"%s %s %s %s %s %s%n\", Align.format(blkID, blkIDWidth,\n             Align.CENTER), Align.format(offset, offsetWidth, Align.CENTER),\n             Align.format(blkLen, blkLenWidth, Align.CENTER), Align.format(\n                 rawSize, rawSizeWidth, Align.CENTER), Align.format(records,\n                 recordsWidth, Align.CENTER), Align.format(endKey, endKeyWidth,\n                 Align.LEFT));\n \n         for (int i \u003d 0; i \u003c blockCnt; ++i) {\n           BlockRegion region \u003d\n               reader.readerBCF.dataIndex.getBlockRegionList().get(i);\n           TFileIndexEntry indexEntry \u003d reader.tfileIndex.getEntry(i);\n           out.printf(\"%s %s %s %s %s \", Align.format(Align.format(i,\n               blkIDWidth2, Align.ZERO_PADDED), blkIDWidth, Align.LEFT), Align\n               .format(region.getOffset(), offsetWidth, Align.LEFT), Align\n               .format(region.getCompressedSize(), blkLenWidth, Align.LEFT),\n               Align.format(region.getRawSize(), rawSizeWidth, Align.LEFT),\n               Align.format(indexEntry.kvEntries, recordsWidth, Align.LEFT));\n           byte[] key \u003d indexEntry.key;\n           boolean asAscii \u003d true;\n           int sampleLen \u003d Math.min(maxKeySampleLen, key.length);\n           for (int j \u003d 0; j \u003c sampleLen; ++j) {\n             byte b \u003d key[j];\n             if ((b \u003c 32 \u0026\u0026 b !\u003d 9) || (b \u003d\u003d 127)) {\n               asAscii \u003d false;\n             }\n           }\n           if (!asAscii) {\n             out.print(\"0X\");\n             for (int j \u003d 0; j \u003c sampleLen; ++j) {\n               byte b \u003d key[i];\n               out.printf(\"%X\", b);\n             }\n           } else {\n-            out.print(new String(key, 0, sampleLen));\n+            out.print(new String(key, 0, sampleLen, Charsets.UTF_8));\n           }\n           if (sampleLen \u003c key.length) {\n             out.print(\"...\");\n           }\n           out.println();\n         }\n       }\n \n       out.println();\n       if (metaBlkCnt \u003e 0) {\n         String name \u003d \"Meta-Block\";\n         int maxNameLen \u003d 0;\n         Set\u003cMap.Entry\u003cString, MetaIndexEntry\u003e\u003e metaBlkEntrySet \u003d\n             reader.readerBCF.metaIndex.index.entrySet();\n         for (Iterator\u003cMap.Entry\u003cString, MetaIndexEntry\u003e\u003e it \u003d\n             metaBlkEntrySet.iterator(); it.hasNext();) {\n           Map.Entry\u003cString, MetaIndexEntry\u003e e \u003d it.next();\n           if (e.getKey().length() \u003e maxNameLen) {\n             maxNameLen \u003d e.getKey().length();\n           }\n         }\n         int nameWidth \u003d Math.max(name.length(), maxNameLen);\n         String offset \u003d \"Offset\";\n         int offsetWidth \u003d Align.calculateWidth(offset, length);\n         String blkLen \u003d \"Length\";\n         int blkLenWidth \u003d\n             Align.calculateWidth(blkLen, metaSize / metaBlkCnt * 10);\n         String rawSize \u003d \"Raw-Size\";\n         int rawSizeWidth \u003d\n             Align.calculateWidth(rawSize, metaSizeUncompressed / metaBlkCnt\n                 * 10);\n         String compression \u003d \"Compression\";\n         int compressionWidth \u003d compression.length();\n         out.printf(\"%s %s %s %s %s%n\", Align.format(name, nameWidth,\n             Align.CENTER), Align.format(offset, offsetWidth, Align.CENTER),\n             Align.format(blkLen, blkLenWidth, Align.CENTER), Align.format(\n                 rawSize, rawSizeWidth, Align.CENTER), Align.format(compression,\n                 compressionWidth, Align.LEFT));\n \n         for (Iterator\u003cMap.Entry\u003cString, MetaIndexEntry\u003e\u003e it \u003d\n             metaBlkEntrySet.iterator(); it.hasNext();) {\n           Map.Entry\u003cString, MetaIndexEntry\u003e e \u003d it.next();\n           String blkName \u003d e.getValue().getMetaName();\n           BlockRegion region \u003d e.getValue().getRegion();\n           String blkCompression \u003d\n               e.getValue().getCompressionAlgorithm().getName();\n           out.printf(\"%s %s %s %s %s%n\", Align.format(blkName, nameWidth,\n               Align.LEFT), Align.format(region.getOffset(), offsetWidth,\n               Align.LEFT), Align.format(region.getCompressedSize(),\n               blkLenWidth, Align.LEFT), Align.format(region.getRawSize(),\n               rawSizeWidth, Align.LEFT), Align.format(blkCompression,\n               compressionWidth, Align.LEFT));\n         }\n       }\n     } finally {\n       IOUtils.cleanup(LOG, reader, fsdis);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static public void dumpInfo(String file, PrintStream out, Configuration conf)\n      throws IOException {\n    final int maxKeySampleLen \u003d 16;\n    Path path \u003d new Path(file);\n    FileSystem fs \u003d path.getFileSystem(conf);\n    long length \u003d fs.getFileStatus(path).getLen();\n    FSDataInputStream fsdis \u003d fs.open(path);\n    TFile.Reader reader \u003d new TFile.Reader(fsdis, length, conf);\n    try {\n      LinkedHashMap\u003cString, String\u003e properties \u003d\n          new LinkedHashMap\u003cString, String\u003e();\n      int blockCnt \u003d reader.readerBCF.getBlockCount();\n      int metaBlkCnt \u003d reader.readerBCF.metaIndex.index.size();\n      properties.put(\"BCFile Version\", reader.readerBCF.version.toString());\n      properties.put(\"TFile Version\", reader.tfileMeta.version.toString());\n      properties.put(\"File Length\", Long.toString(length));\n      properties.put(\"Data Compression\", reader.readerBCF\n          .getDefaultCompressionName());\n      properties.put(\"Record Count\", Long.toString(reader.getEntryCount()));\n      properties.put(\"Sorted\", Boolean.toString(reader.isSorted()));\n      if (reader.isSorted()) {\n        properties.put(\"Comparator\", reader.getComparatorName());\n      }\n      properties.put(\"Data Block Count\", Integer.toString(blockCnt));\n      long dataSize \u003d 0, dataSizeUncompressed \u003d 0;\n      if (blockCnt \u003e 0) {\n        for (int i \u003d 0; i \u003c blockCnt; ++i) {\n          BlockRegion region \u003d\n              reader.readerBCF.dataIndex.getBlockRegionList().get(i);\n          dataSize +\u003d region.getCompressedSize();\n          dataSizeUncompressed +\u003d region.getRawSize();\n        }\n        properties.put(\"Data Block Bytes\", Long.toString(dataSize));\n        if (!reader.readerBCF.getDefaultCompressionName().equals(\"none\")) {\n          properties.put(\"Data Block Uncompressed Bytes\", Long\n              .toString(dataSizeUncompressed));\n          properties.put(\"Data Block Compression Ratio\", String.format(\n              \"1:%.1f\", (double) dataSizeUncompressed / dataSize));\n        }\n      }\n\n      properties.put(\"Meta Block Count\", Integer.toString(metaBlkCnt));\n      long metaSize \u003d 0, metaSizeUncompressed \u003d 0;\n      if (metaBlkCnt \u003e 0) {\n        Collection\u003cMetaIndexEntry\u003e metaBlks \u003d\n            reader.readerBCF.metaIndex.index.values();\n        boolean calculateCompression \u003d false;\n        for (Iterator\u003cMetaIndexEntry\u003e it \u003d metaBlks.iterator(); it.hasNext();) {\n          MetaIndexEntry e \u003d it.next();\n          metaSize +\u003d e.getRegion().getCompressedSize();\n          metaSizeUncompressed +\u003d e.getRegion().getRawSize();\n          if (e.getCompressionAlgorithm() !\u003d Compression.Algorithm.NONE) {\n            calculateCompression \u003d true;\n          }\n        }\n        properties.put(\"Meta Block Bytes\", Long.toString(metaSize));\n        if (calculateCompression) {\n          properties.put(\"Meta Block Uncompressed Bytes\", Long\n              .toString(metaSizeUncompressed));\n          properties.put(\"Meta Block Compression Ratio\", String.format(\n              \"1:%.1f\", (double) metaSizeUncompressed / metaSize));\n        }\n      }\n      properties.put(\"Meta-Data Size Ratio\", String.format(\"1:%.1f\",\n          (double) dataSize / metaSize));\n      long leftOverBytes \u003d length - dataSize - metaSize;\n      long miscSize \u003d\n          BCFile.Magic.size() * 2 + Long.SIZE / Byte.SIZE + Version.size();\n      long metaIndexSize \u003d leftOverBytes - miscSize;\n      properties.put(\"Meta Block Index Bytes\", Long.toString(metaIndexSize));\n      properties.put(\"Headers Etc Bytes\", Long.toString(miscSize));\n      // Now output the properties table.\n      int maxKeyLength \u003d 0;\n      Set\u003cMap.Entry\u003cString, String\u003e\u003e entrySet \u003d properties.entrySet();\n      for (Iterator\u003cMap.Entry\u003cString, String\u003e\u003e it \u003d entrySet.iterator(); it\n          .hasNext();) {\n        Map.Entry\u003cString, String\u003e e \u003d it.next();\n        if (e.getKey().length() \u003e maxKeyLength) {\n          maxKeyLength \u003d e.getKey().length();\n        }\n      }\n      for (Iterator\u003cMap.Entry\u003cString, String\u003e\u003e it \u003d entrySet.iterator(); it\n          .hasNext();) {\n        Map.Entry\u003cString, String\u003e e \u003d it.next();\n        out.printf(\"%s : %s%n\", Align.format(e.getKey(), maxKeyLength,\n            Align.LEFT), e.getValue());\n      }\n      out.println();\n      reader.checkTFileDataIndex();\n      if (blockCnt \u003e 0) {\n        String blkID \u003d \"Data-Block\";\n        int blkIDWidth \u003d Align.calculateWidth(blkID, blockCnt);\n        int blkIDWidth2 \u003d Align.calculateWidth(\"\", blockCnt);\n        String offset \u003d \"Offset\";\n        int offsetWidth \u003d Align.calculateWidth(offset, length);\n        String blkLen \u003d \"Length\";\n        int blkLenWidth \u003d\n            Align.calculateWidth(blkLen, dataSize / blockCnt * 10);\n        String rawSize \u003d \"Raw-Size\";\n        int rawSizeWidth \u003d\n            Align.calculateWidth(rawSize, dataSizeUncompressed / blockCnt * 10);\n        String records \u003d \"Records\";\n        int recordsWidth \u003d\n            Align.calculateWidth(records, reader.getEntryCount() / blockCnt\n                * 10);\n        String endKey \u003d \"End-Key\";\n        int endKeyWidth \u003d Math.max(endKey.length(), maxKeySampleLen * 2 + 5);\n\n        out.printf(\"%s %s %s %s %s %s%n\", Align.format(blkID, blkIDWidth,\n            Align.CENTER), Align.format(offset, offsetWidth, Align.CENTER),\n            Align.format(blkLen, blkLenWidth, Align.CENTER), Align.format(\n                rawSize, rawSizeWidth, Align.CENTER), Align.format(records,\n                recordsWidth, Align.CENTER), Align.format(endKey, endKeyWidth,\n                Align.LEFT));\n\n        for (int i \u003d 0; i \u003c blockCnt; ++i) {\n          BlockRegion region \u003d\n              reader.readerBCF.dataIndex.getBlockRegionList().get(i);\n          TFileIndexEntry indexEntry \u003d reader.tfileIndex.getEntry(i);\n          out.printf(\"%s %s %s %s %s \", Align.format(Align.format(i,\n              blkIDWidth2, Align.ZERO_PADDED), blkIDWidth, Align.LEFT), Align\n              .format(region.getOffset(), offsetWidth, Align.LEFT), Align\n              .format(region.getCompressedSize(), blkLenWidth, Align.LEFT),\n              Align.format(region.getRawSize(), rawSizeWidth, Align.LEFT),\n              Align.format(indexEntry.kvEntries, recordsWidth, Align.LEFT));\n          byte[] key \u003d indexEntry.key;\n          boolean asAscii \u003d true;\n          int sampleLen \u003d Math.min(maxKeySampleLen, key.length);\n          for (int j \u003d 0; j \u003c sampleLen; ++j) {\n            byte b \u003d key[j];\n            if ((b \u003c 32 \u0026\u0026 b !\u003d 9) || (b \u003d\u003d 127)) {\n              asAscii \u003d false;\n            }\n          }\n          if (!asAscii) {\n            out.print(\"0X\");\n            for (int j \u003d 0; j \u003c sampleLen; ++j) {\n              byte b \u003d key[i];\n              out.printf(\"%X\", b);\n            }\n          } else {\n            out.print(new String(key, 0, sampleLen, Charsets.UTF_8));\n          }\n          if (sampleLen \u003c key.length) {\n            out.print(\"...\");\n          }\n          out.println();\n        }\n      }\n\n      out.println();\n      if (metaBlkCnt \u003e 0) {\n        String name \u003d \"Meta-Block\";\n        int maxNameLen \u003d 0;\n        Set\u003cMap.Entry\u003cString, MetaIndexEntry\u003e\u003e metaBlkEntrySet \u003d\n            reader.readerBCF.metaIndex.index.entrySet();\n        for (Iterator\u003cMap.Entry\u003cString, MetaIndexEntry\u003e\u003e it \u003d\n            metaBlkEntrySet.iterator(); it.hasNext();) {\n          Map.Entry\u003cString, MetaIndexEntry\u003e e \u003d it.next();\n          if (e.getKey().length() \u003e maxNameLen) {\n            maxNameLen \u003d e.getKey().length();\n          }\n        }\n        int nameWidth \u003d Math.max(name.length(), maxNameLen);\n        String offset \u003d \"Offset\";\n        int offsetWidth \u003d Align.calculateWidth(offset, length);\n        String blkLen \u003d \"Length\";\n        int blkLenWidth \u003d\n            Align.calculateWidth(blkLen, metaSize / metaBlkCnt * 10);\n        String rawSize \u003d \"Raw-Size\";\n        int rawSizeWidth \u003d\n            Align.calculateWidth(rawSize, metaSizeUncompressed / metaBlkCnt\n                * 10);\n        String compression \u003d \"Compression\";\n        int compressionWidth \u003d compression.length();\n        out.printf(\"%s %s %s %s %s%n\", Align.format(name, nameWidth,\n            Align.CENTER), Align.format(offset, offsetWidth, Align.CENTER),\n            Align.format(blkLen, blkLenWidth, Align.CENTER), Align.format(\n                rawSize, rawSizeWidth, Align.CENTER), Align.format(compression,\n                compressionWidth, Align.LEFT));\n\n        for (Iterator\u003cMap.Entry\u003cString, MetaIndexEntry\u003e\u003e it \u003d\n            metaBlkEntrySet.iterator(); it.hasNext();) {\n          Map.Entry\u003cString, MetaIndexEntry\u003e e \u003d it.next();\n          String blkName \u003d e.getValue().getMetaName();\n          BlockRegion region \u003d e.getValue().getRegion();\n          String blkCompression \u003d\n              e.getValue().getCompressionAlgorithm().getName();\n          out.printf(\"%s %s %s %s %s%n\", Align.format(blkName, nameWidth,\n              Align.LEFT), Align.format(region.getOffset(), offsetWidth,\n              Align.LEFT), Align.format(region.getCompressedSize(),\n              blkLenWidth, Align.LEFT), Align.format(region.getRawSize(),\n              rawSizeWidth, Align.LEFT), Align.format(blkCompression,\n              compressionWidth, Align.LEFT));\n        }\n      }\n    } finally {\n      IOUtils.cleanup(LOG, reader, fsdis);\n    }\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/file/tfile/TFileDumper.java",
      "extendedDetails": {}
    },
    "84d50003f6e46f9f9ac2b9d7bb937de757be161b": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-11386. Replace \\n by %n in format hadoop-common format strings. Contributed by Li Lu.\n",
      "commitDate": "10/12/14 2:37 PM",
      "commitName": "84d50003f6e46f9f9ac2b9d7bb937de757be161b",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "16/09/12 2:10 PM",
      "commitNameOld": "0c53ed4cd122f87b2b041d670b9b59e27da5439c",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 815.06,
      "commitsBetweenForRepo": 5560,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,200 +1,200 @@\n   static public void dumpInfo(String file, PrintStream out, Configuration conf)\n       throws IOException {\n     final int maxKeySampleLen \u003d 16;\n     Path path \u003d new Path(file);\n     FileSystem fs \u003d path.getFileSystem(conf);\n     long length \u003d fs.getFileStatus(path).getLen();\n     FSDataInputStream fsdis \u003d fs.open(path);\n     TFile.Reader reader \u003d new TFile.Reader(fsdis, length, conf);\n     try {\n       LinkedHashMap\u003cString, String\u003e properties \u003d\n           new LinkedHashMap\u003cString, String\u003e();\n       int blockCnt \u003d reader.readerBCF.getBlockCount();\n       int metaBlkCnt \u003d reader.readerBCF.metaIndex.index.size();\n       properties.put(\"BCFile Version\", reader.readerBCF.version.toString());\n       properties.put(\"TFile Version\", reader.tfileMeta.version.toString());\n       properties.put(\"File Length\", Long.toString(length));\n       properties.put(\"Data Compression\", reader.readerBCF\n           .getDefaultCompressionName());\n       properties.put(\"Record Count\", Long.toString(reader.getEntryCount()));\n       properties.put(\"Sorted\", Boolean.toString(reader.isSorted()));\n       if (reader.isSorted()) {\n         properties.put(\"Comparator\", reader.getComparatorName());\n       }\n       properties.put(\"Data Block Count\", Integer.toString(blockCnt));\n       long dataSize \u003d 0, dataSizeUncompressed \u003d 0;\n       if (blockCnt \u003e 0) {\n         for (int i \u003d 0; i \u003c blockCnt; ++i) {\n           BlockRegion region \u003d\n               reader.readerBCF.dataIndex.getBlockRegionList().get(i);\n           dataSize +\u003d region.getCompressedSize();\n           dataSizeUncompressed +\u003d region.getRawSize();\n         }\n         properties.put(\"Data Block Bytes\", Long.toString(dataSize));\n         if (!reader.readerBCF.getDefaultCompressionName().equals(\"none\")) {\n           properties.put(\"Data Block Uncompressed Bytes\", Long\n               .toString(dataSizeUncompressed));\n           properties.put(\"Data Block Compression Ratio\", String.format(\n               \"1:%.1f\", (double) dataSizeUncompressed / dataSize));\n         }\n       }\n \n       properties.put(\"Meta Block Count\", Integer.toString(metaBlkCnt));\n       long metaSize \u003d 0, metaSizeUncompressed \u003d 0;\n       if (metaBlkCnt \u003e 0) {\n         Collection\u003cMetaIndexEntry\u003e metaBlks \u003d\n             reader.readerBCF.metaIndex.index.values();\n         boolean calculateCompression \u003d false;\n         for (Iterator\u003cMetaIndexEntry\u003e it \u003d metaBlks.iterator(); it.hasNext();) {\n           MetaIndexEntry e \u003d it.next();\n           metaSize +\u003d e.getRegion().getCompressedSize();\n           metaSizeUncompressed +\u003d e.getRegion().getRawSize();\n           if (e.getCompressionAlgorithm() !\u003d Compression.Algorithm.NONE) {\n             calculateCompression \u003d true;\n           }\n         }\n         properties.put(\"Meta Block Bytes\", Long.toString(metaSize));\n         if (calculateCompression) {\n           properties.put(\"Meta Block Uncompressed Bytes\", Long\n               .toString(metaSizeUncompressed));\n           properties.put(\"Meta Block Compression Ratio\", String.format(\n               \"1:%.1f\", (double) metaSizeUncompressed / metaSize));\n         }\n       }\n       properties.put(\"Meta-Data Size Ratio\", String.format(\"1:%.1f\",\n           (double) dataSize / metaSize));\n       long leftOverBytes \u003d length - dataSize - metaSize;\n       long miscSize \u003d\n           BCFile.Magic.size() * 2 + Long.SIZE / Byte.SIZE + Version.size();\n       long metaIndexSize \u003d leftOverBytes - miscSize;\n       properties.put(\"Meta Block Index Bytes\", Long.toString(metaIndexSize));\n       properties.put(\"Headers Etc Bytes\", Long.toString(miscSize));\n       // Now output the properties table.\n       int maxKeyLength \u003d 0;\n       Set\u003cMap.Entry\u003cString, String\u003e\u003e entrySet \u003d properties.entrySet();\n       for (Iterator\u003cMap.Entry\u003cString, String\u003e\u003e it \u003d entrySet.iterator(); it\n           .hasNext();) {\n         Map.Entry\u003cString, String\u003e e \u003d it.next();\n         if (e.getKey().length() \u003e maxKeyLength) {\n           maxKeyLength \u003d e.getKey().length();\n         }\n       }\n       for (Iterator\u003cMap.Entry\u003cString, String\u003e\u003e it \u003d entrySet.iterator(); it\n           .hasNext();) {\n         Map.Entry\u003cString, String\u003e e \u003d it.next();\n-        out.printf(\"%s : %s\\n\", Align.format(e.getKey(), maxKeyLength,\n+        out.printf(\"%s : %s%n\", Align.format(e.getKey(), maxKeyLength,\n             Align.LEFT), e.getValue());\n       }\n       out.println();\n       reader.checkTFileDataIndex();\n       if (blockCnt \u003e 0) {\n         String blkID \u003d \"Data-Block\";\n         int blkIDWidth \u003d Align.calculateWidth(blkID, blockCnt);\n         int blkIDWidth2 \u003d Align.calculateWidth(\"\", blockCnt);\n         String offset \u003d \"Offset\";\n         int offsetWidth \u003d Align.calculateWidth(offset, length);\n         String blkLen \u003d \"Length\";\n         int blkLenWidth \u003d\n             Align.calculateWidth(blkLen, dataSize / blockCnt * 10);\n         String rawSize \u003d \"Raw-Size\";\n         int rawSizeWidth \u003d\n             Align.calculateWidth(rawSize, dataSizeUncompressed / blockCnt * 10);\n         String records \u003d \"Records\";\n         int recordsWidth \u003d\n             Align.calculateWidth(records, reader.getEntryCount() / blockCnt\n                 * 10);\n         String endKey \u003d \"End-Key\";\n         int endKeyWidth \u003d Math.max(endKey.length(), maxKeySampleLen * 2 + 5);\n \n-        out.printf(\"%s %s %s %s %s %s\\n\", Align.format(blkID, blkIDWidth,\n+        out.printf(\"%s %s %s %s %s %s%n\", Align.format(blkID, blkIDWidth,\n             Align.CENTER), Align.format(offset, offsetWidth, Align.CENTER),\n             Align.format(blkLen, blkLenWidth, Align.CENTER), Align.format(\n                 rawSize, rawSizeWidth, Align.CENTER), Align.format(records,\n                 recordsWidth, Align.CENTER), Align.format(endKey, endKeyWidth,\n                 Align.LEFT));\n \n         for (int i \u003d 0; i \u003c blockCnt; ++i) {\n           BlockRegion region \u003d\n               reader.readerBCF.dataIndex.getBlockRegionList().get(i);\n           TFileIndexEntry indexEntry \u003d reader.tfileIndex.getEntry(i);\n           out.printf(\"%s %s %s %s %s \", Align.format(Align.format(i,\n               blkIDWidth2, Align.ZERO_PADDED), blkIDWidth, Align.LEFT), Align\n               .format(region.getOffset(), offsetWidth, Align.LEFT), Align\n               .format(region.getCompressedSize(), blkLenWidth, Align.LEFT),\n               Align.format(region.getRawSize(), rawSizeWidth, Align.LEFT),\n               Align.format(indexEntry.kvEntries, recordsWidth, Align.LEFT));\n           byte[] key \u003d indexEntry.key;\n           boolean asAscii \u003d true;\n           int sampleLen \u003d Math.min(maxKeySampleLen, key.length);\n           for (int j \u003d 0; j \u003c sampleLen; ++j) {\n             byte b \u003d key[j];\n             if ((b \u003c 32 \u0026\u0026 b !\u003d 9) || (b \u003d\u003d 127)) {\n               asAscii \u003d false;\n             }\n           }\n           if (!asAscii) {\n             out.print(\"0X\");\n             for (int j \u003d 0; j \u003c sampleLen; ++j) {\n               byte b \u003d key[i];\n               out.printf(\"%X\", b);\n             }\n           } else {\n             out.print(new String(key, 0, sampleLen));\n           }\n           if (sampleLen \u003c key.length) {\n             out.print(\"...\");\n           }\n           out.println();\n         }\n       }\n \n       out.println();\n       if (metaBlkCnt \u003e 0) {\n         String name \u003d \"Meta-Block\";\n         int maxNameLen \u003d 0;\n         Set\u003cMap.Entry\u003cString, MetaIndexEntry\u003e\u003e metaBlkEntrySet \u003d\n             reader.readerBCF.metaIndex.index.entrySet();\n         for (Iterator\u003cMap.Entry\u003cString, MetaIndexEntry\u003e\u003e it \u003d\n             metaBlkEntrySet.iterator(); it.hasNext();) {\n           Map.Entry\u003cString, MetaIndexEntry\u003e e \u003d it.next();\n           if (e.getKey().length() \u003e maxNameLen) {\n             maxNameLen \u003d e.getKey().length();\n           }\n         }\n         int nameWidth \u003d Math.max(name.length(), maxNameLen);\n         String offset \u003d \"Offset\";\n         int offsetWidth \u003d Align.calculateWidth(offset, length);\n         String blkLen \u003d \"Length\";\n         int blkLenWidth \u003d\n             Align.calculateWidth(blkLen, metaSize / metaBlkCnt * 10);\n         String rawSize \u003d \"Raw-Size\";\n         int rawSizeWidth \u003d\n             Align.calculateWidth(rawSize, metaSizeUncompressed / metaBlkCnt\n                 * 10);\n         String compression \u003d \"Compression\";\n         int compressionWidth \u003d compression.length();\n-        out.printf(\"%s %s %s %s %s\\n\", Align.format(name, nameWidth,\n+        out.printf(\"%s %s %s %s %s%n\", Align.format(name, nameWidth,\n             Align.CENTER), Align.format(offset, offsetWidth, Align.CENTER),\n             Align.format(blkLen, blkLenWidth, Align.CENTER), Align.format(\n                 rawSize, rawSizeWidth, Align.CENTER), Align.format(compression,\n                 compressionWidth, Align.LEFT));\n \n         for (Iterator\u003cMap.Entry\u003cString, MetaIndexEntry\u003e\u003e it \u003d\n             metaBlkEntrySet.iterator(); it.hasNext();) {\n           Map.Entry\u003cString, MetaIndexEntry\u003e e \u003d it.next();\n           String blkName \u003d e.getValue().getMetaName();\n           BlockRegion region \u003d e.getValue().getRegion();\n           String blkCompression \u003d\n               e.getValue().getCompressionAlgorithm().getName();\n-          out.printf(\"%s %s %s %s %s\\n\", Align.format(blkName, nameWidth,\n+          out.printf(\"%s %s %s %s %s%n\", Align.format(blkName, nameWidth,\n               Align.LEFT), Align.format(region.getOffset(), offsetWidth,\n               Align.LEFT), Align.format(region.getCompressedSize(),\n               blkLenWidth, Align.LEFT), Align.format(region.getRawSize(),\n               rawSizeWidth, Align.LEFT), Align.format(blkCompression,\n               compressionWidth, Align.LEFT));\n         }\n       }\n     } finally {\n       IOUtils.cleanup(LOG, reader, fsdis);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static public void dumpInfo(String file, PrintStream out, Configuration conf)\n      throws IOException {\n    final int maxKeySampleLen \u003d 16;\n    Path path \u003d new Path(file);\n    FileSystem fs \u003d path.getFileSystem(conf);\n    long length \u003d fs.getFileStatus(path).getLen();\n    FSDataInputStream fsdis \u003d fs.open(path);\n    TFile.Reader reader \u003d new TFile.Reader(fsdis, length, conf);\n    try {\n      LinkedHashMap\u003cString, String\u003e properties \u003d\n          new LinkedHashMap\u003cString, String\u003e();\n      int blockCnt \u003d reader.readerBCF.getBlockCount();\n      int metaBlkCnt \u003d reader.readerBCF.metaIndex.index.size();\n      properties.put(\"BCFile Version\", reader.readerBCF.version.toString());\n      properties.put(\"TFile Version\", reader.tfileMeta.version.toString());\n      properties.put(\"File Length\", Long.toString(length));\n      properties.put(\"Data Compression\", reader.readerBCF\n          .getDefaultCompressionName());\n      properties.put(\"Record Count\", Long.toString(reader.getEntryCount()));\n      properties.put(\"Sorted\", Boolean.toString(reader.isSorted()));\n      if (reader.isSorted()) {\n        properties.put(\"Comparator\", reader.getComparatorName());\n      }\n      properties.put(\"Data Block Count\", Integer.toString(blockCnt));\n      long dataSize \u003d 0, dataSizeUncompressed \u003d 0;\n      if (blockCnt \u003e 0) {\n        for (int i \u003d 0; i \u003c blockCnt; ++i) {\n          BlockRegion region \u003d\n              reader.readerBCF.dataIndex.getBlockRegionList().get(i);\n          dataSize +\u003d region.getCompressedSize();\n          dataSizeUncompressed +\u003d region.getRawSize();\n        }\n        properties.put(\"Data Block Bytes\", Long.toString(dataSize));\n        if (!reader.readerBCF.getDefaultCompressionName().equals(\"none\")) {\n          properties.put(\"Data Block Uncompressed Bytes\", Long\n              .toString(dataSizeUncompressed));\n          properties.put(\"Data Block Compression Ratio\", String.format(\n              \"1:%.1f\", (double) dataSizeUncompressed / dataSize));\n        }\n      }\n\n      properties.put(\"Meta Block Count\", Integer.toString(metaBlkCnt));\n      long metaSize \u003d 0, metaSizeUncompressed \u003d 0;\n      if (metaBlkCnt \u003e 0) {\n        Collection\u003cMetaIndexEntry\u003e metaBlks \u003d\n            reader.readerBCF.metaIndex.index.values();\n        boolean calculateCompression \u003d false;\n        for (Iterator\u003cMetaIndexEntry\u003e it \u003d metaBlks.iterator(); it.hasNext();) {\n          MetaIndexEntry e \u003d it.next();\n          metaSize +\u003d e.getRegion().getCompressedSize();\n          metaSizeUncompressed +\u003d e.getRegion().getRawSize();\n          if (e.getCompressionAlgorithm() !\u003d Compression.Algorithm.NONE) {\n            calculateCompression \u003d true;\n          }\n        }\n        properties.put(\"Meta Block Bytes\", Long.toString(metaSize));\n        if (calculateCompression) {\n          properties.put(\"Meta Block Uncompressed Bytes\", Long\n              .toString(metaSizeUncompressed));\n          properties.put(\"Meta Block Compression Ratio\", String.format(\n              \"1:%.1f\", (double) metaSizeUncompressed / metaSize));\n        }\n      }\n      properties.put(\"Meta-Data Size Ratio\", String.format(\"1:%.1f\",\n          (double) dataSize / metaSize));\n      long leftOverBytes \u003d length - dataSize - metaSize;\n      long miscSize \u003d\n          BCFile.Magic.size() * 2 + Long.SIZE / Byte.SIZE + Version.size();\n      long metaIndexSize \u003d leftOverBytes - miscSize;\n      properties.put(\"Meta Block Index Bytes\", Long.toString(metaIndexSize));\n      properties.put(\"Headers Etc Bytes\", Long.toString(miscSize));\n      // Now output the properties table.\n      int maxKeyLength \u003d 0;\n      Set\u003cMap.Entry\u003cString, String\u003e\u003e entrySet \u003d properties.entrySet();\n      for (Iterator\u003cMap.Entry\u003cString, String\u003e\u003e it \u003d entrySet.iterator(); it\n          .hasNext();) {\n        Map.Entry\u003cString, String\u003e e \u003d it.next();\n        if (e.getKey().length() \u003e maxKeyLength) {\n          maxKeyLength \u003d e.getKey().length();\n        }\n      }\n      for (Iterator\u003cMap.Entry\u003cString, String\u003e\u003e it \u003d entrySet.iterator(); it\n          .hasNext();) {\n        Map.Entry\u003cString, String\u003e e \u003d it.next();\n        out.printf(\"%s : %s%n\", Align.format(e.getKey(), maxKeyLength,\n            Align.LEFT), e.getValue());\n      }\n      out.println();\n      reader.checkTFileDataIndex();\n      if (blockCnt \u003e 0) {\n        String blkID \u003d \"Data-Block\";\n        int blkIDWidth \u003d Align.calculateWidth(blkID, blockCnt);\n        int blkIDWidth2 \u003d Align.calculateWidth(\"\", blockCnt);\n        String offset \u003d \"Offset\";\n        int offsetWidth \u003d Align.calculateWidth(offset, length);\n        String blkLen \u003d \"Length\";\n        int blkLenWidth \u003d\n            Align.calculateWidth(blkLen, dataSize / blockCnt * 10);\n        String rawSize \u003d \"Raw-Size\";\n        int rawSizeWidth \u003d\n            Align.calculateWidth(rawSize, dataSizeUncompressed / blockCnt * 10);\n        String records \u003d \"Records\";\n        int recordsWidth \u003d\n            Align.calculateWidth(records, reader.getEntryCount() / blockCnt\n                * 10);\n        String endKey \u003d \"End-Key\";\n        int endKeyWidth \u003d Math.max(endKey.length(), maxKeySampleLen * 2 + 5);\n\n        out.printf(\"%s %s %s %s %s %s%n\", Align.format(blkID, blkIDWidth,\n            Align.CENTER), Align.format(offset, offsetWidth, Align.CENTER),\n            Align.format(blkLen, blkLenWidth, Align.CENTER), Align.format(\n                rawSize, rawSizeWidth, Align.CENTER), Align.format(records,\n                recordsWidth, Align.CENTER), Align.format(endKey, endKeyWidth,\n                Align.LEFT));\n\n        for (int i \u003d 0; i \u003c blockCnt; ++i) {\n          BlockRegion region \u003d\n              reader.readerBCF.dataIndex.getBlockRegionList().get(i);\n          TFileIndexEntry indexEntry \u003d reader.tfileIndex.getEntry(i);\n          out.printf(\"%s %s %s %s %s \", Align.format(Align.format(i,\n              blkIDWidth2, Align.ZERO_PADDED), blkIDWidth, Align.LEFT), Align\n              .format(region.getOffset(), offsetWidth, Align.LEFT), Align\n              .format(region.getCompressedSize(), blkLenWidth, Align.LEFT),\n              Align.format(region.getRawSize(), rawSizeWidth, Align.LEFT),\n              Align.format(indexEntry.kvEntries, recordsWidth, Align.LEFT));\n          byte[] key \u003d indexEntry.key;\n          boolean asAscii \u003d true;\n          int sampleLen \u003d Math.min(maxKeySampleLen, key.length);\n          for (int j \u003d 0; j \u003c sampleLen; ++j) {\n            byte b \u003d key[j];\n            if ((b \u003c 32 \u0026\u0026 b !\u003d 9) || (b \u003d\u003d 127)) {\n              asAscii \u003d false;\n            }\n          }\n          if (!asAscii) {\n            out.print(\"0X\");\n            for (int j \u003d 0; j \u003c sampleLen; ++j) {\n              byte b \u003d key[i];\n              out.printf(\"%X\", b);\n            }\n          } else {\n            out.print(new String(key, 0, sampleLen));\n          }\n          if (sampleLen \u003c key.length) {\n            out.print(\"...\");\n          }\n          out.println();\n        }\n      }\n\n      out.println();\n      if (metaBlkCnt \u003e 0) {\n        String name \u003d \"Meta-Block\";\n        int maxNameLen \u003d 0;\n        Set\u003cMap.Entry\u003cString, MetaIndexEntry\u003e\u003e metaBlkEntrySet \u003d\n            reader.readerBCF.metaIndex.index.entrySet();\n        for (Iterator\u003cMap.Entry\u003cString, MetaIndexEntry\u003e\u003e it \u003d\n            metaBlkEntrySet.iterator(); it.hasNext();) {\n          Map.Entry\u003cString, MetaIndexEntry\u003e e \u003d it.next();\n          if (e.getKey().length() \u003e maxNameLen) {\n            maxNameLen \u003d e.getKey().length();\n          }\n        }\n        int nameWidth \u003d Math.max(name.length(), maxNameLen);\n        String offset \u003d \"Offset\";\n        int offsetWidth \u003d Align.calculateWidth(offset, length);\n        String blkLen \u003d \"Length\";\n        int blkLenWidth \u003d\n            Align.calculateWidth(blkLen, metaSize / metaBlkCnt * 10);\n        String rawSize \u003d \"Raw-Size\";\n        int rawSizeWidth \u003d\n            Align.calculateWidth(rawSize, metaSizeUncompressed / metaBlkCnt\n                * 10);\n        String compression \u003d \"Compression\";\n        int compressionWidth \u003d compression.length();\n        out.printf(\"%s %s %s %s %s%n\", Align.format(name, nameWidth,\n            Align.CENTER), Align.format(offset, offsetWidth, Align.CENTER),\n            Align.format(blkLen, blkLenWidth, Align.CENTER), Align.format(\n                rawSize, rawSizeWidth, Align.CENTER), Align.format(compression,\n                compressionWidth, Align.LEFT));\n\n        for (Iterator\u003cMap.Entry\u003cString, MetaIndexEntry\u003e\u003e it \u003d\n            metaBlkEntrySet.iterator(); it.hasNext();) {\n          Map.Entry\u003cString, MetaIndexEntry\u003e e \u003d it.next();\n          String blkName \u003d e.getValue().getMetaName();\n          BlockRegion region \u003d e.getValue().getRegion();\n          String blkCompression \u003d\n              e.getValue().getCompressionAlgorithm().getName();\n          out.printf(\"%s %s %s %s %s%n\", Align.format(blkName, nameWidth,\n              Align.LEFT), Align.format(region.getOffset(), offsetWidth,\n              Align.LEFT), Align.format(region.getCompressedSize(),\n              blkLenWidth, Align.LEFT), Align.format(region.getRawSize(),\n              rawSizeWidth, Align.LEFT), Align.format(blkCompression,\n              compressionWidth, Align.LEFT));\n        }\n      }\n    } finally {\n      IOUtils.cleanup(LOG, reader, fsdis);\n    }\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/file/tfile/TFileDumper.java",
      "extendedDetails": {}
    },
    "0c53ed4cd122f87b2b041d670b9b59e27da5439c": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-8818. Use equals instead \u003d\u003d in MD5MD5CRC32FileChecksum and TFileDumper. Contributed by Brandon Li.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1385374 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/09/12 2:10 PM",
      "commitName": "0c53ed4cd122f87b2b041d670b9b59e27da5439c",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "24/08/11 5:14 PM",
      "commitNameOld": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 388.87,
      "commitsBetweenForRepo": 2556,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,200 +1,200 @@\n   static public void dumpInfo(String file, PrintStream out, Configuration conf)\n       throws IOException {\n     final int maxKeySampleLen \u003d 16;\n     Path path \u003d new Path(file);\n     FileSystem fs \u003d path.getFileSystem(conf);\n     long length \u003d fs.getFileStatus(path).getLen();\n     FSDataInputStream fsdis \u003d fs.open(path);\n     TFile.Reader reader \u003d new TFile.Reader(fsdis, length, conf);\n     try {\n       LinkedHashMap\u003cString, String\u003e properties \u003d\n           new LinkedHashMap\u003cString, String\u003e();\n       int blockCnt \u003d reader.readerBCF.getBlockCount();\n       int metaBlkCnt \u003d reader.readerBCF.metaIndex.index.size();\n       properties.put(\"BCFile Version\", reader.readerBCF.version.toString());\n       properties.put(\"TFile Version\", reader.tfileMeta.version.toString());\n       properties.put(\"File Length\", Long.toString(length));\n       properties.put(\"Data Compression\", reader.readerBCF\n           .getDefaultCompressionName());\n       properties.put(\"Record Count\", Long.toString(reader.getEntryCount()));\n       properties.put(\"Sorted\", Boolean.toString(reader.isSorted()));\n       if (reader.isSorted()) {\n         properties.put(\"Comparator\", reader.getComparatorName());\n       }\n       properties.put(\"Data Block Count\", Integer.toString(blockCnt));\n       long dataSize \u003d 0, dataSizeUncompressed \u003d 0;\n       if (blockCnt \u003e 0) {\n         for (int i \u003d 0; i \u003c blockCnt; ++i) {\n           BlockRegion region \u003d\n               reader.readerBCF.dataIndex.getBlockRegionList().get(i);\n           dataSize +\u003d region.getCompressedSize();\n           dataSizeUncompressed +\u003d region.getRawSize();\n         }\n         properties.put(\"Data Block Bytes\", Long.toString(dataSize));\n-        if (reader.readerBCF.getDefaultCompressionName() !\u003d \"none\") {\n+        if (!reader.readerBCF.getDefaultCompressionName().equals(\"none\")) {\n           properties.put(\"Data Block Uncompressed Bytes\", Long\n               .toString(dataSizeUncompressed));\n           properties.put(\"Data Block Compression Ratio\", String.format(\n               \"1:%.1f\", (double) dataSizeUncompressed / dataSize));\n         }\n       }\n \n       properties.put(\"Meta Block Count\", Integer.toString(metaBlkCnt));\n       long metaSize \u003d 0, metaSizeUncompressed \u003d 0;\n       if (metaBlkCnt \u003e 0) {\n         Collection\u003cMetaIndexEntry\u003e metaBlks \u003d\n             reader.readerBCF.metaIndex.index.values();\n         boolean calculateCompression \u003d false;\n         for (Iterator\u003cMetaIndexEntry\u003e it \u003d metaBlks.iterator(); it.hasNext();) {\n           MetaIndexEntry e \u003d it.next();\n           metaSize +\u003d e.getRegion().getCompressedSize();\n           metaSizeUncompressed +\u003d e.getRegion().getRawSize();\n           if (e.getCompressionAlgorithm() !\u003d Compression.Algorithm.NONE) {\n             calculateCompression \u003d true;\n           }\n         }\n         properties.put(\"Meta Block Bytes\", Long.toString(metaSize));\n         if (calculateCompression) {\n           properties.put(\"Meta Block Uncompressed Bytes\", Long\n               .toString(metaSizeUncompressed));\n           properties.put(\"Meta Block Compression Ratio\", String.format(\n               \"1:%.1f\", (double) metaSizeUncompressed / metaSize));\n         }\n       }\n       properties.put(\"Meta-Data Size Ratio\", String.format(\"1:%.1f\",\n           (double) dataSize / metaSize));\n       long leftOverBytes \u003d length - dataSize - metaSize;\n       long miscSize \u003d\n           BCFile.Magic.size() * 2 + Long.SIZE / Byte.SIZE + Version.size();\n       long metaIndexSize \u003d leftOverBytes - miscSize;\n       properties.put(\"Meta Block Index Bytes\", Long.toString(metaIndexSize));\n       properties.put(\"Headers Etc Bytes\", Long.toString(miscSize));\n       // Now output the properties table.\n       int maxKeyLength \u003d 0;\n       Set\u003cMap.Entry\u003cString, String\u003e\u003e entrySet \u003d properties.entrySet();\n       for (Iterator\u003cMap.Entry\u003cString, String\u003e\u003e it \u003d entrySet.iterator(); it\n           .hasNext();) {\n         Map.Entry\u003cString, String\u003e e \u003d it.next();\n         if (e.getKey().length() \u003e maxKeyLength) {\n           maxKeyLength \u003d e.getKey().length();\n         }\n       }\n       for (Iterator\u003cMap.Entry\u003cString, String\u003e\u003e it \u003d entrySet.iterator(); it\n           .hasNext();) {\n         Map.Entry\u003cString, String\u003e e \u003d it.next();\n         out.printf(\"%s : %s\\n\", Align.format(e.getKey(), maxKeyLength,\n             Align.LEFT), e.getValue());\n       }\n       out.println();\n       reader.checkTFileDataIndex();\n       if (blockCnt \u003e 0) {\n         String blkID \u003d \"Data-Block\";\n         int blkIDWidth \u003d Align.calculateWidth(blkID, blockCnt);\n         int blkIDWidth2 \u003d Align.calculateWidth(\"\", blockCnt);\n         String offset \u003d \"Offset\";\n         int offsetWidth \u003d Align.calculateWidth(offset, length);\n         String blkLen \u003d \"Length\";\n         int blkLenWidth \u003d\n             Align.calculateWidth(blkLen, dataSize / blockCnt * 10);\n         String rawSize \u003d \"Raw-Size\";\n         int rawSizeWidth \u003d\n             Align.calculateWidth(rawSize, dataSizeUncompressed / blockCnt * 10);\n         String records \u003d \"Records\";\n         int recordsWidth \u003d\n             Align.calculateWidth(records, reader.getEntryCount() / blockCnt\n                 * 10);\n         String endKey \u003d \"End-Key\";\n         int endKeyWidth \u003d Math.max(endKey.length(), maxKeySampleLen * 2 + 5);\n \n         out.printf(\"%s %s %s %s %s %s\\n\", Align.format(blkID, blkIDWidth,\n             Align.CENTER), Align.format(offset, offsetWidth, Align.CENTER),\n             Align.format(blkLen, blkLenWidth, Align.CENTER), Align.format(\n                 rawSize, rawSizeWidth, Align.CENTER), Align.format(records,\n                 recordsWidth, Align.CENTER), Align.format(endKey, endKeyWidth,\n                 Align.LEFT));\n \n         for (int i \u003d 0; i \u003c blockCnt; ++i) {\n           BlockRegion region \u003d\n               reader.readerBCF.dataIndex.getBlockRegionList().get(i);\n           TFileIndexEntry indexEntry \u003d reader.tfileIndex.getEntry(i);\n           out.printf(\"%s %s %s %s %s \", Align.format(Align.format(i,\n               blkIDWidth2, Align.ZERO_PADDED), blkIDWidth, Align.LEFT), Align\n               .format(region.getOffset(), offsetWidth, Align.LEFT), Align\n               .format(region.getCompressedSize(), blkLenWidth, Align.LEFT),\n               Align.format(region.getRawSize(), rawSizeWidth, Align.LEFT),\n               Align.format(indexEntry.kvEntries, recordsWidth, Align.LEFT));\n           byte[] key \u003d indexEntry.key;\n           boolean asAscii \u003d true;\n           int sampleLen \u003d Math.min(maxKeySampleLen, key.length);\n           for (int j \u003d 0; j \u003c sampleLen; ++j) {\n             byte b \u003d key[j];\n             if ((b \u003c 32 \u0026\u0026 b !\u003d 9) || (b \u003d\u003d 127)) {\n               asAscii \u003d false;\n             }\n           }\n           if (!asAscii) {\n             out.print(\"0X\");\n             for (int j \u003d 0; j \u003c sampleLen; ++j) {\n               byte b \u003d key[i];\n               out.printf(\"%X\", b);\n             }\n           } else {\n             out.print(new String(key, 0, sampleLen));\n           }\n           if (sampleLen \u003c key.length) {\n             out.print(\"...\");\n           }\n           out.println();\n         }\n       }\n \n       out.println();\n       if (metaBlkCnt \u003e 0) {\n         String name \u003d \"Meta-Block\";\n         int maxNameLen \u003d 0;\n         Set\u003cMap.Entry\u003cString, MetaIndexEntry\u003e\u003e metaBlkEntrySet \u003d\n             reader.readerBCF.metaIndex.index.entrySet();\n         for (Iterator\u003cMap.Entry\u003cString, MetaIndexEntry\u003e\u003e it \u003d\n             metaBlkEntrySet.iterator(); it.hasNext();) {\n           Map.Entry\u003cString, MetaIndexEntry\u003e e \u003d it.next();\n           if (e.getKey().length() \u003e maxNameLen) {\n             maxNameLen \u003d e.getKey().length();\n           }\n         }\n         int nameWidth \u003d Math.max(name.length(), maxNameLen);\n         String offset \u003d \"Offset\";\n         int offsetWidth \u003d Align.calculateWidth(offset, length);\n         String blkLen \u003d \"Length\";\n         int blkLenWidth \u003d\n             Align.calculateWidth(blkLen, metaSize / metaBlkCnt * 10);\n         String rawSize \u003d \"Raw-Size\";\n         int rawSizeWidth \u003d\n             Align.calculateWidth(rawSize, metaSizeUncompressed / metaBlkCnt\n                 * 10);\n         String compression \u003d \"Compression\";\n         int compressionWidth \u003d compression.length();\n         out.printf(\"%s %s %s %s %s\\n\", Align.format(name, nameWidth,\n             Align.CENTER), Align.format(offset, offsetWidth, Align.CENTER),\n             Align.format(blkLen, blkLenWidth, Align.CENTER), Align.format(\n                 rawSize, rawSizeWidth, Align.CENTER), Align.format(compression,\n                 compressionWidth, Align.LEFT));\n \n         for (Iterator\u003cMap.Entry\u003cString, MetaIndexEntry\u003e\u003e it \u003d\n             metaBlkEntrySet.iterator(); it.hasNext();) {\n           Map.Entry\u003cString, MetaIndexEntry\u003e e \u003d it.next();\n           String blkName \u003d e.getValue().getMetaName();\n           BlockRegion region \u003d e.getValue().getRegion();\n           String blkCompression \u003d\n               e.getValue().getCompressionAlgorithm().getName();\n           out.printf(\"%s %s %s %s %s\\n\", Align.format(blkName, nameWidth,\n               Align.LEFT), Align.format(region.getOffset(), offsetWidth,\n               Align.LEFT), Align.format(region.getCompressedSize(),\n               blkLenWidth, Align.LEFT), Align.format(region.getRawSize(),\n               rawSizeWidth, Align.LEFT), Align.format(blkCompression,\n               compressionWidth, Align.LEFT));\n         }\n       }\n     } finally {\n       IOUtils.cleanup(LOG, reader, fsdis);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static public void dumpInfo(String file, PrintStream out, Configuration conf)\n      throws IOException {\n    final int maxKeySampleLen \u003d 16;\n    Path path \u003d new Path(file);\n    FileSystem fs \u003d path.getFileSystem(conf);\n    long length \u003d fs.getFileStatus(path).getLen();\n    FSDataInputStream fsdis \u003d fs.open(path);\n    TFile.Reader reader \u003d new TFile.Reader(fsdis, length, conf);\n    try {\n      LinkedHashMap\u003cString, String\u003e properties \u003d\n          new LinkedHashMap\u003cString, String\u003e();\n      int blockCnt \u003d reader.readerBCF.getBlockCount();\n      int metaBlkCnt \u003d reader.readerBCF.metaIndex.index.size();\n      properties.put(\"BCFile Version\", reader.readerBCF.version.toString());\n      properties.put(\"TFile Version\", reader.tfileMeta.version.toString());\n      properties.put(\"File Length\", Long.toString(length));\n      properties.put(\"Data Compression\", reader.readerBCF\n          .getDefaultCompressionName());\n      properties.put(\"Record Count\", Long.toString(reader.getEntryCount()));\n      properties.put(\"Sorted\", Boolean.toString(reader.isSorted()));\n      if (reader.isSorted()) {\n        properties.put(\"Comparator\", reader.getComparatorName());\n      }\n      properties.put(\"Data Block Count\", Integer.toString(blockCnt));\n      long dataSize \u003d 0, dataSizeUncompressed \u003d 0;\n      if (blockCnt \u003e 0) {\n        for (int i \u003d 0; i \u003c blockCnt; ++i) {\n          BlockRegion region \u003d\n              reader.readerBCF.dataIndex.getBlockRegionList().get(i);\n          dataSize +\u003d region.getCompressedSize();\n          dataSizeUncompressed +\u003d region.getRawSize();\n        }\n        properties.put(\"Data Block Bytes\", Long.toString(dataSize));\n        if (!reader.readerBCF.getDefaultCompressionName().equals(\"none\")) {\n          properties.put(\"Data Block Uncompressed Bytes\", Long\n              .toString(dataSizeUncompressed));\n          properties.put(\"Data Block Compression Ratio\", String.format(\n              \"1:%.1f\", (double) dataSizeUncompressed / dataSize));\n        }\n      }\n\n      properties.put(\"Meta Block Count\", Integer.toString(metaBlkCnt));\n      long metaSize \u003d 0, metaSizeUncompressed \u003d 0;\n      if (metaBlkCnt \u003e 0) {\n        Collection\u003cMetaIndexEntry\u003e metaBlks \u003d\n            reader.readerBCF.metaIndex.index.values();\n        boolean calculateCompression \u003d false;\n        for (Iterator\u003cMetaIndexEntry\u003e it \u003d metaBlks.iterator(); it.hasNext();) {\n          MetaIndexEntry e \u003d it.next();\n          metaSize +\u003d e.getRegion().getCompressedSize();\n          metaSizeUncompressed +\u003d e.getRegion().getRawSize();\n          if (e.getCompressionAlgorithm() !\u003d Compression.Algorithm.NONE) {\n            calculateCompression \u003d true;\n          }\n        }\n        properties.put(\"Meta Block Bytes\", Long.toString(metaSize));\n        if (calculateCompression) {\n          properties.put(\"Meta Block Uncompressed Bytes\", Long\n              .toString(metaSizeUncompressed));\n          properties.put(\"Meta Block Compression Ratio\", String.format(\n              \"1:%.1f\", (double) metaSizeUncompressed / metaSize));\n        }\n      }\n      properties.put(\"Meta-Data Size Ratio\", String.format(\"1:%.1f\",\n          (double) dataSize / metaSize));\n      long leftOverBytes \u003d length - dataSize - metaSize;\n      long miscSize \u003d\n          BCFile.Magic.size() * 2 + Long.SIZE / Byte.SIZE + Version.size();\n      long metaIndexSize \u003d leftOverBytes - miscSize;\n      properties.put(\"Meta Block Index Bytes\", Long.toString(metaIndexSize));\n      properties.put(\"Headers Etc Bytes\", Long.toString(miscSize));\n      // Now output the properties table.\n      int maxKeyLength \u003d 0;\n      Set\u003cMap.Entry\u003cString, String\u003e\u003e entrySet \u003d properties.entrySet();\n      for (Iterator\u003cMap.Entry\u003cString, String\u003e\u003e it \u003d entrySet.iterator(); it\n          .hasNext();) {\n        Map.Entry\u003cString, String\u003e e \u003d it.next();\n        if (e.getKey().length() \u003e maxKeyLength) {\n          maxKeyLength \u003d e.getKey().length();\n        }\n      }\n      for (Iterator\u003cMap.Entry\u003cString, String\u003e\u003e it \u003d entrySet.iterator(); it\n          .hasNext();) {\n        Map.Entry\u003cString, String\u003e e \u003d it.next();\n        out.printf(\"%s : %s\\n\", Align.format(e.getKey(), maxKeyLength,\n            Align.LEFT), e.getValue());\n      }\n      out.println();\n      reader.checkTFileDataIndex();\n      if (blockCnt \u003e 0) {\n        String blkID \u003d \"Data-Block\";\n        int blkIDWidth \u003d Align.calculateWidth(blkID, blockCnt);\n        int blkIDWidth2 \u003d Align.calculateWidth(\"\", blockCnt);\n        String offset \u003d \"Offset\";\n        int offsetWidth \u003d Align.calculateWidth(offset, length);\n        String blkLen \u003d \"Length\";\n        int blkLenWidth \u003d\n            Align.calculateWidth(blkLen, dataSize / blockCnt * 10);\n        String rawSize \u003d \"Raw-Size\";\n        int rawSizeWidth \u003d\n            Align.calculateWidth(rawSize, dataSizeUncompressed / blockCnt * 10);\n        String records \u003d \"Records\";\n        int recordsWidth \u003d\n            Align.calculateWidth(records, reader.getEntryCount() / blockCnt\n                * 10);\n        String endKey \u003d \"End-Key\";\n        int endKeyWidth \u003d Math.max(endKey.length(), maxKeySampleLen * 2 + 5);\n\n        out.printf(\"%s %s %s %s %s %s\\n\", Align.format(blkID, blkIDWidth,\n            Align.CENTER), Align.format(offset, offsetWidth, Align.CENTER),\n            Align.format(blkLen, blkLenWidth, Align.CENTER), Align.format(\n                rawSize, rawSizeWidth, Align.CENTER), Align.format(records,\n                recordsWidth, Align.CENTER), Align.format(endKey, endKeyWidth,\n                Align.LEFT));\n\n        for (int i \u003d 0; i \u003c blockCnt; ++i) {\n          BlockRegion region \u003d\n              reader.readerBCF.dataIndex.getBlockRegionList().get(i);\n          TFileIndexEntry indexEntry \u003d reader.tfileIndex.getEntry(i);\n          out.printf(\"%s %s %s %s %s \", Align.format(Align.format(i,\n              blkIDWidth2, Align.ZERO_PADDED), blkIDWidth, Align.LEFT), Align\n              .format(region.getOffset(), offsetWidth, Align.LEFT), Align\n              .format(region.getCompressedSize(), blkLenWidth, Align.LEFT),\n              Align.format(region.getRawSize(), rawSizeWidth, Align.LEFT),\n              Align.format(indexEntry.kvEntries, recordsWidth, Align.LEFT));\n          byte[] key \u003d indexEntry.key;\n          boolean asAscii \u003d true;\n          int sampleLen \u003d Math.min(maxKeySampleLen, key.length);\n          for (int j \u003d 0; j \u003c sampleLen; ++j) {\n            byte b \u003d key[j];\n            if ((b \u003c 32 \u0026\u0026 b !\u003d 9) || (b \u003d\u003d 127)) {\n              asAscii \u003d false;\n            }\n          }\n          if (!asAscii) {\n            out.print(\"0X\");\n            for (int j \u003d 0; j \u003c sampleLen; ++j) {\n              byte b \u003d key[i];\n              out.printf(\"%X\", b);\n            }\n          } else {\n            out.print(new String(key, 0, sampleLen));\n          }\n          if (sampleLen \u003c key.length) {\n            out.print(\"...\");\n          }\n          out.println();\n        }\n      }\n\n      out.println();\n      if (metaBlkCnt \u003e 0) {\n        String name \u003d \"Meta-Block\";\n        int maxNameLen \u003d 0;\n        Set\u003cMap.Entry\u003cString, MetaIndexEntry\u003e\u003e metaBlkEntrySet \u003d\n            reader.readerBCF.metaIndex.index.entrySet();\n        for (Iterator\u003cMap.Entry\u003cString, MetaIndexEntry\u003e\u003e it \u003d\n            metaBlkEntrySet.iterator(); it.hasNext();) {\n          Map.Entry\u003cString, MetaIndexEntry\u003e e \u003d it.next();\n          if (e.getKey().length() \u003e maxNameLen) {\n            maxNameLen \u003d e.getKey().length();\n          }\n        }\n        int nameWidth \u003d Math.max(name.length(), maxNameLen);\n        String offset \u003d \"Offset\";\n        int offsetWidth \u003d Align.calculateWidth(offset, length);\n        String blkLen \u003d \"Length\";\n        int blkLenWidth \u003d\n            Align.calculateWidth(blkLen, metaSize / metaBlkCnt * 10);\n        String rawSize \u003d \"Raw-Size\";\n        int rawSizeWidth \u003d\n            Align.calculateWidth(rawSize, metaSizeUncompressed / metaBlkCnt\n                * 10);\n        String compression \u003d \"Compression\";\n        int compressionWidth \u003d compression.length();\n        out.printf(\"%s %s %s %s %s\\n\", Align.format(name, nameWidth,\n            Align.CENTER), Align.format(offset, offsetWidth, Align.CENTER),\n            Align.format(blkLen, blkLenWidth, Align.CENTER), Align.format(\n                rawSize, rawSizeWidth, Align.CENTER), Align.format(compression,\n                compressionWidth, Align.LEFT));\n\n        for (Iterator\u003cMap.Entry\u003cString, MetaIndexEntry\u003e\u003e it \u003d\n            metaBlkEntrySet.iterator(); it.hasNext();) {\n          Map.Entry\u003cString, MetaIndexEntry\u003e e \u003d it.next();\n          String blkName \u003d e.getValue().getMetaName();\n          BlockRegion region \u003d e.getValue().getRegion();\n          String blkCompression \u003d\n              e.getValue().getCompressionAlgorithm().getName();\n          out.printf(\"%s %s %s %s %s\\n\", Align.format(blkName, nameWidth,\n              Align.LEFT), Align.format(region.getOffset(), offsetWidth,\n              Align.LEFT), Align.format(region.getCompressedSize(),\n              blkLenWidth, Align.LEFT), Align.format(region.getRawSize(),\n              rawSizeWidth, Align.LEFT), Align.format(blkCompression,\n              compressionWidth, Align.LEFT));\n        }\n      }\n    } finally {\n      IOUtils.cleanup(LOG, reader, fsdis);\n    }\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/file/tfile/TFileDumper.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  static public void dumpInfo(String file, PrintStream out, Configuration conf)\n      throws IOException {\n    final int maxKeySampleLen \u003d 16;\n    Path path \u003d new Path(file);\n    FileSystem fs \u003d path.getFileSystem(conf);\n    long length \u003d fs.getFileStatus(path).getLen();\n    FSDataInputStream fsdis \u003d fs.open(path);\n    TFile.Reader reader \u003d new TFile.Reader(fsdis, length, conf);\n    try {\n      LinkedHashMap\u003cString, String\u003e properties \u003d\n          new LinkedHashMap\u003cString, String\u003e();\n      int blockCnt \u003d reader.readerBCF.getBlockCount();\n      int metaBlkCnt \u003d reader.readerBCF.metaIndex.index.size();\n      properties.put(\"BCFile Version\", reader.readerBCF.version.toString());\n      properties.put(\"TFile Version\", reader.tfileMeta.version.toString());\n      properties.put(\"File Length\", Long.toString(length));\n      properties.put(\"Data Compression\", reader.readerBCF\n          .getDefaultCompressionName());\n      properties.put(\"Record Count\", Long.toString(reader.getEntryCount()));\n      properties.put(\"Sorted\", Boolean.toString(reader.isSorted()));\n      if (reader.isSorted()) {\n        properties.put(\"Comparator\", reader.getComparatorName());\n      }\n      properties.put(\"Data Block Count\", Integer.toString(blockCnt));\n      long dataSize \u003d 0, dataSizeUncompressed \u003d 0;\n      if (blockCnt \u003e 0) {\n        for (int i \u003d 0; i \u003c blockCnt; ++i) {\n          BlockRegion region \u003d\n              reader.readerBCF.dataIndex.getBlockRegionList().get(i);\n          dataSize +\u003d region.getCompressedSize();\n          dataSizeUncompressed +\u003d region.getRawSize();\n        }\n        properties.put(\"Data Block Bytes\", Long.toString(dataSize));\n        if (reader.readerBCF.getDefaultCompressionName() !\u003d \"none\") {\n          properties.put(\"Data Block Uncompressed Bytes\", Long\n              .toString(dataSizeUncompressed));\n          properties.put(\"Data Block Compression Ratio\", String.format(\n              \"1:%.1f\", (double) dataSizeUncompressed / dataSize));\n        }\n      }\n\n      properties.put(\"Meta Block Count\", Integer.toString(metaBlkCnt));\n      long metaSize \u003d 0, metaSizeUncompressed \u003d 0;\n      if (metaBlkCnt \u003e 0) {\n        Collection\u003cMetaIndexEntry\u003e metaBlks \u003d\n            reader.readerBCF.metaIndex.index.values();\n        boolean calculateCompression \u003d false;\n        for (Iterator\u003cMetaIndexEntry\u003e it \u003d metaBlks.iterator(); it.hasNext();) {\n          MetaIndexEntry e \u003d it.next();\n          metaSize +\u003d e.getRegion().getCompressedSize();\n          metaSizeUncompressed +\u003d e.getRegion().getRawSize();\n          if (e.getCompressionAlgorithm() !\u003d Compression.Algorithm.NONE) {\n            calculateCompression \u003d true;\n          }\n        }\n        properties.put(\"Meta Block Bytes\", Long.toString(metaSize));\n        if (calculateCompression) {\n          properties.put(\"Meta Block Uncompressed Bytes\", Long\n              .toString(metaSizeUncompressed));\n          properties.put(\"Meta Block Compression Ratio\", String.format(\n              \"1:%.1f\", (double) metaSizeUncompressed / metaSize));\n        }\n      }\n      properties.put(\"Meta-Data Size Ratio\", String.format(\"1:%.1f\",\n          (double) dataSize / metaSize));\n      long leftOverBytes \u003d length - dataSize - metaSize;\n      long miscSize \u003d\n          BCFile.Magic.size() * 2 + Long.SIZE / Byte.SIZE + Version.size();\n      long metaIndexSize \u003d leftOverBytes - miscSize;\n      properties.put(\"Meta Block Index Bytes\", Long.toString(metaIndexSize));\n      properties.put(\"Headers Etc Bytes\", Long.toString(miscSize));\n      // Now output the properties table.\n      int maxKeyLength \u003d 0;\n      Set\u003cMap.Entry\u003cString, String\u003e\u003e entrySet \u003d properties.entrySet();\n      for (Iterator\u003cMap.Entry\u003cString, String\u003e\u003e it \u003d entrySet.iterator(); it\n          .hasNext();) {\n        Map.Entry\u003cString, String\u003e e \u003d it.next();\n        if (e.getKey().length() \u003e maxKeyLength) {\n          maxKeyLength \u003d e.getKey().length();\n        }\n      }\n      for (Iterator\u003cMap.Entry\u003cString, String\u003e\u003e it \u003d entrySet.iterator(); it\n          .hasNext();) {\n        Map.Entry\u003cString, String\u003e e \u003d it.next();\n        out.printf(\"%s : %s\\n\", Align.format(e.getKey(), maxKeyLength,\n            Align.LEFT), e.getValue());\n      }\n      out.println();\n      reader.checkTFileDataIndex();\n      if (blockCnt \u003e 0) {\n        String blkID \u003d \"Data-Block\";\n        int blkIDWidth \u003d Align.calculateWidth(blkID, blockCnt);\n        int blkIDWidth2 \u003d Align.calculateWidth(\"\", blockCnt);\n        String offset \u003d \"Offset\";\n        int offsetWidth \u003d Align.calculateWidth(offset, length);\n        String blkLen \u003d \"Length\";\n        int blkLenWidth \u003d\n            Align.calculateWidth(blkLen, dataSize / blockCnt * 10);\n        String rawSize \u003d \"Raw-Size\";\n        int rawSizeWidth \u003d\n            Align.calculateWidth(rawSize, dataSizeUncompressed / blockCnt * 10);\n        String records \u003d \"Records\";\n        int recordsWidth \u003d\n            Align.calculateWidth(records, reader.getEntryCount() / blockCnt\n                * 10);\n        String endKey \u003d \"End-Key\";\n        int endKeyWidth \u003d Math.max(endKey.length(), maxKeySampleLen * 2 + 5);\n\n        out.printf(\"%s %s %s %s %s %s\\n\", Align.format(blkID, blkIDWidth,\n            Align.CENTER), Align.format(offset, offsetWidth, Align.CENTER),\n            Align.format(blkLen, blkLenWidth, Align.CENTER), Align.format(\n                rawSize, rawSizeWidth, Align.CENTER), Align.format(records,\n                recordsWidth, Align.CENTER), Align.format(endKey, endKeyWidth,\n                Align.LEFT));\n\n        for (int i \u003d 0; i \u003c blockCnt; ++i) {\n          BlockRegion region \u003d\n              reader.readerBCF.dataIndex.getBlockRegionList().get(i);\n          TFileIndexEntry indexEntry \u003d reader.tfileIndex.getEntry(i);\n          out.printf(\"%s %s %s %s %s \", Align.format(Align.format(i,\n              blkIDWidth2, Align.ZERO_PADDED), blkIDWidth, Align.LEFT), Align\n              .format(region.getOffset(), offsetWidth, Align.LEFT), Align\n              .format(region.getCompressedSize(), blkLenWidth, Align.LEFT),\n              Align.format(region.getRawSize(), rawSizeWidth, Align.LEFT),\n              Align.format(indexEntry.kvEntries, recordsWidth, Align.LEFT));\n          byte[] key \u003d indexEntry.key;\n          boolean asAscii \u003d true;\n          int sampleLen \u003d Math.min(maxKeySampleLen, key.length);\n          for (int j \u003d 0; j \u003c sampleLen; ++j) {\n            byte b \u003d key[j];\n            if ((b \u003c 32 \u0026\u0026 b !\u003d 9) || (b \u003d\u003d 127)) {\n              asAscii \u003d false;\n            }\n          }\n          if (!asAscii) {\n            out.print(\"0X\");\n            for (int j \u003d 0; j \u003c sampleLen; ++j) {\n              byte b \u003d key[i];\n              out.printf(\"%X\", b);\n            }\n          } else {\n            out.print(new String(key, 0, sampleLen));\n          }\n          if (sampleLen \u003c key.length) {\n            out.print(\"...\");\n          }\n          out.println();\n        }\n      }\n\n      out.println();\n      if (metaBlkCnt \u003e 0) {\n        String name \u003d \"Meta-Block\";\n        int maxNameLen \u003d 0;\n        Set\u003cMap.Entry\u003cString, MetaIndexEntry\u003e\u003e metaBlkEntrySet \u003d\n            reader.readerBCF.metaIndex.index.entrySet();\n        for (Iterator\u003cMap.Entry\u003cString, MetaIndexEntry\u003e\u003e it \u003d\n            metaBlkEntrySet.iterator(); it.hasNext();) {\n          Map.Entry\u003cString, MetaIndexEntry\u003e e \u003d it.next();\n          if (e.getKey().length() \u003e maxNameLen) {\n            maxNameLen \u003d e.getKey().length();\n          }\n        }\n        int nameWidth \u003d Math.max(name.length(), maxNameLen);\n        String offset \u003d \"Offset\";\n        int offsetWidth \u003d Align.calculateWidth(offset, length);\n        String blkLen \u003d \"Length\";\n        int blkLenWidth \u003d\n            Align.calculateWidth(blkLen, metaSize / metaBlkCnt * 10);\n        String rawSize \u003d \"Raw-Size\";\n        int rawSizeWidth \u003d\n            Align.calculateWidth(rawSize, metaSizeUncompressed / metaBlkCnt\n                * 10);\n        String compression \u003d \"Compression\";\n        int compressionWidth \u003d compression.length();\n        out.printf(\"%s %s %s %s %s\\n\", Align.format(name, nameWidth,\n            Align.CENTER), Align.format(offset, offsetWidth, Align.CENTER),\n            Align.format(blkLen, blkLenWidth, Align.CENTER), Align.format(\n                rawSize, rawSizeWidth, Align.CENTER), Align.format(compression,\n                compressionWidth, Align.LEFT));\n\n        for (Iterator\u003cMap.Entry\u003cString, MetaIndexEntry\u003e\u003e it \u003d\n            metaBlkEntrySet.iterator(); it.hasNext();) {\n          Map.Entry\u003cString, MetaIndexEntry\u003e e \u003d it.next();\n          String blkName \u003d e.getValue().getMetaName();\n          BlockRegion region \u003d e.getValue().getRegion();\n          String blkCompression \u003d\n              e.getValue().getCompressionAlgorithm().getName();\n          out.printf(\"%s %s %s %s %s\\n\", Align.format(blkName, nameWidth,\n              Align.LEFT), Align.format(region.getOffset(), offsetWidth,\n              Align.LEFT), Align.format(region.getCompressedSize(),\n              blkLenWidth, Align.LEFT), Align.format(region.getRawSize(),\n              rawSizeWidth, Align.LEFT), Align.format(blkCompression,\n              compressionWidth, Align.LEFT));\n        }\n      }\n    } finally {\n      IOUtils.cleanup(LOG, reader, fsdis);\n    }\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/file/tfile/TFileDumper.java",
      "extendedDetails": {
        "oldPath": "hadoop-common/src/main/java/org/apache/hadoop/io/file/tfile/TFileDumper.java",
        "newPath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/file/tfile/TFileDumper.java"
      }
    },
    "0f6dfeeacbab65a31a33927a4eb84871d371fe52": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-6671. Use maven for hadoop common builds. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1153184 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/08/11 9:37 AM",
      "commitName": "0f6dfeeacbab65a31a33927a4eb84871d371fe52",
      "commitAuthor": "Thomas White",
      "commitDateOld": "01/08/11 3:53 PM",
      "commitNameOld": "9bac807cedbcff34e1a144fb475eff267e5ed86d",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.74,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  static public void dumpInfo(String file, PrintStream out, Configuration conf)\n      throws IOException {\n    final int maxKeySampleLen \u003d 16;\n    Path path \u003d new Path(file);\n    FileSystem fs \u003d path.getFileSystem(conf);\n    long length \u003d fs.getFileStatus(path).getLen();\n    FSDataInputStream fsdis \u003d fs.open(path);\n    TFile.Reader reader \u003d new TFile.Reader(fsdis, length, conf);\n    try {\n      LinkedHashMap\u003cString, String\u003e properties \u003d\n          new LinkedHashMap\u003cString, String\u003e();\n      int blockCnt \u003d reader.readerBCF.getBlockCount();\n      int metaBlkCnt \u003d reader.readerBCF.metaIndex.index.size();\n      properties.put(\"BCFile Version\", reader.readerBCF.version.toString());\n      properties.put(\"TFile Version\", reader.tfileMeta.version.toString());\n      properties.put(\"File Length\", Long.toString(length));\n      properties.put(\"Data Compression\", reader.readerBCF\n          .getDefaultCompressionName());\n      properties.put(\"Record Count\", Long.toString(reader.getEntryCount()));\n      properties.put(\"Sorted\", Boolean.toString(reader.isSorted()));\n      if (reader.isSorted()) {\n        properties.put(\"Comparator\", reader.getComparatorName());\n      }\n      properties.put(\"Data Block Count\", Integer.toString(blockCnt));\n      long dataSize \u003d 0, dataSizeUncompressed \u003d 0;\n      if (blockCnt \u003e 0) {\n        for (int i \u003d 0; i \u003c blockCnt; ++i) {\n          BlockRegion region \u003d\n              reader.readerBCF.dataIndex.getBlockRegionList().get(i);\n          dataSize +\u003d region.getCompressedSize();\n          dataSizeUncompressed +\u003d region.getRawSize();\n        }\n        properties.put(\"Data Block Bytes\", Long.toString(dataSize));\n        if (reader.readerBCF.getDefaultCompressionName() !\u003d \"none\") {\n          properties.put(\"Data Block Uncompressed Bytes\", Long\n              .toString(dataSizeUncompressed));\n          properties.put(\"Data Block Compression Ratio\", String.format(\n              \"1:%.1f\", (double) dataSizeUncompressed / dataSize));\n        }\n      }\n\n      properties.put(\"Meta Block Count\", Integer.toString(metaBlkCnt));\n      long metaSize \u003d 0, metaSizeUncompressed \u003d 0;\n      if (metaBlkCnt \u003e 0) {\n        Collection\u003cMetaIndexEntry\u003e metaBlks \u003d\n            reader.readerBCF.metaIndex.index.values();\n        boolean calculateCompression \u003d false;\n        for (Iterator\u003cMetaIndexEntry\u003e it \u003d metaBlks.iterator(); it.hasNext();) {\n          MetaIndexEntry e \u003d it.next();\n          metaSize +\u003d e.getRegion().getCompressedSize();\n          metaSizeUncompressed +\u003d e.getRegion().getRawSize();\n          if (e.getCompressionAlgorithm() !\u003d Compression.Algorithm.NONE) {\n            calculateCompression \u003d true;\n          }\n        }\n        properties.put(\"Meta Block Bytes\", Long.toString(metaSize));\n        if (calculateCompression) {\n          properties.put(\"Meta Block Uncompressed Bytes\", Long\n              .toString(metaSizeUncompressed));\n          properties.put(\"Meta Block Compression Ratio\", String.format(\n              \"1:%.1f\", (double) metaSizeUncompressed / metaSize));\n        }\n      }\n      properties.put(\"Meta-Data Size Ratio\", String.format(\"1:%.1f\",\n          (double) dataSize / metaSize));\n      long leftOverBytes \u003d length - dataSize - metaSize;\n      long miscSize \u003d\n          BCFile.Magic.size() * 2 + Long.SIZE / Byte.SIZE + Version.size();\n      long metaIndexSize \u003d leftOverBytes - miscSize;\n      properties.put(\"Meta Block Index Bytes\", Long.toString(metaIndexSize));\n      properties.put(\"Headers Etc Bytes\", Long.toString(miscSize));\n      // Now output the properties table.\n      int maxKeyLength \u003d 0;\n      Set\u003cMap.Entry\u003cString, String\u003e\u003e entrySet \u003d properties.entrySet();\n      for (Iterator\u003cMap.Entry\u003cString, String\u003e\u003e it \u003d entrySet.iterator(); it\n          .hasNext();) {\n        Map.Entry\u003cString, String\u003e e \u003d it.next();\n        if (e.getKey().length() \u003e maxKeyLength) {\n          maxKeyLength \u003d e.getKey().length();\n        }\n      }\n      for (Iterator\u003cMap.Entry\u003cString, String\u003e\u003e it \u003d entrySet.iterator(); it\n          .hasNext();) {\n        Map.Entry\u003cString, String\u003e e \u003d it.next();\n        out.printf(\"%s : %s\\n\", Align.format(e.getKey(), maxKeyLength,\n            Align.LEFT), e.getValue());\n      }\n      out.println();\n      reader.checkTFileDataIndex();\n      if (blockCnt \u003e 0) {\n        String blkID \u003d \"Data-Block\";\n        int blkIDWidth \u003d Align.calculateWidth(blkID, blockCnt);\n        int blkIDWidth2 \u003d Align.calculateWidth(\"\", blockCnt);\n        String offset \u003d \"Offset\";\n        int offsetWidth \u003d Align.calculateWidth(offset, length);\n        String blkLen \u003d \"Length\";\n        int blkLenWidth \u003d\n            Align.calculateWidth(blkLen, dataSize / blockCnt * 10);\n        String rawSize \u003d \"Raw-Size\";\n        int rawSizeWidth \u003d\n            Align.calculateWidth(rawSize, dataSizeUncompressed / blockCnt * 10);\n        String records \u003d \"Records\";\n        int recordsWidth \u003d\n            Align.calculateWidth(records, reader.getEntryCount() / blockCnt\n                * 10);\n        String endKey \u003d \"End-Key\";\n        int endKeyWidth \u003d Math.max(endKey.length(), maxKeySampleLen * 2 + 5);\n\n        out.printf(\"%s %s %s %s %s %s\\n\", Align.format(blkID, blkIDWidth,\n            Align.CENTER), Align.format(offset, offsetWidth, Align.CENTER),\n            Align.format(blkLen, blkLenWidth, Align.CENTER), Align.format(\n                rawSize, rawSizeWidth, Align.CENTER), Align.format(records,\n                recordsWidth, Align.CENTER), Align.format(endKey, endKeyWidth,\n                Align.LEFT));\n\n        for (int i \u003d 0; i \u003c blockCnt; ++i) {\n          BlockRegion region \u003d\n              reader.readerBCF.dataIndex.getBlockRegionList().get(i);\n          TFileIndexEntry indexEntry \u003d reader.tfileIndex.getEntry(i);\n          out.printf(\"%s %s %s %s %s \", Align.format(Align.format(i,\n              blkIDWidth2, Align.ZERO_PADDED), blkIDWidth, Align.LEFT), Align\n              .format(region.getOffset(), offsetWidth, Align.LEFT), Align\n              .format(region.getCompressedSize(), blkLenWidth, Align.LEFT),\n              Align.format(region.getRawSize(), rawSizeWidth, Align.LEFT),\n              Align.format(indexEntry.kvEntries, recordsWidth, Align.LEFT));\n          byte[] key \u003d indexEntry.key;\n          boolean asAscii \u003d true;\n          int sampleLen \u003d Math.min(maxKeySampleLen, key.length);\n          for (int j \u003d 0; j \u003c sampleLen; ++j) {\n            byte b \u003d key[j];\n            if ((b \u003c 32 \u0026\u0026 b !\u003d 9) || (b \u003d\u003d 127)) {\n              asAscii \u003d false;\n            }\n          }\n          if (!asAscii) {\n            out.print(\"0X\");\n            for (int j \u003d 0; j \u003c sampleLen; ++j) {\n              byte b \u003d key[i];\n              out.printf(\"%X\", b);\n            }\n          } else {\n            out.print(new String(key, 0, sampleLen));\n          }\n          if (sampleLen \u003c key.length) {\n            out.print(\"...\");\n          }\n          out.println();\n        }\n      }\n\n      out.println();\n      if (metaBlkCnt \u003e 0) {\n        String name \u003d \"Meta-Block\";\n        int maxNameLen \u003d 0;\n        Set\u003cMap.Entry\u003cString, MetaIndexEntry\u003e\u003e metaBlkEntrySet \u003d\n            reader.readerBCF.metaIndex.index.entrySet();\n        for (Iterator\u003cMap.Entry\u003cString, MetaIndexEntry\u003e\u003e it \u003d\n            metaBlkEntrySet.iterator(); it.hasNext();) {\n          Map.Entry\u003cString, MetaIndexEntry\u003e e \u003d it.next();\n          if (e.getKey().length() \u003e maxNameLen) {\n            maxNameLen \u003d e.getKey().length();\n          }\n        }\n        int nameWidth \u003d Math.max(name.length(), maxNameLen);\n        String offset \u003d \"Offset\";\n        int offsetWidth \u003d Align.calculateWidth(offset, length);\n        String blkLen \u003d \"Length\";\n        int blkLenWidth \u003d\n            Align.calculateWidth(blkLen, metaSize / metaBlkCnt * 10);\n        String rawSize \u003d \"Raw-Size\";\n        int rawSizeWidth \u003d\n            Align.calculateWidth(rawSize, metaSizeUncompressed / metaBlkCnt\n                * 10);\n        String compression \u003d \"Compression\";\n        int compressionWidth \u003d compression.length();\n        out.printf(\"%s %s %s %s %s\\n\", Align.format(name, nameWidth,\n            Align.CENTER), Align.format(offset, offsetWidth, Align.CENTER),\n            Align.format(blkLen, blkLenWidth, Align.CENTER), Align.format(\n                rawSize, rawSizeWidth, Align.CENTER), Align.format(compression,\n                compressionWidth, Align.LEFT));\n\n        for (Iterator\u003cMap.Entry\u003cString, MetaIndexEntry\u003e\u003e it \u003d\n            metaBlkEntrySet.iterator(); it.hasNext();) {\n          Map.Entry\u003cString, MetaIndexEntry\u003e e \u003d it.next();\n          String blkName \u003d e.getValue().getMetaName();\n          BlockRegion region \u003d e.getValue().getRegion();\n          String blkCompression \u003d\n              e.getValue().getCompressionAlgorithm().getName();\n          out.printf(\"%s %s %s %s %s\\n\", Align.format(blkName, nameWidth,\n              Align.LEFT), Align.format(region.getOffset(), offsetWidth,\n              Align.LEFT), Align.format(region.getCompressedSize(),\n              blkLenWidth, Align.LEFT), Align.format(region.getRawSize(),\n              rawSizeWidth, Align.LEFT), Align.format(blkCompression,\n              compressionWidth, Align.LEFT));\n        }\n      }\n    } finally {\n      IOUtils.cleanup(LOG, reader, fsdis);\n    }\n  }",
      "path": "hadoop-common/src/main/java/org/apache/hadoop/io/file/tfile/TFileDumper.java",
      "extendedDetails": {
        "oldPath": "common/src/java/org/apache/hadoop/io/file/tfile/TFileDumper.java",
        "newPath": "hadoop-common/src/main/java/org/apache/hadoop/io/file/tfile/TFileDumper.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "11/06/11 9:13 PM",
      "commitNameOld": "a285fb5effe9ba3be4ec5f942afaf5ddd1186151",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 0.74,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  static public void dumpInfo(String file, PrintStream out, Configuration conf)\n      throws IOException {\n    final int maxKeySampleLen \u003d 16;\n    Path path \u003d new Path(file);\n    FileSystem fs \u003d path.getFileSystem(conf);\n    long length \u003d fs.getFileStatus(path).getLen();\n    FSDataInputStream fsdis \u003d fs.open(path);\n    TFile.Reader reader \u003d new TFile.Reader(fsdis, length, conf);\n    try {\n      LinkedHashMap\u003cString, String\u003e properties \u003d\n          new LinkedHashMap\u003cString, String\u003e();\n      int blockCnt \u003d reader.readerBCF.getBlockCount();\n      int metaBlkCnt \u003d reader.readerBCF.metaIndex.index.size();\n      properties.put(\"BCFile Version\", reader.readerBCF.version.toString());\n      properties.put(\"TFile Version\", reader.tfileMeta.version.toString());\n      properties.put(\"File Length\", Long.toString(length));\n      properties.put(\"Data Compression\", reader.readerBCF\n          .getDefaultCompressionName());\n      properties.put(\"Record Count\", Long.toString(reader.getEntryCount()));\n      properties.put(\"Sorted\", Boolean.toString(reader.isSorted()));\n      if (reader.isSorted()) {\n        properties.put(\"Comparator\", reader.getComparatorName());\n      }\n      properties.put(\"Data Block Count\", Integer.toString(blockCnt));\n      long dataSize \u003d 0, dataSizeUncompressed \u003d 0;\n      if (blockCnt \u003e 0) {\n        for (int i \u003d 0; i \u003c blockCnt; ++i) {\n          BlockRegion region \u003d\n              reader.readerBCF.dataIndex.getBlockRegionList().get(i);\n          dataSize +\u003d region.getCompressedSize();\n          dataSizeUncompressed +\u003d region.getRawSize();\n        }\n        properties.put(\"Data Block Bytes\", Long.toString(dataSize));\n        if (reader.readerBCF.getDefaultCompressionName() !\u003d \"none\") {\n          properties.put(\"Data Block Uncompressed Bytes\", Long\n              .toString(dataSizeUncompressed));\n          properties.put(\"Data Block Compression Ratio\", String.format(\n              \"1:%.1f\", (double) dataSizeUncompressed / dataSize));\n        }\n      }\n\n      properties.put(\"Meta Block Count\", Integer.toString(metaBlkCnt));\n      long metaSize \u003d 0, metaSizeUncompressed \u003d 0;\n      if (metaBlkCnt \u003e 0) {\n        Collection\u003cMetaIndexEntry\u003e metaBlks \u003d\n            reader.readerBCF.metaIndex.index.values();\n        boolean calculateCompression \u003d false;\n        for (Iterator\u003cMetaIndexEntry\u003e it \u003d metaBlks.iterator(); it.hasNext();) {\n          MetaIndexEntry e \u003d it.next();\n          metaSize +\u003d e.getRegion().getCompressedSize();\n          metaSizeUncompressed +\u003d e.getRegion().getRawSize();\n          if (e.getCompressionAlgorithm() !\u003d Compression.Algorithm.NONE) {\n            calculateCompression \u003d true;\n          }\n        }\n        properties.put(\"Meta Block Bytes\", Long.toString(metaSize));\n        if (calculateCompression) {\n          properties.put(\"Meta Block Uncompressed Bytes\", Long\n              .toString(metaSizeUncompressed));\n          properties.put(\"Meta Block Compression Ratio\", String.format(\n              \"1:%.1f\", (double) metaSizeUncompressed / metaSize));\n        }\n      }\n      properties.put(\"Meta-Data Size Ratio\", String.format(\"1:%.1f\",\n          (double) dataSize / metaSize));\n      long leftOverBytes \u003d length - dataSize - metaSize;\n      long miscSize \u003d\n          BCFile.Magic.size() * 2 + Long.SIZE / Byte.SIZE + Version.size();\n      long metaIndexSize \u003d leftOverBytes - miscSize;\n      properties.put(\"Meta Block Index Bytes\", Long.toString(metaIndexSize));\n      properties.put(\"Headers Etc Bytes\", Long.toString(miscSize));\n      // Now output the properties table.\n      int maxKeyLength \u003d 0;\n      Set\u003cMap.Entry\u003cString, String\u003e\u003e entrySet \u003d properties.entrySet();\n      for (Iterator\u003cMap.Entry\u003cString, String\u003e\u003e it \u003d entrySet.iterator(); it\n          .hasNext();) {\n        Map.Entry\u003cString, String\u003e e \u003d it.next();\n        if (e.getKey().length() \u003e maxKeyLength) {\n          maxKeyLength \u003d e.getKey().length();\n        }\n      }\n      for (Iterator\u003cMap.Entry\u003cString, String\u003e\u003e it \u003d entrySet.iterator(); it\n          .hasNext();) {\n        Map.Entry\u003cString, String\u003e e \u003d it.next();\n        out.printf(\"%s : %s\\n\", Align.format(e.getKey(), maxKeyLength,\n            Align.LEFT), e.getValue());\n      }\n      out.println();\n      reader.checkTFileDataIndex();\n      if (blockCnt \u003e 0) {\n        String blkID \u003d \"Data-Block\";\n        int blkIDWidth \u003d Align.calculateWidth(blkID, blockCnt);\n        int blkIDWidth2 \u003d Align.calculateWidth(\"\", blockCnt);\n        String offset \u003d \"Offset\";\n        int offsetWidth \u003d Align.calculateWidth(offset, length);\n        String blkLen \u003d \"Length\";\n        int blkLenWidth \u003d\n            Align.calculateWidth(blkLen, dataSize / blockCnt * 10);\n        String rawSize \u003d \"Raw-Size\";\n        int rawSizeWidth \u003d\n            Align.calculateWidth(rawSize, dataSizeUncompressed / blockCnt * 10);\n        String records \u003d \"Records\";\n        int recordsWidth \u003d\n            Align.calculateWidth(records, reader.getEntryCount() / blockCnt\n                * 10);\n        String endKey \u003d \"End-Key\";\n        int endKeyWidth \u003d Math.max(endKey.length(), maxKeySampleLen * 2 + 5);\n\n        out.printf(\"%s %s %s %s %s %s\\n\", Align.format(blkID, blkIDWidth,\n            Align.CENTER), Align.format(offset, offsetWidth, Align.CENTER),\n            Align.format(blkLen, blkLenWidth, Align.CENTER), Align.format(\n                rawSize, rawSizeWidth, Align.CENTER), Align.format(records,\n                recordsWidth, Align.CENTER), Align.format(endKey, endKeyWidth,\n                Align.LEFT));\n\n        for (int i \u003d 0; i \u003c blockCnt; ++i) {\n          BlockRegion region \u003d\n              reader.readerBCF.dataIndex.getBlockRegionList().get(i);\n          TFileIndexEntry indexEntry \u003d reader.tfileIndex.getEntry(i);\n          out.printf(\"%s %s %s %s %s \", Align.format(Align.format(i,\n              blkIDWidth2, Align.ZERO_PADDED), blkIDWidth, Align.LEFT), Align\n              .format(region.getOffset(), offsetWidth, Align.LEFT), Align\n              .format(region.getCompressedSize(), blkLenWidth, Align.LEFT),\n              Align.format(region.getRawSize(), rawSizeWidth, Align.LEFT),\n              Align.format(indexEntry.kvEntries, recordsWidth, Align.LEFT));\n          byte[] key \u003d indexEntry.key;\n          boolean asAscii \u003d true;\n          int sampleLen \u003d Math.min(maxKeySampleLen, key.length);\n          for (int j \u003d 0; j \u003c sampleLen; ++j) {\n            byte b \u003d key[j];\n            if ((b \u003c 32 \u0026\u0026 b !\u003d 9) || (b \u003d\u003d 127)) {\n              asAscii \u003d false;\n            }\n          }\n          if (!asAscii) {\n            out.print(\"0X\");\n            for (int j \u003d 0; j \u003c sampleLen; ++j) {\n              byte b \u003d key[i];\n              out.printf(\"%X\", b);\n            }\n          } else {\n            out.print(new String(key, 0, sampleLen));\n          }\n          if (sampleLen \u003c key.length) {\n            out.print(\"...\");\n          }\n          out.println();\n        }\n      }\n\n      out.println();\n      if (metaBlkCnt \u003e 0) {\n        String name \u003d \"Meta-Block\";\n        int maxNameLen \u003d 0;\n        Set\u003cMap.Entry\u003cString, MetaIndexEntry\u003e\u003e metaBlkEntrySet \u003d\n            reader.readerBCF.metaIndex.index.entrySet();\n        for (Iterator\u003cMap.Entry\u003cString, MetaIndexEntry\u003e\u003e it \u003d\n            metaBlkEntrySet.iterator(); it.hasNext();) {\n          Map.Entry\u003cString, MetaIndexEntry\u003e e \u003d it.next();\n          if (e.getKey().length() \u003e maxNameLen) {\n            maxNameLen \u003d e.getKey().length();\n          }\n        }\n        int nameWidth \u003d Math.max(name.length(), maxNameLen);\n        String offset \u003d \"Offset\";\n        int offsetWidth \u003d Align.calculateWidth(offset, length);\n        String blkLen \u003d \"Length\";\n        int blkLenWidth \u003d\n            Align.calculateWidth(blkLen, metaSize / metaBlkCnt * 10);\n        String rawSize \u003d \"Raw-Size\";\n        int rawSizeWidth \u003d\n            Align.calculateWidth(rawSize, metaSizeUncompressed / metaBlkCnt\n                * 10);\n        String compression \u003d \"Compression\";\n        int compressionWidth \u003d compression.length();\n        out.printf(\"%s %s %s %s %s\\n\", Align.format(name, nameWidth,\n            Align.CENTER), Align.format(offset, offsetWidth, Align.CENTER),\n            Align.format(blkLen, blkLenWidth, Align.CENTER), Align.format(\n                rawSize, rawSizeWidth, Align.CENTER), Align.format(compression,\n                compressionWidth, Align.LEFT));\n\n        for (Iterator\u003cMap.Entry\u003cString, MetaIndexEntry\u003e\u003e it \u003d\n            metaBlkEntrySet.iterator(); it.hasNext();) {\n          Map.Entry\u003cString, MetaIndexEntry\u003e e \u003d it.next();\n          String blkName \u003d e.getValue().getMetaName();\n          BlockRegion region \u003d e.getValue().getRegion();\n          String blkCompression \u003d\n              e.getValue().getCompressionAlgorithm().getName();\n          out.printf(\"%s %s %s %s %s\\n\", Align.format(blkName, nameWidth,\n              Align.LEFT), Align.format(region.getOffset(), offsetWidth,\n              Align.LEFT), Align.format(region.getCompressedSize(),\n              blkLenWidth, Align.LEFT), Align.format(region.getRawSize(),\n              rawSizeWidth, Align.LEFT), Align.format(blkCompression,\n              compressionWidth, Align.LEFT));\n        }\n      }\n    } finally {\n      IOUtils.cleanup(LOG, reader, fsdis);\n    }\n  }",
      "path": "common/src/java/org/apache/hadoop/io/file/tfile/TFileDumper.java",
      "extendedDetails": {
        "oldPath": "src/java/org/apache/hadoop/io/file/tfile/TFileDumper.java",
        "newPath": "common/src/java/org/apache/hadoop/io/file/tfile/TFileDumper.java"
      }
    },
    "8246aa28ff72e3ae81eb6ce59852abd5828fadc6": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-3315. Add a new, binary file foramt, TFile. Contributed by Hong Tang.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@787913 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "23/06/09 10:48 PM",
      "commitName": "8246aa28ff72e3ae81eb6ce59852abd5828fadc6",
      "commitAuthor": "Christopher Douglas",
      "diff": "@@ -0,0 +1,200 @@\n+  static public void dumpInfo(String file, PrintStream out, Configuration conf)\n+      throws IOException {\n+    final int maxKeySampleLen \u003d 16;\n+    Path path \u003d new Path(file);\n+    FileSystem fs \u003d path.getFileSystem(conf);\n+    long length \u003d fs.getFileStatus(path).getLen();\n+    FSDataInputStream fsdis \u003d fs.open(path);\n+    TFile.Reader reader \u003d new TFile.Reader(fsdis, length, conf);\n+    try {\n+      LinkedHashMap\u003cString, String\u003e properties \u003d\n+          new LinkedHashMap\u003cString, String\u003e();\n+      int blockCnt \u003d reader.readerBCF.getBlockCount();\n+      int metaBlkCnt \u003d reader.readerBCF.metaIndex.index.size();\n+      properties.put(\"BCFile Version\", reader.readerBCF.version.toString());\n+      properties.put(\"TFile Version\", reader.tfileMeta.version.toString());\n+      properties.put(\"File Length\", Long.toString(length));\n+      properties.put(\"Data Compression\", reader.readerBCF\n+          .getDefaultCompressionName());\n+      properties.put(\"Record Count\", Long.toString(reader.getEntryCount()));\n+      properties.put(\"Sorted\", Boolean.toString(reader.isSorted()));\n+      if (reader.isSorted()) {\n+        properties.put(\"Comparator\", reader.getComparatorName());\n+      }\n+      properties.put(\"Data Block Count\", Integer.toString(blockCnt));\n+      long dataSize \u003d 0, dataSizeUncompressed \u003d 0;\n+      if (blockCnt \u003e 0) {\n+        for (int i \u003d 0; i \u003c blockCnt; ++i) {\n+          BlockRegion region \u003d\n+              reader.readerBCF.dataIndex.getBlockRegionList().get(i);\n+          dataSize +\u003d region.getCompressedSize();\n+          dataSizeUncompressed +\u003d region.getRawSize();\n+        }\n+        properties.put(\"Data Block Bytes\", Long.toString(dataSize));\n+        if (reader.readerBCF.getDefaultCompressionName() !\u003d \"none\") {\n+          properties.put(\"Data Block Uncompressed Bytes\", Long\n+              .toString(dataSizeUncompressed));\n+          properties.put(\"Data Block Compression Ratio\", String.format(\n+              \"1:%.1f\", (double) dataSizeUncompressed / dataSize));\n+        }\n+      }\n+\n+      properties.put(\"Meta Block Count\", Integer.toString(metaBlkCnt));\n+      long metaSize \u003d 0, metaSizeUncompressed \u003d 0;\n+      if (metaBlkCnt \u003e 0) {\n+        Collection\u003cMetaIndexEntry\u003e metaBlks \u003d\n+            reader.readerBCF.metaIndex.index.values();\n+        boolean calculateCompression \u003d false;\n+        for (Iterator\u003cMetaIndexEntry\u003e it \u003d metaBlks.iterator(); it.hasNext();) {\n+          MetaIndexEntry e \u003d it.next();\n+          metaSize +\u003d e.getRegion().getCompressedSize();\n+          metaSizeUncompressed +\u003d e.getRegion().getRawSize();\n+          if (e.getCompressionAlgorithm() !\u003d Compression.Algorithm.NONE) {\n+            calculateCompression \u003d true;\n+          }\n+        }\n+        properties.put(\"Meta Block Bytes\", Long.toString(metaSize));\n+        if (calculateCompression) {\n+          properties.put(\"Meta Block Uncompressed Bytes\", Long\n+              .toString(metaSizeUncompressed));\n+          properties.put(\"Meta Block Compression Ratio\", String.format(\n+              \"1:%.1f\", (double) metaSizeUncompressed / metaSize));\n+        }\n+      }\n+      properties.put(\"Meta-Data Size Ratio\", String.format(\"1:%.1f\",\n+          (double) dataSize / metaSize));\n+      long leftOverBytes \u003d length - dataSize - metaSize;\n+      long miscSize \u003d\n+          BCFile.Magic.size() * 2 + Long.SIZE / Byte.SIZE + Version.size();\n+      long metaIndexSize \u003d leftOverBytes - miscSize;\n+      properties.put(\"Meta Block Index Bytes\", Long.toString(metaIndexSize));\n+      properties.put(\"Headers Etc Bytes\", Long.toString(miscSize));\n+      // Now output the properties table.\n+      int maxKeyLength \u003d 0;\n+      Set\u003cMap.Entry\u003cString, String\u003e\u003e entrySet \u003d properties.entrySet();\n+      for (Iterator\u003cMap.Entry\u003cString, String\u003e\u003e it \u003d entrySet.iterator(); it\n+          .hasNext();) {\n+        Map.Entry\u003cString, String\u003e e \u003d it.next();\n+        if (e.getKey().length() \u003e maxKeyLength) {\n+          maxKeyLength \u003d e.getKey().length();\n+        }\n+      }\n+      for (Iterator\u003cMap.Entry\u003cString, String\u003e\u003e it \u003d entrySet.iterator(); it\n+          .hasNext();) {\n+        Map.Entry\u003cString, String\u003e e \u003d it.next();\n+        out.printf(\"%s : %s\\n\", Align.format(e.getKey(), maxKeyLength,\n+            Align.LEFT), e.getValue());\n+      }\n+      out.println();\n+      reader.checkTFileDataIndex();\n+      if (blockCnt \u003e 0) {\n+        String blkID \u003d \"Data-Block\";\n+        int blkIDWidth \u003d Align.calculateWidth(blkID, blockCnt);\n+        int blkIDWidth2 \u003d Align.calculateWidth(\"\", blockCnt);\n+        String offset \u003d \"Offset\";\n+        int offsetWidth \u003d Align.calculateWidth(offset, length);\n+        String blkLen \u003d \"Length\";\n+        int blkLenWidth \u003d\n+            Align.calculateWidth(blkLen, dataSize / blockCnt * 10);\n+        String rawSize \u003d \"Raw-Size\";\n+        int rawSizeWidth \u003d\n+            Align.calculateWidth(rawSize, dataSizeUncompressed / blockCnt * 10);\n+        String records \u003d \"Records\";\n+        int recordsWidth \u003d\n+            Align.calculateWidth(records, reader.getEntryCount() / blockCnt\n+                * 10);\n+        String endKey \u003d \"End-Key\";\n+        int endKeyWidth \u003d Math.max(endKey.length(), maxKeySampleLen * 2 + 5);\n+\n+        out.printf(\"%s %s %s %s %s %s\\n\", Align.format(blkID, blkIDWidth,\n+            Align.CENTER), Align.format(offset, offsetWidth, Align.CENTER),\n+            Align.format(blkLen, blkLenWidth, Align.CENTER), Align.format(\n+                rawSize, rawSizeWidth, Align.CENTER), Align.format(records,\n+                recordsWidth, Align.CENTER), Align.format(endKey, endKeyWidth,\n+                Align.LEFT));\n+\n+        for (int i \u003d 0; i \u003c blockCnt; ++i) {\n+          BlockRegion region \u003d\n+              reader.readerBCF.dataIndex.getBlockRegionList().get(i);\n+          TFileIndexEntry indexEntry \u003d reader.tfileIndex.getEntry(i);\n+          out.printf(\"%s %s %s %s %s \", Align.format(Align.format(i,\n+              blkIDWidth2, Align.ZERO_PADDED), blkIDWidth, Align.LEFT), Align\n+              .format(region.getOffset(), offsetWidth, Align.LEFT), Align\n+              .format(region.getCompressedSize(), blkLenWidth, Align.LEFT),\n+              Align.format(region.getRawSize(), rawSizeWidth, Align.LEFT),\n+              Align.format(indexEntry.kvEntries, recordsWidth, Align.LEFT));\n+          byte[] key \u003d indexEntry.key;\n+          boolean asAscii \u003d true;\n+          int sampleLen \u003d Math.min(maxKeySampleLen, key.length);\n+          for (int j \u003d 0; j \u003c sampleLen; ++j) {\n+            byte b \u003d key[j];\n+            if ((b \u003c 32 \u0026\u0026 b !\u003d 9) || (b \u003d\u003d 127)) {\n+              asAscii \u003d false;\n+            }\n+          }\n+          if (!asAscii) {\n+            out.print(\"0X\");\n+            for (int j \u003d 0; j \u003c sampleLen; ++j) {\n+              byte b \u003d key[i];\n+              out.printf(\"%X\", b);\n+            }\n+          } else {\n+            out.print(new String(key, 0, sampleLen));\n+          }\n+          if (sampleLen \u003c key.length) {\n+            out.print(\"...\");\n+          }\n+          out.println();\n+        }\n+      }\n+\n+      out.println();\n+      if (metaBlkCnt \u003e 0) {\n+        String name \u003d \"Meta-Block\";\n+        int maxNameLen \u003d 0;\n+        Set\u003cMap.Entry\u003cString, MetaIndexEntry\u003e\u003e metaBlkEntrySet \u003d\n+            reader.readerBCF.metaIndex.index.entrySet();\n+        for (Iterator\u003cMap.Entry\u003cString, MetaIndexEntry\u003e\u003e it \u003d\n+            metaBlkEntrySet.iterator(); it.hasNext();) {\n+          Map.Entry\u003cString, MetaIndexEntry\u003e e \u003d it.next();\n+          if (e.getKey().length() \u003e maxNameLen) {\n+            maxNameLen \u003d e.getKey().length();\n+          }\n+        }\n+        int nameWidth \u003d Math.max(name.length(), maxNameLen);\n+        String offset \u003d \"Offset\";\n+        int offsetWidth \u003d Align.calculateWidth(offset, length);\n+        String blkLen \u003d \"Length\";\n+        int blkLenWidth \u003d\n+            Align.calculateWidth(blkLen, metaSize / metaBlkCnt * 10);\n+        String rawSize \u003d \"Raw-Size\";\n+        int rawSizeWidth \u003d\n+            Align.calculateWidth(rawSize, metaSizeUncompressed / metaBlkCnt\n+                * 10);\n+        String compression \u003d \"Compression\";\n+        int compressionWidth \u003d compression.length();\n+        out.printf(\"%s %s %s %s %s\\n\", Align.format(name, nameWidth,\n+            Align.CENTER), Align.format(offset, offsetWidth, Align.CENTER),\n+            Align.format(blkLen, blkLenWidth, Align.CENTER), Align.format(\n+                rawSize, rawSizeWidth, Align.CENTER), Align.format(compression,\n+                compressionWidth, Align.LEFT));\n+\n+        for (Iterator\u003cMap.Entry\u003cString, MetaIndexEntry\u003e\u003e it \u003d\n+            metaBlkEntrySet.iterator(); it.hasNext();) {\n+          Map.Entry\u003cString, MetaIndexEntry\u003e e \u003d it.next();\n+          String blkName \u003d e.getValue().getMetaName();\n+          BlockRegion region \u003d e.getValue().getRegion();\n+          String blkCompression \u003d\n+              e.getValue().getCompressionAlgorithm().getName();\n+          out.printf(\"%s %s %s %s %s\\n\", Align.format(blkName, nameWidth,\n+              Align.LEFT), Align.format(region.getOffset(), offsetWidth,\n+              Align.LEFT), Align.format(region.getCompressedSize(),\n+              blkLenWidth, Align.LEFT), Align.format(region.getRawSize(),\n+              rawSizeWidth, Align.LEFT), Align.format(blkCompression,\n+              compressionWidth, Align.LEFT));\n+        }\n+      }\n+    } finally {\n+      IOUtils.cleanup(LOG, reader, fsdis);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  static public void dumpInfo(String file, PrintStream out, Configuration conf)\n      throws IOException {\n    final int maxKeySampleLen \u003d 16;\n    Path path \u003d new Path(file);\n    FileSystem fs \u003d path.getFileSystem(conf);\n    long length \u003d fs.getFileStatus(path).getLen();\n    FSDataInputStream fsdis \u003d fs.open(path);\n    TFile.Reader reader \u003d new TFile.Reader(fsdis, length, conf);\n    try {\n      LinkedHashMap\u003cString, String\u003e properties \u003d\n          new LinkedHashMap\u003cString, String\u003e();\n      int blockCnt \u003d reader.readerBCF.getBlockCount();\n      int metaBlkCnt \u003d reader.readerBCF.metaIndex.index.size();\n      properties.put(\"BCFile Version\", reader.readerBCF.version.toString());\n      properties.put(\"TFile Version\", reader.tfileMeta.version.toString());\n      properties.put(\"File Length\", Long.toString(length));\n      properties.put(\"Data Compression\", reader.readerBCF\n          .getDefaultCompressionName());\n      properties.put(\"Record Count\", Long.toString(reader.getEntryCount()));\n      properties.put(\"Sorted\", Boolean.toString(reader.isSorted()));\n      if (reader.isSorted()) {\n        properties.put(\"Comparator\", reader.getComparatorName());\n      }\n      properties.put(\"Data Block Count\", Integer.toString(blockCnt));\n      long dataSize \u003d 0, dataSizeUncompressed \u003d 0;\n      if (blockCnt \u003e 0) {\n        for (int i \u003d 0; i \u003c blockCnt; ++i) {\n          BlockRegion region \u003d\n              reader.readerBCF.dataIndex.getBlockRegionList().get(i);\n          dataSize +\u003d region.getCompressedSize();\n          dataSizeUncompressed +\u003d region.getRawSize();\n        }\n        properties.put(\"Data Block Bytes\", Long.toString(dataSize));\n        if (reader.readerBCF.getDefaultCompressionName() !\u003d \"none\") {\n          properties.put(\"Data Block Uncompressed Bytes\", Long\n              .toString(dataSizeUncompressed));\n          properties.put(\"Data Block Compression Ratio\", String.format(\n              \"1:%.1f\", (double) dataSizeUncompressed / dataSize));\n        }\n      }\n\n      properties.put(\"Meta Block Count\", Integer.toString(metaBlkCnt));\n      long metaSize \u003d 0, metaSizeUncompressed \u003d 0;\n      if (metaBlkCnt \u003e 0) {\n        Collection\u003cMetaIndexEntry\u003e metaBlks \u003d\n            reader.readerBCF.metaIndex.index.values();\n        boolean calculateCompression \u003d false;\n        for (Iterator\u003cMetaIndexEntry\u003e it \u003d metaBlks.iterator(); it.hasNext();) {\n          MetaIndexEntry e \u003d it.next();\n          metaSize +\u003d e.getRegion().getCompressedSize();\n          metaSizeUncompressed +\u003d e.getRegion().getRawSize();\n          if (e.getCompressionAlgorithm() !\u003d Compression.Algorithm.NONE) {\n            calculateCompression \u003d true;\n          }\n        }\n        properties.put(\"Meta Block Bytes\", Long.toString(metaSize));\n        if (calculateCompression) {\n          properties.put(\"Meta Block Uncompressed Bytes\", Long\n              .toString(metaSizeUncompressed));\n          properties.put(\"Meta Block Compression Ratio\", String.format(\n              \"1:%.1f\", (double) metaSizeUncompressed / metaSize));\n        }\n      }\n      properties.put(\"Meta-Data Size Ratio\", String.format(\"1:%.1f\",\n          (double) dataSize / metaSize));\n      long leftOverBytes \u003d length - dataSize - metaSize;\n      long miscSize \u003d\n          BCFile.Magic.size() * 2 + Long.SIZE / Byte.SIZE + Version.size();\n      long metaIndexSize \u003d leftOverBytes - miscSize;\n      properties.put(\"Meta Block Index Bytes\", Long.toString(metaIndexSize));\n      properties.put(\"Headers Etc Bytes\", Long.toString(miscSize));\n      // Now output the properties table.\n      int maxKeyLength \u003d 0;\n      Set\u003cMap.Entry\u003cString, String\u003e\u003e entrySet \u003d properties.entrySet();\n      for (Iterator\u003cMap.Entry\u003cString, String\u003e\u003e it \u003d entrySet.iterator(); it\n          .hasNext();) {\n        Map.Entry\u003cString, String\u003e e \u003d it.next();\n        if (e.getKey().length() \u003e maxKeyLength) {\n          maxKeyLength \u003d e.getKey().length();\n        }\n      }\n      for (Iterator\u003cMap.Entry\u003cString, String\u003e\u003e it \u003d entrySet.iterator(); it\n          .hasNext();) {\n        Map.Entry\u003cString, String\u003e e \u003d it.next();\n        out.printf(\"%s : %s\\n\", Align.format(e.getKey(), maxKeyLength,\n            Align.LEFT), e.getValue());\n      }\n      out.println();\n      reader.checkTFileDataIndex();\n      if (blockCnt \u003e 0) {\n        String blkID \u003d \"Data-Block\";\n        int blkIDWidth \u003d Align.calculateWidth(blkID, blockCnt);\n        int blkIDWidth2 \u003d Align.calculateWidth(\"\", blockCnt);\n        String offset \u003d \"Offset\";\n        int offsetWidth \u003d Align.calculateWidth(offset, length);\n        String blkLen \u003d \"Length\";\n        int blkLenWidth \u003d\n            Align.calculateWidth(blkLen, dataSize / blockCnt * 10);\n        String rawSize \u003d \"Raw-Size\";\n        int rawSizeWidth \u003d\n            Align.calculateWidth(rawSize, dataSizeUncompressed / blockCnt * 10);\n        String records \u003d \"Records\";\n        int recordsWidth \u003d\n            Align.calculateWidth(records, reader.getEntryCount() / blockCnt\n                * 10);\n        String endKey \u003d \"End-Key\";\n        int endKeyWidth \u003d Math.max(endKey.length(), maxKeySampleLen * 2 + 5);\n\n        out.printf(\"%s %s %s %s %s %s\\n\", Align.format(blkID, blkIDWidth,\n            Align.CENTER), Align.format(offset, offsetWidth, Align.CENTER),\n            Align.format(blkLen, blkLenWidth, Align.CENTER), Align.format(\n                rawSize, rawSizeWidth, Align.CENTER), Align.format(records,\n                recordsWidth, Align.CENTER), Align.format(endKey, endKeyWidth,\n                Align.LEFT));\n\n        for (int i \u003d 0; i \u003c blockCnt; ++i) {\n          BlockRegion region \u003d\n              reader.readerBCF.dataIndex.getBlockRegionList().get(i);\n          TFileIndexEntry indexEntry \u003d reader.tfileIndex.getEntry(i);\n          out.printf(\"%s %s %s %s %s \", Align.format(Align.format(i,\n              blkIDWidth2, Align.ZERO_PADDED), blkIDWidth, Align.LEFT), Align\n              .format(region.getOffset(), offsetWidth, Align.LEFT), Align\n              .format(region.getCompressedSize(), blkLenWidth, Align.LEFT),\n              Align.format(region.getRawSize(), rawSizeWidth, Align.LEFT),\n              Align.format(indexEntry.kvEntries, recordsWidth, Align.LEFT));\n          byte[] key \u003d indexEntry.key;\n          boolean asAscii \u003d true;\n          int sampleLen \u003d Math.min(maxKeySampleLen, key.length);\n          for (int j \u003d 0; j \u003c sampleLen; ++j) {\n            byte b \u003d key[j];\n            if ((b \u003c 32 \u0026\u0026 b !\u003d 9) || (b \u003d\u003d 127)) {\n              asAscii \u003d false;\n            }\n          }\n          if (!asAscii) {\n            out.print(\"0X\");\n            for (int j \u003d 0; j \u003c sampleLen; ++j) {\n              byte b \u003d key[i];\n              out.printf(\"%X\", b);\n            }\n          } else {\n            out.print(new String(key, 0, sampleLen));\n          }\n          if (sampleLen \u003c key.length) {\n            out.print(\"...\");\n          }\n          out.println();\n        }\n      }\n\n      out.println();\n      if (metaBlkCnt \u003e 0) {\n        String name \u003d \"Meta-Block\";\n        int maxNameLen \u003d 0;\n        Set\u003cMap.Entry\u003cString, MetaIndexEntry\u003e\u003e metaBlkEntrySet \u003d\n            reader.readerBCF.metaIndex.index.entrySet();\n        for (Iterator\u003cMap.Entry\u003cString, MetaIndexEntry\u003e\u003e it \u003d\n            metaBlkEntrySet.iterator(); it.hasNext();) {\n          Map.Entry\u003cString, MetaIndexEntry\u003e e \u003d it.next();\n          if (e.getKey().length() \u003e maxNameLen) {\n            maxNameLen \u003d e.getKey().length();\n          }\n        }\n        int nameWidth \u003d Math.max(name.length(), maxNameLen);\n        String offset \u003d \"Offset\";\n        int offsetWidth \u003d Align.calculateWidth(offset, length);\n        String blkLen \u003d \"Length\";\n        int blkLenWidth \u003d\n            Align.calculateWidth(blkLen, metaSize / metaBlkCnt * 10);\n        String rawSize \u003d \"Raw-Size\";\n        int rawSizeWidth \u003d\n            Align.calculateWidth(rawSize, metaSizeUncompressed / metaBlkCnt\n                * 10);\n        String compression \u003d \"Compression\";\n        int compressionWidth \u003d compression.length();\n        out.printf(\"%s %s %s %s %s\\n\", Align.format(name, nameWidth,\n            Align.CENTER), Align.format(offset, offsetWidth, Align.CENTER),\n            Align.format(blkLen, blkLenWidth, Align.CENTER), Align.format(\n                rawSize, rawSizeWidth, Align.CENTER), Align.format(compression,\n                compressionWidth, Align.LEFT));\n\n        for (Iterator\u003cMap.Entry\u003cString, MetaIndexEntry\u003e\u003e it \u003d\n            metaBlkEntrySet.iterator(); it.hasNext();) {\n          Map.Entry\u003cString, MetaIndexEntry\u003e e \u003d it.next();\n          String blkName \u003d e.getValue().getMetaName();\n          BlockRegion region \u003d e.getValue().getRegion();\n          String blkCompression \u003d\n              e.getValue().getCompressionAlgorithm().getName();\n          out.printf(\"%s %s %s %s %s\\n\", Align.format(blkName, nameWidth,\n              Align.LEFT), Align.format(region.getOffset(), offsetWidth,\n              Align.LEFT), Align.format(region.getCompressedSize(),\n              blkLenWidth, Align.LEFT), Align.format(region.getRawSize(),\n              rawSizeWidth, Align.LEFT), Align.format(blkCompression,\n              compressionWidth, Align.LEFT));\n        }\n      }\n    } finally {\n      IOUtils.cleanup(LOG, reader, fsdis);\n    }\n  }",
      "path": "src/java/org/apache/hadoop/io/file/tfile/TFileDumper.java"
    }
  }
}