{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSOutputSummer.java",
  "functionName": "writeChecksumChunks",
  "functionId": "writeChecksumChunks___b-byte[]__off-int__len-int",
  "sourceFilePath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FSOutputSummer.java",
  "functionStartLine": 209,
  "functionEndLine": 225,
  "numCommitsSeen": 21,
  "timeTaken": 2189,
  "changeHistory": [
    "892ade689f9bcce76daae8f66fc00a49bee8548e",
    "c94d594a57806dec515e2a2053a1221f8ce48cc4",
    "463aec11718e47d4aabb86a7a539cb973460aae6",
    "ab638e77b811d9592470f7d342cd11a66efbbf0d",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "0f6dfeeacbab65a31a33927a4eb84871d371fe52",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
    "5128a9a453d64bfe1ed978cf9ffed27985eeef36"
  ],
  "changeHistoryShort": {
    "892ade689f9bcce76daae8f66fc00a49bee8548e": "Ybodychange",
    "c94d594a57806dec515e2a2053a1221f8ce48cc4": "Ybodychange",
    "463aec11718e47d4aabb86a7a539cb973460aae6": "Ybodychange",
    "ab638e77b811d9592470f7d342cd11a66efbbf0d": "Ymultichange(Yrename,Yparameterchange,Ybodychange)",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "0f6dfeeacbab65a31a33927a4eb84871d371fe52": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yfilerename",
    "5128a9a453d64bfe1ed978cf9ffed27985eeef36": "Yintroduced"
  },
  "changeHistoryDetails": {
    "892ade689f9bcce76daae8f66fc00a49bee8548e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9080. Update htrace version to 4.0.1 (cmccabe)\n",
      "commitDate": "28/09/15 7:42 AM",
      "commitName": "892ade689f9bcce76daae8f66fc00a49bee8548e",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "22/04/15 1:48 PM",
      "commitNameOld": "e54a3e1f4f3ea4dbba14f3fab0c395a235763c54",
      "commitAuthorOld": "Jakob Homan",
      "daysBetweenCommits": 158.75,
      "commitsBetweenForRepo": 1144,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,15 +1,17 @@\n   private void writeChecksumChunks(byte b[], int off, int len)\n   throws IOException {\n     sum.calculateChunkedSums(b, off, len, checksum, 0);\n     TraceScope scope \u003d createWriteTraceScope();\n     try {\n       for (int i \u003d 0; i \u003c len; i +\u003d sum.getBytesPerChecksum()) {\n         int chunkLen \u003d Math.min(sum.getBytesPerChecksum(), len - i);\n         int ckOffset \u003d i / sum.getBytesPerChecksum() * getChecksumSize();\n         writeChunk(b, off + i, chunkLen, checksum, ckOffset,\n             getChecksumSize());\n       }\n     } finally {\n-      scope.close();\n+      if (scope !\u003d null) {\n+        scope.close();\n+      }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void writeChecksumChunks(byte b[], int off, int len)\n  throws IOException {\n    sum.calculateChunkedSums(b, off, len, checksum, 0);\n    TraceScope scope \u003d createWriteTraceScope();\n    try {\n      for (int i \u003d 0; i \u003c len; i +\u003d sum.getBytesPerChecksum()) {\n        int chunkLen \u003d Math.min(sum.getBytesPerChecksum(), len - i);\n        int ckOffset \u003d i / sum.getBytesPerChecksum() * getChecksumSize();\n        writeChunk(b, off + i, chunkLen, checksum, ckOffset,\n            getChecksumSize());\n      }\n    } finally {\n      if (scope !\u003d null) {\n        scope.close();\n      }\n    }\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FSOutputSummer.java",
      "extendedDetails": {}
    },
    "c94d594a57806dec515e2a2053a1221f8ce48cc4": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8026. Trace FSOutputSummer#writeChecksumChunks rather than DFSOutputStream#writeChunk (cmccabe)\n",
      "commitDate": "01/04/15 2:10 PM",
      "commitName": "c94d594a57806dec515e2a2053a1221f8ce48cc4",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "27/01/15 12:58 PM",
      "commitNameOld": "2848db814a98b83e7546f65a2751e56fb5b2dbe0",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 64.01,
      "commitsBetweenForRepo": 610,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,9 +1,15 @@\n   private void writeChecksumChunks(byte b[], int off, int len)\n   throws IOException {\n     sum.calculateChunkedSums(b, off, len, checksum, 0);\n-    for (int i \u003d 0; i \u003c len; i +\u003d sum.getBytesPerChecksum()) {\n-      int chunkLen \u003d Math.min(sum.getBytesPerChecksum(), len - i);\n-      int ckOffset \u003d i / sum.getBytesPerChecksum() * getChecksumSize();\n-      writeChunk(b, off + i, chunkLen, checksum, ckOffset, getChecksumSize());\n+    TraceScope scope \u003d createWriteTraceScope();\n+    try {\n+      for (int i \u003d 0; i \u003c len; i +\u003d sum.getBytesPerChecksum()) {\n+        int chunkLen \u003d Math.min(sum.getBytesPerChecksum(), len - i);\n+        int ckOffset \u003d i / sum.getBytesPerChecksum() * getChecksumSize();\n+        writeChunk(b, off + i, chunkLen, checksum, ckOffset,\n+            getChecksumSize());\n+      }\n+    } finally {\n+      scope.close();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void writeChecksumChunks(byte b[], int off, int len)\n  throws IOException {\n    sum.calculateChunkedSums(b, off, len, checksum, 0);\n    TraceScope scope \u003d createWriteTraceScope();\n    try {\n      for (int i \u003d 0; i \u003c len; i +\u003d sum.getBytesPerChecksum()) {\n        int chunkLen \u003d Math.min(sum.getBytesPerChecksum(), len - i);\n        int ckOffset \u003d i / sum.getBytesPerChecksum() * getChecksumSize();\n        writeChunk(b, off + i, chunkLen, checksum, ckOffset,\n            getChecksumSize());\n      }\n    } finally {\n      scope.close();\n    }\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FSOutputSummer.java",
      "extendedDetails": {}
    },
    "463aec11718e47d4aabb86a7a539cb973460aae6": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6934. Move checksum computation off the hot path when writing to RAM disk. Contributed by Chris Nauroth.\n",
      "commitDate": "27/10/14 9:38 AM",
      "commitName": "463aec11718e47d4aabb86a7a539cb973460aae6",
      "commitAuthor": "cnauroth",
      "commitDateOld": "28/08/14 4:44 PM",
      "commitNameOld": "ab638e77b811d9592470f7d342cd11a66efbbf0d",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 59.7,
      "commitsBetweenForRepo": 595,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,10 +1,9 @@\n   private void writeChecksumChunks(byte b[], int off, int len)\n   throws IOException {\n     sum.calculateChunkedSums(b, off, len, checksum, 0);\n     for (int i \u003d 0; i \u003c len; i +\u003d sum.getBytesPerChecksum()) {\n       int chunkLen \u003d Math.min(sum.getBytesPerChecksum(), len - i);\n-      int ckOffset \u003d i / sum.getBytesPerChecksum() * sum.getChecksumSize();\n-      writeChunk(b, off + i, chunkLen, checksum, ckOffset,\n-          sum.getChecksumSize());\n+      int ckOffset \u003d i / sum.getBytesPerChecksum() * getChecksumSize();\n+      writeChunk(b, off + i, chunkLen, checksum, ckOffset, getChecksumSize());\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void writeChecksumChunks(byte b[], int off, int len)\n  throws IOException {\n    sum.calculateChunkedSums(b, off, len, checksum, 0);\n    for (int i \u003d 0; i \u003c len; i +\u003d sum.getBytesPerChecksum()) {\n      int chunkLen \u003d Math.min(sum.getBytesPerChecksum(), len - i);\n      int ckOffset \u003d i / sum.getBytesPerChecksum() * getChecksumSize();\n      writeChunk(b, off + i, chunkLen, checksum, ckOffset, getChecksumSize());\n    }\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FSOutputSummer.java",
      "extendedDetails": {}
    },
    "ab638e77b811d9592470f7d342cd11a66efbbf0d": {
      "type": "Ymultichange(Yrename,Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-6865. Byte array native checksumming on client side. Contributed by James Thomas.\n",
      "commitDate": "28/08/14 4:44 PM",
      "commitName": "ab638e77b811d9592470f7d342cd11a66efbbf0d",
      "commitAuthor": "Todd Lipcon",
      "subchanges": [
        {
          "type": "Yrename",
          "commitMessage": "HDFS-6865. Byte array native checksumming on client side. Contributed by James Thomas.\n",
          "commitDate": "28/08/14 4:44 PM",
          "commitName": "ab638e77b811d9592470f7d342cd11a66efbbf0d",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "21/11/13 6:05 AM",
          "commitNameOld": "709b74e51508dde79f4f81381d85658b5b47b3ff",
          "commitAuthorOld": "Uma Maheswara Rao G",
          "daysBetweenCommits": 280.4,
          "commitsBetweenForRepo": 1957,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,9 +1,10 @@\n-  private void writeChecksumChunk(byte b[], int off, int len, boolean keep)\n+  private void writeChecksumChunks(byte b[], int off, int len)\n   throws IOException {\n-    int tempChecksum \u003d (int)sum.getValue();\n-    if (!keep) {\n-      sum.reset();\n+    sum.calculateChunkedSums(b, off, len, checksum, 0);\n+    for (int i \u003d 0; i \u003c len; i +\u003d sum.getBytesPerChecksum()) {\n+      int chunkLen \u003d Math.min(sum.getBytesPerChecksum(), len - i);\n+      int ckOffset \u003d i / sum.getBytesPerChecksum() * sum.getChecksumSize();\n+      writeChunk(b, off + i, chunkLen, checksum, ckOffset,\n+          sum.getChecksumSize());\n     }\n-    int2byte(tempChecksum, checksum);\n-    writeChunk(b, off, len, checksum);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void writeChecksumChunks(byte b[], int off, int len)\n  throws IOException {\n    sum.calculateChunkedSums(b, off, len, checksum, 0);\n    for (int i \u003d 0; i \u003c len; i +\u003d sum.getBytesPerChecksum()) {\n      int chunkLen \u003d Math.min(sum.getBytesPerChecksum(), len - i);\n      int ckOffset \u003d i / sum.getBytesPerChecksum() * sum.getChecksumSize();\n      writeChunk(b, off + i, chunkLen, checksum, ckOffset,\n          sum.getChecksumSize());\n    }\n  }",
          "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FSOutputSummer.java",
          "extendedDetails": {
            "oldValue": "writeChecksumChunk",
            "newValue": "writeChecksumChunks"
          }
        },
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-6865. Byte array native checksumming on client side. Contributed by James Thomas.\n",
          "commitDate": "28/08/14 4:44 PM",
          "commitName": "ab638e77b811d9592470f7d342cd11a66efbbf0d",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "21/11/13 6:05 AM",
          "commitNameOld": "709b74e51508dde79f4f81381d85658b5b47b3ff",
          "commitAuthorOld": "Uma Maheswara Rao G",
          "daysBetweenCommits": 280.4,
          "commitsBetweenForRepo": 1957,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,9 +1,10 @@\n-  private void writeChecksumChunk(byte b[], int off, int len, boolean keep)\n+  private void writeChecksumChunks(byte b[], int off, int len)\n   throws IOException {\n-    int tempChecksum \u003d (int)sum.getValue();\n-    if (!keep) {\n-      sum.reset();\n+    sum.calculateChunkedSums(b, off, len, checksum, 0);\n+    for (int i \u003d 0; i \u003c len; i +\u003d sum.getBytesPerChecksum()) {\n+      int chunkLen \u003d Math.min(sum.getBytesPerChecksum(), len - i);\n+      int ckOffset \u003d i / sum.getBytesPerChecksum() * sum.getChecksumSize();\n+      writeChunk(b, off + i, chunkLen, checksum, ckOffset,\n+          sum.getChecksumSize());\n     }\n-    int2byte(tempChecksum, checksum);\n-    writeChunk(b, off, len, checksum);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void writeChecksumChunks(byte b[], int off, int len)\n  throws IOException {\n    sum.calculateChunkedSums(b, off, len, checksum, 0);\n    for (int i \u003d 0; i \u003c len; i +\u003d sum.getBytesPerChecksum()) {\n      int chunkLen \u003d Math.min(sum.getBytesPerChecksum(), len - i);\n      int ckOffset \u003d i / sum.getBytesPerChecksum() * sum.getChecksumSize();\n      writeChunk(b, off + i, chunkLen, checksum, ckOffset,\n          sum.getChecksumSize());\n    }\n  }",
          "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FSOutputSummer.java",
          "extendedDetails": {
            "oldValue": "[b-byte[], off-int, len-int, keep-boolean]",
            "newValue": "[b-byte[], off-int, len-int]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-6865. Byte array native checksumming on client side. Contributed by James Thomas.\n",
          "commitDate": "28/08/14 4:44 PM",
          "commitName": "ab638e77b811d9592470f7d342cd11a66efbbf0d",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "21/11/13 6:05 AM",
          "commitNameOld": "709b74e51508dde79f4f81381d85658b5b47b3ff",
          "commitAuthorOld": "Uma Maheswara Rao G",
          "daysBetweenCommits": 280.4,
          "commitsBetweenForRepo": 1957,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,9 +1,10 @@\n-  private void writeChecksumChunk(byte b[], int off, int len, boolean keep)\n+  private void writeChecksumChunks(byte b[], int off, int len)\n   throws IOException {\n-    int tempChecksum \u003d (int)sum.getValue();\n-    if (!keep) {\n-      sum.reset();\n+    sum.calculateChunkedSums(b, off, len, checksum, 0);\n+    for (int i \u003d 0; i \u003c len; i +\u003d sum.getBytesPerChecksum()) {\n+      int chunkLen \u003d Math.min(sum.getBytesPerChecksum(), len - i);\n+      int ckOffset \u003d i / sum.getBytesPerChecksum() * sum.getChecksumSize();\n+      writeChunk(b, off + i, chunkLen, checksum, ckOffset,\n+          sum.getChecksumSize());\n     }\n-    int2byte(tempChecksum, checksum);\n-    writeChunk(b, off, len, checksum);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void writeChecksumChunks(byte b[], int off, int len)\n  throws IOException {\n    sum.calculateChunkedSums(b, off, len, checksum, 0);\n    for (int i \u003d 0; i \u003c len; i +\u003d sum.getBytesPerChecksum()) {\n      int chunkLen \u003d Math.min(sum.getBytesPerChecksum(), len - i);\n      int ckOffset \u003d i / sum.getBytesPerChecksum() * sum.getChecksumSize();\n      writeChunk(b, off + i, chunkLen, checksum, ckOffset,\n          sum.getChecksumSize());\n    }\n  }",
          "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FSOutputSummer.java",
          "extendedDetails": {}
        }
      ]
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private void writeChecksumChunk(byte b[], int off, int len, boolean keep)\n  throws IOException {\n    int tempChecksum \u003d (int)sum.getValue();\n    if (!keep) {\n      sum.reset();\n    }\n    int2byte(tempChecksum, checksum);\n    writeChunk(b, off, len, checksum);\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FSOutputSummer.java",
      "extendedDetails": {
        "oldPath": "hadoop-common/src/main/java/org/apache/hadoop/fs/FSOutputSummer.java",
        "newPath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FSOutputSummer.java"
      }
    },
    "0f6dfeeacbab65a31a33927a4eb84871d371fe52": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-6671. Use maven for hadoop common builds. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1153184 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/08/11 9:37 AM",
      "commitName": "0f6dfeeacbab65a31a33927a4eb84871d371fe52",
      "commitAuthor": "Thomas White",
      "commitDateOld": "01/08/11 3:53 PM",
      "commitNameOld": "9bac807cedbcff34e1a144fb475eff267e5ed86d",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.74,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private void writeChecksumChunk(byte b[], int off, int len, boolean keep)\n  throws IOException {\n    int tempChecksum \u003d (int)sum.getValue();\n    if (!keep) {\n      sum.reset();\n    }\n    int2byte(tempChecksum, checksum);\n    writeChunk(b, off, len, checksum);\n  }",
      "path": "hadoop-common/src/main/java/org/apache/hadoop/fs/FSOutputSummer.java",
      "extendedDetails": {
        "oldPath": "common/src/java/org/apache/hadoop/fs/FSOutputSummer.java",
        "newPath": "hadoop-common/src/main/java/org/apache/hadoop/fs/FSOutputSummer.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "11/06/11 9:13 PM",
      "commitNameOld": "a285fb5effe9ba3be4ec5f942afaf5ddd1186151",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 0.74,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private void writeChecksumChunk(byte b[], int off, int len, boolean keep)\n  throws IOException {\n    int tempChecksum \u003d (int)sum.getValue();\n    if (!keep) {\n      sum.reset();\n    }\n    int2byte(tempChecksum, checksum);\n    writeChunk(b, off, len, checksum);\n  }",
      "path": "common/src/java/org/apache/hadoop/fs/FSOutputSummer.java",
      "extendedDetails": {
        "oldPath": "src/java/org/apache/hadoop/fs/FSOutputSummer.java",
        "newPath": "common/src/java/org/apache/hadoop/fs/FSOutputSummer.java"
      }
    },
    "5128a9a453d64bfe1ed978cf9ffed27985eeef36": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-4687 Moving src directories on branch\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/core/branches/HADOOP-4687/core@776174 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/05/09 9:20 PM",
      "commitName": "5128a9a453d64bfe1ed978cf9ffed27985eeef36",
      "commitAuthor": "Owen O\u0027Malley",
      "diff": "@@ -0,0 +1,9 @@\n+  private void writeChecksumChunk(byte b[], int off, int len, boolean keep)\n+  throws IOException {\n+    int tempChecksum \u003d (int)sum.getValue();\n+    if (!keep) {\n+      sum.reset();\n+    }\n+    int2byte(tempChecksum, checksum);\n+    writeChunk(b, off, len, checksum);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void writeChecksumChunk(byte b[], int off, int len, boolean keep)\n  throws IOException {\n    int tempChecksum \u003d (int)sum.getValue();\n    if (!keep) {\n      sum.reset();\n    }\n    int2byte(tempChecksum, checksum);\n    writeChunk(b, off, len, checksum);\n  }",
      "path": "src/java/org/apache/hadoop/fs/FSOutputSummer.java"
    }
  }
}