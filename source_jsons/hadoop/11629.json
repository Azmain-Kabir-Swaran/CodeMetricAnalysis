{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockPoolSlice.java",
  "functionName": "addReplicaToReplicasMap",
  "functionId": "addReplicaToReplicasMap___block-Block__volumeMap-ReplicaMap__lazyWriteReplicaMap-RamDiskReplicaTracker(modifiers-final)__isFinalized-boolean",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/BlockPoolSlice.java",
  "functionStartLine": 580,
  "functionEndLine": 663,
  "numCommitsSeen": 58,
  "timeTaken": 4008,
  "changeHistory": [
    "5689355783de005ebc604f4403dc5129a286bfca",
    "6ba9587d370fbf39c129c08c00ebbb894ccc1389",
    "86c9862bec0248d671e657aa56094a2919b8ac14",
    "342c9572bf6a623287f34c5cc0bc3be6038c191a",
    "c07f7fa8ff752436726239d938e0461236839acf",
    "e453989a5722e653bd97e3e54f9bbdffc9454fba",
    "fc1031af749435dc95efea6745b1b2300ce29446"
  ],
  "changeHistoryShort": {
    "5689355783de005ebc604f4403dc5129a286bfca": "Ybodychange",
    "6ba9587d370fbf39c129c08c00ebbb894ccc1389": "Ybodychange",
    "86c9862bec0248d671e657aa56094a2919b8ac14": "Ybodychange",
    "342c9572bf6a623287f34c5cc0bc3be6038c191a": "Ybodychange",
    "c07f7fa8ff752436726239d938e0461236839acf": "Ybodychange",
    "e453989a5722e653bd97e3e54f9bbdffc9454fba": "Ybodychange",
    "fc1031af749435dc95efea6745b1b2300ce29446": "Yintroduced"
  },
  "changeHistoryDetails": {
    "5689355783de005ebc604f4403dc5129a286bfca": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13768. Adding replicas to volume map makes DataNode start slowly. Contributed by Surendra Singh Lilhore.\n",
      "commitDate": "01/10/18 6:43 PM",
      "commitName": "5689355783de005ebc604f4403dc5129a286bfca",
      "commitAuthor": "Yiqun Lin",
      "commitDateOld": "06/09/18 2:48 PM",
      "commitNameOld": "eca1a4bfe952fc184fe90dde50bac9b0e5293568",
      "commitAuthorOld": "Giovanni Matteo Fumarola",
      "daysBetweenCommits": 25.16,
      "commitsBetweenForRepo": 264,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,84 +1,84 @@\n   private void addReplicaToReplicasMap(Block block, ReplicaMap volumeMap,\n       final RamDiskReplicaTracker lazyWriteReplicaMap,boolean isFinalized)\n       throws IOException {\n     ReplicaInfo newReplica \u003d null;\n     long blockId \u003d block.getBlockId();\n     long genStamp \u003d block.getGenerationStamp();\n     if (isFinalized) {\n       newReplica \u003d new ReplicaBuilder(ReplicaState.FINALIZED)\n           .setBlockId(blockId)\n           .setLength(block.getNumBytes())\n           .setGenerationStamp(genStamp)\n           .setFsVolume(volume)\n           .setDirectoryToUse(DatanodeUtil.idToBlockDir(finalizedDir, blockId))\n           .build();\n     } else {\n       File file \u003d new File(rbwDir, block.getBlockName());\n       boolean loadRwr \u003d true;\n       File restartMeta \u003d new File(file.getParent()  +\n           File.pathSeparator + \".\" + file.getName() + \".restart\");\n       Scanner sc \u003d null;\n       try {\n         sc \u003d new Scanner(restartMeta, \"UTF-8\");\n         // The restart meta file exists\n         if (sc.hasNextLong() \u0026\u0026 (sc.nextLong() \u003e timer.now())) {\n           // It didn\u0027t expire. Load the replica as a RBW.\n           // We don\u0027t know the expected block length, so just use 0\n           // and don\u0027t reserve any more space for writes.\n           newReplica \u003d new ReplicaBuilder(ReplicaState.RBW)\n               .setBlockId(blockId)\n               .setLength(validateIntegrityAndSetLength(file, genStamp))\n               .setGenerationStamp(genStamp)\n               .setFsVolume(volume)\n               .setDirectoryToUse(file.getParentFile())\n               .setWriterThread(null)\n               .setBytesToReserve(0)\n               .build();\n           loadRwr \u003d false;\n         }\n         sc.close();\n         if (!fileIoProvider.delete(volume, restartMeta)) {\n           FsDatasetImpl.LOG.warn(\"Failed to delete restart meta file: \" +\n               restartMeta.getPath());\n         }\n       } catch (FileNotFoundException fnfe) {\n         // nothing to do hereFile dir \u003d\n       } finally {\n         if (sc !\u003d null) {\n           sc.close();\n         }\n       }\n       // Restart meta doesn\u0027t exist or expired.\n       if (loadRwr) {\n         ReplicaBuilder builder \u003d new ReplicaBuilder(ReplicaState.RWR)\n             .setBlockId(blockId)\n             .setLength(validateIntegrityAndSetLength(file, genStamp))\n             .setGenerationStamp(genStamp)\n             .setFsVolume(volume)\n             .setDirectoryToUse(file.getParentFile());\n         newReplica \u003d builder.build();\n       }\n     }\n \n-    ReplicaInfo oldReplica \u003d volumeMap.get(bpid, newReplica.getBlockId());\n-    if (oldReplica \u003d\u003d null) {\n-      volumeMap.add(bpid, newReplica);\n-    } else {\n+    ReplicaInfo tmpReplicaInfo \u003d volumeMap.addAndGet(bpid, newReplica);\n+    ReplicaInfo oldReplica \u003d (tmpReplicaInfo \u003d\u003d newReplica) ? null\n+        : tmpReplicaInfo;\n+    if (oldReplica !\u003d null) {\n       // We have multiple replicas of the same block so decide which one\n       // to keep.\n       newReplica \u003d resolveDuplicateReplicas(newReplica, oldReplica, volumeMap);\n     }\n \n     // If we are retaining a replica on transient storage make sure\n     // it is in the lazyWriteReplicaMap so it can be persisted\n     // eventually.\n     if (newReplica.getVolume().isTransientStorage()) {\n       lazyWriteReplicaMap.addReplica(bpid, blockId,\n           (FsVolumeImpl) newReplica.getVolume(), 0);\n     } else {\n       lazyWriteReplicaMap.discardReplica(bpid, blockId, false);\n     }\n     if (oldReplica \u003d\u003d null) {\n       incrNumBlocks();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void addReplicaToReplicasMap(Block block, ReplicaMap volumeMap,\n      final RamDiskReplicaTracker lazyWriteReplicaMap,boolean isFinalized)\n      throws IOException {\n    ReplicaInfo newReplica \u003d null;\n    long blockId \u003d block.getBlockId();\n    long genStamp \u003d block.getGenerationStamp();\n    if (isFinalized) {\n      newReplica \u003d new ReplicaBuilder(ReplicaState.FINALIZED)\n          .setBlockId(blockId)\n          .setLength(block.getNumBytes())\n          .setGenerationStamp(genStamp)\n          .setFsVolume(volume)\n          .setDirectoryToUse(DatanodeUtil.idToBlockDir(finalizedDir, blockId))\n          .build();\n    } else {\n      File file \u003d new File(rbwDir, block.getBlockName());\n      boolean loadRwr \u003d true;\n      File restartMeta \u003d new File(file.getParent()  +\n          File.pathSeparator + \".\" + file.getName() + \".restart\");\n      Scanner sc \u003d null;\n      try {\n        sc \u003d new Scanner(restartMeta, \"UTF-8\");\n        // The restart meta file exists\n        if (sc.hasNextLong() \u0026\u0026 (sc.nextLong() \u003e timer.now())) {\n          // It didn\u0027t expire. Load the replica as a RBW.\n          // We don\u0027t know the expected block length, so just use 0\n          // and don\u0027t reserve any more space for writes.\n          newReplica \u003d new ReplicaBuilder(ReplicaState.RBW)\n              .setBlockId(blockId)\n              .setLength(validateIntegrityAndSetLength(file, genStamp))\n              .setGenerationStamp(genStamp)\n              .setFsVolume(volume)\n              .setDirectoryToUse(file.getParentFile())\n              .setWriterThread(null)\n              .setBytesToReserve(0)\n              .build();\n          loadRwr \u003d false;\n        }\n        sc.close();\n        if (!fileIoProvider.delete(volume, restartMeta)) {\n          FsDatasetImpl.LOG.warn(\"Failed to delete restart meta file: \" +\n              restartMeta.getPath());\n        }\n      } catch (FileNotFoundException fnfe) {\n        // nothing to do hereFile dir \u003d\n      } finally {\n        if (sc !\u003d null) {\n          sc.close();\n        }\n      }\n      // Restart meta doesn\u0027t exist or expired.\n      if (loadRwr) {\n        ReplicaBuilder builder \u003d new ReplicaBuilder(ReplicaState.RWR)\n            .setBlockId(blockId)\n            .setLength(validateIntegrityAndSetLength(file, genStamp))\n            .setGenerationStamp(genStamp)\n            .setFsVolume(volume)\n            .setDirectoryToUse(file.getParentFile());\n        newReplica \u003d builder.build();\n      }\n    }\n\n    ReplicaInfo tmpReplicaInfo \u003d volumeMap.addAndGet(bpid, newReplica);\n    ReplicaInfo oldReplica \u003d (tmpReplicaInfo \u003d\u003d newReplica) ? null\n        : tmpReplicaInfo;\n    if (oldReplica !\u003d null) {\n      // We have multiple replicas of the same block so decide which one\n      // to keep.\n      newReplica \u003d resolveDuplicateReplicas(newReplica, oldReplica, volumeMap);\n    }\n\n    // If we are retaining a replica on transient storage make sure\n    // it is in the lazyWriteReplicaMap so it can be persisted\n    // eventually.\n    if (newReplica.getVolume().isTransientStorage()) {\n      lazyWriteReplicaMap.addReplica(bpid, blockId,\n          (FsVolumeImpl) newReplica.getVolume(), 0);\n    } else {\n      lazyWriteReplicaMap.discardReplica(bpid, blockId, false);\n    }\n    if (oldReplica \u003d\u003d null) {\n      incrNumBlocks();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/BlockPoolSlice.java",
      "extendedDetails": {}
    },
    "6ba9587d370fbf39c129c08c00ebbb894ccc1389": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10958. Add instrumentation hooks around Datanode disk IO.\n",
      "commitDate": "14/12/16 11:18 AM",
      "commitName": "6ba9587d370fbf39c129c08c00ebbb894ccc1389",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "06/12/16 11:05 AM",
      "commitNameOld": "df983b524ab68ea0c70cee9033bfff2d28052cbf",
      "commitAuthorOld": "Xiaoyu Yao",
      "daysBetweenCommits": 8.01,
      "commitsBetweenForRepo": 51,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,84 +1,84 @@\n   private void addReplicaToReplicasMap(Block block, ReplicaMap volumeMap,\n       final RamDiskReplicaTracker lazyWriteReplicaMap,boolean isFinalized)\n       throws IOException {\n     ReplicaInfo newReplica \u003d null;\n     long blockId \u003d block.getBlockId();\n     long genStamp \u003d block.getGenerationStamp();\n     if (isFinalized) {\n       newReplica \u003d new ReplicaBuilder(ReplicaState.FINALIZED)\n           .setBlockId(blockId)\n           .setLength(block.getNumBytes())\n           .setGenerationStamp(genStamp)\n           .setFsVolume(volume)\n           .setDirectoryToUse(DatanodeUtil.idToBlockDir(finalizedDir, blockId))\n           .build();\n     } else {\n       File file \u003d new File(rbwDir, block.getBlockName());\n       boolean loadRwr \u003d true;\n       File restartMeta \u003d new File(file.getParent()  +\n           File.pathSeparator + \".\" + file.getName() + \".restart\");\n       Scanner sc \u003d null;\n       try {\n         sc \u003d new Scanner(restartMeta, \"UTF-8\");\n         // The restart meta file exists\n         if (sc.hasNextLong() \u0026\u0026 (sc.nextLong() \u003e timer.now())) {\n           // It didn\u0027t expire. Load the replica as a RBW.\n           // We don\u0027t know the expected block length, so just use 0\n           // and don\u0027t reserve any more space for writes.\n           newReplica \u003d new ReplicaBuilder(ReplicaState.RBW)\n               .setBlockId(blockId)\n               .setLength(validateIntegrityAndSetLength(file, genStamp))\n               .setGenerationStamp(genStamp)\n               .setFsVolume(volume)\n               .setDirectoryToUse(file.getParentFile())\n               .setWriterThread(null)\n               .setBytesToReserve(0)\n               .build();\n           loadRwr \u003d false;\n         }\n         sc.close();\n-        if (!restartMeta.delete()) {\n+        if (!fileIoProvider.delete(volume, restartMeta)) {\n           FsDatasetImpl.LOG.warn(\"Failed to delete restart meta file: \" +\n               restartMeta.getPath());\n         }\n       } catch (FileNotFoundException fnfe) {\n         // nothing to do hereFile dir \u003d\n       } finally {\n         if (sc !\u003d null) {\n           sc.close();\n         }\n       }\n       // Restart meta doesn\u0027t exist or expired.\n       if (loadRwr) {\n         ReplicaBuilder builder \u003d new ReplicaBuilder(ReplicaState.RWR)\n             .setBlockId(blockId)\n             .setLength(validateIntegrityAndSetLength(file, genStamp))\n             .setGenerationStamp(genStamp)\n             .setFsVolume(volume)\n             .setDirectoryToUse(file.getParentFile());\n         newReplica \u003d builder.build();\n       }\n     }\n \n     ReplicaInfo oldReplica \u003d volumeMap.get(bpid, newReplica.getBlockId());\n     if (oldReplica \u003d\u003d null) {\n       volumeMap.add(bpid, newReplica);\n     } else {\n       // We have multiple replicas of the same block so decide which one\n       // to keep.\n       newReplica \u003d resolveDuplicateReplicas(newReplica, oldReplica, volumeMap);\n     }\n \n     // If we are retaining a replica on transient storage make sure\n     // it is in the lazyWriteReplicaMap so it can be persisted\n     // eventually.\n     if (newReplica.getVolume().isTransientStorage()) {\n       lazyWriteReplicaMap.addReplica(bpid, blockId,\n           (FsVolumeImpl) newReplica.getVolume(), 0);\n     } else {\n       lazyWriteReplicaMap.discardReplica(bpid, blockId, false);\n     }\n     if (oldReplica \u003d\u003d null) {\n       incrNumBlocks();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void addReplicaToReplicasMap(Block block, ReplicaMap volumeMap,\n      final RamDiskReplicaTracker lazyWriteReplicaMap,boolean isFinalized)\n      throws IOException {\n    ReplicaInfo newReplica \u003d null;\n    long blockId \u003d block.getBlockId();\n    long genStamp \u003d block.getGenerationStamp();\n    if (isFinalized) {\n      newReplica \u003d new ReplicaBuilder(ReplicaState.FINALIZED)\n          .setBlockId(blockId)\n          .setLength(block.getNumBytes())\n          .setGenerationStamp(genStamp)\n          .setFsVolume(volume)\n          .setDirectoryToUse(DatanodeUtil.idToBlockDir(finalizedDir, blockId))\n          .build();\n    } else {\n      File file \u003d new File(rbwDir, block.getBlockName());\n      boolean loadRwr \u003d true;\n      File restartMeta \u003d new File(file.getParent()  +\n          File.pathSeparator + \".\" + file.getName() + \".restart\");\n      Scanner sc \u003d null;\n      try {\n        sc \u003d new Scanner(restartMeta, \"UTF-8\");\n        // The restart meta file exists\n        if (sc.hasNextLong() \u0026\u0026 (sc.nextLong() \u003e timer.now())) {\n          // It didn\u0027t expire. Load the replica as a RBW.\n          // We don\u0027t know the expected block length, so just use 0\n          // and don\u0027t reserve any more space for writes.\n          newReplica \u003d new ReplicaBuilder(ReplicaState.RBW)\n              .setBlockId(blockId)\n              .setLength(validateIntegrityAndSetLength(file, genStamp))\n              .setGenerationStamp(genStamp)\n              .setFsVolume(volume)\n              .setDirectoryToUse(file.getParentFile())\n              .setWriterThread(null)\n              .setBytesToReserve(0)\n              .build();\n          loadRwr \u003d false;\n        }\n        sc.close();\n        if (!fileIoProvider.delete(volume, restartMeta)) {\n          FsDatasetImpl.LOG.warn(\"Failed to delete restart meta file: \" +\n              restartMeta.getPath());\n        }\n      } catch (FileNotFoundException fnfe) {\n        // nothing to do hereFile dir \u003d\n      } finally {\n        if (sc !\u003d null) {\n          sc.close();\n        }\n      }\n      // Restart meta doesn\u0027t exist or expired.\n      if (loadRwr) {\n        ReplicaBuilder builder \u003d new ReplicaBuilder(ReplicaState.RWR)\n            .setBlockId(blockId)\n            .setLength(validateIntegrityAndSetLength(file, genStamp))\n            .setGenerationStamp(genStamp)\n            .setFsVolume(volume)\n            .setDirectoryToUse(file.getParentFile());\n        newReplica \u003d builder.build();\n      }\n    }\n\n    ReplicaInfo oldReplica \u003d volumeMap.get(bpid, newReplica.getBlockId());\n    if (oldReplica \u003d\u003d null) {\n      volumeMap.add(bpid, newReplica);\n    } else {\n      // We have multiple replicas of the same block so decide which one\n      // to keep.\n      newReplica \u003d resolveDuplicateReplicas(newReplica, oldReplica, volumeMap);\n    }\n\n    // If we are retaining a replica on transient storage make sure\n    // it is in the lazyWriteReplicaMap so it can be persisted\n    // eventually.\n    if (newReplica.getVolume().isTransientStorage()) {\n      lazyWriteReplicaMap.addReplica(bpid, blockId,\n          (FsVolumeImpl) newReplica.getVolume(), 0);\n    } else {\n      lazyWriteReplicaMap.discardReplica(bpid, blockId, false);\n    }\n    if (oldReplica \u003d\u003d null) {\n      incrNumBlocks();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/BlockPoolSlice.java",
      "extendedDetails": {}
    },
    "86c9862bec0248d671e657aa56094a2919b8ac14": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10636. Modify ReplicaInfo to remove the assumption that replica metadata and data are stored in java.io.File. (Virajith Jalaparti via lei)\n",
      "commitDate": "13/09/16 12:54 PM",
      "commitName": "86c9862bec0248d671e657aa56094a2919b8ac14",
      "commitAuthor": "Lei Xu",
      "commitDateOld": "20/04/16 1:39 PM",
      "commitNameOld": "63ac2db59af2b50e74dc892cae1dbc4d2e061423",
      "commitAuthorOld": "Chris Nauroth",
      "daysBetweenCommits": 145.97,
      "commitsBetweenForRepo": 1086,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,70 +1,84 @@\n   private void addReplicaToReplicasMap(Block block, ReplicaMap volumeMap,\n       final RamDiskReplicaTracker lazyWriteReplicaMap,boolean isFinalized)\n       throws IOException {\n     ReplicaInfo newReplica \u003d null;\n     long blockId \u003d block.getBlockId();\n     long genStamp \u003d block.getGenerationStamp();\n     if (isFinalized) {\n-      newReplica \u003d new FinalizedReplica(blockId,\n-          block.getNumBytes(), genStamp, volume, DatanodeUtil\n-          .idToBlockDir(finalizedDir, blockId));\n+      newReplica \u003d new ReplicaBuilder(ReplicaState.FINALIZED)\n+          .setBlockId(blockId)\n+          .setLength(block.getNumBytes())\n+          .setGenerationStamp(genStamp)\n+          .setFsVolume(volume)\n+          .setDirectoryToUse(DatanodeUtil.idToBlockDir(finalizedDir, blockId))\n+          .build();\n     } else {\n       File file \u003d new File(rbwDir, block.getBlockName());\n       boolean loadRwr \u003d true;\n       File restartMeta \u003d new File(file.getParent()  +\n           File.pathSeparator + \".\" + file.getName() + \".restart\");\n       Scanner sc \u003d null;\n       try {\n         sc \u003d new Scanner(restartMeta, \"UTF-8\");\n         // The restart meta file exists\n         if (sc.hasNextLong() \u0026\u0026 (sc.nextLong() \u003e timer.now())) {\n           // It didn\u0027t expire. Load the replica as a RBW.\n           // We don\u0027t know the expected block length, so just use 0\n           // and don\u0027t reserve any more space for writes.\n-          newReplica \u003d new ReplicaBeingWritten(blockId,\n-              validateIntegrityAndSetLength(file, genStamp),\n-              genStamp, volume, file.getParentFile(), null, 0);\n+          newReplica \u003d new ReplicaBuilder(ReplicaState.RBW)\n+              .setBlockId(blockId)\n+              .setLength(validateIntegrityAndSetLength(file, genStamp))\n+              .setGenerationStamp(genStamp)\n+              .setFsVolume(volume)\n+              .setDirectoryToUse(file.getParentFile())\n+              .setWriterThread(null)\n+              .setBytesToReserve(0)\n+              .build();\n           loadRwr \u003d false;\n         }\n         sc.close();\n         if (!restartMeta.delete()) {\n           FsDatasetImpl.LOG.warn(\"Failed to delete restart meta file: \" +\n               restartMeta.getPath());\n         }\n       } catch (FileNotFoundException fnfe) {\n         // nothing to do hereFile dir \u003d\n       } finally {\n         if (sc !\u003d null) {\n           sc.close();\n         }\n       }\n       // Restart meta doesn\u0027t exist or expired.\n       if (loadRwr) {\n-        newReplica \u003d new ReplicaWaitingToBeRecovered(blockId,\n-            validateIntegrityAndSetLength(file, genStamp),\n-            genStamp, volume, file.getParentFile());\n+        ReplicaBuilder builder \u003d new ReplicaBuilder(ReplicaState.RWR)\n+            .setBlockId(blockId)\n+            .setLength(validateIntegrityAndSetLength(file, genStamp))\n+            .setGenerationStamp(genStamp)\n+            .setFsVolume(volume)\n+            .setDirectoryToUse(file.getParentFile());\n+        newReplica \u003d builder.build();\n       }\n     }\n \n     ReplicaInfo oldReplica \u003d volumeMap.get(bpid, newReplica.getBlockId());\n     if (oldReplica \u003d\u003d null) {\n       volumeMap.add(bpid, newReplica);\n     } else {\n       // We have multiple replicas of the same block so decide which one\n       // to keep.\n       newReplica \u003d resolveDuplicateReplicas(newReplica, oldReplica, volumeMap);\n     }\n \n     // If we are retaining a replica on transient storage make sure\n     // it is in the lazyWriteReplicaMap so it can be persisted\n     // eventually.\n     if (newReplica.getVolume().isTransientStorage()) {\n       lazyWriteReplicaMap.addReplica(bpid, blockId,\n           (FsVolumeImpl) newReplica.getVolume(), 0);\n     } else {\n       lazyWriteReplicaMap.discardReplica(bpid, blockId, false);\n     }\n     if (oldReplica \u003d\u003d null) {\n       incrNumBlocks();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void addReplicaToReplicasMap(Block block, ReplicaMap volumeMap,\n      final RamDiskReplicaTracker lazyWriteReplicaMap,boolean isFinalized)\n      throws IOException {\n    ReplicaInfo newReplica \u003d null;\n    long blockId \u003d block.getBlockId();\n    long genStamp \u003d block.getGenerationStamp();\n    if (isFinalized) {\n      newReplica \u003d new ReplicaBuilder(ReplicaState.FINALIZED)\n          .setBlockId(blockId)\n          .setLength(block.getNumBytes())\n          .setGenerationStamp(genStamp)\n          .setFsVolume(volume)\n          .setDirectoryToUse(DatanodeUtil.idToBlockDir(finalizedDir, blockId))\n          .build();\n    } else {\n      File file \u003d new File(rbwDir, block.getBlockName());\n      boolean loadRwr \u003d true;\n      File restartMeta \u003d new File(file.getParent()  +\n          File.pathSeparator + \".\" + file.getName() + \".restart\");\n      Scanner sc \u003d null;\n      try {\n        sc \u003d new Scanner(restartMeta, \"UTF-8\");\n        // The restart meta file exists\n        if (sc.hasNextLong() \u0026\u0026 (sc.nextLong() \u003e timer.now())) {\n          // It didn\u0027t expire. Load the replica as a RBW.\n          // We don\u0027t know the expected block length, so just use 0\n          // and don\u0027t reserve any more space for writes.\n          newReplica \u003d new ReplicaBuilder(ReplicaState.RBW)\n              .setBlockId(blockId)\n              .setLength(validateIntegrityAndSetLength(file, genStamp))\n              .setGenerationStamp(genStamp)\n              .setFsVolume(volume)\n              .setDirectoryToUse(file.getParentFile())\n              .setWriterThread(null)\n              .setBytesToReserve(0)\n              .build();\n          loadRwr \u003d false;\n        }\n        sc.close();\n        if (!restartMeta.delete()) {\n          FsDatasetImpl.LOG.warn(\"Failed to delete restart meta file: \" +\n              restartMeta.getPath());\n        }\n      } catch (FileNotFoundException fnfe) {\n        // nothing to do hereFile dir \u003d\n      } finally {\n        if (sc !\u003d null) {\n          sc.close();\n        }\n      }\n      // Restart meta doesn\u0027t exist or expired.\n      if (loadRwr) {\n        ReplicaBuilder builder \u003d new ReplicaBuilder(ReplicaState.RWR)\n            .setBlockId(blockId)\n            .setLength(validateIntegrityAndSetLength(file, genStamp))\n            .setGenerationStamp(genStamp)\n            .setFsVolume(volume)\n            .setDirectoryToUse(file.getParentFile());\n        newReplica \u003d builder.build();\n      }\n    }\n\n    ReplicaInfo oldReplica \u003d volumeMap.get(bpid, newReplica.getBlockId());\n    if (oldReplica \u003d\u003d null) {\n      volumeMap.add(bpid, newReplica);\n    } else {\n      // We have multiple replicas of the same block so decide which one\n      // to keep.\n      newReplica \u003d resolveDuplicateReplicas(newReplica, oldReplica, volumeMap);\n    }\n\n    // If we are retaining a replica on transient storage make sure\n    // it is in the lazyWriteReplicaMap so it can be persisted\n    // eventually.\n    if (newReplica.getVolume().isTransientStorage()) {\n      lazyWriteReplicaMap.addReplica(bpid, blockId,\n          (FsVolumeImpl) newReplica.getVolume(), 0);\n    } else {\n      lazyWriteReplicaMap.discardReplica(bpid, blockId, false);\n    }\n    if (oldReplica \u003d\u003d null) {\n      incrNumBlocks();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/BlockPoolSlice.java",
      "extendedDetails": {}
    },
    "342c9572bf6a623287f34c5cc0bc3be6038c191a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9425. Expose number of blocks per volume as a metric (Contributed by Brahma Reddy Battula)\n",
      "commitDate": "21/02/16 7:59 PM",
      "commitName": "342c9572bf6a623287f34c5cc0bc3be6038c191a",
      "commitAuthor": "Vinayakumar B",
      "commitDateOld": "15/01/16 11:28 AM",
      "commitNameOld": "c07f7fa8ff752436726239d938e0461236839acf",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 37.35,
      "commitsBetweenForRepo": 256,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,67 +1,70 @@\n   private void addReplicaToReplicasMap(Block block, ReplicaMap volumeMap,\n       final RamDiskReplicaTracker lazyWriteReplicaMap,boolean isFinalized)\n       throws IOException {\n     ReplicaInfo newReplica \u003d null;\n     long blockId \u003d block.getBlockId();\n     long genStamp \u003d block.getGenerationStamp();\n     if (isFinalized) {\n       newReplica \u003d new FinalizedReplica(blockId, \n           block.getNumBytes(), genStamp, volume, DatanodeUtil\n           .idToBlockDir(finalizedDir, blockId));\n     } else {\n       File file \u003d new File(rbwDir, block.getBlockName());\n       boolean loadRwr \u003d true;\n       File restartMeta \u003d new File(file.getParent()  +\n           File.pathSeparator + \".\" + file.getName() + \".restart\");\n       Scanner sc \u003d null;\n       try {\n         sc \u003d new Scanner(restartMeta, \"UTF-8\");\n         // The restart meta file exists\n         if (sc.hasNextLong() \u0026\u0026 (sc.nextLong() \u003e timer.now())) {\n           // It didn\u0027t expire. Load the replica as a RBW.\n           // We don\u0027t know the expected block length, so just use 0\n           // and don\u0027t reserve any more space for writes.\n           newReplica \u003d new ReplicaBeingWritten(blockId,\n               validateIntegrityAndSetLength(file, genStamp), \n               genStamp, volume, file.getParentFile(), null, 0);\n           loadRwr \u003d false;\n         }\n         sc.close();\n         if (!restartMeta.delete()) {\n           FsDatasetImpl.LOG.warn(\"Failed to delete restart meta file: \" +\n               restartMeta.getPath());\n         }\n       } catch (FileNotFoundException fnfe) {\n         // nothing to do hereFile dir \u003d\n       } finally {\n         if (sc !\u003d null) {\n           sc.close();\n         }\n       }\n       // Restart meta doesn\u0027t exist or expired.\n       if (loadRwr) {\n         newReplica \u003d new ReplicaWaitingToBeRecovered(blockId,\n             validateIntegrityAndSetLength(file, genStamp),\n             genStamp, volume, file.getParentFile());\n       }\n     }\n \n     ReplicaInfo oldReplica \u003d volumeMap.get(bpid, newReplica.getBlockId());\n     if (oldReplica \u003d\u003d null) {\n       volumeMap.add(bpid, newReplica);\n     } else {\n       // We have multiple replicas of the same block so decide which one\n       // to keep.\n       newReplica \u003d resolveDuplicateReplicas(newReplica, oldReplica, volumeMap);\n     }\n \n     // If we are retaining a replica on transient storage make sure\n     // it is in the lazyWriteReplicaMap so it can be persisted\n     // eventually.\n     if (newReplica.getVolume().isTransientStorage()) {\n       lazyWriteReplicaMap.addReplica(bpid, blockId,\n           (FsVolumeImpl) newReplica.getVolume(), 0);\n     } else {\n       lazyWriteReplicaMap.discardReplica(bpid, blockId, false);\n     }\n+    if (oldReplica \u003d\u003d null) {\n+      incrNumBlocks();\n+    }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void addReplicaToReplicasMap(Block block, ReplicaMap volumeMap,\n      final RamDiskReplicaTracker lazyWriteReplicaMap,boolean isFinalized)\n      throws IOException {\n    ReplicaInfo newReplica \u003d null;\n    long blockId \u003d block.getBlockId();\n    long genStamp \u003d block.getGenerationStamp();\n    if (isFinalized) {\n      newReplica \u003d new FinalizedReplica(blockId, \n          block.getNumBytes(), genStamp, volume, DatanodeUtil\n          .idToBlockDir(finalizedDir, blockId));\n    } else {\n      File file \u003d new File(rbwDir, block.getBlockName());\n      boolean loadRwr \u003d true;\n      File restartMeta \u003d new File(file.getParent()  +\n          File.pathSeparator + \".\" + file.getName() + \".restart\");\n      Scanner sc \u003d null;\n      try {\n        sc \u003d new Scanner(restartMeta, \"UTF-8\");\n        // The restart meta file exists\n        if (sc.hasNextLong() \u0026\u0026 (sc.nextLong() \u003e timer.now())) {\n          // It didn\u0027t expire. Load the replica as a RBW.\n          // We don\u0027t know the expected block length, so just use 0\n          // and don\u0027t reserve any more space for writes.\n          newReplica \u003d new ReplicaBeingWritten(blockId,\n              validateIntegrityAndSetLength(file, genStamp), \n              genStamp, volume, file.getParentFile(), null, 0);\n          loadRwr \u003d false;\n        }\n        sc.close();\n        if (!restartMeta.delete()) {\n          FsDatasetImpl.LOG.warn(\"Failed to delete restart meta file: \" +\n              restartMeta.getPath());\n        }\n      } catch (FileNotFoundException fnfe) {\n        // nothing to do hereFile dir \u003d\n      } finally {\n        if (sc !\u003d null) {\n          sc.close();\n        }\n      }\n      // Restart meta doesn\u0027t exist or expired.\n      if (loadRwr) {\n        newReplica \u003d new ReplicaWaitingToBeRecovered(blockId,\n            validateIntegrityAndSetLength(file, genStamp),\n            genStamp, volume, file.getParentFile());\n      }\n    }\n\n    ReplicaInfo oldReplica \u003d volumeMap.get(bpid, newReplica.getBlockId());\n    if (oldReplica \u003d\u003d null) {\n      volumeMap.add(bpid, newReplica);\n    } else {\n      // We have multiple replicas of the same block so decide which one\n      // to keep.\n      newReplica \u003d resolveDuplicateReplicas(newReplica, oldReplica, volumeMap);\n    }\n\n    // If we are retaining a replica on transient storage make sure\n    // it is in the lazyWriteReplicaMap so it can be persisted\n    // eventually.\n    if (newReplica.getVolume().isTransientStorage()) {\n      lazyWriteReplicaMap.addReplica(bpid, blockId,\n          (FsVolumeImpl) newReplica.getVolume(), 0);\n    } else {\n      lazyWriteReplicaMap.discardReplica(bpid, blockId, false);\n    }\n    if (oldReplica \u003d\u003d null) {\n      incrNumBlocks();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/BlockPoolSlice.java",
      "extendedDetails": {}
    },
    "c07f7fa8ff752436726239d938e0461236839acf": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9624. DataNode start slowly due to the initial DU command operations. (Lin Yiqun via wang)\n",
      "commitDate": "15/01/16 11:28 AM",
      "commitName": "c07f7fa8ff752436726239d938e0461236839acf",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "29/09/15 1:20 AM",
      "commitNameOld": "d6fa34e014b0e2a61b24f05dd08ebe12354267fd",
      "commitAuthorOld": "yliu",
      "daysBetweenCommits": 108.46,
      "commitsBetweenForRepo": 737,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,67 +1,67 @@\n   private void addReplicaToReplicasMap(Block block, ReplicaMap volumeMap,\n       final RamDiskReplicaTracker lazyWriteReplicaMap,boolean isFinalized)\n       throws IOException {\n     ReplicaInfo newReplica \u003d null;\n     long blockId \u003d block.getBlockId();\n     long genStamp \u003d block.getGenerationStamp();\n     if (isFinalized) {\n       newReplica \u003d new FinalizedReplica(blockId, \n           block.getNumBytes(), genStamp, volume, DatanodeUtil\n           .idToBlockDir(finalizedDir, blockId));\n     } else {\n       File file \u003d new File(rbwDir, block.getBlockName());\n       boolean loadRwr \u003d true;\n       File restartMeta \u003d new File(file.getParent()  +\n           File.pathSeparator + \".\" + file.getName() + \".restart\");\n       Scanner sc \u003d null;\n       try {\n         sc \u003d new Scanner(restartMeta, \"UTF-8\");\n         // The restart meta file exists\n-        if (sc.hasNextLong() \u0026\u0026 (sc.nextLong() \u003e Time.now())) {\n+        if (sc.hasNextLong() \u0026\u0026 (sc.nextLong() \u003e timer.now())) {\n           // It didn\u0027t expire. Load the replica as a RBW.\n           // We don\u0027t know the expected block length, so just use 0\n           // and don\u0027t reserve any more space for writes.\n           newReplica \u003d new ReplicaBeingWritten(blockId,\n               validateIntegrityAndSetLength(file, genStamp), \n               genStamp, volume, file.getParentFile(), null, 0);\n           loadRwr \u003d false;\n         }\n         sc.close();\n         if (!restartMeta.delete()) {\n           FsDatasetImpl.LOG.warn(\"Failed to delete restart meta file: \" +\n               restartMeta.getPath());\n         }\n       } catch (FileNotFoundException fnfe) {\n         // nothing to do hereFile dir \u003d\n       } finally {\n         if (sc !\u003d null) {\n           sc.close();\n         }\n       }\n       // Restart meta doesn\u0027t exist or expired.\n       if (loadRwr) {\n         newReplica \u003d new ReplicaWaitingToBeRecovered(blockId,\n             validateIntegrityAndSetLength(file, genStamp),\n             genStamp, volume, file.getParentFile());\n       }\n     }\n \n     ReplicaInfo oldReplica \u003d volumeMap.get(bpid, newReplica.getBlockId());\n     if (oldReplica \u003d\u003d null) {\n       volumeMap.add(bpid, newReplica);\n     } else {\n       // We have multiple replicas of the same block so decide which one\n       // to keep.\n       newReplica \u003d resolveDuplicateReplicas(newReplica, oldReplica, volumeMap);\n     }\n \n     // If we are retaining a replica on transient storage make sure\n     // it is in the lazyWriteReplicaMap so it can be persisted\n     // eventually.\n     if (newReplica.getVolume().isTransientStorage()) {\n       lazyWriteReplicaMap.addReplica(bpid, blockId,\n           (FsVolumeImpl) newReplica.getVolume(), 0);\n     } else {\n       lazyWriteReplicaMap.discardReplica(bpid, blockId, false);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void addReplicaToReplicasMap(Block block, ReplicaMap volumeMap,\n      final RamDiskReplicaTracker lazyWriteReplicaMap,boolean isFinalized)\n      throws IOException {\n    ReplicaInfo newReplica \u003d null;\n    long blockId \u003d block.getBlockId();\n    long genStamp \u003d block.getGenerationStamp();\n    if (isFinalized) {\n      newReplica \u003d new FinalizedReplica(blockId, \n          block.getNumBytes(), genStamp, volume, DatanodeUtil\n          .idToBlockDir(finalizedDir, blockId));\n    } else {\n      File file \u003d new File(rbwDir, block.getBlockName());\n      boolean loadRwr \u003d true;\n      File restartMeta \u003d new File(file.getParent()  +\n          File.pathSeparator + \".\" + file.getName() + \".restart\");\n      Scanner sc \u003d null;\n      try {\n        sc \u003d new Scanner(restartMeta, \"UTF-8\");\n        // The restart meta file exists\n        if (sc.hasNextLong() \u0026\u0026 (sc.nextLong() \u003e timer.now())) {\n          // It didn\u0027t expire. Load the replica as a RBW.\n          // We don\u0027t know the expected block length, so just use 0\n          // and don\u0027t reserve any more space for writes.\n          newReplica \u003d new ReplicaBeingWritten(blockId,\n              validateIntegrityAndSetLength(file, genStamp), \n              genStamp, volume, file.getParentFile(), null, 0);\n          loadRwr \u003d false;\n        }\n        sc.close();\n        if (!restartMeta.delete()) {\n          FsDatasetImpl.LOG.warn(\"Failed to delete restart meta file: \" +\n              restartMeta.getPath());\n        }\n      } catch (FileNotFoundException fnfe) {\n        // nothing to do hereFile dir \u003d\n      } finally {\n        if (sc !\u003d null) {\n          sc.close();\n        }\n      }\n      // Restart meta doesn\u0027t exist or expired.\n      if (loadRwr) {\n        newReplica \u003d new ReplicaWaitingToBeRecovered(blockId,\n            validateIntegrityAndSetLength(file, genStamp),\n            genStamp, volume, file.getParentFile());\n      }\n    }\n\n    ReplicaInfo oldReplica \u003d volumeMap.get(bpid, newReplica.getBlockId());\n    if (oldReplica \u003d\u003d null) {\n      volumeMap.add(bpid, newReplica);\n    } else {\n      // We have multiple replicas of the same block so decide which one\n      // to keep.\n      newReplica \u003d resolveDuplicateReplicas(newReplica, oldReplica, volumeMap);\n    }\n\n    // If we are retaining a replica on transient storage make sure\n    // it is in the lazyWriteReplicaMap so it can be persisted\n    // eventually.\n    if (newReplica.getVolume().isTransientStorage()) {\n      lazyWriteReplicaMap.addReplica(bpid, blockId,\n          (FsVolumeImpl) newReplica.getVolume(), 0);\n    } else {\n      lazyWriteReplicaMap.discardReplica(bpid, blockId, false);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/BlockPoolSlice.java",
      "extendedDetails": {}
    },
    "e453989a5722e653bd97e3e54f9bbdffc9454fba": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8157. Writes to RAM DISK reserve locked memory for block files. (Arpit Agarwal)\n",
      "commitDate": "16/05/15 9:05 AM",
      "commitName": "e453989a5722e653bd97e3e54f9bbdffc9454fba",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "05/05/15 3:41 PM",
      "commitNameOld": "4da8490b512a33a255ed27309860859388d7c168",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 10.73,
      "commitsBetweenForRepo": 169,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,67 +1,67 @@\n   private void addReplicaToReplicasMap(Block block, ReplicaMap volumeMap,\n       final RamDiskReplicaTracker lazyWriteReplicaMap,boolean isFinalized)\n       throws IOException {\n     ReplicaInfo newReplica \u003d null;\n     long blockId \u003d block.getBlockId();\n     long genStamp \u003d block.getGenerationStamp();\n     if (isFinalized) {\n       newReplica \u003d new FinalizedReplica(blockId, \n           block.getNumBytes(), genStamp, volume, DatanodeUtil\n           .idToBlockDir(finalizedDir, blockId));\n     } else {\n       File file \u003d new File(rbwDir, block.getBlockName());\n       boolean loadRwr \u003d true;\n       File restartMeta \u003d new File(file.getParent()  +\n           File.pathSeparator + \".\" + file.getName() + \".restart\");\n       Scanner sc \u003d null;\n       try {\n         sc \u003d new Scanner(restartMeta, \"UTF-8\");\n         // The restart meta file exists\n         if (sc.hasNextLong() \u0026\u0026 (sc.nextLong() \u003e Time.now())) {\n           // It didn\u0027t expire. Load the replica as a RBW.\n           // We don\u0027t know the expected block length, so just use 0\n           // and don\u0027t reserve any more space for writes.\n           newReplica \u003d new ReplicaBeingWritten(blockId,\n               validateIntegrityAndSetLength(file, genStamp), \n               genStamp, volume, file.getParentFile(), null, 0);\n           loadRwr \u003d false;\n         }\n         sc.close();\n         if (!restartMeta.delete()) {\n           FsDatasetImpl.LOG.warn(\"Failed to delete restart meta file: \" +\n               restartMeta.getPath());\n         }\n       } catch (FileNotFoundException fnfe) {\n         // nothing to do hereFile dir \u003d\n       } finally {\n         if (sc !\u003d null) {\n           sc.close();\n         }\n       }\n       // Restart meta doesn\u0027t exist or expired.\n       if (loadRwr) {\n         newReplica \u003d new ReplicaWaitingToBeRecovered(blockId,\n             validateIntegrityAndSetLength(file, genStamp),\n             genStamp, volume, file.getParentFile());\n       }\n     }\n \n     ReplicaInfo oldReplica \u003d volumeMap.get(bpid, newReplica.getBlockId());\n     if (oldReplica \u003d\u003d null) {\n       volumeMap.add(bpid, newReplica);\n     } else {\n       // We have multiple replicas of the same block so decide which one\n       // to keep.\n       newReplica \u003d resolveDuplicateReplicas(newReplica, oldReplica, volumeMap);\n     }\n \n     // If we are retaining a replica on transient storage make sure\n     // it is in the lazyWriteReplicaMap so it can be persisted\n     // eventually.\n     if (newReplica.getVolume().isTransientStorage()) {\n       lazyWriteReplicaMap.addReplica(bpid, blockId,\n-          (FsVolumeImpl) newReplica.getVolume());\n+          (FsVolumeImpl) newReplica.getVolume(), 0);\n     } else {\n       lazyWriteReplicaMap.discardReplica(bpid, blockId, false);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void addReplicaToReplicasMap(Block block, ReplicaMap volumeMap,\n      final RamDiskReplicaTracker lazyWriteReplicaMap,boolean isFinalized)\n      throws IOException {\n    ReplicaInfo newReplica \u003d null;\n    long blockId \u003d block.getBlockId();\n    long genStamp \u003d block.getGenerationStamp();\n    if (isFinalized) {\n      newReplica \u003d new FinalizedReplica(blockId, \n          block.getNumBytes(), genStamp, volume, DatanodeUtil\n          .idToBlockDir(finalizedDir, blockId));\n    } else {\n      File file \u003d new File(rbwDir, block.getBlockName());\n      boolean loadRwr \u003d true;\n      File restartMeta \u003d new File(file.getParent()  +\n          File.pathSeparator + \".\" + file.getName() + \".restart\");\n      Scanner sc \u003d null;\n      try {\n        sc \u003d new Scanner(restartMeta, \"UTF-8\");\n        // The restart meta file exists\n        if (sc.hasNextLong() \u0026\u0026 (sc.nextLong() \u003e Time.now())) {\n          // It didn\u0027t expire. Load the replica as a RBW.\n          // We don\u0027t know the expected block length, so just use 0\n          // and don\u0027t reserve any more space for writes.\n          newReplica \u003d new ReplicaBeingWritten(blockId,\n              validateIntegrityAndSetLength(file, genStamp), \n              genStamp, volume, file.getParentFile(), null, 0);\n          loadRwr \u003d false;\n        }\n        sc.close();\n        if (!restartMeta.delete()) {\n          FsDatasetImpl.LOG.warn(\"Failed to delete restart meta file: \" +\n              restartMeta.getPath());\n        }\n      } catch (FileNotFoundException fnfe) {\n        // nothing to do hereFile dir \u003d\n      } finally {\n        if (sc !\u003d null) {\n          sc.close();\n        }\n      }\n      // Restart meta doesn\u0027t exist or expired.\n      if (loadRwr) {\n        newReplica \u003d new ReplicaWaitingToBeRecovered(blockId,\n            validateIntegrityAndSetLength(file, genStamp),\n            genStamp, volume, file.getParentFile());\n      }\n    }\n\n    ReplicaInfo oldReplica \u003d volumeMap.get(bpid, newReplica.getBlockId());\n    if (oldReplica \u003d\u003d null) {\n      volumeMap.add(bpid, newReplica);\n    } else {\n      // We have multiple replicas of the same block so decide which one\n      // to keep.\n      newReplica \u003d resolveDuplicateReplicas(newReplica, oldReplica, volumeMap);\n    }\n\n    // If we are retaining a replica on transient storage make sure\n    // it is in the lazyWriteReplicaMap so it can be persisted\n    // eventually.\n    if (newReplica.getVolume().isTransientStorage()) {\n      lazyWriteReplicaMap.addReplica(bpid, blockId,\n          (FsVolumeImpl) newReplica.getVolume(), 0);\n    } else {\n      lazyWriteReplicaMap.discardReplica(bpid, blockId, false);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/BlockPoolSlice.java",
      "extendedDetails": {}
    },
    "fc1031af749435dc95efea6745b1b2300ce29446": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-7928. Scanning blocks from disk during rolling upgrade startup takes a lot of time if disks are busy. Contributed by Rushabh Shah.\n",
      "commitDate": "25/03/15 12:42 PM",
      "commitName": "fc1031af749435dc95efea6745b1b2300ce29446",
      "commitAuthor": "Kihwal Lee",
      "diff": "@@ -0,0 +1,67 @@\n+  private void addReplicaToReplicasMap(Block block, ReplicaMap volumeMap,\n+      final RamDiskReplicaTracker lazyWriteReplicaMap,boolean isFinalized)\n+      throws IOException {\n+    ReplicaInfo newReplica \u003d null;\n+    long blockId \u003d block.getBlockId();\n+    long genStamp \u003d block.getGenerationStamp();\n+    if (isFinalized) {\n+      newReplica \u003d new FinalizedReplica(blockId, \n+          block.getNumBytes(), genStamp, volume, DatanodeUtil\n+          .idToBlockDir(finalizedDir, blockId));\n+    } else {\n+      File file \u003d new File(rbwDir, block.getBlockName());\n+      boolean loadRwr \u003d true;\n+      File restartMeta \u003d new File(file.getParent()  +\n+          File.pathSeparator + \".\" + file.getName() + \".restart\");\n+      Scanner sc \u003d null;\n+      try {\n+        sc \u003d new Scanner(restartMeta, \"UTF-8\");\n+        // The restart meta file exists\n+        if (sc.hasNextLong() \u0026\u0026 (sc.nextLong() \u003e Time.now())) {\n+          // It didn\u0027t expire. Load the replica as a RBW.\n+          // We don\u0027t know the expected block length, so just use 0\n+          // and don\u0027t reserve any more space for writes.\n+          newReplica \u003d new ReplicaBeingWritten(blockId,\n+              validateIntegrityAndSetLength(file, genStamp), \n+              genStamp, volume, file.getParentFile(), null, 0);\n+          loadRwr \u003d false;\n+        }\n+        sc.close();\n+        if (!restartMeta.delete()) {\n+          FsDatasetImpl.LOG.warn(\"Failed to delete restart meta file: \" +\n+              restartMeta.getPath());\n+        }\n+      } catch (FileNotFoundException fnfe) {\n+        // nothing to do hereFile dir \u003d\n+      } finally {\n+        if (sc !\u003d null) {\n+          sc.close();\n+        }\n+      }\n+      // Restart meta doesn\u0027t exist or expired.\n+      if (loadRwr) {\n+        newReplica \u003d new ReplicaWaitingToBeRecovered(blockId,\n+            validateIntegrityAndSetLength(file, genStamp),\n+            genStamp, volume, file.getParentFile());\n+      }\n+    }\n+\n+    ReplicaInfo oldReplica \u003d volumeMap.get(bpid, newReplica.getBlockId());\n+    if (oldReplica \u003d\u003d null) {\n+      volumeMap.add(bpid, newReplica);\n+    } else {\n+      // We have multiple replicas of the same block so decide which one\n+      // to keep.\n+      newReplica \u003d resolveDuplicateReplicas(newReplica, oldReplica, volumeMap);\n+    }\n+\n+    // If we are retaining a replica on transient storage make sure\n+    // it is in the lazyWriteReplicaMap so it can be persisted\n+    // eventually.\n+    if (newReplica.getVolume().isTransientStorage()) {\n+      lazyWriteReplicaMap.addReplica(bpid, blockId,\n+          (FsVolumeImpl) newReplica.getVolume());\n+    } else {\n+      lazyWriteReplicaMap.discardReplica(bpid, blockId, false);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void addReplicaToReplicasMap(Block block, ReplicaMap volumeMap,\n      final RamDiskReplicaTracker lazyWriteReplicaMap,boolean isFinalized)\n      throws IOException {\n    ReplicaInfo newReplica \u003d null;\n    long blockId \u003d block.getBlockId();\n    long genStamp \u003d block.getGenerationStamp();\n    if (isFinalized) {\n      newReplica \u003d new FinalizedReplica(blockId, \n          block.getNumBytes(), genStamp, volume, DatanodeUtil\n          .idToBlockDir(finalizedDir, blockId));\n    } else {\n      File file \u003d new File(rbwDir, block.getBlockName());\n      boolean loadRwr \u003d true;\n      File restartMeta \u003d new File(file.getParent()  +\n          File.pathSeparator + \".\" + file.getName() + \".restart\");\n      Scanner sc \u003d null;\n      try {\n        sc \u003d new Scanner(restartMeta, \"UTF-8\");\n        // The restart meta file exists\n        if (sc.hasNextLong() \u0026\u0026 (sc.nextLong() \u003e Time.now())) {\n          // It didn\u0027t expire. Load the replica as a RBW.\n          // We don\u0027t know the expected block length, so just use 0\n          // and don\u0027t reserve any more space for writes.\n          newReplica \u003d new ReplicaBeingWritten(blockId,\n              validateIntegrityAndSetLength(file, genStamp), \n              genStamp, volume, file.getParentFile(), null, 0);\n          loadRwr \u003d false;\n        }\n        sc.close();\n        if (!restartMeta.delete()) {\n          FsDatasetImpl.LOG.warn(\"Failed to delete restart meta file: \" +\n              restartMeta.getPath());\n        }\n      } catch (FileNotFoundException fnfe) {\n        // nothing to do hereFile dir \u003d\n      } finally {\n        if (sc !\u003d null) {\n          sc.close();\n        }\n      }\n      // Restart meta doesn\u0027t exist or expired.\n      if (loadRwr) {\n        newReplica \u003d new ReplicaWaitingToBeRecovered(blockId,\n            validateIntegrityAndSetLength(file, genStamp),\n            genStamp, volume, file.getParentFile());\n      }\n    }\n\n    ReplicaInfo oldReplica \u003d volumeMap.get(bpid, newReplica.getBlockId());\n    if (oldReplica \u003d\u003d null) {\n      volumeMap.add(bpid, newReplica);\n    } else {\n      // We have multiple replicas of the same block so decide which one\n      // to keep.\n      newReplica \u003d resolveDuplicateReplicas(newReplica, oldReplica, volumeMap);\n    }\n\n    // If we are retaining a replica on transient storage make sure\n    // it is in the lazyWriteReplicaMap so it can be persisted\n    // eventually.\n    if (newReplica.getVolume().isTransientStorage()) {\n      lazyWriteReplicaMap.addReplica(bpid, blockId,\n          (FsVolumeImpl) newReplica.getVolume());\n    } else {\n      lazyWriteReplicaMap.discardReplica(bpid, blockId, false);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/BlockPoolSlice.java"
    }
  }
}