{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DirectoryScanner.java",
  "functionName": "call",
  "functionId": "call",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DirectoryScanner.java",
  "functionStartLine": 667,
  "functionEndLine": 691,
  "numCommitsSeen": 60,
  "timeTaken": 8771,
  "changeHistory": [
    "73c660b43f3d5311947d2acc9488f17c1caf4de0",
    "1dc0adfac0ee4821c67366728c70be9b59477b0f",
    "b668eb91556b8c85c2b4925808ccb1f769031c20",
    "4b2c442d4e34f4708fa2ca442208427ca10798c1",
    "96b12662ea76e3ded4ef13944fc8df206cfb4613",
    "8703301b466cbc37ef53a96a55bcf6412792d5cf",
    "7a3c381b39887a02e944fa98287afd0eb4db3560",
    "f0c980abed3843923e0eb16b626fa27334195eda",
    "b6ffb08a467f1b5bc89e5114c462c3117b337be6",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "73c660b43f3d5311947d2acc9488f17c1caf4de0": "Ybodychange",
    "1dc0adfac0ee4821c67366728c70be9b59477b0f": "Ymultichange(Yreturntypechange,Ybodychange)",
    "b668eb91556b8c85c2b4925808ccb1f769031c20": "Ybodychange",
    "4b2c442d4e34f4708fa2ca442208427ca10798c1": "Ybodychange",
    "96b12662ea76e3ded4ef13944fc8df206cfb4613": "Ybodychange",
    "8703301b466cbc37ef53a96a55bcf6412792d5cf": "Ybodychange",
    "7a3c381b39887a02e944fa98287afd0eb4db3560": "Ymultichange(Yexceptionschange,Ybodychange)",
    "f0c980abed3843923e0eb16b626fa27334195eda": "Ybodychange",
    "b6ffb08a467f1b5bc89e5114c462c3117b337be6": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "73c660b43f3d5311947d2acc9488f17c1caf4de0": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13958. Miscellaneous Improvements for FsVolumeSpi. Contributed by BELUGA BEHR.\n",
      "commitDate": "05/10/18 9:32 AM",
      "commitName": "73c660b43f3d5311947d2acc9488f17c1caf4de0",
      "commitAuthor": "Inigo Goiri",
      "commitDateOld": "03/10/18 11:19 AM",
      "commitNameOld": "1dc0adfac0ee4821c67366728c70be9b59477b0f",
      "commitAuthorOld": "Inigo Goiri",
      "daysBetweenCommits": 1.93,
      "commitsBetweenForRepo": 23,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,25 +1,25 @@\n     public ScanInfoVolumeReport call() throws IOException {\n       String[] bpList \u003d volume.getBlockPoolList();\n       ScanInfoVolumeReport result \u003d\n           new ScanInfoVolumeReport(volume, Arrays.asList(bpList));\n       perfTimer.start();\n       throttleTimer.start();\n       for (String bpid : bpList) {\n-        LinkedList\u003cScanInfo\u003e report \u003d new LinkedList\u003c\u003e();\n+        List\u003cScanInfo\u003e report \u003d new ArrayList\u003c\u003e(DEFAULT_MAP_SIZE);\n \n         perfTimer.reset().start();\n         throttleTimer.reset().start();\n \n         try {\n           // ScanInfos are added directly to \u0027report\u0027 list\n           volume.compileReport(bpid, report, this);\n           result.addAll(bpid, report);\n         } catch (InterruptedException ex) {\n           // Exit quickly and flag the scanner to do the same\n           result \u003d null;\n           break;\n         }\n       }\n       LOG.trace(\"Scanner volume report: {}\", result);\n       return result;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public ScanInfoVolumeReport call() throws IOException {\n      String[] bpList \u003d volume.getBlockPoolList();\n      ScanInfoVolumeReport result \u003d\n          new ScanInfoVolumeReport(volume, Arrays.asList(bpList));\n      perfTimer.start();\n      throttleTimer.start();\n      for (String bpid : bpList) {\n        List\u003cScanInfo\u003e report \u003d new ArrayList\u003c\u003e(DEFAULT_MAP_SIZE);\n\n        perfTimer.reset().start();\n        throttleTimer.reset().start();\n\n        try {\n          // ScanInfos are added directly to \u0027report\u0027 list\n          volume.compileReport(bpid, report, this);\n          result.addAll(bpid, report);\n        } catch (InterruptedException ex) {\n          // Exit quickly and flag the scanner to do the same\n          result \u003d null;\n          break;\n        }\n      }\n      LOG.trace(\"Scanner volume report: {}\", result);\n      return result;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DirectoryScanner.java",
      "extendedDetails": {}
    },
    "1dc0adfac0ee4821c67366728c70be9b59477b0f": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-13947. Review of DirectoryScanner Class. Contributed by BELUGA BEHR.\n",
      "commitDate": "03/10/18 11:19 AM",
      "commitName": "1dc0adfac0ee4821c67366728c70be9b59477b0f",
      "commitAuthor": "Inigo Goiri",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-13947. Review of DirectoryScanner Class. Contributed by BELUGA BEHR.\n",
          "commitDate": "03/10/18 11:19 AM",
          "commitName": "1dc0adfac0ee4821c67366728c70be9b59477b0f",
          "commitAuthor": "Inigo Goiri",
          "commitDateOld": "06/09/18 2:48 PM",
          "commitNameOld": "eca1a4bfe952fc184fe90dde50bac9b0e5293568",
          "commitAuthorOld": "Giovanni Matteo Fumarola",
          "daysBetweenCommits": 26.86,
          "commitsBetweenForRepo": 283,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,21 +1,25 @@\n-    public ScanInfoPerBlockPool call() throws IOException {\n+    public ScanInfoVolumeReport call() throws IOException {\n       String[] bpList \u003d volume.getBlockPoolList();\n-      ScanInfoPerBlockPool result \u003d new ScanInfoPerBlockPool(bpList.length);\n+      ScanInfoVolumeReport result \u003d\n+          new ScanInfoVolumeReport(volume, Arrays.asList(bpList));\n       perfTimer.start();\n       throttleTimer.start();\n       for (String bpid : bpList) {\n         LinkedList\u003cScanInfo\u003e report \u003d new LinkedList\u003c\u003e();\n \n         perfTimer.reset().start();\n         throttleTimer.reset().start();\n \n         try {\n-          result.put(bpid, volume.compileReport(bpid, report, this));\n+          // ScanInfos are added directly to \u0027report\u0027 list\n+          volume.compileReport(bpid, report, this);\n+          result.addAll(bpid, report);\n         } catch (InterruptedException ex) {\n           // Exit quickly and flag the scanner to do the same\n           result \u003d null;\n           break;\n         }\n       }\n+      LOG.trace(\"Scanner volume report: {}\", result);\n       return result;\n     }\n\\ No newline at end of file\n",
          "actualSource": "    public ScanInfoVolumeReport call() throws IOException {\n      String[] bpList \u003d volume.getBlockPoolList();\n      ScanInfoVolumeReport result \u003d\n          new ScanInfoVolumeReport(volume, Arrays.asList(bpList));\n      perfTimer.start();\n      throttleTimer.start();\n      for (String bpid : bpList) {\n        LinkedList\u003cScanInfo\u003e report \u003d new LinkedList\u003c\u003e();\n\n        perfTimer.reset().start();\n        throttleTimer.reset().start();\n\n        try {\n          // ScanInfos are added directly to \u0027report\u0027 list\n          volume.compileReport(bpid, report, this);\n          result.addAll(bpid, report);\n        } catch (InterruptedException ex) {\n          // Exit quickly and flag the scanner to do the same\n          result \u003d null;\n          break;\n        }\n      }\n      LOG.trace(\"Scanner volume report: {}\", result);\n      return result;\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DirectoryScanner.java",
          "extendedDetails": {
            "oldValue": "ScanInfoPerBlockPool",
            "newValue": "ScanInfoVolumeReport"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-13947. Review of DirectoryScanner Class. Contributed by BELUGA BEHR.\n",
          "commitDate": "03/10/18 11:19 AM",
          "commitName": "1dc0adfac0ee4821c67366728c70be9b59477b0f",
          "commitAuthor": "Inigo Goiri",
          "commitDateOld": "06/09/18 2:48 PM",
          "commitNameOld": "eca1a4bfe952fc184fe90dde50bac9b0e5293568",
          "commitAuthorOld": "Giovanni Matteo Fumarola",
          "daysBetweenCommits": 26.86,
          "commitsBetweenForRepo": 283,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,21 +1,25 @@\n-    public ScanInfoPerBlockPool call() throws IOException {\n+    public ScanInfoVolumeReport call() throws IOException {\n       String[] bpList \u003d volume.getBlockPoolList();\n-      ScanInfoPerBlockPool result \u003d new ScanInfoPerBlockPool(bpList.length);\n+      ScanInfoVolumeReport result \u003d\n+          new ScanInfoVolumeReport(volume, Arrays.asList(bpList));\n       perfTimer.start();\n       throttleTimer.start();\n       for (String bpid : bpList) {\n         LinkedList\u003cScanInfo\u003e report \u003d new LinkedList\u003c\u003e();\n \n         perfTimer.reset().start();\n         throttleTimer.reset().start();\n \n         try {\n-          result.put(bpid, volume.compileReport(bpid, report, this));\n+          // ScanInfos are added directly to \u0027report\u0027 list\n+          volume.compileReport(bpid, report, this);\n+          result.addAll(bpid, report);\n         } catch (InterruptedException ex) {\n           // Exit quickly and flag the scanner to do the same\n           result \u003d null;\n           break;\n         }\n       }\n+      LOG.trace(\"Scanner volume report: {}\", result);\n       return result;\n     }\n\\ No newline at end of file\n",
          "actualSource": "    public ScanInfoVolumeReport call() throws IOException {\n      String[] bpList \u003d volume.getBlockPoolList();\n      ScanInfoVolumeReport result \u003d\n          new ScanInfoVolumeReport(volume, Arrays.asList(bpList));\n      perfTimer.start();\n      throttleTimer.start();\n      for (String bpid : bpList) {\n        LinkedList\u003cScanInfo\u003e report \u003d new LinkedList\u003c\u003e();\n\n        perfTimer.reset().start();\n        throttleTimer.reset().start();\n\n        try {\n          // ScanInfos are added directly to \u0027report\u0027 list\n          volume.compileReport(bpid, report, this);\n          result.addAll(bpid, report);\n        } catch (InterruptedException ex) {\n          // Exit quickly and flag the scanner to do the same\n          result \u003d null;\n          break;\n        }\n      }\n      LOG.trace(\"Scanner volume report: {}\", result);\n      return result;\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DirectoryScanner.java",
          "extendedDetails": {}
        }
      ]
    },
    "b668eb91556b8c85c2b4925808ccb1f769031c20": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10675. Datanode support to read from external stores.\n",
      "commitDate": "15/12/17 5:51 PM",
      "commitName": "b668eb91556b8c85c2b4925808ccb1f769031c20",
      "commitAuthor": "Virajith Jalaparti",
      "commitDateOld": "25/08/17 10:41 AM",
      "commitNameOld": "4b2c442d4e34f4708fa2ca442208427ca10798c1",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 112.34,
      "commitsBetweenForRepo": 958,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,18 +1,21 @@\n     public ScanInfoPerBlockPool call() throws IOException {\n       String[] bpList \u003d volume.getBlockPoolList();\n       ScanInfoPerBlockPool result \u003d new ScanInfoPerBlockPool(bpList.length);\n       perfTimer.start();\n       throttleTimer.start();\n       for (String bpid : bpList) {\n         LinkedList\u003cScanInfo\u003e report \u003d new LinkedList\u003c\u003e();\n \n+        perfTimer.reset().start();\n+        throttleTimer.reset().start();\n+\n         try {\n           result.put(bpid, volume.compileReport(bpid, report, this));\n         } catch (InterruptedException ex) {\n           // Exit quickly and flag the scanner to do the same\n           result \u003d null;\n           break;\n         }\n       }\n       return result;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public ScanInfoPerBlockPool call() throws IOException {\n      String[] bpList \u003d volume.getBlockPoolList();\n      ScanInfoPerBlockPool result \u003d new ScanInfoPerBlockPool(bpList.length);\n      perfTimer.start();\n      throttleTimer.start();\n      for (String bpid : bpList) {\n        LinkedList\u003cScanInfo\u003e report \u003d new LinkedList\u003c\u003e();\n\n        perfTimer.reset().start();\n        throttleTimer.reset().start();\n\n        try {\n          result.put(bpid, volume.compileReport(bpid, report, this));\n        } catch (InterruptedException ex) {\n          // Exit quickly and flag the scanner to do the same\n          result \u003d null;\n          break;\n        }\n      }\n      return result;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DirectoryScanner.java",
      "extendedDetails": {}
    },
    "4b2c442d4e34f4708fa2ca442208427ca10798c1": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12319. DirectoryScanner will throw IllegalStateException when Multiple BP\u0027s are present. Contributed by Brahma Reddy Battula.\n",
      "commitDate": "25/08/17 10:41 AM",
      "commitName": "4b2c442d4e34f4708fa2ca442208427ca10798c1",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "07/12/16 8:38 PM",
      "commitNameOld": "9ef89ede2f18c76c601fd585cb9d47511f5fc3ed",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 260.54,
      "commitsBetweenForRepo": 1418,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,19 +1,18 @@\n     public ScanInfoPerBlockPool call() throws IOException {\n       String[] bpList \u003d volume.getBlockPoolList();\n       ScanInfoPerBlockPool result \u003d new ScanInfoPerBlockPool(bpList.length);\n+      perfTimer.start();\n+      throttleTimer.start();\n       for (String bpid : bpList) {\n         LinkedList\u003cScanInfo\u003e report \u003d new LinkedList\u003c\u003e();\n \n-        perfTimer.start();\n-        throttleTimer.start();\n-\n         try {\n           result.put(bpid, volume.compileReport(bpid, report, this));\n         } catch (InterruptedException ex) {\n           // Exit quickly and flag the scanner to do the same\n           result \u003d null;\n           break;\n         }\n       }\n       return result;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public ScanInfoPerBlockPool call() throws IOException {\n      String[] bpList \u003d volume.getBlockPoolList();\n      ScanInfoPerBlockPool result \u003d new ScanInfoPerBlockPool(bpList.length);\n      perfTimer.start();\n      throttleTimer.start();\n      for (String bpid : bpList) {\n        LinkedList\u003cScanInfo\u003e report \u003d new LinkedList\u003c\u003e();\n\n        try {\n          result.put(bpid, volume.compileReport(bpid, report, this));\n        } catch (InterruptedException ex) {\n          // Exit quickly and flag the scanner to do the same\n          result \u003d null;\n          break;\n        }\n      }\n      return result;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DirectoryScanner.java",
      "extendedDetails": {}
    },
    "96b12662ea76e3ded4ef13944fc8df206cfb4613": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10637. Modifications to remove the assumption that FsVolumes are backed by java.io.File. (Virajith Jalaparti via lei)\n",
      "commitDate": "10/10/16 3:30 PM",
      "commitName": "96b12662ea76e3ded4ef13944fc8df206cfb4613",
      "commitAuthor": "Lei Xu",
      "commitDateOld": "13/09/16 12:54 PM",
      "commitNameOld": "86c9862bec0248d671e657aa56094a2919b8ac14",
      "commitAuthorOld": "Lei Xu",
      "daysBetweenCommits": 27.11,
      "commitsBetweenForRepo": 180,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,19 @@\n     public ScanInfoPerBlockPool call() throws IOException {\n       String[] bpList \u003d volume.getBlockPoolList();\n       ScanInfoPerBlockPool result \u003d new ScanInfoPerBlockPool(bpList.length);\n       for (String bpid : bpList) {\n         LinkedList\u003cScanInfo\u003e report \u003d new LinkedList\u003c\u003e();\n-        File bpFinalizedDir \u003d volume.getFinalizedDir(bpid);\n \n         perfTimer.start();\n         throttleTimer.start();\n \n         try {\n-          result.put(bpid,\n-              compileReport(volume, bpFinalizedDir, bpFinalizedDir, report));\n+          result.put(bpid, volume.compileReport(bpid, report, this));\n         } catch (InterruptedException ex) {\n           // Exit quickly and flag the scanner to do the same\n           result \u003d null;\n           break;\n         }\n       }\n       return result;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public ScanInfoPerBlockPool call() throws IOException {\n      String[] bpList \u003d volume.getBlockPoolList();\n      ScanInfoPerBlockPool result \u003d new ScanInfoPerBlockPool(bpList.length);\n      for (String bpid : bpList) {\n        LinkedList\u003cScanInfo\u003e report \u003d new LinkedList\u003c\u003e();\n\n        perfTimer.start();\n        throttleTimer.start();\n\n        try {\n          result.put(bpid, volume.compileReport(bpid, report, this));\n        } catch (InterruptedException ex) {\n          // Exit quickly and flag the scanner to do the same\n          result \u003d null;\n          break;\n        }\n      }\n      return result;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DirectoryScanner.java",
      "extendedDetails": {}
    },
    "8703301b466cbc37ef53a96a55bcf6412792d5cf": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9174. Fix findbugs warnings in FSOutputSummer.tracer and DirectoryScanner$ReportCompiler.currentThread. Contributed by Yi Liu.\n",
      "commitDate": "29/09/15 2:56 PM",
      "commitName": "8703301b466cbc37ef53a96a55bcf6412792d5cf",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "26/09/15 4:09 AM",
      "commitNameOld": "7a3c381b39887a02e944fa98287afd0eb4db3560",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 3.45,
      "commitsBetweenForRepo": 24,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,21 @@\n     public ScanInfoPerBlockPool call() throws IOException {\n-      currentThread \u003d Thread.currentThread();\n-\n       String[] bpList \u003d volume.getBlockPoolList();\n       ScanInfoPerBlockPool result \u003d new ScanInfoPerBlockPool(bpList.length);\n       for (String bpid : bpList) {\n         LinkedList\u003cScanInfo\u003e report \u003d new LinkedList\u003c\u003e();\n         File bpFinalizedDir \u003d volume.getFinalizedDir(bpid);\n \n         perfTimer.start();\n         throttleTimer.start();\n \n         try {\n           result.put(bpid,\n               compileReport(volume, bpFinalizedDir, bpFinalizedDir, report));\n         } catch (InterruptedException ex) {\n           // Exit quickly and flag the scanner to do the same\n           result \u003d null;\n           break;\n         }\n       }\n       return result;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public ScanInfoPerBlockPool call() throws IOException {\n      String[] bpList \u003d volume.getBlockPoolList();\n      ScanInfoPerBlockPool result \u003d new ScanInfoPerBlockPool(bpList.length);\n      for (String bpid : bpList) {\n        LinkedList\u003cScanInfo\u003e report \u003d new LinkedList\u003c\u003e();\n        File bpFinalizedDir \u003d volume.getFinalizedDir(bpid);\n\n        perfTimer.start();\n        throttleTimer.start();\n\n        try {\n          result.put(bpid,\n              compileReport(volume, bpFinalizedDir, bpFinalizedDir, report));\n        } catch (InterruptedException ex) {\n          // Exit quickly and flag the scanner to do the same\n          result \u003d null;\n          break;\n        }\n      }\n      return result;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DirectoryScanner.java",
      "extendedDetails": {}
    },
    "7a3c381b39887a02e944fa98287afd0eb4db3560": {
      "type": "Ymultichange(Yexceptionschange,Ybodychange)",
      "commitMessage": "HDFS-8873. Allow the directoryScanner to be rate-limited (Daniel Templeton via Colin P. McCabe)\n",
      "commitDate": "26/09/15 4:09 AM",
      "commitName": "7a3c381b39887a02e944fa98287afd0eb4db3560",
      "commitAuthor": "Colin Patrick Mccabe",
      "subchanges": [
        {
          "type": "Yexceptionschange",
          "commitMessage": "HDFS-8873. Allow the directoryScanner to be rate-limited (Daniel Templeton via Colin P. McCabe)\n",
          "commitDate": "26/09/15 4:09 AM",
          "commitName": "7a3c381b39887a02e944fa98287afd0eb4db3560",
          "commitAuthor": "Colin Patrick Mccabe",
          "commitDateOld": "19/05/15 10:50 AM",
          "commitNameOld": "470c87dbc6c24dd3b370f1ad9e7ab1f6dabd2080",
          "commitAuthorOld": "Colin Patrick Mccabe",
          "daysBetweenCommits": 129.72,
          "commitsBetweenForRepo": 819,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,23 @@\n-    public ScanInfoPerBlockPool call() throws Exception {\n+    public ScanInfoPerBlockPool call() throws IOException {\n+      currentThread \u003d Thread.currentThread();\n+\n       String[] bpList \u003d volume.getBlockPoolList();\n       ScanInfoPerBlockPool result \u003d new ScanInfoPerBlockPool(bpList.length);\n       for (String bpid : bpList) {\n-        LinkedList\u003cScanInfo\u003e report \u003d new LinkedList\u003cScanInfo\u003e();\n+        LinkedList\u003cScanInfo\u003e report \u003d new LinkedList\u003c\u003e();\n         File bpFinalizedDir \u003d volume.getFinalizedDir(bpid);\n-        result.put(bpid,\n-            compileReport(volume, bpFinalizedDir, bpFinalizedDir, report));\n+\n+        perfTimer.start();\n+        throttleTimer.start();\n+\n+        try {\n+          result.put(bpid,\n+              compileReport(volume, bpFinalizedDir, bpFinalizedDir, report));\n+        } catch (InterruptedException ex) {\n+          // Exit quickly and flag the scanner to do the same\n+          result \u003d null;\n+          break;\n+        }\n       }\n       return result;\n     }\n\\ No newline at end of file\n",
          "actualSource": "    public ScanInfoPerBlockPool call() throws IOException {\n      currentThread \u003d Thread.currentThread();\n\n      String[] bpList \u003d volume.getBlockPoolList();\n      ScanInfoPerBlockPool result \u003d new ScanInfoPerBlockPool(bpList.length);\n      for (String bpid : bpList) {\n        LinkedList\u003cScanInfo\u003e report \u003d new LinkedList\u003c\u003e();\n        File bpFinalizedDir \u003d volume.getFinalizedDir(bpid);\n\n        perfTimer.start();\n        throttleTimer.start();\n\n        try {\n          result.put(bpid,\n              compileReport(volume, bpFinalizedDir, bpFinalizedDir, report));\n        } catch (InterruptedException ex) {\n          // Exit quickly and flag the scanner to do the same\n          result \u003d null;\n          break;\n        }\n      }\n      return result;\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DirectoryScanner.java",
          "extendedDetails": {
            "oldValue": "[Exception]",
            "newValue": "[IOException]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-8873. Allow the directoryScanner to be rate-limited (Daniel Templeton via Colin P. McCabe)\n",
          "commitDate": "26/09/15 4:09 AM",
          "commitName": "7a3c381b39887a02e944fa98287afd0eb4db3560",
          "commitAuthor": "Colin Patrick Mccabe",
          "commitDateOld": "19/05/15 10:50 AM",
          "commitNameOld": "470c87dbc6c24dd3b370f1ad9e7ab1f6dabd2080",
          "commitAuthorOld": "Colin Patrick Mccabe",
          "daysBetweenCommits": 129.72,
          "commitsBetweenForRepo": 819,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,23 @@\n-    public ScanInfoPerBlockPool call() throws Exception {\n+    public ScanInfoPerBlockPool call() throws IOException {\n+      currentThread \u003d Thread.currentThread();\n+\n       String[] bpList \u003d volume.getBlockPoolList();\n       ScanInfoPerBlockPool result \u003d new ScanInfoPerBlockPool(bpList.length);\n       for (String bpid : bpList) {\n-        LinkedList\u003cScanInfo\u003e report \u003d new LinkedList\u003cScanInfo\u003e();\n+        LinkedList\u003cScanInfo\u003e report \u003d new LinkedList\u003c\u003e();\n         File bpFinalizedDir \u003d volume.getFinalizedDir(bpid);\n-        result.put(bpid,\n-            compileReport(volume, bpFinalizedDir, bpFinalizedDir, report));\n+\n+        perfTimer.start();\n+        throttleTimer.start();\n+\n+        try {\n+          result.put(bpid,\n+              compileReport(volume, bpFinalizedDir, bpFinalizedDir, report));\n+        } catch (InterruptedException ex) {\n+          // Exit quickly and flag the scanner to do the same\n+          result \u003d null;\n+          break;\n+        }\n       }\n       return result;\n     }\n\\ No newline at end of file\n",
          "actualSource": "    public ScanInfoPerBlockPool call() throws IOException {\n      currentThread \u003d Thread.currentThread();\n\n      String[] bpList \u003d volume.getBlockPoolList();\n      ScanInfoPerBlockPool result \u003d new ScanInfoPerBlockPool(bpList.length);\n      for (String bpid : bpList) {\n        LinkedList\u003cScanInfo\u003e report \u003d new LinkedList\u003c\u003e();\n        File bpFinalizedDir \u003d volume.getFinalizedDir(bpid);\n\n        perfTimer.start();\n        throttleTimer.start();\n\n        try {\n          result.put(bpid,\n              compileReport(volume, bpFinalizedDir, bpFinalizedDir, report));\n        } catch (InterruptedException ex) {\n          // Exit quickly and flag the scanner to do the same\n          result \u003d null;\n          break;\n        }\n      }\n      return result;\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DirectoryScanner.java",
          "extendedDetails": {}
        }
      ]
    },
    "f0c980abed3843923e0eb16b626fa27334195eda": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7819. Log WARN message for the blocks which are not in Block ID based layout (Rakesh R via Colin P. McCabe)\n",
      "commitDate": "26/02/15 11:58 AM",
      "commitName": "f0c980abed3843923e0eb16b626fa27334195eda",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "12/09/14 10:13 PM",
      "commitNameOld": "9f22fb8c9a10952225e15c7b67b5f77fa44b155d",
      "commitAuthorOld": "arp",
      "daysBetweenCommits": 166.61,
      "commitsBetweenForRepo": 1397,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,10 +1,11 @@\n     public ScanInfoPerBlockPool call() throws Exception {\n       String[] bpList \u003d volume.getBlockPoolList();\n       ScanInfoPerBlockPool result \u003d new ScanInfoPerBlockPool(bpList.length);\n       for (String bpid : bpList) {\n         LinkedList\u003cScanInfo\u003e report \u003d new LinkedList\u003cScanInfo\u003e();\n         File bpFinalizedDir \u003d volume.getFinalizedDir(bpid);\n-        result.put(bpid, compileReport(volume, bpFinalizedDir, report));\n+        result.put(bpid,\n+            compileReport(volume, bpFinalizedDir, bpFinalizedDir, report));\n       }\n       return result;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public ScanInfoPerBlockPool call() throws Exception {\n      String[] bpList \u003d volume.getBlockPoolList();\n      ScanInfoPerBlockPool result \u003d new ScanInfoPerBlockPool(bpList.length);\n      for (String bpid : bpList) {\n        LinkedList\u003cScanInfo\u003e report \u003d new LinkedList\u003cScanInfo\u003e();\n        File bpFinalizedDir \u003d volume.getFinalizedDir(bpid);\n        result.put(bpid,\n            compileReport(volume, bpFinalizedDir, bpFinalizedDir, report));\n      }\n      return result;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DirectoryScanner.java",
      "extendedDetails": {}
    },
    "b6ffb08a467f1b5bc89e5114c462c3117b337be6": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2887. FSVolume, is a part of FSDatasetInterface implementation, should not be referred outside FSDataset.  A new FSVolumeInterface is defined.  The BlockVolumeChoosingPolicy.chooseVolume(..) method signature is also updated.  (szetszwo)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1242087 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/02/12 12:58 PM",
      "commitName": "b6ffb08a467f1b5bc89e5114c462c3117b337be6",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "24/08/11 5:14 PM",
      "commitNameOld": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 167.86,
      "commitsBetweenForRepo": 1072,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,10 +1,10 @@\n     public ScanInfoPerBlockPool call() throws Exception {\n       String[] bpList \u003d volume.getBlockPoolList();\n       ScanInfoPerBlockPool result \u003d new ScanInfoPerBlockPool(bpList.length);\n       for (String bpid : bpList) {\n         LinkedList\u003cScanInfo\u003e report \u003d new LinkedList\u003cScanInfo\u003e();\n-        File bpFinalizedDir \u003d volume.getBlockPoolSlice(bpid).getFinalizedDir();\n+        File bpFinalizedDir \u003d volume.getFinalizedDir(bpid);\n         result.put(bpid, compileReport(volume, bpFinalizedDir, report));\n       }\n       return result;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public ScanInfoPerBlockPool call() throws Exception {\n      String[] bpList \u003d volume.getBlockPoolList();\n      ScanInfoPerBlockPool result \u003d new ScanInfoPerBlockPool(bpList.length);\n      for (String bpid : bpList) {\n        LinkedList\u003cScanInfo\u003e report \u003d new LinkedList\u003cScanInfo\u003e();\n        File bpFinalizedDir \u003d volume.getFinalizedDir(bpid);\n        result.put(bpid, compileReport(volume, bpFinalizedDir, report));\n      }\n      return result;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DirectoryScanner.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    public ScanInfoPerBlockPool call() throws Exception {\n      String[] bpList \u003d volume.getBlockPoolList();\n      ScanInfoPerBlockPool result \u003d new ScanInfoPerBlockPool(bpList.length);\n      for (String bpid : bpList) {\n        LinkedList\u003cScanInfo\u003e report \u003d new LinkedList\u003cScanInfo\u003e();\n        File bpFinalizedDir \u003d volume.getBlockPoolSlice(bpid).getFinalizedDir();\n        result.put(bpid, compileReport(volume, bpFinalizedDir, report));\n      }\n      return result;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DirectoryScanner.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DirectoryScanner.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DirectoryScanner.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    public ScanInfoPerBlockPool call() throws Exception {\n      String[] bpList \u003d volume.getBlockPoolList();\n      ScanInfoPerBlockPool result \u003d new ScanInfoPerBlockPool(bpList.length);\n      for (String bpid : bpList) {\n        LinkedList\u003cScanInfo\u003e report \u003d new LinkedList\u003cScanInfo\u003e();\n        File bpFinalizedDir \u003d volume.getBlockPoolSlice(bpid).getFinalizedDir();\n        result.put(bpid, compileReport(volume, bpFinalizedDir, report));\n      }\n      return result;\n    }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DirectoryScanner.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/datanode/DirectoryScanner.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DirectoryScanner.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,10 @@\n+    public ScanInfoPerBlockPool call() throws Exception {\n+      String[] bpList \u003d volume.getBlockPoolList();\n+      ScanInfoPerBlockPool result \u003d new ScanInfoPerBlockPool(bpList.length);\n+      for (String bpid : bpList) {\n+        LinkedList\u003cScanInfo\u003e report \u003d new LinkedList\u003cScanInfo\u003e();\n+        File bpFinalizedDir \u003d volume.getBlockPoolSlice(bpid).getFinalizedDir();\n+        result.put(bpid, compileReport(volume, bpFinalizedDir, report));\n+      }\n+      return result;\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    public ScanInfoPerBlockPool call() throws Exception {\n      String[] bpList \u003d volume.getBlockPoolList();\n      ScanInfoPerBlockPool result \u003d new ScanInfoPerBlockPool(bpList.length);\n      for (String bpid : bpList) {\n        LinkedList\u003cScanInfo\u003e report \u003d new LinkedList\u003cScanInfo\u003e();\n        File bpFinalizedDir \u003d volume.getBlockPoolSlice(bpid).getFinalizedDir();\n        result.put(bpid, compileReport(volume, bpFinalizedDir, report));\n      }\n      return result;\n    }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/datanode/DirectoryScanner.java"
    }
  }
}