{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ClientNamenodeProtocolServerSideTranslatorPB.java",
  "functionName": "getECTopologyResultForPolicies",
  "functionId": "getECTopologyResultForPolicies___controller-RpcController__req-GetECTopologyResultForPoliciesRequestProto",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.java",
  "functionStartLine": 1688,
  "functionEndLine": 1703,
  "numCommitsSeen": 165,
  "timeTaken": 6429,
  "changeHistory": [
    "92c58901d767f4fea571274544a590608c911cb8",
    "14282e311be6ffcaddd2f74fa8e67c4e98a32291"
  ],
  "changeHistoryShort": {
    "92c58901d767f4fea571274544a590608c911cb8": "Ymultichange(Ymovefromfile,Yreturntypechange,Ymodifierchange,Yexceptionschange,Ybodychange,Yparameterchange)",
    "14282e311be6ffcaddd2f74fa8e67c4e98a32291": "Yintroduced"
  },
  "changeHistoryDetails": {
    "92c58901d767f4fea571274544a590608c911cb8": {
      "type": "Ymultichange(Ymovefromfile,Yreturntypechange,Ymodifierchange,Yexceptionschange,Ybodychange,Yparameterchange)",
      "commitMessage": "HDFS-15117. EC: Add getECTopologyResultForPolicies to DistributedFileSystem. Contributed by Ayush Saxena\n",
      "commitDate": "23/01/20 4:48 AM",
      "commitName": "92c58901d767f4fea571274544a590608c911cb8",
      "commitAuthor": "Ayush Saxena",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-15117. EC: Add getECTopologyResultForPolicies to DistributedFileSystem. Contributed by Ayush Saxena\n",
          "commitDate": "23/01/20 4:48 AM",
          "commitName": "92c58901d767f4fea571274544a590608c911cb8",
          "commitAuthor": "Ayush Saxena",
          "commitDateOld": "22/01/20 7:25 AM",
          "commitNameOld": "9520b2ad790bd8527033a03e7ee50da71a85df1d",
          "commitAuthorOld": "Szilard Nemeth",
          "daysBetweenCommits": 0.89,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,14 +1,16 @@\n-  private static ECTopologyVerifierResult getECTopologyResultForPolicies(\n-      final DistributedFileSystem dfs, final String... policyNames)\n-      throws IOException {\n-    ErasureCodingPolicy[] policies \u003d\n-        new ErasureCodingPolicy[policyNames.length];\n-    for (int i \u003d 0; i \u003c policyNames.length; i++) {\n-      policies[i] \u003d\n-        getPolicy(dfs.getClient().getNamenode().getErasureCodingPolicies(),\n-            policyNames[i]);\n+  public GetECTopologyResultForPoliciesResponseProto getECTopologyResultForPolicies(\n+      RpcController controller, GetECTopologyResultForPoliciesRequestProto req)\n+      throws ServiceException {\n+    try {\n+      ProtocolStringList policies \u003d req.getPoliciesList();\n+      ECTopologyVerifierResult result \u003d server.getECTopologyResultForPolicies(\n+          policies.toArray(policies.toArray(new String[policies.size()])));\n+      GetECTopologyResultForPoliciesResponseProto.Builder builder \u003d\n+          GetECTopologyResultForPoliciesResponseProto.newBuilder();\n+      builder\n+          .setResponse(PBHelperClient.convertECTopologyVerifierResult(result));\n+      return builder.build();\n+    } catch (IOException e) {\n+      throw new ServiceException(e);\n     }\n-    final DatanodeInfo[] report \u003d dfs.getClient().getNamenode()\n-        .getDatanodeReport(HdfsConstants.DatanodeReportType.ALL);\n-    return ECTopologyVerifier.getECTopologyVerifierResult(report, policies);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public GetECTopologyResultForPoliciesResponseProto getECTopologyResultForPolicies(\n      RpcController controller, GetECTopologyResultForPoliciesRequestProto req)\n      throws ServiceException {\n    try {\n      ProtocolStringList policies \u003d req.getPoliciesList();\n      ECTopologyVerifierResult result \u003d server.getECTopologyResultForPolicies(\n          policies.toArray(policies.toArray(new String[policies.size()])));\n      GetECTopologyResultForPoliciesResponseProto.Builder builder \u003d\n          GetECTopologyResultForPoliciesResponseProto.newBuilder();\n      builder\n          .setResponse(PBHelperClient.convertECTopologyVerifierResult(result));\n      return builder.build();\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/ECAdmin.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.java",
            "oldMethodName": "getECTopologyResultForPolicies",
            "newMethodName": "getECTopologyResultForPolicies"
          }
        },
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-15117. EC: Add getECTopologyResultForPolicies to DistributedFileSystem. Contributed by Ayush Saxena\n",
          "commitDate": "23/01/20 4:48 AM",
          "commitName": "92c58901d767f4fea571274544a590608c911cb8",
          "commitAuthor": "Ayush Saxena",
          "commitDateOld": "22/01/20 7:25 AM",
          "commitNameOld": "9520b2ad790bd8527033a03e7ee50da71a85df1d",
          "commitAuthorOld": "Szilard Nemeth",
          "daysBetweenCommits": 0.89,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,14 +1,16 @@\n-  private static ECTopologyVerifierResult getECTopologyResultForPolicies(\n-      final DistributedFileSystem dfs, final String... policyNames)\n-      throws IOException {\n-    ErasureCodingPolicy[] policies \u003d\n-        new ErasureCodingPolicy[policyNames.length];\n-    for (int i \u003d 0; i \u003c policyNames.length; i++) {\n-      policies[i] \u003d\n-        getPolicy(dfs.getClient().getNamenode().getErasureCodingPolicies(),\n-            policyNames[i]);\n+  public GetECTopologyResultForPoliciesResponseProto getECTopologyResultForPolicies(\n+      RpcController controller, GetECTopologyResultForPoliciesRequestProto req)\n+      throws ServiceException {\n+    try {\n+      ProtocolStringList policies \u003d req.getPoliciesList();\n+      ECTopologyVerifierResult result \u003d server.getECTopologyResultForPolicies(\n+          policies.toArray(policies.toArray(new String[policies.size()])));\n+      GetECTopologyResultForPoliciesResponseProto.Builder builder \u003d\n+          GetECTopologyResultForPoliciesResponseProto.newBuilder();\n+      builder\n+          .setResponse(PBHelperClient.convertECTopologyVerifierResult(result));\n+      return builder.build();\n+    } catch (IOException e) {\n+      throw new ServiceException(e);\n     }\n-    final DatanodeInfo[] report \u003d dfs.getClient().getNamenode()\n-        .getDatanodeReport(HdfsConstants.DatanodeReportType.ALL);\n-    return ECTopologyVerifier.getECTopologyVerifierResult(report, policies);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public GetECTopologyResultForPoliciesResponseProto getECTopologyResultForPolicies(\n      RpcController controller, GetECTopologyResultForPoliciesRequestProto req)\n      throws ServiceException {\n    try {\n      ProtocolStringList policies \u003d req.getPoliciesList();\n      ECTopologyVerifierResult result \u003d server.getECTopologyResultForPolicies(\n          policies.toArray(policies.toArray(new String[policies.size()])));\n      GetECTopologyResultForPoliciesResponseProto.Builder builder \u003d\n          GetECTopologyResultForPoliciesResponseProto.newBuilder();\n      builder\n          .setResponse(PBHelperClient.convertECTopologyVerifierResult(result));\n      return builder.build();\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.java",
          "extendedDetails": {
            "oldValue": "ECTopologyVerifierResult",
            "newValue": "GetECTopologyResultForPoliciesResponseProto"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-15117. EC: Add getECTopologyResultForPolicies to DistributedFileSystem. Contributed by Ayush Saxena\n",
          "commitDate": "23/01/20 4:48 AM",
          "commitName": "92c58901d767f4fea571274544a590608c911cb8",
          "commitAuthor": "Ayush Saxena",
          "commitDateOld": "22/01/20 7:25 AM",
          "commitNameOld": "9520b2ad790bd8527033a03e7ee50da71a85df1d",
          "commitAuthorOld": "Szilard Nemeth",
          "daysBetweenCommits": 0.89,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,14 +1,16 @@\n-  private static ECTopologyVerifierResult getECTopologyResultForPolicies(\n-      final DistributedFileSystem dfs, final String... policyNames)\n-      throws IOException {\n-    ErasureCodingPolicy[] policies \u003d\n-        new ErasureCodingPolicy[policyNames.length];\n-    for (int i \u003d 0; i \u003c policyNames.length; i++) {\n-      policies[i] \u003d\n-        getPolicy(dfs.getClient().getNamenode().getErasureCodingPolicies(),\n-            policyNames[i]);\n+  public GetECTopologyResultForPoliciesResponseProto getECTopologyResultForPolicies(\n+      RpcController controller, GetECTopologyResultForPoliciesRequestProto req)\n+      throws ServiceException {\n+    try {\n+      ProtocolStringList policies \u003d req.getPoliciesList();\n+      ECTopologyVerifierResult result \u003d server.getECTopologyResultForPolicies(\n+          policies.toArray(policies.toArray(new String[policies.size()])));\n+      GetECTopologyResultForPoliciesResponseProto.Builder builder \u003d\n+          GetECTopologyResultForPoliciesResponseProto.newBuilder();\n+      builder\n+          .setResponse(PBHelperClient.convertECTopologyVerifierResult(result));\n+      return builder.build();\n+    } catch (IOException e) {\n+      throw new ServiceException(e);\n     }\n-    final DatanodeInfo[] report \u003d dfs.getClient().getNamenode()\n-        .getDatanodeReport(HdfsConstants.DatanodeReportType.ALL);\n-    return ECTopologyVerifier.getECTopologyVerifierResult(report, policies);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public GetECTopologyResultForPoliciesResponseProto getECTopologyResultForPolicies(\n      RpcController controller, GetECTopologyResultForPoliciesRequestProto req)\n      throws ServiceException {\n    try {\n      ProtocolStringList policies \u003d req.getPoliciesList();\n      ECTopologyVerifierResult result \u003d server.getECTopologyResultForPolicies(\n          policies.toArray(policies.toArray(new String[policies.size()])));\n      GetECTopologyResultForPoliciesResponseProto.Builder builder \u003d\n          GetECTopologyResultForPoliciesResponseProto.newBuilder();\n      builder\n          .setResponse(PBHelperClient.convertECTopologyVerifierResult(result));\n      return builder.build();\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.java",
          "extendedDetails": {
            "oldValue": "[private, static]",
            "newValue": "[public]"
          }
        },
        {
          "type": "Yexceptionschange",
          "commitMessage": "HDFS-15117. EC: Add getECTopologyResultForPolicies to DistributedFileSystem. Contributed by Ayush Saxena\n",
          "commitDate": "23/01/20 4:48 AM",
          "commitName": "92c58901d767f4fea571274544a590608c911cb8",
          "commitAuthor": "Ayush Saxena",
          "commitDateOld": "22/01/20 7:25 AM",
          "commitNameOld": "9520b2ad790bd8527033a03e7ee50da71a85df1d",
          "commitAuthorOld": "Szilard Nemeth",
          "daysBetweenCommits": 0.89,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,14 +1,16 @@\n-  private static ECTopologyVerifierResult getECTopologyResultForPolicies(\n-      final DistributedFileSystem dfs, final String... policyNames)\n-      throws IOException {\n-    ErasureCodingPolicy[] policies \u003d\n-        new ErasureCodingPolicy[policyNames.length];\n-    for (int i \u003d 0; i \u003c policyNames.length; i++) {\n-      policies[i] \u003d\n-        getPolicy(dfs.getClient().getNamenode().getErasureCodingPolicies(),\n-            policyNames[i]);\n+  public GetECTopologyResultForPoliciesResponseProto getECTopologyResultForPolicies(\n+      RpcController controller, GetECTopologyResultForPoliciesRequestProto req)\n+      throws ServiceException {\n+    try {\n+      ProtocolStringList policies \u003d req.getPoliciesList();\n+      ECTopologyVerifierResult result \u003d server.getECTopologyResultForPolicies(\n+          policies.toArray(policies.toArray(new String[policies.size()])));\n+      GetECTopologyResultForPoliciesResponseProto.Builder builder \u003d\n+          GetECTopologyResultForPoliciesResponseProto.newBuilder();\n+      builder\n+          .setResponse(PBHelperClient.convertECTopologyVerifierResult(result));\n+      return builder.build();\n+    } catch (IOException e) {\n+      throw new ServiceException(e);\n     }\n-    final DatanodeInfo[] report \u003d dfs.getClient().getNamenode()\n-        .getDatanodeReport(HdfsConstants.DatanodeReportType.ALL);\n-    return ECTopologyVerifier.getECTopologyVerifierResult(report, policies);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public GetECTopologyResultForPoliciesResponseProto getECTopologyResultForPolicies(\n      RpcController controller, GetECTopologyResultForPoliciesRequestProto req)\n      throws ServiceException {\n    try {\n      ProtocolStringList policies \u003d req.getPoliciesList();\n      ECTopologyVerifierResult result \u003d server.getECTopologyResultForPolicies(\n          policies.toArray(policies.toArray(new String[policies.size()])));\n      GetECTopologyResultForPoliciesResponseProto.Builder builder \u003d\n          GetECTopologyResultForPoliciesResponseProto.newBuilder();\n      builder\n          .setResponse(PBHelperClient.convertECTopologyVerifierResult(result));\n      return builder.build();\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.java",
          "extendedDetails": {
            "oldValue": "[IOException]",
            "newValue": "[ServiceException]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-15117. EC: Add getECTopologyResultForPolicies to DistributedFileSystem. Contributed by Ayush Saxena\n",
          "commitDate": "23/01/20 4:48 AM",
          "commitName": "92c58901d767f4fea571274544a590608c911cb8",
          "commitAuthor": "Ayush Saxena",
          "commitDateOld": "22/01/20 7:25 AM",
          "commitNameOld": "9520b2ad790bd8527033a03e7ee50da71a85df1d",
          "commitAuthorOld": "Szilard Nemeth",
          "daysBetweenCommits": 0.89,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,14 +1,16 @@\n-  private static ECTopologyVerifierResult getECTopologyResultForPolicies(\n-      final DistributedFileSystem dfs, final String... policyNames)\n-      throws IOException {\n-    ErasureCodingPolicy[] policies \u003d\n-        new ErasureCodingPolicy[policyNames.length];\n-    for (int i \u003d 0; i \u003c policyNames.length; i++) {\n-      policies[i] \u003d\n-        getPolicy(dfs.getClient().getNamenode().getErasureCodingPolicies(),\n-            policyNames[i]);\n+  public GetECTopologyResultForPoliciesResponseProto getECTopologyResultForPolicies(\n+      RpcController controller, GetECTopologyResultForPoliciesRequestProto req)\n+      throws ServiceException {\n+    try {\n+      ProtocolStringList policies \u003d req.getPoliciesList();\n+      ECTopologyVerifierResult result \u003d server.getECTopologyResultForPolicies(\n+          policies.toArray(policies.toArray(new String[policies.size()])));\n+      GetECTopologyResultForPoliciesResponseProto.Builder builder \u003d\n+          GetECTopologyResultForPoliciesResponseProto.newBuilder();\n+      builder\n+          .setResponse(PBHelperClient.convertECTopologyVerifierResult(result));\n+      return builder.build();\n+    } catch (IOException e) {\n+      throw new ServiceException(e);\n     }\n-    final DatanodeInfo[] report \u003d dfs.getClient().getNamenode()\n-        .getDatanodeReport(HdfsConstants.DatanodeReportType.ALL);\n-    return ECTopologyVerifier.getECTopologyVerifierResult(report, policies);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public GetECTopologyResultForPoliciesResponseProto getECTopologyResultForPolicies(\n      RpcController controller, GetECTopologyResultForPoliciesRequestProto req)\n      throws ServiceException {\n    try {\n      ProtocolStringList policies \u003d req.getPoliciesList();\n      ECTopologyVerifierResult result \u003d server.getECTopologyResultForPolicies(\n          policies.toArray(policies.toArray(new String[policies.size()])));\n      GetECTopologyResultForPoliciesResponseProto.Builder builder \u003d\n          GetECTopologyResultForPoliciesResponseProto.newBuilder();\n      builder\n          .setResponse(PBHelperClient.convertECTopologyVerifierResult(result));\n      return builder.build();\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.java",
          "extendedDetails": {}
        },
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-15117. EC: Add getECTopologyResultForPolicies to DistributedFileSystem. Contributed by Ayush Saxena\n",
          "commitDate": "23/01/20 4:48 AM",
          "commitName": "92c58901d767f4fea571274544a590608c911cb8",
          "commitAuthor": "Ayush Saxena",
          "commitDateOld": "22/01/20 7:25 AM",
          "commitNameOld": "9520b2ad790bd8527033a03e7ee50da71a85df1d",
          "commitAuthorOld": "Szilard Nemeth",
          "daysBetweenCommits": 0.89,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,14 +1,16 @@\n-  private static ECTopologyVerifierResult getECTopologyResultForPolicies(\n-      final DistributedFileSystem dfs, final String... policyNames)\n-      throws IOException {\n-    ErasureCodingPolicy[] policies \u003d\n-        new ErasureCodingPolicy[policyNames.length];\n-    for (int i \u003d 0; i \u003c policyNames.length; i++) {\n-      policies[i] \u003d\n-        getPolicy(dfs.getClient().getNamenode().getErasureCodingPolicies(),\n-            policyNames[i]);\n+  public GetECTopologyResultForPoliciesResponseProto getECTopologyResultForPolicies(\n+      RpcController controller, GetECTopologyResultForPoliciesRequestProto req)\n+      throws ServiceException {\n+    try {\n+      ProtocolStringList policies \u003d req.getPoliciesList();\n+      ECTopologyVerifierResult result \u003d server.getECTopologyResultForPolicies(\n+          policies.toArray(policies.toArray(new String[policies.size()])));\n+      GetECTopologyResultForPoliciesResponseProto.Builder builder \u003d\n+          GetECTopologyResultForPoliciesResponseProto.newBuilder();\n+      builder\n+          .setResponse(PBHelperClient.convertECTopologyVerifierResult(result));\n+      return builder.build();\n+    } catch (IOException e) {\n+      throw new ServiceException(e);\n     }\n-    final DatanodeInfo[] report \u003d dfs.getClient().getNamenode()\n-        .getDatanodeReport(HdfsConstants.DatanodeReportType.ALL);\n-    return ECTopologyVerifier.getECTopologyVerifierResult(report, policies);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public GetECTopologyResultForPoliciesResponseProto getECTopologyResultForPolicies(\n      RpcController controller, GetECTopologyResultForPoliciesRequestProto req)\n      throws ServiceException {\n    try {\n      ProtocolStringList policies \u003d req.getPoliciesList();\n      ECTopologyVerifierResult result \u003d server.getECTopologyResultForPolicies(\n          policies.toArray(policies.toArray(new String[policies.size()])));\n      GetECTopologyResultForPoliciesResponseProto.Builder builder \u003d\n          GetECTopologyResultForPoliciesResponseProto.newBuilder();\n      builder\n          .setResponse(PBHelperClient.convertECTopologyVerifierResult(result));\n      return builder.build();\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.java",
          "extendedDetails": {
            "oldValue": "[dfs-DistributedFileSystem(modifiers-final), policyNames-String(modifiers-final)]",
            "newValue": "[controller-RpcController, req-GetECTopologyResultForPoliciesRequestProto]"
          }
        }
      ]
    },
    "14282e311be6ffcaddd2f74fa8e67c4e98a32291": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-14188. Make hdfs ec -verifyClusterSetup command accept an erasure coding policy as a parameter. Contributed by Kitti Nanasi.\n\nSigned-off-by: Wei-Chiu Chuang \u003cweichiu@apache.org\u003e\n",
      "commitDate": "19/02/19 12:04 PM",
      "commitName": "14282e311be6ffcaddd2f74fa8e67c4e98a32291",
      "commitAuthor": "Kitti Nanasi",
      "diff": "@@ -0,0 +1,14 @@\n+  private static ECTopologyVerifierResult getECTopologyResultForPolicies(\n+      final DistributedFileSystem dfs, final String... policyNames)\n+      throws IOException {\n+    ErasureCodingPolicy[] policies \u003d\n+        new ErasureCodingPolicy[policyNames.length];\n+    for (int i \u003d 0; i \u003c policyNames.length; i++) {\n+      policies[i] \u003d\n+        getPolicy(dfs.getClient().getNamenode().getErasureCodingPolicies(),\n+            policyNames[i]);\n+    }\n+    final DatanodeInfo[] report \u003d dfs.getClient().getNamenode()\n+        .getDatanodeReport(HdfsConstants.DatanodeReportType.ALL);\n+    return ECTopologyVerifier.getECTopologyVerifierResult(report, policies);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private static ECTopologyVerifierResult getECTopologyResultForPolicies(\n      final DistributedFileSystem dfs, final String... policyNames)\n      throws IOException {\n    ErasureCodingPolicy[] policies \u003d\n        new ErasureCodingPolicy[policyNames.length];\n    for (int i \u003d 0; i \u003c policyNames.length; i++) {\n      policies[i] \u003d\n        getPolicy(dfs.getClient().getNamenode().getErasureCodingPolicies(),\n            policyNames[i]);\n    }\n    final DatanodeInfo[] report \u003d dfs.getClient().getNamenode()\n        .getDatanodeReport(HdfsConstants.DatanodeReportType.ALL);\n    return ECTopologyVerifier.getECTopologyVerifierResult(report, policies);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/ECAdmin.java"
    }
  }
}