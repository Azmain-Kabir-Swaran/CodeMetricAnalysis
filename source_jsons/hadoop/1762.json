{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "PacketReceiver.java",
  "functionName": "reallocPacketBuf",
  "functionId": "reallocPacketBuf___atLeastCapacity-int",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/PacketReceiver.java",
  "functionStartLine": 263,
  "functionEndLine": 284,
  "numCommitsSeen": 11,
  "timeTaken": 1338,
  "changeHistory": [
    "826ae1c26d31f87d88efc920b271bec7eec2e17a",
    "ded304e6a6e74742f6f4a35989f762dcefa234cb",
    "9ea7c06468d236452f03c38a31d1a45f7f09dc50"
  ],
  "changeHistoryShort": {
    "826ae1c26d31f87d88efc920b271bec7eec2e17a": "Yfilerename",
    "ded304e6a6e74742f6f4a35989f762dcefa234cb": "Ybodychange",
    "9ea7c06468d236452f03c38a31d1a45f7f09dc50": "Yintroduced"
  },
  "changeHistoryDetails": {
    "826ae1c26d31f87d88efc920b271bec7eec2e17a": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8990. Move RemoteBlockReader to hdfs-client module. Contributed by Mingliang Liu.\n",
      "commitDate": "31/08/15 1:54 PM",
      "commitName": "826ae1c26d31f87d88efc920b271bec7eec2e17a",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "31/08/15 11:48 AM",
      "commitNameOld": "caa04de149030691b7bc952b534c6128db217ed2",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 0.09,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private void reallocPacketBuf(int atLeastCapacity) {\n    // Realloc the buffer if this packet is longer than the previous\n    // one.\n    if (curPacketBuf \u003d\u003d null ||\n        curPacketBuf.capacity() \u003c atLeastCapacity) {\n      ByteBuffer newBuf;\n      if (useDirectBuffers) {\n        newBuf \u003d bufferPool.getBuffer(atLeastCapacity);\n      } else {\n        newBuf \u003d ByteBuffer.allocate(atLeastCapacity);\n      }\n      // If reallocing an existing buffer, copy the old packet length\n      // prefixes over\n      if (curPacketBuf !\u003d null) {\n        curPacketBuf.flip();\n        newBuf.put(curPacketBuf);\n      }\n      \n      returnPacketBufToPool();\n      curPacketBuf \u003d newBuf;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/PacketReceiver.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/PacketReceiver.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/PacketReceiver.java"
      }
    },
    "ded304e6a6e74742f6f4a35989f762dcefa234cb": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4049. Fix hflush performance regression due to nagling delays. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1398591 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "15/10/12 5:55 PM",
      "commitName": "ded304e6a6e74742f6f4a35989f762dcefa234cb",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "09/08/12 2:31 PM",
      "commitNameOld": "9ea7c06468d236452f03c38a31d1a45f7f09dc50",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 67.14,
      "commitsBetweenForRepo": 411,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,22 @@\n   private void reallocPacketBuf(int atLeastCapacity) {\n     // Realloc the buffer if this packet is longer than the previous\n     // one.\n     if (curPacketBuf \u003d\u003d null ||\n         curPacketBuf.capacity() \u003c atLeastCapacity) {\n-      returnPacketBufToPool();\n+      ByteBuffer newBuf;\n       if (useDirectBuffers) {\n-        curPacketBuf \u003d bufferPool.getBuffer(atLeastCapacity);\n+        newBuf \u003d bufferPool.getBuffer(atLeastCapacity);\n       } else {\n-        curPacketBuf \u003d ByteBuffer.allocate(atLeastCapacity);\n+        newBuf \u003d ByteBuffer.allocate(atLeastCapacity);\n       }\n+      // If reallocing an existing buffer, copy the old packet length\n+      // prefixes over\n+      if (curPacketBuf !\u003d null) {\n+        curPacketBuf.flip();\n+        newBuf.put(curPacketBuf);\n+      }\n+      \n+      returnPacketBufToPool();\n+      curPacketBuf \u003d newBuf;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void reallocPacketBuf(int atLeastCapacity) {\n    // Realloc the buffer if this packet is longer than the previous\n    // one.\n    if (curPacketBuf \u003d\u003d null ||\n        curPacketBuf.capacity() \u003c atLeastCapacity) {\n      ByteBuffer newBuf;\n      if (useDirectBuffers) {\n        newBuf \u003d bufferPool.getBuffer(atLeastCapacity);\n      } else {\n        newBuf \u003d ByteBuffer.allocate(atLeastCapacity);\n      }\n      // If reallocing an existing buffer, copy the old packet length\n      // prefixes over\n      if (curPacketBuf !\u003d null) {\n        curPacketBuf.flip();\n        newBuf.put(curPacketBuf);\n      }\n      \n      returnPacketBufToPool();\n      curPacketBuf \u003d newBuf;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/PacketReceiver.java",
      "extendedDetails": {}
    },
    "9ea7c06468d236452f03c38a31d1a45f7f09dc50": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-3721. hsync support broke wire compatibility. Contributed by Todd Lipcon and Aaron T. Myers.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1371495 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/08/12 2:31 PM",
      "commitName": "9ea7c06468d236452f03c38a31d1a45f7f09dc50",
      "commitAuthor": "Aaron Myers",
      "diff": "@@ -0,0 +1,13 @@\n+  private void reallocPacketBuf(int atLeastCapacity) {\n+    // Realloc the buffer if this packet is longer than the previous\n+    // one.\n+    if (curPacketBuf \u003d\u003d null ||\n+        curPacketBuf.capacity() \u003c atLeastCapacity) {\n+      returnPacketBufToPool();\n+      if (useDirectBuffers) {\n+        curPacketBuf \u003d bufferPool.getBuffer(atLeastCapacity);\n+      } else {\n+        curPacketBuf \u003d ByteBuffer.allocate(atLeastCapacity);\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void reallocPacketBuf(int atLeastCapacity) {\n    // Realloc the buffer if this packet is longer than the previous\n    // one.\n    if (curPacketBuf \u003d\u003d null ||\n        curPacketBuf.capacity() \u003c atLeastCapacity) {\n      returnPacketBufToPool();\n      if (useDirectBuffers) {\n        curPacketBuf \u003d bufferPool.getBuffer(atLeastCapacity);\n      } else {\n        curPacketBuf \u003d ByteBuffer.allocate(atLeastCapacity);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/PacketReceiver.java"
    }
  }
}