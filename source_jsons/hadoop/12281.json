{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DataNode.java",
  "functionName": "getVolumeReport",
  "functionId": "getVolumeReport",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java",
  "functionStartLine": 3732,
  "functionEndLine": 3753,
  "numCommitsSeen": 358,
  "timeTaken": 2117,
  "changeHistory": [
    "dfcb331ba3516264398121c9f23af3a79c0509cc"
  ],
  "changeHistoryShort": {
    "dfcb331ba3516264398121c9f23af3a79c0509cc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "dfcb331ba3516264398121c9f23af3a79c0509cc": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-13076: [SPS]: Addendum. Resolve conflicts after rebasing branch to trunk. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "dfcb331ba3516264398121c9f23af3a79c0509cc",
      "commitAuthor": "Rakesh Radhakrishnan",
      "diff": "@@ -0,0 +1,22 @@\n+  public List\u003cDatanodeVolumeInfo\u003e getVolumeReport() throws IOException {\n+    checkSuperuserPrivilege();\n+    Map\u003cString, Object\u003e volumeInfoMap \u003d data.getVolumeInfoMap();\n+    if (volumeInfoMap \u003d\u003d null) {\n+      LOG.warn(\"DataNode volume info not available.\");\n+      return new ArrayList\u003c\u003e(0);\n+    }\n+    List\u003cDatanodeVolumeInfo\u003e volumeInfoList \u003d new ArrayList\u003c\u003e();\n+    for (Entry\u003cString, Object\u003e volume : volumeInfoMap.entrySet()) {\n+      @SuppressWarnings(\"unchecked\")\n+      Map\u003cString, Object\u003e volumeInfo \u003d (Map\u003cString, Object\u003e) volume.getValue();\n+      DatanodeVolumeInfo dnStorageInfo \u003d new DatanodeVolumeInfo(\n+          volume.getKey(), (Long) volumeInfo.get(\"usedSpace\"),\n+          (Long) volumeInfo.get(\"freeSpace\"),\n+          (Long) volumeInfo.get(\"reservedSpace\"),\n+          (Long) volumeInfo.get(\"reservedSpaceForReplicas\"),\n+          (Long) volumeInfo.get(\"numBlocks\"),\n+          (StorageType) volumeInfo.get(\"storageType\"));\n+      volumeInfoList.add(dnStorageInfo);\n+    }\n+    return volumeInfoList;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public List\u003cDatanodeVolumeInfo\u003e getVolumeReport() throws IOException {\n    checkSuperuserPrivilege();\n    Map\u003cString, Object\u003e volumeInfoMap \u003d data.getVolumeInfoMap();\n    if (volumeInfoMap \u003d\u003d null) {\n      LOG.warn(\"DataNode volume info not available.\");\n      return new ArrayList\u003c\u003e(0);\n    }\n    List\u003cDatanodeVolumeInfo\u003e volumeInfoList \u003d new ArrayList\u003c\u003e();\n    for (Entry\u003cString, Object\u003e volume : volumeInfoMap.entrySet()) {\n      @SuppressWarnings(\"unchecked\")\n      Map\u003cString, Object\u003e volumeInfo \u003d (Map\u003cString, Object\u003e) volume.getValue();\n      DatanodeVolumeInfo dnStorageInfo \u003d new DatanodeVolumeInfo(\n          volume.getKey(), (Long) volumeInfo.get(\"usedSpace\"),\n          (Long) volumeInfo.get(\"freeSpace\"),\n          (Long) volumeInfo.get(\"reservedSpace\"),\n          (Long) volumeInfo.get(\"reservedSpaceForReplicas\"),\n          (Long) volumeInfo.get(\"numBlocks\"),\n          (StorageType) volumeInfo.get(\"storageType\"));\n      volumeInfoList.add(dnStorageInfo);\n    }\n    return volumeInfoList;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java"
    }
  }
}