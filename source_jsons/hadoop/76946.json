{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "HHXORErasureDecodingStep.java",
  "functionName": "doDecodeByPiggyBack",
  "functionId": "doDecodeByPiggyBack___inputs-byte[][]__inputOffsets-int[]__outputs-byte[]__outOffset-int__piggyBack-byte[]__erasedLocationToFix-int__bufSize-int",
  "sourceFilePath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/coder/HHXORErasureDecodingStep.java",
  "functionStartLine": 246,
  "functionEndLine": 263,
  "numCommitsSeen": 3,
  "timeTaken": 584,
  "changeHistory": [
    "1bb31fb22e6f8e6df8e9ff4e94adf20308b4c743"
  ],
  "changeHistoryShort": {
    "1bb31fb22e6f8e6df8e9ff4e94adf20308b4c743": "Yintroduced"
  },
  "changeHistoryDetails": {
    "1bb31fb22e6f8e6df8e9ff4e94adf20308b4c743": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-11828. Implement the Hitchhiker erasure coding algorithm. Contributed by Jack Liu Quan.\n\nChange-Id: If43475ccc2574df60949c947af562722db076251\n",
      "commitDate": "21/01/16 10:30 AM",
      "commitName": "1bb31fb22e6f8e6df8e9ff4e94adf20308b4c743",
      "commitAuthor": "Zhe Zhang",
      "diff": "@@ -0,0 +1,18 @@\n+  private void doDecodeByPiggyBack(byte[][] inputs, int[] inputOffsets,\n+                                   byte[] outputs, int outOffset,\n+                                   byte[] piggyBack, int erasedLocationToFix,\n+                                   int bufSize) {\n+    final int thisPiggyBackSetIdx \u003d piggyBackFullIndex[erasedLocationToFix];\n+    final int startIndex \u003d piggyBackIndex[thisPiggyBackSetIdx - 1];\n+    final int endIndex \u003d piggyBackIndex[thisPiggyBackSetIdx];\n+\n+    // recover first sub-stripe data by XOR piggyback\n+    for (int i \u003d 0; i \u003c bufSize; i++) {\n+      for (int j \u003d startIndex; j \u003c endIndex; j++) {\n+        if (inputs[j] !\u003d null) {\n+          piggyBack[i] \u003d (byte) (piggyBack[i] ^ inputs[j][i + inputOffsets[j]]);\n+        }\n+      }\n+      outputs[i + outOffset] \u003d piggyBack[i];\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void doDecodeByPiggyBack(byte[][] inputs, int[] inputOffsets,\n                                   byte[] outputs, int outOffset,\n                                   byte[] piggyBack, int erasedLocationToFix,\n                                   int bufSize) {\n    final int thisPiggyBackSetIdx \u003d piggyBackFullIndex[erasedLocationToFix];\n    final int startIndex \u003d piggyBackIndex[thisPiggyBackSetIdx - 1];\n    final int endIndex \u003d piggyBackIndex[thisPiggyBackSetIdx];\n\n    // recover first sub-stripe data by XOR piggyback\n    for (int i \u003d 0; i \u003c bufSize; i++) {\n      for (int j \u003d startIndex; j \u003c endIndex; j++) {\n        if (inputs[j] !\u003d null) {\n          piggyBack[i] \u003d (byte) (piggyBack[i] ^ inputs[j][i + inputOffsets[j]]);\n        }\n      }\n      outputs[i + outOffset] \u003d piggyBack[i];\n    }\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/coder/HHXORErasureDecodingStep.java"
    }
  }
}