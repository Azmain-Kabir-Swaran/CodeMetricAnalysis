{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DFSStripedOutputStream.java",
  "functionName": "checkStreamers",
  "functionId": "checkStreamers",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSStripedOutputStream.java",
  "functionStartLine": 393,
  "functionEndLine": 415,
  "numCommitsSeen": 38,
  "timeTaken": 1654,
  "changeHistory": [
    "1d772dc5429bfffa015a1209e6f4a864505c871a",
    "5dba54596a1587e0ba5f9f02f40483e597b0df64"
  ],
  "changeHistoryShort": {
    "1d772dc5429bfffa015a1209e6f4a864505c871a": "Ybodychange",
    "5dba54596a1587e0ba5f9f02f40483e597b0df64": "Ybodychange"
  },
  "changeHistoryDetails": {
    "1d772dc5429bfffa015a1209e6f4a864505c871a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-15211. EC: File write hangs during close in case of Exception during updatePipeline. Contributed by Ayush Saxena.\n",
      "commitDate": "15/03/20 8:14 AM",
      "commitName": "1d772dc5429bfffa015a1209e6f4a864505c871a",
      "commitAuthor": "Surendra Singh Lilhore",
      "commitDateOld": "24/12/19 9:37 PM",
      "commitNameOld": "df622cf4a32ee172ded6c4b3b97a1e49befc4f10",
      "commitAuthorOld": "Ayush Saxena",
      "daysBetweenCommits": 81.4,
      "commitsBetweenForRepo": 272,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,23 @@\n   private Set\u003cStripedDataStreamer\u003e checkStreamers() throws IOException {\n     Set\u003cStripedDataStreamer\u003e newFailed \u003d new HashSet\u003c\u003e();\n     for(StripedDataStreamer s : streamers) {\n       if (!s.isHealthy() \u0026\u0026 !failedStreamers.contains(s)) {\n         newFailed.add(s);\n       }\n     }\n \n     final int failCount \u003d failedStreamers.size() + newFailed.size();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"checkStreamers: \" + streamers);\n       LOG.debug(\"healthy streamer count\u003d\" + (numAllBlocks - failCount));\n       LOG.debug(\"original failed streamers: \" + failedStreamers);\n       LOG.debug(\"newly failed streamers: \" + newFailed);\n     }\n     if (failCount \u003e (numAllBlocks - numDataBlocks)) {\n+      closeAllStreamers();\n       throw new IOException(\"Failed: the number of failed blocks \u003d \"\n           + failCount + \" \u003e the number of parity blocks \u003d \"\n           + (numAllBlocks - numDataBlocks));\n     }\n     return newFailed;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private Set\u003cStripedDataStreamer\u003e checkStreamers() throws IOException {\n    Set\u003cStripedDataStreamer\u003e newFailed \u003d new HashSet\u003c\u003e();\n    for(StripedDataStreamer s : streamers) {\n      if (!s.isHealthy() \u0026\u0026 !failedStreamers.contains(s)) {\n        newFailed.add(s);\n      }\n    }\n\n    final int failCount \u003d failedStreamers.size() + newFailed.size();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"checkStreamers: \" + streamers);\n      LOG.debug(\"healthy streamer count\u003d\" + (numAllBlocks - failCount));\n      LOG.debug(\"original failed streamers: \" + failedStreamers);\n      LOG.debug(\"newly failed streamers: \" + newFailed);\n    }\n    if (failCount \u003e (numAllBlocks - numDataBlocks)) {\n      closeAllStreamers();\n      throw new IOException(\"Failed: the number of failed blocks \u003d \"\n          + failCount + \" \u003e the number of parity blocks \u003d \"\n          + (numAllBlocks - numDataBlocks));\n    }\n    return newFailed;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSStripedOutputStream.java",
      "extendedDetails": {}
    },
    "5dba54596a1587e0ba5f9f02f40483e597b0df64": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12388. A bad error message in DFSStripedOutputStream. Contributed by Huafeng Wang\n",
      "commitDate": "05/09/17 2:46 AM",
      "commitName": "5dba54596a1587e0ba5f9f02f40483e597b0df64",
      "commitAuthor": "Kai Zheng",
      "commitDateOld": "30/08/17 12:28 AM",
      "commitNameOld": "200b11368d3954138a9bce128c8fa763b4a503a1",
      "commitAuthorOld": "Rakesh Radhakrishnan",
      "daysBetweenCommits": 6.1,
      "commitsBetweenForRepo": 36,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,22 @@\n   private Set\u003cStripedDataStreamer\u003e checkStreamers() throws IOException {\n     Set\u003cStripedDataStreamer\u003e newFailed \u003d new HashSet\u003c\u003e();\n     for(StripedDataStreamer s : streamers) {\n       if (!s.isHealthy() \u0026\u0026 !failedStreamers.contains(s)) {\n         newFailed.add(s);\n       }\n     }\n \n     final int failCount \u003d failedStreamers.size() + newFailed.size();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"checkStreamers: \" + streamers);\n       LOG.debug(\"healthy streamer count\u003d\" + (numAllBlocks - failCount));\n       LOG.debug(\"original failed streamers: \" + failedStreamers);\n       LOG.debug(\"newly failed streamers: \" + newFailed);\n     }\n     if (failCount \u003e (numAllBlocks - numDataBlocks)) {\n       throw new IOException(\"Failed: the number of failed blocks \u003d \"\n-          + failCount + \" \u003e the number of data blocks \u003d \"\n+          + failCount + \" \u003e the number of parity blocks \u003d \"\n           + (numAllBlocks - numDataBlocks));\n     }\n     return newFailed;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private Set\u003cStripedDataStreamer\u003e checkStreamers() throws IOException {\n    Set\u003cStripedDataStreamer\u003e newFailed \u003d new HashSet\u003c\u003e();\n    for(StripedDataStreamer s : streamers) {\n      if (!s.isHealthy() \u0026\u0026 !failedStreamers.contains(s)) {\n        newFailed.add(s);\n      }\n    }\n\n    final int failCount \u003d failedStreamers.size() + newFailed.size();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"checkStreamers: \" + streamers);\n      LOG.debug(\"healthy streamer count\u003d\" + (numAllBlocks - failCount));\n      LOG.debug(\"original failed streamers: \" + failedStreamers);\n      LOG.debug(\"newly failed streamers: \" + newFailed);\n    }\n    if (failCount \u003e (numAllBlocks - numDataBlocks)) {\n      throw new IOException(\"Failed: the number of failed blocks \u003d \"\n          + failCount + \" \u003e the number of parity blocks \u003d \"\n          + (numAllBlocks - numDataBlocks));\n    }\n    return newFailed;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSStripedOutputStream.java",
      "extendedDetails": {}
    }
  }
}