{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "WebHdfsHandler.java",
  "functionName": "channelRead0",
  "functionId": "channelRead0___ctx-ChannelHandlerContext(modifiers-final)__req-HttpRequest(modifiers-final)",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/web/webhdfs/WebHdfsHandler.java",
  "functionStartLine": 123,
  "functionEndLine": 153,
  "numCommitsSeen": 19,
  "timeTaken": 4156,
  "changeHistory": [
    "da0006fe0473e353ee2d489156248a01aa982dfd",
    "46d29e3d7ee8dc9bb1818b886d9cc5336b1d67a4",
    "5e74196ede9bfc20eb6d6fe3aa6a0e5c47a40fdd",
    "88da9f6b6782423acd8ab7eb7d938720de7f3c0f",
    "bf74dbf80dc9379d669779a598950908adffb8a7",
    "88beb46cf6e6fd3e51f73a411a2750de7595e326",
    "84cbd72afda6344e220526fac5c560f00f84e374",
    "ada233b7cd7db39e609bb57e487fee8cec59cd48",
    "bf8e4332cb4c33d0287ae6ecca61b335402ac1c4"
  ],
  "changeHistoryShort": {
    "da0006fe0473e353ee2d489156248a01aa982dfd": "Ybodychange",
    "46d29e3d7ee8dc9bb1818b886d9cc5336b1d67a4": "Ybodychange",
    "5e74196ede9bfc20eb6d6fe3aa6a0e5c47a40fdd": "Ybodychange",
    "88da9f6b6782423acd8ab7eb7d938720de7f3c0f": "Ybodychange",
    "bf74dbf80dc9379d669779a598950908adffb8a7": "Ybodychange",
    "88beb46cf6e6fd3e51f73a411a2750de7595e326": "Ybodychange",
    "84cbd72afda6344e220526fac5c560f00f84e374": "Ybodychange",
    "ada233b7cd7db39e609bb57e487fee8cec59cd48": "Ybodychange",
    "bf8e4332cb4c33d0287ae6ecca61b335402ac1c4": "Yintroduced"
  },
  "changeHistoryDetails": {
    "da0006fe0473e353ee2d489156248a01aa982dfd": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14423. Percent (%) and plus (+) characters no longer work in WebHDFS.\n\nSigned-off-by: Masatake Iwasaki \u003ciwasakims@apache.org\u003e\n",
      "commitDate": "13/08/19 4:39 PM",
      "commitName": "da0006fe0473e353ee2d489156248a01aa982dfd",
      "commitAuthor": "Masatake Iwasaki",
      "commitDateOld": "06/09/18 2:48 PM",
      "commitNameOld": "eca1a4bfe952fc184fe90dde50bac9b0e5293568",
      "commitAuthorOld": "Giovanni Matteo Fumarola",
      "daysBetweenCommits": 341.08,
      "commitsBetweenForRepo": 2650,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,31 +1,31 @@\n   public void channelRead0(final ChannelHandlerContext ctx,\n                            final HttpRequest req) throws Exception {\n     Preconditions.checkArgument(req.getUri().startsWith(WEBHDFS_PREFIX));\n     QueryStringDecoder queryString \u003d new QueryStringDecoder(req.getUri());\n     params \u003d new ParameterParser(queryString, conf);\n     DataNodeUGIProvider ugiProvider \u003d new DataNodeUGIProvider(params);\n     ugi \u003d ugiProvider.ugi();\n-    path \u003d URLDecoder.decode(params.path(), \"UTF-8\");\n+    path \u003d params.path();\n \n     injectToken();\n     ugi.doAs(new PrivilegedExceptionAction\u003cVoid\u003e() {\n       @Override\n       public Void run() throws Exception {\n         try {\n           handle(ctx, req);\n         } finally {\n           String host \u003d null;\n           try {\n             host \u003d ((InetSocketAddress)ctx.channel().remoteAddress()).\n                 getAddress().getHostAddress();\n           } catch (Exception e) {\n             LOG.warn(\"Error retrieving hostname: \", e);\n             host \u003d \"unknown\";\n           }\n           REQLOG.info(host + \" \" + req.getMethod() + \" \"  + req.getUri() + \" \" +\n               getResponseCode());\n         }\n         return null;\n       }\n     });\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void channelRead0(final ChannelHandlerContext ctx,\n                           final HttpRequest req) throws Exception {\n    Preconditions.checkArgument(req.getUri().startsWith(WEBHDFS_PREFIX));\n    QueryStringDecoder queryString \u003d new QueryStringDecoder(req.getUri());\n    params \u003d new ParameterParser(queryString, conf);\n    DataNodeUGIProvider ugiProvider \u003d new DataNodeUGIProvider(params);\n    ugi \u003d ugiProvider.ugi();\n    path \u003d params.path();\n\n    injectToken();\n    ugi.doAs(new PrivilegedExceptionAction\u003cVoid\u003e() {\n      @Override\n      public Void run() throws Exception {\n        try {\n          handle(ctx, req);\n        } finally {\n          String host \u003d null;\n          try {\n            host \u003d ((InetSocketAddress)ctx.channel().remoteAddress()).\n                getAddress().getHostAddress();\n          } catch (Exception e) {\n            LOG.warn(\"Error retrieving hostname: \", e);\n            host \u003d \"unknown\";\n          }\n          REQLOG.info(host + \" \" + req.getMethod() + \" \"  + req.getUri() + \" \" +\n              getResponseCode());\n        }\n        return null;\n      }\n    });\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/web/webhdfs/WebHdfsHandler.java",
      "extendedDetails": {}
    },
    "46d29e3d7ee8dc9bb1818b886d9cc5336b1d67a4": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13176. WebHdfs file path gets truncated when having semicolon (;) inside. Contributed by Zsolt Venczel.\n",
      "commitDate": "07/03/18 12:33 PM",
      "commitName": "46d29e3d7ee8dc9bb1818b886d9cc5336b1d67a4",
      "commitAuthor": "Sean Mackrory",
      "commitDateOld": "06/03/17 3:04 PM",
      "commitNameOld": "5e74196ede9bfc20eb6d6fe3aa6a0e5c47a40fdd",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 365.9,
      "commitsBetweenForRepo": 2426,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,31 +1,31 @@\n   public void channelRead0(final ChannelHandlerContext ctx,\n                            final HttpRequest req) throws Exception {\n     Preconditions.checkArgument(req.getUri().startsWith(WEBHDFS_PREFIX));\n     QueryStringDecoder queryString \u003d new QueryStringDecoder(req.getUri());\n     params \u003d new ParameterParser(queryString, conf);\n     DataNodeUGIProvider ugiProvider \u003d new DataNodeUGIProvider(params);\n     ugi \u003d ugiProvider.ugi();\n-    path \u003d params.path();\n+    path \u003d URLDecoder.decode(params.path(), \"UTF-8\");\n \n     injectToken();\n     ugi.doAs(new PrivilegedExceptionAction\u003cVoid\u003e() {\n       @Override\n       public Void run() throws Exception {\n         try {\n           handle(ctx, req);\n         } finally {\n           String host \u003d null;\n           try {\n             host \u003d ((InetSocketAddress)ctx.channel().remoteAddress()).\n                 getAddress().getHostAddress();\n           } catch (Exception e) {\n             LOG.warn(\"Error retrieving hostname: \", e);\n             host \u003d \"unknown\";\n           }\n           REQLOG.info(host + \" \" + req.getMethod() + \" \"  + req.getUri() + \" \" +\n               getResponseCode());\n         }\n         return null;\n       }\n     });\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void channelRead0(final ChannelHandlerContext ctx,\n                           final HttpRequest req) throws Exception {\n    Preconditions.checkArgument(req.getUri().startsWith(WEBHDFS_PREFIX));\n    QueryStringDecoder queryString \u003d new QueryStringDecoder(req.getUri());\n    params \u003d new ParameterParser(queryString, conf);\n    DataNodeUGIProvider ugiProvider \u003d new DataNodeUGIProvider(params);\n    ugi \u003d ugiProvider.ugi();\n    path \u003d URLDecoder.decode(params.path(), \"UTF-8\");\n\n    injectToken();\n    ugi.doAs(new PrivilegedExceptionAction\u003cVoid\u003e() {\n      @Override\n      public Void run() throws Exception {\n        try {\n          handle(ctx, req);\n        } finally {\n          String host \u003d null;\n          try {\n            host \u003d ((InetSocketAddress)ctx.channel().remoteAddress()).\n                getAddress().getHostAddress();\n          } catch (Exception e) {\n            LOG.warn(\"Error retrieving hostname: \", e);\n            host \u003d \"unknown\";\n          }\n          REQLOG.info(host + \" \" + req.getMethod() + \" \"  + req.getUri() + \" \" +\n              getResponseCode());\n        }\n        return null;\n      }\n    });\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/web/webhdfs/WebHdfsHandler.java",
      "extendedDetails": {}
    },
    "5e74196ede9bfc20eb6d6fe3aa6a0e5c47a40fdd": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11498. Make RestCsrfPreventionHandler and WebHdfsHandler compatible with Netty 4.0.\n",
      "commitDate": "06/03/17 3:04 PM",
      "commitName": "5e74196ede9bfc20eb6d6fe3aa6a0e5c47a40fdd",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "24/02/17 4:49 PM",
      "commitNameOld": "e24ed47d9a19f34a4dd8d4bad9b5c78ca3dd1c2e",
      "commitAuthorOld": "Xiao Chen",
      "daysBetweenCommits": 9.93,
      "commitsBetweenForRepo": 55,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,31 +1,31 @@\n   public void channelRead0(final ChannelHandlerContext ctx,\n                            final HttpRequest req) throws Exception {\n     Preconditions.checkArgument(req.getUri().startsWith(WEBHDFS_PREFIX));\n     QueryStringDecoder queryString \u003d new QueryStringDecoder(req.getUri());\n     params \u003d new ParameterParser(queryString, conf);\n     DataNodeUGIProvider ugiProvider \u003d new DataNodeUGIProvider(params);\n     ugi \u003d ugiProvider.ugi();\n     path \u003d params.path();\n \n     injectToken();\n     ugi.doAs(new PrivilegedExceptionAction\u003cVoid\u003e() {\n       @Override\n       public Void run() throws Exception {\n         try {\n           handle(ctx, req);\n         } finally {\n           String host \u003d null;\n           try {\n             host \u003d ((InetSocketAddress)ctx.channel().remoteAddress()).\n                 getAddress().getHostAddress();\n           } catch (Exception e) {\n             LOG.warn(\"Error retrieving hostname: \", e);\n             host \u003d \"unknown\";\n           }\n-          REQLOG.info(host + \" \" + req.method() + \" \"  + req.uri() + \" \" +\n+          REQLOG.info(host + \" \" + req.getMethod() + \" \"  + req.getUri() + \" \" +\n               getResponseCode());\n         }\n         return null;\n       }\n     });\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void channelRead0(final ChannelHandlerContext ctx,\n                           final HttpRequest req) throws Exception {\n    Preconditions.checkArgument(req.getUri().startsWith(WEBHDFS_PREFIX));\n    QueryStringDecoder queryString \u003d new QueryStringDecoder(req.getUri());\n    params \u003d new ParameterParser(queryString, conf);\n    DataNodeUGIProvider ugiProvider \u003d new DataNodeUGIProvider(params);\n    ugi \u003d ugiProvider.ugi();\n    path \u003d params.path();\n\n    injectToken();\n    ugi.doAs(new PrivilegedExceptionAction\u003cVoid\u003e() {\n      @Override\n      public Void run() throws Exception {\n        try {\n          handle(ctx, req);\n        } finally {\n          String host \u003d null;\n          try {\n            host \u003d ((InetSocketAddress)ctx.channel().remoteAddress()).\n                getAddress().getHostAddress();\n          } catch (Exception e) {\n            LOG.warn(\"Error retrieving hostname: \", e);\n            host \u003d \"unknown\";\n          }\n          REQLOG.info(host + \" \" + req.getMethod() + \" \"  + req.getUri() + \" \" +\n              getResponseCode());\n        }\n        return null;\n      }\n    });\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/web/webhdfs/WebHdfsHandler.java",
      "extendedDetails": {}
    },
    "88da9f6b6782423acd8ab7eb7d938720de7f3c0f": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-8377. Support HTTP/2 in datanode. Contributed by Duo Zhang.\"\n\nThis reverts commit ada233b7cd7db39e609bb57e487fee8cec59cd48.\n",
      "commitDate": "26/01/17 1:42 PM",
      "commitName": "88da9f6b6782423acd8ab7eb7d938720de7f3c0f",
      "commitAuthor": "Xiao Chen",
      "commitDateOld": "06/09/16 11:02 AM",
      "commitNameOld": "f0d5382ff3e31a47d13e4cb6c3a244cca82b17ce",
      "commitAuthorOld": "Chris Nauroth",
      "daysBetweenCommits": 142.15,
      "commitsBetweenForRepo": 942,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,31 +1,31 @@\n   public void channelRead0(final ChannelHandlerContext ctx,\n                            final HttpRequest req) throws Exception {\n-    Preconditions.checkArgument(req.uri().startsWith(WEBHDFS_PREFIX));\n-    QueryStringDecoder queryString \u003d new QueryStringDecoder(req.uri());\n+    Preconditions.checkArgument(req.getUri().startsWith(WEBHDFS_PREFIX));\n+    QueryStringDecoder queryString \u003d new QueryStringDecoder(req.getUri());\n     params \u003d new ParameterParser(queryString, conf);\n     DataNodeUGIProvider ugiProvider \u003d new DataNodeUGIProvider(params);\n     ugi \u003d ugiProvider.ugi();\n     path \u003d params.path();\n \n     injectToken();\n     ugi.doAs(new PrivilegedExceptionAction\u003cVoid\u003e() {\n       @Override\n       public Void run() throws Exception {\n         try {\n           handle(ctx, req);\n         } finally {\n           String host \u003d null;\n           try {\n             host \u003d ((InetSocketAddress)ctx.channel().remoteAddress()).\n                 getAddress().getHostAddress();\n           } catch (Exception e) {\n             LOG.warn(\"Error retrieving hostname: \", e);\n             host \u003d \"unknown\";\n           }\n           REQLOG.info(host + \" \" + req.method() + \" \"  + req.uri() + \" \" +\n               getResponseCode());\n         }\n         return null;\n       }\n     });\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void channelRead0(final ChannelHandlerContext ctx,\n                           final HttpRequest req) throws Exception {\n    Preconditions.checkArgument(req.getUri().startsWith(WEBHDFS_PREFIX));\n    QueryStringDecoder queryString \u003d new QueryStringDecoder(req.getUri());\n    params \u003d new ParameterParser(queryString, conf);\n    DataNodeUGIProvider ugiProvider \u003d new DataNodeUGIProvider(params);\n    ugi \u003d ugiProvider.ugi();\n    path \u003d params.path();\n\n    injectToken();\n    ugi.doAs(new PrivilegedExceptionAction\u003cVoid\u003e() {\n      @Override\n      public Void run() throws Exception {\n        try {\n          handle(ctx, req);\n        } finally {\n          String host \u003d null;\n          try {\n            host \u003d ((InetSocketAddress)ctx.channel().remoteAddress()).\n                getAddress().getHostAddress();\n          } catch (Exception e) {\n            LOG.warn(\"Error retrieving hostname: \", e);\n            host \u003d \"unknown\";\n          }\n          REQLOG.info(host + \" \" + req.method() + \" \"  + req.uri() + \" \" +\n              getResponseCode());\n        }\n        return null;\n      }\n    });\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/web/webhdfs/WebHdfsHandler.java",
      "extendedDetails": {}
    },
    "bf74dbf80dc9379d669779a598950908adffb8a7": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7959. WebHdfs logging is missing on Datanode (Kihwal Lee via sjlee)\n",
      "commitDate": "24/06/16 2:44 PM",
      "commitName": "bf74dbf80dc9379d669779a598950908adffb8a7",
      "commitAuthor": "Sangjin Lee",
      "commitDateOld": "23/05/16 3:52 PM",
      "commitNameOld": "4b0f55b6ea1665e2118fd573f72a6fcd1fce20d6",
      "commitAuthorOld": "Allen Wittenauer",
      "daysBetweenCommits": 31.95,
      "commitsBetweenForRepo": 255,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,18 +1,31 @@\n   public void channelRead0(final ChannelHandlerContext ctx,\n                            final HttpRequest req) throws Exception {\n     Preconditions.checkArgument(req.uri().startsWith(WEBHDFS_PREFIX));\n     QueryStringDecoder queryString \u003d new QueryStringDecoder(req.uri());\n     params \u003d new ParameterParser(queryString, conf);\n     DataNodeUGIProvider ugiProvider \u003d new DataNodeUGIProvider(params);\n     ugi \u003d ugiProvider.ugi();\n     path \u003d params.path();\n \n     injectToken();\n     ugi.doAs(new PrivilegedExceptionAction\u003cVoid\u003e() {\n       @Override\n       public Void run() throws Exception {\n-        handle(ctx, req);\n+        try {\n+          handle(ctx, req);\n+        } finally {\n+          String host \u003d null;\n+          try {\n+            host \u003d ((InetSocketAddress)ctx.channel().remoteAddress()).\n+                getAddress().getHostAddress();\n+          } catch (Exception e) {\n+            LOG.warn(\"Error retrieving hostname: \", e);\n+            host \u003d \"unknown\";\n+          }\n+          REQLOG.info(host + \" \" + req.method() + \" \"  + req.uri() + \" \" +\n+              getResponseCode());\n+        }\n         return null;\n       }\n     });\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void channelRead0(final ChannelHandlerContext ctx,\n                           final HttpRequest req) throws Exception {\n    Preconditions.checkArgument(req.uri().startsWith(WEBHDFS_PREFIX));\n    QueryStringDecoder queryString \u003d new QueryStringDecoder(req.uri());\n    params \u003d new ParameterParser(queryString, conf);\n    DataNodeUGIProvider ugiProvider \u003d new DataNodeUGIProvider(params);\n    ugi \u003d ugiProvider.ugi();\n    path \u003d params.path();\n\n    injectToken();\n    ugi.doAs(new PrivilegedExceptionAction\u003cVoid\u003e() {\n      @Override\n      public Void run() throws Exception {\n        try {\n          handle(ctx, req);\n        } finally {\n          String host \u003d null;\n          try {\n            host \u003d ((InetSocketAddress)ctx.channel().remoteAddress()).\n                getAddress().getHostAddress();\n          } catch (Exception e) {\n            LOG.warn(\"Error retrieving hostname: \", e);\n            host \u003d \"unknown\";\n          }\n          REQLOG.info(host + \" \" + req.method() + \" \"  + req.uri() + \" \" +\n              getResponseCode());\n        }\n        return null;\n      }\n    });\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/web/webhdfs/WebHdfsHandler.java",
      "extendedDetails": {}
    },
    "88beb46cf6e6fd3e51f73a411a2750de7595e326": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-8855. Webhdfs client leaks active NameNode connections. Contributed by Xiaobing Zhou.\"\n\nThis reverts commit 84cbd72afda6344e220526fac5c560f00f84e374.\n",
      "commitDate": "04/11/15 10:21 AM",
      "commitName": "88beb46cf6e6fd3e51f73a411a2750de7595e326",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "13/10/15 9:12 AM",
      "commitNameOld": "84cbd72afda6344e220526fac5c560f00f84e374",
      "commitAuthorOld": "Jitendra Pandey",
      "daysBetweenCommits": 22.09,
      "commitsBetweenForRepo": 217,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,18 +1,18 @@\n   public void channelRead0(final ChannelHandlerContext ctx,\n                            final HttpRequest req) throws Exception {\n     Preconditions.checkArgument(req.uri().startsWith(WEBHDFS_PREFIX));\n     QueryStringDecoder queryString \u003d new QueryStringDecoder(req.uri());\n     params \u003d new ParameterParser(queryString, conf);\n-    DataNodeUGIProvider ugiProvider \u003d new DataNodeUGIProvider(params, conf);\n+    DataNodeUGIProvider ugiProvider \u003d new DataNodeUGIProvider(params);\n     ugi \u003d ugiProvider.ugi();\n     path \u003d params.path();\n \n     injectToken();\n     ugi.doAs(new PrivilegedExceptionAction\u003cVoid\u003e() {\n       @Override\n       public Void run() throws Exception {\n         handle(ctx, req);\n         return null;\n       }\n     });\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void channelRead0(final ChannelHandlerContext ctx,\n                           final HttpRequest req) throws Exception {\n    Preconditions.checkArgument(req.uri().startsWith(WEBHDFS_PREFIX));\n    QueryStringDecoder queryString \u003d new QueryStringDecoder(req.uri());\n    params \u003d new ParameterParser(queryString, conf);\n    DataNodeUGIProvider ugiProvider \u003d new DataNodeUGIProvider(params);\n    ugi \u003d ugiProvider.ugi();\n    path \u003d params.path();\n\n    injectToken();\n    ugi.doAs(new PrivilegedExceptionAction\u003cVoid\u003e() {\n      @Override\n      public Void run() throws Exception {\n        handle(ctx, req);\n        return null;\n      }\n    });\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/web/webhdfs/WebHdfsHandler.java",
      "extendedDetails": {}
    },
    "84cbd72afda6344e220526fac5c560f00f84e374": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8855. Webhdfs client leaks active NameNode connections. Contributed by Xiaobing Zhou.\n",
      "commitDate": "13/10/15 9:12 AM",
      "commitName": "84cbd72afda6344e220526fac5c560f00f84e374",
      "commitAuthor": "Jitendra Pandey",
      "commitDateOld": "18/08/15 5:32 PM",
      "commitNameOld": "30e342a5d32be5efffeb472cce76d4ed43642608",
      "commitAuthorOld": "Chris Douglas",
      "daysBetweenCommits": 55.65,
      "commitsBetweenForRepo": 372,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,18 +1,18 @@\n   public void channelRead0(final ChannelHandlerContext ctx,\n                            final HttpRequest req) throws Exception {\n     Preconditions.checkArgument(req.uri().startsWith(WEBHDFS_PREFIX));\n     QueryStringDecoder queryString \u003d new QueryStringDecoder(req.uri());\n     params \u003d new ParameterParser(queryString, conf);\n-    DataNodeUGIProvider ugiProvider \u003d new DataNodeUGIProvider(params);\n+    DataNodeUGIProvider ugiProvider \u003d new DataNodeUGIProvider(params, conf);\n     ugi \u003d ugiProvider.ugi();\n     path \u003d params.path();\n \n     injectToken();\n     ugi.doAs(new PrivilegedExceptionAction\u003cVoid\u003e() {\n       @Override\n       public Void run() throws Exception {\n         handle(ctx, req);\n         return null;\n       }\n     });\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void channelRead0(final ChannelHandlerContext ctx,\n                           final HttpRequest req) throws Exception {\n    Preconditions.checkArgument(req.uri().startsWith(WEBHDFS_PREFIX));\n    QueryStringDecoder queryString \u003d new QueryStringDecoder(req.uri());\n    params \u003d new ParameterParser(queryString, conf);\n    DataNodeUGIProvider ugiProvider \u003d new DataNodeUGIProvider(params, conf);\n    ugi \u003d ugiProvider.ugi();\n    path \u003d params.path();\n\n    injectToken();\n    ugi.doAs(new PrivilegedExceptionAction\u003cVoid\u003e() {\n      @Override\n      public Void run() throws Exception {\n        handle(ctx, req);\n        return null;\n      }\n    });\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/web/webhdfs/WebHdfsHandler.java",
      "extendedDetails": {}
    },
    "ada233b7cd7db39e609bb57e487fee8cec59cd48": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8377. Support HTTP/2 in datanode. Contributed by Duo Zhang.\n",
      "commitDate": "24/05/15 10:30 PM",
      "commitName": "ada233b7cd7db39e609bb57e487fee8cec59cd48",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "18/03/15 4:19 PM",
      "commitNameOld": "8c40e88d5de51a273f6ae5cd11c40f44248bbfcd",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 67.26,
      "commitsBetweenForRepo": 659,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,18 +1,18 @@\n   public void channelRead0(final ChannelHandlerContext ctx,\n                            final HttpRequest req) throws Exception {\n-    Preconditions.checkArgument(req.getUri().startsWith(WEBHDFS_PREFIX));\n-    QueryStringDecoder queryString \u003d new QueryStringDecoder(req.getUri());\n+    Preconditions.checkArgument(req.uri().startsWith(WEBHDFS_PREFIX));\n+    QueryStringDecoder queryString \u003d new QueryStringDecoder(req.uri());\n     params \u003d new ParameterParser(queryString, conf);\n     DataNodeUGIProvider ugiProvider \u003d new DataNodeUGIProvider(params);\n     ugi \u003d ugiProvider.ugi();\n     path \u003d params.path();\n \n     injectToken();\n     ugi.doAs(new PrivilegedExceptionAction\u003cVoid\u003e() {\n       @Override\n       public Void run() throws Exception {\n         handle(ctx, req);\n         return null;\n       }\n     });\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void channelRead0(final ChannelHandlerContext ctx,\n                           final HttpRequest req) throws Exception {\n    Preconditions.checkArgument(req.uri().startsWith(WEBHDFS_PREFIX));\n    QueryStringDecoder queryString \u003d new QueryStringDecoder(req.uri());\n    params \u003d new ParameterParser(queryString, conf);\n    DataNodeUGIProvider ugiProvider \u003d new DataNodeUGIProvider(params);\n    ugi \u003d ugiProvider.ugi();\n    path \u003d params.path();\n\n    injectToken();\n    ugi.doAs(new PrivilegedExceptionAction\u003cVoid\u003e() {\n      @Override\n      public Void run() throws Exception {\n        handle(ctx, req);\n        return null;\n      }\n    });\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/web/webhdfs/WebHdfsHandler.java",
      "extendedDetails": {}
    },
    "bf8e4332cb4c33d0287ae6ecca61b335402ac1c4": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-7279. Use netty to implement DatanodeWebHdfsMethods. Contributed by Haohui Mai.\n",
      "commitDate": "17/11/14 11:42 AM",
      "commitName": "bf8e4332cb4c33d0287ae6ecca61b335402ac1c4",
      "commitAuthor": "Haohui Mai",
      "diff": "@@ -0,0 +1,18 @@\n+  public void channelRead0(final ChannelHandlerContext ctx,\n+                           final HttpRequest req) throws Exception {\n+    Preconditions.checkArgument(req.getUri().startsWith(WEBHDFS_PREFIX));\n+    QueryStringDecoder queryString \u003d new QueryStringDecoder(req.getUri());\n+    params \u003d new ParameterParser(queryString, conf);\n+    DataNodeUGIProvider ugiProvider \u003d new DataNodeUGIProvider(params);\n+    ugi \u003d ugiProvider.ugi();\n+    path \u003d params.path();\n+\n+    injectToken();\n+    ugi.doAs(new PrivilegedExceptionAction\u003cVoid\u003e() {\n+      @Override\n+      public Void run() throws Exception {\n+        handle(ctx, req);\n+        return null;\n+      }\n+    });\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void channelRead0(final ChannelHandlerContext ctx,\n                           final HttpRequest req) throws Exception {\n    Preconditions.checkArgument(req.getUri().startsWith(WEBHDFS_PREFIX));\n    QueryStringDecoder queryString \u003d new QueryStringDecoder(req.getUri());\n    params \u003d new ParameterParser(queryString, conf);\n    DataNodeUGIProvider ugiProvider \u003d new DataNodeUGIProvider(params);\n    ugi \u003d ugiProvider.ugi();\n    path \u003d params.path();\n\n    injectToken();\n    ugi.doAs(new PrivilegedExceptionAction\u003cVoid\u003e() {\n      @Override\n      public Void run() throws Exception {\n        handle(ctx, req);\n        return null;\n      }\n    });\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/web/webhdfs/WebHdfsHandler.java"
    }
  }
}