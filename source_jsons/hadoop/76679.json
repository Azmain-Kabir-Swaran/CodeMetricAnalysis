{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ECChunk.java",
  "functionName": "toBuffers",
  "functionId": "toBuffers___chunks-ECChunk[]",
  "sourceFilePath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/ECChunk.java",
  "functionStartLine": 83,
  "functionEndLine": 97,
  "numCommitsSeen": 8,
  "timeTaken": 775,
  "changeHistory": [
    "b64f6745a45754dcf79c9c2626f3db7db2f33858",
    "e50bcea83d5f6b02ab03b06a3fbf1ed6b8ff4871"
  ],
  "changeHistoryShort": {
    "b64f6745a45754dcf79c9c2626f3db7db2f33858": "Ybodychange",
    "e50bcea83d5f6b02ab03b06a3fbf1ed6b8ff4871": "Yintroduced"
  },
  "changeHistoryDetails": {
    "b64f6745a45754dcf79c9c2626f3db7db2f33858": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-11566. Add tests and fix for erasure coders to recover erased parity units. Contributed by Kai Zheng.\n",
      "commitDate": "26/05/15 12:02 PM",
      "commitName": "b64f6745a45754dcf79c9c2626f3db7db2f33858",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "26/05/15 12:02 PM",
      "commitNameOld": "09c3a375bafa481e88d1317388a73c46950164c9",
      "commitAuthorOld": "Zhe Zhang",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,9 +1,15 @@\n   public static ByteBuffer[] toBuffers(ECChunk[] chunks) {\n     ByteBuffer[] buffers \u003d new ByteBuffer[chunks.length];\n \n+    ECChunk chunk;\n     for (int i \u003d 0; i \u003c chunks.length; i++) {\n-      buffers[i] \u003d chunks[i].getBuffer();\n+      chunk \u003d chunks[i];\n+      if (chunk \u003d\u003d null) {\n+        buffers[i] \u003d null;\n+      } else {\n+        buffers[i] \u003d chunk.getBuffer();\n+      }\n     }\n \n     return buffers;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static ByteBuffer[] toBuffers(ECChunk[] chunks) {\n    ByteBuffer[] buffers \u003d new ByteBuffer[chunks.length];\n\n    ECChunk chunk;\n    for (int i \u003d 0; i \u003c chunks.length; i++) {\n      chunk \u003d chunks[i];\n      if (chunk \u003d\u003d null) {\n        buffers[i] \u003d null;\n      } else {\n        buffers[i] \u003d chunk.getBuffer();\n      }\n    }\n\n    return buffers;\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/ECChunk.java",
      "extendedDetails": {}
    },
    "e50bcea83d5f6b02ab03b06a3fbf1ed6b8ff4871": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-11514. Raw Erasure Coder API for concrete encoding and decoding (Kai Zheng via umamahesh)\n",
      "commitDate": "26/05/15 11:03 AM",
      "commitName": "e50bcea83d5f6b02ab03b06a3fbf1ed6b8ff4871",
      "commitAuthor": "Uma Maheswara Rao G",
      "diff": "@@ -0,0 +1,9 @@\n+  public static ByteBuffer[] toBuffers(ECChunk[] chunks) {\n+    ByteBuffer[] buffers \u003d new ByteBuffer[chunks.length];\n+\n+    for (int i \u003d 0; i \u003c chunks.length; i++) {\n+      buffers[i] \u003d chunks[i].getBuffer();\n+    }\n+\n+    return buffers;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public static ByteBuffer[] toBuffers(ECChunk[] chunks) {\n    ByteBuffer[] buffers \u003d new ByteBuffer[chunks.length];\n\n    for (int i \u003d 0; i \u003c chunks.length; i++) {\n      buffers[i] \u003d chunks[i].getBuffer();\n    }\n\n    return buffers;\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/ECChunk.java"
    }
  }
}