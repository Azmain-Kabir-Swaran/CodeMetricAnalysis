{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSNamesystem.java",
  "functionName": "fsync",
  "functionId": "fsync___src-String__fileId-long__clientName-String__lastBlockLength-long",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
  "functionStartLine": 3574,
  "functionEndLine": 3596,
  "numCommitsSeen": 1389,
  "timeTaken": 59843,
  "changeHistory": [
    "4b95c242eca540455a4d5d0899aaf73b6064b5ea",
    "84a1321f6aa0af6895564a7c47f8f264656f0294",
    "ff0b99eafeda035ebe0dc82cfe689808047a8893",
    "869393643de23dcb010cc33091c8eb398de0fd6c",
    "03dea65e0b17ca2f9460bb6110f6ab3a321b8bf2",
    "3fa33b5c2c289ceaced30c6c5451f3569110459d",
    "e5afac5896a1a88e152746598527d91f73cbb724",
    "6ae2a0d048e133b43249c248a75a4d77d9abb80d",
    "76e7264e8d6407f527bd877009aca11f7bb63bd7",
    "c78e3a7cdd10c40454e9acb06986ba6d8573cb19",
    "c95b878abf313507666ea018f9e6033c4c166e10",
    "407bb3d3e452c8277c498dd14e0cc5b7762a7091",
    "a4e0ff5e052abad498595ee198b49c5310c9ec0d",
    "e98529858edeed11c4f900b0db30d7e4eb2ab1ec",
    "f131dba8a3d603a5d15c4f035ed3da75b4daf0dc",
    "ce68f410b05a58ad05965f32ad7f5b246b363a75",
    "34f08944b7c8d58f531a3f3bf3d4ee4cd3fa643a",
    "1fe1942328856dd832e9f94fb56a40ab3d810870",
    "8c7a7e619699386f9e6991842558d78aa0c8053d",
    "0b101bd7e875ee5597ddb8f0d887159076310ffa",
    "980e6c54bab4ffc87e168cd5c217fef44c72a878",
    "3bf09c51501a23b7fa28fd0a0c4c0965858d026c",
    "9821af9ce8a56a2c583f1ed938902c20e897048f",
    "571da54179f731eb8421ffc681169799588f76bc",
    "cea7bbc630deede93dbe6a1bbda56ad49de4f3de",
    "36d1c49486587c2dbb193e8538b1d4510c462fa6",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "4b95c242eca540455a4d5d0899aaf73b6064b5ea": "Ybodychange",
    "84a1321f6aa0af6895564a7c47f8f264656f0294": "Ybodychange",
    "ff0b99eafeda035ebe0dc82cfe689808047a8893": "Ybodychange",
    "869393643de23dcb010cc33091c8eb398de0fd6c": "Ybodychange",
    "03dea65e0b17ca2f9460bb6110f6ab3a321b8bf2": "Ybodychange",
    "3fa33b5c2c289ceaced30c6c5451f3569110459d": "Ybodychange",
    "e5afac5896a1a88e152746598527d91f73cbb724": "Ybodychange",
    "6ae2a0d048e133b43249c248a75a4d77d9abb80d": "Ybodychange",
    "76e7264e8d6407f527bd877009aca11f7bb63bd7": "Ybodychange",
    "c78e3a7cdd10c40454e9acb06986ba6d8573cb19": "Yexceptionschange",
    "c95b878abf313507666ea018f9e6033c4c166e10": "Ybodychange",
    "407bb3d3e452c8277c498dd14e0cc5b7762a7091": "Ybodychange",
    "a4e0ff5e052abad498595ee198b49c5310c9ec0d": "Ybodychange",
    "e98529858edeed11c4f900b0db30d7e4eb2ab1ec": "Ybodychange",
    "f131dba8a3d603a5d15c4f035ed3da75b4daf0dc": "Ymultichange(Yparameterchange,Ybodychange)",
    "ce68f410b05a58ad05965f32ad7f5b246b363a75": "Ybodychange",
    "34f08944b7c8d58f531a3f3bf3d4ee4cd3fa643a": "Ybodychange",
    "1fe1942328856dd832e9f94fb56a40ab3d810870": "Ybodychange",
    "8c7a7e619699386f9e6991842558d78aa0c8053d": "Ybodychange",
    "0b101bd7e875ee5597ddb8f0d887159076310ffa": "Ybodychange",
    "980e6c54bab4ffc87e168cd5c217fef44c72a878": "Ybodychange",
    "3bf09c51501a23b7fa28fd0a0c4c0965858d026c": "Ybodychange",
    "9821af9ce8a56a2c583f1ed938902c20e897048f": "Ybodychange",
    "571da54179f731eb8421ffc681169799588f76bc": "Ymultichange(Yparameterchange,Ybodychange)",
    "cea7bbc630deede93dbe6a1bbda56ad49de4f3de": "Ybodychange",
    "36d1c49486587c2dbb193e8538b1d4510c462fa6": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "4b95c242eca540455a4d5d0899aaf73b6064b5ea": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14743. Enhance INodeAttributeProvider/ AccessControlEnforcer Interface in HDFS to support Authorization of mkdir, rm, rmdir, copy, move etc... (#1829)\n\nReviewed-by: Xiaoyu Yao \u003cxyao@apache.org\u003e",
      "commitDate": "13/03/20 11:29 AM",
      "commitName": "4b95c242eca540455a4d5d0899aaf73b6064b5ea",
      "commitAuthor": "Wei-Chiu Chuang",
      "commitDateOld": "27/02/20 8:49 AM",
      "commitNameOld": "cd2c6b1aac470991b9b90339ce2721ba179e7c48",
      "commitAuthorOld": "Ayush Saxena",
      "daysBetweenCommits": 15.07,
      "commitsBetweenForRepo": 51,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,23 @@\n   void fsync(String src, long fileId, String clientName, long lastBlockLength)\n       throws IOException {\n     NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n     checkOperation(OperationCategory.WRITE);\n     final FSPermissionChecker pc \u003d getPermissionChecker();\n+    FSPermissionChecker.setOperationType(null);\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       checkNameNodeSafeMode(\"Cannot fsync file \" + src);\n       INodesInPath iip \u003d dir.resolvePath(pc, src, fileId);\n       src \u003d iip.getPath();\n       final INodeFile pendingFile \u003d checkLease(iip, clientName, fileId);\n       if (lastBlockLength \u003e 0) {\n         pendingFile.getFileUnderConstructionFeature().updateLengthOfLastBlock(\n             pendingFile, lastBlockLength);\n       }\n       FSDirWriteFileOp.persistBlocks(dir, src, pendingFile, false);\n     } finally {\n       writeUnlock(\"fsync\");\n     }\n     getEditLog().logSync();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void fsync(String src, long fileId, String clientName, long lastBlockLength)\n      throws IOException {\n    NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n    checkOperation(OperationCategory.WRITE);\n    final FSPermissionChecker pc \u003d getPermissionChecker();\n    FSPermissionChecker.setOperationType(null);\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      checkNameNodeSafeMode(\"Cannot fsync file \" + src);\n      INodesInPath iip \u003d dir.resolvePath(pc, src, fileId);\n      src \u003d iip.getPath();\n      final INodeFile pendingFile \u003d checkLease(iip, clientName, fileId);\n      if (lastBlockLength \u003e 0) {\n        pendingFile.getFileUnderConstructionFeature().updateLengthOfLastBlock(\n            pendingFile, lastBlockLength);\n      }\n      FSDirWriteFileOp.persistBlocks(dir, src, pendingFile, false);\n    } finally {\n      writeUnlock(\"fsync\");\n    }\n    getEditLog().logSync();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "84a1321f6aa0af6895564a7c47f8f264656f0294": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13136. Avoid taking FSN lock while doing group member lookup for FSD permission check. Contributed by Xiaoyu Yao.\n",
      "commitDate": "22/02/18 11:32 AM",
      "commitName": "84a1321f6aa0af6895564a7c47f8f264656f0294",
      "commitAuthor": "Xiaoyu Yao",
      "commitDateOld": "15/02/18 1:32 PM",
      "commitNameOld": "47473952e56b0380147d42f4110ad03c2276c961",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 6.92,
      "commitsBetweenForRepo": 36,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,22 @@\n   void fsync(String src, long fileId, String clientName, long lastBlockLength)\n       throws IOException {\n     NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n     checkOperation(OperationCategory.WRITE);\n-\n-    FSPermissionChecker pc \u003d getPermissionChecker();\n+    final FSPermissionChecker pc \u003d getPermissionChecker();\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       checkNameNodeSafeMode(\"Cannot fsync file \" + src);\n       INodesInPath iip \u003d dir.resolvePath(pc, src, fileId);\n       src \u003d iip.getPath();\n       final INodeFile pendingFile \u003d checkLease(iip, clientName, fileId);\n       if (lastBlockLength \u003e 0) {\n         pendingFile.getFileUnderConstructionFeature().updateLengthOfLastBlock(\n             pendingFile, lastBlockLength);\n       }\n       FSDirWriteFileOp.persistBlocks(dir, src, pendingFile, false);\n     } finally {\n       writeUnlock(\"fsync\");\n     }\n     getEditLog().logSync();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void fsync(String src, long fileId, String clientName, long lastBlockLength)\n      throws IOException {\n    NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n    checkOperation(OperationCategory.WRITE);\n    final FSPermissionChecker pc \u003d getPermissionChecker();\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      checkNameNodeSafeMode(\"Cannot fsync file \" + src);\n      INodesInPath iip \u003d dir.resolvePath(pc, src, fileId);\n      src \u003d iip.getPath();\n      final INodeFile pendingFile \u003d checkLease(iip, clientName, fileId);\n      if (lastBlockLength \u003e 0) {\n        pendingFile.getFileUnderConstructionFeature().updateLengthOfLastBlock(\n            pendingFile, lastBlockLength);\n      }\n      FSDirWriteFileOp.persistBlocks(dir, src, pendingFile, false);\n    } finally {\n      writeUnlock(\"fsync\");\n    }\n    getEditLog().logSync();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "ff0b99eafeda035ebe0dc82cfe689808047a8893": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10872. Add MutableRate metrics for FSNamesystemLock operations. Contributed by Erik Krogen.\n",
      "commitDate": "14/11/16 11:05 AM",
      "commitName": "ff0b99eafeda035ebe0dc82cfe689808047a8893",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "08/11/16 6:17 PM",
      "commitNameOld": "ed0bebabaaf27cd730f7f8eb002d92c9c7db327d",
      "commitAuthorOld": "Brahma Reddy Battula",
      "daysBetweenCommits": 5.7,
      "commitsBetweenForRepo": 36,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,23 @@\n   void fsync(String src, long fileId, String clientName, long lastBlockLength)\n       throws IOException {\n     NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n     checkOperation(OperationCategory.WRITE);\n \n     FSPermissionChecker pc \u003d getPermissionChecker();\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       checkNameNodeSafeMode(\"Cannot fsync file \" + src);\n       INodesInPath iip \u003d dir.resolvePath(pc, src, fileId);\n       src \u003d iip.getPath();\n       final INodeFile pendingFile \u003d checkLease(iip, clientName, fileId);\n       if (lastBlockLength \u003e 0) {\n         pendingFile.getFileUnderConstructionFeature().updateLengthOfLastBlock(\n             pendingFile, lastBlockLength);\n       }\n       FSDirWriteFileOp.persistBlocks(dir, src, pendingFile, false);\n     } finally {\n-      writeUnlock();\n+      writeUnlock(\"fsync\");\n     }\n     getEditLog().logSync();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void fsync(String src, long fileId, String clientName, long lastBlockLength)\n      throws IOException {\n    NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n    checkOperation(OperationCategory.WRITE);\n\n    FSPermissionChecker pc \u003d getPermissionChecker();\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      checkNameNodeSafeMode(\"Cannot fsync file \" + src);\n      INodesInPath iip \u003d dir.resolvePath(pc, src, fileId);\n      src \u003d iip.getPath();\n      final INodeFile pendingFile \u003d checkLease(iip, clientName, fileId);\n      if (lastBlockLength \u003e 0) {\n        pendingFile.getFileUnderConstructionFeature().updateLengthOfLastBlock(\n            pendingFile, lastBlockLength);\n      }\n      FSDirWriteFileOp.persistBlocks(dir, src, pendingFile, false);\n    } finally {\n      writeUnlock(\"fsync\");\n    }\n    getEditLog().logSync();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "869393643de23dcb010cc33091c8eb398de0fd6c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10745. Directly resolve paths into INodesInPath. Contributed by Daryn Sharp.\n",
      "commitDate": "17/08/16 1:53 PM",
      "commitName": "869393643de23dcb010cc33091c8eb398de0fd6c",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "15/08/16 3:28 PM",
      "commitNameOld": "864f878d5912c82f3204f1582cfb7eb7c9f1a1da",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 1.93,
      "commitsBetweenForRepo": 22,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,32 +1,23 @@\n   void fsync(String src, long fileId, String clientName, long lastBlockLength)\n       throws IOException {\n     NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n     checkOperation(OperationCategory.WRITE);\n \n     FSPermissionChecker pc \u003d getPermissionChecker();\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       checkNameNodeSafeMode(\"Cannot fsync file \" + src);\n-      src \u003d dir.resolvePath(pc, src);\n-      final INode inode;\n-      if (fileId \u003d\u003d HdfsConstants.GRANDFATHER_INODE_ID) {\n-        // Older clients may not have given us an inode ID to work with.\n-        // In this case, we have to try to resolve the path and hope it\n-        // hasn\u0027t changed or been deleted since the file was opened for write.\n-        inode \u003d dir.getINode(src);\n-      } else {\n-        inode \u003d dir.getInode(fileId);\n-        if (inode !\u003d null) src \u003d inode.getFullPathName();\n-      }\n-      final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n+      INodesInPath iip \u003d dir.resolvePath(pc, src, fileId);\n+      src \u003d iip.getPath();\n+      final INodeFile pendingFile \u003d checkLease(iip, clientName, fileId);\n       if (lastBlockLength \u003e 0) {\n         pendingFile.getFileUnderConstructionFeature().updateLengthOfLastBlock(\n             pendingFile, lastBlockLength);\n       }\n       FSDirWriteFileOp.persistBlocks(dir, src, pendingFile, false);\n     } finally {\n       writeUnlock();\n     }\n     getEditLog().logSync();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void fsync(String src, long fileId, String clientName, long lastBlockLength)\n      throws IOException {\n    NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n    checkOperation(OperationCategory.WRITE);\n\n    FSPermissionChecker pc \u003d getPermissionChecker();\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      checkNameNodeSafeMode(\"Cannot fsync file \" + src);\n      INodesInPath iip \u003d dir.resolvePath(pc, src, fileId);\n      src \u003d iip.getPath();\n      final INodeFile pendingFile \u003d checkLease(iip, clientName, fileId);\n      if (lastBlockLength \u003e 0) {\n        pendingFile.getFileUnderConstructionFeature().updateLengthOfLastBlock(\n            pendingFile, lastBlockLength);\n      }\n      FSDirWriteFileOp.persistBlocks(dir, src, pendingFile, false);\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "03dea65e0b17ca2f9460bb6110f6ab3a321b8bf2": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10744. Internally optimize path component resolution. Contributed by Daryn Sharp.\n",
      "commitDate": "15/08/16 2:45 PM",
      "commitName": "03dea65e0b17ca2f9460bb6110f6ab3a321b8bf2",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "03/08/16 11:12 AM",
      "commitNameOld": "22ef5286bc8511ddee9594b7cecc598bf41a850b",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 12.15,
      "commitsBetweenForRepo": 86,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,33 +1,32 @@\n   void fsync(String src, long fileId, String clientName, long lastBlockLength)\n       throws IOException {\n     NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n     checkOperation(OperationCategory.WRITE);\n-    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n \n     FSPermissionChecker pc \u003d getPermissionChecker();\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       checkNameNodeSafeMode(\"Cannot fsync file \" + src);\n-      src \u003d dir.resolvePath(pc, src, pathComponents);\n+      src \u003d dir.resolvePath(pc, src);\n       final INode inode;\n       if (fileId \u003d\u003d HdfsConstants.GRANDFATHER_INODE_ID) {\n         // Older clients may not have given us an inode ID to work with.\n         // In this case, we have to try to resolve the path and hope it\n         // hasn\u0027t changed or been deleted since the file was opened for write.\n         inode \u003d dir.getINode(src);\n       } else {\n         inode \u003d dir.getInode(fileId);\n         if (inode !\u003d null) src \u003d inode.getFullPathName();\n       }\n       final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n       if (lastBlockLength \u003e 0) {\n         pendingFile.getFileUnderConstructionFeature().updateLengthOfLastBlock(\n             pendingFile, lastBlockLength);\n       }\n       FSDirWriteFileOp.persistBlocks(dir, src, pendingFile, false);\n     } finally {\n       writeUnlock();\n     }\n     getEditLog().logSync();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void fsync(String src, long fileId, String clientName, long lastBlockLength)\n      throws IOException {\n    NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n    checkOperation(OperationCategory.WRITE);\n\n    FSPermissionChecker pc \u003d getPermissionChecker();\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      checkNameNodeSafeMode(\"Cannot fsync file \" + src);\n      src \u003d dir.resolvePath(pc, src);\n      final INode inode;\n      if (fileId \u003d\u003d HdfsConstants.GRANDFATHER_INODE_ID) {\n        // Older clients may not have given us an inode ID to work with.\n        // In this case, we have to try to resolve the path and hope it\n        // hasn\u0027t changed or been deleted since the file was opened for write.\n        inode \u003d dir.getINode(src);\n      } else {\n        inode \u003d dir.getInode(fileId);\n        if (inode !\u003d null) src \u003d inode.getFullPathName();\n      }\n      final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n      if (lastBlockLength \u003e 0) {\n        pendingFile.getFileUnderConstructionFeature().updateLengthOfLastBlock(\n            pendingFile, lastBlockLength);\n      }\n      FSDirWriteFileOp.persistBlocks(dir, src, pendingFile, false);\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "3fa33b5c2c289ceaced30c6c5451f3569110459d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9430 Remove waitForLoadingFSImage since checkNNStartup has ensured image loaded and namenode started. (Brahma Reddy Battula via mingma)\n",
      "commitDate": "04/12/15 9:47 AM",
      "commitName": "3fa33b5c2c289ceaced30c6c5451f3569110459d",
      "commitAuthor": "Ming Ma",
      "commitDateOld": "01/12/15 4:09 PM",
      "commitNameOld": "a49cc74b4c72195dee1dfb6f9548e5e411dff553",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 2.74,
      "commitsBetweenForRepo": 13,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,34 +1,33 @@\n   void fsync(String src, long fileId, String clientName, long lastBlockLength)\n       throws IOException {\n     NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n     checkOperation(OperationCategory.WRITE);\n     byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n \n     FSPermissionChecker pc \u003d getPermissionChecker();\n-    waitForLoadingFSImage();\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       checkNameNodeSafeMode(\"Cannot fsync file \" + src);\n       src \u003d dir.resolvePath(pc, src, pathComponents);\n       final INode inode;\n       if (fileId \u003d\u003d HdfsConstants.GRANDFATHER_INODE_ID) {\n         // Older clients may not have given us an inode ID to work with.\n         // In this case, we have to try to resolve the path and hope it\n         // hasn\u0027t changed or been deleted since the file was opened for write.\n         inode \u003d dir.getINode(src);\n       } else {\n         inode \u003d dir.getInode(fileId);\n         if (inode !\u003d null) src \u003d inode.getFullPathName();\n       }\n       final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n       if (lastBlockLength \u003e 0) {\n         pendingFile.getFileUnderConstructionFeature().updateLengthOfLastBlock(\n             pendingFile, lastBlockLength);\n       }\n       FSDirWriteFileOp.persistBlocks(dir, src, pendingFile, false);\n     } finally {\n       writeUnlock();\n     }\n     getEditLog().logSync();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void fsync(String src, long fileId, String clientName, long lastBlockLength)\n      throws IOException {\n    NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n    checkOperation(OperationCategory.WRITE);\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n\n    FSPermissionChecker pc \u003d getPermissionChecker();\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      checkNameNodeSafeMode(\"Cannot fsync file \" + src);\n      src \u003d dir.resolvePath(pc, src, pathComponents);\n      final INode inode;\n      if (fileId \u003d\u003d HdfsConstants.GRANDFATHER_INODE_ID) {\n        // Older clients may not have given us an inode ID to work with.\n        // In this case, we have to try to resolve the path and hope it\n        // hasn\u0027t changed or been deleted since the file was opened for write.\n        inode \u003d dir.getINode(src);\n      } else {\n        inode \u003d dir.getInode(fileId);\n        if (inode !\u003d null) src \u003d inode.getFullPathName();\n      }\n      final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n      if (lastBlockLength \u003e 0) {\n        pendingFile.getFileUnderConstructionFeature().updateLengthOfLastBlock(\n            pendingFile, lastBlockLength);\n      }\n      FSDirWriteFileOp.persistBlocks(dir, src, pendingFile, false);\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "e5afac5896a1a88e152746598527d91f73cbb724": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8394. Move getAdditionalBlock() and related functionalities into a separate class. Contributed by Haohui Mai.\n",
      "commitDate": "15/05/15 7:09 PM",
      "commitName": "e5afac5896a1a88e152746598527d91f73cbb724",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "14/05/15 10:37 PM",
      "commitNameOld": "3bef7c80a97709b367781180b2e11fc50653d3c8",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 0.86,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,34 +1,34 @@\n   void fsync(String src, long fileId, String clientName, long lastBlockLength)\n       throws IOException {\n     NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n     checkOperation(OperationCategory.WRITE);\n     byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n \n     FSPermissionChecker pc \u003d getPermissionChecker();\n     waitForLoadingFSImage();\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       checkNameNodeSafeMode(\"Cannot fsync file \" + src);\n       src \u003d dir.resolvePath(pc, src, pathComponents);\n       final INode inode;\n       if (fileId \u003d\u003d HdfsConstants.GRANDFATHER_INODE_ID) {\n         // Older clients may not have given us an inode ID to work with.\n         // In this case, we have to try to resolve the path and hope it\n         // hasn\u0027t changed or been deleted since the file was opened for write.\n         inode \u003d dir.getINode(src);\n       } else {\n         inode \u003d dir.getInode(fileId);\n         if (inode !\u003d null) src \u003d inode.getFullPathName();\n       }\n       final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n       if (lastBlockLength \u003e 0) {\n         pendingFile.getFileUnderConstructionFeature().updateLengthOfLastBlock(\n             pendingFile, lastBlockLength);\n       }\n-      persistBlocks(src, pendingFile, false);\n+      FSDirWriteFileOp.persistBlocks(dir, src, pendingFile, false);\n     } finally {\n       writeUnlock();\n     }\n     getEditLog().logSync();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void fsync(String src, long fileId, String clientName, long lastBlockLength)\n      throws IOException {\n    NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n    checkOperation(OperationCategory.WRITE);\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n\n    FSPermissionChecker pc \u003d getPermissionChecker();\n    waitForLoadingFSImage();\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      checkNameNodeSafeMode(\"Cannot fsync file \" + src);\n      src \u003d dir.resolvePath(pc, src, pathComponents);\n      final INode inode;\n      if (fileId \u003d\u003d HdfsConstants.GRANDFATHER_INODE_ID) {\n        // Older clients may not have given us an inode ID to work with.\n        // In this case, we have to try to resolve the path and hope it\n        // hasn\u0027t changed or been deleted since the file was opened for write.\n        inode \u003d dir.getINode(src);\n      } else {\n        inode \u003d dir.getInode(fileId);\n        if (inode !\u003d null) src \u003d inode.getFullPathName();\n      }\n      final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n      if (lastBlockLength \u003e 0) {\n        pendingFile.getFileUnderConstructionFeature().updateLengthOfLastBlock(\n            pendingFile, lastBlockLength);\n      }\n      FSDirWriteFileOp.persistBlocks(dir, src, pendingFile, false);\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "6ae2a0d048e133b43249c248a75a4d77d9abb80d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8249. Separate HdfsConstants into the client and the server side class. Contributed by Haohui Mai.\n",
      "commitDate": "02/05/15 10:03 AM",
      "commitName": "6ae2a0d048e133b43249c248a75a4d77d9abb80d",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "01/05/15 4:42 PM",
      "commitNameOld": "6f541edce0ed64bf316276715c4bc07794ff20ac",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 0.72,
      "commitsBetweenForRepo": 6,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,34 +1,34 @@\n   void fsync(String src, long fileId, String clientName, long lastBlockLength)\n       throws IOException {\n     NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n     checkOperation(OperationCategory.WRITE);\n     byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n \n     FSPermissionChecker pc \u003d getPermissionChecker();\n     waitForLoadingFSImage();\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       checkNameNodeSafeMode(\"Cannot fsync file \" + src);\n       src \u003d dir.resolvePath(pc, src, pathComponents);\n       final INode inode;\n-      if (fileId \u003d\u003d HdfsConstantsClient.GRANDFATHER_INODE_ID) {\n+      if (fileId \u003d\u003d HdfsConstants.GRANDFATHER_INODE_ID) {\n         // Older clients may not have given us an inode ID to work with.\n         // In this case, we have to try to resolve the path and hope it\n         // hasn\u0027t changed or been deleted since the file was opened for write.\n         inode \u003d dir.getINode(src);\n       } else {\n         inode \u003d dir.getInode(fileId);\n         if (inode !\u003d null) src \u003d inode.getFullPathName();\n       }\n       final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n       if (lastBlockLength \u003e 0) {\n         pendingFile.getFileUnderConstructionFeature().updateLengthOfLastBlock(\n             pendingFile, lastBlockLength);\n       }\n       persistBlocks(src, pendingFile, false);\n     } finally {\n       writeUnlock();\n     }\n     getEditLog().logSync();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void fsync(String src, long fileId, String clientName, long lastBlockLength)\n      throws IOException {\n    NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n    checkOperation(OperationCategory.WRITE);\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n\n    FSPermissionChecker pc \u003d getPermissionChecker();\n    waitForLoadingFSImage();\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      checkNameNodeSafeMode(\"Cannot fsync file \" + src);\n      src \u003d dir.resolvePath(pc, src, pathComponents);\n      final INode inode;\n      if (fileId \u003d\u003d HdfsConstants.GRANDFATHER_INODE_ID) {\n        // Older clients may not have given us an inode ID to work with.\n        // In this case, we have to try to resolve the path and hope it\n        // hasn\u0027t changed or been deleted since the file was opened for write.\n        inode \u003d dir.getINode(src);\n      } else {\n        inode \u003d dir.getInode(fileId);\n        if (inode !\u003d null) src \u003d inode.getFullPathName();\n      }\n      final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n      if (lastBlockLength \u003e 0) {\n        pendingFile.getFileUnderConstructionFeature().updateLengthOfLastBlock(\n            pendingFile, lastBlockLength);\n      }\n      persistBlocks(src, pendingFile, false);\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "76e7264e8d6407f527bd877009aca11f7bb63bd7": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8165. Move GRANDFATHER_GENERATION_STAMP and GRANDFATER_INODE_ID to hdfs-client. Contributed by Haohui Mai.\n",
      "commitDate": "16/04/15 10:49 PM",
      "commitName": "76e7264e8d6407f527bd877009aca11f7bb63bd7",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "14/04/15 3:05 PM",
      "commitNameOld": "fddd55279d0bdd08b3b40aba6fe2ded1d2e0d846",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 2.32,
      "commitsBetweenForRepo": 17,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,34 +1,34 @@\n   void fsync(String src, long fileId, String clientName, long lastBlockLength)\n       throws IOException {\n     NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n     checkOperation(OperationCategory.WRITE);\n     byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n \n     FSPermissionChecker pc \u003d getPermissionChecker();\n     waitForLoadingFSImage();\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       checkNameNodeSafeMode(\"Cannot fsync file \" + src);\n       src \u003d dir.resolvePath(pc, src, pathComponents);\n       final INode inode;\n-      if (fileId \u003d\u003d INodeId.GRANDFATHER_INODE_ID) {\n+      if (fileId \u003d\u003d HdfsConstantsClient.GRANDFATHER_INODE_ID) {\n         // Older clients may not have given us an inode ID to work with.\n         // In this case, we have to try to resolve the path and hope it\n         // hasn\u0027t changed or been deleted since the file was opened for write.\n         inode \u003d dir.getINode(src);\n       } else {\n         inode \u003d dir.getInode(fileId);\n         if (inode !\u003d null) src \u003d inode.getFullPathName();\n       }\n       final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n       if (lastBlockLength \u003e 0) {\n         pendingFile.getFileUnderConstructionFeature().updateLengthOfLastBlock(\n             pendingFile, lastBlockLength);\n       }\n       persistBlocks(src, pendingFile, false);\n     } finally {\n       writeUnlock();\n     }\n     getEditLog().logSync();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void fsync(String src, long fileId, String clientName, long lastBlockLength)\n      throws IOException {\n    NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n    checkOperation(OperationCategory.WRITE);\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n\n    FSPermissionChecker pc \u003d getPermissionChecker();\n    waitForLoadingFSImage();\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      checkNameNodeSafeMode(\"Cannot fsync file \" + src);\n      src \u003d dir.resolvePath(pc, src, pathComponents);\n      final INode inode;\n      if (fileId \u003d\u003d HdfsConstantsClient.GRANDFATHER_INODE_ID) {\n        // Older clients may not have given us an inode ID to work with.\n        // In this case, we have to try to resolve the path and hope it\n        // hasn\u0027t changed or been deleted since the file was opened for write.\n        inode \u003d dir.getINode(src);\n      } else {\n        inode \u003d dir.getInode(fileId);\n        if (inode !\u003d null) src \u003d inode.getFullPathName();\n      }\n      final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n      if (lastBlockLength \u003e 0) {\n        pendingFile.getFileUnderConstructionFeature().updateLengthOfLastBlock(\n            pendingFile, lastBlockLength);\n      }\n      persistBlocks(src, pendingFile, false);\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "c78e3a7cdd10c40454e9acb06986ba6d8573cb19": {
      "type": "Yexceptionschange",
      "commitMessage": "HDFS-7059. Avoid resolving path multiple times. Contributed by Jing Zhao.\n",
      "commitDate": "12/12/14 3:13 PM",
      "commitName": "c78e3a7cdd10c40454e9acb06986ba6d8573cb19",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "12/12/14 11:51 AM",
      "commitNameOld": "46612c7a5135d20b20403780b47dd00654aab057",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 0.14,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,34 +1,34 @@\n   void fsync(String src, long fileId, String clientName, long lastBlockLength)\n-      throws IOException, UnresolvedLinkException {\n+      throws IOException {\n     NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n     checkOperation(OperationCategory.WRITE);\n     byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n \n     FSPermissionChecker pc \u003d getPermissionChecker();\n     waitForLoadingFSImage();\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       checkNameNodeSafeMode(\"Cannot fsync file \" + src);\n       src \u003d dir.resolvePath(pc, src, pathComponents);\n       final INode inode;\n       if (fileId \u003d\u003d INodeId.GRANDFATHER_INODE_ID) {\n         // Older clients may not have given us an inode ID to work with.\n         // In this case, we have to try to resolve the path and hope it\n         // hasn\u0027t changed or been deleted since the file was opened for write.\n         inode \u003d dir.getINode(src);\n       } else {\n         inode \u003d dir.getInode(fileId);\n         if (inode !\u003d null) src \u003d inode.getFullPathName();\n       }\n       final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n       if (lastBlockLength \u003e 0) {\n         pendingFile.getFileUnderConstructionFeature().updateLengthOfLastBlock(\n             pendingFile, lastBlockLength);\n       }\n       persistBlocks(src, pendingFile, false);\n     } finally {\n       writeUnlock();\n     }\n     getEditLog().logSync();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void fsync(String src, long fileId, String clientName, long lastBlockLength)\n      throws IOException {\n    NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n    checkOperation(OperationCategory.WRITE);\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n\n    FSPermissionChecker pc \u003d getPermissionChecker();\n    waitForLoadingFSImage();\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      checkNameNodeSafeMode(\"Cannot fsync file \" + src);\n      src \u003d dir.resolvePath(pc, src, pathComponents);\n      final INode inode;\n      if (fileId \u003d\u003d INodeId.GRANDFATHER_INODE_ID) {\n        // Older clients may not have given us an inode ID to work with.\n        // In this case, we have to try to resolve the path and hope it\n        // hasn\u0027t changed or been deleted since the file was opened for write.\n        inode \u003d dir.getINode(src);\n      } else {\n        inode \u003d dir.getInode(fileId);\n        if (inode !\u003d null) src \u003d inode.getFullPathName();\n      }\n      final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n      if (lastBlockLength \u003e 0) {\n        pendingFile.getFileUnderConstructionFeature().updateLengthOfLastBlock(\n            pendingFile, lastBlockLength);\n      }\n      persistBlocks(src, pendingFile, false);\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {
        "oldValue": "[IOException, UnresolvedLinkException]",
        "newValue": "[IOException]"
      }
    },
    "c95b878abf313507666ea018f9e6033c4c166e10": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7415. Move FSNameSystem.resolvePath() to FSDirectory. Contributed by Haohui Mai.\n",
      "commitDate": "20/11/14 7:23 PM",
      "commitName": "c95b878abf313507666ea018f9e6033c4c166e10",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "17/11/14 5:33 PM",
      "commitNameOld": "dcb8e24427b02e2f3ff9a12d2eb1eb878e3443bb",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 3.08,
      "commitsBetweenForRepo": 22,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,33 +1,34 @@\n   void fsync(String src, long fileId, String clientName, long lastBlockLength)\n       throws IOException, UnresolvedLinkException {\n     NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n     checkOperation(OperationCategory.WRITE);\n     byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n \n+    FSPermissionChecker pc \u003d getPermissionChecker();\n     waitForLoadingFSImage();\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       checkNameNodeSafeMode(\"Cannot fsync file \" + src);\n-      src \u003d resolvePath(src, pathComponents);\n+      src \u003d dir.resolvePath(pc, src, pathComponents);\n       final INode inode;\n       if (fileId \u003d\u003d INodeId.GRANDFATHER_INODE_ID) {\n         // Older clients may not have given us an inode ID to work with.\n         // In this case, we have to try to resolve the path and hope it\n         // hasn\u0027t changed or been deleted since the file was opened for write.\n         inode \u003d dir.getINode(src);\n       } else {\n         inode \u003d dir.getInode(fileId);\n         if (inode !\u003d null) src \u003d inode.getFullPathName();\n       }\n       final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n       if (lastBlockLength \u003e 0) {\n         pendingFile.getFileUnderConstructionFeature().updateLengthOfLastBlock(\n             pendingFile, lastBlockLength);\n       }\n       persistBlocks(src, pendingFile, false);\n     } finally {\n       writeUnlock();\n     }\n     getEditLog().logSync();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void fsync(String src, long fileId, String clientName, long lastBlockLength)\n      throws IOException, UnresolvedLinkException {\n    NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n    checkOperation(OperationCategory.WRITE);\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n\n    FSPermissionChecker pc \u003d getPermissionChecker();\n    waitForLoadingFSImage();\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      checkNameNodeSafeMode(\"Cannot fsync file \" + src);\n      src \u003d dir.resolvePath(pc, src, pathComponents);\n      final INode inode;\n      if (fileId \u003d\u003d INodeId.GRANDFATHER_INODE_ID) {\n        // Older clients may not have given us an inode ID to work with.\n        // In this case, we have to try to resolve the path and hope it\n        // hasn\u0027t changed or been deleted since the file was opened for write.\n        inode \u003d dir.getINode(src);\n      } else {\n        inode \u003d dir.getInode(fileId);\n        if (inode !\u003d null) src \u003d inode.getFullPathName();\n      }\n      final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n      if (lastBlockLength \u003e 0) {\n        pendingFile.getFileUnderConstructionFeature().updateLengthOfLastBlock(\n            pendingFile, lastBlockLength);\n      }\n      persistBlocks(src, pendingFile, false);\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "407bb3d3e452c8277c498dd14e0cc5b7762a7091": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6509. Create a special /.reserved/raw directory for raw access to encrypted data. Contributed by Charles Lamb.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/fs-encryption@1614490 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "29/07/14 2:11 PM",
      "commitName": "407bb3d3e452c8277c498dd14e0cc5b7762a7091",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "27/07/14 6:32 AM",
      "commitNameOld": "1d3e9ec935de0e5bcb6fda0b88fa69d9e9ce6595",
      "commitAuthorOld": "",
      "daysBetweenCommits": 2.32,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,33 +1,33 @@\n   void fsync(String src, long fileId, String clientName, long lastBlockLength)\n       throws IOException, UnresolvedLinkException {\n     NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n     checkOperation(OperationCategory.WRITE);\n     byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n \n     waitForLoadingFSImage();\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       checkNameNodeSafeMode(\"Cannot fsync file \" + src);\n-      src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n+      src \u003d resolvePath(src, pathComponents);\n       final INode inode;\n       if (fileId \u003d\u003d INodeId.GRANDFATHER_INODE_ID) {\n         // Older clients may not have given us an inode ID to work with.\n         // In this case, we have to try to resolve the path and hope it\n         // hasn\u0027t changed or been deleted since the file was opened for write.\n         inode \u003d dir.getINode(src);\n       } else {\n         inode \u003d dir.getInode(fileId);\n         if (inode !\u003d null) src \u003d inode.getFullPathName();\n       }\n       final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n       if (lastBlockLength \u003e 0) {\n         pendingFile.getFileUnderConstructionFeature().updateLengthOfLastBlock(\n             pendingFile, lastBlockLength);\n       }\n       persistBlocks(src, pendingFile, false);\n     } finally {\n       writeUnlock();\n     }\n     getEditLog().logSync();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void fsync(String src, long fileId, String clientName, long lastBlockLength)\n      throws IOException, UnresolvedLinkException {\n    NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n    checkOperation(OperationCategory.WRITE);\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n\n    waitForLoadingFSImage();\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      checkNameNodeSafeMode(\"Cannot fsync file \" + src);\n      src \u003d resolvePath(src, pathComponents);\n      final INode inode;\n      if (fileId \u003d\u003d INodeId.GRANDFATHER_INODE_ID) {\n        // Older clients may not have given us an inode ID to work with.\n        // In this case, we have to try to resolve the path and hope it\n        // hasn\u0027t changed or been deleted since the file was opened for write.\n        inode \u003d dir.getINode(src);\n      } else {\n        inode \u003d dir.getInode(fileId);\n        if (inode !\u003d null) src \u003d inode.getFullPathName();\n      }\n      final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n      if (lastBlockLength \u003e 0) {\n        pendingFile.getFileUnderConstructionFeature().updateLengthOfLastBlock(\n            pendingFile, lastBlockLength);\n      }\n      persistBlocks(src, pendingFile, false);\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "a4e0ff5e052abad498595ee198b49c5310c9ec0d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6480. Move waitForReady() from FSDirectory to FSNamesystem. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1603705 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/06/14 9:13 PM",
      "commitName": "a4e0ff5e052abad498595ee198b49c5310c9ec0d",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "17/06/14 6:00 PM",
      "commitNameOld": "8e8a769e7f5ce806ffdf584f017512ab58cd84e8",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 1.13,
      "commitsBetweenForRepo": 15,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,31 +1,33 @@\n   void fsync(String src, long fileId, String clientName, long lastBlockLength)\n       throws IOException, UnresolvedLinkException {\n     NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n     checkOperation(OperationCategory.WRITE);\n     byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n+\n+    waitForLoadingFSImage();\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       checkNameNodeSafeMode(\"Cannot fsync file \" + src);\n       src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n       final INode inode;\n       if (fileId \u003d\u003d INodeId.GRANDFATHER_INODE_ID) {\n         // Older clients may not have given us an inode ID to work with.\n         // In this case, we have to try to resolve the path and hope it\n         // hasn\u0027t changed or been deleted since the file was opened for write.\n         inode \u003d dir.getINode(src);\n       } else {\n         inode \u003d dir.getInode(fileId);\n         if (inode !\u003d null) src \u003d inode.getFullPathName();\n       }\n       final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n       if (lastBlockLength \u003e 0) {\n         pendingFile.getFileUnderConstructionFeature().updateLengthOfLastBlock(\n             pendingFile, lastBlockLength);\n       }\n       persistBlocks(src, pendingFile, false);\n     } finally {\n       writeUnlock();\n     }\n     getEditLog().logSync();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void fsync(String src, long fileId, String clientName, long lastBlockLength)\n      throws IOException, UnresolvedLinkException {\n    NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n    checkOperation(OperationCategory.WRITE);\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n\n    waitForLoadingFSImage();\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      checkNameNodeSafeMode(\"Cannot fsync file \" + src);\n      src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n      final INode inode;\n      if (fileId \u003d\u003d INodeId.GRANDFATHER_INODE_ID) {\n        // Older clients may not have given us an inode ID to work with.\n        // In this case, we have to try to resolve the path and hope it\n        // hasn\u0027t changed or been deleted since the file was opened for write.\n        inode \u003d dir.getINode(src);\n      } else {\n        inode \u003d dir.getInode(fileId);\n        if (inode !\u003d null) src \u003d inode.getFullPathName();\n      }\n      final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n      if (lastBlockLength \u003e 0) {\n        pendingFile.getFileUnderConstructionFeature().updateLengthOfLastBlock(\n            pendingFile, lastBlockLength);\n      }\n      persistBlocks(src, pendingFile, false);\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "e98529858edeed11c4f900b0db30d7e4eb2ab1ec": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6315. Decouple recording edit logs from FSDirectory. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1601960 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/06/14 10:22 AM",
      "commitName": "e98529858edeed11c4f900b0db30d7e4eb2ab1ec",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "03/06/14 11:33 AM",
      "commitNameOld": "02fcb6b6bae7c3fe2a10b00b2a563e4098ff225e",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 7.95,
      "commitsBetweenForRepo": 35,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,31 +1,31 @@\n   void fsync(String src, long fileId, String clientName, long lastBlockLength)\n       throws IOException, UnresolvedLinkException {\n     NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n     checkOperation(OperationCategory.WRITE);\n     byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       checkNameNodeSafeMode(\"Cannot fsync file \" + src);\n       src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n       final INode inode;\n       if (fileId \u003d\u003d INodeId.GRANDFATHER_INODE_ID) {\n         // Older clients may not have given us an inode ID to work with.\n         // In this case, we have to try to resolve the path and hope it\n         // hasn\u0027t changed or been deleted since the file was opened for write.\n         inode \u003d dir.getINode(src);\n       } else {\n         inode \u003d dir.getInode(fileId);\n         if (inode !\u003d null) src \u003d inode.getFullPathName();\n       }\n       final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n       if (lastBlockLength \u003e 0) {\n         pendingFile.getFileUnderConstructionFeature().updateLengthOfLastBlock(\n             pendingFile, lastBlockLength);\n       }\n-      dir.persistBlocks(src, pendingFile, false);\n+      persistBlocks(src, pendingFile, false);\n     } finally {\n       writeUnlock();\n     }\n     getEditLog().logSync();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void fsync(String src, long fileId, String clientName, long lastBlockLength)\n      throws IOException, UnresolvedLinkException {\n    NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n    checkOperation(OperationCategory.WRITE);\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      checkNameNodeSafeMode(\"Cannot fsync file \" + src);\n      src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n      final INode inode;\n      if (fileId \u003d\u003d INodeId.GRANDFATHER_INODE_ID) {\n        // Older clients may not have given us an inode ID to work with.\n        // In this case, we have to try to resolve the path and hope it\n        // hasn\u0027t changed or been deleted since the file was opened for write.\n        inode \u003d dir.getINode(src);\n      } else {\n        inode \u003d dir.getInode(fileId);\n        if (inode !\u003d null) src \u003d inode.getFullPathName();\n      }\n      final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n      if (lastBlockLength \u003e 0) {\n        pendingFile.getFileUnderConstructionFeature().updateLengthOfLastBlock(\n            pendingFile, lastBlockLength);\n      }\n      persistBlocks(src, pendingFile, false);\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "f131dba8a3d603a5d15c4f035ed3da75b4daf0dc": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-6294. Use INode IDs to avoid conflicts when a file open for write is renamed (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1593634 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/05/14 3:36 PM",
      "commitName": "f131dba8a3d603a5d15c4f035ed3da75b4daf0dc",
      "commitAuthor": "Colin McCabe",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-6294. Use INode IDs to avoid conflicts when a file open for write is renamed (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1593634 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "09/05/14 3:36 PM",
          "commitName": "f131dba8a3d603a5d15c4f035ed3da75b4daf0dc",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "30/04/14 10:44 AM",
          "commitNameOld": "0689363343a281a6f7f6f395227668bddc2663eb",
          "commitAuthorOld": "Haohui Mai",
          "daysBetweenCommits": 9.2,
          "commitsBetweenForRepo": 39,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,21 +1,31 @@\n-  void fsync(String src, String clientName, long lastBlockLength) \n+  void fsync(String src, long fileId, String clientName, long lastBlockLength)\n       throws IOException, UnresolvedLinkException {\n     NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n     checkOperation(OperationCategory.WRITE);\n     byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       checkNameNodeSafeMode(\"Cannot fsync file \" + src);\n       src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n-      INodeFile pendingFile  \u003d checkLease(src, clientName);\n+      final INode inode;\n+      if (fileId \u003d\u003d INodeId.GRANDFATHER_INODE_ID) {\n+        // Older clients may not have given us an inode ID to work with.\n+        // In this case, we have to try to resolve the path and hope it\n+        // hasn\u0027t changed or been deleted since the file was opened for write.\n+        inode \u003d dir.getINode(src);\n+      } else {\n+        inode \u003d dir.getInode(fileId);\n+        if (inode !\u003d null) src \u003d inode.getFullPathName();\n+      }\n+      final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n       if (lastBlockLength \u003e 0) {\n         pendingFile.getFileUnderConstructionFeature().updateLengthOfLastBlock(\n             pendingFile, lastBlockLength);\n       }\n       dir.persistBlocks(src, pendingFile, false);\n     } finally {\n       writeUnlock();\n     }\n     getEditLog().logSync();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  void fsync(String src, long fileId, String clientName, long lastBlockLength)\n      throws IOException, UnresolvedLinkException {\n    NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n    checkOperation(OperationCategory.WRITE);\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      checkNameNodeSafeMode(\"Cannot fsync file \" + src);\n      src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n      final INode inode;\n      if (fileId \u003d\u003d INodeId.GRANDFATHER_INODE_ID) {\n        // Older clients may not have given us an inode ID to work with.\n        // In this case, we have to try to resolve the path and hope it\n        // hasn\u0027t changed or been deleted since the file was opened for write.\n        inode \u003d dir.getINode(src);\n      } else {\n        inode \u003d dir.getInode(fileId);\n        if (inode !\u003d null) src \u003d inode.getFullPathName();\n      }\n      final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n      if (lastBlockLength \u003e 0) {\n        pendingFile.getFileUnderConstructionFeature().updateLengthOfLastBlock(\n            pendingFile, lastBlockLength);\n      }\n      dir.persistBlocks(src, pendingFile, false);\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {
            "oldValue": "[src-String, clientName-String, lastBlockLength-long]",
            "newValue": "[src-String, fileId-long, clientName-String, lastBlockLength-long]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-6294. Use INode IDs to avoid conflicts when a file open for write is renamed (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1593634 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "09/05/14 3:36 PM",
          "commitName": "f131dba8a3d603a5d15c4f035ed3da75b4daf0dc",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "30/04/14 10:44 AM",
          "commitNameOld": "0689363343a281a6f7f6f395227668bddc2663eb",
          "commitAuthorOld": "Haohui Mai",
          "daysBetweenCommits": 9.2,
          "commitsBetweenForRepo": 39,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,21 +1,31 @@\n-  void fsync(String src, String clientName, long lastBlockLength) \n+  void fsync(String src, long fileId, String clientName, long lastBlockLength)\n       throws IOException, UnresolvedLinkException {\n     NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n     checkOperation(OperationCategory.WRITE);\n     byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       checkNameNodeSafeMode(\"Cannot fsync file \" + src);\n       src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n-      INodeFile pendingFile  \u003d checkLease(src, clientName);\n+      final INode inode;\n+      if (fileId \u003d\u003d INodeId.GRANDFATHER_INODE_ID) {\n+        // Older clients may not have given us an inode ID to work with.\n+        // In this case, we have to try to resolve the path and hope it\n+        // hasn\u0027t changed or been deleted since the file was opened for write.\n+        inode \u003d dir.getINode(src);\n+      } else {\n+        inode \u003d dir.getInode(fileId);\n+        if (inode !\u003d null) src \u003d inode.getFullPathName();\n+      }\n+      final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n       if (lastBlockLength \u003e 0) {\n         pendingFile.getFileUnderConstructionFeature().updateLengthOfLastBlock(\n             pendingFile, lastBlockLength);\n       }\n       dir.persistBlocks(src, pendingFile, false);\n     } finally {\n       writeUnlock();\n     }\n     getEditLog().logSync();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  void fsync(String src, long fileId, String clientName, long lastBlockLength)\n      throws IOException, UnresolvedLinkException {\n    NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n    checkOperation(OperationCategory.WRITE);\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      checkNameNodeSafeMode(\"Cannot fsync file \" + src);\n      src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n      final INode inode;\n      if (fileId \u003d\u003d INodeId.GRANDFATHER_INODE_ID) {\n        // Older clients may not have given us an inode ID to work with.\n        // In this case, we have to try to resolve the path and hope it\n        // hasn\u0027t changed or been deleted since the file was opened for write.\n        inode \u003d dir.getINode(src);\n      } else {\n        inode \u003d dir.getInode(fileId);\n        if (inode !\u003d null) src \u003d inode.getFullPathName();\n      }\n      final INodeFile pendingFile \u003d checkLease(src, clientName, inode, fileId);\n      if (lastBlockLength \u003e 0) {\n        pendingFile.getFileUnderConstructionFeature().updateLengthOfLastBlock(\n            pendingFile, lastBlockLength);\n      }\n      dir.persistBlocks(src, pendingFile, false);\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {}
        }
      ]
    },
    "ce68f410b05a58ad05965f32ad7f5b246b363a75": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5285. Flatten INodeFile hierarchy: Replace INodeFileUnderConstruction and INodeFileUnderConstructionWithSnapshot with FileUnderContructionFeature.  Contributed by jing9\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1544389 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/11/13 5:39 PM",
      "commitName": "ce68f410b05a58ad05965f32ad7f5b246b363a75",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "21/11/13 9:12 AM",
      "commitNameOld": "f91a45a96c21db9e5d40097c7d3f5d005ae10dde",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 0.35,
      "commitsBetweenForRepo": 6,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,21 @@\n   void fsync(String src, String clientName, long lastBlockLength) \n       throws IOException, UnresolvedLinkException {\n     NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n     checkOperation(OperationCategory.WRITE);\n     byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       checkNameNodeSafeMode(\"Cannot fsync file \" + src);\n       src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n-      INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n+      INodeFile pendingFile  \u003d checkLease(src, clientName);\n       if (lastBlockLength \u003e 0) {\n-        pendingFile.updateLengthOfLastBlock(lastBlockLength);\n+        pendingFile.getFileUnderConstructionFeature().updateLengthOfLastBlock(\n+            pendingFile, lastBlockLength);\n       }\n       dir.persistBlocks(src, pendingFile, false);\n     } finally {\n       writeUnlock();\n     }\n     getEditLog().logSync();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void fsync(String src, String clientName, long lastBlockLength) \n      throws IOException, UnresolvedLinkException {\n    NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n    checkOperation(OperationCategory.WRITE);\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      checkNameNodeSafeMode(\"Cannot fsync file \" + src);\n      src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n      INodeFile pendingFile  \u003d checkLease(src, clientName);\n      if (lastBlockLength \u003e 0) {\n        pendingFile.getFileUnderConstructionFeature().updateLengthOfLastBlock(\n            pendingFile, lastBlockLength);\n      }\n      dir.persistBlocks(src, pendingFile, false);\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "34f08944b7c8d58f531a3f3bf3d4ee4cd3fa643a": {
      "type": "Ybodychange",
      "commitMessage": "merge trunk to branch HDFS-4949\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1532952 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/10/13 7:14 PM",
      "commitName": "34f08944b7c8d58f531a3f3bf3d4ee4cd3fa643a",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "16/10/13 3:15 PM",
      "commitNameOld": "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 0.17,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,20 @@\n   void fsync(String src, String clientName, long lastBlockLength) \n       throws IOException, UnresolvedLinkException {\n     NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n     checkOperation(OperationCategory.WRITE);\n     byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n-      if (isInSafeMode()) {\n-        throw new SafeModeException(\"Cannot fsync file \" + src, safeMode);\n-      }\n+      checkNameNodeSafeMode(\"Cannot fsync file \" + src);\n       src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n       INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n       if (lastBlockLength \u003e 0) {\n         pendingFile.updateLengthOfLastBlock(lastBlockLength);\n       }\n       dir.persistBlocks(src, pendingFile, false);\n     } finally {\n       writeUnlock();\n     }\n     getEditLog().logSync();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void fsync(String src, String clientName, long lastBlockLength) \n      throws IOException, UnresolvedLinkException {\n    NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n    checkOperation(OperationCategory.WRITE);\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      checkNameNodeSafeMode(\"Cannot fsync file \" + src);\n      src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n      INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n      if (lastBlockLength \u003e 0) {\n        pendingFile.updateLengthOfLastBlock(lastBlockLength);\n      }\n      dir.persistBlocks(src, pendingFile, false);\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "1fe1942328856dd832e9f94fb56a40ab3d810870": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5291. Standby namenode after transition to active goes into safemode. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1530112 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/10/13 4:58 PM",
      "commitName": "1fe1942328856dd832e9f94fb56a40ab3d810870",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "06/10/13 11:39 AM",
      "commitNameOld": "7317e97bd72ca30f5db37fa94389dbdb52ae079e",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 1.22,
      "commitsBetweenForRepo": 10,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,20 @@\n   void fsync(String src, String clientName, long lastBlockLength) \n       throws IOException, UnresolvedLinkException {\n     NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n     checkOperation(OperationCategory.WRITE);\n     byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n-      if (isInSafeMode()) {\n-        throw new SafeModeException(\"Cannot fsync file \" + src, safeMode);\n-      }\n+      checkNameNodeSafeMode(\"Cannot fsync file \" + src);\n       src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n       INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n       if (lastBlockLength \u003e 0) {\n         pendingFile.updateLengthOfLastBlock(lastBlockLength);\n       }\n       dir.persistBlocks(src, pendingFile, false);\n     } finally {\n       writeUnlock();\n     }\n     getEditLog().logSync();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void fsync(String src, String clientName, long lastBlockLength) \n      throws IOException, UnresolvedLinkException {\n    NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n    checkOperation(OperationCategory.WRITE);\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      checkNameNodeSafeMode(\"Cannot fsync file \" + src);\n      src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n      INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n      if (lastBlockLength \u003e 0) {\n        pendingFile.updateLengthOfLastBlock(lastBlockLength);\n      }\n      dir.persistBlocks(src, pendingFile, false);\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "8c7a7e619699386f9e6991842558d78aa0c8053d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5025. Record ClientId and CallId in EditLog to enable rebuilding retry cache in case of HA failover. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1508332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "30/07/13 12:51 AM",
      "commitName": "8c7a7e619699386f9e6991842558d78aa0c8053d",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "26/07/13 4:59 PM",
      "commitNameOld": "dc17bda4b677e30c02c2a9a053895a43e41f7a12",
      "commitAuthorOld": "Konstantin Boudnik",
      "daysBetweenCommits": 3.33,
      "commitsBetweenForRepo": 18,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,22 @@\n   void fsync(String src, String clientName, long lastBlockLength) \n       throws IOException, UnresolvedLinkException {\n     NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n     checkOperation(OperationCategory.WRITE);\n     byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       if (isInSafeMode()) {\n         throw new SafeModeException(\"Cannot fsync file \" + src, safeMode);\n       }\n       src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n       INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n       if (lastBlockLength \u003e 0) {\n         pendingFile.updateLengthOfLastBlock(lastBlockLength);\n       }\n-      dir.persistBlocks(src, pendingFile);\n+      dir.persistBlocks(src, pendingFile, false);\n     } finally {\n       writeUnlock();\n     }\n     getEditLog().logSync();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void fsync(String src, String clientName, long lastBlockLength) \n      throws IOException, UnresolvedLinkException {\n    NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n    checkOperation(OperationCategory.WRITE);\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      if (isInSafeMode()) {\n        throw new SafeModeException(\"Cannot fsync file \" + src, safeMode);\n      }\n      src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n      INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n      if (lastBlockLength \u003e 0) {\n        pendingFile.updateLengthOfLastBlock(lastBlockLength);\n      }\n      dir.persistBlocks(src, pendingFile, false);\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "0b101bd7e875ee5597ddb8f0d887159076310ffa": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4434. Reverting change r1470089 that merges trunk to HDFS-2802.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2802@1470194 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/04/13 9:57 AM",
      "commitName": "0b101bd7e875ee5597ddb8f0d887159076310ffa",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "19/04/13 5:02 PM",
      "commitNameOld": "9af0babe7ef9c4bc956b77aac250f8eee6c8450f",
      "commitAuthorOld": "",
      "daysBetweenCommits": 0.7,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,20 @@\n   void fsync(String src, String clientName, long lastBlockLength) \n       throws IOException, UnresolvedLinkException {\n     NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n     checkOperation(OperationCategory.WRITE);\n-    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       if (isInSafeMode()) {\n         throw new SafeModeException(\"Cannot fsync file \" + src, safeMode);\n       }\n-      src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n       INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n       if (lastBlockLength \u003e 0) {\n         pendingFile.updateLengthOfLastBlock(lastBlockLength);\n       }\n       dir.persistBlocks(src, pendingFile);\n     } finally {\n       writeUnlock();\n     }\n     getEditLog().logSync();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void fsync(String src, String clientName, long lastBlockLength) \n      throws IOException, UnresolvedLinkException {\n    NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n    checkOperation(OperationCategory.WRITE);\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      if (isInSafeMode()) {\n        throw new SafeModeException(\"Cannot fsync file \" + src, safeMode);\n      }\n      INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n      if (lastBlockLength \u003e 0) {\n        pendingFile.updateLengthOfLastBlock(lastBlockLength);\n      }\n      dir.persistBlocks(src, pendingFile);\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "980e6c54bab4ffc87e168cd5c217fef44c72a878": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4434. Provide a mapping from INodeId to INode. Contributed by Suresh Srinivas.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1469644 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/04/13 5:10 PM",
      "commitName": "980e6c54bab4ffc87e168cd5c217fef44c72a878",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "12/04/13 6:35 PM",
      "commitNameOld": "242028a3fb887708dea5ef557c0ded22e014ac7d",
      "commitAuthorOld": "Konstantin Shvachko",
      "daysBetweenCommits": 5.94,
      "commitsBetweenForRepo": 22,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,22 @@\n   void fsync(String src, String clientName, long lastBlockLength) \n       throws IOException, UnresolvedLinkException {\n     NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n     checkOperation(OperationCategory.WRITE);\n+    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       if (isInSafeMode()) {\n         throw new SafeModeException(\"Cannot fsync file \" + src, safeMode);\n       }\n+      src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n       INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n       if (lastBlockLength \u003e 0) {\n         pendingFile.updateLengthOfLastBlock(lastBlockLength);\n       }\n       dir.persistBlocks(src, pendingFile);\n     } finally {\n       writeUnlock();\n     }\n     getEditLog().logSync();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void fsync(String src, String clientName, long lastBlockLength) \n      throws IOException, UnresolvedLinkException {\n    NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n    checkOperation(OperationCategory.WRITE);\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      if (isInSafeMode()) {\n        throw new SafeModeException(\"Cannot fsync file \" + src, safeMode);\n      }\n      src \u003d FSDirectory.resolvePath(src, pathComponents, dir);\n      INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n      if (lastBlockLength \u003e 0) {\n        pendingFile.updateLengthOfLastBlock(lastBlockLength);\n      }\n      dir.persistBlocks(src, pendingFile);\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "3bf09c51501a23b7fa28fd0a0c4c0965858d026c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4591. HA clients can fail to fail over while Standby NN is performing long checkpoint. Contributed by Aaron T. Myers.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1456107 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/03/13 12:51 PM",
      "commitName": "3bf09c51501a23b7fa28fd0a0c4c0965858d026c",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "12/03/13 7:32 PM",
      "commitNameOld": "86a940f7adc5bd9c9eaea2283df5e014e5079ab6",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 0.72,
      "commitsBetweenForRepo": 9,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,19 +1,20 @@\n   void fsync(String src, String clientName, long lastBlockLength) \n       throws IOException, UnresolvedLinkException {\n     NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n+    checkOperation(OperationCategory.WRITE);\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       if (isInSafeMode()) {\n         throw new SafeModeException(\"Cannot fsync file \" + src, safeMode);\n       }\n       INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n       if (lastBlockLength \u003e 0) {\n         pendingFile.updateLengthOfLastBlock(lastBlockLength);\n       }\n       dir.persistBlocks(src, pendingFile);\n     } finally {\n       writeUnlock();\n     }\n     getEditLog().logSync();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void fsync(String src, String clientName, long lastBlockLength) \n      throws IOException, UnresolvedLinkException {\n    NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n    checkOperation(OperationCategory.WRITE);\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      if (isInSafeMode()) {\n        throw new SafeModeException(\"Cannot fsync file \" + src, safeMode);\n      }\n      INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n      if (lastBlockLength \u003e 0) {\n        pendingFile.updateLengthOfLastBlock(lastBlockLength);\n      }\n      dir.persistBlocks(src, pendingFile);\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "9821af9ce8a56a2c583f1ed938902c20e897048f": {
      "type": "Ybodychange",
      "commitMessage": "Reverting the previous merge r1416603 which committed some extra changes\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2802@1416712 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "03/12/12 2:43 PM",
      "commitName": "9821af9ce8a56a2c583f1ed938902c20e897048f",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "03/12/12 10:04 AM",
      "commitNameOld": "d500d59cbef51f1b0b0291995893b85a139bcec9",
      "commitAuthorOld": "",
      "daysBetweenCommits": 0.19,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,19 @@\n   void fsync(String src, String clientName, long lastBlockLength) \n       throws IOException, UnresolvedLinkException {\n     NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       if (isInSafeMode()) {\n         throw new SafeModeException(\"Cannot fsync file \" + src, safeMode);\n       }\n-      final INodeFileUnderConstruction pendingFile  \u003d checkLease(\n-          src, clientName, dir.getINode(src));\n+      INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n       if (lastBlockLength \u003e 0) {\n         pendingFile.updateLengthOfLastBlock(lastBlockLength);\n       }\n       dir.persistBlocks(src, pendingFile);\n     } finally {\n       writeUnlock();\n     }\n     getEditLog().logSync();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void fsync(String src, String clientName, long lastBlockLength) \n      throws IOException, UnresolvedLinkException {\n    NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      if (isInSafeMode()) {\n        throw new SafeModeException(\"Cannot fsync file \" + src, safeMode);\n      }\n      INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n      if (lastBlockLength \u003e 0) {\n        pendingFile.updateLengthOfLastBlock(lastBlockLength);\n      }\n      dir.persistBlocks(src, pendingFile);\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "571da54179f731eb8421ffc681169799588f76bc": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-4213. Add an API to hsync for updating the last block length at the namenode. Contributed by Jing Zhao\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1415799 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "30/11/12 11:24 AM",
      "commitName": "571da54179f731eb8421ffc681169799588f76bc",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-4213. Add an API to hsync for updating the last block length at the namenode. Contributed by Jing Zhao\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1415799 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "30/11/12 11:24 AM",
          "commitName": "571da54179f731eb8421ffc681169799588f76bc",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "30/11/12 11:19 AM",
          "commitNameOld": "d866f81edbd70121a9e29e5d25be67e1c464397e",
          "commitAuthorOld": "Aaron Myers",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,16 +1,19 @@\n-  void fsync(String src, String clientName) \n+  void fsync(String src, String clientName, long lastBlockLength) \n       throws IOException, UnresolvedLinkException {\n     NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       if (isInSafeMode()) {\n         throw new SafeModeException(\"Cannot fsync file \" + src, safeMode);\n       }\n       INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n+      if (lastBlockLength \u003e 0) {\n+        pendingFile.updateLengthOfLastBlock(lastBlockLength);\n+      }\n       dir.persistBlocks(src, pendingFile);\n     } finally {\n       writeUnlock();\n     }\n     getEditLog().logSync();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  void fsync(String src, String clientName, long lastBlockLength) \n      throws IOException, UnresolvedLinkException {\n    NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      if (isInSafeMode()) {\n        throw new SafeModeException(\"Cannot fsync file \" + src, safeMode);\n      }\n      INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n      if (lastBlockLength \u003e 0) {\n        pendingFile.updateLengthOfLastBlock(lastBlockLength);\n      }\n      dir.persistBlocks(src, pendingFile);\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {
            "oldValue": "[src-String, clientName-String]",
            "newValue": "[src-String, clientName-String, lastBlockLength-long]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-4213. Add an API to hsync for updating the last block length at the namenode. Contributed by Jing Zhao\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1415799 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "30/11/12 11:24 AM",
          "commitName": "571da54179f731eb8421ffc681169799588f76bc",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "30/11/12 11:19 AM",
          "commitNameOld": "d866f81edbd70121a9e29e5d25be67e1c464397e",
          "commitAuthorOld": "Aaron Myers",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,16 +1,19 @@\n-  void fsync(String src, String clientName) \n+  void fsync(String src, String clientName, long lastBlockLength) \n       throws IOException, UnresolvedLinkException {\n     NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       if (isInSafeMode()) {\n         throw new SafeModeException(\"Cannot fsync file \" + src, safeMode);\n       }\n       INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n+      if (lastBlockLength \u003e 0) {\n+        pendingFile.updateLengthOfLastBlock(lastBlockLength);\n+      }\n       dir.persistBlocks(src, pendingFile);\n     } finally {\n       writeUnlock();\n     }\n     getEditLog().logSync();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  void fsync(String src, String clientName, long lastBlockLength) \n      throws IOException, UnresolvedLinkException {\n    NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      if (isInSafeMode()) {\n        throw new SafeModeException(\"Cannot fsync file \" + src, safeMode);\n      }\n      INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n      if (lastBlockLength \u003e 0) {\n        pendingFile.updateLengthOfLastBlock(lastBlockLength);\n      }\n      dir.persistBlocks(src, pendingFile);\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {}
        }
      ]
    },
    "cea7bbc630deede93dbe6a1bbda56ad49de4f3de": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4122. Cleanup HDFS logs and reduce the size of logged messages. Contributed by Suresh Srinivas.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1403120 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/10/12 4:10 PM",
      "commitName": "cea7bbc630deede93dbe6a1bbda56ad49de4f3de",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "26/10/12 11:08 AM",
      "commitNameOld": "0e796b61e829c4bf763caf13b0f53cb1bcefdeee",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 2.21,
      "commitsBetweenForRepo": 10,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,16 @@\n   void fsync(String src, String clientName) \n       throws IOException, UnresolvedLinkException {\n-    NameNode.stateChangeLog.info(\"BLOCK* NameSystem.fsync: file \"\n-                                  + src + \" for \" + clientName);\n+    NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       if (isInSafeMode()) {\n         throw new SafeModeException(\"Cannot fsync file \" + src, safeMode);\n       }\n       INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n       dir.persistBlocks(src, pendingFile);\n     } finally {\n       writeUnlock();\n     }\n     getEditLog().logSync();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void fsync(String src, String clientName) \n      throws IOException, UnresolvedLinkException {\n    NameNode.stateChangeLog.info(\"BLOCK* fsync: \" + src + \" for \" + clientName);\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      if (isInSafeMode()) {\n        throw new SafeModeException(\"Cannot fsync file \" + src, safeMode);\n      }\n      INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n      dir.persistBlocks(src, pendingFile);\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "36d1c49486587c2dbb193e8538b1d4510c462fa6": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2693. Fix synchronization issues around state transition. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1221582 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/12/11 7:03 PM",
      "commitName": "36d1c49486587c2dbb193e8538b1d4510c462fa6",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "16/12/11 10:36 AM",
      "commitNameOld": "371f4228e86f5ebffb3d8647fb30b8bdc2b777c4",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 4.35,
      "commitsBetweenForRepo": 20,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,17 @@\n   void fsync(String src, String clientName) \n       throws IOException, UnresolvedLinkException {\n     NameNode.stateChangeLog.info(\"BLOCK* NameSystem.fsync: file \"\n                                   + src + \" for \" + clientName);\n     writeLock();\n     try {\n+      checkOperation(OperationCategory.WRITE);\n       if (isInSafeMode()) {\n         throw new SafeModeException(\"Cannot fsync file \" + src, safeMode);\n       }\n       INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n       dir.persistBlocks(src, pendingFile);\n     } finally {\n       writeUnlock();\n     }\n     getEditLog().logSync();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void fsync(String src, String clientName) \n      throws IOException, UnresolvedLinkException {\n    NameNode.stateChangeLog.info(\"BLOCK* NameSystem.fsync: file \"\n                                  + src + \" for \" + clientName);\n    writeLock();\n    try {\n      checkOperation(OperationCategory.WRITE);\n      if (isInSafeMode()) {\n        throw new SafeModeException(\"Cannot fsync file \" + src, safeMode);\n      }\n      INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n      dir.persistBlocks(src, pendingFile);\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  void fsync(String src, String clientName) \n      throws IOException, UnresolvedLinkException {\n    NameNode.stateChangeLog.info(\"BLOCK* NameSystem.fsync: file \"\n                                  + src + \" for \" + clientName);\n    writeLock();\n    try {\n      if (isInSafeMode()) {\n        throw new SafeModeException(\"Cannot fsync file \" + src, safeMode);\n      }\n      INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n      dir.persistBlocks(src, pendingFile);\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  void fsync(String src, String clientName) \n      throws IOException, UnresolvedLinkException {\n    NameNode.stateChangeLog.info(\"BLOCK* NameSystem.fsync: file \"\n                                  + src + \" for \" + clientName);\n    writeLock();\n    try {\n      if (isInSafeMode()) {\n        throw new SafeModeException(\"Cannot fsync file \" + src, safeMode);\n      }\n      INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n      dir.persistBlocks(src, pendingFile);\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,16 @@\n+  void fsync(String src, String clientName) \n+      throws IOException, UnresolvedLinkException {\n+    NameNode.stateChangeLog.info(\"BLOCK* NameSystem.fsync: file \"\n+                                  + src + \" for \" + clientName);\n+    writeLock();\n+    try {\n+      if (isInSafeMode()) {\n+        throw new SafeModeException(\"Cannot fsync file \" + src, safeMode);\n+      }\n+      INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n+      dir.persistBlocks(src, pendingFile);\n+    } finally {\n+      writeUnlock();\n+    }\n+    getEditLog().logSync();\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  void fsync(String src, String clientName) \n      throws IOException, UnresolvedLinkException {\n    NameNode.stateChangeLog.info(\"BLOCK* NameSystem.fsync: file \"\n                                  + src + \" for \" + clientName);\n    writeLock();\n    try {\n      if (isInSafeMode()) {\n        throw new SafeModeException(\"Cannot fsync file \" + src, safeMode);\n      }\n      INodeFileUnderConstruction pendingFile  \u003d checkLease(src, clientName);\n      dir.persistBlocks(src, pendingFile);\n    } finally {\n      writeUnlock();\n    }\n    getEditLog().logSync();\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java"
    }
  }
}