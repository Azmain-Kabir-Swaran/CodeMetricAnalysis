{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "CacheManager.java",
  "functionName": "addDirectiveFromEditLog",
  "functionId": "addDirectiveFromEditLog___directive-CacheDirectiveInfo",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
  "functionStartLine": 533,
  "functionEndLine": 543,
  "numCommitsSeen": 56,
  "timeTaken": 1809,
  "changeHistory": [
    "b9ae3087c0f83bfeeea47ded8e19932b46fd2350",
    "9da451cac57f3cd64c2c047675e5b60ca88ecf83"
  ],
  "changeHistoryShort": {
    "b9ae3087c0f83bfeeea47ded8e19932b46fd2350": "Ybodychange",
    "9da451cac57f3cd64c2c047675e5b60ca88ecf83": "Yintroduced"
  },
  "changeHistoryDetails": {
    "b9ae3087c0f83bfeeea47ded8e19932b46fd2350": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5636. Enforce a max TTL per cache pool (awang via cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1552841 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/12/13 3:27 PM",
      "commitName": "b9ae3087c0f83bfeeea47ded8e19932b46fd2350",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "17/12/13 10:47 AM",
      "commitNameOld": "991c453ca3ac141a3f286f74af8401f83c38b230",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 3.19,
      "commitsBetweenForRepo": 31,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,11 @@\n   CacheDirectiveInfo addDirectiveFromEditLog(CacheDirectiveInfo directive)\n       throws InvalidRequestException {\n     long id \u003d directive.getId();\n-    CacheDirective entry \u003d\n-        new CacheDirective(\n-            directive.getId(),\n-            directive.getPath().toUri().getPath(),\n-            directive.getReplication(),\n-            directive.getExpiration().getAbsoluteMillis());\n+    CacheDirective entry \u003d new CacheDirective(directive);\n     CachePool pool \u003d cachePools.get(directive.getPool());\n     addInternal(entry, pool);\n     if (nextDirectiveId \u003c\u003d id) {\n       nextDirectiveId \u003d id + 1;\n     }\n     return entry.toInfo();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  CacheDirectiveInfo addDirectiveFromEditLog(CacheDirectiveInfo directive)\n      throws InvalidRequestException {\n    long id \u003d directive.getId();\n    CacheDirective entry \u003d new CacheDirective(directive);\n    CachePool pool \u003d cachePools.get(directive.getPool());\n    addInternal(entry, pool);\n    if (nextDirectiveId \u003c\u003d id) {\n      nextDirectiveId \u003d id + 1;\n    }\n    return entry.toInfo();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
      "extendedDetails": {}
    },
    "9da451cac57f3cd64c2c047675e5b60ca88ecf83": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-5430. Support TTL on CacheDirectives. Contributed by Andrew Wang.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1546301 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/11/13 11:20 PM",
      "commitName": "9da451cac57f3cd64c2c047675e5b60ca88ecf83",
      "commitAuthor": "Andrew Wang",
      "diff": "@@ -0,0 +1,16 @@\n+  CacheDirectiveInfo addDirectiveFromEditLog(CacheDirectiveInfo directive)\n+      throws InvalidRequestException {\n+    long id \u003d directive.getId();\n+    CacheDirective entry \u003d\n+        new CacheDirective(\n+            directive.getId(),\n+            directive.getPath().toUri().getPath(),\n+            directive.getReplication(),\n+            directive.getExpiration().getAbsoluteMillis());\n+    CachePool pool \u003d cachePools.get(directive.getPool());\n+    addInternal(entry, pool);\n+    if (nextDirectiveId \u003c\u003d id) {\n+      nextDirectiveId \u003d id + 1;\n+    }\n+    return entry.toInfo();\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  CacheDirectiveInfo addDirectiveFromEditLog(CacheDirectiveInfo directive)\n      throws InvalidRequestException {\n    long id \u003d directive.getId();\n    CacheDirective entry \u003d\n        new CacheDirective(\n            directive.getId(),\n            directive.getPath().toUri().getPath(),\n            directive.getReplication(),\n            directive.getExpiration().getAbsoluteMillis());\n    CachePool pool \u003d cachePools.get(directive.getPool());\n    addInternal(entry, pool);\n    if (nextDirectiveId \u003c\u003d id) {\n      nextDirectiveId \u003d id + 1;\n    }\n    return entry.toInfo();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java"
    }
  }
}