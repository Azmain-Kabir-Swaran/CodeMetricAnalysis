{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "WebHdfsFileSystem.java",
  "functionName": "getUrl",
  "functionId": "getUrl",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
  "functionStartLine": 2259,
  "functionEndLine": 2261,
  "numCommitsSeen": 179,
  "timeTaken": 4007,
  "changeHistory": [
    "867048c3e4b20ece0039a876def129fa5eb9234f",
    "bcf89ddc7d52e04725caf104f5958e33d9f51b35",
    "37bc8e0c1446e4842fd846c083b48e3a19970daa",
    "7a2443e9f8b95816c7df61530cda29e8b040b12e"
  ],
  "changeHistoryShort": {
    "867048c3e4b20ece0039a876def129fa5eb9234f": "Ymultichange(Yexceptionschange,Ybodychange)",
    "bcf89ddc7d52e04725caf104f5958e33d9f51b35": "Yfilerename",
    "37bc8e0c1446e4842fd846c083b48e3a19970daa": "Ybodychange",
    "7a2443e9f8b95816c7df61530cda29e8b040b12e": "Yintroduced"
  },
  "changeHistoryDetails": {
    "867048c3e4b20ece0039a876def129fa5eb9234f": {
      "type": "Ymultichange(Yexceptionschange,Ybodychange)",
      "commitMessage": "HDFS-7163. WebHdfsFileSystem should retry reads according to the configured retry policy. Contributed by Eric Payne.\n",
      "commitDate": "22/12/15 12:08 PM",
      "commitName": "867048c3e4b20ece0039a876def129fa5eb9234f",
      "commitAuthor": "Kihwal Lee",
      "subchanges": [
        {
          "type": "Yexceptionschange",
          "commitMessage": "HDFS-7163. WebHdfsFileSystem should retry reads according to the configured retry policy. Contributed by Eric Payne.\n",
          "commitDate": "22/12/15 12:08 PM",
          "commitName": "867048c3e4b20ece0039a876def129fa5eb9234f",
          "commitAuthor": "Kihwal Lee",
          "commitDateOld": "11/12/15 10:59 AM",
          "commitNameOld": "576b569b6c97bd5f57e52efdabdf8c2fa996a524",
          "commitAuthorOld": "Allen Wittenauer",
          "daysBetweenCommits": 11.05,
          "commitsBetweenForRepo": 77,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,3 +1,13 @@\n-    protected URL getUrl() {\n-      return url;\n+    protected URL getUrl() throws IOException {\n+      // This method is called every time either a read is executed.\n+      // The check for connection \u003d\u003d null is to ensure that a new URL is only\n+      // created upon a new connection and not for every read.\n+      if (cachedConnection \u003d\u003d null) {\n+        // Update URL with current offset. BufferSize doesn\u0027t change, but it\n+        // still must be included when creating the new URL.\n+        updateURLParameters(new BufferSizeParam(bufferSize),\n+            new OffsetParam(pos));\n+        originalUrl \u003d super.getUrl();\n+      }\n+      return originalUrl;\n     }\n\\ No newline at end of file\n",
          "actualSource": "    protected URL getUrl() throws IOException {\n      // This method is called every time either a read is executed.\n      // The check for connection \u003d\u003d null is to ensure that a new URL is only\n      // created upon a new connection and not for every read.\n      if (cachedConnection \u003d\u003d null) {\n        // Update URL with current offset. BufferSize doesn\u0027t change, but it\n        // still must be included when creating the new URL.\n        updateURLParameters(new BufferSizeParam(bufferSize),\n            new OffsetParam(pos));\n        originalUrl \u003d super.getUrl();\n      }\n      return originalUrl;\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[IOException]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7163. WebHdfsFileSystem should retry reads according to the configured retry policy. Contributed by Eric Payne.\n",
          "commitDate": "22/12/15 12:08 PM",
          "commitName": "867048c3e4b20ece0039a876def129fa5eb9234f",
          "commitAuthor": "Kihwal Lee",
          "commitDateOld": "11/12/15 10:59 AM",
          "commitNameOld": "576b569b6c97bd5f57e52efdabdf8c2fa996a524",
          "commitAuthorOld": "Allen Wittenauer",
          "daysBetweenCommits": 11.05,
          "commitsBetweenForRepo": 77,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,3 +1,13 @@\n-    protected URL getUrl() {\n-      return url;\n+    protected URL getUrl() throws IOException {\n+      // This method is called every time either a read is executed.\n+      // The check for connection \u003d\u003d null is to ensure that a new URL is only\n+      // created upon a new connection and not for every read.\n+      if (cachedConnection \u003d\u003d null) {\n+        // Update URL with current offset. BufferSize doesn\u0027t change, but it\n+        // still must be included when creating the new URL.\n+        updateURLParameters(new BufferSizeParam(bufferSize),\n+            new OffsetParam(pos));\n+        originalUrl \u003d super.getUrl();\n+      }\n+      return originalUrl;\n     }\n\\ No newline at end of file\n",
          "actualSource": "    protected URL getUrl() throws IOException {\n      // This method is called every time either a read is executed.\n      // The check for connection \u003d\u003d null is to ensure that a new URL is only\n      // created upon a new connection and not for every read.\n      if (cachedConnection \u003d\u003d null) {\n        // Update URL with current offset. BufferSize doesn\u0027t change, but it\n        // still must be included when creating the new URL.\n        updateURLParameters(new BufferSizeParam(bufferSize),\n            new OffsetParam(pos));\n        originalUrl \u003d super.getUrl();\n      }\n      return originalUrl;\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
          "extendedDetails": {}
        }
      ]
    },
    "bcf89ddc7d52e04725caf104f5958e33d9f51b35": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8052. Move WebHdfsFileSystem into hadoop-hdfs-client. Contributed by Haohui Mai.\n",
      "commitDate": "23/04/15 5:33 PM",
      "commitName": "bcf89ddc7d52e04725caf104f5958e33d9f51b35",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "23/04/15 4:40 PM",
      "commitNameOld": "0b3f8957a87ada1a275c9904b211fdbdcefafb02",
      "commitAuthorOld": "Xuan",
      "daysBetweenCommits": 0.04,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    protected URL getUrl() {\n      return url;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java"
      }
    },
    "37bc8e0c1446e4842fd846c083b48e3a19970daa": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5325. Remove WebHdfsFileSystem#ConnRunner. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1540235 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/11/13 5:19 PM",
      "commitName": "37bc8e0c1446e4842fd846c083b48e3a19970daa",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "29/10/13 3:44 PM",
      "commitNameOld": "68a79b0d3f189dfdbd3a3e2a0b906627db3eff8d",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 10.11,
      "commitsBetweenForRepo": 43,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,3 +1,3 @@\n     protected URL getUrl() {\n-      return null;\n+      return url;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    protected URL getUrl() {\n      return url;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
      "extendedDetails": {}
    },
    "7a2443e9f8b95816c7df61530cda29e8b040b12e": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-5122. Support failover and retry in WebHdfsFileSystem for NN HA. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1524562 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/09/13 1:47 PM",
      "commitName": "7a2443e9f8b95816c7df61530cda29e8b040b12e",
      "commitAuthor": "Jing Zhao",
      "diff": "@@ -0,0 +1,3 @@\n+    protected URL getUrl() {\n+      return null;\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    protected URL getUrl() {\n      return null;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java"
    }
  }
}