{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DatanodeManager.java",
  "functionName": "getDecommissioningNodes",
  "functionId": "getDecommissioningNodes",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
  "functionStartLine": 1297,
  "functionEndLine": 1302,
  "numCommitsSeen": 203,
  "timeTaken": 8117,
  "changeHistory": [
    "b437f5eef40874287d4fbf9d8e43f1a857b5621f",
    "24d1cf9ac681fadaf2a3614a24b06327d5d5f53e",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "371f4a59059322000a40eb4bdf5386b96b626ece",
    "233a7aa34f37350bf7bcdd9c84b97d613e7344c9",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "b437f5eef40874287d4fbf9d8e43f1a857b5621f": "Ybodychange",
    "24d1cf9ac681fadaf2a3614a24b06327d5d5f53e": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "371f4a59059322000a40eb4bdf5386b96b626ece": "Ymultichange(Ymovefromfile,Yreturntypechange,Ybodychange)",
    "233a7aa34f37350bf7bcdd9c84b97d613e7344c9": "Ybodychange",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "b437f5eef40874287d4fbf9d8e43f1a857b5621f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7497. Inconsistent report of decommissioning DataNodes between dfsadmin and NameNode webui. Contributed by Yongjun Zhang.\n",
      "commitDate": "11/12/14 6:12 PM",
      "commitName": "b437f5eef40874287d4fbf9d8e43f1a857b5621f",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "18/11/14 10:16 PM",
      "commitNameOld": "5bd048e8378034b496bacc73b470a25d855aceb1",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 22.83,
      "commitsBetweenForRepo": 150,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,6 @@\n   public List\u003cDatanodeDescriptor\u003e getDecommissioningNodes() {\n     // There is no need to take namesystem reader lock as\n     // getDatanodeListForReport will synchronize on datanodeMap\n-    final List\u003cDatanodeDescriptor\u003e decommissioningNodes\n-        \u003d new ArrayList\u003cDatanodeDescriptor\u003e();\n-    final List\u003cDatanodeDescriptor\u003e results \u003d getDatanodeListForReport(\n-        DatanodeReportType.LIVE);\n-    for(DatanodeDescriptor node : results) {\n-      if (node.isDecommissionInProgress()) {\n-        decommissioningNodes.add(node);\n-      }\n-    }\n-    return decommissioningNodes;\n+    // A decommissioning DN may be \"alive\" or \"dead\".\n+    return getDatanodeListForReport(DatanodeReportType.DECOMMISSIONING);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public List\u003cDatanodeDescriptor\u003e getDecommissioningNodes() {\n    // There is no need to take namesystem reader lock as\n    // getDatanodeListForReport will synchronize on datanodeMap\n    // A decommissioning DN may be \"alive\" or \"dead\".\n    return getDatanodeListForReport(DatanodeReportType.DECOMMISSIONING);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "24d1cf9ac681fadaf2a3614a24b06327d5d5f53e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5693. Few NN metrics data points were collected via JMX when NN is under heavy load. Contributed by Ming Ma.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1589620 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/04/14 12:24 AM",
      "commitName": "24d1cf9ac681fadaf2a3614a24b06327d5d5f53e",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "23/04/14 1:13 PM",
      "commitNameOld": "876fd8ab7913a259ff9f69c16cc2d9af46ad3f9b",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 0.47,
      "commitsBetweenForRepo": 10,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,14 @@\n   public List\u003cDatanodeDescriptor\u003e getDecommissioningNodes() {\n-    namesystem.readLock();\n-    try {\n-      final List\u003cDatanodeDescriptor\u003e decommissioningNodes\n-          \u003d new ArrayList\u003cDatanodeDescriptor\u003e();\n-      final List\u003cDatanodeDescriptor\u003e results \u003d getDatanodeListForReport(\n-          DatanodeReportType.LIVE);\n-      for(DatanodeDescriptor node : results) {\n-        if (node.isDecommissionInProgress()) {\n-          decommissioningNodes.add(node);\n-        }\n+    // There is no need to take namesystem reader lock as\n+    // getDatanodeListForReport will synchronize on datanodeMap\n+    final List\u003cDatanodeDescriptor\u003e decommissioningNodes\n+        \u003d new ArrayList\u003cDatanodeDescriptor\u003e();\n+    final List\u003cDatanodeDescriptor\u003e results \u003d getDatanodeListForReport(\n+        DatanodeReportType.LIVE);\n+    for(DatanodeDescriptor node : results) {\n+      if (node.isDecommissionInProgress()) {\n+        decommissioningNodes.add(node);\n       }\n-      return decommissioningNodes;\n-    } finally {\n-      namesystem.readUnlock();\n     }\n+    return decommissioningNodes;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public List\u003cDatanodeDescriptor\u003e getDecommissioningNodes() {\n    // There is no need to take namesystem reader lock as\n    // getDatanodeListForReport will synchronize on datanodeMap\n    final List\u003cDatanodeDescriptor\u003e decommissioningNodes\n        \u003d new ArrayList\u003cDatanodeDescriptor\u003e();\n    final List\u003cDatanodeDescriptor\u003e results \u003d getDatanodeListForReport(\n        DatanodeReportType.LIVE);\n    for(DatanodeDescriptor node : results) {\n      if (node.isDecommissionInProgress()) {\n        decommissioningNodes.add(node);\n      }\n    }\n    return decommissioningNodes;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public List\u003cDatanodeDescriptor\u003e getDecommissioningNodes() {\n    namesystem.readLock();\n    try {\n      final List\u003cDatanodeDescriptor\u003e decommissioningNodes\n          \u003d new ArrayList\u003cDatanodeDescriptor\u003e();\n      final List\u003cDatanodeDescriptor\u003e results \u003d getDatanodeListForReport(\n          DatanodeReportType.LIVE);\n      for(DatanodeDescriptor node : results) {\n        if (node.isDecommissionInProgress()) {\n          decommissioningNodes.add(node);\n        }\n      }\n      return decommissioningNodes;\n    } finally {\n      namesystem.readUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public List\u003cDatanodeDescriptor\u003e getDecommissioningNodes() {\n    namesystem.readLock();\n    try {\n      final List\u003cDatanodeDescriptor\u003e decommissioningNodes\n          \u003d new ArrayList\u003cDatanodeDescriptor\u003e();\n      final List\u003cDatanodeDescriptor\u003e results \u003d getDatanodeListForReport(\n          DatanodeReportType.LIVE);\n      for(DatanodeDescriptor node : results) {\n        if (node.isDecommissionInProgress()) {\n          decommissioningNodes.add(node);\n        }\n      }\n      return decommissioningNodes;\n    } finally {\n      namesystem.readUnlock();\n    }\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java"
      }
    },
    "371f4a59059322000a40eb4bdf5386b96b626ece": {
      "type": "Ymultichange(Ymovefromfile,Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-2228. Move block and datanode code from FSNamesystem to BlockManager and DatanodeManager.  (szetszwo)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1154899 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/08/11 3:06 AM",
      "commitName": "371f4a59059322000a40eb4bdf5386b96b626ece",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-2228. Move block and datanode code from FSNamesystem to BlockManager and DatanodeManager.  (szetszwo)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1154899 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "08/08/11 3:06 AM",
          "commitName": "371f4a59059322000a40eb4bdf5386b96b626ece",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "07/08/11 9:36 PM",
          "commitNameOld": "8dc420ba36e7cf7b1e9e0fa6a3ab67043bd911b3",
          "commitAuthorOld": "Thomas White",
          "daysBetweenCommits": 0.23,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,18 +1,17 @@\n-  public ArrayList\u003cDatanodeDescriptor\u003e getDecommissioningNodes() {\n-    readLock();\n+  public List\u003cDatanodeDescriptor\u003e getDecommissioningNodes() {\n+    namesystem.readLock();\n     try {\n-      ArrayList\u003cDatanodeDescriptor\u003e decommissioningNodes \u003d \n-        new ArrayList\u003cDatanodeDescriptor\u003e();\n-      final List\u003cDatanodeDescriptor\u003e results \u003d getBlockManager(\n-          ).getDatanodeManager().getDatanodeListForReport(DatanodeReportType.LIVE);\n-      for (Iterator\u003cDatanodeDescriptor\u003e it \u003d results.iterator(); it.hasNext();) {\n-        DatanodeDescriptor node \u003d it.next();\n+      final List\u003cDatanodeDescriptor\u003e decommissioningNodes\n+          \u003d new ArrayList\u003cDatanodeDescriptor\u003e();\n+      final List\u003cDatanodeDescriptor\u003e results \u003d getDatanodeListForReport(\n+          DatanodeReportType.LIVE);\n+      for(DatanodeDescriptor node : results) {\n         if (node.isDecommissionInProgress()) {\n           decommissioningNodes.add(node);\n         }\n       }\n       return decommissioningNodes;\n     } finally {\n-      readUnlock();\n+      namesystem.readUnlock();\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public List\u003cDatanodeDescriptor\u003e getDecommissioningNodes() {\n    namesystem.readLock();\n    try {\n      final List\u003cDatanodeDescriptor\u003e decommissioningNodes\n          \u003d new ArrayList\u003cDatanodeDescriptor\u003e();\n      final List\u003cDatanodeDescriptor\u003e results \u003d getDatanodeListForReport(\n          DatanodeReportType.LIVE);\n      for(DatanodeDescriptor node : results) {\n        if (node.isDecommissionInProgress()) {\n          decommissioningNodes.add(node);\n        }\n      }\n      return decommissioningNodes;\n    } finally {\n      namesystem.readUnlock();\n    }\n  }",
          "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
          "extendedDetails": {
            "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
            "newPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
            "oldMethodName": "getDecommissioningNodes",
            "newMethodName": "getDecommissioningNodes"
          }
        },
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-2228. Move block and datanode code from FSNamesystem to BlockManager and DatanodeManager.  (szetszwo)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1154899 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "08/08/11 3:06 AM",
          "commitName": "371f4a59059322000a40eb4bdf5386b96b626ece",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "07/08/11 9:36 PM",
          "commitNameOld": "8dc420ba36e7cf7b1e9e0fa6a3ab67043bd911b3",
          "commitAuthorOld": "Thomas White",
          "daysBetweenCommits": 0.23,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,18 +1,17 @@\n-  public ArrayList\u003cDatanodeDescriptor\u003e getDecommissioningNodes() {\n-    readLock();\n+  public List\u003cDatanodeDescriptor\u003e getDecommissioningNodes() {\n+    namesystem.readLock();\n     try {\n-      ArrayList\u003cDatanodeDescriptor\u003e decommissioningNodes \u003d \n-        new ArrayList\u003cDatanodeDescriptor\u003e();\n-      final List\u003cDatanodeDescriptor\u003e results \u003d getBlockManager(\n-          ).getDatanodeManager().getDatanodeListForReport(DatanodeReportType.LIVE);\n-      for (Iterator\u003cDatanodeDescriptor\u003e it \u003d results.iterator(); it.hasNext();) {\n-        DatanodeDescriptor node \u003d it.next();\n+      final List\u003cDatanodeDescriptor\u003e decommissioningNodes\n+          \u003d new ArrayList\u003cDatanodeDescriptor\u003e();\n+      final List\u003cDatanodeDescriptor\u003e results \u003d getDatanodeListForReport(\n+          DatanodeReportType.LIVE);\n+      for(DatanodeDescriptor node : results) {\n         if (node.isDecommissionInProgress()) {\n           decommissioningNodes.add(node);\n         }\n       }\n       return decommissioningNodes;\n     } finally {\n-      readUnlock();\n+      namesystem.readUnlock();\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public List\u003cDatanodeDescriptor\u003e getDecommissioningNodes() {\n    namesystem.readLock();\n    try {\n      final List\u003cDatanodeDescriptor\u003e decommissioningNodes\n          \u003d new ArrayList\u003cDatanodeDescriptor\u003e();\n      final List\u003cDatanodeDescriptor\u003e results \u003d getDatanodeListForReport(\n          DatanodeReportType.LIVE);\n      for(DatanodeDescriptor node : results) {\n        if (node.isDecommissionInProgress()) {\n          decommissioningNodes.add(node);\n        }\n      }\n      return decommissioningNodes;\n    } finally {\n      namesystem.readUnlock();\n    }\n  }",
          "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
          "extendedDetails": {
            "oldValue": "ArrayList\u003cDatanodeDescriptor\u003e",
            "newValue": "List\u003cDatanodeDescriptor\u003e"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-2228. Move block and datanode code from FSNamesystem to BlockManager and DatanodeManager.  (szetszwo)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1154899 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "08/08/11 3:06 AM",
          "commitName": "371f4a59059322000a40eb4bdf5386b96b626ece",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "07/08/11 9:36 PM",
          "commitNameOld": "8dc420ba36e7cf7b1e9e0fa6a3ab67043bd911b3",
          "commitAuthorOld": "Thomas White",
          "daysBetweenCommits": 0.23,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,18 +1,17 @@\n-  public ArrayList\u003cDatanodeDescriptor\u003e getDecommissioningNodes() {\n-    readLock();\n+  public List\u003cDatanodeDescriptor\u003e getDecommissioningNodes() {\n+    namesystem.readLock();\n     try {\n-      ArrayList\u003cDatanodeDescriptor\u003e decommissioningNodes \u003d \n-        new ArrayList\u003cDatanodeDescriptor\u003e();\n-      final List\u003cDatanodeDescriptor\u003e results \u003d getBlockManager(\n-          ).getDatanodeManager().getDatanodeListForReport(DatanodeReportType.LIVE);\n-      for (Iterator\u003cDatanodeDescriptor\u003e it \u003d results.iterator(); it.hasNext();) {\n-        DatanodeDescriptor node \u003d it.next();\n+      final List\u003cDatanodeDescriptor\u003e decommissioningNodes\n+          \u003d new ArrayList\u003cDatanodeDescriptor\u003e();\n+      final List\u003cDatanodeDescriptor\u003e results \u003d getDatanodeListForReport(\n+          DatanodeReportType.LIVE);\n+      for(DatanodeDescriptor node : results) {\n         if (node.isDecommissionInProgress()) {\n           decommissioningNodes.add(node);\n         }\n       }\n       return decommissioningNodes;\n     } finally {\n-      readUnlock();\n+      namesystem.readUnlock();\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public List\u003cDatanodeDescriptor\u003e getDecommissioningNodes() {\n    namesystem.readLock();\n    try {\n      final List\u003cDatanodeDescriptor\u003e decommissioningNodes\n          \u003d new ArrayList\u003cDatanodeDescriptor\u003e();\n      final List\u003cDatanodeDescriptor\u003e results \u003d getDatanodeListForReport(\n          DatanodeReportType.LIVE);\n      for(DatanodeDescriptor node : results) {\n        if (node.isDecommissionInProgress()) {\n          decommissioningNodes.add(node);\n        }\n      }\n      return decommissioningNodes;\n    } finally {\n      namesystem.readUnlock();\n    }\n  }",
          "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "233a7aa34f37350bf7bcdd9c84b97d613e7344c9": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2167.  Move dnsToSwitchMapping and hostsReader from FSNamesystem to DatanodeManager.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1149455 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/07/11 9:20 PM",
      "commitName": "233a7aa34f37350bf7bcdd9c84b97d613e7344c9",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "20/07/11 4:35 PM",
      "commitNameOld": "08928d067bb9e1d38b5e7db9e23fcf20fe161435",
      "commitAuthorOld": "Matthew Foley",
      "daysBetweenCommits": 1.2,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,18 +1,18 @@\n   public ArrayList\u003cDatanodeDescriptor\u003e getDecommissioningNodes() {\n     readLock();\n     try {\n       ArrayList\u003cDatanodeDescriptor\u003e decommissioningNodes \u003d \n         new ArrayList\u003cDatanodeDescriptor\u003e();\n-      ArrayList\u003cDatanodeDescriptor\u003e results \u003d \n-        getDatanodeListForReport(DatanodeReportType.LIVE);\n+      final List\u003cDatanodeDescriptor\u003e results \u003d getBlockManager(\n+          ).getDatanodeManager().getDatanodeListForReport(DatanodeReportType.LIVE);\n       for (Iterator\u003cDatanodeDescriptor\u003e it \u003d results.iterator(); it.hasNext();) {\n         DatanodeDescriptor node \u003d it.next();\n         if (node.isDecommissionInProgress()) {\n           decommissioningNodes.add(node);\n         }\n       }\n       return decommissioningNodes;\n     } finally {\n       readUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ArrayList\u003cDatanodeDescriptor\u003e getDecommissioningNodes() {\n    readLock();\n    try {\n      ArrayList\u003cDatanodeDescriptor\u003e decommissioningNodes \u003d \n        new ArrayList\u003cDatanodeDescriptor\u003e();\n      final List\u003cDatanodeDescriptor\u003e results \u003d getBlockManager(\n          ).getDatanodeManager().getDatanodeListForReport(DatanodeReportType.LIVE);\n      for (Iterator\u003cDatanodeDescriptor\u003e it \u003d results.iterator(); it.hasNext();) {\n        DatanodeDescriptor node \u003d it.next();\n        if (node.isDecommissionInProgress()) {\n          decommissioningNodes.add(node);\n        }\n      }\n      return decommissioningNodes;\n    } finally {\n      readUnlock();\n    }\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,18 @@\n+  public ArrayList\u003cDatanodeDescriptor\u003e getDecommissioningNodes() {\n+    readLock();\n+    try {\n+      ArrayList\u003cDatanodeDescriptor\u003e decommissioningNodes \u003d \n+        new ArrayList\u003cDatanodeDescriptor\u003e();\n+      ArrayList\u003cDatanodeDescriptor\u003e results \u003d \n+        getDatanodeListForReport(DatanodeReportType.LIVE);\n+      for (Iterator\u003cDatanodeDescriptor\u003e it \u003d results.iterator(); it.hasNext();) {\n+        DatanodeDescriptor node \u003d it.next();\n+        if (node.isDecommissionInProgress()) {\n+          decommissioningNodes.add(node);\n+        }\n+      }\n+      return decommissioningNodes;\n+    } finally {\n+      readUnlock();\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public ArrayList\u003cDatanodeDescriptor\u003e getDecommissioningNodes() {\n    readLock();\n    try {\n      ArrayList\u003cDatanodeDescriptor\u003e decommissioningNodes \u003d \n        new ArrayList\u003cDatanodeDescriptor\u003e();\n      ArrayList\u003cDatanodeDescriptor\u003e results \u003d \n        getDatanodeListForReport(DatanodeReportType.LIVE);\n      for (Iterator\u003cDatanodeDescriptor\u003e it \u003d results.iterator(); it.hasNext();) {\n        DatanodeDescriptor node \u003d it.next();\n        if (node.isDecommissionInProgress()) {\n          decommissioningNodes.add(node);\n        }\n      }\n      return decommissioningNodes;\n    } finally {\n      readUnlock();\n    }\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java"
    }
  }
}