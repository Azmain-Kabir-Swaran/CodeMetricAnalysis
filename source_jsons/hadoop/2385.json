{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "PBHelperClient.java",
  "functionName": "convertLocatedBlock",
  "functionId": "convertLocatedBlock___b-LocatedBlock",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java",
  "functionStartLine": 1001,
  "functionEndLine": 1041,
  "numCommitsSeen": 80,
  "timeTaken": 3742,
  "changeHistory": [
    "3a4ff7776e8fab6cc87932b9aa8fb48f7b69c720",
    "a337ceb74e984991dbf976236d2e785cf5921b16",
    "e5ff0ea7ba087984262f1f27200ae5bb40d9b838",
    "70d6f201260086a3f12beaa317fede2a99639fef"
  ],
  "changeHistoryShort": {
    "3a4ff7776e8fab6cc87932b9aa8fb48f7b69c720": "Ybodychange",
    "a337ceb74e984991dbf976236d2e785cf5921b16": "Ybodychange",
    "e5ff0ea7ba087984262f1f27200ae5bb40d9b838": "Ybodychange",
    "70d6f201260086a3f12beaa317fede2a99639fef": "Ybodychange"
  },
  "changeHistoryDetails": {
    "3a4ff7776e8fab6cc87932b9aa8fb48f7b69c720": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9694. Make existing DFSClient#getFileChecksum() work for striped blocks. Contributed by Kai Zheng\n",
      "commitDate": "26/03/16 7:58 PM",
      "commitName": "3a4ff7776e8fab6cc87932b9aa8fb48f7b69c720",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "26/03/16 9:20 AM",
      "commitNameOld": "a337ceb74e984991dbf976236d2e785cf5921b16",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 0.44,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,43 +1,41 @@\n   public static LocatedBlockProto convertLocatedBlock(LocatedBlock b) {\n     if (b \u003d\u003d null) return null;\n     Builder builder \u003d LocatedBlockProto.newBuilder();\n     DatanodeInfo[] locs \u003d b.getLocations();\n     List\u003cDatanodeInfo\u003e cachedLocs \u003d\n         Lists.newLinkedList(Arrays.asList(b.getCachedLocations()));\n     for (int i \u003d 0; i \u003c locs.length; i++) {\n       DatanodeInfo loc \u003d locs[i];\n       builder.addLocs(i, PBHelperClient.convert(loc));\n       boolean locIsCached \u003d cachedLocs.contains(loc);\n       builder.addIsCached(locIsCached);\n       if (locIsCached) {\n         cachedLocs.remove(loc);\n       }\n     }\n     Preconditions.checkArgument(cachedLocs.size() \u003d\u003d 0,\n         \"Found additional cached replica locations that are not in the set of\"\n             + \" storage-backed locations!\");\n \n     StorageType[] storageTypes \u003d b.getStorageTypes();\n     if (storageTypes !\u003d null) {\n       for (StorageType storageType : storageTypes) {\n         builder.addStorageTypes(convertStorageType(storageType));\n       }\n     }\n     final String[] storageIDs \u003d b.getStorageIDs();\n     if (storageIDs !\u003d null) {\n       builder.addAllStorageIDs(Arrays.asList(storageIDs));\n     }\n     if (b instanceof LocatedStripedBlock) {\n       LocatedStripedBlock sb \u003d (LocatedStripedBlock) b;\n       byte[] indices \u003d sb.getBlockIndices();\n       builder.setBlockIndices(PBHelperClient.getByteString(indices));\n       Token\u003cBlockTokenIdentifier\u003e[] blockTokens \u003d sb.getBlockTokens();\n-      for (int i \u003d 0; i \u003c indices.length; i++) {\n-        builder.addBlockTokens(PBHelperClient.convert(blockTokens[i]));\n-      }\n+      builder.addAllBlockTokens(convert(blockTokens));\n     }\n \n     return builder.setB(PBHelperClient.convert(b.getBlock()))\n         .setBlockToken(PBHelperClient.convert(b.getBlockToken()))\n         .setCorrupt(b.isCorrupt()).setOffset(b.getStartOffset()).build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static LocatedBlockProto convertLocatedBlock(LocatedBlock b) {\n    if (b \u003d\u003d null) return null;\n    Builder builder \u003d LocatedBlockProto.newBuilder();\n    DatanodeInfo[] locs \u003d b.getLocations();\n    List\u003cDatanodeInfo\u003e cachedLocs \u003d\n        Lists.newLinkedList(Arrays.asList(b.getCachedLocations()));\n    for (int i \u003d 0; i \u003c locs.length; i++) {\n      DatanodeInfo loc \u003d locs[i];\n      builder.addLocs(i, PBHelperClient.convert(loc));\n      boolean locIsCached \u003d cachedLocs.contains(loc);\n      builder.addIsCached(locIsCached);\n      if (locIsCached) {\n        cachedLocs.remove(loc);\n      }\n    }\n    Preconditions.checkArgument(cachedLocs.size() \u003d\u003d 0,\n        \"Found additional cached replica locations that are not in the set of\"\n            + \" storage-backed locations!\");\n\n    StorageType[] storageTypes \u003d b.getStorageTypes();\n    if (storageTypes !\u003d null) {\n      for (StorageType storageType : storageTypes) {\n        builder.addStorageTypes(convertStorageType(storageType));\n      }\n    }\n    final String[] storageIDs \u003d b.getStorageIDs();\n    if (storageIDs !\u003d null) {\n      builder.addAllStorageIDs(Arrays.asList(storageIDs));\n    }\n    if (b instanceof LocatedStripedBlock) {\n      LocatedStripedBlock sb \u003d (LocatedStripedBlock) b;\n      byte[] indices \u003d sb.getBlockIndices();\n      builder.setBlockIndices(PBHelperClient.getByteString(indices));\n      Token\u003cBlockTokenIdentifier\u003e[] blockTokens \u003d sb.getBlockTokens();\n      builder.addAllBlockTokens(convert(blockTokens));\n    }\n\n    return builder.setB(PBHelperClient.convert(b.getBlock()))\n        .setBlockToken(PBHelperClient.convert(b.getBlockToken()))\n        .setCorrupt(b.isCorrupt()).setOffset(b.getStartOffset()).build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java",
      "extendedDetails": {}
    },
    "a337ceb74e984991dbf976236d2e785cf5921b16": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-9694. Make existing DFSClient#getFileChecksum() work for striped blocks. Contributed by Kai Zheng\"\n\nThis reverts commit e5ff0ea7ba087984262f1f27200ae5bb40d9b838.\n",
      "commitDate": "26/03/16 9:20 AM",
      "commitName": "a337ceb74e984991dbf976236d2e785cf5921b16",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "26/03/16 12:52 AM",
      "commitNameOld": "e5ff0ea7ba087984262f1f27200ae5bb40d9b838",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.35,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,41 +1,43 @@\n   public static LocatedBlockProto convertLocatedBlock(LocatedBlock b) {\n     if (b \u003d\u003d null) return null;\n     Builder builder \u003d LocatedBlockProto.newBuilder();\n     DatanodeInfo[] locs \u003d b.getLocations();\n     List\u003cDatanodeInfo\u003e cachedLocs \u003d\n         Lists.newLinkedList(Arrays.asList(b.getCachedLocations()));\n     for (int i \u003d 0; i \u003c locs.length; i++) {\n       DatanodeInfo loc \u003d locs[i];\n       builder.addLocs(i, PBHelperClient.convert(loc));\n       boolean locIsCached \u003d cachedLocs.contains(loc);\n       builder.addIsCached(locIsCached);\n       if (locIsCached) {\n         cachedLocs.remove(loc);\n       }\n     }\n     Preconditions.checkArgument(cachedLocs.size() \u003d\u003d 0,\n         \"Found additional cached replica locations that are not in the set of\"\n             + \" storage-backed locations!\");\n \n     StorageType[] storageTypes \u003d b.getStorageTypes();\n     if (storageTypes !\u003d null) {\n       for (StorageType storageType : storageTypes) {\n         builder.addStorageTypes(convertStorageType(storageType));\n       }\n     }\n     final String[] storageIDs \u003d b.getStorageIDs();\n     if (storageIDs !\u003d null) {\n       builder.addAllStorageIDs(Arrays.asList(storageIDs));\n     }\n     if (b instanceof LocatedStripedBlock) {\n       LocatedStripedBlock sb \u003d (LocatedStripedBlock) b;\n       byte[] indices \u003d sb.getBlockIndices();\n       builder.setBlockIndices(PBHelperClient.getByteString(indices));\n       Token\u003cBlockTokenIdentifier\u003e[] blockTokens \u003d sb.getBlockTokens();\n-      builder.addAllBlockTokens(convert(blockTokens));\n+      for (int i \u003d 0; i \u003c indices.length; i++) {\n+        builder.addBlockTokens(PBHelperClient.convert(blockTokens[i]));\n+      }\n     }\n \n     return builder.setB(PBHelperClient.convert(b.getBlock()))\n         .setBlockToken(PBHelperClient.convert(b.getBlockToken()))\n         .setCorrupt(b.isCorrupt()).setOffset(b.getStartOffset()).build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static LocatedBlockProto convertLocatedBlock(LocatedBlock b) {\n    if (b \u003d\u003d null) return null;\n    Builder builder \u003d LocatedBlockProto.newBuilder();\n    DatanodeInfo[] locs \u003d b.getLocations();\n    List\u003cDatanodeInfo\u003e cachedLocs \u003d\n        Lists.newLinkedList(Arrays.asList(b.getCachedLocations()));\n    for (int i \u003d 0; i \u003c locs.length; i++) {\n      DatanodeInfo loc \u003d locs[i];\n      builder.addLocs(i, PBHelperClient.convert(loc));\n      boolean locIsCached \u003d cachedLocs.contains(loc);\n      builder.addIsCached(locIsCached);\n      if (locIsCached) {\n        cachedLocs.remove(loc);\n      }\n    }\n    Preconditions.checkArgument(cachedLocs.size() \u003d\u003d 0,\n        \"Found additional cached replica locations that are not in the set of\"\n            + \" storage-backed locations!\");\n\n    StorageType[] storageTypes \u003d b.getStorageTypes();\n    if (storageTypes !\u003d null) {\n      for (StorageType storageType : storageTypes) {\n        builder.addStorageTypes(convertStorageType(storageType));\n      }\n    }\n    final String[] storageIDs \u003d b.getStorageIDs();\n    if (storageIDs !\u003d null) {\n      builder.addAllStorageIDs(Arrays.asList(storageIDs));\n    }\n    if (b instanceof LocatedStripedBlock) {\n      LocatedStripedBlock sb \u003d (LocatedStripedBlock) b;\n      byte[] indices \u003d sb.getBlockIndices();\n      builder.setBlockIndices(PBHelperClient.getByteString(indices));\n      Token\u003cBlockTokenIdentifier\u003e[] blockTokens \u003d sb.getBlockTokens();\n      for (int i \u003d 0; i \u003c indices.length; i++) {\n        builder.addBlockTokens(PBHelperClient.convert(blockTokens[i]));\n      }\n    }\n\n    return builder.setB(PBHelperClient.convert(b.getBlock()))\n        .setBlockToken(PBHelperClient.convert(b.getBlockToken()))\n        .setCorrupt(b.isCorrupt()).setOffset(b.getStartOffset()).build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java",
      "extendedDetails": {}
    },
    "e5ff0ea7ba087984262f1f27200ae5bb40d9b838": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9694. Make existing DFSClient#getFileChecksum() work for striped blocks. Contributed by Kai Zheng\n",
      "commitDate": "26/03/16 12:52 AM",
      "commitName": "e5ff0ea7ba087984262f1f27200ae5bb40d9b838",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "08/03/16 10:30 PM",
      "commitNameOld": "7600e3c48ff2043654dbe9f415a186a336b5ea6c",
      "commitAuthorOld": "Zhe Zhang",
      "daysBetweenCommits": 17.06,
      "commitsBetweenForRepo": 81,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,43 +1,41 @@\n   public static LocatedBlockProto convertLocatedBlock(LocatedBlock b) {\n     if (b \u003d\u003d null) return null;\n     Builder builder \u003d LocatedBlockProto.newBuilder();\n     DatanodeInfo[] locs \u003d b.getLocations();\n     List\u003cDatanodeInfo\u003e cachedLocs \u003d\n         Lists.newLinkedList(Arrays.asList(b.getCachedLocations()));\n     for (int i \u003d 0; i \u003c locs.length; i++) {\n       DatanodeInfo loc \u003d locs[i];\n       builder.addLocs(i, PBHelperClient.convert(loc));\n       boolean locIsCached \u003d cachedLocs.contains(loc);\n       builder.addIsCached(locIsCached);\n       if (locIsCached) {\n         cachedLocs.remove(loc);\n       }\n     }\n     Preconditions.checkArgument(cachedLocs.size() \u003d\u003d 0,\n         \"Found additional cached replica locations that are not in the set of\"\n             + \" storage-backed locations!\");\n \n     StorageType[] storageTypes \u003d b.getStorageTypes();\n     if (storageTypes !\u003d null) {\n       for (StorageType storageType : storageTypes) {\n         builder.addStorageTypes(convertStorageType(storageType));\n       }\n     }\n     final String[] storageIDs \u003d b.getStorageIDs();\n     if (storageIDs !\u003d null) {\n       builder.addAllStorageIDs(Arrays.asList(storageIDs));\n     }\n     if (b instanceof LocatedStripedBlock) {\n       LocatedStripedBlock sb \u003d (LocatedStripedBlock) b;\n       byte[] indices \u003d sb.getBlockIndices();\n       builder.setBlockIndices(PBHelperClient.getByteString(indices));\n       Token\u003cBlockTokenIdentifier\u003e[] blockTokens \u003d sb.getBlockTokens();\n-      for (int i \u003d 0; i \u003c indices.length; i++) {\n-        builder.addBlockTokens(PBHelperClient.convert(blockTokens[i]));\n-      }\n+      builder.addAllBlockTokens(convert(blockTokens));\n     }\n \n     return builder.setB(PBHelperClient.convert(b.getBlock()))\n         .setBlockToken(PBHelperClient.convert(b.getBlockToken()))\n         .setCorrupt(b.isCorrupt()).setOffset(b.getStartOffset()).build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static LocatedBlockProto convertLocatedBlock(LocatedBlock b) {\n    if (b \u003d\u003d null) return null;\n    Builder builder \u003d LocatedBlockProto.newBuilder();\n    DatanodeInfo[] locs \u003d b.getLocations();\n    List\u003cDatanodeInfo\u003e cachedLocs \u003d\n        Lists.newLinkedList(Arrays.asList(b.getCachedLocations()));\n    for (int i \u003d 0; i \u003c locs.length; i++) {\n      DatanodeInfo loc \u003d locs[i];\n      builder.addLocs(i, PBHelperClient.convert(loc));\n      boolean locIsCached \u003d cachedLocs.contains(loc);\n      builder.addIsCached(locIsCached);\n      if (locIsCached) {\n        cachedLocs.remove(loc);\n      }\n    }\n    Preconditions.checkArgument(cachedLocs.size() \u003d\u003d 0,\n        \"Found additional cached replica locations that are not in the set of\"\n            + \" storage-backed locations!\");\n\n    StorageType[] storageTypes \u003d b.getStorageTypes();\n    if (storageTypes !\u003d null) {\n      for (StorageType storageType : storageTypes) {\n        builder.addStorageTypes(convertStorageType(storageType));\n      }\n    }\n    final String[] storageIDs \u003d b.getStorageIDs();\n    if (storageIDs !\u003d null) {\n      builder.addAllStorageIDs(Arrays.asList(storageIDs));\n    }\n    if (b instanceof LocatedStripedBlock) {\n      LocatedStripedBlock sb \u003d (LocatedStripedBlock) b;\n      byte[] indices \u003d sb.getBlockIndices();\n      builder.setBlockIndices(PBHelperClient.getByteString(indices));\n      Token\u003cBlockTokenIdentifier\u003e[] blockTokens \u003d sb.getBlockTokens();\n      builder.addAllBlockTokens(convert(blockTokens));\n    }\n\n    return builder.setB(PBHelperClient.convert(b.getBlock()))\n        .setBlockToken(PBHelperClient.convert(b.getBlockToken()))\n        .setCorrupt(b.isCorrupt()).setOffset(b.getStartOffset()).build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java",
      "extendedDetails": {}
    },
    "70d6f201260086a3f12beaa317fede2a99639fef": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9575. Use byte array for internal block indices in a striped block.  Contributed by jing9\n",
      "commitDate": "21/12/15 10:47 PM",
      "commitName": "70d6f201260086a3f12beaa317fede2a99639fef",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "16/12/15 11:10 AM",
      "commitNameOld": "c470c8953d4927043b6383fad8e792289c634c09",
      "commitAuthorOld": "cnauroth",
      "daysBetweenCommits": 5.48,
      "commitsBetweenForRepo": 48,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,43 +1,43 @@\n   public static LocatedBlockProto convertLocatedBlock(LocatedBlock b) {\n     if (b \u003d\u003d null) return null;\n     Builder builder \u003d LocatedBlockProto.newBuilder();\n     DatanodeInfo[] locs \u003d b.getLocations();\n     List\u003cDatanodeInfo\u003e cachedLocs \u003d\n         Lists.newLinkedList(Arrays.asList(b.getCachedLocations()));\n     for (int i \u003d 0; i \u003c locs.length; i++) {\n       DatanodeInfo loc \u003d locs[i];\n       builder.addLocs(i, PBHelperClient.convert(loc));\n       boolean locIsCached \u003d cachedLocs.contains(loc);\n       builder.addIsCached(locIsCached);\n       if (locIsCached) {\n         cachedLocs.remove(loc);\n       }\n     }\n     Preconditions.checkArgument(cachedLocs.size() \u003d\u003d 0,\n         \"Found additional cached replica locations that are not in the set of\"\n             + \" storage-backed locations!\");\n \n     StorageType[] storageTypes \u003d b.getStorageTypes();\n     if (storageTypes !\u003d null) {\n       for (StorageType storageType : storageTypes) {\n         builder.addStorageTypes(convertStorageType(storageType));\n       }\n     }\n     final String[] storageIDs \u003d b.getStorageIDs();\n     if (storageIDs !\u003d null) {\n       builder.addAllStorageIDs(Arrays.asList(storageIDs));\n     }\n     if (b instanceof LocatedStripedBlock) {\n       LocatedStripedBlock sb \u003d (LocatedStripedBlock) b;\n-      int[] indices \u003d sb.getBlockIndices();\n+      byte[] indices \u003d sb.getBlockIndices();\n+      builder.setBlockIndices(PBHelperClient.getByteString(indices));\n       Token\u003cBlockTokenIdentifier\u003e[] blockTokens \u003d sb.getBlockTokens();\n       for (int i \u003d 0; i \u003c indices.length; i++) {\n-        builder.addBlockIndex(indices[i]);\n         builder.addBlockTokens(PBHelperClient.convert(blockTokens[i]));\n       }\n     }\n \n     return builder.setB(PBHelperClient.convert(b.getBlock()))\n         .setBlockToken(PBHelperClient.convert(b.getBlockToken()))\n         .setCorrupt(b.isCorrupt()).setOffset(b.getStartOffset()).build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static LocatedBlockProto convertLocatedBlock(LocatedBlock b) {\n    if (b \u003d\u003d null) return null;\n    Builder builder \u003d LocatedBlockProto.newBuilder();\n    DatanodeInfo[] locs \u003d b.getLocations();\n    List\u003cDatanodeInfo\u003e cachedLocs \u003d\n        Lists.newLinkedList(Arrays.asList(b.getCachedLocations()));\n    for (int i \u003d 0; i \u003c locs.length; i++) {\n      DatanodeInfo loc \u003d locs[i];\n      builder.addLocs(i, PBHelperClient.convert(loc));\n      boolean locIsCached \u003d cachedLocs.contains(loc);\n      builder.addIsCached(locIsCached);\n      if (locIsCached) {\n        cachedLocs.remove(loc);\n      }\n    }\n    Preconditions.checkArgument(cachedLocs.size() \u003d\u003d 0,\n        \"Found additional cached replica locations that are not in the set of\"\n            + \" storage-backed locations!\");\n\n    StorageType[] storageTypes \u003d b.getStorageTypes();\n    if (storageTypes !\u003d null) {\n      for (StorageType storageType : storageTypes) {\n        builder.addStorageTypes(convertStorageType(storageType));\n      }\n    }\n    final String[] storageIDs \u003d b.getStorageIDs();\n    if (storageIDs !\u003d null) {\n      builder.addAllStorageIDs(Arrays.asList(storageIDs));\n    }\n    if (b instanceof LocatedStripedBlock) {\n      LocatedStripedBlock sb \u003d (LocatedStripedBlock) b;\n      byte[] indices \u003d sb.getBlockIndices();\n      builder.setBlockIndices(PBHelperClient.getByteString(indices));\n      Token\u003cBlockTokenIdentifier\u003e[] blockTokens \u003d sb.getBlockTokens();\n      for (int i \u003d 0; i \u003c indices.length; i++) {\n        builder.addBlockTokens(PBHelperClient.convert(blockTokens[i]));\n      }\n    }\n\n    return builder.setB(PBHelperClient.convert(b.getBlock()))\n        .setBlockToken(PBHelperClient.convert(b.getBlockToken()))\n        .setCorrupt(b.isCorrupt()).setOffset(b.getStartOffset()).build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java",
      "extendedDetails": {}
    }
  }
}