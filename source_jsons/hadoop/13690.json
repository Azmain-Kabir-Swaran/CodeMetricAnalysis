{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockPlacementPolicyDefault.java",
  "functionName": "chooseRandom",
  "functionId": "chooseRandom___numOfReplicas-int__scope-String__excludedNodes-Set__Node____blocksize-long__maxNodesPerRack-int__results-List__DatanodeStorageInfo____avoidStaleNodes-boolean__storageTypes-EnumMap__StorageType,Integer__",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
  "functionStartLine": 790,
  "functionEndLine": 897,
  "numCommitsSeen": 141,
  "timeTaken": 7079,
  "changeHistory": [
    "d23317b1024c90be0d22adbd9d4db094bf6c8cb8",
    "f5ecc0bc080cb8a64c6d4632fc1c121f93d95c5e",
    "5bf7e594d7d54e5295fe4240c3d60c08d4755ab7",
    "ec21ce425f4e5637be716406f9d0e038921550d7",
    "97c2e576c91c2316c2b52bfc948bae9bff8ca49f",
    "1268cf5fbe4458fa75ad0662512d352f9e8d3470",
    "ff47f35deed14ba6463cba76f0e6a6c15abb3eca",
    "7fd6416759cbb202ed21b47d28c1587e04a5cdc6",
    "43539b5ff4ac0874a8a454dc93a2a782b0e0ea8f",
    "8fa41d9dd4b923bf4141f019414a1a8b079124c6",
    "80a29906bcd718bbba223fa099e523281d9f3369",
    "de30d66b2673d0344346fb985e786247ca682317",
    "22a41dce4af4d5b533ba875b322551db1c152878",
    "e08701ec71f7c10d8f15122d90c35f9f22e40837",
    "fa5ba6d977520f1faaa97c55a50a22c98b3ee109"
  ],
  "changeHistoryShort": {
    "d23317b1024c90be0d22adbd9d4db094bf6c8cb8": "Ybodychange",
    "f5ecc0bc080cb8a64c6d4632fc1c121f93d95c5e": "Ybodychange",
    "5bf7e594d7d54e5295fe4240c3d60c08d4755ab7": "Ybodychange",
    "ec21ce425f4e5637be716406f9d0e038921550d7": "Ybodychange",
    "97c2e576c91c2316c2b52bfc948bae9bff8ca49f": "Ybodychange",
    "1268cf5fbe4458fa75ad0662512d352f9e8d3470": "Ybodychange",
    "ff47f35deed14ba6463cba76f0e6a6c15abb3eca": "Ybodychange",
    "7fd6416759cbb202ed21b47d28c1587e04a5cdc6": "Ybodychange",
    "43539b5ff4ac0874a8a454dc93a2a782b0e0ea8f": "Ybodychange",
    "8fa41d9dd4b923bf4141f019414a1a8b079124c6": "Ybodychange",
    "80a29906bcd718bbba223fa099e523281d9f3369": "Ybodychange",
    "de30d66b2673d0344346fb985e786247ca682317": "Ybodychange",
    "22a41dce4af4d5b533ba875b322551db1c152878": "Ybodychange",
    "e08701ec71f7c10d8f15122d90c35f9f22e40837": "Ymultichange(Yparameterchange,Ybodychange)",
    "fa5ba6d977520f1faaa97c55a50a22c98b3ee109": "Ybodychange"
  },
  "changeHistoryDetails": {
    "d23317b1024c90be0d22adbd9d4db094bf6c8cb8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-15115. Namenode crash caused by NPE in BlockPlacementPolicyDefault when dynamically change logger to debug. Contributed by wangzhixiang\n",
      "commitDate": "07/02/20 9:03 PM",
      "commitName": "d23317b1024c90be0d22adbd9d4db094bf6c8cb8",
      "commitAuthor": "Ayush Saxena",
      "commitDateOld": "01/11/19 10:20 AM",
      "commitNameOld": "7d7acb004af5095983e99c86deedfc60a0355ff7",
      "commitAuthorOld": "Ayush Saxena",
      "daysBetweenCommits": 98.49,
      "commitsBetweenForRepo": 342,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,109 +1,108 @@\n   protected DatanodeStorageInfo chooseRandom(int numOfReplicas,\n                             String scope,\n                             Set\u003cNode\u003e excludedNodes,\n                             long blocksize,\n                             int maxNodesPerRack,\n                             List\u003cDatanodeStorageInfo\u003e results,\n                             boolean avoidStaleNodes,\n                             EnumMap\u003cStorageType, Integer\u003e storageTypes)\n                             throws NotEnoughReplicasException {\n-    StringBuilder builder \u003d null;\n+    StringBuilder builder \u003d debugLoggingBuilder.get();\n     if (LOG.isDebugEnabled()) {\n-      builder \u003d debugLoggingBuilder.get();\n       builder.setLength(0);\n       builder.append(\"[\");\n     }\n     CHOOSE_RANDOM_REASONS.get().clear();\n     boolean badTarget \u003d false;\n     DatanodeStorageInfo firstChosen \u003d null;\n     while (numOfReplicas \u003e 0) {\n       // the storage type that current node has\n       StorageType includeType \u003d null;\n       DatanodeDescriptor chosenNode \u003d null;\n       if (clusterMap instanceof DFSNetworkTopology) {\n         for (StorageType type : storageTypes.keySet()) {\n           chosenNode \u003d chooseDataNode(scope, excludedNodes, type);\n \n           if (chosenNode !\u003d null) {\n             includeType \u003d type;\n             break;\n           }\n         }\n       } else {\n         chosenNode \u003d chooseDataNode(scope, excludedNodes);\n       }\n \n       if (chosenNode \u003d\u003d null) {\n         break;\n       }\n       Preconditions.checkState(excludedNodes.add(chosenNode), \"chosenNode \"\n           + chosenNode + \" is already in excludedNodes \" + excludedNodes);\n       if (LOG.isDebugEnabled()) {\n         builder.append(\"\\nNode \").append(NodeBase.getPath(chosenNode))\n             .append(\" [\");\n       }\n       DatanodeStorageInfo storage \u003d null;\n       if (isGoodDatanode(chosenNode, maxNodesPerRack, considerLoad,\n           results, avoidStaleNodes)) {\n         for (Iterator\u003cMap.Entry\u003cStorageType, Integer\u003e\u003e iter \u003d storageTypes\n             .entrySet().iterator(); iter.hasNext();) {\n           Map.Entry\u003cStorageType, Integer\u003e entry \u003d iter.next();\n \n           // If there is one storage type the node has already contained,\n           // then no need to loop through other storage type.\n           if (includeType !\u003d null \u0026\u0026 entry.getKey() !\u003d includeType) {\n             continue;\n           }\n \n           storage \u003d chooseStorage4Block(\n               chosenNode, blocksize, results, entry.getKey());\n           if (storage !\u003d null) {\n             numOfReplicas--;\n             if (firstChosen \u003d\u003d null) {\n               firstChosen \u003d storage;\n             }\n             // add node (subclasses may also add related nodes) to excludedNode\n             addToExcludedNodes(chosenNode, excludedNodes);\n             int num \u003d entry.getValue();\n             if (num \u003d\u003d 1) {\n               iter.remove();\n             } else {\n               entry.setValue(num - 1);\n             }\n             break;\n           }\n         }\n \n         if (LOG.isDebugEnabled()) {\n           builder.append(\"\\n]\");\n         }\n \n         // If no candidate storage was found on this DN then set badTarget.\n         badTarget \u003d (storage \u003d\u003d null);\n       }\n     }\n     if (numOfReplicas\u003e0) {\n       String detail \u003d enableDebugLogging;\n       if (LOG.isDebugEnabled()) {\n         detail \u003d builder.toString();\n         if (badTarget) {\n           builder.setLength(0);\n         } else {\n           if (detail.length() \u003e 1) {\n             // only log if there\u0027s more than \"[\", which is always appended at\n             // the beginning of this method.\n             LOG.debug(detail);\n           }\n           detail \u003d \"\";\n         }\n       }\n       final HashMap\u003cNodeNotChosenReason, Integer\u003e reasonMap \u003d\n           CHOOSE_RANDOM_REASONS.get();\n       if (!reasonMap.isEmpty()) {\n         LOG.info(\"Not enough replicas was chosen. Reason: {}\", reasonMap);\n       }\n       throw new NotEnoughReplicasException(detail);\n     }\n     \n     return firstChosen;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected DatanodeStorageInfo chooseRandom(int numOfReplicas,\n                            String scope,\n                            Set\u003cNode\u003e excludedNodes,\n                            long blocksize,\n                            int maxNodesPerRack,\n                            List\u003cDatanodeStorageInfo\u003e results,\n                            boolean avoidStaleNodes,\n                            EnumMap\u003cStorageType, Integer\u003e storageTypes)\n                            throws NotEnoughReplicasException {\n    StringBuilder builder \u003d debugLoggingBuilder.get();\n    if (LOG.isDebugEnabled()) {\n      builder.setLength(0);\n      builder.append(\"[\");\n    }\n    CHOOSE_RANDOM_REASONS.get().clear();\n    boolean badTarget \u003d false;\n    DatanodeStorageInfo firstChosen \u003d null;\n    while (numOfReplicas \u003e 0) {\n      // the storage type that current node has\n      StorageType includeType \u003d null;\n      DatanodeDescriptor chosenNode \u003d null;\n      if (clusterMap instanceof DFSNetworkTopology) {\n        for (StorageType type : storageTypes.keySet()) {\n          chosenNode \u003d chooseDataNode(scope, excludedNodes, type);\n\n          if (chosenNode !\u003d null) {\n            includeType \u003d type;\n            break;\n          }\n        }\n      } else {\n        chosenNode \u003d chooseDataNode(scope, excludedNodes);\n      }\n\n      if (chosenNode \u003d\u003d null) {\n        break;\n      }\n      Preconditions.checkState(excludedNodes.add(chosenNode), \"chosenNode \"\n          + chosenNode + \" is already in excludedNodes \" + excludedNodes);\n      if (LOG.isDebugEnabled()) {\n        builder.append(\"\\nNode \").append(NodeBase.getPath(chosenNode))\n            .append(\" [\");\n      }\n      DatanodeStorageInfo storage \u003d null;\n      if (isGoodDatanode(chosenNode, maxNodesPerRack, considerLoad,\n          results, avoidStaleNodes)) {\n        for (Iterator\u003cMap.Entry\u003cStorageType, Integer\u003e\u003e iter \u003d storageTypes\n            .entrySet().iterator(); iter.hasNext();) {\n          Map.Entry\u003cStorageType, Integer\u003e entry \u003d iter.next();\n\n          // If there is one storage type the node has already contained,\n          // then no need to loop through other storage type.\n          if (includeType !\u003d null \u0026\u0026 entry.getKey() !\u003d includeType) {\n            continue;\n          }\n\n          storage \u003d chooseStorage4Block(\n              chosenNode, blocksize, results, entry.getKey());\n          if (storage !\u003d null) {\n            numOfReplicas--;\n            if (firstChosen \u003d\u003d null) {\n              firstChosen \u003d storage;\n            }\n            // add node (subclasses may also add related nodes) to excludedNode\n            addToExcludedNodes(chosenNode, excludedNodes);\n            int num \u003d entry.getValue();\n            if (num \u003d\u003d 1) {\n              iter.remove();\n            } else {\n              entry.setValue(num - 1);\n            }\n            break;\n          }\n        }\n\n        if (LOG.isDebugEnabled()) {\n          builder.append(\"\\n]\");\n        }\n\n        // If no candidate storage was found on this DN then set badTarget.\n        badTarget \u003d (storage \u003d\u003d null);\n      }\n    }\n    if (numOfReplicas\u003e0) {\n      String detail \u003d enableDebugLogging;\n      if (LOG.isDebugEnabled()) {\n        detail \u003d builder.toString();\n        if (badTarget) {\n          builder.setLength(0);\n        } else {\n          if (detail.length() \u003e 1) {\n            // only log if there\u0027s more than \"[\", which is always appended at\n            // the beginning of this method.\n            LOG.debug(detail);\n          }\n          detail \u003d \"\";\n        }\n      }\n      final HashMap\u003cNodeNotChosenReason, Integer\u003e reasonMap \u003d\n          CHOOSE_RANDOM_REASONS.get();\n      if (!reasonMap.isEmpty()) {\n        LOG.info(\"Not enough replicas was chosen. Reason: {}\", reasonMap);\n      }\n      throw new NotEnoughReplicasException(detail);\n    }\n    \n    return firstChosen;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
      "extendedDetails": {}
    },
    "f5ecc0bc080cb8a64c6d4632fc1c121f93d95c5e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14103. Review Logging of BlockPlacementPolicyDefault. Contributed by David Mollitor.\n\nSigned-off-by: Wei-Chiu Chuang \u003cweichiu@apache.org\u003e\n",
      "commitDate": "19/06/19 10:06 AM",
      "commitName": "f5ecc0bc080cb8a64c6d4632fc1c121f93d95c5e",
      "commitAuthor": "David Mollitor",
      "commitDateOld": "06/06/19 10:20 AM",
      "commitNameOld": "944adc61b1830388d520d4052fc7eb6c7ba2790d",
      "commitAuthorOld": "Inigo Goiri",
      "daysBetweenCommits": 12.99,
      "commitsBetweenForRepo": 103,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,109 +1,109 @@\n   protected DatanodeStorageInfo chooseRandom(int numOfReplicas,\n                             String scope,\n                             Set\u003cNode\u003e excludedNodes,\n                             long blocksize,\n                             int maxNodesPerRack,\n                             List\u003cDatanodeStorageInfo\u003e results,\n                             boolean avoidStaleNodes,\n                             EnumMap\u003cStorageType, Integer\u003e storageTypes)\n                             throws NotEnoughReplicasException {\n     StringBuilder builder \u003d null;\n     if (LOG.isDebugEnabled()) {\n       builder \u003d debugLoggingBuilder.get();\n       builder.setLength(0);\n       builder.append(\"[\");\n     }\n     CHOOSE_RANDOM_REASONS.get().clear();\n     boolean badTarget \u003d false;\n     DatanodeStorageInfo firstChosen \u003d null;\n     while (numOfReplicas \u003e 0) {\n       // the storage type that current node has\n       StorageType includeType \u003d null;\n       DatanodeDescriptor chosenNode \u003d null;\n       if (clusterMap instanceof DFSNetworkTopology) {\n         for (StorageType type : storageTypes.keySet()) {\n           chosenNode \u003d chooseDataNode(scope, excludedNodes, type);\n \n           if (chosenNode !\u003d null) {\n             includeType \u003d type;\n             break;\n           }\n         }\n       } else {\n         chosenNode \u003d chooseDataNode(scope, excludedNodes);\n       }\n \n       if (chosenNode \u003d\u003d null) {\n         break;\n       }\n       Preconditions.checkState(excludedNodes.add(chosenNode), \"chosenNode \"\n           + chosenNode + \" is already in excludedNodes \" + excludedNodes);\n-      if (LOG.isDebugEnabled() \u0026\u0026 builder !\u003d null) {\n+      if (LOG.isDebugEnabled()) {\n         builder.append(\"\\nNode \").append(NodeBase.getPath(chosenNode))\n             .append(\" [\");\n       }\n       DatanodeStorageInfo storage \u003d null;\n       if (isGoodDatanode(chosenNode, maxNodesPerRack, considerLoad,\n           results, avoidStaleNodes)) {\n         for (Iterator\u003cMap.Entry\u003cStorageType, Integer\u003e\u003e iter \u003d storageTypes\n             .entrySet().iterator(); iter.hasNext();) {\n           Map.Entry\u003cStorageType, Integer\u003e entry \u003d iter.next();\n \n           // If there is one storage type the node has already contained,\n           // then no need to loop through other storage type.\n           if (includeType !\u003d null \u0026\u0026 entry.getKey() !\u003d includeType) {\n             continue;\n           }\n \n           storage \u003d chooseStorage4Block(\n               chosenNode, blocksize, results, entry.getKey());\n           if (storage !\u003d null) {\n             numOfReplicas--;\n             if (firstChosen \u003d\u003d null) {\n               firstChosen \u003d storage;\n             }\n             // add node (subclasses may also add related nodes) to excludedNode\n             addToExcludedNodes(chosenNode, excludedNodes);\n             int num \u003d entry.getValue();\n             if (num \u003d\u003d 1) {\n               iter.remove();\n             } else {\n               entry.setValue(num - 1);\n             }\n             break;\n           }\n         }\n \n-        if (LOG.isDebugEnabled() \u0026\u0026 builder !\u003d null) {\n+        if (LOG.isDebugEnabled()) {\n           builder.append(\"\\n]\");\n         }\n \n         // If no candidate storage was found on this DN then set badTarget.\n         badTarget \u003d (storage \u003d\u003d null);\n       }\n     }\n     if (numOfReplicas\u003e0) {\n       String detail \u003d enableDebugLogging;\n-      if (LOG.isDebugEnabled() \u0026\u0026 builder !\u003d null) {\n+      if (LOG.isDebugEnabled()) {\n         detail \u003d builder.toString();\n         if (badTarget) {\n           builder.setLength(0);\n         } else {\n           if (detail.length() \u003e 1) {\n             // only log if there\u0027s more than \"[\", which is always appended at\n             // the beginning of this method.\n             LOG.debug(detail);\n           }\n           detail \u003d \"\";\n         }\n       }\n       final HashMap\u003cNodeNotChosenReason, Integer\u003e reasonMap \u003d\n           CHOOSE_RANDOM_REASONS.get();\n       if (!reasonMap.isEmpty()) {\n-        LOG.info(\"Not enough replicas was chosen. Reason:{}\", reasonMap);\n+        LOG.info(\"Not enough replicas was chosen. Reason: {}\", reasonMap);\n       }\n       throw new NotEnoughReplicasException(detail);\n     }\n     \n     return firstChosen;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected DatanodeStorageInfo chooseRandom(int numOfReplicas,\n                            String scope,\n                            Set\u003cNode\u003e excludedNodes,\n                            long blocksize,\n                            int maxNodesPerRack,\n                            List\u003cDatanodeStorageInfo\u003e results,\n                            boolean avoidStaleNodes,\n                            EnumMap\u003cStorageType, Integer\u003e storageTypes)\n                            throws NotEnoughReplicasException {\n    StringBuilder builder \u003d null;\n    if (LOG.isDebugEnabled()) {\n      builder \u003d debugLoggingBuilder.get();\n      builder.setLength(0);\n      builder.append(\"[\");\n    }\n    CHOOSE_RANDOM_REASONS.get().clear();\n    boolean badTarget \u003d false;\n    DatanodeStorageInfo firstChosen \u003d null;\n    while (numOfReplicas \u003e 0) {\n      // the storage type that current node has\n      StorageType includeType \u003d null;\n      DatanodeDescriptor chosenNode \u003d null;\n      if (clusterMap instanceof DFSNetworkTopology) {\n        for (StorageType type : storageTypes.keySet()) {\n          chosenNode \u003d chooseDataNode(scope, excludedNodes, type);\n\n          if (chosenNode !\u003d null) {\n            includeType \u003d type;\n            break;\n          }\n        }\n      } else {\n        chosenNode \u003d chooseDataNode(scope, excludedNodes);\n      }\n\n      if (chosenNode \u003d\u003d null) {\n        break;\n      }\n      Preconditions.checkState(excludedNodes.add(chosenNode), \"chosenNode \"\n          + chosenNode + \" is already in excludedNodes \" + excludedNodes);\n      if (LOG.isDebugEnabled()) {\n        builder.append(\"\\nNode \").append(NodeBase.getPath(chosenNode))\n            .append(\" [\");\n      }\n      DatanodeStorageInfo storage \u003d null;\n      if (isGoodDatanode(chosenNode, maxNodesPerRack, considerLoad,\n          results, avoidStaleNodes)) {\n        for (Iterator\u003cMap.Entry\u003cStorageType, Integer\u003e\u003e iter \u003d storageTypes\n            .entrySet().iterator(); iter.hasNext();) {\n          Map.Entry\u003cStorageType, Integer\u003e entry \u003d iter.next();\n\n          // If there is one storage type the node has already contained,\n          // then no need to loop through other storage type.\n          if (includeType !\u003d null \u0026\u0026 entry.getKey() !\u003d includeType) {\n            continue;\n          }\n\n          storage \u003d chooseStorage4Block(\n              chosenNode, blocksize, results, entry.getKey());\n          if (storage !\u003d null) {\n            numOfReplicas--;\n            if (firstChosen \u003d\u003d null) {\n              firstChosen \u003d storage;\n            }\n            // add node (subclasses may also add related nodes) to excludedNode\n            addToExcludedNodes(chosenNode, excludedNodes);\n            int num \u003d entry.getValue();\n            if (num \u003d\u003d 1) {\n              iter.remove();\n            } else {\n              entry.setValue(num - 1);\n            }\n            break;\n          }\n        }\n\n        if (LOG.isDebugEnabled()) {\n          builder.append(\"\\n]\");\n        }\n\n        // If no candidate storage was found on this DN then set badTarget.\n        badTarget \u003d (storage \u003d\u003d null);\n      }\n    }\n    if (numOfReplicas\u003e0) {\n      String detail \u003d enableDebugLogging;\n      if (LOG.isDebugEnabled()) {\n        detail \u003d builder.toString();\n        if (badTarget) {\n          builder.setLength(0);\n        } else {\n          if (detail.length() \u003e 1) {\n            // only log if there\u0027s more than \"[\", which is always appended at\n            // the beginning of this method.\n            LOG.debug(detail);\n          }\n          detail \u003d \"\";\n        }\n      }\n      final HashMap\u003cNodeNotChosenReason, Integer\u003e reasonMap \u003d\n          CHOOSE_RANDOM_REASONS.get();\n      if (!reasonMap.isEmpty()) {\n        LOG.info(\"Not enough replicas was chosen. Reason: {}\", reasonMap);\n      }\n      throw new NotEnoughReplicasException(detail);\n    }\n    \n    return firstChosen;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
      "extendedDetails": {}
    },
    "5bf7e594d7d54e5295fe4240c3d60c08d4755ab7": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9023. When NN is not able to identify DN for replication, reason behind it can be logged.\n",
      "commitDate": "28/12/17 11:54 AM",
      "commitName": "5bf7e594d7d54e5295fe4240c3d60c08d4755ab7",
      "commitAuthor": "Xiao Chen",
      "commitDateOld": "08/11/17 10:14 PM",
      "commitNameOld": "3a3566e1d1ab5f78cfb734796b41802fe039196d",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 49.57,
      "commitsBetweenForRepo": 278,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,98 +1,109 @@\n   protected DatanodeStorageInfo chooseRandom(int numOfReplicas,\n                             String scope,\n                             Set\u003cNode\u003e excludedNodes,\n                             long blocksize,\n                             int maxNodesPerRack,\n                             List\u003cDatanodeStorageInfo\u003e results,\n                             boolean avoidStaleNodes,\n                             EnumMap\u003cStorageType, Integer\u003e storageTypes)\n                             throws NotEnoughReplicasException {\n     StringBuilder builder \u003d null;\n     if (LOG.isDebugEnabled()) {\n       builder \u003d debugLoggingBuilder.get();\n       builder.setLength(0);\n       builder.append(\"[\");\n     }\n+    CHOOSE_RANDOM_REASONS.get().clear();\n     boolean badTarget \u003d false;\n     DatanodeStorageInfo firstChosen \u003d null;\n     while (numOfReplicas \u003e 0) {\n       // the storage type that current node has\n       StorageType includeType \u003d null;\n       DatanodeDescriptor chosenNode \u003d null;\n       if (clusterMap instanceof DFSNetworkTopology) {\n         for (StorageType type : storageTypes.keySet()) {\n           chosenNode \u003d chooseDataNode(scope, excludedNodes, type);\n \n           if (chosenNode !\u003d null) {\n             includeType \u003d type;\n             break;\n           }\n         }\n       } else {\n         chosenNode \u003d chooseDataNode(scope, excludedNodes);\n       }\n \n       if (chosenNode \u003d\u003d null) {\n         break;\n       }\n       Preconditions.checkState(excludedNodes.add(chosenNode), \"chosenNode \"\n           + chosenNode + \" is already in excludedNodes \" + excludedNodes);\n       if (LOG.isDebugEnabled() \u0026\u0026 builder !\u003d null) {\n         builder.append(\"\\nNode \").append(NodeBase.getPath(chosenNode))\n             .append(\" [\");\n       }\n       DatanodeStorageInfo storage \u003d null;\n       if (isGoodDatanode(chosenNode, maxNodesPerRack, considerLoad,\n           results, avoidStaleNodes)) {\n         for (Iterator\u003cMap.Entry\u003cStorageType, Integer\u003e\u003e iter \u003d storageTypes\n             .entrySet().iterator(); iter.hasNext();) {\n           Map.Entry\u003cStorageType, Integer\u003e entry \u003d iter.next();\n \n           // If there is one storage type the node has already contained,\n           // then no need to loop through other storage type.\n           if (includeType !\u003d null \u0026\u0026 entry.getKey() !\u003d includeType) {\n             continue;\n           }\n \n           storage \u003d chooseStorage4Block(\n               chosenNode, blocksize, results, entry.getKey());\n           if (storage !\u003d null) {\n             numOfReplicas--;\n             if (firstChosen \u003d\u003d null) {\n               firstChosen \u003d storage;\n             }\n             // add node (subclasses may also add related nodes) to excludedNode\n             addToExcludedNodes(chosenNode, excludedNodes);\n             int num \u003d entry.getValue();\n             if (num \u003d\u003d 1) {\n               iter.remove();\n             } else {\n               entry.setValue(num - 1);\n             }\n             break;\n           }\n         }\n \n         if (LOG.isDebugEnabled() \u0026\u0026 builder !\u003d null) {\n           builder.append(\"\\n]\");\n         }\n \n         // If no candidate storage was found on this DN then set badTarget.\n         badTarget \u003d (storage \u003d\u003d null);\n       }\n     }\n     if (numOfReplicas\u003e0) {\n       String detail \u003d enableDebugLogging;\n-      if (LOG.isDebugEnabled()) {\n-        if (badTarget \u0026\u0026 builder !\u003d null) {\n-          detail \u003d builder.toString();\n+      if (LOG.isDebugEnabled() \u0026\u0026 builder !\u003d null) {\n+        detail \u003d builder.toString();\n+        if (badTarget) {\n           builder.setLength(0);\n         } else {\n+          if (detail.length() \u003e 1) {\n+            // only log if there\u0027s more than \"[\", which is always appended at\n+            // the beginning of this method.\n+            LOG.debug(detail);\n+          }\n           detail \u003d \"\";\n         }\n       }\n+      final HashMap\u003cNodeNotChosenReason, Integer\u003e reasonMap \u003d\n+          CHOOSE_RANDOM_REASONS.get();\n+      if (!reasonMap.isEmpty()) {\n+        LOG.info(\"Not enough replicas was chosen. Reason:{}\", reasonMap);\n+      }\n       throw new NotEnoughReplicasException(detail);\n     }\n     \n     return firstChosen;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected DatanodeStorageInfo chooseRandom(int numOfReplicas,\n                            String scope,\n                            Set\u003cNode\u003e excludedNodes,\n                            long blocksize,\n                            int maxNodesPerRack,\n                            List\u003cDatanodeStorageInfo\u003e results,\n                            boolean avoidStaleNodes,\n                            EnumMap\u003cStorageType, Integer\u003e storageTypes)\n                            throws NotEnoughReplicasException {\n    StringBuilder builder \u003d null;\n    if (LOG.isDebugEnabled()) {\n      builder \u003d debugLoggingBuilder.get();\n      builder.setLength(0);\n      builder.append(\"[\");\n    }\n    CHOOSE_RANDOM_REASONS.get().clear();\n    boolean badTarget \u003d false;\n    DatanodeStorageInfo firstChosen \u003d null;\n    while (numOfReplicas \u003e 0) {\n      // the storage type that current node has\n      StorageType includeType \u003d null;\n      DatanodeDescriptor chosenNode \u003d null;\n      if (clusterMap instanceof DFSNetworkTopology) {\n        for (StorageType type : storageTypes.keySet()) {\n          chosenNode \u003d chooseDataNode(scope, excludedNodes, type);\n\n          if (chosenNode !\u003d null) {\n            includeType \u003d type;\n            break;\n          }\n        }\n      } else {\n        chosenNode \u003d chooseDataNode(scope, excludedNodes);\n      }\n\n      if (chosenNode \u003d\u003d null) {\n        break;\n      }\n      Preconditions.checkState(excludedNodes.add(chosenNode), \"chosenNode \"\n          + chosenNode + \" is already in excludedNodes \" + excludedNodes);\n      if (LOG.isDebugEnabled() \u0026\u0026 builder !\u003d null) {\n        builder.append(\"\\nNode \").append(NodeBase.getPath(chosenNode))\n            .append(\" [\");\n      }\n      DatanodeStorageInfo storage \u003d null;\n      if (isGoodDatanode(chosenNode, maxNodesPerRack, considerLoad,\n          results, avoidStaleNodes)) {\n        for (Iterator\u003cMap.Entry\u003cStorageType, Integer\u003e\u003e iter \u003d storageTypes\n            .entrySet().iterator(); iter.hasNext();) {\n          Map.Entry\u003cStorageType, Integer\u003e entry \u003d iter.next();\n\n          // If there is one storage type the node has already contained,\n          // then no need to loop through other storage type.\n          if (includeType !\u003d null \u0026\u0026 entry.getKey() !\u003d includeType) {\n            continue;\n          }\n\n          storage \u003d chooseStorage4Block(\n              chosenNode, blocksize, results, entry.getKey());\n          if (storage !\u003d null) {\n            numOfReplicas--;\n            if (firstChosen \u003d\u003d null) {\n              firstChosen \u003d storage;\n            }\n            // add node (subclasses may also add related nodes) to excludedNode\n            addToExcludedNodes(chosenNode, excludedNodes);\n            int num \u003d entry.getValue();\n            if (num \u003d\u003d 1) {\n              iter.remove();\n            } else {\n              entry.setValue(num - 1);\n            }\n            break;\n          }\n        }\n\n        if (LOG.isDebugEnabled() \u0026\u0026 builder !\u003d null) {\n          builder.append(\"\\n]\");\n        }\n\n        // If no candidate storage was found on this DN then set badTarget.\n        badTarget \u003d (storage \u003d\u003d null);\n      }\n    }\n    if (numOfReplicas\u003e0) {\n      String detail \u003d enableDebugLogging;\n      if (LOG.isDebugEnabled() \u0026\u0026 builder !\u003d null) {\n        detail \u003d builder.toString();\n        if (badTarget) {\n          builder.setLength(0);\n        } else {\n          if (detail.length() \u003e 1) {\n            // only log if there\u0027s more than \"[\", which is always appended at\n            // the beginning of this method.\n            LOG.debug(detail);\n          }\n          detail \u003d \"\";\n        }\n      }\n      final HashMap\u003cNodeNotChosenReason, Integer\u003e reasonMap \u003d\n          CHOOSE_RANDOM_REASONS.get();\n      if (!reasonMap.isEmpty()) {\n        LOG.info(\"Not enough replicas was chosen. Reason:{}\", reasonMap);\n      }\n      throw new NotEnoughReplicasException(detail);\n    }\n    \n    return firstChosen;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
      "extendedDetails": {}
    },
    "ec21ce425f4e5637be716406f9d0e038921550d7": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11827. NPE is thrown when log level changed in BlockPlacementPolicyDefault#chooseRandom() method. Contributed by xupeng.\n",
      "commitDate": "16/05/17 7:51 PM",
      "commitName": "ec21ce425f4e5637be716406f9d0e038921550d7",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "04/05/17 8:54 PM",
      "commitNameOld": "97c2e576c91c2316c2b52bfc948bae9bff8ca49f",
      "commitAuthorOld": "Yiqun Lin",
      "daysBetweenCommits": 11.96,
      "commitsBetweenForRepo": 58,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,98 +1,98 @@\n   protected DatanodeStorageInfo chooseRandom(int numOfReplicas,\n                             String scope,\n                             Set\u003cNode\u003e excludedNodes,\n                             long blocksize,\n                             int maxNodesPerRack,\n                             List\u003cDatanodeStorageInfo\u003e results,\n                             boolean avoidStaleNodes,\n                             EnumMap\u003cStorageType, Integer\u003e storageTypes)\n                             throws NotEnoughReplicasException {\n     StringBuilder builder \u003d null;\n     if (LOG.isDebugEnabled()) {\n       builder \u003d debugLoggingBuilder.get();\n       builder.setLength(0);\n       builder.append(\"[\");\n     }\n     boolean badTarget \u003d false;\n     DatanodeStorageInfo firstChosen \u003d null;\n     while (numOfReplicas \u003e 0) {\n       // the storage type that current node has\n       StorageType includeType \u003d null;\n       DatanodeDescriptor chosenNode \u003d null;\n       if (clusterMap instanceof DFSNetworkTopology) {\n         for (StorageType type : storageTypes.keySet()) {\n           chosenNode \u003d chooseDataNode(scope, excludedNodes, type);\n \n           if (chosenNode !\u003d null) {\n             includeType \u003d type;\n             break;\n           }\n         }\n       } else {\n         chosenNode \u003d chooseDataNode(scope, excludedNodes);\n       }\n \n       if (chosenNode \u003d\u003d null) {\n         break;\n       }\n       Preconditions.checkState(excludedNodes.add(chosenNode), \"chosenNode \"\n           + chosenNode + \" is already in excludedNodes \" + excludedNodes);\n-      if (LOG.isDebugEnabled()) {\n+      if (LOG.isDebugEnabled() \u0026\u0026 builder !\u003d null) {\n         builder.append(\"\\nNode \").append(NodeBase.getPath(chosenNode))\n             .append(\" [\");\n       }\n       DatanodeStorageInfo storage \u003d null;\n       if (isGoodDatanode(chosenNode, maxNodesPerRack, considerLoad,\n           results, avoidStaleNodes)) {\n         for (Iterator\u003cMap.Entry\u003cStorageType, Integer\u003e\u003e iter \u003d storageTypes\n             .entrySet().iterator(); iter.hasNext();) {\n           Map.Entry\u003cStorageType, Integer\u003e entry \u003d iter.next();\n \n           // If there is one storage type the node has already contained,\n           // then no need to loop through other storage type.\n           if (includeType !\u003d null \u0026\u0026 entry.getKey() !\u003d includeType) {\n             continue;\n           }\n \n           storage \u003d chooseStorage4Block(\n               chosenNode, blocksize, results, entry.getKey());\n           if (storage !\u003d null) {\n             numOfReplicas--;\n             if (firstChosen \u003d\u003d null) {\n               firstChosen \u003d storage;\n             }\n             // add node (subclasses may also add related nodes) to excludedNode\n             addToExcludedNodes(chosenNode, excludedNodes);\n             int num \u003d entry.getValue();\n             if (num \u003d\u003d 1) {\n               iter.remove();\n             } else {\n               entry.setValue(num - 1);\n             }\n             break;\n           }\n         }\n \n-        if (LOG.isDebugEnabled()) {\n+        if (LOG.isDebugEnabled() \u0026\u0026 builder !\u003d null) {\n           builder.append(\"\\n]\");\n         }\n \n         // If no candidate storage was found on this DN then set badTarget.\n         badTarget \u003d (storage \u003d\u003d null);\n       }\n     }\n     if (numOfReplicas\u003e0) {\n       String detail \u003d enableDebugLogging;\n       if (LOG.isDebugEnabled()) {\n         if (badTarget \u0026\u0026 builder !\u003d null) {\n           detail \u003d builder.toString();\n           builder.setLength(0);\n         } else {\n           detail \u003d \"\";\n         }\n       }\n       throw new NotEnoughReplicasException(detail);\n     }\n     \n     return firstChosen;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected DatanodeStorageInfo chooseRandom(int numOfReplicas,\n                            String scope,\n                            Set\u003cNode\u003e excludedNodes,\n                            long blocksize,\n                            int maxNodesPerRack,\n                            List\u003cDatanodeStorageInfo\u003e results,\n                            boolean avoidStaleNodes,\n                            EnumMap\u003cStorageType, Integer\u003e storageTypes)\n                            throws NotEnoughReplicasException {\n    StringBuilder builder \u003d null;\n    if (LOG.isDebugEnabled()) {\n      builder \u003d debugLoggingBuilder.get();\n      builder.setLength(0);\n      builder.append(\"[\");\n    }\n    boolean badTarget \u003d false;\n    DatanodeStorageInfo firstChosen \u003d null;\n    while (numOfReplicas \u003e 0) {\n      // the storage type that current node has\n      StorageType includeType \u003d null;\n      DatanodeDescriptor chosenNode \u003d null;\n      if (clusterMap instanceof DFSNetworkTopology) {\n        for (StorageType type : storageTypes.keySet()) {\n          chosenNode \u003d chooseDataNode(scope, excludedNodes, type);\n\n          if (chosenNode !\u003d null) {\n            includeType \u003d type;\n            break;\n          }\n        }\n      } else {\n        chosenNode \u003d chooseDataNode(scope, excludedNodes);\n      }\n\n      if (chosenNode \u003d\u003d null) {\n        break;\n      }\n      Preconditions.checkState(excludedNodes.add(chosenNode), \"chosenNode \"\n          + chosenNode + \" is already in excludedNodes \" + excludedNodes);\n      if (LOG.isDebugEnabled() \u0026\u0026 builder !\u003d null) {\n        builder.append(\"\\nNode \").append(NodeBase.getPath(chosenNode))\n            .append(\" [\");\n      }\n      DatanodeStorageInfo storage \u003d null;\n      if (isGoodDatanode(chosenNode, maxNodesPerRack, considerLoad,\n          results, avoidStaleNodes)) {\n        for (Iterator\u003cMap.Entry\u003cStorageType, Integer\u003e\u003e iter \u003d storageTypes\n            .entrySet().iterator(); iter.hasNext();) {\n          Map.Entry\u003cStorageType, Integer\u003e entry \u003d iter.next();\n\n          // If there is one storage type the node has already contained,\n          // then no need to loop through other storage type.\n          if (includeType !\u003d null \u0026\u0026 entry.getKey() !\u003d includeType) {\n            continue;\n          }\n\n          storage \u003d chooseStorage4Block(\n              chosenNode, blocksize, results, entry.getKey());\n          if (storage !\u003d null) {\n            numOfReplicas--;\n            if (firstChosen \u003d\u003d null) {\n              firstChosen \u003d storage;\n            }\n            // add node (subclasses may also add related nodes) to excludedNode\n            addToExcludedNodes(chosenNode, excludedNodes);\n            int num \u003d entry.getValue();\n            if (num \u003d\u003d 1) {\n              iter.remove();\n            } else {\n              entry.setValue(num - 1);\n            }\n            break;\n          }\n        }\n\n        if (LOG.isDebugEnabled() \u0026\u0026 builder !\u003d null) {\n          builder.append(\"\\n]\");\n        }\n\n        // If no candidate storage was found on this DN then set badTarget.\n        badTarget \u003d (storage \u003d\u003d null);\n      }\n    }\n    if (numOfReplicas\u003e0) {\n      String detail \u003d enableDebugLogging;\n      if (LOG.isDebugEnabled()) {\n        if (badTarget \u0026\u0026 builder !\u003d null) {\n          detail \u003d builder.toString();\n          builder.setLength(0);\n        } else {\n          detail \u003d \"\";\n        }\n      }\n      throw new NotEnoughReplicasException(detail);\n    }\n    \n    return firstChosen;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
      "extendedDetails": {}
    },
    "97c2e576c91c2316c2b52bfc948bae9bff8ca49f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11530. Use HDFS specific network topology to choose datanode in BlockPlacementPolicyDefault. Contributed by Yiqun Lin and Chen Liang.\n",
      "commitDate": "04/05/17 8:54 PM",
      "commitName": "97c2e576c91c2316c2b52bfc948bae9bff8ca49f",
      "commitAuthor": "Yiqun Lin",
      "commitDateOld": "24/02/17 3:44 PM",
      "commitNameOld": "d2b3ba9b8fb76753fa1b51661dacbde74aa5c6df",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 69.17,
      "commitsBetweenForRepo": 408,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,76 +1,98 @@\n   protected DatanodeStorageInfo chooseRandom(int numOfReplicas,\n                             String scope,\n                             Set\u003cNode\u003e excludedNodes,\n                             long blocksize,\n                             int maxNodesPerRack,\n                             List\u003cDatanodeStorageInfo\u003e results,\n                             boolean avoidStaleNodes,\n                             EnumMap\u003cStorageType, Integer\u003e storageTypes)\n                             throws NotEnoughReplicasException {\n     StringBuilder builder \u003d null;\n     if (LOG.isDebugEnabled()) {\n       builder \u003d debugLoggingBuilder.get();\n       builder.setLength(0);\n       builder.append(\"[\");\n     }\n     boolean badTarget \u003d false;\n     DatanodeStorageInfo firstChosen \u003d null;\n     while (numOfReplicas \u003e 0) {\n-      DatanodeDescriptor chosenNode \u003d chooseDataNode(scope, excludedNodes);\n+      // the storage type that current node has\n+      StorageType includeType \u003d null;\n+      DatanodeDescriptor chosenNode \u003d null;\n+      if (clusterMap instanceof DFSNetworkTopology) {\n+        for (StorageType type : storageTypes.keySet()) {\n+          chosenNode \u003d chooseDataNode(scope, excludedNodes, type);\n+\n+          if (chosenNode !\u003d null) {\n+            includeType \u003d type;\n+            break;\n+          }\n+        }\n+      } else {\n+        chosenNode \u003d chooseDataNode(scope, excludedNodes);\n+      }\n+\n       if (chosenNode \u003d\u003d null) {\n         break;\n       }\n       Preconditions.checkState(excludedNodes.add(chosenNode), \"chosenNode \"\n           + chosenNode + \" is already in excludedNodes \" + excludedNodes);\n       if (LOG.isDebugEnabled()) {\n         builder.append(\"\\nNode \").append(NodeBase.getPath(chosenNode))\n             .append(\" [\");\n       }\n       DatanodeStorageInfo storage \u003d null;\n       if (isGoodDatanode(chosenNode, maxNodesPerRack, considerLoad,\n           results, avoidStaleNodes)) {\n         for (Iterator\u003cMap.Entry\u003cStorageType, Integer\u003e\u003e iter \u003d storageTypes\n             .entrySet().iterator(); iter.hasNext();) {\n           Map.Entry\u003cStorageType, Integer\u003e entry \u003d iter.next();\n+\n+          // If there is one storage type the node has already contained,\n+          // then no need to loop through other storage type.\n+          if (includeType !\u003d null \u0026\u0026 entry.getKey() !\u003d includeType) {\n+            continue;\n+          }\n+\n           storage \u003d chooseStorage4Block(\n               chosenNode, blocksize, results, entry.getKey());\n           if (storage !\u003d null) {\n             numOfReplicas--;\n             if (firstChosen \u003d\u003d null) {\n               firstChosen \u003d storage;\n             }\n             // add node (subclasses may also add related nodes) to excludedNode\n             addToExcludedNodes(chosenNode, excludedNodes);\n             int num \u003d entry.getValue();\n             if (num \u003d\u003d 1) {\n               iter.remove();\n             } else {\n               entry.setValue(num - 1);\n             }\n             break;\n           }\n         }\n \n         if (LOG.isDebugEnabled()) {\n           builder.append(\"\\n]\");\n         }\n \n         // If no candidate storage was found on this DN then set badTarget.\n         badTarget \u003d (storage \u003d\u003d null);\n       }\n     }\n     if (numOfReplicas\u003e0) {\n       String detail \u003d enableDebugLogging;\n       if (LOG.isDebugEnabled()) {\n         if (badTarget \u0026\u0026 builder !\u003d null) {\n           detail \u003d builder.toString();\n           builder.setLength(0);\n         } else {\n           detail \u003d \"\";\n         }\n       }\n       throw new NotEnoughReplicasException(detail);\n     }\n     \n     return firstChosen;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected DatanodeStorageInfo chooseRandom(int numOfReplicas,\n                            String scope,\n                            Set\u003cNode\u003e excludedNodes,\n                            long blocksize,\n                            int maxNodesPerRack,\n                            List\u003cDatanodeStorageInfo\u003e results,\n                            boolean avoidStaleNodes,\n                            EnumMap\u003cStorageType, Integer\u003e storageTypes)\n                            throws NotEnoughReplicasException {\n    StringBuilder builder \u003d null;\n    if (LOG.isDebugEnabled()) {\n      builder \u003d debugLoggingBuilder.get();\n      builder.setLength(0);\n      builder.append(\"[\");\n    }\n    boolean badTarget \u003d false;\n    DatanodeStorageInfo firstChosen \u003d null;\n    while (numOfReplicas \u003e 0) {\n      // the storage type that current node has\n      StorageType includeType \u003d null;\n      DatanodeDescriptor chosenNode \u003d null;\n      if (clusterMap instanceof DFSNetworkTopology) {\n        for (StorageType type : storageTypes.keySet()) {\n          chosenNode \u003d chooseDataNode(scope, excludedNodes, type);\n\n          if (chosenNode !\u003d null) {\n            includeType \u003d type;\n            break;\n          }\n        }\n      } else {\n        chosenNode \u003d chooseDataNode(scope, excludedNodes);\n      }\n\n      if (chosenNode \u003d\u003d null) {\n        break;\n      }\n      Preconditions.checkState(excludedNodes.add(chosenNode), \"chosenNode \"\n          + chosenNode + \" is already in excludedNodes \" + excludedNodes);\n      if (LOG.isDebugEnabled()) {\n        builder.append(\"\\nNode \").append(NodeBase.getPath(chosenNode))\n            .append(\" [\");\n      }\n      DatanodeStorageInfo storage \u003d null;\n      if (isGoodDatanode(chosenNode, maxNodesPerRack, considerLoad,\n          results, avoidStaleNodes)) {\n        for (Iterator\u003cMap.Entry\u003cStorageType, Integer\u003e\u003e iter \u003d storageTypes\n            .entrySet().iterator(); iter.hasNext();) {\n          Map.Entry\u003cStorageType, Integer\u003e entry \u003d iter.next();\n\n          // If there is one storage type the node has already contained,\n          // then no need to loop through other storage type.\n          if (includeType !\u003d null \u0026\u0026 entry.getKey() !\u003d includeType) {\n            continue;\n          }\n\n          storage \u003d chooseStorage4Block(\n              chosenNode, blocksize, results, entry.getKey());\n          if (storage !\u003d null) {\n            numOfReplicas--;\n            if (firstChosen \u003d\u003d null) {\n              firstChosen \u003d storage;\n            }\n            // add node (subclasses may also add related nodes) to excludedNode\n            addToExcludedNodes(chosenNode, excludedNodes);\n            int num \u003d entry.getValue();\n            if (num \u003d\u003d 1) {\n              iter.remove();\n            } else {\n              entry.setValue(num - 1);\n            }\n            break;\n          }\n        }\n\n        if (LOG.isDebugEnabled()) {\n          builder.append(\"\\n]\");\n        }\n\n        // If no candidate storage was found on this DN then set badTarget.\n        badTarget \u003d (storage \u003d\u003d null);\n      }\n    }\n    if (numOfReplicas\u003e0) {\n      String detail \u003d enableDebugLogging;\n      if (LOG.isDebugEnabled()) {\n        if (badTarget \u0026\u0026 builder !\u003d null) {\n          detail \u003d builder.toString();\n          builder.setLength(0);\n        } else {\n          detail \u003d \"\";\n        }\n      }\n      throw new NotEnoughReplicasException(detail);\n    }\n    \n    return firstChosen;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
      "extendedDetails": {}
    },
    "1268cf5fbe4458fa75ad0662512d352f9e8d3470": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10320. Rack failures may result in NN terminate. (Xiao Chen via mingma)\n",
      "commitDate": "04/05/16 5:02 PM",
      "commitName": "1268cf5fbe4458fa75ad0662512d352f9e8d3470",
      "commitAuthor": "Ming Ma",
      "commitDateOld": "27/04/16 2:22 PM",
      "commitNameOld": "0a152103f19a3e8e1b7f33aeb9dd115ba231d7b7",
      "commitAuthorOld": "Lei Xu",
      "daysBetweenCommits": 7.11,
      "commitsBetweenForRepo": 36,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,87 +1,76 @@\n   protected DatanodeStorageInfo chooseRandom(int numOfReplicas,\n                             String scope,\n                             Set\u003cNode\u003e excludedNodes,\n                             long blocksize,\n                             int maxNodesPerRack,\n                             List\u003cDatanodeStorageInfo\u003e results,\n                             boolean avoidStaleNodes,\n                             EnumMap\u003cStorageType, Integer\u003e storageTypes)\n                             throws NotEnoughReplicasException {\n-\n-    int numOfAvailableNodes \u003d clusterMap.countNumOfAvailableNodes(\n-        scope, excludedNodes);\n-    int refreshCounter \u003d numOfAvailableNodes;\n     StringBuilder builder \u003d null;\n     if (LOG.isDebugEnabled()) {\n       builder \u003d debugLoggingBuilder.get();\n       builder.setLength(0);\n       builder.append(\"[\");\n     }\n     boolean badTarget \u003d false;\n     DatanodeStorageInfo firstChosen \u003d null;\n-    while(numOfReplicas \u003e 0 \u0026\u0026 numOfAvailableNodes \u003e 0) {\n-      DatanodeDescriptor chosenNode \u003d chooseDataNode(scope);\n-      if (excludedNodes.add(chosenNode)) { //was not in the excluded list\n-        if (LOG.isDebugEnabled()) {\n-          builder.append(\"\\nNode \").append(NodeBase.getPath(chosenNode)).append(\" [\");\n-        }\n-        numOfAvailableNodes--;\n-        DatanodeStorageInfo storage \u003d null;\n-        if (isGoodDatanode(chosenNode, maxNodesPerRack, considerLoad,\n-            results, avoidStaleNodes)) {\n-          for (Iterator\u003cMap.Entry\u003cStorageType, Integer\u003e\u003e iter \u003d storageTypes\n-              .entrySet().iterator(); iter.hasNext(); ) {\n-            Map.Entry\u003cStorageType, Integer\u003e entry \u003d iter.next();\n-            storage \u003d chooseStorage4Block(\n-                chosenNode, blocksize, results, entry.getKey());\n-            if (storage !\u003d null) {\n-              numOfReplicas--;\n-              if (firstChosen \u003d\u003d null) {\n-                firstChosen \u003d storage;\n-              }\n-              // add node and related nodes to excludedNode\n-              numOfAvailableNodes -\u003d\n-                  addToExcludedNodes(chosenNode, excludedNodes);\n-              int num \u003d entry.getValue();\n-              if (num \u003d\u003d 1) {\n-                iter.remove();\n-              } else {\n-                entry.setValue(num - 1);\n-              }\n-              break;\n+    while (numOfReplicas \u003e 0) {\n+      DatanodeDescriptor chosenNode \u003d chooseDataNode(scope, excludedNodes);\n+      if (chosenNode \u003d\u003d null) {\n+        break;\n+      }\n+      Preconditions.checkState(excludedNodes.add(chosenNode), \"chosenNode \"\n+          + chosenNode + \" is already in excludedNodes \" + excludedNodes);\n+      if (LOG.isDebugEnabled()) {\n+        builder.append(\"\\nNode \").append(NodeBase.getPath(chosenNode))\n+            .append(\" [\");\n+      }\n+      DatanodeStorageInfo storage \u003d null;\n+      if (isGoodDatanode(chosenNode, maxNodesPerRack, considerLoad,\n+          results, avoidStaleNodes)) {\n+        for (Iterator\u003cMap.Entry\u003cStorageType, Integer\u003e\u003e iter \u003d storageTypes\n+            .entrySet().iterator(); iter.hasNext();) {\n+          Map.Entry\u003cStorageType, Integer\u003e entry \u003d iter.next();\n+          storage \u003d chooseStorage4Block(\n+              chosenNode, blocksize, results, entry.getKey());\n+          if (storage !\u003d null) {\n+            numOfReplicas--;\n+            if (firstChosen \u003d\u003d null) {\n+              firstChosen \u003d storage;\n             }\n+            // add node (subclasses may also add related nodes) to excludedNode\n+            addToExcludedNodes(chosenNode, excludedNodes);\n+            int num \u003d entry.getValue();\n+            if (num \u003d\u003d 1) {\n+              iter.remove();\n+            } else {\n+              entry.setValue(num - 1);\n+            }\n+            break;\n           }\n         }\n \n         if (LOG.isDebugEnabled()) {\n           builder.append(\"\\n]\");\n         }\n \n         // If no candidate storage was found on this DN then set badTarget.\n         badTarget \u003d (storage \u003d\u003d null);\n       }\n-      // Refresh the node count. If the live node count became smaller,\n-      // but it is not reflected in this loop, it may loop forever in case\n-      // the replicas/rack cannot be satisfied.\n-      if (--refreshCounter \u003d\u003d 0) {\n-        numOfAvailableNodes \u003d clusterMap.countNumOfAvailableNodes(scope,\n-            excludedNodes);\n-        refreshCounter \u003d numOfAvailableNodes;\n-      }\n     }\n-      \n     if (numOfReplicas\u003e0) {\n       String detail \u003d enableDebugLogging;\n       if (LOG.isDebugEnabled()) {\n         if (badTarget \u0026\u0026 builder !\u003d null) {\n           detail \u003d builder.toString();\n           builder.setLength(0);\n         } else {\n           detail \u003d \"\";\n         }\n       }\n       throw new NotEnoughReplicasException(detail);\n     }\n     \n     return firstChosen;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected DatanodeStorageInfo chooseRandom(int numOfReplicas,\n                            String scope,\n                            Set\u003cNode\u003e excludedNodes,\n                            long blocksize,\n                            int maxNodesPerRack,\n                            List\u003cDatanodeStorageInfo\u003e results,\n                            boolean avoidStaleNodes,\n                            EnumMap\u003cStorageType, Integer\u003e storageTypes)\n                            throws NotEnoughReplicasException {\n    StringBuilder builder \u003d null;\n    if (LOG.isDebugEnabled()) {\n      builder \u003d debugLoggingBuilder.get();\n      builder.setLength(0);\n      builder.append(\"[\");\n    }\n    boolean badTarget \u003d false;\n    DatanodeStorageInfo firstChosen \u003d null;\n    while (numOfReplicas \u003e 0) {\n      DatanodeDescriptor chosenNode \u003d chooseDataNode(scope, excludedNodes);\n      if (chosenNode \u003d\u003d null) {\n        break;\n      }\n      Preconditions.checkState(excludedNodes.add(chosenNode), \"chosenNode \"\n          + chosenNode + \" is already in excludedNodes \" + excludedNodes);\n      if (LOG.isDebugEnabled()) {\n        builder.append(\"\\nNode \").append(NodeBase.getPath(chosenNode))\n            .append(\" [\");\n      }\n      DatanodeStorageInfo storage \u003d null;\n      if (isGoodDatanode(chosenNode, maxNodesPerRack, considerLoad,\n          results, avoidStaleNodes)) {\n        for (Iterator\u003cMap.Entry\u003cStorageType, Integer\u003e\u003e iter \u003d storageTypes\n            .entrySet().iterator(); iter.hasNext();) {\n          Map.Entry\u003cStorageType, Integer\u003e entry \u003d iter.next();\n          storage \u003d chooseStorage4Block(\n              chosenNode, blocksize, results, entry.getKey());\n          if (storage !\u003d null) {\n            numOfReplicas--;\n            if (firstChosen \u003d\u003d null) {\n              firstChosen \u003d storage;\n            }\n            // add node (subclasses may also add related nodes) to excludedNode\n            addToExcludedNodes(chosenNode, excludedNodes);\n            int num \u003d entry.getValue();\n            if (num \u003d\u003d 1) {\n              iter.remove();\n            } else {\n              entry.setValue(num - 1);\n            }\n            break;\n          }\n        }\n\n        if (LOG.isDebugEnabled()) {\n          builder.append(\"\\n]\");\n        }\n\n        // If no candidate storage was found on this DN then set badTarget.\n        badTarget \u003d (storage \u003d\u003d null);\n      }\n    }\n    if (numOfReplicas\u003e0) {\n      String detail \u003d enableDebugLogging;\n      if (LOG.isDebugEnabled()) {\n        if (badTarget \u0026\u0026 builder !\u003d null) {\n          detail \u003d builder.toString();\n          builder.setLength(0);\n        } else {\n          detail \u003d \"\";\n        }\n      }\n      throw new NotEnoughReplicasException(detail);\n    }\n    \n    return firstChosen;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
      "extendedDetails": {}
    },
    "ff47f35deed14ba6463cba76f0e6a6c15abb3eca": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4937. ReplicationMonitor can infinite-loop in BlockPlacementPolicyDefault#chooseRandom(). Contributed by Kihwal Lee.\n",
      "commitDate": "05/11/15 7:25 AM",
      "commitName": "ff47f35deed14ba6463cba76f0e6a6c15abb3eca",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "04/11/15 10:22 AM",
      "commitNameOld": "ec414600ede8e305c584818565b50e055ea5d2b5",
      "commitAuthorOld": "Lei Xu",
      "daysBetweenCommits": 0.88,
      "commitsBetweenForRepo": 6,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,78 +1,87 @@\n   protected DatanodeStorageInfo chooseRandom(int numOfReplicas,\n                             String scope,\n                             Set\u003cNode\u003e excludedNodes,\n                             long blocksize,\n                             int maxNodesPerRack,\n                             List\u003cDatanodeStorageInfo\u003e results,\n                             boolean avoidStaleNodes,\n                             EnumMap\u003cStorageType, Integer\u003e storageTypes)\n                             throws NotEnoughReplicasException {\n \n     int numOfAvailableNodes \u003d clusterMap.countNumOfAvailableNodes(\n         scope, excludedNodes);\n+    int refreshCounter \u003d numOfAvailableNodes;\n     StringBuilder builder \u003d null;\n     if (LOG.isDebugEnabled()) {\n       builder \u003d debugLoggingBuilder.get();\n       builder.setLength(0);\n       builder.append(\"[\");\n     }\n     boolean badTarget \u003d false;\n     DatanodeStorageInfo firstChosen \u003d null;\n     while(numOfReplicas \u003e 0 \u0026\u0026 numOfAvailableNodes \u003e 0) {\n       DatanodeDescriptor chosenNode \u003d chooseDataNode(scope);\n       if (excludedNodes.add(chosenNode)) { //was not in the excluded list\n         if (LOG.isDebugEnabled()) {\n           builder.append(\"\\nNode \").append(NodeBase.getPath(chosenNode)).append(\" [\");\n         }\n         numOfAvailableNodes--;\n         DatanodeStorageInfo storage \u003d null;\n         if (isGoodDatanode(chosenNode, maxNodesPerRack, considerLoad,\n             results, avoidStaleNodes)) {\n           for (Iterator\u003cMap.Entry\u003cStorageType, Integer\u003e\u003e iter \u003d storageTypes\n               .entrySet().iterator(); iter.hasNext(); ) {\n             Map.Entry\u003cStorageType, Integer\u003e entry \u003d iter.next();\n             storage \u003d chooseStorage4Block(\n                 chosenNode, blocksize, results, entry.getKey());\n             if (storage !\u003d null) {\n               numOfReplicas--;\n               if (firstChosen \u003d\u003d null) {\n                 firstChosen \u003d storage;\n               }\n               // add node and related nodes to excludedNode\n               numOfAvailableNodes -\u003d\n                   addToExcludedNodes(chosenNode, excludedNodes);\n               int num \u003d entry.getValue();\n               if (num \u003d\u003d 1) {\n                 iter.remove();\n               } else {\n                 entry.setValue(num - 1);\n               }\n               break;\n             }\n           }\n         }\n \n         if (LOG.isDebugEnabled()) {\n           builder.append(\"\\n]\");\n         }\n \n         // If no candidate storage was found on this DN then set badTarget.\n         badTarget \u003d (storage \u003d\u003d null);\n       }\n+      // Refresh the node count. If the live node count became smaller,\n+      // but it is not reflected in this loop, it may loop forever in case\n+      // the replicas/rack cannot be satisfied.\n+      if (--refreshCounter \u003d\u003d 0) {\n+        numOfAvailableNodes \u003d clusterMap.countNumOfAvailableNodes(scope,\n+            excludedNodes);\n+        refreshCounter \u003d numOfAvailableNodes;\n+      }\n     }\n       \n     if (numOfReplicas\u003e0) {\n       String detail \u003d enableDebugLogging;\n       if (LOG.isDebugEnabled()) {\n         if (badTarget \u0026\u0026 builder !\u003d null) {\n           detail \u003d builder.toString();\n           builder.setLength(0);\n         } else {\n           detail \u003d \"\";\n         }\n       }\n       throw new NotEnoughReplicasException(detail);\n     }\n     \n     return firstChosen;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected DatanodeStorageInfo chooseRandom(int numOfReplicas,\n                            String scope,\n                            Set\u003cNode\u003e excludedNodes,\n                            long blocksize,\n                            int maxNodesPerRack,\n                            List\u003cDatanodeStorageInfo\u003e results,\n                            boolean avoidStaleNodes,\n                            EnumMap\u003cStorageType, Integer\u003e storageTypes)\n                            throws NotEnoughReplicasException {\n\n    int numOfAvailableNodes \u003d clusterMap.countNumOfAvailableNodes(\n        scope, excludedNodes);\n    int refreshCounter \u003d numOfAvailableNodes;\n    StringBuilder builder \u003d null;\n    if (LOG.isDebugEnabled()) {\n      builder \u003d debugLoggingBuilder.get();\n      builder.setLength(0);\n      builder.append(\"[\");\n    }\n    boolean badTarget \u003d false;\n    DatanodeStorageInfo firstChosen \u003d null;\n    while(numOfReplicas \u003e 0 \u0026\u0026 numOfAvailableNodes \u003e 0) {\n      DatanodeDescriptor chosenNode \u003d chooseDataNode(scope);\n      if (excludedNodes.add(chosenNode)) { //was not in the excluded list\n        if (LOG.isDebugEnabled()) {\n          builder.append(\"\\nNode \").append(NodeBase.getPath(chosenNode)).append(\" [\");\n        }\n        numOfAvailableNodes--;\n        DatanodeStorageInfo storage \u003d null;\n        if (isGoodDatanode(chosenNode, maxNodesPerRack, considerLoad,\n            results, avoidStaleNodes)) {\n          for (Iterator\u003cMap.Entry\u003cStorageType, Integer\u003e\u003e iter \u003d storageTypes\n              .entrySet().iterator(); iter.hasNext(); ) {\n            Map.Entry\u003cStorageType, Integer\u003e entry \u003d iter.next();\n            storage \u003d chooseStorage4Block(\n                chosenNode, blocksize, results, entry.getKey());\n            if (storage !\u003d null) {\n              numOfReplicas--;\n              if (firstChosen \u003d\u003d null) {\n                firstChosen \u003d storage;\n              }\n              // add node and related nodes to excludedNode\n              numOfAvailableNodes -\u003d\n                  addToExcludedNodes(chosenNode, excludedNodes);\n              int num \u003d entry.getValue();\n              if (num \u003d\u003d 1) {\n                iter.remove();\n              } else {\n                entry.setValue(num - 1);\n              }\n              break;\n            }\n          }\n        }\n\n        if (LOG.isDebugEnabled()) {\n          builder.append(\"\\n]\");\n        }\n\n        // If no candidate storage was found on this DN then set badTarget.\n        badTarget \u003d (storage \u003d\u003d null);\n      }\n      // Refresh the node count. If the live node count became smaller,\n      // but it is not reflected in this loop, it may loop forever in case\n      // the replicas/rack cannot be satisfied.\n      if (--refreshCounter \u003d\u003d 0) {\n        numOfAvailableNodes \u003d clusterMap.countNumOfAvailableNodes(scope,\n            excludedNodes);\n        refreshCounter \u003d numOfAvailableNodes;\n      }\n    }\n      \n    if (numOfReplicas\u003e0) {\n      String detail \u003d enableDebugLogging;\n      if (LOG.isDebugEnabled()) {\n        if (badTarget \u0026\u0026 builder !\u003d null) {\n          detail \u003d builder.toString();\n          builder.setLength(0);\n        } else {\n          detail \u003d \"\";\n        }\n      }\n      throw new NotEnoughReplicasException(detail);\n    }\n    \n    return firstChosen;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
      "extendedDetails": {}
    },
    "7fd6416759cbb202ed21b47d28c1587e04a5cdc6": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-4937. ReplicationMonitor can infinite-loop in BlockPlacementPolicyDefault#chooseRandom(). Contributed by Kihwal Lee.\"\n\nThis reverts commit 43539b5ff4ac0874a8a454dc93a2a782b0e0ea8f.\n",
      "commitDate": "31/10/15 1:20 AM",
      "commitName": "7fd6416759cbb202ed21b47d28c1587e04a5cdc6",
      "commitAuthor": "yliu",
      "commitDateOld": "30/10/15 7:29 AM",
      "commitNameOld": "43539b5ff4ac0874a8a454dc93a2a782b0e0ea8f",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 0.74,
      "commitsBetweenForRepo": 11,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,90 +1,78 @@\n   protected DatanodeStorageInfo chooseRandom(int numOfReplicas,\n                             String scope,\n                             Set\u003cNode\u003e excludedNodes,\n                             long blocksize,\n                             int maxNodesPerRack,\n                             List\u003cDatanodeStorageInfo\u003e results,\n                             boolean avoidStaleNodes,\n                             EnumMap\u003cStorageType, Integer\u003e storageTypes)\n                             throws NotEnoughReplicasException {\n \n     int numOfAvailableNodes \u003d clusterMap.countNumOfAvailableNodes(\n         scope, excludedNodes);\n-    int refreshCounter \u003d numOfAvailableNodes;\n     StringBuilder builder \u003d null;\n     if (LOG.isDebugEnabled()) {\n       builder \u003d debugLoggingBuilder.get();\n       builder.setLength(0);\n       builder.append(\"[\");\n     }\n     boolean badTarget \u003d false;\n     DatanodeStorageInfo firstChosen \u003d null;\n     while(numOfReplicas \u003e 0 \u0026\u0026 numOfAvailableNodes \u003e 0) {\n       DatanodeDescriptor chosenNode \u003d chooseDataNode(scope);\n       if (excludedNodes.add(chosenNode)) { //was not in the excluded list\n         if (LOG.isDebugEnabled()) {\n           builder.append(\"\\nNode \").append(NodeBase.getPath(chosenNode)).append(\" [\");\n         }\n         numOfAvailableNodes--;\n         DatanodeStorageInfo storage \u003d null;\n         if (isGoodDatanode(chosenNode, maxNodesPerRack, considerLoad,\n             results, avoidStaleNodes)) {\n           for (Iterator\u003cMap.Entry\u003cStorageType, Integer\u003e\u003e iter \u003d storageTypes\n               .entrySet().iterator(); iter.hasNext(); ) {\n             Map.Entry\u003cStorageType, Integer\u003e entry \u003d iter.next();\n             storage \u003d chooseStorage4Block(\n                 chosenNode, blocksize, results, entry.getKey());\n             if (storage !\u003d null) {\n               numOfReplicas--;\n               if (firstChosen \u003d\u003d null) {\n                 firstChosen \u003d storage;\n               }\n               // add node and related nodes to excludedNode\n               numOfAvailableNodes -\u003d\n                   addToExcludedNodes(chosenNode, excludedNodes);\n               int num \u003d entry.getValue();\n               if (num \u003d\u003d 1) {\n                 iter.remove();\n               } else {\n                 entry.setValue(num - 1);\n               }\n               break;\n             }\n           }\n         }\n \n         if (LOG.isDebugEnabled()) {\n           builder.append(\"\\n]\");\n         }\n \n         // If no candidate storage was found on this DN then set badTarget.\n         badTarget \u003d (storage \u003d\u003d null);\n       }\n-      // Refresh the node count. If the live node count became smaller,\n-      // but it is not reflected in this loop, it may loop forever in case\n-      // the replicas/rack cannot be satisfied.\n-      if (--refreshCounter \u003d\u003d 0) {\n-        refreshCounter \u003d clusterMap.countNumOfAvailableNodes(scope,\n-            excludedNodes);\n-        // It has already gone through enough number of nodes.\n-        if (refreshCounter \u003c\u003d excludedNodes.size()) {\n-          break;\n-        }\n-      }\n     }\n       \n     if (numOfReplicas\u003e0) {\n       String detail \u003d enableDebugLogging;\n       if (LOG.isDebugEnabled()) {\n         if (badTarget \u0026\u0026 builder !\u003d null) {\n           detail \u003d builder.toString();\n           builder.setLength(0);\n         } else {\n           detail \u003d \"\";\n         }\n       }\n       throw new NotEnoughReplicasException(detail);\n     }\n     \n     return firstChosen;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected DatanodeStorageInfo chooseRandom(int numOfReplicas,\n                            String scope,\n                            Set\u003cNode\u003e excludedNodes,\n                            long blocksize,\n                            int maxNodesPerRack,\n                            List\u003cDatanodeStorageInfo\u003e results,\n                            boolean avoidStaleNodes,\n                            EnumMap\u003cStorageType, Integer\u003e storageTypes)\n                            throws NotEnoughReplicasException {\n\n    int numOfAvailableNodes \u003d clusterMap.countNumOfAvailableNodes(\n        scope, excludedNodes);\n    StringBuilder builder \u003d null;\n    if (LOG.isDebugEnabled()) {\n      builder \u003d debugLoggingBuilder.get();\n      builder.setLength(0);\n      builder.append(\"[\");\n    }\n    boolean badTarget \u003d false;\n    DatanodeStorageInfo firstChosen \u003d null;\n    while(numOfReplicas \u003e 0 \u0026\u0026 numOfAvailableNodes \u003e 0) {\n      DatanodeDescriptor chosenNode \u003d chooseDataNode(scope);\n      if (excludedNodes.add(chosenNode)) { //was not in the excluded list\n        if (LOG.isDebugEnabled()) {\n          builder.append(\"\\nNode \").append(NodeBase.getPath(chosenNode)).append(\" [\");\n        }\n        numOfAvailableNodes--;\n        DatanodeStorageInfo storage \u003d null;\n        if (isGoodDatanode(chosenNode, maxNodesPerRack, considerLoad,\n            results, avoidStaleNodes)) {\n          for (Iterator\u003cMap.Entry\u003cStorageType, Integer\u003e\u003e iter \u003d storageTypes\n              .entrySet().iterator(); iter.hasNext(); ) {\n            Map.Entry\u003cStorageType, Integer\u003e entry \u003d iter.next();\n            storage \u003d chooseStorage4Block(\n                chosenNode, blocksize, results, entry.getKey());\n            if (storage !\u003d null) {\n              numOfReplicas--;\n              if (firstChosen \u003d\u003d null) {\n                firstChosen \u003d storage;\n              }\n              // add node and related nodes to excludedNode\n              numOfAvailableNodes -\u003d\n                  addToExcludedNodes(chosenNode, excludedNodes);\n              int num \u003d entry.getValue();\n              if (num \u003d\u003d 1) {\n                iter.remove();\n              } else {\n                entry.setValue(num - 1);\n              }\n              break;\n            }\n          }\n        }\n\n        if (LOG.isDebugEnabled()) {\n          builder.append(\"\\n]\");\n        }\n\n        // If no candidate storage was found on this DN then set badTarget.\n        badTarget \u003d (storage \u003d\u003d null);\n      }\n    }\n      \n    if (numOfReplicas\u003e0) {\n      String detail \u003d enableDebugLogging;\n      if (LOG.isDebugEnabled()) {\n        if (badTarget \u0026\u0026 builder !\u003d null) {\n          detail \u003d builder.toString();\n          builder.setLength(0);\n        } else {\n          detail \u003d \"\";\n        }\n      }\n      throw new NotEnoughReplicasException(detail);\n    }\n    \n    return firstChosen;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
      "extendedDetails": {}
    },
    "43539b5ff4ac0874a8a454dc93a2a782b0e0ea8f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4937. ReplicationMonitor can infinite-loop in BlockPlacementPolicyDefault#chooseRandom(). Contributed by Kihwal Lee.\n",
      "commitDate": "30/10/15 7:29 AM",
      "commitName": "43539b5ff4ac0874a8a454dc93a2a782b0e0ea8f",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "28/10/15 11:14 PM",
      "commitNameOld": "588baab160e7c328dca1c45cf3541e79218406e8",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 1.34,
      "commitsBetweenForRepo": 18,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,78 +1,90 @@\n   protected DatanodeStorageInfo chooseRandom(int numOfReplicas,\n                             String scope,\n                             Set\u003cNode\u003e excludedNodes,\n                             long blocksize,\n                             int maxNodesPerRack,\n                             List\u003cDatanodeStorageInfo\u003e results,\n                             boolean avoidStaleNodes,\n                             EnumMap\u003cStorageType, Integer\u003e storageTypes)\n                             throws NotEnoughReplicasException {\n \n     int numOfAvailableNodes \u003d clusterMap.countNumOfAvailableNodes(\n         scope, excludedNodes);\n+    int refreshCounter \u003d numOfAvailableNodes;\n     StringBuilder builder \u003d null;\n     if (LOG.isDebugEnabled()) {\n       builder \u003d debugLoggingBuilder.get();\n       builder.setLength(0);\n       builder.append(\"[\");\n     }\n     boolean badTarget \u003d false;\n     DatanodeStorageInfo firstChosen \u003d null;\n     while(numOfReplicas \u003e 0 \u0026\u0026 numOfAvailableNodes \u003e 0) {\n       DatanodeDescriptor chosenNode \u003d chooseDataNode(scope);\n       if (excludedNodes.add(chosenNode)) { //was not in the excluded list\n         if (LOG.isDebugEnabled()) {\n           builder.append(\"\\nNode \").append(NodeBase.getPath(chosenNode)).append(\" [\");\n         }\n         numOfAvailableNodes--;\n         DatanodeStorageInfo storage \u003d null;\n         if (isGoodDatanode(chosenNode, maxNodesPerRack, considerLoad,\n             results, avoidStaleNodes)) {\n           for (Iterator\u003cMap.Entry\u003cStorageType, Integer\u003e\u003e iter \u003d storageTypes\n               .entrySet().iterator(); iter.hasNext(); ) {\n             Map.Entry\u003cStorageType, Integer\u003e entry \u003d iter.next();\n             storage \u003d chooseStorage4Block(\n                 chosenNode, blocksize, results, entry.getKey());\n             if (storage !\u003d null) {\n               numOfReplicas--;\n               if (firstChosen \u003d\u003d null) {\n                 firstChosen \u003d storage;\n               }\n               // add node and related nodes to excludedNode\n               numOfAvailableNodes -\u003d\n                   addToExcludedNodes(chosenNode, excludedNodes);\n               int num \u003d entry.getValue();\n               if (num \u003d\u003d 1) {\n                 iter.remove();\n               } else {\n                 entry.setValue(num - 1);\n               }\n               break;\n             }\n           }\n         }\n \n         if (LOG.isDebugEnabled()) {\n           builder.append(\"\\n]\");\n         }\n \n         // If no candidate storage was found on this DN then set badTarget.\n         badTarget \u003d (storage \u003d\u003d null);\n       }\n+      // Refresh the node count. If the live node count became smaller,\n+      // but it is not reflected in this loop, it may loop forever in case\n+      // the replicas/rack cannot be satisfied.\n+      if (--refreshCounter \u003d\u003d 0) {\n+        refreshCounter \u003d clusterMap.countNumOfAvailableNodes(scope,\n+            excludedNodes);\n+        // It has already gone through enough number of nodes.\n+        if (refreshCounter \u003c\u003d excludedNodes.size()) {\n+          break;\n+        }\n+      }\n     }\n       \n     if (numOfReplicas\u003e0) {\n       String detail \u003d enableDebugLogging;\n       if (LOG.isDebugEnabled()) {\n         if (badTarget \u0026\u0026 builder !\u003d null) {\n           detail \u003d builder.toString();\n           builder.setLength(0);\n         } else {\n           detail \u003d \"\";\n         }\n       }\n       throw new NotEnoughReplicasException(detail);\n     }\n     \n     return firstChosen;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected DatanodeStorageInfo chooseRandom(int numOfReplicas,\n                            String scope,\n                            Set\u003cNode\u003e excludedNodes,\n                            long blocksize,\n                            int maxNodesPerRack,\n                            List\u003cDatanodeStorageInfo\u003e results,\n                            boolean avoidStaleNodes,\n                            EnumMap\u003cStorageType, Integer\u003e storageTypes)\n                            throws NotEnoughReplicasException {\n\n    int numOfAvailableNodes \u003d clusterMap.countNumOfAvailableNodes(\n        scope, excludedNodes);\n    int refreshCounter \u003d numOfAvailableNodes;\n    StringBuilder builder \u003d null;\n    if (LOG.isDebugEnabled()) {\n      builder \u003d debugLoggingBuilder.get();\n      builder.setLength(0);\n      builder.append(\"[\");\n    }\n    boolean badTarget \u003d false;\n    DatanodeStorageInfo firstChosen \u003d null;\n    while(numOfReplicas \u003e 0 \u0026\u0026 numOfAvailableNodes \u003e 0) {\n      DatanodeDescriptor chosenNode \u003d chooseDataNode(scope);\n      if (excludedNodes.add(chosenNode)) { //was not in the excluded list\n        if (LOG.isDebugEnabled()) {\n          builder.append(\"\\nNode \").append(NodeBase.getPath(chosenNode)).append(\" [\");\n        }\n        numOfAvailableNodes--;\n        DatanodeStorageInfo storage \u003d null;\n        if (isGoodDatanode(chosenNode, maxNodesPerRack, considerLoad,\n            results, avoidStaleNodes)) {\n          for (Iterator\u003cMap.Entry\u003cStorageType, Integer\u003e\u003e iter \u003d storageTypes\n              .entrySet().iterator(); iter.hasNext(); ) {\n            Map.Entry\u003cStorageType, Integer\u003e entry \u003d iter.next();\n            storage \u003d chooseStorage4Block(\n                chosenNode, blocksize, results, entry.getKey());\n            if (storage !\u003d null) {\n              numOfReplicas--;\n              if (firstChosen \u003d\u003d null) {\n                firstChosen \u003d storage;\n              }\n              // add node and related nodes to excludedNode\n              numOfAvailableNodes -\u003d\n                  addToExcludedNodes(chosenNode, excludedNodes);\n              int num \u003d entry.getValue();\n              if (num \u003d\u003d 1) {\n                iter.remove();\n              } else {\n                entry.setValue(num - 1);\n              }\n              break;\n            }\n          }\n        }\n\n        if (LOG.isDebugEnabled()) {\n          builder.append(\"\\n]\");\n        }\n\n        // If no candidate storage was found on this DN then set badTarget.\n        badTarget \u003d (storage \u003d\u003d null);\n      }\n      // Refresh the node count. If the live node count became smaller,\n      // but it is not reflected in this loop, it may loop forever in case\n      // the replicas/rack cannot be satisfied.\n      if (--refreshCounter \u003d\u003d 0) {\n        refreshCounter \u003d clusterMap.countNumOfAvailableNodes(scope,\n            excludedNodes);\n        // It has already gone through enough number of nodes.\n        if (refreshCounter \u003c\u003d excludedNodes.size()) {\n          break;\n        }\n      }\n    }\n      \n    if (numOfReplicas\u003e0) {\n      String detail \u003d enableDebugLogging;\n      if (LOG.isDebugEnabled()) {\n        if (badTarget \u0026\u0026 builder !\u003d null) {\n          detail \u003d builder.toString();\n          builder.setLength(0);\n        } else {\n          detail \u003d \"\";\n        }\n      }\n      throw new NotEnoughReplicasException(detail);\n    }\n    \n    return firstChosen;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
      "extendedDetails": {}
    },
    "8fa41d9dd4b923bf4141f019414a1a8b079124c6": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8946. Improve choosing datanode storage for block placement. (yliu)\n",
      "commitDate": "31/08/15 5:52 PM",
      "commitName": "8fa41d9dd4b923bf4141f019414a1a8b079124c6",
      "commitAuthor": "yliu",
      "commitDateOld": "20/08/15 5:15 AM",
      "commitNameOld": "5e8fe8943718309b5e39a794360aebccae28b331",
      "commitAuthorOld": "yliu",
      "daysBetweenCommits": 11.53,
      "commitsBetweenForRepo": 55,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,88 +1,78 @@\n   protected DatanodeStorageInfo chooseRandom(int numOfReplicas,\n                             String scope,\n                             Set\u003cNode\u003e excludedNodes,\n                             long blocksize,\n                             int maxNodesPerRack,\n                             List\u003cDatanodeStorageInfo\u003e results,\n                             boolean avoidStaleNodes,\n                             EnumMap\u003cStorageType, Integer\u003e storageTypes)\n                             throws NotEnoughReplicasException {\n-      \n+\n     int numOfAvailableNodes \u003d clusterMap.countNumOfAvailableNodes(\n         scope, excludedNodes);\n     StringBuilder builder \u003d null;\n     if (LOG.isDebugEnabled()) {\n       builder \u003d debugLoggingBuilder.get();\n       builder.setLength(0);\n       builder.append(\"[\");\n     }\n     boolean badTarget \u003d false;\n     DatanodeStorageInfo firstChosen \u003d null;\n     while(numOfReplicas \u003e 0 \u0026\u0026 numOfAvailableNodes \u003e 0) {\n       DatanodeDescriptor chosenNode \u003d chooseDataNode(scope);\n       if (excludedNodes.add(chosenNode)) { //was not in the excluded list\n         if (LOG.isDebugEnabled()) {\n           builder.append(\"\\nNode \").append(NodeBase.getPath(chosenNode)).append(\" [\");\n         }\n         numOfAvailableNodes--;\n-        if (!isGoodDatanode(chosenNode, maxNodesPerRack, considerLoad,\n+        DatanodeStorageInfo storage \u003d null;\n+        if (isGoodDatanode(chosenNode, maxNodesPerRack, considerLoad,\n             results, avoidStaleNodes)) {\n-          if (LOG.isDebugEnabled()) {\n-            builder.append(\"\\n]\");\n-          }\n-          badTarget \u003d true;\n-          continue;\n-        }\n-\n-        final DatanodeStorageInfo[] storages \u003d DFSUtil.shuffle(\n-            chosenNode.getStorageInfos());\n-        int i \u003d 0;\n-        boolean search \u003d true;\n-        for (Iterator\u003cMap.Entry\u003cStorageType, Integer\u003e\u003e iter \u003d storageTypes\n-            .entrySet().iterator(); search \u0026\u0026 iter.hasNext(); ) {\n-          Map.Entry\u003cStorageType, Integer\u003e entry \u003d iter.next();\n-          for (i \u003d 0; i \u003c storages.length; i++) {\n-            StorageType type \u003d entry.getKey();\n-            final int newExcludedNodes \u003d addIfIsGoodTarget(storages[i],\n-                excludedNodes, blocksize, results, type);\n-            if (newExcludedNodes \u003e\u003d 0) {\n+          for (Iterator\u003cMap.Entry\u003cStorageType, Integer\u003e\u003e iter \u003d storageTypes\n+              .entrySet().iterator(); iter.hasNext(); ) {\n+            Map.Entry\u003cStorageType, Integer\u003e entry \u003d iter.next();\n+            storage \u003d chooseStorage4Block(\n+                chosenNode, blocksize, results, entry.getKey());\n+            if (storage !\u003d null) {\n               numOfReplicas--;\n               if (firstChosen \u003d\u003d null) {\n-                firstChosen \u003d storages[i];\n+                firstChosen \u003d storage;\n               }\n-              numOfAvailableNodes -\u003d newExcludedNodes;\n+              // add node and related nodes to excludedNode\n+              numOfAvailableNodes -\u003d\n+                  addToExcludedNodes(chosenNode, excludedNodes);\n               int num \u003d entry.getValue();\n               if (num \u003d\u003d 1) {\n                 iter.remove();\n               } else {\n                 entry.setValue(num - 1);\n               }\n-              search \u003d false;\n               break;\n             }\n           }\n         }\n+\n         if (LOG.isDebugEnabled()) {\n           builder.append(\"\\n]\");\n         }\n \n         // If no candidate storage was found on this DN then set badTarget.\n-        badTarget \u003d (i \u003d\u003d storages.length);\n+        badTarget \u003d (storage \u003d\u003d null);\n       }\n     }\n       \n     if (numOfReplicas\u003e0) {\n       String detail \u003d enableDebugLogging;\n       if (LOG.isDebugEnabled()) {\n         if (badTarget \u0026\u0026 builder !\u003d null) {\n           detail \u003d builder.toString();\n           builder.setLength(0);\n         } else {\n           detail \u003d \"\";\n         }\n       }\n       throw new NotEnoughReplicasException(detail);\n     }\n     \n     return firstChosen;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected DatanodeStorageInfo chooseRandom(int numOfReplicas,\n                            String scope,\n                            Set\u003cNode\u003e excludedNodes,\n                            long blocksize,\n                            int maxNodesPerRack,\n                            List\u003cDatanodeStorageInfo\u003e results,\n                            boolean avoidStaleNodes,\n                            EnumMap\u003cStorageType, Integer\u003e storageTypes)\n                            throws NotEnoughReplicasException {\n\n    int numOfAvailableNodes \u003d clusterMap.countNumOfAvailableNodes(\n        scope, excludedNodes);\n    StringBuilder builder \u003d null;\n    if (LOG.isDebugEnabled()) {\n      builder \u003d debugLoggingBuilder.get();\n      builder.setLength(0);\n      builder.append(\"[\");\n    }\n    boolean badTarget \u003d false;\n    DatanodeStorageInfo firstChosen \u003d null;\n    while(numOfReplicas \u003e 0 \u0026\u0026 numOfAvailableNodes \u003e 0) {\n      DatanodeDescriptor chosenNode \u003d chooseDataNode(scope);\n      if (excludedNodes.add(chosenNode)) { //was not in the excluded list\n        if (LOG.isDebugEnabled()) {\n          builder.append(\"\\nNode \").append(NodeBase.getPath(chosenNode)).append(\" [\");\n        }\n        numOfAvailableNodes--;\n        DatanodeStorageInfo storage \u003d null;\n        if (isGoodDatanode(chosenNode, maxNodesPerRack, considerLoad,\n            results, avoidStaleNodes)) {\n          for (Iterator\u003cMap.Entry\u003cStorageType, Integer\u003e\u003e iter \u003d storageTypes\n              .entrySet().iterator(); iter.hasNext(); ) {\n            Map.Entry\u003cStorageType, Integer\u003e entry \u003d iter.next();\n            storage \u003d chooseStorage4Block(\n                chosenNode, blocksize, results, entry.getKey());\n            if (storage !\u003d null) {\n              numOfReplicas--;\n              if (firstChosen \u003d\u003d null) {\n                firstChosen \u003d storage;\n              }\n              // add node and related nodes to excludedNode\n              numOfAvailableNodes -\u003d\n                  addToExcludedNodes(chosenNode, excludedNodes);\n              int num \u003d entry.getValue();\n              if (num \u003d\u003d 1) {\n                iter.remove();\n              } else {\n                entry.setValue(num - 1);\n              }\n              break;\n            }\n          }\n        }\n\n        if (LOG.isDebugEnabled()) {\n          builder.append(\"\\n]\");\n        }\n\n        // If no candidate storage was found on this DN then set badTarget.\n        badTarget \u003d (storage \u003d\u003d null);\n      }\n    }\n      \n    if (numOfReplicas\u003e0) {\n      String detail \u003d enableDebugLogging;\n      if (LOG.isDebugEnabled()) {\n        if (badTarget \u0026\u0026 builder !\u003d null) {\n          detail \u003d builder.toString();\n          builder.setLength(0);\n        } else {\n          detail \u003d \"\";\n        }\n      }\n      throw new NotEnoughReplicasException(detail);\n    }\n    \n    return firstChosen;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
      "extendedDetails": {}
    },
    "80a29906bcd718bbba223fa099e523281d9f3369": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8884. Fail-fast check in BlockPlacementPolicyDefault#chooseTarget. (yliu)\n",
      "commitDate": "20/08/15 5:07 AM",
      "commitName": "80a29906bcd718bbba223fa099e523281d9f3369",
      "commitAuthor": "yliu",
      "commitDateOld": "29/06/15 2:55 AM",
      "commitNameOld": "88ceb382ef45bd09cf004cf44aedbabaf3976759",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 52.09,
      "commitsBetweenForRepo": 309,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,81 +1,88 @@\n   protected DatanodeStorageInfo chooseRandom(int numOfReplicas,\n                             String scope,\n                             Set\u003cNode\u003e excludedNodes,\n                             long blocksize,\n                             int maxNodesPerRack,\n                             List\u003cDatanodeStorageInfo\u003e results,\n                             boolean avoidStaleNodes,\n                             EnumMap\u003cStorageType, Integer\u003e storageTypes)\n                             throws NotEnoughReplicasException {\n       \n     int numOfAvailableNodes \u003d clusterMap.countNumOfAvailableNodes(\n         scope, excludedNodes);\n     StringBuilder builder \u003d null;\n     if (LOG.isDebugEnabled()) {\n       builder \u003d debugLoggingBuilder.get();\n       builder.setLength(0);\n       builder.append(\"[\");\n     }\n     boolean badTarget \u003d false;\n     DatanodeStorageInfo firstChosen \u003d null;\n     while(numOfReplicas \u003e 0 \u0026\u0026 numOfAvailableNodes \u003e 0) {\n       DatanodeDescriptor chosenNode \u003d chooseDataNode(scope);\n       if (excludedNodes.add(chosenNode)) { //was not in the excluded list\n         if (LOG.isDebugEnabled()) {\n           builder.append(\"\\nNode \").append(NodeBase.getPath(chosenNode)).append(\" [\");\n         }\n         numOfAvailableNodes--;\n+        if (!isGoodDatanode(chosenNode, maxNodesPerRack, considerLoad,\n+            results, avoidStaleNodes)) {\n+          if (LOG.isDebugEnabled()) {\n+            builder.append(\"\\n]\");\n+          }\n+          badTarget \u003d true;\n+          continue;\n+        }\n \n         final DatanodeStorageInfo[] storages \u003d DFSUtil.shuffle(\n             chosenNode.getStorageInfos());\n         int i \u003d 0;\n         boolean search \u003d true;\n         for (Iterator\u003cMap.Entry\u003cStorageType, Integer\u003e\u003e iter \u003d storageTypes\n             .entrySet().iterator(); search \u0026\u0026 iter.hasNext(); ) {\n           Map.Entry\u003cStorageType, Integer\u003e entry \u003d iter.next();\n           for (i \u003d 0; i \u003c storages.length; i++) {\n             StorageType type \u003d entry.getKey();\n             final int newExcludedNodes \u003d addIfIsGoodTarget(storages[i],\n-                excludedNodes, blocksize, maxNodesPerRack, considerLoad, results,\n-                avoidStaleNodes, type);\n+                excludedNodes, blocksize, results, type);\n             if (newExcludedNodes \u003e\u003d 0) {\n               numOfReplicas--;\n               if (firstChosen \u003d\u003d null) {\n                 firstChosen \u003d storages[i];\n               }\n               numOfAvailableNodes -\u003d newExcludedNodes;\n               int num \u003d entry.getValue();\n               if (num \u003d\u003d 1) {\n                 iter.remove();\n               } else {\n                 entry.setValue(num - 1);\n               }\n               search \u003d false;\n               break;\n             }\n           }\n         }\n         if (LOG.isDebugEnabled()) {\n           builder.append(\"\\n]\");\n         }\n \n         // If no candidate storage was found on this DN then set badTarget.\n         badTarget \u003d (i \u003d\u003d storages.length);\n       }\n     }\n       \n     if (numOfReplicas\u003e0) {\n       String detail \u003d enableDebugLogging;\n       if (LOG.isDebugEnabled()) {\n         if (badTarget \u0026\u0026 builder !\u003d null) {\n           detail \u003d builder.toString();\n           builder.setLength(0);\n         } else {\n           detail \u003d \"\";\n         }\n       }\n       throw new NotEnoughReplicasException(detail);\n     }\n     \n     return firstChosen;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected DatanodeStorageInfo chooseRandom(int numOfReplicas,\n                            String scope,\n                            Set\u003cNode\u003e excludedNodes,\n                            long blocksize,\n                            int maxNodesPerRack,\n                            List\u003cDatanodeStorageInfo\u003e results,\n                            boolean avoidStaleNodes,\n                            EnumMap\u003cStorageType, Integer\u003e storageTypes)\n                            throws NotEnoughReplicasException {\n      \n    int numOfAvailableNodes \u003d clusterMap.countNumOfAvailableNodes(\n        scope, excludedNodes);\n    StringBuilder builder \u003d null;\n    if (LOG.isDebugEnabled()) {\n      builder \u003d debugLoggingBuilder.get();\n      builder.setLength(0);\n      builder.append(\"[\");\n    }\n    boolean badTarget \u003d false;\n    DatanodeStorageInfo firstChosen \u003d null;\n    while(numOfReplicas \u003e 0 \u0026\u0026 numOfAvailableNodes \u003e 0) {\n      DatanodeDescriptor chosenNode \u003d chooseDataNode(scope);\n      if (excludedNodes.add(chosenNode)) { //was not in the excluded list\n        if (LOG.isDebugEnabled()) {\n          builder.append(\"\\nNode \").append(NodeBase.getPath(chosenNode)).append(\" [\");\n        }\n        numOfAvailableNodes--;\n        if (!isGoodDatanode(chosenNode, maxNodesPerRack, considerLoad,\n            results, avoidStaleNodes)) {\n          if (LOG.isDebugEnabled()) {\n            builder.append(\"\\n]\");\n          }\n          badTarget \u003d true;\n          continue;\n        }\n\n        final DatanodeStorageInfo[] storages \u003d DFSUtil.shuffle(\n            chosenNode.getStorageInfos());\n        int i \u003d 0;\n        boolean search \u003d true;\n        for (Iterator\u003cMap.Entry\u003cStorageType, Integer\u003e\u003e iter \u003d storageTypes\n            .entrySet().iterator(); search \u0026\u0026 iter.hasNext(); ) {\n          Map.Entry\u003cStorageType, Integer\u003e entry \u003d iter.next();\n          for (i \u003d 0; i \u003c storages.length; i++) {\n            StorageType type \u003d entry.getKey();\n            final int newExcludedNodes \u003d addIfIsGoodTarget(storages[i],\n                excludedNodes, blocksize, results, type);\n            if (newExcludedNodes \u003e\u003d 0) {\n              numOfReplicas--;\n              if (firstChosen \u003d\u003d null) {\n                firstChosen \u003d storages[i];\n              }\n              numOfAvailableNodes -\u003d newExcludedNodes;\n              int num \u003d entry.getValue();\n              if (num \u003d\u003d 1) {\n                iter.remove();\n              } else {\n                entry.setValue(num - 1);\n              }\n              search \u003d false;\n              break;\n            }\n          }\n        }\n        if (LOG.isDebugEnabled()) {\n          builder.append(\"\\n]\");\n        }\n\n        // If no candidate storage was found on this DN then set badTarget.\n        badTarget \u003d (i \u003d\u003d storages.length);\n      }\n    }\n      \n    if (numOfReplicas\u003e0) {\n      String detail \u003d enableDebugLogging;\n      if (LOG.isDebugEnabled()) {\n        if (badTarget \u0026\u0026 builder !\u003d null) {\n          detail \u003d builder.toString();\n          builder.setLength(0);\n        } else {\n          detail \u003d \"\";\n        }\n      }\n      throw new NotEnoughReplicasException(detail);\n    }\n    \n    return firstChosen;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
      "extendedDetails": {}
    },
    "de30d66b2673d0344346fb985e786247ca682317": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8131. Implement a space balanced block placement policy. Contributed by Liu Shaohui.\n",
      "commitDate": "19/05/15 6:04 AM",
      "commitName": "de30d66b2673d0344346fb985e786247ca682317",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "02/05/15 10:03 AM",
      "commitNameOld": "6ae2a0d048e133b43249c248a75a4d77d9abb80d",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 16.83,
      "commitsBetweenForRepo": 219,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,82 +1,81 @@\n   protected DatanodeStorageInfo chooseRandom(int numOfReplicas,\n                             String scope,\n                             Set\u003cNode\u003e excludedNodes,\n                             long blocksize,\n                             int maxNodesPerRack,\n                             List\u003cDatanodeStorageInfo\u003e results,\n                             boolean avoidStaleNodes,\n                             EnumMap\u003cStorageType, Integer\u003e storageTypes)\n                             throws NotEnoughReplicasException {\n       \n     int numOfAvailableNodes \u003d clusterMap.countNumOfAvailableNodes(\n         scope, excludedNodes);\n     StringBuilder builder \u003d null;\n     if (LOG.isDebugEnabled()) {\n       builder \u003d debugLoggingBuilder.get();\n       builder.setLength(0);\n       builder.append(\"[\");\n     }\n     boolean badTarget \u003d false;\n     DatanodeStorageInfo firstChosen \u003d null;\n     while(numOfReplicas \u003e 0 \u0026\u0026 numOfAvailableNodes \u003e 0) {\n-      DatanodeDescriptor chosenNode \u003d \n-          (DatanodeDescriptor)clusterMap.chooseRandom(scope);\n+      DatanodeDescriptor chosenNode \u003d chooseDataNode(scope);\n       if (excludedNodes.add(chosenNode)) { //was not in the excluded list\n         if (LOG.isDebugEnabled()) {\n           builder.append(\"\\nNode \").append(NodeBase.getPath(chosenNode)).append(\" [\");\n         }\n         numOfAvailableNodes--;\n \n         final DatanodeStorageInfo[] storages \u003d DFSUtil.shuffle(\n             chosenNode.getStorageInfos());\n         int i \u003d 0;\n         boolean search \u003d true;\n         for (Iterator\u003cMap.Entry\u003cStorageType, Integer\u003e\u003e iter \u003d storageTypes\n             .entrySet().iterator(); search \u0026\u0026 iter.hasNext(); ) {\n           Map.Entry\u003cStorageType, Integer\u003e entry \u003d iter.next();\n           for (i \u003d 0; i \u003c storages.length; i++) {\n             StorageType type \u003d entry.getKey();\n             final int newExcludedNodes \u003d addIfIsGoodTarget(storages[i],\n                 excludedNodes, blocksize, maxNodesPerRack, considerLoad, results,\n                 avoidStaleNodes, type);\n             if (newExcludedNodes \u003e\u003d 0) {\n               numOfReplicas--;\n               if (firstChosen \u003d\u003d null) {\n                 firstChosen \u003d storages[i];\n               }\n               numOfAvailableNodes -\u003d newExcludedNodes;\n               int num \u003d entry.getValue();\n               if (num \u003d\u003d 1) {\n                 iter.remove();\n               } else {\n                 entry.setValue(num - 1);\n               }\n               search \u003d false;\n               break;\n             }\n           }\n         }\n         if (LOG.isDebugEnabled()) {\n           builder.append(\"\\n]\");\n         }\n \n         // If no candidate storage was found on this DN then set badTarget.\n         badTarget \u003d (i \u003d\u003d storages.length);\n       }\n     }\n       \n     if (numOfReplicas\u003e0) {\n       String detail \u003d enableDebugLogging;\n       if (LOG.isDebugEnabled()) {\n         if (badTarget \u0026\u0026 builder !\u003d null) {\n           detail \u003d builder.toString();\n           builder.setLength(0);\n         } else {\n           detail \u003d \"\";\n         }\n       }\n       throw new NotEnoughReplicasException(detail);\n     }\n     \n     return firstChosen;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected DatanodeStorageInfo chooseRandom(int numOfReplicas,\n                            String scope,\n                            Set\u003cNode\u003e excludedNodes,\n                            long blocksize,\n                            int maxNodesPerRack,\n                            List\u003cDatanodeStorageInfo\u003e results,\n                            boolean avoidStaleNodes,\n                            EnumMap\u003cStorageType, Integer\u003e storageTypes)\n                            throws NotEnoughReplicasException {\n      \n    int numOfAvailableNodes \u003d clusterMap.countNumOfAvailableNodes(\n        scope, excludedNodes);\n    StringBuilder builder \u003d null;\n    if (LOG.isDebugEnabled()) {\n      builder \u003d debugLoggingBuilder.get();\n      builder.setLength(0);\n      builder.append(\"[\");\n    }\n    boolean badTarget \u003d false;\n    DatanodeStorageInfo firstChosen \u003d null;\n    while(numOfReplicas \u003e 0 \u0026\u0026 numOfAvailableNodes \u003e 0) {\n      DatanodeDescriptor chosenNode \u003d chooseDataNode(scope);\n      if (excludedNodes.add(chosenNode)) { //was not in the excluded list\n        if (LOG.isDebugEnabled()) {\n          builder.append(\"\\nNode \").append(NodeBase.getPath(chosenNode)).append(\" [\");\n        }\n        numOfAvailableNodes--;\n\n        final DatanodeStorageInfo[] storages \u003d DFSUtil.shuffle(\n            chosenNode.getStorageInfos());\n        int i \u003d 0;\n        boolean search \u003d true;\n        for (Iterator\u003cMap.Entry\u003cStorageType, Integer\u003e\u003e iter \u003d storageTypes\n            .entrySet().iterator(); search \u0026\u0026 iter.hasNext(); ) {\n          Map.Entry\u003cStorageType, Integer\u003e entry \u003d iter.next();\n          for (i \u003d 0; i \u003c storages.length; i++) {\n            StorageType type \u003d entry.getKey();\n            final int newExcludedNodes \u003d addIfIsGoodTarget(storages[i],\n                excludedNodes, blocksize, maxNodesPerRack, considerLoad, results,\n                avoidStaleNodes, type);\n            if (newExcludedNodes \u003e\u003d 0) {\n              numOfReplicas--;\n              if (firstChosen \u003d\u003d null) {\n                firstChosen \u003d storages[i];\n              }\n              numOfAvailableNodes -\u003d newExcludedNodes;\n              int num \u003d entry.getValue();\n              if (num \u003d\u003d 1) {\n                iter.remove();\n              } else {\n                entry.setValue(num - 1);\n              }\n              search \u003d false;\n              break;\n            }\n          }\n        }\n        if (LOG.isDebugEnabled()) {\n          builder.append(\"\\n]\");\n        }\n\n        // If no candidate storage was found on this DN then set badTarget.\n        badTarget \u003d (i \u003d\u003d storages.length);\n      }\n    }\n      \n    if (numOfReplicas\u003e0) {\n      String detail \u003d enableDebugLogging;\n      if (LOG.isDebugEnabled()) {\n        if (badTarget \u0026\u0026 builder !\u003d null) {\n          detail \u003d builder.toString();\n          builder.setLength(0);\n        } else {\n          detail \u003d \"\";\n        }\n      }\n      throw new NotEnoughReplicasException(detail);\n    }\n    \n    return firstChosen;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
      "extendedDetails": {}
    },
    "22a41dce4af4d5b533ba875b322551db1c152878": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6997: add more tests for data migration and replicaion.\n",
      "commitDate": "06/09/14 4:44 PM",
      "commitName": "22a41dce4af4d5b533ba875b322551db1c152878",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "04/09/14 2:19 PM",
      "commitNameOld": "e08701ec71f7c10d8f15122d90c35f9f22e40837",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 2.1,
      "commitsBetweenForRepo": 16,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,74 +1,82 @@\n   protected DatanodeStorageInfo chooseRandom(int numOfReplicas,\n                             String scope,\n                             Set\u003cNode\u003e excludedNodes,\n                             long blocksize,\n                             int maxNodesPerRack,\n                             List\u003cDatanodeStorageInfo\u003e results,\n                             boolean avoidStaleNodes,\n                             EnumMap\u003cStorageType, Integer\u003e storageTypes)\n                             throws NotEnoughReplicasException {\n       \n     int numOfAvailableNodes \u003d clusterMap.countNumOfAvailableNodes(\n         scope, excludedNodes);\n     StringBuilder builder \u003d null;\n     if (LOG.isDebugEnabled()) {\n       builder \u003d debugLoggingBuilder.get();\n       builder.setLength(0);\n       builder.append(\"[\");\n     }\n     boolean badTarget \u003d false;\n     DatanodeStorageInfo firstChosen \u003d null;\n     while(numOfReplicas \u003e 0 \u0026\u0026 numOfAvailableNodes \u003e 0) {\n       DatanodeDescriptor chosenNode \u003d \n           (DatanodeDescriptor)clusterMap.chooseRandom(scope);\n       if (excludedNodes.add(chosenNode)) { //was not in the excluded list\n+        if (LOG.isDebugEnabled()) {\n+          builder.append(\"\\nNode \").append(NodeBase.getPath(chosenNode)).append(\" [\");\n+        }\n         numOfAvailableNodes--;\n \n         final DatanodeStorageInfo[] storages \u003d DFSUtil.shuffle(\n             chosenNode.getStorageInfos());\n         int i \u003d 0;\n         boolean search \u003d true;\n         for (Iterator\u003cMap.Entry\u003cStorageType, Integer\u003e\u003e iter \u003d storageTypes\n             .entrySet().iterator(); search \u0026\u0026 iter.hasNext(); ) {\n           Map.Entry\u003cStorageType, Integer\u003e entry \u003d iter.next();\n           for (i \u003d 0; i \u003c storages.length; i++) {\n             StorageType type \u003d entry.getKey();\n             final int newExcludedNodes \u003d addIfIsGoodTarget(storages[i],\n                 excludedNodes, blocksize, maxNodesPerRack, considerLoad, results,\n                 avoidStaleNodes, type);\n             if (newExcludedNodes \u003e\u003d 0) {\n               numOfReplicas--;\n               if (firstChosen \u003d\u003d null) {\n                 firstChosen \u003d storages[i];\n               }\n               numOfAvailableNodes -\u003d newExcludedNodes;\n               int num \u003d entry.getValue();\n               if (num \u003d\u003d 1) {\n                 iter.remove();\n               } else {\n                 entry.setValue(num - 1);\n               }\n               search \u003d false;\n               break;\n             }\n           }\n         }\n+        if (LOG.isDebugEnabled()) {\n+          builder.append(\"\\n]\");\n+        }\n \n         // If no candidate storage was found on this DN then set badTarget.\n         badTarget \u003d (i \u003d\u003d storages.length);\n       }\n     }\n       \n     if (numOfReplicas\u003e0) {\n       String detail \u003d enableDebugLogging;\n       if (LOG.isDebugEnabled()) {\n         if (badTarget \u0026\u0026 builder !\u003d null) {\n-          detail \u003d builder.append(\"]\").toString();\n+          detail \u003d builder.toString();\n           builder.setLength(0);\n-        } else detail \u003d \"\";\n+        } else {\n+          detail \u003d \"\";\n+        }\n       }\n       throw new NotEnoughReplicasException(detail);\n     }\n     \n     return firstChosen;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected DatanodeStorageInfo chooseRandom(int numOfReplicas,\n                            String scope,\n                            Set\u003cNode\u003e excludedNodes,\n                            long blocksize,\n                            int maxNodesPerRack,\n                            List\u003cDatanodeStorageInfo\u003e results,\n                            boolean avoidStaleNodes,\n                            EnumMap\u003cStorageType, Integer\u003e storageTypes)\n                            throws NotEnoughReplicasException {\n      \n    int numOfAvailableNodes \u003d clusterMap.countNumOfAvailableNodes(\n        scope, excludedNodes);\n    StringBuilder builder \u003d null;\n    if (LOG.isDebugEnabled()) {\n      builder \u003d debugLoggingBuilder.get();\n      builder.setLength(0);\n      builder.append(\"[\");\n    }\n    boolean badTarget \u003d false;\n    DatanodeStorageInfo firstChosen \u003d null;\n    while(numOfReplicas \u003e 0 \u0026\u0026 numOfAvailableNodes \u003e 0) {\n      DatanodeDescriptor chosenNode \u003d \n          (DatanodeDescriptor)clusterMap.chooseRandom(scope);\n      if (excludedNodes.add(chosenNode)) { //was not in the excluded list\n        if (LOG.isDebugEnabled()) {\n          builder.append(\"\\nNode \").append(NodeBase.getPath(chosenNode)).append(\" [\");\n        }\n        numOfAvailableNodes--;\n\n        final DatanodeStorageInfo[] storages \u003d DFSUtil.shuffle(\n            chosenNode.getStorageInfos());\n        int i \u003d 0;\n        boolean search \u003d true;\n        for (Iterator\u003cMap.Entry\u003cStorageType, Integer\u003e\u003e iter \u003d storageTypes\n            .entrySet().iterator(); search \u0026\u0026 iter.hasNext(); ) {\n          Map.Entry\u003cStorageType, Integer\u003e entry \u003d iter.next();\n          for (i \u003d 0; i \u003c storages.length; i++) {\n            StorageType type \u003d entry.getKey();\n            final int newExcludedNodes \u003d addIfIsGoodTarget(storages[i],\n                excludedNodes, blocksize, maxNodesPerRack, considerLoad, results,\n                avoidStaleNodes, type);\n            if (newExcludedNodes \u003e\u003d 0) {\n              numOfReplicas--;\n              if (firstChosen \u003d\u003d null) {\n                firstChosen \u003d storages[i];\n              }\n              numOfAvailableNodes -\u003d newExcludedNodes;\n              int num \u003d entry.getValue();\n              if (num \u003d\u003d 1) {\n                iter.remove();\n              } else {\n                entry.setValue(num - 1);\n              }\n              search \u003d false;\n              break;\n            }\n          }\n        }\n        if (LOG.isDebugEnabled()) {\n          builder.append(\"\\n]\");\n        }\n\n        // If no candidate storage was found on this DN then set badTarget.\n        badTarget \u003d (i \u003d\u003d storages.length);\n      }\n    }\n      \n    if (numOfReplicas\u003e0) {\n      String detail \u003d enableDebugLogging;\n      if (LOG.isDebugEnabled()) {\n        if (badTarget \u0026\u0026 builder !\u003d null) {\n          detail \u003d builder.toString();\n          builder.setLength(0);\n        } else {\n          detail \u003d \"\";\n        }\n      }\n      throw new NotEnoughReplicasException(detail);\n    }\n    \n    return firstChosen;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
      "extendedDetails": {}
    },
    "e08701ec71f7c10d8f15122d90c35f9f22e40837": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-6961. Archival Storage: BlockPlacementPolicy#chooseTarget should check each valid storage type in each choosing round.\n",
      "commitDate": "04/09/14 2:19 PM",
      "commitName": "e08701ec71f7c10d8f15122d90c35f9f22e40837",
      "commitAuthor": "Jing Zhao",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-6961. Archival Storage: BlockPlacementPolicy#chooseTarget should check each valid storage type in each choosing round.\n",
          "commitDate": "04/09/14 2:19 PM",
          "commitName": "e08701ec71f7c10d8f15122d90c35f9f22e40837",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "27/08/14 2:08 PM",
          "commitNameOld": "b7ded466b00db0fe273058b844d56d810e0f8cc2",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 8.01,
          "commitsBetweenForRepo": 50,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,61 +1,74 @@\n   protected DatanodeStorageInfo chooseRandom(int numOfReplicas,\n                             String scope,\n                             Set\u003cNode\u003e excludedNodes,\n                             long blocksize,\n                             int maxNodesPerRack,\n                             List\u003cDatanodeStorageInfo\u003e results,\n                             boolean avoidStaleNodes,\n-                            StorageType storageType)\n-                                throws NotEnoughReplicasException {\n+                            EnumMap\u003cStorageType, Integer\u003e storageTypes)\n+                            throws NotEnoughReplicasException {\n       \n     int numOfAvailableNodes \u003d clusterMap.countNumOfAvailableNodes(\n         scope, excludedNodes);\n     StringBuilder builder \u003d null;\n     if (LOG.isDebugEnabled()) {\n       builder \u003d debugLoggingBuilder.get();\n       builder.setLength(0);\n       builder.append(\"[\");\n     }\n     boolean badTarget \u003d false;\n     DatanodeStorageInfo firstChosen \u003d null;\n     while(numOfReplicas \u003e 0 \u0026\u0026 numOfAvailableNodes \u003e 0) {\n       DatanodeDescriptor chosenNode \u003d \n           (DatanodeDescriptor)clusterMap.chooseRandom(scope);\n       if (excludedNodes.add(chosenNode)) { //was not in the excluded list\n         numOfAvailableNodes--;\n \n         final DatanodeStorageInfo[] storages \u003d DFSUtil.shuffle(\n             chosenNode.getStorageInfos());\n-        int i;\n-        for(i \u003d 0; i \u003c storages.length; i++) {\n-          final int newExcludedNodes \u003d addIfIsGoodTarget(storages[i],\n-              excludedNodes, blocksize, maxNodesPerRack, considerLoad, results,\n-              avoidStaleNodes, storageType);\n-          if (newExcludedNodes \u003e\u003d 0) {\n-            numOfReplicas--;\n-            if (firstChosen \u003d\u003d null) {\n-              firstChosen \u003d storages[i];\n+        int i \u003d 0;\n+        boolean search \u003d true;\n+        for (Iterator\u003cMap.Entry\u003cStorageType, Integer\u003e\u003e iter \u003d storageTypes\n+            .entrySet().iterator(); search \u0026\u0026 iter.hasNext(); ) {\n+          Map.Entry\u003cStorageType, Integer\u003e entry \u003d iter.next();\n+          for (i \u003d 0; i \u003c storages.length; i++) {\n+            StorageType type \u003d entry.getKey();\n+            final int newExcludedNodes \u003d addIfIsGoodTarget(storages[i],\n+                excludedNodes, blocksize, maxNodesPerRack, considerLoad, results,\n+                avoidStaleNodes, type);\n+            if (newExcludedNodes \u003e\u003d 0) {\n+              numOfReplicas--;\n+              if (firstChosen \u003d\u003d null) {\n+                firstChosen \u003d storages[i];\n+              }\n+              numOfAvailableNodes -\u003d newExcludedNodes;\n+              int num \u003d entry.getValue();\n+              if (num \u003d\u003d 1) {\n+                iter.remove();\n+              } else {\n+                entry.setValue(num - 1);\n+              }\n+              search \u003d false;\n+              break;\n             }\n-            numOfAvailableNodes -\u003d newExcludedNodes;\n-            break;\n           }\n         }\n \n         // If no candidate storage was found on this DN then set badTarget.\n         badTarget \u003d (i \u003d\u003d storages.length);\n       }\n     }\n       \n     if (numOfReplicas\u003e0) {\n       String detail \u003d enableDebugLogging;\n       if (LOG.isDebugEnabled()) {\n         if (badTarget \u0026\u0026 builder !\u003d null) {\n           detail \u003d builder.append(\"]\").toString();\n           builder.setLength(0);\n         } else detail \u003d \"\";\n       }\n       throw new NotEnoughReplicasException(detail);\n     }\n     \n     return firstChosen;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected DatanodeStorageInfo chooseRandom(int numOfReplicas,\n                            String scope,\n                            Set\u003cNode\u003e excludedNodes,\n                            long blocksize,\n                            int maxNodesPerRack,\n                            List\u003cDatanodeStorageInfo\u003e results,\n                            boolean avoidStaleNodes,\n                            EnumMap\u003cStorageType, Integer\u003e storageTypes)\n                            throws NotEnoughReplicasException {\n      \n    int numOfAvailableNodes \u003d clusterMap.countNumOfAvailableNodes(\n        scope, excludedNodes);\n    StringBuilder builder \u003d null;\n    if (LOG.isDebugEnabled()) {\n      builder \u003d debugLoggingBuilder.get();\n      builder.setLength(0);\n      builder.append(\"[\");\n    }\n    boolean badTarget \u003d false;\n    DatanodeStorageInfo firstChosen \u003d null;\n    while(numOfReplicas \u003e 0 \u0026\u0026 numOfAvailableNodes \u003e 0) {\n      DatanodeDescriptor chosenNode \u003d \n          (DatanodeDescriptor)clusterMap.chooseRandom(scope);\n      if (excludedNodes.add(chosenNode)) { //was not in the excluded list\n        numOfAvailableNodes--;\n\n        final DatanodeStorageInfo[] storages \u003d DFSUtil.shuffle(\n            chosenNode.getStorageInfos());\n        int i \u003d 0;\n        boolean search \u003d true;\n        for (Iterator\u003cMap.Entry\u003cStorageType, Integer\u003e\u003e iter \u003d storageTypes\n            .entrySet().iterator(); search \u0026\u0026 iter.hasNext(); ) {\n          Map.Entry\u003cStorageType, Integer\u003e entry \u003d iter.next();\n          for (i \u003d 0; i \u003c storages.length; i++) {\n            StorageType type \u003d entry.getKey();\n            final int newExcludedNodes \u003d addIfIsGoodTarget(storages[i],\n                excludedNodes, blocksize, maxNodesPerRack, considerLoad, results,\n                avoidStaleNodes, type);\n            if (newExcludedNodes \u003e\u003d 0) {\n              numOfReplicas--;\n              if (firstChosen \u003d\u003d null) {\n                firstChosen \u003d storages[i];\n              }\n              numOfAvailableNodes -\u003d newExcludedNodes;\n              int num \u003d entry.getValue();\n              if (num \u003d\u003d 1) {\n                iter.remove();\n              } else {\n                entry.setValue(num - 1);\n              }\n              search \u003d false;\n              break;\n            }\n          }\n        }\n\n        // If no candidate storage was found on this DN then set badTarget.\n        badTarget \u003d (i \u003d\u003d storages.length);\n      }\n    }\n      \n    if (numOfReplicas\u003e0) {\n      String detail \u003d enableDebugLogging;\n      if (LOG.isDebugEnabled()) {\n        if (badTarget \u0026\u0026 builder !\u003d null) {\n          detail \u003d builder.append(\"]\").toString();\n          builder.setLength(0);\n        } else detail \u003d \"\";\n      }\n      throw new NotEnoughReplicasException(detail);\n    }\n    \n    return firstChosen;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
          "extendedDetails": {
            "oldValue": "[numOfReplicas-int, scope-String, excludedNodes-Set\u003cNode\u003e, blocksize-long, maxNodesPerRack-int, results-List\u003cDatanodeStorageInfo\u003e, avoidStaleNodes-boolean, storageType-StorageType]",
            "newValue": "[numOfReplicas-int, scope-String, excludedNodes-Set\u003cNode\u003e, blocksize-long, maxNodesPerRack-int, results-List\u003cDatanodeStorageInfo\u003e, avoidStaleNodes-boolean, storageTypes-EnumMap\u003cStorageType,Integer\u003e]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-6961. Archival Storage: BlockPlacementPolicy#chooseTarget should check each valid storage type in each choosing round.\n",
          "commitDate": "04/09/14 2:19 PM",
          "commitName": "e08701ec71f7c10d8f15122d90c35f9f22e40837",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "27/08/14 2:08 PM",
          "commitNameOld": "b7ded466b00db0fe273058b844d56d810e0f8cc2",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 8.01,
          "commitsBetweenForRepo": 50,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,61 +1,74 @@\n   protected DatanodeStorageInfo chooseRandom(int numOfReplicas,\n                             String scope,\n                             Set\u003cNode\u003e excludedNodes,\n                             long blocksize,\n                             int maxNodesPerRack,\n                             List\u003cDatanodeStorageInfo\u003e results,\n                             boolean avoidStaleNodes,\n-                            StorageType storageType)\n-                                throws NotEnoughReplicasException {\n+                            EnumMap\u003cStorageType, Integer\u003e storageTypes)\n+                            throws NotEnoughReplicasException {\n       \n     int numOfAvailableNodes \u003d clusterMap.countNumOfAvailableNodes(\n         scope, excludedNodes);\n     StringBuilder builder \u003d null;\n     if (LOG.isDebugEnabled()) {\n       builder \u003d debugLoggingBuilder.get();\n       builder.setLength(0);\n       builder.append(\"[\");\n     }\n     boolean badTarget \u003d false;\n     DatanodeStorageInfo firstChosen \u003d null;\n     while(numOfReplicas \u003e 0 \u0026\u0026 numOfAvailableNodes \u003e 0) {\n       DatanodeDescriptor chosenNode \u003d \n           (DatanodeDescriptor)clusterMap.chooseRandom(scope);\n       if (excludedNodes.add(chosenNode)) { //was not in the excluded list\n         numOfAvailableNodes--;\n \n         final DatanodeStorageInfo[] storages \u003d DFSUtil.shuffle(\n             chosenNode.getStorageInfos());\n-        int i;\n-        for(i \u003d 0; i \u003c storages.length; i++) {\n-          final int newExcludedNodes \u003d addIfIsGoodTarget(storages[i],\n-              excludedNodes, blocksize, maxNodesPerRack, considerLoad, results,\n-              avoidStaleNodes, storageType);\n-          if (newExcludedNodes \u003e\u003d 0) {\n-            numOfReplicas--;\n-            if (firstChosen \u003d\u003d null) {\n-              firstChosen \u003d storages[i];\n+        int i \u003d 0;\n+        boolean search \u003d true;\n+        for (Iterator\u003cMap.Entry\u003cStorageType, Integer\u003e\u003e iter \u003d storageTypes\n+            .entrySet().iterator(); search \u0026\u0026 iter.hasNext(); ) {\n+          Map.Entry\u003cStorageType, Integer\u003e entry \u003d iter.next();\n+          for (i \u003d 0; i \u003c storages.length; i++) {\n+            StorageType type \u003d entry.getKey();\n+            final int newExcludedNodes \u003d addIfIsGoodTarget(storages[i],\n+                excludedNodes, blocksize, maxNodesPerRack, considerLoad, results,\n+                avoidStaleNodes, type);\n+            if (newExcludedNodes \u003e\u003d 0) {\n+              numOfReplicas--;\n+              if (firstChosen \u003d\u003d null) {\n+                firstChosen \u003d storages[i];\n+              }\n+              numOfAvailableNodes -\u003d newExcludedNodes;\n+              int num \u003d entry.getValue();\n+              if (num \u003d\u003d 1) {\n+                iter.remove();\n+              } else {\n+                entry.setValue(num - 1);\n+              }\n+              search \u003d false;\n+              break;\n             }\n-            numOfAvailableNodes -\u003d newExcludedNodes;\n-            break;\n           }\n         }\n \n         // If no candidate storage was found on this DN then set badTarget.\n         badTarget \u003d (i \u003d\u003d storages.length);\n       }\n     }\n       \n     if (numOfReplicas\u003e0) {\n       String detail \u003d enableDebugLogging;\n       if (LOG.isDebugEnabled()) {\n         if (badTarget \u0026\u0026 builder !\u003d null) {\n           detail \u003d builder.append(\"]\").toString();\n           builder.setLength(0);\n         } else detail \u003d \"\";\n       }\n       throw new NotEnoughReplicasException(detail);\n     }\n     \n     return firstChosen;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected DatanodeStorageInfo chooseRandom(int numOfReplicas,\n                            String scope,\n                            Set\u003cNode\u003e excludedNodes,\n                            long blocksize,\n                            int maxNodesPerRack,\n                            List\u003cDatanodeStorageInfo\u003e results,\n                            boolean avoidStaleNodes,\n                            EnumMap\u003cStorageType, Integer\u003e storageTypes)\n                            throws NotEnoughReplicasException {\n      \n    int numOfAvailableNodes \u003d clusterMap.countNumOfAvailableNodes(\n        scope, excludedNodes);\n    StringBuilder builder \u003d null;\n    if (LOG.isDebugEnabled()) {\n      builder \u003d debugLoggingBuilder.get();\n      builder.setLength(0);\n      builder.append(\"[\");\n    }\n    boolean badTarget \u003d false;\n    DatanodeStorageInfo firstChosen \u003d null;\n    while(numOfReplicas \u003e 0 \u0026\u0026 numOfAvailableNodes \u003e 0) {\n      DatanodeDescriptor chosenNode \u003d \n          (DatanodeDescriptor)clusterMap.chooseRandom(scope);\n      if (excludedNodes.add(chosenNode)) { //was not in the excluded list\n        numOfAvailableNodes--;\n\n        final DatanodeStorageInfo[] storages \u003d DFSUtil.shuffle(\n            chosenNode.getStorageInfos());\n        int i \u003d 0;\n        boolean search \u003d true;\n        for (Iterator\u003cMap.Entry\u003cStorageType, Integer\u003e\u003e iter \u003d storageTypes\n            .entrySet().iterator(); search \u0026\u0026 iter.hasNext(); ) {\n          Map.Entry\u003cStorageType, Integer\u003e entry \u003d iter.next();\n          for (i \u003d 0; i \u003c storages.length; i++) {\n            StorageType type \u003d entry.getKey();\n            final int newExcludedNodes \u003d addIfIsGoodTarget(storages[i],\n                excludedNodes, blocksize, maxNodesPerRack, considerLoad, results,\n                avoidStaleNodes, type);\n            if (newExcludedNodes \u003e\u003d 0) {\n              numOfReplicas--;\n              if (firstChosen \u003d\u003d null) {\n                firstChosen \u003d storages[i];\n              }\n              numOfAvailableNodes -\u003d newExcludedNodes;\n              int num \u003d entry.getValue();\n              if (num \u003d\u003d 1) {\n                iter.remove();\n              } else {\n                entry.setValue(num - 1);\n              }\n              search \u003d false;\n              break;\n            }\n          }\n        }\n\n        // If no candidate storage was found on this DN then set badTarget.\n        badTarget \u003d (i \u003d\u003d storages.length);\n      }\n    }\n      \n    if (numOfReplicas\u003e0) {\n      String detail \u003d enableDebugLogging;\n      if (LOG.isDebugEnabled()) {\n        if (badTarget \u0026\u0026 builder !\u003d null) {\n          detail \u003d builder.append(\"]\").toString();\n          builder.setLength(0);\n        } else detail \u003d \"\";\n      }\n      throw new NotEnoughReplicasException(detail);\n    }\n    \n    return firstChosen;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
          "extendedDetails": {}
        }
      ]
    },
    "fa5ba6d977520f1faaa97c55a50a22c98b3ee109": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5439. Fix TestPendingReplication. (Contributed by Junping Du, Arpit Agarwal)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2832@1539247 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "05/11/13 10:50 PM",
      "commitName": "fa5ba6d977520f1faaa97c55a50a22c98b3ee109",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "03/11/13 9:49 AM",
      "commitNameOld": "26a1fda51e325377734c90399850ff3aa44b5bc1",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 2.54,
      "commitsBetweenForRepo": 13,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,57 +1,61 @@\n   protected DatanodeStorageInfo chooseRandom(int numOfReplicas,\n                             String scope,\n                             Set\u003cNode\u003e excludedNodes,\n                             long blocksize,\n                             int maxNodesPerRack,\n                             List\u003cDatanodeStorageInfo\u003e results,\n                             boolean avoidStaleNodes,\n                             StorageType storageType)\n                                 throws NotEnoughReplicasException {\n       \n     int numOfAvailableNodes \u003d clusterMap.countNumOfAvailableNodes(\n         scope, excludedNodes);\n     StringBuilder builder \u003d null;\n     if (LOG.isDebugEnabled()) {\n       builder \u003d debugLoggingBuilder.get();\n       builder.setLength(0);\n       builder.append(\"[\");\n     }\n-    boolean goodTarget \u003d false;\n+    boolean badTarget \u003d false;\n     DatanodeStorageInfo firstChosen \u003d null;\n     while(numOfReplicas \u003e 0 \u0026\u0026 numOfAvailableNodes \u003e 0) {\n       DatanodeDescriptor chosenNode \u003d \n           (DatanodeDescriptor)clusterMap.chooseRandom(scope);\n       if (excludedNodes.add(chosenNode)) { //was not in the excluded list\n         numOfAvailableNodes--;\n \n         final DatanodeStorageInfo[] storages \u003d DFSUtil.shuffle(\n             chosenNode.getStorageInfos());\n-        for(int i \u003d 0; i \u003c storages.length \u0026\u0026 !goodTarget; i++) {\n+        int i;\n+        for(i \u003d 0; i \u003c storages.length; i++) {\n           final int newExcludedNodes \u003d addIfIsGoodTarget(storages[i],\n               excludedNodes, blocksize, maxNodesPerRack, considerLoad, results,\n               avoidStaleNodes, storageType);\n-          goodTarget \u003d newExcludedNodes \u003e\u003d 0;\n-          if (goodTarget) {\n+          if (newExcludedNodes \u003e\u003d 0) {\n             numOfReplicas--;\n             if (firstChosen \u003d\u003d null) {\n               firstChosen \u003d storages[i];\n             }\n             numOfAvailableNodes -\u003d newExcludedNodes;\n+            break;\n           }\n         }\n+\n+        // If no candidate storage was found on this DN then set badTarget.\n+        badTarget \u003d (i \u003d\u003d storages.length);\n       }\n     }\n       \n     if (numOfReplicas\u003e0) {\n       String detail \u003d enableDebugLogging;\n       if (LOG.isDebugEnabled()) {\n-        if (!goodTarget \u0026\u0026 builder !\u003d null) {\n+        if (badTarget \u0026\u0026 builder !\u003d null) {\n           detail \u003d builder.append(\"]\").toString();\n           builder.setLength(0);\n         } else detail \u003d \"\";\n       }\n       throw new NotEnoughReplicasException(detail);\n     }\n     \n     return firstChosen;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected DatanodeStorageInfo chooseRandom(int numOfReplicas,\n                            String scope,\n                            Set\u003cNode\u003e excludedNodes,\n                            long blocksize,\n                            int maxNodesPerRack,\n                            List\u003cDatanodeStorageInfo\u003e results,\n                            boolean avoidStaleNodes,\n                            StorageType storageType)\n                                throws NotEnoughReplicasException {\n      \n    int numOfAvailableNodes \u003d clusterMap.countNumOfAvailableNodes(\n        scope, excludedNodes);\n    StringBuilder builder \u003d null;\n    if (LOG.isDebugEnabled()) {\n      builder \u003d debugLoggingBuilder.get();\n      builder.setLength(0);\n      builder.append(\"[\");\n    }\n    boolean badTarget \u003d false;\n    DatanodeStorageInfo firstChosen \u003d null;\n    while(numOfReplicas \u003e 0 \u0026\u0026 numOfAvailableNodes \u003e 0) {\n      DatanodeDescriptor chosenNode \u003d \n          (DatanodeDescriptor)clusterMap.chooseRandom(scope);\n      if (excludedNodes.add(chosenNode)) { //was not in the excluded list\n        numOfAvailableNodes--;\n\n        final DatanodeStorageInfo[] storages \u003d DFSUtil.shuffle(\n            chosenNode.getStorageInfos());\n        int i;\n        for(i \u003d 0; i \u003c storages.length; i++) {\n          final int newExcludedNodes \u003d addIfIsGoodTarget(storages[i],\n              excludedNodes, blocksize, maxNodesPerRack, considerLoad, results,\n              avoidStaleNodes, storageType);\n          if (newExcludedNodes \u003e\u003d 0) {\n            numOfReplicas--;\n            if (firstChosen \u003d\u003d null) {\n              firstChosen \u003d storages[i];\n            }\n            numOfAvailableNodes -\u003d newExcludedNodes;\n            break;\n          }\n        }\n\n        // If no candidate storage was found on this DN then set badTarget.\n        badTarget \u003d (i \u003d\u003d storages.length);\n      }\n    }\n      \n    if (numOfReplicas\u003e0) {\n      String detail \u003d enableDebugLogging;\n      if (LOG.isDebugEnabled()) {\n        if (badTarget \u0026\u0026 builder !\u003d null) {\n          detail \u003d builder.append(\"]\").toString();\n          builder.setLength(0);\n        } else detail \u003d \"\";\n      }\n      throw new NotEnoughReplicasException(detail);\n    }\n    \n    return firstChosen;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
      "extendedDetails": {}
    }
  }
}