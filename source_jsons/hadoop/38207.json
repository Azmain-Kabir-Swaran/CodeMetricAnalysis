{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ProportionalCapacityPreemptionPolicy.java",
  "functionName": "preemptOrkillSelectedContainerAfterWait",
  "functionId": "preemptOrkillSelectedContainerAfterWait___toPreemptPerSelector-Map__PreemptionCandidatesSelector,Map__ApplicationAttemptId,Set__RMContainer________currentTime-long",
  "sourceFilePath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/monitor/capacity/ProportionalCapacityPreemptionPolicy.java",
  "functionStartLine": 327,
  "functionEndLine": 383,
  "numCommitsSeen": 120,
  "timeTaken": 4881,
  "changeHistory": [
    "2064ca015d1584263aac0cc20c60b925a3aff612",
    "291194302cc1a875d6d94ea93cf1184a3f1fc2cc",
    "90dd3a8148468ac37a3f2173ad8d45e38bfcb0c9",
    "7cb3a3da96e59fc9b6528644dae5fb0ac1e44eac",
    "60e4116bf1d00afed91010e57357fe54057e4e39"
  ],
  "changeHistoryShort": {
    "2064ca015d1584263aac0cc20c60b925a3aff612": "Ybodychange",
    "291194302cc1a875d6d94ea93cf1184a3f1fc2cc": "Ymultichange(Yparameterchange,Ybodychange)",
    "90dd3a8148468ac37a3f2173ad8d45e38bfcb0c9": "Ybodychange",
    "7cb3a3da96e59fc9b6528644dae5fb0ac1e44eac": "Ymultichange(Yparameterchange,Ybodychange)",
    "60e4116bf1d00afed91010e57357fe54057e4e39": "Yintroduced"
  },
  "changeHistoryDetails": {
    "2064ca015d1584263aac0cc20c60b925a3aff612": {
      "type": "Ybodychange",
      "commitMessage": "YARN-9349.  Changed logging to use slf4j api.\n            Contributed by Prabhu Joseph\n",
      "commitDate": "15/03/19 4:20 PM",
      "commitName": "2064ca015d1584263aac0cc20c60b925a3aff612",
      "commitAuthor": "Eric Yang",
      "commitDateOld": "07/03/19 1:47 PM",
      "commitNameOld": "39b4a37e02e929a698fcf9e32f1f71bb6b977635",
      "commitAuthorOld": "Eric Yang",
      "daysBetweenCommits": 8.06,
      "commitsBetweenForRepo": 69,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,59 +1,57 @@\n   private void preemptOrkillSelectedContainerAfterWait(\n       Map\u003cPreemptionCandidatesSelector, Map\u003cApplicationAttemptId,\n           Set\u003cRMContainer\u003e\u003e\u003e toPreemptPerSelector, long currentTime) {\n     int toPreemptCount \u003d 0;\n     for (Map\u003cApplicationAttemptId, Set\u003cRMContainer\u003e\u003e containers :\n         toPreemptPerSelector.values()) {\n       toPreemptCount +\u003d containers.size();\n     }\n-    if (LOG.isDebugEnabled()) {\n-      LOG.debug(\n-          \"Starting to preempt containers for selectedCandidates and size:\"\n-              + toPreemptCount);\n-    }\n+    LOG.debug(\n+        \"Starting to preempt containers for selectedCandidates and size:{}\",\n+        toPreemptCount);\n \n     // preempt (or kill) the selected containers\n     // We need toPreemptPerSelector here to match list of containers to\n     // its selector so that we can get custom timeout per selector when\n     // checking if current container should be killed or not\n     for (Map.Entry\u003cPreemptionCandidatesSelector, Map\u003cApplicationAttemptId,\n         Set\u003cRMContainer\u003e\u003e\u003e pc : toPreemptPerSelector\n         .entrySet()) {\n       Map\u003cApplicationAttemptId, Set\u003cRMContainer\u003e\u003e cMap \u003d pc.getValue();\n       if (cMap.size() \u003e 0) {\n         for (Map.Entry\u003cApplicationAttemptId,\n             Set\u003cRMContainer\u003e\u003e e : cMap.entrySet()) {\n           ApplicationAttemptId appAttemptId \u003d e.getKey();\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"Send to scheduler: in app\u003d\" + appAttemptId\n                 + \" #containers-to-be-preemptionCandidates\u003d\" + e.getValue().size());\n           }\n           for (RMContainer container : e.getValue()) {\n             // if we tried to preempt this for more than maxWaitTime, this\n             // should be based on custom timeout per container per selector\n             if (preemptionCandidates.get(container) !\u003d null\n                 \u0026\u0026 preemptionCandidates.get(container)\n                 + pc.getKey().getMaximumKillWaitTimeMs() \u003c\u003d currentTime) {\n               // kill it\n               rmContext.getDispatcher().getEventHandler().handle(\n                   new ContainerPreemptEvent(appAttemptId, container,\n                       SchedulerEventType.MARK_CONTAINER_FOR_KILLABLE));\n               preemptionCandidates.remove(container);\n             } else {\n               if (preemptionCandidates.get(container) !\u003d null) {\n                 // We already updated the information to scheduler earlier, we need\n                 // not have to raise another event.\n                 continue;\n               }\n \n               //otherwise just send preemption events\n               rmContext.getDispatcher().getEventHandler().handle(\n                   new ContainerPreemptEvent(appAttemptId, container,\n                       SchedulerEventType.MARK_CONTAINER_FOR_PREEMPTION));\n               preemptionCandidates.put(container, currentTime);\n             }\n           }\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void preemptOrkillSelectedContainerAfterWait(\n      Map\u003cPreemptionCandidatesSelector, Map\u003cApplicationAttemptId,\n          Set\u003cRMContainer\u003e\u003e\u003e toPreemptPerSelector, long currentTime) {\n    int toPreemptCount \u003d 0;\n    for (Map\u003cApplicationAttemptId, Set\u003cRMContainer\u003e\u003e containers :\n        toPreemptPerSelector.values()) {\n      toPreemptCount +\u003d containers.size();\n    }\n    LOG.debug(\n        \"Starting to preempt containers for selectedCandidates and size:{}\",\n        toPreemptCount);\n\n    // preempt (or kill) the selected containers\n    // We need toPreemptPerSelector here to match list of containers to\n    // its selector so that we can get custom timeout per selector when\n    // checking if current container should be killed or not\n    for (Map.Entry\u003cPreemptionCandidatesSelector, Map\u003cApplicationAttemptId,\n        Set\u003cRMContainer\u003e\u003e\u003e pc : toPreemptPerSelector\n        .entrySet()) {\n      Map\u003cApplicationAttemptId, Set\u003cRMContainer\u003e\u003e cMap \u003d pc.getValue();\n      if (cMap.size() \u003e 0) {\n        for (Map.Entry\u003cApplicationAttemptId,\n            Set\u003cRMContainer\u003e\u003e e : cMap.entrySet()) {\n          ApplicationAttemptId appAttemptId \u003d e.getKey();\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Send to scheduler: in app\u003d\" + appAttemptId\n                + \" #containers-to-be-preemptionCandidates\u003d\" + e.getValue().size());\n          }\n          for (RMContainer container : e.getValue()) {\n            // if we tried to preempt this for more than maxWaitTime, this\n            // should be based on custom timeout per container per selector\n            if (preemptionCandidates.get(container) !\u003d null\n                \u0026\u0026 preemptionCandidates.get(container)\n                + pc.getKey().getMaximumKillWaitTimeMs() \u003c\u003d currentTime) {\n              // kill it\n              rmContext.getDispatcher().getEventHandler().handle(\n                  new ContainerPreemptEvent(appAttemptId, container,\n                      SchedulerEventType.MARK_CONTAINER_FOR_KILLABLE));\n              preemptionCandidates.remove(container);\n            } else {\n              if (preemptionCandidates.get(container) !\u003d null) {\n                // We already updated the information to scheduler earlier, we need\n                // not have to raise another event.\n                continue;\n              }\n\n              //otherwise just send preemption events\n              rmContext.getDispatcher().getEventHandler().handle(\n                  new ContainerPreemptEvent(appAttemptId, container,\n                      SchedulerEventType.MARK_CONTAINER_FOR_PREEMPTION));\n              preemptionCandidates.put(container, currentTime);\n            }\n          }\n        }\n      }\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/monitor/capacity/ProportionalCapacityPreemptionPolicy.java",
      "extendedDetails": {}
    },
    "291194302cc1a875d6d94ea93cf1184a3f1fc2cc": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "YARN-8379. Improve balancing resources in already satisfied queues by using Capacity Scheduler preemption. Contributed by Zian Chen.\n",
      "commitDate": "28/06/18 10:23 AM",
      "commitName": "291194302cc1a875d6d94ea93cf1184a3f1fc2cc",
      "commitAuthor": "Sunil G",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "YARN-8379. Improve balancing resources in already satisfied queues by using Capacity Scheduler preemption. Contributed by Zian Chen.\n",
          "commitDate": "28/06/18 10:23 AM",
          "commitName": "291194302cc1a875d6d94ea93cf1184a3f1fc2cc",
          "commitAuthor": "Sunil G",
          "commitDateOld": "12/06/18 8:35 AM",
          "commitNameOld": "652bcbb3e4950758e61ce123ecc1798ae2b60a7f",
          "commitAuthorOld": "Akira Ajisaka",
          "daysBetweenCommits": 16.07,
          "commitsBetweenForRepo": 93,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,43 +1,59 @@\n   private void preemptOrkillSelectedContainerAfterWait(\n-      Map\u003cApplicationAttemptId, Set\u003cRMContainer\u003e\u003e selectedCandidates,\n-      long currentTime) {\n+      Map\u003cPreemptionCandidatesSelector, Map\u003cApplicationAttemptId,\n+          Set\u003cRMContainer\u003e\u003e\u003e toPreemptPerSelector, long currentTime) {\n+    int toPreemptCount \u003d 0;\n+    for (Map\u003cApplicationAttemptId, Set\u003cRMContainer\u003e\u003e containers :\n+        toPreemptPerSelector.values()) {\n+      toPreemptCount +\u003d containers.size();\n+    }\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\n           \"Starting to preempt containers for selectedCandidates and size:\"\n-              + selectedCandidates.size());\n+              + toPreemptCount);\n     }\n \n     // preempt (or kill) the selected containers\n-    for (Map.Entry\u003cApplicationAttemptId, Set\u003cRMContainer\u003e\u003e e : selectedCandidates\n+    // We need toPreemptPerSelector here to match list of containers to\n+    // its selector so that we can get custom timeout per selector when\n+    // checking if current container should be killed or not\n+    for (Map.Entry\u003cPreemptionCandidatesSelector, Map\u003cApplicationAttemptId,\n+        Set\u003cRMContainer\u003e\u003e\u003e pc : toPreemptPerSelector\n         .entrySet()) {\n-      ApplicationAttemptId appAttemptId \u003d e.getKey();\n-      if (LOG.isDebugEnabled()) {\n-        LOG.debug(\"Send to scheduler: in app\u003d\" + appAttemptId\n-            + \" #containers-to-be-preemptionCandidates\u003d\" + e.getValue().size());\n-      }\n-      for (RMContainer container : e.getValue()) {\n-        // if we tried to preempt this for more than maxWaitTime\n-        if (preemptionCandidates.get(container) !\u003d null\n-            \u0026\u0026 preemptionCandidates.get(container)\n-                + maxWaitTime \u003c\u003d currentTime) {\n-          // kill it\n-          rmContext.getDispatcher().getEventHandler().handle(\n-              new ContainerPreemptEvent(appAttemptId, container,\n-                  SchedulerEventType.MARK_CONTAINER_FOR_KILLABLE));\n-          preemptionCandidates.remove(container);\n-        } else {\n-          if (preemptionCandidates.get(container) !\u003d null) {\n-            // We already updated the information to scheduler earlier, we need\n-            // not have to raise another event.\n-            continue;\n+      Map\u003cApplicationAttemptId, Set\u003cRMContainer\u003e\u003e cMap \u003d pc.getValue();\n+      if (cMap.size() \u003e 0) {\n+        for (Map.Entry\u003cApplicationAttemptId,\n+            Set\u003cRMContainer\u003e\u003e e : cMap.entrySet()) {\n+          ApplicationAttemptId appAttemptId \u003d e.getKey();\n+          if (LOG.isDebugEnabled()) {\n+            LOG.debug(\"Send to scheduler: in app\u003d\" + appAttemptId\n+                + \" #containers-to-be-preemptionCandidates\u003d\" + e.getValue().size());\n           }\n+          for (RMContainer container : e.getValue()) {\n+            // if we tried to preempt this for more than maxWaitTime, this\n+            // should be based on custom timeout per container per selector\n+            if (preemptionCandidates.get(container) !\u003d null\n+                \u0026\u0026 preemptionCandidates.get(container)\n+                + pc.getKey().getMaximumKillWaitTimeMs() \u003c\u003d currentTime) {\n+              // kill it\n+              rmContext.getDispatcher().getEventHandler().handle(\n+                  new ContainerPreemptEvent(appAttemptId, container,\n+                      SchedulerEventType.MARK_CONTAINER_FOR_KILLABLE));\n+              preemptionCandidates.remove(container);\n+            } else {\n+              if (preemptionCandidates.get(container) !\u003d null) {\n+                // We already updated the information to scheduler earlier, we need\n+                // not have to raise another event.\n+                continue;\n+              }\n \n-          //otherwise just send preemption events\n-          rmContext.getDispatcher().getEventHandler().handle(\n-              new ContainerPreemptEvent(appAttemptId, container,\n-                  SchedulerEventType.MARK_CONTAINER_FOR_PREEMPTION));\n-          preemptionCandidates.put(container, currentTime);\n+              //otherwise just send preemption events\n+              rmContext.getDispatcher().getEventHandler().handle(\n+                  new ContainerPreemptEvent(appAttemptId, container,\n+                      SchedulerEventType.MARK_CONTAINER_FOR_PREEMPTION));\n+              preemptionCandidates.put(container, currentTime);\n+            }\n+          }\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void preemptOrkillSelectedContainerAfterWait(\n      Map\u003cPreemptionCandidatesSelector, Map\u003cApplicationAttemptId,\n          Set\u003cRMContainer\u003e\u003e\u003e toPreemptPerSelector, long currentTime) {\n    int toPreemptCount \u003d 0;\n    for (Map\u003cApplicationAttemptId, Set\u003cRMContainer\u003e\u003e containers :\n        toPreemptPerSelector.values()) {\n      toPreemptCount +\u003d containers.size();\n    }\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\n          \"Starting to preempt containers for selectedCandidates and size:\"\n              + toPreemptCount);\n    }\n\n    // preempt (or kill) the selected containers\n    // We need toPreemptPerSelector here to match list of containers to\n    // its selector so that we can get custom timeout per selector when\n    // checking if current container should be killed or not\n    for (Map.Entry\u003cPreemptionCandidatesSelector, Map\u003cApplicationAttemptId,\n        Set\u003cRMContainer\u003e\u003e\u003e pc : toPreemptPerSelector\n        .entrySet()) {\n      Map\u003cApplicationAttemptId, Set\u003cRMContainer\u003e\u003e cMap \u003d pc.getValue();\n      if (cMap.size() \u003e 0) {\n        for (Map.Entry\u003cApplicationAttemptId,\n            Set\u003cRMContainer\u003e\u003e e : cMap.entrySet()) {\n          ApplicationAttemptId appAttemptId \u003d e.getKey();\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Send to scheduler: in app\u003d\" + appAttemptId\n                + \" #containers-to-be-preemptionCandidates\u003d\" + e.getValue().size());\n          }\n          for (RMContainer container : e.getValue()) {\n            // if we tried to preempt this for more than maxWaitTime, this\n            // should be based on custom timeout per container per selector\n            if (preemptionCandidates.get(container) !\u003d null\n                \u0026\u0026 preemptionCandidates.get(container)\n                + pc.getKey().getMaximumKillWaitTimeMs() \u003c\u003d currentTime) {\n              // kill it\n              rmContext.getDispatcher().getEventHandler().handle(\n                  new ContainerPreemptEvent(appAttemptId, container,\n                      SchedulerEventType.MARK_CONTAINER_FOR_KILLABLE));\n              preemptionCandidates.remove(container);\n            } else {\n              if (preemptionCandidates.get(container) !\u003d null) {\n                // We already updated the information to scheduler earlier, we need\n                // not have to raise another event.\n                continue;\n              }\n\n              //otherwise just send preemption events\n              rmContext.getDispatcher().getEventHandler().handle(\n                  new ContainerPreemptEvent(appAttemptId, container,\n                      SchedulerEventType.MARK_CONTAINER_FOR_PREEMPTION));\n              preemptionCandidates.put(container, currentTime);\n            }\n          }\n        }\n      }\n    }\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/monitor/capacity/ProportionalCapacityPreemptionPolicy.java",
          "extendedDetails": {
            "oldValue": "[selectedCandidates-Map\u003cApplicationAttemptId,Set\u003cRMContainer\u003e\u003e, currentTime-long]",
            "newValue": "[toPreemptPerSelector-Map\u003cPreemptionCandidatesSelector,Map\u003cApplicationAttemptId,Set\u003cRMContainer\u003e\u003e\u003e, currentTime-long]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-8379. Improve balancing resources in already satisfied queues by using Capacity Scheduler preemption. Contributed by Zian Chen.\n",
          "commitDate": "28/06/18 10:23 AM",
          "commitName": "291194302cc1a875d6d94ea93cf1184a3f1fc2cc",
          "commitAuthor": "Sunil G",
          "commitDateOld": "12/06/18 8:35 AM",
          "commitNameOld": "652bcbb3e4950758e61ce123ecc1798ae2b60a7f",
          "commitAuthorOld": "Akira Ajisaka",
          "daysBetweenCommits": 16.07,
          "commitsBetweenForRepo": 93,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,43 +1,59 @@\n   private void preemptOrkillSelectedContainerAfterWait(\n-      Map\u003cApplicationAttemptId, Set\u003cRMContainer\u003e\u003e selectedCandidates,\n-      long currentTime) {\n+      Map\u003cPreemptionCandidatesSelector, Map\u003cApplicationAttemptId,\n+          Set\u003cRMContainer\u003e\u003e\u003e toPreemptPerSelector, long currentTime) {\n+    int toPreemptCount \u003d 0;\n+    for (Map\u003cApplicationAttemptId, Set\u003cRMContainer\u003e\u003e containers :\n+        toPreemptPerSelector.values()) {\n+      toPreemptCount +\u003d containers.size();\n+    }\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\n           \"Starting to preempt containers for selectedCandidates and size:\"\n-              + selectedCandidates.size());\n+              + toPreemptCount);\n     }\n \n     // preempt (or kill) the selected containers\n-    for (Map.Entry\u003cApplicationAttemptId, Set\u003cRMContainer\u003e\u003e e : selectedCandidates\n+    // We need toPreemptPerSelector here to match list of containers to\n+    // its selector so that we can get custom timeout per selector when\n+    // checking if current container should be killed or not\n+    for (Map.Entry\u003cPreemptionCandidatesSelector, Map\u003cApplicationAttemptId,\n+        Set\u003cRMContainer\u003e\u003e\u003e pc : toPreemptPerSelector\n         .entrySet()) {\n-      ApplicationAttemptId appAttemptId \u003d e.getKey();\n-      if (LOG.isDebugEnabled()) {\n-        LOG.debug(\"Send to scheduler: in app\u003d\" + appAttemptId\n-            + \" #containers-to-be-preemptionCandidates\u003d\" + e.getValue().size());\n-      }\n-      for (RMContainer container : e.getValue()) {\n-        // if we tried to preempt this for more than maxWaitTime\n-        if (preemptionCandidates.get(container) !\u003d null\n-            \u0026\u0026 preemptionCandidates.get(container)\n-                + maxWaitTime \u003c\u003d currentTime) {\n-          // kill it\n-          rmContext.getDispatcher().getEventHandler().handle(\n-              new ContainerPreemptEvent(appAttemptId, container,\n-                  SchedulerEventType.MARK_CONTAINER_FOR_KILLABLE));\n-          preemptionCandidates.remove(container);\n-        } else {\n-          if (preemptionCandidates.get(container) !\u003d null) {\n-            // We already updated the information to scheduler earlier, we need\n-            // not have to raise another event.\n-            continue;\n+      Map\u003cApplicationAttemptId, Set\u003cRMContainer\u003e\u003e cMap \u003d pc.getValue();\n+      if (cMap.size() \u003e 0) {\n+        for (Map.Entry\u003cApplicationAttemptId,\n+            Set\u003cRMContainer\u003e\u003e e : cMap.entrySet()) {\n+          ApplicationAttemptId appAttemptId \u003d e.getKey();\n+          if (LOG.isDebugEnabled()) {\n+            LOG.debug(\"Send to scheduler: in app\u003d\" + appAttemptId\n+                + \" #containers-to-be-preemptionCandidates\u003d\" + e.getValue().size());\n           }\n+          for (RMContainer container : e.getValue()) {\n+            // if we tried to preempt this for more than maxWaitTime, this\n+            // should be based on custom timeout per container per selector\n+            if (preemptionCandidates.get(container) !\u003d null\n+                \u0026\u0026 preemptionCandidates.get(container)\n+                + pc.getKey().getMaximumKillWaitTimeMs() \u003c\u003d currentTime) {\n+              // kill it\n+              rmContext.getDispatcher().getEventHandler().handle(\n+                  new ContainerPreemptEvent(appAttemptId, container,\n+                      SchedulerEventType.MARK_CONTAINER_FOR_KILLABLE));\n+              preemptionCandidates.remove(container);\n+            } else {\n+              if (preemptionCandidates.get(container) !\u003d null) {\n+                // We already updated the information to scheduler earlier, we need\n+                // not have to raise another event.\n+                continue;\n+              }\n \n-          //otherwise just send preemption events\n-          rmContext.getDispatcher().getEventHandler().handle(\n-              new ContainerPreemptEvent(appAttemptId, container,\n-                  SchedulerEventType.MARK_CONTAINER_FOR_PREEMPTION));\n-          preemptionCandidates.put(container, currentTime);\n+              //otherwise just send preemption events\n+              rmContext.getDispatcher().getEventHandler().handle(\n+                  new ContainerPreemptEvent(appAttemptId, container,\n+                      SchedulerEventType.MARK_CONTAINER_FOR_PREEMPTION));\n+              preemptionCandidates.put(container, currentTime);\n+            }\n+          }\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void preemptOrkillSelectedContainerAfterWait(\n      Map\u003cPreemptionCandidatesSelector, Map\u003cApplicationAttemptId,\n          Set\u003cRMContainer\u003e\u003e\u003e toPreemptPerSelector, long currentTime) {\n    int toPreemptCount \u003d 0;\n    for (Map\u003cApplicationAttemptId, Set\u003cRMContainer\u003e\u003e containers :\n        toPreemptPerSelector.values()) {\n      toPreemptCount +\u003d containers.size();\n    }\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\n          \"Starting to preempt containers for selectedCandidates and size:\"\n              + toPreemptCount);\n    }\n\n    // preempt (or kill) the selected containers\n    // We need toPreemptPerSelector here to match list of containers to\n    // its selector so that we can get custom timeout per selector when\n    // checking if current container should be killed or not\n    for (Map.Entry\u003cPreemptionCandidatesSelector, Map\u003cApplicationAttemptId,\n        Set\u003cRMContainer\u003e\u003e\u003e pc : toPreemptPerSelector\n        .entrySet()) {\n      Map\u003cApplicationAttemptId, Set\u003cRMContainer\u003e\u003e cMap \u003d pc.getValue();\n      if (cMap.size() \u003e 0) {\n        for (Map.Entry\u003cApplicationAttemptId,\n            Set\u003cRMContainer\u003e\u003e e : cMap.entrySet()) {\n          ApplicationAttemptId appAttemptId \u003d e.getKey();\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Send to scheduler: in app\u003d\" + appAttemptId\n                + \" #containers-to-be-preemptionCandidates\u003d\" + e.getValue().size());\n          }\n          for (RMContainer container : e.getValue()) {\n            // if we tried to preempt this for more than maxWaitTime, this\n            // should be based on custom timeout per container per selector\n            if (preemptionCandidates.get(container) !\u003d null\n                \u0026\u0026 preemptionCandidates.get(container)\n                + pc.getKey().getMaximumKillWaitTimeMs() \u003c\u003d currentTime) {\n              // kill it\n              rmContext.getDispatcher().getEventHandler().handle(\n                  new ContainerPreemptEvent(appAttemptId, container,\n                      SchedulerEventType.MARK_CONTAINER_FOR_KILLABLE));\n              preemptionCandidates.remove(container);\n            } else {\n              if (preemptionCandidates.get(container) !\u003d null) {\n                // We already updated the information to scheduler earlier, we need\n                // not have to raise another event.\n                continue;\n              }\n\n              //otherwise just send preemption events\n              rmContext.getDispatcher().getEventHandler().handle(\n                  new ContainerPreemptEvent(appAttemptId, container,\n                      SchedulerEventType.MARK_CONTAINER_FOR_PREEMPTION));\n              preemptionCandidates.put(container, currentTime);\n            }\n          }\n        }\n      }\n    }\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/monitor/capacity/ProportionalCapacityPreemptionPolicy.java",
          "extendedDetails": {}
        }
      ]
    },
    "90dd3a8148468ac37a3f2173ad8d45e38bfcb0c9": {
      "type": "Ybodychange",
      "commitMessage": "YARN-2009. CapacityScheduler: Add intra-queue preemption for app priority support. (Sunil G via wangda)\n",
      "commitDate": "31/10/16 3:18 PM",
      "commitName": "90dd3a8148468ac37a3f2173ad8d45e38bfcb0c9",
      "commitAuthor": "Wangda Tan",
      "commitDateOld": "05/05/16 12:56 PM",
      "commitNameOld": "bb62e0592566b2fcae7136b30972aad2d3ac55b0",
      "commitAuthorOld": "Jian He",
      "daysBetweenCommits": 179.1,
      "commitsBetweenForRepo": 1369,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,36 +1,43 @@\n   private void preemptOrkillSelectedContainerAfterWait(\n       Map\u003cApplicationAttemptId, Set\u003cRMContainer\u003e\u003e selectedCandidates,\n       long currentTime) {\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\n+          \"Starting to preempt containers for selectedCandidates and size:\"\n+              + selectedCandidates.size());\n+    }\n+\n     // preempt (or kill) the selected containers\n     for (Map.Entry\u003cApplicationAttemptId, Set\u003cRMContainer\u003e\u003e e : selectedCandidates\n         .entrySet()) {\n       ApplicationAttemptId appAttemptId \u003d e.getKey();\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Send to scheduler: in app\u003d\" + appAttemptId\n             + \" #containers-to-be-preemptionCandidates\u003d\" + e.getValue().size());\n       }\n       for (RMContainer container : e.getValue()) {\n         // if we tried to preempt this for more than maxWaitTime\n         if (preemptionCandidates.get(container) !\u003d null\n             \u0026\u0026 preemptionCandidates.get(container)\n                 + maxWaitTime \u003c\u003d currentTime) {\n           // kill it\n           rmContext.getDispatcher().getEventHandler().handle(\n               new ContainerPreemptEvent(appAttemptId, container,\n                   SchedulerEventType.MARK_CONTAINER_FOR_KILLABLE));\n           preemptionCandidates.remove(container);\n         } else {\n           if (preemptionCandidates.get(container) !\u003d null) {\n             // We already updated the information to scheduler earlier, we need\n             // not have to raise another event.\n             continue;\n           }\n+\n           //otherwise just send preemption events\n           rmContext.getDispatcher().getEventHandler().handle(\n               new ContainerPreemptEvent(appAttemptId, container,\n                   SchedulerEventType.MARK_CONTAINER_FOR_PREEMPTION));\n           preemptionCandidates.put(container, currentTime);\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void preemptOrkillSelectedContainerAfterWait(\n      Map\u003cApplicationAttemptId, Set\u003cRMContainer\u003e\u003e selectedCandidates,\n      long currentTime) {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\n          \"Starting to preempt containers for selectedCandidates and size:\"\n              + selectedCandidates.size());\n    }\n\n    // preempt (or kill) the selected containers\n    for (Map.Entry\u003cApplicationAttemptId, Set\u003cRMContainer\u003e\u003e e : selectedCandidates\n        .entrySet()) {\n      ApplicationAttemptId appAttemptId \u003d e.getKey();\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Send to scheduler: in app\u003d\" + appAttemptId\n            + \" #containers-to-be-preemptionCandidates\u003d\" + e.getValue().size());\n      }\n      for (RMContainer container : e.getValue()) {\n        // if we tried to preempt this for more than maxWaitTime\n        if (preemptionCandidates.get(container) !\u003d null\n            \u0026\u0026 preemptionCandidates.get(container)\n                + maxWaitTime \u003c\u003d currentTime) {\n          // kill it\n          rmContext.getDispatcher().getEventHandler().handle(\n              new ContainerPreemptEvent(appAttemptId, container,\n                  SchedulerEventType.MARK_CONTAINER_FOR_KILLABLE));\n          preemptionCandidates.remove(container);\n        } else {\n          if (preemptionCandidates.get(container) !\u003d null) {\n            // We already updated the information to scheduler earlier, we need\n            // not have to raise another event.\n            continue;\n          }\n\n          //otherwise just send preemption events\n          rmContext.getDispatcher().getEventHandler().handle(\n              new ContainerPreemptEvent(appAttemptId, container,\n                  SchedulerEventType.MARK_CONTAINER_FOR_PREEMPTION));\n          preemptionCandidates.put(container, currentTime);\n        }\n      }\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/monitor/capacity/ProportionalCapacityPreemptionPolicy.java",
      "extendedDetails": {}
    },
    "7cb3a3da96e59fc9b6528644dae5fb0ac1e44eac": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "YARN-4846. Fix random failures for TestCapacitySchedulerPreemption#testPreemptionPolicyShouldRespectAlreadyMarkedKillableContainers. (Bibin A Chundatt via wangda)\n",
      "commitDate": "22/04/16 11:40 AM",
      "commitName": "7cb3a3da96e59fc9b6528644dae5fb0ac1e44eac",
      "commitAuthor": "Wangda Tan",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "YARN-4846. Fix random failures for TestCapacitySchedulerPreemption#testPreemptionPolicyShouldRespectAlreadyMarkedKillableContainers. (Bibin A Chundatt via wangda)\n",
          "commitDate": "22/04/16 11:40 AM",
          "commitName": "7cb3a3da96e59fc9b6528644dae5fb0ac1e44eac",
          "commitAuthor": "Wangda Tan",
          "commitDateOld": "30/03/16 12:43 PM",
          "commitNameOld": "60e4116bf1d00afed91010e57357fe54057e4e39",
          "commitAuthorOld": "Jian He",
          "daysBetweenCommits": 22.96,
          "commitsBetweenForRepo": 153,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,35 +1,36 @@\n   private void preemptOrkillSelectedContainerAfterWait(\n-      Map\u003cApplicationAttemptId, Set\u003cRMContainer\u003e\u003e selectedCandidates) {\n+      Map\u003cApplicationAttemptId, Set\u003cRMContainer\u003e\u003e selectedCandidates,\n+      long currentTime) {\n     // preempt (or kill) the selected containers\n     for (Map.Entry\u003cApplicationAttemptId, Set\u003cRMContainer\u003e\u003e e : selectedCandidates\n         .entrySet()) {\n       ApplicationAttemptId appAttemptId \u003d e.getKey();\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Send to scheduler: in app\u003d\" + appAttemptId\n             + \" #containers-to-be-preemptionCandidates\u003d\" + e.getValue().size());\n       }\n       for (RMContainer container : e.getValue()) {\n         // if we tried to preempt this for more than maxWaitTime\n         if (preemptionCandidates.get(container) !\u003d null\n-            \u0026\u0026 preemptionCandidates.get(container) + maxWaitTime \u003c clock\n-            .getTime()) {\n+            \u0026\u0026 preemptionCandidates.get(container)\n+                + maxWaitTime \u003c\u003d currentTime) {\n           // kill it\n           rmContext.getDispatcher().getEventHandler().handle(\n               new ContainerPreemptEvent(appAttemptId, container,\n                   SchedulerEventType.MARK_CONTAINER_FOR_KILLABLE));\n           preemptionCandidates.remove(container);\n         } else {\n           if (preemptionCandidates.get(container) !\u003d null) {\n             // We already updated the information to scheduler earlier, we need\n             // not have to raise another event.\n             continue;\n           }\n           //otherwise just send preemption events\n           rmContext.getDispatcher().getEventHandler().handle(\n               new ContainerPreemptEvent(appAttemptId, container,\n                   SchedulerEventType.MARK_CONTAINER_FOR_PREEMPTION));\n-          preemptionCandidates.put(container, clock.getTime());\n+          preemptionCandidates.put(container, currentTime);\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void preemptOrkillSelectedContainerAfterWait(\n      Map\u003cApplicationAttemptId, Set\u003cRMContainer\u003e\u003e selectedCandidates,\n      long currentTime) {\n    // preempt (or kill) the selected containers\n    for (Map.Entry\u003cApplicationAttemptId, Set\u003cRMContainer\u003e\u003e e : selectedCandidates\n        .entrySet()) {\n      ApplicationAttemptId appAttemptId \u003d e.getKey();\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Send to scheduler: in app\u003d\" + appAttemptId\n            + \" #containers-to-be-preemptionCandidates\u003d\" + e.getValue().size());\n      }\n      for (RMContainer container : e.getValue()) {\n        // if we tried to preempt this for more than maxWaitTime\n        if (preemptionCandidates.get(container) !\u003d null\n            \u0026\u0026 preemptionCandidates.get(container)\n                + maxWaitTime \u003c\u003d currentTime) {\n          // kill it\n          rmContext.getDispatcher().getEventHandler().handle(\n              new ContainerPreemptEvent(appAttemptId, container,\n                  SchedulerEventType.MARK_CONTAINER_FOR_KILLABLE));\n          preemptionCandidates.remove(container);\n        } else {\n          if (preemptionCandidates.get(container) !\u003d null) {\n            // We already updated the information to scheduler earlier, we need\n            // not have to raise another event.\n            continue;\n          }\n          //otherwise just send preemption events\n          rmContext.getDispatcher().getEventHandler().handle(\n              new ContainerPreemptEvent(appAttemptId, container,\n                  SchedulerEventType.MARK_CONTAINER_FOR_PREEMPTION));\n          preemptionCandidates.put(container, currentTime);\n        }\n      }\n    }\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/monitor/capacity/ProportionalCapacityPreemptionPolicy.java",
          "extendedDetails": {
            "oldValue": "[selectedCandidates-Map\u003cApplicationAttemptId,Set\u003cRMContainer\u003e\u003e]",
            "newValue": "[selectedCandidates-Map\u003cApplicationAttemptId,Set\u003cRMContainer\u003e\u003e, currentTime-long]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-4846. Fix random failures for TestCapacitySchedulerPreemption#testPreemptionPolicyShouldRespectAlreadyMarkedKillableContainers. (Bibin A Chundatt via wangda)\n",
          "commitDate": "22/04/16 11:40 AM",
          "commitName": "7cb3a3da96e59fc9b6528644dae5fb0ac1e44eac",
          "commitAuthor": "Wangda Tan",
          "commitDateOld": "30/03/16 12:43 PM",
          "commitNameOld": "60e4116bf1d00afed91010e57357fe54057e4e39",
          "commitAuthorOld": "Jian He",
          "daysBetweenCommits": 22.96,
          "commitsBetweenForRepo": 153,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,35 +1,36 @@\n   private void preemptOrkillSelectedContainerAfterWait(\n-      Map\u003cApplicationAttemptId, Set\u003cRMContainer\u003e\u003e selectedCandidates) {\n+      Map\u003cApplicationAttemptId, Set\u003cRMContainer\u003e\u003e selectedCandidates,\n+      long currentTime) {\n     // preempt (or kill) the selected containers\n     for (Map.Entry\u003cApplicationAttemptId, Set\u003cRMContainer\u003e\u003e e : selectedCandidates\n         .entrySet()) {\n       ApplicationAttemptId appAttemptId \u003d e.getKey();\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Send to scheduler: in app\u003d\" + appAttemptId\n             + \" #containers-to-be-preemptionCandidates\u003d\" + e.getValue().size());\n       }\n       for (RMContainer container : e.getValue()) {\n         // if we tried to preempt this for more than maxWaitTime\n         if (preemptionCandidates.get(container) !\u003d null\n-            \u0026\u0026 preemptionCandidates.get(container) + maxWaitTime \u003c clock\n-            .getTime()) {\n+            \u0026\u0026 preemptionCandidates.get(container)\n+                + maxWaitTime \u003c\u003d currentTime) {\n           // kill it\n           rmContext.getDispatcher().getEventHandler().handle(\n               new ContainerPreemptEvent(appAttemptId, container,\n                   SchedulerEventType.MARK_CONTAINER_FOR_KILLABLE));\n           preemptionCandidates.remove(container);\n         } else {\n           if (preemptionCandidates.get(container) !\u003d null) {\n             // We already updated the information to scheduler earlier, we need\n             // not have to raise another event.\n             continue;\n           }\n           //otherwise just send preemption events\n           rmContext.getDispatcher().getEventHandler().handle(\n               new ContainerPreemptEvent(appAttemptId, container,\n                   SchedulerEventType.MARK_CONTAINER_FOR_PREEMPTION));\n-          preemptionCandidates.put(container, clock.getTime());\n+          preemptionCandidates.put(container, currentTime);\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void preemptOrkillSelectedContainerAfterWait(\n      Map\u003cApplicationAttemptId, Set\u003cRMContainer\u003e\u003e selectedCandidates,\n      long currentTime) {\n    // preempt (or kill) the selected containers\n    for (Map.Entry\u003cApplicationAttemptId, Set\u003cRMContainer\u003e\u003e e : selectedCandidates\n        .entrySet()) {\n      ApplicationAttemptId appAttemptId \u003d e.getKey();\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Send to scheduler: in app\u003d\" + appAttemptId\n            + \" #containers-to-be-preemptionCandidates\u003d\" + e.getValue().size());\n      }\n      for (RMContainer container : e.getValue()) {\n        // if we tried to preempt this for more than maxWaitTime\n        if (preemptionCandidates.get(container) !\u003d null\n            \u0026\u0026 preemptionCandidates.get(container)\n                + maxWaitTime \u003c\u003d currentTime) {\n          // kill it\n          rmContext.getDispatcher().getEventHandler().handle(\n              new ContainerPreemptEvent(appAttemptId, container,\n                  SchedulerEventType.MARK_CONTAINER_FOR_KILLABLE));\n          preemptionCandidates.remove(container);\n        } else {\n          if (preemptionCandidates.get(container) !\u003d null) {\n            // We already updated the information to scheduler earlier, we need\n            // not have to raise another event.\n            continue;\n          }\n          //otherwise just send preemption events\n          rmContext.getDispatcher().getEventHandler().handle(\n              new ContainerPreemptEvent(appAttemptId, container,\n                  SchedulerEventType.MARK_CONTAINER_FOR_PREEMPTION));\n          preemptionCandidates.put(container, currentTime);\n        }\n      }\n    }\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/monitor/capacity/ProportionalCapacityPreemptionPolicy.java",
          "extendedDetails": {}
        }
      ]
    },
    "60e4116bf1d00afed91010e57357fe54057e4e39": {
      "type": "Yintroduced",
      "commitMessage": "YARN-4822. Refactor existing Preemption Policy of CS for easier adding new approach to select preemption candidates. Contributed by Wangda Tan\n",
      "commitDate": "30/03/16 12:43 PM",
      "commitName": "60e4116bf1d00afed91010e57357fe54057e4e39",
      "commitAuthor": "Jian He",
      "diff": "@@ -0,0 +1,35 @@\n+  private void preemptOrkillSelectedContainerAfterWait(\n+      Map\u003cApplicationAttemptId, Set\u003cRMContainer\u003e\u003e selectedCandidates) {\n+    // preempt (or kill) the selected containers\n+    for (Map.Entry\u003cApplicationAttemptId, Set\u003cRMContainer\u003e\u003e e : selectedCandidates\n+        .entrySet()) {\n+      ApplicationAttemptId appAttemptId \u003d e.getKey();\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(\"Send to scheduler: in app\u003d\" + appAttemptId\n+            + \" #containers-to-be-preemptionCandidates\u003d\" + e.getValue().size());\n+      }\n+      for (RMContainer container : e.getValue()) {\n+        // if we tried to preempt this for more than maxWaitTime\n+        if (preemptionCandidates.get(container) !\u003d null\n+            \u0026\u0026 preemptionCandidates.get(container) + maxWaitTime \u003c clock\n+            .getTime()) {\n+          // kill it\n+          rmContext.getDispatcher().getEventHandler().handle(\n+              new ContainerPreemptEvent(appAttemptId, container,\n+                  SchedulerEventType.MARK_CONTAINER_FOR_KILLABLE));\n+          preemptionCandidates.remove(container);\n+        } else {\n+          if (preemptionCandidates.get(container) !\u003d null) {\n+            // We already updated the information to scheduler earlier, we need\n+            // not have to raise another event.\n+            continue;\n+          }\n+          //otherwise just send preemption events\n+          rmContext.getDispatcher().getEventHandler().handle(\n+              new ContainerPreemptEvent(appAttemptId, container,\n+                  SchedulerEventType.MARK_CONTAINER_FOR_PREEMPTION));\n+          preemptionCandidates.put(container, clock.getTime());\n+        }\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void preemptOrkillSelectedContainerAfterWait(\n      Map\u003cApplicationAttemptId, Set\u003cRMContainer\u003e\u003e selectedCandidates) {\n    // preempt (or kill) the selected containers\n    for (Map.Entry\u003cApplicationAttemptId, Set\u003cRMContainer\u003e\u003e e : selectedCandidates\n        .entrySet()) {\n      ApplicationAttemptId appAttemptId \u003d e.getKey();\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Send to scheduler: in app\u003d\" + appAttemptId\n            + \" #containers-to-be-preemptionCandidates\u003d\" + e.getValue().size());\n      }\n      for (RMContainer container : e.getValue()) {\n        // if we tried to preempt this for more than maxWaitTime\n        if (preemptionCandidates.get(container) !\u003d null\n            \u0026\u0026 preemptionCandidates.get(container) + maxWaitTime \u003c clock\n            .getTime()) {\n          // kill it\n          rmContext.getDispatcher().getEventHandler().handle(\n              new ContainerPreemptEvent(appAttemptId, container,\n                  SchedulerEventType.MARK_CONTAINER_FOR_KILLABLE));\n          preemptionCandidates.remove(container);\n        } else {\n          if (preemptionCandidates.get(container) !\u003d null) {\n            // We already updated the information to scheduler earlier, we need\n            // not have to raise another event.\n            continue;\n          }\n          //otherwise just send preemption events\n          rmContext.getDispatcher().getEventHandler().handle(\n              new ContainerPreemptEvent(appAttemptId, container,\n                  SchedulerEventType.MARK_CONTAINER_FOR_PREEMPTION));\n          preemptionCandidates.put(container, clock.getTime());\n        }\n      }\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/monitor/capacity/ProportionalCapacityPreemptionPolicy.java"
    }
  }
}