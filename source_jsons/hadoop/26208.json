{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "TaskHeartbeatHandler.java",
  "functionName": "run",
  "functionId": "run",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/TaskHeartbeatHandler.java",
  "functionStartLine": 171,
  "functionEndLine": 183,
  "numCommitsSeen": 21,
  "timeTaken": 9429,
  "changeHistory": [
    "82f029f7b50679ea477a3a898e4ee400fa394adf",
    "5caef4894760c666a3dcb9cdbd6b584724a92182",
    "bb74427da27ab90ade868c4fd89ed8ac3310aea2",
    "39b8bbe663abc10d2dd327f426c94c147deb36ab",
    "428529b58fe7f405f393aaec822bf39c80401760",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "82f029f7b50679ea477a3a898e4ee400fa394adf": "Ybodychange",
    "5caef4894760c666a3dcb9cdbd6b584724a92182": "Ybodychange",
    "bb74427da27ab90ade868c4fd89ed8ac3310aea2": "Ybodychange",
    "39b8bbe663abc10d2dd327f426c94c147deb36ab": "Ybodychange",
    "428529b58fe7f405f393aaec822bf39c80401760": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Ymultichange(Ymovefromfile,Yexceptionschange,Ybodychange,Yparameterchange)",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "82f029f7b50679ea477a3a898e4ee400fa394adf": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-7053: Timed out tasks can fail to produce thread dump. Contributed by Jason Lowe.\n",
      "commitDate": "16/02/18 6:15 AM",
      "commitName": "82f029f7b50679ea477a3a898e4ee400fa394adf",
      "commitAuthor": "Eric Payne",
      "commitDateOld": "02/10/17 8:14 PM",
      "commitNameOld": "453d48bdfbb67ed3e66c33c4aef239c3d7bdd3bc",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 136.46,
      "commitsBetweenForRepo": 932,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,31 +1,13 @@\n     public void run() {\n       while (!stopped \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n-        Iterator\u003cMap.Entry\u003cTaskAttemptId, ReportTime\u003e\u003e iterator \u003d\n-            runningAttempts.entrySet().iterator();\n-\n-        // avoid calculating current time everytime in loop\n         long currentTime \u003d clock.getTime();\n-\n-        while (iterator.hasNext()) {\n-          Map.Entry\u003cTaskAttemptId, ReportTime\u003e entry \u003d iterator.next();\n-          boolean taskTimedOut \u003d (taskTimeOut \u003e 0) \u0026\u0026\n-              (currentTime \u003e (entry.getValue().getLastProgress() + taskTimeOut));\n-           \n-          if(taskTimedOut) {\n-            // task is lost, remove from the list and raise lost event\n-            iterator.remove();\n-            eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(entry\n-                .getKey(), \"AttemptID:\" + entry.getKey().toString()\n-                + \" Timed out after \" + taskTimeOut / 1000 + \" secs\"));\n-            eventHandler.handle(new TaskAttemptEvent(entry.getKey(),\n-                TaskAttemptEventType.TA_TIMED_OUT));\n-          }\n-        }\n+        checkRunning(currentTime);\n+        checkRecentlyUnregistered(currentTime);\n         try {\n           Thread.sleep(taskTimeOutCheckInterval);\n         } catch (InterruptedException e) {\n           LOG.info(\"TaskHeartbeatHandler thread interrupted\");\n           break;\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n      while (!stopped \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n        long currentTime \u003d clock.getTime();\n        checkRunning(currentTime);\n        checkRecentlyUnregistered(currentTime);\n        try {\n          Thread.sleep(taskTimeOutCheckInterval);\n        } catch (InterruptedException e) {\n          LOG.info(\"TaskHeartbeatHandler thread interrupted\");\n          break;\n        }\n      }\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/TaskHeartbeatHandler.java",
      "extendedDetails": {}
    },
    "5caef4894760c666a3dcb9cdbd6b584724a92182": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4817. Hardcoded task ping timeout kills tasks localizing large amounts of data (tgraves)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1414873 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/11/12 11:19 AM",
      "commitName": "5caef4894760c666a3dcb9cdbd6b584724a92182",
      "commitAuthor": "Thomas Graves",
      "commitDateOld": "02/04/12 1:20 PM",
      "commitNameOld": "bb74427da27ab90ade868c4fd89ed8ac3310aea2",
      "commitAuthorOld": "Thomas Graves",
      "daysBetweenCommits": 239.96,
      "commitsBetweenForRepo": 1422,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,33 +1,31 @@\n     public void run() {\n       while (!stopped \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n         Iterator\u003cMap.Entry\u003cTaskAttemptId, ReportTime\u003e\u003e iterator \u003d\n             runningAttempts.entrySet().iterator();\n \n         // avoid calculating current time everytime in loop\n         long currentTime \u003d clock.getTime();\n \n         while (iterator.hasNext()) {\n           Map.Entry\u003cTaskAttemptId, ReportTime\u003e entry \u003d iterator.next();\n           boolean taskTimedOut \u003d (taskTimeOut \u003e 0) \u0026\u0026 \n               (currentTime \u003e (entry.getValue().getLastProgress() + taskTimeOut));\n-          boolean pingTimedOut \u003d\n-              (currentTime \u003e (entry.getValue().getLastPing() + PING_TIMEOUT));\n-              \n-          if(taskTimedOut || pingTimedOut) {\n+           \n+          if(taskTimedOut) {\n             // task is lost, remove from the list and raise lost event\n             iterator.remove();\n             eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(entry\n                 .getKey(), \"AttemptID:\" + entry.getKey().toString()\n                 + \" Timed out after \" + taskTimeOut / 1000 + \" secs\"));\n             eventHandler.handle(new TaskAttemptEvent(entry.getKey(),\n                 TaskAttemptEventType.TA_TIMED_OUT));\n           }\n         }\n         try {\n           Thread.sleep(taskTimeOutCheckInterval);\n         } catch (InterruptedException e) {\n           LOG.info(\"TaskHeartbeatHandler thread interrupted\");\n           break;\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n      while (!stopped \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n        Iterator\u003cMap.Entry\u003cTaskAttemptId, ReportTime\u003e\u003e iterator \u003d\n            runningAttempts.entrySet().iterator();\n\n        // avoid calculating current time everytime in loop\n        long currentTime \u003d clock.getTime();\n\n        while (iterator.hasNext()) {\n          Map.Entry\u003cTaskAttemptId, ReportTime\u003e entry \u003d iterator.next();\n          boolean taskTimedOut \u003d (taskTimeOut \u003e 0) \u0026\u0026 \n              (currentTime \u003e (entry.getValue().getLastProgress() + taskTimeOut));\n           \n          if(taskTimedOut) {\n            // task is lost, remove from the list and raise lost event\n            iterator.remove();\n            eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(entry\n                .getKey(), \"AttemptID:\" + entry.getKey().toString()\n                + \" Timed out after \" + taskTimeOut / 1000 + \" secs\"));\n            eventHandler.handle(new TaskAttemptEvent(entry.getKey(),\n                TaskAttemptEventType.TA_TIMED_OUT));\n          }\n        }\n        try {\n          Thread.sleep(taskTimeOutCheckInterval);\n        } catch (InterruptedException e) {\n          LOG.info(\"TaskHeartbeatHandler thread interrupted\");\n          break;\n        }\n      }\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/TaskHeartbeatHandler.java",
      "extendedDetails": {}
    },
    "bb74427da27ab90ade868c4fd89ed8ac3310aea2": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4089. Hung Tasks never time out. (Robert Evans via tgraves)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1308531 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/04/12 1:20 PM",
      "commitName": "bb74427da27ab90ade868c4fd89ed8ac3310aea2",
      "commitAuthor": "Thomas Graves",
      "commitDateOld": "13/01/12 1:31 PM",
      "commitNameOld": "0c278b0f636a01c81aba9e46fe7658fcdfb0f33c",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 79.95,
      "commitsBetweenForRepo": 599,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,36 +1,33 @@\n     public void run() {\n       while (!stopped \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n-        Iterator\u003cMap.Entry\u003cTaskAttemptId, Long\u003e\u003e iterator \u003d\n+        Iterator\u003cMap.Entry\u003cTaskAttemptId, ReportTime\u003e\u003e iterator \u003d\n             runningAttempts.entrySet().iterator();\n \n         // avoid calculating current time everytime in loop\n         long currentTime \u003d clock.getTime();\n \n         while (iterator.hasNext()) {\n-          Map.Entry\u003cTaskAttemptId, Long\u003e entry \u003d iterator.next();\n-          if (currentTime \u003e entry.getValue() + taskTimeOut) {\n-\n-            //In case the iterator isn\u0027t picking up the latest.\n-            // Extra lookup outside of the iterator - but only if the task\n-            // is considered to be timed out.\n-            Long taskTime \u003d runningAttempts.get(entry.getKey());\n-            if (taskTime !\u003d null \u0026\u0026 currentTime \u003e taskTime + taskTimeOut) {\n-              // task is lost, remove from the list and raise lost event\n-              iterator.remove();\n-              eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(entry\n-                  .getKey(), \"AttemptID:\" + entry.getKey().toString()\n-                  + \" Timed out after \" + taskTimeOut / 1000 + \" secs\"));\n-              eventHandler.handle(new TaskAttemptEvent(entry.getKey(),\n-                  TaskAttemptEventType.TA_TIMED_OUT));\n-            }\n-\n+          Map.Entry\u003cTaskAttemptId, ReportTime\u003e entry \u003d iterator.next();\n+          boolean taskTimedOut \u003d (taskTimeOut \u003e 0) \u0026\u0026 \n+              (currentTime \u003e (entry.getValue().getLastProgress() + taskTimeOut));\n+          boolean pingTimedOut \u003d\n+              (currentTime \u003e (entry.getValue().getLastPing() + PING_TIMEOUT));\n+              \n+          if(taskTimedOut || pingTimedOut) {\n+            // task is lost, remove from the list and raise lost event\n+            iterator.remove();\n+            eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(entry\n+                .getKey(), \"AttemptID:\" + entry.getKey().toString()\n+                + \" Timed out after \" + taskTimeOut / 1000 + \" secs\"));\n+            eventHandler.handle(new TaskAttemptEvent(entry.getKey(),\n+                TaskAttemptEventType.TA_TIMED_OUT));\n           }\n         }\n         try {\n           Thread.sleep(taskTimeOutCheckInterval);\n         } catch (InterruptedException e) {\n           LOG.info(\"TaskHeartbeatHandler thread interrupted\");\n           break;\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n      while (!stopped \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n        Iterator\u003cMap.Entry\u003cTaskAttemptId, ReportTime\u003e\u003e iterator \u003d\n            runningAttempts.entrySet().iterator();\n\n        // avoid calculating current time everytime in loop\n        long currentTime \u003d clock.getTime();\n\n        while (iterator.hasNext()) {\n          Map.Entry\u003cTaskAttemptId, ReportTime\u003e entry \u003d iterator.next();\n          boolean taskTimedOut \u003d (taskTimeOut \u003e 0) \u0026\u0026 \n              (currentTime \u003e (entry.getValue().getLastProgress() + taskTimeOut));\n          boolean pingTimedOut \u003d\n              (currentTime \u003e (entry.getValue().getLastPing() + PING_TIMEOUT));\n              \n          if(taskTimedOut || pingTimedOut) {\n            // task is lost, remove from the list and raise lost event\n            iterator.remove();\n            eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(entry\n                .getKey(), \"AttemptID:\" + entry.getKey().toString()\n                + \" Timed out after \" + taskTimeOut / 1000 + \" secs\"));\n            eventHandler.handle(new TaskAttemptEvent(entry.getKey(),\n                TaskAttemptEventType.TA_TIMED_OUT));\n          }\n        }\n        try {\n          Thread.sleep(taskTimeOutCheckInterval);\n        } catch (InterruptedException e) {\n          LOG.info(\"TaskHeartbeatHandler thread interrupted\");\n          break;\n        }\n      }\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/TaskHeartbeatHandler.java",
      "extendedDetails": {}
    },
    "39b8bbe663abc10d2dd327f426c94c147deb36ab": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3618. Fixed TaskHeartbeatHandler to not hold a global lock for all task-updates. Contributed by Siddarth Seth.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1229906 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/01/12 10:53 PM",
      "commitName": "39b8bbe663abc10d2dd327f426c94c147deb36ab",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "09/01/12 2:37 PM",
      "commitNameOld": "428529b58fe7f405f393aaec822bf39c80401760",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 1.34,
      "commitsBetweenForRepo": 10,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,31 +1,36 @@\n     public void run() {\n       while (!stopped \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n-        synchronized (TaskHeartbeatHandler.this) {\n-          Iterator\u003cMap.Entry\u003cTaskAttemptId, Long\u003e\u003e iterator \u003d \n+        Iterator\u003cMap.Entry\u003cTaskAttemptId, Long\u003e\u003e iterator \u003d\n             runningAttempts.entrySet().iterator();\n \n-          //avoid calculating current time everytime in loop\n-          long currentTime \u003d clock.getTime();\n+        // avoid calculating current time everytime in loop\n+        long currentTime \u003d clock.getTime();\n \n-          while (iterator.hasNext()) {\n-            Map.Entry\u003cTaskAttemptId, Long\u003e entry \u003d iterator.next();\n-            if (currentTime \u003e entry.getValue() + taskTimeOut) {\n-              //task is lost, remove from the list and raise lost event\n+        while (iterator.hasNext()) {\n+          Map.Entry\u003cTaskAttemptId, Long\u003e entry \u003d iterator.next();\n+          if (currentTime \u003e entry.getValue() + taskTimeOut) {\n+\n+            //In case the iterator isn\u0027t picking up the latest.\n+            // Extra lookup outside of the iterator - but only if the task\n+            // is considered to be timed out.\n+            Long taskTime \u003d runningAttempts.get(entry.getKey());\n+            if (taskTime !\u003d null \u0026\u0026 currentTime \u003e taskTime + taskTimeOut) {\n+              // task is lost, remove from the list and raise lost event\n               iterator.remove();\n-              eventHandler.handle(\n-                  new TaskAttemptDiagnosticsUpdateEvent(entry.getKey(),\n-                      \"AttemptID:\" + entry.getKey().toString() + \n-                      \" Timed out after \" + taskTimeOut/1000 + \" secs\"));\n-              eventHandler.handle(new TaskAttemptEvent(entry\n-                  .getKey(), TaskAttemptEventType.TA_TIMED_OUT));\n+              eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(entry\n+                  .getKey(), \"AttemptID:\" + entry.getKey().toString()\n+                  + \" Timed out after \" + taskTimeOut / 1000 + \" secs\"));\n+              eventHandler.handle(new TaskAttemptEvent(entry.getKey(),\n+                  TaskAttemptEventType.TA_TIMED_OUT));\n             }\n+\n           }\n         }\n         try {\n           Thread.sleep(taskTimeOutCheckInterval);\n         } catch (InterruptedException e) {\n           LOG.info(\"TaskHeartbeatHandler thread interrupted\");\n           break;\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n      while (!stopped \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n        Iterator\u003cMap.Entry\u003cTaskAttemptId, Long\u003e\u003e iterator \u003d\n            runningAttempts.entrySet().iterator();\n\n        // avoid calculating current time everytime in loop\n        long currentTime \u003d clock.getTime();\n\n        while (iterator.hasNext()) {\n          Map.Entry\u003cTaskAttemptId, Long\u003e entry \u003d iterator.next();\n          if (currentTime \u003e entry.getValue() + taskTimeOut) {\n\n            //In case the iterator isn\u0027t picking up the latest.\n            // Extra lookup outside of the iterator - but only if the task\n            // is considered to be timed out.\n            Long taskTime \u003d runningAttempts.get(entry.getKey());\n            if (taskTime !\u003d null \u0026\u0026 currentTime \u003e taskTime + taskTimeOut) {\n              // task is lost, remove from the list and raise lost event\n              iterator.remove();\n              eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(entry\n                  .getKey(), \"AttemptID:\" + entry.getKey().toString()\n                  + \" Timed out after \" + taskTimeOut / 1000 + \" secs\"));\n              eventHandler.handle(new TaskAttemptEvent(entry.getKey(),\n                  TaskAttemptEventType.TA_TIMED_OUT));\n            }\n\n          }\n        }\n        try {\n          Thread.sleep(taskTimeOutCheckInterval);\n        } catch (InterruptedException e) {\n          LOG.info(\"TaskHeartbeatHandler thread interrupted\");\n          break;\n        }\n      }\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/TaskHeartbeatHandler.java",
      "extendedDetails": {}
    },
    "428529b58fe7f405f393aaec822bf39c80401760": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3528. Fixed TaskHeartBeatHandler to use a new configuration for the thread loop interval separate from task-timeout configuration property. (Siddharth Seth via vinodkv)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1229403 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/01/12 2:37 PM",
      "commitName": "428529b58fe7f405f393aaec822bf39c80401760",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "16/10/11 12:27 PM",
      "commitNameOld": "68328ae92632afc9cdd6e75b7a8d832723ddbe3b",
      "commitAuthorOld": "Mahadev Konar",
      "daysBetweenCommits": 85.13,
      "commitsBetweenForRepo": 514,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,31 +1,31 @@\n     public void run() {\n       while (!stopped \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n         synchronized (TaskHeartbeatHandler.this) {\n           Iterator\u003cMap.Entry\u003cTaskAttemptId, Long\u003e\u003e iterator \u003d \n             runningAttempts.entrySet().iterator();\n \n           //avoid calculating current time everytime in loop\n           long currentTime \u003d clock.getTime();\n \n           while (iterator.hasNext()) {\n             Map.Entry\u003cTaskAttemptId, Long\u003e entry \u003d iterator.next();\n             if (currentTime \u003e entry.getValue() + taskTimeOut) {\n               //task is lost, remove from the list and raise lost event\n               iterator.remove();\n               eventHandler.handle(\n                   new TaskAttemptDiagnosticsUpdateEvent(entry.getKey(),\n                       \"AttemptID:\" + entry.getKey().toString() + \n                       \" Timed out after \" + taskTimeOut/1000 + \" secs\"));\n               eventHandler.handle(new TaskAttemptEvent(entry\n                   .getKey(), TaskAttemptEventType.TA_TIMED_OUT));\n             }\n           }\n         }\n         try {\n-          Thread.sleep(taskTimeOut);\n+          Thread.sleep(taskTimeOutCheckInterval);\n         } catch (InterruptedException e) {\n           LOG.info(\"TaskHeartbeatHandler thread interrupted\");\n           break;\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n      while (!stopped \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n        synchronized (TaskHeartbeatHandler.this) {\n          Iterator\u003cMap.Entry\u003cTaskAttemptId, Long\u003e\u003e iterator \u003d \n            runningAttempts.entrySet().iterator();\n\n          //avoid calculating current time everytime in loop\n          long currentTime \u003d clock.getTime();\n\n          while (iterator.hasNext()) {\n            Map.Entry\u003cTaskAttemptId, Long\u003e entry \u003d iterator.next();\n            if (currentTime \u003e entry.getValue() + taskTimeOut) {\n              //task is lost, remove from the list and raise lost event\n              iterator.remove();\n              eventHandler.handle(\n                  new TaskAttemptDiagnosticsUpdateEvent(entry.getKey(),\n                      \"AttemptID:\" + entry.getKey().toString() + \n                      \" Timed out after \" + taskTimeOut/1000 + \" secs\"));\n              eventHandler.handle(new TaskAttemptEvent(entry\n                  .getKey(), TaskAttemptEventType.TA_TIMED_OUT));\n            }\n          }\n        }\n        try {\n          Thread.sleep(taskTimeOutCheckInterval);\n        } catch (InterruptedException e) {\n          LOG.info(\"TaskHeartbeatHandler thread interrupted\");\n          break;\n        }\n      }\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/TaskHeartbeatHandler.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    public void run() {\n      while (!stopped \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n        synchronized (TaskHeartbeatHandler.this) {\n          Iterator\u003cMap.Entry\u003cTaskAttemptId, Long\u003e\u003e iterator \u003d \n            runningAttempts.entrySet().iterator();\n\n          //avoid calculating current time everytime in loop\n          long currentTime \u003d clock.getTime();\n\n          while (iterator.hasNext()) {\n            Map.Entry\u003cTaskAttemptId, Long\u003e entry \u003d iterator.next();\n            if (currentTime \u003e entry.getValue() + taskTimeOut) {\n              //task is lost, remove from the list and raise lost event\n              iterator.remove();\n              eventHandler.handle(\n                  new TaskAttemptDiagnosticsUpdateEvent(entry.getKey(),\n                      \"AttemptID:\" + entry.getKey().toString() + \n                      \" Timed out after \" + taskTimeOut/1000 + \" secs\"));\n              eventHandler.handle(new TaskAttemptEvent(entry\n                  .getKey(), TaskAttemptEventType.TA_TIMED_OUT));\n            }\n          }\n        }\n        try {\n          Thread.sleep(taskTimeOut);\n        } catch (InterruptedException e) {\n          LOG.info(\"TaskHeartbeatHandler thread interrupted\");\n          break;\n        }\n      }\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/TaskHeartbeatHandler.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/TaskHeartbeatHandler.java",
        "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/TaskHeartbeatHandler.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Ymultichange(Ymovefromfile,Yexceptionschange,Ybodychange,Yparameterchange)",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/08/11 4:07 AM",
          "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "17/08/11 8:02 PM",
          "commitNameOld": "dd86860633d2ed64705b669a75bf318442ed6225",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 0.34,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,42 +1,31 @@\n-  public void run(final JobConf job, final TaskUmbilicalProtocol umbilical)\n-    throws IOException, ClassNotFoundException, InterruptedException {\n-    this.umbilical \u003d umbilical;\n+    public void run() {\n+      while (!stopped \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n+        synchronized (TaskHeartbeatHandler.this) {\n+          Iterator\u003cMap.Entry\u003cTaskAttemptId, Long\u003e\u003e iterator \u003d \n+            runningAttempts.entrySet().iterator();\n \n-    if (isMapTask()) {\n-      // If there are no reducers then there won\u0027t be any sort. Hence the map \n-      // phase will govern the entire attempt\u0027s progress.\n-      if (conf.getNumReduceTasks() \u003d\u003d 0) {\n-        mapPhase \u003d getProgress().addPhase(\"map\", 1.0f);\n-      } else {\n-        // If there are reducers then the entire attempt\u0027s progress will be \n-        // split between the map phase (67%) and the sort phase (33%).\n-        mapPhase \u003d getProgress().addPhase(\"map\", 0.667f);\n-        sortPhase  \u003d getProgress().addPhase(\"sort\", 0.333f);\n+          //avoid calculating current time everytime in loop\n+          long currentTime \u003d clock.getTime();\n+\n+          while (iterator.hasNext()) {\n+            Map.Entry\u003cTaskAttemptId, Long\u003e entry \u003d iterator.next();\n+            if (currentTime \u003e entry.getValue() + taskTimeOut) {\n+              //task is lost, remove from the list and raise lost event\n+              iterator.remove();\n+              eventHandler.handle(\n+                  new TaskAttemptDiagnosticsUpdateEvent(entry.getKey(),\n+                      \"AttemptID:\" + entry.getKey().toString() + \n+                      \" Timed out after \" + taskTimeOut/1000 + \" secs\"));\n+              eventHandler.handle(new TaskAttemptEvent(entry\n+                  .getKey(), TaskAttemptEventType.TA_TIMED_OUT));\n+            }\n+          }\n+        }\n+        try {\n+          Thread.sleep(taskTimeOut);\n+        } catch (InterruptedException e) {\n+          LOG.info(\"TaskHeartbeatHandler thread interrupted\");\n+          break;\n+        }\n       }\n-    }\n-    TaskReporter reporter \u003d startReporter(umbilical);\n- \n-    boolean useNewApi \u003d job.getUseNewMapper();\n-    initialize(job, getJobID(), reporter, useNewApi);\n-\n-    // check if it is a cleanupJobTask\n-    if (jobCleanup) {\n-      runJobCleanupTask(umbilical, reporter);\n-      return;\n-    }\n-    if (jobSetup) {\n-      runJobSetupTask(umbilical, reporter);\n-      return;\n-    }\n-    if (taskCleanup) {\n-      runTaskCleanupTask(umbilical, reporter);\n-      return;\n-    }\n-\n-    if (useNewApi) {\n-      runNewMapper(job, splitMetaInfo, umbilical, reporter);\n-    } else {\n-      runOldMapper(job, splitMetaInfo, umbilical, reporter);\n-    }\n-    done(umbilical, reporter);\n-  }\n\\ No newline at end of file\n+    }\n\\ No newline at end of file\n",
          "actualSource": "    public void run() {\n      while (!stopped \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n        synchronized (TaskHeartbeatHandler.this) {\n          Iterator\u003cMap.Entry\u003cTaskAttemptId, Long\u003e\u003e iterator \u003d \n            runningAttempts.entrySet().iterator();\n\n          //avoid calculating current time everytime in loop\n          long currentTime \u003d clock.getTime();\n\n          while (iterator.hasNext()) {\n            Map.Entry\u003cTaskAttemptId, Long\u003e entry \u003d iterator.next();\n            if (currentTime \u003e entry.getValue() + taskTimeOut) {\n              //task is lost, remove from the list and raise lost event\n              iterator.remove();\n              eventHandler.handle(\n                  new TaskAttemptDiagnosticsUpdateEvent(entry.getKey(),\n                      \"AttemptID:\" + entry.getKey().toString() + \n                      \" Timed out after \" + taskTimeOut/1000 + \" secs\"));\n              eventHandler.handle(new TaskAttemptEvent(entry\n                  .getKey(), TaskAttemptEventType.TA_TIMED_OUT));\n            }\n          }\n        }\n        try {\n          Thread.sleep(taskTimeOut);\n        } catch (InterruptedException e) {\n          LOG.info(\"TaskHeartbeatHandler thread interrupted\");\n          break;\n        }\n      }\n    }",
          "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/TaskHeartbeatHandler.java",
          "extendedDetails": {
            "oldPath": "mapreduce/src/java/org/apache/hadoop/mapred/MapTask.java",
            "newPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/TaskHeartbeatHandler.java",
            "oldMethodName": "run",
            "newMethodName": "run"
          }
        },
        {
          "type": "Yexceptionschange",
          "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/08/11 4:07 AM",
          "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "17/08/11 8:02 PM",
          "commitNameOld": "dd86860633d2ed64705b669a75bf318442ed6225",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 0.34,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,42 +1,31 @@\n-  public void run(final JobConf job, final TaskUmbilicalProtocol umbilical)\n-    throws IOException, ClassNotFoundException, InterruptedException {\n-    this.umbilical \u003d umbilical;\n+    public void run() {\n+      while (!stopped \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n+        synchronized (TaskHeartbeatHandler.this) {\n+          Iterator\u003cMap.Entry\u003cTaskAttemptId, Long\u003e\u003e iterator \u003d \n+            runningAttempts.entrySet().iterator();\n \n-    if (isMapTask()) {\n-      // If there are no reducers then there won\u0027t be any sort. Hence the map \n-      // phase will govern the entire attempt\u0027s progress.\n-      if (conf.getNumReduceTasks() \u003d\u003d 0) {\n-        mapPhase \u003d getProgress().addPhase(\"map\", 1.0f);\n-      } else {\n-        // If there are reducers then the entire attempt\u0027s progress will be \n-        // split between the map phase (67%) and the sort phase (33%).\n-        mapPhase \u003d getProgress().addPhase(\"map\", 0.667f);\n-        sortPhase  \u003d getProgress().addPhase(\"sort\", 0.333f);\n+          //avoid calculating current time everytime in loop\n+          long currentTime \u003d clock.getTime();\n+\n+          while (iterator.hasNext()) {\n+            Map.Entry\u003cTaskAttemptId, Long\u003e entry \u003d iterator.next();\n+            if (currentTime \u003e entry.getValue() + taskTimeOut) {\n+              //task is lost, remove from the list and raise lost event\n+              iterator.remove();\n+              eventHandler.handle(\n+                  new TaskAttemptDiagnosticsUpdateEvent(entry.getKey(),\n+                      \"AttemptID:\" + entry.getKey().toString() + \n+                      \" Timed out after \" + taskTimeOut/1000 + \" secs\"));\n+              eventHandler.handle(new TaskAttemptEvent(entry\n+                  .getKey(), TaskAttemptEventType.TA_TIMED_OUT));\n+            }\n+          }\n+        }\n+        try {\n+          Thread.sleep(taskTimeOut);\n+        } catch (InterruptedException e) {\n+          LOG.info(\"TaskHeartbeatHandler thread interrupted\");\n+          break;\n+        }\n       }\n-    }\n-    TaskReporter reporter \u003d startReporter(umbilical);\n- \n-    boolean useNewApi \u003d job.getUseNewMapper();\n-    initialize(job, getJobID(), reporter, useNewApi);\n-\n-    // check if it is a cleanupJobTask\n-    if (jobCleanup) {\n-      runJobCleanupTask(umbilical, reporter);\n-      return;\n-    }\n-    if (jobSetup) {\n-      runJobSetupTask(umbilical, reporter);\n-      return;\n-    }\n-    if (taskCleanup) {\n-      runTaskCleanupTask(umbilical, reporter);\n-      return;\n-    }\n-\n-    if (useNewApi) {\n-      runNewMapper(job, splitMetaInfo, umbilical, reporter);\n-    } else {\n-      runOldMapper(job, splitMetaInfo, umbilical, reporter);\n-    }\n-    done(umbilical, reporter);\n-  }\n\\ No newline at end of file\n+    }\n\\ No newline at end of file\n",
          "actualSource": "    public void run() {\n      while (!stopped \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n        synchronized (TaskHeartbeatHandler.this) {\n          Iterator\u003cMap.Entry\u003cTaskAttemptId, Long\u003e\u003e iterator \u003d \n            runningAttempts.entrySet().iterator();\n\n          //avoid calculating current time everytime in loop\n          long currentTime \u003d clock.getTime();\n\n          while (iterator.hasNext()) {\n            Map.Entry\u003cTaskAttemptId, Long\u003e entry \u003d iterator.next();\n            if (currentTime \u003e entry.getValue() + taskTimeOut) {\n              //task is lost, remove from the list and raise lost event\n              iterator.remove();\n              eventHandler.handle(\n                  new TaskAttemptDiagnosticsUpdateEvent(entry.getKey(),\n                      \"AttemptID:\" + entry.getKey().toString() + \n                      \" Timed out after \" + taskTimeOut/1000 + \" secs\"));\n              eventHandler.handle(new TaskAttemptEvent(entry\n                  .getKey(), TaskAttemptEventType.TA_TIMED_OUT));\n            }\n          }\n        }\n        try {\n          Thread.sleep(taskTimeOut);\n        } catch (InterruptedException e) {\n          LOG.info(\"TaskHeartbeatHandler thread interrupted\");\n          break;\n        }\n      }\n    }",
          "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/TaskHeartbeatHandler.java",
          "extendedDetails": {
            "oldValue": "[IOException, ClassNotFoundException, InterruptedException]",
            "newValue": "[]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/08/11 4:07 AM",
          "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "17/08/11 8:02 PM",
          "commitNameOld": "dd86860633d2ed64705b669a75bf318442ed6225",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 0.34,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,42 +1,31 @@\n-  public void run(final JobConf job, final TaskUmbilicalProtocol umbilical)\n-    throws IOException, ClassNotFoundException, InterruptedException {\n-    this.umbilical \u003d umbilical;\n+    public void run() {\n+      while (!stopped \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n+        synchronized (TaskHeartbeatHandler.this) {\n+          Iterator\u003cMap.Entry\u003cTaskAttemptId, Long\u003e\u003e iterator \u003d \n+            runningAttempts.entrySet().iterator();\n \n-    if (isMapTask()) {\n-      // If there are no reducers then there won\u0027t be any sort. Hence the map \n-      // phase will govern the entire attempt\u0027s progress.\n-      if (conf.getNumReduceTasks() \u003d\u003d 0) {\n-        mapPhase \u003d getProgress().addPhase(\"map\", 1.0f);\n-      } else {\n-        // If there are reducers then the entire attempt\u0027s progress will be \n-        // split between the map phase (67%) and the sort phase (33%).\n-        mapPhase \u003d getProgress().addPhase(\"map\", 0.667f);\n-        sortPhase  \u003d getProgress().addPhase(\"sort\", 0.333f);\n+          //avoid calculating current time everytime in loop\n+          long currentTime \u003d clock.getTime();\n+\n+          while (iterator.hasNext()) {\n+            Map.Entry\u003cTaskAttemptId, Long\u003e entry \u003d iterator.next();\n+            if (currentTime \u003e entry.getValue() + taskTimeOut) {\n+              //task is lost, remove from the list and raise lost event\n+              iterator.remove();\n+              eventHandler.handle(\n+                  new TaskAttemptDiagnosticsUpdateEvent(entry.getKey(),\n+                      \"AttemptID:\" + entry.getKey().toString() + \n+                      \" Timed out after \" + taskTimeOut/1000 + \" secs\"));\n+              eventHandler.handle(new TaskAttemptEvent(entry\n+                  .getKey(), TaskAttemptEventType.TA_TIMED_OUT));\n+            }\n+          }\n+        }\n+        try {\n+          Thread.sleep(taskTimeOut);\n+        } catch (InterruptedException e) {\n+          LOG.info(\"TaskHeartbeatHandler thread interrupted\");\n+          break;\n+        }\n       }\n-    }\n-    TaskReporter reporter \u003d startReporter(umbilical);\n- \n-    boolean useNewApi \u003d job.getUseNewMapper();\n-    initialize(job, getJobID(), reporter, useNewApi);\n-\n-    // check if it is a cleanupJobTask\n-    if (jobCleanup) {\n-      runJobCleanupTask(umbilical, reporter);\n-      return;\n-    }\n-    if (jobSetup) {\n-      runJobSetupTask(umbilical, reporter);\n-      return;\n-    }\n-    if (taskCleanup) {\n-      runTaskCleanupTask(umbilical, reporter);\n-      return;\n-    }\n-\n-    if (useNewApi) {\n-      runNewMapper(job, splitMetaInfo, umbilical, reporter);\n-    } else {\n-      runOldMapper(job, splitMetaInfo, umbilical, reporter);\n-    }\n-    done(umbilical, reporter);\n-  }\n\\ No newline at end of file\n+    }\n\\ No newline at end of file\n",
          "actualSource": "    public void run() {\n      while (!stopped \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n        synchronized (TaskHeartbeatHandler.this) {\n          Iterator\u003cMap.Entry\u003cTaskAttemptId, Long\u003e\u003e iterator \u003d \n            runningAttempts.entrySet().iterator();\n\n          //avoid calculating current time everytime in loop\n          long currentTime \u003d clock.getTime();\n\n          while (iterator.hasNext()) {\n            Map.Entry\u003cTaskAttemptId, Long\u003e entry \u003d iterator.next();\n            if (currentTime \u003e entry.getValue() + taskTimeOut) {\n              //task is lost, remove from the list and raise lost event\n              iterator.remove();\n              eventHandler.handle(\n                  new TaskAttemptDiagnosticsUpdateEvent(entry.getKey(),\n                      \"AttemptID:\" + entry.getKey().toString() + \n                      \" Timed out after \" + taskTimeOut/1000 + \" secs\"));\n              eventHandler.handle(new TaskAttemptEvent(entry\n                  .getKey(), TaskAttemptEventType.TA_TIMED_OUT));\n            }\n          }\n        }\n        try {\n          Thread.sleep(taskTimeOut);\n        } catch (InterruptedException e) {\n          LOG.info(\"TaskHeartbeatHandler thread interrupted\");\n          break;\n        }\n      }\n    }",
          "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/TaskHeartbeatHandler.java",
          "extendedDetails": {}
        },
        {
          "type": "Yparameterchange",
          "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/08/11 4:07 AM",
          "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "17/08/11 8:02 PM",
          "commitNameOld": "dd86860633d2ed64705b669a75bf318442ed6225",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 0.34,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,42 +1,31 @@\n-  public void run(final JobConf job, final TaskUmbilicalProtocol umbilical)\n-    throws IOException, ClassNotFoundException, InterruptedException {\n-    this.umbilical \u003d umbilical;\n+    public void run() {\n+      while (!stopped \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n+        synchronized (TaskHeartbeatHandler.this) {\n+          Iterator\u003cMap.Entry\u003cTaskAttemptId, Long\u003e\u003e iterator \u003d \n+            runningAttempts.entrySet().iterator();\n \n-    if (isMapTask()) {\n-      // If there are no reducers then there won\u0027t be any sort. Hence the map \n-      // phase will govern the entire attempt\u0027s progress.\n-      if (conf.getNumReduceTasks() \u003d\u003d 0) {\n-        mapPhase \u003d getProgress().addPhase(\"map\", 1.0f);\n-      } else {\n-        // If there are reducers then the entire attempt\u0027s progress will be \n-        // split between the map phase (67%) and the sort phase (33%).\n-        mapPhase \u003d getProgress().addPhase(\"map\", 0.667f);\n-        sortPhase  \u003d getProgress().addPhase(\"sort\", 0.333f);\n+          //avoid calculating current time everytime in loop\n+          long currentTime \u003d clock.getTime();\n+\n+          while (iterator.hasNext()) {\n+            Map.Entry\u003cTaskAttemptId, Long\u003e entry \u003d iterator.next();\n+            if (currentTime \u003e entry.getValue() + taskTimeOut) {\n+              //task is lost, remove from the list and raise lost event\n+              iterator.remove();\n+              eventHandler.handle(\n+                  new TaskAttemptDiagnosticsUpdateEvent(entry.getKey(),\n+                      \"AttemptID:\" + entry.getKey().toString() + \n+                      \" Timed out after \" + taskTimeOut/1000 + \" secs\"));\n+              eventHandler.handle(new TaskAttemptEvent(entry\n+                  .getKey(), TaskAttemptEventType.TA_TIMED_OUT));\n+            }\n+          }\n+        }\n+        try {\n+          Thread.sleep(taskTimeOut);\n+        } catch (InterruptedException e) {\n+          LOG.info(\"TaskHeartbeatHandler thread interrupted\");\n+          break;\n+        }\n       }\n-    }\n-    TaskReporter reporter \u003d startReporter(umbilical);\n- \n-    boolean useNewApi \u003d job.getUseNewMapper();\n-    initialize(job, getJobID(), reporter, useNewApi);\n-\n-    // check if it is a cleanupJobTask\n-    if (jobCleanup) {\n-      runJobCleanupTask(umbilical, reporter);\n-      return;\n-    }\n-    if (jobSetup) {\n-      runJobSetupTask(umbilical, reporter);\n-      return;\n-    }\n-    if (taskCleanup) {\n-      runTaskCleanupTask(umbilical, reporter);\n-      return;\n-    }\n-\n-    if (useNewApi) {\n-      runNewMapper(job, splitMetaInfo, umbilical, reporter);\n-    } else {\n-      runOldMapper(job, splitMetaInfo, umbilical, reporter);\n-    }\n-    done(umbilical, reporter);\n-  }\n\\ No newline at end of file\n+    }\n\\ No newline at end of file\n",
          "actualSource": "    public void run() {\n      while (!stopped \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n        synchronized (TaskHeartbeatHandler.this) {\n          Iterator\u003cMap.Entry\u003cTaskAttemptId, Long\u003e\u003e iterator \u003d \n            runningAttempts.entrySet().iterator();\n\n          //avoid calculating current time everytime in loop\n          long currentTime \u003d clock.getTime();\n\n          while (iterator.hasNext()) {\n            Map.Entry\u003cTaskAttemptId, Long\u003e entry \u003d iterator.next();\n            if (currentTime \u003e entry.getValue() + taskTimeOut) {\n              //task is lost, remove from the list and raise lost event\n              iterator.remove();\n              eventHandler.handle(\n                  new TaskAttemptDiagnosticsUpdateEvent(entry.getKey(),\n                      \"AttemptID:\" + entry.getKey().toString() + \n                      \" Timed out after \" + taskTimeOut/1000 + \" secs\"));\n              eventHandler.handle(new TaskAttemptEvent(entry\n                  .getKey(), TaskAttemptEventType.TA_TIMED_OUT));\n            }\n          }\n        }\n        try {\n          Thread.sleep(taskTimeOut);\n        } catch (InterruptedException e) {\n          LOG.info(\"TaskHeartbeatHandler thread interrupted\");\n          break;\n        }\n      }\n    }",
          "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/TaskHeartbeatHandler.java",
          "extendedDetails": {
            "oldValue": "[job-JobConf(modifiers-final), umbilical-TaskUmbilicalProtocol(modifiers-final)]",
            "newValue": "[]"
          }
        }
      ]
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,42 @@\n+  public void run(final JobConf job, final TaskUmbilicalProtocol umbilical)\n+    throws IOException, ClassNotFoundException, InterruptedException {\n+    this.umbilical \u003d umbilical;\n+\n+    if (isMapTask()) {\n+      // If there are no reducers then there won\u0027t be any sort. Hence the map \n+      // phase will govern the entire attempt\u0027s progress.\n+      if (conf.getNumReduceTasks() \u003d\u003d 0) {\n+        mapPhase \u003d getProgress().addPhase(\"map\", 1.0f);\n+      } else {\n+        // If there are reducers then the entire attempt\u0027s progress will be \n+        // split between the map phase (67%) and the sort phase (33%).\n+        mapPhase \u003d getProgress().addPhase(\"map\", 0.667f);\n+        sortPhase  \u003d getProgress().addPhase(\"sort\", 0.333f);\n+      }\n+    }\n+    TaskReporter reporter \u003d startReporter(umbilical);\n+ \n+    boolean useNewApi \u003d job.getUseNewMapper();\n+    initialize(job, getJobID(), reporter, useNewApi);\n+\n+    // check if it is a cleanupJobTask\n+    if (jobCleanup) {\n+      runJobCleanupTask(umbilical, reporter);\n+      return;\n+    }\n+    if (jobSetup) {\n+      runJobSetupTask(umbilical, reporter);\n+      return;\n+    }\n+    if (taskCleanup) {\n+      runTaskCleanupTask(umbilical, reporter);\n+      return;\n+    }\n+\n+    if (useNewApi) {\n+      runNewMapper(job, splitMetaInfo, umbilical, reporter);\n+    } else {\n+      runOldMapper(job, splitMetaInfo, umbilical, reporter);\n+    }\n+    done(umbilical, reporter);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void run(final JobConf job, final TaskUmbilicalProtocol umbilical)\n    throws IOException, ClassNotFoundException, InterruptedException {\n    this.umbilical \u003d umbilical;\n\n    if (isMapTask()) {\n      // If there are no reducers then there won\u0027t be any sort. Hence the map \n      // phase will govern the entire attempt\u0027s progress.\n      if (conf.getNumReduceTasks() \u003d\u003d 0) {\n        mapPhase \u003d getProgress().addPhase(\"map\", 1.0f);\n      } else {\n        // If there are reducers then the entire attempt\u0027s progress will be \n        // split between the map phase (67%) and the sort phase (33%).\n        mapPhase \u003d getProgress().addPhase(\"map\", 0.667f);\n        sortPhase  \u003d getProgress().addPhase(\"sort\", 0.333f);\n      }\n    }\n    TaskReporter reporter \u003d startReporter(umbilical);\n \n    boolean useNewApi \u003d job.getUseNewMapper();\n    initialize(job, getJobID(), reporter, useNewApi);\n\n    // check if it is a cleanupJobTask\n    if (jobCleanup) {\n      runJobCleanupTask(umbilical, reporter);\n      return;\n    }\n    if (jobSetup) {\n      runJobSetupTask(umbilical, reporter);\n      return;\n    }\n    if (taskCleanup) {\n      runTaskCleanupTask(umbilical, reporter);\n      return;\n    }\n\n    if (useNewApi) {\n      runNewMapper(job, splitMetaInfo, umbilical, reporter);\n    } else {\n      runOldMapper(job, splitMetaInfo, umbilical, reporter);\n    }\n    done(umbilical, reporter);\n  }",
      "path": "mapreduce/src/java/org/apache/hadoop/mapred/MapTask.java"
    }
  }
}