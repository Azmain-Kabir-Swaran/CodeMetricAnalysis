{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "WebHdfsFileSystem.java",
  "functionName": "connect",
  "functionId": "connect___url-URL",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
  "functionStartLine": 698,
  "functionEndLine": 743,
  "numCommitsSeen": 258,
  "timeTaken": 5112,
  "changeHistory": [
    "867048c3e4b20ece0039a876def129fa5eb9234f",
    "bcf89ddc7d52e04725caf104f5958e33d9f51b35",
    "7c18f8d55b899dc4a6e118d3b54447a9b36b960a",
    "e4ee1d111be15ae6cca2f79be7ca73c204288d2b",
    "53cb787d48eead93bfa47faac469d88ec464146a",
    "cb787968c5deac3dd5d10291aae39c36656a1487"
  ],
  "changeHistoryShort": {
    "867048c3e4b20ece0039a876def129fa5eb9234f": "Ymultichange(Ymodifierchange,Ybodychange)",
    "bcf89ddc7d52e04725caf104f5958e33d9f51b35": "Yfilerename",
    "7c18f8d55b899dc4a6e118d3b54447a9b36b960a": "Ybodychange",
    "e4ee1d111be15ae6cca2f79be7ca73c204288d2b": "Ymultichange(Yparameterchange,Yreturntypechange,Ybodychange)",
    "53cb787d48eead93bfa47faac469d88ec464146a": "Ybodychange",
    "cb787968c5deac3dd5d10291aae39c36656a1487": "Yintroduced"
  },
  "changeHistoryDetails": {
    "867048c3e4b20ece0039a876def129fa5eb9234f": {
      "type": "Ymultichange(Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-7163. WebHdfsFileSystem should retry reads according to the configured retry policy. Contributed by Eric Payne.\n",
      "commitDate": "22/12/15 12:08 PM",
      "commitName": "867048c3e4b20ece0039a876def129fa5eb9234f",
      "commitAuthor": "Kihwal Lee",
      "subchanges": [
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-7163. WebHdfsFileSystem should retry reads according to the configured retry policy. Contributed by Eric Payne.\n",
          "commitDate": "22/12/15 12:08 PM",
          "commitName": "867048c3e4b20ece0039a876def129fa5eb9234f",
          "commitAuthor": "Kihwal Lee",
          "commitDateOld": "11/12/15 10:59 AM",
          "commitNameOld": "576b569b6c97bd5f57e52efdabdf8c2fa996a524",
          "commitAuthorOld": "Allen Wittenauer",
          "daysBetweenCommits": 11.05,
          "commitsBetweenForRepo": 77,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,36 +1,12 @@\n-    private HttpURLConnection connect(URL url) throws IOException {\n-      //redirect hostname and port\n-      String redirectHost \u003d null;\n-\n-\n-      // resolve redirects for a DN operation unless already resolved\n-      if (op.getRedirect() \u0026\u0026 !redirected) {\n-        final HttpOpParam.Op redirectOp \u003d\n-            HttpOpParam.TemporaryRedirectOp.valueOf(op);\n-        final HttpURLConnection conn \u003d connect(redirectOp, url);\n-        // application level proxy like httpfs might not issue a redirect\n-        if (conn.getResponseCode() \u003d\u003d op.getExpectedHttpResponseCode()) {\n-          return conn;\n-        }\n+    protected HttpURLConnection connect(URL url) throws IOException {\n+      HttpURLConnection conn \u003d cachedConnection;\n+      if (conn \u003d\u003d null) {\n         try {\n-          validateResponse(redirectOp, conn, false);\n-          url \u003d new URL(conn.getHeaderField(\"Location\"));\n-          redirectHost \u003d url.getHost() + \":\" + url.getPort();\n-        } finally {\n-          conn.disconnect();\n+          conn \u003d super.connect(url);\n+        } catch (IOException e) {\n+          closeInputStream(RunnerState.DISCONNECTED);\n+          throw e;\n         }\n       }\n-      try {\n-        return connect(op, url);\n-      } catch (IOException ioe) {\n-        if (redirectHost !\u003d null) {\n-          if (excludeDatanodes.getValue() !\u003d null) {\n-            excludeDatanodes \u003d new ExcludeDatanodesParam(redirectHost + \",\"\n-                + excludeDatanodes.getValue());\n-          } else {\n-            excludeDatanodes \u003d new ExcludeDatanodesParam(redirectHost);\n-          }\n-        }\n-        throw ioe;\n-      }\n+      return conn;\n     }\n\\ No newline at end of file\n",
          "actualSource": "    protected HttpURLConnection connect(URL url) throws IOException {\n      HttpURLConnection conn \u003d cachedConnection;\n      if (conn \u003d\u003d null) {\n        try {\n          conn \u003d super.connect(url);\n        } catch (IOException e) {\n          closeInputStream(RunnerState.DISCONNECTED);\n          throw e;\n        }\n      }\n      return conn;\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
          "extendedDetails": {
            "oldValue": "[private]",
            "newValue": "[protected]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7163. WebHdfsFileSystem should retry reads according to the configured retry policy. Contributed by Eric Payne.\n",
          "commitDate": "22/12/15 12:08 PM",
          "commitName": "867048c3e4b20ece0039a876def129fa5eb9234f",
          "commitAuthor": "Kihwal Lee",
          "commitDateOld": "11/12/15 10:59 AM",
          "commitNameOld": "576b569b6c97bd5f57e52efdabdf8c2fa996a524",
          "commitAuthorOld": "Allen Wittenauer",
          "daysBetweenCommits": 11.05,
          "commitsBetweenForRepo": 77,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,36 +1,12 @@\n-    private HttpURLConnection connect(URL url) throws IOException {\n-      //redirect hostname and port\n-      String redirectHost \u003d null;\n-\n-\n-      // resolve redirects for a DN operation unless already resolved\n-      if (op.getRedirect() \u0026\u0026 !redirected) {\n-        final HttpOpParam.Op redirectOp \u003d\n-            HttpOpParam.TemporaryRedirectOp.valueOf(op);\n-        final HttpURLConnection conn \u003d connect(redirectOp, url);\n-        // application level proxy like httpfs might not issue a redirect\n-        if (conn.getResponseCode() \u003d\u003d op.getExpectedHttpResponseCode()) {\n-          return conn;\n-        }\n+    protected HttpURLConnection connect(URL url) throws IOException {\n+      HttpURLConnection conn \u003d cachedConnection;\n+      if (conn \u003d\u003d null) {\n         try {\n-          validateResponse(redirectOp, conn, false);\n-          url \u003d new URL(conn.getHeaderField(\"Location\"));\n-          redirectHost \u003d url.getHost() + \":\" + url.getPort();\n-        } finally {\n-          conn.disconnect();\n+          conn \u003d super.connect(url);\n+        } catch (IOException e) {\n+          closeInputStream(RunnerState.DISCONNECTED);\n+          throw e;\n         }\n       }\n-      try {\n-        return connect(op, url);\n-      } catch (IOException ioe) {\n-        if (redirectHost !\u003d null) {\n-          if (excludeDatanodes.getValue() !\u003d null) {\n-            excludeDatanodes \u003d new ExcludeDatanodesParam(redirectHost + \",\"\n-                + excludeDatanodes.getValue());\n-          } else {\n-            excludeDatanodes \u003d new ExcludeDatanodesParam(redirectHost);\n-          }\n-        }\n-        throw ioe;\n-      }\n+      return conn;\n     }\n\\ No newline at end of file\n",
          "actualSource": "    protected HttpURLConnection connect(URL url) throws IOException {\n      HttpURLConnection conn \u003d cachedConnection;\n      if (conn \u003d\u003d null) {\n        try {\n          conn \u003d super.connect(url);\n        } catch (IOException e) {\n          closeInputStream(RunnerState.DISCONNECTED);\n          throw e;\n        }\n      }\n      return conn;\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
          "extendedDetails": {}
        }
      ]
    },
    "bcf89ddc7d52e04725caf104f5958e33d9f51b35": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8052. Move WebHdfsFileSystem into hadoop-hdfs-client. Contributed by Haohui Mai.\n",
      "commitDate": "23/04/15 5:33 PM",
      "commitName": "bcf89ddc7d52e04725caf104f5958e33d9f51b35",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "23/04/15 4:40 PM",
      "commitNameOld": "0b3f8957a87ada1a275c9904b211fdbdcefafb02",
      "commitAuthorOld": "Xuan",
      "daysBetweenCommits": 0.04,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,36 +1,36 @@\n     private HttpURLConnection connect(URL url) throws IOException {\n       //redirect hostname and port\n       String redirectHost \u003d null;\n \n-      \n+\n       // resolve redirects for a DN operation unless already resolved\n       if (op.getRedirect() \u0026\u0026 !redirected) {\n         final HttpOpParam.Op redirectOp \u003d\n             HttpOpParam.TemporaryRedirectOp.valueOf(op);\n         final HttpURLConnection conn \u003d connect(redirectOp, url);\n         // application level proxy like httpfs might not issue a redirect\n         if (conn.getResponseCode() \u003d\u003d op.getExpectedHttpResponseCode()) {\n           return conn;\n         }\n         try {\n           validateResponse(redirectOp, conn, false);\n           url \u003d new URL(conn.getHeaderField(\"Location\"));\n           redirectHost \u003d url.getHost() + \":\" + url.getPort();\n         } finally {\n           conn.disconnect();\n         }\n       }\n       try {\n         return connect(op, url);\n       } catch (IOException ioe) {\n         if (redirectHost !\u003d null) {\n           if (excludeDatanodes.getValue() !\u003d null) {\n             excludeDatanodes \u003d new ExcludeDatanodesParam(redirectHost + \",\"\n                 + excludeDatanodes.getValue());\n           } else {\n             excludeDatanodes \u003d new ExcludeDatanodesParam(redirectHost);\n           }\n         }\n         throw ioe;\n-      }      \n+      }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private HttpURLConnection connect(URL url) throws IOException {\n      //redirect hostname and port\n      String redirectHost \u003d null;\n\n\n      // resolve redirects for a DN operation unless already resolved\n      if (op.getRedirect() \u0026\u0026 !redirected) {\n        final HttpOpParam.Op redirectOp \u003d\n            HttpOpParam.TemporaryRedirectOp.valueOf(op);\n        final HttpURLConnection conn \u003d connect(redirectOp, url);\n        // application level proxy like httpfs might not issue a redirect\n        if (conn.getResponseCode() \u003d\u003d op.getExpectedHttpResponseCode()) {\n          return conn;\n        }\n        try {\n          validateResponse(redirectOp, conn, false);\n          url \u003d new URL(conn.getHeaderField(\"Location\"));\n          redirectHost \u003d url.getHost() + \":\" + url.getPort();\n        } finally {\n          conn.disconnect();\n        }\n      }\n      try {\n        return connect(op, url);\n      } catch (IOException ioe) {\n        if (redirectHost !\u003d null) {\n          if (excludeDatanodes.getValue() !\u003d null) {\n            excludeDatanodes \u003d new ExcludeDatanodesParam(redirectHost + \",\"\n                + excludeDatanodes.getValue());\n          } else {\n            excludeDatanodes \u003d new ExcludeDatanodesParam(redirectHost);\n          }\n        }\n        throw ioe;\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java"
      }
    },
    "7c18f8d55b899dc4a6e118d3b54447a9b36b960a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6616. Add exclude-datanodes feature to WebHDFS redirection so that it will not redirect retries to the same datanode. Contributed by zhaoyunjiong\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1611750 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/07/14 11:20 AM",
      "commitName": "7c18f8d55b899dc4a6e118d3b54447a9b36b960a",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "17/07/14 4:11 PM",
      "commitNameOld": "7ba5913797c49d5001ad95558eadd119c3361060",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 0.8,
      "commitsBetweenForRepo": 12,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,19 +1,36 @@\n     private HttpURLConnection connect(URL url) throws IOException {\n+      //redirect hostname and port\n+      String redirectHost \u003d null;\n+\n+      \n       // resolve redirects for a DN operation unless already resolved\n       if (op.getRedirect() \u0026\u0026 !redirected) {\n         final HttpOpParam.Op redirectOp \u003d\n             HttpOpParam.TemporaryRedirectOp.valueOf(op);\n         final HttpURLConnection conn \u003d connect(redirectOp, url);\n         // application level proxy like httpfs might not issue a redirect\n         if (conn.getResponseCode() \u003d\u003d op.getExpectedHttpResponseCode()) {\n           return conn;\n         }\n         try {\n           validateResponse(redirectOp, conn, false);\n           url \u003d new URL(conn.getHeaderField(\"Location\"));\n+          redirectHost \u003d url.getHost() + \":\" + url.getPort();\n         } finally {\n           conn.disconnect();\n         }\n       }\n-      return connect(op, url);\n+      try {\n+        return connect(op, url);\n+      } catch (IOException ioe) {\n+        if (redirectHost !\u003d null) {\n+          if (excludeDatanodes.getValue() !\u003d null) {\n+            excludeDatanodes \u003d new ExcludeDatanodesParam(redirectHost + \",\"\n+                + excludeDatanodes.getValue());\n+          } else {\n+            excludeDatanodes \u003d new ExcludeDatanodesParam(redirectHost);\n+          }\n+        }\n+        throw ioe;\n+      }      \n     }\n\\ No newline at end of file\n",
      "actualSource": "    private HttpURLConnection connect(URL url) throws IOException {\n      //redirect hostname and port\n      String redirectHost \u003d null;\n\n      \n      // resolve redirects for a DN operation unless already resolved\n      if (op.getRedirect() \u0026\u0026 !redirected) {\n        final HttpOpParam.Op redirectOp \u003d\n            HttpOpParam.TemporaryRedirectOp.valueOf(op);\n        final HttpURLConnection conn \u003d connect(redirectOp, url);\n        // application level proxy like httpfs might not issue a redirect\n        if (conn.getResponseCode() \u003d\u003d op.getExpectedHttpResponseCode()) {\n          return conn;\n        }\n        try {\n          validateResponse(redirectOp, conn, false);\n          url \u003d new URL(conn.getHeaderField(\"Location\"));\n          redirectHost \u003d url.getHost() + \":\" + url.getPort();\n        } finally {\n          conn.disconnect();\n        }\n      }\n      try {\n        return connect(op, url);\n      } catch (IOException ioe) {\n        if (redirectHost !\u003d null) {\n          if (excludeDatanodes.getValue() !\u003d null) {\n            excludeDatanodes \u003d new ExcludeDatanodesParam(redirectHost + \",\"\n                + excludeDatanodes.getValue());\n          } else {\n            excludeDatanodes \u003d new ExcludeDatanodesParam(redirectHost);\n          }\n        }\n        throw ioe;\n      }      \n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
      "extendedDetails": {}
    },
    "e4ee1d111be15ae6cca2f79be7ca73c204288d2b": {
      "type": "Ymultichange(Yparameterchange,Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-6305. WebHdfs response decoding may throw RuntimeExceptions (Daryn Sharp via jeagles)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1594273 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/05/14 9:40 AM",
      "commitName": "e4ee1d111be15ae6cca2f79be7ca73c204288d2b",
      "commitAuthor": "Jonathan Turner Eagles",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-6305. WebHdfs response decoding may throw RuntimeExceptions (Daryn Sharp via jeagles)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1594273 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "13/05/14 9:40 AM",
          "commitName": "e4ee1d111be15ae6cca2f79be7ca73c204288d2b",
          "commitAuthor": "Jonathan Turner Eagles",
          "commitDateOld": "13/05/14 9:19 AM",
          "commitNameOld": "33ade356b35223654a077103ed7fbed89f3f2321",
          "commitAuthorOld": "Kihwal Lee",
          "daysBetweenCommits": 0.01,
          "commitsBetweenForRepo": 2,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,23 +1,19 @@\n-    private void connect(boolean doOutput) throws IOException {\n-      conn.setRequestMethod(op.getType().toString());\n-      conn.setInstanceFollowRedirects(false);\n-      switch (op.getType()) {\n-        // if not sending a message body for a POST or PUT operation, need\n-        // to ensure the server/proxy knows this \n-        case POST:\n-        case PUT: {\n-          conn.setDoOutput(true);\n-          if (!doOutput) {\n-            // explicitly setting content-length to 0 won\u0027t do spnego!!\n-            // opening and closing the stream will send \"Content-Length: 0\"\n-            conn.getOutputStream().close();\n-          }\n-          break;\n+    private HttpURLConnection connect(URL url) throws IOException {\n+      // resolve redirects for a DN operation unless already resolved\n+      if (op.getRedirect() \u0026\u0026 !redirected) {\n+        final HttpOpParam.Op redirectOp \u003d\n+            HttpOpParam.TemporaryRedirectOp.valueOf(op);\n+        final HttpURLConnection conn \u003d connect(redirectOp, url);\n+        // application level proxy like httpfs might not issue a redirect\n+        if (conn.getResponseCode() \u003d\u003d op.getExpectedHttpResponseCode()) {\n+          return conn;\n         }\n-        default: {\n-          conn.setDoOutput(doOutput);\n-          break;\n+        try {\n+          validateResponse(redirectOp, conn, false);\n+          url \u003d new URL(conn.getHeaderField(\"Location\"));\n+        } finally {\n+          conn.disconnect();\n         }\n       }\n-      conn.connect();\n+      return connect(op, url);\n     }\n\\ No newline at end of file\n",
          "actualSource": "    private HttpURLConnection connect(URL url) throws IOException {\n      // resolve redirects for a DN operation unless already resolved\n      if (op.getRedirect() \u0026\u0026 !redirected) {\n        final HttpOpParam.Op redirectOp \u003d\n            HttpOpParam.TemporaryRedirectOp.valueOf(op);\n        final HttpURLConnection conn \u003d connect(redirectOp, url);\n        // application level proxy like httpfs might not issue a redirect\n        if (conn.getResponseCode() \u003d\u003d op.getExpectedHttpResponseCode()) {\n          return conn;\n        }\n        try {\n          validateResponse(redirectOp, conn, false);\n          url \u003d new URL(conn.getHeaderField(\"Location\"));\n        } finally {\n          conn.disconnect();\n        }\n      }\n      return connect(op, url);\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
          "extendedDetails": {
            "oldValue": "[doOutput-boolean]",
            "newValue": "[url-URL]"
          }
        },
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-6305. WebHdfs response decoding may throw RuntimeExceptions (Daryn Sharp via jeagles)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1594273 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "13/05/14 9:40 AM",
          "commitName": "e4ee1d111be15ae6cca2f79be7ca73c204288d2b",
          "commitAuthor": "Jonathan Turner Eagles",
          "commitDateOld": "13/05/14 9:19 AM",
          "commitNameOld": "33ade356b35223654a077103ed7fbed89f3f2321",
          "commitAuthorOld": "Kihwal Lee",
          "daysBetweenCommits": 0.01,
          "commitsBetweenForRepo": 2,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,23 +1,19 @@\n-    private void connect(boolean doOutput) throws IOException {\n-      conn.setRequestMethod(op.getType().toString());\n-      conn.setInstanceFollowRedirects(false);\n-      switch (op.getType()) {\n-        // if not sending a message body for a POST or PUT operation, need\n-        // to ensure the server/proxy knows this \n-        case POST:\n-        case PUT: {\n-          conn.setDoOutput(true);\n-          if (!doOutput) {\n-            // explicitly setting content-length to 0 won\u0027t do spnego!!\n-            // opening and closing the stream will send \"Content-Length: 0\"\n-            conn.getOutputStream().close();\n-          }\n-          break;\n+    private HttpURLConnection connect(URL url) throws IOException {\n+      // resolve redirects for a DN operation unless already resolved\n+      if (op.getRedirect() \u0026\u0026 !redirected) {\n+        final HttpOpParam.Op redirectOp \u003d\n+            HttpOpParam.TemporaryRedirectOp.valueOf(op);\n+        final HttpURLConnection conn \u003d connect(redirectOp, url);\n+        // application level proxy like httpfs might not issue a redirect\n+        if (conn.getResponseCode() \u003d\u003d op.getExpectedHttpResponseCode()) {\n+          return conn;\n         }\n-        default: {\n-          conn.setDoOutput(doOutput);\n-          break;\n+        try {\n+          validateResponse(redirectOp, conn, false);\n+          url \u003d new URL(conn.getHeaderField(\"Location\"));\n+        } finally {\n+          conn.disconnect();\n         }\n       }\n-      conn.connect();\n+      return connect(op, url);\n     }\n\\ No newline at end of file\n",
          "actualSource": "    private HttpURLConnection connect(URL url) throws IOException {\n      // resolve redirects for a DN operation unless already resolved\n      if (op.getRedirect() \u0026\u0026 !redirected) {\n        final HttpOpParam.Op redirectOp \u003d\n            HttpOpParam.TemporaryRedirectOp.valueOf(op);\n        final HttpURLConnection conn \u003d connect(redirectOp, url);\n        // application level proxy like httpfs might not issue a redirect\n        if (conn.getResponseCode() \u003d\u003d op.getExpectedHttpResponseCode()) {\n          return conn;\n        }\n        try {\n          validateResponse(redirectOp, conn, false);\n          url \u003d new URL(conn.getHeaderField(\"Location\"));\n        } finally {\n          conn.disconnect();\n        }\n      }\n      return connect(op, url);\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
          "extendedDetails": {
            "oldValue": "void",
            "newValue": "HttpURLConnection"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-6305. WebHdfs response decoding may throw RuntimeExceptions (Daryn Sharp via jeagles)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1594273 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "13/05/14 9:40 AM",
          "commitName": "e4ee1d111be15ae6cca2f79be7ca73c204288d2b",
          "commitAuthor": "Jonathan Turner Eagles",
          "commitDateOld": "13/05/14 9:19 AM",
          "commitNameOld": "33ade356b35223654a077103ed7fbed89f3f2321",
          "commitAuthorOld": "Kihwal Lee",
          "daysBetweenCommits": 0.01,
          "commitsBetweenForRepo": 2,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,23 +1,19 @@\n-    private void connect(boolean doOutput) throws IOException {\n-      conn.setRequestMethod(op.getType().toString());\n-      conn.setInstanceFollowRedirects(false);\n-      switch (op.getType()) {\n-        // if not sending a message body for a POST or PUT operation, need\n-        // to ensure the server/proxy knows this \n-        case POST:\n-        case PUT: {\n-          conn.setDoOutput(true);\n-          if (!doOutput) {\n-            // explicitly setting content-length to 0 won\u0027t do spnego!!\n-            // opening and closing the stream will send \"Content-Length: 0\"\n-            conn.getOutputStream().close();\n-          }\n-          break;\n+    private HttpURLConnection connect(URL url) throws IOException {\n+      // resolve redirects for a DN operation unless already resolved\n+      if (op.getRedirect() \u0026\u0026 !redirected) {\n+        final HttpOpParam.Op redirectOp \u003d\n+            HttpOpParam.TemporaryRedirectOp.valueOf(op);\n+        final HttpURLConnection conn \u003d connect(redirectOp, url);\n+        // application level proxy like httpfs might not issue a redirect\n+        if (conn.getResponseCode() \u003d\u003d op.getExpectedHttpResponseCode()) {\n+          return conn;\n         }\n-        default: {\n-          conn.setDoOutput(doOutput);\n-          break;\n+        try {\n+          validateResponse(redirectOp, conn, false);\n+          url \u003d new URL(conn.getHeaderField(\"Location\"));\n+        } finally {\n+          conn.disconnect();\n         }\n       }\n-      conn.connect();\n+      return connect(op, url);\n     }\n\\ No newline at end of file\n",
          "actualSource": "    private HttpURLConnection connect(URL url) throws IOException {\n      // resolve redirects for a DN operation unless already resolved\n      if (op.getRedirect() \u0026\u0026 !redirected) {\n        final HttpOpParam.Op redirectOp \u003d\n            HttpOpParam.TemporaryRedirectOp.valueOf(op);\n        final HttpURLConnection conn \u003d connect(redirectOp, url);\n        // application level proxy like httpfs might not issue a redirect\n        if (conn.getResponseCode() \u003d\u003d op.getExpectedHttpResponseCode()) {\n          return conn;\n        }\n        try {\n          validateResponse(redirectOp, conn, false);\n          url \u003d new URL(conn.getHeaderField(\"Location\"));\n        } finally {\n          conn.disconnect();\n        }\n      }\n      return connect(op, url);\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
          "extendedDetails": {}
        }
      ]
    },
    "53cb787d48eead93bfa47faac469d88ec464146a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6217. Webhdfs PUT operations may not work via a http proxy. Contributed by Daryn Sharp.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1589528 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "23/04/14 3:00 PM",
      "commitName": "53cb787d48eead93bfa47faac469d88ec464146a",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "07/04/14 6:39 PM",
      "commitNameOld": "bcf1f33acdb7b602998b6e99277d6e78e78745da",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 15.85,
      "commitsBetweenForRepo": 109,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,6 +1,23 @@\n     private void connect(boolean doOutput) throws IOException {\n       conn.setRequestMethod(op.getType().toString());\n-      conn.setDoOutput(doOutput);\n       conn.setInstanceFollowRedirects(false);\n+      switch (op.getType()) {\n+        // if not sending a message body for a POST or PUT operation, need\n+        // to ensure the server/proxy knows this \n+        case POST:\n+        case PUT: {\n+          conn.setDoOutput(true);\n+          if (!doOutput) {\n+            // explicitly setting content-length to 0 won\u0027t do spnego!!\n+            // opening and closing the stream will send \"Content-Length: 0\"\n+            conn.getOutputStream().close();\n+          }\n+          break;\n+        }\n+        default: {\n+          conn.setDoOutput(doOutput);\n+          break;\n+        }\n+      }\n       conn.connect();\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void connect(boolean doOutput) throws IOException {\n      conn.setRequestMethod(op.getType().toString());\n      conn.setInstanceFollowRedirects(false);\n      switch (op.getType()) {\n        // if not sending a message body for a POST or PUT operation, need\n        // to ensure the server/proxy knows this \n        case POST:\n        case PUT: {\n          conn.setDoOutput(true);\n          if (!doOutput) {\n            // explicitly setting content-length to 0 won\u0027t do spnego!!\n            // opening and closing the stream will send \"Content-Length: 0\"\n            conn.getOutputStream().close();\n          }\n          break;\n        }\n        default: {\n          conn.setDoOutput(doOutput);\n          break;\n        }\n      }\n      conn.connect();\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
      "extendedDetails": {}
    },
    "cb787968c5deac3dd5d10291aae39c36656a1487": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-3667.  Add retry support to WebHdfsFileSystem.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1367841 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "31/07/12 6:41 PM",
      "commitName": "cb787968c5deac3dd5d10291aae39c36656a1487",
      "commitAuthor": "Tsz-wo Sze",
      "diff": "@@ -0,0 +1,6 @@\n+    private void connect(boolean doOutput) throws IOException {\n+      conn.setRequestMethod(op.getType().toString());\n+      conn.setDoOutput(doOutput);\n+      conn.setInstanceFollowRedirects(false);\n+      conn.connect();\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    private void connect(boolean doOutput) throws IOException {\n      conn.setRequestMethod(op.getType().toString());\n      conn.setDoOutput(doOutput);\n      conn.setInstanceFollowRedirects(false);\n      conn.connect();\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java"
    }
  }
}