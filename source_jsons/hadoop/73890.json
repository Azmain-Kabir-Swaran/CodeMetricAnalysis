{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "Server.java",
  "functionName": "processOneRpc",
  "functionId": "processOneRpc___bb-ByteBuffer",
  "sourceFilePath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
  "functionStartLine": 2541,
  "functionEndLine": 2585,
  "numCommitsSeen": 323,
  "timeTaken": 9696,
  "changeHistory": [
    "07530314c2130ecd1525682c59bf51f15b82c024",
    "b6bb99c18a772d2179d5cc6757cddf141e8d39c0",
    "76cd81f4b656f0d40a4b2122e15f04ea53d8020b",
    "81485dbfc1ffb8daa609be8eb31094cc28646dd3",
    "d288a0ba8364d81aacda9f4a21022eecb6dc4e22",
    "580a8334963709e728ed677c815fb7fef9bca70e",
    "2d8227605fe22c1c05f31729edc8939013763c05",
    "e617cf6dd13f2bb5d7cbb15ee2cdb260ecd46cd3",
    "8724ceb2359af66c800043e665c17a2a30981c7d",
    "a3a9d72e98a9cc0f94af7c832dd13c408856636d",
    "725623534ce7ab20c28af6e0cdf57bd7278551dd",
    "7ae04652a6adf0f9d04b8702a7fe3b9790afa8b9",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "0f6dfeeacbab65a31a33927a4eb84871d371fe52",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
    "c4c122a0def592136e03a653c9fdc4f464ed0854",
    "ffdde40b9f189cb30dee4c5187d63b61809f2d62",
    "940389afce6a1b9b9e1519aed528cbc444786756",
    "0c5734e4aca873f405fbf994e5fe7061e31731c8",
    "ae93ba7501d95e9d26a29de25f4cc39e5225ca20",
    "5128a9a453d64bfe1ed978cf9ffed27985eeef36"
  ],
  "changeHistoryShort": {
    "07530314c2130ecd1525682c59bf51f15b82c024": "Ybodychange",
    "b6bb99c18a772d2179d5cc6757cddf141e8d39c0": "Ymultichange(Yexceptionschange,Ybodychange)",
    "76cd81f4b656f0d40a4b2122e15f04ea53d8020b": "Ybodychange",
    "81485dbfc1ffb8daa609be8eb31094cc28646dd3": "Ybodychange",
    "d288a0ba8364d81aacda9f4a21022eecb6dc4e22": "Ybodychange",
    "580a8334963709e728ed677c815fb7fef9bca70e": "Ymultichange(Yparameterchange,Ybodychange)",
    "2d8227605fe22c1c05f31729edc8939013763c05": "Ybodychange",
    "e617cf6dd13f2bb5d7cbb15ee2cdb260ecd46cd3": "Ybodychange",
    "8724ceb2359af66c800043e665c17a2a30981c7d": "Ybodychange",
    "a3a9d72e98a9cc0f94af7c832dd13c408856636d": "Ymultichange(Yexceptionschange,Ybodychange)",
    "725623534ce7ab20c28af6e0cdf57bd7278551dd": "Ybodychange",
    "7ae04652a6adf0f9d04b8702a7fe3b9790afa8b9": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "0f6dfeeacbab65a31a33927a4eb84871d371fe52": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yfilerename",
    "c4c122a0def592136e03a653c9fdc4f464ed0854": "Ybodychange",
    "ffdde40b9f189cb30dee4c5187d63b61809f2d62": "Ybodychange",
    "940389afce6a1b9b9e1519aed528cbc444786756": "Ymultichange(Yrename,Yparameterchange,Yexceptionschange,Ybodychange)",
    "0c5734e4aca873f405fbf994e5fe7061e31731c8": "Ybodychange",
    "ae93ba7501d95e9d26a29de25f4cc39e5225ca20": "Ybodychange",
    "5128a9a453d64bfe1ed978cf9ffed27985eeef36": "Yintroduced"
  },
  "changeHistoryDetails": {
    "07530314c2130ecd1525682c59bf51f15b82c024": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-9844. NPE when trying to create an error message response of SASL RPC\n\nThis closes #55\n\nChange-Id: I10a20380565fa89762f4aa564b2f1c83b9aeecdc\nSigned-off-by: Akira Ajisaka \u003caajisaka@apache.org\u003e\n",
      "commitDate": "26/07/19 1:53 AM",
      "commitName": "07530314c2130ecd1525682c59bf51f15b82c024",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "18/06/19 9:58 AM",
      "commitNameOld": "3ab77d9bc9eacfdb218b68988235a921c810b0d1",
      "commitAuthorOld": "Inigo Goiri",
      "daysBetweenCommits": 37.66,
      "commitsBetweenForRepo": 315,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,44 +1,45 @@\n     private void processOneRpc(ByteBuffer bb)\n         throws IOException, InterruptedException {\n       // exceptions that escape this method are fatal to the connection.\n       // setupResponse will use the rpc status to determine if the connection\n       // should be closed.\n       int callId \u003d -1;\n       int retry \u003d RpcConstants.INVALID_RETRY_COUNT;\n       try {\n         final RpcWritable.Buffer buffer \u003d RpcWritable.Buffer.wrap(bb);\n         final RpcRequestHeaderProto header \u003d\n             getMessage(RpcRequestHeaderProto.getDefaultInstance(), buffer);\n         callId \u003d header.getCallId();\n         retry \u003d header.getRetryCount();\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\" got #\" + callId);\n         }\n         checkRpcHeaders(header);\n \n         if (callId \u003c 0) { // callIds typically used during connection setup\n           processRpcOutOfBandRequest(header, buffer);\n         } else if (!connectionContextRead) {\n           throw new FatalRpcServerException(\n               RpcErrorCodeProto.FATAL_INVALID_RPC_HEADER,\n               \"Connection context not established\");\n         } else {\n           processRpcRequest(header, buffer);\n         }\n       } catch (RpcServerException rse) {\n         // inform client of error, but do not rethrow else non-fatal\n         // exceptions will close connection!\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(Thread.currentThread().getName() +\n               \": processOneRpc from client \" + this +\n               \" threw exception [\" + rse + \"]\");\n         }\n         // use the wrapped exception if there is one.\n         Throwable t \u003d (rse.getCause() !\u003d null) ? rse.getCause() : rse;\n         final RpcCall call \u003d new RpcCall(this, callId, retry);\n         setupResponse(call,\n             rse.getRpcStatusProto(), rse.getRpcErrorCodeProto(), null,\n-            t.getClass().getName(), t.getMessage());\n+            t.getClass().getName(),\n+            t.getMessage() !\u003d null ? t.getMessage() : t.toString());\n         sendResponse(call);\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void processOneRpc(ByteBuffer bb)\n        throws IOException, InterruptedException {\n      // exceptions that escape this method are fatal to the connection.\n      // setupResponse will use the rpc status to determine if the connection\n      // should be closed.\n      int callId \u003d -1;\n      int retry \u003d RpcConstants.INVALID_RETRY_COUNT;\n      try {\n        final RpcWritable.Buffer buffer \u003d RpcWritable.Buffer.wrap(bb);\n        final RpcRequestHeaderProto header \u003d\n            getMessage(RpcRequestHeaderProto.getDefaultInstance(), buffer);\n        callId \u003d header.getCallId();\n        retry \u003d header.getRetryCount();\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\" got #\" + callId);\n        }\n        checkRpcHeaders(header);\n\n        if (callId \u003c 0) { // callIds typically used during connection setup\n          processRpcOutOfBandRequest(header, buffer);\n        } else if (!connectionContextRead) {\n          throw new FatalRpcServerException(\n              RpcErrorCodeProto.FATAL_INVALID_RPC_HEADER,\n              \"Connection context not established\");\n        } else {\n          processRpcRequest(header, buffer);\n        }\n      } catch (RpcServerException rse) {\n        // inform client of error, but do not rethrow else non-fatal\n        // exceptions will close connection!\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(Thread.currentThread().getName() +\n              \": processOneRpc from client \" + this +\n              \" threw exception [\" + rse + \"]\");\n        }\n        // use the wrapped exception if there is one.\n        Throwable t \u003d (rse.getCause() !\u003d null) ? rse.getCause() : rse;\n        final RpcCall call \u003d new RpcCall(this, callId, retry);\n        setupResponse(call,\n            rse.getRpcStatusProto(), rse.getRpcErrorCodeProto(), null,\n            t.getClass().getName(),\n            t.getMessage() !\u003d null ? t.getMessage() : t.toString());\n        sendResponse(call);\n      }\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {}
    },
    "b6bb99c18a772d2179d5cc6757cddf141e8d39c0": {
      "type": "Ymultichange(Yexceptionschange,Ybodychange)",
      "commitMessage": "HADOOP-14034. Allow ipc layer exceptions to selectively close connections. Contributed by Daryn Sharp.\n",
      "commitDate": "09/02/17 8:47 AM",
      "commitName": "b6bb99c18a772d2179d5cc6757cddf141e8d39c0",
      "commitAuthor": "Kihwal Lee",
      "subchanges": [
        {
          "type": "Yexceptionschange",
          "commitMessage": "HADOOP-14034. Allow ipc layer exceptions to selectively close connections. Contributed by Daryn Sharp.\n",
          "commitDate": "09/02/17 8:47 AM",
          "commitName": "b6bb99c18a772d2179d5cc6757cddf141e8d39c0",
          "commitAuthor": "Kihwal Lee",
          "commitDateOld": "28/11/16 9:07 PM",
          "commitNameOld": "67d9f2808efb34b9a7b0b824cb4033b95ad33474",
          "commitAuthorOld": "Akira Ajisaka",
          "daysBetweenCommits": 72.49,
          "commitsBetweenForRepo": 352,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,34 +1,44 @@\n     private void processOneRpc(ByteBuffer bb)\n-        throws IOException, WrappedRpcServerException, InterruptedException {\n+        throws IOException, InterruptedException {\n+      // exceptions that escape this method are fatal to the connection.\n+      // setupResponse will use the rpc status to determine if the connection\n+      // should be closed.\n       int callId \u003d -1;\n       int retry \u003d RpcConstants.INVALID_RETRY_COUNT;\n       try {\n         final RpcWritable.Buffer buffer \u003d RpcWritable.Buffer.wrap(bb);\n         final RpcRequestHeaderProto header \u003d\n             getMessage(RpcRequestHeaderProto.getDefaultInstance(), buffer);\n         callId \u003d header.getCallId();\n         retry \u003d header.getRetryCount();\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\" got #\" + callId);\n         }\n         checkRpcHeaders(header);\n \n         if (callId \u003c 0) { // callIds typically used during connection setup\n           processRpcOutOfBandRequest(header, buffer);\n         } else if (!connectionContextRead) {\n-          throw new WrappedRpcServerException(\n+          throw new FatalRpcServerException(\n               RpcErrorCodeProto.FATAL_INVALID_RPC_HEADER,\n               \"Connection context not established\");\n         } else {\n           processRpcRequest(header, buffer);\n         }\n-      } catch (WrappedRpcServerException wrse) { // inform client of error\n-        Throwable ioe \u003d wrse.getCause();\n+      } catch (RpcServerException rse) {\n+        // inform client of error, but do not rethrow else non-fatal\n+        // exceptions will close connection!\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(Thread.currentThread().getName() +\n+              \": processOneRpc from client \" + this +\n+              \" threw exception [\" + rse + \"]\");\n+        }\n+        // use the wrapped exception if there is one.\n+        Throwable t \u003d (rse.getCause() !\u003d null) ? rse.getCause() : rse;\n         final RpcCall call \u003d new RpcCall(this, callId, retry);\n         setupResponse(call,\n-            RpcStatusProto.FATAL, wrse.getRpcErrorCodeProto(), null,\n-            ioe.getClass().getName(), ioe.getMessage());\n-        call.sendResponse();\n-        throw wrse;\n+            rse.getRpcStatusProto(), rse.getRpcErrorCodeProto(), null,\n+            t.getClass().getName(), t.getMessage());\n+        sendResponse(call);\n       }\n     }\n\\ No newline at end of file\n",
          "actualSource": "    private void processOneRpc(ByteBuffer bb)\n        throws IOException, InterruptedException {\n      // exceptions that escape this method are fatal to the connection.\n      // setupResponse will use the rpc status to determine if the connection\n      // should be closed.\n      int callId \u003d -1;\n      int retry \u003d RpcConstants.INVALID_RETRY_COUNT;\n      try {\n        final RpcWritable.Buffer buffer \u003d RpcWritable.Buffer.wrap(bb);\n        final RpcRequestHeaderProto header \u003d\n            getMessage(RpcRequestHeaderProto.getDefaultInstance(), buffer);\n        callId \u003d header.getCallId();\n        retry \u003d header.getRetryCount();\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\" got #\" + callId);\n        }\n        checkRpcHeaders(header);\n\n        if (callId \u003c 0) { // callIds typically used during connection setup\n          processRpcOutOfBandRequest(header, buffer);\n        } else if (!connectionContextRead) {\n          throw new FatalRpcServerException(\n              RpcErrorCodeProto.FATAL_INVALID_RPC_HEADER,\n              \"Connection context not established\");\n        } else {\n          processRpcRequest(header, buffer);\n        }\n      } catch (RpcServerException rse) {\n        // inform client of error, but do not rethrow else non-fatal\n        // exceptions will close connection!\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(Thread.currentThread().getName() +\n              \": processOneRpc from client \" + this +\n              \" threw exception [\" + rse + \"]\");\n        }\n        // use the wrapped exception if there is one.\n        Throwable t \u003d (rse.getCause() !\u003d null) ? rse.getCause() : rse;\n        final RpcCall call \u003d new RpcCall(this, callId, retry);\n        setupResponse(call,\n            rse.getRpcStatusProto(), rse.getRpcErrorCodeProto(), null,\n            t.getClass().getName(), t.getMessage());\n        sendResponse(call);\n      }\n    }",
          "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
          "extendedDetails": {
            "oldValue": "[IOException, WrappedRpcServerException, InterruptedException]",
            "newValue": "[IOException, InterruptedException]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HADOOP-14034. Allow ipc layer exceptions to selectively close connections. Contributed by Daryn Sharp.\n",
          "commitDate": "09/02/17 8:47 AM",
          "commitName": "b6bb99c18a772d2179d5cc6757cddf141e8d39c0",
          "commitAuthor": "Kihwal Lee",
          "commitDateOld": "28/11/16 9:07 PM",
          "commitNameOld": "67d9f2808efb34b9a7b0b824cb4033b95ad33474",
          "commitAuthorOld": "Akira Ajisaka",
          "daysBetweenCommits": 72.49,
          "commitsBetweenForRepo": 352,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,34 +1,44 @@\n     private void processOneRpc(ByteBuffer bb)\n-        throws IOException, WrappedRpcServerException, InterruptedException {\n+        throws IOException, InterruptedException {\n+      // exceptions that escape this method are fatal to the connection.\n+      // setupResponse will use the rpc status to determine if the connection\n+      // should be closed.\n       int callId \u003d -1;\n       int retry \u003d RpcConstants.INVALID_RETRY_COUNT;\n       try {\n         final RpcWritable.Buffer buffer \u003d RpcWritable.Buffer.wrap(bb);\n         final RpcRequestHeaderProto header \u003d\n             getMessage(RpcRequestHeaderProto.getDefaultInstance(), buffer);\n         callId \u003d header.getCallId();\n         retry \u003d header.getRetryCount();\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\" got #\" + callId);\n         }\n         checkRpcHeaders(header);\n \n         if (callId \u003c 0) { // callIds typically used during connection setup\n           processRpcOutOfBandRequest(header, buffer);\n         } else if (!connectionContextRead) {\n-          throw new WrappedRpcServerException(\n+          throw new FatalRpcServerException(\n               RpcErrorCodeProto.FATAL_INVALID_RPC_HEADER,\n               \"Connection context not established\");\n         } else {\n           processRpcRequest(header, buffer);\n         }\n-      } catch (WrappedRpcServerException wrse) { // inform client of error\n-        Throwable ioe \u003d wrse.getCause();\n+      } catch (RpcServerException rse) {\n+        // inform client of error, but do not rethrow else non-fatal\n+        // exceptions will close connection!\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(Thread.currentThread().getName() +\n+              \": processOneRpc from client \" + this +\n+              \" threw exception [\" + rse + \"]\");\n+        }\n+        // use the wrapped exception if there is one.\n+        Throwable t \u003d (rse.getCause() !\u003d null) ? rse.getCause() : rse;\n         final RpcCall call \u003d new RpcCall(this, callId, retry);\n         setupResponse(call,\n-            RpcStatusProto.FATAL, wrse.getRpcErrorCodeProto(), null,\n-            ioe.getClass().getName(), ioe.getMessage());\n-        call.sendResponse();\n-        throw wrse;\n+            rse.getRpcStatusProto(), rse.getRpcErrorCodeProto(), null,\n+            t.getClass().getName(), t.getMessage());\n+        sendResponse(call);\n       }\n     }\n\\ No newline at end of file\n",
          "actualSource": "    private void processOneRpc(ByteBuffer bb)\n        throws IOException, InterruptedException {\n      // exceptions that escape this method are fatal to the connection.\n      // setupResponse will use the rpc status to determine if the connection\n      // should be closed.\n      int callId \u003d -1;\n      int retry \u003d RpcConstants.INVALID_RETRY_COUNT;\n      try {\n        final RpcWritable.Buffer buffer \u003d RpcWritable.Buffer.wrap(bb);\n        final RpcRequestHeaderProto header \u003d\n            getMessage(RpcRequestHeaderProto.getDefaultInstance(), buffer);\n        callId \u003d header.getCallId();\n        retry \u003d header.getRetryCount();\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\" got #\" + callId);\n        }\n        checkRpcHeaders(header);\n\n        if (callId \u003c 0) { // callIds typically used during connection setup\n          processRpcOutOfBandRequest(header, buffer);\n        } else if (!connectionContextRead) {\n          throw new FatalRpcServerException(\n              RpcErrorCodeProto.FATAL_INVALID_RPC_HEADER,\n              \"Connection context not established\");\n        } else {\n          processRpcRequest(header, buffer);\n        }\n      } catch (RpcServerException rse) {\n        // inform client of error, but do not rethrow else non-fatal\n        // exceptions will close connection!\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(Thread.currentThread().getName() +\n              \": processOneRpc from client \" + this +\n              \" threw exception [\" + rse + \"]\");\n        }\n        // use the wrapped exception if there is one.\n        Throwable t \u003d (rse.getCause() !\u003d null) ? rse.getCause() : rse;\n        final RpcCall call \u003d new RpcCall(this, callId, retry);\n        setupResponse(call,\n            rse.getRpcStatusProto(), rse.getRpcErrorCodeProto(), null,\n            t.getClass().getName(), t.getMessage());\n        sendResponse(call);\n      }\n    }",
          "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
          "extendedDetails": {}
        }
      ]
    },
    "76cd81f4b656f0d40a4b2122e15f04ea53d8020b": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-13465. Design Server.Call to be extensible for unified call queue. Contributed by Daryn Sharp.\n",
      "commitDate": "01/09/16 1:44 PM",
      "commitName": "76cd81f4b656f0d40a4b2122e15f04ea53d8020b",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "25/08/16 2:04 PM",
      "commitNameOld": "81485dbfc1ffb8daa609be8eb31094cc28646dd3",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 6.99,
      "commitsBetweenForRepo": 39,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,34 +1,34 @@\n     private void processOneRpc(ByteBuffer bb)\n         throws IOException, WrappedRpcServerException, InterruptedException {\n       int callId \u003d -1;\n       int retry \u003d RpcConstants.INVALID_RETRY_COUNT;\n       try {\n         final RpcWritable.Buffer buffer \u003d RpcWritable.Buffer.wrap(bb);\n         final RpcRequestHeaderProto header \u003d\n             getMessage(RpcRequestHeaderProto.getDefaultInstance(), buffer);\n         callId \u003d header.getCallId();\n         retry \u003d header.getRetryCount();\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\" got #\" + callId);\n         }\n         checkRpcHeaders(header);\n \n         if (callId \u003c 0) { // callIds typically used during connection setup\n           processRpcOutOfBandRequest(header, buffer);\n         } else if (!connectionContextRead) {\n           throw new WrappedRpcServerException(\n               RpcErrorCodeProto.FATAL_INVALID_RPC_HEADER,\n               \"Connection context not established\");\n         } else {\n           processRpcRequest(header, buffer);\n         }\n       } catch (WrappedRpcServerException wrse) { // inform client of error\n         Throwable ioe \u003d wrse.getCause();\n-        final Call call \u003d new Call(callId, retry, null, this);\n+        final RpcCall call \u003d new RpcCall(this, callId, retry);\n         setupResponse(call,\n             RpcStatusProto.FATAL, wrse.getRpcErrorCodeProto(), null,\n             ioe.getClass().getName(), ioe.getMessage());\n         call.sendResponse();\n         throw wrse;\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void processOneRpc(ByteBuffer bb)\n        throws IOException, WrappedRpcServerException, InterruptedException {\n      int callId \u003d -1;\n      int retry \u003d RpcConstants.INVALID_RETRY_COUNT;\n      try {\n        final RpcWritable.Buffer buffer \u003d RpcWritable.Buffer.wrap(bb);\n        final RpcRequestHeaderProto header \u003d\n            getMessage(RpcRequestHeaderProto.getDefaultInstance(), buffer);\n        callId \u003d header.getCallId();\n        retry \u003d header.getRetryCount();\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\" got #\" + callId);\n        }\n        checkRpcHeaders(header);\n\n        if (callId \u003c 0) { // callIds typically used during connection setup\n          processRpcOutOfBandRequest(header, buffer);\n        } else if (!connectionContextRead) {\n          throw new WrappedRpcServerException(\n              RpcErrorCodeProto.FATAL_INVALID_RPC_HEADER,\n              \"Connection context not established\");\n        } else {\n          processRpcRequest(header, buffer);\n        }\n      } catch (WrappedRpcServerException wrse) { // inform client of error\n        Throwable ioe \u003d wrse.getCause();\n        final RpcCall call \u003d new RpcCall(this, callId, retry);\n        setupResponse(call,\n            RpcStatusProto.FATAL, wrse.getRpcErrorCodeProto(), null,\n            ioe.getClass().getName(), ioe.getMessage());\n        call.sendResponse();\n        throw wrse;\n      }\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {}
    },
    "81485dbfc1ffb8daa609be8eb31094cc28646dd3": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HADOOP-13465. Design Server.Call to be extensible for unified call queue. Contributed by Daryn Sharp.\"\n\nThis reverts commit d288a0ba8364d81aacda9f4a21022eecb6dc4e22.\n",
      "commitDate": "25/08/16 2:04 PM",
      "commitName": "81485dbfc1ffb8daa609be8eb31094cc28646dd3",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "25/08/16 9:44 AM",
      "commitNameOld": "d288a0ba8364d81aacda9f4a21022eecb6dc4e22",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 0.18,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,34 +1,34 @@\n     private void processOneRpc(ByteBuffer bb)\n         throws IOException, WrappedRpcServerException, InterruptedException {\n       int callId \u003d -1;\n       int retry \u003d RpcConstants.INVALID_RETRY_COUNT;\n       try {\n         final RpcWritable.Buffer buffer \u003d RpcWritable.Buffer.wrap(bb);\n         final RpcRequestHeaderProto header \u003d\n             getMessage(RpcRequestHeaderProto.getDefaultInstance(), buffer);\n         callId \u003d header.getCallId();\n         retry \u003d header.getRetryCount();\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\" got #\" + callId);\n         }\n         checkRpcHeaders(header);\n \n         if (callId \u003c 0) { // callIds typically used during connection setup\n           processRpcOutOfBandRequest(header, buffer);\n         } else if (!connectionContextRead) {\n           throw new WrappedRpcServerException(\n               RpcErrorCodeProto.FATAL_INVALID_RPC_HEADER,\n               \"Connection context not established\");\n         } else {\n           processRpcRequest(header, buffer);\n         }\n       } catch (WrappedRpcServerException wrse) { // inform client of error\n         Throwable ioe \u003d wrse.getCause();\n-        final RpcCall call \u003d new RpcCall(this, callId, retry);\n+        final Call call \u003d new Call(callId, retry, null, this);\n         setupResponse(call,\n             RpcStatusProto.FATAL, wrse.getRpcErrorCodeProto(), null,\n             ioe.getClass().getName(), ioe.getMessage());\n         call.sendResponse();\n         throw wrse;\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void processOneRpc(ByteBuffer bb)\n        throws IOException, WrappedRpcServerException, InterruptedException {\n      int callId \u003d -1;\n      int retry \u003d RpcConstants.INVALID_RETRY_COUNT;\n      try {\n        final RpcWritable.Buffer buffer \u003d RpcWritable.Buffer.wrap(bb);\n        final RpcRequestHeaderProto header \u003d\n            getMessage(RpcRequestHeaderProto.getDefaultInstance(), buffer);\n        callId \u003d header.getCallId();\n        retry \u003d header.getRetryCount();\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\" got #\" + callId);\n        }\n        checkRpcHeaders(header);\n\n        if (callId \u003c 0) { // callIds typically used during connection setup\n          processRpcOutOfBandRequest(header, buffer);\n        } else if (!connectionContextRead) {\n          throw new WrappedRpcServerException(\n              RpcErrorCodeProto.FATAL_INVALID_RPC_HEADER,\n              \"Connection context not established\");\n        } else {\n          processRpcRequest(header, buffer);\n        }\n      } catch (WrappedRpcServerException wrse) { // inform client of error\n        Throwable ioe \u003d wrse.getCause();\n        final Call call \u003d new Call(callId, retry, null, this);\n        setupResponse(call,\n            RpcStatusProto.FATAL, wrse.getRpcErrorCodeProto(), null,\n            ioe.getClass().getName(), ioe.getMessage());\n        call.sendResponse();\n        throw wrse;\n      }\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {}
    },
    "d288a0ba8364d81aacda9f4a21022eecb6dc4e22": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-13465. Design Server.Call to be extensible for unified call queue. Contributed by Daryn Sharp.\n",
      "commitDate": "25/08/16 9:44 AM",
      "commitName": "d288a0ba8364d81aacda9f4a21022eecb6dc4e22",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "03/08/16 11:22 AM",
      "commitNameOld": "580a8334963709e728ed677c815fb7fef9bca70e",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 21.93,
      "commitsBetweenForRepo": 167,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,34 +1,34 @@\n     private void processOneRpc(ByteBuffer bb)\n         throws IOException, WrappedRpcServerException, InterruptedException {\n       int callId \u003d -1;\n       int retry \u003d RpcConstants.INVALID_RETRY_COUNT;\n       try {\n         final RpcWritable.Buffer buffer \u003d RpcWritable.Buffer.wrap(bb);\n         final RpcRequestHeaderProto header \u003d\n             getMessage(RpcRequestHeaderProto.getDefaultInstance(), buffer);\n         callId \u003d header.getCallId();\n         retry \u003d header.getRetryCount();\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\" got #\" + callId);\n         }\n         checkRpcHeaders(header);\n \n         if (callId \u003c 0) { // callIds typically used during connection setup\n           processRpcOutOfBandRequest(header, buffer);\n         } else if (!connectionContextRead) {\n           throw new WrappedRpcServerException(\n               RpcErrorCodeProto.FATAL_INVALID_RPC_HEADER,\n               \"Connection context not established\");\n         } else {\n           processRpcRequest(header, buffer);\n         }\n       } catch (WrappedRpcServerException wrse) { // inform client of error\n         Throwable ioe \u003d wrse.getCause();\n-        final Call call \u003d new Call(callId, retry, null, this);\n+        final RpcCall call \u003d new RpcCall(this, callId, retry);\n         setupResponse(call,\n             RpcStatusProto.FATAL, wrse.getRpcErrorCodeProto(), null,\n             ioe.getClass().getName(), ioe.getMessage());\n         call.sendResponse();\n         throw wrse;\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void processOneRpc(ByteBuffer bb)\n        throws IOException, WrappedRpcServerException, InterruptedException {\n      int callId \u003d -1;\n      int retry \u003d RpcConstants.INVALID_RETRY_COUNT;\n      try {\n        final RpcWritable.Buffer buffer \u003d RpcWritable.Buffer.wrap(bb);\n        final RpcRequestHeaderProto header \u003d\n            getMessage(RpcRequestHeaderProto.getDefaultInstance(), buffer);\n        callId \u003d header.getCallId();\n        retry \u003d header.getRetryCount();\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\" got #\" + callId);\n        }\n        checkRpcHeaders(header);\n\n        if (callId \u003c 0) { // callIds typically used during connection setup\n          processRpcOutOfBandRequest(header, buffer);\n        } else if (!connectionContextRead) {\n          throw new WrappedRpcServerException(\n              RpcErrorCodeProto.FATAL_INVALID_RPC_HEADER,\n              \"Connection context not established\");\n        } else {\n          processRpcRequest(header, buffer);\n        }\n      } catch (WrappedRpcServerException wrse) { // inform client of error\n        Throwable ioe \u003d wrse.getCause();\n        final RpcCall call \u003d new RpcCall(this, callId, retry);\n        setupResponse(call,\n            RpcStatusProto.FATAL, wrse.getRpcErrorCodeProto(), null,\n            ioe.getClass().getName(), ioe.getMessage());\n        call.sendResponse();\n        throw wrse;\n      }\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {}
    },
    "580a8334963709e728ed677c815fb7fef9bca70e": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HADOOP-13483. Optimize IPC server protobuf decoding. Contributed by Daryn Sharp.\n",
      "commitDate": "03/08/16 11:22 AM",
      "commitName": "580a8334963709e728ed677c815fb7fef9bca70e",
      "commitAuthor": "Kihwal Lee",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HADOOP-13483. Optimize IPC server protobuf decoding. Contributed by Daryn Sharp.\n",
          "commitDate": "03/08/16 11:22 AM",
          "commitName": "580a8334963709e728ed677c815fb7fef9bca70e",
          "commitAuthor": "Kihwal Lee",
          "commitDateOld": "03/08/16 7:31 AM",
          "commitNameOld": "2d8227605fe22c1c05f31729edc8939013763c05",
          "commitAuthorOld": "Kihwal Lee",
          "daysBetweenCommits": 0.16,
          "commitsBetweenForRepo": 4,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,35 +1,34 @@\n-    private void processOneRpc(byte[] buf)\n+    private void processOneRpc(ByteBuffer bb)\n         throws IOException, WrappedRpcServerException, InterruptedException {\n       int callId \u003d -1;\n       int retry \u003d RpcConstants.INVALID_RETRY_COUNT;\n       try {\n-        final DataInputStream dis \u003d\n-            new DataInputStream(new ByteArrayInputStream(buf));\n+        final RpcWritable.Buffer buffer \u003d RpcWritable.Buffer.wrap(bb);\n         final RpcRequestHeaderProto header \u003d\n-            decodeProtobufFromStream(RpcRequestHeaderProto.newBuilder(), dis);\n+            getMessage(RpcRequestHeaderProto.getDefaultInstance(), buffer);\n         callId \u003d header.getCallId();\n         retry \u003d header.getRetryCount();\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\" got #\" + callId);\n         }\n         checkRpcHeaders(header);\n-        \n+\n         if (callId \u003c 0) { // callIds typically used during connection setup\n-          processRpcOutOfBandRequest(header, dis);\n+          processRpcOutOfBandRequest(header, buffer);\n         } else if (!connectionContextRead) {\n           throw new WrappedRpcServerException(\n               RpcErrorCodeProto.FATAL_INVALID_RPC_HEADER,\n               \"Connection context not established\");\n         } else {\n-          processRpcRequest(header, dis);\n+          processRpcRequest(header, buffer);\n         }\n       } catch (WrappedRpcServerException wrse) { // inform client of error\n         Throwable ioe \u003d wrse.getCause();\n         final Call call \u003d new Call(callId, retry, null, this);\n         setupResponse(call,\n             RpcStatusProto.FATAL, wrse.getRpcErrorCodeProto(), null,\n             ioe.getClass().getName(), ioe.getMessage());\n         call.sendResponse();\n         throw wrse;\n       }\n     }\n\\ No newline at end of file\n",
          "actualSource": "    private void processOneRpc(ByteBuffer bb)\n        throws IOException, WrappedRpcServerException, InterruptedException {\n      int callId \u003d -1;\n      int retry \u003d RpcConstants.INVALID_RETRY_COUNT;\n      try {\n        final RpcWritable.Buffer buffer \u003d RpcWritable.Buffer.wrap(bb);\n        final RpcRequestHeaderProto header \u003d\n            getMessage(RpcRequestHeaderProto.getDefaultInstance(), buffer);\n        callId \u003d header.getCallId();\n        retry \u003d header.getRetryCount();\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\" got #\" + callId);\n        }\n        checkRpcHeaders(header);\n\n        if (callId \u003c 0) { // callIds typically used during connection setup\n          processRpcOutOfBandRequest(header, buffer);\n        } else if (!connectionContextRead) {\n          throw new WrappedRpcServerException(\n              RpcErrorCodeProto.FATAL_INVALID_RPC_HEADER,\n              \"Connection context not established\");\n        } else {\n          processRpcRequest(header, buffer);\n        }\n      } catch (WrappedRpcServerException wrse) { // inform client of error\n        Throwable ioe \u003d wrse.getCause();\n        final Call call \u003d new Call(callId, retry, null, this);\n        setupResponse(call,\n            RpcStatusProto.FATAL, wrse.getRpcErrorCodeProto(), null,\n            ioe.getClass().getName(), ioe.getMessage());\n        call.sendResponse();\n        throw wrse;\n      }\n    }",
          "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
          "extendedDetails": {
            "oldValue": "[buf-byte[]]",
            "newValue": "[bb-ByteBuffer]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HADOOP-13483. Optimize IPC server protobuf decoding. Contributed by Daryn Sharp.\n",
          "commitDate": "03/08/16 11:22 AM",
          "commitName": "580a8334963709e728ed677c815fb7fef9bca70e",
          "commitAuthor": "Kihwal Lee",
          "commitDateOld": "03/08/16 7:31 AM",
          "commitNameOld": "2d8227605fe22c1c05f31729edc8939013763c05",
          "commitAuthorOld": "Kihwal Lee",
          "daysBetweenCommits": 0.16,
          "commitsBetweenForRepo": 4,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,35 +1,34 @@\n-    private void processOneRpc(byte[] buf)\n+    private void processOneRpc(ByteBuffer bb)\n         throws IOException, WrappedRpcServerException, InterruptedException {\n       int callId \u003d -1;\n       int retry \u003d RpcConstants.INVALID_RETRY_COUNT;\n       try {\n-        final DataInputStream dis \u003d\n-            new DataInputStream(new ByteArrayInputStream(buf));\n+        final RpcWritable.Buffer buffer \u003d RpcWritable.Buffer.wrap(bb);\n         final RpcRequestHeaderProto header \u003d\n-            decodeProtobufFromStream(RpcRequestHeaderProto.newBuilder(), dis);\n+            getMessage(RpcRequestHeaderProto.getDefaultInstance(), buffer);\n         callId \u003d header.getCallId();\n         retry \u003d header.getRetryCount();\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\" got #\" + callId);\n         }\n         checkRpcHeaders(header);\n-        \n+\n         if (callId \u003c 0) { // callIds typically used during connection setup\n-          processRpcOutOfBandRequest(header, dis);\n+          processRpcOutOfBandRequest(header, buffer);\n         } else if (!connectionContextRead) {\n           throw new WrappedRpcServerException(\n               RpcErrorCodeProto.FATAL_INVALID_RPC_HEADER,\n               \"Connection context not established\");\n         } else {\n-          processRpcRequest(header, dis);\n+          processRpcRequest(header, buffer);\n         }\n       } catch (WrappedRpcServerException wrse) { // inform client of error\n         Throwable ioe \u003d wrse.getCause();\n         final Call call \u003d new Call(callId, retry, null, this);\n         setupResponse(call,\n             RpcStatusProto.FATAL, wrse.getRpcErrorCodeProto(), null,\n             ioe.getClass().getName(), ioe.getMessage());\n         call.sendResponse();\n         throw wrse;\n       }\n     }\n\\ No newline at end of file\n",
          "actualSource": "    private void processOneRpc(ByteBuffer bb)\n        throws IOException, WrappedRpcServerException, InterruptedException {\n      int callId \u003d -1;\n      int retry \u003d RpcConstants.INVALID_RETRY_COUNT;\n      try {\n        final RpcWritable.Buffer buffer \u003d RpcWritable.Buffer.wrap(bb);\n        final RpcRequestHeaderProto header \u003d\n            getMessage(RpcRequestHeaderProto.getDefaultInstance(), buffer);\n        callId \u003d header.getCallId();\n        retry \u003d header.getRetryCount();\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\" got #\" + callId);\n        }\n        checkRpcHeaders(header);\n\n        if (callId \u003c 0) { // callIds typically used during connection setup\n          processRpcOutOfBandRequest(header, buffer);\n        } else if (!connectionContextRead) {\n          throw new WrappedRpcServerException(\n              RpcErrorCodeProto.FATAL_INVALID_RPC_HEADER,\n              \"Connection context not established\");\n        } else {\n          processRpcRequest(header, buffer);\n        }\n      } catch (WrappedRpcServerException wrse) { // inform client of error\n        Throwable ioe \u003d wrse.getCause();\n        final Call call \u003d new Call(callId, retry, null, this);\n        setupResponse(call,\n            RpcStatusProto.FATAL, wrse.getRpcErrorCodeProto(), null,\n            ioe.getClass().getName(), ioe.getMessage());\n        call.sendResponse();\n        throw wrse;\n      }\n    }",
          "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
          "extendedDetails": {}
        }
      ]
    },
    "2d8227605fe22c1c05f31729edc8939013763c05": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-13426. More efficiently build IPC responses. Contributed by Daryn Sharp.\n",
      "commitDate": "03/08/16 7:31 AM",
      "commitName": "2d8227605fe22c1c05f31729edc8939013763c05",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "02/08/16 8:40 AM",
      "commitNameOld": "b3018e73ccae43484d9cb85eabae814eb7f050a6",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 0.95,
      "commitsBetweenForRepo": 9,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,35 +1,35 @@\n     private void processOneRpc(byte[] buf)\n         throws IOException, WrappedRpcServerException, InterruptedException {\n       int callId \u003d -1;\n       int retry \u003d RpcConstants.INVALID_RETRY_COUNT;\n       try {\n         final DataInputStream dis \u003d\n             new DataInputStream(new ByteArrayInputStream(buf));\n         final RpcRequestHeaderProto header \u003d\n             decodeProtobufFromStream(RpcRequestHeaderProto.newBuilder(), dis);\n         callId \u003d header.getCallId();\n         retry \u003d header.getRetryCount();\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\" got #\" + callId);\n         }\n         checkRpcHeaders(header);\n         \n         if (callId \u003c 0) { // callIds typically used during connection setup\n           processRpcOutOfBandRequest(header, dis);\n         } else if (!connectionContextRead) {\n           throw new WrappedRpcServerException(\n               RpcErrorCodeProto.FATAL_INVALID_RPC_HEADER,\n               \"Connection context not established\");\n         } else {\n           processRpcRequest(header, dis);\n         }\n       } catch (WrappedRpcServerException wrse) { // inform client of error\n         Throwable ioe \u003d wrse.getCause();\n         final Call call \u003d new Call(callId, retry, null, this);\n-        setupResponse(authFailedResponse, call,\n+        setupResponse(call,\n             RpcStatusProto.FATAL, wrse.getRpcErrorCodeProto(), null,\n             ioe.getClass().getName(), ioe.getMessage());\n         call.sendResponse();\n         throw wrse;\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void processOneRpc(byte[] buf)\n        throws IOException, WrappedRpcServerException, InterruptedException {\n      int callId \u003d -1;\n      int retry \u003d RpcConstants.INVALID_RETRY_COUNT;\n      try {\n        final DataInputStream dis \u003d\n            new DataInputStream(new ByteArrayInputStream(buf));\n        final RpcRequestHeaderProto header \u003d\n            decodeProtobufFromStream(RpcRequestHeaderProto.newBuilder(), dis);\n        callId \u003d header.getCallId();\n        retry \u003d header.getRetryCount();\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\" got #\" + callId);\n        }\n        checkRpcHeaders(header);\n        \n        if (callId \u003c 0) { // callIds typically used during connection setup\n          processRpcOutOfBandRequest(header, dis);\n        } else if (!connectionContextRead) {\n          throw new WrappedRpcServerException(\n              RpcErrorCodeProto.FATAL_INVALID_RPC_HEADER,\n              \"Connection context not established\");\n        } else {\n          processRpcRequest(header, dis);\n        }\n      } catch (WrappedRpcServerException wrse) { // inform client of error\n        Throwable ioe \u003d wrse.getCause();\n        final Call call \u003d new Call(callId, retry, null, this);\n        setupResponse(call,\n            RpcStatusProto.FATAL, wrse.getRpcErrorCodeProto(), null,\n            ioe.getClass().getName(), ioe.getMessage());\n        call.sendResponse();\n        throw wrse;\n      }\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {}
    },
    "e617cf6dd13f2bb5d7cbb15ee2cdb260ecd46cd3": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-10300. Allowed deferred sending of call responses. (Daryn Sharp via yliu)\n",
      "commitDate": "12/10/15 1:09 AM",
      "commitName": "e617cf6dd13f2bb5d7cbb15ee2cdb260ecd46cd3",
      "commitAuthor": "yliu",
      "commitDateOld": "28/09/15 7:42 AM",
      "commitNameOld": "892ade689f9bcce76daae8f66fc00a49bee8548e",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 13.73,
      "commitsBetweenForRepo": 94,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,35 +1,35 @@\n     private void processOneRpc(byte[] buf)\n         throws IOException, WrappedRpcServerException, InterruptedException {\n       int callId \u003d -1;\n       int retry \u003d RpcConstants.INVALID_RETRY_COUNT;\n       try {\n         final DataInputStream dis \u003d\n             new DataInputStream(new ByteArrayInputStream(buf));\n         final RpcRequestHeaderProto header \u003d\n             decodeProtobufFromStream(RpcRequestHeaderProto.newBuilder(), dis);\n         callId \u003d header.getCallId();\n         retry \u003d header.getRetryCount();\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\" got #\" + callId);\n         }\n         checkRpcHeaders(header);\n         \n         if (callId \u003c 0) { // callIds typically used during connection setup\n           processRpcOutOfBandRequest(header, dis);\n         } else if (!connectionContextRead) {\n           throw new WrappedRpcServerException(\n               RpcErrorCodeProto.FATAL_INVALID_RPC_HEADER,\n               \"Connection context not established\");\n         } else {\n           processRpcRequest(header, dis);\n         }\n       } catch (WrappedRpcServerException wrse) { // inform client of error\n         Throwable ioe \u003d wrse.getCause();\n         final Call call \u003d new Call(callId, retry, null, this);\n         setupResponse(authFailedResponse, call,\n             RpcStatusProto.FATAL, wrse.getRpcErrorCodeProto(), null,\n             ioe.getClass().getName(), ioe.getMessage());\n-        responder.doRespond(call);\n+        call.sendResponse();\n         throw wrse;\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void processOneRpc(byte[] buf)\n        throws IOException, WrappedRpcServerException, InterruptedException {\n      int callId \u003d -1;\n      int retry \u003d RpcConstants.INVALID_RETRY_COUNT;\n      try {\n        final DataInputStream dis \u003d\n            new DataInputStream(new ByteArrayInputStream(buf));\n        final RpcRequestHeaderProto header \u003d\n            decodeProtobufFromStream(RpcRequestHeaderProto.newBuilder(), dis);\n        callId \u003d header.getCallId();\n        retry \u003d header.getRetryCount();\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\" got #\" + callId);\n        }\n        checkRpcHeaders(header);\n        \n        if (callId \u003c 0) { // callIds typically used during connection setup\n          processRpcOutOfBandRequest(header, dis);\n        } else if (!connectionContextRead) {\n          throw new WrappedRpcServerException(\n              RpcErrorCodeProto.FATAL_INVALID_RPC_HEADER,\n              \"Connection context not established\");\n        } else {\n          processRpcRequest(header, dis);\n        }\n      } catch (WrappedRpcServerException wrse) { // inform client of error\n        Throwable ioe \u003d wrse.getCause();\n        final Call call \u003d new Call(callId, retry, null, this);\n        setupResponse(authFailedResponse, call,\n            RpcStatusProto.FATAL, wrse.getRpcErrorCodeProto(), null,\n            ioe.getClass().getName(), ioe.getMessage());\n        call.sendResponse();\n        throw wrse;\n      }\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {}
    },
    "8724ceb2359af66c800043e665c17a2a30981c7d": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-9717. Add retry attempt count to the RPC requests. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1504725 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/07/13 4:44 PM",
      "commitName": "8724ceb2359af66c800043e665c17a2a30981c7d",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "17/07/13 9:42 PM",
      "commitNameOld": "7ec67c5118e8d13e2cb0ab09d04f0609b645a676",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 0.79,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,33 +1,35 @@\n     private void processOneRpc(byte[] buf)\n         throws IOException, WrappedRpcServerException, InterruptedException {\n       int callId \u003d -1;\n+      int retry \u003d RpcConstants.INVALID_RETRY_COUNT;\n       try {\n         final DataInputStream dis \u003d\n             new DataInputStream(new ByteArrayInputStream(buf));\n         final RpcRequestHeaderProto header \u003d\n             decodeProtobufFromStream(RpcRequestHeaderProto.newBuilder(), dis);\n         callId \u003d header.getCallId();\n+        retry \u003d header.getRetryCount();\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\" got #\" + callId);\n         }\n         checkRpcHeaders(header);\n         \n         if (callId \u003c 0) { // callIds typically used during connection setup\n           processRpcOutOfBandRequest(header, dis);\n         } else if (!connectionContextRead) {\n           throw new WrappedRpcServerException(\n               RpcErrorCodeProto.FATAL_INVALID_RPC_HEADER,\n               \"Connection context not established\");\n         } else {\n           processRpcRequest(header, dis);\n         }\n       } catch (WrappedRpcServerException wrse) { // inform client of error\n         Throwable ioe \u003d wrse.getCause();\n-        final Call call \u003d new Call(callId, null, this);\n+        final Call call \u003d new Call(callId, retry, null, this);\n         setupResponse(authFailedResponse, call,\n             RpcStatusProto.FATAL, wrse.getRpcErrorCodeProto(), null,\n             ioe.getClass().getName(), ioe.getMessage());\n         responder.doRespond(call);\n         throw wrse;\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void processOneRpc(byte[] buf)\n        throws IOException, WrappedRpcServerException, InterruptedException {\n      int callId \u003d -1;\n      int retry \u003d RpcConstants.INVALID_RETRY_COUNT;\n      try {\n        final DataInputStream dis \u003d\n            new DataInputStream(new ByteArrayInputStream(buf));\n        final RpcRequestHeaderProto header \u003d\n            decodeProtobufFromStream(RpcRequestHeaderProto.newBuilder(), dis);\n        callId \u003d header.getCallId();\n        retry \u003d header.getRetryCount();\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\" got #\" + callId);\n        }\n        checkRpcHeaders(header);\n        \n        if (callId \u003c 0) { // callIds typically used during connection setup\n          processRpcOutOfBandRequest(header, dis);\n        } else if (!connectionContextRead) {\n          throw new WrappedRpcServerException(\n              RpcErrorCodeProto.FATAL_INVALID_RPC_HEADER,\n              \"Connection context not established\");\n        } else {\n          processRpcRequest(header, dis);\n        }\n      } catch (WrappedRpcServerException wrse) { // inform client of error\n        Throwable ioe \u003d wrse.getCause();\n        final Call call \u003d new Call(callId, retry, null, this);\n        setupResponse(authFailedResponse, call,\n            RpcStatusProto.FATAL, wrse.getRpcErrorCodeProto(), null,\n            ioe.getClass().getName(), ioe.getMessage());\n        responder.doRespond(call);\n        throw wrse;\n      }\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {}
    },
    "a3a9d72e98a9cc0f94af7c832dd13c408856636d": {
      "type": "Ymultichange(Yexceptionschange,Ybodychange)",
      "commitMessage": "HADOOP-9683. [RPC v9] Wrap IpcConnectionContext in RPC headers (daryn)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1503811 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/07/13 10:59 AM",
      "commitName": "a3a9d72e98a9cc0f94af7c832dd13c408856636d",
      "commitAuthor": "Daryn Sharp",
      "subchanges": [
        {
          "type": "Yexceptionschange",
          "commitMessage": "HADOOP-9683. [RPC v9] Wrap IpcConnectionContext in RPC headers (daryn)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1503811 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "16/07/13 10:59 AM",
          "commitName": "a3a9d72e98a9cc0f94af7c832dd13c408856636d",
          "commitAuthor": "Daryn Sharp",
          "commitDateOld": "09/07/13 4:45 PM",
          "commitNameOld": "0a5f16a89e3942953d7d6c2d26542764298c6430",
          "commitAuthorOld": "Chris Nauroth",
          "daysBetweenCommits": 6.76,
          "commitsBetweenForRepo": 40,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,14 +1,33 @@\n-    private void processOneRpc(byte[] buf) throws IOException,\n-        InterruptedException {\n-      if (connectionContextRead) {\n-        processRpcRequest(buf);\n-      } else {\n-        processConnectionContext(buf);\n-        connectionContextRead \u003d true;\n-        if (!authorizeConnection()) {\n-          throw new AccessControlException(\"Connection from \" + this\n-              + \" for protocol \" + connectionContext.getProtocol()\n-              + \" is unauthorized for user \" + user);      \n+    private void processOneRpc(byte[] buf)\n+        throws IOException, WrappedRpcServerException, InterruptedException {\n+      int callId \u003d -1;\n+      try {\n+        final DataInputStream dis \u003d\n+            new DataInputStream(new ByteArrayInputStream(buf));\n+        final RpcRequestHeaderProto header \u003d\n+            decodeProtobufFromStream(RpcRequestHeaderProto.newBuilder(), dis);\n+        callId \u003d header.getCallId();\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\" got #\" + callId);\n         }\n+        checkRpcHeaders(header);\n+        \n+        if (callId \u003c 0) { // callIds typically used during connection setup\n+          processRpcOutOfBandRequest(header, dis);\n+        } else if (!connectionContextRead) {\n+          throw new WrappedRpcServerException(\n+              RpcErrorCodeProto.FATAL_INVALID_RPC_HEADER,\n+              \"Connection context not established\");\n+        } else {\n+          processRpcRequest(header, dis);\n+        }\n+      } catch (WrappedRpcServerException wrse) { // inform client of error\n+        Throwable ioe \u003d wrse.getCause();\n+        final Call call \u003d new Call(callId, null, this);\n+        setupResponse(authFailedResponse, call,\n+            RpcStatusProto.FATAL, wrse.getRpcErrorCodeProto(), null,\n+            ioe.getClass().getName(), ioe.getMessage());\n+        responder.doRespond(call);\n+        throw wrse;\n       }\n     }\n\\ No newline at end of file\n",
          "actualSource": "    private void processOneRpc(byte[] buf)\n        throws IOException, WrappedRpcServerException, InterruptedException {\n      int callId \u003d -1;\n      try {\n        final DataInputStream dis \u003d\n            new DataInputStream(new ByteArrayInputStream(buf));\n        final RpcRequestHeaderProto header \u003d\n            decodeProtobufFromStream(RpcRequestHeaderProto.newBuilder(), dis);\n        callId \u003d header.getCallId();\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\" got #\" + callId);\n        }\n        checkRpcHeaders(header);\n        \n        if (callId \u003c 0) { // callIds typically used during connection setup\n          processRpcOutOfBandRequest(header, dis);\n        } else if (!connectionContextRead) {\n          throw new WrappedRpcServerException(\n              RpcErrorCodeProto.FATAL_INVALID_RPC_HEADER,\n              \"Connection context not established\");\n        } else {\n          processRpcRequest(header, dis);\n        }\n      } catch (WrappedRpcServerException wrse) { // inform client of error\n        Throwable ioe \u003d wrse.getCause();\n        final Call call \u003d new Call(callId, null, this);\n        setupResponse(authFailedResponse, call,\n            RpcStatusProto.FATAL, wrse.getRpcErrorCodeProto(), null,\n            ioe.getClass().getName(), ioe.getMessage());\n        responder.doRespond(call);\n        throw wrse;\n      }\n    }",
          "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
          "extendedDetails": {
            "oldValue": "[IOException, InterruptedException]",
            "newValue": "[IOException, WrappedRpcServerException, InterruptedException]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HADOOP-9683. [RPC v9] Wrap IpcConnectionContext in RPC headers (daryn)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1503811 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "16/07/13 10:59 AM",
          "commitName": "a3a9d72e98a9cc0f94af7c832dd13c408856636d",
          "commitAuthor": "Daryn Sharp",
          "commitDateOld": "09/07/13 4:45 PM",
          "commitNameOld": "0a5f16a89e3942953d7d6c2d26542764298c6430",
          "commitAuthorOld": "Chris Nauroth",
          "daysBetweenCommits": 6.76,
          "commitsBetweenForRepo": 40,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,14 +1,33 @@\n-    private void processOneRpc(byte[] buf) throws IOException,\n-        InterruptedException {\n-      if (connectionContextRead) {\n-        processRpcRequest(buf);\n-      } else {\n-        processConnectionContext(buf);\n-        connectionContextRead \u003d true;\n-        if (!authorizeConnection()) {\n-          throw new AccessControlException(\"Connection from \" + this\n-              + \" for protocol \" + connectionContext.getProtocol()\n-              + \" is unauthorized for user \" + user);      \n+    private void processOneRpc(byte[] buf)\n+        throws IOException, WrappedRpcServerException, InterruptedException {\n+      int callId \u003d -1;\n+      try {\n+        final DataInputStream dis \u003d\n+            new DataInputStream(new ByteArrayInputStream(buf));\n+        final RpcRequestHeaderProto header \u003d\n+            decodeProtobufFromStream(RpcRequestHeaderProto.newBuilder(), dis);\n+        callId \u003d header.getCallId();\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\" got #\" + callId);\n         }\n+        checkRpcHeaders(header);\n+        \n+        if (callId \u003c 0) { // callIds typically used during connection setup\n+          processRpcOutOfBandRequest(header, dis);\n+        } else if (!connectionContextRead) {\n+          throw new WrappedRpcServerException(\n+              RpcErrorCodeProto.FATAL_INVALID_RPC_HEADER,\n+              \"Connection context not established\");\n+        } else {\n+          processRpcRequest(header, dis);\n+        }\n+      } catch (WrappedRpcServerException wrse) { // inform client of error\n+        Throwable ioe \u003d wrse.getCause();\n+        final Call call \u003d new Call(callId, null, this);\n+        setupResponse(authFailedResponse, call,\n+            RpcStatusProto.FATAL, wrse.getRpcErrorCodeProto(), null,\n+            ioe.getClass().getName(), ioe.getMessage());\n+        responder.doRespond(call);\n+        throw wrse;\n       }\n     }\n\\ No newline at end of file\n",
          "actualSource": "    private void processOneRpc(byte[] buf)\n        throws IOException, WrappedRpcServerException, InterruptedException {\n      int callId \u003d -1;\n      try {\n        final DataInputStream dis \u003d\n            new DataInputStream(new ByteArrayInputStream(buf));\n        final RpcRequestHeaderProto header \u003d\n            decodeProtobufFromStream(RpcRequestHeaderProto.newBuilder(), dis);\n        callId \u003d header.getCallId();\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\" got #\" + callId);\n        }\n        checkRpcHeaders(header);\n        \n        if (callId \u003c 0) { // callIds typically used during connection setup\n          processRpcOutOfBandRequest(header, dis);\n        } else if (!connectionContextRead) {\n          throw new WrappedRpcServerException(\n              RpcErrorCodeProto.FATAL_INVALID_RPC_HEADER,\n              \"Connection context not established\");\n        } else {\n          processRpcRequest(header, dis);\n        }\n      } catch (WrappedRpcServerException wrse) { // inform client of error\n        Throwable ioe \u003d wrse.getCause();\n        final Call call \u003d new Call(callId, null, this);\n        setupResponse(authFailedResponse, call,\n            RpcStatusProto.FATAL, wrse.getRpcErrorCodeProto(), null,\n            ioe.getClass().getName(), ioe.getMessage());\n        responder.doRespond(call);\n        throw wrse;\n      }\n    }",
          "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
          "extendedDetails": {}
        }
      ]
    },
    "725623534ce7ab20c28af6e0cdf57bd7278551dd": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-9425 Add error codes to rpc-response (sanjay Radia)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1479143 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/05/13 10:51 AM",
      "commitName": "725623534ce7ab20c28af6e0cdf57bd7278551dd",
      "commitAuthor": "Sanjay Radia",
      "commitDateOld": "27/03/13 11:51 AM",
      "commitNameOld": "fc0a4de670c3e6dcf5d30305d3969fe4946a0fed",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 37.96,
      "commitsBetweenForRepo": 210,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,14 @@\n     private void processOneRpc(byte[] buf) throws IOException,\n         InterruptedException {\n       if (connectionContextRead) {\n-        processData(buf);\n+        processRpcRequest(buf);\n       } else {\n         processConnectionContext(buf);\n         connectionContextRead \u003d true;\n         if (!authorizeConnection()) {\n           throw new AccessControlException(\"Connection from \" + this\n               + \" for protocol \" + connectionContext.getProtocol()\n               + \" is unauthorized for user \" + user);      \n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void processOneRpc(byte[] buf) throws IOException,\n        InterruptedException {\n      if (connectionContextRead) {\n        processRpcRequest(buf);\n      } else {\n        processConnectionContext(buf);\n        connectionContextRead \u003d true;\n        if (!authorizeConnection()) {\n          throw new AccessControlException(\"Connection from \" + this\n              + \" for protocol \" + connectionContext.getProtocol()\n              + \" is unauthorized for user \" + user);      \n        }\n      }\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {}
    },
    "7ae04652a6adf0f9d04b8702a7fe3b9790afa8b9": {
      "type": "Ybodychange",
      "commitMessage": "    HADOOP-7557 Make IPC header be extensible (sanjay radia)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1295261 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "29/02/12 12:43 PM",
      "commitName": "7ae04652a6adf0f9d04b8702a7fe3b9790afa8b9",
      "commitAuthor": "Sanjay Radia",
      "commitDateOld": "23/02/12 8:05 PM",
      "commitNameOld": "22d5944c42b4bef5144a9f6426751b15717c5a3e",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 5.69,
      "commitsBetweenForRepo": 51,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,14 @@\n     private void processOneRpc(byte[] buf) throws IOException,\n         InterruptedException {\n-      if (headerRead) {\n+      if (connectionContextRead) {\n         processData(buf);\n       } else {\n-        processHeader(buf);\n-        headerRead \u003d true;\n+        processConnectionContext(buf);\n+        connectionContextRead \u003d true;\n         if (!authorizeConnection()) {\n           throw new AccessControlException(\"Connection from \" + this\n-              + \" for protocol \" + header.getProtocol()\n-              + \" is unauthorized for user \" + user);\n+              + \" for protocol \" + connectionContext.getProtocol()\n+              + \" is unauthorized for user \" + user);      \n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void processOneRpc(byte[] buf) throws IOException,\n        InterruptedException {\n      if (connectionContextRead) {\n        processData(buf);\n      } else {\n        processConnectionContext(buf);\n        connectionContextRead \u003d true;\n        if (!authorizeConnection()) {\n          throw new AccessControlException(\"Connection from \" + this\n              + \" for protocol \" + connectionContext.getProtocol()\n              + \" is unauthorized for user \" + user);      \n        }\n      }\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    private void processOneRpc(byte[] buf) throws IOException,\n        InterruptedException {\n      if (headerRead) {\n        processData(buf);\n      } else {\n        processHeader(buf);\n        headerRead \u003d true;\n        if (!authorizeConnection()) {\n          throw new AccessControlException(\"Connection from \" + this\n              + \" for protocol \" + header.getProtocol()\n              + \" is unauthorized for user \" + user);\n        }\n      }\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {
        "oldPath": "hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
        "newPath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java"
      }
    },
    "0f6dfeeacbab65a31a33927a4eb84871d371fe52": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-6671. Use maven for hadoop common builds. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1153184 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/08/11 9:37 AM",
      "commitName": "0f6dfeeacbab65a31a33927a4eb84871d371fe52",
      "commitAuthor": "Thomas White",
      "commitDateOld": "01/08/11 3:53 PM",
      "commitNameOld": "9bac807cedbcff34e1a144fb475eff267e5ed86d",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.74,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    private void processOneRpc(byte[] buf) throws IOException,\n        InterruptedException {\n      if (headerRead) {\n        processData(buf);\n      } else {\n        processHeader(buf);\n        headerRead \u003d true;\n        if (!authorizeConnection()) {\n          throw new AccessControlException(\"Connection from \" + this\n              + \" for protocol \" + header.getProtocol()\n              + \" is unauthorized for user \" + user);\n        }\n      }\n    }",
      "path": "hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {
        "oldPath": "common/src/java/org/apache/hadoop/ipc/Server.java",
        "newPath": "hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "11/06/11 9:13 PM",
      "commitNameOld": "a285fb5effe9ba3be4ec5f942afaf5ddd1186151",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 0.74,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    private void processOneRpc(byte[] buf) throws IOException,\n        InterruptedException {\n      if (headerRead) {\n        processData(buf);\n      } else {\n        processHeader(buf);\n        headerRead \u003d true;\n        if (!authorizeConnection()) {\n          throw new AccessControlException(\"Connection from \" + this\n              + \" for protocol \" + header.getProtocol()\n              + \" is unauthorized for user \" + user);\n        }\n      }\n    }",
      "path": "common/src/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {
        "oldPath": "src/java/org/apache/hadoop/ipc/Server.java",
        "newPath": "common/src/java/org/apache/hadoop/ipc/Server.java"
      }
    },
    "c4c122a0def592136e03a653c9fdc4f464ed0854": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-6586. Log authentication and authorization failures and successes for RPC\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@916779 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "26/02/10 10:35 AM",
      "commitName": "c4c122a0def592136e03a653c9fdc4f464ed0854",
      "commitAuthor": "Boris Shkolnik",
      "commitDateOld": "25/02/10 5:37 PM",
      "commitNameOld": "ea650d8d6c139ab7d6078c09da5c3cf72f2915fb",
      "commitAuthorOld": "Konstantin Shvachko",
      "daysBetweenCommits": 0.71,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,15 +1,14 @@\n     private void processOneRpc(byte[] buf) throws IOException,\n         InterruptedException {\n-      rpcMetrics.authenticationSuccesses.inc();\n       if (headerRead) {\n         processData(buf);\n       } else {\n         processHeader(buf);\n         headerRead \u003d true;\n         if (!authorizeConnection()) {\n           throw new AccessControlException(\"Connection from \" + this\n               + \" for protocol \" + header.getProtocol()\n               + \" is unauthorized for user \" + user);\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void processOneRpc(byte[] buf) throws IOException,\n        InterruptedException {\n      if (headerRead) {\n        processData(buf);\n      } else {\n        processHeader(buf);\n        headerRead \u003d true;\n        if (!authorizeConnection()) {\n          throw new AccessControlException(\"Connection from \" + this\n              + \" for protocol \" + header.getProtocol()\n              + \" is unauthorized for user \" + user);\n        }\n      }\n    }",
      "path": "src/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {}
    },
    "ffdde40b9f189cb30dee4c5187d63b61809f2d62": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-6583. Captures authentication and authorization metrics. Contributed by Devaraj Das.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@915095 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "22/02/10 2:26 PM",
      "commitName": "ffdde40b9f189cb30dee4c5187d63b61809f2d62",
      "commitAuthor": "Devaraj Das",
      "commitDateOld": "19/02/10 5:23 PM",
      "commitNameOld": "9871771bb55b3da4fd03435ddb5990e20e546c0e",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 2.88,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,15 @@\n     private void processOneRpc(byte[] buf) throws IOException,\n         InterruptedException {\n+      rpcMetrics.authenticationSuccesses.inc();\n       if (headerRead) {\n         processData(buf);\n       } else {\n         processHeader(buf);\n         headerRead \u003d true;\n         if (!authorizeConnection()) {\n           throw new AccessControlException(\"Connection from \" + this\n               + \" for protocol \" + header.getProtocol()\n               + \" is unauthorized for user \" + user);\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void processOneRpc(byte[] buf) throws IOException,\n        InterruptedException {\n      rpcMetrics.authenticationSuccesses.inc();\n      if (headerRead) {\n        processData(buf);\n      } else {\n        processHeader(buf);\n        headerRead \u003d true;\n        if (!authorizeConnection()) {\n          throw new AccessControlException(\"Connection from \" + this\n              + \" for protocol \" + header.getProtocol()\n              + \" is unauthorized for user \" + user);\n        }\n      }\n    }",
      "path": "src/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {}
    },
    "940389afce6a1b9b9e1519aed528cbc444786756": {
      "type": "Ymultichange(Yrename,Yparameterchange,Yexceptionschange,Ybodychange)",
      "commitMessage": "HADOOP-6419. Adds SASL based authentication to RPC. Contributed by Kan Zhang.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@905860 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/02/10 5:30 PM",
      "commitName": "940389afce6a1b9b9e1519aed528cbc444786756",
      "commitAuthor": "Devaraj Das",
      "subchanges": [
        {
          "type": "Yrename",
          "commitMessage": "HADOOP-6419. Adds SASL based authentication to RPC. Contributed by Kan Zhang.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@905860 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "02/02/10 5:30 PM",
          "commitName": "940389afce6a1b9b9e1519aed528cbc444786756",
          "commitAuthor": "Devaraj Das",
          "commitDateOld": "27/01/10 12:08 AM",
          "commitNameOld": "0c5734e4aca873f405fbf994e5fe7061e31731c8",
          "commitAuthorOld": "Owen O\u0027Malley",
          "daysBetweenCommits": 6.72,
          "commitsBetweenForRepo": 5,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,15 +1,14 @@\n-    private void processHeader() throws IOException {\n-      DataInputStream in \u003d\n-        new DataInputStream(new ByteArrayInputStream(data.array()));\n-      header.readFields(in);\n-      try {\n-        String protocolClassName \u003d header.getProtocol();\n-        if (protocolClassName !\u003d null) {\n-          protocol \u003d getProtocolClass(header.getProtocol(), conf);\n+    private void processOneRpc(byte[] buf) throws IOException,\n+        InterruptedException {\n+      if (headerRead) {\n+        processData(buf);\n+      } else {\n+        processHeader(buf);\n+        headerRead \u003d true;\n+        if (!authorizeConnection()) {\n+          throw new AccessControlException(\"Connection from \" + this\n+              + \" for protocol \" + header.getProtocol()\n+              + \" is unauthorized for user \" + user);\n         }\n-      } catch (ClassNotFoundException cnfe) {\n-        throw new IOException(\"Unknown protocol: \" + header.getProtocol());\n       }\n-      \n-      user \u003d header.getUgi();\n     }\n\\ No newline at end of file\n",
          "actualSource": "    private void processOneRpc(byte[] buf) throws IOException,\n        InterruptedException {\n      if (headerRead) {\n        processData(buf);\n      } else {\n        processHeader(buf);\n        headerRead \u003d true;\n        if (!authorizeConnection()) {\n          throw new AccessControlException(\"Connection from \" + this\n              + \" for protocol \" + header.getProtocol()\n              + \" is unauthorized for user \" + user);\n        }\n      }\n    }",
          "path": "src/java/org/apache/hadoop/ipc/Server.java",
          "extendedDetails": {
            "oldValue": "processHeader",
            "newValue": "processOneRpc"
          }
        },
        {
          "type": "Yparameterchange",
          "commitMessage": "HADOOP-6419. Adds SASL based authentication to RPC. Contributed by Kan Zhang.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@905860 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "02/02/10 5:30 PM",
          "commitName": "940389afce6a1b9b9e1519aed528cbc444786756",
          "commitAuthor": "Devaraj Das",
          "commitDateOld": "27/01/10 12:08 AM",
          "commitNameOld": "0c5734e4aca873f405fbf994e5fe7061e31731c8",
          "commitAuthorOld": "Owen O\u0027Malley",
          "daysBetweenCommits": 6.72,
          "commitsBetweenForRepo": 5,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,15 +1,14 @@\n-    private void processHeader() throws IOException {\n-      DataInputStream in \u003d\n-        new DataInputStream(new ByteArrayInputStream(data.array()));\n-      header.readFields(in);\n-      try {\n-        String protocolClassName \u003d header.getProtocol();\n-        if (protocolClassName !\u003d null) {\n-          protocol \u003d getProtocolClass(header.getProtocol(), conf);\n+    private void processOneRpc(byte[] buf) throws IOException,\n+        InterruptedException {\n+      if (headerRead) {\n+        processData(buf);\n+      } else {\n+        processHeader(buf);\n+        headerRead \u003d true;\n+        if (!authorizeConnection()) {\n+          throw new AccessControlException(\"Connection from \" + this\n+              + \" for protocol \" + header.getProtocol()\n+              + \" is unauthorized for user \" + user);\n         }\n-      } catch (ClassNotFoundException cnfe) {\n-        throw new IOException(\"Unknown protocol: \" + header.getProtocol());\n       }\n-      \n-      user \u003d header.getUgi();\n     }\n\\ No newline at end of file\n",
          "actualSource": "    private void processOneRpc(byte[] buf) throws IOException,\n        InterruptedException {\n      if (headerRead) {\n        processData(buf);\n      } else {\n        processHeader(buf);\n        headerRead \u003d true;\n        if (!authorizeConnection()) {\n          throw new AccessControlException(\"Connection from \" + this\n              + \" for protocol \" + header.getProtocol()\n              + \" is unauthorized for user \" + user);\n        }\n      }\n    }",
          "path": "src/java/org/apache/hadoop/ipc/Server.java",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[buf-byte[]]"
          }
        },
        {
          "type": "Yexceptionschange",
          "commitMessage": "HADOOP-6419. Adds SASL based authentication to RPC. Contributed by Kan Zhang.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@905860 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "02/02/10 5:30 PM",
          "commitName": "940389afce6a1b9b9e1519aed528cbc444786756",
          "commitAuthor": "Devaraj Das",
          "commitDateOld": "27/01/10 12:08 AM",
          "commitNameOld": "0c5734e4aca873f405fbf994e5fe7061e31731c8",
          "commitAuthorOld": "Owen O\u0027Malley",
          "daysBetweenCommits": 6.72,
          "commitsBetweenForRepo": 5,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,15 +1,14 @@\n-    private void processHeader() throws IOException {\n-      DataInputStream in \u003d\n-        new DataInputStream(new ByteArrayInputStream(data.array()));\n-      header.readFields(in);\n-      try {\n-        String protocolClassName \u003d header.getProtocol();\n-        if (protocolClassName !\u003d null) {\n-          protocol \u003d getProtocolClass(header.getProtocol(), conf);\n+    private void processOneRpc(byte[] buf) throws IOException,\n+        InterruptedException {\n+      if (headerRead) {\n+        processData(buf);\n+      } else {\n+        processHeader(buf);\n+        headerRead \u003d true;\n+        if (!authorizeConnection()) {\n+          throw new AccessControlException(\"Connection from \" + this\n+              + \" for protocol \" + header.getProtocol()\n+              + \" is unauthorized for user \" + user);\n         }\n-      } catch (ClassNotFoundException cnfe) {\n-        throw new IOException(\"Unknown protocol: \" + header.getProtocol());\n       }\n-      \n-      user \u003d header.getUgi();\n     }\n\\ No newline at end of file\n",
          "actualSource": "    private void processOneRpc(byte[] buf) throws IOException,\n        InterruptedException {\n      if (headerRead) {\n        processData(buf);\n      } else {\n        processHeader(buf);\n        headerRead \u003d true;\n        if (!authorizeConnection()) {\n          throw new AccessControlException(\"Connection from \" + this\n              + \" for protocol \" + header.getProtocol()\n              + \" is unauthorized for user \" + user);\n        }\n      }\n    }",
          "path": "src/java/org/apache/hadoop/ipc/Server.java",
          "extendedDetails": {
            "oldValue": "[IOException]",
            "newValue": "[IOException, InterruptedException]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HADOOP-6419. Adds SASL based authentication to RPC. Contributed by Kan Zhang.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@905860 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "02/02/10 5:30 PM",
          "commitName": "940389afce6a1b9b9e1519aed528cbc444786756",
          "commitAuthor": "Devaraj Das",
          "commitDateOld": "27/01/10 12:08 AM",
          "commitNameOld": "0c5734e4aca873f405fbf994e5fe7061e31731c8",
          "commitAuthorOld": "Owen O\u0027Malley",
          "daysBetweenCommits": 6.72,
          "commitsBetweenForRepo": 5,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,15 +1,14 @@\n-    private void processHeader() throws IOException {\n-      DataInputStream in \u003d\n-        new DataInputStream(new ByteArrayInputStream(data.array()));\n-      header.readFields(in);\n-      try {\n-        String protocolClassName \u003d header.getProtocol();\n-        if (protocolClassName !\u003d null) {\n-          protocol \u003d getProtocolClass(header.getProtocol(), conf);\n+    private void processOneRpc(byte[] buf) throws IOException,\n+        InterruptedException {\n+      if (headerRead) {\n+        processData(buf);\n+      } else {\n+        processHeader(buf);\n+        headerRead \u003d true;\n+        if (!authorizeConnection()) {\n+          throw new AccessControlException(\"Connection from \" + this\n+              + \" for protocol \" + header.getProtocol()\n+              + \" is unauthorized for user \" + user);\n         }\n-      } catch (ClassNotFoundException cnfe) {\n-        throw new IOException(\"Unknown protocol: \" + header.getProtocol());\n       }\n-      \n-      user \u003d header.getUgi();\n     }\n\\ No newline at end of file\n",
          "actualSource": "    private void processOneRpc(byte[] buf) throws IOException,\n        InterruptedException {\n      if (headerRead) {\n        processData(buf);\n      } else {\n        processHeader(buf);\n        headerRead \u003d true;\n        if (!authorizeConnection()) {\n          throw new AccessControlException(\"Connection from \" + this\n              + \" for protocol \" + header.getProtocol()\n              + \" is unauthorized for user \" + user);\n        }\n      }\n    }",
          "path": "src/java/org/apache/hadoop/ipc/Server.java",
          "extendedDetails": {}
        }
      ]
    },
    "0c5734e4aca873f405fbf994e5fe7061e31731c8": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-6299. Reimplement the UserGroupInformation to use the OS\nspecific and Kerberos JAAS login. (omalley)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@903560 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/01/10 12:08 AM",
      "commitName": "0c5734e4aca873f405fbf994e5fe7061e31731c8",
      "commitAuthor": "Owen O\u0027Malley",
      "commitDateOld": "23/12/09 4:47 PM",
      "commitNameOld": "29a1ba1e8fb11432404cea49e46eef47c36bb70a",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 34.31,
      "commitsBetweenForRepo": 23,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,15 @@\n     private void processHeader() throws IOException {\n       DataInputStream in \u003d\n         new DataInputStream(new ByteArrayInputStream(data.array()));\n       header.readFields(in);\n       try {\n         String protocolClassName \u003d header.getProtocol();\n         if (protocolClassName !\u003d null) {\n           protocol \u003d getProtocolClass(header.getProtocol(), conf);\n         }\n       } catch (ClassNotFoundException cnfe) {\n         throw new IOException(\"Unknown protocol: \" + header.getProtocol());\n       }\n       \n-      // TODO: Get the user name from the GSS API for Kerberbos-based security\n-      // Create the user subject; however use the groups as defined on the\n-      // server-side, don\u0027t trust the user groups provided by the client\n-      UserGroupInformation ugi \u003d header.getUgi();\n-      user \u003d null;\n-      if(ugi !\u003d null) {\n-        user \u003d SecurityUtil.getSubject(conf, header.getUgi().getUserName());\n-      }\n+      user \u003d header.getUgi();\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void processHeader() throws IOException {\n      DataInputStream in \u003d\n        new DataInputStream(new ByteArrayInputStream(data.array()));\n      header.readFields(in);\n      try {\n        String protocolClassName \u003d header.getProtocol();\n        if (protocolClassName !\u003d null) {\n          protocol \u003d getProtocolClass(header.getProtocol(), conf);\n        }\n      } catch (ClassNotFoundException cnfe) {\n        throw new IOException(\"Unknown protocol: \" + header.getProtocol());\n      }\n      \n      user \u003d header.getUgi();\n    }",
      "path": "src/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {}
    },
    "ae93ba7501d95e9d26a29de25f4cc39e5225ca20": {
      "type": "Ybodychange",
      "commitMessage": "   HADOOP-4656. Add a user to groups mapping service (boryas and acmurthy_)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@892066 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/12/09 5:29 PM",
      "commitName": "ae93ba7501d95e9d26a29de25f4cc39e5225ca20",
      "commitAuthor": "Boris Shkolnik",
      "commitDateOld": "18/05/09 9:20 PM",
      "commitNameOld": "5128a9a453d64bfe1ed978cf9ffed27985eeef36",
      "commitAuthorOld": "Owen O\u0027Malley",
      "daysBetweenCommits": 212.88,
      "commitsBetweenForRepo": 193,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,22 @@\n     private void processHeader() throws IOException {\n       DataInputStream in \u003d\n         new DataInputStream(new ByteArrayInputStream(data.array()));\n       header.readFields(in);\n       try {\n         String protocolClassName \u003d header.getProtocol();\n         if (protocolClassName !\u003d null) {\n           protocol \u003d getProtocolClass(header.getProtocol(), conf);\n         }\n       } catch (ClassNotFoundException cnfe) {\n         throw new IOException(\"Unknown protocol: \" + header.getProtocol());\n       }\n       \n       // TODO: Get the user name from the GSS API for Kerberbos-based security\n-      // Create the user subject\n-      user \u003d SecurityUtil.getSubject(header.getUgi());\n+      // Create the user subject; however use the groups as defined on the\n+      // server-side, don\u0027t trust the user groups provided by the client\n+      UserGroupInformation ugi \u003d header.getUgi();\n+      user \u003d null;\n+      if(ugi !\u003d null) {\n+        user \u003d SecurityUtil.getSubject(conf, header.getUgi().getUserName());\n+      }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void processHeader() throws IOException {\n      DataInputStream in \u003d\n        new DataInputStream(new ByteArrayInputStream(data.array()));\n      header.readFields(in);\n      try {\n        String protocolClassName \u003d header.getProtocol();\n        if (protocolClassName !\u003d null) {\n          protocol \u003d getProtocolClass(header.getProtocol(), conf);\n        }\n      } catch (ClassNotFoundException cnfe) {\n        throw new IOException(\"Unknown protocol: \" + header.getProtocol());\n      }\n      \n      // TODO: Get the user name from the GSS API for Kerberbos-based security\n      // Create the user subject; however use the groups as defined on the\n      // server-side, don\u0027t trust the user groups provided by the client\n      UserGroupInformation ugi \u003d header.getUgi();\n      user \u003d null;\n      if(ugi !\u003d null) {\n        user \u003d SecurityUtil.getSubject(conf, header.getUgi().getUserName());\n      }\n    }",
      "path": "src/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {}
    },
    "5128a9a453d64bfe1ed978cf9ffed27985eeef36": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-4687 Moving src directories on branch\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/core/branches/HADOOP-4687/core@776174 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/05/09 9:20 PM",
      "commitName": "5128a9a453d64bfe1ed978cf9ffed27985eeef36",
      "commitAuthor": "Owen O\u0027Malley",
      "diff": "@@ -0,0 +1,17 @@\n+    private void processHeader() throws IOException {\n+      DataInputStream in \u003d\n+        new DataInputStream(new ByteArrayInputStream(data.array()));\n+      header.readFields(in);\n+      try {\n+        String protocolClassName \u003d header.getProtocol();\n+        if (protocolClassName !\u003d null) {\n+          protocol \u003d getProtocolClass(header.getProtocol(), conf);\n+        }\n+      } catch (ClassNotFoundException cnfe) {\n+        throw new IOException(\"Unknown protocol: \" + header.getProtocol());\n+      }\n+      \n+      // TODO: Get the user name from the GSS API for Kerberbos-based security\n+      // Create the user subject\n+      user \u003d SecurityUtil.getSubject(header.getUgi());\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    private void processHeader() throws IOException {\n      DataInputStream in \u003d\n        new DataInputStream(new ByteArrayInputStream(data.array()));\n      header.readFields(in);\n      try {\n        String protocolClassName \u003d header.getProtocol();\n        if (protocolClassName !\u003d null) {\n          protocol \u003d getProtocolClass(header.getProtocol(), conf);\n        }\n      } catch (ClassNotFoundException cnfe) {\n        throw new IOException(\"Unknown protocol: \" + header.getProtocol());\n      }\n      \n      // TODO: Get the user name from the GSS API for Kerberbos-based security\n      // Create the user subject\n      user \u003d SecurityUtil.getSubject(header.getUgi());\n    }",
      "path": "src/java/org/apache/hadoop/ipc/Server.java"
    }
  }
}