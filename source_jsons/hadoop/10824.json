{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ErasureCodingWorker.java",
  "functionName": "processErasureCodingTasks",
  "functionId": "processErasureCodingTasks___ecTasks-Collection__BlockECReconstructionInfo__",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/erasurecode/ErasureCodingWorker.java",
  "functionStartLine": 121,
  "functionEndLine": 155,
  "numCommitsSeen": 66,
  "timeTaken": 5665,
  "changeHistory": [
    "9367c25dbdfedf60cdbd65611281cf9c667829e6",
    "77791e4c36ddc9305306c83806bf486d4d32575d",
    "a3954ccab148bddc290cb96528e63ff19799bcc9",
    "d749cf65e1ab0e0daf5be86931507183f189e855",
    "3c18a53cbd2efabb2ad108d63a0b0b558424115f",
    "e54cc2931262bf49682a8323da9811976218c03b",
    "6546d9e7ff73d2c81a803f2c61a1376a8c426987",
    "4ae543fdcd6dcfbe32257b1e72a405df9aa73e17",
    "b762199adbd10173c588df67bd227393c5bbcce9",
    "ced438a4bf50fe0ac9072c128e18249e6742956a",
    "6616de24cb14f1c2d0d6568fd4382062618834bd",
    "014d8675c59d44ad68dec36db6afe3f3666a3f15"
  ],
  "changeHistoryShort": {
    "9367c25dbdfedf60cdbd65611281cf9c667829e6": "Ybodychange",
    "77791e4c36ddc9305306c83806bf486d4d32575d": "Ybodychange",
    "a3954ccab148bddc290cb96528e63ff19799bcc9": "Ybodychange",
    "d749cf65e1ab0e0daf5be86931507183f189e855": "Ybodychange",
    "3c18a53cbd2efabb2ad108d63a0b0b558424115f": "Ybodychange",
    "e54cc2931262bf49682a8323da9811976218c03b": "Ybodychange",
    "6546d9e7ff73d2c81a803f2c61a1376a8c426987": "Ybodychange",
    "4ae543fdcd6dcfbe32257b1e72a405df9aa73e17": "Ymultichange(Yparameterchange,Ybodychange)",
    "b762199adbd10173c588df67bd227393c5bbcce9": "Ybodychange",
    "ced438a4bf50fe0ac9072c128e18249e6742956a": "Ybodychange",
    "6616de24cb14f1c2d0d6568fd4382062618834bd": "Ybodychange",
    "014d8675c59d44ad68dec36db6afe3f3666a3f15": "Yintroduced"
  },
  "changeHistoryDetails": {
    "9367c25dbdfedf60cdbd65611281cf9c667829e6": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12482. Provide a configuration to adjust the weight of EC recovery tasks to adjust the speed of recovery. (lei)\n",
      "commitDate": "31/10/17 9:58 PM",
      "commitName": "9367c25dbdfedf60cdbd65611281cf9c667829e6",
      "commitAuthor": "Lei Xu",
      "commitDateOld": "26/09/17 10:08 AM",
      "commitNameOld": "1267ff22ce9226b6dd52e3f33cbe3b3094fb0e35",
      "commitAuthorOld": "Lei Xu",
      "daysBetweenCommits": 35.49,
      "commitsBetweenForRepo": 250,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,35 +1,35 @@\n   public void processErasureCodingTasks(\n       Collection\u003cBlockECReconstructionInfo\u003e ecTasks) {\n     for (BlockECReconstructionInfo reconInfo : ecTasks) {\n       int xmitsSubmitted \u003d 0;\n       try {\n         StripedReconstructionInfo stripedReconInfo \u003d\n             new StripedReconstructionInfo(\n             reconInfo.getExtendedBlock(), reconInfo.getErasureCodingPolicy(),\n             reconInfo.getLiveBlockIndices(), reconInfo.getSourceDnInfos(),\n             reconInfo.getTargetDnInfos(), reconInfo.getTargetStorageTypes(),\n             reconInfo.getTargetStorageIDs());\n         // It may throw IllegalArgumentException from task#stripedReader\n         // constructor.\n         final StripedBlockReconstructor task \u003d\n             new StripedBlockReconstructor(this, stripedReconInfo);\n         if (task.hasValidTargets()) {\n           // See HDFS-12044. We increase xmitsInProgress even the task is only\n           // enqueued, so that\n           //   1) NN will not send more tasks than what DN can execute and\n           //   2) DN will not throw away reconstruction tasks, and instead keeps\n           //      an unbounded number of tasks in the executor\u0027s task queue.\n-          xmitsSubmitted \u003d task.getXmits();\n+          xmitsSubmitted \u003d Math.max((int)(task.getXmits() * xmitWeight), 1);\n           getDatanode().incrementXmitsInProcess(xmitsSubmitted);\n           stripedReconstructionPool.submit(task);\n         } else {\n           LOG.warn(\"No missing internal block. Skip reconstruction for task:{}\",\n               reconInfo);\n         }\n       } catch (Throwable e) {\n         getDatanode().decrementXmitsInProgress(xmitsSubmitted);\n         LOG.warn(\"Failed to reconstruct striped block {}\",\n             reconInfo.getExtendedBlock().getLocalBlock(), e);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void processErasureCodingTasks(\n      Collection\u003cBlockECReconstructionInfo\u003e ecTasks) {\n    for (BlockECReconstructionInfo reconInfo : ecTasks) {\n      int xmitsSubmitted \u003d 0;\n      try {\n        StripedReconstructionInfo stripedReconInfo \u003d\n            new StripedReconstructionInfo(\n            reconInfo.getExtendedBlock(), reconInfo.getErasureCodingPolicy(),\n            reconInfo.getLiveBlockIndices(), reconInfo.getSourceDnInfos(),\n            reconInfo.getTargetDnInfos(), reconInfo.getTargetStorageTypes(),\n            reconInfo.getTargetStorageIDs());\n        // It may throw IllegalArgumentException from task#stripedReader\n        // constructor.\n        final StripedBlockReconstructor task \u003d\n            new StripedBlockReconstructor(this, stripedReconInfo);\n        if (task.hasValidTargets()) {\n          // See HDFS-12044. We increase xmitsInProgress even the task is only\n          // enqueued, so that\n          //   1) NN will not send more tasks than what DN can execute and\n          //   2) DN will not throw away reconstruction tasks, and instead keeps\n          //      an unbounded number of tasks in the executor\u0027s task queue.\n          xmitsSubmitted \u003d Math.max((int)(task.getXmits() * xmitWeight), 1);\n          getDatanode().incrementXmitsInProcess(xmitsSubmitted);\n          stripedReconstructionPool.submit(task);\n        } else {\n          LOG.warn(\"No missing internal block. Skip reconstruction for task:{}\",\n              reconInfo);\n        }\n      } catch (Throwable e) {\n        getDatanode().decrementXmitsInProgress(xmitsSubmitted);\n        LOG.warn(\"Failed to reconstruct striped block {}\",\n            reconInfo.getExtendedBlock().getLocalBlock(), e);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/erasurecode/ErasureCodingWorker.java",
      "extendedDetails": {}
    },
    "77791e4c36ddc9305306c83806bf486d4d32575d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12044. Mismatch between BlockManager.maxReplicationStreams and ErasureCodingWorker.stripedReconstructionPool pool size causes slow and bursty recovery. (Contributed by Lei (Eddy) Xu)\n",
      "commitDate": "28/07/17 10:50 AM",
      "commitName": "77791e4c36ddc9305306c83806bf486d4d32575d",
      "commitAuthor": "Lei Xu",
      "commitDateOld": "05/05/17 12:01 PM",
      "commitNameOld": "a3954ccab148bddc290cb96528e63ff19799bcc9",
      "commitAuthorOld": "Chris Douglas",
      "daysBetweenCommits": 83.95,
      "commitsBetweenForRepo": 406,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,35 @@\n   public void processErasureCodingTasks(\n       Collection\u003cBlockECReconstructionInfo\u003e ecTasks) {\n     for (BlockECReconstructionInfo reconInfo : ecTasks) {\n+      int xmitsSubmitted \u003d 0;\n       try {\n         StripedReconstructionInfo stripedReconInfo \u003d\n             new StripedReconstructionInfo(\n             reconInfo.getExtendedBlock(), reconInfo.getErasureCodingPolicy(),\n             reconInfo.getLiveBlockIndices(), reconInfo.getSourceDnInfos(),\n             reconInfo.getTargetDnInfos(), reconInfo.getTargetStorageTypes(),\n             reconInfo.getTargetStorageIDs());\n+        // It may throw IllegalArgumentException from task#stripedReader\n+        // constructor.\n         final StripedBlockReconstructor task \u003d\n             new StripedBlockReconstructor(this, stripedReconInfo);\n         if (task.hasValidTargets()) {\n+          // See HDFS-12044. We increase xmitsInProgress even the task is only\n+          // enqueued, so that\n+          //   1) NN will not send more tasks than what DN can execute and\n+          //   2) DN will not throw away reconstruction tasks, and instead keeps\n+          //      an unbounded number of tasks in the executor\u0027s task queue.\n+          xmitsSubmitted \u003d task.getXmits();\n+          getDatanode().incrementXmitsInProcess(xmitsSubmitted);\n           stripedReconstructionPool.submit(task);\n         } else {\n           LOG.warn(\"No missing internal block. Skip reconstruction for task:{}\",\n               reconInfo);\n         }\n       } catch (Throwable e) {\n+        getDatanode().decrementXmitsInProgress(xmitsSubmitted);\n         LOG.warn(\"Failed to reconstruct striped block {}\",\n             reconInfo.getExtendedBlock().getLocalBlock(), e);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void processErasureCodingTasks(\n      Collection\u003cBlockECReconstructionInfo\u003e ecTasks) {\n    for (BlockECReconstructionInfo reconInfo : ecTasks) {\n      int xmitsSubmitted \u003d 0;\n      try {\n        StripedReconstructionInfo stripedReconInfo \u003d\n            new StripedReconstructionInfo(\n            reconInfo.getExtendedBlock(), reconInfo.getErasureCodingPolicy(),\n            reconInfo.getLiveBlockIndices(), reconInfo.getSourceDnInfos(),\n            reconInfo.getTargetDnInfos(), reconInfo.getTargetStorageTypes(),\n            reconInfo.getTargetStorageIDs());\n        // It may throw IllegalArgumentException from task#stripedReader\n        // constructor.\n        final StripedBlockReconstructor task \u003d\n            new StripedBlockReconstructor(this, stripedReconInfo);\n        if (task.hasValidTargets()) {\n          // See HDFS-12044. We increase xmitsInProgress even the task is only\n          // enqueued, so that\n          //   1) NN will not send more tasks than what DN can execute and\n          //   2) DN will not throw away reconstruction tasks, and instead keeps\n          //      an unbounded number of tasks in the executor\u0027s task queue.\n          xmitsSubmitted \u003d task.getXmits();\n          getDatanode().incrementXmitsInProcess(xmitsSubmitted);\n          stripedReconstructionPool.submit(task);\n        } else {\n          LOG.warn(\"No missing internal block. Skip reconstruction for task:{}\",\n              reconInfo);\n        }\n      } catch (Throwable e) {\n        getDatanode().decrementXmitsInProgress(xmitsSubmitted);\n        LOG.warn(\"Failed to reconstruct striped block {}\",\n            reconInfo.getExtendedBlock().getLocalBlock(), e);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/erasurecode/ErasureCodingWorker.java",
      "extendedDetails": {}
    },
    "a3954ccab148bddc290cb96528e63ff19799bcc9": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9807. Add an optional StorageID to writes. Contributed by Ewan Higgs\n",
      "commitDate": "05/05/17 12:01 PM",
      "commitName": "a3954ccab148bddc290cb96528e63ff19799bcc9",
      "commitAuthor": "Chris Douglas",
      "commitDateOld": "02/11/16 4:45 PM",
      "commitNameOld": "b59206190e6f773fc223bcb81774a09715551367",
      "commitAuthorOld": "Lei Xu",
      "daysBetweenCommits": 183.8,
      "commitsBetweenForRepo": 1047,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,24 @@\n   public void processErasureCodingTasks(\n       Collection\u003cBlockECReconstructionInfo\u003e ecTasks) {\n     for (BlockECReconstructionInfo reconInfo : ecTasks) {\n       try {\n         StripedReconstructionInfo stripedReconInfo \u003d\n             new StripedReconstructionInfo(\n             reconInfo.getExtendedBlock(), reconInfo.getErasureCodingPolicy(),\n             reconInfo.getLiveBlockIndices(), reconInfo.getSourceDnInfos(),\n-            reconInfo.getTargetDnInfos(), reconInfo.getTargetStorageTypes());\n+            reconInfo.getTargetDnInfos(), reconInfo.getTargetStorageTypes(),\n+            reconInfo.getTargetStorageIDs());\n         final StripedBlockReconstructor task \u003d\n             new StripedBlockReconstructor(this, stripedReconInfo);\n         if (task.hasValidTargets()) {\n           stripedReconstructionPool.submit(task);\n         } else {\n           LOG.warn(\"No missing internal block. Skip reconstruction for task:{}\",\n               reconInfo);\n         }\n       } catch (Throwable e) {\n         LOG.warn(\"Failed to reconstruct striped block {}\",\n             reconInfo.getExtendedBlock().getLocalBlock(), e);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void processErasureCodingTasks(\n      Collection\u003cBlockECReconstructionInfo\u003e ecTasks) {\n    for (BlockECReconstructionInfo reconInfo : ecTasks) {\n      try {\n        StripedReconstructionInfo stripedReconInfo \u003d\n            new StripedReconstructionInfo(\n            reconInfo.getExtendedBlock(), reconInfo.getErasureCodingPolicy(),\n            reconInfo.getLiveBlockIndices(), reconInfo.getSourceDnInfos(),\n            reconInfo.getTargetDnInfos(), reconInfo.getTargetStorageTypes(),\n            reconInfo.getTargetStorageIDs());\n        final StripedBlockReconstructor task \u003d\n            new StripedBlockReconstructor(this, stripedReconInfo);\n        if (task.hasValidTargets()) {\n          stripedReconstructionPool.submit(task);\n        } else {\n          LOG.warn(\"No missing internal block. Skip reconstruction for task:{}\",\n              reconInfo);\n        }\n      } catch (Throwable e) {\n        LOG.warn(\"Failed to reconstruct striped block {}\",\n            reconInfo.getExtendedBlock().getLocalBlock(), e);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/erasurecode/ErasureCodingWorker.java",
      "extendedDetails": {}
    },
    "d749cf65e1ab0e0daf5be86931507183f189e855": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9833. Erasure coding: recomputing block checksum on the fly by reconstructing the missed/corrupt block data. Contributed by Rakesh R.\n",
      "commitDate": "01/06/16 9:56 PM",
      "commitName": "d749cf65e1ab0e0daf5be86931507183f189e855",
      "commitAuthor": "Kai Zheng",
      "commitDateOld": "06/04/16 10:50 PM",
      "commitNameOld": "3c18a53cbd2efabb2ad108d63a0b0b558424115f",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 55.96,
      "commitsBetweenForRepo": 351,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,18 +1,23 @@\n   public void processErasureCodingTasks(\n       Collection\u003cBlockECReconstructionInfo\u003e ecTasks) {\n-    for (BlockECReconstructionInfo reconstructionInfo : ecTasks) {\n+    for (BlockECReconstructionInfo reconInfo : ecTasks) {\n       try {\n-        final StripedReconstructor task \u003d\n-            new StripedReconstructor(this, reconstructionInfo);\n+        StripedReconstructionInfo stripedReconInfo \u003d\n+            new StripedReconstructionInfo(\n+            reconInfo.getExtendedBlock(), reconInfo.getErasureCodingPolicy(),\n+            reconInfo.getLiveBlockIndices(), reconInfo.getSourceDnInfos(),\n+            reconInfo.getTargetDnInfos(), reconInfo.getTargetStorageTypes());\n+        final StripedBlockReconstructor task \u003d\n+            new StripedBlockReconstructor(this, stripedReconInfo);\n         if (task.hasValidTargets()) {\n           stripedReconstructionPool.submit(task);\n         } else {\n           LOG.warn(\"No missing internal block. Skip reconstruction for task:{}\",\n-              reconstructionInfo);\n+              reconInfo);\n         }\n       } catch (Throwable e) {\n         LOG.warn(\"Failed to reconstruct striped block {}\",\n-            reconstructionInfo.getExtendedBlock().getLocalBlock(), e);\n+            reconInfo.getExtendedBlock().getLocalBlock(), e);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void processErasureCodingTasks(\n      Collection\u003cBlockECReconstructionInfo\u003e ecTasks) {\n    for (BlockECReconstructionInfo reconInfo : ecTasks) {\n      try {\n        StripedReconstructionInfo stripedReconInfo \u003d\n            new StripedReconstructionInfo(\n            reconInfo.getExtendedBlock(), reconInfo.getErasureCodingPolicy(),\n            reconInfo.getLiveBlockIndices(), reconInfo.getSourceDnInfos(),\n            reconInfo.getTargetDnInfos(), reconInfo.getTargetStorageTypes());\n        final StripedBlockReconstructor task \u003d\n            new StripedBlockReconstructor(this, stripedReconInfo);\n        if (task.hasValidTargets()) {\n          stripedReconstructionPool.submit(task);\n        } else {\n          LOG.warn(\"No missing internal block. Skip reconstruction for task:{}\",\n              reconInfo);\n        }\n      } catch (Throwable e) {\n        LOG.warn(\"Failed to reconstruct striped block {}\",\n            reconInfo.getExtendedBlock().getLocalBlock(), e);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/erasurecode/ErasureCodingWorker.java",
      "extendedDetails": {}
    },
    "3c18a53cbd2efabb2ad108d63a0b0b558424115f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9719. Refactoring ErasureCodingWorker into smaller reusable constructs. Contributed by Kai Zheng.\n",
      "commitDate": "06/04/16 10:50 PM",
      "commitName": "3c18a53cbd2efabb2ad108d63a0b0b558424115f",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "30/03/16 1:37 PM",
      "commitNameOld": "37e23ce45c592f3c9c48a08a52a5f46787f6c0e9",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 7.38,
      "commitsBetweenForRepo": 55,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,18 +1,18 @@\n   public void processErasureCodingTasks(\n       Collection\u003cBlockECReconstructionInfo\u003e ecTasks) {\n     for (BlockECReconstructionInfo reconstructionInfo : ecTasks) {\n       try {\n-        ReconstructAndTransferBlock task \u003d\n-            new ReconstructAndTransferBlock(reconstructionInfo);\n+        final StripedReconstructor task \u003d\n+            new StripedReconstructor(this, reconstructionInfo);\n         if (task.hasValidTargets()) {\n-          EC_RECONSTRUCTION_STRIPED_BLK_THREAD_POOL.submit(task);\n+          stripedReconstructionPool.submit(task);\n         } else {\n           LOG.warn(\"No missing internal block. Skip reconstruction for task:{}\",\n               reconstructionInfo);\n         }\n       } catch (Throwable e) {\n         LOG.warn(\"Failed to reconstruct striped block {}\",\n             reconstructionInfo.getExtendedBlock().getLocalBlock(), e);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void processErasureCodingTasks(\n      Collection\u003cBlockECReconstructionInfo\u003e ecTasks) {\n    for (BlockECReconstructionInfo reconstructionInfo : ecTasks) {\n      try {\n        final StripedReconstructor task \u003d\n            new StripedReconstructor(this, reconstructionInfo);\n        if (task.hasValidTargets()) {\n          stripedReconstructionPool.submit(task);\n        } else {\n          LOG.warn(\"No missing internal block. Skip reconstruction for task:{}\",\n              reconstructionInfo);\n        }\n      } catch (Throwable e) {\n        LOG.warn(\"Failed to reconstruct striped block {}\",\n            reconstructionInfo.getExtendedBlock().getLocalBlock(), e);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/erasurecode/ErasureCodingWorker.java",
      "extendedDetails": {}
    },
    "e54cc2931262bf49682a8323da9811976218c03b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9818. Correctly handle EC reconstruction work caused by not enough racks. Contributed by Jing Zhao.\n",
      "commitDate": "19/02/16 7:02 PM",
      "commitName": "e54cc2931262bf49682a8323da9811976218c03b",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "19/02/16 10:40 AM",
      "commitNameOld": "6546d9e7ff73d2c81a803f2c61a1376a8c426987",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 0.35,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,18 @@\n   public void processErasureCodingTasks(\n       Collection\u003cBlockECReconstructionInfo\u003e ecTasks) {\n     for (BlockECReconstructionInfo reconstructionInfo : ecTasks) {\n       try {\n-        EC_RECONSTRUCTION_STRIPED_BLK_THREAD_POOL\n-            .submit(new ReconstructAndTransferBlock(reconstructionInfo));\n+        ReconstructAndTransferBlock task \u003d\n+            new ReconstructAndTransferBlock(reconstructionInfo);\n+        if (task.hasValidTargets()) {\n+          EC_RECONSTRUCTION_STRIPED_BLK_THREAD_POOL.submit(task);\n+        } else {\n+          LOG.warn(\"No missing internal block. Skip reconstruction for task:{}\",\n+              reconstructionInfo);\n+        }\n       } catch (Throwable e) {\n         LOG.warn(\"Failed to reconstruct striped block {}\",\n             reconstructionInfo.getExtendedBlock().getLocalBlock(), e);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void processErasureCodingTasks(\n      Collection\u003cBlockECReconstructionInfo\u003e ecTasks) {\n    for (BlockECReconstructionInfo reconstructionInfo : ecTasks) {\n      try {\n        ReconstructAndTransferBlock task \u003d\n            new ReconstructAndTransferBlock(reconstructionInfo);\n        if (task.hasValidTargets()) {\n          EC_RECONSTRUCTION_STRIPED_BLK_THREAD_POOL.submit(task);\n        } else {\n          LOG.warn(\"No missing internal block. Skip reconstruction for task:{}\",\n              reconstructionInfo);\n        }\n      } catch (Throwable e) {\n        LOG.warn(\"Failed to reconstruct striped block {}\",\n            reconstructionInfo.getExtendedBlock().getLocalBlock(), e);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/erasurecode/ErasureCodingWorker.java",
      "extendedDetails": {}
    },
    "6546d9e7ff73d2c81a803f2c61a1376a8c426987": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9829. Erasure Coding: Improve few exception handling logic of ErasureCodingWorker. Contributed by Rakesh R.\n",
      "commitDate": "19/02/16 10:40 AM",
      "commitName": "6546d9e7ff73d2c81a803f2c61a1376a8c426987",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "02/02/16 12:32 PM",
      "commitNameOld": "4ae543fdcd6dcfbe32257b1e72a405df9aa73e17",
      "commitAuthorOld": "zhezhang",
      "daysBetweenCommits": 16.92,
      "commitsBetweenForRepo": 120,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,12 @@\n   public void processErasureCodingTasks(\n       Collection\u003cBlockECReconstructionInfo\u003e ecTasks) {\n     for (BlockECReconstructionInfo reconstructionInfo : ecTasks) {\n       try {\n         EC_RECONSTRUCTION_STRIPED_BLK_THREAD_POOL\n             .submit(new ReconstructAndTransferBlock(reconstructionInfo));\n       } catch (Throwable e) {\n-        LOG.warn(\"Failed to reconstruct striped block \"\n-            + reconstructionInfo.getExtendedBlock().getLocalBlock(), e);\n+        LOG.warn(\"Failed to reconstruct striped block {}\",\n+            reconstructionInfo.getExtendedBlock().getLocalBlock(), e);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void processErasureCodingTasks(\n      Collection\u003cBlockECReconstructionInfo\u003e ecTasks) {\n    for (BlockECReconstructionInfo reconstructionInfo : ecTasks) {\n      try {\n        EC_RECONSTRUCTION_STRIPED_BLK_THREAD_POOL\n            .submit(new ReconstructAndTransferBlock(reconstructionInfo));\n      } catch (Throwable e) {\n        LOG.warn(\"Failed to reconstruct striped block {}\",\n            reconstructionInfo.getExtendedBlock().getLocalBlock(), e);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/erasurecode/ErasureCodingWorker.java",
      "extendedDetails": {}
    },
    "4ae543fdcd6dcfbe32257b1e72a405df9aa73e17": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-9731. Erasure Coding: Rename BlockECRecoveryCommand to BlockECReconstructionCommand. Contributed by Rakesh R.\n\nChange-Id: I405365a8395770e494b92bfe9651f4f0366d8f28\n",
      "commitDate": "02/02/16 12:32 PM",
      "commitName": "4ae543fdcd6dcfbe32257b1e72a405df9aa73e17",
      "commitAuthor": "zhezhang",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-9731. Erasure Coding: Rename BlockECRecoveryCommand to BlockECReconstructionCommand. Contributed by Rakesh R.\n\nChange-Id: I405365a8395770e494b92bfe9651f4f0366d8f28\n",
          "commitDate": "02/02/16 12:32 PM",
          "commitName": "4ae543fdcd6dcfbe32257b1e72a405df9aa73e17",
          "commitAuthor": "zhezhang",
          "commitDateOld": "22/01/16 9:46 AM",
          "commitNameOld": "95363bcc7dae28ba9ae2cd7ee9a258fcb58cd932",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 11.12,
          "commitsBetweenForRepo": 72,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,12 @@\n-  public void processErasureCodingTasks(Collection\u003cBlockECRecoveryInfo\u003e ecTasks) {\n-    for (BlockECRecoveryInfo recoveryInfo : ecTasks) {\n+  public void processErasureCodingTasks(\n+      Collection\u003cBlockECReconstructionInfo\u003e ecTasks) {\n+    for (BlockECReconstructionInfo reconstructionInfo : ecTasks) {\n       try {\n-        STRIPED_BLK_RECOVERY_THREAD_POOL\n-            .submit(new ReconstructAndTransferBlock(recoveryInfo));\n+        EC_RECONSTRUCTION_STRIPED_BLK_THREAD_POOL\n+            .submit(new ReconstructAndTransferBlock(reconstructionInfo));\n       } catch (Throwable e) {\n-        LOG.warn(\"Failed to recover striped block \"\n-            + recoveryInfo.getExtendedBlock().getLocalBlock(), e);\n+        LOG.warn(\"Failed to reconstruct striped block \"\n+            + reconstructionInfo.getExtendedBlock().getLocalBlock(), e);\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void processErasureCodingTasks(\n      Collection\u003cBlockECReconstructionInfo\u003e ecTasks) {\n    for (BlockECReconstructionInfo reconstructionInfo : ecTasks) {\n      try {\n        EC_RECONSTRUCTION_STRIPED_BLK_THREAD_POOL\n            .submit(new ReconstructAndTransferBlock(reconstructionInfo));\n      } catch (Throwable e) {\n        LOG.warn(\"Failed to reconstruct striped block \"\n            + reconstructionInfo.getExtendedBlock().getLocalBlock(), e);\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/erasurecode/ErasureCodingWorker.java",
          "extendedDetails": {
            "oldValue": "[ecTasks-Collection\u003cBlockECRecoveryInfo\u003e]",
            "newValue": "[ecTasks-Collection\u003cBlockECReconstructionInfo\u003e]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-9731. Erasure Coding: Rename BlockECRecoveryCommand to BlockECReconstructionCommand. Contributed by Rakesh R.\n\nChange-Id: I405365a8395770e494b92bfe9651f4f0366d8f28\n",
          "commitDate": "02/02/16 12:32 PM",
          "commitName": "4ae543fdcd6dcfbe32257b1e72a405df9aa73e17",
          "commitAuthor": "zhezhang",
          "commitDateOld": "22/01/16 9:46 AM",
          "commitNameOld": "95363bcc7dae28ba9ae2cd7ee9a258fcb58cd932",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 11.12,
          "commitsBetweenForRepo": 72,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,12 @@\n-  public void processErasureCodingTasks(Collection\u003cBlockECRecoveryInfo\u003e ecTasks) {\n-    for (BlockECRecoveryInfo recoveryInfo : ecTasks) {\n+  public void processErasureCodingTasks(\n+      Collection\u003cBlockECReconstructionInfo\u003e ecTasks) {\n+    for (BlockECReconstructionInfo reconstructionInfo : ecTasks) {\n       try {\n-        STRIPED_BLK_RECOVERY_THREAD_POOL\n-            .submit(new ReconstructAndTransferBlock(recoveryInfo));\n+        EC_RECONSTRUCTION_STRIPED_BLK_THREAD_POOL\n+            .submit(new ReconstructAndTransferBlock(reconstructionInfo));\n       } catch (Throwable e) {\n-        LOG.warn(\"Failed to recover striped block \"\n-            + recoveryInfo.getExtendedBlock().getLocalBlock(), e);\n+        LOG.warn(\"Failed to reconstruct striped block \"\n+            + reconstructionInfo.getExtendedBlock().getLocalBlock(), e);\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void processErasureCodingTasks(\n      Collection\u003cBlockECReconstructionInfo\u003e ecTasks) {\n    for (BlockECReconstructionInfo reconstructionInfo : ecTasks) {\n      try {\n        EC_RECONSTRUCTION_STRIPED_BLK_THREAD_POOL\n            .submit(new ReconstructAndTransferBlock(reconstructionInfo));\n      } catch (Throwable e) {\n        LOG.warn(\"Failed to reconstruct striped block \"\n            + reconstructionInfo.getExtendedBlock().getLocalBlock(), e);\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/erasurecode/ErasureCodingWorker.java",
          "extendedDetails": {}
        }
      ]
    },
    "b762199adbd10173c588df67bd227393c5bbcce9": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9113. ErasureCodingWorker#processErasureCodingTasks should not fail to process remaining tasks due to one invalid ECTask. Contributed by Uma Maheswara Rao G.\n",
      "commitDate": "19/09/15 9:18 PM",
      "commitName": "b762199adbd10173c588df67bd227393c5bbcce9",
      "commitAuthor": "Uma Mahesh",
      "commitDateOld": "18/09/15 10:45 AM",
      "commitNameOld": "82a88b92b46911c1b33d11898f8f678a134a9b69",
      "commitAuthorOld": "Zhe Zhang",
      "daysBetweenCommits": 1.44,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,6 +1,11 @@\n   public void processErasureCodingTasks(Collection\u003cBlockECRecoveryInfo\u003e ecTasks) {\n     for (BlockECRecoveryInfo recoveryInfo : ecTasks) {\n-      STRIPED_BLK_RECOVERY_THREAD_POOL.submit(new ReconstructAndTransferBlock(\n-          recoveryInfo));\n+      try {\n+        STRIPED_BLK_RECOVERY_THREAD_POOL\n+            .submit(new ReconstructAndTransferBlock(recoveryInfo));\n+      } catch (Throwable e) {\n+        LOG.warn(\"Failed to recover striped block \"\n+            + recoveryInfo.getExtendedBlock().getLocalBlock(), e);\n+      }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void processErasureCodingTasks(Collection\u003cBlockECRecoveryInfo\u003e ecTasks) {\n    for (BlockECRecoveryInfo recoveryInfo : ecTasks) {\n      try {\n        STRIPED_BLK_RECOVERY_THREAD_POOL\n            .submit(new ReconstructAndTransferBlock(recoveryInfo));\n      } catch (Throwable e) {\n        LOG.warn(\"Failed to recover striped block \"\n            + recoveryInfo.getExtendedBlock().getLocalBlock(), e);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/erasurecode/ErasureCodingWorker.java",
      "extendedDetails": {}
    },
    "ced438a4bf50fe0ac9072c128e18249e6742956a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8899. Erasure Coding: use threadpool for EC recovery tasks on DataNode. Contributed by Rakesh R.\n\nChange-Id: I9429706ae3c9b10a9274c07b98da6ed54cce192b\n",
      "commitDate": "15/09/15 10:43 AM",
      "commitName": "ced438a4bf50fe0ac9072c128e18249e6742956a",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "13/08/15 10:04 AM",
      "commitNameOld": "1d37a8812160bb030244a1e6b1c753f962d8d2ed",
      "commitAuthorOld": "Zhe Zhang",
      "daysBetweenCommits": 33.03,
      "commitsBetweenForRepo": 119,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,10 +1,6 @@\n   public void processErasureCodingTasks(Collection\u003cBlockECRecoveryInfo\u003e ecTasks) {\n     for (BlockECRecoveryInfo recoveryInfo : ecTasks) {\n-      try {\n-        new Daemon(new ReconstructAndTransferBlock(recoveryInfo)).start();\n-      } catch (Throwable e) {\n-        LOG.warn(\"Failed to recover striped block \" + \n-            recoveryInfo.getExtendedBlock().getLocalBlock(), e);\n-      }\n+      STRIPED_BLK_RECOVERY_THREAD_POOL.submit(new ReconstructAndTransferBlock(\n+          recoveryInfo));\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void processErasureCodingTasks(Collection\u003cBlockECRecoveryInfo\u003e ecTasks) {\n    for (BlockECRecoveryInfo recoveryInfo : ecTasks) {\n      STRIPED_BLK_RECOVERY_THREAD_POOL.submit(new ReconstructAndTransferBlock(\n          recoveryInfo));\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/erasurecode/ErasureCodingWorker.java",
      "extendedDetails": {}
    },
    "6616de24cb14f1c2d0d6568fd4382062618834bd": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7348. Erasure Coding: DataNode reconstruct striped blocks. Contributed by Yi Liu.\n",
      "commitDate": "26/05/15 12:01 PM",
      "commitName": "6616de24cb14f1c2d0d6568fd4382062618834bd",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "26/05/15 11:59 AM",
      "commitNameOld": "014d8675c59d44ad68dec36db6afe3f3666a3f15",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 22,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,3 +1,10 @@\n   public void processErasureCodingTasks(Collection\u003cBlockECRecoveryInfo\u003e ecTasks) {\n-    // HDFS-7348 : Implement the actual recovery process\n+    for (BlockECRecoveryInfo recoveryInfo : ecTasks) {\n+      try {\n+        new Daemon(new ReconstructAndTransferBlock(recoveryInfo)).start();\n+      } catch (Throwable e) {\n+        LOG.warn(\"Failed to recover striped block \" + \n+            recoveryInfo.getExtendedBlock().getLocalBlock(), e);\n+      }\n+    }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void processErasureCodingTasks(Collection\u003cBlockECRecoveryInfo\u003e ecTasks) {\n    for (BlockECRecoveryInfo recoveryInfo : ecTasks) {\n      try {\n        new Daemon(new ReconstructAndTransferBlock(recoveryInfo)).start();\n      } catch (Throwable e) {\n        LOG.warn(\"Failed to recover striped block \" + \n            recoveryInfo.getExtendedBlock().getLocalBlock(), e);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/erasurecode/ErasureCodingWorker.java",
      "extendedDetails": {}
    },
    "014d8675c59d44ad68dec36db6afe3f3666a3f15": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-8024. Erasure Coding: ECworker frame, basics, bootstraping and configuration. (Contributed by Uma Maheswara Rao G)\n",
      "commitDate": "26/05/15 11:59 AM",
      "commitName": "014d8675c59d44ad68dec36db6afe3f3666a3f15",
      "commitAuthor": "Uma Maheswara Rao G",
      "diff": "@@ -0,0 +1,3 @@\n+  public void processErasureCodingTasks(Collection\u003cBlockECRecoveryInfo\u003e ecTasks) {\n+    // HDFS-7348 : Implement the actual recovery process\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void processErasureCodingTasks(Collection\u003cBlockECRecoveryInfo\u003e ecTasks) {\n    // HDFS-7348 : Implement the actual recovery process\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/erasurecode/ErasureCodingWorker.java"
    }
  }
}