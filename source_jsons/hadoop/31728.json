{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "AppIdKeyConverter.java",
  "functionName": "encode",
  "functionId": "encode___appIdStr-String",
  "sourceFilePath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-common/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/common/AppIdKeyConverter.java",
  "functionStartLine": 51,
  "functionEndLine": 61,
  "numCommitsSeen": 14,
  "timeTaken": 4340,
  "changeHistory": [
    "9af30d46c6e82332a8eda20cb3eb5f987e25e7a2",
    "b01514f65bc6090a50a583f67d1ecb5d74b6d276",
    "55f5886ea24671ff3db87a64aaba2e76b3355455",
    "6cf6ab7b780de2b0c2c9ea730e1f366965a0d682",
    "892b193bd77c15932b4c084c1d525b7017def0d4",
    "7b8cfa5c2ff62005c8b78867fedd64b48e50383d",
    "b51d0fef56a59b15489f5b932025718b4e9613d2"
  ],
  "changeHistoryShort": {
    "9af30d46c6e82332a8eda20cb3eb5f987e25e7a2": "Ymultichange(Yfilerename,Ybodychange)",
    "b01514f65bc6090a50a583f67d1ecb5d74b6d276": "Yfilerename",
    "55f5886ea24671ff3db87a64aaba2e76b3355455": "Ybodychange",
    "6cf6ab7b780de2b0c2c9ea730e1f366965a0d682": "Ybodychange",
    "892b193bd77c15932b4c084c1d525b7017def0d4": "Ybodychange",
    "7b8cfa5c2ff62005c8b78867fedd64b48e50383d": "Ymultichange(Ymovefromfile,Ymodifierchange,Ybodychange,Yrename)",
    "b51d0fef56a59b15489f5b932025718b4e9613d2": "Yintroduced"
  },
  "changeHistoryDetails": {
    "9af30d46c6e82332a8eda20cb3eb5f987e25e7a2": {
      "type": "Ymultichange(Yfilerename,Ybodychange)",
      "commitMessage": "YARN-7919. Refactor timelineservice-hbase module into submodules. Contributed by Haibo Chen.\n",
      "commitDate": "17/02/18 7:00 AM",
      "commitName": "9af30d46c6e82332a8eda20cb3eb5f987e25e7a2",
      "commitAuthor": "Rohith Sharma K S",
      "subchanges": [
        {
          "type": "Yfilerename",
          "commitMessage": "YARN-7919. Refactor timelineservice-hbase module into submodules. Contributed by Haibo Chen.\n",
          "commitDate": "17/02/18 7:00 AM",
          "commitName": "9af30d46c6e82332a8eda20cb3eb5f987e25e7a2",
          "commitAuthor": "Rohith Sharma K S",
          "commitDateOld": "17/02/18 3:24 AM",
          "commitNameOld": "a1e56a62863d8d494af309ec5f476c4b7e4d5ef9",
          "commitAuthorOld": "Arun Suresh",
          "daysBetweenCommits": 0.15,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,11 @@\n   public byte[] encode(String appIdStr) {\n     ApplicationId appId \u003d ApplicationId.fromString(appIdStr);\n     byte[] appIdBytes \u003d new byte[getKeySize()];\n     byte[] clusterTs \u003d Bytes.toBytes(\n         LongConverter.invertLong(appId.getClusterTimestamp()));\n     System.arraycopy(clusterTs, 0, appIdBytes, 0, Bytes.SIZEOF_LONG);\n     byte[] seqId \u003d Bytes.toBytes(\n-        HBaseTimelineStorageUtils.invertInt(appId.getId()));\n+        HBaseTimelineSchemaUtils.invertInt(appId.getId()));\n     System.arraycopy(seqId, 0, appIdBytes, Bytes.SIZEOF_LONG, Bytes.SIZEOF_INT);\n     return appIdBytes;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public byte[] encode(String appIdStr) {\n    ApplicationId appId \u003d ApplicationId.fromString(appIdStr);\n    byte[] appIdBytes \u003d new byte[getKeySize()];\n    byte[] clusterTs \u003d Bytes.toBytes(\n        LongConverter.invertLong(appId.getClusterTimestamp()));\n    System.arraycopy(clusterTs, 0, appIdBytes, 0, Bytes.SIZEOF_LONG);\n    byte[] seqId \u003d Bytes.toBytes(\n        HBaseTimelineSchemaUtils.invertInt(appId.getId()));\n    System.arraycopy(seqId, 0, appIdBytes, Bytes.SIZEOF_LONG, Bytes.SIZEOF_INT);\n    return appIdBytes;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-common/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/common/AppIdKeyConverter.java",
          "extendedDetails": {
            "oldPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/common/AppIdKeyConverter.java",
            "newPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-common/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/common/AppIdKeyConverter.java"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-7919. Refactor timelineservice-hbase module into submodules. Contributed by Haibo Chen.\n",
          "commitDate": "17/02/18 7:00 AM",
          "commitName": "9af30d46c6e82332a8eda20cb3eb5f987e25e7a2",
          "commitAuthor": "Rohith Sharma K S",
          "commitDateOld": "17/02/18 3:24 AM",
          "commitNameOld": "a1e56a62863d8d494af309ec5f476c4b7e4d5ef9",
          "commitAuthorOld": "Arun Suresh",
          "daysBetweenCommits": 0.15,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,11 @@\n   public byte[] encode(String appIdStr) {\n     ApplicationId appId \u003d ApplicationId.fromString(appIdStr);\n     byte[] appIdBytes \u003d new byte[getKeySize()];\n     byte[] clusterTs \u003d Bytes.toBytes(\n         LongConverter.invertLong(appId.getClusterTimestamp()));\n     System.arraycopy(clusterTs, 0, appIdBytes, 0, Bytes.SIZEOF_LONG);\n     byte[] seqId \u003d Bytes.toBytes(\n-        HBaseTimelineStorageUtils.invertInt(appId.getId()));\n+        HBaseTimelineSchemaUtils.invertInt(appId.getId()));\n     System.arraycopy(seqId, 0, appIdBytes, Bytes.SIZEOF_LONG, Bytes.SIZEOF_INT);\n     return appIdBytes;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public byte[] encode(String appIdStr) {\n    ApplicationId appId \u003d ApplicationId.fromString(appIdStr);\n    byte[] appIdBytes \u003d new byte[getKeySize()];\n    byte[] clusterTs \u003d Bytes.toBytes(\n        LongConverter.invertLong(appId.getClusterTimestamp()));\n    System.arraycopy(clusterTs, 0, appIdBytes, 0, Bytes.SIZEOF_LONG);\n    byte[] seqId \u003d Bytes.toBytes(\n        HBaseTimelineSchemaUtils.invertInt(appId.getId()));\n    System.arraycopy(seqId, 0, appIdBytes, Bytes.SIZEOF_LONG, Bytes.SIZEOF_INT);\n    return appIdBytes;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-common/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/common/AppIdKeyConverter.java",
          "extendedDetails": {}
        }
      ]
    },
    "b01514f65bc6090a50a583f67d1ecb5d74b6d276": {
      "type": "Yfilerename",
      "commitMessage": "YARN-5928. Move ATSv2 HBase backend code into a new module that is only dependent at runtime by yarn servers. Contributed by Haibo Chen.\n",
      "commitDate": "19/01/17 8:52 PM",
      "commitName": "b01514f65bc6090a50a583f67d1ecb5d74b6d276",
      "commitAuthor": "Sangjin Lee",
      "commitDateOld": "19/01/17 5:32 PM",
      "commitNameOld": "60865c8ea08053f3d6ac23f81c3376a3de3ca996",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 0.14,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public byte[] encode(String appIdStr) {\n    ApplicationId appId \u003d ApplicationId.fromString(appIdStr);\n    byte[] appIdBytes \u003d new byte[getKeySize()];\n    byte[] clusterTs \u003d Bytes.toBytes(\n        LongConverter.invertLong(appId.getClusterTimestamp()));\n    System.arraycopy(clusterTs, 0, appIdBytes, 0, Bytes.SIZEOF_LONG);\n    byte[] seqId \u003d Bytes.toBytes(\n        HBaseTimelineStorageUtils.invertInt(appId.getId()));\n    System.arraycopy(seqId, 0, appIdBytes, Bytes.SIZEOF_LONG, Bytes.SIZEOF_INT);\n    return appIdBytes;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/common/AppIdKeyConverter.java",
      "extendedDetails": {
        "oldPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/common/AppIdKeyConverter.java",
        "newPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/common/AppIdKeyConverter.java"
      }
    },
    "55f5886ea24671ff3db87a64aaba2e76b3355455": {
      "type": "Ybodychange",
      "commitMessage": "YARN-5925. Extract hbase-backend-exclusive utility methods from TimelineStorageUtil. Contributed by Haibo Chen.\n",
      "commitDate": "09/12/16 4:17 PM",
      "commitName": "55f5886ea24671ff3db87a64aaba2e76b3355455",
      "commitAuthor": "Sangjin Lee",
      "commitDateOld": "10/07/16 8:46 AM",
      "commitNameOld": "6cf6ab7b780de2b0c2c9ea730e1f366965a0d682",
      "commitAuthorOld": "Sangjin Lee",
      "daysBetweenCommits": 152.36,
      "commitsBetweenForRepo": 1101,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,10 +1,11 @@\n   public byte[] encode(String appIdStr) {\n     ApplicationId appId \u003d ApplicationId.fromString(appIdStr);\n     byte[] appIdBytes \u003d new byte[getKeySize()];\n     byte[] clusterTs \u003d Bytes.toBytes(\n         LongConverter.invertLong(appId.getClusterTimestamp()));\n     System.arraycopy(clusterTs, 0, appIdBytes, 0, Bytes.SIZEOF_LONG);\n-    byte[] seqId \u003d Bytes.toBytes(TimelineStorageUtils.invertInt(appId.getId()));\n+    byte[] seqId \u003d Bytes.toBytes(\n+        HBaseTimelineStorageUtils.invertInt(appId.getId()));\n     System.arraycopy(seqId, 0, appIdBytes, Bytes.SIZEOF_LONG, Bytes.SIZEOF_INT);\n     return appIdBytes;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public byte[] encode(String appIdStr) {\n    ApplicationId appId \u003d ApplicationId.fromString(appIdStr);\n    byte[] appIdBytes \u003d new byte[getKeySize()];\n    byte[] clusterTs \u003d Bytes.toBytes(\n        LongConverter.invertLong(appId.getClusterTimestamp()));\n    System.arraycopy(clusterTs, 0, appIdBytes, 0, Bytes.SIZEOF_LONG);\n    byte[] seqId \u003d Bytes.toBytes(\n        HBaseTimelineStorageUtils.invertInt(appId.getId()));\n    System.arraycopy(seqId, 0, appIdBytes, Bytes.SIZEOF_LONG, Bytes.SIZEOF_INT);\n    return appIdBytes;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/common/AppIdKeyConverter.java",
      "extendedDetails": {}
    },
    "6cf6ab7b780de2b0c2c9ea730e1f366965a0d682": {
      "type": "Ybodychange",
      "commitMessage": "Made a number of miscellaneous fixes for javac, javadoc, and checstyle warnings.\n",
      "commitDate": "10/07/16 8:46 AM",
      "commitName": "6cf6ab7b780de2b0c2c9ea730e1f366965a0d682",
      "commitAuthor": "Sangjin Lee",
      "commitDateOld": "10/07/16 8:46 AM",
      "commitNameOld": "892b193bd77c15932b4c084c1d525b7017def0d4",
      "commitAuthorOld": "Varun Saxena",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 9,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,10 +1,10 @@\n   public byte[] encode(String appIdStr) {\n-    ApplicationId appId \u003d ConverterUtils.toApplicationId(appIdStr);\n+    ApplicationId appId \u003d ApplicationId.fromString(appIdStr);\n     byte[] appIdBytes \u003d new byte[getKeySize()];\n     byte[] clusterTs \u003d Bytes.toBytes(\n         LongConverter.invertLong(appId.getClusterTimestamp()));\n     System.arraycopy(clusterTs, 0, appIdBytes, 0, Bytes.SIZEOF_LONG);\n     byte[] seqId \u003d Bytes.toBytes(TimelineStorageUtils.invertInt(appId.getId()));\n     System.arraycopy(seqId, 0, appIdBytes, Bytes.SIZEOF_LONG, Bytes.SIZEOF_INT);\n     return appIdBytes;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public byte[] encode(String appIdStr) {\n    ApplicationId appId \u003d ApplicationId.fromString(appIdStr);\n    byte[] appIdBytes \u003d new byte[getKeySize()];\n    byte[] clusterTs \u003d Bytes.toBytes(\n        LongConverter.invertLong(appId.getClusterTimestamp()));\n    System.arraycopy(clusterTs, 0, appIdBytes, 0, Bytes.SIZEOF_LONG);\n    byte[] seqId \u003d Bytes.toBytes(TimelineStorageUtils.invertInt(appId.getId()));\n    System.arraycopy(seqId, 0, appIdBytes, Bytes.SIZEOF_LONG, Bytes.SIZEOF_INT);\n    return appIdBytes;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/common/AppIdKeyConverter.java",
      "extendedDetails": {}
    },
    "892b193bd77c15932b4c084c1d525b7017def0d4": {
      "type": "Ybodychange",
      "commitMessage": "YARN-5170. Eliminate singleton converters and static method access. (Joep Rottinghuis via Varun Saxena)\n",
      "commitDate": "10/07/16 8:46 AM",
      "commitName": "892b193bd77c15932b4c084c1d525b7017def0d4",
      "commitAuthor": "Varun Saxena",
      "commitDateOld": "10/07/16 8:46 AM",
      "commitNameOld": "7b8cfa5c2ff62005c8b78867fedd64b48e50383d",
      "commitAuthorOld": "Sangjin Lee",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 7,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,10 +1,10 @@\n   public byte[] encode(String appIdStr) {\n     ApplicationId appId \u003d ConverterUtils.toApplicationId(appIdStr);\n     byte[] appIdBytes \u003d new byte[getKeySize()];\n     byte[] clusterTs \u003d Bytes.toBytes(\n-        TimelineStorageUtils.invertLong(appId.getClusterTimestamp()));\n+        LongConverter.invertLong(appId.getClusterTimestamp()));\n     System.arraycopy(clusterTs, 0, appIdBytes, 0, Bytes.SIZEOF_LONG);\n     byte[] seqId \u003d Bytes.toBytes(TimelineStorageUtils.invertInt(appId.getId()));\n     System.arraycopy(seqId, 0, appIdBytes, Bytes.SIZEOF_LONG, Bytes.SIZEOF_INT);\n     return appIdBytes;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public byte[] encode(String appIdStr) {\n    ApplicationId appId \u003d ConverterUtils.toApplicationId(appIdStr);\n    byte[] appIdBytes \u003d new byte[getKeySize()];\n    byte[] clusterTs \u003d Bytes.toBytes(\n        LongConverter.invertLong(appId.getClusterTimestamp()));\n    System.arraycopy(clusterTs, 0, appIdBytes, 0, Bytes.SIZEOF_LONG);\n    byte[] seqId \u003d Bytes.toBytes(TimelineStorageUtils.invertInt(appId.getId()));\n    System.arraycopy(seqId, 0, appIdBytes, Bytes.SIZEOF_LONG, Bytes.SIZEOF_INT);\n    return appIdBytes;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/common/AppIdKeyConverter.java",
      "extendedDetails": {}
    },
    "7b8cfa5c2ff62005c8b78867fedd64b48e50383d": {
      "type": "Ymultichange(Ymovefromfile,Ymodifierchange,Ybodychange,Yrename)",
      "commitMessage": "YARN-5109. timestamps are stored unencoded causing parse errors (Varun Saxena via sjlee)\n",
      "commitDate": "10/07/16 8:46 AM",
      "commitName": "7b8cfa5c2ff62005c8b78867fedd64b48e50383d",
      "commitAuthor": "Sangjin Lee",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "YARN-5109. timestamps are stored unencoded causing parse errors (Varun Saxena via sjlee)\n",
          "commitDate": "10/07/16 8:46 AM",
          "commitName": "7b8cfa5c2ff62005c8b78867fedd64b48e50383d",
          "commitAuthor": "Sangjin Lee",
          "commitDateOld": "10/07/16 8:46 AM",
          "commitNameOld": "d729e8211bbbbc49f4dc4d0250859bcf86f6acef",
          "commitAuthorOld": "Li Lu",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,9 +1,10 @@\n-  public static byte[] encodeAppId(String appIdStr) {\n+  public byte[] encode(String appIdStr) {\n     ApplicationId appId \u003d ConverterUtils.toApplicationId(appIdStr);\n-    byte[] appIdBytes \u003d new byte[Bytes.SIZEOF_LONG + Bytes.SIZEOF_INT];\n-    byte[] clusterTs \u003d Bytes.toBytes(invertLong(appId.getClusterTimestamp()));\n+    byte[] appIdBytes \u003d new byte[getKeySize()];\n+    byte[] clusterTs \u003d Bytes.toBytes(\n+        TimelineStorageUtils.invertLong(appId.getClusterTimestamp()));\n     System.arraycopy(clusterTs, 0, appIdBytes, 0, Bytes.SIZEOF_LONG);\n-    byte[] seqId \u003d Bytes.toBytes(invertInt(appId.getId()));\n+    byte[] seqId \u003d Bytes.toBytes(TimelineStorageUtils.invertInt(appId.getId()));\n     System.arraycopy(seqId, 0, appIdBytes, Bytes.SIZEOF_LONG, Bytes.SIZEOF_INT);\n     return appIdBytes;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public byte[] encode(String appIdStr) {\n    ApplicationId appId \u003d ConverterUtils.toApplicationId(appIdStr);\n    byte[] appIdBytes \u003d new byte[getKeySize()];\n    byte[] clusterTs \u003d Bytes.toBytes(\n        TimelineStorageUtils.invertLong(appId.getClusterTimestamp()));\n    System.arraycopy(clusterTs, 0, appIdBytes, 0, Bytes.SIZEOF_LONG);\n    byte[] seqId \u003d Bytes.toBytes(TimelineStorageUtils.invertInt(appId.getId()));\n    System.arraycopy(seqId, 0, appIdBytes, Bytes.SIZEOF_LONG, Bytes.SIZEOF_INT);\n    return appIdBytes;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/common/AppIdKeyConverter.java",
          "extendedDetails": {
            "oldPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/common/TimelineStorageUtils.java",
            "newPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/common/AppIdKeyConverter.java",
            "oldMethodName": "encodeAppId",
            "newMethodName": "encode"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "YARN-5109. timestamps are stored unencoded causing parse errors (Varun Saxena via sjlee)\n",
          "commitDate": "10/07/16 8:46 AM",
          "commitName": "7b8cfa5c2ff62005c8b78867fedd64b48e50383d",
          "commitAuthor": "Sangjin Lee",
          "commitDateOld": "10/07/16 8:46 AM",
          "commitNameOld": "d729e8211bbbbc49f4dc4d0250859bcf86f6acef",
          "commitAuthorOld": "Li Lu",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,9 +1,10 @@\n-  public static byte[] encodeAppId(String appIdStr) {\n+  public byte[] encode(String appIdStr) {\n     ApplicationId appId \u003d ConverterUtils.toApplicationId(appIdStr);\n-    byte[] appIdBytes \u003d new byte[Bytes.SIZEOF_LONG + Bytes.SIZEOF_INT];\n-    byte[] clusterTs \u003d Bytes.toBytes(invertLong(appId.getClusterTimestamp()));\n+    byte[] appIdBytes \u003d new byte[getKeySize()];\n+    byte[] clusterTs \u003d Bytes.toBytes(\n+        TimelineStorageUtils.invertLong(appId.getClusterTimestamp()));\n     System.arraycopy(clusterTs, 0, appIdBytes, 0, Bytes.SIZEOF_LONG);\n-    byte[] seqId \u003d Bytes.toBytes(invertInt(appId.getId()));\n+    byte[] seqId \u003d Bytes.toBytes(TimelineStorageUtils.invertInt(appId.getId()));\n     System.arraycopy(seqId, 0, appIdBytes, Bytes.SIZEOF_LONG, Bytes.SIZEOF_INT);\n     return appIdBytes;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public byte[] encode(String appIdStr) {\n    ApplicationId appId \u003d ConverterUtils.toApplicationId(appIdStr);\n    byte[] appIdBytes \u003d new byte[getKeySize()];\n    byte[] clusterTs \u003d Bytes.toBytes(\n        TimelineStorageUtils.invertLong(appId.getClusterTimestamp()));\n    System.arraycopy(clusterTs, 0, appIdBytes, 0, Bytes.SIZEOF_LONG);\n    byte[] seqId \u003d Bytes.toBytes(TimelineStorageUtils.invertInt(appId.getId()));\n    System.arraycopy(seqId, 0, appIdBytes, Bytes.SIZEOF_LONG, Bytes.SIZEOF_INT);\n    return appIdBytes;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/common/AppIdKeyConverter.java",
          "extendedDetails": {
            "oldValue": "[public, static]",
            "newValue": "[public]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-5109. timestamps are stored unencoded causing parse errors (Varun Saxena via sjlee)\n",
          "commitDate": "10/07/16 8:46 AM",
          "commitName": "7b8cfa5c2ff62005c8b78867fedd64b48e50383d",
          "commitAuthor": "Sangjin Lee",
          "commitDateOld": "10/07/16 8:46 AM",
          "commitNameOld": "d729e8211bbbbc49f4dc4d0250859bcf86f6acef",
          "commitAuthorOld": "Li Lu",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,9 +1,10 @@\n-  public static byte[] encodeAppId(String appIdStr) {\n+  public byte[] encode(String appIdStr) {\n     ApplicationId appId \u003d ConverterUtils.toApplicationId(appIdStr);\n-    byte[] appIdBytes \u003d new byte[Bytes.SIZEOF_LONG + Bytes.SIZEOF_INT];\n-    byte[] clusterTs \u003d Bytes.toBytes(invertLong(appId.getClusterTimestamp()));\n+    byte[] appIdBytes \u003d new byte[getKeySize()];\n+    byte[] clusterTs \u003d Bytes.toBytes(\n+        TimelineStorageUtils.invertLong(appId.getClusterTimestamp()));\n     System.arraycopy(clusterTs, 0, appIdBytes, 0, Bytes.SIZEOF_LONG);\n-    byte[] seqId \u003d Bytes.toBytes(invertInt(appId.getId()));\n+    byte[] seqId \u003d Bytes.toBytes(TimelineStorageUtils.invertInt(appId.getId()));\n     System.arraycopy(seqId, 0, appIdBytes, Bytes.SIZEOF_LONG, Bytes.SIZEOF_INT);\n     return appIdBytes;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public byte[] encode(String appIdStr) {\n    ApplicationId appId \u003d ConverterUtils.toApplicationId(appIdStr);\n    byte[] appIdBytes \u003d new byte[getKeySize()];\n    byte[] clusterTs \u003d Bytes.toBytes(\n        TimelineStorageUtils.invertLong(appId.getClusterTimestamp()));\n    System.arraycopy(clusterTs, 0, appIdBytes, 0, Bytes.SIZEOF_LONG);\n    byte[] seqId \u003d Bytes.toBytes(TimelineStorageUtils.invertInt(appId.getId()));\n    System.arraycopy(seqId, 0, appIdBytes, Bytes.SIZEOF_LONG, Bytes.SIZEOF_INT);\n    return appIdBytes;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/common/AppIdKeyConverter.java",
          "extendedDetails": {}
        },
        {
          "type": "Yrename",
          "commitMessage": "YARN-5109. timestamps are stored unencoded causing parse errors (Varun Saxena via sjlee)\n",
          "commitDate": "10/07/16 8:46 AM",
          "commitName": "7b8cfa5c2ff62005c8b78867fedd64b48e50383d",
          "commitAuthor": "Sangjin Lee",
          "commitDateOld": "10/07/16 8:46 AM",
          "commitNameOld": "d729e8211bbbbc49f4dc4d0250859bcf86f6acef",
          "commitAuthorOld": "Li Lu",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,9 +1,10 @@\n-  public static byte[] encodeAppId(String appIdStr) {\n+  public byte[] encode(String appIdStr) {\n     ApplicationId appId \u003d ConverterUtils.toApplicationId(appIdStr);\n-    byte[] appIdBytes \u003d new byte[Bytes.SIZEOF_LONG + Bytes.SIZEOF_INT];\n-    byte[] clusterTs \u003d Bytes.toBytes(invertLong(appId.getClusterTimestamp()));\n+    byte[] appIdBytes \u003d new byte[getKeySize()];\n+    byte[] clusterTs \u003d Bytes.toBytes(\n+        TimelineStorageUtils.invertLong(appId.getClusterTimestamp()));\n     System.arraycopy(clusterTs, 0, appIdBytes, 0, Bytes.SIZEOF_LONG);\n-    byte[] seqId \u003d Bytes.toBytes(invertInt(appId.getId()));\n+    byte[] seqId \u003d Bytes.toBytes(TimelineStorageUtils.invertInt(appId.getId()));\n     System.arraycopy(seqId, 0, appIdBytes, Bytes.SIZEOF_LONG, Bytes.SIZEOF_INT);\n     return appIdBytes;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public byte[] encode(String appIdStr) {\n    ApplicationId appId \u003d ConverterUtils.toApplicationId(appIdStr);\n    byte[] appIdBytes \u003d new byte[getKeySize()];\n    byte[] clusterTs \u003d Bytes.toBytes(\n        TimelineStorageUtils.invertLong(appId.getClusterTimestamp()));\n    System.arraycopy(clusterTs, 0, appIdBytes, 0, Bytes.SIZEOF_LONG);\n    byte[] seqId \u003d Bytes.toBytes(TimelineStorageUtils.invertInt(appId.getId()));\n    System.arraycopy(seqId, 0, appIdBytes, Bytes.SIZEOF_LONG, Bytes.SIZEOF_INT);\n    return appIdBytes;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/common/AppIdKeyConverter.java",
          "extendedDetails": {
            "oldValue": "encodeAppId",
            "newValue": "encode"
          }
        }
      ]
    },
    "b51d0fef56a59b15489f5b932025718b4e9613d2": {
      "type": "Yintroduced",
      "commitMessage": "YARN-4178. [storage implementation] app id as string in row keys can cause incorrect ordering (Varun Saxena via sjlee)\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "b51d0fef56a59b15489f5b932025718b4e9613d2",
      "commitAuthor": "Sangjin Lee",
      "diff": "@@ -0,0 +1,9 @@\n+  public static byte[] encodeAppId(String appIdStr) {\n+    ApplicationId appId \u003d ConverterUtils.toApplicationId(appIdStr);\n+    byte[] appIdBytes \u003d new byte[Bytes.SIZEOF_LONG + Bytes.SIZEOF_INT];\n+    byte[] clusterTs \u003d Bytes.toBytes(invertLong(appId.getClusterTimestamp()));\n+    System.arraycopy(clusterTs, 0, appIdBytes, 0, Bytes.SIZEOF_LONG);\n+    byte[] seqId \u003d Bytes.toBytes(invertInt(appId.getId()));\n+    System.arraycopy(seqId, 0, appIdBytes, Bytes.SIZEOF_LONG, Bytes.SIZEOF_INT);\n+    return appIdBytes;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public static byte[] encodeAppId(String appIdStr) {\n    ApplicationId appId \u003d ConverterUtils.toApplicationId(appIdStr);\n    byte[] appIdBytes \u003d new byte[Bytes.SIZEOF_LONG + Bytes.SIZEOF_INT];\n    byte[] clusterTs \u003d Bytes.toBytes(invertLong(appId.getClusterTimestamp()));\n    System.arraycopy(clusterTs, 0, appIdBytes, 0, Bytes.SIZEOF_LONG);\n    byte[] seqId \u003d Bytes.toBytes(invertInt(appId.getId()));\n    System.arraycopy(seqId, 0, appIdBytes, Bytes.SIZEOF_LONG, Bytes.SIZEOF_INT);\n    return appIdBytes;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/common/TimelineStorageUtils.java"
    }
  }
}