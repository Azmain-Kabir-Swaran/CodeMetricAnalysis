{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FsDatasetUtil.java",
  "functionName": "openAndSeek",
  "functionId": "openAndSeek___file-File__offset-long",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetUtil.java",
  "functionStartLine": 110,
  "functionEndLine": 123,
  "numCommitsSeen": 146,
  "timeTaken": 5757,
  "changeHistory": [
    "6ba9587d370fbf39c129c08c00ebbb894ccc1389",
    "86c9862bec0248d671e657aa56094a2919b8ac14",
    "d085eb15d7ca7b43a69bd70bad4e2ea601ba2ae0"
  ],
  "changeHistoryShort": {
    "6ba9587d370fbf39c129c08c00ebbb894ccc1389": "Ymultichange(Yreturntypechange,Ybodychange)",
    "86c9862bec0248d671e657aa56094a2919b8ac14": "Ymultichange(Ymovefromfile,Ymodifierchange)",
    "d085eb15d7ca7b43a69bd70bad4e2ea601ba2ae0": "Yintroduced"
  },
  "changeHistoryDetails": {
    "6ba9587d370fbf39c129c08c00ebbb894ccc1389": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-10958. Add instrumentation hooks around Datanode disk IO.\n",
      "commitDate": "14/12/16 11:18 AM",
      "commitName": "6ba9587d370fbf39c129c08c00ebbb894ccc1389",
      "commitAuthor": "Arpit Agarwal",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-10958. Add instrumentation hooks around Datanode disk IO.\n",
          "commitDate": "14/12/16 11:18 AM",
          "commitName": "6ba9587d370fbf39c129c08c00ebbb894ccc1389",
          "commitAuthor": "Arpit Agarwal",
          "commitDateOld": "18/10/16 10:42 PM",
          "commitNameOld": "c5573e6a7599da17cad733cd274e7a9b75b22bb0",
          "commitAuthorOld": "Xiao Chen",
          "daysBetweenCommits": 56.57,
          "commitsBetweenForRepo": 446,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,14 +1,14 @@\n-  public static FileInputStream openAndSeek(File file, long offset)\n+  public static FileDescriptor openAndSeek(File file, long offset)\n       throws IOException {\n     RandomAccessFile raf \u003d null;\n     try {\n       raf \u003d new RandomAccessFile(file, \"r\");\n       if (offset \u003e 0) {\n         raf.seek(offset);\n       }\n-      return new FileInputStream(raf.getFD());\n+      return raf.getFD();\n     } catch(IOException ioe) {\n       IOUtils.cleanup(null, raf);\n       throw ioe;\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static FileDescriptor openAndSeek(File file, long offset)\n      throws IOException {\n    RandomAccessFile raf \u003d null;\n    try {\n      raf \u003d new RandomAccessFile(file, \"r\");\n      if (offset \u003e 0) {\n        raf.seek(offset);\n      }\n      return raf.getFD();\n    } catch(IOException ioe) {\n      IOUtils.cleanup(null, raf);\n      throw ioe;\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetUtil.java",
          "extendedDetails": {
            "oldValue": "FileInputStream",
            "newValue": "FileDescriptor"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-10958. Add instrumentation hooks around Datanode disk IO.\n",
          "commitDate": "14/12/16 11:18 AM",
          "commitName": "6ba9587d370fbf39c129c08c00ebbb894ccc1389",
          "commitAuthor": "Arpit Agarwal",
          "commitDateOld": "18/10/16 10:42 PM",
          "commitNameOld": "c5573e6a7599da17cad733cd274e7a9b75b22bb0",
          "commitAuthorOld": "Xiao Chen",
          "daysBetweenCommits": 56.57,
          "commitsBetweenForRepo": 446,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,14 +1,14 @@\n-  public static FileInputStream openAndSeek(File file, long offset)\n+  public static FileDescriptor openAndSeek(File file, long offset)\n       throws IOException {\n     RandomAccessFile raf \u003d null;\n     try {\n       raf \u003d new RandomAccessFile(file, \"r\");\n       if (offset \u003e 0) {\n         raf.seek(offset);\n       }\n-      return new FileInputStream(raf.getFD());\n+      return raf.getFD();\n     } catch(IOException ioe) {\n       IOUtils.cleanup(null, raf);\n       throw ioe;\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static FileDescriptor openAndSeek(File file, long offset)\n      throws IOException {\n    RandomAccessFile raf \u003d null;\n    try {\n      raf \u003d new RandomAccessFile(file, \"r\");\n      if (offset \u003e 0) {\n        raf.seek(offset);\n      }\n      return raf.getFD();\n    } catch(IOException ioe) {\n      IOUtils.cleanup(null, raf);\n      throw ioe;\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetUtil.java",
          "extendedDetails": {}
        }
      ]
    },
    "86c9862bec0248d671e657aa56094a2919b8ac14": {
      "type": "Ymultichange(Ymovefromfile,Ymodifierchange)",
      "commitMessage": "HDFS-10636. Modify ReplicaInfo to remove the assumption that replica metadata and data are stored in java.io.File. (Virajith Jalaparti via lei)\n",
      "commitDate": "13/09/16 12:54 PM",
      "commitName": "86c9862bec0248d671e657aa56094a2919b8ac14",
      "commitAuthor": "Lei Xu",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-10636. Modify ReplicaInfo to remove the assumption that replica metadata and data are stored in java.io.File. (Virajith Jalaparti via lei)\n",
          "commitDate": "13/09/16 12:54 PM",
          "commitName": "86c9862bec0248d671e657aa56094a2919b8ac14",
          "commitAuthor": "Lei Xu",
          "commitDateOld": "13/09/16 12:42 PM",
          "commitNameOld": "1c0d18f32289837b8981aed80e7bdcd360adfb85",
          "commitAuthorOld": "Anu Engineer",
          "daysBetweenCommits": 0.01,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,14 +1,14 @@\n-  private static FileInputStream openAndSeek(File file, long offset)\n+  public static FileInputStream openAndSeek(File file, long offset)\n       throws IOException {\n     RandomAccessFile raf \u003d null;\n     try {\n       raf \u003d new RandomAccessFile(file, \"r\");\n       if (offset \u003e 0) {\n         raf.seek(offset);\n       }\n       return new FileInputStream(raf.getFD());\n     } catch(IOException ioe) {\n       IOUtils.cleanup(null, raf);\n       throw ioe;\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static FileInputStream openAndSeek(File file, long offset)\n      throws IOException {\n    RandomAccessFile raf \u003d null;\n    try {\n      raf \u003d new RandomAccessFile(file, \"r\");\n      if (offset \u003e 0) {\n        raf.seek(offset);\n      }\n      return new FileInputStream(raf.getFD());\n    } catch(IOException ioe) {\n      IOUtils.cleanup(null, raf);\n      throw ioe;\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetUtil.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetUtil.java",
            "oldMethodName": "openAndSeek",
            "newMethodName": "openAndSeek"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-10636. Modify ReplicaInfo to remove the assumption that replica metadata and data are stored in java.io.File. (Virajith Jalaparti via lei)\n",
          "commitDate": "13/09/16 12:54 PM",
          "commitName": "86c9862bec0248d671e657aa56094a2919b8ac14",
          "commitAuthor": "Lei Xu",
          "commitDateOld": "13/09/16 12:42 PM",
          "commitNameOld": "1c0d18f32289837b8981aed80e7bdcd360adfb85",
          "commitAuthorOld": "Anu Engineer",
          "daysBetweenCommits": 0.01,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,14 +1,14 @@\n-  private static FileInputStream openAndSeek(File file, long offset)\n+  public static FileInputStream openAndSeek(File file, long offset)\n       throws IOException {\n     RandomAccessFile raf \u003d null;\n     try {\n       raf \u003d new RandomAccessFile(file, \"r\");\n       if (offset \u003e 0) {\n         raf.seek(offset);\n       }\n       return new FileInputStream(raf.getFD());\n     } catch(IOException ioe) {\n       IOUtils.cleanup(null, raf);\n       throw ioe;\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static FileInputStream openAndSeek(File file, long offset)\n      throws IOException {\n    RandomAccessFile raf \u003d null;\n    try {\n      raf \u003d new RandomAccessFile(file, \"r\");\n      if (offset \u003e 0) {\n        raf.seek(offset);\n      }\n      return new FileInputStream(raf.getFD());\n    } catch(IOException ioe) {\n      IOUtils.cleanup(null, raf);\n      throw ioe;\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetUtil.java",
          "extendedDetails": {
            "oldValue": "[private, static]",
            "newValue": "[public, static]"
          }
        }
      ]
    },
    "d085eb15d7ca7b43a69bd70bad4e2ea601ba2ae0": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-7696. In FsDatasetImpl, the getBlockInputStream(..) and getTmpInputStreams(..) methods may leak file descriptors.\n",
      "commitDate": "02/02/15 1:38 PM",
      "commitName": "d085eb15d7ca7b43a69bd70bad4e2ea601ba2ae0",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "diff": "@@ -0,0 +1,14 @@\n+  private static FileInputStream openAndSeek(File file, long offset)\n+      throws IOException {\n+    RandomAccessFile raf \u003d null;\n+    try {\n+      raf \u003d new RandomAccessFile(file, \"r\");\n+      if (offset \u003e 0) {\n+        raf.seek(offset);\n+      }\n+      return new FileInputStream(raf.getFD());\n+    } catch(IOException ioe) {\n+      IOUtils.cleanup(null, raf);\n+      throw ioe;\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private static FileInputStream openAndSeek(File file, long offset)\n      throws IOException {\n    RandomAccessFile raf \u003d null;\n    try {\n      raf \u003d new RandomAccessFile(file, \"r\");\n      if (offset \u003e 0) {\n        raf.seek(offset);\n      }\n      return new FileInputStream(raf.getFD());\n    } catch(IOException ioe) {\n      IOUtils.cleanup(null, raf);\n      throw ioe;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java"
    }
  }
}