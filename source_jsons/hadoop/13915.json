{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockManager.java",
  "functionName": "getBlockPlacementStatus",
  "functionId": "getBlockPlacementStatus___storedBlock-BlockInfo__additionalStorage-DatanodeStorageInfo[]",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
  "functionStartLine": 4721,
  "functionEndLine": 4771,
  "numCommitsSeen": 477,
  "timeTaken": 2209,
  "changeHistory": [
    "c99a12167ff9566012ef32104a3964887d62c899"
  ],
  "changeHistoryShort": {
    "c99a12167ff9566012ef32104a3964887d62c899": "Yintroduced"
  },
  "changeHistoryDetails": {
    "c99a12167ff9566012ef32104a3964887d62c899": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-14637. Namenode may not replicate blocks to meet the policy after enabling upgradeDomain. Contributed by Stephen O\u0027Donnell.\n\nReviewed-by: Ayush Saxena \u003cayushsaxena@apache.org\u003e\nSigned-off-by: Wei-Chiu Chuang \u003cweichiu@apache.org\u003e\n",
      "commitDate": "03/10/19 10:13 PM",
      "commitName": "c99a12167ff9566012ef32104a3964887d62c899",
      "commitAuthor": "Stephen O\u0027Donnell",
      "diff": "@@ -0,0 +1,51 @@\n+  BlockPlacementStatus getBlockPlacementStatus(BlockInfo storedBlock,\n+      DatanodeStorageInfo[] additionalStorage) {\n+    List\u003cDatanodeDescriptor\u003e liveNodes \u003d new ArrayList\u003c\u003e();\n+    if (additionalStorage !\u003d null) {\n+      // additionalNodes, are potential new targets for the block. If there are\n+      // any passed, include them when checking the placement policy to see if\n+      // the policy is met, when it may not have been met without these nodes.\n+      for (DatanodeStorageInfo s : additionalStorage) {\n+        liveNodes.add(getDatanodeDescriptorFromStorage(s));\n+      }\n+    }\n+    Collection\u003cDatanodeDescriptor\u003e corruptNodes \u003d corruptReplicas\n+        .getNodes(storedBlock);\n+    for (DatanodeStorageInfo storage : blocksMap.getStorages(storedBlock)) {\n+      if (storage.getStorageType() \u003d\u003d StorageType.PROVIDED\n+          \u0026\u0026 storage.getState() \u003d\u003d State.NORMAL) {\n+        // assume the policy is satisfied for blocks on PROVIDED storage\n+        // as long as the storage is in normal state.\n+        return new BlockPlacementStatus() {\n+          @Override\n+          public boolean isPlacementPolicySatisfied() {\n+            return true;\n+          }\n+\n+          @Override\n+          public String getErrorDescription() {\n+            return null;\n+          }\n+\n+          @Override\n+          public int getAdditionalReplicasRequired() {\n+            return 0;\n+          }\n+        };\n+      }\n+      final DatanodeDescriptor cur \u003d getDatanodeDescriptorFromStorage(storage);\n+      // Nodes under maintenance should be counted as valid replicas from\n+      // rack policy point of view.\n+      if (!cur.isDecommissionInProgress() \u0026\u0026 !cur.isDecommissioned()\n+          \u0026\u0026 ((corruptNodes \u003d\u003d null) || !corruptNodes.contains(cur))) {\n+        liveNodes.add(cur);\n+      }\n+    }\n+    DatanodeInfo[] locs \u003d liveNodes.toArray(new DatanodeInfo[liveNodes.size()]);\n+    BlockType blockType \u003d storedBlock.getBlockType();\n+    BlockPlacementPolicy placementPolicy \u003d placementPolicies\n+        .getPolicy(blockType);\n+    int numReplicas \u003d blockType \u003d\u003d STRIPED ? ((BlockInfoStriped) storedBlock)\n+        .getRealTotalBlockNum() : storedBlock.getReplication();\n+    return placementPolicy.verifyBlockPlacement(locs, numReplicas);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  BlockPlacementStatus getBlockPlacementStatus(BlockInfo storedBlock,\n      DatanodeStorageInfo[] additionalStorage) {\n    List\u003cDatanodeDescriptor\u003e liveNodes \u003d new ArrayList\u003c\u003e();\n    if (additionalStorage !\u003d null) {\n      // additionalNodes, are potential new targets for the block. If there are\n      // any passed, include them when checking the placement policy to see if\n      // the policy is met, when it may not have been met without these nodes.\n      for (DatanodeStorageInfo s : additionalStorage) {\n        liveNodes.add(getDatanodeDescriptorFromStorage(s));\n      }\n    }\n    Collection\u003cDatanodeDescriptor\u003e corruptNodes \u003d corruptReplicas\n        .getNodes(storedBlock);\n    for (DatanodeStorageInfo storage : blocksMap.getStorages(storedBlock)) {\n      if (storage.getStorageType() \u003d\u003d StorageType.PROVIDED\n          \u0026\u0026 storage.getState() \u003d\u003d State.NORMAL) {\n        // assume the policy is satisfied for blocks on PROVIDED storage\n        // as long as the storage is in normal state.\n        return new BlockPlacementStatus() {\n          @Override\n          public boolean isPlacementPolicySatisfied() {\n            return true;\n          }\n\n          @Override\n          public String getErrorDescription() {\n            return null;\n          }\n\n          @Override\n          public int getAdditionalReplicasRequired() {\n            return 0;\n          }\n        };\n      }\n      final DatanodeDescriptor cur \u003d getDatanodeDescriptorFromStorage(storage);\n      // Nodes under maintenance should be counted as valid replicas from\n      // rack policy point of view.\n      if (!cur.isDecommissionInProgress() \u0026\u0026 !cur.isDecommissioned()\n          \u0026\u0026 ((corruptNodes \u003d\u003d null) || !corruptNodes.contains(cur))) {\n        liveNodes.add(cur);\n      }\n    }\n    DatanodeInfo[] locs \u003d liveNodes.toArray(new DatanodeInfo[liveNodes.size()]);\n    BlockType blockType \u003d storedBlock.getBlockType();\n    BlockPlacementPolicy placementPolicy \u003d placementPolicies\n        .getPolicy(blockType);\n    int numReplicas \u003d blockType \u003d\u003d STRIPED ? ((BlockInfoStriped) storedBlock)\n        .getRealTotalBlockNum() : storedBlock.getReplication();\n    return placementPolicy.verifyBlockPlacement(locs, numReplicas);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java"
    }
  }
}