{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "RamDiskReplicaLruTracker.java",
  "functionName": "recordEndLazyPersist",
  "functionId": "recordEndLazyPersist___bpid-String(modifiers-final)__blockId-long(modifiers-final)__savedFiles-File[](modifiers-final)",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/RamDiskReplicaLruTracker.java",
  "functionStartLine": 124,
  "functionEndLine": 146,
  "numCommitsSeen": 17,
  "timeTaken": 4078,
  "changeHistory": [
    "5e8b6973527e5f714652641ed95e8a4509e18cfa",
    "b2d5ed36bcb80e2581191dcdc3976e825c959142",
    "9f22fb8c9a10952225e15c7b67b5f77fa44b155d",
    "ccdf0054a354fc110124b83de742c2ee6076449e",
    "cb9b485075ce773f2d6189aa2f54bbc69aad4dab",
    "4cf9afacbe3d0814fb616d238aa9b16b1ae68386",
    "eb448e14399e17f11b9e523e4050de245b9b0408"
  ],
  "changeHistoryShort": {
    "5e8b6973527e5f714652641ed95e8a4509e18cfa": "Ybodychange",
    "b2d5ed36bcb80e2581191dcdc3976e825c959142": "Ymultichange(Ymovefromfile,Ybodychange)",
    "9f22fb8c9a10952225e15c7b67b5f77fa44b155d": "Ymultichange(Yparameterchange,Ybodychange)",
    "ccdf0054a354fc110124b83de742c2ee6076449e": "Ymultichange(Yparameterchange,Ybodychange,Yparametermetachange)",
    "cb9b485075ce773f2d6189aa2f54bbc69aad4dab": "Ybodychange",
    "4cf9afacbe3d0814fb616d238aa9b16b1ae68386": "Ybodychange",
    "eb448e14399e17f11b9e523e4050de245b9b0408": "Yintroduced"
  },
  "changeHistoryDetails": {
    "5e8b6973527e5f714652641ed95e8a4509e18cfa": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7129. Metrics to track usage of memory for writes. (Contributed by Xiaoyu Yao)\n",
      "commitDate": "30/09/14 12:53 AM",
      "commitName": "5e8b6973527e5f714652641ed95e8a4509e18cfa",
      "commitAuthor": "arp",
      "commitDateOld": "25/09/14 11:14 AM",
      "commitNameOld": "364e60b1691a4d7b2f745b8ebf78177f254a4287",
      "commitAuthorOld": "arp",
      "daysBetweenCommits": 4.57,
      "commitsBetweenForRepo": 54,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,23 @@\n   synchronized void recordEndLazyPersist(\n       final String bpid, final long blockId, final File[] savedFiles) {\n     Map\u003cLong, RamDiskReplicaLru\u003e map \u003d replicaMaps.get(bpid);\n     RamDiskReplicaLru ramDiskReplicaLru \u003d map.get(blockId);\n \n     if (ramDiskReplicaLru \u003d\u003d null) {\n       throw new IllegalStateException(\"Unknown replica bpid\u003d\" +\n           bpid + \"; blockId\u003d\" + blockId);\n     }\n     ramDiskReplicaLru.recordSavedBlockFiles(savedFiles);\n \n     if (replicasNotPersisted.peek() \u003d\u003d ramDiskReplicaLru) {\n       // Common case.\n       replicasNotPersisted.remove();\n     } else {\n       // Caller error? Fallback to O(n) removal.\n       replicasNotPersisted.remove(ramDiskReplicaLru);\n     }\n \n-    ramDiskReplicaLru.lastUsedTime \u003d System.currentTimeMillis();\n+    ramDiskReplicaLru.lastUsedTime \u003d Time.monotonicNow();\n     replicasPersisted.put(ramDiskReplicaLru.lastUsedTime, ramDiskReplicaLru);\n+    ramDiskReplicaLru.isPersisted \u003d true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  synchronized void recordEndLazyPersist(\n      final String bpid, final long blockId, final File[] savedFiles) {\n    Map\u003cLong, RamDiskReplicaLru\u003e map \u003d replicaMaps.get(bpid);\n    RamDiskReplicaLru ramDiskReplicaLru \u003d map.get(blockId);\n\n    if (ramDiskReplicaLru \u003d\u003d null) {\n      throw new IllegalStateException(\"Unknown replica bpid\u003d\" +\n          bpid + \"; blockId\u003d\" + blockId);\n    }\n    ramDiskReplicaLru.recordSavedBlockFiles(savedFiles);\n\n    if (replicasNotPersisted.peek() \u003d\u003d ramDiskReplicaLru) {\n      // Common case.\n      replicasNotPersisted.remove();\n    } else {\n      // Caller error? Fallback to O(n) removal.\n      replicasNotPersisted.remove(ramDiskReplicaLru);\n    }\n\n    ramDiskReplicaLru.lastUsedTime \u003d Time.monotonicNow();\n    replicasPersisted.put(ramDiskReplicaLru.lastUsedTime, ramDiskReplicaLru);\n    ramDiskReplicaLru.isPersisted \u003d true;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/RamDiskReplicaLruTracker.java",
      "extendedDetails": {}
    },
    "b2d5ed36bcb80e2581191dcdc3976e825c959142": {
      "type": "Ymultichange(Ymovefromfile,Ybodychange)",
      "commitMessage": "HDFS-7100. Make eviction scheme pluggable. (Arpit Agarwal)\n",
      "commitDate": "20/09/14 1:25 PM",
      "commitName": "b2d5ed36bcb80e2581191dcdc3976e825c959142",
      "commitAuthor": "arp",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-7100. Make eviction scheme pluggable. (Arpit Agarwal)\n",
          "commitDate": "20/09/14 1:25 PM",
          "commitName": "b2d5ed36bcb80e2581191dcdc3976e825c959142",
          "commitAuthor": "arp",
          "commitDateOld": "20/09/14 10:34 AM",
          "commitNameOld": "09dab88d3eeb9947211b075d8103f9b836a61e8a",
          "commitAuthorOld": "arp",
          "daysBetweenCommits": 0.12,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,25 +1,22 @@\n   synchronized void recordEndLazyPersist(\n       final String bpid, final long blockId, final File[] savedFiles) {\n-    Map\u003cLong, ReplicaState\u003e map \u003d replicaMaps.get(bpid);\n-    ReplicaState replicaState \u003d map.get(blockId);\n+    Map\u003cLong, RamDiskReplicaLru\u003e map \u003d replicaMaps.get(bpid);\n+    RamDiskReplicaLru ramDiskReplicaLru \u003d map.get(blockId);\n \n-    if (replicaState \u003d\u003d null) {\n+    if (ramDiskReplicaLru \u003d\u003d null) {\n       throw new IllegalStateException(\"Unknown replica bpid\u003d\" +\n           bpid + \"; blockId\u003d\" + blockId);\n     }\n-    replicaState.state \u003d State.LAZY_PERSIST_COMPLETE;\n-    replicaState.savedMetaFile \u003d savedFiles[0];\n-    replicaState.savedBlockFile \u003d savedFiles[1];\n+    ramDiskReplicaLru.recordSavedBlockFiles(savedFiles);\n \n-    if (replicasNotPersisted.peek() \u003d\u003d replicaState) {\n+    if (replicasNotPersisted.peek() \u003d\u003d ramDiskReplicaLru) {\n       // Common case.\n       replicasNotPersisted.remove();\n     } else {\n-      // Should never occur in practice as lazy writer always persists\n-      // the replica at the head of the queue before moving to the next\n-      // one.\n-      replicasNotPersisted.remove(replicaState);\n+      // Caller error? Fallback to O(n) removal.\n+      replicasNotPersisted.remove(ramDiskReplicaLru);\n     }\n \n-    replicasPersisted.add(replicaState);\n+    ramDiskReplicaLru.lastUsedTime \u003d System.currentTimeMillis();\n+    replicasPersisted.put(ramDiskReplicaLru.lastUsedTime, ramDiskReplicaLru);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  synchronized void recordEndLazyPersist(\n      final String bpid, final long blockId, final File[] savedFiles) {\n    Map\u003cLong, RamDiskReplicaLru\u003e map \u003d replicaMaps.get(bpid);\n    RamDiskReplicaLru ramDiskReplicaLru \u003d map.get(blockId);\n\n    if (ramDiskReplicaLru \u003d\u003d null) {\n      throw new IllegalStateException(\"Unknown replica bpid\u003d\" +\n          bpid + \"; blockId\u003d\" + blockId);\n    }\n    ramDiskReplicaLru.recordSavedBlockFiles(savedFiles);\n\n    if (replicasNotPersisted.peek() \u003d\u003d ramDiskReplicaLru) {\n      // Common case.\n      replicasNotPersisted.remove();\n    } else {\n      // Caller error? Fallback to O(n) removal.\n      replicasNotPersisted.remove(ramDiskReplicaLru);\n    }\n\n    ramDiskReplicaLru.lastUsedTime \u003d System.currentTimeMillis();\n    replicasPersisted.put(ramDiskReplicaLru.lastUsedTime, ramDiskReplicaLru);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/RamDiskReplicaLruTracker.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/LazyWriteReplicaTracker.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/RamDiskReplicaLruTracker.java",
            "oldMethodName": "recordEndLazyPersist",
            "newMethodName": "recordEndLazyPersist"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7100. Make eviction scheme pluggable. (Arpit Agarwal)\n",
          "commitDate": "20/09/14 1:25 PM",
          "commitName": "b2d5ed36bcb80e2581191dcdc3976e825c959142",
          "commitAuthor": "arp",
          "commitDateOld": "20/09/14 10:34 AM",
          "commitNameOld": "09dab88d3eeb9947211b075d8103f9b836a61e8a",
          "commitAuthorOld": "arp",
          "daysBetweenCommits": 0.12,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,25 +1,22 @@\n   synchronized void recordEndLazyPersist(\n       final String bpid, final long blockId, final File[] savedFiles) {\n-    Map\u003cLong, ReplicaState\u003e map \u003d replicaMaps.get(bpid);\n-    ReplicaState replicaState \u003d map.get(blockId);\n+    Map\u003cLong, RamDiskReplicaLru\u003e map \u003d replicaMaps.get(bpid);\n+    RamDiskReplicaLru ramDiskReplicaLru \u003d map.get(blockId);\n \n-    if (replicaState \u003d\u003d null) {\n+    if (ramDiskReplicaLru \u003d\u003d null) {\n       throw new IllegalStateException(\"Unknown replica bpid\u003d\" +\n           bpid + \"; blockId\u003d\" + blockId);\n     }\n-    replicaState.state \u003d State.LAZY_PERSIST_COMPLETE;\n-    replicaState.savedMetaFile \u003d savedFiles[0];\n-    replicaState.savedBlockFile \u003d savedFiles[1];\n+    ramDiskReplicaLru.recordSavedBlockFiles(savedFiles);\n \n-    if (replicasNotPersisted.peek() \u003d\u003d replicaState) {\n+    if (replicasNotPersisted.peek() \u003d\u003d ramDiskReplicaLru) {\n       // Common case.\n       replicasNotPersisted.remove();\n     } else {\n-      // Should never occur in practice as lazy writer always persists\n-      // the replica at the head of the queue before moving to the next\n-      // one.\n-      replicasNotPersisted.remove(replicaState);\n+      // Caller error? Fallback to O(n) removal.\n+      replicasNotPersisted.remove(ramDiskReplicaLru);\n     }\n \n-    replicasPersisted.add(replicaState);\n+    ramDiskReplicaLru.lastUsedTime \u003d System.currentTimeMillis();\n+    replicasPersisted.put(ramDiskReplicaLru.lastUsedTime, ramDiskReplicaLru);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  synchronized void recordEndLazyPersist(\n      final String bpid, final long blockId, final File[] savedFiles) {\n    Map\u003cLong, RamDiskReplicaLru\u003e map \u003d replicaMaps.get(bpid);\n    RamDiskReplicaLru ramDiskReplicaLru \u003d map.get(blockId);\n\n    if (ramDiskReplicaLru \u003d\u003d null) {\n      throw new IllegalStateException(\"Unknown replica bpid\u003d\" +\n          bpid + \"; blockId\u003d\" + blockId);\n    }\n    ramDiskReplicaLru.recordSavedBlockFiles(savedFiles);\n\n    if (replicasNotPersisted.peek() \u003d\u003d ramDiskReplicaLru) {\n      // Common case.\n      replicasNotPersisted.remove();\n    } else {\n      // Caller error? Fallback to O(n) removal.\n      replicasNotPersisted.remove(ramDiskReplicaLru);\n    }\n\n    ramDiskReplicaLru.lastUsedTime \u003d System.currentTimeMillis();\n    replicasPersisted.put(ramDiskReplicaLru.lastUsedTime, ramDiskReplicaLru);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/RamDiskReplicaLruTracker.java",
          "extendedDetails": {}
        }
      ]
    },
    "9f22fb8c9a10952225e15c7b67b5f77fa44b155d": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-6978. Directory scanner should correctly reconcile blocks on RAM disk. (Arpit Agarwal)\n",
      "commitDate": "12/09/14 10:13 PM",
      "commitName": "9f22fb8c9a10952225e15c7b67b5f77fa44b155d",
      "commitAuthor": "arp",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-6978. Directory scanner should correctly reconcile blocks on RAM disk. (Arpit Agarwal)\n",
          "commitDate": "12/09/14 10:13 PM",
          "commitName": "9f22fb8c9a10952225e15c7b67b5f77fa44b155d",
          "commitAuthor": "arp",
          "commitDateOld": "08/09/14 10:35 AM",
          "commitNameOld": "ccdf0054a354fc110124b83de742c2ee6076449e",
          "commitAuthorOld": "arp",
          "daysBetweenCommits": 4.48,
          "commitsBetweenForRepo": 57,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,26 +1,25 @@\n   synchronized void recordEndLazyPersist(\n-      final String bpid, final long blockId,\n-      final File savedMetaFile, final File savedBlockFile) {\n+      final String bpid, final long blockId, final File[] savedFiles) {\n     Map\u003cLong, ReplicaState\u003e map \u003d replicaMaps.get(bpid);\n     ReplicaState replicaState \u003d map.get(blockId);\n \n     if (replicaState \u003d\u003d null) {\n       throw new IllegalStateException(\"Unknown replica bpid\u003d\" +\n           bpid + \"; blockId\u003d\" + blockId);\n     }\n     replicaState.state \u003d State.LAZY_PERSIST_COMPLETE;\n-    replicaState.savedMetaFile \u003d savedMetaFile;\n-    replicaState.savedBlockFile \u003d savedBlockFile;\n+    replicaState.savedMetaFile \u003d savedFiles[0];\n+    replicaState.savedBlockFile \u003d savedFiles[1];\n \n     if (replicasNotPersisted.peek() \u003d\u003d replicaState) {\n       // Common case.\n       replicasNotPersisted.remove();\n     } else {\n       // Should never occur in practice as lazy writer always persists\n       // the replica at the head of the queue before moving to the next\n       // one.\n       replicasNotPersisted.remove(replicaState);\n     }\n \n     replicasPersisted.add(replicaState);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  synchronized void recordEndLazyPersist(\n      final String bpid, final long blockId, final File[] savedFiles) {\n    Map\u003cLong, ReplicaState\u003e map \u003d replicaMaps.get(bpid);\n    ReplicaState replicaState \u003d map.get(blockId);\n\n    if (replicaState \u003d\u003d null) {\n      throw new IllegalStateException(\"Unknown replica bpid\u003d\" +\n          bpid + \"; blockId\u003d\" + blockId);\n    }\n    replicaState.state \u003d State.LAZY_PERSIST_COMPLETE;\n    replicaState.savedMetaFile \u003d savedFiles[0];\n    replicaState.savedBlockFile \u003d savedFiles[1];\n\n    if (replicasNotPersisted.peek() \u003d\u003d replicaState) {\n      // Common case.\n      replicasNotPersisted.remove();\n    } else {\n      // Should never occur in practice as lazy writer always persists\n      // the replica at the head of the queue before moving to the next\n      // one.\n      replicasNotPersisted.remove(replicaState);\n    }\n\n    replicasPersisted.add(replicaState);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/LazyWriteReplicaTracker.java",
          "extendedDetails": {
            "oldValue": "[bpid-String(modifiers-final), blockId-long(modifiers-final), savedMetaFile-File(modifiers-final), savedBlockFile-File(modifiers-final)]",
            "newValue": "[bpid-String(modifiers-final), blockId-long(modifiers-final), savedFiles-File[](modifiers-final)]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-6978. Directory scanner should correctly reconcile blocks on RAM disk. (Arpit Agarwal)\n",
          "commitDate": "12/09/14 10:13 PM",
          "commitName": "9f22fb8c9a10952225e15c7b67b5f77fa44b155d",
          "commitAuthor": "arp",
          "commitDateOld": "08/09/14 10:35 AM",
          "commitNameOld": "ccdf0054a354fc110124b83de742c2ee6076449e",
          "commitAuthorOld": "arp",
          "daysBetweenCommits": 4.48,
          "commitsBetweenForRepo": 57,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,26 +1,25 @@\n   synchronized void recordEndLazyPersist(\n-      final String bpid, final long blockId,\n-      final File savedMetaFile, final File savedBlockFile) {\n+      final String bpid, final long blockId, final File[] savedFiles) {\n     Map\u003cLong, ReplicaState\u003e map \u003d replicaMaps.get(bpid);\n     ReplicaState replicaState \u003d map.get(blockId);\n \n     if (replicaState \u003d\u003d null) {\n       throw new IllegalStateException(\"Unknown replica bpid\u003d\" +\n           bpid + \"; blockId\u003d\" + blockId);\n     }\n     replicaState.state \u003d State.LAZY_PERSIST_COMPLETE;\n-    replicaState.savedMetaFile \u003d savedMetaFile;\n-    replicaState.savedBlockFile \u003d savedBlockFile;\n+    replicaState.savedMetaFile \u003d savedFiles[0];\n+    replicaState.savedBlockFile \u003d savedFiles[1];\n \n     if (replicasNotPersisted.peek() \u003d\u003d replicaState) {\n       // Common case.\n       replicasNotPersisted.remove();\n     } else {\n       // Should never occur in practice as lazy writer always persists\n       // the replica at the head of the queue before moving to the next\n       // one.\n       replicasNotPersisted.remove(replicaState);\n     }\n \n     replicasPersisted.add(replicaState);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  synchronized void recordEndLazyPersist(\n      final String bpid, final long blockId, final File[] savedFiles) {\n    Map\u003cLong, ReplicaState\u003e map \u003d replicaMaps.get(bpid);\n    ReplicaState replicaState \u003d map.get(blockId);\n\n    if (replicaState \u003d\u003d null) {\n      throw new IllegalStateException(\"Unknown replica bpid\u003d\" +\n          bpid + \"; blockId\u003d\" + blockId);\n    }\n    replicaState.state \u003d State.LAZY_PERSIST_COMPLETE;\n    replicaState.savedMetaFile \u003d savedFiles[0];\n    replicaState.savedBlockFile \u003d savedFiles[1];\n\n    if (replicasNotPersisted.peek() \u003d\u003d replicaState) {\n      // Common case.\n      replicasNotPersisted.remove();\n    } else {\n      // Should never occur in practice as lazy writer always persists\n      // the replica at the head of the queue before moving to the next\n      // one.\n      replicasNotPersisted.remove(replicaState);\n    }\n\n    replicasPersisted.add(replicaState);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/LazyWriteReplicaTracker.java",
          "extendedDetails": {}
        }
      ]
    },
    "ccdf0054a354fc110124b83de742c2ee6076449e": {
      "type": "Ymultichange(Yparameterchange,Ybodychange,Yparametermetachange)",
      "commitMessage": "HDFS-6977. Delete all copies when a block is deleted from the block space. (Arpit Agarwal)\n",
      "commitDate": "08/09/14 10:35 AM",
      "commitName": "ccdf0054a354fc110124b83de742c2ee6076449e",
      "commitAuthor": "arp",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-6977. Delete all copies when a block is deleted from the block space. (Arpit Agarwal)\n",
          "commitDate": "08/09/14 10:35 AM",
          "commitName": "ccdf0054a354fc110124b83de742c2ee6076449e",
          "commitAuthor": "arp",
          "commitDateOld": "03/09/14 1:53 PM",
          "commitNameOld": "cb9b485075ce773f2d6189aa2f54bbc69aad4dab",
          "commitAuthorOld": "arp",
          "daysBetweenCommits": 4.86,
          "commitsBetweenForRepo": 35,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,26 @@\n   synchronized void recordEndLazyPersist(\n-      final String bpid, final long blockId, File savedBlockFile) {\n+      final String bpid, final long blockId,\n+      final File savedMetaFile, final File savedBlockFile) {\n     Map\u003cLong, ReplicaState\u003e map \u003d replicaMaps.get(bpid);\n     ReplicaState replicaState \u003d map.get(blockId);\n \n     if (replicaState \u003d\u003d null) {\n       throw new IllegalStateException(\"Unknown replica bpid\u003d\" +\n           bpid + \"; blockId\u003d\" + blockId);\n     }\n     replicaState.state \u003d State.LAZY_PERSIST_COMPLETE;\n+    replicaState.savedMetaFile \u003d savedMetaFile;\n     replicaState.savedBlockFile \u003d savedBlockFile;\n \n     if (replicasNotPersisted.peek() \u003d\u003d replicaState) {\n       // Common case.\n       replicasNotPersisted.remove();\n     } else {\n       // Should never occur in practice as lazy writer always persists\n       // the replica at the head of the queue before moving to the next\n       // one.\n       replicasNotPersisted.remove(replicaState);\n     }\n \n     replicasPersisted.add(replicaState);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  synchronized void recordEndLazyPersist(\n      final String bpid, final long blockId,\n      final File savedMetaFile, final File savedBlockFile) {\n    Map\u003cLong, ReplicaState\u003e map \u003d replicaMaps.get(bpid);\n    ReplicaState replicaState \u003d map.get(blockId);\n\n    if (replicaState \u003d\u003d null) {\n      throw new IllegalStateException(\"Unknown replica bpid\u003d\" +\n          bpid + \"; blockId\u003d\" + blockId);\n    }\n    replicaState.state \u003d State.LAZY_PERSIST_COMPLETE;\n    replicaState.savedMetaFile \u003d savedMetaFile;\n    replicaState.savedBlockFile \u003d savedBlockFile;\n\n    if (replicasNotPersisted.peek() \u003d\u003d replicaState) {\n      // Common case.\n      replicasNotPersisted.remove();\n    } else {\n      // Should never occur in practice as lazy writer always persists\n      // the replica at the head of the queue before moving to the next\n      // one.\n      replicasNotPersisted.remove(replicaState);\n    }\n\n    replicasPersisted.add(replicaState);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/LazyWriteReplicaTracker.java",
          "extendedDetails": {
            "oldValue": "[bpid-String(modifiers-final), blockId-long(modifiers-final), savedBlockFile-File]",
            "newValue": "[bpid-String(modifiers-final), blockId-long(modifiers-final), savedMetaFile-File(modifiers-final), savedBlockFile-File(modifiers-final)]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-6977. Delete all copies when a block is deleted from the block space. (Arpit Agarwal)\n",
          "commitDate": "08/09/14 10:35 AM",
          "commitName": "ccdf0054a354fc110124b83de742c2ee6076449e",
          "commitAuthor": "arp",
          "commitDateOld": "03/09/14 1:53 PM",
          "commitNameOld": "cb9b485075ce773f2d6189aa2f54bbc69aad4dab",
          "commitAuthorOld": "arp",
          "daysBetweenCommits": 4.86,
          "commitsBetweenForRepo": 35,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,26 @@\n   synchronized void recordEndLazyPersist(\n-      final String bpid, final long blockId, File savedBlockFile) {\n+      final String bpid, final long blockId,\n+      final File savedMetaFile, final File savedBlockFile) {\n     Map\u003cLong, ReplicaState\u003e map \u003d replicaMaps.get(bpid);\n     ReplicaState replicaState \u003d map.get(blockId);\n \n     if (replicaState \u003d\u003d null) {\n       throw new IllegalStateException(\"Unknown replica bpid\u003d\" +\n           bpid + \"; blockId\u003d\" + blockId);\n     }\n     replicaState.state \u003d State.LAZY_PERSIST_COMPLETE;\n+    replicaState.savedMetaFile \u003d savedMetaFile;\n     replicaState.savedBlockFile \u003d savedBlockFile;\n \n     if (replicasNotPersisted.peek() \u003d\u003d replicaState) {\n       // Common case.\n       replicasNotPersisted.remove();\n     } else {\n       // Should never occur in practice as lazy writer always persists\n       // the replica at the head of the queue before moving to the next\n       // one.\n       replicasNotPersisted.remove(replicaState);\n     }\n \n     replicasPersisted.add(replicaState);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  synchronized void recordEndLazyPersist(\n      final String bpid, final long blockId,\n      final File savedMetaFile, final File savedBlockFile) {\n    Map\u003cLong, ReplicaState\u003e map \u003d replicaMaps.get(bpid);\n    ReplicaState replicaState \u003d map.get(blockId);\n\n    if (replicaState \u003d\u003d null) {\n      throw new IllegalStateException(\"Unknown replica bpid\u003d\" +\n          bpid + \"; blockId\u003d\" + blockId);\n    }\n    replicaState.state \u003d State.LAZY_PERSIST_COMPLETE;\n    replicaState.savedMetaFile \u003d savedMetaFile;\n    replicaState.savedBlockFile \u003d savedBlockFile;\n\n    if (replicasNotPersisted.peek() \u003d\u003d replicaState) {\n      // Common case.\n      replicasNotPersisted.remove();\n    } else {\n      // Should never occur in practice as lazy writer always persists\n      // the replica at the head of the queue before moving to the next\n      // one.\n      replicasNotPersisted.remove(replicaState);\n    }\n\n    replicasPersisted.add(replicaState);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/LazyWriteReplicaTracker.java",
          "extendedDetails": {}
        },
        {
          "type": "Yparametermetachange",
          "commitMessage": "HDFS-6977. Delete all copies when a block is deleted from the block space. (Arpit Agarwal)\n",
          "commitDate": "08/09/14 10:35 AM",
          "commitName": "ccdf0054a354fc110124b83de742c2ee6076449e",
          "commitAuthor": "arp",
          "commitDateOld": "03/09/14 1:53 PM",
          "commitNameOld": "cb9b485075ce773f2d6189aa2f54bbc69aad4dab",
          "commitAuthorOld": "arp",
          "daysBetweenCommits": 4.86,
          "commitsBetweenForRepo": 35,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,26 @@\n   synchronized void recordEndLazyPersist(\n-      final String bpid, final long blockId, File savedBlockFile) {\n+      final String bpid, final long blockId,\n+      final File savedMetaFile, final File savedBlockFile) {\n     Map\u003cLong, ReplicaState\u003e map \u003d replicaMaps.get(bpid);\n     ReplicaState replicaState \u003d map.get(blockId);\n \n     if (replicaState \u003d\u003d null) {\n       throw new IllegalStateException(\"Unknown replica bpid\u003d\" +\n           bpid + \"; blockId\u003d\" + blockId);\n     }\n     replicaState.state \u003d State.LAZY_PERSIST_COMPLETE;\n+    replicaState.savedMetaFile \u003d savedMetaFile;\n     replicaState.savedBlockFile \u003d savedBlockFile;\n \n     if (replicasNotPersisted.peek() \u003d\u003d replicaState) {\n       // Common case.\n       replicasNotPersisted.remove();\n     } else {\n       // Should never occur in practice as lazy writer always persists\n       // the replica at the head of the queue before moving to the next\n       // one.\n       replicasNotPersisted.remove(replicaState);\n     }\n \n     replicasPersisted.add(replicaState);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  synchronized void recordEndLazyPersist(\n      final String bpid, final long blockId,\n      final File savedMetaFile, final File savedBlockFile) {\n    Map\u003cLong, ReplicaState\u003e map \u003d replicaMaps.get(bpid);\n    ReplicaState replicaState \u003d map.get(blockId);\n\n    if (replicaState \u003d\u003d null) {\n      throw new IllegalStateException(\"Unknown replica bpid\u003d\" +\n          bpid + \"; blockId\u003d\" + blockId);\n    }\n    replicaState.state \u003d State.LAZY_PERSIST_COMPLETE;\n    replicaState.savedMetaFile \u003d savedMetaFile;\n    replicaState.savedBlockFile \u003d savedBlockFile;\n\n    if (replicasNotPersisted.peek() \u003d\u003d replicaState) {\n      // Common case.\n      replicasNotPersisted.remove();\n    } else {\n      // Should never occur in practice as lazy writer always persists\n      // the replica at the head of the queue before moving to the next\n      // one.\n      replicasNotPersisted.remove(replicaState);\n    }\n\n    replicasPersisted.add(replicaState);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/LazyWriteReplicaTracker.java",
          "extendedDetails": {
            "oldValue": "[bpid-String(modifiers-final), blockId-long(modifiers-final), savedBlockFile-File]",
            "newValue": "[bpid-String(modifiers-final), blockId-long(modifiers-final), savedMetaFile-File(modifiers-final), savedBlockFile-File(modifiers-final)]"
          }
        }
      ]
    },
    "cb9b485075ce773f2d6189aa2f54bbc69aad4dab": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6930. Improve replica eviction from RAM disk. (Arpit Agarwal)\n",
      "commitDate": "03/09/14 1:53 PM",
      "commitName": "cb9b485075ce773f2d6189aa2f54bbc69aad4dab",
      "commitAuthor": "arp",
      "commitDateOld": "28/08/14 11:05 PM",
      "commitNameOld": "4cf9afacbe3d0814fb616d238aa9b16b1ae68386",
      "commitAuthorOld": "arp",
      "daysBetweenCommits": 5.62,
      "commitsBetweenForRepo": 36,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,24 @@\n   synchronized void recordEndLazyPersist(\n       final String bpid, final long blockId, File savedBlockFile) {\n     Map\u003cLong, ReplicaState\u003e map \u003d replicaMaps.get(bpid);\n     ReplicaState replicaState \u003d map.get(blockId);\n \n     if (replicaState \u003d\u003d null) {\n       throw new IllegalStateException(\"Unknown replica bpid\u003d\" +\n           bpid + \"; blockId\u003d\" + blockId);\n     }\n     replicaState.state \u003d State.LAZY_PERSIST_COMPLETE;\n     replicaState.savedBlockFile \u003d savedBlockFile;\n \n     if (replicasNotPersisted.peek() \u003d\u003d replicaState) {\n       // Common case.\n       replicasNotPersisted.remove();\n     } else {\n       // Should never occur in practice as lazy writer always persists\n       // the replica at the head of the queue before moving to the next\n       // one.\n       replicasNotPersisted.remove(replicaState);\n     }\n-    replicasPersisted.put(replicaState, System.currentTimeMillis() / 1000);\n+\n+    replicasPersisted.add(replicaState);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  synchronized void recordEndLazyPersist(\n      final String bpid, final long blockId, File savedBlockFile) {\n    Map\u003cLong, ReplicaState\u003e map \u003d replicaMaps.get(bpid);\n    ReplicaState replicaState \u003d map.get(blockId);\n\n    if (replicaState \u003d\u003d null) {\n      throw new IllegalStateException(\"Unknown replica bpid\u003d\" +\n          bpid + \"; blockId\u003d\" + blockId);\n    }\n    replicaState.state \u003d State.LAZY_PERSIST_COMPLETE;\n    replicaState.savedBlockFile \u003d savedBlockFile;\n\n    if (replicasNotPersisted.peek() \u003d\u003d replicaState) {\n      // Common case.\n      replicasNotPersisted.remove();\n    } else {\n      // Should never occur in practice as lazy writer always persists\n      // the replica at the head of the queue before moving to the next\n      // one.\n      replicasNotPersisted.remove(replicaState);\n    }\n\n    replicasPersisted.add(replicaState);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/LazyWriteReplicaTracker.java",
      "extendedDetails": {}
    },
    "4cf9afacbe3d0814fb616d238aa9b16b1ae68386": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6960. Bugfix in LazyWriter, fix test case and some refactoring. (Arpit Agarwal)\n",
      "commitDate": "28/08/14 11:05 PM",
      "commitName": "4cf9afacbe3d0814fb616d238aa9b16b1ae68386",
      "commitAuthor": "arp",
      "commitDateOld": "27/08/14 9:47 PM",
      "commitNameOld": "eb448e14399e17f11b9e523e4050de245b9b0408",
      "commitAuthorOld": "arp",
      "daysBetweenCommits": 1.05,
      "commitsBetweenForRepo": 16,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,23 @@\n   synchronized void recordEndLazyPersist(\n       final String bpid, final long blockId, File savedBlockFile) {\n     Map\u003cLong, ReplicaState\u003e map \u003d replicaMaps.get(bpid);\n     ReplicaState replicaState \u003d map.get(blockId);\n \n     if (replicaState \u003d\u003d null) {\n       throw new IllegalStateException(\"Unknown replica bpid\u003d\" +\n           bpid + \"; blockId\u003d\" + blockId);\n     }\n     replicaState.state \u003d State.LAZY_PERSIST_COMPLETE;\n     replicaState.savedBlockFile \u003d savedBlockFile;\n-    persistTimeMap.put(replicaState, System.currentTimeMillis() / 1000);\n+\n+    if (replicasNotPersisted.peek() \u003d\u003d replicaState) {\n+      // Common case.\n+      replicasNotPersisted.remove();\n+    } else {\n+      // Should never occur in practice as lazy writer always persists\n+      // the replica at the head of the queue before moving to the next\n+      // one.\n+      replicasNotPersisted.remove(replicaState);\n+    }\n+    replicasPersisted.put(replicaState, System.currentTimeMillis() / 1000);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  synchronized void recordEndLazyPersist(\n      final String bpid, final long blockId, File savedBlockFile) {\n    Map\u003cLong, ReplicaState\u003e map \u003d replicaMaps.get(bpid);\n    ReplicaState replicaState \u003d map.get(blockId);\n\n    if (replicaState \u003d\u003d null) {\n      throw new IllegalStateException(\"Unknown replica bpid\u003d\" +\n          bpid + \"; blockId\u003d\" + blockId);\n    }\n    replicaState.state \u003d State.LAZY_PERSIST_COMPLETE;\n    replicaState.savedBlockFile \u003d savedBlockFile;\n\n    if (replicasNotPersisted.peek() \u003d\u003d replicaState) {\n      // Common case.\n      replicasNotPersisted.remove();\n    } else {\n      // Should never occur in practice as lazy writer always persists\n      // the replica at the head of the queue before moving to the next\n      // one.\n      replicasNotPersisted.remove(replicaState);\n    }\n    replicasPersisted.put(replicaState, System.currentTimeMillis() / 1000);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/LazyWriteReplicaTracker.java",
      "extendedDetails": {}
    },
    "eb448e14399e17f11b9e523e4050de245b9b0408": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-6926. DN support for saving replicas to persistent storage and evicting in-memory replicas. (Arpit Agarwal)\n",
      "commitDate": "27/08/14 9:47 PM",
      "commitName": "eb448e14399e17f11b9e523e4050de245b9b0408",
      "commitAuthor": "arp",
      "diff": "@@ -0,0 +1,13 @@\n+  synchronized void recordEndLazyPersist(\n+      final String bpid, final long blockId, File savedBlockFile) {\n+    Map\u003cLong, ReplicaState\u003e map \u003d replicaMaps.get(bpid);\n+    ReplicaState replicaState \u003d map.get(blockId);\n+\n+    if (replicaState \u003d\u003d null) {\n+      throw new IllegalStateException(\"Unknown replica bpid\u003d\" +\n+          bpid + \"; blockId\u003d\" + blockId);\n+    }\n+    replicaState.state \u003d State.LAZY_PERSIST_COMPLETE;\n+    replicaState.savedBlockFile \u003d savedBlockFile;\n+    persistTimeMap.put(replicaState, System.currentTimeMillis() / 1000);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  synchronized void recordEndLazyPersist(\n      final String bpid, final long blockId, File savedBlockFile) {\n    Map\u003cLong, ReplicaState\u003e map \u003d replicaMaps.get(bpid);\n    ReplicaState replicaState \u003d map.get(blockId);\n\n    if (replicaState \u003d\u003d null) {\n      throw new IllegalStateException(\"Unknown replica bpid\u003d\" +\n          bpid + \"; blockId\u003d\" + blockId);\n    }\n    replicaState.state \u003d State.LAZY_PERSIST_COMPLETE;\n    replicaState.savedBlockFile \u003d savedBlockFile;\n    persistTimeMap.put(replicaState, System.currentTimeMillis() / 1000);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/LazyWriteReplicaTracker.java"
    }
  }
}