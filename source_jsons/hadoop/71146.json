{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "Client.java",
  "functionName": "launchAndMonitorWorkloadDriver",
  "functionId": "launchAndMonitorWorkloadDriver___nameNodeProperties-Properties",
  "sourceFilePath": "hadoop-tools/hadoop-dynamometer/hadoop-dynamometer-infra/src/main/java/org/apache/hadoop/tools/dynamometer/Client.java",
  "functionStartLine": 1035,
  "functionEndLine": 1069,
  "numCommitsSeen": 7,
  "timeTaken": 1525,
  "changeHistory": [
    "9520b2ad790bd8527033a03e7ee50da71a85df1d",
    "477505ccfc480f2605a7b65de95ea6f6ff5ce090",
    "ab0b180ddb5d0775a2452d5eeb7badd252aadb91"
  ],
  "changeHistoryShort": {
    "9520b2ad790bd8527033a03e7ee50da71a85df1d": "Ybodychange",
    "477505ccfc480f2605a7b65de95ea6f6ff5ce090": "Ybodychange",
    "ab0b180ddb5d0775a2452d5eeb7badd252aadb91": "Yintroduced"
  },
  "changeHistoryDetails": {
    "9520b2ad790bd8527033a03e7ee50da71a85df1d": {
      "type": "Ybodychange",
      "commitMessage": "YARN-10083. Provide utility to ask whether an application is in final status. Contributed by Adam Antal\n",
      "commitDate": "22/01/20 7:25 AM",
      "commitName": "9520b2ad790bd8527033a03e7ee50da71a85df1d",
      "commitAuthor": "Szilard Nemeth",
      "commitDateOld": "01/11/19 9:32 AM",
      "commitNameOld": "477505ccfc480f2605a7b65de95ea6f6ff5ce090",
      "commitAuthorOld": "Takanobu Asanuma",
      "daysBetweenCommits": 81.95,
      "commitsBetweenForRepo": 300,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,34 +1,35 @@\n   private void launchAndMonitorWorkloadDriver(Properties nameNodeProperties) {\n     URI nameNodeURI \u003d DynoInfraUtils.getNameNodeHdfsUri(nameNodeProperties);\n     LOG.info(\"Launching workload job using input path: \" + workloadInputPath);\n     try {\n       long workloadStartTime \u003d System.currentTimeMillis()\n           + workloadStartDelayMs;\n       Configuration workloadConf \u003d new Configuration(getConf());\n       workloadConf.set(AuditReplayMapper.INPUT_PATH_KEY, workloadInputPath);\n       workloadConf.set(AuditReplayMapper.OUTPUT_PATH_KEY, workloadOutputPath);\n       workloadConf.setInt(AuditReplayMapper.NUM_THREADS_KEY,\n           workloadThreadsPerMapper);\n       workloadConf.setDouble(AuditReplayMapper.RATE_FACTOR_KEY,\n           workloadRateFactor);\n       for (Map.Entry\u003cString, String\u003e configPair : workloadExtraConfigs\n           .entrySet()) {\n         workloadConf.set(configPair.getKey(), configPair.getValue());\n       }\n       workloadJob \u003d WorkloadDriver.getJobForSubmission(workloadConf,\n           nameNodeURI.toString(), workloadStartTime, AuditReplayMapper.class);\n       workloadJob.submit();\n-      while (!isCompleted(infraAppState) \u0026\u0026 !isCompleted(workloadAppState)) {\n+      while (!Apps.isApplicationFinalState(infraAppState) \u0026\u0026\n+          !isCompleted(workloadAppState)) {\n         workloadJob.monitorAndPrintJob();\n         Thread.sleep(5000);\n         workloadAppState \u003d workloadJob.getJobState();\n       }\n       if (isCompleted(workloadAppState)) {\n         LOG.info(\"Workload job completed successfully!\");\n       } else {\n         LOG.warn(\"Workload job failed.\");\n       }\n     } catch (Exception e) {\n       LOG.error(\"Exception encountered while running workload job\", e);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void launchAndMonitorWorkloadDriver(Properties nameNodeProperties) {\n    URI nameNodeURI \u003d DynoInfraUtils.getNameNodeHdfsUri(nameNodeProperties);\n    LOG.info(\"Launching workload job using input path: \" + workloadInputPath);\n    try {\n      long workloadStartTime \u003d System.currentTimeMillis()\n          + workloadStartDelayMs;\n      Configuration workloadConf \u003d new Configuration(getConf());\n      workloadConf.set(AuditReplayMapper.INPUT_PATH_KEY, workloadInputPath);\n      workloadConf.set(AuditReplayMapper.OUTPUT_PATH_KEY, workloadOutputPath);\n      workloadConf.setInt(AuditReplayMapper.NUM_THREADS_KEY,\n          workloadThreadsPerMapper);\n      workloadConf.setDouble(AuditReplayMapper.RATE_FACTOR_KEY,\n          workloadRateFactor);\n      for (Map.Entry\u003cString, String\u003e configPair : workloadExtraConfigs\n          .entrySet()) {\n        workloadConf.set(configPair.getKey(), configPair.getValue());\n      }\n      workloadJob \u003d WorkloadDriver.getJobForSubmission(workloadConf,\n          nameNodeURI.toString(), workloadStartTime, AuditReplayMapper.class);\n      workloadJob.submit();\n      while (!Apps.isApplicationFinalState(infraAppState) \u0026\u0026\n          !isCompleted(workloadAppState)) {\n        workloadJob.monitorAndPrintJob();\n        Thread.sleep(5000);\n        workloadAppState \u003d workloadJob.getJobState();\n      }\n      if (isCompleted(workloadAppState)) {\n        LOG.info(\"Workload job completed successfully!\");\n      } else {\n        LOG.warn(\"Workload job failed.\");\n      }\n    } catch (Exception e) {\n      LOG.error(\"Exception encountered while running workload job\", e);\n    }\n  }",
      "path": "hadoop-tools/hadoop-dynamometer/hadoop-dynamometer-infra/src/main/java/org/apache/hadoop/tools/dynamometer/Client.java",
      "extendedDetails": {}
    },
    "477505ccfc480f2605a7b65de95ea6f6ff5ce090": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14824. [Dynamometer] Dynamometer in org.apache.hadoop.tools does not output the benchmark results. (#1685)\n\n\r\n",
      "commitDate": "01/11/19 9:32 AM",
      "commitName": "477505ccfc480f2605a7b65de95ea6f6ff5ce090",
      "commitAuthor": "Takanobu Asanuma",
      "commitDateOld": "06/09/19 10:24 AM",
      "commitNameOld": "9637097ef9b213fcbeffa2538ccb7e0aaabde9c4",
      "commitAuthorOld": "Erik Krogen",
      "daysBetweenCommits": 55.96,
      "commitsBetweenForRepo": 364,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,33 +1,34 @@\n   private void launchAndMonitorWorkloadDriver(Properties nameNodeProperties) {\n     URI nameNodeURI \u003d DynoInfraUtils.getNameNodeHdfsUri(nameNodeProperties);\n     LOG.info(\"Launching workload job using input path: \" + workloadInputPath);\n     try {\n       long workloadStartTime \u003d System.currentTimeMillis()\n           + workloadStartDelayMs;\n       Configuration workloadConf \u003d new Configuration(getConf());\n       workloadConf.set(AuditReplayMapper.INPUT_PATH_KEY, workloadInputPath);\n+      workloadConf.set(AuditReplayMapper.OUTPUT_PATH_KEY, workloadOutputPath);\n       workloadConf.setInt(AuditReplayMapper.NUM_THREADS_KEY,\n           workloadThreadsPerMapper);\n       workloadConf.setDouble(AuditReplayMapper.RATE_FACTOR_KEY,\n           workloadRateFactor);\n       for (Map.Entry\u003cString, String\u003e configPair : workloadExtraConfigs\n           .entrySet()) {\n         workloadConf.set(configPair.getKey(), configPair.getValue());\n       }\n       workloadJob \u003d WorkloadDriver.getJobForSubmission(workloadConf,\n           nameNodeURI.toString(), workloadStartTime, AuditReplayMapper.class);\n       workloadJob.submit();\n       while (!isCompleted(infraAppState) \u0026\u0026 !isCompleted(workloadAppState)) {\n         workloadJob.monitorAndPrintJob();\n         Thread.sleep(5000);\n         workloadAppState \u003d workloadJob.getJobState();\n       }\n       if (isCompleted(workloadAppState)) {\n         LOG.info(\"Workload job completed successfully!\");\n       } else {\n         LOG.warn(\"Workload job failed.\");\n       }\n     } catch (Exception e) {\n       LOG.error(\"Exception encountered while running workload job\", e);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void launchAndMonitorWorkloadDriver(Properties nameNodeProperties) {\n    URI nameNodeURI \u003d DynoInfraUtils.getNameNodeHdfsUri(nameNodeProperties);\n    LOG.info(\"Launching workload job using input path: \" + workloadInputPath);\n    try {\n      long workloadStartTime \u003d System.currentTimeMillis()\n          + workloadStartDelayMs;\n      Configuration workloadConf \u003d new Configuration(getConf());\n      workloadConf.set(AuditReplayMapper.INPUT_PATH_KEY, workloadInputPath);\n      workloadConf.set(AuditReplayMapper.OUTPUT_PATH_KEY, workloadOutputPath);\n      workloadConf.setInt(AuditReplayMapper.NUM_THREADS_KEY,\n          workloadThreadsPerMapper);\n      workloadConf.setDouble(AuditReplayMapper.RATE_FACTOR_KEY,\n          workloadRateFactor);\n      for (Map.Entry\u003cString, String\u003e configPair : workloadExtraConfigs\n          .entrySet()) {\n        workloadConf.set(configPair.getKey(), configPair.getValue());\n      }\n      workloadJob \u003d WorkloadDriver.getJobForSubmission(workloadConf,\n          nameNodeURI.toString(), workloadStartTime, AuditReplayMapper.class);\n      workloadJob.submit();\n      while (!isCompleted(infraAppState) \u0026\u0026 !isCompleted(workloadAppState)) {\n        workloadJob.monitorAndPrintJob();\n        Thread.sleep(5000);\n        workloadAppState \u003d workloadJob.getJobState();\n      }\n      if (isCompleted(workloadAppState)) {\n        LOG.info(\"Workload job completed successfully!\");\n      } else {\n        LOG.warn(\"Workload job failed.\");\n      }\n    } catch (Exception e) {\n      LOG.error(\"Exception encountered while running workload job\", e);\n    }\n  }",
      "path": "hadoop-tools/hadoop-dynamometer/hadoop-dynamometer-infra/src/main/java/org/apache/hadoop/tools/dynamometer/Client.java",
      "extendedDetails": {}
    },
    "ab0b180ddb5d0775a2452d5eeb7badd252aadb91": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-12345 Add Dynamometer to hadoop-tools, a tool for scale testing the HDFS NameNode with real metadata and workloads. Contributed by Erik Krogen.\n",
      "commitDate": "25/06/19 8:07 AM",
      "commitName": "ab0b180ddb5d0775a2452d5eeb7badd252aadb91",
      "commitAuthor": "Erik Krogen",
      "diff": "@@ -0,0 +1,33 @@\n+  private void launchAndMonitorWorkloadDriver(Properties nameNodeProperties) {\n+    URI nameNodeURI \u003d DynoInfraUtils.getNameNodeHdfsUri(nameNodeProperties);\n+    LOG.info(\"Launching workload job using input path: \" + workloadInputPath);\n+    try {\n+      long workloadStartTime \u003d System.currentTimeMillis()\n+          + workloadStartDelayMs;\n+      Configuration workloadConf \u003d new Configuration(getConf());\n+      workloadConf.set(AuditReplayMapper.INPUT_PATH_KEY, workloadInputPath);\n+      workloadConf.setInt(AuditReplayMapper.NUM_THREADS_KEY,\n+          workloadThreadsPerMapper);\n+      workloadConf.setDouble(AuditReplayMapper.RATE_FACTOR_KEY,\n+          workloadRateFactor);\n+      for (Map.Entry\u003cString, String\u003e configPair : workloadExtraConfigs\n+          .entrySet()) {\n+        workloadConf.set(configPair.getKey(), configPair.getValue());\n+      }\n+      workloadJob \u003d WorkloadDriver.getJobForSubmission(workloadConf,\n+          nameNodeURI.toString(), workloadStartTime, AuditReplayMapper.class);\n+      workloadJob.submit();\n+      while (!isCompleted(infraAppState) \u0026\u0026 !isCompleted(workloadAppState)) {\n+        workloadJob.monitorAndPrintJob();\n+        Thread.sleep(5000);\n+        workloadAppState \u003d workloadJob.getJobState();\n+      }\n+      if (isCompleted(workloadAppState)) {\n+        LOG.info(\"Workload job completed successfully!\");\n+      } else {\n+        LOG.warn(\"Workload job failed.\");\n+      }\n+    } catch (Exception e) {\n+      LOG.error(\"Exception encountered while running workload job\", e);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void launchAndMonitorWorkloadDriver(Properties nameNodeProperties) {\n    URI nameNodeURI \u003d DynoInfraUtils.getNameNodeHdfsUri(nameNodeProperties);\n    LOG.info(\"Launching workload job using input path: \" + workloadInputPath);\n    try {\n      long workloadStartTime \u003d System.currentTimeMillis()\n          + workloadStartDelayMs;\n      Configuration workloadConf \u003d new Configuration(getConf());\n      workloadConf.set(AuditReplayMapper.INPUT_PATH_KEY, workloadInputPath);\n      workloadConf.setInt(AuditReplayMapper.NUM_THREADS_KEY,\n          workloadThreadsPerMapper);\n      workloadConf.setDouble(AuditReplayMapper.RATE_FACTOR_KEY,\n          workloadRateFactor);\n      for (Map.Entry\u003cString, String\u003e configPair : workloadExtraConfigs\n          .entrySet()) {\n        workloadConf.set(configPair.getKey(), configPair.getValue());\n      }\n      workloadJob \u003d WorkloadDriver.getJobForSubmission(workloadConf,\n          nameNodeURI.toString(), workloadStartTime, AuditReplayMapper.class);\n      workloadJob.submit();\n      while (!isCompleted(infraAppState) \u0026\u0026 !isCompleted(workloadAppState)) {\n        workloadJob.monitorAndPrintJob();\n        Thread.sleep(5000);\n        workloadAppState \u003d workloadJob.getJobState();\n      }\n      if (isCompleted(workloadAppState)) {\n        LOG.info(\"Workload job completed successfully!\");\n      } else {\n        LOG.warn(\"Workload job failed.\");\n      }\n    } catch (Exception e) {\n      LOG.error(\"Exception encountered while running workload job\", e);\n    }\n  }",
      "path": "hadoop-tools/hadoop-dynamometer/hadoop-dynamometer-infra/src/main/java/org/apache/hadoop/tools/dynamometer/Client.java"
    }
  }
}