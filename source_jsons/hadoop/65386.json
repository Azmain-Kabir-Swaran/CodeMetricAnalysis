{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DelayedUpdateRenameTracker.java",
  "functionName": "deleteParentPaths",
  "functionId": "deleteParentPaths",
  "sourceFilePath": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/s3guard/DelayedUpdateRenameTracker.java",
  "functionStartLine": 166,
  "functionEndLine": 187,
  "numCommitsSeen": 3,
  "timeTaken": 2188,
  "changeHistory": [
    "511df1e837b19ccb9271520589452d82d50ac69d",
    "c58e11bf521d746842ce16724211a2a0339d7b61",
    "e02eb24e0a9139418120027b694492e0738df20a"
  ],
  "changeHistoryShort": {
    "511df1e837b19ccb9271520589452d82d50ac69d": "Ybodychange",
    "c58e11bf521d746842ce16724211a2a0339d7b61": "Ybodychange",
    "e02eb24e0a9139418120027b694492e0738df20a": "Yintroduced"
  },
  "changeHistoryDetails": {
    "511df1e837b19ccb9271520589452d82d50ac69d": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-16430. S3AFilesystem.delete to incrementally update s3guard with deletions\n\nContributed by Steve Loughran.\n\nThis overlaps the scanning for directory entries with batched calls to S3 DELETE and updates of the S3Guard tables.\nIt also uses S3Guard to list the files to delete, so find newly created files even when S3 listings are not use consistent.\n\nFor path which the client considers S3Guard to be authoritative, we also do a recursive LIST of the store and delete files; this is to find unindexed files and do guarantee that the delete(path, true) call really does delete everything underneath.\n\nChange-Id: Ice2f6e940c506e0b3a78fa534a99721b1698708e\n",
      "commitDate": "05/09/19 6:25 AM",
      "commitName": "511df1e837b19ccb9271520589452d82d50ac69d",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "17/07/19 7:24 AM",
      "commitNameOld": "c58e11bf521d746842ce16724211a2a0339d7b61",
      "commitAuthorOld": "Gabor Bota",
      "daysBetweenCommits": 49.96,
      "commitsBetweenForRepo": 456,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,22 @@\n   private void deleteParentPaths() throws IOException {\n     Set\u003cPath\u003e parentPaths \u003d new HashSet\u003c\u003e();\n     for (Path deletedPath : deletedPaths) {\n       Path parent \u003d deletedPath.getParent();\n       if (!parent.equals(getSourceRoot())) {\n         parentPaths.add(parent);\n       }\n     }\n     // now there\u0027s a set of parent paths. We now want to\n     // get them ordered by depth, so that deeper entries come first\n     // that way: when we check for a parent path existing we can\n     // see if it really is empty.\n     List\u003cPath\u003e parents \u003d new ArrayList\u003c\u003e(parentPaths);\n     parents.sort(PathOrderComparators.TOPMOST_PATH_LAST);\n     for (Path parent : parents) {\n       PathMetadata md \u003d metadataStore.get(parent, true);\n       if (md !\u003d null \u0026\u0026 md.isEmptyDirectory() \u003d\u003d Tristate.TRUE) {\n         // if were confident that this is empty: delete it.\n-        metadataStore.delete(parent);\n+        metadataStore.delete(parent, getOperationState());\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void deleteParentPaths() throws IOException {\n    Set\u003cPath\u003e parentPaths \u003d new HashSet\u003c\u003e();\n    for (Path deletedPath : deletedPaths) {\n      Path parent \u003d deletedPath.getParent();\n      if (!parent.equals(getSourceRoot())) {\n        parentPaths.add(parent);\n      }\n    }\n    // now there\u0027s a set of parent paths. We now want to\n    // get them ordered by depth, so that deeper entries come first\n    // that way: when we check for a parent path existing we can\n    // see if it really is empty.\n    List\u003cPath\u003e parents \u003d new ArrayList\u003c\u003e(parentPaths);\n    parents.sort(PathOrderComparators.TOPMOST_PATH_LAST);\n    for (Path parent : parents) {\n      PathMetadata md \u003d metadataStore.get(parent, true);\n      if (md !\u003d null \u0026\u0026 md.isEmptyDirectory() \u003d\u003d Tristate.TRUE) {\n        // if were confident that this is empty: delete it.\n        metadataStore.delete(parent, getOperationState());\n      }\n    }\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/s3guard/DelayedUpdateRenameTracker.java",
      "extendedDetails": {}
    },
    "c58e11bf521d746842ce16724211a2a0339d7b61": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-16383. Pass ITtlTimeProvider instance in initialize method in MetadataStore interface.  Contributed by Gabor Bota. (#1009) \n\n\r\n",
      "commitDate": "17/07/19 7:24 AM",
      "commitName": "c58e11bf521d746842ce16724211a2a0339d7b61",
      "commitAuthor": "Gabor Bota",
      "commitDateOld": "20/06/19 1:56 AM",
      "commitNameOld": "e02eb24e0a9139418120027b694492e0738df20a",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 27.23,
      "commitsBetweenForRepo": 235,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,22 @@\n   private void deleteParentPaths() throws IOException {\n     Set\u003cPath\u003e parentPaths \u003d new HashSet\u003c\u003e();\n     for (Path deletedPath : deletedPaths) {\n       Path parent \u003d deletedPath.getParent();\n       if (!parent.equals(getSourceRoot())) {\n         parentPaths.add(parent);\n       }\n     }\n     // now there\u0027s a set of parent paths. We now want to\n     // get them ordered by depth, so that deeper entries come first\n     // that way: when we check for a parent path existing we can\n     // see if it really is empty.\n     List\u003cPath\u003e parents \u003d new ArrayList\u003c\u003e(parentPaths);\n     parents.sort(PathOrderComparators.TOPMOST_PATH_LAST);\n     for (Path parent : parents) {\n       PathMetadata md \u003d metadataStore.get(parent, true);\n       if (md !\u003d null \u0026\u0026 md.isEmptyDirectory() \u003d\u003d Tristate.TRUE) {\n         // if were confident that this is empty: delete it.\n-        metadataStore.delete(parent, getStoreContext().getTimeProvider());\n+        metadataStore.delete(parent);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void deleteParentPaths() throws IOException {\n    Set\u003cPath\u003e parentPaths \u003d new HashSet\u003c\u003e();\n    for (Path deletedPath : deletedPaths) {\n      Path parent \u003d deletedPath.getParent();\n      if (!parent.equals(getSourceRoot())) {\n        parentPaths.add(parent);\n      }\n    }\n    // now there\u0027s a set of parent paths. We now want to\n    // get them ordered by depth, so that deeper entries come first\n    // that way: when we check for a parent path existing we can\n    // see if it really is empty.\n    List\u003cPath\u003e parents \u003d new ArrayList\u003c\u003e(parentPaths);\n    parents.sort(PathOrderComparators.TOPMOST_PATH_LAST);\n    for (Path parent : parents) {\n      PathMetadata md \u003d metadataStore.get(parent, true);\n      if (md !\u003d null \u0026\u0026 md.isEmptyDirectory() \u003d\u003d Tristate.TRUE) {\n        // if were confident that this is empty: delete it.\n        metadataStore.delete(parent);\n      }\n    }\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/s3guard/DelayedUpdateRenameTracker.java",
      "extendedDetails": {}
    },
    "e02eb24e0a9139418120027b694492e0738df20a": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-15183. S3Guard store becomes inconsistent after partial failure of rename.\n\nContributed by Steve Loughran.\n\nChange-Id: I825b0bc36be960475d2d259b1cdab45ae1bb78eb\n",
      "commitDate": "20/06/19 1:56 AM",
      "commitName": "e02eb24e0a9139418120027b694492e0738df20a",
      "commitAuthor": "Steve Loughran",
      "diff": "@@ -0,0 +1,22 @@\n+  private void deleteParentPaths() throws IOException {\n+    Set\u003cPath\u003e parentPaths \u003d new HashSet\u003c\u003e();\n+    for (Path deletedPath : deletedPaths) {\n+      Path parent \u003d deletedPath.getParent();\n+      if (!parent.equals(getSourceRoot())) {\n+        parentPaths.add(parent);\n+      }\n+    }\n+    // now there\u0027s a set of parent paths. We now want to\n+    // get them ordered by depth, so that deeper entries come first\n+    // that way: when we check for a parent path existing we can\n+    // see if it really is empty.\n+    List\u003cPath\u003e parents \u003d new ArrayList\u003c\u003e(parentPaths);\n+    parents.sort(PathOrderComparators.TOPMOST_PATH_LAST);\n+    for (Path parent : parents) {\n+      PathMetadata md \u003d metadataStore.get(parent, true);\n+      if (md !\u003d null \u0026\u0026 md.isEmptyDirectory() \u003d\u003d Tristate.TRUE) {\n+        // if were confident that this is empty: delete it.\n+        metadataStore.delete(parent, getStoreContext().getTimeProvider());\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void deleteParentPaths() throws IOException {\n    Set\u003cPath\u003e parentPaths \u003d new HashSet\u003c\u003e();\n    for (Path deletedPath : deletedPaths) {\n      Path parent \u003d deletedPath.getParent();\n      if (!parent.equals(getSourceRoot())) {\n        parentPaths.add(parent);\n      }\n    }\n    // now there\u0027s a set of parent paths. We now want to\n    // get them ordered by depth, so that deeper entries come first\n    // that way: when we check for a parent path existing we can\n    // see if it really is empty.\n    List\u003cPath\u003e parents \u003d new ArrayList\u003c\u003e(parentPaths);\n    parents.sort(PathOrderComparators.TOPMOST_PATH_LAST);\n    for (Path parent : parents) {\n      PathMetadata md \u003d metadataStore.get(parent, true);\n      if (md !\u003d null \u0026\u0026 md.isEmptyDirectory() \u003d\u003d Tristate.TRUE) {\n        // if were confident that this is empty: delete it.\n        metadataStore.delete(parent, getStoreContext().getTimeProvider());\n      }\n    }\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/s3guard/DelayedUpdateRenameTracker.java"
    }
  }
}