{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "LeafQueue.java",
  "functionName": "getUserAMResourceLimitPerPartition",
  "functionId": "getUserAMResourceLimitPerPartition___nodePartition-String__userName-String",
  "sourceFilePath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue.java",
  "functionStartLine": 675,
  "functionEndLine": 726,
  "numCommitsSeen": 407,
  "timeTaken": 10218,
  "changeHistory": [
    "2064ca015d1584263aac0cc20c60b925a3aff612",
    "39b4a37e02e929a698fcf9e32f1f71bb6b977635",
    "0c75d0634bcbdc29e804035b3b84ae6a38d6a110",
    "d52627a7cbddfd981db973e223aefffde1ebf82d",
    "5e798b1a0ddceeaf54703b94052501867156e979",
    "ca13b224b2feb9c44de861da9cbba8dd2a12cb35",
    "5fb723bb77722d41df6959eee23e1b0cfeb5584e",
    "2b66d9ec5bdaec7e6b278926fbb6f222c4e3afaa",
    "b08ecf5c7589b055e93b2907413213f36097724d",
    "56e4f6237ae8b1852e82b186e08db3934f79a9db",
    "bdd90110e6904b59746812d9a093924a65e72280",
    "14dd647c556016d351f425ee956ccf800ccb9ce2",
    "c53420f58364b11fbda1dace7679d45534533382"
  ],
  "changeHistoryShort": {
    "2064ca015d1584263aac0cc20c60b925a3aff612": "Ybodychange",
    "39b4a37e02e929a698fcf9e32f1f71bb6b977635": "Ybodychange",
    "0c75d0634bcbdc29e804035b3b84ae6a38d6a110": "Ybodychange",
    "d52627a7cbddfd981db973e223aefffde1ebf82d": "Ybodychange",
    "5e798b1a0ddceeaf54703b94052501867156e979": "Ybodychange",
    "ca13b224b2feb9c44de861da9cbba8dd2a12cb35": "Ymultichange(Yparameterchange,Ybodychange)",
    "5fb723bb77722d41df6959eee23e1b0cfeb5584e": "Ybodychange",
    "2b66d9ec5bdaec7e6b278926fbb6f222c4e3afaa": "Ymultichange(Ymodifierchange,Ybodychange)",
    "b08ecf5c7589b055e93b2907413213f36097724d": "Ybodychange",
    "56e4f6237ae8b1852e82b186e08db3934f79a9db": "Ymultichange(Yrename,Yparameterchange,Ybodychange)",
    "bdd90110e6904b59746812d9a093924a65e72280": "Ybodychange",
    "14dd647c556016d351f425ee956ccf800ccb9ce2": "Ybodychange",
    "c53420f58364b11fbda1dace7679d45534533382": "Yintroduced"
  },
  "changeHistoryDetails": {
    "2064ca015d1584263aac0cc20c60b925a3aff612": {
      "type": "Ybodychange",
      "commitMessage": "YARN-9349.  Changed logging to use slf4j api.\n            Contributed by Prabhu Joseph\n",
      "commitDate": "15/03/19 4:20 PM",
      "commitName": "2064ca015d1584263aac0cc20c60b925a3aff612",
      "commitAuthor": "Eric Yang",
      "commitDateOld": "07/03/19 1:47 PM",
      "commitNameOld": "39b4a37e02e929a698fcf9e32f1f71bb6b977635",
      "commitAuthorOld": "Eric Yang",
      "daysBetweenCommits": 8.06,
      "commitsBetweenForRepo": 69,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,54 +1,52 @@\n   public Resource getUserAMResourceLimitPerPartition(\n       String nodePartition, String userName) {\n     float userWeight \u003d 1.0f;\n     if (userName !\u003d null \u0026\u0026 getUser(userName) !\u003d null) {\n       userWeight \u003d getUser(userName).getWeight();\n     }\n \n     readLock.lock();\n     try {\n       /*\n        * The user am resource limit is based on the same approach as the user\n        * limit (as it should represent a subset of that). This means that it uses\n        * the absolute queue capacity (per partition) instead of the max and is\n        * modified by the userlimit and the userlimit factor as is the userlimit\n        */\n       float effectiveUserLimit \u003d Math.max(usersManager.getUserLimit() / 100.0f,\n           1.0f / Math.max(getAbstractUsersManager().getNumActiveUsers(), 1));\n       float preWeightedUserLimit \u003d effectiveUserLimit;\n       effectiveUserLimit \u003d Math.min(effectiveUserLimit * userWeight, 1.0f);\n \n       Resource queuePartitionResource \u003d getEffectiveCapacity(nodePartition);\n \n       Resource userAMLimit \u003d Resources.multiplyAndNormalizeUp(\n           resourceCalculator, queuePartitionResource,\n           queueCapacities.getMaxAMResourcePercentage(nodePartition)\n               * effectiveUserLimit * usersManager.getUserLimitFactor(),\n           minimumAllocation);\n       userAMLimit \u003d\n           Resources.min(resourceCalculator, lastClusterResource,\n               userAMLimit,\n               Resources.clone(getAMResourceLimitPerPartition(nodePartition)));\n \n       Resource preWeighteduserAMLimit \u003d Resources.multiplyAndNormalizeUp(\n           resourceCalculator, queuePartitionResource,\n           queueCapacities.getMaxAMResourcePercentage(nodePartition)\n               * preWeightedUserLimit * usersManager.getUserLimitFactor(),\n           minimumAllocation);\n       preWeighteduserAMLimit \u003d\n           Resources.min(resourceCalculator, lastClusterResource,\n               preWeighteduserAMLimit,\n               Resources.clone(getAMResourceLimitPerPartition(nodePartition)));\n       queueUsage.setUserAMLimit(nodePartition, preWeighteduserAMLimit);\n \n-      if (LOG.isDebugEnabled()) {\n-        LOG.debug(\"Effective user AM limit for \\\"\" + userName + \"\\\":\" +\n-            preWeighteduserAMLimit + \". \" + \"Effective weighted user AM limit: \"\n-            + userAMLimit + \". User weight: \" + userWeight);\n-      }\n+      LOG.debug(\"Effective user AM limit for \\\"{}\\\":{}. Effective weighted\"\n+          + \" user AM limit: {}. User weight: {}\", userName,\n+          preWeighteduserAMLimit, userAMLimit, userWeight);\n       return userAMLimit;\n     } finally {\n       readLock.unlock();\n     }\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public Resource getUserAMResourceLimitPerPartition(\n      String nodePartition, String userName) {\n    float userWeight \u003d 1.0f;\n    if (userName !\u003d null \u0026\u0026 getUser(userName) !\u003d null) {\n      userWeight \u003d getUser(userName).getWeight();\n    }\n\n    readLock.lock();\n    try {\n      /*\n       * The user am resource limit is based on the same approach as the user\n       * limit (as it should represent a subset of that). This means that it uses\n       * the absolute queue capacity (per partition) instead of the max and is\n       * modified by the userlimit and the userlimit factor as is the userlimit\n       */\n      float effectiveUserLimit \u003d Math.max(usersManager.getUserLimit() / 100.0f,\n          1.0f / Math.max(getAbstractUsersManager().getNumActiveUsers(), 1));\n      float preWeightedUserLimit \u003d effectiveUserLimit;\n      effectiveUserLimit \u003d Math.min(effectiveUserLimit * userWeight, 1.0f);\n\n      Resource queuePartitionResource \u003d getEffectiveCapacity(nodePartition);\n\n      Resource userAMLimit \u003d Resources.multiplyAndNormalizeUp(\n          resourceCalculator, queuePartitionResource,\n          queueCapacities.getMaxAMResourcePercentage(nodePartition)\n              * effectiveUserLimit * usersManager.getUserLimitFactor(),\n          minimumAllocation);\n      userAMLimit \u003d\n          Resources.min(resourceCalculator, lastClusterResource,\n              userAMLimit,\n              Resources.clone(getAMResourceLimitPerPartition(nodePartition)));\n\n      Resource preWeighteduserAMLimit \u003d Resources.multiplyAndNormalizeUp(\n          resourceCalculator, queuePartitionResource,\n          queueCapacities.getMaxAMResourcePercentage(nodePartition)\n              * preWeightedUserLimit * usersManager.getUserLimitFactor(),\n          minimumAllocation);\n      preWeighteduserAMLimit \u003d\n          Resources.min(resourceCalculator, lastClusterResource,\n              preWeighteduserAMLimit,\n              Resources.clone(getAMResourceLimitPerPartition(nodePartition)));\n      queueUsage.setUserAMLimit(nodePartition, preWeighteduserAMLimit);\n\n      LOG.debug(\"Effective user AM limit for \\\"{}\\\":{}. Effective weighted\"\n          + \" user AM limit: {}. User weight: {}\", userName,\n          preWeighteduserAMLimit, userAMLimit, userWeight);\n      return userAMLimit;\n    } finally {\n      readLock.unlock();\n    }\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue.java",
      "extendedDetails": {}
    },
    "39b4a37e02e929a698fcf9e32f1f71bb6b977635": {
      "type": "Ybodychange",
      "commitMessage": "YARN-9341.  Fixed enentrant lock usage in YARN project.\n            Contributed by Prabhu Joseph\n",
      "commitDate": "07/03/19 1:47 PM",
      "commitName": "39b4a37e02e929a698fcf9e32f1f71bb6b977635",
      "commitAuthor": "Eric Yang",
      "commitDateOld": "04/03/19 9:10 PM",
      "commitNameOld": "e40e2d6ad5cbe782c3a067229270738b501ed27e",
      "commitAuthorOld": "Prabhu Joseph",
      "daysBetweenCommits": 2.69,
      "commitsBetweenForRepo": 39,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,53 +1,54 @@\n   public Resource getUserAMResourceLimitPerPartition(\n       String nodePartition, String userName) {\n     float userWeight \u003d 1.0f;\n     if (userName !\u003d null \u0026\u0026 getUser(userName) !\u003d null) {\n       userWeight \u003d getUser(userName).getWeight();\n     }\n+\n+    readLock.lock();\n     try {\n-      readLock.lock();\n       /*\n        * The user am resource limit is based on the same approach as the user\n        * limit (as it should represent a subset of that). This means that it uses\n        * the absolute queue capacity (per partition) instead of the max and is\n        * modified by the userlimit and the userlimit factor as is the userlimit\n        */\n       float effectiveUserLimit \u003d Math.max(usersManager.getUserLimit() / 100.0f,\n           1.0f / Math.max(getAbstractUsersManager().getNumActiveUsers(), 1));\n       float preWeightedUserLimit \u003d effectiveUserLimit;\n       effectiveUserLimit \u003d Math.min(effectiveUserLimit * userWeight, 1.0f);\n \n       Resource queuePartitionResource \u003d getEffectiveCapacity(nodePartition);\n \n       Resource userAMLimit \u003d Resources.multiplyAndNormalizeUp(\n           resourceCalculator, queuePartitionResource,\n           queueCapacities.getMaxAMResourcePercentage(nodePartition)\n               * effectiveUserLimit * usersManager.getUserLimitFactor(),\n           minimumAllocation);\n       userAMLimit \u003d\n           Resources.min(resourceCalculator, lastClusterResource,\n               userAMLimit,\n               Resources.clone(getAMResourceLimitPerPartition(nodePartition)));\n \n       Resource preWeighteduserAMLimit \u003d Resources.multiplyAndNormalizeUp(\n           resourceCalculator, queuePartitionResource,\n           queueCapacities.getMaxAMResourcePercentage(nodePartition)\n               * preWeightedUserLimit * usersManager.getUserLimitFactor(),\n           minimumAllocation);\n       preWeighteduserAMLimit \u003d\n           Resources.min(resourceCalculator, lastClusterResource,\n               preWeighteduserAMLimit,\n               Resources.clone(getAMResourceLimitPerPartition(nodePartition)));\n       queueUsage.setUserAMLimit(nodePartition, preWeighteduserAMLimit);\n \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Effective user AM limit for \\\"\" + userName + \"\\\":\" +\n             preWeighteduserAMLimit + \". \" + \"Effective weighted user AM limit: \"\n             + userAMLimit + \". User weight: \" + userWeight);\n       }\n       return userAMLimit;\n     } finally {\n       readLock.unlock();\n     }\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public Resource getUserAMResourceLimitPerPartition(\n      String nodePartition, String userName) {\n    float userWeight \u003d 1.0f;\n    if (userName !\u003d null \u0026\u0026 getUser(userName) !\u003d null) {\n      userWeight \u003d getUser(userName).getWeight();\n    }\n\n    readLock.lock();\n    try {\n      /*\n       * The user am resource limit is based on the same approach as the user\n       * limit (as it should represent a subset of that). This means that it uses\n       * the absolute queue capacity (per partition) instead of the max and is\n       * modified by the userlimit and the userlimit factor as is the userlimit\n       */\n      float effectiveUserLimit \u003d Math.max(usersManager.getUserLimit() / 100.0f,\n          1.0f / Math.max(getAbstractUsersManager().getNumActiveUsers(), 1));\n      float preWeightedUserLimit \u003d effectiveUserLimit;\n      effectiveUserLimit \u003d Math.min(effectiveUserLimit * userWeight, 1.0f);\n\n      Resource queuePartitionResource \u003d getEffectiveCapacity(nodePartition);\n\n      Resource userAMLimit \u003d Resources.multiplyAndNormalizeUp(\n          resourceCalculator, queuePartitionResource,\n          queueCapacities.getMaxAMResourcePercentage(nodePartition)\n              * effectiveUserLimit * usersManager.getUserLimitFactor(),\n          minimumAllocation);\n      userAMLimit \u003d\n          Resources.min(resourceCalculator, lastClusterResource,\n              userAMLimit,\n              Resources.clone(getAMResourceLimitPerPartition(nodePartition)));\n\n      Resource preWeighteduserAMLimit \u003d Resources.multiplyAndNormalizeUp(\n          resourceCalculator, queuePartitionResource,\n          queueCapacities.getMaxAMResourcePercentage(nodePartition)\n              * preWeightedUserLimit * usersManager.getUserLimitFactor(),\n          minimumAllocation);\n      preWeighteduserAMLimit \u003d\n          Resources.min(resourceCalculator, lastClusterResource,\n              preWeighteduserAMLimit,\n              Resources.clone(getAMResourceLimitPerPartition(nodePartition)));\n      queueUsage.setUserAMLimit(nodePartition, preWeighteduserAMLimit);\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Effective user AM limit for \\\"\" + userName + \"\\\":\" +\n            preWeighteduserAMLimit + \". \" + \"Effective weighted user AM limit: \"\n            + userAMLimit + \". User weight: \" + userWeight);\n      }\n      return userAMLimit;\n    } finally {\n      readLock.unlock();\n    }\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue.java",
      "extendedDetails": {}
    },
    "0c75d0634bcbdc29e804035b3b84ae6a38d6a110": {
      "type": "Ybodychange",
      "commitMessage": "YARN-7619. Max AM Resource value in Capacity Scheduler UI has to be refreshed for every user. Contributed by Eric Payne.\n",
      "commitDate": "05/01/18 1:12 AM",
      "commitName": "0c75d0634bcbdc29e804035b3b84ae6a38d6a110",
      "commitAuthor": "Sunil G",
      "commitDateOld": "14/12/17 11:30 PM",
      "commitNameOld": "890d3d06456a026d9551a0cf15ce3986b0641454",
      "commitAuthorOld": "Sunil G",
      "daysBetweenCommits": 21.07,
      "commitsBetweenForRepo": 108,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,34 +1,53 @@\n   public Resource getUserAMResourceLimitPerPartition(\n       String nodePartition, String userName) {\n     float userWeight \u003d 1.0f;\n     if (userName !\u003d null \u0026\u0026 getUser(userName) !\u003d null) {\n       userWeight \u003d getUser(userName).getWeight();\n     }\n     try {\n       readLock.lock();\n       /*\n        * The user am resource limit is based on the same approach as the user\n        * limit (as it should represent a subset of that). This means that it uses\n        * the absolute queue capacity (per partition) instead of the max and is\n        * modified by the userlimit and the userlimit factor as is the userlimit\n        */\n       float effectiveUserLimit \u003d Math.max(usersManager.getUserLimit() / 100.0f,\n           1.0f / Math.max(getAbstractUsersManager().getNumActiveUsers(), 1));\n+      float preWeightedUserLimit \u003d effectiveUserLimit;\n       effectiveUserLimit \u003d Math.min(effectiveUserLimit * userWeight, 1.0f);\n \n       Resource queuePartitionResource \u003d getEffectiveCapacity(nodePartition);\n \n       Resource userAMLimit \u003d Resources.multiplyAndNormalizeUp(\n           resourceCalculator, queuePartitionResource,\n           queueCapacities.getMaxAMResourcePercentage(nodePartition)\n               * effectiveUserLimit * usersManager.getUserLimitFactor(),\n           minimumAllocation);\n-      return Resources.lessThanOrEqual(resourceCalculator, lastClusterResource,\n-          userAMLimit, getAMResourceLimitPerPartition(nodePartition)) ?\n-          userAMLimit :\n-          getAMResourceLimitPerPartition(nodePartition);\n+      userAMLimit \u003d\n+          Resources.min(resourceCalculator, lastClusterResource,\n+              userAMLimit,\n+              Resources.clone(getAMResourceLimitPerPartition(nodePartition)));\n+\n+      Resource preWeighteduserAMLimit \u003d Resources.multiplyAndNormalizeUp(\n+          resourceCalculator, queuePartitionResource,\n+          queueCapacities.getMaxAMResourcePercentage(nodePartition)\n+              * preWeightedUserLimit * usersManager.getUserLimitFactor(),\n+          minimumAllocation);\n+      preWeighteduserAMLimit \u003d\n+          Resources.min(resourceCalculator, lastClusterResource,\n+              preWeighteduserAMLimit,\n+              Resources.clone(getAMResourceLimitPerPartition(nodePartition)));\n+      queueUsage.setUserAMLimit(nodePartition, preWeighteduserAMLimit);\n+\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(\"Effective user AM limit for \\\"\" + userName + \"\\\":\" +\n+            preWeighteduserAMLimit + \". \" + \"Effective weighted user AM limit: \"\n+            + userAMLimit + \". User weight: \" + userWeight);\n+      }\n+      return userAMLimit;\n     } finally {\n       readLock.unlock();\n     }\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public Resource getUserAMResourceLimitPerPartition(\n      String nodePartition, String userName) {\n    float userWeight \u003d 1.0f;\n    if (userName !\u003d null \u0026\u0026 getUser(userName) !\u003d null) {\n      userWeight \u003d getUser(userName).getWeight();\n    }\n    try {\n      readLock.lock();\n      /*\n       * The user am resource limit is based on the same approach as the user\n       * limit (as it should represent a subset of that). This means that it uses\n       * the absolute queue capacity (per partition) instead of the max and is\n       * modified by the userlimit and the userlimit factor as is the userlimit\n       */\n      float effectiveUserLimit \u003d Math.max(usersManager.getUserLimit() / 100.0f,\n          1.0f / Math.max(getAbstractUsersManager().getNumActiveUsers(), 1));\n      float preWeightedUserLimit \u003d effectiveUserLimit;\n      effectiveUserLimit \u003d Math.min(effectiveUserLimit * userWeight, 1.0f);\n\n      Resource queuePartitionResource \u003d getEffectiveCapacity(nodePartition);\n\n      Resource userAMLimit \u003d Resources.multiplyAndNormalizeUp(\n          resourceCalculator, queuePartitionResource,\n          queueCapacities.getMaxAMResourcePercentage(nodePartition)\n              * effectiveUserLimit * usersManager.getUserLimitFactor(),\n          minimumAllocation);\n      userAMLimit \u003d\n          Resources.min(resourceCalculator, lastClusterResource,\n              userAMLimit,\n              Resources.clone(getAMResourceLimitPerPartition(nodePartition)));\n\n      Resource preWeighteduserAMLimit \u003d Resources.multiplyAndNormalizeUp(\n          resourceCalculator, queuePartitionResource,\n          queueCapacities.getMaxAMResourcePercentage(nodePartition)\n              * preWeightedUserLimit * usersManager.getUserLimitFactor(),\n          minimumAllocation);\n      preWeighteduserAMLimit \u003d\n          Resources.min(resourceCalculator, lastClusterResource,\n              preWeighteduserAMLimit,\n              Resources.clone(getAMResourceLimitPerPartition(nodePartition)));\n      queueUsage.setUserAMLimit(nodePartition, preWeighteduserAMLimit);\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Effective user AM limit for \\\"\" + userName + \"\\\":\" +\n            preWeighteduserAMLimit + \". \" + \"Effective weighted user AM limit: \"\n            + userAMLimit + \". User weight: \" + userWeight);\n      }\n      return userAMLimit;\n    } finally {\n      readLock.unlock();\n    }\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue.java",
      "extendedDetails": {}
    },
    "d52627a7cbddfd981db973e223aefffde1ebf82d": {
      "type": "Ybodychange",
      "commitMessage": "YARN-7254. UI and metrics changes related to absolute resource configuration. (Sunil G via wangda)\n",
      "commitDate": "07/12/17 6:56 PM",
      "commitName": "d52627a7cbddfd981db973e223aefffde1ebf82d",
      "commitAuthor": "Wangda Tan",
      "commitDateOld": "07/12/17 6:56 PM",
      "commitNameOld": "5e798b1a0ddceeaf54703b94052501867156e979",
      "commitAuthorOld": "Wangda Tan",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,34 +1,34 @@\n   public Resource getUserAMResourceLimitPerPartition(\n       String nodePartition, String userName) {\n     float userWeight \u003d 1.0f;\n     if (userName !\u003d null \u0026\u0026 getUser(userName) !\u003d null) {\n       userWeight \u003d getUser(userName).getWeight();\n     }\n     try {\n       readLock.lock();\n       /*\n        * The user am resource limit is based on the same approach as the user\n        * limit (as it should represent a subset of that). This means that it uses\n        * the absolute queue capacity (per partition) instead of the max and is\n        * modified by the userlimit and the userlimit factor as is the userlimit\n        */\n       float effectiveUserLimit \u003d Math.max(usersManager.getUserLimit() / 100.0f,\n           1.0f / Math.max(getAbstractUsersManager().getNumActiveUsers(), 1));\n       effectiveUserLimit \u003d Math.min(effectiveUserLimit * userWeight, 1.0f);\n \n-      Resource queuePartitionResource \u003d getEffectiveCapacityUp(nodePartition);\n+      Resource queuePartitionResource \u003d getEffectiveCapacity(nodePartition);\n \n       Resource userAMLimit \u003d Resources.multiplyAndNormalizeUp(\n           resourceCalculator, queuePartitionResource,\n           queueCapacities.getMaxAMResourcePercentage(nodePartition)\n               * effectiveUserLimit * usersManager.getUserLimitFactor(),\n           minimumAllocation);\n       return Resources.lessThanOrEqual(resourceCalculator, lastClusterResource,\n           userAMLimit, getAMResourceLimitPerPartition(nodePartition)) ?\n           userAMLimit :\n           getAMResourceLimitPerPartition(nodePartition);\n     } finally {\n       readLock.unlock();\n     }\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public Resource getUserAMResourceLimitPerPartition(\n      String nodePartition, String userName) {\n    float userWeight \u003d 1.0f;\n    if (userName !\u003d null \u0026\u0026 getUser(userName) !\u003d null) {\n      userWeight \u003d getUser(userName).getWeight();\n    }\n    try {\n      readLock.lock();\n      /*\n       * The user am resource limit is based on the same approach as the user\n       * limit (as it should represent a subset of that). This means that it uses\n       * the absolute queue capacity (per partition) instead of the max and is\n       * modified by the userlimit and the userlimit factor as is the userlimit\n       */\n      float effectiveUserLimit \u003d Math.max(usersManager.getUserLimit() / 100.0f,\n          1.0f / Math.max(getAbstractUsersManager().getNumActiveUsers(), 1));\n      effectiveUserLimit \u003d Math.min(effectiveUserLimit * userWeight, 1.0f);\n\n      Resource queuePartitionResource \u003d getEffectiveCapacity(nodePartition);\n\n      Resource userAMLimit \u003d Resources.multiplyAndNormalizeUp(\n          resourceCalculator, queuePartitionResource,\n          queueCapacities.getMaxAMResourcePercentage(nodePartition)\n              * effectiveUserLimit * usersManager.getUserLimitFactor(),\n          minimumAllocation);\n      return Resources.lessThanOrEqual(resourceCalculator, lastClusterResource,\n          userAMLimit, getAMResourceLimitPerPartition(nodePartition)) ?\n          userAMLimit :\n          getAMResourceLimitPerPartition(nodePartition);\n    } finally {\n      readLock.unlock();\n    }\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue.java",
      "extendedDetails": {}
    },
    "5e798b1a0ddceeaf54703b94052501867156e979": {
      "type": "Ybodychange",
      "commitMessage": "YARN-6471. Support to add min/max resource configuration for a queue. (Sunil G via wangda)\n\nChange-Id: I9213f5297a6841fab5c573e85ee4c4e5f4a0b7ff\n",
      "commitDate": "07/12/17 6:56 PM",
      "commitName": "5e798b1a0ddceeaf54703b94052501867156e979",
      "commitAuthor": "Wangda Tan",
      "commitDateOld": "09/11/17 1:01 PM",
      "commitNameOld": "ac4d2b1081d8836a21bc70e77f4e6cd2071a9949",
      "commitAuthorOld": "Konstantinos Karanasos",
      "daysBetweenCommits": 28.25,
      "commitsBetweenForRepo": 137,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,39 +1,34 @@\n   public Resource getUserAMResourceLimitPerPartition(\n       String nodePartition, String userName) {\n     float userWeight \u003d 1.0f;\n     if (userName !\u003d null \u0026\u0026 getUser(userName) !\u003d null) {\n       userWeight \u003d getUser(userName).getWeight();\n     }\n     try {\n       readLock.lock();\n       /*\n        * The user am resource limit is based on the same approach as the user\n        * limit (as it should represent a subset of that). This means that it uses\n        * the absolute queue capacity (per partition) instead of the max and is\n        * modified by the userlimit and the userlimit factor as is the userlimit\n        */\n       float effectiveUserLimit \u003d Math.max(usersManager.getUserLimit() / 100.0f,\n           1.0f / Math.max(getAbstractUsersManager().getNumActiveUsers(), 1));\n       effectiveUserLimit \u003d Math.min(effectiveUserLimit * userWeight, 1.0f);\n \n-      Resource queuePartitionResource \u003d Resources\n-          .multiplyAndNormalizeUp(resourceCalculator,\n-              labelManager.getResourceByLabel(nodePartition,\n-                  lastClusterResource),\n-              queueCapacities.getAbsoluteCapacity(nodePartition),\n-              minimumAllocation);\n+      Resource queuePartitionResource \u003d getEffectiveCapacityUp(nodePartition);\n \n       Resource userAMLimit \u003d Resources.multiplyAndNormalizeUp(\n           resourceCalculator, queuePartitionResource,\n           queueCapacities.getMaxAMResourcePercentage(nodePartition)\n               * effectiveUserLimit * usersManager.getUserLimitFactor(),\n           minimumAllocation);\n       return Resources.lessThanOrEqual(resourceCalculator, lastClusterResource,\n           userAMLimit, getAMResourceLimitPerPartition(nodePartition)) ?\n           userAMLimit :\n           getAMResourceLimitPerPartition(nodePartition);\n     } finally {\n       readLock.unlock();\n     }\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public Resource getUserAMResourceLimitPerPartition(\n      String nodePartition, String userName) {\n    float userWeight \u003d 1.0f;\n    if (userName !\u003d null \u0026\u0026 getUser(userName) !\u003d null) {\n      userWeight \u003d getUser(userName).getWeight();\n    }\n    try {\n      readLock.lock();\n      /*\n       * The user am resource limit is based on the same approach as the user\n       * limit (as it should represent a subset of that). This means that it uses\n       * the absolute queue capacity (per partition) instead of the max and is\n       * modified by the userlimit and the userlimit factor as is the userlimit\n       */\n      float effectiveUserLimit \u003d Math.max(usersManager.getUserLimit() / 100.0f,\n          1.0f / Math.max(getAbstractUsersManager().getNumActiveUsers(), 1));\n      effectiveUserLimit \u003d Math.min(effectiveUserLimit * userWeight, 1.0f);\n\n      Resource queuePartitionResource \u003d getEffectiveCapacityUp(nodePartition);\n\n      Resource userAMLimit \u003d Resources.multiplyAndNormalizeUp(\n          resourceCalculator, queuePartitionResource,\n          queueCapacities.getMaxAMResourcePercentage(nodePartition)\n              * effectiveUserLimit * usersManager.getUserLimitFactor(),\n          minimumAllocation);\n      return Resources.lessThanOrEqual(resourceCalculator, lastClusterResource,\n          userAMLimit, getAMResourceLimitPerPartition(nodePartition)) ?\n          userAMLimit :\n          getAMResourceLimitPerPartition(nodePartition);\n    } finally {\n      readLock.unlock();\n    }\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue.java",
      "extendedDetails": {}
    },
    "ca13b224b2feb9c44de861da9cbba8dd2a12cb35": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "YARN-5892. Support user-specific minimum user limit percentage in Capacity Scheduler. Contributed by Eric Payne.\n",
      "commitDate": "22/06/17 11:50 PM",
      "commitName": "ca13b224b2feb9c44de861da9cbba8dd2a12cb35",
      "commitAuthor": "Sunil G",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "YARN-5892. Support user-specific minimum user limit percentage in Capacity Scheduler. Contributed by Eric Payne.\n",
          "commitDate": "22/06/17 11:50 PM",
          "commitName": "ca13b224b2feb9c44de861da9cbba8dd2a12cb35",
          "commitAuthor": "Sunil G",
          "commitDateOld": "19/06/17 9:01 AM",
          "commitNameOld": "e9c2aa1bc383cb08784846534415bf17667d6e41",
          "commitAuthorOld": "Naganarasimha",
          "daysBetweenCommits": 3.62,
          "commitsBetweenForRepo": 29,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,34 +1,39 @@\n   public Resource getUserAMResourceLimitPerPartition(\n-      String nodePartition) {\n+      String nodePartition, String userName) {\n+    float userWeight \u003d 1.0f;\n+    if (userName !\u003d null \u0026\u0026 getUser(userName) !\u003d null) {\n+      userWeight \u003d getUser(userName).getWeight();\n+    }\n     try {\n       readLock.lock();\n       /*\n        * The user am resource limit is based on the same approach as the user\n        * limit (as it should represent a subset of that). This means that it uses\n        * the absolute queue capacity (per partition) instead of the max and is\n        * modified by the userlimit and the userlimit factor as is the userlimit\n        */\n       float effectiveUserLimit \u003d Math.max(usersManager.getUserLimit() / 100.0f,\n           1.0f / Math.max(getAbstractUsersManager().getNumActiveUsers(), 1));\n+      effectiveUserLimit \u003d Math.min(effectiveUserLimit * userWeight, 1.0f);\n \n       Resource queuePartitionResource \u003d Resources\n           .multiplyAndNormalizeUp(resourceCalculator,\n               labelManager.getResourceByLabel(nodePartition,\n                   lastClusterResource),\n               queueCapacities.getAbsoluteCapacity(nodePartition),\n               minimumAllocation);\n \n       Resource userAMLimit \u003d Resources.multiplyAndNormalizeUp(\n           resourceCalculator, queuePartitionResource,\n           queueCapacities.getMaxAMResourcePercentage(nodePartition)\n               * effectiveUserLimit * usersManager.getUserLimitFactor(),\n           minimumAllocation);\n       return Resources.lessThanOrEqual(resourceCalculator, lastClusterResource,\n           userAMLimit, getAMResourceLimitPerPartition(nodePartition)) ?\n           userAMLimit :\n           getAMResourceLimitPerPartition(nodePartition);\n     } finally {\n       readLock.unlock();\n     }\n \n   }\n\\ No newline at end of file\n",
          "actualSource": "  public Resource getUserAMResourceLimitPerPartition(\n      String nodePartition, String userName) {\n    float userWeight \u003d 1.0f;\n    if (userName !\u003d null \u0026\u0026 getUser(userName) !\u003d null) {\n      userWeight \u003d getUser(userName).getWeight();\n    }\n    try {\n      readLock.lock();\n      /*\n       * The user am resource limit is based on the same approach as the user\n       * limit (as it should represent a subset of that). This means that it uses\n       * the absolute queue capacity (per partition) instead of the max and is\n       * modified by the userlimit and the userlimit factor as is the userlimit\n       */\n      float effectiveUserLimit \u003d Math.max(usersManager.getUserLimit() / 100.0f,\n          1.0f / Math.max(getAbstractUsersManager().getNumActiveUsers(), 1));\n      effectiveUserLimit \u003d Math.min(effectiveUserLimit * userWeight, 1.0f);\n\n      Resource queuePartitionResource \u003d Resources\n          .multiplyAndNormalizeUp(resourceCalculator,\n              labelManager.getResourceByLabel(nodePartition,\n                  lastClusterResource),\n              queueCapacities.getAbsoluteCapacity(nodePartition),\n              minimumAllocation);\n\n      Resource userAMLimit \u003d Resources.multiplyAndNormalizeUp(\n          resourceCalculator, queuePartitionResource,\n          queueCapacities.getMaxAMResourcePercentage(nodePartition)\n              * effectiveUserLimit * usersManager.getUserLimitFactor(),\n          minimumAllocation);\n      return Resources.lessThanOrEqual(resourceCalculator, lastClusterResource,\n          userAMLimit, getAMResourceLimitPerPartition(nodePartition)) ?\n          userAMLimit :\n          getAMResourceLimitPerPartition(nodePartition);\n    } finally {\n      readLock.unlock();\n    }\n\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue.java",
          "extendedDetails": {
            "oldValue": "[nodePartition-String]",
            "newValue": "[nodePartition-String, userName-String]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-5892. Support user-specific minimum user limit percentage in Capacity Scheduler. Contributed by Eric Payne.\n",
          "commitDate": "22/06/17 11:50 PM",
          "commitName": "ca13b224b2feb9c44de861da9cbba8dd2a12cb35",
          "commitAuthor": "Sunil G",
          "commitDateOld": "19/06/17 9:01 AM",
          "commitNameOld": "e9c2aa1bc383cb08784846534415bf17667d6e41",
          "commitAuthorOld": "Naganarasimha",
          "daysBetweenCommits": 3.62,
          "commitsBetweenForRepo": 29,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,34 +1,39 @@\n   public Resource getUserAMResourceLimitPerPartition(\n-      String nodePartition) {\n+      String nodePartition, String userName) {\n+    float userWeight \u003d 1.0f;\n+    if (userName !\u003d null \u0026\u0026 getUser(userName) !\u003d null) {\n+      userWeight \u003d getUser(userName).getWeight();\n+    }\n     try {\n       readLock.lock();\n       /*\n        * The user am resource limit is based on the same approach as the user\n        * limit (as it should represent a subset of that). This means that it uses\n        * the absolute queue capacity (per partition) instead of the max and is\n        * modified by the userlimit and the userlimit factor as is the userlimit\n        */\n       float effectiveUserLimit \u003d Math.max(usersManager.getUserLimit() / 100.0f,\n           1.0f / Math.max(getAbstractUsersManager().getNumActiveUsers(), 1));\n+      effectiveUserLimit \u003d Math.min(effectiveUserLimit * userWeight, 1.0f);\n \n       Resource queuePartitionResource \u003d Resources\n           .multiplyAndNormalizeUp(resourceCalculator,\n               labelManager.getResourceByLabel(nodePartition,\n                   lastClusterResource),\n               queueCapacities.getAbsoluteCapacity(nodePartition),\n               minimumAllocation);\n \n       Resource userAMLimit \u003d Resources.multiplyAndNormalizeUp(\n           resourceCalculator, queuePartitionResource,\n           queueCapacities.getMaxAMResourcePercentage(nodePartition)\n               * effectiveUserLimit * usersManager.getUserLimitFactor(),\n           minimumAllocation);\n       return Resources.lessThanOrEqual(resourceCalculator, lastClusterResource,\n           userAMLimit, getAMResourceLimitPerPartition(nodePartition)) ?\n           userAMLimit :\n           getAMResourceLimitPerPartition(nodePartition);\n     } finally {\n       readLock.unlock();\n     }\n \n   }\n\\ No newline at end of file\n",
          "actualSource": "  public Resource getUserAMResourceLimitPerPartition(\n      String nodePartition, String userName) {\n    float userWeight \u003d 1.0f;\n    if (userName !\u003d null \u0026\u0026 getUser(userName) !\u003d null) {\n      userWeight \u003d getUser(userName).getWeight();\n    }\n    try {\n      readLock.lock();\n      /*\n       * The user am resource limit is based on the same approach as the user\n       * limit (as it should represent a subset of that). This means that it uses\n       * the absolute queue capacity (per partition) instead of the max and is\n       * modified by the userlimit and the userlimit factor as is the userlimit\n       */\n      float effectiveUserLimit \u003d Math.max(usersManager.getUserLimit() / 100.0f,\n          1.0f / Math.max(getAbstractUsersManager().getNumActiveUsers(), 1));\n      effectiveUserLimit \u003d Math.min(effectiveUserLimit * userWeight, 1.0f);\n\n      Resource queuePartitionResource \u003d Resources\n          .multiplyAndNormalizeUp(resourceCalculator,\n              labelManager.getResourceByLabel(nodePartition,\n                  lastClusterResource),\n              queueCapacities.getAbsoluteCapacity(nodePartition),\n              minimumAllocation);\n\n      Resource userAMLimit \u003d Resources.multiplyAndNormalizeUp(\n          resourceCalculator, queuePartitionResource,\n          queueCapacities.getMaxAMResourcePercentage(nodePartition)\n              * effectiveUserLimit * usersManager.getUserLimitFactor(),\n          minimumAllocation);\n      return Resources.lessThanOrEqual(resourceCalculator, lastClusterResource,\n          userAMLimit, getAMResourceLimitPerPartition(nodePartition)) ?\n          userAMLimit :\n          getAMResourceLimitPerPartition(nodePartition);\n    } finally {\n      readLock.unlock();\n    }\n\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue.java",
          "extendedDetails": {}
        }
      ]
    },
    "5fb723bb77722d41df6959eee23e1b0cfeb5584e": {
      "type": "Ybodychange",
      "commitMessage": "YARN-5889. Improve and refactor user-limit calculation in Capacity Scheduler. (Sunil G via wangda)\n",
      "commitDate": "09/02/17 10:23 AM",
      "commitName": "5fb723bb77722d41df6959eee23e1b0cfeb5584e",
      "commitAuthor": "Wangda Tan",
      "commitDateOld": "23/01/17 10:52 AM",
      "commitNameOld": "ce832059db077fa95922198b066a737ed4f609fe",
      "commitAuthorOld": "Wangda Tan",
      "daysBetweenCommits": 16.98,
      "commitsBetweenForRepo": 67,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,32 +1,34 @@\n   public Resource getUserAMResourceLimitPerPartition(\n       String nodePartition) {\n     try {\n       readLock.lock();\n       /*\n        * The user am resource limit is based on the same approach as the user\n        * limit (as it should represent a subset of that). This means that it uses\n        * the absolute queue capacity (per partition) instead of the max and is\n        * modified by the userlimit and the userlimit factor as is the userlimit\n        */\n-      float effectiveUserLimit \u003d Math.max(userLimit / 100.0f,\n-          1.0f / Math.max(getActiveUsersManager().getNumActiveUsers(), 1));\n+      float effectiveUserLimit \u003d Math.max(usersManager.getUserLimit() / 100.0f,\n+          1.0f / Math.max(getAbstractUsersManager().getNumActiveUsers(), 1));\n \n-      Resource queuePartitionResource \u003d Resources.multiplyAndNormalizeUp(\n-          resourceCalculator,\n-          labelManager.getResourceByLabel(nodePartition, lastClusterResource),\n-          queueCapacities.getAbsoluteCapacity(nodePartition),\n-          minimumAllocation);\n+      Resource queuePartitionResource \u003d Resources\n+          .multiplyAndNormalizeUp(resourceCalculator,\n+              labelManager.getResourceByLabel(nodePartition,\n+                  lastClusterResource),\n+              queueCapacities.getAbsoluteCapacity(nodePartition),\n+              minimumAllocation);\n \n       Resource userAMLimit \u003d Resources.multiplyAndNormalizeUp(\n           resourceCalculator, queuePartitionResource,\n           queueCapacities.getMaxAMResourcePercentage(nodePartition)\n-              * effectiveUserLimit * userLimitFactor, minimumAllocation);\n+              * effectiveUserLimit * usersManager.getUserLimitFactor(),\n+          minimumAllocation);\n       return Resources.lessThanOrEqual(resourceCalculator, lastClusterResource,\n           userAMLimit, getAMResourceLimitPerPartition(nodePartition)) ?\n           userAMLimit :\n           getAMResourceLimitPerPartition(nodePartition);\n     } finally {\n       readLock.unlock();\n     }\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public Resource getUserAMResourceLimitPerPartition(\n      String nodePartition) {\n    try {\n      readLock.lock();\n      /*\n       * The user am resource limit is based on the same approach as the user\n       * limit (as it should represent a subset of that). This means that it uses\n       * the absolute queue capacity (per partition) instead of the max and is\n       * modified by the userlimit and the userlimit factor as is the userlimit\n       */\n      float effectiveUserLimit \u003d Math.max(usersManager.getUserLimit() / 100.0f,\n          1.0f / Math.max(getAbstractUsersManager().getNumActiveUsers(), 1));\n\n      Resource queuePartitionResource \u003d Resources\n          .multiplyAndNormalizeUp(resourceCalculator,\n              labelManager.getResourceByLabel(nodePartition,\n                  lastClusterResource),\n              queueCapacities.getAbsoluteCapacity(nodePartition),\n              minimumAllocation);\n\n      Resource userAMLimit \u003d Resources.multiplyAndNormalizeUp(\n          resourceCalculator, queuePartitionResource,\n          queueCapacities.getMaxAMResourcePercentage(nodePartition)\n              * effectiveUserLimit * usersManager.getUserLimitFactor(),\n          minimumAllocation);\n      return Resources.lessThanOrEqual(resourceCalculator, lastClusterResource,\n          userAMLimit, getAMResourceLimitPerPartition(nodePartition)) ?\n          userAMLimit :\n          getAMResourceLimitPerPartition(nodePartition);\n    } finally {\n      readLock.unlock();\n    }\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue.java",
      "extendedDetails": {}
    },
    "2b66d9ec5bdaec7e6b278926fbb6f222c4e3afaa": {
      "type": "Ymultichange(Ymodifierchange,Ybodychange)",
      "commitMessage": "YARN-3140. Improve locks in AbstractCSQueue/LeafQueue/ParentQueue. Contributed by Wangda Tan\n",
      "commitDate": "20/09/16 12:03 AM",
      "commitName": "2b66d9ec5bdaec7e6b278926fbb6f222c4e3afaa",
      "commitAuthor": "Jian He",
      "subchanges": [
        {
          "type": "Ymodifierchange",
          "commitMessage": "YARN-3140. Improve locks in AbstractCSQueue/LeafQueue/ParentQueue. Contributed by Wangda Tan\n",
          "commitDate": "20/09/16 12:03 AM",
          "commitName": "2b66d9ec5bdaec7e6b278926fbb6f222c4e3afaa",
          "commitAuthor": "Jian He",
          "commitDateOld": "16/09/16 10:05 PM",
          "commitNameOld": "4174b9756c8c7877797545c4356b1f40df603ec5",
          "commitAuthorOld": "Naganarasimha",
          "daysBetweenCommits": 3.08,
          "commitsBetweenForRepo": 11,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,25 +1,32 @@\n-  public synchronized Resource getUserAMResourceLimitPerPartition(\n+  public Resource getUserAMResourceLimitPerPartition(\n       String nodePartition) {\n-    /*\n-     * The user am resource limit is based on the same approach as the user\n-     * limit (as it should represent a subset of that). This means that it uses\n-     * the absolute queue capacity (per partition) instead of the max and is\n-     * modified by the userlimit and the userlimit factor as is the userlimit\n-     */\n-    float effectiveUserLimit \u003d Math.max(userLimit / 100.0f,\n-        1.0f / Math.max(getActiveUsersManager().getNumActiveUsers(), 1));\n+    try {\n+      readLock.lock();\n+      /*\n+       * The user am resource limit is based on the same approach as the user\n+       * limit (as it should represent a subset of that). This means that it uses\n+       * the absolute queue capacity (per partition) instead of the max and is\n+       * modified by the userlimit and the userlimit factor as is the userlimit\n+       */\n+      float effectiveUserLimit \u003d Math.max(userLimit / 100.0f,\n+          1.0f / Math.max(getActiveUsersManager().getNumActiveUsers(), 1));\n \n-    Resource queuePartitionResource \u003d Resources.multiplyAndNormalizeUp(\n-        resourceCalculator,\n-        labelManager.getResourceByLabel(nodePartition, lastClusterResource),\n-        queueCapacities.getAbsoluteCapacity(nodePartition), minimumAllocation);\n+      Resource queuePartitionResource \u003d Resources.multiplyAndNormalizeUp(\n+          resourceCalculator,\n+          labelManager.getResourceByLabel(nodePartition, lastClusterResource),\n+          queueCapacities.getAbsoluteCapacity(nodePartition),\n+          minimumAllocation);\n \n-    Resource userAMLimit \u003d Resources.multiplyAndNormalizeUp(resourceCalculator,\n-        queuePartitionResource,\n-        queueCapacities.getMaxAMResourcePercentage(nodePartition)\n-            * effectiveUserLimit * userLimitFactor, minimumAllocation);\n-    return Resources.lessThanOrEqual(resourceCalculator, lastClusterResource,\n-        userAMLimit, getAMResourceLimitPerPartition(nodePartition))\n-        ? userAMLimit\n-        : getAMResourceLimitPerPartition(nodePartition);\n+      Resource userAMLimit \u003d Resources.multiplyAndNormalizeUp(\n+          resourceCalculator, queuePartitionResource,\n+          queueCapacities.getMaxAMResourcePercentage(nodePartition)\n+              * effectiveUserLimit * userLimitFactor, minimumAllocation);\n+      return Resources.lessThanOrEqual(resourceCalculator, lastClusterResource,\n+          userAMLimit, getAMResourceLimitPerPartition(nodePartition)) ?\n+          userAMLimit :\n+          getAMResourceLimitPerPartition(nodePartition);\n+    } finally {\n+      readLock.unlock();\n+    }\n+\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public Resource getUserAMResourceLimitPerPartition(\n      String nodePartition) {\n    try {\n      readLock.lock();\n      /*\n       * The user am resource limit is based on the same approach as the user\n       * limit (as it should represent a subset of that). This means that it uses\n       * the absolute queue capacity (per partition) instead of the max and is\n       * modified by the userlimit and the userlimit factor as is the userlimit\n       */\n      float effectiveUserLimit \u003d Math.max(userLimit / 100.0f,\n          1.0f / Math.max(getActiveUsersManager().getNumActiveUsers(), 1));\n\n      Resource queuePartitionResource \u003d Resources.multiplyAndNormalizeUp(\n          resourceCalculator,\n          labelManager.getResourceByLabel(nodePartition, lastClusterResource),\n          queueCapacities.getAbsoluteCapacity(nodePartition),\n          minimumAllocation);\n\n      Resource userAMLimit \u003d Resources.multiplyAndNormalizeUp(\n          resourceCalculator, queuePartitionResource,\n          queueCapacities.getMaxAMResourcePercentage(nodePartition)\n              * effectiveUserLimit * userLimitFactor, minimumAllocation);\n      return Resources.lessThanOrEqual(resourceCalculator, lastClusterResource,\n          userAMLimit, getAMResourceLimitPerPartition(nodePartition)) ?\n          userAMLimit :\n          getAMResourceLimitPerPartition(nodePartition);\n    } finally {\n      readLock.unlock();\n    }\n\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue.java",
          "extendedDetails": {
            "oldValue": "[public, synchronized]",
            "newValue": "[public]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-3140. Improve locks in AbstractCSQueue/LeafQueue/ParentQueue. Contributed by Wangda Tan\n",
          "commitDate": "20/09/16 12:03 AM",
          "commitName": "2b66d9ec5bdaec7e6b278926fbb6f222c4e3afaa",
          "commitAuthor": "Jian He",
          "commitDateOld": "16/09/16 10:05 PM",
          "commitNameOld": "4174b9756c8c7877797545c4356b1f40df603ec5",
          "commitAuthorOld": "Naganarasimha",
          "daysBetweenCommits": 3.08,
          "commitsBetweenForRepo": 11,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,25 +1,32 @@\n-  public synchronized Resource getUserAMResourceLimitPerPartition(\n+  public Resource getUserAMResourceLimitPerPartition(\n       String nodePartition) {\n-    /*\n-     * The user am resource limit is based on the same approach as the user\n-     * limit (as it should represent a subset of that). This means that it uses\n-     * the absolute queue capacity (per partition) instead of the max and is\n-     * modified by the userlimit and the userlimit factor as is the userlimit\n-     */\n-    float effectiveUserLimit \u003d Math.max(userLimit / 100.0f,\n-        1.0f / Math.max(getActiveUsersManager().getNumActiveUsers(), 1));\n+    try {\n+      readLock.lock();\n+      /*\n+       * The user am resource limit is based on the same approach as the user\n+       * limit (as it should represent a subset of that). This means that it uses\n+       * the absolute queue capacity (per partition) instead of the max and is\n+       * modified by the userlimit and the userlimit factor as is the userlimit\n+       */\n+      float effectiveUserLimit \u003d Math.max(userLimit / 100.0f,\n+          1.0f / Math.max(getActiveUsersManager().getNumActiveUsers(), 1));\n \n-    Resource queuePartitionResource \u003d Resources.multiplyAndNormalizeUp(\n-        resourceCalculator,\n-        labelManager.getResourceByLabel(nodePartition, lastClusterResource),\n-        queueCapacities.getAbsoluteCapacity(nodePartition), minimumAllocation);\n+      Resource queuePartitionResource \u003d Resources.multiplyAndNormalizeUp(\n+          resourceCalculator,\n+          labelManager.getResourceByLabel(nodePartition, lastClusterResource),\n+          queueCapacities.getAbsoluteCapacity(nodePartition),\n+          minimumAllocation);\n \n-    Resource userAMLimit \u003d Resources.multiplyAndNormalizeUp(resourceCalculator,\n-        queuePartitionResource,\n-        queueCapacities.getMaxAMResourcePercentage(nodePartition)\n-            * effectiveUserLimit * userLimitFactor, minimumAllocation);\n-    return Resources.lessThanOrEqual(resourceCalculator, lastClusterResource,\n-        userAMLimit, getAMResourceLimitPerPartition(nodePartition))\n-        ? userAMLimit\n-        : getAMResourceLimitPerPartition(nodePartition);\n+      Resource userAMLimit \u003d Resources.multiplyAndNormalizeUp(\n+          resourceCalculator, queuePartitionResource,\n+          queueCapacities.getMaxAMResourcePercentage(nodePartition)\n+              * effectiveUserLimit * userLimitFactor, minimumAllocation);\n+      return Resources.lessThanOrEqual(resourceCalculator, lastClusterResource,\n+          userAMLimit, getAMResourceLimitPerPartition(nodePartition)) ?\n+          userAMLimit :\n+          getAMResourceLimitPerPartition(nodePartition);\n+    } finally {\n+      readLock.unlock();\n+    }\n+\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public Resource getUserAMResourceLimitPerPartition(\n      String nodePartition) {\n    try {\n      readLock.lock();\n      /*\n       * The user am resource limit is based on the same approach as the user\n       * limit (as it should represent a subset of that). This means that it uses\n       * the absolute queue capacity (per partition) instead of the max and is\n       * modified by the userlimit and the userlimit factor as is the userlimit\n       */\n      float effectiveUserLimit \u003d Math.max(userLimit / 100.0f,\n          1.0f / Math.max(getActiveUsersManager().getNumActiveUsers(), 1));\n\n      Resource queuePartitionResource \u003d Resources.multiplyAndNormalizeUp(\n          resourceCalculator,\n          labelManager.getResourceByLabel(nodePartition, lastClusterResource),\n          queueCapacities.getAbsoluteCapacity(nodePartition),\n          minimumAllocation);\n\n      Resource userAMLimit \u003d Resources.multiplyAndNormalizeUp(\n          resourceCalculator, queuePartitionResource,\n          queueCapacities.getMaxAMResourcePercentage(nodePartition)\n              * effectiveUserLimit * userLimitFactor, minimumAllocation);\n      return Resources.lessThanOrEqual(resourceCalculator, lastClusterResource,\n          userAMLimit, getAMResourceLimitPerPartition(nodePartition)) ?\n          userAMLimit :\n          getAMResourceLimitPerPartition(nodePartition);\n    } finally {\n      readLock.unlock();\n    }\n\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue.java",
          "extendedDetails": {}
        }
      ]
    },
    "b08ecf5c7589b055e93b2907413213f36097724d": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4304. AM max resource configuration per partition to be displayed/updated correctly in UI and in various partition related metrics. (Sunil G via wangda)\n",
      "commitDate": "17/01/16 7:11 PM",
      "commitName": "b08ecf5c7589b055e93b2907413213f36097724d",
      "commitAuthor": "Wangda Tan",
      "commitDateOld": "08/01/16 3:51 PM",
      "commitNameOld": "109e528ef5d8df07443373751266b4417acc981a",
      "commitAuthorOld": "Jian He",
      "daysBetweenCommits": 9.14,
      "commitsBetweenForRepo": 64,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,25 @@\n   public synchronized Resource getUserAMResourceLimitPerPartition(\n       String nodePartition) {\n     /*\n      * The user am resource limit is based on the same approach as the user\n      * limit (as it should represent a subset of that). This means that it uses\n      * the absolute queue capacity (per partition) instead of the max and is\n      * modified by the userlimit and the userlimit factor as is the userlimit\n      */\n     float effectiveUserLimit \u003d Math.max(userLimit / 100.0f,\n         1.0f / Math.max(getActiveUsersManager().getNumActiveUsers(), 1));\n \n     Resource queuePartitionResource \u003d Resources.multiplyAndNormalizeUp(\n         resourceCalculator,\n         labelManager.getResourceByLabel(nodePartition, lastClusterResource),\n         queueCapacities.getAbsoluteCapacity(nodePartition), minimumAllocation);\n \n-    return Resources.multiplyAndNormalizeUp(resourceCalculator,\n+    Resource userAMLimit \u003d Resources.multiplyAndNormalizeUp(resourceCalculator,\n         queuePartitionResource,\n         queueCapacities.getMaxAMResourcePercentage(nodePartition)\n             * effectiveUserLimit * userLimitFactor, minimumAllocation);\n+    return Resources.lessThanOrEqual(resourceCalculator, lastClusterResource,\n+        userAMLimit, getAMResourceLimitPerPartition(nodePartition))\n+        ? userAMLimit\n+        : getAMResourceLimitPerPartition(nodePartition);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized Resource getUserAMResourceLimitPerPartition(\n      String nodePartition) {\n    /*\n     * The user am resource limit is based on the same approach as the user\n     * limit (as it should represent a subset of that). This means that it uses\n     * the absolute queue capacity (per partition) instead of the max and is\n     * modified by the userlimit and the userlimit factor as is the userlimit\n     */\n    float effectiveUserLimit \u003d Math.max(userLimit / 100.0f,\n        1.0f / Math.max(getActiveUsersManager().getNumActiveUsers(), 1));\n\n    Resource queuePartitionResource \u003d Resources.multiplyAndNormalizeUp(\n        resourceCalculator,\n        labelManager.getResourceByLabel(nodePartition, lastClusterResource),\n        queueCapacities.getAbsoluteCapacity(nodePartition), minimumAllocation);\n\n    Resource userAMLimit \u003d Resources.multiplyAndNormalizeUp(resourceCalculator,\n        queuePartitionResource,\n        queueCapacities.getMaxAMResourcePercentage(nodePartition)\n            * effectiveUserLimit * userLimitFactor, minimumAllocation);\n    return Resources.lessThanOrEqual(resourceCalculator, lastClusterResource,\n        userAMLimit, getAMResourceLimitPerPartition(nodePartition))\n        ? userAMLimit\n        : getAMResourceLimitPerPartition(nodePartition);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue.java",
      "extendedDetails": {}
    },
    "56e4f6237ae8b1852e82b186e08db3934f79a9db": {
      "type": "Ymultichange(Yrename,Yparameterchange,Ybodychange)",
      "commitMessage": "YARN-3216. Max-AM-Resource-Percentage should respect node labels. (Sunil G via wangda)\n",
      "commitDate": "26/10/15 4:44 PM",
      "commitName": "56e4f6237ae8b1852e82b186e08db3934f79a9db",
      "commitAuthor": "Wangda Tan",
      "subchanges": [
        {
          "type": "Yrename",
          "commitMessage": "YARN-3216. Max-AM-Resource-Percentage should respect node labels. (Sunil G via wangda)\n",
          "commitDate": "26/10/15 4:44 PM",
          "commitName": "56e4f6237ae8b1852e82b186e08db3934f79a9db",
          "commitAuthor": "Wangda Tan",
          "commitDateOld": "26/10/15 1:07 PM",
          "commitNameOld": "3cc73773eb26f7469c99b25a76814d6fad0be28e",
          "commitAuthorOld": "Wangda Tan",
          "daysBetweenCommits": 0.15,
          "commitsBetweenForRepo": 10,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,28 +1,21 @@\n-  public synchronized Resource getAMResourceLimit() {\n-     /* \n-      * The limit to the amount of resources which can be consumed by\n-      * application masters for applications running in the queue\n-      * is calculated by taking the greater of the max resources currently\n-      * available to the queue (see absoluteMaxAvailCapacity) and the absolute\n-      * resources guaranteed for the queue and multiplying it by the am\n-      * resource percent.\n-      *\n-      * This is to allow a queue to grow its (proportional) application \n-      * master resource use up to its max capacity when other queues are \n-      * idle but to scale back down to it\u0027s guaranteed capacity as they \n-      * become busy.\n-      *\n-      */\n-     Resource queueCurrentLimit;\n-     synchronized (queueResourceLimitsInfo) {\n-       queueCurrentLimit \u003d queueResourceLimitsInfo.getQueueCurrentLimit();\n-     }\n-     Resource queueCap \u003d Resources.max(resourceCalculator, lastClusterResource,\n-       absoluteCapacityResource, queueCurrentLimit);\n-    Resource amResouceLimit \u003d\n-        Resources.multiplyAndNormalizeUp(resourceCalculator, queueCap,\n-            maxAMResourcePerQueuePercent, minimumAllocation);\n+  public synchronized Resource getUserAMResourceLimitPerPartition(\n+      String nodePartition) {\n+    /*\n+     * The user am resource limit is based on the same approach as the user\n+     * limit (as it should represent a subset of that). This means that it uses\n+     * the absolute queue capacity (per partition) instead of the max and is\n+     * modified by the userlimit and the userlimit factor as is the userlimit\n+     */\n+    float effectiveUserLimit \u003d Math.max(userLimit / 100.0f,\n+        1.0f / Math.max(getActiveUsersManager().getNumActiveUsers(), 1));\n \n-    metrics.setAMResouceLimit(amResouceLimit);\n-    return amResouceLimit;\n+    Resource queuePartitionResource \u003d Resources.multiplyAndNormalizeUp(\n+        resourceCalculator,\n+        labelManager.getResourceByLabel(nodePartition, lastClusterResource),\n+        queueCapacities.getAbsoluteCapacity(nodePartition), minimumAllocation);\n+\n+    return Resources.multiplyAndNormalizeUp(resourceCalculator,\n+        queuePartitionResource,\n+        queueCapacities.getMaxAMResourcePercentage(nodePartition)\n+            * effectiveUserLimit * userLimitFactor, minimumAllocation);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public synchronized Resource getUserAMResourceLimitPerPartition(\n      String nodePartition) {\n    /*\n     * The user am resource limit is based on the same approach as the user\n     * limit (as it should represent a subset of that). This means that it uses\n     * the absolute queue capacity (per partition) instead of the max and is\n     * modified by the userlimit and the userlimit factor as is the userlimit\n     */\n    float effectiveUserLimit \u003d Math.max(userLimit / 100.0f,\n        1.0f / Math.max(getActiveUsersManager().getNumActiveUsers(), 1));\n\n    Resource queuePartitionResource \u003d Resources.multiplyAndNormalizeUp(\n        resourceCalculator,\n        labelManager.getResourceByLabel(nodePartition, lastClusterResource),\n        queueCapacities.getAbsoluteCapacity(nodePartition), minimumAllocation);\n\n    return Resources.multiplyAndNormalizeUp(resourceCalculator,\n        queuePartitionResource,\n        queueCapacities.getMaxAMResourcePercentage(nodePartition)\n            * effectiveUserLimit * userLimitFactor, minimumAllocation);\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue.java",
          "extendedDetails": {
            "oldValue": "getAMResourceLimit",
            "newValue": "getUserAMResourceLimitPerPartition"
          }
        },
        {
          "type": "Yparameterchange",
          "commitMessage": "YARN-3216. Max-AM-Resource-Percentage should respect node labels. (Sunil G via wangda)\n",
          "commitDate": "26/10/15 4:44 PM",
          "commitName": "56e4f6237ae8b1852e82b186e08db3934f79a9db",
          "commitAuthor": "Wangda Tan",
          "commitDateOld": "26/10/15 1:07 PM",
          "commitNameOld": "3cc73773eb26f7469c99b25a76814d6fad0be28e",
          "commitAuthorOld": "Wangda Tan",
          "daysBetweenCommits": 0.15,
          "commitsBetweenForRepo": 10,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,28 +1,21 @@\n-  public synchronized Resource getAMResourceLimit() {\n-     /* \n-      * The limit to the amount of resources which can be consumed by\n-      * application masters for applications running in the queue\n-      * is calculated by taking the greater of the max resources currently\n-      * available to the queue (see absoluteMaxAvailCapacity) and the absolute\n-      * resources guaranteed for the queue and multiplying it by the am\n-      * resource percent.\n-      *\n-      * This is to allow a queue to grow its (proportional) application \n-      * master resource use up to its max capacity when other queues are \n-      * idle but to scale back down to it\u0027s guaranteed capacity as they \n-      * become busy.\n-      *\n-      */\n-     Resource queueCurrentLimit;\n-     synchronized (queueResourceLimitsInfo) {\n-       queueCurrentLimit \u003d queueResourceLimitsInfo.getQueueCurrentLimit();\n-     }\n-     Resource queueCap \u003d Resources.max(resourceCalculator, lastClusterResource,\n-       absoluteCapacityResource, queueCurrentLimit);\n-    Resource amResouceLimit \u003d\n-        Resources.multiplyAndNormalizeUp(resourceCalculator, queueCap,\n-            maxAMResourcePerQueuePercent, minimumAllocation);\n+  public synchronized Resource getUserAMResourceLimitPerPartition(\n+      String nodePartition) {\n+    /*\n+     * The user am resource limit is based on the same approach as the user\n+     * limit (as it should represent a subset of that). This means that it uses\n+     * the absolute queue capacity (per partition) instead of the max and is\n+     * modified by the userlimit and the userlimit factor as is the userlimit\n+     */\n+    float effectiveUserLimit \u003d Math.max(userLimit / 100.0f,\n+        1.0f / Math.max(getActiveUsersManager().getNumActiveUsers(), 1));\n \n-    metrics.setAMResouceLimit(amResouceLimit);\n-    return amResouceLimit;\n+    Resource queuePartitionResource \u003d Resources.multiplyAndNormalizeUp(\n+        resourceCalculator,\n+        labelManager.getResourceByLabel(nodePartition, lastClusterResource),\n+        queueCapacities.getAbsoluteCapacity(nodePartition), minimumAllocation);\n+\n+    return Resources.multiplyAndNormalizeUp(resourceCalculator,\n+        queuePartitionResource,\n+        queueCapacities.getMaxAMResourcePercentage(nodePartition)\n+            * effectiveUserLimit * userLimitFactor, minimumAllocation);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public synchronized Resource getUserAMResourceLimitPerPartition(\n      String nodePartition) {\n    /*\n     * The user am resource limit is based on the same approach as the user\n     * limit (as it should represent a subset of that). This means that it uses\n     * the absolute queue capacity (per partition) instead of the max and is\n     * modified by the userlimit and the userlimit factor as is the userlimit\n     */\n    float effectiveUserLimit \u003d Math.max(userLimit / 100.0f,\n        1.0f / Math.max(getActiveUsersManager().getNumActiveUsers(), 1));\n\n    Resource queuePartitionResource \u003d Resources.multiplyAndNormalizeUp(\n        resourceCalculator,\n        labelManager.getResourceByLabel(nodePartition, lastClusterResource),\n        queueCapacities.getAbsoluteCapacity(nodePartition), minimumAllocation);\n\n    return Resources.multiplyAndNormalizeUp(resourceCalculator,\n        queuePartitionResource,\n        queueCapacities.getMaxAMResourcePercentage(nodePartition)\n            * effectiveUserLimit * userLimitFactor, minimumAllocation);\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue.java",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[nodePartition-String]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-3216. Max-AM-Resource-Percentage should respect node labels. (Sunil G via wangda)\n",
          "commitDate": "26/10/15 4:44 PM",
          "commitName": "56e4f6237ae8b1852e82b186e08db3934f79a9db",
          "commitAuthor": "Wangda Tan",
          "commitDateOld": "26/10/15 1:07 PM",
          "commitNameOld": "3cc73773eb26f7469c99b25a76814d6fad0be28e",
          "commitAuthorOld": "Wangda Tan",
          "daysBetweenCommits": 0.15,
          "commitsBetweenForRepo": 10,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,28 +1,21 @@\n-  public synchronized Resource getAMResourceLimit() {\n-     /* \n-      * The limit to the amount of resources which can be consumed by\n-      * application masters for applications running in the queue\n-      * is calculated by taking the greater of the max resources currently\n-      * available to the queue (see absoluteMaxAvailCapacity) and the absolute\n-      * resources guaranteed for the queue and multiplying it by the am\n-      * resource percent.\n-      *\n-      * This is to allow a queue to grow its (proportional) application \n-      * master resource use up to its max capacity when other queues are \n-      * idle but to scale back down to it\u0027s guaranteed capacity as they \n-      * become busy.\n-      *\n-      */\n-     Resource queueCurrentLimit;\n-     synchronized (queueResourceLimitsInfo) {\n-       queueCurrentLimit \u003d queueResourceLimitsInfo.getQueueCurrentLimit();\n-     }\n-     Resource queueCap \u003d Resources.max(resourceCalculator, lastClusterResource,\n-       absoluteCapacityResource, queueCurrentLimit);\n-    Resource amResouceLimit \u003d\n-        Resources.multiplyAndNormalizeUp(resourceCalculator, queueCap,\n-            maxAMResourcePerQueuePercent, minimumAllocation);\n+  public synchronized Resource getUserAMResourceLimitPerPartition(\n+      String nodePartition) {\n+    /*\n+     * The user am resource limit is based on the same approach as the user\n+     * limit (as it should represent a subset of that). This means that it uses\n+     * the absolute queue capacity (per partition) instead of the max and is\n+     * modified by the userlimit and the userlimit factor as is the userlimit\n+     */\n+    float effectiveUserLimit \u003d Math.max(userLimit / 100.0f,\n+        1.0f / Math.max(getActiveUsersManager().getNumActiveUsers(), 1));\n \n-    metrics.setAMResouceLimit(amResouceLimit);\n-    return amResouceLimit;\n+    Resource queuePartitionResource \u003d Resources.multiplyAndNormalizeUp(\n+        resourceCalculator,\n+        labelManager.getResourceByLabel(nodePartition, lastClusterResource),\n+        queueCapacities.getAbsoluteCapacity(nodePartition), minimumAllocation);\n+\n+    return Resources.multiplyAndNormalizeUp(resourceCalculator,\n+        queuePartitionResource,\n+        queueCapacities.getMaxAMResourcePercentage(nodePartition)\n+            * effectiveUserLimit * userLimitFactor, minimumAllocation);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public synchronized Resource getUserAMResourceLimitPerPartition(\n      String nodePartition) {\n    /*\n     * The user am resource limit is based on the same approach as the user\n     * limit (as it should represent a subset of that). This means that it uses\n     * the absolute queue capacity (per partition) instead of the max and is\n     * modified by the userlimit and the userlimit factor as is the userlimit\n     */\n    float effectiveUserLimit \u003d Math.max(userLimit / 100.0f,\n        1.0f / Math.max(getActiveUsersManager().getNumActiveUsers(), 1));\n\n    Resource queuePartitionResource \u003d Resources.multiplyAndNormalizeUp(\n        resourceCalculator,\n        labelManager.getResourceByLabel(nodePartition, lastClusterResource),\n        queueCapacities.getAbsoluteCapacity(nodePartition), minimumAllocation);\n\n    return Resources.multiplyAndNormalizeUp(resourceCalculator,\n        queuePartitionResource,\n        queueCapacities.getMaxAMResourcePercentage(nodePartition)\n            * effectiveUserLimit * userLimitFactor, minimumAllocation);\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue.java",
          "extendedDetails": {}
        }
      ]
    },
    "bdd90110e6904b59746812d9a093924a65e72280": {
      "type": "Ybodychange",
      "commitMessage": "YARN-3494. Expose AM resource limit and usage in CS QueueMetrics. Contributed by Rohith Sharmaks\n",
      "commitDate": "21/04/15 8:06 PM",
      "commitName": "bdd90110e6904b59746812d9a093924a65e72280",
      "commitAuthor": "Jian He",
      "commitDateOld": "20/04/15 5:12 PM",
      "commitNameOld": "44872b76fcc0ddfbc7b0a4e54eef50fe8708e0f5",
      "commitAuthorOld": "Wangda Tan",
      "daysBetweenCommits": 1.12,
      "commitsBetweenForRepo": 15,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,26 +1,28 @@\n   public synchronized Resource getAMResourceLimit() {\n      /* \n       * The limit to the amount of resources which can be consumed by\n       * application masters for applications running in the queue\n       * is calculated by taking the greater of the max resources currently\n       * available to the queue (see absoluteMaxAvailCapacity) and the absolute\n       * resources guaranteed for the queue and multiplying it by the am\n       * resource percent.\n       *\n       * This is to allow a queue to grow its (proportional) application \n       * master resource use up to its max capacity when other queues are \n       * idle but to scale back down to it\u0027s guaranteed capacity as they \n       * become busy.\n       *\n       */\n      Resource queueCurrentLimit;\n      synchronized (queueResourceLimitsInfo) {\n        queueCurrentLimit \u003d queueResourceLimitsInfo.getQueueCurrentLimit();\n      }\n      Resource queueCap \u003d Resources.max(resourceCalculator, lastClusterResource,\n        absoluteCapacityResource, queueCurrentLimit);\n-     return Resources.multiplyAndNormalizeUp( \n-          resourceCalculator,\n-          queueCap, \n-          maxAMResourcePerQueuePercent, minimumAllocation);\n+    Resource amResouceLimit \u003d\n+        Resources.multiplyAndNormalizeUp(resourceCalculator, queueCap,\n+            maxAMResourcePerQueuePercent, minimumAllocation);\n+\n+    metrics.setAMResouceLimit(amResouceLimit);\n+    return amResouceLimit;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized Resource getAMResourceLimit() {\n     /* \n      * The limit to the amount of resources which can be consumed by\n      * application masters for applications running in the queue\n      * is calculated by taking the greater of the max resources currently\n      * available to the queue (see absoluteMaxAvailCapacity) and the absolute\n      * resources guaranteed for the queue and multiplying it by the am\n      * resource percent.\n      *\n      * This is to allow a queue to grow its (proportional) application \n      * master resource use up to its max capacity when other queues are \n      * idle but to scale back down to it\u0027s guaranteed capacity as they \n      * become busy.\n      *\n      */\n     Resource queueCurrentLimit;\n     synchronized (queueResourceLimitsInfo) {\n       queueCurrentLimit \u003d queueResourceLimitsInfo.getQueueCurrentLimit();\n     }\n     Resource queueCap \u003d Resources.max(resourceCalculator, lastClusterResource,\n       absoluteCapacityResource, queueCurrentLimit);\n    Resource amResouceLimit \u003d\n        Resources.multiplyAndNormalizeUp(resourceCalculator, queueCap,\n            maxAMResourcePerQueuePercent, minimumAllocation);\n\n    metrics.setAMResouceLimit(amResouceLimit);\n    return amResouceLimit;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue.java",
      "extendedDetails": {}
    },
    "14dd647c556016d351f425ee956ccf800ccb9ce2": {
      "type": "Ybodychange",
      "commitMessage": "YARN-3265. Fixed a deadlock in CapacityScheduler by always passing a queue\u0027s available resource-limit from the parent queue. Contributed by Wangda Tan.\n",
      "commitDate": "02/03/15 5:52 PM",
      "commitName": "14dd647c556016d351f425ee956ccf800ccb9ce2",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "12/02/15 2:58 PM",
      "commitNameOld": "18a594257e052e8f10a03e5594e6cc6901dc56be",
      "commitAuthorOld": "Jian He",
      "daysBetweenCommits": 18.12,
      "commitsBetweenForRepo": 155,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,26 +1,26 @@\n   public synchronized Resource getAMResourceLimit() {\n      /* \n       * The limit to the amount of resources which can be consumed by\n       * application masters for applications running in the queue\n       * is calculated by taking the greater of the max resources currently\n       * available to the queue (see absoluteMaxAvailCapacity) and the absolute\n       * resources guaranteed for the queue and multiplying it by the am\n       * resource percent.\n       *\n       * This is to allow a queue to grow its (proportional) application \n       * master resource use up to its max capacity when other queues are \n       * idle but to scale back down to it\u0027s guaranteed capacity as they \n       * become busy.\n       *\n       */\n-     Resource queueMaxCap;\n-     synchronized (queueHeadroomInfo) {\n-       queueMaxCap \u003d queueHeadroomInfo.getQueueMaxCap();\n+     Resource queueCurrentLimit;\n+     synchronized (queueResourceLimitsInfo) {\n+       queueCurrentLimit \u003d queueResourceLimitsInfo.getQueueCurrentLimit();\n      }\n      Resource queueCap \u003d Resources.max(resourceCalculator, lastClusterResource,\n-       absoluteCapacityResource, queueMaxCap);\n+       absoluteCapacityResource, queueCurrentLimit);\n      return Resources.multiplyAndNormalizeUp( \n           resourceCalculator,\n           queueCap, \n           maxAMResourcePerQueuePercent, minimumAllocation);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized Resource getAMResourceLimit() {\n     /* \n      * The limit to the amount of resources which can be consumed by\n      * application masters for applications running in the queue\n      * is calculated by taking the greater of the max resources currently\n      * available to the queue (see absoluteMaxAvailCapacity) and the absolute\n      * resources guaranteed for the queue and multiplying it by the am\n      * resource percent.\n      *\n      * This is to allow a queue to grow its (proportional) application \n      * master resource use up to its max capacity when other queues are \n      * idle but to scale back down to it\u0027s guaranteed capacity as they \n      * become busy.\n      *\n      */\n     Resource queueCurrentLimit;\n     synchronized (queueResourceLimitsInfo) {\n       queueCurrentLimit \u003d queueResourceLimitsInfo.getQueueCurrentLimit();\n     }\n     Resource queueCap \u003d Resources.max(resourceCalculator, lastClusterResource,\n       absoluteCapacityResource, queueCurrentLimit);\n     return Resources.multiplyAndNormalizeUp( \n          resourceCalculator,\n          queueCap, \n          maxAMResourcePerQueuePercent, minimumAllocation);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue.java",
      "extendedDetails": {}
    },
    "c53420f58364b11fbda1dace7679d45534533382": {
      "type": "Yintroduced",
      "commitMessage": "YARN-2637. Fixed max-am-resource-percent calculation in CapacityScheduler when activating applications. Contributed by Craig Welch\n",
      "commitDate": "13/01/15 5:32 PM",
      "commitName": "c53420f58364b11fbda1dace7679d45534533382",
      "commitAuthor": "Jian He",
      "diff": "@@ -0,0 +1,26 @@\n+  public synchronized Resource getAMResourceLimit() {\n+     /* \n+      * The limit to the amount of resources which can be consumed by\n+      * application masters for applications running in the queue\n+      * is calculated by taking the greater of the max resources currently\n+      * available to the queue (see absoluteMaxAvailCapacity) and the absolute\n+      * resources guaranteed for the queue and multiplying it by the am\n+      * resource percent.\n+      *\n+      * This is to allow a queue to grow its (proportional) application \n+      * master resource use up to its max capacity when other queues are \n+      * idle but to scale back down to it\u0027s guaranteed capacity as they \n+      * become busy.\n+      *\n+      */\n+     Resource queueMaxCap;\n+     synchronized (queueHeadroomInfo) {\n+       queueMaxCap \u003d queueHeadroomInfo.getQueueMaxCap();\n+     }\n+     Resource queueCap \u003d Resources.max(resourceCalculator, lastClusterResource,\n+       absoluteCapacityResource, queueMaxCap);\n+     return Resources.multiplyAndNormalizeUp( \n+          resourceCalculator,\n+          queueCap, \n+          maxAMResourcePerQueuePercent, minimumAllocation);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized Resource getAMResourceLimit() {\n     /* \n      * The limit to the amount of resources which can be consumed by\n      * application masters for applications running in the queue\n      * is calculated by taking the greater of the max resources currently\n      * available to the queue (see absoluteMaxAvailCapacity) and the absolute\n      * resources guaranteed for the queue and multiplying it by the am\n      * resource percent.\n      *\n      * This is to allow a queue to grow its (proportional) application \n      * master resource use up to its max capacity when other queues are \n      * idle but to scale back down to it\u0027s guaranteed capacity as they \n      * become busy.\n      *\n      */\n     Resource queueMaxCap;\n     synchronized (queueHeadroomInfo) {\n       queueMaxCap \u003d queueHeadroomInfo.getQueueMaxCap();\n     }\n     Resource queueCap \u003d Resources.max(resourceCalculator, lastClusterResource,\n       absoluteCapacityResource, queueMaxCap);\n     return Resources.multiplyAndNormalizeUp( \n          resourceCalculator,\n          queueCap, \n          maxAMResourcePerQueuePercent, minimumAllocation);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue.java"
    }
  }
}