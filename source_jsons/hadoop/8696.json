{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSEditLogLoader.java",
  "functionName": "checkLimit",
  "functionId": "checkLimit___amt-long",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogLoader.java",
  "functionStartLine": 1345,
  "functionEndLine": 1351,
  "numCommitsSeen": 198,
  "timeTaken": 3287,
  "changeHistory": [
    "7d1f97b8213795efa26eb53c1914819c74c22502"
  ],
  "changeHistoryShort": {
    "7d1f97b8213795efa26eb53c1914819c74c22502": "Yintroduced"
  },
  "changeHistoryDetails": {
    "7d1f97b8213795efa26eb53c1914819c74c22502": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-3440. More effectively limit stream memory consumption when reading corrupt edit logs. Contributed by Colin Patrick McCabe.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1339978 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/05/12 10:28 PM",
      "commitName": "7d1f97b8213795efa26eb53c1914819c74c22502",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,7 @@\n+    private void checkLimit(long amt) throws IOException {\n+      long extra \u003d (curPos + amt) - limitPos;\n+      if (extra \u003e 0) {\n+        throw new IOException(\"Tried to read \" + amt + \" byte(s) past \" +\n+            \"the limit at offset \" + limitPos);\n+      }\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    private void checkLimit(long amt) throws IOException {\n      long extra \u003d (curPos + amt) - limitPos;\n      if (extra \u003e 0) {\n        throw new IOException(\"Tried to read \" + amt + \" byte(s) past \" +\n            \"the limit at offset \" + limitPos);\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogLoader.java"
    }
  }
}