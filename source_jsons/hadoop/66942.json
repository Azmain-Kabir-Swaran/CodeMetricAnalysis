{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ZombieJob.java",
  "functionName": "getMapTaskAttemptInfoAdjusted",
  "functionId": "getMapTaskAttemptInfoAdjusted___taskNumber-int__taskAttemptNumber-int__locality-int",
  "sourceFilePath": "hadoop-tools/hadoop-rumen/src/main/java/org/apache/hadoop/tools/rumen/ZombieJob.java",
  "functionStartLine": 470,
  "functionEndLine": 516,
  "numCommitsSeen": 10,
  "timeTaken": 4746,
  "changeHistory": [
    "de69d6e81128470dd5d2fd865d4b3a79188f740b",
    "10325d97329c214bb3899c8535df5a366bc86d2f",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "de69d6e81128470dd5d2fd865d4b3a79188f740b": "Ybodychange",
    "10325d97329c214bb3899c8535df5a366bc86d2f": "Yfilerename",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "de69d6e81128470dd5d2fd865d4b3a79188f740b": {
      "type": "Ybodychange",
      "commitMessage": "YARN-6363. Extending SLS: Synthetic Load Generator. (Carlo Curino via wangda)\n",
      "commitDate": "20/04/17 9:54 PM",
      "commitName": "de69d6e81128470dd5d2fd865d4b3a79188f740b",
      "commitAuthor": "Wangda Tan",
      "commitDateOld": "21/03/12 2:42 AM",
      "commitNameOld": "7b3a98cfcd0eb729b1971b3e5607a1d7755fdb07",
      "commitAuthorOld": "Ravi Gummadi",
      "daysBetweenCommits": 1856.8,
      "commitsBetweenForRepo": 12901,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,47 +1,47 @@\n   public TaskAttemptInfo getMapTaskAttemptInfoAdjusted(int taskNumber,\n       int taskAttemptNumber, int locality) {\n     TaskType taskType \u003d TaskType.MAP;\n     LoggedTask loggedTask \u003d getLoggedTask(taskType, taskNumber);\n     if (loggedTask \u003d\u003d null) {\n       // TODO insert parameters\n-      TaskInfo taskInfo \u003d new TaskInfo(0, 0, 0, 0, 0);\n+      TaskInfo taskInfo \u003d new TaskInfo(0, 0, 0, 0, 0, 0);\n       return makeUpTaskAttemptInfo(taskType, taskInfo, taskAttemptNumber,\n           taskNumber, locality);\n     }\n     LoggedTaskAttempt loggedAttempt \u003d getLoggedTaskAttempt(taskType,\n         taskNumber, taskAttemptNumber);\n     if (loggedAttempt \u003d\u003d null) {\n       // Task exists, but attempt is missing.\n       TaskInfo taskInfo \u003d getTaskInfo(loggedTask);\n       return makeUpTaskAttemptInfo(taskType, taskInfo, taskAttemptNumber,\n           taskNumber, locality);\n     } else {\n       // Task and TaskAttempt both exist.\n       if (loggedAttempt.getResult() \u003d\u003d Values.KILLED) {\n         TaskInfo taskInfo \u003d getTaskInfo(loggedTask);\n         return makeUpTaskAttemptInfo(taskType, taskInfo, taskAttemptNumber,\n             taskNumber, locality);\n       } else if (loggedAttempt.getResult() \u003d\u003d Values.FAILED) {\n         /**\n          * FAILED attempt is not affected by locality however, made-up FAILED\n          * attempts ARE affected by locality, since statistics are present for\n          * attempts of different locality.\n          */\n         return getTaskAttemptInfo(loggedTask, loggedAttempt);\n       } else if (loggedAttempt.getResult() \u003d\u003d Values.SUCCESS) {\n         int loggedLocality \u003d getLocality(loggedTask, loggedAttempt);\n         if (locality \u003d\u003d loggedLocality) {\n           return getTaskAttemptInfo(loggedTask, loggedAttempt);\n         } else {\n           // attempt succeeded in trace. It is scheduled in simulation with\n           // a different locality.\n           return scaleInfo(loggedTask, loggedAttempt, locality, loggedLocality,\n               rackLocalOverNodeLocal, rackRemoteOverNodeLocal);\n         }\n       } else {\n         throw new IllegalArgumentException(\n             \"attempt result is not SUCCEEDED, FAILED or KILLED: \"\n                 + loggedAttempt.getResult());\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public TaskAttemptInfo getMapTaskAttemptInfoAdjusted(int taskNumber,\n      int taskAttemptNumber, int locality) {\n    TaskType taskType \u003d TaskType.MAP;\n    LoggedTask loggedTask \u003d getLoggedTask(taskType, taskNumber);\n    if (loggedTask \u003d\u003d null) {\n      // TODO insert parameters\n      TaskInfo taskInfo \u003d new TaskInfo(0, 0, 0, 0, 0, 0);\n      return makeUpTaskAttemptInfo(taskType, taskInfo, taskAttemptNumber,\n          taskNumber, locality);\n    }\n    LoggedTaskAttempt loggedAttempt \u003d getLoggedTaskAttempt(taskType,\n        taskNumber, taskAttemptNumber);\n    if (loggedAttempt \u003d\u003d null) {\n      // Task exists, but attempt is missing.\n      TaskInfo taskInfo \u003d getTaskInfo(loggedTask);\n      return makeUpTaskAttemptInfo(taskType, taskInfo, taskAttemptNumber,\n          taskNumber, locality);\n    } else {\n      // Task and TaskAttempt both exist.\n      if (loggedAttempt.getResult() \u003d\u003d Values.KILLED) {\n        TaskInfo taskInfo \u003d getTaskInfo(loggedTask);\n        return makeUpTaskAttemptInfo(taskType, taskInfo, taskAttemptNumber,\n            taskNumber, locality);\n      } else if (loggedAttempt.getResult() \u003d\u003d Values.FAILED) {\n        /**\n         * FAILED attempt is not affected by locality however, made-up FAILED\n         * attempts ARE affected by locality, since statistics are present for\n         * attempts of different locality.\n         */\n        return getTaskAttemptInfo(loggedTask, loggedAttempt);\n      } else if (loggedAttempt.getResult() \u003d\u003d Values.SUCCESS) {\n        int loggedLocality \u003d getLocality(loggedTask, loggedAttempt);\n        if (locality \u003d\u003d loggedLocality) {\n          return getTaskAttemptInfo(loggedTask, loggedAttempt);\n        } else {\n          // attempt succeeded in trace. It is scheduled in simulation with\n          // a different locality.\n          return scaleInfo(loggedTask, loggedAttempt, locality, loggedLocality,\n              rackLocalOverNodeLocal, rackRemoteOverNodeLocal);\n        }\n      } else {\n        throw new IllegalArgumentException(\n            \"attempt result is not SUCCEEDED, FAILED or KILLED: \"\n                + loggedAttempt.getResult());\n      }\n    }\n  }",
      "path": "hadoop-tools/hadoop-rumen/src/main/java/org/apache/hadoop/tools/rumen/ZombieJob.java",
      "extendedDetails": {}
    },
    "10325d97329c214bb3899c8535df5a366bc86d2f": {
      "type": "Yfilerename",
      "commitMessage": "MAPREDUCE-3582. Move successfully passing MR1 tests to MR2 maven tree.(ahmed via tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1233090 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/01/12 2:10 PM",
      "commitName": "10325d97329c214bb3899c8535df5a366bc86d2f",
      "commitAuthor": "Alejandro Abdelnur",
      "commitDateOld": "18/01/12 10:20 AM",
      "commitNameOld": "8b2f6909ec7df5cffb5ef417f5c9cffdee43e38a",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.16,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public TaskAttemptInfo getMapTaskAttemptInfoAdjusted(int taskNumber,\n      int taskAttemptNumber, int locality) {\n    TaskType taskType \u003d TaskType.MAP;\n    LoggedTask loggedTask \u003d getLoggedTask(taskType, taskNumber);\n    if (loggedTask \u003d\u003d null) {\n      // TODO insert parameters\n      TaskInfo taskInfo \u003d new TaskInfo(0, 0, 0, 0, 0);\n      return makeUpTaskAttemptInfo(taskType, taskInfo, taskAttemptNumber,\n          taskNumber, locality);\n    }\n    LoggedTaskAttempt loggedAttempt \u003d getLoggedTaskAttempt(taskType,\n        taskNumber, taskAttemptNumber);\n    if (loggedAttempt \u003d\u003d null) {\n      // Task exists, but attempt is missing.\n      TaskInfo taskInfo \u003d getTaskInfo(loggedTask);\n      return makeUpTaskAttemptInfo(taskType, taskInfo, taskAttemptNumber,\n          taskNumber, locality);\n    } else {\n      // Task and TaskAttempt both exist.\n      if (loggedAttempt.getResult() \u003d\u003d Values.KILLED) {\n        TaskInfo taskInfo \u003d getTaskInfo(loggedTask);\n        return makeUpTaskAttemptInfo(taskType, taskInfo, taskAttemptNumber,\n            taskNumber, locality);\n      } else if (loggedAttempt.getResult() \u003d\u003d Values.FAILED) {\n        /**\n         * FAILED attempt is not affected by locality however, made-up FAILED\n         * attempts ARE affected by locality, since statistics are present for\n         * attempts of different locality.\n         */\n        return getTaskAttemptInfo(loggedTask, loggedAttempt);\n      } else if (loggedAttempt.getResult() \u003d\u003d Values.SUCCESS) {\n        int loggedLocality \u003d getLocality(loggedTask, loggedAttempt);\n        if (locality \u003d\u003d loggedLocality) {\n          return getTaskAttemptInfo(loggedTask, loggedAttempt);\n        } else {\n          // attempt succeeded in trace. It is scheduled in simulation with\n          // a different locality.\n          return scaleInfo(loggedTask, loggedAttempt, locality, loggedLocality,\n              rackLocalOverNodeLocal, rackRemoteOverNodeLocal);\n        }\n      } else {\n        throw new IllegalArgumentException(\n            \"attempt result is not SUCCEEDED, FAILED or KILLED: \"\n                + loggedAttempt.getResult());\n      }\n    }\n  }",
      "path": "hadoop-tools/hadoop-rumen/src/main/java/org/apache/hadoop/tools/rumen/ZombieJob.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce-project/src/tools/org/apache/hadoop/tools/rumen/ZombieJob.java",
        "newPath": "hadoop-tools/hadoop-rumen/src/main/java/org/apache/hadoop/tools/rumen/ZombieJob.java"
      }
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public TaskAttemptInfo getMapTaskAttemptInfoAdjusted(int taskNumber,\n      int taskAttemptNumber, int locality) {\n    TaskType taskType \u003d TaskType.MAP;\n    LoggedTask loggedTask \u003d getLoggedTask(taskType, taskNumber);\n    if (loggedTask \u003d\u003d null) {\n      // TODO insert parameters\n      TaskInfo taskInfo \u003d new TaskInfo(0, 0, 0, 0, 0);\n      return makeUpTaskAttemptInfo(taskType, taskInfo, taskAttemptNumber,\n          taskNumber, locality);\n    }\n    LoggedTaskAttempt loggedAttempt \u003d getLoggedTaskAttempt(taskType,\n        taskNumber, taskAttemptNumber);\n    if (loggedAttempt \u003d\u003d null) {\n      // Task exists, but attempt is missing.\n      TaskInfo taskInfo \u003d getTaskInfo(loggedTask);\n      return makeUpTaskAttemptInfo(taskType, taskInfo, taskAttemptNumber,\n          taskNumber, locality);\n    } else {\n      // Task and TaskAttempt both exist.\n      if (loggedAttempt.getResult() \u003d\u003d Values.KILLED) {\n        TaskInfo taskInfo \u003d getTaskInfo(loggedTask);\n        return makeUpTaskAttemptInfo(taskType, taskInfo, taskAttemptNumber,\n            taskNumber, locality);\n      } else if (loggedAttempt.getResult() \u003d\u003d Values.FAILED) {\n        /**\n         * FAILED attempt is not affected by locality however, made-up FAILED\n         * attempts ARE affected by locality, since statistics are present for\n         * attempts of different locality.\n         */\n        return getTaskAttemptInfo(loggedTask, loggedAttempt);\n      } else if (loggedAttempt.getResult() \u003d\u003d Values.SUCCESS) {\n        int loggedLocality \u003d getLocality(loggedTask, loggedAttempt);\n        if (locality \u003d\u003d loggedLocality) {\n          return getTaskAttemptInfo(loggedTask, loggedAttempt);\n        } else {\n          // attempt succeeded in trace. It is scheduled in simulation with\n          // a different locality.\n          return scaleInfo(loggedTask, loggedAttempt, locality, loggedLocality,\n              rackLocalOverNodeLocal, rackRemoteOverNodeLocal);\n        }\n      } else {\n        throw new IllegalArgumentException(\n            \"attempt result is not SUCCEEDED, FAILED or KILLED: \"\n                + loggedAttempt.getResult());\n      }\n    }\n  }",
      "path": "hadoop-mapreduce-project/src/tools/org/apache/hadoop/tools/rumen/ZombieJob.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/src/tools/org/apache/hadoop/tools/rumen/ZombieJob.java",
        "newPath": "hadoop-mapreduce-project/src/tools/org/apache/hadoop/tools/rumen/ZombieJob.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yfilerename",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "17/08/11 8:02 PM",
      "commitNameOld": "dd86860633d2ed64705b669a75bf318442ed6225",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 0.34,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public TaskAttemptInfo getMapTaskAttemptInfoAdjusted(int taskNumber,\n      int taskAttemptNumber, int locality) {\n    TaskType taskType \u003d TaskType.MAP;\n    LoggedTask loggedTask \u003d getLoggedTask(taskType, taskNumber);\n    if (loggedTask \u003d\u003d null) {\n      // TODO insert parameters\n      TaskInfo taskInfo \u003d new TaskInfo(0, 0, 0, 0, 0);\n      return makeUpTaskAttemptInfo(taskType, taskInfo, taskAttemptNumber,\n          taskNumber, locality);\n    }\n    LoggedTaskAttempt loggedAttempt \u003d getLoggedTaskAttempt(taskType,\n        taskNumber, taskAttemptNumber);\n    if (loggedAttempt \u003d\u003d null) {\n      // Task exists, but attempt is missing.\n      TaskInfo taskInfo \u003d getTaskInfo(loggedTask);\n      return makeUpTaskAttemptInfo(taskType, taskInfo, taskAttemptNumber,\n          taskNumber, locality);\n    } else {\n      // Task and TaskAttempt both exist.\n      if (loggedAttempt.getResult() \u003d\u003d Values.KILLED) {\n        TaskInfo taskInfo \u003d getTaskInfo(loggedTask);\n        return makeUpTaskAttemptInfo(taskType, taskInfo, taskAttemptNumber,\n            taskNumber, locality);\n      } else if (loggedAttempt.getResult() \u003d\u003d Values.FAILED) {\n        /**\n         * FAILED attempt is not affected by locality however, made-up FAILED\n         * attempts ARE affected by locality, since statistics are present for\n         * attempts of different locality.\n         */\n        return getTaskAttemptInfo(loggedTask, loggedAttempt);\n      } else if (loggedAttempt.getResult() \u003d\u003d Values.SUCCESS) {\n        int loggedLocality \u003d getLocality(loggedTask, loggedAttempt);\n        if (locality \u003d\u003d loggedLocality) {\n          return getTaskAttemptInfo(loggedTask, loggedAttempt);\n        } else {\n          // attempt succeeded in trace. It is scheduled in simulation with\n          // a different locality.\n          return scaleInfo(loggedTask, loggedAttempt, locality, loggedLocality,\n              rackLocalOverNodeLocal, rackRemoteOverNodeLocal);\n        }\n      } else {\n        throw new IllegalArgumentException(\n            \"attempt result is not SUCCEEDED, FAILED or KILLED: \"\n                + loggedAttempt.getResult());\n      }\n    }\n  }",
      "path": "hadoop-mapreduce/src/tools/org/apache/hadoop/tools/rumen/ZombieJob.java",
      "extendedDetails": {
        "oldPath": "mapreduce/src/tools/org/apache/hadoop/tools/rumen/ZombieJob.java",
        "newPath": "hadoop-mapreduce/src/tools/org/apache/hadoop/tools/rumen/ZombieJob.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,47 @@\n+  public TaskAttemptInfo getMapTaskAttemptInfoAdjusted(int taskNumber,\n+      int taskAttemptNumber, int locality) {\n+    TaskType taskType \u003d TaskType.MAP;\n+    LoggedTask loggedTask \u003d getLoggedTask(taskType, taskNumber);\n+    if (loggedTask \u003d\u003d null) {\n+      // TODO insert parameters\n+      TaskInfo taskInfo \u003d new TaskInfo(0, 0, 0, 0, 0);\n+      return makeUpTaskAttemptInfo(taskType, taskInfo, taskAttemptNumber,\n+          taskNumber, locality);\n+    }\n+    LoggedTaskAttempt loggedAttempt \u003d getLoggedTaskAttempt(taskType,\n+        taskNumber, taskAttemptNumber);\n+    if (loggedAttempt \u003d\u003d null) {\n+      // Task exists, but attempt is missing.\n+      TaskInfo taskInfo \u003d getTaskInfo(loggedTask);\n+      return makeUpTaskAttemptInfo(taskType, taskInfo, taskAttemptNumber,\n+          taskNumber, locality);\n+    } else {\n+      // Task and TaskAttempt both exist.\n+      if (loggedAttempt.getResult() \u003d\u003d Values.KILLED) {\n+        TaskInfo taskInfo \u003d getTaskInfo(loggedTask);\n+        return makeUpTaskAttemptInfo(taskType, taskInfo, taskAttemptNumber,\n+            taskNumber, locality);\n+      } else if (loggedAttempt.getResult() \u003d\u003d Values.FAILED) {\n+        /**\n+         * FAILED attempt is not affected by locality however, made-up FAILED\n+         * attempts ARE affected by locality, since statistics are present for\n+         * attempts of different locality.\n+         */\n+        return getTaskAttemptInfo(loggedTask, loggedAttempt);\n+      } else if (loggedAttempt.getResult() \u003d\u003d Values.SUCCESS) {\n+        int loggedLocality \u003d getLocality(loggedTask, loggedAttempt);\n+        if (locality \u003d\u003d loggedLocality) {\n+          return getTaskAttemptInfo(loggedTask, loggedAttempt);\n+        } else {\n+          // attempt succeeded in trace. It is scheduled in simulation with\n+          // a different locality.\n+          return scaleInfo(loggedTask, loggedAttempt, locality, loggedLocality,\n+              rackLocalOverNodeLocal, rackRemoteOverNodeLocal);\n+        }\n+      } else {\n+        throw new IllegalArgumentException(\n+            \"attempt result is not SUCCEEDED, FAILED or KILLED: \"\n+                + loggedAttempt.getResult());\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public TaskAttemptInfo getMapTaskAttemptInfoAdjusted(int taskNumber,\n      int taskAttemptNumber, int locality) {\n    TaskType taskType \u003d TaskType.MAP;\n    LoggedTask loggedTask \u003d getLoggedTask(taskType, taskNumber);\n    if (loggedTask \u003d\u003d null) {\n      // TODO insert parameters\n      TaskInfo taskInfo \u003d new TaskInfo(0, 0, 0, 0, 0);\n      return makeUpTaskAttemptInfo(taskType, taskInfo, taskAttemptNumber,\n          taskNumber, locality);\n    }\n    LoggedTaskAttempt loggedAttempt \u003d getLoggedTaskAttempt(taskType,\n        taskNumber, taskAttemptNumber);\n    if (loggedAttempt \u003d\u003d null) {\n      // Task exists, but attempt is missing.\n      TaskInfo taskInfo \u003d getTaskInfo(loggedTask);\n      return makeUpTaskAttemptInfo(taskType, taskInfo, taskAttemptNumber,\n          taskNumber, locality);\n    } else {\n      // Task and TaskAttempt both exist.\n      if (loggedAttempt.getResult() \u003d\u003d Values.KILLED) {\n        TaskInfo taskInfo \u003d getTaskInfo(loggedTask);\n        return makeUpTaskAttemptInfo(taskType, taskInfo, taskAttemptNumber,\n            taskNumber, locality);\n      } else if (loggedAttempt.getResult() \u003d\u003d Values.FAILED) {\n        /**\n         * FAILED attempt is not affected by locality however, made-up FAILED\n         * attempts ARE affected by locality, since statistics are present for\n         * attempts of different locality.\n         */\n        return getTaskAttemptInfo(loggedTask, loggedAttempt);\n      } else if (loggedAttempt.getResult() \u003d\u003d Values.SUCCESS) {\n        int loggedLocality \u003d getLocality(loggedTask, loggedAttempt);\n        if (locality \u003d\u003d loggedLocality) {\n          return getTaskAttemptInfo(loggedTask, loggedAttempt);\n        } else {\n          // attempt succeeded in trace. It is scheduled in simulation with\n          // a different locality.\n          return scaleInfo(loggedTask, loggedAttempt, locality, loggedLocality,\n              rackLocalOverNodeLocal, rackRemoteOverNodeLocal);\n        }\n      } else {\n        throw new IllegalArgumentException(\n            \"attempt result is not SUCCEEDED, FAILED or KILLED: \"\n                + loggedAttempt.getResult());\n      }\n    }\n  }",
      "path": "mapreduce/src/tools/org/apache/hadoop/tools/rumen/ZombieJob.java"
    }
  }
}