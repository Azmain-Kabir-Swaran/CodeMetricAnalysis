{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FsDatasetImpl.java",
  "functionName": "createRbw",
  "functionId": "createRbw___storageType-StorageType__storageId-String__b-ExtendedBlock__allowLazyPersist-boolean",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
  "functionStartLine": 1428,
  "functionEndLine": 1498,
  "numCommitsSeen": 352,
  "timeTaken": 10224,
  "changeHistory": [
    "d3b595157256e198c4340d555e14ad6144f2eaa1",
    "d7c136b9ed6d99e1b03f5b89723b3a20df359ba8",
    "582cb10ec74ed5666946a3769002ceb80ba660cb",
    "a3954ccab148bddc290cb96528e63ff19799bcc9",
    "86c9862bec0248d671e657aa56094a2919b8ac14",
    "8c0638471f8f1dd47667b2d6727d4d2d54e4b48c",
    "c7d022b66f0c5baafbb7000a435c1d6e39906efe",
    "e453989a5722e653bd97e3e54f9bbdffc9454fba",
    "b7f4a3156c0f5c600816c469637237ba6c9b330c",
    "5e8b6973527e5f714652641ed95e8a4509e18cfa"
  ],
  "changeHistoryShort": {
    "d3b595157256e198c4340d555e14ad6144f2eaa1": "Ybodychange",
    "d7c136b9ed6d99e1b03f5b89723b3a20df359ba8": "Ybodychange",
    "582cb10ec74ed5666946a3769002ceb80ba660cb": "Ybodychange",
    "a3954ccab148bddc290cb96528e63ff19799bcc9": "Ymultichange(Yparameterchange,Ybodychange)",
    "86c9862bec0248d671e657aa56094a2919b8ac14": "Ybodychange",
    "8c0638471f8f1dd47667b2d6727d4d2d54e4b48c": "Ymultichange(Ymodifierchange,Ybodychange)",
    "c7d022b66f0c5baafbb7000a435c1d6e39906efe": "Ybodychange",
    "e453989a5722e653bd97e3e54f9bbdffc9454fba": "Ybodychange",
    "b7f4a3156c0f5c600816c469637237ba6c9b330c": "Ymultichange(Yreturntypechange,Ybodychange)",
    "5e8b6973527e5f714652641ed95e8a4509e18cfa": "Ybodychange"
  },
  "changeHistoryDetails": {
    "d3b595157256e198c4340d555e14ad6144f2eaa1": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-15242. Add metrics for operations hold lock times of FsDatasetImpl. Contributed by Xiaoqiao He.\n\nSigned-off-by: Wei-Chiu Chuang \u003cweichiu@apache.org\u003e\nReviewed-by: Inigo Goiri \u003cinigoiri@apache.org\u003e\n",
      "commitDate": "01/04/20 4:36 PM",
      "commitName": "d3b595157256e198c4340d555e14ad6144f2eaa1",
      "commitAuthor": "He Xiaoqiao",
      "commitDateOld": "11/02/20 8:00 AM",
      "commitNameOld": "d7c136b9ed6d99e1b03f5b89723b3a20df359ba8",
      "commitAuthorOld": "Stephen O\u0027Donnell",
      "daysBetweenCommits": 50.32,
      "commitsBetweenForRepo": 174,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,65 +1,71 @@\n   public ReplicaHandler createRbw(\n       StorageType storageType, String storageId, ExtendedBlock b,\n       boolean allowLazyPersist) throws IOException {\n+    long startTimeMs \u003d Time.monotonicNow();\n     try (AutoCloseableLock lock \u003d datasetWriteLock.acquire()) {\n       ReplicaInfo replicaInfo \u003d volumeMap.get(b.getBlockPoolId(),\n           b.getBlockId());\n       if (replicaInfo !\u003d null) {\n         throw new ReplicaAlreadyExistsException(\"Block \" + b +\n             \" already exists in state \" + replicaInfo.getState() +\n             \" and thus cannot be created.\");\n       }\n       // create a new block\n       FsVolumeReference ref \u003d null;\n \n       // Use ramdisk only if block size is a multiple of OS page size.\n       // This simplifies reservation for partially used replicas\n       // significantly.\n       if (allowLazyPersist \u0026\u0026\n           lazyWriter !\u003d null \u0026\u0026\n           b.getNumBytes() % cacheManager.getOsPageSize() \u003d\u003d 0 \u0026\u0026\n           reserveLockedMemory(b.getNumBytes())) {\n         try {\n           // First try to place the block on a transient volume.\n           ref \u003d volumes.getNextTransientVolume(b.getNumBytes());\n           datanode.getMetrics().incrRamDiskBlocksWrite();\n         } catch (DiskOutOfSpaceException de) {\n           // Ignore the exception since we just fall back to persistent storage.\n           LOG.warn(\"Insufficient space for placing the block on a transient \"\n               + \"volume, fall back to persistent storage: \"\n               + de.getMessage());\n         } finally {\n           if (ref \u003d\u003d null) {\n             cacheManager.release(b.getNumBytes());\n           }\n         }\n       }\n \n       if (ref \u003d\u003d null) {\n         ref \u003d volumes.getNextVolume(storageType, storageId, b.getNumBytes());\n       }\n \n       FsVolumeImpl v \u003d (FsVolumeImpl) ref.getVolume();\n       // create an rbw file to hold block in the designated volume\n \n       if (allowLazyPersist \u0026\u0026 !v.isTransientStorage()) {\n         datanode.getMetrics().incrRamDiskBlocksWriteFallback();\n       }\n \n       ReplicaInPipeline newReplicaInfo;\n       try {\n         newReplicaInfo \u003d v.createRbw(b);\n         if (newReplicaInfo.getReplicaInfo().getState() !\u003d ReplicaState.RBW) {\n           throw new IOException(\"CreateRBW returned a replica of state \"\n               + newReplicaInfo.getReplicaInfo().getState()\n               + \" for block \" + b.getBlockId());\n         }\n       } catch (IOException e) {\n         IOUtils.cleanup(null, ref);\n         throw e;\n       }\n \n       volumeMap.add(b.getBlockPoolId(), newReplicaInfo.getReplicaInfo());\n       return new ReplicaHandler(newReplicaInfo, ref);\n+    } finally {\n+      if (dataNodeMetrics !\u003d null) {\n+        long createRbwMs \u003d Time.monotonicNow() - startTimeMs;\n+        dataNodeMetrics.addCreateRbwOp(createRbwMs);\n+      }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ReplicaHandler createRbw(\n      StorageType storageType, String storageId, ExtendedBlock b,\n      boolean allowLazyPersist) throws IOException {\n    long startTimeMs \u003d Time.monotonicNow();\n    try (AutoCloseableLock lock \u003d datasetWriteLock.acquire()) {\n      ReplicaInfo replicaInfo \u003d volumeMap.get(b.getBlockPoolId(),\n          b.getBlockId());\n      if (replicaInfo !\u003d null) {\n        throw new ReplicaAlreadyExistsException(\"Block \" + b +\n            \" already exists in state \" + replicaInfo.getState() +\n            \" and thus cannot be created.\");\n      }\n      // create a new block\n      FsVolumeReference ref \u003d null;\n\n      // Use ramdisk only if block size is a multiple of OS page size.\n      // This simplifies reservation for partially used replicas\n      // significantly.\n      if (allowLazyPersist \u0026\u0026\n          lazyWriter !\u003d null \u0026\u0026\n          b.getNumBytes() % cacheManager.getOsPageSize() \u003d\u003d 0 \u0026\u0026\n          reserveLockedMemory(b.getNumBytes())) {\n        try {\n          // First try to place the block on a transient volume.\n          ref \u003d volumes.getNextTransientVolume(b.getNumBytes());\n          datanode.getMetrics().incrRamDiskBlocksWrite();\n        } catch (DiskOutOfSpaceException de) {\n          // Ignore the exception since we just fall back to persistent storage.\n          LOG.warn(\"Insufficient space for placing the block on a transient \"\n              + \"volume, fall back to persistent storage: \"\n              + de.getMessage());\n        } finally {\n          if (ref \u003d\u003d null) {\n            cacheManager.release(b.getNumBytes());\n          }\n        }\n      }\n\n      if (ref \u003d\u003d null) {\n        ref \u003d volumes.getNextVolume(storageType, storageId, b.getNumBytes());\n      }\n\n      FsVolumeImpl v \u003d (FsVolumeImpl) ref.getVolume();\n      // create an rbw file to hold block in the designated volume\n\n      if (allowLazyPersist \u0026\u0026 !v.isTransientStorage()) {\n        datanode.getMetrics().incrRamDiskBlocksWriteFallback();\n      }\n\n      ReplicaInPipeline newReplicaInfo;\n      try {\n        newReplicaInfo \u003d v.createRbw(b);\n        if (newReplicaInfo.getReplicaInfo().getState() !\u003d ReplicaState.RBW) {\n          throw new IOException(\"CreateRBW returned a replica of state \"\n              + newReplicaInfo.getReplicaInfo().getState()\n              + \" for block \" + b.getBlockId());\n        }\n      } catch (IOException e) {\n        IOUtils.cleanup(null, ref);\n        throw e;\n      }\n\n      volumeMap.add(b.getBlockPoolId(), newReplicaInfo.getReplicaInfo());\n      return new ReplicaHandler(newReplicaInfo, ref);\n    } finally {\n      if (dataNodeMetrics !\u003d null) {\n        long createRbwMs \u003d Time.monotonicNow() - startTimeMs;\n        dataNodeMetrics.addCreateRbwOp(createRbwMs);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "d7c136b9ed6d99e1b03f5b89723b3a20df359ba8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-15150. Introduce read write lock to Datanode. Contributed Stephen O\u0027Donnell.\n\nSigned-off-by: Wei-Chiu Chuang \u003cweichiu@apache.org\u003e\n",
      "commitDate": "11/02/20 8:00 AM",
      "commitName": "d7c136b9ed6d99e1b03f5b89723b3a20df359ba8",
      "commitAuthor": "Stephen O\u0027Donnell",
      "commitDateOld": "28/01/20 10:10 AM",
      "commitNameOld": "1839c467f60cbb8592d446694ec3d7710cda5142",
      "commitAuthorOld": "Inigo Goiri",
      "daysBetweenCommits": 13.91,
      "commitsBetweenForRepo": 33,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,65 +1,65 @@\n   public ReplicaHandler createRbw(\n       StorageType storageType, String storageId, ExtendedBlock b,\n       boolean allowLazyPersist) throws IOException {\n-    try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n+    try (AutoCloseableLock lock \u003d datasetWriteLock.acquire()) {\n       ReplicaInfo replicaInfo \u003d volumeMap.get(b.getBlockPoolId(),\n           b.getBlockId());\n       if (replicaInfo !\u003d null) {\n         throw new ReplicaAlreadyExistsException(\"Block \" + b +\n             \" already exists in state \" + replicaInfo.getState() +\n             \" and thus cannot be created.\");\n       }\n       // create a new block\n       FsVolumeReference ref \u003d null;\n \n       // Use ramdisk only if block size is a multiple of OS page size.\n       // This simplifies reservation for partially used replicas\n       // significantly.\n       if (allowLazyPersist \u0026\u0026\n           lazyWriter !\u003d null \u0026\u0026\n           b.getNumBytes() % cacheManager.getOsPageSize() \u003d\u003d 0 \u0026\u0026\n           reserveLockedMemory(b.getNumBytes())) {\n         try {\n           // First try to place the block on a transient volume.\n           ref \u003d volumes.getNextTransientVolume(b.getNumBytes());\n           datanode.getMetrics().incrRamDiskBlocksWrite();\n         } catch (DiskOutOfSpaceException de) {\n           // Ignore the exception since we just fall back to persistent storage.\n           LOG.warn(\"Insufficient space for placing the block on a transient \"\n               + \"volume, fall back to persistent storage: \"\n               + de.getMessage());\n         } finally {\n           if (ref \u003d\u003d null) {\n             cacheManager.release(b.getNumBytes());\n           }\n         }\n       }\n \n       if (ref \u003d\u003d null) {\n         ref \u003d volumes.getNextVolume(storageType, storageId, b.getNumBytes());\n       }\n \n       FsVolumeImpl v \u003d (FsVolumeImpl) ref.getVolume();\n       // create an rbw file to hold block in the designated volume\n \n       if (allowLazyPersist \u0026\u0026 !v.isTransientStorage()) {\n         datanode.getMetrics().incrRamDiskBlocksWriteFallback();\n       }\n \n       ReplicaInPipeline newReplicaInfo;\n       try {\n         newReplicaInfo \u003d v.createRbw(b);\n         if (newReplicaInfo.getReplicaInfo().getState() !\u003d ReplicaState.RBW) {\n           throw new IOException(\"CreateRBW returned a replica of state \"\n               + newReplicaInfo.getReplicaInfo().getState()\n               + \" for block \" + b.getBlockId());\n         }\n       } catch (IOException e) {\n         IOUtils.cleanup(null, ref);\n         throw e;\n       }\n \n       volumeMap.add(b.getBlockPoolId(), newReplicaInfo.getReplicaInfo());\n       return new ReplicaHandler(newReplicaInfo, ref);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ReplicaHandler createRbw(\n      StorageType storageType, String storageId, ExtendedBlock b,\n      boolean allowLazyPersist) throws IOException {\n    try (AutoCloseableLock lock \u003d datasetWriteLock.acquire()) {\n      ReplicaInfo replicaInfo \u003d volumeMap.get(b.getBlockPoolId(),\n          b.getBlockId());\n      if (replicaInfo !\u003d null) {\n        throw new ReplicaAlreadyExistsException(\"Block \" + b +\n            \" already exists in state \" + replicaInfo.getState() +\n            \" and thus cannot be created.\");\n      }\n      // create a new block\n      FsVolumeReference ref \u003d null;\n\n      // Use ramdisk only if block size is a multiple of OS page size.\n      // This simplifies reservation for partially used replicas\n      // significantly.\n      if (allowLazyPersist \u0026\u0026\n          lazyWriter !\u003d null \u0026\u0026\n          b.getNumBytes() % cacheManager.getOsPageSize() \u003d\u003d 0 \u0026\u0026\n          reserveLockedMemory(b.getNumBytes())) {\n        try {\n          // First try to place the block on a transient volume.\n          ref \u003d volumes.getNextTransientVolume(b.getNumBytes());\n          datanode.getMetrics().incrRamDiskBlocksWrite();\n        } catch (DiskOutOfSpaceException de) {\n          // Ignore the exception since we just fall back to persistent storage.\n          LOG.warn(\"Insufficient space for placing the block on a transient \"\n              + \"volume, fall back to persistent storage: \"\n              + de.getMessage());\n        } finally {\n          if (ref \u003d\u003d null) {\n            cacheManager.release(b.getNumBytes());\n          }\n        }\n      }\n\n      if (ref \u003d\u003d null) {\n        ref \u003d volumes.getNextVolume(storageType, storageId, b.getNumBytes());\n      }\n\n      FsVolumeImpl v \u003d (FsVolumeImpl) ref.getVolume();\n      // create an rbw file to hold block in the designated volume\n\n      if (allowLazyPersist \u0026\u0026 !v.isTransientStorage()) {\n        datanode.getMetrics().incrRamDiskBlocksWriteFallback();\n      }\n\n      ReplicaInPipeline newReplicaInfo;\n      try {\n        newReplicaInfo \u003d v.createRbw(b);\n        if (newReplicaInfo.getReplicaInfo().getState() !\u003d ReplicaState.RBW) {\n          throw new IOException(\"CreateRBW returned a replica of state \"\n              + newReplicaInfo.getReplicaInfo().getState()\n              + \" for block \" + b.getBlockId());\n        }\n      } catch (IOException e) {\n        IOUtils.cleanup(null, ref);\n        throw e;\n      }\n\n      volumeMap.add(b.getBlockPoolId(), newReplicaInfo.getReplicaInfo());\n      return new ReplicaHandler(newReplicaInfo, ref);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "582cb10ec74ed5666946a3769002ceb80ba660cb": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13863. FsDatasetImpl should log DiskOutOfSpaceException. Contributed by Fei Hui.\n",
      "commitDate": "29/08/18 8:21 PM",
      "commitName": "582cb10ec74ed5666946a3769002ceb80ba660cb",
      "commitAuthor": "Yiqun Lin",
      "commitDateOld": "30/07/18 3:20 AM",
      "commitNameOld": "3108d27edde941d153a58f71fb1096cce2995531",
      "commitAuthorOld": "Brahma Reddy Battula",
      "daysBetweenCommits": 30.71,
      "commitsBetweenForRepo": 262,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,62 +1,65 @@\n   public ReplicaHandler createRbw(\n       StorageType storageType, String storageId, ExtendedBlock b,\n       boolean allowLazyPersist) throws IOException {\n     try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n       ReplicaInfo replicaInfo \u003d volumeMap.get(b.getBlockPoolId(),\n           b.getBlockId());\n       if (replicaInfo !\u003d null) {\n         throw new ReplicaAlreadyExistsException(\"Block \" + b +\n             \" already exists in state \" + replicaInfo.getState() +\n             \" and thus cannot be created.\");\n       }\n       // create a new block\n       FsVolumeReference ref \u003d null;\n \n       // Use ramdisk only if block size is a multiple of OS page size.\n       // This simplifies reservation for partially used replicas\n       // significantly.\n       if (allowLazyPersist \u0026\u0026\n           lazyWriter !\u003d null \u0026\u0026\n           b.getNumBytes() % cacheManager.getOsPageSize() \u003d\u003d 0 \u0026\u0026\n           reserveLockedMemory(b.getNumBytes())) {\n         try {\n           // First try to place the block on a transient volume.\n           ref \u003d volumes.getNextTransientVolume(b.getNumBytes());\n           datanode.getMetrics().incrRamDiskBlocksWrite();\n         } catch (DiskOutOfSpaceException de) {\n           // Ignore the exception since we just fall back to persistent storage.\n+          LOG.warn(\"Insufficient space for placing the block on a transient \"\n+              + \"volume, fall back to persistent storage: \"\n+              + de.getMessage());\n         } finally {\n           if (ref \u003d\u003d null) {\n             cacheManager.release(b.getNumBytes());\n           }\n         }\n       }\n \n       if (ref \u003d\u003d null) {\n         ref \u003d volumes.getNextVolume(storageType, storageId, b.getNumBytes());\n       }\n \n       FsVolumeImpl v \u003d (FsVolumeImpl) ref.getVolume();\n       // create an rbw file to hold block in the designated volume\n \n       if (allowLazyPersist \u0026\u0026 !v.isTransientStorage()) {\n         datanode.getMetrics().incrRamDiskBlocksWriteFallback();\n       }\n \n       ReplicaInPipeline newReplicaInfo;\n       try {\n         newReplicaInfo \u003d v.createRbw(b);\n         if (newReplicaInfo.getReplicaInfo().getState() !\u003d ReplicaState.RBW) {\n           throw new IOException(\"CreateRBW returned a replica of state \"\n               + newReplicaInfo.getReplicaInfo().getState()\n               + \" for block \" + b.getBlockId());\n         }\n       } catch (IOException e) {\n         IOUtils.cleanup(null, ref);\n         throw e;\n       }\n \n       volumeMap.add(b.getBlockPoolId(), newReplicaInfo.getReplicaInfo());\n       return new ReplicaHandler(newReplicaInfo, ref);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ReplicaHandler createRbw(\n      StorageType storageType, String storageId, ExtendedBlock b,\n      boolean allowLazyPersist) throws IOException {\n    try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n      ReplicaInfo replicaInfo \u003d volumeMap.get(b.getBlockPoolId(),\n          b.getBlockId());\n      if (replicaInfo !\u003d null) {\n        throw new ReplicaAlreadyExistsException(\"Block \" + b +\n            \" already exists in state \" + replicaInfo.getState() +\n            \" and thus cannot be created.\");\n      }\n      // create a new block\n      FsVolumeReference ref \u003d null;\n\n      // Use ramdisk only if block size is a multiple of OS page size.\n      // This simplifies reservation for partially used replicas\n      // significantly.\n      if (allowLazyPersist \u0026\u0026\n          lazyWriter !\u003d null \u0026\u0026\n          b.getNumBytes() % cacheManager.getOsPageSize() \u003d\u003d 0 \u0026\u0026\n          reserveLockedMemory(b.getNumBytes())) {\n        try {\n          // First try to place the block on a transient volume.\n          ref \u003d volumes.getNextTransientVolume(b.getNumBytes());\n          datanode.getMetrics().incrRamDiskBlocksWrite();\n        } catch (DiskOutOfSpaceException de) {\n          // Ignore the exception since we just fall back to persistent storage.\n          LOG.warn(\"Insufficient space for placing the block on a transient \"\n              + \"volume, fall back to persistent storage: \"\n              + de.getMessage());\n        } finally {\n          if (ref \u003d\u003d null) {\n            cacheManager.release(b.getNumBytes());\n          }\n        }\n      }\n\n      if (ref \u003d\u003d null) {\n        ref \u003d volumes.getNextVolume(storageType, storageId, b.getNumBytes());\n      }\n\n      FsVolumeImpl v \u003d (FsVolumeImpl) ref.getVolume();\n      // create an rbw file to hold block in the designated volume\n\n      if (allowLazyPersist \u0026\u0026 !v.isTransientStorage()) {\n        datanode.getMetrics().incrRamDiskBlocksWriteFallback();\n      }\n\n      ReplicaInPipeline newReplicaInfo;\n      try {\n        newReplicaInfo \u003d v.createRbw(b);\n        if (newReplicaInfo.getReplicaInfo().getState() !\u003d ReplicaState.RBW) {\n          throw new IOException(\"CreateRBW returned a replica of state \"\n              + newReplicaInfo.getReplicaInfo().getState()\n              + \" for block \" + b.getBlockId());\n        }\n      } catch (IOException e) {\n        IOUtils.cleanup(null, ref);\n        throw e;\n      }\n\n      volumeMap.add(b.getBlockPoolId(), newReplicaInfo.getReplicaInfo());\n      return new ReplicaHandler(newReplicaInfo, ref);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "a3954ccab148bddc290cb96528e63ff19799bcc9": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-9807. Add an optional StorageID to writes. Contributed by Ewan Higgs\n",
      "commitDate": "05/05/17 12:01 PM",
      "commitName": "a3954ccab148bddc290cb96528e63ff19799bcc9",
      "commitAuthor": "Chris Douglas",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-9807. Add an optional StorageID to writes. Contributed by Ewan Higgs\n",
          "commitDate": "05/05/17 12:01 PM",
          "commitName": "a3954ccab148bddc290cb96528e63ff19799bcc9",
          "commitAuthor": "Chris Douglas",
          "commitDateOld": "10/03/17 2:37 PM",
          "commitNameOld": "6d356b6b4d8ccb32397cacfb5d0357b21f6035fc",
          "commitAuthorOld": "Lei Xu",
          "daysBetweenCommits": 55.85,
          "commitsBetweenForRepo": 315,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,62 +1,62 @@\n   public ReplicaHandler createRbw(\n-      StorageType storageType, ExtendedBlock b, boolean allowLazyPersist)\n-      throws IOException {\n+      StorageType storageType, String storageId, ExtendedBlock b,\n+      boolean allowLazyPersist) throws IOException {\n     try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n       ReplicaInfo replicaInfo \u003d volumeMap.get(b.getBlockPoolId(),\n           b.getBlockId());\n       if (replicaInfo !\u003d null) {\n         throw new ReplicaAlreadyExistsException(\"Block \" + b +\n             \" already exists in state \" + replicaInfo.getState() +\n             \" and thus cannot be created.\");\n       }\n       // create a new block\n       FsVolumeReference ref \u003d null;\n \n       // Use ramdisk only if block size is a multiple of OS page size.\n       // This simplifies reservation for partially used replicas\n       // significantly.\n       if (allowLazyPersist \u0026\u0026\n           lazyWriter !\u003d null \u0026\u0026\n           b.getNumBytes() % cacheManager.getOsPageSize() \u003d\u003d 0 \u0026\u0026\n           reserveLockedMemory(b.getNumBytes())) {\n         try {\n           // First try to place the block on a transient volume.\n           ref \u003d volumes.getNextTransientVolume(b.getNumBytes());\n           datanode.getMetrics().incrRamDiskBlocksWrite();\n         } catch (DiskOutOfSpaceException de) {\n           // Ignore the exception since we just fall back to persistent storage.\n         } finally {\n           if (ref \u003d\u003d null) {\n             cacheManager.release(b.getNumBytes());\n           }\n         }\n       }\n \n       if (ref \u003d\u003d null) {\n-        ref \u003d volumes.getNextVolume(storageType, b.getNumBytes());\n+        ref \u003d volumes.getNextVolume(storageType, storageId, b.getNumBytes());\n       }\n \n       FsVolumeImpl v \u003d (FsVolumeImpl) ref.getVolume();\n       // create an rbw file to hold block in the designated volume\n \n       if (allowLazyPersist \u0026\u0026 !v.isTransientStorage()) {\n         datanode.getMetrics().incrRamDiskBlocksWriteFallback();\n       }\n \n       ReplicaInPipeline newReplicaInfo;\n       try {\n         newReplicaInfo \u003d v.createRbw(b);\n         if (newReplicaInfo.getReplicaInfo().getState() !\u003d ReplicaState.RBW) {\n           throw new IOException(\"CreateRBW returned a replica of state \"\n               + newReplicaInfo.getReplicaInfo().getState()\n               + \" for block \" + b.getBlockId());\n         }\n       } catch (IOException e) {\n         IOUtils.cleanup(null, ref);\n         throw e;\n       }\n \n       volumeMap.add(b.getBlockPoolId(), newReplicaInfo.getReplicaInfo());\n       return new ReplicaHandler(newReplicaInfo, ref);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public ReplicaHandler createRbw(\n      StorageType storageType, String storageId, ExtendedBlock b,\n      boolean allowLazyPersist) throws IOException {\n    try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n      ReplicaInfo replicaInfo \u003d volumeMap.get(b.getBlockPoolId(),\n          b.getBlockId());\n      if (replicaInfo !\u003d null) {\n        throw new ReplicaAlreadyExistsException(\"Block \" + b +\n            \" already exists in state \" + replicaInfo.getState() +\n            \" and thus cannot be created.\");\n      }\n      // create a new block\n      FsVolumeReference ref \u003d null;\n\n      // Use ramdisk only if block size is a multiple of OS page size.\n      // This simplifies reservation for partially used replicas\n      // significantly.\n      if (allowLazyPersist \u0026\u0026\n          lazyWriter !\u003d null \u0026\u0026\n          b.getNumBytes() % cacheManager.getOsPageSize() \u003d\u003d 0 \u0026\u0026\n          reserveLockedMemory(b.getNumBytes())) {\n        try {\n          // First try to place the block on a transient volume.\n          ref \u003d volumes.getNextTransientVolume(b.getNumBytes());\n          datanode.getMetrics().incrRamDiskBlocksWrite();\n        } catch (DiskOutOfSpaceException de) {\n          // Ignore the exception since we just fall back to persistent storage.\n        } finally {\n          if (ref \u003d\u003d null) {\n            cacheManager.release(b.getNumBytes());\n          }\n        }\n      }\n\n      if (ref \u003d\u003d null) {\n        ref \u003d volumes.getNextVolume(storageType, storageId, b.getNumBytes());\n      }\n\n      FsVolumeImpl v \u003d (FsVolumeImpl) ref.getVolume();\n      // create an rbw file to hold block in the designated volume\n\n      if (allowLazyPersist \u0026\u0026 !v.isTransientStorage()) {\n        datanode.getMetrics().incrRamDiskBlocksWriteFallback();\n      }\n\n      ReplicaInPipeline newReplicaInfo;\n      try {\n        newReplicaInfo \u003d v.createRbw(b);\n        if (newReplicaInfo.getReplicaInfo().getState() !\u003d ReplicaState.RBW) {\n          throw new IOException(\"CreateRBW returned a replica of state \"\n              + newReplicaInfo.getReplicaInfo().getState()\n              + \" for block \" + b.getBlockId());\n        }\n      } catch (IOException e) {\n        IOUtils.cleanup(null, ref);\n        throw e;\n      }\n\n      volumeMap.add(b.getBlockPoolId(), newReplicaInfo.getReplicaInfo());\n      return new ReplicaHandler(newReplicaInfo, ref);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
          "extendedDetails": {
            "oldValue": "[storageType-StorageType, b-ExtendedBlock, allowLazyPersist-boolean]",
            "newValue": "[storageType-StorageType, storageId-String, b-ExtendedBlock, allowLazyPersist-boolean]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-9807. Add an optional StorageID to writes. Contributed by Ewan Higgs\n",
          "commitDate": "05/05/17 12:01 PM",
          "commitName": "a3954ccab148bddc290cb96528e63ff19799bcc9",
          "commitAuthor": "Chris Douglas",
          "commitDateOld": "10/03/17 2:37 PM",
          "commitNameOld": "6d356b6b4d8ccb32397cacfb5d0357b21f6035fc",
          "commitAuthorOld": "Lei Xu",
          "daysBetweenCommits": 55.85,
          "commitsBetweenForRepo": 315,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,62 +1,62 @@\n   public ReplicaHandler createRbw(\n-      StorageType storageType, ExtendedBlock b, boolean allowLazyPersist)\n-      throws IOException {\n+      StorageType storageType, String storageId, ExtendedBlock b,\n+      boolean allowLazyPersist) throws IOException {\n     try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n       ReplicaInfo replicaInfo \u003d volumeMap.get(b.getBlockPoolId(),\n           b.getBlockId());\n       if (replicaInfo !\u003d null) {\n         throw new ReplicaAlreadyExistsException(\"Block \" + b +\n             \" already exists in state \" + replicaInfo.getState() +\n             \" and thus cannot be created.\");\n       }\n       // create a new block\n       FsVolumeReference ref \u003d null;\n \n       // Use ramdisk only if block size is a multiple of OS page size.\n       // This simplifies reservation for partially used replicas\n       // significantly.\n       if (allowLazyPersist \u0026\u0026\n           lazyWriter !\u003d null \u0026\u0026\n           b.getNumBytes() % cacheManager.getOsPageSize() \u003d\u003d 0 \u0026\u0026\n           reserveLockedMemory(b.getNumBytes())) {\n         try {\n           // First try to place the block on a transient volume.\n           ref \u003d volumes.getNextTransientVolume(b.getNumBytes());\n           datanode.getMetrics().incrRamDiskBlocksWrite();\n         } catch (DiskOutOfSpaceException de) {\n           // Ignore the exception since we just fall back to persistent storage.\n         } finally {\n           if (ref \u003d\u003d null) {\n             cacheManager.release(b.getNumBytes());\n           }\n         }\n       }\n \n       if (ref \u003d\u003d null) {\n-        ref \u003d volumes.getNextVolume(storageType, b.getNumBytes());\n+        ref \u003d volumes.getNextVolume(storageType, storageId, b.getNumBytes());\n       }\n \n       FsVolumeImpl v \u003d (FsVolumeImpl) ref.getVolume();\n       // create an rbw file to hold block in the designated volume\n \n       if (allowLazyPersist \u0026\u0026 !v.isTransientStorage()) {\n         datanode.getMetrics().incrRamDiskBlocksWriteFallback();\n       }\n \n       ReplicaInPipeline newReplicaInfo;\n       try {\n         newReplicaInfo \u003d v.createRbw(b);\n         if (newReplicaInfo.getReplicaInfo().getState() !\u003d ReplicaState.RBW) {\n           throw new IOException(\"CreateRBW returned a replica of state \"\n               + newReplicaInfo.getReplicaInfo().getState()\n               + \" for block \" + b.getBlockId());\n         }\n       } catch (IOException e) {\n         IOUtils.cleanup(null, ref);\n         throw e;\n       }\n \n       volumeMap.add(b.getBlockPoolId(), newReplicaInfo.getReplicaInfo());\n       return new ReplicaHandler(newReplicaInfo, ref);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public ReplicaHandler createRbw(\n      StorageType storageType, String storageId, ExtendedBlock b,\n      boolean allowLazyPersist) throws IOException {\n    try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n      ReplicaInfo replicaInfo \u003d volumeMap.get(b.getBlockPoolId(),\n          b.getBlockId());\n      if (replicaInfo !\u003d null) {\n        throw new ReplicaAlreadyExistsException(\"Block \" + b +\n            \" already exists in state \" + replicaInfo.getState() +\n            \" and thus cannot be created.\");\n      }\n      // create a new block\n      FsVolumeReference ref \u003d null;\n\n      // Use ramdisk only if block size is a multiple of OS page size.\n      // This simplifies reservation for partially used replicas\n      // significantly.\n      if (allowLazyPersist \u0026\u0026\n          lazyWriter !\u003d null \u0026\u0026\n          b.getNumBytes() % cacheManager.getOsPageSize() \u003d\u003d 0 \u0026\u0026\n          reserveLockedMemory(b.getNumBytes())) {\n        try {\n          // First try to place the block on a transient volume.\n          ref \u003d volumes.getNextTransientVolume(b.getNumBytes());\n          datanode.getMetrics().incrRamDiskBlocksWrite();\n        } catch (DiskOutOfSpaceException de) {\n          // Ignore the exception since we just fall back to persistent storage.\n        } finally {\n          if (ref \u003d\u003d null) {\n            cacheManager.release(b.getNumBytes());\n          }\n        }\n      }\n\n      if (ref \u003d\u003d null) {\n        ref \u003d volumes.getNextVolume(storageType, storageId, b.getNumBytes());\n      }\n\n      FsVolumeImpl v \u003d (FsVolumeImpl) ref.getVolume();\n      // create an rbw file to hold block in the designated volume\n\n      if (allowLazyPersist \u0026\u0026 !v.isTransientStorage()) {\n        datanode.getMetrics().incrRamDiskBlocksWriteFallback();\n      }\n\n      ReplicaInPipeline newReplicaInfo;\n      try {\n        newReplicaInfo \u003d v.createRbw(b);\n        if (newReplicaInfo.getReplicaInfo().getState() !\u003d ReplicaState.RBW) {\n          throw new IOException(\"CreateRBW returned a replica of state \"\n              + newReplicaInfo.getReplicaInfo().getState()\n              + \" for block \" + b.getBlockId());\n        }\n      } catch (IOException e) {\n        IOUtils.cleanup(null, ref);\n        throw e;\n      }\n\n      volumeMap.add(b.getBlockPoolId(), newReplicaInfo.getReplicaInfo());\n      return new ReplicaHandler(newReplicaInfo, ref);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
          "extendedDetails": {}
        }
      ]
    },
    "86c9862bec0248d671e657aa56094a2919b8ac14": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10636. Modify ReplicaInfo to remove the assumption that replica metadata and data are stored in java.io.File. (Virajith Jalaparti via lei)\n",
      "commitDate": "13/09/16 12:54 PM",
      "commitName": "86c9862bec0248d671e657aa56094a2919b8ac14",
      "commitAuthor": "Lei Xu",
      "commitDateOld": "10/09/16 6:22 PM",
      "commitNameOld": "a99bf26a0899bcc4307c3a242c8414eaef555aa7",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 2.77,
      "commitsBetweenForRepo": 15,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,60 +1,62 @@\n   public ReplicaHandler createRbw(\n       StorageType storageType, ExtendedBlock b, boolean allowLazyPersist)\n       throws IOException {\n     try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n       ReplicaInfo replicaInfo \u003d volumeMap.get(b.getBlockPoolId(),\n           b.getBlockId());\n       if (replicaInfo !\u003d null) {\n         throw new ReplicaAlreadyExistsException(\"Block \" + b +\n             \" already exists in state \" + replicaInfo.getState() +\n             \" and thus cannot be created.\");\n       }\n       // create a new block\n       FsVolumeReference ref \u003d null;\n \n       // Use ramdisk only if block size is a multiple of OS page size.\n       // This simplifies reservation for partially used replicas\n       // significantly.\n       if (allowLazyPersist \u0026\u0026\n           lazyWriter !\u003d null \u0026\u0026\n           b.getNumBytes() % cacheManager.getOsPageSize() \u003d\u003d 0 \u0026\u0026\n           reserveLockedMemory(b.getNumBytes())) {\n         try {\n           // First try to place the block on a transient volume.\n           ref \u003d volumes.getNextTransientVolume(b.getNumBytes());\n           datanode.getMetrics().incrRamDiskBlocksWrite();\n         } catch (DiskOutOfSpaceException de) {\n           // Ignore the exception since we just fall back to persistent storage.\n         } finally {\n           if (ref \u003d\u003d null) {\n             cacheManager.release(b.getNumBytes());\n           }\n         }\n       }\n \n       if (ref \u003d\u003d null) {\n         ref \u003d volumes.getNextVolume(storageType, b.getNumBytes());\n       }\n \n       FsVolumeImpl v \u003d (FsVolumeImpl) ref.getVolume();\n       // create an rbw file to hold block in the designated volume\n \n       if (allowLazyPersist \u0026\u0026 !v.isTransientStorage()) {\n         datanode.getMetrics().incrRamDiskBlocksWriteFallback();\n       }\n \n-      File f;\n+      ReplicaInPipeline newReplicaInfo;\n       try {\n-        f \u003d v.createRbwFile(b.getBlockPoolId(), b.getLocalBlock());\n+        newReplicaInfo \u003d v.createRbw(b);\n+        if (newReplicaInfo.getReplicaInfo().getState() !\u003d ReplicaState.RBW) {\n+          throw new IOException(\"CreateRBW returned a replica of state \"\n+              + newReplicaInfo.getReplicaInfo().getState()\n+              + \" for block \" + b.getBlockId());\n+        }\n       } catch (IOException e) {\n         IOUtils.cleanup(null, ref);\n         throw e;\n       }\n \n-      ReplicaBeingWritten newReplicaInfo \u003d\n-          new ReplicaBeingWritten(b.getBlockId(),\n-          b.getGenerationStamp(), v, f.getParentFile(), b.getNumBytes());\n-      volumeMap.add(b.getBlockPoolId(), newReplicaInfo);\n+      volumeMap.add(b.getBlockPoolId(), newReplicaInfo.getReplicaInfo());\n       return new ReplicaHandler(newReplicaInfo, ref);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ReplicaHandler createRbw(\n      StorageType storageType, ExtendedBlock b, boolean allowLazyPersist)\n      throws IOException {\n    try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n      ReplicaInfo replicaInfo \u003d volumeMap.get(b.getBlockPoolId(),\n          b.getBlockId());\n      if (replicaInfo !\u003d null) {\n        throw new ReplicaAlreadyExistsException(\"Block \" + b +\n            \" already exists in state \" + replicaInfo.getState() +\n            \" and thus cannot be created.\");\n      }\n      // create a new block\n      FsVolumeReference ref \u003d null;\n\n      // Use ramdisk only if block size is a multiple of OS page size.\n      // This simplifies reservation for partially used replicas\n      // significantly.\n      if (allowLazyPersist \u0026\u0026\n          lazyWriter !\u003d null \u0026\u0026\n          b.getNumBytes() % cacheManager.getOsPageSize() \u003d\u003d 0 \u0026\u0026\n          reserveLockedMemory(b.getNumBytes())) {\n        try {\n          // First try to place the block on a transient volume.\n          ref \u003d volumes.getNextTransientVolume(b.getNumBytes());\n          datanode.getMetrics().incrRamDiskBlocksWrite();\n        } catch (DiskOutOfSpaceException de) {\n          // Ignore the exception since we just fall back to persistent storage.\n        } finally {\n          if (ref \u003d\u003d null) {\n            cacheManager.release(b.getNumBytes());\n          }\n        }\n      }\n\n      if (ref \u003d\u003d null) {\n        ref \u003d volumes.getNextVolume(storageType, b.getNumBytes());\n      }\n\n      FsVolumeImpl v \u003d (FsVolumeImpl) ref.getVolume();\n      // create an rbw file to hold block in the designated volume\n\n      if (allowLazyPersist \u0026\u0026 !v.isTransientStorage()) {\n        datanode.getMetrics().incrRamDiskBlocksWriteFallback();\n      }\n\n      ReplicaInPipeline newReplicaInfo;\n      try {\n        newReplicaInfo \u003d v.createRbw(b);\n        if (newReplicaInfo.getReplicaInfo().getState() !\u003d ReplicaState.RBW) {\n          throw new IOException(\"CreateRBW returned a replica of state \"\n              + newReplicaInfo.getReplicaInfo().getState()\n              + \" for block \" + b.getBlockId());\n        }\n      } catch (IOException e) {\n        IOUtils.cleanup(null, ref);\n        throw e;\n      }\n\n      volumeMap.add(b.getBlockPoolId(), newReplicaInfo.getReplicaInfo());\n      return new ReplicaHandler(newReplicaInfo, ref);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "8c0638471f8f1dd47667b2d6727d4d2d54e4b48c": {
      "type": "Ymultichange(Ymodifierchange,Ybodychange)",
      "commitMessage": "HADOOP-10682. Replace FsDatasetImpl object lock with a separate lock object. (Chen Liang)\n",
      "commitDate": "08/08/16 12:02 PM",
      "commitName": "8c0638471f8f1dd47667b2d6727d4d2d54e4b48c",
      "commitAuthor": "Arpit Agarwal",
      "subchanges": [
        {
          "type": "Ymodifierchange",
          "commitMessage": "HADOOP-10682. Replace FsDatasetImpl object lock with a separate lock object. (Chen Liang)\n",
          "commitDate": "08/08/16 12:02 PM",
          "commitName": "8c0638471f8f1dd47667b2d6727d4d2d54e4b48c",
          "commitAuthor": "Arpit Agarwal",
          "commitDateOld": "08/07/16 7:40 PM",
          "commitNameOld": "da6f1b88dd47e22b24d44f6fc8bbee73e85746f7",
          "commitAuthorOld": "Yongjun Zhang",
          "daysBetweenCommits": 30.68,
          "commitsBetweenForRepo": 320,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,57 +1,60 @@\n-  public synchronized ReplicaHandler createRbw(\n+  public ReplicaHandler createRbw(\n       StorageType storageType, ExtendedBlock b, boolean allowLazyPersist)\n       throws IOException {\n-    ReplicaInfo replicaInfo \u003d volumeMap.get(b.getBlockPoolId(),\n-        b.getBlockId());\n-    if (replicaInfo !\u003d null) {\n-      throw new ReplicaAlreadyExistsException(\"Block \" + b +\n-      \" already exists in state \" + replicaInfo.getState() +\n-      \" and thus cannot be created.\");\n-    }\n-    // create a new block\n-    FsVolumeReference ref \u003d null;\n+    try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n+      ReplicaInfo replicaInfo \u003d volumeMap.get(b.getBlockPoolId(),\n+          b.getBlockId());\n+      if (replicaInfo !\u003d null) {\n+        throw new ReplicaAlreadyExistsException(\"Block \" + b +\n+            \" already exists in state \" + replicaInfo.getState() +\n+            \" and thus cannot be created.\");\n+      }\n+      // create a new block\n+      FsVolumeReference ref \u003d null;\n \n-    // Use ramdisk only if block size is a multiple of OS page size.\n-    // This simplifies reservation for partially used replicas\n-    // significantly.\n-    if (allowLazyPersist \u0026\u0026\n-        lazyWriter !\u003d null \u0026\u0026\n-        b.getNumBytes() % cacheManager.getOsPageSize() \u003d\u003d 0 \u0026\u0026\n-        reserveLockedMemory(b.getNumBytes())) {\n-      try {\n-        // First try to place the block on a transient volume.\n-        ref \u003d volumes.getNextTransientVolume(b.getNumBytes());\n-        datanode.getMetrics().incrRamDiskBlocksWrite();\n-      } catch(DiskOutOfSpaceException de) {\n-        // Ignore the exception since we just fall back to persistent storage.\n-      } finally {\n-        if (ref \u003d\u003d null) {\n-          cacheManager.release(b.getNumBytes());\n+      // Use ramdisk only if block size is a multiple of OS page size.\n+      // This simplifies reservation for partially used replicas\n+      // significantly.\n+      if (allowLazyPersist \u0026\u0026\n+          lazyWriter !\u003d null \u0026\u0026\n+          b.getNumBytes() % cacheManager.getOsPageSize() \u003d\u003d 0 \u0026\u0026\n+          reserveLockedMemory(b.getNumBytes())) {\n+        try {\n+          // First try to place the block on a transient volume.\n+          ref \u003d volumes.getNextTransientVolume(b.getNumBytes());\n+          datanode.getMetrics().incrRamDiskBlocksWrite();\n+        } catch (DiskOutOfSpaceException de) {\n+          // Ignore the exception since we just fall back to persistent storage.\n+        } finally {\n+          if (ref \u003d\u003d null) {\n+            cacheManager.release(b.getNumBytes());\n+          }\n         }\n       }\n+\n+      if (ref \u003d\u003d null) {\n+        ref \u003d volumes.getNextVolume(storageType, b.getNumBytes());\n+      }\n+\n+      FsVolumeImpl v \u003d (FsVolumeImpl) ref.getVolume();\n+      // create an rbw file to hold block in the designated volume\n+\n+      if (allowLazyPersist \u0026\u0026 !v.isTransientStorage()) {\n+        datanode.getMetrics().incrRamDiskBlocksWriteFallback();\n+      }\n+\n+      File f;\n+      try {\n+        f \u003d v.createRbwFile(b.getBlockPoolId(), b.getLocalBlock());\n+      } catch (IOException e) {\n+        IOUtils.cleanup(null, ref);\n+        throw e;\n+      }\n+\n+      ReplicaBeingWritten newReplicaInfo \u003d\n+          new ReplicaBeingWritten(b.getBlockId(),\n+          b.getGenerationStamp(), v, f.getParentFile(), b.getNumBytes());\n+      volumeMap.add(b.getBlockPoolId(), newReplicaInfo);\n+      return new ReplicaHandler(newReplicaInfo, ref);\n     }\n-\n-    if (ref \u003d\u003d null) {\n-      ref \u003d volumes.getNextVolume(storageType, b.getNumBytes());\n-    }\n-\n-    FsVolumeImpl v \u003d (FsVolumeImpl) ref.getVolume();\n-    // create an rbw file to hold block in the designated volume\n-\n-    if (allowLazyPersist \u0026\u0026 !v.isTransientStorage()) {\n-      datanode.getMetrics().incrRamDiskBlocksWriteFallback();\n-    }\n-\n-    File f;\n-    try {\n-      f \u003d v.createRbwFile(b.getBlockPoolId(), b.getLocalBlock());\n-    } catch (IOException e) {\n-      IOUtils.cleanup(null, ref);\n-      throw e;\n-    }\n-\n-    ReplicaBeingWritten newReplicaInfo \u003d new ReplicaBeingWritten(b.getBlockId(), \n-        b.getGenerationStamp(), v, f.getParentFile(), b.getNumBytes());\n-    volumeMap.add(b.getBlockPoolId(), newReplicaInfo);\n-    return new ReplicaHandler(newReplicaInfo, ref);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public ReplicaHandler createRbw(\n      StorageType storageType, ExtendedBlock b, boolean allowLazyPersist)\n      throws IOException {\n    try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n      ReplicaInfo replicaInfo \u003d volumeMap.get(b.getBlockPoolId(),\n          b.getBlockId());\n      if (replicaInfo !\u003d null) {\n        throw new ReplicaAlreadyExistsException(\"Block \" + b +\n            \" already exists in state \" + replicaInfo.getState() +\n            \" and thus cannot be created.\");\n      }\n      // create a new block\n      FsVolumeReference ref \u003d null;\n\n      // Use ramdisk only if block size is a multiple of OS page size.\n      // This simplifies reservation for partially used replicas\n      // significantly.\n      if (allowLazyPersist \u0026\u0026\n          lazyWriter !\u003d null \u0026\u0026\n          b.getNumBytes() % cacheManager.getOsPageSize() \u003d\u003d 0 \u0026\u0026\n          reserveLockedMemory(b.getNumBytes())) {\n        try {\n          // First try to place the block on a transient volume.\n          ref \u003d volumes.getNextTransientVolume(b.getNumBytes());\n          datanode.getMetrics().incrRamDiskBlocksWrite();\n        } catch (DiskOutOfSpaceException de) {\n          // Ignore the exception since we just fall back to persistent storage.\n        } finally {\n          if (ref \u003d\u003d null) {\n            cacheManager.release(b.getNumBytes());\n          }\n        }\n      }\n\n      if (ref \u003d\u003d null) {\n        ref \u003d volumes.getNextVolume(storageType, b.getNumBytes());\n      }\n\n      FsVolumeImpl v \u003d (FsVolumeImpl) ref.getVolume();\n      // create an rbw file to hold block in the designated volume\n\n      if (allowLazyPersist \u0026\u0026 !v.isTransientStorage()) {\n        datanode.getMetrics().incrRamDiskBlocksWriteFallback();\n      }\n\n      File f;\n      try {\n        f \u003d v.createRbwFile(b.getBlockPoolId(), b.getLocalBlock());\n      } catch (IOException e) {\n        IOUtils.cleanup(null, ref);\n        throw e;\n      }\n\n      ReplicaBeingWritten newReplicaInfo \u003d\n          new ReplicaBeingWritten(b.getBlockId(),\n          b.getGenerationStamp(), v, f.getParentFile(), b.getNumBytes());\n      volumeMap.add(b.getBlockPoolId(), newReplicaInfo);\n      return new ReplicaHandler(newReplicaInfo, ref);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
          "extendedDetails": {
            "oldValue": "[public, synchronized]",
            "newValue": "[public]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HADOOP-10682. Replace FsDatasetImpl object lock with a separate lock object. (Chen Liang)\n",
          "commitDate": "08/08/16 12:02 PM",
          "commitName": "8c0638471f8f1dd47667b2d6727d4d2d54e4b48c",
          "commitAuthor": "Arpit Agarwal",
          "commitDateOld": "08/07/16 7:40 PM",
          "commitNameOld": "da6f1b88dd47e22b24d44f6fc8bbee73e85746f7",
          "commitAuthorOld": "Yongjun Zhang",
          "daysBetweenCommits": 30.68,
          "commitsBetweenForRepo": 320,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,57 +1,60 @@\n-  public synchronized ReplicaHandler createRbw(\n+  public ReplicaHandler createRbw(\n       StorageType storageType, ExtendedBlock b, boolean allowLazyPersist)\n       throws IOException {\n-    ReplicaInfo replicaInfo \u003d volumeMap.get(b.getBlockPoolId(),\n-        b.getBlockId());\n-    if (replicaInfo !\u003d null) {\n-      throw new ReplicaAlreadyExistsException(\"Block \" + b +\n-      \" already exists in state \" + replicaInfo.getState() +\n-      \" and thus cannot be created.\");\n-    }\n-    // create a new block\n-    FsVolumeReference ref \u003d null;\n+    try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n+      ReplicaInfo replicaInfo \u003d volumeMap.get(b.getBlockPoolId(),\n+          b.getBlockId());\n+      if (replicaInfo !\u003d null) {\n+        throw new ReplicaAlreadyExistsException(\"Block \" + b +\n+            \" already exists in state \" + replicaInfo.getState() +\n+            \" and thus cannot be created.\");\n+      }\n+      // create a new block\n+      FsVolumeReference ref \u003d null;\n \n-    // Use ramdisk only if block size is a multiple of OS page size.\n-    // This simplifies reservation for partially used replicas\n-    // significantly.\n-    if (allowLazyPersist \u0026\u0026\n-        lazyWriter !\u003d null \u0026\u0026\n-        b.getNumBytes() % cacheManager.getOsPageSize() \u003d\u003d 0 \u0026\u0026\n-        reserveLockedMemory(b.getNumBytes())) {\n-      try {\n-        // First try to place the block on a transient volume.\n-        ref \u003d volumes.getNextTransientVolume(b.getNumBytes());\n-        datanode.getMetrics().incrRamDiskBlocksWrite();\n-      } catch(DiskOutOfSpaceException de) {\n-        // Ignore the exception since we just fall back to persistent storage.\n-      } finally {\n-        if (ref \u003d\u003d null) {\n-          cacheManager.release(b.getNumBytes());\n+      // Use ramdisk only if block size is a multiple of OS page size.\n+      // This simplifies reservation for partially used replicas\n+      // significantly.\n+      if (allowLazyPersist \u0026\u0026\n+          lazyWriter !\u003d null \u0026\u0026\n+          b.getNumBytes() % cacheManager.getOsPageSize() \u003d\u003d 0 \u0026\u0026\n+          reserveLockedMemory(b.getNumBytes())) {\n+        try {\n+          // First try to place the block on a transient volume.\n+          ref \u003d volumes.getNextTransientVolume(b.getNumBytes());\n+          datanode.getMetrics().incrRamDiskBlocksWrite();\n+        } catch (DiskOutOfSpaceException de) {\n+          // Ignore the exception since we just fall back to persistent storage.\n+        } finally {\n+          if (ref \u003d\u003d null) {\n+            cacheManager.release(b.getNumBytes());\n+          }\n         }\n       }\n+\n+      if (ref \u003d\u003d null) {\n+        ref \u003d volumes.getNextVolume(storageType, b.getNumBytes());\n+      }\n+\n+      FsVolumeImpl v \u003d (FsVolumeImpl) ref.getVolume();\n+      // create an rbw file to hold block in the designated volume\n+\n+      if (allowLazyPersist \u0026\u0026 !v.isTransientStorage()) {\n+        datanode.getMetrics().incrRamDiskBlocksWriteFallback();\n+      }\n+\n+      File f;\n+      try {\n+        f \u003d v.createRbwFile(b.getBlockPoolId(), b.getLocalBlock());\n+      } catch (IOException e) {\n+        IOUtils.cleanup(null, ref);\n+        throw e;\n+      }\n+\n+      ReplicaBeingWritten newReplicaInfo \u003d\n+          new ReplicaBeingWritten(b.getBlockId(),\n+          b.getGenerationStamp(), v, f.getParentFile(), b.getNumBytes());\n+      volumeMap.add(b.getBlockPoolId(), newReplicaInfo);\n+      return new ReplicaHandler(newReplicaInfo, ref);\n     }\n-\n-    if (ref \u003d\u003d null) {\n-      ref \u003d volumes.getNextVolume(storageType, b.getNumBytes());\n-    }\n-\n-    FsVolumeImpl v \u003d (FsVolumeImpl) ref.getVolume();\n-    // create an rbw file to hold block in the designated volume\n-\n-    if (allowLazyPersist \u0026\u0026 !v.isTransientStorage()) {\n-      datanode.getMetrics().incrRamDiskBlocksWriteFallback();\n-    }\n-\n-    File f;\n-    try {\n-      f \u003d v.createRbwFile(b.getBlockPoolId(), b.getLocalBlock());\n-    } catch (IOException e) {\n-      IOUtils.cleanup(null, ref);\n-      throw e;\n-    }\n-\n-    ReplicaBeingWritten newReplicaInfo \u003d new ReplicaBeingWritten(b.getBlockId(), \n-        b.getGenerationStamp(), v, f.getParentFile(), b.getNumBytes());\n-    volumeMap.add(b.getBlockPoolId(), newReplicaInfo);\n-    return new ReplicaHandler(newReplicaInfo, ref);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public ReplicaHandler createRbw(\n      StorageType storageType, ExtendedBlock b, boolean allowLazyPersist)\n      throws IOException {\n    try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n      ReplicaInfo replicaInfo \u003d volumeMap.get(b.getBlockPoolId(),\n          b.getBlockId());\n      if (replicaInfo !\u003d null) {\n        throw new ReplicaAlreadyExistsException(\"Block \" + b +\n            \" already exists in state \" + replicaInfo.getState() +\n            \" and thus cannot be created.\");\n      }\n      // create a new block\n      FsVolumeReference ref \u003d null;\n\n      // Use ramdisk only if block size is a multiple of OS page size.\n      // This simplifies reservation for partially used replicas\n      // significantly.\n      if (allowLazyPersist \u0026\u0026\n          lazyWriter !\u003d null \u0026\u0026\n          b.getNumBytes() % cacheManager.getOsPageSize() \u003d\u003d 0 \u0026\u0026\n          reserveLockedMemory(b.getNumBytes())) {\n        try {\n          // First try to place the block on a transient volume.\n          ref \u003d volumes.getNextTransientVolume(b.getNumBytes());\n          datanode.getMetrics().incrRamDiskBlocksWrite();\n        } catch (DiskOutOfSpaceException de) {\n          // Ignore the exception since we just fall back to persistent storage.\n        } finally {\n          if (ref \u003d\u003d null) {\n            cacheManager.release(b.getNumBytes());\n          }\n        }\n      }\n\n      if (ref \u003d\u003d null) {\n        ref \u003d volumes.getNextVolume(storageType, b.getNumBytes());\n      }\n\n      FsVolumeImpl v \u003d (FsVolumeImpl) ref.getVolume();\n      // create an rbw file to hold block in the designated volume\n\n      if (allowLazyPersist \u0026\u0026 !v.isTransientStorage()) {\n        datanode.getMetrics().incrRamDiskBlocksWriteFallback();\n      }\n\n      File f;\n      try {\n        f \u003d v.createRbwFile(b.getBlockPoolId(), b.getLocalBlock());\n      } catch (IOException e) {\n        IOUtils.cleanup(null, ref);\n        throw e;\n      }\n\n      ReplicaBeingWritten newReplicaInfo \u003d\n          new ReplicaBeingWritten(b.getBlockId(),\n          b.getGenerationStamp(), v, f.getParentFile(), b.getNumBytes());\n      volumeMap.add(b.getBlockPoolId(), newReplicaInfo);\n      return new ReplicaHandler(newReplicaInfo, ref);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
          "extendedDetails": {}
        }
      ]
    },
    "c7d022b66f0c5baafbb7000a435c1d6e39906efe": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8192. Eviction should key off used locked memory instead of ram disk free space. (Contributed by Arpit Agarwal)\n",
      "commitDate": "20/06/15 1:27 PM",
      "commitName": "c7d022b66f0c5baafbb7000a435c1d6e39906efe",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "16/05/15 9:05 AM",
      "commitNameOld": "e453989a5722e653bd97e3e54f9bbdffc9454fba",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 35.18,
      "commitsBetweenForRepo": 253,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,53 +1,57 @@\n   public synchronized ReplicaHandler createRbw(\n       StorageType storageType, ExtendedBlock b, boolean allowLazyPersist)\n       throws IOException {\n     ReplicaInfo replicaInfo \u003d volumeMap.get(b.getBlockPoolId(),\n         b.getBlockId());\n     if (replicaInfo !\u003d null) {\n       throw new ReplicaAlreadyExistsException(\"Block \" + b +\n       \" already exists in state \" + replicaInfo.getState() +\n       \" and thus cannot be created.\");\n     }\n     // create a new block\n     FsVolumeReference ref \u003d null;\n \n     // Use ramdisk only if block size is a multiple of OS page size.\n     // This simplifies reservation for partially used replicas\n     // significantly.\n     if (allowLazyPersist \u0026\u0026\n         lazyWriter !\u003d null \u0026\u0026\n         b.getNumBytes() % cacheManager.getOsPageSize() \u003d\u003d 0 \u0026\u0026\n-        (cacheManager.reserve(b.getNumBytes())) \u003e 0) {\n+        reserveLockedMemory(b.getNumBytes())) {\n       try {\n         // First try to place the block on a transient volume.\n         ref \u003d volumes.getNextTransientVolume(b.getNumBytes());\n         datanode.getMetrics().incrRamDiskBlocksWrite();\n       } catch(DiskOutOfSpaceException de) {\n         // Ignore the exception since we just fall back to persistent storage.\n-        datanode.getMetrics().incrRamDiskBlocksWriteFallback();\n       } finally {\n         if (ref \u003d\u003d null) {\n           cacheManager.release(b.getNumBytes());\n         }\n       }\n     }\n \n     if (ref \u003d\u003d null) {\n       ref \u003d volumes.getNextVolume(storageType, b.getNumBytes());\n     }\n \n     FsVolumeImpl v \u003d (FsVolumeImpl) ref.getVolume();\n     // create an rbw file to hold block in the designated volume\n+\n+    if (allowLazyPersist \u0026\u0026 !v.isTransientStorage()) {\n+      datanode.getMetrics().incrRamDiskBlocksWriteFallback();\n+    }\n+\n     File f;\n     try {\n       f \u003d v.createRbwFile(b.getBlockPoolId(), b.getLocalBlock());\n     } catch (IOException e) {\n       IOUtils.cleanup(null, ref);\n       throw e;\n     }\n \n     ReplicaBeingWritten newReplicaInfo \u003d new ReplicaBeingWritten(b.getBlockId(), \n         b.getGenerationStamp(), v, f.getParentFile(), b.getNumBytes());\n     volumeMap.add(b.getBlockPoolId(), newReplicaInfo);\n     return new ReplicaHandler(newReplicaInfo, ref);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized ReplicaHandler createRbw(\n      StorageType storageType, ExtendedBlock b, boolean allowLazyPersist)\n      throws IOException {\n    ReplicaInfo replicaInfo \u003d volumeMap.get(b.getBlockPoolId(),\n        b.getBlockId());\n    if (replicaInfo !\u003d null) {\n      throw new ReplicaAlreadyExistsException(\"Block \" + b +\n      \" already exists in state \" + replicaInfo.getState() +\n      \" and thus cannot be created.\");\n    }\n    // create a new block\n    FsVolumeReference ref \u003d null;\n\n    // Use ramdisk only if block size is a multiple of OS page size.\n    // This simplifies reservation for partially used replicas\n    // significantly.\n    if (allowLazyPersist \u0026\u0026\n        lazyWriter !\u003d null \u0026\u0026\n        b.getNumBytes() % cacheManager.getOsPageSize() \u003d\u003d 0 \u0026\u0026\n        reserveLockedMemory(b.getNumBytes())) {\n      try {\n        // First try to place the block on a transient volume.\n        ref \u003d volumes.getNextTransientVolume(b.getNumBytes());\n        datanode.getMetrics().incrRamDiskBlocksWrite();\n      } catch(DiskOutOfSpaceException de) {\n        // Ignore the exception since we just fall back to persistent storage.\n      } finally {\n        if (ref \u003d\u003d null) {\n          cacheManager.release(b.getNumBytes());\n        }\n      }\n    }\n\n    if (ref \u003d\u003d null) {\n      ref \u003d volumes.getNextVolume(storageType, b.getNumBytes());\n    }\n\n    FsVolumeImpl v \u003d (FsVolumeImpl) ref.getVolume();\n    // create an rbw file to hold block in the designated volume\n\n    if (allowLazyPersist \u0026\u0026 !v.isTransientStorage()) {\n      datanode.getMetrics().incrRamDiskBlocksWriteFallback();\n    }\n\n    File f;\n    try {\n      f \u003d v.createRbwFile(b.getBlockPoolId(), b.getLocalBlock());\n    } catch (IOException e) {\n      IOUtils.cleanup(null, ref);\n      throw e;\n    }\n\n    ReplicaBeingWritten newReplicaInfo \u003d new ReplicaBeingWritten(b.getBlockId(), \n        b.getGenerationStamp(), v, f.getParentFile(), b.getNumBytes());\n    volumeMap.add(b.getBlockPoolId(), newReplicaInfo);\n    return new ReplicaHandler(newReplicaInfo, ref);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "e453989a5722e653bd97e3e54f9bbdffc9454fba": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8157. Writes to RAM DISK reserve locked memory for block files. (Arpit Agarwal)\n",
      "commitDate": "16/05/15 9:05 AM",
      "commitName": "e453989a5722e653bd97e3e54f9bbdffc9454fba",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "06/05/15 9:11 PM",
      "commitNameOld": "6633a8474d7e92fa028ede8fd6c6e41b6c5887f5",
      "commitAuthorOld": "cnauroth",
      "daysBetweenCommits": 9.5,
      "commitsBetweenForRepo": 157,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,46 +1,53 @@\n   public synchronized ReplicaHandler createRbw(\n       StorageType storageType, ExtendedBlock b, boolean allowLazyPersist)\n       throws IOException {\n     ReplicaInfo replicaInfo \u003d volumeMap.get(b.getBlockPoolId(),\n         b.getBlockId());\n     if (replicaInfo !\u003d null) {\n       throw new ReplicaAlreadyExistsException(\"Block \" + b +\n       \" already exists in state \" + replicaInfo.getState() +\n       \" and thus cannot be created.\");\n     }\n     // create a new block\n-    FsVolumeReference ref;\n-    while (true) {\n+    FsVolumeReference ref \u003d null;\n+\n+    // Use ramdisk only if block size is a multiple of OS page size.\n+    // This simplifies reservation for partially used replicas\n+    // significantly.\n+    if (allowLazyPersist \u0026\u0026\n+        lazyWriter !\u003d null \u0026\u0026\n+        b.getNumBytes() % cacheManager.getOsPageSize() \u003d\u003d 0 \u0026\u0026\n+        (cacheManager.reserve(b.getNumBytes())) \u003e 0) {\n       try {\n-        if (allowLazyPersist) {\n-          // First try to place the block on a transient volume.\n-          ref \u003d volumes.getNextTransientVolume(b.getNumBytes());\n-          datanode.getMetrics().incrRamDiskBlocksWrite();\n-        } else {\n-          ref \u003d volumes.getNextVolume(storageType, b.getNumBytes());\n+        // First try to place the block on a transient volume.\n+        ref \u003d volumes.getNextTransientVolume(b.getNumBytes());\n+        datanode.getMetrics().incrRamDiskBlocksWrite();\n+      } catch(DiskOutOfSpaceException de) {\n+        // Ignore the exception since we just fall back to persistent storage.\n+        datanode.getMetrics().incrRamDiskBlocksWriteFallback();\n+      } finally {\n+        if (ref \u003d\u003d null) {\n+          cacheManager.release(b.getNumBytes());\n         }\n-      } catch (DiskOutOfSpaceException de) {\n-        if (allowLazyPersist) {\n-          datanode.getMetrics().incrRamDiskBlocksWriteFallback();\n-          allowLazyPersist \u003d false;\n-          continue;\n-        }\n-        throw de;\n       }\n-      break;\n     }\n+\n+    if (ref \u003d\u003d null) {\n+      ref \u003d volumes.getNextVolume(storageType, b.getNumBytes());\n+    }\n+\n     FsVolumeImpl v \u003d (FsVolumeImpl) ref.getVolume();\n     // create an rbw file to hold block in the designated volume\n     File f;\n     try {\n       f \u003d v.createRbwFile(b.getBlockPoolId(), b.getLocalBlock());\n     } catch (IOException e) {\n       IOUtils.cleanup(null, ref);\n       throw e;\n     }\n \n     ReplicaBeingWritten newReplicaInfo \u003d new ReplicaBeingWritten(b.getBlockId(), \n         b.getGenerationStamp(), v, f.getParentFile(), b.getNumBytes());\n     volumeMap.add(b.getBlockPoolId(), newReplicaInfo);\n     return new ReplicaHandler(newReplicaInfo, ref);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized ReplicaHandler createRbw(\n      StorageType storageType, ExtendedBlock b, boolean allowLazyPersist)\n      throws IOException {\n    ReplicaInfo replicaInfo \u003d volumeMap.get(b.getBlockPoolId(),\n        b.getBlockId());\n    if (replicaInfo !\u003d null) {\n      throw new ReplicaAlreadyExistsException(\"Block \" + b +\n      \" already exists in state \" + replicaInfo.getState() +\n      \" and thus cannot be created.\");\n    }\n    // create a new block\n    FsVolumeReference ref \u003d null;\n\n    // Use ramdisk only if block size is a multiple of OS page size.\n    // This simplifies reservation for partially used replicas\n    // significantly.\n    if (allowLazyPersist \u0026\u0026\n        lazyWriter !\u003d null \u0026\u0026\n        b.getNumBytes() % cacheManager.getOsPageSize() \u003d\u003d 0 \u0026\u0026\n        (cacheManager.reserve(b.getNumBytes())) \u003e 0) {\n      try {\n        // First try to place the block on a transient volume.\n        ref \u003d volumes.getNextTransientVolume(b.getNumBytes());\n        datanode.getMetrics().incrRamDiskBlocksWrite();\n      } catch(DiskOutOfSpaceException de) {\n        // Ignore the exception since we just fall back to persistent storage.\n        datanode.getMetrics().incrRamDiskBlocksWriteFallback();\n      } finally {\n        if (ref \u003d\u003d null) {\n          cacheManager.release(b.getNumBytes());\n        }\n      }\n    }\n\n    if (ref \u003d\u003d null) {\n      ref \u003d volumes.getNextVolume(storageType, b.getNumBytes());\n    }\n\n    FsVolumeImpl v \u003d (FsVolumeImpl) ref.getVolume();\n    // create an rbw file to hold block in the designated volume\n    File f;\n    try {\n      f \u003d v.createRbwFile(b.getBlockPoolId(), b.getLocalBlock());\n    } catch (IOException e) {\n      IOUtils.cleanup(null, ref);\n      throw e;\n    }\n\n    ReplicaBeingWritten newReplicaInfo \u003d new ReplicaBeingWritten(b.getBlockId(), \n        b.getGenerationStamp(), v, f.getParentFile(), b.getNumBytes());\n    volumeMap.add(b.getBlockPoolId(), newReplicaInfo);\n    return new ReplicaHandler(newReplicaInfo, ref);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "b7f4a3156c0f5c600816c469637237ba6c9b330c": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-7496. Fix FsVolume removal race conditions on the DataNode by reference-counting the volume instances (lei via cmccabe)\n",
      "commitDate": "20/01/15 7:05 PM",
      "commitName": "b7f4a3156c0f5c600816c469637237ba6c9b330c",
      "commitAuthor": "Colin Patrick Mccabe",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-7496. Fix FsVolume removal race conditions on the DataNode by reference-counting the volume instances (lei via cmccabe)\n",
          "commitDate": "20/01/15 7:05 PM",
          "commitName": "b7f4a3156c0f5c600816c469637237ba6c9b330c",
          "commitAuthor": "Colin Patrick Mccabe",
          "commitDateOld": "13/01/15 12:24 AM",
          "commitNameOld": "08ac06283a3e9bf0d49d873823aabd419b08e41f",
          "commitAuthorOld": "Konstantin V Shvachko",
          "daysBetweenCommits": 7.78,
          "commitsBetweenForRepo": 49,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,38 +1,46 @@\n-  public synchronized ReplicaInPipeline createRbw(StorageType storageType,\n-      ExtendedBlock b, boolean allowLazyPersist) throws IOException {\n+  public synchronized ReplicaHandler createRbw(\n+      StorageType storageType, ExtendedBlock b, boolean allowLazyPersist)\n+      throws IOException {\n     ReplicaInfo replicaInfo \u003d volumeMap.get(b.getBlockPoolId(),\n         b.getBlockId());\n     if (replicaInfo !\u003d null) {\n       throw new ReplicaAlreadyExistsException(\"Block \" + b +\n       \" already exists in state \" + replicaInfo.getState() +\n       \" and thus cannot be created.\");\n     }\n     // create a new block\n-    FsVolumeImpl v;\n+    FsVolumeReference ref;\n     while (true) {\n       try {\n         if (allowLazyPersist) {\n           // First try to place the block on a transient volume.\n-          v \u003d volumes.getNextTransientVolume(b.getNumBytes());\n+          ref \u003d volumes.getNextTransientVolume(b.getNumBytes());\n           datanode.getMetrics().incrRamDiskBlocksWrite();\n         } else {\n-          v \u003d volumes.getNextVolume(storageType, b.getNumBytes());\n+          ref \u003d volumes.getNextVolume(storageType, b.getNumBytes());\n         }\n       } catch (DiskOutOfSpaceException de) {\n         if (allowLazyPersist) {\n           datanode.getMetrics().incrRamDiskBlocksWriteFallback();\n           allowLazyPersist \u003d false;\n           continue;\n         }\n         throw de;\n       }\n       break;\n     }\n+    FsVolumeImpl v \u003d (FsVolumeImpl) ref.getVolume();\n     // create an rbw file to hold block in the designated volume\n-    File f \u003d v.createRbwFile(b.getBlockPoolId(), b.getLocalBlock());\n+    File f;\n+    try {\n+      f \u003d v.createRbwFile(b.getBlockPoolId(), b.getLocalBlock());\n+    } catch (IOException e) {\n+      IOUtils.cleanup(null, ref);\n+      throw e;\n+    }\n+\n     ReplicaBeingWritten newReplicaInfo \u003d new ReplicaBeingWritten(b.getBlockId(), \n         b.getGenerationStamp(), v, f.getParentFile(), b.getNumBytes());\n     volumeMap.add(b.getBlockPoolId(), newReplicaInfo);\n-\n-    return newReplicaInfo;\n+    return new ReplicaHandler(newReplicaInfo, ref);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public synchronized ReplicaHandler createRbw(\n      StorageType storageType, ExtendedBlock b, boolean allowLazyPersist)\n      throws IOException {\n    ReplicaInfo replicaInfo \u003d volumeMap.get(b.getBlockPoolId(),\n        b.getBlockId());\n    if (replicaInfo !\u003d null) {\n      throw new ReplicaAlreadyExistsException(\"Block \" + b +\n      \" already exists in state \" + replicaInfo.getState() +\n      \" and thus cannot be created.\");\n    }\n    // create a new block\n    FsVolumeReference ref;\n    while (true) {\n      try {\n        if (allowLazyPersist) {\n          // First try to place the block on a transient volume.\n          ref \u003d volumes.getNextTransientVolume(b.getNumBytes());\n          datanode.getMetrics().incrRamDiskBlocksWrite();\n        } else {\n          ref \u003d volumes.getNextVolume(storageType, b.getNumBytes());\n        }\n      } catch (DiskOutOfSpaceException de) {\n        if (allowLazyPersist) {\n          datanode.getMetrics().incrRamDiskBlocksWriteFallback();\n          allowLazyPersist \u003d false;\n          continue;\n        }\n        throw de;\n      }\n      break;\n    }\n    FsVolumeImpl v \u003d (FsVolumeImpl) ref.getVolume();\n    // create an rbw file to hold block in the designated volume\n    File f;\n    try {\n      f \u003d v.createRbwFile(b.getBlockPoolId(), b.getLocalBlock());\n    } catch (IOException e) {\n      IOUtils.cleanup(null, ref);\n      throw e;\n    }\n\n    ReplicaBeingWritten newReplicaInfo \u003d new ReplicaBeingWritten(b.getBlockId(), \n        b.getGenerationStamp(), v, f.getParentFile(), b.getNumBytes());\n    volumeMap.add(b.getBlockPoolId(), newReplicaInfo);\n    return new ReplicaHandler(newReplicaInfo, ref);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
          "extendedDetails": {
            "oldValue": "ReplicaInPipeline",
            "newValue": "ReplicaHandler"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7496. Fix FsVolume removal race conditions on the DataNode by reference-counting the volume instances (lei via cmccabe)\n",
          "commitDate": "20/01/15 7:05 PM",
          "commitName": "b7f4a3156c0f5c600816c469637237ba6c9b330c",
          "commitAuthor": "Colin Patrick Mccabe",
          "commitDateOld": "13/01/15 12:24 AM",
          "commitNameOld": "08ac06283a3e9bf0d49d873823aabd419b08e41f",
          "commitAuthorOld": "Konstantin V Shvachko",
          "daysBetweenCommits": 7.78,
          "commitsBetweenForRepo": 49,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,38 +1,46 @@\n-  public synchronized ReplicaInPipeline createRbw(StorageType storageType,\n-      ExtendedBlock b, boolean allowLazyPersist) throws IOException {\n+  public synchronized ReplicaHandler createRbw(\n+      StorageType storageType, ExtendedBlock b, boolean allowLazyPersist)\n+      throws IOException {\n     ReplicaInfo replicaInfo \u003d volumeMap.get(b.getBlockPoolId(),\n         b.getBlockId());\n     if (replicaInfo !\u003d null) {\n       throw new ReplicaAlreadyExistsException(\"Block \" + b +\n       \" already exists in state \" + replicaInfo.getState() +\n       \" and thus cannot be created.\");\n     }\n     // create a new block\n-    FsVolumeImpl v;\n+    FsVolumeReference ref;\n     while (true) {\n       try {\n         if (allowLazyPersist) {\n           // First try to place the block on a transient volume.\n-          v \u003d volumes.getNextTransientVolume(b.getNumBytes());\n+          ref \u003d volumes.getNextTransientVolume(b.getNumBytes());\n           datanode.getMetrics().incrRamDiskBlocksWrite();\n         } else {\n-          v \u003d volumes.getNextVolume(storageType, b.getNumBytes());\n+          ref \u003d volumes.getNextVolume(storageType, b.getNumBytes());\n         }\n       } catch (DiskOutOfSpaceException de) {\n         if (allowLazyPersist) {\n           datanode.getMetrics().incrRamDiskBlocksWriteFallback();\n           allowLazyPersist \u003d false;\n           continue;\n         }\n         throw de;\n       }\n       break;\n     }\n+    FsVolumeImpl v \u003d (FsVolumeImpl) ref.getVolume();\n     // create an rbw file to hold block in the designated volume\n-    File f \u003d v.createRbwFile(b.getBlockPoolId(), b.getLocalBlock());\n+    File f;\n+    try {\n+      f \u003d v.createRbwFile(b.getBlockPoolId(), b.getLocalBlock());\n+    } catch (IOException e) {\n+      IOUtils.cleanup(null, ref);\n+      throw e;\n+    }\n+\n     ReplicaBeingWritten newReplicaInfo \u003d new ReplicaBeingWritten(b.getBlockId(), \n         b.getGenerationStamp(), v, f.getParentFile(), b.getNumBytes());\n     volumeMap.add(b.getBlockPoolId(), newReplicaInfo);\n-\n-    return newReplicaInfo;\n+    return new ReplicaHandler(newReplicaInfo, ref);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public synchronized ReplicaHandler createRbw(\n      StorageType storageType, ExtendedBlock b, boolean allowLazyPersist)\n      throws IOException {\n    ReplicaInfo replicaInfo \u003d volumeMap.get(b.getBlockPoolId(),\n        b.getBlockId());\n    if (replicaInfo !\u003d null) {\n      throw new ReplicaAlreadyExistsException(\"Block \" + b +\n      \" already exists in state \" + replicaInfo.getState() +\n      \" and thus cannot be created.\");\n    }\n    // create a new block\n    FsVolumeReference ref;\n    while (true) {\n      try {\n        if (allowLazyPersist) {\n          // First try to place the block on a transient volume.\n          ref \u003d volumes.getNextTransientVolume(b.getNumBytes());\n          datanode.getMetrics().incrRamDiskBlocksWrite();\n        } else {\n          ref \u003d volumes.getNextVolume(storageType, b.getNumBytes());\n        }\n      } catch (DiskOutOfSpaceException de) {\n        if (allowLazyPersist) {\n          datanode.getMetrics().incrRamDiskBlocksWriteFallback();\n          allowLazyPersist \u003d false;\n          continue;\n        }\n        throw de;\n      }\n      break;\n    }\n    FsVolumeImpl v \u003d (FsVolumeImpl) ref.getVolume();\n    // create an rbw file to hold block in the designated volume\n    File f;\n    try {\n      f \u003d v.createRbwFile(b.getBlockPoolId(), b.getLocalBlock());\n    } catch (IOException e) {\n      IOUtils.cleanup(null, ref);\n      throw e;\n    }\n\n    ReplicaBeingWritten newReplicaInfo \u003d new ReplicaBeingWritten(b.getBlockId(), \n        b.getGenerationStamp(), v, f.getParentFile(), b.getNumBytes());\n    volumeMap.add(b.getBlockPoolId(), newReplicaInfo);\n    return new ReplicaHandler(newReplicaInfo, ref);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
          "extendedDetails": {}
        }
      ]
    },
    "5e8b6973527e5f714652641ed95e8a4509e18cfa": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7129. Metrics to track usage of memory for writes. (Contributed by Xiaoyu Yao)\n",
      "commitDate": "30/09/14 12:53 AM",
      "commitName": "5e8b6973527e5f714652641ed95e8a4509e18cfa",
      "commitAuthor": "arp",
      "commitDateOld": "29/09/14 10:27 PM",
      "commitNameOld": "bb84f1fccb18c6c7373851e05d2451d55e908242",
      "commitAuthorOld": "arp",
      "daysBetweenCommits": 0.1,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,36 +1,38 @@\n   public synchronized ReplicaInPipeline createRbw(StorageType storageType,\n       ExtendedBlock b, boolean allowLazyPersist) throws IOException {\n     ReplicaInfo replicaInfo \u003d volumeMap.get(b.getBlockPoolId(),\n         b.getBlockId());\n     if (replicaInfo !\u003d null) {\n       throw new ReplicaAlreadyExistsException(\"Block \" + b +\n       \" already exists in state \" + replicaInfo.getState() +\n       \" and thus cannot be created.\");\n     }\n     // create a new block\n     FsVolumeImpl v;\n     while (true) {\n       try {\n         if (allowLazyPersist) {\n           // First try to place the block on a transient volume.\n           v \u003d volumes.getNextTransientVolume(b.getNumBytes());\n+          datanode.getMetrics().incrRamDiskBlocksWrite();\n         } else {\n           v \u003d volumes.getNextVolume(storageType, b.getNumBytes());\n         }\n       } catch (DiskOutOfSpaceException de) {\n         if (allowLazyPersist) {\n+          datanode.getMetrics().incrRamDiskBlocksWriteFallback();\n           allowLazyPersist \u003d false;\n           continue;\n         }\n         throw de;\n       }\n       break;\n     }\n     // create an rbw file to hold block in the designated volume\n     File f \u003d v.createRbwFile(b.getBlockPoolId(), b.getLocalBlock());\n     ReplicaBeingWritten newReplicaInfo \u003d new ReplicaBeingWritten(b.getBlockId(), \n         b.getGenerationStamp(), v, f.getParentFile(), b.getNumBytes());\n     volumeMap.add(b.getBlockPoolId(), newReplicaInfo);\n \n     return newReplicaInfo;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized ReplicaInPipeline createRbw(StorageType storageType,\n      ExtendedBlock b, boolean allowLazyPersist) throws IOException {\n    ReplicaInfo replicaInfo \u003d volumeMap.get(b.getBlockPoolId(),\n        b.getBlockId());\n    if (replicaInfo !\u003d null) {\n      throw new ReplicaAlreadyExistsException(\"Block \" + b +\n      \" already exists in state \" + replicaInfo.getState() +\n      \" and thus cannot be created.\");\n    }\n    // create a new block\n    FsVolumeImpl v;\n    while (true) {\n      try {\n        if (allowLazyPersist) {\n          // First try to place the block on a transient volume.\n          v \u003d volumes.getNextTransientVolume(b.getNumBytes());\n          datanode.getMetrics().incrRamDiskBlocksWrite();\n        } else {\n          v \u003d volumes.getNextVolume(storageType, b.getNumBytes());\n        }\n      } catch (DiskOutOfSpaceException de) {\n        if (allowLazyPersist) {\n          datanode.getMetrics().incrRamDiskBlocksWriteFallback();\n          allowLazyPersist \u003d false;\n          continue;\n        }\n        throw de;\n      }\n      break;\n    }\n    // create an rbw file to hold block in the designated volume\n    File f \u003d v.createRbwFile(b.getBlockPoolId(), b.getLocalBlock());\n    ReplicaBeingWritten newReplicaInfo \u003d new ReplicaBeingWritten(b.getBlockId(), \n        b.getGenerationStamp(), v, f.getParentFile(), b.getNumBytes());\n    volumeMap.add(b.getBlockPoolId(), newReplicaInfo);\n\n    return newReplicaInfo;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    }
  }
}