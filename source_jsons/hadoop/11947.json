{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FsDatasetImpl.java",
  "functionName": "addVolume",
  "functionId": "addVolume___location-StorageLocation(modifiers-final)__nsInfos-List__NamespaceInfo__(modifiers-final)",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
  "functionStartLine": 500,
  "functionEndLine": 547,
  "numCommitsSeen": 314,
  "timeTaken": 11200,
  "changeHistory": [
    "d7c136b9ed6d99e1b03f5b89723b3a20df359ba8",
    "96b12662ea76e3ded4ef13944fc8df206cfb4613",
    "8ae4729107d33c6001cf1fdc8837afb71ea6c0d3",
    "04375756a5ed6e907ee7548469c2c508aebbafb7",
    "c07f7fa8ff752436726239d938e0461236839acf",
    "5c1036d598051cf6af595740f1ab82092b0b6554",
    "9729b244de50322c2cc889c97c2ffb2b4675cf77",
    "6e62a1a6728b1f782f64065424f92b292c3f163a",
    "a17584936cc5141e3f5612ac3ecf35e27968e439",
    "a9331fe9b071fdcdae0c6c747d7b6b306142e671",
    "1efd9c98258fbb973d2058dcf0850042e53bd02f",
    "fe38d2e9b5ac7e13f97cd2d3d2a984ab6bbaaf77",
    "d758be1f35f6c1c7e9edd491af559721a3b8b8f8"
  ],
  "changeHistoryShort": {
    "d7c136b9ed6d99e1b03f5b89723b3a20df359ba8": "Ybodychange",
    "96b12662ea76e3ded4ef13944fc8df206cfb4613": "Ybodychange",
    "8ae4729107d33c6001cf1fdc8837afb71ea6c0d3": "Ybodychange",
    "04375756a5ed6e907ee7548469c2c508aebbafb7": "Ybodychange",
    "c07f7fa8ff752436726239d938e0461236839acf": "Ybodychange",
    "5c1036d598051cf6af595740f1ab82092b0b6554": "Ybodychange",
    "9729b244de50322c2cc889c97c2ffb2b4675cf77": "Ybodychange",
    "6e62a1a6728b1f782f64065424f92b292c3f163a": "Ybodychange",
    "a17584936cc5141e3f5612ac3ecf35e27968e439": "Ybodychange",
    "a9331fe9b071fdcdae0c6c747d7b6b306142e671": "Ymultichange(Yrename,Yparameterchange,Yreturntypechange,Ymodifierchange,Yexceptionschange,Ybodychange)",
    "1efd9c98258fbb973d2058dcf0850042e53bd02f": "Ybodychange",
    "fe38d2e9b5ac7e13f97cd2d3d2a984ab6bbaaf77": "Ymultichange(Yparameterchange,Yreturntypechange,Yexceptionschange,Ybodychange)",
    "d758be1f35f6c1c7e9edd491af559721a3b8b8f8": "Yintroduced"
  },
  "changeHistoryDetails": {
    "d7c136b9ed6d99e1b03f5b89723b3a20df359ba8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-15150. Introduce read write lock to Datanode. Contributed Stephen O\u0027Donnell.\n\nSigned-off-by: Wei-Chiu Chuang \u003cweichiu@apache.org\u003e\n",
      "commitDate": "11/02/20 8:00 AM",
      "commitName": "d7c136b9ed6d99e1b03f5b89723b3a20df359ba8",
      "commitAuthor": "Stephen O\u0027Donnell",
      "commitDateOld": "28/01/20 10:10 AM",
      "commitNameOld": "1839c467f60cbb8592d446694ec3d7710cda5142",
      "commitAuthorOld": "Inigo Goiri",
      "daysBetweenCommits": 13.91,
      "commitsBetweenForRepo": 33,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,47 +1,48 @@\n   public void addVolume(final StorageLocation location,\n       final List\u003cNamespaceInfo\u003e nsInfos)\n       throws IOException {\n     // Prepare volume in DataStorage\n     final DataStorage.VolumeBuilder builder;\n     try {\n       builder \u003d dataStorage.prepareVolume(datanode, location, nsInfos);\n     } catch (IOException e) {\n       volumes.addVolumeFailureInfo(new VolumeFailureInfo(location, Time.now()));\n       throw e;\n     }\n \n     final Storage.StorageDirectory sd \u003d builder.getStorageDirectory();\n \n     StorageType storageType \u003d location.getStorageType();\n     final FsVolumeImpl fsVolume \u003d\n         createFsVolume(sd.getStorageUuid(), sd, location);\n-    final ReplicaMap tempVolumeMap \u003d new ReplicaMap(new AutoCloseableLock());\n+    final ReplicaMap tempVolumeMap \u003d\n+        new ReplicaMap(new ReentrantReadWriteLock());\n     ArrayList\u003cIOException\u003e exceptions \u003d Lists.newArrayList();\n \n     for (final NamespaceInfo nsInfo : nsInfos) {\n       String bpid \u003d nsInfo.getBlockPoolID();\n       try {\n         fsVolume.addBlockPool(bpid, this.conf, this.timer);\n         fsVolume.getVolumeMap(bpid, tempVolumeMap, ramDiskReplicaTracker);\n       } catch (IOException e) {\n         LOG.warn(\"Caught exception when adding \" + fsVolume +\n             \". Will throw later.\", e);\n         exceptions.add(e);\n       }\n     }\n     if (!exceptions.isEmpty()) {\n       try {\n         sd.unlock();\n       } catch (IOException e) {\n         exceptions.add(e);\n       }\n       throw MultipleIOException.createIOException(exceptions);\n     }\n \n     final FsVolumeReference ref \u003d fsVolume.obtainReference();\n     setupAsyncLazyPersistThread(fsVolume);\n \n     builder.build();\n     activateVolume(tempVolumeMap, sd, storageType, ref);\n     LOG.info(\"Added volume - \" + location + \", StorageType: \" + storageType);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void addVolume(final StorageLocation location,\n      final List\u003cNamespaceInfo\u003e nsInfos)\n      throws IOException {\n    // Prepare volume in DataStorage\n    final DataStorage.VolumeBuilder builder;\n    try {\n      builder \u003d dataStorage.prepareVolume(datanode, location, nsInfos);\n    } catch (IOException e) {\n      volumes.addVolumeFailureInfo(new VolumeFailureInfo(location, Time.now()));\n      throw e;\n    }\n\n    final Storage.StorageDirectory sd \u003d builder.getStorageDirectory();\n\n    StorageType storageType \u003d location.getStorageType();\n    final FsVolumeImpl fsVolume \u003d\n        createFsVolume(sd.getStorageUuid(), sd, location);\n    final ReplicaMap tempVolumeMap \u003d\n        new ReplicaMap(new ReentrantReadWriteLock());\n    ArrayList\u003cIOException\u003e exceptions \u003d Lists.newArrayList();\n\n    for (final NamespaceInfo nsInfo : nsInfos) {\n      String bpid \u003d nsInfo.getBlockPoolID();\n      try {\n        fsVolume.addBlockPool(bpid, this.conf, this.timer);\n        fsVolume.getVolumeMap(bpid, tempVolumeMap, ramDiskReplicaTracker);\n      } catch (IOException e) {\n        LOG.warn(\"Caught exception when adding \" + fsVolume +\n            \". Will throw later.\", e);\n        exceptions.add(e);\n      }\n    }\n    if (!exceptions.isEmpty()) {\n      try {\n        sd.unlock();\n      } catch (IOException e) {\n        exceptions.add(e);\n      }\n      throw MultipleIOException.createIOException(exceptions);\n    }\n\n    final FsVolumeReference ref \u003d fsVolume.obtainReference();\n    setupAsyncLazyPersistThread(fsVolume);\n\n    builder.build();\n    activateVolume(tempVolumeMap, sd, storageType, ref);\n    LOG.info(\"Added volume - \" + location + \", StorageType: \" + storageType);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "96b12662ea76e3ded4ef13944fc8df206cfb4613": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10637. Modifications to remove the assumption that FsVolumes are backed by java.io.File. (Virajith Jalaparti via lei)\n",
      "commitDate": "10/10/16 3:30 PM",
      "commitName": "96b12662ea76e3ded4ef13944fc8df206cfb4613",
      "commitAuthor": "Lei Xu",
      "commitDateOld": "30/09/16 11:11 PM",
      "commitNameOld": "fe9ebe20ab113567f0777c11cb48ce0d3ce587a8",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 9.68,
      "commitsBetweenForRepo": 64,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,50 +1,47 @@\n   public void addVolume(final StorageLocation location,\n       final List\u003cNamespaceInfo\u003e nsInfos)\n       throws IOException {\n-    final File dir \u003d location.getFile();\n-\n     // Prepare volume in DataStorage\n     final DataStorage.VolumeBuilder builder;\n     try {\n-      builder \u003d dataStorage.prepareVolume(datanode, location.getFile(), nsInfos);\n+      builder \u003d dataStorage.prepareVolume(datanode, location, nsInfos);\n     } catch (IOException e) {\n-      volumes.addVolumeFailureInfo(new VolumeFailureInfo(\n-          location.getFile().getAbsolutePath(), Time.now()));\n+      volumes.addVolumeFailureInfo(new VolumeFailureInfo(location, Time.now()));\n       throw e;\n     }\n \n     final Storage.StorageDirectory sd \u003d builder.getStorageDirectory();\n \n     StorageType storageType \u003d location.getStorageType();\n     final FsVolumeImpl fsVolume \u003d\n-        createFsVolume(sd.getStorageUuid(), sd.getCurrentDir(), storageType);\n+        createFsVolume(sd.getStorageUuid(), sd, location);\n     final ReplicaMap tempVolumeMap \u003d new ReplicaMap(new AutoCloseableLock());\n     ArrayList\u003cIOException\u003e exceptions \u003d Lists.newArrayList();\n \n     for (final NamespaceInfo nsInfo : nsInfos) {\n       String bpid \u003d nsInfo.getBlockPoolID();\n       try {\n         fsVolume.addBlockPool(bpid, this.conf, this.timer);\n         fsVolume.getVolumeMap(bpid, tempVolumeMap, ramDiskReplicaTracker);\n       } catch (IOException e) {\n         LOG.warn(\"Caught exception when adding \" + fsVolume +\n             \". Will throw later.\", e);\n         exceptions.add(e);\n       }\n     }\n     if (!exceptions.isEmpty()) {\n       try {\n         sd.unlock();\n       } catch (IOException e) {\n         exceptions.add(e);\n       }\n       throw MultipleIOException.createIOException(exceptions);\n     }\n \n     final FsVolumeReference ref \u003d fsVolume.obtainReference();\n     setupAsyncLazyPersistThread(fsVolume);\n \n     builder.build();\n     activateVolume(tempVolumeMap, sd, storageType, ref);\n-    LOG.info(\"Added volume - \" + dir + \", StorageType: \" + storageType);\n+    LOG.info(\"Added volume - \" + location + \", StorageType: \" + storageType);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void addVolume(final StorageLocation location,\n      final List\u003cNamespaceInfo\u003e nsInfos)\n      throws IOException {\n    // Prepare volume in DataStorage\n    final DataStorage.VolumeBuilder builder;\n    try {\n      builder \u003d dataStorage.prepareVolume(datanode, location, nsInfos);\n    } catch (IOException e) {\n      volumes.addVolumeFailureInfo(new VolumeFailureInfo(location, Time.now()));\n      throw e;\n    }\n\n    final Storage.StorageDirectory sd \u003d builder.getStorageDirectory();\n\n    StorageType storageType \u003d location.getStorageType();\n    final FsVolumeImpl fsVolume \u003d\n        createFsVolume(sd.getStorageUuid(), sd, location);\n    final ReplicaMap tempVolumeMap \u003d new ReplicaMap(new AutoCloseableLock());\n    ArrayList\u003cIOException\u003e exceptions \u003d Lists.newArrayList();\n\n    for (final NamespaceInfo nsInfo : nsInfos) {\n      String bpid \u003d nsInfo.getBlockPoolID();\n      try {\n        fsVolume.addBlockPool(bpid, this.conf, this.timer);\n        fsVolume.getVolumeMap(bpid, tempVolumeMap, ramDiskReplicaTracker);\n      } catch (IOException e) {\n        LOG.warn(\"Caught exception when adding \" + fsVolume +\n            \". Will throw later.\", e);\n        exceptions.add(e);\n      }\n    }\n    if (!exceptions.isEmpty()) {\n      try {\n        sd.unlock();\n      } catch (IOException e) {\n        exceptions.add(e);\n      }\n      throw MultipleIOException.createIOException(exceptions);\n    }\n\n    final FsVolumeReference ref \u003d fsVolume.obtainReference();\n    setupAsyncLazyPersistThread(fsVolume);\n\n    builder.build();\n    activateVolume(tempVolumeMap, sd, storageType, ref);\n    LOG.info(\"Added volume - \" + location + \", StorageType: \" + storageType);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "8ae4729107d33c6001cf1fdc8837afb71ea6c0d3": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10828. Fix usage of FsDatasetImpl object lock in ReplicaMap. (Arpit Agarwal)\n",
      "commitDate": "27/09/16 10:02 AM",
      "commitName": "8ae4729107d33c6001cf1fdc8837afb71ea6c0d3",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "13/09/16 12:54 PM",
      "commitNameOld": "86c9862bec0248d671e657aa56094a2919b8ac14",
      "commitAuthorOld": "Lei Xu",
      "daysBetweenCommits": 13.88,
      "commitsBetweenForRepo": 72,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,50 +1,50 @@\n   public void addVolume(final StorageLocation location,\n       final List\u003cNamespaceInfo\u003e nsInfos)\n       throws IOException {\n     final File dir \u003d location.getFile();\n \n     // Prepare volume in DataStorage\n     final DataStorage.VolumeBuilder builder;\n     try {\n       builder \u003d dataStorage.prepareVolume(datanode, location.getFile(), nsInfos);\n     } catch (IOException e) {\n       volumes.addVolumeFailureInfo(new VolumeFailureInfo(\n           location.getFile().getAbsolutePath(), Time.now()));\n       throw e;\n     }\n \n     final Storage.StorageDirectory sd \u003d builder.getStorageDirectory();\n \n     StorageType storageType \u003d location.getStorageType();\n     final FsVolumeImpl fsVolume \u003d\n         createFsVolume(sd.getStorageUuid(), sd.getCurrentDir(), storageType);\n-    final ReplicaMap tempVolumeMap \u003d new ReplicaMap(fsVolume);\n+    final ReplicaMap tempVolumeMap \u003d new ReplicaMap(new AutoCloseableLock());\n     ArrayList\u003cIOException\u003e exceptions \u003d Lists.newArrayList();\n \n     for (final NamespaceInfo nsInfo : nsInfos) {\n       String bpid \u003d nsInfo.getBlockPoolID();\n       try {\n         fsVolume.addBlockPool(bpid, this.conf, this.timer);\n         fsVolume.getVolumeMap(bpid, tempVolumeMap, ramDiskReplicaTracker);\n       } catch (IOException e) {\n         LOG.warn(\"Caught exception when adding \" + fsVolume +\n             \". Will throw later.\", e);\n         exceptions.add(e);\n       }\n     }\n     if (!exceptions.isEmpty()) {\n       try {\n         sd.unlock();\n       } catch (IOException e) {\n         exceptions.add(e);\n       }\n       throw MultipleIOException.createIOException(exceptions);\n     }\n \n     final FsVolumeReference ref \u003d fsVolume.obtainReference();\n     setupAsyncLazyPersistThread(fsVolume);\n \n     builder.build();\n     activateVolume(tempVolumeMap, sd, storageType, ref);\n     LOG.info(\"Added volume - \" + dir + \", StorageType: \" + storageType);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void addVolume(final StorageLocation location,\n      final List\u003cNamespaceInfo\u003e nsInfos)\n      throws IOException {\n    final File dir \u003d location.getFile();\n\n    // Prepare volume in DataStorage\n    final DataStorage.VolumeBuilder builder;\n    try {\n      builder \u003d dataStorage.prepareVolume(datanode, location.getFile(), nsInfos);\n    } catch (IOException e) {\n      volumes.addVolumeFailureInfo(new VolumeFailureInfo(\n          location.getFile().getAbsolutePath(), Time.now()));\n      throw e;\n    }\n\n    final Storage.StorageDirectory sd \u003d builder.getStorageDirectory();\n\n    StorageType storageType \u003d location.getStorageType();\n    final FsVolumeImpl fsVolume \u003d\n        createFsVolume(sd.getStorageUuid(), sd.getCurrentDir(), storageType);\n    final ReplicaMap tempVolumeMap \u003d new ReplicaMap(new AutoCloseableLock());\n    ArrayList\u003cIOException\u003e exceptions \u003d Lists.newArrayList();\n\n    for (final NamespaceInfo nsInfo : nsInfos) {\n      String bpid \u003d nsInfo.getBlockPoolID();\n      try {\n        fsVolume.addBlockPool(bpid, this.conf, this.timer);\n        fsVolume.getVolumeMap(bpid, tempVolumeMap, ramDiskReplicaTracker);\n      } catch (IOException e) {\n        LOG.warn(\"Caught exception when adding \" + fsVolume +\n            \". Will throw later.\", e);\n        exceptions.add(e);\n      }\n    }\n    if (!exceptions.isEmpty()) {\n      try {\n        sd.unlock();\n      } catch (IOException e) {\n        exceptions.add(e);\n      }\n      throw MultipleIOException.createIOException(exceptions);\n    }\n\n    final FsVolumeReference ref \u003d fsVolume.obtainReference();\n    setupAsyncLazyPersistThread(fsVolume);\n\n    builder.build();\n    activateVolume(tempVolumeMap, sd, storageType, ref);\n    LOG.info(\"Added volume - \" + dir + \", StorageType: \" + storageType);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "04375756a5ed6e907ee7548469c2c508aebbafb7": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9715. Check storage ID uniqueness on datanode startup (Contributed by Lei (Eddy) Xu)\n",
      "commitDate": "02/02/16 6:05 PM",
      "commitName": "04375756a5ed6e907ee7548469c2c508aebbafb7",
      "commitAuthor": "Vinayakumar B",
      "commitDateOld": "01/02/16 12:56 PM",
      "commitNameOld": "e50aa53eed3d0ff1bc8fe60381524bb3bbe53bc1",
      "commitAuthorOld": "Lei Xu",
      "daysBetweenCommits": 1.21,
      "commitsBetweenForRepo": 19,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,58 +1,50 @@\n   public void addVolume(final StorageLocation location,\n       final List\u003cNamespaceInfo\u003e nsInfos)\n       throws IOException {\n     final File dir \u003d location.getFile();\n \n     // Prepare volume in DataStorage\n     final DataStorage.VolumeBuilder builder;\n     try {\n       builder \u003d dataStorage.prepareVolume(datanode, location.getFile(), nsInfos);\n     } catch (IOException e) {\n       volumes.addVolumeFailureInfo(new VolumeFailureInfo(\n           location.getFile().getAbsolutePath(), Time.now()));\n       throw e;\n     }\n \n     final Storage.StorageDirectory sd \u003d builder.getStorageDirectory();\n \n     StorageType storageType \u003d location.getStorageType();\n     final FsVolumeImpl fsVolume \u003d\n         createFsVolume(sd.getStorageUuid(), sd.getCurrentDir(), storageType);\n     final ReplicaMap tempVolumeMap \u003d new ReplicaMap(fsVolume);\n     ArrayList\u003cIOException\u003e exceptions \u003d Lists.newArrayList();\n \n     for (final NamespaceInfo nsInfo : nsInfos) {\n       String bpid \u003d nsInfo.getBlockPoolID();\n       try {\n         fsVolume.addBlockPool(bpid, this.conf, this.timer);\n         fsVolume.getVolumeMap(bpid, tempVolumeMap, ramDiskReplicaTracker);\n       } catch (IOException e) {\n         LOG.warn(\"Caught exception when adding \" + fsVolume +\n             \". Will throw later.\", e);\n         exceptions.add(e);\n       }\n     }\n     if (!exceptions.isEmpty()) {\n       try {\n         sd.unlock();\n       } catch (IOException e) {\n         exceptions.add(e);\n       }\n       throw MultipleIOException.createIOException(exceptions);\n     }\n \n     final FsVolumeReference ref \u003d fsVolume.obtainReference();\n     setupAsyncLazyPersistThread(fsVolume);\n \n     builder.build();\n-    synchronized (this) {\n-      volumeMap.addAll(tempVolumeMap);\n-      storageMap.put(sd.getStorageUuid(),\n-          new DatanodeStorage(sd.getStorageUuid(),\n-              DatanodeStorage.State.NORMAL,\n-              storageType));\n-      asyncDiskService.addVolume(sd.getCurrentDir());\n-      volumes.addVolume(ref);\n-    }\n+    activateVolume(tempVolumeMap, sd, storageType, ref);\n     LOG.info(\"Added volume - \" + dir + \", StorageType: \" + storageType);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void addVolume(final StorageLocation location,\n      final List\u003cNamespaceInfo\u003e nsInfos)\n      throws IOException {\n    final File dir \u003d location.getFile();\n\n    // Prepare volume in DataStorage\n    final DataStorage.VolumeBuilder builder;\n    try {\n      builder \u003d dataStorage.prepareVolume(datanode, location.getFile(), nsInfos);\n    } catch (IOException e) {\n      volumes.addVolumeFailureInfo(new VolumeFailureInfo(\n          location.getFile().getAbsolutePath(), Time.now()));\n      throw e;\n    }\n\n    final Storage.StorageDirectory sd \u003d builder.getStorageDirectory();\n\n    StorageType storageType \u003d location.getStorageType();\n    final FsVolumeImpl fsVolume \u003d\n        createFsVolume(sd.getStorageUuid(), sd.getCurrentDir(), storageType);\n    final ReplicaMap tempVolumeMap \u003d new ReplicaMap(fsVolume);\n    ArrayList\u003cIOException\u003e exceptions \u003d Lists.newArrayList();\n\n    for (final NamespaceInfo nsInfo : nsInfos) {\n      String bpid \u003d nsInfo.getBlockPoolID();\n      try {\n        fsVolume.addBlockPool(bpid, this.conf, this.timer);\n        fsVolume.getVolumeMap(bpid, tempVolumeMap, ramDiskReplicaTracker);\n      } catch (IOException e) {\n        LOG.warn(\"Caught exception when adding \" + fsVolume +\n            \". Will throw later.\", e);\n        exceptions.add(e);\n      }\n    }\n    if (!exceptions.isEmpty()) {\n      try {\n        sd.unlock();\n      } catch (IOException e) {\n        exceptions.add(e);\n      }\n      throw MultipleIOException.createIOException(exceptions);\n    }\n\n    final FsVolumeReference ref \u003d fsVolume.obtainReference();\n    setupAsyncLazyPersistThread(fsVolume);\n\n    builder.build();\n    activateVolume(tempVolumeMap, sd, storageType, ref);\n    LOG.info(\"Added volume - \" + dir + \", StorageType: \" + storageType);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "c07f7fa8ff752436726239d938e0461236839acf": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9624. DataNode start slowly due to the initial DU command operations. (Lin Yiqun via wang)\n",
      "commitDate": "15/01/16 11:28 AM",
      "commitName": "c07f7fa8ff752436726239d938e0461236839acf",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "22/12/15 9:36 AM",
      "commitNameOld": "bb540ba85aa37d9fe31e640665158afe8a936230",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 24.08,
      "commitsBetweenForRepo": 122,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,58 +1,58 @@\n   public void addVolume(final StorageLocation location,\n       final List\u003cNamespaceInfo\u003e nsInfos)\n       throws IOException {\n     final File dir \u003d location.getFile();\n \n     // Prepare volume in DataStorage\n     final DataStorage.VolumeBuilder builder;\n     try {\n       builder \u003d dataStorage.prepareVolume(datanode, location.getFile(), nsInfos);\n     } catch (IOException e) {\n       volumes.addVolumeFailureInfo(new VolumeFailureInfo(\n           location.getFile().getAbsolutePath(), Time.now()));\n       throw e;\n     }\n \n     final Storage.StorageDirectory sd \u003d builder.getStorageDirectory();\n \n     StorageType storageType \u003d location.getStorageType();\n     final FsVolumeImpl fsVolume \u003d\n         createFsVolume(sd.getStorageUuid(), sd.getCurrentDir(), storageType);\n     final ReplicaMap tempVolumeMap \u003d new ReplicaMap(fsVolume);\n     ArrayList\u003cIOException\u003e exceptions \u003d Lists.newArrayList();\n \n     for (final NamespaceInfo nsInfo : nsInfos) {\n       String bpid \u003d nsInfo.getBlockPoolID();\n       try {\n-        fsVolume.addBlockPool(bpid, this.conf);\n+        fsVolume.addBlockPool(bpid, this.conf, this.timer);\n         fsVolume.getVolumeMap(bpid, tempVolumeMap, ramDiskReplicaTracker);\n       } catch (IOException e) {\n         LOG.warn(\"Caught exception when adding \" + fsVolume +\n             \". Will throw later.\", e);\n         exceptions.add(e);\n       }\n     }\n     if (!exceptions.isEmpty()) {\n       try {\n         sd.unlock();\n       } catch (IOException e) {\n         exceptions.add(e);\n       }\n       throw MultipleIOException.createIOException(exceptions);\n     }\n \n     final FsVolumeReference ref \u003d fsVolume.obtainReference();\n     setupAsyncLazyPersistThread(fsVolume);\n \n     builder.build();\n     synchronized (this) {\n       volumeMap.addAll(tempVolumeMap);\n       storageMap.put(sd.getStorageUuid(),\n           new DatanodeStorage(sd.getStorageUuid(),\n               DatanodeStorage.State.NORMAL,\n               storageType));\n       asyncDiskService.addVolume(sd.getCurrentDir());\n       volumes.addVolume(ref);\n     }\n     LOG.info(\"Added volume - \" + dir + \", StorageType: \" + storageType);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void addVolume(final StorageLocation location,\n      final List\u003cNamespaceInfo\u003e nsInfos)\n      throws IOException {\n    final File dir \u003d location.getFile();\n\n    // Prepare volume in DataStorage\n    final DataStorage.VolumeBuilder builder;\n    try {\n      builder \u003d dataStorage.prepareVolume(datanode, location.getFile(), nsInfos);\n    } catch (IOException e) {\n      volumes.addVolumeFailureInfo(new VolumeFailureInfo(\n          location.getFile().getAbsolutePath(), Time.now()));\n      throw e;\n    }\n\n    final Storage.StorageDirectory sd \u003d builder.getStorageDirectory();\n\n    StorageType storageType \u003d location.getStorageType();\n    final FsVolumeImpl fsVolume \u003d\n        createFsVolume(sd.getStorageUuid(), sd.getCurrentDir(), storageType);\n    final ReplicaMap tempVolumeMap \u003d new ReplicaMap(fsVolume);\n    ArrayList\u003cIOException\u003e exceptions \u003d Lists.newArrayList();\n\n    for (final NamespaceInfo nsInfo : nsInfos) {\n      String bpid \u003d nsInfo.getBlockPoolID();\n      try {\n        fsVolume.addBlockPool(bpid, this.conf, this.timer);\n        fsVolume.getVolumeMap(bpid, tempVolumeMap, ramDiskReplicaTracker);\n      } catch (IOException e) {\n        LOG.warn(\"Caught exception when adding \" + fsVolume +\n            \". Will throw later.\", e);\n        exceptions.add(e);\n      }\n    }\n    if (!exceptions.isEmpty()) {\n      try {\n        sd.unlock();\n      } catch (IOException e) {\n        exceptions.add(e);\n      }\n      throw MultipleIOException.createIOException(exceptions);\n    }\n\n    final FsVolumeReference ref \u003d fsVolume.obtainReference();\n    setupAsyncLazyPersistThread(fsVolume);\n\n    builder.build();\n    synchronized (this) {\n      volumeMap.addAll(tempVolumeMap);\n      storageMap.put(sd.getStorageUuid(),\n          new DatanodeStorage(sd.getStorageUuid(),\n              DatanodeStorage.State.NORMAL,\n              storageType));\n      asyncDiskService.addVolume(sd.getCurrentDir());\n      volumes.addVolume(ref);\n    }\n    LOG.info(\"Added volume - \" + dir + \", StorageType: \" + storageType);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "5c1036d598051cf6af595740f1ab82092b0b6554": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7830. DataNode does not release the volume lock when adding a volume fails. (Lei Xu via Colin P. McCabe)\n",
      "commitDate": "10/03/15 6:20 PM",
      "commitName": "5c1036d598051cf6af595740f1ab82092b0b6554",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "06/03/15 10:55 AM",
      "commitNameOld": "24db0812be64e83a48ade01fc1eaaeaedad4dec0",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 4.27,
      "commitsBetweenForRepo": 33,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,53 +1,58 @@\n   public void addVolume(final StorageLocation location,\n       final List\u003cNamespaceInfo\u003e nsInfos)\n       throws IOException {\n     final File dir \u003d location.getFile();\n \n     // Prepare volume in DataStorage\n     final DataStorage.VolumeBuilder builder;\n     try {\n       builder \u003d dataStorage.prepareVolume(datanode, location.getFile(), nsInfos);\n     } catch (IOException e) {\n       volumes.addVolumeFailureInfo(new VolumeFailureInfo(\n           location.getFile().getAbsolutePath(), Time.now()));\n       throw e;\n     }\n \n     final Storage.StorageDirectory sd \u003d builder.getStorageDirectory();\n \n     StorageType storageType \u003d location.getStorageType();\n-    final FsVolumeImpl fsVolume \u003d new FsVolumeImpl(\n-        this, sd.getStorageUuid(), sd.getCurrentDir(), this.conf, storageType);\n+    final FsVolumeImpl fsVolume \u003d\n+        createFsVolume(sd.getStorageUuid(), sd.getCurrentDir(), storageType);\n     final ReplicaMap tempVolumeMap \u003d new ReplicaMap(fsVolume);\n     ArrayList\u003cIOException\u003e exceptions \u003d Lists.newArrayList();\n \n     for (final NamespaceInfo nsInfo : nsInfos) {\n       String bpid \u003d nsInfo.getBlockPoolID();\n       try {\n         fsVolume.addBlockPool(bpid, this.conf);\n         fsVolume.getVolumeMap(bpid, tempVolumeMap, ramDiskReplicaTracker);\n       } catch (IOException e) {\n         LOG.warn(\"Caught exception when adding \" + fsVolume +\n             \". Will throw later.\", e);\n         exceptions.add(e);\n       }\n     }\n     if (!exceptions.isEmpty()) {\n+      try {\n+        sd.unlock();\n+      } catch (IOException e) {\n+        exceptions.add(e);\n+      }\n       throw MultipleIOException.createIOException(exceptions);\n     }\n \n     final FsVolumeReference ref \u003d fsVolume.obtainReference();\n     setupAsyncLazyPersistThread(fsVolume);\n \n     builder.build();\n     synchronized (this) {\n       volumeMap.addAll(tempVolumeMap);\n       storageMap.put(sd.getStorageUuid(),\n           new DatanodeStorage(sd.getStorageUuid(),\n               DatanodeStorage.State.NORMAL,\n               storageType));\n       asyncDiskService.addVolume(sd.getCurrentDir());\n       volumes.addVolume(ref);\n     }\n     LOG.info(\"Added volume - \" + dir + \", StorageType: \" + storageType);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void addVolume(final StorageLocation location,\n      final List\u003cNamespaceInfo\u003e nsInfos)\n      throws IOException {\n    final File dir \u003d location.getFile();\n\n    // Prepare volume in DataStorage\n    final DataStorage.VolumeBuilder builder;\n    try {\n      builder \u003d dataStorage.prepareVolume(datanode, location.getFile(), nsInfos);\n    } catch (IOException e) {\n      volumes.addVolumeFailureInfo(new VolumeFailureInfo(\n          location.getFile().getAbsolutePath(), Time.now()));\n      throw e;\n    }\n\n    final Storage.StorageDirectory sd \u003d builder.getStorageDirectory();\n\n    StorageType storageType \u003d location.getStorageType();\n    final FsVolumeImpl fsVolume \u003d\n        createFsVolume(sd.getStorageUuid(), sd.getCurrentDir(), storageType);\n    final ReplicaMap tempVolumeMap \u003d new ReplicaMap(fsVolume);\n    ArrayList\u003cIOException\u003e exceptions \u003d Lists.newArrayList();\n\n    for (final NamespaceInfo nsInfo : nsInfos) {\n      String bpid \u003d nsInfo.getBlockPoolID();\n      try {\n        fsVolume.addBlockPool(bpid, this.conf);\n        fsVolume.getVolumeMap(bpid, tempVolumeMap, ramDiskReplicaTracker);\n      } catch (IOException e) {\n        LOG.warn(\"Caught exception when adding \" + fsVolume +\n            \". Will throw later.\", e);\n        exceptions.add(e);\n      }\n    }\n    if (!exceptions.isEmpty()) {\n      try {\n        sd.unlock();\n      } catch (IOException e) {\n        exceptions.add(e);\n      }\n      throw MultipleIOException.createIOException(exceptions);\n    }\n\n    final FsVolumeReference ref \u003d fsVolume.obtainReference();\n    setupAsyncLazyPersistThread(fsVolume);\n\n    builder.build();\n    synchronized (this) {\n      volumeMap.addAll(tempVolumeMap);\n      storageMap.put(sd.getStorageUuid(),\n          new DatanodeStorage(sd.getStorageUuid(),\n              DatanodeStorage.State.NORMAL,\n              storageType));\n      asyncDiskService.addVolume(sd.getCurrentDir());\n      volumes.addVolume(ref);\n    }\n    LOG.info(\"Added volume - \" + dir + \", StorageType: \" + storageType);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "9729b244de50322c2cc889c97c2ffb2b4675cf77": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7604. Track and display failed DataNode storage locations in NameNode. Contributed by Chris Nauroth.\n",
      "commitDate": "16/02/15 2:43 PM",
      "commitName": "9729b244de50322c2cc889c97c2ffb2b4675cf77",
      "commitAuthor": "cnauroth",
      "commitDateOld": "11/02/15 3:12 PM",
      "commitNameOld": "085b1e293ff53f7a86aa21406cfd4bfa0f3bf33b",
      "commitAuthorOld": "Tsz-Wo Nicholas Sze",
      "daysBetweenCommits": 4.98,
      "commitsBetweenForRepo": 61,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,47 +1,53 @@\n   public void addVolume(final StorageLocation location,\n       final List\u003cNamespaceInfo\u003e nsInfos)\n       throws IOException {\n     final File dir \u003d location.getFile();\n \n     // Prepare volume in DataStorage\n-    DataStorage.VolumeBuilder builder \u003d\n-        dataStorage.prepareVolume(datanode, location.getFile(), nsInfos);\n+    final DataStorage.VolumeBuilder builder;\n+    try {\n+      builder \u003d dataStorage.prepareVolume(datanode, location.getFile(), nsInfos);\n+    } catch (IOException e) {\n+      volumes.addVolumeFailureInfo(new VolumeFailureInfo(\n+          location.getFile().getAbsolutePath(), Time.now()));\n+      throw e;\n+    }\n \n     final Storage.StorageDirectory sd \u003d builder.getStorageDirectory();\n \n     StorageType storageType \u003d location.getStorageType();\n     final FsVolumeImpl fsVolume \u003d new FsVolumeImpl(\n         this, sd.getStorageUuid(), sd.getCurrentDir(), this.conf, storageType);\n     final ReplicaMap tempVolumeMap \u003d new ReplicaMap(fsVolume);\n     ArrayList\u003cIOException\u003e exceptions \u003d Lists.newArrayList();\n \n     for (final NamespaceInfo nsInfo : nsInfos) {\n       String bpid \u003d nsInfo.getBlockPoolID();\n       try {\n         fsVolume.addBlockPool(bpid, this.conf);\n         fsVolume.getVolumeMap(bpid, tempVolumeMap, ramDiskReplicaTracker);\n       } catch (IOException e) {\n         LOG.warn(\"Caught exception when adding \" + fsVolume +\n             \". Will throw later.\", e);\n         exceptions.add(e);\n       }\n     }\n     if (!exceptions.isEmpty()) {\n       throw MultipleIOException.createIOException(exceptions);\n     }\n \n     final FsVolumeReference ref \u003d fsVolume.obtainReference();\n     setupAsyncLazyPersistThread(fsVolume);\n \n     builder.build();\n     synchronized (this) {\n       volumeMap.addAll(tempVolumeMap);\n       storageMap.put(sd.getStorageUuid(),\n           new DatanodeStorage(sd.getStorageUuid(),\n               DatanodeStorage.State.NORMAL,\n               storageType));\n       asyncDiskService.addVolume(sd.getCurrentDir());\n       volumes.addVolume(ref);\n     }\n     LOG.info(\"Added volume - \" + dir + \", StorageType: \" + storageType);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void addVolume(final StorageLocation location,\n      final List\u003cNamespaceInfo\u003e nsInfos)\n      throws IOException {\n    final File dir \u003d location.getFile();\n\n    // Prepare volume in DataStorage\n    final DataStorage.VolumeBuilder builder;\n    try {\n      builder \u003d dataStorage.prepareVolume(datanode, location.getFile(), nsInfos);\n    } catch (IOException e) {\n      volumes.addVolumeFailureInfo(new VolumeFailureInfo(\n          location.getFile().getAbsolutePath(), Time.now()));\n      throw e;\n    }\n\n    final Storage.StorageDirectory sd \u003d builder.getStorageDirectory();\n\n    StorageType storageType \u003d location.getStorageType();\n    final FsVolumeImpl fsVolume \u003d new FsVolumeImpl(\n        this, sd.getStorageUuid(), sd.getCurrentDir(), this.conf, storageType);\n    final ReplicaMap tempVolumeMap \u003d new ReplicaMap(fsVolume);\n    ArrayList\u003cIOException\u003e exceptions \u003d Lists.newArrayList();\n\n    for (final NamespaceInfo nsInfo : nsInfos) {\n      String bpid \u003d nsInfo.getBlockPoolID();\n      try {\n        fsVolume.addBlockPool(bpid, this.conf);\n        fsVolume.getVolumeMap(bpid, tempVolumeMap, ramDiskReplicaTracker);\n      } catch (IOException e) {\n        LOG.warn(\"Caught exception when adding \" + fsVolume +\n            \". Will throw later.\", e);\n        exceptions.add(e);\n      }\n    }\n    if (!exceptions.isEmpty()) {\n      throw MultipleIOException.createIOException(exceptions);\n    }\n\n    final FsVolumeReference ref \u003d fsVolume.obtainReference();\n    setupAsyncLazyPersistThread(fsVolume);\n\n    builder.build();\n    synchronized (this) {\n      volumeMap.addAll(tempVolumeMap);\n      storageMap.put(sd.getStorageUuid(),\n          new DatanodeStorage(sd.getStorageUuid(),\n              DatanodeStorage.State.NORMAL,\n              storageType));\n      asyncDiskService.addVolume(sd.getCurrentDir());\n      volumes.addVolume(ref);\n    }\n    LOG.info(\"Added volume - \" + dir + \", StorageType: \" + storageType);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "6e62a1a6728b1f782f64065424f92b292c3f163a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7430. Refactor the BlockScanner to use O(1) memory and use multiple threads (cmccabe)\n",
      "commitDate": "21/01/15 7:00 PM",
      "commitName": "6e62a1a6728b1f782f64065424f92b292c3f163a",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "21/01/15 12:41 PM",
      "commitNameOld": "c0af72c7f74b6925786e24543cac433b906dd6d3",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 0.26,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,46 +1,47 @@\n   public void addVolume(final StorageLocation location,\n       final List\u003cNamespaceInfo\u003e nsInfos)\n       throws IOException {\n     final File dir \u003d location.getFile();\n \n     // Prepare volume in DataStorage\n     DataStorage.VolumeBuilder builder \u003d\n         dataStorage.prepareVolume(datanode, location.getFile(), nsInfos);\n \n     final Storage.StorageDirectory sd \u003d builder.getStorageDirectory();\n \n     StorageType storageType \u003d location.getStorageType();\n     final FsVolumeImpl fsVolume \u003d new FsVolumeImpl(\n         this, sd.getStorageUuid(), sd.getCurrentDir(), this.conf, storageType);\n     final ReplicaMap tempVolumeMap \u003d new ReplicaMap(fsVolume);\n     ArrayList\u003cIOException\u003e exceptions \u003d Lists.newArrayList();\n \n     for (final NamespaceInfo nsInfo : nsInfos) {\n       String bpid \u003d nsInfo.getBlockPoolID();\n       try {\n         fsVolume.addBlockPool(bpid, this.conf);\n         fsVolume.getVolumeMap(bpid, tempVolumeMap, ramDiskReplicaTracker);\n       } catch (IOException e) {\n         LOG.warn(\"Caught exception when adding \" + fsVolume +\n             \". Will throw later.\", e);\n         exceptions.add(e);\n       }\n     }\n     if (!exceptions.isEmpty()) {\n       throw MultipleIOException.createIOException(exceptions);\n     }\n \n+    final FsVolumeReference ref \u003d fsVolume.obtainReference();\n     setupAsyncLazyPersistThread(fsVolume);\n \n     builder.build();\n     synchronized (this) {\n       volumeMap.addAll(tempVolumeMap);\n       storageMap.put(sd.getStorageUuid(),\n           new DatanodeStorage(sd.getStorageUuid(),\n               DatanodeStorage.State.NORMAL,\n               storageType));\n       asyncDiskService.addVolume(sd.getCurrentDir());\n-      volumes.addVolume(fsVolume);\n+      volumes.addVolume(ref);\n     }\n     LOG.info(\"Added volume - \" + dir + \", StorageType: \" + storageType);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void addVolume(final StorageLocation location,\n      final List\u003cNamespaceInfo\u003e nsInfos)\n      throws IOException {\n    final File dir \u003d location.getFile();\n\n    // Prepare volume in DataStorage\n    DataStorage.VolumeBuilder builder \u003d\n        dataStorage.prepareVolume(datanode, location.getFile(), nsInfos);\n\n    final Storage.StorageDirectory sd \u003d builder.getStorageDirectory();\n\n    StorageType storageType \u003d location.getStorageType();\n    final FsVolumeImpl fsVolume \u003d new FsVolumeImpl(\n        this, sd.getStorageUuid(), sd.getCurrentDir(), this.conf, storageType);\n    final ReplicaMap tempVolumeMap \u003d new ReplicaMap(fsVolume);\n    ArrayList\u003cIOException\u003e exceptions \u003d Lists.newArrayList();\n\n    for (final NamespaceInfo nsInfo : nsInfos) {\n      String bpid \u003d nsInfo.getBlockPoolID();\n      try {\n        fsVolume.addBlockPool(bpid, this.conf);\n        fsVolume.getVolumeMap(bpid, tempVolumeMap, ramDiskReplicaTracker);\n      } catch (IOException e) {\n        LOG.warn(\"Caught exception when adding \" + fsVolume +\n            \". Will throw later.\", e);\n        exceptions.add(e);\n      }\n    }\n    if (!exceptions.isEmpty()) {\n      throw MultipleIOException.createIOException(exceptions);\n    }\n\n    final FsVolumeReference ref \u003d fsVolume.obtainReference();\n    setupAsyncLazyPersistThread(fsVolume);\n\n    builder.build();\n    synchronized (this) {\n      volumeMap.addAll(tempVolumeMap);\n      storageMap.put(sd.getStorageUuid(),\n          new DatanodeStorage(sd.getStorageUuid(),\n              DatanodeStorage.State.NORMAL,\n              storageType));\n      asyncDiskService.addVolume(sd.getCurrentDir());\n      volumes.addVolume(ref);\n    }\n    LOG.info(\"Added volume - \" + dir + \", StorageType: \" + storageType);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "a17584936cc5141e3f5612ac3ecf35e27968e439": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7610. Fix removal of dynamically added DN volumes (Lei (Eddy) Xu via Colin P. McCabe)\n",
      "commitDate": "20/01/15 8:11 PM",
      "commitName": "a17584936cc5141e3f5612ac3ecf35e27968e439",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "20/01/15 7:05 PM",
      "commitNameOld": "b7f4a3156c0f5c600816c469637237ba6c9b330c",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 0.05,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,46 +1,46 @@\n   public void addVolume(final StorageLocation location,\n       final List\u003cNamespaceInfo\u003e nsInfos)\n       throws IOException {\n     final File dir \u003d location.getFile();\n \n     // Prepare volume in DataStorage\n     DataStorage.VolumeBuilder builder \u003d\n         dataStorage.prepareVolume(datanode, location.getFile(), nsInfos);\n \n     final Storage.StorageDirectory sd \u003d builder.getStorageDirectory();\n \n     StorageType storageType \u003d location.getStorageType();\n     final FsVolumeImpl fsVolume \u003d new FsVolumeImpl(\n-        this, sd.getStorageUuid(), dir, this.conf, storageType);\n+        this, sd.getStorageUuid(), sd.getCurrentDir(), this.conf, storageType);\n     final ReplicaMap tempVolumeMap \u003d new ReplicaMap(fsVolume);\n     ArrayList\u003cIOException\u003e exceptions \u003d Lists.newArrayList();\n \n     for (final NamespaceInfo nsInfo : nsInfos) {\n       String bpid \u003d nsInfo.getBlockPoolID();\n       try {\n         fsVolume.addBlockPool(bpid, this.conf);\n         fsVolume.getVolumeMap(bpid, tempVolumeMap, ramDiskReplicaTracker);\n       } catch (IOException e) {\n         LOG.warn(\"Caught exception when adding \" + fsVolume +\n             \". Will throw later.\", e);\n         exceptions.add(e);\n       }\n     }\n     if (!exceptions.isEmpty()) {\n       throw MultipleIOException.createIOException(exceptions);\n     }\n \n     setupAsyncLazyPersistThread(fsVolume);\n \n     builder.build();\n     synchronized (this) {\n       volumeMap.addAll(tempVolumeMap);\n       storageMap.put(sd.getStorageUuid(),\n           new DatanodeStorage(sd.getStorageUuid(),\n               DatanodeStorage.State.NORMAL,\n               storageType));\n       asyncDiskService.addVolume(sd.getCurrentDir());\n       volumes.addVolume(fsVolume);\n     }\n     LOG.info(\"Added volume - \" + dir + \", StorageType: \" + storageType);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void addVolume(final StorageLocation location,\n      final List\u003cNamespaceInfo\u003e nsInfos)\n      throws IOException {\n    final File dir \u003d location.getFile();\n\n    // Prepare volume in DataStorage\n    DataStorage.VolumeBuilder builder \u003d\n        dataStorage.prepareVolume(datanode, location.getFile(), nsInfos);\n\n    final Storage.StorageDirectory sd \u003d builder.getStorageDirectory();\n\n    StorageType storageType \u003d location.getStorageType();\n    final FsVolumeImpl fsVolume \u003d new FsVolumeImpl(\n        this, sd.getStorageUuid(), sd.getCurrentDir(), this.conf, storageType);\n    final ReplicaMap tempVolumeMap \u003d new ReplicaMap(fsVolume);\n    ArrayList\u003cIOException\u003e exceptions \u003d Lists.newArrayList();\n\n    for (final NamespaceInfo nsInfo : nsInfos) {\n      String bpid \u003d nsInfo.getBlockPoolID();\n      try {\n        fsVolume.addBlockPool(bpid, this.conf);\n        fsVolume.getVolumeMap(bpid, tempVolumeMap, ramDiskReplicaTracker);\n      } catch (IOException e) {\n        LOG.warn(\"Caught exception when adding \" + fsVolume +\n            \". Will throw later.\", e);\n        exceptions.add(e);\n      }\n    }\n    if (!exceptions.isEmpty()) {\n      throw MultipleIOException.createIOException(exceptions);\n    }\n\n    setupAsyncLazyPersistThread(fsVolume);\n\n    builder.build();\n    synchronized (this) {\n      volumeMap.addAll(tempVolumeMap);\n      storageMap.put(sd.getStorageUuid(),\n          new DatanodeStorage(sd.getStorageUuid(),\n              DatanodeStorage.State.NORMAL,\n              storageType));\n      asyncDiskService.addVolume(sd.getCurrentDir());\n      volumes.addVolume(fsVolume);\n    }\n    LOG.info(\"Added volume - \" + dir + \", StorageType: \" + storageType);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "a9331fe9b071fdcdae0c6c747d7b6b306142e671": {
      "type": "Ymultichange(Yrename,Yparameterchange,Yreturntypechange,Ymodifierchange,Yexceptionschange,Ybodychange)",
      "commitMessage": "HDFS-7035. Make adding a new data directory to the DataNode an atomic operation and improve error handling (Lei Xu via Colin P. McCabe)\n",
      "commitDate": "30/10/14 5:31 PM",
      "commitName": "a9331fe9b071fdcdae0c6c747d7b6b306142e671",
      "commitAuthor": "Colin Patrick Mccabe",
      "subchanges": [
        {
          "type": "Yrename",
          "commitMessage": "HDFS-7035. Make adding a new data directory to the DataNode an atomic operation and improve error handling (Lei Xu via Colin P. McCabe)\n",
          "commitDate": "30/10/14 5:31 PM",
          "commitName": "a9331fe9b071fdcdae0c6c747d7b6b306142e671",
          "commitAuthor": "Colin Patrick Mccabe",
          "commitDateOld": "28/10/14 4:41 PM",
          "commitNameOld": "ac9ab037e9a9b03e4fa9bd471d3ab9940beb53fb",
          "commitAuthorOld": "Colin Patrick Mccabe",
          "daysBetweenCommits": 2.03,
          "commitsBetweenForRepo": 30,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,60 +1,46 @@\n-  public synchronized List\u003cStorageLocation\u003e addVolumes(\n-      final List\u003cStorageLocation\u003e volumes, final Collection\u003cString\u003e bpids) {\n-    final Collection\u003cStorageLocation\u003e dataLocations \u003d\n-        DataNode.getStorageLocations(this.conf);\n-    final Map\u003cString, Storage.StorageDirectory\u003e allStorageDirs \u003d\n-        new HashMap\u003cString, Storage.StorageDirectory\u003e();\n-    List\u003cStorageLocation\u003e succeedVolumes \u003d Lists.newArrayList();\n-    try {\n-      for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n-        Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n-        allStorageDirs.put(sd.getRoot().getCanonicalPath(), sd);\n-      }\n-    } catch (IOException ioe) {\n-      LOG.warn(\"Caught exception when parsing storage URL.\", ioe);\n-      return succeedVolumes;\n-    }\n+  public void addVolume(final StorageLocation location,\n+      final List\u003cNamespaceInfo\u003e nsInfos)\n+      throws IOException {\n+    final File dir \u003d location.getFile();\n \n-    final boolean[] successFlags \u003d new boolean[volumes.size()];\n-    Arrays.fill(successFlags, false);\n-    List\u003cThread\u003e volumeAddingThreads \u003d Lists.newArrayList();\n-    for (int i \u003d 0; i \u003c volumes.size(); i++) {\n-      final int idx \u003d i;\n-      Thread t \u003d new Thread() {\n-        public void run() {\n-          StorageLocation vol \u003d volumes.get(idx);\n-          try {\n-            String key \u003d vol.getFile().getCanonicalPath();\n-            if (!allStorageDirs.containsKey(key)) {\n-              LOG.warn(\"Attempt to add an invalid volume: \" + vol.getFile());\n-            } else {\n-              addVolumeAndBlockPool(dataLocations, allStorageDirs.get(key),\n-                  bpids);\n-              successFlags[idx] \u003d true;\n-            }\n-          } catch (IOException e) {\n-            LOG.warn(\"Caught exception when adding volume \" + vol, e);\n-          }\n-        }\n-      };\n-      volumeAddingThreads.add(t);\n-      t.start();\n-    }\n+    // Prepare volume in DataStorage\n+    DataStorage.VolumeBuilder builder \u003d\n+        dataStorage.prepareVolume(datanode, location.getFile(), nsInfos);\n \n-    for (Thread t : volumeAddingThreads) {\n+    final Storage.StorageDirectory sd \u003d builder.getStorageDirectory();\n+\n+    StorageType storageType \u003d location.getStorageType();\n+    final FsVolumeImpl fsVolume \u003d new FsVolumeImpl(\n+        this, sd.getStorageUuid(), dir, this.conf, storageType);\n+    final ReplicaMap tempVolumeMap \u003d new ReplicaMap(fsVolume);\n+    ArrayList\u003cIOException\u003e exceptions \u003d Lists.newArrayList();\n+\n+    for (final NamespaceInfo nsInfo : nsInfos) {\n+      String bpid \u003d nsInfo.getBlockPoolID();\n       try {\n-        t.join();\n-      } catch (InterruptedException e) {\n-        LOG.warn(\"Caught InterruptedException when adding volume.\", e);\n+        fsVolume.addBlockPool(bpid, this.conf);\n+        fsVolume.getVolumeMap(bpid, tempVolumeMap, ramDiskReplicaTracker);\n+      } catch (IOException e) {\n+        LOG.warn(\"Caught exception when adding \" + fsVolume +\n+            \". Will throw later.\", e);\n+        exceptions.add(e);\n       }\n     }\n-\n-    setupAsyncLazyPersistThreads();\n-\n-    for (int i \u003d 0; i \u003c volumes.size(); i++) {\n-      if (successFlags[i]) {\n-        succeedVolumes.add(volumes.get(i));\n-      }\n+    if (!exceptions.isEmpty()) {\n+      throw MultipleIOException.createIOException(exceptions);\n     }\n-    return succeedVolumes;\n+\n+    setupAsyncLazyPersistThread(fsVolume);\n+\n+    builder.build();\n+    synchronized (this) {\n+      volumeMap.addAll(tempVolumeMap);\n+      storageMap.put(sd.getStorageUuid(),\n+          new DatanodeStorage(sd.getStorageUuid(),\n+              DatanodeStorage.State.NORMAL,\n+              storageType));\n+      asyncDiskService.addVolume(sd.getCurrentDir());\n+      volumes.addVolume(fsVolume);\n+    }\n+    LOG.info(\"Added volume - \" + dir + \", StorageType: \" + storageType);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void addVolume(final StorageLocation location,\n      final List\u003cNamespaceInfo\u003e nsInfos)\n      throws IOException {\n    final File dir \u003d location.getFile();\n\n    // Prepare volume in DataStorage\n    DataStorage.VolumeBuilder builder \u003d\n        dataStorage.prepareVolume(datanode, location.getFile(), nsInfos);\n\n    final Storage.StorageDirectory sd \u003d builder.getStorageDirectory();\n\n    StorageType storageType \u003d location.getStorageType();\n    final FsVolumeImpl fsVolume \u003d new FsVolumeImpl(\n        this, sd.getStorageUuid(), dir, this.conf, storageType);\n    final ReplicaMap tempVolumeMap \u003d new ReplicaMap(fsVolume);\n    ArrayList\u003cIOException\u003e exceptions \u003d Lists.newArrayList();\n\n    for (final NamespaceInfo nsInfo : nsInfos) {\n      String bpid \u003d nsInfo.getBlockPoolID();\n      try {\n        fsVolume.addBlockPool(bpid, this.conf);\n        fsVolume.getVolumeMap(bpid, tempVolumeMap, ramDiskReplicaTracker);\n      } catch (IOException e) {\n        LOG.warn(\"Caught exception when adding \" + fsVolume +\n            \". Will throw later.\", e);\n        exceptions.add(e);\n      }\n    }\n    if (!exceptions.isEmpty()) {\n      throw MultipleIOException.createIOException(exceptions);\n    }\n\n    setupAsyncLazyPersistThread(fsVolume);\n\n    builder.build();\n    synchronized (this) {\n      volumeMap.addAll(tempVolumeMap);\n      storageMap.put(sd.getStorageUuid(),\n          new DatanodeStorage(sd.getStorageUuid(),\n              DatanodeStorage.State.NORMAL,\n              storageType));\n      asyncDiskService.addVolume(sd.getCurrentDir());\n      volumes.addVolume(fsVolume);\n    }\n    LOG.info(\"Added volume - \" + dir + \", StorageType: \" + storageType);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
          "extendedDetails": {
            "oldValue": "addVolumes",
            "newValue": "addVolume"
          }
        },
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-7035. Make adding a new data directory to the DataNode an atomic operation and improve error handling (Lei Xu via Colin P. McCabe)\n",
          "commitDate": "30/10/14 5:31 PM",
          "commitName": "a9331fe9b071fdcdae0c6c747d7b6b306142e671",
          "commitAuthor": "Colin Patrick Mccabe",
          "commitDateOld": "28/10/14 4:41 PM",
          "commitNameOld": "ac9ab037e9a9b03e4fa9bd471d3ab9940beb53fb",
          "commitAuthorOld": "Colin Patrick Mccabe",
          "daysBetweenCommits": 2.03,
          "commitsBetweenForRepo": 30,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,60 +1,46 @@\n-  public synchronized List\u003cStorageLocation\u003e addVolumes(\n-      final List\u003cStorageLocation\u003e volumes, final Collection\u003cString\u003e bpids) {\n-    final Collection\u003cStorageLocation\u003e dataLocations \u003d\n-        DataNode.getStorageLocations(this.conf);\n-    final Map\u003cString, Storage.StorageDirectory\u003e allStorageDirs \u003d\n-        new HashMap\u003cString, Storage.StorageDirectory\u003e();\n-    List\u003cStorageLocation\u003e succeedVolumes \u003d Lists.newArrayList();\n-    try {\n-      for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n-        Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n-        allStorageDirs.put(sd.getRoot().getCanonicalPath(), sd);\n-      }\n-    } catch (IOException ioe) {\n-      LOG.warn(\"Caught exception when parsing storage URL.\", ioe);\n-      return succeedVolumes;\n-    }\n+  public void addVolume(final StorageLocation location,\n+      final List\u003cNamespaceInfo\u003e nsInfos)\n+      throws IOException {\n+    final File dir \u003d location.getFile();\n \n-    final boolean[] successFlags \u003d new boolean[volumes.size()];\n-    Arrays.fill(successFlags, false);\n-    List\u003cThread\u003e volumeAddingThreads \u003d Lists.newArrayList();\n-    for (int i \u003d 0; i \u003c volumes.size(); i++) {\n-      final int idx \u003d i;\n-      Thread t \u003d new Thread() {\n-        public void run() {\n-          StorageLocation vol \u003d volumes.get(idx);\n-          try {\n-            String key \u003d vol.getFile().getCanonicalPath();\n-            if (!allStorageDirs.containsKey(key)) {\n-              LOG.warn(\"Attempt to add an invalid volume: \" + vol.getFile());\n-            } else {\n-              addVolumeAndBlockPool(dataLocations, allStorageDirs.get(key),\n-                  bpids);\n-              successFlags[idx] \u003d true;\n-            }\n-          } catch (IOException e) {\n-            LOG.warn(\"Caught exception when adding volume \" + vol, e);\n-          }\n-        }\n-      };\n-      volumeAddingThreads.add(t);\n-      t.start();\n-    }\n+    // Prepare volume in DataStorage\n+    DataStorage.VolumeBuilder builder \u003d\n+        dataStorage.prepareVolume(datanode, location.getFile(), nsInfos);\n \n-    for (Thread t : volumeAddingThreads) {\n+    final Storage.StorageDirectory sd \u003d builder.getStorageDirectory();\n+\n+    StorageType storageType \u003d location.getStorageType();\n+    final FsVolumeImpl fsVolume \u003d new FsVolumeImpl(\n+        this, sd.getStorageUuid(), dir, this.conf, storageType);\n+    final ReplicaMap tempVolumeMap \u003d new ReplicaMap(fsVolume);\n+    ArrayList\u003cIOException\u003e exceptions \u003d Lists.newArrayList();\n+\n+    for (final NamespaceInfo nsInfo : nsInfos) {\n+      String bpid \u003d nsInfo.getBlockPoolID();\n       try {\n-        t.join();\n-      } catch (InterruptedException e) {\n-        LOG.warn(\"Caught InterruptedException when adding volume.\", e);\n+        fsVolume.addBlockPool(bpid, this.conf);\n+        fsVolume.getVolumeMap(bpid, tempVolumeMap, ramDiskReplicaTracker);\n+      } catch (IOException e) {\n+        LOG.warn(\"Caught exception when adding \" + fsVolume +\n+            \". Will throw later.\", e);\n+        exceptions.add(e);\n       }\n     }\n-\n-    setupAsyncLazyPersistThreads();\n-\n-    for (int i \u003d 0; i \u003c volumes.size(); i++) {\n-      if (successFlags[i]) {\n-        succeedVolumes.add(volumes.get(i));\n-      }\n+    if (!exceptions.isEmpty()) {\n+      throw MultipleIOException.createIOException(exceptions);\n     }\n-    return succeedVolumes;\n+\n+    setupAsyncLazyPersistThread(fsVolume);\n+\n+    builder.build();\n+    synchronized (this) {\n+      volumeMap.addAll(tempVolumeMap);\n+      storageMap.put(sd.getStorageUuid(),\n+          new DatanodeStorage(sd.getStorageUuid(),\n+              DatanodeStorage.State.NORMAL,\n+              storageType));\n+      asyncDiskService.addVolume(sd.getCurrentDir());\n+      volumes.addVolume(fsVolume);\n+    }\n+    LOG.info(\"Added volume - \" + dir + \", StorageType: \" + storageType);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void addVolume(final StorageLocation location,\n      final List\u003cNamespaceInfo\u003e nsInfos)\n      throws IOException {\n    final File dir \u003d location.getFile();\n\n    // Prepare volume in DataStorage\n    DataStorage.VolumeBuilder builder \u003d\n        dataStorage.prepareVolume(datanode, location.getFile(), nsInfos);\n\n    final Storage.StorageDirectory sd \u003d builder.getStorageDirectory();\n\n    StorageType storageType \u003d location.getStorageType();\n    final FsVolumeImpl fsVolume \u003d new FsVolumeImpl(\n        this, sd.getStorageUuid(), dir, this.conf, storageType);\n    final ReplicaMap tempVolumeMap \u003d new ReplicaMap(fsVolume);\n    ArrayList\u003cIOException\u003e exceptions \u003d Lists.newArrayList();\n\n    for (final NamespaceInfo nsInfo : nsInfos) {\n      String bpid \u003d nsInfo.getBlockPoolID();\n      try {\n        fsVolume.addBlockPool(bpid, this.conf);\n        fsVolume.getVolumeMap(bpid, tempVolumeMap, ramDiskReplicaTracker);\n      } catch (IOException e) {\n        LOG.warn(\"Caught exception when adding \" + fsVolume +\n            \". Will throw later.\", e);\n        exceptions.add(e);\n      }\n    }\n    if (!exceptions.isEmpty()) {\n      throw MultipleIOException.createIOException(exceptions);\n    }\n\n    setupAsyncLazyPersistThread(fsVolume);\n\n    builder.build();\n    synchronized (this) {\n      volumeMap.addAll(tempVolumeMap);\n      storageMap.put(sd.getStorageUuid(),\n          new DatanodeStorage(sd.getStorageUuid(),\n              DatanodeStorage.State.NORMAL,\n              storageType));\n      asyncDiskService.addVolume(sd.getCurrentDir());\n      volumes.addVolume(fsVolume);\n    }\n    LOG.info(\"Added volume - \" + dir + \", StorageType: \" + storageType);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
          "extendedDetails": {
            "oldValue": "[volumes-List\u003cStorageLocation\u003e(modifiers-final), bpids-Collection\u003cString\u003e(modifiers-final)]",
            "newValue": "[location-StorageLocation(modifiers-final), nsInfos-List\u003cNamespaceInfo\u003e(modifiers-final)]"
          }
        },
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-7035. Make adding a new data directory to the DataNode an atomic operation and improve error handling (Lei Xu via Colin P. McCabe)\n",
          "commitDate": "30/10/14 5:31 PM",
          "commitName": "a9331fe9b071fdcdae0c6c747d7b6b306142e671",
          "commitAuthor": "Colin Patrick Mccabe",
          "commitDateOld": "28/10/14 4:41 PM",
          "commitNameOld": "ac9ab037e9a9b03e4fa9bd471d3ab9940beb53fb",
          "commitAuthorOld": "Colin Patrick Mccabe",
          "daysBetweenCommits": 2.03,
          "commitsBetweenForRepo": 30,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,60 +1,46 @@\n-  public synchronized List\u003cStorageLocation\u003e addVolumes(\n-      final List\u003cStorageLocation\u003e volumes, final Collection\u003cString\u003e bpids) {\n-    final Collection\u003cStorageLocation\u003e dataLocations \u003d\n-        DataNode.getStorageLocations(this.conf);\n-    final Map\u003cString, Storage.StorageDirectory\u003e allStorageDirs \u003d\n-        new HashMap\u003cString, Storage.StorageDirectory\u003e();\n-    List\u003cStorageLocation\u003e succeedVolumes \u003d Lists.newArrayList();\n-    try {\n-      for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n-        Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n-        allStorageDirs.put(sd.getRoot().getCanonicalPath(), sd);\n-      }\n-    } catch (IOException ioe) {\n-      LOG.warn(\"Caught exception when parsing storage URL.\", ioe);\n-      return succeedVolumes;\n-    }\n+  public void addVolume(final StorageLocation location,\n+      final List\u003cNamespaceInfo\u003e nsInfos)\n+      throws IOException {\n+    final File dir \u003d location.getFile();\n \n-    final boolean[] successFlags \u003d new boolean[volumes.size()];\n-    Arrays.fill(successFlags, false);\n-    List\u003cThread\u003e volumeAddingThreads \u003d Lists.newArrayList();\n-    for (int i \u003d 0; i \u003c volumes.size(); i++) {\n-      final int idx \u003d i;\n-      Thread t \u003d new Thread() {\n-        public void run() {\n-          StorageLocation vol \u003d volumes.get(idx);\n-          try {\n-            String key \u003d vol.getFile().getCanonicalPath();\n-            if (!allStorageDirs.containsKey(key)) {\n-              LOG.warn(\"Attempt to add an invalid volume: \" + vol.getFile());\n-            } else {\n-              addVolumeAndBlockPool(dataLocations, allStorageDirs.get(key),\n-                  bpids);\n-              successFlags[idx] \u003d true;\n-            }\n-          } catch (IOException e) {\n-            LOG.warn(\"Caught exception when adding volume \" + vol, e);\n-          }\n-        }\n-      };\n-      volumeAddingThreads.add(t);\n-      t.start();\n-    }\n+    // Prepare volume in DataStorage\n+    DataStorage.VolumeBuilder builder \u003d\n+        dataStorage.prepareVolume(datanode, location.getFile(), nsInfos);\n \n-    for (Thread t : volumeAddingThreads) {\n+    final Storage.StorageDirectory sd \u003d builder.getStorageDirectory();\n+\n+    StorageType storageType \u003d location.getStorageType();\n+    final FsVolumeImpl fsVolume \u003d new FsVolumeImpl(\n+        this, sd.getStorageUuid(), dir, this.conf, storageType);\n+    final ReplicaMap tempVolumeMap \u003d new ReplicaMap(fsVolume);\n+    ArrayList\u003cIOException\u003e exceptions \u003d Lists.newArrayList();\n+\n+    for (final NamespaceInfo nsInfo : nsInfos) {\n+      String bpid \u003d nsInfo.getBlockPoolID();\n       try {\n-        t.join();\n-      } catch (InterruptedException e) {\n-        LOG.warn(\"Caught InterruptedException when adding volume.\", e);\n+        fsVolume.addBlockPool(bpid, this.conf);\n+        fsVolume.getVolumeMap(bpid, tempVolumeMap, ramDiskReplicaTracker);\n+      } catch (IOException e) {\n+        LOG.warn(\"Caught exception when adding \" + fsVolume +\n+            \". Will throw later.\", e);\n+        exceptions.add(e);\n       }\n     }\n-\n-    setupAsyncLazyPersistThreads();\n-\n-    for (int i \u003d 0; i \u003c volumes.size(); i++) {\n-      if (successFlags[i]) {\n-        succeedVolumes.add(volumes.get(i));\n-      }\n+    if (!exceptions.isEmpty()) {\n+      throw MultipleIOException.createIOException(exceptions);\n     }\n-    return succeedVolumes;\n+\n+    setupAsyncLazyPersistThread(fsVolume);\n+\n+    builder.build();\n+    synchronized (this) {\n+      volumeMap.addAll(tempVolumeMap);\n+      storageMap.put(sd.getStorageUuid(),\n+          new DatanodeStorage(sd.getStorageUuid(),\n+              DatanodeStorage.State.NORMAL,\n+              storageType));\n+      asyncDiskService.addVolume(sd.getCurrentDir());\n+      volumes.addVolume(fsVolume);\n+    }\n+    LOG.info(\"Added volume - \" + dir + \", StorageType: \" + storageType);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void addVolume(final StorageLocation location,\n      final List\u003cNamespaceInfo\u003e nsInfos)\n      throws IOException {\n    final File dir \u003d location.getFile();\n\n    // Prepare volume in DataStorage\n    DataStorage.VolumeBuilder builder \u003d\n        dataStorage.prepareVolume(datanode, location.getFile(), nsInfos);\n\n    final Storage.StorageDirectory sd \u003d builder.getStorageDirectory();\n\n    StorageType storageType \u003d location.getStorageType();\n    final FsVolumeImpl fsVolume \u003d new FsVolumeImpl(\n        this, sd.getStorageUuid(), dir, this.conf, storageType);\n    final ReplicaMap tempVolumeMap \u003d new ReplicaMap(fsVolume);\n    ArrayList\u003cIOException\u003e exceptions \u003d Lists.newArrayList();\n\n    for (final NamespaceInfo nsInfo : nsInfos) {\n      String bpid \u003d nsInfo.getBlockPoolID();\n      try {\n        fsVolume.addBlockPool(bpid, this.conf);\n        fsVolume.getVolumeMap(bpid, tempVolumeMap, ramDiskReplicaTracker);\n      } catch (IOException e) {\n        LOG.warn(\"Caught exception when adding \" + fsVolume +\n            \". Will throw later.\", e);\n        exceptions.add(e);\n      }\n    }\n    if (!exceptions.isEmpty()) {\n      throw MultipleIOException.createIOException(exceptions);\n    }\n\n    setupAsyncLazyPersistThread(fsVolume);\n\n    builder.build();\n    synchronized (this) {\n      volumeMap.addAll(tempVolumeMap);\n      storageMap.put(sd.getStorageUuid(),\n          new DatanodeStorage(sd.getStorageUuid(),\n              DatanodeStorage.State.NORMAL,\n              storageType));\n      asyncDiskService.addVolume(sd.getCurrentDir());\n      volumes.addVolume(fsVolume);\n    }\n    LOG.info(\"Added volume - \" + dir + \", StorageType: \" + storageType);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
          "extendedDetails": {
            "oldValue": "List\u003cStorageLocation\u003e",
            "newValue": "void"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-7035. Make adding a new data directory to the DataNode an atomic operation and improve error handling (Lei Xu via Colin P. McCabe)\n",
          "commitDate": "30/10/14 5:31 PM",
          "commitName": "a9331fe9b071fdcdae0c6c747d7b6b306142e671",
          "commitAuthor": "Colin Patrick Mccabe",
          "commitDateOld": "28/10/14 4:41 PM",
          "commitNameOld": "ac9ab037e9a9b03e4fa9bd471d3ab9940beb53fb",
          "commitAuthorOld": "Colin Patrick Mccabe",
          "daysBetweenCommits": 2.03,
          "commitsBetweenForRepo": 30,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,60 +1,46 @@\n-  public synchronized List\u003cStorageLocation\u003e addVolumes(\n-      final List\u003cStorageLocation\u003e volumes, final Collection\u003cString\u003e bpids) {\n-    final Collection\u003cStorageLocation\u003e dataLocations \u003d\n-        DataNode.getStorageLocations(this.conf);\n-    final Map\u003cString, Storage.StorageDirectory\u003e allStorageDirs \u003d\n-        new HashMap\u003cString, Storage.StorageDirectory\u003e();\n-    List\u003cStorageLocation\u003e succeedVolumes \u003d Lists.newArrayList();\n-    try {\n-      for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n-        Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n-        allStorageDirs.put(sd.getRoot().getCanonicalPath(), sd);\n-      }\n-    } catch (IOException ioe) {\n-      LOG.warn(\"Caught exception when parsing storage URL.\", ioe);\n-      return succeedVolumes;\n-    }\n+  public void addVolume(final StorageLocation location,\n+      final List\u003cNamespaceInfo\u003e nsInfos)\n+      throws IOException {\n+    final File dir \u003d location.getFile();\n \n-    final boolean[] successFlags \u003d new boolean[volumes.size()];\n-    Arrays.fill(successFlags, false);\n-    List\u003cThread\u003e volumeAddingThreads \u003d Lists.newArrayList();\n-    for (int i \u003d 0; i \u003c volumes.size(); i++) {\n-      final int idx \u003d i;\n-      Thread t \u003d new Thread() {\n-        public void run() {\n-          StorageLocation vol \u003d volumes.get(idx);\n-          try {\n-            String key \u003d vol.getFile().getCanonicalPath();\n-            if (!allStorageDirs.containsKey(key)) {\n-              LOG.warn(\"Attempt to add an invalid volume: \" + vol.getFile());\n-            } else {\n-              addVolumeAndBlockPool(dataLocations, allStorageDirs.get(key),\n-                  bpids);\n-              successFlags[idx] \u003d true;\n-            }\n-          } catch (IOException e) {\n-            LOG.warn(\"Caught exception when adding volume \" + vol, e);\n-          }\n-        }\n-      };\n-      volumeAddingThreads.add(t);\n-      t.start();\n-    }\n+    // Prepare volume in DataStorage\n+    DataStorage.VolumeBuilder builder \u003d\n+        dataStorage.prepareVolume(datanode, location.getFile(), nsInfos);\n \n-    for (Thread t : volumeAddingThreads) {\n+    final Storage.StorageDirectory sd \u003d builder.getStorageDirectory();\n+\n+    StorageType storageType \u003d location.getStorageType();\n+    final FsVolumeImpl fsVolume \u003d new FsVolumeImpl(\n+        this, sd.getStorageUuid(), dir, this.conf, storageType);\n+    final ReplicaMap tempVolumeMap \u003d new ReplicaMap(fsVolume);\n+    ArrayList\u003cIOException\u003e exceptions \u003d Lists.newArrayList();\n+\n+    for (final NamespaceInfo nsInfo : nsInfos) {\n+      String bpid \u003d nsInfo.getBlockPoolID();\n       try {\n-        t.join();\n-      } catch (InterruptedException e) {\n-        LOG.warn(\"Caught InterruptedException when adding volume.\", e);\n+        fsVolume.addBlockPool(bpid, this.conf);\n+        fsVolume.getVolumeMap(bpid, tempVolumeMap, ramDiskReplicaTracker);\n+      } catch (IOException e) {\n+        LOG.warn(\"Caught exception when adding \" + fsVolume +\n+            \". Will throw later.\", e);\n+        exceptions.add(e);\n       }\n     }\n-\n-    setupAsyncLazyPersistThreads();\n-\n-    for (int i \u003d 0; i \u003c volumes.size(); i++) {\n-      if (successFlags[i]) {\n-        succeedVolumes.add(volumes.get(i));\n-      }\n+    if (!exceptions.isEmpty()) {\n+      throw MultipleIOException.createIOException(exceptions);\n     }\n-    return succeedVolumes;\n+\n+    setupAsyncLazyPersistThread(fsVolume);\n+\n+    builder.build();\n+    synchronized (this) {\n+      volumeMap.addAll(tempVolumeMap);\n+      storageMap.put(sd.getStorageUuid(),\n+          new DatanodeStorage(sd.getStorageUuid(),\n+              DatanodeStorage.State.NORMAL,\n+              storageType));\n+      asyncDiskService.addVolume(sd.getCurrentDir());\n+      volumes.addVolume(fsVolume);\n+    }\n+    LOG.info(\"Added volume - \" + dir + \", StorageType: \" + storageType);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void addVolume(final StorageLocation location,\n      final List\u003cNamespaceInfo\u003e nsInfos)\n      throws IOException {\n    final File dir \u003d location.getFile();\n\n    // Prepare volume in DataStorage\n    DataStorage.VolumeBuilder builder \u003d\n        dataStorage.prepareVolume(datanode, location.getFile(), nsInfos);\n\n    final Storage.StorageDirectory sd \u003d builder.getStorageDirectory();\n\n    StorageType storageType \u003d location.getStorageType();\n    final FsVolumeImpl fsVolume \u003d new FsVolumeImpl(\n        this, sd.getStorageUuid(), dir, this.conf, storageType);\n    final ReplicaMap tempVolumeMap \u003d new ReplicaMap(fsVolume);\n    ArrayList\u003cIOException\u003e exceptions \u003d Lists.newArrayList();\n\n    for (final NamespaceInfo nsInfo : nsInfos) {\n      String bpid \u003d nsInfo.getBlockPoolID();\n      try {\n        fsVolume.addBlockPool(bpid, this.conf);\n        fsVolume.getVolumeMap(bpid, tempVolumeMap, ramDiskReplicaTracker);\n      } catch (IOException e) {\n        LOG.warn(\"Caught exception when adding \" + fsVolume +\n            \". Will throw later.\", e);\n        exceptions.add(e);\n      }\n    }\n    if (!exceptions.isEmpty()) {\n      throw MultipleIOException.createIOException(exceptions);\n    }\n\n    setupAsyncLazyPersistThread(fsVolume);\n\n    builder.build();\n    synchronized (this) {\n      volumeMap.addAll(tempVolumeMap);\n      storageMap.put(sd.getStorageUuid(),\n          new DatanodeStorage(sd.getStorageUuid(),\n              DatanodeStorage.State.NORMAL,\n              storageType));\n      asyncDiskService.addVolume(sd.getCurrentDir());\n      volumes.addVolume(fsVolume);\n    }\n    LOG.info(\"Added volume - \" + dir + \", StorageType: \" + storageType);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
          "extendedDetails": {
            "oldValue": "[public, synchronized]",
            "newValue": "[public]"
          }
        },
        {
          "type": "Yexceptionschange",
          "commitMessage": "HDFS-7035. Make adding a new data directory to the DataNode an atomic operation and improve error handling (Lei Xu via Colin P. McCabe)\n",
          "commitDate": "30/10/14 5:31 PM",
          "commitName": "a9331fe9b071fdcdae0c6c747d7b6b306142e671",
          "commitAuthor": "Colin Patrick Mccabe",
          "commitDateOld": "28/10/14 4:41 PM",
          "commitNameOld": "ac9ab037e9a9b03e4fa9bd471d3ab9940beb53fb",
          "commitAuthorOld": "Colin Patrick Mccabe",
          "daysBetweenCommits": 2.03,
          "commitsBetweenForRepo": 30,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,60 +1,46 @@\n-  public synchronized List\u003cStorageLocation\u003e addVolumes(\n-      final List\u003cStorageLocation\u003e volumes, final Collection\u003cString\u003e bpids) {\n-    final Collection\u003cStorageLocation\u003e dataLocations \u003d\n-        DataNode.getStorageLocations(this.conf);\n-    final Map\u003cString, Storage.StorageDirectory\u003e allStorageDirs \u003d\n-        new HashMap\u003cString, Storage.StorageDirectory\u003e();\n-    List\u003cStorageLocation\u003e succeedVolumes \u003d Lists.newArrayList();\n-    try {\n-      for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n-        Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n-        allStorageDirs.put(sd.getRoot().getCanonicalPath(), sd);\n-      }\n-    } catch (IOException ioe) {\n-      LOG.warn(\"Caught exception when parsing storage URL.\", ioe);\n-      return succeedVolumes;\n-    }\n+  public void addVolume(final StorageLocation location,\n+      final List\u003cNamespaceInfo\u003e nsInfos)\n+      throws IOException {\n+    final File dir \u003d location.getFile();\n \n-    final boolean[] successFlags \u003d new boolean[volumes.size()];\n-    Arrays.fill(successFlags, false);\n-    List\u003cThread\u003e volumeAddingThreads \u003d Lists.newArrayList();\n-    for (int i \u003d 0; i \u003c volumes.size(); i++) {\n-      final int idx \u003d i;\n-      Thread t \u003d new Thread() {\n-        public void run() {\n-          StorageLocation vol \u003d volumes.get(idx);\n-          try {\n-            String key \u003d vol.getFile().getCanonicalPath();\n-            if (!allStorageDirs.containsKey(key)) {\n-              LOG.warn(\"Attempt to add an invalid volume: \" + vol.getFile());\n-            } else {\n-              addVolumeAndBlockPool(dataLocations, allStorageDirs.get(key),\n-                  bpids);\n-              successFlags[idx] \u003d true;\n-            }\n-          } catch (IOException e) {\n-            LOG.warn(\"Caught exception when adding volume \" + vol, e);\n-          }\n-        }\n-      };\n-      volumeAddingThreads.add(t);\n-      t.start();\n-    }\n+    // Prepare volume in DataStorage\n+    DataStorage.VolumeBuilder builder \u003d\n+        dataStorage.prepareVolume(datanode, location.getFile(), nsInfos);\n \n-    for (Thread t : volumeAddingThreads) {\n+    final Storage.StorageDirectory sd \u003d builder.getStorageDirectory();\n+\n+    StorageType storageType \u003d location.getStorageType();\n+    final FsVolumeImpl fsVolume \u003d new FsVolumeImpl(\n+        this, sd.getStorageUuid(), dir, this.conf, storageType);\n+    final ReplicaMap tempVolumeMap \u003d new ReplicaMap(fsVolume);\n+    ArrayList\u003cIOException\u003e exceptions \u003d Lists.newArrayList();\n+\n+    for (final NamespaceInfo nsInfo : nsInfos) {\n+      String bpid \u003d nsInfo.getBlockPoolID();\n       try {\n-        t.join();\n-      } catch (InterruptedException e) {\n-        LOG.warn(\"Caught InterruptedException when adding volume.\", e);\n+        fsVolume.addBlockPool(bpid, this.conf);\n+        fsVolume.getVolumeMap(bpid, tempVolumeMap, ramDiskReplicaTracker);\n+      } catch (IOException e) {\n+        LOG.warn(\"Caught exception when adding \" + fsVolume +\n+            \". Will throw later.\", e);\n+        exceptions.add(e);\n       }\n     }\n-\n-    setupAsyncLazyPersistThreads();\n-\n-    for (int i \u003d 0; i \u003c volumes.size(); i++) {\n-      if (successFlags[i]) {\n-        succeedVolumes.add(volumes.get(i));\n-      }\n+    if (!exceptions.isEmpty()) {\n+      throw MultipleIOException.createIOException(exceptions);\n     }\n-    return succeedVolumes;\n+\n+    setupAsyncLazyPersistThread(fsVolume);\n+\n+    builder.build();\n+    synchronized (this) {\n+      volumeMap.addAll(tempVolumeMap);\n+      storageMap.put(sd.getStorageUuid(),\n+          new DatanodeStorage(sd.getStorageUuid(),\n+              DatanodeStorage.State.NORMAL,\n+              storageType));\n+      asyncDiskService.addVolume(sd.getCurrentDir());\n+      volumes.addVolume(fsVolume);\n+    }\n+    LOG.info(\"Added volume - \" + dir + \", StorageType: \" + storageType);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void addVolume(final StorageLocation location,\n      final List\u003cNamespaceInfo\u003e nsInfos)\n      throws IOException {\n    final File dir \u003d location.getFile();\n\n    // Prepare volume in DataStorage\n    DataStorage.VolumeBuilder builder \u003d\n        dataStorage.prepareVolume(datanode, location.getFile(), nsInfos);\n\n    final Storage.StorageDirectory sd \u003d builder.getStorageDirectory();\n\n    StorageType storageType \u003d location.getStorageType();\n    final FsVolumeImpl fsVolume \u003d new FsVolumeImpl(\n        this, sd.getStorageUuid(), dir, this.conf, storageType);\n    final ReplicaMap tempVolumeMap \u003d new ReplicaMap(fsVolume);\n    ArrayList\u003cIOException\u003e exceptions \u003d Lists.newArrayList();\n\n    for (final NamespaceInfo nsInfo : nsInfos) {\n      String bpid \u003d nsInfo.getBlockPoolID();\n      try {\n        fsVolume.addBlockPool(bpid, this.conf);\n        fsVolume.getVolumeMap(bpid, tempVolumeMap, ramDiskReplicaTracker);\n      } catch (IOException e) {\n        LOG.warn(\"Caught exception when adding \" + fsVolume +\n            \". Will throw later.\", e);\n        exceptions.add(e);\n      }\n    }\n    if (!exceptions.isEmpty()) {\n      throw MultipleIOException.createIOException(exceptions);\n    }\n\n    setupAsyncLazyPersistThread(fsVolume);\n\n    builder.build();\n    synchronized (this) {\n      volumeMap.addAll(tempVolumeMap);\n      storageMap.put(sd.getStorageUuid(),\n          new DatanodeStorage(sd.getStorageUuid(),\n              DatanodeStorage.State.NORMAL,\n              storageType));\n      asyncDiskService.addVolume(sd.getCurrentDir());\n      volumes.addVolume(fsVolume);\n    }\n    LOG.info(\"Added volume - \" + dir + \", StorageType: \" + storageType);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[IOException]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7035. Make adding a new data directory to the DataNode an atomic operation and improve error handling (Lei Xu via Colin P. McCabe)\n",
          "commitDate": "30/10/14 5:31 PM",
          "commitName": "a9331fe9b071fdcdae0c6c747d7b6b306142e671",
          "commitAuthor": "Colin Patrick Mccabe",
          "commitDateOld": "28/10/14 4:41 PM",
          "commitNameOld": "ac9ab037e9a9b03e4fa9bd471d3ab9940beb53fb",
          "commitAuthorOld": "Colin Patrick Mccabe",
          "daysBetweenCommits": 2.03,
          "commitsBetweenForRepo": 30,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,60 +1,46 @@\n-  public synchronized List\u003cStorageLocation\u003e addVolumes(\n-      final List\u003cStorageLocation\u003e volumes, final Collection\u003cString\u003e bpids) {\n-    final Collection\u003cStorageLocation\u003e dataLocations \u003d\n-        DataNode.getStorageLocations(this.conf);\n-    final Map\u003cString, Storage.StorageDirectory\u003e allStorageDirs \u003d\n-        new HashMap\u003cString, Storage.StorageDirectory\u003e();\n-    List\u003cStorageLocation\u003e succeedVolumes \u003d Lists.newArrayList();\n-    try {\n-      for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n-        Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n-        allStorageDirs.put(sd.getRoot().getCanonicalPath(), sd);\n-      }\n-    } catch (IOException ioe) {\n-      LOG.warn(\"Caught exception when parsing storage URL.\", ioe);\n-      return succeedVolumes;\n-    }\n+  public void addVolume(final StorageLocation location,\n+      final List\u003cNamespaceInfo\u003e nsInfos)\n+      throws IOException {\n+    final File dir \u003d location.getFile();\n \n-    final boolean[] successFlags \u003d new boolean[volumes.size()];\n-    Arrays.fill(successFlags, false);\n-    List\u003cThread\u003e volumeAddingThreads \u003d Lists.newArrayList();\n-    for (int i \u003d 0; i \u003c volumes.size(); i++) {\n-      final int idx \u003d i;\n-      Thread t \u003d new Thread() {\n-        public void run() {\n-          StorageLocation vol \u003d volumes.get(idx);\n-          try {\n-            String key \u003d vol.getFile().getCanonicalPath();\n-            if (!allStorageDirs.containsKey(key)) {\n-              LOG.warn(\"Attempt to add an invalid volume: \" + vol.getFile());\n-            } else {\n-              addVolumeAndBlockPool(dataLocations, allStorageDirs.get(key),\n-                  bpids);\n-              successFlags[idx] \u003d true;\n-            }\n-          } catch (IOException e) {\n-            LOG.warn(\"Caught exception when adding volume \" + vol, e);\n-          }\n-        }\n-      };\n-      volumeAddingThreads.add(t);\n-      t.start();\n-    }\n+    // Prepare volume in DataStorage\n+    DataStorage.VolumeBuilder builder \u003d\n+        dataStorage.prepareVolume(datanode, location.getFile(), nsInfos);\n \n-    for (Thread t : volumeAddingThreads) {\n+    final Storage.StorageDirectory sd \u003d builder.getStorageDirectory();\n+\n+    StorageType storageType \u003d location.getStorageType();\n+    final FsVolumeImpl fsVolume \u003d new FsVolumeImpl(\n+        this, sd.getStorageUuid(), dir, this.conf, storageType);\n+    final ReplicaMap tempVolumeMap \u003d new ReplicaMap(fsVolume);\n+    ArrayList\u003cIOException\u003e exceptions \u003d Lists.newArrayList();\n+\n+    for (final NamespaceInfo nsInfo : nsInfos) {\n+      String bpid \u003d nsInfo.getBlockPoolID();\n       try {\n-        t.join();\n-      } catch (InterruptedException e) {\n-        LOG.warn(\"Caught InterruptedException when adding volume.\", e);\n+        fsVolume.addBlockPool(bpid, this.conf);\n+        fsVolume.getVolumeMap(bpid, tempVolumeMap, ramDiskReplicaTracker);\n+      } catch (IOException e) {\n+        LOG.warn(\"Caught exception when adding \" + fsVolume +\n+            \". Will throw later.\", e);\n+        exceptions.add(e);\n       }\n     }\n-\n-    setupAsyncLazyPersistThreads();\n-\n-    for (int i \u003d 0; i \u003c volumes.size(); i++) {\n-      if (successFlags[i]) {\n-        succeedVolumes.add(volumes.get(i));\n-      }\n+    if (!exceptions.isEmpty()) {\n+      throw MultipleIOException.createIOException(exceptions);\n     }\n-    return succeedVolumes;\n+\n+    setupAsyncLazyPersistThread(fsVolume);\n+\n+    builder.build();\n+    synchronized (this) {\n+      volumeMap.addAll(tempVolumeMap);\n+      storageMap.put(sd.getStorageUuid(),\n+          new DatanodeStorage(sd.getStorageUuid(),\n+              DatanodeStorage.State.NORMAL,\n+              storageType));\n+      asyncDiskService.addVolume(sd.getCurrentDir());\n+      volumes.addVolume(fsVolume);\n+    }\n+    LOG.info(\"Added volume - \" + dir + \", StorageType: \" + storageType);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void addVolume(final StorageLocation location,\n      final List\u003cNamespaceInfo\u003e nsInfos)\n      throws IOException {\n    final File dir \u003d location.getFile();\n\n    // Prepare volume in DataStorage\n    DataStorage.VolumeBuilder builder \u003d\n        dataStorage.prepareVolume(datanode, location.getFile(), nsInfos);\n\n    final Storage.StorageDirectory sd \u003d builder.getStorageDirectory();\n\n    StorageType storageType \u003d location.getStorageType();\n    final FsVolumeImpl fsVolume \u003d new FsVolumeImpl(\n        this, sd.getStorageUuid(), dir, this.conf, storageType);\n    final ReplicaMap tempVolumeMap \u003d new ReplicaMap(fsVolume);\n    ArrayList\u003cIOException\u003e exceptions \u003d Lists.newArrayList();\n\n    for (final NamespaceInfo nsInfo : nsInfos) {\n      String bpid \u003d nsInfo.getBlockPoolID();\n      try {\n        fsVolume.addBlockPool(bpid, this.conf);\n        fsVolume.getVolumeMap(bpid, tempVolumeMap, ramDiskReplicaTracker);\n      } catch (IOException e) {\n        LOG.warn(\"Caught exception when adding \" + fsVolume +\n            \". Will throw later.\", e);\n        exceptions.add(e);\n      }\n    }\n    if (!exceptions.isEmpty()) {\n      throw MultipleIOException.createIOException(exceptions);\n    }\n\n    setupAsyncLazyPersistThread(fsVolume);\n\n    builder.build();\n    synchronized (this) {\n      volumeMap.addAll(tempVolumeMap);\n      storageMap.put(sd.getStorageUuid(),\n          new DatanodeStorage(sd.getStorageUuid(),\n              DatanodeStorage.State.NORMAL,\n              storageType));\n      asyncDiskService.addVolume(sd.getCurrentDir());\n      volumes.addVolume(fsVolume);\n    }\n    LOG.info(\"Added volume - \" + dir + \", StorageType: \" + storageType);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
          "extendedDetails": {}
        }
      ]
    },
    "1efd9c98258fbb973d2058dcf0850042e53bd02f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7112. LazyWriter should use either async IO or one thread per physical disk. Contributed by Xiaoyu Yao.\n",
      "commitDate": "07/10/14 8:25 PM",
      "commitName": "1efd9c98258fbb973d2058dcf0850042e53bd02f",
      "commitAuthor": "cnauroth",
      "commitDateOld": "30/09/14 12:53 AM",
      "commitNameOld": "5e8b6973527e5f714652641ed95e8a4509e18cfa",
      "commitAuthorOld": "arp",
      "daysBetweenCommits": 7.81,
      "commitsBetweenForRepo": 80,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,58 +1,60 @@\n   public synchronized List\u003cStorageLocation\u003e addVolumes(\n       final List\u003cStorageLocation\u003e volumes, final Collection\u003cString\u003e bpids) {\n     final Collection\u003cStorageLocation\u003e dataLocations \u003d\n         DataNode.getStorageLocations(this.conf);\n     final Map\u003cString, Storage.StorageDirectory\u003e allStorageDirs \u003d\n         new HashMap\u003cString, Storage.StorageDirectory\u003e();\n     List\u003cStorageLocation\u003e succeedVolumes \u003d Lists.newArrayList();\n     try {\n       for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n         Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n         allStorageDirs.put(sd.getRoot().getCanonicalPath(), sd);\n       }\n     } catch (IOException ioe) {\n       LOG.warn(\"Caught exception when parsing storage URL.\", ioe);\n       return succeedVolumes;\n     }\n \n     final boolean[] successFlags \u003d new boolean[volumes.size()];\n     Arrays.fill(successFlags, false);\n     List\u003cThread\u003e volumeAddingThreads \u003d Lists.newArrayList();\n     for (int i \u003d 0; i \u003c volumes.size(); i++) {\n       final int idx \u003d i;\n       Thread t \u003d new Thread() {\n         public void run() {\n           StorageLocation vol \u003d volumes.get(idx);\n           try {\n             String key \u003d vol.getFile().getCanonicalPath();\n             if (!allStorageDirs.containsKey(key)) {\n               LOG.warn(\"Attempt to add an invalid volume: \" + vol.getFile());\n             } else {\n               addVolumeAndBlockPool(dataLocations, allStorageDirs.get(key),\n                   bpids);\n               successFlags[idx] \u003d true;\n             }\n           } catch (IOException e) {\n             LOG.warn(\"Caught exception when adding volume \" + vol, e);\n           }\n         }\n       };\n       volumeAddingThreads.add(t);\n       t.start();\n     }\n \n     for (Thread t : volumeAddingThreads) {\n       try {\n         t.join();\n       } catch (InterruptedException e) {\n         LOG.warn(\"Caught InterruptedException when adding volume.\", e);\n       }\n     }\n \n+    setupAsyncLazyPersistThreads();\n+\n     for (int i \u003d 0; i \u003c volumes.size(); i++) {\n       if (successFlags[i]) {\n         succeedVolumes.add(volumes.get(i));\n       }\n     }\n     return succeedVolumes;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized List\u003cStorageLocation\u003e addVolumes(\n      final List\u003cStorageLocation\u003e volumes, final Collection\u003cString\u003e bpids) {\n    final Collection\u003cStorageLocation\u003e dataLocations \u003d\n        DataNode.getStorageLocations(this.conf);\n    final Map\u003cString, Storage.StorageDirectory\u003e allStorageDirs \u003d\n        new HashMap\u003cString, Storage.StorageDirectory\u003e();\n    List\u003cStorageLocation\u003e succeedVolumes \u003d Lists.newArrayList();\n    try {\n      for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n        Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n        allStorageDirs.put(sd.getRoot().getCanonicalPath(), sd);\n      }\n    } catch (IOException ioe) {\n      LOG.warn(\"Caught exception when parsing storage URL.\", ioe);\n      return succeedVolumes;\n    }\n\n    final boolean[] successFlags \u003d new boolean[volumes.size()];\n    Arrays.fill(successFlags, false);\n    List\u003cThread\u003e volumeAddingThreads \u003d Lists.newArrayList();\n    for (int i \u003d 0; i \u003c volumes.size(); i++) {\n      final int idx \u003d i;\n      Thread t \u003d new Thread() {\n        public void run() {\n          StorageLocation vol \u003d volumes.get(idx);\n          try {\n            String key \u003d vol.getFile().getCanonicalPath();\n            if (!allStorageDirs.containsKey(key)) {\n              LOG.warn(\"Attempt to add an invalid volume: \" + vol.getFile());\n            } else {\n              addVolumeAndBlockPool(dataLocations, allStorageDirs.get(key),\n                  bpids);\n              successFlags[idx] \u003d true;\n            }\n          } catch (IOException e) {\n            LOG.warn(\"Caught exception when adding volume \" + vol, e);\n          }\n        }\n      };\n      volumeAddingThreads.add(t);\n      t.start();\n    }\n\n    for (Thread t : volumeAddingThreads) {\n      try {\n        t.join();\n      } catch (InterruptedException e) {\n        LOG.warn(\"Caught InterruptedException when adding volume.\", e);\n      }\n    }\n\n    setupAsyncLazyPersistThreads();\n\n    for (int i \u003d 0; i \u003c volumes.size(); i++) {\n      if (successFlags[i]) {\n        succeedVolumes.add(volumes.get(i));\n      }\n    }\n    return succeedVolumes;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "fe38d2e9b5ac7e13f97cd2d3d2a984ab6bbaaf77": {
      "type": "Ymultichange(Yparameterchange,Yreturntypechange,Yexceptionschange,Ybodychange)",
      "commitMessage": "HDFS-6727. Refresh data volumes on DataNode based on configuration changes (Lei Xu via Colin Patrick McCabe)\n",
      "commitDate": "18/09/14 4:52 PM",
      "commitName": "fe38d2e9b5ac7e13f97cd2d3d2a984ab6bbaaf77",
      "commitAuthor": "Colin Patrick Mccabe",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-6727. Refresh data volumes on DataNode based on configuration changes (Lei Xu via Colin Patrick McCabe)\n",
          "commitDate": "18/09/14 4:52 PM",
          "commitName": "fe38d2e9b5ac7e13f97cd2d3d2a984ab6bbaaf77",
          "commitAuthor": "Colin Patrick Mccabe",
          "commitDateOld": "08/09/14 9:20 PM",
          "commitNameOld": "f949f6b54825dac61511a5761837e2fd14437239",
          "commitAuthorOld": "arp",
          "daysBetweenCommits": 9.81,
          "commitsBetweenForRepo": 117,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,20 +1,58 @@\n-  public synchronized void addVolumes(Collection\u003cStorageLocation\u003e volumes)\n-      throws IOException {\n+  public synchronized List\u003cStorageLocation\u003e addVolumes(\n+      final List\u003cStorageLocation\u003e volumes, final Collection\u003cString\u003e bpids) {\n     final Collection\u003cStorageLocation\u003e dataLocations \u003d\n         DataNode.getStorageLocations(this.conf);\n-    Map\u003cString, Storage.StorageDirectory\u003e allStorageDirs \u003d\n+    final Map\u003cString, Storage.StorageDirectory\u003e allStorageDirs \u003d\n         new HashMap\u003cString, Storage.StorageDirectory\u003e();\n-    for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n-      Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n-      allStorageDirs.put(sd.getRoot().getAbsolutePath(), sd);\n+    List\u003cStorageLocation\u003e succeedVolumes \u003d Lists.newArrayList();\n+    try {\n+      for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n+        Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n+        allStorageDirs.put(sd.getRoot().getCanonicalPath(), sd);\n+      }\n+    } catch (IOException ioe) {\n+      LOG.warn(\"Caught exception when parsing storage URL.\", ioe);\n+      return succeedVolumes;\n     }\n \n-    for (StorageLocation vol : volumes) {\n-      String key \u003d vol.getFile().getAbsolutePath();\n-      if (!allStorageDirs.containsKey(key)) {\n-        LOG.warn(\"Attempt to add an invalid volume: \" + vol.getFile());\n-      } else {\n-        addVolume(dataLocations, allStorageDirs.get(key));\n+    final boolean[] successFlags \u003d new boolean[volumes.size()];\n+    Arrays.fill(successFlags, false);\n+    List\u003cThread\u003e volumeAddingThreads \u003d Lists.newArrayList();\n+    for (int i \u003d 0; i \u003c volumes.size(); i++) {\n+      final int idx \u003d i;\n+      Thread t \u003d new Thread() {\n+        public void run() {\n+          StorageLocation vol \u003d volumes.get(idx);\n+          try {\n+            String key \u003d vol.getFile().getCanonicalPath();\n+            if (!allStorageDirs.containsKey(key)) {\n+              LOG.warn(\"Attempt to add an invalid volume: \" + vol.getFile());\n+            } else {\n+              addVolumeAndBlockPool(dataLocations, allStorageDirs.get(key),\n+                  bpids);\n+              successFlags[idx] \u003d true;\n+            }\n+          } catch (IOException e) {\n+            LOG.warn(\"Caught exception when adding volume \" + vol, e);\n+          }\n+        }\n+      };\n+      volumeAddingThreads.add(t);\n+      t.start();\n+    }\n+\n+    for (Thread t : volumeAddingThreads) {\n+      try {\n+        t.join();\n+      } catch (InterruptedException e) {\n+        LOG.warn(\"Caught InterruptedException when adding volume.\", e);\n       }\n     }\n+\n+    for (int i \u003d 0; i \u003c volumes.size(); i++) {\n+      if (successFlags[i]) {\n+        succeedVolumes.add(volumes.get(i));\n+      }\n+    }\n+    return succeedVolumes;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public synchronized List\u003cStorageLocation\u003e addVolumes(\n      final List\u003cStorageLocation\u003e volumes, final Collection\u003cString\u003e bpids) {\n    final Collection\u003cStorageLocation\u003e dataLocations \u003d\n        DataNode.getStorageLocations(this.conf);\n    final Map\u003cString, Storage.StorageDirectory\u003e allStorageDirs \u003d\n        new HashMap\u003cString, Storage.StorageDirectory\u003e();\n    List\u003cStorageLocation\u003e succeedVolumes \u003d Lists.newArrayList();\n    try {\n      for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n        Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n        allStorageDirs.put(sd.getRoot().getCanonicalPath(), sd);\n      }\n    } catch (IOException ioe) {\n      LOG.warn(\"Caught exception when parsing storage URL.\", ioe);\n      return succeedVolumes;\n    }\n\n    final boolean[] successFlags \u003d new boolean[volumes.size()];\n    Arrays.fill(successFlags, false);\n    List\u003cThread\u003e volumeAddingThreads \u003d Lists.newArrayList();\n    for (int i \u003d 0; i \u003c volumes.size(); i++) {\n      final int idx \u003d i;\n      Thread t \u003d new Thread() {\n        public void run() {\n          StorageLocation vol \u003d volumes.get(idx);\n          try {\n            String key \u003d vol.getFile().getCanonicalPath();\n            if (!allStorageDirs.containsKey(key)) {\n              LOG.warn(\"Attempt to add an invalid volume: \" + vol.getFile());\n            } else {\n              addVolumeAndBlockPool(dataLocations, allStorageDirs.get(key),\n                  bpids);\n              successFlags[idx] \u003d true;\n            }\n          } catch (IOException e) {\n            LOG.warn(\"Caught exception when adding volume \" + vol, e);\n          }\n        }\n      };\n      volumeAddingThreads.add(t);\n      t.start();\n    }\n\n    for (Thread t : volumeAddingThreads) {\n      try {\n        t.join();\n      } catch (InterruptedException e) {\n        LOG.warn(\"Caught InterruptedException when adding volume.\", e);\n      }\n    }\n\n    for (int i \u003d 0; i \u003c volumes.size(); i++) {\n      if (successFlags[i]) {\n        succeedVolumes.add(volumes.get(i));\n      }\n    }\n    return succeedVolumes;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
          "extendedDetails": {
            "oldValue": "[volumes-Collection\u003cStorageLocation\u003e]",
            "newValue": "[volumes-List\u003cStorageLocation\u003e(modifiers-final), bpids-Collection\u003cString\u003e(modifiers-final)]"
          }
        },
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-6727. Refresh data volumes on DataNode based on configuration changes (Lei Xu via Colin Patrick McCabe)\n",
          "commitDate": "18/09/14 4:52 PM",
          "commitName": "fe38d2e9b5ac7e13f97cd2d3d2a984ab6bbaaf77",
          "commitAuthor": "Colin Patrick Mccabe",
          "commitDateOld": "08/09/14 9:20 PM",
          "commitNameOld": "f949f6b54825dac61511a5761837e2fd14437239",
          "commitAuthorOld": "arp",
          "daysBetweenCommits": 9.81,
          "commitsBetweenForRepo": 117,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,20 +1,58 @@\n-  public synchronized void addVolumes(Collection\u003cStorageLocation\u003e volumes)\n-      throws IOException {\n+  public synchronized List\u003cStorageLocation\u003e addVolumes(\n+      final List\u003cStorageLocation\u003e volumes, final Collection\u003cString\u003e bpids) {\n     final Collection\u003cStorageLocation\u003e dataLocations \u003d\n         DataNode.getStorageLocations(this.conf);\n-    Map\u003cString, Storage.StorageDirectory\u003e allStorageDirs \u003d\n+    final Map\u003cString, Storage.StorageDirectory\u003e allStorageDirs \u003d\n         new HashMap\u003cString, Storage.StorageDirectory\u003e();\n-    for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n-      Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n-      allStorageDirs.put(sd.getRoot().getAbsolutePath(), sd);\n+    List\u003cStorageLocation\u003e succeedVolumes \u003d Lists.newArrayList();\n+    try {\n+      for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n+        Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n+        allStorageDirs.put(sd.getRoot().getCanonicalPath(), sd);\n+      }\n+    } catch (IOException ioe) {\n+      LOG.warn(\"Caught exception when parsing storage URL.\", ioe);\n+      return succeedVolumes;\n     }\n \n-    for (StorageLocation vol : volumes) {\n-      String key \u003d vol.getFile().getAbsolutePath();\n-      if (!allStorageDirs.containsKey(key)) {\n-        LOG.warn(\"Attempt to add an invalid volume: \" + vol.getFile());\n-      } else {\n-        addVolume(dataLocations, allStorageDirs.get(key));\n+    final boolean[] successFlags \u003d new boolean[volumes.size()];\n+    Arrays.fill(successFlags, false);\n+    List\u003cThread\u003e volumeAddingThreads \u003d Lists.newArrayList();\n+    for (int i \u003d 0; i \u003c volumes.size(); i++) {\n+      final int idx \u003d i;\n+      Thread t \u003d new Thread() {\n+        public void run() {\n+          StorageLocation vol \u003d volumes.get(idx);\n+          try {\n+            String key \u003d vol.getFile().getCanonicalPath();\n+            if (!allStorageDirs.containsKey(key)) {\n+              LOG.warn(\"Attempt to add an invalid volume: \" + vol.getFile());\n+            } else {\n+              addVolumeAndBlockPool(dataLocations, allStorageDirs.get(key),\n+                  bpids);\n+              successFlags[idx] \u003d true;\n+            }\n+          } catch (IOException e) {\n+            LOG.warn(\"Caught exception when adding volume \" + vol, e);\n+          }\n+        }\n+      };\n+      volumeAddingThreads.add(t);\n+      t.start();\n+    }\n+\n+    for (Thread t : volumeAddingThreads) {\n+      try {\n+        t.join();\n+      } catch (InterruptedException e) {\n+        LOG.warn(\"Caught InterruptedException when adding volume.\", e);\n       }\n     }\n+\n+    for (int i \u003d 0; i \u003c volumes.size(); i++) {\n+      if (successFlags[i]) {\n+        succeedVolumes.add(volumes.get(i));\n+      }\n+    }\n+    return succeedVolumes;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public synchronized List\u003cStorageLocation\u003e addVolumes(\n      final List\u003cStorageLocation\u003e volumes, final Collection\u003cString\u003e bpids) {\n    final Collection\u003cStorageLocation\u003e dataLocations \u003d\n        DataNode.getStorageLocations(this.conf);\n    final Map\u003cString, Storage.StorageDirectory\u003e allStorageDirs \u003d\n        new HashMap\u003cString, Storage.StorageDirectory\u003e();\n    List\u003cStorageLocation\u003e succeedVolumes \u003d Lists.newArrayList();\n    try {\n      for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n        Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n        allStorageDirs.put(sd.getRoot().getCanonicalPath(), sd);\n      }\n    } catch (IOException ioe) {\n      LOG.warn(\"Caught exception when parsing storage URL.\", ioe);\n      return succeedVolumes;\n    }\n\n    final boolean[] successFlags \u003d new boolean[volumes.size()];\n    Arrays.fill(successFlags, false);\n    List\u003cThread\u003e volumeAddingThreads \u003d Lists.newArrayList();\n    for (int i \u003d 0; i \u003c volumes.size(); i++) {\n      final int idx \u003d i;\n      Thread t \u003d new Thread() {\n        public void run() {\n          StorageLocation vol \u003d volumes.get(idx);\n          try {\n            String key \u003d vol.getFile().getCanonicalPath();\n            if (!allStorageDirs.containsKey(key)) {\n              LOG.warn(\"Attempt to add an invalid volume: \" + vol.getFile());\n            } else {\n              addVolumeAndBlockPool(dataLocations, allStorageDirs.get(key),\n                  bpids);\n              successFlags[idx] \u003d true;\n            }\n          } catch (IOException e) {\n            LOG.warn(\"Caught exception when adding volume \" + vol, e);\n          }\n        }\n      };\n      volumeAddingThreads.add(t);\n      t.start();\n    }\n\n    for (Thread t : volumeAddingThreads) {\n      try {\n        t.join();\n      } catch (InterruptedException e) {\n        LOG.warn(\"Caught InterruptedException when adding volume.\", e);\n      }\n    }\n\n    for (int i \u003d 0; i \u003c volumes.size(); i++) {\n      if (successFlags[i]) {\n        succeedVolumes.add(volumes.get(i));\n      }\n    }\n    return succeedVolumes;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
          "extendedDetails": {
            "oldValue": "void",
            "newValue": "List\u003cStorageLocation\u003e"
          }
        },
        {
          "type": "Yexceptionschange",
          "commitMessage": "HDFS-6727. Refresh data volumes on DataNode based on configuration changes (Lei Xu via Colin Patrick McCabe)\n",
          "commitDate": "18/09/14 4:52 PM",
          "commitName": "fe38d2e9b5ac7e13f97cd2d3d2a984ab6bbaaf77",
          "commitAuthor": "Colin Patrick Mccabe",
          "commitDateOld": "08/09/14 9:20 PM",
          "commitNameOld": "f949f6b54825dac61511a5761837e2fd14437239",
          "commitAuthorOld": "arp",
          "daysBetweenCommits": 9.81,
          "commitsBetweenForRepo": 117,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,20 +1,58 @@\n-  public synchronized void addVolumes(Collection\u003cStorageLocation\u003e volumes)\n-      throws IOException {\n+  public synchronized List\u003cStorageLocation\u003e addVolumes(\n+      final List\u003cStorageLocation\u003e volumes, final Collection\u003cString\u003e bpids) {\n     final Collection\u003cStorageLocation\u003e dataLocations \u003d\n         DataNode.getStorageLocations(this.conf);\n-    Map\u003cString, Storage.StorageDirectory\u003e allStorageDirs \u003d\n+    final Map\u003cString, Storage.StorageDirectory\u003e allStorageDirs \u003d\n         new HashMap\u003cString, Storage.StorageDirectory\u003e();\n-    for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n-      Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n-      allStorageDirs.put(sd.getRoot().getAbsolutePath(), sd);\n+    List\u003cStorageLocation\u003e succeedVolumes \u003d Lists.newArrayList();\n+    try {\n+      for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n+        Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n+        allStorageDirs.put(sd.getRoot().getCanonicalPath(), sd);\n+      }\n+    } catch (IOException ioe) {\n+      LOG.warn(\"Caught exception when parsing storage URL.\", ioe);\n+      return succeedVolumes;\n     }\n \n-    for (StorageLocation vol : volumes) {\n-      String key \u003d vol.getFile().getAbsolutePath();\n-      if (!allStorageDirs.containsKey(key)) {\n-        LOG.warn(\"Attempt to add an invalid volume: \" + vol.getFile());\n-      } else {\n-        addVolume(dataLocations, allStorageDirs.get(key));\n+    final boolean[] successFlags \u003d new boolean[volumes.size()];\n+    Arrays.fill(successFlags, false);\n+    List\u003cThread\u003e volumeAddingThreads \u003d Lists.newArrayList();\n+    for (int i \u003d 0; i \u003c volumes.size(); i++) {\n+      final int idx \u003d i;\n+      Thread t \u003d new Thread() {\n+        public void run() {\n+          StorageLocation vol \u003d volumes.get(idx);\n+          try {\n+            String key \u003d vol.getFile().getCanonicalPath();\n+            if (!allStorageDirs.containsKey(key)) {\n+              LOG.warn(\"Attempt to add an invalid volume: \" + vol.getFile());\n+            } else {\n+              addVolumeAndBlockPool(dataLocations, allStorageDirs.get(key),\n+                  bpids);\n+              successFlags[idx] \u003d true;\n+            }\n+          } catch (IOException e) {\n+            LOG.warn(\"Caught exception when adding volume \" + vol, e);\n+          }\n+        }\n+      };\n+      volumeAddingThreads.add(t);\n+      t.start();\n+    }\n+\n+    for (Thread t : volumeAddingThreads) {\n+      try {\n+        t.join();\n+      } catch (InterruptedException e) {\n+        LOG.warn(\"Caught InterruptedException when adding volume.\", e);\n       }\n     }\n+\n+    for (int i \u003d 0; i \u003c volumes.size(); i++) {\n+      if (successFlags[i]) {\n+        succeedVolumes.add(volumes.get(i));\n+      }\n+    }\n+    return succeedVolumes;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public synchronized List\u003cStorageLocation\u003e addVolumes(\n      final List\u003cStorageLocation\u003e volumes, final Collection\u003cString\u003e bpids) {\n    final Collection\u003cStorageLocation\u003e dataLocations \u003d\n        DataNode.getStorageLocations(this.conf);\n    final Map\u003cString, Storage.StorageDirectory\u003e allStorageDirs \u003d\n        new HashMap\u003cString, Storage.StorageDirectory\u003e();\n    List\u003cStorageLocation\u003e succeedVolumes \u003d Lists.newArrayList();\n    try {\n      for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n        Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n        allStorageDirs.put(sd.getRoot().getCanonicalPath(), sd);\n      }\n    } catch (IOException ioe) {\n      LOG.warn(\"Caught exception when parsing storage URL.\", ioe);\n      return succeedVolumes;\n    }\n\n    final boolean[] successFlags \u003d new boolean[volumes.size()];\n    Arrays.fill(successFlags, false);\n    List\u003cThread\u003e volumeAddingThreads \u003d Lists.newArrayList();\n    for (int i \u003d 0; i \u003c volumes.size(); i++) {\n      final int idx \u003d i;\n      Thread t \u003d new Thread() {\n        public void run() {\n          StorageLocation vol \u003d volumes.get(idx);\n          try {\n            String key \u003d vol.getFile().getCanonicalPath();\n            if (!allStorageDirs.containsKey(key)) {\n              LOG.warn(\"Attempt to add an invalid volume: \" + vol.getFile());\n            } else {\n              addVolumeAndBlockPool(dataLocations, allStorageDirs.get(key),\n                  bpids);\n              successFlags[idx] \u003d true;\n            }\n          } catch (IOException e) {\n            LOG.warn(\"Caught exception when adding volume \" + vol, e);\n          }\n        }\n      };\n      volumeAddingThreads.add(t);\n      t.start();\n    }\n\n    for (Thread t : volumeAddingThreads) {\n      try {\n        t.join();\n      } catch (InterruptedException e) {\n        LOG.warn(\"Caught InterruptedException when adding volume.\", e);\n      }\n    }\n\n    for (int i \u003d 0; i \u003c volumes.size(); i++) {\n      if (successFlags[i]) {\n        succeedVolumes.add(volumes.get(i));\n      }\n    }\n    return succeedVolumes;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
          "extendedDetails": {
            "oldValue": "[IOException]",
            "newValue": "[]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-6727. Refresh data volumes on DataNode based on configuration changes (Lei Xu via Colin Patrick McCabe)\n",
          "commitDate": "18/09/14 4:52 PM",
          "commitName": "fe38d2e9b5ac7e13f97cd2d3d2a984ab6bbaaf77",
          "commitAuthor": "Colin Patrick Mccabe",
          "commitDateOld": "08/09/14 9:20 PM",
          "commitNameOld": "f949f6b54825dac61511a5761837e2fd14437239",
          "commitAuthorOld": "arp",
          "daysBetweenCommits": 9.81,
          "commitsBetweenForRepo": 117,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,20 +1,58 @@\n-  public synchronized void addVolumes(Collection\u003cStorageLocation\u003e volumes)\n-      throws IOException {\n+  public synchronized List\u003cStorageLocation\u003e addVolumes(\n+      final List\u003cStorageLocation\u003e volumes, final Collection\u003cString\u003e bpids) {\n     final Collection\u003cStorageLocation\u003e dataLocations \u003d\n         DataNode.getStorageLocations(this.conf);\n-    Map\u003cString, Storage.StorageDirectory\u003e allStorageDirs \u003d\n+    final Map\u003cString, Storage.StorageDirectory\u003e allStorageDirs \u003d\n         new HashMap\u003cString, Storage.StorageDirectory\u003e();\n-    for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n-      Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n-      allStorageDirs.put(sd.getRoot().getAbsolutePath(), sd);\n+    List\u003cStorageLocation\u003e succeedVolumes \u003d Lists.newArrayList();\n+    try {\n+      for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n+        Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n+        allStorageDirs.put(sd.getRoot().getCanonicalPath(), sd);\n+      }\n+    } catch (IOException ioe) {\n+      LOG.warn(\"Caught exception when parsing storage URL.\", ioe);\n+      return succeedVolumes;\n     }\n \n-    for (StorageLocation vol : volumes) {\n-      String key \u003d vol.getFile().getAbsolutePath();\n-      if (!allStorageDirs.containsKey(key)) {\n-        LOG.warn(\"Attempt to add an invalid volume: \" + vol.getFile());\n-      } else {\n-        addVolume(dataLocations, allStorageDirs.get(key));\n+    final boolean[] successFlags \u003d new boolean[volumes.size()];\n+    Arrays.fill(successFlags, false);\n+    List\u003cThread\u003e volumeAddingThreads \u003d Lists.newArrayList();\n+    for (int i \u003d 0; i \u003c volumes.size(); i++) {\n+      final int idx \u003d i;\n+      Thread t \u003d new Thread() {\n+        public void run() {\n+          StorageLocation vol \u003d volumes.get(idx);\n+          try {\n+            String key \u003d vol.getFile().getCanonicalPath();\n+            if (!allStorageDirs.containsKey(key)) {\n+              LOG.warn(\"Attempt to add an invalid volume: \" + vol.getFile());\n+            } else {\n+              addVolumeAndBlockPool(dataLocations, allStorageDirs.get(key),\n+                  bpids);\n+              successFlags[idx] \u003d true;\n+            }\n+          } catch (IOException e) {\n+            LOG.warn(\"Caught exception when adding volume \" + vol, e);\n+          }\n+        }\n+      };\n+      volumeAddingThreads.add(t);\n+      t.start();\n+    }\n+\n+    for (Thread t : volumeAddingThreads) {\n+      try {\n+        t.join();\n+      } catch (InterruptedException e) {\n+        LOG.warn(\"Caught InterruptedException when adding volume.\", e);\n       }\n     }\n+\n+    for (int i \u003d 0; i \u003c volumes.size(); i++) {\n+      if (successFlags[i]) {\n+        succeedVolumes.add(volumes.get(i));\n+      }\n+    }\n+    return succeedVolumes;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public synchronized List\u003cStorageLocation\u003e addVolumes(\n      final List\u003cStorageLocation\u003e volumes, final Collection\u003cString\u003e bpids) {\n    final Collection\u003cStorageLocation\u003e dataLocations \u003d\n        DataNode.getStorageLocations(this.conf);\n    final Map\u003cString, Storage.StorageDirectory\u003e allStorageDirs \u003d\n        new HashMap\u003cString, Storage.StorageDirectory\u003e();\n    List\u003cStorageLocation\u003e succeedVolumes \u003d Lists.newArrayList();\n    try {\n      for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n        Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n        allStorageDirs.put(sd.getRoot().getCanonicalPath(), sd);\n      }\n    } catch (IOException ioe) {\n      LOG.warn(\"Caught exception when parsing storage URL.\", ioe);\n      return succeedVolumes;\n    }\n\n    final boolean[] successFlags \u003d new boolean[volumes.size()];\n    Arrays.fill(successFlags, false);\n    List\u003cThread\u003e volumeAddingThreads \u003d Lists.newArrayList();\n    for (int i \u003d 0; i \u003c volumes.size(); i++) {\n      final int idx \u003d i;\n      Thread t \u003d new Thread() {\n        public void run() {\n          StorageLocation vol \u003d volumes.get(idx);\n          try {\n            String key \u003d vol.getFile().getCanonicalPath();\n            if (!allStorageDirs.containsKey(key)) {\n              LOG.warn(\"Attempt to add an invalid volume: \" + vol.getFile());\n            } else {\n              addVolumeAndBlockPool(dataLocations, allStorageDirs.get(key),\n                  bpids);\n              successFlags[idx] \u003d true;\n            }\n          } catch (IOException e) {\n            LOG.warn(\"Caught exception when adding volume \" + vol, e);\n          }\n        }\n      };\n      volumeAddingThreads.add(t);\n      t.start();\n    }\n\n    for (Thread t : volumeAddingThreads) {\n      try {\n        t.join();\n      } catch (InterruptedException e) {\n        LOG.warn(\"Caught InterruptedException when adding volume.\", e);\n      }\n    }\n\n    for (int i \u003d 0; i \u003c volumes.size(); i++) {\n      if (successFlags[i]) {\n        succeedVolumes.add(volumes.get(i));\n      }\n    }\n    return succeedVolumes;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
          "extendedDetails": {}
        }
      ]
    },
    "d758be1f35f6c1c7e9edd491af559721a3b8b8f8": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-6740. Make FSDataset support adding data volumes dynamically. Contributed by Lei Xu.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1616623 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/08/14 3:59 PM",
      "commitName": "d758be1f35f6c1c7e9edd491af559721a3b8b8f8",
      "commitAuthor": "Aaron Myers",
      "diff": "@@ -0,0 +1,20 @@\n+  public synchronized void addVolumes(Collection\u003cStorageLocation\u003e volumes)\n+      throws IOException {\n+    final Collection\u003cStorageLocation\u003e dataLocations \u003d\n+        DataNode.getStorageLocations(this.conf);\n+    Map\u003cString, Storage.StorageDirectory\u003e allStorageDirs \u003d\n+        new HashMap\u003cString, Storage.StorageDirectory\u003e();\n+    for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n+      Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n+      allStorageDirs.put(sd.getRoot().getAbsolutePath(), sd);\n+    }\n+\n+    for (StorageLocation vol : volumes) {\n+      String key \u003d vol.getFile().getAbsolutePath();\n+      if (!allStorageDirs.containsKey(key)) {\n+        LOG.warn(\"Attempt to add an invalid volume: \" + vol.getFile());\n+      } else {\n+        addVolume(dataLocations, allStorageDirs.get(key));\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void addVolumes(Collection\u003cStorageLocation\u003e volumes)\n      throws IOException {\n    final Collection\u003cStorageLocation\u003e dataLocations \u003d\n        DataNode.getStorageLocations(this.conf);\n    Map\u003cString, Storage.StorageDirectory\u003e allStorageDirs \u003d\n        new HashMap\u003cString, Storage.StorageDirectory\u003e();\n    for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n      Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n      allStorageDirs.put(sd.getRoot().getAbsolutePath(), sd);\n    }\n\n    for (StorageLocation vol : volumes) {\n      String key \u003d vol.getFile().getAbsolutePath();\n      if (!allStorageDirs.containsKey(key)) {\n        LOG.warn(\"Attempt to add an invalid volume: \" + vol.getFile());\n      } else {\n        addVolume(dataLocations, allStorageDirs.get(key));\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java"
    }
  }
}