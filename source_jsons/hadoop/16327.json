{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "RouterClientProtocol.java",
  "functionName": "getListing",
  "functionId": "getListing___src-String__startAfter-byte[]__needLocation-boolean",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterClientProtocol.java",
  "functionStartLine": 769,
  "functionEndLine": 882,
  "numCommitsSeen": 40,
  "timeTaken": 4781,
  "changeHistory": [
    "80b877a72f52ef0f4acafe15db55b8ed61fbe6d2",
    "375224edebb1c937afe4bbea8fe884499ca8ece5",
    "ffbb6b6557f4eb8587c7d57cda38f2a0de573f8b",
    "3deb5d345f439cbebcad5296c69689e8334f59ce",
    "203664e6b258b642239651fa6a17fd2561b903d2",
    "b320caecb32e0eb739ad925a4646bef1a85caebd",
    "f4bd1114ff529e971f9b496ad62a7edca37fdf8d",
    "6425ed27ea638da75f656204d6df4adad1d91fe1"
  ],
  "changeHistoryShort": {
    "80b877a72f52ef0f4acafe15db55b8ed61fbe6d2": "Ybodychange",
    "375224edebb1c937afe4bbea8fe884499ca8ece5": "Ybodychange",
    "ffbb6b6557f4eb8587c7d57cda38f2a0de573f8b": "Ybodychange",
    "3deb5d345f439cbebcad5296c69689e8334f59ce": "Ybodychange",
    "203664e6b258b642239651fa6a17fd2561b903d2": "Ybodychange",
    "b320caecb32e0eb739ad925a4646bef1a85caebd": "Ybodychange",
    "f4bd1114ff529e971f9b496ad62a7edca37fdf8d": "Ybodychange",
    "6425ed27ea638da75f656204d6df4adad1d91fe1": "Yintroduced"
  },
  "changeHistoryDetails": {
    "80b877a72f52ef0f4acafe15db55b8ed61fbe6d2": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-15196. RBF: RouterRpcServer getListing cannot list large dirs correctly. Contributed by Fengnan Li.\n",
      "commitDate": "30/03/20 12:29 PM",
      "commitName": "80b877a72f52ef0f4acafe15db55b8ed61fbe6d2",
      "commitAuthor": "Inigo Goiri",
      "commitDateOld": "23/01/20 4:48 AM",
      "commitNameOld": "92c58901d767f4fea571274544a590608c911cb8",
      "commitAuthorOld": "Ayush Saxena",
      "daysBetweenCommits": 67.28,
      "commitsBetweenForRepo": 221,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,91 +1,114 @@\n   public DirectoryListing getListing(String src, byte[] startAfter,\n       boolean needLocation) throws IOException {\n     rpcServer.checkOperation(NameNode.OperationCategory.READ);\n \n     List\u003cRemoteResult\u003cRemoteLocation, DirectoryListing\u003e\u003e listings \u003d\n         getListingInt(src, startAfter, needLocation);\n-    Map\u003cString, HdfsFileStatus\u003e nnListing \u003d new TreeMap\u003c\u003e();\n+    TreeMap\u003cString, HdfsFileStatus\u003e nnListing \u003d new TreeMap\u003c\u003e();\n     int totalRemainingEntries \u003d 0;\n     int remainingEntries \u003d 0;\n     boolean namenodeListingExists \u003d false;\n+    // Check the subcluster listing with the smallest name to make sure\n+    // no file is skipped across subclusters\n+    String lastName \u003d null;\n     if (listings !\u003d null) {\n-      // Check the subcluster listing with the smallest name\n-      String lastName \u003d null;\n       for (RemoteResult\u003cRemoteLocation, DirectoryListing\u003e result : listings) {\n         if (result.hasException()) {\n           IOException ioe \u003d result.getException();\n           if (ioe instanceof FileNotFoundException) {\n             RemoteLocation location \u003d result.getLocation();\n             LOG.debug(\"Cannot get listing from {}\", location);\n           } else if (!allowPartialList) {\n             throw ioe;\n           }\n         } else if (result.getResult() !\u003d null) {\n           DirectoryListing listing \u003d result.getResult();\n           totalRemainingEntries +\u003d listing.getRemainingEntries();\n           HdfsFileStatus[] partialListing \u003d listing.getPartialListing();\n           int length \u003d partialListing.length;\n           if (length \u003e 0) {\n             HdfsFileStatus lastLocalEntry \u003d partialListing[length-1];\n             String lastLocalName \u003d lastLocalEntry.getLocalName();\n             if (lastName \u003d\u003d null || lastName.compareTo(lastLocalName) \u003e 0) {\n               lastName \u003d lastLocalName;\n             }\n           }\n         }\n       }\n \n       // Add existing entries\n       for (RemoteResult\u003cRemoteLocation, DirectoryListing\u003e result : listings) {\n         DirectoryListing listing \u003d result.getResult();\n         if (listing !\u003d null) {\n           namenodeListingExists \u003d true;\n           for (HdfsFileStatus file : listing.getPartialListing()) {\n             String filename \u003d file.getLocalName();\n             if (totalRemainingEntries \u003e 0 \u0026\u0026\n                 filename.compareTo(lastName) \u003e 0) {\n               // Discarding entries further than the lastName\n               remainingEntries++;\n             } else {\n               nnListing.put(filename, file);\n             }\n           }\n           remainingEntries +\u003d listing.getRemainingEntries();\n         }\n       }\n     }\n \n     // Add mount points at this level in the tree\n     final List\u003cString\u003e children \u003d subclusterResolver.getMountPoints(src);\n+    // Sort the list as the entries from subcluster are also sorted\n+    if (children !\u003d null) {\n+      Collections.sort(children);\n+    }\n     if (children !\u003d null) {\n       // Get the dates for each mount point\n       Map\u003cString, Long\u003e dates \u003d getMountPointDates(src);\n \n       // Create virtual folder with the mount name\n       for (String child : children) {\n         long date \u003d 0;\n         if (dates !\u003d null \u0026\u0026 dates.containsKey(child)) {\n           date \u003d dates.get(child);\n         }\n         Path childPath \u003d new Path(src, child);\n         HdfsFileStatus dirStatus \u003d\n             getMountPointStatus(childPath.toString(), 0, date);\n \n-        // This may overwrite existing listing entries with the mount point\n-        // TODO don\u0027t add if already there?\n-        nnListing.put(child, dirStatus);\n+        // if there is no subcluster path, always add mount point\n+        if (lastName \u003d\u003d null) {\n+          nnListing.put(child, dirStatus);\n+        } else {\n+          if (shouldAddMountPoint(child,\n+                lastName, startAfter, remainingEntries)) {\n+            // This may overwrite existing listing entries with the mount point\n+            // TODO don\u0027t add if already there?\n+            nnListing.put(child, dirStatus);\n+          }\n+        }\n+      }\n+      // Update the remaining count to include left mount points\n+      if (nnListing.size() \u003e 0) {\n+        String lastListing \u003d nnListing.lastKey();\n+        for (int i \u003d 0; i \u003c children.size(); i++) {\n+          if (children.get(i).compareTo(lastListing) \u003e 0) {\n+            remainingEntries +\u003d (children.size() - i);\n+            break;\n+          }\n+        }\n       }\n     }\n \n     if (!namenodeListingExists \u0026\u0026 nnListing.size() \u003d\u003d 0) {\n       // NN returns a null object if the directory cannot be found and has no\n       // listing. If we didn\u0027t retrieve any NN listing data, and there are no\n       // mount points here, return null.\n       return null;\n     }\n \n     // Generate combined listing\n     HdfsFileStatus[] combinedData \u003d new HdfsFileStatus[nnListing.size()];\n     combinedData \u003d nnListing.values().toArray(combinedData);\n     return new DirectoryListing(combinedData, remainingEntries);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public DirectoryListing getListing(String src, byte[] startAfter,\n      boolean needLocation) throws IOException {\n    rpcServer.checkOperation(NameNode.OperationCategory.READ);\n\n    List\u003cRemoteResult\u003cRemoteLocation, DirectoryListing\u003e\u003e listings \u003d\n        getListingInt(src, startAfter, needLocation);\n    TreeMap\u003cString, HdfsFileStatus\u003e nnListing \u003d new TreeMap\u003c\u003e();\n    int totalRemainingEntries \u003d 0;\n    int remainingEntries \u003d 0;\n    boolean namenodeListingExists \u003d false;\n    // Check the subcluster listing with the smallest name to make sure\n    // no file is skipped across subclusters\n    String lastName \u003d null;\n    if (listings !\u003d null) {\n      for (RemoteResult\u003cRemoteLocation, DirectoryListing\u003e result : listings) {\n        if (result.hasException()) {\n          IOException ioe \u003d result.getException();\n          if (ioe instanceof FileNotFoundException) {\n            RemoteLocation location \u003d result.getLocation();\n            LOG.debug(\"Cannot get listing from {}\", location);\n          } else if (!allowPartialList) {\n            throw ioe;\n          }\n        } else if (result.getResult() !\u003d null) {\n          DirectoryListing listing \u003d result.getResult();\n          totalRemainingEntries +\u003d listing.getRemainingEntries();\n          HdfsFileStatus[] partialListing \u003d listing.getPartialListing();\n          int length \u003d partialListing.length;\n          if (length \u003e 0) {\n            HdfsFileStatus lastLocalEntry \u003d partialListing[length-1];\n            String lastLocalName \u003d lastLocalEntry.getLocalName();\n            if (lastName \u003d\u003d null || lastName.compareTo(lastLocalName) \u003e 0) {\n              lastName \u003d lastLocalName;\n            }\n          }\n        }\n      }\n\n      // Add existing entries\n      for (RemoteResult\u003cRemoteLocation, DirectoryListing\u003e result : listings) {\n        DirectoryListing listing \u003d result.getResult();\n        if (listing !\u003d null) {\n          namenodeListingExists \u003d true;\n          for (HdfsFileStatus file : listing.getPartialListing()) {\n            String filename \u003d file.getLocalName();\n            if (totalRemainingEntries \u003e 0 \u0026\u0026\n                filename.compareTo(lastName) \u003e 0) {\n              // Discarding entries further than the lastName\n              remainingEntries++;\n            } else {\n              nnListing.put(filename, file);\n            }\n          }\n          remainingEntries +\u003d listing.getRemainingEntries();\n        }\n      }\n    }\n\n    // Add mount points at this level in the tree\n    final List\u003cString\u003e children \u003d subclusterResolver.getMountPoints(src);\n    // Sort the list as the entries from subcluster are also sorted\n    if (children !\u003d null) {\n      Collections.sort(children);\n    }\n    if (children !\u003d null) {\n      // Get the dates for each mount point\n      Map\u003cString, Long\u003e dates \u003d getMountPointDates(src);\n\n      // Create virtual folder with the mount name\n      for (String child : children) {\n        long date \u003d 0;\n        if (dates !\u003d null \u0026\u0026 dates.containsKey(child)) {\n          date \u003d dates.get(child);\n        }\n        Path childPath \u003d new Path(src, child);\n        HdfsFileStatus dirStatus \u003d\n            getMountPointStatus(childPath.toString(), 0, date);\n\n        // if there is no subcluster path, always add mount point\n        if (lastName \u003d\u003d null) {\n          nnListing.put(child, dirStatus);\n        } else {\n          if (shouldAddMountPoint(child,\n                lastName, startAfter, remainingEntries)) {\n            // This may overwrite existing listing entries with the mount point\n            // TODO don\u0027t add if already there?\n            nnListing.put(child, dirStatus);\n          }\n        }\n      }\n      // Update the remaining count to include left mount points\n      if (nnListing.size() \u003e 0) {\n        String lastListing \u003d nnListing.lastKey();\n        for (int i \u003d 0; i \u003c children.size(); i++) {\n          if (children.get(i).compareTo(lastListing) \u003e 0) {\n            remainingEntries +\u003d (children.size() - i);\n            break;\n          }\n        }\n      }\n    }\n\n    if (!namenodeListingExists \u0026\u0026 nnListing.size() \u003d\u003d 0) {\n      // NN returns a null object if the directory cannot be found and has no\n      // listing. If we didn\u0027t retrieve any NN listing data, and there are no\n      // mount points here, return null.\n      return null;\n    }\n\n    // Generate combined listing\n    HdfsFileStatus[] combinedData \u003d new HdfsFileStatus[nnListing.size()];\n    combinedData \u003d nnListing.values().toArray(combinedData);\n    return new DirectoryListing(combinedData, remainingEntries);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterClientProtocol.java",
      "extendedDetails": {}
    },
    "375224edebb1c937afe4bbea8fe884499ca8ece5": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14739. RBF: LS command for mount point shows wrong owner and permission information. Contributed by Jinglun.\n",
      "commitDate": "16/10/19 6:56 AM",
      "commitName": "375224edebb1c937afe4bbea8fe884499ca8ece5",
      "commitAuthor": "Ayush Saxena",
      "commitDateOld": "28/08/19 10:48 AM",
      "commitNameOld": "48cb58390655b87506fb8b620e4aafd11e38bb34",
      "commitAuthorOld": "Inigo Goiri",
      "daysBetweenCommits": 48.84,
      "commitsBetweenForRepo": 394,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,97 +1,91 @@\n   public DirectoryListing getListing(String src, byte[] startAfter,\n       boolean needLocation) throws IOException {\n     rpcServer.checkOperation(NameNode.OperationCategory.READ);\n \n-    // Locate the dir and fetch the listing\n-    final List\u003cRemoteLocation\u003e locations \u003d\n-        rpcServer.getLocationsForPath(src, false, false);\n-    RemoteMethod method \u003d new RemoteMethod(\"getListing\",\n-        new Class\u003c?\u003e[] {String.class, startAfter.getClass(), boolean.class},\n-        new RemoteParam(), startAfter, needLocation);\n-    final List\u003cRemoteResult\u003cRemoteLocation, DirectoryListing\u003e\u003e listings \u003d\n-        rpcClient.invokeConcurrent(\n-            locations, method, false, -1, DirectoryListing.class);\n-\n+    List\u003cRemoteResult\u003cRemoteLocation, DirectoryListing\u003e\u003e listings \u003d\n+        getListingInt(src, startAfter, needLocation);\n     Map\u003cString, HdfsFileStatus\u003e nnListing \u003d new TreeMap\u003c\u003e();\n     int totalRemainingEntries \u003d 0;\n     int remainingEntries \u003d 0;\n     boolean namenodeListingExists \u003d false;\n     if (listings !\u003d null) {\n       // Check the subcluster listing with the smallest name\n       String lastName \u003d null;\n       for (RemoteResult\u003cRemoteLocation, DirectoryListing\u003e result : listings) {\n         if (result.hasException()) {\n           IOException ioe \u003d result.getException();\n           if (ioe instanceof FileNotFoundException) {\n             RemoteLocation location \u003d result.getLocation();\n             LOG.debug(\"Cannot get listing from {}\", location);\n           } else if (!allowPartialList) {\n             throw ioe;\n           }\n         } else if (result.getResult() !\u003d null) {\n           DirectoryListing listing \u003d result.getResult();\n           totalRemainingEntries +\u003d listing.getRemainingEntries();\n           HdfsFileStatus[] partialListing \u003d listing.getPartialListing();\n           int length \u003d partialListing.length;\n           if (length \u003e 0) {\n             HdfsFileStatus lastLocalEntry \u003d partialListing[length-1];\n             String lastLocalName \u003d lastLocalEntry.getLocalName();\n             if (lastName \u003d\u003d null || lastName.compareTo(lastLocalName) \u003e 0) {\n               lastName \u003d lastLocalName;\n             }\n           }\n         }\n       }\n \n       // Add existing entries\n       for (RemoteResult\u003cRemoteLocation, DirectoryListing\u003e result : listings) {\n         DirectoryListing listing \u003d result.getResult();\n         if (listing !\u003d null) {\n           namenodeListingExists \u003d true;\n           for (HdfsFileStatus file : listing.getPartialListing()) {\n             String filename \u003d file.getLocalName();\n             if (totalRemainingEntries \u003e 0 \u0026\u0026\n                 filename.compareTo(lastName) \u003e 0) {\n               // Discarding entries further than the lastName\n               remainingEntries++;\n             } else {\n               nnListing.put(filename, file);\n             }\n           }\n           remainingEntries +\u003d listing.getRemainingEntries();\n         }\n       }\n     }\n \n     // Add mount points at this level in the tree\n     final List\u003cString\u003e children \u003d subclusterResolver.getMountPoints(src);\n     if (children !\u003d null) {\n       // Get the dates for each mount point\n       Map\u003cString, Long\u003e dates \u003d getMountPointDates(src);\n \n       // Create virtual folder with the mount name\n       for (String child : children) {\n         long date \u003d 0;\n         if (dates !\u003d null \u0026\u0026 dates.containsKey(child)) {\n           date \u003d dates.get(child);\n         }\n-        HdfsFileStatus dirStatus \u003d getMountPointStatus(child, 0, date);\n+        Path childPath \u003d new Path(src, child);\n+        HdfsFileStatus dirStatus \u003d\n+            getMountPointStatus(childPath.toString(), 0, date);\n \n         // This may overwrite existing listing entries with the mount point\n         // TODO don\u0027t add if already there?\n         nnListing.put(child, dirStatus);\n       }\n     }\n \n     if (!namenodeListingExists \u0026\u0026 nnListing.size() \u003d\u003d 0) {\n       // NN returns a null object if the directory cannot be found and has no\n       // listing. If we didn\u0027t retrieve any NN listing data, and there are no\n       // mount points here, return null.\n       return null;\n     }\n \n     // Generate combined listing\n     HdfsFileStatus[] combinedData \u003d new HdfsFileStatus[nnListing.size()];\n     combinedData \u003d nnListing.values().toArray(combinedData);\n     return new DirectoryListing(combinedData, remainingEntries);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public DirectoryListing getListing(String src, byte[] startAfter,\n      boolean needLocation) throws IOException {\n    rpcServer.checkOperation(NameNode.OperationCategory.READ);\n\n    List\u003cRemoteResult\u003cRemoteLocation, DirectoryListing\u003e\u003e listings \u003d\n        getListingInt(src, startAfter, needLocation);\n    Map\u003cString, HdfsFileStatus\u003e nnListing \u003d new TreeMap\u003c\u003e();\n    int totalRemainingEntries \u003d 0;\n    int remainingEntries \u003d 0;\n    boolean namenodeListingExists \u003d false;\n    if (listings !\u003d null) {\n      // Check the subcluster listing with the smallest name\n      String lastName \u003d null;\n      for (RemoteResult\u003cRemoteLocation, DirectoryListing\u003e result : listings) {\n        if (result.hasException()) {\n          IOException ioe \u003d result.getException();\n          if (ioe instanceof FileNotFoundException) {\n            RemoteLocation location \u003d result.getLocation();\n            LOG.debug(\"Cannot get listing from {}\", location);\n          } else if (!allowPartialList) {\n            throw ioe;\n          }\n        } else if (result.getResult() !\u003d null) {\n          DirectoryListing listing \u003d result.getResult();\n          totalRemainingEntries +\u003d listing.getRemainingEntries();\n          HdfsFileStatus[] partialListing \u003d listing.getPartialListing();\n          int length \u003d partialListing.length;\n          if (length \u003e 0) {\n            HdfsFileStatus lastLocalEntry \u003d partialListing[length-1];\n            String lastLocalName \u003d lastLocalEntry.getLocalName();\n            if (lastName \u003d\u003d null || lastName.compareTo(lastLocalName) \u003e 0) {\n              lastName \u003d lastLocalName;\n            }\n          }\n        }\n      }\n\n      // Add existing entries\n      for (RemoteResult\u003cRemoteLocation, DirectoryListing\u003e result : listings) {\n        DirectoryListing listing \u003d result.getResult();\n        if (listing !\u003d null) {\n          namenodeListingExists \u003d true;\n          for (HdfsFileStatus file : listing.getPartialListing()) {\n            String filename \u003d file.getLocalName();\n            if (totalRemainingEntries \u003e 0 \u0026\u0026\n                filename.compareTo(lastName) \u003e 0) {\n              // Discarding entries further than the lastName\n              remainingEntries++;\n            } else {\n              nnListing.put(filename, file);\n            }\n          }\n          remainingEntries +\u003d listing.getRemainingEntries();\n        }\n      }\n    }\n\n    // Add mount points at this level in the tree\n    final List\u003cString\u003e children \u003d subclusterResolver.getMountPoints(src);\n    if (children !\u003d null) {\n      // Get the dates for each mount point\n      Map\u003cString, Long\u003e dates \u003d getMountPointDates(src);\n\n      // Create virtual folder with the mount name\n      for (String child : children) {\n        long date \u003d 0;\n        if (dates !\u003d null \u0026\u0026 dates.containsKey(child)) {\n          date \u003d dates.get(child);\n        }\n        Path childPath \u003d new Path(src, child);\n        HdfsFileStatus dirStatus \u003d\n            getMountPointStatus(childPath.toString(), 0, date);\n\n        // This may overwrite existing listing entries with the mount point\n        // TODO don\u0027t add if already there?\n        nnListing.put(child, dirStatus);\n      }\n    }\n\n    if (!namenodeListingExists \u0026\u0026 nnListing.size() \u003d\u003d 0) {\n      // NN returns a null object if the directory cannot be found and has no\n      // listing. If we didn\u0027t retrieve any NN listing data, and there are no\n      // mount points here, return null.\n      return null;\n    }\n\n    // Generate combined listing\n    HdfsFileStatus[] combinedData \u003d new HdfsFileStatus[nnListing.size()];\n    combinedData \u003d nnListing.values().toArray(combinedData);\n    return new DirectoryListing(combinedData, remainingEntries);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterClientProtocol.java",
      "extendedDetails": {}
    },
    "ffbb6b6557f4eb8587c7d57cda38f2a0de573f8b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13255. RBF: Fail when try to remove mount point paths. Contributed by Akira Ajisaka.\n",
      "commitDate": "24/06/19 9:33 AM",
      "commitName": "ffbb6b6557f4eb8587c7d57cda38f2a0de573f8b",
      "commitAuthor": "Ayush Saxena",
      "commitDateOld": "24/06/19 9:33 AM",
      "commitNameOld": "3deb5d345f439cbebcad5296c69689e8334f59ce",
      "commitAuthorOld": "Giovanni Matteo Fumarola",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,97 +1,97 @@\n   public DirectoryListing getListing(String src, byte[] startAfter,\n       boolean needLocation) throws IOException {\n     rpcServer.checkOperation(NameNode.OperationCategory.READ);\n \n     // Locate the dir and fetch the listing\n     final List\u003cRemoteLocation\u003e locations \u003d\n-        rpcServer.getLocationsForPath(src, true, false);\n+        rpcServer.getLocationsForPath(src, false, false);\n     RemoteMethod method \u003d new RemoteMethod(\"getListing\",\n         new Class\u003c?\u003e[] {String.class, startAfter.getClass(), boolean.class},\n         new RemoteParam(), startAfter, needLocation);\n     final List\u003cRemoteResult\u003cRemoteLocation, DirectoryListing\u003e\u003e listings \u003d\n         rpcClient.invokeConcurrent(\n             locations, method, false, -1, DirectoryListing.class);\n \n     Map\u003cString, HdfsFileStatus\u003e nnListing \u003d new TreeMap\u003c\u003e();\n     int totalRemainingEntries \u003d 0;\n     int remainingEntries \u003d 0;\n     boolean namenodeListingExists \u003d false;\n     if (listings !\u003d null) {\n       // Check the subcluster listing with the smallest name\n       String lastName \u003d null;\n       for (RemoteResult\u003cRemoteLocation, DirectoryListing\u003e result : listings) {\n         if (result.hasException()) {\n           IOException ioe \u003d result.getException();\n           if (ioe instanceof FileNotFoundException) {\n             RemoteLocation location \u003d result.getLocation();\n             LOG.debug(\"Cannot get listing from {}\", location);\n           } else if (!allowPartialList) {\n             throw ioe;\n           }\n         } else if (result.getResult() !\u003d null) {\n           DirectoryListing listing \u003d result.getResult();\n           totalRemainingEntries +\u003d listing.getRemainingEntries();\n           HdfsFileStatus[] partialListing \u003d listing.getPartialListing();\n           int length \u003d partialListing.length;\n           if (length \u003e 0) {\n             HdfsFileStatus lastLocalEntry \u003d partialListing[length-1];\n             String lastLocalName \u003d lastLocalEntry.getLocalName();\n             if (lastName \u003d\u003d null || lastName.compareTo(lastLocalName) \u003e 0) {\n               lastName \u003d lastLocalName;\n             }\n           }\n         }\n       }\n \n       // Add existing entries\n       for (RemoteResult\u003cRemoteLocation, DirectoryListing\u003e result : listings) {\n         DirectoryListing listing \u003d result.getResult();\n         if (listing !\u003d null) {\n           namenodeListingExists \u003d true;\n           for (HdfsFileStatus file : listing.getPartialListing()) {\n             String filename \u003d file.getLocalName();\n             if (totalRemainingEntries \u003e 0 \u0026\u0026\n                 filename.compareTo(lastName) \u003e 0) {\n               // Discarding entries further than the lastName\n               remainingEntries++;\n             } else {\n               nnListing.put(filename, file);\n             }\n           }\n           remainingEntries +\u003d listing.getRemainingEntries();\n         }\n       }\n     }\n \n     // Add mount points at this level in the tree\n     final List\u003cString\u003e children \u003d subclusterResolver.getMountPoints(src);\n     if (children !\u003d null) {\n       // Get the dates for each mount point\n       Map\u003cString, Long\u003e dates \u003d getMountPointDates(src);\n \n       // Create virtual folder with the mount name\n       for (String child : children) {\n         long date \u003d 0;\n         if (dates !\u003d null \u0026\u0026 dates.containsKey(child)) {\n           date \u003d dates.get(child);\n         }\n         HdfsFileStatus dirStatus \u003d getMountPointStatus(child, 0, date);\n \n         // This may overwrite existing listing entries with the mount point\n         // TODO don\u0027t add if already there?\n         nnListing.put(child, dirStatus);\n       }\n     }\n \n     if (!namenodeListingExists \u0026\u0026 nnListing.size() \u003d\u003d 0) {\n       // NN returns a null object if the directory cannot be found and has no\n       // listing. If we didn\u0027t retrieve any NN listing data, and there are no\n       // mount points here, return null.\n       return null;\n     }\n \n     // Generate combined listing\n     HdfsFileStatus[] combinedData \u003d new HdfsFileStatus[nnListing.size()];\n     combinedData \u003d nnListing.values().toArray(combinedData);\n     return new DirectoryListing(combinedData, remainingEntries);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public DirectoryListing getListing(String src, byte[] startAfter,\n      boolean needLocation) throws IOException {\n    rpcServer.checkOperation(NameNode.OperationCategory.READ);\n\n    // Locate the dir and fetch the listing\n    final List\u003cRemoteLocation\u003e locations \u003d\n        rpcServer.getLocationsForPath(src, false, false);\n    RemoteMethod method \u003d new RemoteMethod(\"getListing\",\n        new Class\u003c?\u003e[] {String.class, startAfter.getClass(), boolean.class},\n        new RemoteParam(), startAfter, needLocation);\n    final List\u003cRemoteResult\u003cRemoteLocation, DirectoryListing\u003e\u003e listings \u003d\n        rpcClient.invokeConcurrent(\n            locations, method, false, -1, DirectoryListing.class);\n\n    Map\u003cString, HdfsFileStatus\u003e nnListing \u003d new TreeMap\u003c\u003e();\n    int totalRemainingEntries \u003d 0;\n    int remainingEntries \u003d 0;\n    boolean namenodeListingExists \u003d false;\n    if (listings !\u003d null) {\n      // Check the subcluster listing with the smallest name\n      String lastName \u003d null;\n      for (RemoteResult\u003cRemoteLocation, DirectoryListing\u003e result : listings) {\n        if (result.hasException()) {\n          IOException ioe \u003d result.getException();\n          if (ioe instanceof FileNotFoundException) {\n            RemoteLocation location \u003d result.getLocation();\n            LOG.debug(\"Cannot get listing from {}\", location);\n          } else if (!allowPartialList) {\n            throw ioe;\n          }\n        } else if (result.getResult() !\u003d null) {\n          DirectoryListing listing \u003d result.getResult();\n          totalRemainingEntries +\u003d listing.getRemainingEntries();\n          HdfsFileStatus[] partialListing \u003d listing.getPartialListing();\n          int length \u003d partialListing.length;\n          if (length \u003e 0) {\n            HdfsFileStatus lastLocalEntry \u003d partialListing[length-1];\n            String lastLocalName \u003d lastLocalEntry.getLocalName();\n            if (lastName \u003d\u003d null || lastName.compareTo(lastLocalName) \u003e 0) {\n              lastName \u003d lastLocalName;\n            }\n          }\n        }\n      }\n\n      // Add existing entries\n      for (RemoteResult\u003cRemoteLocation, DirectoryListing\u003e result : listings) {\n        DirectoryListing listing \u003d result.getResult();\n        if (listing !\u003d null) {\n          namenodeListingExists \u003d true;\n          for (HdfsFileStatus file : listing.getPartialListing()) {\n            String filename \u003d file.getLocalName();\n            if (totalRemainingEntries \u003e 0 \u0026\u0026\n                filename.compareTo(lastName) \u003e 0) {\n              // Discarding entries further than the lastName\n              remainingEntries++;\n            } else {\n              nnListing.put(filename, file);\n            }\n          }\n          remainingEntries +\u003d listing.getRemainingEntries();\n        }\n      }\n    }\n\n    // Add mount points at this level in the tree\n    final List\u003cString\u003e children \u003d subclusterResolver.getMountPoints(src);\n    if (children !\u003d null) {\n      // Get the dates for each mount point\n      Map\u003cString, Long\u003e dates \u003d getMountPointDates(src);\n\n      // Create virtual folder with the mount name\n      for (String child : children) {\n        long date \u003d 0;\n        if (dates !\u003d null \u0026\u0026 dates.containsKey(child)) {\n          date \u003d dates.get(child);\n        }\n        HdfsFileStatus dirStatus \u003d getMountPointStatus(child, 0, date);\n\n        // This may overwrite existing listing entries with the mount point\n        // TODO don\u0027t add if already there?\n        nnListing.put(child, dirStatus);\n      }\n    }\n\n    if (!namenodeListingExists \u0026\u0026 nnListing.size() \u003d\u003d 0) {\n      // NN returns a null object if the directory cannot be found and has no\n      // listing. If we didn\u0027t retrieve any NN listing data, and there are no\n      // mount points here, return null.\n      return null;\n    }\n\n    // Generate combined listing\n    HdfsFileStatus[] combinedData \u003d new HdfsFileStatus[nnListing.size()];\n    combinedData \u003d nnListing.values().toArray(combinedData);\n    return new DirectoryListing(combinedData, remainingEntries);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterClientProtocol.java",
      "extendedDetails": {}
    },
    "3deb5d345f439cbebcad5296c69689e8334f59ce": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14490. RBF: Remove unnecessary quota checks. Contributed by Ayush Saxena.\n",
      "commitDate": "24/06/19 9:33 AM",
      "commitName": "3deb5d345f439cbebcad5296c69689e8334f59ce",
      "commitAuthor": "Giovanni Matteo Fumarola",
      "commitDateOld": "24/06/19 9:33 AM",
      "commitNameOld": "62fa53a01dc7165d7965cdd4fddb444082f0602c",
      "commitAuthorOld": "Ayush Saxena",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,97 +1,97 @@\n   public DirectoryListing getListing(String src, byte[] startAfter,\n       boolean needLocation) throws IOException {\n     rpcServer.checkOperation(NameNode.OperationCategory.READ);\n \n     // Locate the dir and fetch the listing\n     final List\u003cRemoteLocation\u003e locations \u003d\n-        rpcServer.getLocationsForPath(src, true);\n+        rpcServer.getLocationsForPath(src, true, false);\n     RemoteMethod method \u003d new RemoteMethod(\"getListing\",\n         new Class\u003c?\u003e[] {String.class, startAfter.getClass(), boolean.class},\n         new RemoteParam(), startAfter, needLocation);\n     final List\u003cRemoteResult\u003cRemoteLocation, DirectoryListing\u003e\u003e listings \u003d\n         rpcClient.invokeConcurrent(\n             locations, method, false, -1, DirectoryListing.class);\n \n     Map\u003cString, HdfsFileStatus\u003e nnListing \u003d new TreeMap\u003c\u003e();\n     int totalRemainingEntries \u003d 0;\n     int remainingEntries \u003d 0;\n     boolean namenodeListingExists \u003d false;\n     if (listings !\u003d null) {\n       // Check the subcluster listing with the smallest name\n       String lastName \u003d null;\n       for (RemoteResult\u003cRemoteLocation, DirectoryListing\u003e result : listings) {\n         if (result.hasException()) {\n           IOException ioe \u003d result.getException();\n           if (ioe instanceof FileNotFoundException) {\n             RemoteLocation location \u003d result.getLocation();\n             LOG.debug(\"Cannot get listing from {}\", location);\n           } else if (!allowPartialList) {\n             throw ioe;\n           }\n         } else if (result.getResult() !\u003d null) {\n           DirectoryListing listing \u003d result.getResult();\n           totalRemainingEntries +\u003d listing.getRemainingEntries();\n           HdfsFileStatus[] partialListing \u003d listing.getPartialListing();\n           int length \u003d partialListing.length;\n           if (length \u003e 0) {\n             HdfsFileStatus lastLocalEntry \u003d partialListing[length-1];\n             String lastLocalName \u003d lastLocalEntry.getLocalName();\n             if (lastName \u003d\u003d null || lastName.compareTo(lastLocalName) \u003e 0) {\n               lastName \u003d lastLocalName;\n             }\n           }\n         }\n       }\n \n       // Add existing entries\n       for (RemoteResult\u003cRemoteLocation, DirectoryListing\u003e result : listings) {\n         DirectoryListing listing \u003d result.getResult();\n         if (listing !\u003d null) {\n           namenodeListingExists \u003d true;\n           for (HdfsFileStatus file : listing.getPartialListing()) {\n             String filename \u003d file.getLocalName();\n             if (totalRemainingEntries \u003e 0 \u0026\u0026\n                 filename.compareTo(lastName) \u003e 0) {\n               // Discarding entries further than the lastName\n               remainingEntries++;\n             } else {\n               nnListing.put(filename, file);\n             }\n           }\n           remainingEntries +\u003d listing.getRemainingEntries();\n         }\n       }\n     }\n \n     // Add mount points at this level in the tree\n     final List\u003cString\u003e children \u003d subclusterResolver.getMountPoints(src);\n     if (children !\u003d null) {\n       // Get the dates for each mount point\n       Map\u003cString, Long\u003e dates \u003d getMountPointDates(src);\n \n       // Create virtual folder with the mount name\n       for (String child : children) {\n         long date \u003d 0;\n         if (dates !\u003d null \u0026\u0026 dates.containsKey(child)) {\n           date \u003d dates.get(child);\n         }\n         HdfsFileStatus dirStatus \u003d getMountPointStatus(child, 0, date);\n \n         // This may overwrite existing listing entries with the mount point\n         // TODO don\u0027t add if already there?\n         nnListing.put(child, dirStatus);\n       }\n     }\n \n     if (!namenodeListingExists \u0026\u0026 nnListing.size() \u003d\u003d 0) {\n       // NN returns a null object if the directory cannot be found and has no\n       // listing. If we didn\u0027t retrieve any NN listing data, and there are no\n       // mount points here, return null.\n       return null;\n     }\n \n     // Generate combined listing\n     HdfsFileStatus[] combinedData \u003d new HdfsFileStatus[nnListing.size()];\n     combinedData \u003d nnListing.values().toArray(combinedData);\n     return new DirectoryListing(combinedData, remainingEntries);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public DirectoryListing getListing(String src, byte[] startAfter,\n      boolean needLocation) throws IOException {\n    rpcServer.checkOperation(NameNode.OperationCategory.READ);\n\n    // Locate the dir and fetch the listing\n    final List\u003cRemoteLocation\u003e locations \u003d\n        rpcServer.getLocationsForPath(src, true, false);\n    RemoteMethod method \u003d new RemoteMethod(\"getListing\",\n        new Class\u003c?\u003e[] {String.class, startAfter.getClass(), boolean.class},\n        new RemoteParam(), startAfter, needLocation);\n    final List\u003cRemoteResult\u003cRemoteLocation, DirectoryListing\u003e\u003e listings \u003d\n        rpcClient.invokeConcurrent(\n            locations, method, false, -1, DirectoryListing.class);\n\n    Map\u003cString, HdfsFileStatus\u003e nnListing \u003d new TreeMap\u003c\u003e();\n    int totalRemainingEntries \u003d 0;\n    int remainingEntries \u003d 0;\n    boolean namenodeListingExists \u003d false;\n    if (listings !\u003d null) {\n      // Check the subcluster listing with the smallest name\n      String lastName \u003d null;\n      for (RemoteResult\u003cRemoteLocation, DirectoryListing\u003e result : listings) {\n        if (result.hasException()) {\n          IOException ioe \u003d result.getException();\n          if (ioe instanceof FileNotFoundException) {\n            RemoteLocation location \u003d result.getLocation();\n            LOG.debug(\"Cannot get listing from {}\", location);\n          } else if (!allowPartialList) {\n            throw ioe;\n          }\n        } else if (result.getResult() !\u003d null) {\n          DirectoryListing listing \u003d result.getResult();\n          totalRemainingEntries +\u003d listing.getRemainingEntries();\n          HdfsFileStatus[] partialListing \u003d listing.getPartialListing();\n          int length \u003d partialListing.length;\n          if (length \u003e 0) {\n            HdfsFileStatus lastLocalEntry \u003d partialListing[length-1];\n            String lastLocalName \u003d lastLocalEntry.getLocalName();\n            if (lastName \u003d\u003d null || lastName.compareTo(lastLocalName) \u003e 0) {\n              lastName \u003d lastLocalName;\n            }\n          }\n        }\n      }\n\n      // Add existing entries\n      for (RemoteResult\u003cRemoteLocation, DirectoryListing\u003e result : listings) {\n        DirectoryListing listing \u003d result.getResult();\n        if (listing !\u003d null) {\n          namenodeListingExists \u003d true;\n          for (HdfsFileStatus file : listing.getPartialListing()) {\n            String filename \u003d file.getLocalName();\n            if (totalRemainingEntries \u003e 0 \u0026\u0026\n                filename.compareTo(lastName) \u003e 0) {\n              // Discarding entries further than the lastName\n              remainingEntries++;\n            } else {\n              nnListing.put(filename, file);\n            }\n          }\n          remainingEntries +\u003d listing.getRemainingEntries();\n        }\n      }\n    }\n\n    // Add mount points at this level in the tree\n    final List\u003cString\u003e children \u003d subclusterResolver.getMountPoints(src);\n    if (children !\u003d null) {\n      // Get the dates for each mount point\n      Map\u003cString, Long\u003e dates \u003d getMountPointDates(src);\n\n      // Create virtual folder with the mount name\n      for (String child : children) {\n        long date \u003d 0;\n        if (dates !\u003d null \u0026\u0026 dates.containsKey(child)) {\n          date \u003d dates.get(child);\n        }\n        HdfsFileStatus dirStatus \u003d getMountPointStatus(child, 0, date);\n\n        // This may overwrite existing listing entries with the mount point\n        // TODO don\u0027t add if already there?\n        nnListing.put(child, dirStatus);\n      }\n    }\n\n    if (!namenodeListingExists \u0026\u0026 nnListing.size() \u003d\u003d 0) {\n      // NN returns a null object if the directory cannot be found and has no\n      // listing. If we didn\u0027t retrieve any NN listing data, and there are no\n      // mount points here, return null.\n      return null;\n    }\n\n    // Generate combined listing\n    HdfsFileStatus[] combinedData \u003d new HdfsFileStatus[nnListing.size()];\n    combinedData \u003d nnListing.values().toArray(combinedData);\n    return new DirectoryListing(combinedData, remainingEntries);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterClientProtocol.java",
      "extendedDetails": {}
    },
    "203664e6b258b642239651fa6a17fd2561b903d2": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14454. RBF: getContentSummary() should allow non-existing folders. Contributed by Inigo Goiri.\n",
      "commitDate": "24/06/19 9:33 AM",
      "commitName": "203664e6b258b642239651fa6a17fd2561b903d2",
      "commitAuthor": "Ayush Saxena",
      "commitDateOld": "24/06/19 9:33 AM",
      "commitNameOld": "6c42d4050461ab71c88f123569649793dc53aebd",
      "commitAuthorOld": "Ayush Saxena",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 6,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,92 +1,97 @@\n   public DirectoryListing getListing(String src, byte[] startAfter,\n       boolean needLocation) throws IOException {\n     rpcServer.checkOperation(NameNode.OperationCategory.READ);\n \n     // Locate the dir and fetch the listing\n     final List\u003cRemoteLocation\u003e locations \u003d\n         rpcServer.getLocationsForPath(src, true);\n     RemoteMethod method \u003d new RemoteMethod(\"getListing\",\n         new Class\u003c?\u003e[] {String.class, startAfter.getClass(), boolean.class},\n         new RemoteParam(), startAfter, needLocation);\n-    Map\u003cRemoteLocation, DirectoryListing\u003e listings \u003d\n-        rpcClient.invokeConcurrent(locations, method,\n-            !this.allowPartialList, false, DirectoryListing.class);\n+    final List\u003cRemoteResult\u003cRemoteLocation, DirectoryListing\u003e\u003e listings \u003d\n+        rpcClient.invokeConcurrent(\n+            locations, method, false, -1, DirectoryListing.class);\n \n     Map\u003cString, HdfsFileStatus\u003e nnListing \u003d new TreeMap\u003c\u003e();\n     int totalRemainingEntries \u003d 0;\n     int remainingEntries \u003d 0;\n     boolean namenodeListingExists \u003d false;\n     if (listings !\u003d null) {\n       // Check the subcluster listing with the smallest name\n       String lastName \u003d null;\n-      for (Map.Entry\u003cRemoteLocation, DirectoryListing\u003e entry :\n-          listings.entrySet()) {\n-        RemoteLocation location \u003d entry.getKey();\n-        DirectoryListing listing \u003d entry.getValue();\n-        if (listing \u003d\u003d null) {\n-          LOG.debug(\"Cannot get listing from {}\", location);\n-        } else {\n+      for (RemoteResult\u003cRemoteLocation, DirectoryListing\u003e result : listings) {\n+        if (result.hasException()) {\n+          IOException ioe \u003d result.getException();\n+          if (ioe instanceof FileNotFoundException) {\n+            RemoteLocation location \u003d result.getLocation();\n+            LOG.debug(\"Cannot get listing from {}\", location);\n+          } else if (!allowPartialList) {\n+            throw ioe;\n+          }\n+        } else if (result.getResult() !\u003d null) {\n+          DirectoryListing listing \u003d result.getResult();\n           totalRemainingEntries +\u003d listing.getRemainingEntries();\n           HdfsFileStatus[] partialListing \u003d listing.getPartialListing();\n           int length \u003d partialListing.length;\n           if (length \u003e 0) {\n             HdfsFileStatus lastLocalEntry \u003d partialListing[length-1];\n             String lastLocalName \u003d lastLocalEntry.getLocalName();\n             if (lastName \u003d\u003d null || lastName.compareTo(lastLocalName) \u003e 0) {\n               lastName \u003d lastLocalName;\n             }\n           }\n         }\n       }\n \n       // Add existing entries\n-      for (Object value : listings.values()) {\n-        DirectoryListing listing \u003d (DirectoryListing) value;\n+      for (RemoteResult\u003cRemoteLocation, DirectoryListing\u003e result : listings) {\n+        DirectoryListing listing \u003d result.getResult();\n         if (listing !\u003d null) {\n           namenodeListingExists \u003d true;\n           for (HdfsFileStatus file : listing.getPartialListing()) {\n             String filename \u003d file.getLocalName();\n-            if (totalRemainingEntries \u003e 0 \u0026\u0026 filename.compareTo(lastName) \u003e 0) {\n+            if (totalRemainingEntries \u003e 0 \u0026\u0026\n+                filename.compareTo(lastName) \u003e 0) {\n               // Discarding entries further than the lastName\n               remainingEntries++;\n             } else {\n               nnListing.put(filename, file);\n             }\n           }\n           remainingEntries +\u003d listing.getRemainingEntries();\n         }\n       }\n     }\n \n     // Add mount points at this level in the tree\n     final List\u003cString\u003e children \u003d subclusterResolver.getMountPoints(src);\n     if (children !\u003d null) {\n       // Get the dates for each mount point\n       Map\u003cString, Long\u003e dates \u003d getMountPointDates(src);\n \n       // Create virtual folder with the mount name\n       for (String child : children) {\n         long date \u003d 0;\n         if (dates !\u003d null \u0026\u0026 dates.containsKey(child)) {\n           date \u003d dates.get(child);\n         }\n         HdfsFileStatus dirStatus \u003d getMountPointStatus(child, 0, date);\n \n         // This may overwrite existing listing entries with the mount point\n         // TODO don\u0027t add if already there?\n         nnListing.put(child, dirStatus);\n       }\n     }\n \n     if (!namenodeListingExists \u0026\u0026 nnListing.size() \u003d\u003d 0) {\n       // NN returns a null object if the directory cannot be found and has no\n       // listing. If we didn\u0027t retrieve any NN listing data, and there are no\n       // mount points here, return null.\n       return null;\n     }\n \n     // Generate combined listing\n     HdfsFileStatus[] combinedData \u003d new HdfsFileStatus[nnListing.size()];\n     combinedData \u003d nnListing.values().toArray(combinedData);\n     return new DirectoryListing(combinedData, remainingEntries);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public DirectoryListing getListing(String src, byte[] startAfter,\n      boolean needLocation) throws IOException {\n    rpcServer.checkOperation(NameNode.OperationCategory.READ);\n\n    // Locate the dir and fetch the listing\n    final List\u003cRemoteLocation\u003e locations \u003d\n        rpcServer.getLocationsForPath(src, true);\n    RemoteMethod method \u003d new RemoteMethod(\"getListing\",\n        new Class\u003c?\u003e[] {String.class, startAfter.getClass(), boolean.class},\n        new RemoteParam(), startAfter, needLocation);\n    final List\u003cRemoteResult\u003cRemoteLocation, DirectoryListing\u003e\u003e listings \u003d\n        rpcClient.invokeConcurrent(\n            locations, method, false, -1, DirectoryListing.class);\n\n    Map\u003cString, HdfsFileStatus\u003e nnListing \u003d new TreeMap\u003c\u003e();\n    int totalRemainingEntries \u003d 0;\n    int remainingEntries \u003d 0;\n    boolean namenodeListingExists \u003d false;\n    if (listings !\u003d null) {\n      // Check the subcluster listing with the smallest name\n      String lastName \u003d null;\n      for (RemoteResult\u003cRemoteLocation, DirectoryListing\u003e result : listings) {\n        if (result.hasException()) {\n          IOException ioe \u003d result.getException();\n          if (ioe instanceof FileNotFoundException) {\n            RemoteLocation location \u003d result.getLocation();\n            LOG.debug(\"Cannot get listing from {}\", location);\n          } else if (!allowPartialList) {\n            throw ioe;\n          }\n        } else if (result.getResult() !\u003d null) {\n          DirectoryListing listing \u003d result.getResult();\n          totalRemainingEntries +\u003d listing.getRemainingEntries();\n          HdfsFileStatus[] partialListing \u003d listing.getPartialListing();\n          int length \u003d partialListing.length;\n          if (length \u003e 0) {\n            HdfsFileStatus lastLocalEntry \u003d partialListing[length-1];\n            String lastLocalName \u003d lastLocalEntry.getLocalName();\n            if (lastName \u003d\u003d null || lastName.compareTo(lastLocalName) \u003e 0) {\n              lastName \u003d lastLocalName;\n            }\n          }\n        }\n      }\n\n      // Add existing entries\n      for (RemoteResult\u003cRemoteLocation, DirectoryListing\u003e result : listings) {\n        DirectoryListing listing \u003d result.getResult();\n        if (listing !\u003d null) {\n          namenodeListingExists \u003d true;\n          for (HdfsFileStatus file : listing.getPartialListing()) {\n            String filename \u003d file.getLocalName();\n            if (totalRemainingEntries \u003e 0 \u0026\u0026\n                filename.compareTo(lastName) \u003e 0) {\n              // Discarding entries further than the lastName\n              remainingEntries++;\n            } else {\n              nnListing.put(filename, file);\n            }\n          }\n          remainingEntries +\u003d listing.getRemainingEntries();\n        }\n      }\n    }\n\n    // Add mount points at this level in the tree\n    final List\u003cString\u003e children \u003d subclusterResolver.getMountPoints(src);\n    if (children !\u003d null) {\n      // Get the dates for each mount point\n      Map\u003cString, Long\u003e dates \u003d getMountPointDates(src);\n\n      // Create virtual folder with the mount name\n      for (String child : children) {\n        long date \u003d 0;\n        if (dates !\u003d null \u0026\u0026 dates.containsKey(child)) {\n          date \u003d dates.get(child);\n        }\n        HdfsFileStatus dirStatus \u003d getMountPointStatus(child, 0, date);\n\n        // This may overwrite existing listing entries with the mount point\n        // TODO don\u0027t add if already there?\n        nnListing.put(child, dirStatus);\n      }\n    }\n\n    if (!namenodeListingExists \u0026\u0026 nnListing.size() \u003d\u003d 0) {\n      // NN returns a null object if the directory cannot be found and has no\n      // listing. If we didn\u0027t retrieve any NN listing data, and there are no\n      // mount points here, return null.\n      return null;\n    }\n\n    // Generate combined listing\n    HdfsFileStatus[] combinedData \u003d new HdfsFileStatus[nnListing.size()];\n    combinedData \u003d nnListing.values().toArray(combinedData);\n    return new DirectoryListing(combinedData, remainingEntries);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterClientProtocol.java",
      "extendedDetails": {}
    },
    "b320caecb32e0eb739ad925a4646bef1a85caebd": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14085. RBF: LS command for root shows wrong owner and permission information. Contributed by Ayush Saxena.\n",
      "commitDate": "24/06/19 9:33 AM",
      "commitName": "b320caecb32e0eb739ad925a4646bef1a85caebd",
      "commitAuthor": "Surendra Singh Lilhore",
      "commitDateOld": "24/06/19 9:33 AM",
      "commitNameOld": "f2355c706361594b7b2ef8b65b37060eab1d66df",
      "commitAuthorOld": "Brahma Reddy Battula",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,93 +1,92 @@\n   public DirectoryListing getListing(String src, byte[] startAfter,\n       boolean needLocation) throws IOException {\n     rpcServer.checkOperation(NameNode.OperationCategory.READ);\n \n     // Locate the dir and fetch the listing\n     final List\u003cRemoteLocation\u003e locations \u003d\n         rpcServer.getLocationsForPath(src, true);\n     RemoteMethod method \u003d new RemoteMethod(\"getListing\",\n         new Class\u003c?\u003e[] {String.class, startAfter.getClass(), boolean.class},\n         new RemoteParam(), startAfter, needLocation);\n     Map\u003cRemoteLocation, DirectoryListing\u003e listings \u003d\n         rpcClient.invokeConcurrent(locations, method,\n             !this.allowPartialList, false, DirectoryListing.class);\n \n     Map\u003cString, HdfsFileStatus\u003e nnListing \u003d new TreeMap\u003c\u003e();\n     int totalRemainingEntries \u003d 0;\n     int remainingEntries \u003d 0;\n     boolean namenodeListingExists \u003d false;\n     if (listings !\u003d null) {\n       // Check the subcluster listing with the smallest name\n       String lastName \u003d null;\n       for (Map.Entry\u003cRemoteLocation, DirectoryListing\u003e entry :\n           listings.entrySet()) {\n         RemoteLocation location \u003d entry.getKey();\n         DirectoryListing listing \u003d entry.getValue();\n         if (listing \u003d\u003d null) {\n           LOG.debug(\"Cannot get listing from {}\", location);\n         } else {\n           totalRemainingEntries +\u003d listing.getRemainingEntries();\n           HdfsFileStatus[] partialListing \u003d listing.getPartialListing();\n           int length \u003d partialListing.length;\n           if (length \u003e 0) {\n             HdfsFileStatus lastLocalEntry \u003d partialListing[length-1];\n             String lastLocalName \u003d lastLocalEntry.getLocalName();\n             if (lastName \u003d\u003d null || lastName.compareTo(lastLocalName) \u003e 0) {\n               lastName \u003d lastLocalName;\n             }\n           }\n         }\n       }\n \n       // Add existing entries\n       for (Object value : listings.values()) {\n         DirectoryListing listing \u003d (DirectoryListing) value;\n         if (listing !\u003d null) {\n           namenodeListingExists \u003d true;\n           for (HdfsFileStatus file : listing.getPartialListing()) {\n             String filename \u003d file.getLocalName();\n             if (totalRemainingEntries \u003e 0 \u0026\u0026 filename.compareTo(lastName) \u003e 0) {\n               // Discarding entries further than the lastName\n               remainingEntries++;\n             } else {\n               nnListing.put(filename, file);\n             }\n           }\n           remainingEntries +\u003d listing.getRemainingEntries();\n         }\n       }\n     }\n \n     // Add mount points at this level in the tree\n     final List\u003cString\u003e children \u003d subclusterResolver.getMountPoints(src);\n     if (children !\u003d null) {\n       // Get the dates for each mount point\n       Map\u003cString, Long\u003e dates \u003d getMountPointDates(src);\n \n       // Create virtual folder with the mount name\n       for (String child : children) {\n         long date \u003d 0;\n         if (dates !\u003d null \u0026\u0026 dates.containsKey(child)) {\n           date \u003d dates.get(child);\n         }\n-        // TODO add number of children\n         HdfsFileStatus dirStatus \u003d getMountPointStatus(child, 0, date);\n \n         // This may overwrite existing listing entries with the mount point\n         // TODO don\u0027t add if already there?\n         nnListing.put(child, dirStatus);\n       }\n     }\n \n     if (!namenodeListingExists \u0026\u0026 nnListing.size() \u003d\u003d 0) {\n       // NN returns a null object if the directory cannot be found and has no\n       // listing. If we didn\u0027t retrieve any NN listing data, and there are no\n       // mount points here, return null.\n       return null;\n     }\n \n     // Generate combined listing\n     HdfsFileStatus[] combinedData \u003d new HdfsFileStatus[nnListing.size()];\n     combinedData \u003d nnListing.values().toArray(combinedData);\n     return new DirectoryListing(combinedData, remainingEntries);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public DirectoryListing getListing(String src, byte[] startAfter,\n      boolean needLocation) throws IOException {\n    rpcServer.checkOperation(NameNode.OperationCategory.READ);\n\n    // Locate the dir and fetch the listing\n    final List\u003cRemoteLocation\u003e locations \u003d\n        rpcServer.getLocationsForPath(src, true);\n    RemoteMethod method \u003d new RemoteMethod(\"getListing\",\n        new Class\u003c?\u003e[] {String.class, startAfter.getClass(), boolean.class},\n        new RemoteParam(), startAfter, needLocation);\n    Map\u003cRemoteLocation, DirectoryListing\u003e listings \u003d\n        rpcClient.invokeConcurrent(locations, method,\n            !this.allowPartialList, false, DirectoryListing.class);\n\n    Map\u003cString, HdfsFileStatus\u003e nnListing \u003d new TreeMap\u003c\u003e();\n    int totalRemainingEntries \u003d 0;\n    int remainingEntries \u003d 0;\n    boolean namenodeListingExists \u003d false;\n    if (listings !\u003d null) {\n      // Check the subcluster listing with the smallest name\n      String lastName \u003d null;\n      for (Map.Entry\u003cRemoteLocation, DirectoryListing\u003e entry :\n          listings.entrySet()) {\n        RemoteLocation location \u003d entry.getKey();\n        DirectoryListing listing \u003d entry.getValue();\n        if (listing \u003d\u003d null) {\n          LOG.debug(\"Cannot get listing from {}\", location);\n        } else {\n          totalRemainingEntries +\u003d listing.getRemainingEntries();\n          HdfsFileStatus[] partialListing \u003d listing.getPartialListing();\n          int length \u003d partialListing.length;\n          if (length \u003e 0) {\n            HdfsFileStatus lastLocalEntry \u003d partialListing[length-1];\n            String lastLocalName \u003d lastLocalEntry.getLocalName();\n            if (lastName \u003d\u003d null || lastName.compareTo(lastLocalName) \u003e 0) {\n              lastName \u003d lastLocalName;\n            }\n          }\n        }\n      }\n\n      // Add existing entries\n      for (Object value : listings.values()) {\n        DirectoryListing listing \u003d (DirectoryListing) value;\n        if (listing !\u003d null) {\n          namenodeListingExists \u003d true;\n          for (HdfsFileStatus file : listing.getPartialListing()) {\n            String filename \u003d file.getLocalName();\n            if (totalRemainingEntries \u003e 0 \u0026\u0026 filename.compareTo(lastName) \u003e 0) {\n              // Discarding entries further than the lastName\n              remainingEntries++;\n            } else {\n              nnListing.put(filename, file);\n            }\n          }\n          remainingEntries +\u003d listing.getRemainingEntries();\n        }\n      }\n    }\n\n    // Add mount points at this level in the tree\n    final List\u003cString\u003e children \u003d subclusterResolver.getMountPoints(src);\n    if (children !\u003d null) {\n      // Get the dates for each mount point\n      Map\u003cString, Long\u003e dates \u003d getMountPointDates(src);\n\n      // Create virtual folder with the mount name\n      for (String child : children) {\n        long date \u003d 0;\n        if (dates !\u003d null \u0026\u0026 dates.containsKey(child)) {\n          date \u003d dates.get(child);\n        }\n        HdfsFileStatus dirStatus \u003d getMountPointStatus(child, 0, date);\n\n        // This may overwrite existing listing entries with the mount point\n        // TODO don\u0027t add if already there?\n        nnListing.put(child, dirStatus);\n      }\n    }\n\n    if (!namenodeListingExists \u0026\u0026 nnListing.size() \u003d\u003d 0) {\n      // NN returns a null object if the directory cannot be found and has no\n      // listing. If we didn\u0027t retrieve any NN listing data, and there are no\n      // mount points here, return null.\n      return null;\n    }\n\n    // Generate combined listing\n    HdfsFileStatus[] combinedData \u003d new HdfsFileStatus[nnListing.size()];\n    combinedData \u003d nnListing.values().toArray(combinedData);\n    return new DirectoryListing(combinedData, remainingEntries);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterClientProtocol.java",
      "extendedDetails": {}
    },
    "f4bd1114ff529e971f9b496ad62a7edca37fdf8d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14082. RBF: Add option to fail operations when a subcluster is unavailable. Contributed by Inigo Goiri.\n",
      "commitDate": "24/06/19 9:33 AM",
      "commitName": "f4bd1114ff529e971f9b496ad62a7edca37fdf8d",
      "commitAuthor": "Yiqun Lin",
      "commitDateOld": "24/06/19 9:33 AM",
      "commitNameOld": "b3fee1d2bfe5d289b8f279071589f21ace99e04c",
      "commitAuthorOld": "Yiqun Lin",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 7,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,93 +1,93 @@\n   public DirectoryListing getListing(String src, byte[] startAfter,\n       boolean needLocation) throws IOException {\n     rpcServer.checkOperation(NameNode.OperationCategory.READ);\n \n     // Locate the dir and fetch the listing\n     final List\u003cRemoteLocation\u003e locations \u003d\n         rpcServer.getLocationsForPath(src, true);\n     RemoteMethod method \u003d new RemoteMethod(\"getListing\",\n         new Class\u003c?\u003e[] {String.class, startAfter.getClass(), boolean.class},\n         new RemoteParam(), startAfter, needLocation);\n     Map\u003cRemoteLocation, DirectoryListing\u003e listings \u003d\n-        rpcClient.invokeConcurrent(\n-            locations, method, false, false, DirectoryListing.class);\n+        rpcClient.invokeConcurrent(locations, method,\n+            !this.allowPartialList, false, DirectoryListing.class);\n \n     Map\u003cString, HdfsFileStatus\u003e nnListing \u003d new TreeMap\u003c\u003e();\n     int totalRemainingEntries \u003d 0;\n     int remainingEntries \u003d 0;\n     boolean namenodeListingExists \u003d false;\n     if (listings !\u003d null) {\n       // Check the subcluster listing with the smallest name\n       String lastName \u003d null;\n       for (Map.Entry\u003cRemoteLocation, DirectoryListing\u003e entry :\n           listings.entrySet()) {\n         RemoteLocation location \u003d entry.getKey();\n         DirectoryListing listing \u003d entry.getValue();\n         if (listing \u003d\u003d null) {\n           LOG.debug(\"Cannot get listing from {}\", location);\n         } else {\n           totalRemainingEntries +\u003d listing.getRemainingEntries();\n           HdfsFileStatus[] partialListing \u003d listing.getPartialListing();\n           int length \u003d partialListing.length;\n           if (length \u003e 0) {\n             HdfsFileStatus lastLocalEntry \u003d partialListing[length-1];\n             String lastLocalName \u003d lastLocalEntry.getLocalName();\n             if (lastName \u003d\u003d null || lastName.compareTo(lastLocalName) \u003e 0) {\n               lastName \u003d lastLocalName;\n             }\n           }\n         }\n       }\n \n       // Add existing entries\n       for (Object value : listings.values()) {\n         DirectoryListing listing \u003d (DirectoryListing) value;\n         if (listing !\u003d null) {\n           namenodeListingExists \u003d true;\n           for (HdfsFileStatus file : listing.getPartialListing()) {\n             String filename \u003d file.getLocalName();\n             if (totalRemainingEntries \u003e 0 \u0026\u0026 filename.compareTo(lastName) \u003e 0) {\n               // Discarding entries further than the lastName\n               remainingEntries++;\n             } else {\n               nnListing.put(filename, file);\n             }\n           }\n           remainingEntries +\u003d listing.getRemainingEntries();\n         }\n       }\n     }\n \n     // Add mount points at this level in the tree\n     final List\u003cString\u003e children \u003d subclusterResolver.getMountPoints(src);\n     if (children !\u003d null) {\n       // Get the dates for each mount point\n       Map\u003cString, Long\u003e dates \u003d getMountPointDates(src);\n \n       // Create virtual folder with the mount name\n       for (String child : children) {\n         long date \u003d 0;\n         if (dates !\u003d null \u0026\u0026 dates.containsKey(child)) {\n           date \u003d dates.get(child);\n         }\n         // TODO add number of children\n         HdfsFileStatus dirStatus \u003d getMountPointStatus(child, 0, date);\n \n         // This may overwrite existing listing entries with the mount point\n         // TODO don\u0027t add if already there?\n         nnListing.put(child, dirStatus);\n       }\n     }\n \n     if (!namenodeListingExists \u0026\u0026 nnListing.size() \u003d\u003d 0) {\n       // NN returns a null object if the directory cannot be found and has no\n       // listing. If we didn\u0027t retrieve any NN listing data, and there are no\n       // mount points here, return null.\n       return null;\n     }\n \n     // Generate combined listing\n     HdfsFileStatus[] combinedData \u003d new HdfsFileStatus[nnListing.size()];\n     combinedData \u003d nnListing.values().toArray(combinedData);\n     return new DirectoryListing(combinedData, remainingEntries);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public DirectoryListing getListing(String src, byte[] startAfter,\n      boolean needLocation) throws IOException {\n    rpcServer.checkOperation(NameNode.OperationCategory.READ);\n\n    // Locate the dir and fetch the listing\n    final List\u003cRemoteLocation\u003e locations \u003d\n        rpcServer.getLocationsForPath(src, true);\n    RemoteMethod method \u003d new RemoteMethod(\"getListing\",\n        new Class\u003c?\u003e[] {String.class, startAfter.getClass(), boolean.class},\n        new RemoteParam(), startAfter, needLocation);\n    Map\u003cRemoteLocation, DirectoryListing\u003e listings \u003d\n        rpcClient.invokeConcurrent(locations, method,\n            !this.allowPartialList, false, DirectoryListing.class);\n\n    Map\u003cString, HdfsFileStatus\u003e nnListing \u003d new TreeMap\u003c\u003e();\n    int totalRemainingEntries \u003d 0;\n    int remainingEntries \u003d 0;\n    boolean namenodeListingExists \u003d false;\n    if (listings !\u003d null) {\n      // Check the subcluster listing with the smallest name\n      String lastName \u003d null;\n      for (Map.Entry\u003cRemoteLocation, DirectoryListing\u003e entry :\n          listings.entrySet()) {\n        RemoteLocation location \u003d entry.getKey();\n        DirectoryListing listing \u003d entry.getValue();\n        if (listing \u003d\u003d null) {\n          LOG.debug(\"Cannot get listing from {}\", location);\n        } else {\n          totalRemainingEntries +\u003d listing.getRemainingEntries();\n          HdfsFileStatus[] partialListing \u003d listing.getPartialListing();\n          int length \u003d partialListing.length;\n          if (length \u003e 0) {\n            HdfsFileStatus lastLocalEntry \u003d partialListing[length-1];\n            String lastLocalName \u003d lastLocalEntry.getLocalName();\n            if (lastName \u003d\u003d null || lastName.compareTo(lastLocalName) \u003e 0) {\n              lastName \u003d lastLocalName;\n            }\n          }\n        }\n      }\n\n      // Add existing entries\n      for (Object value : listings.values()) {\n        DirectoryListing listing \u003d (DirectoryListing) value;\n        if (listing !\u003d null) {\n          namenodeListingExists \u003d true;\n          for (HdfsFileStatus file : listing.getPartialListing()) {\n            String filename \u003d file.getLocalName();\n            if (totalRemainingEntries \u003e 0 \u0026\u0026 filename.compareTo(lastName) \u003e 0) {\n              // Discarding entries further than the lastName\n              remainingEntries++;\n            } else {\n              nnListing.put(filename, file);\n            }\n          }\n          remainingEntries +\u003d listing.getRemainingEntries();\n        }\n      }\n    }\n\n    // Add mount points at this level in the tree\n    final List\u003cString\u003e children \u003d subclusterResolver.getMountPoints(src);\n    if (children !\u003d null) {\n      // Get the dates for each mount point\n      Map\u003cString, Long\u003e dates \u003d getMountPointDates(src);\n\n      // Create virtual folder with the mount name\n      for (String child : children) {\n        long date \u003d 0;\n        if (dates !\u003d null \u0026\u0026 dates.containsKey(child)) {\n          date \u003d dates.get(child);\n        }\n        // TODO add number of children\n        HdfsFileStatus dirStatus \u003d getMountPointStatus(child, 0, date);\n\n        // This may overwrite existing listing entries with the mount point\n        // TODO don\u0027t add if already there?\n        nnListing.put(child, dirStatus);\n      }\n    }\n\n    if (!namenodeListingExists \u0026\u0026 nnListing.size() \u003d\u003d 0) {\n      // NN returns a null object if the directory cannot be found and has no\n      // listing. If we didn\u0027t retrieve any NN listing data, and there are no\n      // mount points here, return null.\n      return null;\n    }\n\n    // Generate combined listing\n    HdfsFileStatus[] combinedData \u003d new HdfsFileStatus[nnListing.size()];\n    combinedData \u003d nnListing.values().toArray(combinedData);\n    return new DirectoryListing(combinedData, remainingEntries);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterClientProtocol.java",
      "extendedDetails": {}
    },
    "6425ed27ea638da75f656204d6df4adad1d91fe1": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-13790. RBF: Move ClientProtocol APIs to its own module. Contributed by Chao Sun.\n",
      "commitDate": "19/08/18 11:50 PM",
      "commitName": "6425ed27ea638da75f656204d6df4adad1d91fe1",
      "commitAuthor": "Brahma Reddy Battula",
      "diff": "@@ -0,0 +1,93 @@\n+  public DirectoryListing getListing(String src, byte[] startAfter,\n+      boolean needLocation) throws IOException {\n+    rpcServer.checkOperation(NameNode.OperationCategory.READ);\n+\n+    // Locate the dir and fetch the listing\n+    final List\u003cRemoteLocation\u003e locations \u003d\n+        rpcServer.getLocationsForPath(src, true);\n+    RemoteMethod method \u003d new RemoteMethod(\"getListing\",\n+        new Class\u003c?\u003e[] {String.class, startAfter.getClass(), boolean.class},\n+        new RemoteParam(), startAfter, needLocation);\n+    Map\u003cRemoteLocation, DirectoryListing\u003e listings \u003d\n+        rpcClient.invokeConcurrent(\n+            locations, method, false, false, DirectoryListing.class);\n+\n+    Map\u003cString, HdfsFileStatus\u003e nnListing \u003d new TreeMap\u003c\u003e();\n+    int totalRemainingEntries \u003d 0;\n+    int remainingEntries \u003d 0;\n+    boolean namenodeListingExists \u003d false;\n+    if (listings !\u003d null) {\n+      // Check the subcluster listing with the smallest name\n+      String lastName \u003d null;\n+      for (Map.Entry\u003cRemoteLocation, DirectoryListing\u003e entry :\n+          listings.entrySet()) {\n+        RemoteLocation location \u003d entry.getKey();\n+        DirectoryListing listing \u003d entry.getValue();\n+        if (listing \u003d\u003d null) {\n+          LOG.debug(\"Cannot get listing from {}\", location);\n+        } else {\n+          totalRemainingEntries +\u003d listing.getRemainingEntries();\n+          HdfsFileStatus[] partialListing \u003d listing.getPartialListing();\n+          int length \u003d partialListing.length;\n+          if (length \u003e 0) {\n+            HdfsFileStatus lastLocalEntry \u003d partialListing[length-1];\n+            String lastLocalName \u003d lastLocalEntry.getLocalName();\n+            if (lastName \u003d\u003d null || lastName.compareTo(lastLocalName) \u003e 0) {\n+              lastName \u003d lastLocalName;\n+            }\n+          }\n+        }\n+      }\n+\n+      // Add existing entries\n+      for (Object value : listings.values()) {\n+        DirectoryListing listing \u003d (DirectoryListing) value;\n+        if (listing !\u003d null) {\n+          namenodeListingExists \u003d true;\n+          for (HdfsFileStatus file : listing.getPartialListing()) {\n+            String filename \u003d file.getLocalName();\n+            if (totalRemainingEntries \u003e 0 \u0026\u0026 filename.compareTo(lastName) \u003e 0) {\n+              // Discarding entries further than the lastName\n+              remainingEntries++;\n+            } else {\n+              nnListing.put(filename, file);\n+            }\n+          }\n+          remainingEntries +\u003d listing.getRemainingEntries();\n+        }\n+      }\n+    }\n+\n+    // Add mount points at this level in the tree\n+    final List\u003cString\u003e children \u003d subclusterResolver.getMountPoints(src);\n+    if (children !\u003d null) {\n+      // Get the dates for each mount point\n+      Map\u003cString, Long\u003e dates \u003d getMountPointDates(src);\n+\n+      // Create virtual folder with the mount name\n+      for (String child : children) {\n+        long date \u003d 0;\n+        if (dates !\u003d null \u0026\u0026 dates.containsKey(child)) {\n+          date \u003d dates.get(child);\n+        }\n+        // TODO add number of children\n+        HdfsFileStatus dirStatus \u003d getMountPointStatus(child, 0, date);\n+\n+        // This may overwrite existing listing entries with the mount point\n+        // TODO don\u0027t add if already there?\n+        nnListing.put(child, dirStatus);\n+      }\n+    }\n+\n+    if (!namenodeListingExists \u0026\u0026 nnListing.size() \u003d\u003d 0) {\n+      // NN returns a null object if the directory cannot be found and has no\n+      // listing. If we didn\u0027t retrieve any NN listing data, and there are no\n+      // mount points here, return null.\n+      return null;\n+    }\n+\n+    // Generate combined listing\n+    HdfsFileStatus[] combinedData \u003d new HdfsFileStatus[nnListing.size()];\n+    combinedData \u003d nnListing.values().toArray(combinedData);\n+    return new DirectoryListing(combinedData, remainingEntries);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public DirectoryListing getListing(String src, byte[] startAfter,\n      boolean needLocation) throws IOException {\n    rpcServer.checkOperation(NameNode.OperationCategory.READ);\n\n    // Locate the dir and fetch the listing\n    final List\u003cRemoteLocation\u003e locations \u003d\n        rpcServer.getLocationsForPath(src, true);\n    RemoteMethod method \u003d new RemoteMethod(\"getListing\",\n        new Class\u003c?\u003e[] {String.class, startAfter.getClass(), boolean.class},\n        new RemoteParam(), startAfter, needLocation);\n    Map\u003cRemoteLocation, DirectoryListing\u003e listings \u003d\n        rpcClient.invokeConcurrent(\n            locations, method, false, false, DirectoryListing.class);\n\n    Map\u003cString, HdfsFileStatus\u003e nnListing \u003d new TreeMap\u003c\u003e();\n    int totalRemainingEntries \u003d 0;\n    int remainingEntries \u003d 0;\n    boolean namenodeListingExists \u003d false;\n    if (listings !\u003d null) {\n      // Check the subcluster listing with the smallest name\n      String lastName \u003d null;\n      for (Map.Entry\u003cRemoteLocation, DirectoryListing\u003e entry :\n          listings.entrySet()) {\n        RemoteLocation location \u003d entry.getKey();\n        DirectoryListing listing \u003d entry.getValue();\n        if (listing \u003d\u003d null) {\n          LOG.debug(\"Cannot get listing from {}\", location);\n        } else {\n          totalRemainingEntries +\u003d listing.getRemainingEntries();\n          HdfsFileStatus[] partialListing \u003d listing.getPartialListing();\n          int length \u003d partialListing.length;\n          if (length \u003e 0) {\n            HdfsFileStatus lastLocalEntry \u003d partialListing[length-1];\n            String lastLocalName \u003d lastLocalEntry.getLocalName();\n            if (lastName \u003d\u003d null || lastName.compareTo(lastLocalName) \u003e 0) {\n              lastName \u003d lastLocalName;\n            }\n          }\n        }\n      }\n\n      // Add existing entries\n      for (Object value : listings.values()) {\n        DirectoryListing listing \u003d (DirectoryListing) value;\n        if (listing !\u003d null) {\n          namenodeListingExists \u003d true;\n          for (HdfsFileStatus file : listing.getPartialListing()) {\n            String filename \u003d file.getLocalName();\n            if (totalRemainingEntries \u003e 0 \u0026\u0026 filename.compareTo(lastName) \u003e 0) {\n              // Discarding entries further than the lastName\n              remainingEntries++;\n            } else {\n              nnListing.put(filename, file);\n            }\n          }\n          remainingEntries +\u003d listing.getRemainingEntries();\n        }\n      }\n    }\n\n    // Add mount points at this level in the tree\n    final List\u003cString\u003e children \u003d subclusterResolver.getMountPoints(src);\n    if (children !\u003d null) {\n      // Get the dates for each mount point\n      Map\u003cString, Long\u003e dates \u003d getMountPointDates(src);\n\n      // Create virtual folder with the mount name\n      for (String child : children) {\n        long date \u003d 0;\n        if (dates !\u003d null \u0026\u0026 dates.containsKey(child)) {\n          date \u003d dates.get(child);\n        }\n        // TODO add number of children\n        HdfsFileStatus dirStatus \u003d getMountPointStatus(child, 0, date);\n\n        // This may overwrite existing listing entries with the mount point\n        // TODO don\u0027t add if already there?\n        nnListing.put(child, dirStatus);\n      }\n    }\n\n    if (!namenodeListingExists \u0026\u0026 nnListing.size() \u003d\u003d 0) {\n      // NN returns a null object if the directory cannot be found and has no\n      // listing. If we didn\u0027t retrieve any NN listing data, and there are no\n      // mount points here, return null.\n      return null;\n    }\n\n    // Generate combined listing\n    HdfsFileStatus[] combinedData \u003d new HdfsFileStatus[nnListing.size()];\n    combinedData \u003d nnListing.values().toArray(combinedData);\n    return new DirectoryListing(combinedData, remainingEntries);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterClientProtocol.java"
    }
  }
}