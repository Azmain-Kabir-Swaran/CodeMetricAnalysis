{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DynamoDBMetadataStore.java",
  "functionName": "initialize",
  "functionId": "initialize___fs-FileSystem__ttlTp-ITtlTimeProvider",
  "sourceFilePath": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/s3guard/DynamoDBMetadataStore.java",
  "functionStartLine": 398,
  "functionEndLine": 440,
  "numCommitsSeen": 73,
  "timeTaken": 6300,
  "changeHistory": [
    "56dee667707926f3796c7757be1a133a362f05c9",
    "49df83899543586bbcaf80f01399ade031cf68b0",
    "bbcf0b91d6f5eb697d09e45505b0e72e193c3d75",
    "4a700c20d553dc5336ee881719bcf189fc46bfbf",
    "c58e11bf521d746842ce16724211a2a0339d7b61",
    "e02eb24e0a9139418120027b694492e0738df20a",
    "d7c0a08a1c077752918a8cf1b4f1900ce2721899",
    "da9a39eed138210de29b59b90c449b28da1c04f9",
    "b089a06793d94d42b7da1b7566e366ceb748e081",
    "de8b6ca5ef8614de6d6277b7617e27c788b0555c",
    "621b43e254afaff708cd6fc4698b29628f6abc33"
  ],
  "changeHistoryShort": {
    "56dee667707926f3796c7757be1a133a362f05c9": "Ybodychange",
    "49df83899543586bbcaf80f01399ade031cf68b0": "Ybodychange",
    "bbcf0b91d6f5eb697d09e45505b0e72e193c3d75": "Ybodychange",
    "4a700c20d553dc5336ee881719bcf189fc46bfbf": "Ybodychange",
    "c58e11bf521d746842ce16724211a2a0339d7b61": "Ymultichange(Yparameterchange,Ybodychange)",
    "e02eb24e0a9139418120027b694492e0738df20a": "Ybodychange",
    "d7c0a08a1c077752918a8cf1b4f1900ce2721899": "Ybodychange",
    "da9a39eed138210de29b59b90c449b28da1c04f9": "Ybodychange",
    "b089a06793d94d42b7da1b7566e366ceb748e081": "Ybodychange",
    "de8b6ca5ef8614de6d6277b7617e27c788b0555c": "Ybodychange",
    "621b43e254afaff708cd6fc4698b29628f6abc33": "Yintroduced"
  },
  "changeHistoryDetails": {
    "56dee667707926f3796c7757be1a133a362f05c9": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-16823. Large DeleteObject requests are their own Thundering Herd.\n\nContributed by Steve Loughran.\n\nDuring S3A rename() and delete() calls, the list of objects delete is\nbuilt up into batches of a thousand and then POSTed in a single large\nDeleteObjects request.\n\nBut as the IO capacity allowed on an S3 partition may only be 3500 writes\nper second *and* each entry in that POST counts as a single write, then\none of those posts alone can trigger throttling on an already loaded\nS3 directory tree. Which can trigger backoff and retry, with the same\nthousand entry post, and so recreate the exact same problem.\n\nFixes\n\n* Page size for delete object requests is set in\n  fs.s3a.bulk.delete.page.size; the default is 250.\n* The property fs.s3a.experimental.aws.s3.throttling (default\u003dtrue)\n  can be set to false to disable throttle retry logic in the AWS\n  client SDK -it is all handled in the S3A client. This\n  gives more visibility in to when operations are being throttled\n* Bulk delete throttling events are logged to the log\n  org.apache.hadoop.fs.s3a.throttled log at INFO; if this appears\n  often then choose a smaller page size.\n* The metric \"store_io_throttled\" adds the entire count of delete\n  requests when a single DeleteObjects request is throttled.\n* A new quantile, \"store_io_throttle_rate\" can track throttling\n  load over time.\n* DynamoDB metastore throttle resilience issues have also been\n  identified and fixed. Note: the fs.s3a.experimental.aws.s3.throttling\n  flag does not apply to DDB IO precisely because there may still be\n  lurking issues there and it safest to rely on the DynamoDB client\n  SDK.\n\nChange-Id: I00f85cdd94fc008864d060533f6bd4870263fd84\n",
      "commitDate": "13/02/20 11:09 AM",
      "commitName": "56dee667707926f3796c7757be1a133a362f05c9",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "25/01/20 10:35 AM",
      "commitNameOld": "7f40e6688a5716fca53e1090d8347a43064d6d43",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 19.02,
      "commitsBetweenForRepo": 56,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,48 +1,43 @@\n   public void initialize(FileSystem fs, ITtlTimeProvider ttlTp)\n       throws IOException {\n     Preconditions.checkNotNull(fs, \"Null filesystem\");\n     Preconditions.checkArgument(fs instanceof S3AFileSystem,\n         \"DynamoDBMetadataStore only supports S3A filesystem - not %s\",\n         fs);\n     bindToOwnerFilesystem((S3AFileSystem) fs);\n     final String bucket \u003d owner.getBucket();\n     String confRegion \u003d conf.getTrimmed(S3GUARD_DDB_REGION_KEY);\n     if (!StringUtils.isEmpty(confRegion)) {\n       region \u003d confRegion;\n       LOG.debug(\"Overriding S3 region with configured DynamoDB region: {}\",\n           region);\n     } else {\n       try {\n         region \u003d owner.getBucketLocation();\n       } catch (AccessDeniedException e) {\n         // access denied here \u003d\u003d can\u0027t call getBucket. Report meaningfully\n         URI uri \u003d owner.getUri();\n         String message \u003d\n             \"Failed to get bucket location as client lacks permission \"\n                 + RolePolicies.S3_GET_BUCKET_LOCATION + \" for \" + uri;\n         LOG.error(message);\n         throw (IOException)new AccessDeniedException(message).initCause(e);\n       }\n       LOG.debug(\"Inferring DynamoDB region from S3 bucket: {}\", region);\n     }\n     credentials \u003d owner.shareCredentials(\"s3guard\");\n     dynamoDB \u003d createDynamoDB(conf, region, bucket, credentials);\n \n     // use the bucket as the DynamoDB table name if not specified in config\n     tableName \u003d conf.getTrimmed(S3GUARD_DDB_TABLE_NAME_KEY, bucket);\n     initDataAccessRetries(conf);\n \n-    // set up a full retry policy\n-    invoker \u003d new Invoker(new S3GuardDataAccessRetryPolicy(conf),\n-        this::retryEvent\n-    );\n-\n     this.ttlTimeProvider \u003d ttlTp;\n \n     tableHandler \u003d new DynamoDBMetadataStoreTableManager(\n         dynamoDB, tableName, region, amazonDynamoDB, conf, readOp,\n         batchWriteRetryPolicy);\n     this.table \u003d tableHandler.initTable();\n \n     instrumentation.initialized();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void initialize(FileSystem fs, ITtlTimeProvider ttlTp)\n      throws IOException {\n    Preconditions.checkNotNull(fs, \"Null filesystem\");\n    Preconditions.checkArgument(fs instanceof S3AFileSystem,\n        \"DynamoDBMetadataStore only supports S3A filesystem - not %s\",\n        fs);\n    bindToOwnerFilesystem((S3AFileSystem) fs);\n    final String bucket \u003d owner.getBucket();\n    String confRegion \u003d conf.getTrimmed(S3GUARD_DDB_REGION_KEY);\n    if (!StringUtils.isEmpty(confRegion)) {\n      region \u003d confRegion;\n      LOG.debug(\"Overriding S3 region with configured DynamoDB region: {}\",\n          region);\n    } else {\n      try {\n        region \u003d owner.getBucketLocation();\n      } catch (AccessDeniedException e) {\n        // access denied here \u003d\u003d can\u0027t call getBucket. Report meaningfully\n        URI uri \u003d owner.getUri();\n        String message \u003d\n            \"Failed to get bucket location as client lacks permission \"\n                + RolePolicies.S3_GET_BUCKET_LOCATION + \" for \" + uri;\n        LOG.error(message);\n        throw (IOException)new AccessDeniedException(message).initCause(e);\n      }\n      LOG.debug(\"Inferring DynamoDB region from S3 bucket: {}\", region);\n    }\n    credentials \u003d owner.shareCredentials(\"s3guard\");\n    dynamoDB \u003d createDynamoDB(conf, region, bucket, credentials);\n\n    // use the bucket as the DynamoDB table name if not specified in config\n    tableName \u003d conf.getTrimmed(S3GUARD_DDB_TABLE_NAME_KEY, bucket);\n    initDataAccessRetries(conf);\n\n    this.ttlTimeProvider \u003d ttlTp;\n\n    tableHandler \u003d new DynamoDBMetadataStoreTableManager(\n        dynamoDB, tableName, region, amazonDynamoDB, conf, readOp,\n        batchWriteRetryPolicy);\n    this.table \u003d tableHandler.initTable();\n\n    instrumentation.initialized();\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/s3guard/DynamoDBMetadataStore.java",
      "extendedDetails": {}
    },
    "49df83899543586bbcaf80f01399ade031cf68b0": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-16697. Tune/audit S3A authoritative mode.\n\nContains:\n\nHADOOP-16474. S3Guard ProgressiveRenameTracker to mark destination\n              dirirectory as authoritative on success.\nHADOOP-16684. S3guard bucket info to list a bit more about\n              authoritative paths.\nHADOOP-16722. S3GuardTool to support FilterFileSystem.\n\nThis patch improves the marking of newly created/import directory\ntrees in S3Guard DynamoDB tables as authoritative.\n\nSpecific changes:\n\n * Renamed directories are marked as authoritative if the entire\n   operation succeeded (HADOOP-16474).\n * When updating parent table entries as part of any table write,\n   there\u0027s no overwriting of their authoritative flag.\n\ns3guard import changes:\n\n* new -verbose flag to print out what is going on.\n\n* The \"s3guard import\" command lets you declare that a directory tree\nis to be marked as authoritative\n\n  hadoop s3guard import -authoritative -verbose s3a://bucket/path\n\nWhen importing a listing and a file is found, the import tool queries\nthe metastore and only updates the entry if the file is different from\nbefore, where different \u003d\u003d new timestamp, etag, or length. S3Guard can get\ntimestamp differences due to clock skew in PUT operations.\n\nAs the recursive list performed by the import command doesn\u0027t retrieve the\nversionID, the existing entry may in fact be more complete.\nWhen updating an existing due to clock skew the existing version ID\nis propagated to the new entry (note: the etags must match; this is needed\nto deal with inconsistent listings).\n\nThere is a new s3guard command to audit a s3guard bucket/path\u0027s\nauthoritative state:\n\n  hadoop s3guard authoritative -check-config s3a://bucket/path\n\nThis is primarily for testing/auditing.\n\nThe s3guard bucket-info command also provides some more details on the\nauthoritative state of a store (HADOOP-16684).\n\nChange-Id: I58001341c04f6f3597fcb4fcb1581ccefeb77d91\n",
      "commitDate": "10/01/20 3:11 AM",
      "commitName": "49df83899543586bbcaf80f01399ade031cf68b0",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "26/11/19 7:36 AM",
      "commitNameOld": "ea25f4de236611d388e14a710ebe5d6872c421b6",
      "commitAuthorOld": "Gabor Bota",
      "daysBetweenCommits": 44.82,
      "commitsBetweenForRepo": 155,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,47 +1,48 @@\n   public void initialize(FileSystem fs, ITtlTimeProvider ttlTp)\n       throws IOException {\n     Preconditions.checkNotNull(fs, \"Null filesystem\");\n     Preconditions.checkArgument(fs instanceof S3AFileSystem,\n-        \"DynamoDBMetadataStore only supports S3A filesystem.\");\n+        \"DynamoDBMetadataStore only supports S3A filesystem - not %s\",\n+        fs);\n     bindToOwnerFilesystem((S3AFileSystem) fs);\n     final String bucket \u003d owner.getBucket();\n     String confRegion \u003d conf.getTrimmed(S3GUARD_DDB_REGION_KEY);\n     if (!StringUtils.isEmpty(confRegion)) {\n       region \u003d confRegion;\n       LOG.debug(\"Overriding S3 region with configured DynamoDB region: {}\",\n           region);\n     } else {\n       try {\n         region \u003d owner.getBucketLocation();\n       } catch (AccessDeniedException e) {\n         // access denied here \u003d\u003d can\u0027t call getBucket. Report meaningfully\n         URI uri \u003d owner.getUri();\n         String message \u003d\n             \"Failed to get bucket location as client lacks permission \"\n                 + RolePolicies.S3_GET_BUCKET_LOCATION + \" for \" + uri;\n         LOG.error(message);\n         throw (IOException)new AccessDeniedException(message).initCause(e);\n       }\n       LOG.debug(\"Inferring DynamoDB region from S3 bucket: {}\", region);\n     }\n     credentials \u003d owner.shareCredentials(\"s3guard\");\n     dynamoDB \u003d createDynamoDB(conf, region, bucket, credentials);\n \n     // use the bucket as the DynamoDB table name if not specified in config\n     tableName \u003d conf.getTrimmed(S3GUARD_DDB_TABLE_NAME_KEY, bucket);\n     initDataAccessRetries(conf);\n \n     // set up a full retry policy\n     invoker \u003d new Invoker(new S3GuardDataAccessRetryPolicy(conf),\n         this::retryEvent\n     );\n \n     this.ttlTimeProvider \u003d ttlTp;\n \n     tableHandler \u003d new DynamoDBMetadataStoreTableManager(\n         dynamoDB, tableName, region, amazonDynamoDB, conf, readOp,\n         batchWriteRetryPolicy);\n     this.table \u003d tableHandler.initTable();\n \n     instrumentation.initialized();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void initialize(FileSystem fs, ITtlTimeProvider ttlTp)\n      throws IOException {\n    Preconditions.checkNotNull(fs, \"Null filesystem\");\n    Preconditions.checkArgument(fs instanceof S3AFileSystem,\n        \"DynamoDBMetadataStore only supports S3A filesystem - not %s\",\n        fs);\n    bindToOwnerFilesystem((S3AFileSystem) fs);\n    final String bucket \u003d owner.getBucket();\n    String confRegion \u003d conf.getTrimmed(S3GUARD_DDB_REGION_KEY);\n    if (!StringUtils.isEmpty(confRegion)) {\n      region \u003d confRegion;\n      LOG.debug(\"Overriding S3 region with configured DynamoDB region: {}\",\n          region);\n    } else {\n      try {\n        region \u003d owner.getBucketLocation();\n      } catch (AccessDeniedException e) {\n        // access denied here \u003d\u003d can\u0027t call getBucket. Report meaningfully\n        URI uri \u003d owner.getUri();\n        String message \u003d\n            \"Failed to get bucket location as client lacks permission \"\n                + RolePolicies.S3_GET_BUCKET_LOCATION + \" for \" + uri;\n        LOG.error(message);\n        throw (IOException)new AccessDeniedException(message).initCause(e);\n      }\n      LOG.debug(\"Inferring DynamoDB region from S3 bucket: {}\", region);\n    }\n    credentials \u003d owner.shareCredentials(\"s3guard\");\n    dynamoDB \u003d createDynamoDB(conf, region, bucket, credentials);\n\n    // use the bucket as the DynamoDB table name if not specified in config\n    tableName \u003d conf.getTrimmed(S3GUARD_DDB_TABLE_NAME_KEY, bucket);\n    initDataAccessRetries(conf);\n\n    // set up a full retry policy\n    invoker \u003d new Invoker(new S3GuardDataAccessRetryPolicy(conf),\n        this::retryEvent\n    );\n\n    this.ttlTimeProvider \u003d ttlTp;\n\n    tableHandler \u003d new DynamoDBMetadataStoreTableManager(\n        dynamoDB, tableName, region, amazonDynamoDB, conf, readOp,\n        batchWriteRetryPolicy);\n    this.table \u003d tableHandler.initTable();\n\n    instrumentation.initialized();\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/s3guard/DynamoDBMetadataStore.java",
      "extendedDetails": {}
    },
    "bbcf0b91d6f5eb697d09e45505b0e72e193c3d75": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-16478. S3Guard bucket-info fails if the caller lacks s3:GetBucketLocation.\n\nContributed by Steve Loughran.\n\nIncludes HADOOP-16651. S3 getBucketLocation() can return \"US\" for us-east.\n\nChange-Id: Ifc0dca76e51495ed1a8fc0f077b86bf125deff40\n",
      "commitDate": "16/10/19 1:41 AM",
      "commitName": "bbcf0b91d6f5eb697d09e45505b0e72e193c3d75",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "11/10/19 3:08 AM",
      "commitNameOld": "4a700c20d553dc5336ee881719bcf189fc46bfbf",
      "commitAuthorOld": "Gabor Bota",
      "daysBetweenCommits": 4.94,
      "commitsBetweenForRepo": 15,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,48 +1,47 @@\n   public void initialize(FileSystem fs, ITtlTimeProvider ttlTp)\n       throws IOException {\n     Preconditions.checkNotNull(fs, \"Null filesystem\");\n     Preconditions.checkArgument(fs instanceof S3AFileSystem,\n         \"DynamoDBMetadataStore only supports S3A filesystem.\");\n     bindToOwnerFilesystem((S3AFileSystem) fs);\n     final String bucket \u003d owner.getBucket();\n     String confRegion \u003d conf.getTrimmed(S3GUARD_DDB_REGION_KEY);\n     if (!StringUtils.isEmpty(confRegion)) {\n       region \u003d confRegion;\n       LOG.debug(\"Overriding S3 region with configured DynamoDB region: {}\",\n           region);\n     } else {\n       try {\n         region \u003d owner.getBucketLocation();\n       } catch (AccessDeniedException e) {\n         // access denied here \u003d\u003d can\u0027t call getBucket. Report meaningfully\n         URI uri \u003d owner.getUri();\n-        LOG.error(\"Failed to get bucket location from S3 bucket {}\",\n-            uri);\n-        throw (IOException)new AccessDeniedException(\n-            \"S3 client role lacks permission \"\n-                + RolePolicies.S3_GET_BUCKET_LOCATION + \" for \" + uri)\n-            .initCause(e);\n+        String message \u003d\n+            \"Failed to get bucket location as client lacks permission \"\n+                + RolePolicies.S3_GET_BUCKET_LOCATION + \" for \" + uri;\n+        LOG.error(message);\n+        throw (IOException)new AccessDeniedException(message).initCause(e);\n       }\n       LOG.debug(\"Inferring DynamoDB region from S3 bucket: {}\", region);\n     }\n     credentials \u003d owner.shareCredentials(\"s3guard\");\n     dynamoDB \u003d createDynamoDB(conf, region, bucket, credentials);\n \n     // use the bucket as the DynamoDB table name if not specified in config\n     tableName \u003d conf.getTrimmed(S3GUARD_DDB_TABLE_NAME_KEY, bucket);\n     initDataAccessRetries(conf);\n \n     // set up a full retry policy\n     invoker \u003d new Invoker(new S3GuardDataAccessRetryPolicy(conf),\n         this::retryEvent\n     );\n \n     this.ttlTimeProvider \u003d ttlTp;\n \n     tableHandler \u003d new DynamoDBMetadataStoreTableManager(\n         dynamoDB, tableName, region, amazonDynamoDB, conf, readOp,\n         batchWriteRetryPolicy);\n     this.table \u003d tableHandler.initTable();\n \n     instrumentation.initialized();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void initialize(FileSystem fs, ITtlTimeProvider ttlTp)\n      throws IOException {\n    Preconditions.checkNotNull(fs, \"Null filesystem\");\n    Preconditions.checkArgument(fs instanceof S3AFileSystem,\n        \"DynamoDBMetadataStore only supports S3A filesystem.\");\n    bindToOwnerFilesystem((S3AFileSystem) fs);\n    final String bucket \u003d owner.getBucket();\n    String confRegion \u003d conf.getTrimmed(S3GUARD_DDB_REGION_KEY);\n    if (!StringUtils.isEmpty(confRegion)) {\n      region \u003d confRegion;\n      LOG.debug(\"Overriding S3 region with configured DynamoDB region: {}\",\n          region);\n    } else {\n      try {\n        region \u003d owner.getBucketLocation();\n      } catch (AccessDeniedException e) {\n        // access denied here \u003d\u003d can\u0027t call getBucket. Report meaningfully\n        URI uri \u003d owner.getUri();\n        String message \u003d\n            \"Failed to get bucket location as client lacks permission \"\n                + RolePolicies.S3_GET_BUCKET_LOCATION + \" for \" + uri;\n        LOG.error(message);\n        throw (IOException)new AccessDeniedException(message).initCause(e);\n      }\n      LOG.debug(\"Inferring DynamoDB region from S3 bucket: {}\", region);\n    }\n    credentials \u003d owner.shareCredentials(\"s3guard\");\n    dynamoDB \u003d createDynamoDB(conf, region, bucket, credentials);\n\n    // use the bucket as the DynamoDB table name if not specified in config\n    tableName \u003d conf.getTrimmed(S3GUARD_DDB_TABLE_NAME_KEY, bucket);\n    initDataAccessRetries(conf);\n\n    // set up a full retry policy\n    invoker \u003d new Invoker(new S3GuardDataAccessRetryPolicy(conf),\n        this::retryEvent\n    );\n\n    this.ttlTimeProvider \u003d ttlTp;\n\n    tableHandler \u003d new DynamoDBMetadataStoreTableManager(\n        dynamoDB, tableName, region, amazonDynamoDB, conf, readOp,\n        batchWriteRetryPolicy);\n    this.table \u003d tableHandler.initTable();\n\n    instrumentation.initialized();\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/s3guard/DynamoDBMetadataStore.java",
      "extendedDetails": {}
    },
    "4a700c20d553dc5336ee881719bcf189fc46bfbf": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-16520. Race condition in DDB table init and waiting threads.  (#1576). Contributed by Gabor Bota.\n\nFixes HADOOP-16349. DynamoDBMetadataStore.getVersionMarkerItem() to log at info/warn on retry\r\n\r\nChange-Id: Ia83e92b9039ccb780090c99c41b4f71ef7539d35",
      "commitDate": "11/10/19 3:08 AM",
      "commitName": "4a700c20d553dc5336ee881719bcf189fc46bfbf",
      "commitAuthor": "Gabor Bota",
      "commitDateOld": "05/09/19 6:25 AM",
      "commitNameOld": "511df1e837b19ccb9271520589452d82d50ac69d",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 35.86,
      "commitsBetweenForRepo": 307,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,44 +1,48 @@\n   public void initialize(FileSystem fs, ITtlTimeProvider ttlTp)\n       throws IOException {\n     Preconditions.checkNotNull(fs, \"Null filesystem\");\n     Preconditions.checkArgument(fs instanceof S3AFileSystem,\n         \"DynamoDBMetadataStore only supports S3A filesystem.\");\n     bindToOwnerFilesystem((S3AFileSystem) fs);\n     final String bucket \u003d owner.getBucket();\n     String confRegion \u003d conf.getTrimmed(S3GUARD_DDB_REGION_KEY);\n     if (!StringUtils.isEmpty(confRegion)) {\n       region \u003d confRegion;\n       LOG.debug(\"Overriding S3 region with configured DynamoDB region: {}\",\n           region);\n     } else {\n       try {\n         region \u003d owner.getBucketLocation();\n       } catch (AccessDeniedException e) {\n         // access denied here \u003d\u003d can\u0027t call getBucket. Report meaningfully\n         URI uri \u003d owner.getUri();\n         LOG.error(\"Failed to get bucket location from S3 bucket {}\",\n             uri);\n         throw (IOException)new AccessDeniedException(\n             \"S3 client role lacks permission \"\n                 + RolePolicies.S3_GET_BUCKET_LOCATION + \" for \" + uri)\n             .initCause(e);\n       }\n       LOG.debug(\"Inferring DynamoDB region from S3 bucket: {}\", region);\n     }\n     credentials \u003d owner.shareCredentials(\"s3guard\");\n     dynamoDB \u003d createDynamoDB(conf, region, bucket, credentials);\n \n     // use the bucket as the DynamoDB table name if not specified in config\n     tableName \u003d conf.getTrimmed(S3GUARD_DDB_TABLE_NAME_KEY, bucket);\n     initDataAccessRetries(conf);\n \n     // set up a full retry policy\n     invoker \u003d new Invoker(new S3GuardDataAccessRetryPolicy(conf),\n         this::retryEvent\n     );\n \n     this.ttlTimeProvider \u003d ttlTp;\n-    initTable();\n+\n+    tableHandler \u003d new DynamoDBMetadataStoreTableManager(\n+        dynamoDB, tableName, region, amazonDynamoDB, conf, readOp,\n+        batchWriteRetryPolicy);\n+    this.table \u003d tableHandler.initTable();\n \n     instrumentation.initialized();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void initialize(FileSystem fs, ITtlTimeProvider ttlTp)\n      throws IOException {\n    Preconditions.checkNotNull(fs, \"Null filesystem\");\n    Preconditions.checkArgument(fs instanceof S3AFileSystem,\n        \"DynamoDBMetadataStore only supports S3A filesystem.\");\n    bindToOwnerFilesystem((S3AFileSystem) fs);\n    final String bucket \u003d owner.getBucket();\n    String confRegion \u003d conf.getTrimmed(S3GUARD_DDB_REGION_KEY);\n    if (!StringUtils.isEmpty(confRegion)) {\n      region \u003d confRegion;\n      LOG.debug(\"Overriding S3 region with configured DynamoDB region: {}\",\n          region);\n    } else {\n      try {\n        region \u003d owner.getBucketLocation();\n      } catch (AccessDeniedException e) {\n        // access denied here \u003d\u003d can\u0027t call getBucket. Report meaningfully\n        URI uri \u003d owner.getUri();\n        LOG.error(\"Failed to get bucket location from S3 bucket {}\",\n            uri);\n        throw (IOException)new AccessDeniedException(\n            \"S3 client role lacks permission \"\n                + RolePolicies.S3_GET_BUCKET_LOCATION + \" for \" + uri)\n            .initCause(e);\n      }\n      LOG.debug(\"Inferring DynamoDB region from S3 bucket: {}\", region);\n    }\n    credentials \u003d owner.shareCredentials(\"s3guard\");\n    dynamoDB \u003d createDynamoDB(conf, region, bucket, credentials);\n\n    // use the bucket as the DynamoDB table name if not specified in config\n    tableName \u003d conf.getTrimmed(S3GUARD_DDB_TABLE_NAME_KEY, bucket);\n    initDataAccessRetries(conf);\n\n    // set up a full retry policy\n    invoker \u003d new Invoker(new S3GuardDataAccessRetryPolicy(conf),\n        this::retryEvent\n    );\n\n    this.ttlTimeProvider \u003d ttlTp;\n\n    tableHandler \u003d new DynamoDBMetadataStoreTableManager(\n        dynamoDB, tableName, region, amazonDynamoDB, conf, readOp,\n        batchWriteRetryPolicy);\n    this.table \u003d tableHandler.initTable();\n\n    instrumentation.initialized();\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/s3guard/DynamoDBMetadataStore.java",
      "extendedDetails": {}
    },
    "c58e11bf521d746842ce16724211a2a0339d7b61": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HADOOP-16383. Pass ITtlTimeProvider instance in initialize method in MetadataStore interface.  Contributed by Gabor Bota. (#1009) \n\n\r\n",
      "commitDate": "17/07/19 7:24 AM",
      "commitName": "c58e11bf521d746842ce16724211a2a0339d7b61",
      "commitAuthor": "Gabor Bota",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HADOOP-16383. Pass ITtlTimeProvider instance in initialize method in MetadataStore interface.  Contributed by Gabor Bota. (#1009) \n\n\r\n",
          "commitDate": "17/07/19 7:24 AM",
          "commitName": "c58e11bf521d746842ce16724211a2a0339d7b61",
          "commitAuthor": "Gabor Bota",
          "commitDateOld": "12/07/19 5:02 AM",
          "commitNameOld": "b15ef7dc3d91c6d50fa515158104fba29f43e6b0",
          "commitAuthorOld": "Steve Loughran",
          "daysBetweenCommits": 5.1,
          "commitsBetweenForRepo": 35,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,43 +1,44 @@\n-  public void initialize(FileSystem fs) throws IOException {\n+  public void initialize(FileSystem fs, ITtlTimeProvider ttlTp)\n+      throws IOException {\n     Preconditions.checkNotNull(fs, \"Null filesystem\");\n     Preconditions.checkArgument(fs instanceof S3AFileSystem,\n         \"DynamoDBMetadataStore only supports S3A filesystem.\");\n     bindToOwnerFilesystem((S3AFileSystem) fs);\n     final String bucket \u003d owner.getBucket();\n     String confRegion \u003d conf.getTrimmed(S3GUARD_DDB_REGION_KEY);\n     if (!StringUtils.isEmpty(confRegion)) {\n       region \u003d confRegion;\n       LOG.debug(\"Overriding S3 region with configured DynamoDB region: {}\",\n           region);\n     } else {\n       try {\n         region \u003d owner.getBucketLocation();\n       } catch (AccessDeniedException e) {\n         // access denied here \u003d\u003d can\u0027t call getBucket. Report meaningfully\n         URI uri \u003d owner.getUri();\n         LOG.error(\"Failed to get bucket location from S3 bucket {}\",\n             uri);\n         throw (IOException)new AccessDeniedException(\n             \"S3 client role lacks permission \"\n                 + RolePolicies.S3_GET_BUCKET_LOCATION + \" for \" + uri)\n             .initCause(e);\n       }\n       LOG.debug(\"Inferring DynamoDB region from S3 bucket: {}\", region);\n     }\n     credentials \u003d owner.shareCredentials(\"s3guard\");\n     dynamoDB \u003d createDynamoDB(conf, region, bucket, credentials);\n \n     // use the bucket as the DynamoDB table name if not specified in config\n     tableName \u003d conf.getTrimmed(S3GUARD_DDB_TABLE_NAME_KEY, bucket);\n     initDataAccessRetries(conf);\n \n     // set up a full retry policy\n     invoker \u003d new Invoker(new S3GuardDataAccessRetryPolicy(conf),\n         this::retryEvent\n     );\n \n-    timeProvider \u003d new S3Guard.TtlTimeProvider(conf);\n+    this.ttlTimeProvider \u003d ttlTp;\n     initTable();\n \n     instrumentation.initialized();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void initialize(FileSystem fs, ITtlTimeProvider ttlTp)\n      throws IOException {\n    Preconditions.checkNotNull(fs, \"Null filesystem\");\n    Preconditions.checkArgument(fs instanceof S3AFileSystem,\n        \"DynamoDBMetadataStore only supports S3A filesystem.\");\n    bindToOwnerFilesystem((S3AFileSystem) fs);\n    final String bucket \u003d owner.getBucket();\n    String confRegion \u003d conf.getTrimmed(S3GUARD_DDB_REGION_KEY);\n    if (!StringUtils.isEmpty(confRegion)) {\n      region \u003d confRegion;\n      LOG.debug(\"Overriding S3 region with configured DynamoDB region: {}\",\n          region);\n    } else {\n      try {\n        region \u003d owner.getBucketLocation();\n      } catch (AccessDeniedException e) {\n        // access denied here \u003d\u003d can\u0027t call getBucket. Report meaningfully\n        URI uri \u003d owner.getUri();\n        LOG.error(\"Failed to get bucket location from S3 bucket {}\",\n            uri);\n        throw (IOException)new AccessDeniedException(\n            \"S3 client role lacks permission \"\n                + RolePolicies.S3_GET_BUCKET_LOCATION + \" for \" + uri)\n            .initCause(e);\n      }\n      LOG.debug(\"Inferring DynamoDB region from S3 bucket: {}\", region);\n    }\n    credentials \u003d owner.shareCredentials(\"s3guard\");\n    dynamoDB \u003d createDynamoDB(conf, region, bucket, credentials);\n\n    // use the bucket as the DynamoDB table name if not specified in config\n    tableName \u003d conf.getTrimmed(S3GUARD_DDB_TABLE_NAME_KEY, bucket);\n    initDataAccessRetries(conf);\n\n    // set up a full retry policy\n    invoker \u003d new Invoker(new S3GuardDataAccessRetryPolicy(conf),\n        this::retryEvent\n    );\n\n    this.ttlTimeProvider \u003d ttlTp;\n    initTable();\n\n    instrumentation.initialized();\n  }",
          "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/s3guard/DynamoDBMetadataStore.java",
          "extendedDetails": {
            "oldValue": "[fs-FileSystem]",
            "newValue": "[fs-FileSystem, ttlTp-ITtlTimeProvider]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HADOOP-16383. Pass ITtlTimeProvider instance in initialize method in MetadataStore interface.  Contributed by Gabor Bota. (#1009) \n\n\r\n",
          "commitDate": "17/07/19 7:24 AM",
          "commitName": "c58e11bf521d746842ce16724211a2a0339d7b61",
          "commitAuthor": "Gabor Bota",
          "commitDateOld": "12/07/19 5:02 AM",
          "commitNameOld": "b15ef7dc3d91c6d50fa515158104fba29f43e6b0",
          "commitAuthorOld": "Steve Loughran",
          "daysBetweenCommits": 5.1,
          "commitsBetweenForRepo": 35,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,43 +1,44 @@\n-  public void initialize(FileSystem fs) throws IOException {\n+  public void initialize(FileSystem fs, ITtlTimeProvider ttlTp)\n+      throws IOException {\n     Preconditions.checkNotNull(fs, \"Null filesystem\");\n     Preconditions.checkArgument(fs instanceof S3AFileSystem,\n         \"DynamoDBMetadataStore only supports S3A filesystem.\");\n     bindToOwnerFilesystem((S3AFileSystem) fs);\n     final String bucket \u003d owner.getBucket();\n     String confRegion \u003d conf.getTrimmed(S3GUARD_DDB_REGION_KEY);\n     if (!StringUtils.isEmpty(confRegion)) {\n       region \u003d confRegion;\n       LOG.debug(\"Overriding S3 region with configured DynamoDB region: {}\",\n           region);\n     } else {\n       try {\n         region \u003d owner.getBucketLocation();\n       } catch (AccessDeniedException e) {\n         // access denied here \u003d\u003d can\u0027t call getBucket. Report meaningfully\n         URI uri \u003d owner.getUri();\n         LOG.error(\"Failed to get bucket location from S3 bucket {}\",\n             uri);\n         throw (IOException)new AccessDeniedException(\n             \"S3 client role lacks permission \"\n                 + RolePolicies.S3_GET_BUCKET_LOCATION + \" for \" + uri)\n             .initCause(e);\n       }\n       LOG.debug(\"Inferring DynamoDB region from S3 bucket: {}\", region);\n     }\n     credentials \u003d owner.shareCredentials(\"s3guard\");\n     dynamoDB \u003d createDynamoDB(conf, region, bucket, credentials);\n \n     // use the bucket as the DynamoDB table name if not specified in config\n     tableName \u003d conf.getTrimmed(S3GUARD_DDB_TABLE_NAME_KEY, bucket);\n     initDataAccessRetries(conf);\n \n     // set up a full retry policy\n     invoker \u003d new Invoker(new S3GuardDataAccessRetryPolicy(conf),\n         this::retryEvent\n     );\n \n-    timeProvider \u003d new S3Guard.TtlTimeProvider(conf);\n+    this.ttlTimeProvider \u003d ttlTp;\n     initTable();\n \n     instrumentation.initialized();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void initialize(FileSystem fs, ITtlTimeProvider ttlTp)\n      throws IOException {\n    Preconditions.checkNotNull(fs, \"Null filesystem\");\n    Preconditions.checkArgument(fs instanceof S3AFileSystem,\n        \"DynamoDBMetadataStore only supports S3A filesystem.\");\n    bindToOwnerFilesystem((S3AFileSystem) fs);\n    final String bucket \u003d owner.getBucket();\n    String confRegion \u003d conf.getTrimmed(S3GUARD_DDB_REGION_KEY);\n    if (!StringUtils.isEmpty(confRegion)) {\n      region \u003d confRegion;\n      LOG.debug(\"Overriding S3 region with configured DynamoDB region: {}\",\n          region);\n    } else {\n      try {\n        region \u003d owner.getBucketLocation();\n      } catch (AccessDeniedException e) {\n        // access denied here \u003d\u003d can\u0027t call getBucket. Report meaningfully\n        URI uri \u003d owner.getUri();\n        LOG.error(\"Failed to get bucket location from S3 bucket {}\",\n            uri);\n        throw (IOException)new AccessDeniedException(\n            \"S3 client role lacks permission \"\n                + RolePolicies.S3_GET_BUCKET_LOCATION + \" for \" + uri)\n            .initCause(e);\n      }\n      LOG.debug(\"Inferring DynamoDB region from S3 bucket: {}\", region);\n    }\n    credentials \u003d owner.shareCredentials(\"s3guard\");\n    dynamoDB \u003d createDynamoDB(conf, region, bucket, credentials);\n\n    // use the bucket as the DynamoDB table name if not specified in config\n    tableName \u003d conf.getTrimmed(S3GUARD_DDB_TABLE_NAME_KEY, bucket);\n    initDataAccessRetries(conf);\n\n    // set up a full retry policy\n    invoker \u003d new Invoker(new S3GuardDataAccessRetryPolicy(conf),\n        this::retryEvent\n    );\n\n    this.ttlTimeProvider \u003d ttlTp;\n    initTable();\n\n    instrumentation.initialized();\n  }",
          "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/s3guard/DynamoDBMetadataStore.java",
          "extendedDetails": {}
        }
      ]
    },
    "e02eb24e0a9139418120027b694492e0738df20a": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-15183. S3Guard store becomes inconsistent after partial failure of rename.\n\nContributed by Steve Loughran.\n\nChange-Id: I825b0bc36be960475d2d259b1cdab45ae1bb78eb\n",
      "commitDate": "20/06/19 1:56 AM",
      "commitName": "e02eb24e0a9139418120027b694492e0738df20a",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "16/06/19 9:05 AM",
      "commitNameOld": "f9cc9e162175444efe9d5b07ecb9a795f750ca3c",
      "commitAuthorOld": "Gabor Bota",
      "daysBetweenCommits": 3.7,
      "commitsBetweenForRepo": 44,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,42 +1,43 @@\n   public void initialize(FileSystem fs) throws IOException {\n     Preconditions.checkNotNull(fs, \"Null filesystem\");\n     Preconditions.checkArgument(fs instanceof S3AFileSystem,\n         \"DynamoDBMetadataStore only supports S3A filesystem.\");\n     bindToOwnerFilesystem((S3AFileSystem) fs);\n     final String bucket \u003d owner.getBucket();\n     String confRegion \u003d conf.getTrimmed(S3GUARD_DDB_REGION_KEY);\n     if (!StringUtils.isEmpty(confRegion)) {\n       region \u003d confRegion;\n       LOG.debug(\"Overriding S3 region with configured DynamoDB region: {}\",\n           region);\n     } else {\n       try {\n         region \u003d owner.getBucketLocation();\n       } catch (AccessDeniedException e) {\n         // access denied here \u003d\u003d can\u0027t call getBucket. Report meaningfully\n         URI uri \u003d owner.getUri();\n         LOG.error(\"Failed to get bucket location from S3 bucket {}\",\n             uri);\n         throw (IOException)new AccessDeniedException(\n             \"S3 client role lacks permission \"\n                 + RolePolicies.S3_GET_BUCKET_LOCATION + \" for \" + uri)\n             .initCause(e);\n       }\n       LOG.debug(\"Inferring DynamoDB region from S3 bucket: {}\", region);\n     }\n     credentials \u003d owner.shareCredentials(\"s3guard\");\n     dynamoDB \u003d createDynamoDB(conf, region, bucket, credentials);\n \n     // use the bucket as the DynamoDB table name if not specified in config\n     tableName \u003d conf.getTrimmed(S3GUARD_DDB_TABLE_NAME_KEY, bucket);\n     initDataAccessRetries(conf);\n \n     // set up a full retry policy\n     invoker \u003d new Invoker(new S3GuardDataAccessRetryPolicy(conf),\n         this::retryEvent\n     );\n \n+    timeProvider \u003d new S3Guard.TtlTimeProvider(conf);\n     initTable();\n \n     instrumentation.initialized();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void initialize(FileSystem fs) throws IOException {\n    Preconditions.checkNotNull(fs, \"Null filesystem\");\n    Preconditions.checkArgument(fs instanceof S3AFileSystem,\n        \"DynamoDBMetadataStore only supports S3A filesystem.\");\n    bindToOwnerFilesystem((S3AFileSystem) fs);\n    final String bucket \u003d owner.getBucket();\n    String confRegion \u003d conf.getTrimmed(S3GUARD_DDB_REGION_KEY);\n    if (!StringUtils.isEmpty(confRegion)) {\n      region \u003d confRegion;\n      LOG.debug(\"Overriding S3 region with configured DynamoDB region: {}\",\n          region);\n    } else {\n      try {\n        region \u003d owner.getBucketLocation();\n      } catch (AccessDeniedException e) {\n        // access denied here \u003d\u003d can\u0027t call getBucket. Report meaningfully\n        URI uri \u003d owner.getUri();\n        LOG.error(\"Failed to get bucket location from S3 bucket {}\",\n            uri);\n        throw (IOException)new AccessDeniedException(\n            \"S3 client role lacks permission \"\n                + RolePolicies.S3_GET_BUCKET_LOCATION + \" for \" + uri)\n            .initCause(e);\n      }\n      LOG.debug(\"Inferring DynamoDB region from S3 bucket: {}\", region);\n    }\n    credentials \u003d owner.shareCredentials(\"s3guard\");\n    dynamoDB \u003d createDynamoDB(conf, region, bucket, credentials);\n\n    // use the bucket as the DynamoDB table name if not specified in config\n    tableName \u003d conf.getTrimmed(S3GUARD_DDB_TABLE_NAME_KEY, bucket);\n    initDataAccessRetries(conf);\n\n    // set up a full retry policy\n    invoker \u003d new Invoker(new S3GuardDataAccessRetryPolicy(conf),\n        this::retryEvent\n    );\n\n    timeProvider \u003d new S3Guard.TtlTimeProvider(conf);\n    initTable();\n\n    instrumentation.initialized();\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/s3guard/DynamoDBMetadataStore.java",
      "extendedDetails": {}
    },
    "d7c0a08a1c077752918a8cf1b4f1900ce2721899": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-15426 Make S3guard client resilient to DDB throttle events and network failures (Contributed by Steve Loughran)\n",
      "commitDate": "12/09/18 9:04 PM",
      "commitName": "d7c0a08a1c077752918a8cf1b4f1900ce2721899",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "12/09/18 4:36 PM",
      "commitNameOld": "d32a8d5d582725eb724b78f27310ad1efd33ed2a",
      "commitAuthorOld": "Aaron Fabbri",
      "daysBetweenCommits": 0.19,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,45 +1,42 @@\n   public void initialize(FileSystem fs) throws IOException {\n     Preconditions.checkNotNull(fs, \"Null filesystem\");\n     Preconditions.checkArgument(fs instanceof S3AFileSystem,\n         \"DynamoDBMetadataStore only supports S3A filesystem.\");\n-    owner \u003d (S3AFileSystem) fs;\n-    instrumentation \u003d owner.getInstrumentation().getS3GuardInstrumentation();\n+    bindToOwnerFilesystem((S3AFileSystem) fs);\n     final String bucket \u003d owner.getBucket();\n-    conf \u003d owner.getConf();\n     String confRegion \u003d conf.getTrimmed(S3GUARD_DDB_REGION_KEY);\n     if (!StringUtils.isEmpty(confRegion)) {\n       region \u003d confRegion;\n       LOG.debug(\"Overriding S3 region with configured DynamoDB region: {}\",\n           region);\n     } else {\n       try {\n         region \u003d owner.getBucketLocation();\n       } catch (AccessDeniedException e) {\n         // access denied here \u003d\u003d can\u0027t call getBucket. Report meaningfully\n         URI uri \u003d owner.getUri();\n         LOG.error(\"Failed to get bucket location from S3 bucket {}\",\n             uri);\n         throw (IOException)new AccessDeniedException(\n             \"S3 client role lacks permission \"\n                 + RolePolicies.S3_GET_BUCKET_LOCATION + \" for \" + uri)\n             .initCause(e);\n       }\n       LOG.debug(\"Inferring DynamoDB region from S3 bucket: {}\", region);\n     }\n-    username \u003d owner.getUsername();\n     credentials \u003d owner.shareCredentials(\"s3guard\");\n     dynamoDB \u003d createDynamoDB(conf, region, bucket, credentials);\n \n     // use the bucket as the DynamoDB table name if not specified in config\n     tableName \u003d conf.getTrimmed(S3GUARD_DDB_TABLE_NAME_KEY, bucket);\n     initDataAccessRetries(conf);\n \n     // set up a full retry policy\n-    invoker \u003d new Invoker(new S3ARetryPolicy(conf),\n+    invoker \u003d new Invoker(new S3GuardDataAccessRetryPolicy(conf),\n         this::retryEvent\n     );\n \n     initTable();\n \n     instrumentation.initialized();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void initialize(FileSystem fs) throws IOException {\n    Preconditions.checkNotNull(fs, \"Null filesystem\");\n    Preconditions.checkArgument(fs instanceof S3AFileSystem,\n        \"DynamoDBMetadataStore only supports S3A filesystem.\");\n    bindToOwnerFilesystem((S3AFileSystem) fs);\n    final String bucket \u003d owner.getBucket();\n    String confRegion \u003d conf.getTrimmed(S3GUARD_DDB_REGION_KEY);\n    if (!StringUtils.isEmpty(confRegion)) {\n      region \u003d confRegion;\n      LOG.debug(\"Overriding S3 region with configured DynamoDB region: {}\",\n          region);\n    } else {\n      try {\n        region \u003d owner.getBucketLocation();\n      } catch (AccessDeniedException e) {\n        // access denied here \u003d\u003d can\u0027t call getBucket. Report meaningfully\n        URI uri \u003d owner.getUri();\n        LOG.error(\"Failed to get bucket location from S3 bucket {}\",\n            uri);\n        throw (IOException)new AccessDeniedException(\n            \"S3 client role lacks permission \"\n                + RolePolicies.S3_GET_BUCKET_LOCATION + \" for \" + uri)\n            .initCause(e);\n      }\n      LOG.debug(\"Inferring DynamoDB region from S3 bucket: {}\", region);\n    }\n    credentials \u003d owner.shareCredentials(\"s3guard\");\n    dynamoDB \u003d createDynamoDB(conf, region, bucket, credentials);\n\n    // use the bucket as the DynamoDB table name if not specified in config\n    tableName \u003d conf.getTrimmed(S3GUARD_DDB_TABLE_NAME_KEY, bucket);\n    initDataAccessRetries(conf);\n\n    // set up a full retry policy\n    invoker \u003d new Invoker(new S3GuardDataAccessRetryPolicy(conf),\n        this::retryEvent\n    );\n\n    initTable();\n\n    instrumentation.initialized();\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/s3guard/DynamoDBMetadataStore.java",
      "extendedDetails": {}
    },
    "da9a39eed138210de29b59b90c449b28da1c04f9": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-15583. Stabilize S3A Assumed Role support.\nContributed by Steve Loughran.\n",
      "commitDate": "08/08/18 10:57 PM",
      "commitName": "da9a39eed138210de29b59b90c449b28da1c04f9",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "12/07/18 8:24 AM",
      "commitNameOld": "a08812a1b10df059b26f6a216e6339490298ba28",
      "commitAuthorOld": "Sean Mackrory",
      "daysBetweenCommits": 27.61,
      "commitsBetweenForRepo": 177,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,33 +1,45 @@\n   public void initialize(FileSystem fs) throws IOException {\n     Preconditions.checkNotNull(fs, \"Null filesystem\");\n     Preconditions.checkArgument(fs instanceof S3AFileSystem,\n         \"DynamoDBMetadataStore only supports S3A filesystem.\");\n     owner \u003d (S3AFileSystem) fs;\n     instrumentation \u003d owner.getInstrumentation().getS3GuardInstrumentation();\n     final String bucket \u003d owner.getBucket();\n     conf \u003d owner.getConf();\n     String confRegion \u003d conf.getTrimmed(S3GUARD_DDB_REGION_KEY);\n     if (!StringUtils.isEmpty(confRegion)) {\n       region \u003d confRegion;\n       LOG.debug(\"Overriding S3 region with configured DynamoDB region: {}\",\n           region);\n     } else {\n-      region \u003d owner.getBucketLocation();\n+      try {\n+        region \u003d owner.getBucketLocation();\n+      } catch (AccessDeniedException e) {\n+        // access denied here \u003d\u003d can\u0027t call getBucket. Report meaningfully\n+        URI uri \u003d owner.getUri();\n+        LOG.error(\"Failed to get bucket location from S3 bucket {}\",\n+            uri);\n+        throw (IOException)new AccessDeniedException(\n+            \"S3 client role lacks permission \"\n+                + RolePolicies.S3_GET_BUCKET_LOCATION + \" for \" + uri)\n+            .initCause(e);\n+      }\n       LOG.debug(\"Inferring DynamoDB region from S3 bucket: {}\", region);\n     }\n     username \u003d owner.getUsername();\n-    dynamoDB \u003d createDynamoDB(conf, region);\n+    credentials \u003d owner.shareCredentials(\"s3guard\");\n+    dynamoDB \u003d createDynamoDB(conf, region, bucket, credentials);\n \n     // use the bucket as the DynamoDB table name if not specified in config\n     tableName \u003d conf.getTrimmed(S3GUARD_DDB_TABLE_NAME_KEY, bucket);\n     initDataAccessRetries(conf);\n \n     // set up a full retry policy\n     invoker \u003d new Invoker(new S3ARetryPolicy(conf),\n         this::retryEvent\n     );\n \n     initTable();\n \n     instrumentation.initialized();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void initialize(FileSystem fs) throws IOException {\n    Preconditions.checkNotNull(fs, \"Null filesystem\");\n    Preconditions.checkArgument(fs instanceof S3AFileSystem,\n        \"DynamoDBMetadataStore only supports S3A filesystem.\");\n    owner \u003d (S3AFileSystem) fs;\n    instrumentation \u003d owner.getInstrumentation().getS3GuardInstrumentation();\n    final String bucket \u003d owner.getBucket();\n    conf \u003d owner.getConf();\n    String confRegion \u003d conf.getTrimmed(S3GUARD_DDB_REGION_KEY);\n    if (!StringUtils.isEmpty(confRegion)) {\n      region \u003d confRegion;\n      LOG.debug(\"Overriding S3 region with configured DynamoDB region: {}\",\n          region);\n    } else {\n      try {\n        region \u003d owner.getBucketLocation();\n      } catch (AccessDeniedException e) {\n        // access denied here \u003d\u003d can\u0027t call getBucket. Report meaningfully\n        URI uri \u003d owner.getUri();\n        LOG.error(\"Failed to get bucket location from S3 bucket {}\",\n            uri);\n        throw (IOException)new AccessDeniedException(\n            \"S3 client role lacks permission \"\n                + RolePolicies.S3_GET_BUCKET_LOCATION + \" for \" + uri)\n            .initCause(e);\n      }\n      LOG.debug(\"Inferring DynamoDB region from S3 bucket: {}\", region);\n    }\n    username \u003d owner.getUsername();\n    credentials \u003d owner.shareCredentials(\"s3guard\");\n    dynamoDB \u003d createDynamoDB(conf, region, bucket, credentials);\n\n    // use the bucket as the DynamoDB table name if not specified in config\n    tableName \u003d conf.getTrimmed(S3GUARD_DDB_TABLE_NAME_KEY, bucket);\n    initDataAccessRetries(conf);\n\n    // set up a full retry policy\n    invoker \u003d new Invoker(new S3ARetryPolicy(conf),\n        this::retryEvent\n    );\n\n    initTable();\n\n    instrumentation.initialized();\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/s3guard/DynamoDBMetadataStore.java",
      "extendedDetails": {}
    },
    "b089a06793d94d42b7da1b7566e366ceb748e081": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-14918. Remove the Local Dynamo DB test option. Contributed by Gabor Bota.\n",
      "commitDate": "20/06/18 3:45 PM",
      "commitName": "b089a06793d94d42b7da1b7566e366ceb748e081",
      "commitAuthor": "Sean Mackrory",
      "commitDateOld": "23/04/18 3:26 PM",
      "commitNameOld": "989a3929a92edb000cfa486146987fb75a9eda61",
      "commitAuthorOld": "Aaron Fabbri",
      "daysBetweenCommits": 58.01,
      "commitsBetweenForRepo": 950,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,32 +1,33 @@\n   public void initialize(FileSystem fs) throws IOException {\n+    Preconditions.checkNotNull(fs, \"Null filesystem\");\n     Preconditions.checkArgument(fs instanceof S3AFileSystem,\n         \"DynamoDBMetadataStore only supports S3A filesystem.\");\n     owner \u003d (S3AFileSystem) fs;\n     instrumentation \u003d owner.getInstrumentation().getS3GuardInstrumentation();\n     final String bucket \u003d owner.getBucket();\n     conf \u003d owner.getConf();\n     String confRegion \u003d conf.getTrimmed(S3GUARD_DDB_REGION_KEY);\n     if (!StringUtils.isEmpty(confRegion)) {\n       region \u003d confRegion;\n       LOG.debug(\"Overriding S3 region with configured DynamoDB region: {}\",\n           region);\n     } else {\n       region \u003d owner.getBucketLocation();\n       LOG.debug(\"Inferring DynamoDB region from S3 bucket: {}\", region);\n     }\n     username \u003d owner.getUsername();\n     dynamoDB \u003d createDynamoDB(conf, region);\n \n     // use the bucket as the DynamoDB table name if not specified in config\n     tableName \u003d conf.getTrimmed(S3GUARD_DDB_TABLE_NAME_KEY, bucket);\n     initDataAccessRetries(conf);\n \n     // set up a full retry policy\n     invoker \u003d new Invoker(new S3ARetryPolicy(conf),\n         this::retryEvent\n     );\n \n     initTable();\n \n     instrumentation.initialized();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void initialize(FileSystem fs) throws IOException {\n    Preconditions.checkNotNull(fs, \"Null filesystem\");\n    Preconditions.checkArgument(fs instanceof S3AFileSystem,\n        \"DynamoDBMetadataStore only supports S3A filesystem.\");\n    owner \u003d (S3AFileSystem) fs;\n    instrumentation \u003d owner.getInstrumentation().getS3GuardInstrumentation();\n    final String bucket \u003d owner.getBucket();\n    conf \u003d owner.getConf();\n    String confRegion \u003d conf.getTrimmed(S3GUARD_DDB_REGION_KEY);\n    if (!StringUtils.isEmpty(confRegion)) {\n      region \u003d confRegion;\n      LOG.debug(\"Overriding S3 region with configured DynamoDB region: {}\",\n          region);\n    } else {\n      region \u003d owner.getBucketLocation();\n      LOG.debug(\"Inferring DynamoDB region from S3 bucket: {}\", region);\n    }\n    username \u003d owner.getUsername();\n    dynamoDB \u003d createDynamoDB(conf, region);\n\n    // use the bucket as the DynamoDB table name if not specified in config\n    tableName \u003d conf.getTrimmed(S3GUARD_DDB_TABLE_NAME_KEY, bucket);\n    initDataAccessRetries(conf);\n\n    // set up a full retry policy\n    invoker \u003d new Invoker(new S3ARetryPolicy(conf),\n        this::retryEvent\n    );\n\n    initTable();\n\n    instrumentation.initialized();\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/s3guard/DynamoDBMetadataStore.java",
      "extendedDetails": {}
    },
    "de8b6ca5ef8614de6d6277b7617e27c788b0555c": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-13786 Add S3A committer for zero-rename commits to S3 endpoints.\nContributed by Steve Loughran and Ryan Blue.\n",
      "commitDate": "22/11/17 7:28 AM",
      "commitName": "de8b6ca5ef8614de6d6277b7617e27c788b0555c",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "25/09/17 3:59 PM",
      "commitNameOld": "47011d7dd300b0c74bb6cfe25b918c479d718f4f",
      "commitAuthorOld": "Aaron Fabbri",
      "daysBetweenCommits": 57.69,
      "commitsBetweenForRepo": 477,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,27 +1,32 @@\n   public void initialize(FileSystem fs) throws IOException {\n     Preconditions.checkArgument(fs instanceof S3AFileSystem,\n         \"DynamoDBMetadataStore only supports S3A filesystem.\");\n-    final S3AFileSystem s3afs \u003d (S3AFileSystem) fs;\n-    instrumentation \u003d s3afs.getInstrumentation().getS3GuardInstrumentation();\n-    final String bucket \u003d s3afs.getBucket();\n-    String confRegion \u003d s3afs.getConf().getTrimmed(S3GUARD_DDB_REGION_KEY);\n+    owner \u003d (S3AFileSystem) fs;\n+    instrumentation \u003d owner.getInstrumentation().getS3GuardInstrumentation();\n+    final String bucket \u003d owner.getBucket();\n+    conf \u003d owner.getConf();\n+    String confRegion \u003d conf.getTrimmed(S3GUARD_DDB_REGION_KEY);\n     if (!StringUtils.isEmpty(confRegion)) {\n       region \u003d confRegion;\n       LOG.debug(\"Overriding S3 region with configured DynamoDB region: {}\",\n           region);\n     } else {\n-      region \u003d s3afs.getBucketLocation();\n+      region \u003d owner.getBucketLocation();\n       LOG.debug(\"Inferring DynamoDB region from S3 bucket: {}\", region);\n     }\n-    username \u003d s3afs.getUsername();\n-    conf \u003d s3afs.getConf();\n+    username \u003d owner.getUsername();\n     dynamoDB \u003d createDynamoDB(conf, region);\n \n     // use the bucket as the DynamoDB table name if not specified in config\n     tableName \u003d conf.getTrimmed(S3GUARD_DDB_TABLE_NAME_KEY, bucket);\n-    setMaxRetries(conf);\n+    initDataAccessRetries(conf);\n+\n+    // set up a full retry policy\n+    invoker \u003d new Invoker(new S3ARetryPolicy(conf),\n+        this::retryEvent\n+    );\n \n     initTable();\n \n     instrumentation.initialized();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void initialize(FileSystem fs) throws IOException {\n    Preconditions.checkArgument(fs instanceof S3AFileSystem,\n        \"DynamoDBMetadataStore only supports S3A filesystem.\");\n    owner \u003d (S3AFileSystem) fs;\n    instrumentation \u003d owner.getInstrumentation().getS3GuardInstrumentation();\n    final String bucket \u003d owner.getBucket();\n    conf \u003d owner.getConf();\n    String confRegion \u003d conf.getTrimmed(S3GUARD_DDB_REGION_KEY);\n    if (!StringUtils.isEmpty(confRegion)) {\n      region \u003d confRegion;\n      LOG.debug(\"Overriding S3 region with configured DynamoDB region: {}\",\n          region);\n    } else {\n      region \u003d owner.getBucketLocation();\n      LOG.debug(\"Inferring DynamoDB region from S3 bucket: {}\", region);\n    }\n    username \u003d owner.getUsername();\n    dynamoDB \u003d createDynamoDB(conf, region);\n\n    // use the bucket as the DynamoDB table name if not specified in config\n    tableName \u003d conf.getTrimmed(S3GUARD_DDB_TABLE_NAME_KEY, bucket);\n    initDataAccessRetries(conf);\n\n    // set up a full retry policy\n    invoker \u003d new Invoker(new S3ARetryPolicy(conf),\n        this::retryEvent\n    );\n\n    initTable();\n\n    instrumentation.initialized();\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/s3guard/DynamoDBMetadataStore.java",
      "extendedDetails": {}
    },
    "621b43e254afaff708cd6fc4698b29628f6abc33": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-13345 HS3Guard: Improved Consistency for S3A.\nContributed by: Chris Nauroth, Aaron Fabbri, Mingliang Liu, Lei (Eddy) Xu,\nSean Mackrory, Steve Loughran and others.\n",
      "commitDate": "01/09/17 6:13 AM",
      "commitName": "621b43e254afaff708cd6fc4698b29628f6abc33",
      "commitAuthor": "Steve Loughran",
      "diff": "@@ -0,0 +1,27 @@\n+  public void initialize(FileSystem fs) throws IOException {\n+    Preconditions.checkArgument(fs instanceof S3AFileSystem,\n+        \"DynamoDBMetadataStore only supports S3A filesystem.\");\n+    final S3AFileSystem s3afs \u003d (S3AFileSystem) fs;\n+    instrumentation \u003d s3afs.getInstrumentation().getS3GuardInstrumentation();\n+    final String bucket \u003d s3afs.getBucket();\n+    String confRegion \u003d s3afs.getConf().getTrimmed(S3GUARD_DDB_REGION_KEY);\n+    if (!StringUtils.isEmpty(confRegion)) {\n+      region \u003d confRegion;\n+      LOG.debug(\"Overriding S3 region with configured DynamoDB region: {}\",\n+          region);\n+    } else {\n+      region \u003d s3afs.getBucketLocation();\n+      LOG.debug(\"Inferring DynamoDB region from S3 bucket: {}\", region);\n+    }\n+    username \u003d s3afs.getUsername();\n+    conf \u003d s3afs.getConf();\n+    dynamoDB \u003d createDynamoDB(conf, region);\n+\n+    // use the bucket as the DynamoDB table name if not specified in config\n+    tableName \u003d conf.getTrimmed(S3GUARD_DDB_TABLE_NAME_KEY, bucket);\n+    setMaxRetries(conf);\n+\n+    initTable();\n+\n+    instrumentation.initialized();\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void initialize(FileSystem fs) throws IOException {\n    Preconditions.checkArgument(fs instanceof S3AFileSystem,\n        \"DynamoDBMetadataStore only supports S3A filesystem.\");\n    final S3AFileSystem s3afs \u003d (S3AFileSystem) fs;\n    instrumentation \u003d s3afs.getInstrumentation().getS3GuardInstrumentation();\n    final String bucket \u003d s3afs.getBucket();\n    String confRegion \u003d s3afs.getConf().getTrimmed(S3GUARD_DDB_REGION_KEY);\n    if (!StringUtils.isEmpty(confRegion)) {\n      region \u003d confRegion;\n      LOG.debug(\"Overriding S3 region with configured DynamoDB region: {}\",\n          region);\n    } else {\n      region \u003d s3afs.getBucketLocation();\n      LOG.debug(\"Inferring DynamoDB region from S3 bucket: {}\", region);\n    }\n    username \u003d s3afs.getUsername();\n    conf \u003d s3afs.getConf();\n    dynamoDB \u003d createDynamoDB(conf, region);\n\n    // use the bucket as the DynamoDB table name if not specified in config\n    tableName \u003d conf.getTrimmed(S3GUARD_DDB_TABLE_NAME_KEY, bucket);\n    setMaxRetries(conf);\n\n    initTable();\n\n    instrumentation.initialized();\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/s3guard/DynamoDBMetadataStore.java"
    }
  }
}