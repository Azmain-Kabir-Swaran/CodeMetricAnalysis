{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DefaultSubClusterResolverImpl.java",
  "functionName": "load",
  "functionId": "load",
  "sourceFilePath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common/src/main/java/org/apache/hadoop/yarn/server/federation/resolver/DefaultSubClusterResolverImpl.java",
  "functionStartLine": 87,
  "functionEndLine": 144,
  "numCommitsSeen": 1,
  "timeTaken": 614,
  "changeHistory": [
    "d19b6773012d78cb20b92e98e13546013b6622c2"
  ],
  "changeHistoryShort": {
    "d19b6773012d78cb20b92e98e13546013b6622c2": "Yintroduced"
  },
  "changeHistoryDetails": {
    "d19b6773012d78cb20b92e98e13546013b6622c2": {
      "type": "Yintroduced",
      "commitMessage": "YARN-5390. Federation Subcluster Resolver. Contributed by Ellen Hui.\n\n(cherry picked from commit d3dc461a935c2af4ec3f0312ff0c26918c408467)\n",
      "commitDate": "01/08/17 5:28 PM",
      "commitName": "d19b6773012d78cb20b92e98e13546013b6622c2",
      "commitAuthor": "Subru Krishnan",
      "diff": "@@ -0,0 +1,58 @@\n+  public void load() {\n+    String fileName \u003d\n+        this.conf.get(YarnConfiguration.FEDERATION_MACHINE_LIST, \"\");\n+\n+    try {\n+      if (fileName \u003d\u003d null || fileName.trim().length() \u003d\u003d 0) {\n+        LOG.info(\n+            \"The machine list file path is not specified in the configuration\");\n+        return;\n+      }\n+\n+      Path file \u003d null;\n+      BufferedReader reader \u003d null;\n+\n+      try {\n+        file \u003d Paths.get(fileName);\n+      } catch (InvalidPathException e) {\n+        LOG.info(\"The configured machine list file path {} does not exist\",\n+            fileName);\n+        return;\n+      }\n+\n+      try {\n+        reader \u003d Files.newBufferedReader(file, Charset.defaultCharset());\n+        String line \u003d null;\n+        while ((line \u003d reader.readLine()) !\u003d null) {\n+          String[] tokens \u003d line.split(\",\");\n+          if (tokens.length \u003d\u003d 3) {\n+\n+            String nodeName \u003d tokens[NODE_NAME_INDEX].trim().toUpperCase();\n+            SubClusterId subClusterId \u003d\n+                SubClusterId.newInstance(tokens[SUBCLUSTER_ID_INDEX].trim());\n+            String rackName \u003d tokens[RACK_NAME_INDEX].trim().toUpperCase();\n+\n+            if (LOG.isDebugEnabled()) {\n+              LOG.debug(\"Loading node into resolver: {} --\u003e {}\", nodeName,\n+                  subClusterId);\n+              LOG.debug(\"Loading rack into resolver: {} --\u003e {} \", rackName,\n+                  subClusterId);\n+            }\n+\n+            this.getNodeToSubCluster().put(nodeName, subClusterId);\n+            loadRackToSubCluster(rackName, subClusterId);\n+          } else {\n+            LOG.warn(\"Skipping malformed line in machine list: \" + line);\n+          }\n+        }\n+      } finally {\n+        if (reader !\u003d null) {\n+          reader.close();\n+        }\n+      }\n+      LOG.info(\"Successfully loaded file {}\", fileName);\n+\n+    } catch (Exception e) {\n+      LOG.error(\"Failed to parse file \" + fileName, e);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void load() {\n    String fileName \u003d\n        this.conf.get(YarnConfiguration.FEDERATION_MACHINE_LIST, \"\");\n\n    try {\n      if (fileName \u003d\u003d null || fileName.trim().length() \u003d\u003d 0) {\n        LOG.info(\n            \"The machine list file path is not specified in the configuration\");\n        return;\n      }\n\n      Path file \u003d null;\n      BufferedReader reader \u003d null;\n\n      try {\n        file \u003d Paths.get(fileName);\n      } catch (InvalidPathException e) {\n        LOG.info(\"The configured machine list file path {} does not exist\",\n            fileName);\n        return;\n      }\n\n      try {\n        reader \u003d Files.newBufferedReader(file, Charset.defaultCharset());\n        String line \u003d null;\n        while ((line \u003d reader.readLine()) !\u003d null) {\n          String[] tokens \u003d line.split(\",\");\n          if (tokens.length \u003d\u003d 3) {\n\n            String nodeName \u003d tokens[NODE_NAME_INDEX].trim().toUpperCase();\n            SubClusterId subClusterId \u003d\n                SubClusterId.newInstance(tokens[SUBCLUSTER_ID_INDEX].trim());\n            String rackName \u003d tokens[RACK_NAME_INDEX].trim().toUpperCase();\n\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(\"Loading node into resolver: {} --\u003e {}\", nodeName,\n                  subClusterId);\n              LOG.debug(\"Loading rack into resolver: {} --\u003e {} \", rackName,\n                  subClusterId);\n            }\n\n            this.getNodeToSubCluster().put(nodeName, subClusterId);\n            loadRackToSubCluster(rackName, subClusterId);\n          } else {\n            LOG.warn(\"Skipping malformed line in machine list: \" + line);\n          }\n        }\n      } finally {\n        if (reader !\u003d null) {\n          reader.close();\n        }\n      }\n      LOG.info(\"Successfully loaded file {}\", fileName);\n\n    } catch (Exception e) {\n      LOG.error(\"Failed to parse file \" + fileName, e);\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common/src/main/java/org/apache/hadoop/yarn/server/federation/resolver/DefaultSubClusterResolverImpl.java"
    }
  }
}