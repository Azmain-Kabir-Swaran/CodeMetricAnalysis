{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "Journal.java",
  "functionName": "scanStorageForLatestEdits",
  "functionId": "scanStorageForLatestEdits",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java",
  "functionStartLine": 221,
  "functionEndLine": 246,
  "numCommitsSeen": 79,
  "timeTaken": 3300,
  "changeHistory": [
    "6beb25ab7e4f5454dba0315a296081e61753f301",
    "53bad4eb008ec553dcdbe01e7ae975dcecde6590",
    "6ae2a0d048e133b43249c248a75a4d77d9abb80d",
    "9dab514b22f49322738935cfd915c2b4eba50b88",
    "60c20e559b8036410e2d9081b9c60d1e04e56253",
    "8021d9199f278345aca6211f318145342ad036f4",
    "c95a1674b61ef2a6963dc64604986ef90a8c636d",
    "74d4573a23db5586c6e47ff2277aa7c35237da34"
  ],
  "changeHistoryShort": {
    "6beb25ab7e4f5454dba0315a296081e61753f301": "Ybodychange",
    "53bad4eb008ec553dcdbe01e7ae975dcecde6590": "Ybodychange",
    "6ae2a0d048e133b43249c248a75a4d77d9abb80d": "Ybodychange",
    "9dab514b22f49322738935cfd915c2b4eba50b88": "Ybodychange",
    "60c20e559b8036410e2d9081b9c60d1e04e56253": "Ymultichange(Yrename,Yreturntypechange,Ybodychange)",
    "8021d9199f278345aca6211f318145342ad036f4": "Ybodychange",
    "c95a1674b61ef2a6963dc64604986ef90a8c636d": "Ybodychange",
    "74d4573a23db5586c6e47ff2277aa7c35237da34": "Yintroduced"
  },
  "changeHistoryDetails": {
    "6beb25ab7e4f5454dba0315a296081e61753f301": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13544. Improve logging for JournalNode in federated cluster.\n",
      "commitDate": "14/05/18 10:12 AM",
      "commitName": "6beb25ab7e4f5454dba0315a296081e61753f301",
      "commitAuthor": "Hanisha Koneru",
      "commitDateOld": "13/10/17 2:22 PM",
      "commitNameOld": "8dd1eeb94fef59feaf19182dd8f1fcf1389c7f34",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 212.83,
      "commitsBetweenForRepo": 2051,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,25 +1,26 @@\n   private synchronized EditLogFile scanStorageForLatestEdits() throws IOException {\n     if (!fjm.getStorageDirectory().getCurrentDir().exists()) {\n       return null;\n     }\n     \n     LOG.info(\"Scanning storage \" + fjm);\n     List\u003cEditLogFile\u003e files \u003d fjm.getLogFiles(0);\n     \n     while (!files.isEmpty()) {\n       EditLogFile latestLog \u003d files.remove(files.size() - 1);\n       latestLog.scanLog(Long.MAX_VALUE, false);\n-      LOG.info(\"Latest log is \" + latestLog);\n+      LOG.info(\"Latest log is \" + latestLog + \" ; journal id: \" + journalId);\n       if (latestLog.getLastTxId() \u003d\u003d HdfsServerConstants.INVALID_TXID) {\n         // the log contains no transactions\n         LOG.warn(\"Latest log \" + latestLog + \" has no transactions. \" +\n-            \"moving it aside and looking for previous log\");\n+            \"moving it aside and looking for previous log\"\n+            + \" ; journal id: \" + journalId);\n         latestLog.moveAsideEmptyFile();\n       } else {\n         return latestLog;\n       }\n     }\n     \n     LOG.info(\"No files in \" + fjm);\n     return null;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized EditLogFile scanStorageForLatestEdits() throws IOException {\n    if (!fjm.getStorageDirectory().getCurrentDir().exists()) {\n      return null;\n    }\n    \n    LOG.info(\"Scanning storage \" + fjm);\n    List\u003cEditLogFile\u003e files \u003d fjm.getLogFiles(0);\n    \n    while (!files.isEmpty()) {\n      EditLogFile latestLog \u003d files.remove(files.size() - 1);\n      latestLog.scanLog(Long.MAX_VALUE, false);\n      LOG.info(\"Latest log is \" + latestLog + \" ; journal id: \" + journalId);\n      if (latestLog.getLastTxId() \u003d\u003d HdfsServerConstants.INVALID_TXID) {\n        // the log contains no transactions\n        LOG.warn(\"Latest log \" + latestLog + \" has no transactions. \" +\n            \"moving it aside and looking for previous log\"\n            + \" ; journal id: \" + journalId);\n        latestLog.moveAsideEmptyFile();\n      } else {\n        return latestLog;\n      }\n    }\n    \n    LOG.info(\"No files in \" + fjm);\n    return null;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java",
      "extendedDetails": {}
    },
    "53bad4eb008ec553dcdbe01e7ae975dcecde6590": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8996. Consolidate validateLog and scanLog in FJM#EditLogFile (Zhe Zhang via Colin P. McCabe)\n",
      "commitDate": "14/09/15 3:22 PM",
      "commitName": "53bad4eb008ec553dcdbe01e7ae975dcecde6590",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "08/09/15 10:33 PM",
      "commitNameOld": "94cf7ab9d28a885181afeb2c181dfe857d158254",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 5.7,
      "commitsBetweenForRepo": 32,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,25 +1,25 @@\n   private synchronized EditLogFile scanStorageForLatestEdits() throws IOException {\n     if (!fjm.getStorageDirectory().getCurrentDir().exists()) {\n       return null;\n     }\n     \n     LOG.info(\"Scanning storage \" + fjm);\n     List\u003cEditLogFile\u003e files \u003d fjm.getLogFiles(0);\n     \n     while (!files.isEmpty()) {\n       EditLogFile latestLog \u003d files.remove(files.size() - 1);\n-      latestLog.scanLog();\n+      latestLog.scanLog(Long.MAX_VALUE, false);\n       LOG.info(\"Latest log is \" + latestLog);\n       if (latestLog.getLastTxId() \u003d\u003d HdfsServerConstants.INVALID_TXID) {\n         // the log contains no transactions\n         LOG.warn(\"Latest log \" + latestLog + \" has no transactions. \" +\n             \"moving it aside and looking for previous log\");\n         latestLog.moveAsideEmptyFile();\n       } else {\n         return latestLog;\n       }\n     }\n     \n     LOG.info(\"No files in \" + fjm);\n     return null;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized EditLogFile scanStorageForLatestEdits() throws IOException {\n    if (!fjm.getStorageDirectory().getCurrentDir().exists()) {\n      return null;\n    }\n    \n    LOG.info(\"Scanning storage \" + fjm);\n    List\u003cEditLogFile\u003e files \u003d fjm.getLogFiles(0);\n    \n    while (!files.isEmpty()) {\n      EditLogFile latestLog \u003d files.remove(files.size() - 1);\n      latestLog.scanLog(Long.MAX_VALUE, false);\n      LOG.info(\"Latest log is \" + latestLog);\n      if (latestLog.getLastTxId() \u003d\u003d HdfsServerConstants.INVALID_TXID) {\n        // the log contains no transactions\n        LOG.warn(\"Latest log \" + latestLog + \" has no transactions. \" +\n            \"moving it aside and looking for previous log\");\n        latestLog.moveAsideEmptyFile();\n      } else {\n        return latestLog;\n      }\n    }\n    \n    LOG.info(\"No files in \" + fjm);\n    return null;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java",
      "extendedDetails": {}
    },
    "6ae2a0d048e133b43249c248a75a4d77d9abb80d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8249. Separate HdfsConstants into the client and the server side class. Contributed by Haohui Mai.\n",
      "commitDate": "02/05/15 10:03 AM",
      "commitName": "6ae2a0d048e133b43249c248a75a4d77d9abb80d",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "08/01/15 4:09 PM",
      "commitNameOld": "ae91b13a4b1896b893268253104f935c3078d345",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 113.7,
      "commitsBetweenForRepo": 1004,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,25 +1,25 @@\n   private synchronized EditLogFile scanStorageForLatestEdits() throws IOException {\n     if (!fjm.getStorageDirectory().getCurrentDir().exists()) {\n       return null;\n     }\n     \n     LOG.info(\"Scanning storage \" + fjm);\n     List\u003cEditLogFile\u003e files \u003d fjm.getLogFiles(0);\n     \n     while (!files.isEmpty()) {\n       EditLogFile latestLog \u003d files.remove(files.size() - 1);\n       latestLog.scanLog();\n       LOG.info(\"Latest log is \" + latestLog);\n-      if (latestLog.getLastTxId() \u003d\u003d HdfsConstants.INVALID_TXID) {\n+      if (latestLog.getLastTxId() \u003d\u003d HdfsServerConstants.INVALID_TXID) {\n         // the log contains no transactions\n         LOG.warn(\"Latest log \" + latestLog + \" has no transactions. \" +\n             \"moving it aside and looking for previous log\");\n         latestLog.moveAsideEmptyFile();\n       } else {\n         return latestLog;\n       }\n     }\n     \n     LOG.info(\"No files in \" + fjm);\n     return null;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized EditLogFile scanStorageForLatestEdits() throws IOException {\n    if (!fjm.getStorageDirectory().getCurrentDir().exists()) {\n      return null;\n    }\n    \n    LOG.info(\"Scanning storage \" + fjm);\n    List\u003cEditLogFile\u003e files \u003d fjm.getLogFiles(0);\n    \n    while (!files.isEmpty()) {\n      EditLogFile latestLog \u003d files.remove(files.size() - 1);\n      latestLog.scanLog();\n      LOG.info(\"Latest log is \" + latestLog);\n      if (latestLog.getLastTxId() \u003d\u003d HdfsServerConstants.INVALID_TXID) {\n        // the log contains no transactions\n        LOG.warn(\"Latest log \" + latestLog + \" has no transactions. \" +\n            \"moving it aside and looking for previous log\");\n        latestLog.moveAsideEmptyFile();\n      } else {\n        return latestLog;\n      }\n    }\n    \n    LOG.info(\"No files in \" + fjm);\n    return null;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java",
      "extendedDetails": {}
    },
    "9dab514b22f49322738935cfd915c2b4eba50b88": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6038. Allow JournalNode to handle editlog produced by new release with future layoutversion. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1579813 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/03/14 4:06 PM",
      "commitName": "9dab514b22f49322738935cfd915c2b4eba50b88",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "20/02/14 3:21 PM",
      "commitNameOld": "329c7051817c956bfc64661f4e1349b7009a2747",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 27.99,
      "commitsBetweenForRepo": 248,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,25 +1,25 @@\n   private synchronized EditLogFile scanStorageForLatestEdits() throws IOException {\n     if (!fjm.getStorageDirectory().getCurrentDir().exists()) {\n       return null;\n     }\n     \n     LOG.info(\"Scanning storage \" + fjm);\n     List\u003cEditLogFile\u003e files \u003d fjm.getLogFiles(0);\n     \n     while (!files.isEmpty()) {\n       EditLogFile latestLog \u003d files.remove(files.size() - 1);\n-      latestLog.validateLog();\n+      latestLog.scanLog();\n       LOG.info(\"Latest log is \" + latestLog);\n       if (latestLog.getLastTxId() \u003d\u003d HdfsConstants.INVALID_TXID) {\n         // the log contains no transactions\n         LOG.warn(\"Latest log \" + latestLog + \" has no transactions. \" +\n             \"moving it aside and looking for previous log\");\n         latestLog.moveAsideEmptyFile();\n       } else {\n         return latestLog;\n       }\n     }\n     \n     LOG.info(\"No files in \" + fjm);\n     return null;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized EditLogFile scanStorageForLatestEdits() throws IOException {\n    if (!fjm.getStorageDirectory().getCurrentDir().exists()) {\n      return null;\n    }\n    \n    LOG.info(\"Scanning storage \" + fjm);\n    List\u003cEditLogFile\u003e files \u003d fjm.getLogFiles(0);\n    \n    while (!files.isEmpty()) {\n      EditLogFile latestLog \u003d files.remove(files.size() - 1);\n      latestLog.scanLog();\n      LOG.info(\"Latest log is \" + latestLog);\n      if (latestLog.getLastTxId() \u003d\u003d HdfsConstants.INVALID_TXID) {\n        // the log contains no transactions\n        LOG.warn(\"Latest log \" + latestLog + \" has no transactions. \" +\n            \"moving it aside and looking for previous log\");\n        latestLog.moveAsideEmptyFile();\n      } else {\n        return latestLog;\n      }\n    }\n    \n    LOG.info(\"No files in \" + fjm);\n    return null;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java",
      "extendedDetails": {}
    },
    "60c20e559b8036410e2d9081b9c60d1e04e56253": {
      "type": "Ymultichange(Yrename,Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-3900. QJM: avoid validating log segments on log rolls. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1383041 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/09/12 11:53 AM",
      "commitName": "60c20e559b8036410e2d9081b9c60d1e04e56253",
      "commitAuthor": "Todd Lipcon",
      "subchanges": [
        {
          "type": "Yrename",
          "commitMessage": "HDFS-3900. QJM: avoid validating log segments on log rolls. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1383041 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "10/09/12 11:53 AM",
          "commitName": "60c20e559b8036410e2d9081b9c60d1e04e56253",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "10/09/12 11:51 AM",
          "commitNameOld": "ca4582222e89114e4c61d38fbf973a66d2867abf",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,23 +1,25 @@\n-  private synchronized void scanStorage() throws IOException {\n+  private synchronized EditLogFile scanStorageForLatestEdits() throws IOException {\n     if (!fjm.getStorageDirectory().getCurrentDir().exists()) {\n-      return;\n+      return null;\n     }\n+    \n     LOG.info(\"Scanning storage \" + fjm);\n     List\u003cEditLogFile\u003e files \u003d fjm.getLogFiles(0);\n-    curSegmentTxId \u003d HdfsConstants.INVALID_TXID;\n     \n     while (!files.isEmpty()) {\n       EditLogFile latestLog \u003d files.remove(files.size() - 1);\n       latestLog.validateLog();\n       LOG.info(\"Latest log is \" + latestLog);\n       if (latestLog.getLastTxId() \u003d\u003d HdfsConstants.INVALID_TXID) {\n         // the log contains no transactions\n         LOG.warn(\"Latest log \" + latestLog + \" has no transactions. \" +\n             \"moving it aside and looking for previous log\");\n         latestLog.moveAsideEmptyFile();\n       } else {\n-        curSegmentTxId \u003d latestLog.getFirstTxId();\n-        break;\n+        return latestLog;\n       }\n     }\n+    \n+    LOG.info(\"No files in \" + fjm);\n+    return null;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private synchronized EditLogFile scanStorageForLatestEdits() throws IOException {\n    if (!fjm.getStorageDirectory().getCurrentDir().exists()) {\n      return null;\n    }\n    \n    LOG.info(\"Scanning storage \" + fjm);\n    List\u003cEditLogFile\u003e files \u003d fjm.getLogFiles(0);\n    \n    while (!files.isEmpty()) {\n      EditLogFile latestLog \u003d files.remove(files.size() - 1);\n      latestLog.validateLog();\n      LOG.info(\"Latest log is \" + latestLog);\n      if (latestLog.getLastTxId() \u003d\u003d HdfsConstants.INVALID_TXID) {\n        // the log contains no transactions\n        LOG.warn(\"Latest log \" + latestLog + \" has no transactions. \" +\n            \"moving it aside and looking for previous log\");\n        latestLog.moveAsideEmptyFile();\n      } else {\n        return latestLog;\n      }\n    }\n    \n    LOG.info(\"No files in \" + fjm);\n    return null;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java",
          "extendedDetails": {
            "oldValue": "scanStorage",
            "newValue": "scanStorageForLatestEdits"
          }
        },
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-3900. QJM: avoid validating log segments on log rolls. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1383041 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "10/09/12 11:53 AM",
          "commitName": "60c20e559b8036410e2d9081b9c60d1e04e56253",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "10/09/12 11:51 AM",
          "commitNameOld": "ca4582222e89114e4c61d38fbf973a66d2867abf",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,23 +1,25 @@\n-  private synchronized void scanStorage() throws IOException {\n+  private synchronized EditLogFile scanStorageForLatestEdits() throws IOException {\n     if (!fjm.getStorageDirectory().getCurrentDir().exists()) {\n-      return;\n+      return null;\n     }\n+    \n     LOG.info(\"Scanning storage \" + fjm);\n     List\u003cEditLogFile\u003e files \u003d fjm.getLogFiles(0);\n-    curSegmentTxId \u003d HdfsConstants.INVALID_TXID;\n     \n     while (!files.isEmpty()) {\n       EditLogFile latestLog \u003d files.remove(files.size() - 1);\n       latestLog.validateLog();\n       LOG.info(\"Latest log is \" + latestLog);\n       if (latestLog.getLastTxId() \u003d\u003d HdfsConstants.INVALID_TXID) {\n         // the log contains no transactions\n         LOG.warn(\"Latest log \" + latestLog + \" has no transactions. \" +\n             \"moving it aside and looking for previous log\");\n         latestLog.moveAsideEmptyFile();\n       } else {\n-        curSegmentTxId \u003d latestLog.getFirstTxId();\n-        break;\n+        return latestLog;\n       }\n     }\n+    \n+    LOG.info(\"No files in \" + fjm);\n+    return null;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private synchronized EditLogFile scanStorageForLatestEdits() throws IOException {\n    if (!fjm.getStorageDirectory().getCurrentDir().exists()) {\n      return null;\n    }\n    \n    LOG.info(\"Scanning storage \" + fjm);\n    List\u003cEditLogFile\u003e files \u003d fjm.getLogFiles(0);\n    \n    while (!files.isEmpty()) {\n      EditLogFile latestLog \u003d files.remove(files.size() - 1);\n      latestLog.validateLog();\n      LOG.info(\"Latest log is \" + latestLog);\n      if (latestLog.getLastTxId() \u003d\u003d HdfsConstants.INVALID_TXID) {\n        // the log contains no transactions\n        LOG.warn(\"Latest log \" + latestLog + \" has no transactions. \" +\n            \"moving it aside and looking for previous log\");\n        latestLog.moveAsideEmptyFile();\n      } else {\n        return latestLog;\n      }\n    }\n    \n    LOG.info(\"No files in \" + fjm);\n    return null;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java",
          "extendedDetails": {
            "oldValue": "void",
            "newValue": "EditLogFile"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-3900. QJM: avoid validating log segments on log rolls. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1383041 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "10/09/12 11:53 AM",
          "commitName": "60c20e559b8036410e2d9081b9c60d1e04e56253",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "10/09/12 11:51 AM",
          "commitNameOld": "ca4582222e89114e4c61d38fbf973a66d2867abf",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,23 +1,25 @@\n-  private synchronized void scanStorage() throws IOException {\n+  private synchronized EditLogFile scanStorageForLatestEdits() throws IOException {\n     if (!fjm.getStorageDirectory().getCurrentDir().exists()) {\n-      return;\n+      return null;\n     }\n+    \n     LOG.info(\"Scanning storage \" + fjm);\n     List\u003cEditLogFile\u003e files \u003d fjm.getLogFiles(0);\n-    curSegmentTxId \u003d HdfsConstants.INVALID_TXID;\n     \n     while (!files.isEmpty()) {\n       EditLogFile latestLog \u003d files.remove(files.size() - 1);\n       latestLog.validateLog();\n       LOG.info(\"Latest log is \" + latestLog);\n       if (latestLog.getLastTxId() \u003d\u003d HdfsConstants.INVALID_TXID) {\n         // the log contains no transactions\n         LOG.warn(\"Latest log \" + latestLog + \" has no transactions. \" +\n             \"moving it aside and looking for previous log\");\n         latestLog.moveAsideEmptyFile();\n       } else {\n-        curSegmentTxId \u003d latestLog.getFirstTxId();\n-        break;\n+        return latestLog;\n       }\n     }\n+    \n+    LOG.info(\"No files in \" + fjm);\n+    return null;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private synchronized EditLogFile scanStorageForLatestEdits() throws IOException {\n    if (!fjm.getStorageDirectory().getCurrentDir().exists()) {\n      return null;\n    }\n    \n    LOG.info(\"Scanning storage \" + fjm);\n    List\u003cEditLogFile\u003e files \u003d fjm.getLogFiles(0);\n    \n    while (!files.isEmpty()) {\n      EditLogFile latestLog \u003d files.remove(files.size() - 1);\n      latestLog.validateLog();\n      LOG.info(\"Latest log is \" + latestLog);\n      if (latestLog.getLastTxId() \u003d\u003d HdfsConstants.INVALID_TXID) {\n        // the log contains no transactions\n        LOG.warn(\"Latest log \" + latestLog + \" has no transactions. \" +\n            \"moving it aside and looking for previous log\");\n        latestLog.moveAsideEmptyFile();\n      } else {\n        return latestLog;\n      }\n    }\n    \n    LOG.info(\"No files in \" + fjm);\n    return null;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java",
          "extendedDetails": {}
        }
      ]
    },
    "8021d9199f278345aca6211f318145342ad036f4": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3863. Track last \"committed\" txid in QJM. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1380976 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/09/12 9:13 PM",
      "commitName": "8021d9199f278345aca6211f318145342ad036f4",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "27/08/12 12:55 PM",
      "commitNameOld": "1e68d4726b225fb4a62eb8d79a3160dd03059ccb",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 8.35,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,23 @@\n   private synchronized void scanStorage() throws IOException {\n     if (!fjm.getStorageDirectory().getCurrentDir().exists()) {\n       return;\n     }\n     LOG.info(\"Scanning storage \" + fjm);\n     List\u003cEditLogFile\u003e files \u003d fjm.getLogFiles(0);\n-    if (files.isEmpty()) {\n-      curSegmentTxId \u003d HdfsConstants.INVALID_TXID;\n-      return;\n-    }\n+    curSegmentTxId \u003d HdfsConstants.INVALID_TXID;\n     \n-    EditLogFile latestLog \u003d files.get(files.size() - 1);\n-    latestLog.validateLog();\n-    LOG.info(\"Latest log is \" + latestLog);\n-    if (latestLog.getLastTxId() \u003d\u003d HdfsConstants.INVALID_TXID) {\n-      // the log contains no transactions\n-      LOG.warn(\"Latest log \" + latestLog + \" has no transactions. \" +\n-          \"moving it aside\");\n-      latestLog.moveAsideEmptyFile();\n-      curSegmentTxId \u003d HdfsConstants.INVALID_TXID;\n-    } else {\n-      curSegmentTxId \u003d latestLog.getFirstTxId();\n+    while (!files.isEmpty()) {\n+      EditLogFile latestLog \u003d files.remove(files.size() - 1);\n+      latestLog.validateLog();\n+      LOG.info(\"Latest log is \" + latestLog);\n+      if (latestLog.getLastTxId() \u003d\u003d HdfsConstants.INVALID_TXID) {\n+        // the log contains no transactions\n+        LOG.warn(\"Latest log \" + latestLog + \" has no transactions. \" +\n+            \"moving it aside and looking for previous log\");\n+        latestLog.moveAsideEmptyFile();\n+      } else {\n+        curSegmentTxId \u003d latestLog.getFirstTxId();\n+        break;\n+      }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void scanStorage() throws IOException {\n    if (!fjm.getStorageDirectory().getCurrentDir().exists()) {\n      return;\n    }\n    LOG.info(\"Scanning storage \" + fjm);\n    List\u003cEditLogFile\u003e files \u003d fjm.getLogFiles(0);\n    curSegmentTxId \u003d HdfsConstants.INVALID_TXID;\n    \n    while (!files.isEmpty()) {\n      EditLogFile latestLog \u003d files.remove(files.size() - 1);\n      latestLog.validateLog();\n      LOG.info(\"Latest log is \" + latestLog);\n      if (latestLog.getLastTxId() \u003d\u003d HdfsConstants.INVALID_TXID) {\n        // the log contains no transactions\n        LOG.warn(\"Latest log \" + latestLog + \" has no transactions. \" +\n            \"moving it aside and looking for previous log\");\n        latestLog.moveAsideEmptyFile();\n      } else {\n        curSegmentTxId \u003d latestLog.getFirstTxId();\n        break;\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java",
      "extendedDetails": {}
    },
    "c95a1674b61ef2a6963dc64604986ef90a8c636d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3799. QJM: handle empty log segments during recovery. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1373183 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/08/12 5:57 PM",
      "commitName": "c95a1674b61ef2a6963dc64604986ef90a8c636d",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "14/08/12 5:54 PM",
      "commitNameOld": "4a9b3c693def87579298fb59b7df0b8892a3508e",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,24 @@\n   private synchronized void scanStorage() throws IOException {\n     if (!fjm.getStorageDirectory().getCurrentDir().exists()) {\n       return;\n     }\n     LOG.info(\"Scanning storage \" + fjm);\n     List\u003cEditLogFile\u003e files \u003d fjm.getLogFiles(0);\n-    if (!files.isEmpty()) {\n-      EditLogFile latestLog \u003d files.get(files.size() - 1);\n-      LOG.info(\"Latest log is \" + latestLog);\n+    if (files.isEmpty()) {\n+      curSegmentTxId \u003d HdfsConstants.INVALID_TXID;\n+      return;\n+    }\n+    \n+    EditLogFile latestLog \u003d files.get(files.size() - 1);\n+    latestLog.validateLog();\n+    LOG.info(\"Latest log is \" + latestLog);\n+    if (latestLog.getLastTxId() \u003d\u003d HdfsConstants.INVALID_TXID) {\n+      // the log contains no transactions\n+      LOG.warn(\"Latest log \" + latestLog + \" has no transactions. \" +\n+          \"moving it aside\");\n+      latestLog.moveAsideEmptyFile();\n+      curSegmentTxId \u003d HdfsConstants.INVALID_TXID;\n+    } else {\n       curSegmentTxId \u003d latestLog.getFirstTxId();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void scanStorage() throws IOException {\n    if (!fjm.getStorageDirectory().getCurrentDir().exists()) {\n      return;\n    }\n    LOG.info(\"Scanning storage \" + fjm);\n    List\u003cEditLogFile\u003e files \u003d fjm.getLogFiles(0);\n    if (files.isEmpty()) {\n      curSegmentTxId \u003d HdfsConstants.INVALID_TXID;\n      return;\n    }\n    \n    EditLogFile latestLog \u003d files.get(files.size() - 1);\n    latestLog.validateLog();\n    LOG.info(\"Latest log is \" + latestLog);\n    if (latestLog.getLastTxId() \u003d\u003d HdfsConstants.INVALID_TXID) {\n      // the log contains no transactions\n      LOG.warn(\"Latest log \" + latestLog + \" has no transactions. \" +\n          \"moving it aside\");\n      latestLog.moveAsideEmptyFile();\n      curSegmentTxId \u003d HdfsConstants.INVALID_TXID;\n    } else {\n      curSegmentTxId \u003d latestLog.getFirstTxId();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java",
      "extendedDetails": {}
    },
    "74d4573a23db5586c6e47ff2277aa7c35237da34": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-3077. Quorum-based protocol for reading and writing edit logs. Contributed by Todd Lipcon based on initial work from Brandon Li and Hari Mankude.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1363596 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/07/12 5:25 PM",
      "commitName": "74d4573a23db5586c6e47ff2277aa7c35237da34",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,12 @@\n+  private synchronized void scanStorage() throws IOException {\n+    if (!fjm.getStorageDirectory().getCurrentDir().exists()) {\n+      return;\n+    }\n+    LOG.info(\"Scanning storage \" + fjm);\n+    List\u003cEditLogFile\u003e files \u003d fjm.getLogFiles(0);\n+    if (!files.isEmpty()) {\n+      EditLogFile latestLog \u003d files.get(files.size() - 1);\n+      LOG.info(\"Latest log is \" + latestLog);\n+      curSegmentTxId \u003d latestLog.getFirstTxId();\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void scanStorage() throws IOException {\n    if (!fjm.getStorageDirectory().getCurrentDir().exists()) {\n      return;\n    }\n    LOG.info(\"Scanning storage \" + fjm);\n    List\u003cEditLogFile\u003e files \u003d fjm.getLogFiles(0);\n    if (!files.isEmpty()) {\n      EditLogFile latestLog \u003d files.get(files.size() - 1);\n      LOG.info(\"Latest log is \" + latestLog);\n      curSegmentTxId \u003d latestLog.getFirstTxId();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java"
    }
  }
}