{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "AuditLogDirectParser.java",
  "functionName": "initialize",
  "functionId": "initialize___conf-Configuration",
  "sourceFilePath": "hadoop-tools/hadoop-dynamometer/hadoop-dynamometer-workload/src/main/java/org/apache/hadoop/tools/dynamometer/workloadgenerator/audit/AuditLogDirectParser.java",
  "functionStartLine": 93,
  "functionEndLine": 112,
  "numCommitsSeen": 4,
  "timeTaken": 377,
  "changeHistory": [
    "ab0b180ddb5d0775a2452d5eeb7badd252aadb91"
  ],
  "changeHistoryShort": {
    "ab0b180ddb5d0775a2452d5eeb7badd252aadb91": "Yintroduced"
  },
  "changeHistoryDetails": {
    "ab0b180ddb5d0775a2452d5eeb7badd252aadb91": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-12345 Add Dynamometer to hadoop-tools, a tool for scale testing the HDFS NameNode with real metadata and workloads. Contributed by Erik Krogen.\n",
      "commitDate": "25/06/19 8:07 AM",
      "commitName": "ab0b180ddb5d0775a2452d5eeb7badd252aadb91",
      "commitAuthor": "Erik Krogen",
      "diff": "@@ -0,0 +1,20 @@\n+  public void initialize(Configuration conf) throws IOException {\n+    startTimestamp \u003d conf.getLong(AUDIT_START_TIMESTAMP_KEY, -1);\n+    if (startTimestamp \u003c 0) {\n+      throw new IOException(\n+          \"Invalid or missing audit start timestamp: \" + startTimestamp);\n+    }\n+    dateFormat \u003d new SimpleDateFormat(conf.get(AUDIT_LOG_DATE_FORMAT_KEY,\n+        AUDIT_LOG_DATE_FORMAT_DEFAULT));\n+    String timeZoneString \u003d conf.get(AUDIT_LOG_DATE_TIME_ZONE_KEY,\n+        AUDIT_LOG_DATE_TIME_ZONE_DEFAULT);\n+    dateFormat.setTimeZone(TimeZone.getTimeZone(timeZoneString));\n+    String logLineParseRegexString \u003d\n+        conf.get(AUDIT_LOG_PARSE_REGEX_KEY, AUDIT_LOG_PARSE_REGEX_DEFAULT);\n+    if (!logLineParseRegexString.contains(\"(?\u003ctimestamp\u003e\")\n+        \u0026\u0026 logLineParseRegexString.contains(\"(?\u003cmessage\u003e\")) {\n+      throw new IllegalArgumentException(\"Must configure regex with named \"\n+          + \"capture groups \u0027timestamp\u0027 and \u0027message\u0027\");\n+    }\n+    logLineParseRegex \u003d Pattern.compile(logLineParseRegexString);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void initialize(Configuration conf) throws IOException {\n    startTimestamp \u003d conf.getLong(AUDIT_START_TIMESTAMP_KEY, -1);\n    if (startTimestamp \u003c 0) {\n      throw new IOException(\n          \"Invalid or missing audit start timestamp: \" + startTimestamp);\n    }\n    dateFormat \u003d new SimpleDateFormat(conf.get(AUDIT_LOG_DATE_FORMAT_KEY,\n        AUDIT_LOG_DATE_FORMAT_DEFAULT));\n    String timeZoneString \u003d conf.get(AUDIT_LOG_DATE_TIME_ZONE_KEY,\n        AUDIT_LOG_DATE_TIME_ZONE_DEFAULT);\n    dateFormat.setTimeZone(TimeZone.getTimeZone(timeZoneString));\n    String logLineParseRegexString \u003d\n        conf.get(AUDIT_LOG_PARSE_REGEX_KEY, AUDIT_LOG_PARSE_REGEX_DEFAULT);\n    if (!logLineParseRegexString.contains(\"(?\u003ctimestamp\u003e\")\n        \u0026\u0026 logLineParseRegexString.contains(\"(?\u003cmessage\u003e\")) {\n      throw new IllegalArgumentException(\"Must configure regex with named \"\n          + \"capture groups \u0027timestamp\u0027 and \u0027message\u0027\");\n    }\n    logLineParseRegex \u003d Pattern.compile(logLineParseRegexString);\n  }",
      "path": "hadoop-tools/hadoop-dynamometer/hadoop-dynamometer-workload/src/main/java/org/apache/hadoop/tools/dynamometer/workloadgenerator/audit/AuditLogDirectParser.java"
    }
  }
}