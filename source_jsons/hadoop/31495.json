{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "GenericEntityReader.java",
  "functionName": "augmentParams",
  "functionId": "augmentParams___hbaseConf-Configuration__conn-Connection",
  "sourceFilePath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-client/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/reader/GenericEntityReader.java",
  "functionStartLine": 425,
  "functionEndLine": 434,
  "numCommitsSeen": 27,
  "timeTaken": 4663,
  "changeHistory": [
    "9af30d46c6e82332a8eda20cb3eb5f987e25e7a2",
    "4481561e4a3433197dd8e73f38856eef84f0fd03",
    "b01514f65bc6090a50a583f67d1ecb5d74b6d276",
    "892b193bd77c15932b4c084c1d525b7017def0d4",
    "c2efdc415a13496da43a9a8d13c73d88ca8565a1",
    "9cb1287e9b8425f91de925f411c3c2a8fa9fe2a3",
    "6934b05c7117a12286fb2ba7a47f75e227cacb22",
    "88f02941144824187b70fa2aaf0c6d90bcb77d8f",
    "8ef546c1ee9fce0b171813547253374d268566ba",
    "1f710484e5b8ab4d5c67379c012004e8a4242d15",
    "09649005ca269f249f98384ecd1abf9fb6d5b0c1",
    "10fa6da7d8a6013698767c6136ae20f0e04415e9"
  ],
  "changeHistoryShort": {
    "9af30d46c6e82332a8eda20cb3eb5f987e25e7a2": "Yfilerename",
    "4481561e4a3433197dd8e73f38856eef84f0fd03": "Ybodychange",
    "b01514f65bc6090a50a583f67d1ecb5d74b6d276": "Yfilerename",
    "892b193bd77c15932b4c084c1d525b7017def0d4": "Ybodychange",
    "c2efdc415a13496da43a9a8d13c73d88ca8565a1": "Ybodychange",
    "9cb1287e9b8425f91de925f411c3c2a8fa9fe2a3": "Ybodychange",
    "6934b05c7117a12286fb2ba7a47f75e227cacb22": "Ybodychange",
    "88f02941144824187b70fa2aaf0c6d90bcb77d8f": "Yfilerename",
    "8ef546c1ee9fce0b171813547253374d268566ba": "Ybodychange",
    "1f710484e5b8ab4d5c67379c012004e8a4242d15": "Ybodychange",
    "09649005ca269f249f98384ecd1abf9fb6d5b0c1": "Ybodychange",
    "10fa6da7d8a6013698767c6136ae20f0e04415e9": "Yintroduced"
  },
  "changeHistoryDetails": {
    "9af30d46c6e82332a8eda20cb3eb5f987e25e7a2": {
      "type": "Yfilerename",
      "commitMessage": "YARN-7919. Refactor timelineservice-hbase module into submodules. Contributed by Haibo Chen.\n",
      "commitDate": "17/02/18 7:00 AM",
      "commitName": "9af30d46c6e82332a8eda20cb3eb5f987e25e7a2",
      "commitAuthor": "Rohith Sharma K S",
      "commitDateOld": "17/02/18 3:24 AM",
      "commitNameOld": "a1e56a62863d8d494af309ec5f476c4b7e4d5ef9",
      "commitAuthorOld": "Arun Suresh",
      "daysBetweenCommits": 0.15,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  protected void augmentParams(Configuration hbaseConf, Connection conn)\n      throws IOException {\n    defaultAugmentParams(hbaseConf, conn);\n    // Add configs/metrics to fields to retrieve if confsToRetrieve and/or\n    // metricsToRetrieve are specified.\n    getDataToRetrieve().addFieldsBasedOnConfsAndMetricsToRetrieve();\n    if (!isSingleEntityRead()) {\n      createFiltersIfNull();\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-client/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/reader/GenericEntityReader.java",
      "extendedDetails": {
        "oldPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/reader/GenericEntityReader.java",
        "newPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-client/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/reader/GenericEntityReader.java"
      }
    },
    "4481561e4a3433197dd8e73f38856eef84f0fd03": {
      "type": "Ybodychange",
      "commitMessage": "YARN-5739. Provide timeline reader API to list available timeline entity types for one application. Contributed by Li Lu.\n",
      "commitDate": "29/08/17 10:59 PM",
      "commitName": "4481561e4a3433197dd8e73f38856eef84f0fd03",
      "commitAuthor": "Sangjin Lee",
      "commitDateOld": "29/08/17 10:59 PM",
      "commitNameOld": "05ff04439e2edeef0460bc9e21034535b8b6eb9e",
      "commitAuthorOld": "Sangjin Lee",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,10 @@\n   protected void augmentParams(Configuration hbaseConf, Connection conn)\n       throws IOException {\n-    TimelineReaderContext context \u003d getContext();\n-    // In reality all three should be null or neither should be null\n-    if (context.getFlowName() \u003d\u003d null || context.getFlowRunId() \u003d\u003d null\n-        || context.getUserId() \u003d\u003d null) {\n-      // Get flow context information from AppToFlow table.\n-      AppToFlowRowKey appToFlowRowKey \u003d\n-          new AppToFlowRowKey(context.getClusterId(), context.getAppId());\n-      FlowContext flowContext \u003d\n-          lookupFlowContext(appToFlowRowKey, hbaseConf, conn);\n-      context.setFlowName(flowContext.flowName);\n-      context.setFlowRunId(flowContext.flowRunId);\n-      context.setUserId(flowContext.userId);\n-    }\n+    defaultAugmentParams(hbaseConf, conn);\n     // Add configs/metrics to fields to retrieve if confsToRetrieve and/or\n     // metricsToRetrieve are specified.\n     getDataToRetrieve().addFieldsBasedOnConfsAndMetricsToRetrieve();\n     if (!isSingleEntityRead()) {\n       createFiltersIfNull();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void augmentParams(Configuration hbaseConf, Connection conn)\n      throws IOException {\n    defaultAugmentParams(hbaseConf, conn);\n    // Add configs/metrics to fields to retrieve if confsToRetrieve and/or\n    // metricsToRetrieve are specified.\n    getDataToRetrieve().addFieldsBasedOnConfsAndMetricsToRetrieve();\n    if (!isSingleEntityRead()) {\n      createFiltersIfNull();\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/reader/GenericEntityReader.java",
      "extendedDetails": {}
    },
    "b01514f65bc6090a50a583f67d1ecb5d74b6d276": {
      "type": "Yfilerename",
      "commitMessage": "YARN-5928. Move ATSv2 HBase backend code into a new module that is only dependent at runtime by yarn servers. Contributed by Haibo Chen.\n",
      "commitDate": "19/01/17 8:52 PM",
      "commitName": "b01514f65bc6090a50a583f67d1ecb5d74b6d276",
      "commitAuthor": "Sangjin Lee",
      "commitDateOld": "19/01/17 5:32 PM",
      "commitNameOld": "60865c8ea08053f3d6ac23f81c3376a3de3ca996",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 0.14,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  protected void augmentParams(Configuration hbaseConf, Connection conn)\n      throws IOException {\n    TimelineReaderContext context \u003d getContext();\n    // In reality all three should be null or neither should be null\n    if (context.getFlowName() \u003d\u003d null || context.getFlowRunId() \u003d\u003d null\n        || context.getUserId() \u003d\u003d null) {\n      // Get flow context information from AppToFlow table.\n      AppToFlowRowKey appToFlowRowKey \u003d\n          new AppToFlowRowKey(context.getClusterId(), context.getAppId());\n      FlowContext flowContext \u003d\n          lookupFlowContext(appToFlowRowKey, hbaseConf, conn);\n      context.setFlowName(flowContext.flowName);\n      context.setFlowRunId(flowContext.flowRunId);\n      context.setUserId(flowContext.userId);\n    }\n    // Add configs/metrics to fields to retrieve if confsToRetrieve and/or\n    // metricsToRetrieve are specified.\n    getDataToRetrieve().addFieldsBasedOnConfsAndMetricsToRetrieve();\n    if (!isSingleEntityRead()) {\n      createFiltersIfNull();\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/reader/GenericEntityReader.java",
      "extendedDetails": {
        "oldPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/reader/GenericEntityReader.java",
        "newPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/reader/GenericEntityReader.java"
      }
    },
    "892b193bd77c15932b4c084c1d525b7017def0d4": {
      "type": "Ybodychange",
      "commitMessage": "YARN-5170. Eliminate singleton converters and static method access. (Joep Rottinghuis via Varun Saxena)\n",
      "commitDate": "10/07/16 8:46 AM",
      "commitName": "892b193bd77c15932b4c084c1d525b7017def0d4",
      "commitAuthor": "Varun Saxena",
      "commitDateOld": "10/07/16 8:46 AM",
      "commitNameOld": "c81a2e1d197b9995103797348cb5cc4bcf9a015b",
      "commitAuthorOld": "Sangjin Lee",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,22 @@\n   protected void augmentParams(Configuration hbaseConf, Connection conn)\n       throws IOException {\n     TimelineReaderContext context \u003d getContext();\n     // In reality all three should be null or neither should be null\n-    if (context.getFlowName() \u003d\u003d null || context.getFlowRunId() \u003d\u003d null ||\n-        context.getUserId() \u003d\u003d null) {\n+    if (context.getFlowName() \u003d\u003d null || context.getFlowRunId() \u003d\u003d null\n+        || context.getUserId() \u003d\u003d null) {\n       // Get flow context information from AppToFlow table.\n-      FlowContext flowContext \u003d lookupFlowContext(\n-          context.getClusterId(), context.getAppId(), hbaseConf, conn);\n+      AppToFlowRowKey appToFlowRowKey \u003d\n+          new AppToFlowRowKey(context.getClusterId(), context.getAppId());\n+      FlowContext flowContext \u003d\n+          lookupFlowContext(appToFlowRowKey, hbaseConf, conn);\n       context.setFlowName(flowContext.flowName);\n       context.setFlowRunId(flowContext.flowRunId);\n       context.setUserId(flowContext.userId);\n     }\n     // Add configs/metrics to fields to retrieve if confsToRetrieve and/or\n     // metricsToRetrieve are specified.\n     getDataToRetrieve().addFieldsBasedOnConfsAndMetricsToRetrieve();\n     if (!isSingleEntityRead()) {\n       createFiltersIfNull();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void augmentParams(Configuration hbaseConf, Connection conn)\n      throws IOException {\n    TimelineReaderContext context \u003d getContext();\n    // In reality all three should be null or neither should be null\n    if (context.getFlowName() \u003d\u003d null || context.getFlowRunId() \u003d\u003d null\n        || context.getUserId() \u003d\u003d null) {\n      // Get flow context information from AppToFlow table.\n      AppToFlowRowKey appToFlowRowKey \u003d\n          new AppToFlowRowKey(context.getClusterId(), context.getAppId());\n      FlowContext flowContext \u003d\n          lookupFlowContext(appToFlowRowKey, hbaseConf, conn);\n      context.setFlowName(flowContext.flowName);\n      context.setFlowRunId(flowContext.flowRunId);\n      context.setUserId(flowContext.userId);\n    }\n    // Add configs/metrics to fields to retrieve if confsToRetrieve and/or\n    // metricsToRetrieve are specified.\n    getDataToRetrieve().addFieldsBasedOnConfsAndMetricsToRetrieve();\n    if (!isSingleEntityRead()) {\n      createFiltersIfNull();\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/reader/GenericEntityReader.java",
      "extendedDetails": {}
    },
    "c2efdc415a13496da43a9a8d13c73d88ca8565a1": {
      "type": "Ybodychange",
      "commitMessage": "YARN-3863. Support complex filters in TimelineReader (Varun Saxena via sjlee)\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "c2efdc415a13496da43a9a8d13c73d88ca8565a1",
      "commitAuthor": "Sangjin Lee",
      "commitDateOld": "10/07/16 8:45 AM",
      "commitNameOld": "960af7d4717b8a8949d0b2e43949e7daab45aa88",
      "commitAuthorOld": "Sangjin Lee",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 8,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,20 @@\n   protected void augmentParams(Configuration hbaseConf, Connection conn)\n       throws IOException {\n     TimelineReaderContext context \u003d getContext();\n     // In reality all three should be null or neither should be null\n     if (context.getFlowName() \u003d\u003d null || context.getFlowRunId() \u003d\u003d null ||\n         context.getUserId() \u003d\u003d null) {\n+      // Get flow context information from AppToFlow table.\n       FlowContext flowContext \u003d lookupFlowContext(\n           context.getClusterId(), context.getAppId(), hbaseConf, conn);\n       context.setFlowName(flowContext.flowName);\n       context.setFlowRunId(flowContext.flowRunId);\n       context.setUserId(flowContext.userId);\n     }\n+    // Add configs/metrics to fields to retrieve if confsToRetrieve and/or\n+    // metricsToRetrieve are specified.\n     getDataToRetrieve().addFieldsBasedOnConfsAndMetricsToRetrieve();\n+    if (!isSingleEntityRead()) {\n+      createFiltersIfNull();\n+    }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void augmentParams(Configuration hbaseConf, Connection conn)\n      throws IOException {\n    TimelineReaderContext context \u003d getContext();\n    // In reality all three should be null or neither should be null\n    if (context.getFlowName() \u003d\u003d null || context.getFlowRunId() \u003d\u003d null ||\n        context.getUserId() \u003d\u003d null) {\n      // Get flow context information from AppToFlow table.\n      FlowContext flowContext \u003d lookupFlowContext(\n          context.getClusterId(), context.getAppId(), hbaseConf, conn);\n      context.setFlowName(flowContext.flowName);\n      context.setFlowRunId(flowContext.flowRunId);\n      context.setUserId(flowContext.userId);\n    }\n    // Add configs/metrics to fields to retrieve if confsToRetrieve and/or\n    // metricsToRetrieve are specified.\n    getDataToRetrieve().addFieldsBasedOnConfsAndMetricsToRetrieve();\n    if (!isSingleEntityRead()) {\n      createFiltersIfNull();\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/reader/GenericEntityReader.java",
      "extendedDetails": {}
    },
    "9cb1287e9b8425f91de925f411c3c2a8fa9fe2a3": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4446. Refactor reader API for better extensibility (Varun Saxena via sjlee)\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "9cb1287e9b8425f91de925f411c3c2a8fa9fe2a3",
      "commitAuthor": "Sangjin Lee",
      "commitDateOld": "10/07/16 8:45 AM",
      "commitNameOld": "9d40d9d34ce3b88e868ae91fcc09377107c094c7",
      "commitAuthorOld": "Li Lu",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,34 +1,14 @@\n   protected void augmentParams(Configuration hbaseConf, Connection conn)\n       throws IOException {\n+    TimelineReaderContext context \u003d getContext();\n     // In reality all three should be null or neither should be null\n-    if (flowName \u003d\u003d null || flowRunId \u003d\u003d null || userId \u003d\u003d null) {\n-      FlowContext context \u003d\n-          lookupFlowContext(clusterId, appId, hbaseConf, conn);\n-      flowName \u003d context.flowName;\n-      flowRunId \u003d context.flowRunId;\n-      userId \u003d context.userId;\n+    if (context.getFlowName() \u003d\u003d null || context.getFlowRunId() \u003d\u003d null ||\n+        context.getUserId() \u003d\u003d null) {\n+      FlowContext flowContext \u003d lookupFlowContext(\n+          context.getClusterId(), context.getAppId(), hbaseConf, conn);\n+      context.setFlowName(flowContext.flowName);\n+      context.setFlowRunId(flowContext.flowRunId);\n+      context.setUserId(flowContext.userId);\n     }\n-    if (fieldsToRetrieve \u003d\u003d null) {\n-      fieldsToRetrieve \u003d EnumSet.noneOf(Field.class);\n-    }\n-    if (!fieldsToRetrieve.contains(Field.CONFIGS) \u0026\u0026\n-        confsToRetrieve !\u003d null \u0026\u0026 !confsToRetrieve.getFilterList().isEmpty()) {\n-      fieldsToRetrieve.add(Field.CONFIGS);\n-    }\n-    if (!fieldsToRetrieve.contains(Field.METRICS) \u0026\u0026\n-        metricsToRetrieve !\u003d null \u0026\u0026\n-        !metricsToRetrieve.getFilterList().isEmpty()) {\n-      fieldsToRetrieve.add(Field.METRICS);\n-    }\n-    if (!singleEntityRead) {\n-      if (limit \u003d\u003d null || limit \u003c 0) {\n-        limit \u003d TimelineReader.DEFAULT_LIMIT;\n-      }\n-      if (createdTimeBegin \u003d\u003d null) {\n-        createdTimeBegin \u003d DEFAULT_BEGIN_TIME;\n-      }\n-      if (createdTimeEnd \u003d\u003d null) {\n-        createdTimeEnd \u003d DEFAULT_END_TIME;\n-      }\n-    }\n+    getDataToRetrieve().addFieldsBasedOnConfsAndMetricsToRetrieve();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void augmentParams(Configuration hbaseConf, Connection conn)\n      throws IOException {\n    TimelineReaderContext context \u003d getContext();\n    // In reality all three should be null or neither should be null\n    if (context.getFlowName() \u003d\u003d null || context.getFlowRunId() \u003d\u003d null ||\n        context.getUserId() \u003d\u003d null) {\n      FlowContext flowContext \u003d lookupFlowContext(\n          context.getClusterId(), context.getAppId(), hbaseConf, conn);\n      context.setFlowName(flowContext.flowName);\n      context.setFlowRunId(flowContext.flowRunId);\n      context.setUserId(flowContext.userId);\n    }\n    getDataToRetrieve().addFieldsBasedOnConfsAndMetricsToRetrieve();\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/reader/GenericEntityReader.java",
      "extendedDetails": {}
    },
    "6934b05c7117a12286fb2ba7a47f75e227cacb22": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4238. createdTime and modifiedTime is not reported while publishing entities to ATSv2. (Varun Saxena via Naganarasimha G R)\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "6934b05c7117a12286fb2ba7a47f75e227cacb22",
      "commitAuthor": "Naganarasimha",
      "commitDateOld": "10/07/16 8:45 AM",
      "commitNameOld": "88f02941144824187b70fa2aaf0c6d90bcb77d8f",
      "commitAuthorOld": "Li Lu",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,40 +1,34 @@\n   protected void augmentParams(Configuration hbaseConf, Connection conn)\n       throws IOException {\n     // In reality all three should be null or neither should be null\n     if (flowName \u003d\u003d null || flowRunId \u003d\u003d null || userId \u003d\u003d null) {\n       FlowContext context \u003d\n           lookupFlowContext(clusterId, appId, hbaseConf, conn);\n       flowName \u003d context.flowName;\n       flowRunId \u003d context.flowRunId;\n       userId \u003d context.userId;\n     }\n     if (fieldsToRetrieve \u003d\u003d null) {\n       fieldsToRetrieve \u003d EnumSet.noneOf(Field.class);\n     }\n     if (!fieldsToRetrieve.contains(Field.CONFIGS) \u0026\u0026\n         confsToRetrieve !\u003d null \u0026\u0026 !confsToRetrieve.getFilterList().isEmpty()) {\n       fieldsToRetrieve.add(Field.CONFIGS);\n     }\n     if (!fieldsToRetrieve.contains(Field.METRICS) \u0026\u0026\n         metricsToRetrieve !\u003d null \u0026\u0026\n         !metricsToRetrieve.getFilterList().isEmpty()) {\n       fieldsToRetrieve.add(Field.METRICS);\n     }\n     if (!singleEntityRead) {\n       if (limit \u003d\u003d null || limit \u003c 0) {\n         limit \u003d TimelineReader.DEFAULT_LIMIT;\n       }\n       if (createdTimeBegin \u003d\u003d null) {\n         createdTimeBegin \u003d DEFAULT_BEGIN_TIME;\n       }\n       if (createdTimeEnd \u003d\u003d null) {\n         createdTimeEnd \u003d DEFAULT_END_TIME;\n       }\n-      if (modifiedTimeBegin \u003d\u003d null) {\n-        modifiedTimeBegin \u003d DEFAULT_BEGIN_TIME;\n-      }\n-      if (modifiedTimeEnd \u003d\u003d null) {\n-        modifiedTimeEnd \u003d DEFAULT_END_TIME;\n-      }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void augmentParams(Configuration hbaseConf, Connection conn)\n      throws IOException {\n    // In reality all three should be null or neither should be null\n    if (flowName \u003d\u003d null || flowRunId \u003d\u003d null || userId \u003d\u003d null) {\n      FlowContext context \u003d\n          lookupFlowContext(clusterId, appId, hbaseConf, conn);\n      flowName \u003d context.flowName;\n      flowRunId \u003d context.flowRunId;\n      userId \u003d context.userId;\n    }\n    if (fieldsToRetrieve \u003d\u003d null) {\n      fieldsToRetrieve \u003d EnumSet.noneOf(Field.class);\n    }\n    if (!fieldsToRetrieve.contains(Field.CONFIGS) \u0026\u0026\n        confsToRetrieve !\u003d null \u0026\u0026 !confsToRetrieve.getFilterList().isEmpty()) {\n      fieldsToRetrieve.add(Field.CONFIGS);\n    }\n    if (!fieldsToRetrieve.contains(Field.METRICS) \u0026\u0026\n        metricsToRetrieve !\u003d null \u0026\u0026\n        !metricsToRetrieve.getFilterList().isEmpty()) {\n      fieldsToRetrieve.add(Field.METRICS);\n    }\n    if (!singleEntityRead) {\n      if (limit \u003d\u003d null || limit \u003c 0) {\n        limit \u003d TimelineReader.DEFAULT_LIMIT;\n      }\n      if (createdTimeBegin \u003d\u003d null) {\n        createdTimeBegin \u003d DEFAULT_BEGIN_TIME;\n      }\n      if (createdTimeEnd \u003d\u003d null) {\n        createdTimeEnd \u003d DEFAULT_END_TIME;\n      }\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/reader/GenericEntityReader.java",
      "extendedDetails": {}
    },
    "88f02941144824187b70fa2aaf0c6d90bcb77d8f": {
      "type": "Yfilerename",
      "commitMessage": "YARN-4200. Refactor reader classes in storage to nest under hbase\nspecific package name. Contributed by Li Lu.\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "88f02941144824187b70fa2aaf0c6d90bcb77d8f",
      "commitAuthor": "Li Lu",
      "commitDateOld": "10/07/16 8:45 AM",
      "commitNameOld": "cc16683cefe2611cf4de7819496aa54854f5394c",
      "commitAuthorOld": "Sangjin Lee",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  protected void augmentParams(Configuration hbaseConf, Connection conn)\n      throws IOException {\n    // In reality all three should be null or neither should be null\n    if (flowName \u003d\u003d null || flowRunId \u003d\u003d null || userId \u003d\u003d null) {\n      FlowContext context \u003d\n          lookupFlowContext(clusterId, appId, hbaseConf, conn);\n      flowName \u003d context.flowName;\n      flowRunId \u003d context.flowRunId;\n      userId \u003d context.userId;\n    }\n    if (fieldsToRetrieve \u003d\u003d null) {\n      fieldsToRetrieve \u003d EnumSet.noneOf(Field.class);\n    }\n    if (!fieldsToRetrieve.contains(Field.CONFIGS) \u0026\u0026\n        confsToRetrieve !\u003d null \u0026\u0026 !confsToRetrieve.getFilterList().isEmpty()) {\n      fieldsToRetrieve.add(Field.CONFIGS);\n    }\n    if (!fieldsToRetrieve.contains(Field.METRICS) \u0026\u0026\n        metricsToRetrieve !\u003d null \u0026\u0026\n        !metricsToRetrieve.getFilterList().isEmpty()) {\n      fieldsToRetrieve.add(Field.METRICS);\n    }\n    if (!singleEntityRead) {\n      if (limit \u003d\u003d null || limit \u003c 0) {\n        limit \u003d TimelineReader.DEFAULT_LIMIT;\n      }\n      if (createdTimeBegin \u003d\u003d null) {\n        createdTimeBegin \u003d DEFAULT_BEGIN_TIME;\n      }\n      if (createdTimeEnd \u003d\u003d null) {\n        createdTimeEnd \u003d DEFAULT_END_TIME;\n      }\n      if (modifiedTimeBegin \u003d\u003d null) {\n        modifiedTimeBegin \u003d DEFAULT_BEGIN_TIME;\n      }\n      if (modifiedTimeEnd \u003d\u003d null) {\n        modifiedTimeEnd \u003d DEFAULT_END_TIME;\n      }\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/reader/GenericEntityReader.java",
      "extendedDetails": {
        "oldPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/GenericEntityReader.java",
        "newPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/reader/GenericEntityReader.java"
      }
    },
    "8ef546c1ee9fce0b171813547253374d268566ba": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4445. Unify the term flowId and flowName in timeline v2 codebase.\nContributed by Zhan Zhang.\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "8ef546c1ee9fce0b171813547253374d268566ba",
      "commitAuthor": "Li Lu",
      "commitDateOld": "10/07/16 8:45 AM",
      "commitNameOld": "1f710484e5b8ab4d5c67379c012004e8a4242d15",
      "commitAuthorOld": "Sangjin Lee",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 6,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,40 +1,40 @@\n   protected void augmentParams(Configuration hbaseConf, Connection conn)\n       throws IOException {\n     // In reality all three should be null or neither should be null\n-    if (flowId \u003d\u003d null || flowRunId \u003d\u003d null || userId \u003d\u003d null) {\n+    if (flowName \u003d\u003d null || flowRunId \u003d\u003d null || userId \u003d\u003d null) {\n       FlowContext context \u003d\n           lookupFlowContext(clusterId, appId, hbaseConf, conn);\n-      flowId \u003d context.flowId;\n+      flowName \u003d context.flowName;\n       flowRunId \u003d context.flowRunId;\n       userId \u003d context.userId;\n     }\n     if (fieldsToRetrieve \u003d\u003d null) {\n       fieldsToRetrieve \u003d EnumSet.noneOf(Field.class);\n     }\n     if (!fieldsToRetrieve.contains(Field.CONFIGS) \u0026\u0026\n         confsToRetrieve !\u003d null \u0026\u0026 !confsToRetrieve.getFilterList().isEmpty()) {\n       fieldsToRetrieve.add(Field.CONFIGS);\n     }\n     if (!fieldsToRetrieve.contains(Field.METRICS) \u0026\u0026\n         metricsToRetrieve !\u003d null \u0026\u0026\n         !metricsToRetrieve.getFilterList().isEmpty()) {\n       fieldsToRetrieve.add(Field.METRICS);\n     }\n     if (!singleEntityRead) {\n       if (limit \u003d\u003d null || limit \u003c 0) {\n         limit \u003d TimelineReader.DEFAULT_LIMIT;\n       }\n       if (createdTimeBegin \u003d\u003d null) {\n         createdTimeBegin \u003d DEFAULT_BEGIN_TIME;\n       }\n       if (createdTimeEnd \u003d\u003d null) {\n         createdTimeEnd \u003d DEFAULT_END_TIME;\n       }\n       if (modifiedTimeBegin \u003d\u003d null) {\n         modifiedTimeBegin \u003d DEFAULT_BEGIN_TIME;\n       }\n       if (modifiedTimeEnd \u003d\u003d null) {\n         modifiedTimeEnd \u003d DEFAULT_END_TIME;\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void augmentParams(Configuration hbaseConf, Connection conn)\n      throws IOException {\n    // In reality all three should be null or neither should be null\n    if (flowName \u003d\u003d null || flowRunId \u003d\u003d null || userId \u003d\u003d null) {\n      FlowContext context \u003d\n          lookupFlowContext(clusterId, appId, hbaseConf, conn);\n      flowName \u003d context.flowName;\n      flowRunId \u003d context.flowRunId;\n      userId \u003d context.userId;\n    }\n    if (fieldsToRetrieve \u003d\u003d null) {\n      fieldsToRetrieve \u003d EnumSet.noneOf(Field.class);\n    }\n    if (!fieldsToRetrieve.contains(Field.CONFIGS) \u0026\u0026\n        confsToRetrieve !\u003d null \u0026\u0026 !confsToRetrieve.getFilterList().isEmpty()) {\n      fieldsToRetrieve.add(Field.CONFIGS);\n    }\n    if (!fieldsToRetrieve.contains(Field.METRICS) \u0026\u0026\n        metricsToRetrieve !\u003d null \u0026\u0026\n        !metricsToRetrieve.getFilterList().isEmpty()) {\n      fieldsToRetrieve.add(Field.METRICS);\n    }\n    if (!singleEntityRead) {\n      if (limit \u003d\u003d null || limit \u003c 0) {\n        limit \u003d TimelineReader.DEFAULT_LIMIT;\n      }\n      if (createdTimeBegin \u003d\u003d null) {\n        createdTimeBegin \u003d DEFAULT_BEGIN_TIME;\n      }\n      if (createdTimeEnd \u003d\u003d null) {\n        createdTimeEnd \u003d DEFAULT_END_TIME;\n      }\n      if (modifiedTimeBegin \u003d\u003d null) {\n        modifiedTimeBegin \u003d DEFAULT_BEGIN_TIME;\n      }\n      if (modifiedTimeEnd \u003d\u003d null) {\n        modifiedTimeEnd \u003d DEFAULT_END_TIME;\n      }\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/GenericEntityReader.java",
      "extendedDetails": {}
    },
    "1f710484e5b8ab4d5c67379c012004e8a4242d15": {
      "type": "Ybodychange",
      "commitMessage": "YARN-3862. Support for fetching specific configs and metrics based on prefixes (Varun Saxena via sjlee)\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "1f710484e5b8ab4d5c67379c012004e8a4242d15",
      "commitAuthor": "Sangjin Lee",
      "commitDateOld": "10/07/16 8:45 AM",
      "commitNameOld": "09649005ca269f249f98384ecd1abf9fb6d5b0c1",
      "commitAuthorOld": "Sangjin Lee",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,31 +1,40 @@\n   protected void augmentParams(Configuration hbaseConf, Connection conn)\n       throws IOException {\n     // In reality all three should be null or neither should be null\n     if (flowId \u003d\u003d null || flowRunId \u003d\u003d null || userId \u003d\u003d null) {\n       FlowContext context \u003d\n           lookupFlowContext(clusterId, appId, hbaseConf, conn);\n       flowId \u003d context.flowId;\n       flowRunId \u003d context.flowRunId;\n       userId \u003d context.userId;\n     }\n     if (fieldsToRetrieve \u003d\u003d null) {\n       fieldsToRetrieve \u003d EnumSet.noneOf(Field.class);\n     }\n+    if (!fieldsToRetrieve.contains(Field.CONFIGS) \u0026\u0026\n+        confsToRetrieve !\u003d null \u0026\u0026 !confsToRetrieve.getFilterList().isEmpty()) {\n+      fieldsToRetrieve.add(Field.CONFIGS);\n+    }\n+    if (!fieldsToRetrieve.contains(Field.METRICS) \u0026\u0026\n+        metricsToRetrieve !\u003d null \u0026\u0026\n+        !metricsToRetrieve.getFilterList().isEmpty()) {\n+      fieldsToRetrieve.add(Field.METRICS);\n+    }\n     if (!singleEntityRead) {\n       if (limit \u003d\u003d null || limit \u003c 0) {\n         limit \u003d TimelineReader.DEFAULT_LIMIT;\n       }\n       if (createdTimeBegin \u003d\u003d null) {\n         createdTimeBegin \u003d DEFAULT_BEGIN_TIME;\n       }\n       if (createdTimeEnd \u003d\u003d null) {\n         createdTimeEnd \u003d DEFAULT_END_TIME;\n       }\n       if (modifiedTimeBegin \u003d\u003d null) {\n         modifiedTimeBegin \u003d DEFAULT_BEGIN_TIME;\n       }\n       if (modifiedTimeEnd \u003d\u003d null) {\n         modifiedTimeEnd \u003d DEFAULT_END_TIME;\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void augmentParams(Configuration hbaseConf, Connection conn)\n      throws IOException {\n    // In reality all three should be null or neither should be null\n    if (flowId \u003d\u003d null || flowRunId \u003d\u003d null || userId \u003d\u003d null) {\n      FlowContext context \u003d\n          lookupFlowContext(clusterId, appId, hbaseConf, conn);\n      flowId \u003d context.flowId;\n      flowRunId \u003d context.flowRunId;\n      userId \u003d context.userId;\n    }\n    if (fieldsToRetrieve \u003d\u003d null) {\n      fieldsToRetrieve \u003d EnumSet.noneOf(Field.class);\n    }\n    if (!fieldsToRetrieve.contains(Field.CONFIGS) \u0026\u0026\n        confsToRetrieve !\u003d null \u0026\u0026 !confsToRetrieve.getFilterList().isEmpty()) {\n      fieldsToRetrieve.add(Field.CONFIGS);\n    }\n    if (!fieldsToRetrieve.contains(Field.METRICS) \u0026\u0026\n        metricsToRetrieve !\u003d null \u0026\u0026\n        !metricsToRetrieve.getFilterList().isEmpty()) {\n      fieldsToRetrieve.add(Field.METRICS);\n    }\n    if (!singleEntityRead) {\n      if (limit \u003d\u003d null || limit \u003c 0) {\n        limit \u003d TimelineReader.DEFAULT_LIMIT;\n      }\n      if (createdTimeBegin \u003d\u003d null) {\n        createdTimeBegin \u003d DEFAULT_BEGIN_TIME;\n      }\n      if (createdTimeEnd \u003d\u003d null) {\n        createdTimeEnd \u003d DEFAULT_END_TIME;\n      }\n      if (modifiedTimeBegin \u003d\u003d null) {\n        modifiedTimeBegin \u003d DEFAULT_BEGIN_TIME;\n      }\n      if (modifiedTimeEnd \u003d\u003d null) {\n        modifiedTimeEnd \u003d DEFAULT_END_TIME;\n      }\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/GenericEntityReader.java",
      "extendedDetails": {}
    },
    "09649005ca269f249f98384ecd1abf9fb6d5b0c1": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4221. Store user in app to flow table (Varun Saxena via sjlee)\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "09649005ca269f249f98384ecd1abf9fb6d5b0c1",
      "commitAuthor": "Sangjin Lee",
      "commitDateOld": "10/07/16 8:45 AM",
      "commitNameOld": "d014f2ffd24c1aaebda7503ce0e5a81334a5f266",
      "commitAuthorOld": "Li Lu",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,30 +1,31 @@\n   protected void augmentParams(Configuration hbaseConf, Connection conn)\n       throws IOException {\n-    // In reality both should be null or neither should be null\n-    if (flowId \u003d\u003d null || flowRunId \u003d\u003d null) {\n+    // In reality all three should be null or neither should be null\n+    if (flowId \u003d\u003d null || flowRunId \u003d\u003d null || userId \u003d\u003d null) {\n       FlowContext context \u003d\n           lookupFlowContext(clusterId, appId, hbaseConf, conn);\n       flowId \u003d context.flowId;\n       flowRunId \u003d context.flowRunId;\n+      userId \u003d context.userId;\n     }\n     if (fieldsToRetrieve \u003d\u003d null) {\n       fieldsToRetrieve \u003d EnumSet.noneOf(Field.class);\n     }\n     if (!singleEntityRead) {\n       if (limit \u003d\u003d null || limit \u003c 0) {\n         limit \u003d TimelineReader.DEFAULT_LIMIT;\n       }\n       if (createdTimeBegin \u003d\u003d null) {\n         createdTimeBegin \u003d DEFAULT_BEGIN_TIME;\n       }\n       if (createdTimeEnd \u003d\u003d null) {\n         createdTimeEnd \u003d DEFAULT_END_TIME;\n       }\n       if (modifiedTimeBegin \u003d\u003d null) {\n         modifiedTimeBegin \u003d DEFAULT_BEGIN_TIME;\n       }\n       if (modifiedTimeEnd \u003d\u003d null) {\n         modifiedTimeEnd \u003d DEFAULT_END_TIME;\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void augmentParams(Configuration hbaseConf, Connection conn)\n      throws IOException {\n    // In reality all three should be null or neither should be null\n    if (flowId \u003d\u003d null || flowRunId \u003d\u003d null || userId \u003d\u003d null) {\n      FlowContext context \u003d\n          lookupFlowContext(clusterId, appId, hbaseConf, conn);\n      flowId \u003d context.flowId;\n      flowRunId \u003d context.flowRunId;\n      userId \u003d context.userId;\n    }\n    if (fieldsToRetrieve \u003d\u003d null) {\n      fieldsToRetrieve \u003d EnumSet.noneOf(Field.class);\n    }\n    if (!singleEntityRead) {\n      if (limit \u003d\u003d null || limit \u003c 0) {\n        limit \u003d TimelineReader.DEFAULT_LIMIT;\n      }\n      if (createdTimeBegin \u003d\u003d null) {\n        createdTimeBegin \u003d DEFAULT_BEGIN_TIME;\n      }\n      if (createdTimeEnd \u003d\u003d null) {\n        createdTimeEnd \u003d DEFAULT_END_TIME;\n      }\n      if (modifiedTimeBegin \u003d\u003d null) {\n        modifiedTimeBegin \u003d DEFAULT_BEGIN_TIME;\n      }\n      if (modifiedTimeEnd \u003d\u003d null) {\n        modifiedTimeEnd \u003d DEFAULT_END_TIME;\n      }\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/GenericEntityReader.java",
      "extendedDetails": {}
    },
    "10fa6da7d8a6013698767c6136ae20f0e04415e9": {
      "type": "Yintroduced",
      "commitMessage": "YARN-4074. [timeline reader] implement support for querying for flows and flow runs (sjlee via vrushali)\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "10fa6da7d8a6013698767c6136ae20f0e04415e9",
      "commitAuthor": "Vrushali",
      "diff": "@@ -0,0 +1,30 @@\n+  protected void augmentParams(Configuration hbaseConf, Connection conn)\n+      throws IOException {\n+    // In reality both should be null or neither should be null\n+    if (flowId \u003d\u003d null || flowRunId \u003d\u003d null) {\n+      FlowContext context \u003d\n+          lookupFlowContext(clusterId, appId, hbaseConf, conn);\n+      flowId \u003d context.flowId;\n+      flowRunId \u003d context.flowRunId;\n+    }\n+    if (fieldsToRetrieve \u003d\u003d null) {\n+      fieldsToRetrieve \u003d EnumSet.noneOf(Field.class);\n+    }\n+    if (!singleEntityRead) {\n+      if (limit \u003d\u003d null || limit \u003c 0) {\n+        limit \u003d TimelineReader.DEFAULT_LIMIT;\n+      }\n+      if (createdTimeBegin \u003d\u003d null) {\n+        createdTimeBegin \u003d DEFAULT_BEGIN_TIME;\n+      }\n+      if (createdTimeEnd \u003d\u003d null) {\n+        createdTimeEnd \u003d DEFAULT_END_TIME;\n+      }\n+      if (modifiedTimeBegin \u003d\u003d null) {\n+        modifiedTimeBegin \u003d DEFAULT_BEGIN_TIME;\n+      }\n+      if (modifiedTimeEnd \u003d\u003d null) {\n+        modifiedTimeEnd \u003d DEFAULT_END_TIME;\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  protected void augmentParams(Configuration hbaseConf, Connection conn)\n      throws IOException {\n    // In reality both should be null or neither should be null\n    if (flowId \u003d\u003d null || flowRunId \u003d\u003d null) {\n      FlowContext context \u003d\n          lookupFlowContext(clusterId, appId, hbaseConf, conn);\n      flowId \u003d context.flowId;\n      flowRunId \u003d context.flowRunId;\n    }\n    if (fieldsToRetrieve \u003d\u003d null) {\n      fieldsToRetrieve \u003d EnumSet.noneOf(Field.class);\n    }\n    if (!singleEntityRead) {\n      if (limit \u003d\u003d null || limit \u003c 0) {\n        limit \u003d TimelineReader.DEFAULT_LIMIT;\n      }\n      if (createdTimeBegin \u003d\u003d null) {\n        createdTimeBegin \u003d DEFAULT_BEGIN_TIME;\n      }\n      if (createdTimeEnd \u003d\u003d null) {\n        createdTimeEnd \u003d DEFAULT_END_TIME;\n      }\n      if (modifiedTimeBegin \u003d\u003d null) {\n        modifiedTimeBegin \u003d DEFAULT_BEGIN_TIME;\n      }\n      if (modifiedTimeEnd \u003d\u003d null) {\n        modifiedTimeEnd \u003d DEFAULT_END_TIME;\n      }\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/GenericEntityReader.java"
    }
  }
}