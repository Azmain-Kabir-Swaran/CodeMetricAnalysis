{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "StreamInputFormat.java",
  "functionName": "createRecordReader",
  "functionId": "createRecordReader___genericSplit-InputSplit__context-TaskAttemptContext",
  "sourceFilePath": "hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/mapreduce/StreamInputFormat.java",
  "functionStartLine": 48,
  "functionEndLine": 102,
  "numCommitsSeen": 2,
  "timeTaken": 978,
  "changeHistory": [
    "f365957c6326f88734bc0a5d01cfb7eac713db20",
    "9c87911c4ab35faead3e4729951b2855fb20e3b0"
  ],
  "changeHistoryShort": {
    "f365957c6326f88734bc0a5d01cfb7eac713db20": "Ybodychange",
    "9c87911c4ab35faead3e4729951b2855fb20e3b0": "Yintroduced"
  },
  "changeHistoryDetails": {
    "f365957c6326f88734bc0a5d01cfb7eac713db20": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-15229. Add FileSystem builder-based openFile() API to match createFile();\nS3A to implement S3 Select through this API.\n\nThe new openFile() API is asynchronous, and implemented across FileSystem and FileContext.\n\nThe MapReduce V2 inputs are moved to this API, and you can actually set must/may\noptions to pass in.\n\nThis is more useful for setting things like s3a seek policy than for S3 select,\nas the existing input format/record readers can\u0027t handle S3 select output where\nthe stream is shorter than the file length, and splitting plain text is suboptimal.\nFuture work is needed there.\n\nIn the meantime, any/all filesystem connectors are now free to add their own filesystem-specific\nconfiguration parameters which can be set in jobs and used to set filesystem input stream\noptions (seek policy, retry, encryption secrets, etc).\n\nContributed by Steve Loughran\n",
      "commitDate": "05/02/19 3:51 AM",
      "commitName": "f365957c6326f88734bc0a5d01cfb7eac713db20",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "11/07/12 8:44 AM",
      "commitNameOld": "9c87911c4ab35faead3e4729951b2855fb20e3b0",
      "commitAuthorOld": "Robert Joseph Evans",
      "daysBetweenCommits": 2399.84,
      "commitsBetweenForRepo": 17513,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,49 +1,55 @@\n   public RecordReader\u003cText, Text\u003e createRecordReader(InputSplit genericSplit,\n       TaskAttemptContext context) throws IOException {\n \n     Configuration conf \u003d context.getConfiguration();\n \n     String c \u003d conf.get(\"stream.recordreader.class\");\n     if (c \u003d\u003d null || c.indexOf(\"LineRecordReader\") \u003e\u003d 0) {\n       return super.createRecordReader(genericSplit, context);\n     }\n \n     // handling non-standard record reader (likely StreamXmlRecordReader)\n     FileSplit split \u003d (FileSplit) genericSplit;\n     // LOG.info(\"getRecordReader start.....split\u003d\" + split);\n     context.setStatus(split.toString());\n     context.progress();\n \n     // Open the file and seek to the start of the split\n-    FileSystem fs \u003d split.getPath().getFileSystem(conf);\n-    FSDataInputStream in \u003d fs.open(split.getPath());\n+    Path path \u003d split.getPath();\n+    FileSystem fs \u003d path.getFileSystem(conf);\n+    // open the file\n+    final FutureDataInputStreamBuilder builder \u003d fs.openFile(path);\n+    FutureIOSupport.propagateOptions(builder, conf,\n+        MRJobConfig.INPUT_FILE_OPTION_PREFIX,\n+        MRJobConfig.INPUT_FILE_MANDATORY_PREFIX);\n+    FSDataInputStream in \u003d FutureIOSupport.awaitFuture(builder.build());\n \n     // Factory dispatch based on available params..\n     Class readerClass;\n \n     {\n       readerClass \u003d StreamUtil.goodClassOrNull(conf, c, null);\n       if (readerClass \u003d\u003d null) {\n         throw new RuntimeException(\"Class not found: \" + c);\n       }\n     }\n     Constructor ctor;\n \n     try {\n       ctor \u003d readerClass.getConstructor(new Class[] { FSDataInputStream.class,\n           FileSplit.class, TaskAttemptContext.class, Configuration.class,\n           FileSystem.class });\n     } catch (NoSuchMethodException nsm) {\n       throw new RuntimeException(nsm);\n     }\n \n     RecordReader\u003cText, Text\u003e reader;\n     try {\n       reader \u003d (RecordReader\u003cText, Text\u003e) ctor.newInstance(new Object[] { in,\n           split, context, conf, fs });\n     } catch (Exception nsm) {\n       throw new RuntimeException(nsm);\n     }\n     return reader;\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public RecordReader\u003cText, Text\u003e createRecordReader(InputSplit genericSplit,\n      TaskAttemptContext context) throws IOException {\n\n    Configuration conf \u003d context.getConfiguration();\n\n    String c \u003d conf.get(\"stream.recordreader.class\");\n    if (c \u003d\u003d null || c.indexOf(\"LineRecordReader\") \u003e\u003d 0) {\n      return super.createRecordReader(genericSplit, context);\n    }\n\n    // handling non-standard record reader (likely StreamXmlRecordReader)\n    FileSplit split \u003d (FileSplit) genericSplit;\n    // LOG.info(\"getRecordReader start.....split\u003d\" + split);\n    context.setStatus(split.toString());\n    context.progress();\n\n    // Open the file and seek to the start of the split\n    Path path \u003d split.getPath();\n    FileSystem fs \u003d path.getFileSystem(conf);\n    // open the file\n    final FutureDataInputStreamBuilder builder \u003d fs.openFile(path);\n    FutureIOSupport.propagateOptions(builder, conf,\n        MRJobConfig.INPUT_FILE_OPTION_PREFIX,\n        MRJobConfig.INPUT_FILE_MANDATORY_PREFIX);\n    FSDataInputStream in \u003d FutureIOSupport.awaitFuture(builder.build());\n\n    // Factory dispatch based on available params..\n    Class readerClass;\n\n    {\n      readerClass \u003d StreamUtil.goodClassOrNull(conf, c, null);\n      if (readerClass \u003d\u003d null) {\n        throw new RuntimeException(\"Class not found: \" + c);\n      }\n    }\n    Constructor ctor;\n\n    try {\n      ctor \u003d readerClass.getConstructor(new Class[] { FSDataInputStream.class,\n          FileSplit.class, TaskAttemptContext.class, Configuration.class,\n          FileSystem.class });\n    } catch (NoSuchMethodException nsm) {\n      throw new RuntimeException(nsm);\n    }\n\n    RecordReader\u003cText, Text\u003e reader;\n    try {\n      reader \u003d (RecordReader\u003cText, Text\u003e) ctor.newInstance(new Object[] { in,\n          split, context, conf, fs });\n    } catch (Exception nsm) {\n      throw new RuntimeException(nsm);\n    }\n    return reader;\n\n  }",
      "path": "hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/mapreduce/StreamInputFormat.java",
      "extendedDetails": {}
    },
    "9c87911c4ab35faead3e4729951b2855fb20e3b0": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-8521. Port StreamInputFormat to new Map Reduce API (madhukara phatak via bobby)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1360238 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/07/12 8:44 AM",
      "commitName": "9c87911c4ab35faead3e4729951b2855fb20e3b0",
      "commitAuthor": "Robert Joseph Evans",
      "diff": "@@ -0,0 +1,49 @@\n+  public RecordReader\u003cText, Text\u003e createRecordReader(InputSplit genericSplit,\n+      TaskAttemptContext context) throws IOException {\n+\n+    Configuration conf \u003d context.getConfiguration();\n+\n+    String c \u003d conf.get(\"stream.recordreader.class\");\n+    if (c \u003d\u003d null || c.indexOf(\"LineRecordReader\") \u003e\u003d 0) {\n+      return super.createRecordReader(genericSplit, context);\n+    }\n+\n+    // handling non-standard record reader (likely StreamXmlRecordReader)\n+    FileSplit split \u003d (FileSplit) genericSplit;\n+    // LOG.info(\"getRecordReader start.....split\u003d\" + split);\n+    context.setStatus(split.toString());\n+    context.progress();\n+\n+    // Open the file and seek to the start of the split\n+    FileSystem fs \u003d split.getPath().getFileSystem(conf);\n+    FSDataInputStream in \u003d fs.open(split.getPath());\n+\n+    // Factory dispatch based on available params..\n+    Class readerClass;\n+\n+    {\n+      readerClass \u003d StreamUtil.goodClassOrNull(conf, c, null);\n+      if (readerClass \u003d\u003d null) {\n+        throw new RuntimeException(\"Class not found: \" + c);\n+      }\n+    }\n+    Constructor ctor;\n+\n+    try {\n+      ctor \u003d readerClass.getConstructor(new Class[] { FSDataInputStream.class,\n+          FileSplit.class, TaskAttemptContext.class, Configuration.class,\n+          FileSystem.class });\n+    } catch (NoSuchMethodException nsm) {\n+      throw new RuntimeException(nsm);\n+    }\n+\n+    RecordReader\u003cText, Text\u003e reader;\n+    try {\n+      reader \u003d (RecordReader\u003cText, Text\u003e) ctor.newInstance(new Object[] { in,\n+          split, context, conf, fs });\n+    } catch (Exception nsm) {\n+      throw new RuntimeException(nsm);\n+    }\n+    return reader;\n+\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public RecordReader\u003cText, Text\u003e createRecordReader(InputSplit genericSplit,\n      TaskAttemptContext context) throws IOException {\n\n    Configuration conf \u003d context.getConfiguration();\n\n    String c \u003d conf.get(\"stream.recordreader.class\");\n    if (c \u003d\u003d null || c.indexOf(\"LineRecordReader\") \u003e\u003d 0) {\n      return super.createRecordReader(genericSplit, context);\n    }\n\n    // handling non-standard record reader (likely StreamXmlRecordReader)\n    FileSplit split \u003d (FileSplit) genericSplit;\n    // LOG.info(\"getRecordReader start.....split\u003d\" + split);\n    context.setStatus(split.toString());\n    context.progress();\n\n    // Open the file and seek to the start of the split\n    FileSystem fs \u003d split.getPath().getFileSystem(conf);\n    FSDataInputStream in \u003d fs.open(split.getPath());\n\n    // Factory dispatch based on available params..\n    Class readerClass;\n\n    {\n      readerClass \u003d StreamUtil.goodClassOrNull(conf, c, null);\n      if (readerClass \u003d\u003d null) {\n        throw new RuntimeException(\"Class not found: \" + c);\n      }\n    }\n    Constructor ctor;\n\n    try {\n      ctor \u003d readerClass.getConstructor(new Class[] { FSDataInputStream.class,\n          FileSplit.class, TaskAttemptContext.class, Configuration.class,\n          FileSystem.class });\n    } catch (NoSuchMethodException nsm) {\n      throw new RuntimeException(nsm);\n    }\n\n    RecordReader\u003cText, Text\u003e reader;\n    try {\n      reader \u003d (RecordReader\u003cText, Text\u003e) ctor.newInstance(new Object[] { in,\n          split, context, conf, fs });\n    } catch (Exception nsm) {\n      throw new RuntimeException(nsm);\n    }\n    return reader;\n\n  }",
      "path": "hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/mapreduce/StreamInputFormat.java"
    }
  }
}