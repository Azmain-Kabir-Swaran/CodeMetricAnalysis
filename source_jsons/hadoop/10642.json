{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "StorageLocationChecker.java",
  "functionName": "check",
  "functionId": "check___conf-Configuration(modifiers-final)__dataDirs-Collection__StorageLocation__(modifiers-final)",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/checker/StorageLocationChecker.java",
  "functionStartLine": 151,
  "functionEndLine": 245,
  "numCommitsSeen": 9,
  "timeTaken": 2799,
  "changeHistory": [
    "e1dfc060f8f0247f97127c75c9284a068fc93907",
    "3108d27edde941d153a58f71fb1096cce2995531",
    "7c1cc30b3c611ad2d0ae19ebaefd45f31a734e6c",
    "603f3ef1386048111940b66f3a0750ab84d0588f",
    "613b902b9808c1c679674047cff15feade01dfab",
    "3d267177776547ceb32c5b9ed04cd9ec05b3421a"
  ],
  "changeHistoryShort": {
    "e1dfc060f8f0247f97127c75c9284a068fc93907": "Ybodychange",
    "3108d27edde941d153a58f71fb1096cce2995531": "Ybodychange",
    "7c1cc30b3c611ad2d0ae19ebaefd45f31a734e6c": "Ybodychange",
    "603f3ef1386048111940b66f3a0750ab84d0588f": "Ybodychange",
    "613b902b9808c1c679674047cff15feade01dfab": "Ybodychange",
    "3d267177776547ceb32c5b9ed04cd9ec05b3421a": "Yintroduced"
  },
  "changeHistoryDetails": {
    "e1dfc060f8f0247f97127c75c9284a068fc93907": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14486. The exception classes in some throw statements do not accurately describe why they are thrown. Contributed by Ayush Saxena.\n",
      "commitDate": "06/06/19 11:59 AM",
      "commitName": "e1dfc060f8f0247f97127c75c9284a068fc93907",
      "commitAuthor": "Inigo Goiri",
      "commitDateOld": "21/01/19 8:44 PM",
      "commitNameOld": "1ff658b2ef3fb933897712c728bc628f3f44bded",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 135.59,
      "commitsBetweenForRepo": 961,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,95 +1,95 @@\n   public List\u003cStorageLocation\u003e check(\n       final Configuration conf,\n       final Collection\u003cStorageLocation\u003e dataDirs)\n       throws InterruptedException, IOException {\n \n     final HashMap\u003cStorageLocation, Boolean\u003e goodLocations \u003d\n         new LinkedHashMap\u003c\u003e();\n     final Set\u003cStorageLocation\u003e failedLocations \u003d new HashSet\u003c\u003e();\n     final Map\u003cStorageLocation, ListenableFuture\u003cVolumeCheckResult\u003e\u003e futures \u003d\n         Maps.newHashMap();\n     final LocalFileSystem localFS \u003d FileSystem.getLocal(conf);\n     final CheckContext context \u003d new CheckContext(localFS, expectedPermission);\n \n     // Start parallel disk check operations on all StorageLocations.\n     for (StorageLocation location : dataDirs) {\n       goodLocations.put(location, true);\n       Optional\u003cListenableFuture\u003cVolumeCheckResult\u003e\u003e olf \u003d\n           delegateChecker.schedule(location, context);\n       if (olf.isPresent()) {\n         futures.put(location, olf.get());\n       }\n     }\n \n     if (maxVolumeFailuresTolerated \u003e\u003d dataDirs.size()) {\n-      throw new DiskErrorException(\"Invalid value configured for \"\n+      throw new HadoopIllegalArgumentException(\"Invalid value configured for \"\n           + DFS_DATANODE_FAILED_VOLUMES_TOLERATED_KEY + \" - \"\n           + maxVolumeFailuresTolerated + \". Value configured is \u003e\u003d \"\n           + \"to the number of configured volumes (\" + dataDirs.size() + \").\");\n     }\n \n     final long checkStartTimeMs \u003d timer.monotonicNow();\n \n     // Retrieve the results of the disk checks.\n     for (Map.Entry\u003cStorageLocation,\n              ListenableFuture\u003cVolumeCheckResult\u003e\u003e entry : futures.entrySet()) {\n \n       // Determine how much time we can allow for this check to complete.\n       // The cumulative wait time cannot exceed maxAllowedTimeForCheck.\n       final long waitSoFarMs \u003d (timer.monotonicNow() - checkStartTimeMs);\n       final long timeLeftMs \u003d Math.max(0,\n           maxAllowedTimeForCheckMs - waitSoFarMs);\n       final StorageLocation location \u003d entry.getKey();\n \n       try {\n         final VolumeCheckResult result \u003d\n             entry.getValue().get(timeLeftMs, TimeUnit.MILLISECONDS);\n         switch (result) {\n         case HEALTHY:\n           break;\n         case DEGRADED:\n           LOG.warn(\"StorageLocation {} appears to be degraded.\", location);\n           break;\n         case FAILED:\n           LOG.warn(\"StorageLocation {} detected as failed.\", location);\n           failedLocations.add(location);\n           goodLocations.remove(location);\n           break;\n         default:\n           LOG.error(\"Unexpected health check result {} for StorageLocation {}\",\n               result, location);\n         }\n       } catch (ExecutionException|TimeoutException e) {\n         LOG.warn(\"Exception checking StorageLocation \" + location,\n             e.getCause());\n         failedLocations.add(location);\n         goodLocations.remove(location);\n       }\n     }\n \n     if (maxVolumeFailuresTolerated \u003d\u003d DataNode.MAX_VOLUME_FAILURE_TOLERATED_LIMIT) {\n       if (dataDirs.size() \u003d\u003d failedLocations.size()) {\n         throw new DiskErrorException(\"Too many failed volumes - \"\n             + \"current valid volumes: \" + goodLocations.size()\n             + \", volumes configured: \" + dataDirs.size()\n             + \", volumes failed: \" + failedLocations.size()\n             + \", volume failures tolerated: \" + maxVolumeFailuresTolerated);\n       }\n     } else {\n       if (failedLocations.size() \u003e maxVolumeFailuresTolerated) {\n         throw new DiskErrorException(\"Too many failed volumes - \"\n             + \"current valid volumes: \" + goodLocations.size()\n             + \", volumes configured: \" + dataDirs.size()\n             + \", volumes failed: \" + failedLocations.size()\n             + \", volume failures tolerated: \" + maxVolumeFailuresTolerated);\n       }\n     }\n \n     if (goodLocations.size() \u003d\u003d 0) {\n       throw new DiskErrorException(\"All directories in \"\n           + DFS_DATANODE_DATA_DIR_KEY + \" are invalid: \"\n           + failedLocations);\n     }\n \n     return new ArrayList\u003c\u003e(goodLocations.keySet());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public List\u003cStorageLocation\u003e check(\n      final Configuration conf,\n      final Collection\u003cStorageLocation\u003e dataDirs)\n      throws InterruptedException, IOException {\n\n    final HashMap\u003cStorageLocation, Boolean\u003e goodLocations \u003d\n        new LinkedHashMap\u003c\u003e();\n    final Set\u003cStorageLocation\u003e failedLocations \u003d new HashSet\u003c\u003e();\n    final Map\u003cStorageLocation, ListenableFuture\u003cVolumeCheckResult\u003e\u003e futures \u003d\n        Maps.newHashMap();\n    final LocalFileSystem localFS \u003d FileSystem.getLocal(conf);\n    final CheckContext context \u003d new CheckContext(localFS, expectedPermission);\n\n    // Start parallel disk check operations on all StorageLocations.\n    for (StorageLocation location : dataDirs) {\n      goodLocations.put(location, true);\n      Optional\u003cListenableFuture\u003cVolumeCheckResult\u003e\u003e olf \u003d\n          delegateChecker.schedule(location, context);\n      if (olf.isPresent()) {\n        futures.put(location, olf.get());\n      }\n    }\n\n    if (maxVolumeFailuresTolerated \u003e\u003d dataDirs.size()) {\n      throw new HadoopIllegalArgumentException(\"Invalid value configured for \"\n          + DFS_DATANODE_FAILED_VOLUMES_TOLERATED_KEY + \" - \"\n          + maxVolumeFailuresTolerated + \". Value configured is \u003e\u003d \"\n          + \"to the number of configured volumes (\" + dataDirs.size() + \").\");\n    }\n\n    final long checkStartTimeMs \u003d timer.monotonicNow();\n\n    // Retrieve the results of the disk checks.\n    for (Map.Entry\u003cStorageLocation,\n             ListenableFuture\u003cVolumeCheckResult\u003e\u003e entry : futures.entrySet()) {\n\n      // Determine how much time we can allow for this check to complete.\n      // The cumulative wait time cannot exceed maxAllowedTimeForCheck.\n      final long waitSoFarMs \u003d (timer.monotonicNow() - checkStartTimeMs);\n      final long timeLeftMs \u003d Math.max(0,\n          maxAllowedTimeForCheckMs - waitSoFarMs);\n      final StorageLocation location \u003d entry.getKey();\n\n      try {\n        final VolumeCheckResult result \u003d\n            entry.getValue().get(timeLeftMs, TimeUnit.MILLISECONDS);\n        switch (result) {\n        case HEALTHY:\n          break;\n        case DEGRADED:\n          LOG.warn(\"StorageLocation {} appears to be degraded.\", location);\n          break;\n        case FAILED:\n          LOG.warn(\"StorageLocation {} detected as failed.\", location);\n          failedLocations.add(location);\n          goodLocations.remove(location);\n          break;\n        default:\n          LOG.error(\"Unexpected health check result {} for StorageLocation {}\",\n              result, location);\n        }\n      } catch (ExecutionException|TimeoutException e) {\n        LOG.warn(\"Exception checking StorageLocation \" + location,\n            e.getCause());\n        failedLocations.add(location);\n        goodLocations.remove(location);\n      }\n    }\n\n    if (maxVolumeFailuresTolerated \u003d\u003d DataNode.MAX_VOLUME_FAILURE_TOLERATED_LIMIT) {\n      if (dataDirs.size() \u003d\u003d failedLocations.size()) {\n        throw new DiskErrorException(\"Too many failed volumes - \"\n            + \"current valid volumes: \" + goodLocations.size()\n            + \", volumes configured: \" + dataDirs.size()\n            + \", volumes failed: \" + failedLocations.size()\n            + \", volume failures tolerated: \" + maxVolumeFailuresTolerated);\n      }\n    } else {\n      if (failedLocations.size() \u003e maxVolumeFailuresTolerated) {\n        throw new DiskErrorException(\"Too many failed volumes - \"\n            + \"current valid volumes: \" + goodLocations.size()\n            + \", volumes configured: \" + dataDirs.size()\n            + \", volumes failed: \" + failedLocations.size()\n            + \", volume failures tolerated: \" + maxVolumeFailuresTolerated);\n      }\n    }\n\n    if (goodLocations.size() \u003d\u003d 0) {\n      throw new DiskErrorException(\"All directories in \"\n          + DFS_DATANODE_DATA_DIR_KEY + \" are invalid: \"\n          + failedLocations);\n    }\n\n    return new ArrayList\u003c\u003e(goodLocations.keySet());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/checker/StorageLocationChecker.java",
      "extendedDetails": {}
    },
    "3108d27edde941d153a58f71fb1096cce2995531": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12716. \u0027dfs.datanode.failed.volumes.tolerated\u0027 to support minimum number of volumes to be available. Contributed by Ranith Sardar and usharani\n",
      "commitDate": "30/07/18 3:20 AM",
      "commitName": "3108d27edde941d153a58f71fb1096cce2995531",
      "commitAuthor": "Brahma Reddy Battula",
      "commitDateOld": "31/07/17 5:02 PM",
      "commitNameOld": "ea568123fa76e4683d355a67be01b730d0c11068",
      "commitAuthorOld": "Weiwei Yang",
      "daysBetweenCommits": 363.43,
      "commitsBetweenForRepo": 3287,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,85 +1,95 @@\n   public List\u003cStorageLocation\u003e check(\n       final Configuration conf,\n       final Collection\u003cStorageLocation\u003e dataDirs)\n       throws InterruptedException, IOException {\n \n     final HashMap\u003cStorageLocation, Boolean\u003e goodLocations \u003d\n         new LinkedHashMap\u003c\u003e();\n     final Set\u003cStorageLocation\u003e failedLocations \u003d new HashSet\u003c\u003e();\n     final Map\u003cStorageLocation, ListenableFuture\u003cVolumeCheckResult\u003e\u003e futures \u003d\n         Maps.newHashMap();\n     final LocalFileSystem localFS \u003d FileSystem.getLocal(conf);\n     final CheckContext context \u003d new CheckContext(localFS, expectedPermission);\n \n     // Start parallel disk check operations on all StorageLocations.\n     for (StorageLocation location : dataDirs) {\n       goodLocations.put(location, true);\n       Optional\u003cListenableFuture\u003cVolumeCheckResult\u003e\u003e olf \u003d\n           delegateChecker.schedule(location, context);\n       if (olf.isPresent()) {\n         futures.put(location, olf.get());\n       }\n     }\n \n     if (maxVolumeFailuresTolerated \u003e\u003d dataDirs.size()) {\n       throw new DiskErrorException(\"Invalid value configured for \"\n           + DFS_DATANODE_FAILED_VOLUMES_TOLERATED_KEY + \" - \"\n           + maxVolumeFailuresTolerated + \". Value configured is \u003e\u003d \"\n           + \"to the number of configured volumes (\" + dataDirs.size() + \").\");\n     }\n \n     final long checkStartTimeMs \u003d timer.monotonicNow();\n \n     // Retrieve the results of the disk checks.\n     for (Map.Entry\u003cStorageLocation,\n              ListenableFuture\u003cVolumeCheckResult\u003e\u003e entry : futures.entrySet()) {\n \n       // Determine how much time we can allow for this check to complete.\n       // The cumulative wait time cannot exceed maxAllowedTimeForCheck.\n       final long waitSoFarMs \u003d (timer.monotonicNow() - checkStartTimeMs);\n       final long timeLeftMs \u003d Math.max(0,\n           maxAllowedTimeForCheckMs - waitSoFarMs);\n       final StorageLocation location \u003d entry.getKey();\n \n       try {\n         final VolumeCheckResult result \u003d\n             entry.getValue().get(timeLeftMs, TimeUnit.MILLISECONDS);\n         switch (result) {\n         case HEALTHY:\n           break;\n         case DEGRADED:\n           LOG.warn(\"StorageLocation {} appears to be degraded.\", location);\n           break;\n         case FAILED:\n           LOG.warn(\"StorageLocation {} detected as failed.\", location);\n           failedLocations.add(location);\n           goodLocations.remove(location);\n           break;\n         default:\n           LOG.error(\"Unexpected health check result {} for StorageLocation {}\",\n               result, location);\n         }\n       } catch (ExecutionException|TimeoutException e) {\n         LOG.warn(\"Exception checking StorageLocation \" + location,\n             e.getCause());\n         failedLocations.add(location);\n         goodLocations.remove(location);\n       }\n     }\n \n-    if (failedLocations.size() \u003e maxVolumeFailuresTolerated) {\n-      throw new DiskErrorException(\"Too many failed volumes - \"\n-          + \"current valid volumes: \" + goodLocations.size()\n-          + \", volumes configured: \" + dataDirs.size()\n-          + \", volumes failed: \" + failedLocations.size()\n-          + \", volume failures tolerated: \" + maxVolumeFailuresTolerated);\n+    if (maxVolumeFailuresTolerated \u003d\u003d DataNode.MAX_VOLUME_FAILURE_TOLERATED_LIMIT) {\n+      if (dataDirs.size() \u003d\u003d failedLocations.size()) {\n+        throw new DiskErrorException(\"Too many failed volumes - \"\n+            + \"current valid volumes: \" + goodLocations.size()\n+            + \", volumes configured: \" + dataDirs.size()\n+            + \", volumes failed: \" + failedLocations.size()\n+            + \", volume failures tolerated: \" + maxVolumeFailuresTolerated);\n+      }\n+    } else {\n+      if (failedLocations.size() \u003e maxVolumeFailuresTolerated) {\n+        throw new DiskErrorException(\"Too many failed volumes - \"\n+            + \"current valid volumes: \" + goodLocations.size()\n+            + \", volumes configured: \" + dataDirs.size()\n+            + \", volumes failed: \" + failedLocations.size()\n+            + \", volume failures tolerated: \" + maxVolumeFailuresTolerated);\n+      }\n     }\n \n     if (goodLocations.size() \u003d\u003d 0) {\n       throw new DiskErrorException(\"All directories in \"\n           + DFS_DATANODE_DATA_DIR_KEY + \" are invalid: \"\n           + failedLocations);\n     }\n \n     return new ArrayList\u003c\u003e(goodLocations.keySet());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public List\u003cStorageLocation\u003e check(\n      final Configuration conf,\n      final Collection\u003cStorageLocation\u003e dataDirs)\n      throws InterruptedException, IOException {\n\n    final HashMap\u003cStorageLocation, Boolean\u003e goodLocations \u003d\n        new LinkedHashMap\u003c\u003e();\n    final Set\u003cStorageLocation\u003e failedLocations \u003d new HashSet\u003c\u003e();\n    final Map\u003cStorageLocation, ListenableFuture\u003cVolumeCheckResult\u003e\u003e futures \u003d\n        Maps.newHashMap();\n    final LocalFileSystem localFS \u003d FileSystem.getLocal(conf);\n    final CheckContext context \u003d new CheckContext(localFS, expectedPermission);\n\n    // Start parallel disk check operations on all StorageLocations.\n    for (StorageLocation location : dataDirs) {\n      goodLocations.put(location, true);\n      Optional\u003cListenableFuture\u003cVolumeCheckResult\u003e\u003e olf \u003d\n          delegateChecker.schedule(location, context);\n      if (olf.isPresent()) {\n        futures.put(location, olf.get());\n      }\n    }\n\n    if (maxVolumeFailuresTolerated \u003e\u003d dataDirs.size()) {\n      throw new DiskErrorException(\"Invalid value configured for \"\n          + DFS_DATANODE_FAILED_VOLUMES_TOLERATED_KEY + \" - \"\n          + maxVolumeFailuresTolerated + \". Value configured is \u003e\u003d \"\n          + \"to the number of configured volumes (\" + dataDirs.size() + \").\");\n    }\n\n    final long checkStartTimeMs \u003d timer.monotonicNow();\n\n    // Retrieve the results of the disk checks.\n    for (Map.Entry\u003cStorageLocation,\n             ListenableFuture\u003cVolumeCheckResult\u003e\u003e entry : futures.entrySet()) {\n\n      // Determine how much time we can allow for this check to complete.\n      // The cumulative wait time cannot exceed maxAllowedTimeForCheck.\n      final long waitSoFarMs \u003d (timer.monotonicNow() - checkStartTimeMs);\n      final long timeLeftMs \u003d Math.max(0,\n          maxAllowedTimeForCheckMs - waitSoFarMs);\n      final StorageLocation location \u003d entry.getKey();\n\n      try {\n        final VolumeCheckResult result \u003d\n            entry.getValue().get(timeLeftMs, TimeUnit.MILLISECONDS);\n        switch (result) {\n        case HEALTHY:\n          break;\n        case DEGRADED:\n          LOG.warn(\"StorageLocation {} appears to be degraded.\", location);\n          break;\n        case FAILED:\n          LOG.warn(\"StorageLocation {} detected as failed.\", location);\n          failedLocations.add(location);\n          goodLocations.remove(location);\n          break;\n        default:\n          LOG.error(\"Unexpected health check result {} for StorageLocation {}\",\n              result, location);\n        }\n      } catch (ExecutionException|TimeoutException e) {\n        LOG.warn(\"Exception checking StorageLocation \" + location,\n            e.getCause());\n        failedLocations.add(location);\n        goodLocations.remove(location);\n      }\n    }\n\n    if (maxVolumeFailuresTolerated \u003d\u003d DataNode.MAX_VOLUME_FAILURE_TOLERATED_LIMIT) {\n      if (dataDirs.size() \u003d\u003d failedLocations.size()) {\n        throw new DiskErrorException(\"Too many failed volumes - \"\n            + \"current valid volumes: \" + goodLocations.size()\n            + \", volumes configured: \" + dataDirs.size()\n            + \", volumes failed: \" + failedLocations.size()\n            + \", volume failures tolerated: \" + maxVolumeFailuresTolerated);\n      }\n    } else {\n      if (failedLocations.size() \u003e maxVolumeFailuresTolerated) {\n        throw new DiskErrorException(\"Too many failed volumes - \"\n            + \"current valid volumes: \" + goodLocations.size()\n            + \", volumes configured: \" + dataDirs.size()\n            + \", volumes failed: \" + failedLocations.size()\n            + \", volume failures tolerated: \" + maxVolumeFailuresTolerated);\n      }\n    }\n\n    if (goodLocations.size() \u003d\u003d 0) {\n      throw new DiskErrorException(\"All directories in \"\n          + DFS_DATANODE_DATA_DIR_KEY + \" are invalid: \"\n          + failedLocations);\n    }\n\n    return new ArrayList\u003c\u003e(goodLocations.keySet());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/checker/StorageLocationChecker.java",
      "extendedDetails": {}
    },
    "7c1cc30b3c611ad2d0ae19ebaefd45f31a734e6c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11369. Change exception message in StorageLocationChecker.\n",
      "commitDate": "26/01/17 9:12 AM",
      "commitName": "7c1cc30b3c611ad2d0ae19ebaefd45f31a734e6c",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "28/12/16 10:08 PM",
      "commitNameOld": "603f3ef1386048111940b66f3a0750ab84d0588f",
      "commitAuthorOld": "Xiaoyu Yao",
      "daysBetweenCommits": 28.46,
      "commitsBetweenForRepo": 142,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,84 +1,85 @@\n   public List\u003cStorageLocation\u003e check(\n       final Configuration conf,\n       final Collection\u003cStorageLocation\u003e dataDirs)\n       throws InterruptedException, IOException {\n \n     final HashMap\u003cStorageLocation, Boolean\u003e goodLocations \u003d\n         new LinkedHashMap\u003c\u003e();\n     final Set\u003cStorageLocation\u003e failedLocations \u003d new HashSet\u003c\u003e();\n     final Map\u003cStorageLocation, ListenableFuture\u003cVolumeCheckResult\u003e\u003e futures \u003d\n         Maps.newHashMap();\n     final LocalFileSystem localFS \u003d FileSystem.getLocal(conf);\n     final CheckContext context \u003d new CheckContext(localFS, expectedPermission);\n \n     // Start parallel disk check operations on all StorageLocations.\n     for (StorageLocation location : dataDirs) {\n       goodLocations.put(location, true);\n       Optional\u003cListenableFuture\u003cVolumeCheckResult\u003e\u003e olf \u003d\n           delegateChecker.schedule(location, context);\n       if (olf.isPresent()) {\n         futures.put(location, olf.get());\n       }\n     }\n \n     if (maxVolumeFailuresTolerated \u003e\u003d dataDirs.size()) {\n       throw new DiskErrorException(\"Invalid value configured for \"\n           + DFS_DATANODE_FAILED_VOLUMES_TOLERATED_KEY + \" - \"\n           + maxVolumeFailuresTolerated + \". Value configured is \u003e\u003d \"\n           + \"to the number of configured volumes (\" + dataDirs.size() + \").\");\n     }\n \n     final long checkStartTimeMs \u003d timer.monotonicNow();\n \n     // Retrieve the results of the disk checks.\n     for (Map.Entry\u003cStorageLocation,\n              ListenableFuture\u003cVolumeCheckResult\u003e\u003e entry : futures.entrySet()) {\n \n       // Determine how much time we can allow for this check to complete.\n       // The cumulative wait time cannot exceed maxAllowedTimeForCheck.\n       final long waitSoFarMs \u003d (timer.monotonicNow() - checkStartTimeMs);\n       final long timeLeftMs \u003d Math.max(0,\n           maxAllowedTimeForCheckMs - waitSoFarMs);\n       final StorageLocation location \u003d entry.getKey();\n \n       try {\n         final VolumeCheckResult result \u003d\n             entry.getValue().get(timeLeftMs, TimeUnit.MILLISECONDS);\n         switch (result) {\n         case HEALTHY:\n           break;\n         case DEGRADED:\n           LOG.warn(\"StorageLocation {} appears to be degraded.\", location);\n           break;\n         case FAILED:\n           LOG.warn(\"StorageLocation {} detected as failed.\", location);\n           failedLocations.add(location);\n           goodLocations.remove(location);\n           break;\n         default:\n           LOG.error(\"Unexpected health check result {} for StorageLocation {}\",\n               result, location);\n         }\n       } catch (ExecutionException|TimeoutException e) {\n         LOG.warn(\"Exception checking StorageLocation \" + location,\n             e.getCause());\n         failedLocations.add(location);\n         goodLocations.remove(location);\n       }\n     }\n \n     if (failedLocations.size() \u003e maxVolumeFailuresTolerated) {\n-      throw new IOException(\n-          \"Too many failed volumes: \" + failedLocations.size() +\n-          \". The configuration allows for a maximum of \" +\n-          maxVolumeFailuresTolerated + \" failed volumes.\");\n+      throw new DiskErrorException(\"Too many failed volumes - \"\n+          + \"current valid volumes: \" + goodLocations.size()\n+          + \", volumes configured: \" + dataDirs.size()\n+          + \", volumes failed: \" + failedLocations.size()\n+          + \", volume failures tolerated: \" + maxVolumeFailuresTolerated);\n     }\n \n     if (goodLocations.size() \u003d\u003d 0) {\n-      throw new IOException(\"All directories in \"\n+      throw new DiskErrorException(\"All directories in \"\n           + DFS_DATANODE_DATA_DIR_KEY + \" are invalid: \"\n           + failedLocations);\n     }\n \n     return new ArrayList\u003c\u003e(goodLocations.keySet());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public List\u003cStorageLocation\u003e check(\n      final Configuration conf,\n      final Collection\u003cStorageLocation\u003e dataDirs)\n      throws InterruptedException, IOException {\n\n    final HashMap\u003cStorageLocation, Boolean\u003e goodLocations \u003d\n        new LinkedHashMap\u003c\u003e();\n    final Set\u003cStorageLocation\u003e failedLocations \u003d new HashSet\u003c\u003e();\n    final Map\u003cStorageLocation, ListenableFuture\u003cVolumeCheckResult\u003e\u003e futures \u003d\n        Maps.newHashMap();\n    final LocalFileSystem localFS \u003d FileSystem.getLocal(conf);\n    final CheckContext context \u003d new CheckContext(localFS, expectedPermission);\n\n    // Start parallel disk check operations on all StorageLocations.\n    for (StorageLocation location : dataDirs) {\n      goodLocations.put(location, true);\n      Optional\u003cListenableFuture\u003cVolumeCheckResult\u003e\u003e olf \u003d\n          delegateChecker.schedule(location, context);\n      if (olf.isPresent()) {\n        futures.put(location, olf.get());\n      }\n    }\n\n    if (maxVolumeFailuresTolerated \u003e\u003d dataDirs.size()) {\n      throw new DiskErrorException(\"Invalid value configured for \"\n          + DFS_DATANODE_FAILED_VOLUMES_TOLERATED_KEY + \" - \"\n          + maxVolumeFailuresTolerated + \". Value configured is \u003e\u003d \"\n          + \"to the number of configured volumes (\" + dataDirs.size() + \").\");\n    }\n\n    final long checkStartTimeMs \u003d timer.monotonicNow();\n\n    // Retrieve the results of the disk checks.\n    for (Map.Entry\u003cStorageLocation,\n             ListenableFuture\u003cVolumeCheckResult\u003e\u003e entry : futures.entrySet()) {\n\n      // Determine how much time we can allow for this check to complete.\n      // The cumulative wait time cannot exceed maxAllowedTimeForCheck.\n      final long waitSoFarMs \u003d (timer.monotonicNow() - checkStartTimeMs);\n      final long timeLeftMs \u003d Math.max(0,\n          maxAllowedTimeForCheckMs - waitSoFarMs);\n      final StorageLocation location \u003d entry.getKey();\n\n      try {\n        final VolumeCheckResult result \u003d\n            entry.getValue().get(timeLeftMs, TimeUnit.MILLISECONDS);\n        switch (result) {\n        case HEALTHY:\n          break;\n        case DEGRADED:\n          LOG.warn(\"StorageLocation {} appears to be degraded.\", location);\n          break;\n        case FAILED:\n          LOG.warn(\"StorageLocation {} detected as failed.\", location);\n          failedLocations.add(location);\n          goodLocations.remove(location);\n          break;\n        default:\n          LOG.error(\"Unexpected health check result {} for StorageLocation {}\",\n              result, location);\n        }\n      } catch (ExecutionException|TimeoutException e) {\n        LOG.warn(\"Exception checking StorageLocation \" + location,\n            e.getCause());\n        failedLocations.add(location);\n        goodLocations.remove(location);\n      }\n    }\n\n    if (failedLocations.size() \u003e maxVolumeFailuresTolerated) {\n      throw new DiskErrorException(\"Too many failed volumes - \"\n          + \"current valid volumes: \" + goodLocations.size()\n          + \", volumes configured: \" + dataDirs.size()\n          + \", volumes failed: \" + failedLocations.size()\n          + \", volume failures tolerated: \" + maxVolumeFailuresTolerated);\n    }\n\n    if (goodLocations.size() \u003d\u003d 0) {\n      throw new DiskErrorException(\"All directories in \"\n          + DFS_DATANODE_DATA_DIR_KEY + \" are invalid: \"\n          + failedLocations);\n    }\n\n    return new ArrayList\u003c\u003e(goodLocations.keySet());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/checker/StorageLocationChecker.java",
      "extendedDetails": {}
    },
    "603f3ef1386048111940b66f3a0750ab84d0588f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11274. Datanode should only check the failed volume upon IO errors. Contributed by Xiaoyu Yao.\n",
      "commitDate": "28/12/16 10:08 PM",
      "commitName": "603f3ef1386048111940b66f3a0750ab84d0588f",
      "commitAuthor": "Xiaoyu Yao",
      "commitDateOld": "22/11/16 10:50 AM",
      "commitNameOld": "613b902b9808c1c679674047cff15feade01dfab",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 36.47,
      "commitsBetweenForRepo": 201,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,81 +1,84 @@\n   public List\u003cStorageLocation\u003e check(\n       final Configuration conf,\n       final Collection\u003cStorageLocation\u003e dataDirs)\n       throws InterruptedException, IOException {\n \n     final HashMap\u003cStorageLocation, Boolean\u003e goodLocations \u003d\n         new LinkedHashMap\u003c\u003e();\n     final Set\u003cStorageLocation\u003e failedLocations \u003d new HashSet\u003c\u003e();\n     final Map\u003cStorageLocation, ListenableFuture\u003cVolumeCheckResult\u003e\u003e futures \u003d\n         Maps.newHashMap();\n     final LocalFileSystem localFS \u003d FileSystem.getLocal(conf);\n     final CheckContext context \u003d new CheckContext(localFS, expectedPermission);\n \n     // Start parallel disk check operations on all StorageLocations.\n     for (StorageLocation location : dataDirs) {\n       goodLocations.put(location, true);\n-      futures.put(location,\n-          delegateChecker.schedule(location, context));\n+      Optional\u003cListenableFuture\u003cVolumeCheckResult\u003e\u003e olf \u003d\n+          delegateChecker.schedule(location, context);\n+      if (olf.isPresent()) {\n+        futures.put(location, olf.get());\n+      }\n     }\n \n     if (maxVolumeFailuresTolerated \u003e\u003d dataDirs.size()) {\n       throw new DiskErrorException(\"Invalid value configured for \"\n           + DFS_DATANODE_FAILED_VOLUMES_TOLERATED_KEY + \" - \"\n           + maxVolumeFailuresTolerated + \". Value configured is \u003e\u003d \"\n           + \"to the number of configured volumes (\" + dataDirs.size() + \").\");\n     }\n \n     final long checkStartTimeMs \u003d timer.monotonicNow();\n \n     // Retrieve the results of the disk checks.\n     for (Map.Entry\u003cStorageLocation,\n              ListenableFuture\u003cVolumeCheckResult\u003e\u003e entry : futures.entrySet()) {\n \n       // Determine how much time we can allow for this check to complete.\n       // The cumulative wait time cannot exceed maxAllowedTimeForCheck.\n       final long waitSoFarMs \u003d (timer.monotonicNow() - checkStartTimeMs);\n       final long timeLeftMs \u003d Math.max(0,\n           maxAllowedTimeForCheckMs - waitSoFarMs);\n       final StorageLocation location \u003d entry.getKey();\n \n       try {\n         final VolumeCheckResult result \u003d\n             entry.getValue().get(timeLeftMs, TimeUnit.MILLISECONDS);\n         switch (result) {\n         case HEALTHY:\n           break;\n         case DEGRADED:\n           LOG.warn(\"StorageLocation {} appears to be degraded.\", location);\n           break;\n         case FAILED:\n           LOG.warn(\"StorageLocation {} detected as failed.\", location);\n           failedLocations.add(location);\n           goodLocations.remove(location);\n           break;\n         default:\n           LOG.error(\"Unexpected health check result {} for StorageLocation {}\",\n               result, location);\n         }\n       } catch (ExecutionException|TimeoutException e) {\n         LOG.warn(\"Exception checking StorageLocation \" + location,\n             e.getCause());\n         failedLocations.add(location);\n         goodLocations.remove(location);\n       }\n     }\n \n     if (failedLocations.size() \u003e maxVolumeFailuresTolerated) {\n       throw new IOException(\n           \"Too many failed volumes: \" + failedLocations.size() +\n           \". The configuration allows for a maximum of \" +\n           maxVolumeFailuresTolerated + \" failed volumes.\");\n     }\n \n     if (goodLocations.size() \u003d\u003d 0) {\n       throw new IOException(\"All directories in \"\n           + DFS_DATANODE_DATA_DIR_KEY + \" are invalid: \"\n           + failedLocations);\n     }\n \n     return new ArrayList\u003c\u003e(goodLocations.keySet());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public List\u003cStorageLocation\u003e check(\n      final Configuration conf,\n      final Collection\u003cStorageLocation\u003e dataDirs)\n      throws InterruptedException, IOException {\n\n    final HashMap\u003cStorageLocation, Boolean\u003e goodLocations \u003d\n        new LinkedHashMap\u003c\u003e();\n    final Set\u003cStorageLocation\u003e failedLocations \u003d new HashSet\u003c\u003e();\n    final Map\u003cStorageLocation, ListenableFuture\u003cVolumeCheckResult\u003e\u003e futures \u003d\n        Maps.newHashMap();\n    final LocalFileSystem localFS \u003d FileSystem.getLocal(conf);\n    final CheckContext context \u003d new CheckContext(localFS, expectedPermission);\n\n    // Start parallel disk check operations on all StorageLocations.\n    for (StorageLocation location : dataDirs) {\n      goodLocations.put(location, true);\n      Optional\u003cListenableFuture\u003cVolumeCheckResult\u003e\u003e olf \u003d\n          delegateChecker.schedule(location, context);\n      if (olf.isPresent()) {\n        futures.put(location, olf.get());\n      }\n    }\n\n    if (maxVolumeFailuresTolerated \u003e\u003d dataDirs.size()) {\n      throw new DiskErrorException(\"Invalid value configured for \"\n          + DFS_DATANODE_FAILED_VOLUMES_TOLERATED_KEY + \" - \"\n          + maxVolumeFailuresTolerated + \". Value configured is \u003e\u003d \"\n          + \"to the number of configured volumes (\" + dataDirs.size() + \").\");\n    }\n\n    final long checkStartTimeMs \u003d timer.monotonicNow();\n\n    // Retrieve the results of the disk checks.\n    for (Map.Entry\u003cStorageLocation,\n             ListenableFuture\u003cVolumeCheckResult\u003e\u003e entry : futures.entrySet()) {\n\n      // Determine how much time we can allow for this check to complete.\n      // The cumulative wait time cannot exceed maxAllowedTimeForCheck.\n      final long waitSoFarMs \u003d (timer.monotonicNow() - checkStartTimeMs);\n      final long timeLeftMs \u003d Math.max(0,\n          maxAllowedTimeForCheckMs - waitSoFarMs);\n      final StorageLocation location \u003d entry.getKey();\n\n      try {\n        final VolumeCheckResult result \u003d\n            entry.getValue().get(timeLeftMs, TimeUnit.MILLISECONDS);\n        switch (result) {\n        case HEALTHY:\n          break;\n        case DEGRADED:\n          LOG.warn(\"StorageLocation {} appears to be degraded.\", location);\n          break;\n        case FAILED:\n          LOG.warn(\"StorageLocation {} detected as failed.\", location);\n          failedLocations.add(location);\n          goodLocations.remove(location);\n          break;\n        default:\n          LOG.error(\"Unexpected health check result {} for StorageLocation {}\",\n              result, location);\n        }\n      } catch (ExecutionException|TimeoutException e) {\n        LOG.warn(\"Exception checking StorageLocation \" + location,\n            e.getCause());\n        failedLocations.add(location);\n        goodLocations.remove(location);\n      }\n    }\n\n    if (failedLocations.size() \u003e maxVolumeFailuresTolerated) {\n      throw new IOException(\n          \"Too many failed volumes: \" + failedLocations.size() +\n          \". The configuration allows for a maximum of \" +\n          maxVolumeFailuresTolerated + \" failed volumes.\");\n    }\n\n    if (goodLocations.size() \u003d\u003d 0) {\n      throw new IOException(\"All directories in \"\n          + DFS_DATANODE_DATA_DIR_KEY + \" are invalid: \"\n          + failedLocations);\n    }\n\n    return new ArrayList\u003c\u003e(goodLocations.keySet());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/checker/StorageLocationChecker.java",
      "extendedDetails": {}
    },
    "613b902b9808c1c679674047cff15feade01dfab": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11148. Update DataNode to use StorageLocationChecker at startup.\n",
      "commitDate": "22/11/16 10:50 AM",
      "commitName": "613b902b9808c1c679674047cff15feade01dfab",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "11/11/16 3:02 PM",
      "commitNameOld": "3d267177776547ceb32c5b9ed04cd9ec05b3421a",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 10.82,
      "commitsBetweenForRepo": 51,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,72 +1,81 @@\n   public List\u003cStorageLocation\u003e check(\n       final Configuration conf,\n       final Collection\u003cStorageLocation\u003e dataDirs)\n       throws InterruptedException, IOException {\n \n-    final ArrayList\u003cStorageLocation\u003e goodLocations \u003d new ArrayList\u003c\u003e();\n+    final HashMap\u003cStorageLocation, Boolean\u003e goodLocations \u003d\n+        new LinkedHashMap\u003c\u003e();\n     final Set\u003cStorageLocation\u003e failedLocations \u003d new HashSet\u003c\u003e();\n     final Map\u003cStorageLocation, ListenableFuture\u003cVolumeCheckResult\u003e\u003e futures \u003d\n         Maps.newHashMap();\n     final LocalFileSystem localFS \u003d FileSystem.getLocal(conf);\n     final CheckContext context \u003d new CheckContext(localFS, expectedPermission);\n \n     // Start parallel disk check operations on all StorageLocations.\n     for (StorageLocation location : dataDirs) {\n+      goodLocations.put(location, true);\n       futures.put(location,\n           delegateChecker.schedule(location, context));\n     }\n \n+    if (maxVolumeFailuresTolerated \u003e\u003d dataDirs.size()) {\n+      throw new DiskErrorException(\"Invalid value configured for \"\n+          + DFS_DATANODE_FAILED_VOLUMES_TOLERATED_KEY + \" - \"\n+          + maxVolumeFailuresTolerated + \". Value configured is \u003e\u003d \"\n+          + \"to the number of configured volumes (\" + dataDirs.size() + \").\");\n+    }\n+\n     final long checkStartTimeMs \u003d timer.monotonicNow();\n \n     // Retrieve the results of the disk checks.\n     for (Map.Entry\u003cStorageLocation,\n              ListenableFuture\u003cVolumeCheckResult\u003e\u003e entry : futures.entrySet()) {\n \n       // Determine how much time we can allow for this check to complete.\n       // The cumulative wait time cannot exceed maxAllowedTimeForCheck.\n       final long waitSoFarMs \u003d (timer.monotonicNow() - checkStartTimeMs);\n       final long timeLeftMs \u003d Math.max(0,\n           maxAllowedTimeForCheckMs - waitSoFarMs);\n       final StorageLocation location \u003d entry.getKey();\n \n       try {\n         final VolumeCheckResult result \u003d\n             entry.getValue().get(timeLeftMs, TimeUnit.MILLISECONDS);\n         switch (result) {\n         case HEALTHY:\n-          goodLocations.add(entry.getKey());\n           break;\n         case DEGRADED:\n           LOG.warn(\"StorageLocation {} appears to be degraded.\", location);\n           break;\n         case FAILED:\n           LOG.warn(\"StorageLocation {} detected as failed.\", location);\n           failedLocations.add(location);\n+          goodLocations.remove(location);\n           break;\n         default:\n           LOG.error(\"Unexpected health check result {} for StorageLocation {}\",\n               result, location);\n-          goodLocations.add(entry.getKey());\n         }\n       } catch (ExecutionException|TimeoutException e) {\n         LOG.warn(\"Exception checking StorageLocation \" + location,\n             e.getCause());\n         failedLocations.add(location);\n+        goodLocations.remove(location);\n       }\n     }\n \n     if (failedLocations.size() \u003e maxVolumeFailuresTolerated) {\n       throw new IOException(\n           \"Too many failed volumes: \" + failedLocations.size() +\n           \". The configuration allows for a maximum of \" +\n           maxVolumeFailuresTolerated + \" failed volumes.\");\n     }\n \n     if (goodLocations.size() \u003d\u003d 0) {\n       throw new IOException(\"All directories in \"\n           + DFS_DATANODE_DATA_DIR_KEY + \" are invalid: \"\n           + failedLocations);\n     }\n \n-    return goodLocations;\n+    return new ArrayList\u003c\u003e(goodLocations.keySet());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public List\u003cStorageLocation\u003e check(\n      final Configuration conf,\n      final Collection\u003cStorageLocation\u003e dataDirs)\n      throws InterruptedException, IOException {\n\n    final HashMap\u003cStorageLocation, Boolean\u003e goodLocations \u003d\n        new LinkedHashMap\u003c\u003e();\n    final Set\u003cStorageLocation\u003e failedLocations \u003d new HashSet\u003c\u003e();\n    final Map\u003cStorageLocation, ListenableFuture\u003cVolumeCheckResult\u003e\u003e futures \u003d\n        Maps.newHashMap();\n    final LocalFileSystem localFS \u003d FileSystem.getLocal(conf);\n    final CheckContext context \u003d new CheckContext(localFS, expectedPermission);\n\n    // Start parallel disk check operations on all StorageLocations.\n    for (StorageLocation location : dataDirs) {\n      goodLocations.put(location, true);\n      futures.put(location,\n          delegateChecker.schedule(location, context));\n    }\n\n    if (maxVolumeFailuresTolerated \u003e\u003d dataDirs.size()) {\n      throw new DiskErrorException(\"Invalid value configured for \"\n          + DFS_DATANODE_FAILED_VOLUMES_TOLERATED_KEY + \" - \"\n          + maxVolumeFailuresTolerated + \". Value configured is \u003e\u003d \"\n          + \"to the number of configured volumes (\" + dataDirs.size() + \").\");\n    }\n\n    final long checkStartTimeMs \u003d timer.monotonicNow();\n\n    // Retrieve the results of the disk checks.\n    for (Map.Entry\u003cStorageLocation,\n             ListenableFuture\u003cVolumeCheckResult\u003e\u003e entry : futures.entrySet()) {\n\n      // Determine how much time we can allow for this check to complete.\n      // The cumulative wait time cannot exceed maxAllowedTimeForCheck.\n      final long waitSoFarMs \u003d (timer.monotonicNow() - checkStartTimeMs);\n      final long timeLeftMs \u003d Math.max(0,\n          maxAllowedTimeForCheckMs - waitSoFarMs);\n      final StorageLocation location \u003d entry.getKey();\n\n      try {\n        final VolumeCheckResult result \u003d\n            entry.getValue().get(timeLeftMs, TimeUnit.MILLISECONDS);\n        switch (result) {\n        case HEALTHY:\n          break;\n        case DEGRADED:\n          LOG.warn(\"StorageLocation {} appears to be degraded.\", location);\n          break;\n        case FAILED:\n          LOG.warn(\"StorageLocation {} detected as failed.\", location);\n          failedLocations.add(location);\n          goodLocations.remove(location);\n          break;\n        default:\n          LOG.error(\"Unexpected health check result {} for StorageLocation {}\",\n              result, location);\n        }\n      } catch (ExecutionException|TimeoutException e) {\n        LOG.warn(\"Exception checking StorageLocation \" + location,\n            e.getCause());\n        failedLocations.add(location);\n        goodLocations.remove(location);\n      }\n    }\n\n    if (failedLocations.size() \u003e maxVolumeFailuresTolerated) {\n      throw new IOException(\n          \"Too many failed volumes: \" + failedLocations.size() +\n          \". The configuration allows for a maximum of \" +\n          maxVolumeFailuresTolerated + \" failed volumes.\");\n    }\n\n    if (goodLocations.size() \u003d\u003d 0) {\n      throw new IOException(\"All directories in \"\n          + DFS_DATANODE_DATA_DIR_KEY + \" are invalid: \"\n          + failedLocations);\n    }\n\n    return new ArrayList\u003c\u003e(goodLocations.keySet());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/checker/StorageLocationChecker.java",
      "extendedDetails": {}
    },
    "3d267177776547ceb32c5b9ed04cd9ec05b3421a": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-11119. Support for parallel checking of StorageLocations on DataNode startup.\n\nThis closes #155.\n",
      "commitDate": "11/11/16 3:02 PM",
      "commitName": "3d267177776547ceb32c5b9ed04cd9ec05b3421a",
      "commitAuthor": "Arpit Agarwal",
      "diff": "@@ -0,0 +1,72 @@\n+  public List\u003cStorageLocation\u003e check(\n+      final Configuration conf,\n+      final Collection\u003cStorageLocation\u003e dataDirs)\n+      throws InterruptedException, IOException {\n+\n+    final ArrayList\u003cStorageLocation\u003e goodLocations \u003d new ArrayList\u003c\u003e();\n+    final Set\u003cStorageLocation\u003e failedLocations \u003d new HashSet\u003c\u003e();\n+    final Map\u003cStorageLocation, ListenableFuture\u003cVolumeCheckResult\u003e\u003e futures \u003d\n+        Maps.newHashMap();\n+    final LocalFileSystem localFS \u003d FileSystem.getLocal(conf);\n+    final CheckContext context \u003d new CheckContext(localFS, expectedPermission);\n+\n+    // Start parallel disk check operations on all StorageLocations.\n+    for (StorageLocation location : dataDirs) {\n+      futures.put(location,\n+          delegateChecker.schedule(location, context));\n+    }\n+\n+    final long checkStartTimeMs \u003d timer.monotonicNow();\n+\n+    // Retrieve the results of the disk checks.\n+    for (Map.Entry\u003cStorageLocation,\n+             ListenableFuture\u003cVolumeCheckResult\u003e\u003e entry : futures.entrySet()) {\n+\n+      // Determine how much time we can allow for this check to complete.\n+      // The cumulative wait time cannot exceed maxAllowedTimeForCheck.\n+      final long waitSoFarMs \u003d (timer.monotonicNow() - checkStartTimeMs);\n+      final long timeLeftMs \u003d Math.max(0,\n+          maxAllowedTimeForCheckMs - waitSoFarMs);\n+      final StorageLocation location \u003d entry.getKey();\n+\n+      try {\n+        final VolumeCheckResult result \u003d\n+            entry.getValue().get(timeLeftMs, TimeUnit.MILLISECONDS);\n+        switch (result) {\n+        case HEALTHY:\n+          goodLocations.add(entry.getKey());\n+          break;\n+        case DEGRADED:\n+          LOG.warn(\"StorageLocation {} appears to be degraded.\", location);\n+          break;\n+        case FAILED:\n+          LOG.warn(\"StorageLocation {} detected as failed.\", location);\n+          failedLocations.add(location);\n+          break;\n+        default:\n+          LOG.error(\"Unexpected health check result {} for StorageLocation {}\",\n+              result, location);\n+          goodLocations.add(entry.getKey());\n+        }\n+      } catch (ExecutionException|TimeoutException e) {\n+        LOG.warn(\"Exception checking StorageLocation \" + location,\n+            e.getCause());\n+        failedLocations.add(location);\n+      }\n+    }\n+\n+    if (failedLocations.size() \u003e maxVolumeFailuresTolerated) {\n+      throw new IOException(\n+          \"Too many failed volumes: \" + failedLocations.size() +\n+          \". The configuration allows for a maximum of \" +\n+          maxVolumeFailuresTolerated + \" failed volumes.\");\n+    }\n+\n+    if (goodLocations.size() \u003d\u003d 0) {\n+      throw new IOException(\"All directories in \"\n+          + DFS_DATANODE_DATA_DIR_KEY + \" are invalid: \"\n+          + failedLocations);\n+    }\n+\n+    return goodLocations;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public List\u003cStorageLocation\u003e check(\n      final Configuration conf,\n      final Collection\u003cStorageLocation\u003e dataDirs)\n      throws InterruptedException, IOException {\n\n    final ArrayList\u003cStorageLocation\u003e goodLocations \u003d new ArrayList\u003c\u003e();\n    final Set\u003cStorageLocation\u003e failedLocations \u003d new HashSet\u003c\u003e();\n    final Map\u003cStorageLocation, ListenableFuture\u003cVolumeCheckResult\u003e\u003e futures \u003d\n        Maps.newHashMap();\n    final LocalFileSystem localFS \u003d FileSystem.getLocal(conf);\n    final CheckContext context \u003d new CheckContext(localFS, expectedPermission);\n\n    // Start parallel disk check operations on all StorageLocations.\n    for (StorageLocation location : dataDirs) {\n      futures.put(location,\n          delegateChecker.schedule(location, context));\n    }\n\n    final long checkStartTimeMs \u003d timer.monotonicNow();\n\n    // Retrieve the results of the disk checks.\n    for (Map.Entry\u003cStorageLocation,\n             ListenableFuture\u003cVolumeCheckResult\u003e\u003e entry : futures.entrySet()) {\n\n      // Determine how much time we can allow for this check to complete.\n      // The cumulative wait time cannot exceed maxAllowedTimeForCheck.\n      final long waitSoFarMs \u003d (timer.monotonicNow() - checkStartTimeMs);\n      final long timeLeftMs \u003d Math.max(0,\n          maxAllowedTimeForCheckMs - waitSoFarMs);\n      final StorageLocation location \u003d entry.getKey();\n\n      try {\n        final VolumeCheckResult result \u003d\n            entry.getValue().get(timeLeftMs, TimeUnit.MILLISECONDS);\n        switch (result) {\n        case HEALTHY:\n          goodLocations.add(entry.getKey());\n          break;\n        case DEGRADED:\n          LOG.warn(\"StorageLocation {} appears to be degraded.\", location);\n          break;\n        case FAILED:\n          LOG.warn(\"StorageLocation {} detected as failed.\", location);\n          failedLocations.add(location);\n          break;\n        default:\n          LOG.error(\"Unexpected health check result {} for StorageLocation {}\",\n              result, location);\n          goodLocations.add(entry.getKey());\n        }\n      } catch (ExecutionException|TimeoutException e) {\n        LOG.warn(\"Exception checking StorageLocation \" + location,\n            e.getCause());\n        failedLocations.add(location);\n      }\n    }\n\n    if (failedLocations.size() \u003e maxVolumeFailuresTolerated) {\n      throw new IOException(\n          \"Too many failed volumes: \" + failedLocations.size() +\n          \". The configuration allows for a maximum of \" +\n          maxVolumeFailuresTolerated + \" failed volumes.\");\n    }\n\n    if (goodLocations.size() \u003d\u003d 0) {\n      throw new IOException(\"All directories in \"\n          + DFS_DATANODE_DATA_DIR_KEY + \" are invalid: \"\n          + failedLocations);\n    }\n\n    return goodLocations;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/checker/StorageLocationChecker.java"
    }
  }
}