{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSNamesystem.java",
  "functionName": "startActiveServices",
  "functionId": "startActiveServices",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
  "functionStartLine": 1313,
  "functionEndLine": 1407,
  "numCommitsSeen": 873,
  "timeTaken": 54183,
  "changeHistory": [
    "dd900259c421d6edd0b89a535a1fe08ada91735f",
    "2acc50b826fa8b00f2b09d9546c4b3215b89d46d",
    "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52",
    "b0cb8d9bb44c963ae686d2b5c1b70bc76b955e10",
    "8d4f74e7339abc77dc0daa162d7bd2814bd79b3d",
    "0e820f16af309cc8476edba448dd548686431133",
    "681d2804c95e5a569ffb8d9ceafaf5a4f8be2b88",
    "1000a2af04b24c123a3b08168f36b4e90420cab7",
    "ff0b99eafeda035ebe0dc82cfe689808047a8893",
    "221b3a8722f84f8e9ad0a98eea38a12cc4ad2f24",
    "e3bb38d62567eafe57d16b78deeba1b71c58e41c",
    "a49cc74b4c72195dee1dfb6f9548e5e411dff553",
    "a40342b0dab1f9137ae4b3679a5aca7f2a57d23d",
    "715b9c649982bff91d1f9eae656ba3b82178e1a3",
    "71de367c5e80ea76d1e8d21f0216cd6b879dcee5",
    "64d30a61867e5cb0a2acaa7ae4fa4d3eb3be8edd",
    "9e355719653c5e7b48b601090634882e4f29a743",
    "2e987148e02d0087fc70ce5b1ce571d3324bf1dd",
    "9ca79e8d327e95845ef9794396afd43a52bc3d40",
    "fe328621d4a84ae99efcb6394a910009b4e1761f",
    "d85c017d0488930d806f267141057fc73e68c728",
    "788fca4124ecac818a20bfc2607676849cf0d94f",
    "3c591aa442d342bdd4a0c4abe9a43c64d8ef3e65",
    "3b91b7dece84b563a4b7cf66c245b7c5ee094578",
    "34f08944b7c8d58f531a3f3bf3d4ee4cd3fa643a",
    "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a",
    "f7eaacc103344f5fd81dd69584c93fb99d8b94c9",
    "40eb94ade3161d93e7a762a839004748f6d0ae89",
    "b3e42a1ed56f83e2cc35e58f2ffd02c9ff3821e0",
    "cea7bbc630deede93dbe6a1bbda56ad49de4f3de",
    "23b6ed973e1ff5ace1e3a97cded008908e8daa55",
    "b98e26af58b78d0cfb233b2b596ebf71b3e148fb"
  ],
  "changeHistoryShort": {
    "dd900259c421d6edd0b89a535a1fe08ada91735f": "Ybodychange",
    "2acc50b826fa8b00f2b09d9546c4b3215b89d46d": "Ybodychange",
    "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52": "Ybodychange",
    "b0cb8d9bb44c963ae686d2b5c1b70bc76b955e10": "Ybodychange",
    "8d4f74e7339abc77dc0daa162d7bd2814bd79b3d": "Ybodychange",
    "0e820f16af309cc8476edba448dd548686431133": "Ybodychange",
    "681d2804c95e5a569ffb8d9ceafaf5a4f8be2b88": "Ybodychange",
    "1000a2af04b24c123a3b08168f36b4e90420cab7": "Ybodychange",
    "ff0b99eafeda035ebe0dc82cfe689808047a8893": "Ybodychange",
    "221b3a8722f84f8e9ad0a98eea38a12cc4ad2f24": "Ybodychange",
    "e3bb38d62567eafe57d16b78deeba1b71c58e41c": "Ybodychange",
    "a49cc74b4c72195dee1dfb6f9548e5e411dff553": "Ybodychange",
    "a40342b0dab1f9137ae4b3679a5aca7f2a57d23d": "Ybodychange",
    "715b9c649982bff91d1f9eae656ba3b82178e1a3": "Ybodychange",
    "71de367c5e80ea76d1e8d21f0216cd6b879dcee5": "Ybodychange",
    "64d30a61867e5cb0a2acaa7ae4fa4d3eb3be8edd": "Ybodychange",
    "9e355719653c5e7b48b601090634882e4f29a743": "Ybodychange",
    "2e987148e02d0087fc70ce5b1ce571d3324bf1dd": "Ybodychange",
    "9ca79e8d327e95845ef9794396afd43a52bc3d40": "Ybodychange",
    "fe328621d4a84ae99efcb6394a910009b4e1761f": "Ybodychange",
    "d85c017d0488930d806f267141057fc73e68c728": "Ybodychange",
    "788fca4124ecac818a20bfc2607676849cf0d94f": "Ybodychange",
    "3c591aa442d342bdd4a0c4abe9a43c64d8ef3e65": "Ybodychange",
    "3b91b7dece84b563a4b7cf66c245b7c5ee094578": "Ybodychange",
    "34f08944b7c8d58f531a3f3bf3d4ee4cd3fa643a": "Ybodychange",
    "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a": "Ybodychange",
    "f7eaacc103344f5fd81dd69584c93fb99d8b94c9": "Ybodychange",
    "40eb94ade3161d93e7a762a839004748f6d0ae89": "Ybodychange",
    "b3e42a1ed56f83e2cc35e58f2ffd02c9ff3821e0": "Ybodychange",
    "cea7bbc630deede93dbe6a1bbda56ad49de4f3de": "Ybodychange",
    "23b6ed973e1ff5ace1e3a97cded008908e8daa55": "Ybodychange",
    "b98e26af58b78d0cfb233b2b596ebf71b3e148fb": "Ybodychange"
  },
  "changeHistoryDetails": {
    "dd900259c421d6edd0b89a535a1fe08ada91735f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14941. Potential editlog race condition can cause corrupted file. Contributed by Chen Liang and Konstantin Shvachko.\n",
      "commitDate": "06/11/19 9:56 AM",
      "commitName": "dd900259c421d6edd0b89a535a1fe08ada91735f",
      "commitAuthor": "Chen Liang",
      "commitDateOld": "22/10/19 6:14 AM",
      "commitNameOld": "6020505943fbb6133f7c2747e6d85d79cde788ea",
      "commitAuthorOld": "Ayush Saxena",
      "daysBetweenCommits": 15.2,
      "commitsBetweenForRepo": 52,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,94 +1,95 @@\n   void startActiveServices() throws IOException {\n     startingActiveService \u003d true;\n     LOG.info(\"Starting services required for active state\");\n     writeLock();\n     try {\n       FSEditLog editLog \u003d getFSImage().getEditLog();\n       \n       if (!editLog.isOpenForWrite()) {\n         // During startup, we\u0027re already open for write during initialization.\n         editLog.initJournalsForWrite();\n         // May need to recover\n         editLog.recoverUnclosedStreams();\n         \n         LOG.info(\"Catching up to latest edits from old active before \" +\n             \"taking over writer role in edits logs\");\n         editLogTailer.catchupDuringFailover();\n         \n         blockManager.setPostponeBlocksFromFuture(false);\n         blockManager.getDatanodeManager().markAllDatanodesStale();\n         blockManager.clearQueues();\n         blockManager.processAllPendingDNMessages();\n+        blockManager.getBlockIdManager().applyImpendingGenerationStamp();\n \n         // Only need to re-process the queue, If not in SafeMode.\n         if (!isInSafeMode()) {\n           LOG.info(\"Reprocessing replication and invalidation queues\");\n           blockManager.initializeReplQueues();\n         }\n \n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"NameNode metadata after re-processing \" +\n               \"replication and invalidation queues during failover:\\n\" +\n               metaSaveAsString());\n         }\n \n         long nextTxId \u003d getFSImage().getLastAppliedTxId() + 1;\n         LOG.info(\"Will take over writing edit logs at txnid \" + \n             nextTxId);\n         editLog.setNextTxId(nextTxId);\n \n         getFSImage().editLog.openForWrite(getEffectiveLayoutVersion());\n       }\n \n       // Initialize the quota.\n       dir.updateCountForQuota();\n       // Enable quota checks.\n       dir.enableQuotaChecks();\n       dir.ezManager.startReencryptThreads();\n \n       if (haEnabled) {\n         // Renew all of the leases before becoming active.\n         // This is because, while we were in standby mode,\n         // the leases weren\u0027t getting renewed on this NN.\n         // Give them all a fresh start here.\n         leaseManager.renewAllLeases();\n       }\n       leaseManager.startMonitor();\n       startSecretManagerIfNecessary();\n \n       //ResourceMonitor required only at ActiveNN. See HDFS-2914\n       this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n       nnrmthread.start();\n \n       nnEditLogRoller \u003d new Daemon(new NameNodeEditLogRoller(\n           editLogRollerThreshold, editLogRollerInterval));\n       nnEditLogRoller.start();\n \n       if (lazyPersistFileScrubIntervalSec \u003e 0) {\n         lazyPersistFileScrubber \u003d new Daemon(new LazyPersistFileScrubber(\n             lazyPersistFileScrubIntervalSec));\n         lazyPersistFileScrubber.start();\n       } else {\n         LOG.warn(\"Lazy persist file scrubber is disabled,\"\n             + \" configured scrub interval is zero.\");\n       }\n \n       cacheManager.startMonitorThread();\n       blockManager.getDatanodeManager().setShouldSendCachingCommands(true);\n       if (provider !\u003d null) {\n         edekCacheLoader \u003d Executors.newSingleThreadExecutor(\n             new ThreadFactoryBuilder().setDaemon(true)\n                 .setNameFormat(\"Warm Up EDEK Cache Thread #%d\")\n                 .build());\n         FSDirEncryptionZoneOp.warmUpEdekCache(edekCacheLoader, dir,\n             edekCacheLoaderDelay, edekCacheLoaderInterval);\n       }\n       if (blockManager.getSPSManager() !\u003d null) {\n         blockManager.getSPSManager().start();\n       }\n     } finally {\n       startingActiveService \u003d false;\n       blockManager.checkSafeMode();\n       writeUnlock(\"startActiveServices\");\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void startActiveServices() throws IOException {\n    startingActiveService \u003d true;\n    LOG.info(\"Starting services required for active state\");\n    writeLock();\n    try {\n      FSEditLog editLog \u003d getFSImage().getEditLog();\n      \n      if (!editLog.isOpenForWrite()) {\n        // During startup, we\u0027re already open for write during initialization.\n        editLog.initJournalsForWrite();\n        // May need to recover\n        editLog.recoverUnclosedStreams();\n        \n        LOG.info(\"Catching up to latest edits from old active before \" +\n            \"taking over writer role in edits logs\");\n        editLogTailer.catchupDuringFailover();\n        \n        blockManager.setPostponeBlocksFromFuture(false);\n        blockManager.getDatanodeManager().markAllDatanodesStale();\n        blockManager.clearQueues();\n        blockManager.processAllPendingDNMessages();\n        blockManager.getBlockIdManager().applyImpendingGenerationStamp();\n\n        // Only need to re-process the queue, If not in SafeMode.\n        if (!isInSafeMode()) {\n          LOG.info(\"Reprocessing replication and invalidation queues\");\n          blockManager.initializeReplQueues();\n        }\n\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"NameNode metadata after re-processing \" +\n              \"replication and invalidation queues during failover:\\n\" +\n              metaSaveAsString());\n        }\n\n        long nextTxId \u003d getFSImage().getLastAppliedTxId() + 1;\n        LOG.info(\"Will take over writing edit logs at txnid \" + \n            nextTxId);\n        editLog.setNextTxId(nextTxId);\n\n        getFSImage().editLog.openForWrite(getEffectiveLayoutVersion());\n      }\n\n      // Initialize the quota.\n      dir.updateCountForQuota();\n      // Enable quota checks.\n      dir.enableQuotaChecks();\n      dir.ezManager.startReencryptThreads();\n\n      if (haEnabled) {\n        // Renew all of the leases before becoming active.\n        // This is because, while we were in standby mode,\n        // the leases weren\u0027t getting renewed on this NN.\n        // Give them all a fresh start here.\n        leaseManager.renewAllLeases();\n      }\n      leaseManager.startMonitor();\n      startSecretManagerIfNecessary();\n\n      //ResourceMonitor required only at ActiveNN. See HDFS-2914\n      this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n      nnrmthread.start();\n\n      nnEditLogRoller \u003d new Daemon(new NameNodeEditLogRoller(\n          editLogRollerThreshold, editLogRollerInterval));\n      nnEditLogRoller.start();\n\n      if (lazyPersistFileScrubIntervalSec \u003e 0) {\n        lazyPersistFileScrubber \u003d new Daemon(new LazyPersistFileScrubber(\n            lazyPersistFileScrubIntervalSec));\n        lazyPersistFileScrubber.start();\n      } else {\n        LOG.warn(\"Lazy persist file scrubber is disabled,\"\n            + \" configured scrub interval is zero.\");\n      }\n\n      cacheManager.startMonitorThread();\n      blockManager.getDatanodeManager().setShouldSendCachingCommands(true);\n      if (provider !\u003d null) {\n        edekCacheLoader \u003d Executors.newSingleThreadExecutor(\n            new ThreadFactoryBuilder().setDaemon(true)\n                .setNameFormat(\"Warm Up EDEK Cache Thread #%d\")\n                .build());\n        FSDirEncryptionZoneOp.warmUpEdekCache(edekCacheLoader, dir,\n            edekCacheLoaderDelay, edekCacheLoaderInterval);\n      }\n      if (blockManager.getSPSManager() !\u003d null) {\n        blockManager.getSPSManager().start();\n      }\n    } finally {\n      startingActiveService \u003d false;\n      blockManager.checkSafeMode();\n      writeUnlock(\"startActiveServices\");\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "2acc50b826fa8b00f2b09d9546c4b3215b89d46d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13165: [SPS]: Collects successfully moved block details via IBR. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "2acc50b826fa8b00f2b09d9546c4b3215b89d46d",
      "commitAuthor": "Rakesh Radhakrishnan",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,92 +1,94 @@\n   void startActiveServices() throws IOException {\n     startingActiveService \u003d true;\n     LOG.info(\"Starting services required for active state\");\n     writeLock();\n     try {\n       FSEditLog editLog \u003d getFSImage().getEditLog();\n       \n       if (!editLog.isOpenForWrite()) {\n         // During startup, we\u0027re already open for write during initialization.\n         editLog.initJournalsForWrite();\n         // May need to recover\n         editLog.recoverUnclosedStreams();\n         \n         LOG.info(\"Catching up to latest edits from old active before \" +\n             \"taking over writer role in edits logs\");\n         editLogTailer.catchupDuringFailover();\n         \n         blockManager.setPostponeBlocksFromFuture(false);\n         blockManager.getDatanodeManager().markAllDatanodesStale();\n         blockManager.clearQueues();\n         blockManager.processAllPendingDNMessages();\n \n         // Only need to re-process the queue, If not in SafeMode.\n         if (!isInSafeMode()) {\n           LOG.info(\"Reprocessing replication and invalidation queues\");\n           blockManager.initializeReplQueues();\n         }\n \n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"NameNode metadata after re-processing \" +\n               \"replication and invalidation queues during failover:\\n\" +\n               metaSaveAsString());\n         }\n \n         long nextTxId \u003d getFSImage().getLastAppliedTxId() + 1;\n         LOG.info(\"Will take over writing edit logs at txnid \" + \n             nextTxId);\n         editLog.setNextTxId(nextTxId);\n \n         getFSImage().editLog.openForWrite(getEffectiveLayoutVersion());\n       }\n \n       // Initialize the quota.\n       dir.updateCountForQuota();\n       // Enable quota checks.\n       dir.enableQuotaChecks();\n       dir.ezManager.startReencryptThreads();\n \n       if (haEnabled) {\n         // Renew all of the leases before becoming active.\n         // This is because, while we were in standby mode,\n         // the leases weren\u0027t getting renewed on this NN.\n         // Give them all a fresh start here.\n         leaseManager.renewAllLeases();\n       }\n       leaseManager.startMonitor();\n       startSecretManagerIfNecessary();\n \n       //ResourceMonitor required only at ActiveNN. See HDFS-2914\n       this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n       nnrmthread.start();\n \n       nnEditLogRoller \u003d new Daemon(new NameNodeEditLogRoller(\n           editLogRollerThreshold, editLogRollerInterval));\n       nnEditLogRoller.start();\n \n       if (lazyPersistFileScrubIntervalSec \u003e 0) {\n         lazyPersistFileScrubber \u003d new Daemon(new LazyPersistFileScrubber(\n             lazyPersistFileScrubIntervalSec));\n         lazyPersistFileScrubber.start();\n       } else {\n         LOG.warn(\"Lazy persist file scrubber is disabled,\"\n             + \" configured scrub interval is zero.\");\n       }\n \n       cacheManager.startMonitorThread();\n       blockManager.getDatanodeManager().setShouldSendCachingCommands(true);\n       if (provider !\u003d null) {\n         edekCacheLoader \u003d Executors.newSingleThreadExecutor(\n             new ThreadFactoryBuilder().setDaemon(true)\n                 .setNameFormat(\"Warm Up EDEK Cache Thread #%d\")\n                 .build());\n         FSDirEncryptionZoneOp.warmUpEdekCache(edekCacheLoader, dir,\n             edekCacheLoaderDelay, edekCacheLoaderInterval);\n       }\n-      blockManager.getSPSManager().start();\n+      if (blockManager.getSPSManager() !\u003d null) {\n+        blockManager.getSPSManager().start();\n+      }\n     } finally {\n       startingActiveService \u003d false;\n       blockManager.checkSafeMode();\n       writeUnlock(\"startActiveServices\");\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void startActiveServices() throws IOException {\n    startingActiveService \u003d true;\n    LOG.info(\"Starting services required for active state\");\n    writeLock();\n    try {\n      FSEditLog editLog \u003d getFSImage().getEditLog();\n      \n      if (!editLog.isOpenForWrite()) {\n        // During startup, we\u0027re already open for write during initialization.\n        editLog.initJournalsForWrite();\n        // May need to recover\n        editLog.recoverUnclosedStreams();\n        \n        LOG.info(\"Catching up to latest edits from old active before \" +\n            \"taking over writer role in edits logs\");\n        editLogTailer.catchupDuringFailover();\n        \n        blockManager.setPostponeBlocksFromFuture(false);\n        blockManager.getDatanodeManager().markAllDatanodesStale();\n        blockManager.clearQueues();\n        blockManager.processAllPendingDNMessages();\n\n        // Only need to re-process the queue, If not in SafeMode.\n        if (!isInSafeMode()) {\n          LOG.info(\"Reprocessing replication and invalidation queues\");\n          blockManager.initializeReplQueues();\n        }\n\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"NameNode metadata after re-processing \" +\n              \"replication and invalidation queues during failover:\\n\" +\n              metaSaveAsString());\n        }\n\n        long nextTxId \u003d getFSImage().getLastAppliedTxId() + 1;\n        LOG.info(\"Will take over writing edit logs at txnid \" + \n            nextTxId);\n        editLog.setNextTxId(nextTxId);\n\n        getFSImage().editLog.openForWrite(getEffectiveLayoutVersion());\n      }\n\n      // Initialize the quota.\n      dir.updateCountForQuota();\n      // Enable quota checks.\n      dir.enableQuotaChecks();\n      dir.ezManager.startReencryptThreads();\n\n      if (haEnabled) {\n        // Renew all of the leases before becoming active.\n        // This is because, while we were in standby mode,\n        // the leases weren\u0027t getting renewed on this NN.\n        // Give them all a fresh start here.\n        leaseManager.renewAllLeases();\n      }\n      leaseManager.startMonitor();\n      startSecretManagerIfNecessary();\n\n      //ResourceMonitor required only at ActiveNN. See HDFS-2914\n      this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n      nnrmthread.start();\n\n      nnEditLogRoller \u003d new Daemon(new NameNodeEditLogRoller(\n          editLogRollerThreshold, editLogRollerInterval));\n      nnEditLogRoller.start();\n\n      if (lazyPersistFileScrubIntervalSec \u003e 0) {\n        lazyPersistFileScrubber \u003d new Daemon(new LazyPersistFileScrubber(\n            lazyPersistFileScrubIntervalSec));\n        lazyPersistFileScrubber.start();\n      } else {\n        LOG.warn(\"Lazy persist file scrubber is disabled,\"\n            + \" configured scrub interval is zero.\");\n      }\n\n      cacheManager.startMonitorThread();\n      blockManager.getDatanodeManager().setShouldSendCachingCommands(true);\n      if (provider !\u003d null) {\n        edekCacheLoader \u003d Executors.newSingleThreadExecutor(\n            new ThreadFactoryBuilder().setDaemon(true)\n                .setNameFormat(\"Warm Up EDEK Cache Thread #%d\")\n                .build());\n        FSDirEncryptionZoneOp.warmUpEdekCache(edekCacheLoader, dir,\n            edekCacheLoaderDelay, edekCacheLoaderInterval);\n      }\n      if (blockManager.getSPSManager() !\u003d null) {\n        blockManager.getSPSManager().start();\n      }\n    } finally {\n      startingActiveService \u003d false;\n      blockManager.checkSafeMode();\n      writeUnlock(\"startActiveServices\");\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13097: [SPS]: Fix the branch review comments(Part1). Contributed by Surendra Singh.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "d3de4fb2a084cbadab8ef91f11aa7732d3b0f308",
      "commitAuthorOld": "Surendra Singh Lilhore",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,98 +1,92 @@\n   void startActiveServices() throws IOException {\n     startingActiveService \u003d true;\n     LOG.info(\"Starting services required for active state\");\n     writeLock();\n     try {\n       FSEditLog editLog \u003d getFSImage().getEditLog();\n       \n       if (!editLog.isOpenForWrite()) {\n         // During startup, we\u0027re already open for write during initialization.\n         editLog.initJournalsForWrite();\n         // May need to recover\n         editLog.recoverUnclosedStreams();\n         \n         LOG.info(\"Catching up to latest edits from old active before \" +\n             \"taking over writer role in edits logs\");\n         editLogTailer.catchupDuringFailover();\n         \n         blockManager.setPostponeBlocksFromFuture(false);\n         blockManager.getDatanodeManager().markAllDatanodesStale();\n         blockManager.clearQueues();\n         blockManager.processAllPendingDNMessages();\n \n         // Only need to re-process the queue, If not in SafeMode.\n         if (!isInSafeMode()) {\n           LOG.info(\"Reprocessing replication and invalidation queues\");\n           blockManager.initializeReplQueues();\n         }\n \n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"NameNode metadata after re-processing \" +\n               \"replication and invalidation queues during failover:\\n\" +\n               metaSaveAsString());\n         }\n \n         long nextTxId \u003d getFSImage().getLastAppliedTxId() + 1;\n         LOG.info(\"Will take over writing edit logs at txnid \" + \n             nextTxId);\n         editLog.setNextTxId(nextTxId);\n \n         getFSImage().editLog.openForWrite(getEffectiveLayoutVersion());\n       }\n \n       // Initialize the quota.\n       dir.updateCountForQuota();\n       // Enable quota checks.\n       dir.enableQuotaChecks();\n       dir.ezManager.startReencryptThreads();\n \n       if (haEnabled) {\n         // Renew all of the leases before becoming active.\n         // This is because, while we were in standby mode,\n         // the leases weren\u0027t getting renewed on this NN.\n         // Give them all a fresh start here.\n         leaseManager.renewAllLeases();\n       }\n       leaseManager.startMonitor();\n       startSecretManagerIfNecessary();\n \n       //ResourceMonitor required only at ActiveNN. See HDFS-2914\n       this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n       nnrmthread.start();\n \n       nnEditLogRoller \u003d new Daemon(new NameNodeEditLogRoller(\n           editLogRollerThreshold, editLogRollerInterval));\n       nnEditLogRoller.start();\n \n       if (lazyPersistFileScrubIntervalSec \u003e 0) {\n         lazyPersistFileScrubber \u003d new Daemon(new LazyPersistFileScrubber(\n             lazyPersistFileScrubIntervalSec));\n         lazyPersistFileScrubber.start();\n       } else {\n         LOG.warn(\"Lazy persist file scrubber is disabled,\"\n             + \" configured scrub interval is zero.\");\n       }\n \n       cacheManager.startMonitorThread();\n       blockManager.getDatanodeManager().setShouldSendCachingCommands(true);\n       if (provider !\u003d null) {\n         edekCacheLoader \u003d Executors.newSingleThreadExecutor(\n             new ThreadFactoryBuilder().setDaemon(true)\n                 .setNameFormat(\"Warm Up EDEK Cache Thread #%d\")\n                 .build());\n         FSDirEncryptionZoneOp.warmUpEdekCache(edekCacheLoader, dir,\n             edekCacheLoaderDelay, edekCacheLoaderInterval);\n       }\n-      blockManager.getSPSService().init(\n-          new IntraSPSNameNodeContext(this, blockManager,\n-              blockManager.getSPSService()),\n-          new IntraSPSNameNodeFileIdCollector(getFSDirectory(),\n-              blockManager.getSPSService()),\n-          new IntraSPSNameNodeBlockMoveTaskHandler(blockManager, this), null);\n-      blockManager.startSPS();\n+      blockManager.getSPSManager().start();\n     } finally {\n       startingActiveService \u003d false;\n       blockManager.checkSafeMode();\n       writeUnlock(\"startActiveServices\");\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void startActiveServices() throws IOException {\n    startingActiveService \u003d true;\n    LOG.info(\"Starting services required for active state\");\n    writeLock();\n    try {\n      FSEditLog editLog \u003d getFSImage().getEditLog();\n      \n      if (!editLog.isOpenForWrite()) {\n        // During startup, we\u0027re already open for write during initialization.\n        editLog.initJournalsForWrite();\n        // May need to recover\n        editLog.recoverUnclosedStreams();\n        \n        LOG.info(\"Catching up to latest edits from old active before \" +\n            \"taking over writer role in edits logs\");\n        editLogTailer.catchupDuringFailover();\n        \n        blockManager.setPostponeBlocksFromFuture(false);\n        blockManager.getDatanodeManager().markAllDatanodesStale();\n        blockManager.clearQueues();\n        blockManager.processAllPendingDNMessages();\n\n        // Only need to re-process the queue, If not in SafeMode.\n        if (!isInSafeMode()) {\n          LOG.info(\"Reprocessing replication and invalidation queues\");\n          blockManager.initializeReplQueues();\n        }\n\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"NameNode metadata after re-processing \" +\n              \"replication and invalidation queues during failover:\\n\" +\n              metaSaveAsString());\n        }\n\n        long nextTxId \u003d getFSImage().getLastAppliedTxId() + 1;\n        LOG.info(\"Will take over writing edit logs at txnid \" + \n            nextTxId);\n        editLog.setNextTxId(nextTxId);\n\n        getFSImage().editLog.openForWrite(getEffectiveLayoutVersion());\n      }\n\n      // Initialize the quota.\n      dir.updateCountForQuota();\n      // Enable quota checks.\n      dir.enableQuotaChecks();\n      dir.ezManager.startReencryptThreads();\n\n      if (haEnabled) {\n        // Renew all of the leases before becoming active.\n        // This is because, while we were in standby mode,\n        // the leases weren\u0027t getting renewed on this NN.\n        // Give them all a fresh start here.\n        leaseManager.renewAllLeases();\n      }\n      leaseManager.startMonitor();\n      startSecretManagerIfNecessary();\n\n      //ResourceMonitor required only at ActiveNN. See HDFS-2914\n      this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n      nnrmthread.start();\n\n      nnEditLogRoller \u003d new Daemon(new NameNodeEditLogRoller(\n          editLogRollerThreshold, editLogRollerInterval));\n      nnEditLogRoller.start();\n\n      if (lazyPersistFileScrubIntervalSec \u003e 0) {\n        lazyPersistFileScrubber \u003d new Daemon(new LazyPersistFileScrubber(\n            lazyPersistFileScrubIntervalSec));\n        lazyPersistFileScrubber.start();\n      } else {\n        LOG.warn(\"Lazy persist file scrubber is disabled,\"\n            + \" configured scrub interval is zero.\");\n      }\n\n      cacheManager.startMonitorThread();\n      blockManager.getDatanodeManager().setShouldSendCachingCommands(true);\n      if (provider !\u003d null) {\n        edekCacheLoader \u003d Executors.newSingleThreadExecutor(\n            new ThreadFactoryBuilder().setDaemon(true)\n                .setNameFormat(\"Warm Up EDEK Cache Thread #%d\")\n                .build());\n        FSDirEncryptionZoneOp.warmUpEdekCache(edekCacheLoader, dir,\n            edekCacheLoaderDelay, edekCacheLoaderInterval);\n      }\n      blockManager.getSPSManager().start();\n    } finally {\n      startingActiveService \u003d false;\n      blockManager.checkSafeMode();\n      writeUnlock(\"startActiveServices\");\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "b0cb8d9bb44c963ae686d2b5c1b70bc76b955e10": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13033: [SPS]: Implement a mechanism to do file block movements for external SPS. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "b0cb8d9bb44c963ae686d2b5c1b70bc76b955e10",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "8d4f74e7339abc77dc0daa162d7bd2814bd79b3d",
      "commitAuthorOld": "Rakesh Radhakrishnan",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,98 +1,98 @@\n   void startActiveServices() throws IOException {\n     startingActiveService \u003d true;\n     LOG.info(\"Starting services required for active state\");\n     writeLock();\n     try {\n       FSEditLog editLog \u003d getFSImage().getEditLog();\n       \n       if (!editLog.isOpenForWrite()) {\n         // During startup, we\u0027re already open for write during initialization.\n         editLog.initJournalsForWrite();\n         // May need to recover\n         editLog.recoverUnclosedStreams();\n         \n         LOG.info(\"Catching up to latest edits from old active before \" +\n             \"taking over writer role in edits logs\");\n         editLogTailer.catchupDuringFailover();\n         \n         blockManager.setPostponeBlocksFromFuture(false);\n         blockManager.getDatanodeManager().markAllDatanodesStale();\n         blockManager.clearQueues();\n         blockManager.processAllPendingDNMessages();\n \n         // Only need to re-process the queue, If not in SafeMode.\n         if (!isInSafeMode()) {\n           LOG.info(\"Reprocessing replication and invalidation queues\");\n           blockManager.initializeReplQueues();\n         }\n \n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"NameNode metadata after re-processing \" +\n               \"replication and invalidation queues during failover:\\n\" +\n               metaSaveAsString());\n         }\n \n         long nextTxId \u003d getFSImage().getLastAppliedTxId() + 1;\n         LOG.info(\"Will take over writing edit logs at txnid \" + \n             nextTxId);\n         editLog.setNextTxId(nextTxId);\n \n         getFSImage().editLog.openForWrite(getEffectiveLayoutVersion());\n       }\n \n       // Initialize the quota.\n       dir.updateCountForQuota();\n       // Enable quota checks.\n       dir.enableQuotaChecks();\n       dir.ezManager.startReencryptThreads();\n \n       if (haEnabled) {\n         // Renew all of the leases before becoming active.\n         // This is because, while we were in standby mode,\n         // the leases weren\u0027t getting renewed on this NN.\n         // Give them all a fresh start here.\n         leaseManager.renewAllLeases();\n       }\n       leaseManager.startMonitor();\n       startSecretManagerIfNecessary();\n \n       //ResourceMonitor required only at ActiveNN. See HDFS-2914\n       this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n       nnrmthread.start();\n \n       nnEditLogRoller \u003d new Daemon(new NameNodeEditLogRoller(\n           editLogRollerThreshold, editLogRollerInterval));\n       nnEditLogRoller.start();\n \n       if (lazyPersistFileScrubIntervalSec \u003e 0) {\n         lazyPersistFileScrubber \u003d new Daemon(new LazyPersistFileScrubber(\n             lazyPersistFileScrubIntervalSec));\n         lazyPersistFileScrubber.start();\n       } else {\n         LOG.warn(\"Lazy persist file scrubber is disabled,\"\n             + \" configured scrub interval is zero.\");\n       }\n \n       cacheManager.startMonitorThread();\n       blockManager.getDatanodeManager().setShouldSendCachingCommands(true);\n       if (provider !\u003d null) {\n         edekCacheLoader \u003d Executors.newSingleThreadExecutor(\n             new ThreadFactoryBuilder().setDaemon(true)\n                 .setNameFormat(\"Warm Up EDEK Cache Thread #%d\")\n                 .build());\n         FSDirEncryptionZoneOp.warmUpEdekCache(edekCacheLoader, dir,\n             edekCacheLoaderDelay, edekCacheLoaderInterval);\n       }\n       blockManager.getSPSService().init(\n           new IntraSPSNameNodeContext(this, blockManager,\n               blockManager.getSPSService()),\n           new IntraSPSNameNodeFileIdCollector(getFSDirectory(),\n               blockManager.getSPSService()),\n-          new IntraSPSNameNodeBlockMoveTaskHandler(blockManager, this));\n+          new IntraSPSNameNodeBlockMoveTaskHandler(blockManager, this), null);\n       blockManager.startSPS();\n     } finally {\n       startingActiveService \u003d false;\n       blockManager.checkSafeMode();\n       writeUnlock(\"startActiveServices\");\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void startActiveServices() throws IOException {\n    startingActiveService \u003d true;\n    LOG.info(\"Starting services required for active state\");\n    writeLock();\n    try {\n      FSEditLog editLog \u003d getFSImage().getEditLog();\n      \n      if (!editLog.isOpenForWrite()) {\n        // During startup, we\u0027re already open for write during initialization.\n        editLog.initJournalsForWrite();\n        // May need to recover\n        editLog.recoverUnclosedStreams();\n        \n        LOG.info(\"Catching up to latest edits from old active before \" +\n            \"taking over writer role in edits logs\");\n        editLogTailer.catchupDuringFailover();\n        \n        blockManager.setPostponeBlocksFromFuture(false);\n        blockManager.getDatanodeManager().markAllDatanodesStale();\n        blockManager.clearQueues();\n        blockManager.processAllPendingDNMessages();\n\n        // Only need to re-process the queue, If not in SafeMode.\n        if (!isInSafeMode()) {\n          LOG.info(\"Reprocessing replication and invalidation queues\");\n          blockManager.initializeReplQueues();\n        }\n\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"NameNode metadata after re-processing \" +\n              \"replication and invalidation queues during failover:\\n\" +\n              metaSaveAsString());\n        }\n\n        long nextTxId \u003d getFSImage().getLastAppliedTxId() + 1;\n        LOG.info(\"Will take over writing edit logs at txnid \" + \n            nextTxId);\n        editLog.setNextTxId(nextTxId);\n\n        getFSImage().editLog.openForWrite(getEffectiveLayoutVersion());\n      }\n\n      // Initialize the quota.\n      dir.updateCountForQuota();\n      // Enable quota checks.\n      dir.enableQuotaChecks();\n      dir.ezManager.startReencryptThreads();\n\n      if (haEnabled) {\n        // Renew all of the leases before becoming active.\n        // This is because, while we were in standby mode,\n        // the leases weren\u0027t getting renewed on this NN.\n        // Give them all a fresh start here.\n        leaseManager.renewAllLeases();\n      }\n      leaseManager.startMonitor();\n      startSecretManagerIfNecessary();\n\n      //ResourceMonitor required only at ActiveNN. See HDFS-2914\n      this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n      nnrmthread.start();\n\n      nnEditLogRoller \u003d new Daemon(new NameNodeEditLogRoller(\n          editLogRollerThreshold, editLogRollerInterval));\n      nnEditLogRoller.start();\n\n      if (lazyPersistFileScrubIntervalSec \u003e 0) {\n        lazyPersistFileScrubber \u003d new Daemon(new LazyPersistFileScrubber(\n            lazyPersistFileScrubIntervalSec));\n        lazyPersistFileScrubber.start();\n      } else {\n        LOG.warn(\"Lazy persist file scrubber is disabled,\"\n            + \" configured scrub interval is zero.\");\n      }\n\n      cacheManager.startMonitorThread();\n      blockManager.getDatanodeManager().setShouldSendCachingCommands(true);\n      if (provider !\u003d null) {\n        edekCacheLoader \u003d Executors.newSingleThreadExecutor(\n            new ThreadFactoryBuilder().setDaemon(true)\n                .setNameFormat(\"Warm Up EDEK Cache Thread #%d\")\n                .build());\n        FSDirEncryptionZoneOp.warmUpEdekCache(edekCacheLoader, dir,\n            edekCacheLoaderDelay, edekCacheLoaderInterval);\n      }\n      blockManager.getSPSService().init(\n          new IntraSPSNameNodeContext(this, blockManager,\n              blockManager.getSPSService()),\n          new IntraSPSNameNodeFileIdCollector(getFSDirectory(),\n              blockManager.getSPSService()),\n          new IntraSPSNameNodeBlockMoveTaskHandler(blockManager, this), null);\n      blockManager.startSPS();\n    } finally {\n      startingActiveService \u003d false;\n      blockManager.checkSafeMode();\n      writeUnlock(\"startActiveServices\");\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "8d4f74e7339abc77dc0daa162d7bd2814bd79b3d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12911. [SPS]: Modularize the SPS code and expose necessary interfaces for external/internal implementations. Contributed by Uma Maheswara Rao G\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "8d4f74e7339abc77dc0daa162d7bd2814bd79b3d",
      "commitAuthor": "Rakesh Radhakrishnan",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "05d4daf6ba3e5bd40f46e8003ee12fc7c613453d",
      "commitAuthorOld": "Surendra Singh Lilhore",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,93 +1,98 @@\n   void startActiveServices() throws IOException {\n     startingActiveService \u003d true;\n     LOG.info(\"Starting services required for active state\");\n     writeLock();\n     try {\n       FSEditLog editLog \u003d getFSImage().getEditLog();\n       \n       if (!editLog.isOpenForWrite()) {\n         // During startup, we\u0027re already open for write during initialization.\n         editLog.initJournalsForWrite();\n         // May need to recover\n         editLog.recoverUnclosedStreams();\n         \n         LOG.info(\"Catching up to latest edits from old active before \" +\n             \"taking over writer role in edits logs\");\n         editLogTailer.catchupDuringFailover();\n         \n         blockManager.setPostponeBlocksFromFuture(false);\n         blockManager.getDatanodeManager().markAllDatanodesStale();\n         blockManager.clearQueues();\n         blockManager.processAllPendingDNMessages();\n \n         // Only need to re-process the queue, If not in SafeMode.\n         if (!isInSafeMode()) {\n           LOG.info(\"Reprocessing replication and invalidation queues\");\n           blockManager.initializeReplQueues();\n         }\n \n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"NameNode metadata after re-processing \" +\n               \"replication and invalidation queues during failover:\\n\" +\n               metaSaveAsString());\n         }\n \n         long nextTxId \u003d getFSImage().getLastAppliedTxId() + 1;\n         LOG.info(\"Will take over writing edit logs at txnid \" + \n             nextTxId);\n         editLog.setNextTxId(nextTxId);\n \n         getFSImage().editLog.openForWrite(getEffectiveLayoutVersion());\n       }\n \n       // Initialize the quota.\n       dir.updateCountForQuota();\n       // Enable quota checks.\n       dir.enableQuotaChecks();\n       dir.ezManager.startReencryptThreads();\n \n       if (haEnabled) {\n         // Renew all of the leases before becoming active.\n         // This is because, while we were in standby mode,\n         // the leases weren\u0027t getting renewed on this NN.\n         // Give them all a fresh start here.\n         leaseManager.renewAllLeases();\n       }\n       leaseManager.startMonitor();\n       startSecretManagerIfNecessary();\n \n       //ResourceMonitor required only at ActiveNN. See HDFS-2914\n       this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n       nnrmthread.start();\n \n       nnEditLogRoller \u003d new Daemon(new NameNodeEditLogRoller(\n           editLogRollerThreshold, editLogRollerInterval));\n       nnEditLogRoller.start();\n \n       if (lazyPersistFileScrubIntervalSec \u003e 0) {\n         lazyPersistFileScrubber \u003d new Daemon(new LazyPersistFileScrubber(\n             lazyPersistFileScrubIntervalSec));\n         lazyPersistFileScrubber.start();\n       } else {\n         LOG.warn(\"Lazy persist file scrubber is disabled,\"\n             + \" configured scrub interval is zero.\");\n       }\n \n       cacheManager.startMonitorThread();\n       blockManager.getDatanodeManager().setShouldSendCachingCommands(true);\n       if (provider !\u003d null) {\n         edekCacheLoader \u003d Executors.newSingleThreadExecutor(\n             new ThreadFactoryBuilder().setDaemon(true)\n                 .setNameFormat(\"Warm Up EDEK Cache Thread #%d\")\n                 .build());\n         FSDirEncryptionZoneOp.warmUpEdekCache(edekCacheLoader, dir,\n             edekCacheLoaderDelay, edekCacheLoaderInterval);\n       }\n-\n+      blockManager.getSPSService().init(\n+          new IntraSPSNameNodeContext(this, blockManager,\n+              blockManager.getSPSService()),\n+          new IntraSPSNameNodeFileIdCollector(getFSDirectory(),\n+              blockManager.getSPSService()),\n+          new IntraSPSNameNodeBlockMoveTaskHandler(blockManager, this));\n       blockManager.startSPS();\n     } finally {\n       startingActiveService \u003d false;\n       blockManager.checkSafeMode();\n       writeUnlock(\"startActiveServices\");\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void startActiveServices() throws IOException {\n    startingActiveService \u003d true;\n    LOG.info(\"Starting services required for active state\");\n    writeLock();\n    try {\n      FSEditLog editLog \u003d getFSImage().getEditLog();\n      \n      if (!editLog.isOpenForWrite()) {\n        // During startup, we\u0027re already open for write during initialization.\n        editLog.initJournalsForWrite();\n        // May need to recover\n        editLog.recoverUnclosedStreams();\n        \n        LOG.info(\"Catching up to latest edits from old active before \" +\n            \"taking over writer role in edits logs\");\n        editLogTailer.catchupDuringFailover();\n        \n        blockManager.setPostponeBlocksFromFuture(false);\n        blockManager.getDatanodeManager().markAllDatanodesStale();\n        blockManager.clearQueues();\n        blockManager.processAllPendingDNMessages();\n\n        // Only need to re-process the queue, If not in SafeMode.\n        if (!isInSafeMode()) {\n          LOG.info(\"Reprocessing replication and invalidation queues\");\n          blockManager.initializeReplQueues();\n        }\n\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"NameNode metadata after re-processing \" +\n              \"replication and invalidation queues during failover:\\n\" +\n              metaSaveAsString());\n        }\n\n        long nextTxId \u003d getFSImage().getLastAppliedTxId() + 1;\n        LOG.info(\"Will take over writing edit logs at txnid \" + \n            nextTxId);\n        editLog.setNextTxId(nextTxId);\n\n        getFSImage().editLog.openForWrite(getEffectiveLayoutVersion());\n      }\n\n      // Initialize the quota.\n      dir.updateCountForQuota();\n      // Enable quota checks.\n      dir.enableQuotaChecks();\n      dir.ezManager.startReencryptThreads();\n\n      if (haEnabled) {\n        // Renew all of the leases before becoming active.\n        // This is because, while we were in standby mode,\n        // the leases weren\u0027t getting renewed on this NN.\n        // Give them all a fresh start here.\n        leaseManager.renewAllLeases();\n      }\n      leaseManager.startMonitor();\n      startSecretManagerIfNecessary();\n\n      //ResourceMonitor required only at ActiveNN. See HDFS-2914\n      this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n      nnrmthread.start();\n\n      nnEditLogRoller \u003d new Daemon(new NameNodeEditLogRoller(\n          editLogRollerThreshold, editLogRollerInterval));\n      nnEditLogRoller.start();\n\n      if (lazyPersistFileScrubIntervalSec \u003e 0) {\n        lazyPersistFileScrubber \u003d new Daemon(new LazyPersistFileScrubber(\n            lazyPersistFileScrubIntervalSec));\n        lazyPersistFileScrubber.start();\n      } else {\n        LOG.warn(\"Lazy persist file scrubber is disabled,\"\n            + \" configured scrub interval is zero.\");\n      }\n\n      cacheManager.startMonitorThread();\n      blockManager.getDatanodeManager().setShouldSendCachingCommands(true);\n      if (provider !\u003d null) {\n        edekCacheLoader \u003d Executors.newSingleThreadExecutor(\n            new ThreadFactoryBuilder().setDaemon(true)\n                .setNameFormat(\"Warm Up EDEK Cache Thread #%d\")\n                .build());\n        FSDirEncryptionZoneOp.warmUpEdekCache(edekCacheLoader, dir,\n            edekCacheLoaderDelay, edekCacheLoaderInterval);\n      }\n      blockManager.getSPSService().init(\n          new IntraSPSNameNodeContext(this, blockManager,\n              blockManager.getSPSService()),\n          new IntraSPSNameNodeFileIdCollector(getFSDirectory(),\n              blockManager.getSPSService()),\n          new IntraSPSNameNodeBlockMoveTaskHandler(blockManager, this));\n      blockManager.startSPS();\n    } finally {\n      startingActiveService \u003d false;\n      blockManager.checkSafeMode();\n      writeUnlock(\"startActiveServices\");\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "0e820f16af309cc8476edba448dd548686431133": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12214: [SPS]: Fix review comments of StoragePolicySatisfier feature. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "0e820f16af309cc8476edba448dd548686431133",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:05 AM",
      "commitNameOld": "5ce332dc9a072f8850ab71ba16898faf8e866c06",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 12,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,93 +1,93 @@\n   void startActiveServices() throws IOException {\n     startingActiveService \u003d true;\n     LOG.info(\"Starting services required for active state\");\n     writeLock();\n     try {\n       FSEditLog editLog \u003d getFSImage().getEditLog();\n       \n       if (!editLog.isOpenForWrite()) {\n         // During startup, we\u0027re already open for write during initialization.\n         editLog.initJournalsForWrite();\n         // May need to recover\n         editLog.recoverUnclosedStreams();\n         \n         LOG.info(\"Catching up to latest edits from old active before \" +\n             \"taking over writer role in edits logs\");\n         editLogTailer.catchupDuringFailover();\n         \n         blockManager.setPostponeBlocksFromFuture(false);\n         blockManager.getDatanodeManager().markAllDatanodesStale();\n         blockManager.clearQueues();\n         blockManager.processAllPendingDNMessages();\n \n         // Only need to re-process the queue, If not in SafeMode.\n         if (!isInSafeMode()) {\n           LOG.info(\"Reprocessing replication and invalidation queues\");\n           blockManager.initializeReplQueues();\n         }\n \n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"NameNode metadata after re-processing \" +\n               \"replication and invalidation queues during failover:\\n\" +\n               metaSaveAsString());\n         }\n \n         long nextTxId \u003d getFSImage().getLastAppliedTxId() + 1;\n         LOG.info(\"Will take over writing edit logs at txnid \" + \n             nextTxId);\n         editLog.setNextTxId(nextTxId);\n \n         getFSImage().editLog.openForWrite(getEffectiveLayoutVersion());\n       }\n \n       // Initialize the quota.\n       dir.updateCountForQuota();\n       // Enable quota checks.\n       dir.enableQuotaChecks();\n       dir.ezManager.startReencryptThreads();\n \n       if (haEnabled) {\n         // Renew all of the leases before becoming active.\n         // This is because, while we were in standby mode,\n         // the leases weren\u0027t getting renewed on this NN.\n         // Give them all a fresh start here.\n         leaseManager.renewAllLeases();\n       }\n       leaseManager.startMonitor();\n       startSecretManagerIfNecessary();\n \n       //ResourceMonitor required only at ActiveNN. See HDFS-2914\n       this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n       nnrmthread.start();\n \n       nnEditLogRoller \u003d new Daemon(new NameNodeEditLogRoller(\n           editLogRollerThreshold, editLogRollerInterval));\n       nnEditLogRoller.start();\n \n       if (lazyPersistFileScrubIntervalSec \u003e 0) {\n         lazyPersistFileScrubber \u003d new Daemon(new LazyPersistFileScrubber(\n             lazyPersistFileScrubIntervalSec));\n         lazyPersistFileScrubber.start();\n       } else {\n         LOG.warn(\"Lazy persist file scrubber is disabled,\"\n             + \" configured scrub interval is zero.\");\n       }\n \n       cacheManager.startMonitorThread();\n       blockManager.getDatanodeManager().setShouldSendCachingCommands(true);\n       if (provider !\u003d null) {\n         edekCacheLoader \u003d Executors.newSingleThreadExecutor(\n             new ThreadFactoryBuilder().setDaemon(true)\n                 .setNameFormat(\"Warm Up EDEK Cache Thread #%d\")\n                 .build());\n         FSDirEncryptionZoneOp.warmUpEdekCache(edekCacheLoader, dir,\n             edekCacheLoaderDelay, edekCacheLoaderInterval);\n       }\n \n-      blockManager.activateSPS();\n+      blockManager.startSPS();\n     } finally {\n       startingActiveService \u003d false;\n       blockManager.checkSafeMode();\n       writeUnlock(\"startActiveServices\");\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void startActiveServices() throws IOException {\n    startingActiveService \u003d true;\n    LOG.info(\"Starting services required for active state\");\n    writeLock();\n    try {\n      FSEditLog editLog \u003d getFSImage().getEditLog();\n      \n      if (!editLog.isOpenForWrite()) {\n        // During startup, we\u0027re already open for write during initialization.\n        editLog.initJournalsForWrite();\n        // May need to recover\n        editLog.recoverUnclosedStreams();\n        \n        LOG.info(\"Catching up to latest edits from old active before \" +\n            \"taking over writer role in edits logs\");\n        editLogTailer.catchupDuringFailover();\n        \n        blockManager.setPostponeBlocksFromFuture(false);\n        blockManager.getDatanodeManager().markAllDatanodesStale();\n        blockManager.clearQueues();\n        blockManager.processAllPendingDNMessages();\n\n        // Only need to re-process the queue, If not in SafeMode.\n        if (!isInSafeMode()) {\n          LOG.info(\"Reprocessing replication and invalidation queues\");\n          blockManager.initializeReplQueues();\n        }\n\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"NameNode metadata after re-processing \" +\n              \"replication and invalidation queues during failover:\\n\" +\n              metaSaveAsString());\n        }\n\n        long nextTxId \u003d getFSImage().getLastAppliedTxId() + 1;\n        LOG.info(\"Will take over writing edit logs at txnid \" + \n            nextTxId);\n        editLog.setNextTxId(nextTxId);\n\n        getFSImage().editLog.openForWrite(getEffectiveLayoutVersion());\n      }\n\n      // Initialize the quota.\n      dir.updateCountForQuota();\n      // Enable quota checks.\n      dir.enableQuotaChecks();\n      dir.ezManager.startReencryptThreads();\n\n      if (haEnabled) {\n        // Renew all of the leases before becoming active.\n        // This is because, while we were in standby mode,\n        // the leases weren\u0027t getting renewed on this NN.\n        // Give them all a fresh start here.\n        leaseManager.renewAllLeases();\n      }\n      leaseManager.startMonitor();\n      startSecretManagerIfNecessary();\n\n      //ResourceMonitor required only at ActiveNN. See HDFS-2914\n      this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n      nnrmthread.start();\n\n      nnEditLogRoller \u003d new Daemon(new NameNodeEditLogRoller(\n          editLogRollerThreshold, editLogRollerInterval));\n      nnEditLogRoller.start();\n\n      if (lazyPersistFileScrubIntervalSec \u003e 0) {\n        lazyPersistFileScrubber \u003d new Daemon(new LazyPersistFileScrubber(\n            lazyPersistFileScrubIntervalSec));\n        lazyPersistFileScrubber.start();\n      } else {\n        LOG.warn(\"Lazy persist file scrubber is disabled,\"\n            + \" configured scrub interval is zero.\");\n      }\n\n      cacheManager.startMonitorThread();\n      blockManager.getDatanodeManager().setShouldSendCachingCommands(true);\n      if (provider !\u003d null) {\n        edekCacheLoader \u003d Executors.newSingleThreadExecutor(\n            new ThreadFactoryBuilder().setDaemon(true)\n                .setNameFormat(\"Warm Up EDEK Cache Thread #%d\")\n                .build());\n        FSDirEncryptionZoneOp.warmUpEdekCache(edekCacheLoader, dir,\n            edekCacheLoaderDelay, edekCacheLoaderInterval);\n      }\n\n      blockManager.startSPS();\n    } finally {\n      startingActiveService \u003d false;\n      blockManager.checkSafeMode();\n      writeUnlock(\"startActiveServices\");\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "681d2804c95e5a569ffb8d9ceafaf5a4f8be2b88": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11186. [SPS]: Daemon thread of SPS should start only in Active NN. Contributed by Wei Zhou\n",
      "commitDate": "12/08/18 3:05 AM",
      "commitName": "681d2804c95e5a569ffb8d9ceafaf5a4f8be2b88",
      "commitAuthor": "Rakesh Radhakrishnan",
      "commitDateOld": "12/08/18 3:05 AM",
      "commitNameOld": "6215e35bb633706753a464ad3e8633366e6a10b2",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,91 +1,93 @@\n   void startActiveServices() throws IOException {\n     startingActiveService \u003d true;\n     LOG.info(\"Starting services required for active state\");\n     writeLock();\n     try {\n       FSEditLog editLog \u003d getFSImage().getEditLog();\n       \n       if (!editLog.isOpenForWrite()) {\n         // During startup, we\u0027re already open for write during initialization.\n         editLog.initJournalsForWrite();\n         // May need to recover\n         editLog.recoverUnclosedStreams();\n         \n         LOG.info(\"Catching up to latest edits from old active before \" +\n             \"taking over writer role in edits logs\");\n         editLogTailer.catchupDuringFailover();\n         \n         blockManager.setPostponeBlocksFromFuture(false);\n         blockManager.getDatanodeManager().markAllDatanodesStale();\n         blockManager.clearQueues();\n         blockManager.processAllPendingDNMessages();\n \n         // Only need to re-process the queue, If not in SafeMode.\n         if (!isInSafeMode()) {\n           LOG.info(\"Reprocessing replication and invalidation queues\");\n           blockManager.initializeReplQueues();\n         }\n \n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"NameNode metadata after re-processing \" +\n               \"replication and invalidation queues during failover:\\n\" +\n               metaSaveAsString());\n         }\n \n         long nextTxId \u003d getFSImage().getLastAppliedTxId() + 1;\n         LOG.info(\"Will take over writing edit logs at txnid \" + \n             nextTxId);\n         editLog.setNextTxId(nextTxId);\n \n         getFSImage().editLog.openForWrite(getEffectiveLayoutVersion());\n       }\n \n       // Initialize the quota.\n       dir.updateCountForQuota();\n       // Enable quota checks.\n       dir.enableQuotaChecks();\n       dir.ezManager.startReencryptThreads();\n \n       if (haEnabled) {\n         // Renew all of the leases before becoming active.\n         // This is because, while we were in standby mode,\n         // the leases weren\u0027t getting renewed on this NN.\n         // Give them all a fresh start here.\n         leaseManager.renewAllLeases();\n       }\n       leaseManager.startMonitor();\n       startSecretManagerIfNecessary();\n \n       //ResourceMonitor required only at ActiveNN. See HDFS-2914\n       this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n       nnrmthread.start();\n \n       nnEditLogRoller \u003d new Daemon(new NameNodeEditLogRoller(\n           editLogRollerThreshold, editLogRollerInterval));\n       nnEditLogRoller.start();\n \n       if (lazyPersistFileScrubIntervalSec \u003e 0) {\n         lazyPersistFileScrubber \u003d new Daemon(new LazyPersistFileScrubber(\n             lazyPersistFileScrubIntervalSec));\n         lazyPersistFileScrubber.start();\n       } else {\n         LOG.warn(\"Lazy persist file scrubber is disabled,\"\n             + \" configured scrub interval is zero.\");\n       }\n \n       cacheManager.startMonitorThread();\n       blockManager.getDatanodeManager().setShouldSendCachingCommands(true);\n       if (provider !\u003d null) {\n         edekCacheLoader \u003d Executors.newSingleThreadExecutor(\n             new ThreadFactoryBuilder().setDaemon(true)\n                 .setNameFormat(\"Warm Up EDEK Cache Thread #%d\")\n                 .build());\n         FSDirEncryptionZoneOp.warmUpEdekCache(edekCacheLoader, dir,\n             edekCacheLoaderDelay, edekCacheLoaderInterval);\n       }\n+\n+      blockManager.activateSPS();\n     } finally {\n       startingActiveService \u003d false;\n       blockManager.checkSafeMode();\n       writeUnlock(\"startActiveServices\");\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void startActiveServices() throws IOException {\n    startingActiveService \u003d true;\n    LOG.info(\"Starting services required for active state\");\n    writeLock();\n    try {\n      FSEditLog editLog \u003d getFSImage().getEditLog();\n      \n      if (!editLog.isOpenForWrite()) {\n        // During startup, we\u0027re already open for write during initialization.\n        editLog.initJournalsForWrite();\n        // May need to recover\n        editLog.recoverUnclosedStreams();\n        \n        LOG.info(\"Catching up to latest edits from old active before \" +\n            \"taking over writer role in edits logs\");\n        editLogTailer.catchupDuringFailover();\n        \n        blockManager.setPostponeBlocksFromFuture(false);\n        blockManager.getDatanodeManager().markAllDatanodesStale();\n        blockManager.clearQueues();\n        blockManager.processAllPendingDNMessages();\n\n        // Only need to re-process the queue, If not in SafeMode.\n        if (!isInSafeMode()) {\n          LOG.info(\"Reprocessing replication and invalidation queues\");\n          blockManager.initializeReplQueues();\n        }\n\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"NameNode metadata after re-processing \" +\n              \"replication and invalidation queues during failover:\\n\" +\n              metaSaveAsString());\n        }\n\n        long nextTxId \u003d getFSImage().getLastAppliedTxId() + 1;\n        LOG.info(\"Will take over writing edit logs at txnid \" + \n            nextTxId);\n        editLog.setNextTxId(nextTxId);\n\n        getFSImage().editLog.openForWrite(getEffectiveLayoutVersion());\n      }\n\n      // Initialize the quota.\n      dir.updateCountForQuota();\n      // Enable quota checks.\n      dir.enableQuotaChecks();\n      dir.ezManager.startReencryptThreads();\n\n      if (haEnabled) {\n        // Renew all of the leases before becoming active.\n        // This is because, while we were in standby mode,\n        // the leases weren\u0027t getting renewed on this NN.\n        // Give them all a fresh start here.\n        leaseManager.renewAllLeases();\n      }\n      leaseManager.startMonitor();\n      startSecretManagerIfNecessary();\n\n      //ResourceMonitor required only at ActiveNN. See HDFS-2914\n      this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n      nnrmthread.start();\n\n      nnEditLogRoller \u003d new Daemon(new NameNodeEditLogRoller(\n          editLogRollerThreshold, editLogRollerInterval));\n      nnEditLogRoller.start();\n\n      if (lazyPersistFileScrubIntervalSec \u003e 0) {\n        lazyPersistFileScrubber \u003d new Daemon(new LazyPersistFileScrubber(\n            lazyPersistFileScrubIntervalSec));\n        lazyPersistFileScrubber.start();\n      } else {\n        LOG.warn(\"Lazy persist file scrubber is disabled,\"\n            + \" configured scrub interval is zero.\");\n      }\n\n      cacheManager.startMonitorThread();\n      blockManager.getDatanodeManager().setShouldSendCachingCommands(true);\n      if (provider !\u003d null) {\n        edekCacheLoader \u003d Executors.newSingleThreadExecutor(\n            new ThreadFactoryBuilder().setDaemon(true)\n                .setNameFormat(\"Warm Up EDEK Cache Thread #%d\")\n                .build());\n        FSDirEncryptionZoneOp.warmUpEdekCache(edekCacheLoader, dir,\n            edekCacheLoaderDelay, edekCacheLoaderInterval);\n      }\n\n      blockManager.activateSPS();\n    } finally {\n      startingActiveService \u003d false;\n      blockManager.checkSafeMode();\n      writeUnlock(\"startActiveServices\");\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "1000a2af04b24c123a3b08168f36b4e90420cab7": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10899. Add functionality to re-encrypt EDEKs.\n",
      "commitDate": "23/08/17 5:06 PM",
      "commitName": "1000a2af04b24c123a3b08168f36b4e90420cab7",
      "commitAuthor": "Xiao Chen",
      "commitDateOld": "16/08/17 9:20 PM",
      "commitNameOld": "08aaa4b36fab44c3f47878b3c487db3b373ffccf",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 6.82,
      "commitsBetweenForRepo": 32,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,89 +1,91 @@\n   void startActiveServices() throws IOException {\n     startingActiveService \u003d true;\n     LOG.info(\"Starting services required for active state\");\n     writeLock();\n     try {\n       FSEditLog editLog \u003d getFSImage().getEditLog();\n       \n       if (!editLog.isOpenForWrite()) {\n         // During startup, we\u0027re already open for write during initialization.\n         editLog.initJournalsForWrite();\n         // May need to recover\n         editLog.recoverUnclosedStreams();\n         \n         LOG.info(\"Catching up to latest edits from old active before \" +\n             \"taking over writer role in edits logs\");\n         editLogTailer.catchupDuringFailover();\n         \n         blockManager.setPostponeBlocksFromFuture(false);\n         blockManager.getDatanodeManager().markAllDatanodesStale();\n         blockManager.clearQueues();\n         blockManager.processAllPendingDNMessages();\n \n         // Only need to re-process the queue, If not in SafeMode.\n         if (!isInSafeMode()) {\n           LOG.info(\"Reprocessing replication and invalidation queues\");\n           blockManager.initializeReplQueues();\n         }\n \n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"NameNode metadata after re-processing \" +\n               \"replication and invalidation queues during failover:\\n\" +\n               metaSaveAsString());\n         }\n \n         long nextTxId \u003d getFSImage().getLastAppliedTxId() + 1;\n         LOG.info(\"Will take over writing edit logs at txnid \" + \n             nextTxId);\n         editLog.setNextTxId(nextTxId);\n \n         getFSImage().editLog.openForWrite(getEffectiveLayoutVersion());\n       }\n \n       // Initialize the quota.\n       dir.updateCountForQuota();\n       // Enable quota checks.\n       dir.enableQuotaChecks();\n+      dir.ezManager.startReencryptThreads();\n+\n       if (haEnabled) {\n         // Renew all of the leases before becoming active.\n         // This is because, while we were in standby mode,\n         // the leases weren\u0027t getting renewed on this NN.\n         // Give them all a fresh start here.\n         leaseManager.renewAllLeases();\n       }\n       leaseManager.startMonitor();\n       startSecretManagerIfNecessary();\n \n       //ResourceMonitor required only at ActiveNN. See HDFS-2914\n       this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n       nnrmthread.start();\n \n       nnEditLogRoller \u003d new Daemon(new NameNodeEditLogRoller(\n           editLogRollerThreshold, editLogRollerInterval));\n       nnEditLogRoller.start();\n \n       if (lazyPersistFileScrubIntervalSec \u003e 0) {\n         lazyPersistFileScrubber \u003d new Daemon(new LazyPersistFileScrubber(\n             lazyPersistFileScrubIntervalSec));\n         lazyPersistFileScrubber.start();\n       } else {\n         LOG.warn(\"Lazy persist file scrubber is disabled,\"\n             + \" configured scrub interval is zero.\");\n       }\n \n       cacheManager.startMonitorThread();\n       blockManager.getDatanodeManager().setShouldSendCachingCommands(true);\n       if (provider !\u003d null) {\n         edekCacheLoader \u003d Executors.newSingleThreadExecutor(\n             new ThreadFactoryBuilder().setDaemon(true)\n                 .setNameFormat(\"Warm Up EDEK Cache Thread #%d\")\n                 .build());\n         FSDirEncryptionZoneOp.warmUpEdekCache(edekCacheLoader, dir,\n             edekCacheLoaderDelay, edekCacheLoaderInterval);\n       }\n     } finally {\n       startingActiveService \u003d false;\n       blockManager.checkSafeMode();\n       writeUnlock(\"startActiveServices\");\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void startActiveServices() throws IOException {\n    startingActiveService \u003d true;\n    LOG.info(\"Starting services required for active state\");\n    writeLock();\n    try {\n      FSEditLog editLog \u003d getFSImage().getEditLog();\n      \n      if (!editLog.isOpenForWrite()) {\n        // During startup, we\u0027re already open for write during initialization.\n        editLog.initJournalsForWrite();\n        // May need to recover\n        editLog.recoverUnclosedStreams();\n        \n        LOG.info(\"Catching up to latest edits from old active before \" +\n            \"taking over writer role in edits logs\");\n        editLogTailer.catchupDuringFailover();\n        \n        blockManager.setPostponeBlocksFromFuture(false);\n        blockManager.getDatanodeManager().markAllDatanodesStale();\n        blockManager.clearQueues();\n        blockManager.processAllPendingDNMessages();\n\n        // Only need to re-process the queue, If not in SafeMode.\n        if (!isInSafeMode()) {\n          LOG.info(\"Reprocessing replication and invalidation queues\");\n          blockManager.initializeReplQueues();\n        }\n\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"NameNode metadata after re-processing \" +\n              \"replication and invalidation queues during failover:\\n\" +\n              metaSaveAsString());\n        }\n\n        long nextTxId \u003d getFSImage().getLastAppliedTxId() + 1;\n        LOG.info(\"Will take over writing edit logs at txnid \" + \n            nextTxId);\n        editLog.setNextTxId(nextTxId);\n\n        getFSImage().editLog.openForWrite(getEffectiveLayoutVersion());\n      }\n\n      // Initialize the quota.\n      dir.updateCountForQuota();\n      // Enable quota checks.\n      dir.enableQuotaChecks();\n      dir.ezManager.startReencryptThreads();\n\n      if (haEnabled) {\n        // Renew all of the leases before becoming active.\n        // This is because, while we were in standby mode,\n        // the leases weren\u0027t getting renewed on this NN.\n        // Give them all a fresh start here.\n        leaseManager.renewAllLeases();\n      }\n      leaseManager.startMonitor();\n      startSecretManagerIfNecessary();\n\n      //ResourceMonitor required only at ActiveNN. See HDFS-2914\n      this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n      nnrmthread.start();\n\n      nnEditLogRoller \u003d new Daemon(new NameNodeEditLogRoller(\n          editLogRollerThreshold, editLogRollerInterval));\n      nnEditLogRoller.start();\n\n      if (lazyPersistFileScrubIntervalSec \u003e 0) {\n        lazyPersistFileScrubber \u003d new Daemon(new LazyPersistFileScrubber(\n            lazyPersistFileScrubIntervalSec));\n        lazyPersistFileScrubber.start();\n      } else {\n        LOG.warn(\"Lazy persist file scrubber is disabled,\"\n            + \" configured scrub interval is zero.\");\n      }\n\n      cacheManager.startMonitorThread();\n      blockManager.getDatanodeManager().setShouldSendCachingCommands(true);\n      if (provider !\u003d null) {\n        edekCacheLoader \u003d Executors.newSingleThreadExecutor(\n            new ThreadFactoryBuilder().setDaemon(true)\n                .setNameFormat(\"Warm Up EDEK Cache Thread #%d\")\n                .build());\n        FSDirEncryptionZoneOp.warmUpEdekCache(edekCacheLoader, dir,\n            edekCacheLoaderDelay, edekCacheLoaderInterval);\n      }\n    } finally {\n      startingActiveService \u003d false;\n      blockManager.checkSafeMode();\n      writeUnlock(\"startActiveServices\");\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "ff0b99eafeda035ebe0dc82cfe689808047a8893": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10872. Add MutableRate metrics for FSNamesystemLock operations. Contributed by Erik Krogen.\n",
      "commitDate": "14/11/16 11:05 AM",
      "commitName": "ff0b99eafeda035ebe0dc82cfe689808047a8893",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "08/11/16 6:17 PM",
      "commitNameOld": "ed0bebabaaf27cd730f7f8eb002d92c9c7db327d",
      "commitAuthorOld": "Brahma Reddy Battula",
      "daysBetweenCommits": 5.7,
      "commitsBetweenForRepo": 36,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,89 +1,89 @@\n   void startActiveServices() throws IOException {\n     startingActiveService \u003d true;\n     LOG.info(\"Starting services required for active state\");\n     writeLock();\n     try {\n       FSEditLog editLog \u003d getFSImage().getEditLog();\n       \n       if (!editLog.isOpenForWrite()) {\n         // During startup, we\u0027re already open for write during initialization.\n         editLog.initJournalsForWrite();\n         // May need to recover\n         editLog.recoverUnclosedStreams();\n         \n         LOG.info(\"Catching up to latest edits from old active before \" +\n             \"taking over writer role in edits logs\");\n         editLogTailer.catchupDuringFailover();\n         \n         blockManager.setPostponeBlocksFromFuture(false);\n         blockManager.getDatanodeManager().markAllDatanodesStale();\n         blockManager.clearQueues();\n         blockManager.processAllPendingDNMessages();\n \n         // Only need to re-process the queue, If not in SafeMode.\n         if (!isInSafeMode()) {\n           LOG.info(\"Reprocessing replication and invalidation queues\");\n           blockManager.initializeReplQueues();\n         }\n \n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"NameNode metadata after re-processing \" +\n               \"replication and invalidation queues during failover:\\n\" +\n               metaSaveAsString());\n         }\n \n         long nextTxId \u003d getFSImage().getLastAppliedTxId() + 1;\n         LOG.info(\"Will take over writing edit logs at txnid \" + \n             nextTxId);\n         editLog.setNextTxId(nextTxId);\n \n         getFSImage().editLog.openForWrite(getEffectiveLayoutVersion());\n       }\n \n       // Initialize the quota.\n       dir.updateCountForQuota();\n       // Enable quota checks.\n       dir.enableQuotaChecks();\n       if (haEnabled) {\n         // Renew all of the leases before becoming active.\n         // This is because, while we were in standby mode,\n         // the leases weren\u0027t getting renewed on this NN.\n         // Give them all a fresh start here.\n         leaseManager.renewAllLeases();\n       }\n       leaseManager.startMonitor();\n       startSecretManagerIfNecessary();\n \n       //ResourceMonitor required only at ActiveNN. See HDFS-2914\n       this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n       nnrmthread.start();\n \n       nnEditLogRoller \u003d new Daemon(new NameNodeEditLogRoller(\n           editLogRollerThreshold, editLogRollerInterval));\n       nnEditLogRoller.start();\n \n       if (lazyPersistFileScrubIntervalSec \u003e 0) {\n         lazyPersistFileScrubber \u003d new Daemon(new LazyPersistFileScrubber(\n             lazyPersistFileScrubIntervalSec));\n         lazyPersistFileScrubber.start();\n       } else {\n         LOG.warn(\"Lazy persist file scrubber is disabled,\"\n             + \" configured scrub interval is zero.\");\n       }\n \n       cacheManager.startMonitorThread();\n       blockManager.getDatanodeManager().setShouldSendCachingCommands(true);\n       if (provider !\u003d null) {\n         edekCacheLoader \u003d Executors.newSingleThreadExecutor(\n             new ThreadFactoryBuilder().setDaemon(true)\n                 .setNameFormat(\"Warm Up EDEK Cache Thread #%d\")\n                 .build());\n         FSDirEncryptionZoneOp.warmUpEdekCache(edekCacheLoader, dir,\n             edekCacheLoaderDelay, edekCacheLoaderInterval);\n       }\n     } finally {\n       startingActiveService \u003d false;\n       blockManager.checkSafeMode();\n-      writeUnlock();\n+      writeUnlock(\"startActiveServices\");\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void startActiveServices() throws IOException {\n    startingActiveService \u003d true;\n    LOG.info(\"Starting services required for active state\");\n    writeLock();\n    try {\n      FSEditLog editLog \u003d getFSImage().getEditLog();\n      \n      if (!editLog.isOpenForWrite()) {\n        // During startup, we\u0027re already open for write during initialization.\n        editLog.initJournalsForWrite();\n        // May need to recover\n        editLog.recoverUnclosedStreams();\n        \n        LOG.info(\"Catching up to latest edits from old active before \" +\n            \"taking over writer role in edits logs\");\n        editLogTailer.catchupDuringFailover();\n        \n        blockManager.setPostponeBlocksFromFuture(false);\n        blockManager.getDatanodeManager().markAllDatanodesStale();\n        blockManager.clearQueues();\n        blockManager.processAllPendingDNMessages();\n\n        // Only need to re-process the queue, If not in SafeMode.\n        if (!isInSafeMode()) {\n          LOG.info(\"Reprocessing replication and invalidation queues\");\n          blockManager.initializeReplQueues();\n        }\n\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"NameNode metadata after re-processing \" +\n              \"replication and invalidation queues during failover:\\n\" +\n              metaSaveAsString());\n        }\n\n        long nextTxId \u003d getFSImage().getLastAppliedTxId() + 1;\n        LOG.info(\"Will take over writing edit logs at txnid \" + \n            nextTxId);\n        editLog.setNextTxId(nextTxId);\n\n        getFSImage().editLog.openForWrite(getEffectiveLayoutVersion());\n      }\n\n      // Initialize the quota.\n      dir.updateCountForQuota();\n      // Enable quota checks.\n      dir.enableQuotaChecks();\n      if (haEnabled) {\n        // Renew all of the leases before becoming active.\n        // This is because, while we were in standby mode,\n        // the leases weren\u0027t getting renewed on this NN.\n        // Give them all a fresh start here.\n        leaseManager.renewAllLeases();\n      }\n      leaseManager.startMonitor();\n      startSecretManagerIfNecessary();\n\n      //ResourceMonitor required only at ActiveNN. See HDFS-2914\n      this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n      nnrmthread.start();\n\n      nnEditLogRoller \u003d new Daemon(new NameNodeEditLogRoller(\n          editLogRollerThreshold, editLogRollerInterval));\n      nnEditLogRoller.start();\n\n      if (lazyPersistFileScrubIntervalSec \u003e 0) {\n        lazyPersistFileScrubber \u003d new Daemon(new LazyPersistFileScrubber(\n            lazyPersistFileScrubIntervalSec));\n        lazyPersistFileScrubber.start();\n      } else {\n        LOG.warn(\"Lazy persist file scrubber is disabled,\"\n            + \" configured scrub interval is zero.\");\n      }\n\n      cacheManager.startMonitorThread();\n      blockManager.getDatanodeManager().setShouldSendCachingCommands(true);\n      if (provider !\u003d null) {\n        edekCacheLoader \u003d Executors.newSingleThreadExecutor(\n            new ThreadFactoryBuilder().setDaemon(true)\n                .setNameFormat(\"Warm Up EDEK Cache Thread #%d\")\n                .build());\n        FSDirEncryptionZoneOp.warmUpEdekCache(edekCacheLoader, dir,\n            edekCacheLoaderDelay, edekCacheLoaderInterval);\n      }\n    } finally {\n      startingActiveService \u003d false;\n      blockManager.checkSafeMode();\n      writeUnlock(\"startActiveServices\");\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "221b3a8722f84f8e9ad0a98eea38a12cc4ad2f24": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10192. Namenode safemode not coming out during failover. Contributed by Brahma Reddy Battula.\n",
      "commitDate": "06/04/16 10:42 AM",
      "commitName": "221b3a8722f84f8e9ad0a98eea38a12cc4ad2f24",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "21/03/16 11:39 AM",
      "commitNameOld": "e3bb38d62567eafe57d16b78deeba1b71c58e41c",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 15.96,
      "commitsBetweenForRepo": 102,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,88 +1,89 @@\n   void startActiveServices() throws IOException {\n     startingActiveService \u003d true;\n     LOG.info(\"Starting services required for active state\");\n     writeLock();\n     try {\n       FSEditLog editLog \u003d getFSImage().getEditLog();\n       \n       if (!editLog.isOpenForWrite()) {\n         // During startup, we\u0027re already open for write during initialization.\n         editLog.initJournalsForWrite();\n         // May need to recover\n         editLog.recoverUnclosedStreams();\n         \n         LOG.info(\"Catching up to latest edits from old active before \" +\n             \"taking over writer role in edits logs\");\n         editLogTailer.catchupDuringFailover();\n         \n         blockManager.setPostponeBlocksFromFuture(false);\n         blockManager.getDatanodeManager().markAllDatanodesStale();\n         blockManager.clearQueues();\n         blockManager.processAllPendingDNMessages();\n \n         // Only need to re-process the queue, If not in SafeMode.\n         if (!isInSafeMode()) {\n           LOG.info(\"Reprocessing replication and invalidation queues\");\n           blockManager.initializeReplQueues();\n         }\n \n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"NameNode metadata after re-processing \" +\n               \"replication and invalidation queues during failover:\\n\" +\n               metaSaveAsString());\n         }\n \n         long nextTxId \u003d getFSImage().getLastAppliedTxId() + 1;\n         LOG.info(\"Will take over writing edit logs at txnid \" + \n             nextTxId);\n         editLog.setNextTxId(nextTxId);\n \n         getFSImage().editLog.openForWrite(getEffectiveLayoutVersion());\n       }\n \n       // Initialize the quota.\n       dir.updateCountForQuota();\n       // Enable quota checks.\n       dir.enableQuotaChecks();\n       if (haEnabled) {\n         // Renew all of the leases before becoming active.\n         // This is because, while we were in standby mode,\n         // the leases weren\u0027t getting renewed on this NN.\n         // Give them all a fresh start here.\n         leaseManager.renewAllLeases();\n       }\n       leaseManager.startMonitor();\n       startSecretManagerIfNecessary();\n \n       //ResourceMonitor required only at ActiveNN. See HDFS-2914\n       this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n       nnrmthread.start();\n \n       nnEditLogRoller \u003d new Daemon(new NameNodeEditLogRoller(\n           editLogRollerThreshold, editLogRollerInterval));\n       nnEditLogRoller.start();\n \n       if (lazyPersistFileScrubIntervalSec \u003e 0) {\n         lazyPersistFileScrubber \u003d new Daemon(new LazyPersistFileScrubber(\n             lazyPersistFileScrubIntervalSec));\n         lazyPersistFileScrubber.start();\n       } else {\n         LOG.warn(\"Lazy persist file scrubber is disabled,\"\n             + \" configured scrub interval is zero.\");\n       }\n \n       cacheManager.startMonitorThread();\n       blockManager.getDatanodeManager().setShouldSendCachingCommands(true);\n       if (provider !\u003d null) {\n         edekCacheLoader \u003d Executors.newSingleThreadExecutor(\n             new ThreadFactoryBuilder().setDaemon(true)\n                 .setNameFormat(\"Warm Up EDEK Cache Thread #%d\")\n                 .build());\n         FSDirEncryptionZoneOp.warmUpEdekCache(edekCacheLoader, dir,\n             edekCacheLoaderDelay, edekCacheLoaderInterval);\n       }\n     } finally {\n       startingActiveService \u003d false;\n+      blockManager.checkSafeMode();\n       writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void startActiveServices() throws IOException {\n    startingActiveService \u003d true;\n    LOG.info(\"Starting services required for active state\");\n    writeLock();\n    try {\n      FSEditLog editLog \u003d getFSImage().getEditLog();\n      \n      if (!editLog.isOpenForWrite()) {\n        // During startup, we\u0027re already open for write during initialization.\n        editLog.initJournalsForWrite();\n        // May need to recover\n        editLog.recoverUnclosedStreams();\n        \n        LOG.info(\"Catching up to latest edits from old active before \" +\n            \"taking over writer role in edits logs\");\n        editLogTailer.catchupDuringFailover();\n        \n        blockManager.setPostponeBlocksFromFuture(false);\n        blockManager.getDatanodeManager().markAllDatanodesStale();\n        blockManager.clearQueues();\n        blockManager.processAllPendingDNMessages();\n\n        // Only need to re-process the queue, If not in SafeMode.\n        if (!isInSafeMode()) {\n          LOG.info(\"Reprocessing replication and invalidation queues\");\n          blockManager.initializeReplQueues();\n        }\n\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"NameNode metadata after re-processing \" +\n              \"replication and invalidation queues during failover:\\n\" +\n              metaSaveAsString());\n        }\n\n        long nextTxId \u003d getFSImage().getLastAppliedTxId() + 1;\n        LOG.info(\"Will take over writing edit logs at txnid \" + \n            nextTxId);\n        editLog.setNextTxId(nextTxId);\n\n        getFSImage().editLog.openForWrite(getEffectiveLayoutVersion());\n      }\n\n      // Initialize the quota.\n      dir.updateCountForQuota();\n      // Enable quota checks.\n      dir.enableQuotaChecks();\n      if (haEnabled) {\n        // Renew all of the leases before becoming active.\n        // This is because, while we were in standby mode,\n        // the leases weren\u0027t getting renewed on this NN.\n        // Give them all a fresh start here.\n        leaseManager.renewAllLeases();\n      }\n      leaseManager.startMonitor();\n      startSecretManagerIfNecessary();\n\n      //ResourceMonitor required only at ActiveNN. See HDFS-2914\n      this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n      nnrmthread.start();\n\n      nnEditLogRoller \u003d new Daemon(new NameNodeEditLogRoller(\n          editLogRollerThreshold, editLogRollerInterval));\n      nnEditLogRoller.start();\n\n      if (lazyPersistFileScrubIntervalSec \u003e 0) {\n        lazyPersistFileScrubber \u003d new Daemon(new LazyPersistFileScrubber(\n            lazyPersistFileScrubIntervalSec));\n        lazyPersistFileScrubber.start();\n      } else {\n        LOG.warn(\"Lazy persist file scrubber is disabled,\"\n            + \" configured scrub interval is zero.\");\n      }\n\n      cacheManager.startMonitorThread();\n      blockManager.getDatanodeManager().setShouldSendCachingCommands(true);\n      if (provider !\u003d null) {\n        edekCacheLoader \u003d Executors.newSingleThreadExecutor(\n            new ThreadFactoryBuilder().setDaemon(true)\n                .setNameFormat(\"Warm Up EDEK Cache Thread #%d\")\n                .build());\n        FSDirEncryptionZoneOp.warmUpEdekCache(edekCacheLoader, dir,\n            edekCacheLoaderDelay, edekCacheLoaderInterval);\n      }\n    } finally {\n      startingActiveService \u003d false;\n      blockManager.checkSafeMode();\n      writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "e3bb38d62567eafe57d16b78deeba1b71c58e41c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9405. Warmup NameNode EDEK caches in background thread. Contributed by Xiao Chen.\n",
      "commitDate": "21/03/16 11:39 AM",
      "commitName": "e3bb38d62567eafe57d16b78deeba1b71c58e41c",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "04/03/16 3:29 PM",
      "commitNameOld": "2759689d7d23001f007cb0dbe2521de90734dd5c",
      "commitAuthorOld": "Chris Nauroth",
      "daysBetweenCommits": 16.8,
      "commitsBetweenForRepo": 81,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,80 +1,88 @@\n   void startActiveServices() throws IOException {\n     startingActiveService \u003d true;\n     LOG.info(\"Starting services required for active state\");\n     writeLock();\n     try {\n       FSEditLog editLog \u003d getFSImage().getEditLog();\n       \n       if (!editLog.isOpenForWrite()) {\n         // During startup, we\u0027re already open for write during initialization.\n         editLog.initJournalsForWrite();\n         // May need to recover\n         editLog.recoverUnclosedStreams();\n         \n         LOG.info(\"Catching up to latest edits from old active before \" +\n             \"taking over writer role in edits logs\");\n         editLogTailer.catchupDuringFailover();\n         \n         blockManager.setPostponeBlocksFromFuture(false);\n         blockManager.getDatanodeManager().markAllDatanodesStale();\n         blockManager.clearQueues();\n         blockManager.processAllPendingDNMessages();\n \n         // Only need to re-process the queue, If not in SafeMode.\n         if (!isInSafeMode()) {\n           LOG.info(\"Reprocessing replication and invalidation queues\");\n           blockManager.initializeReplQueues();\n         }\n \n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"NameNode metadata after re-processing \" +\n               \"replication and invalidation queues during failover:\\n\" +\n               metaSaveAsString());\n         }\n \n         long nextTxId \u003d getFSImage().getLastAppliedTxId() + 1;\n         LOG.info(\"Will take over writing edit logs at txnid \" + \n             nextTxId);\n         editLog.setNextTxId(nextTxId);\n \n         getFSImage().editLog.openForWrite(getEffectiveLayoutVersion());\n       }\n \n       // Initialize the quota.\n       dir.updateCountForQuota();\n       // Enable quota checks.\n       dir.enableQuotaChecks();\n       if (haEnabled) {\n         // Renew all of the leases before becoming active.\n         // This is because, while we were in standby mode,\n         // the leases weren\u0027t getting renewed on this NN.\n         // Give them all a fresh start here.\n         leaseManager.renewAllLeases();\n       }\n       leaseManager.startMonitor();\n       startSecretManagerIfNecessary();\n \n       //ResourceMonitor required only at ActiveNN. See HDFS-2914\n       this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n       nnrmthread.start();\n \n       nnEditLogRoller \u003d new Daemon(new NameNodeEditLogRoller(\n           editLogRollerThreshold, editLogRollerInterval));\n       nnEditLogRoller.start();\n \n       if (lazyPersistFileScrubIntervalSec \u003e 0) {\n         lazyPersistFileScrubber \u003d new Daemon(new LazyPersistFileScrubber(\n             lazyPersistFileScrubIntervalSec));\n         lazyPersistFileScrubber.start();\n       } else {\n         LOG.warn(\"Lazy persist file scrubber is disabled,\"\n             + \" configured scrub interval is zero.\");\n       }\n \n       cacheManager.startMonitorThread();\n       blockManager.getDatanodeManager().setShouldSendCachingCommands(true);\n+      if (provider !\u003d null) {\n+        edekCacheLoader \u003d Executors.newSingleThreadExecutor(\n+            new ThreadFactoryBuilder().setDaemon(true)\n+                .setNameFormat(\"Warm Up EDEK Cache Thread #%d\")\n+                .build());\n+        FSDirEncryptionZoneOp.warmUpEdekCache(edekCacheLoader, dir,\n+            edekCacheLoaderDelay, edekCacheLoaderInterval);\n+      }\n     } finally {\n       startingActiveService \u003d false;\n       writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void startActiveServices() throws IOException {\n    startingActiveService \u003d true;\n    LOG.info(\"Starting services required for active state\");\n    writeLock();\n    try {\n      FSEditLog editLog \u003d getFSImage().getEditLog();\n      \n      if (!editLog.isOpenForWrite()) {\n        // During startup, we\u0027re already open for write during initialization.\n        editLog.initJournalsForWrite();\n        // May need to recover\n        editLog.recoverUnclosedStreams();\n        \n        LOG.info(\"Catching up to latest edits from old active before \" +\n            \"taking over writer role in edits logs\");\n        editLogTailer.catchupDuringFailover();\n        \n        blockManager.setPostponeBlocksFromFuture(false);\n        blockManager.getDatanodeManager().markAllDatanodesStale();\n        blockManager.clearQueues();\n        blockManager.processAllPendingDNMessages();\n\n        // Only need to re-process the queue, If not in SafeMode.\n        if (!isInSafeMode()) {\n          LOG.info(\"Reprocessing replication and invalidation queues\");\n          blockManager.initializeReplQueues();\n        }\n\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"NameNode metadata after re-processing \" +\n              \"replication and invalidation queues during failover:\\n\" +\n              metaSaveAsString());\n        }\n\n        long nextTxId \u003d getFSImage().getLastAppliedTxId() + 1;\n        LOG.info(\"Will take over writing edit logs at txnid \" + \n            nextTxId);\n        editLog.setNextTxId(nextTxId);\n\n        getFSImage().editLog.openForWrite(getEffectiveLayoutVersion());\n      }\n\n      // Initialize the quota.\n      dir.updateCountForQuota();\n      // Enable quota checks.\n      dir.enableQuotaChecks();\n      if (haEnabled) {\n        // Renew all of the leases before becoming active.\n        // This is because, while we were in standby mode,\n        // the leases weren\u0027t getting renewed on this NN.\n        // Give them all a fresh start here.\n        leaseManager.renewAllLeases();\n      }\n      leaseManager.startMonitor();\n      startSecretManagerIfNecessary();\n\n      //ResourceMonitor required only at ActiveNN. See HDFS-2914\n      this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n      nnrmthread.start();\n\n      nnEditLogRoller \u003d new Daemon(new NameNodeEditLogRoller(\n          editLogRollerThreshold, editLogRollerInterval));\n      nnEditLogRoller.start();\n\n      if (lazyPersistFileScrubIntervalSec \u003e 0) {\n        lazyPersistFileScrubber \u003d new Daemon(new LazyPersistFileScrubber(\n            lazyPersistFileScrubIntervalSec));\n        lazyPersistFileScrubber.start();\n      } else {\n        LOG.warn(\"Lazy persist file scrubber is disabled,\"\n            + \" configured scrub interval is zero.\");\n      }\n\n      cacheManager.startMonitorThread();\n      blockManager.getDatanodeManager().setShouldSendCachingCommands(true);\n      if (provider !\u003d null) {\n        edekCacheLoader \u003d Executors.newSingleThreadExecutor(\n            new ThreadFactoryBuilder().setDaemon(true)\n                .setNameFormat(\"Warm Up EDEK Cache Thread #%d\")\n                .build());\n        FSDirEncryptionZoneOp.warmUpEdekCache(edekCacheLoader, dir,\n            edekCacheLoaderDelay, edekCacheLoaderInterval);\n      }\n    } finally {\n      startingActiveService \u003d false;\n      writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "a49cc74b4c72195dee1dfb6f9548e5e411dff553": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9129. Move the safemode block count into BlockManager. Contributed by Mingliang Liu.\n",
      "commitDate": "01/12/15 4:09 PM",
      "commitName": "a49cc74b4c72195dee1dfb6f9548e5e411dff553",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "25/11/15 2:22 PM",
      "commitNameOld": "e556c35b0596700f9ec9d0a51cf5027259d531b5",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 6.07,
      "commitsBetweenForRepo": 19,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,81 +1,80 @@\n   void startActiveServices() throws IOException {\n     startingActiveService \u003d true;\n     LOG.info(\"Starting services required for active state\");\n     writeLock();\n     try {\n       FSEditLog editLog \u003d getFSImage().getEditLog();\n       \n       if (!editLog.isOpenForWrite()) {\n         // During startup, we\u0027re already open for write during initialization.\n         editLog.initJournalsForWrite();\n         // May need to recover\n         editLog.recoverUnclosedStreams();\n         \n         LOG.info(\"Catching up to latest edits from old active before \" +\n             \"taking over writer role in edits logs\");\n         editLogTailer.catchupDuringFailover();\n         \n         blockManager.setPostponeBlocksFromFuture(false);\n         blockManager.getDatanodeManager().markAllDatanodesStale();\n         blockManager.clearQueues();\n         blockManager.processAllPendingDNMessages();\n \n         // Only need to re-process the queue, If not in SafeMode.\n         if (!isInSafeMode()) {\n           LOG.info(\"Reprocessing replication and invalidation queues\");\n           blockManager.initializeReplQueues();\n         }\n \n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"NameNode metadata after re-processing \" +\n               \"replication and invalidation queues during failover:\\n\" +\n               metaSaveAsString());\n         }\n-        \n+\n         long nextTxId \u003d getFSImage().getLastAppliedTxId() + 1;\n         LOG.info(\"Will take over writing edit logs at txnid \" + \n             nextTxId);\n         editLog.setNextTxId(nextTxId);\n \n         getFSImage().editLog.openForWrite(getEffectiveLayoutVersion());\n       }\n \n       // Initialize the quota.\n       dir.updateCountForQuota();\n       // Enable quota checks.\n       dir.enableQuotaChecks();\n       if (haEnabled) {\n         // Renew all of the leases before becoming active.\n         // This is because, while we were in standby mode,\n         // the leases weren\u0027t getting renewed on this NN.\n         // Give them all a fresh start here.\n         leaseManager.renewAllLeases();\n       }\n       leaseManager.startMonitor();\n       startSecretManagerIfNecessary();\n \n       //ResourceMonitor required only at ActiveNN. See HDFS-2914\n       this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n       nnrmthread.start();\n \n       nnEditLogRoller \u003d new Daemon(new NameNodeEditLogRoller(\n           editLogRollerThreshold, editLogRollerInterval));\n       nnEditLogRoller.start();\n \n       if (lazyPersistFileScrubIntervalSec \u003e 0) {\n         lazyPersistFileScrubber \u003d new Daemon(new LazyPersistFileScrubber(\n             lazyPersistFileScrubIntervalSec));\n         lazyPersistFileScrubber.start();\n       } else {\n         LOG.warn(\"Lazy persist file scrubber is disabled,\"\n             + \" configured scrub interval is zero.\");\n       }\n \n       cacheManager.startMonitorThread();\n       blockManager.getDatanodeManager().setShouldSendCachingCommands(true);\n     } finally {\n       startingActiveService \u003d false;\n-      checkSafeMode();\n       writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void startActiveServices() throws IOException {\n    startingActiveService \u003d true;\n    LOG.info(\"Starting services required for active state\");\n    writeLock();\n    try {\n      FSEditLog editLog \u003d getFSImage().getEditLog();\n      \n      if (!editLog.isOpenForWrite()) {\n        // During startup, we\u0027re already open for write during initialization.\n        editLog.initJournalsForWrite();\n        // May need to recover\n        editLog.recoverUnclosedStreams();\n        \n        LOG.info(\"Catching up to latest edits from old active before \" +\n            \"taking over writer role in edits logs\");\n        editLogTailer.catchupDuringFailover();\n        \n        blockManager.setPostponeBlocksFromFuture(false);\n        blockManager.getDatanodeManager().markAllDatanodesStale();\n        blockManager.clearQueues();\n        blockManager.processAllPendingDNMessages();\n\n        // Only need to re-process the queue, If not in SafeMode.\n        if (!isInSafeMode()) {\n          LOG.info(\"Reprocessing replication and invalidation queues\");\n          blockManager.initializeReplQueues();\n        }\n\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"NameNode metadata after re-processing \" +\n              \"replication and invalidation queues during failover:\\n\" +\n              metaSaveAsString());\n        }\n\n        long nextTxId \u003d getFSImage().getLastAppliedTxId() + 1;\n        LOG.info(\"Will take over writing edit logs at txnid \" + \n            nextTxId);\n        editLog.setNextTxId(nextTxId);\n\n        getFSImage().editLog.openForWrite(getEffectiveLayoutVersion());\n      }\n\n      // Initialize the quota.\n      dir.updateCountForQuota();\n      // Enable quota checks.\n      dir.enableQuotaChecks();\n      if (haEnabled) {\n        // Renew all of the leases before becoming active.\n        // This is because, while we were in standby mode,\n        // the leases weren\u0027t getting renewed on this NN.\n        // Give them all a fresh start here.\n        leaseManager.renewAllLeases();\n      }\n      leaseManager.startMonitor();\n      startSecretManagerIfNecessary();\n\n      //ResourceMonitor required only at ActiveNN. See HDFS-2914\n      this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n      nnrmthread.start();\n\n      nnEditLogRoller \u003d new Daemon(new NameNodeEditLogRoller(\n          editLogRollerThreshold, editLogRollerInterval));\n      nnEditLogRoller.start();\n\n      if (lazyPersistFileScrubIntervalSec \u003e 0) {\n        lazyPersistFileScrubber \u003d new Daemon(new LazyPersistFileScrubber(\n            lazyPersistFileScrubIntervalSec));\n        lazyPersistFileScrubber.start();\n      } else {\n        LOG.warn(\"Lazy persist file scrubber is disabled,\"\n            + \" configured scrub interval is zero.\");\n      }\n\n      cacheManager.startMonitorThread();\n      blockManager.getDatanodeManager().setShouldSendCachingCommands(true);\n    } finally {\n      startingActiveService \u003d false;\n      writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "a40342b0dab1f9137ae4b3679a5aca7f2a57d23d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6763. Initialize file system-wide quota once on transitioning to active. Contributed by Kihwal Lee\n",
      "commitDate": "10/09/15 7:16 AM",
      "commitName": "a40342b0dab1f9137ae4b3679a5aca7f2a57d23d",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "09/09/15 9:08 AM",
      "commitNameOld": "4d13335fc93780126bab35de92a640fa31b204d9",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 0.92,
      "commitsBetweenForRepo": 7,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,79 +1,81 @@\n   void startActiveServices() throws IOException {\n     startingActiveService \u003d true;\n     LOG.info(\"Starting services required for active state\");\n     writeLock();\n     try {\n       FSEditLog editLog \u003d getFSImage().getEditLog();\n       \n       if (!editLog.isOpenForWrite()) {\n         // During startup, we\u0027re already open for write during initialization.\n         editLog.initJournalsForWrite();\n         // May need to recover\n         editLog.recoverUnclosedStreams();\n         \n         LOG.info(\"Catching up to latest edits from old active before \" +\n             \"taking over writer role in edits logs\");\n         editLogTailer.catchupDuringFailover();\n         \n         blockManager.setPostponeBlocksFromFuture(false);\n         blockManager.getDatanodeManager().markAllDatanodesStale();\n         blockManager.clearQueues();\n         blockManager.processAllPendingDNMessages();\n \n         // Only need to re-process the queue, If not in SafeMode.\n         if (!isInSafeMode()) {\n           LOG.info(\"Reprocessing replication and invalidation queues\");\n           blockManager.initializeReplQueues();\n         }\n \n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"NameNode metadata after re-processing \" +\n               \"replication and invalidation queues during failover:\\n\" +\n               metaSaveAsString());\n         }\n         \n         long nextTxId \u003d getFSImage().getLastAppliedTxId() + 1;\n         LOG.info(\"Will take over writing edit logs at txnid \" + \n             nextTxId);\n         editLog.setNextTxId(nextTxId);\n \n         getFSImage().editLog.openForWrite(getEffectiveLayoutVersion());\n       }\n \n+      // Initialize the quota.\n+      dir.updateCountForQuota();\n       // Enable quota checks.\n       dir.enableQuotaChecks();\n       if (haEnabled) {\n         // Renew all of the leases before becoming active.\n         // This is because, while we were in standby mode,\n         // the leases weren\u0027t getting renewed on this NN.\n         // Give them all a fresh start here.\n         leaseManager.renewAllLeases();\n       }\n       leaseManager.startMonitor();\n       startSecretManagerIfNecessary();\n \n       //ResourceMonitor required only at ActiveNN. See HDFS-2914\n       this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n       nnrmthread.start();\n \n       nnEditLogRoller \u003d new Daemon(new NameNodeEditLogRoller(\n           editLogRollerThreshold, editLogRollerInterval));\n       nnEditLogRoller.start();\n \n       if (lazyPersistFileScrubIntervalSec \u003e 0) {\n         lazyPersistFileScrubber \u003d new Daemon(new LazyPersistFileScrubber(\n             lazyPersistFileScrubIntervalSec));\n         lazyPersistFileScrubber.start();\n       } else {\n         LOG.warn(\"Lazy persist file scrubber is disabled,\"\n             + \" configured scrub interval is zero.\");\n       }\n \n       cacheManager.startMonitorThread();\n       blockManager.getDatanodeManager().setShouldSendCachingCommands(true);\n     } finally {\n       startingActiveService \u003d false;\n       checkSafeMode();\n       writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void startActiveServices() throws IOException {\n    startingActiveService \u003d true;\n    LOG.info(\"Starting services required for active state\");\n    writeLock();\n    try {\n      FSEditLog editLog \u003d getFSImage().getEditLog();\n      \n      if (!editLog.isOpenForWrite()) {\n        // During startup, we\u0027re already open for write during initialization.\n        editLog.initJournalsForWrite();\n        // May need to recover\n        editLog.recoverUnclosedStreams();\n        \n        LOG.info(\"Catching up to latest edits from old active before \" +\n            \"taking over writer role in edits logs\");\n        editLogTailer.catchupDuringFailover();\n        \n        blockManager.setPostponeBlocksFromFuture(false);\n        blockManager.getDatanodeManager().markAllDatanodesStale();\n        blockManager.clearQueues();\n        blockManager.processAllPendingDNMessages();\n\n        // Only need to re-process the queue, If not in SafeMode.\n        if (!isInSafeMode()) {\n          LOG.info(\"Reprocessing replication and invalidation queues\");\n          blockManager.initializeReplQueues();\n        }\n\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"NameNode metadata after re-processing \" +\n              \"replication and invalidation queues during failover:\\n\" +\n              metaSaveAsString());\n        }\n        \n        long nextTxId \u003d getFSImage().getLastAppliedTxId() + 1;\n        LOG.info(\"Will take over writing edit logs at txnid \" + \n            nextTxId);\n        editLog.setNextTxId(nextTxId);\n\n        getFSImage().editLog.openForWrite(getEffectiveLayoutVersion());\n      }\n\n      // Initialize the quota.\n      dir.updateCountForQuota();\n      // Enable quota checks.\n      dir.enableQuotaChecks();\n      if (haEnabled) {\n        // Renew all of the leases before becoming active.\n        // This is because, while we were in standby mode,\n        // the leases weren\u0027t getting renewed on this NN.\n        // Give them all a fresh start here.\n        leaseManager.renewAllLeases();\n      }\n      leaseManager.startMonitor();\n      startSecretManagerIfNecessary();\n\n      //ResourceMonitor required only at ActiveNN. See HDFS-2914\n      this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n      nnrmthread.start();\n\n      nnEditLogRoller \u003d new Daemon(new NameNodeEditLogRoller(\n          editLogRollerThreshold, editLogRollerInterval));\n      nnEditLogRoller.start();\n\n      if (lazyPersistFileScrubIntervalSec \u003e 0) {\n        lazyPersistFileScrubber \u003d new Daemon(new LazyPersistFileScrubber(\n            lazyPersistFileScrubIntervalSec));\n        lazyPersistFileScrubber.start();\n      } else {\n        LOG.warn(\"Lazy persist file scrubber is disabled,\"\n            + \" configured scrub interval is zero.\");\n      }\n\n      cacheManager.startMonitorThread();\n      blockManager.getDatanodeManager().setShouldSendCachingCommands(true);\n    } finally {\n      startingActiveService \u003d false;\n      checkSafeMode();\n      writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "715b9c649982bff91d1f9eae656ba3b82178e1a3": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8984. Move replication queues related methods in FSNamesystem to BlockManager. Contributed by Haohui Mai.\n",
      "commitDate": "04/09/15 11:45 AM",
      "commitName": "715b9c649982bff91d1f9eae656ba3b82178e1a3",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "04/09/15 11:42 AM",
      "commitNameOld": "8928729c80af0a154524e06fb13ed9b191986a78",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,79 +1,79 @@\n   void startActiveServices() throws IOException {\n     startingActiveService \u003d true;\n     LOG.info(\"Starting services required for active state\");\n     writeLock();\n     try {\n       FSEditLog editLog \u003d getFSImage().getEditLog();\n       \n       if (!editLog.isOpenForWrite()) {\n         // During startup, we\u0027re already open for write during initialization.\n         editLog.initJournalsForWrite();\n         // May need to recover\n         editLog.recoverUnclosedStreams();\n         \n         LOG.info(\"Catching up to latest edits from old active before \" +\n             \"taking over writer role in edits logs\");\n         editLogTailer.catchupDuringFailover();\n         \n         blockManager.setPostponeBlocksFromFuture(false);\n         blockManager.getDatanodeManager().markAllDatanodesStale();\n         blockManager.clearQueues();\n         blockManager.processAllPendingDNMessages();\n \n         // Only need to re-process the queue, If not in SafeMode.\n         if (!isInSafeMode()) {\n           LOG.info(\"Reprocessing replication and invalidation queues\");\n-          initializeReplQueues();\n+          blockManager.initializeReplQueues();\n         }\n \n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"NameNode metadata after re-processing \" +\n               \"replication and invalidation queues during failover:\\n\" +\n               metaSaveAsString());\n         }\n         \n         long nextTxId \u003d getFSImage().getLastAppliedTxId() + 1;\n         LOG.info(\"Will take over writing edit logs at txnid \" + \n             nextTxId);\n         editLog.setNextTxId(nextTxId);\n \n         getFSImage().editLog.openForWrite(getEffectiveLayoutVersion());\n       }\n \n       // Enable quota checks.\n       dir.enableQuotaChecks();\n       if (haEnabled) {\n         // Renew all of the leases before becoming active.\n         // This is because, while we were in standby mode,\n         // the leases weren\u0027t getting renewed on this NN.\n         // Give them all a fresh start here.\n         leaseManager.renewAllLeases();\n       }\n       leaseManager.startMonitor();\n       startSecretManagerIfNecessary();\n \n       //ResourceMonitor required only at ActiveNN. See HDFS-2914\n       this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n       nnrmthread.start();\n \n       nnEditLogRoller \u003d new Daemon(new NameNodeEditLogRoller(\n           editLogRollerThreshold, editLogRollerInterval));\n       nnEditLogRoller.start();\n \n       if (lazyPersistFileScrubIntervalSec \u003e 0) {\n         lazyPersistFileScrubber \u003d new Daemon(new LazyPersistFileScrubber(\n             lazyPersistFileScrubIntervalSec));\n         lazyPersistFileScrubber.start();\n       } else {\n         LOG.warn(\"Lazy persist file scrubber is disabled,\"\n             + \" configured scrub interval is zero.\");\n       }\n \n       cacheManager.startMonitorThread();\n       blockManager.getDatanodeManager().setShouldSendCachingCommands(true);\n     } finally {\n       startingActiveService \u003d false;\n       checkSafeMode();\n       writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void startActiveServices() throws IOException {\n    startingActiveService \u003d true;\n    LOG.info(\"Starting services required for active state\");\n    writeLock();\n    try {\n      FSEditLog editLog \u003d getFSImage().getEditLog();\n      \n      if (!editLog.isOpenForWrite()) {\n        // During startup, we\u0027re already open for write during initialization.\n        editLog.initJournalsForWrite();\n        // May need to recover\n        editLog.recoverUnclosedStreams();\n        \n        LOG.info(\"Catching up to latest edits from old active before \" +\n            \"taking over writer role in edits logs\");\n        editLogTailer.catchupDuringFailover();\n        \n        blockManager.setPostponeBlocksFromFuture(false);\n        blockManager.getDatanodeManager().markAllDatanodesStale();\n        blockManager.clearQueues();\n        blockManager.processAllPendingDNMessages();\n\n        // Only need to re-process the queue, If not in SafeMode.\n        if (!isInSafeMode()) {\n          LOG.info(\"Reprocessing replication and invalidation queues\");\n          blockManager.initializeReplQueues();\n        }\n\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"NameNode metadata after re-processing \" +\n              \"replication and invalidation queues during failover:\\n\" +\n              metaSaveAsString());\n        }\n        \n        long nextTxId \u003d getFSImage().getLastAppliedTxId() + 1;\n        LOG.info(\"Will take over writing edit logs at txnid \" + \n            nextTxId);\n        editLog.setNextTxId(nextTxId);\n\n        getFSImage().editLog.openForWrite(getEffectiveLayoutVersion());\n      }\n\n      // Enable quota checks.\n      dir.enableQuotaChecks();\n      if (haEnabled) {\n        // Renew all of the leases before becoming active.\n        // This is because, while we were in standby mode,\n        // the leases weren\u0027t getting renewed on this NN.\n        // Give them all a fresh start here.\n        leaseManager.renewAllLeases();\n      }\n      leaseManager.startMonitor();\n      startSecretManagerIfNecessary();\n\n      //ResourceMonitor required only at ActiveNN. See HDFS-2914\n      this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n      nnrmthread.start();\n\n      nnEditLogRoller \u003d new Daemon(new NameNodeEditLogRoller(\n          editLogRollerThreshold, editLogRollerInterval));\n      nnEditLogRoller.start();\n\n      if (lazyPersistFileScrubIntervalSec \u003e 0) {\n        lazyPersistFileScrubber \u003d new Daemon(new LazyPersistFileScrubber(\n            lazyPersistFileScrubIntervalSec));\n        lazyPersistFileScrubber.start();\n      } else {\n        LOG.warn(\"Lazy persist file scrubber is disabled,\"\n            + \" configured scrub interval is zero.\");\n      }\n\n      cacheManager.startMonitorThread();\n      blockManager.getDatanodeManager().setShouldSendCachingCommands(true);\n    } finally {\n      startingActiveService \u003d false;\n      checkSafeMode();\n      writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "71de367c5e80ea76d1e8d21f0216cd6b879dcee5": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8432. Introduce a minimum compatible layout version to allow downgrade in more rolling upgrade use cases. Contributed by Chris Nauroth.\n",
      "commitDate": "06/06/15 9:43 AM",
      "commitName": "71de367c5e80ea76d1e8d21f0216cd6b879dcee5",
      "commitAuthor": "cnauroth",
      "commitDateOld": "05/06/15 3:09 PM",
      "commitNameOld": "3841d09765bab332c9ae4803c5981799585b1f41",
      "commitAuthorOld": "Xiaoyu Yao",
      "daysBetweenCommits": 0.77,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,79 +1,79 @@\n   void startActiveServices() throws IOException {\n     startingActiveService \u003d true;\n     LOG.info(\"Starting services required for active state\");\n     writeLock();\n     try {\n       FSEditLog editLog \u003d getFSImage().getEditLog();\n       \n       if (!editLog.isOpenForWrite()) {\n         // During startup, we\u0027re already open for write during initialization.\n         editLog.initJournalsForWrite();\n         // May need to recover\n         editLog.recoverUnclosedStreams();\n         \n         LOG.info(\"Catching up to latest edits from old active before \" +\n             \"taking over writer role in edits logs\");\n         editLogTailer.catchupDuringFailover();\n         \n         blockManager.setPostponeBlocksFromFuture(false);\n         blockManager.getDatanodeManager().markAllDatanodesStale();\n         blockManager.clearQueues();\n         blockManager.processAllPendingDNMessages();\n \n         // Only need to re-process the queue, If not in SafeMode.\n         if (!isInSafeMode()) {\n           LOG.info(\"Reprocessing replication and invalidation queues\");\n           initializeReplQueues();\n         }\n \n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"NameNode metadata after re-processing \" +\n               \"replication and invalidation queues during failover:\\n\" +\n               metaSaveAsString());\n         }\n         \n         long nextTxId \u003d getFSImage().getLastAppliedTxId() + 1;\n         LOG.info(\"Will take over writing edit logs at txnid \" + \n             nextTxId);\n         editLog.setNextTxId(nextTxId);\n \n-        getFSImage().editLog.openForWrite();\n+        getFSImage().editLog.openForWrite(getEffectiveLayoutVersion());\n       }\n \n       // Enable quota checks.\n       dir.enableQuotaChecks();\n       if (haEnabled) {\n         // Renew all of the leases before becoming active.\n         // This is because, while we were in standby mode,\n         // the leases weren\u0027t getting renewed on this NN.\n         // Give them all a fresh start here.\n         leaseManager.renewAllLeases();\n       }\n       leaseManager.startMonitor();\n       startSecretManagerIfNecessary();\n \n       //ResourceMonitor required only at ActiveNN. See HDFS-2914\n       this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n       nnrmthread.start();\n \n       nnEditLogRoller \u003d new Daemon(new NameNodeEditLogRoller(\n           editLogRollerThreshold, editLogRollerInterval));\n       nnEditLogRoller.start();\n \n       if (lazyPersistFileScrubIntervalSec \u003e 0) {\n         lazyPersistFileScrubber \u003d new Daemon(new LazyPersistFileScrubber(\n             lazyPersistFileScrubIntervalSec));\n         lazyPersistFileScrubber.start();\n       } else {\n         LOG.warn(\"Lazy persist file scrubber is disabled,\"\n             + \" configured scrub interval is zero.\");\n       }\n \n       cacheManager.startMonitorThread();\n       blockManager.getDatanodeManager().setShouldSendCachingCommands(true);\n     } finally {\n       startingActiveService \u003d false;\n       checkSafeMode();\n       writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void startActiveServices() throws IOException {\n    startingActiveService \u003d true;\n    LOG.info(\"Starting services required for active state\");\n    writeLock();\n    try {\n      FSEditLog editLog \u003d getFSImage().getEditLog();\n      \n      if (!editLog.isOpenForWrite()) {\n        // During startup, we\u0027re already open for write during initialization.\n        editLog.initJournalsForWrite();\n        // May need to recover\n        editLog.recoverUnclosedStreams();\n        \n        LOG.info(\"Catching up to latest edits from old active before \" +\n            \"taking over writer role in edits logs\");\n        editLogTailer.catchupDuringFailover();\n        \n        blockManager.setPostponeBlocksFromFuture(false);\n        blockManager.getDatanodeManager().markAllDatanodesStale();\n        blockManager.clearQueues();\n        blockManager.processAllPendingDNMessages();\n\n        // Only need to re-process the queue, If not in SafeMode.\n        if (!isInSafeMode()) {\n          LOG.info(\"Reprocessing replication and invalidation queues\");\n          initializeReplQueues();\n        }\n\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"NameNode metadata after re-processing \" +\n              \"replication and invalidation queues during failover:\\n\" +\n              metaSaveAsString());\n        }\n        \n        long nextTxId \u003d getFSImage().getLastAppliedTxId() + 1;\n        LOG.info(\"Will take over writing edit logs at txnid \" + \n            nextTxId);\n        editLog.setNextTxId(nextTxId);\n\n        getFSImage().editLog.openForWrite(getEffectiveLayoutVersion());\n      }\n\n      // Enable quota checks.\n      dir.enableQuotaChecks();\n      if (haEnabled) {\n        // Renew all of the leases before becoming active.\n        // This is because, while we were in standby mode,\n        // the leases weren\u0027t getting renewed on this NN.\n        // Give them all a fresh start here.\n        leaseManager.renewAllLeases();\n      }\n      leaseManager.startMonitor();\n      startSecretManagerIfNecessary();\n\n      //ResourceMonitor required only at ActiveNN. See HDFS-2914\n      this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n      nnrmthread.start();\n\n      nnEditLogRoller \u003d new Daemon(new NameNodeEditLogRoller(\n          editLogRollerThreshold, editLogRollerInterval));\n      nnEditLogRoller.start();\n\n      if (lazyPersistFileScrubIntervalSec \u003e 0) {\n        lazyPersistFileScrubber \u003d new Daemon(new LazyPersistFileScrubber(\n            lazyPersistFileScrubIntervalSec));\n        lazyPersistFileScrubber.start();\n      } else {\n        LOG.warn(\"Lazy persist file scrubber is disabled,\"\n            + \" configured scrub interval is zero.\");\n      }\n\n      cacheManager.startMonitorThread();\n      blockManager.getDatanodeManager().setShouldSendCachingCommands(true);\n    } finally {\n      startingActiveService \u003d false;\n      checkSafeMode();\n      writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "64d30a61867e5cb0a2acaa7ae4fa4d3eb3be8edd": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8276. LazyPersistFileScrubber should be disabled if scrubber interval configured zero. (Contributed by Surendra Singh Lilhore)\n",
      "commitDate": "01/05/15 2:43 PM",
      "commitName": "64d30a61867e5cb0a2acaa7ae4fa4d3eb3be8edd",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "29/04/15 11:12 AM",
      "commitNameOld": "3dd6395bb2448e5b178a51c864e3c9a3d12e8bc9",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 2.15,
      "commitsBetweenForRepo": 20,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,76 +1,79 @@\n   void startActiveServices() throws IOException {\n     startingActiveService \u003d true;\n     LOG.info(\"Starting services required for active state\");\n     writeLock();\n     try {\n       FSEditLog editLog \u003d getFSImage().getEditLog();\n       \n       if (!editLog.isOpenForWrite()) {\n         // During startup, we\u0027re already open for write during initialization.\n         editLog.initJournalsForWrite();\n         // May need to recover\n         editLog.recoverUnclosedStreams();\n         \n         LOG.info(\"Catching up to latest edits from old active before \" +\n             \"taking over writer role in edits logs\");\n         editLogTailer.catchupDuringFailover();\n         \n         blockManager.setPostponeBlocksFromFuture(false);\n         blockManager.getDatanodeManager().markAllDatanodesStale();\n         blockManager.clearQueues();\n         blockManager.processAllPendingDNMessages();\n \n         // Only need to re-process the queue, If not in SafeMode.\n         if (!isInSafeMode()) {\n           LOG.info(\"Reprocessing replication and invalidation queues\");\n           initializeReplQueues();\n         }\n \n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"NameNode metadata after re-processing \" +\n               \"replication and invalidation queues during failover:\\n\" +\n               metaSaveAsString());\n         }\n         \n         long nextTxId \u003d getFSImage().getLastAppliedTxId() + 1;\n         LOG.info(\"Will take over writing edit logs at txnid \" + \n             nextTxId);\n         editLog.setNextTxId(nextTxId);\n \n         getFSImage().editLog.openForWrite();\n       }\n \n       // Enable quota checks.\n       dir.enableQuotaChecks();\n       if (haEnabled) {\n         // Renew all of the leases before becoming active.\n         // This is because, while we were in standby mode,\n         // the leases weren\u0027t getting renewed on this NN.\n         // Give them all a fresh start here.\n         leaseManager.renewAllLeases();\n       }\n       leaseManager.startMonitor();\n       startSecretManagerIfNecessary();\n \n       //ResourceMonitor required only at ActiveNN. See HDFS-2914\n       this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n       nnrmthread.start();\n \n       nnEditLogRoller \u003d new Daemon(new NameNodeEditLogRoller(\n           editLogRollerThreshold, editLogRollerInterval));\n       nnEditLogRoller.start();\n \n       if (lazyPersistFileScrubIntervalSec \u003e 0) {\n         lazyPersistFileScrubber \u003d new Daemon(new LazyPersistFileScrubber(\n             lazyPersistFileScrubIntervalSec));\n         lazyPersistFileScrubber.start();\n+      } else {\n+        LOG.warn(\"Lazy persist file scrubber is disabled,\"\n+            + \" configured scrub interval is zero.\");\n       }\n \n       cacheManager.startMonitorThread();\n       blockManager.getDatanodeManager().setShouldSendCachingCommands(true);\n     } finally {\n       startingActiveService \u003d false;\n       checkSafeMode();\n       writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void startActiveServices() throws IOException {\n    startingActiveService \u003d true;\n    LOG.info(\"Starting services required for active state\");\n    writeLock();\n    try {\n      FSEditLog editLog \u003d getFSImage().getEditLog();\n      \n      if (!editLog.isOpenForWrite()) {\n        // During startup, we\u0027re already open for write during initialization.\n        editLog.initJournalsForWrite();\n        // May need to recover\n        editLog.recoverUnclosedStreams();\n        \n        LOG.info(\"Catching up to latest edits from old active before \" +\n            \"taking over writer role in edits logs\");\n        editLogTailer.catchupDuringFailover();\n        \n        blockManager.setPostponeBlocksFromFuture(false);\n        blockManager.getDatanodeManager().markAllDatanodesStale();\n        blockManager.clearQueues();\n        blockManager.processAllPendingDNMessages();\n\n        // Only need to re-process the queue, If not in SafeMode.\n        if (!isInSafeMode()) {\n          LOG.info(\"Reprocessing replication and invalidation queues\");\n          initializeReplQueues();\n        }\n\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"NameNode metadata after re-processing \" +\n              \"replication and invalidation queues during failover:\\n\" +\n              metaSaveAsString());\n        }\n        \n        long nextTxId \u003d getFSImage().getLastAppliedTxId() + 1;\n        LOG.info(\"Will take over writing edit logs at txnid \" + \n            nextTxId);\n        editLog.setNextTxId(nextTxId);\n\n        getFSImage().editLog.openForWrite();\n      }\n\n      // Enable quota checks.\n      dir.enableQuotaChecks();\n      if (haEnabled) {\n        // Renew all of the leases before becoming active.\n        // This is because, while we were in standby mode,\n        // the leases weren\u0027t getting renewed on this NN.\n        // Give them all a fresh start here.\n        leaseManager.renewAllLeases();\n      }\n      leaseManager.startMonitor();\n      startSecretManagerIfNecessary();\n\n      //ResourceMonitor required only at ActiveNN. See HDFS-2914\n      this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n      nnrmthread.start();\n\n      nnEditLogRoller \u003d new Daemon(new NameNodeEditLogRoller(\n          editLogRollerThreshold, editLogRollerInterval));\n      nnEditLogRoller.start();\n\n      if (lazyPersistFileScrubIntervalSec \u003e 0) {\n        lazyPersistFileScrubber \u003d new Daemon(new LazyPersistFileScrubber(\n            lazyPersistFileScrubIntervalSec));\n        lazyPersistFileScrubber.start();\n      } else {\n        LOG.warn(\"Lazy persist file scrubber is disabled,\"\n            + \" configured scrub interval is zero.\");\n      }\n\n      cacheManager.startMonitorThread();\n      blockManager.getDatanodeManager().setShouldSendCachingCommands(true);\n    } finally {\n      startingActiveService \u003d false;\n      checkSafeMode();\n      writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "9e355719653c5e7b48b601090634882e4f29a743": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7046. HA NN can NPE upon transition to active. Contributed by\nKihwal Lee.\n",
      "commitDate": "19/09/14 3:07 PM",
      "commitName": "9e355719653c5e7b48b601090634882e4f29a743",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "18/09/14 5:49 PM",
      "commitNameOld": "8e73084491c9f317bc8cc3590f93ca67a63687a8",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 0.89,
      "commitsBetweenForRepo": 11,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,69 +1,70 @@\n   void startActiveServices() throws IOException {\n     startingActiveService \u003d true;\n     LOG.info(\"Starting services required for active state\");\n     writeLock();\n     try {\n       FSEditLog editLog \u003d getFSImage().getEditLog();\n       \n       if (!editLog.isOpenForWrite()) {\n         // During startup, we\u0027re already open for write during initialization.\n         editLog.initJournalsForWrite();\n         // May need to recover\n         editLog.recoverUnclosedStreams();\n         \n         LOG.info(\"Catching up to latest edits from old active before \" +\n             \"taking over writer role in edits logs\");\n         editLogTailer.catchupDuringFailover();\n         \n         blockManager.setPostponeBlocksFromFuture(false);\n         blockManager.getDatanodeManager().markAllDatanodesStale();\n         blockManager.clearQueues();\n         blockManager.processAllPendingDNMessages();\n \n         // Only need to re-process the queue, If not in SafeMode.\n         if (!isInSafeMode()) {\n           LOG.info(\"Reprocessing replication and invalidation queues\");\n           initializeReplQueues();\n         }\n \n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"NameNode metadata after re-processing \" +\n               \"replication and invalidation queues during failover:\\n\" +\n               metaSaveAsString());\n         }\n         \n         long nextTxId \u003d getFSImage().getLastAppliedTxId() + 1;\n         LOG.info(\"Will take over writing edit logs at txnid \" + \n             nextTxId);\n         editLog.setNextTxId(nextTxId);\n \n         getFSImage().editLog.openForWrite();\n       }\n \n       // Enable quota checks.\n       dir.enableQuotaChecks();\n       if (haEnabled) {\n         // Renew all of the leases before becoming active.\n         // This is because, while we were in standby mode,\n         // the leases weren\u0027t getting renewed on this NN.\n         // Give them all a fresh start here.\n         leaseManager.renewAllLeases();\n       }\n       leaseManager.startMonitor();\n       startSecretManagerIfNecessary();\n \n       //ResourceMonitor required only at ActiveNN. See HDFS-2914\n       this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n       nnrmthread.start();\n \n       nnEditLogRoller \u003d new Daemon(new NameNodeEditLogRoller(\n           editLogRollerThreshold, editLogRollerInterval));\n       nnEditLogRoller.start();\n \n       cacheManager.startMonitorThread();\n       blockManager.getDatanodeManager().setShouldSendCachingCommands(true);\n     } finally {\n-      writeUnlock();\n       startingActiveService \u003d false;\n+      checkSafeMode();\n+      writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void startActiveServices() throws IOException {\n    startingActiveService \u003d true;\n    LOG.info(\"Starting services required for active state\");\n    writeLock();\n    try {\n      FSEditLog editLog \u003d getFSImage().getEditLog();\n      \n      if (!editLog.isOpenForWrite()) {\n        // During startup, we\u0027re already open for write during initialization.\n        editLog.initJournalsForWrite();\n        // May need to recover\n        editLog.recoverUnclosedStreams();\n        \n        LOG.info(\"Catching up to latest edits from old active before \" +\n            \"taking over writer role in edits logs\");\n        editLogTailer.catchupDuringFailover();\n        \n        blockManager.setPostponeBlocksFromFuture(false);\n        blockManager.getDatanodeManager().markAllDatanodesStale();\n        blockManager.clearQueues();\n        blockManager.processAllPendingDNMessages();\n\n        // Only need to re-process the queue, If not in SafeMode.\n        if (!isInSafeMode()) {\n          LOG.info(\"Reprocessing replication and invalidation queues\");\n          initializeReplQueues();\n        }\n\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"NameNode metadata after re-processing \" +\n              \"replication and invalidation queues during failover:\\n\" +\n              metaSaveAsString());\n        }\n        \n        long nextTxId \u003d getFSImage().getLastAppliedTxId() + 1;\n        LOG.info(\"Will take over writing edit logs at txnid \" + \n            nextTxId);\n        editLog.setNextTxId(nextTxId);\n\n        getFSImage().editLog.openForWrite();\n      }\n\n      // Enable quota checks.\n      dir.enableQuotaChecks();\n      if (haEnabled) {\n        // Renew all of the leases before becoming active.\n        // This is because, while we were in standby mode,\n        // the leases weren\u0027t getting renewed on this NN.\n        // Give them all a fresh start here.\n        leaseManager.renewAllLeases();\n      }\n      leaseManager.startMonitor();\n      startSecretManagerIfNecessary();\n\n      //ResourceMonitor required only at ActiveNN. See HDFS-2914\n      this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n      nnrmthread.start();\n\n      nnEditLogRoller \u003d new Daemon(new NameNodeEditLogRoller(\n          editLogRollerThreshold, editLogRollerInterval));\n      nnEditLogRoller.start();\n\n      cacheManager.startMonitorThread();\n      blockManager.getDatanodeManager().setShouldSendCachingCommands(true);\n    } finally {\n      startingActiveService \u003d false;\n      checkSafeMode();\n      writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "2e987148e02d0087fc70ce5b1ce571d3324bf1dd": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6929. NN periodically unlinks lazy persist files with missing replicas from namespace. (Arpit Agarwal)\n",
      "commitDate": "27/08/14 9:47 PM",
      "commitName": "2e987148e02d0087fc70ce5b1ce571d3324bf1dd",
      "commitAuthor": "arp",
      "commitDateOld": "27/08/14 9:47 PM",
      "commitNameOld": "042b33f20b01aadb5cd03da731ae7a3d94026aac",
      "commitAuthorOld": "arp",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,69 +1,75 @@\n   void startActiveServices() throws IOException {\n     startingActiveService \u003d true;\n     LOG.info(\"Starting services required for active state\");\n     writeLock();\n     try {\n       FSEditLog editLog \u003d getFSImage().getEditLog();\n       \n       if (!editLog.isOpenForWrite()) {\n         // During startup, we\u0027re already open for write during initialization.\n         editLog.initJournalsForWrite();\n         // May need to recover\n         editLog.recoverUnclosedStreams();\n         \n         LOG.info(\"Catching up to latest edits from old active before \" +\n             \"taking over writer role in edits logs\");\n         editLogTailer.catchupDuringFailover();\n         \n         blockManager.setPostponeBlocksFromFuture(false);\n         blockManager.getDatanodeManager().markAllDatanodesStale();\n         blockManager.clearQueues();\n         blockManager.processAllPendingDNMessages();\n \n         // Only need to re-process the queue, If not in SafeMode.\n         if (!isInSafeMode()) {\n           LOG.info(\"Reprocessing replication and invalidation queues\");\n           initializeReplQueues();\n         }\n \n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"NameNode metadata after re-processing \" +\n               \"replication and invalidation queues during failover:\\n\" +\n               metaSaveAsString());\n         }\n         \n         long nextTxId \u003d getFSImage().getLastAppliedTxId() + 1;\n         LOG.info(\"Will take over writing edit logs at txnid \" + \n             nextTxId);\n         editLog.setNextTxId(nextTxId);\n \n         getFSImage().editLog.openForWrite();\n       }\n \n       // Enable quota checks.\n       dir.enableQuotaChecks();\n       if (haEnabled) {\n         // Renew all of the leases before becoming active.\n         // This is because, while we were in standby mode,\n         // the leases weren\u0027t getting renewed on this NN.\n         // Give them all a fresh start here.\n         leaseManager.renewAllLeases();\n       }\n       leaseManager.startMonitor();\n       startSecretManagerIfNecessary();\n \n       //ResourceMonitor required only at ActiveNN. See HDFS-2914\n       this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n       nnrmthread.start();\n \n       nnEditLogRoller \u003d new Daemon(new NameNodeEditLogRoller(\n           editLogRollerThreshold, editLogRollerInterval));\n       nnEditLogRoller.start();\n \n+      if (lazyPersistFileScrubIntervalSec \u003e 0) {\n+        lazyPersistFileScrubber \u003d new Daemon(new LazyPersistFileScrubber(\n+            lazyPersistFileScrubIntervalSec));\n+        lazyPersistFileScrubber.start();\n+      }\n+\n       cacheManager.startMonitorThread();\n       blockManager.getDatanodeManager().setShouldSendCachingCommands(true);\n     } finally {\n       writeUnlock();\n       startingActiveService \u003d false;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void startActiveServices() throws IOException {\n    startingActiveService \u003d true;\n    LOG.info(\"Starting services required for active state\");\n    writeLock();\n    try {\n      FSEditLog editLog \u003d getFSImage().getEditLog();\n      \n      if (!editLog.isOpenForWrite()) {\n        // During startup, we\u0027re already open for write during initialization.\n        editLog.initJournalsForWrite();\n        // May need to recover\n        editLog.recoverUnclosedStreams();\n        \n        LOG.info(\"Catching up to latest edits from old active before \" +\n            \"taking over writer role in edits logs\");\n        editLogTailer.catchupDuringFailover();\n        \n        blockManager.setPostponeBlocksFromFuture(false);\n        blockManager.getDatanodeManager().markAllDatanodesStale();\n        blockManager.clearQueues();\n        blockManager.processAllPendingDNMessages();\n\n        // Only need to re-process the queue, If not in SafeMode.\n        if (!isInSafeMode()) {\n          LOG.info(\"Reprocessing replication and invalidation queues\");\n          initializeReplQueues();\n        }\n\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"NameNode metadata after re-processing \" +\n              \"replication and invalidation queues during failover:\\n\" +\n              metaSaveAsString());\n        }\n        \n        long nextTxId \u003d getFSImage().getLastAppliedTxId() + 1;\n        LOG.info(\"Will take over writing edit logs at txnid \" + \n            nextTxId);\n        editLog.setNextTxId(nextTxId);\n\n        getFSImage().editLog.openForWrite();\n      }\n\n      // Enable quota checks.\n      dir.enableQuotaChecks();\n      if (haEnabled) {\n        // Renew all of the leases before becoming active.\n        // This is because, while we were in standby mode,\n        // the leases weren\u0027t getting renewed on this NN.\n        // Give them all a fresh start here.\n        leaseManager.renewAllLeases();\n      }\n      leaseManager.startMonitor();\n      startSecretManagerIfNecessary();\n\n      //ResourceMonitor required only at ActiveNN. See HDFS-2914\n      this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n      nnrmthread.start();\n\n      nnEditLogRoller \u003d new Daemon(new NameNodeEditLogRoller(\n          editLogRollerThreshold, editLogRollerInterval));\n      nnEditLogRoller.start();\n\n      if (lazyPersistFileScrubIntervalSec \u003e 0) {\n        lazyPersistFileScrubber \u003d new Daemon(new LazyPersistFileScrubber(\n            lazyPersistFileScrubIntervalSec));\n        lazyPersistFileScrubber.start();\n      }\n\n      cacheManager.startMonitorThread();\n      blockManager.getDatanodeManager().setShouldSendCachingCommands(true);\n    } finally {\n      writeUnlock();\n      startingActiveService \u003d false;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "9ca79e8d327e95845ef9794396afd43a52bc3d40": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6557. Move the reference of fsimage to FSNamesystem. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1604242 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/06/14 11:54 AM",
      "commitName": "9ca79e8d327e95845ef9794396afd43a52bc3d40",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "20/06/14 11:25 AM",
      "commitNameOld": "d9eb18bb2e6c25ecc3acaaa2f7e53aff1d795edd",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 0.02,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,69 +1,69 @@\n   void startActiveServices() throws IOException {\n     startingActiveService \u003d true;\n     LOG.info(\"Starting services required for active state\");\n     writeLock();\n     try {\n-      FSEditLog editLog \u003d dir.fsImage.getEditLog();\n+      FSEditLog editLog \u003d getFSImage().getEditLog();\n       \n       if (!editLog.isOpenForWrite()) {\n         // During startup, we\u0027re already open for write during initialization.\n         editLog.initJournalsForWrite();\n         // May need to recover\n         editLog.recoverUnclosedStreams();\n         \n         LOG.info(\"Catching up to latest edits from old active before \" +\n             \"taking over writer role in edits logs\");\n         editLogTailer.catchupDuringFailover();\n         \n         blockManager.setPostponeBlocksFromFuture(false);\n         blockManager.getDatanodeManager().markAllDatanodesStale();\n         blockManager.clearQueues();\n         blockManager.processAllPendingDNMessages();\n \n         // Only need to re-process the queue, If not in SafeMode.\n         if (!isInSafeMode()) {\n           LOG.info(\"Reprocessing replication and invalidation queues\");\n           initializeReplQueues();\n         }\n \n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"NameNode metadata after re-processing \" +\n               \"replication and invalidation queues during failover:\\n\" +\n               metaSaveAsString());\n         }\n         \n-        long nextTxId \u003d dir.fsImage.getLastAppliedTxId() + 1;\n+        long nextTxId \u003d getFSImage().getLastAppliedTxId() + 1;\n         LOG.info(\"Will take over writing edit logs at txnid \" + \n             nextTxId);\n         editLog.setNextTxId(nextTxId);\n \n-        dir.fsImage.editLog.openForWrite();\n+        getFSImage().editLog.openForWrite();\n       }\n \n       // Enable quota checks.\n       dir.enableQuotaChecks();\n       if (haEnabled) {\n         // Renew all of the leases before becoming active.\n         // This is because, while we were in standby mode,\n         // the leases weren\u0027t getting renewed on this NN.\n         // Give them all a fresh start here.\n         leaseManager.renewAllLeases();\n       }\n       leaseManager.startMonitor();\n       startSecretManagerIfNecessary();\n \n       //ResourceMonitor required only at ActiveNN. See HDFS-2914\n       this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n       nnrmthread.start();\n \n       nnEditLogRoller \u003d new Daemon(new NameNodeEditLogRoller(\n           editLogRollerThreshold, editLogRollerInterval));\n       nnEditLogRoller.start();\n \n       cacheManager.startMonitorThread();\n       blockManager.getDatanodeManager().setShouldSendCachingCommands(true);\n     } finally {\n       writeUnlock();\n       startingActiveService \u003d false;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void startActiveServices() throws IOException {\n    startingActiveService \u003d true;\n    LOG.info(\"Starting services required for active state\");\n    writeLock();\n    try {\n      FSEditLog editLog \u003d getFSImage().getEditLog();\n      \n      if (!editLog.isOpenForWrite()) {\n        // During startup, we\u0027re already open for write during initialization.\n        editLog.initJournalsForWrite();\n        // May need to recover\n        editLog.recoverUnclosedStreams();\n        \n        LOG.info(\"Catching up to latest edits from old active before \" +\n            \"taking over writer role in edits logs\");\n        editLogTailer.catchupDuringFailover();\n        \n        blockManager.setPostponeBlocksFromFuture(false);\n        blockManager.getDatanodeManager().markAllDatanodesStale();\n        blockManager.clearQueues();\n        blockManager.processAllPendingDNMessages();\n\n        // Only need to re-process the queue, If not in SafeMode.\n        if (!isInSafeMode()) {\n          LOG.info(\"Reprocessing replication and invalidation queues\");\n          initializeReplQueues();\n        }\n\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"NameNode metadata after re-processing \" +\n              \"replication and invalidation queues during failover:\\n\" +\n              metaSaveAsString());\n        }\n        \n        long nextTxId \u003d getFSImage().getLastAppliedTxId() + 1;\n        LOG.info(\"Will take over writing edit logs at txnid \" + \n            nextTxId);\n        editLog.setNextTxId(nextTxId);\n\n        getFSImage().editLog.openForWrite();\n      }\n\n      // Enable quota checks.\n      dir.enableQuotaChecks();\n      if (haEnabled) {\n        // Renew all of the leases before becoming active.\n        // This is because, while we were in standby mode,\n        // the leases weren\u0027t getting renewed on this NN.\n        // Give them all a fresh start here.\n        leaseManager.renewAllLeases();\n      }\n      leaseManager.startMonitor();\n      startSecretManagerIfNecessary();\n\n      //ResourceMonitor required only at ActiveNN. See HDFS-2914\n      this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n      nnrmthread.start();\n\n      nnEditLogRoller \u003d new Daemon(new NameNodeEditLogRoller(\n          editLogRollerThreshold, editLogRollerInterval));\n      nnEditLogRoller.start();\n\n      cacheManager.startMonitorThread();\n      blockManager.getDatanodeManager().setShouldSendCachingCommands(true);\n    } finally {\n      writeUnlock();\n      startingActiveService \u003d false;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "fe328621d4a84ae99efcb6394a910009b4e1761f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6191. Disable quota checks when replaying edit log.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1585544 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/04/14 11:25 AM",
      "commitName": "fe328621d4a84ae99efcb6394a910009b4e1761f",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "26/03/14 9:25 PM",
      "commitNameOld": "21d225af4dd0189509fa98c3499319672096a1b6",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 11.58,
      "commitsBetweenForRepo": 49,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,67 +1,69 @@\n   void startActiveServices() throws IOException {\n     startingActiveService \u003d true;\n     LOG.info(\"Starting services required for active state\");\n     writeLock();\n     try {\n       FSEditLog editLog \u003d dir.fsImage.getEditLog();\n       \n       if (!editLog.isOpenForWrite()) {\n         // During startup, we\u0027re already open for write during initialization.\n         editLog.initJournalsForWrite();\n         // May need to recover\n         editLog.recoverUnclosedStreams();\n         \n         LOG.info(\"Catching up to latest edits from old active before \" +\n             \"taking over writer role in edits logs\");\n         editLogTailer.catchupDuringFailover();\n         \n         blockManager.setPostponeBlocksFromFuture(false);\n         blockManager.getDatanodeManager().markAllDatanodesStale();\n         blockManager.clearQueues();\n         blockManager.processAllPendingDNMessages();\n \n         // Only need to re-process the queue, If not in SafeMode.\n         if (!isInSafeMode()) {\n           LOG.info(\"Reprocessing replication and invalidation queues\");\n           initializeReplQueues();\n         }\n \n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"NameNode metadata after re-processing \" +\n               \"replication and invalidation queues during failover:\\n\" +\n               metaSaveAsString());\n         }\n         \n         long nextTxId \u003d dir.fsImage.getLastAppliedTxId() + 1;\n         LOG.info(\"Will take over writing edit logs at txnid \" + \n             nextTxId);\n         editLog.setNextTxId(nextTxId);\n \n         dir.fsImage.editLog.openForWrite();\n       }\n-      \n+\n+      // Enable quota checks.\n+      dir.enableQuotaChecks();\n       if (haEnabled) {\n         // Renew all of the leases before becoming active.\n         // This is because, while we were in standby mode,\n         // the leases weren\u0027t getting renewed on this NN.\n         // Give them all a fresh start here.\n         leaseManager.renewAllLeases();\n       }\n       leaseManager.startMonitor();\n       startSecretManagerIfNecessary();\n \n       //ResourceMonitor required only at ActiveNN. See HDFS-2914\n       this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n       nnrmthread.start();\n \n       nnEditLogRoller \u003d new Daemon(new NameNodeEditLogRoller(\n           editLogRollerThreshold, editLogRollerInterval));\n       nnEditLogRoller.start();\n \n       cacheManager.startMonitorThread();\n       blockManager.getDatanodeManager().setShouldSendCachingCommands(true);\n     } finally {\n       writeUnlock();\n       startingActiveService \u003d false;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void startActiveServices() throws IOException {\n    startingActiveService \u003d true;\n    LOG.info(\"Starting services required for active state\");\n    writeLock();\n    try {\n      FSEditLog editLog \u003d dir.fsImage.getEditLog();\n      \n      if (!editLog.isOpenForWrite()) {\n        // During startup, we\u0027re already open for write during initialization.\n        editLog.initJournalsForWrite();\n        // May need to recover\n        editLog.recoverUnclosedStreams();\n        \n        LOG.info(\"Catching up to latest edits from old active before \" +\n            \"taking over writer role in edits logs\");\n        editLogTailer.catchupDuringFailover();\n        \n        blockManager.setPostponeBlocksFromFuture(false);\n        blockManager.getDatanodeManager().markAllDatanodesStale();\n        blockManager.clearQueues();\n        blockManager.processAllPendingDNMessages();\n\n        // Only need to re-process the queue, If not in SafeMode.\n        if (!isInSafeMode()) {\n          LOG.info(\"Reprocessing replication and invalidation queues\");\n          initializeReplQueues();\n        }\n\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"NameNode metadata after re-processing \" +\n              \"replication and invalidation queues during failover:\\n\" +\n              metaSaveAsString());\n        }\n        \n        long nextTxId \u003d dir.fsImage.getLastAppliedTxId() + 1;\n        LOG.info(\"Will take over writing edit logs at txnid \" + \n            nextTxId);\n        editLog.setNextTxId(nextTxId);\n\n        dir.fsImage.editLog.openForWrite();\n      }\n\n      // Enable quota checks.\n      dir.enableQuotaChecks();\n      if (haEnabled) {\n        // Renew all of the leases before becoming active.\n        // This is because, while we were in standby mode,\n        // the leases weren\u0027t getting renewed on this NN.\n        // Give them all a fresh start here.\n        leaseManager.renewAllLeases();\n      }\n      leaseManager.startMonitor();\n      startSecretManagerIfNecessary();\n\n      //ResourceMonitor required only at ActiveNN. See HDFS-2914\n      this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n      nnrmthread.start();\n\n      nnEditLogRoller \u003d new Daemon(new NameNodeEditLogRoller(\n          editLogRollerThreshold, editLogRollerInterval));\n      nnEditLogRoller.start();\n\n      cacheManager.startMonitorThread();\n      blockManager.getDatanodeManager().setShouldSendCachingCommands(true);\n    } finally {\n      writeUnlock();\n      startingActiveService \u003d false;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "d85c017d0488930d806f267141057fc73e68c728": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5651. Remove dfs.namenode.caching.enabled and improve CRM locking. Contributed by Colin Patrick McCabe.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1555002 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/01/14 6:45 PM",
      "commitName": "d85c017d0488930d806f267141057fc73e68c728",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "20/12/13 8:05 AM",
      "commitNameOld": "04d139e2a0e61a62471556255fc9a65792fa373c",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 13.45,
      "commitsBetweenForRepo": 37,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,66 +1,66 @@\n   void startActiveServices() throws IOException {\n     startingActiveService \u003d true;\n     LOG.info(\"Starting services required for active state\");\n     writeLock();\n     try {\n       FSEditLog editLog \u003d dir.fsImage.getEditLog();\n       \n       if (!editLog.isOpenForWrite()) {\n         // During startup, we\u0027re already open for write during initialization.\n         editLog.initJournalsForWrite();\n         // May need to recover\n         editLog.recoverUnclosedStreams();\n         \n         LOG.info(\"Catching up to latest edits from old active before \" +\n             \"taking over writer role in edits logs\");\n         editLogTailer.catchupDuringFailover();\n         \n         blockManager.setPostponeBlocksFromFuture(false);\n         blockManager.getDatanodeManager().markAllDatanodesStale();\n         blockManager.clearQueues();\n         blockManager.processAllPendingDNMessages();\n \n         if (!isInSafeMode() ||\n             (isInSafeMode() \u0026\u0026 safeMode.isPopulatingReplQueues())) {\n           LOG.info(\"Reprocessing replication and invalidation queues\");\n           blockManager.processMisReplicatedBlocks();\n         }\n         \n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"NameNode metadata after re-processing \" +\n               \"replication and invalidation queues during failover:\\n\" +\n               metaSaveAsString());\n         }\n         \n         long nextTxId \u003d dir.fsImage.getLastAppliedTxId() + 1;\n         LOG.info(\"Will take over writing edit logs at txnid \" + \n             nextTxId);\n         editLog.setNextTxId(nextTxId);\n \n         dir.fsImage.editLog.openForWrite();\n       }\n       if (haEnabled) {\n         // Renew all of the leases before becoming active.\n         // This is because, while we were in standby mode,\n         // the leases weren\u0027t getting renewed on this NN.\n         // Give them all a fresh start here.\n         leaseManager.renewAllLeases();\n       }\n       leaseManager.startMonitor();\n       startSecretManagerIfNecessary();\n \n       //ResourceMonitor required only at ActiveNN. See HDFS-2914\n       this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n       nnrmthread.start();\n \n       nnEditLogRoller \u003d new Daemon(new NameNodeEditLogRoller(\n           editLogRollerThreshold, editLogRollerInterval));\n       nnEditLogRoller.start();\n \n-      cacheManager.activate();\n+      cacheManager.startMonitorThread();\n       blockManager.getDatanodeManager().setShouldSendCachingCommands(true);\n     } finally {\n       writeUnlock();\n       startingActiveService \u003d false;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void startActiveServices() throws IOException {\n    startingActiveService \u003d true;\n    LOG.info(\"Starting services required for active state\");\n    writeLock();\n    try {\n      FSEditLog editLog \u003d dir.fsImage.getEditLog();\n      \n      if (!editLog.isOpenForWrite()) {\n        // During startup, we\u0027re already open for write during initialization.\n        editLog.initJournalsForWrite();\n        // May need to recover\n        editLog.recoverUnclosedStreams();\n        \n        LOG.info(\"Catching up to latest edits from old active before \" +\n            \"taking over writer role in edits logs\");\n        editLogTailer.catchupDuringFailover();\n        \n        blockManager.setPostponeBlocksFromFuture(false);\n        blockManager.getDatanodeManager().markAllDatanodesStale();\n        blockManager.clearQueues();\n        blockManager.processAllPendingDNMessages();\n\n        if (!isInSafeMode() ||\n            (isInSafeMode() \u0026\u0026 safeMode.isPopulatingReplQueues())) {\n          LOG.info(\"Reprocessing replication and invalidation queues\");\n          blockManager.processMisReplicatedBlocks();\n        }\n        \n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"NameNode metadata after re-processing \" +\n              \"replication and invalidation queues during failover:\\n\" +\n              metaSaveAsString());\n        }\n        \n        long nextTxId \u003d dir.fsImage.getLastAppliedTxId() + 1;\n        LOG.info(\"Will take over writing edit logs at txnid \" + \n            nextTxId);\n        editLog.setNextTxId(nextTxId);\n\n        dir.fsImage.editLog.openForWrite();\n      }\n      if (haEnabled) {\n        // Renew all of the leases before becoming active.\n        // This is because, while we were in standby mode,\n        // the leases weren\u0027t getting renewed on this NN.\n        // Give them all a fresh start here.\n        leaseManager.renewAllLeases();\n      }\n      leaseManager.startMonitor();\n      startSecretManagerIfNecessary();\n\n      //ResourceMonitor required only at ActiveNN. See HDFS-2914\n      this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n      nnrmthread.start();\n\n      nnEditLogRoller \u003d new Daemon(new NameNodeEditLogRoller(\n          editLogRollerThreshold, editLogRollerInterval));\n      nnEditLogRoller.start();\n\n      cacheManager.startMonitorThread();\n      blockManager.getDatanodeManager().setShouldSendCachingCommands(true);\n    } finally {\n      writeUnlock();\n      startingActiveService \u003d false;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "788fca4124ecac818a20bfc2607676849cf0d94f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5496. Make replication queue initialization asynchronous. Contributed by Vinay.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535@1552109 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/12/13 1:30 PM",
      "commitName": "788fca4124ecac818a20bfc2607676849cf0d94f",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "06/12/13 10:17 PM",
      "commitNameOld": "4c87a27ad851ffaa3cc3e2074a9ef7073b5a164a",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 11.63,
      "commitsBetweenForRepo": 17,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,66 +1,66 @@\n   void startActiveServices() throws IOException {\n     startingActiveService \u003d true;\n     LOG.info(\"Starting services required for active state\");\n     writeLock();\n     try {\n       FSEditLog editLog \u003d dir.fsImage.getEditLog();\n       \n       if (!editLog.isOpenForWrite()) {\n         // During startup, we\u0027re already open for write during initialization.\n         editLog.initJournalsForWrite();\n         // May need to recover\n         editLog.recoverUnclosedStreams();\n         \n         LOG.info(\"Catching up to latest edits from old active before \" +\n             \"taking over writer role in edits logs\");\n         editLogTailer.catchupDuringFailover();\n         \n         blockManager.setPostponeBlocksFromFuture(false);\n         blockManager.getDatanodeManager().markAllDatanodesStale();\n         blockManager.clearQueues();\n         blockManager.processAllPendingDNMessages();\n \n-        if (!isInSafeMode() ||\n-            (isInSafeMode() \u0026\u0026 safeMode.isPopulatingReplQueues())) {\n+        // Only need to re-process the queue, If not in SafeMode.\n+        if (!isInSafeMode()) {\n           LOG.info(\"Reprocessing replication and invalidation queues\");\n-          blockManager.processMisReplicatedBlocks();\n+          initializeReplQueues();\n         }\n-        \n+\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"NameNode metadata after re-processing \" +\n               \"replication and invalidation queues during failover:\\n\" +\n               metaSaveAsString());\n         }\n         \n         long nextTxId \u003d dir.fsImage.getLastAppliedTxId() + 1;\n         LOG.info(\"Will take over writing edit logs at txnid \" + \n             nextTxId);\n         editLog.setNextTxId(nextTxId);\n \n         dir.fsImage.editLog.openForWrite();\n       }\n       if (haEnabled) {\n         // Renew all of the leases before becoming active.\n         // This is because, while we were in standby mode,\n         // the leases weren\u0027t getting renewed on this NN.\n         // Give them all a fresh start here.\n         leaseManager.renewAllLeases();\n       }\n       leaseManager.startMonitor();\n       startSecretManagerIfNecessary();\n \n       //ResourceMonitor required only at ActiveNN. See HDFS-2914\n       this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n       nnrmthread.start();\n \n       nnEditLogRoller \u003d new Daemon(new NameNodeEditLogRoller(\n           editLogRollerThreshold, editLogRollerInterval));\n       nnEditLogRoller.start();\n \n       cacheManager.activate();\n       blockManager.getDatanodeManager().setShouldSendCachingCommands(true);\n     } finally {\n       writeUnlock();\n       startingActiveService \u003d false;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void startActiveServices() throws IOException {\n    startingActiveService \u003d true;\n    LOG.info(\"Starting services required for active state\");\n    writeLock();\n    try {\n      FSEditLog editLog \u003d dir.fsImage.getEditLog();\n      \n      if (!editLog.isOpenForWrite()) {\n        // During startup, we\u0027re already open for write during initialization.\n        editLog.initJournalsForWrite();\n        // May need to recover\n        editLog.recoverUnclosedStreams();\n        \n        LOG.info(\"Catching up to latest edits from old active before \" +\n            \"taking over writer role in edits logs\");\n        editLogTailer.catchupDuringFailover();\n        \n        blockManager.setPostponeBlocksFromFuture(false);\n        blockManager.getDatanodeManager().markAllDatanodesStale();\n        blockManager.clearQueues();\n        blockManager.processAllPendingDNMessages();\n\n        // Only need to re-process the queue, If not in SafeMode.\n        if (!isInSafeMode()) {\n          LOG.info(\"Reprocessing replication and invalidation queues\");\n          initializeReplQueues();\n        }\n\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"NameNode metadata after re-processing \" +\n              \"replication and invalidation queues during failover:\\n\" +\n              metaSaveAsString());\n        }\n        \n        long nextTxId \u003d dir.fsImage.getLastAppliedTxId() + 1;\n        LOG.info(\"Will take over writing edit logs at txnid \" + \n            nextTxId);\n        editLog.setNextTxId(nextTxId);\n\n        dir.fsImage.editLog.openForWrite();\n      }\n      if (haEnabled) {\n        // Renew all of the leases before becoming active.\n        // This is because, while we were in standby mode,\n        // the leases weren\u0027t getting renewed on this NN.\n        // Give them all a fresh start here.\n        leaseManager.renewAllLeases();\n      }\n      leaseManager.startMonitor();\n      startSecretManagerIfNecessary();\n\n      //ResourceMonitor required only at ActiveNN. See HDFS-2914\n      this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n      nnrmthread.start();\n\n      nnEditLogRoller \u003d new Daemon(new NameNodeEditLogRoller(\n          editLogRollerThreshold, editLogRollerInterval));\n      nnEditLogRoller.start();\n\n      cacheManager.activate();\n      blockManager.getDatanodeManager().setShouldSendCachingCommands(true);\n    } finally {\n      writeUnlock();\n      startingActiveService \u003d false;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "3c591aa442d342bdd4a0c4abe9a43c64d8ef3e65": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5366. recaching improvements (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1541647 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/11/13 10:18 AM",
      "commitName": "3c591aa442d342bdd4a0c4abe9a43c64d8ef3e65",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "12/11/13 2:10 PM",
      "commitNameOld": "8162fdcdbc23d749fdb188ae8419e173c59cb1ed",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 0.84,
      "commitsBetweenForRepo": 8,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,66 +1,66 @@\n   void startActiveServices() throws IOException {\n     startingActiveService \u003d true;\n     LOG.info(\"Starting services required for active state\");\n     writeLock();\n     try {\n       FSEditLog editLog \u003d dir.fsImage.getEditLog();\n       \n       if (!editLog.isOpenForWrite()) {\n         // During startup, we\u0027re already open for write during initialization.\n         editLog.initJournalsForWrite();\n         // May need to recover\n         editLog.recoverUnclosedStreams();\n         \n         LOG.info(\"Catching up to latest edits from old active before \" +\n             \"taking over writer role in edits logs\");\n         editLogTailer.catchupDuringFailover();\n         \n         blockManager.setPostponeBlocksFromFuture(false);\n         blockManager.getDatanodeManager().markAllDatanodesStale();\n         blockManager.clearQueues();\n         blockManager.processAllPendingDNMessages();\n \n         if (!isInSafeMode() ||\n             (isInSafeMode() \u0026\u0026 safeMode.isPopulatingReplQueues())) {\n           LOG.info(\"Reprocessing replication and invalidation queues\");\n           blockManager.processMisReplicatedBlocks();\n         }\n         \n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"NameNode metadata after re-processing \" +\n               \"replication and invalidation queues during failover:\\n\" +\n               metaSaveAsString());\n         }\n         \n         long nextTxId \u003d dir.fsImage.getLastAppliedTxId() + 1;\n         LOG.info(\"Will take over writing edit logs at txnid \" + \n             nextTxId);\n         editLog.setNextTxId(nextTxId);\n \n         dir.fsImage.editLog.openForWrite();\n       }\n       if (haEnabled) {\n         // Renew all of the leases before becoming active.\n         // This is because, while we were in standby mode,\n         // the leases weren\u0027t getting renewed on this NN.\n         // Give them all a fresh start here.\n         leaseManager.renewAllLeases();\n       }\n       leaseManager.startMonitor();\n       startSecretManagerIfNecessary();\n \n       //ResourceMonitor required only at ActiveNN. See HDFS-2914\n       this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n       nnrmthread.start();\n \n       nnEditLogRoller \u003d new Daemon(new NameNodeEditLogRoller(\n           editLogRollerThreshold, editLogRollerInterval));\n       nnEditLogRoller.start();\n \n       cacheManager.activate();\n-      blockManager.getDatanodeManager().setSendCachingCommands(true);\n+      blockManager.getDatanodeManager().setShouldSendCachingCommands(true);\n     } finally {\n       writeUnlock();\n       startingActiveService \u003d false;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void startActiveServices() throws IOException {\n    startingActiveService \u003d true;\n    LOG.info(\"Starting services required for active state\");\n    writeLock();\n    try {\n      FSEditLog editLog \u003d dir.fsImage.getEditLog();\n      \n      if (!editLog.isOpenForWrite()) {\n        // During startup, we\u0027re already open for write during initialization.\n        editLog.initJournalsForWrite();\n        // May need to recover\n        editLog.recoverUnclosedStreams();\n        \n        LOG.info(\"Catching up to latest edits from old active before \" +\n            \"taking over writer role in edits logs\");\n        editLogTailer.catchupDuringFailover();\n        \n        blockManager.setPostponeBlocksFromFuture(false);\n        blockManager.getDatanodeManager().markAllDatanodesStale();\n        blockManager.clearQueues();\n        blockManager.processAllPendingDNMessages();\n\n        if (!isInSafeMode() ||\n            (isInSafeMode() \u0026\u0026 safeMode.isPopulatingReplQueues())) {\n          LOG.info(\"Reprocessing replication and invalidation queues\");\n          blockManager.processMisReplicatedBlocks();\n        }\n        \n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"NameNode metadata after re-processing \" +\n              \"replication and invalidation queues during failover:\\n\" +\n              metaSaveAsString());\n        }\n        \n        long nextTxId \u003d dir.fsImage.getLastAppliedTxId() + 1;\n        LOG.info(\"Will take over writing edit logs at txnid \" + \n            nextTxId);\n        editLog.setNextTxId(nextTxId);\n\n        dir.fsImage.editLog.openForWrite();\n      }\n      if (haEnabled) {\n        // Renew all of the leases before becoming active.\n        // This is because, while we were in standby mode,\n        // the leases weren\u0027t getting renewed on this NN.\n        // Give them all a fresh start here.\n        leaseManager.renewAllLeases();\n      }\n      leaseManager.startMonitor();\n      startSecretManagerIfNecessary();\n\n      //ResourceMonitor required only at ActiveNN. See HDFS-2914\n      this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n      nnrmthread.start();\n\n      nnEditLogRoller \u003d new Daemon(new NameNodeEditLogRoller(\n          editLogRollerThreshold, editLogRollerInterval));\n      nnEditLogRoller.start();\n\n      cacheManager.activate();\n      blockManager.getDatanodeManager().setShouldSendCachingCommands(true);\n    } finally {\n      writeUnlock();\n      startingActiveService \u003d false;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "3b91b7dece84b563a4b7cf66c245b7c5ee094578": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5037. Active NN should trigger its own edit log rolls. Contributed by Andrew Wang.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1538059 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "01/11/13 1:49 PM",
      "commitName": "3b91b7dece84b563a4b7cf66c245b7c5ee094578",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "30/10/13 10:27 AM",
      "commitNameOld": "75a162ff92d365d88ed253335b52aaa3709f6365",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 2.14,
      "commitsBetweenForRepo": 16,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,61 +1,66 @@\n   void startActiveServices() throws IOException {\n     startingActiveService \u003d true;\n     LOG.info(\"Starting services required for active state\");\n     writeLock();\n     try {\n       FSEditLog editLog \u003d dir.fsImage.getEditLog();\n       \n       if (!editLog.isOpenForWrite()) {\n         // During startup, we\u0027re already open for write during initialization.\n         editLog.initJournalsForWrite();\n         // May need to recover\n         editLog.recoverUnclosedStreams();\n         \n         LOG.info(\"Catching up to latest edits from old active before \" +\n             \"taking over writer role in edits logs\");\n         editLogTailer.catchupDuringFailover();\n         \n         blockManager.setPostponeBlocksFromFuture(false);\n         blockManager.getDatanodeManager().markAllDatanodesStale();\n         blockManager.clearQueues();\n         blockManager.processAllPendingDNMessages();\n \n         if (!isInSafeMode() ||\n             (isInSafeMode() \u0026\u0026 safeMode.isPopulatingReplQueues())) {\n           LOG.info(\"Reprocessing replication and invalidation queues\");\n           blockManager.processMisReplicatedBlocks();\n         }\n         \n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"NameNode metadata after re-processing \" +\n               \"replication and invalidation queues during failover:\\n\" +\n               metaSaveAsString());\n         }\n         \n         long nextTxId \u003d dir.fsImage.getLastAppliedTxId() + 1;\n         LOG.info(\"Will take over writing edit logs at txnid \" + \n             nextTxId);\n         editLog.setNextTxId(nextTxId);\n \n         dir.fsImage.editLog.openForWrite();\n       }\n       if (haEnabled) {\n         // Renew all of the leases before becoming active.\n         // This is because, while we were in standby mode,\n         // the leases weren\u0027t getting renewed on this NN.\n         // Give them all a fresh start here.\n         leaseManager.renewAllLeases();\n       }\n       leaseManager.startMonitor();\n       startSecretManagerIfNecessary();\n \n       //ResourceMonitor required only at ActiveNN. See HDFS-2914\n       this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n       nnrmthread.start();\n+\n+      nnEditLogRoller \u003d new Daemon(new NameNodeEditLogRoller(\n+          editLogRollerThreshold, editLogRollerInterval));\n+      nnEditLogRoller.start();\n+\n       cacheManager.activate();\n       blockManager.getDatanodeManager().setSendCachingCommands(true);\n     } finally {\n       writeUnlock();\n       startingActiveService \u003d false;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void startActiveServices() throws IOException {\n    startingActiveService \u003d true;\n    LOG.info(\"Starting services required for active state\");\n    writeLock();\n    try {\n      FSEditLog editLog \u003d dir.fsImage.getEditLog();\n      \n      if (!editLog.isOpenForWrite()) {\n        // During startup, we\u0027re already open for write during initialization.\n        editLog.initJournalsForWrite();\n        // May need to recover\n        editLog.recoverUnclosedStreams();\n        \n        LOG.info(\"Catching up to latest edits from old active before \" +\n            \"taking over writer role in edits logs\");\n        editLogTailer.catchupDuringFailover();\n        \n        blockManager.setPostponeBlocksFromFuture(false);\n        blockManager.getDatanodeManager().markAllDatanodesStale();\n        blockManager.clearQueues();\n        blockManager.processAllPendingDNMessages();\n\n        if (!isInSafeMode() ||\n            (isInSafeMode() \u0026\u0026 safeMode.isPopulatingReplQueues())) {\n          LOG.info(\"Reprocessing replication and invalidation queues\");\n          blockManager.processMisReplicatedBlocks();\n        }\n        \n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"NameNode metadata after re-processing \" +\n              \"replication and invalidation queues during failover:\\n\" +\n              metaSaveAsString());\n        }\n        \n        long nextTxId \u003d dir.fsImage.getLastAppliedTxId() + 1;\n        LOG.info(\"Will take over writing edit logs at txnid \" + \n            nextTxId);\n        editLog.setNextTxId(nextTxId);\n\n        dir.fsImage.editLog.openForWrite();\n      }\n      if (haEnabled) {\n        // Renew all of the leases before becoming active.\n        // This is because, while we were in standby mode,\n        // the leases weren\u0027t getting renewed on this NN.\n        // Give them all a fresh start here.\n        leaseManager.renewAllLeases();\n      }\n      leaseManager.startMonitor();\n      startSecretManagerIfNecessary();\n\n      //ResourceMonitor required only at ActiveNN. See HDFS-2914\n      this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n      nnrmthread.start();\n\n      nnEditLogRoller \u003d new Daemon(new NameNodeEditLogRoller(\n          editLogRollerThreshold, editLogRollerInterval));\n      nnEditLogRoller.start();\n\n      cacheManager.activate();\n      blockManager.getDatanodeManager().setSendCachingCommands(true);\n    } finally {\n      writeUnlock();\n      startingActiveService \u003d false;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "34f08944b7c8d58f531a3f3bf3d4ee4cd3fa643a": {
      "type": "Ybodychange",
      "commitMessage": "merge trunk to branch HDFS-4949\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1532952 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/10/13 7:14 PM",
      "commitName": "34f08944b7c8d58f531a3f3bf3d4ee4cd3fa643a",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "16/10/13 3:15 PM",
      "commitNameOld": "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 0.17,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,59 +1,61 @@\n   void startActiveServices() throws IOException {\n+    startingActiveService \u003d true;\n     LOG.info(\"Starting services required for active state\");\n     writeLock();\n     try {\n       FSEditLog editLog \u003d dir.fsImage.getEditLog();\n       \n       if (!editLog.isOpenForWrite()) {\n         // During startup, we\u0027re already open for write during initialization.\n         editLog.initJournalsForWrite();\n         // May need to recover\n         editLog.recoverUnclosedStreams();\n         \n         LOG.info(\"Catching up to latest edits from old active before \" +\n             \"taking over writer role in edits logs\");\n         editLogTailer.catchupDuringFailover();\n         \n         blockManager.setPostponeBlocksFromFuture(false);\n         blockManager.getDatanodeManager().markAllDatanodesStale();\n         blockManager.clearQueues();\n         blockManager.processAllPendingDNMessages();\n \n         if (!isInSafeMode() ||\n             (isInSafeMode() \u0026\u0026 safeMode.isPopulatingReplQueues())) {\n           LOG.info(\"Reprocessing replication and invalidation queues\");\n           blockManager.processMisReplicatedBlocks();\n         }\n         \n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"NameNode metadata after re-processing \" +\n               \"replication and invalidation queues during failover:\\n\" +\n               metaSaveAsString());\n         }\n         \n         long nextTxId \u003d dir.fsImage.getLastAppliedTxId() + 1;\n         LOG.info(\"Will take over writing edit logs at txnid \" + \n             nextTxId);\n         editLog.setNextTxId(nextTxId);\n \n         dir.fsImage.editLog.openForWrite();\n       }\n       if (haEnabled) {\n         // Renew all of the leases before becoming active.\n         // This is because, while we were in standby mode,\n         // the leases weren\u0027t getting renewed on this NN.\n         // Give them all a fresh start here.\n         leaseManager.renewAllLeases();\n       }\n       leaseManager.startMonitor();\n       startSecretManagerIfNecessary();\n \n       //ResourceMonitor required only at ActiveNN. See HDFS-2914\n       this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n       nnrmthread.start();\n       cacheManager.activate();\n       blockManager.getDatanodeManager().setSendCachingCommands(true);\n     } finally {\n       writeUnlock();\n+      startingActiveService \u003d false;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void startActiveServices() throws IOException {\n    startingActiveService \u003d true;\n    LOG.info(\"Starting services required for active state\");\n    writeLock();\n    try {\n      FSEditLog editLog \u003d dir.fsImage.getEditLog();\n      \n      if (!editLog.isOpenForWrite()) {\n        // During startup, we\u0027re already open for write during initialization.\n        editLog.initJournalsForWrite();\n        // May need to recover\n        editLog.recoverUnclosedStreams();\n        \n        LOG.info(\"Catching up to latest edits from old active before \" +\n            \"taking over writer role in edits logs\");\n        editLogTailer.catchupDuringFailover();\n        \n        blockManager.setPostponeBlocksFromFuture(false);\n        blockManager.getDatanodeManager().markAllDatanodesStale();\n        blockManager.clearQueues();\n        blockManager.processAllPendingDNMessages();\n\n        if (!isInSafeMode() ||\n            (isInSafeMode() \u0026\u0026 safeMode.isPopulatingReplQueues())) {\n          LOG.info(\"Reprocessing replication and invalidation queues\");\n          blockManager.processMisReplicatedBlocks();\n        }\n        \n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"NameNode metadata after re-processing \" +\n              \"replication and invalidation queues during failover:\\n\" +\n              metaSaveAsString());\n        }\n        \n        long nextTxId \u003d dir.fsImage.getLastAppliedTxId() + 1;\n        LOG.info(\"Will take over writing edit logs at txnid \" + \n            nextTxId);\n        editLog.setNextTxId(nextTxId);\n\n        dir.fsImage.editLog.openForWrite();\n      }\n      if (haEnabled) {\n        // Renew all of the leases before becoming active.\n        // This is because, while we were in standby mode,\n        // the leases weren\u0027t getting renewed on this NN.\n        // Give them all a fresh start here.\n        leaseManager.renewAllLeases();\n      }\n      leaseManager.startMonitor();\n      startSecretManagerIfNecessary();\n\n      //ResourceMonitor required only at ActiveNN. See HDFS-2914\n      this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n      nnrmthread.start();\n      cacheManager.activate();\n      blockManager.getDatanodeManager().setSendCachingCommands(true);\n    } finally {\n      writeUnlock();\n      startingActiveService \u003d false;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5096. Automatically cache new data added to a cached path (contributed by Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1532924 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/10/13 3:15 PM",
      "commitName": "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "09/10/13 2:30 PM",
      "commitNameOld": "3fc8792b5c75fca9fc4f6cf4b95fb2927c62e624",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 7.03,
      "commitsBetweenForRepo": 8,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,59 +1,59 @@\n   void startActiveServices() throws IOException {\n     LOG.info(\"Starting services required for active state\");\n     writeLock();\n     try {\n       FSEditLog editLog \u003d dir.fsImage.getEditLog();\n       \n       if (!editLog.isOpenForWrite()) {\n         // During startup, we\u0027re already open for write during initialization.\n         editLog.initJournalsForWrite();\n         // May need to recover\n         editLog.recoverUnclosedStreams();\n         \n         LOG.info(\"Catching up to latest edits from old active before \" +\n             \"taking over writer role in edits logs\");\n         editLogTailer.catchupDuringFailover();\n         \n         blockManager.setPostponeBlocksFromFuture(false);\n         blockManager.getDatanodeManager().markAllDatanodesStale();\n         blockManager.clearQueues();\n         blockManager.processAllPendingDNMessages();\n \n-        cacheReplicationManager.clearQueues();\n-\n         if (!isInSafeMode() ||\n             (isInSafeMode() \u0026\u0026 safeMode.isPopulatingReplQueues())) {\n           LOG.info(\"Reprocessing replication and invalidation queues\");\n           blockManager.processMisReplicatedBlocks();\n         }\n         \n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"NameNode metadata after re-processing \" +\n               \"replication and invalidation queues during failover:\\n\" +\n               metaSaveAsString());\n         }\n         \n         long nextTxId \u003d dir.fsImage.getLastAppliedTxId() + 1;\n         LOG.info(\"Will take over writing edit logs at txnid \" + \n             nextTxId);\n         editLog.setNextTxId(nextTxId);\n \n         dir.fsImage.editLog.openForWrite();\n       }\n       if (haEnabled) {\n         // Renew all of the leases before becoming active.\n         // This is because, while we were in standby mode,\n         // the leases weren\u0027t getting renewed on this NN.\n         // Give them all a fresh start here.\n         leaseManager.renewAllLeases();\n       }\n       leaseManager.startMonitor();\n       startSecretManagerIfNecessary();\n \n       //ResourceMonitor required only at ActiveNN. See HDFS-2914\n       this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n       nnrmthread.start();\n+      cacheManager.activate();\n+      blockManager.getDatanodeManager().setSendCachingCommands(true);\n     } finally {\n       writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void startActiveServices() throws IOException {\n    LOG.info(\"Starting services required for active state\");\n    writeLock();\n    try {\n      FSEditLog editLog \u003d dir.fsImage.getEditLog();\n      \n      if (!editLog.isOpenForWrite()) {\n        // During startup, we\u0027re already open for write during initialization.\n        editLog.initJournalsForWrite();\n        // May need to recover\n        editLog.recoverUnclosedStreams();\n        \n        LOG.info(\"Catching up to latest edits from old active before \" +\n            \"taking over writer role in edits logs\");\n        editLogTailer.catchupDuringFailover();\n        \n        blockManager.setPostponeBlocksFromFuture(false);\n        blockManager.getDatanodeManager().markAllDatanodesStale();\n        blockManager.clearQueues();\n        blockManager.processAllPendingDNMessages();\n\n        if (!isInSafeMode() ||\n            (isInSafeMode() \u0026\u0026 safeMode.isPopulatingReplQueues())) {\n          LOG.info(\"Reprocessing replication and invalidation queues\");\n          blockManager.processMisReplicatedBlocks();\n        }\n        \n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"NameNode metadata after re-processing \" +\n              \"replication and invalidation queues during failover:\\n\" +\n              metaSaveAsString());\n        }\n        \n        long nextTxId \u003d dir.fsImage.getLastAppliedTxId() + 1;\n        LOG.info(\"Will take over writing edit logs at txnid \" + \n            nextTxId);\n        editLog.setNextTxId(nextTxId);\n\n        dir.fsImage.editLog.openForWrite();\n      }\n      if (haEnabled) {\n        // Renew all of the leases before becoming active.\n        // This is because, while we were in standby mode,\n        // the leases weren\u0027t getting renewed on this NN.\n        // Give them all a fresh start here.\n        leaseManager.renewAllLeases();\n      }\n      leaseManager.startMonitor();\n      startSecretManagerIfNecessary();\n\n      //ResourceMonitor required only at ActiveNN. See HDFS-2914\n      this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n      nnrmthread.start();\n      cacheManager.activate();\n      blockManager.getDatanodeManager().setSendCachingCommands(true);\n    } finally {\n      writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "f7eaacc103344f5fd81dd69584c93fb99d8b94c9": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5322. HDFS delegation token not found in cache errors seen on secure HA clusters. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1531436 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/10/13 2:49 PM",
      "commitName": "f7eaacc103344f5fd81dd69584c93fb99d8b94c9",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "07/10/13 4:58 PM",
      "commitNameOld": "1fe1942328856dd832e9f94fb56a40ab3d810870",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 3.91,
      "commitsBetweenForRepo": 31,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,57 +1,59 @@\n   void startActiveServices() throws IOException {\n+    startingActiveService \u003d true;\n     LOG.info(\"Starting services required for active state\");\n     writeLock();\n     try {\n       FSEditLog editLog \u003d dir.fsImage.getEditLog();\n       \n       if (!editLog.isOpenForWrite()) {\n         // During startup, we\u0027re already open for write during initialization.\n         editLog.initJournalsForWrite();\n         // May need to recover\n         editLog.recoverUnclosedStreams();\n         \n         LOG.info(\"Catching up to latest edits from old active before \" +\n             \"taking over writer role in edits logs\");\n         editLogTailer.catchupDuringFailover();\n         \n         blockManager.setPostponeBlocksFromFuture(false);\n         blockManager.getDatanodeManager().markAllDatanodesStale();\n         blockManager.clearQueues();\n         blockManager.processAllPendingDNMessages();\n         \n         if (!isInSafeMode() ||\n             (isInSafeMode() \u0026\u0026 safeMode.isPopulatingReplQueues())) {\n           LOG.info(\"Reprocessing replication and invalidation queues\");\n           blockManager.processMisReplicatedBlocks();\n         }\n         \n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"NameNode metadata after re-processing \" +\n               \"replication and invalidation queues during failover:\\n\" +\n               metaSaveAsString());\n         }\n         \n         long nextTxId \u003d dir.fsImage.getLastAppliedTxId() + 1;\n         LOG.info(\"Will take over writing edit logs at txnid \" + \n             nextTxId);\n         editLog.setNextTxId(nextTxId);\n \n         dir.fsImage.editLog.openForWrite();\n       }\n       if (haEnabled) {\n         // Renew all of the leases before becoming active.\n         // This is because, while we were in standby mode,\n         // the leases weren\u0027t getting renewed on this NN.\n         // Give them all a fresh start here.\n         leaseManager.renewAllLeases();\n       }\n       leaseManager.startMonitor();\n       startSecretManagerIfNecessary();\n \n       //ResourceMonitor required only at ActiveNN. See HDFS-2914\n       this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n       nnrmthread.start();\n     } finally {\n       writeUnlock();\n+      startingActiveService \u003d false;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void startActiveServices() throws IOException {\n    startingActiveService \u003d true;\n    LOG.info(\"Starting services required for active state\");\n    writeLock();\n    try {\n      FSEditLog editLog \u003d dir.fsImage.getEditLog();\n      \n      if (!editLog.isOpenForWrite()) {\n        // During startup, we\u0027re already open for write during initialization.\n        editLog.initJournalsForWrite();\n        // May need to recover\n        editLog.recoverUnclosedStreams();\n        \n        LOG.info(\"Catching up to latest edits from old active before \" +\n            \"taking over writer role in edits logs\");\n        editLogTailer.catchupDuringFailover();\n        \n        blockManager.setPostponeBlocksFromFuture(false);\n        blockManager.getDatanodeManager().markAllDatanodesStale();\n        blockManager.clearQueues();\n        blockManager.processAllPendingDNMessages();\n        \n        if (!isInSafeMode() ||\n            (isInSafeMode() \u0026\u0026 safeMode.isPopulatingReplQueues())) {\n          LOG.info(\"Reprocessing replication and invalidation queues\");\n          blockManager.processMisReplicatedBlocks();\n        }\n        \n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"NameNode metadata after re-processing \" +\n              \"replication and invalidation queues during failover:\\n\" +\n              metaSaveAsString());\n        }\n        \n        long nextTxId \u003d dir.fsImage.getLastAppliedTxId() + 1;\n        LOG.info(\"Will take over writing edit logs at txnid \" + \n            nextTxId);\n        editLog.setNextTxId(nextTxId);\n\n        dir.fsImage.editLog.openForWrite();\n      }\n      if (haEnabled) {\n        // Renew all of the leases before becoming active.\n        // This is because, while we were in standby mode,\n        // the leases weren\u0027t getting renewed on this NN.\n        // Give them all a fresh start here.\n        leaseManager.renewAllLeases();\n      }\n      leaseManager.startMonitor();\n      startSecretManagerIfNecessary();\n\n      //ResourceMonitor required only at ActiveNN. See HDFS-2914\n      this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n      nnrmthread.start();\n    } finally {\n      writeUnlock();\n      startingActiveService \u003d false;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "40eb94ade3161d93e7a762a839004748f6d0ae89": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5053. NameNode should invoke DataNode APIs to coordinate caching. (Andrew Wang)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1523145 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/09/13 4:27 PM",
      "commitName": "40eb94ade3161d93e7a762a839004748f6d0ae89",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "11/09/13 8:55 PM",
      "commitNameOld": "02e0e158a26f81ce8375426ba0ea56db09ee36be",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 1.81,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,57 +1,59 @@\n   void startActiveServices() throws IOException {\n     LOG.info(\"Starting services required for active state\");\n     writeLock();\n     try {\n       FSEditLog editLog \u003d dir.fsImage.getEditLog();\n       \n       if (!editLog.isOpenForWrite()) {\n         // During startup, we\u0027re already open for write during initialization.\n         editLog.initJournalsForWrite();\n         // May need to recover\n         editLog.recoverUnclosedStreams();\n         \n         LOG.info(\"Catching up to latest edits from old active before \" +\n             \"taking over writer role in edits logs\");\n         editLogTailer.catchupDuringFailover();\n         \n         blockManager.setPostponeBlocksFromFuture(false);\n         blockManager.getDatanodeManager().markAllDatanodesStale();\n         blockManager.clearQueues();\n         blockManager.processAllPendingDNMessages();\n-        \n+\n+        cacheReplicationManager.clearQueues();\n+\n         if (!isInSafeMode() ||\n             (isInSafeMode() \u0026\u0026 safeMode.isPopulatingReplQueues())) {\n           LOG.info(\"Reprocessing replication and invalidation queues\");\n           blockManager.processMisReplicatedBlocks();\n         }\n         \n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"NameNode metadata after re-processing \" +\n               \"replication and invalidation queues during failover:\\n\" +\n               metaSaveAsString());\n         }\n         \n         long nextTxId \u003d dir.fsImage.getLastAppliedTxId() + 1;\n         LOG.info(\"Will take over writing edit logs at txnid \" + \n             nextTxId);\n         editLog.setNextTxId(nextTxId);\n \n         dir.fsImage.editLog.openForWrite();\n       }\n       if (haEnabled) {\n         // Renew all of the leases before becoming active.\n         // This is because, while we were in standby mode,\n         // the leases weren\u0027t getting renewed on this NN.\n         // Give them all a fresh start here.\n         leaseManager.renewAllLeases();\n       }\n       leaseManager.startMonitor();\n       startSecretManagerIfNecessary();\n \n       //ResourceMonitor required only at ActiveNN. See HDFS-2914\n       this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n       nnrmthread.start();\n     } finally {\n       writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void startActiveServices() throws IOException {\n    LOG.info(\"Starting services required for active state\");\n    writeLock();\n    try {\n      FSEditLog editLog \u003d dir.fsImage.getEditLog();\n      \n      if (!editLog.isOpenForWrite()) {\n        // During startup, we\u0027re already open for write during initialization.\n        editLog.initJournalsForWrite();\n        // May need to recover\n        editLog.recoverUnclosedStreams();\n        \n        LOG.info(\"Catching up to latest edits from old active before \" +\n            \"taking over writer role in edits logs\");\n        editLogTailer.catchupDuringFailover();\n        \n        blockManager.setPostponeBlocksFromFuture(false);\n        blockManager.getDatanodeManager().markAllDatanodesStale();\n        blockManager.clearQueues();\n        blockManager.processAllPendingDNMessages();\n\n        cacheReplicationManager.clearQueues();\n\n        if (!isInSafeMode() ||\n            (isInSafeMode() \u0026\u0026 safeMode.isPopulatingReplQueues())) {\n          LOG.info(\"Reprocessing replication and invalidation queues\");\n          blockManager.processMisReplicatedBlocks();\n        }\n        \n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"NameNode metadata after re-processing \" +\n              \"replication and invalidation queues during failover:\\n\" +\n              metaSaveAsString());\n        }\n        \n        long nextTxId \u003d dir.fsImage.getLastAppliedTxId() + 1;\n        LOG.info(\"Will take over writing edit logs at txnid \" + \n            nextTxId);\n        editLog.setNextTxId(nextTxId);\n\n        dir.fsImage.editLog.openForWrite();\n      }\n      if (haEnabled) {\n        // Renew all of the leases before becoming active.\n        // This is because, while we were in standby mode,\n        // the leases weren\u0027t getting renewed on this NN.\n        // Give them all a fresh start here.\n        leaseManager.renewAllLeases();\n      }\n      leaseManager.startMonitor();\n      startSecretManagerIfNecessary();\n\n      //ResourceMonitor required only at ActiveNN. See HDFS-2914\n      this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n      nnrmthread.start();\n    } finally {\n      writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "b3e42a1ed56f83e2cc35e58f2ffd02c9ff3821e0": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3921. NN will prematurely consider blocks missing when entering active state while still in safe mode. Contributed by Aaron T. Myers.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1408531 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/11/12 5:26 PM",
      "commitName": "b3e42a1ed56f83e2cc35e58f2ffd02c9ff3821e0",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "07/11/12 9:45 AM",
      "commitNameOld": "1ab97373deea303e3f43af36b974db52e0ba6d13",
      "commitAuthorOld": "Konstantin Shvachko",
      "daysBetweenCommits": 5.32,
      "commitsBetweenForRepo": 36,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,53 +1,57 @@\n   void startActiveServices() throws IOException {\n     LOG.info(\"Starting services required for active state\");\n     writeLock();\n     try {\n       FSEditLog editLog \u003d dir.fsImage.getEditLog();\n       \n       if (!editLog.isOpenForWrite()) {\n         // During startup, we\u0027re already open for write during initialization.\n         editLog.initJournalsForWrite();\n         // May need to recover\n         editLog.recoverUnclosedStreams();\n         \n         LOG.info(\"Catching up to latest edits from old active before \" +\n             \"taking over writer role in edits logs\");\n         editLogTailer.catchupDuringFailover();\n-        blockManager.setPostponeBlocksFromFuture(false);\n         \n-        LOG.info(\"Reprocessing replication and invalidation queues\");\n+        blockManager.setPostponeBlocksFromFuture(false);\n         blockManager.getDatanodeManager().markAllDatanodesStale();\n         blockManager.clearQueues();\n         blockManager.processAllPendingDNMessages();\n-        blockManager.processMisReplicatedBlocks();\n+        \n+        if (!isInSafeMode() ||\n+            (isInSafeMode() \u0026\u0026 safeMode.isPopulatingReplQueues())) {\n+          LOG.info(\"Reprocessing replication and invalidation queues\");\n+          blockManager.processMisReplicatedBlocks();\n+        }\n         \n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"NameNode metadata after re-processing \" +\n               \"replication and invalidation queues during failover:\\n\" +\n               metaSaveAsString());\n         }\n         \n         long nextTxId \u003d dir.fsImage.getLastAppliedTxId() + 1;\n         LOG.info(\"Will take over writing edit logs at txnid \" + \n             nextTxId);\n         editLog.setNextTxId(nextTxId);\n \n         dir.fsImage.editLog.openForWrite();\n       }\n       if (haEnabled) {\n         // Renew all of the leases before becoming active.\n         // This is because, while we were in standby mode,\n         // the leases weren\u0027t getting renewed on this NN.\n         // Give them all a fresh start here.\n         leaseManager.renewAllLeases();\n       }\n       leaseManager.startMonitor();\n       startSecretManagerIfNecessary();\n \n       //ResourceMonitor required only at ActiveNN. See HDFS-2914\n       this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n       nnrmthread.start();\n     } finally {\n       writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void startActiveServices() throws IOException {\n    LOG.info(\"Starting services required for active state\");\n    writeLock();\n    try {\n      FSEditLog editLog \u003d dir.fsImage.getEditLog();\n      \n      if (!editLog.isOpenForWrite()) {\n        // During startup, we\u0027re already open for write during initialization.\n        editLog.initJournalsForWrite();\n        // May need to recover\n        editLog.recoverUnclosedStreams();\n        \n        LOG.info(\"Catching up to latest edits from old active before \" +\n            \"taking over writer role in edits logs\");\n        editLogTailer.catchupDuringFailover();\n        \n        blockManager.setPostponeBlocksFromFuture(false);\n        blockManager.getDatanodeManager().markAllDatanodesStale();\n        blockManager.clearQueues();\n        blockManager.processAllPendingDNMessages();\n        \n        if (!isInSafeMode() ||\n            (isInSafeMode() \u0026\u0026 safeMode.isPopulatingReplQueues())) {\n          LOG.info(\"Reprocessing replication and invalidation queues\");\n          blockManager.processMisReplicatedBlocks();\n        }\n        \n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"NameNode metadata after re-processing \" +\n              \"replication and invalidation queues during failover:\\n\" +\n              metaSaveAsString());\n        }\n        \n        long nextTxId \u003d dir.fsImage.getLastAppliedTxId() + 1;\n        LOG.info(\"Will take over writing edit logs at txnid \" + \n            nextTxId);\n        editLog.setNextTxId(nextTxId);\n\n        dir.fsImage.editLog.openForWrite();\n      }\n      if (haEnabled) {\n        // Renew all of the leases before becoming active.\n        // This is because, while we were in standby mode,\n        // the leases weren\u0027t getting renewed on this NN.\n        // Give them all a fresh start here.\n        leaseManager.renewAllLeases();\n      }\n      leaseManager.startMonitor();\n      startSecretManagerIfNecessary();\n\n      //ResourceMonitor required only at ActiveNN. See HDFS-2914\n      this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n      nnrmthread.start();\n    } finally {\n      writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "cea7bbc630deede93dbe6a1bbda56ad49de4f3de": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4122. Cleanup HDFS logs and reduce the size of logged messages. Contributed by Suresh Srinivas.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1403120 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/10/12 4:10 PM",
      "commitName": "cea7bbc630deede93dbe6a1bbda56ad49de4f3de",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "26/10/12 11:08 AM",
      "commitNameOld": "0e796b61e829c4bf763caf13b0f53cb1bcefdeee",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 2.21,
      "commitsBetweenForRepo": 10,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,53 +1,53 @@\n   void startActiveServices() throws IOException {\n     LOG.info(\"Starting services required for active state\");\n     writeLock();\n     try {\n       FSEditLog editLog \u003d dir.fsImage.getEditLog();\n       \n       if (!editLog.isOpenForWrite()) {\n         // During startup, we\u0027re already open for write during initialization.\n         editLog.initJournalsForWrite();\n         // May need to recover\n         editLog.recoverUnclosedStreams();\n         \n         LOG.info(\"Catching up to latest edits from old active before \" +\n-            \"taking over writer role in edits logs.\");\n+            \"taking over writer role in edits logs\");\n         editLogTailer.catchupDuringFailover();\n         blockManager.setPostponeBlocksFromFuture(false);\n         \n-        LOG.info(\"Reprocessing replication and invalidation queues...\");\n+        LOG.info(\"Reprocessing replication and invalidation queues\");\n         blockManager.getDatanodeManager().markAllDatanodesStale();\n         blockManager.clearQueues();\n         blockManager.processAllPendingDNMessages();\n         blockManager.processMisReplicatedBlocks();\n         \n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"NameNode metadata after re-processing \" +\n               \"replication and invalidation queues during failover:\\n\" +\n               metaSaveAsString());\n         }\n         \n         long nextTxId \u003d dir.fsImage.getLastAppliedTxId() + 1;\n         LOG.info(\"Will take over writing edit logs at txnid \" + \n             nextTxId);\n         editLog.setNextTxId(nextTxId);\n \n         dir.fsImage.editLog.openForWrite();\n       }\n       if (haEnabled) {\n         // Renew all of the leases before becoming active.\n         // This is because, while we were in standby mode,\n         // the leases weren\u0027t getting renewed on this NN.\n         // Give them all a fresh start here.\n         leaseManager.renewAllLeases();\n       }\n       leaseManager.startMonitor();\n       startSecretManagerIfNecessary();\n \n       //ResourceMonitor required only at ActiveNN. See HDFS-2914\n       this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n       nnrmthread.start();\n     } finally {\n       writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void startActiveServices() throws IOException {\n    LOG.info(\"Starting services required for active state\");\n    writeLock();\n    try {\n      FSEditLog editLog \u003d dir.fsImage.getEditLog();\n      \n      if (!editLog.isOpenForWrite()) {\n        // During startup, we\u0027re already open for write during initialization.\n        editLog.initJournalsForWrite();\n        // May need to recover\n        editLog.recoverUnclosedStreams();\n        \n        LOG.info(\"Catching up to latest edits from old active before \" +\n            \"taking over writer role in edits logs\");\n        editLogTailer.catchupDuringFailover();\n        blockManager.setPostponeBlocksFromFuture(false);\n        \n        LOG.info(\"Reprocessing replication and invalidation queues\");\n        blockManager.getDatanodeManager().markAllDatanodesStale();\n        blockManager.clearQueues();\n        blockManager.processAllPendingDNMessages();\n        blockManager.processMisReplicatedBlocks();\n        \n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"NameNode metadata after re-processing \" +\n              \"replication and invalidation queues during failover:\\n\" +\n              metaSaveAsString());\n        }\n        \n        long nextTxId \u003d dir.fsImage.getLastAppliedTxId() + 1;\n        LOG.info(\"Will take over writing edit logs at txnid \" + \n            nextTxId);\n        editLog.setNextTxId(nextTxId);\n\n        dir.fsImage.editLog.openForWrite();\n      }\n      if (haEnabled) {\n        // Renew all of the leases before becoming active.\n        // This is because, while we were in standby mode,\n        // the leases weren\u0027t getting renewed on this NN.\n        // Give them all a fresh start here.\n        leaseManager.renewAllLeases();\n      }\n      leaseManager.startMonitor();\n      startSecretManagerIfNecessary();\n\n      //ResourceMonitor required only at ActiveNN. See HDFS-2914\n      this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n      nnrmthread.start();\n    } finally {\n      writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "23b6ed973e1ff5ace1e3a97cded008908e8daa55": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3605. Block mistakenly marked corrupt during edit log catchup phase of failover. Contributed by Todd Lipcon and Brahma Reddy Battula.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1363175 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/07/12 4:42 PM",
      "commitName": "23b6ed973e1ff5ace1e3a97cded008908e8daa55",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "17/07/12 10:05 PM",
      "commitNameOld": "6981b14003d3ff99fd719515ac08d748fc5f44bd",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 0.78,
      "commitsBetweenForRepo": 6,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,52 +1,53 @@\n   void startActiveServices() throws IOException {\n     LOG.info(\"Starting services required for active state\");\n     writeLock();\n     try {\n       FSEditLog editLog \u003d dir.fsImage.getEditLog();\n       \n       if (!editLog.isOpenForWrite()) {\n         // During startup, we\u0027re already open for write during initialization.\n         editLog.initJournalsForWrite();\n         // May need to recover\n         editLog.recoverUnclosedStreams();\n         \n         LOG.info(\"Catching up to latest edits from old active before \" +\n             \"taking over writer role in edits logs.\");\n         editLogTailer.catchupDuringFailover();\n+        blockManager.setPostponeBlocksFromFuture(false);\n         \n         LOG.info(\"Reprocessing replication and invalidation queues...\");\n         blockManager.getDatanodeManager().markAllDatanodesStale();\n         blockManager.clearQueues();\n         blockManager.processAllPendingDNMessages();\n         blockManager.processMisReplicatedBlocks();\n         \n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"NameNode metadata after re-processing \" +\n               \"replication and invalidation queues during failover:\\n\" +\n               metaSaveAsString());\n         }\n         \n         long nextTxId \u003d dir.fsImage.getLastAppliedTxId() + 1;\n         LOG.info(\"Will take over writing edit logs at txnid \" + \n             nextTxId);\n         editLog.setNextTxId(nextTxId);\n \n         dir.fsImage.editLog.openForWrite();\n       }\n       if (haEnabled) {\n         // Renew all of the leases before becoming active.\n         // This is because, while we were in standby mode,\n         // the leases weren\u0027t getting renewed on this NN.\n         // Give them all a fresh start here.\n         leaseManager.renewAllLeases();\n       }\n       leaseManager.startMonitor();\n       startSecretManagerIfNecessary();\n \n       //ResourceMonitor required only at ActiveNN. See HDFS-2914\n       this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n       nnrmthread.start();\n     } finally {\n       writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void startActiveServices() throws IOException {\n    LOG.info(\"Starting services required for active state\");\n    writeLock();\n    try {\n      FSEditLog editLog \u003d dir.fsImage.getEditLog();\n      \n      if (!editLog.isOpenForWrite()) {\n        // During startup, we\u0027re already open for write during initialization.\n        editLog.initJournalsForWrite();\n        // May need to recover\n        editLog.recoverUnclosedStreams();\n        \n        LOG.info(\"Catching up to latest edits from old active before \" +\n            \"taking over writer role in edits logs.\");\n        editLogTailer.catchupDuringFailover();\n        blockManager.setPostponeBlocksFromFuture(false);\n        \n        LOG.info(\"Reprocessing replication and invalidation queues...\");\n        blockManager.getDatanodeManager().markAllDatanodesStale();\n        blockManager.clearQueues();\n        blockManager.processAllPendingDNMessages();\n        blockManager.processMisReplicatedBlocks();\n        \n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"NameNode metadata after re-processing \" +\n              \"replication and invalidation queues during failover:\\n\" +\n              metaSaveAsString());\n        }\n        \n        long nextTxId \u003d dir.fsImage.getLastAppliedTxId() + 1;\n        LOG.info(\"Will take over writing edit logs at txnid \" + \n            nextTxId);\n        editLog.setNextTxId(nextTxId);\n\n        dir.fsImage.editLog.openForWrite();\n      }\n      if (haEnabled) {\n        // Renew all of the leases before becoming active.\n        // This is because, while we were in standby mode,\n        // the leases weren\u0027t getting renewed on this NN.\n        // Give them all a fresh start here.\n        leaseManager.renewAllLeases();\n      }\n      leaseManager.startMonitor();\n      startSecretManagerIfNecessary();\n\n      //ResourceMonitor required only at ActiveNN. See HDFS-2914\n      this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n      nnrmthread.start();\n    } finally {\n      writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "b98e26af58b78d0cfb233b2b596ebf71b3e148fb": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2914. HA: Standby should not enter safemode when resources are low. Contributed by Vinay.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1347895 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/06/12 11:57 PM",
      "commitName": "b98e26af58b78d0cfb233b2b596ebf71b3e148fb",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "31/05/12 2:02 PM",
      "commitNameOld": "675a7e4acba1417a80e1403b468c32efe597ba90",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 7.41,
      "commitsBetweenForRepo": 34,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,48 +1,52 @@\n   void startActiveServices() throws IOException {\n     LOG.info(\"Starting services required for active state\");\n     writeLock();\n     try {\n       FSEditLog editLog \u003d dir.fsImage.getEditLog();\n       \n       if (!editLog.isOpenForWrite()) {\n         // During startup, we\u0027re already open for write during initialization.\n         editLog.initJournalsForWrite();\n         // May need to recover\n         editLog.recoverUnclosedStreams();\n         \n         LOG.info(\"Catching up to latest edits from old active before \" +\n             \"taking over writer role in edits logs.\");\n         editLogTailer.catchupDuringFailover();\n         \n         LOG.info(\"Reprocessing replication and invalidation queues...\");\n         blockManager.getDatanodeManager().markAllDatanodesStale();\n         blockManager.clearQueues();\n         blockManager.processAllPendingDNMessages();\n         blockManager.processMisReplicatedBlocks();\n         \n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"NameNode metadata after re-processing \" +\n               \"replication and invalidation queues during failover:\\n\" +\n               metaSaveAsString());\n         }\n         \n         long nextTxId \u003d dir.fsImage.getLastAppliedTxId() + 1;\n         LOG.info(\"Will take over writing edit logs at txnid \" + \n             nextTxId);\n         editLog.setNextTxId(nextTxId);\n \n         dir.fsImage.editLog.openForWrite();\n       }\n       if (haEnabled) {\n         // Renew all of the leases before becoming active.\n         // This is because, while we were in standby mode,\n         // the leases weren\u0027t getting renewed on this NN.\n         // Give them all a fresh start here.\n         leaseManager.renewAllLeases();\n       }\n       leaseManager.startMonitor();\n       startSecretManagerIfNecessary();\n+\n+      //ResourceMonitor required only at ActiveNN. See HDFS-2914\n+      this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n+      nnrmthread.start();\n     } finally {\n       writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void startActiveServices() throws IOException {\n    LOG.info(\"Starting services required for active state\");\n    writeLock();\n    try {\n      FSEditLog editLog \u003d dir.fsImage.getEditLog();\n      \n      if (!editLog.isOpenForWrite()) {\n        // During startup, we\u0027re already open for write during initialization.\n        editLog.initJournalsForWrite();\n        // May need to recover\n        editLog.recoverUnclosedStreams();\n        \n        LOG.info(\"Catching up to latest edits from old active before \" +\n            \"taking over writer role in edits logs.\");\n        editLogTailer.catchupDuringFailover();\n        \n        LOG.info(\"Reprocessing replication and invalidation queues...\");\n        blockManager.getDatanodeManager().markAllDatanodesStale();\n        blockManager.clearQueues();\n        blockManager.processAllPendingDNMessages();\n        blockManager.processMisReplicatedBlocks();\n        \n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"NameNode metadata after re-processing \" +\n              \"replication and invalidation queues during failover:\\n\" +\n              metaSaveAsString());\n        }\n        \n        long nextTxId \u003d dir.fsImage.getLastAppliedTxId() + 1;\n        LOG.info(\"Will take over writing edit logs at txnid \" + \n            nextTxId);\n        editLog.setNextTxId(nextTxId);\n\n        dir.fsImage.editLog.openForWrite();\n      }\n      if (haEnabled) {\n        // Renew all of the leases before becoming active.\n        // This is because, while we were in standby mode,\n        // the leases weren\u0027t getting renewed on this NN.\n        // Give them all a fresh start here.\n        leaseManager.renewAllLeases();\n      }\n      leaseManager.startMonitor();\n      startSecretManagerIfNecessary();\n\n      //ResourceMonitor required only at ActiveNN. See HDFS-2914\n      this.nnrmthread \u003d new Daemon(new NameNodeResourceMonitor());\n      nnrmthread.start();\n    } finally {\n      writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    }
  }
}