{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "RouterRpcClient.java",
  "functionName": "getClientConfiguration",
  "functionId": "getClientConfiguration___conf-Configuration(modifiers-final)",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcClient.java",
  "functionStartLine": 183,
  "functionEndLine": 200,
  "numCommitsSeen": 24,
  "timeTaken": 1000,
  "changeHistory": [
    "6c42d4050461ab71c88f123569649793dc53aebd"
  ],
  "changeHistoryShort": {
    "6c42d4050461ab71c88f123569649793dc53aebd": "Yintroduced"
  },
  "changeHistoryDetails": {
    "6c42d4050461ab71c88f123569649793dc53aebd": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-14316. RBF: Support unavailable subclusters for mount points with multiple destinations. Contributed by Inigo Goiri.\n",
      "commitDate": "24/06/19 9:33 AM",
      "commitName": "6c42d4050461ab71c88f123569649793dc53aebd",
      "commitAuthor": "Ayush Saxena",
      "diff": "@@ -0,0 +1,18 @@\n+  private Configuration getClientConfiguration(final Configuration conf) {\n+    Configuration clientConf \u003d new Configuration(conf);\n+    int maxRetries \u003d conf.getInt(\n+        RBFConfigKeys.DFS_ROUTER_CLIENT_MAX_RETRIES_TIME_OUT,\n+        RBFConfigKeys.DFS_ROUTER_CLIENT_MAX_RETRIES_TIME_OUT_DEFAULT);\n+    if (maxRetries \u003e\u003d 0) {\n+      clientConf.setInt(\n+          IPC_CLIENT_CONNECT_MAX_RETRIES_ON_SOCKET_TIMEOUTS_KEY, maxRetries);\n+    }\n+    long connectTimeOut \u003d conf.getTimeDuration(\n+        RBFConfigKeys.DFS_ROUTER_CLIENT_CONNECT_TIMEOUT,\n+        RBFConfigKeys.DFS_ROUTER_CLIENT_CONNECT_TIMEOUT_DEFAULT,\n+        TimeUnit.MILLISECONDS);\n+    if (connectTimeOut \u003e\u003d 0) {\n+      clientConf.setLong(IPC_CLIENT_CONNECT_TIMEOUT_KEY, connectTimeOut);\n+    }\n+    return clientConf;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private Configuration getClientConfiguration(final Configuration conf) {\n    Configuration clientConf \u003d new Configuration(conf);\n    int maxRetries \u003d conf.getInt(\n        RBFConfigKeys.DFS_ROUTER_CLIENT_MAX_RETRIES_TIME_OUT,\n        RBFConfigKeys.DFS_ROUTER_CLIENT_MAX_RETRIES_TIME_OUT_DEFAULT);\n    if (maxRetries \u003e\u003d 0) {\n      clientConf.setInt(\n          IPC_CLIENT_CONNECT_MAX_RETRIES_ON_SOCKET_TIMEOUTS_KEY, maxRetries);\n    }\n    long connectTimeOut \u003d conf.getTimeDuration(\n        RBFConfigKeys.DFS_ROUTER_CLIENT_CONNECT_TIMEOUT,\n        RBFConfigKeys.DFS_ROUTER_CLIENT_CONNECT_TIMEOUT_DEFAULT,\n        TimeUnit.MILLISECONDS);\n    if (connectTimeOut \u003e\u003d 0) {\n      clientConf.setLong(IPC_CLIENT_CONNECT_TIMEOUT_KEY, connectTimeOut);\n    }\n    return clientConf;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcClient.java"
    }
  }
}