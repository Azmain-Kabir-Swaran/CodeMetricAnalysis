{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ReadBufferManager.java",
  "functionName": "evict",
  "functionId": "evict___buf-ReadBuffer(modifiers-final)",
  "sourceFilePath": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ReadBufferManager.java",
  "functionStartLine": 260,
  "functionEndLine": 273,
  "numCommitsSeen": 3,
  "timeTaken": 1270,
  "changeHistory": [
    "53b993e6048ffaaf98e460690211fc08efb20cf2",
    "ce03a93f78c4d97ccb48a3906fcd77ad0ac756be",
    "f044deedbbfee0812316d587139cb828f27172e9"
  ],
  "changeHistoryShort": {
    "53b993e6048ffaaf98e460690211fc08efb20cf2": "Ybodychange",
    "ce03a93f78c4d97ccb48a3906fcd77ad0ac756be": "Ybodychange",
    "f044deedbbfee0812316d587139cb828f27172e9": "Yintroduced"
  },
  "changeHistoryDetails": {
    "53b993e6048ffaaf98e460690211fc08efb20cf2": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-16852: Report read-ahead error back\n\nContributed by Sneha Vijayarajan",
      "commitDate": "27/05/20 1:51 PM",
      "commitName": "53b993e6048ffaaf98e460690211fc08efb20cf2",
      "commitAuthor": "Sneha Vijayarajan",
      "commitDateOld": "17/09/18 12:54 PM",
      "commitNameOld": "ce03a93f78c4d97ccb48a3906fcd77ad0ac756be",
      "commitAuthorOld": "Thomas Marquardt",
      "daysBetweenCommits": 618.04,
      "commitsBetweenForRepo": 3845,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,9 +1,14 @@\n   private boolean evict(final ReadBuffer buf) {\n-    freeList.push(buf.getBufferindex());\n+    // As failed ReadBuffers (bufferIndx \u003d -1) are saved in completedReadList,\n+    // avoid adding it to freeList.\n+    if (buf.getBufferindex() !\u003d -1) {\n+      freeList.push(buf.getBufferindex());\n+    }\n+\n     completedReadList.remove(buf);\n     if (LOGGER.isTraceEnabled()) {\n       LOGGER.trace(\"Evicting buffer idx {}; was used for file {} offset {} length {}\",\n           buf.getBufferindex(), buf.getStream().getPath(), buf.getOffset(), buf.getLength());\n     }\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean evict(final ReadBuffer buf) {\n    // As failed ReadBuffers (bufferIndx \u003d -1) are saved in completedReadList,\n    // avoid adding it to freeList.\n    if (buf.getBufferindex() !\u003d -1) {\n      freeList.push(buf.getBufferindex());\n    }\n\n    completedReadList.remove(buf);\n    if (LOGGER.isTraceEnabled()) {\n      LOGGER.trace(\"Evicting buffer idx {}; was used for file {} offset {} length {}\",\n          buf.getBufferindex(), buf.getStream().getPath(), buf.getOffset(), buf.getLength());\n    }\n    return true;\n  }",
      "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ReadBufferManager.java",
      "extendedDetails": {}
    },
    "ce03a93f78c4d97ccb48a3906fcd77ad0ac756be": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-15446. ABFS: tune imports \u0026 javadocs; stabilise tests.\nContributed by Steve Loughran and Da Zhou.\n",
      "commitDate": "17/09/18 12:54 PM",
      "commitName": "ce03a93f78c4d97ccb48a3906fcd77ad0ac756be",
      "commitAuthor": "Thomas Marquardt",
      "commitDateOld": "17/09/18 12:54 PM",
      "commitNameOld": "f044deedbbfee0812316d587139cb828f27172e9",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,9 +1,9 @@\n   private boolean evict(final ReadBuffer buf) {\n     freeList.push(buf.getBufferindex());\n     completedReadList.remove(buf);\n     if (LOGGER.isTraceEnabled()) {\n-      LOGGER.trace(\"Evicting buffer idx \" + buf.getBufferindex() + \"; was used for file \" + buf.getStream().getPath()\n-          + \" offset \" + buf.getOffset() + \" length \" + buf.getLength());\n+      LOGGER.trace(\"Evicting buffer idx {}; was used for file {} offset {} length {}\",\n+          buf.getBufferindex(), buf.getStream().getPath(), buf.getOffset(), buf.getLength());\n     }\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean evict(final ReadBuffer buf) {\n    freeList.push(buf.getBufferindex());\n    completedReadList.remove(buf);\n    if (LOGGER.isTraceEnabled()) {\n      LOGGER.trace(\"Evicting buffer idx {}; was used for file {} offset {} length {}\",\n          buf.getBufferindex(), buf.getStream().getPath(), buf.getOffset(), buf.getLength());\n    }\n    return true;\n  }",
      "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ReadBufferManager.java",
      "extendedDetails": {}
    },
    "f044deedbbfee0812316d587139cb828f27172e9": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-15407. HADOOP-15540. Support Windows Azure Storage - Blob file system \"ABFS\" in Hadoop: Core Commit.\n\nContributed by Shane Mainali, Thomas Marquardt, Zichen Sun, Georgi Chalakov, Esfandiar Manii, Amit Singh, Dana Kaban, Da Zhou, Junhua Gu, Saher Ahwal, Saurabh Pant, James Baker, Shaoyu Zhang, Lawrence Chen, Kevin Chen and Steve Loughran\n",
      "commitDate": "17/09/18 12:54 PM",
      "commitName": "f044deedbbfee0812316d587139cb828f27172e9",
      "commitAuthor": "Steve Loughran",
      "diff": "@@ -0,0 +1,9 @@\n+  private boolean evict(final ReadBuffer buf) {\n+    freeList.push(buf.getBufferindex());\n+    completedReadList.remove(buf);\n+    if (LOGGER.isTraceEnabled()) {\n+      LOGGER.trace(\"Evicting buffer idx \" + buf.getBufferindex() + \"; was used for file \" + buf.getStream().getPath()\n+          + \" offset \" + buf.getOffset() + \" length \" + buf.getLength());\n+    }\n+    return true;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean evict(final ReadBuffer buf) {\n    freeList.push(buf.getBufferindex());\n    completedReadList.remove(buf);\n    if (LOGGER.isTraceEnabled()) {\n      LOGGER.trace(\"Evicting buffer idx \" + buf.getBufferindex() + \"; was used for file \" + buf.getStream().getPath()\n          + \" offset \" + buf.getOffset() + \" length \" + buf.getLength());\n    }\n    return true;\n  }",
      "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ReadBufferManager.java"
    }
  }
}