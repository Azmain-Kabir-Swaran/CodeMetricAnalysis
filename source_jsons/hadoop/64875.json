{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "S3ALocatedFileStatus.java",
  "functionName": "toS3AFileStatus",
  "functionId": "toS3AFileStatus",
  "sourceFilePath": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ALocatedFileStatus.java",
  "functionStartLine": 70,
  "functionEndLine": 81,
  "numCommitsSeen": 3,
  "timeTaken": 2009,
  "changeHistory": [
    "511df1e837b19ccb9271520589452d82d50ac69d",
    "b15ef7dc3d91c6d50fa515158104fba29f43e6b0"
  ],
  "changeHistoryShort": {
    "511df1e837b19ccb9271520589452d82d50ac69d": "Ybodychange",
    "b15ef7dc3d91c6d50fa515158104fba29f43e6b0": "Yintroduced"
  },
  "changeHistoryDetails": {
    "511df1e837b19ccb9271520589452d82d50ac69d": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-16430. S3AFilesystem.delete to incrementally update s3guard with deletions\n\nContributed by Steve Loughran.\n\nThis overlaps the scanning for directory entries with batched calls to S3 DELETE and updates of the S3Guard tables.\nIt also uses S3Guard to list the files to delete, so find newly created files even when S3 listings are not use consistent.\n\nFor path which the client considers S3Guard to be authoritative, we also do a recursive LIST of the store and delete files; this is to find unindexed files and do guarantee that the delete(path, true) call really does delete everything underneath.\n\nChange-Id: Ice2f6e940c506e0b3a78fa534a99721b1698708e\n",
      "commitDate": "05/09/19 6:25 AM",
      "commitName": "511df1e837b19ccb9271520589452d82d50ac69d",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "12/07/19 5:02 AM",
      "commitNameOld": "b15ef7dc3d91c6d50fa515158104fba29f43e6b0",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 55.06,
      "commitsBetweenForRepo": 491,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,10 +1,12 @@\n   public S3AFileStatus toS3AFileStatus() {\n     return new S3AFileStatus(\n+        getPath(),\n+        isDirectory(),\n+        isEmptyDirectory,\n         getLen(),\n         getModificationTime(),\n-        getPath(),\n         getBlockSize(),\n         getOwner(),\n         getETag(),\n         getVersionId());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public S3AFileStatus toS3AFileStatus() {\n    return new S3AFileStatus(\n        getPath(),\n        isDirectory(),\n        isEmptyDirectory,\n        getLen(),\n        getModificationTime(),\n        getBlockSize(),\n        getOwner(),\n        getETag(),\n        getVersionId());\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ALocatedFileStatus.java",
      "extendedDetails": {}
    },
    "b15ef7dc3d91c6d50fa515158104fba29f43e6b0": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-16384: S3A: Avoid inconsistencies between DDB and S3.\n\nContributed by Steve Loughran\n\nContains\n\n- HADOOP-16397. Hadoop S3Guard Prune command to support a -tombstone option.\n- HADOOP-16406. ITestDynamoDBMetadataStore.testProvisionTable times out intermittently\n\nThis patch doesn\u0027t fix the underlying problem but it\n\n* changes some tests to clean up better\n* does a lot more in logging operations in against DDB, if enabled\n* adds an entry point to dump the state of the metastore and s3 tables (precursor to fsck)\n* adds a purge entry point to help clean up after a test run has got a store into a mess\n* s3guard prune command adds -tombstone option to only clear tombstones\n\nThe outcome is that tests should pass consistently and if problems occur we have better diagnostics.\n\nChange-Id: I3eca3f5529d7f6fec398c0ff0472919f08f054eb\n",
      "commitDate": "12/07/19 5:02 AM",
      "commitName": "b15ef7dc3d91c6d50fa515158104fba29f43e6b0",
      "commitAuthor": "Steve Loughran",
      "diff": "@@ -0,0 +1,10 @@\n+  public S3AFileStatus toS3AFileStatus() {\n+    return new S3AFileStatus(\n+        getLen(),\n+        getModificationTime(),\n+        getPath(),\n+        getBlockSize(),\n+        getOwner(),\n+        getETag(),\n+        getVersionId());\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public S3AFileStatus toS3AFileStatus() {\n    return new S3AFileStatus(\n        getLen(),\n        getModificationTime(),\n        getPath(),\n        getBlockSize(),\n        getOwner(),\n        getETag(),\n        getVersionId());\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ALocatedFileStatus.java"
    }
  }
}