{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "WebHdfsFileSystem.java",
  "functionName": "jsonParse",
  "functionId": "jsonParse___c-HttpURLConnection(modifiers-final)__useErrorStream-boolean(modifiers-final)",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
  "functionStartLine": 463,
  "functionEndLine": 488,
  "numCommitsSeen": 211,
  "timeTaken": 5274,
  "changeHistory": [
    "7a3c6e9c3cd9ffdc71946fd12f5c3d59718c4939",
    "1bcfab8e7fd8562f1829ac484d2f6c91f7afe3d6",
    "bcf89ddc7d52e04725caf104f5958e33d9f51b35",
    "e2262d3d18c6d5c2aa20f96920104dc07271b869",
    "2b0fa20f69417326a92beac10ffa072db2616e73",
    "6449f524552f8c24d20b314ad21f6c579fa08e85",
    "361ea9a62cb85e6d60682c4a73e874d305625d8b",
    "09a156fcce2bc1be4081717bf7ef7d290e80d818",
    "8cb0d4b380e0fd4437310c1dd6ef8b8995cc383d",
    "6c3b59505b863f03629da52a1e9b886fe9b496d0",
    "61d0b7530c8978c095ab6f62d9d38e168bd829c6"
  ],
  "changeHistoryShort": {
    "7a3c6e9c3cd9ffdc71946fd12f5c3d59718c4939": "Ybodychange",
    "1bcfab8e7fd8562f1829ac484d2f6c91f7afe3d6": "Ybodychange",
    "bcf89ddc7d52e04725caf104f5958e33d9f51b35": "Yfilerename",
    "e2262d3d18c6d5c2aa20f96920104dc07271b869": "Ybodychange",
    "2b0fa20f69417326a92beac10ffa072db2616e73": "Ybodychange",
    "6449f524552f8c24d20b314ad21f6c579fa08e85": "Ybodychange",
    "361ea9a62cb85e6d60682c4a73e874d305625d8b": "Ymultichange(Yparameterchange,Ybodychange)",
    "09a156fcce2bc1be4081717bf7ef7d290e80d818": "Ymodifierchange",
    "8cb0d4b380e0fd4437310c1dd6ef8b8995cc383d": "Ymultichange(Yreturntypechange,Ybodychange)",
    "6c3b59505b863f03629da52a1e9b886fe9b496d0": "Ymultichange(Yreturntypechange,Ybodychange)",
    "61d0b7530c8978c095ab6f62d9d38e168bd829c6": "Yintroduced"
  },
  "changeHistoryDetails": {
    "7a3c6e9c3cd9ffdc71946fd12f5c3d59718c4939": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-15550. Avoid static initialization of ObjectMappers\n",
      "commitDate": "25/06/18 3:36 PM",
      "commitName": "7a3c6e9c3cd9ffdc71946fd12f5c3d59718c4939",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "31/05/18 6:59 AM",
      "commitNameOld": "1361030e59d7557a2bffac0ea8df116ce2eaae4a",
      "commitAuthorOld": "Sean Mackrory",
      "daysBetweenCommits": 25.36,
      "commitsBetweenForRepo": 166,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,26 +1,26 @@\n   static Map\u003c?, ?\u003e jsonParse(final HttpURLConnection c,\n       final boolean useErrorStream) throws IOException {\n     if (c.getContentLength() \u003d\u003d 0) {\n       return null;\n     }\n     final InputStream in \u003d useErrorStream ?\n         c.getErrorStream() : c.getInputStream();\n     if (in \u003d\u003d null) {\n       throw new IOException(\"The \" + (useErrorStream? \"error\": \"input\") +\n           \" stream is null.\");\n     }\n     try {\n       final String contentType \u003d c.getContentType();\n       if (contentType !\u003d null) {\n         final MediaType parsed \u003d MediaType.valueOf(contentType);\n         if (!MediaType.APPLICATION_JSON_TYPE.isCompatible(parsed)) {\n           throw new IOException(\"Content-Type \\\"\" + contentType\n               + \"\\\" is incompatible with \\\"\" + MediaType.APPLICATION_JSON\n               + \"\\\" (parsed\u003d\\\"\" + parsed + \"\\\")\");\n         }\n       }\n-      return READER.readValue(in);\n+      return JsonSerialization.mapReader().readValue(in);\n     } finally {\n       in.close();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static Map\u003c?, ?\u003e jsonParse(final HttpURLConnection c,\n      final boolean useErrorStream) throws IOException {\n    if (c.getContentLength() \u003d\u003d 0) {\n      return null;\n    }\n    final InputStream in \u003d useErrorStream ?\n        c.getErrorStream() : c.getInputStream();\n    if (in \u003d\u003d null) {\n      throw new IOException(\"The \" + (useErrorStream? \"error\": \"input\") +\n          \" stream is null.\");\n    }\n    try {\n      final String contentType \u003d c.getContentType();\n      if (contentType !\u003d null) {\n        final MediaType parsed \u003d MediaType.valueOf(contentType);\n        if (!MediaType.APPLICATION_JSON_TYPE.isCompatible(parsed)) {\n          throw new IOException(\"Content-Type \\\"\" + contentType\n              + \"\\\" is incompatible with \\\"\" + MediaType.APPLICATION_JSON\n              + \"\\\" (parsed\u003d\\\"\" + parsed + \"\\\")\");\n        }\n      }\n      return JsonSerialization.mapReader().readValue(in);\n    } finally {\n      in.close();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
      "extendedDetails": {}
    },
    "1bcfab8e7fd8562f1829ac484d2f6c91f7afe3d6": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9724. Degraded performance in WebHDFS listing as it does not reuse ObjectMapper. Contributed by Akira Ajisaka.\n",
      "commitDate": "04/02/16 11:34 AM",
      "commitName": "1bcfab8e7fd8562f1829ac484d2f6c91f7afe3d6",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "22/01/16 12:15 PM",
      "commitNameOld": "d22c4239a40a1c7ed49c06038138f0e3f387b4a0",
      "commitAuthorOld": "Allen Wittenauer",
      "daysBetweenCommits": 12.97,
      "commitsBetweenForRepo": 91,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,27 +1,26 @@\n   static Map\u003c?, ?\u003e jsonParse(final HttpURLConnection c,\n       final boolean useErrorStream) throws IOException {\n     if (c.getContentLength() \u003d\u003d 0) {\n       return null;\n     }\n     final InputStream in \u003d useErrorStream ?\n         c.getErrorStream() : c.getInputStream();\n     if (in \u003d\u003d null) {\n       throw new IOException(\"The \" + (useErrorStream? \"error\": \"input\") +\n           \" stream is null.\");\n     }\n     try {\n       final String contentType \u003d c.getContentType();\n       if (contentType !\u003d null) {\n         final MediaType parsed \u003d MediaType.valueOf(contentType);\n         if (!MediaType.APPLICATION_JSON_TYPE.isCompatible(parsed)) {\n           throw new IOException(\"Content-Type \\\"\" + contentType\n               + \"\\\" is incompatible with \\\"\" + MediaType.APPLICATION_JSON\n               + \"\\\" (parsed\u003d\\\"\" + parsed + \"\\\")\");\n         }\n       }\n-      ObjectMapper mapper \u003d new ObjectMapper();\n-      return mapper.reader(Map.class).readValue(in);\n+      return READER.readValue(in);\n     } finally {\n       in.close();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static Map\u003c?, ?\u003e jsonParse(final HttpURLConnection c,\n      final boolean useErrorStream) throws IOException {\n    if (c.getContentLength() \u003d\u003d 0) {\n      return null;\n    }\n    final InputStream in \u003d useErrorStream ?\n        c.getErrorStream() : c.getInputStream();\n    if (in \u003d\u003d null) {\n      throw new IOException(\"The \" + (useErrorStream? \"error\": \"input\") +\n          \" stream is null.\");\n    }\n    try {\n      final String contentType \u003d c.getContentType();\n      if (contentType !\u003d null) {\n        final MediaType parsed \u003d MediaType.valueOf(contentType);\n        if (!MediaType.APPLICATION_JSON_TYPE.isCompatible(parsed)) {\n          throw new IOException(\"Content-Type \\\"\" + contentType\n              + \"\\\" is incompatible with \\\"\" + MediaType.APPLICATION_JSON\n              + \"\\\" (parsed\u003d\\\"\" + parsed + \"\\\")\");\n        }\n      }\n      return READER.readValue(in);\n    } finally {\n      in.close();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
      "extendedDetails": {}
    },
    "bcf89ddc7d52e04725caf104f5958e33d9f51b35": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8052. Move WebHdfsFileSystem into hadoop-hdfs-client. Contributed by Haohui Mai.\n",
      "commitDate": "23/04/15 5:33 PM",
      "commitName": "bcf89ddc7d52e04725caf104f5958e33d9f51b35",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "23/04/15 4:40 PM",
      "commitNameOld": "0b3f8957a87ada1a275c9904b211fdbdcefafb02",
      "commitAuthorOld": "Xuan",
      "daysBetweenCommits": 0.04,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  static Map\u003c?, ?\u003e jsonParse(final HttpURLConnection c, final boolean useErrorStream\n      ) throws IOException {\n    if (c.getContentLength() \u003d\u003d 0) {\n      return null;\n    }\n    final InputStream in \u003d useErrorStream? c.getErrorStream(): c.getInputStream();\n    if (in \u003d\u003d null) {\n      throw new IOException(\"The \" + (useErrorStream? \"error\": \"input\") + \" stream is null.\");\n    }\n    try {\n      final String contentType \u003d c.getContentType();\n      if (contentType !\u003d null) {\n        final MediaType parsed \u003d MediaType.valueOf(contentType);\n        if (!MediaType.APPLICATION_JSON_TYPE.isCompatible(parsed)) {\n          throw new IOException(\"Content-Type \\\"\" + contentType\n              + \"\\\" is incompatible with \\\"\" + MediaType.APPLICATION_JSON\n              + \"\\\" (parsed\u003d\\\"\" + parsed + \"\\\")\");\n        }\n      }\n      ObjectMapper mapper \u003d new ObjectMapper();\n      return mapper.reader(Map.class).readValue(in);\n    } finally {\n      in.close();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java"
      }
    },
    "e2262d3d18c6d5c2aa20f96920104dc07271b869": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6565. Use jackson instead jetty json in hdfs-client. Contributed by Akira AJISAKA.\n",
      "commitDate": "03/03/15 5:54 PM",
      "commitName": "e2262d3d18c6d5c2aa20f96920104dc07271b869",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "02/03/15 9:17 PM",
      "commitNameOld": "d1c6accb6f87b08975175580e15f1ff1fe29ab04",
      "commitAuthorOld": "Tsuyoshi Ozawa",
      "daysBetweenCommits": 0.86,
      "commitsBetweenForRepo": 9,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,25 @@\n   static Map\u003c?, ?\u003e jsonParse(final HttpURLConnection c, final boolean useErrorStream\n       ) throws IOException {\n     if (c.getContentLength() \u003d\u003d 0) {\n       return null;\n     }\n     final InputStream in \u003d useErrorStream? c.getErrorStream(): c.getInputStream();\n     if (in \u003d\u003d null) {\n       throw new IOException(\"The \" + (useErrorStream? \"error\": \"input\") + \" stream is null.\");\n     }\n     try {\n       final String contentType \u003d c.getContentType();\n       if (contentType !\u003d null) {\n         final MediaType parsed \u003d MediaType.valueOf(contentType);\n         if (!MediaType.APPLICATION_JSON_TYPE.isCompatible(parsed)) {\n           throw new IOException(\"Content-Type \\\"\" + contentType\n               + \"\\\" is incompatible with \\\"\" + MediaType.APPLICATION_JSON\n               + \"\\\" (parsed\u003d\\\"\" + parsed + \"\\\")\");\n         }\n       }\n-      return (Map\u003c?, ?\u003e)JSON.parse(new InputStreamReader(in, Charsets.UTF_8));\n+      ObjectMapper mapper \u003d new ObjectMapper();\n+      return mapper.reader(Map.class).readValue(in);\n     } finally {\n       in.close();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static Map\u003c?, ?\u003e jsonParse(final HttpURLConnection c, final boolean useErrorStream\n      ) throws IOException {\n    if (c.getContentLength() \u003d\u003d 0) {\n      return null;\n    }\n    final InputStream in \u003d useErrorStream? c.getErrorStream(): c.getInputStream();\n    if (in \u003d\u003d null) {\n      throw new IOException(\"The \" + (useErrorStream? \"error\": \"input\") + \" stream is null.\");\n    }\n    try {\n      final String contentType \u003d c.getContentType();\n      if (contentType !\u003d null) {\n        final MediaType parsed \u003d MediaType.valueOf(contentType);\n        if (!MediaType.APPLICATION_JSON_TYPE.isCompatible(parsed)) {\n          throw new IOException(\"Content-Type \\\"\" + contentType\n              + \"\\\" is incompatible with \\\"\" + MediaType.APPLICATION_JSON\n              + \"\\\" (parsed\u003d\\\"\" + parsed + \"\\\")\");\n        }\n      }\n      ObjectMapper mapper \u003d new ObjectMapper();\n      return mapper.reader(Map.class).readValue(in);\n    } finally {\n      in.close();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
      "extendedDetails": {}
    },
    "2b0fa20f69417326a92beac10ffa072db2616e73": {
      "type": "Ybodychange",
      "commitMessage": " HDFS-7224. Allow reuse of NN connections via webhdfs. Contributed by Eric Payne\n",
      "commitDate": "26/01/15 6:14 AM",
      "commitName": "2b0fa20f69417326a92beac10ffa072db2616e73",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "29/10/14 4:25 PM",
      "commitNameOld": "6f5f604a798b545faf6fadc9b66c8a8995b354db",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 88.62,
      "commitsBetweenForRepo": 600,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,24 @@\n   static Map\u003c?, ?\u003e jsonParse(final HttpURLConnection c, final boolean useErrorStream\n       ) throws IOException {\n     if (c.getContentLength() \u003d\u003d 0) {\n       return null;\n     }\n     final InputStream in \u003d useErrorStream? c.getErrorStream(): c.getInputStream();\n     if (in \u003d\u003d null) {\n       throw new IOException(\"The \" + (useErrorStream? \"error\": \"input\") + \" stream is null.\");\n     }\n-    final String contentType \u003d c.getContentType();\n-    if (contentType !\u003d null) {\n-      final MediaType parsed \u003d MediaType.valueOf(contentType);\n-      if (!MediaType.APPLICATION_JSON_TYPE.isCompatible(parsed)) {\n-        throw new IOException(\"Content-Type \\\"\" + contentType\n-            + \"\\\" is incompatible with \\\"\" + MediaType.APPLICATION_JSON\n-            + \"\\\" (parsed\u003d\\\"\" + parsed + \"\\\")\");\n+    try {\n+      final String contentType \u003d c.getContentType();\n+      if (contentType !\u003d null) {\n+        final MediaType parsed \u003d MediaType.valueOf(contentType);\n+        if (!MediaType.APPLICATION_JSON_TYPE.isCompatible(parsed)) {\n+          throw new IOException(\"Content-Type \\\"\" + contentType\n+              + \"\\\" is incompatible with \\\"\" + MediaType.APPLICATION_JSON\n+              + \"\\\" (parsed\u003d\\\"\" + parsed + \"\\\")\");\n+        }\n       }\n+      return (Map\u003c?, ?\u003e)JSON.parse(new InputStreamReader(in, Charsets.UTF_8));\n+    } finally {\n+      in.close();\n     }\n-    return (Map\u003c?, ?\u003e)JSON.parse(new InputStreamReader(in, Charsets.UTF_8));\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static Map\u003c?, ?\u003e jsonParse(final HttpURLConnection c, final boolean useErrorStream\n      ) throws IOException {\n    if (c.getContentLength() \u003d\u003d 0) {\n      return null;\n    }\n    final InputStream in \u003d useErrorStream? c.getErrorStream(): c.getInputStream();\n    if (in \u003d\u003d null) {\n      throw new IOException(\"The \" + (useErrorStream? \"error\": \"input\") + \" stream is null.\");\n    }\n    try {\n      final String contentType \u003d c.getContentType();\n      if (contentType !\u003d null) {\n        final MediaType parsed \u003d MediaType.valueOf(contentType);\n        if (!MediaType.APPLICATION_JSON_TYPE.isCompatible(parsed)) {\n          throw new IOException(\"Content-Type \\\"\" + contentType\n              + \"\\\" is incompatible with \\\"\" + MediaType.APPLICATION_JSON\n              + \"\\\" (parsed\u003d\\\"\" + parsed + \"\\\")\");\n        }\n      }\n      return (Map\u003c?, ?\u003e)JSON.parse(new InputStreamReader(in, Charsets.UTF_8));\n    } finally {\n      in.close();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
      "extendedDetails": {}
    },
    "6449f524552f8c24d20b314ad21f6c579fa08e85": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4032. Specify the charset explicitly rather than rely on the default. Contributed by Eli Collins\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1431179 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/01/13 6:30 PM",
      "commitName": "6449f524552f8c24d20b314ad21f6c579fa08e85",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "21/11/12 4:29 AM",
      "commitNameOld": "d6af50719961be7052c9f363110ebad26e5937f9",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 49.58,
      "commitsBetweenForRepo": 184,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,20 @@\n   static Map\u003c?, ?\u003e jsonParse(final HttpURLConnection c, final boolean useErrorStream\n       ) throws IOException {\n     if (c.getContentLength() \u003d\u003d 0) {\n       return null;\n     }\n     final InputStream in \u003d useErrorStream? c.getErrorStream(): c.getInputStream();\n     if (in \u003d\u003d null) {\n       throw new IOException(\"The \" + (useErrorStream? \"error\": \"input\") + \" stream is null.\");\n     }\n     final String contentType \u003d c.getContentType();\n     if (contentType !\u003d null) {\n       final MediaType parsed \u003d MediaType.valueOf(contentType);\n       if (!MediaType.APPLICATION_JSON_TYPE.isCompatible(parsed)) {\n         throw new IOException(\"Content-Type \\\"\" + contentType\n             + \"\\\" is incompatible with \\\"\" + MediaType.APPLICATION_JSON\n             + \"\\\" (parsed\u003d\\\"\" + parsed + \"\\\")\");\n       }\n     }\n-    return (Map\u003c?, ?\u003e)JSON.parse(new InputStreamReader(in));\n+    return (Map\u003c?, ?\u003e)JSON.parse(new InputStreamReader(in, Charsets.UTF_8));\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static Map\u003c?, ?\u003e jsonParse(final HttpURLConnection c, final boolean useErrorStream\n      ) throws IOException {\n    if (c.getContentLength() \u003d\u003d 0) {\n      return null;\n    }\n    final InputStream in \u003d useErrorStream? c.getErrorStream(): c.getInputStream();\n    if (in \u003d\u003d null) {\n      throw new IOException(\"The \" + (useErrorStream? \"error\": \"input\") + \" stream is null.\");\n    }\n    final String contentType \u003d c.getContentType();\n    if (contentType !\u003d null) {\n      final MediaType parsed \u003d MediaType.valueOf(contentType);\n      if (!MediaType.APPLICATION_JSON_TYPE.isCompatible(parsed)) {\n        throw new IOException(\"Content-Type \\\"\" + contentType\n            + \"\\\" is incompatible with \\\"\" + MediaType.APPLICATION_JSON\n            + \"\\\" (parsed\u003d\\\"\" + parsed + \"\\\")\");\n      }\n    }\n    return (Map\u003c?, ?\u003e)JSON.parse(new InputStreamReader(in, Charsets.UTF_8));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
      "extendedDetails": {}
    },
    "361ea9a62cb85e6d60682c4a73e874d305625d8b": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-3516. Check content-type in WebHdfsFileSystem.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1353800 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "25/06/12 6:58 PM",
      "commitName": "361ea9a62cb85e6d60682c4a73e874d305625d8b",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-3516. Check content-type in WebHdfsFileSystem.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1353800 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "25/06/12 6:58 PM",
          "commitName": "361ea9a62cb85e6d60682c4a73e874d305625d8b",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "12/06/12 2:52 PM",
          "commitNameOld": "4d4661802e8109c264a5fce27cbad091fb91697a",
          "commitAuthorOld": "Alejandro Abdelnur",
          "daysBetweenCommits": 13.17,
          "commitsBetweenForRepo": 41,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,6 +1,20 @@\n-  static Map\u003c?, ?\u003e jsonParse(final InputStream in) throws IOException {\n+  static Map\u003c?, ?\u003e jsonParse(final HttpURLConnection c, final boolean useErrorStream\n+      ) throws IOException {\n+    if (c.getContentLength() \u003d\u003d 0) {\n+      return null;\n+    }\n+    final InputStream in \u003d useErrorStream? c.getErrorStream(): c.getInputStream();\n     if (in \u003d\u003d null) {\n-      throw new IOException(\"The input stream is null.\");\n+      throw new IOException(\"The \" + (useErrorStream? \"error\": \"input\") + \" stream is null.\");\n+    }\n+    final String contentType \u003d c.getContentType();\n+    if (contentType !\u003d null) {\n+      final MediaType parsed \u003d MediaType.valueOf(contentType);\n+      if (!MediaType.APPLICATION_JSON_TYPE.isCompatible(parsed)) {\n+        throw new IOException(\"Content-Type \\\"\" + contentType\n+            + \"\\\" is incompatible with \\\"\" + MediaType.APPLICATION_JSON\n+            + \"\\\" (parsed\u003d\\\"\" + parsed + \"\\\")\");\n+      }\n     }\n     return (Map\u003c?, ?\u003e)JSON.parse(new InputStreamReader(in));\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static Map\u003c?, ?\u003e jsonParse(final HttpURLConnection c, final boolean useErrorStream\n      ) throws IOException {\n    if (c.getContentLength() \u003d\u003d 0) {\n      return null;\n    }\n    final InputStream in \u003d useErrorStream? c.getErrorStream(): c.getInputStream();\n    if (in \u003d\u003d null) {\n      throw new IOException(\"The \" + (useErrorStream? \"error\": \"input\") + \" stream is null.\");\n    }\n    final String contentType \u003d c.getContentType();\n    if (contentType !\u003d null) {\n      final MediaType parsed \u003d MediaType.valueOf(contentType);\n      if (!MediaType.APPLICATION_JSON_TYPE.isCompatible(parsed)) {\n        throw new IOException(\"Content-Type \\\"\" + contentType\n            + \"\\\" is incompatible with \\\"\" + MediaType.APPLICATION_JSON\n            + \"\\\" (parsed\u003d\\\"\" + parsed + \"\\\")\");\n      }\n    }\n    return (Map\u003c?, ?\u003e)JSON.parse(new InputStreamReader(in));\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
          "extendedDetails": {
            "oldValue": "[in-InputStream(modifiers-final)]",
            "newValue": "[c-HttpURLConnection(modifiers-final), useErrorStream-boolean(modifiers-final)]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-3516. Check content-type in WebHdfsFileSystem.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1353800 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "25/06/12 6:58 PM",
          "commitName": "361ea9a62cb85e6d60682c4a73e874d305625d8b",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "12/06/12 2:52 PM",
          "commitNameOld": "4d4661802e8109c264a5fce27cbad091fb91697a",
          "commitAuthorOld": "Alejandro Abdelnur",
          "daysBetweenCommits": 13.17,
          "commitsBetweenForRepo": 41,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,6 +1,20 @@\n-  static Map\u003c?, ?\u003e jsonParse(final InputStream in) throws IOException {\n+  static Map\u003c?, ?\u003e jsonParse(final HttpURLConnection c, final boolean useErrorStream\n+      ) throws IOException {\n+    if (c.getContentLength() \u003d\u003d 0) {\n+      return null;\n+    }\n+    final InputStream in \u003d useErrorStream? c.getErrorStream(): c.getInputStream();\n     if (in \u003d\u003d null) {\n-      throw new IOException(\"The input stream is null.\");\n+      throw new IOException(\"The \" + (useErrorStream? \"error\": \"input\") + \" stream is null.\");\n+    }\n+    final String contentType \u003d c.getContentType();\n+    if (contentType !\u003d null) {\n+      final MediaType parsed \u003d MediaType.valueOf(contentType);\n+      if (!MediaType.APPLICATION_JSON_TYPE.isCompatible(parsed)) {\n+        throw new IOException(\"Content-Type \\\"\" + contentType\n+            + \"\\\" is incompatible with \\\"\" + MediaType.APPLICATION_JSON\n+            + \"\\\" (parsed\u003d\\\"\" + parsed + \"\\\")\");\n+      }\n     }\n     return (Map\u003c?, ?\u003e)JSON.parse(new InputStreamReader(in));\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static Map\u003c?, ?\u003e jsonParse(final HttpURLConnection c, final boolean useErrorStream\n      ) throws IOException {\n    if (c.getContentLength() \u003d\u003d 0) {\n      return null;\n    }\n    final InputStream in \u003d useErrorStream? c.getErrorStream(): c.getInputStream();\n    if (in \u003d\u003d null) {\n      throw new IOException(\"The \" + (useErrorStream? \"error\": \"input\") + \" stream is null.\");\n    }\n    final String contentType \u003d c.getContentType();\n    if (contentType !\u003d null) {\n      final MediaType parsed \u003d MediaType.valueOf(contentType);\n      if (!MediaType.APPLICATION_JSON_TYPE.isCompatible(parsed)) {\n        throw new IOException(\"Content-Type \\\"\" + contentType\n            + \"\\\" is incompatible with \\\"\" + MediaType.APPLICATION_JSON\n            + \"\\\" (parsed\u003d\\\"\" + parsed + \"\\\")\");\n      }\n    }\n    return (Map\u003c?, ?\u003e)JSON.parse(new InputStreamReader(in));\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
          "extendedDetails": {}
        }
      ]
    },
    "09a156fcce2bc1be4081717bf7ef7d290e80d818": {
      "type": "Ymodifierchange",
      "commitMessage": "HDFS-2539. Support doAs and GETHOMEDIRECTORY in webhdfs.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1200731 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/11/11 8:19 PM",
      "commitName": "09a156fcce2bc1be4081717bf7ef7d290e80d818",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "08/11/11 11:25 AM",
      "commitNameOld": "94c631af1fc49f5ae5881fcd5f0e80b17308d15d",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 2.37,
      "commitsBetweenForRepo": 6,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,6 +1,6 @@\n-  private static Map\u003c?, ?\u003e jsonParse(final InputStream in) throws IOException {\n+  static Map\u003c?, ?\u003e jsonParse(final InputStream in) throws IOException {\n     if (in \u003d\u003d null) {\n       throw new IOException(\"The input stream is null.\");\n     }\n     return (Map\u003c?, ?\u003e)JSON.parse(new InputStreamReader(in));\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static Map\u003c?, ?\u003e jsonParse(final InputStream in) throws IOException {\n    if (in \u003d\u003d null) {\n      throw new IOException(\"The input stream is null.\");\n    }\n    return (Map\u003c?, ?\u003e)JSON.parse(new InputStreamReader(in));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
      "extendedDetails": {
        "oldValue": "[private, static]",
        "newValue": "[static]"
      }
    },
    "8cb0d4b380e0fd4437310c1dd6ef8b8995cc383d": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-2432. Webhdfs: response FORBIDDEN when setReplication on non-files; clear umask before creating a flie; throw IllegalArgumentException if setOwner with both owner and group empty; throw FileNotFoundException if getFileStatus on non-existing files; fix bugs in getBlockLocations; and changed getFileChecksum json response root to \"FileChecksum\".\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1190077 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/10/11 4:13 PM",
      "commitName": "8cb0d4b380e0fd4437310c1dd6ef8b8995cc383d",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-2432. Webhdfs: response FORBIDDEN when setReplication on non-files; clear umask before creating a flie; throw IllegalArgumentException if setOwner with both owner and group empty; throw FileNotFoundException if getFileStatus on non-existing files; fix bugs in getBlockLocations; and changed getFileChecksum json response root to \"FileChecksum\".\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1190077 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "27/10/11 4:13 PM",
          "commitName": "8cb0d4b380e0fd4437310c1dd6ef8b8995cc383d",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "25/10/11 10:16 PM",
          "commitNameOld": "8335995630e2c4288795fa0dfa9b670090a6790b",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 1.75,
          "commitsBetweenForRepo": 30,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,6 +1,6 @@\n-  private static \u003cT\u003e T jsonParse(final InputStream in) throws IOException {\n+  private static Map\u003c?, ?\u003e jsonParse(final InputStream in) throws IOException {\n     if (in \u003d\u003d null) {\n       throw new IOException(\"The input stream is null.\");\n     }\n-    return (T)JSON.parse(new InputStreamReader(in));\n+    return (Map\u003c?, ?\u003e)JSON.parse(new InputStreamReader(in));\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private static Map\u003c?, ?\u003e jsonParse(final InputStream in) throws IOException {\n    if (in \u003d\u003d null) {\n      throw new IOException(\"The input stream is null.\");\n    }\n    return (Map\u003c?, ?\u003e)JSON.parse(new InputStreamReader(in));\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
          "extendedDetails": {
            "oldValue": "T",
            "newValue": "Map\u003c?,?\u003e"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-2432. Webhdfs: response FORBIDDEN when setReplication on non-files; clear umask before creating a flie; throw IllegalArgumentException if setOwner with both owner and group empty; throw FileNotFoundException if getFileStatus on non-existing files; fix bugs in getBlockLocations; and changed getFileChecksum json response root to \"FileChecksum\".\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1190077 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "27/10/11 4:13 PM",
          "commitName": "8cb0d4b380e0fd4437310c1dd6ef8b8995cc383d",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "25/10/11 10:16 PM",
          "commitNameOld": "8335995630e2c4288795fa0dfa9b670090a6790b",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 1.75,
          "commitsBetweenForRepo": 30,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,6 +1,6 @@\n-  private static \u003cT\u003e T jsonParse(final InputStream in) throws IOException {\n+  private static Map\u003c?, ?\u003e jsonParse(final InputStream in) throws IOException {\n     if (in \u003d\u003d null) {\n       throw new IOException(\"The input stream is null.\");\n     }\n-    return (T)JSON.parse(new InputStreamReader(in));\n+    return (Map\u003c?, ?\u003e)JSON.parse(new InputStreamReader(in));\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private static Map\u003c?, ?\u003e jsonParse(final InputStream in) throws IOException {\n    if (in \u003d\u003d null) {\n      throw new IOException(\"The input stream is null.\");\n    }\n    return (Map\u003c?, ?\u003e)JSON.parse(new InputStreamReader(in));\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
          "extendedDetails": {}
        }
      ]
    },
    "6c3b59505b863f03629da52a1e9b886fe9b496d0": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-2317. Support read access to HDFS in webhdfs.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1170085 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/09/11 1:34 AM",
      "commitName": "6c3b59505b863f03629da52a1e9b886fe9b496d0",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-2317. Support read access to HDFS in webhdfs.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1170085 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "13/09/11 1:34 AM",
          "commitName": "6c3b59505b863f03629da52a1e9b886fe9b496d0",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "10/09/11 6:41 PM",
          "commitNameOld": "61d0b7530c8978c095ab6f62d9d38e168bd829c6",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 2.29,
          "commitsBetweenForRepo": 14,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,7 +1,6 @@\n-  private static Map\u003cString, Object\u003e jsonParse(final InputStream in\n-      ) throws IOException {\n+  private static \u003cT\u003e T jsonParse(final InputStream in) throws IOException {\n     if (in \u003d\u003d null) {\n       throw new IOException(\"The input stream is null.\");\n     }\n-    return (Map\u003cString, Object\u003e)JSON.parse(new InputStreamReader(in));\n+    return (T)JSON.parse(new InputStreamReader(in));\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private static \u003cT\u003e T jsonParse(final InputStream in) throws IOException {\n    if (in \u003d\u003d null) {\n      throw new IOException(\"The input stream is null.\");\n    }\n    return (T)JSON.parse(new InputStreamReader(in));\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
          "extendedDetails": {
            "oldValue": "Map\u003cString,Object\u003e",
            "newValue": "T"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-2317. Support read access to HDFS in webhdfs.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1170085 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "13/09/11 1:34 AM",
          "commitName": "6c3b59505b863f03629da52a1e9b886fe9b496d0",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "10/09/11 6:41 PM",
          "commitNameOld": "61d0b7530c8978c095ab6f62d9d38e168bd829c6",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 2.29,
          "commitsBetweenForRepo": 14,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,7 +1,6 @@\n-  private static Map\u003cString, Object\u003e jsonParse(final InputStream in\n-      ) throws IOException {\n+  private static \u003cT\u003e T jsonParse(final InputStream in) throws IOException {\n     if (in \u003d\u003d null) {\n       throw new IOException(\"The input stream is null.\");\n     }\n-    return (Map\u003cString, Object\u003e)JSON.parse(new InputStreamReader(in));\n+    return (T)JSON.parse(new InputStreamReader(in));\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private static \u003cT\u003e T jsonParse(final InputStream in) throws IOException {\n    if (in \u003d\u003d null) {\n      throw new IOException(\"The input stream is null.\");\n    }\n    return (T)JSON.parse(new InputStreamReader(in));\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
          "extendedDetails": {}
        }
      ]
    },
    "61d0b7530c8978c095ab6f62d9d38e168bd829c6": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-2284. Add a new FileSystem, webhdfs://, for supporting write Http access to HDFS.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1167662 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/09/11 6:41 PM",
      "commitName": "61d0b7530c8978c095ab6f62d9d38e168bd829c6",
      "commitAuthor": "Tsz-wo Sze",
      "diff": "@@ -0,0 +1,7 @@\n+  private static Map\u003cString, Object\u003e jsonParse(final InputStream in\n+      ) throws IOException {\n+    if (in \u003d\u003d null) {\n+      throw new IOException(\"The input stream is null.\");\n+    }\n+    return (Map\u003cString, Object\u003e)JSON.parse(new InputStreamReader(in));\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private static Map\u003cString, Object\u003e jsonParse(final InputStream in\n      ) throws IOException {\n    if (in \u003d\u003d null) {\n      throw new IOException(\"The input stream is null.\");\n    }\n    return (Map\u003cString, Object\u003e)JSON.parse(new InputStreamReader(in));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java"
    }
  }
}