{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "INodeFile.java",
  "functionName": "getPreferredBlockReplication",
  "functionId": "getPreferredBlockReplication",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
  "functionStartLine": 528,
  "functionEndLine": 547,
  "numCommitsSeen": 282,
  "timeTaken": 11626,
  "changeHistory": [
    "cb672a45a0bbd8950b9b5e304c2e03f516945903",
    "e8bdad7385ab63a122c1e8e8a6a73e0f1100e80b",
    "33a38a534110de454662256545a7f4c075d328c8",
    "3749152b661d0359b3b941ab1d17177230f3b8dc",
    "51e6c1cc3f66f9908d2e816e7291ac34bee43f52",
    "cfd8076f81930c3ffea8ec2ef42926217b83ab1a",
    "5d5614f847b2ef2a5b70bd9a06edc4eba06174c6",
    "c09dc258a8f64fab852bf6f26187163480dbee3c",
    "745d04be59accf80feda0ad38efcc74ba362f2ca",
    "57a84c0d149b693c913416975cafe6de4e23c321",
    "6d5da9484185ca9f585195d6da069b9cd5be4044",
    "70cff9e2f0c8f78c1dc54a064182971bb2106795",
    "4c87a27ad851ffaa3cc3e2074a9ef7073b5a164a",
    "8df119da214babde03e73243c7ca4cfe6d0ca562",
    "fac3883188d9c4f1fe188d98f88cb3c83b243bbd",
    "4f7d921324c7fa9623c34688e3f2aa57fbfcb8b3",
    "d66f9e8269424f588180f2659c8cf132a2a7dfc9",
    "9a0651b4b86727910ae29d055aac6a23490b5ed3",
    "ad06a087131d69d173d8e03dce5c97650a530f2e",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "cb672a45a0bbd8950b9b5e304c2e03f516945903": "Ybodychange",
    "e8bdad7385ab63a122c1e8e8a6a73e0f1100e80b": "Ybodychange",
    "33a38a534110de454662256545a7f4c075d328c8": "Ybodychange",
    "3749152b661d0359b3b941ab1d17177230f3b8dc": "Ybodychange",
    "51e6c1cc3f66f9908d2e816e7291ac34bee43f52": "Ybodychange",
    "cfd8076f81930c3ffea8ec2ef42926217b83ab1a": "Ybodychange",
    "5d5614f847b2ef2a5b70bd9a06edc4eba06174c6": "Ybodychange",
    "c09dc258a8f64fab852bf6f26187163480dbee3c": "Ybodychange",
    "745d04be59accf80feda0ad38efcc74ba362f2ca": "Ybodychange",
    "57a84c0d149b693c913416975cafe6de4e23c321": "Ybodychange",
    "6d5da9484185ca9f585195d6da069b9cd5be4044": "Yrename",
    "70cff9e2f0c8f78c1dc54a064182971bb2106795": "Ybodychange",
    "4c87a27ad851ffaa3cc3e2074a9ef7073b5a164a": "Ybodychange",
    "8df119da214babde03e73243c7ca4cfe6d0ca562": "Ymultichange(Ymodifierchange,Ybodychange)",
    "fac3883188d9c4f1fe188d98f88cb3c83b243bbd": "Ymultichange(Ymodifierchange,Ybodychange)",
    "4f7d921324c7fa9623c34688e3f2aa57fbfcb8b3": "Ybodychange",
    "d66f9e8269424f588180f2659c8cf132a2a7dfc9": "Ybodychange",
    "9a0651b4b86727910ae29d055aac6a23490b5ed3": "Ybodychange",
    "ad06a087131d69d173d8e03dce5c97650a530f2e": "Yrename",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "cb672a45a0bbd8950b9b5e304c2e03f516945903": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11605. Allow user to customize new erasure code policies. Contributed by Huafeng Wang\n",
      "commitDate": "27/04/17 10:18 PM",
      "commitName": "cb672a45a0bbd8950b9b5e304c2e03f516945903",
      "commitAuthor": "Kai Zheng",
      "commitDateOld": "07/04/17 4:46 PM",
      "commitNameOld": "e8bdad7385ab63a122c1e8e8a6a73e0f1100e80b",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 20.23,
      "commitsBetweenForRepo": 103,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,20 @@\n   public short getPreferredBlockReplication() {\n     short max \u003d getFileReplication(CURRENT_STATE_ID);\n     FileWithSnapshotFeature sf \u003d this.getFileWithSnapshotFeature();\n     if (sf !\u003d null) {\n       short maxInSnapshot \u003d sf.getMaxBlockRepInDiffs(null);\n       if (sf.isCurrentFileDeleted()) {\n         return maxInSnapshot;\n       }\n       max \u003d maxInSnapshot \u003e max ? maxInSnapshot : max;\n     }\n     if(!isStriped()){\n       return max;\n     }\n \n-    ErasureCodingPolicy ecPolicy \u003d\n-        SystemErasureCodingPolicies.getByID(getErasureCodingPolicyID());\n+    ErasureCodingPolicy ecPolicy \u003d ErasureCodingPolicyManager.getInstance()\n+        .getByID(getErasureCodingPolicyID());\n     Preconditions.checkNotNull(ecPolicy, \"Could not find EC policy with ID 0x\"\n         + StringUtils.byteToHexString(getErasureCodingPolicyID()));\n     return (short) (ecPolicy.getNumDataUnits() + ecPolicy.getNumParityUnits());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public short getPreferredBlockReplication() {\n    short max \u003d getFileReplication(CURRENT_STATE_ID);\n    FileWithSnapshotFeature sf \u003d this.getFileWithSnapshotFeature();\n    if (sf !\u003d null) {\n      short maxInSnapshot \u003d sf.getMaxBlockRepInDiffs(null);\n      if (sf.isCurrentFileDeleted()) {\n        return maxInSnapshot;\n      }\n      max \u003d maxInSnapshot \u003e max ? maxInSnapshot : max;\n    }\n    if(!isStriped()){\n      return max;\n    }\n\n    ErasureCodingPolicy ecPolicy \u003d ErasureCodingPolicyManager.getInstance()\n        .getByID(getErasureCodingPolicyID());\n    Preconditions.checkNotNull(ecPolicy, \"Could not find EC policy with ID 0x\"\n        + StringUtils.byteToHexString(getErasureCodingPolicyID()));\n    return (short) (ecPolicy.getNumDataUnits() + ecPolicy.getNumParityUnits());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
      "extendedDetails": {}
    },
    "e8bdad7385ab63a122c1e8e8a6a73e0f1100e80b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11623. Move system erasure coding policies into hadoop-hdfs-client.\n",
      "commitDate": "07/04/17 4:46 PM",
      "commitName": "e8bdad7385ab63a122c1e8e8a6a73e0f1100e80b",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "30/03/17 3:44 PM",
      "commitNameOld": "e5f0622a6f40706d360d45200c8f259c79046438",
      "commitAuthorOld": "Mingliang Liu",
      "daysBetweenCommits": 8.04,
      "commitsBetweenForRepo": 52,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,20 @@\n   public short getPreferredBlockReplication() {\n     short max \u003d getFileReplication(CURRENT_STATE_ID);\n     FileWithSnapshotFeature sf \u003d this.getFileWithSnapshotFeature();\n     if (sf !\u003d null) {\n       short maxInSnapshot \u003d sf.getMaxBlockRepInDiffs(null);\n       if (sf.isCurrentFileDeleted()) {\n         return maxInSnapshot;\n       }\n       max \u003d maxInSnapshot \u003e max ? maxInSnapshot : max;\n     }\n     if(!isStriped()){\n       return max;\n     }\n \n     ErasureCodingPolicy ecPolicy \u003d\n-        ErasureCodingPolicyManager.getPolicyByID(\n-            getErasureCodingPolicyID());\n+        SystemErasureCodingPolicies.getByID(getErasureCodingPolicyID());\n     Preconditions.checkNotNull(ecPolicy, \"Could not find EC policy with ID 0x\"\n         + StringUtils.byteToHexString(getErasureCodingPolicyID()));\n     return (short) (ecPolicy.getNumDataUnits() + ecPolicy.getNumParityUnits());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public short getPreferredBlockReplication() {\n    short max \u003d getFileReplication(CURRENT_STATE_ID);\n    FileWithSnapshotFeature sf \u003d this.getFileWithSnapshotFeature();\n    if (sf !\u003d null) {\n      short maxInSnapshot \u003d sf.getMaxBlockRepInDiffs(null);\n      if (sf.isCurrentFileDeleted()) {\n        return maxInSnapshot;\n      }\n      max \u003d maxInSnapshot \u003e max ? maxInSnapshot : max;\n    }\n    if(!isStriped()){\n      return max;\n    }\n\n    ErasureCodingPolicy ecPolicy \u003d\n        SystemErasureCodingPolicies.getByID(getErasureCodingPolicyID());\n    Preconditions.checkNotNull(ecPolicy, \"Could not find EC policy with ID 0x\"\n        + StringUtils.byteToHexString(getErasureCodingPolicyID()));\n    return (short) (ecPolicy.getNumDataUnits() + ecPolicy.getNumParityUnits());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
      "extendedDetails": {}
    },
    "33a38a534110de454662256545a7f4c075d328c8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11314. Enforce set of enabled EC policies on the NameNode.\n",
      "commitDate": "08/03/17 4:41 PM",
      "commitName": "33a38a534110de454662256545a7f4c075d328c8",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "02/03/17 7:58 PM",
      "commitNameOld": "3749152b661d0359b3b941ab1d17177230f3b8dc",
      "commitAuthorOld": "Rakesh Radhakrishnan",
      "daysBetweenCommits": 5.86,
      "commitsBetweenForRepo": 44,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,21 @@\n   public short getPreferredBlockReplication() {\n     short max \u003d getFileReplication(CURRENT_STATE_ID);\n     FileWithSnapshotFeature sf \u003d this.getFileWithSnapshotFeature();\n     if (sf !\u003d null) {\n       short maxInSnapshot \u003d sf.getMaxBlockRepInDiffs(null);\n       if (sf.isCurrentFileDeleted()) {\n         return maxInSnapshot;\n       }\n       max \u003d maxInSnapshot \u003e max ? maxInSnapshot : max;\n     }\n     if(!isStriped()){\n       return max;\n     }\n \n     ErasureCodingPolicy ecPolicy \u003d\n-        ErasureCodingPolicyManager.getPolicyByPolicyID(\n+        ErasureCodingPolicyManager.getPolicyByID(\n             getErasureCodingPolicyID());\n     Preconditions.checkNotNull(ecPolicy, \"Could not find EC policy with ID 0x\"\n         + StringUtils.byteToHexString(getErasureCodingPolicyID()));\n     return (short) (ecPolicy.getNumDataUnits() + ecPolicy.getNumParityUnits());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public short getPreferredBlockReplication() {\n    short max \u003d getFileReplication(CURRENT_STATE_ID);\n    FileWithSnapshotFeature sf \u003d this.getFileWithSnapshotFeature();\n    if (sf !\u003d null) {\n      short maxInSnapshot \u003d sf.getMaxBlockRepInDiffs(null);\n      if (sf.isCurrentFileDeleted()) {\n        return maxInSnapshot;\n      }\n      max \u003d maxInSnapshot \u003e max ? maxInSnapshot : max;\n    }\n    if(!isStriped()){\n      return max;\n    }\n\n    ErasureCodingPolicy ecPolicy \u003d\n        ErasureCodingPolicyManager.getPolicyByID(\n            getErasureCodingPolicyID());\n    Preconditions.checkNotNull(ecPolicy, \"Could not find EC policy with ID 0x\"\n        + StringUtils.byteToHexString(getErasureCodingPolicyID()));\n    return (short) (ecPolicy.getNumDataUnits() + ecPolicy.getNumParityUnits());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
      "extendedDetails": {}
    },
    "3749152b661d0359b3b941ab1d17177230f3b8dc": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11416. Refactor out system default erasure coding policy. Contributed by Andrew Wang.\n",
      "commitDate": "02/03/17 7:58 PM",
      "commitName": "3749152b661d0359b3b941ab1d17177230f3b8dc",
      "commitAuthor": "Rakesh Radhakrishnan",
      "commitDateOld": "27/02/17 5:07 PM",
      "commitNameOld": "55c07bbed2f475f7b584a86112ee1b6fe0221e98",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 3.12,
      "commitsBetweenForRepo": 24,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,21 @@\n   public short getPreferredBlockReplication() {\n     short max \u003d getFileReplication(CURRENT_STATE_ID);\n     FileWithSnapshotFeature sf \u003d this.getFileWithSnapshotFeature();\n     if (sf !\u003d null) {\n       short maxInSnapshot \u003d sf.getMaxBlockRepInDiffs(null);\n       if (sf.isCurrentFileDeleted()) {\n         return maxInSnapshot;\n       }\n       max \u003d maxInSnapshot \u003e max ? maxInSnapshot : max;\n     }\n     if(!isStriped()){\n       return max;\n     }\n \n     ErasureCodingPolicy ecPolicy \u003d\n         ErasureCodingPolicyManager.getPolicyByPolicyID(\n             getErasureCodingPolicyID());\n-    if (ecPolicy \u003d\u003d null){\n-      ecPolicy \u003d ErasureCodingPolicyManager.getSystemDefaultPolicy();\n-    }\n+    Preconditions.checkNotNull(ecPolicy, \"Could not find EC policy with ID 0x\"\n+        + StringUtils.byteToHexString(getErasureCodingPolicyID()));\n     return (short) (ecPolicy.getNumDataUnits() + ecPolicy.getNumParityUnits());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public short getPreferredBlockReplication() {\n    short max \u003d getFileReplication(CURRENT_STATE_ID);\n    FileWithSnapshotFeature sf \u003d this.getFileWithSnapshotFeature();\n    if (sf !\u003d null) {\n      short maxInSnapshot \u003d sf.getMaxBlockRepInDiffs(null);\n      if (sf.isCurrentFileDeleted()) {\n        return maxInSnapshot;\n      }\n      max \u003d maxInSnapshot \u003e max ? maxInSnapshot : max;\n    }\n    if(!isStriped()){\n      return max;\n    }\n\n    ErasureCodingPolicy ecPolicy \u003d\n        ErasureCodingPolicyManager.getPolicyByPolicyID(\n            getErasureCodingPolicyID());\n    Preconditions.checkNotNull(ecPolicy, \"Could not find EC policy with ID 0x\"\n        + StringUtils.byteToHexString(getErasureCodingPolicyID()));\n    return (short) (ecPolicy.getNumDataUnits() + ecPolicy.getNumParityUnits());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
      "extendedDetails": {}
    },
    "51e6c1cc3f66f9908d2e816e7291ac34bee43f52": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10994. Support an XOR policy XOR-2-1-64k in HDFS. Contributed by Sammi Chen\n",
      "commitDate": "29/11/16 11:52 PM",
      "commitName": "51e6c1cc3f66f9908d2e816e7291ac34bee43f52",
      "commitAuthor": "Kai Zheng",
      "commitDateOld": "29/11/16 11:44 PM",
      "commitNameOld": "cfd8076f81930c3ffea8ec2ef42926217b83ab1a",
      "commitAuthorOld": "Kai Zheng",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,18 +1,22 @@\n   public short getPreferredBlockReplication() {\n     short max \u003d getFileReplication(CURRENT_STATE_ID);\n     FileWithSnapshotFeature sf \u003d this.getFileWithSnapshotFeature();\n     if (sf !\u003d null) {\n       short maxInSnapshot \u003d sf.getMaxBlockRepInDiffs(null);\n       if (sf.isCurrentFileDeleted()) {\n         return maxInSnapshot;\n       }\n       max \u003d maxInSnapshot \u003e max ? maxInSnapshot : max;\n     }\n     if(!isStriped()){\n       return max;\n     }\n-    // TODO support more policies based on policyId\n+\n     ErasureCodingPolicy ecPolicy \u003d\n-        ErasureCodingPolicyManager.getSystemDefaultPolicy();\n+        ErasureCodingPolicyManager.getPolicyByPolicyID(\n+            getErasureCodingPolicyID());\n+    if (ecPolicy \u003d\u003d null){\n+      ecPolicy \u003d ErasureCodingPolicyManager.getSystemDefaultPolicy();\n+    }\n     return (short) (ecPolicy.getNumDataUnits() + ecPolicy.getNumParityUnits());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public short getPreferredBlockReplication() {\n    short max \u003d getFileReplication(CURRENT_STATE_ID);\n    FileWithSnapshotFeature sf \u003d this.getFileWithSnapshotFeature();\n    if (sf !\u003d null) {\n      short maxInSnapshot \u003d sf.getMaxBlockRepInDiffs(null);\n      if (sf.isCurrentFileDeleted()) {\n        return maxInSnapshot;\n      }\n      max \u003d maxInSnapshot \u003e max ? maxInSnapshot : max;\n    }\n    if(!isStriped()){\n      return max;\n    }\n\n    ErasureCodingPolicy ecPolicy \u003d\n        ErasureCodingPolicyManager.getPolicyByPolicyID(\n            getErasureCodingPolicyID());\n    if (ecPolicy \u003d\u003d null){\n      ecPolicy \u003d ErasureCodingPolicyManager.getSystemDefaultPolicy();\n    }\n    return (short) (ecPolicy.getNumDataUnits() + ecPolicy.getNumParityUnits());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
      "extendedDetails": {}
    },
    "cfd8076f81930c3ffea8ec2ef42926217b83ab1a": {
      "type": "Ybodychange",
      "commitMessage": "Revert due to an error \"HDFS-10994. Support an XOR policy XOR-2-1-64k in HDFS. Contributed by Sammi Chen\"\n\nThis reverts commit 5614f847b2ef2a5b70bd9a06edc4eba06174c6.\n",
      "commitDate": "29/11/16 11:44 PM",
      "commitName": "cfd8076f81930c3ffea8ec2ef42926217b83ab1a",
      "commitAuthor": "Kai Zheng",
      "commitDateOld": "27/11/16 10:34 PM",
      "commitNameOld": "5d5614f847b2ef2a5b70bd9a06edc4eba06174c6",
      "commitAuthorOld": "Kai Zheng",
      "daysBetweenCommits": 2.05,
      "commitsBetweenForRepo": 17,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,18 @@\n   public short getPreferredBlockReplication() {\n     short max \u003d getFileReplication(CURRENT_STATE_ID);\n     FileWithSnapshotFeature sf \u003d this.getFileWithSnapshotFeature();\n     if (sf !\u003d null) {\n       short maxInSnapshot \u003d sf.getMaxBlockRepInDiffs(null);\n       if (sf.isCurrentFileDeleted()) {\n         return maxInSnapshot;\n       }\n       max \u003d maxInSnapshot \u003e max ? maxInSnapshot : max;\n     }\n     if(!isStriped()){\n       return max;\n     }\n-\n+    // TODO support more policies based on policyId\n     ErasureCodingPolicy ecPolicy \u003d\n-        ErasureCodingPolicyManager.getPolicyByPolicyID(\n-            getErasureCodingPolicyID());\n-    if (ecPolicy \u003d\u003d null){\n-      ecPolicy \u003d ErasureCodingPolicyManager.getSystemDefaultPolicy();\n-    }\n+        ErasureCodingPolicyManager.getSystemDefaultPolicy();\n     return (short) (ecPolicy.getNumDataUnits() + ecPolicy.getNumParityUnits());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public short getPreferredBlockReplication() {\n    short max \u003d getFileReplication(CURRENT_STATE_ID);\n    FileWithSnapshotFeature sf \u003d this.getFileWithSnapshotFeature();\n    if (sf !\u003d null) {\n      short maxInSnapshot \u003d sf.getMaxBlockRepInDiffs(null);\n      if (sf.isCurrentFileDeleted()) {\n        return maxInSnapshot;\n      }\n      max \u003d maxInSnapshot \u003e max ? maxInSnapshot : max;\n    }\n    if(!isStriped()){\n      return max;\n    }\n    // TODO support more policies based on policyId\n    ErasureCodingPolicy ecPolicy \u003d\n        ErasureCodingPolicyManager.getSystemDefaultPolicy();\n    return (short) (ecPolicy.getNumDataUnits() + ecPolicy.getNumParityUnits());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
      "extendedDetails": {}
    },
    "5d5614f847b2ef2a5b70bd9a06edc4eba06174c6": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10994. Support an XOR policy XOR-2-1-64k in HDFS. Contributed by Sammi Chen\n",
      "commitDate": "27/11/16 10:34 PM",
      "commitName": "5d5614f847b2ef2a5b70bd9a06edc4eba06174c6",
      "commitAuthor": "Kai Zheng",
      "commitDateOld": "07/10/16 5:37 PM",
      "commitNameOld": "6a38d118d86b7907009bcec34f1b788d076f1d1c",
      "commitAuthorOld": "Xiao Chen",
      "daysBetweenCommits": 51.25,
      "commitsBetweenForRepo": 413,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,18 +1,22 @@\n   public short getPreferredBlockReplication() {\n     short max \u003d getFileReplication(CURRENT_STATE_ID);\n     FileWithSnapshotFeature sf \u003d this.getFileWithSnapshotFeature();\n     if (sf !\u003d null) {\n       short maxInSnapshot \u003d sf.getMaxBlockRepInDiffs(null);\n       if (sf.isCurrentFileDeleted()) {\n         return maxInSnapshot;\n       }\n       max \u003d maxInSnapshot \u003e max ? maxInSnapshot : max;\n     }\n     if(!isStriped()){\n       return max;\n     }\n-    // TODO support more policies based on policyId\n+\n     ErasureCodingPolicy ecPolicy \u003d\n-        ErasureCodingPolicyManager.getSystemDefaultPolicy();\n+        ErasureCodingPolicyManager.getPolicyByPolicyID(\n+            getErasureCodingPolicyID());\n+    if (ecPolicy \u003d\u003d null){\n+      ecPolicy \u003d ErasureCodingPolicyManager.getSystemDefaultPolicy();\n+    }\n     return (short) (ecPolicy.getNumDataUnits() + ecPolicy.getNumParityUnits());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public short getPreferredBlockReplication() {\n    short max \u003d getFileReplication(CURRENT_STATE_ID);\n    FileWithSnapshotFeature sf \u003d this.getFileWithSnapshotFeature();\n    if (sf !\u003d null) {\n      short maxInSnapshot \u003d sf.getMaxBlockRepInDiffs(null);\n      if (sf.isCurrentFileDeleted()) {\n        return maxInSnapshot;\n      }\n      max \u003d maxInSnapshot \u003e max ? maxInSnapshot : max;\n    }\n    if(!isStriped()){\n      return max;\n    }\n\n    ErasureCodingPolicy ecPolicy \u003d\n        ErasureCodingPolicyManager.getPolicyByPolicyID(\n            getErasureCodingPolicyID());\n    if (ecPolicy \u003d\u003d null){\n      ecPolicy \u003d ErasureCodingPolicyManager.getSystemDefaultPolicy();\n    }\n    return (short) (ecPolicy.getNumDataUnits() + ecPolicy.getNumParityUnits());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
      "extendedDetails": {}
    },
    "c09dc258a8f64fab852bf6f26187163480dbee3c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8882. Erasure Coding: Use datablocks, parityblocks and cell size from ErasureCodingPolicy. Contributed by Vinayakumar B.\n\nChange-Id: Ic56da0b426f47c63dac440aef6f5fc8554f6cf13\n",
      "commitDate": "23/09/15 1:34 PM",
      "commitName": "c09dc258a8f64fab852bf6f26187163480dbee3c",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "22/09/15 1:27 PM",
      "commitNameOld": "1080c3730068177ddd10dc313890ac1f5dc58f1a",
      "commitAuthorOld": "",
      "daysBetweenCommits": 1.0,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,18 @@\n   public short getPreferredBlockReplication() {\n     short max \u003d getFileReplication(CURRENT_STATE_ID);\n     FileWithSnapshotFeature sf \u003d this.getFileWithSnapshotFeature();\n     if (sf !\u003d null) {\n       short maxInSnapshot \u003d sf.getMaxBlockRepInDiffs(null);\n       if (sf.isCurrentFileDeleted()) {\n         return maxInSnapshot;\n       }\n       max \u003d maxInSnapshot \u003e max ? maxInSnapshot : max;\n     }\n-    return isStriped() ?\n-        HdfsConstants.NUM_DATA_BLOCKS + HdfsConstants.NUM_PARITY_BLOCKS : max;\n+    if(!isStriped()){\n+      return max;\n+    }\n+    // TODO support more policies based on policyId\n+    ErasureCodingPolicy ecPolicy \u003d\n+        ErasureCodingPolicyManager.getSystemDefaultPolicy();\n+    return (short) (ecPolicy.getNumDataUnits() + ecPolicy.getNumParityUnits());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public short getPreferredBlockReplication() {\n    short max \u003d getFileReplication(CURRENT_STATE_ID);\n    FileWithSnapshotFeature sf \u003d this.getFileWithSnapshotFeature();\n    if (sf !\u003d null) {\n      short maxInSnapshot \u003d sf.getMaxBlockRepInDiffs(null);\n      if (sf.isCurrentFileDeleted()) {\n        return maxInSnapshot;\n      }\n      max \u003d maxInSnapshot \u003e max ? maxInSnapshot : max;\n    }\n    if(!isStriped()){\n      return max;\n    }\n    // TODO support more policies based on policyId\n    ErasureCodingPolicy ecPolicy \u003d\n        ErasureCodingPolicyManager.getSystemDefaultPolicy();\n    return (short) (ecPolicy.getNumDataUnits() + ecPolicy.getNumParityUnits());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
      "extendedDetails": {}
    },
    "745d04be59accf80feda0ad38efcc74ba362f2ca": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8823. Move replication factor into individual blocks. Contributed by Haohui Mai.\n",
      "commitDate": "22/08/15 12:09 AM",
      "commitName": "745d04be59accf80feda0ad38efcc74ba362f2ca",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "19/08/15 3:11 PM",
      "commitNameOld": "4e14f7982a6e57bf08deb3b266806c2b779a157d",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 2.37,
      "commitsBetweenForRepo": 15,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,12 @@\n   public short getPreferredBlockReplication() {\n     short max \u003d getFileReplication(CURRENT_STATE_ID);\n     FileWithSnapshotFeature sf \u003d this.getFileWithSnapshotFeature();\n     if (sf !\u003d null) {\n-      short maxInSnapshot \u003d sf.getMaxBlockRepInDiffs();\n+      short maxInSnapshot \u003d sf.getMaxBlockRepInDiffs(null);\n       if (sf.isCurrentFileDeleted()) {\n         return maxInSnapshot;\n       }\n       max \u003d maxInSnapshot \u003e max ? maxInSnapshot : max;\n     }\n     return max;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public short getPreferredBlockReplication() {\n    short max \u003d getFileReplication(CURRENT_STATE_ID);\n    FileWithSnapshotFeature sf \u003d this.getFileWithSnapshotFeature();\n    if (sf !\u003d null) {\n      short maxInSnapshot \u003d sf.getMaxBlockRepInDiffs(null);\n      if (sf.isCurrentFileDeleted()) {\n        return maxInSnapshot;\n      }\n      max \u003d maxInSnapshot \u003e max ? maxInSnapshot : max;\n    }\n    return max;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
      "extendedDetails": {}
    },
    "57a84c0d149b693c913416975cafe6de4e23c321": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7369. Erasure coding: distribute recovery work for striped blocks to DataNode. Contributed by Zhe Zhang.\n",
      "commitDate": "26/05/15 11:43 AM",
      "commitName": "57a84c0d149b693c913416975cafe6de4e23c321",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "26/05/15 11:41 AM",
      "commitNameOld": "a38a37c63417a3b19dcdf98251af196c9d7b8c31",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,13 @@\n   public short getPreferredBlockReplication() {\n     short max \u003d getFileReplication(CURRENT_STATE_ID);\n     FileWithSnapshotFeature sf \u003d this.getFileWithSnapshotFeature();\n     if (sf !\u003d null) {\n       short maxInSnapshot \u003d sf.getMaxBlockRepInDiffs();\n       if (sf.isCurrentFileDeleted()) {\n         return maxInSnapshot;\n       }\n       max \u003d maxInSnapshot \u003e max ? maxInSnapshot : max;\n     }\n-    return max;\n+    return isStriped()?\n+        HdfsConstants.NUM_DATA_BLOCKS + HdfsConstants.NUM_PARITY_BLOCKS : max;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public short getPreferredBlockReplication() {\n    short max \u003d getFileReplication(CURRENT_STATE_ID);\n    FileWithSnapshotFeature sf \u003d this.getFileWithSnapshotFeature();\n    if (sf !\u003d null) {\n      short maxInSnapshot \u003d sf.getMaxBlockRepInDiffs();\n      if (sf.isCurrentFileDeleted()) {\n        return maxInSnapshot;\n      }\n      max \u003d maxInSnapshot \u003e max ? maxInSnapshot : max;\n    }\n    return isStriped()?\n        HdfsConstants.NUM_DATA_BLOCKS + HdfsConstants.NUM_PARITY_BLOCKS : max;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
      "extendedDetails": {}
    },
    "6d5da9484185ca9f585195d6da069b9cd5be4044": {
      "type": "Yrename",
      "commitMessage": "HDFS-8255. Rename getBlockReplication to getPreferredBlockReplication. (Contributed by Zhe Zhang)\n",
      "commitDate": "12/05/15 6:29 AM",
      "commitName": "6d5da9484185ca9f585195d6da069b9cd5be4044",
      "commitAuthor": "yliu",
      "commitDateOld": "09/05/15 10:51 PM",
      "commitNameOld": "4536399d47f6c061e149e2504600804a0f1e093d",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 2.32,
      "commitsBetweenForRepo": 19,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,12 @@\n-  public short getBlockReplication() {\n+  public short getPreferredBlockReplication() {\n     short max \u003d getFileReplication(CURRENT_STATE_ID);\n     FileWithSnapshotFeature sf \u003d this.getFileWithSnapshotFeature();\n     if (sf !\u003d null) {\n       short maxInSnapshot \u003d sf.getMaxBlockRepInDiffs();\n       if (sf.isCurrentFileDeleted()) {\n         return maxInSnapshot;\n       }\n       max \u003d maxInSnapshot \u003e max ? maxInSnapshot : max;\n     }\n     return max;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public short getPreferredBlockReplication() {\n    short max \u003d getFileReplication(CURRENT_STATE_ID);\n    FileWithSnapshotFeature sf \u003d this.getFileWithSnapshotFeature();\n    if (sf !\u003d null) {\n      short maxInSnapshot \u003d sf.getMaxBlockRepInDiffs();\n      if (sf.isCurrentFileDeleted()) {\n        return maxInSnapshot;\n      }\n      max \u003d maxInSnapshot \u003e max ? maxInSnapshot : max;\n    }\n    return max;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
      "extendedDetails": {
        "oldValue": "getBlockReplication",
        "newValue": "getPreferredBlockReplication"
      }
    },
    "70cff9e2f0c8f78c1dc54a064182971bb2106795": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5715. Use Snapshot ID to indicate the corresponding Snapshot for a FileDiff/DirectoryDiff. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1556353 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/01/14 12:52 PM",
      "commitName": "70cff9e2f0c8f78c1dc54a064182971bb2106795",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "14/12/13 2:13 AM",
      "commitNameOld": "44a6560b5da3f79d2299579a36e7a2a60a91f823",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 24.44,
      "commitsBetweenForRepo": 98,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,12 @@\n   public short getBlockReplication() {\n-    short max \u003d getFileReplication(null);\n+    short max \u003d getFileReplication(CURRENT_STATE_ID);\n     FileWithSnapshotFeature sf \u003d this.getFileWithSnapshotFeature();\n     if (sf !\u003d null) {\n       short maxInSnapshot \u003d sf.getMaxBlockRepInDiffs();\n       if (sf.isCurrentFileDeleted()) {\n         return maxInSnapshot;\n       }\n       max \u003d maxInSnapshot \u003e max ? maxInSnapshot : max;\n     }\n     return max;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public short getBlockReplication() {\n    short max \u003d getFileReplication(CURRENT_STATE_ID);\n    FileWithSnapshotFeature sf \u003d this.getFileWithSnapshotFeature();\n    if (sf !\u003d null) {\n      short maxInSnapshot \u003d sf.getMaxBlockRepInDiffs();\n      if (sf.isCurrentFileDeleted()) {\n        return maxInSnapshot;\n      }\n      max \u003d maxInSnapshot \u003e max ? maxInSnapshot : max;\n    }\n    return max;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
      "extendedDetails": {}
    },
    "4c87a27ad851ffaa3cc3e2074a9ef7073b5a164a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5554. Flatten INodeFile hierarchy: Replace INodeFileWithSnapshot with FileWithSnapshotFeature.  Contributed by jing9\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1548796 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "06/12/13 10:17 PM",
      "commitName": "4c87a27ad851ffaa3cc3e2074a9ef7073b5a164a",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "27/11/13 12:32 PM",
      "commitNameOld": "8df119da214babde03e73243c7ca4cfe6d0ca562",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 9.41,
      "commitsBetweenForRepo": 53,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,3 +1,12 @@\n   public short getBlockReplication() {\n-    return getFileReplication(null);\n+    short max \u003d getFileReplication(null);\n+    FileWithSnapshotFeature sf \u003d this.getFileWithSnapshotFeature();\n+    if (sf !\u003d null) {\n+      short maxInSnapshot \u003d sf.getMaxBlockRepInDiffs();\n+      if (sf.isCurrentFileDeleted()) {\n+        return maxInSnapshot;\n+      }\n+      max \u003d maxInSnapshot \u003e max ? maxInSnapshot : max;\n+    }\n+    return max;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public short getBlockReplication() {\n    short max \u003d getFileReplication(null);\n    FileWithSnapshotFeature sf \u003d this.getFileWithSnapshotFeature();\n    if (sf !\u003d null) {\n      short maxInSnapshot \u003d sf.getMaxBlockRepInDiffs();\n      if (sf.isCurrentFileDeleted()) {\n        return maxInSnapshot;\n      }\n      max \u003d maxInSnapshot \u003e max ? maxInSnapshot : max;\n    }\n    return max;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
      "extendedDetails": {}
    },
    "8df119da214babde03e73243c7ca4cfe6d0ca562": {
      "type": "Ymultichange(Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-5537. Remove FileWithSnapshot interface.  Contributed by jing9\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1546184 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/11/13 12:32 PM",
      "commitName": "8df119da214babde03e73243c7ca4cfe6d0ca562",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-5537. Remove FileWithSnapshot interface.  Contributed by jing9\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1546184 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "27/11/13 12:32 PM",
          "commitName": "8df119da214babde03e73243c7ca4cfe6d0ca562",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "26/11/13 10:33 AM",
          "commitNameOld": "82ff2d3f2e569879500d851f4d67dfa2d02b5c9b",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 1.08,
          "commitsBetweenForRepo": 6,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,5 +1,3 @@\n-  public final short getBlockReplication() {\n-    return this instanceof FileWithSnapshot?\n-        Util.getBlockReplication((FileWithSnapshot)this)\n-        : getFileReplication(null);\n+  public short getBlockReplication() {\n+    return getFileReplication(null);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public short getBlockReplication() {\n    return getFileReplication(null);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
          "extendedDetails": {
            "oldValue": "[public, final]",
            "newValue": "[public]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5537. Remove FileWithSnapshot interface.  Contributed by jing9\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1546184 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "27/11/13 12:32 PM",
          "commitName": "8df119da214babde03e73243c7ca4cfe6d0ca562",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "26/11/13 10:33 AM",
          "commitNameOld": "82ff2d3f2e569879500d851f4d67dfa2d02b5c9b",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 1.08,
          "commitsBetweenForRepo": 6,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,5 +1,3 @@\n-  public final short getBlockReplication() {\n-    return this instanceof FileWithSnapshot?\n-        Util.getBlockReplication((FileWithSnapshot)this)\n-        : getFileReplication(null);\n+  public short getBlockReplication() {\n+    return getFileReplication(null);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public short getBlockReplication() {\n    return getFileReplication(null);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
          "extendedDetails": {}
        }
      ]
    },
    "fac3883188d9c4f1fe188d98f88cb3c83b243bbd": {
      "type": "Ymultichange(Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-4503. Update computeContentSummary(..), spaceConsumedInTree(..) and diskspaceConsumed(..) in INode for snapshot.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2802@1448373 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/02/13 12:02 PM",
      "commitName": "fac3883188d9c4f1fe188d98f88cb3c83b243bbd",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-4503. Update computeContentSummary(..), spaceConsumedInTree(..) and diskspaceConsumed(..) in INode for snapshot.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2802@1448373 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "20/02/13 12:02 PM",
          "commitName": "fac3883188d9c4f1fe188d98f88cb3c83b243bbd",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "14/02/13 2:00 PM",
          "commitNameOld": "d42d0860cb670c8284bb298029cd6f8f59db9510",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 5.92,
          "commitsBetweenForRepo": 4,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,3 +1,5 @@\n-  public short getBlockReplication() {\n-    return getFileReplication(null);\n+  public final short getBlockReplication() {\n+    return this instanceof FileWithSnapshot?\n+        Util.getBlockReplication((FileWithSnapshot)this)\n+        : getFileReplication(null);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public final short getBlockReplication() {\n    return this instanceof FileWithSnapshot?\n        Util.getBlockReplication((FileWithSnapshot)this)\n        : getFileReplication(null);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
          "extendedDetails": {
            "oldValue": "[public]",
            "newValue": "[public, final]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-4503. Update computeContentSummary(..), spaceConsumedInTree(..) and diskspaceConsumed(..) in INode for snapshot.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2802@1448373 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "20/02/13 12:02 PM",
          "commitName": "fac3883188d9c4f1fe188d98f88cb3c83b243bbd",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "14/02/13 2:00 PM",
          "commitNameOld": "d42d0860cb670c8284bb298029cd6f8f59db9510",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 5.92,
          "commitsBetweenForRepo": 4,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,3 +1,5 @@\n-  public short getBlockReplication() {\n-    return getFileReplication(null);\n+  public final short getBlockReplication() {\n+    return this instanceof FileWithSnapshot?\n+        Util.getBlockReplication((FileWithSnapshot)this)\n+        : getFileReplication(null);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public final short getBlockReplication() {\n    return this instanceof FileWithSnapshot?\n        Util.getBlockReplication((FileWithSnapshot)this)\n        : getFileReplication(null);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
          "extendedDetails": {}
        }
      ]
    },
    "4f7d921324c7fa9623c34688e3f2aa57fbfcb8b3": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4446. Support file snapshots with diff lists.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2802@1443825 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/02/13 6:18 PM",
      "commitName": "4f7d921324c7fa9623c34688e3f2aa57fbfcb8b3",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "01/02/13 5:53 PM",
      "commitNameOld": "e7db60fbfcc222b32d610ffd912683494674ad2f",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 6.02,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,3 +1,3 @@\n   public short getBlockReplication() {\n-    return getFileReplication();\n+    return getFileReplication(null);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public short getBlockReplication() {\n    return getFileReplication(null);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
      "extendedDetails": {}
    },
    "d66f9e8269424f588180f2659c8cf132a2a7dfc9": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4206. Change the fields in INode and its subclasses to private.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1410996 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/11/12 2:03 PM",
      "commitName": "d66f9e8269424f588180f2659c8cf132a2a7dfc9",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "06/11/12 1:04 PM",
      "commitNameOld": "1734215a10fd93e38849ed0235b5e026b7f50f83",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 12.04,
      "commitsBetweenForRepo": 85,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,3 +1,3 @@\n   public short getBlockReplication() {\n-    return (short) ((header \u0026 HEADERMASK) \u003e\u003e BLOCKBITS);\n+    return HeaderFormat.getReplication(header);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public short getBlockReplication() {\n    return HeaderFormat.getReplication(header);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
      "extendedDetails": {}
    },
    "9a0651b4b86727910ae29d055aac6a23490b5ed3": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4078. Handle replication in snapshots.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2802@1400743 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/10/12 5:11 PM",
      "commitName": "9a0651b4b86727910ae29d055aac6a23490b5ed3",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "19/10/12 12:35 PM",
      "commitNameOld": "5c1a7b9d5d79a1cd69dea4ca038fe74259b29653",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 2.19,
      "commitsBetweenForRepo": 21,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,3 +1,3 @@\n   public short getBlockReplication() {\n-    return (short) ((header \u0026 HEADERMASK) \u003e\u003e BLOCKBITS);\n+    return getFileReplication();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public short getBlockReplication() {\n    return getFileReplication();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
      "extendedDetails": {}
    },
    "ad06a087131d69d173d8e03dce5c97650a530f2e": {
      "type": "Yrename",
      "commitMessage": "HDFS-4037. Rename the getReplication() method in BlockCollection to getBlockReplication(). \n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1398288 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "15/10/12 6:48 AM",
      "commitName": "ad06a087131d69d173d8e03dce5c97650a530f2e",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "15/07/12 7:58 PM",
      "commitNameOld": "0e8e499ff482c165d21c8e4f5ff9c33f306ca0d9",
      "commitAuthorOld": "Harsh J",
      "daysBetweenCommits": 91.45,
      "commitsBetweenForRepo": 537,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,3 +1,3 @@\n-  public short getReplication() {\n+  public short getBlockReplication() {\n     return (short) ((header \u0026 HEADERMASK) \u003e\u003e BLOCKBITS);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public short getBlockReplication() {\n    return (short) ((header \u0026 HEADERMASK) \u003e\u003e BLOCKBITS);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
      "extendedDetails": {
        "oldValue": "getReplication",
        "newValue": "getBlockReplication"
      }
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public short getReplication() {\n    return (short) ((header \u0026 HEADERMASK) \u003e\u003e BLOCKBITS);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public short getReplication() {\n    return (short) ((header \u0026 HEADERMASK) \u003e\u003e BLOCKBITS);\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,3 @@\n+  public short getReplication() {\n+    return (short) ((header \u0026 HEADERMASK) \u003e\u003e BLOCKBITS);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public short getReplication() {\n    return (short) ((header \u0026 HEADERMASK) \u003e\u003e BLOCKBITS);\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java"
    }
  }
}