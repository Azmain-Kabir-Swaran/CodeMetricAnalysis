{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DFSOutputStream.java",
  "functionName": "newStreamForAppend",
  "functionId": "newStreamForAppend___dfsClient-DFSClient__src-String__flags-EnumSet__CreateFlag____progress-Progressable__lastBlock-LocatedBlock__stat-HdfsFileStatus__checksum-DataChecksum__favoredNodes-String[]",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
  "functionStartLine": 393,
  "functionEndLine": 410,
  "numCommitsSeen": 408,
  "timeTaken": 7150,
  "changeHistory": [
    "f940ab242da80a22bae95509d5c282d7e2f7ecdb",
    "7136e8c5582dc4061b566cb9f11a0d6a6d08bb93",
    "892ade689f9bcce76daae8f66fc00a49bee8548e",
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c",
    "7947e5b53b9ac9524b535b0384c1c355b74723ff",
    "61df1b27a797efd094328c7d9141b9e157e01bf4",
    "8234fd0e1087e0e49aa1d6f286f292b7f70b368e",
    "89a544928083501625bc69f96b530040228f0a5f",
    "2848db814a98b83e7546f65a2751e56fb5b2dbe0",
    "4525c4a25ba90163c9543116e2bd54239e0dd097",
    "3b773da0361bdec594acd6814c49b81f867bd673"
  ],
  "changeHistoryShort": {
    "f940ab242da80a22bae95509d5c282d7e2f7ecdb": "Ybodychange",
    "7136e8c5582dc4061b566cb9f11a0d6a6d08bb93": "Ymultichange(Yparameterchange,Ybodychange)",
    "892ade689f9bcce76daae8f66fc00a49bee8548e": "Ybodychange",
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c": "Yfilerename",
    "7947e5b53b9ac9524b535b0384c1c355b74723ff": "Ybodychange",
    "61df1b27a797efd094328c7d9141b9e157e01bf4": "Ymultichange(Yparameterchange,Ybodychange)",
    "8234fd0e1087e0e49aa1d6f286f292b7f70b368e": "Ybodychange",
    "89a544928083501625bc69f96b530040228f0a5f": "Ymultichange(Yparameterchange,Ybodychange)",
    "2848db814a98b83e7546f65a2751e56fb5b2dbe0": "Ymultichange(Yparameterchange,Ybodychange)",
    "4525c4a25ba90163c9543116e2bd54239e0dd097": "Ybodychange",
    "3b773da0361bdec594acd6814c49b81f867bd673": "Yintroduced"
  },
  "changeHistoryDetails": {
    "f940ab242da80a22bae95509d5c282d7e2f7ecdb": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7663. Erasure Coding: Append on striped file. Contributed by Ayush Saxena.\n",
      "commitDate": "05/03/19 5:56 AM",
      "commitName": "f940ab242da80a22bae95509d5c282d7e2f7ecdb",
      "commitAuthor": "Vinayakumar B",
      "commitDateOld": "14/02/19 8:43 AM",
      "commitNameOld": "0d7a5ac5f526801367a9ec963e6d72783b637d55",
      "commitAuthorOld": "Surendra Singh Lilhore",
      "daysBetweenCommits": 18.88,
      "commitsBetweenForRepo": 175,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,18 @@\n   static DFSOutputStream newStreamForAppend(DFSClient dfsClient, String src,\n       EnumSet\u003cCreateFlag\u003e flags, Progressable progress, LocatedBlock lastBlock,\n       HdfsFileStatus stat, DataChecksum checksum, String[] favoredNodes)\n       throws IOException {\n-    if(stat.getErasureCodingPolicy() !\u003d null) {\n-      throw new IOException(\n-          \"Not support appending to a striping layout file yet.\");\n-    }\n     try (TraceScope ignored \u003d\n              dfsClient.newPathTraceScope(\"newStreamForAppend\", src)) {\n-      final DFSOutputStream out \u003d new DFSOutputStream(dfsClient, src, flags,\n-          progress, lastBlock, stat, checksum, favoredNodes);\n+      DFSOutputStream out;\n+      if (stat.isErasureCoded()) {\n+        out \u003d new DFSStripedOutputStream(dfsClient, src, flags, progress,\n+            lastBlock, stat, checksum, favoredNodes);\n+      } else {\n+        out \u003d new DFSOutputStream(dfsClient, src, flags, progress, lastBlock,\n+            stat, checksum, favoredNodes);\n+      }\n       out.start();\n       return out;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static DFSOutputStream newStreamForAppend(DFSClient dfsClient, String src,\n      EnumSet\u003cCreateFlag\u003e flags, Progressable progress, LocatedBlock lastBlock,\n      HdfsFileStatus stat, DataChecksum checksum, String[] favoredNodes)\n      throws IOException {\n    try (TraceScope ignored \u003d\n             dfsClient.newPathTraceScope(\"newStreamForAppend\", src)) {\n      DFSOutputStream out;\n      if (stat.isErasureCoded()) {\n        out \u003d new DFSStripedOutputStream(dfsClient, src, flags, progress,\n            lastBlock, stat, checksum, favoredNodes);\n      } else {\n        out \u003d new DFSOutputStream(dfsClient, src, flags, progress, lastBlock,\n            stat, checksum, favoredNodes);\n      }\n      out.start();\n      return out;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {}
    },
    "7136e8c5582dc4061b566cb9f11a0d6a6d08bb93": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-8979. Clean up checkstyle warnings in hadoop-hdfs-client module. Contributed by Mingliang Liu.\n",
      "commitDate": "03/10/15 11:38 AM",
      "commitName": "7136e8c5582dc4061b566cb9f11a0d6a6d08bb93",
      "commitAuthor": "Haohui Mai",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-8979. Clean up checkstyle warnings in hadoop-hdfs-client module. Contributed by Mingliang Liu.\n",
          "commitDate": "03/10/15 11:38 AM",
          "commitName": "7136e8c5582dc4061b566cb9f11a0d6a6d08bb93",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "30/09/15 8:39 AM",
          "commitNameOld": "6c17d315287020368689fa078a40a1eaedf89d5b",
          "commitAuthorOld": "",
          "daysBetweenCommits": 3.12,
          "commitsBetweenForRepo": 16,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,18 +1,16 @@\n   static DFSOutputStream newStreamForAppend(DFSClient dfsClient, String src,\n-      EnumSet\u003cCreateFlag\u003e flags, int bufferSize, Progressable progress,\n-      LocatedBlock lastBlock, HdfsFileStatus stat, DataChecksum checksum,\n-      String[] favoredNodes) throws IOException {\n-    TraceScope scope \u003d\n-        dfsClient.newPathTraceScope(\"newStreamForAppend\", src);\n+      EnumSet\u003cCreateFlag\u003e flags, Progressable progress, LocatedBlock lastBlock,\n+      HdfsFileStatus stat, DataChecksum checksum, String[] favoredNodes)\n+      throws IOException {\n     if(stat.getErasureCodingPolicy() !\u003d null) {\n-      throw new IOException(\"Not support appending to a striping layout file yet.\");\n+      throw new IOException(\n+          \"Not support appending to a striping layout file yet.\");\n     }\n-    try {\n+    try (TraceScope ignored \u003d\n+             dfsClient.newPathTraceScope(\"newStreamForAppend\", src)) {\n       final DFSOutputStream out \u003d new DFSOutputStream(dfsClient, src, flags,\n           progress, lastBlock, stat, checksum, favoredNodes);\n       out.start();\n       return out;\n-    } finally {\n-      scope.close();\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static DFSOutputStream newStreamForAppend(DFSClient dfsClient, String src,\n      EnumSet\u003cCreateFlag\u003e flags, Progressable progress, LocatedBlock lastBlock,\n      HdfsFileStatus stat, DataChecksum checksum, String[] favoredNodes)\n      throws IOException {\n    if(stat.getErasureCodingPolicy() !\u003d null) {\n      throw new IOException(\n          \"Not support appending to a striping layout file yet.\");\n    }\n    try (TraceScope ignored \u003d\n             dfsClient.newPathTraceScope(\"newStreamForAppend\", src)) {\n      final DFSOutputStream out \u003d new DFSOutputStream(dfsClient, src, flags,\n          progress, lastBlock, stat, checksum, favoredNodes);\n      out.start();\n      return out;\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
          "extendedDetails": {
            "oldValue": "[dfsClient-DFSClient, src-String, flags-EnumSet\u003cCreateFlag\u003e, bufferSize-int, progress-Progressable, lastBlock-LocatedBlock, stat-HdfsFileStatus, checksum-DataChecksum, favoredNodes-String[]]",
            "newValue": "[dfsClient-DFSClient, src-String, flags-EnumSet\u003cCreateFlag\u003e, progress-Progressable, lastBlock-LocatedBlock, stat-HdfsFileStatus, checksum-DataChecksum, favoredNodes-String[]]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-8979. Clean up checkstyle warnings in hadoop-hdfs-client module. Contributed by Mingliang Liu.\n",
          "commitDate": "03/10/15 11:38 AM",
          "commitName": "7136e8c5582dc4061b566cb9f11a0d6a6d08bb93",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "30/09/15 8:39 AM",
          "commitNameOld": "6c17d315287020368689fa078a40a1eaedf89d5b",
          "commitAuthorOld": "",
          "daysBetweenCommits": 3.12,
          "commitsBetweenForRepo": 16,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,18 +1,16 @@\n   static DFSOutputStream newStreamForAppend(DFSClient dfsClient, String src,\n-      EnumSet\u003cCreateFlag\u003e flags, int bufferSize, Progressable progress,\n-      LocatedBlock lastBlock, HdfsFileStatus stat, DataChecksum checksum,\n-      String[] favoredNodes) throws IOException {\n-    TraceScope scope \u003d\n-        dfsClient.newPathTraceScope(\"newStreamForAppend\", src);\n+      EnumSet\u003cCreateFlag\u003e flags, Progressable progress, LocatedBlock lastBlock,\n+      HdfsFileStatus stat, DataChecksum checksum, String[] favoredNodes)\n+      throws IOException {\n     if(stat.getErasureCodingPolicy() !\u003d null) {\n-      throw new IOException(\"Not support appending to a striping layout file yet.\");\n+      throw new IOException(\n+          \"Not support appending to a striping layout file yet.\");\n     }\n-    try {\n+    try (TraceScope ignored \u003d\n+             dfsClient.newPathTraceScope(\"newStreamForAppend\", src)) {\n       final DFSOutputStream out \u003d new DFSOutputStream(dfsClient, src, flags,\n           progress, lastBlock, stat, checksum, favoredNodes);\n       out.start();\n       return out;\n-    } finally {\n-      scope.close();\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static DFSOutputStream newStreamForAppend(DFSClient dfsClient, String src,\n      EnumSet\u003cCreateFlag\u003e flags, Progressable progress, LocatedBlock lastBlock,\n      HdfsFileStatus stat, DataChecksum checksum, String[] favoredNodes)\n      throws IOException {\n    if(stat.getErasureCodingPolicy() !\u003d null) {\n      throw new IOException(\n          \"Not support appending to a striping layout file yet.\");\n    }\n    try (TraceScope ignored \u003d\n             dfsClient.newPathTraceScope(\"newStreamForAppend\", src)) {\n      final DFSOutputStream out \u003d new DFSOutputStream(dfsClient, src, flags,\n          progress, lastBlock, stat, checksum, favoredNodes);\n      out.start();\n      return out;\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
          "extendedDetails": {}
        }
      ]
    },
    "892ade689f9bcce76daae8f66fc00a49bee8548e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9080. Update htrace version to 4.0.1 (cmccabe)\n",
      "commitDate": "28/09/15 7:42 AM",
      "commitName": "892ade689f9bcce76daae8f66fc00a49bee8548e",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "26/09/15 11:08 AM",
      "commitNameOld": "bf37d3d80e5179dea27e5bd5aea804a38aa9934c",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 1.86,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,15 +1,15 @@\n   static DFSOutputStream newStreamForAppend(DFSClient dfsClient, String src,\n       EnumSet\u003cCreateFlag\u003e flags, int bufferSize, Progressable progress,\n       LocatedBlock lastBlock, HdfsFileStatus stat, DataChecksum checksum,\n       String[] favoredNodes) throws IOException {\n     TraceScope scope \u003d\n-        dfsClient.getPathTraceScope(\"newStreamForAppend\", src);\n+        dfsClient.newPathTraceScope(\"newStreamForAppend\", src);\n     try {\n       final DFSOutputStream out \u003d new DFSOutputStream(dfsClient, src, flags,\n           progress, lastBlock, stat, checksum, favoredNodes);\n       out.start();\n       return out;\n     } finally {\n       scope.close();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static DFSOutputStream newStreamForAppend(DFSClient dfsClient, String src,\n      EnumSet\u003cCreateFlag\u003e flags, int bufferSize, Progressable progress,\n      LocatedBlock lastBlock, HdfsFileStatus stat, DataChecksum checksum,\n      String[] favoredNodes) throws IOException {\n    TraceScope scope \u003d\n        dfsClient.newPathTraceScope(\"newStreamForAppend\", src);\n    try {\n      final DFSOutputStream out \u003d new DFSOutputStream(dfsClient, src, flags,\n          progress, lastBlock, stat, checksum, favoredNodes);\n      out.start();\n      return out;\n    } finally {\n      scope.close();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {}
    },
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8053. Move DFSIn/OutputStream and related classes to hadoop-hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "26/09/15 11:08 AM",
      "commitName": "bf37d3d80e5179dea27e5bd5aea804a38aa9934c",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "26/09/15 9:06 AM",
      "commitNameOld": "861b52db242f238d7e36ad75c158025be959a696",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 0.08,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  static DFSOutputStream newStreamForAppend(DFSClient dfsClient, String src,\n      EnumSet\u003cCreateFlag\u003e flags, int bufferSize, Progressable progress,\n      LocatedBlock lastBlock, HdfsFileStatus stat, DataChecksum checksum,\n      String[] favoredNodes) throws IOException {\n    TraceScope scope \u003d\n        dfsClient.getPathTraceScope(\"newStreamForAppend\", src);\n    try {\n      final DFSOutputStream out \u003d new DFSOutputStream(dfsClient, src, flags,\n          progress, lastBlock, stat, checksum, favoredNodes);\n      out.start();\n      return out;\n    } finally {\n      scope.close();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java"
      }
    },
    "7947e5b53b9ac9524b535b0384c1c355b74723ff": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8283. DataStreamer cleanup and some minor improvement. Contributed by Tsz Wo Nicholas Sze.\n",
      "commitDate": "29/04/15 10:41 AM",
      "commitName": "7947e5b53b9ac9524b535b0384c1c355b74723ff",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "24/04/15 12:21 AM",
      "commitNameOld": "c8d72907ff5a4cb9ce1effca8ad9b69689d11d1d",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 5.43,
      "commitsBetweenForRepo": 43,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,18 +1,15 @@\n   static DFSOutputStream newStreamForAppend(DFSClient dfsClient, String src,\n       EnumSet\u003cCreateFlag\u003e flags, int bufferSize, Progressable progress,\n       LocatedBlock lastBlock, HdfsFileStatus stat, DataChecksum checksum,\n       String[] favoredNodes) throws IOException {\n     TraceScope scope \u003d\n         dfsClient.getPathTraceScope(\"newStreamForAppend\", src);\n     try {\n       final DFSOutputStream out \u003d new DFSOutputStream(dfsClient, src, flags,\n-          progress, lastBlock, stat, checksum);\n-      if (favoredNodes !\u003d null \u0026\u0026 favoredNodes.length !\u003d 0) {\n-        out.streamer.setFavoredNodes(favoredNodes);\n-      }\n+          progress, lastBlock, stat, checksum, favoredNodes);\n       out.start();\n       return out;\n     } finally {\n       scope.close();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static DFSOutputStream newStreamForAppend(DFSClient dfsClient, String src,\n      EnumSet\u003cCreateFlag\u003e flags, int bufferSize, Progressable progress,\n      LocatedBlock lastBlock, HdfsFileStatus stat, DataChecksum checksum,\n      String[] favoredNodes) throws IOException {\n    TraceScope scope \u003d\n        dfsClient.getPathTraceScope(\"newStreamForAppend\", src);\n    try {\n      final DFSOutputStream out \u003d new DFSOutputStream(dfsClient, src, flags,\n          progress, lastBlock, stat, checksum, favoredNodes);\n      out.start();\n      return out;\n    } finally {\n      scope.close();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {}
    },
    "61df1b27a797efd094328c7d9141b9e157e01bf4": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-7410. Support CreateFlags with append() to support hsync() for appending streams (Vinayakumar B via Colin P. McCabe)\n",
      "commitDate": "26/03/15 1:21 PM",
      "commitName": "61df1b27a797efd094328c7d9141b9e157e01bf4",
      "commitAuthor": "Colin Patrick Mccabe",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-7410. Support CreateFlags with append() to support hsync() for appending streams (Vinayakumar B via Colin P. McCabe)\n",
          "commitDate": "26/03/15 1:21 PM",
          "commitName": "61df1b27a797efd094328c7d9141b9e157e01bf4",
          "commitAuthor": "Colin Patrick Mccabe",
          "commitDateOld": "24/03/15 11:06 AM",
          "commitNameOld": "a16bfff71bd7f00e06e1f59bfe5445a154bb8c66",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 2.09,
          "commitsBetweenForRepo": 22,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,18 +1,18 @@\n   static DFSOutputStream newStreamForAppend(DFSClient dfsClient, String src,\n-      boolean toNewBlock, int bufferSize, Progressable progress,\n+      EnumSet\u003cCreateFlag\u003e flags, int bufferSize, Progressable progress,\n       LocatedBlock lastBlock, HdfsFileStatus stat, DataChecksum checksum,\n       String[] favoredNodes) throws IOException {\n     TraceScope scope \u003d\n         dfsClient.getPathTraceScope(\"newStreamForAppend\", src);\n     try {\n-      final DFSOutputStream out \u003d new DFSOutputStream(dfsClient, src, toNewBlock,\n+      final DFSOutputStream out \u003d new DFSOutputStream(dfsClient, src, flags,\n           progress, lastBlock, stat, checksum);\n       if (favoredNodes !\u003d null \u0026\u0026 favoredNodes.length !\u003d 0) {\n         out.streamer.setFavoredNodes(favoredNodes);\n       }\n       out.start();\n       return out;\n     } finally {\n       scope.close();\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static DFSOutputStream newStreamForAppend(DFSClient dfsClient, String src,\n      EnumSet\u003cCreateFlag\u003e flags, int bufferSize, Progressable progress,\n      LocatedBlock lastBlock, HdfsFileStatus stat, DataChecksum checksum,\n      String[] favoredNodes) throws IOException {\n    TraceScope scope \u003d\n        dfsClient.getPathTraceScope(\"newStreamForAppend\", src);\n    try {\n      final DFSOutputStream out \u003d new DFSOutputStream(dfsClient, src, flags,\n          progress, lastBlock, stat, checksum);\n      if (favoredNodes !\u003d null \u0026\u0026 favoredNodes.length !\u003d 0) {\n        out.streamer.setFavoredNodes(favoredNodes);\n      }\n      out.start();\n      return out;\n    } finally {\n      scope.close();\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
          "extendedDetails": {
            "oldValue": "[dfsClient-DFSClient, src-String, toNewBlock-boolean, bufferSize-int, progress-Progressable, lastBlock-LocatedBlock, stat-HdfsFileStatus, checksum-DataChecksum, favoredNodes-String[]]",
            "newValue": "[dfsClient-DFSClient, src-String, flags-EnumSet\u003cCreateFlag\u003e, bufferSize-int, progress-Progressable, lastBlock-LocatedBlock, stat-HdfsFileStatus, checksum-DataChecksum, favoredNodes-String[]]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7410. Support CreateFlags with append() to support hsync() for appending streams (Vinayakumar B via Colin P. McCabe)\n",
          "commitDate": "26/03/15 1:21 PM",
          "commitName": "61df1b27a797efd094328c7d9141b9e157e01bf4",
          "commitAuthor": "Colin Patrick Mccabe",
          "commitDateOld": "24/03/15 11:06 AM",
          "commitNameOld": "a16bfff71bd7f00e06e1f59bfe5445a154bb8c66",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 2.09,
          "commitsBetweenForRepo": 22,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,18 +1,18 @@\n   static DFSOutputStream newStreamForAppend(DFSClient dfsClient, String src,\n-      boolean toNewBlock, int bufferSize, Progressable progress,\n+      EnumSet\u003cCreateFlag\u003e flags, int bufferSize, Progressable progress,\n       LocatedBlock lastBlock, HdfsFileStatus stat, DataChecksum checksum,\n       String[] favoredNodes) throws IOException {\n     TraceScope scope \u003d\n         dfsClient.getPathTraceScope(\"newStreamForAppend\", src);\n     try {\n-      final DFSOutputStream out \u003d new DFSOutputStream(dfsClient, src, toNewBlock,\n+      final DFSOutputStream out \u003d new DFSOutputStream(dfsClient, src, flags,\n           progress, lastBlock, stat, checksum);\n       if (favoredNodes !\u003d null \u0026\u0026 favoredNodes.length !\u003d 0) {\n         out.streamer.setFavoredNodes(favoredNodes);\n       }\n       out.start();\n       return out;\n     } finally {\n       scope.close();\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static DFSOutputStream newStreamForAppend(DFSClient dfsClient, String src,\n      EnumSet\u003cCreateFlag\u003e flags, int bufferSize, Progressable progress,\n      LocatedBlock lastBlock, HdfsFileStatus stat, DataChecksum checksum,\n      String[] favoredNodes) throws IOException {\n    TraceScope scope \u003d\n        dfsClient.getPathTraceScope(\"newStreamForAppend\", src);\n    try {\n      final DFSOutputStream out \u003d new DFSOutputStream(dfsClient, src, flags,\n          progress, lastBlock, stat, checksum);\n      if (favoredNodes !\u003d null \u0026\u0026 favoredNodes.length !\u003d 0) {\n        out.streamer.setFavoredNodes(favoredNodes);\n      }\n      out.start();\n      return out;\n    } finally {\n      scope.close();\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
          "extendedDetails": {}
        }
      ]
    },
    "8234fd0e1087e0e49aa1d6f286f292b7f70b368e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7054. Make DFSOutputStream tracing more fine-grained (cmccabe)\n",
      "commitDate": "18/03/15 6:14 PM",
      "commitName": "8234fd0e1087e0e49aa1d6f286f292b7f70b368e",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "16/03/15 9:58 PM",
      "commitNameOld": "046521cd6511b7fc6d9478cb2bed90d8e75fca20",
      "commitAuthorOld": "Harsh J",
      "daysBetweenCommits": 1.84,
      "commitsBetweenForRepo": 25,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,18 @@\n   static DFSOutputStream newStreamForAppend(DFSClient dfsClient, String src,\n       boolean toNewBlock, int bufferSize, Progressable progress,\n       LocatedBlock lastBlock, HdfsFileStatus stat, DataChecksum checksum,\n       String[] favoredNodes) throws IOException {\n-    final DFSOutputStream out \u003d new DFSOutputStream(dfsClient, src, toNewBlock,\n-        progress, lastBlock, stat, checksum);\n-    if (favoredNodes !\u003d null \u0026\u0026 favoredNodes.length !\u003d 0) {\n-      out.streamer.setFavoredNodes(favoredNodes);\n+    TraceScope scope \u003d\n+        dfsClient.getPathTraceScope(\"newStreamForAppend\", src);\n+    try {\n+      final DFSOutputStream out \u003d new DFSOutputStream(dfsClient, src, toNewBlock,\n+          progress, lastBlock, stat, checksum);\n+      if (favoredNodes !\u003d null \u0026\u0026 favoredNodes.length !\u003d 0) {\n+        out.streamer.setFavoredNodes(favoredNodes);\n+      }\n+      out.start();\n+      return out;\n+    } finally {\n+      scope.close();\n     }\n-    out.start();\n-    return out;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static DFSOutputStream newStreamForAppend(DFSClient dfsClient, String src,\n      boolean toNewBlock, int bufferSize, Progressable progress,\n      LocatedBlock lastBlock, HdfsFileStatus stat, DataChecksum checksum,\n      String[] favoredNodes) throws IOException {\n    TraceScope scope \u003d\n        dfsClient.getPathTraceScope(\"newStreamForAppend\", src);\n    try {\n      final DFSOutputStream out \u003d new DFSOutputStream(dfsClient, src, toNewBlock,\n          progress, lastBlock, stat, checksum);\n      if (favoredNodes !\u003d null \u0026\u0026 favoredNodes.length !\u003d 0) {\n        out.streamer.setFavoredNodes(favoredNodes);\n      }\n      out.start();\n      return out;\n    } finally {\n      scope.close();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {}
    },
    "89a544928083501625bc69f96b530040228f0a5f": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-7703. Support favouredNodes for the append for new blocks ( Contributed by Vinayakumar B)\n",
      "commitDate": "11/02/15 11:08 PM",
      "commitName": "89a544928083501625bc69f96b530040228f0a5f",
      "commitAuthor": "Vinayakumar B",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-7703. Support favouredNodes for the append for new blocks ( Contributed by Vinayakumar B)\n",
          "commitDate": "11/02/15 11:08 PM",
          "commitName": "89a544928083501625bc69f96b530040228f0a5f",
          "commitAuthor": "Vinayakumar B",
          "commitDateOld": "11/02/15 3:12 PM",
          "commitNameOld": "085b1e293ff53f7a86aa21406cfd4bfa0f3bf33b",
          "commitAuthorOld": "Tsz-Wo Nicholas Sze",
          "daysBetweenCommits": 0.33,
          "commitsBetweenForRepo": 3,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,9 +1,12 @@\n   static DFSOutputStream newStreamForAppend(DFSClient dfsClient, String src,\n       boolean toNewBlock, int bufferSize, Progressable progress,\n-      LocatedBlock lastBlock, HdfsFileStatus stat, DataChecksum checksum)\n-      throws IOException {\n+      LocatedBlock lastBlock, HdfsFileStatus stat, DataChecksum checksum,\n+      String[] favoredNodes) throws IOException {\n     final DFSOutputStream out \u003d new DFSOutputStream(dfsClient, src, toNewBlock,\n         progress, lastBlock, stat, checksum);\n+    if (favoredNodes !\u003d null \u0026\u0026 favoredNodes.length !\u003d 0) {\n+      out.streamer.setFavoredNodes(favoredNodes);\n+    }\n     out.start();\n     return out;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static DFSOutputStream newStreamForAppend(DFSClient dfsClient, String src,\n      boolean toNewBlock, int bufferSize, Progressable progress,\n      LocatedBlock lastBlock, HdfsFileStatus stat, DataChecksum checksum,\n      String[] favoredNodes) throws IOException {\n    final DFSOutputStream out \u003d new DFSOutputStream(dfsClient, src, toNewBlock,\n        progress, lastBlock, stat, checksum);\n    if (favoredNodes !\u003d null \u0026\u0026 favoredNodes.length !\u003d 0) {\n      out.streamer.setFavoredNodes(favoredNodes);\n    }\n    out.start();\n    return out;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
          "extendedDetails": {
            "oldValue": "[dfsClient-DFSClient, src-String, toNewBlock-boolean, bufferSize-int, progress-Progressable, lastBlock-LocatedBlock, stat-HdfsFileStatus, checksum-DataChecksum]",
            "newValue": "[dfsClient-DFSClient, src-String, toNewBlock-boolean, bufferSize-int, progress-Progressable, lastBlock-LocatedBlock, stat-HdfsFileStatus, checksum-DataChecksum, favoredNodes-String[]]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7703. Support favouredNodes for the append for new blocks ( Contributed by Vinayakumar B)\n",
          "commitDate": "11/02/15 11:08 PM",
          "commitName": "89a544928083501625bc69f96b530040228f0a5f",
          "commitAuthor": "Vinayakumar B",
          "commitDateOld": "11/02/15 3:12 PM",
          "commitNameOld": "085b1e293ff53f7a86aa21406cfd4bfa0f3bf33b",
          "commitAuthorOld": "Tsz-Wo Nicholas Sze",
          "daysBetweenCommits": 0.33,
          "commitsBetweenForRepo": 3,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,9 +1,12 @@\n   static DFSOutputStream newStreamForAppend(DFSClient dfsClient, String src,\n       boolean toNewBlock, int bufferSize, Progressable progress,\n-      LocatedBlock lastBlock, HdfsFileStatus stat, DataChecksum checksum)\n-      throws IOException {\n+      LocatedBlock lastBlock, HdfsFileStatus stat, DataChecksum checksum,\n+      String[] favoredNodes) throws IOException {\n     final DFSOutputStream out \u003d new DFSOutputStream(dfsClient, src, toNewBlock,\n         progress, lastBlock, stat, checksum);\n+    if (favoredNodes !\u003d null \u0026\u0026 favoredNodes.length !\u003d 0) {\n+      out.streamer.setFavoredNodes(favoredNodes);\n+    }\n     out.start();\n     return out;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static DFSOutputStream newStreamForAppend(DFSClient dfsClient, String src,\n      boolean toNewBlock, int bufferSize, Progressable progress,\n      LocatedBlock lastBlock, HdfsFileStatus stat, DataChecksum checksum,\n      String[] favoredNodes) throws IOException {\n    final DFSOutputStream out \u003d new DFSOutputStream(dfsClient, src, toNewBlock,\n        progress, lastBlock, stat, checksum);\n    if (favoredNodes !\u003d null \u0026\u0026 favoredNodes.length !\u003d 0) {\n      out.streamer.setFavoredNodes(favoredNodes);\n    }\n    out.start();\n    return out;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
          "extendedDetails": {}
        }
      ]
    },
    "2848db814a98b83e7546f65a2751e56fb5b2dbe0": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-3689. Add support for variable length block. Contributed by Jing Zhao.\n",
      "commitDate": "27/01/15 12:58 PM",
      "commitName": "2848db814a98b83e7546f65a2751e56fb5b2dbe0",
      "commitAuthor": "Jing Zhao",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-3689. Add support for variable length block. Contributed by Jing Zhao.\n",
          "commitDate": "27/01/15 12:58 PM",
          "commitName": "2848db814a98b83e7546f65a2751e56fb5b2dbe0",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "11/12/14 12:36 PM",
          "commitNameOld": "b9f6d0c956f0278c8b9b83e05b523a442a730ebb",
          "commitAuthorOld": "Haohui Mai",
          "daysBetweenCommits": 47.02,
          "commitsBetweenForRepo": 264,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,8 +1,9 @@\n   static DFSOutputStream newStreamForAppend(DFSClient dfsClient, String src,\n-      int buffersize, Progressable progress, LocatedBlock lastBlock,\n-      HdfsFileStatus stat, DataChecksum checksum) throws IOException {\n-    final DFSOutputStream out \u003d new DFSOutputStream(dfsClient, src,\n+      boolean toNewBlock, int bufferSize, Progressable progress,\n+      LocatedBlock lastBlock, HdfsFileStatus stat, DataChecksum checksum)\n+      throws IOException {\n+    final DFSOutputStream out \u003d new DFSOutputStream(dfsClient, src, toNewBlock,\n         progress, lastBlock, stat, checksum);\n     out.start();\n     return out;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static DFSOutputStream newStreamForAppend(DFSClient dfsClient, String src,\n      boolean toNewBlock, int bufferSize, Progressable progress,\n      LocatedBlock lastBlock, HdfsFileStatus stat, DataChecksum checksum)\n      throws IOException {\n    final DFSOutputStream out \u003d new DFSOutputStream(dfsClient, src, toNewBlock,\n        progress, lastBlock, stat, checksum);\n    out.start();\n    return out;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
          "extendedDetails": {
            "oldValue": "[dfsClient-DFSClient, src-String, buffersize-int, progress-Progressable, lastBlock-LocatedBlock, stat-HdfsFileStatus, checksum-DataChecksum]",
            "newValue": "[dfsClient-DFSClient, src-String, toNewBlock-boolean, bufferSize-int, progress-Progressable, lastBlock-LocatedBlock, stat-HdfsFileStatus, checksum-DataChecksum]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-3689. Add support for variable length block. Contributed by Jing Zhao.\n",
          "commitDate": "27/01/15 12:58 PM",
          "commitName": "2848db814a98b83e7546f65a2751e56fb5b2dbe0",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "11/12/14 12:36 PM",
          "commitNameOld": "b9f6d0c956f0278c8b9b83e05b523a442a730ebb",
          "commitAuthorOld": "Haohui Mai",
          "daysBetweenCommits": 47.02,
          "commitsBetweenForRepo": 264,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,8 +1,9 @@\n   static DFSOutputStream newStreamForAppend(DFSClient dfsClient, String src,\n-      int buffersize, Progressable progress, LocatedBlock lastBlock,\n-      HdfsFileStatus stat, DataChecksum checksum) throws IOException {\n-    final DFSOutputStream out \u003d new DFSOutputStream(dfsClient, src,\n+      boolean toNewBlock, int bufferSize, Progressable progress,\n+      LocatedBlock lastBlock, HdfsFileStatus stat, DataChecksum checksum)\n+      throws IOException {\n+    final DFSOutputStream out \u003d new DFSOutputStream(dfsClient, src, toNewBlock,\n         progress, lastBlock, stat, checksum);\n     out.start();\n     return out;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static DFSOutputStream newStreamForAppend(DFSClient dfsClient, String src,\n      boolean toNewBlock, int bufferSize, Progressable progress,\n      LocatedBlock lastBlock, HdfsFileStatus stat, DataChecksum checksum)\n      throws IOException {\n    final DFSOutputStream out \u003d new DFSOutputStream(dfsClient, src, toNewBlock,\n        progress, lastBlock, stat, checksum);\n    out.start();\n    return out;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
          "extendedDetails": {}
        }
      ]
    },
    "4525c4a25ba90163c9543116e2bd54239e0dd097": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4340. Update addBlock() to inculde inode id as additional argument. Contributed Brandon Li.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1443169 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "06/02/13 11:52 AM",
      "commitName": "4525c4a25ba90163c9543116e2bd54239e0dd097",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "27/01/13 9:42 AM",
      "commitNameOld": "9639f37ee21427303e877e8aeb486e0d71982e0f",
      "commitAuthorOld": "Harsh J",
      "daysBetweenCommits": 10.09,
      "commitsBetweenForRepo": 56,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,8 +1,8 @@\n   static DFSOutputStream newStreamForAppend(DFSClient dfsClient, String src,\n       int buffersize, Progressable progress, LocatedBlock lastBlock,\n       HdfsFileStatus stat, DataChecksum checksum) throws IOException {\n-    final DFSOutputStream out \u003d new DFSOutputStream(dfsClient, src, buffersize,\n+    final DFSOutputStream out \u003d new DFSOutputStream(dfsClient, src,\n         progress, lastBlock, stat, checksum);\n-    out.streamer.start();\n+    out.start();\n     return out;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static DFSOutputStream newStreamForAppend(DFSClient dfsClient, String src,\n      int buffersize, Progressable progress, LocatedBlock lastBlock,\n      HdfsFileStatus stat, DataChecksum checksum) throws IOException {\n    final DFSOutputStream out \u003d new DFSOutputStream(dfsClient, src,\n        progress, lastBlock, stat, checksum);\n    out.start();\n    return out;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {}
    },
    "3b773da0361bdec594acd6814c49b81f867bd673": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-3319. Change DFSOutputStream to not to start a thread in constructors.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1330535 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "25/04/12 1:17 PM",
      "commitName": "3b773da0361bdec594acd6814c49b81f867bd673",
      "commitAuthor": "Tsz-wo Sze",
      "diff": "@@ -0,0 +1,8 @@\n+  static DFSOutputStream newStreamForAppend(DFSClient dfsClient, String src,\n+      int buffersize, Progressable progress, LocatedBlock lastBlock,\n+      HdfsFileStatus stat, DataChecksum checksum) throws IOException {\n+    final DFSOutputStream out \u003d new DFSOutputStream(dfsClient, src, buffersize,\n+        progress, lastBlock, stat, checksum);\n+    out.streamer.start();\n+    return out;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  static DFSOutputStream newStreamForAppend(DFSClient dfsClient, String src,\n      int buffersize, Progressable progress, LocatedBlock lastBlock,\n      HdfsFileStatus stat, DataChecksum checksum) throws IOException {\n    final DFSOutputStream out \u003d new DFSOutputStream(dfsClient, src, buffersize,\n        progress, lastBlock, stat, checksum);\n    out.streamer.start();\n    return out;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java"
    }
  }
}