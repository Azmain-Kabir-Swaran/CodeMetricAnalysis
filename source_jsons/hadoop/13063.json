{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockPlacementPolicyWithNodeGroup.java",
  "functionName": "verifyBlockPlacement",
  "functionId": "verifyBlockPlacement___locs-DatanodeInfo[]__numberOfReplicas-int",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyWithNodeGroup.java",
  "functionStartLine": 400,
  "functionEndLine": 430,
  "numCommitsSeen": 23,
  "timeTaken": 967,
  "changeHistory": [
    "77ba5add0d9cb10d45ca9122bca48baa7c8fb3b8"
  ],
  "changeHistoryShort": {
    "77ba5add0d9cb10d45ca9122bca48baa7c8fb3b8": "Yintroduced"
  },
  "changeHistoryDetails": {
    "77ba5add0d9cb10d45ca9122bca48baa7c8fb3b8": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-9456. BlockPlacementPolicyWithNodeGroup should override verifyBlockPlacement(). Contributed by Xiaobing Zhou.\n",
      "commitDate": "16/02/16 6:55 PM",
      "commitName": "77ba5add0d9cb10d45ca9122bca48baa7c8fb3b8",
      "commitAuthor": "Junping Du",
      "diff": "@@ -0,0 +1,31 @@\n+  public BlockPlacementStatus verifyBlockPlacement(DatanodeInfo[] locs,\n+      int numberOfReplicas) {\n+    if (locs \u003d\u003d null) {\n+      locs \u003d DatanodeDescriptor.EMPTY_ARRAY;\n+    }\n+\n+    List\u003cString\u003e locList \u003d new ArrayList\u003cString\u003e();\n+    /*\n+     * remove the part of node group for BlockPlacementPolicyDefault to count\n+     * distinct racks, e.g. \"/d1/r1/n1\" --\u003e \"/d1/r1\"\n+     */\n+    for (int i \u003d 0; i \u003c locs.length; i++) {\n+      locList.add(locs[i].getNetworkLocation());\n+      locs[i].setNetworkLocation(NetworkTopology.getFirstHalf(locs[i]\n+          .getNetworkLocation()));\n+    }\n+\n+    BlockPlacementStatus defaultStatus \u003d super.verifyBlockPlacement(locs,\n+        numberOfReplicas);\n+\n+    // restore the part of node group back\n+    for (int i \u003d 0; i \u003c locs.length; i++) {\n+      locs[i].setNetworkLocation(locList.get(i));\n+    }\n+\n+    int minNodeGroups \u003d numberOfReplicas;\n+    BlockPlacementStatusWithNodeGroup nodeGroupStatus \u003d\n+        new BlockPlacementStatusWithNodeGroup(\n+            defaultStatus, getNodeGroupsFromNode(locs), minNodeGroups);\n+    return nodeGroupStatus;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public BlockPlacementStatus verifyBlockPlacement(DatanodeInfo[] locs,\n      int numberOfReplicas) {\n    if (locs \u003d\u003d null) {\n      locs \u003d DatanodeDescriptor.EMPTY_ARRAY;\n    }\n\n    List\u003cString\u003e locList \u003d new ArrayList\u003cString\u003e();\n    /*\n     * remove the part of node group for BlockPlacementPolicyDefault to count\n     * distinct racks, e.g. \"/d1/r1/n1\" --\u003e \"/d1/r1\"\n     */\n    for (int i \u003d 0; i \u003c locs.length; i++) {\n      locList.add(locs[i].getNetworkLocation());\n      locs[i].setNetworkLocation(NetworkTopology.getFirstHalf(locs[i]\n          .getNetworkLocation()));\n    }\n\n    BlockPlacementStatus defaultStatus \u003d super.verifyBlockPlacement(locs,\n        numberOfReplicas);\n\n    // restore the part of node group back\n    for (int i \u003d 0; i \u003c locs.length; i++) {\n      locs[i].setNetworkLocation(locList.get(i));\n    }\n\n    int minNodeGroups \u003d numberOfReplicas;\n    BlockPlacementStatusWithNodeGroup nodeGroupStatus \u003d\n        new BlockPlacementStatusWithNodeGroup(\n            defaultStatus, getNodeGroupsFromNode(locs), minNodeGroups);\n    return nodeGroupStatus;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyWithNodeGroup.java"
    }
  }
}