{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "LeaseManager.java",
  "functionName": "checkLeases",
  "functionId": "checkLeases",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/LeaseManager.java",
  "functionStartLine": 559,
  "functionEndLine": 634,
  "numCommitsSeen": 56,
  "timeTaken": 8745,
  "changeHistory": [
    "96be795656039c0c12031ec31becfcd35fbb1b70",
    "52b894db33bc68b46eec5cdf2735dfcf4030853a",
    "b5c02f95b5a2fcb8931d4a86f8192caa18009ea9",
    "1a33c9d58927186c2f219a5ecb5f1573801823ad",
    "2b5ad48762587abbcd8bdb50d0ae98f8080d926c",
    "ae047655f4355288406cd5396fb4e3ea7c307b14",
    "00fe1ed3a4b3ee35fe24be257ec36445d2f44d63",
    "c78e3a7cdd10c40454e9acb06986ba6d8573cb19",
    "daacbc18d739d030822df0b75205eeb067f89850",
    "298eb4265702362d14d7c375983bcd85371ab9af",
    "47410642500e6f0d61c5d2f479d1d3673e6ebf35",
    "cea7bbc630deede93dbe6a1bbda56ad49de4f3de",
    "8ae98a9d1ca4725e28783370517cb3a3ecda7324",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "96be795656039c0c12031ec31becfcd35fbb1b70": "Ybodychange",
    "52b894db33bc68b46eec5cdf2735dfcf4030853a": "Ybodychange",
    "b5c02f95b5a2fcb8931d4a86f8192caa18009ea9": "Ybodychange",
    "1a33c9d58927186c2f219a5ecb5f1573801823ad": "Ybodychange",
    "2b5ad48762587abbcd8bdb50d0ae98f8080d926c": "Ybodychange",
    "ae047655f4355288406cd5396fb4e3ea7c307b14": "Ybodychange",
    "00fe1ed3a4b3ee35fe24be257ec36445d2f44d63": "Ybodychange",
    "c78e3a7cdd10c40454e9acb06986ba6d8573cb19": "Ybodychange",
    "daacbc18d739d030822df0b75205eeb067f89850": "Ymultichange(Ymodifierchange,Ybodychange)",
    "298eb4265702362d14d7c375983bcd85371ab9af": "Ymultichange(Yreturntypechange,Ybodychange)",
    "47410642500e6f0d61c5d2f479d1d3673e6ebf35": "Ybodychange",
    "cea7bbc630deede93dbe6a1bbda56ad49de4f3de": "Ybodychange",
    "8ae98a9d1ca4725e28783370517cb3a3ecda7324": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "96be795656039c0c12031ec31becfcd35fbb1b70": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12650. Use slf4j instead of log4j in LeaseManager. Contributed by Ajay Kumar.\n",
      "commitDate": "23/10/17 1:20 PM",
      "commitName": "96be795656039c0c12031ec31becfcd35fbb1b70",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "07/09/17 4:30 PM",
      "commitNameOld": "52b894db33bc68b46eec5cdf2735dfcf4030853a",
      "commitAuthorOld": "Xiao Chen",
      "daysBetweenCommits": 45.87,
      "commitsBetweenForRepo": 392,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,76 +1,76 @@\n   synchronized boolean checkLeases() {\n     boolean needSync \u003d false;\n     assert fsnamesystem.hasWriteLock();\n \n     long start \u003d monotonicNow();\n \n     while(!sortedLeases.isEmpty() \u0026\u0026\n         sortedLeases.first().expiredHardLimit()\n         \u0026\u0026 !isMaxLockHoldToReleaseLease(start)) {\n       Lease leaseToCheck \u003d sortedLeases.first();\n-      LOG.info(leaseToCheck + \" has expired hard limit\");\n+      LOG.info(\"{} has expired hard limit\", leaseToCheck);\n \n       final List\u003cLong\u003e removing \u003d new ArrayList\u003c\u003e();\n       // need to create a copy of the oldest lease files, because\n       // internalReleaseLease() removes files corresponding to empty files,\n       // i.e. it needs to modify the collection being iterated over\n       // causing ConcurrentModificationException\n       Collection\u003cLong\u003e files \u003d leaseToCheck.getFiles();\n       Long[] leaseINodeIds \u003d files.toArray(new Long[files.size()]);\n       FSDirectory fsd \u003d fsnamesystem.getFSDirectory();\n       String p \u003d null;\n       String newHolder \u003d getInternalLeaseHolder();\n       for(Long id : leaseINodeIds) {\n         try {\n           INodesInPath iip \u003d INodesInPath.fromINode(fsd.getInode(id));\n           p \u003d iip.getPath();\n           // Sanity check to make sure the path is correct\n           if (!p.startsWith(\"/\")) {\n             throw new IOException(\"Invalid path in the lease \" + p);\n           }\n           final INodeFile lastINode \u003d iip.getLastINode().asFile();\n           if (fsnamesystem.isFileDeleted(lastINode)) {\n             // INode referred by the lease could have been deleted.\n             removeLease(lastINode.getId());\n             continue;\n           }\n           boolean completed \u003d false;\n           try {\n             completed \u003d fsnamesystem.internalReleaseLease(\n                 leaseToCheck, p, iip, newHolder);\n           } catch (IOException e) {\n-            LOG.warn(\"Cannot release the path \" + p + \" in the lease \"\n-                + leaseToCheck + \". It will be retried.\", e);\n+            LOG.warn(\"Cannot release the path {} in the lease {}. It will be \"\n+                + \"retried.\", p, leaseToCheck, e);\n             continue;\n           }\n           if (LOG.isDebugEnabled()) {\n             if (completed) {\n-              LOG.debug(\"Lease recovery for inode \" + id + \" is complete. \" +\n-                            \"File closed.\");\n+              LOG.debug(\"Lease recovery for inode {} is complete. File closed\"\n+                  + \".\", id);\n             } else {\n-              LOG.debug(\"Started block recovery \" + p + \" lease \" + leaseToCheck);\n+              LOG.debug(\"Started block recovery {} lease {}\", p, leaseToCheck);\n             }\n           }\n           // If a lease recovery happened, we need to sync later.\n           if (!needSync \u0026\u0026 !completed) {\n             needSync \u003d true;\n           }\n         } catch (IOException e) {\n-          LOG.warn(\"Removing lease with an invalid path: \" + p + \",\"\n-              + leaseToCheck, e);\n+          LOG.warn(\"Removing lease with an invalid path: {},{}\", p,\n+              leaseToCheck, e);\n           removing.add(id);\n         }\n         if (isMaxLockHoldToReleaseLease(start)) {\n-          LOG.debug(\"Breaking out of checkLeases after \" +\n-              fsnamesystem.getMaxLockHoldToReleaseLeaseMs() + \"ms.\");\n+          LOG.debug(\"Breaking out of checkLeases after {} ms.\",\n+              fsnamesystem.getMaxLockHoldToReleaseLeaseMs());\n           break;\n         }\n       }\n \n       for(Long id : removing) {\n         removeLease(leaseToCheck, id);\n       }\n     }\n \n     return needSync;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  synchronized boolean checkLeases() {\n    boolean needSync \u003d false;\n    assert fsnamesystem.hasWriteLock();\n\n    long start \u003d monotonicNow();\n\n    while(!sortedLeases.isEmpty() \u0026\u0026\n        sortedLeases.first().expiredHardLimit()\n        \u0026\u0026 !isMaxLockHoldToReleaseLease(start)) {\n      Lease leaseToCheck \u003d sortedLeases.first();\n      LOG.info(\"{} has expired hard limit\", leaseToCheck);\n\n      final List\u003cLong\u003e removing \u003d new ArrayList\u003c\u003e();\n      // need to create a copy of the oldest lease files, because\n      // internalReleaseLease() removes files corresponding to empty files,\n      // i.e. it needs to modify the collection being iterated over\n      // causing ConcurrentModificationException\n      Collection\u003cLong\u003e files \u003d leaseToCheck.getFiles();\n      Long[] leaseINodeIds \u003d files.toArray(new Long[files.size()]);\n      FSDirectory fsd \u003d fsnamesystem.getFSDirectory();\n      String p \u003d null;\n      String newHolder \u003d getInternalLeaseHolder();\n      for(Long id : leaseINodeIds) {\n        try {\n          INodesInPath iip \u003d INodesInPath.fromINode(fsd.getInode(id));\n          p \u003d iip.getPath();\n          // Sanity check to make sure the path is correct\n          if (!p.startsWith(\"/\")) {\n            throw new IOException(\"Invalid path in the lease \" + p);\n          }\n          final INodeFile lastINode \u003d iip.getLastINode().asFile();\n          if (fsnamesystem.isFileDeleted(lastINode)) {\n            // INode referred by the lease could have been deleted.\n            removeLease(lastINode.getId());\n            continue;\n          }\n          boolean completed \u003d false;\n          try {\n            completed \u003d fsnamesystem.internalReleaseLease(\n                leaseToCheck, p, iip, newHolder);\n          } catch (IOException e) {\n            LOG.warn(\"Cannot release the path {} in the lease {}. It will be \"\n                + \"retried.\", p, leaseToCheck, e);\n            continue;\n          }\n          if (LOG.isDebugEnabled()) {\n            if (completed) {\n              LOG.debug(\"Lease recovery for inode {} is complete. File closed\"\n                  + \".\", id);\n            } else {\n              LOG.debug(\"Started block recovery {} lease {}\", p, leaseToCheck);\n            }\n          }\n          // If a lease recovery happened, we need to sync later.\n          if (!needSync \u0026\u0026 !completed) {\n            needSync \u003d true;\n          }\n        } catch (IOException e) {\n          LOG.warn(\"Removing lease with an invalid path: {},{}\", p,\n              leaseToCheck, e);\n          removing.add(id);\n        }\n        if (isMaxLockHoldToReleaseLease(start)) {\n          LOG.debug(\"Breaking out of checkLeases after {} ms.\",\n              fsnamesystem.getMaxLockHoldToReleaseLeaseMs());\n          break;\n        }\n      }\n\n      for(Long id : removing) {\n        removeLease(leaseToCheck, id);\n      }\n    }\n\n    return needSync;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/LeaseManager.java",
      "extendedDetails": {}
    },
    "52b894db33bc68b46eec5cdf2735dfcf4030853a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12369. Edit log corruption due to hard lease recovery of not-closed file which has snapshots.\n",
      "commitDate": "07/09/17 4:30 PM",
      "commitName": "52b894db33bc68b46eec5cdf2735dfcf4030853a",
      "commitAuthor": "Xiao Chen",
      "commitDateOld": "09/08/17 2:46 PM",
      "commitNameOld": "b5c02f95b5a2fcb8931d4a86f8192caa18009ea9",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 29.07,
      "commitsBetweenForRepo": 235,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,70 +1,76 @@\n   synchronized boolean checkLeases() {\n     boolean needSync \u003d false;\n     assert fsnamesystem.hasWriteLock();\n \n     long start \u003d monotonicNow();\n \n     while(!sortedLeases.isEmpty() \u0026\u0026\n         sortedLeases.first().expiredHardLimit()\n         \u0026\u0026 !isMaxLockHoldToReleaseLease(start)) {\n       Lease leaseToCheck \u003d sortedLeases.first();\n       LOG.info(leaseToCheck + \" has expired hard limit\");\n \n       final List\u003cLong\u003e removing \u003d new ArrayList\u003c\u003e();\n       // need to create a copy of the oldest lease files, because\n       // internalReleaseLease() removes files corresponding to empty files,\n       // i.e. it needs to modify the collection being iterated over\n       // causing ConcurrentModificationException\n       Collection\u003cLong\u003e files \u003d leaseToCheck.getFiles();\n       Long[] leaseINodeIds \u003d files.toArray(new Long[files.size()]);\n       FSDirectory fsd \u003d fsnamesystem.getFSDirectory();\n       String p \u003d null;\n       String newHolder \u003d getInternalLeaseHolder();\n       for(Long id : leaseINodeIds) {\n         try {\n           INodesInPath iip \u003d INodesInPath.fromINode(fsd.getInode(id));\n           p \u003d iip.getPath();\n           // Sanity check to make sure the path is correct\n           if (!p.startsWith(\"/\")) {\n             throw new IOException(\"Invalid path in the lease \" + p);\n           }\n+          final INodeFile lastINode \u003d iip.getLastINode().asFile();\n+          if (fsnamesystem.isFileDeleted(lastINode)) {\n+            // INode referred by the lease could have been deleted.\n+            removeLease(lastINode.getId());\n+            continue;\n+          }\n           boolean completed \u003d false;\n           try {\n             completed \u003d fsnamesystem.internalReleaseLease(\n                 leaseToCheck, p, iip, newHolder);\n           } catch (IOException e) {\n             LOG.warn(\"Cannot release the path \" + p + \" in the lease \"\n                 + leaseToCheck + \". It will be retried.\", e);\n             continue;\n           }\n           if (LOG.isDebugEnabled()) {\n             if (completed) {\n               LOG.debug(\"Lease recovery for inode \" + id + \" is complete. \" +\n                             \"File closed.\");\n             } else {\n               LOG.debug(\"Started block recovery \" + p + \" lease \" + leaseToCheck);\n             }\n           }\n           // If a lease recovery happened, we need to sync later.\n           if (!needSync \u0026\u0026 !completed) {\n             needSync \u003d true;\n           }\n         } catch (IOException e) {\n           LOG.warn(\"Removing lease with an invalid path: \" + p + \",\"\n               + leaseToCheck, e);\n           removing.add(id);\n         }\n         if (isMaxLockHoldToReleaseLease(start)) {\n           LOG.debug(\"Breaking out of checkLeases after \" +\n               fsnamesystem.getMaxLockHoldToReleaseLeaseMs() + \"ms.\");\n           break;\n         }\n       }\n \n       for(Long id : removing) {\n         removeLease(leaseToCheck, id);\n       }\n     }\n \n     return needSync;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  synchronized boolean checkLeases() {\n    boolean needSync \u003d false;\n    assert fsnamesystem.hasWriteLock();\n\n    long start \u003d monotonicNow();\n\n    while(!sortedLeases.isEmpty() \u0026\u0026\n        sortedLeases.first().expiredHardLimit()\n        \u0026\u0026 !isMaxLockHoldToReleaseLease(start)) {\n      Lease leaseToCheck \u003d sortedLeases.first();\n      LOG.info(leaseToCheck + \" has expired hard limit\");\n\n      final List\u003cLong\u003e removing \u003d new ArrayList\u003c\u003e();\n      // need to create a copy of the oldest lease files, because\n      // internalReleaseLease() removes files corresponding to empty files,\n      // i.e. it needs to modify the collection being iterated over\n      // causing ConcurrentModificationException\n      Collection\u003cLong\u003e files \u003d leaseToCheck.getFiles();\n      Long[] leaseINodeIds \u003d files.toArray(new Long[files.size()]);\n      FSDirectory fsd \u003d fsnamesystem.getFSDirectory();\n      String p \u003d null;\n      String newHolder \u003d getInternalLeaseHolder();\n      for(Long id : leaseINodeIds) {\n        try {\n          INodesInPath iip \u003d INodesInPath.fromINode(fsd.getInode(id));\n          p \u003d iip.getPath();\n          // Sanity check to make sure the path is correct\n          if (!p.startsWith(\"/\")) {\n            throw new IOException(\"Invalid path in the lease \" + p);\n          }\n          final INodeFile lastINode \u003d iip.getLastINode().asFile();\n          if (fsnamesystem.isFileDeleted(lastINode)) {\n            // INode referred by the lease could have been deleted.\n            removeLease(lastINode.getId());\n            continue;\n          }\n          boolean completed \u003d false;\n          try {\n            completed \u003d fsnamesystem.internalReleaseLease(\n                leaseToCheck, p, iip, newHolder);\n          } catch (IOException e) {\n            LOG.warn(\"Cannot release the path \" + p + \" in the lease \"\n                + leaseToCheck + \". It will be retried.\", e);\n            continue;\n          }\n          if (LOG.isDebugEnabled()) {\n            if (completed) {\n              LOG.debug(\"Lease recovery for inode \" + id + \" is complete. \" +\n                            \"File closed.\");\n            } else {\n              LOG.debug(\"Started block recovery \" + p + \" lease \" + leaseToCheck);\n            }\n          }\n          // If a lease recovery happened, we need to sync later.\n          if (!needSync \u0026\u0026 !completed) {\n            needSync \u003d true;\n          }\n        } catch (IOException e) {\n          LOG.warn(\"Removing lease with an invalid path: \" + p + \",\"\n              + leaseToCheck, e);\n          removing.add(id);\n        }\n        if (isMaxLockHoldToReleaseLease(start)) {\n          LOG.debug(\"Breaking out of checkLeases after \" +\n              fsnamesystem.getMaxLockHoldToReleaseLeaseMs() + \"ms.\");\n          break;\n        }\n      }\n\n      for(Long id : removing) {\n        removeLease(leaseToCheck, id);\n      }\n    }\n\n    return needSync;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/LeaseManager.java",
      "extendedDetails": {}
    },
    "b5c02f95b5a2fcb8931d4a86f8192caa18009ea9": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12278. LeaseManager operations are inefficient in 2.8. Contributed by Rushabh S Shah.\n",
      "commitDate": "09/08/17 2:46 PM",
      "commitName": "b5c02f95b5a2fcb8931d4a86f8192caa18009ea9",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "01/08/17 4:28 PM",
      "commitNameOld": "52d7bafcf49916887197436ddb0f08f021d248d9",
      "commitAuthorOld": "Manoj Govindassamy",
      "daysBetweenCommits": 7.93,
      "commitsBetweenForRepo": 110,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,69 +1,70 @@\n   synchronized boolean checkLeases() {\n     boolean needSync \u003d false;\n     assert fsnamesystem.hasWriteLock();\n \n     long start \u003d monotonicNow();\n \n-    while(!sortedLeases.isEmpty() \u0026\u0026 sortedLeases.peek().expiredHardLimit()\n-      \u0026\u0026 !isMaxLockHoldToReleaseLease(start)) {\n-      Lease leaseToCheck \u003d sortedLeases.peek();\n+    while(!sortedLeases.isEmpty() \u0026\u0026\n+        sortedLeases.first().expiredHardLimit()\n+        \u0026\u0026 !isMaxLockHoldToReleaseLease(start)) {\n+      Lease leaseToCheck \u003d sortedLeases.first();\n       LOG.info(leaseToCheck + \" has expired hard limit\");\n \n       final List\u003cLong\u003e removing \u003d new ArrayList\u003c\u003e();\n       // need to create a copy of the oldest lease files, because\n       // internalReleaseLease() removes files corresponding to empty files,\n       // i.e. it needs to modify the collection being iterated over\n       // causing ConcurrentModificationException\n       Collection\u003cLong\u003e files \u003d leaseToCheck.getFiles();\n       Long[] leaseINodeIds \u003d files.toArray(new Long[files.size()]);\n       FSDirectory fsd \u003d fsnamesystem.getFSDirectory();\n       String p \u003d null;\n       String newHolder \u003d getInternalLeaseHolder();\n       for(Long id : leaseINodeIds) {\n         try {\n           INodesInPath iip \u003d INodesInPath.fromINode(fsd.getInode(id));\n           p \u003d iip.getPath();\n           // Sanity check to make sure the path is correct\n           if (!p.startsWith(\"/\")) {\n             throw new IOException(\"Invalid path in the lease \" + p);\n           }\n           boolean completed \u003d false;\n           try {\n             completed \u003d fsnamesystem.internalReleaseLease(\n                 leaseToCheck, p, iip, newHolder);\n           } catch (IOException e) {\n             LOG.warn(\"Cannot release the path \" + p + \" in the lease \"\n                 + leaseToCheck + \". It will be retried.\", e);\n             continue;\n           }\n           if (LOG.isDebugEnabled()) {\n             if (completed) {\n               LOG.debug(\"Lease recovery for inode \" + id + \" is complete. \" +\n                             \"File closed.\");\n             } else {\n               LOG.debug(\"Started block recovery \" + p + \" lease \" + leaseToCheck);\n             }\n           }\n           // If a lease recovery happened, we need to sync later.\n           if (!needSync \u0026\u0026 !completed) {\n             needSync \u003d true;\n           }\n         } catch (IOException e) {\n           LOG.warn(\"Removing lease with an invalid path: \" + p + \",\"\n               + leaseToCheck, e);\n           removing.add(id);\n         }\n         if (isMaxLockHoldToReleaseLease(start)) {\n           LOG.debug(\"Breaking out of checkLeases after \" +\n               fsnamesystem.getMaxLockHoldToReleaseLeaseMs() + \"ms.\");\n           break;\n         }\n       }\n \n       for(Long id : removing) {\n         removeLease(leaseToCheck, id);\n       }\n     }\n \n     return needSync;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  synchronized boolean checkLeases() {\n    boolean needSync \u003d false;\n    assert fsnamesystem.hasWriteLock();\n\n    long start \u003d monotonicNow();\n\n    while(!sortedLeases.isEmpty() \u0026\u0026\n        sortedLeases.first().expiredHardLimit()\n        \u0026\u0026 !isMaxLockHoldToReleaseLease(start)) {\n      Lease leaseToCheck \u003d sortedLeases.first();\n      LOG.info(leaseToCheck + \" has expired hard limit\");\n\n      final List\u003cLong\u003e removing \u003d new ArrayList\u003c\u003e();\n      // need to create a copy of the oldest lease files, because\n      // internalReleaseLease() removes files corresponding to empty files,\n      // i.e. it needs to modify the collection being iterated over\n      // causing ConcurrentModificationException\n      Collection\u003cLong\u003e files \u003d leaseToCheck.getFiles();\n      Long[] leaseINodeIds \u003d files.toArray(new Long[files.size()]);\n      FSDirectory fsd \u003d fsnamesystem.getFSDirectory();\n      String p \u003d null;\n      String newHolder \u003d getInternalLeaseHolder();\n      for(Long id : leaseINodeIds) {\n        try {\n          INodesInPath iip \u003d INodesInPath.fromINode(fsd.getInode(id));\n          p \u003d iip.getPath();\n          // Sanity check to make sure the path is correct\n          if (!p.startsWith(\"/\")) {\n            throw new IOException(\"Invalid path in the lease \" + p);\n          }\n          boolean completed \u003d false;\n          try {\n            completed \u003d fsnamesystem.internalReleaseLease(\n                leaseToCheck, p, iip, newHolder);\n          } catch (IOException e) {\n            LOG.warn(\"Cannot release the path \" + p + \" in the lease \"\n                + leaseToCheck + \". It will be retried.\", e);\n            continue;\n          }\n          if (LOG.isDebugEnabled()) {\n            if (completed) {\n              LOG.debug(\"Lease recovery for inode \" + id + \" is complete. \" +\n                            \"File closed.\");\n            } else {\n              LOG.debug(\"Started block recovery \" + p + \" lease \" + leaseToCheck);\n            }\n          }\n          // If a lease recovery happened, we need to sync later.\n          if (!needSync \u0026\u0026 !completed) {\n            needSync \u003d true;\n          }\n        } catch (IOException e) {\n          LOG.warn(\"Removing lease with an invalid path: \" + p + \",\"\n              + leaseToCheck, e);\n          removing.add(id);\n        }\n        if (isMaxLockHoldToReleaseLease(start)) {\n          LOG.debug(\"Breaking out of checkLeases after \" +\n              fsnamesystem.getMaxLockHoldToReleaseLeaseMs() + \"ms.\");\n          break;\n        }\n      }\n\n      for(Long id : removing) {\n        removeLease(leaseToCheck, id);\n      }\n    }\n\n    return needSync;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/LeaseManager.java",
      "extendedDetails": {}
    },
    "1a33c9d58927186c2f219a5ecb5f1573801823ad": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11945. Internal lease recovery may not be retried for a long time. Contributed by Kihwal Lee\n",
      "commitDate": "08/06/17 2:36 PM",
      "commitName": "1a33c9d58927186c2f219a5ecb5f1573801823ad",
      "commitAuthor": "Mingliang Liu",
      "commitDateOld": "25/05/17 3:17 PM",
      "commitNameOld": "2b5ad48762587abbcd8bdb50d0ae98f8080d926c",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 13.97,
      "commitsBetweenForRepo": 64,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,69 +1,69 @@\n   synchronized boolean checkLeases() {\n     boolean needSync \u003d false;\n     assert fsnamesystem.hasWriteLock();\n \n     long start \u003d monotonicNow();\n \n     while(!sortedLeases.isEmpty() \u0026\u0026 sortedLeases.peek().expiredHardLimit()\n       \u0026\u0026 !isMaxLockHoldToReleaseLease(start)) {\n       Lease leaseToCheck \u003d sortedLeases.peek();\n       LOG.info(leaseToCheck + \" has expired hard limit\");\n \n       final List\u003cLong\u003e removing \u003d new ArrayList\u003c\u003e();\n       // need to create a copy of the oldest lease files, because\n       // internalReleaseLease() removes files corresponding to empty files,\n       // i.e. it needs to modify the collection being iterated over\n       // causing ConcurrentModificationException\n       Collection\u003cLong\u003e files \u003d leaseToCheck.getFiles();\n       Long[] leaseINodeIds \u003d files.toArray(new Long[files.size()]);\n       FSDirectory fsd \u003d fsnamesystem.getFSDirectory();\n       String p \u003d null;\n+      String newHolder \u003d getInternalLeaseHolder();\n       for(Long id : leaseINodeIds) {\n         try {\n           INodesInPath iip \u003d INodesInPath.fromINode(fsd.getInode(id));\n           p \u003d iip.getPath();\n           // Sanity check to make sure the path is correct\n           if (!p.startsWith(\"/\")) {\n             throw new IOException(\"Invalid path in the lease \" + p);\n           }\n           boolean completed \u003d false;\n           try {\n             completed \u003d fsnamesystem.internalReleaseLease(\n-                leaseToCheck, p, iip,\n-                HdfsServerConstants.NAMENODE_LEASE_HOLDER);\n+                leaseToCheck, p, iip, newHolder);\n           } catch (IOException e) {\n             LOG.warn(\"Cannot release the path \" + p + \" in the lease \"\n                 + leaseToCheck + \". It will be retried.\", e);\n             continue;\n           }\n           if (LOG.isDebugEnabled()) {\n             if (completed) {\n               LOG.debug(\"Lease recovery for inode \" + id + \" is complete. \" +\n                             \"File closed.\");\n             } else {\n               LOG.debug(\"Started block recovery \" + p + \" lease \" + leaseToCheck);\n             }\n           }\n           // If a lease recovery happened, we need to sync later.\n           if (!needSync \u0026\u0026 !completed) {\n             needSync \u003d true;\n           }\n         } catch (IOException e) {\n           LOG.warn(\"Removing lease with an invalid path: \" + p + \",\"\n               + leaseToCheck, e);\n           removing.add(id);\n         }\n         if (isMaxLockHoldToReleaseLease(start)) {\n           LOG.debug(\"Breaking out of checkLeases after \" +\n               fsnamesystem.getMaxLockHoldToReleaseLeaseMs() + \"ms.\");\n           break;\n         }\n       }\n \n       for(Long id : removing) {\n         removeLease(leaseToCheck, id);\n       }\n     }\n \n     return needSync;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  synchronized boolean checkLeases() {\n    boolean needSync \u003d false;\n    assert fsnamesystem.hasWriteLock();\n\n    long start \u003d monotonicNow();\n\n    while(!sortedLeases.isEmpty() \u0026\u0026 sortedLeases.peek().expiredHardLimit()\n      \u0026\u0026 !isMaxLockHoldToReleaseLease(start)) {\n      Lease leaseToCheck \u003d sortedLeases.peek();\n      LOG.info(leaseToCheck + \" has expired hard limit\");\n\n      final List\u003cLong\u003e removing \u003d new ArrayList\u003c\u003e();\n      // need to create a copy of the oldest lease files, because\n      // internalReleaseLease() removes files corresponding to empty files,\n      // i.e. it needs to modify the collection being iterated over\n      // causing ConcurrentModificationException\n      Collection\u003cLong\u003e files \u003d leaseToCheck.getFiles();\n      Long[] leaseINodeIds \u003d files.toArray(new Long[files.size()]);\n      FSDirectory fsd \u003d fsnamesystem.getFSDirectory();\n      String p \u003d null;\n      String newHolder \u003d getInternalLeaseHolder();\n      for(Long id : leaseINodeIds) {\n        try {\n          INodesInPath iip \u003d INodesInPath.fromINode(fsd.getInode(id));\n          p \u003d iip.getPath();\n          // Sanity check to make sure the path is correct\n          if (!p.startsWith(\"/\")) {\n            throw new IOException(\"Invalid path in the lease \" + p);\n          }\n          boolean completed \u003d false;\n          try {\n            completed \u003d fsnamesystem.internalReleaseLease(\n                leaseToCheck, p, iip, newHolder);\n          } catch (IOException e) {\n            LOG.warn(\"Cannot release the path \" + p + \" in the lease \"\n                + leaseToCheck + \". It will be retried.\", e);\n            continue;\n          }\n          if (LOG.isDebugEnabled()) {\n            if (completed) {\n              LOG.debug(\"Lease recovery for inode \" + id + \" is complete. \" +\n                            \"File closed.\");\n            } else {\n              LOG.debug(\"Started block recovery \" + p + \" lease \" + leaseToCheck);\n            }\n          }\n          // If a lease recovery happened, we need to sync later.\n          if (!needSync \u0026\u0026 !completed) {\n            needSync \u003d true;\n          }\n        } catch (IOException e) {\n          LOG.warn(\"Removing lease with an invalid path: \" + p + \",\"\n              + leaseToCheck, e);\n          removing.add(id);\n        }\n        if (isMaxLockHoldToReleaseLease(start)) {\n          LOG.debug(\"Breaking out of checkLeases after \" +\n              fsnamesystem.getMaxLockHoldToReleaseLeaseMs() + \"ms.\");\n          break;\n        }\n      }\n\n      for(Long id : removing) {\n        removeLease(leaseToCheck, id);\n      }\n    }\n\n    return needSync;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/LeaseManager.java",
      "extendedDetails": {}
    },
    "2b5ad48762587abbcd8bdb50d0ae98f8080d926c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11817. A faulty node can cause a lease leak and NPE on accessing data. Contributed by Kihwal Lee.\n",
      "commitDate": "25/05/17 3:17 PM",
      "commitName": "2b5ad48762587abbcd8bdb50d0ae98f8080d926c",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "21/04/17 8:35 PM",
      "commitNameOld": "20e3ae260b40cd6ef657b2a629a02219d68f162f",
      "commitAuthorOld": "Yongjun Zhang",
      "daysBetweenCommits": 33.78,
      "commitsBetweenForRepo": 188,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,62 +1,69 @@\n   synchronized boolean checkLeases() {\n     boolean needSync \u003d false;\n     assert fsnamesystem.hasWriteLock();\n \n     long start \u003d monotonicNow();\n \n     while(!sortedLeases.isEmpty() \u0026\u0026 sortedLeases.peek().expiredHardLimit()\n       \u0026\u0026 !isMaxLockHoldToReleaseLease(start)) {\n       Lease leaseToCheck \u003d sortedLeases.peek();\n       LOG.info(leaseToCheck + \" has expired hard limit\");\n \n       final List\u003cLong\u003e removing \u003d new ArrayList\u003c\u003e();\n       // need to create a copy of the oldest lease files, because\n       // internalReleaseLease() removes files corresponding to empty files,\n       // i.e. it needs to modify the collection being iterated over\n       // causing ConcurrentModificationException\n       Collection\u003cLong\u003e files \u003d leaseToCheck.getFiles();\n       Long[] leaseINodeIds \u003d files.toArray(new Long[files.size()]);\n       FSDirectory fsd \u003d fsnamesystem.getFSDirectory();\n       String p \u003d null;\n       for(Long id : leaseINodeIds) {\n         try {\n           INodesInPath iip \u003d INodesInPath.fromINode(fsd.getInode(id));\n           p \u003d iip.getPath();\n           // Sanity check to make sure the path is correct\n           if (!p.startsWith(\"/\")) {\n             throw new IOException(\"Invalid path in the lease \" + p);\n           }\n-          boolean completed \u003d fsnamesystem.internalReleaseLease(\n-              leaseToCheck, p, iip,\n-              HdfsServerConstants.NAMENODE_LEASE_HOLDER);\n+          boolean completed \u003d false;\n+          try {\n+            completed \u003d fsnamesystem.internalReleaseLease(\n+                leaseToCheck, p, iip,\n+                HdfsServerConstants.NAMENODE_LEASE_HOLDER);\n+          } catch (IOException e) {\n+            LOG.warn(\"Cannot release the path \" + p + \" in the lease \"\n+                + leaseToCheck + \". It will be retried.\", e);\n+            continue;\n+          }\n           if (LOG.isDebugEnabled()) {\n             if (completed) {\n               LOG.debug(\"Lease recovery for inode \" + id + \" is complete. \" +\n                             \"File closed.\");\n             } else {\n               LOG.debug(\"Started block recovery \" + p + \" lease \" + leaseToCheck);\n             }\n           }\n           // If a lease recovery happened, we need to sync later.\n           if (!needSync \u0026\u0026 !completed) {\n             needSync \u003d true;\n           }\n         } catch (IOException e) {\n-          LOG.error(\"Cannot release the path \" + p + \" in the lease \"\n+          LOG.warn(\"Removing lease with an invalid path: \" + p + \",\"\n               + leaseToCheck, e);\n           removing.add(id);\n         }\n         if (isMaxLockHoldToReleaseLease(start)) {\n           LOG.debug(\"Breaking out of checkLeases after \" +\n               fsnamesystem.getMaxLockHoldToReleaseLeaseMs() + \"ms.\");\n           break;\n         }\n       }\n \n       for(Long id : removing) {\n         removeLease(leaseToCheck, id);\n       }\n     }\n \n     return needSync;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  synchronized boolean checkLeases() {\n    boolean needSync \u003d false;\n    assert fsnamesystem.hasWriteLock();\n\n    long start \u003d monotonicNow();\n\n    while(!sortedLeases.isEmpty() \u0026\u0026 sortedLeases.peek().expiredHardLimit()\n      \u0026\u0026 !isMaxLockHoldToReleaseLease(start)) {\n      Lease leaseToCheck \u003d sortedLeases.peek();\n      LOG.info(leaseToCheck + \" has expired hard limit\");\n\n      final List\u003cLong\u003e removing \u003d new ArrayList\u003c\u003e();\n      // need to create a copy of the oldest lease files, because\n      // internalReleaseLease() removes files corresponding to empty files,\n      // i.e. it needs to modify the collection being iterated over\n      // causing ConcurrentModificationException\n      Collection\u003cLong\u003e files \u003d leaseToCheck.getFiles();\n      Long[] leaseINodeIds \u003d files.toArray(new Long[files.size()]);\n      FSDirectory fsd \u003d fsnamesystem.getFSDirectory();\n      String p \u003d null;\n      for(Long id : leaseINodeIds) {\n        try {\n          INodesInPath iip \u003d INodesInPath.fromINode(fsd.getInode(id));\n          p \u003d iip.getPath();\n          // Sanity check to make sure the path is correct\n          if (!p.startsWith(\"/\")) {\n            throw new IOException(\"Invalid path in the lease \" + p);\n          }\n          boolean completed \u003d false;\n          try {\n            completed \u003d fsnamesystem.internalReleaseLease(\n                leaseToCheck, p, iip,\n                HdfsServerConstants.NAMENODE_LEASE_HOLDER);\n          } catch (IOException e) {\n            LOG.warn(\"Cannot release the path \" + p + \" in the lease \"\n                + leaseToCheck + \". It will be retried.\", e);\n            continue;\n          }\n          if (LOG.isDebugEnabled()) {\n            if (completed) {\n              LOG.debug(\"Lease recovery for inode \" + id + \" is complete. \" +\n                            \"File closed.\");\n            } else {\n              LOG.debug(\"Started block recovery \" + p + \" lease \" + leaseToCheck);\n            }\n          }\n          // If a lease recovery happened, we need to sync later.\n          if (!needSync \u0026\u0026 !completed) {\n            needSync \u003d true;\n          }\n        } catch (IOException e) {\n          LOG.warn(\"Removing lease with an invalid path: \" + p + \",\"\n              + leaseToCheck, e);\n          removing.add(id);\n        }\n        if (isMaxLockHoldToReleaseLease(start)) {\n          LOG.debug(\"Breaking out of checkLeases after \" +\n              fsnamesystem.getMaxLockHoldToReleaseLeaseMs() + \"ms.\");\n          break;\n        }\n      }\n\n      for(Long id : removing) {\n        removeLease(leaseToCheck, id);\n      }\n    }\n\n    return needSync;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/LeaseManager.java",
      "extendedDetails": {}
    },
    "ae047655f4355288406cd5396fb4e3ea7c307b14": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10220. A large number of expired leases can make namenode unresponsive and cause failover (Nicolas Fraison via raviprak)\n",
      "commitDate": "08/06/16 1:44 PM",
      "commitName": "ae047655f4355288406cd5396fb4e3ea7c307b14",
      "commitAuthor": "Ravi Prakash",
      "commitDateOld": "25/01/16 6:32 PM",
      "commitNameOld": "bd909ed9f2d853f614f04a50e2230a7932732776",
      "commitAuthorOld": "Tsz-Wo Nicholas Sze",
      "daysBetweenCommits": 134.76,
      "commitsBetweenForRepo": 875,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,54 +1,62 @@\n   synchronized boolean checkLeases() {\n     boolean needSync \u003d false;\n     assert fsnamesystem.hasWriteLock();\n \n-    while(!sortedLeases.isEmpty() \u0026\u0026 sortedLeases.peek().expiredHardLimit()) {\n-      Lease leaseToCheck \u003d sortedLeases.poll();\n+    long start \u003d monotonicNow();\n+\n+    while(!sortedLeases.isEmpty() \u0026\u0026 sortedLeases.peek().expiredHardLimit()\n+      \u0026\u0026 !isMaxLockHoldToReleaseLease(start)) {\n+      Lease leaseToCheck \u003d sortedLeases.peek();\n       LOG.info(leaseToCheck + \" has expired hard limit\");\n \n       final List\u003cLong\u003e removing \u003d new ArrayList\u003c\u003e();\n       // need to create a copy of the oldest lease files, because\n       // internalReleaseLease() removes files corresponding to empty files,\n       // i.e. it needs to modify the collection being iterated over\n       // causing ConcurrentModificationException\n       Collection\u003cLong\u003e files \u003d leaseToCheck.getFiles();\n       Long[] leaseINodeIds \u003d files.toArray(new Long[files.size()]);\n       FSDirectory fsd \u003d fsnamesystem.getFSDirectory();\n       String p \u003d null;\n       for(Long id : leaseINodeIds) {\n         try {\n           INodesInPath iip \u003d INodesInPath.fromINode(fsd.getInode(id));\n           p \u003d iip.getPath();\n           // Sanity check to make sure the path is correct\n           if (!p.startsWith(\"/\")) {\n             throw new IOException(\"Invalid path in the lease \" + p);\n           }\n           boolean completed \u003d fsnamesystem.internalReleaseLease(\n               leaseToCheck, p, iip,\n               HdfsServerConstants.NAMENODE_LEASE_HOLDER);\n           if (LOG.isDebugEnabled()) {\n             if (completed) {\n               LOG.debug(\"Lease recovery for inode \" + id + \" is complete. \" +\n                             \"File closed.\");\n             } else {\n               LOG.debug(\"Started block recovery \" + p + \" lease \" + leaseToCheck);\n             }\n           }\n           // If a lease recovery happened, we need to sync later.\n           if (!needSync \u0026\u0026 !completed) {\n             needSync \u003d true;\n           }\n         } catch (IOException e) {\n           LOG.error(\"Cannot release the path \" + p + \" in the lease \"\n               + leaseToCheck, e);\n           removing.add(id);\n         }\n+        if (isMaxLockHoldToReleaseLease(start)) {\n+          LOG.debug(\"Breaking out of checkLeases after \" +\n+              fsnamesystem.getMaxLockHoldToReleaseLeaseMs() + \"ms.\");\n+          break;\n+        }\n       }\n \n       for(Long id : removing) {\n         removeLease(leaseToCheck, id);\n       }\n     }\n \n     return needSync;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  synchronized boolean checkLeases() {\n    boolean needSync \u003d false;\n    assert fsnamesystem.hasWriteLock();\n\n    long start \u003d monotonicNow();\n\n    while(!sortedLeases.isEmpty() \u0026\u0026 sortedLeases.peek().expiredHardLimit()\n      \u0026\u0026 !isMaxLockHoldToReleaseLease(start)) {\n      Lease leaseToCheck \u003d sortedLeases.peek();\n      LOG.info(leaseToCheck + \" has expired hard limit\");\n\n      final List\u003cLong\u003e removing \u003d new ArrayList\u003c\u003e();\n      // need to create a copy of the oldest lease files, because\n      // internalReleaseLease() removes files corresponding to empty files,\n      // i.e. it needs to modify the collection being iterated over\n      // causing ConcurrentModificationException\n      Collection\u003cLong\u003e files \u003d leaseToCheck.getFiles();\n      Long[] leaseINodeIds \u003d files.toArray(new Long[files.size()]);\n      FSDirectory fsd \u003d fsnamesystem.getFSDirectory();\n      String p \u003d null;\n      for(Long id : leaseINodeIds) {\n        try {\n          INodesInPath iip \u003d INodesInPath.fromINode(fsd.getInode(id));\n          p \u003d iip.getPath();\n          // Sanity check to make sure the path is correct\n          if (!p.startsWith(\"/\")) {\n            throw new IOException(\"Invalid path in the lease \" + p);\n          }\n          boolean completed \u003d fsnamesystem.internalReleaseLease(\n              leaseToCheck, p, iip,\n              HdfsServerConstants.NAMENODE_LEASE_HOLDER);\n          if (LOG.isDebugEnabled()) {\n            if (completed) {\n              LOG.debug(\"Lease recovery for inode \" + id + \" is complete. \" +\n                            \"File closed.\");\n            } else {\n              LOG.debug(\"Started block recovery \" + p + \" lease \" + leaseToCheck);\n            }\n          }\n          // If a lease recovery happened, we need to sync later.\n          if (!needSync \u0026\u0026 !completed) {\n            needSync \u003d true;\n          }\n        } catch (IOException e) {\n          LOG.error(\"Cannot release the path \" + p + \" in the lease \"\n              + leaseToCheck, e);\n          removing.add(id);\n        }\n        if (isMaxLockHoldToReleaseLease(start)) {\n          LOG.debug(\"Breaking out of checkLeases after \" +\n              fsnamesystem.getMaxLockHoldToReleaseLeaseMs() + \"ms.\");\n          break;\n        }\n      }\n\n      for(Long id : removing) {\n        removeLease(leaseToCheck, id);\n      }\n    }\n\n    return needSync;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/LeaseManager.java",
      "extendedDetails": {}
    },
    "00fe1ed3a4b3ee35fe24be257ec36445d2f44d63": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6757. Simplify lease manager with INodeID. Contributed by Haohui Mai.\n",
      "commitDate": "08/05/15 11:04 PM",
      "commitName": "00fe1ed3a4b3ee35fe24be257ec36445d2f44d63",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "02/05/15 10:03 AM",
      "commitNameOld": "6ae2a0d048e133b43249c248a75a4d77d9abb80d",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 6.54,
      "commitsBetweenForRepo": 129,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,60 +1,54 @@\n   synchronized boolean checkLeases() {\n     boolean needSync \u003d false;\n     assert fsnamesystem.hasWriteLock();\n-    Lease leaseToCheck \u003d null;\n-    try {\n-      leaseToCheck \u003d sortedLeases.first();\n-    } catch(NoSuchElementException e) {}\n \n-    while(leaseToCheck !\u003d null) {\n-      if (!leaseToCheck.expiredHardLimit()) {\n-        break;\n-      }\n-\n+    while(!sortedLeases.isEmpty() \u0026\u0026 sortedLeases.peek().expiredHardLimit()) {\n+      Lease leaseToCheck \u003d sortedLeases.poll();\n       LOG.info(leaseToCheck + \" has expired hard limit\");\n \n-      final List\u003cString\u003e removing \u003d new ArrayList\u003cString\u003e();\n-      // need to create a copy of the oldest lease paths, because \n-      // internalReleaseLease() removes paths corresponding to empty files,\n+      final List\u003cLong\u003e removing \u003d new ArrayList\u003c\u003e();\n+      // need to create a copy of the oldest lease files, because\n+      // internalReleaseLease() removes files corresponding to empty files,\n       // i.e. it needs to modify the collection being iterated over\n       // causing ConcurrentModificationException\n-      String[] leasePaths \u003d new String[leaseToCheck.getPaths().size()];\n-      leaseToCheck.getPaths().toArray(leasePaths);\n-      for(String p : leasePaths) {\n+      Collection\u003cLong\u003e files \u003d leaseToCheck.getFiles();\n+      Long[] leaseINodeIds \u003d files.toArray(new Long[files.size()]);\n+      FSDirectory fsd \u003d fsnamesystem.getFSDirectory();\n+      String p \u003d null;\n+      for(Long id : leaseINodeIds) {\n         try {\n-          INodesInPath iip \u003d fsnamesystem.getFSDirectory().getINodesInPath(p,\n-              true);\n-          boolean completed \u003d fsnamesystem.internalReleaseLease(leaseToCheck, p,\n-              iip, HdfsServerConstants.NAMENODE_LEASE_HOLDER);\n+          INodesInPath iip \u003d INodesInPath.fromINode(fsd.getInode(id));\n+          p \u003d iip.getPath();\n+          // Sanity check to make sure the path is correct\n+          if (!p.startsWith(\"/\")) {\n+            throw new IOException(\"Invalid path in the lease \" + p);\n+          }\n+          boolean completed \u003d fsnamesystem.internalReleaseLease(\n+              leaseToCheck, p, iip,\n+              HdfsServerConstants.NAMENODE_LEASE_HOLDER);\n           if (LOG.isDebugEnabled()) {\n             if (completed) {\n-              LOG.debug(\"Lease recovery for \" + p + \" is complete. File closed.\");\n+              LOG.debug(\"Lease recovery for inode \" + id + \" is complete. \" +\n+                            \"File closed.\");\n             } else {\n               LOG.debug(\"Started block recovery \" + p + \" lease \" + leaseToCheck);\n             }\n           }\n           // If a lease recovery happened, we need to sync later.\n           if (!needSync \u0026\u0026 !completed) {\n             needSync \u003d true;\n           }\n         } catch (IOException e) {\n           LOG.error(\"Cannot release the path \" + p + \" in the lease \"\n               + leaseToCheck, e);\n-          removing.add(p);\n+          removing.add(id);\n         }\n       }\n \n-      for(String p : removing) {\n-        removeLease(leaseToCheck, p);\n+      for(Long id : removing) {\n+        removeLease(leaseToCheck, id);\n       }\n-      leaseToCheck \u003d sortedLeases.higher(leaseToCheck);\n     }\n \n-    try {\n-      if(leaseToCheck !\u003d sortedLeases.first()) {\n-        LOG.warn(\"Unable to release hard-limit expired lease: \"\n-          + sortedLeases.first());\n-      }\n-    } catch(NoSuchElementException e) {}\n     return needSync;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  synchronized boolean checkLeases() {\n    boolean needSync \u003d false;\n    assert fsnamesystem.hasWriteLock();\n\n    while(!sortedLeases.isEmpty() \u0026\u0026 sortedLeases.peek().expiredHardLimit()) {\n      Lease leaseToCheck \u003d sortedLeases.poll();\n      LOG.info(leaseToCheck + \" has expired hard limit\");\n\n      final List\u003cLong\u003e removing \u003d new ArrayList\u003c\u003e();\n      // need to create a copy of the oldest lease files, because\n      // internalReleaseLease() removes files corresponding to empty files,\n      // i.e. it needs to modify the collection being iterated over\n      // causing ConcurrentModificationException\n      Collection\u003cLong\u003e files \u003d leaseToCheck.getFiles();\n      Long[] leaseINodeIds \u003d files.toArray(new Long[files.size()]);\n      FSDirectory fsd \u003d fsnamesystem.getFSDirectory();\n      String p \u003d null;\n      for(Long id : leaseINodeIds) {\n        try {\n          INodesInPath iip \u003d INodesInPath.fromINode(fsd.getInode(id));\n          p \u003d iip.getPath();\n          // Sanity check to make sure the path is correct\n          if (!p.startsWith(\"/\")) {\n            throw new IOException(\"Invalid path in the lease \" + p);\n          }\n          boolean completed \u003d fsnamesystem.internalReleaseLease(\n              leaseToCheck, p, iip,\n              HdfsServerConstants.NAMENODE_LEASE_HOLDER);\n          if (LOG.isDebugEnabled()) {\n            if (completed) {\n              LOG.debug(\"Lease recovery for inode \" + id + \" is complete. \" +\n                            \"File closed.\");\n            } else {\n              LOG.debug(\"Started block recovery \" + p + \" lease \" + leaseToCheck);\n            }\n          }\n          // If a lease recovery happened, we need to sync later.\n          if (!needSync \u0026\u0026 !completed) {\n            needSync \u003d true;\n          }\n        } catch (IOException e) {\n          LOG.error(\"Cannot release the path \" + p + \" in the lease \"\n              + leaseToCheck, e);\n          removing.add(id);\n        }\n      }\n\n      for(Long id : removing) {\n        removeLease(leaseToCheck, id);\n      }\n    }\n\n    return needSync;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/LeaseManager.java",
      "extendedDetails": {}
    },
    "c78e3a7cdd10c40454e9acb06986ba6d8573cb19": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7059. Avoid resolving path multiple times. Contributed by Jing Zhao.\n",
      "commitDate": "12/12/14 3:13 PM",
      "commitName": "c78e3a7cdd10c40454e9acb06986ba6d8573cb19",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "24/11/14 10:46 AM",
      "commitNameOld": "daacbc18d739d030822df0b75205eeb067f89850",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 18.19,
      "commitsBetweenForRepo": 124,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,58 +1,60 @@\n   synchronized boolean checkLeases() {\n     boolean needSync \u003d false;\n     assert fsnamesystem.hasWriteLock();\n     Lease leaseToCheck \u003d null;\n     try {\n       leaseToCheck \u003d sortedLeases.first();\n     } catch(NoSuchElementException e) {}\n \n     while(leaseToCheck !\u003d null) {\n       if (!leaseToCheck.expiredHardLimit()) {\n         break;\n       }\n \n       LOG.info(leaseToCheck + \" has expired hard limit\");\n \n       final List\u003cString\u003e removing \u003d new ArrayList\u003cString\u003e();\n       // need to create a copy of the oldest lease paths, because \n       // internalReleaseLease() removes paths corresponding to empty files,\n       // i.e. it needs to modify the collection being iterated over\n       // causing ConcurrentModificationException\n       String[] leasePaths \u003d new String[leaseToCheck.getPaths().size()];\n       leaseToCheck.getPaths().toArray(leasePaths);\n       for(String p : leasePaths) {\n         try {\n+          INodesInPath iip \u003d fsnamesystem.getFSDirectory().getINodesInPath(p,\n+              true);\n           boolean completed \u003d fsnamesystem.internalReleaseLease(leaseToCheck, p,\n-              HdfsServerConstants.NAMENODE_LEASE_HOLDER);\n+              iip, HdfsServerConstants.NAMENODE_LEASE_HOLDER);\n           if (LOG.isDebugEnabled()) {\n             if (completed) {\n               LOG.debug(\"Lease recovery for \" + p + \" is complete. File closed.\");\n             } else {\n               LOG.debug(\"Started block recovery \" + p + \" lease \" + leaseToCheck);\n             }\n           }\n           // If a lease recovery happened, we need to sync later.\n           if (!needSync \u0026\u0026 !completed) {\n             needSync \u003d true;\n           }\n         } catch (IOException e) {\n           LOG.error(\"Cannot release the path \" + p + \" in the lease \"\n               + leaseToCheck, e);\n           removing.add(p);\n         }\n       }\n \n       for(String p : removing) {\n         removeLease(leaseToCheck, p);\n       }\n       leaseToCheck \u003d sortedLeases.higher(leaseToCheck);\n     }\n \n     try {\n       if(leaseToCheck !\u003d sortedLeases.first()) {\n         LOG.warn(\"Unable to release hard-limit expired lease: \"\n           + sortedLeases.first());\n       }\n     } catch(NoSuchElementException e) {}\n     return needSync;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  synchronized boolean checkLeases() {\n    boolean needSync \u003d false;\n    assert fsnamesystem.hasWriteLock();\n    Lease leaseToCheck \u003d null;\n    try {\n      leaseToCheck \u003d sortedLeases.first();\n    } catch(NoSuchElementException e) {}\n\n    while(leaseToCheck !\u003d null) {\n      if (!leaseToCheck.expiredHardLimit()) {\n        break;\n      }\n\n      LOG.info(leaseToCheck + \" has expired hard limit\");\n\n      final List\u003cString\u003e removing \u003d new ArrayList\u003cString\u003e();\n      // need to create a copy of the oldest lease paths, because \n      // internalReleaseLease() removes paths corresponding to empty files,\n      // i.e. it needs to modify the collection being iterated over\n      // causing ConcurrentModificationException\n      String[] leasePaths \u003d new String[leaseToCheck.getPaths().size()];\n      leaseToCheck.getPaths().toArray(leasePaths);\n      for(String p : leasePaths) {\n        try {\n          INodesInPath iip \u003d fsnamesystem.getFSDirectory().getINodesInPath(p,\n              true);\n          boolean completed \u003d fsnamesystem.internalReleaseLease(leaseToCheck, p,\n              iip, HdfsServerConstants.NAMENODE_LEASE_HOLDER);\n          if (LOG.isDebugEnabled()) {\n            if (completed) {\n              LOG.debug(\"Lease recovery for \" + p + \" is complete. File closed.\");\n            } else {\n              LOG.debug(\"Started block recovery \" + p + \" lease \" + leaseToCheck);\n            }\n          }\n          // If a lease recovery happened, we need to sync later.\n          if (!needSync \u0026\u0026 !completed) {\n            needSync \u003d true;\n          }\n        } catch (IOException e) {\n          LOG.error(\"Cannot release the path \" + p + \" in the lease \"\n              + leaseToCheck, e);\n          removing.add(p);\n        }\n      }\n\n      for(String p : removing) {\n        removeLease(leaseToCheck, p);\n      }\n      leaseToCheck \u003d sortedLeases.higher(leaseToCheck);\n    }\n\n    try {\n      if(leaseToCheck !\u003d sortedLeases.first()) {\n        LOG.warn(\"Unable to release hard-limit expired lease: \"\n          + sortedLeases.first());\n      }\n    } catch(NoSuchElementException e) {}\n    return needSync;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/LeaseManager.java",
      "extendedDetails": {}
    },
    "daacbc18d739d030822df0b75205eeb067f89850": {
      "type": "Ymultichange(Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-4882. Prevent the Namenode\u0027s LeaseManager from looping forever in checkLeases (Ravi Prakash via Colin P. McCabe)\n",
      "commitDate": "24/11/14 10:46 AM",
      "commitName": "daacbc18d739d030822df0b75205eeb067f89850",
      "commitAuthor": "Colin Patrick Mccabe",
      "subchanges": [
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-4882. Prevent the Namenode\u0027s LeaseManager from looping forever in checkLeases (Ravi Prakash via Colin P. McCabe)\n",
          "commitDate": "24/11/14 10:46 AM",
          "commitName": "daacbc18d739d030822df0b75205eeb067f89850",
          "commitAuthor": "Colin Patrick Mccabe",
          "commitDateOld": "23/04/14 1:13 PM",
          "commitNameOld": "876fd8ab7913a259ff9f69c16cc2d9af46ad3f9b",
          "commitAuthorOld": "Suresh Srinivas",
          "daysBetweenCommits": 214.94,
          "commitsBetweenForRepo": 1801,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,46 +1,58 @@\n-  private synchronized boolean checkLeases() {\n+  synchronized boolean checkLeases() {\n     boolean needSync \u003d false;\n     assert fsnamesystem.hasWriteLock();\n-    for(; sortedLeases.size() \u003e 0; ) {\n-      final Lease oldest \u003d sortedLeases.first();\n-      if (!oldest.expiredHardLimit()) {\n-        return needSync;\n+    Lease leaseToCheck \u003d null;\n+    try {\n+      leaseToCheck \u003d sortedLeases.first();\n+    } catch(NoSuchElementException e) {}\n+\n+    while(leaseToCheck !\u003d null) {\n+      if (!leaseToCheck.expiredHardLimit()) {\n+        break;\n       }\n \n-      LOG.info(oldest + \" has expired hard limit\");\n+      LOG.info(leaseToCheck + \" has expired hard limit\");\n \n       final List\u003cString\u003e removing \u003d new ArrayList\u003cString\u003e();\n-      // need to create a copy of the oldest lease paths, becuase \n+      // need to create a copy of the oldest lease paths, because \n       // internalReleaseLease() removes paths corresponding to empty files,\n       // i.e. it needs to modify the collection being iterated over\n       // causing ConcurrentModificationException\n-      String[] leasePaths \u003d new String[oldest.getPaths().size()];\n-      oldest.getPaths().toArray(leasePaths);\n+      String[] leasePaths \u003d new String[leaseToCheck.getPaths().size()];\n+      leaseToCheck.getPaths().toArray(leasePaths);\n       for(String p : leasePaths) {\n         try {\n-          boolean completed \u003d fsnamesystem.internalReleaseLease(oldest, p,\n+          boolean completed \u003d fsnamesystem.internalReleaseLease(leaseToCheck, p,\n               HdfsServerConstants.NAMENODE_LEASE_HOLDER);\n           if (LOG.isDebugEnabled()) {\n             if (completed) {\n               LOG.debug(\"Lease recovery for \" + p + \" is complete. File closed.\");\n             } else {\n-              LOG.debug(\"Started block recovery \" + p + \" lease \" + oldest);\n+              LOG.debug(\"Started block recovery \" + p + \" lease \" + leaseToCheck);\n             }\n           }\n           // If a lease recovery happened, we need to sync later.\n           if (!needSync \u0026\u0026 !completed) {\n             needSync \u003d true;\n           }\n         } catch (IOException e) {\n           LOG.error(\"Cannot release the path \" + p + \" in the lease \"\n-              + oldest, e);\n+              + leaseToCheck, e);\n           removing.add(p);\n         }\n       }\n \n       for(String p : removing) {\n-        removeLease(oldest, p);\n+        removeLease(leaseToCheck, p);\n       }\n+      leaseToCheck \u003d sortedLeases.higher(leaseToCheck);\n     }\n+\n+    try {\n+      if(leaseToCheck !\u003d sortedLeases.first()) {\n+        LOG.warn(\"Unable to release hard-limit expired lease: \"\n+          + sortedLeases.first());\n+      }\n+    } catch(NoSuchElementException e) {}\n     return needSync;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  synchronized boolean checkLeases() {\n    boolean needSync \u003d false;\n    assert fsnamesystem.hasWriteLock();\n    Lease leaseToCheck \u003d null;\n    try {\n      leaseToCheck \u003d sortedLeases.first();\n    } catch(NoSuchElementException e) {}\n\n    while(leaseToCheck !\u003d null) {\n      if (!leaseToCheck.expiredHardLimit()) {\n        break;\n      }\n\n      LOG.info(leaseToCheck + \" has expired hard limit\");\n\n      final List\u003cString\u003e removing \u003d new ArrayList\u003cString\u003e();\n      // need to create a copy of the oldest lease paths, because \n      // internalReleaseLease() removes paths corresponding to empty files,\n      // i.e. it needs to modify the collection being iterated over\n      // causing ConcurrentModificationException\n      String[] leasePaths \u003d new String[leaseToCheck.getPaths().size()];\n      leaseToCheck.getPaths().toArray(leasePaths);\n      for(String p : leasePaths) {\n        try {\n          boolean completed \u003d fsnamesystem.internalReleaseLease(leaseToCheck, p,\n              HdfsServerConstants.NAMENODE_LEASE_HOLDER);\n          if (LOG.isDebugEnabled()) {\n            if (completed) {\n              LOG.debug(\"Lease recovery for \" + p + \" is complete. File closed.\");\n            } else {\n              LOG.debug(\"Started block recovery \" + p + \" lease \" + leaseToCheck);\n            }\n          }\n          // If a lease recovery happened, we need to sync later.\n          if (!needSync \u0026\u0026 !completed) {\n            needSync \u003d true;\n          }\n        } catch (IOException e) {\n          LOG.error(\"Cannot release the path \" + p + \" in the lease \"\n              + leaseToCheck, e);\n          removing.add(p);\n        }\n      }\n\n      for(String p : removing) {\n        removeLease(leaseToCheck, p);\n      }\n      leaseToCheck \u003d sortedLeases.higher(leaseToCheck);\n    }\n\n    try {\n      if(leaseToCheck !\u003d sortedLeases.first()) {\n        LOG.warn(\"Unable to release hard-limit expired lease: \"\n          + sortedLeases.first());\n      }\n    } catch(NoSuchElementException e) {}\n    return needSync;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/LeaseManager.java",
          "extendedDetails": {
            "oldValue": "[private, synchronized]",
            "newValue": "[synchronized]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-4882. Prevent the Namenode\u0027s LeaseManager from looping forever in checkLeases (Ravi Prakash via Colin P. McCabe)\n",
          "commitDate": "24/11/14 10:46 AM",
          "commitName": "daacbc18d739d030822df0b75205eeb067f89850",
          "commitAuthor": "Colin Patrick Mccabe",
          "commitDateOld": "23/04/14 1:13 PM",
          "commitNameOld": "876fd8ab7913a259ff9f69c16cc2d9af46ad3f9b",
          "commitAuthorOld": "Suresh Srinivas",
          "daysBetweenCommits": 214.94,
          "commitsBetweenForRepo": 1801,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,46 +1,58 @@\n-  private synchronized boolean checkLeases() {\n+  synchronized boolean checkLeases() {\n     boolean needSync \u003d false;\n     assert fsnamesystem.hasWriteLock();\n-    for(; sortedLeases.size() \u003e 0; ) {\n-      final Lease oldest \u003d sortedLeases.first();\n-      if (!oldest.expiredHardLimit()) {\n-        return needSync;\n+    Lease leaseToCheck \u003d null;\n+    try {\n+      leaseToCheck \u003d sortedLeases.first();\n+    } catch(NoSuchElementException e) {}\n+\n+    while(leaseToCheck !\u003d null) {\n+      if (!leaseToCheck.expiredHardLimit()) {\n+        break;\n       }\n \n-      LOG.info(oldest + \" has expired hard limit\");\n+      LOG.info(leaseToCheck + \" has expired hard limit\");\n \n       final List\u003cString\u003e removing \u003d new ArrayList\u003cString\u003e();\n-      // need to create a copy of the oldest lease paths, becuase \n+      // need to create a copy of the oldest lease paths, because \n       // internalReleaseLease() removes paths corresponding to empty files,\n       // i.e. it needs to modify the collection being iterated over\n       // causing ConcurrentModificationException\n-      String[] leasePaths \u003d new String[oldest.getPaths().size()];\n-      oldest.getPaths().toArray(leasePaths);\n+      String[] leasePaths \u003d new String[leaseToCheck.getPaths().size()];\n+      leaseToCheck.getPaths().toArray(leasePaths);\n       for(String p : leasePaths) {\n         try {\n-          boolean completed \u003d fsnamesystem.internalReleaseLease(oldest, p,\n+          boolean completed \u003d fsnamesystem.internalReleaseLease(leaseToCheck, p,\n               HdfsServerConstants.NAMENODE_LEASE_HOLDER);\n           if (LOG.isDebugEnabled()) {\n             if (completed) {\n               LOG.debug(\"Lease recovery for \" + p + \" is complete. File closed.\");\n             } else {\n-              LOG.debug(\"Started block recovery \" + p + \" lease \" + oldest);\n+              LOG.debug(\"Started block recovery \" + p + \" lease \" + leaseToCheck);\n             }\n           }\n           // If a lease recovery happened, we need to sync later.\n           if (!needSync \u0026\u0026 !completed) {\n             needSync \u003d true;\n           }\n         } catch (IOException e) {\n           LOG.error(\"Cannot release the path \" + p + \" in the lease \"\n-              + oldest, e);\n+              + leaseToCheck, e);\n           removing.add(p);\n         }\n       }\n \n       for(String p : removing) {\n-        removeLease(oldest, p);\n+        removeLease(leaseToCheck, p);\n       }\n+      leaseToCheck \u003d sortedLeases.higher(leaseToCheck);\n     }\n+\n+    try {\n+      if(leaseToCheck !\u003d sortedLeases.first()) {\n+        LOG.warn(\"Unable to release hard-limit expired lease: \"\n+          + sortedLeases.first());\n+      }\n+    } catch(NoSuchElementException e) {}\n     return needSync;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  synchronized boolean checkLeases() {\n    boolean needSync \u003d false;\n    assert fsnamesystem.hasWriteLock();\n    Lease leaseToCheck \u003d null;\n    try {\n      leaseToCheck \u003d sortedLeases.first();\n    } catch(NoSuchElementException e) {}\n\n    while(leaseToCheck !\u003d null) {\n      if (!leaseToCheck.expiredHardLimit()) {\n        break;\n      }\n\n      LOG.info(leaseToCheck + \" has expired hard limit\");\n\n      final List\u003cString\u003e removing \u003d new ArrayList\u003cString\u003e();\n      // need to create a copy of the oldest lease paths, because \n      // internalReleaseLease() removes paths corresponding to empty files,\n      // i.e. it needs to modify the collection being iterated over\n      // causing ConcurrentModificationException\n      String[] leasePaths \u003d new String[leaseToCheck.getPaths().size()];\n      leaseToCheck.getPaths().toArray(leasePaths);\n      for(String p : leasePaths) {\n        try {\n          boolean completed \u003d fsnamesystem.internalReleaseLease(leaseToCheck, p,\n              HdfsServerConstants.NAMENODE_LEASE_HOLDER);\n          if (LOG.isDebugEnabled()) {\n            if (completed) {\n              LOG.debug(\"Lease recovery for \" + p + \" is complete. File closed.\");\n            } else {\n              LOG.debug(\"Started block recovery \" + p + \" lease \" + leaseToCheck);\n            }\n          }\n          // If a lease recovery happened, we need to sync later.\n          if (!needSync \u0026\u0026 !completed) {\n            needSync \u003d true;\n          }\n        } catch (IOException e) {\n          LOG.error(\"Cannot release the path \" + p + \" in the lease \"\n              + leaseToCheck, e);\n          removing.add(p);\n        }\n      }\n\n      for(String p : removing) {\n        removeLease(leaseToCheck, p);\n      }\n      leaseToCheck \u003d sortedLeases.higher(leaseToCheck);\n    }\n\n    try {\n      if(leaseToCheck !\u003d sortedLeases.first()) {\n        LOG.warn(\"Unable to release hard-limit expired lease: \"\n          + sortedLeases.first());\n      }\n    } catch(NoSuchElementException e) {}\n    return needSync;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/LeaseManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "298eb4265702362d14d7c375983bcd85371ab9af": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-4186. logSync() is called with the write lock held while releasing lease (Kihwal Lee via daryn)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1409988 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "15/11/12 12:33 PM",
      "commitName": "298eb4265702362d14d7c375983bcd85371ab9af",
      "commitAuthor": "Daryn Sharp",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-4186. logSync() is called with the write lock held while releasing lease (Kihwal Lee via daryn)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1409988 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "15/11/12 12:33 PM",
          "commitName": "298eb4265702362d14d7c375983bcd85371ab9af",
          "commitAuthor": "Daryn Sharp",
          "commitDateOld": "13/11/12 7:29 AM",
          "commitNameOld": "47410642500e6f0d61c5d2f479d1d3673e6ebf35",
          "commitAuthorOld": "Daryn Sharp",
          "daysBetweenCommits": 2.21,
          "commitsBetweenForRepo": 23,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,40 +1,46 @@\n-  private synchronized void checkLeases() {\n+  private synchronized boolean checkLeases() {\n+    boolean needSync \u003d false;\n     assert fsnamesystem.hasWriteLock();\n     for(; sortedLeases.size() \u003e 0; ) {\n       final Lease oldest \u003d sortedLeases.first();\n       if (!oldest.expiredHardLimit()) {\n-        return;\n+        return needSync;\n       }\n \n       LOG.info(oldest + \" has expired hard limit\");\n \n       final List\u003cString\u003e removing \u003d new ArrayList\u003cString\u003e();\n       // need to create a copy of the oldest lease paths, becuase \n       // internalReleaseLease() removes paths corresponding to empty files,\n       // i.e. it needs to modify the collection being iterated over\n       // causing ConcurrentModificationException\n       String[] leasePaths \u003d new String[oldest.getPaths().size()];\n       oldest.getPaths().toArray(leasePaths);\n       for(String p : leasePaths) {\n         try {\n           boolean completed \u003d fsnamesystem.internalReleaseLease(oldest, p,\n               HdfsServerConstants.NAMENODE_LEASE_HOLDER);\n           if (LOG.isDebugEnabled()) {\n             if (completed) {\n               LOG.debug(\"Lease recovery for \" + p + \" is complete. File closed.\");\n             } else {\n               LOG.debug(\"Started block recovery \" + p + \" lease \" + oldest);\n             }\n           }\n+          // If a lease recovery happened, we need to sync later.\n+          if (!needSync \u0026\u0026 !completed) {\n+            needSync \u003d true;\n+          }\n         } catch (IOException e) {\n           LOG.error(\"Cannot release the path \" + p + \" in the lease \"\n               + oldest, e);\n           removing.add(p);\n         }\n       }\n \n       for(String p : removing) {\n         removeLease(oldest, p);\n       }\n     }\n+    return needSync;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private synchronized boolean checkLeases() {\n    boolean needSync \u003d false;\n    assert fsnamesystem.hasWriteLock();\n    for(; sortedLeases.size() \u003e 0; ) {\n      final Lease oldest \u003d sortedLeases.first();\n      if (!oldest.expiredHardLimit()) {\n        return needSync;\n      }\n\n      LOG.info(oldest + \" has expired hard limit\");\n\n      final List\u003cString\u003e removing \u003d new ArrayList\u003cString\u003e();\n      // need to create a copy of the oldest lease paths, becuase \n      // internalReleaseLease() removes paths corresponding to empty files,\n      // i.e. it needs to modify the collection being iterated over\n      // causing ConcurrentModificationException\n      String[] leasePaths \u003d new String[oldest.getPaths().size()];\n      oldest.getPaths().toArray(leasePaths);\n      for(String p : leasePaths) {\n        try {\n          boolean completed \u003d fsnamesystem.internalReleaseLease(oldest, p,\n              HdfsServerConstants.NAMENODE_LEASE_HOLDER);\n          if (LOG.isDebugEnabled()) {\n            if (completed) {\n              LOG.debug(\"Lease recovery for \" + p + \" is complete. File closed.\");\n            } else {\n              LOG.debug(\"Started block recovery \" + p + \" lease \" + oldest);\n            }\n          }\n          // If a lease recovery happened, we need to sync later.\n          if (!needSync \u0026\u0026 !completed) {\n            needSync \u003d true;\n          }\n        } catch (IOException e) {\n          LOG.error(\"Cannot release the path \" + p + \" in the lease \"\n              + oldest, e);\n          removing.add(p);\n        }\n      }\n\n      for(String p : removing) {\n        removeLease(oldest, p);\n      }\n    }\n    return needSync;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/LeaseManager.java",
          "extendedDetails": {
            "oldValue": "void",
            "newValue": "boolean"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-4186. logSync() is called with the write lock held while releasing lease (Kihwal Lee via daryn)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1409988 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "15/11/12 12:33 PM",
          "commitName": "298eb4265702362d14d7c375983bcd85371ab9af",
          "commitAuthor": "Daryn Sharp",
          "commitDateOld": "13/11/12 7:29 AM",
          "commitNameOld": "47410642500e6f0d61c5d2f479d1d3673e6ebf35",
          "commitAuthorOld": "Daryn Sharp",
          "daysBetweenCommits": 2.21,
          "commitsBetweenForRepo": 23,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,40 +1,46 @@\n-  private synchronized void checkLeases() {\n+  private synchronized boolean checkLeases() {\n+    boolean needSync \u003d false;\n     assert fsnamesystem.hasWriteLock();\n     for(; sortedLeases.size() \u003e 0; ) {\n       final Lease oldest \u003d sortedLeases.first();\n       if (!oldest.expiredHardLimit()) {\n-        return;\n+        return needSync;\n       }\n \n       LOG.info(oldest + \" has expired hard limit\");\n \n       final List\u003cString\u003e removing \u003d new ArrayList\u003cString\u003e();\n       // need to create a copy of the oldest lease paths, becuase \n       // internalReleaseLease() removes paths corresponding to empty files,\n       // i.e. it needs to modify the collection being iterated over\n       // causing ConcurrentModificationException\n       String[] leasePaths \u003d new String[oldest.getPaths().size()];\n       oldest.getPaths().toArray(leasePaths);\n       for(String p : leasePaths) {\n         try {\n           boolean completed \u003d fsnamesystem.internalReleaseLease(oldest, p,\n               HdfsServerConstants.NAMENODE_LEASE_HOLDER);\n           if (LOG.isDebugEnabled()) {\n             if (completed) {\n               LOG.debug(\"Lease recovery for \" + p + \" is complete. File closed.\");\n             } else {\n               LOG.debug(\"Started block recovery \" + p + \" lease \" + oldest);\n             }\n           }\n+          // If a lease recovery happened, we need to sync later.\n+          if (!needSync \u0026\u0026 !completed) {\n+            needSync \u003d true;\n+          }\n         } catch (IOException e) {\n           LOG.error(\"Cannot release the path \" + p + \" in the lease \"\n               + oldest, e);\n           removing.add(p);\n         }\n       }\n \n       for(String p : removing) {\n         removeLease(oldest, p);\n       }\n     }\n+    return needSync;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private synchronized boolean checkLeases() {\n    boolean needSync \u003d false;\n    assert fsnamesystem.hasWriteLock();\n    for(; sortedLeases.size() \u003e 0; ) {\n      final Lease oldest \u003d sortedLeases.first();\n      if (!oldest.expiredHardLimit()) {\n        return needSync;\n      }\n\n      LOG.info(oldest + \" has expired hard limit\");\n\n      final List\u003cString\u003e removing \u003d new ArrayList\u003cString\u003e();\n      // need to create a copy of the oldest lease paths, becuase \n      // internalReleaseLease() removes paths corresponding to empty files,\n      // i.e. it needs to modify the collection being iterated over\n      // causing ConcurrentModificationException\n      String[] leasePaths \u003d new String[oldest.getPaths().size()];\n      oldest.getPaths().toArray(leasePaths);\n      for(String p : leasePaths) {\n        try {\n          boolean completed \u003d fsnamesystem.internalReleaseLease(oldest, p,\n              HdfsServerConstants.NAMENODE_LEASE_HOLDER);\n          if (LOG.isDebugEnabled()) {\n            if (completed) {\n              LOG.debug(\"Lease recovery for \" + p + \" is complete. File closed.\");\n            } else {\n              LOG.debug(\"Started block recovery \" + p + \" lease \" + oldest);\n            }\n          }\n          // If a lease recovery happened, we need to sync later.\n          if (!needSync \u0026\u0026 !completed) {\n            needSync \u003d true;\n          }\n        } catch (IOException e) {\n          LOG.error(\"Cannot release the path \" + p + \" in the lease \"\n              + oldest, e);\n          removing.add(p);\n        }\n      }\n\n      for(String p : removing) {\n        removeLease(oldest, p);\n      }\n    }\n    return needSync;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/LeaseManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "47410642500e6f0d61c5d2f479d1d3673e6ebf35": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4181.  LeaseManager tries to double remove and prints extra messages (Kihwal Lee via daryn)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1408779 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/11/12 7:29 AM",
      "commitName": "47410642500e6f0d61c5d2f479d1d3673e6ebf35",
      "commitAuthor": "Daryn Sharp",
      "commitDateOld": "28/10/12 4:10 PM",
      "commitNameOld": "cea7bbc630deede93dbe6a1bbda56ad49de4f3de",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 15.68,
      "commitsBetweenForRepo": 87,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,37 +1,40 @@\n   private synchronized void checkLeases() {\n     assert fsnamesystem.hasWriteLock();\n     for(; sortedLeases.size() \u003e 0; ) {\n       final Lease oldest \u003d sortedLeases.first();\n       if (!oldest.expiredHardLimit()) {\n         return;\n       }\n \n       LOG.info(oldest + \" has expired hard limit\");\n \n       final List\u003cString\u003e removing \u003d new ArrayList\u003cString\u003e();\n       // need to create a copy of the oldest lease paths, becuase \n       // internalReleaseLease() removes paths corresponding to empty files,\n       // i.e. it needs to modify the collection being iterated over\n       // causing ConcurrentModificationException\n       String[] leasePaths \u003d new String[oldest.getPaths().size()];\n       oldest.getPaths().toArray(leasePaths);\n       for(String p : leasePaths) {\n         try {\n-          if(fsnamesystem.internalReleaseLease(oldest, p, HdfsServerConstants.NAMENODE_LEASE_HOLDER)) {\n-            LOG.info(\"Lease recovery for \" + p + \" is complete. File closed.\");\n-            removing.add(p);\n-          } else {\n-            LOG.info(\"Started block recovery \" + p + \" lease \" + oldest);\n+          boolean completed \u003d fsnamesystem.internalReleaseLease(oldest, p,\n+              HdfsServerConstants.NAMENODE_LEASE_HOLDER);\n+          if (LOG.isDebugEnabled()) {\n+            if (completed) {\n+              LOG.debug(\"Lease recovery for \" + p + \" is complete. File closed.\");\n+            } else {\n+              LOG.debug(\"Started block recovery \" + p + \" lease \" + oldest);\n+            }\n           }\n         } catch (IOException e) {\n           LOG.error(\"Cannot release the path \" + p + \" in the lease \"\n               + oldest, e);\n           removing.add(p);\n         }\n       }\n \n       for(String p : removing) {\n         removeLease(oldest, p);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void checkLeases() {\n    assert fsnamesystem.hasWriteLock();\n    for(; sortedLeases.size() \u003e 0; ) {\n      final Lease oldest \u003d sortedLeases.first();\n      if (!oldest.expiredHardLimit()) {\n        return;\n      }\n\n      LOG.info(oldest + \" has expired hard limit\");\n\n      final List\u003cString\u003e removing \u003d new ArrayList\u003cString\u003e();\n      // need to create a copy of the oldest lease paths, becuase \n      // internalReleaseLease() removes paths corresponding to empty files,\n      // i.e. it needs to modify the collection being iterated over\n      // causing ConcurrentModificationException\n      String[] leasePaths \u003d new String[oldest.getPaths().size()];\n      oldest.getPaths().toArray(leasePaths);\n      for(String p : leasePaths) {\n        try {\n          boolean completed \u003d fsnamesystem.internalReleaseLease(oldest, p,\n              HdfsServerConstants.NAMENODE_LEASE_HOLDER);\n          if (LOG.isDebugEnabled()) {\n            if (completed) {\n              LOG.debug(\"Lease recovery for \" + p + \" is complete. File closed.\");\n            } else {\n              LOG.debug(\"Started block recovery \" + p + \" lease \" + oldest);\n            }\n          }\n        } catch (IOException e) {\n          LOG.error(\"Cannot release the path \" + p + \" in the lease \"\n              + oldest, e);\n          removing.add(p);\n        }\n      }\n\n      for(String p : removing) {\n        removeLease(oldest, p);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/LeaseManager.java",
      "extendedDetails": {}
    },
    "cea7bbc630deede93dbe6a1bbda56ad49de4f3de": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4122. Cleanup HDFS logs and reduce the size of logged messages. Contributed by Suresh Srinivas.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1403120 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/10/12 4:10 PM",
      "commitName": "cea7bbc630deede93dbe6a1bbda56ad49de4f3de",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "25/10/12 11:44 AM",
      "commitNameOld": "ba2ee1d7fb91462c861169224d250d2d90bec3a6",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 3.18,
      "commitsBetweenForRepo": 12,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,38 +1,37 @@\n   private synchronized void checkLeases() {\n     assert fsnamesystem.hasWriteLock();\n     for(; sortedLeases.size() \u003e 0; ) {\n       final Lease oldest \u003d sortedLeases.first();\n       if (!oldest.expiredHardLimit()) {\n         return;\n       }\n \n-      LOG.info(\"Lease \" + oldest + \" has expired hard limit\");\n+      LOG.info(oldest + \" has expired hard limit\");\n \n       final List\u003cString\u003e removing \u003d new ArrayList\u003cString\u003e();\n       // need to create a copy of the oldest lease paths, becuase \n       // internalReleaseLease() removes paths corresponding to empty files,\n       // i.e. it needs to modify the collection being iterated over\n       // causing ConcurrentModificationException\n       String[] leasePaths \u003d new String[oldest.getPaths().size()];\n       oldest.getPaths().toArray(leasePaths);\n       for(String p : leasePaths) {\n         try {\n           if(fsnamesystem.internalReleaseLease(oldest, p, HdfsServerConstants.NAMENODE_LEASE_HOLDER)) {\n-            LOG.info(\"Lease recovery for file \" + p +\n-                          \" is complete. File closed.\");\n+            LOG.info(\"Lease recovery for \" + p + \" is complete. File closed.\");\n             removing.add(p);\n           } else {\n-            LOG.info(\"Started block recovery for file \" + p +\n-                          \" lease \" + oldest);\n+            LOG.info(\"Started block recovery \" + p + \" lease \" + oldest);\n           }\n         } catch (IOException e) {\n-          LOG.error(\"Cannot release the path \"+p+\" in the lease \"+oldest, e);\n+          LOG.error(\"Cannot release the path \" + p + \" in the lease \"\n+              + oldest, e);\n           removing.add(p);\n         }\n       }\n \n       for(String p : removing) {\n         removeLease(oldest, p);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void checkLeases() {\n    assert fsnamesystem.hasWriteLock();\n    for(; sortedLeases.size() \u003e 0; ) {\n      final Lease oldest \u003d sortedLeases.first();\n      if (!oldest.expiredHardLimit()) {\n        return;\n      }\n\n      LOG.info(oldest + \" has expired hard limit\");\n\n      final List\u003cString\u003e removing \u003d new ArrayList\u003cString\u003e();\n      // need to create a copy of the oldest lease paths, becuase \n      // internalReleaseLease() removes paths corresponding to empty files,\n      // i.e. it needs to modify the collection being iterated over\n      // causing ConcurrentModificationException\n      String[] leasePaths \u003d new String[oldest.getPaths().size()];\n      oldest.getPaths().toArray(leasePaths);\n      for(String p : leasePaths) {\n        try {\n          if(fsnamesystem.internalReleaseLease(oldest, p, HdfsServerConstants.NAMENODE_LEASE_HOLDER)) {\n            LOG.info(\"Lease recovery for \" + p + \" is complete. File closed.\");\n            removing.add(p);\n          } else {\n            LOG.info(\"Started block recovery \" + p + \" lease \" + oldest);\n          }\n        } catch (IOException e) {\n          LOG.error(\"Cannot release the path \" + p + \" in the lease \"\n              + oldest, e);\n          removing.add(p);\n        }\n      }\n\n      for(String p : removing) {\n        removeLease(oldest, p);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/LeaseManager.java",
      "extendedDetails": {}
    },
    "8ae98a9d1ca4725e28783370517cb3a3ecda7324": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-1620. Rename HdfsConstants -\u003e HdfsServerConstants, FSConstants -\u003e HdfsConstants. (Harsh J Chouraria via atm)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1165096 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/09/11 12:30 PM",
      "commitName": "8ae98a9d1ca4725e28783370517cb3a3ecda7324",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "24/08/11 5:14 PM",
      "commitNameOld": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 10.8,
      "commitsBetweenForRepo": 53,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,38 +1,38 @@\n   private synchronized void checkLeases() {\n     assert fsnamesystem.hasWriteLock();\n     for(; sortedLeases.size() \u003e 0; ) {\n       final Lease oldest \u003d sortedLeases.first();\n       if (!oldest.expiredHardLimit()) {\n         return;\n       }\n \n       LOG.info(\"Lease \" + oldest + \" has expired hard limit\");\n \n       final List\u003cString\u003e removing \u003d new ArrayList\u003cString\u003e();\n       // need to create a copy of the oldest lease paths, becuase \n       // internalReleaseLease() removes paths corresponding to empty files,\n       // i.e. it needs to modify the collection being iterated over\n       // causing ConcurrentModificationException\n       String[] leasePaths \u003d new String[oldest.getPaths().size()];\n       oldest.getPaths().toArray(leasePaths);\n       for(String p : leasePaths) {\n         try {\n-          if(fsnamesystem.internalReleaseLease(oldest, p, HdfsConstants.NAMENODE_LEASE_HOLDER)) {\n+          if(fsnamesystem.internalReleaseLease(oldest, p, HdfsServerConstants.NAMENODE_LEASE_HOLDER)) {\n             LOG.info(\"Lease recovery for file \" + p +\n                           \" is complete. File closed.\");\n             removing.add(p);\n           } else {\n             LOG.info(\"Started block recovery for file \" + p +\n                           \" lease \" + oldest);\n           }\n         } catch (IOException e) {\n           LOG.error(\"Cannot release the path \"+p+\" in the lease \"+oldest, e);\n           removing.add(p);\n         }\n       }\n \n       for(String p : removing) {\n         removeLease(oldest, p);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void checkLeases() {\n    assert fsnamesystem.hasWriteLock();\n    for(; sortedLeases.size() \u003e 0; ) {\n      final Lease oldest \u003d sortedLeases.first();\n      if (!oldest.expiredHardLimit()) {\n        return;\n      }\n\n      LOG.info(\"Lease \" + oldest + \" has expired hard limit\");\n\n      final List\u003cString\u003e removing \u003d new ArrayList\u003cString\u003e();\n      // need to create a copy of the oldest lease paths, becuase \n      // internalReleaseLease() removes paths corresponding to empty files,\n      // i.e. it needs to modify the collection being iterated over\n      // causing ConcurrentModificationException\n      String[] leasePaths \u003d new String[oldest.getPaths().size()];\n      oldest.getPaths().toArray(leasePaths);\n      for(String p : leasePaths) {\n        try {\n          if(fsnamesystem.internalReleaseLease(oldest, p, HdfsServerConstants.NAMENODE_LEASE_HOLDER)) {\n            LOG.info(\"Lease recovery for file \" + p +\n                          \" is complete. File closed.\");\n            removing.add(p);\n          } else {\n            LOG.info(\"Started block recovery for file \" + p +\n                          \" lease \" + oldest);\n          }\n        } catch (IOException e) {\n          LOG.error(\"Cannot release the path \"+p+\" in the lease \"+oldest, e);\n          removing.add(p);\n        }\n      }\n\n      for(String p : removing) {\n        removeLease(oldest, p);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/LeaseManager.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private synchronized void checkLeases() {\n    assert fsnamesystem.hasWriteLock();\n    for(; sortedLeases.size() \u003e 0; ) {\n      final Lease oldest \u003d sortedLeases.first();\n      if (!oldest.expiredHardLimit()) {\n        return;\n      }\n\n      LOG.info(\"Lease \" + oldest + \" has expired hard limit\");\n\n      final List\u003cString\u003e removing \u003d new ArrayList\u003cString\u003e();\n      // need to create a copy of the oldest lease paths, becuase \n      // internalReleaseLease() removes paths corresponding to empty files,\n      // i.e. it needs to modify the collection being iterated over\n      // causing ConcurrentModificationException\n      String[] leasePaths \u003d new String[oldest.getPaths().size()];\n      oldest.getPaths().toArray(leasePaths);\n      for(String p : leasePaths) {\n        try {\n          if(fsnamesystem.internalReleaseLease(oldest, p, HdfsConstants.NAMENODE_LEASE_HOLDER)) {\n            LOG.info(\"Lease recovery for file \" + p +\n                          \" is complete. File closed.\");\n            removing.add(p);\n          } else {\n            LOG.info(\"Started block recovery for file \" + p +\n                          \" lease \" + oldest);\n          }\n        } catch (IOException e) {\n          LOG.error(\"Cannot release the path \"+p+\" in the lease \"+oldest, e);\n          removing.add(p);\n        }\n      }\n\n      for(String p : removing) {\n        removeLease(oldest, p);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/LeaseManager.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/LeaseManager.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/LeaseManager.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private synchronized void checkLeases() {\n    assert fsnamesystem.hasWriteLock();\n    for(; sortedLeases.size() \u003e 0; ) {\n      final Lease oldest \u003d sortedLeases.first();\n      if (!oldest.expiredHardLimit()) {\n        return;\n      }\n\n      LOG.info(\"Lease \" + oldest + \" has expired hard limit\");\n\n      final List\u003cString\u003e removing \u003d new ArrayList\u003cString\u003e();\n      // need to create a copy of the oldest lease paths, becuase \n      // internalReleaseLease() removes paths corresponding to empty files,\n      // i.e. it needs to modify the collection being iterated over\n      // causing ConcurrentModificationException\n      String[] leasePaths \u003d new String[oldest.getPaths().size()];\n      oldest.getPaths().toArray(leasePaths);\n      for(String p : leasePaths) {\n        try {\n          if(fsnamesystem.internalReleaseLease(oldest, p, HdfsConstants.NAMENODE_LEASE_HOLDER)) {\n            LOG.info(\"Lease recovery for file \" + p +\n                          \" is complete. File closed.\");\n            removing.add(p);\n          } else {\n            LOG.info(\"Started block recovery for file \" + p +\n                          \" lease \" + oldest);\n          }\n        } catch (IOException e) {\n          LOG.error(\"Cannot release the path \"+p+\" in the lease \"+oldest, e);\n          removing.add(p);\n        }\n      }\n\n      for(String p : removing) {\n        removeLease(oldest, p);\n      }\n    }\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/LeaseManager.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/LeaseManager.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/LeaseManager.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,38 @@\n+  private synchronized void checkLeases() {\n+    assert fsnamesystem.hasWriteLock();\n+    for(; sortedLeases.size() \u003e 0; ) {\n+      final Lease oldest \u003d sortedLeases.first();\n+      if (!oldest.expiredHardLimit()) {\n+        return;\n+      }\n+\n+      LOG.info(\"Lease \" + oldest + \" has expired hard limit\");\n+\n+      final List\u003cString\u003e removing \u003d new ArrayList\u003cString\u003e();\n+      // need to create a copy of the oldest lease paths, becuase \n+      // internalReleaseLease() removes paths corresponding to empty files,\n+      // i.e. it needs to modify the collection being iterated over\n+      // causing ConcurrentModificationException\n+      String[] leasePaths \u003d new String[oldest.getPaths().size()];\n+      oldest.getPaths().toArray(leasePaths);\n+      for(String p : leasePaths) {\n+        try {\n+          if(fsnamesystem.internalReleaseLease(oldest, p, HdfsConstants.NAMENODE_LEASE_HOLDER)) {\n+            LOG.info(\"Lease recovery for file \" + p +\n+                          \" is complete. File closed.\");\n+            removing.add(p);\n+          } else {\n+            LOG.info(\"Started block recovery for file \" + p +\n+                          \" lease \" + oldest);\n+          }\n+        } catch (IOException e) {\n+          LOG.error(\"Cannot release the path \"+p+\" in the lease \"+oldest, e);\n+          removing.add(p);\n+        }\n+      }\n+\n+      for(String p : removing) {\n+        removeLease(oldest, p);\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void checkLeases() {\n    assert fsnamesystem.hasWriteLock();\n    for(; sortedLeases.size() \u003e 0; ) {\n      final Lease oldest \u003d sortedLeases.first();\n      if (!oldest.expiredHardLimit()) {\n        return;\n      }\n\n      LOG.info(\"Lease \" + oldest + \" has expired hard limit\");\n\n      final List\u003cString\u003e removing \u003d new ArrayList\u003cString\u003e();\n      // need to create a copy of the oldest lease paths, becuase \n      // internalReleaseLease() removes paths corresponding to empty files,\n      // i.e. it needs to modify the collection being iterated over\n      // causing ConcurrentModificationException\n      String[] leasePaths \u003d new String[oldest.getPaths().size()];\n      oldest.getPaths().toArray(leasePaths);\n      for(String p : leasePaths) {\n        try {\n          if(fsnamesystem.internalReleaseLease(oldest, p, HdfsConstants.NAMENODE_LEASE_HOLDER)) {\n            LOG.info(\"Lease recovery for file \" + p +\n                          \" is complete. File closed.\");\n            removing.add(p);\n          } else {\n            LOG.info(\"Started block recovery for file \" + p +\n                          \" lease \" + oldest);\n          }\n        } catch (IOException e) {\n          LOG.error(\"Cannot release the path \"+p+\" in the lease \"+oldest, e);\n          removing.add(p);\n        }\n      }\n\n      for(String p : removing) {\n        removeLease(oldest, p);\n      }\n    }\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/LeaseManager.java"
    }
  }
}