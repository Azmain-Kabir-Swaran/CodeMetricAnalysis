{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FileInputFormat.java",
  "functionName": "getSplitHostsAndCachedHosts",
  "functionId": "getSplitHostsAndCachedHosts___blkLocations-BlockLocation[]__offset-long__splitSize-long__clusterMap-NetworkTopology",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/FileInputFormat.java",
  "functionStartLine": 609,
  "functionEndLine": 711,
  "numCommitsSeen": 31,
  "timeTaken": 5694,
  "changeHistory": [
    "bd23a2ff22dba8a5203e8e498244f985e728da51",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "bd23a2ff22dba8a5203e8e498244f985e728da51": "Ymultichange(Yrename,Yreturntypechange,Ymodifierchange,Ybodychange)",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "bd23a2ff22dba8a5203e8e498244f985e728da51": {
      "type": "Ymultichange(Yrename,Yreturntypechange,Ymodifierchange,Ybodychange)",
      "commitMessage": "MAPREDUCE-5896. InputSplits should indicate which locations have the block cached in memory. (Sandy Ryza via kasha)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1603670 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/06/14 4:28 PM",
      "commitName": "bd23a2ff22dba8a5203e8e498244f985e728da51",
      "commitAuthor": "Karthik Kambatla",
      "subchanges": [
        {
          "type": "Yrename",
          "commitMessage": "MAPREDUCE-5896. InputSplits should indicate which locations have the block cached in memory. (Sandy Ryza via kasha)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1603670 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/06/14 4:28 PM",
          "commitName": "bd23a2ff22dba8a5203e8e498244f985e728da51",
          "commitAuthor": "Karthik Kambatla",
          "commitDateOld": "19/03/14 7:46 PM",
          "commitNameOld": "396c6c63a26b098fd0221e830f79be13b7e97432",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 90.86,
          "commitsBetweenForRepo": 549,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,100 +1,103 @@\n-  protected String[] getSplitHosts(BlockLocation[] blkLocations, \n+  private String[][] getSplitHostsAndCachedHosts(BlockLocation[] blkLocations, \n       long offset, long splitSize, NetworkTopology clusterMap)\n   throws IOException {\n \n     int startIndex \u003d getBlockIndex(blkLocations, offset);\n \n     long bytesInThisBlock \u003d blkLocations[startIndex].getOffset() + \n                           blkLocations[startIndex].getLength() - offset;\n \n     //If this is the only block, just return\n     if (bytesInThisBlock \u003e\u003d splitSize) {\n-      return blkLocations[startIndex].getHosts();\n+      return new String[][] { blkLocations[startIndex].getHosts(),\n+          blkLocations[startIndex].getCachedHosts() };\n     }\n \n     long bytesInFirstBlock \u003d bytesInThisBlock;\n     int index \u003d startIndex + 1;\n     splitSize -\u003d bytesInThisBlock;\n \n     while (splitSize \u003e 0) {\n       bytesInThisBlock \u003d\n         Math.min(splitSize, blkLocations[index++].getLength());\n       splitSize -\u003d bytesInThisBlock;\n     }\n \n     long bytesInLastBlock \u003d bytesInThisBlock;\n     int endIndex \u003d index - 1;\n     \n     Map \u003cNode,NodeInfo\u003e hostsMap \u003d new IdentityHashMap\u003cNode,NodeInfo\u003e();\n     Map \u003cNode,NodeInfo\u003e racksMap \u003d new IdentityHashMap\u003cNode,NodeInfo\u003e();\n     String [] allTopos \u003d new String[0];\n \n     // Build the hierarchy and aggregate the contribution of \n     // bytes at each level. See TestGetSplitHosts.java \n \n     for (index \u003d startIndex; index \u003c\u003d endIndex; index++) {\n \n       // Establish the bytes in this block\n       if (index \u003d\u003d startIndex) {\n         bytesInThisBlock \u003d bytesInFirstBlock;\n       }\n       else if (index \u003d\u003d endIndex) {\n         bytesInThisBlock \u003d bytesInLastBlock;\n       }\n       else {\n         bytesInThisBlock \u003d blkLocations[index].getLength();\n       }\n       \n       allTopos \u003d blkLocations[index].getTopologyPaths();\n \n       // If no topology information is available, just\n       // prefix a fakeRack\n       if (allTopos.length \u003d\u003d 0) {\n         allTopos \u003d fakeRacks(blkLocations, index);\n       }\n \n       // NOTE: This code currently works only for one level of\n       // hierarchy (rack/host). However, it is relatively easy\n       // to extend this to support aggregation at different\n       // levels \n       \n       for (String topo: allTopos) {\n \n         Node node, parentNode;\n         NodeInfo nodeInfo, parentNodeInfo;\n \n         node \u003d clusterMap.getNode(topo);\n \n         if (node \u003d\u003d null) {\n           node \u003d new NodeBase(topo);\n           clusterMap.add(node);\n         }\n         \n         nodeInfo \u003d hostsMap.get(node);\n         \n         if (nodeInfo \u003d\u003d null) {\n           nodeInfo \u003d new NodeInfo(node);\n           hostsMap.put(node,nodeInfo);\n           parentNode \u003d node.getParent();\n           parentNodeInfo \u003d racksMap.get(parentNode);\n           if (parentNodeInfo \u003d\u003d null) {\n             parentNodeInfo \u003d new NodeInfo(parentNode);\n             racksMap.put(parentNode,parentNodeInfo);\n           }\n           parentNodeInfo.addLeaf(nodeInfo);\n         }\n         else {\n           nodeInfo \u003d hostsMap.get(node);\n           parentNode \u003d node.getParent();\n           parentNodeInfo \u003d racksMap.get(parentNode);\n         }\n \n         nodeInfo.addValue(index, bytesInThisBlock);\n         parentNodeInfo.addValue(index, bytesInThisBlock);\n \n       } // for all topos\n     \n     } // for all indices\n \n-    return identifyHosts(allTopos.length, racksMap);\n+    // We don\u0027t yet support cached hosts when bytesInThisBlock \u003e splitSize\n+    return new String[][] { identifyHosts(allTopos.length, racksMap),\n+        new String[0]};\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private String[][] getSplitHostsAndCachedHosts(BlockLocation[] blkLocations, \n      long offset, long splitSize, NetworkTopology clusterMap)\n  throws IOException {\n\n    int startIndex \u003d getBlockIndex(blkLocations, offset);\n\n    long bytesInThisBlock \u003d blkLocations[startIndex].getOffset() + \n                          blkLocations[startIndex].getLength() - offset;\n\n    //If this is the only block, just return\n    if (bytesInThisBlock \u003e\u003d splitSize) {\n      return new String[][] { blkLocations[startIndex].getHosts(),\n          blkLocations[startIndex].getCachedHosts() };\n    }\n\n    long bytesInFirstBlock \u003d bytesInThisBlock;\n    int index \u003d startIndex + 1;\n    splitSize -\u003d bytesInThisBlock;\n\n    while (splitSize \u003e 0) {\n      bytesInThisBlock \u003d\n        Math.min(splitSize, blkLocations[index++].getLength());\n      splitSize -\u003d bytesInThisBlock;\n    }\n\n    long bytesInLastBlock \u003d bytesInThisBlock;\n    int endIndex \u003d index - 1;\n    \n    Map \u003cNode,NodeInfo\u003e hostsMap \u003d new IdentityHashMap\u003cNode,NodeInfo\u003e();\n    Map \u003cNode,NodeInfo\u003e racksMap \u003d new IdentityHashMap\u003cNode,NodeInfo\u003e();\n    String [] allTopos \u003d new String[0];\n\n    // Build the hierarchy and aggregate the contribution of \n    // bytes at each level. See TestGetSplitHosts.java \n\n    for (index \u003d startIndex; index \u003c\u003d endIndex; index++) {\n\n      // Establish the bytes in this block\n      if (index \u003d\u003d startIndex) {\n        bytesInThisBlock \u003d bytesInFirstBlock;\n      }\n      else if (index \u003d\u003d endIndex) {\n        bytesInThisBlock \u003d bytesInLastBlock;\n      }\n      else {\n        bytesInThisBlock \u003d blkLocations[index].getLength();\n      }\n      \n      allTopos \u003d blkLocations[index].getTopologyPaths();\n\n      // If no topology information is available, just\n      // prefix a fakeRack\n      if (allTopos.length \u003d\u003d 0) {\n        allTopos \u003d fakeRacks(blkLocations, index);\n      }\n\n      // NOTE: This code currently works only for one level of\n      // hierarchy (rack/host). However, it is relatively easy\n      // to extend this to support aggregation at different\n      // levels \n      \n      for (String topo: allTopos) {\n\n        Node node, parentNode;\n        NodeInfo nodeInfo, parentNodeInfo;\n\n        node \u003d clusterMap.getNode(topo);\n\n        if (node \u003d\u003d null) {\n          node \u003d new NodeBase(topo);\n          clusterMap.add(node);\n        }\n        \n        nodeInfo \u003d hostsMap.get(node);\n        \n        if (nodeInfo \u003d\u003d null) {\n          nodeInfo \u003d new NodeInfo(node);\n          hostsMap.put(node,nodeInfo);\n          parentNode \u003d node.getParent();\n          parentNodeInfo \u003d racksMap.get(parentNode);\n          if (parentNodeInfo \u003d\u003d null) {\n            parentNodeInfo \u003d new NodeInfo(parentNode);\n            racksMap.put(parentNode,parentNodeInfo);\n          }\n          parentNodeInfo.addLeaf(nodeInfo);\n        }\n        else {\n          nodeInfo \u003d hostsMap.get(node);\n          parentNode \u003d node.getParent();\n          parentNodeInfo \u003d racksMap.get(parentNode);\n        }\n\n        nodeInfo.addValue(index, bytesInThisBlock);\n        parentNodeInfo.addValue(index, bytesInThisBlock);\n\n      } // for all topos\n    \n    } // for all indices\n\n    // We don\u0027t yet support cached hosts when bytesInThisBlock \u003e splitSize\n    return new String[][] { identifyHosts(allTopos.length, racksMap),\n        new String[0]};\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/FileInputFormat.java",
          "extendedDetails": {
            "oldValue": "getSplitHosts",
            "newValue": "getSplitHostsAndCachedHosts"
          }
        },
        {
          "type": "Yreturntypechange",
          "commitMessage": "MAPREDUCE-5896. InputSplits should indicate which locations have the block cached in memory. (Sandy Ryza via kasha)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1603670 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/06/14 4:28 PM",
          "commitName": "bd23a2ff22dba8a5203e8e498244f985e728da51",
          "commitAuthor": "Karthik Kambatla",
          "commitDateOld": "19/03/14 7:46 PM",
          "commitNameOld": "396c6c63a26b098fd0221e830f79be13b7e97432",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 90.86,
          "commitsBetweenForRepo": 549,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,100 +1,103 @@\n-  protected String[] getSplitHosts(BlockLocation[] blkLocations, \n+  private String[][] getSplitHostsAndCachedHosts(BlockLocation[] blkLocations, \n       long offset, long splitSize, NetworkTopology clusterMap)\n   throws IOException {\n \n     int startIndex \u003d getBlockIndex(blkLocations, offset);\n \n     long bytesInThisBlock \u003d blkLocations[startIndex].getOffset() + \n                           blkLocations[startIndex].getLength() - offset;\n \n     //If this is the only block, just return\n     if (bytesInThisBlock \u003e\u003d splitSize) {\n-      return blkLocations[startIndex].getHosts();\n+      return new String[][] { blkLocations[startIndex].getHosts(),\n+          blkLocations[startIndex].getCachedHosts() };\n     }\n \n     long bytesInFirstBlock \u003d bytesInThisBlock;\n     int index \u003d startIndex + 1;\n     splitSize -\u003d bytesInThisBlock;\n \n     while (splitSize \u003e 0) {\n       bytesInThisBlock \u003d\n         Math.min(splitSize, blkLocations[index++].getLength());\n       splitSize -\u003d bytesInThisBlock;\n     }\n \n     long bytesInLastBlock \u003d bytesInThisBlock;\n     int endIndex \u003d index - 1;\n     \n     Map \u003cNode,NodeInfo\u003e hostsMap \u003d new IdentityHashMap\u003cNode,NodeInfo\u003e();\n     Map \u003cNode,NodeInfo\u003e racksMap \u003d new IdentityHashMap\u003cNode,NodeInfo\u003e();\n     String [] allTopos \u003d new String[0];\n \n     // Build the hierarchy and aggregate the contribution of \n     // bytes at each level. See TestGetSplitHosts.java \n \n     for (index \u003d startIndex; index \u003c\u003d endIndex; index++) {\n \n       // Establish the bytes in this block\n       if (index \u003d\u003d startIndex) {\n         bytesInThisBlock \u003d bytesInFirstBlock;\n       }\n       else if (index \u003d\u003d endIndex) {\n         bytesInThisBlock \u003d bytesInLastBlock;\n       }\n       else {\n         bytesInThisBlock \u003d blkLocations[index].getLength();\n       }\n       \n       allTopos \u003d blkLocations[index].getTopologyPaths();\n \n       // If no topology information is available, just\n       // prefix a fakeRack\n       if (allTopos.length \u003d\u003d 0) {\n         allTopos \u003d fakeRacks(blkLocations, index);\n       }\n \n       // NOTE: This code currently works only for one level of\n       // hierarchy (rack/host). However, it is relatively easy\n       // to extend this to support aggregation at different\n       // levels \n       \n       for (String topo: allTopos) {\n \n         Node node, parentNode;\n         NodeInfo nodeInfo, parentNodeInfo;\n \n         node \u003d clusterMap.getNode(topo);\n \n         if (node \u003d\u003d null) {\n           node \u003d new NodeBase(topo);\n           clusterMap.add(node);\n         }\n         \n         nodeInfo \u003d hostsMap.get(node);\n         \n         if (nodeInfo \u003d\u003d null) {\n           nodeInfo \u003d new NodeInfo(node);\n           hostsMap.put(node,nodeInfo);\n           parentNode \u003d node.getParent();\n           parentNodeInfo \u003d racksMap.get(parentNode);\n           if (parentNodeInfo \u003d\u003d null) {\n             parentNodeInfo \u003d new NodeInfo(parentNode);\n             racksMap.put(parentNode,parentNodeInfo);\n           }\n           parentNodeInfo.addLeaf(nodeInfo);\n         }\n         else {\n           nodeInfo \u003d hostsMap.get(node);\n           parentNode \u003d node.getParent();\n           parentNodeInfo \u003d racksMap.get(parentNode);\n         }\n \n         nodeInfo.addValue(index, bytesInThisBlock);\n         parentNodeInfo.addValue(index, bytesInThisBlock);\n \n       } // for all topos\n     \n     } // for all indices\n \n-    return identifyHosts(allTopos.length, racksMap);\n+    // We don\u0027t yet support cached hosts when bytesInThisBlock \u003e splitSize\n+    return new String[][] { identifyHosts(allTopos.length, racksMap),\n+        new String[0]};\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private String[][] getSplitHostsAndCachedHosts(BlockLocation[] blkLocations, \n      long offset, long splitSize, NetworkTopology clusterMap)\n  throws IOException {\n\n    int startIndex \u003d getBlockIndex(blkLocations, offset);\n\n    long bytesInThisBlock \u003d blkLocations[startIndex].getOffset() + \n                          blkLocations[startIndex].getLength() - offset;\n\n    //If this is the only block, just return\n    if (bytesInThisBlock \u003e\u003d splitSize) {\n      return new String[][] { blkLocations[startIndex].getHosts(),\n          blkLocations[startIndex].getCachedHosts() };\n    }\n\n    long bytesInFirstBlock \u003d bytesInThisBlock;\n    int index \u003d startIndex + 1;\n    splitSize -\u003d bytesInThisBlock;\n\n    while (splitSize \u003e 0) {\n      bytesInThisBlock \u003d\n        Math.min(splitSize, blkLocations[index++].getLength());\n      splitSize -\u003d bytesInThisBlock;\n    }\n\n    long bytesInLastBlock \u003d bytesInThisBlock;\n    int endIndex \u003d index - 1;\n    \n    Map \u003cNode,NodeInfo\u003e hostsMap \u003d new IdentityHashMap\u003cNode,NodeInfo\u003e();\n    Map \u003cNode,NodeInfo\u003e racksMap \u003d new IdentityHashMap\u003cNode,NodeInfo\u003e();\n    String [] allTopos \u003d new String[0];\n\n    // Build the hierarchy and aggregate the contribution of \n    // bytes at each level. See TestGetSplitHosts.java \n\n    for (index \u003d startIndex; index \u003c\u003d endIndex; index++) {\n\n      // Establish the bytes in this block\n      if (index \u003d\u003d startIndex) {\n        bytesInThisBlock \u003d bytesInFirstBlock;\n      }\n      else if (index \u003d\u003d endIndex) {\n        bytesInThisBlock \u003d bytesInLastBlock;\n      }\n      else {\n        bytesInThisBlock \u003d blkLocations[index].getLength();\n      }\n      \n      allTopos \u003d blkLocations[index].getTopologyPaths();\n\n      // If no topology information is available, just\n      // prefix a fakeRack\n      if (allTopos.length \u003d\u003d 0) {\n        allTopos \u003d fakeRacks(blkLocations, index);\n      }\n\n      // NOTE: This code currently works only for one level of\n      // hierarchy (rack/host). However, it is relatively easy\n      // to extend this to support aggregation at different\n      // levels \n      \n      for (String topo: allTopos) {\n\n        Node node, parentNode;\n        NodeInfo nodeInfo, parentNodeInfo;\n\n        node \u003d clusterMap.getNode(topo);\n\n        if (node \u003d\u003d null) {\n          node \u003d new NodeBase(topo);\n          clusterMap.add(node);\n        }\n        \n        nodeInfo \u003d hostsMap.get(node);\n        \n        if (nodeInfo \u003d\u003d null) {\n          nodeInfo \u003d new NodeInfo(node);\n          hostsMap.put(node,nodeInfo);\n          parentNode \u003d node.getParent();\n          parentNodeInfo \u003d racksMap.get(parentNode);\n          if (parentNodeInfo \u003d\u003d null) {\n            parentNodeInfo \u003d new NodeInfo(parentNode);\n            racksMap.put(parentNode,parentNodeInfo);\n          }\n          parentNodeInfo.addLeaf(nodeInfo);\n        }\n        else {\n          nodeInfo \u003d hostsMap.get(node);\n          parentNode \u003d node.getParent();\n          parentNodeInfo \u003d racksMap.get(parentNode);\n        }\n\n        nodeInfo.addValue(index, bytesInThisBlock);\n        parentNodeInfo.addValue(index, bytesInThisBlock);\n\n      } // for all topos\n    \n    } // for all indices\n\n    // We don\u0027t yet support cached hosts when bytesInThisBlock \u003e splitSize\n    return new String[][] { identifyHosts(allTopos.length, racksMap),\n        new String[0]};\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/FileInputFormat.java",
          "extendedDetails": {
            "oldValue": "String[]",
            "newValue": "String[][]"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "MAPREDUCE-5896. InputSplits should indicate which locations have the block cached in memory. (Sandy Ryza via kasha)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1603670 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/06/14 4:28 PM",
          "commitName": "bd23a2ff22dba8a5203e8e498244f985e728da51",
          "commitAuthor": "Karthik Kambatla",
          "commitDateOld": "19/03/14 7:46 PM",
          "commitNameOld": "396c6c63a26b098fd0221e830f79be13b7e97432",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 90.86,
          "commitsBetweenForRepo": 549,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,100 +1,103 @@\n-  protected String[] getSplitHosts(BlockLocation[] blkLocations, \n+  private String[][] getSplitHostsAndCachedHosts(BlockLocation[] blkLocations, \n       long offset, long splitSize, NetworkTopology clusterMap)\n   throws IOException {\n \n     int startIndex \u003d getBlockIndex(blkLocations, offset);\n \n     long bytesInThisBlock \u003d blkLocations[startIndex].getOffset() + \n                           blkLocations[startIndex].getLength() - offset;\n \n     //If this is the only block, just return\n     if (bytesInThisBlock \u003e\u003d splitSize) {\n-      return blkLocations[startIndex].getHosts();\n+      return new String[][] { blkLocations[startIndex].getHosts(),\n+          blkLocations[startIndex].getCachedHosts() };\n     }\n \n     long bytesInFirstBlock \u003d bytesInThisBlock;\n     int index \u003d startIndex + 1;\n     splitSize -\u003d bytesInThisBlock;\n \n     while (splitSize \u003e 0) {\n       bytesInThisBlock \u003d\n         Math.min(splitSize, blkLocations[index++].getLength());\n       splitSize -\u003d bytesInThisBlock;\n     }\n \n     long bytesInLastBlock \u003d bytesInThisBlock;\n     int endIndex \u003d index - 1;\n     \n     Map \u003cNode,NodeInfo\u003e hostsMap \u003d new IdentityHashMap\u003cNode,NodeInfo\u003e();\n     Map \u003cNode,NodeInfo\u003e racksMap \u003d new IdentityHashMap\u003cNode,NodeInfo\u003e();\n     String [] allTopos \u003d new String[0];\n \n     // Build the hierarchy and aggregate the contribution of \n     // bytes at each level. See TestGetSplitHosts.java \n \n     for (index \u003d startIndex; index \u003c\u003d endIndex; index++) {\n \n       // Establish the bytes in this block\n       if (index \u003d\u003d startIndex) {\n         bytesInThisBlock \u003d bytesInFirstBlock;\n       }\n       else if (index \u003d\u003d endIndex) {\n         bytesInThisBlock \u003d bytesInLastBlock;\n       }\n       else {\n         bytesInThisBlock \u003d blkLocations[index].getLength();\n       }\n       \n       allTopos \u003d blkLocations[index].getTopologyPaths();\n \n       // If no topology information is available, just\n       // prefix a fakeRack\n       if (allTopos.length \u003d\u003d 0) {\n         allTopos \u003d fakeRacks(blkLocations, index);\n       }\n \n       // NOTE: This code currently works only for one level of\n       // hierarchy (rack/host). However, it is relatively easy\n       // to extend this to support aggregation at different\n       // levels \n       \n       for (String topo: allTopos) {\n \n         Node node, parentNode;\n         NodeInfo nodeInfo, parentNodeInfo;\n \n         node \u003d clusterMap.getNode(topo);\n \n         if (node \u003d\u003d null) {\n           node \u003d new NodeBase(topo);\n           clusterMap.add(node);\n         }\n         \n         nodeInfo \u003d hostsMap.get(node);\n         \n         if (nodeInfo \u003d\u003d null) {\n           nodeInfo \u003d new NodeInfo(node);\n           hostsMap.put(node,nodeInfo);\n           parentNode \u003d node.getParent();\n           parentNodeInfo \u003d racksMap.get(parentNode);\n           if (parentNodeInfo \u003d\u003d null) {\n             parentNodeInfo \u003d new NodeInfo(parentNode);\n             racksMap.put(parentNode,parentNodeInfo);\n           }\n           parentNodeInfo.addLeaf(nodeInfo);\n         }\n         else {\n           nodeInfo \u003d hostsMap.get(node);\n           parentNode \u003d node.getParent();\n           parentNodeInfo \u003d racksMap.get(parentNode);\n         }\n \n         nodeInfo.addValue(index, bytesInThisBlock);\n         parentNodeInfo.addValue(index, bytesInThisBlock);\n \n       } // for all topos\n     \n     } // for all indices\n \n-    return identifyHosts(allTopos.length, racksMap);\n+    // We don\u0027t yet support cached hosts when bytesInThisBlock \u003e splitSize\n+    return new String[][] { identifyHosts(allTopos.length, racksMap),\n+        new String[0]};\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private String[][] getSplitHostsAndCachedHosts(BlockLocation[] blkLocations, \n      long offset, long splitSize, NetworkTopology clusterMap)\n  throws IOException {\n\n    int startIndex \u003d getBlockIndex(blkLocations, offset);\n\n    long bytesInThisBlock \u003d blkLocations[startIndex].getOffset() + \n                          blkLocations[startIndex].getLength() - offset;\n\n    //If this is the only block, just return\n    if (bytesInThisBlock \u003e\u003d splitSize) {\n      return new String[][] { blkLocations[startIndex].getHosts(),\n          blkLocations[startIndex].getCachedHosts() };\n    }\n\n    long bytesInFirstBlock \u003d bytesInThisBlock;\n    int index \u003d startIndex + 1;\n    splitSize -\u003d bytesInThisBlock;\n\n    while (splitSize \u003e 0) {\n      bytesInThisBlock \u003d\n        Math.min(splitSize, blkLocations[index++].getLength());\n      splitSize -\u003d bytesInThisBlock;\n    }\n\n    long bytesInLastBlock \u003d bytesInThisBlock;\n    int endIndex \u003d index - 1;\n    \n    Map \u003cNode,NodeInfo\u003e hostsMap \u003d new IdentityHashMap\u003cNode,NodeInfo\u003e();\n    Map \u003cNode,NodeInfo\u003e racksMap \u003d new IdentityHashMap\u003cNode,NodeInfo\u003e();\n    String [] allTopos \u003d new String[0];\n\n    // Build the hierarchy and aggregate the contribution of \n    // bytes at each level. See TestGetSplitHosts.java \n\n    for (index \u003d startIndex; index \u003c\u003d endIndex; index++) {\n\n      // Establish the bytes in this block\n      if (index \u003d\u003d startIndex) {\n        bytesInThisBlock \u003d bytesInFirstBlock;\n      }\n      else if (index \u003d\u003d endIndex) {\n        bytesInThisBlock \u003d bytesInLastBlock;\n      }\n      else {\n        bytesInThisBlock \u003d blkLocations[index].getLength();\n      }\n      \n      allTopos \u003d blkLocations[index].getTopologyPaths();\n\n      // If no topology information is available, just\n      // prefix a fakeRack\n      if (allTopos.length \u003d\u003d 0) {\n        allTopos \u003d fakeRacks(blkLocations, index);\n      }\n\n      // NOTE: This code currently works only for one level of\n      // hierarchy (rack/host). However, it is relatively easy\n      // to extend this to support aggregation at different\n      // levels \n      \n      for (String topo: allTopos) {\n\n        Node node, parentNode;\n        NodeInfo nodeInfo, parentNodeInfo;\n\n        node \u003d clusterMap.getNode(topo);\n\n        if (node \u003d\u003d null) {\n          node \u003d new NodeBase(topo);\n          clusterMap.add(node);\n        }\n        \n        nodeInfo \u003d hostsMap.get(node);\n        \n        if (nodeInfo \u003d\u003d null) {\n          nodeInfo \u003d new NodeInfo(node);\n          hostsMap.put(node,nodeInfo);\n          parentNode \u003d node.getParent();\n          parentNodeInfo \u003d racksMap.get(parentNode);\n          if (parentNodeInfo \u003d\u003d null) {\n            parentNodeInfo \u003d new NodeInfo(parentNode);\n            racksMap.put(parentNode,parentNodeInfo);\n          }\n          parentNodeInfo.addLeaf(nodeInfo);\n        }\n        else {\n          nodeInfo \u003d hostsMap.get(node);\n          parentNode \u003d node.getParent();\n          parentNodeInfo \u003d racksMap.get(parentNode);\n        }\n\n        nodeInfo.addValue(index, bytesInThisBlock);\n        parentNodeInfo.addValue(index, bytesInThisBlock);\n\n      } // for all topos\n    \n    } // for all indices\n\n    // We don\u0027t yet support cached hosts when bytesInThisBlock \u003e splitSize\n    return new String[][] { identifyHosts(allTopos.length, racksMap),\n        new String[0]};\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/FileInputFormat.java",
          "extendedDetails": {
            "oldValue": "[protected]",
            "newValue": "[private]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "MAPREDUCE-5896. InputSplits should indicate which locations have the block cached in memory. (Sandy Ryza via kasha)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1603670 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/06/14 4:28 PM",
          "commitName": "bd23a2ff22dba8a5203e8e498244f985e728da51",
          "commitAuthor": "Karthik Kambatla",
          "commitDateOld": "19/03/14 7:46 PM",
          "commitNameOld": "396c6c63a26b098fd0221e830f79be13b7e97432",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 90.86,
          "commitsBetweenForRepo": 549,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,100 +1,103 @@\n-  protected String[] getSplitHosts(BlockLocation[] blkLocations, \n+  private String[][] getSplitHostsAndCachedHosts(BlockLocation[] blkLocations, \n       long offset, long splitSize, NetworkTopology clusterMap)\n   throws IOException {\n \n     int startIndex \u003d getBlockIndex(blkLocations, offset);\n \n     long bytesInThisBlock \u003d blkLocations[startIndex].getOffset() + \n                           blkLocations[startIndex].getLength() - offset;\n \n     //If this is the only block, just return\n     if (bytesInThisBlock \u003e\u003d splitSize) {\n-      return blkLocations[startIndex].getHosts();\n+      return new String[][] { blkLocations[startIndex].getHosts(),\n+          blkLocations[startIndex].getCachedHosts() };\n     }\n \n     long bytesInFirstBlock \u003d bytesInThisBlock;\n     int index \u003d startIndex + 1;\n     splitSize -\u003d bytesInThisBlock;\n \n     while (splitSize \u003e 0) {\n       bytesInThisBlock \u003d\n         Math.min(splitSize, blkLocations[index++].getLength());\n       splitSize -\u003d bytesInThisBlock;\n     }\n \n     long bytesInLastBlock \u003d bytesInThisBlock;\n     int endIndex \u003d index - 1;\n     \n     Map \u003cNode,NodeInfo\u003e hostsMap \u003d new IdentityHashMap\u003cNode,NodeInfo\u003e();\n     Map \u003cNode,NodeInfo\u003e racksMap \u003d new IdentityHashMap\u003cNode,NodeInfo\u003e();\n     String [] allTopos \u003d new String[0];\n \n     // Build the hierarchy and aggregate the contribution of \n     // bytes at each level. See TestGetSplitHosts.java \n \n     for (index \u003d startIndex; index \u003c\u003d endIndex; index++) {\n \n       // Establish the bytes in this block\n       if (index \u003d\u003d startIndex) {\n         bytesInThisBlock \u003d bytesInFirstBlock;\n       }\n       else if (index \u003d\u003d endIndex) {\n         bytesInThisBlock \u003d bytesInLastBlock;\n       }\n       else {\n         bytesInThisBlock \u003d blkLocations[index].getLength();\n       }\n       \n       allTopos \u003d blkLocations[index].getTopologyPaths();\n \n       // If no topology information is available, just\n       // prefix a fakeRack\n       if (allTopos.length \u003d\u003d 0) {\n         allTopos \u003d fakeRacks(blkLocations, index);\n       }\n \n       // NOTE: This code currently works only for one level of\n       // hierarchy (rack/host). However, it is relatively easy\n       // to extend this to support aggregation at different\n       // levels \n       \n       for (String topo: allTopos) {\n \n         Node node, parentNode;\n         NodeInfo nodeInfo, parentNodeInfo;\n \n         node \u003d clusterMap.getNode(topo);\n \n         if (node \u003d\u003d null) {\n           node \u003d new NodeBase(topo);\n           clusterMap.add(node);\n         }\n         \n         nodeInfo \u003d hostsMap.get(node);\n         \n         if (nodeInfo \u003d\u003d null) {\n           nodeInfo \u003d new NodeInfo(node);\n           hostsMap.put(node,nodeInfo);\n           parentNode \u003d node.getParent();\n           parentNodeInfo \u003d racksMap.get(parentNode);\n           if (parentNodeInfo \u003d\u003d null) {\n             parentNodeInfo \u003d new NodeInfo(parentNode);\n             racksMap.put(parentNode,parentNodeInfo);\n           }\n           parentNodeInfo.addLeaf(nodeInfo);\n         }\n         else {\n           nodeInfo \u003d hostsMap.get(node);\n           parentNode \u003d node.getParent();\n           parentNodeInfo \u003d racksMap.get(parentNode);\n         }\n \n         nodeInfo.addValue(index, bytesInThisBlock);\n         parentNodeInfo.addValue(index, bytesInThisBlock);\n \n       } // for all topos\n     \n     } // for all indices\n \n-    return identifyHosts(allTopos.length, racksMap);\n+    // We don\u0027t yet support cached hosts when bytesInThisBlock \u003e splitSize\n+    return new String[][] { identifyHosts(allTopos.length, racksMap),\n+        new String[0]};\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private String[][] getSplitHostsAndCachedHosts(BlockLocation[] blkLocations, \n      long offset, long splitSize, NetworkTopology clusterMap)\n  throws IOException {\n\n    int startIndex \u003d getBlockIndex(blkLocations, offset);\n\n    long bytesInThisBlock \u003d blkLocations[startIndex].getOffset() + \n                          blkLocations[startIndex].getLength() - offset;\n\n    //If this is the only block, just return\n    if (bytesInThisBlock \u003e\u003d splitSize) {\n      return new String[][] { blkLocations[startIndex].getHosts(),\n          blkLocations[startIndex].getCachedHosts() };\n    }\n\n    long bytesInFirstBlock \u003d bytesInThisBlock;\n    int index \u003d startIndex + 1;\n    splitSize -\u003d bytesInThisBlock;\n\n    while (splitSize \u003e 0) {\n      bytesInThisBlock \u003d\n        Math.min(splitSize, blkLocations[index++].getLength());\n      splitSize -\u003d bytesInThisBlock;\n    }\n\n    long bytesInLastBlock \u003d bytesInThisBlock;\n    int endIndex \u003d index - 1;\n    \n    Map \u003cNode,NodeInfo\u003e hostsMap \u003d new IdentityHashMap\u003cNode,NodeInfo\u003e();\n    Map \u003cNode,NodeInfo\u003e racksMap \u003d new IdentityHashMap\u003cNode,NodeInfo\u003e();\n    String [] allTopos \u003d new String[0];\n\n    // Build the hierarchy and aggregate the contribution of \n    // bytes at each level. See TestGetSplitHosts.java \n\n    for (index \u003d startIndex; index \u003c\u003d endIndex; index++) {\n\n      // Establish the bytes in this block\n      if (index \u003d\u003d startIndex) {\n        bytesInThisBlock \u003d bytesInFirstBlock;\n      }\n      else if (index \u003d\u003d endIndex) {\n        bytesInThisBlock \u003d bytesInLastBlock;\n      }\n      else {\n        bytesInThisBlock \u003d blkLocations[index].getLength();\n      }\n      \n      allTopos \u003d blkLocations[index].getTopologyPaths();\n\n      // If no topology information is available, just\n      // prefix a fakeRack\n      if (allTopos.length \u003d\u003d 0) {\n        allTopos \u003d fakeRacks(blkLocations, index);\n      }\n\n      // NOTE: This code currently works only for one level of\n      // hierarchy (rack/host). However, it is relatively easy\n      // to extend this to support aggregation at different\n      // levels \n      \n      for (String topo: allTopos) {\n\n        Node node, parentNode;\n        NodeInfo nodeInfo, parentNodeInfo;\n\n        node \u003d clusterMap.getNode(topo);\n\n        if (node \u003d\u003d null) {\n          node \u003d new NodeBase(topo);\n          clusterMap.add(node);\n        }\n        \n        nodeInfo \u003d hostsMap.get(node);\n        \n        if (nodeInfo \u003d\u003d null) {\n          nodeInfo \u003d new NodeInfo(node);\n          hostsMap.put(node,nodeInfo);\n          parentNode \u003d node.getParent();\n          parentNodeInfo \u003d racksMap.get(parentNode);\n          if (parentNodeInfo \u003d\u003d null) {\n            parentNodeInfo \u003d new NodeInfo(parentNode);\n            racksMap.put(parentNode,parentNodeInfo);\n          }\n          parentNodeInfo.addLeaf(nodeInfo);\n        }\n        else {\n          nodeInfo \u003d hostsMap.get(node);\n          parentNode \u003d node.getParent();\n          parentNodeInfo \u003d racksMap.get(parentNode);\n        }\n\n        nodeInfo.addValue(index, bytesInThisBlock);\n        parentNodeInfo.addValue(index, bytesInThisBlock);\n\n      } // for all topos\n    \n    } // for all indices\n\n    // We don\u0027t yet support cached hosts when bytesInThisBlock \u003e splitSize\n    return new String[][] { identifyHosts(allTopos.length, racksMap),\n        new String[0]};\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/FileInputFormat.java",
          "extendedDetails": {}
        }
      ]
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  protected String[] getSplitHosts(BlockLocation[] blkLocations, \n      long offset, long splitSize, NetworkTopology clusterMap)\n  throws IOException {\n\n    int startIndex \u003d getBlockIndex(blkLocations, offset);\n\n    long bytesInThisBlock \u003d blkLocations[startIndex].getOffset() + \n                          blkLocations[startIndex].getLength() - offset;\n\n    //If this is the only block, just return\n    if (bytesInThisBlock \u003e\u003d splitSize) {\n      return blkLocations[startIndex].getHosts();\n    }\n\n    long bytesInFirstBlock \u003d bytesInThisBlock;\n    int index \u003d startIndex + 1;\n    splitSize -\u003d bytesInThisBlock;\n\n    while (splitSize \u003e 0) {\n      bytesInThisBlock \u003d\n        Math.min(splitSize, blkLocations[index++].getLength());\n      splitSize -\u003d bytesInThisBlock;\n    }\n\n    long bytesInLastBlock \u003d bytesInThisBlock;\n    int endIndex \u003d index - 1;\n    \n    Map \u003cNode,NodeInfo\u003e hostsMap \u003d new IdentityHashMap\u003cNode,NodeInfo\u003e();\n    Map \u003cNode,NodeInfo\u003e racksMap \u003d new IdentityHashMap\u003cNode,NodeInfo\u003e();\n    String [] allTopos \u003d new String[0];\n\n    // Build the hierarchy and aggregate the contribution of \n    // bytes at each level. See TestGetSplitHosts.java \n\n    for (index \u003d startIndex; index \u003c\u003d endIndex; index++) {\n\n      // Establish the bytes in this block\n      if (index \u003d\u003d startIndex) {\n        bytesInThisBlock \u003d bytesInFirstBlock;\n      }\n      else if (index \u003d\u003d endIndex) {\n        bytesInThisBlock \u003d bytesInLastBlock;\n      }\n      else {\n        bytesInThisBlock \u003d blkLocations[index].getLength();\n      }\n      \n      allTopos \u003d blkLocations[index].getTopologyPaths();\n\n      // If no topology information is available, just\n      // prefix a fakeRack\n      if (allTopos.length \u003d\u003d 0) {\n        allTopos \u003d fakeRacks(blkLocations, index);\n      }\n\n      // NOTE: This code currently works only for one level of\n      // hierarchy (rack/host). However, it is relatively easy\n      // to extend this to support aggregation at different\n      // levels \n      \n      for (String topo: allTopos) {\n\n        Node node, parentNode;\n        NodeInfo nodeInfo, parentNodeInfo;\n\n        node \u003d clusterMap.getNode(topo);\n\n        if (node \u003d\u003d null) {\n          node \u003d new NodeBase(topo);\n          clusterMap.add(node);\n        }\n        \n        nodeInfo \u003d hostsMap.get(node);\n        \n        if (nodeInfo \u003d\u003d null) {\n          nodeInfo \u003d new NodeInfo(node);\n          hostsMap.put(node,nodeInfo);\n          parentNode \u003d node.getParent();\n          parentNodeInfo \u003d racksMap.get(parentNode);\n          if (parentNodeInfo \u003d\u003d null) {\n            parentNodeInfo \u003d new NodeInfo(parentNode);\n            racksMap.put(parentNode,parentNodeInfo);\n          }\n          parentNodeInfo.addLeaf(nodeInfo);\n        }\n        else {\n          nodeInfo \u003d hostsMap.get(node);\n          parentNode \u003d node.getParent();\n          parentNodeInfo \u003d racksMap.get(parentNode);\n        }\n\n        nodeInfo.addValue(index, bytesInThisBlock);\n        parentNodeInfo.addValue(index, bytesInThisBlock);\n\n      } // for all topos\n    \n    } // for all indices\n\n    return identifyHosts(allTopos.length, racksMap);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/FileInputFormat.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/FileInputFormat.java",
        "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/FileInputFormat.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yfilerename",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "17/08/11 8:02 PM",
      "commitNameOld": "dd86860633d2ed64705b669a75bf318442ed6225",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 0.34,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  protected String[] getSplitHosts(BlockLocation[] blkLocations, \n      long offset, long splitSize, NetworkTopology clusterMap)\n  throws IOException {\n\n    int startIndex \u003d getBlockIndex(blkLocations, offset);\n\n    long bytesInThisBlock \u003d blkLocations[startIndex].getOffset() + \n                          blkLocations[startIndex].getLength() - offset;\n\n    //If this is the only block, just return\n    if (bytesInThisBlock \u003e\u003d splitSize) {\n      return blkLocations[startIndex].getHosts();\n    }\n\n    long bytesInFirstBlock \u003d bytesInThisBlock;\n    int index \u003d startIndex + 1;\n    splitSize -\u003d bytesInThisBlock;\n\n    while (splitSize \u003e 0) {\n      bytesInThisBlock \u003d\n        Math.min(splitSize, blkLocations[index++].getLength());\n      splitSize -\u003d bytesInThisBlock;\n    }\n\n    long bytesInLastBlock \u003d bytesInThisBlock;\n    int endIndex \u003d index - 1;\n    \n    Map \u003cNode,NodeInfo\u003e hostsMap \u003d new IdentityHashMap\u003cNode,NodeInfo\u003e();\n    Map \u003cNode,NodeInfo\u003e racksMap \u003d new IdentityHashMap\u003cNode,NodeInfo\u003e();\n    String [] allTopos \u003d new String[0];\n\n    // Build the hierarchy and aggregate the contribution of \n    // bytes at each level. See TestGetSplitHosts.java \n\n    for (index \u003d startIndex; index \u003c\u003d endIndex; index++) {\n\n      // Establish the bytes in this block\n      if (index \u003d\u003d startIndex) {\n        bytesInThisBlock \u003d bytesInFirstBlock;\n      }\n      else if (index \u003d\u003d endIndex) {\n        bytesInThisBlock \u003d bytesInLastBlock;\n      }\n      else {\n        bytesInThisBlock \u003d blkLocations[index].getLength();\n      }\n      \n      allTopos \u003d blkLocations[index].getTopologyPaths();\n\n      // If no topology information is available, just\n      // prefix a fakeRack\n      if (allTopos.length \u003d\u003d 0) {\n        allTopos \u003d fakeRacks(blkLocations, index);\n      }\n\n      // NOTE: This code currently works only for one level of\n      // hierarchy (rack/host). However, it is relatively easy\n      // to extend this to support aggregation at different\n      // levels \n      \n      for (String topo: allTopos) {\n\n        Node node, parentNode;\n        NodeInfo nodeInfo, parentNodeInfo;\n\n        node \u003d clusterMap.getNode(topo);\n\n        if (node \u003d\u003d null) {\n          node \u003d new NodeBase(topo);\n          clusterMap.add(node);\n        }\n        \n        nodeInfo \u003d hostsMap.get(node);\n        \n        if (nodeInfo \u003d\u003d null) {\n          nodeInfo \u003d new NodeInfo(node);\n          hostsMap.put(node,nodeInfo);\n          parentNode \u003d node.getParent();\n          parentNodeInfo \u003d racksMap.get(parentNode);\n          if (parentNodeInfo \u003d\u003d null) {\n            parentNodeInfo \u003d new NodeInfo(parentNode);\n            racksMap.put(parentNode,parentNodeInfo);\n          }\n          parentNodeInfo.addLeaf(nodeInfo);\n        }\n        else {\n          nodeInfo \u003d hostsMap.get(node);\n          parentNode \u003d node.getParent();\n          parentNodeInfo \u003d racksMap.get(parentNode);\n        }\n\n        nodeInfo.addValue(index, bytesInThisBlock);\n        parentNodeInfo.addValue(index, bytesInThisBlock);\n\n      } // for all topos\n    \n    } // for all indices\n\n    return identifyHosts(allTopos.length, racksMap);\n  }",
      "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/FileInputFormat.java",
      "extendedDetails": {
        "oldPath": "mapreduce/src/java/org/apache/hadoop/mapred/FileInputFormat.java",
        "newPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/FileInputFormat.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,100 @@\n+  protected String[] getSplitHosts(BlockLocation[] blkLocations, \n+      long offset, long splitSize, NetworkTopology clusterMap)\n+  throws IOException {\n+\n+    int startIndex \u003d getBlockIndex(blkLocations, offset);\n+\n+    long bytesInThisBlock \u003d blkLocations[startIndex].getOffset() + \n+                          blkLocations[startIndex].getLength() - offset;\n+\n+    //If this is the only block, just return\n+    if (bytesInThisBlock \u003e\u003d splitSize) {\n+      return blkLocations[startIndex].getHosts();\n+    }\n+\n+    long bytesInFirstBlock \u003d bytesInThisBlock;\n+    int index \u003d startIndex + 1;\n+    splitSize -\u003d bytesInThisBlock;\n+\n+    while (splitSize \u003e 0) {\n+      bytesInThisBlock \u003d\n+        Math.min(splitSize, blkLocations[index++].getLength());\n+      splitSize -\u003d bytesInThisBlock;\n+    }\n+\n+    long bytesInLastBlock \u003d bytesInThisBlock;\n+    int endIndex \u003d index - 1;\n+    \n+    Map \u003cNode,NodeInfo\u003e hostsMap \u003d new IdentityHashMap\u003cNode,NodeInfo\u003e();\n+    Map \u003cNode,NodeInfo\u003e racksMap \u003d new IdentityHashMap\u003cNode,NodeInfo\u003e();\n+    String [] allTopos \u003d new String[0];\n+\n+    // Build the hierarchy and aggregate the contribution of \n+    // bytes at each level. See TestGetSplitHosts.java \n+\n+    for (index \u003d startIndex; index \u003c\u003d endIndex; index++) {\n+\n+      // Establish the bytes in this block\n+      if (index \u003d\u003d startIndex) {\n+        bytesInThisBlock \u003d bytesInFirstBlock;\n+      }\n+      else if (index \u003d\u003d endIndex) {\n+        bytesInThisBlock \u003d bytesInLastBlock;\n+      }\n+      else {\n+        bytesInThisBlock \u003d blkLocations[index].getLength();\n+      }\n+      \n+      allTopos \u003d blkLocations[index].getTopologyPaths();\n+\n+      // If no topology information is available, just\n+      // prefix a fakeRack\n+      if (allTopos.length \u003d\u003d 0) {\n+        allTopos \u003d fakeRacks(blkLocations, index);\n+      }\n+\n+      // NOTE: This code currently works only for one level of\n+      // hierarchy (rack/host). However, it is relatively easy\n+      // to extend this to support aggregation at different\n+      // levels \n+      \n+      for (String topo: allTopos) {\n+\n+        Node node, parentNode;\n+        NodeInfo nodeInfo, parentNodeInfo;\n+\n+        node \u003d clusterMap.getNode(topo);\n+\n+        if (node \u003d\u003d null) {\n+          node \u003d new NodeBase(topo);\n+          clusterMap.add(node);\n+        }\n+        \n+        nodeInfo \u003d hostsMap.get(node);\n+        \n+        if (nodeInfo \u003d\u003d null) {\n+          nodeInfo \u003d new NodeInfo(node);\n+          hostsMap.put(node,nodeInfo);\n+          parentNode \u003d node.getParent();\n+          parentNodeInfo \u003d racksMap.get(parentNode);\n+          if (parentNodeInfo \u003d\u003d null) {\n+            parentNodeInfo \u003d new NodeInfo(parentNode);\n+            racksMap.put(parentNode,parentNodeInfo);\n+          }\n+          parentNodeInfo.addLeaf(nodeInfo);\n+        }\n+        else {\n+          nodeInfo \u003d hostsMap.get(node);\n+          parentNode \u003d node.getParent();\n+          parentNodeInfo \u003d racksMap.get(parentNode);\n+        }\n+\n+        nodeInfo.addValue(index, bytesInThisBlock);\n+        parentNodeInfo.addValue(index, bytesInThisBlock);\n+\n+      } // for all topos\n+    \n+    } // for all indices\n+\n+    return identifyHosts(allTopos.length, racksMap);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  protected String[] getSplitHosts(BlockLocation[] blkLocations, \n      long offset, long splitSize, NetworkTopology clusterMap)\n  throws IOException {\n\n    int startIndex \u003d getBlockIndex(blkLocations, offset);\n\n    long bytesInThisBlock \u003d blkLocations[startIndex].getOffset() + \n                          blkLocations[startIndex].getLength() - offset;\n\n    //If this is the only block, just return\n    if (bytesInThisBlock \u003e\u003d splitSize) {\n      return blkLocations[startIndex].getHosts();\n    }\n\n    long bytesInFirstBlock \u003d bytesInThisBlock;\n    int index \u003d startIndex + 1;\n    splitSize -\u003d bytesInThisBlock;\n\n    while (splitSize \u003e 0) {\n      bytesInThisBlock \u003d\n        Math.min(splitSize, blkLocations[index++].getLength());\n      splitSize -\u003d bytesInThisBlock;\n    }\n\n    long bytesInLastBlock \u003d bytesInThisBlock;\n    int endIndex \u003d index - 1;\n    \n    Map \u003cNode,NodeInfo\u003e hostsMap \u003d new IdentityHashMap\u003cNode,NodeInfo\u003e();\n    Map \u003cNode,NodeInfo\u003e racksMap \u003d new IdentityHashMap\u003cNode,NodeInfo\u003e();\n    String [] allTopos \u003d new String[0];\n\n    // Build the hierarchy and aggregate the contribution of \n    // bytes at each level. See TestGetSplitHosts.java \n\n    for (index \u003d startIndex; index \u003c\u003d endIndex; index++) {\n\n      // Establish the bytes in this block\n      if (index \u003d\u003d startIndex) {\n        bytesInThisBlock \u003d bytesInFirstBlock;\n      }\n      else if (index \u003d\u003d endIndex) {\n        bytesInThisBlock \u003d bytesInLastBlock;\n      }\n      else {\n        bytesInThisBlock \u003d blkLocations[index].getLength();\n      }\n      \n      allTopos \u003d blkLocations[index].getTopologyPaths();\n\n      // If no topology information is available, just\n      // prefix a fakeRack\n      if (allTopos.length \u003d\u003d 0) {\n        allTopos \u003d fakeRacks(blkLocations, index);\n      }\n\n      // NOTE: This code currently works only for one level of\n      // hierarchy (rack/host). However, it is relatively easy\n      // to extend this to support aggregation at different\n      // levels \n      \n      for (String topo: allTopos) {\n\n        Node node, parentNode;\n        NodeInfo nodeInfo, parentNodeInfo;\n\n        node \u003d clusterMap.getNode(topo);\n\n        if (node \u003d\u003d null) {\n          node \u003d new NodeBase(topo);\n          clusterMap.add(node);\n        }\n        \n        nodeInfo \u003d hostsMap.get(node);\n        \n        if (nodeInfo \u003d\u003d null) {\n          nodeInfo \u003d new NodeInfo(node);\n          hostsMap.put(node,nodeInfo);\n          parentNode \u003d node.getParent();\n          parentNodeInfo \u003d racksMap.get(parentNode);\n          if (parentNodeInfo \u003d\u003d null) {\n            parentNodeInfo \u003d new NodeInfo(parentNode);\n            racksMap.put(parentNode,parentNodeInfo);\n          }\n          parentNodeInfo.addLeaf(nodeInfo);\n        }\n        else {\n          nodeInfo \u003d hostsMap.get(node);\n          parentNode \u003d node.getParent();\n          parentNodeInfo \u003d racksMap.get(parentNode);\n        }\n\n        nodeInfo.addValue(index, bytesInThisBlock);\n        parentNodeInfo.addValue(index, bytesInThisBlock);\n\n      } // for all topos\n    \n    } // for all indices\n\n    return identifyHosts(allTopos.length, racksMap);\n  }",
      "path": "mapreduce/src/java/org/apache/hadoop/mapred/FileInputFormat.java"
    }
  }
}