{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "RPC.java",
  "functionName": "getSuperInterfaces",
  "functionId": "getSuperInterfaces___childInterfaces-Class__?__[]",
  "sourceFilePath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/RPC.java",
  "functionStartLine": 122,
  "functionEndLine": 137,
  "numCommitsSeen": 49,
  "timeTaken": 2181,
  "changeHistory": [
    "65200998c01b17e017d1814e8b1f4d82ac334a23",
    "b97a4d40c8752451fc02168a7f6eb3e93e459c2d"
  ],
  "changeHistoryShort": {
    "65200998c01b17e017d1814e8b1f4d82ac334a23": "Ymultichange(Ymovefromfile,Ymodifierchange,Ybodychange)",
    "b97a4d40c8752451fc02168a7f6eb3e93e459c2d": "Yintroduced"
  },
  "changeHistoryDetails": {
    "65200998c01b17e017d1814e8b1f4d82ac334a23": {
      "type": "Ymultichange(Ymovefromfile,Ymodifierchange,Ybodychange)",
      "commitMessage": "HADOOP-7862  Move the support for multiple protocols to lower layer so that Writable, PB and Avro can all use it (includes HDFS and MR changes to match) (Sanjay) \n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1210208 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/12/11 12:44 PM",
      "commitName": "65200998c01b17e017d1814e8b1f4d82ac334a23",
      "commitAuthor": "Sanjay Radia",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HADOOP-7862  Move the support for multiple protocols to lower layer so that Writable, PB and Avro can all use it (includes HDFS and MR changes to match) (Sanjay) \n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1210208 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "04/12/11 12:44 PM",
          "commitName": "65200998c01b17e017d1814e8b1f4d82ac334a23",
          "commitAuthor": "Sanjay Radia",
          "commitDateOld": "04/12/11 12:11 PM",
          "commitNameOld": "e948247715ba001b00eafc5f801fa926c409ea5a",
          "commitAuthorOld": "Mahadev Konar",
          "daysBetweenCommits": 0.02,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,16 +1,16 @@\n-  private static Class\u003c?\u003e[] getSuperInterfaces(Class\u003c?\u003e[] childInterfaces) {\n+  static Class\u003c?\u003e[] getSuperInterfaces(Class\u003c?\u003e[] childInterfaces) {\n     List\u003cClass\u003c?\u003e\u003e allInterfaces \u003d new ArrayList\u003cClass\u003c?\u003e\u003e();\n \n     for (Class\u003c?\u003e childInterface : childInterfaces) {\n       if (VersionedProtocol.class.isAssignableFrom(childInterface)) {\n           allInterfaces.add(childInterface);\n           allInterfaces.addAll(\n               Arrays.asList(\n                   getSuperInterfaces(childInterface.getInterfaces())));\n       } else {\n         LOG.warn(\"Interface \" + childInterface +\n               \" ignored because it does not extend VersionedProtocol\");\n       }\n     }\n-    return (Class\u003c?\u003e[]) allInterfaces.toArray(new Class[allInterfaces.size()]);\n+    return allInterfaces.toArray(new Class[allInterfaces.size()]);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static Class\u003c?\u003e[] getSuperInterfaces(Class\u003c?\u003e[] childInterfaces) {\n    List\u003cClass\u003c?\u003e\u003e allInterfaces \u003d new ArrayList\u003cClass\u003c?\u003e\u003e();\n\n    for (Class\u003c?\u003e childInterface : childInterfaces) {\n      if (VersionedProtocol.class.isAssignableFrom(childInterface)) {\n          allInterfaces.add(childInterface);\n          allInterfaces.addAll(\n              Arrays.asList(\n                  getSuperInterfaces(childInterface.getInterfaces())));\n      } else {\n        LOG.warn(\"Interface \" + childInterface +\n              \" ignored because it does not extend VersionedProtocol\");\n      }\n    }\n    return allInterfaces.toArray(new Class[allInterfaces.size()]);\n  }",
          "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/RPC.java",
          "extendedDetails": {
            "oldPath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/WritableRpcEngine.java",
            "newPath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/RPC.java",
            "oldMethodName": "getSuperInterfaces",
            "newMethodName": "getSuperInterfaces"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HADOOP-7862  Move the support for multiple protocols to lower layer so that Writable, PB and Avro can all use it (includes HDFS and MR changes to match) (Sanjay) \n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1210208 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "04/12/11 12:44 PM",
          "commitName": "65200998c01b17e017d1814e8b1f4d82ac334a23",
          "commitAuthor": "Sanjay Radia",
          "commitDateOld": "04/12/11 12:11 PM",
          "commitNameOld": "e948247715ba001b00eafc5f801fa926c409ea5a",
          "commitAuthorOld": "Mahadev Konar",
          "daysBetweenCommits": 0.02,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,16 +1,16 @@\n-  private static Class\u003c?\u003e[] getSuperInterfaces(Class\u003c?\u003e[] childInterfaces) {\n+  static Class\u003c?\u003e[] getSuperInterfaces(Class\u003c?\u003e[] childInterfaces) {\n     List\u003cClass\u003c?\u003e\u003e allInterfaces \u003d new ArrayList\u003cClass\u003c?\u003e\u003e();\n \n     for (Class\u003c?\u003e childInterface : childInterfaces) {\n       if (VersionedProtocol.class.isAssignableFrom(childInterface)) {\n           allInterfaces.add(childInterface);\n           allInterfaces.addAll(\n               Arrays.asList(\n                   getSuperInterfaces(childInterface.getInterfaces())));\n       } else {\n         LOG.warn(\"Interface \" + childInterface +\n               \" ignored because it does not extend VersionedProtocol\");\n       }\n     }\n-    return (Class\u003c?\u003e[]) allInterfaces.toArray(new Class[allInterfaces.size()]);\n+    return allInterfaces.toArray(new Class[allInterfaces.size()]);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static Class\u003c?\u003e[] getSuperInterfaces(Class\u003c?\u003e[] childInterfaces) {\n    List\u003cClass\u003c?\u003e\u003e allInterfaces \u003d new ArrayList\u003cClass\u003c?\u003e\u003e();\n\n    for (Class\u003c?\u003e childInterface : childInterfaces) {\n      if (VersionedProtocol.class.isAssignableFrom(childInterface)) {\n          allInterfaces.add(childInterface);\n          allInterfaces.addAll(\n              Arrays.asList(\n                  getSuperInterfaces(childInterface.getInterfaces())));\n      } else {\n        LOG.warn(\"Interface \" + childInterface +\n              \" ignored because it does not extend VersionedProtocol\");\n      }\n    }\n    return allInterfaces.toArray(new Class[allInterfaces.size()]);\n  }",
          "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/RPC.java",
          "extendedDetails": {
            "oldValue": "[private, static]",
            "newValue": "[static]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HADOOP-7862  Move the support for multiple protocols to lower layer so that Writable, PB and Avro can all use it (includes HDFS and MR changes to match) (Sanjay) \n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1210208 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "04/12/11 12:44 PM",
          "commitName": "65200998c01b17e017d1814e8b1f4d82ac334a23",
          "commitAuthor": "Sanjay Radia",
          "commitDateOld": "04/12/11 12:11 PM",
          "commitNameOld": "e948247715ba001b00eafc5f801fa926c409ea5a",
          "commitAuthorOld": "Mahadev Konar",
          "daysBetweenCommits": 0.02,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,16 +1,16 @@\n-  private static Class\u003c?\u003e[] getSuperInterfaces(Class\u003c?\u003e[] childInterfaces) {\n+  static Class\u003c?\u003e[] getSuperInterfaces(Class\u003c?\u003e[] childInterfaces) {\n     List\u003cClass\u003c?\u003e\u003e allInterfaces \u003d new ArrayList\u003cClass\u003c?\u003e\u003e();\n \n     for (Class\u003c?\u003e childInterface : childInterfaces) {\n       if (VersionedProtocol.class.isAssignableFrom(childInterface)) {\n           allInterfaces.add(childInterface);\n           allInterfaces.addAll(\n               Arrays.asList(\n                   getSuperInterfaces(childInterface.getInterfaces())));\n       } else {\n         LOG.warn(\"Interface \" + childInterface +\n               \" ignored because it does not extend VersionedProtocol\");\n       }\n     }\n-    return (Class\u003c?\u003e[]) allInterfaces.toArray(new Class[allInterfaces.size()]);\n+    return allInterfaces.toArray(new Class[allInterfaces.size()]);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static Class\u003c?\u003e[] getSuperInterfaces(Class\u003c?\u003e[] childInterfaces) {\n    List\u003cClass\u003c?\u003e\u003e allInterfaces \u003d new ArrayList\u003cClass\u003c?\u003e\u003e();\n\n    for (Class\u003c?\u003e childInterface : childInterfaces) {\n      if (VersionedProtocol.class.isAssignableFrom(childInterface)) {\n          allInterfaces.add(childInterface);\n          allInterfaces.addAll(\n              Arrays.asList(\n                  getSuperInterfaces(childInterface.getInterfaces())));\n      } else {\n        LOG.warn(\"Interface \" + childInterface +\n              \" ignored because it does not extend VersionedProtocol\");\n      }\n    }\n    return allInterfaces.toArray(new Class[allInterfaces.size()]);\n  }",
          "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/RPC.java",
          "extendedDetails": {}
        }
      ]
    },
    "b97a4d40c8752451fc02168a7f6eb3e93e459c2d": {
      "type": "Yintroduced",
      "commitMessage": "  HADOOP-7524 and MapReduce-2887 Change RPC to allow multiple protocols including multuple versions of the same protocol (sanjay Radia)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1164771 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/09/11 5:31 PM",
      "commitName": "b97a4d40c8752451fc02168a7f6eb3e93e459c2d",
      "commitAuthor": "Sanjay Radia",
      "diff": "@@ -0,0 +1,16 @@\n+  private static Class\u003c?\u003e[] getSuperInterfaces(Class\u003c?\u003e[] childInterfaces) {\n+    List\u003cClass\u003c?\u003e\u003e allInterfaces \u003d new ArrayList\u003cClass\u003c?\u003e\u003e();\n+\n+    for (Class\u003c?\u003e childInterface : childInterfaces) {\n+      if (VersionedProtocol.class.isAssignableFrom(childInterface)) {\n+          allInterfaces.add(childInterface);\n+          allInterfaces.addAll(\n+              Arrays.asList(\n+                  getSuperInterfaces(childInterface.getInterfaces())));\n+      } else {\n+        LOG.warn(\"Interface \" + childInterface +\n+              \" ignored because it does not extend VersionedProtocol\");\n+      }\n+    }\n+    return (Class\u003c?\u003e[]) allInterfaces.toArray(new Class[allInterfaces.size()]);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private static Class\u003c?\u003e[] getSuperInterfaces(Class\u003c?\u003e[] childInterfaces) {\n    List\u003cClass\u003c?\u003e\u003e allInterfaces \u003d new ArrayList\u003cClass\u003c?\u003e\u003e();\n\n    for (Class\u003c?\u003e childInterface : childInterfaces) {\n      if (VersionedProtocol.class.isAssignableFrom(childInterface)) {\n          allInterfaces.add(childInterface);\n          allInterfaces.addAll(\n              Arrays.asList(\n                  getSuperInterfaces(childInterface.getInterfaces())));\n      } else {\n        LOG.warn(\"Interface \" + childInterface +\n              \" ignored because it does not extend VersionedProtocol\");\n      }\n    }\n    return (Class\u003c?\u003e[]) allInterfaces.toArray(new Class[allInterfaces.size()]);\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/WritableRpcEngine.java"
    }
  }
}