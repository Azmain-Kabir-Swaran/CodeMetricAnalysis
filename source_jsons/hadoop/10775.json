{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockPoolSliceStorage.java",
  "functionName": "getRestoreDirectory",
  "functionId": "getRestoreDirectory___blockFile-File",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockPoolSliceStorage.java",
  "functionStartLine": 799,
  "functionEndLine": 804,
  "numCommitsSeen": 38,
  "timeTaken": 1873,
  "changeHistory": [
    "b3ae11d59790bb08b81848e9f944db7d3afbbd8a",
    "5df82fa01d26c18685ad7617128dbc2913547cb3"
  ],
  "changeHistoryShort": {
    "b3ae11d59790bb08b81848e9f944db7d3afbbd8a": "Ybodychange",
    "5df82fa01d26c18685ad7617128dbc2913547cb3": "Yintroduced"
  },
  "changeHistoryDetails": {
    "b3ae11d59790bb08b81848e9f944db7d3afbbd8a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12997. Move logging to slf4j in BlockPoolSliceStorage and Storage. Contributed by Ajay Kumar.\n",
      "commitDate": "01/02/18 10:45 AM",
      "commitName": "b3ae11d59790bb08b81848e9f944db7d3afbbd8a",
      "commitAuthor": "Xiaoyu Yao",
      "commitDateOld": "15/12/17 5:51 PM",
      "commitNameOld": "8239e3afb31d3c4485817d4b8b8b195b554acbe7",
      "commitAuthorOld": "Virajith Jalaparti",
      "daysBetweenCommits": 47.7,
      "commitsBetweenForRepo": 240,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,6 +1,6 @@\n   String getRestoreDirectory(File blockFile) {\n     Matcher matcher \u003d BLOCK_POOL_TRASH_PATH_PATTERN.matcher(blockFile.getParent());\n     String restoreDirectory \u003d matcher.replaceFirst(\"$1$2\" + STORAGE_DIR_CURRENT + \"$4\");\n-    LOG.info(\"Restoring \" + blockFile + \" to \" + restoreDirectory);\n+    LOG.info(\"Restoring {} to {}\", blockFile, restoreDirectory);\n     return restoreDirectory;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  String getRestoreDirectory(File blockFile) {\n    Matcher matcher \u003d BLOCK_POOL_TRASH_PATH_PATTERN.matcher(blockFile.getParent());\n    String restoreDirectory \u003d matcher.replaceFirst(\"$1$2\" + STORAGE_DIR_CURRENT + \"$4\");\n    LOG.info(\"Restoring {} to {}\", blockFile, restoreDirectory);\n    return restoreDirectory;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockPoolSliceStorage.java",
      "extendedDetails": {}
    },
    "5df82fa01d26c18685ad7617128dbc2913547cb3": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-5907. BlockPoolSliceStorage trash to handle block deletions during rolling upgrade. (Arpit Agarwal)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535@1568346 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/02/14 8:37 AM",
      "commitName": "5df82fa01d26c18685ad7617128dbc2913547cb3",
      "commitAuthor": "Arpit Agarwal",
      "diff": "@@ -0,0 +1,6 @@\n+  String getRestoreDirectory(File blockFile) {\n+    Matcher matcher \u003d BLOCK_POOL_TRASH_PATH_PATTERN.matcher(blockFile.getParent());\n+    String restoreDirectory \u003d matcher.replaceFirst(\"$1$2\" + STORAGE_DIR_CURRENT + \"$4\");\n+    LOG.info(\"Restoring \" + blockFile + \" to \" + restoreDirectory);\n+    return restoreDirectory;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  String getRestoreDirectory(File blockFile) {\n    Matcher matcher \u003d BLOCK_POOL_TRASH_PATH_PATTERN.matcher(blockFile.getParent());\n    String restoreDirectory \u003d matcher.replaceFirst(\"$1$2\" + STORAGE_DIR_CURRENT + \"$4\");\n    LOG.info(\"Restoring \" + blockFile + \" to \" + restoreDirectory);\n    return restoreDirectory;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockPoolSliceStorage.java"
    }
  }
}