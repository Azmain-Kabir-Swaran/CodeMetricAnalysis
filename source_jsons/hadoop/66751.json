{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "JobProperties.java",
  "functionName": "getAnonymizedValue",
  "functionId": "getAnonymizedValue___statePool-StatePool__conf-Configuration",
  "sourceFilePath": "hadoop-tools/hadoop-rumen/src/main/java/org/apache/hadoop/tools/rumen/datatypes/JobProperties.java",
  "functionStartLine": 52,
  "functionEndLine": 92,
  "numCommitsSeen": 2,
  "timeTaken": 1114,
  "changeHistory": [
    "10325d97329c214bb3899c8535df5a366bc86d2f",
    "a238f931ea7dce0ca620d1798156c84ff77097ff"
  ],
  "changeHistoryShort": {
    "10325d97329c214bb3899c8535df5a366bc86d2f": "Yfilerename",
    "a238f931ea7dce0ca620d1798156c84ff77097ff": "Yintroduced"
  },
  "changeHistoryDetails": {
    "10325d97329c214bb3899c8535df5a366bc86d2f": {
      "type": "Yfilerename",
      "commitMessage": "MAPREDUCE-3582. Move successfully passing MR1 tests to MR2 maven tree.(ahmed via tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1233090 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/01/12 2:10 PM",
      "commitName": "10325d97329c214bb3899c8535df5a366bc86d2f",
      "commitAuthor": "Alejandro Abdelnur",
      "commitDateOld": "18/01/12 10:20 AM",
      "commitNameOld": "8b2f6909ec7df5cffb5ef417f5c9cffdee43e38a",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.16,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public Properties getAnonymizedValue(StatePool statePool, \n                                       Configuration conf) {\n    Properties filteredProperties \u003d null;\n    List\u003cJobPropertyParser\u003e pList \u003d new ArrayList\u003cJobPropertyParser\u003e(1);\n    // load the parsers\n    String config \u003d conf.get(PARSERS_CONFIG_KEY);\n    if (config !\u003d null) {\n      @SuppressWarnings(\"unchecked\")\n      Class\u003cJobPropertyParser\u003e[] parsers \u003d \n        (Class[])conf.getClasses(PARSERS_CONFIG_KEY);\n      for (Class\u003cJobPropertyParser\u003e c : parsers) {\n        JobPropertyParser parser \u003d ReflectionUtils.newInstance(c, conf);\n        pList.add(parser);\n      }\n    } else {\n      // add the default MapReduce filter\n      JobPropertyParser parser \u003d new MapReduceJobPropertiesParser();\n      pList.add(parser);\n    }\n    \n    // filter out the desired config key-value pairs\n    if (jobProperties !\u003d null) {\n      filteredProperties \u003d new Properties();\n      // define a configuration object and load it with original job properties\n      for (Map.Entry\u003cObject, Object\u003e entry : jobProperties.entrySet()) {\n        //TODO Check for null key/value?\n        String key \u003d entry.getKey().toString();\n        String value \u003d entry.getValue().toString(); \n        \n        // find a parser for this key\n        for (JobPropertyParser p : pList) {\n          DataType\u003c?\u003e pValue \u003d p.parseJobProperty(key, value);\n          if (pValue !\u003d null) {\n            filteredProperties.put(key, pValue);\n            break;\n          }\n        }\n      }\n    }\n    return filteredProperties;\n  }",
      "path": "hadoop-tools/hadoop-rumen/src/main/java/org/apache/hadoop/tools/rumen/datatypes/JobProperties.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce-project/src/tools/org/apache/hadoop/tools/rumen/datatypes/JobProperties.java",
        "newPath": "hadoop-tools/hadoop-rumen/src/main/java/org/apache/hadoop/tools/rumen/datatypes/JobProperties.java"
      }
    },
    "a238f931ea7dce0ca620d1798156c84ff77097ff": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-778. Rumen Anonymizer. (Amar Kamat and Chris Douglas via amarrk)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1215141 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/12/11 6:20 AM",
      "commitName": "a238f931ea7dce0ca620d1798156c84ff77097ff",
      "commitAuthor": "Amar Kamat",
      "diff": "@@ -0,0 +1,41 @@\n+  public Properties getAnonymizedValue(StatePool statePool, \n+                                       Configuration conf) {\n+    Properties filteredProperties \u003d null;\n+    List\u003cJobPropertyParser\u003e pList \u003d new ArrayList\u003cJobPropertyParser\u003e(1);\n+    // load the parsers\n+    String config \u003d conf.get(PARSERS_CONFIG_KEY);\n+    if (config !\u003d null) {\n+      @SuppressWarnings(\"unchecked\")\n+      Class\u003cJobPropertyParser\u003e[] parsers \u003d \n+        (Class[])conf.getClasses(PARSERS_CONFIG_KEY);\n+      for (Class\u003cJobPropertyParser\u003e c : parsers) {\n+        JobPropertyParser parser \u003d ReflectionUtils.newInstance(c, conf);\n+        pList.add(parser);\n+      }\n+    } else {\n+      // add the default MapReduce filter\n+      JobPropertyParser parser \u003d new MapReduceJobPropertiesParser();\n+      pList.add(parser);\n+    }\n+    \n+    // filter out the desired config key-value pairs\n+    if (jobProperties !\u003d null) {\n+      filteredProperties \u003d new Properties();\n+      // define a configuration object and load it with original job properties\n+      for (Map.Entry\u003cObject, Object\u003e entry : jobProperties.entrySet()) {\n+        //TODO Check for null key/value?\n+        String key \u003d entry.getKey().toString();\n+        String value \u003d entry.getValue().toString(); \n+        \n+        // find a parser for this key\n+        for (JobPropertyParser p : pList) {\n+          DataType\u003c?\u003e pValue \u003d p.parseJobProperty(key, value);\n+          if (pValue !\u003d null) {\n+            filteredProperties.put(key, pValue);\n+            break;\n+          }\n+        }\n+      }\n+    }\n+    return filteredProperties;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public Properties getAnonymizedValue(StatePool statePool, \n                                       Configuration conf) {\n    Properties filteredProperties \u003d null;\n    List\u003cJobPropertyParser\u003e pList \u003d new ArrayList\u003cJobPropertyParser\u003e(1);\n    // load the parsers\n    String config \u003d conf.get(PARSERS_CONFIG_KEY);\n    if (config !\u003d null) {\n      @SuppressWarnings(\"unchecked\")\n      Class\u003cJobPropertyParser\u003e[] parsers \u003d \n        (Class[])conf.getClasses(PARSERS_CONFIG_KEY);\n      for (Class\u003cJobPropertyParser\u003e c : parsers) {\n        JobPropertyParser parser \u003d ReflectionUtils.newInstance(c, conf);\n        pList.add(parser);\n      }\n    } else {\n      // add the default MapReduce filter\n      JobPropertyParser parser \u003d new MapReduceJobPropertiesParser();\n      pList.add(parser);\n    }\n    \n    // filter out the desired config key-value pairs\n    if (jobProperties !\u003d null) {\n      filteredProperties \u003d new Properties();\n      // define a configuration object and load it with original job properties\n      for (Map.Entry\u003cObject, Object\u003e entry : jobProperties.entrySet()) {\n        //TODO Check for null key/value?\n        String key \u003d entry.getKey().toString();\n        String value \u003d entry.getValue().toString(); \n        \n        // find a parser for this key\n        for (JobPropertyParser p : pList) {\n          DataType\u003c?\u003e pValue \u003d p.parseJobProperty(key, value);\n          if (pValue !\u003d null) {\n            filteredProperties.put(key, pValue);\n            break;\n          }\n        }\n      }\n    }\n    return filteredProperties;\n  }",
      "path": "hadoop-mapreduce-project/src/tools/org/apache/hadoop/tools/rumen/datatypes/JobProperties.java"
    }
  }
}