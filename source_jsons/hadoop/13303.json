{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DatanodeManager.java",
  "functionName": "registerDatanode",
  "functionId": "registerDatanode___nodeReg-DatanodeRegistration",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
  "functionStartLine": 1047,
  "functionEndLine": 1204,
  "numCommitsSeen": 195,
  "timeTaken": 14854,
  "changeHistory": [
    "80b77deb42a3ef94d6bef160bc58d807f2faa104",
    "39ed3a66dbb01383ed16b141183fc48bfd2e613d",
    "00eceed233d6e80d5c7137bf5b5286746ec4d5fb",
    "695a402fcad20c711c5d845e0664c43fd6b06286",
    "9dcbdbdb5a34d85910707f81ebc1bb1f81c99978",
    "fde8ac5d8514f5146f438f8d0794116aaef20416",
    "df83230948204ee2d2b06ecc66ce0163e2df27ef",
    "8602692338d6f493647205e0241e4116211fab75",
    "2ffd84273ac490724fe7e7825664bb6d09ef0e99",
    "6ee0d32b98bc3aa5ed42859f1325d5a14fd1722a",
    "5bd048e8378034b496bacc73b470a25d855aceb1",
    "b2f65c276da2c4420a0974a7e2d75e081abf5d63",
    "328fc86bdbf84fcc80a0920b2cacfc2e74ac5c9f",
    "9660bfa84c900afd4824feb62d14256584edfb95",
    "34f08944b7c8d58f531a3f3bf3d4ee4cd3fa643a",
    "0a5f0efcb4c906dd5820925cce8723946841be61",
    "46099ce7f1a1d5aab85d9408dc1454fcbe54f7e8",
    "8a66e493ba03f710b353638647013401d18f413c",
    "4551da302d94cffea0313eac79479ab6f9b7cb34",
    "39252995c4d734e993e3fa5338e1a7816aee86fc",
    "6f699e8ea5d8a48c3daaf8dffa2292ce0524cfdb",
    "a7bfb25d2bbab0a329712d1efb143edc49a4076d",
    "5d2ffde68e2c14ee33fa2ba4a34cb42fbd14b5ec",
    "64741f46352f25743bfb77f804a06970d355a177",
    "f31b8270db0dd1a4670ce6e921df18725d7a9248",
    "be94bf6b57895846853d3e0ebc5c33b4f725ae2c",
    "cea7bbc630deede93dbe6a1bbda56ad49de4f3de",
    "4d5600f6c714732d16bed29f0bc210eb72901545",
    "08f35a04c69ea20913bb28b00a1827c77e0e23e3",
    "be7dd8333a7e56e732171db0781786987de03195",
    "0663dbaac0a19719ddf9cd4290ba893bfca69da2",
    "8bd825bb6f35fd6fef397e3ccae0898bf7bed201",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "371f4a59059322000a40eb4bdf5386b96b626ece",
    "7fac946ac983e31613fd62836c8ac9c4a579210a",
    "d68e38b78d9687987c4de2046ce9aa0016685e98",
    "969a263188f7015261719fe45fa1505121ebb80e",
    "233a7aa34f37350bf7bcdd9c84b97d613e7344c9",
    "c3f6575ca44e8ad803d0b46991472465b595cdeb",
    "8327e70be87990c37ac14dcc1cb1a4d209c65593",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "80b77deb42a3ef94d6bef160bc58d807f2faa104": "Ybodychange",
    "39ed3a66dbb01383ed16b141183fc48bfd2e613d": "Ybodychange",
    "00eceed233d6e80d5c7137bf5b5286746ec4d5fb": "Ybodychange",
    "695a402fcad20c711c5d845e0664c43fd6b06286": "Ybodychange",
    "9dcbdbdb5a34d85910707f81ebc1bb1f81c99978": "Ybodychange",
    "fde8ac5d8514f5146f438f8d0794116aaef20416": "Ybodychange",
    "df83230948204ee2d2b06ecc66ce0163e2df27ef": "Ybodychange",
    "8602692338d6f493647205e0241e4116211fab75": "Ybodychange",
    "2ffd84273ac490724fe7e7825664bb6d09ef0e99": "Ybodychange",
    "6ee0d32b98bc3aa5ed42859f1325d5a14fd1722a": "Ybodychange",
    "5bd048e8378034b496bacc73b470a25d855aceb1": "Ybodychange",
    "b2f65c276da2c4420a0974a7e2d75e081abf5d63": "Ybodychange",
    "328fc86bdbf84fcc80a0920b2cacfc2e74ac5c9f": "Ymultichange(Yexceptionschange,Ybodychange)",
    "9660bfa84c900afd4824feb62d14256584edfb95": "Ybodychange",
    "34f08944b7c8d58f531a3f3bf3d4ee4cd3fa643a": "Ybodychange",
    "0a5f0efcb4c906dd5820925cce8723946841be61": "Ybodychange",
    "46099ce7f1a1d5aab85d9408dc1454fcbe54f7e8": "Ybodychange",
    "8a66e493ba03f710b353638647013401d18f413c": "Ybodychange",
    "4551da302d94cffea0313eac79479ab6f9b7cb34": "Ybodychange",
    "39252995c4d734e993e3fa5338e1a7816aee86fc": "Ybodychange",
    "6f699e8ea5d8a48c3daaf8dffa2292ce0524cfdb": "Ybodychange",
    "a7bfb25d2bbab0a329712d1efb143edc49a4076d": "Ybodychange",
    "5d2ffde68e2c14ee33fa2ba4a34cb42fbd14b5ec": "Ybodychange",
    "64741f46352f25743bfb77f804a06970d355a177": "Ybodychange",
    "f31b8270db0dd1a4670ce6e921df18725d7a9248": "Ybodychange",
    "be94bf6b57895846853d3e0ebc5c33b4f725ae2c": "Ybodychange",
    "cea7bbc630deede93dbe6a1bbda56ad49de4f3de": "Ybodychange",
    "4d5600f6c714732d16bed29f0bc210eb72901545": "Ybodychange",
    "08f35a04c69ea20913bb28b00a1827c77e0e23e3": "Ybodychange",
    "be7dd8333a7e56e732171db0781786987de03195": "Ybodychange",
    "0663dbaac0a19719ddf9cd4290ba893bfca69da2": "Ymultichange(Yexceptionschange,Ybodychange)",
    "8bd825bb6f35fd6fef397e3ccae0898bf7bed201": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "371f4a59059322000a40eb4bdf5386b96b626ece": "Ybodychange",
    "7fac946ac983e31613fd62836c8ac9c4a579210a": "Ybodychange",
    "d68e38b78d9687987c4de2046ce9aa0016685e98": "Ybodychange",
    "969a263188f7015261719fe45fa1505121ebb80e": "Ybodychange",
    "233a7aa34f37350bf7bcdd9c84b97d613e7344c9": "Ymultichange(Ymovefromfile,Ybodychange,Yrename)",
    "c3f6575ca44e8ad803d0b46991472465b595cdeb": "Ybodychange",
    "8327e70be87990c37ac14dcc1cb1a4d209c65593": "Ybodychange",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "80b77deb42a3ef94d6bef160bc58d807f2faa104": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14247. Repeat adding node description into network topology. Contributed by HuangTao.\n",
      "commitDate": "01/03/19 9:18 AM",
      "commitName": "80b77deb42a3ef94d6bef160bc58d807f2faa104",
      "commitAuthor": "Inigo Goiri",
      "commitDateOld": "03/12/18 10:01 AM",
      "commitNameOld": "dd5e7c6b7239a93f2391beaa11181e442a387db4",
      "commitAuthorOld": "Kitti Nanasi",
      "daysBetweenCommits": 87.97,
      "commitsBetweenForRepo": 627,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,159 +1,158 @@\n   public void registerDatanode(DatanodeRegistration nodeReg)\n       throws DisallowedDatanodeException, UnresolvedTopologyException {\n     InetAddress dnAddress \u003d Server.getRemoteIp();\n     if (dnAddress !\u003d null) {\n       // Mostly called inside an RPC, update ip and peer hostname\n       String hostname \u003d dnAddress.getHostName();\n       String ip \u003d dnAddress.getHostAddress();\n       if (checkIpHostnameInRegistration \u0026\u0026 !isNameResolved(dnAddress)) {\n         // Reject registration of unresolved datanode to prevent performance\n         // impact of repetitive DNS lookups later.\n         final String message \u003d \"hostname cannot be resolved (ip\u003d\"\n             + ip + \", hostname\u003d\" + hostname + \")\";\n         LOG.warn(\"Unresolved datanode registration: \" + message);\n         throw new DisallowedDatanodeException(nodeReg, message);\n       }\n       // update node registration with the ip and hostname from rpc request\n       nodeReg.setIpAddr(ip);\n       nodeReg.setPeerHostName(hostname);\n     }\n     \n     try {\n       nodeReg.setExportedKeys(blockManager.getBlockKeys());\n   \n       // Checks if the node is not on the hosts list.  If it is not, then\n       // it will be disallowed from registering. \n       if (!hostConfigManager.isIncluded(nodeReg)) {\n         throw new DisallowedDatanodeException(nodeReg);\n       }\n         \n       NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n           + nodeReg + \" storage \" + nodeReg.getDatanodeUuid());\n   \n       DatanodeDescriptor nodeS \u003d getDatanode(nodeReg.getDatanodeUuid());\n       DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n           nodeReg.getIpAddr(), nodeReg.getXferPort());\n         \n       if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n         NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n         // nodeN previously served a different data storage, \n         // which is not served by anybody anymore.\n         removeDatanode(nodeN);\n         // physically remove node from datanodeMap\n         wipeDatanode(nodeN);\n         nodeN \u003d null;\n       }\n   \n       if (nodeS !\u003d null) {\n         if (nodeN \u003d\u003d nodeS) {\n           // The same datanode has been just restarted to serve the same data \n           // storage. We do not need to remove old data blocks, the delta will\n           // be calculated on the next block report from the datanode\n           if(NameNode.stateChangeLog.isDebugEnabled()) {\n             NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n                 + \"node restarted.\");\n           }\n         } else {\n           // nodeS is found\n           /* The registering datanode is a replacement node for the existing \n             data storage, which from now on will be served by a new node.\n             If this message repeats, both nodes might have same storageID \n             by (insanely rare) random chance. User needs to restart one of the\n             nodes with its data cleared (or user can just remove the StorageID\n             value in \"VERSION\" file under the data directory of the datanode,\n             but this is might not work if VERSION file format has changed \n          */        \n           NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n               + \" is replaced by \" + nodeReg + \" with the same storageID \"\n               + nodeReg.getDatanodeUuid());\n         }\n         \n         boolean success \u003d false;\n         try {\n           // update cluster map\n           getNetworkTopology().remove(nodeS);\n           if(shouldCountVersion(nodeS)) {\n             decrementVersionCount(nodeS.getSoftwareVersion());\n           }\n           nodeS.updateRegInfo(nodeReg);\n \n           nodeS.setSoftwareVersion(nodeReg.getSoftwareVersion());\n           nodeS.setDisallowed(false); // Node is in the include list\n \n           // resolve network location\n           if(this.rejectUnresolvedTopologyDN) {\n             nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));\n             nodeS.setDependentHostNames(getNetworkDependencies(nodeS));\n           } else {\n             nodeS.setNetworkLocation(\n                 resolveNetworkLocationWithFallBackToDefaultLocation(nodeS));\n             nodeS.setDependentHostNames(\n                 getNetworkDependenciesWithDefault(nodeS));\n           }\n           getNetworkTopology().add(nodeS);\n           resolveUpgradeDomain(nodeS);\n \n           // also treat the registration message as a heartbeat\n           heartbeatManager.register(nodeS);\n           incrementVersionCount(nodeS.getSoftwareVersion());\n           startAdminOperationIfNecessary(nodeS);\n           success \u003d true;\n         } finally {\n           if (!success) {\n             removeDatanode(nodeS);\n             wipeDatanode(nodeS);\n             countSoftwareVersions();\n           }\n         }\n         return;\n       }\n \n       DatanodeDescriptor nodeDescr \n         \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n       boolean success \u003d false;\n       try {\n         // resolve network location\n         if(this.rejectUnresolvedTopologyDN) {\n           nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n           nodeDescr.setDependentHostNames(getNetworkDependencies(nodeDescr));\n         } else {\n           nodeDescr.setNetworkLocation(\n               resolveNetworkLocationWithFallBackToDefaultLocation(nodeDescr));\n           nodeDescr.setDependentHostNames(\n               getNetworkDependenciesWithDefault(nodeDescr));\n         }\n-        networktopology.add(nodeDescr);\n         nodeDescr.setSoftwareVersion(nodeReg.getSoftwareVersion());\n         resolveUpgradeDomain(nodeDescr);\n \n         // register new datanode\n         addDatanode(nodeDescr);\n         blockManager.getBlockReportLeaseManager().register(nodeDescr);\n         // also treat the registration message as a heartbeat\n         // no need to update its timestamp\n         // because its is done when the descriptor is created\n         heartbeatManager.addDatanode(nodeDescr);\n         heartbeatManager.updateDnStat(nodeDescr);\n         incrementVersionCount(nodeReg.getSoftwareVersion());\n         startAdminOperationIfNecessary(nodeDescr);\n         success \u003d true;\n       } finally {\n         if (!success) {\n           removeDatanode(nodeDescr);\n           wipeDatanode(nodeDescr);\n           countSoftwareVersions();\n         }\n       }\n     } catch (InvalidTopologyException e) {\n       // If the network location is invalid, clear the cached mappings\n       // so that we have a chance to re-add this DataNode with the\n       // correct network location later.\n       List\u003cString\u003e invalidNodeNames \u003d new ArrayList\u003c\u003e(3);\n       // clear cache for nodes in IP or Hostname\n       invalidNodeNames.add(nodeReg.getIpAddr());\n       invalidNodeNames.add(nodeReg.getHostName());\n       invalidNodeNames.add(nodeReg.getPeerHostName());\n       dnsToSwitchMapping.reloadCachedMappings(invalidNodeNames);\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void registerDatanode(DatanodeRegistration nodeReg)\n      throws DisallowedDatanodeException, UnresolvedTopologyException {\n    InetAddress dnAddress \u003d Server.getRemoteIp();\n    if (dnAddress !\u003d null) {\n      // Mostly called inside an RPC, update ip and peer hostname\n      String hostname \u003d dnAddress.getHostName();\n      String ip \u003d dnAddress.getHostAddress();\n      if (checkIpHostnameInRegistration \u0026\u0026 !isNameResolved(dnAddress)) {\n        // Reject registration of unresolved datanode to prevent performance\n        // impact of repetitive DNS lookups later.\n        final String message \u003d \"hostname cannot be resolved (ip\u003d\"\n            + ip + \", hostname\u003d\" + hostname + \")\";\n        LOG.warn(\"Unresolved datanode registration: \" + message);\n        throw new DisallowedDatanodeException(nodeReg, message);\n      }\n      // update node registration with the ip and hostname from rpc request\n      nodeReg.setIpAddr(ip);\n      nodeReg.setPeerHostName(hostname);\n    }\n    \n    try {\n      nodeReg.setExportedKeys(blockManager.getBlockKeys());\n  \n      // Checks if the node is not on the hosts list.  If it is not, then\n      // it will be disallowed from registering. \n      if (!hostConfigManager.isIncluded(nodeReg)) {\n        throw new DisallowedDatanodeException(nodeReg);\n      }\n        \n      NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n          + nodeReg + \" storage \" + nodeReg.getDatanodeUuid());\n  \n      DatanodeDescriptor nodeS \u003d getDatanode(nodeReg.getDatanodeUuid());\n      DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n          nodeReg.getIpAddr(), nodeReg.getXferPort());\n        \n      if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n        NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n        // nodeN previously served a different data storage, \n        // which is not served by anybody anymore.\n        removeDatanode(nodeN);\n        // physically remove node from datanodeMap\n        wipeDatanode(nodeN);\n        nodeN \u003d null;\n      }\n  \n      if (nodeS !\u003d null) {\n        if (nodeN \u003d\u003d nodeS) {\n          // The same datanode has been just restarted to serve the same data \n          // storage. We do not need to remove old data blocks, the delta will\n          // be calculated on the next block report from the datanode\n          if(NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n                + \"node restarted.\");\n          }\n        } else {\n          // nodeS is found\n          /* The registering datanode is a replacement node for the existing \n            data storage, which from now on will be served by a new node.\n            If this message repeats, both nodes might have same storageID \n            by (insanely rare) random chance. User needs to restart one of the\n            nodes with its data cleared (or user can just remove the StorageID\n            value in \"VERSION\" file under the data directory of the datanode,\n            but this is might not work if VERSION file format has changed \n         */        \n          NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n              + \" is replaced by \" + nodeReg + \" with the same storageID \"\n              + nodeReg.getDatanodeUuid());\n        }\n        \n        boolean success \u003d false;\n        try {\n          // update cluster map\n          getNetworkTopology().remove(nodeS);\n          if(shouldCountVersion(nodeS)) {\n            decrementVersionCount(nodeS.getSoftwareVersion());\n          }\n          nodeS.updateRegInfo(nodeReg);\n\n          nodeS.setSoftwareVersion(nodeReg.getSoftwareVersion());\n          nodeS.setDisallowed(false); // Node is in the include list\n\n          // resolve network location\n          if(this.rejectUnresolvedTopologyDN) {\n            nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));\n            nodeS.setDependentHostNames(getNetworkDependencies(nodeS));\n          } else {\n            nodeS.setNetworkLocation(\n                resolveNetworkLocationWithFallBackToDefaultLocation(nodeS));\n            nodeS.setDependentHostNames(\n                getNetworkDependenciesWithDefault(nodeS));\n          }\n          getNetworkTopology().add(nodeS);\n          resolveUpgradeDomain(nodeS);\n\n          // also treat the registration message as a heartbeat\n          heartbeatManager.register(nodeS);\n          incrementVersionCount(nodeS.getSoftwareVersion());\n          startAdminOperationIfNecessary(nodeS);\n          success \u003d true;\n        } finally {\n          if (!success) {\n            removeDatanode(nodeS);\n            wipeDatanode(nodeS);\n            countSoftwareVersions();\n          }\n        }\n        return;\n      }\n\n      DatanodeDescriptor nodeDescr \n        \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n      boolean success \u003d false;\n      try {\n        // resolve network location\n        if(this.rejectUnresolvedTopologyDN) {\n          nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n          nodeDescr.setDependentHostNames(getNetworkDependencies(nodeDescr));\n        } else {\n          nodeDescr.setNetworkLocation(\n              resolveNetworkLocationWithFallBackToDefaultLocation(nodeDescr));\n          nodeDescr.setDependentHostNames(\n              getNetworkDependenciesWithDefault(nodeDescr));\n        }\n        nodeDescr.setSoftwareVersion(nodeReg.getSoftwareVersion());\n        resolveUpgradeDomain(nodeDescr);\n\n        // register new datanode\n        addDatanode(nodeDescr);\n        blockManager.getBlockReportLeaseManager().register(nodeDescr);\n        // also treat the registration message as a heartbeat\n        // no need to update its timestamp\n        // because its is done when the descriptor is created\n        heartbeatManager.addDatanode(nodeDescr);\n        heartbeatManager.updateDnStat(nodeDescr);\n        incrementVersionCount(nodeReg.getSoftwareVersion());\n        startAdminOperationIfNecessary(nodeDescr);\n        success \u003d true;\n      } finally {\n        if (!success) {\n          removeDatanode(nodeDescr);\n          wipeDatanode(nodeDescr);\n          countSoftwareVersions();\n        }\n      }\n    } catch (InvalidTopologyException e) {\n      // If the network location is invalid, clear the cached mappings\n      // so that we have a chance to re-add this DataNode with the\n      // correct network location later.\n      List\u003cString\u003e invalidNodeNames \u003d new ArrayList\u003c\u003e(3);\n      // clear cache for nodes in IP or Hostname\n      invalidNodeNames.add(nodeReg.getIpAddr());\n      invalidNodeNames.add(nodeReg.getHostName());\n      invalidNodeNames.add(nodeReg.getPeerHostName());\n      dnsToSwitchMapping.reloadCachedMappings(invalidNodeNames);\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "39ed3a66dbb01383ed16b141183fc48bfd2e613d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13076: [SPS]: Cleanup work for HDFS-10285 merge. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "39ed3a66dbb01383ed16b141183fc48bfd2e613d",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "99594b48b8e040ab5a0939d7c3dbcfb34400e6fc",
      "commitAuthorOld": "Surendra Singh Lilhore",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 10,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,172 +1,159 @@\n   public void registerDatanode(DatanodeRegistration nodeReg)\n       throws DisallowedDatanodeException, UnresolvedTopologyException {\n     InetAddress dnAddress \u003d Server.getRemoteIp();\n     if (dnAddress !\u003d null) {\n       // Mostly called inside an RPC, update ip and peer hostname\n       String hostname \u003d dnAddress.getHostName();\n       String ip \u003d dnAddress.getHostAddress();\n       if (checkIpHostnameInRegistration \u0026\u0026 !isNameResolved(dnAddress)) {\n         // Reject registration of unresolved datanode to prevent performance\n         // impact of repetitive DNS lookups later.\n         final String message \u003d \"hostname cannot be resolved (ip\u003d\"\n             + ip + \", hostname\u003d\" + hostname + \")\";\n         LOG.warn(\"Unresolved datanode registration: \" + message);\n         throw new DisallowedDatanodeException(nodeReg, message);\n       }\n       // update node registration with the ip and hostname from rpc request\n       nodeReg.setIpAddr(ip);\n       nodeReg.setPeerHostName(hostname);\n     }\n     \n     try {\n       nodeReg.setExportedKeys(blockManager.getBlockKeys());\n   \n       // Checks if the node is not on the hosts list.  If it is not, then\n       // it will be disallowed from registering. \n       if (!hostConfigManager.isIncluded(nodeReg)) {\n         throw new DisallowedDatanodeException(nodeReg);\n       }\n         \n       NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n           + nodeReg + \" storage \" + nodeReg.getDatanodeUuid());\n   \n       DatanodeDescriptor nodeS \u003d getDatanode(nodeReg.getDatanodeUuid());\n       DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n           nodeReg.getIpAddr(), nodeReg.getXferPort());\n         \n       if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n         NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n         // nodeN previously served a different data storage, \n         // which is not served by anybody anymore.\n         removeDatanode(nodeN);\n         // physically remove node from datanodeMap\n         wipeDatanode(nodeN);\n         nodeN \u003d null;\n       }\n   \n       if (nodeS !\u003d null) {\n         if (nodeN \u003d\u003d nodeS) {\n           // The same datanode has been just restarted to serve the same data \n           // storage. We do not need to remove old data blocks, the delta will\n           // be calculated on the next block report from the datanode\n           if(NameNode.stateChangeLog.isDebugEnabled()) {\n             NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n                 + \"node restarted.\");\n           }\n         } else {\n           // nodeS is found\n           /* The registering datanode is a replacement node for the existing \n             data storage, which from now on will be served by a new node.\n             If this message repeats, both nodes might have same storageID \n             by (insanely rare) random chance. User needs to restart one of the\n             nodes with its data cleared (or user can just remove the StorageID\n             value in \"VERSION\" file under the data directory of the datanode,\n             but this is might not work if VERSION file format has changed \n          */        \n           NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n               + \" is replaced by \" + nodeReg + \" with the same storageID \"\n               + nodeReg.getDatanodeUuid());\n         }\n         \n         boolean success \u003d false;\n         try {\n           // update cluster map\n           getNetworkTopology().remove(nodeS);\n           if(shouldCountVersion(nodeS)) {\n             decrementVersionCount(nodeS.getSoftwareVersion());\n           }\n           nodeS.updateRegInfo(nodeReg);\n \n           nodeS.setSoftwareVersion(nodeReg.getSoftwareVersion());\n           nodeS.setDisallowed(false); // Node is in the include list\n \n-          // Sets dropSPSWork flag to true, to ensure that\n-          // DNA_DROP_SPS_WORK_COMMAND will send to datanode via next heartbeat\n-          // response immediately after the node registration. This is\n-          // to avoid a situation, where multiple block attempt finished\n-          // responses coming from different datanodes. After SPS monitor time\n-          // out, it will retry the files which were scheduled to the\n-          // disconnected(for long time more than heartbeat expiry) DN, by\n-          // finding new datanode. Now, if the expired datanode reconnects back\n-          // after SPS reschedules, it leads to get different movement attempt\n-          // finished report from reconnected and newly datanode which is\n-          // attempting the block movement.\n-          nodeS.setDropSPSWork(true);\n-\n           // resolve network location\n           if(this.rejectUnresolvedTopologyDN) {\n             nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));\n             nodeS.setDependentHostNames(getNetworkDependencies(nodeS));\n           } else {\n             nodeS.setNetworkLocation(\n                 resolveNetworkLocationWithFallBackToDefaultLocation(nodeS));\n             nodeS.setDependentHostNames(\n                 getNetworkDependenciesWithDefault(nodeS));\n           }\n           getNetworkTopology().add(nodeS);\n           resolveUpgradeDomain(nodeS);\n \n           // also treat the registration message as a heartbeat\n           heartbeatManager.register(nodeS);\n           incrementVersionCount(nodeS.getSoftwareVersion());\n           startAdminOperationIfNecessary(nodeS);\n           success \u003d true;\n         } finally {\n           if (!success) {\n             removeDatanode(nodeS);\n             wipeDatanode(nodeS);\n             countSoftwareVersions();\n           }\n         }\n         return;\n       }\n \n       DatanodeDescriptor nodeDescr \n         \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n       boolean success \u003d false;\n       try {\n         // resolve network location\n         if(this.rejectUnresolvedTopologyDN) {\n           nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n           nodeDescr.setDependentHostNames(getNetworkDependencies(nodeDescr));\n         } else {\n           nodeDescr.setNetworkLocation(\n               resolveNetworkLocationWithFallBackToDefaultLocation(nodeDescr));\n           nodeDescr.setDependentHostNames(\n               getNetworkDependenciesWithDefault(nodeDescr));\n         }\n         networktopology.add(nodeDescr);\n         nodeDescr.setSoftwareVersion(nodeReg.getSoftwareVersion());\n         resolveUpgradeDomain(nodeDescr);\n \n         // register new datanode\n         addDatanode(nodeDescr);\n         blockManager.getBlockReportLeaseManager().register(nodeDescr);\n         // also treat the registration message as a heartbeat\n         // no need to update its timestamp\n         // because its is done when the descriptor is created\n         heartbeatManager.addDatanode(nodeDescr);\n         heartbeatManager.updateDnStat(nodeDescr);\n         incrementVersionCount(nodeReg.getSoftwareVersion());\n         startAdminOperationIfNecessary(nodeDescr);\n         success \u003d true;\n       } finally {\n         if (!success) {\n           removeDatanode(nodeDescr);\n           wipeDatanode(nodeDescr);\n           countSoftwareVersions();\n         }\n       }\n     } catch (InvalidTopologyException e) {\n       // If the network location is invalid, clear the cached mappings\n       // so that we have a chance to re-add this DataNode with the\n       // correct network location later.\n       List\u003cString\u003e invalidNodeNames \u003d new ArrayList\u003c\u003e(3);\n       // clear cache for nodes in IP or Hostname\n       invalidNodeNames.add(nodeReg.getIpAddr());\n       invalidNodeNames.add(nodeReg.getHostName());\n       invalidNodeNames.add(nodeReg.getPeerHostName());\n       dnsToSwitchMapping.reloadCachedMappings(invalidNodeNames);\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void registerDatanode(DatanodeRegistration nodeReg)\n      throws DisallowedDatanodeException, UnresolvedTopologyException {\n    InetAddress dnAddress \u003d Server.getRemoteIp();\n    if (dnAddress !\u003d null) {\n      // Mostly called inside an RPC, update ip and peer hostname\n      String hostname \u003d dnAddress.getHostName();\n      String ip \u003d dnAddress.getHostAddress();\n      if (checkIpHostnameInRegistration \u0026\u0026 !isNameResolved(dnAddress)) {\n        // Reject registration of unresolved datanode to prevent performance\n        // impact of repetitive DNS lookups later.\n        final String message \u003d \"hostname cannot be resolved (ip\u003d\"\n            + ip + \", hostname\u003d\" + hostname + \")\";\n        LOG.warn(\"Unresolved datanode registration: \" + message);\n        throw new DisallowedDatanodeException(nodeReg, message);\n      }\n      // update node registration with the ip and hostname from rpc request\n      nodeReg.setIpAddr(ip);\n      nodeReg.setPeerHostName(hostname);\n    }\n    \n    try {\n      nodeReg.setExportedKeys(blockManager.getBlockKeys());\n  \n      // Checks if the node is not on the hosts list.  If it is not, then\n      // it will be disallowed from registering. \n      if (!hostConfigManager.isIncluded(nodeReg)) {\n        throw new DisallowedDatanodeException(nodeReg);\n      }\n        \n      NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n          + nodeReg + \" storage \" + nodeReg.getDatanodeUuid());\n  \n      DatanodeDescriptor nodeS \u003d getDatanode(nodeReg.getDatanodeUuid());\n      DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n          nodeReg.getIpAddr(), nodeReg.getXferPort());\n        \n      if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n        NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n        // nodeN previously served a different data storage, \n        // which is not served by anybody anymore.\n        removeDatanode(nodeN);\n        // physically remove node from datanodeMap\n        wipeDatanode(nodeN);\n        nodeN \u003d null;\n      }\n  \n      if (nodeS !\u003d null) {\n        if (nodeN \u003d\u003d nodeS) {\n          // The same datanode has been just restarted to serve the same data \n          // storage. We do not need to remove old data blocks, the delta will\n          // be calculated on the next block report from the datanode\n          if(NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n                + \"node restarted.\");\n          }\n        } else {\n          // nodeS is found\n          /* The registering datanode is a replacement node for the existing \n            data storage, which from now on will be served by a new node.\n            If this message repeats, both nodes might have same storageID \n            by (insanely rare) random chance. User needs to restart one of the\n            nodes with its data cleared (or user can just remove the StorageID\n            value in \"VERSION\" file under the data directory of the datanode,\n            but this is might not work if VERSION file format has changed \n         */        \n          NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n              + \" is replaced by \" + nodeReg + \" with the same storageID \"\n              + nodeReg.getDatanodeUuid());\n        }\n        \n        boolean success \u003d false;\n        try {\n          // update cluster map\n          getNetworkTopology().remove(nodeS);\n          if(shouldCountVersion(nodeS)) {\n            decrementVersionCount(nodeS.getSoftwareVersion());\n          }\n          nodeS.updateRegInfo(nodeReg);\n\n          nodeS.setSoftwareVersion(nodeReg.getSoftwareVersion());\n          nodeS.setDisallowed(false); // Node is in the include list\n\n          // resolve network location\n          if(this.rejectUnresolvedTopologyDN) {\n            nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));\n            nodeS.setDependentHostNames(getNetworkDependencies(nodeS));\n          } else {\n            nodeS.setNetworkLocation(\n                resolveNetworkLocationWithFallBackToDefaultLocation(nodeS));\n            nodeS.setDependentHostNames(\n                getNetworkDependenciesWithDefault(nodeS));\n          }\n          getNetworkTopology().add(nodeS);\n          resolveUpgradeDomain(nodeS);\n\n          // also treat the registration message as a heartbeat\n          heartbeatManager.register(nodeS);\n          incrementVersionCount(nodeS.getSoftwareVersion());\n          startAdminOperationIfNecessary(nodeS);\n          success \u003d true;\n        } finally {\n          if (!success) {\n            removeDatanode(nodeS);\n            wipeDatanode(nodeS);\n            countSoftwareVersions();\n          }\n        }\n        return;\n      }\n\n      DatanodeDescriptor nodeDescr \n        \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n      boolean success \u003d false;\n      try {\n        // resolve network location\n        if(this.rejectUnresolvedTopologyDN) {\n          nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n          nodeDescr.setDependentHostNames(getNetworkDependencies(nodeDescr));\n        } else {\n          nodeDescr.setNetworkLocation(\n              resolveNetworkLocationWithFallBackToDefaultLocation(nodeDescr));\n          nodeDescr.setDependentHostNames(\n              getNetworkDependenciesWithDefault(nodeDescr));\n        }\n        networktopology.add(nodeDescr);\n        nodeDescr.setSoftwareVersion(nodeReg.getSoftwareVersion());\n        resolveUpgradeDomain(nodeDescr);\n\n        // register new datanode\n        addDatanode(nodeDescr);\n        blockManager.getBlockReportLeaseManager().register(nodeDescr);\n        // also treat the registration message as a heartbeat\n        // no need to update its timestamp\n        // because its is done when the descriptor is created\n        heartbeatManager.addDatanode(nodeDescr);\n        heartbeatManager.updateDnStat(nodeDescr);\n        incrementVersionCount(nodeReg.getSoftwareVersion());\n        startAdminOperationIfNecessary(nodeDescr);\n        success \u003d true;\n      } finally {\n        if (!success) {\n          removeDatanode(nodeDescr);\n          wipeDatanode(nodeDescr);\n          countSoftwareVersions();\n        }\n      }\n    } catch (InvalidTopologyException e) {\n      // If the network location is invalid, clear the cached mappings\n      // so that we have a chance to re-add this DataNode with the\n      // correct network location later.\n      List\u003cString\u003e invalidNodeNames \u003d new ArrayList\u003c\u003e(3);\n      // clear cache for nodes in IP or Hostname\n      invalidNodeNames.add(nodeReg.getIpAddr());\n      invalidNodeNames.add(nodeReg.getHostName());\n      invalidNodeNames.add(nodeReg.getPeerHostName());\n      dnsToSwitchMapping.reloadCachedMappings(invalidNodeNames);\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "00eceed233d6e80d5c7137bf5b5286746ec4d5fb": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12570: [SPS]: Refactor Co-ordinator datanode logic to track the block storage movements. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "00eceed233d6e80d5c7137bf5b5286746ec4d5fb",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "7ea24fc06c081e2ba6f5f66d212abb14b80c9064",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,171 +1,172 @@\n   public void registerDatanode(DatanodeRegistration nodeReg)\n       throws DisallowedDatanodeException, UnresolvedTopologyException {\n     InetAddress dnAddress \u003d Server.getRemoteIp();\n     if (dnAddress !\u003d null) {\n       // Mostly called inside an RPC, update ip and peer hostname\n       String hostname \u003d dnAddress.getHostName();\n       String ip \u003d dnAddress.getHostAddress();\n       if (checkIpHostnameInRegistration \u0026\u0026 !isNameResolved(dnAddress)) {\n         // Reject registration of unresolved datanode to prevent performance\n         // impact of repetitive DNS lookups later.\n         final String message \u003d \"hostname cannot be resolved (ip\u003d\"\n             + ip + \", hostname\u003d\" + hostname + \")\";\n         LOG.warn(\"Unresolved datanode registration: \" + message);\n         throw new DisallowedDatanodeException(nodeReg, message);\n       }\n       // update node registration with the ip and hostname from rpc request\n       nodeReg.setIpAddr(ip);\n       nodeReg.setPeerHostName(hostname);\n     }\n     \n     try {\n       nodeReg.setExportedKeys(blockManager.getBlockKeys());\n   \n       // Checks if the node is not on the hosts list.  If it is not, then\n       // it will be disallowed from registering. \n       if (!hostConfigManager.isIncluded(nodeReg)) {\n         throw new DisallowedDatanodeException(nodeReg);\n       }\n         \n       NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n           + nodeReg + \" storage \" + nodeReg.getDatanodeUuid());\n   \n       DatanodeDescriptor nodeS \u003d getDatanode(nodeReg.getDatanodeUuid());\n       DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n           nodeReg.getIpAddr(), nodeReg.getXferPort());\n         \n       if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n         NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n         // nodeN previously served a different data storage, \n         // which is not served by anybody anymore.\n         removeDatanode(nodeN);\n         // physically remove node from datanodeMap\n         wipeDatanode(nodeN);\n         nodeN \u003d null;\n       }\n   \n       if (nodeS !\u003d null) {\n         if (nodeN \u003d\u003d nodeS) {\n           // The same datanode has been just restarted to serve the same data \n           // storage. We do not need to remove old data blocks, the delta will\n           // be calculated on the next block report from the datanode\n           if(NameNode.stateChangeLog.isDebugEnabled()) {\n             NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n                 + \"node restarted.\");\n           }\n         } else {\n           // nodeS is found\n           /* The registering datanode is a replacement node for the existing \n             data storage, which from now on will be served by a new node.\n             If this message repeats, both nodes might have same storageID \n             by (insanely rare) random chance. User needs to restart one of the\n             nodes with its data cleared (or user can just remove the StorageID\n             value in \"VERSION\" file under the data directory of the datanode,\n             but this is might not work if VERSION file format has changed \n          */        \n           NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n               + \" is replaced by \" + nodeReg + \" with the same storageID \"\n               + nodeReg.getDatanodeUuid());\n         }\n         \n         boolean success \u003d false;\n         try {\n           // update cluster map\n           getNetworkTopology().remove(nodeS);\n           if(shouldCountVersion(nodeS)) {\n             decrementVersionCount(nodeS.getSoftwareVersion());\n           }\n           nodeS.updateRegInfo(nodeReg);\n \n           nodeS.setSoftwareVersion(nodeReg.getSoftwareVersion());\n           nodeS.setDisallowed(false); // Node is in the include list\n \n           // Sets dropSPSWork flag to true, to ensure that\n           // DNA_DROP_SPS_WORK_COMMAND will send to datanode via next heartbeat\n           // response immediately after the node registration. This is\n-          // to avoid a situation, where multiple trackId responses coming from\n-          // different co-odinator datanodes. After SPS monitor time out, it\n-          // will retry the files which were scheduled to the disconnected(for\n-          // long time more than heartbeat expiry) DN, by finding new\n-          // co-ordinator datanode. Now, if the expired datanode reconnects back\n-          // after SPS reschedules, it leads to get different movement results\n-          // from reconnected and new DN co-ordinators.\n+          // to avoid a situation, where multiple block attempt finished\n+          // responses coming from different datanodes. After SPS monitor time\n+          // out, it will retry the files which were scheduled to the\n+          // disconnected(for long time more than heartbeat expiry) DN, by\n+          // finding new datanode. Now, if the expired datanode reconnects back\n+          // after SPS reschedules, it leads to get different movement attempt\n+          // finished report from reconnected and newly datanode which is\n+          // attempting the block movement.\n           nodeS.setDropSPSWork(true);\n \n           // resolve network location\n           if(this.rejectUnresolvedTopologyDN) {\n             nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));\n             nodeS.setDependentHostNames(getNetworkDependencies(nodeS));\n           } else {\n             nodeS.setNetworkLocation(\n                 resolveNetworkLocationWithFallBackToDefaultLocation(nodeS));\n             nodeS.setDependentHostNames(\n                 getNetworkDependenciesWithDefault(nodeS));\n           }\n           getNetworkTopology().add(nodeS);\n           resolveUpgradeDomain(nodeS);\n \n           // also treat the registration message as a heartbeat\n           heartbeatManager.register(nodeS);\n           incrementVersionCount(nodeS.getSoftwareVersion());\n           startAdminOperationIfNecessary(nodeS);\n           success \u003d true;\n         } finally {\n           if (!success) {\n             removeDatanode(nodeS);\n             wipeDatanode(nodeS);\n             countSoftwareVersions();\n           }\n         }\n         return;\n       }\n \n       DatanodeDescriptor nodeDescr \n         \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n       boolean success \u003d false;\n       try {\n         // resolve network location\n         if(this.rejectUnresolvedTopologyDN) {\n           nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n           nodeDescr.setDependentHostNames(getNetworkDependencies(nodeDescr));\n         } else {\n           nodeDescr.setNetworkLocation(\n               resolveNetworkLocationWithFallBackToDefaultLocation(nodeDescr));\n           nodeDescr.setDependentHostNames(\n               getNetworkDependenciesWithDefault(nodeDescr));\n         }\n         networktopology.add(nodeDescr);\n         nodeDescr.setSoftwareVersion(nodeReg.getSoftwareVersion());\n         resolveUpgradeDomain(nodeDescr);\n \n         // register new datanode\n         addDatanode(nodeDescr);\n         blockManager.getBlockReportLeaseManager().register(nodeDescr);\n         // also treat the registration message as a heartbeat\n         // no need to update its timestamp\n         // because its is done when the descriptor is created\n         heartbeatManager.addDatanode(nodeDescr);\n         heartbeatManager.updateDnStat(nodeDescr);\n         incrementVersionCount(nodeReg.getSoftwareVersion());\n         startAdminOperationIfNecessary(nodeDescr);\n         success \u003d true;\n       } finally {\n         if (!success) {\n           removeDatanode(nodeDescr);\n           wipeDatanode(nodeDescr);\n           countSoftwareVersions();\n         }\n       }\n     } catch (InvalidTopologyException e) {\n       // If the network location is invalid, clear the cached mappings\n       // so that we have a chance to re-add this DataNode with the\n       // correct network location later.\n       List\u003cString\u003e invalidNodeNames \u003d new ArrayList\u003c\u003e(3);\n       // clear cache for nodes in IP or Hostname\n       invalidNodeNames.add(nodeReg.getIpAddr());\n       invalidNodeNames.add(nodeReg.getHostName());\n       invalidNodeNames.add(nodeReg.getPeerHostName());\n       dnsToSwitchMapping.reloadCachedMappings(invalidNodeNames);\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void registerDatanode(DatanodeRegistration nodeReg)\n      throws DisallowedDatanodeException, UnresolvedTopologyException {\n    InetAddress dnAddress \u003d Server.getRemoteIp();\n    if (dnAddress !\u003d null) {\n      // Mostly called inside an RPC, update ip and peer hostname\n      String hostname \u003d dnAddress.getHostName();\n      String ip \u003d dnAddress.getHostAddress();\n      if (checkIpHostnameInRegistration \u0026\u0026 !isNameResolved(dnAddress)) {\n        // Reject registration of unresolved datanode to prevent performance\n        // impact of repetitive DNS lookups later.\n        final String message \u003d \"hostname cannot be resolved (ip\u003d\"\n            + ip + \", hostname\u003d\" + hostname + \")\";\n        LOG.warn(\"Unresolved datanode registration: \" + message);\n        throw new DisallowedDatanodeException(nodeReg, message);\n      }\n      // update node registration with the ip and hostname from rpc request\n      nodeReg.setIpAddr(ip);\n      nodeReg.setPeerHostName(hostname);\n    }\n    \n    try {\n      nodeReg.setExportedKeys(blockManager.getBlockKeys());\n  \n      // Checks if the node is not on the hosts list.  If it is not, then\n      // it will be disallowed from registering. \n      if (!hostConfigManager.isIncluded(nodeReg)) {\n        throw new DisallowedDatanodeException(nodeReg);\n      }\n        \n      NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n          + nodeReg + \" storage \" + nodeReg.getDatanodeUuid());\n  \n      DatanodeDescriptor nodeS \u003d getDatanode(nodeReg.getDatanodeUuid());\n      DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n          nodeReg.getIpAddr(), nodeReg.getXferPort());\n        \n      if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n        NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n        // nodeN previously served a different data storage, \n        // which is not served by anybody anymore.\n        removeDatanode(nodeN);\n        // physically remove node from datanodeMap\n        wipeDatanode(nodeN);\n        nodeN \u003d null;\n      }\n  \n      if (nodeS !\u003d null) {\n        if (nodeN \u003d\u003d nodeS) {\n          // The same datanode has been just restarted to serve the same data \n          // storage. We do not need to remove old data blocks, the delta will\n          // be calculated on the next block report from the datanode\n          if(NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n                + \"node restarted.\");\n          }\n        } else {\n          // nodeS is found\n          /* The registering datanode is a replacement node for the existing \n            data storage, which from now on will be served by a new node.\n            If this message repeats, both nodes might have same storageID \n            by (insanely rare) random chance. User needs to restart one of the\n            nodes with its data cleared (or user can just remove the StorageID\n            value in \"VERSION\" file under the data directory of the datanode,\n            but this is might not work if VERSION file format has changed \n         */        \n          NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n              + \" is replaced by \" + nodeReg + \" with the same storageID \"\n              + nodeReg.getDatanodeUuid());\n        }\n        \n        boolean success \u003d false;\n        try {\n          // update cluster map\n          getNetworkTopology().remove(nodeS);\n          if(shouldCountVersion(nodeS)) {\n            decrementVersionCount(nodeS.getSoftwareVersion());\n          }\n          nodeS.updateRegInfo(nodeReg);\n\n          nodeS.setSoftwareVersion(nodeReg.getSoftwareVersion());\n          nodeS.setDisallowed(false); // Node is in the include list\n\n          // Sets dropSPSWork flag to true, to ensure that\n          // DNA_DROP_SPS_WORK_COMMAND will send to datanode via next heartbeat\n          // response immediately after the node registration. This is\n          // to avoid a situation, where multiple block attempt finished\n          // responses coming from different datanodes. After SPS monitor time\n          // out, it will retry the files which were scheduled to the\n          // disconnected(for long time more than heartbeat expiry) DN, by\n          // finding new datanode. Now, if the expired datanode reconnects back\n          // after SPS reschedules, it leads to get different movement attempt\n          // finished report from reconnected and newly datanode which is\n          // attempting the block movement.\n          nodeS.setDropSPSWork(true);\n\n          // resolve network location\n          if(this.rejectUnresolvedTopologyDN) {\n            nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));\n            nodeS.setDependentHostNames(getNetworkDependencies(nodeS));\n          } else {\n            nodeS.setNetworkLocation(\n                resolveNetworkLocationWithFallBackToDefaultLocation(nodeS));\n            nodeS.setDependentHostNames(\n                getNetworkDependenciesWithDefault(nodeS));\n          }\n          getNetworkTopology().add(nodeS);\n          resolveUpgradeDomain(nodeS);\n\n          // also treat the registration message as a heartbeat\n          heartbeatManager.register(nodeS);\n          incrementVersionCount(nodeS.getSoftwareVersion());\n          startAdminOperationIfNecessary(nodeS);\n          success \u003d true;\n        } finally {\n          if (!success) {\n            removeDatanode(nodeS);\n            wipeDatanode(nodeS);\n            countSoftwareVersions();\n          }\n        }\n        return;\n      }\n\n      DatanodeDescriptor nodeDescr \n        \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n      boolean success \u003d false;\n      try {\n        // resolve network location\n        if(this.rejectUnresolvedTopologyDN) {\n          nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n          nodeDescr.setDependentHostNames(getNetworkDependencies(nodeDescr));\n        } else {\n          nodeDescr.setNetworkLocation(\n              resolveNetworkLocationWithFallBackToDefaultLocation(nodeDescr));\n          nodeDescr.setDependentHostNames(\n              getNetworkDependenciesWithDefault(nodeDescr));\n        }\n        networktopology.add(nodeDescr);\n        nodeDescr.setSoftwareVersion(nodeReg.getSoftwareVersion());\n        resolveUpgradeDomain(nodeDescr);\n\n        // register new datanode\n        addDatanode(nodeDescr);\n        blockManager.getBlockReportLeaseManager().register(nodeDescr);\n        // also treat the registration message as a heartbeat\n        // no need to update its timestamp\n        // because its is done when the descriptor is created\n        heartbeatManager.addDatanode(nodeDescr);\n        heartbeatManager.updateDnStat(nodeDescr);\n        incrementVersionCount(nodeReg.getSoftwareVersion());\n        startAdminOperationIfNecessary(nodeDescr);\n        success \u003d true;\n      } finally {\n        if (!success) {\n          removeDatanode(nodeDescr);\n          wipeDatanode(nodeDescr);\n          countSoftwareVersions();\n        }\n      }\n    } catch (InvalidTopologyException e) {\n      // If the network location is invalid, clear the cached mappings\n      // so that we have a chance to re-add this DataNode with the\n      // correct network location later.\n      List\u003cString\u003e invalidNodeNames \u003d new ArrayList\u003c\u003e(3);\n      // clear cache for nodes in IP or Hostname\n      invalidNodeNames.add(nodeReg.getIpAddr());\n      invalidNodeNames.add(nodeReg.getHostName());\n      invalidNodeNames.add(nodeReg.getPeerHostName());\n      dnsToSwitchMapping.reloadCachedMappings(invalidNodeNames);\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "695a402fcad20c711c5d845e0664c43fd6b06286": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11334: [SPS]: NN switch and rescheduling movements can lead to have more than one coordinator for same file blocks. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:05 AM",
      "commitName": "695a402fcad20c711c5d845e0664c43fd6b06286",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:05 AM",
      "commitNameOld": "e34331c31d68cb22891db48011db5b36ad178af1",
      "commitAuthorOld": "Rakesh Radhakrishnan",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,159 +1,171 @@\n   public void registerDatanode(DatanodeRegistration nodeReg)\n       throws DisallowedDatanodeException, UnresolvedTopologyException {\n     InetAddress dnAddress \u003d Server.getRemoteIp();\n     if (dnAddress !\u003d null) {\n       // Mostly called inside an RPC, update ip and peer hostname\n       String hostname \u003d dnAddress.getHostName();\n       String ip \u003d dnAddress.getHostAddress();\n       if (checkIpHostnameInRegistration \u0026\u0026 !isNameResolved(dnAddress)) {\n         // Reject registration of unresolved datanode to prevent performance\n         // impact of repetitive DNS lookups later.\n         final String message \u003d \"hostname cannot be resolved (ip\u003d\"\n             + ip + \", hostname\u003d\" + hostname + \")\";\n         LOG.warn(\"Unresolved datanode registration: \" + message);\n         throw new DisallowedDatanodeException(nodeReg, message);\n       }\n       // update node registration with the ip and hostname from rpc request\n       nodeReg.setIpAddr(ip);\n       nodeReg.setPeerHostName(hostname);\n     }\n     \n     try {\n       nodeReg.setExportedKeys(blockManager.getBlockKeys());\n   \n       // Checks if the node is not on the hosts list.  If it is not, then\n       // it will be disallowed from registering. \n       if (!hostConfigManager.isIncluded(nodeReg)) {\n         throw new DisallowedDatanodeException(nodeReg);\n       }\n         \n       NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n           + nodeReg + \" storage \" + nodeReg.getDatanodeUuid());\n   \n       DatanodeDescriptor nodeS \u003d getDatanode(nodeReg.getDatanodeUuid());\n       DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n           nodeReg.getIpAddr(), nodeReg.getXferPort());\n         \n       if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n         NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n         // nodeN previously served a different data storage, \n         // which is not served by anybody anymore.\n         removeDatanode(nodeN);\n         // physically remove node from datanodeMap\n         wipeDatanode(nodeN);\n         nodeN \u003d null;\n       }\n   \n       if (nodeS !\u003d null) {\n         if (nodeN \u003d\u003d nodeS) {\n           // The same datanode has been just restarted to serve the same data \n           // storage. We do not need to remove old data blocks, the delta will\n           // be calculated on the next block report from the datanode\n           if(NameNode.stateChangeLog.isDebugEnabled()) {\n             NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n                 + \"node restarted.\");\n           }\n         } else {\n           // nodeS is found\n           /* The registering datanode is a replacement node for the existing \n             data storage, which from now on will be served by a new node.\n             If this message repeats, both nodes might have same storageID \n             by (insanely rare) random chance. User needs to restart one of the\n             nodes with its data cleared (or user can just remove the StorageID\n             value in \"VERSION\" file under the data directory of the datanode,\n             but this is might not work if VERSION file format has changed \n          */        \n           NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n               + \" is replaced by \" + nodeReg + \" with the same storageID \"\n               + nodeReg.getDatanodeUuid());\n         }\n         \n         boolean success \u003d false;\n         try {\n           // update cluster map\n           getNetworkTopology().remove(nodeS);\n           if(shouldCountVersion(nodeS)) {\n             decrementVersionCount(nodeS.getSoftwareVersion());\n           }\n           nodeS.updateRegInfo(nodeReg);\n \n           nodeS.setSoftwareVersion(nodeReg.getSoftwareVersion());\n           nodeS.setDisallowed(false); // Node is in the include list\n \n+          // Sets dropSPSWork flag to true, to ensure that\n+          // DNA_DROP_SPS_WORK_COMMAND will send to datanode via next heartbeat\n+          // response immediately after the node registration. This is\n+          // to avoid a situation, where multiple trackId responses coming from\n+          // different co-odinator datanodes. After SPS monitor time out, it\n+          // will retry the files which were scheduled to the disconnected(for\n+          // long time more than heartbeat expiry) DN, by finding new\n+          // co-ordinator datanode. Now, if the expired datanode reconnects back\n+          // after SPS reschedules, it leads to get different movement results\n+          // from reconnected and new DN co-ordinators.\n+          nodeS.setDropSPSWork(true);\n+\n           // resolve network location\n           if(this.rejectUnresolvedTopologyDN) {\n             nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));\n             nodeS.setDependentHostNames(getNetworkDependencies(nodeS));\n           } else {\n             nodeS.setNetworkLocation(\n                 resolveNetworkLocationWithFallBackToDefaultLocation(nodeS));\n             nodeS.setDependentHostNames(\n                 getNetworkDependenciesWithDefault(nodeS));\n           }\n           getNetworkTopology().add(nodeS);\n           resolveUpgradeDomain(nodeS);\n \n           // also treat the registration message as a heartbeat\n           heartbeatManager.register(nodeS);\n           incrementVersionCount(nodeS.getSoftwareVersion());\n           startAdminOperationIfNecessary(nodeS);\n           success \u003d true;\n         } finally {\n           if (!success) {\n             removeDatanode(nodeS);\n             wipeDatanode(nodeS);\n             countSoftwareVersions();\n           }\n         }\n         return;\n       }\n \n       DatanodeDescriptor nodeDescr \n         \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n       boolean success \u003d false;\n       try {\n         // resolve network location\n         if(this.rejectUnresolvedTopologyDN) {\n           nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n           nodeDescr.setDependentHostNames(getNetworkDependencies(nodeDescr));\n         } else {\n           nodeDescr.setNetworkLocation(\n               resolveNetworkLocationWithFallBackToDefaultLocation(nodeDescr));\n           nodeDescr.setDependentHostNames(\n               getNetworkDependenciesWithDefault(nodeDescr));\n         }\n         networktopology.add(nodeDescr);\n         nodeDescr.setSoftwareVersion(nodeReg.getSoftwareVersion());\n         resolveUpgradeDomain(nodeDescr);\n \n         // register new datanode\n         addDatanode(nodeDescr);\n         blockManager.getBlockReportLeaseManager().register(nodeDescr);\n         // also treat the registration message as a heartbeat\n         // no need to update its timestamp\n         // because its is done when the descriptor is created\n         heartbeatManager.addDatanode(nodeDescr);\n         heartbeatManager.updateDnStat(nodeDescr);\n         incrementVersionCount(nodeReg.getSoftwareVersion());\n         startAdminOperationIfNecessary(nodeDescr);\n         success \u003d true;\n       } finally {\n         if (!success) {\n           removeDatanode(nodeDescr);\n           wipeDatanode(nodeDescr);\n           countSoftwareVersions();\n         }\n       }\n     } catch (InvalidTopologyException e) {\n       // If the network location is invalid, clear the cached mappings\n       // so that we have a chance to re-add this DataNode with the\n       // correct network location later.\n       List\u003cString\u003e invalidNodeNames \u003d new ArrayList\u003c\u003e(3);\n       // clear cache for nodes in IP or Hostname\n       invalidNodeNames.add(nodeReg.getIpAddr());\n       invalidNodeNames.add(nodeReg.getHostName());\n       invalidNodeNames.add(nodeReg.getPeerHostName());\n       dnsToSwitchMapping.reloadCachedMappings(invalidNodeNames);\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void registerDatanode(DatanodeRegistration nodeReg)\n      throws DisallowedDatanodeException, UnresolvedTopologyException {\n    InetAddress dnAddress \u003d Server.getRemoteIp();\n    if (dnAddress !\u003d null) {\n      // Mostly called inside an RPC, update ip and peer hostname\n      String hostname \u003d dnAddress.getHostName();\n      String ip \u003d dnAddress.getHostAddress();\n      if (checkIpHostnameInRegistration \u0026\u0026 !isNameResolved(dnAddress)) {\n        // Reject registration of unresolved datanode to prevent performance\n        // impact of repetitive DNS lookups later.\n        final String message \u003d \"hostname cannot be resolved (ip\u003d\"\n            + ip + \", hostname\u003d\" + hostname + \")\";\n        LOG.warn(\"Unresolved datanode registration: \" + message);\n        throw new DisallowedDatanodeException(nodeReg, message);\n      }\n      // update node registration with the ip and hostname from rpc request\n      nodeReg.setIpAddr(ip);\n      nodeReg.setPeerHostName(hostname);\n    }\n    \n    try {\n      nodeReg.setExportedKeys(blockManager.getBlockKeys());\n  \n      // Checks if the node is not on the hosts list.  If it is not, then\n      // it will be disallowed from registering. \n      if (!hostConfigManager.isIncluded(nodeReg)) {\n        throw new DisallowedDatanodeException(nodeReg);\n      }\n        \n      NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n          + nodeReg + \" storage \" + nodeReg.getDatanodeUuid());\n  \n      DatanodeDescriptor nodeS \u003d getDatanode(nodeReg.getDatanodeUuid());\n      DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n          nodeReg.getIpAddr(), nodeReg.getXferPort());\n        \n      if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n        NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n        // nodeN previously served a different data storage, \n        // which is not served by anybody anymore.\n        removeDatanode(nodeN);\n        // physically remove node from datanodeMap\n        wipeDatanode(nodeN);\n        nodeN \u003d null;\n      }\n  \n      if (nodeS !\u003d null) {\n        if (nodeN \u003d\u003d nodeS) {\n          // The same datanode has been just restarted to serve the same data \n          // storage. We do not need to remove old data blocks, the delta will\n          // be calculated on the next block report from the datanode\n          if(NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n                + \"node restarted.\");\n          }\n        } else {\n          // nodeS is found\n          /* The registering datanode is a replacement node for the existing \n            data storage, which from now on will be served by a new node.\n            If this message repeats, both nodes might have same storageID \n            by (insanely rare) random chance. User needs to restart one of the\n            nodes with its data cleared (or user can just remove the StorageID\n            value in \"VERSION\" file under the data directory of the datanode,\n            but this is might not work if VERSION file format has changed \n         */        \n          NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n              + \" is replaced by \" + nodeReg + \" with the same storageID \"\n              + nodeReg.getDatanodeUuid());\n        }\n        \n        boolean success \u003d false;\n        try {\n          // update cluster map\n          getNetworkTopology().remove(nodeS);\n          if(shouldCountVersion(nodeS)) {\n            decrementVersionCount(nodeS.getSoftwareVersion());\n          }\n          nodeS.updateRegInfo(nodeReg);\n\n          nodeS.setSoftwareVersion(nodeReg.getSoftwareVersion());\n          nodeS.setDisallowed(false); // Node is in the include list\n\n          // Sets dropSPSWork flag to true, to ensure that\n          // DNA_DROP_SPS_WORK_COMMAND will send to datanode via next heartbeat\n          // response immediately after the node registration. This is\n          // to avoid a situation, where multiple trackId responses coming from\n          // different co-odinator datanodes. After SPS monitor time out, it\n          // will retry the files which were scheduled to the disconnected(for\n          // long time more than heartbeat expiry) DN, by finding new\n          // co-ordinator datanode. Now, if the expired datanode reconnects back\n          // after SPS reschedules, it leads to get different movement results\n          // from reconnected and new DN co-ordinators.\n          nodeS.setDropSPSWork(true);\n\n          // resolve network location\n          if(this.rejectUnresolvedTopologyDN) {\n            nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));\n            nodeS.setDependentHostNames(getNetworkDependencies(nodeS));\n          } else {\n            nodeS.setNetworkLocation(\n                resolveNetworkLocationWithFallBackToDefaultLocation(nodeS));\n            nodeS.setDependentHostNames(\n                getNetworkDependenciesWithDefault(nodeS));\n          }\n          getNetworkTopology().add(nodeS);\n          resolveUpgradeDomain(nodeS);\n\n          // also treat the registration message as a heartbeat\n          heartbeatManager.register(nodeS);\n          incrementVersionCount(nodeS.getSoftwareVersion());\n          startAdminOperationIfNecessary(nodeS);\n          success \u003d true;\n        } finally {\n          if (!success) {\n            removeDatanode(nodeS);\n            wipeDatanode(nodeS);\n            countSoftwareVersions();\n          }\n        }\n        return;\n      }\n\n      DatanodeDescriptor nodeDescr \n        \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n      boolean success \u003d false;\n      try {\n        // resolve network location\n        if(this.rejectUnresolvedTopologyDN) {\n          nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n          nodeDescr.setDependentHostNames(getNetworkDependencies(nodeDescr));\n        } else {\n          nodeDescr.setNetworkLocation(\n              resolveNetworkLocationWithFallBackToDefaultLocation(nodeDescr));\n          nodeDescr.setDependentHostNames(\n              getNetworkDependenciesWithDefault(nodeDescr));\n        }\n        networktopology.add(nodeDescr);\n        nodeDescr.setSoftwareVersion(nodeReg.getSoftwareVersion());\n        resolveUpgradeDomain(nodeDescr);\n\n        // register new datanode\n        addDatanode(nodeDescr);\n        blockManager.getBlockReportLeaseManager().register(nodeDescr);\n        // also treat the registration message as a heartbeat\n        // no need to update its timestamp\n        // because its is done when the descriptor is created\n        heartbeatManager.addDatanode(nodeDescr);\n        heartbeatManager.updateDnStat(nodeDescr);\n        incrementVersionCount(nodeReg.getSoftwareVersion());\n        startAdminOperationIfNecessary(nodeDescr);\n        success \u003d true;\n      } finally {\n        if (!success) {\n          removeDatanode(nodeDescr);\n          wipeDatanode(nodeDescr);\n          countSoftwareVersions();\n        }\n      }\n    } catch (InvalidTopologyException e) {\n      // If the network location is invalid, clear the cached mappings\n      // so that we have a chance to re-add this DataNode with the\n      // correct network location later.\n      List\u003cString\u003e invalidNodeNames \u003d new ArrayList\u003c\u003e(3);\n      // clear cache for nodes in IP or Hostname\n      invalidNodeNames.add(nodeReg.getIpAddr());\n      invalidNodeNames.add(nodeReg.getHostName());\n      invalidNodeNames.add(nodeReg.getPeerHostName());\n      dnsToSwitchMapping.reloadCachedMappings(invalidNodeNames);\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "9dcbdbdb5a34d85910707f81ebc1bb1f81c99978": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9392. Admins support for maintenance state. Contributed by Ming Ma.\n",
      "commitDate": "30/08/16 2:00 PM",
      "commitName": "9dcbdbdb5a34d85910707f81ebc1bb1f81c99978",
      "commitAuthor": "Ming Ma",
      "commitDateOld": "12/04/16 1:38 PM",
      "commitNameOld": "6ef42873a02bfcbff5521869f4d6f66539d1db41",
      "commitAuthorOld": "Zhe Zhang",
      "daysBetweenCommits": 140.01,
      "commitsBetweenForRepo": 1065,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,159 +1,159 @@\n   public void registerDatanode(DatanodeRegistration nodeReg)\n       throws DisallowedDatanodeException, UnresolvedTopologyException {\n     InetAddress dnAddress \u003d Server.getRemoteIp();\n     if (dnAddress !\u003d null) {\n       // Mostly called inside an RPC, update ip and peer hostname\n       String hostname \u003d dnAddress.getHostName();\n       String ip \u003d dnAddress.getHostAddress();\n       if (checkIpHostnameInRegistration \u0026\u0026 !isNameResolved(dnAddress)) {\n         // Reject registration of unresolved datanode to prevent performance\n         // impact of repetitive DNS lookups later.\n         final String message \u003d \"hostname cannot be resolved (ip\u003d\"\n             + ip + \", hostname\u003d\" + hostname + \")\";\n         LOG.warn(\"Unresolved datanode registration: \" + message);\n         throw new DisallowedDatanodeException(nodeReg, message);\n       }\n       // update node registration with the ip and hostname from rpc request\n       nodeReg.setIpAddr(ip);\n       nodeReg.setPeerHostName(hostname);\n     }\n     \n     try {\n       nodeReg.setExportedKeys(blockManager.getBlockKeys());\n   \n       // Checks if the node is not on the hosts list.  If it is not, then\n       // it will be disallowed from registering. \n       if (!hostConfigManager.isIncluded(nodeReg)) {\n         throw new DisallowedDatanodeException(nodeReg);\n       }\n         \n       NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n           + nodeReg + \" storage \" + nodeReg.getDatanodeUuid());\n   \n       DatanodeDescriptor nodeS \u003d getDatanode(nodeReg.getDatanodeUuid());\n       DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n           nodeReg.getIpAddr(), nodeReg.getXferPort());\n         \n       if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n         NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n         // nodeN previously served a different data storage, \n         // which is not served by anybody anymore.\n         removeDatanode(nodeN);\n         // physically remove node from datanodeMap\n         wipeDatanode(nodeN);\n         nodeN \u003d null;\n       }\n   \n       if (nodeS !\u003d null) {\n         if (nodeN \u003d\u003d nodeS) {\n           // The same datanode has been just restarted to serve the same data \n           // storage. We do not need to remove old data blocks, the delta will\n           // be calculated on the next block report from the datanode\n           if(NameNode.stateChangeLog.isDebugEnabled()) {\n             NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n                 + \"node restarted.\");\n           }\n         } else {\n           // nodeS is found\n           /* The registering datanode is a replacement node for the existing \n             data storage, which from now on will be served by a new node.\n             If this message repeats, both nodes might have same storageID \n             by (insanely rare) random chance. User needs to restart one of the\n             nodes with its data cleared (or user can just remove the StorageID\n             value in \"VERSION\" file under the data directory of the datanode,\n             but this is might not work if VERSION file format has changed \n          */        \n           NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n               + \" is replaced by \" + nodeReg + \" with the same storageID \"\n               + nodeReg.getDatanodeUuid());\n         }\n         \n         boolean success \u003d false;\n         try {\n           // update cluster map\n           getNetworkTopology().remove(nodeS);\n           if(shouldCountVersion(nodeS)) {\n             decrementVersionCount(nodeS.getSoftwareVersion());\n           }\n           nodeS.updateRegInfo(nodeReg);\n \n           nodeS.setSoftwareVersion(nodeReg.getSoftwareVersion());\n           nodeS.setDisallowed(false); // Node is in the include list\n \n           // resolve network location\n           if(this.rejectUnresolvedTopologyDN) {\n             nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));\n             nodeS.setDependentHostNames(getNetworkDependencies(nodeS));\n           } else {\n             nodeS.setNetworkLocation(\n                 resolveNetworkLocationWithFallBackToDefaultLocation(nodeS));\n             nodeS.setDependentHostNames(\n                 getNetworkDependenciesWithDefault(nodeS));\n           }\n           getNetworkTopology().add(nodeS);\n           resolveUpgradeDomain(nodeS);\n \n           // also treat the registration message as a heartbeat\n           heartbeatManager.register(nodeS);\n           incrementVersionCount(nodeS.getSoftwareVersion());\n-          startDecommissioningIfExcluded(nodeS);\n+          startAdminOperationIfNecessary(nodeS);\n           success \u003d true;\n         } finally {\n           if (!success) {\n             removeDatanode(nodeS);\n             wipeDatanode(nodeS);\n             countSoftwareVersions();\n           }\n         }\n         return;\n       }\n \n       DatanodeDescriptor nodeDescr \n         \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n       boolean success \u003d false;\n       try {\n         // resolve network location\n         if(this.rejectUnresolvedTopologyDN) {\n           nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n           nodeDescr.setDependentHostNames(getNetworkDependencies(nodeDescr));\n         } else {\n           nodeDescr.setNetworkLocation(\n               resolveNetworkLocationWithFallBackToDefaultLocation(nodeDescr));\n           nodeDescr.setDependentHostNames(\n               getNetworkDependenciesWithDefault(nodeDescr));\n         }\n         networktopology.add(nodeDescr);\n         nodeDescr.setSoftwareVersion(nodeReg.getSoftwareVersion());\n         resolveUpgradeDomain(nodeDescr);\n \n         // register new datanode\n         addDatanode(nodeDescr);\n         blockManager.getBlockReportLeaseManager().register(nodeDescr);\n         // also treat the registration message as a heartbeat\n         // no need to update its timestamp\n         // because its is done when the descriptor is created\n         heartbeatManager.addDatanode(nodeDescr);\n         heartbeatManager.updateDnStat(nodeDescr);\n         incrementVersionCount(nodeReg.getSoftwareVersion());\n-        startDecommissioningIfExcluded(nodeDescr);\n+        startAdminOperationIfNecessary(nodeDescr);\n         success \u003d true;\n       } finally {\n         if (!success) {\n           removeDatanode(nodeDescr);\n           wipeDatanode(nodeDescr);\n           countSoftwareVersions();\n         }\n       }\n     } catch (InvalidTopologyException e) {\n       // If the network location is invalid, clear the cached mappings\n       // so that we have a chance to re-add this DataNode with the\n       // correct network location later.\n       List\u003cString\u003e invalidNodeNames \u003d new ArrayList\u003c\u003e(3);\n       // clear cache for nodes in IP or Hostname\n       invalidNodeNames.add(nodeReg.getIpAddr());\n       invalidNodeNames.add(nodeReg.getHostName());\n       invalidNodeNames.add(nodeReg.getPeerHostName());\n       dnsToSwitchMapping.reloadCachedMappings(invalidNodeNames);\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void registerDatanode(DatanodeRegistration nodeReg)\n      throws DisallowedDatanodeException, UnresolvedTopologyException {\n    InetAddress dnAddress \u003d Server.getRemoteIp();\n    if (dnAddress !\u003d null) {\n      // Mostly called inside an RPC, update ip and peer hostname\n      String hostname \u003d dnAddress.getHostName();\n      String ip \u003d dnAddress.getHostAddress();\n      if (checkIpHostnameInRegistration \u0026\u0026 !isNameResolved(dnAddress)) {\n        // Reject registration of unresolved datanode to prevent performance\n        // impact of repetitive DNS lookups later.\n        final String message \u003d \"hostname cannot be resolved (ip\u003d\"\n            + ip + \", hostname\u003d\" + hostname + \")\";\n        LOG.warn(\"Unresolved datanode registration: \" + message);\n        throw new DisallowedDatanodeException(nodeReg, message);\n      }\n      // update node registration with the ip and hostname from rpc request\n      nodeReg.setIpAddr(ip);\n      nodeReg.setPeerHostName(hostname);\n    }\n    \n    try {\n      nodeReg.setExportedKeys(blockManager.getBlockKeys());\n  \n      // Checks if the node is not on the hosts list.  If it is not, then\n      // it will be disallowed from registering. \n      if (!hostConfigManager.isIncluded(nodeReg)) {\n        throw new DisallowedDatanodeException(nodeReg);\n      }\n        \n      NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n          + nodeReg + \" storage \" + nodeReg.getDatanodeUuid());\n  \n      DatanodeDescriptor nodeS \u003d getDatanode(nodeReg.getDatanodeUuid());\n      DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n          nodeReg.getIpAddr(), nodeReg.getXferPort());\n        \n      if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n        NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n        // nodeN previously served a different data storage, \n        // which is not served by anybody anymore.\n        removeDatanode(nodeN);\n        // physically remove node from datanodeMap\n        wipeDatanode(nodeN);\n        nodeN \u003d null;\n      }\n  \n      if (nodeS !\u003d null) {\n        if (nodeN \u003d\u003d nodeS) {\n          // The same datanode has been just restarted to serve the same data \n          // storage. We do not need to remove old data blocks, the delta will\n          // be calculated on the next block report from the datanode\n          if(NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n                + \"node restarted.\");\n          }\n        } else {\n          // nodeS is found\n          /* The registering datanode is a replacement node for the existing \n            data storage, which from now on will be served by a new node.\n            If this message repeats, both nodes might have same storageID \n            by (insanely rare) random chance. User needs to restart one of the\n            nodes with its data cleared (or user can just remove the StorageID\n            value in \"VERSION\" file under the data directory of the datanode,\n            but this is might not work if VERSION file format has changed \n         */        \n          NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n              + \" is replaced by \" + nodeReg + \" with the same storageID \"\n              + nodeReg.getDatanodeUuid());\n        }\n        \n        boolean success \u003d false;\n        try {\n          // update cluster map\n          getNetworkTopology().remove(nodeS);\n          if(shouldCountVersion(nodeS)) {\n            decrementVersionCount(nodeS.getSoftwareVersion());\n          }\n          nodeS.updateRegInfo(nodeReg);\n\n          nodeS.setSoftwareVersion(nodeReg.getSoftwareVersion());\n          nodeS.setDisallowed(false); // Node is in the include list\n\n          // resolve network location\n          if(this.rejectUnresolvedTopologyDN) {\n            nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));\n            nodeS.setDependentHostNames(getNetworkDependencies(nodeS));\n          } else {\n            nodeS.setNetworkLocation(\n                resolveNetworkLocationWithFallBackToDefaultLocation(nodeS));\n            nodeS.setDependentHostNames(\n                getNetworkDependenciesWithDefault(nodeS));\n          }\n          getNetworkTopology().add(nodeS);\n          resolveUpgradeDomain(nodeS);\n\n          // also treat the registration message as a heartbeat\n          heartbeatManager.register(nodeS);\n          incrementVersionCount(nodeS.getSoftwareVersion());\n          startAdminOperationIfNecessary(nodeS);\n          success \u003d true;\n        } finally {\n          if (!success) {\n            removeDatanode(nodeS);\n            wipeDatanode(nodeS);\n            countSoftwareVersions();\n          }\n        }\n        return;\n      }\n\n      DatanodeDescriptor nodeDescr \n        \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n      boolean success \u003d false;\n      try {\n        // resolve network location\n        if(this.rejectUnresolvedTopologyDN) {\n          nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n          nodeDescr.setDependentHostNames(getNetworkDependencies(nodeDescr));\n        } else {\n          nodeDescr.setNetworkLocation(\n              resolveNetworkLocationWithFallBackToDefaultLocation(nodeDescr));\n          nodeDescr.setDependentHostNames(\n              getNetworkDependenciesWithDefault(nodeDescr));\n        }\n        networktopology.add(nodeDescr);\n        nodeDescr.setSoftwareVersion(nodeReg.getSoftwareVersion());\n        resolveUpgradeDomain(nodeDescr);\n\n        // register new datanode\n        addDatanode(nodeDescr);\n        blockManager.getBlockReportLeaseManager().register(nodeDescr);\n        // also treat the registration message as a heartbeat\n        // no need to update its timestamp\n        // because its is done when the descriptor is created\n        heartbeatManager.addDatanode(nodeDescr);\n        heartbeatManager.updateDnStat(nodeDescr);\n        incrementVersionCount(nodeReg.getSoftwareVersion());\n        startAdminOperationIfNecessary(nodeDescr);\n        success \u003d true;\n      } finally {\n        if (!success) {\n          removeDatanode(nodeDescr);\n          wipeDatanode(nodeDescr);\n          countSoftwareVersions();\n        }\n      }\n    } catch (InvalidTopologyException e) {\n      // If the network location is invalid, clear the cached mappings\n      // so that we have a chance to re-add this DataNode with the\n      // correct network location later.\n      List\u003cString\u003e invalidNodeNames \u003d new ArrayList\u003c\u003e(3);\n      // clear cache for nodes in IP or Hostname\n      invalidNodeNames.add(nodeReg.getIpAddr());\n      invalidNodeNames.add(nodeReg.getHostName());\n      invalidNodeNames.add(nodeReg.getPeerHostName());\n      dnsToSwitchMapping.reloadCachedMappings(invalidNodeNames);\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "fde8ac5d8514f5146f438f8d0794116aaef20416": {
      "type": "Ybodychange",
      "commitMessage": "Add missing files from HDFS-9005. (lei)\n",
      "commitDate": "25/03/16 5:11 PM",
      "commitName": "fde8ac5d8514f5146f438f8d0794116aaef20416",
      "commitAuthor": "Lei Xu",
      "commitDateOld": "10/03/16 7:03 PM",
      "commitNameOld": "e01c6ea688e62f25c4310e771a0cd85b53a5fb87",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 14.88,
      "commitsBetweenForRepo": 69,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,157 +1,159 @@\n   public void registerDatanode(DatanodeRegistration nodeReg)\n       throws DisallowedDatanodeException, UnresolvedTopologyException {\n     InetAddress dnAddress \u003d Server.getRemoteIp();\n     if (dnAddress !\u003d null) {\n       // Mostly called inside an RPC, update ip and peer hostname\n       String hostname \u003d dnAddress.getHostName();\n       String ip \u003d dnAddress.getHostAddress();\n       if (checkIpHostnameInRegistration \u0026\u0026 !isNameResolved(dnAddress)) {\n         // Reject registration of unresolved datanode to prevent performance\n         // impact of repetitive DNS lookups later.\n         final String message \u003d \"hostname cannot be resolved (ip\u003d\"\n             + ip + \", hostname\u003d\" + hostname + \")\";\n         LOG.warn(\"Unresolved datanode registration: \" + message);\n         throw new DisallowedDatanodeException(nodeReg, message);\n       }\n       // update node registration with the ip and hostname from rpc request\n       nodeReg.setIpAddr(ip);\n       nodeReg.setPeerHostName(hostname);\n     }\n     \n     try {\n       nodeReg.setExportedKeys(blockManager.getBlockKeys());\n   \n       // Checks if the node is not on the hosts list.  If it is not, then\n       // it will be disallowed from registering. \n-      if (!hostFileManager.isIncluded(nodeReg)) {\n+      if (!hostConfigManager.isIncluded(nodeReg)) {\n         throw new DisallowedDatanodeException(nodeReg);\n       }\n         \n       NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n           + nodeReg + \" storage \" + nodeReg.getDatanodeUuid());\n   \n       DatanodeDescriptor nodeS \u003d getDatanode(nodeReg.getDatanodeUuid());\n       DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n           nodeReg.getIpAddr(), nodeReg.getXferPort());\n         \n       if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n         NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n         // nodeN previously served a different data storage, \n         // which is not served by anybody anymore.\n         removeDatanode(nodeN);\n         // physically remove node from datanodeMap\n         wipeDatanode(nodeN);\n         nodeN \u003d null;\n       }\n   \n       if (nodeS !\u003d null) {\n         if (nodeN \u003d\u003d nodeS) {\n           // The same datanode has been just restarted to serve the same data \n           // storage. We do not need to remove old data blocks, the delta will\n           // be calculated on the next block report from the datanode\n           if(NameNode.stateChangeLog.isDebugEnabled()) {\n             NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n                 + \"node restarted.\");\n           }\n         } else {\n           // nodeS is found\n           /* The registering datanode is a replacement node for the existing \n             data storage, which from now on will be served by a new node.\n             If this message repeats, both nodes might have same storageID \n             by (insanely rare) random chance. User needs to restart one of the\n             nodes with its data cleared (or user can just remove the StorageID\n             value in \"VERSION\" file under the data directory of the datanode,\n             but this is might not work if VERSION file format has changed \n          */        \n           NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n               + \" is replaced by \" + nodeReg + \" with the same storageID \"\n               + nodeReg.getDatanodeUuid());\n         }\n         \n         boolean success \u003d false;\n         try {\n           // update cluster map\n           getNetworkTopology().remove(nodeS);\n           if(shouldCountVersion(nodeS)) {\n             decrementVersionCount(nodeS.getSoftwareVersion());\n           }\n           nodeS.updateRegInfo(nodeReg);\n \n           nodeS.setSoftwareVersion(nodeReg.getSoftwareVersion());\n           nodeS.setDisallowed(false); // Node is in the include list\n \n           // resolve network location\n           if(this.rejectUnresolvedTopologyDN) {\n             nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));\n             nodeS.setDependentHostNames(getNetworkDependencies(nodeS));\n           } else {\n             nodeS.setNetworkLocation(\n                 resolveNetworkLocationWithFallBackToDefaultLocation(nodeS));\n             nodeS.setDependentHostNames(\n                 getNetworkDependenciesWithDefault(nodeS));\n           }\n           getNetworkTopology().add(nodeS);\n-            \n+          resolveUpgradeDomain(nodeS);\n+\n           // also treat the registration message as a heartbeat\n           heartbeatManager.register(nodeS);\n           incrementVersionCount(nodeS.getSoftwareVersion());\n           startDecommissioningIfExcluded(nodeS);\n           success \u003d true;\n         } finally {\n           if (!success) {\n             removeDatanode(nodeS);\n             wipeDatanode(nodeS);\n             countSoftwareVersions();\n           }\n         }\n         return;\n       }\n \n       DatanodeDescriptor nodeDescr \n         \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n       boolean success \u003d false;\n       try {\n         // resolve network location\n         if(this.rejectUnresolvedTopologyDN) {\n           nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n           nodeDescr.setDependentHostNames(getNetworkDependencies(nodeDescr));\n         } else {\n           nodeDescr.setNetworkLocation(\n               resolveNetworkLocationWithFallBackToDefaultLocation(nodeDescr));\n           nodeDescr.setDependentHostNames(\n               getNetworkDependenciesWithDefault(nodeDescr));\n         }\n         networktopology.add(nodeDescr);\n         nodeDescr.setSoftwareVersion(nodeReg.getSoftwareVersion());\n-  \n+        resolveUpgradeDomain(nodeDescr);\n+\n         // register new datanode\n         addDatanode(nodeDescr);\n         blockManager.getBlockReportLeaseManager().register(nodeDescr);\n         // also treat the registration message as a heartbeat\n         // no need to update its timestamp\n         // because its is done when the descriptor is created\n         heartbeatManager.addDatanode(nodeDescr);\n         heartbeatManager.updateDnStat(nodeDescr);\n         incrementVersionCount(nodeReg.getSoftwareVersion());\n         startDecommissioningIfExcluded(nodeDescr);\n         success \u003d true;\n       } finally {\n         if (!success) {\n           removeDatanode(nodeDescr);\n           wipeDatanode(nodeDescr);\n           countSoftwareVersions();\n         }\n       }\n     } catch (InvalidTopologyException e) {\n       // If the network location is invalid, clear the cached mappings\n       // so that we have a chance to re-add this DataNode with the\n       // correct network location later.\n       List\u003cString\u003e invalidNodeNames \u003d new ArrayList\u003c\u003e(3);\n       // clear cache for nodes in IP or Hostname\n       invalidNodeNames.add(nodeReg.getIpAddr());\n       invalidNodeNames.add(nodeReg.getHostName());\n       invalidNodeNames.add(nodeReg.getPeerHostName());\n       dnsToSwitchMapping.reloadCachedMappings(invalidNodeNames);\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void registerDatanode(DatanodeRegistration nodeReg)\n      throws DisallowedDatanodeException, UnresolvedTopologyException {\n    InetAddress dnAddress \u003d Server.getRemoteIp();\n    if (dnAddress !\u003d null) {\n      // Mostly called inside an RPC, update ip and peer hostname\n      String hostname \u003d dnAddress.getHostName();\n      String ip \u003d dnAddress.getHostAddress();\n      if (checkIpHostnameInRegistration \u0026\u0026 !isNameResolved(dnAddress)) {\n        // Reject registration of unresolved datanode to prevent performance\n        // impact of repetitive DNS lookups later.\n        final String message \u003d \"hostname cannot be resolved (ip\u003d\"\n            + ip + \", hostname\u003d\" + hostname + \")\";\n        LOG.warn(\"Unresolved datanode registration: \" + message);\n        throw new DisallowedDatanodeException(nodeReg, message);\n      }\n      // update node registration with the ip and hostname from rpc request\n      nodeReg.setIpAddr(ip);\n      nodeReg.setPeerHostName(hostname);\n    }\n    \n    try {\n      nodeReg.setExportedKeys(blockManager.getBlockKeys());\n  \n      // Checks if the node is not on the hosts list.  If it is not, then\n      // it will be disallowed from registering. \n      if (!hostConfigManager.isIncluded(nodeReg)) {\n        throw new DisallowedDatanodeException(nodeReg);\n      }\n        \n      NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n          + nodeReg + \" storage \" + nodeReg.getDatanodeUuid());\n  \n      DatanodeDescriptor nodeS \u003d getDatanode(nodeReg.getDatanodeUuid());\n      DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n          nodeReg.getIpAddr(), nodeReg.getXferPort());\n        \n      if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n        NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n        // nodeN previously served a different data storage, \n        // which is not served by anybody anymore.\n        removeDatanode(nodeN);\n        // physically remove node from datanodeMap\n        wipeDatanode(nodeN);\n        nodeN \u003d null;\n      }\n  \n      if (nodeS !\u003d null) {\n        if (nodeN \u003d\u003d nodeS) {\n          // The same datanode has been just restarted to serve the same data \n          // storage. We do not need to remove old data blocks, the delta will\n          // be calculated on the next block report from the datanode\n          if(NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n                + \"node restarted.\");\n          }\n        } else {\n          // nodeS is found\n          /* The registering datanode is a replacement node for the existing \n            data storage, which from now on will be served by a new node.\n            If this message repeats, both nodes might have same storageID \n            by (insanely rare) random chance. User needs to restart one of the\n            nodes with its data cleared (or user can just remove the StorageID\n            value in \"VERSION\" file under the data directory of the datanode,\n            but this is might not work if VERSION file format has changed \n         */        \n          NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n              + \" is replaced by \" + nodeReg + \" with the same storageID \"\n              + nodeReg.getDatanodeUuid());\n        }\n        \n        boolean success \u003d false;\n        try {\n          // update cluster map\n          getNetworkTopology().remove(nodeS);\n          if(shouldCountVersion(nodeS)) {\n            decrementVersionCount(nodeS.getSoftwareVersion());\n          }\n          nodeS.updateRegInfo(nodeReg);\n\n          nodeS.setSoftwareVersion(nodeReg.getSoftwareVersion());\n          nodeS.setDisallowed(false); // Node is in the include list\n\n          // resolve network location\n          if(this.rejectUnresolvedTopologyDN) {\n            nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));\n            nodeS.setDependentHostNames(getNetworkDependencies(nodeS));\n          } else {\n            nodeS.setNetworkLocation(\n                resolveNetworkLocationWithFallBackToDefaultLocation(nodeS));\n            nodeS.setDependentHostNames(\n                getNetworkDependenciesWithDefault(nodeS));\n          }\n          getNetworkTopology().add(nodeS);\n          resolveUpgradeDomain(nodeS);\n\n          // also treat the registration message as a heartbeat\n          heartbeatManager.register(nodeS);\n          incrementVersionCount(nodeS.getSoftwareVersion());\n          startDecommissioningIfExcluded(nodeS);\n          success \u003d true;\n        } finally {\n          if (!success) {\n            removeDatanode(nodeS);\n            wipeDatanode(nodeS);\n            countSoftwareVersions();\n          }\n        }\n        return;\n      }\n\n      DatanodeDescriptor nodeDescr \n        \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n      boolean success \u003d false;\n      try {\n        // resolve network location\n        if(this.rejectUnresolvedTopologyDN) {\n          nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n          nodeDescr.setDependentHostNames(getNetworkDependencies(nodeDescr));\n        } else {\n          nodeDescr.setNetworkLocation(\n              resolveNetworkLocationWithFallBackToDefaultLocation(nodeDescr));\n          nodeDescr.setDependentHostNames(\n              getNetworkDependenciesWithDefault(nodeDescr));\n        }\n        networktopology.add(nodeDescr);\n        nodeDescr.setSoftwareVersion(nodeReg.getSoftwareVersion());\n        resolveUpgradeDomain(nodeDescr);\n\n        // register new datanode\n        addDatanode(nodeDescr);\n        blockManager.getBlockReportLeaseManager().register(nodeDescr);\n        // also treat the registration message as a heartbeat\n        // no need to update its timestamp\n        // because its is done when the descriptor is created\n        heartbeatManager.addDatanode(nodeDescr);\n        heartbeatManager.updateDnStat(nodeDescr);\n        incrementVersionCount(nodeReg.getSoftwareVersion());\n        startDecommissioningIfExcluded(nodeDescr);\n        success \u003d true;\n      } finally {\n        if (!success) {\n          removeDatanode(nodeDescr);\n          wipeDatanode(nodeDescr);\n          countSoftwareVersions();\n        }\n      }\n    } catch (InvalidTopologyException e) {\n      // If the network location is invalid, clear the cached mappings\n      // so that we have a chance to re-add this DataNode with the\n      // correct network location later.\n      List\u003cString\u003e invalidNodeNames \u003d new ArrayList\u003c\u003e(3);\n      // clear cache for nodes in IP or Hostname\n      invalidNodeNames.add(nodeReg.getIpAddr());\n      invalidNodeNames.add(nodeReg.getHostName());\n      invalidNodeNames.add(nodeReg.getPeerHostName());\n      dnsToSwitchMapping.reloadCachedMappings(invalidNodeNames);\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "df83230948204ee2d2b06ecc66ce0163e2df27ef": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9034. StorageTypeStats Metric should not count failed storage. Contributed by Surendra Singh Lilhore.\n",
      "commitDate": "22/12/15 3:28 PM",
      "commitName": "df83230948204ee2d2b06ecc66ce0163e2df27ef",
      "commitAuthor": "Benoy Antony",
      "commitDateOld": "18/12/15 3:57 PM",
      "commitNameOld": "61ab0440f7eaff0f631cbae0378403912f88d7ad",
      "commitAuthorOld": "Zhe Zhang",
      "daysBetweenCommits": 3.98,
      "commitsBetweenForRepo": 19,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,156 +1,157 @@\n   public void registerDatanode(DatanodeRegistration nodeReg)\n       throws DisallowedDatanodeException, UnresolvedTopologyException {\n     InetAddress dnAddress \u003d Server.getRemoteIp();\n     if (dnAddress !\u003d null) {\n       // Mostly called inside an RPC, update ip and peer hostname\n       String hostname \u003d dnAddress.getHostName();\n       String ip \u003d dnAddress.getHostAddress();\n       if (checkIpHostnameInRegistration \u0026\u0026 !isNameResolved(dnAddress)) {\n         // Reject registration of unresolved datanode to prevent performance\n         // impact of repetitive DNS lookups later.\n         final String message \u003d \"hostname cannot be resolved (ip\u003d\"\n             + ip + \", hostname\u003d\" + hostname + \")\";\n         LOG.warn(\"Unresolved datanode registration: \" + message);\n         throw new DisallowedDatanodeException(nodeReg, message);\n       }\n       // update node registration with the ip and hostname from rpc request\n       nodeReg.setIpAddr(ip);\n       nodeReg.setPeerHostName(hostname);\n     }\n     \n     try {\n       nodeReg.setExportedKeys(blockManager.getBlockKeys());\n   \n       // Checks if the node is not on the hosts list.  If it is not, then\n       // it will be disallowed from registering. \n       if (!hostFileManager.isIncluded(nodeReg)) {\n         throw new DisallowedDatanodeException(nodeReg);\n       }\n         \n       NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n           + nodeReg + \" storage \" + nodeReg.getDatanodeUuid());\n   \n       DatanodeDescriptor nodeS \u003d getDatanode(nodeReg.getDatanodeUuid());\n       DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n           nodeReg.getIpAddr(), nodeReg.getXferPort());\n         \n       if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n         NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n         // nodeN previously served a different data storage, \n         // which is not served by anybody anymore.\n         removeDatanode(nodeN);\n         // physically remove node from datanodeMap\n         wipeDatanode(nodeN);\n         nodeN \u003d null;\n       }\n   \n       if (nodeS !\u003d null) {\n         if (nodeN \u003d\u003d nodeS) {\n           // The same datanode has been just restarted to serve the same data \n           // storage. We do not need to remove old data blocks, the delta will\n           // be calculated on the next block report from the datanode\n           if(NameNode.stateChangeLog.isDebugEnabled()) {\n             NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n                 + \"node restarted.\");\n           }\n         } else {\n           // nodeS is found\n           /* The registering datanode is a replacement node for the existing \n             data storage, which from now on will be served by a new node.\n             If this message repeats, both nodes might have same storageID \n             by (insanely rare) random chance. User needs to restart one of the\n             nodes with its data cleared (or user can just remove the StorageID\n             value in \"VERSION\" file under the data directory of the datanode,\n             but this is might not work if VERSION file format has changed \n          */        \n           NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n               + \" is replaced by \" + nodeReg + \" with the same storageID \"\n               + nodeReg.getDatanodeUuid());\n         }\n         \n         boolean success \u003d false;\n         try {\n           // update cluster map\n           getNetworkTopology().remove(nodeS);\n           if(shouldCountVersion(nodeS)) {\n             decrementVersionCount(nodeS.getSoftwareVersion());\n           }\n           nodeS.updateRegInfo(nodeReg);\n \n           nodeS.setSoftwareVersion(nodeReg.getSoftwareVersion());\n           nodeS.setDisallowed(false); // Node is in the include list\n \n           // resolve network location\n           if(this.rejectUnresolvedTopologyDN) {\n             nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));\n             nodeS.setDependentHostNames(getNetworkDependencies(nodeS));\n           } else {\n             nodeS.setNetworkLocation(\n                 resolveNetworkLocationWithFallBackToDefaultLocation(nodeS));\n             nodeS.setDependentHostNames(\n                 getNetworkDependenciesWithDefault(nodeS));\n           }\n           getNetworkTopology().add(nodeS);\n             \n           // also treat the registration message as a heartbeat\n           heartbeatManager.register(nodeS);\n           incrementVersionCount(nodeS.getSoftwareVersion());\n           startDecommissioningIfExcluded(nodeS);\n           success \u003d true;\n         } finally {\n           if (!success) {\n             removeDatanode(nodeS);\n             wipeDatanode(nodeS);\n             countSoftwareVersions();\n           }\n         }\n         return;\n       }\n \n       DatanodeDescriptor nodeDescr \n         \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n       boolean success \u003d false;\n       try {\n         // resolve network location\n         if(this.rejectUnresolvedTopologyDN) {\n           nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n           nodeDescr.setDependentHostNames(getNetworkDependencies(nodeDescr));\n         } else {\n           nodeDescr.setNetworkLocation(\n               resolveNetworkLocationWithFallBackToDefaultLocation(nodeDescr));\n           nodeDescr.setDependentHostNames(\n               getNetworkDependenciesWithDefault(nodeDescr));\n         }\n         networktopology.add(nodeDescr);\n         nodeDescr.setSoftwareVersion(nodeReg.getSoftwareVersion());\n   \n         // register new datanode\n         addDatanode(nodeDescr);\n         blockManager.getBlockReportLeaseManager().register(nodeDescr);\n         // also treat the registration message as a heartbeat\n         // no need to update its timestamp\n         // because its is done when the descriptor is created\n         heartbeatManager.addDatanode(nodeDescr);\n+        heartbeatManager.updateDnStat(nodeDescr);\n         incrementVersionCount(nodeReg.getSoftwareVersion());\n         startDecommissioningIfExcluded(nodeDescr);\n         success \u003d true;\n       } finally {\n         if (!success) {\n           removeDatanode(nodeDescr);\n           wipeDatanode(nodeDescr);\n           countSoftwareVersions();\n         }\n       }\n     } catch (InvalidTopologyException e) {\n       // If the network location is invalid, clear the cached mappings\n       // so that we have a chance to re-add this DataNode with the\n       // correct network location later.\n       List\u003cString\u003e invalidNodeNames \u003d new ArrayList\u003c\u003e(3);\n       // clear cache for nodes in IP or Hostname\n       invalidNodeNames.add(nodeReg.getIpAddr());\n       invalidNodeNames.add(nodeReg.getHostName());\n       invalidNodeNames.add(nodeReg.getPeerHostName());\n       dnsToSwitchMapping.reloadCachedMappings(invalidNodeNames);\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void registerDatanode(DatanodeRegistration nodeReg)\n      throws DisallowedDatanodeException, UnresolvedTopologyException {\n    InetAddress dnAddress \u003d Server.getRemoteIp();\n    if (dnAddress !\u003d null) {\n      // Mostly called inside an RPC, update ip and peer hostname\n      String hostname \u003d dnAddress.getHostName();\n      String ip \u003d dnAddress.getHostAddress();\n      if (checkIpHostnameInRegistration \u0026\u0026 !isNameResolved(dnAddress)) {\n        // Reject registration of unresolved datanode to prevent performance\n        // impact of repetitive DNS lookups later.\n        final String message \u003d \"hostname cannot be resolved (ip\u003d\"\n            + ip + \", hostname\u003d\" + hostname + \")\";\n        LOG.warn(\"Unresolved datanode registration: \" + message);\n        throw new DisallowedDatanodeException(nodeReg, message);\n      }\n      // update node registration with the ip and hostname from rpc request\n      nodeReg.setIpAddr(ip);\n      nodeReg.setPeerHostName(hostname);\n    }\n    \n    try {\n      nodeReg.setExportedKeys(blockManager.getBlockKeys());\n  \n      // Checks if the node is not on the hosts list.  If it is not, then\n      // it will be disallowed from registering. \n      if (!hostFileManager.isIncluded(nodeReg)) {\n        throw new DisallowedDatanodeException(nodeReg);\n      }\n        \n      NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n          + nodeReg + \" storage \" + nodeReg.getDatanodeUuid());\n  \n      DatanodeDescriptor nodeS \u003d getDatanode(nodeReg.getDatanodeUuid());\n      DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n          nodeReg.getIpAddr(), nodeReg.getXferPort());\n        \n      if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n        NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n        // nodeN previously served a different data storage, \n        // which is not served by anybody anymore.\n        removeDatanode(nodeN);\n        // physically remove node from datanodeMap\n        wipeDatanode(nodeN);\n        nodeN \u003d null;\n      }\n  \n      if (nodeS !\u003d null) {\n        if (nodeN \u003d\u003d nodeS) {\n          // The same datanode has been just restarted to serve the same data \n          // storage. We do not need to remove old data blocks, the delta will\n          // be calculated on the next block report from the datanode\n          if(NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n                + \"node restarted.\");\n          }\n        } else {\n          // nodeS is found\n          /* The registering datanode is a replacement node for the existing \n            data storage, which from now on will be served by a new node.\n            If this message repeats, both nodes might have same storageID \n            by (insanely rare) random chance. User needs to restart one of the\n            nodes with its data cleared (or user can just remove the StorageID\n            value in \"VERSION\" file under the data directory of the datanode,\n            but this is might not work if VERSION file format has changed \n         */        \n          NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n              + \" is replaced by \" + nodeReg + \" with the same storageID \"\n              + nodeReg.getDatanodeUuid());\n        }\n        \n        boolean success \u003d false;\n        try {\n          // update cluster map\n          getNetworkTopology().remove(nodeS);\n          if(shouldCountVersion(nodeS)) {\n            decrementVersionCount(nodeS.getSoftwareVersion());\n          }\n          nodeS.updateRegInfo(nodeReg);\n\n          nodeS.setSoftwareVersion(nodeReg.getSoftwareVersion());\n          nodeS.setDisallowed(false); // Node is in the include list\n\n          // resolve network location\n          if(this.rejectUnresolvedTopologyDN) {\n            nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));\n            nodeS.setDependentHostNames(getNetworkDependencies(nodeS));\n          } else {\n            nodeS.setNetworkLocation(\n                resolveNetworkLocationWithFallBackToDefaultLocation(nodeS));\n            nodeS.setDependentHostNames(\n                getNetworkDependenciesWithDefault(nodeS));\n          }\n          getNetworkTopology().add(nodeS);\n            \n          // also treat the registration message as a heartbeat\n          heartbeatManager.register(nodeS);\n          incrementVersionCount(nodeS.getSoftwareVersion());\n          startDecommissioningIfExcluded(nodeS);\n          success \u003d true;\n        } finally {\n          if (!success) {\n            removeDatanode(nodeS);\n            wipeDatanode(nodeS);\n            countSoftwareVersions();\n          }\n        }\n        return;\n      }\n\n      DatanodeDescriptor nodeDescr \n        \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n      boolean success \u003d false;\n      try {\n        // resolve network location\n        if(this.rejectUnresolvedTopologyDN) {\n          nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n          nodeDescr.setDependentHostNames(getNetworkDependencies(nodeDescr));\n        } else {\n          nodeDescr.setNetworkLocation(\n              resolveNetworkLocationWithFallBackToDefaultLocation(nodeDescr));\n          nodeDescr.setDependentHostNames(\n              getNetworkDependenciesWithDefault(nodeDescr));\n        }\n        networktopology.add(nodeDescr);\n        nodeDescr.setSoftwareVersion(nodeReg.getSoftwareVersion());\n  \n        // register new datanode\n        addDatanode(nodeDescr);\n        blockManager.getBlockReportLeaseManager().register(nodeDescr);\n        // also treat the registration message as a heartbeat\n        // no need to update its timestamp\n        // because its is done when the descriptor is created\n        heartbeatManager.addDatanode(nodeDescr);\n        heartbeatManager.updateDnStat(nodeDescr);\n        incrementVersionCount(nodeReg.getSoftwareVersion());\n        startDecommissioningIfExcluded(nodeDescr);\n        success \u003d true;\n      } finally {\n        if (!success) {\n          removeDatanode(nodeDescr);\n          wipeDatanode(nodeDescr);\n          countSoftwareVersions();\n        }\n      }\n    } catch (InvalidTopologyException e) {\n      // If the network location is invalid, clear the cached mappings\n      // so that we have a chance to re-add this DataNode with the\n      // correct network location later.\n      List\u003cString\u003e invalidNodeNames \u003d new ArrayList\u003c\u003e(3);\n      // clear cache for nodes in IP or Hostname\n      invalidNodeNames.add(nodeReg.getIpAddr());\n      invalidNodeNames.add(nodeReg.getHostName());\n      invalidNodeNames.add(nodeReg.getPeerHostName());\n      dnsToSwitchMapping.reloadCachedMappings(invalidNodeNames);\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "8602692338d6f493647205e0241e4116211fab75": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9371. Code cleanup for DatanodeManager. Contributed by Jing Zhao.\n",
      "commitDate": "15/12/15 10:47 AM",
      "commitName": "8602692338d6f493647205e0241e4116211fab75",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "01/12/15 4:09 PM",
      "commitNameOld": "a49cc74b4c72195dee1dfb6f9548e5e411dff553",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 13.78,
      "commitsBetweenForRepo": 73,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,155 +1,156 @@\n   public void registerDatanode(DatanodeRegistration nodeReg)\n       throws DisallowedDatanodeException, UnresolvedTopologyException {\n     InetAddress dnAddress \u003d Server.getRemoteIp();\n     if (dnAddress !\u003d null) {\n       // Mostly called inside an RPC, update ip and peer hostname\n       String hostname \u003d dnAddress.getHostName();\n       String ip \u003d dnAddress.getHostAddress();\n       if (checkIpHostnameInRegistration \u0026\u0026 !isNameResolved(dnAddress)) {\n         // Reject registration of unresolved datanode to prevent performance\n         // impact of repetitive DNS lookups later.\n         final String message \u003d \"hostname cannot be resolved (ip\u003d\"\n             + ip + \", hostname\u003d\" + hostname + \")\";\n         LOG.warn(\"Unresolved datanode registration: \" + message);\n         throw new DisallowedDatanodeException(nodeReg, message);\n       }\n       // update node registration with the ip and hostname from rpc request\n       nodeReg.setIpAddr(ip);\n       nodeReg.setPeerHostName(hostname);\n     }\n     \n     try {\n       nodeReg.setExportedKeys(blockManager.getBlockKeys());\n   \n       // Checks if the node is not on the hosts list.  If it is not, then\n       // it will be disallowed from registering. \n       if (!hostFileManager.isIncluded(nodeReg)) {\n         throw new DisallowedDatanodeException(nodeReg);\n       }\n         \n       NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n           + nodeReg + \" storage \" + nodeReg.getDatanodeUuid());\n   \n       DatanodeDescriptor nodeS \u003d getDatanode(nodeReg.getDatanodeUuid());\n       DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n           nodeReg.getIpAddr(), nodeReg.getXferPort());\n         \n       if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n         NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n         // nodeN previously served a different data storage, \n         // which is not served by anybody anymore.\n         removeDatanode(nodeN);\n         // physically remove node from datanodeMap\n         wipeDatanode(nodeN);\n         nodeN \u003d null;\n       }\n   \n       if (nodeS !\u003d null) {\n         if (nodeN \u003d\u003d nodeS) {\n           // The same datanode has been just restarted to serve the same data \n           // storage. We do not need to remove old data blocks, the delta will\n           // be calculated on the next block report from the datanode\n           if(NameNode.stateChangeLog.isDebugEnabled()) {\n             NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n                 + \"node restarted.\");\n           }\n         } else {\n           // nodeS is found\n           /* The registering datanode is a replacement node for the existing \n             data storage, which from now on will be served by a new node.\n             If this message repeats, both nodes might have same storageID \n             by (insanely rare) random chance. User needs to restart one of the\n             nodes with its data cleared (or user can just remove the StorageID\n             value in \"VERSION\" file under the data directory of the datanode,\n             but this is might not work if VERSION file format has changed \n          */        \n           NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n               + \" is replaced by \" + nodeReg + \" with the same storageID \"\n               + nodeReg.getDatanodeUuid());\n         }\n         \n         boolean success \u003d false;\n         try {\n           // update cluster map\n           getNetworkTopology().remove(nodeS);\n           if(shouldCountVersion(nodeS)) {\n             decrementVersionCount(nodeS.getSoftwareVersion());\n           }\n           nodeS.updateRegInfo(nodeReg);\n \n           nodeS.setSoftwareVersion(nodeReg.getSoftwareVersion());\n           nodeS.setDisallowed(false); // Node is in the include list\n \n           // resolve network location\n           if(this.rejectUnresolvedTopologyDN) {\n             nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));\n             nodeS.setDependentHostNames(getNetworkDependencies(nodeS));\n           } else {\n             nodeS.setNetworkLocation(\n                 resolveNetworkLocationWithFallBackToDefaultLocation(nodeS));\n             nodeS.setDependentHostNames(\n                 getNetworkDependenciesWithDefault(nodeS));\n           }\n           getNetworkTopology().add(nodeS);\n             \n           // also treat the registration message as a heartbeat\n           heartbeatManager.register(nodeS);\n           incrementVersionCount(nodeS.getSoftwareVersion());\n           startDecommissioningIfExcluded(nodeS);\n           success \u003d true;\n         } finally {\n           if (!success) {\n             removeDatanode(nodeS);\n             wipeDatanode(nodeS);\n             countSoftwareVersions();\n           }\n         }\n         return;\n       }\n \n       DatanodeDescriptor nodeDescr \n         \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n       boolean success \u003d false;\n       try {\n         // resolve network location\n         if(this.rejectUnresolvedTopologyDN) {\n           nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n           nodeDescr.setDependentHostNames(getNetworkDependencies(nodeDescr));\n         } else {\n           nodeDescr.setNetworkLocation(\n               resolveNetworkLocationWithFallBackToDefaultLocation(nodeDescr));\n           nodeDescr.setDependentHostNames(\n               getNetworkDependenciesWithDefault(nodeDescr));\n         }\n         networktopology.add(nodeDescr);\n         nodeDescr.setSoftwareVersion(nodeReg.getSoftwareVersion());\n   \n         // register new datanode\n         addDatanode(nodeDescr);\n+        blockManager.getBlockReportLeaseManager().register(nodeDescr);\n         // also treat the registration message as a heartbeat\n         // no need to update its timestamp\n         // because its is done when the descriptor is created\n         heartbeatManager.addDatanode(nodeDescr);\n         incrementVersionCount(nodeReg.getSoftwareVersion());\n         startDecommissioningIfExcluded(nodeDescr);\n         success \u003d true;\n       } finally {\n         if (!success) {\n           removeDatanode(nodeDescr);\n           wipeDatanode(nodeDescr);\n           countSoftwareVersions();\n         }\n       }\n     } catch (InvalidTopologyException e) {\n       // If the network location is invalid, clear the cached mappings\n       // so that we have a chance to re-add this DataNode with the\n       // correct network location later.\n       List\u003cString\u003e invalidNodeNames \u003d new ArrayList\u003c\u003e(3);\n       // clear cache for nodes in IP or Hostname\n       invalidNodeNames.add(nodeReg.getIpAddr());\n       invalidNodeNames.add(nodeReg.getHostName());\n       invalidNodeNames.add(nodeReg.getPeerHostName());\n       dnsToSwitchMapping.reloadCachedMappings(invalidNodeNames);\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void registerDatanode(DatanodeRegistration nodeReg)\n      throws DisallowedDatanodeException, UnresolvedTopologyException {\n    InetAddress dnAddress \u003d Server.getRemoteIp();\n    if (dnAddress !\u003d null) {\n      // Mostly called inside an RPC, update ip and peer hostname\n      String hostname \u003d dnAddress.getHostName();\n      String ip \u003d dnAddress.getHostAddress();\n      if (checkIpHostnameInRegistration \u0026\u0026 !isNameResolved(dnAddress)) {\n        // Reject registration of unresolved datanode to prevent performance\n        // impact of repetitive DNS lookups later.\n        final String message \u003d \"hostname cannot be resolved (ip\u003d\"\n            + ip + \", hostname\u003d\" + hostname + \")\";\n        LOG.warn(\"Unresolved datanode registration: \" + message);\n        throw new DisallowedDatanodeException(nodeReg, message);\n      }\n      // update node registration with the ip and hostname from rpc request\n      nodeReg.setIpAddr(ip);\n      nodeReg.setPeerHostName(hostname);\n    }\n    \n    try {\n      nodeReg.setExportedKeys(blockManager.getBlockKeys());\n  \n      // Checks if the node is not on the hosts list.  If it is not, then\n      // it will be disallowed from registering. \n      if (!hostFileManager.isIncluded(nodeReg)) {\n        throw new DisallowedDatanodeException(nodeReg);\n      }\n        \n      NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n          + nodeReg + \" storage \" + nodeReg.getDatanodeUuid());\n  \n      DatanodeDescriptor nodeS \u003d getDatanode(nodeReg.getDatanodeUuid());\n      DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n          nodeReg.getIpAddr(), nodeReg.getXferPort());\n        \n      if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n        NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n        // nodeN previously served a different data storage, \n        // which is not served by anybody anymore.\n        removeDatanode(nodeN);\n        // physically remove node from datanodeMap\n        wipeDatanode(nodeN);\n        nodeN \u003d null;\n      }\n  \n      if (nodeS !\u003d null) {\n        if (nodeN \u003d\u003d nodeS) {\n          // The same datanode has been just restarted to serve the same data \n          // storage. We do not need to remove old data blocks, the delta will\n          // be calculated on the next block report from the datanode\n          if(NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n                + \"node restarted.\");\n          }\n        } else {\n          // nodeS is found\n          /* The registering datanode is a replacement node for the existing \n            data storage, which from now on will be served by a new node.\n            If this message repeats, both nodes might have same storageID \n            by (insanely rare) random chance. User needs to restart one of the\n            nodes with its data cleared (or user can just remove the StorageID\n            value in \"VERSION\" file under the data directory of the datanode,\n            but this is might not work if VERSION file format has changed \n         */        \n          NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n              + \" is replaced by \" + nodeReg + \" with the same storageID \"\n              + nodeReg.getDatanodeUuid());\n        }\n        \n        boolean success \u003d false;\n        try {\n          // update cluster map\n          getNetworkTopology().remove(nodeS);\n          if(shouldCountVersion(nodeS)) {\n            decrementVersionCount(nodeS.getSoftwareVersion());\n          }\n          nodeS.updateRegInfo(nodeReg);\n\n          nodeS.setSoftwareVersion(nodeReg.getSoftwareVersion());\n          nodeS.setDisallowed(false); // Node is in the include list\n\n          // resolve network location\n          if(this.rejectUnresolvedTopologyDN) {\n            nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));\n            nodeS.setDependentHostNames(getNetworkDependencies(nodeS));\n          } else {\n            nodeS.setNetworkLocation(\n                resolveNetworkLocationWithFallBackToDefaultLocation(nodeS));\n            nodeS.setDependentHostNames(\n                getNetworkDependenciesWithDefault(nodeS));\n          }\n          getNetworkTopology().add(nodeS);\n            \n          // also treat the registration message as a heartbeat\n          heartbeatManager.register(nodeS);\n          incrementVersionCount(nodeS.getSoftwareVersion());\n          startDecommissioningIfExcluded(nodeS);\n          success \u003d true;\n        } finally {\n          if (!success) {\n            removeDatanode(nodeS);\n            wipeDatanode(nodeS);\n            countSoftwareVersions();\n          }\n        }\n        return;\n      }\n\n      DatanodeDescriptor nodeDescr \n        \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n      boolean success \u003d false;\n      try {\n        // resolve network location\n        if(this.rejectUnresolvedTopologyDN) {\n          nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n          nodeDescr.setDependentHostNames(getNetworkDependencies(nodeDescr));\n        } else {\n          nodeDescr.setNetworkLocation(\n              resolveNetworkLocationWithFallBackToDefaultLocation(nodeDescr));\n          nodeDescr.setDependentHostNames(\n              getNetworkDependenciesWithDefault(nodeDescr));\n        }\n        networktopology.add(nodeDescr);\n        nodeDescr.setSoftwareVersion(nodeReg.getSoftwareVersion());\n  \n        // register new datanode\n        addDatanode(nodeDescr);\n        blockManager.getBlockReportLeaseManager().register(nodeDescr);\n        // also treat the registration message as a heartbeat\n        // no need to update its timestamp\n        // because its is done when the descriptor is created\n        heartbeatManager.addDatanode(nodeDescr);\n        incrementVersionCount(nodeReg.getSoftwareVersion());\n        startDecommissioningIfExcluded(nodeDescr);\n        success \u003d true;\n      } finally {\n        if (!success) {\n          removeDatanode(nodeDescr);\n          wipeDatanode(nodeDescr);\n          countSoftwareVersions();\n        }\n      }\n    } catch (InvalidTopologyException e) {\n      // If the network location is invalid, clear the cached mappings\n      // so that we have a chance to re-add this DataNode with the\n      // correct network location later.\n      List\u003cString\u003e invalidNodeNames \u003d new ArrayList\u003c\u003e(3);\n      // clear cache for nodes in IP or Hostname\n      invalidNodeNames.add(nodeReg.getIpAddr());\n      invalidNodeNames.add(nodeReg.getHostName());\n      invalidNodeNames.add(nodeReg.getPeerHostName());\n      dnsToSwitchMapping.reloadCachedMappings(invalidNodeNames);\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "2ffd84273ac490724fe7e7825664bb6d09ef0e99": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8653. Code cleanup for DatanodeManager, DatanodeDescriptor and DatanodeStorageInfo. Contributed by Zhe Zhang.\n",
      "commitDate": "29/06/15 12:12 PM",
      "commitName": "2ffd84273ac490724fe7e7825664bb6d09ef0e99",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "12/06/15 11:38 AM",
      "commitNameOld": "c17439c2ddd921b63b1635e6f1cba634b8da8557",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 17.02,
      "commitsBetweenForRepo": 104,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,155 +1,155 @@\n   public void registerDatanode(DatanodeRegistration nodeReg)\n       throws DisallowedDatanodeException, UnresolvedTopologyException {\n     InetAddress dnAddress \u003d Server.getRemoteIp();\n     if (dnAddress !\u003d null) {\n       // Mostly called inside an RPC, update ip and peer hostname\n       String hostname \u003d dnAddress.getHostName();\n       String ip \u003d dnAddress.getHostAddress();\n       if (checkIpHostnameInRegistration \u0026\u0026 !isNameResolved(dnAddress)) {\n         // Reject registration of unresolved datanode to prevent performance\n         // impact of repetitive DNS lookups later.\n         final String message \u003d \"hostname cannot be resolved (ip\u003d\"\n             + ip + \", hostname\u003d\" + hostname + \")\";\n         LOG.warn(\"Unresolved datanode registration: \" + message);\n         throw new DisallowedDatanodeException(nodeReg, message);\n       }\n       // update node registration with the ip and hostname from rpc request\n       nodeReg.setIpAddr(ip);\n       nodeReg.setPeerHostName(hostname);\n     }\n     \n     try {\n       nodeReg.setExportedKeys(blockManager.getBlockKeys());\n   \n       // Checks if the node is not on the hosts list.  If it is not, then\n       // it will be disallowed from registering. \n       if (!hostFileManager.isIncluded(nodeReg)) {\n         throw new DisallowedDatanodeException(nodeReg);\n       }\n         \n       NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n           + nodeReg + \" storage \" + nodeReg.getDatanodeUuid());\n   \n       DatanodeDescriptor nodeS \u003d getDatanode(nodeReg.getDatanodeUuid());\n       DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n           nodeReg.getIpAddr(), nodeReg.getXferPort());\n         \n       if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n         NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n         // nodeN previously served a different data storage, \n         // which is not served by anybody anymore.\n         removeDatanode(nodeN);\n         // physically remove node from datanodeMap\n         wipeDatanode(nodeN);\n         nodeN \u003d null;\n       }\n   \n       if (nodeS !\u003d null) {\n         if (nodeN \u003d\u003d nodeS) {\n           // The same datanode has been just restarted to serve the same data \n           // storage. We do not need to remove old data blocks, the delta will\n           // be calculated on the next block report from the datanode\n           if(NameNode.stateChangeLog.isDebugEnabled()) {\n             NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n                 + \"node restarted.\");\n           }\n         } else {\n           // nodeS is found\n           /* The registering datanode is a replacement node for the existing \n             data storage, which from now on will be served by a new node.\n             If this message repeats, both nodes might have same storageID \n             by (insanely rare) random chance. User needs to restart one of the\n             nodes with its data cleared (or user can just remove the StorageID\n             value in \"VERSION\" file under the data directory of the datanode,\n             but this is might not work if VERSION file format has changed \n          */        \n           NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n               + \" is replaced by \" + nodeReg + \" with the same storageID \"\n               + nodeReg.getDatanodeUuid());\n         }\n         \n         boolean success \u003d false;\n         try {\n           // update cluster map\n           getNetworkTopology().remove(nodeS);\n           if(shouldCountVersion(nodeS)) {\n             decrementVersionCount(nodeS.getSoftwareVersion());\n           }\n           nodeS.updateRegInfo(nodeReg);\n \n           nodeS.setSoftwareVersion(nodeReg.getSoftwareVersion());\n           nodeS.setDisallowed(false); // Node is in the include list\n \n           // resolve network location\n           if(this.rejectUnresolvedTopologyDN) {\n             nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));\n             nodeS.setDependentHostNames(getNetworkDependencies(nodeS));\n           } else {\n             nodeS.setNetworkLocation(\n                 resolveNetworkLocationWithFallBackToDefaultLocation(nodeS));\n             nodeS.setDependentHostNames(\n                 getNetworkDependenciesWithDefault(nodeS));\n           }\n           getNetworkTopology().add(nodeS);\n             \n           // also treat the registration message as a heartbeat\n           heartbeatManager.register(nodeS);\n           incrementVersionCount(nodeS.getSoftwareVersion());\n           startDecommissioningIfExcluded(nodeS);\n           success \u003d true;\n         } finally {\n           if (!success) {\n             removeDatanode(nodeS);\n             wipeDatanode(nodeS);\n             countSoftwareVersions();\n           }\n         }\n         return;\n       }\n \n       DatanodeDescriptor nodeDescr \n         \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n       boolean success \u003d false;\n       try {\n         // resolve network location\n         if(this.rejectUnresolvedTopologyDN) {\n           nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n           nodeDescr.setDependentHostNames(getNetworkDependencies(nodeDescr));\n         } else {\n           nodeDescr.setNetworkLocation(\n               resolveNetworkLocationWithFallBackToDefaultLocation(nodeDescr));\n           nodeDescr.setDependentHostNames(\n               getNetworkDependenciesWithDefault(nodeDescr));\n         }\n         networktopology.add(nodeDescr);\n         nodeDescr.setSoftwareVersion(nodeReg.getSoftwareVersion());\n   \n         // register new datanode\n         addDatanode(nodeDescr);\n         // also treat the registration message as a heartbeat\n         // no need to update its timestamp\n         // because its is done when the descriptor is created\n         heartbeatManager.addDatanode(nodeDescr);\n         incrementVersionCount(nodeReg.getSoftwareVersion());\n         startDecommissioningIfExcluded(nodeDescr);\n         success \u003d true;\n       } finally {\n         if (!success) {\n           removeDatanode(nodeDescr);\n           wipeDatanode(nodeDescr);\n           countSoftwareVersions();\n         }\n       }\n     } catch (InvalidTopologyException e) {\n       // If the network location is invalid, clear the cached mappings\n       // so that we have a chance to re-add this DataNode with the\n       // correct network location later.\n-      List\u003cString\u003e invalidNodeNames \u003d new ArrayList\u003cString\u003e(3);\n+      List\u003cString\u003e invalidNodeNames \u003d new ArrayList\u003c\u003e(3);\n       // clear cache for nodes in IP or Hostname\n       invalidNodeNames.add(nodeReg.getIpAddr());\n       invalidNodeNames.add(nodeReg.getHostName());\n       invalidNodeNames.add(nodeReg.getPeerHostName());\n       dnsToSwitchMapping.reloadCachedMappings(invalidNodeNames);\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void registerDatanode(DatanodeRegistration nodeReg)\n      throws DisallowedDatanodeException, UnresolvedTopologyException {\n    InetAddress dnAddress \u003d Server.getRemoteIp();\n    if (dnAddress !\u003d null) {\n      // Mostly called inside an RPC, update ip and peer hostname\n      String hostname \u003d dnAddress.getHostName();\n      String ip \u003d dnAddress.getHostAddress();\n      if (checkIpHostnameInRegistration \u0026\u0026 !isNameResolved(dnAddress)) {\n        // Reject registration of unresolved datanode to prevent performance\n        // impact of repetitive DNS lookups later.\n        final String message \u003d \"hostname cannot be resolved (ip\u003d\"\n            + ip + \", hostname\u003d\" + hostname + \")\";\n        LOG.warn(\"Unresolved datanode registration: \" + message);\n        throw new DisallowedDatanodeException(nodeReg, message);\n      }\n      // update node registration with the ip and hostname from rpc request\n      nodeReg.setIpAddr(ip);\n      nodeReg.setPeerHostName(hostname);\n    }\n    \n    try {\n      nodeReg.setExportedKeys(blockManager.getBlockKeys());\n  \n      // Checks if the node is not on the hosts list.  If it is not, then\n      // it will be disallowed from registering. \n      if (!hostFileManager.isIncluded(nodeReg)) {\n        throw new DisallowedDatanodeException(nodeReg);\n      }\n        \n      NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n          + nodeReg + \" storage \" + nodeReg.getDatanodeUuid());\n  \n      DatanodeDescriptor nodeS \u003d getDatanode(nodeReg.getDatanodeUuid());\n      DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n          nodeReg.getIpAddr(), nodeReg.getXferPort());\n        \n      if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n        NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n        // nodeN previously served a different data storage, \n        // which is not served by anybody anymore.\n        removeDatanode(nodeN);\n        // physically remove node from datanodeMap\n        wipeDatanode(nodeN);\n        nodeN \u003d null;\n      }\n  \n      if (nodeS !\u003d null) {\n        if (nodeN \u003d\u003d nodeS) {\n          // The same datanode has been just restarted to serve the same data \n          // storage. We do not need to remove old data blocks, the delta will\n          // be calculated on the next block report from the datanode\n          if(NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n                + \"node restarted.\");\n          }\n        } else {\n          // nodeS is found\n          /* The registering datanode is a replacement node for the existing \n            data storage, which from now on will be served by a new node.\n            If this message repeats, both nodes might have same storageID \n            by (insanely rare) random chance. User needs to restart one of the\n            nodes with its data cleared (or user can just remove the StorageID\n            value in \"VERSION\" file under the data directory of the datanode,\n            but this is might not work if VERSION file format has changed \n         */        \n          NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n              + \" is replaced by \" + nodeReg + \" with the same storageID \"\n              + nodeReg.getDatanodeUuid());\n        }\n        \n        boolean success \u003d false;\n        try {\n          // update cluster map\n          getNetworkTopology().remove(nodeS);\n          if(shouldCountVersion(nodeS)) {\n            decrementVersionCount(nodeS.getSoftwareVersion());\n          }\n          nodeS.updateRegInfo(nodeReg);\n\n          nodeS.setSoftwareVersion(nodeReg.getSoftwareVersion());\n          nodeS.setDisallowed(false); // Node is in the include list\n\n          // resolve network location\n          if(this.rejectUnresolvedTopologyDN) {\n            nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));\n            nodeS.setDependentHostNames(getNetworkDependencies(nodeS));\n          } else {\n            nodeS.setNetworkLocation(\n                resolveNetworkLocationWithFallBackToDefaultLocation(nodeS));\n            nodeS.setDependentHostNames(\n                getNetworkDependenciesWithDefault(nodeS));\n          }\n          getNetworkTopology().add(nodeS);\n            \n          // also treat the registration message as a heartbeat\n          heartbeatManager.register(nodeS);\n          incrementVersionCount(nodeS.getSoftwareVersion());\n          startDecommissioningIfExcluded(nodeS);\n          success \u003d true;\n        } finally {\n          if (!success) {\n            removeDatanode(nodeS);\n            wipeDatanode(nodeS);\n            countSoftwareVersions();\n          }\n        }\n        return;\n      }\n\n      DatanodeDescriptor nodeDescr \n        \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n      boolean success \u003d false;\n      try {\n        // resolve network location\n        if(this.rejectUnresolvedTopologyDN) {\n          nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n          nodeDescr.setDependentHostNames(getNetworkDependencies(nodeDescr));\n        } else {\n          nodeDescr.setNetworkLocation(\n              resolveNetworkLocationWithFallBackToDefaultLocation(nodeDescr));\n          nodeDescr.setDependentHostNames(\n              getNetworkDependenciesWithDefault(nodeDescr));\n        }\n        networktopology.add(nodeDescr);\n        nodeDescr.setSoftwareVersion(nodeReg.getSoftwareVersion());\n  \n        // register new datanode\n        addDatanode(nodeDescr);\n        // also treat the registration message as a heartbeat\n        // no need to update its timestamp\n        // because its is done when the descriptor is created\n        heartbeatManager.addDatanode(nodeDescr);\n        incrementVersionCount(nodeReg.getSoftwareVersion());\n        startDecommissioningIfExcluded(nodeDescr);\n        success \u003d true;\n      } finally {\n        if (!success) {\n          removeDatanode(nodeDescr);\n          wipeDatanode(nodeDescr);\n          countSoftwareVersions();\n        }\n      }\n    } catch (InvalidTopologyException e) {\n      // If the network location is invalid, clear the cached mappings\n      // so that we have a chance to re-add this DataNode with the\n      // correct network location later.\n      List\u003cString\u003e invalidNodeNames \u003d new ArrayList\u003c\u003e(3);\n      // clear cache for nodes in IP or Hostname\n      invalidNodeNames.add(nodeReg.getIpAddr());\n      invalidNodeNames.add(nodeReg.getHostName());\n      invalidNodeNames.add(nodeReg.getPeerHostName());\n      dnsToSwitchMapping.reloadCachedMappings(invalidNodeNames);\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "6ee0d32b98bc3aa5ed42859f1325d5a14fd1722a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7411. Change decommission logic to throttle by blocks rather\nthan nodes in each interval. Contributed by Andrew Wang\n",
      "commitDate": "08/03/15 6:31 PM",
      "commitName": "6ee0d32b98bc3aa5ed42859f1325d5a14fd1722a",
      "commitAuthor": "Chris Douglas",
      "commitDateOld": "16/02/15 2:43 PM",
      "commitNameOld": "9729b244de50322c2cc889c97c2ffb2b4675cf77",
      "commitAuthorOld": "cnauroth",
      "daysBetweenCommits": 20.12,
      "commitsBetweenForRepo": 164,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,155 +1,155 @@\n   public void registerDatanode(DatanodeRegistration nodeReg)\n       throws DisallowedDatanodeException, UnresolvedTopologyException {\n     InetAddress dnAddress \u003d Server.getRemoteIp();\n     if (dnAddress !\u003d null) {\n       // Mostly called inside an RPC, update ip and peer hostname\n       String hostname \u003d dnAddress.getHostName();\n       String ip \u003d dnAddress.getHostAddress();\n       if (checkIpHostnameInRegistration \u0026\u0026 !isNameResolved(dnAddress)) {\n         // Reject registration of unresolved datanode to prevent performance\n         // impact of repetitive DNS lookups later.\n         final String message \u003d \"hostname cannot be resolved (ip\u003d\"\n             + ip + \", hostname\u003d\" + hostname + \")\";\n         LOG.warn(\"Unresolved datanode registration: \" + message);\n         throw new DisallowedDatanodeException(nodeReg, message);\n       }\n       // update node registration with the ip and hostname from rpc request\n       nodeReg.setIpAddr(ip);\n       nodeReg.setPeerHostName(hostname);\n     }\n     \n     try {\n       nodeReg.setExportedKeys(blockManager.getBlockKeys());\n   \n       // Checks if the node is not on the hosts list.  If it is not, then\n       // it will be disallowed from registering. \n       if (!hostFileManager.isIncluded(nodeReg)) {\n         throw new DisallowedDatanodeException(nodeReg);\n       }\n         \n       NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n           + nodeReg + \" storage \" + nodeReg.getDatanodeUuid());\n   \n       DatanodeDescriptor nodeS \u003d getDatanode(nodeReg.getDatanodeUuid());\n       DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n           nodeReg.getIpAddr(), nodeReg.getXferPort());\n         \n       if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n         NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n         // nodeN previously served a different data storage, \n         // which is not served by anybody anymore.\n         removeDatanode(nodeN);\n         // physically remove node from datanodeMap\n         wipeDatanode(nodeN);\n         nodeN \u003d null;\n       }\n   \n       if (nodeS !\u003d null) {\n         if (nodeN \u003d\u003d nodeS) {\n           // The same datanode has been just restarted to serve the same data \n           // storage. We do not need to remove old data blocks, the delta will\n           // be calculated on the next block report from the datanode\n           if(NameNode.stateChangeLog.isDebugEnabled()) {\n             NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n                 + \"node restarted.\");\n           }\n         } else {\n           // nodeS is found\n           /* The registering datanode is a replacement node for the existing \n             data storage, which from now on will be served by a new node.\n             If this message repeats, both nodes might have same storageID \n             by (insanely rare) random chance. User needs to restart one of the\n             nodes with its data cleared (or user can just remove the StorageID\n             value in \"VERSION\" file under the data directory of the datanode,\n             but this is might not work if VERSION file format has changed \n          */        \n           NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n               + \" is replaced by \" + nodeReg + \" with the same storageID \"\n               + nodeReg.getDatanodeUuid());\n         }\n         \n         boolean success \u003d false;\n         try {\n           // update cluster map\n           getNetworkTopology().remove(nodeS);\n           if(shouldCountVersion(nodeS)) {\n             decrementVersionCount(nodeS.getSoftwareVersion());\n           }\n           nodeS.updateRegInfo(nodeReg);\n \n           nodeS.setSoftwareVersion(nodeReg.getSoftwareVersion());\n           nodeS.setDisallowed(false); // Node is in the include list\n \n           // resolve network location\n           if(this.rejectUnresolvedTopologyDN) {\n             nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));\n             nodeS.setDependentHostNames(getNetworkDependencies(nodeS));\n           } else {\n             nodeS.setNetworkLocation(\n                 resolveNetworkLocationWithFallBackToDefaultLocation(nodeS));\n             nodeS.setDependentHostNames(\n                 getNetworkDependenciesWithDefault(nodeS));\n           }\n           getNetworkTopology().add(nodeS);\n             \n           // also treat the registration message as a heartbeat\n           heartbeatManager.register(nodeS);\n           incrementVersionCount(nodeS.getSoftwareVersion());\n-          checkDecommissioning(nodeS);\n+          startDecommissioningIfExcluded(nodeS);\n           success \u003d true;\n         } finally {\n           if (!success) {\n             removeDatanode(nodeS);\n             wipeDatanode(nodeS);\n             countSoftwareVersions();\n           }\n         }\n         return;\n       }\n \n       DatanodeDescriptor nodeDescr \n         \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n       boolean success \u003d false;\n       try {\n         // resolve network location\n         if(this.rejectUnresolvedTopologyDN) {\n           nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n           nodeDescr.setDependentHostNames(getNetworkDependencies(nodeDescr));\n         } else {\n           nodeDescr.setNetworkLocation(\n               resolveNetworkLocationWithFallBackToDefaultLocation(nodeDescr));\n           nodeDescr.setDependentHostNames(\n               getNetworkDependenciesWithDefault(nodeDescr));\n         }\n         networktopology.add(nodeDescr);\n         nodeDescr.setSoftwareVersion(nodeReg.getSoftwareVersion());\n   \n         // register new datanode\n         addDatanode(nodeDescr);\n         // also treat the registration message as a heartbeat\n         // no need to update its timestamp\n         // because its is done when the descriptor is created\n         heartbeatManager.addDatanode(nodeDescr);\n         incrementVersionCount(nodeReg.getSoftwareVersion());\n-        checkDecommissioning(nodeDescr);\n+        startDecommissioningIfExcluded(nodeDescr);\n         success \u003d true;\n       } finally {\n         if (!success) {\n           removeDatanode(nodeDescr);\n           wipeDatanode(nodeDescr);\n           countSoftwareVersions();\n         }\n       }\n     } catch (InvalidTopologyException e) {\n       // If the network location is invalid, clear the cached mappings\n       // so that we have a chance to re-add this DataNode with the\n       // correct network location later.\n       List\u003cString\u003e invalidNodeNames \u003d new ArrayList\u003cString\u003e(3);\n       // clear cache for nodes in IP or Hostname\n       invalidNodeNames.add(nodeReg.getIpAddr());\n       invalidNodeNames.add(nodeReg.getHostName());\n       invalidNodeNames.add(nodeReg.getPeerHostName());\n       dnsToSwitchMapping.reloadCachedMappings(invalidNodeNames);\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void registerDatanode(DatanodeRegistration nodeReg)\n      throws DisallowedDatanodeException, UnresolvedTopologyException {\n    InetAddress dnAddress \u003d Server.getRemoteIp();\n    if (dnAddress !\u003d null) {\n      // Mostly called inside an RPC, update ip and peer hostname\n      String hostname \u003d dnAddress.getHostName();\n      String ip \u003d dnAddress.getHostAddress();\n      if (checkIpHostnameInRegistration \u0026\u0026 !isNameResolved(dnAddress)) {\n        // Reject registration of unresolved datanode to prevent performance\n        // impact of repetitive DNS lookups later.\n        final String message \u003d \"hostname cannot be resolved (ip\u003d\"\n            + ip + \", hostname\u003d\" + hostname + \")\";\n        LOG.warn(\"Unresolved datanode registration: \" + message);\n        throw new DisallowedDatanodeException(nodeReg, message);\n      }\n      // update node registration with the ip and hostname from rpc request\n      nodeReg.setIpAddr(ip);\n      nodeReg.setPeerHostName(hostname);\n    }\n    \n    try {\n      nodeReg.setExportedKeys(blockManager.getBlockKeys());\n  \n      // Checks if the node is not on the hosts list.  If it is not, then\n      // it will be disallowed from registering. \n      if (!hostFileManager.isIncluded(nodeReg)) {\n        throw new DisallowedDatanodeException(nodeReg);\n      }\n        \n      NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n          + nodeReg + \" storage \" + nodeReg.getDatanodeUuid());\n  \n      DatanodeDescriptor nodeS \u003d getDatanode(nodeReg.getDatanodeUuid());\n      DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n          nodeReg.getIpAddr(), nodeReg.getXferPort());\n        \n      if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n        NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n        // nodeN previously served a different data storage, \n        // which is not served by anybody anymore.\n        removeDatanode(nodeN);\n        // physically remove node from datanodeMap\n        wipeDatanode(nodeN);\n        nodeN \u003d null;\n      }\n  \n      if (nodeS !\u003d null) {\n        if (nodeN \u003d\u003d nodeS) {\n          // The same datanode has been just restarted to serve the same data \n          // storage. We do not need to remove old data blocks, the delta will\n          // be calculated on the next block report from the datanode\n          if(NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n                + \"node restarted.\");\n          }\n        } else {\n          // nodeS is found\n          /* The registering datanode is a replacement node for the existing \n            data storage, which from now on will be served by a new node.\n            If this message repeats, both nodes might have same storageID \n            by (insanely rare) random chance. User needs to restart one of the\n            nodes with its data cleared (or user can just remove the StorageID\n            value in \"VERSION\" file under the data directory of the datanode,\n            but this is might not work if VERSION file format has changed \n         */        \n          NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n              + \" is replaced by \" + nodeReg + \" with the same storageID \"\n              + nodeReg.getDatanodeUuid());\n        }\n        \n        boolean success \u003d false;\n        try {\n          // update cluster map\n          getNetworkTopology().remove(nodeS);\n          if(shouldCountVersion(nodeS)) {\n            decrementVersionCount(nodeS.getSoftwareVersion());\n          }\n          nodeS.updateRegInfo(nodeReg);\n\n          nodeS.setSoftwareVersion(nodeReg.getSoftwareVersion());\n          nodeS.setDisallowed(false); // Node is in the include list\n\n          // resolve network location\n          if(this.rejectUnresolvedTopologyDN) {\n            nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));\n            nodeS.setDependentHostNames(getNetworkDependencies(nodeS));\n          } else {\n            nodeS.setNetworkLocation(\n                resolveNetworkLocationWithFallBackToDefaultLocation(nodeS));\n            nodeS.setDependentHostNames(\n                getNetworkDependenciesWithDefault(nodeS));\n          }\n          getNetworkTopology().add(nodeS);\n            \n          // also treat the registration message as a heartbeat\n          heartbeatManager.register(nodeS);\n          incrementVersionCount(nodeS.getSoftwareVersion());\n          startDecommissioningIfExcluded(nodeS);\n          success \u003d true;\n        } finally {\n          if (!success) {\n            removeDatanode(nodeS);\n            wipeDatanode(nodeS);\n            countSoftwareVersions();\n          }\n        }\n        return;\n      }\n\n      DatanodeDescriptor nodeDescr \n        \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n      boolean success \u003d false;\n      try {\n        // resolve network location\n        if(this.rejectUnresolvedTopologyDN) {\n          nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n          nodeDescr.setDependentHostNames(getNetworkDependencies(nodeDescr));\n        } else {\n          nodeDescr.setNetworkLocation(\n              resolveNetworkLocationWithFallBackToDefaultLocation(nodeDescr));\n          nodeDescr.setDependentHostNames(\n              getNetworkDependenciesWithDefault(nodeDescr));\n        }\n        networktopology.add(nodeDescr);\n        nodeDescr.setSoftwareVersion(nodeReg.getSoftwareVersion());\n  \n        // register new datanode\n        addDatanode(nodeDescr);\n        // also treat the registration message as a heartbeat\n        // no need to update its timestamp\n        // because its is done when the descriptor is created\n        heartbeatManager.addDatanode(nodeDescr);\n        incrementVersionCount(nodeReg.getSoftwareVersion());\n        startDecommissioningIfExcluded(nodeDescr);\n        success \u003d true;\n      } finally {\n        if (!success) {\n          removeDatanode(nodeDescr);\n          wipeDatanode(nodeDescr);\n          countSoftwareVersions();\n        }\n      }\n    } catch (InvalidTopologyException e) {\n      // If the network location is invalid, clear the cached mappings\n      // so that we have a chance to re-add this DataNode with the\n      // correct network location later.\n      List\u003cString\u003e invalidNodeNames \u003d new ArrayList\u003cString\u003e(3);\n      // clear cache for nodes in IP or Hostname\n      invalidNodeNames.add(nodeReg.getIpAddr());\n      invalidNodeNames.add(nodeReg.getHostName());\n      invalidNodeNames.add(nodeReg.getPeerHostName());\n      dnsToSwitchMapping.reloadCachedMappings(invalidNodeNames);\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "5bd048e8378034b496bacc73b470a25d855aceb1": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7373. Allow decommissioning of dead DataNodes. Contributed by Zhe Zhang.\n",
      "commitDate": "18/11/14 10:16 PM",
      "commitName": "5bd048e8378034b496bacc73b470a25d855aceb1",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "18/11/14 10:14 PM",
      "commitNameOld": "406c09ad1150c4971c2b7675fcb0263d40517fbf",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,156 +1,155 @@\n   public void registerDatanode(DatanodeRegistration nodeReg)\n       throws DisallowedDatanodeException, UnresolvedTopologyException {\n     InetAddress dnAddress \u003d Server.getRemoteIp();\n     if (dnAddress !\u003d null) {\n       // Mostly called inside an RPC, update ip and peer hostname\n       String hostname \u003d dnAddress.getHostName();\n       String ip \u003d dnAddress.getHostAddress();\n       if (checkIpHostnameInRegistration \u0026\u0026 !isNameResolved(dnAddress)) {\n         // Reject registration of unresolved datanode to prevent performance\n         // impact of repetitive DNS lookups later.\n         final String message \u003d \"hostname cannot be resolved (ip\u003d\"\n             + ip + \", hostname\u003d\" + hostname + \")\";\n         LOG.warn(\"Unresolved datanode registration: \" + message);\n         throw new DisallowedDatanodeException(nodeReg, message);\n       }\n       // update node registration with the ip and hostname from rpc request\n       nodeReg.setIpAddr(ip);\n       nodeReg.setPeerHostName(hostname);\n     }\n     \n     try {\n       nodeReg.setExportedKeys(blockManager.getBlockKeys());\n   \n       // Checks if the node is not on the hosts list.  If it is not, then\n       // it will be disallowed from registering. \n       if (!hostFileManager.isIncluded(nodeReg)) {\n         throw new DisallowedDatanodeException(nodeReg);\n       }\n         \n       NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n           + nodeReg + \" storage \" + nodeReg.getDatanodeUuid());\n   \n       DatanodeDescriptor nodeS \u003d getDatanode(nodeReg.getDatanodeUuid());\n       DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n           nodeReg.getIpAddr(), nodeReg.getXferPort());\n         \n       if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n         NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n         // nodeN previously served a different data storage, \n         // which is not served by anybody anymore.\n         removeDatanode(nodeN);\n         // physically remove node from datanodeMap\n         wipeDatanode(nodeN);\n         nodeN \u003d null;\n       }\n   \n       if (nodeS !\u003d null) {\n         if (nodeN \u003d\u003d nodeS) {\n           // The same datanode has been just restarted to serve the same data \n           // storage. We do not need to remove old data blocks, the delta will\n           // be calculated on the next block report from the datanode\n           if(NameNode.stateChangeLog.isDebugEnabled()) {\n             NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n                 + \"node restarted.\");\n           }\n         } else {\n           // nodeS is found\n           /* The registering datanode is a replacement node for the existing \n             data storage, which from now on will be served by a new node.\n             If this message repeats, both nodes might have same storageID \n             by (insanely rare) random chance. User needs to restart one of the\n             nodes with its data cleared (or user can just remove the StorageID\n             value in \"VERSION\" file under the data directory of the datanode,\n             but this is might not work if VERSION file format has changed \n          */        \n           NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n               + \" is replaced by \" + nodeReg + \" with the same storageID \"\n               + nodeReg.getDatanodeUuid());\n         }\n         \n         boolean success \u003d false;\n         try {\n           // update cluster map\n           getNetworkTopology().remove(nodeS);\n           if(shouldCountVersion(nodeS)) {\n             decrementVersionCount(nodeS.getSoftwareVersion());\n           }\n           nodeS.updateRegInfo(nodeReg);\n \n           nodeS.setSoftwareVersion(nodeReg.getSoftwareVersion());\n           nodeS.setDisallowed(false); // Node is in the include list\n \n           // resolve network location\n           if(this.rejectUnresolvedTopologyDN) {\n             nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));\n             nodeS.setDependentHostNames(getNetworkDependencies(nodeS));\n           } else {\n             nodeS.setNetworkLocation(\n                 resolveNetworkLocationWithFallBackToDefaultLocation(nodeS));\n             nodeS.setDependentHostNames(\n                 getNetworkDependenciesWithDefault(nodeS));\n           }\n           getNetworkTopology().add(nodeS);\n             \n           // also treat the registration message as a heartbeat\n           heartbeatManager.register(nodeS);\n           incrementVersionCount(nodeS.getSoftwareVersion());\n           checkDecommissioning(nodeS);\n           success \u003d true;\n         } finally {\n           if (!success) {\n             removeDatanode(nodeS);\n             wipeDatanode(nodeS);\n             countSoftwareVersions();\n           }\n         }\n         return;\n       }\n \n       DatanodeDescriptor nodeDescr \n         \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n       boolean success \u003d false;\n       try {\n         // resolve network location\n         if(this.rejectUnresolvedTopologyDN) {\n           nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n           nodeDescr.setDependentHostNames(getNetworkDependencies(nodeDescr));\n         } else {\n           nodeDescr.setNetworkLocation(\n               resolveNetworkLocationWithFallBackToDefaultLocation(nodeDescr));\n           nodeDescr.setDependentHostNames(\n               getNetworkDependenciesWithDefault(nodeDescr));\n         }\n         networktopology.add(nodeDescr);\n         nodeDescr.setSoftwareVersion(nodeReg.getSoftwareVersion());\n   \n         // register new datanode\n         addDatanode(nodeDescr);\n-        checkDecommissioning(nodeDescr);\n-        \n         // also treat the registration message as a heartbeat\n         // no need to update its timestamp\n         // because its is done when the descriptor is created\n         heartbeatManager.addDatanode(nodeDescr);\n-        success \u003d true;\n         incrementVersionCount(nodeReg.getSoftwareVersion());\n+        checkDecommissioning(nodeDescr);\n+        success \u003d true;\n       } finally {\n         if (!success) {\n           removeDatanode(nodeDescr);\n           wipeDatanode(nodeDescr);\n           countSoftwareVersions();\n         }\n       }\n     } catch (InvalidTopologyException e) {\n       // If the network location is invalid, clear the cached mappings\n       // so that we have a chance to re-add this DataNode with the\n       // correct network location later.\n       List\u003cString\u003e invalidNodeNames \u003d new ArrayList\u003cString\u003e(3);\n       // clear cache for nodes in IP or Hostname\n       invalidNodeNames.add(nodeReg.getIpAddr());\n       invalidNodeNames.add(nodeReg.getHostName());\n       invalidNodeNames.add(nodeReg.getPeerHostName());\n       dnsToSwitchMapping.reloadCachedMappings(invalidNodeNames);\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void registerDatanode(DatanodeRegistration nodeReg)\n      throws DisallowedDatanodeException, UnresolvedTopologyException {\n    InetAddress dnAddress \u003d Server.getRemoteIp();\n    if (dnAddress !\u003d null) {\n      // Mostly called inside an RPC, update ip and peer hostname\n      String hostname \u003d dnAddress.getHostName();\n      String ip \u003d dnAddress.getHostAddress();\n      if (checkIpHostnameInRegistration \u0026\u0026 !isNameResolved(dnAddress)) {\n        // Reject registration of unresolved datanode to prevent performance\n        // impact of repetitive DNS lookups later.\n        final String message \u003d \"hostname cannot be resolved (ip\u003d\"\n            + ip + \", hostname\u003d\" + hostname + \")\";\n        LOG.warn(\"Unresolved datanode registration: \" + message);\n        throw new DisallowedDatanodeException(nodeReg, message);\n      }\n      // update node registration with the ip and hostname from rpc request\n      nodeReg.setIpAddr(ip);\n      nodeReg.setPeerHostName(hostname);\n    }\n    \n    try {\n      nodeReg.setExportedKeys(blockManager.getBlockKeys());\n  \n      // Checks if the node is not on the hosts list.  If it is not, then\n      // it will be disallowed from registering. \n      if (!hostFileManager.isIncluded(nodeReg)) {\n        throw new DisallowedDatanodeException(nodeReg);\n      }\n        \n      NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n          + nodeReg + \" storage \" + nodeReg.getDatanodeUuid());\n  \n      DatanodeDescriptor nodeS \u003d getDatanode(nodeReg.getDatanodeUuid());\n      DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n          nodeReg.getIpAddr(), nodeReg.getXferPort());\n        \n      if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n        NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n        // nodeN previously served a different data storage, \n        // which is not served by anybody anymore.\n        removeDatanode(nodeN);\n        // physically remove node from datanodeMap\n        wipeDatanode(nodeN);\n        nodeN \u003d null;\n      }\n  \n      if (nodeS !\u003d null) {\n        if (nodeN \u003d\u003d nodeS) {\n          // The same datanode has been just restarted to serve the same data \n          // storage. We do not need to remove old data blocks, the delta will\n          // be calculated on the next block report from the datanode\n          if(NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n                + \"node restarted.\");\n          }\n        } else {\n          // nodeS is found\n          /* The registering datanode is a replacement node for the existing \n            data storage, which from now on will be served by a new node.\n            If this message repeats, both nodes might have same storageID \n            by (insanely rare) random chance. User needs to restart one of the\n            nodes with its data cleared (or user can just remove the StorageID\n            value in \"VERSION\" file under the data directory of the datanode,\n            but this is might not work if VERSION file format has changed \n         */        \n          NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n              + \" is replaced by \" + nodeReg + \" with the same storageID \"\n              + nodeReg.getDatanodeUuid());\n        }\n        \n        boolean success \u003d false;\n        try {\n          // update cluster map\n          getNetworkTopology().remove(nodeS);\n          if(shouldCountVersion(nodeS)) {\n            decrementVersionCount(nodeS.getSoftwareVersion());\n          }\n          nodeS.updateRegInfo(nodeReg);\n\n          nodeS.setSoftwareVersion(nodeReg.getSoftwareVersion());\n          nodeS.setDisallowed(false); // Node is in the include list\n\n          // resolve network location\n          if(this.rejectUnresolvedTopologyDN) {\n            nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));\n            nodeS.setDependentHostNames(getNetworkDependencies(nodeS));\n          } else {\n            nodeS.setNetworkLocation(\n                resolveNetworkLocationWithFallBackToDefaultLocation(nodeS));\n            nodeS.setDependentHostNames(\n                getNetworkDependenciesWithDefault(nodeS));\n          }\n          getNetworkTopology().add(nodeS);\n            \n          // also treat the registration message as a heartbeat\n          heartbeatManager.register(nodeS);\n          incrementVersionCount(nodeS.getSoftwareVersion());\n          checkDecommissioning(nodeS);\n          success \u003d true;\n        } finally {\n          if (!success) {\n            removeDatanode(nodeS);\n            wipeDatanode(nodeS);\n            countSoftwareVersions();\n          }\n        }\n        return;\n      }\n\n      DatanodeDescriptor nodeDescr \n        \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n      boolean success \u003d false;\n      try {\n        // resolve network location\n        if(this.rejectUnresolvedTopologyDN) {\n          nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n          nodeDescr.setDependentHostNames(getNetworkDependencies(nodeDescr));\n        } else {\n          nodeDescr.setNetworkLocation(\n              resolveNetworkLocationWithFallBackToDefaultLocation(nodeDescr));\n          nodeDescr.setDependentHostNames(\n              getNetworkDependenciesWithDefault(nodeDescr));\n        }\n        networktopology.add(nodeDescr);\n        nodeDescr.setSoftwareVersion(nodeReg.getSoftwareVersion());\n  \n        // register new datanode\n        addDatanode(nodeDescr);\n        // also treat the registration message as a heartbeat\n        // no need to update its timestamp\n        // because its is done when the descriptor is created\n        heartbeatManager.addDatanode(nodeDescr);\n        incrementVersionCount(nodeReg.getSoftwareVersion());\n        checkDecommissioning(nodeDescr);\n        success \u003d true;\n      } finally {\n        if (!success) {\n          removeDatanode(nodeDescr);\n          wipeDatanode(nodeDescr);\n          countSoftwareVersions();\n        }\n      }\n    } catch (InvalidTopologyException e) {\n      // If the network location is invalid, clear the cached mappings\n      // so that we have a chance to re-add this DataNode with the\n      // correct network location later.\n      List\u003cString\u003e invalidNodeNames \u003d new ArrayList\u003cString\u003e(3);\n      // clear cache for nodes in IP or Hostname\n      invalidNodeNames.add(nodeReg.getIpAddr());\n      invalidNodeNames.add(nodeReg.getHostName());\n      invalidNodeNames.add(nodeReg.getPeerHostName());\n      dnsToSwitchMapping.reloadCachedMappings(invalidNodeNames);\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "b2f65c276da2c4420a0974a7e2d75e081abf5d63": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5168. Add cross node dependency support to BlockPlacementPolicy.  Contributed by Nikola Vujic\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1592179 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "03/05/14 4:02 AM",
      "commitName": "b2f65c276da2c4420a0974a7e2d75e081abf5d63",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "24/04/14 12:24 AM",
      "commitNameOld": "24d1cf9ac681fadaf2a3614a24b06327d5d5f53e",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 9.15,
      "commitsBetweenForRepo": 44,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,151 +1,156 @@\n   public void registerDatanode(DatanodeRegistration nodeReg)\n       throws DisallowedDatanodeException, UnresolvedTopologyException {\n     InetAddress dnAddress \u003d Server.getRemoteIp();\n     if (dnAddress !\u003d null) {\n       // Mostly called inside an RPC, update ip and peer hostname\n       String hostname \u003d dnAddress.getHostName();\n       String ip \u003d dnAddress.getHostAddress();\n       if (checkIpHostnameInRegistration \u0026\u0026 !isNameResolved(dnAddress)) {\n         // Reject registration of unresolved datanode to prevent performance\n         // impact of repetitive DNS lookups later.\n         final String message \u003d \"hostname cannot be resolved (ip\u003d\"\n             + ip + \", hostname\u003d\" + hostname + \")\";\n         LOG.warn(\"Unresolved datanode registration: \" + message);\n         throw new DisallowedDatanodeException(nodeReg, message);\n       }\n       // update node registration with the ip and hostname from rpc request\n       nodeReg.setIpAddr(ip);\n       nodeReg.setPeerHostName(hostname);\n     }\n     \n     try {\n       nodeReg.setExportedKeys(blockManager.getBlockKeys());\n   \n       // Checks if the node is not on the hosts list.  If it is not, then\n       // it will be disallowed from registering. \n       if (!hostFileManager.isIncluded(nodeReg)) {\n         throw new DisallowedDatanodeException(nodeReg);\n       }\n         \n       NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n           + nodeReg + \" storage \" + nodeReg.getDatanodeUuid());\n   \n       DatanodeDescriptor nodeS \u003d getDatanode(nodeReg.getDatanodeUuid());\n       DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n           nodeReg.getIpAddr(), nodeReg.getXferPort());\n         \n       if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n         NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n         // nodeN previously served a different data storage, \n         // which is not served by anybody anymore.\n         removeDatanode(nodeN);\n         // physically remove node from datanodeMap\n         wipeDatanode(nodeN);\n         nodeN \u003d null;\n       }\n   \n       if (nodeS !\u003d null) {\n         if (nodeN \u003d\u003d nodeS) {\n           // The same datanode has been just restarted to serve the same data \n           // storage. We do not need to remove old data blocks, the delta will\n           // be calculated on the next block report from the datanode\n           if(NameNode.stateChangeLog.isDebugEnabled()) {\n             NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n                 + \"node restarted.\");\n           }\n         } else {\n           // nodeS is found\n           /* The registering datanode is a replacement node for the existing \n             data storage, which from now on will be served by a new node.\n             If this message repeats, both nodes might have same storageID \n             by (insanely rare) random chance. User needs to restart one of the\n             nodes with its data cleared (or user can just remove the StorageID\n             value in \"VERSION\" file under the data directory of the datanode,\n             but this is might not work if VERSION file format has changed \n          */        \n           NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n               + \" is replaced by \" + nodeReg + \" with the same storageID \"\n               + nodeReg.getDatanodeUuid());\n         }\n         \n         boolean success \u003d false;\n         try {\n           // update cluster map\n           getNetworkTopology().remove(nodeS);\n           if(shouldCountVersion(nodeS)) {\n             decrementVersionCount(nodeS.getSoftwareVersion());\n           }\n           nodeS.updateRegInfo(nodeReg);\n \n           nodeS.setSoftwareVersion(nodeReg.getSoftwareVersion());\n           nodeS.setDisallowed(false); // Node is in the include list\n \n           // resolve network location\n-          if(this.rejectUnresolvedTopologyDN)\n-          {\n-            nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));  \n+          if(this.rejectUnresolvedTopologyDN) {\n+            nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));\n+            nodeS.setDependentHostNames(getNetworkDependencies(nodeS));\n           } else {\n             nodeS.setNetworkLocation(\n                 resolveNetworkLocationWithFallBackToDefaultLocation(nodeS));\n+            nodeS.setDependentHostNames(\n+                getNetworkDependenciesWithDefault(nodeS));\n           }\n           getNetworkTopology().add(nodeS);\n             \n           // also treat the registration message as a heartbeat\n           heartbeatManager.register(nodeS);\n           incrementVersionCount(nodeS.getSoftwareVersion());\n           checkDecommissioning(nodeS);\n           success \u003d true;\n         } finally {\n           if (!success) {\n             removeDatanode(nodeS);\n             wipeDatanode(nodeS);\n             countSoftwareVersions();\n           }\n         }\n         return;\n       }\n \n       DatanodeDescriptor nodeDescr \n         \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n       boolean success \u003d false;\n       try {\n         // resolve network location\n         if(this.rejectUnresolvedTopologyDN) {\n           nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n+          nodeDescr.setDependentHostNames(getNetworkDependencies(nodeDescr));\n         } else {\n           nodeDescr.setNetworkLocation(\n               resolveNetworkLocationWithFallBackToDefaultLocation(nodeDescr));\n+          nodeDescr.setDependentHostNames(\n+              getNetworkDependenciesWithDefault(nodeDescr));\n         }\n         networktopology.add(nodeDescr);\n         nodeDescr.setSoftwareVersion(nodeReg.getSoftwareVersion());\n   \n         // register new datanode\n         addDatanode(nodeDescr);\n         checkDecommissioning(nodeDescr);\n         \n         // also treat the registration message as a heartbeat\n         // no need to update its timestamp\n         // because its is done when the descriptor is created\n         heartbeatManager.addDatanode(nodeDescr);\n         success \u003d true;\n         incrementVersionCount(nodeReg.getSoftwareVersion());\n       } finally {\n         if (!success) {\n           removeDatanode(nodeDescr);\n           wipeDatanode(nodeDescr);\n           countSoftwareVersions();\n         }\n       }\n     } catch (InvalidTopologyException e) {\n       // If the network location is invalid, clear the cached mappings\n       // so that we have a chance to re-add this DataNode with the\n       // correct network location later.\n       List\u003cString\u003e invalidNodeNames \u003d new ArrayList\u003cString\u003e(3);\n       // clear cache for nodes in IP or Hostname\n       invalidNodeNames.add(nodeReg.getIpAddr());\n       invalidNodeNames.add(nodeReg.getHostName());\n       invalidNodeNames.add(nodeReg.getPeerHostName());\n       dnsToSwitchMapping.reloadCachedMappings(invalidNodeNames);\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void registerDatanode(DatanodeRegistration nodeReg)\n      throws DisallowedDatanodeException, UnresolvedTopologyException {\n    InetAddress dnAddress \u003d Server.getRemoteIp();\n    if (dnAddress !\u003d null) {\n      // Mostly called inside an RPC, update ip and peer hostname\n      String hostname \u003d dnAddress.getHostName();\n      String ip \u003d dnAddress.getHostAddress();\n      if (checkIpHostnameInRegistration \u0026\u0026 !isNameResolved(dnAddress)) {\n        // Reject registration of unresolved datanode to prevent performance\n        // impact of repetitive DNS lookups later.\n        final String message \u003d \"hostname cannot be resolved (ip\u003d\"\n            + ip + \", hostname\u003d\" + hostname + \")\";\n        LOG.warn(\"Unresolved datanode registration: \" + message);\n        throw new DisallowedDatanodeException(nodeReg, message);\n      }\n      // update node registration with the ip and hostname from rpc request\n      nodeReg.setIpAddr(ip);\n      nodeReg.setPeerHostName(hostname);\n    }\n    \n    try {\n      nodeReg.setExportedKeys(blockManager.getBlockKeys());\n  \n      // Checks if the node is not on the hosts list.  If it is not, then\n      // it will be disallowed from registering. \n      if (!hostFileManager.isIncluded(nodeReg)) {\n        throw new DisallowedDatanodeException(nodeReg);\n      }\n        \n      NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n          + nodeReg + \" storage \" + nodeReg.getDatanodeUuid());\n  \n      DatanodeDescriptor nodeS \u003d getDatanode(nodeReg.getDatanodeUuid());\n      DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n          nodeReg.getIpAddr(), nodeReg.getXferPort());\n        \n      if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n        NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n        // nodeN previously served a different data storage, \n        // which is not served by anybody anymore.\n        removeDatanode(nodeN);\n        // physically remove node from datanodeMap\n        wipeDatanode(nodeN);\n        nodeN \u003d null;\n      }\n  \n      if (nodeS !\u003d null) {\n        if (nodeN \u003d\u003d nodeS) {\n          // The same datanode has been just restarted to serve the same data \n          // storage. We do not need to remove old data blocks, the delta will\n          // be calculated on the next block report from the datanode\n          if(NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n                + \"node restarted.\");\n          }\n        } else {\n          // nodeS is found\n          /* The registering datanode is a replacement node for the existing \n            data storage, which from now on will be served by a new node.\n            If this message repeats, both nodes might have same storageID \n            by (insanely rare) random chance. User needs to restart one of the\n            nodes with its data cleared (or user can just remove the StorageID\n            value in \"VERSION\" file under the data directory of the datanode,\n            but this is might not work if VERSION file format has changed \n         */        \n          NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n              + \" is replaced by \" + nodeReg + \" with the same storageID \"\n              + nodeReg.getDatanodeUuid());\n        }\n        \n        boolean success \u003d false;\n        try {\n          // update cluster map\n          getNetworkTopology().remove(nodeS);\n          if(shouldCountVersion(nodeS)) {\n            decrementVersionCount(nodeS.getSoftwareVersion());\n          }\n          nodeS.updateRegInfo(nodeReg);\n\n          nodeS.setSoftwareVersion(nodeReg.getSoftwareVersion());\n          nodeS.setDisallowed(false); // Node is in the include list\n\n          // resolve network location\n          if(this.rejectUnresolvedTopologyDN) {\n            nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));\n            nodeS.setDependentHostNames(getNetworkDependencies(nodeS));\n          } else {\n            nodeS.setNetworkLocation(\n                resolveNetworkLocationWithFallBackToDefaultLocation(nodeS));\n            nodeS.setDependentHostNames(\n                getNetworkDependenciesWithDefault(nodeS));\n          }\n          getNetworkTopology().add(nodeS);\n            \n          // also treat the registration message as a heartbeat\n          heartbeatManager.register(nodeS);\n          incrementVersionCount(nodeS.getSoftwareVersion());\n          checkDecommissioning(nodeS);\n          success \u003d true;\n        } finally {\n          if (!success) {\n            removeDatanode(nodeS);\n            wipeDatanode(nodeS);\n            countSoftwareVersions();\n          }\n        }\n        return;\n      }\n\n      DatanodeDescriptor nodeDescr \n        \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n      boolean success \u003d false;\n      try {\n        // resolve network location\n        if(this.rejectUnresolvedTopologyDN) {\n          nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n          nodeDescr.setDependentHostNames(getNetworkDependencies(nodeDescr));\n        } else {\n          nodeDescr.setNetworkLocation(\n              resolveNetworkLocationWithFallBackToDefaultLocation(nodeDescr));\n          nodeDescr.setDependentHostNames(\n              getNetworkDependenciesWithDefault(nodeDescr));\n        }\n        networktopology.add(nodeDescr);\n        nodeDescr.setSoftwareVersion(nodeReg.getSoftwareVersion());\n  \n        // register new datanode\n        addDatanode(nodeDescr);\n        checkDecommissioning(nodeDescr);\n        \n        // also treat the registration message as a heartbeat\n        // no need to update its timestamp\n        // because its is done when the descriptor is created\n        heartbeatManager.addDatanode(nodeDescr);\n        success \u003d true;\n        incrementVersionCount(nodeReg.getSoftwareVersion());\n      } finally {\n        if (!success) {\n          removeDatanode(nodeDescr);\n          wipeDatanode(nodeDescr);\n          countSoftwareVersions();\n        }\n      }\n    } catch (InvalidTopologyException e) {\n      // If the network location is invalid, clear the cached mappings\n      // so that we have a chance to re-add this DataNode with the\n      // correct network location later.\n      List\u003cString\u003e invalidNodeNames \u003d new ArrayList\u003cString\u003e(3);\n      // clear cache for nodes in IP or Hostname\n      invalidNodeNames.add(nodeReg.getIpAddr());\n      invalidNodeNames.add(nodeReg.getHostName());\n      invalidNodeNames.add(nodeReg.getPeerHostName());\n      dnsToSwitchMapping.reloadCachedMappings(invalidNodeNames);\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "328fc86bdbf84fcc80a0920b2cacfc2e74ac5c9f": {
      "type": "Ymultichange(Yexceptionschange,Ybodychange)",
      "commitMessage": "HDFS-5846. Shuffle phase is slow in Windows - FadviseFileRegion::transferTo does not read disks efficiently. Contributed by Nikola Vujic.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1581091 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/03/14 3:16 PM",
      "commitName": "328fc86bdbf84fcc80a0920b2cacfc2e74ac5c9f",
      "commitAuthor": "Chris Nauroth",
      "subchanges": [
        {
          "type": "Yexceptionschange",
          "commitMessage": "HDFS-5846. Shuffle phase is slow in Windows - FadviseFileRegion::transferTo does not read disks efficiently. Contributed by Nikola Vujic.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1581091 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "24/03/14 3:16 PM",
          "commitName": "328fc86bdbf84fcc80a0920b2cacfc2e74ac5c9f",
          "commitAuthor": "Chris Nauroth",
          "commitDateOld": "24/03/14 8:39 AM",
          "commitNameOld": "7a18c4a1992aefc6f5cac4e0fb6931e0e3efdd1c",
          "commitAuthorOld": "Kihwal Lee",
          "daysBetweenCommits": 0.28,
          "commitsBetweenForRepo": 9,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,139 +1,151 @@\n   public void registerDatanode(DatanodeRegistration nodeReg)\n-      throws DisallowedDatanodeException {\n+      throws DisallowedDatanodeException, UnresolvedTopologyException {\n     InetAddress dnAddress \u003d Server.getRemoteIp();\n     if (dnAddress !\u003d null) {\n       // Mostly called inside an RPC, update ip and peer hostname\n       String hostname \u003d dnAddress.getHostName();\n       String ip \u003d dnAddress.getHostAddress();\n       if (checkIpHostnameInRegistration \u0026\u0026 !isNameResolved(dnAddress)) {\n         // Reject registration of unresolved datanode to prevent performance\n         // impact of repetitive DNS lookups later.\n         final String message \u003d \"hostname cannot be resolved (ip\u003d\"\n             + ip + \", hostname\u003d\" + hostname + \")\";\n         LOG.warn(\"Unresolved datanode registration: \" + message);\n         throw new DisallowedDatanodeException(nodeReg, message);\n       }\n       // update node registration with the ip and hostname from rpc request\n       nodeReg.setIpAddr(ip);\n       nodeReg.setPeerHostName(hostname);\n     }\n     \n     try {\n       nodeReg.setExportedKeys(blockManager.getBlockKeys());\n   \n       // Checks if the node is not on the hosts list.  If it is not, then\n       // it will be disallowed from registering. \n       if (!hostFileManager.isIncluded(nodeReg)) {\n         throw new DisallowedDatanodeException(nodeReg);\n       }\n         \n       NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n           + nodeReg + \" storage \" + nodeReg.getDatanodeUuid());\n   \n       DatanodeDescriptor nodeS \u003d getDatanode(nodeReg.getDatanodeUuid());\n       DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n           nodeReg.getIpAddr(), nodeReg.getXferPort());\n         \n       if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n         NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n         // nodeN previously served a different data storage, \n         // which is not served by anybody anymore.\n         removeDatanode(nodeN);\n         // physically remove node from datanodeMap\n         wipeDatanode(nodeN);\n         nodeN \u003d null;\n       }\n   \n       if (nodeS !\u003d null) {\n         if (nodeN \u003d\u003d nodeS) {\n           // The same datanode has been just restarted to serve the same data \n           // storage. We do not need to remove old data blocks, the delta will\n           // be calculated on the next block report from the datanode\n           if(NameNode.stateChangeLog.isDebugEnabled()) {\n             NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n                 + \"node restarted.\");\n           }\n         } else {\n           // nodeS is found\n           /* The registering datanode is a replacement node for the existing \n             data storage, which from now on will be served by a new node.\n             If this message repeats, both nodes might have same storageID \n             by (insanely rare) random chance. User needs to restart one of the\n             nodes with its data cleared (or user can just remove the StorageID\n             value in \"VERSION\" file under the data directory of the datanode,\n             but this is might not work if VERSION file format has changed \n          */        \n           NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n               + \" is replaced by \" + nodeReg + \" with the same storageID \"\n               + nodeReg.getDatanodeUuid());\n         }\n         \n         boolean success \u003d false;\n         try {\n           // update cluster map\n           getNetworkTopology().remove(nodeS);\n           if(shouldCountVersion(nodeS)) {\n             decrementVersionCount(nodeS.getSoftwareVersion());\n           }\n           nodeS.updateRegInfo(nodeReg);\n \n           nodeS.setSoftwareVersion(nodeReg.getSoftwareVersion());\n           nodeS.setDisallowed(false); // Node is in the include list\n \n           // resolve network location\n-          nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));\n+          if(this.rejectUnresolvedTopologyDN)\n+          {\n+            nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));  \n+          } else {\n+            nodeS.setNetworkLocation(\n+                resolveNetworkLocationWithFallBackToDefaultLocation(nodeS));\n+          }\n           getNetworkTopology().add(nodeS);\n             \n           // also treat the registration message as a heartbeat\n           heartbeatManager.register(nodeS);\n           incrementVersionCount(nodeS.getSoftwareVersion());\n           checkDecommissioning(nodeS);\n           success \u003d true;\n         } finally {\n           if (!success) {\n             removeDatanode(nodeS);\n             wipeDatanode(nodeS);\n             countSoftwareVersions();\n           }\n         }\n         return;\n       }\n \n       DatanodeDescriptor nodeDescr \n         \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n       boolean success \u003d false;\n       try {\n-        nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n+        // resolve network location\n+        if(this.rejectUnresolvedTopologyDN) {\n+          nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n+        } else {\n+          nodeDescr.setNetworkLocation(\n+              resolveNetworkLocationWithFallBackToDefaultLocation(nodeDescr));\n+        }\n         networktopology.add(nodeDescr);\n         nodeDescr.setSoftwareVersion(nodeReg.getSoftwareVersion());\n   \n         // register new datanode\n         addDatanode(nodeDescr);\n         checkDecommissioning(nodeDescr);\n         \n         // also treat the registration message as a heartbeat\n         // no need to update its timestamp\n         // because its is done when the descriptor is created\n         heartbeatManager.addDatanode(nodeDescr);\n         success \u003d true;\n         incrementVersionCount(nodeReg.getSoftwareVersion());\n       } finally {\n         if (!success) {\n           removeDatanode(nodeDescr);\n           wipeDatanode(nodeDescr);\n           countSoftwareVersions();\n         }\n       }\n     } catch (InvalidTopologyException e) {\n       // If the network location is invalid, clear the cached mappings\n       // so that we have a chance to re-add this DataNode with the\n       // correct network location later.\n       List\u003cString\u003e invalidNodeNames \u003d new ArrayList\u003cString\u003e(3);\n       // clear cache for nodes in IP or Hostname\n       invalidNodeNames.add(nodeReg.getIpAddr());\n       invalidNodeNames.add(nodeReg.getHostName());\n       invalidNodeNames.add(nodeReg.getPeerHostName());\n       dnsToSwitchMapping.reloadCachedMappings(invalidNodeNames);\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void registerDatanode(DatanodeRegistration nodeReg)\n      throws DisallowedDatanodeException, UnresolvedTopologyException {\n    InetAddress dnAddress \u003d Server.getRemoteIp();\n    if (dnAddress !\u003d null) {\n      // Mostly called inside an RPC, update ip and peer hostname\n      String hostname \u003d dnAddress.getHostName();\n      String ip \u003d dnAddress.getHostAddress();\n      if (checkIpHostnameInRegistration \u0026\u0026 !isNameResolved(dnAddress)) {\n        // Reject registration of unresolved datanode to prevent performance\n        // impact of repetitive DNS lookups later.\n        final String message \u003d \"hostname cannot be resolved (ip\u003d\"\n            + ip + \", hostname\u003d\" + hostname + \")\";\n        LOG.warn(\"Unresolved datanode registration: \" + message);\n        throw new DisallowedDatanodeException(nodeReg, message);\n      }\n      // update node registration with the ip and hostname from rpc request\n      nodeReg.setIpAddr(ip);\n      nodeReg.setPeerHostName(hostname);\n    }\n    \n    try {\n      nodeReg.setExportedKeys(blockManager.getBlockKeys());\n  \n      // Checks if the node is not on the hosts list.  If it is not, then\n      // it will be disallowed from registering. \n      if (!hostFileManager.isIncluded(nodeReg)) {\n        throw new DisallowedDatanodeException(nodeReg);\n      }\n        \n      NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n          + nodeReg + \" storage \" + nodeReg.getDatanodeUuid());\n  \n      DatanodeDescriptor nodeS \u003d getDatanode(nodeReg.getDatanodeUuid());\n      DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n          nodeReg.getIpAddr(), nodeReg.getXferPort());\n        \n      if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n        NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n        // nodeN previously served a different data storage, \n        // which is not served by anybody anymore.\n        removeDatanode(nodeN);\n        // physically remove node from datanodeMap\n        wipeDatanode(nodeN);\n        nodeN \u003d null;\n      }\n  \n      if (nodeS !\u003d null) {\n        if (nodeN \u003d\u003d nodeS) {\n          // The same datanode has been just restarted to serve the same data \n          // storage. We do not need to remove old data blocks, the delta will\n          // be calculated on the next block report from the datanode\n          if(NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n                + \"node restarted.\");\n          }\n        } else {\n          // nodeS is found\n          /* The registering datanode is a replacement node for the existing \n            data storage, which from now on will be served by a new node.\n            If this message repeats, both nodes might have same storageID \n            by (insanely rare) random chance. User needs to restart one of the\n            nodes with its data cleared (or user can just remove the StorageID\n            value in \"VERSION\" file under the data directory of the datanode,\n            but this is might not work if VERSION file format has changed \n         */        \n          NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n              + \" is replaced by \" + nodeReg + \" with the same storageID \"\n              + nodeReg.getDatanodeUuid());\n        }\n        \n        boolean success \u003d false;\n        try {\n          // update cluster map\n          getNetworkTopology().remove(nodeS);\n          if(shouldCountVersion(nodeS)) {\n            decrementVersionCount(nodeS.getSoftwareVersion());\n          }\n          nodeS.updateRegInfo(nodeReg);\n\n          nodeS.setSoftwareVersion(nodeReg.getSoftwareVersion());\n          nodeS.setDisallowed(false); // Node is in the include list\n\n          // resolve network location\n          if(this.rejectUnresolvedTopologyDN)\n          {\n            nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));  \n          } else {\n            nodeS.setNetworkLocation(\n                resolveNetworkLocationWithFallBackToDefaultLocation(nodeS));\n          }\n          getNetworkTopology().add(nodeS);\n            \n          // also treat the registration message as a heartbeat\n          heartbeatManager.register(nodeS);\n          incrementVersionCount(nodeS.getSoftwareVersion());\n          checkDecommissioning(nodeS);\n          success \u003d true;\n        } finally {\n          if (!success) {\n            removeDatanode(nodeS);\n            wipeDatanode(nodeS);\n            countSoftwareVersions();\n          }\n        }\n        return;\n      }\n\n      DatanodeDescriptor nodeDescr \n        \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n      boolean success \u003d false;\n      try {\n        // resolve network location\n        if(this.rejectUnresolvedTopologyDN) {\n          nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n        } else {\n          nodeDescr.setNetworkLocation(\n              resolveNetworkLocationWithFallBackToDefaultLocation(nodeDescr));\n        }\n        networktopology.add(nodeDescr);\n        nodeDescr.setSoftwareVersion(nodeReg.getSoftwareVersion());\n  \n        // register new datanode\n        addDatanode(nodeDescr);\n        checkDecommissioning(nodeDescr);\n        \n        // also treat the registration message as a heartbeat\n        // no need to update its timestamp\n        // because its is done when the descriptor is created\n        heartbeatManager.addDatanode(nodeDescr);\n        success \u003d true;\n        incrementVersionCount(nodeReg.getSoftwareVersion());\n      } finally {\n        if (!success) {\n          removeDatanode(nodeDescr);\n          wipeDatanode(nodeDescr);\n          countSoftwareVersions();\n        }\n      }\n    } catch (InvalidTopologyException e) {\n      // If the network location is invalid, clear the cached mappings\n      // so that we have a chance to re-add this DataNode with the\n      // correct network location later.\n      List\u003cString\u003e invalidNodeNames \u003d new ArrayList\u003cString\u003e(3);\n      // clear cache for nodes in IP or Hostname\n      invalidNodeNames.add(nodeReg.getIpAddr());\n      invalidNodeNames.add(nodeReg.getHostName());\n      invalidNodeNames.add(nodeReg.getPeerHostName());\n      dnsToSwitchMapping.reloadCachedMappings(invalidNodeNames);\n      throw e;\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
          "extendedDetails": {
            "oldValue": "[DisallowedDatanodeException]",
            "newValue": "[DisallowedDatanodeException, UnresolvedTopologyException]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5846. Shuffle phase is slow in Windows - FadviseFileRegion::transferTo does not read disks efficiently. Contributed by Nikola Vujic.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1581091 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "24/03/14 3:16 PM",
          "commitName": "328fc86bdbf84fcc80a0920b2cacfc2e74ac5c9f",
          "commitAuthor": "Chris Nauroth",
          "commitDateOld": "24/03/14 8:39 AM",
          "commitNameOld": "7a18c4a1992aefc6f5cac4e0fb6931e0e3efdd1c",
          "commitAuthorOld": "Kihwal Lee",
          "daysBetweenCommits": 0.28,
          "commitsBetweenForRepo": 9,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,139 +1,151 @@\n   public void registerDatanode(DatanodeRegistration nodeReg)\n-      throws DisallowedDatanodeException {\n+      throws DisallowedDatanodeException, UnresolvedTopologyException {\n     InetAddress dnAddress \u003d Server.getRemoteIp();\n     if (dnAddress !\u003d null) {\n       // Mostly called inside an RPC, update ip and peer hostname\n       String hostname \u003d dnAddress.getHostName();\n       String ip \u003d dnAddress.getHostAddress();\n       if (checkIpHostnameInRegistration \u0026\u0026 !isNameResolved(dnAddress)) {\n         // Reject registration of unresolved datanode to prevent performance\n         // impact of repetitive DNS lookups later.\n         final String message \u003d \"hostname cannot be resolved (ip\u003d\"\n             + ip + \", hostname\u003d\" + hostname + \")\";\n         LOG.warn(\"Unresolved datanode registration: \" + message);\n         throw new DisallowedDatanodeException(nodeReg, message);\n       }\n       // update node registration with the ip and hostname from rpc request\n       nodeReg.setIpAddr(ip);\n       nodeReg.setPeerHostName(hostname);\n     }\n     \n     try {\n       nodeReg.setExportedKeys(blockManager.getBlockKeys());\n   \n       // Checks if the node is not on the hosts list.  If it is not, then\n       // it will be disallowed from registering. \n       if (!hostFileManager.isIncluded(nodeReg)) {\n         throw new DisallowedDatanodeException(nodeReg);\n       }\n         \n       NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n           + nodeReg + \" storage \" + nodeReg.getDatanodeUuid());\n   \n       DatanodeDescriptor nodeS \u003d getDatanode(nodeReg.getDatanodeUuid());\n       DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n           nodeReg.getIpAddr(), nodeReg.getXferPort());\n         \n       if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n         NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n         // nodeN previously served a different data storage, \n         // which is not served by anybody anymore.\n         removeDatanode(nodeN);\n         // physically remove node from datanodeMap\n         wipeDatanode(nodeN);\n         nodeN \u003d null;\n       }\n   \n       if (nodeS !\u003d null) {\n         if (nodeN \u003d\u003d nodeS) {\n           // The same datanode has been just restarted to serve the same data \n           // storage. We do not need to remove old data blocks, the delta will\n           // be calculated on the next block report from the datanode\n           if(NameNode.stateChangeLog.isDebugEnabled()) {\n             NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n                 + \"node restarted.\");\n           }\n         } else {\n           // nodeS is found\n           /* The registering datanode is a replacement node for the existing \n             data storage, which from now on will be served by a new node.\n             If this message repeats, both nodes might have same storageID \n             by (insanely rare) random chance. User needs to restart one of the\n             nodes with its data cleared (or user can just remove the StorageID\n             value in \"VERSION\" file under the data directory of the datanode,\n             but this is might not work if VERSION file format has changed \n          */        \n           NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n               + \" is replaced by \" + nodeReg + \" with the same storageID \"\n               + nodeReg.getDatanodeUuid());\n         }\n         \n         boolean success \u003d false;\n         try {\n           // update cluster map\n           getNetworkTopology().remove(nodeS);\n           if(shouldCountVersion(nodeS)) {\n             decrementVersionCount(nodeS.getSoftwareVersion());\n           }\n           nodeS.updateRegInfo(nodeReg);\n \n           nodeS.setSoftwareVersion(nodeReg.getSoftwareVersion());\n           nodeS.setDisallowed(false); // Node is in the include list\n \n           // resolve network location\n-          nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));\n+          if(this.rejectUnresolvedTopologyDN)\n+          {\n+            nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));  \n+          } else {\n+            nodeS.setNetworkLocation(\n+                resolveNetworkLocationWithFallBackToDefaultLocation(nodeS));\n+          }\n           getNetworkTopology().add(nodeS);\n             \n           // also treat the registration message as a heartbeat\n           heartbeatManager.register(nodeS);\n           incrementVersionCount(nodeS.getSoftwareVersion());\n           checkDecommissioning(nodeS);\n           success \u003d true;\n         } finally {\n           if (!success) {\n             removeDatanode(nodeS);\n             wipeDatanode(nodeS);\n             countSoftwareVersions();\n           }\n         }\n         return;\n       }\n \n       DatanodeDescriptor nodeDescr \n         \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n       boolean success \u003d false;\n       try {\n-        nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n+        // resolve network location\n+        if(this.rejectUnresolvedTopologyDN) {\n+          nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n+        } else {\n+          nodeDescr.setNetworkLocation(\n+              resolveNetworkLocationWithFallBackToDefaultLocation(nodeDescr));\n+        }\n         networktopology.add(nodeDescr);\n         nodeDescr.setSoftwareVersion(nodeReg.getSoftwareVersion());\n   \n         // register new datanode\n         addDatanode(nodeDescr);\n         checkDecommissioning(nodeDescr);\n         \n         // also treat the registration message as a heartbeat\n         // no need to update its timestamp\n         // because its is done when the descriptor is created\n         heartbeatManager.addDatanode(nodeDescr);\n         success \u003d true;\n         incrementVersionCount(nodeReg.getSoftwareVersion());\n       } finally {\n         if (!success) {\n           removeDatanode(nodeDescr);\n           wipeDatanode(nodeDescr);\n           countSoftwareVersions();\n         }\n       }\n     } catch (InvalidTopologyException e) {\n       // If the network location is invalid, clear the cached mappings\n       // so that we have a chance to re-add this DataNode with the\n       // correct network location later.\n       List\u003cString\u003e invalidNodeNames \u003d new ArrayList\u003cString\u003e(3);\n       // clear cache for nodes in IP or Hostname\n       invalidNodeNames.add(nodeReg.getIpAddr());\n       invalidNodeNames.add(nodeReg.getHostName());\n       invalidNodeNames.add(nodeReg.getPeerHostName());\n       dnsToSwitchMapping.reloadCachedMappings(invalidNodeNames);\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void registerDatanode(DatanodeRegistration nodeReg)\n      throws DisallowedDatanodeException, UnresolvedTopologyException {\n    InetAddress dnAddress \u003d Server.getRemoteIp();\n    if (dnAddress !\u003d null) {\n      // Mostly called inside an RPC, update ip and peer hostname\n      String hostname \u003d dnAddress.getHostName();\n      String ip \u003d dnAddress.getHostAddress();\n      if (checkIpHostnameInRegistration \u0026\u0026 !isNameResolved(dnAddress)) {\n        // Reject registration of unresolved datanode to prevent performance\n        // impact of repetitive DNS lookups later.\n        final String message \u003d \"hostname cannot be resolved (ip\u003d\"\n            + ip + \", hostname\u003d\" + hostname + \")\";\n        LOG.warn(\"Unresolved datanode registration: \" + message);\n        throw new DisallowedDatanodeException(nodeReg, message);\n      }\n      // update node registration with the ip and hostname from rpc request\n      nodeReg.setIpAddr(ip);\n      nodeReg.setPeerHostName(hostname);\n    }\n    \n    try {\n      nodeReg.setExportedKeys(blockManager.getBlockKeys());\n  \n      // Checks if the node is not on the hosts list.  If it is not, then\n      // it will be disallowed from registering. \n      if (!hostFileManager.isIncluded(nodeReg)) {\n        throw new DisallowedDatanodeException(nodeReg);\n      }\n        \n      NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n          + nodeReg + \" storage \" + nodeReg.getDatanodeUuid());\n  \n      DatanodeDescriptor nodeS \u003d getDatanode(nodeReg.getDatanodeUuid());\n      DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n          nodeReg.getIpAddr(), nodeReg.getXferPort());\n        \n      if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n        NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n        // nodeN previously served a different data storage, \n        // which is not served by anybody anymore.\n        removeDatanode(nodeN);\n        // physically remove node from datanodeMap\n        wipeDatanode(nodeN);\n        nodeN \u003d null;\n      }\n  \n      if (nodeS !\u003d null) {\n        if (nodeN \u003d\u003d nodeS) {\n          // The same datanode has been just restarted to serve the same data \n          // storage. We do not need to remove old data blocks, the delta will\n          // be calculated on the next block report from the datanode\n          if(NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n                + \"node restarted.\");\n          }\n        } else {\n          // nodeS is found\n          /* The registering datanode is a replacement node for the existing \n            data storage, which from now on will be served by a new node.\n            If this message repeats, both nodes might have same storageID \n            by (insanely rare) random chance. User needs to restart one of the\n            nodes with its data cleared (or user can just remove the StorageID\n            value in \"VERSION\" file under the data directory of the datanode,\n            but this is might not work if VERSION file format has changed \n         */        \n          NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n              + \" is replaced by \" + nodeReg + \" with the same storageID \"\n              + nodeReg.getDatanodeUuid());\n        }\n        \n        boolean success \u003d false;\n        try {\n          // update cluster map\n          getNetworkTopology().remove(nodeS);\n          if(shouldCountVersion(nodeS)) {\n            decrementVersionCount(nodeS.getSoftwareVersion());\n          }\n          nodeS.updateRegInfo(nodeReg);\n\n          nodeS.setSoftwareVersion(nodeReg.getSoftwareVersion());\n          nodeS.setDisallowed(false); // Node is in the include list\n\n          // resolve network location\n          if(this.rejectUnresolvedTopologyDN)\n          {\n            nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));  \n          } else {\n            nodeS.setNetworkLocation(\n                resolveNetworkLocationWithFallBackToDefaultLocation(nodeS));\n          }\n          getNetworkTopology().add(nodeS);\n            \n          // also treat the registration message as a heartbeat\n          heartbeatManager.register(nodeS);\n          incrementVersionCount(nodeS.getSoftwareVersion());\n          checkDecommissioning(nodeS);\n          success \u003d true;\n        } finally {\n          if (!success) {\n            removeDatanode(nodeS);\n            wipeDatanode(nodeS);\n            countSoftwareVersions();\n          }\n        }\n        return;\n      }\n\n      DatanodeDescriptor nodeDescr \n        \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n      boolean success \u003d false;\n      try {\n        // resolve network location\n        if(this.rejectUnresolvedTopologyDN) {\n          nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n        } else {\n          nodeDescr.setNetworkLocation(\n              resolveNetworkLocationWithFallBackToDefaultLocation(nodeDescr));\n        }\n        networktopology.add(nodeDescr);\n        nodeDescr.setSoftwareVersion(nodeReg.getSoftwareVersion());\n  \n        // register new datanode\n        addDatanode(nodeDescr);\n        checkDecommissioning(nodeDescr);\n        \n        // also treat the registration message as a heartbeat\n        // no need to update its timestamp\n        // because its is done when the descriptor is created\n        heartbeatManager.addDatanode(nodeDescr);\n        success \u003d true;\n        incrementVersionCount(nodeReg.getSoftwareVersion());\n      } finally {\n        if (!success) {\n          removeDatanode(nodeDescr);\n          wipeDatanode(nodeDescr);\n          countSoftwareVersions();\n        }\n      }\n    } catch (InvalidTopologyException e) {\n      // If the network location is invalid, clear the cached mappings\n      // so that we have a chance to re-add this DataNode with the\n      // correct network location later.\n      List\u003cString\u003e invalidNodeNames \u003d new ArrayList\u003cString\u003e(3);\n      // clear cache for nodes in IP or Hostname\n      invalidNodeNames.add(nodeReg.getIpAddr());\n      invalidNodeNames.add(nodeReg.getHostName());\n      invalidNodeNames.add(nodeReg.getPeerHostName());\n      dnsToSwitchMapping.reloadCachedMappings(invalidNodeNames);\n      throw e;\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "9660bfa84c900afd4824feb62d14256584edfb95": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5448. Datanode should generate its ID on first registration\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2832@1538496 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "03/11/13 6:13 PM",
      "commitName": "9660bfa84c900afd4824feb62d14256584edfb95",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "29/10/13 2:04 PM",
      "commitNameOld": "c2495a7bff01df9660d50484cf3c15c1083a70d2",
      "commitAuthorOld": "",
      "daysBetweenCommits": 5.21,
      "commitsBetweenForRepo": 28,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,151 +1,139 @@\n   public void registerDatanode(DatanodeRegistration nodeReg)\n       throws DisallowedDatanodeException {\n     InetAddress dnAddress \u003d Server.getRemoteIp();\n     if (dnAddress !\u003d null) {\n       // Mostly called inside an RPC, update ip and peer hostname\n       String hostname \u003d dnAddress.getHostName();\n       String ip \u003d dnAddress.getHostAddress();\n       if (checkIpHostnameInRegistration \u0026\u0026 !isNameResolved(dnAddress)) {\n         // Reject registration of unresolved datanode to prevent performance\n         // impact of repetitive DNS lookups later.\n         final String message \u003d \"hostname cannot be resolved (ip\u003d\"\n             + ip + \", hostname\u003d\" + hostname + \")\";\n         LOG.warn(\"Unresolved datanode registration: \" + message);\n         throw new DisallowedDatanodeException(nodeReg, message);\n       }\n       // update node registration with the ip and hostname from rpc request\n       nodeReg.setIpAddr(ip);\n       nodeReg.setPeerHostName(hostname);\n     }\n     \n     try {\n       nodeReg.setExportedKeys(blockManager.getBlockKeys());\n   \n       // Checks if the node is not on the hosts list.  If it is not, then\n       // it will be disallowed from registering. \n       if (!hostFileManager.isIncluded(nodeReg)) {\n         throw new DisallowedDatanodeException(nodeReg);\n       }\n         \n       NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n           + nodeReg + \" storage \" + nodeReg.getDatanodeUuid());\n   \n       DatanodeDescriptor nodeS \u003d getDatanode(nodeReg.getDatanodeUuid());\n       DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n           nodeReg.getIpAddr(), nodeReg.getXferPort());\n         \n       if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n         NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n         // nodeN previously served a different data storage, \n         // which is not served by anybody anymore.\n         removeDatanode(nodeN);\n         // physically remove node from datanodeMap\n         wipeDatanode(nodeN);\n         nodeN \u003d null;\n       }\n   \n       if (nodeS !\u003d null) {\n         if (nodeN \u003d\u003d nodeS) {\n           // The same datanode has been just restarted to serve the same data \n           // storage. We do not need to remove old data blocks, the delta will\n           // be calculated on the next block report from the datanode\n           if(NameNode.stateChangeLog.isDebugEnabled()) {\n             NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n                 + \"node restarted.\");\n           }\n         } else {\n           // nodeS is found\n           /* The registering datanode is a replacement node for the existing \n             data storage, which from now on will be served by a new node.\n             If this message repeats, both nodes might have same storageID \n             by (insanely rare) random chance. User needs to restart one of the\n             nodes with its data cleared (or user can just remove the StorageID\n             value in \"VERSION\" file under the data directory of the datanode,\n             but this is might not work if VERSION file format has changed \n          */        \n           NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n               + \" is replaced by \" + nodeReg + \" with the same storageID \"\n               + nodeReg.getDatanodeUuid());\n         }\n         \n         boolean success \u003d false;\n         try {\n           // update cluster map\n           getNetworkTopology().remove(nodeS);\n           if(shouldCountVersion(nodeS)) {\n             decrementVersionCount(nodeS.getSoftwareVersion());\n           }\n           nodeS.updateRegInfo(nodeReg);\n \n           nodeS.setSoftwareVersion(nodeReg.getSoftwareVersion());\n           nodeS.setDisallowed(false); // Node is in the include list\n \n           // resolve network location\n           nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));\n           getNetworkTopology().add(nodeS);\n             \n           // also treat the registration message as a heartbeat\n           heartbeatManager.register(nodeS);\n           incrementVersionCount(nodeS.getSoftwareVersion());\n           checkDecommissioning(nodeS);\n           success \u003d true;\n         } finally {\n           if (!success) {\n             removeDatanode(nodeS);\n             wipeDatanode(nodeS);\n             countSoftwareVersions();\n           }\n         }\n         return;\n       }\n \n-      // This is a new datanode.\n-      if (nodeReg.getDatanodeUuid() \u003d\u003d null ||\n-          nodeReg.getDatanodeUuid().isEmpty()) {\n-        // this data node has never been registered\n-        nodeReg.generateNewDatanodeUuid();\n-        if (NameNode.stateChangeLog.isDebugEnabled()) {\n-          NameNode.stateChangeLog.debug(\n-              \"BLOCK* NameSystem.registerDatanode: \"\n-              + \"new Datanode UUID \" + nodeReg.getDatanodeUuid() + \" assigned.\");\n-        }\n-      }\n-      \n       DatanodeDescriptor nodeDescr \n         \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n       boolean success \u003d false;\n       try {\n         nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n         networktopology.add(nodeDescr);\n         nodeDescr.setSoftwareVersion(nodeReg.getSoftwareVersion());\n   \n         // register new datanode\n         addDatanode(nodeDescr);\n         checkDecommissioning(nodeDescr);\n         \n         // also treat the registration message as a heartbeat\n         // no need to update its timestamp\n         // because its is done when the descriptor is created\n         heartbeatManager.addDatanode(nodeDescr);\n         success \u003d true;\n         incrementVersionCount(nodeReg.getSoftwareVersion());\n       } finally {\n         if (!success) {\n           removeDatanode(nodeDescr);\n           wipeDatanode(nodeDescr);\n           countSoftwareVersions();\n         }\n       }\n     } catch (InvalidTopologyException e) {\n       // If the network location is invalid, clear the cached mappings\n       // so that we have a chance to re-add this DataNode with the\n       // correct network location later.\n       List\u003cString\u003e invalidNodeNames \u003d new ArrayList\u003cString\u003e(3);\n       // clear cache for nodes in IP or Hostname\n       invalidNodeNames.add(nodeReg.getIpAddr());\n       invalidNodeNames.add(nodeReg.getHostName());\n       invalidNodeNames.add(nodeReg.getPeerHostName());\n       dnsToSwitchMapping.reloadCachedMappings(invalidNodeNames);\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void registerDatanode(DatanodeRegistration nodeReg)\n      throws DisallowedDatanodeException {\n    InetAddress dnAddress \u003d Server.getRemoteIp();\n    if (dnAddress !\u003d null) {\n      // Mostly called inside an RPC, update ip and peer hostname\n      String hostname \u003d dnAddress.getHostName();\n      String ip \u003d dnAddress.getHostAddress();\n      if (checkIpHostnameInRegistration \u0026\u0026 !isNameResolved(dnAddress)) {\n        // Reject registration of unresolved datanode to prevent performance\n        // impact of repetitive DNS lookups later.\n        final String message \u003d \"hostname cannot be resolved (ip\u003d\"\n            + ip + \", hostname\u003d\" + hostname + \")\";\n        LOG.warn(\"Unresolved datanode registration: \" + message);\n        throw new DisallowedDatanodeException(nodeReg, message);\n      }\n      // update node registration with the ip and hostname from rpc request\n      nodeReg.setIpAddr(ip);\n      nodeReg.setPeerHostName(hostname);\n    }\n    \n    try {\n      nodeReg.setExportedKeys(blockManager.getBlockKeys());\n  \n      // Checks if the node is not on the hosts list.  If it is not, then\n      // it will be disallowed from registering. \n      if (!hostFileManager.isIncluded(nodeReg)) {\n        throw new DisallowedDatanodeException(nodeReg);\n      }\n        \n      NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n          + nodeReg + \" storage \" + nodeReg.getDatanodeUuid());\n  \n      DatanodeDescriptor nodeS \u003d getDatanode(nodeReg.getDatanodeUuid());\n      DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n          nodeReg.getIpAddr(), nodeReg.getXferPort());\n        \n      if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n        NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n        // nodeN previously served a different data storage, \n        // which is not served by anybody anymore.\n        removeDatanode(nodeN);\n        // physically remove node from datanodeMap\n        wipeDatanode(nodeN);\n        nodeN \u003d null;\n      }\n  \n      if (nodeS !\u003d null) {\n        if (nodeN \u003d\u003d nodeS) {\n          // The same datanode has been just restarted to serve the same data \n          // storage. We do not need to remove old data blocks, the delta will\n          // be calculated on the next block report from the datanode\n          if(NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n                + \"node restarted.\");\n          }\n        } else {\n          // nodeS is found\n          /* The registering datanode is a replacement node for the existing \n            data storage, which from now on will be served by a new node.\n            If this message repeats, both nodes might have same storageID \n            by (insanely rare) random chance. User needs to restart one of the\n            nodes with its data cleared (or user can just remove the StorageID\n            value in \"VERSION\" file under the data directory of the datanode,\n            but this is might not work if VERSION file format has changed \n         */        \n          NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n              + \" is replaced by \" + nodeReg + \" with the same storageID \"\n              + nodeReg.getDatanodeUuid());\n        }\n        \n        boolean success \u003d false;\n        try {\n          // update cluster map\n          getNetworkTopology().remove(nodeS);\n          if(shouldCountVersion(nodeS)) {\n            decrementVersionCount(nodeS.getSoftwareVersion());\n          }\n          nodeS.updateRegInfo(nodeReg);\n\n          nodeS.setSoftwareVersion(nodeReg.getSoftwareVersion());\n          nodeS.setDisallowed(false); // Node is in the include list\n\n          // resolve network location\n          nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));\n          getNetworkTopology().add(nodeS);\n            \n          // also treat the registration message as a heartbeat\n          heartbeatManager.register(nodeS);\n          incrementVersionCount(nodeS.getSoftwareVersion());\n          checkDecommissioning(nodeS);\n          success \u003d true;\n        } finally {\n          if (!success) {\n            removeDatanode(nodeS);\n            wipeDatanode(nodeS);\n            countSoftwareVersions();\n          }\n        }\n        return;\n      }\n\n      DatanodeDescriptor nodeDescr \n        \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n      boolean success \u003d false;\n      try {\n        nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n        networktopology.add(nodeDescr);\n        nodeDescr.setSoftwareVersion(nodeReg.getSoftwareVersion());\n  \n        // register new datanode\n        addDatanode(nodeDescr);\n        checkDecommissioning(nodeDescr);\n        \n        // also treat the registration message as a heartbeat\n        // no need to update its timestamp\n        // because its is done when the descriptor is created\n        heartbeatManager.addDatanode(nodeDescr);\n        success \u003d true;\n        incrementVersionCount(nodeReg.getSoftwareVersion());\n      } finally {\n        if (!success) {\n          removeDatanode(nodeDescr);\n          wipeDatanode(nodeDescr);\n          countSoftwareVersions();\n        }\n      }\n    } catch (InvalidTopologyException e) {\n      // If the network location is invalid, clear the cached mappings\n      // so that we have a chance to re-add this DataNode with the\n      // correct network location later.\n      List\u003cString\u003e invalidNodeNames \u003d new ArrayList\u003cString\u003e(3);\n      // clear cache for nodes in IP or Hostname\n      invalidNodeNames.add(nodeReg.getIpAddr());\n      invalidNodeNames.add(nodeReg.getHostName());\n      invalidNodeNames.add(nodeReg.getPeerHostName());\n      dnsToSwitchMapping.reloadCachedMappings(invalidNodeNames);\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "34f08944b7c8d58f531a3f3bf3d4ee4cd3fa643a": {
      "type": "Ybodychange",
      "commitMessage": "merge trunk to branch HDFS-4949\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1532952 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/10/13 7:14 PM",
      "commitName": "34f08944b7c8d58f531a3f3bf3d4ee4cd3fa643a",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "16/10/13 3:15 PM",
      "commitNameOld": "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 0.17,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,144 +1,151 @@\n   public void registerDatanode(DatanodeRegistration nodeReg)\n       throws DisallowedDatanodeException {\n     InetAddress dnAddress \u003d Server.getRemoteIp();\n     if (dnAddress !\u003d null) {\n       // Mostly called inside an RPC, update ip and peer hostname\n       String hostname \u003d dnAddress.getHostName();\n       String ip \u003d dnAddress.getHostAddress();\n-      if (!isNameResolved(dnAddress)) {\n+      if (checkIpHostnameInRegistration \u0026\u0026 !isNameResolved(dnAddress)) {\n         // Reject registration of unresolved datanode to prevent performance\n         // impact of repetitive DNS lookups later.\n-        LOG.warn(\"Unresolved datanode registration from \" + ip);\n-        throw new DisallowedDatanodeException(nodeReg);\n+        final String message \u003d \"hostname cannot be resolved (ip\u003d\"\n+            + ip + \", hostname\u003d\" + hostname + \")\";\n+        LOG.warn(\"Unresolved datanode registration: \" + message);\n+        throw new DisallowedDatanodeException(nodeReg, message);\n       }\n       // update node registration with the ip and hostname from rpc request\n       nodeReg.setIpAddr(ip);\n       nodeReg.setPeerHostName(hostname);\n     }\n     \n     try {\n       nodeReg.setExportedKeys(blockManager.getBlockKeys());\n   \n       // Checks if the node is not on the hosts list.  If it is not, then\n       // it will be disallowed from registering. \n       if (!hostFileManager.isIncluded(nodeReg)) {\n         throw new DisallowedDatanodeException(nodeReg);\n       }\n         \n       NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n           + nodeReg + \" storage \" + nodeReg.getStorageID());\n   \n       DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n       DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n           nodeReg.getIpAddr(), nodeReg.getXferPort());\n         \n       if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n         NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n         // nodeN previously served a different data storage, \n         // which is not served by anybody anymore.\n         removeDatanode(nodeN);\n         // physically remove node from datanodeMap\n         wipeDatanode(nodeN);\n         nodeN \u003d null;\n       }\n   \n       if (nodeS !\u003d null) {\n         if (nodeN \u003d\u003d nodeS) {\n           // The same datanode has been just restarted to serve the same data \n           // storage. We do not need to remove old data blocks, the delta will\n           // be calculated on the next block report from the datanode\n           if(NameNode.stateChangeLog.isDebugEnabled()) {\n             NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n                 + \"node restarted.\");\n           }\n         } else {\n           // nodeS is found\n           /* The registering datanode is a replacement node for the existing \n             data storage, which from now on will be served by a new node.\n             If this message repeats, both nodes might have same storageID \n             by (insanely rare) random chance. User needs to restart one of the\n             nodes with its data cleared (or user can just remove the StorageID\n             value in \"VERSION\" file under the data directory of the datanode,\n             but this is might not work if VERSION file format has changed \n          */        \n           NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n               + \" is replaced by \" + nodeReg + \" with the same storageID \"\n               + nodeReg.getStorageID());\n         }\n         \n         boolean success \u003d false;\n         try {\n           // update cluster map\n           getNetworkTopology().remove(nodeS);\n           if(shouldCountVersion(nodeS)) {\n             decrementVersionCount(nodeS.getSoftwareVersion());\n           }\n           nodeS.updateRegInfo(nodeReg);\n \n           nodeS.setSoftwareVersion(nodeReg.getSoftwareVersion());\n           nodeS.setDisallowed(false); // Node is in the include list\n \n           // resolve network location\n           nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));\n           getNetworkTopology().add(nodeS);\n             \n           // also treat the registration message as a heartbeat\n           heartbeatManager.register(nodeS);\n           incrementVersionCount(nodeS.getSoftwareVersion());\n           checkDecommissioning(nodeS);\n           success \u003d true;\n         } finally {\n           if (!success) {\n             removeDatanode(nodeS);\n             wipeDatanode(nodeS);\n             countSoftwareVersions();\n           }\n         }\n         return;\n       } \n   \n       // this is a new datanode serving a new data storage\n       if (\"\".equals(nodeReg.getStorageID())) {\n         // this data storage has never been registered\n         // it is either empty or was created by pre-storageID version of DFS\n         nodeReg.setStorageID(newStorageID());\n         if (NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\n               \"BLOCK* NameSystem.registerDatanode: \"\n               + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n         }\n       }\n       \n       DatanodeDescriptor nodeDescr \n         \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n       boolean success \u003d false;\n       try {\n         nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n         networktopology.add(nodeDescr);\n         nodeDescr.setSoftwareVersion(nodeReg.getSoftwareVersion());\n   \n         // register new datanode\n         addDatanode(nodeDescr);\n         checkDecommissioning(nodeDescr);\n         \n         // also treat the registration message as a heartbeat\n         // no need to update its timestamp\n         // because its is done when the descriptor is created\n         heartbeatManager.addDatanode(nodeDescr);\n         success \u003d true;\n         incrementVersionCount(nodeReg.getSoftwareVersion());\n       } finally {\n         if (!success) {\n           removeDatanode(nodeDescr);\n           wipeDatanode(nodeDescr);\n           countSoftwareVersions();\n         }\n       }\n     } catch (InvalidTopologyException e) {\n       // If the network location is invalid, clear the cached mappings\n       // so that we have a chance to re-add this DataNode with the\n       // correct network location later.\n-      dnsToSwitchMapping.reloadCachedMappings();\n+      List\u003cString\u003e invalidNodeNames \u003d new ArrayList\u003cString\u003e(3);\n+      // clear cache for nodes in IP or Hostname\n+      invalidNodeNames.add(nodeReg.getIpAddr());\n+      invalidNodeNames.add(nodeReg.getHostName());\n+      invalidNodeNames.add(nodeReg.getPeerHostName());\n+      dnsToSwitchMapping.reloadCachedMappings(invalidNodeNames);\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void registerDatanode(DatanodeRegistration nodeReg)\n      throws DisallowedDatanodeException {\n    InetAddress dnAddress \u003d Server.getRemoteIp();\n    if (dnAddress !\u003d null) {\n      // Mostly called inside an RPC, update ip and peer hostname\n      String hostname \u003d dnAddress.getHostName();\n      String ip \u003d dnAddress.getHostAddress();\n      if (checkIpHostnameInRegistration \u0026\u0026 !isNameResolved(dnAddress)) {\n        // Reject registration of unresolved datanode to prevent performance\n        // impact of repetitive DNS lookups later.\n        final String message \u003d \"hostname cannot be resolved (ip\u003d\"\n            + ip + \", hostname\u003d\" + hostname + \")\";\n        LOG.warn(\"Unresolved datanode registration: \" + message);\n        throw new DisallowedDatanodeException(nodeReg, message);\n      }\n      // update node registration with the ip and hostname from rpc request\n      nodeReg.setIpAddr(ip);\n      nodeReg.setPeerHostName(hostname);\n    }\n    \n    try {\n      nodeReg.setExportedKeys(blockManager.getBlockKeys());\n  \n      // Checks if the node is not on the hosts list.  If it is not, then\n      // it will be disallowed from registering. \n      if (!hostFileManager.isIncluded(nodeReg)) {\n        throw new DisallowedDatanodeException(nodeReg);\n      }\n        \n      NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n          + nodeReg + \" storage \" + nodeReg.getStorageID());\n  \n      DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n      DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n          nodeReg.getIpAddr(), nodeReg.getXferPort());\n        \n      if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n        NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n        // nodeN previously served a different data storage, \n        // which is not served by anybody anymore.\n        removeDatanode(nodeN);\n        // physically remove node from datanodeMap\n        wipeDatanode(nodeN);\n        nodeN \u003d null;\n      }\n  \n      if (nodeS !\u003d null) {\n        if (nodeN \u003d\u003d nodeS) {\n          // The same datanode has been just restarted to serve the same data \n          // storage. We do not need to remove old data blocks, the delta will\n          // be calculated on the next block report from the datanode\n          if(NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n                + \"node restarted.\");\n          }\n        } else {\n          // nodeS is found\n          /* The registering datanode is a replacement node for the existing \n            data storage, which from now on will be served by a new node.\n            If this message repeats, both nodes might have same storageID \n            by (insanely rare) random chance. User needs to restart one of the\n            nodes with its data cleared (or user can just remove the StorageID\n            value in \"VERSION\" file under the data directory of the datanode,\n            but this is might not work if VERSION file format has changed \n         */        \n          NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n              + \" is replaced by \" + nodeReg + \" with the same storageID \"\n              + nodeReg.getStorageID());\n        }\n        \n        boolean success \u003d false;\n        try {\n          // update cluster map\n          getNetworkTopology().remove(nodeS);\n          if(shouldCountVersion(nodeS)) {\n            decrementVersionCount(nodeS.getSoftwareVersion());\n          }\n          nodeS.updateRegInfo(nodeReg);\n\n          nodeS.setSoftwareVersion(nodeReg.getSoftwareVersion());\n          nodeS.setDisallowed(false); // Node is in the include list\n\n          // resolve network location\n          nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));\n          getNetworkTopology().add(nodeS);\n            \n          // also treat the registration message as a heartbeat\n          heartbeatManager.register(nodeS);\n          incrementVersionCount(nodeS.getSoftwareVersion());\n          checkDecommissioning(nodeS);\n          success \u003d true;\n        } finally {\n          if (!success) {\n            removeDatanode(nodeS);\n            wipeDatanode(nodeS);\n            countSoftwareVersions();\n          }\n        }\n        return;\n      } \n  \n      // this is a new datanode serving a new data storage\n      if (\"\".equals(nodeReg.getStorageID())) {\n        // this data storage has never been registered\n        // it is either empty or was created by pre-storageID version of DFS\n        nodeReg.setStorageID(newStorageID());\n        if (NameNode.stateChangeLog.isDebugEnabled()) {\n          NameNode.stateChangeLog.debug(\n              \"BLOCK* NameSystem.registerDatanode: \"\n              + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n        }\n      }\n      \n      DatanodeDescriptor nodeDescr \n        \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n      boolean success \u003d false;\n      try {\n        nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n        networktopology.add(nodeDescr);\n        nodeDescr.setSoftwareVersion(nodeReg.getSoftwareVersion());\n  \n        // register new datanode\n        addDatanode(nodeDescr);\n        checkDecommissioning(nodeDescr);\n        \n        // also treat the registration message as a heartbeat\n        // no need to update its timestamp\n        // because its is done when the descriptor is created\n        heartbeatManager.addDatanode(nodeDescr);\n        success \u003d true;\n        incrementVersionCount(nodeReg.getSoftwareVersion());\n      } finally {\n        if (!success) {\n          removeDatanode(nodeDescr);\n          wipeDatanode(nodeDescr);\n          countSoftwareVersions();\n        }\n      }\n    } catch (InvalidTopologyException e) {\n      // If the network location is invalid, clear the cached mappings\n      // so that we have a chance to re-add this DataNode with the\n      // correct network location later.\n      List\u003cString\u003e invalidNodeNames \u003d new ArrayList\u003cString\u003e(3);\n      // clear cache for nodes in IP or Hostname\n      invalidNodeNames.add(nodeReg.getIpAddr());\n      invalidNodeNames.add(nodeReg.getHostName());\n      invalidNodeNames.add(nodeReg.getPeerHostName());\n      dnsToSwitchMapping.reloadCachedMappings(invalidNodeNames);\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "0a5f0efcb4c906dd5820925cce8723946841be61": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5338. Add a conf to disable hostname check in datanode registration.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1532468 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "15/10/13 11:21 AM",
      "commitName": "0a5f0efcb4c906dd5820925cce8723946841be61",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "05/10/13 8:22 PM",
      "commitNameOld": "8e0804666189ce9a66b7b41b744776bad29770dd",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 9.62,
      "commitsBetweenForRepo": 64,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,149 +1,151 @@\n   public void registerDatanode(DatanodeRegistration nodeReg)\n       throws DisallowedDatanodeException {\n     InetAddress dnAddress \u003d Server.getRemoteIp();\n     if (dnAddress !\u003d null) {\n       // Mostly called inside an RPC, update ip and peer hostname\n       String hostname \u003d dnAddress.getHostName();\n       String ip \u003d dnAddress.getHostAddress();\n-      if (!isNameResolved(dnAddress)) {\n+      if (checkIpHostnameInRegistration \u0026\u0026 !isNameResolved(dnAddress)) {\n         // Reject registration of unresolved datanode to prevent performance\n         // impact of repetitive DNS lookups later.\n-        LOG.warn(\"Unresolved datanode registration from \" + ip);\n-        throw new DisallowedDatanodeException(nodeReg);\n+        final String message \u003d \"hostname cannot be resolved (ip\u003d\"\n+            + ip + \", hostname\u003d\" + hostname + \")\";\n+        LOG.warn(\"Unresolved datanode registration: \" + message);\n+        throw new DisallowedDatanodeException(nodeReg, message);\n       }\n       // update node registration with the ip and hostname from rpc request\n       nodeReg.setIpAddr(ip);\n       nodeReg.setPeerHostName(hostname);\n     }\n     \n     try {\n       nodeReg.setExportedKeys(blockManager.getBlockKeys());\n   \n       // Checks if the node is not on the hosts list.  If it is not, then\n       // it will be disallowed from registering. \n       if (!hostFileManager.isIncluded(nodeReg)) {\n         throw new DisallowedDatanodeException(nodeReg);\n       }\n         \n       NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n           + nodeReg + \" storage \" + nodeReg.getStorageID());\n   \n       DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n       DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n           nodeReg.getIpAddr(), nodeReg.getXferPort());\n         \n       if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n         NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n         // nodeN previously served a different data storage, \n         // which is not served by anybody anymore.\n         removeDatanode(nodeN);\n         // physically remove node from datanodeMap\n         wipeDatanode(nodeN);\n         nodeN \u003d null;\n       }\n   \n       if (nodeS !\u003d null) {\n         if (nodeN \u003d\u003d nodeS) {\n           // The same datanode has been just restarted to serve the same data \n           // storage. We do not need to remove old data blocks, the delta will\n           // be calculated on the next block report from the datanode\n           if(NameNode.stateChangeLog.isDebugEnabled()) {\n             NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n                 + \"node restarted.\");\n           }\n         } else {\n           // nodeS is found\n           /* The registering datanode is a replacement node for the existing \n             data storage, which from now on will be served by a new node.\n             If this message repeats, both nodes might have same storageID \n             by (insanely rare) random chance. User needs to restart one of the\n             nodes with its data cleared (or user can just remove the StorageID\n             value in \"VERSION\" file under the data directory of the datanode,\n             but this is might not work if VERSION file format has changed \n          */        \n           NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n               + \" is replaced by \" + nodeReg + \" with the same storageID \"\n               + nodeReg.getStorageID());\n         }\n         \n         boolean success \u003d false;\n         try {\n           // update cluster map\n           getNetworkTopology().remove(nodeS);\n           if(shouldCountVersion(nodeS)) {\n             decrementVersionCount(nodeS.getSoftwareVersion());\n           }\n           nodeS.updateRegInfo(nodeReg);\n \n           nodeS.setSoftwareVersion(nodeReg.getSoftwareVersion());\n           nodeS.setDisallowed(false); // Node is in the include list\n \n           // resolve network location\n           nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));\n           getNetworkTopology().add(nodeS);\n             \n           // also treat the registration message as a heartbeat\n           heartbeatManager.register(nodeS);\n           incrementVersionCount(nodeS.getSoftwareVersion());\n           checkDecommissioning(nodeS);\n           success \u003d true;\n         } finally {\n           if (!success) {\n             removeDatanode(nodeS);\n             wipeDatanode(nodeS);\n             countSoftwareVersions();\n           }\n         }\n         return;\n       } \n   \n       // this is a new datanode serving a new data storage\n       if (\"\".equals(nodeReg.getStorageID())) {\n         // this data storage has never been registered\n         // it is either empty or was created by pre-storageID version of DFS\n         nodeReg.setStorageID(newStorageID());\n         if (NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\n               \"BLOCK* NameSystem.registerDatanode: \"\n               + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n         }\n       }\n       \n       DatanodeDescriptor nodeDescr \n         \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n       boolean success \u003d false;\n       try {\n         nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n         networktopology.add(nodeDescr);\n         nodeDescr.setSoftwareVersion(nodeReg.getSoftwareVersion());\n   \n         // register new datanode\n         addDatanode(nodeDescr);\n         checkDecommissioning(nodeDescr);\n         \n         // also treat the registration message as a heartbeat\n         // no need to update its timestamp\n         // because its is done when the descriptor is created\n         heartbeatManager.addDatanode(nodeDescr);\n         success \u003d true;\n         incrementVersionCount(nodeReg.getSoftwareVersion());\n       } finally {\n         if (!success) {\n           removeDatanode(nodeDescr);\n           wipeDatanode(nodeDescr);\n           countSoftwareVersions();\n         }\n       }\n     } catch (InvalidTopologyException e) {\n       // If the network location is invalid, clear the cached mappings\n       // so that we have a chance to re-add this DataNode with the\n       // correct network location later.\n       List\u003cString\u003e invalidNodeNames \u003d new ArrayList\u003cString\u003e(3);\n       // clear cache for nodes in IP or Hostname\n       invalidNodeNames.add(nodeReg.getIpAddr());\n       invalidNodeNames.add(nodeReg.getHostName());\n       invalidNodeNames.add(nodeReg.getPeerHostName());\n       dnsToSwitchMapping.reloadCachedMappings(invalidNodeNames);\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void registerDatanode(DatanodeRegistration nodeReg)\n      throws DisallowedDatanodeException {\n    InetAddress dnAddress \u003d Server.getRemoteIp();\n    if (dnAddress !\u003d null) {\n      // Mostly called inside an RPC, update ip and peer hostname\n      String hostname \u003d dnAddress.getHostName();\n      String ip \u003d dnAddress.getHostAddress();\n      if (checkIpHostnameInRegistration \u0026\u0026 !isNameResolved(dnAddress)) {\n        // Reject registration of unresolved datanode to prevent performance\n        // impact of repetitive DNS lookups later.\n        final String message \u003d \"hostname cannot be resolved (ip\u003d\"\n            + ip + \", hostname\u003d\" + hostname + \")\";\n        LOG.warn(\"Unresolved datanode registration: \" + message);\n        throw new DisallowedDatanodeException(nodeReg, message);\n      }\n      // update node registration with the ip and hostname from rpc request\n      nodeReg.setIpAddr(ip);\n      nodeReg.setPeerHostName(hostname);\n    }\n    \n    try {\n      nodeReg.setExportedKeys(blockManager.getBlockKeys());\n  \n      // Checks if the node is not on the hosts list.  If it is not, then\n      // it will be disallowed from registering. \n      if (!hostFileManager.isIncluded(nodeReg)) {\n        throw new DisallowedDatanodeException(nodeReg);\n      }\n        \n      NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n          + nodeReg + \" storage \" + nodeReg.getStorageID());\n  \n      DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n      DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n          nodeReg.getIpAddr(), nodeReg.getXferPort());\n        \n      if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n        NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n        // nodeN previously served a different data storage, \n        // which is not served by anybody anymore.\n        removeDatanode(nodeN);\n        // physically remove node from datanodeMap\n        wipeDatanode(nodeN);\n        nodeN \u003d null;\n      }\n  \n      if (nodeS !\u003d null) {\n        if (nodeN \u003d\u003d nodeS) {\n          // The same datanode has been just restarted to serve the same data \n          // storage. We do not need to remove old data blocks, the delta will\n          // be calculated on the next block report from the datanode\n          if(NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n                + \"node restarted.\");\n          }\n        } else {\n          // nodeS is found\n          /* The registering datanode is a replacement node for the existing \n            data storage, which from now on will be served by a new node.\n            If this message repeats, both nodes might have same storageID \n            by (insanely rare) random chance. User needs to restart one of the\n            nodes with its data cleared (or user can just remove the StorageID\n            value in \"VERSION\" file under the data directory of the datanode,\n            but this is might not work if VERSION file format has changed \n         */        \n          NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n              + \" is replaced by \" + nodeReg + \" with the same storageID \"\n              + nodeReg.getStorageID());\n        }\n        \n        boolean success \u003d false;\n        try {\n          // update cluster map\n          getNetworkTopology().remove(nodeS);\n          if(shouldCountVersion(nodeS)) {\n            decrementVersionCount(nodeS.getSoftwareVersion());\n          }\n          nodeS.updateRegInfo(nodeReg);\n\n          nodeS.setSoftwareVersion(nodeReg.getSoftwareVersion());\n          nodeS.setDisallowed(false); // Node is in the include list\n\n          // resolve network location\n          nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));\n          getNetworkTopology().add(nodeS);\n            \n          // also treat the registration message as a heartbeat\n          heartbeatManager.register(nodeS);\n          incrementVersionCount(nodeS.getSoftwareVersion());\n          checkDecommissioning(nodeS);\n          success \u003d true;\n        } finally {\n          if (!success) {\n            removeDatanode(nodeS);\n            wipeDatanode(nodeS);\n            countSoftwareVersions();\n          }\n        }\n        return;\n      } \n  \n      // this is a new datanode serving a new data storage\n      if (\"\".equals(nodeReg.getStorageID())) {\n        // this data storage has never been registered\n        // it is either empty or was created by pre-storageID version of DFS\n        nodeReg.setStorageID(newStorageID());\n        if (NameNode.stateChangeLog.isDebugEnabled()) {\n          NameNode.stateChangeLog.debug(\n              \"BLOCK* NameSystem.registerDatanode: \"\n              + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n        }\n      }\n      \n      DatanodeDescriptor nodeDescr \n        \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n      boolean success \u003d false;\n      try {\n        nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n        networktopology.add(nodeDescr);\n        nodeDescr.setSoftwareVersion(nodeReg.getSoftwareVersion());\n  \n        // register new datanode\n        addDatanode(nodeDescr);\n        checkDecommissioning(nodeDescr);\n        \n        // also treat the registration message as a heartbeat\n        // no need to update its timestamp\n        // because its is done when the descriptor is created\n        heartbeatManager.addDatanode(nodeDescr);\n        success \u003d true;\n        incrementVersionCount(nodeReg.getSoftwareVersion());\n      } finally {\n        if (!success) {\n          removeDatanode(nodeDescr);\n          wipeDatanode(nodeDescr);\n          countSoftwareVersions();\n        }\n      }\n    } catch (InvalidTopologyException e) {\n      // If the network location is invalid, clear the cached mappings\n      // so that we have a chance to re-add this DataNode with the\n      // correct network location later.\n      List\u003cString\u003e invalidNodeNames \u003d new ArrayList\u003cString\u003e(3);\n      // clear cache for nodes in IP or Hostname\n      invalidNodeNames.add(nodeReg.getIpAddr());\n      invalidNodeNames.add(nodeReg.getHostName());\n      invalidNodeNames.add(nodeReg.getPeerHostName());\n      dnsToSwitchMapping.reloadCachedMappings(invalidNodeNames);\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "46099ce7f1a1d5aab85d9408dc1454fcbe54f7e8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4988. Datanode must support all the volumes as individual storages.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2832@1526969 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/09/13 9:05 AM",
      "commitName": "46099ce7f1a1d5aab85d9408dc1454fcbe54f7e8",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "26/09/13 2:49 PM",
      "commitNameOld": "8062d8c23925d4e78633a3799d64c2fa9621066f",
      "commitAuthorOld": "",
      "daysBetweenCommits": 0.76,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,149 +1,149 @@\n   public void registerDatanode(DatanodeRegistration nodeReg)\n       throws DisallowedDatanodeException {\n     InetAddress dnAddress \u003d Server.getRemoteIp();\n     if (dnAddress !\u003d null) {\n       // Mostly called inside an RPC, update ip and peer hostname\n       String hostname \u003d dnAddress.getHostName();\n       String ip \u003d dnAddress.getHostAddress();\n       if (!isNameResolved(dnAddress)) {\n         // Reject registration of unresolved datanode to prevent performance\n         // impact of repetitive DNS lookups later.\n         LOG.warn(\"Unresolved datanode registration from \" + ip);\n         throw new DisallowedDatanodeException(nodeReg);\n       }\n       // update node registration with the ip and hostname from rpc request\n       nodeReg.setIpAddr(ip);\n       nodeReg.setPeerHostName(hostname);\n     }\n     \n     try {\n       nodeReg.setExportedKeys(blockManager.getBlockKeys());\n   \n       // Checks if the node is not on the hosts list.  If it is not, then\n       // it will be disallowed from registering. \n       if (!hostFileManager.isIncluded(nodeReg)) {\n         throw new DisallowedDatanodeException(nodeReg);\n       }\n         \n       NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n           + nodeReg + \" storage \" + nodeReg.getDatanodeUuid());\n   \n-      DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getDatanodeUuid());\n+      DatanodeDescriptor nodeS \u003d getDatanode(nodeReg.getDatanodeUuid());\n       DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n           nodeReg.getIpAddr(), nodeReg.getXferPort());\n         \n       if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n         NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n         // nodeN previously served a different data storage, \n         // which is not served by anybody anymore.\n         removeDatanode(nodeN);\n         // physically remove node from datanodeMap\n         wipeDatanode(nodeN);\n         nodeN \u003d null;\n       }\n   \n       if (nodeS !\u003d null) {\n         if (nodeN \u003d\u003d nodeS) {\n           // The same datanode has been just restarted to serve the same data \n           // storage. We do not need to remove old data blocks, the delta will\n           // be calculated on the next block report from the datanode\n           if(NameNode.stateChangeLog.isDebugEnabled()) {\n             NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n                 + \"node restarted.\");\n           }\n         } else {\n           // nodeS is found\n           /* The registering datanode is a replacement node for the existing \n             data storage, which from now on will be served by a new node.\n             If this message repeats, both nodes might have same storageID \n             by (insanely rare) random chance. User needs to restart one of the\n             nodes with its data cleared (or user can just remove the StorageID\n             value in \"VERSION\" file under the data directory of the datanode,\n             but this is might not work if VERSION file format has changed \n          */        \n           NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n               + \" is replaced by \" + nodeReg + \" with the same storageID \"\n               + nodeReg.getDatanodeUuid());\n         }\n         \n         boolean success \u003d false;\n         try {\n           // update cluster map\n           getNetworkTopology().remove(nodeS);\n           if(shouldCountVersion(nodeS)) {\n             decrementVersionCount(nodeS.getSoftwareVersion());\n           }\n           nodeS.updateRegInfo(nodeReg);\n \n           nodeS.setSoftwareVersion(nodeReg.getSoftwareVersion());\n           nodeS.setDisallowed(false); // Node is in the include list\n \n           // resolve network location\n           nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));\n           getNetworkTopology().add(nodeS);\n             \n           // also treat the registration message as a heartbeat\n           heartbeatManager.register(nodeS);\n           incrementVersionCount(nodeS.getSoftwareVersion());\n           checkDecommissioning(nodeS);\n           success \u003d true;\n         } finally {\n           if (!success) {\n             removeDatanode(nodeS);\n             wipeDatanode(nodeS);\n             countSoftwareVersions();\n           }\n         }\n         return;\n-      } \n-  \n-      // this is a new datanode serving a new data storage\n-      if (\"\".equals(nodeReg.getDatanodeUuid())) {\n-        // this data storage has never been registered\n-        // it is either empty or was created by pre-storageID version of DFS\n-        nodeReg.setDatanodeUuid(DatanodeStorage.newStorageID());\n+      }\n+\n+      // This is a new datanode.\n+      if (nodeReg.getDatanodeUuid() \u003d\u003d null ||\n+          nodeReg.getDatanodeUuid().isEmpty()) {\n+        // this data node has never been registered\n+        nodeReg.generateNewDatanodeUuid();\n         if (NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\n               \"BLOCK* NameSystem.registerDatanode: \"\n               + \"new Datanode UUID \" + nodeReg.getDatanodeUuid() + \" assigned.\");\n         }\n       }\n       \n       DatanodeDescriptor nodeDescr \n         \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n       boolean success \u003d false;\n       try {\n         nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n         networktopology.add(nodeDescr);\n         nodeDescr.setSoftwareVersion(nodeReg.getSoftwareVersion());\n   \n         // register new datanode\n         addDatanode(nodeDescr);\n         checkDecommissioning(nodeDescr);\n         \n         // also treat the registration message as a heartbeat\n         // no need to update its timestamp\n         // because its is done when the descriptor is created\n         heartbeatManager.addDatanode(nodeDescr);\n         success \u003d true;\n         incrementVersionCount(nodeReg.getSoftwareVersion());\n       } finally {\n         if (!success) {\n           removeDatanode(nodeDescr);\n           wipeDatanode(nodeDescr);\n           countSoftwareVersions();\n         }\n       }\n     } catch (InvalidTopologyException e) {\n       // If the network location is invalid, clear the cached mappings\n       // so that we have a chance to re-add this DataNode with the\n       // correct network location later.\n       List\u003cString\u003e invalidNodeNames \u003d new ArrayList\u003cString\u003e(3);\n       // clear cache for nodes in IP or Hostname\n       invalidNodeNames.add(nodeReg.getIpAddr());\n       invalidNodeNames.add(nodeReg.getHostName());\n       invalidNodeNames.add(nodeReg.getPeerHostName());\n       dnsToSwitchMapping.reloadCachedMappings(invalidNodeNames);\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void registerDatanode(DatanodeRegistration nodeReg)\n      throws DisallowedDatanodeException {\n    InetAddress dnAddress \u003d Server.getRemoteIp();\n    if (dnAddress !\u003d null) {\n      // Mostly called inside an RPC, update ip and peer hostname\n      String hostname \u003d dnAddress.getHostName();\n      String ip \u003d dnAddress.getHostAddress();\n      if (!isNameResolved(dnAddress)) {\n        // Reject registration of unresolved datanode to prevent performance\n        // impact of repetitive DNS lookups later.\n        LOG.warn(\"Unresolved datanode registration from \" + ip);\n        throw new DisallowedDatanodeException(nodeReg);\n      }\n      // update node registration with the ip and hostname from rpc request\n      nodeReg.setIpAddr(ip);\n      nodeReg.setPeerHostName(hostname);\n    }\n    \n    try {\n      nodeReg.setExportedKeys(blockManager.getBlockKeys());\n  \n      // Checks if the node is not on the hosts list.  If it is not, then\n      // it will be disallowed from registering. \n      if (!hostFileManager.isIncluded(nodeReg)) {\n        throw new DisallowedDatanodeException(nodeReg);\n      }\n        \n      NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n          + nodeReg + \" storage \" + nodeReg.getDatanodeUuid());\n  \n      DatanodeDescriptor nodeS \u003d getDatanode(nodeReg.getDatanodeUuid());\n      DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n          nodeReg.getIpAddr(), nodeReg.getXferPort());\n        \n      if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n        NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n        // nodeN previously served a different data storage, \n        // which is not served by anybody anymore.\n        removeDatanode(nodeN);\n        // physically remove node from datanodeMap\n        wipeDatanode(nodeN);\n        nodeN \u003d null;\n      }\n  \n      if (nodeS !\u003d null) {\n        if (nodeN \u003d\u003d nodeS) {\n          // The same datanode has been just restarted to serve the same data \n          // storage. We do not need to remove old data blocks, the delta will\n          // be calculated on the next block report from the datanode\n          if(NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n                + \"node restarted.\");\n          }\n        } else {\n          // nodeS is found\n          /* The registering datanode is a replacement node for the existing \n            data storage, which from now on will be served by a new node.\n            If this message repeats, both nodes might have same storageID \n            by (insanely rare) random chance. User needs to restart one of the\n            nodes with its data cleared (or user can just remove the StorageID\n            value in \"VERSION\" file under the data directory of the datanode,\n            but this is might not work if VERSION file format has changed \n         */        \n          NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n              + \" is replaced by \" + nodeReg + \" with the same storageID \"\n              + nodeReg.getDatanodeUuid());\n        }\n        \n        boolean success \u003d false;\n        try {\n          // update cluster map\n          getNetworkTopology().remove(nodeS);\n          if(shouldCountVersion(nodeS)) {\n            decrementVersionCount(nodeS.getSoftwareVersion());\n          }\n          nodeS.updateRegInfo(nodeReg);\n\n          nodeS.setSoftwareVersion(nodeReg.getSoftwareVersion());\n          nodeS.setDisallowed(false); // Node is in the include list\n\n          // resolve network location\n          nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));\n          getNetworkTopology().add(nodeS);\n            \n          // also treat the registration message as a heartbeat\n          heartbeatManager.register(nodeS);\n          incrementVersionCount(nodeS.getSoftwareVersion());\n          checkDecommissioning(nodeS);\n          success \u003d true;\n        } finally {\n          if (!success) {\n            removeDatanode(nodeS);\n            wipeDatanode(nodeS);\n            countSoftwareVersions();\n          }\n        }\n        return;\n      }\n\n      // This is a new datanode.\n      if (nodeReg.getDatanodeUuid() \u003d\u003d null ||\n          nodeReg.getDatanodeUuid().isEmpty()) {\n        // this data node has never been registered\n        nodeReg.generateNewDatanodeUuid();\n        if (NameNode.stateChangeLog.isDebugEnabled()) {\n          NameNode.stateChangeLog.debug(\n              \"BLOCK* NameSystem.registerDatanode: \"\n              + \"new Datanode UUID \" + nodeReg.getDatanodeUuid() + \" assigned.\");\n        }\n      }\n      \n      DatanodeDescriptor nodeDescr \n        \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n      boolean success \u003d false;\n      try {\n        nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n        networktopology.add(nodeDescr);\n        nodeDescr.setSoftwareVersion(nodeReg.getSoftwareVersion());\n  \n        // register new datanode\n        addDatanode(nodeDescr);\n        checkDecommissioning(nodeDescr);\n        \n        // also treat the registration message as a heartbeat\n        // no need to update its timestamp\n        // because its is done when the descriptor is created\n        heartbeatManager.addDatanode(nodeDescr);\n        success \u003d true;\n        incrementVersionCount(nodeReg.getSoftwareVersion());\n      } finally {\n        if (!success) {\n          removeDatanode(nodeDescr);\n          wipeDatanode(nodeDescr);\n          countSoftwareVersions();\n        }\n      }\n    } catch (InvalidTopologyException e) {\n      // If the network location is invalid, clear the cached mappings\n      // so that we have a chance to re-add this DataNode with the\n      // correct network location later.\n      List\u003cString\u003e invalidNodeNames \u003d new ArrayList\u003cString\u003e(3);\n      // clear cache for nodes in IP or Hostname\n      invalidNodeNames.add(nodeReg.getIpAddr());\n      invalidNodeNames.add(nodeReg.getHostName());\n      invalidNodeNames.add(nodeReg.getPeerHostName());\n      dnsToSwitchMapping.reloadCachedMappings(invalidNodeNames);\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "8a66e493ba03f710b353638647013401d18f413c": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-9998. Provide methods to clear only part of the DNSToSwitchMapping. (Junping Du via Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1526567 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "26/09/13 8:24 AM",
      "commitName": "8a66e493ba03f710b353638647013401d18f413c",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "27/08/13 12:21 PM",
      "commitNameOld": "39252995c4d734e993e3fa5338e1a7816aee86fc",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 29.84,
      "commitsBetweenForRepo": 153,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,144 +1,149 @@\n   public void registerDatanode(DatanodeRegistration nodeReg)\n       throws DisallowedDatanodeException {\n     InetAddress dnAddress \u003d Server.getRemoteIp();\n     if (dnAddress !\u003d null) {\n       // Mostly called inside an RPC, update ip and peer hostname\n       String hostname \u003d dnAddress.getHostName();\n       String ip \u003d dnAddress.getHostAddress();\n       if (!isNameResolved(dnAddress)) {\n         // Reject registration of unresolved datanode to prevent performance\n         // impact of repetitive DNS lookups later.\n         LOG.warn(\"Unresolved datanode registration from \" + ip);\n         throw new DisallowedDatanodeException(nodeReg);\n       }\n       // update node registration with the ip and hostname from rpc request\n       nodeReg.setIpAddr(ip);\n       nodeReg.setPeerHostName(hostname);\n     }\n     \n     try {\n       nodeReg.setExportedKeys(blockManager.getBlockKeys());\n   \n       // Checks if the node is not on the hosts list.  If it is not, then\n       // it will be disallowed from registering. \n       if (!hostFileManager.isIncluded(nodeReg)) {\n         throw new DisallowedDatanodeException(nodeReg);\n       }\n         \n       NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n           + nodeReg + \" storage \" + nodeReg.getStorageID());\n   \n       DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n       DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n           nodeReg.getIpAddr(), nodeReg.getXferPort());\n         \n       if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n         NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n         // nodeN previously served a different data storage, \n         // which is not served by anybody anymore.\n         removeDatanode(nodeN);\n         // physically remove node from datanodeMap\n         wipeDatanode(nodeN);\n         nodeN \u003d null;\n       }\n   \n       if (nodeS !\u003d null) {\n         if (nodeN \u003d\u003d nodeS) {\n           // The same datanode has been just restarted to serve the same data \n           // storage. We do not need to remove old data blocks, the delta will\n           // be calculated on the next block report from the datanode\n           if(NameNode.stateChangeLog.isDebugEnabled()) {\n             NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n                 + \"node restarted.\");\n           }\n         } else {\n           // nodeS is found\n           /* The registering datanode is a replacement node for the existing \n             data storage, which from now on will be served by a new node.\n             If this message repeats, both nodes might have same storageID \n             by (insanely rare) random chance. User needs to restart one of the\n             nodes with its data cleared (or user can just remove the StorageID\n             value in \"VERSION\" file under the data directory of the datanode,\n             but this is might not work if VERSION file format has changed \n          */        \n           NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n               + \" is replaced by \" + nodeReg + \" with the same storageID \"\n               + nodeReg.getStorageID());\n         }\n         \n         boolean success \u003d false;\n         try {\n           // update cluster map\n           getNetworkTopology().remove(nodeS);\n           if(shouldCountVersion(nodeS)) {\n             decrementVersionCount(nodeS.getSoftwareVersion());\n           }\n           nodeS.updateRegInfo(nodeReg);\n \n           nodeS.setSoftwareVersion(nodeReg.getSoftwareVersion());\n           nodeS.setDisallowed(false); // Node is in the include list\n \n           // resolve network location\n           nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));\n           getNetworkTopology().add(nodeS);\n             \n           // also treat the registration message as a heartbeat\n           heartbeatManager.register(nodeS);\n           incrementVersionCount(nodeS.getSoftwareVersion());\n           checkDecommissioning(nodeS);\n           success \u003d true;\n         } finally {\n           if (!success) {\n             removeDatanode(nodeS);\n             wipeDatanode(nodeS);\n             countSoftwareVersions();\n           }\n         }\n         return;\n       } \n   \n       // this is a new datanode serving a new data storage\n       if (\"\".equals(nodeReg.getStorageID())) {\n         // this data storage has never been registered\n         // it is either empty or was created by pre-storageID version of DFS\n         nodeReg.setStorageID(newStorageID());\n         if (NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\n               \"BLOCK* NameSystem.registerDatanode: \"\n               + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n         }\n       }\n       \n       DatanodeDescriptor nodeDescr \n         \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n       boolean success \u003d false;\n       try {\n         nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n         networktopology.add(nodeDescr);\n         nodeDescr.setSoftwareVersion(nodeReg.getSoftwareVersion());\n   \n         // register new datanode\n         addDatanode(nodeDescr);\n         checkDecommissioning(nodeDescr);\n         \n         // also treat the registration message as a heartbeat\n         // no need to update its timestamp\n         // because its is done when the descriptor is created\n         heartbeatManager.addDatanode(nodeDescr);\n         success \u003d true;\n         incrementVersionCount(nodeReg.getSoftwareVersion());\n       } finally {\n         if (!success) {\n           removeDatanode(nodeDescr);\n           wipeDatanode(nodeDescr);\n           countSoftwareVersions();\n         }\n       }\n     } catch (InvalidTopologyException e) {\n       // If the network location is invalid, clear the cached mappings\n       // so that we have a chance to re-add this DataNode with the\n       // correct network location later.\n-      dnsToSwitchMapping.reloadCachedMappings();\n+      List\u003cString\u003e invalidNodeNames \u003d new ArrayList\u003cString\u003e(3);\n+      // clear cache for nodes in IP or Hostname\n+      invalidNodeNames.add(nodeReg.getIpAddr());\n+      invalidNodeNames.add(nodeReg.getHostName());\n+      invalidNodeNames.add(nodeReg.getPeerHostName());\n+      dnsToSwitchMapping.reloadCachedMappings(invalidNodeNames);\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void registerDatanode(DatanodeRegistration nodeReg)\n      throws DisallowedDatanodeException {\n    InetAddress dnAddress \u003d Server.getRemoteIp();\n    if (dnAddress !\u003d null) {\n      // Mostly called inside an RPC, update ip and peer hostname\n      String hostname \u003d dnAddress.getHostName();\n      String ip \u003d dnAddress.getHostAddress();\n      if (!isNameResolved(dnAddress)) {\n        // Reject registration of unresolved datanode to prevent performance\n        // impact of repetitive DNS lookups later.\n        LOG.warn(\"Unresolved datanode registration from \" + ip);\n        throw new DisallowedDatanodeException(nodeReg);\n      }\n      // update node registration with the ip and hostname from rpc request\n      nodeReg.setIpAddr(ip);\n      nodeReg.setPeerHostName(hostname);\n    }\n    \n    try {\n      nodeReg.setExportedKeys(blockManager.getBlockKeys());\n  \n      // Checks if the node is not on the hosts list.  If it is not, then\n      // it will be disallowed from registering. \n      if (!hostFileManager.isIncluded(nodeReg)) {\n        throw new DisallowedDatanodeException(nodeReg);\n      }\n        \n      NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n          + nodeReg + \" storage \" + nodeReg.getStorageID());\n  \n      DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n      DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n          nodeReg.getIpAddr(), nodeReg.getXferPort());\n        \n      if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n        NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n        // nodeN previously served a different data storage, \n        // which is not served by anybody anymore.\n        removeDatanode(nodeN);\n        // physically remove node from datanodeMap\n        wipeDatanode(nodeN);\n        nodeN \u003d null;\n      }\n  \n      if (nodeS !\u003d null) {\n        if (nodeN \u003d\u003d nodeS) {\n          // The same datanode has been just restarted to serve the same data \n          // storage. We do not need to remove old data blocks, the delta will\n          // be calculated on the next block report from the datanode\n          if(NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n                + \"node restarted.\");\n          }\n        } else {\n          // nodeS is found\n          /* The registering datanode is a replacement node for the existing \n            data storage, which from now on will be served by a new node.\n            If this message repeats, both nodes might have same storageID \n            by (insanely rare) random chance. User needs to restart one of the\n            nodes with its data cleared (or user can just remove the StorageID\n            value in \"VERSION\" file under the data directory of the datanode,\n            but this is might not work if VERSION file format has changed \n         */        \n          NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n              + \" is replaced by \" + nodeReg + \" with the same storageID \"\n              + nodeReg.getStorageID());\n        }\n        \n        boolean success \u003d false;\n        try {\n          // update cluster map\n          getNetworkTopology().remove(nodeS);\n          if(shouldCountVersion(nodeS)) {\n            decrementVersionCount(nodeS.getSoftwareVersion());\n          }\n          nodeS.updateRegInfo(nodeReg);\n\n          nodeS.setSoftwareVersion(nodeReg.getSoftwareVersion());\n          nodeS.setDisallowed(false); // Node is in the include list\n\n          // resolve network location\n          nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));\n          getNetworkTopology().add(nodeS);\n            \n          // also treat the registration message as a heartbeat\n          heartbeatManager.register(nodeS);\n          incrementVersionCount(nodeS.getSoftwareVersion());\n          checkDecommissioning(nodeS);\n          success \u003d true;\n        } finally {\n          if (!success) {\n            removeDatanode(nodeS);\n            wipeDatanode(nodeS);\n            countSoftwareVersions();\n          }\n        }\n        return;\n      } \n  \n      // this is a new datanode serving a new data storage\n      if (\"\".equals(nodeReg.getStorageID())) {\n        // this data storage has never been registered\n        // it is either empty or was created by pre-storageID version of DFS\n        nodeReg.setStorageID(newStorageID());\n        if (NameNode.stateChangeLog.isDebugEnabled()) {\n          NameNode.stateChangeLog.debug(\n              \"BLOCK* NameSystem.registerDatanode: \"\n              + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n        }\n      }\n      \n      DatanodeDescriptor nodeDescr \n        \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n      boolean success \u003d false;\n      try {\n        nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n        networktopology.add(nodeDescr);\n        nodeDescr.setSoftwareVersion(nodeReg.getSoftwareVersion());\n  \n        // register new datanode\n        addDatanode(nodeDescr);\n        checkDecommissioning(nodeDescr);\n        \n        // also treat the registration message as a heartbeat\n        // no need to update its timestamp\n        // because its is done when the descriptor is created\n        heartbeatManager.addDatanode(nodeDescr);\n        success \u003d true;\n        incrementVersionCount(nodeReg.getSoftwareVersion());\n      } finally {\n        if (!success) {\n          removeDatanode(nodeDescr);\n          wipeDatanode(nodeDescr);\n          countSoftwareVersions();\n        }\n      }\n    } catch (InvalidTopologyException e) {\n      // If the network location is invalid, clear the cached mappings\n      // so that we have a chance to re-add this DataNode with the\n      // correct network location later.\n      List\u003cString\u003e invalidNodeNames \u003d new ArrayList\u003cString\u003e(3);\n      // clear cache for nodes in IP or Hostname\n      invalidNodeNames.add(nodeReg.getIpAddr());\n      invalidNodeNames.add(nodeReg.getHostName());\n      invalidNodeNames.add(nodeReg.getPeerHostName());\n      dnsToSwitchMapping.reloadCachedMappings(invalidNodeNames);\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "4551da302d94cffea0313eac79479ab6f9b7cb34": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5233. Use Datanode UUID to identify Datanodes.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2832@1525407 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "22/09/13 11:03 AM",
      "commitName": "4551da302d94cffea0313eac79479ab6f9b7cb34",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "08/09/13 3:53 PM",
      "commitNameOld": "282be1b38e5cd141ed7e2b2194bfb67a7c2f7f15",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 13.8,
      "commitsBetweenForRepo": 61,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,144 +1,144 @@\n   public void registerDatanode(DatanodeRegistration nodeReg)\n       throws DisallowedDatanodeException {\n     InetAddress dnAddress \u003d Server.getRemoteIp();\n     if (dnAddress !\u003d null) {\n       // Mostly called inside an RPC, update ip and peer hostname\n       String hostname \u003d dnAddress.getHostName();\n       String ip \u003d dnAddress.getHostAddress();\n       if (!isNameResolved(dnAddress)) {\n         // Reject registration of unresolved datanode to prevent performance\n         // impact of repetitive DNS lookups later.\n         LOG.warn(\"Unresolved datanode registration from \" + ip);\n         throw new DisallowedDatanodeException(nodeReg);\n       }\n       // update node registration with the ip and hostname from rpc request\n       nodeReg.setIpAddr(ip);\n       nodeReg.setPeerHostName(hostname);\n     }\n     \n     try {\n       nodeReg.setExportedKeys(blockManager.getBlockKeys());\n   \n       // Checks if the node is not on the hosts list.  If it is not, then\n       // it will be disallowed from registering. \n       if (!hostFileManager.isIncluded(nodeReg)) {\n         throw new DisallowedDatanodeException(nodeReg);\n       }\n         \n       NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n-          + nodeReg + \" storage \" + nodeReg.getStorageID());\n+          + nodeReg + \" storage \" + nodeReg.getDatanodeUuid());\n   \n-      DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n+      DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getDatanodeUuid());\n       DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n           nodeReg.getIpAddr(), nodeReg.getXferPort());\n         \n       if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n         NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n         // nodeN previously served a different data storage, \n         // which is not served by anybody anymore.\n         removeDatanode(nodeN);\n         // physically remove node from datanodeMap\n         wipeDatanode(nodeN);\n         nodeN \u003d null;\n       }\n   \n       if (nodeS !\u003d null) {\n         if (nodeN \u003d\u003d nodeS) {\n           // The same datanode has been just restarted to serve the same data \n           // storage. We do not need to remove old data blocks, the delta will\n           // be calculated on the next block report from the datanode\n           if(NameNode.stateChangeLog.isDebugEnabled()) {\n             NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n                 + \"node restarted.\");\n           }\n         } else {\n           // nodeS is found\n           /* The registering datanode is a replacement node for the existing \n             data storage, which from now on will be served by a new node.\n             If this message repeats, both nodes might have same storageID \n             by (insanely rare) random chance. User needs to restart one of the\n             nodes with its data cleared (or user can just remove the StorageID\n             value in \"VERSION\" file under the data directory of the datanode,\n             but this is might not work if VERSION file format has changed \n          */        \n           NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n               + \" is replaced by \" + nodeReg + \" with the same storageID \"\n-              + nodeReg.getStorageID());\n+              + nodeReg.getDatanodeUuid());\n         }\n         \n         boolean success \u003d false;\n         try {\n           // update cluster map\n           getNetworkTopology().remove(nodeS);\n           if(shouldCountVersion(nodeS)) {\n             decrementVersionCount(nodeS.getSoftwareVersion());\n           }\n           nodeS.updateRegInfo(nodeReg);\n \n           nodeS.setSoftwareVersion(nodeReg.getSoftwareVersion());\n           nodeS.setDisallowed(false); // Node is in the include list\n \n           // resolve network location\n           nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));\n           getNetworkTopology().add(nodeS);\n             \n           // also treat the registration message as a heartbeat\n           heartbeatManager.register(nodeS);\n           incrementVersionCount(nodeS.getSoftwareVersion());\n           checkDecommissioning(nodeS);\n           success \u003d true;\n         } finally {\n           if (!success) {\n             removeDatanode(nodeS);\n             wipeDatanode(nodeS);\n             countSoftwareVersions();\n           }\n         }\n         return;\n       } \n   \n       // this is a new datanode serving a new data storage\n-      if (\"\".equals(nodeReg.getStorageID())) {\n+      if (\"\".equals(nodeReg.getDatanodeUuid())) {\n         // this data storage has never been registered\n         // it is either empty or was created by pre-storageID version of DFS\n-        nodeReg.setStorageID(DatanodeStorage.newStorageID());\n+        nodeReg.setDatanodeUuid(DatanodeStorage.newStorageID());\n         if (NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\n               \"BLOCK* NameSystem.registerDatanode: \"\n-              + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n+              + \"new Datanode UUID \" + nodeReg.getDatanodeUuid() + \" assigned.\");\n         }\n       }\n       \n       DatanodeDescriptor nodeDescr \n         \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n       boolean success \u003d false;\n       try {\n         nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n         networktopology.add(nodeDescr);\n         nodeDescr.setSoftwareVersion(nodeReg.getSoftwareVersion());\n   \n         // register new datanode\n         addDatanode(nodeDescr);\n         checkDecommissioning(nodeDescr);\n         \n         // also treat the registration message as a heartbeat\n         // no need to update its timestamp\n         // because its is done when the descriptor is created\n         heartbeatManager.addDatanode(nodeDescr);\n         success \u003d true;\n         incrementVersionCount(nodeReg.getSoftwareVersion());\n       } finally {\n         if (!success) {\n           removeDatanode(nodeDescr);\n           wipeDatanode(nodeDescr);\n           countSoftwareVersions();\n         }\n       }\n     } catch (InvalidTopologyException e) {\n       // If the network location is invalid, clear the cached mappings\n       // so that we have a chance to re-add this DataNode with the\n       // correct network location later.\n       dnsToSwitchMapping.reloadCachedMappings();\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void registerDatanode(DatanodeRegistration nodeReg)\n      throws DisallowedDatanodeException {\n    InetAddress dnAddress \u003d Server.getRemoteIp();\n    if (dnAddress !\u003d null) {\n      // Mostly called inside an RPC, update ip and peer hostname\n      String hostname \u003d dnAddress.getHostName();\n      String ip \u003d dnAddress.getHostAddress();\n      if (!isNameResolved(dnAddress)) {\n        // Reject registration of unresolved datanode to prevent performance\n        // impact of repetitive DNS lookups later.\n        LOG.warn(\"Unresolved datanode registration from \" + ip);\n        throw new DisallowedDatanodeException(nodeReg);\n      }\n      // update node registration with the ip and hostname from rpc request\n      nodeReg.setIpAddr(ip);\n      nodeReg.setPeerHostName(hostname);\n    }\n    \n    try {\n      nodeReg.setExportedKeys(blockManager.getBlockKeys());\n  \n      // Checks if the node is not on the hosts list.  If it is not, then\n      // it will be disallowed from registering. \n      if (!hostFileManager.isIncluded(nodeReg)) {\n        throw new DisallowedDatanodeException(nodeReg);\n      }\n        \n      NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n          + nodeReg + \" storage \" + nodeReg.getDatanodeUuid());\n  \n      DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getDatanodeUuid());\n      DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n          nodeReg.getIpAddr(), nodeReg.getXferPort());\n        \n      if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n        NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n        // nodeN previously served a different data storage, \n        // which is not served by anybody anymore.\n        removeDatanode(nodeN);\n        // physically remove node from datanodeMap\n        wipeDatanode(nodeN);\n        nodeN \u003d null;\n      }\n  \n      if (nodeS !\u003d null) {\n        if (nodeN \u003d\u003d nodeS) {\n          // The same datanode has been just restarted to serve the same data \n          // storage. We do not need to remove old data blocks, the delta will\n          // be calculated on the next block report from the datanode\n          if(NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n                + \"node restarted.\");\n          }\n        } else {\n          // nodeS is found\n          /* The registering datanode is a replacement node for the existing \n            data storage, which from now on will be served by a new node.\n            If this message repeats, both nodes might have same storageID \n            by (insanely rare) random chance. User needs to restart one of the\n            nodes with its data cleared (or user can just remove the StorageID\n            value in \"VERSION\" file under the data directory of the datanode,\n            but this is might not work if VERSION file format has changed \n         */        \n          NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n              + \" is replaced by \" + nodeReg + \" with the same storageID \"\n              + nodeReg.getDatanodeUuid());\n        }\n        \n        boolean success \u003d false;\n        try {\n          // update cluster map\n          getNetworkTopology().remove(nodeS);\n          if(shouldCountVersion(nodeS)) {\n            decrementVersionCount(nodeS.getSoftwareVersion());\n          }\n          nodeS.updateRegInfo(nodeReg);\n\n          nodeS.setSoftwareVersion(nodeReg.getSoftwareVersion());\n          nodeS.setDisallowed(false); // Node is in the include list\n\n          // resolve network location\n          nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));\n          getNetworkTopology().add(nodeS);\n            \n          // also treat the registration message as a heartbeat\n          heartbeatManager.register(nodeS);\n          incrementVersionCount(nodeS.getSoftwareVersion());\n          checkDecommissioning(nodeS);\n          success \u003d true;\n        } finally {\n          if (!success) {\n            removeDatanode(nodeS);\n            wipeDatanode(nodeS);\n            countSoftwareVersions();\n          }\n        }\n        return;\n      } \n  \n      // this is a new datanode serving a new data storage\n      if (\"\".equals(nodeReg.getDatanodeUuid())) {\n        // this data storage has never been registered\n        // it is either empty or was created by pre-storageID version of DFS\n        nodeReg.setDatanodeUuid(DatanodeStorage.newStorageID());\n        if (NameNode.stateChangeLog.isDebugEnabled()) {\n          NameNode.stateChangeLog.debug(\n              \"BLOCK* NameSystem.registerDatanode: \"\n              + \"new Datanode UUID \" + nodeReg.getDatanodeUuid() + \" assigned.\");\n        }\n      }\n      \n      DatanodeDescriptor nodeDescr \n        \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n      boolean success \u003d false;\n      try {\n        nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n        networktopology.add(nodeDescr);\n        nodeDescr.setSoftwareVersion(nodeReg.getSoftwareVersion());\n  \n        // register new datanode\n        addDatanode(nodeDescr);\n        checkDecommissioning(nodeDescr);\n        \n        // also treat the registration message as a heartbeat\n        // no need to update its timestamp\n        // because its is done when the descriptor is created\n        heartbeatManager.addDatanode(nodeDescr);\n        success \u003d true;\n        incrementVersionCount(nodeReg.getSoftwareVersion());\n      } finally {\n        if (!success) {\n          removeDatanode(nodeDescr);\n          wipeDatanode(nodeDescr);\n          countSoftwareVersions();\n        }\n      }\n    } catch (InvalidTopologyException e) {\n      // If the network location is invalid, clear the cached mappings\n      // so that we have a chance to re-add this DataNode with the\n      // correct network location later.\n      dnsToSwitchMapping.reloadCachedMappings();\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "39252995c4d734e993e3fa5338e1a7816aee86fc": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3245. Add metrics and web UI for cluster version summary. Contributed by Ravi Prakash.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1517937 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/08/13 12:21 PM",
      "commitName": "39252995c4d734e993e3fa5338e1a7816aee86fc",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "07/06/13 1:01 PM",
      "commitNameOld": "2a76cddcd53ab10a79372b09595bb6df4bb44e01",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 80.97,
      "commitsBetweenForRepo": 489,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,134 +1,144 @@\n   public void registerDatanode(DatanodeRegistration nodeReg)\n       throws DisallowedDatanodeException {\n     InetAddress dnAddress \u003d Server.getRemoteIp();\n     if (dnAddress !\u003d null) {\n       // Mostly called inside an RPC, update ip and peer hostname\n       String hostname \u003d dnAddress.getHostName();\n       String ip \u003d dnAddress.getHostAddress();\n       if (!isNameResolved(dnAddress)) {\n         // Reject registration of unresolved datanode to prevent performance\n         // impact of repetitive DNS lookups later.\n         LOG.warn(\"Unresolved datanode registration from \" + ip);\n         throw new DisallowedDatanodeException(nodeReg);\n       }\n       // update node registration with the ip and hostname from rpc request\n       nodeReg.setIpAddr(ip);\n       nodeReg.setPeerHostName(hostname);\n     }\n     \n     try {\n       nodeReg.setExportedKeys(blockManager.getBlockKeys());\n   \n       // Checks if the node is not on the hosts list.  If it is not, then\n       // it will be disallowed from registering. \n       if (!hostFileManager.isIncluded(nodeReg)) {\n         throw new DisallowedDatanodeException(nodeReg);\n       }\n         \n       NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n           + nodeReg + \" storage \" + nodeReg.getStorageID());\n   \n       DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n       DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n           nodeReg.getIpAddr(), nodeReg.getXferPort());\n         \n       if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n         NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n         // nodeN previously served a different data storage, \n         // which is not served by anybody anymore.\n         removeDatanode(nodeN);\n         // physically remove node from datanodeMap\n         wipeDatanode(nodeN);\n         nodeN \u003d null;\n       }\n   \n       if (nodeS !\u003d null) {\n         if (nodeN \u003d\u003d nodeS) {\n           // The same datanode has been just restarted to serve the same data \n           // storage. We do not need to remove old data blocks, the delta will\n           // be calculated on the next block report from the datanode\n           if(NameNode.stateChangeLog.isDebugEnabled()) {\n             NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n                 + \"node restarted.\");\n           }\n         } else {\n           // nodeS is found\n           /* The registering datanode is a replacement node for the existing \n             data storage, which from now on will be served by a new node.\n             If this message repeats, both nodes might have same storageID \n             by (insanely rare) random chance. User needs to restart one of the\n             nodes with its data cleared (or user can just remove the StorageID\n             value in \"VERSION\" file under the data directory of the datanode,\n             but this is might not work if VERSION file format has changed \n          */        \n           NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n               + \" is replaced by \" + nodeReg + \" with the same storageID \"\n               + nodeReg.getStorageID());\n         }\n         \n         boolean success \u003d false;\n         try {\n           // update cluster map\n           getNetworkTopology().remove(nodeS);\n+          if(shouldCountVersion(nodeS)) {\n+            decrementVersionCount(nodeS.getSoftwareVersion());\n+          }\n           nodeS.updateRegInfo(nodeReg);\n+\n+          nodeS.setSoftwareVersion(nodeReg.getSoftwareVersion());\n           nodeS.setDisallowed(false); // Node is in the include list\n-          \n+\n           // resolve network location\n           nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));\n           getNetworkTopology().add(nodeS);\n             \n           // also treat the registration message as a heartbeat\n           heartbeatManager.register(nodeS);\n+          incrementVersionCount(nodeS.getSoftwareVersion());\n           checkDecommissioning(nodeS);\n           success \u003d true;\n         } finally {\n           if (!success) {\n             removeDatanode(nodeS);\n             wipeDatanode(nodeS);\n+            countSoftwareVersions();\n           }\n         }\n         return;\n       } \n   \n       // this is a new datanode serving a new data storage\n       if (\"\".equals(nodeReg.getStorageID())) {\n         // this data storage has never been registered\n         // it is either empty or was created by pre-storageID version of DFS\n         nodeReg.setStorageID(newStorageID());\n         if (NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\n               \"BLOCK* NameSystem.registerDatanode: \"\n               + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n         }\n       }\n       \n       DatanodeDescriptor nodeDescr \n         \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n       boolean success \u003d false;\n       try {\n         nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n         networktopology.add(nodeDescr);\n+        nodeDescr.setSoftwareVersion(nodeReg.getSoftwareVersion());\n   \n         // register new datanode\n         addDatanode(nodeDescr);\n         checkDecommissioning(nodeDescr);\n         \n         // also treat the registration message as a heartbeat\n         // no need to update its timestamp\n         // because its is done when the descriptor is created\n         heartbeatManager.addDatanode(nodeDescr);\n         success \u003d true;\n+        incrementVersionCount(nodeReg.getSoftwareVersion());\n       } finally {\n         if (!success) {\n           removeDatanode(nodeDescr);\n           wipeDatanode(nodeDescr);\n+          countSoftwareVersions();\n         }\n       }\n     } catch (InvalidTopologyException e) {\n       // If the network location is invalid, clear the cached mappings\n       // so that we have a chance to re-add this DataNode with the\n       // correct network location later.\n       dnsToSwitchMapping.reloadCachedMappings();\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void registerDatanode(DatanodeRegistration nodeReg)\n      throws DisallowedDatanodeException {\n    InetAddress dnAddress \u003d Server.getRemoteIp();\n    if (dnAddress !\u003d null) {\n      // Mostly called inside an RPC, update ip and peer hostname\n      String hostname \u003d dnAddress.getHostName();\n      String ip \u003d dnAddress.getHostAddress();\n      if (!isNameResolved(dnAddress)) {\n        // Reject registration of unresolved datanode to prevent performance\n        // impact of repetitive DNS lookups later.\n        LOG.warn(\"Unresolved datanode registration from \" + ip);\n        throw new DisallowedDatanodeException(nodeReg);\n      }\n      // update node registration with the ip and hostname from rpc request\n      nodeReg.setIpAddr(ip);\n      nodeReg.setPeerHostName(hostname);\n    }\n    \n    try {\n      nodeReg.setExportedKeys(blockManager.getBlockKeys());\n  \n      // Checks if the node is not on the hosts list.  If it is not, then\n      // it will be disallowed from registering. \n      if (!hostFileManager.isIncluded(nodeReg)) {\n        throw new DisallowedDatanodeException(nodeReg);\n      }\n        \n      NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n          + nodeReg + \" storage \" + nodeReg.getStorageID());\n  \n      DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n      DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n          nodeReg.getIpAddr(), nodeReg.getXferPort());\n        \n      if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n        NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n        // nodeN previously served a different data storage, \n        // which is not served by anybody anymore.\n        removeDatanode(nodeN);\n        // physically remove node from datanodeMap\n        wipeDatanode(nodeN);\n        nodeN \u003d null;\n      }\n  \n      if (nodeS !\u003d null) {\n        if (nodeN \u003d\u003d nodeS) {\n          // The same datanode has been just restarted to serve the same data \n          // storage. We do not need to remove old data blocks, the delta will\n          // be calculated on the next block report from the datanode\n          if(NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n                + \"node restarted.\");\n          }\n        } else {\n          // nodeS is found\n          /* The registering datanode is a replacement node for the existing \n            data storage, which from now on will be served by a new node.\n            If this message repeats, both nodes might have same storageID \n            by (insanely rare) random chance. User needs to restart one of the\n            nodes with its data cleared (or user can just remove the StorageID\n            value in \"VERSION\" file under the data directory of the datanode,\n            but this is might not work if VERSION file format has changed \n         */        \n          NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n              + \" is replaced by \" + nodeReg + \" with the same storageID \"\n              + nodeReg.getStorageID());\n        }\n        \n        boolean success \u003d false;\n        try {\n          // update cluster map\n          getNetworkTopology().remove(nodeS);\n          if(shouldCountVersion(nodeS)) {\n            decrementVersionCount(nodeS.getSoftwareVersion());\n          }\n          nodeS.updateRegInfo(nodeReg);\n\n          nodeS.setSoftwareVersion(nodeReg.getSoftwareVersion());\n          nodeS.setDisallowed(false); // Node is in the include list\n\n          // resolve network location\n          nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));\n          getNetworkTopology().add(nodeS);\n            \n          // also treat the registration message as a heartbeat\n          heartbeatManager.register(nodeS);\n          incrementVersionCount(nodeS.getSoftwareVersion());\n          checkDecommissioning(nodeS);\n          success \u003d true;\n        } finally {\n          if (!success) {\n            removeDatanode(nodeS);\n            wipeDatanode(nodeS);\n            countSoftwareVersions();\n          }\n        }\n        return;\n      } \n  \n      // this is a new datanode serving a new data storage\n      if (\"\".equals(nodeReg.getStorageID())) {\n        // this data storage has never been registered\n        // it is either empty or was created by pre-storageID version of DFS\n        nodeReg.setStorageID(newStorageID());\n        if (NameNode.stateChangeLog.isDebugEnabled()) {\n          NameNode.stateChangeLog.debug(\n              \"BLOCK* NameSystem.registerDatanode: \"\n              + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n        }\n      }\n      \n      DatanodeDescriptor nodeDescr \n        \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n      boolean success \u003d false;\n      try {\n        nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n        networktopology.add(nodeDescr);\n        nodeDescr.setSoftwareVersion(nodeReg.getSoftwareVersion());\n  \n        // register new datanode\n        addDatanode(nodeDescr);\n        checkDecommissioning(nodeDescr);\n        \n        // also treat the registration message as a heartbeat\n        // no need to update its timestamp\n        // because its is done when the descriptor is created\n        heartbeatManager.addDatanode(nodeDescr);\n        success \u003d true;\n        incrementVersionCount(nodeReg.getSoftwareVersion());\n      } finally {\n        if (!success) {\n          removeDatanode(nodeDescr);\n          wipeDatanode(nodeDescr);\n          countSoftwareVersions();\n        }\n      }\n    } catch (InvalidTopologyException e) {\n      // If the network location is invalid, clear the cached mappings\n      // so that we have a chance to re-add this DataNode with the\n      // correct network location later.\n      dnsToSwitchMapping.reloadCachedMappings();\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "6f699e8ea5d8a48c3daaf8dffa2292ce0524cfdb": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5115. Make StorageID a UUID.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2832@1516666 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "22/08/13 4:21 PM",
      "commitName": "6f699e8ea5d8a48c3daaf8dffa2292ce0524cfdb",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "07/06/13 1:01 PM",
      "commitNameOld": "2a76cddcd53ab10a79372b09595bb6df4bb44e01",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 76.14,
      "commitsBetweenForRepo": 463,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,134 +1,134 @@\n   public void registerDatanode(DatanodeRegistration nodeReg)\n       throws DisallowedDatanodeException {\n     InetAddress dnAddress \u003d Server.getRemoteIp();\n     if (dnAddress !\u003d null) {\n       // Mostly called inside an RPC, update ip and peer hostname\n       String hostname \u003d dnAddress.getHostName();\n       String ip \u003d dnAddress.getHostAddress();\n       if (!isNameResolved(dnAddress)) {\n         // Reject registration of unresolved datanode to prevent performance\n         // impact of repetitive DNS lookups later.\n         LOG.warn(\"Unresolved datanode registration from \" + ip);\n         throw new DisallowedDatanodeException(nodeReg);\n       }\n       // update node registration with the ip and hostname from rpc request\n       nodeReg.setIpAddr(ip);\n       nodeReg.setPeerHostName(hostname);\n     }\n     \n     try {\n       nodeReg.setExportedKeys(blockManager.getBlockKeys());\n   \n       // Checks if the node is not on the hosts list.  If it is not, then\n       // it will be disallowed from registering. \n       if (!hostFileManager.isIncluded(nodeReg)) {\n         throw new DisallowedDatanodeException(nodeReg);\n       }\n         \n       NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n           + nodeReg + \" storage \" + nodeReg.getStorageID());\n   \n       DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n       DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n           nodeReg.getIpAddr(), nodeReg.getXferPort());\n         \n       if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n         NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n         // nodeN previously served a different data storage, \n         // which is not served by anybody anymore.\n         removeDatanode(nodeN);\n         // physically remove node from datanodeMap\n         wipeDatanode(nodeN);\n         nodeN \u003d null;\n       }\n   \n       if (nodeS !\u003d null) {\n         if (nodeN \u003d\u003d nodeS) {\n           // The same datanode has been just restarted to serve the same data \n           // storage. We do not need to remove old data blocks, the delta will\n           // be calculated on the next block report from the datanode\n           if(NameNode.stateChangeLog.isDebugEnabled()) {\n             NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n                 + \"node restarted.\");\n           }\n         } else {\n           // nodeS is found\n           /* The registering datanode is a replacement node for the existing \n             data storage, which from now on will be served by a new node.\n             If this message repeats, both nodes might have same storageID \n             by (insanely rare) random chance. User needs to restart one of the\n             nodes with its data cleared (or user can just remove the StorageID\n             value in \"VERSION\" file under the data directory of the datanode,\n             but this is might not work if VERSION file format has changed \n          */        \n           NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n               + \" is replaced by \" + nodeReg + \" with the same storageID \"\n               + nodeReg.getStorageID());\n         }\n         \n         boolean success \u003d false;\n         try {\n           // update cluster map\n           getNetworkTopology().remove(nodeS);\n           nodeS.updateRegInfo(nodeReg);\n           nodeS.setDisallowed(false); // Node is in the include list\n           \n           // resolve network location\n           nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));\n           getNetworkTopology().add(nodeS);\n             \n           // also treat the registration message as a heartbeat\n           heartbeatManager.register(nodeS);\n           checkDecommissioning(nodeS);\n           success \u003d true;\n         } finally {\n           if (!success) {\n             removeDatanode(nodeS);\n             wipeDatanode(nodeS);\n           }\n         }\n         return;\n       } \n   \n       // this is a new datanode serving a new data storage\n       if (\"\".equals(nodeReg.getStorageID())) {\n         // this data storage has never been registered\n         // it is either empty or was created by pre-storageID version of DFS\n-        nodeReg.setStorageID(newStorageID());\n+        nodeReg.setStorageID(DatanodeStorage.newStorageID());\n         if (NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\n               \"BLOCK* NameSystem.registerDatanode: \"\n               + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n         }\n       }\n       \n       DatanodeDescriptor nodeDescr \n         \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n       boolean success \u003d false;\n       try {\n         nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n         networktopology.add(nodeDescr);\n   \n         // register new datanode\n         addDatanode(nodeDescr);\n         checkDecommissioning(nodeDescr);\n         \n         // also treat the registration message as a heartbeat\n         // no need to update its timestamp\n         // because its is done when the descriptor is created\n         heartbeatManager.addDatanode(nodeDescr);\n         success \u003d true;\n       } finally {\n         if (!success) {\n           removeDatanode(nodeDescr);\n           wipeDatanode(nodeDescr);\n         }\n       }\n     } catch (InvalidTopologyException e) {\n       // If the network location is invalid, clear the cached mappings\n       // so that we have a chance to re-add this DataNode with the\n       // correct network location later.\n       dnsToSwitchMapping.reloadCachedMappings();\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void registerDatanode(DatanodeRegistration nodeReg)\n      throws DisallowedDatanodeException {\n    InetAddress dnAddress \u003d Server.getRemoteIp();\n    if (dnAddress !\u003d null) {\n      // Mostly called inside an RPC, update ip and peer hostname\n      String hostname \u003d dnAddress.getHostName();\n      String ip \u003d dnAddress.getHostAddress();\n      if (!isNameResolved(dnAddress)) {\n        // Reject registration of unresolved datanode to prevent performance\n        // impact of repetitive DNS lookups later.\n        LOG.warn(\"Unresolved datanode registration from \" + ip);\n        throw new DisallowedDatanodeException(nodeReg);\n      }\n      // update node registration with the ip and hostname from rpc request\n      nodeReg.setIpAddr(ip);\n      nodeReg.setPeerHostName(hostname);\n    }\n    \n    try {\n      nodeReg.setExportedKeys(blockManager.getBlockKeys());\n  \n      // Checks if the node is not on the hosts list.  If it is not, then\n      // it will be disallowed from registering. \n      if (!hostFileManager.isIncluded(nodeReg)) {\n        throw new DisallowedDatanodeException(nodeReg);\n      }\n        \n      NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n          + nodeReg + \" storage \" + nodeReg.getStorageID());\n  \n      DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n      DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n          nodeReg.getIpAddr(), nodeReg.getXferPort());\n        \n      if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n        NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n        // nodeN previously served a different data storage, \n        // which is not served by anybody anymore.\n        removeDatanode(nodeN);\n        // physically remove node from datanodeMap\n        wipeDatanode(nodeN);\n        nodeN \u003d null;\n      }\n  \n      if (nodeS !\u003d null) {\n        if (nodeN \u003d\u003d nodeS) {\n          // The same datanode has been just restarted to serve the same data \n          // storage. We do not need to remove old data blocks, the delta will\n          // be calculated on the next block report from the datanode\n          if(NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n                + \"node restarted.\");\n          }\n        } else {\n          // nodeS is found\n          /* The registering datanode is a replacement node for the existing \n            data storage, which from now on will be served by a new node.\n            If this message repeats, both nodes might have same storageID \n            by (insanely rare) random chance. User needs to restart one of the\n            nodes with its data cleared (or user can just remove the StorageID\n            value in \"VERSION\" file under the data directory of the datanode,\n            but this is might not work if VERSION file format has changed \n         */        \n          NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n              + \" is replaced by \" + nodeReg + \" with the same storageID \"\n              + nodeReg.getStorageID());\n        }\n        \n        boolean success \u003d false;\n        try {\n          // update cluster map\n          getNetworkTopology().remove(nodeS);\n          nodeS.updateRegInfo(nodeReg);\n          nodeS.setDisallowed(false); // Node is in the include list\n          \n          // resolve network location\n          nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));\n          getNetworkTopology().add(nodeS);\n            \n          // also treat the registration message as a heartbeat\n          heartbeatManager.register(nodeS);\n          checkDecommissioning(nodeS);\n          success \u003d true;\n        } finally {\n          if (!success) {\n            removeDatanode(nodeS);\n            wipeDatanode(nodeS);\n          }\n        }\n        return;\n      } \n  \n      // this is a new datanode serving a new data storage\n      if (\"\".equals(nodeReg.getStorageID())) {\n        // this data storage has never been registered\n        // it is either empty or was created by pre-storageID version of DFS\n        nodeReg.setStorageID(DatanodeStorage.newStorageID());\n        if (NameNode.stateChangeLog.isDebugEnabled()) {\n          NameNode.stateChangeLog.debug(\n              \"BLOCK* NameSystem.registerDatanode: \"\n              + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n        }\n      }\n      \n      DatanodeDescriptor nodeDescr \n        \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n      boolean success \u003d false;\n      try {\n        nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n        networktopology.add(nodeDescr);\n  \n        // register new datanode\n        addDatanode(nodeDescr);\n        checkDecommissioning(nodeDescr);\n        \n        // also treat the registration message as a heartbeat\n        // no need to update its timestamp\n        // because its is done when the descriptor is created\n        heartbeatManager.addDatanode(nodeDescr);\n        success \u003d true;\n      } finally {\n        if (!success) {\n          removeDatanode(nodeDescr);\n          wipeDatanode(nodeDescr);\n        }\n      }\n    } catch (InvalidTopologyException e) {\n      // If the network location is invalid, clear the cached mappings\n      // so that we have a chance to re-add this DataNode with the\n      // correct network location later.\n      dnsToSwitchMapping.reloadCachedMappings();\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "a7bfb25d2bbab0a329712d1efb143edc49a4076d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3934. duplicative dfs_hosts entries handled wrong. (cmccabe)\n\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1489065 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "03/06/13 10:14 AM",
      "commitName": "a7bfb25d2bbab0a329712d1efb143edc49a4076d",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "28/05/13 1:17 PM",
      "commitNameOld": "4bb72210c266707806f3ce3e974968a9a137b25b",
      "commitAuthorOld": "Devaraj Das",
      "daysBetweenCommits": 5.87,
      "commitsBetweenForRepo": 49,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,134 +1,134 @@\n   public void registerDatanode(DatanodeRegistration nodeReg)\n       throws DisallowedDatanodeException {\n     InetAddress dnAddress \u003d Server.getRemoteIp();\n     if (dnAddress !\u003d null) {\n       // Mostly called inside an RPC, update ip and peer hostname\n       String hostname \u003d dnAddress.getHostName();\n       String ip \u003d dnAddress.getHostAddress();\n       if (!isNameResolved(dnAddress)) {\n         // Reject registration of unresolved datanode to prevent performance\n         // impact of repetitive DNS lookups later.\n         LOG.warn(\"Unresolved datanode registration from \" + ip);\n         throw new DisallowedDatanodeException(nodeReg);\n       }\n       // update node registration with the ip and hostname from rpc request\n       nodeReg.setIpAddr(ip);\n       nodeReg.setPeerHostName(hostname);\n     }\n     \n     try {\n       nodeReg.setExportedKeys(blockManager.getBlockKeys());\n   \n       // Checks if the node is not on the hosts list.  If it is not, then\n       // it will be disallowed from registering. \n-      if (!inHostsList(nodeReg)) {\n+      if (!hostFileManager.isIncluded(nodeReg)) {\n         throw new DisallowedDatanodeException(nodeReg);\n       }\n         \n       NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n           + nodeReg + \" storage \" + nodeReg.getStorageID());\n   \n       DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n       DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n           nodeReg.getIpAddr(), nodeReg.getXferPort());\n         \n       if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n         NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n         // nodeN previously served a different data storage, \n         // which is not served by anybody anymore.\n         removeDatanode(nodeN);\n         // physically remove node from datanodeMap\n         wipeDatanode(nodeN);\n         nodeN \u003d null;\n       }\n   \n       if (nodeS !\u003d null) {\n         if (nodeN \u003d\u003d nodeS) {\n           // The same datanode has been just restarted to serve the same data \n           // storage. We do not need to remove old data blocks, the delta will\n           // be calculated on the next block report from the datanode\n           if(NameNode.stateChangeLog.isDebugEnabled()) {\n             NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n                 + \"node restarted.\");\n           }\n         } else {\n           // nodeS is found\n           /* The registering datanode is a replacement node for the existing \n             data storage, which from now on will be served by a new node.\n             If this message repeats, both nodes might have same storageID \n             by (insanely rare) random chance. User needs to restart one of the\n             nodes with its data cleared (or user can just remove the StorageID\n             value in \"VERSION\" file under the data directory of the datanode,\n             but this is might not work if VERSION file format has changed \n          */        \n           NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n               + \" is replaced by \" + nodeReg + \" with the same storageID \"\n               + nodeReg.getStorageID());\n         }\n         \n         boolean success \u003d false;\n         try {\n           // update cluster map\n           getNetworkTopology().remove(nodeS);\n           nodeS.updateRegInfo(nodeReg);\n           nodeS.setDisallowed(false); // Node is in the include list\n           \n           // resolve network location\n           nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));\n           getNetworkTopology().add(nodeS);\n             \n           // also treat the registration message as a heartbeat\n           heartbeatManager.register(nodeS);\n           checkDecommissioning(nodeS);\n           success \u003d true;\n         } finally {\n           if (!success) {\n             removeDatanode(nodeS);\n             wipeDatanode(nodeS);\n           }\n         }\n         return;\n       } \n   \n       // this is a new datanode serving a new data storage\n       if (\"\".equals(nodeReg.getStorageID())) {\n         // this data storage has never been registered\n         // it is either empty or was created by pre-storageID version of DFS\n         nodeReg.setStorageID(newStorageID());\n         if (NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\n               \"BLOCK* NameSystem.registerDatanode: \"\n               + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n         }\n       }\n       \n       DatanodeDescriptor nodeDescr \n         \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n       boolean success \u003d false;\n       try {\n         nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n         networktopology.add(nodeDescr);\n   \n         // register new datanode\n         addDatanode(nodeDescr);\n         checkDecommissioning(nodeDescr);\n         \n         // also treat the registration message as a heartbeat\n         // no need to update its timestamp\n         // because its is done when the descriptor is created\n         heartbeatManager.addDatanode(nodeDescr);\n         success \u003d true;\n       } finally {\n         if (!success) {\n           removeDatanode(nodeDescr);\n           wipeDatanode(nodeDescr);\n         }\n       }\n     } catch (InvalidTopologyException e) {\n       // If the network location is invalid, clear the cached mappings\n       // so that we have a chance to re-add this DataNode with the\n       // correct network location later.\n       dnsToSwitchMapping.reloadCachedMappings();\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void registerDatanode(DatanodeRegistration nodeReg)\n      throws DisallowedDatanodeException {\n    InetAddress dnAddress \u003d Server.getRemoteIp();\n    if (dnAddress !\u003d null) {\n      // Mostly called inside an RPC, update ip and peer hostname\n      String hostname \u003d dnAddress.getHostName();\n      String ip \u003d dnAddress.getHostAddress();\n      if (!isNameResolved(dnAddress)) {\n        // Reject registration of unresolved datanode to prevent performance\n        // impact of repetitive DNS lookups later.\n        LOG.warn(\"Unresolved datanode registration from \" + ip);\n        throw new DisallowedDatanodeException(nodeReg);\n      }\n      // update node registration with the ip and hostname from rpc request\n      nodeReg.setIpAddr(ip);\n      nodeReg.setPeerHostName(hostname);\n    }\n    \n    try {\n      nodeReg.setExportedKeys(blockManager.getBlockKeys());\n  \n      // Checks if the node is not on the hosts list.  If it is not, then\n      // it will be disallowed from registering. \n      if (!hostFileManager.isIncluded(nodeReg)) {\n        throw new DisallowedDatanodeException(nodeReg);\n      }\n        \n      NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n          + nodeReg + \" storage \" + nodeReg.getStorageID());\n  \n      DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n      DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n          nodeReg.getIpAddr(), nodeReg.getXferPort());\n        \n      if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n        NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n        // nodeN previously served a different data storage, \n        // which is not served by anybody anymore.\n        removeDatanode(nodeN);\n        // physically remove node from datanodeMap\n        wipeDatanode(nodeN);\n        nodeN \u003d null;\n      }\n  \n      if (nodeS !\u003d null) {\n        if (nodeN \u003d\u003d nodeS) {\n          // The same datanode has been just restarted to serve the same data \n          // storage. We do not need to remove old data blocks, the delta will\n          // be calculated on the next block report from the datanode\n          if(NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n                + \"node restarted.\");\n          }\n        } else {\n          // nodeS is found\n          /* The registering datanode is a replacement node for the existing \n            data storage, which from now on will be served by a new node.\n            If this message repeats, both nodes might have same storageID \n            by (insanely rare) random chance. User needs to restart one of the\n            nodes with its data cleared (or user can just remove the StorageID\n            value in \"VERSION\" file under the data directory of the datanode,\n            but this is might not work if VERSION file format has changed \n         */        \n          NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n              + \" is replaced by \" + nodeReg + \" with the same storageID \"\n              + nodeReg.getStorageID());\n        }\n        \n        boolean success \u003d false;\n        try {\n          // update cluster map\n          getNetworkTopology().remove(nodeS);\n          nodeS.updateRegInfo(nodeReg);\n          nodeS.setDisallowed(false); // Node is in the include list\n          \n          // resolve network location\n          nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));\n          getNetworkTopology().add(nodeS);\n            \n          // also treat the registration message as a heartbeat\n          heartbeatManager.register(nodeS);\n          checkDecommissioning(nodeS);\n          success \u003d true;\n        } finally {\n          if (!success) {\n            removeDatanode(nodeS);\n            wipeDatanode(nodeS);\n          }\n        }\n        return;\n      } \n  \n      // this is a new datanode serving a new data storage\n      if (\"\".equals(nodeReg.getStorageID())) {\n        // this data storage has never been registered\n        // it is either empty or was created by pre-storageID version of DFS\n        nodeReg.setStorageID(newStorageID());\n        if (NameNode.stateChangeLog.isDebugEnabled()) {\n          NameNode.stateChangeLog.debug(\n              \"BLOCK* NameSystem.registerDatanode: \"\n              + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n        }\n      }\n      \n      DatanodeDescriptor nodeDescr \n        \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n      boolean success \u003d false;\n      try {\n        nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n        networktopology.add(nodeDescr);\n  \n        // register new datanode\n        addDatanode(nodeDescr);\n        checkDecommissioning(nodeDescr);\n        \n        // also treat the registration message as a heartbeat\n        // no need to update its timestamp\n        // because its is done when the descriptor is created\n        heartbeatManager.addDatanode(nodeDescr);\n        success \u003d true;\n      } finally {\n        if (!success) {\n          removeDatanode(nodeDescr);\n          wipeDatanode(nodeDescr);\n        }\n      }\n    } catch (InvalidTopologyException e) {\n      // If the network location is invalid, clear the cached mappings\n      // so that we have a chance to re-add this DataNode with the\n      // correct network location later.\n      dnsToSwitchMapping.reloadCachedMappings();\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "5d2ffde68e2c14ee33fa2ba4a34cb42fbd14b5ec": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2576. Enhances the DistributedFileSystem\u0027s create API so that clients can specify favored datanodes for a file\u0027s blocks. Contributed by Devaraj Das and Pritam Damania.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1476395 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "26/04/13 1:39 PM",
      "commitName": "5d2ffde68e2c14ee33fa2ba4a34cb42fbd14b5ec",
      "commitAuthor": "Devaraj Das",
      "commitDateOld": "18/03/13 10:20 AM",
      "commitNameOld": "64741f46352f25743bfb77f804a06970d355a177",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 39.14,
      "commitsBetweenForRepo": 219,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,134 +1,134 @@\n   public void registerDatanode(DatanodeRegistration nodeReg)\n       throws DisallowedDatanodeException {\n     InetAddress dnAddress \u003d Server.getRemoteIp();\n     if (dnAddress !\u003d null) {\n       // Mostly called inside an RPC, update ip and peer hostname\n       String hostname \u003d dnAddress.getHostName();\n       String ip \u003d dnAddress.getHostAddress();\n       if (!isNameResolved(dnAddress)) {\n         // Reject registration of unresolved datanode to prevent performance\n         // impact of repetitive DNS lookups later.\n         LOG.warn(\"Unresolved datanode registration from \" + ip);\n         throw new DisallowedDatanodeException(nodeReg);\n       }\n       // update node registration with the ip and hostname from rpc request\n       nodeReg.setIpAddr(ip);\n       nodeReg.setPeerHostName(hostname);\n     }\n     \n     try {\n       nodeReg.setExportedKeys(blockManager.getBlockKeys());\n   \n       // Checks if the node is not on the hosts list.  If it is not, then\n       // it will be disallowed from registering. \n       if (!inHostsList(nodeReg)) {\n         throw new DisallowedDatanodeException(nodeReg);\n       }\n         \n       NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n           + nodeReg + \" storage \" + nodeReg.getStorageID());\n   \n       DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n       DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n           nodeReg.getIpAddr(), nodeReg.getXferPort());\n         \n       if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n         NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n         // nodeN previously served a different data storage, \n         // which is not served by anybody anymore.\n         removeDatanode(nodeN);\n         // physically remove node from datanodeMap\n         wipeDatanode(nodeN);\n         nodeN \u003d null;\n       }\n   \n       if (nodeS !\u003d null) {\n         if (nodeN \u003d\u003d nodeS) {\n           // The same datanode has been just restarted to serve the same data \n           // storage. We do not need to remove old data blocks, the delta will\n           // be calculated on the next block report from the datanode\n           if(NameNode.stateChangeLog.isDebugEnabled()) {\n             NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n                 + \"node restarted.\");\n           }\n         } else {\n           // nodeS is found\n           /* The registering datanode is a replacement node for the existing \n             data storage, which from now on will be served by a new node.\n             If this message repeats, both nodes might have same storageID \n             by (insanely rare) random chance. User needs to restart one of the\n             nodes with its data cleared (or user can just remove the StorageID\n             value in \"VERSION\" file under the data directory of the datanode,\n             but this is might not work if VERSION file format has changed \n          */        \n           NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n               + \" is replaced by \" + nodeReg + \" with the same storageID \"\n               + nodeReg.getStorageID());\n         }\n         \n         boolean success \u003d false;\n         try {\n           // update cluster map\n           getNetworkTopology().remove(nodeS);\n           nodeS.updateRegInfo(nodeReg);\n           nodeS.setDisallowed(false); // Node is in the include list\n           \n           // resolve network location\n-          resolveNetworkLocation(nodeS);\n+          nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));\n           getNetworkTopology().add(nodeS);\n             \n           // also treat the registration message as a heartbeat\n           heartbeatManager.register(nodeS);\n           checkDecommissioning(nodeS);\n           success \u003d true;\n         } finally {\n           if (!success) {\n             removeDatanode(nodeS);\n             wipeDatanode(nodeS);\n           }\n         }\n         return;\n       } \n   \n       // this is a new datanode serving a new data storage\n       if (\"\".equals(nodeReg.getStorageID())) {\n         // this data storage has never been registered\n         // it is either empty or was created by pre-storageID version of DFS\n         nodeReg.setStorageID(newStorageID());\n         if (NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\n               \"BLOCK* NameSystem.registerDatanode: \"\n               + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n         }\n       }\n       \n       DatanodeDescriptor nodeDescr \n         \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n       boolean success \u003d false;\n       try {\n-        resolveNetworkLocation(nodeDescr);\n+        nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n         networktopology.add(nodeDescr);\n   \n         // register new datanode\n         addDatanode(nodeDescr);\n         checkDecommissioning(nodeDescr);\n         \n         // also treat the registration message as a heartbeat\n         // no need to update its timestamp\n         // because its is done when the descriptor is created\n         heartbeatManager.addDatanode(nodeDescr);\n         success \u003d true;\n       } finally {\n         if (!success) {\n           removeDatanode(nodeDescr);\n           wipeDatanode(nodeDescr);\n         }\n       }\n     } catch (InvalidTopologyException e) {\n       // If the network location is invalid, clear the cached mappings\n       // so that we have a chance to re-add this DataNode with the\n       // correct network location later.\n       dnsToSwitchMapping.reloadCachedMappings();\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void registerDatanode(DatanodeRegistration nodeReg)\n      throws DisallowedDatanodeException {\n    InetAddress dnAddress \u003d Server.getRemoteIp();\n    if (dnAddress !\u003d null) {\n      // Mostly called inside an RPC, update ip and peer hostname\n      String hostname \u003d dnAddress.getHostName();\n      String ip \u003d dnAddress.getHostAddress();\n      if (!isNameResolved(dnAddress)) {\n        // Reject registration of unresolved datanode to prevent performance\n        // impact of repetitive DNS lookups later.\n        LOG.warn(\"Unresolved datanode registration from \" + ip);\n        throw new DisallowedDatanodeException(nodeReg);\n      }\n      // update node registration with the ip and hostname from rpc request\n      nodeReg.setIpAddr(ip);\n      nodeReg.setPeerHostName(hostname);\n    }\n    \n    try {\n      nodeReg.setExportedKeys(blockManager.getBlockKeys());\n  \n      // Checks if the node is not on the hosts list.  If it is not, then\n      // it will be disallowed from registering. \n      if (!inHostsList(nodeReg)) {\n        throw new DisallowedDatanodeException(nodeReg);\n      }\n        \n      NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n          + nodeReg + \" storage \" + nodeReg.getStorageID());\n  \n      DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n      DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n          nodeReg.getIpAddr(), nodeReg.getXferPort());\n        \n      if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n        NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n        // nodeN previously served a different data storage, \n        // which is not served by anybody anymore.\n        removeDatanode(nodeN);\n        // physically remove node from datanodeMap\n        wipeDatanode(nodeN);\n        nodeN \u003d null;\n      }\n  \n      if (nodeS !\u003d null) {\n        if (nodeN \u003d\u003d nodeS) {\n          // The same datanode has been just restarted to serve the same data \n          // storage. We do not need to remove old data blocks, the delta will\n          // be calculated on the next block report from the datanode\n          if(NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n                + \"node restarted.\");\n          }\n        } else {\n          // nodeS is found\n          /* The registering datanode is a replacement node for the existing \n            data storage, which from now on will be served by a new node.\n            If this message repeats, both nodes might have same storageID \n            by (insanely rare) random chance. User needs to restart one of the\n            nodes with its data cleared (or user can just remove the StorageID\n            value in \"VERSION\" file under the data directory of the datanode,\n            but this is might not work if VERSION file format has changed \n         */        \n          NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n              + \" is replaced by \" + nodeReg + \" with the same storageID \"\n              + nodeReg.getStorageID());\n        }\n        \n        boolean success \u003d false;\n        try {\n          // update cluster map\n          getNetworkTopology().remove(nodeS);\n          nodeS.updateRegInfo(nodeReg);\n          nodeS.setDisallowed(false); // Node is in the include list\n          \n          // resolve network location\n          nodeS.setNetworkLocation(resolveNetworkLocation(nodeS));\n          getNetworkTopology().add(nodeS);\n            \n          // also treat the registration message as a heartbeat\n          heartbeatManager.register(nodeS);\n          checkDecommissioning(nodeS);\n          success \u003d true;\n        } finally {\n          if (!success) {\n            removeDatanode(nodeS);\n            wipeDatanode(nodeS);\n          }\n        }\n        return;\n      } \n  \n      // this is a new datanode serving a new data storage\n      if (\"\".equals(nodeReg.getStorageID())) {\n        // this data storage has never been registered\n        // it is either empty or was created by pre-storageID version of DFS\n        nodeReg.setStorageID(newStorageID());\n        if (NameNode.stateChangeLog.isDebugEnabled()) {\n          NameNode.stateChangeLog.debug(\n              \"BLOCK* NameSystem.registerDatanode: \"\n              + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n        }\n      }\n      \n      DatanodeDescriptor nodeDescr \n        \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n      boolean success \u003d false;\n      try {\n        nodeDescr.setNetworkLocation(resolveNetworkLocation(nodeDescr));\n        networktopology.add(nodeDescr);\n  \n        // register new datanode\n        addDatanode(nodeDescr);\n        checkDecommissioning(nodeDescr);\n        \n        // also treat the registration message as a heartbeat\n        // no need to update its timestamp\n        // because its is done when the descriptor is created\n        heartbeatManager.addDatanode(nodeDescr);\n        success \u003d true;\n      } finally {\n        if (!success) {\n          removeDatanode(nodeDescr);\n          wipeDatanode(nodeDescr);\n        }\n      }\n    } catch (InvalidTopologyException e) {\n      // If the network location is invalid, clear the cached mappings\n      // so that we have a chance to re-add this DataNode with the\n      // correct network location later.\n      dnsToSwitchMapping.reloadCachedMappings();\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "64741f46352f25743bfb77f804a06970d355a177": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4521. Invalid network toploogies should not be cached. Contributed by Colin Patrick McCabe.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1457878 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/03/13 10:20 AM",
      "commitName": "64741f46352f25743bfb77f804a06970d355a177",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "04/02/13 8:07 PM",
      "commitNameOld": "ef8dd606aba790a097f499dcd3bd129d385a961f",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 41.55,
      "commitsBetweenForRepo": 176,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,104 +1,134 @@\n   public void registerDatanode(DatanodeRegistration nodeReg)\n       throws DisallowedDatanodeException {\n     InetAddress dnAddress \u003d Server.getRemoteIp();\n     if (dnAddress !\u003d null) {\n       // Mostly called inside an RPC, update ip and peer hostname\n       String hostname \u003d dnAddress.getHostName();\n       String ip \u003d dnAddress.getHostAddress();\n       if (!isNameResolved(dnAddress)) {\n         // Reject registration of unresolved datanode to prevent performance\n         // impact of repetitive DNS lookups later.\n         LOG.warn(\"Unresolved datanode registration from \" + ip);\n         throw new DisallowedDatanodeException(nodeReg);\n       }\n       // update node registration with the ip and hostname from rpc request\n       nodeReg.setIpAddr(ip);\n       nodeReg.setPeerHostName(hostname);\n     }\n-\n-    nodeReg.setExportedKeys(blockManager.getBlockKeys());\n-\n-    // Checks if the node is not on the hosts list.  If it is not, then\n-    // it will be disallowed from registering. \n-    if (!inHostsList(nodeReg)) {\n-      throw new DisallowedDatanodeException(nodeReg);\n-    }\n-      \n-    NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n-        + nodeReg + \" storage \" + nodeReg.getStorageID());\n-\n-    DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n-    DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n-        nodeReg.getIpAddr(), nodeReg.getXferPort());\n-      \n-    if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n-      NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n-      // nodeN previously served a different data storage, \n-      // which is not served by anybody anymore.\n-      removeDatanode(nodeN);\n-      // physically remove node from datanodeMap\n-      wipeDatanode(nodeN);\n-      nodeN \u003d null;\n-    }\n-\n-    if (nodeS !\u003d null) {\n-      if (nodeN \u003d\u003d nodeS) {\n-        // The same datanode has been just restarted to serve the same data \n-        // storage. We do not need to remove old data blocks, the delta will\n-        // be calculated on the next block report from the datanode\n-        if(NameNode.stateChangeLog.isDebugEnabled()) {\n-          NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n-              + \"node restarted.\");\n-        }\n-      } else {\n-        // nodeS is found\n-        /* The registering datanode is a replacement node for the existing \n-          data storage, which from now on will be served by a new node.\n-          If this message repeats, both nodes might have same storageID \n-          by (insanely rare) random chance. User needs to restart one of the\n-          nodes with its data cleared (or user can just remove the StorageID\n-          value in \"VERSION\" file under the data directory of the datanode,\n-          but this is might not work if VERSION file format has changed \n-       */        \n-        NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n-            + \" is replaced by \" + nodeReg + \" with the same storageID \"\n-            + nodeReg.getStorageID());\n-      }\n-      // update cluster map\n-      getNetworkTopology().remove(nodeS);\n-      nodeS.updateRegInfo(nodeReg);\n-      nodeS.setDisallowed(false); // Node is in the include list\n-      \n-      // resolve network location\n-      resolveNetworkLocation(nodeS);\n-      getNetworkTopology().add(nodeS);\n-        \n-      // also treat the registration message as a heartbeat\n-      heartbeatManager.register(nodeS);\n-      checkDecommissioning(nodeS);\n-      return;\n-    } \n-\n-    // this is a new datanode serving a new data storage\n-    if (\"\".equals(nodeReg.getStorageID())) {\n-      // this data storage has never been registered\n-      // it is either empty or was created by pre-storageID version of DFS\n-      nodeReg.setStorageID(newStorageID());\n-      if (NameNode.stateChangeLog.isDebugEnabled()) {\n-        NameNode.stateChangeLog.debug(\n-            \"BLOCK* NameSystem.registerDatanode: \"\n-            + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n-      }\n-    }\n-    // register new datanode\n-    DatanodeDescriptor nodeDescr \n-      \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n-    resolveNetworkLocation(nodeDescr);\n-    addDatanode(nodeDescr);\n-    checkDecommissioning(nodeDescr);\n     \n-    // also treat the registration message as a heartbeat\n-    // no need to update its timestamp\n-    // because its is done when the descriptor is created\n-    heartbeatManager.addDatanode(nodeDescr);\n+    try {\n+      nodeReg.setExportedKeys(blockManager.getBlockKeys());\n+  \n+      // Checks if the node is not on the hosts list.  If it is not, then\n+      // it will be disallowed from registering. \n+      if (!inHostsList(nodeReg)) {\n+        throw new DisallowedDatanodeException(nodeReg);\n+      }\n+        \n+      NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n+          + nodeReg + \" storage \" + nodeReg.getStorageID());\n+  \n+      DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n+      DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n+          nodeReg.getIpAddr(), nodeReg.getXferPort());\n+        \n+      if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n+        NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n+        // nodeN previously served a different data storage, \n+        // which is not served by anybody anymore.\n+        removeDatanode(nodeN);\n+        // physically remove node from datanodeMap\n+        wipeDatanode(nodeN);\n+        nodeN \u003d null;\n+      }\n+  \n+      if (nodeS !\u003d null) {\n+        if (nodeN \u003d\u003d nodeS) {\n+          // The same datanode has been just restarted to serve the same data \n+          // storage. We do not need to remove old data blocks, the delta will\n+          // be calculated on the next block report from the datanode\n+          if(NameNode.stateChangeLog.isDebugEnabled()) {\n+            NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n+                + \"node restarted.\");\n+          }\n+        } else {\n+          // nodeS is found\n+          /* The registering datanode is a replacement node for the existing \n+            data storage, which from now on will be served by a new node.\n+            If this message repeats, both nodes might have same storageID \n+            by (insanely rare) random chance. User needs to restart one of the\n+            nodes with its data cleared (or user can just remove the StorageID\n+            value in \"VERSION\" file under the data directory of the datanode,\n+            but this is might not work if VERSION file format has changed \n+         */        \n+          NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n+              + \" is replaced by \" + nodeReg + \" with the same storageID \"\n+              + nodeReg.getStorageID());\n+        }\n+        \n+        boolean success \u003d false;\n+        try {\n+          // update cluster map\n+          getNetworkTopology().remove(nodeS);\n+          nodeS.updateRegInfo(nodeReg);\n+          nodeS.setDisallowed(false); // Node is in the include list\n+          \n+          // resolve network location\n+          resolveNetworkLocation(nodeS);\n+          getNetworkTopology().add(nodeS);\n+            \n+          // also treat the registration message as a heartbeat\n+          heartbeatManager.register(nodeS);\n+          checkDecommissioning(nodeS);\n+          success \u003d true;\n+        } finally {\n+          if (!success) {\n+            removeDatanode(nodeS);\n+            wipeDatanode(nodeS);\n+          }\n+        }\n+        return;\n+      } \n+  \n+      // this is a new datanode serving a new data storage\n+      if (\"\".equals(nodeReg.getStorageID())) {\n+        // this data storage has never been registered\n+        // it is either empty or was created by pre-storageID version of DFS\n+        nodeReg.setStorageID(newStorageID());\n+        if (NameNode.stateChangeLog.isDebugEnabled()) {\n+          NameNode.stateChangeLog.debug(\n+              \"BLOCK* NameSystem.registerDatanode: \"\n+              + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n+        }\n+      }\n+      \n+      DatanodeDescriptor nodeDescr \n+        \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n+      boolean success \u003d false;\n+      try {\n+        resolveNetworkLocation(nodeDescr);\n+        networktopology.add(nodeDescr);\n+  \n+        // register new datanode\n+        addDatanode(nodeDescr);\n+        checkDecommissioning(nodeDescr);\n+        \n+        // also treat the registration message as a heartbeat\n+        // no need to update its timestamp\n+        // because its is done when the descriptor is created\n+        heartbeatManager.addDatanode(nodeDescr);\n+        success \u003d true;\n+      } finally {\n+        if (!success) {\n+          removeDatanode(nodeDescr);\n+          wipeDatanode(nodeDescr);\n+        }\n+      }\n+    } catch (InvalidTopologyException e) {\n+      // If the network location is invalid, clear the cached mappings\n+      // so that we have a chance to re-add this DataNode with the\n+      // correct network location later.\n+      dnsToSwitchMapping.reloadCachedMappings();\n+      throw e;\n+    }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void registerDatanode(DatanodeRegistration nodeReg)\n      throws DisallowedDatanodeException {\n    InetAddress dnAddress \u003d Server.getRemoteIp();\n    if (dnAddress !\u003d null) {\n      // Mostly called inside an RPC, update ip and peer hostname\n      String hostname \u003d dnAddress.getHostName();\n      String ip \u003d dnAddress.getHostAddress();\n      if (!isNameResolved(dnAddress)) {\n        // Reject registration of unresolved datanode to prevent performance\n        // impact of repetitive DNS lookups later.\n        LOG.warn(\"Unresolved datanode registration from \" + ip);\n        throw new DisallowedDatanodeException(nodeReg);\n      }\n      // update node registration with the ip and hostname from rpc request\n      nodeReg.setIpAddr(ip);\n      nodeReg.setPeerHostName(hostname);\n    }\n    \n    try {\n      nodeReg.setExportedKeys(blockManager.getBlockKeys());\n  \n      // Checks if the node is not on the hosts list.  If it is not, then\n      // it will be disallowed from registering. \n      if (!inHostsList(nodeReg)) {\n        throw new DisallowedDatanodeException(nodeReg);\n      }\n        \n      NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n          + nodeReg + \" storage \" + nodeReg.getStorageID());\n  \n      DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n      DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n          nodeReg.getIpAddr(), nodeReg.getXferPort());\n        \n      if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n        NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n        // nodeN previously served a different data storage, \n        // which is not served by anybody anymore.\n        removeDatanode(nodeN);\n        // physically remove node from datanodeMap\n        wipeDatanode(nodeN);\n        nodeN \u003d null;\n      }\n  \n      if (nodeS !\u003d null) {\n        if (nodeN \u003d\u003d nodeS) {\n          // The same datanode has been just restarted to serve the same data \n          // storage. We do not need to remove old data blocks, the delta will\n          // be calculated on the next block report from the datanode\n          if(NameNode.stateChangeLog.isDebugEnabled()) {\n            NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n                + \"node restarted.\");\n          }\n        } else {\n          // nodeS is found\n          /* The registering datanode is a replacement node for the existing \n            data storage, which from now on will be served by a new node.\n            If this message repeats, both nodes might have same storageID \n            by (insanely rare) random chance. User needs to restart one of the\n            nodes with its data cleared (or user can just remove the StorageID\n            value in \"VERSION\" file under the data directory of the datanode,\n            but this is might not work if VERSION file format has changed \n         */        \n          NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n              + \" is replaced by \" + nodeReg + \" with the same storageID \"\n              + nodeReg.getStorageID());\n        }\n        \n        boolean success \u003d false;\n        try {\n          // update cluster map\n          getNetworkTopology().remove(nodeS);\n          nodeS.updateRegInfo(nodeReg);\n          nodeS.setDisallowed(false); // Node is in the include list\n          \n          // resolve network location\n          resolveNetworkLocation(nodeS);\n          getNetworkTopology().add(nodeS);\n            \n          // also treat the registration message as a heartbeat\n          heartbeatManager.register(nodeS);\n          checkDecommissioning(nodeS);\n          success \u003d true;\n        } finally {\n          if (!success) {\n            removeDatanode(nodeS);\n            wipeDatanode(nodeS);\n          }\n        }\n        return;\n      } \n  \n      // this is a new datanode serving a new data storage\n      if (\"\".equals(nodeReg.getStorageID())) {\n        // this data storage has never been registered\n        // it is either empty or was created by pre-storageID version of DFS\n        nodeReg.setStorageID(newStorageID());\n        if (NameNode.stateChangeLog.isDebugEnabled()) {\n          NameNode.stateChangeLog.debug(\n              \"BLOCK* NameSystem.registerDatanode: \"\n              + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n        }\n      }\n      \n      DatanodeDescriptor nodeDescr \n        \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n      boolean success \u003d false;\n      try {\n        resolveNetworkLocation(nodeDescr);\n        networktopology.add(nodeDescr);\n  \n        // register new datanode\n        addDatanode(nodeDescr);\n        checkDecommissioning(nodeDescr);\n        \n        // also treat the registration message as a heartbeat\n        // no need to update its timestamp\n        // because its is done when the descriptor is created\n        heartbeatManager.addDatanode(nodeDescr);\n        success \u003d true;\n      } finally {\n        if (!success) {\n          removeDatanode(nodeDescr);\n          wipeDatanode(nodeDescr);\n        }\n      }\n    } catch (InvalidTopologyException e) {\n      // If the network location is invalid, clear the cached mappings\n      // so that we have a chance to re-add this DataNode with the\n      // correct network location later.\n      dnsToSwitchMapping.reloadCachedMappings();\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "f31b8270db0dd1a4670ce6e921df18725d7a9248": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4269. Datanode rejects all datanode registrations from localhost in single-node developer setup on Windows. Contributed by Chris Nauroth.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1420492 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/12/12 4:14 PM",
      "commitName": "f31b8270db0dd1a4670ce6e921df18725d7a9248",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "28/11/12 11:19 AM",
      "commitNameOld": "1634e980af422c0af2f7c9c7280a77f2fbddc9c0",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 13.2,
      "commitsBetweenForRepo": 51,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,102 +1,104 @@\n   public void registerDatanode(DatanodeRegistration nodeReg)\n       throws DisallowedDatanodeException {\n     InetAddress dnAddress \u003d Server.getRemoteIp();\n     if (dnAddress !\u003d null) {\n       // Mostly called inside an RPC, update ip and peer hostname\n       String hostname \u003d dnAddress.getHostName();\n       String ip \u003d dnAddress.getHostAddress();\n-      if (hostname.equals(ip)) {\n+      if (!isNameResolved(dnAddress)) {\n+        // Reject registration of unresolved datanode to prevent performance\n+        // impact of repetitive DNS lookups later.\n         LOG.warn(\"Unresolved datanode registration from \" + ip);\n         throw new DisallowedDatanodeException(nodeReg);\n       }\n       // update node registration with the ip and hostname from rpc request\n       nodeReg.setIpAddr(ip);\n       nodeReg.setPeerHostName(hostname);\n     }\n \n     nodeReg.setExportedKeys(blockManager.getBlockKeys());\n \n     // Checks if the node is not on the hosts list.  If it is not, then\n     // it will be disallowed from registering. \n     if (!inHostsList(nodeReg)) {\n       throw new DisallowedDatanodeException(nodeReg);\n     }\n       \n     NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n         + nodeReg + \" storage \" + nodeReg.getStorageID());\n \n     DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n     DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n         nodeReg.getIpAddr(), nodeReg.getXferPort());\n       \n     if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n       NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n       // nodeN previously served a different data storage, \n       // which is not served by anybody anymore.\n       removeDatanode(nodeN);\n       // physically remove node from datanodeMap\n       wipeDatanode(nodeN);\n       nodeN \u003d null;\n     }\n \n     if (nodeS !\u003d null) {\n       if (nodeN \u003d\u003d nodeS) {\n         // The same datanode has been just restarted to serve the same data \n         // storage. We do not need to remove old data blocks, the delta will\n         // be calculated on the next block report from the datanode\n         if(NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n               + \"node restarted.\");\n         }\n       } else {\n         // nodeS is found\n         /* The registering datanode is a replacement node for the existing \n           data storage, which from now on will be served by a new node.\n           If this message repeats, both nodes might have same storageID \n           by (insanely rare) random chance. User needs to restart one of the\n           nodes with its data cleared (or user can just remove the StorageID\n           value in \"VERSION\" file under the data directory of the datanode,\n           but this is might not work if VERSION file format has changed \n        */        \n         NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n             + \" is replaced by \" + nodeReg + \" with the same storageID \"\n             + nodeReg.getStorageID());\n       }\n       // update cluster map\n       getNetworkTopology().remove(nodeS);\n       nodeS.updateRegInfo(nodeReg);\n       nodeS.setDisallowed(false); // Node is in the include list\n       \n       // resolve network location\n       resolveNetworkLocation(nodeS);\n       getNetworkTopology().add(nodeS);\n         \n       // also treat the registration message as a heartbeat\n       heartbeatManager.register(nodeS);\n       checkDecommissioning(nodeS);\n       return;\n     } \n \n     // this is a new datanode serving a new data storage\n     if (\"\".equals(nodeReg.getStorageID())) {\n       // this data storage has never been registered\n       // it is either empty or was created by pre-storageID version of DFS\n       nodeReg.setStorageID(newStorageID());\n       if (NameNode.stateChangeLog.isDebugEnabled()) {\n         NameNode.stateChangeLog.debug(\n             \"BLOCK* NameSystem.registerDatanode: \"\n             + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n       }\n     }\n     // register new datanode\n     DatanodeDescriptor nodeDescr \n       \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n     resolveNetworkLocation(nodeDescr);\n     addDatanode(nodeDescr);\n     checkDecommissioning(nodeDescr);\n     \n     // also treat the registration message as a heartbeat\n     // no need to update its timestamp\n     // because its is done when the descriptor is created\n     heartbeatManager.addDatanode(nodeDescr);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void registerDatanode(DatanodeRegistration nodeReg)\n      throws DisallowedDatanodeException {\n    InetAddress dnAddress \u003d Server.getRemoteIp();\n    if (dnAddress !\u003d null) {\n      // Mostly called inside an RPC, update ip and peer hostname\n      String hostname \u003d dnAddress.getHostName();\n      String ip \u003d dnAddress.getHostAddress();\n      if (!isNameResolved(dnAddress)) {\n        // Reject registration of unresolved datanode to prevent performance\n        // impact of repetitive DNS lookups later.\n        LOG.warn(\"Unresolved datanode registration from \" + ip);\n        throw new DisallowedDatanodeException(nodeReg);\n      }\n      // update node registration with the ip and hostname from rpc request\n      nodeReg.setIpAddr(ip);\n      nodeReg.setPeerHostName(hostname);\n    }\n\n    nodeReg.setExportedKeys(blockManager.getBlockKeys());\n\n    // Checks if the node is not on the hosts list.  If it is not, then\n    // it will be disallowed from registering. \n    if (!inHostsList(nodeReg)) {\n      throw new DisallowedDatanodeException(nodeReg);\n    }\n      \n    NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n        + nodeReg + \" storage \" + nodeReg.getStorageID());\n\n    DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n    DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n        nodeReg.getIpAddr(), nodeReg.getXferPort());\n      \n    if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n      NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n      // nodeN previously served a different data storage, \n      // which is not served by anybody anymore.\n      removeDatanode(nodeN);\n      // physically remove node from datanodeMap\n      wipeDatanode(nodeN);\n      nodeN \u003d null;\n    }\n\n    if (nodeS !\u003d null) {\n      if (nodeN \u003d\u003d nodeS) {\n        // The same datanode has been just restarted to serve the same data \n        // storage. We do not need to remove old data blocks, the delta will\n        // be calculated on the next block report from the datanode\n        if(NameNode.stateChangeLog.isDebugEnabled()) {\n          NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n              + \"node restarted.\");\n        }\n      } else {\n        // nodeS is found\n        /* The registering datanode is a replacement node for the existing \n          data storage, which from now on will be served by a new node.\n          If this message repeats, both nodes might have same storageID \n          by (insanely rare) random chance. User needs to restart one of the\n          nodes with its data cleared (or user can just remove the StorageID\n          value in \"VERSION\" file under the data directory of the datanode,\n          but this is might not work if VERSION file format has changed \n       */        \n        NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n            + \" is replaced by \" + nodeReg + \" with the same storageID \"\n            + nodeReg.getStorageID());\n      }\n      // update cluster map\n      getNetworkTopology().remove(nodeS);\n      nodeS.updateRegInfo(nodeReg);\n      nodeS.setDisallowed(false); // Node is in the include list\n      \n      // resolve network location\n      resolveNetworkLocation(nodeS);\n      getNetworkTopology().add(nodeS);\n        \n      // also treat the registration message as a heartbeat\n      heartbeatManager.register(nodeS);\n      checkDecommissioning(nodeS);\n      return;\n    } \n\n    // this is a new datanode serving a new data storage\n    if (\"\".equals(nodeReg.getStorageID())) {\n      // this data storage has never been registered\n      // it is either empty or was created by pre-storageID version of DFS\n      nodeReg.setStorageID(newStorageID());\n      if (NameNode.stateChangeLog.isDebugEnabled()) {\n        NameNode.stateChangeLog.debug(\n            \"BLOCK* NameSystem.registerDatanode: \"\n            + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n      }\n    }\n    // register new datanode\n    DatanodeDescriptor nodeDescr \n      \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n    resolveNetworkLocation(nodeDescr);\n    addDatanode(nodeDescr);\n    checkDecommissioning(nodeDescr);\n    \n    // also treat the registration message as a heartbeat\n    // no need to update its timestamp\n    // because its is done when the descriptor is created\n    heartbeatManager.addDatanode(nodeDescr);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "be94bf6b57895846853d3e0ebc5c33b4f725ae2c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3990.  NN\u0027s health report has severe performance problems (daryn)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1407333 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/11/12 4:53 PM",
      "commitName": "be94bf6b57895846853d3e0ebc5c33b4f725ae2c",
      "commitAuthor": "Daryn Sharp",
      "commitDateOld": "06/11/12 11:27 AM",
      "commitNameOld": "54b70db347c2ebf577919f2c42f171c6801e9ba1",
      "commitAuthorOld": "Daryn Sharp",
      "daysBetweenCommits": 2.23,
      "commitsBetweenForRepo": 22,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,98 +1,102 @@\n   public void registerDatanode(DatanodeRegistration nodeReg)\n       throws DisallowedDatanodeException {\n-    String dnAddress \u003d Server.getRemoteAddress();\n-    if (dnAddress \u003d\u003d null) {\n-      // Mostly called inside an RPC.\n-      // But if not, use address passed by the data-node.\n-      dnAddress \u003d nodeReg.getIpAddr();\n+    InetAddress dnAddress \u003d Server.getRemoteIp();\n+    if (dnAddress !\u003d null) {\n+      // Mostly called inside an RPC, update ip and peer hostname\n+      String hostname \u003d dnAddress.getHostName();\n+      String ip \u003d dnAddress.getHostAddress();\n+      if (hostname.equals(ip)) {\n+        LOG.warn(\"Unresolved datanode registration from \" + ip);\n+        throw new DisallowedDatanodeException(nodeReg);\n+      }\n+      // update node registration with the ip and hostname from rpc request\n+      nodeReg.setIpAddr(ip);\n+      nodeReg.setPeerHostName(hostname);\n     }\n \n-    // Update the IP to the address of the RPC request that is\n-    // registering this datanode.\n-    nodeReg.setIpAddr(dnAddress);\n     nodeReg.setExportedKeys(blockManager.getBlockKeys());\n \n     // Checks if the node is not on the hosts list.  If it is not, then\n     // it will be disallowed from registering. \n     if (!inHostsList(nodeReg)) {\n       throw new DisallowedDatanodeException(nodeReg);\n     }\n       \n     NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n         + nodeReg + \" storage \" + nodeReg.getStorageID());\n \n     DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n     DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n         nodeReg.getIpAddr(), nodeReg.getXferPort());\n       \n     if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n       NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n       // nodeN previously served a different data storage, \n       // which is not served by anybody anymore.\n       removeDatanode(nodeN);\n       // physically remove node from datanodeMap\n       wipeDatanode(nodeN);\n       nodeN \u003d null;\n     }\n \n     if (nodeS !\u003d null) {\n       if (nodeN \u003d\u003d nodeS) {\n         // The same datanode has been just restarted to serve the same data \n         // storage. We do not need to remove old data blocks, the delta will\n         // be calculated on the next block report from the datanode\n         if(NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n               + \"node restarted.\");\n         }\n       } else {\n         // nodeS is found\n         /* The registering datanode is a replacement node for the existing \n           data storage, which from now on will be served by a new node.\n           If this message repeats, both nodes might have same storageID \n           by (insanely rare) random chance. User needs to restart one of the\n           nodes with its data cleared (or user can just remove the StorageID\n           value in \"VERSION\" file under the data directory of the datanode,\n           but this is might not work if VERSION file format has changed \n        */        \n         NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n             + \" is replaced by \" + nodeReg + \" with the same storageID \"\n             + nodeReg.getStorageID());\n       }\n       // update cluster map\n       getNetworkTopology().remove(nodeS);\n       nodeS.updateRegInfo(nodeReg);\n       nodeS.setDisallowed(false); // Node is in the include list\n       \n       // resolve network location\n       resolveNetworkLocation(nodeS);\n       getNetworkTopology().add(nodeS);\n         \n       // also treat the registration message as a heartbeat\n       heartbeatManager.register(nodeS);\n       checkDecommissioning(nodeS);\n       return;\n     } \n \n     // this is a new datanode serving a new data storage\n     if (\"\".equals(nodeReg.getStorageID())) {\n       // this data storage has never been registered\n       // it is either empty or was created by pre-storageID version of DFS\n       nodeReg.setStorageID(newStorageID());\n       if (NameNode.stateChangeLog.isDebugEnabled()) {\n         NameNode.stateChangeLog.debug(\n             \"BLOCK* NameSystem.registerDatanode: \"\n             + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n       }\n     }\n     // register new datanode\n     DatanodeDescriptor nodeDescr \n       \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n     resolveNetworkLocation(nodeDescr);\n     addDatanode(nodeDescr);\n     checkDecommissioning(nodeDescr);\n     \n     // also treat the registration message as a heartbeat\n     // no need to update its timestamp\n     // because its is done when the descriptor is created\n     heartbeatManager.addDatanode(nodeDescr);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void registerDatanode(DatanodeRegistration nodeReg)\n      throws DisallowedDatanodeException {\n    InetAddress dnAddress \u003d Server.getRemoteIp();\n    if (dnAddress !\u003d null) {\n      // Mostly called inside an RPC, update ip and peer hostname\n      String hostname \u003d dnAddress.getHostName();\n      String ip \u003d dnAddress.getHostAddress();\n      if (hostname.equals(ip)) {\n        LOG.warn(\"Unresolved datanode registration from \" + ip);\n        throw new DisallowedDatanodeException(nodeReg);\n      }\n      // update node registration with the ip and hostname from rpc request\n      nodeReg.setIpAddr(ip);\n      nodeReg.setPeerHostName(hostname);\n    }\n\n    nodeReg.setExportedKeys(blockManager.getBlockKeys());\n\n    // Checks if the node is not on the hosts list.  If it is not, then\n    // it will be disallowed from registering. \n    if (!inHostsList(nodeReg)) {\n      throw new DisallowedDatanodeException(nodeReg);\n    }\n      \n    NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n        + nodeReg + \" storage \" + nodeReg.getStorageID());\n\n    DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n    DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n        nodeReg.getIpAddr(), nodeReg.getXferPort());\n      \n    if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n      NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n      // nodeN previously served a different data storage, \n      // which is not served by anybody anymore.\n      removeDatanode(nodeN);\n      // physically remove node from datanodeMap\n      wipeDatanode(nodeN);\n      nodeN \u003d null;\n    }\n\n    if (nodeS !\u003d null) {\n      if (nodeN \u003d\u003d nodeS) {\n        // The same datanode has been just restarted to serve the same data \n        // storage. We do not need to remove old data blocks, the delta will\n        // be calculated on the next block report from the datanode\n        if(NameNode.stateChangeLog.isDebugEnabled()) {\n          NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n              + \"node restarted.\");\n        }\n      } else {\n        // nodeS is found\n        /* The registering datanode is a replacement node for the existing \n          data storage, which from now on will be served by a new node.\n          If this message repeats, both nodes might have same storageID \n          by (insanely rare) random chance. User needs to restart one of the\n          nodes with its data cleared (or user can just remove the StorageID\n          value in \"VERSION\" file under the data directory of the datanode,\n          but this is might not work if VERSION file format has changed \n       */        \n        NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n            + \" is replaced by \" + nodeReg + \" with the same storageID \"\n            + nodeReg.getStorageID());\n      }\n      // update cluster map\n      getNetworkTopology().remove(nodeS);\n      nodeS.updateRegInfo(nodeReg);\n      nodeS.setDisallowed(false); // Node is in the include list\n      \n      // resolve network location\n      resolveNetworkLocation(nodeS);\n      getNetworkTopology().add(nodeS);\n        \n      // also treat the registration message as a heartbeat\n      heartbeatManager.register(nodeS);\n      checkDecommissioning(nodeS);\n      return;\n    } \n\n    // this is a new datanode serving a new data storage\n    if (\"\".equals(nodeReg.getStorageID())) {\n      // this data storage has never been registered\n      // it is either empty or was created by pre-storageID version of DFS\n      nodeReg.setStorageID(newStorageID());\n      if (NameNode.stateChangeLog.isDebugEnabled()) {\n        NameNode.stateChangeLog.debug(\n            \"BLOCK* NameSystem.registerDatanode: \"\n            + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n      }\n    }\n    // register new datanode\n    DatanodeDescriptor nodeDescr \n      \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n    resolveNetworkLocation(nodeDescr);\n    addDatanode(nodeDescr);\n    checkDecommissioning(nodeDescr);\n    \n    // also treat the registration message as a heartbeat\n    // no need to update its timestamp\n    // because its is done when the descriptor is created\n    heartbeatManager.addDatanode(nodeDescr);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "cea7bbc630deede93dbe6a1bbda56ad49de4f3de": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4122. Cleanup HDFS logs and reduce the size of logged messages. Contributed by Suresh Srinivas.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1403120 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/10/12 4:10 PM",
      "commitName": "cea7bbc630deede93dbe6a1bbda56ad49de4f3de",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "17/10/12 2:34 PM",
      "commitNameOld": "4d5600f6c714732d16bed29f0bc210eb72901545",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 11.07,
      "commitsBetweenForRepo": 61,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,102 +1,98 @@\n   public void registerDatanode(DatanodeRegistration nodeReg)\n       throws DisallowedDatanodeException {\n     String dnAddress \u003d Server.getRemoteAddress();\n     if (dnAddress \u003d\u003d null) {\n       // Mostly called inside an RPC.\n       // But if not, use address passed by the data-node.\n       dnAddress \u003d nodeReg.getIpAddr();\n     }\n \n     // Update the IP to the address of the RPC request that is\n     // registering this datanode.\n     nodeReg.setIpAddr(dnAddress);\n     nodeReg.setExportedKeys(blockManager.getBlockKeys());\n \n     // Checks if the node is not on the hosts list.  If it is not, then\n     // it will be disallowed from registering. \n     if (!inHostsList(nodeReg)) {\n       throw new DisallowedDatanodeException(nodeReg);\n     }\n       \n-    NameNode.stateChangeLog.info(\"BLOCK* NameSystem.registerDatanode: \"\n-        + \"node registration from \" + nodeReg\n-        + \" storage \" + nodeReg.getStorageID());\n+    NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n+        + nodeReg + \" storage \" + nodeReg.getStorageID());\n \n     DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n     DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n         nodeReg.getIpAddr(), nodeReg.getXferPort());\n       \n     if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n-      NameNode.LOG.info(\"BLOCK* NameSystem.registerDatanode: \"\n-                        + \"node from name: \" + nodeN);\n+      NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n       // nodeN previously served a different data storage, \n       // which is not served by anybody anymore.\n       removeDatanode(nodeN);\n       // physically remove node from datanodeMap\n       wipeDatanode(nodeN);\n       nodeN \u003d null;\n     }\n \n     if (nodeS !\u003d null) {\n       if (nodeN \u003d\u003d nodeS) {\n         // The same datanode has been just restarted to serve the same data \n         // storage. We do not need to remove old data blocks, the delta will\n         // be calculated on the next block report from the datanode\n         if(NameNode.stateChangeLog.isDebugEnabled()) {\n-          NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.registerDatanode: \"\n-                                        + \"node restarted.\");\n+          NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n+              + \"node restarted.\");\n         }\n       } else {\n         // nodeS is found\n         /* The registering datanode is a replacement node for the existing \n           data storage, which from now on will be served by a new node.\n           If this message repeats, both nodes might have same storageID \n           by (insanely rare) random chance. User needs to restart one of the\n           nodes with its data cleared (or user can just remove the StorageID\n           value in \"VERSION\" file under the data directory of the datanode,\n           but this is might not work if VERSION file format has changed \n        */        \n-        NameNode.stateChangeLog.info( \"BLOCK* NameSystem.registerDatanode: \"\n-                                      + \"node \" + nodeS\n-                                      + \" is replaced by \" + nodeReg + \n-                                      \" with the same storageID \" +\n-                                      nodeReg.getStorageID());\n+        NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n+            + \" is replaced by \" + nodeReg + \" with the same storageID \"\n+            + nodeReg.getStorageID());\n       }\n       // update cluster map\n       getNetworkTopology().remove(nodeS);\n       nodeS.updateRegInfo(nodeReg);\n       nodeS.setDisallowed(false); // Node is in the include list\n       \n       // resolve network location\n       resolveNetworkLocation(nodeS);\n       getNetworkTopology().add(nodeS);\n         \n       // also treat the registration message as a heartbeat\n       heartbeatManager.register(nodeS);\n       checkDecommissioning(nodeS);\n       return;\n     } \n \n     // this is a new datanode serving a new data storage\n     if (\"\".equals(nodeReg.getStorageID())) {\n       // this data storage has never been registered\n       // it is either empty or was created by pre-storageID version of DFS\n       nodeReg.setStorageID(newStorageID());\n       if (NameNode.stateChangeLog.isDebugEnabled()) {\n         NameNode.stateChangeLog.debug(\n             \"BLOCK* NameSystem.registerDatanode: \"\n             + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n       }\n     }\n     // register new datanode\n     DatanodeDescriptor nodeDescr \n       \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n     resolveNetworkLocation(nodeDescr);\n     addDatanode(nodeDescr);\n     checkDecommissioning(nodeDescr);\n     \n     // also treat the registration message as a heartbeat\n     // no need to update its timestamp\n     // because its is done when the descriptor is created\n     heartbeatManager.addDatanode(nodeDescr);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void registerDatanode(DatanodeRegistration nodeReg)\n      throws DisallowedDatanodeException {\n    String dnAddress \u003d Server.getRemoteAddress();\n    if (dnAddress \u003d\u003d null) {\n      // Mostly called inside an RPC.\n      // But if not, use address passed by the data-node.\n      dnAddress \u003d nodeReg.getIpAddr();\n    }\n\n    // Update the IP to the address of the RPC request that is\n    // registering this datanode.\n    nodeReg.setIpAddr(dnAddress);\n    nodeReg.setExportedKeys(blockManager.getBlockKeys());\n\n    // Checks if the node is not on the hosts list.  If it is not, then\n    // it will be disallowed from registering. \n    if (!inHostsList(nodeReg)) {\n      throw new DisallowedDatanodeException(nodeReg);\n    }\n      \n    NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: from \"\n        + nodeReg + \" storage \" + nodeReg.getStorageID());\n\n    DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n    DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n        nodeReg.getIpAddr(), nodeReg.getXferPort());\n      \n    if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n      NameNode.LOG.info(\"BLOCK* registerDatanode: \" + nodeN);\n      // nodeN previously served a different data storage, \n      // which is not served by anybody anymore.\n      removeDatanode(nodeN);\n      // physically remove node from datanodeMap\n      wipeDatanode(nodeN);\n      nodeN \u003d null;\n    }\n\n    if (nodeS !\u003d null) {\n      if (nodeN \u003d\u003d nodeS) {\n        // The same datanode has been just restarted to serve the same data \n        // storage. We do not need to remove old data blocks, the delta will\n        // be calculated on the next block report from the datanode\n        if(NameNode.stateChangeLog.isDebugEnabled()) {\n          NameNode.stateChangeLog.debug(\"BLOCK* registerDatanode: \"\n              + \"node restarted.\");\n        }\n      } else {\n        // nodeS is found\n        /* The registering datanode is a replacement node for the existing \n          data storage, which from now on will be served by a new node.\n          If this message repeats, both nodes might have same storageID \n          by (insanely rare) random chance. User needs to restart one of the\n          nodes with its data cleared (or user can just remove the StorageID\n          value in \"VERSION\" file under the data directory of the datanode,\n          but this is might not work if VERSION file format has changed \n       */        \n        NameNode.stateChangeLog.info(\"BLOCK* registerDatanode: \" + nodeS\n            + \" is replaced by \" + nodeReg + \" with the same storageID \"\n            + nodeReg.getStorageID());\n      }\n      // update cluster map\n      getNetworkTopology().remove(nodeS);\n      nodeS.updateRegInfo(nodeReg);\n      nodeS.setDisallowed(false); // Node is in the include list\n      \n      // resolve network location\n      resolveNetworkLocation(nodeS);\n      getNetworkTopology().add(nodeS);\n        \n      // also treat the registration message as a heartbeat\n      heartbeatManager.register(nodeS);\n      checkDecommissioning(nodeS);\n      return;\n    } \n\n    // this is a new datanode serving a new data storage\n    if (\"\".equals(nodeReg.getStorageID())) {\n      // this data storage has never been registered\n      // it is either empty or was created by pre-storageID version of DFS\n      nodeReg.setStorageID(newStorageID());\n      if (NameNode.stateChangeLog.isDebugEnabled()) {\n        NameNode.stateChangeLog.debug(\n            \"BLOCK* NameSystem.registerDatanode: \"\n            + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n      }\n    }\n    // register new datanode\n    DatanodeDescriptor nodeDescr \n      \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n    resolveNetworkLocation(nodeDescr);\n    addDatanode(nodeDescr);\n    checkDecommissioning(nodeDescr);\n    \n    // also treat the registration message as a heartbeat\n    // no need to update its timestamp\n    // because its is done when the descriptor is created\n    heartbeatManager.addDatanode(nodeDescr);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "4d5600f6c714732d16bed29f0bc210eb72901545": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4068. DatanodeID and DatanodeInfo member should be private. Contributed by Eli Collins\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1399443 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/10/12 2:34 PM",
      "commitName": "4d5600f6c714732d16bed29f0bc210eb72901545",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "16/10/12 12:39 PM",
      "commitNameOld": "0ef9c6f71a4397d60a024a9de6695d6e5f764c80",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 1.08,
      "commitsBetweenForRepo": 13,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,102 +1,102 @@\n   public void registerDatanode(DatanodeRegistration nodeReg)\n       throws DisallowedDatanodeException {\n     String dnAddress \u003d Server.getRemoteAddress();\n     if (dnAddress \u003d\u003d null) {\n       // Mostly called inside an RPC.\n       // But if not, use address passed by the data-node.\n       dnAddress \u003d nodeReg.getIpAddr();\n     }\n \n     // Update the IP to the address of the RPC request that is\n     // registering this datanode.\n     nodeReg.setIpAddr(dnAddress);\n     nodeReg.setExportedKeys(blockManager.getBlockKeys());\n \n     // Checks if the node is not on the hosts list.  If it is not, then\n     // it will be disallowed from registering. \n     if (!inHostsList(nodeReg)) {\n       throw new DisallowedDatanodeException(nodeReg);\n     }\n       \n     NameNode.stateChangeLog.info(\"BLOCK* NameSystem.registerDatanode: \"\n         + \"node registration from \" + nodeReg\n         + \" storage \" + nodeReg.getStorageID());\n \n     DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n     DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n         nodeReg.getIpAddr(), nodeReg.getXferPort());\n       \n     if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n       NameNode.LOG.info(\"BLOCK* NameSystem.registerDatanode: \"\n                         + \"node from name: \" + nodeN);\n       // nodeN previously served a different data storage, \n       // which is not served by anybody anymore.\n       removeDatanode(nodeN);\n       // physically remove node from datanodeMap\n       wipeDatanode(nodeN);\n       nodeN \u003d null;\n     }\n \n     if (nodeS !\u003d null) {\n       if (nodeN \u003d\u003d nodeS) {\n         // The same datanode has been just restarted to serve the same data \n         // storage. We do not need to remove old data blocks, the delta will\n         // be calculated on the next block report from the datanode\n         if(NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.registerDatanode: \"\n                                         + \"node restarted.\");\n         }\n       } else {\n         // nodeS is found\n         /* The registering datanode is a replacement node for the existing \n           data storage, which from now on will be served by a new node.\n           If this message repeats, both nodes might have same storageID \n           by (insanely rare) random chance. User needs to restart one of the\n           nodes with its data cleared (or user can just remove the StorageID\n           value in \"VERSION\" file under the data directory of the datanode,\n           but this is might not work if VERSION file format has changed \n        */        \n         NameNode.stateChangeLog.info( \"BLOCK* NameSystem.registerDatanode: \"\n                                       + \"node \" + nodeS\n                                       + \" is replaced by \" + nodeReg + \n                                       \" with the same storageID \" +\n                                       nodeReg.getStorageID());\n       }\n       // update cluster map\n       getNetworkTopology().remove(nodeS);\n       nodeS.updateRegInfo(nodeReg);\n       nodeS.setDisallowed(false); // Node is in the include list\n       \n       // resolve network location\n       resolveNetworkLocation(nodeS);\n       getNetworkTopology().add(nodeS);\n         \n       // also treat the registration message as a heartbeat\n       heartbeatManager.register(nodeS);\n-      checkDecommissioning(nodeS, dnAddress);\n+      checkDecommissioning(nodeS);\n       return;\n     } \n \n     // this is a new datanode serving a new data storage\n     if (\"\".equals(nodeReg.getStorageID())) {\n       // this data storage has never been registered\n       // it is either empty or was created by pre-storageID version of DFS\n       nodeReg.setStorageID(newStorageID());\n       if (NameNode.stateChangeLog.isDebugEnabled()) {\n         NameNode.stateChangeLog.debug(\n             \"BLOCK* NameSystem.registerDatanode: \"\n             + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n       }\n     }\n     // register new datanode\n     DatanodeDescriptor nodeDescr \n       \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n     resolveNetworkLocation(nodeDescr);\n     addDatanode(nodeDescr);\n-    checkDecommissioning(nodeDescr, dnAddress);\n+    checkDecommissioning(nodeDescr);\n     \n     // also treat the registration message as a heartbeat\n     // no need to update its timestamp\n     // because its is done when the descriptor is created\n     heartbeatManager.addDatanode(nodeDescr);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void registerDatanode(DatanodeRegistration nodeReg)\n      throws DisallowedDatanodeException {\n    String dnAddress \u003d Server.getRemoteAddress();\n    if (dnAddress \u003d\u003d null) {\n      // Mostly called inside an RPC.\n      // But if not, use address passed by the data-node.\n      dnAddress \u003d nodeReg.getIpAddr();\n    }\n\n    // Update the IP to the address of the RPC request that is\n    // registering this datanode.\n    nodeReg.setIpAddr(dnAddress);\n    nodeReg.setExportedKeys(blockManager.getBlockKeys());\n\n    // Checks if the node is not on the hosts list.  If it is not, then\n    // it will be disallowed from registering. \n    if (!inHostsList(nodeReg)) {\n      throw new DisallowedDatanodeException(nodeReg);\n    }\n      \n    NameNode.stateChangeLog.info(\"BLOCK* NameSystem.registerDatanode: \"\n        + \"node registration from \" + nodeReg\n        + \" storage \" + nodeReg.getStorageID());\n\n    DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n    DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n        nodeReg.getIpAddr(), nodeReg.getXferPort());\n      \n    if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n      NameNode.LOG.info(\"BLOCK* NameSystem.registerDatanode: \"\n                        + \"node from name: \" + nodeN);\n      // nodeN previously served a different data storage, \n      // which is not served by anybody anymore.\n      removeDatanode(nodeN);\n      // physically remove node from datanodeMap\n      wipeDatanode(nodeN);\n      nodeN \u003d null;\n    }\n\n    if (nodeS !\u003d null) {\n      if (nodeN \u003d\u003d nodeS) {\n        // The same datanode has been just restarted to serve the same data \n        // storage. We do not need to remove old data blocks, the delta will\n        // be calculated on the next block report from the datanode\n        if(NameNode.stateChangeLog.isDebugEnabled()) {\n          NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.registerDatanode: \"\n                                        + \"node restarted.\");\n        }\n      } else {\n        // nodeS is found\n        /* The registering datanode is a replacement node for the existing \n          data storage, which from now on will be served by a new node.\n          If this message repeats, both nodes might have same storageID \n          by (insanely rare) random chance. User needs to restart one of the\n          nodes with its data cleared (or user can just remove the StorageID\n          value in \"VERSION\" file under the data directory of the datanode,\n          but this is might not work if VERSION file format has changed \n       */        \n        NameNode.stateChangeLog.info( \"BLOCK* NameSystem.registerDatanode: \"\n                                      + \"node \" + nodeS\n                                      + \" is replaced by \" + nodeReg + \n                                      \" with the same storageID \" +\n                                      nodeReg.getStorageID());\n      }\n      // update cluster map\n      getNetworkTopology().remove(nodeS);\n      nodeS.updateRegInfo(nodeReg);\n      nodeS.setDisallowed(false); // Node is in the include list\n      \n      // resolve network location\n      resolveNetworkLocation(nodeS);\n      getNetworkTopology().add(nodeS);\n        \n      // also treat the registration message as a heartbeat\n      heartbeatManager.register(nodeS);\n      checkDecommissioning(nodeS);\n      return;\n    } \n\n    // this is a new datanode serving a new data storage\n    if (\"\".equals(nodeReg.getStorageID())) {\n      // this data storage has never been registered\n      // it is either empty or was created by pre-storageID version of DFS\n      nodeReg.setStorageID(newStorageID());\n      if (NameNode.stateChangeLog.isDebugEnabled()) {\n        NameNode.stateChangeLog.debug(\n            \"BLOCK* NameSystem.registerDatanode: \"\n            + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n      }\n    }\n    // register new datanode\n    DatanodeDescriptor nodeDescr \n      \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n    resolveNetworkLocation(nodeDescr);\n    addDatanode(nodeDescr);\n    checkDecommissioning(nodeDescr);\n    \n    // also treat the registration message as a heartbeat\n    // no need to update its timestamp\n    // because its is done when the descriptor is created\n    heartbeatManager.addDatanode(nodeDescr);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "08f35a04c69ea20913bb28b00a1827c77e0e23e3": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3224. Bug in check for DN re-registration with different storage ID. Contributed by Jason Lowe\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1396798 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/10/12 2:15 PM",
      "commitName": "08f35a04c69ea20913bb28b00a1827c77e0e23e3",
      "commitAuthor": "Jason Darrell Lowe",
      "commitDateOld": "12/09/12 10:46 PM",
      "commitNameOld": "d543140089690f4ec877d26981f4ad7908b33d1d",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 27.64,
      "commitsBetweenForRepo": 136,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,101 +1,102 @@\n   public void registerDatanode(DatanodeRegistration nodeReg)\n       throws DisallowedDatanodeException {\n     String dnAddress \u003d Server.getRemoteAddress();\n     if (dnAddress \u003d\u003d null) {\n       // Mostly called inside an RPC.\n       // But if not, use address passed by the data-node.\n       dnAddress \u003d nodeReg.getIpAddr();\n     }\n \n     // Update the IP to the address of the RPC request that is\n     // registering this datanode.\n     nodeReg.setIpAddr(dnAddress);\n     nodeReg.setExportedKeys(blockManager.getBlockKeys());\n \n     // Checks if the node is not on the hosts list.  If it is not, then\n     // it will be disallowed from registering. \n     if (!inHostsList(nodeReg)) {\n       throw new DisallowedDatanodeException(nodeReg);\n     }\n       \n     NameNode.stateChangeLog.info(\"BLOCK* NameSystem.registerDatanode: \"\n         + \"node registration from \" + nodeReg\n         + \" storage \" + nodeReg.getStorageID());\n \n     DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n-    DatanodeDescriptor nodeN \u003d getDatanodeByHost(nodeReg.getXferAddr());\n+    DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n+        nodeReg.getIpAddr(), nodeReg.getXferPort());\n       \n     if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n       NameNode.LOG.info(\"BLOCK* NameSystem.registerDatanode: \"\n                         + \"node from name: \" + nodeN);\n       // nodeN previously served a different data storage, \n       // which is not served by anybody anymore.\n       removeDatanode(nodeN);\n       // physically remove node from datanodeMap\n       wipeDatanode(nodeN);\n       nodeN \u003d null;\n     }\n \n     if (nodeS !\u003d null) {\n       if (nodeN \u003d\u003d nodeS) {\n         // The same datanode has been just restarted to serve the same data \n         // storage. We do not need to remove old data blocks, the delta will\n         // be calculated on the next block report from the datanode\n         if(NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.registerDatanode: \"\n                                         + \"node restarted.\");\n         }\n       } else {\n         // nodeS is found\n         /* The registering datanode is a replacement node for the existing \n           data storage, which from now on will be served by a new node.\n           If this message repeats, both nodes might have same storageID \n           by (insanely rare) random chance. User needs to restart one of the\n           nodes with its data cleared (or user can just remove the StorageID\n           value in \"VERSION\" file under the data directory of the datanode,\n           but this is might not work if VERSION file format has changed \n        */        \n         NameNode.stateChangeLog.info( \"BLOCK* NameSystem.registerDatanode: \"\n                                       + \"node \" + nodeS\n                                       + \" is replaced by \" + nodeReg + \n                                       \" with the same storageID \" +\n                                       nodeReg.getStorageID());\n       }\n       // update cluster map\n       getNetworkTopology().remove(nodeS);\n       nodeS.updateRegInfo(nodeReg);\n       nodeS.setDisallowed(false); // Node is in the include list\n       \n       // resolve network location\n       resolveNetworkLocation(nodeS);\n       getNetworkTopology().add(nodeS);\n         \n       // also treat the registration message as a heartbeat\n       heartbeatManager.register(nodeS);\n       checkDecommissioning(nodeS, dnAddress);\n       return;\n     } \n \n     // this is a new datanode serving a new data storage\n     if (\"\".equals(nodeReg.getStorageID())) {\n       // this data storage has never been registered\n       // it is either empty or was created by pre-storageID version of DFS\n       nodeReg.setStorageID(newStorageID());\n       if (NameNode.stateChangeLog.isDebugEnabled()) {\n         NameNode.stateChangeLog.debug(\n             \"BLOCK* NameSystem.registerDatanode: \"\n             + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n       }\n     }\n     // register new datanode\n     DatanodeDescriptor nodeDescr \n       \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n     resolveNetworkLocation(nodeDescr);\n     addDatanode(nodeDescr);\n     checkDecommissioning(nodeDescr, dnAddress);\n     \n     // also treat the registration message as a heartbeat\n     // no need to update its timestamp\n     // because its is done when the descriptor is created\n     heartbeatManager.addDatanode(nodeDescr);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void registerDatanode(DatanodeRegistration nodeReg)\n      throws DisallowedDatanodeException {\n    String dnAddress \u003d Server.getRemoteAddress();\n    if (dnAddress \u003d\u003d null) {\n      // Mostly called inside an RPC.\n      // But if not, use address passed by the data-node.\n      dnAddress \u003d nodeReg.getIpAddr();\n    }\n\n    // Update the IP to the address of the RPC request that is\n    // registering this datanode.\n    nodeReg.setIpAddr(dnAddress);\n    nodeReg.setExportedKeys(blockManager.getBlockKeys());\n\n    // Checks if the node is not on the hosts list.  If it is not, then\n    // it will be disallowed from registering. \n    if (!inHostsList(nodeReg)) {\n      throw new DisallowedDatanodeException(nodeReg);\n    }\n      \n    NameNode.stateChangeLog.info(\"BLOCK* NameSystem.registerDatanode: \"\n        + \"node registration from \" + nodeReg\n        + \" storage \" + nodeReg.getStorageID());\n\n    DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n    DatanodeDescriptor nodeN \u003d host2DatanodeMap.getDatanodeByXferAddr(\n        nodeReg.getIpAddr(), nodeReg.getXferPort());\n      \n    if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n      NameNode.LOG.info(\"BLOCK* NameSystem.registerDatanode: \"\n                        + \"node from name: \" + nodeN);\n      // nodeN previously served a different data storage, \n      // which is not served by anybody anymore.\n      removeDatanode(nodeN);\n      // physically remove node from datanodeMap\n      wipeDatanode(nodeN);\n      nodeN \u003d null;\n    }\n\n    if (nodeS !\u003d null) {\n      if (nodeN \u003d\u003d nodeS) {\n        // The same datanode has been just restarted to serve the same data \n        // storage. We do not need to remove old data blocks, the delta will\n        // be calculated on the next block report from the datanode\n        if(NameNode.stateChangeLog.isDebugEnabled()) {\n          NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.registerDatanode: \"\n                                        + \"node restarted.\");\n        }\n      } else {\n        // nodeS is found\n        /* The registering datanode is a replacement node for the existing \n          data storage, which from now on will be served by a new node.\n          If this message repeats, both nodes might have same storageID \n          by (insanely rare) random chance. User needs to restart one of the\n          nodes with its data cleared (or user can just remove the StorageID\n          value in \"VERSION\" file under the data directory of the datanode,\n          but this is might not work if VERSION file format has changed \n       */        \n        NameNode.stateChangeLog.info( \"BLOCK* NameSystem.registerDatanode: \"\n                                      + \"node \" + nodeS\n                                      + \" is replaced by \" + nodeReg + \n                                      \" with the same storageID \" +\n                                      nodeReg.getStorageID());\n      }\n      // update cluster map\n      getNetworkTopology().remove(nodeS);\n      nodeS.updateRegInfo(nodeReg);\n      nodeS.setDisallowed(false); // Node is in the include list\n      \n      // resolve network location\n      resolveNetworkLocation(nodeS);\n      getNetworkTopology().add(nodeS);\n        \n      // also treat the registration message as a heartbeat\n      heartbeatManager.register(nodeS);\n      checkDecommissioning(nodeS, dnAddress);\n      return;\n    } \n\n    // this is a new datanode serving a new data storage\n    if (\"\".equals(nodeReg.getStorageID())) {\n      // this data storage has never been registered\n      // it is either empty or was created by pre-storageID version of DFS\n      nodeReg.setStorageID(newStorageID());\n      if (NameNode.stateChangeLog.isDebugEnabled()) {\n        NameNode.stateChangeLog.debug(\n            \"BLOCK* NameSystem.registerDatanode: \"\n            + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n      }\n    }\n    // register new datanode\n    DatanodeDescriptor nodeDescr \n      \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n    resolveNetworkLocation(nodeDescr);\n    addDatanode(nodeDescr);\n    checkDecommissioning(nodeDescr, dnAddress);\n    \n    // also treat the registration message as a heartbeat\n    // no need to update its timestamp\n    // because its is done when the descriptor is created\n    heartbeatManager.addDatanode(nodeDescr);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "be7dd8333a7e56e732171db0781786987de03195": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3144. Refactor DatanodeID#getName by use. Contributed by Eli Collins\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1308205 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "01/04/12 3:12 PM",
      "commitName": "be7dd8333a7e56e732171db0781786987de03195",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "31/03/12 8:41 PM",
      "commitNameOld": "0663dbaac0a19719ddf9cd4290ba893bfca69da2",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 0.77,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,101 +1,101 @@\n   public void registerDatanode(DatanodeRegistration nodeReg)\n       throws DisallowedDatanodeException {\n     String dnAddress \u003d Server.getRemoteAddress();\n     if (dnAddress \u003d\u003d null) {\n       // Mostly called inside an RPC.\n       // But if not, use address passed by the data-node.\n-      dnAddress \u003d nodeReg.getHost();\n-    }      \n+      dnAddress \u003d nodeReg.getIpAddr();\n+    }\n+\n+    // Update the IP to the address of the RPC request that is\n+    // registering this datanode.\n+    nodeReg.setIpAddr(dnAddress);\n+    nodeReg.setExportedKeys(blockManager.getBlockKeys());\n \n     // Checks if the node is not on the hosts list.  If it is not, then\n     // it will be disallowed from registering. \n-    if (!inHostsList(nodeReg, dnAddress)) {\n+    if (!inHostsList(nodeReg)) {\n       throw new DisallowedDatanodeException(nodeReg);\n     }\n-\n-    // Update \"name\" with the IP address of the RPC request that\n-    // is registering this datanode.\n-    nodeReg.setName(dnAddress + \":\" + nodeReg.getPort());\n-    nodeReg.setExportedKeys(blockManager.getBlockKeys());\n       \n     NameNode.stateChangeLog.info(\"BLOCK* NameSystem.registerDatanode: \"\n-        + \"node registration from \" + nodeReg.getName()\n+        + \"node registration from \" + nodeReg\n         + \" storage \" + nodeReg.getStorageID());\n \n     DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n-    DatanodeDescriptor nodeN \u003d getDatanodeByHost(nodeReg.getName());\n+    DatanodeDescriptor nodeN \u003d getDatanodeByHost(nodeReg.getXferAddr());\n       \n     if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n       NameNode.LOG.info(\"BLOCK* NameSystem.registerDatanode: \"\n-                        + \"node from name: \" + nodeN.getName());\n+                        + \"node from name: \" + nodeN);\n       // nodeN previously served a different data storage, \n       // which is not served by anybody anymore.\n       removeDatanode(nodeN);\n       // physically remove node from datanodeMap\n       wipeDatanode(nodeN);\n       nodeN \u003d null;\n     }\n \n     if (nodeS !\u003d null) {\n       if (nodeN \u003d\u003d nodeS) {\n         // The same datanode has been just restarted to serve the same data \n         // storage. We do not need to remove old data blocks, the delta will\n         // be calculated on the next block report from the datanode\n         if(NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.registerDatanode: \"\n                                         + \"node restarted.\");\n         }\n       } else {\n         // nodeS is found\n         /* The registering datanode is a replacement node for the existing \n           data storage, which from now on will be served by a new node.\n           If this message repeats, both nodes might have same storageID \n           by (insanely rare) random chance. User needs to restart one of the\n           nodes with its data cleared (or user can just remove the StorageID\n           value in \"VERSION\" file under the data directory of the datanode,\n           but this is might not work if VERSION file format has changed \n        */        \n         NameNode.stateChangeLog.info( \"BLOCK* NameSystem.registerDatanode: \"\n-                                      + \"node \" + nodeS.getName()\n-                                      + \" is replaced by \" + nodeReg.getName() + \n+                                      + \"node \" + nodeS\n+                                      + \" is replaced by \" + nodeReg + \n                                       \" with the same storageID \" +\n                                       nodeReg.getStorageID());\n       }\n       // update cluster map\n       getNetworkTopology().remove(nodeS);\n       nodeS.updateRegInfo(nodeReg);\n       nodeS.setDisallowed(false); // Node is in the include list\n       \n       // resolve network location\n       resolveNetworkLocation(nodeS);\n       getNetworkTopology().add(nodeS);\n         \n       // also treat the registration message as a heartbeat\n       heartbeatManager.register(nodeS);\n       checkDecommissioning(nodeS, dnAddress);\n       return;\n     } \n \n     // this is a new datanode serving a new data storage\n     if (\"\".equals(nodeReg.getStorageID())) {\n       // this data storage has never been registered\n       // it is either empty or was created by pre-storageID version of DFS\n       nodeReg.setStorageID(newStorageID());\n       if (NameNode.stateChangeLog.isDebugEnabled()) {\n         NameNode.stateChangeLog.debug(\n             \"BLOCK* NameSystem.registerDatanode: \"\n             + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n       }\n     }\n     // register new datanode\n     DatanodeDescriptor nodeDescr \n       \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n     resolveNetworkLocation(nodeDescr);\n     addDatanode(nodeDescr);\n     checkDecommissioning(nodeDescr, dnAddress);\n     \n     // also treat the registration message as a heartbeat\n     // no need to update its timestamp\n     // because its is done when the descriptor is created\n     heartbeatManager.addDatanode(nodeDescr);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void registerDatanode(DatanodeRegistration nodeReg)\n      throws DisallowedDatanodeException {\n    String dnAddress \u003d Server.getRemoteAddress();\n    if (dnAddress \u003d\u003d null) {\n      // Mostly called inside an RPC.\n      // But if not, use address passed by the data-node.\n      dnAddress \u003d nodeReg.getIpAddr();\n    }\n\n    // Update the IP to the address of the RPC request that is\n    // registering this datanode.\n    nodeReg.setIpAddr(dnAddress);\n    nodeReg.setExportedKeys(blockManager.getBlockKeys());\n\n    // Checks if the node is not on the hosts list.  If it is not, then\n    // it will be disallowed from registering. \n    if (!inHostsList(nodeReg)) {\n      throw new DisallowedDatanodeException(nodeReg);\n    }\n      \n    NameNode.stateChangeLog.info(\"BLOCK* NameSystem.registerDatanode: \"\n        + \"node registration from \" + nodeReg\n        + \" storage \" + nodeReg.getStorageID());\n\n    DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n    DatanodeDescriptor nodeN \u003d getDatanodeByHost(nodeReg.getXferAddr());\n      \n    if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n      NameNode.LOG.info(\"BLOCK* NameSystem.registerDatanode: \"\n                        + \"node from name: \" + nodeN);\n      // nodeN previously served a different data storage, \n      // which is not served by anybody anymore.\n      removeDatanode(nodeN);\n      // physically remove node from datanodeMap\n      wipeDatanode(nodeN);\n      nodeN \u003d null;\n    }\n\n    if (nodeS !\u003d null) {\n      if (nodeN \u003d\u003d nodeS) {\n        // The same datanode has been just restarted to serve the same data \n        // storage. We do not need to remove old data blocks, the delta will\n        // be calculated on the next block report from the datanode\n        if(NameNode.stateChangeLog.isDebugEnabled()) {\n          NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.registerDatanode: \"\n                                        + \"node restarted.\");\n        }\n      } else {\n        // nodeS is found\n        /* The registering datanode is a replacement node for the existing \n          data storage, which from now on will be served by a new node.\n          If this message repeats, both nodes might have same storageID \n          by (insanely rare) random chance. User needs to restart one of the\n          nodes with its data cleared (or user can just remove the StorageID\n          value in \"VERSION\" file under the data directory of the datanode,\n          but this is might not work if VERSION file format has changed \n       */        \n        NameNode.stateChangeLog.info( \"BLOCK* NameSystem.registerDatanode: \"\n                                      + \"node \" + nodeS\n                                      + \" is replaced by \" + nodeReg + \n                                      \" with the same storageID \" +\n                                      nodeReg.getStorageID());\n      }\n      // update cluster map\n      getNetworkTopology().remove(nodeS);\n      nodeS.updateRegInfo(nodeReg);\n      nodeS.setDisallowed(false); // Node is in the include list\n      \n      // resolve network location\n      resolveNetworkLocation(nodeS);\n      getNetworkTopology().add(nodeS);\n        \n      // also treat the registration message as a heartbeat\n      heartbeatManager.register(nodeS);\n      checkDecommissioning(nodeS, dnAddress);\n      return;\n    } \n\n    // this is a new datanode serving a new data storage\n    if (\"\".equals(nodeReg.getStorageID())) {\n      // this data storage has never been registered\n      // it is either empty or was created by pre-storageID version of DFS\n      nodeReg.setStorageID(newStorageID());\n      if (NameNode.stateChangeLog.isDebugEnabled()) {\n        NameNode.stateChangeLog.debug(\n            \"BLOCK* NameSystem.registerDatanode: \"\n            + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n      }\n    }\n    // register new datanode\n    DatanodeDescriptor nodeDescr \n      \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n    resolveNetworkLocation(nodeDescr);\n    addDatanode(nodeDescr);\n    checkDecommissioning(nodeDescr, dnAddress);\n    \n    // also treat the registration message as a heartbeat\n    // no need to update its timestamp\n    // because its is done when the descriptor is created\n    heartbeatManager.addDatanode(nodeDescr);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "0663dbaac0a19719ddf9cd4290ba893bfca69da2": {
      "type": "Ymultichange(Yexceptionschange,Ybodychange)",
      "commitMessage": "HDFS-3171. The DatanodeID \"name\" field is overloaded. Contributed by Eli Collins\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1308014 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "31/03/12 8:41 PM",
      "commitName": "0663dbaac0a19719ddf9cd4290ba893bfca69da2",
      "commitAuthor": "Eli Collins",
      "subchanges": [
        {
          "type": "Yexceptionschange",
          "commitMessage": "HDFS-3171. The DatanodeID \"name\" field is overloaded. Contributed by Eli Collins\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1308014 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "31/03/12 8:41 PM",
          "commitName": "0663dbaac0a19719ddf9cd4290ba893bfca69da2",
          "commitAuthor": "Eli Collins",
          "commitDateOld": "31/03/12 12:58 PM",
          "commitNameOld": "8bd825bb6f35fd6fef397e3ccae0898bf7bed201",
          "commitAuthorOld": "Eli Collins",
          "daysBetweenCommits": 0.32,
          "commitsBetweenForRepo": 2,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,108 +1,101 @@\n-  public void registerDatanode(DatanodeRegistration nodeReg\n-      ) throws IOException {\n+  public void registerDatanode(DatanodeRegistration nodeReg)\n+      throws DisallowedDatanodeException {\n     String dnAddress \u003d Server.getRemoteAddress();\n     if (dnAddress \u003d\u003d null) {\n       // Mostly called inside an RPC.\n       // But if not, use address passed by the data-node.\n       dnAddress \u003d nodeReg.getHost();\n     }      \n \n     // Checks if the node is not on the hosts list.  If it is not, then\n     // it will be disallowed from registering. \n     if (!inHostsList(nodeReg, dnAddress)) {\n       throw new DisallowedDatanodeException(nodeReg);\n     }\n \n-    String hostName \u003d nodeReg.getHost();\n-      \n-    // update the datanode\u0027s name with ip:port\n-    DatanodeID dnReg \u003d new DatanodeID(dnAddress + \":\" + nodeReg.getPort(),\n-                                      hostName,\n-                                      nodeReg.getStorageID(),\n-                                      nodeReg.getInfoPort(),\n-                                      nodeReg.getIpcPort());\n-    nodeReg.updateRegInfo(dnReg);\n-    nodeReg.exportedKeys \u003d blockManager.getBlockKeys();\n+    // Update \"name\" with the IP address of the RPC request that\n+    // is registering this datanode.\n+    nodeReg.setName(dnAddress + \":\" + nodeReg.getPort());\n+    nodeReg.setExportedKeys(blockManager.getBlockKeys());\n       \n     NameNode.stateChangeLog.info(\"BLOCK* NameSystem.registerDatanode: \"\n         + \"node registration from \" + nodeReg.getName()\n         + \" storage \" + nodeReg.getStorageID());\n \n     DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n     DatanodeDescriptor nodeN \u003d getDatanodeByHost(nodeReg.getName());\n       \n     if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n       NameNode.LOG.info(\"BLOCK* NameSystem.registerDatanode: \"\n                         + \"node from name: \" + nodeN.getName());\n       // nodeN previously served a different data storage, \n       // which is not served by anybody anymore.\n       removeDatanode(nodeN);\n       // physically remove node from datanodeMap\n       wipeDatanode(nodeN);\n       nodeN \u003d null;\n     }\n \n     if (nodeS !\u003d null) {\n       if (nodeN \u003d\u003d nodeS) {\n         // The same datanode has been just restarted to serve the same data \n         // storage. We do not need to remove old data blocks, the delta will\n         // be calculated on the next block report from the datanode\n         if(NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.registerDatanode: \"\n                                         + \"node restarted.\");\n         }\n       } else {\n         // nodeS is found\n         /* The registering datanode is a replacement node for the existing \n           data storage, which from now on will be served by a new node.\n           If this message repeats, both nodes might have same storageID \n           by (insanely rare) random chance. User needs to restart one of the\n           nodes with its data cleared (or user can just remove the StorageID\n           value in \"VERSION\" file under the data directory of the datanode,\n           but this is might not work if VERSION file format has changed \n        */        \n         NameNode.stateChangeLog.info( \"BLOCK* NameSystem.registerDatanode: \"\n                                       + \"node \" + nodeS.getName()\n                                       + \" is replaced by \" + nodeReg.getName() + \n                                       \" with the same storageID \" +\n                                       nodeReg.getStorageID());\n       }\n       // update cluster map\n       getNetworkTopology().remove(nodeS);\n       nodeS.updateRegInfo(nodeReg);\n-      nodeS.setHostName(hostName);\n       nodeS.setDisallowed(false); // Node is in the include list\n       \n       // resolve network location\n       resolveNetworkLocation(nodeS);\n       getNetworkTopology().add(nodeS);\n         \n       // also treat the registration message as a heartbeat\n       heartbeatManager.register(nodeS);\n       checkDecommissioning(nodeS, dnAddress);\n       return;\n     } \n \n     // this is a new datanode serving a new data storage\n     if (\"\".equals(nodeReg.getStorageID())) {\n       // this data storage has never been registered\n       // it is either empty or was created by pre-storageID version of DFS\n       nodeReg.setStorageID(newStorageID());\n-      if(NameNode.stateChangeLog.isDebugEnabled()) {\n+      if (NameNode.stateChangeLog.isDebugEnabled()) {\n         NameNode.stateChangeLog.debug(\n             \"BLOCK* NameSystem.registerDatanode: \"\n             + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n       }\n     }\n     // register new datanode\n     DatanodeDescriptor nodeDescr \n       \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n     resolveNetworkLocation(nodeDescr);\n     addDatanode(nodeDescr);\n     checkDecommissioning(nodeDescr, dnAddress);\n     \n     // also treat the registration message as a heartbeat\n     // no need to update its timestamp\n     // because its is done when the descriptor is created\n     heartbeatManager.addDatanode(nodeDescr);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void registerDatanode(DatanodeRegistration nodeReg)\n      throws DisallowedDatanodeException {\n    String dnAddress \u003d Server.getRemoteAddress();\n    if (dnAddress \u003d\u003d null) {\n      // Mostly called inside an RPC.\n      // But if not, use address passed by the data-node.\n      dnAddress \u003d nodeReg.getHost();\n    }      \n\n    // Checks if the node is not on the hosts list.  If it is not, then\n    // it will be disallowed from registering. \n    if (!inHostsList(nodeReg, dnAddress)) {\n      throw new DisallowedDatanodeException(nodeReg);\n    }\n\n    // Update \"name\" with the IP address of the RPC request that\n    // is registering this datanode.\n    nodeReg.setName(dnAddress + \":\" + nodeReg.getPort());\n    nodeReg.setExportedKeys(blockManager.getBlockKeys());\n      \n    NameNode.stateChangeLog.info(\"BLOCK* NameSystem.registerDatanode: \"\n        + \"node registration from \" + nodeReg.getName()\n        + \" storage \" + nodeReg.getStorageID());\n\n    DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n    DatanodeDescriptor nodeN \u003d getDatanodeByHost(nodeReg.getName());\n      \n    if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n      NameNode.LOG.info(\"BLOCK* NameSystem.registerDatanode: \"\n                        + \"node from name: \" + nodeN.getName());\n      // nodeN previously served a different data storage, \n      // which is not served by anybody anymore.\n      removeDatanode(nodeN);\n      // physically remove node from datanodeMap\n      wipeDatanode(nodeN);\n      nodeN \u003d null;\n    }\n\n    if (nodeS !\u003d null) {\n      if (nodeN \u003d\u003d nodeS) {\n        // The same datanode has been just restarted to serve the same data \n        // storage. We do not need to remove old data blocks, the delta will\n        // be calculated on the next block report from the datanode\n        if(NameNode.stateChangeLog.isDebugEnabled()) {\n          NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.registerDatanode: \"\n                                        + \"node restarted.\");\n        }\n      } else {\n        // nodeS is found\n        /* The registering datanode is a replacement node for the existing \n          data storage, which from now on will be served by a new node.\n          If this message repeats, both nodes might have same storageID \n          by (insanely rare) random chance. User needs to restart one of the\n          nodes with its data cleared (or user can just remove the StorageID\n          value in \"VERSION\" file under the data directory of the datanode,\n          but this is might not work if VERSION file format has changed \n       */        \n        NameNode.stateChangeLog.info( \"BLOCK* NameSystem.registerDatanode: \"\n                                      + \"node \" + nodeS.getName()\n                                      + \" is replaced by \" + nodeReg.getName() + \n                                      \" with the same storageID \" +\n                                      nodeReg.getStorageID());\n      }\n      // update cluster map\n      getNetworkTopology().remove(nodeS);\n      nodeS.updateRegInfo(nodeReg);\n      nodeS.setDisallowed(false); // Node is in the include list\n      \n      // resolve network location\n      resolveNetworkLocation(nodeS);\n      getNetworkTopology().add(nodeS);\n        \n      // also treat the registration message as a heartbeat\n      heartbeatManager.register(nodeS);\n      checkDecommissioning(nodeS, dnAddress);\n      return;\n    } \n\n    // this is a new datanode serving a new data storage\n    if (\"\".equals(nodeReg.getStorageID())) {\n      // this data storage has never been registered\n      // it is either empty or was created by pre-storageID version of DFS\n      nodeReg.setStorageID(newStorageID());\n      if (NameNode.stateChangeLog.isDebugEnabled()) {\n        NameNode.stateChangeLog.debug(\n            \"BLOCK* NameSystem.registerDatanode: \"\n            + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n      }\n    }\n    // register new datanode\n    DatanodeDescriptor nodeDescr \n      \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n    resolveNetworkLocation(nodeDescr);\n    addDatanode(nodeDescr);\n    checkDecommissioning(nodeDescr, dnAddress);\n    \n    // also treat the registration message as a heartbeat\n    // no need to update its timestamp\n    // because its is done when the descriptor is created\n    heartbeatManager.addDatanode(nodeDescr);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
          "extendedDetails": {
            "oldValue": "[IOException]",
            "newValue": "[DisallowedDatanodeException]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-3171. The DatanodeID \"name\" field is overloaded. Contributed by Eli Collins\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1308014 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "31/03/12 8:41 PM",
          "commitName": "0663dbaac0a19719ddf9cd4290ba893bfca69da2",
          "commitAuthor": "Eli Collins",
          "commitDateOld": "31/03/12 12:58 PM",
          "commitNameOld": "8bd825bb6f35fd6fef397e3ccae0898bf7bed201",
          "commitAuthorOld": "Eli Collins",
          "daysBetweenCommits": 0.32,
          "commitsBetweenForRepo": 2,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,108 +1,101 @@\n-  public void registerDatanode(DatanodeRegistration nodeReg\n-      ) throws IOException {\n+  public void registerDatanode(DatanodeRegistration nodeReg)\n+      throws DisallowedDatanodeException {\n     String dnAddress \u003d Server.getRemoteAddress();\n     if (dnAddress \u003d\u003d null) {\n       // Mostly called inside an RPC.\n       // But if not, use address passed by the data-node.\n       dnAddress \u003d nodeReg.getHost();\n     }      \n \n     // Checks if the node is not on the hosts list.  If it is not, then\n     // it will be disallowed from registering. \n     if (!inHostsList(nodeReg, dnAddress)) {\n       throw new DisallowedDatanodeException(nodeReg);\n     }\n \n-    String hostName \u003d nodeReg.getHost();\n-      \n-    // update the datanode\u0027s name with ip:port\n-    DatanodeID dnReg \u003d new DatanodeID(dnAddress + \":\" + nodeReg.getPort(),\n-                                      hostName,\n-                                      nodeReg.getStorageID(),\n-                                      nodeReg.getInfoPort(),\n-                                      nodeReg.getIpcPort());\n-    nodeReg.updateRegInfo(dnReg);\n-    nodeReg.exportedKeys \u003d blockManager.getBlockKeys();\n+    // Update \"name\" with the IP address of the RPC request that\n+    // is registering this datanode.\n+    nodeReg.setName(dnAddress + \":\" + nodeReg.getPort());\n+    nodeReg.setExportedKeys(blockManager.getBlockKeys());\n       \n     NameNode.stateChangeLog.info(\"BLOCK* NameSystem.registerDatanode: \"\n         + \"node registration from \" + nodeReg.getName()\n         + \" storage \" + nodeReg.getStorageID());\n \n     DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n     DatanodeDescriptor nodeN \u003d getDatanodeByHost(nodeReg.getName());\n       \n     if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n       NameNode.LOG.info(\"BLOCK* NameSystem.registerDatanode: \"\n                         + \"node from name: \" + nodeN.getName());\n       // nodeN previously served a different data storage, \n       // which is not served by anybody anymore.\n       removeDatanode(nodeN);\n       // physically remove node from datanodeMap\n       wipeDatanode(nodeN);\n       nodeN \u003d null;\n     }\n \n     if (nodeS !\u003d null) {\n       if (nodeN \u003d\u003d nodeS) {\n         // The same datanode has been just restarted to serve the same data \n         // storage. We do not need to remove old data blocks, the delta will\n         // be calculated on the next block report from the datanode\n         if(NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.registerDatanode: \"\n                                         + \"node restarted.\");\n         }\n       } else {\n         // nodeS is found\n         /* The registering datanode is a replacement node for the existing \n           data storage, which from now on will be served by a new node.\n           If this message repeats, both nodes might have same storageID \n           by (insanely rare) random chance. User needs to restart one of the\n           nodes with its data cleared (or user can just remove the StorageID\n           value in \"VERSION\" file under the data directory of the datanode,\n           but this is might not work if VERSION file format has changed \n        */        \n         NameNode.stateChangeLog.info( \"BLOCK* NameSystem.registerDatanode: \"\n                                       + \"node \" + nodeS.getName()\n                                       + \" is replaced by \" + nodeReg.getName() + \n                                       \" with the same storageID \" +\n                                       nodeReg.getStorageID());\n       }\n       // update cluster map\n       getNetworkTopology().remove(nodeS);\n       nodeS.updateRegInfo(nodeReg);\n-      nodeS.setHostName(hostName);\n       nodeS.setDisallowed(false); // Node is in the include list\n       \n       // resolve network location\n       resolveNetworkLocation(nodeS);\n       getNetworkTopology().add(nodeS);\n         \n       // also treat the registration message as a heartbeat\n       heartbeatManager.register(nodeS);\n       checkDecommissioning(nodeS, dnAddress);\n       return;\n     } \n \n     // this is a new datanode serving a new data storage\n     if (\"\".equals(nodeReg.getStorageID())) {\n       // this data storage has never been registered\n       // it is either empty or was created by pre-storageID version of DFS\n       nodeReg.setStorageID(newStorageID());\n-      if(NameNode.stateChangeLog.isDebugEnabled()) {\n+      if (NameNode.stateChangeLog.isDebugEnabled()) {\n         NameNode.stateChangeLog.debug(\n             \"BLOCK* NameSystem.registerDatanode: \"\n             + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n       }\n     }\n     // register new datanode\n     DatanodeDescriptor nodeDescr \n       \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n     resolveNetworkLocation(nodeDescr);\n     addDatanode(nodeDescr);\n     checkDecommissioning(nodeDescr, dnAddress);\n     \n     // also treat the registration message as a heartbeat\n     // no need to update its timestamp\n     // because its is done when the descriptor is created\n     heartbeatManager.addDatanode(nodeDescr);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void registerDatanode(DatanodeRegistration nodeReg)\n      throws DisallowedDatanodeException {\n    String dnAddress \u003d Server.getRemoteAddress();\n    if (dnAddress \u003d\u003d null) {\n      // Mostly called inside an RPC.\n      // But if not, use address passed by the data-node.\n      dnAddress \u003d nodeReg.getHost();\n    }      \n\n    // Checks if the node is not on the hosts list.  If it is not, then\n    // it will be disallowed from registering. \n    if (!inHostsList(nodeReg, dnAddress)) {\n      throw new DisallowedDatanodeException(nodeReg);\n    }\n\n    // Update \"name\" with the IP address of the RPC request that\n    // is registering this datanode.\n    nodeReg.setName(dnAddress + \":\" + nodeReg.getPort());\n    nodeReg.setExportedKeys(blockManager.getBlockKeys());\n      \n    NameNode.stateChangeLog.info(\"BLOCK* NameSystem.registerDatanode: \"\n        + \"node registration from \" + nodeReg.getName()\n        + \" storage \" + nodeReg.getStorageID());\n\n    DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n    DatanodeDescriptor nodeN \u003d getDatanodeByHost(nodeReg.getName());\n      \n    if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n      NameNode.LOG.info(\"BLOCK* NameSystem.registerDatanode: \"\n                        + \"node from name: \" + nodeN.getName());\n      // nodeN previously served a different data storage, \n      // which is not served by anybody anymore.\n      removeDatanode(nodeN);\n      // physically remove node from datanodeMap\n      wipeDatanode(nodeN);\n      nodeN \u003d null;\n    }\n\n    if (nodeS !\u003d null) {\n      if (nodeN \u003d\u003d nodeS) {\n        // The same datanode has been just restarted to serve the same data \n        // storage. We do not need to remove old data blocks, the delta will\n        // be calculated on the next block report from the datanode\n        if(NameNode.stateChangeLog.isDebugEnabled()) {\n          NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.registerDatanode: \"\n                                        + \"node restarted.\");\n        }\n      } else {\n        // nodeS is found\n        /* The registering datanode is a replacement node for the existing \n          data storage, which from now on will be served by a new node.\n          If this message repeats, both nodes might have same storageID \n          by (insanely rare) random chance. User needs to restart one of the\n          nodes with its data cleared (or user can just remove the StorageID\n          value in \"VERSION\" file under the data directory of the datanode,\n          but this is might not work if VERSION file format has changed \n       */        \n        NameNode.stateChangeLog.info( \"BLOCK* NameSystem.registerDatanode: \"\n                                      + \"node \" + nodeS.getName()\n                                      + \" is replaced by \" + nodeReg.getName() + \n                                      \" with the same storageID \" +\n                                      nodeReg.getStorageID());\n      }\n      // update cluster map\n      getNetworkTopology().remove(nodeS);\n      nodeS.updateRegInfo(nodeReg);\n      nodeS.setDisallowed(false); // Node is in the include list\n      \n      // resolve network location\n      resolveNetworkLocation(nodeS);\n      getNetworkTopology().add(nodeS);\n        \n      // also treat the registration message as a heartbeat\n      heartbeatManager.register(nodeS);\n      checkDecommissioning(nodeS, dnAddress);\n      return;\n    } \n\n    // this is a new datanode serving a new data storage\n    if (\"\".equals(nodeReg.getStorageID())) {\n      // this data storage has never been registered\n      // it is either empty or was created by pre-storageID version of DFS\n      nodeReg.setStorageID(newStorageID());\n      if (NameNode.stateChangeLog.isDebugEnabled()) {\n        NameNode.stateChangeLog.debug(\n            \"BLOCK* NameSystem.registerDatanode: \"\n            + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n      }\n    }\n    // register new datanode\n    DatanodeDescriptor nodeDescr \n      \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n    resolveNetworkLocation(nodeDescr);\n    addDatanode(nodeDescr);\n    checkDecommissioning(nodeDescr, dnAddress);\n    \n    // also treat the registration message as a heartbeat\n    // no need to update its timestamp\n    // because its is done when the descriptor is created\n    heartbeatManager.addDatanode(nodeDescr);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "8bd825bb6f35fd6fef397e3ccae0898bf7bed201": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3164. Move DatanodeInfo#hostName to DatanodeID. Contributed by Eli Collins\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1307890 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "31/03/12 12:58 PM",
      "commitName": "8bd825bb6f35fd6fef397e3ccae0898bf7bed201",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "27/12/11 10:18 AM",
      "commitNameOld": "a500ba50c248ec71bbb5301c6ca0fce0652af042",
      "commitAuthorOld": "",
      "daysBetweenCommits": 95.07,
      "commitsBetweenForRepo": 681,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,107 +1,108 @@\n   public void registerDatanode(DatanodeRegistration nodeReg\n       ) throws IOException {\n     String dnAddress \u003d Server.getRemoteAddress();\n     if (dnAddress \u003d\u003d null) {\n       // Mostly called inside an RPC.\n       // But if not, use address passed by the data-node.\n       dnAddress \u003d nodeReg.getHost();\n     }      \n \n     // Checks if the node is not on the hosts list.  If it is not, then\n     // it will be disallowed from registering. \n     if (!inHostsList(nodeReg, dnAddress)) {\n       throw new DisallowedDatanodeException(nodeReg);\n     }\n \n     String hostName \u003d nodeReg.getHost();\n       \n     // update the datanode\u0027s name with ip:port\n     DatanodeID dnReg \u003d new DatanodeID(dnAddress + \":\" + nodeReg.getPort(),\n+                                      hostName,\n                                       nodeReg.getStorageID(),\n                                       nodeReg.getInfoPort(),\n                                       nodeReg.getIpcPort());\n     nodeReg.updateRegInfo(dnReg);\n     nodeReg.exportedKeys \u003d blockManager.getBlockKeys();\n       \n     NameNode.stateChangeLog.info(\"BLOCK* NameSystem.registerDatanode: \"\n         + \"node registration from \" + nodeReg.getName()\n         + \" storage \" + nodeReg.getStorageID());\n \n     DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n     DatanodeDescriptor nodeN \u003d getDatanodeByHost(nodeReg.getName());\n       \n     if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n       NameNode.LOG.info(\"BLOCK* NameSystem.registerDatanode: \"\n                         + \"node from name: \" + nodeN.getName());\n       // nodeN previously served a different data storage, \n       // which is not served by anybody anymore.\n       removeDatanode(nodeN);\n       // physically remove node from datanodeMap\n       wipeDatanode(nodeN);\n       nodeN \u003d null;\n     }\n \n     if (nodeS !\u003d null) {\n       if (nodeN \u003d\u003d nodeS) {\n         // The same datanode has been just restarted to serve the same data \n         // storage. We do not need to remove old data blocks, the delta will\n         // be calculated on the next block report from the datanode\n         if(NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.registerDatanode: \"\n                                         + \"node restarted.\");\n         }\n       } else {\n         // nodeS is found\n         /* The registering datanode is a replacement node for the existing \n           data storage, which from now on will be served by a new node.\n           If this message repeats, both nodes might have same storageID \n           by (insanely rare) random chance. User needs to restart one of the\n           nodes with its data cleared (or user can just remove the StorageID\n           value in \"VERSION\" file under the data directory of the datanode,\n           but this is might not work if VERSION file format has changed \n        */        \n         NameNode.stateChangeLog.info( \"BLOCK* NameSystem.registerDatanode: \"\n                                       + \"node \" + nodeS.getName()\n                                       + \" is replaced by \" + nodeReg.getName() + \n                                       \" with the same storageID \" +\n                                       nodeReg.getStorageID());\n       }\n       // update cluster map\n       getNetworkTopology().remove(nodeS);\n       nodeS.updateRegInfo(nodeReg);\n       nodeS.setHostName(hostName);\n       nodeS.setDisallowed(false); // Node is in the include list\n       \n       // resolve network location\n       resolveNetworkLocation(nodeS);\n       getNetworkTopology().add(nodeS);\n         \n       // also treat the registration message as a heartbeat\n       heartbeatManager.register(nodeS);\n       checkDecommissioning(nodeS, dnAddress);\n       return;\n     } \n \n     // this is a new datanode serving a new data storage\n-    if (nodeReg.getStorageID().equals(\"\")) {\n+    if (\"\".equals(nodeReg.getStorageID())) {\n       // this data storage has never been registered\n       // it is either empty or was created by pre-storageID version of DFS\n-      nodeReg.storageID \u003d newStorageID();\n+      nodeReg.setStorageID(newStorageID());\n       if(NameNode.stateChangeLog.isDebugEnabled()) {\n         NameNode.stateChangeLog.debug(\n             \"BLOCK* NameSystem.registerDatanode: \"\n             + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n       }\n     }\n     // register new datanode\n     DatanodeDescriptor nodeDescr \n-      \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK, hostName);\n+      \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n     resolveNetworkLocation(nodeDescr);\n     addDatanode(nodeDescr);\n     checkDecommissioning(nodeDescr, dnAddress);\n     \n     // also treat the registration message as a heartbeat\n     // no need to update its timestamp\n     // because its is done when the descriptor is created\n     heartbeatManager.addDatanode(nodeDescr);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void registerDatanode(DatanodeRegistration nodeReg\n      ) throws IOException {\n    String dnAddress \u003d Server.getRemoteAddress();\n    if (dnAddress \u003d\u003d null) {\n      // Mostly called inside an RPC.\n      // But if not, use address passed by the data-node.\n      dnAddress \u003d nodeReg.getHost();\n    }      \n\n    // Checks if the node is not on the hosts list.  If it is not, then\n    // it will be disallowed from registering. \n    if (!inHostsList(nodeReg, dnAddress)) {\n      throw new DisallowedDatanodeException(nodeReg);\n    }\n\n    String hostName \u003d nodeReg.getHost();\n      \n    // update the datanode\u0027s name with ip:port\n    DatanodeID dnReg \u003d new DatanodeID(dnAddress + \":\" + nodeReg.getPort(),\n                                      hostName,\n                                      nodeReg.getStorageID(),\n                                      nodeReg.getInfoPort(),\n                                      nodeReg.getIpcPort());\n    nodeReg.updateRegInfo(dnReg);\n    nodeReg.exportedKeys \u003d blockManager.getBlockKeys();\n      \n    NameNode.stateChangeLog.info(\"BLOCK* NameSystem.registerDatanode: \"\n        + \"node registration from \" + nodeReg.getName()\n        + \" storage \" + nodeReg.getStorageID());\n\n    DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n    DatanodeDescriptor nodeN \u003d getDatanodeByHost(nodeReg.getName());\n      \n    if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n      NameNode.LOG.info(\"BLOCK* NameSystem.registerDatanode: \"\n                        + \"node from name: \" + nodeN.getName());\n      // nodeN previously served a different data storage, \n      // which is not served by anybody anymore.\n      removeDatanode(nodeN);\n      // physically remove node from datanodeMap\n      wipeDatanode(nodeN);\n      nodeN \u003d null;\n    }\n\n    if (nodeS !\u003d null) {\n      if (nodeN \u003d\u003d nodeS) {\n        // The same datanode has been just restarted to serve the same data \n        // storage. We do not need to remove old data blocks, the delta will\n        // be calculated on the next block report from the datanode\n        if(NameNode.stateChangeLog.isDebugEnabled()) {\n          NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.registerDatanode: \"\n                                        + \"node restarted.\");\n        }\n      } else {\n        // nodeS is found\n        /* The registering datanode is a replacement node for the existing \n          data storage, which from now on will be served by a new node.\n          If this message repeats, both nodes might have same storageID \n          by (insanely rare) random chance. User needs to restart one of the\n          nodes with its data cleared (or user can just remove the StorageID\n          value in \"VERSION\" file under the data directory of the datanode,\n          but this is might not work if VERSION file format has changed \n       */        \n        NameNode.stateChangeLog.info( \"BLOCK* NameSystem.registerDatanode: \"\n                                      + \"node \" + nodeS.getName()\n                                      + \" is replaced by \" + nodeReg.getName() + \n                                      \" with the same storageID \" +\n                                      nodeReg.getStorageID());\n      }\n      // update cluster map\n      getNetworkTopology().remove(nodeS);\n      nodeS.updateRegInfo(nodeReg);\n      nodeS.setHostName(hostName);\n      nodeS.setDisallowed(false); // Node is in the include list\n      \n      // resolve network location\n      resolveNetworkLocation(nodeS);\n      getNetworkTopology().add(nodeS);\n        \n      // also treat the registration message as a heartbeat\n      heartbeatManager.register(nodeS);\n      checkDecommissioning(nodeS, dnAddress);\n      return;\n    } \n\n    // this is a new datanode serving a new data storage\n    if (\"\".equals(nodeReg.getStorageID())) {\n      // this data storage has never been registered\n      // it is either empty or was created by pre-storageID version of DFS\n      nodeReg.setStorageID(newStorageID());\n      if(NameNode.stateChangeLog.isDebugEnabled()) {\n        NameNode.stateChangeLog.debug(\n            \"BLOCK* NameSystem.registerDatanode: \"\n            + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n      }\n    }\n    // register new datanode\n    DatanodeDescriptor nodeDescr \n      \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK);\n    resolveNetworkLocation(nodeDescr);\n    addDatanode(nodeDescr);\n    checkDecommissioning(nodeDescr, dnAddress);\n    \n    // also treat the registration message as a heartbeat\n    // no need to update its timestamp\n    // because its is done when the descriptor is created\n    heartbeatManager.addDatanode(nodeDescr);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void registerDatanode(DatanodeRegistration nodeReg\n      ) throws IOException {\n    String dnAddress \u003d Server.getRemoteAddress();\n    if (dnAddress \u003d\u003d null) {\n      // Mostly called inside an RPC.\n      // But if not, use address passed by the data-node.\n      dnAddress \u003d nodeReg.getHost();\n    }      \n\n    // Checks if the node is not on the hosts list.  If it is not, then\n    // it will be disallowed from registering. \n    if (!inHostsList(nodeReg, dnAddress)) {\n      throw new DisallowedDatanodeException(nodeReg);\n    }\n\n    String hostName \u003d nodeReg.getHost();\n      \n    // update the datanode\u0027s name with ip:port\n    DatanodeID dnReg \u003d new DatanodeID(dnAddress + \":\" + nodeReg.getPort(),\n                                      nodeReg.getStorageID(),\n                                      nodeReg.getInfoPort(),\n                                      nodeReg.getIpcPort());\n    nodeReg.updateRegInfo(dnReg);\n    nodeReg.exportedKeys \u003d blockManager.getBlockKeys();\n      \n    NameNode.stateChangeLog.info(\"BLOCK* NameSystem.registerDatanode: \"\n        + \"node registration from \" + nodeReg.getName()\n        + \" storage \" + nodeReg.getStorageID());\n\n    DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n    DatanodeDescriptor nodeN \u003d getDatanodeByHost(nodeReg.getName());\n      \n    if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n      NameNode.LOG.info(\"BLOCK* NameSystem.registerDatanode: \"\n                        + \"node from name: \" + nodeN.getName());\n      // nodeN previously served a different data storage, \n      // which is not served by anybody anymore.\n      removeDatanode(nodeN);\n      // physically remove node from datanodeMap\n      wipeDatanode(nodeN);\n      nodeN \u003d null;\n    }\n\n    if (nodeS !\u003d null) {\n      if (nodeN \u003d\u003d nodeS) {\n        // The same datanode has been just restarted to serve the same data \n        // storage. We do not need to remove old data blocks, the delta will\n        // be calculated on the next block report from the datanode\n        if(NameNode.stateChangeLog.isDebugEnabled()) {\n          NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.registerDatanode: \"\n                                        + \"node restarted.\");\n        }\n      } else {\n        // nodeS is found\n        /* The registering datanode is a replacement node for the existing \n          data storage, which from now on will be served by a new node.\n          If this message repeats, both nodes might have same storageID \n          by (insanely rare) random chance. User needs to restart one of the\n          nodes with its data cleared (or user can just remove the StorageID\n          value in \"VERSION\" file under the data directory of the datanode,\n          but this is might not work if VERSION file format has changed \n       */        \n        NameNode.stateChangeLog.info( \"BLOCK* NameSystem.registerDatanode: \"\n                                      + \"node \" + nodeS.getName()\n                                      + \" is replaced by \" + nodeReg.getName() + \n                                      \" with the same storageID \" +\n                                      nodeReg.getStorageID());\n      }\n      // update cluster map\n      getNetworkTopology().remove(nodeS);\n      nodeS.updateRegInfo(nodeReg);\n      nodeS.setHostName(hostName);\n      nodeS.setDisallowed(false); // Node is in the include list\n      \n      // resolve network location\n      resolveNetworkLocation(nodeS);\n      getNetworkTopology().add(nodeS);\n        \n      // also treat the registration message as a heartbeat\n      heartbeatManager.register(nodeS);\n      checkDecommissioning(nodeS, dnAddress);\n      return;\n    } \n\n    // this is a new datanode serving a new data storage\n    if (nodeReg.getStorageID().equals(\"\")) {\n      // this data storage has never been registered\n      // it is either empty or was created by pre-storageID version of DFS\n      nodeReg.storageID \u003d newStorageID();\n      if(NameNode.stateChangeLog.isDebugEnabled()) {\n        NameNode.stateChangeLog.debug(\n            \"BLOCK* NameSystem.registerDatanode: \"\n            + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n      }\n    }\n    // register new datanode\n    DatanodeDescriptor nodeDescr \n      \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK, hostName);\n    resolveNetworkLocation(nodeDescr);\n    addDatanode(nodeDescr);\n    checkDecommissioning(nodeDescr, dnAddress);\n    \n    // also treat the registration message as a heartbeat\n    // no need to update its timestamp\n    // because its is done when the descriptor is created\n    heartbeatManager.addDatanode(nodeDescr);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void registerDatanode(DatanodeRegistration nodeReg\n      ) throws IOException {\n    String dnAddress \u003d Server.getRemoteAddress();\n    if (dnAddress \u003d\u003d null) {\n      // Mostly called inside an RPC.\n      // But if not, use address passed by the data-node.\n      dnAddress \u003d nodeReg.getHost();\n    }      \n\n    // Checks if the node is not on the hosts list.  If it is not, then\n    // it will be disallowed from registering. \n    if (!inHostsList(nodeReg, dnAddress)) {\n      throw new DisallowedDatanodeException(nodeReg);\n    }\n\n    String hostName \u003d nodeReg.getHost();\n      \n    // update the datanode\u0027s name with ip:port\n    DatanodeID dnReg \u003d new DatanodeID(dnAddress + \":\" + nodeReg.getPort(),\n                                      nodeReg.getStorageID(),\n                                      nodeReg.getInfoPort(),\n                                      nodeReg.getIpcPort());\n    nodeReg.updateRegInfo(dnReg);\n    nodeReg.exportedKeys \u003d blockManager.getBlockKeys();\n      \n    NameNode.stateChangeLog.info(\"BLOCK* NameSystem.registerDatanode: \"\n        + \"node registration from \" + nodeReg.getName()\n        + \" storage \" + nodeReg.getStorageID());\n\n    DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n    DatanodeDescriptor nodeN \u003d getDatanodeByHost(nodeReg.getName());\n      \n    if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n      NameNode.LOG.info(\"BLOCK* NameSystem.registerDatanode: \"\n                        + \"node from name: \" + nodeN.getName());\n      // nodeN previously served a different data storage, \n      // which is not served by anybody anymore.\n      removeDatanode(nodeN);\n      // physically remove node from datanodeMap\n      wipeDatanode(nodeN);\n      nodeN \u003d null;\n    }\n\n    if (nodeS !\u003d null) {\n      if (nodeN \u003d\u003d nodeS) {\n        // The same datanode has been just restarted to serve the same data \n        // storage. We do not need to remove old data blocks, the delta will\n        // be calculated on the next block report from the datanode\n        if(NameNode.stateChangeLog.isDebugEnabled()) {\n          NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.registerDatanode: \"\n                                        + \"node restarted.\");\n        }\n      } else {\n        // nodeS is found\n        /* The registering datanode is a replacement node for the existing \n          data storage, which from now on will be served by a new node.\n          If this message repeats, both nodes might have same storageID \n          by (insanely rare) random chance. User needs to restart one of the\n          nodes with its data cleared (or user can just remove the StorageID\n          value in \"VERSION\" file under the data directory of the datanode,\n          but this is might not work if VERSION file format has changed \n       */        \n        NameNode.stateChangeLog.info( \"BLOCK* NameSystem.registerDatanode: \"\n                                      + \"node \" + nodeS.getName()\n                                      + \" is replaced by \" + nodeReg.getName() + \n                                      \" with the same storageID \" +\n                                      nodeReg.getStorageID());\n      }\n      // update cluster map\n      getNetworkTopology().remove(nodeS);\n      nodeS.updateRegInfo(nodeReg);\n      nodeS.setHostName(hostName);\n      nodeS.setDisallowed(false); // Node is in the include list\n      \n      // resolve network location\n      resolveNetworkLocation(nodeS);\n      getNetworkTopology().add(nodeS);\n        \n      // also treat the registration message as a heartbeat\n      heartbeatManager.register(nodeS);\n      checkDecommissioning(nodeS, dnAddress);\n      return;\n    } \n\n    // this is a new datanode serving a new data storage\n    if (nodeReg.getStorageID().equals(\"\")) {\n      // this data storage has never been registered\n      // it is either empty or was created by pre-storageID version of DFS\n      nodeReg.storageID \u003d newStorageID();\n      if(NameNode.stateChangeLog.isDebugEnabled()) {\n        NameNode.stateChangeLog.debug(\n            \"BLOCK* NameSystem.registerDatanode: \"\n            + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n      }\n    }\n    // register new datanode\n    DatanodeDescriptor nodeDescr \n      \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK, hostName);\n    resolveNetworkLocation(nodeDescr);\n    addDatanode(nodeDescr);\n    checkDecommissioning(nodeDescr, dnAddress);\n    \n    // also treat the registration message as a heartbeat\n    // no need to update its timestamp\n    // because its is done when the descriptor is created\n    heartbeatManager.addDatanode(nodeDescr);\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java"
      }
    },
    "371f4a59059322000a40eb4bdf5386b96b626ece": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2228. Move block and datanode code from FSNamesystem to BlockManager and DatanodeManager.  (szetszwo)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1154899 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/08/11 3:06 AM",
      "commitName": "371f4a59059322000a40eb4bdf5386b96b626ece",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "04/08/11 3:55 PM",
      "commitNameOld": "7fac946ac983e31613fd62836c8ac9c4a579210a",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 3.47,
      "commitsBetweenForRepo": 8,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,107 +1,107 @@\n   public void registerDatanode(DatanodeRegistration nodeReg\n       ) throws IOException {\n     String dnAddress \u003d Server.getRemoteAddress();\n     if (dnAddress \u003d\u003d null) {\n       // Mostly called inside an RPC.\n       // But if not, use address passed by the data-node.\n       dnAddress \u003d nodeReg.getHost();\n     }      \n \n     // Checks if the node is not on the hosts list.  If it is not, then\n     // it will be disallowed from registering. \n     if (!inHostsList(nodeReg, dnAddress)) {\n       throw new DisallowedDatanodeException(nodeReg);\n     }\n \n     String hostName \u003d nodeReg.getHost();\n       \n     // update the datanode\u0027s name with ip:port\n     DatanodeID dnReg \u003d new DatanodeID(dnAddress + \":\" + nodeReg.getPort(),\n                                       nodeReg.getStorageID(),\n                                       nodeReg.getInfoPort(),\n                                       nodeReg.getIpcPort());\n     nodeReg.updateRegInfo(dnReg);\n-    nodeReg.exportedKeys \u003d namesystem.getBlockManager().getBlockKeys();\n+    nodeReg.exportedKeys \u003d blockManager.getBlockKeys();\n       \n     NameNode.stateChangeLog.info(\"BLOCK* NameSystem.registerDatanode: \"\n         + \"node registration from \" + nodeReg.getName()\n         + \" storage \" + nodeReg.getStorageID());\n \n     DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n     DatanodeDescriptor nodeN \u003d getDatanodeByHost(nodeReg.getName());\n       \n     if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n       NameNode.LOG.info(\"BLOCK* NameSystem.registerDatanode: \"\n                         + \"node from name: \" + nodeN.getName());\n       // nodeN previously served a different data storage, \n       // which is not served by anybody anymore.\n       removeDatanode(nodeN);\n       // physically remove node from datanodeMap\n       wipeDatanode(nodeN);\n       nodeN \u003d null;\n     }\n \n     if (nodeS !\u003d null) {\n       if (nodeN \u003d\u003d nodeS) {\n         // The same datanode has been just restarted to serve the same data \n         // storage. We do not need to remove old data blocks, the delta will\n         // be calculated on the next block report from the datanode\n         if(NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.registerDatanode: \"\n                                         + \"node restarted.\");\n         }\n       } else {\n         // nodeS is found\n         /* The registering datanode is a replacement node for the existing \n           data storage, which from now on will be served by a new node.\n           If this message repeats, both nodes might have same storageID \n           by (insanely rare) random chance. User needs to restart one of the\n           nodes with its data cleared (or user can just remove the StorageID\n           value in \"VERSION\" file under the data directory of the datanode,\n           but this is might not work if VERSION file format has changed \n        */        \n         NameNode.stateChangeLog.info( \"BLOCK* NameSystem.registerDatanode: \"\n                                       + \"node \" + nodeS.getName()\n                                       + \" is replaced by \" + nodeReg.getName() + \n                                       \" with the same storageID \" +\n                                       nodeReg.getStorageID());\n       }\n       // update cluster map\n       getNetworkTopology().remove(nodeS);\n       nodeS.updateRegInfo(nodeReg);\n       nodeS.setHostName(hostName);\n       nodeS.setDisallowed(false); // Node is in the include list\n       \n       // resolve network location\n       resolveNetworkLocation(nodeS);\n       getNetworkTopology().add(nodeS);\n         \n       // also treat the registration message as a heartbeat\n       heartbeatManager.register(nodeS);\n       checkDecommissioning(nodeS, dnAddress);\n       return;\n     } \n \n     // this is a new datanode serving a new data storage\n     if (nodeReg.getStorageID().equals(\"\")) {\n       // this data storage has never been registered\n       // it is either empty or was created by pre-storageID version of DFS\n       nodeReg.storageID \u003d newStorageID();\n       if(NameNode.stateChangeLog.isDebugEnabled()) {\n         NameNode.stateChangeLog.debug(\n             \"BLOCK* NameSystem.registerDatanode: \"\n             + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n       }\n     }\n     // register new datanode\n     DatanodeDescriptor nodeDescr \n       \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK, hostName);\n     resolveNetworkLocation(nodeDescr);\n     addDatanode(nodeDescr);\n     checkDecommissioning(nodeDescr, dnAddress);\n     \n     // also treat the registration message as a heartbeat\n     // no need to update its timestamp\n     // because its is done when the descriptor is created\n     heartbeatManager.addDatanode(nodeDescr);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void registerDatanode(DatanodeRegistration nodeReg\n      ) throws IOException {\n    String dnAddress \u003d Server.getRemoteAddress();\n    if (dnAddress \u003d\u003d null) {\n      // Mostly called inside an RPC.\n      // But if not, use address passed by the data-node.\n      dnAddress \u003d nodeReg.getHost();\n    }      \n\n    // Checks if the node is not on the hosts list.  If it is not, then\n    // it will be disallowed from registering. \n    if (!inHostsList(nodeReg, dnAddress)) {\n      throw new DisallowedDatanodeException(nodeReg);\n    }\n\n    String hostName \u003d nodeReg.getHost();\n      \n    // update the datanode\u0027s name with ip:port\n    DatanodeID dnReg \u003d new DatanodeID(dnAddress + \":\" + nodeReg.getPort(),\n                                      nodeReg.getStorageID(),\n                                      nodeReg.getInfoPort(),\n                                      nodeReg.getIpcPort());\n    nodeReg.updateRegInfo(dnReg);\n    nodeReg.exportedKeys \u003d blockManager.getBlockKeys();\n      \n    NameNode.stateChangeLog.info(\"BLOCK* NameSystem.registerDatanode: \"\n        + \"node registration from \" + nodeReg.getName()\n        + \" storage \" + nodeReg.getStorageID());\n\n    DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n    DatanodeDescriptor nodeN \u003d getDatanodeByHost(nodeReg.getName());\n      \n    if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n      NameNode.LOG.info(\"BLOCK* NameSystem.registerDatanode: \"\n                        + \"node from name: \" + nodeN.getName());\n      // nodeN previously served a different data storage, \n      // which is not served by anybody anymore.\n      removeDatanode(nodeN);\n      // physically remove node from datanodeMap\n      wipeDatanode(nodeN);\n      nodeN \u003d null;\n    }\n\n    if (nodeS !\u003d null) {\n      if (nodeN \u003d\u003d nodeS) {\n        // The same datanode has been just restarted to serve the same data \n        // storage. We do not need to remove old data blocks, the delta will\n        // be calculated on the next block report from the datanode\n        if(NameNode.stateChangeLog.isDebugEnabled()) {\n          NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.registerDatanode: \"\n                                        + \"node restarted.\");\n        }\n      } else {\n        // nodeS is found\n        /* The registering datanode is a replacement node for the existing \n          data storage, which from now on will be served by a new node.\n          If this message repeats, both nodes might have same storageID \n          by (insanely rare) random chance. User needs to restart one of the\n          nodes with its data cleared (or user can just remove the StorageID\n          value in \"VERSION\" file under the data directory of the datanode,\n          but this is might not work if VERSION file format has changed \n       */        \n        NameNode.stateChangeLog.info( \"BLOCK* NameSystem.registerDatanode: \"\n                                      + \"node \" + nodeS.getName()\n                                      + \" is replaced by \" + nodeReg.getName() + \n                                      \" with the same storageID \" +\n                                      nodeReg.getStorageID());\n      }\n      // update cluster map\n      getNetworkTopology().remove(nodeS);\n      nodeS.updateRegInfo(nodeReg);\n      nodeS.setHostName(hostName);\n      nodeS.setDisallowed(false); // Node is in the include list\n      \n      // resolve network location\n      resolveNetworkLocation(nodeS);\n      getNetworkTopology().add(nodeS);\n        \n      // also treat the registration message as a heartbeat\n      heartbeatManager.register(nodeS);\n      checkDecommissioning(nodeS, dnAddress);\n      return;\n    } \n\n    // this is a new datanode serving a new data storage\n    if (nodeReg.getStorageID().equals(\"\")) {\n      // this data storage has never been registered\n      // it is either empty or was created by pre-storageID version of DFS\n      nodeReg.storageID \u003d newStorageID();\n      if(NameNode.stateChangeLog.isDebugEnabled()) {\n        NameNode.stateChangeLog.debug(\n            \"BLOCK* NameSystem.registerDatanode: \"\n            + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n      }\n    }\n    // register new datanode\n    DatanodeDescriptor nodeDescr \n      \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK, hostName);\n    resolveNetworkLocation(nodeDescr);\n    addDatanode(nodeDescr);\n    checkDecommissioning(nodeDescr, dnAddress);\n    \n    // also treat the registration message as a heartbeat\n    // no need to update its timestamp\n    // because its is done when the descriptor is created\n    heartbeatManager.addDatanode(nodeDescr);\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "7fac946ac983e31613fd62836c8ac9c4a579210a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2108. Move datanode heartbeat handling from namenode package to blockmanagement package.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1154042 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/08/11 3:55 PM",
      "commitName": "7fac946ac983e31613fd62836c8ac9c4a579210a",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "01/08/11 6:57 AM",
      "commitNameOld": "d68e38b78d9687987c4de2046ce9aa0016685e98",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 3.37,
      "commitsBetweenForRepo": 18,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,117 +1,107 @@\n   public void registerDatanode(DatanodeRegistration nodeReg\n       ) throws IOException {\n     String dnAddress \u003d Server.getRemoteAddress();\n     if (dnAddress \u003d\u003d null) {\n       // Mostly called inside an RPC.\n       // But if not, use address passed by the data-node.\n       dnAddress \u003d nodeReg.getHost();\n     }      \n \n     // Checks if the node is not on the hosts list.  If it is not, then\n     // it will be disallowed from registering. \n     if (!inHostsList(nodeReg, dnAddress)) {\n       throw new DisallowedDatanodeException(nodeReg);\n     }\n \n     String hostName \u003d nodeReg.getHost();\n       \n     // update the datanode\u0027s name with ip:port\n     DatanodeID dnReg \u003d new DatanodeID(dnAddress + \":\" + nodeReg.getPort(),\n                                       nodeReg.getStorageID(),\n                                       nodeReg.getInfoPort(),\n                                       nodeReg.getIpcPort());\n     nodeReg.updateRegInfo(dnReg);\n     nodeReg.exportedKeys \u003d namesystem.getBlockManager().getBlockKeys();\n       \n     NameNode.stateChangeLog.info(\"BLOCK* NameSystem.registerDatanode: \"\n         + \"node registration from \" + nodeReg.getName()\n         + \" storage \" + nodeReg.getStorageID());\n \n     DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n     DatanodeDescriptor nodeN \u003d getDatanodeByHost(nodeReg.getName());\n       \n     if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n       NameNode.LOG.info(\"BLOCK* NameSystem.registerDatanode: \"\n                         + \"node from name: \" + nodeN.getName());\n       // nodeN previously served a different data storage, \n       // which is not served by anybody anymore.\n-      namesystem.removeDatanode(nodeN);\n+      removeDatanode(nodeN);\n       // physically remove node from datanodeMap\n       wipeDatanode(nodeN);\n       nodeN \u003d null;\n     }\n \n     if (nodeS !\u003d null) {\n       if (nodeN \u003d\u003d nodeS) {\n         // The same datanode has been just restarted to serve the same data \n         // storage. We do not need to remove old data blocks, the delta will\n         // be calculated on the next block report from the datanode\n         if(NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.registerDatanode: \"\n                                         + \"node restarted.\");\n         }\n       } else {\n         // nodeS is found\n         /* The registering datanode is a replacement node for the existing \n           data storage, which from now on will be served by a new node.\n           If this message repeats, both nodes might have same storageID \n           by (insanely rare) random chance. User needs to restart one of the\n           nodes with its data cleared (or user can just remove the StorageID\n           value in \"VERSION\" file under the data directory of the datanode,\n           but this is might not work if VERSION file format has changed \n        */        \n         NameNode.stateChangeLog.info( \"BLOCK* NameSystem.registerDatanode: \"\n                                       + \"node \" + nodeS.getName()\n                                       + \" is replaced by \" + nodeReg.getName() + \n                                       \" with the same storageID \" +\n                                       nodeReg.getStorageID());\n       }\n       // update cluster map\n       getNetworkTopology().remove(nodeS);\n       nodeS.updateRegInfo(nodeReg);\n       nodeS.setHostName(hostName);\n       nodeS.setDisallowed(false); // Node is in the include list\n       \n       // resolve network location\n       resolveNetworkLocation(nodeS);\n       getNetworkTopology().add(nodeS);\n         \n       // also treat the registration message as a heartbeat\n-      synchronized(namesystem.heartbeats) {\n-        if( !namesystem.heartbeats.contains(nodeS)) {\n-          namesystem.heartbeats.add(nodeS);\n-          //update its timestamp\n-          nodeS.updateHeartbeat(0L, 0L, 0L, 0L, 0, 0);\n-          nodeS.isAlive \u003d true;\n-        }\n-      }\n+      heartbeatManager.register(nodeS);\n       checkDecommissioning(nodeS, dnAddress);\n       return;\n     } \n \n     // this is a new datanode serving a new data storage\n     if (nodeReg.getStorageID().equals(\"\")) {\n       // this data storage has never been registered\n       // it is either empty or was created by pre-storageID version of DFS\n       nodeReg.storageID \u003d newStorageID();\n       if(NameNode.stateChangeLog.isDebugEnabled()) {\n         NameNode.stateChangeLog.debug(\n             \"BLOCK* NameSystem.registerDatanode: \"\n             + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n       }\n     }\n     // register new datanode\n     DatanodeDescriptor nodeDescr \n       \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK, hostName);\n     resolveNetworkLocation(nodeDescr);\n     addDatanode(nodeDescr);\n     checkDecommissioning(nodeDescr, dnAddress);\n     \n     // also treat the registration message as a heartbeat\n-    synchronized(namesystem.heartbeats) {\n-      namesystem.heartbeats.add(nodeDescr);\n-      nodeDescr.isAlive \u003d true;\n-      // no need to update its timestamp\n-      // because its is done when the descriptor is created\n-    }\n+    // no need to update its timestamp\n+    // because its is done when the descriptor is created\n+    heartbeatManager.addDatanode(nodeDescr);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void registerDatanode(DatanodeRegistration nodeReg\n      ) throws IOException {\n    String dnAddress \u003d Server.getRemoteAddress();\n    if (dnAddress \u003d\u003d null) {\n      // Mostly called inside an RPC.\n      // But if not, use address passed by the data-node.\n      dnAddress \u003d nodeReg.getHost();\n    }      \n\n    // Checks if the node is not on the hosts list.  If it is not, then\n    // it will be disallowed from registering. \n    if (!inHostsList(nodeReg, dnAddress)) {\n      throw new DisallowedDatanodeException(nodeReg);\n    }\n\n    String hostName \u003d nodeReg.getHost();\n      \n    // update the datanode\u0027s name with ip:port\n    DatanodeID dnReg \u003d new DatanodeID(dnAddress + \":\" + nodeReg.getPort(),\n                                      nodeReg.getStorageID(),\n                                      nodeReg.getInfoPort(),\n                                      nodeReg.getIpcPort());\n    nodeReg.updateRegInfo(dnReg);\n    nodeReg.exportedKeys \u003d namesystem.getBlockManager().getBlockKeys();\n      \n    NameNode.stateChangeLog.info(\"BLOCK* NameSystem.registerDatanode: \"\n        + \"node registration from \" + nodeReg.getName()\n        + \" storage \" + nodeReg.getStorageID());\n\n    DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n    DatanodeDescriptor nodeN \u003d getDatanodeByHost(nodeReg.getName());\n      \n    if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n      NameNode.LOG.info(\"BLOCK* NameSystem.registerDatanode: \"\n                        + \"node from name: \" + nodeN.getName());\n      // nodeN previously served a different data storage, \n      // which is not served by anybody anymore.\n      removeDatanode(nodeN);\n      // physically remove node from datanodeMap\n      wipeDatanode(nodeN);\n      nodeN \u003d null;\n    }\n\n    if (nodeS !\u003d null) {\n      if (nodeN \u003d\u003d nodeS) {\n        // The same datanode has been just restarted to serve the same data \n        // storage. We do not need to remove old data blocks, the delta will\n        // be calculated on the next block report from the datanode\n        if(NameNode.stateChangeLog.isDebugEnabled()) {\n          NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.registerDatanode: \"\n                                        + \"node restarted.\");\n        }\n      } else {\n        // nodeS is found\n        /* The registering datanode is a replacement node for the existing \n          data storage, which from now on will be served by a new node.\n          If this message repeats, both nodes might have same storageID \n          by (insanely rare) random chance. User needs to restart one of the\n          nodes with its data cleared (or user can just remove the StorageID\n          value in \"VERSION\" file under the data directory of the datanode,\n          but this is might not work if VERSION file format has changed \n       */        \n        NameNode.stateChangeLog.info( \"BLOCK* NameSystem.registerDatanode: \"\n                                      + \"node \" + nodeS.getName()\n                                      + \" is replaced by \" + nodeReg.getName() + \n                                      \" with the same storageID \" +\n                                      nodeReg.getStorageID());\n      }\n      // update cluster map\n      getNetworkTopology().remove(nodeS);\n      nodeS.updateRegInfo(nodeReg);\n      nodeS.setHostName(hostName);\n      nodeS.setDisallowed(false); // Node is in the include list\n      \n      // resolve network location\n      resolveNetworkLocation(nodeS);\n      getNetworkTopology().add(nodeS);\n        \n      // also treat the registration message as a heartbeat\n      heartbeatManager.register(nodeS);\n      checkDecommissioning(nodeS, dnAddress);\n      return;\n    } \n\n    // this is a new datanode serving a new data storage\n    if (nodeReg.getStorageID().equals(\"\")) {\n      // this data storage has never been registered\n      // it is either empty or was created by pre-storageID version of DFS\n      nodeReg.storageID \u003d newStorageID();\n      if(NameNode.stateChangeLog.isDebugEnabled()) {\n        NameNode.stateChangeLog.debug(\n            \"BLOCK* NameSystem.registerDatanode: \"\n            + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n      }\n    }\n    // register new datanode\n    DatanodeDescriptor nodeDescr \n      \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK, hostName);\n    resolveNetworkLocation(nodeDescr);\n    addDatanode(nodeDescr);\n    checkDecommissioning(nodeDescr, dnAddress);\n    \n    // also treat the registration message as a heartbeat\n    // no need to update its timestamp\n    // because its is done when the descriptor is created\n    heartbeatManager.addDatanode(nodeDescr);\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "d68e38b78d9687987c4de2046ce9aa0016685e98": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2199. Move blockTokenSecretManager from FSNamesystem to BlockManager.  Contributed by Uma Maheswara Rao G\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1152776 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "01/08/11 6:57 AM",
      "commitName": "d68e38b78d9687987c4de2046ce9aa0016685e98",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "29/07/11 5:10 PM",
      "commitNameOld": "8390152d08306caad31b78abbd509e5ea8580671",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 2.57,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,117 +1,117 @@\n   public void registerDatanode(DatanodeRegistration nodeReg\n       ) throws IOException {\n     String dnAddress \u003d Server.getRemoteAddress();\n     if (dnAddress \u003d\u003d null) {\n       // Mostly called inside an RPC.\n       // But if not, use address passed by the data-node.\n       dnAddress \u003d nodeReg.getHost();\n     }      \n \n     // Checks if the node is not on the hosts list.  If it is not, then\n     // it will be disallowed from registering. \n     if (!inHostsList(nodeReg, dnAddress)) {\n       throw new DisallowedDatanodeException(nodeReg);\n     }\n \n     String hostName \u003d nodeReg.getHost();\n       \n     // update the datanode\u0027s name with ip:port\n     DatanodeID dnReg \u003d new DatanodeID(dnAddress + \":\" + nodeReg.getPort(),\n                                       nodeReg.getStorageID(),\n                                       nodeReg.getInfoPort(),\n                                       nodeReg.getIpcPort());\n     nodeReg.updateRegInfo(dnReg);\n-    nodeReg.exportedKeys \u003d namesystem.getBlockKeys();\n+    nodeReg.exportedKeys \u003d namesystem.getBlockManager().getBlockKeys();\n       \n     NameNode.stateChangeLog.info(\"BLOCK* NameSystem.registerDatanode: \"\n         + \"node registration from \" + nodeReg.getName()\n         + \" storage \" + nodeReg.getStorageID());\n \n     DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n     DatanodeDescriptor nodeN \u003d getDatanodeByHost(nodeReg.getName());\n       \n     if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n       NameNode.LOG.info(\"BLOCK* NameSystem.registerDatanode: \"\n                         + \"node from name: \" + nodeN.getName());\n       // nodeN previously served a different data storage, \n       // which is not served by anybody anymore.\n       namesystem.removeDatanode(nodeN);\n       // physically remove node from datanodeMap\n       wipeDatanode(nodeN);\n       nodeN \u003d null;\n     }\n \n     if (nodeS !\u003d null) {\n       if (nodeN \u003d\u003d nodeS) {\n         // The same datanode has been just restarted to serve the same data \n         // storage. We do not need to remove old data blocks, the delta will\n         // be calculated on the next block report from the datanode\n         if(NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.registerDatanode: \"\n                                         + \"node restarted.\");\n         }\n       } else {\n         // nodeS is found\n         /* The registering datanode is a replacement node for the existing \n           data storage, which from now on will be served by a new node.\n           If this message repeats, both nodes might have same storageID \n           by (insanely rare) random chance. User needs to restart one of the\n           nodes with its data cleared (or user can just remove the StorageID\n           value in \"VERSION\" file under the data directory of the datanode,\n           but this is might not work if VERSION file format has changed \n        */        \n         NameNode.stateChangeLog.info( \"BLOCK* NameSystem.registerDatanode: \"\n                                       + \"node \" + nodeS.getName()\n                                       + \" is replaced by \" + nodeReg.getName() + \n                                       \" with the same storageID \" +\n                                       nodeReg.getStorageID());\n       }\n       // update cluster map\n       getNetworkTopology().remove(nodeS);\n       nodeS.updateRegInfo(nodeReg);\n       nodeS.setHostName(hostName);\n       nodeS.setDisallowed(false); // Node is in the include list\n       \n       // resolve network location\n       resolveNetworkLocation(nodeS);\n       getNetworkTopology().add(nodeS);\n         \n       // also treat the registration message as a heartbeat\n       synchronized(namesystem.heartbeats) {\n         if( !namesystem.heartbeats.contains(nodeS)) {\n           namesystem.heartbeats.add(nodeS);\n           //update its timestamp\n           nodeS.updateHeartbeat(0L, 0L, 0L, 0L, 0, 0);\n           nodeS.isAlive \u003d true;\n         }\n       }\n       checkDecommissioning(nodeS, dnAddress);\n       return;\n     } \n \n     // this is a new datanode serving a new data storage\n     if (nodeReg.getStorageID().equals(\"\")) {\n       // this data storage has never been registered\n       // it is either empty or was created by pre-storageID version of DFS\n       nodeReg.storageID \u003d newStorageID();\n       if(NameNode.stateChangeLog.isDebugEnabled()) {\n         NameNode.stateChangeLog.debug(\n             \"BLOCK* NameSystem.registerDatanode: \"\n             + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n       }\n     }\n     // register new datanode\n     DatanodeDescriptor nodeDescr \n       \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK, hostName);\n     resolveNetworkLocation(nodeDescr);\n     addDatanode(nodeDescr);\n     checkDecommissioning(nodeDescr, dnAddress);\n     \n     // also treat the registration message as a heartbeat\n     synchronized(namesystem.heartbeats) {\n       namesystem.heartbeats.add(nodeDescr);\n       nodeDescr.isAlive \u003d true;\n       // no need to update its timestamp\n       // because its is done when the descriptor is created\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void registerDatanode(DatanodeRegistration nodeReg\n      ) throws IOException {\n    String dnAddress \u003d Server.getRemoteAddress();\n    if (dnAddress \u003d\u003d null) {\n      // Mostly called inside an RPC.\n      // But if not, use address passed by the data-node.\n      dnAddress \u003d nodeReg.getHost();\n    }      \n\n    // Checks if the node is not on the hosts list.  If it is not, then\n    // it will be disallowed from registering. \n    if (!inHostsList(nodeReg, dnAddress)) {\n      throw new DisallowedDatanodeException(nodeReg);\n    }\n\n    String hostName \u003d nodeReg.getHost();\n      \n    // update the datanode\u0027s name with ip:port\n    DatanodeID dnReg \u003d new DatanodeID(dnAddress + \":\" + nodeReg.getPort(),\n                                      nodeReg.getStorageID(),\n                                      nodeReg.getInfoPort(),\n                                      nodeReg.getIpcPort());\n    nodeReg.updateRegInfo(dnReg);\n    nodeReg.exportedKeys \u003d namesystem.getBlockManager().getBlockKeys();\n      \n    NameNode.stateChangeLog.info(\"BLOCK* NameSystem.registerDatanode: \"\n        + \"node registration from \" + nodeReg.getName()\n        + \" storage \" + nodeReg.getStorageID());\n\n    DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n    DatanodeDescriptor nodeN \u003d getDatanodeByHost(nodeReg.getName());\n      \n    if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n      NameNode.LOG.info(\"BLOCK* NameSystem.registerDatanode: \"\n                        + \"node from name: \" + nodeN.getName());\n      // nodeN previously served a different data storage, \n      // which is not served by anybody anymore.\n      namesystem.removeDatanode(nodeN);\n      // physically remove node from datanodeMap\n      wipeDatanode(nodeN);\n      nodeN \u003d null;\n    }\n\n    if (nodeS !\u003d null) {\n      if (nodeN \u003d\u003d nodeS) {\n        // The same datanode has been just restarted to serve the same data \n        // storage. We do not need to remove old data blocks, the delta will\n        // be calculated on the next block report from the datanode\n        if(NameNode.stateChangeLog.isDebugEnabled()) {\n          NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.registerDatanode: \"\n                                        + \"node restarted.\");\n        }\n      } else {\n        // nodeS is found\n        /* The registering datanode is a replacement node for the existing \n          data storage, which from now on will be served by a new node.\n          If this message repeats, both nodes might have same storageID \n          by (insanely rare) random chance. User needs to restart one of the\n          nodes with its data cleared (or user can just remove the StorageID\n          value in \"VERSION\" file under the data directory of the datanode,\n          but this is might not work if VERSION file format has changed \n       */        \n        NameNode.stateChangeLog.info( \"BLOCK* NameSystem.registerDatanode: \"\n                                      + \"node \" + nodeS.getName()\n                                      + \" is replaced by \" + nodeReg.getName() + \n                                      \" with the same storageID \" +\n                                      nodeReg.getStorageID());\n      }\n      // update cluster map\n      getNetworkTopology().remove(nodeS);\n      nodeS.updateRegInfo(nodeReg);\n      nodeS.setHostName(hostName);\n      nodeS.setDisallowed(false); // Node is in the include list\n      \n      // resolve network location\n      resolveNetworkLocation(nodeS);\n      getNetworkTopology().add(nodeS);\n        \n      // also treat the registration message as a heartbeat\n      synchronized(namesystem.heartbeats) {\n        if( !namesystem.heartbeats.contains(nodeS)) {\n          namesystem.heartbeats.add(nodeS);\n          //update its timestamp\n          nodeS.updateHeartbeat(0L, 0L, 0L, 0L, 0, 0);\n          nodeS.isAlive \u003d true;\n        }\n      }\n      checkDecommissioning(nodeS, dnAddress);\n      return;\n    } \n\n    // this is a new datanode serving a new data storage\n    if (nodeReg.getStorageID().equals(\"\")) {\n      // this data storage has never been registered\n      // it is either empty or was created by pre-storageID version of DFS\n      nodeReg.storageID \u003d newStorageID();\n      if(NameNode.stateChangeLog.isDebugEnabled()) {\n        NameNode.stateChangeLog.debug(\n            \"BLOCK* NameSystem.registerDatanode: \"\n            + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n      }\n    }\n    // register new datanode\n    DatanodeDescriptor nodeDescr \n      \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK, hostName);\n    resolveNetworkLocation(nodeDescr);\n    addDatanode(nodeDescr);\n    checkDecommissioning(nodeDescr, dnAddress);\n    \n    // also treat the registration message as a heartbeat\n    synchronized(namesystem.heartbeats) {\n      namesystem.heartbeats.add(nodeDescr);\n      nodeDescr.isAlive \u003d true;\n      // no need to update its timestamp\n      // because its is done when the descriptor is created\n    }\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "969a263188f7015261719fe45fa1505121ebb80e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2191.  Move datanodeMap from FSNamesystem to DatanodeManager.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1151339 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "26/07/11 10:46 PM",
      "commitName": "969a263188f7015261719fe45fa1505121ebb80e",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "21/07/11 9:20 PM",
      "commitNameOld": "233a7aa34f37350bf7bcdd9c84b97d613e7344c9",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 5.06,
      "commitsBetweenForRepo": 16,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,117 +1,117 @@\n   public void registerDatanode(DatanodeRegistration nodeReg\n       ) throws IOException {\n     String dnAddress \u003d Server.getRemoteAddress();\n     if (dnAddress \u003d\u003d null) {\n       // Mostly called inside an RPC.\n       // But if not, use address passed by the data-node.\n       dnAddress \u003d nodeReg.getHost();\n     }      \n \n     // Checks if the node is not on the hosts list.  If it is not, then\n     // it will be disallowed from registering. \n     if (!inHostsList(nodeReg, dnAddress)) {\n       throw new DisallowedDatanodeException(nodeReg);\n     }\n \n     String hostName \u003d nodeReg.getHost();\n       \n     // update the datanode\u0027s name with ip:port\n     DatanodeID dnReg \u003d new DatanodeID(dnAddress + \":\" + nodeReg.getPort(),\n                                       nodeReg.getStorageID(),\n                                       nodeReg.getInfoPort(),\n                                       nodeReg.getIpcPort());\n     nodeReg.updateRegInfo(dnReg);\n     nodeReg.exportedKeys \u003d namesystem.getBlockKeys();\n       \n     NameNode.stateChangeLog.info(\"BLOCK* NameSystem.registerDatanode: \"\n         + \"node registration from \" + nodeReg.getName()\n         + \" storage \" + nodeReg.getStorageID());\n \n-    DatanodeDescriptor nodeS \u003d namesystem.datanodeMap.get(nodeReg.getStorageID());\n+    DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n     DatanodeDescriptor nodeN \u003d getDatanodeByHost(nodeReg.getName());\n       \n     if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n       NameNode.LOG.info(\"BLOCK* NameSystem.registerDatanode: \"\n                         + \"node from name: \" + nodeN.getName());\n       // nodeN previously served a different data storage, \n       // which is not served by anybody anymore.\n       namesystem.removeDatanode(nodeN);\n       // physically remove node from datanodeMap\n       wipeDatanode(nodeN);\n       nodeN \u003d null;\n     }\n \n     if (nodeS !\u003d null) {\n       if (nodeN \u003d\u003d nodeS) {\n         // The same datanode has been just restarted to serve the same data \n         // storage. We do not need to remove old data blocks, the delta will\n         // be calculated on the next block report from the datanode\n         if(NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.registerDatanode: \"\n                                         + \"node restarted.\");\n         }\n       } else {\n         // nodeS is found\n         /* The registering datanode is a replacement node for the existing \n           data storage, which from now on will be served by a new node.\n           If this message repeats, both nodes might have same storageID \n           by (insanely rare) random chance. User needs to restart one of the\n           nodes with its data cleared (or user can just remove the StorageID\n           value in \"VERSION\" file under the data directory of the datanode,\n           but this is might not work if VERSION file format has changed \n        */        \n         NameNode.stateChangeLog.info( \"BLOCK* NameSystem.registerDatanode: \"\n                                       + \"node \" + nodeS.getName()\n                                       + \" is replaced by \" + nodeReg.getName() + \n                                       \" with the same storageID \" +\n                                       nodeReg.getStorageID());\n       }\n       // update cluster map\n       getNetworkTopology().remove(nodeS);\n       nodeS.updateRegInfo(nodeReg);\n       nodeS.setHostName(hostName);\n       nodeS.setDisallowed(false); // Node is in the include list\n       \n       // resolve network location\n       resolveNetworkLocation(nodeS);\n       getNetworkTopology().add(nodeS);\n         \n       // also treat the registration message as a heartbeat\n       synchronized(namesystem.heartbeats) {\n         if( !namesystem.heartbeats.contains(nodeS)) {\n           namesystem.heartbeats.add(nodeS);\n           //update its timestamp\n           nodeS.updateHeartbeat(0L, 0L, 0L, 0L, 0, 0);\n           nodeS.isAlive \u003d true;\n         }\n       }\n       checkDecommissioning(nodeS, dnAddress);\n       return;\n     } \n \n     // this is a new datanode serving a new data storage\n     if (nodeReg.getStorageID().equals(\"\")) {\n       // this data storage has never been registered\n       // it is either empty or was created by pre-storageID version of DFS\n       nodeReg.storageID \u003d newStorageID();\n       if(NameNode.stateChangeLog.isDebugEnabled()) {\n         NameNode.stateChangeLog.debug(\n             \"BLOCK* NameSystem.registerDatanode: \"\n             + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n       }\n     }\n     // register new datanode\n     DatanodeDescriptor nodeDescr \n       \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK, hostName);\n     resolveNetworkLocation(nodeDescr);\n     addDatanode(nodeDescr);\n     checkDecommissioning(nodeDescr, dnAddress);\n     \n     // also treat the registration message as a heartbeat\n     synchronized(namesystem.heartbeats) {\n       namesystem.heartbeats.add(nodeDescr);\n       nodeDescr.isAlive \u003d true;\n       // no need to update its timestamp\n       // because its is done when the descriptor is created\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void registerDatanode(DatanodeRegistration nodeReg\n      ) throws IOException {\n    String dnAddress \u003d Server.getRemoteAddress();\n    if (dnAddress \u003d\u003d null) {\n      // Mostly called inside an RPC.\n      // But if not, use address passed by the data-node.\n      dnAddress \u003d nodeReg.getHost();\n    }      \n\n    // Checks if the node is not on the hosts list.  If it is not, then\n    // it will be disallowed from registering. \n    if (!inHostsList(nodeReg, dnAddress)) {\n      throw new DisallowedDatanodeException(nodeReg);\n    }\n\n    String hostName \u003d nodeReg.getHost();\n      \n    // update the datanode\u0027s name with ip:port\n    DatanodeID dnReg \u003d new DatanodeID(dnAddress + \":\" + nodeReg.getPort(),\n                                      nodeReg.getStorageID(),\n                                      nodeReg.getInfoPort(),\n                                      nodeReg.getIpcPort());\n    nodeReg.updateRegInfo(dnReg);\n    nodeReg.exportedKeys \u003d namesystem.getBlockKeys();\n      \n    NameNode.stateChangeLog.info(\"BLOCK* NameSystem.registerDatanode: \"\n        + \"node registration from \" + nodeReg.getName()\n        + \" storage \" + nodeReg.getStorageID());\n\n    DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n    DatanodeDescriptor nodeN \u003d getDatanodeByHost(nodeReg.getName());\n      \n    if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n      NameNode.LOG.info(\"BLOCK* NameSystem.registerDatanode: \"\n                        + \"node from name: \" + nodeN.getName());\n      // nodeN previously served a different data storage, \n      // which is not served by anybody anymore.\n      namesystem.removeDatanode(nodeN);\n      // physically remove node from datanodeMap\n      wipeDatanode(nodeN);\n      nodeN \u003d null;\n    }\n\n    if (nodeS !\u003d null) {\n      if (nodeN \u003d\u003d nodeS) {\n        // The same datanode has been just restarted to serve the same data \n        // storage. We do not need to remove old data blocks, the delta will\n        // be calculated on the next block report from the datanode\n        if(NameNode.stateChangeLog.isDebugEnabled()) {\n          NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.registerDatanode: \"\n                                        + \"node restarted.\");\n        }\n      } else {\n        // nodeS is found\n        /* The registering datanode is a replacement node for the existing \n          data storage, which from now on will be served by a new node.\n          If this message repeats, both nodes might have same storageID \n          by (insanely rare) random chance. User needs to restart one of the\n          nodes with its data cleared (or user can just remove the StorageID\n          value in \"VERSION\" file under the data directory of the datanode,\n          but this is might not work if VERSION file format has changed \n       */        \n        NameNode.stateChangeLog.info( \"BLOCK* NameSystem.registerDatanode: \"\n                                      + \"node \" + nodeS.getName()\n                                      + \" is replaced by \" + nodeReg.getName() + \n                                      \" with the same storageID \" +\n                                      nodeReg.getStorageID());\n      }\n      // update cluster map\n      getNetworkTopology().remove(nodeS);\n      nodeS.updateRegInfo(nodeReg);\n      nodeS.setHostName(hostName);\n      nodeS.setDisallowed(false); // Node is in the include list\n      \n      // resolve network location\n      resolveNetworkLocation(nodeS);\n      getNetworkTopology().add(nodeS);\n        \n      // also treat the registration message as a heartbeat\n      synchronized(namesystem.heartbeats) {\n        if( !namesystem.heartbeats.contains(nodeS)) {\n          namesystem.heartbeats.add(nodeS);\n          //update its timestamp\n          nodeS.updateHeartbeat(0L, 0L, 0L, 0L, 0, 0);\n          nodeS.isAlive \u003d true;\n        }\n      }\n      checkDecommissioning(nodeS, dnAddress);\n      return;\n    } \n\n    // this is a new datanode serving a new data storage\n    if (nodeReg.getStorageID().equals(\"\")) {\n      // this data storage has never been registered\n      // it is either empty or was created by pre-storageID version of DFS\n      nodeReg.storageID \u003d newStorageID();\n      if(NameNode.stateChangeLog.isDebugEnabled()) {\n        NameNode.stateChangeLog.debug(\n            \"BLOCK* NameSystem.registerDatanode: \"\n            + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n      }\n    }\n    // register new datanode\n    DatanodeDescriptor nodeDescr \n      \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK, hostName);\n    resolveNetworkLocation(nodeDescr);\n    addDatanode(nodeDescr);\n    checkDecommissioning(nodeDescr, dnAddress);\n    \n    // also treat the registration message as a heartbeat\n    synchronized(namesystem.heartbeats) {\n      namesystem.heartbeats.add(nodeDescr);\n      nodeDescr.isAlive \u003d true;\n      // no need to update its timestamp\n      // because its is done when the descriptor is created\n    }\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "233a7aa34f37350bf7bcdd9c84b97d613e7344c9": {
      "type": "Ymultichange(Ymovefromfile,Ybodychange,Yrename)",
      "commitMessage": "HDFS-2167.  Move dnsToSwitchMapping and hostsReader from FSNamesystem to DatanodeManager.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1149455 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/07/11 9:20 PM",
      "commitName": "233a7aa34f37350bf7bcdd9c84b97d613e7344c9",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-2167.  Move dnsToSwitchMapping and hostsReader from FSNamesystem to DatanodeManager.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1149455 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "21/07/11 9:20 PM",
          "commitName": "233a7aa34f37350bf7bcdd9c84b97d613e7344c9",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "21/07/11 12:16 PM",
          "commitNameOld": "c187bdc0a28e4f3b9378e2b1daa964c23b599383",
          "commitAuthorOld": "Owen O\u0027Malley",
          "daysBetweenCommits": 0.38,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,121 +1,117 @@\n-  public void registerDatanodeInternal(DatanodeRegistration nodeReg)\n-      throws IOException {\n-    assert hasWriteLock();\n+  public void registerDatanode(DatanodeRegistration nodeReg\n+      ) throws IOException {\n     String dnAddress \u003d Server.getRemoteAddress();\n     if (dnAddress \u003d\u003d null) {\n       // Mostly called inside an RPC.\n       // But if not, use address passed by the data-node.\n       dnAddress \u003d nodeReg.getHost();\n     }      \n \n-    // check if the datanode is allowed to be connect to the namenode\n-    if (!verifyNodeRegistration(nodeReg, dnAddress)) {\n+    // Checks if the node is not on the hosts list.  If it is not, then\n+    // it will be disallowed from registering. \n+    if (!inHostsList(nodeReg, dnAddress)) {\n       throw new DisallowedDatanodeException(nodeReg);\n     }\n \n     String hostName \u003d nodeReg.getHost();\n       \n     // update the datanode\u0027s name with ip:port\n     DatanodeID dnReg \u003d new DatanodeID(dnAddress + \":\" + nodeReg.getPort(),\n                                       nodeReg.getStorageID(),\n                                       nodeReg.getInfoPort(),\n                                       nodeReg.getIpcPort());\n     nodeReg.updateRegInfo(dnReg);\n-    nodeReg.exportedKeys \u003d getBlockKeys();\n+    nodeReg.exportedKeys \u003d namesystem.getBlockKeys();\n       \n-    NameNode.stateChangeLog.info(\n-                                 \"BLOCK* NameSystem.registerDatanode: \"\n-                                 + \"node registration from \" + nodeReg.getName()\n-                                 + \" storage \" + nodeReg.getStorageID());\n+    NameNode.stateChangeLog.info(\"BLOCK* NameSystem.registerDatanode: \"\n+        + \"node registration from \" + nodeReg.getName()\n+        + \" storage \" + nodeReg.getStorageID());\n \n-    DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n-    DatanodeDescriptor nodeN \u003d\n-        blockManager.getDatanodeManager().getDatanodeByHost(nodeReg.getName());\n+    DatanodeDescriptor nodeS \u003d namesystem.datanodeMap.get(nodeReg.getStorageID());\n+    DatanodeDescriptor nodeN \u003d getDatanodeByHost(nodeReg.getName());\n       \n     if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n       NameNode.LOG.info(\"BLOCK* NameSystem.registerDatanode: \"\n                         + \"node from name: \" + nodeN.getName());\n       // nodeN previously served a different data storage, \n       // which is not served by anybody anymore.\n-      removeDatanode(nodeN);\n+      namesystem.removeDatanode(nodeN);\n       // physically remove node from datanodeMap\n-      blockManager.getDatanodeManager().wipeDatanode(nodeN);\n+      wipeDatanode(nodeN);\n       nodeN \u003d null;\n     }\n \n     if (nodeS !\u003d null) {\n       if (nodeN \u003d\u003d nodeS) {\n         // The same datanode has been just restarted to serve the same data \n         // storage. We do not need to remove old data blocks, the delta will\n         // be calculated on the next block report from the datanode\n         if(NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.registerDatanode: \"\n                                         + \"node restarted.\");\n         }\n       } else {\n         // nodeS is found\n         /* The registering datanode is a replacement node for the existing \n           data storage, which from now on will be served by a new node.\n           If this message repeats, both nodes might have same storageID \n           by (insanely rare) random chance. User needs to restart one of the\n           nodes with its data cleared (or user can just remove the StorageID\n           value in \"VERSION\" file under the data directory of the datanode,\n           but this is might not work if VERSION file format has changed \n        */        \n         NameNode.stateChangeLog.info( \"BLOCK* NameSystem.registerDatanode: \"\n                                       + \"node \" + nodeS.getName()\n                                       + \" is replaced by \" + nodeReg.getName() + \n                                       \" with the same storageID \" +\n                                       nodeReg.getStorageID());\n       }\n       // update cluster map\n-      blockManager.getDatanodeManager().getNetworkTopology().remove(nodeS);\n+      getNetworkTopology().remove(nodeS);\n       nodeS.updateRegInfo(nodeReg);\n       nodeS.setHostName(hostName);\n       nodeS.setDisallowed(false); // Node is in the include list\n       \n       // resolve network location\n       resolveNetworkLocation(nodeS);\n-      blockManager.getDatanodeManager().getNetworkTopology().add(nodeS);\n+      getNetworkTopology().add(nodeS);\n         \n       // also treat the registration message as a heartbeat\n-      synchronized(heartbeats) {\n-        if( !heartbeats.contains(nodeS)) {\n-          heartbeats.add(nodeS);\n+      synchronized(namesystem.heartbeats) {\n+        if( !namesystem.heartbeats.contains(nodeS)) {\n+          namesystem.heartbeats.add(nodeS);\n           //update its timestamp\n           nodeS.updateHeartbeat(0L, 0L, 0L, 0L, 0, 0);\n           nodeS.isAlive \u003d true;\n         }\n       }\n       checkDecommissioning(nodeS, dnAddress);\n       return;\n     } \n \n     // this is a new datanode serving a new data storage\n     if (nodeReg.getStorageID().equals(\"\")) {\n       // this data storage has never been registered\n       // it is either empty or was created by pre-storageID version of DFS\n       nodeReg.storageID \u003d newStorageID();\n       if(NameNode.stateChangeLog.isDebugEnabled()) {\n         NameNode.stateChangeLog.debug(\n             \"BLOCK* NameSystem.registerDatanode: \"\n             + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n       }\n     }\n     // register new datanode\n     DatanodeDescriptor nodeDescr \n       \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK, hostName);\n     resolveNetworkLocation(nodeDescr);\n-    blockManager.getDatanodeManager().addDatanode(nodeDescr);\n+    addDatanode(nodeDescr);\n     checkDecommissioning(nodeDescr, dnAddress);\n     \n     // also treat the registration message as a heartbeat\n-    synchronized(heartbeats) {\n-      heartbeats.add(nodeDescr);\n+    synchronized(namesystem.heartbeats) {\n+      namesystem.heartbeats.add(nodeDescr);\n       nodeDescr.isAlive \u003d true;\n       // no need to update its timestamp\n       // because its is done when the descriptor is created\n     }\n-\n-    checkSafeMode();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void registerDatanode(DatanodeRegistration nodeReg\n      ) throws IOException {\n    String dnAddress \u003d Server.getRemoteAddress();\n    if (dnAddress \u003d\u003d null) {\n      // Mostly called inside an RPC.\n      // But if not, use address passed by the data-node.\n      dnAddress \u003d nodeReg.getHost();\n    }      \n\n    // Checks if the node is not on the hosts list.  If it is not, then\n    // it will be disallowed from registering. \n    if (!inHostsList(nodeReg, dnAddress)) {\n      throw new DisallowedDatanodeException(nodeReg);\n    }\n\n    String hostName \u003d nodeReg.getHost();\n      \n    // update the datanode\u0027s name with ip:port\n    DatanodeID dnReg \u003d new DatanodeID(dnAddress + \":\" + nodeReg.getPort(),\n                                      nodeReg.getStorageID(),\n                                      nodeReg.getInfoPort(),\n                                      nodeReg.getIpcPort());\n    nodeReg.updateRegInfo(dnReg);\n    nodeReg.exportedKeys \u003d namesystem.getBlockKeys();\n      \n    NameNode.stateChangeLog.info(\"BLOCK* NameSystem.registerDatanode: \"\n        + \"node registration from \" + nodeReg.getName()\n        + \" storage \" + nodeReg.getStorageID());\n\n    DatanodeDescriptor nodeS \u003d namesystem.datanodeMap.get(nodeReg.getStorageID());\n    DatanodeDescriptor nodeN \u003d getDatanodeByHost(nodeReg.getName());\n      \n    if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n      NameNode.LOG.info(\"BLOCK* NameSystem.registerDatanode: \"\n                        + \"node from name: \" + nodeN.getName());\n      // nodeN previously served a different data storage, \n      // which is not served by anybody anymore.\n      namesystem.removeDatanode(nodeN);\n      // physically remove node from datanodeMap\n      wipeDatanode(nodeN);\n      nodeN \u003d null;\n    }\n\n    if (nodeS !\u003d null) {\n      if (nodeN \u003d\u003d nodeS) {\n        // The same datanode has been just restarted to serve the same data \n        // storage. We do not need to remove old data blocks, the delta will\n        // be calculated on the next block report from the datanode\n        if(NameNode.stateChangeLog.isDebugEnabled()) {\n          NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.registerDatanode: \"\n                                        + \"node restarted.\");\n        }\n      } else {\n        // nodeS is found\n        /* The registering datanode is a replacement node for the existing \n          data storage, which from now on will be served by a new node.\n          If this message repeats, both nodes might have same storageID \n          by (insanely rare) random chance. User needs to restart one of the\n          nodes with its data cleared (or user can just remove the StorageID\n          value in \"VERSION\" file under the data directory of the datanode,\n          but this is might not work if VERSION file format has changed \n       */        \n        NameNode.stateChangeLog.info( \"BLOCK* NameSystem.registerDatanode: \"\n                                      + \"node \" + nodeS.getName()\n                                      + \" is replaced by \" + nodeReg.getName() + \n                                      \" with the same storageID \" +\n                                      nodeReg.getStorageID());\n      }\n      // update cluster map\n      getNetworkTopology().remove(nodeS);\n      nodeS.updateRegInfo(nodeReg);\n      nodeS.setHostName(hostName);\n      nodeS.setDisallowed(false); // Node is in the include list\n      \n      // resolve network location\n      resolveNetworkLocation(nodeS);\n      getNetworkTopology().add(nodeS);\n        \n      // also treat the registration message as a heartbeat\n      synchronized(namesystem.heartbeats) {\n        if( !namesystem.heartbeats.contains(nodeS)) {\n          namesystem.heartbeats.add(nodeS);\n          //update its timestamp\n          nodeS.updateHeartbeat(0L, 0L, 0L, 0L, 0, 0);\n          nodeS.isAlive \u003d true;\n        }\n      }\n      checkDecommissioning(nodeS, dnAddress);\n      return;\n    } \n\n    // this is a new datanode serving a new data storage\n    if (nodeReg.getStorageID().equals(\"\")) {\n      // this data storage has never been registered\n      // it is either empty or was created by pre-storageID version of DFS\n      nodeReg.storageID \u003d newStorageID();\n      if(NameNode.stateChangeLog.isDebugEnabled()) {\n        NameNode.stateChangeLog.debug(\n            \"BLOCK* NameSystem.registerDatanode: \"\n            + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n      }\n    }\n    // register new datanode\n    DatanodeDescriptor nodeDescr \n      \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK, hostName);\n    resolveNetworkLocation(nodeDescr);\n    addDatanode(nodeDescr);\n    checkDecommissioning(nodeDescr, dnAddress);\n    \n    // also treat the registration message as a heartbeat\n    synchronized(namesystem.heartbeats) {\n      namesystem.heartbeats.add(nodeDescr);\n      nodeDescr.isAlive \u003d true;\n      // no need to update its timestamp\n      // because its is done when the descriptor is created\n    }\n  }",
          "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
          "extendedDetails": {
            "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
            "newPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
            "oldMethodName": "registerDatanodeInternal",
            "newMethodName": "registerDatanode"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-2167.  Move dnsToSwitchMapping and hostsReader from FSNamesystem to DatanodeManager.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1149455 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "21/07/11 9:20 PM",
          "commitName": "233a7aa34f37350bf7bcdd9c84b97d613e7344c9",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "21/07/11 12:16 PM",
          "commitNameOld": "c187bdc0a28e4f3b9378e2b1daa964c23b599383",
          "commitAuthorOld": "Owen O\u0027Malley",
          "daysBetweenCommits": 0.38,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,121 +1,117 @@\n-  public void registerDatanodeInternal(DatanodeRegistration nodeReg)\n-      throws IOException {\n-    assert hasWriteLock();\n+  public void registerDatanode(DatanodeRegistration nodeReg\n+      ) throws IOException {\n     String dnAddress \u003d Server.getRemoteAddress();\n     if (dnAddress \u003d\u003d null) {\n       // Mostly called inside an RPC.\n       // But if not, use address passed by the data-node.\n       dnAddress \u003d nodeReg.getHost();\n     }      \n \n-    // check if the datanode is allowed to be connect to the namenode\n-    if (!verifyNodeRegistration(nodeReg, dnAddress)) {\n+    // Checks if the node is not on the hosts list.  If it is not, then\n+    // it will be disallowed from registering. \n+    if (!inHostsList(nodeReg, dnAddress)) {\n       throw new DisallowedDatanodeException(nodeReg);\n     }\n \n     String hostName \u003d nodeReg.getHost();\n       \n     // update the datanode\u0027s name with ip:port\n     DatanodeID dnReg \u003d new DatanodeID(dnAddress + \":\" + nodeReg.getPort(),\n                                       nodeReg.getStorageID(),\n                                       nodeReg.getInfoPort(),\n                                       nodeReg.getIpcPort());\n     nodeReg.updateRegInfo(dnReg);\n-    nodeReg.exportedKeys \u003d getBlockKeys();\n+    nodeReg.exportedKeys \u003d namesystem.getBlockKeys();\n       \n-    NameNode.stateChangeLog.info(\n-                                 \"BLOCK* NameSystem.registerDatanode: \"\n-                                 + \"node registration from \" + nodeReg.getName()\n-                                 + \" storage \" + nodeReg.getStorageID());\n+    NameNode.stateChangeLog.info(\"BLOCK* NameSystem.registerDatanode: \"\n+        + \"node registration from \" + nodeReg.getName()\n+        + \" storage \" + nodeReg.getStorageID());\n \n-    DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n-    DatanodeDescriptor nodeN \u003d\n-        blockManager.getDatanodeManager().getDatanodeByHost(nodeReg.getName());\n+    DatanodeDescriptor nodeS \u003d namesystem.datanodeMap.get(nodeReg.getStorageID());\n+    DatanodeDescriptor nodeN \u003d getDatanodeByHost(nodeReg.getName());\n       \n     if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n       NameNode.LOG.info(\"BLOCK* NameSystem.registerDatanode: \"\n                         + \"node from name: \" + nodeN.getName());\n       // nodeN previously served a different data storage, \n       // which is not served by anybody anymore.\n-      removeDatanode(nodeN);\n+      namesystem.removeDatanode(nodeN);\n       // physically remove node from datanodeMap\n-      blockManager.getDatanodeManager().wipeDatanode(nodeN);\n+      wipeDatanode(nodeN);\n       nodeN \u003d null;\n     }\n \n     if (nodeS !\u003d null) {\n       if (nodeN \u003d\u003d nodeS) {\n         // The same datanode has been just restarted to serve the same data \n         // storage. We do not need to remove old data blocks, the delta will\n         // be calculated on the next block report from the datanode\n         if(NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.registerDatanode: \"\n                                         + \"node restarted.\");\n         }\n       } else {\n         // nodeS is found\n         /* The registering datanode is a replacement node for the existing \n           data storage, which from now on will be served by a new node.\n           If this message repeats, both nodes might have same storageID \n           by (insanely rare) random chance. User needs to restart one of the\n           nodes with its data cleared (or user can just remove the StorageID\n           value in \"VERSION\" file under the data directory of the datanode,\n           but this is might not work if VERSION file format has changed \n        */        \n         NameNode.stateChangeLog.info( \"BLOCK* NameSystem.registerDatanode: \"\n                                       + \"node \" + nodeS.getName()\n                                       + \" is replaced by \" + nodeReg.getName() + \n                                       \" with the same storageID \" +\n                                       nodeReg.getStorageID());\n       }\n       // update cluster map\n-      blockManager.getDatanodeManager().getNetworkTopology().remove(nodeS);\n+      getNetworkTopology().remove(nodeS);\n       nodeS.updateRegInfo(nodeReg);\n       nodeS.setHostName(hostName);\n       nodeS.setDisallowed(false); // Node is in the include list\n       \n       // resolve network location\n       resolveNetworkLocation(nodeS);\n-      blockManager.getDatanodeManager().getNetworkTopology().add(nodeS);\n+      getNetworkTopology().add(nodeS);\n         \n       // also treat the registration message as a heartbeat\n-      synchronized(heartbeats) {\n-        if( !heartbeats.contains(nodeS)) {\n-          heartbeats.add(nodeS);\n+      synchronized(namesystem.heartbeats) {\n+        if( !namesystem.heartbeats.contains(nodeS)) {\n+          namesystem.heartbeats.add(nodeS);\n           //update its timestamp\n           nodeS.updateHeartbeat(0L, 0L, 0L, 0L, 0, 0);\n           nodeS.isAlive \u003d true;\n         }\n       }\n       checkDecommissioning(nodeS, dnAddress);\n       return;\n     } \n \n     // this is a new datanode serving a new data storage\n     if (nodeReg.getStorageID().equals(\"\")) {\n       // this data storage has never been registered\n       // it is either empty or was created by pre-storageID version of DFS\n       nodeReg.storageID \u003d newStorageID();\n       if(NameNode.stateChangeLog.isDebugEnabled()) {\n         NameNode.stateChangeLog.debug(\n             \"BLOCK* NameSystem.registerDatanode: \"\n             + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n       }\n     }\n     // register new datanode\n     DatanodeDescriptor nodeDescr \n       \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK, hostName);\n     resolveNetworkLocation(nodeDescr);\n-    blockManager.getDatanodeManager().addDatanode(nodeDescr);\n+    addDatanode(nodeDescr);\n     checkDecommissioning(nodeDescr, dnAddress);\n     \n     // also treat the registration message as a heartbeat\n-    synchronized(heartbeats) {\n-      heartbeats.add(nodeDescr);\n+    synchronized(namesystem.heartbeats) {\n+      namesystem.heartbeats.add(nodeDescr);\n       nodeDescr.isAlive \u003d true;\n       // no need to update its timestamp\n       // because its is done when the descriptor is created\n     }\n-\n-    checkSafeMode();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void registerDatanode(DatanodeRegistration nodeReg\n      ) throws IOException {\n    String dnAddress \u003d Server.getRemoteAddress();\n    if (dnAddress \u003d\u003d null) {\n      // Mostly called inside an RPC.\n      // But if not, use address passed by the data-node.\n      dnAddress \u003d nodeReg.getHost();\n    }      \n\n    // Checks if the node is not on the hosts list.  If it is not, then\n    // it will be disallowed from registering. \n    if (!inHostsList(nodeReg, dnAddress)) {\n      throw new DisallowedDatanodeException(nodeReg);\n    }\n\n    String hostName \u003d nodeReg.getHost();\n      \n    // update the datanode\u0027s name with ip:port\n    DatanodeID dnReg \u003d new DatanodeID(dnAddress + \":\" + nodeReg.getPort(),\n                                      nodeReg.getStorageID(),\n                                      nodeReg.getInfoPort(),\n                                      nodeReg.getIpcPort());\n    nodeReg.updateRegInfo(dnReg);\n    nodeReg.exportedKeys \u003d namesystem.getBlockKeys();\n      \n    NameNode.stateChangeLog.info(\"BLOCK* NameSystem.registerDatanode: \"\n        + \"node registration from \" + nodeReg.getName()\n        + \" storage \" + nodeReg.getStorageID());\n\n    DatanodeDescriptor nodeS \u003d namesystem.datanodeMap.get(nodeReg.getStorageID());\n    DatanodeDescriptor nodeN \u003d getDatanodeByHost(nodeReg.getName());\n      \n    if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n      NameNode.LOG.info(\"BLOCK* NameSystem.registerDatanode: \"\n                        + \"node from name: \" + nodeN.getName());\n      // nodeN previously served a different data storage, \n      // which is not served by anybody anymore.\n      namesystem.removeDatanode(nodeN);\n      // physically remove node from datanodeMap\n      wipeDatanode(nodeN);\n      nodeN \u003d null;\n    }\n\n    if (nodeS !\u003d null) {\n      if (nodeN \u003d\u003d nodeS) {\n        // The same datanode has been just restarted to serve the same data \n        // storage. We do not need to remove old data blocks, the delta will\n        // be calculated on the next block report from the datanode\n        if(NameNode.stateChangeLog.isDebugEnabled()) {\n          NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.registerDatanode: \"\n                                        + \"node restarted.\");\n        }\n      } else {\n        // nodeS is found\n        /* The registering datanode is a replacement node for the existing \n          data storage, which from now on will be served by a new node.\n          If this message repeats, both nodes might have same storageID \n          by (insanely rare) random chance. User needs to restart one of the\n          nodes with its data cleared (or user can just remove the StorageID\n          value in \"VERSION\" file under the data directory of the datanode,\n          but this is might not work if VERSION file format has changed \n       */        \n        NameNode.stateChangeLog.info( \"BLOCK* NameSystem.registerDatanode: \"\n                                      + \"node \" + nodeS.getName()\n                                      + \" is replaced by \" + nodeReg.getName() + \n                                      \" with the same storageID \" +\n                                      nodeReg.getStorageID());\n      }\n      // update cluster map\n      getNetworkTopology().remove(nodeS);\n      nodeS.updateRegInfo(nodeReg);\n      nodeS.setHostName(hostName);\n      nodeS.setDisallowed(false); // Node is in the include list\n      \n      // resolve network location\n      resolveNetworkLocation(nodeS);\n      getNetworkTopology().add(nodeS);\n        \n      // also treat the registration message as a heartbeat\n      synchronized(namesystem.heartbeats) {\n        if( !namesystem.heartbeats.contains(nodeS)) {\n          namesystem.heartbeats.add(nodeS);\n          //update its timestamp\n          nodeS.updateHeartbeat(0L, 0L, 0L, 0L, 0, 0);\n          nodeS.isAlive \u003d true;\n        }\n      }\n      checkDecommissioning(nodeS, dnAddress);\n      return;\n    } \n\n    // this is a new datanode serving a new data storage\n    if (nodeReg.getStorageID().equals(\"\")) {\n      // this data storage has never been registered\n      // it is either empty or was created by pre-storageID version of DFS\n      nodeReg.storageID \u003d newStorageID();\n      if(NameNode.stateChangeLog.isDebugEnabled()) {\n        NameNode.stateChangeLog.debug(\n            \"BLOCK* NameSystem.registerDatanode: \"\n            + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n      }\n    }\n    // register new datanode\n    DatanodeDescriptor nodeDescr \n      \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK, hostName);\n    resolveNetworkLocation(nodeDescr);\n    addDatanode(nodeDescr);\n    checkDecommissioning(nodeDescr, dnAddress);\n    \n    // also treat the registration message as a heartbeat\n    synchronized(namesystem.heartbeats) {\n      namesystem.heartbeats.add(nodeDescr);\n      nodeDescr.isAlive \u003d true;\n      // no need to update its timestamp\n      // because its is done when the descriptor is created\n    }\n  }",
          "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
          "extendedDetails": {}
        },
        {
          "type": "Yrename",
          "commitMessage": "HDFS-2167.  Move dnsToSwitchMapping and hostsReader from FSNamesystem to DatanodeManager.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1149455 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "21/07/11 9:20 PM",
          "commitName": "233a7aa34f37350bf7bcdd9c84b97d613e7344c9",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "21/07/11 12:16 PM",
          "commitNameOld": "c187bdc0a28e4f3b9378e2b1daa964c23b599383",
          "commitAuthorOld": "Owen O\u0027Malley",
          "daysBetweenCommits": 0.38,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,121 +1,117 @@\n-  public void registerDatanodeInternal(DatanodeRegistration nodeReg)\n-      throws IOException {\n-    assert hasWriteLock();\n+  public void registerDatanode(DatanodeRegistration nodeReg\n+      ) throws IOException {\n     String dnAddress \u003d Server.getRemoteAddress();\n     if (dnAddress \u003d\u003d null) {\n       // Mostly called inside an RPC.\n       // But if not, use address passed by the data-node.\n       dnAddress \u003d nodeReg.getHost();\n     }      \n \n-    // check if the datanode is allowed to be connect to the namenode\n-    if (!verifyNodeRegistration(nodeReg, dnAddress)) {\n+    // Checks if the node is not on the hosts list.  If it is not, then\n+    // it will be disallowed from registering. \n+    if (!inHostsList(nodeReg, dnAddress)) {\n       throw new DisallowedDatanodeException(nodeReg);\n     }\n \n     String hostName \u003d nodeReg.getHost();\n       \n     // update the datanode\u0027s name with ip:port\n     DatanodeID dnReg \u003d new DatanodeID(dnAddress + \":\" + nodeReg.getPort(),\n                                       nodeReg.getStorageID(),\n                                       nodeReg.getInfoPort(),\n                                       nodeReg.getIpcPort());\n     nodeReg.updateRegInfo(dnReg);\n-    nodeReg.exportedKeys \u003d getBlockKeys();\n+    nodeReg.exportedKeys \u003d namesystem.getBlockKeys();\n       \n-    NameNode.stateChangeLog.info(\n-                                 \"BLOCK* NameSystem.registerDatanode: \"\n-                                 + \"node registration from \" + nodeReg.getName()\n-                                 + \" storage \" + nodeReg.getStorageID());\n+    NameNode.stateChangeLog.info(\"BLOCK* NameSystem.registerDatanode: \"\n+        + \"node registration from \" + nodeReg.getName()\n+        + \" storage \" + nodeReg.getStorageID());\n \n-    DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n-    DatanodeDescriptor nodeN \u003d\n-        blockManager.getDatanodeManager().getDatanodeByHost(nodeReg.getName());\n+    DatanodeDescriptor nodeS \u003d namesystem.datanodeMap.get(nodeReg.getStorageID());\n+    DatanodeDescriptor nodeN \u003d getDatanodeByHost(nodeReg.getName());\n       \n     if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n       NameNode.LOG.info(\"BLOCK* NameSystem.registerDatanode: \"\n                         + \"node from name: \" + nodeN.getName());\n       // nodeN previously served a different data storage, \n       // which is not served by anybody anymore.\n-      removeDatanode(nodeN);\n+      namesystem.removeDatanode(nodeN);\n       // physically remove node from datanodeMap\n-      blockManager.getDatanodeManager().wipeDatanode(nodeN);\n+      wipeDatanode(nodeN);\n       nodeN \u003d null;\n     }\n \n     if (nodeS !\u003d null) {\n       if (nodeN \u003d\u003d nodeS) {\n         // The same datanode has been just restarted to serve the same data \n         // storage. We do not need to remove old data blocks, the delta will\n         // be calculated on the next block report from the datanode\n         if(NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.registerDatanode: \"\n                                         + \"node restarted.\");\n         }\n       } else {\n         // nodeS is found\n         /* The registering datanode is a replacement node for the existing \n           data storage, which from now on will be served by a new node.\n           If this message repeats, both nodes might have same storageID \n           by (insanely rare) random chance. User needs to restart one of the\n           nodes with its data cleared (or user can just remove the StorageID\n           value in \"VERSION\" file under the data directory of the datanode,\n           but this is might not work if VERSION file format has changed \n        */        \n         NameNode.stateChangeLog.info( \"BLOCK* NameSystem.registerDatanode: \"\n                                       + \"node \" + nodeS.getName()\n                                       + \" is replaced by \" + nodeReg.getName() + \n                                       \" with the same storageID \" +\n                                       nodeReg.getStorageID());\n       }\n       // update cluster map\n-      blockManager.getDatanodeManager().getNetworkTopology().remove(nodeS);\n+      getNetworkTopology().remove(nodeS);\n       nodeS.updateRegInfo(nodeReg);\n       nodeS.setHostName(hostName);\n       nodeS.setDisallowed(false); // Node is in the include list\n       \n       // resolve network location\n       resolveNetworkLocation(nodeS);\n-      blockManager.getDatanodeManager().getNetworkTopology().add(nodeS);\n+      getNetworkTopology().add(nodeS);\n         \n       // also treat the registration message as a heartbeat\n-      synchronized(heartbeats) {\n-        if( !heartbeats.contains(nodeS)) {\n-          heartbeats.add(nodeS);\n+      synchronized(namesystem.heartbeats) {\n+        if( !namesystem.heartbeats.contains(nodeS)) {\n+          namesystem.heartbeats.add(nodeS);\n           //update its timestamp\n           nodeS.updateHeartbeat(0L, 0L, 0L, 0L, 0, 0);\n           nodeS.isAlive \u003d true;\n         }\n       }\n       checkDecommissioning(nodeS, dnAddress);\n       return;\n     } \n \n     // this is a new datanode serving a new data storage\n     if (nodeReg.getStorageID().equals(\"\")) {\n       // this data storage has never been registered\n       // it is either empty or was created by pre-storageID version of DFS\n       nodeReg.storageID \u003d newStorageID();\n       if(NameNode.stateChangeLog.isDebugEnabled()) {\n         NameNode.stateChangeLog.debug(\n             \"BLOCK* NameSystem.registerDatanode: \"\n             + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n       }\n     }\n     // register new datanode\n     DatanodeDescriptor nodeDescr \n       \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK, hostName);\n     resolveNetworkLocation(nodeDescr);\n-    blockManager.getDatanodeManager().addDatanode(nodeDescr);\n+    addDatanode(nodeDescr);\n     checkDecommissioning(nodeDescr, dnAddress);\n     \n     // also treat the registration message as a heartbeat\n-    synchronized(heartbeats) {\n-      heartbeats.add(nodeDescr);\n+    synchronized(namesystem.heartbeats) {\n+      namesystem.heartbeats.add(nodeDescr);\n       nodeDescr.isAlive \u003d true;\n       // no need to update its timestamp\n       // because its is done when the descriptor is created\n     }\n-\n-    checkSafeMode();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void registerDatanode(DatanodeRegistration nodeReg\n      ) throws IOException {\n    String dnAddress \u003d Server.getRemoteAddress();\n    if (dnAddress \u003d\u003d null) {\n      // Mostly called inside an RPC.\n      // But if not, use address passed by the data-node.\n      dnAddress \u003d nodeReg.getHost();\n    }      \n\n    // Checks if the node is not on the hosts list.  If it is not, then\n    // it will be disallowed from registering. \n    if (!inHostsList(nodeReg, dnAddress)) {\n      throw new DisallowedDatanodeException(nodeReg);\n    }\n\n    String hostName \u003d nodeReg.getHost();\n      \n    // update the datanode\u0027s name with ip:port\n    DatanodeID dnReg \u003d new DatanodeID(dnAddress + \":\" + nodeReg.getPort(),\n                                      nodeReg.getStorageID(),\n                                      nodeReg.getInfoPort(),\n                                      nodeReg.getIpcPort());\n    nodeReg.updateRegInfo(dnReg);\n    nodeReg.exportedKeys \u003d namesystem.getBlockKeys();\n      \n    NameNode.stateChangeLog.info(\"BLOCK* NameSystem.registerDatanode: \"\n        + \"node registration from \" + nodeReg.getName()\n        + \" storage \" + nodeReg.getStorageID());\n\n    DatanodeDescriptor nodeS \u003d namesystem.datanodeMap.get(nodeReg.getStorageID());\n    DatanodeDescriptor nodeN \u003d getDatanodeByHost(nodeReg.getName());\n      \n    if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n      NameNode.LOG.info(\"BLOCK* NameSystem.registerDatanode: \"\n                        + \"node from name: \" + nodeN.getName());\n      // nodeN previously served a different data storage, \n      // which is not served by anybody anymore.\n      namesystem.removeDatanode(nodeN);\n      // physically remove node from datanodeMap\n      wipeDatanode(nodeN);\n      nodeN \u003d null;\n    }\n\n    if (nodeS !\u003d null) {\n      if (nodeN \u003d\u003d nodeS) {\n        // The same datanode has been just restarted to serve the same data \n        // storage. We do not need to remove old data blocks, the delta will\n        // be calculated on the next block report from the datanode\n        if(NameNode.stateChangeLog.isDebugEnabled()) {\n          NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.registerDatanode: \"\n                                        + \"node restarted.\");\n        }\n      } else {\n        // nodeS is found\n        /* The registering datanode is a replacement node for the existing \n          data storage, which from now on will be served by a new node.\n          If this message repeats, both nodes might have same storageID \n          by (insanely rare) random chance. User needs to restart one of the\n          nodes with its data cleared (or user can just remove the StorageID\n          value in \"VERSION\" file under the data directory of the datanode,\n          but this is might not work if VERSION file format has changed \n       */        \n        NameNode.stateChangeLog.info( \"BLOCK* NameSystem.registerDatanode: \"\n                                      + \"node \" + nodeS.getName()\n                                      + \" is replaced by \" + nodeReg.getName() + \n                                      \" with the same storageID \" +\n                                      nodeReg.getStorageID());\n      }\n      // update cluster map\n      getNetworkTopology().remove(nodeS);\n      nodeS.updateRegInfo(nodeReg);\n      nodeS.setHostName(hostName);\n      nodeS.setDisallowed(false); // Node is in the include list\n      \n      // resolve network location\n      resolveNetworkLocation(nodeS);\n      getNetworkTopology().add(nodeS);\n        \n      // also treat the registration message as a heartbeat\n      synchronized(namesystem.heartbeats) {\n        if( !namesystem.heartbeats.contains(nodeS)) {\n          namesystem.heartbeats.add(nodeS);\n          //update its timestamp\n          nodeS.updateHeartbeat(0L, 0L, 0L, 0L, 0, 0);\n          nodeS.isAlive \u003d true;\n        }\n      }\n      checkDecommissioning(nodeS, dnAddress);\n      return;\n    } \n\n    // this is a new datanode serving a new data storage\n    if (nodeReg.getStorageID().equals(\"\")) {\n      // this data storage has never been registered\n      // it is either empty or was created by pre-storageID version of DFS\n      nodeReg.storageID \u003d newStorageID();\n      if(NameNode.stateChangeLog.isDebugEnabled()) {\n        NameNode.stateChangeLog.debug(\n            \"BLOCK* NameSystem.registerDatanode: \"\n            + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n      }\n    }\n    // register new datanode\n    DatanodeDescriptor nodeDescr \n      \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK, hostName);\n    resolveNetworkLocation(nodeDescr);\n    addDatanode(nodeDescr);\n    checkDecommissioning(nodeDescr, dnAddress);\n    \n    // also treat the registration message as a heartbeat\n    synchronized(namesystem.heartbeats) {\n      namesystem.heartbeats.add(nodeDescr);\n      nodeDescr.isAlive \u003d true;\n      // no need to update its timestamp\n      // because its is done when the descriptor is created\n    }\n  }",
          "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
          "extendedDetails": {
            "oldValue": "registerDatanodeInternal",
            "newValue": "registerDatanode"
          }
        }
      ]
    },
    "c3f6575ca44e8ad803d0b46991472465b595cdeb": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2147. Move cluster network topology to block management and fix some javac warnings.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1148112 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/07/11 5:26 PM",
      "commitName": "c3f6575ca44e8ad803d0b46991472465b595cdeb",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "13/07/11 4:24 PM",
      "commitNameOld": "8327e70be87990c37ac14dcc1cb1a4d209c65593",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 5.04,
      "commitsBetweenForRepo": 17,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,122 +1,121 @@\n   public void registerDatanodeInternal(DatanodeRegistration nodeReg)\n       throws IOException {\n     assert hasWriteLock();\n     String dnAddress \u003d Server.getRemoteAddress();\n     if (dnAddress \u003d\u003d null) {\n       // Mostly called inside an RPC.\n       // But if not, use address passed by the data-node.\n       dnAddress \u003d nodeReg.getHost();\n     }      \n \n     // check if the datanode is allowed to be connect to the namenode\n     if (!verifyNodeRegistration(nodeReg, dnAddress)) {\n       throw new DisallowedDatanodeException(nodeReg);\n     }\n \n     String hostName \u003d nodeReg.getHost();\n       \n     // update the datanode\u0027s name with ip:port\n     DatanodeID dnReg \u003d new DatanodeID(dnAddress + \":\" + nodeReg.getPort(),\n                                       nodeReg.getStorageID(),\n                                       nodeReg.getInfoPort(),\n                                       nodeReg.getIpcPort());\n     nodeReg.updateRegInfo(dnReg);\n     nodeReg.exportedKeys \u003d getBlockKeys();\n       \n     NameNode.stateChangeLog.info(\n                                  \"BLOCK* NameSystem.registerDatanode: \"\n                                  + \"node registration from \" + nodeReg.getName()\n                                  + \" storage \" + nodeReg.getStorageID());\n \n     DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n     DatanodeDescriptor nodeN \u003d\n         blockManager.getDatanodeManager().getDatanodeByHost(nodeReg.getName());\n       \n     if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n       NameNode.LOG.info(\"BLOCK* NameSystem.registerDatanode: \"\n                         + \"node from name: \" + nodeN.getName());\n       // nodeN previously served a different data storage, \n       // which is not served by anybody anymore.\n       removeDatanode(nodeN);\n       // physically remove node from datanodeMap\n       blockManager.getDatanodeManager().wipeDatanode(nodeN);\n       nodeN \u003d null;\n     }\n \n     if (nodeS !\u003d null) {\n       if (nodeN \u003d\u003d nodeS) {\n         // The same datanode has been just restarted to serve the same data \n         // storage. We do not need to remove old data blocks, the delta will\n         // be calculated on the next block report from the datanode\n         if(NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.registerDatanode: \"\n                                         + \"node restarted.\");\n         }\n       } else {\n         // nodeS is found\n         /* The registering datanode is a replacement node for the existing \n           data storage, which from now on will be served by a new node.\n           If this message repeats, both nodes might have same storageID \n           by (insanely rare) random chance. User needs to restart one of the\n           nodes with its data cleared (or user can just remove the StorageID\n           value in \"VERSION\" file under the data directory of the datanode,\n           but this is might not work if VERSION file format has changed \n        */        \n         NameNode.stateChangeLog.info( \"BLOCK* NameSystem.registerDatanode: \"\n                                       + \"node \" + nodeS.getName()\n                                       + \" is replaced by \" + nodeReg.getName() + \n                                       \" with the same storageID \" +\n                                       nodeReg.getStorageID());\n       }\n       // update cluster map\n-      clusterMap.remove(nodeS);\n+      blockManager.getDatanodeManager().getNetworkTopology().remove(nodeS);\n       nodeS.updateRegInfo(nodeReg);\n       nodeS.setHostName(hostName);\n       nodeS.setDisallowed(false); // Node is in the include list\n       \n       // resolve network location\n       resolveNetworkLocation(nodeS);\n-      clusterMap.add(nodeS);\n+      blockManager.getDatanodeManager().getNetworkTopology().add(nodeS);\n         \n       // also treat the registration message as a heartbeat\n       synchronized(heartbeats) {\n         if( !heartbeats.contains(nodeS)) {\n           heartbeats.add(nodeS);\n           //update its timestamp\n           nodeS.updateHeartbeat(0L, 0L, 0L, 0L, 0, 0);\n           nodeS.isAlive \u003d true;\n         }\n       }\n       checkDecommissioning(nodeS, dnAddress);\n       return;\n     } \n \n     // this is a new datanode serving a new data storage\n     if (nodeReg.getStorageID().equals(\"\")) {\n       // this data storage has never been registered\n       // it is either empty or was created by pre-storageID version of DFS\n       nodeReg.storageID \u003d newStorageID();\n       if(NameNode.stateChangeLog.isDebugEnabled()) {\n         NameNode.stateChangeLog.debug(\n             \"BLOCK* NameSystem.registerDatanode: \"\n             + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n       }\n     }\n     // register new datanode\n     DatanodeDescriptor nodeDescr \n       \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK, hostName);\n     resolveNetworkLocation(nodeDescr);\n     blockManager.getDatanodeManager().addDatanode(nodeDescr);\n-    clusterMap.add(nodeDescr);\n     checkDecommissioning(nodeDescr, dnAddress);\n     \n     // also treat the registration message as a heartbeat\n     synchronized(heartbeats) {\n       heartbeats.add(nodeDescr);\n       nodeDescr.isAlive \u003d true;\n       // no need to update its timestamp\n       // because its is done when the descriptor is created\n     }\n \n     checkSafeMode();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void registerDatanodeInternal(DatanodeRegistration nodeReg)\n      throws IOException {\n    assert hasWriteLock();\n    String dnAddress \u003d Server.getRemoteAddress();\n    if (dnAddress \u003d\u003d null) {\n      // Mostly called inside an RPC.\n      // But if not, use address passed by the data-node.\n      dnAddress \u003d nodeReg.getHost();\n    }      \n\n    // check if the datanode is allowed to be connect to the namenode\n    if (!verifyNodeRegistration(nodeReg, dnAddress)) {\n      throw new DisallowedDatanodeException(nodeReg);\n    }\n\n    String hostName \u003d nodeReg.getHost();\n      \n    // update the datanode\u0027s name with ip:port\n    DatanodeID dnReg \u003d new DatanodeID(dnAddress + \":\" + nodeReg.getPort(),\n                                      nodeReg.getStorageID(),\n                                      nodeReg.getInfoPort(),\n                                      nodeReg.getIpcPort());\n    nodeReg.updateRegInfo(dnReg);\n    nodeReg.exportedKeys \u003d getBlockKeys();\n      \n    NameNode.stateChangeLog.info(\n                                 \"BLOCK* NameSystem.registerDatanode: \"\n                                 + \"node registration from \" + nodeReg.getName()\n                                 + \" storage \" + nodeReg.getStorageID());\n\n    DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n    DatanodeDescriptor nodeN \u003d\n        blockManager.getDatanodeManager().getDatanodeByHost(nodeReg.getName());\n      \n    if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n      NameNode.LOG.info(\"BLOCK* NameSystem.registerDatanode: \"\n                        + \"node from name: \" + nodeN.getName());\n      // nodeN previously served a different data storage, \n      // which is not served by anybody anymore.\n      removeDatanode(nodeN);\n      // physically remove node from datanodeMap\n      blockManager.getDatanodeManager().wipeDatanode(nodeN);\n      nodeN \u003d null;\n    }\n\n    if (nodeS !\u003d null) {\n      if (nodeN \u003d\u003d nodeS) {\n        // The same datanode has been just restarted to serve the same data \n        // storage. We do not need to remove old data blocks, the delta will\n        // be calculated on the next block report from the datanode\n        if(NameNode.stateChangeLog.isDebugEnabled()) {\n          NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.registerDatanode: \"\n                                        + \"node restarted.\");\n        }\n      } else {\n        // nodeS is found\n        /* The registering datanode is a replacement node for the existing \n          data storage, which from now on will be served by a new node.\n          If this message repeats, both nodes might have same storageID \n          by (insanely rare) random chance. User needs to restart one of the\n          nodes with its data cleared (or user can just remove the StorageID\n          value in \"VERSION\" file under the data directory of the datanode,\n          but this is might not work if VERSION file format has changed \n       */        \n        NameNode.stateChangeLog.info( \"BLOCK* NameSystem.registerDatanode: \"\n                                      + \"node \" + nodeS.getName()\n                                      + \" is replaced by \" + nodeReg.getName() + \n                                      \" with the same storageID \" +\n                                      nodeReg.getStorageID());\n      }\n      // update cluster map\n      blockManager.getDatanodeManager().getNetworkTopology().remove(nodeS);\n      nodeS.updateRegInfo(nodeReg);\n      nodeS.setHostName(hostName);\n      nodeS.setDisallowed(false); // Node is in the include list\n      \n      // resolve network location\n      resolveNetworkLocation(nodeS);\n      blockManager.getDatanodeManager().getNetworkTopology().add(nodeS);\n        \n      // also treat the registration message as a heartbeat\n      synchronized(heartbeats) {\n        if( !heartbeats.contains(nodeS)) {\n          heartbeats.add(nodeS);\n          //update its timestamp\n          nodeS.updateHeartbeat(0L, 0L, 0L, 0L, 0, 0);\n          nodeS.isAlive \u003d true;\n        }\n      }\n      checkDecommissioning(nodeS, dnAddress);\n      return;\n    } \n\n    // this is a new datanode serving a new data storage\n    if (nodeReg.getStorageID().equals(\"\")) {\n      // this data storage has never been registered\n      // it is either empty or was created by pre-storageID version of DFS\n      nodeReg.storageID \u003d newStorageID();\n      if(NameNode.stateChangeLog.isDebugEnabled()) {\n        NameNode.stateChangeLog.debug(\n            \"BLOCK* NameSystem.registerDatanode: \"\n            + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n      }\n    }\n    // register new datanode\n    DatanodeDescriptor nodeDescr \n      \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK, hostName);\n    resolveNetworkLocation(nodeDescr);\n    blockManager.getDatanodeManager().addDatanode(nodeDescr);\n    checkDecommissioning(nodeDescr, dnAddress);\n    \n    // also treat the registration message as a heartbeat\n    synchronized(heartbeats) {\n      heartbeats.add(nodeDescr);\n      nodeDescr.isAlive \u003d true;\n      // no need to update its timestamp\n      // because its is done when the descriptor is created\n    }\n\n    checkSafeMode();\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "8327e70be87990c37ac14dcc1cb1a4d209c65593": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2140. Move Host2NodesMap to the blockmanagement package.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1146514 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/07/11 4:24 PM",
      "commitName": "8327e70be87990c37ac14dcc1cb1a4d209c65593",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "12/07/11 6:11 PM",
      "commitNameOld": "2c5dd549e31aa5d3377ff2619ede8e92b8dc5d0f",
      "commitAuthorOld": "Jitendra Nath Pandey",
      "daysBetweenCommits": 0.93,
      "commitsBetweenForRepo": 9,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,121 +1,122 @@\n   public void registerDatanodeInternal(DatanodeRegistration nodeReg)\n       throws IOException {\n     assert hasWriteLock();\n     String dnAddress \u003d Server.getRemoteAddress();\n     if (dnAddress \u003d\u003d null) {\n       // Mostly called inside an RPC.\n       // But if not, use address passed by the data-node.\n       dnAddress \u003d nodeReg.getHost();\n     }      \n \n     // check if the datanode is allowed to be connect to the namenode\n     if (!verifyNodeRegistration(nodeReg, dnAddress)) {\n       throw new DisallowedDatanodeException(nodeReg);\n     }\n \n     String hostName \u003d nodeReg.getHost();\n       \n     // update the datanode\u0027s name with ip:port\n     DatanodeID dnReg \u003d new DatanodeID(dnAddress + \":\" + nodeReg.getPort(),\n                                       nodeReg.getStorageID(),\n                                       nodeReg.getInfoPort(),\n                                       nodeReg.getIpcPort());\n     nodeReg.updateRegInfo(dnReg);\n     nodeReg.exportedKeys \u003d getBlockKeys();\n       \n     NameNode.stateChangeLog.info(\n                                  \"BLOCK* NameSystem.registerDatanode: \"\n                                  + \"node registration from \" + nodeReg.getName()\n                                  + \" storage \" + nodeReg.getStorageID());\n \n     DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n-    DatanodeDescriptor nodeN \u003d host2DataNodeMap.getDatanodeByName(nodeReg.getName());\n+    DatanodeDescriptor nodeN \u003d\n+        blockManager.getDatanodeManager().getDatanodeByHost(nodeReg.getName());\n       \n     if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n       NameNode.LOG.info(\"BLOCK* NameSystem.registerDatanode: \"\n                         + \"node from name: \" + nodeN.getName());\n       // nodeN previously served a different data storage, \n       // which is not served by anybody anymore.\n       removeDatanode(nodeN);\n       // physically remove node from datanodeMap\n-      wipeDatanode(nodeN);\n+      blockManager.getDatanodeManager().wipeDatanode(nodeN);\n       nodeN \u003d null;\n     }\n \n     if (nodeS !\u003d null) {\n       if (nodeN \u003d\u003d nodeS) {\n         // The same datanode has been just restarted to serve the same data \n         // storage. We do not need to remove old data blocks, the delta will\n         // be calculated on the next block report from the datanode\n         if(NameNode.stateChangeLog.isDebugEnabled()) {\n           NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.registerDatanode: \"\n                                         + \"node restarted.\");\n         }\n       } else {\n         // nodeS is found\n         /* The registering datanode is a replacement node for the existing \n           data storage, which from now on will be served by a new node.\n           If this message repeats, both nodes might have same storageID \n           by (insanely rare) random chance. User needs to restart one of the\n           nodes with its data cleared (or user can just remove the StorageID\n           value in \"VERSION\" file under the data directory of the datanode,\n           but this is might not work if VERSION file format has changed \n        */        \n         NameNode.stateChangeLog.info( \"BLOCK* NameSystem.registerDatanode: \"\n                                       + \"node \" + nodeS.getName()\n                                       + \" is replaced by \" + nodeReg.getName() + \n                                       \" with the same storageID \" +\n                                       nodeReg.getStorageID());\n       }\n       // update cluster map\n       clusterMap.remove(nodeS);\n       nodeS.updateRegInfo(nodeReg);\n       nodeS.setHostName(hostName);\n       nodeS.setDisallowed(false); // Node is in the include list\n       \n       // resolve network location\n       resolveNetworkLocation(nodeS);\n       clusterMap.add(nodeS);\n         \n       // also treat the registration message as a heartbeat\n       synchronized(heartbeats) {\n         if( !heartbeats.contains(nodeS)) {\n           heartbeats.add(nodeS);\n           //update its timestamp\n           nodeS.updateHeartbeat(0L, 0L, 0L, 0L, 0, 0);\n           nodeS.isAlive \u003d true;\n         }\n       }\n       checkDecommissioning(nodeS, dnAddress);\n       return;\n     } \n \n     // this is a new datanode serving a new data storage\n     if (nodeReg.getStorageID().equals(\"\")) {\n       // this data storage has never been registered\n       // it is either empty or was created by pre-storageID version of DFS\n       nodeReg.storageID \u003d newStorageID();\n       if(NameNode.stateChangeLog.isDebugEnabled()) {\n         NameNode.stateChangeLog.debug(\n             \"BLOCK* NameSystem.registerDatanode: \"\n             + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n       }\n     }\n     // register new datanode\n     DatanodeDescriptor nodeDescr \n       \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK, hostName);\n     resolveNetworkLocation(nodeDescr);\n-    unprotectedAddDatanode(nodeDescr);\n+    blockManager.getDatanodeManager().addDatanode(nodeDescr);\n     clusterMap.add(nodeDescr);\n     checkDecommissioning(nodeDescr, dnAddress);\n     \n     // also treat the registration message as a heartbeat\n     synchronized(heartbeats) {\n       heartbeats.add(nodeDescr);\n       nodeDescr.isAlive \u003d true;\n       // no need to update its timestamp\n       // because its is done when the descriptor is created\n     }\n \n     checkSafeMode();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void registerDatanodeInternal(DatanodeRegistration nodeReg)\n      throws IOException {\n    assert hasWriteLock();\n    String dnAddress \u003d Server.getRemoteAddress();\n    if (dnAddress \u003d\u003d null) {\n      // Mostly called inside an RPC.\n      // But if not, use address passed by the data-node.\n      dnAddress \u003d nodeReg.getHost();\n    }      \n\n    // check if the datanode is allowed to be connect to the namenode\n    if (!verifyNodeRegistration(nodeReg, dnAddress)) {\n      throw new DisallowedDatanodeException(nodeReg);\n    }\n\n    String hostName \u003d nodeReg.getHost();\n      \n    // update the datanode\u0027s name with ip:port\n    DatanodeID dnReg \u003d new DatanodeID(dnAddress + \":\" + nodeReg.getPort(),\n                                      nodeReg.getStorageID(),\n                                      nodeReg.getInfoPort(),\n                                      nodeReg.getIpcPort());\n    nodeReg.updateRegInfo(dnReg);\n    nodeReg.exportedKeys \u003d getBlockKeys();\n      \n    NameNode.stateChangeLog.info(\n                                 \"BLOCK* NameSystem.registerDatanode: \"\n                                 + \"node registration from \" + nodeReg.getName()\n                                 + \" storage \" + nodeReg.getStorageID());\n\n    DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n    DatanodeDescriptor nodeN \u003d\n        blockManager.getDatanodeManager().getDatanodeByHost(nodeReg.getName());\n      \n    if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n      NameNode.LOG.info(\"BLOCK* NameSystem.registerDatanode: \"\n                        + \"node from name: \" + nodeN.getName());\n      // nodeN previously served a different data storage, \n      // which is not served by anybody anymore.\n      removeDatanode(nodeN);\n      // physically remove node from datanodeMap\n      blockManager.getDatanodeManager().wipeDatanode(nodeN);\n      nodeN \u003d null;\n    }\n\n    if (nodeS !\u003d null) {\n      if (nodeN \u003d\u003d nodeS) {\n        // The same datanode has been just restarted to serve the same data \n        // storage. We do not need to remove old data blocks, the delta will\n        // be calculated on the next block report from the datanode\n        if(NameNode.stateChangeLog.isDebugEnabled()) {\n          NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.registerDatanode: \"\n                                        + \"node restarted.\");\n        }\n      } else {\n        // nodeS is found\n        /* The registering datanode is a replacement node for the existing \n          data storage, which from now on will be served by a new node.\n          If this message repeats, both nodes might have same storageID \n          by (insanely rare) random chance. User needs to restart one of the\n          nodes with its data cleared (or user can just remove the StorageID\n          value in \"VERSION\" file under the data directory of the datanode,\n          but this is might not work if VERSION file format has changed \n       */        \n        NameNode.stateChangeLog.info( \"BLOCK* NameSystem.registerDatanode: \"\n                                      + \"node \" + nodeS.getName()\n                                      + \" is replaced by \" + nodeReg.getName() + \n                                      \" with the same storageID \" +\n                                      nodeReg.getStorageID());\n      }\n      // update cluster map\n      clusterMap.remove(nodeS);\n      nodeS.updateRegInfo(nodeReg);\n      nodeS.setHostName(hostName);\n      nodeS.setDisallowed(false); // Node is in the include list\n      \n      // resolve network location\n      resolveNetworkLocation(nodeS);\n      clusterMap.add(nodeS);\n        \n      // also treat the registration message as a heartbeat\n      synchronized(heartbeats) {\n        if( !heartbeats.contains(nodeS)) {\n          heartbeats.add(nodeS);\n          //update its timestamp\n          nodeS.updateHeartbeat(0L, 0L, 0L, 0L, 0, 0);\n          nodeS.isAlive \u003d true;\n        }\n      }\n      checkDecommissioning(nodeS, dnAddress);\n      return;\n    } \n\n    // this is a new datanode serving a new data storage\n    if (nodeReg.getStorageID().equals(\"\")) {\n      // this data storage has never been registered\n      // it is either empty or was created by pre-storageID version of DFS\n      nodeReg.storageID \u003d newStorageID();\n      if(NameNode.stateChangeLog.isDebugEnabled()) {\n        NameNode.stateChangeLog.debug(\n            \"BLOCK* NameSystem.registerDatanode: \"\n            + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n      }\n    }\n    // register new datanode\n    DatanodeDescriptor nodeDescr \n      \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK, hostName);\n    resolveNetworkLocation(nodeDescr);\n    blockManager.getDatanodeManager().addDatanode(nodeDescr);\n    clusterMap.add(nodeDescr);\n    checkDecommissioning(nodeDescr, dnAddress);\n    \n    // also treat the registration message as a heartbeat\n    synchronized(heartbeats) {\n      heartbeats.add(nodeDescr);\n      nodeDescr.isAlive \u003d true;\n      // no need to update its timestamp\n      // because its is done when the descriptor is created\n    }\n\n    checkSafeMode();\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,121 @@\n+  public void registerDatanodeInternal(DatanodeRegistration nodeReg)\n+      throws IOException {\n+    assert hasWriteLock();\n+    String dnAddress \u003d Server.getRemoteAddress();\n+    if (dnAddress \u003d\u003d null) {\n+      // Mostly called inside an RPC.\n+      // But if not, use address passed by the data-node.\n+      dnAddress \u003d nodeReg.getHost();\n+    }      \n+\n+    // check if the datanode is allowed to be connect to the namenode\n+    if (!verifyNodeRegistration(nodeReg, dnAddress)) {\n+      throw new DisallowedDatanodeException(nodeReg);\n+    }\n+\n+    String hostName \u003d nodeReg.getHost();\n+      \n+    // update the datanode\u0027s name with ip:port\n+    DatanodeID dnReg \u003d new DatanodeID(dnAddress + \":\" + nodeReg.getPort(),\n+                                      nodeReg.getStorageID(),\n+                                      nodeReg.getInfoPort(),\n+                                      nodeReg.getIpcPort());\n+    nodeReg.updateRegInfo(dnReg);\n+    nodeReg.exportedKeys \u003d getBlockKeys();\n+      \n+    NameNode.stateChangeLog.info(\n+                                 \"BLOCK* NameSystem.registerDatanode: \"\n+                                 + \"node registration from \" + nodeReg.getName()\n+                                 + \" storage \" + nodeReg.getStorageID());\n+\n+    DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n+    DatanodeDescriptor nodeN \u003d host2DataNodeMap.getDatanodeByName(nodeReg.getName());\n+      \n+    if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n+      NameNode.LOG.info(\"BLOCK* NameSystem.registerDatanode: \"\n+                        + \"node from name: \" + nodeN.getName());\n+      // nodeN previously served a different data storage, \n+      // which is not served by anybody anymore.\n+      removeDatanode(nodeN);\n+      // physically remove node from datanodeMap\n+      wipeDatanode(nodeN);\n+      nodeN \u003d null;\n+    }\n+\n+    if (nodeS !\u003d null) {\n+      if (nodeN \u003d\u003d nodeS) {\n+        // The same datanode has been just restarted to serve the same data \n+        // storage. We do not need to remove old data blocks, the delta will\n+        // be calculated on the next block report from the datanode\n+        if(NameNode.stateChangeLog.isDebugEnabled()) {\n+          NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.registerDatanode: \"\n+                                        + \"node restarted.\");\n+        }\n+      } else {\n+        // nodeS is found\n+        /* The registering datanode is a replacement node for the existing \n+          data storage, which from now on will be served by a new node.\n+          If this message repeats, both nodes might have same storageID \n+          by (insanely rare) random chance. User needs to restart one of the\n+          nodes with its data cleared (or user can just remove the StorageID\n+          value in \"VERSION\" file under the data directory of the datanode,\n+          but this is might not work if VERSION file format has changed \n+       */        \n+        NameNode.stateChangeLog.info( \"BLOCK* NameSystem.registerDatanode: \"\n+                                      + \"node \" + nodeS.getName()\n+                                      + \" is replaced by \" + nodeReg.getName() + \n+                                      \" with the same storageID \" +\n+                                      nodeReg.getStorageID());\n+      }\n+      // update cluster map\n+      clusterMap.remove(nodeS);\n+      nodeS.updateRegInfo(nodeReg);\n+      nodeS.setHostName(hostName);\n+      nodeS.setDisallowed(false); // Node is in the include list\n+      \n+      // resolve network location\n+      resolveNetworkLocation(nodeS);\n+      clusterMap.add(nodeS);\n+        \n+      // also treat the registration message as a heartbeat\n+      synchronized(heartbeats) {\n+        if( !heartbeats.contains(nodeS)) {\n+          heartbeats.add(nodeS);\n+          //update its timestamp\n+          nodeS.updateHeartbeat(0L, 0L, 0L, 0L, 0, 0);\n+          nodeS.isAlive \u003d true;\n+        }\n+      }\n+      checkDecommissioning(nodeS, dnAddress);\n+      return;\n+    } \n+\n+    // this is a new datanode serving a new data storage\n+    if (nodeReg.getStorageID().equals(\"\")) {\n+      // this data storage has never been registered\n+      // it is either empty or was created by pre-storageID version of DFS\n+      nodeReg.storageID \u003d newStorageID();\n+      if(NameNode.stateChangeLog.isDebugEnabled()) {\n+        NameNode.stateChangeLog.debug(\n+            \"BLOCK* NameSystem.registerDatanode: \"\n+            + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n+      }\n+    }\n+    // register new datanode\n+    DatanodeDescriptor nodeDescr \n+      \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK, hostName);\n+    resolveNetworkLocation(nodeDescr);\n+    unprotectedAddDatanode(nodeDescr);\n+    clusterMap.add(nodeDescr);\n+    checkDecommissioning(nodeDescr, dnAddress);\n+    \n+    // also treat the registration message as a heartbeat\n+    synchronized(heartbeats) {\n+      heartbeats.add(nodeDescr);\n+      nodeDescr.isAlive \u003d true;\n+      // no need to update its timestamp\n+      // because its is done when the descriptor is created\n+    }\n+\n+    checkSafeMode();\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void registerDatanodeInternal(DatanodeRegistration nodeReg)\n      throws IOException {\n    assert hasWriteLock();\n    String dnAddress \u003d Server.getRemoteAddress();\n    if (dnAddress \u003d\u003d null) {\n      // Mostly called inside an RPC.\n      // But if not, use address passed by the data-node.\n      dnAddress \u003d nodeReg.getHost();\n    }      \n\n    // check if the datanode is allowed to be connect to the namenode\n    if (!verifyNodeRegistration(nodeReg, dnAddress)) {\n      throw new DisallowedDatanodeException(nodeReg);\n    }\n\n    String hostName \u003d nodeReg.getHost();\n      \n    // update the datanode\u0027s name with ip:port\n    DatanodeID dnReg \u003d new DatanodeID(dnAddress + \":\" + nodeReg.getPort(),\n                                      nodeReg.getStorageID(),\n                                      nodeReg.getInfoPort(),\n                                      nodeReg.getIpcPort());\n    nodeReg.updateRegInfo(dnReg);\n    nodeReg.exportedKeys \u003d getBlockKeys();\n      \n    NameNode.stateChangeLog.info(\n                                 \"BLOCK* NameSystem.registerDatanode: \"\n                                 + \"node registration from \" + nodeReg.getName()\n                                 + \" storage \" + nodeReg.getStorageID());\n\n    DatanodeDescriptor nodeS \u003d datanodeMap.get(nodeReg.getStorageID());\n    DatanodeDescriptor nodeN \u003d host2DataNodeMap.getDatanodeByName(nodeReg.getName());\n      \n    if (nodeN !\u003d null \u0026\u0026 nodeN !\u003d nodeS) {\n      NameNode.LOG.info(\"BLOCK* NameSystem.registerDatanode: \"\n                        + \"node from name: \" + nodeN.getName());\n      // nodeN previously served a different data storage, \n      // which is not served by anybody anymore.\n      removeDatanode(nodeN);\n      // physically remove node from datanodeMap\n      wipeDatanode(nodeN);\n      nodeN \u003d null;\n    }\n\n    if (nodeS !\u003d null) {\n      if (nodeN \u003d\u003d nodeS) {\n        // The same datanode has been just restarted to serve the same data \n        // storage. We do not need to remove old data blocks, the delta will\n        // be calculated on the next block report from the datanode\n        if(NameNode.stateChangeLog.isDebugEnabled()) {\n          NameNode.stateChangeLog.debug(\"BLOCK* NameSystem.registerDatanode: \"\n                                        + \"node restarted.\");\n        }\n      } else {\n        // nodeS is found\n        /* The registering datanode is a replacement node for the existing \n          data storage, which from now on will be served by a new node.\n          If this message repeats, both nodes might have same storageID \n          by (insanely rare) random chance. User needs to restart one of the\n          nodes with its data cleared (or user can just remove the StorageID\n          value in \"VERSION\" file under the data directory of the datanode,\n          but this is might not work if VERSION file format has changed \n       */        \n        NameNode.stateChangeLog.info( \"BLOCK* NameSystem.registerDatanode: \"\n                                      + \"node \" + nodeS.getName()\n                                      + \" is replaced by \" + nodeReg.getName() + \n                                      \" with the same storageID \" +\n                                      nodeReg.getStorageID());\n      }\n      // update cluster map\n      clusterMap.remove(nodeS);\n      nodeS.updateRegInfo(nodeReg);\n      nodeS.setHostName(hostName);\n      nodeS.setDisallowed(false); // Node is in the include list\n      \n      // resolve network location\n      resolveNetworkLocation(nodeS);\n      clusterMap.add(nodeS);\n        \n      // also treat the registration message as a heartbeat\n      synchronized(heartbeats) {\n        if( !heartbeats.contains(nodeS)) {\n          heartbeats.add(nodeS);\n          //update its timestamp\n          nodeS.updateHeartbeat(0L, 0L, 0L, 0L, 0, 0);\n          nodeS.isAlive \u003d true;\n        }\n      }\n      checkDecommissioning(nodeS, dnAddress);\n      return;\n    } \n\n    // this is a new datanode serving a new data storage\n    if (nodeReg.getStorageID().equals(\"\")) {\n      // this data storage has never been registered\n      // it is either empty or was created by pre-storageID version of DFS\n      nodeReg.storageID \u003d newStorageID();\n      if(NameNode.stateChangeLog.isDebugEnabled()) {\n        NameNode.stateChangeLog.debug(\n            \"BLOCK* NameSystem.registerDatanode: \"\n            + \"new storageID \" + nodeReg.getStorageID() + \" assigned.\");\n      }\n    }\n    // register new datanode\n    DatanodeDescriptor nodeDescr \n      \u003d new DatanodeDescriptor(nodeReg, NetworkTopology.DEFAULT_RACK, hostName);\n    resolveNetworkLocation(nodeDescr);\n    unprotectedAddDatanode(nodeDescr);\n    clusterMap.add(nodeDescr);\n    checkDecommissioning(nodeDescr, dnAddress);\n    \n    // also treat the registration message as a heartbeat\n    synchronized(heartbeats) {\n      heartbeats.add(nodeDescr);\n      nodeDescr.isAlive \u003d true;\n      // no need to update its timestamp\n      // because its is done when the descriptor is created\n    }\n\n    checkSafeMode();\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java"
    }
  }
}