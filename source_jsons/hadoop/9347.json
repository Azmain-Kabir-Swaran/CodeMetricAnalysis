{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSNamesystem.java",
  "functionName": "getECTopologyResultForPolicies",
  "functionId": "getECTopologyResultForPolicies___policyNames-String[]",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
  "functionStartLine": 8176,
  "functionEndLine": 8209,
  "numCommitsSeen": 873,
  "timeTaken": 3807,
  "changeHistory": [
    "1824aee9da4056de0fb638906b2172e486bbebe7",
    "92c58901d767f4fea571274544a590608c911cb8"
  ],
  "changeHistoryShort": {
    "1824aee9da4056de0fb638906b2172e486bbebe7": "Ybodychange",
    "92c58901d767f4fea571274544a590608c911cb8": "Yintroduced"
  },
  "changeHistoryDetails": {
    "1824aee9da4056de0fb638906b2172e486bbebe7": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-15217 Add more information to longest write/read lock held log\n\n",
      "commitDate": "18/04/20 1:52 PM",
      "commitName": "1824aee9da4056de0fb638906b2172e486bbebe7",
      "commitAuthor": "Toshihiro Suzuki",
      "commitDateOld": "25/03/20 10:28 AM",
      "commitNameOld": "a700803a18fb957d2799001a2ce1dcb70f75c080",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 24.14,
      "commitsBetweenForRepo": 78,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,34 +1,34 @@\n   public ECTopologyVerifierResult getECTopologyResultForPolicies(\n       String[] policyNames) throws IOException {\n     String operationName \u003d \"getECTopologyResultForPolicies\";\n     checkSuperuserPrivilege(operationName);\n     checkOperation(OperationCategory.UNCHECKED);\n     ECTopologyVerifierResult result;\n     readLock();\n     try {\n       checkOperation(OperationCategory.UNCHECKED);\n       // If no policy name is specified return the result\n       // for all enabled policies.\n       if (policyNames \u003d\u003d null || policyNames.length \u003d\u003d 0) {\n         result \u003d getEcTopologyVerifierResultForEnabledPolicies();\n       } else {\n         Collection\u003cErasureCodingPolicy\u003e policies \u003d\n             new ArrayList\u003cErasureCodingPolicy\u003e();\n         for (int i \u003d 0; i \u003c policyNames.length; i++) {\n           policies.add(FSDirErasureCodingOp\n               .getErasureCodingPolicyByName(this, policyNames[i]));\n         }\n         int numOfDataNodes \u003d\n             getBlockManager().getDatanodeManager().getNumOfDataNodes();\n         int numOfRacks \u003d\n             getBlockManager().getDatanodeManager().getNetworkTopology()\n                 .getNumOfRacks();\n         result \u003d ECTopologyVerifier\n             .getECTopologyVerifierResult(numOfRacks, numOfDataNodes, policies);\n       }\n     } finally {\n-      readUnlock();\n+      readUnlock(operationName, getLockReportInfoSupplier(null));\n     }\n     logAuditEvent(true, operationName, null);\n     return result;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ECTopologyVerifierResult getECTopologyResultForPolicies(\n      String[] policyNames) throws IOException {\n    String operationName \u003d \"getECTopologyResultForPolicies\";\n    checkSuperuserPrivilege(operationName);\n    checkOperation(OperationCategory.UNCHECKED);\n    ECTopologyVerifierResult result;\n    readLock();\n    try {\n      checkOperation(OperationCategory.UNCHECKED);\n      // If no policy name is specified return the result\n      // for all enabled policies.\n      if (policyNames \u003d\u003d null || policyNames.length \u003d\u003d 0) {\n        result \u003d getEcTopologyVerifierResultForEnabledPolicies();\n      } else {\n        Collection\u003cErasureCodingPolicy\u003e policies \u003d\n            new ArrayList\u003cErasureCodingPolicy\u003e();\n        for (int i \u003d 0; i \u003c policyNames.length; i++) {\n          policies.add(FSDirErasureCodingOp\n              .getErasureCodingPolicyByName(this, policyNames[i]));\n        }\n        int numOfDataNodes \u003d\n            getBlockManager().getDatanodeManager().getNumOfDataNodes();\n        int numOfRacks \u003d\n            getBlockManager().getDatanodeManager().getNetworkTopology()\n                .getNumOfRacks();\n        result \u003d ECTopologyVerifier\n            .getECTopologyVerifierResult(numOfRacks, numOfDataNodes, policies);\n      }\n    } finally {\n      readUnlock(operationName, getLockReportInfoSupplier(null));\n    }\n    logAuditEvent(true, operationName, null);\n    return result;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "92c58901d767f4fea571274544a590608c911cb8": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-15117. EC: Add getECTopologyResultForPolicies to DistributedFileSystem. Contributed by Ayush Saxena\n",
      "commitDate": "23/01/20 4:48 AM",
      "commitName": "92c58901d767f4fea571274544a590608c911cb8",
      "commitAuthor": "Ayush Saxena",
      "diff": "@@ -0,0 +1,34 @@\n+  public ECTopologyVerifierResult getECTopologyResultForPolicies(\n+      String[] policyNames) throws IOException {\n+    String operationName \u003d \"getECTopologyResultForPolicies\";\n+    checkSuperuserPrivilege(operationName);\n+    checkOperation(OperationCategory.UNCHECKED);\n+    ECTopologyVerifierResult result;\n+    readLock();\n+    try {\n+      checkOperation(OperationCategory.UNCHECKED);\n+      // If no policy name is specified return the result\n+      // for all enabled policies.\n+      if (policyNames \u003d\u003d null || policyNames.length \u003d\u003d 0) {\n+        result \u003d getEcTopologyVerifierResultForEnabledPolicies();\n+      } else {\n+        Collection\u003cErasureCodingPolicy\u003e policies \u003d\n+            new ArrayList\u003cErasureCodingPolicy\u003e();\n+        for (int i \u003d 0; i \u003c policyNames.length; i++) {\n+          policies.add(FSDirErasureCodingOp\n+              .getErasureCodingPolicyByName(this, policyNames[i]));\n+        }\n+        int numOfDataNodes \u003d\n+            getBlockManager().getDatanodeManager().getNumOfDataNodes();\n+        int numOfRacks \u003d\n+            getBlockManager().getDatanodeManager().getNetworkTopology()\n+                .getNumOfRacks();\n+        result \u003d ECTopologyVerifier\n+            .getECTopologyVerifierResult(numOfRacks, numOfDataNodes, policies);\n+      }\n+    } finally {\n+      readUnlock();\n+    }\n+    logAuditEvent(true, operationName, null);\n+    return result;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public ECTopologyVerifierResult getECTopologyResultForPolicies(\n      String[] policyNames) throws IOException {\n    String operationName \u003d \"getECTopologyResultForPolicies\";\n    checkSuperuserPrivilege(operationName);\n    checkOperation(OperationCategory.UNCHECKED);\n    ECTopologyVerifierResult result;\n    readLock();\n    try {\n      checkOperation(OperationCategory.UNCHECKED);\n      // If no policy name is specified return the result\n      // for all enabled policies.\n      if (policyNames \u003d\u003d null || policyNames.length \u003d\u003d 0) {\n        result \u003d getEcTopologyVerifierResultForEnabledPolicies();\n      } else {\n        Collection\u003cErasureCodingPolicy\u003e policies \u003d\n            new ArrayList\u003cErasureCodingPolicy\u003e();\n        for (int i \u003d 0; i \u003c policyNames.length; i++) {\n          policies.add(FSDirErasureCodingOp\n              .getErasureCodingPolicyByName(this, policyNames[i]));\n        }\n        int numOfDataNodes \u003d\n            getBlockManager().getDatanodeManager().getNumOfDataNodes();\n        int numOfRacks \u003d\n            getBlockManager().getDatanodeManager().getNetworkTopology()\n                .getNumOfRacks();\n        result \u003d ECTopologyVerifier\n            .getECTopologyVerifierResult(numOfRacks, numOfDataNodes, policies);\n      }\n    } finally {\n      readUnlock();\n    }\n    logAuditEvent(true, operationName, null);\n    return result;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java"
    }
  }
}