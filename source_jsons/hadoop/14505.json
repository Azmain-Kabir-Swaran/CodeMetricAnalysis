{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "JournalNode.java",
  "functionName": "start",
  "functionId": "start",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JournalNode.java",
  "functionStartLine": 216,
  "functionEndLine": 250,
  "numCommitsSeen": 32,
  "timeTaken": 2883,
  "changeHistory": [
    "c9b33514b8d11db44b5f95b4df43789ed45c47a7",
    "dd50f53997239bf9078481cf46592ca3e41520b5",
    "68282c8eacfedb0298741e6c41ff0b2ec71b018c",
    "a5b37c6ed14e92f5a7f7dd76a9a82b3f859fb6dd",
    "87a6db45b70a1a07165e0773c4452d1327258bfa",
    "02b19e0738d9df1e4d38280c5575e1d3ba49f8cb",
    "df801074c929d5414b92cc9fc0cc8a2794e02751",
    "160bfcd6c2e2bc4a4adfa397f0f716430a0832bb",
    "74d4573a23db5586c6e47ff2277aa7c35237da34"
  ],
  "changeHistoryShort": {
    "c9b33514b8d11db44b5f95b4df43789ed45c47a7": "Ybodychange",
    "dd50f53997239bf9078481cf46592ca3e41520b5": "Ybodychange",
    "68282c8eacfedb0298741e6c41ff0b2ec71b018c": "Ybodychange",
    "a5b37c6ed14e92f5a7f7dd76a9a82b3f859fb6dd": "Ybodychange",
    "87a6db45b70a1a07165e0773c4452d1327258bfa": "Ybodychange",
    "02b19e0738d9df1e4d38280c5575e1d3ba49f8cb": "Ybodychange",
    "df801074c929d5414b92cc9fc0cc8a2794e02751": "Ybodychange",
    "160bfcd6c2e2bc4a4adfa397f0f716430a0832bb": "Ybodychange",
    "74d4573a23db5586c6e47ff2277aa7c35237da34": "Yintroduced"
  },
  "changeHistoryDetails": {
    "c9b33514b8d11db44b5f95b4df43789ed45c47a7": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13462. Add BIND_HOST configuration for JournalNode\u0027s HTTP and RPC Servers. Contributed by Lukas Majercak.\n",
      "commitDate": "17/04/18 2:19 PM",
      "commitName": "c9b33514b8d11db44b5f95b4df43789ed45c47a7",
      "commitAuthor": "Inigo Goiri",
      "commitDateOld": "01/02/18 12:28 PM",
      "commitNameOld": "dd50f53997239bf9078481cf46592ca3e41520b5",
      "commitAuthorOld": "Hanisha Koneru",
      "daysBetweenCommits": 75.04,
      "commitsBetweenForRepo": 608,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,34 +1,35 @@\n   public void start() throws IOException {\n     Preconditions.checkState(!isStarted(), \"JN already running\");\n \n     try {\n \n       for (File journalDir : localDir) {\n         validateAndCreateJournalDir(journalDir);\n       }\n       DefaultMetricsSystem.initialize(\"JournalNode\");\n       JvmMetrics.create(\"JournalNode\",\n           conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n           DefaultMetricsSystem.instance());\n \n       InetSocketAddress socAddr \u003d JournalNodeRpcServer.getAddress(conf);\n       SecurityUtil.login(conf, DFSConfigKeys.DFS_JOURNALNODE_KEYTAB_FILE_KEY,\n           DFSConfigKeys.DFS_JOURNALNODE_KERBEROS_PRINCIPAL_KEY,\n           socAddr.getHostName());\n \n       registerJNMXBean();\n \n-      httpServer \u003d new JournalNodeHttpServer(conf, this);\n+      httpServer \u003d new JournalNodeHttpServer(conf, this,\n+          getHttpServerBindAddress(conf));\n       httpServer.start();\n \n       httpServerURI \u003d httpServer.getServerURI().toString();\n \n       rpcServer \u003d new JournalNodeRpcServer(conf, this);\n       rpcServer.start();\n     } catch (IOException ioe) {\n       //Shutdown JournalNode of JournalNodeRpcServer fails to start\n       LOG.error(\"Failed to start JournalNode.\", ioe);\n       this.stop(1);\n       throw ioe;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void start() throws IOException {\n    Preconditions.checkState(!isStarted(), \"JN already running\");\n\n    try {\n\n      for (File journalDir : localDir) {\n        validateAndCreateJournalDir(journalDir);\n      }\n      DefaultMetricsSystem.initialize(\"JournalNode\");\n      JvmMetrics.create(\"JournalNode\",\n          conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n          DefaultMetricsSystem.instance());\n\n      InetSocketAddress socAddr \u003d JournalNodeRpcServer.getAddress(conf);\n      SecurityUtil.login(conf, DFSConfigKeys.DFS_JOURNALNODE_KEYTAB_FILE_KEY,\n          DFSConfigKeys.DFS_JOURNALNODE_KERBEROS_PRINCIPAL_KEY,\n          socAddr.getHostName());\n\n      registerJNMXBean();\n\n      httpServer \u003d new JournalNodeHttpServer(conf, this,\n          getHttpServerBindAddress(conf));\n      httpServer.start();\n\n      httpServerURI \u003d httpServer.getServerURI().toString();\n\n      rpcServer \u003d new JournalNodeRpcServer(conf, this);\n      rpcServer.start();\n    } catch (IOException ioe) {\n      //Shutdown JournalNode of JournalNodeRpcServer fails to start\n      LOG.error(\"Failed to start JournalNode.\", ioe);\n      this.stop(1);\n      throw ioe;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JournalNode.java",
      "extendedDetails": {}
    },
    "dd50f53997239bf9078481cf46592ca3e41520b5": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13062. Provide support for JN to use separate journal disk per namespace. Contributed by Bharat Viswanadham.\n",
      "commitDate": "01/02/18 12:28 PM",
      "commitName": "dd50f53997239bf9078481cf46592ca3e41520b5",
      "commitAuthor": "Hanisha Koneru",
      "commitDateOld": "13/10/17 2:22 PM",
      "commitNameOld": "8dd1eeb94fef59feaf19182dd8f1fcf1389c7f34",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 110.96,
      "commitsBetweenForRepo": 747,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,33 +1,34 @@\n   public void start() throws IOException {\n     Preconditions.checkState(!isStarted(), \"JN already running\");\n \n     try {\n \n-      validateAndCreateJournalDir(localDir);\n-\n+      for (File journalDir : localDir) {\n+        validateAndCreateJournalDir(journalDir);\n+      }\n       DefaultMetricsSystem.initialize(\"JournalNode\");\n       JvmMetrics.create(\"JournalNode\",\n           conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n           DefaultMetricsSystem.instance());\n \n       InetSocketAddress socAddr \u003d JournalNodeRpcServer.getAddress(conf);\n       SecurityUtil.login(conf, DFSConfigKeys.DFS_JOURNALNODE_KEYTAB_FILE_KEY,\n           DFSConfigKeys.DFS_JOURNALNODE_KERBEROS_PRINCIPAL_KEY,\n           socAddr.getHostName());\n \n       registerJNMXBean();\n \n       httpServer \u003d new JournalNodeHttpServer(conf, this);\n       httpServer.start();\n \n       httpServerURI \u003d httpServer.getServerURI().toString();\n \n       rpcServer \u003d new JournalNodeRpcServer(conf, this);\n       rpcServer.start();\n     } catch (IOException ioe) {\n       //Shutdown JournalNode of JournalNodeRpcServer fails to start\n       LOG.error(\"Failed to start JournalNode.\", ioe);\n       this.stop(1);\n       throw ioe;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void start() throws IOException {\n    Preconditions.checkState(!isStarted(), \"JN already running\");\n\n    try {\n\n      for (File journalDir : localDir) {\n        validateAndCreateJournalDir(journalDir);\n      }\n      DefaultMetricsSystem.initialize(\"JournalNode\");\n      JvmMetrics.create(\"JournalNode\",\n          conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n          DefaultMetricsSystem.instance());\n\n      InetSocketAddress socAddr \u003d JournalNodeRpcServer.getAddress(conf);\n      SecurityUtil.login(conf, DFSConfigKeys.DFS_JOURNALNODE_KEYTAB_FILE_KEY,\n          DFSConfigKeys.DFS_JOURNALNODE_KERBEROS_PRINCIPAL_KEY,\n          socAddr.getHostName());\n\n      registerJNMXBean();\n\n      httpServer \u003d new JournalNodeHttpServer(conf, this);\n      httpServer.start();\n\n      httpServerURI \u003d httpServer.getServerURI().toString();\n\n      rpcServer \u003d new JournalNodeRpcServer(conf, this);\n      rpcServer.start();\n    } catch (IOException ioe) {\n      //Shutdown JournalNode of JournalNodeRpcServer fails to start\n      LOG.error(\"Failed to start JournalNode.\", ioe);\n      this.stop(1);\n      throw ioe;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JournalNode.java",
      "extendedDetails": {}
    },
    "68282c8eacfedb0298741e6c41ff0b2ec71b018c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12407. Journal node fails to shutdown cleanly if JournalNodeHttpServer or JournalNodeRpcServer fails to start. Contributed by Ajay Kumar.\n",
      "commitDate": "12/09/17 4:18 PM",
      "commitName": "68282c8eacfedb0298741e6c41ff0b2ec71b018c",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "15/08/17 1:48 AM",
      "commitNameOld": "2e43c28e01fe006210e71aab179527669f6412ed",
      "commitAuthorOld": "Yiqun Lin",
      "daysBetweenCommits": 28.6,
      "commitsBetweenForRepo": 278,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,33 @@\n   public void start() throws IOException {\n     Preconditions.checkState(!isStarted(), \"JN already running\");\n-    \n-    validateAndCreateJournalDir(localDir);\n-    \n-    DefaultMetricsSystem.initialize(\"JournalNode\");\n-    JvmMetrics.create(\"JournalNode\",\n-        conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n-        DefaultMetricsSystem.instance());\n \n-    InetSocketAddress socAddr \u003d JournalNodeRpcServer.getAddress(conf);\n-    SecurityUtil.login(conf, DFSConfigKeys.DFS_JOURNALNODE_KEYTAB_FILE_KEY,\n-        DFSConfigKeys.DFS_JOURNALNODE_KERBEROS_PRINCIPAL_KEY, socAddr.getHostName());\n-    \n-    registerJNMXBean();\n-    \n-    httpServer \u003d new JournalNodeHttpServer(conf, this);\n-    httpServer.start();\n+    try {\n \n-    httpServerURI \u003d httpServer.getServerURI().toString();\n+      validateAndCreateJournalDir(localDir);\n \n-    rpcServer \u003d new JournalNodeRpcServer(conf, this);\n-    rpcServer.start();\n+      DefaultMetricsSystem.initialize(\"JournalNode\");\n+      JvmMetrics.create(\"JournalNode\",\n+          conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n+          DefaultMetricsSystem.instance());\n+\n+      InetSocketAddress socAddr \u003d JournalNodeRpcServer.getAddress(conf);\n+      SecurityUtil.login(conf, DFSConfigKeys.DFS_JOURNALNODE_KEYTAB_FILE_KEY,\n+          DFSConfigKeys.DFS_JOURNALNODE_KERBEROS_PRINCIPAL_KEY,\n+          socAddr.getHostName());\n+\n+      registerJNMXBean();\n+\n+      httpServer \u003d new JournalNodeHttpServer(conf, this);\n+      httpServer.start();\n+\n+      httpServerURI \u003d httpServer.getServerURI().toString();\n+\n+      rpcServer \u003d new JournalNodeRpcServer(conf, this);\n+      rpcServer.start();\n+    } catch (IOException ioe) {\n+      //Shutdown JournalNode of JournalNodeRpcServer fails to start\n+      LOG.error(\"Failed to start JournalNode.\", ioe);\n+      this.stop(1);\n+      throw ioe;\n+    }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void start() throws IOException {\n    Preconditions.checkState(!isStarted(), \"JN already running\");\n\n    try {\n\n      validateAndCreateJournalDir(localDir);\n\n      DefaultMetricsSystem.initialize(\"JournalNode\");\n      JvmMetrics.create(\"JournalNode\",\n          conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n          DefaultMetricsSystem.instance());\n\n      InetSocketAddress socAddr \u003d JournalNodeRpcServer.getAddress(conf);\n      SecurityUtil.login(conf, DFSConfigKeys.DFS_JOURNALNODE_KEYTAB_FILE_KEY,\n          DFSConfigKeys.DFS_JOURNALNODE_KERBEROS_PRINCIPAL_KEY,\n          socAddr.getHostName());\n\n      registerJNMXBean();\n\n      httpServer \u003d new JournalNodeHttpServer(conf, this);\n      httpServer.start();\n\n      httpServerURI \u003d httpServer.getServerURI().toString();\n\n      rpcServer \u003d new JournalNodeRpcServer(conf, this);\n      rpcServer.start();\n    } catch (IOException ioe) {\n      //Shutdown JournalNode of JournalNodeRpcServer fails to start\n      LOG.error(\"Failed to start JournalNode.\", ioe);\n      this.stop(1);\n      throw ioe;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JournalNode.java",
      "extendedDetails": {}
    },
    "a5b37c6ed14e92f5a7f7dd76a9a82b3f859fb6dd": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6181. Fix the wrong property names in NFS user guide. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1585563 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/04/14 11:55 AM",
      "commitName": "a5b37c6ed14e92f5a7f7dd76a9a82b3f859fb6dd",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "24/03/14 11:48 PM",
      "commitNameOld": "56205ca7d7f3b2a7e55f48b9cf444326e1d2b1a7",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 13.51,
      "commitsBetweenForRepo": 73,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,24 @@\n   public void start() throws IOException {\n     Preconditions.checkState(!isStarted(), \"JN already running\");\n     \n     validateAndCreateJournalDir(localDir);\n     \n     DefaultMetricsSystem.initialize(\"JournalNode\");\n     JvmMetrics.create(\"JournalNode\",\n         conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n         DefaultMetricsSystem.instance());\n \n     InetSocketAddress socAddr \u003d JournalNodeRpcServer.getAddress(conf);\n     SecurityUtil.login(conf, DFSConfigKeys.DFS_JOURNALNODE_KEYTAB_FILE_KEY,\n-        DFSConfigKeys.DFS_JOURNALNODE_USER_NAME_KEY, socAddr.getHostName());\n+        DFSConfigKeys.DFS_JOURNALNODE_KERBEROS_PRINCIPAL_KEY, socAddr.getHostName());\n     \n     registerJNMXBean();\n     \n     httpServer \u003d new JournalNodeHttpServer(conf, this);\n     httpServer.start();\n \n     httpServerURI \u003d httpServer.getServerURI().toString();\n \n     rpcServer \u003d new JournalNodeRpcServer(conf, this);\n     rpcServer.start();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void start() throws IOException {\n    Preconditions.checkState(!isStarted(), \"JN already running\");\n    \n    validateAndCreateJournalDir(localDir);\n    \n    DefaultMetricsSystem.initialize(\"JournalNode\");\n    JvmMetrics.create(\"JournalNode\",\n        conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n        DefaultMetricsSystem.instance());\n\n    InetSocketAddress socAddr \u003d JournalNodeRpcServer.getAddress(conf);\n    SecurityUtil.login(conf, DFSConfigKeys.DFS_JOURNALNODE_KEYTAB_FILE_KEY,\n        DFSConfigKeys.DFS_JOURNALNODE_KERBEROS_PRINCIPAL_KEY, socAddr.getHostName());\n    \n    registerJNMXBean();\n    \n    httpServer \u003d new JournalNodeHttpServer(conf, this);\n    httpServer.start();\n\n    httpServerURI \u003d httpServer.getServerURI().toString();\n\n    rpcServer \u003d new JournalNodeRpcServer(conf, this);\n    rpcServer.start();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JournalNode.java",
      "extendedDetails": {}
    },
    "87a6db45b70a1a07165e0773c4452d1327258bfa": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5629. Support HTTPS in JournalNode and SecondaryNameNode. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1549692 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/12/13 1:58 PM",
      "commitName": "87a6db45b70a1a07165e0773c4452d1327258bfa",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "19/11/13 2:44 PM",
      "commitNameOld": "587f68b160411dd90d3215dab6a30126a0bd78a6",
      "commitAuthorOld": "Jonathan Turner Eagles",
      "daysBetweenCommits": 19.97,
      "commitsBetweenForRepo": 104,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,24 @@\n   public void start() throws IOException {\n     Preconditions.checkState(!isStarted(), \"JN already running\");\n     \n     validateAndCreateJournalDir(localDir);\n     \n     DefaultMetricsSystem.initialize(\"JournalNode\");\n     JvmMetrics.create(\"JournalNode\",\n         conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n         DefaultMetricsSystem.instance());\n \n     InetSocketAddress socAddr \u003d JournalNodeRpcServer.getAddress(conf);\n     SecurityUtil.login(conf, DFSConfigKeys.DFS_JOURNALNODE_KEYTAB_FILE_KEY,\n         DFSConfigKeys.DFS_JOURNALNODE_USER_NAME_KEY, socAddr.getHostName());\n     \n     registerJNMXBean();\n     \n     httpServer \u003d new JournalNodeHttpServer(conf, this);\n     httpServer.start();\n \n+    httpServerURI \u003d httpServer.getServerURI().toString();\n+\n     rpcServer \u003d new JournalNodeRpcServer(conf, this);\n     rpcServer.start();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void start() throws IOException {\n    Preconditions.checkState(!isStarted(), \"JN already running\");\n    \n    validateAndCreateJournalDir(localDir);\n    \n    DefaultMetricsSystem.initialize(\"JournalNode\");\n    JvmMetrics.create(\"JournalNode\",\n        conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n        DefaultMetricsSystem.instance());\n\n    InetSocketAddress socAddr \u003d JournalNodeRpcServer.getAddress(conf);\n    SecurityUtil.login(conf, DFSConfigKeys.DFS_JOURNALNODE_KEYTAB_FILE_KEY,\n        DFSConfigKeys.DFS_JOURNALNODE_USER_NAME_KEY, socAddr.getHostName());\n    \n    registerJNMXBean();\n    \n    httpServer \u003d new JournalNodeHttpServer(conf, this);\n    httpServer.start();\n\n    httpServerURI \u003d httpServer.getServerURI().toString();\n\n    rpcServer \u003d new JournalNodeRpcServer(conf, this);\n    rpcServer.start();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JournalNode.java",
      "extendedDetails": {}
    },
    "02b19e0738d9df1e4d38280c5575e1d3ba49f8cb": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5076. Add MXBean methods to query NN\u0027s transaction information and JournalNode\u0027s journal status. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1514422 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "15/08/13 11:22 AM",
      "commitName": "02b19e0738d9df1e4d38280c5575e1d3ba49f8cb",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "08/06/13 4:28 PM",
      "commitNameOld": "cb11d68f409b7dabfc1f31c43f026a905810ed01",
      "commitAuthorOld": "Ivan Mitic",
      "daysBetweenCommits": 67.79,
      "commitsBetweenForRepo": 418,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,22 @@\n   public void start() throws IOException {\n     Preconditions.checkState(!isStarted(), \"JN already running\");\n     \n     validateAndCreateJournalDir(localDir);\n     \n     DefaultMetricsSystem.initialize(\"JournalNode\");\n     JvmMetrics.create(\"JournalNode\",\n         conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n         DefaultMetricsSystem.instance());\n \n     InetSocketAddress socAddr \u003d JournalNodeRpcServer.getAddress(conf);\n     SecurityUtil.login(conf, DFSConfigKeys.DFS_JOURNALNODE_KEYTAB_FILE_KEY,\n         DFSConfigKeys.DFS_JOURNALNODE_USER_NAME_KEY, socAddr.getHostName());\n     \n+    registerJNMXBean();\n+    \n     httpServer \u003d new JournalNodeHttpServer(conf, this);\n     httpServer.start();\n \n     rpcServer \u003d new JournalNodeRpcServer(conf, this);\n     rpcServer.start();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void start() throws IOException {\n    Preconditions.checkState(!isStarted(), \"JN already running\");\n    \n    validateAndCreateJournalDir(localDir);\n    \n    DefaultMetricsSystem.initialize(\"JournalNode\");\n    JvmMetrics.create(\"JournalNode\",\n        conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n        DefaultMetricsSystem.instance());\n\n    InetSocketAddress socAddr \u003d JournalNodeRpcServer.getAddress(conf);\n    SecurityUtil.login(conf, DFSConfigKeys.DFS_JOURNALNODE_KEYTAB_FILE_KEY,\n        DFSConfigKeys.DFS_JOURNALNODE_USER_NAME_KEY, socAddr.getHostName());\n    \n    registerJNMXBean();\n    \n    httpServer \u003d new JournalNodeHttpServer(conf, this);\n    httpServer.start();\n\n    rpcServer \u003d new JournalNodeRpcServer(conf, this);\n    rpcServer.start();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JournalNode.java",
      "extendedDetails": {}
    },
    "df801074c929d5414b92cc9fc0cc8a2794e02751": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3893. QJM: Make QJM work with security enabled. Contributed by Aaron T. Myers.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1381770 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "06/09/12 2:42 PM",
      "commitName": "df801074c929d5414b92cc9fc0cc8a2794e02751",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "04/09/12 9:30 PM",
      "commitNameOld": "13daca1ef6aa4a24ff9a840397dda1bbddb16e37",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 1.72,
      "commitsBetweenForRepo": 6,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,20 @@\n   public void start() throws IOException {\n     Preconditions.checkState(!isStarted(), \"JN already running\");\n     \n     validateAndCreateJournalDir(localDir);\n     \n     DefaultMetricsSystem.initialize(\"JournalNode\");\n     JvmMetrics.create(\"JournalNode\",\n         conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n         DefaultMetricsSystem.instance());\n+\n+    InetSocketAddress socAddr \u003d JournalNodeRpcServer.getAddress(conf);\n+    SecurityUtil.login(conf, DFSConfigKeys.DFS_JOURNALNODE_KEYTAB_FILE_KEY,\n+        DFSConfigKeys.DFS_JOURNALNODE_USER_NAME_KEY, socAddr.getHostName());\n     \n     httpServer \u003d new JournalNodeHttpServer(conf, this);\n     httpServer.start();\n \n     rpcServer \u003d new JournalNodeRpcServer(conf, this);\n     rpcServer.start();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void start() throws IOException {\n    Preconditions.checkState(!isStarted(), \"JN already running\");\n    \n    validateAndCreateJournalDir(localDir);\n    \n    DefaultMetricsSystem.initialize(\"JournalNode\");\n    JvmMetrics.create(\"JournalNode\",\n        conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n        DefaultMetricsSystem.instance());\n\n    InetSocketAddress socAddr \u003d JournalNodeRpcServer.getAddress(conf);\n    SecurityUtil.login(conf, DFSConfigKeys.DFS_JOURNALNODE_KEYTAB_FILE_KEY,\n        DFSConfigKeys.DFS_JOURNALNODE_USER_NAME_KEY, socAddr.getHostName());\n    \n    httpServer \u003d new JournalNodeHttpServer(conf, this);\n    httpServer.start();\n\n    rpcServer \u003d new JournalNodeRpcServer(conf, this);\n    rpcServer.start();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JournalNode.java",
      "extendedDetails": {}
    },
    "160bfcd6c2e2bc4a4adfa397f0f716430a0832bb": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3795. QJM: validate journal dir at startup. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1373178 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/08/12 5:52 PM",
      "commitName": "160bfcd6c2e2bc4a4adfa397f0f716430a0832bb",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "25/07/12 2:47 PM",
      "commitNameOld": "b17018e4b821ec860144d8bd38bc1fcb0d7eeaa5",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 20.13,
      "commitsBetweenForRepo": 83,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,16 @@\n   public void start() throws IOException {\n     Preconditions.checkState(!isStarted(), \"JN already running\");\n     \n+    validateAndCreateJournalDir(localDir);\n+    \n     DefaultMetricsSystem.initialize(\"JournalNode\");\n     JvmMetrics.create(\"JournalNode\",\n         conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n         DefaultMetricsSystem.instance());\n     \n     httpServer \u003d new JournalNodeHttpServer(conf, this);\n     httpServer.start();\n \n     rpcServer \u003d new JournalNodeRpcServer(conf, this);\n     rpcServer.start();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void start() throws IOException {\n    Preconditions.checkState(!isStarted(), \"JN already running\");\n    \n    validateAndCreateJournalDir(localDir);\n    \n    DefaultMetricsSystem.initialize(\"JournalNode\");\n    JvmMetrics.create(\"JournalNode\",\n        conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n        DefaultMetricsSystem.instance());\n    \n    httpServer \u003d new JournalNodeHttpServer(conf, this);\n    httpServer.start();\n\n    rpcServer \u003d new JournalNodeRpcServer(conf, this);\n    rpcServer.start();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JournalNode.java",
      "extendedDetails": {}
    },
    "74d4573a23db5586c6e47ff2277aa7c35237da34": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-3077. Quorum-based protocol for reading and writing edit logs. Contributed by Todd Lipcon based on initial work from Brandon Li and Hari Mankude.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1363596 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/07/12 5:25 PM",
      "commitName": "74d4573a23db5586c6e47ff2277aa7c35237da34",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,14 @@\n+  public void start() throws IOException {\n+    Preconditions.checkState(!isStarted(), \"JN already running\");\n+    \n+    DefaultMetricsSystem.initialize(\"JournalNode\");\n+    JvmMetrics.create(\"JournalNode\",\n+        conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n+        DefaultMetricsSystem.instance());\n+    \n+    httpServer \u003d new JournalNodeHttpServer(conf, this);\n+    httpServer.start();\n+\n+    rpcServer \u003d new JournalNodeRpcServer(conf, this);\n+    rpcServer.start();\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void start() throws IOException {\n    Preconditions.checkState(!isStarted(), \"JN already running\");\n    \n    DefaultMetricsSystem.initialize(\"JournalNode\");\n    JvmMetrics.create(\"JournalNode\",\n        conf.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY),\n        DefaultMetricsSystem.instance());\n    \n    httpServer \u003d new JournalNodeHttpServer(conf, this);\n    httpServer.start();\n\n    rpcServer \u003d new JournalNodeRpcServer(conf, this);\n    rpcServer.start();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JournalNode.java"
    }
  }
}