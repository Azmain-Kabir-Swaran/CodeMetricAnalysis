{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSEditLogOp.java",
  "functionName": "writeFields",
  "functionId": "writeFields___out-DataOutputStream",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
  "functionStartLine": 4271,
  "functionEndLine": 4280,
  "numCommitsSeen": 109,
  "timeTaken": 5789,
  "changeHistory": [
    "37207b75d4b83f7c032dc446d5c7e578f5b7e93a",
    "4f9bbaa301194e3d20972a10f51638c7f4d121f0",
    "09b8ce5b442489739694a2ebac4e342f6d2e2ac0",
    "4563ba08e75ecf09afe0d803b731fdde0657101b",
    "c3b56ed1c869ff225e549a1a3abc032209103195",
    "69e5f90e9febf37d2cdd69c485729c448ac3cabc",
    "af1ac9a5e8d8d97a855940d853dd59ab4666f6e2",
    "ecffab63af630dac6e51fd2ccf225bf40d31b157",
    "40f8b7dcfb72727558ebed99f68f6fec368546e5",
    "4cccdc2a96b90c9e46e801b12b03788c1b16ecb7",
    "e75424544ff60d38575cde580fdae1a17f7a7289",
    "4f6e0a5a659064e0af3bec315e7c25d5e43b47f5",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "28e6a4e44a3e920dcaf858f9a74a6358226b3a63",
    "438c32aaf9fb0c63f55044cf5ef1b2e0adcf7fea"
  ],
  "changeHistoryShort": {
    "37207b75d4b83f7c032dc446d5c7e578f5b7e93a": "Ybodychange",
    "4f9bbaa301194e3d20972a10f51638c7f4d121f0": "Ybodychange",
    "09b8ce5b442489739694a2ebac4e342f6d2e2ac0": "Ybodychange",
    "4563ba08e75ecf09afe0d803b731fdde0657101b": "Ybodychange",
    "c3b56ed1c869ff225e549a1a3abc032209103195": "Ybodychange",
    "69e5f90e9febf37d2cdd69c485729c448ac3cabc": "Ybodychange",
    "af1ac9a5e8d8d97a855940d853dd59ab4666f6e2": "Ybodychange",
    "ecffab63af630dac6e51fd2ccf225bf40d31b157": "Ybodychange",
    "40f8b7dcfb72727558ebed99f68f6fec368546e5": "Ybodychange",
    "4cccdc2a96b90c9e46e801b12b03788c1b16ecb7": "Ybodychange",
    "e75424544ff60d38575cde580fdae1a17f7a7289": "Ybodychange",
    "4f6e0a5a659064e0af3bec315e7c25d5e43b47f5": "Ymodifierchange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "28e6a4e44a3e920dcaf858f9a74a6358226b3a63": "Ybodychange",
    "438c32aaf9fb0c63f55044cf5ef1b2e0adcf7fea": "Yintroduced"
  },
  "changeHistoryDetails": {
    "37207b75d4b83f7c032dc446d5c7e578f5b7e93a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6835. Archival Storage: Add a new API to set storage policy. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-6584@1617568 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/08/14 12:32 PM",
      "commitName": "37207b75d4b83f7c032dc446d5c7e578f5b7e93a",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "23/07/14 12:05 PM",
      "commitNameOld": "5343b43fd989ec596afed807ddce29ad96c23e2d",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 20.02,
      "commitsBetweenForRepo": 135,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,3 +1,4 @@\n     public void writeFields(DataOutputStream out) throws IOException {\n-      FSImageSerialization.writeLong(time, out);\n+      FSImageSerialization.writeString(path, out);\n+      out.writeByte(policyId);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void writeFields(DataOutputStream out) throws IOException {\n      FSImageSerialization.writeString(path, out);\n      out.writeByte(policyId);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
      "extendedDetails": {}
    },
    "4f9bbaa301194e3d20972a10f51638c7f4d121f0": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5889. When starting rolling upgrade, create a fs image for rollback so that the standby namenode can create checkpoints during upgrade.  Contributed by szetszwo \u0026 jing9\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535@1567861 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/02/14 12:04 AM",
      "commitName": "4f9bbaa301194e3d20972a10f51638c7f4d121f0",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "30/01/14 7:21 PM",
      "commitNameOld": "00067895a01c66d53715b50bbcb3605efd6425f2",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 13.2,
      "commitsBetweenForRepo": 60,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,3 +1,3 @@\n     public void writeFields(DataOutputStream out) throws IOException {\n-      FSImageSerialization.writeLong(startTime, out);\n+      FSImageSerialization.writeLong(time, out);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void writeFields(DataOutputStream out) throws IOException {\n      FSImageSerialization.writeLong(time, out);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
      "extendedDetails": {}
    },
    "09b8ce5b442489739694a2ebac4e342f6d2e2ac0": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5786. Support QUERY and FINALIZE actions of rolling upgrade.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535@1559304 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/01/14 6:07 PM",
      "commitName": "09b8ce5b442489739694a2ebac4e342f6d2e2ac0",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "09/01/14 10:06 PM",
      "commitNameOld": "4563ba08e75ecf09afe0d803b731fdde0657101b",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 7.83,
      "commitsBetweenForRepo": 20,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,2 +1,3 @@\n     public void writeFields(DataOutputStream out) throws IOException {\n+      FSImageSerialization.writeLong(startTime, out);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void writeFields(DataOutputStream out) throws IOException {\n      FSImageSerialization.writeLong(startTime, out);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
      "extendedDetails": {}
    },
    "4563ba08e75ecf09afe0d803b731fdde0657101b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5645. Support upgrade marker in editlog streams.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535@1557038 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/01/14 10:06 PM",
      "commitName": "4563ba08e75ecf09afe0d803b731fdde0657101b",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "17/12/13 6:46 PM",
      "commitNameOld": "504bd0bca3ebed1941bbf5407fac0636447e745b",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 23.14,
      "commitsBetweenForRepo": 80,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,4 +1,2 @@\n     public void writeFields(DataOutputStream out) throws IOException {\n-      FSImageSerialization.writeString(poolName, out);\n-      writeRpcIds(rpcClientId, rpcCallId, out);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void writeFields(DataOutputStream out) throws IOException {\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
      "extendedDetails": {}
    },
    "c3b56ed1c869ff225e549a1a3abc032209103195": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5619. NameNode: record ACL modifications to edit log. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4685@1553224 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "23/12/13 2:12 PM",
      "commitName": "c3b56ed1c869ff225e549a1a3abc032209103195",
      "commitAuthor": "Chris Nauroth",
      "commitDateOld": "17/12/13 6:46 PM",
      "commitNameOld": "504bd0bca3ebed1941bbf5407fac0636447e745b",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 5.81,
      "commitsBetweenForRepo": 18,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,4 +1,7 @@\n     public void writeFields(DataOutputStream out) throws IOException {\n-      FSImageSerialization.writeString(poolName, out);\n-      writeRpcIds(rpcClientId, rpcCallId, out);\n+      AclEditLogProto.Builder b \u003d AclEditLogProto.newBuilder();\n+      if (src !\u003d null)\n+        b.setSrc(src);\n+      b.addAllEntries(PBHelper.convertAclEntryProto(aclEntries));\n+      b.build().writeDelimitedTo(out);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void writeFields(DataOutputStream out) throws IOException {\n      AclEditLogProto.Builder b \u003d AclEditLogProto.newBuilder();\n      if (src !\u003d null)\n        b.setSrc(src);\n      b.addAllEntries(PBHelper.convertAclEntryProto(aclEntries));\n      b.build().writeDelimitedTo(out);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
      "extendedDetails": {}
    },
    "69e5f90e9febf37d2cdd69c485729c448ac3cabc": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5385. Caching RPCs are AtMostOnce, but do not persist client ID and call ID to edit log.  (Chris Nauroth via Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1534345 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/10/13 12:42 PM",
      "commitName": "69e5f90e9febf37d2cdd69c485729c448ac3cabc",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "14/10/13 3:56 PM",
      "commitNameOld": "efe545b0c219eeba61ac5259aee4d518beb74316",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 6.87,
      "commitsBetweenForRepo": 31,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,3 +1,4 @@\n     public void writeFields(DataOutputStream out) throws IOException {\n       FSImageSerialization.writeString(poolName, out);\n+      writeRpcIds(rpcClientId, rpcCallId, out);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void writeFields(DataOutputStream out) throws IOException {\n      FSImageSerialization.writeString(poolName, out);\n      writeRpcIds(rpcClientId, rpcCallId, out);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
      "extendedDetails": {}
    },
    "af1ac9a5e8d8d97a855940d853dd59ab4666f6e2": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5119. Persist CacheManager state in the edit log. (Contributed by Andrew Wang)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1529238 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/10/13 10:46 AM",
      "commitName": "af1ac9a5e8d8d97a855940d853dd59ab4666f6e2",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "30/07/13 12:51 AM",
      "commitNameOld": "8c7a7e619699386f9e6991842558d78aa0c8053d",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 66.41,
      "commitsBetweenForRepo": 271,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,3 +1,3 @@\n     public void writeFields(DataOutputStream out) throws IOException {\n-      FSImageSerialization.writeString(snapshotRoot, out);\n+      FSImageSerialization.writeString(poolName, out);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void writeFields(DataOutputStream out) throws IOException {\n      FSImageSerialization.writeString(poolName, out);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
      "extendedDetails": {}
    },
    "ecffab63af630dac6e51fd2ccf225bf40d31b157": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4086. Add editlog opcodes to allow and disallow snapshots on a directory. Contributed by Brandon Li.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2802@1400298 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/10/12 2:15 PM",
      "commitName": "ecffab63af630dac6e51fd2ccf225bf40d31b157",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "19/10/12 2:04 PM",
      "commitNameOld": "40f8b7dcfb72727558ebed99f68f6fec368546e5",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,4 +1,3 @@\n     public void writeFields(DataOutputStream out) throws IOException {\n-      FSImageSerialization.writeString(snapshotName, out);\n       FSImageSerialization.writeString(snapshotRoot, out);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void writeFields(DataOutputStream out) throws IOException {\n      FSImageSerialization.writeString(snapshotRoot, out);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
      "extendedDetails": {}
    },
    "40f8b7dcfb72727558ebed99f68f6fec368546e5": {
      "type": "Ybodychange",
      "commitMessage": "Reverting the change r1400285 since it included unrelated changes\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2802@1400290 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/10/12 2:04 PM",
      "commitName": "40f8b7dcfb72727558ebed99f68f6fec368546e5",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "19/10/12 2:01 PM",
      "commitNameOld": "4cccdc2a96b90c9e46e801b12b03788c1b16ecb7",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,3 +1,4 @@\n     public void writeFields(DataOutputStream out) throws IOException {\n+      FSImageSerialization.writeString(snapshotName, out);\n       FSImageSerialization.writeString(snapshotRoot, out);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void writeFields(DataOutputStream out) throws IOException {\n      FSImageSerialization.writeString(snapshotName, out);\n      FSImageSerialization.writeString(snapshotRoot, out);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
      "extendedDetails": {}
    },
    "4cccdc2a96b90c9e46e801b12b03788c1b16ecb7": {
      "type": "Ybodychange",
      "commitMessage": "Moving HDFS-2802 related changes to a separate CHANGES.txt\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2802@1400285 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/10/12 2:01 PM",
      "commitName": "4cccdc2a96b90c9e46e801b12b03788c1b16ecb7",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "19/10/12 12:38 PM",
      "commitNameOld": "e75424544ff60d38575cde580fdae1a17f7a7289",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 0.06,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,4 +1,3 @@\n     public void writeFields(DataOutputStream out) throws IOException {\n-      FSImageSerialization.writeString(snapshotName, out);\n       FSImageSerialization.writeString(snapshotRoot, out);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void writeFields(DataOutputStream out) throws IOException {\n      FSImageSerialization.writeString(snapshotRoot, out);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
      "extendedDetails": {}
    },
    "e75424544ff60d38575cde580fdae1a17f7a7289": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4082. Add editlog opcodes for snapshot create and delete operations.  Contributed by suresh\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2802@1400247 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/10/12 12:38 PM",
      "commitName": "e75424544ff60d38575cde580fdae1a17f7a7289",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "24/08/12 6:03 PM",
      "commitNameOld": "deead78e35b0cb81af875b5a8032cbd06c9a2dae",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 55.77,
      "commitsBetweenForRepo": 332,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,2 +1,4 @@\n-    void writeFields(DataOutputStream out) throws IOException {\n+    public void writeFields(DataOutputStream out) throws IOException {\n+      FSImageSerialization.writeString(snapshotName, out);\n+      FSImageSerialization.writeString(snapshotRoot, out);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void writeFields(DataOutputStream out) throws IOException {\n      FSImageSerialization.writeString(snapshotName, out);\n      FSImageSerialization.writeString(snapshotRoot, out);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
      "extendedDetails": {}
    },
    "4f6e0a5a659064e0af3bec315e7c25d5e43b47f5": {
      "type": "Ymodifierchange",
      "commitMessage": "HDFS-3050. rework OEV to share more code with the NameNode. Contributed by Colin Patrick McCabe\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1309629 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/04/12 5:02 PM",
      "commitName": "4f6e0a5a659064e0af3bec315e7c25d5e43b47f5",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "29/03/12 5:11 PM",
      "commitNameOld": "64641c28b5ea8538033060452b0c45b7f2eeb60c",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 5.99,
      "commitsBetweenForRepo": 60,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    void writeFields(DataOutputStream out) throws IOException {\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
      "extendedDetails": {
        "oldValue": "[]",
        "newValue": "[public]"
      }
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    void writeFields(DataOutputStream out) throws IOException {\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    void writeFields(DataOutputStream out) throws IOException {\n    }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java"
      }
    },
    "28e6a4e44a3e920dcaf858f9a74a6358226b3a63": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-1073. Redesign the NameNode\u0027s storage layout for image checkpoints and edit logs to introduce transaction IDs and be more robust. Contributed by Todd Lipcon and Ivan Kelly.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1152295 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "29/07/11 9:28 AM",
      "commitName": "28e6a4e44a3e920dcaf858f9a74a6358226b3a63",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "27/07/11 10:46 PM",
      "commitNameOld": "44320eed1732ea59bd9ec83009eb10e0e6f13023",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 1.45,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,3 +1,2 @@\n     void writeFields(DataOutputStream out) throws IOException {\n-      new LongWritable(checkpointTime).write(out);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void writeFields(DataOutputStream out) throws IOException {\n    }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
      "extendedDetails": {}
    },
    "438c32aaf9fb0c63f55044cf5ef1b2e0adcf7fea": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-2149. Move EditLogOp serialization formats into FsEditLogOp implementations. Contributed by Ivan Kelly.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1151238 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "26/07/11 1:46 PM",
      "commitName": "438c32aaf9fb0c63f55044cf5ef1b2e0adcf7fea",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,3 @@\n+    void writeFields(DataOutputStream out) throws IOException {\n+      new LongWritable(checkpointTime).write(out);\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    void writeFields(DataOutputStream out) throws IOException {\n      new LongWritable(checkpointTime).write(out);\n    }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java"
    }
  }
}