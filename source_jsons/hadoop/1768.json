{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DataTransferProtoUtil.java",
  "functionName": "toProto",
  "functionId": "toProto___checksum-DataChecksum",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/DataTransferProtoUtil.java",
  "functionStartLine": 58,
  "functionEndLine": 65,
  "numCommitsSeen": 15,
  "timeTaken": 2353,
  "changeHistory": [
    "490bb5ebd6c6d6f9c08fcad167f976687fc3aa42",
    "3cd17b614e9436d06cd9b4ccc5f9cf59fbe1cf21",
    "6d4a0915676b8185a4727a10fcfeb40aa24cacc5",
    "e0ce1b247550c6c89c292fb328c91d4b091a1473",
    "89b66da42c79395816a64dfefe97175c2b293bc3",
    "3cab01ba6e0349126a23063e135cd5c814a4ae18",
    "1c940637b14eee777a65d153d0d712a1aea3866c"
  ],
  "changeHistoryShort": {
    "490bb5ebd6c6d6f9c08fcad167f976687fc3aa42": "Ymultichange(Yfilerename,Ybodychange)",
    "3cd17b614e9436d06cd9b4ccc5f9cf59fbe1cf21": "Ybodychange",
    "6d4a0915676b8185a4727a10fcfeb40aa24cacc5": "Ybodychange",
    "e0ce1b247550c6c89c292fb328c91d4b091a1473": "Ybodychange",
    "89b66da42c79395816a64dfefe97175c2b293bc3": "Ybodychange",
    "3cab01ba6e0349126a23063e135cd5c814a4ae18": "Ybodychange",
    "1c940637b14eee777a65d153d0d712a1aea3866c": "Yintroduced"
  },
  "changeHistoryDetails": {
    "490bb5ebd6c6d6f9c08fcad167f976687fc3aa42": {
      "type": "Ymultichange(Yfilerename,Ybodychange)",
      "commitMessage": "HDFS-8934. Move ShortCircuitShm to hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "22/08/15 1:31 PM",
      "commitName": "490bb5ebd6c6d6f9c08fcad167f976687fc3aa42",
      "commitAuthor": "Haohui Mai",
      "subchanges": [
        {
          "type": "Yfilerename",
          "commitMessage": "HDFS-8934. Move ShortCircuitShm to hdfs-client. Contributed by Mingliang Liu.\n",
          "commitDate": "22/08/15 1:31 PM",
          "commitName": "490bb5ebd6c6d6f9c08fcad167f976687fc3aa42",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "22/08/15 12:39 AM",
          "commitNameOld": "61bf9cae6f3882c6e9a9222f59457b9be91e3018",
          "commitAuthorOld": "Karthik Kambatla",
          "daysBetweenCommits": 0.54,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,8 +1,8 @@\n   public static ChecksumProto toProto(DataChecksum checksum) {\n-    ChecksumTypeProto type \u003d PBHelper.convert(checksum.getChecksumType());\n+    ChecksumTypeProto type \u003d PBHelperClient.convert(checksum.getChecksumType());\n     // ChecksumType#valueOf never returns null\n     return ChecksumProto.newBuilder()\n       .setBytesPerChecksum(checksum.getBytesPerChecksum())\n       .setType(type)\n       .build();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static ChecksumProto toProto(DataChecksum checksum) {\n    ChecksumTypeProto type \u003d PBHelperClient.convert(checksum.getChecksumType());\n    // ChecksumType#valueOf never returns null\n    return ChecksumProto.newBuilder()\n      .setBytesPerChecksum(checksum.getBytesPerChecksum())\n      .setType(type)\n      .build();\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/DataTransferProtoUtil.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/DataTransferProtoUtil.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/DataTransferProtoUtil.java"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-8934. Move ShortCircuitShm to hdfs-client. Contributed by Mingliang Liu.\n",
          "commitDate": "22/08/15 1:31 PM",
          "commitName": "490bb5ebd6c6d6f9c08fcad167f976687fc3aa42",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "22/08/15 12:39 AM",
          "commitNameOld": "61bf9cae6f3882c6e9a9222f59457b9be91e3018",
          "commitAuthorOld": "Karthik Kambatla",
          "daysBetweenCommits": 0.54,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,8 +1,8 @@\n   public static ChecksumProto toProto(DataChecksum checksum) {\n-    ChecksumTypeProto type \u003d PBHelper.convert(checksum.getChecksumType());\n+    ChecksumTypeProto type \u003d PBHelperClient.convert(checksum.getChecksumType());\n     // ChecksumType#valueOf never returns null\n     return ChecksumProto.newBuilder()\n       .setBytesPerChecksum(checksum.getBytesPerChecksum())\n       .setType(type)\n       .build();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static ChecksumProto toProto(DataChecksum checksum) {\n    ChecksumTypeProto type \u003d PBHelperClient.convert(checksum.getChecksumType());\n    // ChecksumType#valueOf never returns null\n    return ChecksumProto.newBuilder()\n      .setBytesPerChecksum(checksum.getBytesPerChecksum())\n      .setType(type)\n      .build();\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/DataTransferProtoUtil.java",
          "extendedDetails": {}
        }
      ]
    },
    "3cd17b614e9436d06cd9b4ccc5f9cf59fbe1cf21": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4363. Combine PBHelper and HdfsProtoUtil and remove redundant methods. Contributed by Suresh Srinivas.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1431088 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/01/13 1:20 PM",
      "commitName": "3cd17b614e9436d06cd9b4ccc5f9cf59fbe1cf21",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "08/01/13 2:38 PM",
      "commitNameOld": "6d4a0915676b8185a4727a10fcfeb40aa24cacc5",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 0.95,
      "commitsBetweenForRepo": 11,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,8 +1,8 @@\n   public static ChecksumProto toProto(DataChecksum checksum) {\n-    ChecksumTypeProto type \u003d HdfsProtoUtil.toProto(checksum.getChecksumType());\n+    ChecksumTypeProto type \u003d PBHelper.convert(checksum.getChecksumType());\n     // ChecksumType#valueOf never returns null\n     return ChecksumProto.newBuilder()\n       .setBytesPerChecksum(checksum.getBytesPerChecksum())\n       .setType(type)\n       .build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static ChecksumProto toProto(DataChecksum checksum) {\n    ChecksumTypeProto type \u003d PBHelper.convert(checksum.getChecksumType());\n    // ChecksumType#valueOf never returns null\n    return ChecksumProto.newBuilder()\n      .setBytesPerChecksum(checksum.getBytesPerChecksum())\n      .setType(type)\n      .build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/DataTransferProtoUtil.java",
      "extendedDetails": {}
    },
    "6d4a0915676b8185a4727a10fcfeb40aa24cacc5": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4034. Remove redundant null checks. Contributed by Eli Collins\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1430585 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/01/13 2:38 PM",
      "commitName": "6d4a0915676b8185a4727a10fcfeb40aa24cacc5",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "05/11/12 3:49 PM",
      "commitNameOld": "e0ce1b247550c6c89c292fb328c91d4b091a1473",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 63.95,
      "commitsBetweenForRepo": 272,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,8 @@\n   public static ChecksumProto toProto(DataChecksum checksum) {\n     ChecksumTypeProto type \u003d HdfsProtoUtil.toProto(checksum.getChecksumType());\n-    if (type \u003d\u003d null) {\n-      throw new IllegalArgumentException(\n-          \"Can\u0027t convert checksum to protobuf: \" + checksum);\n-    }\n-\n+    // ChecksumType#valueOf never returns null\n     return ChecksumProto.newBuilder()\n       .setBytesPerChecksum(checksum.getBytesPerChecksum())\n       .setType(type)\n       .build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static ChecksumProto toProto(DataChecksum checksum) {\n    ChecksumTypeProto type \u003d HdfsProtoUtil.toProto(checksum.getChecksumType());\n    // ChecksumType#valueOf never returns null\n    return ChecksumProto.newBuilder()\n      .setBytesPerChecksum(checksum.getBytesPerChecksum())\n      .setType(type)\n      .build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/DataTransferProtoUtil.java",
      "extendedDetails": {}
    },
    "e0ce1b247550c6c89c292fb328c91d4b091a1473": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4046. Rename ChecksumTypeProto enum NULL since it is illegal in C/C++. Contributed by Binglin Chang.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1406011 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "05/11/12 3:49 PM",
      "commitName": "e0ce1b247550c6c89c292fb328c91d4b091a1473",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "12/10/12 7:32 AM",
      "commitNameOld": "89b66da42c79395816a64dfefe97175c2b293bc3",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 24.39,
      "commitsBetweenForRepo": 123,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,12 @@\n   public static ChecksumProto toProto(DataChecksum checksum) {\n-    ChecksumTypeProto type \u003d ChecksumTypeProto.valueOf(checksum.getChecksumType().name());\n+    ChecksumTypeProto type \u003d HdfsProtoUtil.toProto(checksum.getChecksumType());\n     if (type \u003d\u003d null) {\n       throw new IllegalArgumentException(\n           \"Can\u0027t convert checksum to protobuf: \" + checksum);\n     }\n \n     return ChecksumProto.newBuilder()\n       .setBytesPerChecksum(checksum.getBytesPerChecksum())\n       .setType(type)\n       .build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static ChecksumProto toProto(DataChecksum checksum) {\n    ChecksumTypeProto type \u003d HdfsProtoUtil.toProto(checksum.getChecksumType());\n    if (type \u003d\u003d null) {\n      throw new IllegalArgumentException(\n          \"Can\u0027t convert checksum to protobuf: \" + checksum);\n    }\n\n    return ChecksumProto.newBuilder()\n      .setBytesPerChecksum(checksum.getBytesPerChecksum())\n      .setType(type)\n      .build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/DataTransferProtoUtil.java",
      "extendedDetails": {}
    },
    "89b66da42c79395816a64dfefe97175c2b293bc3": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4044. Duplicate ChecksumType definition in HDFS .proto files. Contributed by Binglin Chang.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1397580 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/10/12 7:32 AM",
      "commitName": "89b66da42c79395816a64dfefe97175c2b293bc3",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "15/08/12 6:32 PM",
      "commitNameOld": "3cab01ba6e0349126a23063e135cd5c814a4ae18",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 57.54,
      "commitsBetweenForRepo": 362,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,12 @@\n   public static ChecksumProto toProto(DataChecksum checksum) {\n-    ChecksumType type \u003d ChecksumType.valueOf(checksum.getChecksumType().name());\n+    ChecksumTypeProto type \u003d ChecksumTypeProto.valueOf(checksum.getChecksumType().name());\n     if (type \u003d\u003d null) {\n       throw new IllegalArgumentException(\n           \"Can\u0027t convert checksum to protobuf: \" + checksum);\n     }\n \n     return ChecksumProto.newBuilder()\n       .setBytesPerChecksum(checksum.getBytesPerChecksum())\n       .setType(type)\n       .build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static ChecksumProto toProto(DataChecksum checksum) {\n    ChecksumTypeProto type \u003d ChecksumTypeProto.valueOf(checksum.getChecksumType().name());\n    if (type \u003d\u003d null) {\n      throw new IllegalArgumentException(\n          \"Can\u0027t convert checksum to protobuf: \" + checksum);\n    }\n\n    return ChecksumProto.newBuilder()\n      .setBytesPerChecksum(checksum.getBytesPerChecksum())\n      .setType(type)\n      .build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/DataTransferProtoUtil.java",
      "extendedDetails": {}
    },
    "3cab01ba6e0349126a23063e135cd5c814a4ae18": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-8700.  Use enum to define the checksum constants in DataChecksum.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1373683 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "15/08/12 6:32 PM",
      "commitName": "3cab01ba6e0349126a23063e135cd5c814a4ae18",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "31/10/11 10:17 PM",
      "commitNameOld": "1c940637b14eee777a65d153d0d712a1aea3866c",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 288.84,
      "commitsBetweenForRepo": 1833,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,12 @@\n   public static ChecksumProto toProto(DataChecksum checksum) {\n-    ChecksumType type \u003d checksumTypeMap.get(checksum.getChecksumType());\n+    ChecksumType type \u003d ChecksumType.valueOf(checksum.getChecksumType().name());\n     if (type \u003d\u003d null) {\n       throw new IllegalArgumentException(\n           \"Can\u0027t convert checksum to protobuf: \" + checksum);\n     }\n \n     return ChecksumProto.newBuilder()\n       .setBytesPerChecksum(checksum.getBytesPerChecksum())\n       .setType(type)\n       .build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static ChecksumProto toProto(DataChecksum checksum) {\n    ChecksumType type \u003d ChecksumType.valueOf(checksum.getChecksumType().name());\n    if (type \u003d\u003d null) {\n      throw new IllegalArgumentException(\n          \"Can\u0027t convert checksum to protobuf: \" + checksum);\n    }\n\n    return ChecksumProto.newBuilder()\n      .setBytesPerChecksum(checksum.getBytesPerChecksum())\n      .setType(type)\n      .build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/DataTransferProtoUtil.java",
      "extendedDetails": {}
    },
    "1c940637b14eee777a65d153d0d712a1aea3866c": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-2521. Remove custom checksum headers from data transfer protocol. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1195829 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "31/10/11 10:17 PM",
      "commitName": "1c940637b14eee777a65d153d0d712a1aea3866c",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,12 @@\n+  public static ChecksumProto toProto(DataChecksum checksum) {\n+    ChecksumType type \u003d checksumTypeMap.get(checksum.getChecksumType());\n+    if (type \u003d\u003d null) {\n+      throw new IllegalArgumentException(\n+          \"Can\u0027t convert checksum to protobuf: \" + checksum);\n+    }\n+\n+    return ChecksumProto.newBuilder()\n+      .setBytesPerChecksum(checksum.getBytesPerChecksum())\n+      .setType(type)\n+      .build();\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public static ChecksumProto toProto(DataChecksum checksum) {\n    ChecksumType type \u003d checksumTypeMap.get(checksum.getChecksumType());\n    if (type \u003d\u003d null) {\n      throw new IllegalArgumentException(\n          \"Can\u0027t convert checksum to protobuf: \" + checksum);\n    }\n\n    return ChecksumProto.newBuilder()\n      .setBytesPerChecksum(checksum.getBytesPerChecksum())\n      .setType(type)\n      .build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/DataTransferProtoUtil.java"
    }
  }
}