{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ProvidedStorageMap.java",
  "functionName": "remove",
  "functionId": "remove___dnToRemove-DatanodeDescriptor",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/ProvidedStorageMap.java",
  "functionStartLine": 416,
  "functionEndLine": 427,
  "numCommitsSeen": 17,
  "timeTaken": 1285,
  "changeHistory": [
    "4d59dabb7f6ef1d8565bf2bb2d38aeb91bf7f7cc",
    "546b95f4843f3cbbbdf72d90d202cad551696082"
  ],
  "changeHistoryShort": {
    "4d59dabb7f6ef1d8565bf2bb2d38aeb91bf7f7cc": "Ybodychange",
    "546b95f4843f3cbbbdf72d90d202cad551696082": "Yintroduced"
  },
  "changeHistoryDetails": {
    "4d59dabb7f6ef1d8565bf2bb2d38aeb91bf7f7cc": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12809. [READ] Fix the randomized selection of locations in {{ProvidedBlocksBuilder}}.\n",
      "commitDate": "15/12/17 5:51 PM",
      "commitName": "4d59dabb7f6ef1d8565bf2bb2d38aeb91bf7f7cc",
      "commitAuthor": "Virajith Jalaparti",
      "commitDateOld": "15/12/17 5:51 PM",
      "commitNameOld": "3d3be87e301d9f8ab1a220bc5dbeae0f032c5a86",
      "commitAuthorOld": "Virajith Jalaparti",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,11 +1,12 @@\n     int remove(DatanodeDescriptor dnToRemove) {\n       // this operation happens under the FSNamesystem lock;\n       // no additional synchronization required.\n       if (dnToRemove !\u003d null) {\n         DatanodeDescriptor storedDN \u003d dns.get(dnToRemove.getDatanodeUuid());\n         if (storedDN !\u003d null) {\n           dns.remove(dnToRemove.getDatanodeUuid());\n+          dnR.remove(dnToRemove);\n         }\n       }\n       return dns.size();\n     }\n\\ No newline at end of file\n",
      "actualSource": "    int remove(DatanodeDescriptor dnToRemove) {\n      // this operation happens under the FSNamesystem lock;\n      // no additional synchronization required.\n      if (dnToRemove !\u003d null) {\n        DatanodeDescriptor storedDN \u003d dns.get(dnToRemove.getDatanodeUuid());\n        if (storedDN !\u003d null) {\n          dns.remove(dnToRemove.getDatanodeUuid());\n          dnR.remove(dnToRemove);\n        }\n      }\n      return dns.size();\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/ProvidedStorageMap.java",
      "extendedDetails": {}
    },
    "546b95f4843f3cbbbdf72d90d202cad551696082": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-11673. [READ] Handle failures of Datanode with PROVIDED storage\n",
      "commitDate": "15/12/17 5:51 PM",
      "commitName": "546b95f4843f3cbbbdf72d90d202cad551696082",
      "commitAuthor": "Virajith Jalaparti",
      "diff": "@@ -0,0 +1,11 @@\n+    int remove(DatanodeDescriptor dnToRemove) {\n+      // this operation happens under the FSNamesystem lock;\n+      // no additional synchronization required.\n+      if (dnToRemove !\u003d null) {\n+        DatanodeDescriptor storedDN \u003d dns.get(dnToRemove.getDatanodeUuid());\n+        if (storedDN !\u003d null) {\n+          dns.remove(dnToRemove.getDatanodeUuid());\n+        }\n+      }\n+      return dns.size();\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    int remove(DatanodeDescriptor dnToRemove) {\n      // this operation happens under the FSNamesystem lock;\n      // no additional synchronization required.\n      if (dnToRemove !\u003d null) {\n        DatanodeDescriptor storedDN \u003d dns.get(dnToRemove.getDatanodeUuid());\n        if (storedDN !\u003d null) {\n          dns.remove(dnToRemove.getDatanodeUuid());\n        }\n      }\n      return dns.size();\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/ProvidedStorageMap.java"
    }
  }
}