{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "CopyCommitter.java",
  "functionName": "concatFileChunks",
  "functionId": "concatFileChunks___conf-Configuration",
  "sourceFilePath": "hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/CopyCommitter.java",
  "functionStartLine": 218,
  "functionEndLine": 301,
  "numCommitsSeen": 23,
  "timeTaken": 1912,
  "changeHistory": [
    "51c64b357d4bd1a0038e61df3d4b8ea0a3ad7449",
    "c765584eb231f8482f5b90b7e8f61f9f7a931d09",
    "bf3fb585aaf2b179836e139c041fc87920a3c886"
  ],
  "changeHistoryShort": {
    "51c64b357d4bd1a0038e61df3d4b8ea0a3ad7449": "Ybodychange",
    "c765584eb231f8482f5b90b7e8f61f9f7a931d09": "Ybodychange",
    "bf3fb585aaf2b179836e139c041fc87920a3c886": "Yintroduced"
  },
  "changeHistoryDetails": {
    "51c64b357d4bd1a0038e61df3d4b8ea0a3ad7449": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13660. DistCp job fails when new data is appended in the file while the DistCp copy job is running\n\nThis uses the length of the file known at the start of the copy to determine the amount of data to copy.\n\n* If a file is appended to during the copy, the original bytes are copied.\n* If a file is truncated during a copy, or the attempt to read the data fails with a truncated stream,\n  distcp will now fail. Until now these failures were not detected.\n\nContributed by Mukund Thakur.\n\nChange-Id: I576a49d951fa48d37a45a7e4c82c47488aa8e884\n",
      "commitDate": "24/09/19 3:23 AM",
      "commitName": "51c64b357d4bd1a0038e61df3d4b8ea0a3ad7449",
      "commitAuthor": "Mukund Thakur",
      "commitDateOld": "18/08/19 6:46 PM",
      "commitNameOld": "c765584eb231f8482f5b90b7e8f61f9f7a931d09",
      "commitAuthorOld": "KAI XIE",
      "daysBetweenCommits": 36.36,
      "commitsBetweenForRepo": 313,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,84 +1,84 @@\n   private void concatFileChunks(Configuration conf) throws IOException {\n \n     LOG.info(\"concat file chunks ...\");\n \n     String spath \u003d conf.get(DistCpConstants.CONF_LABEL_LISTING_FILE_PATH);\n     if (spath \u003d\u003d null || spath.isEmpty()) {\n       return;\n     }\n     Path sourceListing \u003d new Path(spath);\n     SequenceFile.Reader sourceReader \u003d new SequenceFile.Reader(conf,\n                                       SequenceFile.Reader.file(sourceListing));\n     Path targetRoot \u003d\n         new Path(conf.get(DistCpConstants.CONF_LABEL_TARGET_WORK_PATH));\n \n     try {\n       CopyListingFileStatus srcFileStatus \u003d new CopyListingFileStatus();\n       Text srcRelPath \u003d new Text();\n       CopyListingFileStatus lastFileStatus \u003d null;\n       LinkedList\u003cPath\u003e allChunkPaths \u003d new LinkedList\u003cPath\u003e();\n \n       // Iterate over every source path that was copied.\n       while (sourceReader.next(srcRelPath, srcFileStatus)) {\n         if (srcFileStatus.isDirectory()) {\n           continue;\n         }\n         Path targetFile \u003d new Path(targetRoot.toString() + \"/\" + srcRelPath);\n         Path targetFileChunkPath \u003d\n             DistCpUtils.getSplitChunkPath(targetFile, srcFileStatus);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"  add \" + targetFileChunkPath + \" to concat.\");\n         }\n         allChunkPaths.add(targetFileChunkPath);\n         if (srcFileStatus.getChunkOffset() + srcFileStatus.getChunkLength()\n             \u003d\u003d srcFileStatus.getLen()) {\n           // This is the last chunk of the splits, consolidate allChunkPaths\n           try {\n             concatFileChunks(conf, srcFileStatus.getPath(), targetFile,\n-                allChunkPaths);\n+                allChunkPaths, srcFileStatus);\n           } catch (IOException e) {\n             // If the concat failed because a chunk file doesn\u0027t exist,\n             // then we assume that the CopyMapper has skipped copying this\n             // file, and we ignore the exception here.\n             // If a chunk file should have been created but it was not, then\n             // the CopyMapper would have failed.\n             if (!isFileNotFoundException(e)) {\n               String emsg \u003d \"Failed to concat chunk files for \" + targetFile;\n               if (!ignoreFailures) {\n                 throw new IOException(emsg, e);\n               } else {\n                 LOG.warn(emsg, e);\n               }\n             }\n           }\n           allChunkPaths.clear();\n           lastFileStatus \u003d null;\n         } else {\n           if (lastFileStatus \u003d\u003d null) {\n             lastFileStatus \u003d new CopyListingFileStatus(srcFileStatus);\n           } else {\n             // Two neighboring chunks have to be consecutive ones for the same\n             // file, for them to be merged\n             if (!srcFileStatus.getPath().equals(lastFileStatus.getPath()) ||\n                 srcFileStatus.getChunkOffset() !\u003d\n                 (lastFileStatus.getChunkOffset() +\n                 lastFileStatus.getChunkLength())) {\n               String emsg \u003d \"Inconsistent sequence file: current \" +\n                   \"chunk file \" + srcFileStatus + \" doesnt match prior \" +\n                   \"entry \" + lastFileStatus;\n               if (!ignoreFailures) {\n                 throw new IOException(emsg);\n               } else {\n                 LOG.warn(emsg + \", skipping concat this set.\");\n               }\n             } else {\n               lastFileStatus.setChunkOffset(srcFileStatus.getChunkOffset());\n               lastFileStatus.setChunkLength(srcFileStatus.getChunkLength());\n             }\n           }\n         }\n       }\n     } finally {\n       IOUtils.closeStream(sourceReader);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void concatFileChunks(Configuration conf) throws IOException {\n\n    LOG.info(\"concat file chunks ...\");\n\n    String spath \u003d conf.get(DistCpConstants.CONF_LABEL_LISTING_FILE_PATH);\n    if (spath \u003d\u003d null || spath.isEmpty()) {\n      return;\n    }\n    Path sourceListing \u003d new Path(spath);\n    SequenceFile.Reader sourceReader \u003d new SequenceFile.Reader(conf,\n                                      SequenceFile.Reader.file(sourceListing));\n    Path targetRoot \u003d\n        new Path(conf.get(DistCpConstants.CONF_LABEL_TARGET_WORK_PATH));\n\n    try {\n      CopyListingFileStatus srcFileStatus \u003d new CopyListingFileStatus();\n      Text srcRelPath \u003d new Text();\n      CopyListingFileStatus lastFileStatus \u003d null;\n      LinkedList\u003cPath\u003e allChunkPaths \u003d new LinkedList\u003cPath\u003e();\n\n      // Iterate over every source path that was copied.\n      while (sourceReader.next(srcRelPath, srcFileStatus)) {\n        if (srcFileStatus.isDirectory()) {\n          continue;\n        }\n        Path targetFile \u003d new Path(targetRoot.toString() + \"/\" + srcRelPath);\n        Path targetFileChunkPath \u003d\n            DistCpUtils.getSplitChunkPath(targetFile, srcFileStatus);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"  add \" + targetFileChunkPath + \" to concat.\");\n        }\n        allChunkPaths.add(targetFileChunkPath);\n        if (srcFileStatus.getChunkOffset() + srcFileStatus.getChunkLength()\n            \u003d\u003d srcFileStatus.getLen()) {\n          // This is the last chunk of the splits, consolidate allChunkPaths\n          try {\n            concatFileChunks(conf, srcFileStatus.getPath(), targetFile,\n                allChunkPaths, srcFileStatus);\n          } catch (IOException e) {\n            // If the concat failed because a chunk file doesn\u0027t exist,\n            // then we assume that the CopyMapper has skipped copying this\n            // file, and we ignore the exception here.\n            // If a chunk file should have been created but it was not, then\n            // the CopyMapper would have failed.\n            if (!isFileNotFoundException(e)) {\n              String emsg \u003d \"Failed to concat chunk files for \" + targetFile;\n              if (!ignoreFailures) {\n                throw new IOException(emsg, e);\n              } else {\n                LOG.warn(emsg, e);\n              }\n            }\n          }\n          allChunkPaths.clear();\n          lastFileStatus \u003d null;\n        } else {\n          if (lastFileStatus \u003d\u003d null) {\n            lastFileStatus \u003d new CopyListingFileStatus(srcFileStatus);\n          } else {\n            // Two neighboring chunks have to be consecutive ones for the same\n            // file, for them to be merged\n            if (!srcFileStatus.getPath().equals(lastFileStatus.getPath()) ||\n                srcFileStatus.getChunkOffset() !\u003d\n                (lastFileStatus.getChunkOffset() +\n                lastFileStatus.getChunkLength())) {\n              String emsg \u003d \"Inconsistent sequence file: current \" +\n                  \"chunk file \" + srcFileStatus + \" doesnt match prior \" +\n                  \"entry \" + lastFileStatus;\n              if (!ignoreFailures) {\n                throw new IOException(emsg);\n              } else {\n                LOG.warn(emsg + \", skipping concat this set.\");\n              }\n            } else {\n              lastFileStatus.setChunkOffset(srcFileStatus.getChunkOffset());\n              lastFileStatus.setChunkLength(srcFileStatus.getChunkLength());\n            }\n          }\n        }\n      }\n    } finally {\n      IOUtils.closeStream(sourceReader);\n    }\n  }",
      "path": "hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/CopyCommitter.java",
      "extendedDetails": {}
    },
    "c765584eb231f8482f5b90b7e8f61f9f7a931d09": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-16158. DistCp to support checksum validation when copy blocks in parallel (#919)\n\n* DistCp to support checksum validation when copy blocks in parallel\r\n\r\n* address review comments\r\n\r\n* add checksums comparison test for combine mode\r\n",
      "commitDate": "18/08/19 6:46 PM",
      "commitName": "c765584eb231f8482f5b90b7e8f61f9f7a931d09",
      "commitAuthor": "KAI XIE",
      "commitDateOld": "20/07/19 12:41 AM",
      "commitNameOld": "e60f5e2572532e2bce44757997f1086065b8fd80",
      "commitAuthorOld": "Ayush Saxena",
      "daysBetweenCommits": 29.75,
      "commitsBetweenForRepo": 268,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,83 +1,84 @@\n   private void concatFileChunks(Configuration conf) throws IOException {\n \n     LOG.info(\"concat file chunks ...\");\n \n     String spath \u003d conf.get(DistCpConstants.CONF_LABEL_LISTING_FILE_PATH);\n     if (spath \u003d\u003d null || spath.isEmpty()) {\n       return;\n     }\n     Path sourceListing \u003d new Path(spath);\n     SequenceFile.Reader sourceReader \u003d new SequenceFile.Reader(conf,\n                                       SequenceFile.Reader.file(sourceListing));\n     Path targetRoot \u003d\n         new Path(conf.get(DistCpConstants.CONF_LABEL_TARGET_WORK_PATH));\n \n     try {\n       CopyListingFileStatus srcFileStatus \u003d new CopyListingFileStatus();\n       Text srcRelPath \u003d new Text();\n       CopyListingFileStatus lastFileStatus \u003d null;\n       LinkedList\u003cPath\u003e allChunkPaths \u003d new LinkedList\u003cPath\u003e();\n \n       // Iterate over every source path that was copied.\n       while (sourceReader.next(srcRelPath, srcFileStatus)) {\n         if (srcFileStatus.isDirectory()) {\n           continue;\n         }\n         Path targetFile \u003d new Path(targetRoot.toString() + \"/\" + srcRelPath);\n         Path targetFileChunkPath \u003d\n             DistCpUtils.getSplitChunkPath(targetFile, srcFileStatus);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"  add \" + targetFileChunkPath + \" to concat.\");\n         }\n         allChunkPaths.add(targetFileChunkPath);\n         if (srcFileStatus.getChunkOffset() + srcFileStatus.getChunkLength()\n             \u003d\u003d srcFileStatus.getLen()) {\n           // This is the last chunk of the splits, consolidate allChunkPaths\n           try {\n-            concatFileChunks(conf, targetFile, allChunkPaths);\n+            concatFileChunks(conf, srcFileStatus.getPath(), targetFile,\n+                allChunkPaths);\n           } catch (IOException e) {\n             // If the concat failed because a chunk file doesn\u0027t exist,\n             // then we assume that the CopyMapper has skipped copying this\n             // file, and we ignore the exception here.\n             // If a chunk file should have been created but it was not, then\n             // the CopyMapper would have failed.\n             if (!isFileNotFoundException(e)) {\n               String emsg \u003d \"Failed to concat chunk files for \" + targetFile;\n               if (!ignoreFailures) {\n                 throw new IOException(emsg, e);\n               } else {\n                 LOG.warn(emsg, e);\n               }\n             }\n           }\n           allChunkPaths.clear();\n           lastFileStatus \u003d null;\n         } else {\n           if (lastFileStatus \u003d\u003d null) {\n             lastFileStatus \u003d new CopyListingFileStatus(srcFileStatus);\n           } else {\n             // Two neighboring chunks have to be consecutive ones for the same\n             // file, for them to be merged\n             if (!srcFileStatus.getPath().equals(lastFileStatus.getPath()) ||\n                 srcFileStatus.getChunkOffset() !\u003d\n                 (lastFileStatus.getChunkOffset() +\n                 lastFileStatus.getChunkLength())) {\n               String emsg \u003d \"Inconsistent sequence file: current \" +\n                   \"chunk file \" + srcFileStatus + \" doesnt match prior \" +\n                   \"entry \" + lastFileStatus;\n               if (!ignoreFailures) {\n                 throw new IOException(emsg);\n               } else {\n                 LOG.warn(emsg + \", skipping concat this set.\");\n               }\n             } else {\n               lastFileStatus.setChunkOffset(srcFileStatus.getChunkOffset());\n               lastFileStatus.setChunkLength(srcFileStatus.getChunkLength());\n             }\n           }\n         }\n       }\n     } finally {\n       IOUtils.closeStream(sourceReader);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void concatFileChunks(Configuration conf) throws IOException {\n\n    LOG.info(\"concat file chunks ...\");\n\n    String spath \u003d conf.get(DistCpConstants.CONF_LABEL_LISTING_FILE_PATH);\n    if (spath \u003d\u003d null || spath.isEmpty()) {\n      return;\n    }\n    Path sourceListing \u003d new Path(spath);\n    SequenceFile.Reader sourceReader \u003d new SequenceFile.Reader(conf,\n                                      SequenceFile.Reader.file(sourceListing));\n    Path targetRoot \u003d\n        new Path(conf.get(DistCpConstants.CONF_LABEL_TARGET_WORK_PATH));\n\n    try {\n      CopyListingFileStatus srcFileStatus \u003d new CopyListingFileStatus();\n      Text srcRelPath \u003d new Text();\n      CopyListingFileStatus lastFileStatus \u003d null;\n      LinkedList\u003cPath\u003e allChunkPaths \u003d new LinkedList\u003cPath\u003e();\n\n      // Iterate over every source path that was copied.\n      while (sourceReader.next(srcRelPath, srcFileStatus)) {\n        if (srcFileStatus.isDirectory()) {\n          continue;\n        }\n        Path targetFile \u003d new Path(targetRoot.toString() + \"/\" + srcRelPath);\n        Path targetFileChunkPath \u003d\n            DistCpUtils.getSplitChunkPath(targetFile, srcFileStatus);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"  add \" + targetFileChunkPath + \" to concat.\");\n        }\n        allChunkPaths.add(targetFileChunkPath);\n        if (srcFileStatus.getChunkOffset() + srcFileStatus.getChunkLength()\n            \u003d\u003d srcFileStatus.getLen()) {\n          // This is the last chunk of the splits, consolidate allChunkPaths\n          try {\n            concatFileChunks(conf, srcFileStatus.getPath(), targetFile,\n                allChunkPaths);\n          } catch (IOException e) {\n            // If the concat failed because a chunk file doesn\u0027t exist,\n            // then we assume that the CopyMapper has skipped copying this\n            // file, and we ignore the exception here.\n            // If a chunk file should have been created but it was not, then\n            // the CopyMapper would have failed.\n            if (!isFileNotFoundException(e)) {\n              String emsg \u003d \"Failed to concat chunk files for \" + targetFile;\n              if (!ignoreFailures) {\n                throw new IOException(emsg, e);\n              } else {\n                LOG.warn(emsg, e);\n              }\n            }\n          }\n          allChunkPaths.clear();\n          lastFileStatus \u003d null;\n        } else {\n          if (lastFileStatus \u003d\u003d null) {\n            lastFileStatus \u003d new CopyListingFileStatus(srcFileStatus);\n          } else {\n            // Two neighboring chunks have to be consecutive ones for the same\n            // file, for them to be merged\n            if (!srcFileStatus.getPath().equals(lastFileStatus.getPath()) ||\n                srcFileStatus.getChunkOffset() !\u003d\n                (lastFileStatus.getChunkOffset() +\n                lastFileStatus.getChunkLength())) {\n              String emsg \u003d \"Inconsistent sequence file: current \" +\n                  \"chunk file \" + srcFileStatus + \" doesnt match prior \" +\n                  \"entry \" + lastFileStatus;\n              if (!ignoreFailures) {\n                throw new IOException(emsg);\n              } else {\n                LOG.warn(emsg + \", skipping concat this set.\");\n              }\n            } else {\n              lastFileStatus.setChunkOffset(srcFileStatus.getChunkOffset());\n              lastFileStatus.setChunkLength(srcFileStatus.getChunkLength());\n            }\n          }\n        }\n      }\n    } finally {\n      IOUtils.closeStream(sourceReader);\n    }\n  }",
      "path": "hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/CopyCommitter.java",
      "extendedDetails": {}
    },
    "bf3fb585aaf2b179836e139c041fc87920a3c886": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-11794. Enable distcp to copy blocks in parallel. Contributed by Yongjun Zhang, Wei-Chiu Chuang, Xiao Chen, Rosie Li.\n",
      "commitDate": "30/03/17 5:38 PM",
      "commitName": "bf3fb585aaf2b179836e139c041fc87920a3c886",
      "commitAuthor": "Yongjun Zhang",
      "diff": "@@ -0,0 +1,83 @@\n+  private void concatFileChunks(Configuration conf) throws IOException {\n+\n+    LOG.info(\"concat file chunks ...\");\n+\n+    String spath \u003d conf.get(DistCpConstants.CONF_LABEL_LISTING_FILE_PATH);\n+    if (spath \u003d\u003d null || spath.isEmpty()) {\n+      return;\n+    }\n+    Path sourceListing \u003d new Path(spath);\n+    SequenceFile.Reader sourceReader \u003d new SequenceFile.Reader(conf,\n+                                      SequenceFile.Reader.file(sourceListing));\n+    Path targetRoot \u003d\n+        new Path(conf.get(DistCpConstants.CONF_LABEL_TARGET_WORK_PATH));\n+\n+    try {\n+      CopyListingFileStatus srcFileStatus \u003d new CopyListingFileStatus();\n+      Text srcRelPath \u003d new Text();\n+      CopyListingFileStatus lastFileStatus \u003d null;\n+      LinkedList\u003cPath\u003e allChunkPaths \u003d new LinkedList\u003cPath\u003e();\n+\n+      // Iterate over every source path that was copied.\n+      while (sourceReader.next(srcRelPath, srcFileStatus)) {\n+        if (srcFileStatus.isDirectory()) {\n+          continue;\n+        }\n+        Path targetFile \u003d new Path(targetRoot.toString() + \"/\" + srcRelPath);\n+        Path targetFileChunkPath \u003d\n+            DistCpUtils.getSplitChunkPath(targetFile, srcFileStatus);\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\"  add \" + targetFileChunkPath + \" to concat.\");\n+        }\n+        allChunkPaths.add(targetFileChunkPath);\n+        if (srcFileStatus.getChunkOffset() + srcFileStatus.getChunkLength()\n+            \u003d\u003d srcFileStatus.getLen()) {\n+          // This is the last chunk of the splits, consolidate allChunkPaths\n+          try {\n+            concatFileChunks(conf, targetFile, allChunkPaths);\n+          } catch (IOException e) {\n+            // If the concat failed because a chunk file doesn\u0027t exist,\n+            // then we assume that the CopyMapper has skipped copying this\n+            // file, and we ignore the exception here.\n+            // If a chunk file should have been created but it was not, then\n+            // the CopyMapper would have failed.\n+            if (!isFileNotFoundException(e)) {\n+              String emsg \u003d \"Failed to concat chunk files for \" + targetFile;\n+              if (!ignoreFailures) {\n+                throw new IOException(emsg, e);\n+              } else {\n+                LOG.warn(emsg, e);\n+              }\n+            }\n+          }\n+          allChunkPaths.clear();\n+          lastFileStatus \u003d null;\n+        } else {\n+          if (lastFileStatus \u003d\u003d null) {\n+            lastFileStatus \u003d new CopyListingFileStatus(srcFileStatus);\n+          } else {\n+            // Two neighboring chunks have to be consecutive ones for the same\n+            // file, for them to be merged\n+            if (!srcFileStatus.getPath().equals(lastFileStatus.getPath()) ||\n+                srcFileStatus.getChunkOffset() !\u003d\n+                (lastFileStatus.getChunkOffset() +\n+                lastFileStatus.getChunkLength())) {\n+              String emsg \u003d \"Inconsistent sequence file: current \" +\n+                  \"chunk file \" + srcFileStatus + \" doesnt match prior \" +\n+                  \"entry \" + lastFileStatus;\n+              if (!ignoreFailures) {\n+                throw new IOException(emsg);\n+              } else {\n+                LOG.warn(emsg + \", skipping concat this set.\");\n+              }\n+            } else {\n+              lastFileStatus.setChunkOffset(srcFileStatus.getChunkOffset());\n+              lastFileStatus.setChunkLength(srcFileStatus.getChunkLength());\n+            }\n+          }\n+        }\n+      }\n+    } finally {\n+      IOUtils.closeStream(sourceReader);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void concatFileChunks(Configuration conf) throws IOException {\n\n    LOG.info(\"concat file chunks ...\");\n\n    String spath \u003d conf.get(DistCpConstants.CONF_LABEL_LISTING_FILE_PATH);\n    if (spath \u003d\u003d null || spath.isEmpty()) {\n      return;\n    }\n    Path sourceListing \u003d new Path(spath);\n    SequenceFile.Reader sourceReader \u003d new SequenceFile.Reader(conf,\n                                      SequenceFile.Reader.file(sourceListing));\n    Path targetRoot \u003d\n        new Path(conf.get(DistCpConstants.CONF_LABEL_TARGET_WORK_PATH));\n\n    try {\n      CopyListingFileStatus srcFileStatus \u003d new CopyListingFileStatus();\n      Text srcRelPath \u003d new Text();\n      CopyListingFileStatus lastFileStatus \u003d null;\n      LinkedList\u003cPath\u003e allChunkPaths \u003d new LinkedList\u003cPath\u003e();\n\n      // Iterate over every source path that was copied.\n      while (sourceReader.next(srcRelPath, srcFileStatus)) {\n        if (srcFileStatus.isDirectory()) {\n          continue;\n        }\n        Path targetFile \u003d new Path(targetRoot.toString() + \"/\" + srcRelPath);\n        Path targetFileChunkPath \u003d\n            DistCpUtils.getSplitChunkPath(targetFile, srcFileStatus);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"  add \" + targetFileChunkPath + \" to concat.\");\n        }\n        allChunkPaths.add(targetFileChunkPath);\n        if (srcFileStatus.getChunkOffset() + srcFileStatus.getChunkLength()\n            \u003d\u003d srcFileStatus.getLen()) {\n          // This is the last chunk of the splits, consolidate allChunkPaths\n          try {\n            concatFileChunks(conf, targetFile, allChunkPaths);\n          } catch (IOException e) {\n            // If the concat failed because a chunk file doesn\u0027t exist,\n            // then we assume that the CopyMapper has skipped copying this\n            // file, and we ignore the exception here.\n            // If a chunk file should have been created but it was not, then\n            // the CopyMapper would have failed.\n            if (!isFileNotFoundException(e)) {\n              String emsg \u003d \"Failed to concat chunk files for \" + targetFile;\n              if (!ignoreFailures) {\n                throw new IOException(emsg, e);\n              } else {\n                LOG.warn(emsg, e);\n              }\n            }\n          }\n          allChunkPaths.clear();\n          lastFileStatus \u003d null;\n        } else {\n          if (lastFileStatus \u003d\u003d null) {\n            lastFileStatus \u003d new CopyListingFileStatus(srcFileStatus);\n          } else {\n            // Two neighboring chunks have to be consecutive ones for the same\n            // file, for them to be merged\n            if (!srcFileStatus.getPath().equals(lastFileStatus.getPath()) ||\n                srcFileStatus.getChunkOffset() !\u003d\n                (lastFileStatus.getChunkOffset() +\n                lastFileStatus.getChunkLength())) {\n              String emsg \u003d \"Inconsistent sequence file: current \" +\n                  \"chunk file \" + srcFileStatus + \" doesnt match prior \" +\n                  \"entry \" + lastFileStatus;\n              if (!ignoreFailures) {\n                throw new IOException(emsg);\n              } else {\n                LOG.warn(emsg + \", skipping concat this set.\");\n              }\n            } else {\n              lastFileStatus.setChunkOffset(srcFileStatus.getChunkOffset());\n              lastFileStatus.setChunkLength(srcFileStatus.getChunkLength());\n            }\n          }\n        }\n      }\n    } finally {\n      IOUtils.closeStream(sourceReader);\n    }\n  }",
      "path": "hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/CopyCommitter.java"
    }
  }
}