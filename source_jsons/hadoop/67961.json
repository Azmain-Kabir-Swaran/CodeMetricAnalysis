{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DistCpUtils.java",
  "functionName": "compareFileLengthsAndChecksums",
  "functionId": "compareFileLengthsAndChecksums___srcLen-long__sourceFS-FileSystem__source-Path__sourceChecksum-FileChecksum__targetFS-FileSystem__target-Path__skipCrc-boolean__targetLen-long",
  "sourceFilePath": "hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/util/DistCpUtils.java",
  "functionStartLine": 604,
  "functionEndLine": 649,
  "numCommitsSeen": 56,
  "timeTaken": 3061,
  "changeHistory": [
    "51c64b357d4bd1a0038e61df3d4b8ea0a3ad7449",
    "c765584eb231f8482f5b90b7e8f61f9f7a931d09"
  ],
  "changeHistoryShort": {
    "51c64b357d4bd1a0038e61df3d4b8ea0a3ad7449": "Ymultichange(Yparameterchange,Ybodychange)",
    "c765584eb231f8482f5b90b7e8f61f9f7a931d09": "Yintroduced"
  },
  "changeHistoryDetails": {
    "51c64b357d4bd1a0038e61df3d4b8ea0a3ad7449": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-13660. DistCp job fails when new data is appended in the file while the DistCp copy job is running\n\nThis uses the length of the file known at the start of the copy to determine the amount of data to copy.\n\n* If a file is appended to during the copy, the original bytes are copied.\n* If a file is truncated during a copy, or the attempt to read the data fails with a truncated stream,\n  distcp will now fail. Until now these failures were not detected.\n\nContributed by Mukund Thakur.\n\nChange-Id: I576a49d951fa48d37a45a7e4c82c47488aa8e884\n",
      "commitDate": "24/09/19 3:23 AM",
      "commitName": "51c64b357d4bd1a0038e61df3d4b8ea0a3ad7449",
      "commitAuthor": "Mukund Thakur",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-13660. DistCp job fails when new data is appended in the file while the DistCp copy job is running\n\nThis uses the length of the file known at the start of the copy to determine the amount of data to copy.\n\n* If a file is appended to during the copy, the original bytes are copied.\n* If a file is truncated during a copy, or the attempt to read the data fails with a truncated stream,\n  distcp will now fail. Until now these failures were not detected.\n\nContributed by Mukund Thakur.\n\nChange-Id: I576a49d951fa48d37a45a7e4c82c47488aa8e884\n",
          "commitDate": "24/09/19 3:23 AM",
          "commitName": "51c64b357d4bd1a0038e61df3d4b8ea0a3ad7449",
          "commitAuthor": "Mukund Thakur",
          "commitDateOld": "18/08/19 6:46 PM",
          "commitNameOld": "c765584eb231f8482f5b90b7e8f61f9f7a931d09",
          "commitAuthorOld": "KAI XIE",
          "daysBetweenCommits": 36.36,
          "commitsBetweenForRepo": 313,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,47 +1,46 @@\n-  public static void compareFileLengthsAndChecksums(\n-      FileSystem sourceFS, Path source, FileChecksum sourceChecksum,\n-      FileSystem targetFS, Path target, boolean skipCrc) throws IOException {\n-    long srcLen \u003d sourceFS.getFileStatus(source).getLen();\n-    long tgtLen \u003d targetFS.getFileStatus(target).getLen();\n-    if (srcLen !\u003d tgtLen) {\n+  public static void compareFileLengthsAndChecksums(long srcLen,\n+             FileSystem sourceFS, Path source, FileChecksum sourceChecksum,\n+             FileSystem targetFS, Path target, boolean skipCrc,\n+             long targetLen) throws IOException {\n+    if (srcLen !\u003d targetLen) {\n       throw new IOException(\n-          \"Mismatch in length of source:\" + source + \" (\" + srcLen\n-              + \") and target:\" + target + \" (\" + tgtLen + \")\");\n+          DistCpConstants.LENGTH_MISMATCH_ERROR_MSG + source + \" (\" + srcLen\n+              + \") and target:\" + target + \" (\" + targetLen + \")\");\n     }\n \n     //At this point, src \u0026 dest lengths are same. if length\u003d\u003d0, we skip checksum\n     if ((srcLen !\u003d 0) \u0026\u0026 (!skipCrc)) {\n       if (!checksumsAreEqual(sourceFS, source, sourceChecksum,\n-          targetFS, target)) {\n+          targetFS, target, srcLen)) {\n         StringBuilder errorMessage \u003d\n-            new StringBuilder(\"Checksum mismatch between \")\n+            new StringBuilder(DistCpConstants.CHECKSUM_MISMATCH_ERROR_MSG)\n                 .append(source).append(\" and \").append(target).append(\".\");\n         boolean addSkipHint \u003d false;\n         String srcScheme \u003d sourceFS.getScheme();\n         String targetScheme \u003d targetFS.getScheme();\n         if (!srcScheme.equals(targetScheme)) {\n           // the filesystems are different and they aren\u0027t both hdfs connectors\n           errorMessage.append(\"Source and destination filesystems are of\"\n               + \" different types\\n\")\n               .append(\"Their checksum algorithms may be incompatible\");\n           addSkipHint \u003d true;\n         } else if (sourceFS.getFileStatus(source).getBlockSize() !\u003d\n             targetFS.getFileStatus(target).getBlockSize()) {\n           errorMessage.append(\" Source and target differ in block-size.\\n\")\n               .append(\" Use -pb to preserve block-sizes during copy.\");\n           addSkipHint \u003d true;\n         }\n         if (addSkipHint) {\n           errorMessage\n               .append(\" You can choose file-level checksum validation via \"\n                   + \"-Ddfs.checksum.combine.mode\u003dCOMPOSITE_CRC when block-sizes\"\n                   + \" or filesystems are different.\")\n               .append(\" Or you can skip checksum-checks altogether \"\n                   + \" with -skipcrccheck.\\n\")\n               .append(\" (NOTE: By skipping checksums, one runs the risk of \" +\n                   \"masking data-corruption during file-transfer.)\\n\");\n         }\n         throw new IOException(errorMessage.toString());\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static void compareFileLengthsAndChecksums(long srcLen,\n             FileSystem sourceFS, Path source, FileChecksum sourceChecksum,\n             FileSystem targetFS, Path target, boolean skipCrc,\n             long targetLen) throws IOException {\n    if (srcLen !\u003d targetLen) {\n      throw new IOException(\n          DistCpConstants.LENGTH_MISMATCH_ERROR_MSG + source + \" (\" + srcLen\n              + \") and target:\" + target + \" (\" + targetLen + \")\");\n    }\n\n    //At this point, src \u0026 dest lengths are same. if length\u003d\u003d0, we skip checksum\n    if ((srcLen !\u003d 0) \u0026\u0026 (!skipCrc)) {\n      if (!checksumsAreEqual(sourceFS, source, sourceChecksum,\n          targetFS, target, srcLen)) {\n        StringBuilder errorMessage \u003d\n            new StringBuilder(DistCpConstants.CHECKSUM_MISMATCH_ERROR_MSG)\n                .append(source).append(\" and \").append(target).append(\".\");\n        boolean addSkipHint \u003d false;\n        String srcScheme \u003d sourceFS.getScheme();\n        String targetScheme \u003d targetFS.getScheme();\n        if (!srcScheme.equals(targetScheme)) {\n          // the filesystems are different and they aren\u0027t both hdfs connectors\n          errorMessage.append(\"Source and destination filesystems are of\"\n              + \" different types\\n\")\n              .append(\"Their checksum algorithms may be incompatible\");\n          addSkipHint \u003d true;\n        } else if (sourceFS.getFileStatus(source).getBlockSize() !\u003d\n            targetFS.getFileStatus(target).getBlockSize()) {\n          errorMessage.append(\" Source and target differ in block-size.\\n\")\n              .append(\" Use -pb to preserve block-sizes during copy.\");\n          addSkipHint \u003d true;\n        }\n        if (addSkipHint) {\n          errorMessage\n              .append(\" You can choose file-level checksum validation via \"\n                  + \"-Ddfs.checksum.combine.mode\u003dCOMPOSITE_CRC when block-sizes\"\n                  + \" or filesystems are different.\")\n              .append(\" Or you can skip checksum-checks altogether \"\n                  + \" with -skipcrccheck.\\n\")\n              .append(\" (NOTE: By skipping checksums, one runs the risk of \" +\n                  \"masking data-corruption during file-transfer.)\\n\");\n        }\n        throw new IOException(errorMessage.toString());\n      }\n    }\n  }",
          "path": "hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/util/DistCpUtils.java",
          "extendedDetails": {
            "oldValue": "[sourceFS-FileSystem, source-Path, sourceChecksum-FileChecksum, targetFS-FileSystem, target-Path, skipCrc-boolean]",
            "newValue": "[srcLen-long, sourceFS-FileSystem, source-Path, sourceChecksum-FileChecksum, targetFS-FileSystem, target-Path, skipCrc-boolean, targetLen-long]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-13660. DistCp job fails when new data is appended in the file while the DistCp copy job is running\n\nThis uses the length of the file known at the start of the copy to determine the amount of data to copy.\n\n* If a file is appended to during the copy, the original bytes are copied.\n* If a file is truncated during a copy, or the attempt to read the data fails with a truncated stream,\n  distcp will now fail. Until now these failures were not detected.\n\nContributed by Mukund Thakur.\n\nChange-Id: I576a49d951fa48d37a45a7e4c82c47488aa8e884\n",
          "commitDate": "24/09/19 3:23 AM",
          "commitName": "51c64b357d4bd1a0038e61df3d4b8ea0a3ad7449",
          "commitAuthor": "Mukund Thakur",
          "commitDateOld": "18/08/19 6:46 PM",
          "commitNameOld": "c765584eb231f8482f5b90b7e8f61f9f7a931d09",
          "commitAuthorOld": "KAI XIE",
          "daysBetweenCommits": 36.36,
          "commitsBetweenForRepo": 313,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,47 +1,46 @@\n-  public static void compareFileLengthsAndChecksums(\n-      FileSystem sourceFS, Path source, FileChecksum sourceChecksum,\n-      FileSystem targetFS, Path target, boolean skipCrc) throws IOException {\n-    long srcLen \u003d sourceFS.getFileStatus(source).getLen();\n-    long tgtLen \u003d targetFS.getFileStatus(target).getLen();\n-    if (srcLen !\u003d tgtLen) {\n+  public static void compareFileLengthsAndChecksums(long srcLen,\n+             FileSystem sourceFS, Path source, FileChecksum sourceChecksum,\n+             FileSystem targetFS, Path target, boolean skipCrc,\n+             long targetLen) throws IOException {\n+    if (srcLen !\u003d targetLen) {\n       throw new IOException(\n-          \"Mismatch in length of source:\" + source + \" (\" + srcLen\n-              + \") and target:\" + target + \" (\" + tgtLen + \")\");\n+          DistCpConstants.LENGTH_MISMATCH_ERROR_MSG + source + \" (\" + srcLen\n+              + \") and target:\" + target + \" (\" + targetLen + \")\");\n     }\n \n     //At this point, src \u0026 dest lengths are same. if length\u003d\u003d0, we skip checksum\n     if ((srcLen !\u003d 0) \u0026\u0026 (!skipCrc)) {\n       if (!checksumsAreEqual(sourceFS, source, sourceChecksum,\n-          targetFS, target)) {\n+          targetFS, target, srcLen)) {\n         StringBuilder errorMessage \u003d\n-            new StringBuilder(\"Checksum mismatch between \")\n+            new StringBuilder(DistCpConstants.CHECKSUM_MISMATCH_ERROR_MSG)\n                 .append(source).append(\" and \").append(target).append(\".\");\n         boolean addSkipHint \u003d false;\n         String srcScheme \u003d sourceFS.getScheme();\n         String targetScheme \u003d targetFS.getScheme();\n         if (!srcScheme.equals(targetScheme)) {\n           // the filesystems are different and they aren\u0027t both hdfs connectors\n           errorMessage.append(\"Source and destination filesystems are of\"\n               + \" different types\\n\")\n               .append(\"Their checksum algorithms may be incompatible\");\n           addSkipHint \u003d true;\n         } else if (sourceFS.getFileStatus(source).getBlockSize() !\u003d\n             targetFS.getFileStatus(target).getBlockSize()) {\n           errorMessage.append(\" Source and target differ in block-size.\\n\")\n               .append(\" Use -pb to preserve block-sizes during copy.\");\n           addSkipHint \u003d true;\n         }\n         if (addSkipHint) {\n           errorMessage\n               .append(\" You can choose file-level checksum validation via \"\n                   + \"-Ddfs.checksum.combine.mode\u003dCOMPOSITE_CRC when block-sizes\"\n                   + \" or filesystems are different.\")\n               .append(\" Or you can skip checksum-checks altogether \"\n                   + \" with -skipcrccheck.\\n\")\n               .append(\" (NOTE: By skipping checksums, one runs the risk of \" +\n                   \"masking data-corruption during file-transfer.)\\n\");\n         }\n         throw new IOException(errorMessage.toString());\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static void compareFileLengthsAndChecksums(long srcLen,\n             FileSystem sourceFS, Path source, FileChecksum sourceChecksum,\n             FileSystem targetFS, Path target, boolean skipCrc,\n             long targetLen) throws IOException {\n    if (srcLen !\u003d targetLen) {\n      throw new IOException(\n          DistCpConstants.LENGTH_MISMATCH_ERROR_MSG + source + \" (\" + srcLen\n              + \") and target:\" + target + \" (\" + targetLen + \")\");\n    }\n\n    //At this point, src \u0026 dest lengths are same. if length\u003d\u003d0, we skip checksum\n    if ((srcLen !\u003d 0) \u0026\u0026 (!skipCrc)) {\n      if (!checksumsAreEqual(sourceFS, source, sourceChecksum,\n          targetFS, target, srcLen)) {\n        StringBuilder errorMessage \u003d\n            new StringBuilder(DistCpConstants.CHECKSUM_MISMATCH_ERROR_MSG)\n                .append(source).append(\" and \").append(target).append(\".\");\n        boolean addSkipHint \u003d false;\n        String srcScheme \u003d sourceFS.getScheme();\n        String targetScheme \u003d targetFS.getScheme();\n        if (!srcScheme.equals(targetScheme)) {\n          // the filesystems are different and they aren\u0027t both hdfs connectors\n          errorMessage.append(\"Source and destination filesystems are of\"\n              + \" different types\\n\")\n              .append(\"Their checksum algorithms may be incompatible\");\n          addSkipHint \u003d true;\n        } else if (sourceFS.getFileStatus(source).getBlockSize() !\u003d\n            targetFS.getFileStatus(target).getBlockSize()) {\n          errorMessage.append(\" Source and target differ in block-size.\\n\")\n              .append(\" Use -pb to preserve block-sizes during copy.\");\n          addSkipHint \u003d true;\n        }\n        if (addSkipHint) {\n          errorMessage\n              .append(\" You can choose file-level checksum validation via \"\n                  + \"-Ddfs.checksum.combine.mode\u003dCOMPOSITE_CRC when block-sizes\"\n                  + \" or filesystems are different.\")\n              .append(\" Or you can skip checksum-checks altogether \"\n                  + \" with -skipcrccheck.\\n\")\n              .append(\" (NOTE: By skipping checksums, one runs the risk of \" +\n                  \"masking data-corruption during file-transfer.)\\n\");\n        }\n        throw new IOException(errorMessage.toString());\n      }\n    }\n  }",
          "path": "hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/util/DistCpUtils.java",
          "extendedDetails": {}
        }
      ]
    },
    "c765584eb231f8482f5b90b7e8f61f9f7a931d09": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-16158. DistCp to support checksum validation when copy blocks in parallel (#919)\n\n* DistCp to support checksum validation when copy blocks in parallel\r\n\r\n* address review comments\r\n\r\n* add checksums comparison test for combine mode\r\n",
      "commitDate": "18/08/19 6:46 PM",
      "commitName": "c765584eb231f8482f5b90b7e8f61f9f7a931d09",
      "commitAuthor": "KAI XIE",
      "diff": "@@ -0,0 +1,47 @@\n+  public static void compareFileLengthsAndChecksums(\n+      FileSystem sourceFS, Path source, FileChecksum sourceChecksum,\n+      FileSystem targetFS, Path target, boolean skipCrc) throws IOException {\n+    long srcLen \u003d sourceFS.getFileStatus(source).getLen();\n+    long tgtLen \u003d targetFS.getFileStatus(target).getLen();\n+    if (srcLen !\u003d tgtLen) {\n+      throw new IOException(\n+          \"Mismatch in length of source:\" + source + \" (\" + srcLen\n+              + \") and target:\" + target + \" (\" + tgtLen + \")\");\n+    }\n+\n+    //At this point, src \u0026 dest lengths are same. if length\u003d\u003d0, we skip checksum\n+    if ((srcLen !\u003d 0) \u0026\u0026 (!skipCrc)) {\n+      if (!checksumsAreEqual(sourceFS, source, sourceChecksum,\n+          targetFS, target)) {\n+        StringBuilder errorMessage \u003d\n+            new StringBuilder(\"Checksum mismatch between \")\n+                .append(source).append(\" and \").append(target).append(\".\");\n+        boolean addSkipHint \u003d false;\n+        String srcScheme \u003d sourceFS.getScheme();\n+        String targetScheme \u003d targetFS.getScheme();\n+        if (!srcScheme.equals(targetScheme)) {\n+          // the filesystems are different and they aren\u0027t both hdfs connectors\n+          errorMessage.append(\"Source and destination filesystems are of\"\n+              + \" different types\\n\")\n+              .append(\"Their checksum algorithms may be incompatible\");\n+          addSkipHint \u003d true;\n+        } else if (sourceFS.getFileStatus(source).getBlockSize() !\u003d\n+            targetFS.getFileStatus(target).getBlockSize()) {\n+          errorMessage.append(\" Source and target differ in block-size.\\n\")\n+              .append(\" Use -pb to preserve block-sizes during copy.\");\n+          addSkipHint \u003d true;\n+        }\n+        if (addSkipHint) {\n+          errorMessage\n+              .append(\" You can choose file-level checksum validation via \"\n+                  + \"-Ddfs.checksum.combine.mode\u003dCOMPOSITE_CRC when block-sizes\"\n+                  + \" or filesystems are different.\")\n+              .append(\" Or you can skip checksum-checks altogether \"\n+                  + \" with -skipcrccheck.\\n\")\n+              .append(\" (NOTE: By skipping checksums, one runs the risk of \" +\n+                  \"masking data-corruption during file-transfer.)\\n\");\n+        }\n+        throw new IOException(errorMessage.toString());\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public static void compareFileLengthsAndChecksums(\n      FileSystem sourceFS, Path source, FileChecksum sourceChecksum,\n      FileSystem targetFS, Path target, boolean skipCrc) throws IOException {\n    long srcLen \u003d sourceFS.getFileStatus(source).getLen();\n    long tgtLen \u003d targetFS.getFileStatus(target).getLen();\n    if (srcLen !\u003d tgtLen) {\n      throw new IOException(\n          \"Mismatch in length of source:\" + source + \" (\" + srcLen\n              + \") and target:\" + target + \" (\" + tgtLen + \")\");\n    }\n\n    //At this point, src \u0026 dest lengths are same. if length\u003d\u003d0, we skip checksum\n    if ((srcLen !\u003d 0) \u0026\u0026 (!skipCrc)) {\n      if (!checksumsAreEqual(sourceFS, source, sourceChecksum,\n          targetFS, target)) {\n        StringBuilder errorMessage \u003d\n            new StringBuilder(\"Checksum mismatch between \")\n                .append(source).append(\" and \").append(target).append(\".\");\n        boolean addSkipHint \u003d false;\n        String srcScheme \u003d sourceFS.getScheme();\n        String targetScheme \u003d targetFS.getScheme();\n        if (!srcScheme.equals(targetScheme)) {\n          // the filesystems are different and they aren\u0027t both hdfs connectors\n          errorMessage.append(\"Source and destination filesystems are of\"\n              + \" different types\\n\")\n              .append(\"Their checksum algorithms may be incompatible\");\n          addSkipHint \u003d true;\n        } else if (sourceFS.getFileStatus(source).getBlockSize() !\u003d\n            targetFS.getFileStatus(target).getBlockSize()) {\n          errorMessage.append(\" Source and target differ in block-size.\\n\")\n              .append(\" Use -pb to preserve block-sizes during copy.\");\n          addSkipHint \u003d true;\n        }\n        if (addSkipHint) {\n          errorMessage\n              .append(\" You can choose file-level checksum validation via \"\n                  + \"-Ddfs.checksum.combine.mode\u003dCOMPOSITE_CRC when block-sizes\"\n                  + \" or filesystems are different.\")\n              .append(\" Or you can skip checksum-checks altogether \"\n                  + \" with -skipcrccheck.\\n\")\n              .append(\" (NOTE: By skipping checksums, one runs the risk of \" +\n                  \"masking data-corruption during file-transfer.)\\n\");\n        }\n        throw new IOException(errorMessage.toString());\n      }\n    }\n  }",
      "path": "hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/util/DistCpUtils.java"
    }
  }
}