{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "InstrumentationService.java",
  "functionName": "getToAdd",
  "functionId": "getToAdd___group-String__name-String__klass-Class__T____lock-Lock__map-Map__String,Map__String,T____",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-httpfs/src/main/java/org/apache/hadoop/lib/service/instrumentation/InstrumentationService.java",
  "functionStartLine": 121,
  "functionEndLine": 160,
  "numCommitsSeen": 4,
  "timeTaken": 501,
  "changeHistory": [
    "3334306512b5dc932814fded31a89ba1ee97cd9f"
  ],
  "changeHistoryShort": {
    "3334306512b5dc932814fded31a89ba1ee97cd9f": "Yintroduced"
  },
  "changeHistoryDetails": {
    "3334306512b5dc932814fded31a89ba1ee97cd9f": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-2178. Contributing Hoop to HDFS, replacement for HDFS proxy with read/write capabilities. (tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1212060 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/12/11 11:25 AM",
      "commitName": "3334306512b5dc932814fded31a89ba1ee97cd9f",
      "commitAuthor": "Alejandro Abdelnur",
      "diff": "@@ -0,0 +1,40 @@\n+  private \u003cT\u003e T getToAdd(String group, String name, Class\u003cT\u003e klass, Lock lock, Map\u003cString, Map\u003cString, T\u003e\u003e map) {\n+    boolean locked \u003d false;\n+    try {\n+      Map\u003cString, T\u003e groupMap \u003d map.get(group);\n+      if (groupMap \u003d\u003d null) {\n+        lock.lock();\n+        locked \u003d true;\n+        groupMap \u003d map.get(group);\n+        if (groupMap \u003d\u003d null) {\n+          groupMap \u003d new ConcurrentHashMap\u003cString, T\u003e();\n+          map.put(group, groupMap);\n+        }\n+      }\n+      T element \u003d groupMap.get(name);\n+      if (element \u003d\u003d null) {\n+        if (!locked) {\n+          lock.lock();\n+          locked \u003d true;\n+        }\n+        element \u003d groupMap.get(name);\n+        if (element \u003d\u003d null) {\n+          try {\n+            if (klass \u003d\u003d Timer.class) {\n+              element \u003d (T) new Timer(timersSize);\n+            } else {\n+              element \u003d klass.newInstance();\n+            }\n+          } catch (Exception ex) {\n+            throw new RuntimeException(ex);\n+          }\n+          groupMap.put(name, element);\n+        }\n+      }\n+      return element;\n+    } finally {\n+      if (locked) {\n+        lock.unlock();\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private \u003cT\u003e T getToAdd(String group, String name, Class\u003cT\u003e klass, Lock lock, Map\u003cString, Map\u003cString, T\u003e\u003e map) {\n    boolean locked \u003d false;\n    try {\n      Map\u003cString, T\u003e groupMap \u003d map.get(group);\n      if (groupMap \u003d\u003d null) {\n        lock.lock();\n        locked \u003d true;\n        groupMap \u003d map.get(group);\n        if (groupMap \u003d\u003d null) {\n          groupMap \u003d new ConcurrentHashMap\u003cString, T\u003e();\n          map.put(group, groupMap);\n        }\n      }\n      T element \u003d groupMap.get(name);\n      if (element \u003d\u003d null) {\n        if (!locked) {\n          lock.lock();\n          locked \u003d true;\n        }\n        element \u003d groupMap.get(name);\n        if (element \u003d\u003d null) {\n          try {\n            if (klass \u003d\u003d Timer.class) {\n              element \u003d (T) new Timer(timersSize);\n            } else {\n              element \u003d klass.newInstance();\n            }\n          } catch (Exception ex) {\n            throw new RuntimeException(ex);\n          }\n          groupMap.put(name, element);\n        }\n      }\n      return element;\n    } finally {\n      if (locked) {\n        lock.unlock();\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-httpfs/src/main/java/org/apache/hadoop/lib/service/instrumentation/InstrumentationService.java"
    }
  }
}