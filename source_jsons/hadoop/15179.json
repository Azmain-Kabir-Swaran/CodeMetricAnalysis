{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FileDistributionCalculator.java",
  "functionName": "output",
  "functionId": "output",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/FileDistributionCalculator.java",
  "functionStartLine": 153,
  "functionEndLine": 177,
  "numCommitsSeen": 9,
  "timeTaken": 2348,
  "changeHistory": [
    "835560983ed74a2798d2fb3a2bb0bb46a4ee7c55",
    "63f594892ecd4687e37a99790288e36eb278849f",
    "a2edb11b68ae01a44092cb14ac2717a6aad93305"
  ],
  "changeHistoryShort": {
    "835560983ed74a2798d2fb3a2bb0bb46a4ee7c55": "Ybodychange",
    "63f594892ecd4687e37a99790288e36eb278849f": "Ybodychange",
    "a2edb11b68ae01a44092cb14ac2717a6aad93305": "Yintroduced"
  },
  "changeHistoryDetails": {
    "835560983ed74a2798d2fb3a2bb0bb46a4ee7c55": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11928. Segment overflow in FileDistributionCalculator. Contributed by LiXin Ge.\n",
      "commitDate": "05/06/17 1:21 PM",
      "commitName": "835560983ed74a2798d2fb3a2bb0bb46a4ee7c55",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "07/09/16 11:13 PM",
      "commitNameOld": "63f594892ecd4687e37a99790288e36eb278849f",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 270.59,
      "commitsBetweenForRepo": 1626,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,25 +1,25 @@\n   private void output() {\n     // write the distribution into the output file\n     out.print((formatOutput ? \"Size Range\" : \"Size\") + \"\\tNumFiles\\n\");\n     for (int i \u003d 0; i \u003c distribution.length; i++) {\n       if (distribution[i] !\u003d 0) {\n         if (formatOutput) {\n           out.print((i \u003d\u003d 0 ? \"[\" : \"(\")\n               + StringUtils.byteDesc(((long) (i \u003d\u003d 0 ? 0 : i - 1) * steps))\n               + \", \"\n               + StringUtils.byteDesc((long)\n-                  (i \u003d\u003d distribution.length - 1 ? maxFileSize : i * steps))\n-                  + \"]\\t\" + distribution[i]);\n+                  (i \u003d\u003d distribution.length - 1 ? maxFileSize :\n+                      (long) i * steps)) + \"]\\t\" + distribution[i]);\n         } else {\n           out.print(((long) i * steps) + \"\\t\" + distribution[i]);\n         }\n \n         out.print(\u0027\\n\u0027);\n       }\n     }\n     out.print(\"totalFiles \u003d \" + totalFiles + \"\\n\");\n     out.print(\"totalDirectories \u003d \" + totalDirectories + \"\\n\");\n     out.print(\"totalBlocks \u003d \" + totalBlocks + \"\\n\");\n     out.print(\"totalSpace \u003d \" + totalSpace + \"\\n\");\n     out.print(\"maxFileSize \u003d \" + maxFileSize + \"\\n\");\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void output() {\n    // write the distribution into the output file\n    out.print((formatOutput ? \"Size Range\" : \"Size\") + \"\\tNumFiles\\n\");\n    for (int i \u003d 0; i \u003c distribution.length; i++) {\n      if (distribution[i] !\u003d 0) {\n        if (formatOutput) {\n          out.print((i \u003d\u003d 0 ? \"[\" : \"(\")\n              + StringUtils.byteDesc(((long) (i \u003d\u003d 0 ? 0 : i - 1) * steps))\n              + \", \"\n              + StringUtils.byteDesc((long)\n                  (i \u003d\u003d distribution.length - 1 ? maxFileSize :\n                      (long) i * steps)) + \"]\\t\" + distribution[i]);\n        } else {\n          out.print(((long) i * steps) + \"\\t\" + distribution[i]);\n        }\n\n        out.print(\u0027\\n\u0027);\n      }\n    }\n    out.print(\"totalFiles \u003d \" + totalFiles + \"\\n\");\n    out.print(\"totalDirectories \u003d \" + totalDirectories + \"\\n\");\n    out.print(\"totalBlocks \u003d \" + totalBlocks + \"\\n\");\n    out.print(\"totalSpace \u003d \" + totalSpace + \"\\n\");\n    out.print(\"maxFileSize \u003d \" + maxFileSize + \"\\n\");\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/FileDistributionCalculator.java",
      "extendedDetails": {}
    },
    "63f594892ecd4687e37a99790288e36eb278849f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10778. Add -format option to make the output of FileDistribution processor human-readable in OfflineImageViewer.\n",
      "commitDate": "07/09/16 11:13 PM",
      "commitName": "63f594892ecd4687e37a99790288e36eb278849f",
      "commitAuthor": "Akira Ajisaka",
      "commitDateOld": "28/07/16 11:39 PM",
      "commitNameOld": "204a2055b1b9270ae13ea03b7aeac62b65166efd",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 40.98,
      "commitsBetweenForRepo": 264,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,15 +1,25 @@\n   private void output() {\n     // write the distribution into the output file\n-    out.print(\"Size\\tNumFiles\\n\");\n+    out.print((formatOutput ? \"Size Range\" : \"Size\") + \"\\tNumFiles\\n\");\n     for (int i \u003d 0; i \u003c distribution.length; i++) {\n       if (distribution[i] !\u003d 0) {\n-        out.print(((long) i * steps) + \"\\t\" + distribution[i]);\n+        if (formatOutput) {\n+          out.print((i \u003d\u003d 0 ? \"[\" : \"(\")\n+              + StringUtils.byteDesc(((long) (i \u003d\u003d 0 ? 0 : i - 1) * steps))\n+              + \", \"\n+              + StringUtils.byteDesc((long)\n+                  (i \u003d\u003d distribution.length - 1 ? maxFileSize : i * steps))\n+                  + \"]\\t\" + distribution[i]);\n+        } else {\n+          out.print(((long) i * steps) + \"\\t\" + distribution[i]);\n+        }\n+\n         out.print(\u0027\\n\u0027);\n       }\n     }\n     out.print(\"totalFiles \u003d \" + totalFiles + \"\\n\");\n     out.print(\"totalDirectories \u003d \" + totalDirectories + \"\\n\");\n     out.print(\"totalBlocks \u003d \" + totalBlocks + \"\\n\");\n     out.print(\"totalSpace \u003d \" + totalSpace + \"\\n\");\n     out.print(\"maxFileSize \u003d \" + maxFileSize + \"\\n\");\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void output() {\n    // write the distribution into the output file\n    out.print((formatOutput ? \"Size Range\" : \"Size\") + \"\\tNumFiles\\n\");\n    for (int i \u003d 0; i \u003c distribution.length; i++) {\n      if (distribution[i] !\u003d 0) {\n        if (formatOutput) {\n          out.print((i \u003d\u003d 0 ? \"[\" : \"(\")\n              + StringUtils.byteDesc(((long) (i \u003d\u003d 0 ? 0 : i - 1) * steps))\n              + \", \"\n              + StringUtils.byteDesc((long)\n                  (i \u003d\u003d distribution.length - 1 ? maxFileSize : i * steps))\n                  + \"]\\t\" + distribution[i]);\n        } else {\n          out.print(((long) i * steps) + \"\\t\" + distribution[i]);\n        }\n\n        out.print(\u0027\\n\u0027);\n      }\n    }\n    out.print(\"totalFiles \u003d \" + totalFiles + \"\\n\");\n    out.print(\"totalDirectories \u003d \" + totalDirectories + \"\\n\");\n    out.print(\"totalBlocks \u003d \" + totalBlocks + \"\\n\");\n    out.print(\"totalSpace \u003d \" + totalSpace + \"\\n\");\n    out.print(\"maxFileSize \u003d \" + maxFileSize + \"\\n\");\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/FileDistributionCalculator.java",
      "extendedDetails": {}
    },
    "a2edb11b68ae01a44092cb14ac2717a6aad93305": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-5698. Use protobuf to serialize / deserialize FSImage. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1566359 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/02/14 11:18 AM",
      "commitName": "a2edb11b68ae01a44092cb14ac2717a6aad93305",
      "commitAuthor": "Jing Zhao",
      "diff": "@@ -0,0 +1,15 @@\n+  private void output() {\n+    // write the distribution into the output file\n+    out.print(\"Size\\tNumFiles\\n\");\n+    for (int i \u003d 0; i \u003c distribution.length; i++) {\n+      if (distribution[i] !\u003d 0) {\n+        out.print(((long) i * steps) + \"\\t\" + distribution[i]);\n+        out.print(\u0027\\n\u0027);\n+      }\n+    }\n+    out.print(\"totalFiles \u003d \" + totalFiles + \"\\n\");\n+    out.print(\"totalDirectories \u003d \" + totalDirectories + \"\\n\");\n+    out.print(\"totalBlocks \u003d \" + totalBlocks + \"\\n\");\n+    out.print(\"totalSpace \u003d \" + totalSpace + \"\\n\");\n+    out.print(\"maxFileSize \u003d \" + maxFileSize + \"\\n\");\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void output() {\n    // write the distribution into the output file\n    out.print(\"Size\\tNumFiles\\n\");\n    for (int i \u003d 0; i \u003c distribution.length; i++) {\n      if (distribution[i] !\u003d 0) {\n        out.print(((long) i * steps) + \"\\t\" + distribution[i]);\n        out.print(\u0027\\n\u0027);\n      }\n    }\n    out.print(\"totalFiles \u003d \" + totalFiles + \"\\n\");\n    out.print(\"totalDirectories \u003d \" + totalDirectories + \"\\n\");\n    out.print(\"totalBlocks \u003d \" + totalBlocks + \"\\n\");\n    out.print(\"totalSpace \u003d \" + totalSpace + \"\\n\");\n    out.print(\"maxFileSize \u003d \" + maxFileSize + \"\\n\");\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/FileDistributionCalculator.java"
    }
  }
}