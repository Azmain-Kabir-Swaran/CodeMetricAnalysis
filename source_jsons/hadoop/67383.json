{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "HadoopLogsAnalyzer.java",
  "functionName": "processReduceAttemptLine",
  "functionId": "processReduceAttemptLine___line-ParsedLine",
  "sourceFilePath": "hadoop-tools/hadoop-rumen/src/main/java/org/apache/hadoop/tools/rumen/HadoopLogsAnalyzer.java",
  "functionStartLine": 1381,
  "functionEndLine": 1528,
  "numCommitsSeen": 13,
  "timeTaken": 4718,
  "changeHistory": [
    "10325d97329c214bb3899c8535df5a366bc86d2f",
    "264d3b7dd0c81fe02baaa09b6e3aaad5ee6d191a",
    "9db078212f5a37154925cc8872f9adaeca0ed371",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "10325d97329c214bb3899c8535df5a366bc86d2f": "Yfilerename",
    "264d3b7dd0c81fe02baaa09b6e3aaad5ee6d191a": "Ybodychange",
    "9db078212f5a37154925cc8872f9adaeca0ed371": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "10325d97329c214bb3899c8535df5a366bc86d2f": {
      "type": "Yfilerename",
      "commitMessage": "MAPREDUCE-3582. Move successfully passing MR1 tests to MR2 maven tree.(ahmed via tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1233090 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/01/12 2:10 PM",
      "commitName": "10325d97329c214bb3899c8535df5a366bc86d2f",
      "commitAuthor": "Alejandro Abdelnur",
      "commitDateOld": "18/01/12 10:20 AM",
      "commitNameOld": "8b2f6909ec7df5cffb5ef417f5c9cffdee43e38a",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.16,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private void processReduceAttemptLine(ParsedLine line) {\n    String attemptID \u003d line.get(\"TASK_ATTEMPT_ID\");\n\n    String taskID \u003d line.get(\"TASKID\");\n\n    String status \u003d line.get(\"TASK_STATUS\");\n\n    String attemptStartTime \u003d line.get(\"START_TIME\");\n    String attemptFinishTime \u003d line.get(\"FINISH_TIME\");\n    String attemptShuffleFinished \u003d line.get(\"SHUFFLE_FINISHED\");\n    String attemptSortFinished \u003d line.get(\"SORT_FINISHED\");\n\n    String counters \u003d line.get(\"COUNTERS\");\n\n    String hostName \u003d line.get(\"HOSTNAME\");\n\n    if (hostName !\u003d null \u0026\u0026 !hostNames.contains(hostName)) {\n      hostNames.add(hostName);\n    }\n\n    if (jobBeingTraced !\u003d null \u0026\u0026 taskID !\u003d null) {\n      LoggedTask task \u003d tasksInCurrentJob.get(taskID);\n\n      if (task \u003d\u003d null) {\n        task \u003d new LoggedTask();\n\n        task.setTaskID(taskID);\n\n        jobBeingTraced.getReduceTasks().add(task);\n\n        tasksInCurrentJob.put(taskID, task);\n      }\n\n      task.setTaskID(taskID);\n\n      LoggedTaskAttempt attempt \u003d attemptsInCurrentJob.get(attemptID);\n\n      boolean attemptAlreadyExists \u003d attempt !\u003d null;\n\n      if (attempt \u003d\u003d null) {\n        attempt \u003d new LoggedTaskAttempt();\n\n        attempt.setAttemptID(attemptID);\n      }\n\n      if (!attemptAlreadyExists) {\n        attemptsInCurrentJob.put(attemptID, attempt);\n        task.getAttempts().add(attempt);\n      }\n\n      Pre21JobHistoryConstants.Values stat \u003d null;\n\n      try {\n        stat \u003d\n            status \u003d\u003d null ? null : Pre21JobHistoryConstants.Values\n                .valueOf(status);\n      } catch (IllegalArgumentException e) {\n        LOG.warn(\"A map attempt status you don\u0027t know about is \\\"\" + status\n            + \"\\\".\", e);\n        stat \u003d null;\n      }\n\n      incorporateCounters(attempt, counters);\n\n      attempt.setResult(stat);\n\n      if (attemptStartTime !\u003d null) {\n        attempt.setStartTime(Long.parseLong(attemptStartTime));\n      }\n\n      if (attemptFinishTime !\u003d null) {\n        attempt.setFinishTime(Long.parseLong(attemptFinishTime));\n      }\n\n      if (attemptShuffleFinished !\u003d null) {\n        attempt.setShuffleFinished(Long.parseLong(attemptShuffleFinished));\n      }\n\n      if (attemptSortFinished !\u003d null) {\n        attempt.setSortFinished(Long.parseLong(attemptSortFinished));\n      }\n\n      if (attempt.getStartTime() \u003e 0 \u0026\u0026 attempt.getFinishTime() \u003e 0) {\n        long runtime \u003d attempt.getFinishTime() - attempt.getStartTime();\n\n        if (stat \u003d\u003d Pre21JobHistoryConstants.Values.SUCCESS) {\n          successfulReduceAttemptTimes.enter(runtime);\n        }\n\n        if (stat \u003d\u003d Pre21JobHistoryConstants.Values.FAILED) {\n          failedReduceAttemptTimes.enter(runtime);\n        }\n      }\n\n      if (hostName !\u003d null) {\n        ParsedHost host \u003d getAndRecordParsedHost(hostName);\n        if (host !\u003d null) {\n          attempt.setHostName(host.getNodeName(), host.getRackName());\n        } else {\n          attempt.setHostName(hostName, null);\n        }\n      }\n\n      if (attemptID !\u003d null) {\n        Matcher matcher \u003d taskAttemptIDPattern.matcher(attemptID);\n\n        if (matcher.matches()) {\n          String attemptNumberString \u003d matcher.group(1);\n\n          if (attemptNumberString !\u003d null) {\n            int attemptNumber \u003d Integer.parseInt(attemptNumberString);\n\n            successfulNthReducerAttempts.enter(attemptNumber);\n          }\n        }\n      }\n    }\n\n    try {\n      if (attemptStartTime !\u003d null) {\n        long startTimeValue \u003d Long.parseLong(attemptStartTime);\n\n        if (startTimeValue !\u003d 0\n            \u0026\u0026 startTimeValue + MAXIMUM_CLOCK_SKEW \u003e\u003d launchTimeCurrentJob) {\n          taskAttemptStartTimes.put(attemptID, startTimeValue);\n        }\n      } else if (status !\u003d null \u0026\u0026 status.equals(\"SUCCESS\")\n          \u0026\u0026 attemptFinishTime !\u003d null) {\n        long finishTime \u003d Long.parseLong(attemptFinishTime);\n\n        taskReduceAttemptFinishTimes.put(attemptID, finishTime);\n\n        if (attemptShuffleFinished !\u003d null) {\n          taskReduceAttemptShuffleEndTimes.put(attemptID, Long\n              .parseLong(attemptShuffleFinished));\n        }\n\n        if (attemptSortFinished !\u003d null) {\n          taskReduceAttemptSortEndTimes.put(attemptID, Long\n              .parseLong(attemptSortFinished));\n        }\n      }\n    } catch (NumberFormatException e) {\n      LOG.error(\n          \"HadoopLogsAnalyzer.processReduceAttemptLine: bad numerical format, at line\"\n              + lineNumber + \".\", e);\n    }\n  }",
      "path": "hadoop-tools/hadoop-rumen/src/main/java/org/apache/hadoop/tools/rumen/HadoopLogsAnalyzer.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce-project/src/tools/org/apache/hadoop/tools/rumen/HadoopLogsAnalyzer.java",
        "newPath": "hadoop-tools/hadoop-rumen/src/main/java/org/apache/hadoop/tools/rumen/HadoopLogsAnalyzer.java"
      }
    },
    "264d3b7dd0c81fe02baaa09b6e3aaad5ee6d191a": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3349. Log rack-name in JobHistory for unsuccessful tasks. (Devaraj K and Amar Kamat via amarrk)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1221578 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/12/11 6:58 PM",
      "commitName": "264d3b7dd0c81fe02baaa09b6e3aaad5ee6d191a",
      "commitAuthor": "Amar Kamat",
      "commitDateOld": "16/12/11 6:20 AM",
      "commitNameOld": "a238f931ea7dce0ca620d1798156c84ff77097ff",
      "commitAuthorOld": "Amar Kamat",
      "daysBetweenCommits": 4.53,
      "commitsBetweenForRepo": 21,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,144 +1,148 @@\n   private void processReduceAttemptLine(ParsedLine line) {\n     String attemptID \u003d line.get(\"TASK_ATTEMPT_ID\");\n \n     String taskID \u003d line.get(\"TASKID\");\n \n     String status \u003d line.get(\"TASK_STATUS\");\n \n     String attemptStartTime \u003d line.get(\"START_TIME\");\n     String attemptFinishTime \u003d line.get(\"FINISH_TIME\");\n     String attemptShuffleFinished \u003d line.get(\"SHUFFLE_FINISHED\");\n     String attemptSortFinished \u003d line.get(\"SORT_FINISHED\");\n \n     String counters \u003d line.get(\"COUNTERS\");\n \n     String hostName \u003d line.get(\"HOSTNAME\");\n \n     if (hostName !\u003d null \u0026\u0026 !hostNames.contains(hostName)) {\n       hostNames.add(hostName);\n     }\n \n     if (jobBeingTraced !\u003d null \u0026\u0026 taskID !\u003d null) {\n       LoggedTask task \u003d tasksInCurrentJob.get(taskID);\n \n       if (task \u003d\u003d null) {\n         task \u003d new LoggedTask();\n \n         task.setTaskID(taskID);\n \n         jobBeingTraced.getReduceTasks().add(task);\n \n         tasksInCurrentJob.put(taskID, task);\n       }\n \n       task.setTaskID(taskID);\n \n       LoggedTaskAttempt attempt \u003d attemptsInCurrentJob.get(attemptID);\n \n       boolean attemptAlreadyExists \u003d attempt !\u003d null;\n \n       if (attempt \u003d\u003d null) {\n         attempt \u003d new LoggedTaskAttempt();\n \n         attempt.setAttemptID(attemptID);\n       }\n \n       if (!attemptAlreadyExists) {\n         attemptsInCurrentJob.put(attemptID, attempt);\n         task.getAttempts().add(attempt);\n       }\n \n       Pre21JobHistoryConstants.Values stat \u003d null;\n \n       try {\n         stat \u003d\n             status \u003d\u003d null ? null : Pre21JobHistoryConstants.Values\n                 .valueOf(status);\n       } catch (IllegalArgumentException e) {\n         LOG.warn(\"A map attempt status you don\u0027t know about is \\\"\" + status\n             + \"\\\".\", e);\n         stat \u003d null;\n       }\n \n       incorporateCounters(attempt, counters);\n \n       attempt.setResult(stat);\n \n       if (attemptStartTime !\u003d null) {\n         attempt.setStartTime(Long.parseLong(attemptStartTime));\n       }\n \n       if (attemptFinishTime !\u003d null) {\n         attempt.setFinishTime(Long.parseLong(attemptFinishTime));\n       }\n \n       if (attemptShuffleFinished !\u003d null) {\n         attempt.setShuffleFinished(Long.parseLong(attemptShuffleFinished));\n       }\n \n       if (attemptSortFinished !\u003d null) {\n         attempt.setSortFinished(Long.parseLong(attemptSortFinished));\n       }\n \n       if (attempt.getStartTime() \u003e 0 \u0026\u0026 attempt.getFinishTime() \u003e 0) {\n         long runtime \u003d attempt.getFinishTime() - attempt.getStartTime();\n \n         if (stat \u003d\u003d Pre21JobHistoryConstants.Values.SUCCESS) {\n           successfulReduceAttemptTimes.enter(runtime);\n         }\n \n         if (stat \u003d\u003d Pre21JobHistoryConstants.Values.FAILED) {\n           failedReduceAttemptTimes.enter(runtime);\n         }\n       }\n \n-      ParsedHost host \u003d getAndRecordParsedHost(hostName);\n-      if (host !\u003d null) {\n-        attempt.setHostName(host.getNodeName(), host.getRackName());\n+      if (hostName !\u003d null) {\n+        ParsedHost host \u003d getAndRecordParsedHost(hostName);\n+        if (host !\u003d null) {\n+          attempt.setHostName(host.getNodeName(), host.getRackName());\n+        } else {\n+          attempt.setHostName(hostName, null);\n+        }\n       }\n \n       if (attemptID !\u003d null) {\n         Matcher matcher \u003d taskAttemptIDPattern.matcher(attemptID);\n \n         if (matcher.matches()) {\n           String attemptNumberString \u003d matcher.group(1);\n \n           if (attemptNumberString !\u003d null) {\n             int attemptNumber \u003d Integer.parseInt(attemptNumberString);\n \n             successfulNthReducerAttempts.enter(attemptNumber);\n           }\n         }\n       }\n     }\n \n     try {\n       if (attemptStartTime !\u003d null) {\n         long startTimeValue \u003d Long.parseLong(attemptStartTime);\n \n         if (startTimeValue !\u003d 0\n             \u0026\u0026 startTimeValue + MAXIMUM_CLOCK_SKEW \u003e\u003d launchTimeCurrentJob) {\n           taskAttemptStartTimes.put(attemptID, startTimeValue);\n         }\n       } else if (status !\u003d null \u0026\u0026 status.equals(\"SUCCESS\")\n           \u0026\u0026 attemptFinishTime !\u003d null) {\n         long finishTime \u003d Long.parseLong(attemptFinishTime);\n \n         taskReduceAttemptFinishTimes.put(attemptID, finishTime);\n \n         if (attemptShuffleFinished !\u003d null) {\n           taskReduceAttemptShuffleEndTimes.put(attemptID, Long\n               .parseLong(attemptShuffleFinished));\n         }\n \n         if (attemptSortFinished !\u003d null) {\n           taskReduceAttemptSortEndTimes.put(attemptID, Long\n               .parseLong(attemptSortFinished));\n         }\n       }\n     } catch (NumberFormatException e) {\n       LOG.error(\n           \"HadoopLogsAnalyzer.processReduceAttemptLine: bad numerical format, at line\"\n               + lineNumber + \".\", e);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void processReduceAttemptLine(ParsedLine line) {\n    String attemptID \u003d line.get(\"TASK_ATTEMPT_ID\");\n\n    String taskID \u003d line.get(\"TASKID\");\n\n    String status \u003d line.get(\"TASK_STATUS\");\n\n    String attemptStartTime \u003d line.get(\"START_TIME\");\n    String attemptFinishTime \u003d line.get(\"FINISH_TIME\");\n    String attemptShuffleFinished \u003d line.get(\"SHUFFLE_FINISHED\");\n    String attemptSortFinished \u003d line.get(\"SORT_FINISHED\");\n\n    String counters \u003d line.get(\"COUNTERS\");\n\n    String hostName \u003d line.get(\"HOSTNAME\");\n\n    if (hostName !\u003d null \u0026\u0026 !hostNames.contains(hostName)) {\n      hostNames.add(hostName);\n    }\n\n    if (jobBeingTraced !\u003d null \u0026\u0026 taskID !\u003d null) {\n      LoggedTask task \u003d tasksInCurrentJob.get(taskID);\n\n      if (task \u003d\u003d null) {\n        task \u003d new LoggedTask();\n\n        task.setTaskID(taskID);\n\n        jobBeingTraced.getReduceTasks().add(task);\n\n        tasksInCurrentJob.put(taskID, task);\n      }\n\n      task.setTaskID(taskID);\n\n      LoggedTaskAttempt attempt \u003d attemptsInCurrentJob.get(attemptID);\n\n      boolean attemptAlreadyExists \u003d attempt !\u003d null;\n\n      if (attempt \u003d\u003d null) {\n        attempt \u003d new LoggedTaskAttempt();\n\n        attempt.setAttemptID(attemptID);\n      }\n\n      if (!attemptAlreadyExists) {\n        attemptsInCurrentJob.put(attemptID, attempt);\n        task.getAttempts().add(attempt);\n      }\n\n      Pre21JobHistoryConstants.Values stat \u003d null;\n\n      try {\n        stat \u003d\n            status \u003d\u003d null ? null : Pre21JobHistoryConstants.Values\n                .valueOf(status);\n      } catch (IllegalArgumentException e) {\n        LOG.warn(\"A map attempt status you don\u0027t know about is \\\"\" + status\n            + \"\\\".\", e);\n        stat \u003d null;\n      }\n\n      incorporateCounters(attempt, counters);\n\n      attempt.setResult(stat);\n\n      if (attemptStartTime !\u003d null) {\n        attempt.setStartTime(Long.parseLong(attemptStartTime));\n      }\n\n      if (attemptFinishTime !\u003d null) {\n        attempt.setFinishTime(Long.parseLong(attemptFinishTime));\n      }\n\n      if (attemptShuffleFinished !\u003d null) {\n        attempt.setShuffleFinished(Long.parseLong(attemptShuffleFinished));\n      }\n\n      if (attemptSortFinished !\u003d null) {\n        attempt.setSortFinished(Long.parseLong(attemptSortFinished));\n      }\n\n      if (attempt.getStartTime() \u003e 0 \u0026\u0026 attempt.getFinishTime() \u003e 0) {\n        long runtime \u003d attempt.getFinishTime() - attempt.getStartTime();\n\n        if (stat \u003d\u003d Pre21JobHistoryConstants.Values.SUCCESS) {\n          successfulReduceAttemptTimes.enter(runtime);\n        }\n\n        if (stat \u003d\u003d Pre21JobHistoryConstants.Values.FAILED) {\n          failedReduceAttemptTimes.enter(runtime);\n        }\n      }\n\n      if (hostName !\u003d null) {\n        ParsedHost host \u003d getAndRecordParsedHost(hostName);\n        if (host !\u003d null) {\n          attempt.setHostName(host.getNodeName(), host.getRackName());\n        } else {\n          attempt.setHostName(hostName, null);\n        }\n      }\n\n      if (attemptID !\u003d null) {\n        Matcher matcher \u003d taskAttemptIDPattern.matcher(attemptID);\n\n        if (matcher.matches()) {\n          String attemptNumberString \u003d matcher.group(1);\n\n          if (attemptNumberString !\u003d null) {\n            int attemptNumber \u003d Integer.parseInt(attemptNumberString);\n\n            successfulNthReducerAttempts.enter(attemptNumber);\n          }\n        }\n      }\n    }\n\n    try {\n      if (attemptStartTime !\u003d null) {\n        long startTimeValue \u003d Long.parseLong(attemptStartTime);\n\n        if (startTimeValue !\u003d 0\n            \u0026\u0026 startTimeValue + MAXIMUM_CLOCK_SKEW \u003e\u003d launchTimeCurrentJob) {\n          taskAttemptStartTimes.put(attemptID, startTimeValue);\n        }\n      } else if (status !\u003d null \u0026\u0026 status.equals(\"SUCCESS\")\n          \u0026\u0026 attemptFinishTime !\u003d null) {\n        long finishTime \u003d Long.parseLong(attemptFinishTime);\n\n        taskReduceAttemptFinishTimes.put(attemptID, finishTime);\n\n        if (attemptShuffleFinished !\u003d null) {\n          taskReduceAttemptShuffleEndTimes.put(attemptID, Long\n              .parseLong(attemptShuffleFinished));\n        }\n\n        if (attemptSortFinished !\u003d null) {\n          taskReduceAttemptSortEndTimes.put(attemptID, Long\n              .parseLong(attemptSortFinished));\n        }\n      }\n    } catch (NumberFormatException e) {\n      LOG.error(\n          \"HadoopLogsAnalyzer.processReduceAttemptLine: bad numerical format, at line\"\n              + lineNumber + \".\", e);\n    }\n  }",
      "path": "hadoop-mapreduce-project/src/tools/org/apache/hadoop/tools/rumen/HadoopLogsAnalyzer.java",
      "extendedDetails": {}
    },
    "9db078212f5a37154925cc8872f9adaeca0ed371": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3035. Fixed MR JobHistory to ensure rack information is present. Contributed by chakravarthy.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1195575 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "31/10/11 10:27 AM",
      "commitName": "9db078212f5a37154925cc8872f9adaeca0ed371",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:14 PM",
      "commitNameOld": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 67.72,
      "commitsBetweenForRepo": 508,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,142 +1,144 @@\n   private void processReduceAttemptLine(ParsedLine line) {\n     String attemptID \u003d line.get(\"TASK_ATTEMPT_ID\");\n \n     String taskID \u003d line.get(\"TASKID\");\n \n     String status \u003d line.get(\"TASK_STATUS\");\n \n     String attemptStartTime \u003d line.get(\"START_TIME\");\n     String attemptFinishTime \u003d line.get(\"FINISH_TIME\");\n     String attemptShuffleFinished \u003d line.get(\"SHUFFLE_FINISHED\");\n     String attemptSortFinished \u003d line.get(\"SORT_FINISHED\");\n \n     String counters \u003d line.get(\"COUNTERS\");\n \n     String hostName \u003d line.get(\"HOSTNAME\");\n \n     if (hostName !\u003d null \u0026\u0026 !hostNames.contains(hostName)) {\n       hostNames.add(hostName);\n     }\n \n     if (jobBeingTraced !\u003d null \u0026\u0026 taskID !\u003d null) {\n       LoggedTask task \u003d tasksInCurrentJob.get(taskID);\n \n       if (task \u003d\u003d null) {\n         task \u003d new LoggedTask();\n \n         task.setTaskID(taskID);\n \n         jobBeingTraced.getReduceTasks().add(task);\n \n         tasksInCurrentJob.put(taskID, task);\n       }\n \n       task.setTaskID(taskID);\n \n       LoggedTaskAttempt attempt \u003d attemptsInCurrentJob.get(attemptID);\n \n       boolean attemptAlreadyExists \u003d attempt !\u003d null;\n \n       if (attempt \u003d\u003d null) {\n         attempt \u003d new LoggedTaskAttempt();\n \n         attempt.setAttemptID(attemptID);\n       }\n \n       if (!attemptAlreadyExists) {\n         attemptsInCurrentJob.put(attemptID, attempt);\n         task.getAttempts().add(attempt);\n       }\n \n       Pre21JobHistoryConstants.Values stat \u003d null;\n \n       try {\n         stat \u003d\n             status \u003d\u003d null ? null : Pre21JobHistoryConstants.Values\n                 .valueOf(status);\n       } catch (IllegalArgumentException e) {\n         LOG.warn(\"A map attempt status you don\u0027t know about is \\\"\" + status\n             + \"\\\".\", e);\n         stat \u003d null;\n       }\n \n       incorporateCounters(attempt, counters);\n \n       attempt.setResult(stat);\n \n       if (attemptStartTime !\u003d null) {\n         attempt.setStartTime(Long.parseLong(attemptStartTime));\n       }\n \n       if (attemptFinishTime !\u003d null) {\n         attempt.setFinishTime(Long.parseLong(attemptFinishTime));\n       }\n \n       if (attemptShuffleFinished !\u003d null) {\n         attempt.setShuffleFinished(Long.parseLong(attemptShuffleFinished));\n       }\n \n       if (attemptSortFinished !\u003d null) {\n         attempt.setSortFinished(Long.parseLong(attemptSortFinished));\n       }\n \n       if (attempt.getStartTime() \u003e 0 \u0026\u0026 attempt.getFinishTime() \u003e 0) {\n         long runtime \u003d attempt.getFinishTime() - attempt.getStartTime();\n \n         if (stat \u003d\u003d Pre21JobHistoryConstants.Values.SUCCESS) {\n           successfulReduceAttemptTimes.enter(runtime);\n         }\n \n         if (stat \u003d\u003d Pre21JobHistoryConstants.Values.FAILED) {\n           failedReduceAttemptTimes.enter(runtime);\n         }\n       }\n-      if (hostName !\u003d null) {\n-        attempt.setHostName(hostName);\n+\n+      ParsedHost host \u003d getAndRecordParsedHost(hostName);\n+      if (host !\u003d null) {\n+        attempt.setHostName(host.getNodeName(), host.getRackName());\n       }\n \n       if (attemptID !\u003d null) {\n         Matcher matcher \u003d taskAttemptIDPattern.matcher(attemptID);\n \n         if (matcher.matches()) {\n           String attemptNumberString \u003d matcher.group(1);\n \n           if (attemptNumberString !\u003d null) {\n             int attemptNumber \u003d Integer.parseInt(attemptNumberString);\n \n             successfulNthReducerAttempts.enter(attemptNumber);\n           }\n         }\n       }\n     }\n \n     try {\n       if (attemptStartTime !\u003d null) {\n         long startTimeValue \u003d Long.parseLong(attemptStartTime);\n \n         if (startTimeValue !\u003d 0\n             \u0026\u0026 startTimeValue + MAXIMUM_CLOCK_SKEW \u003e\u003d launchTimeCurrentJob) {\n           taskAttemptStartTimes.put(attemptID, startTimeValue);\n         }\n       } else if (status !\u003d null \u0026\u0026 status.equals(\"SUCCESS\")\n           \u0026\u0026 attemptFinishTime !\u003d null) {\n         long finishTime \u003d Long.parseLong(attemptFinishTime);\n \n         taskReduceAttemptFinishTimes.put(attemptID, finishTime);\n \n         if (attemptShuffleFinished !\u003d null) {\n           taskReduceAttemptShuffleEndTimes.put(attemptID, Long\n               .parseLong(attemptShuffleFinished));\n         }\n \n         if (attemptSortFinished !\u003d null) {\n           taskReduceAttemptSortEndTimes.put(attemptID, Long\n               .parseLong(attemptSortFinished));\n         }\n       }\n     } catch (NumberFormatException e) {\n       LOG.error(\n           \"HadoopLogsAnalyzer.processReduceAttemptLine: bad numerical format, at line\"\n               + lineNumber + \".\", e);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void processReduceAttemptLine(ParsedLine line) {\n    String attemptID \u003d line.get(\"TASK_ATTEMPT_ID\");\n\n    String taskID \u003d line.get(\"TASKID\");\n\n    String status \u003d line.get(\"TASK_STATUS\");\n\n    String attemptStartTime \u003d line.get(\"START_TIME\");\n    String attemptFinishTime \u003d line.get(\"FINISH_TIME\");\n    String attemptShuffleFinished \u003d line.get(\"SHUFFLE_FINISHED\");\n    String attemptSortFinished \u003d line.get(\"SORT_FINISHED\");\n\n    String counters \u003d line.get(\"COUNTERS\");\n\n    String hostName \u003d line.get(\"HOSTNAME\");\n\n    if (hostName !\u003d null \u0026\u0026 !hostNames.contains(hostName)) {\n      hostNames.add(hostName);\n    }\n\n    if (jobBeingTraced !\u003d null \u0026\u0026 taskID !\u003d null) {\n      LoggedTask task \u003d tasksInCurrentJob.get(taskID);\n\n      if (task \u003d\u003d null) {\n        task \u003d new LoggedTask();\n\n        task.setTaskID(taskID);\n\n        jobBeingTraced.getReduceTasks().add(task);\n\n        tasksInCurrentJob.put(taskID, task);\n      }\n\n      task.setTaskID(taskID);\n\n      LoggedTaskAttempt attempt \u003d attemptsInCurrentJob.get(attemptID);\n\n      boolean attemptAlreadyExists \u003d attempt !\u003d null;\n\n      if (attempt \u003d\u003d null) {\n        attempt \u003d new LoggedTaskAttempt();\n\n        attempt.setAttemptID(attemptID);\n      }\n\n      if (!attemptAlreadyExists) {\n        attemptsInCurrentJob.put(attemptID, attempt);\n        task.getAttempts().add(attempt);\n      }\n\n      Pre21JobHistoryConstants.Values stat \u003d null;\n\n      try {\n        stat \u003d\n            status \u003d\u003d null ? null : Pre21JobHistoryConstants.Values\n                .valueOf(status);\n      } catch (IllegalArgumentException e) {\n        LOG.warn(\"A map attempt status you don\u0027t know about is \\\"\" + status\n            + \"\\\".\", e);\n        stat \u003d null;\n      }\n\n      incorporateCounters(attempt, counters);\n\n      attempt.setResult(stat);\n\n      if (attemptStartTime !\u003d null) {\n        attempt.setStartTime(Long.parseLong(attemptStartTime));\n      }\n\n      if (attemptFinishTime !\u003d null) {\n        attempt.setFinishTime(Long.parseLong(attemptFinishTime));\n      }\n\n      if (attemptShuffleFinished !\u003d null) {\n        attempt.setShuffleFinished(Long.parseLong(attemptShuffleFinished));\n      }\n\n      if (attemptSortFinished !\u003d null) {\n        attempt.setSortFinished(Long.parseLong(attemptSortFinished));\n      }\n\n      if (attempt.getStartTime() \u003e 0 \u0026\u0026 attempt.getFinishTime() \u003e 0) {\n        long runtime \u003d attempt.getFinishTime() - attempt.getStartTime();\n\n        if (stat \u003d\u003d Pre21JobHistoryConstants.Values.SUCCESS) {\n          successfulReduceAttemptTimes.enter(runtime);\n        }\n\n        if (stat \u003d\u003d Pre21JobHistoryConstants.Values.FAILED) {\n          failedReduceAttemptTimes.enter(runtime);\n        }\n      }\n\n      ParsedHost host \u003d getAndRecordParsedHost(hostName);\n      if (host !\u003d null) {\n        attempt.setHostName(host.getNodeName(), host.getRackName());\n      }\n\n      if (attemptID !\u003d null) {\n        Matcher matcher \u003d taskAttemptIDPattern.matcher(attemptID);\n\n        if (matcher.matches()) {\n          String attemptNumberString \u003d matcher.group(1);\n\n          if (attemptNumberString !\u003d null) {\n            int attemptNumber \u003d Integer.parseInt(attemptNumberString);\n\n            successfulNthReducerAttempts.enter(attemptNumber);\n          }\n        }\n      }\n    }\n\n    try {\n      if (attemptStartTime !\u003d null) {\n        long startTimeValue \u003d Long.parseLong(attemptStartTime);\n\n        if (startTimeValue !\u003d 0\n            \u0026\u0026 startTimeValue + MAXIMUM_CLOCK_SKEW \u003e\u003d launchTimeCurrentJob) {\n          taskAttemptStartTimes.put(attemptID, startTimeValue);\n        }\n      } else if (status !\u003d null \u0026\u0026 status.equals(\"SUCCESS\")\n          \u0026\u0026 attemptFinishTime !\u003d null) {\n        long finishTime \u003d Long.parseLong(attemptFinishTime);\n\n        taskReduceAttemptFinishTimes.put(attemptID, finishTime);\n\n        if (attemptShuffleFinished !\u003d null) {\n          taskReduceAttemptShuffleEndTimes.put(attemptID, Long\n              .parseLong(attemptShuffleFinished));\n        }\n\n        if (attemptSortFinished !\u003d null) {\n          taskReduceAttemptSortEndTimes.put(attemptID, Long\n              .parseLong(attemptSortFinished));\n        }\n      }\n    } catch (NumberFormatException e) {\n      LOG.error(\n          \"HadoopLogsAnalyzer.processReduceAttemptLine: bad numerical format, at line\"\n              + lineNumber + \".\", e);\n    }\n  }",
      "path": "hadoop-mapreduce-project/src/tools/org/apache/hadoop/tools/rumen/HadoopLogsAnalyzer.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private void processReduceAttemptLine(ParsedLine line) {\n    String attemptID \u003d line.get(\"TASK_ATTEMPT_ID\");\n\n    String taskID \u003d line.get(\"TASKID\");\n\n    String status \u003d line.get(\"TASK_STATUS\");\n\n    String attemptStartTime \u003d line.get(\"START_TIME\");\n    String attemptFinishTime \u003d line.get(\"FINISH_TIME\");\n    String attemptShuffleFinished \u003d line.get(\"SHUFFLE_FINISHED\");\n    String attemptSortFinished \u003d line.get(\"SORT_FINISHED\");\n\n    String counters \u003d line.get(\"COUNTERS\");\n\n    String hostName \u003d line.get(\"HOSTNAME\");\n\n    if (hostName !\u003d null \u0026\u0026 !hostNames.contains(hostName)) {\n      hostNames.add(hostName);\n    }\n\n    if (jobBeingTraced !\u003d null \u0026\u0026 taskID !\u003d null) {\n      LoggedTask task \u003d tasksInCurrentJob.get(taskID);\n\n      if (task \u003d\u003d null) {\n        task \u003d new LoggedTask();\n\n        task.setTaskID(taskID);\n\n        jobBeingTraced.getReduceTasks().add(task);\n\n        tasksInCurrentJob.put(taskID, task);\n      }\n\n      task.setTaskID(taskID);\n\n      LoggedTaskAttempt attempt \u003d attemptsInCurrentJob.get(attemptID);\n\n      boolean attemptAlreadyExists \u003d attempt !\u003d null;\n\n      if (attempt \u003d\u003d null) {\n        attempt \u003d new LoggedTaskAttempt();\n\n        attempt.setAttemptID(attemptID);\n      }\n\n      if (!attemptAlreadyExists) {\n        attemptsInCurrentJob.put(attemptID, attempt);\n        task.getAttempts().add(attempt);\n      }\n\n      Pre21JobHistoryConstants.Values stat \u003d null;\n\n      try {\n        stat \u003d\n            status \u003d\u003d null ? null : Pre21JobHistoryConstants.Values\n                .valueOf(status);\n      } catch (IllegalArgumentException e) {\n        LOG.warn(\"A map attempt status you don\u0027t know about is \\\"\" + status\n            + \"\\\".\", e);\n        stat \u003d null;\n      }\n\n      incorporateCounters(attempt, counters);\n\n      attempt.setResult(stat);\n\n      if (attemptStartTime !\u003d null) {\n        attempt.setStartTime(Long.parseLong(attemptStartTime));\n      }\n\n      if (attemptFinishTime !\u003d null) {\n        attempt.setFinishTime(Long.parseLong(attemptFinishTime));\n      }\n\n      if (attemptShuffleFinished !\u003d null) {\n        attempt.setShuffleFinished(Long.parseLong(attemptShuffleFinished));\n      }\n\n      if (attemptSortFinished !\u003d null) {\n        attempt.setSortFinished(Long.parseLong(attemptSortFinished));\n      }\n\n      if (attempt.getStartTime() \u003e 0 \u0026\u0026 attempt.getFinishTime() \u003e 0) {\n        long runtime \u003d attempt.getFinishTime() - attempt.getStartTime();\n\n        if (stat \u003d\u003d Pre21JobHistoryConstants.Values.SUCCESS) {\n          successfulReduceAttemptTimes.enter(runtime);\n        }\n\n        if (stat \u003d\u003d Pre21JobHistoryConstants.Values.FAILED) {\n          failedReduceAttemptTimes.enter(runtime);\n        }\n      }\n      if (hostName !\u003d null) {\n        attempt.setHostName(hostName);\n      }\n\n      if (attemptID !\u003d null) {\n        Matcher matcher \u003d taskAttemptIDPattern.matcher(attemptID);\n\n        if (matcher.matches()) {\n          String attemptNumberString \u003d matcher.group(1);\n\n          if (attemptNumberString !\u003d null) {\n            int attemptNumber \u003d Integer.parseInt(attemptNumberString);\n\n            successfulNthReducerAttempts.enter(attemptNumber);\n          }\n        }\n      }\n    }\n\n    try {\n      if (attemptStartTime !\u003d null) {\n        long startTimeValue \u003d Long.parseLong(attemptStartTime);\n\n        if (startTimeValue !\u003d 0\n            \u0026\u0026 startTimeValue + MAXIMUM_CLOCK_SKEW \u003e\u003d launchTimeCurrentJob) {\n          taskAttemptStartTimes.put(attemptID, startTimeValue);\n        }\n      } else if (status !\u003d null \u0026\u0026 status.equals(\"SUCCESS\")\n          \u0026\u0026 attemptFinishTime !\u003d null) {\n        long finishTime \u003d Long.parseLong(attemptFinishTime);\n\n        taskReduceAttemptFinishTimes.put(attemptID, finishTime);\n\n        if (attemptShuffleFinished !\u003d null) {\n          taskReduceAttemptShuffleEndTimes.put(attemptID, Long\n              .parseLong(attemptShuffleFinished));\n        }\n\n        if (attemptSortFinished !\u003d null) {\n          taskReduceAttemptSortEndTimes.put(attemptID, Long\n              .parseLong(attemptSortFinished));\n        }\n      }\n    } catch (NumberFormatException e) {\n      LOG.error(\n          \"HadoopLogsAnalyzer.processReduceAttemptLine: bad numerical format, at line\"\n              + lineNumber + \".\", e);\n    }\n  }",
      "path": "hadoop-mapreduce-project/src/tools/org/apache/hadoop/tools/rumen/HadoopLogsAnalyzer.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/src/tools/org/apache/hadoop/tools/rumen/HadoopLogsAnalyzer.java",
        "newPath": "hadoop-mapreduce-project/src/tools/org/apache/hadoop/tools/rumen/HadoopLogsAnalyzer.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yfilerename",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "17/08/11 8:02 PM",
      "commitNameOld": "dd86860633d2ed64705b669a75bf318442ed6225",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 0.34,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private void processReduceAttemptLine(ParsedLine line) {\n    String attemptID \u003d line.get(\"TASK_ATTEMPT_ID\");\n\n    String taskID \u003d line.get(\"TASKID\");\n\n    String status \u003d line.get(\"TASK_STATUS\");\n\n    String attemptStartTime \u003d line.get(\"START_TIME\");\n    String attemptFinishTime \u003d line.get(\"FINISH_TIME\");\n    String attemptShuffleFinished \u003d line.get(\"SHUFFLE_FINISHED\");\n    String attemptSortFinished \u003d line.get(\"SORT_FINISHED\");\n\n    String counters \u003d line.get(\"COUNTERS\");\n\n    String hostName \u003d line.get(\"HOSTNAME\");\n\n    if (hostName !\u003d null \u0026\u0026 !hostNames.contains(hostName)) {\n      hostNames.add(hostName);\n    }\n\n    if (jobBeingTraced !\u003d null \u0026\u0026 taskID !\u003d null) {\n      LoggedTask task \u003d tasksInCurrentJob.get(taskID);\n\n      if (task \u003d\u003d null) {\n        task \u003d new LoggedTask();\n\n        task.setTaskID(taskID);\n\n        jobBeingTraced.getReduceTasks().add(task);\n\n        tasksInCurrentJob.put(taskID, task);\n      }\n\n      task.setTaskID(taskID);\n\n      LoggedTaskAttempt attempt \u003d attemptsInCurrentJob.get(attemptID);\n\n      boolean attemptAlreadyExists \u003d attempt !\u003d null;\n\n      if (attempt \u003d\u003d null) {\n        attempt \u003d new LoggedTaskAttempt();\n\n        attempt.setAttemptID(attemptID);\n      }\n\n      if (!attemptAlreadyExists) {\n        attemptsInCurrentJob.put(attemptID, attempt);\n        task.getAttempts().add(attempt);\n      }\n\n      Pre21JobHistoryConstants.Values stat \u003d null;\n\n      try {\n        stat \u003d\n            status \u003d\u003d null ? null : Pre21JobHistoryConstants.Values\n                .valueOf(status);\n      } catch (IllegalArgumentException e) {\n        LOG.warn(\"A map attempt status you don\u0027t know about is \\\"\" + status\n            + \"\\\".\", e);\n        stat \u003d null;\n      }\n\n      incorporateCounters(attempt, counters);\n\n      attempt.setResult(stat);\n\n      if (attemptStartTime !\u003d null) {\n        attempt.setStartTime(Long.parseLong(attemptStartTime));\n      }\n\n      if (attemptFinishTime !\u003d null) {\n        attempt.setFinishTime(Long.parseLong(attemptFinishTime));\n      }\n\n      if (attemptShuffleFinished !\u003d null) {\n        attempt.setShuffleFinished(Long.parseLong(attemptShuffleFinished));\n      }\n\n      if (attemptSortFinished !\u003d null) {\n        attempt.setSortFinished(Long.parseLong(attemptSortFinished));\n      }\n\n      if (attempt.getStartTime() \u003e 0 \u0026\u0026 attempt.getFinishTime() \u003e 0) {\n        long runtime \u003d attempt.getFinishTime() - attempt.getStartTime();\n\n        if (stat \u003d\u003d Pre21JobHistoryConstants.Values.SUCCESS) {\n          successfulReduceAttemptTimes.enter(runtime);\n        }\n\n        if (stat \u003d\u003d Pre21JobHistoryConstants.Values.FAILED) {\n          failedReduceAttemptTimes.enter(runtime);\n        }\n      }\n      if (hostName !\u003d null) {\n        attempt.setHostName(hostName);\n      }\n\n      if (attemptID !\u003d null) {\n        Matcher matcher \u003d taskAttemptIDPattern.matcher(attemptID);\n\n        if (matcher.matches()) {\n          String attemptNumberString \u003d matcher.group(1);\n\n          if (attemptNumberString !\u003d null) {\n            int attemptNumber \u003d Integer.parseInt(attemptNumberString);\n\n            successfulNthReducerAttempts.enter(attemptNumber);\n          }\n        }\n      }\n    }\n\n    try {\n      if (attemptStartTime !\u003d null) {\n        long startTimeValue \u003d Long.parseLong(attemptStartTime);\n\n        if (startTimeValue !\u003d 0\n            \u0026\u0026 startTimeValue + MAXIMUM_CLOCK_SKEW \u003e\u003d launchTimeCurrentJob) {\n          taskAttemptStartTimes.put(attemptID, startTimeValue);\n        }\n      } else if (status !\u003d null \u0026\u0026 status.equals(\"SUCCESS\")\n          \u0026\u0026 attemptFinishTime !\u003d null) {\n        long finishTime \u003d Long.parseLong(attemptFinishTime);\n\n        taskReduceAttemptFinishTimes.put(attemptID, finishTime);\n\n        if (attemptShuffleFinished !\u003d null) {\n          taskReduceAttemptShuffleEndTimes.put(attemptID, Long\n              .parseLong(attemptShuffleFinished));\n        }\n\n        if (attemptSortFinished !\u003d null) {\n          taskReduceAttemptSortEndTimes.put(attemptID, Long\n              .parseLong(attemptSortFinished));\n        }\n      }\n    } catch (NumberFormatException e) {\n      LOG.error(\n          \"HadoopLogsAnalyzer.processReduceAttemptLine: bad numerical format, at line\"\n              + lineNumber + \".\", e);\n    }\n  }",
      "path": "hadoop-mapreduce/src/tools/org/apache/hadoop/tools/rumen/HadoopLogsAnalyzer.java",
      "extendedDetails": {
        "oldPath": "mapreduce/src/tools/org/apache/hadoop/tools/rumen/HadoopLogsAnalyzer.java",
        "newPath": "hadoop-mapreduce/src/tools/org/apache/hadoop/tools/rumen/HadoopLogsAnalyzer.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,142 @@\n+  private void processReduceAttemptLine(ParsedLine line) {\n+    String attemptID \u003d line.get(\"TASK_ATTEMPT_ID\");\n+\n+    String taskID \u003d line.get(\"TASKID\");\n+\n+    String status \u003d line.get(\"TASK_STATUS\");\n+\n+    String attemptStartTime \u003d line.get(\"START_TIME\");\n+    String attemptFinishTime \u003d line.get(\"FINISH_TIME\");\n+    String attemptShuffleFinished \u003d line.get(\"SHUFFLE_FINISHED\");\n+    String attemptSortFinished \u003d line.get(\"SORT_FINISHED\");\n+\n+    String counters \u003d line.get(\"COUNTERS\");\n+\n+    String hostName \u003d line.get(\"HOSTNAME\");\n+\n+    if (hostName !\u003d null \u0026\u0026 !hostNames.contains(hostName)) {\n+      hostNames.add(hostName);\n+    }\n+\n+    if (jobBeingTraced !\u003d null \u0026\u0026 taskID !\u003d null) {\n+      LoggedTask task \u003d tasksInCurrentJob.get(taskID);\n+\n+      if (task \u003d\u003d null) {\n+        task \u003d new LoggedTask();\n+\n+        task.setTaskID(taskID);\n+\n+        jobBeingTraced.getReduceTasks().add(task);\n+\n+        tasksInCurrentJob.put(taskID, task);\n+      }\n+\n+      task.setTaskID(taskID);\n+\n+      LoggedTaskAttempt attempt \u003d attemptsInCurrentJob.get(attemptID);\n+\n+      boolean attemptAlreadyExists \u003d attempt !\u003d null;\n+\n+      if (attempt \u003d\u003d null) {\n+        attempt \u003d new LoggedTaskAttempt();\n+\n+        attempt.setAttemptID(attemptID);\n+      }\n+\n+      if (!attemptAlreadyExists) {\n+        attemptsInCurrentJob.put(attemptID, attempt);\n+        task.getAttempts().add(attempt);\n+      }\n+\n+      Pre21JobHistoryConstants.Values stat \u003d null;\n+\n+      try {\n+        stat \u003d\n+            status \u003d\u003d null ? null : Pre21JobHistoryConstants.Values\n+                .valueOf(status);\n+      } catch (IllegalArgumentException e) {\n+        LOG.warn(\"A map attempt status you don\u0027t know about is \\\"\" + status\n+            + \"\\\".\", e);\n+        stat \u003d null;\n+      }\n+\n+      incorporateCounters(attempt, counters);\n+\n+      attempt.setResult(stat);\n+\n+      if (attemptStartTime !\u003d null) {\n+        attempt.setStartTime(Long.parseLong(attemptStartTime));\n+      }\n+\n+      if (attemptFinishTime !\u003d null) {\n+        attempt.setFinishTime(Long.parseLong(attemptFinishTime));\n+      }\n+\n+      if (attemptShuffleFinished !\u003d null) {\n+        attempt.setShuffleFinished(Long.parseLong(attemptShuffleFinished));\n+      }\n+\n+      if (attemptSortFinished !\u003d null) {\n+        attempt.setSortFinished(Long.parseLong(attemptSortFinished));\n+      }\n+\n+      if (attempt.getStartTime() \u003e 0 \u0026\u0026 attempt.getFinishTime() \u003e 0) {\n+        long runtime \u003d attempt.getFinishTime() - attempt.getStartTime();\n+\n+        if (stat \u003d\u003d Pre21JobHistoryConstants.Values.SUCCESS) {\n+          successfulReduceAttemptTimes.enter(runtime);\n+        }\n+\n+        if (stat \u003d\u003d Pre21JobHistoryConstants.Values.FAILED) {\n+          failedReduceAttemptTimes.enter(runtime);\n+        }\n+      }\n+      if (hostName !\u003d null) {\n+        attempt.setHostName(hostName);\n+      }\n+\n+      if (attemptID !\u003d null) {\n+        Matcher matcher \u003d taskAttemptIDPattern.matcher(attemptID);\n+\n+        if (matcher.matches()) {\n+          String attemptNumberString \u003d matcher.group(1);\n+\n+          if (attemptNumberString !\u003d null) {\n+            int attemptNumber \u003d Integer.parseInt(attemptNumberString);\n+\n+            successfulNthReducerAttempts.enter(attemptNumber);\n+          }\n+        }\n+      }\n+    }\n+\n+    try {\n+      if (attemptStartTime !\u003d null) {\n+        long startTimeValue \u003d Long.parseLong(attemptStartTime);\n+\n+        if (startTimeValue !\u003d 0\n+            \u0026\u0026 startTimeValue + MAXIMUM_CLOCK_SKEW \u003e\u003d launchTimeCurrentJob) {\n+          taskAttemptStartTimes.put(attemptID, startTimeValue);\n+        }\n+      } else if (status !\u003d null \u0026\u0026 status.equals(\"SUCCESS\")\n+          \u0026\u0026 attemptFinishTime !\u003d null) {\n+        long finishTime \u003d Long.parseLong(attemptFinishTime);\n+\n+        taskReduceAttemptFinishTimes.put(attemptID, finishTime);\n+\n+        if (attemptShuffleFinished !\u003d null) {\n+          taskReduceAttemptShuffleEndTimes.put(attemptID, Long\n+              .parseLong(attemptShuffleFinished));\n+        }\n+\n+        if (attemptSortFinished !\u003d null) {\n+          taskReduceAttemptSortEndTimes.put(attemptID, Long\n+              .parseLong(attemptSortFinished));\n+        }\n+      }\n+    } catch (NumberFormatException e) {\n+      LOG.error(\n+          \"HadoopLogsAnalyzer.processReduceAttemptLine: bad numerical format, at line\"\n+              + lineNumber + \".\", e);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void processReduceAttemptLine(ParsedLine line) {\n    String attemptID \u003d line.get(\"TASK_ATTEMPT_ID\");\n\n    String taskID \u003d line.get(\"TASKID\");\n\n    String status \u003d line.get(\"TASK_STATUS\");\n\n    String attemptStartTime \u003d line.get(\"START_TIME\");\n    String attemptFinishTime \u003d line.get(\"FINISH_TIME\");\n    String attemptShuffleFinished \u003d line.get(\"SHUFFLE_FINISHED\");\n    String attemptSortFinished \u003d line.get(\"SORT_FINISHED\");\n\n    String counters \u003d line.get(\"COUNTERS\");\n\n    String hostName \u003d line.get(\"HOSTNAME\");\n\n    if (hostName !\u003d null \u0026\u0026 !hostNames.contains(hostName)) {\n      hostNames.add(hostName);\n    }\n\n    if (jobBeingTraced !\u003d null \u0026\u0026 taskID !\u003d null) {\n      LoggedTask task \u003d tasksInCurrentJob.get(taskID);\n\n      if (task \u003d\u003d null) {\n        task \u003d new LoggedTask();\n\n        task.setTaskID(taskID);\n\n        jobBeingTraced.getReduceTasks().add(task);\n\n        tasksInCurrentJob.put(taskID, task);\n      }\n\n      task.setTaskID(taskID);\n\n      LoggedTaskAttempt attempt \u003d attemptsInCurrentJob.get(attemptID);\n\n      boolean attemptAlreadyExists \u003d attempt !\u003d null;\n\n      if (attempt \u003d\u003d null) {\n        attempt \u003d new LoggedTaskAttempt();\n\n        attempt.setAttemptID(attemptID);\n      }\n\n      if (!attemptAlreadyExists) {\n        attemptsInCurrentJob.put(attemptID, attempt);\n        task.getAttempts().add(attempt);\n      }\n\n      Pre21JobHistoryConstants.Values stat \u003d null;\n\n      try {\n        stat \u003d\n            status \u003d\u003d null ? null : Pre21JobHistoryConstants.Values\n                .valueOf(status);\n      } catch (IllegalArgumentException e) {\n        LOG.warn(\"A map attempt status you don\u0027t know about is \\\"\" + status\n            + \"\\\".\", e);\n        stat \u003d null;\n      }\n\n      incorporateCounters(attempt, counters);\n\n      attempt.setResult(stat);\n\n      if (attemptStartTime !\u003d null) {\n        attempt.setStartTime(Long.parseLong(attemptStartTime));\n      }\n\n      if (attemptFinishTime !\u003d null) {\n        attempt.setFinishTime(Long.parseLong(attemptFinishTime));\n      }\n\n      if (attemptShuffleFinished !\u003d null) {\n        attempt.setShuffleFinished(Long.parseLong(attemptShuffleFinished));\n      }\n\n      if (attemptSortFinished !\u003d null) {\n        attempt.setSortFinished(Long.parseLong(attemptSortFinished));\n      }\n\n      if (attempt.getStartTime() \u003e 0 \u0026\u0026 attempt.getFinishTime() \u003e 0) {\n        long runtime \u003d attempt.getFinishTime() - attempt.getStartTime();\n\n        if (stat \u003d\u003d Pre21JobHistoryConstants.Values.SUCCESS) {\n          successfulReduceAttemptTimes.enter(runtime);\n        }\n\n        if (stat \u003d\u003d Pre21JobHistoryConstants.Values.FAILED) {\n          failedReduceAttemptTimes.enter(runtime);\n        }\n      }\n      if (hostName !\u003d null) {\n        attempt.setHostName(hostName);\n      }\n\n      if (attemptID !\u003d null) {\n        Matcher matcher \u003d taskAttemptIDPattern.matcher(attemptID);\n\n        if (matcher.matches()) {\n          String attemptNumberString \u003d matcher.group(1);\n\n          if (attemptNumberString !\u003d null) {\n            int attemptNumber \u003d Integer.parseInt(attemptNumberString);\n\n            successfulNthReducerAttempts.enter(attemptNumber);\n          }\n        }\n      }\n    }\n\n    try {\n      if (attemptStartTime !\u003d null) {\n        long startTimeValue \u003d Long.parseLong(attemptStartTime);\n\n        if (startTimeValue !\u003d 0\n            \u0026\u0026 startTimeValue + MAXIMUM_CLOCK_SKEW \u003e\u003d launchTimeCurrentJob) {\n          taskAttemptStartTimes.put(attemptID, startTimeValue);\n        }\n      } else if (status !\u003d null \u0026\u0026 status.equals(\"SUCCESS\")\n          \u0026\u0026 attemptFinishTime !\u003d null) {\n        long finishTime \u003d Long.parseLong(attemptFinishTime);\n\n        taskReduceAttemptFinishTimes.put(attemptID, finishTime);\n\n        if (attemptShuffleFinished !\u003d null) {\n          taskReduceAttemptShuffleEndTimes.put(attemptID, Long\n              .parseLong(attemptShuffleFinished));\n        }\n\n        if (attemptSortFinished !\u003d null) {\n          taskReduceAttemptSortEndTimes.put(attemptID, Long\n              .parseLong(attemptSortFinished));\n        }\n      }\n    } catch (NumberFormatException e) {\n      LOG.error(\n          \"HadoopLogsAnalyzer.processReduceAttemptLine: bad numerical format, at line\"\n              + lineNumber + \".\", e);\n    }\n  }",
      "path": "mapreduce/src/tools/org/apache/hadoop/tools/rumen/HadoopLogsAnalyzer.java"
    }
  }
}