{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ApplicationTableRW.java",
  "functionName": "createTable",
  "functionId": "createTable___admin-Admin__hbaseConf-Configuration",
  "sourceFilePath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-client/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/application/ApplicationTableRW.java",
  "functionStartLine": 84,
  "functionEndLine": 126,
  "numCommitsSeen": 10,
  "timeTaken": 2040,
  "changeHistory": [
    "9af30d46c6e82332a8eda20cb3eb5f987e25e7a2",
    "461ee44d287b1fcf0bf15d662aebd3e6f2b83a72",
    "b01514f65bc6090a50a583f67d1ecb5d74b6d276",
    "00e85e7a2b9446dc37265feba07473b156d66367"
  ],
  "changeHistoryShort": {
    "9af30d46c6e82332a8eda20cb3eb5f987e25e7a2": "Yfilerename",
    "461ee44d287b1fcf0bf15d662aebd3e6f2b83a72": "Ybodychange",
    "b01514f65bc6090a50a583f67d1ecb5d74b6d276": "Yfilerename",
    "00e85e7a2b9446dc37265feba07473b156d66367": "Yintroduced"
  },
  "changeHistoryDetails": {
    "9af30d46c6e82332a8eda20cb3eb5f987e25e7a2": {
      "type": "Yfilerename",
      "commitMessage": "YARN-7919. Refactor timelineservice-hbase module into submodules. Contributed by Haibo Chen.\n",
      "commitDate": "17/02/18 7:00 AM",
      "commitName": "9af30d46c6e82332a8eda20cb3eb5f987e25e7a2",
      "commitAuthor": "Rohith Sharma K S",
      "commitDateOld": "17/02/18 3:24 AM",
      "commitNameOld": "a1e56a62863d8d494af309ec5f476c4b7e4d5ef9",
      "commitAuthorOld": "Arun Suresh",
      "daysBetweenCommits": 0.15,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void createTable(Admin admin, Configuration hbaseConf)\n      throws IOException {\n\n    TableName table \u003d getTableName(hbaseConf);\n    if (admin.tableExists(table)) {\n      // do not disable / delete existing table\n      // similar to the approach taken by map-reduce jobs when\n      // output directory exists\n      throw new IOException(\"Table \" + table.getNameAsString()\n          + \" already exists.\");\n    }\n\n    HTableDescriptor applicationTableDescp \u003d new HTableDescriptor(table);\n    HColumnDescriptor infoCF \u003d\n        new HColumnDescriptor(ApplicationColumnFamily.INFO.getBytes());\n    infoCF.setBloomFilterType(BloomType.ROWCOL);\n    applicationTableDescp.addFamily(infoCF);\n\n    HColumnDescriptor configCF \u003d\n        new HColumnDescriptor(ApplicationColumnFamily.CONFIGS.getBytes());\n    configCF.setBloomFilterType(BloomType.ROWCOL);\n    configCF.setBlockCacheEnabled(true);\n    applicationTableDescp.addFamily(configCF);\n\n    HColumnDescriptor metricsCF \u003d\n        new HColumnDescriptor(ApplicationColumnFamily.METRICS.getBytes());\n    applicationTableDescp.addFamily(metricsCF);\n    metricsCF.setBlockCacheEnabled(true);\n    // always keep 1 version (the latest)\n    metricsCF.setMinVersions(1);\n    metricsCF.setMaxVersions(\n        hbaseConf.getInt(METRICS_MAX_VERSIONS, DEFAULT_METRICS_MAX_VERSIONS));\n    metricsCF.setTimeToLive(hbaseConf.getInt(METRICS_TTL_CONF_NAME,\n        DEFAULT_METRICS_TTL));\n    applicationTableDescp.setRegionSplitPolicyClassName(\n        \"org.apache.hadoop.hbase.regionserver.KeyPrefixRegionSplitPolicy\");\n    applicationTableDescp.setValue(\"KeyPrefixRegionSplitPolicy.prefix_length\",\n        TimelineHBaseSchemaConstants.USERNAME_SPLIT_KEY_PREFIX_LENGTH);\n    admin.createTable(applicationTableDescp,\n        TimelineHBaseSchemaConstants.getUsernameSplits());\n    LOG.info(\"Status of table creation for \" + table.getNameAsString() + \"\u003d\"\n        + admin.tableExists(table));\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-client/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/application/ApplicationTableRW.java",
      "extendedDetails": {
        "oldPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/application/ApplicationTable.java",
        "newPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-client/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/application/ApplicationTableRW.java"
      }
    },
    "461ee44d287b1fcf0bf15d662aebd3e6f2b83a72": {
      "type": "Ybodychange",
      "commitMessage": "YARN-6435. [ATSv2] Can\u0027t retrieve more than 1000 versions of metrics in time series. (Rohith Sharma K S via Haibo Chen)\n",
      "commitDate": "09/05/17 9:12 PM",
      "commitName": "461ee44d287b1fcf0bf15d662aebd3e6f2b83a72",
      "commitAuthor": "Haibo Chen",
      "commitDateOld": "19/01/17 8:52 PM",
      "commitNameOld": "b01514f65bc6090a50a583f67d1ecb5d74b6d276",
      "commitAuthorOld": "Sangjin Lee",
      "daysBetweenCommits": 109.97,
      "commitsBetweenForRepo": 602,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,42 +1,43 @@\n   public void createTable(Admin admin, Configuration hbaseConf)\n       throws IOException {\n \n     TableName table \u003d getTableName(hbaseConf);\n     if (admin.tableExists(table)) {\n       // do not disable / delete existing table\n       // similar to the approach taken by map-reduce jobs when\n       // output directory exists\n       throw new IOException(\"Table \" + table.getNameAsString()\n           + \" already exists.\");\n     }\n \n     HTableDescriptor applicationTableDescp \u003d new HTableDescriptor(table);\n     HColumnDescriptor infoCF \u003d\n         new HColumnDescriptor(ApplicationColumnFamily.INFO.getBytes());\n     infoCF.setBloomFilterType(BloomType.ROWCOL);\n     applicationTableDescp.addFamily(infoCF);\n \n     HColumnDescriptor configCF \u003d\n         new HColumnDescriptor(ApplicationColumnFamily.CONFIGS.getBytes());\n     configCF.setBloomFilterType(BloomType.ROWCOL);\n     configCF.setBlockCacheEnabled(true);\n     applicationTableDescp.addFamily(configCF);\n \n     HColumnDescriptor metricsCF \u003d\n         new HColumnDescriptor(ApplicationColumnFamily.METRICS.getBytes());\n     applicationTableDescp.addFamily(metricsCF);\n     metricsCF.setBlockCacheEnabled(true);\n     // always keep 1 version (the latest)\n     metricsCF.setMinVersions(1);\n-    metricsCF.setMaxVersions(DEFAULT_METRICS_MAX_VERSIONS);\n+    metricsCF.setMaxVersions(\n+        hbaseConf.getInt(METRICS_MAX_VERSIONS, DEFAULT_METRICS_MAX_VERSIONS));\n     metricsCF.setTimeToLive(hbaseConf.getInt(METRICS_TTL_CONF_NAME,\n         DEFAULT_METRICS_TTL));\n     applicationTableDescp.setRegionSplitPolicyClassName(\n         \"org.apache.hadoop.hbase.regionserver.KeyPrefixRegionSplitPolicy\");\n     applicationTableDescp.setValue(\"KeyPrefixRegionSplitPolicy.prefix_length\",\n         TimelineHBaseSchemaConstants.USERNAME_SPLIT_KEY_PREFIX_LENGTH);\n     admin.createTable(applicationTableDescp,\n         TimelineHBaseSchemaConstants.getUsernameSplits());\n     LOG.info(\"Status of table creation for \" + table.getNameAsString() + \"\u003d\"\n         + admin.tableExists(table));\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void createTable(Admin admin, Configuration hbaseConf)\n      throws IOException {\n\n    TableName table \u003d getTableName(hbaseConf);\n    if (admin.tableExists(table)) {\n      // do not disable / delete existing table\n      // similar to the approach taken by map-reduce jobs when\n      // output directory exists\n      throw new IOException(\"Table \" + table.getNameAsString()\n          + \" already exists.\");\n    }\n\n    HTableDescriptor applicationTableDescp \u003d new HTableDescriptor(table);\n    HColumnDescriptor infoCF \u003d\n        new HColumnDescriptor(ApplicationColumnFamily.INFO.getBytes());\n    infoCF.setBloomFilterType(BloomType.ROWCOL);\n    applicationTableDescp.addFamily(infoCF);\n\n    HColumnDescriptor configCF \u003d\n        new HColumnDescriptor(ApplicationColumnFamily.CONFIGS.getBytes());\n    configCF.setBloomFilterType(BloomType.ROWCOL);\n    configCF.setBlockCacheEnabled(true);\n    applicationTableDescp.addFamily(configCF);\n\n    HColumnDescriptor metricsCF \u003d\n        new HColumnDescriptor(ApplicationColumnFamily.METRICS.getBytes());\n    applicationTableDescp.addFamily(metricsCF);\n    metricsCF.setBlockCacheEnabled(true);\n    // always keep 1 version (the latest)\n    metricsCF.setMinVersions(1);\n    metricsCF.setMaxVersions(\n        hbaseConf.getInt(METRICS_MAX_VERSIONS, DEFAULT_METRICS_MAX_VERSIONS));\n    metricsCF.setTimeToLive(hbaseConf.getInt(METRICS_TTL_CONF_NAME,\n        DEFAULT_METRICS_TTL));\n    applicationTableDescp.setRegionSplitPolicyClassName(\n        \"org.apache.hadoop.hbase.regionserver.KeyPrefixRegionSplitPolicy\");\n    applicationTableDescp.setValue(\"KeyPrefixRegionSplitPolicy.prefix_length\",\n        TimelineHBaseSchemaConstants.USERNAME_SPLIT_KEY_PREFIX_LENGTH);\n    admin.createTable(applicationTableDescp,\n        TimelineHBaseSchemaConstants.getUsernameSplits());\n    LOG.info(\"Status of table creation for \" + table.getNameAsString() + \"\u003d\"\n        + admin.tableExists(table));\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/application/ApplicationTable.java",
      "extendedDetails": {}
    },
    "b01514f65bc6090a50a583f67d1ecb5d74b6d276": {
      "type": "Yfilerename",
      "commitMessage": "YARN-5928. Move ATSv2 HBase backend code into a new module that is only dependent at runtime by yarn servers. Contributed by Haibo Chen.\n",
      "commitDate": "19/01/17 8:52 PM",
      "commitName": "b01514f65bc6090a50a583f67d1ecb5d74b6d276",
      "commitAuthor": "Sangjin Lee",
      "commitDateOld": "19/01/17 5:32 PM",
      "commitNameOld": "60865c8ea08053f3d6ac23f81c3376a3de3ca996",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 0.14,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void createTable(Admin admin, Configuration hbaseConf)\n      throws IOException {\n\n    TableName table \u003d getTableName(hbaseConf);\n    if (admin.tableExists(table)) {\n      // do not disable / delete existing table\n      // similar to the approach taken by map-reduce jobs when\n      // output directory exists\n      throw new IOException(\"Table \" + table.getNameAsString()\n          + \" already exists.\");\n    }\n\n    HTableDescriptor applicationTableDescp \u003d new HTableDescriptor(table);\n    HColumnDescriptor infoCF \u003d\n        new HColumnDescriptor(ApplicationColumnFamily.INFO.getBytes());\n    infoCF.setBloomFilterType(BloomType.ROWCOL);\n    applicationTableDescp.addFamily(infoCF);\n\n    HColumnDescriptor configCF \u003d\n        new HColumnDescriptor(ApplicationColumnFamily.CONFIGS.getBytes());\n    configCF.setBloomFilterType(BloomType.ROWCOL);\n    configCF.setBlockCacheEnabled(true);\n    applicationTableDescp.addFamily(configCF);\n\n    HColumnDescriptor metricsCF \u003d\n        new HColumnDescriptor(ApplicationColumnFamily.METRICS.getBytes());\n    applicationTableDescp.addFamily(metricsCF);\n    metricsCF.setBlockCacheEnabled(true);\n    // always keep 1 version (the latest)\n    metricsCF.setMinVersions(1);\n    metricsCF.setMaxVersions(DEFAULT_METRICS_MAX_VERSIONS);\n    metricsCF.setTimeToLive(hbaseConf.getInt(METRICS_TTL_CONF_NAME,\n        DEFAULT_METRICS_TTL));\n    applicationTableDescp.setRegionSplitPolicyClassName(\n        \"org.apache.hadoop.hbase.regionserver.KeyPrefixRegionSplitPolicy\");\n    applicationTableDescp.setValue(\"KeyPrefixRegionSplitPolicy.prefix_length\",\n        TimelineHBaseSchemaConstants.USERNAME_SPLIT_KEY_PREFIX_LENGTH);\n    admin.createTable(applicationTableDescp,\n        TimelineHBaseSchemaConstants.getUsernameSplits());\n    LOG.info(\"Status of table creation for \" + table.getNameAsString() + \"\u003d\"\n        + admin.tableExists(table));\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/application/ApplicationTable.java",
      "extendedDetails": {
        "oldPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/application/ApplicationTable.java",
        "newPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/application/ApplicationTable.java"
      }
    },
    "00e85e7a2b9446dc37265feba07473b156d66367": {
      "type": "Yintroduced",
      "commitMessage": "YARN-3906. Split the application table from the entity table. Contributed by Sangjin Lee.\n\n(cherry picked from commit bcd755eba9466ce277d3c14192c31da6462c4ab3)\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "00e85e7a2b9446dc37265feba07473b156d66367",
      "commitAuthor": "Junping Du",
      "diff": "@@ -0,0 +1,42 @@\n+  public void createTable(Admin admin, Configuration hbaseConf)\n+      throws IOException {\n+\n+    TableName table \u003d getTableName(hbaseConf);\n+    if (admin.tableExists(table)) {\n+      // do not disable / delete existing table\n+      // similar to the approach taken by map-reduce jobs when\n+      // output directory exists\n+      throw new IOException(\"Table \" + table.getNameAsString()\n+          + \" already exists.\");\n+    }\n+\n+    HTableDescriptor applicationTableDescp \u003d new HTableDescriptor(table);\n+    HColumnDescriptor infoCF \u003d\n+        new HColumnDescriptor(ApplicationColumnFamily.INFO.getBytes());\n+    infoCF.setBloomFilterType(BloomType.ROWCOL);\n+    applicationTableDescp.addFamily(infoCF);\n+\n+    HColumnDescriptor configCF \u003d\n+        new HColumnDescriptor(ApplicationColumnFamily.CONFIGS.getBytes());\n+    configCF.setBloomFilterType(BloomType.ROWCOL);\n+    configCF.setBlockCacheEnabled(true);\n+    applicationTableDescp.addFamily(configCF);\n+\n+    HColumnDescriptor metricsCF \u003d\n+        new HColumnDescriptor(ApplicationColumnFamily.METRICS.getBytes());\n+    applicationTableDescp.addFamily(metricsCF);\n+    metricsCF.setBlockCacheEnabled(true);\n+    // always keep 1 version (the latest)\n+    metricsCF.setMinVersions(1);\n+    metricsCF.setMaxVersions(DEFAULT_METRICS_MAX_VERSIONS);\n+    metricsCF.setTimeToLive(hbaseConf.getInt(METRICS_TTL_CONF_NAME,\n+        DEFAULT_METRICS_TTL));\n+    applicationTableDescp\n+        .setRegionSplitPolicyClassName(\"org.apache.hadoop.hbase.regionserver.KeyPrefixRegionSplitPolicy\");\n+    applicationTableDescp.setValue(\"KeyPrefixRegionSplitPolicy.prefix_length\",\n+        TimelineHBaseSchemaConstants.USERNAME_SPLIT_KEY_PREFIX_LENGTH);\n+    admin.createTable(applicationTableDescp,\n+        TimelineHBaseSchemaConstants.getUsernameSplits());\n+    LOG.info(\"Status of table creation for \" + table.getNameAsString() + \"\u003d\"\n+        + admin.tableExists(table));\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void createTable(Admin admin, Configuration hbaseConf)\n      throws IOException {\n\n    TableName table \u003d getTableName(hbaseConf);\n    if (admin.tableExists(table)) {\n      // do not disable / delete existing table\n      // similar to the approach taken by map-reduce jobs when\n      // output directory exists\n      throw new IOException(\"Table \" + table.getNameAsString()\n          + \" already exists.\");\n    }\n\n    HTableDescriptor applicationTableDescp \u003d new HTableDescriptor(table);\n    HColumnDescriptor infoCF \u003d\n        new HColumnDescriptor(ApplicationColumnFamily.INFO.getBytes());\n    infoCF.setBloomFilterType(BloomType.ROWCOL);\n    applicationTableDescp.addFamily(infoCF);\n\n    HColumnDescriptor configCF \u003d\n        new HColumnDescriptor(ApplicationColumnFamily.CONFIGS.getBytes());\n    configCF.setBloomFilterType(BloomType.ROWCOL);\n    configCF.setBlockCacheEnabled(true);\n    applicationTableDescp.addFamily(configCF);\n\n    HColumnDescriptor metricsCF \u003d\n        new HColumnDescriptor(ApplicationColumnFamily.METRICS.getBytes());\n    applicationTableDescp.addFamily(metricsCF);\n    metricsCF.setBlockCacheEnabled(true);\n    // always keep 1 version (the latest)\n    metricsCF.setMinVersions(1);\n    metricsCF.setMaxVersions(DEFAULT_METRICS_MAX_VERSIONS);\n    metricsCF.setTimeToLive(hbaseConf.getInt(METRICS_TTL_CONF_NAME,\n        DEFAULT_METRICS_TTL));\n    applicationTableDescp\n        .setRegionSplitPolicyClassName(\"org.apache.hadoop.hbase.regionserver.KeyPrefixRegionSplitPolicy\");\n    applicationTableDescp.setValue(\"KeyPrefixRegionSplitPolicy.prefix_length\",\n        TimelineHBaseSchemaConstants.USERNAME_SPLIT_KEY_PREFIX_LENGTH);\n    admin.createTable(applicationTableDescp,\n        TimelineHBaseSchemaConstants.getUsernameSplits());\n    LOG.info(\"Status of table creation for \" + table.getNameAsString() + \"\u003d\"\n        + admin.tableExists(table));\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/application/ApplicationTable.java"
    }
  }
}