{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "CommitOperations.java",
  "functionName": "uploadFileToPendingCommit",
  "functionId": "uploadFileToPendingCommit___localFile-File__destPath-Path__partition-String__uploadPartSize-long__progress-Progressable",
  "sourceFilePath": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/commit/CommitOperations.java",
  "functionStartLine": 447,
  "functionEndLine": 531,
  "numCommitsSeen": 22,
  "timeTaken": 3694,
  "changeHistory": [
    "29b19cd59245c8809b697b3d7d7445813a685aad",
    "c77fc6971b5194c9dae184703caa87da271a85eb",
    "de8b6ca5ef8614de6d6277b7617e27c788b0555c"
  ],
  "changeHistoryShort": {
    "29b19cd59245c8809b697b3d7d7445813a685aad": "Ybodychange",
    "c77fc6971b5194c9dae184703caa87da271a85eb": "Ymultichange(Yparameterchange,Ybodychange)",
    "de8b6ca5ef8614de6d6277b7617e27c788b0555c": "Yintroduced"
  },
  "changeHistoryDetails": {
    "29b19cd59245c8809b697b3d7d7445813a685aad": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-16900. Very large files can be truncated when written through the S3A FileSystem.\n\nContributed by Mukund Thakur and Steve Loughran.\n\nThis patch ensures that writes to S3A fail when more than 10,000 blocks are\nwritten. That upper bound still exists. To write massive files, make sure\nthat the value of fs.s3a.multipart.size is set to a size which is large\nenough to upload the files in fewer than 10,000 blocks.\n\nChange-Id: Icec604e2a357ffd38d7ae7bc3f887ff55f2d721a\n",
      "commitDate": "20/05/20 5:42 AM",
      "commitName": "29b19cd59245c8809b697b3d7d7445813a685aad",
      "commitAuthor": "Mukund Thakur",
      "commitDateOld": "17/02/20 2:06 PM",
      "commitNameOld": "c77fc6971b5194c9dae184703caa87da271a85eb",
      "commitAuthorOld": "lqjacklee",
      "daysBetweenCommits": 92.61,
      "commitsBetweenForRepo": 325,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,77 +1,85 @@\n   public SinglePendingCommit uploadFileToPendingCommit(File localFile,\n       Path destPath,\n       String partition,\n       long uploadPartSize,\n       Progressable progress)\n       throws IOException {\n \n     LOG.debug(\"Initiating multipart upload from {} to {}\",\n         localFile, destPath);\n     Preconditions.checkArgument(destPath !\u003d null);\n     if (!localFile.isFile()) {\n       throw new FileNotFoundException(\"Not a file: \" + localFile);\n     }\n     String destURI \u003d destPath.toString();\n     String destKey \u003d fs.pathToKey(destPath);\n     String uploadId \u003d null;\n \n     boolean threw \u003d true;\n     try {\n       statistics.commitCreated();\n       uploadId \u003d writeOperations.initiateMultiPartUpload(destKey);\n       long length \u003d localFile.length();\n \n       SinglePendingCommit commitData \u003d new SinglePendingCommit();\n       commitData.setDestinationKey(destKey);\n       commitData.setBucket(fs.getBucket());\n       commitData.touch(System.currentTimeMillis());\n       commitData.setUploadId(uploadId);\n       commitData.setUri(destURI);\n       commitData.setText(partition !\u003d null ? \"partition: \" + partition : \"\");\n       commitData.setLength(length);\n \n       long offset \u003d 0;\n       long numParts \u003d (length / uploadPartSize +\n           ((length % uploadPartSize) \u003e 0 ? 1 : 0));\n       // always write one part, even if it is just an empty one\n       if (numParts \u003d\u003d 0) {\n         numParts \u003d 1;\n       }\n+      if (numParts \u003e InternalConstants.DEFAULT_UPLOAD_PART_COUNT_LIMIT) {\n+        // fail if the file is too big.\n+        // it would be possible to be clever here and recalculate the part size,\n+        // but this is not currently done.\n+        throw new PathIOException(destPath.toString(),\n+            String.format(\"File to upload (size %d)\"\n+                + \" is too big to be uploaded in parts of size %d\",\n+                numParts, length));\n+      }\n \n       List\u003cPartETag\u003e parts \u003d new ArrayList\u003c\u003e((int) numParts);\n \n       LOG.debug(\"File size is {}, number of parts to upload \u003d {}\",\n           length, numParts);\n       for (int partNumber \u003d 1; partNumber \u003c\u003d numParts; partNumber +\u003d 1) {\n         long size \u003d Math.min(length - offset, uploadPartSize);\n         UploadPartRequest part;\n         part \u003d writeOperations.newUploadPartRequest(\n             destKey,\n             uploadId,\n             partNumber,\n             (int) size,\n             null,\n             localFile,\n             offset);\n         part.setLastPart(partNumber \u003d\u003d numParts);\n         UploadPartResult partResult \u003d writeOperations.uploadPart(part);\n         offset +\u003d uploadPartSize;\n         parts.add(partResult.getPartETag());\n       }\n \n       commitData.bindCommitData(parts);\n       statistics.commitUploaded(length);\n       progress.progress();\n       threw \u003d false;\n       return commitData;\n     } finally {\n       if (threw \u0026\u0026 uploadId !\u003d null) {\n-        statistics.commitAborted();\n         try {\n           abortMultipartCommit(destKey, uploadId);\n         } catch (IOException e) {\n           LOG.error(\"Failed to abort upload {} to {}\", uploadId, destKey, e);\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public SinglePendingCommit uploadFileToPendingCommit(File localFile,\n      Path destPath,\n      String partition,\n      long uploadPartSize,\n      Progressable progress)\n      throws IOException {\n\n    LOG.debug(\"Initiating multipart upload from {} to {}\",\n        localFile, destPath);\n    Preconditions.checkArgument(destPath !\u003d null);\n    if (!localFile.isFile()) {\n      throw new FileNotFoundException(\"Not a file: \" + localFile);\n    }\n    String destURI \u003d destPath.toString();\n    String destKey \u003d fs.pathToKey(destPath);\n    String uploadId \u003d null;\n\n    boolean threw \u003d true;\n    try {\n      statistics.commitCreated();\n      uploadId \u003d writeOperations.initiateMultiPartUpload(destKey);\n      long length \u003d localFile.length();\n\n      SinglePendingCommit commitData \u003d new SinglePendingCommit();\n      commitData.setDestinationKey(destKey);\n      commitData.setBucket(fs.getBucket());\n      commitData.touch(System.currentTimeMillis());\n      commitData.setUploadId(uploadId);\n      commitData.setUri(destURI);\n      commitData.setText(partition !\u003d null ? \"partition: \" + partition : \"\");\n      commitData.setLength(length);\n\n      long offset \u003d 0;\n      long numParts \u003d (length / uploadPartSize +\n          ((length % uploadPartSize) \u003e 0 ? 1 : 0));\n      // always write one part, even if it is just an empty one\n      if (numParts \u003d\u003d 0) {\n        numParts \u003d 1;\n      }\n      if (numParts \u003e InternalConstants.DEFAULT_UPLOAD_PART_COUNT_LIMIT) {\n        // fail if the file is too big.\n        // it would be possible to be clever here and recalculate the part size,\n        // but this is not currently done.\n        throw new PathIOException(destPath.toString(),\n            String.format(\"File to upload (size %d)\"\n                + \" is too big to be uploaded in parts of size %d\",\n                numParts, length));\n      }\n\n      List\u003cPartETag\u003e parts \u003d new ArrayList\u003c\u003e((int) numParts);\n\n      LOG.debug(\"File size is {}, number of parts to upload \u003d {}\",\n          length, numParts);\n      for (int partNumber \u003d 1; partNumber \u003c\u003d numParts; partNumber +\u003d 1) {\n        long size \u003d Math.min(length - offset, uploadPartSize);\n        UploadPartRequest part;\n        part \u003d writeOperations.newUploadPartRequest(\n            destKey,\n            uploadId,\n            partNumber,\n            (int) size,\n            null,\n            localFile,\n            offset);\n        part.setLastPart(partNumber \u003d\u003d numParts);\n        UploadPartResult partResult \u003d writeOperations.uploadPart(part);\n        offset +\u003d uploadPartSize;\n        parts.add(partResult.getPartETag());\n      }\n\n      commitData.bindCommitData(parts);\n      statistics.commitUploaded(length);\n      progress.progress();\n      threw \u003d false;\n      return commitData;\n    } finally {\n      if (threw \u0026\u0026 uploadId !\u003d null) {\n        try {\n          abortMultipartCommit(destKey, uploadId);\n        } catch (IOException e) {\n          LOG.error(\"Failed to abort upload {} to {}\", uploadId, destKey, e);\n        }\n      }\n    }\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/commit/CommitOperations.java",
      "extendedDetails": {}
    },
    "c77fc6971b5194c9dae184703caa87da271a85eb": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HADOOP-15961. S3A committers: make sure there\u0027s regular progress() calls.\n\nContributed by lqjacklee.\n\nChange-Id: I13ca153e1e32b21dbe64d6fb25e260e0ff66154d\n",
      "commitDate": "17/02/20 2:06 PM",
      "commitName": "c77fc6971b5194c9dae184703caa87da271a85eb",
      "commitAuthor": "lqjacklee",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HADOOP-15961. S3A committers: make sure there\u0027s regular progress() calls.\n\nContributed by lqjacklee.\n\nChange-Id: I13ca153e1e32b21dbe64d6fb25e260e0ff66154d\n",
          "commitDate": "17/02/20 2:06 PM",
          "commitName": "c77fc6971b5194c9dae184703caa87da271a85eb",
          "commitAuthor": "lqjacklee",
          "commitDateOld": "10/09/19 7:05 AM",
          "commitNameOld": "dc9abd27d9cbe09990ee654a073d22a1bf466ed2",
          "commitAuthorOld": "Xieming Li",
          "daysBetweenCommits": 160.33,
          "commitsBetweenForRepo": 713,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,75 +1,77 @@\n   public SinglePendingCommit uploadFileToPendingCommit(File localFile,\n       Path destPath,\n       String partition,\n-      long uploadPartSize)\n+      long uploadPartSize,\n+      Progressable progress)\n       throws IOException {\n \n     LOG.debug(\"Initiating multipart upload from {} to {}\",\n         localFile, destPath);\n     Preconditions.checkArgument(destPath !\u003d null);\n     if (!localFile.isFile()) {\n       throw new FileNotFoundException(\"Not a file: \" + localFile);\n     }\n     String destURI \u003d destPath.toString();\n     String destKey \u003d fs.pathToKey(destPath);\n     String uploadId \u003d null;\n \n     boolean threw \u003d true;\n     try {\n       statistics.commitCreated();\n       uploadId \u003d writeOperations.initiateMultiPartUpload(destKey);\n       long length \u003d localFile.length();\n \n       SinglePendingCommit commitData \u003d new SinglePendingCommit();\n       commitData.setDestinationKey(destKey);\n       commitData.setBucket(fs.getBucket());\n       commitData.touch(System.currentTimeMillis());\n       commitData.setUploadId(uploadId);\n       commitData.setUri(destURI);\n       commitData.setText(partition !\u003d null ? \"partition: \" + partition : \"\");\n       commitData.setLength(length);\n \n       long offset \u003d 0;\n       long numParts \u003d (length / uploadPartSize +\n           ((length % uploadPartSize) \u003e 0 ? 1 : 0));\n       // always write one part, even if it is just an empty one\n       if (numParts \u003d\u003d 0) {\n         numParts \u003d 1;\n       }\n \n       List\u003cPartETag\u003e parts \u003d new ArrayList\u003c\u003e((int) numParts);\n \n       LOG.debug(\"File size is {}, number of parts to upload \u003d {}\",\n           length, numParts);\n       for (int partNumber \u003d 1; partNumber \u003c\u003d numParts; partNumber +\u003d 1) {\n         long size \u003d Math.min(length - offset, uploadPartSize);\n         UploadPartRequest part;\n         part \u003d writeOperations.newUploadPartRequest(\n             destKey,\n             uploadId,\n             partNumber,\n             (int) size,\n             null,\n             localFile,\n             offset);\n         part.setLastPart(partNumber \u003d\u003d numParts);\n         UploadPartResult partResult \u003d writeOperations.uploadPart(part);\n         offset +\u003d uploadPartSize;\n         parts.add(partResult.getPartETag());\n       }\n \n       commitData.bindCommitData(parts);\n       statistics.commitUploaded(length);\n+      progress.progress();\n       threw \u003d false;\n       return commitData;\n     } finally {\n       if (threw \u0026\u0026 uploadId !\u003d null) {\n         statistics.commitAborted();\n         try {\n           abortMultipartCommit(destKey, uploadId);\n         } catch (IOException e) {\n           LOG.error(\"Failed to abort upload {} to {}\", uploadId, destKey, e);\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public SinglePendingCommit uploadFileToPendingCommit(File localFile,\n      Path destPath,\n      String partition,\n      long uploadPartSize,\n      Progressable progress)\n      throws IOException {\n\n    LOG.debug(\"Initiating multipart upload from {} to {}\",\n        localFile, destPath);\n    Preconditions.checkArgument(destPath !\u003d null);\n    if (!localFile.isFile()) {\n      throw new FileNotFoundException(\"Not a file: \" + localFile);\n    }\n    String destURI \u003d destPath.toString();\n    String destKey \u003d fs.pathToKey(destPath);\n    String uploadId \u003d null;\n\n    boolean threw \u003d true;\n    try {\n      statistics.commitCreated();\n      uploadId \u003d writeOperations.initiateMultiPartUpload(destKey);\n      long length \u003d localFile.length();\n\n      SinglePendingCommit commitData \u003d new SinglePendingCommit();\n      commitData.setDestinationKey(destKey);\n      commitData.setBucket(fs.getBucket());\n      commitData.touch(System.currentTimeMillis());\n      commitData.setUploadId(uploadId);\n      commitData.setUri(destURI);\n      commitData.setText(partition !\u003d null ? \"partition: \" + partition : \"\");\n      commitData.setLength(length);\n\n      long offset \u003d 0;\n      long numParts \u003d (length / uploadPartSize +\n          ((length % uploadPartSize) \u003e 0 ? 1 : 0));\n      // always write one part, even if it is just an empty one\n      if (numParts \u003d\u003d 0) {\n        numParts \u003d 1;\n      }\n\n      List\u003cPartETag\u003e parts \u003d new ArrayList\u003c\u003e((int) numParts);\n\n      LOG.debug(\"File size is {}, number of parts to upload \u003d {}\",\n          length, numParts);\n      for (int partNumber \u003d 1; partNumber \u003c\u003d numParts; partNumber +\u003d 1) {\n        long size \u003d Math.min(length - offset, uploadPartSize);\n        UploadPartRequest part;\n        part \u003d writeOperations.newUploadPartRequest(\n            destKey,\n            uploadId,\n            partNumber,\n            (int) size,\n            null,\n            localFile,\n            offset);\n        part.setLastPart(partNumber \u003d\u003d numParts);\n        UploadPartResult partResult \u003d writeOperations.uploadPart(part);\n        offset +\u003d uploadPartSize;\n        parts.add(partResult.getPartETag());\n      }\n\n      commitData.bindCommitData(parts);\n      statistics.commitUploaded(length);\n      progress.progress();\n      threw \u003d false;\n      return commitData;\n    } finally {\n      if (threw \u0026\u0026 uploadId !\u003d null) {\n        statistics.commitAborted();\n        try {\n          abortMultipartCommit(destKey, uploadId);\n        } catch (IOException e) {\n          LOG.error(\"Failed to abort upload {} to {}\", uploadId, destKey, e);\n        }\n      }\n    }\n  }",
          "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/commit/CommitOperations.java",
          "extendedDetails": {
            "oldValue": "[localFile-File, destPath-Path, partition-String, uploadPartSize-long]",
            "newValue": "[localFile-File, destPath-Path, partition-String, uploadPartSize-long, progress-Progressable]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HADOOP-15961. S3A committers: make sure there\u0027s regular progress() calls.\n\nContributed by lqjacklee.\n\nChange-Id: I13ca153e1e32b21dbe64d6fb25e260e0ff66154d\n",
          "commitDate": "17/02/20 2:06 PM",
          "commitName": "c77fc6971b5194c9dae184703caa87da271a85eb",
          "commitAuthor": "lqjacklee",
          "commitDateOld": "10/09/19 7:05 AM",
          "commitNameOld": "dc9abd27d9cbe09990ee654a073d22a1bf466ed2",
          "commitAuthorOld": "Xieming Li",
          "daysBetweenCommits": 160.33,
          "commitsBetweenForRepo": 713,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,75 +1,77 @@\n   public SinglePendingCommit uploadFileToPendingCommit(File localFile,\n       Path destPath,\n       String partition,\n-      long uploadPartSize)\n+      long uploadPartSize,\n+      Progressable progress)\n       throws IOException {\n \n     LOG.debug(\"Initiating multipart upload from {} to {}\",\n         localFile, destPath);\n     Preconditions.checkArgument(destPath !\u003d null);\n     if (!localFile.isFile()) {\n       throw new FileNotFoundException(\"Not a file: \" + localFile);\n     }\n     String destURI \u003d destPath.toString();\n     String destKey \u003d fs.pathToKey(destPath);\n     String uploadId \u003d null;\n \n     boolean threw \u003d true;\n     try {\n       statistics.commitCreated();\n       uploadId \u003d writeOperations.initiateMultiPartUpload(destKey);\n       long length \u003d localFile.length();\n \n       SinglePendingCommit commitData \u003d new SinglePendingCommit();\n       commitData.setDestinationKey(destKey);\n       commitData.setBucket(fs.getBucket());\n       commitData.touch(System.currentTimeMillis());\n       commitData.setUploadId(uploadId);\n       commitData.setUri(destURI);\n       commitData.setText(partition !\u003d null ? \"partition: \" + partition : \"\");\n       commitData.setLength(length);\n \n       long offset \u003d 0;\n       long numParts \u003d (length / uploadPartSize +\n           ((length % uploadPartSize) \u003e 0 ? 1 : 0));\n       // always write one part, even if it is just an empty one\n       if (numParts \u003d\u003d 0) {\n         numParts \u003d 1;\n       }\n \n       List\u003cPartETag\u003e parts \u003d new ArrayList\u003c\u003e((int) numParts);\n \n       LOG.debug(\"File size is {}, number of parts to upload \u003d {}\",\n           length, numParts);\n       for (int partNumber \u003d 1; partNumber \u003c\u003d numParts; partNumber +\u003d 1) {\n         long size \u003d Math.min(length - offset, uploadPartSize);\n         UploadPartRequest part;\n         part \u003d writeOperations.newUploadPartRequest(\n             destKey,\n             uploadId,\n             partNumber,\n             (int) size,\n             null,\n             localFile,\n             offset);\n         part.setLastPart(partNumber \u003d\u003d numParts);\n         UploadPartResult partResult \u003d writeOperations.uploadPart(part);\n         offset +\u003d uploadPartSize;\n         parts.add(partResult.getPartETag());\n       }\n \n       commitData.bindCommitData(parts);\n       statistics.commitUploaded(length);\n+      progress.progress();\n       threw \u003d false;\n       return commitData;\n     } finally {\n       if (threw \u0026\u0026 uploadId !\u003d null) {\n         statistics.commitAborted();\n         try {\n           abortMultipartCommit(destKey, uploadId);\n         } catch (IOException e) {\n           LOG.error(\"Failed to abort upload {} to {}\", uploadId, destKey, e);\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public SinglePendingCommit uploadFileToPendingCommit(File localFile,\n      Path destPath,\n      String partition,\n      long uploadPartSize,\n      Progressable progress)\n      throws IOException {\n\n    LOG.debug(\"Initiating multipart upload from {} to {}\",\n        localFile, destPath);\n    Preconditions.checkArgument(destPath !\u003d null);\n    if (!localFile.isFile()) {\n      throw new FileNotFoundException(\"Not a file: \" + localFile);\n    }\n    String destURI \u003d destPath.toString();\n    String destKey \u003d fs.pathToKey(destPath);\n    String uploadId \u003d null;\n\n    boolean threw \u003d true;\n    try {\n      statistics.commitCreated();\n      uploadId \u003d writeOperations.initiateMultiPartUpload(destKey);\n      long length \u003d localFile.length();\n\n      SinglePendingCommit commitData \u003d new SinglePendingCommit();\n      commitData.setDestinationKey(destKey);\n      commitData.setBucket(fs.getBucket());\n      commitData.touch(System.currentTimeMillis());\n      commitData.setUploadId(uploadId);\n      commitData.setUri(destURI);\n      commitData.setText(partition !\u003d null ? \"partition: \" + partition : \"\");\n      commitData.setLength(length);\n\n      long offset \u003d 0;\n      long numParts \u003d (length / uploadPartSize +\n          ((length % uploadPartSize) \u003e 0 ? 1 : 0));\n      // always write one part, even if it is just an empty one\n      if (numParts \u003d\u003d 0) {\n        numParts \u003d 1;\n      }\n\n      List\u003cPartETag\u003e parts \u003d new ArrayList\u003c\u003e((int) numParts);\n\n      LOG.debug(\"File size is {}, number of parts to upload \u003d {}\",\n          length, numParts);\n      for (int partNumber \u003d 1; partNumber \u003c\u003d numParts; partNumber +\u003d 1) {\n        long size \u003d Math.min(length - offset, uploadPartSize);\n        UploadPartRequest part;\n        part \u003d writeOperations.newUploadPartRequest(\n            destKey,\n            uploadId,\n            partNumber,\n            (int) size,\n            null,\n            localFile,\n            offset);\n        part.setLastPart(partNumber \u003d\u003d numParts);\n        UploadPartResult partResult \u003d writeOperations.uploadPart(part);\n        offset +\u003d uploadPartSize;\n        parts.add(partResult.getPartETag());\n      }\n\n      commitData.bindCommitData(parts);\n      statistics.commitUploaded(length);\n      progress.progress();\n      threw \u003d false;\n      return commitData;\n    } finally {\n      if (threw \u0026\u0026 uploadId !\u003d null) {\n        statistics.commitAborted();\n        try {\n          abortMultipartCommit(destKey, uploadId);\n        } catch (IOException e) {\n          LOG.error(\"Failed to abort upload {} to {}\", uploadId, destKey, e);\n        }\n      }\n    }\n  }",
          "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/commit/CommitOperations.java",
          "extendedDetails": {}
        }
      ]
    },
    "de8b6ca5ef8614de6d6277b7617e27c788b0555c": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-13786 Add S3A committer for zero-rename commits to S3 endpoints.\nContributed by Steve Loughran and Ryan Blue.\n",
      "commitDate": "22/11/17 7:28 AM",
      "commitName": "de8b6ca5ef8614de6d6277b7617e27c788b0555c",
      "commitAuthor": "Steve Loughran",
      "diff": "@@ -0,0 +1,75 @@\n+  public SinglePendingCommit uploadFileToPendingCommit(File localFile,\n+      Path destPath,\n+      String partition,\n+      long uploadPartSize)\n+      throws IOException {\n+\n+    LOG.debug(\"Initiating multipart upload from {} to {}\",\n+        localFile, destPath);\n+    Preconditions.checkArgument(destPath !\u003d null);\n+    if (!localFile.isFile()) {\n+      throw new FileNotFoundException(\"Not a file: \" + localFile);\n+    }\n+    String destURI \u003d destPath.toString();\n+    String destKey \u003d fs.pathToKey(destPath);\n+    String uploadId \u003d null;\n+\n+    boolean threw \u003d true;\n+    try {\n+      statistics.commitCreated();\n+      uploadId \u003d writeOperations.initiateMultiPartUpload(destKey);\n+      long length \u003d localFile.length();\n+\n+      SinglePendingCommit commitData \u003d new SinglePendingCommit();\n+      commitData.setDestinationKey(destKey);\n+      commitData.setBucket(fs.getBucket());\n+      commitData.touch(System.currentTimeMillis());\n+      commitData.setUploadId(uploadId);\n+      commitData.setUri(destURI);\n+      commitData.setText(partition !\u003d null ? \"partition: \" + partition : \"\");\n+      commitData.setLength(length);\n+\n+      long offset \u003d 0;\n+      long numParts \u003d (length / uploadPartSize +\n+          ((length % uploadPartSize) \u003e 0 ? 1 : 0));\n+      // always write one part, even if it is just an empty one\n+      if (numParts \u003d\u003d 0) {\n+        numParts \u003d 1;\n+      }\n+\n+      List\u003cPartETag\u003e parts \u003d new ArrayList\u003c\u003e((int) numParts);\n+\n+      LOG.debug(\"File size is {}, number of parts to upload \u003d {}\",\n+          length, numParts);\n+      for (int partNumber \u003d 1; partNumber \u003c\u003d numParts; partNumber +\u003d 1) {\n+        long size \u003d Math.min(length - offset, uploadPartSize);\n+        UploadPartRequest part;\n+        part \u003d writeOperations.newUploadPartRequest(\n+            destKey,\n+            uploadId,\n+            partNumber,\n+            (int) size,\n+            null,\n+            localFile,\n+            offset);\n+        part.setLastPart(partNumber \u003d\u003d numParts);\n+        UploadPartResult partResult \u003d writeOperations.uploadPart(part);\n+        offset +\u003d uploadPartSize;\n+        parts.add(partResult.getPartETag());\n+      }\n+\n+      commitData.bindCommitData(parts);\n+      statistics.commitUploaded(length);\n+      threw \u003d false;\n+      return commitData;\n+    } finally {\n+      if (threw \u0026\u0026 uploadId !\u003d null) {\n+        statistics.commitAborted();\n+        try {\n+          abortMultipartCommit(destKey, uploadId);\n+        } catch (IOException e) {\n+          LOG.error(\"Failed to abort upload {} to {}\", uploadId, destKey, e);\n+        }\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public SinglePendingCommit uploadFileToPendingCommit(File localFile,\n      Path destPath,\n      String partition,\n      long uploadPartSize)\n      throws IOException {\n\n    LOG.debug(\"Initiating multipart upload from {} to {}\",\n        localFile, destPath);\n    Preconditions.checkArgument(destPath !\u003d null);\n    if (!localFile.isFile()) {\n      throw new FileNotFoundException(\"Not a file: \" + localFile);\n    }\n    String destURI \u003d destPath.toString();\n    String destKey \u003d fs.pathToKey(destPath);\n    String uploadId \u003d null;\n\n    boolean threw \u003d true;\n    try {\n      statistics.commitCreated();\n      uploadId \u003d writeOperations.initiateMultiPartUpload(destKey);\n      long length \u003d localFile.length();\n\n      SinglePendingCommit commitData \u003d new SinglePendingCommit();\n      commitData.setDestinationKey(destKey);\n      commitData.setBucket(fs.getBucket());\n      commitData.touch(System.currentTimeMillis());\n      commitData.setUploadId(uploadId);\n      commitData.setUri(destURI);\n      commitData.setText(partition !\u003d null ? \"partition: \" + partition : \"\");\n      commitData.setLength(length);\n\n      long offset \u003d 0;\n      long numParts \u003d (length / uploadPartSize +\n          ((length % uploadPartSize) \u003e 0 ? 1 : 0));\n      // always write one part, even if it is just an empty one\n      if (numParts \u003d\u003d 0) {\n        numParts \u003d 1;\n      }\n\n      List\u003cPartETag\u003e parts \u003d new ArrayList\u003c\u003e((int) numParts);\n\n      LOG.debug(\"File size is {}, number of parts to upload \u003d {}\",\n          length, numParts);\n      for (int partNumber \u003d 1; partNumber \u003c\u003d numParts; partNumber +\u003d 1) {\n        long size \u003d Math.min(length - offset, uploadPartSize);\n        UploadPartRequest part;\n        part \u003d writeOperations.newUploadPartRequest(\n            destKey,\n            uploadId,\n            partNumber,\n            (int) size,\n            null,\n            localFile,\n            offset);\n        part.setLastPart(partNumber \u003d\u003d numParts);\n        UploadPartResult partResult \u003d writeOperations.uploadPart(part);\n        offset +\u003d uploadPartSize;\n        parts.add(partResult.getPartETag());\n      }\n\n      commitData.bindCommitData(parts);\n      statistics.commitUploaded(length);\n      threw \u003d false;\n      return commitData;\n    } finally {\n      if (threw \u0026\u0026 uploadId !\u003d null) {\n        statistics.commitAborted();\n        try {\n          abortMultipartCommit(destKey, uploadId);\n        } catch (IOException e) {\n          LOG.error(\"Failed to abort upload {} to {}\", uploadId, destKey, e);\n        }\n      }\n    }\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/commit/CommitOperations.java"
    }
  }
}