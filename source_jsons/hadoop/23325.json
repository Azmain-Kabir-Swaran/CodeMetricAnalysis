{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FloatSplitter.java",
  "functionName": "split",
  "functionId": "split___conf-Configuration__results-ResultSet__colName-String",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/db/FloatSplitter.java",
  "functionStartLine": 47,
  "functionEndLine": 105,
  "numCommitsSeen": 5,
  "timeTaken": 4434,
  "changeHistory": [
    "7b7caa1e56f6794152adcc0a99d26ebc50ea5a47",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "7b7caa1e56f6794152adcc0a99d26ebc50ea5a47": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "7b7caa1e56f6794152adcc0a99d26ebc50ea5a47": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5569. FloatSplitter is not generating correct splits. Contributed by Nathan Roberts\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1530683 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/10/13 8:43 AM",
      "commitName": "7b7caa1e56f6794152adcc0a99d26ebc50ea5a47",
      "commitAuthor": "Jason Darrell Lowe",
      "commitDateOld": "24/08/11 5:14 PM",
      "commitNameOld": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 776.65,
      "commitsBetweenForRepo": 4843,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,59 +1,59 @@\n   public List\u003cInputSplit\u003e split(Configuration conf, ResultSet results, String colName)\n       throws SQLException {\n \n     LOG.warn(\"Generating splits for a floating-point index column. Due to the\");\n     LOG.warn(\"imprecise representation of floating-point values in Java, this\");\n     LOG.warn(\"may result in an incomplete import.\");\n     LOG.warn(\"You are strongly encouraged to choose an integral split column.\");\n \n     List\u003cInputSplit\u003e splits \u003d new ArrayList\u003cInputSplit\u003e();\n \n     if (results.getString(1) \u003d\u003d null \u0026\u0026 results.getString(2) \u003d\u003d null) {\n       // Range is null to null. Return a null split accordingly.\n       splits.add(new DataDrivenDBInputFormat.DataDrivenDBInputSplit(\n           colName + \" IS NULL\", colName + \" IS NULL\"));\n       return splits;\n     }\n \n     double minVal \u003d results.getDouble(1);\n     double maxVal \u003d results.getDouble(2);\n \n     // Use this as a hint. May need an extra task if the size doesn\u0027t\n     // divide cleanly.\n     int numSplits \u003d conf.getInt(MRJobConfig.NUM_MAPS, 1);\n     double splitSize \u003d (maxVal - minVal) / (double) numSplits;\n \n     if (splitSize \u003c MIN_INCREMENT) {\n       splitSize \u003d MIN_INCREMENT;\n     }\n \n     String lowClausePrefix \u003d colName + \" \u003e\u003d \";\n     String highClausePrefix \u003d colName + \" \u003c \";\n \n     double curLower \u003d minVal;\n     double curUpper \u003d curLower + splitSize;\n \n     while (curUpper \u003c maxVal) {\n       splits.add(new DataDrivenDBInputFormat.DataDrivenDBInputSplit(\n           lowClausePrefix + Double.toString(curLower),\n           highClausePrefix + Double.toString(curUpper)));\n \n       curLower \u003d curUpper;\n       curUpper +\u003d splitSize;\n     }\n \n     // Catch any overage and create the closed interval for the last split.\n     if (curLower \u003c\u003d maxVal || splits.size() \u003d\u003d 1) {\n       splits.add(new DataDrivenDBInputFormat.DataDrivenDBInputSplit(\n-          lowClausePrefix + Double.toString(curUpper),\n+          lowClausePrefix + Double.toString(curLower),\n           colName + \" \u003c\u003d \" + Double.toString(maxVal)));\n     }\n \n     if (results.getString(1) \u003d\u003d null || results.getString(2) \u003d\u003d null) {\n       // At least one extrema is null; add a null split.\n       splits.add(new DataDrivenDBInputFormat.DataDrivenDBInputSplit(\n           colName + \" IS NULL\", colName + \" IS NULL\"));\n     }\n \n     return splits;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public List\u003cInputSplit\u003e split(Configuration conf, ResultSet results, String colName)\n      throws SQLException {\n\n    LOG.warn(\"Generating splits for a floating-point index column. Due to the\");\n    LOG.warn(\"imprecise representation of floating-point values in Java, this\");\n    LOG.warn(\"may result in an incomplete import.\");\n    LOG.warn(\"You are strongly encouraged to choose an integral split column.\");\n\n    List\u003cInputSplit\u003e splits \u003d new ArrayList\u003cInputSplit\u003e();\n\n    if (results.getString(1) \u003d\u003d null \u0026\u0026 results.getString(2) \u003d\u003d null) {\n      // Range is null to null. Return a null split accordingly.\n      splits.add(new DataDrivenDBInputFormat.DataDrivenDBInputSplit(\n          colName + \" IS NULL\", colName + \" IS NULL\"));\n      return splits;\n    }\n\n    double minVal \u003d results.getDouble(1);\n    double maxVal \u003d results.getDouble(2);\n\n    // Use this as a hint. May need an extra task if the size doesn\u0027t\n    // divide cleanly.\n    int numSplits \u003d conf.getInt(MRJobConfig.NUM_MAPS, 1);\n    double splitSize \u003d (maxVal - minVal) / (double) numSplits;\n\n    if (splitSize \u003c MIN_INCREMENT) {\n      splitSize \u003d MIN_INCREMENT;\n    }\n\n    String lowClausePrefix \u003d colName + \" \u003e\u003d \";\n    String highClausePrefix \u003d colName + \" \u003c \";\n\n    double curLower \u003d minVal;\n    double curUpper \u003d curLower + splitSize;\n\n    while (curUpper \u003c maxVal) {\n      splits.add(new DataDrivenDBInputFormat.DataDrivenDBInputSplit(\n          lowClausePrefix + Double.toString(curLower),\n          highClausePrefix + Double.toString(curUpper)));\n\n      curLower \u003d curUpper;\n      curUpper +\u003d splitSize;\n    }\n\n    // Catch any overage and create the closed interval for the last split.\n    if (curLower \u003c\u003d maxVal || splits.size() \u003d\u003d 1) {\n      splits.add(new DataDrivenDBInputFormat.DataDrivenDBInputSplit(\n          lowClausePrefix + Double.toString(curLower),\n          colName + \" \u003c\u003d \" + Double.toString(maxVal)));\n    }\n\n    if (results.getString(1) \u003d\u003d null || results.getString(2) \u003d\u003d null) {\n      // At least one extrema is null; add a null split.\n      splits.add(new DataDrivenDBInputFormat.DataDrivenDBInputSplit(\n          colName + \" IS NULL\", colName + \" IS NULL\"));\n    }\n\n    return splits;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/db/FloatSplitter.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public List\u003cInputSplit\u003e split(Configuration conf, ResultSet results, String colName)\n      throws SQLException {\n\n    LOG.warn(\"Generating splits for a floating-point index column. Due to the\");\n    LOG.warn(\"imprecise representation of floating-point values in Java, this\");\n    LOG.warn(\"may result in an incomplete import.\");\n    LOG.warn(\"You are strongly encouraged to choose an integral split column.\");\n\n    List\u003cInputSplit\u003e splits \u003d new ArrayList\u003cInputSplit\u003e();\n\n    if (results.getString(1) \u003d\u003d null \u0026\u0026 results.getString(2) \u003d\u003d null) {\n      // Range is null to null. Return a null split accordingly.\n      splits.add(new DataDrivenDBInputFormat.DataDrivenDBInputSplit(\n          colName + \" IS NULL\", colName + \" IS NULL\"));\n      return splits;\n    }\n\n    double minVal \u003d results.getDouble(1);\n    double maxVal \u003d results.getDouble(2);\n\n    // Use this as a hint. May need an extra task if the size doesn\u0027t\n    // divide cleanly.\n    int numSplits \u003d conf.getInt(MRJobConfig.NUM_MAPS, 1);\n    double splitSize \u003d (maxVal - minVal) / (double) numSplits;\n\n    if (splitSize \u003c MIN_INCREMENT) {\n      splitSize \u003d MIN_INCREMENT;\n    }\n\n    String lowClausePrefix \u003d colName + \" \u003e\u003d \";\n    String highClausePrefix \u003d colName + \" \u003c \";\n\n    double curLower \u003d minVal;\n    double curUpper \u003d curLower + splitSize;\n\n    while (curUpper \u003c maxVal) {\n      splits.add(new DataDrivenDBInputFormat.DataDrivenDBInputSplit(\n          lowClausePrefix + Double.toString(curLower),\n          highClausePrefix + Double.toString(curUpper)));\n\n      curLower \u003d curUpper;\n      curUpper +\u003d splitSize;\n    }\n\n    // Catch any overage and create the closed interval for the last split.\n    if (curLower \u003c\u003d maxVal || splits.size() \u003d\u003d 1) {\n      splits.add(new DataDrivenDBInputFormat.DataDrivenDBInputSplit(\n          lowClausePrefix + Double.toString(curUpper),\n          colName + \" \u003c\u003d \" + Double.toString(maxVal)));\n    }\n\n    if (results.getString(1) \u003d\u003d null || results.getString(2) \u003d\u003d null) {\n      // At least one extrema is null; add a null split.\n      splits.add(new DataDrivenDBInputFormat.DataDrivenDBInputSplit(\n          colName + \" IS NULL\", colName + \" IS NULL\"));\n    }\n\n    return splits;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/db/FloatSplitter.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/db/FloatSplitter.java",
        "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/db/FloatSplitter.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yfilerename",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "17/08/11 8:02 PM",
      "commitNameOld": "dd86860633d2ed64705b669a75bf318442ed6225",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 0.34,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public List\u003cInputSplit\u003e split(Configuration conf, ResultSet results, String colName)\n      throws SQLException {\n\n    LOG.warn(\"Generating splits for a floating-point index column. Due to the\");\n    LOG.warn(\"imprecise representation of floating-point values in Java, this\");\n    LOG.warn(\"may result in an incomplete import.\");\n    LOG.warn(\"You are strongly encouraged to choose an integral split column.\");\n\n    List\u003cInputSplit\u003e splits \u003d new ArrayList\u003cInputSplit\u003e();\n\n    if (results.getString(1) \u003d\u003d null \u0026\u0026 results.getString(2) \u003d\u003d null) {\n      // Range is null to null. Return a null split accordingly.\n      splits.add(new DataDrivenDBInputFormat.DataDrivenDBInputSplit(\n          colName + \" IS NULL\", colName + \" IS NULL\"));\n      return splits;\n    }\n\n    double minVal \u003d results.getDouble(1);\n    double maxVal \u003d results.getDouble(2);\n\n    // Use this as a hint. May need an extra task if the size doesn\u0027t\n    // divide cleanly.\n    int numSplits \u003d conf.getInt(MRJobConfig.NUM_MAPS, 1);\n    double splitSize \u003d (maxVal - minVal) / (double) numSplits;\n\n    if (splitSize \u003c MIN_INCREMENT) {\n      splitSize \u003d MIN_INCREMENT;\n    }\n\n    String lowClausePrefix \u003d colName + \" \u003e\u003d \";\n    String highClausePrefix \u003d colName + \" \u003c \";\n\n    double curLower \u003d minVal;\n    double curUpper \u003d curLower + splitSize;\n\n    while (curUpper \u003c maxVal) {\n      splits.add(new DataDrivenDBInputFormat.DataDrivenDBInputSplit(\n          lowClausePrefix + Double.toString(curLower),\n          highClausePrefix + Double.toString(curUpper)));\n\n      curLower \u003d curUpper;\n      curUpper +\u003d splitSize;\n    }\n\n    // Catch any overage and create the closed interval for the last split.\n    if (curLower \u003c\u003d maxVal || splits.size() \u003d\u003d 1) {\n      splits.add(new DataDrivenDBInputFormat.DataDrivenDBInputSplit(\n          lowClausePrefix + Double.toString(curUpper),\n          colName + \" \u003c\u003d \" + Double.toString(maxVal)));\n    }\n\n    if (results.getString(1) \u003d\u003d null || results.getString(2) \u003d\u003d null) {\n      // At least one extrema is null; add a null split.\n      splits.add(new DataDrivenDBInputFormat.DataDrivenDBInputSplit(\n          colName + \" IS NULL\", colName + \" IS NULL\"));\n    }\n\n    return splits;\n  }",
      "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/db/FloatSplitter.java",
      "extendedDetails": {
        "oldPath": "mapreduce/src/java/org/apache/hadoop/mapreduce/lib/db/FloatSplitter.java",
        "newPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/db/FloatSplitter.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,59 @@\n+  public List\u003cInputSplit\u003e split(Configuration conf, ResultSet results, String colName)\n+      throws SQLException {\n+\n+    LOG.warn(\"Generating splits for a floating-point index column. Due to the\");\n+    LOG.warn(\"imprecise representation of floating-point values in Java, this\");\n+    LOG.warn(\"may result in an incomplete import.\");\n+    LOG.warn(\"You are strongly encouraged to choose an integral split column.\");\n+\n+    List\u003cInputSplit\u003e splits \u003d new ArrayList\u003cInputSplit\u003e();\n+\n+    if (results.getString(1) \u003d\u003d null \u0026\u0026 results.getString(2) \u003d\u003d null) {\n+      // Range is null to null. Return a null split accordingly.\n+      splits.add(new DataDrivenDBInputFormat.DataDrivenDBInputSplit(\n+          colName + \" IS NULL\", colName + \" IS NULL\"));\n+      return splits;\n+    }\n+\n+    double minVal \u003d results.getDouble(1);\n+    double maxVal \u003d results.getDouble(2);\n+\n+    // Use this as a hint. May need an extra task if the size doesn\u0027t\n+    // divide cleanly.\n+    int numSplits \u003d conf.getInt(MRJobConfig.NUM_MAPS, 1);\n+    double splitSize \u003d (maxVal - minVal) / (double) numSplits;\n+\n+    if (splitSize \u003c MIN_INCREMENT) {\n+      splitSize \u003d MIN_INCREMENT;\n+    }\n+\n+    String lowClausePrefix \u003d colName + \" \u003e\u003d \";\n+    String highClausePrefix \u003d colName + \" \u003c \";\n+\n+    double curLower \u003d minVal;\n+    double curUpper \u003d curLower + splitSize;\n+\n+    while (curUpper \u003c maxVal) {\n+      splits.add(new DataDrivenDBInputFormat.DataDrivenDBInputSplit(\n+          lowClausePrefix + Double.toString(curLower),\n+          highClausePrefix + Double.toString(curUpper)));\n+\n+      curLower \u003d curUpper;\n+      curUpper +\u003d splitSize;\n+    }\n+\n+    // Catch any overage and create the closed interval for the last split.\n+    if (curLower \u003c\u003d maxVal || splits.size() \u003d\u003d 1) {\n+      splits.add(new DataDrivenDBInputFormat.DataDrivenDBInputSplit(\n+          lowClausePrefix + Double.toString(curUpper),\n+          colName + \" \u003c\u003d \" + Double.toString(maxVal)));\n+    }\n+\n+    if (results.getString(1) \u003d\u003d null || results.getString(2) \u003d\u003d null) {\n+      // At least one extrema is null; add a null split.\n+      splits.add(new DataDrivenDBInputFormat.DataDrivenDBInputSplit(\n+          colName + \" IS NULL\", colName + \" IS NULL\"));\n+    }\n+\n+    return splits;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public List\u003cInputSplit\u003e split(Configuration conf, ResultSet results, String colName)\n      throws SQLException {\n\n    LOG.warn(\"Generating splits for a floating-point index column. Due to the\");\n    LOG.warn(\"imprecise representation of floating-point values in Java, this\");\n    LOG.warn(\"may result in an incomplete import.\");\n    LOG.warn(\"You are strongly encouraged to choose an integral split column.\");\n\n    List\u003cInputSplit\u003e splits \u003d new ArrayList\u003cInputSplit\u003e();\n\n    if (results.getString(1) \u003d\u003d null \u0026\u0026 results.getString(2) \u003d\u003d null) {\n      // Range is null to null. Return a null split accordingly.\n      splits.add(new DataDrivenDBInputFormat.DataDrivenDBInputSplit(\n          colName + \" IS NULL\", colName + \" IS NULL\"));\n      return splits;\n    }\n\n    double minVal \u003d results.getDouble(1);\n    double maxVal \u003d results.getDouble(2);\n\n    // Use this as a hint. May need an extra task if the size doesn\u0027t\n    // divide cleanly.\n    int numSplits \u003d conf.getInt(MRJobConfig.NUM_MAPS, 1);\n    double splitSize \u003d (maxVal - minVal) / (double) numSplits;\n\n    if (splitSize \u003c MIN_INCREMENT) {\n      splitSize \u003d MIN_INCREMENT;\n    }\n\n    String lowClausePrefix \u003d colName + \" \u003e\u003d \";\n    String highClausePrefix \u003d colName + \" \u003c \";\n\n    double curLower \u003d minVal;\n    double curUpper \u003d curLower + splitSize;\n\n    while (curUpper \u003c maxVal) {\n      splits.add(new DataDrivenDBInputFormat.DataDrivenDBInputSplit(\n          lowClausePrefix + Double.toString(curLower),\n          highClausePrefix + Double.toString(curUpper)));\n\n      curLower \u003d curUpper;\n      curUpper +\u003d splitSize;\n    }\n\n    // Catch any overage and create the closed interval for the last split.\n    if (curLower \u003c\u003d maxVal || splits.size() \u003d\u003d 1) {\n      splits.add(new DataDrivenDBInputFormat.DataDrivenDBInputSplit(\n          lowClausePrefix + Double.toString(curUpper),\n          colName + \" \u003c\u003d \" + Double.toString(maxVal)));\n    }\n\n    if (results.getString(1) \u003d\u003d null || results.getString(2) \u003d\u003d null) {\n      // At least one extrema is null; add a null split.\n      splits.add(new DataDrivenDBInputFormat.DataDrivenDBInputSplit(\n          colName + \" IS NULL\", colName + \" IS NULL\"));\n    }\n\n    return splits;\n  }",
      "path": "mapreduce/src/java/org/apache/hadoop/mapreduce/lib/db/FloatSplitter.java"
    }
  }
}