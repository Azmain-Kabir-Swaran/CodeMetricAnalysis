{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "INodeFile.java",
  "functionName": "removeLastBlock",
  "functionId": "removeLastBlock___oldblock-Block",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
  "functionStartLine": 419,
  "functionEndLine": 437,
  "numCommitsSeen": 200,
  "timeTaken": 12950,
  "changeHistory": [
    "0faee62a0c8c1b8fd83227babfd00fbc2b26bddf",
    "972782d9568e0849484c027f27c1638ba50ec56e",
    "164cbe643988f878f0f4100a4de51783e5b6738e",
    "e535e0f05b5fbd087c93238deb888cc985254b4c",
    "f4c523b69ba55b1fd35e8995c3011a9f546ac835",
    "7e091de1366f4b57b5433bc19d738199dc05313d",
    "c17439c2ddd921b63b1635e6f1cba634b8da8557",
    "4928f5473394981829e5ffd4b16ea0801baf5c45",
    "97a2396af685838c9fcb31e48573e758c124d8d7",
    "9f2f583f401189c3f4a2687795a9e3e0b288322b",
    "02a4a22b9c0e22c2e7dd6ec85edd5c5a167fe19f",
    "1382ae525c67bf95d8f3a436b547dbc72cfbb177",
    "8df119da214babde03e73243c7ca4cfe6d0ca562",
    "ce68f410b05a58ad05965f32ad7f5b246b363a75",
    "9964a9438687f5bd318e18e447445514d50ab9d5",
    "11c073134afc878619c37c95935d6a3098a21f17",
    "d174f574bafcfefc635c64a47f258b1ce5d5c84e",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "0faee62a0c8c1b8fd83227babfd00fbc2b26bddf": "Ybodychange",
    "972782d9568e0849484c027f27c1638ba50ec56e": "Ybodychange",
    "164cbe643988f878f0f4100a4de51783e5b6738e": "Ymultichange(Yreturntypechange,Ybodychange)",
    "e535e0f05b5fbd087c93238deb888cc985254b4c": "Ymultichange(Yreturntypechange,Ybodychange)",
    "f4c523b69ba55b1fd35e8995c3011a9f546ac835": "Ymultichange(Yreturntypechange,Ybodychange)",
    "7e091de1366f4b57b5433bc19d738199dc05313d": "Ybodychange",
    "c17439c2ddd921b63b1635e6f1cba634b8da8557": "Ymultichange(Yreturntypechange,Ybodychange)",
    "4928f5473394981829e5ffd4b16ea0801baf5c45": "Ybodychange",
    "97a2396af685838c9fcb31e48573e758c124d8d7": "Ymultichange(Yreturntypechange,Ybodychange)",
    "9f2f583f401189c3f4a2687795a9e3e0b288322b": "Ybodychange",
    "02a4a22b9c0e22c2e7dd6ec85edd5c5a167fe19f": "Ymultichange(Yreturntypechange,Ybodychange)",
    "1382ae525c67bf95d8f3a436b547dbc72cfbb177": "Ybodychange",
    "8df119da214babde03e73243c7ca4cfe6d0ca562": "Ybodychange",
    "ce68f410b05a58ad05965f32ad7f5b246b363a75": "Ymultichange(Ymovefromfile,Ybodychange)",
    "9964a9438687f5bd318e18e447445514d50ab9d5": "Yexceptionschange",
    "11c073134afc878619c37c95935d6a3098a21f17": "Ymultichange(Yreturntypechange,Ybodychange)",
    "d174f574bafcfefc635c64a47f258b1ce5d5c84e": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "0faee62a0c8c1b8fd83227babfd00fbc2b26bddf": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10764. Fix INodeFile#getBlocks to not return null. Contributed by Arpit Agarwal.\n",
      "commitDate": "19/08/16 10:13 PM",
      "commitName": "0faee62a0c8c1b8fd83227babfd00fbc2b26bddf",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "22/06/16 11:17 AM",
      "commitNameOld": "17eae9ebb30a3b106c4f6ae0c5374a3ab83abd8a",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 58.46,
      "commitsBetweenForRepo": 541,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,19 +1,19 @@\n   BlockInfo removeLastBlock(Block oldblock) {\n     Preconditions.checkState(isUnderConstruction(),\n         \"file is no longer under construction\");\n-    if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n+    if (blocks.length \u003d\u003d 0) {\n       return null;\n     }\n     int size_1 \u003d blocks.length - 1;\n     if (!blocks[size_1].equals(oldblock)) {\n       return null;\n     }\n \n     BlockInfo lastBlock \u003d blocks[size_1];\n     //copy to a new list\n     BlockInfo[] newlist \u003d new BlockInfo[size_1];\n     System.arraycopy(blocks, 0, newlist, 0, size_1);\n     setBlocks(newlist);\n     lastBlock.delete();\n     return lastBlock;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  BlockInfo removeLastBlock(Block oldblock) {\n    Preconditions.checkState(isUnderConstruction(),\n        \"file is no longer under construction\");\n    if (blocks.length \u003d\u003d 0) {\n      return null;\n    }\n    int size_1 \u003d blocks.length - 1;\n    if (!blocks[size_1].equals(oldblock)) {\n      return null;\n    }\n\n    BlockInfo lastBlock \u003d blocks[size_1];\n    //copy to a new list\n    BlockInfo[] newlist \u003d new BlockInfo[size_1];\n    System.arraycopy(blocks, 0, newlist, 0, size_1);\n    setBlocks(newlist);\n    lastBlock.delete();\n    return lastBlock;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
      "extendedDetails": {}
    },
    "972782d9568e0849484c027f27c1638ba50ec56e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9754. Avoid unnecessary getBlockCollection calls in BlockManager. Contributed by Jing Zhao.\n",
      "commitDate": "12/02/16 11:07 AM",
      "commitName": "972782d9568e0849484c027f27c1638ba50ec56e",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "01/02/16 1:56 PM",
      "commitNameOld": "34ab50ea92370cc7440a8f7649286b148c2fde65",
      "commitAuthorOld": "Yongjun Zhang",
      "daysBetweenCommits": 10.88,
      "commitsBetweenForRepo": 93,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,18 +1,19 @@\n   BlockInfo removeLastBlock(Block oldblock) {\n     Preconditions.checkState(isUnderConstruction(),\n         \"file is no longer under construction\");\n     if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n       return null;\n     }\n     int size_1 \u003d blocks.length - 1;\n     if (!blocks[size_1].equals(oldblock)) {\n       return null;\n     }\n \n-    BlockInfo ucBlock \u003d blocks[size_1];\n+    BlockInfo lastBlock \u003d blocks[size_1];\n     //copy to a new list\n     BlockInfo[] newlist \u003d new BlockInfo[size_1];\n     System.arraycopy(blocks, 0, newlist, 0, size_1);\n     setBlocks(newlist);\n-    return ucBlock;\n+    lastBlock.delete();\n+    return lastBlock;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  BlockInfo removeLastBlock(Block oldblock) {\n    Preconditions.checkState(isUnderConstruction(),\n        \"file is no longer under construction\");\n    if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n      return null;\n    }\n    int size_1 \u003d blocks.length - 1;\n    if (!blocks[size_1].equals(oldblock)) {\n      return null;\n    }\n\n    BlockInfo lastBlock \u003d blocks[size_1];\n    //copy to a new list\n    BlockInfo[] newlist \u003d new BlockInfo[size_1];\n    System.arraycopy(blocks, 0, newlist, 0, size_1);\n    setBlocks(newlist);\n    lastBlock.delete();\n    return lastBlock;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
      "extendedDetails": {}
    },
    "164cbe643988f878f0f4100a4de51783e5b6738e": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-8909. Erasure coding: update BlockInfoContiguousUC and BlockInfoStripedUC to use BlockUnderConstructionFeature. Contributed by Jing Zhao.\n",
      "commitDate": "27/08/15 1:02 AM",
      "commitName": "164cbe643988f878f0f4100a4de51783e5b6738e",
      "commitAuthor": "Walter Su",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-8909. Erasure coding: update BlockInfoContiguousUC and BlockInfoStripedUC to use BlockUnderConstructionFeature. Contributed by Jing Zhao.\n",
          "commitDate": "27/08/15 1:02 AM",
          "commitName": "164cbe643988f878f0f4100a4de51783e5b6738e",
          "commitAuthor": "Walter Su",
          "commitDateOld": "24/08/15 12:59 PM",
          "commitNameOld": "6b6a63bbbda920315d3d24b61ed3344a78a981b6",
          "commitAuthorOld": "",
          "daysBetweenCommits": 2.5,
          "commitsBetweenForRepo": 2,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,19 +1,18 @@\n-  BlockInfoUnderConstruction removeLastBlock(Block oldblock) {\n+  BlockInfo removeLastBlock(Block oldblock) {\n     Preconditions.checkState(isUnderConstruction(),\n         \"file is no longer under construction\");\n     if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n       return null;\n     }\n     int size_1 \u003d blocks.length - 1;\n     if (!blocks[size_1].equals(oldblock)) {\n       return null;\n     }\n \n-    BlockInfoUnderConstruction uc \u003d\n-        (BlockInfoUnderConstruction)blocks[size_1];\n+    BlockInfo ucBlock \u003d blocks[size_1];\n     //copy to a new list\n     BlockInfo[] newlist \u003d new BlockInfo[size_1];\n     System.arraycopy(blocks, 0, newlist, 0, size_1);\n     setBlocks(newlist);\n-    return uc;\n+    return ucBlock;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  BlockInfo removeLastBlock(Block oldblock) {\n    Preconditions.checkState(isUnderConstruction(),\n        \"file is no longer under construction\");\n    if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n      return null;\n    }\n    int size_1 \u003d blocks.length - 1;\n    if (!blocks[size_1].equals(oldblock)) {\n      return null;\n    }\n\n    BlockInfo ucBlock \u003d blocks[size_1];\n    //copy to a new list\n    BlockInfo[] newlist \u003d new BlockInfo[size_1];\n    System.arraycopy(blocks, 0, newlist, 0, size_1);\n    setBlocks(newlist);\n    return ucBlock;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
          "extendedDetails": {
            "oldValue": "BlockInfoUnderConstruction",
            "newValue": "BlockInfo"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-8909. Erasure coding: update BlockInfoContiguousUC and BlockInfoStripedUC to use BlockUnderConstructionFeature. Contributed by Jing Zhao.\n",
          "commitDate": "27/08/15 1:02 AM",
          "commitName": "164cbe643988f878f0f4100a4de51783e5b6738e",
          "commitAuthor": "Walter Su",
          "commitDateOld": "24/08/15 12:59 PM",
          "commitNameOld": "6b6a63bbbda920315d3d24b61ed3344a78a981b6",
          "commitAuthorOld": "",
          "daysBetweenCommits": 2.5,
          "commitsBetweenForRepo": 2,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,19 +1,18 @@\n-  BlockInfoUnderConstruction removeLastBlock(Block oldblock) {\n+  BlockInfo removeLastBlock(Block oldblock) {\n     Preconditions.checkState(isUnderConstruction(),\n         \"file is no longer under construction\");\n     if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n       return null;\n     }\n     int size_1 \u003d blocks.length - 1;\n     if (!blocks[size_1].equals(oldblock)) {\n       return null;\n     }\n \n-    BlockInfoUnderConstruction uc \u003d\n-        (BlockInfoUnderConstruction)blocks[size_1];\n+    BlockInfo ucBlock \u003d blocks[size_1];\n     //copy to a new list\n     BlockInfo[] newlist \u003d new BlockInfo[size_1];\n     System.arraycopy(blocks, 0, newlist, 0, size_1);\n     setBlocks(newlist);\n-    return uc;\n+    return ucBlock;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  BlockInfo removeLastBlock(Block oldblock) {\n    Preconditions.checkState(isUnderConstruction(),\n        \"file is no longer under construction\");\n    if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n      return null;\n    }\n    int size_1 \u003d blocks.length - 1;\n    if (!blocks[size_1].equals(oldblock)) {\n      return null;\n    }\n\n    BlockInfo ucBlock \u003d blocks[size_1];\n    //copy to a new list\n    BlockInfo[] newlist \u003d new BlockInfo[size_1];\n    System.arraycopy(blocks, 0, newlist, 0, size_1);\n    setBlocks(newlist);\n    return ucBlock;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
          "extendedDetails": {}
        }
      ]
    },
    "e535e0f05b5fbd087c93238deb888cc985254b4c": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-8801. Convert BlockInfoUnderConstruction as a feature. Contributed by Jing Zhao.\n",
      "commitDate": "17/08/15 11:28 AM",
      "commitName": "e535e0f05b5fbd087c93238deb888cc985254b4c",
      "commitAuthor": "Haohui Mai",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-8801. Convert BlockInfoUnderConstruction as a feature. Contributed by Jing Zhao.\n",
          "commitDate": "17/08/15 11:28 AM",
          "commitName": "e535e0f05b5fbd087c93238deb888cc985254b4c",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "06/08/15 10:21 AM",
          "commitNameOld": "f4c523b69ba55b1fd35e8995c3011a9f546ac835",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 11.05,
          "commitsBetweenForRepo": 46,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,19 +1,18 @@\n-  BlockInfoContiguousUnderConstruction removeLastBlock(Block oldblock) {\n+  BlockInfo removeLastBlock(Block oldblock) {\n     Preconditions.checkState(isUnderConstruction(),\n         \"file is no longer under construction\");\n     if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n       return null;\n     }\n     int size_1 \u003d blocks.length - 1;\n     if (!blocks[size_1].equals(oldblock)) {\n       return null;\n     }\n \n-    BlockInfoContiguousUnderConstruction uc \u003d\n-        (BlockInfoContiguousUnderConstruction)blocks[size_1];\n+    BlockInfo ucBlock \u003d blocks[size_1];\n     //copy to a new list\n     BlockInfo[] newlist \u003d new BlockInfo[size_1];\n     System.arraycopy(blocks, 0, newlist, 0, size_1);\n     setBlocks(newlist);\n-    return uc;\n+    return ucBlock;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  BlockInfo removeLastBlock(Block oldblock) {\n    Preconditions.checkState(isUnderConstruction(),\n        \"file is no longer under construction\");\n    if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n      return null;\n    }\n    int size_1 \u003d blocks.length - 1;\n    if (!blocks[size_1].equals(oldblock)) {\n      return null;\n    }\n\n    BlockInfo ucBlock \u003d blocks[size_1];\n    //copy to a new list\n    BlockInfo[] newlist \u003d new BlockInfo[size_1];\n    System.arraycopy(blocks, 0, newlist, 0, size_1);\n    setBlocks(newlist);\n    return ucBlock;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
          "extendedDetails": {
            "oldValue": "BlockInfoContiguousUnderConstruction",
            "newValue": "BlockInfo"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-8801. Convert BlockInfoUnderConstruction as a feature. Contributed by Jing Zhao.\n",
          "commitDate": "17/08/15 11:28 AM",
          "commitName": "e535e0f05b5fbd087c93238deb888cc985254b4c",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "06/08/15 10:21 AM",
          "commitNameOld": "f4c523b69ba55b1fd35e8995c3011a9f546ac835",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 11.05,
          "commitsBetweenForRepo": 46,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,19 +1,18 @@\n-  BlockInfoContiguousUnderConstruction removeLastBlock(Block oldblock) {\n+  BlockInfo removeLastBlock(Block oldblock) {\n     Preconditions.checkState(isUnderConstruction(),\n         \"file is no longer under construction\");\n     if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n       return null;\n     }\n     int size_1 \u003d blocks.length - 1;\n     if (!blocks[size_1].equals(oldblock)) {\n       return null;\n     }\n \n-    BlockInfoContiguousUnderConstruction uc \u003d\n-        (BlockInfoContiguousUnderConstruction)blocks[size_1];\n+    BlockInfo ucBlock \u003d blocks[size_1];\n     //copy to a new list\n     BlockInfo[] newlist \u003d new BlockInfo[size_1];\n     System.arraycopy(blocks, 0, newlist, 0, size_1);\n     setBlocks(newlist);\n-    return uc;\n+    return ucBlock;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  BlockInfo removeLastBlock(Block oldblock) {\n    Preconditions.checkState(isUnderConstruction(),\n        \"file is no longer under construction\");\n    if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n      return null;\n    }\n    int size_1 \u003d blocks.length - 1;\n    if (!blocks[size_1].equals(oldblock)) {\n      return null;\n    }\n\n    BlockInfo ucBlock \u003d blocks[size_1];\n    //copy to a new list\n    BlockInfo[] newlist \u003d new BlockInfo[size_1];\n    System.arraycopy(blocks, 0, newlist, 0, size_1);\n    setBlocks(newlist);\n    return ucBlock;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
          "extendedDetails": {}
        }
      ]
    },
    "f4c523b69ba55b1fd35e8995c3011a9f546ac835": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": "Revert \"HDFS-8499. Refactor BlockInfo class hierarchy with static helper class. Contributed by Zhe Zhang.\"\n\nThis reverts commit c17439c2ddd921b63b1635e6f1cba634b8da8557.\n",
      "commitDate": "06/08/15 10:21 AM",
      "commitName": "f4c523b69ba55b1fd35e8995c3011a9f546ac835",
      "commitAuthor": "Jing Zhao",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "Revert \"HDFS-8499. Refactor BlockInfo class hierarchy with static helper class. Contributed by Zhe Zhang.\"\n\nThis reverts commit c17439c2ddd921b63b1635e6f1cba634b8da8557.\n",
          "commitDate": "06/08/15 10:21 AM",
          "commitName": "f4c523b69ba55b1fd35e8995c3011a9f546ac835",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "10/07/15 2:15 PM",
          "commitNameOld": "47f4c54106ebb234a7d3dc71320aa584ecba161a",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 26.84,
          "commitsBetweenForRepo": 152,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,19 +1,19 @@\n-  BlockInfoUnderConstruction removeLastBlock(Block oldblock) {\n+  BlockInfoContiguousUnderConstruction removeLastBlock(Block oldblock) {\n     Preconditions.checkState(isUnderConstruction(),\n         \"file is no longer under construction\");\n     if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n       return null;\n     }\n     int size_1 \u003d blocks.length - 1;\n     if (!blocks[size_1].equals(oldblock)) {\n       return null;\n     }\n \n-    BlockInfoUnderConstruction uc \u003d\n-        (BlockInfoUnderConstruction)blocks[size_1];\n+    BlockInfoContiguousUnderConstruction uc \u003d\n+        (BlockInfoContiguousUnderConstruction)blocks[size_1];\n     //copy to a new list\n     BlockInfo[] newlist \u003d new BlockInfo[size_1];\n     System.arraycopy(blocks, 0, newlist, 0, size_1);\n     setBlocks(newlist);\n     return uc;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  BlockInfoContiguousUnderConstruction removeLastBlock(Block oldblock) {\n    Preconditions.checkState(isUnderConstruction(),\n        \"file is no longer under construction\");\n    if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n      return null;\n    }\n    int size_1 \u003d blocks.length - 1;\n    if (!blocks[size_1].equals(oldblock)) {\n      return null;\n    }\n\n    BlockInfoContiguousUnderConstruction uc \u003d\n        (BlockInfoContiguousUnderConstruction)blocks[size_1];\n    //copy to a new list\n    BlockInfo[] newlist \u003d new BlockInfo[size_1];\n    System.arraycopy(blocks, 0, newlist, 0, size_1);\n    setBlocks(newlist);\n    return uc;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
          "extendedDetails": {
            "oldValue": "BlockInfoUnderConstruction",
            "newValue": "BlockInfoContiguousUnderConstruction"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "Revert \"HDFS-8499. Refactor BlockInfo class hierarchy with static helper class. Contributed by Zhe Zhang.\"\n\nThis reverts commit c17439c2ddd921b63b1635e6f1cba634b8da8557.\n",
          "commitDate": "06/08/15 10:21 AM",
          "commitName": "f4c523b69ba55b1fd35e8995c3011a9f546ac835",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "10/07/15 2:15 PM",
          "commitNameOld": "47f4c54106ebb234a7d3dc71320aa584ecba161a",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 26.84,
          "commitsBetweenForRepo": 152,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,19 +1,19 @@\n-  BlockInfoUnderConstruction removeLastBlock(Block oldblock) {\n+  BlockInfoContiguousUnderConstruction removeLastBlock(Block oldblock) {\n     Preconditions.checkState(isUnderConstruction(),\n         \"file is no longer under construction\");\n     if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n       return null;\n     }\n     int size_1 \u003d blocks.length - 1;\n     if (!blocks[size_1].equals(oldblock)) {\n       return null;\n     }\n \n-    BlockInfoUnderConstruction uc \u003d\n-        (BlockInfoUnderConstruction)blocks[size_1];\n+    BlockInfoContiguousUnderConstruction uc \u003d\n+        (BlockInfoContiguousUnderConstruction)blocks[size_1];\n     //copy to a new list\n     BlockInfo[] newlist \u003d new BlockInfo[size_1];\n     System.arraycopy(blocks, 0, newlist, 0, size_1);\n     setBlocks(newlist);\n     return uc;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  BlockInfoContiguousUnderConstruction removeLastBlock(Block oldblock) {\n    Preconditions.checkState(isUnderConstruction(),\n        \"file is no longer under construction\");\n    if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n      return null;\n    }\n    int size_1 \u003d blocks.length - 1;\n    if (!blocks[size_1].equals(oldblock)) {\n      return null;\n    }\n\n    BlockInfoContiguousUnderConstruction uc \u003d\n        (BlockInfoContiguousUnderConstruction)blocks[size_1];\n    //copy to a new list\n    BlockInfo[] newlist \u003d new BlockInfo[size_1];\n    System.arraycopy(blocks, 0, newlist, 0, size_1);\n    setBlocks(newlist);\n    return uc;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
          "extendedDetails": {}
        }
      ]
    },
    "7e091de1366f4b57b5433bc19d738199dc05313d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8058. Erasure coding: use BlockInfo[] for both striped and contiguous blocks in INodeFile. Contributed by Zhe Zhang and Yi Liu.\n",
      "commitDate": "15/07/15 9:49 AM",
      "commitName": "7e091de1366f4b57b5433bc19d738199dc05313d",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "06/07/15 4:14 AM",
      "commitNameOld": "ee01a09500224136464f2c3e0a5d9ba53242d93f",
      "commitAuthorOld": "yliu",
      "daysBetweenCommits": 9.23,
      "commitsBetweenForRepo": 11,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,25 +1,19 @@\n   BlockInfoUnderConstruction removeLastBlock(Block oldblock) {\n     Preconditions.checkState(isUnderConstruction(),\n         \"file is no longer under construction\");\n-    FileWithStripedBlocksFeature sb \u003d getStripedBlocksFeature();\n-    if (sb \u003d\u003d null) {\n-      if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n-        return null;\n-      }\n-      int size_1 \u003d blocks.length - 1;\n-      if (!blocks[size_1].equals(oldblock)) {\n-        return null;\n-      }\n-\n-      BlockInfoContiguousUnderConstruction uc \u003d\n-          (BlockInfoContiguousUnderConstruction)blocks[size_1];\n-      //copy to a new list\n-      BlockInfoContiguous[] newlist \u003d new BlockInfoContiguous[size_1];\n-      System.arraycopy(blocks, 0, newlist, 0, size_1);\n-      setContiguousBlocks(newlist);\n-      return uc;\n-    } else {\n-      assert hasNoContiguousBlock();\n-      return sb.removeLastBlock(oldblock);\n+    if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n+      return null;\n     }\n+    int size_1 \u003d blocks.length - 1;\n+    if (!blocks[size_1].equals(oldblock)) {\n+      return null;\n+    }\n+\n+    BlockInfoUnderConstruction uc \u003d\n+        (BlockInfoUnderConstruction)blocks[size_1];\n+    //copy to a new list\n+    BlockInfo[] newlist \u003d new BlockInfo[size_1];\n+    System.arraycopy(blocks, 0, newlist, 0, size_1);\n+    setBlocks(newlist);\n+    return uc;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  BlockInfoUnderConstruction removeLastBlock(Block oldblock) {\n    Preconditions.checkState(isUnderConstruction(),\n        \"file is no longer under construction\");\n    if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n      return null;\n    }\n    int size_1 \u003d blocks.length - 1;\n    if (!blocks[size_1].equals(oldblock)) {\n      return null;\n    }\n\n    BlockInfoUnderConstruction uc \u003d\n        (BlockInfoUnderConstruction)blocks[size_1];\n    //copy to a new list\n    BlockInfo[] newlist \u003d new BlockInfo[size_1];\n    System.arraycopy(blocks, 0, newlist, 0, size_1);\n    setBlocks(newlist);\n    return uc;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
      "extendedDetails": {}
    },
    "c17439c2ddd921b63b1635e6f1cba634b8da8557": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-8499. Refactor BlockInfo class hierarchy with static helper class. Contributed by Zhe Zhang.\n",
      "commitDate": "12/06/15 11:38 AM",
      "commitName": "c17439c2ddd921b63b1635e6f1cba634b8da8557",
      "commitAuthor": "Andrew Wang",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-8499. Refactor BlockInfo class hierarchy with static helper class. Contributed by Zhe Zhang.\n",
          "commitDate": "12/06/15 11:38 AM",
          "commitName": "c17439c2ddd921b63b1635e6f1cba634b8da8557",
          "commitAuthor": "Andrew Wang",
          "commitDateOld": "27/05/15 3:42 PM",
          "commitNameOld": "4928f5473394981829e5ffd4b16ea0801baf5c45",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 15.83,
          "commitsBetweenForRepo": 122,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,19 +1,19 @@\n-  BlockInfoContiguousUnderConstruction removeLastBlock(Block oldblock) {\n+  BlockInfoUnderConstruction removeLastBlock(Block oldblock) {\n     Preconditions.checkState(isUnderConstruction(),\n         \"file is no longer under construction\");\n     if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n       return null;\n     }\n     int size_1 \u003d blocks.length - 1;\n     if (!blocks[size_1].equals(oldblock)) {\n       return null;\n     }\n \n-    BlockInfoContiguousUnderConstruction uc \u003d\n-        (BlockInfoContiguousUnderConstruction)blocks[size_1];\n+    BlockInfoUnderConstruction uc \u003d\n+        (BlockInfoUnderConstruction)blocks[size_1];\n     //copy to a new list\n     BlockInfo[] newlist \u003d new BlockInfo[size_1];\n     System.arraycopy(blocks, 0, newlist, 0, size_1);\n     setBlocks(newlist);\n     return uc;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  BlockInfoUnderConstruction removeLastBlock(Block oldblock) {\n    Preconditions.checkState(isUnderConstruction(),\n        \"file is no longer under construction\");\n    if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n      return null;\n    }\n    int size_1 \u003d blocks.length - 1;\n    if (!blocks[size_1].equals(oldblock)) {\n      return null;\n    }\n\n    BlockInfoUnderConstruction uc \u003d\n        (BlockInfoUnderConstruction)blocks[size_1];\n    //copy to a new list\n    BlockInfo[] newlist \u003d new BlockInfo[size_1];\n    System.arraycopy(blocks, 0, newlist, 0, size_1);\n    setBlocks(newlist);\n    return uc;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
          "extendedDetails": {
            "oldValue": "BlockInfoContiguousUnderConstruction",
            "newValue": "BlockInfoUnderConstruction"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-8499. Refactor BlockInfo class hierarchy with static helper class. Contributed by Zhe Zhang.\n",
          "commitDate": "12/06/15 11:38 AM",
          "commitName": "c17439c2ddd921b63b1635e6f1cba634b8da8557",
          "commitAuthor": "Andrew Wang",
          "commitDateOld": "27/05/15 3:42 PM",
          "commitNameOld": "4928f5473394981829e5ffd4b16ea0801baf5c45",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 15.83,
          "commitsBetweenForRepo": 122,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,19 +1,19 @@\n-  BlockInfoContiguousUnderConstruction removeLastBlock(Block oldblock) {\n+  BlockInfoUnderConstruction removeLastBlock(Block oldblock) {\n     Preconditions.checkState(isUnderConstruction(),\n         \"file is no longer under construction\");\n     if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n       return null;\n     }\n     int size_1 \u003d blocks.length - 1;\n     if (!blocks[size_1].equals(oldblock)) {\n       return null;\n     }\n \n-    BlockInfoContiguousUnderConstruction uc \u003d\n-        (BlockInfoContiguousUnderConstruction)blocks[size_1];\n+    BlockInfoUnderConstruction uc \u003d\n+        (BlockInfoUnderConstruction)blocks[size_1];\n     //copy to a new list\n     BlockInfo[] newlist \u003d new BlockInfo[size_1];\n     System.arraycopy(blocks, 0, newlist, 0, size_1);\n     setBlocks(newlist);\n     return uc;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  BlockInfoUnderConstruction removeLastBlock(Block oldblock) {\n    Preconditions.checkState(isUnderConstruction(),\n        \"file is no longer under construction\");\n    if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n      return null;\n    }\n    int size_1 \u003d blocks.length - 1;\n    if (!blocks[size_1].equals(oldblock)) {\n      return null;\n    }\n\n    BlockInfoUnderConstruction uc \u003d\n        (BlockInfoUnderConstruction)blocks[size_1];\n    //copy to a new list\n    BlockInfo[] newlist \u003d new BlockInfo[size_1];\n    System.arraycopy(blocks, 0, newlist, 0, size_1);\n    setBlocks(newlist);\n    return uc;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
          "extendedDetails": {}
        }
      ]
    },
    "4928f5473394981829e5ffd4b16ea0801baf5c45": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8482. Rename BlockInfoContiguous to BlockInfo. Contributed by Zhe Zhang.\n",
      "commitDate": "27/05/15 3:42 PM",
      "commitName": "4928f5473394981829e5ffd4b16ea0801baf5c45",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "13/05/15 9:50 PM",
      "commitNameOld": "b2c85db86c9a62b0a03ee87547265077f664970a",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 13.74,
      "commitsBetweenForRepo": 96,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,19 +1,19 @@\n   BlockInfoContiguousUnderConstruction removeLastBlock(Block oldblock) {\n     Preconditions.checkState(isUnderConstruction(),\n         \"file is no longer under construction\");\n     if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n       return null;\n     }\n     int size_1 \u003d blocks.length - 1;\n     if (!blocks[size_1].equals(oldblock)) {\n       return null;\n     }\n \n     BlockInfoContiguousUnderConstruction uc \u003d\n         (BlockInfoContiguousUnderConstruction)blocks[size_1];\n     //copy to a new list\n-    BlockInfoContiguous[] newlist \u003d new BlockInfoContiguous[size_1];\n+    BlockInfo[] newlist \u003d new BlockInfo[size_1];\n     System.arraycopy(blocks, 0, newlist, 0, size_1);\n     setBlocks(newlist);\n     return uc;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  BlockInfoContiguousUnderConstruction removeLastBlock(Block oldblock) {\n    Preconditions.checkState(isUnderConstruction(),\n        \"file is no longer under construction\");\n    if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n      return null;\n    }\n    int size_1 \u003d blocks.length - 1;\n    if (!blocks[size_1].equals(oldblock)) {\n      return null;\n    }\n\n    BlockInfoContiguousUnderConstruction uc \u003d\n        (BlockInfoContiguousUnderConstruction)blocks[size_1];\n    //copy to a new list\n    BlockInfo[] newlist \u003d new BlockInfo[size_1];\n    System.arraycopy(blocks, 0, newlist, 0, size_1);\n    setBlocks(newlist);\n    return uc;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
      "extendedDetails": {}
    },
    "97a2396af685838c9fcb31e48573e758c124d8d7": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-8372. Erasure coding: compute storage type quotas for striped files, to be consistent with HDFS-8327. Contributed by Zhe Zhang.\n",
      "commitDate": "26/05/15 12:01 PM",
      "commitName": "97a2396af685838c9fcb31e48573e758c124d8d7",
      "commitAuthor": "Jing Zhao",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-8372. Erasure coding: compute storage type quotas for striped files, to be consistent with HDFS-8327. Contributed by Zhe Zhang.\n",
          "commitDate": "26/05/15 12:01 PM",
          "commitName": "97a2396af685838c9fcb31e48573e758c124d8d7",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "26/05/15 12:01 PM",
          "commitNameOld": "6bacaa9a5233cbad7f311ccd9d8f8dc9375c732d",
          "commitAuthorOld": "Zhe Zhang",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 2,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,25 +1,25 @@\n-  BlockInfoContiguousUnderConstruction removeLastBlock(Block oldblock) {\n+  BlockInfoUnderConstruction removeLastBlock(Block oldblock) {\n     Preconditions.checkState(isUnderConstruction(),\n         \"file is no longer under construction\");\n     FileWithStripedBlocksFeature sb \u003d getStripedBlocksFeature();\n     if (sb \u003d\u003d null) {\n       if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n         return null;\n       }\n       int size_1 \u003d blocks.length - 1;\n       if (!blocks[size_1].equals(oldblock)) {\n         return null;\n       }\n \n       BlockInfoContiguousUnderConstruction uc \u003d\n           (BlockInfoContiguousUnderConstruction)blocks[size_1];\n       //copy to a new list\n       BlockInfoContiguous[] newlist \u003d new BlockInfoContiguous[size_1];\n       System.arraycopy(blocks, 0, newlist, 0, size_1);\n       setContiguousBlocks(newlist);\n       return uc;\n     } else {\n       assert hasNoContiguousBlock();\n-      return null;\n+      return sb.removeLastBlock(oldblock);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  BlockInfoUnderConstruction removeLastBlock(Block oldblock) {\n    Preconditions.checkState(isUnderConstruction(),\n        \"file is no longer under construction\");\n    FileWithStripedBlocksFeature sb \u003d getStripedBlocksFeature();\n    if (sb \u003d\u003d null) {\n      if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n        return null;\n      }\n      int size_1 \u003d blocks.length - 1;\n      if (!blocks[size_1].equals(oldblock)) {\n        return null;\n      }\n\n      BlockInfoContiguousUnderConstruction uc \u003d\n          (BlockInfoContiguousUnderConstruction)blocks[size_1];\n      //copy to a new list\n      BlockInfoContiguous[] newlist \u003d new BlockInfoContiguous[size_1];\n      System.arraycopy(blocks, 0, newlist, 0, size_1);\n      setContiguousBlocks(newlist);\n      return uc;\n    } else {\n      assert hasNoContiguousBlock();\n      return sb.removeLastBlock(oldblock);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
          "extendedDetails": {
            "oldValue": "BlockInfoContiguousUnderConstruction",
            "newValue": "BlockInfoUnderConstruction"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-8372. Erasure coding: compute storage type quotas for striped files, to be consistent with HDFS-8327. Contributed by Zhe Zhang.\n",
          "commitDate": "26/05/15 12:01 PM",
          "commitName": "97a2396af685838c9fcb31e48573e758c124d8d7",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "26/05/15 12:01 PM",
          "commitNameOld": "6bacaa9a5233cbad7f311ccd9d8f8dc9375c732d",
          "commitAuthorOld": "Zhe Zhang",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 2,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,25 +1,25 @@\n-  BlockInfoContiguousUnderConstruction removeLastBlock(Block oldblock) {\n+  BlockInfoUnderConstruction removeLastBlock(Block oldblock) {\n     Preconditions.checkState(isUnderConstruction(),\n         \"file is no longer under construction\");\n     FileWithStripedBlocksFeature sb \u003d getStripedBlocksFeature();\n     if (sb \u003d\u003d null) {\n       if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n         return null;\n       }\n       int size_1 \u003d blocks.length - 1;\n       if (!blocks[size_1].equals(oldblock)) {\n         return null;\n       }\n \n       BlockInfoContiguousUnderConstruction uc \u003d\n           (BlockInfoContiguousUnderConstruction)blocks[size_1];\n       //copy to a new list\n       BlockInfoContiguous[] newlist \u003d new BlockInfoContiguous[size_1];\n       System.arraycopy(blocks, 0, newlist, 0, size_1);\n       setContiguousBlocks(newlist);\n       return uc;\n     } else {\n       assert hasNoContiguousBlock();\n-      return null;\n+      return sb.removeLastBlock(oldblock);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  BlockInfoUnderConstruction removeLastBlock(Block oldblock) {\n    Preconditions.checkState(isUnderConstruction(),\n        \"file is no longer under construction\");\n    FileWithStripedBlocksFeature sb \u003d getStripedBlocksFeature();\n    if (sb \u003d\u003d null) {\n      if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n        return null;\n      }\n      int size_1 \u003d blocks.length - 1;\n      if (!blocks[size_1].equals(oldblock)) {\n        return null;\n      }\n\n      BlockInfoContiguousUnderConstruction uc \u003d\n          (BlockInfoContiguousUnderConstruction)blocks[size_1];\n      //copy to a new list\n      BlockInfoContiguous[] newlist \u003d new BlockInfoContiguous[size_1];\n      System.arraycopy(blocks, 0, newlist, 0, size_1);\n      setContiguousBlocks(newlist);\n      return uc;\n    } else {\n      assert hasNoContiguousBlock();\n      return sb.removeLastBlock(oldblock);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
          "extendedDetails": {}
        }
      ]
    },
    "9f2f583f401189c3f4a2687795a9e3e0b288322b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7749. Erasure Coding: Add striped block support in INodeFile. Contributed by Jing Zhao.\n",
      "commitDate": "26/05/15 11:07 AM",
      "commitName": "9f2f583f401189c3f4a2687795a9e3e0b288322b",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "26/05/15 11:03 AM",
      "commitNameOld": "bc2833b1c91e107d090619d755c584f6eae82327",
      "commitAuthorOld": "Zhe Zhang",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 8,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,19 +1,25 @@\n   BlockInfoContiguousUnderConstruction removeLastBlock(Block oldblock) {\n     Preconditions.checkState(isUnderConstruction(),\n         \"file is no longer under construction\");\n-    if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n-      return null;\n-    }\n-    int size_1 \u003d blocks.length - 1;\n-    if (!blocks[size_1].equals(oldblock)) {\n-      return null;\n-    }\n+    FileWithStripedBlocksFeature sb \u003d getStripedBlocksFeature();\n+    if (sb \u003d\u003d null) {\n+      if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n+        return null;\n+      }\n+      int size_1 \u003d blocks.length - 1;\n+      if (!blocks[size_1].equals(oldblock)) {\n+        return null;\n+      }\n \n-    BlockInfoContiguousUnderConstruction uc \u003d\n-        (BlockInfoContiguousUnderConstruction)blocks[size_1];\n-    //copy to a new list\n-    BlockInfoContiguous[] newlist \u003d new BlockInfoContiguous[size_1];\n-    System.arraycopy(blocks, 0, newlist, 0, size_1);\n-    setBlocks(newlist);\n-    return uc;\n+      BlockInfoContiguousUnderConstruction uc \u003d\n+          (BlockInfoContiguousUnderConstruction)blocks[size_1];\n+      //copy to a new list\n+      BlockInfoContiguous[] newlist \u003d new BlockInfoContiguous[size_1];\n+      System.arraycopy(blocks, 0, newlist, 0, size_1);\n+      setContiguousBlocks(newlist);\n+      return uc;\n+    } else {\n+      assert hasNoContiguousBlock();\n+      return null;\n+    }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  BlockInfoContiguousUnderConstruction removeLastBlock(Block oldblock) {\n    Preconditions.checkState(isUnderConstruction(),\n        \"file is no longer under construction\");\n    FileWithStripedBlocksFeature sb \u003d getStripedBlocksFeature();\n    if (sb \u003d\u003d null) {\n      if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n        return null;\n      }\n      int size_1 \u003d blocks.length - 1;\n      if (!blocks[size_1].equals(oldblock)) {\n        return null;\n      }\n\n      BlockInfoContiguousUnderConstruction uc \u003d\n          (BlockInfoContiguousUnderConstruction)blocks[size_1];\n      //copy to a new list\n      BlockInfoContiguous[] newlist \u003d new BlockInfoContiguous[size_1];\n      System.arraycopy(blocks, 0, newlist, 0, size_1);\n      setContiguousBlocks(newlist);\n      return uc;\n    } else {\n      assert hasNoContiguousBlock();\n      return null;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
      "extendedDetails": {}
    },
    "02a4a22b9c0e22c2e7dd6ec85edd5c5a167fe19f": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-8327. Compute storage type quotas in INodeFile.computeQuotaDeltaForTruncate(). Contributed by Haohui Mai.\n",
      "commitDate": "08/05/15 11:09 PM",
      "commitName": "02a4a22b9c0e22c2e7dd6ec85edd5c5a167fe19f",
      "commitAuthor": "Haohui Mai",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-8327. Compute storage type quotas in INodeFile.computeQuotaDeltaForTruncate(). Contributed by Haohui Mai.\n",
          "commitDate": "08/05/15 11:09 PM",
          "commitName": "02a4a22b9c0e22c2e7dd6ec85edd5c5a167fe19f",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "08/05/15 11:04 PM",
          "commitNameOld": "00fe1ed3a4b3ee35fe24be257ec36445d2f44d63",
          "commitAuthorOld": "Haohui Mai",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 2,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,17 +1,19 @@\n-  boolean removeLastBlock(Block oldblock) {\n+  BlockInfoContiguousUnderConstruction removeLastBlock(Block oldblock) {\n     Preconditions.checkState(isUnderConstruction(),\n         \"file is no longer under construction\");\n     if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n-      return false;\n+      return null;\n     }\n     int size_1 \u003d blocks.length - 1;\n     if (!blocks[size_1].equals(oldblock)) {\n-      return false;\n+      return null;\n     }\n \n+    BlockInfoContiguousUnderConstruction uc \u003d\n+        (BlockInfoContiguousUnderConstruction)blocks[size_1];\n     //copy to a new list\n     BlockInfoContiguous[] newlist \u003d new BlockInfoContiguous[size_1];\n     System.arraycopy(blocks, 0, newlist, 0, size_1);\n     setBlocks(newlist);\n-    return true;\n+    return uc;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  BlockInfoContiguousUnderConstruction removeLastBlock(Block oldblock) {\n    Preconditions.checkState(isUnderConstruction(),\n        \"file is no longer under construction\");\n    if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n      return null;\n    }\n    int size_1 \u003d blocks.length - 1;\n    if (!blocks[size_1].equals(oldblock)) {\n      return null;\n    }\n\n    BlockInfoContiguousUnderConstruction uc \u003d\n        (BlockInfoContiguousUnderConstruction)blocks[size_1];\n    //copy to a new list\n    BlockInfoContiguous[] newlist \u003d new BlockInfoContiguous[size_1];\n    System.arraycopy(blocks, 0, newlist, 0, size_1);\n    setBlocks(newlist);\n    return uc;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
          "extendedDetails": {
            "oldValue": "boolean",
            "newValue": "BlockInfoContiguousUnderConstruction"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-8327. Compute storage type quotas in INodeFile.computeQuotaDeltaForTruncate(). Contributed by Haohui Mai.\n",
          "commitDate": "08/05/15 11:09 PM",
          "commitName": "02a4a22b9c0e22c2e7dd6ec85edd5c5a167fe19f",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "08/05/15 11:04 PM",
          "commitNameOld": "00fe1ed3a4b3ee35fe24be257ec36445d2f44d63",
          "commitAuthorOld": "Haohui Mai",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 2,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,17 +1,19 @@\n-  boolean removeLastBlock(Block oldblock) {\n+  BlockInfoContiguousUnderConstruction removeLastBlock(Block oldblock) {\n     Preconditions.checkState(isUnderConstruction(),\n         \"file is no longer under construction\");\n     if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n-      return false;\n+      return null;\n     }\n     int size_1 \u003d blocks.length - 1;\n     if (!blocks[size_1].equals(oldblock)) {\n-      return false;\n+      return null;\n     }\n \n+    BlockInfoContiguousUnderConstruction uc \u003d\n+        (BlockInfoContiguousUnderConstruction)blocks[size_1];\n     //copy to a new list\n     BlockInfoContiguous[] newlist \u003d new BlockInfoContiguous[size_1];\n     System.arraycopy(blocks, 0, newlist, 0, size_1);\n     setBlocks(newlist);\n-    return true;\n+    return uc;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  BlockInfoContiguousUnderConstruction removeLastBlock(Block oldblock) {\n    Preconditions.checkState(isUnderConstruction(),\n        \"file is no longer under construction\");\n    if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n      return null;\n    }\n    int size_1 \u003d blocks.length - 1;\n    if (!blocks[size_1].equals(oldblock)) {\n      return null;\n    }\n\n    BlockInfoContiguousUnderConstruction uc \u003d\n        (BlockInfoContiguousUnderConstruction)blocks[size_1];\n    //copy to a new list\n    BlockInfoContiguous[] newlist \u003d new BlockInfoContiguous[size_1];\n    System.arraycopy(blocks, 0, newlist, 0, size_1);\n    setBlocks(newlist);\n    return uc;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
          "extendedDetails": {}
        }
      ]
    },
    "1382ae525c67bf95d8f3a436b547dbc72cfbb177": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7743. Code cleanup of BlockInfo and rename BlockInfo to BlockInfoContiguous. Contributed by Jing Zhao.\n",
      "commitDate": "08/02/15 11:51 AM",
      "commitName": "1382ae525c67bf95d8f3a436b547dbc72cfbb177",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "02/02/15 4:32 PM",
      "commitNameOld": "8cb473124c1cf1c6f68ead7bde06558ebf7ce47e",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 5.8,
      "commitsBetweenForRepo": 69,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,17 @@\n   boolean removeLastBlock(Block oldblock) {\n     Preconditions.checkState(isUnderConstruction(),\n         \"file is no longer under construction\");\n     if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n       return false;\n     }\n     int size_1 \u003d blocks.length - 1;\n     if (!blocks[size_1].equals(oldblock)) {\n       return false;\n     }\n \n     //copy to a new list\n-    BlockInfo[] newlist \u003d new BlockInfo[size_1];\n+    BlockInfoContiguous[] newlist \u003d new BlockInfoContiguous[size_1];\n     System.arraycopy(blocks, 0, newlist, 0, size_1);\n     setBlocks(newlist);\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  boolean removeLastBlock(Block oldblock) {\n    Preconditions.checkState(isUnderConstruction(),\n        \"file is no longer under construction\");\n    if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n      return false;\n    }\n    int size_1 \u003d blocks.length - 1;\n    if (!blocks[size_1].equals(oldblock)) {\n      return false;\n    }\n\n    //copy to a new list\n    BlockInfoContiguous[] newlist \u003d new BlockInfoContiguous[size_1];\n    System.arraycopy(blocks, 0, newlist, 0, size_1);\n    setBlocks(newlist);\n    return true;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
      "extendedDetails": {}
    },
    "8df119da214babde03e73243c7ca4cfe6d0ca562": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5537. Remove FileWithSnapshot interface.  Contributed by jing9\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1546184 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/11/13 12:32 PM",
      "commitName": "8df119da214babde03e73243c7ca4cfe6d0ca562",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "26/11/13 10:33 AM",
      "commitNameOld": "82ff2d3f2e569879500d851f4d67dfa2d02b5c9b",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 1.08,
      "commitsBetweenForRepo": 6,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,15 +1,17 @@\n   boolean removeLastBlock(Block oldblock) {\n+    Preconditions.checkState(isUnderConstruction(),\n+        \"file is no longer under construction\");\n     if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n       return false;\n     }\n     int size_1 \u003d blocks.length - 1;\n     if (!blocks[size_1].equals(oldblock)) {\n       return false;\n     }\n \n     //copy to a new list\n     BlockInfo[] newlist \u003d new BlockInfo[size_1];\n     System.arraycopy(blocks, 0, newlist, 0, size_1);\n     setBlocks(newlist);\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  boolean removeLastBlock(Block oldblock) {\n    Preconditions.checkState(isUnderConstruction(),\n        \"file is no longer under construction\");\n    if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n      return false;\n    }\n    int size_1 \u003d blocks.length - 1;\n    if (!blocks[size_1].equals(oldblock)) {\n      return false;\n    }\n\n    //copy to a new list\n    BlockInfo[] newlist \u003d new BlockInfo[size_1];\n    System.arraycopy(blocks, 0, newlist, 0, size_1);\n    setBlocks(newlist);\n    return true;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
      "extendedDetails": {}
    },
    "ce68f410b05a58ad05965f32ad7f5b246b363a75": {
      "type": "Ymultichange(Ymovefromfile,Ybodychange)",
      "commitMessage": "HDFS-5285. Flatten INodeFile hierarchy: Replace INodeFileUnderConstruction and INodeFileUnderConstructionWithSnapshot with FileUnderContructionFeature.  Contributed by jing9\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1544389 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/11/13 5:39 PM",
      "commitName": "ce68f410b05a58ad05965f32ad7f5b246b363a75",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-5285. Flatten INodeFile hierarchy: Replace INodeFileUnderConstruction and INodeFileUnderConstructionWithSnapshot with FileUnderContructionFeature.  Contributed by jing9\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1544389 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "21/11/13 5:39 PM",
          "commitName": "ce68f410b05a58ad05965f32ad7f5b246b363a75",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "21/11/13 3:16 PM",
          "commitNameOld": "33a8234040959ecd0d0202162e1b18c990effabe",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 0.1,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,16 +1,15 @@\n   boolean removeLastBlock(Block oldblock) {\n-    final BlockInfo[] blocks \u003d getBlocks();\n     if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n       return false;\n     }\n     int size_1 \u003d blocks.length - 1;\n     if (!blocks[size_1].equals(oldblock)) {\n       return false;\n     }\n \n     //copy to a new list\n     BlockInfo[] newlist \u003d new BlockInfo[size_1];\n     System.arraycopy(blocks, 0, newlist, 0, size_1);\n     setBlocks(newlist);\n     return true;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  boolean removeLastBlock(Block oldblock) {\n    if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n      return false;\n    }\n    int size_1 \u003d blocks.length - 1;\n    if (!blocks[size_1].equals(oldblock)) {\n      return false;\n    }\n\n    //copy to a new list\n    BlockInfo[] newlist \u003d new BlockInfo[size_1];\n    System.arraycopy(blocks, 0, newlist, 0, size_1);\n    setBlocks(newlist);\n    return true;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFileUnderConstruction.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
            "oldMethodName": "removeLastBlock",
            "newMethodName": "removeLastBlock"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5285. Flatten INodeFile hierarchy: Replace INodeFileUnderConstruction and INodeFileUnderConstructionWithSnapshot with FileUnderContructionFeature.  Contributed by jing9\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1544389 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "21/11/13 5:39 PM",
          "commitName": "ce68f410b05a58ad05965f32ad7f5b246b363a75",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "21/11/13 3:16 PM",
          "commitNameOld": "33a8234040959ecd0d0202162e1b18c990effabe",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 0.1,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,16 +1,15 @@\n   boolean removeLastBlock(Block oldblock) {\n-    final BlockInfo[] blocks \u003d getBlocks();\n     if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n       return false;\n     }\n     int size_1 \u003d blocks.length - 1;\n     if (!blocks[size_1].equals(oldblock)) {\n       return false;\n     }\n \n     //copy to a new list\n     BlockInfo[] newlist \u003d new BlockInfo[size_1];\n     System.arraycopy(blocks, 0, newlist, 0, size_1);\n     setBlocks(newlist);\n     return true;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  boolean removeLastBlock(Block oldblock) {\n    if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n      return false;\n    }\n    int size_1 \u003d blocks.length - 1;\n    if (!blocks[size_1].equals(oldblock)) {\n      return false;\n    }\n\n    //copy to a new list\n    BlockInfo[] newlist \u003d new BlockInfo[size_1];\n    System.arraycopy(blocks, 0, newlist, 0, size_1);\n    setBlocks(newlist);\n    return true;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
          "extendedDetails": {}
        }
      ]
    },
    "9964a9438687f5bd318e18e447445514d50ab9d5": {
      "type": "Yexceptionschange",
      "commitMessage": "HDFS-5443. Delete 0-sized block when deleting an under-construction file that is included in snapshot. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1539754 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/11/13 10:37 AM",
      "commitName": "9964a9438687f5bd318e18e447445514d50ab9d5",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "22/07/13 11:22 AM",
      "commitNameOld": "11c073134afc878619c37c95935d6a3098a21f17",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 108.01,
      "commitsBetweenForRepo": 679,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,16 @@\n-  boolean removeLastBlock(Block oldblock) throws IOException {\n+  boolean removeLastBlock(Block oldblock) {\n     final BlockInfo[] blocks \u003d getBlocks();\n     if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n       return false;\n     }\n     int size_1 \u003d blocks.length - 1;\n     if (!blocks[size_1].equals(oldblock)) {\n       return false;\n     }\n \n     //copy to a new list\n     BlockInfo[] newlist \u003d new BlockInfo[size_1];\n     System.arraycopy(blocks, 0, newlist, 0, size_1);\n     setBlocks(newlist);\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  boolean removeLastBlock(Block oldblock) {\n    final BlockInfo[] blocks \u003d getBlocks();\n    if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n      return false;\n    }\n    int size_1 \u003d blocks.length - 1;\n    if (!blocks[size_1].equals(oldblock)) {\n      return false;\n    }\n\n    //copy to a new list\n    BlockInfo[] newlist \u003d new BlockInfo[size_1];\n    System.arraycopy(blocks, 0, newlist, 0, size_1);\n    setBlocks(newlist);\n    return true;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFileUnderConstruction.java",
      "extendedDetails": {
        "oldValue": "[IOException]",
        "newValue": "[]"
      }
    },
    "11c073134afc878619c37c95935d6a3098a21f17": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-5008. Make ClientProtocol#abandonBlock() idempotent. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1505761 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "22/07/13 11:22 AM",
      "commitName": "11c073134afc878619c37c95935d6a3098a21f17",
      "commitAuthor": "Jing Zhao",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-5008. Make ClientProtocol#abandonBlock() idempotent. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1505761 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "22/07/13 11:22 AM",
          "commitName": "11c073134afc878619c37c95935d6a3098a21f17",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "06/05/13 5:17 PM",
          "commitNameOld": "393188c445b2fe2c8c674dc982a6ce1070f7d17d",
          "commitAuthorOld": "",
          "daysBetweenCommits": 76.75,
          "commitsBetweenForRepo": 464,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,15 +1,16 @@\n-  void removeLastBlock(Block oldblock) throws IOException {\n+  boolean removeLastBlock(Block oldblock) throws IOException {\n     final BlockInfo[] blocks \u003d getBlocks();\n-    if (blocks \u003d\u003d null) {\n-      throw new IOException(\"Trying to delete non-existant block \" + oldblock);\n+    if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n+      return false;\n     }\n     int size_1 \u003d blocks.length - 1;\n     if (!blocks[size_1].equals(oldblock)) {\n-      throw new IOException(\"Trying to delete non-last block \" + oldblock);\n+      return false;\n     }\n \n     //copy to a new list\n     BlockInfo[] newlist \u003d new BlockInfo[size_1];\n     System.arraycopy(blocks, 0, newlist, 0, size_1);\n     setBlocks(newlist);\n+    return true;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  boolean removeLastBlock(Block oldblock) throws IOException {\n    final BlockInfo[] blocks \u003d getBlocks();\n    if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n      return false;\n    }\n    int size_1 \u003d blocks.length - 1;\n    if (!blocks[size_1].equals(oldblock)) {\n      return false;\n    }\n\n    //copy to a new list\n    BlockInfo[] newlist \u003d new BlockInfo[size_1];\n    System.arraycopy(blocks, 0, newlist, 0, size_1);\n    setBlocks(newlist);\n    return true;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFileUnderConstruction.java",
          "extendedDetails": {
            "oldValue": "void",
            "newValue": "boolean"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5008. Make ClientProtocol#abandonBlock() idempotent. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1505761 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "22/07/13 11:22 AM",
          "commitName": "11c073134afc878619c37c95935d6a3098a21f17",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "06/05/13 5:17 PM",
          "commitNameOld": "393188c445b2fe2c8c674dc982a6ce1070f7d17d",
          "commitAuthorOld": "",
          "daysBetweenCommits": 76.75,
          "commitsBetweenForRepo": 464,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,15 +1,16 @@\n-  void removeLastBlock(Block oldblock) throws IOException {\n+  boolean removeLastBlock(Block oldblock) throws IOException {\n     final BlockInfo[] blocks \u003d getBlocks();\n-    if (blocks \u003d\u003d null) {\n-      throw new IOException(\"Trying to delete non-existant block \" + oldblock);\n+    if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n+      return false;\n     }\n     int size_1 \u003d blocks.length - 1;\n     if (!blocks[size_1].equals(oldblock)) {\n-      throw new IOException(\"Trying to delete non-last block \" + oldblock);\n+      return false;\n     }\n \n     //copy to a new list\n     BlockInfo[] newlist \u003d new BlockInfo[size_1];\n     System.arraycopy(blocks, 0, newlist, 0, size_1);\n     setBlocks(newlist);\n+    return true;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  boolean removeLastBlock(Block oldblock) throws IOException {\n    final BlockInfo[] blocks \u003d getBlocks();\n    if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n      return false;\n    }\n    int size_1 \u003d blocks.length - 1;\n    if (!blocks[size_1].equals(oldblock)) {\n      return false;\n    }\n\n    //copy to a new list\n    BlockInfo[] newlist \u003d new BlockInfo[size_1];\n    System.arraycopy(blocks, 0, newlist, 0, size_1);\n    setBlocks(newlist);\n    return true;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFileUnderConstruction.java",
          "extendedDetails": {}
        }
      ]
    },
    "d174f574bafcfefc635c64a47f258b1ce5d5c84e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4143. Change blocks to private in INodeFile and renames isLink() to isSymlink() in INode.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1405237 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/11/12 5:20 PM",
      "commitName": "d174f574bafcfefc635c64a47f258b1ce5d5c84e",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "25/10/12 11:44 AM",
      "commitNameOld": "ba2ee1d7fb91462c861169224d250d2d90bec3a6",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 8.23,
      "commitsBetweenForRepo": 37,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,15 @@\n   void removeLastBlock(Block oldblock) throws IOException {\n+    final BlockInfo[] blocks \u003d getBlocks();\n     if (blocks \u003d\u003d null) {\n       throw new IOException(\"Trying to delete non-existant block \" + oldblock);\n     }\n     int size_1 \u003d blocks.length - 1;\n     if (!blocks[size_1].equals(oldblock)) {\n       throw new IOException(\"Trying to delete non-last block \" + oldblock);\n     }\n \n     //copy to a new list\n     BlockInfo[] newlist \u003d new BlockInfo[size_1];\n     System.arraycopy(blocks, 0, newlist, 0, size_1);\n-    blocks \u003d newlist;\n+    setBlocks(newlist);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void removeLastBlock(Block oldblock) throws IOException {\n    final BlockInfo[] blocks \u003d getBlocks();\n    if (blocks \u003d\u003d null) {\n      throw new IOException(\"Trying to delete non-existant block \" + oldblock);\n    }\n    int size_1 \u003d blocks.length - 1;\n    if (!blocks[size_1].equals(oldblock)) {\n      throw new IOException(\"Trying to delete non-last block \" + oldblock);\n    }\n\n    //copy to a new list\n    BlockInfo[] newlist \u003d new BlockInfo[size_1];\n    System.arraycopy(blocks, 0, newlist, 0, size_1);\n    setBlocks(newlist);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFileUnderConstruction.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  void removeLastBlock(Block oldblock) throws IOException {\n    if (blocks \u003d\u003d null) {\n      throw new IOException(\"Trying to delete non-existant block \" + oldblock);\n    }\n    int size_1 \u003d blocks.length - 1;\n    if (!blocks[size_1].equals(oldblock)) {\n      throw new IOException(\"Trying to delete non-last block \" + oldblock);\n    }\n\n    //copy to a new list\n    BlockInfo[] newlist \u003d new BlockInfo[size_1];\n    System.arraycopy(blocks, 0, newlist, 0, size_1);\n    blocks \u003d newlist;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFileUnderConstruction.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFileUnderConstruction.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFileUnderConstruction.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  void removeLastBlock(Block oldblock) throws IOException {\n    if (blocks \u003d\u003d null) {\n      throw new IOException(\"Trying to delete non-existant block \" + oldblock);\n    }\n    int size_1 \u003d blocks.length - 1;\n    if (!blocks[size_1].equals(oldblock)) {\n      throw new IOException(\"Trying to delete non-last block \" + oldblock);\n    }\n\n    //copy to a new list\n    BlockInfo[] newlist \u003d new BlockInfo[size_1];\n    System.arraycopy(blocks, 0, newlist, 0, size_1);\n    blocks \u003d newlist;\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFileUnderConstruction.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/INodeFileUnderConstruction.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFileUnderConstruction.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,14 @@\n+  void removeLastBlock(Block oldblock) throws IOException {\n+    if (blocks \u003d\u003d null) {\n+      throw new IOException(\"Trying to delete non-existant block \" + oldblock);\n+    }\n+    int size_1 \u003d blocks.length - 1;\n+    if (!blocks[size_1].equals(oldblock)) {\n+      throw new IOException(\"Trying to delete non-last block \" + oldblock);\n+    }\n+\n+    //copy to a new list\n+    BlockInfo[] newlist \u003d new BlockInfo[size_1];\n+    System.arraycopy(blocks, 0, newlist, 0, size_1);\n+    blocks \u003d newlist;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  void removeLastBlock(Block oldblock) throws IOException {\n    if (blocks \u003d\u003d null) {\n      throw new IOException(\"Trying to delete non-existant block \" + oldblock);\n    }\n    int size_1 \u003d blocks.length - 1;\n    if (!blocks[size_1].equals(oldblock)) {\n      throw new IOException(\"Trying to delete non-last block \" + oldblock);\n    }\n\n    //copy to a new list\n    BlockInfo[] newlist \u003d new BlockInfo[size_1];\n    System.arraycopy(blocks, 0, newlist, 0, size_1);\n    blocks \u003d newlist;\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/INodeFileUnderConstruction.java"
    }
  }
}