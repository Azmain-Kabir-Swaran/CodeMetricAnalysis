{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "WindowsBasedProcessTree.java",
  "functionName": "createProcessInfo",
  "functionId": "createProcessInfo___processesInfoStr-String",
  "sourceFilePath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/util/WindowsBasedProcessTree.java",
  "functionStartLine": 120,
  "functionEndLine": 145,
  "numCommitsSeen": 16,
  "timeTaken": 2121,
  "changeHistory": [
    "2064ca015d1584263aac0cc20c60b925a3aff612",
    "638801cce16fc1dc3259c541dc30a599faaddda1"
  ],
  "changeHistoryShort": {
    "2064ca015d1584263aac0cc20c60b925a3aff612": "Ybodychange",
    "638801cce16fc1dc3259c541dc30a599faaddda1": "Yintroduced"
  },
  "changeHistoryDetails": {
    "2064ca015d1584263aac0cc20c60b925a3aff612": {
      "type": "Ybodychange",
      "commitMessage": "YARN-9349.  Changed logging to use slf4j api.\n            Contributed by Prabhu Joseph\n",
      "commitDate": "15/03/19 4:20 PM",
      "commitName": "2064ca015d1584263aac0cc20c60b925a3aff612",
      "commitAuthor": "Eric Yang",
      "commitDateOld": "03/03/19 11:59 PM",
      "commitNameOld": "bd8d299ded742813cabd4b4e7ce1e33e0d1f9509",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 11.64,
      "commitsBetweenForRepo": 118,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,26 +1,26 @@\n   Map\u003cString, ProcessInfo\u003e createProcessInfo(String processesInfoStr) {\n     String[] processesStr \u003d processesInfoStr.split(\"\\r\\n\");\n     Map\u003cString, ProcessInfo\u003e allProcs \u003d new HashMap\u003cString, ProcessInfo\u003e();\n     final int procInfoSplitCount \u003d 4;\n     for (String processStr : processesStr) {\n       if (processStr !\u003d null) {\n         String[] procInfo \u003d processStr.split(\",\");\n         if (procInfo.length \u003d\u003d procInfoSplitCount) {\n           try {\n             ProcessInfo pInfo \u003d new ProcessInfo();\n             pInfo.pid \u003d procInfo[0];\n             pInfo.vmem \u003d Long.parseLong(procInfo[1]);\n             pInfo.workingSet \u003d Long.parseLong(procInfo[2]);\n             pInfo.cpuTimeMs \u003d Long.parseLong(procInfo[3]);\n             allProcs.put(pInfo.pid, pInfo);\n           } catch (NumberFormatException nfe) {\n-            LOG.debug(\"Error parsing procInfo.\" + nfe);\n+            LOG.debug(\"Error parsing procInfo.\", nfe);\n           }\n         } else {\n-          LOG.debug(\"Expected split length of proc info to be \"\n-              + procInfoSplitCount + \". Got \" + procInfo.length);\n+          LOG.debug(\"Expected split length of proc info to be {}. Got {}\",\n+              procInfoSplitCount, procInfo.length);\n         }\n       }\n     }\n     return allProcs;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  Map\u003cString, ProcessInfo\u003e createProcessInfo(String processesInfoStr) {\n    String[] processesStr \u003d processesInfoStr.split(\"\\r\\n\");\n    Map\u003cString, ProcessInfo\u003e allProcs \u003d new HashMap\u003cString, ProcessInfo\u003e();\n    final int procInfoSplitCount \u003d 4;\n    for (String processStr : processesStr) {\n      if (processStr !\u003d null) {\n        String[] procInfo \u003d processStr.split(\",\");\n        if (procInfo.length \u003d\u003d procInfoSplitCount) {\n          try {\n            ProcessInfo pInfo \u003d new ProcessInfo();\n            pInfo.pid \u003d procInfo[0];\n            pInfo.vmem \u003d Long.parseLong(procInfo[1]);\n            pInfo.workingSet \u003d Long.parseLong(procInfo[2]);\n            pInfo.cpuTimeMs \u003d Long.parseLong(procInfo[3]);\n            allProcs.put(pInfo.pid, pInfo);\n          } catch (NumberFormatException nfe) {\n            LOG.debug(\"Error parsing procInfo.\", nfe);\n          }\n        } else {\n          LOG.debug(\"Expected split length of proc info to be {}. Got {}\",\n              procInfoSplitCount, procInfo.length);\n        }\n      }\n    }\n    return allProcs;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/util/WindowsBasedProcessTree.java",
      "extendedDetails": {}
    },
    "638801cce16fc1dc3259c541dc30a599faaddda1": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-8952. Enhancements to support Hadoop on Windows Server and Windows Azure environments. Contributed by Ivan Mitic, Chuan Liu, Ramya Sunil, Bikas Saha, Kanna Karanam, John Gordon, Brandon Li, Chris Nauroth, David Lao, Sumadhur Reddy Bolli, Arpit Agarwal, Ahmed El Baz, Mike Liddell, Jing Zhao, Thejas Nair, Steve Maine, Ganeshan Iyer, Raja Aluri, Giridharan Kesavan, Ramya Bharathi Nimmagadda.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1453486 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "06/03/13 11:15 AM",
      "commitName": "638801cce16fc1dc3259c541dc30a599faaddda1",
      "commitAuthor": "Suresh Srinivas",
      "diff": "@@ -0,0 +1,26 @@\n+  Map\u003cString, ProcessInfo\u003e createProcessInfo(String processesInfoStr) {\n+    String[] processesStr \u003d processesInfoStr.split(\"\\r\\n\");\n+    Map\u003cString, ProcessInfo\u003e allProcs \u003d new HashMap\u003cString, ProcessInfo\u003e();\n+    final int procInfoSplitCount \u003d 4;\n+    for (String processStr : processesStr) {\n+      if (processStr !\u003d null) {\n+        String[] procInfo \u003d processStr.split(\",\");\n+        if (procInfo.length \u003d\u003d procInfoSplitCount) {\n+          try {\n+            ProcessInfo pInfo \u003d new ProcessInfo();\n+            pInfo.pid \u003d procInfo[0];\n+            pInfo.vmem \u003d Long.parseLong(procInfo[1]);\n+            pInfo.workingSet \u003d Long.parseLong(procInfo[2]);\n+            pInfo.cpuTimeMs \u003d Long.parseLong(procInfo[3]);\n+            allProcs.put(pInfo.pid, pInfo);\n+          } catch (NumberFormatException nfe) {\n+            LOG.debug(\"Error parsing procInfo.\" + nfe);\n+          }\n+        } else {\n+          LOG.debug(\"Expected split length of proc info to be \"\n+              + procInfoSplitCount + \". Got \" + procInfo.length);\n+        }\n+      }\n+    }\n+    return allProcs;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  Map\u003cString, ProcessInfo\u003e createProcessInfo(String processesInfoStr) {\n    String[] processesStr \u003d processesInfoStr.split(\"\\r\\n\");\n    Map\u003cString, ProcessInfo\u003e allProcs \u003d new HashMap\u003cString, ProcessInfo\u003e();\n    final int procInfoSplitCount \u003d 4;\n    for (String processStr : processesStr) {\n      if (processStr !\u003d null) {\n        String[] procInfo \u003d processStr.split(\",\");\n        if (procInfo.length \u003d\u003d procInfoSplitCount) {\n          try {\n            ProcessInfo pInfo \u003d new ProcessInfo();\n            pInfo.pid \u003d procInfo[0];\n            pInfo.vmem \u003d Long.parseLong(procInfo[1]);\n            pInfo.workingSet \u003d Long.parseLong(procInfo[2]);\n            pInfo.cpuTimeMs \u003d Long.parseLong(procInfo[3]);\n            allProcs.put(pInfo.pid, pInfo);\n          } catch (NumberFormatException nfe) {\n            LOG.debug(\"Error parsing procInfo.\" + nfe);\n          }\n        } else {\n          LOG.debug(\"Expected split length of proc info to be \"\n              + procInfoSplitCount + \". Got \" + procInfo.length);\n        }\n      }\n    }\n    return allProcs;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/util/WindowsBasedProcessTree.java"
    }
  }
}