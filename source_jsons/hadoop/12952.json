{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DatanodeAdminDefaultMonitor.java",
  "functionName": "handleInsufficientlyStored",
  "functionId": "handleInsufficientlyStored___datanode-DatanodeDescriptor(modifiers-final)",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminDefaultMonitor.java",
  "functionStartLine": 306,
  "functionEndLine": 312,
  "numCommitsSeen": 40,
  "timeTaken": 3275,
  "changeHistory": [
    "c93cb6790e0f1c64efd03d859f907a0522010894",
    "79df1e750ef558afed6d166ce225a23061b36aed",
    "b61fb267b92b2736920b4bd0c673d31e7632ebb9"
  ],
  "changeHistoryShort": {
    "c93cb6790e0f1c64efd03d859f907a0522010894": "Ymovefromfile",
    "79df1e750ef558afed6d166ce225a23061b36aed": "Yfilerename",
    "b61fb267b92b2736920b4bd0c673d31e7632ebb9": "Ybodychange"
  },
  "changeHistoryDetails": {
    "c93cb6790e0f1c64efd03d859f907a0522010894": {
      "type": "Ymovefromfile",
      "commitMessage": "HDFS-14854. Create improved decommission monitor implementation. Contributed by Stephen O\u0027Donnell.\n\nReviewed-by: Inigo Goiri \u003cinigoiri@apache.org\u003e\nSigned-off-by: Wei-Chiu Chuang \u003cweichiu@apache.org\u003e\n",
      "commitDate": "10/12/19 5:16 PM",
      "commitName": "c93cb6790e0f1c64efd03d859f907a0522010894",
      "commitAuthor": "Stephen O\u0027Donnell",
      "commitDateOld": "10/12/19 6:51 AM",
      "commitNameOld": "875a3e97dd4a26fe224a1858c54d1b4512db6be3",
      "commitAuthorOld": "Gabor Bota",
      "daysBetweenCommits": 0.43,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,7 +1,7 @@\n-    private AbstractList\u003cBlockInfo\u003e handleInsufficientlyStored(\n-        final DatanodeDescriptor datanode) {\n-      AbstractList\u003cBlockInfo\u003e insufficient \u003d new ChunkedArrayList\u003c\u003e();\n-      processBlocksInternal(datanode, datanode.getBlockIterator(),\n-          insufficient, false);\n-      return insufficient;\n-    }\n\\ No newline at end of file\n+  private AbstractList\u003cBlockInfo\u003e handleInsufficientlyStored(\n+      final DatanodeDescriptor datanode) {\n+    AbstractList\u003cBlockInfo\u003e insufficient \u003d new ChunkedArrayList\u003c\u003e();\n+    processBlocksInternal(datanode, datanode.getBlockIterator(),\n+        insufficient, false);\n+    return insufficient;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private AbstractList\u003cBlockInfo\u003e handleInsufficientlyStored(\n      final DatanodeDescriptor datanode) {\n    AbstractList\u003cBlockInfo\u003e insufficient \u003d new ChunkedArrayList\u003c\u003e();\n    processBlocksInternal(datanode, datanode.getBlockIterator(),\n        insufficient, false);\n    return insufficient;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminDefaultMonitor.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminManager.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminDefaultMonitor.java",
        "oldMethodName": "handleInsufficientlyStored",
        "newMethodName": "handleInsufficientlyStored"
      }
    },
    "79df1e750ef558afed6d166ce225a23061b36aed": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-9388. Decommission related code to support Maintenance State for datanodes.\n",
      "commitDate": "02/08/17 2:22 PM",
      "commitName": "79df1e750ef558afed6d166ce225a23061b36aed",
      "commitAuthor": "Manoj Govindassamy",
      "commitDateOld": "02/08/17 12:12 PM",
      "commitNameOld": "12e44e7bdaf53d3720a89d32f0cc2717241bd6b2",
      "commitAuthorOld": "Chris Douglas",
      "daysBetweenCommits": 0.09,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    private AbstractList\u003cBlockInfo\u003e handleInsufficientlyStored(\n        final DatanodeDescriptor datanode) {\n      AbstractList\u003cBlockInfo\u003e insufficient \u003d new ChunkedArrayList\u003c\u003e();\n      processBlocksInternal(datanode, datanode.getBlockIterator(),\n          insufficient, false);\n      return insufficient;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminManager.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DecommissionManager.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminManager.java"
      }
    },
    "b61fb267b92b2736920b4bd0c673d31e7632ebb9": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9390. Block management for maintenance states.\n",
      "commitDate": "17/10/16 5:45 PM",
      "commitName": "b61fb267b92b2736920b4bd0c673d31e7632ebb9",
      "commitAuthor": "Ming Ma",
      "commitDateOld": "13/10/16 11:52 AM",
      "commitNameOld": "332a61fd74fd2a9874319232c583ab5d2c53ff03",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 4.25,
      "commitsBetweenForRepo": 27,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,7 +1,7 @@\n     private AbstractList\u003cBlockInfo\u003e handleInsufficientlyStored(\n         final DatanodeDescriptor datanode) {\n       AbstractList\u003cBlockInfo\u003e insufficient \u003d new ChunkedArrayList\u003c\u003e();\n-      processBlocksForDecomInternal(datanode, datanode.getBlockIterator(),\n+      processBlocksInternal(datanode, datanode.getBlockIterator(),\n           insufficient, false);\n       return insufficient;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private AbstractList\u003cBlockInfo\u003e handleInsufficientlyStored(\n        final DatanodeDescriptor datanode) {\n      AbstractList\u003cBlockInfo\u003e insufficient \u003d new ChunkedArrayList\u003c\u003e();\n      processBlocksInternal(datanode, datanode.getBlockIterator(),\n          insufficient, false);\n      return insufficient;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DecommissionManager.java",
      "extendedDetails": {}
    }
  }
}