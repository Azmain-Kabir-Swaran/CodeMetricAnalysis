{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "AzureBlobFileSystemStore.java",
  "functionName": "openFileForRead",
  "functionId": "openFileForRead___path-Path(modifiers-final)__statistics-FileSystem.Statistics(modifiers-final)",
  "sourceFilePath": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java",
  "functionStartLine": 462,
  "functionEndLine": 494,
  "numCommitsSeen": 49,
  "timeTaken": 6561,
  "changeHistory": [
    "b214bbd2d92a0c02b71d352dba85f3b87317933c",
    "8031c66295b530dcaae9e00d4f656330bc3b3952",
    "b033c681e4fc3ee1a38caa807e130aee481d99d5",
    "e0260417ade5568ae37dcc3753aea0d1e0fd701b",
    "e8d19003695e3bc76bfa8e1187a238eec0220def",
    "a8302e398c2ca4b0deff062c0e921053351b688e",
    "6b6f8cc2bedefc98028d875398ce022edaf77933",
    "ce03a93f78c4d97ccb48a3906fcd77ad0ac756be",
    "a271fd0eca75cef8b8ba940cdac8ad4fd21b4462",
    "f044deedbbfee0812316d587139cb828f27172e9"
  ],
  "changeHistoryShort": {
    "b214bbd2d92a0c02b71d352dba85f3b87317933c": "Ybodychange",
    "8031c66295b530dcaae9e00d4f656330bc3b3952": "Ybodychange",
    "b033c681e4fc3ee1a38caa807e130aee481d99d5": "Ybodychange",
    "e0260417ade5568ae37dcc3753aea0d1e0fd701b": "Ybodychange",
    "e8d19003695e3bc76bfa8e1187a238eec0220def": "Ybodychange",
    "a8302e398c2ca4b0deff062c0e921053351b688e": "Ybodychange",
    "6b6f8cc2bedefc98028d875398ce022edaf77933": "Ymultichange(Yreturntypechange,Ybodychange)",
    "ce03a93f78c4d97ccb48a3906fcd77ad0ac756be": "Ybodychange",
    "a271fd0eca75cef8b8ba940cdac8ad4fd21b4462": "Ymultichange(Yfilerename,Ybodychange,Yparameterchange)",
    "f044deedbbfee0812316d587139cb828f27172e9": "Yintroduced"
  },
  "changeHistoryDetails": {
    "b214bbd2d92a0c02b71d352dba85f3b87317933c": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-16916: ABFS: Delegation SAS generator for integration with Ranger\n\nContributed by Thomas Marquardt.\n\nDETAILS:\n\nPreviously we had a SASGenerator class which generated Service SAS, but we need to add DelegationSASGenerator.\nI separated SASGenerator into a base class and two subclasses ServiceSASGenerator and DelegationSASGenreator.  The\ncode in ServiceSASGenerator is copied from SASGenerator but the DelegationSASGenrator code is new.  The\nDelegationSASGenerator code demonstrates how to use Delegation SAS with minimal permissions, as would be used\nby an authorization service such as Apache Ranger.  Adding this to the tests helps us lock in this behavior.\n\nAdded a MockDelegationSASTokenProvider for testing User Delegation SAS.\n\nFixed the ITestAzureBlobFileSystemCheckAccess tests to assume oauth client ID so that they are ignored when that\nis not configured.\n\nTo improve performance, AbfsInputStream/AbfsOutputStream re-use SAS tokens until the expiry is within 120 seconds.\nAfter this a new SAS will be requested.  The default period of 120 seconds can be changed using the configuration\nsetting \"fs.azure.sas.token.renew.period.for.streams\".\n\nThe SASTokenProvider operation names were updated to correspond better with the ADLS Gen2 REST API, since these\noperations must be provided tokens with appropriate SAS parameters to succeed.\n\nSupport for the version 2.0 AAD authentication endpoint was added to AzureADAuthenticator.\n\nThe getFileStatus method was mistakenly calling the ADLS Gen2 Get Properties API which requires read permission\nwhile the getFileStatus call only requires execute permission.  ADLS Gen2 Get Status API is supposed to be used\nfor this purpose, so the underlying AbfsClient.getPathStatus API was updated with a includeProperties\nparameter which is set to false for getFileStatus and true for getXAttr.\n\nAdded SASTokenProvider support for delete recursive.\n\nFixed bugs in AzureBlobFileSystem where public methods were not validating the Path by calling makeQualified.  This is\nnecessary to avoid passing null paths and to convert relative paths into absolute paths.\n\nCanonicalized the path used for root path internally so that root path can be used with SAS tokens, which requires\nthat the path in the URL and the path in the SAS token match.  Internally the code was using\n\"//\" instead of \"/\" for the root path, sometimes.  Also related to this, the AzureBlobFileSystemStore.getRelativePath\nAPI was updated so that we no longer remove and then add back a preceding forward / to paths.\n\nTo run ITestAzureBlobFileSystemDelegationSAS tests follow the instructions in testing_azure.md under the heading\n\"To run Delegation SAS test cases\".  You also need to set \"fs.azure.enable.check.access\" to true.\n\nTEST RESULTS:\n\nnamespace.enabled\u003dtrue\nauth.type\u003dSharedKey\n-------------------\n$mvn -T 1C -Dparallel-tests\u003dabfs -Dscale -DtestsThreadCount\u003d8 clean verify\nTests run: 63, Failures: 0, Errors: 0, Skipped: 0\nTests run: 432, Failures: 0, Errors: 0, Skipped: 41\nTests run: 206, Failures: 0, Errors: 0, Skipped: 24\n\nnamespace.enabled\u003dfalse\nauth.type\u003dSharedKey\n-------------------\n$mvn -T 1C -Dparallel-tests\u003dabfs -Dscale -DtestsThreadCount\u003d8 clean verify\nTests run: 63, Failures: 0, Errors: 0, Skipped: 0\nTests run: 432, Failures: 0, Errors: 0, Skipped: 244\nTests run: 206, Failures: 0, Errors: 0, Skipped: 24\n\nnamespace.enabled\u003dtrue\nauth.type\u003dSharedKey\nsas.token.provider.type\u003dMockDelegationSASTokenProvider\nenable.check.access\u003dtrue\n-------------------\n$mvn -T 1C -Dparallel-tests\u003dabfs -Dscale -DtestsThreadCount\u003d8 clean verify\nTests run: 63, Failures: 0, Errors: 0, Skipped: 0\nTests run: 432, Failures: 0, Errors: 0, Skipped: 33\nTests run: 206, Failures: 0, Errors: 0, Skipped: 24\n\nnamespace.enabled\u003dtrue\nauth.type\u003dOAuth\n-------------------\n$mvn -T 1C -Dparallel-tests\u003dabfs -Dscale -DtestsThreadCount\u003d8 clean verify\nTests run: 63, Failures: 0, Errors: 0, Skipped: 0\nTests run: 432, Failures: 0, Errors: 1, Skipped: 74\nTests run: 206, Failures: 0, Errors: 0, Skipped: 140\n",
      "commitDate": "12/05/20 11:35 AM",
      "commitName": "b214bbd2d92a0c02b71d352dba85f3b87317933c",
      "commitAuthor": "Thomas Marquardt",
      "commitDateOld": "23/04/20 5:46 PM",
      "commitNameOld": "30ef8d0f1a1463931fe581a46c739dad4c8260e4",
      "commitAuthorOld": "bilaharith",
      "daysBetweenCommits": 18.74,
      "commitsBetweenForRepo": 65,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,31 +1,33 @@\n   public AbfsInputStream openFileForRead(final Path path, final FileSystem.Statistics statistics)\n       throws AzureBlobFileSystemException {\n     try (AbfsPerfInfo perfInfo \u003d startTracking(\"openFileForRead\", \"getPathStatus\")) {\n       LOG.debug(\"openFileForRead filesystem: {} path: {}\",\n               client.getFileSystem(),\n               path);\n \n-      final AbfsRestOperation op \u003d client.getPathStatus(AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path));\n+      String relativePath \u003d getRelativePath(path);\n+\n+      final AbfsRestOperation op \u003d client.getPathStatus(relativePath, false);\n       perfInfo.registerResult(op.getResult());\n \n       final String resourceType \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.X_MS_RESOURCE_TYPE);\n       final long contentLength \u003d Long.parseLong(op.getResult().getResponseHeader(HttpHeaderConfigurations.CONTENT_LENGTH));\n       final String eTag \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.ETAG);\n \n       if (parseIsDirectory(resourceType)) {\n         throw new AbfsRestOperationException(\n                 AzureServiceErrorCode.PATH_NOT_FOUND.getStatusCode(),\n                 AzureServiceErrorCode.PATH_NOT_FOUND.getErrorCode(),\n                 \"openFileForRead must be used with files and not directories\",\n                 null);\n       }\n \n       perfInfo.registerSuccess(true);\n \n       // Add statistics for InputStream\n       return new AbfsInputStream(client, statistics,\n-              AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path), contentLength,\n+              relativePath, contentLength,\n               populateAbfsInputStreamContext(),\n               eTag);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AbfsInputStream openFileForRead(final Path path, final FileSystem.Statistics statistics)\n      throws AzureBlobFileSystemException {\n    try (AbfsPerfInfo perfInfo \u003d startTracking(\"openFileForRead\", \"getPathStatus\")) {\n      LOG.debug(\"openFileForRead filesystem: {} path: {}\",\n              client.getFileSystem(),\n              path);\n\n      String relativePath \u003d getRelativePath(path);\n\n      final AbfsRestOperation op \u003d client.getPathStatus(relativePath, false);\n      perfInfo.registerResult(op.getResult());\n\n      final String resourceType \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.X_MS_RESOURCE_TYPE);\n      final long contentLength \u003d Long.parseLong(op.getResult().getResponseHeader(HttpHeaderConfigurations.CONTENT_LENGTH));\n      final String eTag \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.ETAG);\n\n      if (parseIsDirectory(resourceType)) {\n        throw new AbfsRestOperationException(\n                AzureServiceErrorCode.PATH_NOT_FOUND.getStatusCode(),\n                AzureServiceErrorCode.PATH_NOT_FOUND.getErrorCode(),\n                \"openFileForRead must be used with files and not directories\",\n                null);\n      }\n\n      perfInfo.registerSuccess(true);\n\n      // Add statistics for InputStream\n      return new AbfsInputStream(client, statistics,\n              relativePath, contentLength,\n              populateAbfsInputStreamContext(),\n              eTag);\n    }\n  }",
      "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java",
      "extendedDetails": {}
    },
    "8031c66295b530dcaae9e00d4f656330bc3b3952": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-16965. Refactor abfs stream configuration. (#1956)\n\n\r\nContributed by Mukund Thakur.",
      "commitDate": "21/04/20 9:27 AM",
      "commitName": "8031c66295b530dcaae9e00d4f656330bc3b3952",
      "commitAuthor": "Mukund Thakur",
      "commitDateOld": "31/03/20 5:49 AM",
      "commitNameOld": "c734d247b1ea16b7028de3a37ff556cb1ef8b7d6",
      "commitAuthorOld": "Mehakmeet Singh",
      "daysBetweenCommits": 21.15,
      "commitsBetweenForRepo": 67,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,31 +1,31 @@\n   public AbfsInputStream openFileForRead(final Path path, final FileSystem.Statistics statistics)\n       throws AzureBlobFileSystemException {\n     try (AbfsPerfInfo perfInfo \u003d startTracking(\"openFileForRead\", \"getPathStatus\")) {\n       LOG.debug(\"openFileForRead filesystem: {} path: {}\",\n               client.getFileSystem(),\n               path);\n \n       final AbfsRestOperation op \u003d client.getPathStatus(AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path));\n       perfInfo.registerResult(op.getResult());\n \n       final String resourceType \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.X_MS_RESOURCE_TYPE);\n       final long contentLength \u003d Long.parseLong(op.getResult().getResponseHeader(HttpHeaderConfigurations.CONTENT_LENGTH));\n       final String eTag \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.ETAG);\n \n       if (parseIsDirectory(resourceType)) {\n         throw new AbfsRestOperationException(\n                 AzureServiceErrorCode.PATH_NOT_FOUND.getStatusCode(),\n                 AzureServiceErrorCode.PATH_NOT_FOUND.getErrorCode(),\n                 \"openFileForRead must be used with files and not directories\",\n                 null);\n       }\n \n       perfInfo.registerSuccess(true);\n \n       // Add statistics for InputStream\n       return new AbfsInputStream(client, statistics,\n               AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path), contentLength,\n-              abfsConfiguration.getReadBufferSize(), abfsConfiguration.getReadAheadQueueDepth(),\n-              abfsConfiguration.getTolerateOobAppends(), eTag);\n+              populateAbfsInputStreamContext(),\n+              eTag);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AbfsInputStream openFileForRead(final Path path, final FileSystem.Statistics statistics)\n      throws AzureBlobFileSystemException {\n    try (AbfsPerfInfo perfInfo \u003d startTracking(\"openFileForRead\", \"getPathStatus\")) {\n      LOG.debug(\"openFileForRead filesystem: {} path: {}\",\n              client.getFileSystem(),\n              path);\n\n      final AbfsRestOperation op \u003d client.getPathStatus(AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path));\n      perfInfo.registerResult(op.getResult());\n\n      final String resourceType \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.X_MS_RESOURCE_TYPE);\n      final long contentLength \u003d Long.parseLong(op.getResult().getResponseHeader(HttpHeaderConfigurations.CONTENT_LENGTH));\n      final String eTag \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.ETAG);\n\n      if (parseIsDirectory(resourceType)) {\n        throw new AbfsRestOperationException(\n                AzureServiceErrorCode.PATH_NOT_FOUND.getStatusCode(),\n                AzureServiceErrorCode.PATH_NOT_FOUND.getErrorCode(),\n                \"openFileForRead must be used with files and not directories\",\n                null);\n      }\n\n      perfInfo.registerSuccess(true);\n\n      // Add statistics for InputStream\n      return new AbfsInputStream(client, statistics,\n              AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path), contentLength,\n              populateAbfsInputStreamContext(),\n              eTag);\n    }\n  }",
      "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java",
      "extendedDetails": {}
    },
    "b033c681e4fc3ee1a38caa807e130aee481d99d5": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-16612. Track Azure Blob File System client-perceived latency\n\nContributed by Jeetesh Mangwani.\n\nThis add the ability to track the end-to-end performance of ADLS Gen 2 REST APIs by measuring latency in the Hadoop ABFS driver.\nThe latency information is sent back to the ADLS Gen 2 REST API endpoints in the subsequent requests.\n",
      "commitDate": "19/11/19 9:00 AM",
      "commitName": "b033c681e4fc3ee1a38caa807e130aee481d99d5",
      "commitAuthor": "Jeetesh Mangwani",
      "commitDateOld": "28/09/19 8:39 PM",
      "commitNameOld": "c0edc848a8e71b5e2a1586a589bbf2ac8685040d",
      "commitAuthorOld": "Sneha Vijayarajan",
      "daysBetweenCommits": 51.56,
      "commitsBetweenForRepo": 252,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,26 +1,31 @@\n   public AbfsInputStream openFileForRead(final Path path, final FileSystem.Statistics statistics)\n       throws AzureBlobFileSystemException {\n-    LOG.debug(\"openFileForRead filesystem: {} path: {}\",\n-            client.getFileSystem(),\n-            path);\n+    try (AbfsPerfInfo perfInfo \u003d startTracking(\"openFileForRead\", \"getPathStatus\")) {\n+      LOG.debug(\"openFileForRead filesystem: {} path: {}\",\n+              client.getFileSystem(),\n+              path);\n \n-    final AbfsRestOperation op \u003d client.getPathStatus(AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path));\n+      final AbfsRestOperation op \u003d client.getPathStatus(AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path));\n+      perfInfo.registerResult(op.getResult());\n \n-    final String resourceType \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.X_MS_RESOURCE_TYPE);\n-    final long contentLength \u003d Long.parseLong(op.getResult().getResponseHeader(HttpHeaderConfigurations.CONTENT_LENGTH));\n-    final String eTag \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.ETAG);\n+      final String resourceType \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.X_MS_RESOURCE_TYPE);\n+      final long contentLength \u003d Long.parseLong(op.getResult().getResponseHeader(HttpHeaderConfigurations.CONTENT_LENGTH));\n+      final String eTag \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.ETAG);\n \n-    if (parseIsDirectory(resourceType)) {\n-      throw new AbfsRestOperationException(\n-              AzureServiceErrorCode.PATH_NOT_FOUND.getStatusCode(),\n-              AzureServiceErrorCode.PATH_NOT_FOUND.getErrorCode(),\n-              \"openFileForRead must be used with files and not directories\",\n-              null);\n+      if (parseIsDirectory(resourceType)) {\n+        throw new AbfsRestOperationException(\n+                AzureServiceErrorCode.PATH_NOT_FOUND.getStatusCode(),\n+                AzureServiceErrorCode.PATH_NOT_FOUND.getErrorCode(),\n+                \"openFileForRead must be used with files and not directories\",\n+                null);\n+      }\n+\n+      perfInfo.registerSuccess(true);\n+\n+      // Add statistics for InputStream\n+      return new AbfsInputStream(client, statistics,\n+              AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path), contentLength,\n+              abfsConfiguration.getReadBufferSize(), abfsConfiguration.getReadAheadQueueDepth(),\n+              abfsConfiguration.getTolerateOobAppends(), eTag);\n     }\n-\n-    // Add statistics for InputStream\n-    return new AbfsInputStream(client, statistics,\n-            AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path), contentLength,\n-                abfsConfiguration.getReadBufferSize(), abfsConfiguration.getReadAheadQueueDepth(),\n-                abfsConfiguration.getTolerateOobAppends(), eTag);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AbfsInputStream openFileForRead(final Path path, final FileSystem.Statistics statistics)\n      throws AzureBlobFileSystemException {\n    try (AbfsPerfInfo perfInfo \u003d startTracking(\"openFileForRead\", \"getPathStatus\")) {\n      LOG.debug(\"openFileForRead filesystem: {} path: {}\",\n              client.getFileSystem(),\n              path);\n\n      final AbfsRestOperation op \u003d client.getPathStatus(AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path));\n      perfInfo.registerResult(op.getResult());\n\n      final String resourceType \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.X_MS_RESOURCE_TYPE);\n      final long contentLength \u003d Long.parseLong(op.getResult().getResponseHeader(HttpHeaderConfigurations.CONTENT_LENGTH));\n      final String eTag \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.ETAG);\n\n      if (parseIsDirectory(resourceType)) {\n        throw new AbfsRestOperationException(\n                AzureServiceErrorCode.PATH_NOT_FOUND.getStatusCode(),\n                AzureServiceErrorCode.PATH_NOT_FOUND.getErrorCode(),\n                \"openFileForRead must be used with files and not directories\",\n                null);\n      }\n\n      perfInfo.registerSuccess(true);\n\n      // Add statistics for InputStream\n      return new AbfsInputStream(client, statistics,\n              AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path), contentLength,\n              abfsConfiguration.getReadBufferSize(), abfsConfiguration.getReadAheadQueueDepth(),\n              abfsConfiguration.getTolerateOobAppends(), eTag);\n    }\n  }",
      "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java",
      "extendedDetails": {}
    },
    "e0260417ade5568ae37dcc3753aea0d1e0fd701b": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-16169. ABFS: Bug fix for getPathProperties.\n\nAuthor:    Da Zhou \u003cda.zhou@microsoft.com\u003e\n",
      "commitDate": "08/03/19 5:53 AM",
      "commitName": "e0260417ade5568ae37dcc3753aea0d1e0fd701b",
      "commitAuthor": "Da Zhou",
      "commitDateOld": "28/02/19 6:22 AM",
      "commitNameOld": "65f60e56b082faf92e1cd3daee2569d8fc669c67",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 7.98,
      "commitsBetweenForRepo": 77,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,26 +1,26 @@\n   public AbfsInputStream openFileForRead(final Path path, final FileSystem.Statistics statistics)\n       throws AzureBlobFileSystemException {\n     LOG.debug(\"openFileForRead filesystem: {} path: {}\",\n             client.getFileSystem(),\n             path);\n \n-    final AbfsRestOperation op \u003d client.getPathProperties(AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path), isNamespaceEnabled);\n+    final AbfsRestOperation op \u003d client.getPathStatus(AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path));\n \n     final String resourceType \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.X_MS_RESOURCE_TYPE);\n     final long contentLength \u003d Long.parseLong(op.getResult().getResponseHeader(HttpHeaderConfigurations.CONTENT_LENGTH));\n     final String eTag \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.ETAG);\n \n     if (parseIsDirectory(resourceType)) {\n       throw new AbfsRestOperationException(\n               AzureServiceErrorCode.PATH_NOT_FOUND.getStatusCode(),\n               AzureServiceErrorCode.PATH_NOT_FOUND.getErrorCode(),\n               \"openFileForRead must be used with files and not directories\",\n               null);\n     }\n \n     // Add statistics for InputStream\n     return new AbfsInputStream(client, statistics,\n             AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path), contentLength,\n                 abfsConfiguration.getReadBufferSize(), abfsConfiguration.getReadAheadQueueDepth(),\n                 abfsConfiguration.getTolerateOobAppends(), eTag);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AbfsInputStream openFileForRead(final Path path, final FileSystem.Statistics statistics)\n      throws AzureBlobFileSystemException {\n    LOG.debug(\"openFileForRead filesystem: {} path: {}\",\n            client.getFileSystem(),\n            path);\n\n    final AbfsRestOperation op \u003d client.getPathStatus(AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path));\n\n    final String resourceType \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.X_MS_RESOURCE_TYPE);\n    final long contentLength \u003d Long.parseLong(op.getResult().getResponseHeader(HttpHeaderConfigurations.CONTENT_LENGTH));\n    final String eTag \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.ETAG);\n\n    if (parseIsDirectory(resourceType)) {\n      throw new AbfsRestOperationException(\n              AzureServiceErrorCode.PATH_NOT_FOUND.getStatusCode(),\n              AzureServiceErrorCode.PATH_NOT_FOUND.getErrorCode(),\n              \"openFileForRead must be used with files and not directories\",\n              null);\n    }\n\n    // Add statistics for InputStream\n    return new AbfsInputStream(client, statistics,\n            AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path), contentLength,\n                abfsConfiguration.getReadBufferSize(), abfsConfiguration.getReadAheadQueueDepth(),\n                abfsConfiguration.getTolerateOobAppends(), eTag);\n  }",
      "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java",
      "extendedDetails": {}
    },
    "e8d19003695e3bc76bfa8e1187a238eec0220def": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-16040. ABFS: Bug fix for tolerateOobAppends configuration.\n\nContributed by Da Zhou.\n",
      "commitDate": "10/01/19 3:58 AM",
      "commitName": "e8d19003695e3bc76bfa8e1187a238eec0220def",
      "commitAuthor": "Da Zhou",
      "commitDateOld": "17/12/18 3:10 AM",
      "commitNameOld": "62df60737c828afc3d1526973a24c6779a1ca9e6",
      "commitAuthorOld": "Da Zhou",
      "daysBetweenCommits": 24.03,
      "commitsBetweenForRepo": 152,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,25 +1,26 @@\n   public AbfsInputStream openFileForRead(final Path path, final FileSystem.Statistics statistics)\n       throws AzureBlobFileSystemException {\n     LOG.debug(\"openFileForRead filesystem: {} path: {}\",\n             client.getFileSystem(),\n             path);\n \n     final AbfsRestOperation op \u003d client.getPathProperties(AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path), isNamespaceEnabled);\n \n     final String resourceType \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.X_MS_RESOURCE_TYPE);\n     final long contentLength \u003d Long.parseLong(op.getResult().getResponseHeader(HttpHeaderConfigurations.CONTENT_LENGTH));\n     final String eTag \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.ETAG);\n \n     if (parseIsDirectory(resourceType)) {\n       throw new AbfsRestOperationException(\n               AzureServiceErrorCode.PATH_NOT_FOUND.getStatusCode(),\n               AzureServiceErrorCode.PATH_NOT_FOUND.getErrorCode(),\n               \"openFileForRead must be used with files and not directories\",\n               null);\n     }\n \n     // Add statistics for InputStream\n     return new AbfsInputStream(client, statistics,\n             AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path), contentLength,\n-                abfsConfiguration.getReadBufferSize(), abfsConfiguration.getReadAheadQueueDepth(), eTag);\n+                abfsConfiguration.getReadBufferSize(), abfsConfiguration.getReadAheadQueueDepth(),\n+                abfsConfiguration.getTolerateOobAppends(), eTag);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AbfsInputStream openFileForRead(final Path path, final FileSystem.Statistics statistics)\n      throws AzureBlobFileSystemException {\n    LOG.debug(\"openFileForRead filesystem: {} path: {}\",\n            client.getFileSystem(),\n            path);\n\n    final AbfsRestOperation op \u003d client.getPathProperties(AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path), isNamespaceEnabled);\n\n    final String resourceType \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.X_MS_RESOURCE_TYPE);\n    final long contentLength \u003d Long.parseLong(op.getResult().getResponseHeader(HttpHeaderConfigurations.CONTENT_LENGTH));\n    final String eTag \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.ETAG);\n\n    if (parseIsDirectory(resourceType)) {\n      throw new AbfsRestOperationException(\n              AzureServiceErrorCode.PATH_NOT_FOUND.getStatusCode(),\n              AzureServiceErrorCode.PATH_NOT_FOUND.getErrorCode(),\n              \"openFileForRead must be used with files and not directories\",\n              null);\n    }\n\n    // Add statistics for InputStream\n    return new AbfsInputStream(client, statistics,\n            AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path), contentLength,\n                abfsConfiguration.getReadBufferSize(), abfsConfiguration.getReadAheadQueueDepth(),\n                abfsConfiguration.getTolerateOobAppends(), eTag);\n  }",
      "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java",
      "extendedDetails": {}
    },
    "a8302e398c2ca4b0deff062c0e921053351b688e": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-15872. ABFS: Update to target 2018-11-09 REST version for ADLS Gen 2.\n\nContributed by Junhua Gu and Da Zhou.\n",
      "commitDate": "23/11/18 6:17 AM",
      "commitName": "a8302e398c2ca4b0deff062c0e921053351b688e",
      "commitAuthor": "Da Zhou",
      "commitDateOld": "13/11/18 1:46 PM",
      "commitNameOld": "a13be203b7877ba56ef63aac4a2e65d4e1a4adbc",
      "commitAuthorOld": "Da Zhou",
      "daysBetweenCommits": 9.69,
      "commitsBetweenForRepo": 79,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,25 +1,25 @@\n   public AbfsInputStream openFileForRead(final Path path, final FileSystem.Statistics statistics)\n       throws AzureBlobFileSystemException {\n     LOG.debug(\"openFileForRead filesystem: {} path: {}\",\n             client.getFileSystem(),\n             path);\n \n-    final AbfsRestOperation op \u003d client.getPathProperties(AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path));\n+    final AbfsRestOperation op \u003d client.getPathProperties(AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path), isNamespaceEnabled);\n \n     final String resourceType \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.X_MS_RESOURCE_TYPE);\n     final long contentLength \u003d Long.parseLong(op.getResult().getResponseHeader(HttpHeaderConfigurations.CONTENT_LENGTH));\n     final String eTag \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.ETAG);\n \n     if (parseIsDirectory(resourceType)) {\n       throw new AbfsRestOperationException(\n               AzureServiceErrorCode.PATH_NOT_FOUND.getStatusCode(),\n               AzureServiceErrorCode.PATH_NOT_FOUND.getErrorCode(),\n               \"openFileForRead must be used with files and not directories\",\n               null);\n     }\n \n     // Add statistics for InputStream\n     return new AbfsInputStream(client, statistics,\n             AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path), contentLength,\n                 abfsConfiguration.getReadBufferSize(), abfsConfiguration.getReadAheadQueueDepth(), eTag);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AbfsInputStream openFileForRead(final Path path, final FileSystem.Statistics statistics)\n      throws AzureBlobFileSystemException {\n    LOG.debug(\"openFileForRead filesystem: {} path: {}\",\n            client.getFileSystem(),\n            path);\n\n    final AbfsRestOperation op \u003d client.getPathProperties(AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path), isNamespaceEnabled);\n\n    final String resourceType \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.X_MS_RESOURCE_TYPE);\n    final long contentLength \u003d Long.parseLong(op.getResult().getResponseHeader(HttpHeaderConfigurations.CONTENT_LENGTH));\n    final String eTag \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.ETAG);\n\n    if (parseIsDirectory(resourceType)) {\n      throw new AbfsRestOperationException(\n              AzureServiceErrorCode.PATH_NOT_FOUND.getStatusCode(),\n              AzureServiceErrorCode.PATH_NOT_FOUND.getErrorCode(),\n              \"openFileForRead must be used with files and not directories\",\n              null);\n    }\n\n    // Add statistics for InputStream\n    return new AbfsInputStream(client, statistics,\n            AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path), contentLength,\n                abfsConfiguration.getReadBufferSize(), abfsConfiguration.getReadAheadQueueDepth(), eTag);\n  }",
      "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java",
      "extendedDetails": {}
    },
    "6b6f8cc2bedefc98028d875398ce022edaf77933": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": "HADOOP 15688. ABFS: InputStream wrapped in FSDataInputStream twice.\nContributed by Sean Mackrory.\n",
      "commitDate": "17/09/18 12:54 PM",
      "commitName": "6b6f8cc2bedefc98028d875398ce022edaf77933",
      "commitAuthor": "Thomas Marquardt",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "HADOOP 15688. ABFS: InputStream wrapped in FSDataInputStream twice.\nContributed by Sean Mackrory.\n",
          "commitDate": "17/09/18 12:54 PM",
          "commitName": "6b6f8cc2bedefc98028d875398ce022edaf77933",
          "commitAuthor": "Thomas Marquardt",
          "commitDateOld": "17/09/18 12:54 PM",
          "commitNameOld": "9c1e4e81399913f180131f4faa95604087c6d962",
          "commitAuthorOld": "Thomas Marquardt",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,26 +1,25 @@\n-  public InputStream openFileForRead(final Path path, final FileSystem.Statistics statistics)\n+  public AbfsInputStream openFileForRead(final Path path, final FileSystem.Statistics statistics)\n       throws AzureBlobFileSystemException {\n     LOG.debug(\"openFileForRead filesystem: {} path: {}\",\n             client.getFileSystem(),\n             path);\n \n     final AbfsRestOperation op \u003d client.getPathProperties(AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path));\n \n     final String resourceType \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.X_MS_RESOURCE_TYPE);\n     final long contentLength \u003d Long.parseLong(op.getResult().getResponseHeader(HttpHeaderConfigurations.CONTENT_LENGTH));\n     final String eTag \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.ETAG);\n \n     if (parseIsDirectory(resourceType)) {\n       throw new AbfsRestOperationException(\n               AzureServiceErrorCode.PATH_NOT_FOUND.getStatusCode(),\n               AzureServiceErrorCode.PATH_NOT_FOUND.getErrorCode(),\n               \"openFileForRead must be used with files and not directories\",\n               null);\n     }\n \n     // Add statistics for InputStream\n-    return new FSDataInputStream(\n-            new AbfsInputStream(client, statistics,\n-                AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path), contentLength,\n-                    abfsConfiguration.getReadBufferSize(), abfsConfiguration.getReadAheadQueueDepth(), eTag));\n+    return new AbfsInputStream(client, statistics,\n+            AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path), contentLength,\n+                abfsConfiguration.getReadBufferSize(), abfsConfiguration.getReadAheadQueueDepth(), eTag);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public AbfsInputStream openFileForRead(final Path path, final FileSystem.Statistics statistics)\n      throws AzureBlobFileSystemException {\n    LOG.debug(\"openFileForRead filesystem: {} path: {}\",\n            client.getFileSystem(),\n            path);\n\n    final AbfsRestOperation op \u003d client.getPathProperties(AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path));\n\n    final String resourceType \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.X_MS_RESOURCE_TYPE);\n    final long contentLength \u003d Long.parseLong(op.getResult().getResponseHeader(HttpHeaderConfigurations.CONTENT_LENGTH));\n    final String eTag \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.ETAG);\n\n    if (parseIsDirectory(resourceType)) {\n      throw new AbfsRestOperationException(\n              AzureServiceErrorCode.PATH_NOT_FOUND.getStatusCode(),\n              AzureServiceErrorCode.PATH_NOT_FOUND.getErrorCode(),\n              \"openFileForRead must be used with files and not directories\",\n              null);\n    }\n\n    // Add statistics for InputStream\n    return new AbfsInputStream(client, statistics,\n            AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path), contentLength,\n                abfsConfiguration.getReadBufferSize(), abfsConfiguration.getReadAheadQueueDepth(), eTag);\n  }",
          "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java",
          "extendedDetails": {
            "oldValue": "InputStream",
            "newValue": "AbfsInputStream"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HADOOP 15688. ABFS: InputStream wrapped in FSDataInputStream twice.\nContributed by Sean Mackrory.\n",
          "commitDate": "17/09/18 12:54 PM",
          "commitName": "6b6f8cc2bedefc98028d875398ce022edaf77933",
          "commitAuthor": "Thomas Marquardt",
          "commitDateOld": "17/09/18 12:54 PM",
          "commitNameOld": "9c1e4e81399913f180131f4faa95604087c6d962",
          "commitAuthorOld": "Thomas Marquardt",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,26 +1,25 @@\n-  public InputStream openFileForRead(final Path path, final FileSystem.Statistics statistics)\n+  public AbfsInputStream openFileForRead(final Path path, final FileSystem.Statistics statistics)\n       throws AzureBlobFileSystemException {\n     LOG.debug(\"openFileForRead filesystem: {} path: {}\",\n             client.getFileSystem(),\n             path);\n \n     final AbfsRestOperation op \u003d client.getPathProperties(AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path));\n \n     final String resourceType \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.X_MS_RESOURCE_TYPE);\n     final long contentLength \u003d Long.parseLong(op.getResult().getResponseHeader(HttpHeaderConfigurations.CONTENT_LENGTH));\n     final String eTag \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.ETAG);\n \n     if (parseIsDirectory(resourceType)) {\n       throw new AbfsRestOperationException(\n               AzureServiceErrorCode.PATH_NOT_FOUND.getStatusCode(),\n               AzureServiceErrorCode.PATH_NOT_FOUND.getErrorCode(),\n               \"openFileForRead must be used with files and not directories\",\n               null);\n     }\n \n     // Add statistics for InputStream\n-    return new FSDataInputStream(\n-            new AbfsInputStream(client, statistics,\n-                AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path), contentLength,\n-                    abfsConfiguration.getReadBufferSize(), abfsConfiguration.getReadAheadQueueDepth(), eTag));\n+    return new AbfsInputStream(client, statistics,\n+            AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path), contentLength,\n+                abfsConfiguration.getReadBufferSize(), abfsConfiguration.getReadAheadQueueDepth(), eTag);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public AbfsInputStream openFileForRead(final Path path, final FileSystem.Statistics statistics)\n      throws AzureBlobFileSystemException {\n    LOG.debug(\"openFileForRead filesystem: {} path: {}\",\n            client.getFileSystem(),\n            path);\n\n    final AbfsRestOperation op \u003d client.getPathProperties(AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path));\n\n    final String resourceType \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.X_MS_RESOURCE_TYPE);\n    final long contentLength \u003d Long.parseLong(op.getResult().getResponseHeader(HttpHeaderConfigurations.CONTENT_LENGTH));\n    final String eTag \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.ETAG);\n\n    if (parseIsDirectory(resourceType)) {\n      throw new AbfsRestOperationException(\n              AzureServiceErrorCode.PATH_NOT_FOUND.getStatusCode(),\n              AzureServiceErrorCode.PATH_NOT_FOUND.getErrorCode(),\n              \"openFileForRead must be used with files and not directories\",\n              null);\n    }\n\n    // Add statistics for InputStream\n    return new AbfsInputStream(client, statistics,\n            AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path), contentLength,\n                abfsConfiguration.getReadBufferSize(), abfsConfiguration.getReadAheadQueueDepth(), eTag);\n  }",
          "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java",
          "extendedDetails": {}
        }
      ]
    },
    "ce03a93f78c4d97ccb48a3906fcd77ad0ac756be": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-15446. ABFS: tune imports \u0026 javadocs; stabilise tests.\nContributed by Steve Loughran and Da Zhou.\n",
      "commitDate": "17/09/18 12:54 PM",
      "commitName": "ce03a93f78c4d97ccb48a3906fcd77ad0ac756be",
      "commitAuthor": "Thomas Marquardt",
      "commitDateOld": "17/09/18 12:54 PM",
      "commitNameOld": "a271fd0eca75cef8b8ba940cdac8ad4fd21b4462",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,26 +1,26 @@\n   public InputStream openFileForRead(final Path path, final FileSystem.Statistics statistics) throws AzureBlobFileSystemException {\n \n-    this.LOG.debug(\n-            \"openFileForRead filesystem: {} path: {}\",\n+    LOG.debug(\"openFileForRead filesystem: {} path: {}\",\n             client.getFileSystem(),\n-            path.toString());\n+            path);\n \n     final AbfsRestOperation op \u003d client.getPathProperties(AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path));\n \n     final String resourceType \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.X_MS_RESOURCE_TYPE);\n     final long contentLength \u003d Long.parseLong(op.getResult().getResponseHeader(HttpHeaderConfigurations.CONTENT_LENGTH));\n     final String eTag \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.ETAG);\n \n     if (parseIsDirectory(resourceType)) {\n       throw new AbfsRestOperationException(\n               AzureServiceErrorCode.PATH_NOT_FOUND.getStatusCode(),\n               AzureServiceErrorCode.PATH_NOT_FOUND.getErrorCode(),\n               \"openFileForRead must be used with files and not directories\",\n               null);\n     }\n \n     // Add statistics for InputStream\n     return new FSDataInputStream(\n-            new AbfsInputStream(client, statistics, AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path), contentLength,\n+            new AbfsInputStream(client, statistics,\n+                AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path), contentLength,\n                     abfsConfiguration.getReadBufferSize(), abfsConfiguration.getReadAheadQueueDepth(), eTag));\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public InputStream openFileForRead(final Path path, final FileSystem.Statistics statistics) throws AzureBlobFileSystemException {\n\n    LOG.debug(\"openFileForRead filesystem: {} path: {}\",\n            client.getFileSystem(),\n            path);\n\n    final AbfsRestOperation op \u003d client.getPathProperties(AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path));\n\n    final String resourceType \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.X_MS_RESOURCE_TYPE);\n    final long contentLength \u003d Long.parseLong(op.getResult().getResponseHeader(HttpHeaderConfigurations.CONTENT_LENGTH));\n    final String eTag \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.ETAG);\n\n    if (parseIsDirectory(resourceType)) {\n      throw new AbfsRestOperationException(\n              AzureServiceErrorCode.PATH_NOT_FOUND.getStatusCode(),\n              AzureServiceErrorCode.PATH_NOT_FOUND.getErrorCode(),\n              \"openFileForRead must be used with files and not directories\",\n              null);\n    }\n\n    // Add statistics for InputStream\n    return new FSDataInputStream(\n            new AbfsInputStream(client, statistics,\n                AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path), contentLength,\n                    abfsConfiguration.getReadBufferSize(), abfsConfiguration.getReadAheadQueueDepth(), eTag));\n  }",
      "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java",
      "extendedDetails": {}
    },
    "a271fd0eca75cef8b8ba940cdac8ad4fd21b4462": {
      "type": "Ymultichange(Yfilerename,Ybodychange,Yparameterchange)",
      "commitMessage": "HADOOP-15560. ABFS: removed dependency injection and unnecessary dependencies.\nContributed by Da Zhou.\n",
      "commitDate": "17/09/18 12:54 PM",
      "commitName": "a271fd0eca75cef8b8ba940cdac8ad4fd21b4462",
      "commitAuthor": "Steve Loughran",
      "subchanges": [
        {
          "type": "Yfilerename",
          "commitMessage": "HADOOP-15560. ABFS: removed dependency injection and unnecessary dependencies.\nContributed by Da Zhou.\n",
          "commitDate": "17/09/18 12:54 PM",
          "commitName": "a271fd0eca75cef8b8ba940cdac8ad4fd21b4462",
          "commitAuthor": "Steve Loughran",
          "commitDateOld": "17/09/18 12:54 PM",
          "commitNameOld": "f044deedbbfee0812316d587139cb828f27172e9",
          "commitAuthorOld": "Steve Loughran",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,28 +1,26 @@\n-  public InputStream openFileForRead(final AzureBlobFileSystem azureBlobFileSystem, final Path path,\n-      final FileSystem.Statistics statistics) throws AzureBlobFileSystemException {\n-    final AbfsClient client \u003d getOrCreateClient(azureBlobFileSystem);\n+  public InputStream openFileForRead(final Path path, final FileSystem.Statistics statistics) throws AzureBlobFileSystemException {\n \n     this.LOG.debug(\n-        \"openFileForRead filesystem: {} path: {}\",\n-        client.getFileSystem(),\n-        path.toString());\n+            \"openFileForRead filesystem: {} path: {}\",\n+            client.getFileSystem(),\n+            path.toString());\n \n     final AbfsRestOperation op \u003d client.getPathProperties(AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path));\n \n     final String resourceType \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.X_MS_RESOURCE_TYPE);\n     final long contentLength \u003d Long.parseLong(op.getResult().getResponseHeader(HttpHeaderConfigurations.CONTENT_LENGTH));\n     final String eTag \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.ETAG);\n \n     if (parseIsDirectory(resourceType)) {\n       throw new AbfsRestOperationException(\n-          AzureServiceErrorCode.PATH_NOT_FOUND.getStatusCode(),\n-          AzureServiceErrorCode.PATH_NOT_FOUND.getErrorCode(),\n-          \"openFileForRead must be used with files and not directories\",\n-          null);\n+              AzureServiceErrorCode.PATH_NOT_FOUND.getStatusCode(),\n+              AzureServiceErrorCode.PATH_NOT_FOUND.getErrorCode(),\n+              \"openFileForRead must be used with files and not directories\",\n+              null);\n     }\n \n     // Add statistics for InputStream\n     return new FSDataInputStream(\n-        new AbfsInputStream(client, statistics, AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path), contentLength,\n-            configurationService.getReadBufferSize(), configurationService.getReadAheadQueueDepth(), eTag));\n+            new AbfsInputStream(client, statistics, AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path), contentLength,\n+                    abfsConfiguration.getReadBufferSize(), abfsConfiguration.getReadAheadQueueDepth(), eTag));\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public InputStream openFileForRead(final Path path, final FileSystem.Statistics statistics) throws AzureBlobFileSystemException {\n\n    this.LOG.debug(\n            \"openFileForRead filesystem: {} path: {}\",\n            client.getFileSystem(),\n            path.toString());\n\n    final AbfsRestOperation op \u003d client.getPathProperties(AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path));\n\n    final String resourceType \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.X_MS_RESOURCE_TYPE);\n    final long contentLength \u003d Long.parseLong(op.getResult().getResponseHeader(HttpHeaderConfigurations.CONTENT_LENGTH));\n    final String eTag \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.ETAG);\n\n    if (parseIsDirectory(resourceType)) {\n      throw new AbfsRestOperationException(\n              AzureServiceErrorCode.PATH_NOT_FOUND.getStatusCode(),\n              AzureServiceErrorCode.PATH_NOT_FOUND.getErrorCode(),\n              \"openFileForRead must be used with files and not directories\",\n              null);\n    }\n\n    // Add statistics for InputStream\n    return new FSDataInputStream(\n            new AbfsInputStream(client, statistics, AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path), contentLength,\n                    abfsConfiguration.getReadBufferSize(), abfsConfiguration.getReadAheadQueueDepth(), eTag));\n  }",
          "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java",
          "extendedDetails": {
            "oldPath": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsHttpServiceImpl.java",
            "newPath": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HADOOP-15560. ABFS: removed dependency injection and unnecessary dependencies.\nContributed by Da Zhou.\n",
          "commitDate": "17/09/18 12:54 PM",
          "commitName": "a271fd0eca75cef8b8ba940cdac8ad4fd21b4462",
          "commitAuthor": "Steve Loughran",
          "commitDateOld": "17/09/18 12:54 PM",
          "commitNameOld": "f044deedbbfee0812316d587139cb828f27172e9",
          "commitAuthorOld": "Steve Loughran",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,28 +1,26 @@\n-  public InputStream openFileForRead(final AzureBlobFileSystem azureBlobFileSystem, final Path path,\n-      final FileSystem.Statistics statistics) throws AzureBlobFileSystemException {\n-    final AbfsClient client \u003d getOrCreateClient(azureBlobFileSystem);\n+  public InputStream openFileForRead(final Path path, final FileSystem.Statistics statistics) throws AzureBlobFileSystemException {\n \n     this.LOG.debug(\n-        \"openFileForRead filesystem: {} path: {}\",\n-        client.getFileSystem(),\n-        path.toString());\n+            \"openFileForRead filesystem: {} path: {}\",\n+            client.getFileSystem(),\n+            path.toString());\n \n     final AbfsRestOperation op \u003d client.getPathProperties(AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path));\n \n     final String resourceType \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.X_MS_RESOURCE_TYPE);\n     final long contentLength \u003d Long.parseLong(op.getResult().getResponseHeader(HttpHeaderConfigurations.CONTENT_LENGTH));\n     final String eTag \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.ETAG);\n \n     if (parseIsDirectory(resourceType)) {\n       throw new AbfsRestOperationException(\n-          AzureServiceErrorCode.PATH_NOT_FOUND.getStatusCode(),\n-          AzureServiceErrorCode.PATH_NOT_FOUND.getErrorCode(),\n-          \"openFileForRead must be used with files and not directories\",\n-          null);\n+              AzureServiceErrorCode.PATH_NOT_FOUND.getStatusCode(),\n+              AzureServiceErrorCode.PATH_NOT_FOUND.getErrorCode(),\n+              \"openFileForRead must be used with files and not directories\",\n+              null);\n     }\n \n     // Add statistics for InputStream\n     return new FSDataInputStream(\n-        new AbfsInputStream(client, statistics, AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path), contentLength,\n-            configurationService.getReadBufferSize(), configurationService.getReadAheadQueueDepth(), eTag));\n+            new AbfsInputStream(client, statistics, AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path), contentLength,\n+                    abfsConfiguration.getReadBufferSize(), abfsConfiguration.getReadAheadQueueDepth(), eTag));\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public InputStream openFileForRead(final Path path, final FileSystem.Statistics statistics) throws AzureBlobFileSystemException {\n\n    this.LOG.debug(\n            \"openFileForRead filesystem: {} path: {}\",\n            client.getFileSystem(),\n            path.toString());\n\n    final AbfsRestOperation op \u003d client.getPathProperties(AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path));\n\n    final String resourceType \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.X_MS_RESOURCE_TYPE);\n    final long contentLength \u003d Long.parseLong(op.getResult().getResponseHeader(HttpHeaderConfigurations.CONTENT_LENGTH));\n    final String eTag \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.ETAG);\n\n    if (parseIsDirectory(resourceType)) {\n      throw new AbfsRestOperationException(\n              AzureServiceErrorCode.PATH_NOT_FOUND.getStatusCode(),\n              AzureServiceErrorCode.PATH_NOT_FOUND.getErrorCode(),\n              \"openFileForRead must be used with files and not directories\",\n              null);\n    }\n\n    // Add statistics for InputStream\n    return new FSDataInputStream(\n            new AbfsInputStream(client, statistics, AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path), contentLength,\n                    abfsConfiguration.getReadBufferSize(), abfsConfiguration.getReadAheadQueueDepth(), eTag));\n  }",
          "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java",
          "extendedDetails": {}
        },
        {
          "type": "Yparameterchange",
          "commitMessage": "HADOOP-15560. ABFS: removed dependency injection and unnecessary dependencies.\nContributed by Da Zhou.\n",
          "commitDate": "17/09/18 12:54 PM",
          "commitName": "a271fd0eca75cef8b8ba940cdac8ad4fd21b4462",
          "commitAuthor": "Steve Loughran",
          "commitDateOld": "17/09/18 12:54 PM",
          "commitNameOld": "f044deedbbfee0812316d587139cb828f27172e9",
          "commitAuthorOld": "Steve Loughran",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,28 +1,26 @@\n-  public InputStream openFileForRead(final AzureBlobFileSystem azureBlobFileSystem, final Path path,\n-      final FileSystem.Statistics statistics) throws AzureBlobFileSystemException {\n-    final AbfsClient client \u003d getOrCreateClient(azureBlobFileSystem);\n+  public InputStream openFileForRead(final Path path, final FileSystem.Statistics statistics) throws AzureBlobFileSystemException {\n \n     this.LOG.debug(\n-        \"openFileForRead filesystem: {} path: {}\",\n-        client.getFileSystem(),\n-        path.toString());\n+            \"openFileForRead filesystem: {} path: {}\",\n+            client.getFileSystem(),\n+            path.toString());\n \n     final AbfsRestOperation op \u003d client.getPathProperties(AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path));\n \n     final String resourceType \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.X_MS_RESOURCE_TYPE);\n     final long contentLength \u003d Long.parseLong(op.getResult().getResponseHeader(HttpHeaderConfigurations.CONTENT_LENGTH));\n     final String eTag \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.ETAG);\n \n     if (parseIsDirectory(resourceType)) {\n       throw new AbfsRestOperationException(\n-          AzureServiceErrorCode.PATH_NOT_FOUND.getStatusCode(),\n-          AzureServiceErrorCode.PATH_NOT_FOUND.getErrorCode(),\n-          \"openFileForRead must be used with files and not directories\",\n-          null);\n+              AzureServiceErrorCode.PATH_NOT_FOUND.getStatusCode(),\n+              AzureServiceErrorCode.PATH_NOT_FOUND.getErrorCode(),\n+              \"openFileForRead must be used with files and not directories\",\n+              null);\n     }\n \n     // Add statistics for InputStream\n     return new FSDataInputStream(\n-        new AbfsInputStream(client, statistics, AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path), contentLength,\n-            configurationService.getReadBufferSize(), configurationService.getReadAheadQueueDepth(), eTag));\n+            new AbfsInputStream(client, statistics, AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path), contentLength,\n+                    abfsConfiguration.getReadBufferSize(), abfsConfiguration.getReadAheadQueueDepth(), eTag));\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public InputStream openFileForRead(final Path path, final FileSystem.Statistics statistics) throws AzureBlobFileSystemException {\n\n    this.LOG.debug(\n            \"openFileForRead filesystem: {} path: {}\",\n            client.getFileSystem(),\n            path.toString());\n\n    final AbfsRestOperation op \u003d client.getPathProperties(AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path));\n\n    final String resourceType \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.X_MS_RESOURCE_TYPE);\n    final long contentLength \u003d Long.parseLong(op.getResult().getResponseHeader(HttpHeaderConfigurations.CONTENT_LENGTH));\n    final String eTag \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.ETAG);\n\n    if (parseIsDirectory(resourceType)) {\n      throw new AbfsRestOperationException(\n              AzureServiceErrorCode.PATH_NOT_FOUND.getStatusCode(),\n              AzureServiceErrorCode.PATH_NOT_FOUND.getErrorCode(),\n              \"openFileForRead must be used with files and not directories\",\n              null);\n    }\n\n    // Add statistics for InputStream\n    return new FSDataInputStream(\n            new AbfsInputStream(client, statistics, AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path), contentLength,\n                    abfsConfiguration.getReadBufferSize(), abfsConfiguration.getReadAheadQueueDepth(), eTag));\n  }",
          "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java",
          "extendedDetails": {
            "oldValue": "[azureBlobFileSystem-AzureBlobFileSystem(modifiers-final), path-Path(modifiers-final), statistics-FileSystem.Statistics(modifiers-final)]",
            "newValue": "[path-Path(modifiers-final), statistics-FileSystem.Statistics(modifiers-final)]"
          }
        }
      ]
    },
    "f044deedbbfee0812316d587139cb828f27172e9": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-15407. HADOOP-15540. Support Windows Azure Storage - Blob file system \"ABFS\" in Hadoop: Core Commit.\n\nContributed by Shane Mainali, Thomas Marquardt, Zichen Sun, Georgi Chalakov, Esfandiar Manii, Amit Singh, Dana Kaban, Da Zhou, Junhua Gu, Saher Ahwal, Saurabh Pant, James Baker, Shaoyu Zhang, Lawrence Chen, Kevin Chen and Steve Loughran\n",
      "commitDate": "17/09/18 12:54 PM",
      "commitName": "f044deedbbfee0812316d587139cb828f27172e9",
      "commitAuthor": "Steve Loughran",
      "diff": "@@ -0,0 +1,28 @@\n+  public InputStream openFileForRead(final AzureBlobFileSystem azureBlobFileSystem, final Path path,\n+      final FileSystem.Statistics statistics) throws AzureBlobFileSystemException {\n+    final AbfsClient client \u003d getOrCreateClient(azureBlobFileSystem);\n+\n+    this.LOG.debug(\n+        \"openFileForRead filesystem: {} path: {}\",\n+        client.getFileSystem(),\n+        path.toString());\n+\n+    final AbfsRestOperation op \u003d client.getPathProperties(AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path));\n+\n+    final String resourceType \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.X_MS_RESOURCE_TYPE);\n+    final long contentLength \u003d Long.parseLong(op.getResult().getResponseHeader(HttpHeaderConfigurations.CONTENT_LENGTH));\n+    final String eTag \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.ETAG);\n+\n+    if (parseIsDirectory(resourceType)) {\n+      throw new AbfsRestOperationException(\n+          AzureServiceErrorCode.PATH_NOT_FOUND.getStatusCode(),\n+          AzureServiceErrorCode.PATH_NOT_FOUND.getErrorCode(),\n+          \"openFileForRead must be used with files and not directories\",\n+          null);\n+    }\n+\n+    // Add statistics for InputStream\n+    return new FSDataInputStream(\n+        new AbfsInputStream(client, statistics, AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path), contentLength,\n+            configurationService.getReadBufferSize(), configurationService.getReadAheadQueueDepth(), eTag));\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public InputStream openFileForRead(final AzureBlobFileSystem azureBlobFileSystem, final Path path,\n      final FileSystem.Statistics statistics) throws AzureBlobFileSystemException {\n    final AbfsClient client \u003d getOrCreateClient(azureBlobFileSystem);\n\n    this.LOG.debug(\n        \"openFileForRead filesystem: {} path: {}\",\n        client.getFileSystem(),\n        path.toString());\n\n    final AbfsRestOperation op \u003d client.getPathProperties(AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path));\n\n    final String resourceType \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.X_MS_RESOURCE_TYPE);\n    final long contentLength \u003d Long.parseLong(op.getResult().getResponseHeader(HttpHeaderConfigurations.CONTENT_LENGTH));\n    final String eTag \u003d op.getResult().getResponseHeader(HttpHeaderConfigurations.ETAG);\n\n    if (parseIsDirectory(resourceType)) {\n      throw new AbfsRestOperationException(\n          AzureServiceErrorCode.PATH_NOT_FOUND.getStatusCode(),\n          AzureServiceErrorCode.PATH_NOT_FOUND.getErrorCode(),\n          \"openFileForRead must be used with files and not directories\",\n          null);\n    }\n\n    // Add statistics for InputStream\n    return new FSDataInputStream(\n        new AbfsInputStream(client, statistics, AbfsHttpConstants.FORWARD_SLASH + getRelativePath(path), contentLength,\n            configurationService.getReadBufferSize(), configurationService.getReadAheadQueueDepth(), eTag));\n  }",
      "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsHttpServiceImpl.java"
    }
  }
}