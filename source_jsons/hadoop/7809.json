{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "JournalSet.java",
  "functionName": "writeRaw",
  "functionId": "writeRaw___data-byte[](modifiers-final)__offset-int(modifiers-final)__length-int(modifiers-final)",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/JournalSet.java",
  "functionStartLine": 457,
  "functionEndLine": 467,
  "numCommitsSeen": 33,
  "timeTaken": 1210,
  "changeHistory": [
    "d18e5b38447273b95d975c703df25fe5f679e006",
    "1ae5b5e338ef383c5642e2f04b927871c7b184f6"
  ],
  "changeHistoryShort": {
    "d18e5b38447273b95d975c703df25fe5f679e006": "Ymodifierchange",
    "1ae5b5e338ef383c5642e2f04b927871c7b184f6": "Yintroduced"
  },
  "changeHistoryDetails": {
    "d18e5b38447273b95d975c703df25fe5f679e006": {
      "type": "Ymodifierchange",
      "commitMessage": "HDFS-1580. Add interface for generic Write Ahead Logging mechanisms. Contributed by Ivan Kelly.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1210602 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "05/12/11 12:10 PM",
      "commitName": "d18e5b38447273b95d975c703df25fe5f679e006",
      "commitAuthor": "Jitendra Nath Pandey",
      "commitDateOld": "31/10/11 12:03 PM",
      "commitNameOld": "7cb77a3b1bf9e41384a1f74a60d34214199755d8",
      "commitAuthorOld": "Jitendra Nath Pandey",
      "daysBetweenCommits": 35.05,
      "commitsBetweenForRepo": 187,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,11 +1,11 @@\n-    void writeRaw(final byte[] data, final int offset, final int length)\n+    public void writeRaw(final byte[] data, final int offset, final int length)\n         throws IOException {\n       mapJournalsAndReportErrors(new JournalClosure() {\n         @Override\n         public void apply(JournalAndStream jas) throws IOException {\n           if (jas.isActive()) {\n             jas.getCurrentStream().writeRaw(data, offset, length);\n           }\n         }\n       }, \"write bytes\");\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void writeRaw(final byte[] data, final int offset, final int length)\n        throws IOException {\n      mapJournalsAndReportErrors(new JournalClosure() {\n        @Override\n        public void apply(JournalAndStream jas) throws IOException {\n          if (jas.isActive()) {\n            jas.getCurrentStream().writeRaw(data, offset, length);\n          }\n        }\n      }, \"write bytes\");\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/JournalSet.java",
      "extendedDetails": {
        "oldValue": "[]",
        "newValue": "[public]"
      }
    },
    "1ae5b5e338ef383c5642e2f04b927871c7b184f6": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-2158. Add JournalSet to manage the set of journals.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1177473 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "29/09/11 6:14 PM",
      "commitName": "1ae5b5e338ef383c5642e2f04b927871c7b184f6",
      "commitAuthor": "Jitendra Nath Pandey",
      "diff": "@@ -0,0 +1,11 @@\n+    void writeRaw(final byte[] data, final int offset, final int length)\n+        throws IOException {\n+      mapJournalsAndReportErrors(new JournalClosure() {\n+        @Override\n+        public void apply(JournalAndStream jas) throws IOException {\n+          if (jas.isActive()) {\n+            jas.getCurrentStream().writeRaw(data, offset, length);\n+          }\n+        }\n+      }, \"write bytes\");\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    void writeRaw(final byte[] data, final int offset, final int length)\n        throws IOException {\n      mapJournalsAndReportErrors(new JournalClosure() {\n        @Override\n        public void apply(JournalAndStream jas) throws IOException {\n          if (jas.isActive()) {\n            jas.getCurrentStream().writeRaw(data, offset, length);\n          }\n        }\n      }, \"write bytes\");\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/JournalSet.java"
    }
  }
}