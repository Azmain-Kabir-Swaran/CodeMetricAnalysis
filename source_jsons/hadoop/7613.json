{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "NameNode.java",
  "functionName": "reconfigurePropertyImpl",
  "functionId": "reconfigurePropertyImpl___property-String__newVal-String",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java",
  "functionStartLine": 2164,
  "functionEndLine": 2194,
  "numCommitsSeen": 210,
  "timeTaken": 7774,
  "changeHistory": [
    "209630472a3216c9f13bcffa62b553f9fb7675ca",
    "4f455290b15902e7e44c4b1a762bf915414b2bb6",
    "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52",
    "3b83110d5ed582b9f913ecf3f62ce410535f8fca",
    "0e820f16af309cc8476edba448dd548686431133",
    "5179d99b7e1faeac1ce041967480115913d9f795",
    "b4be288c5d6801988f555a566c2eb793c88a15a4",
    "5566177c9af913baf380811dbbb1fa7e70235491",
    "4895c73dd493a53eab43f0d16e92c19af15c460b",
    "192112d5a2e7ce4ec8eb47e21ab744b34c848893",
    "ddfe6774c21c8ccf5582a05bb0b58e961bbec309",
    "e01c6ea688e62f25c4310e771a0cd85b53a5fb87"
  ],
  "changeHistoryShort": {
    "209630472a3216c9f13bcffa62b553f9fb7675ca": "Ybodychange",
    "4f455290b15902e7e44c4b1a762bf915414b2bb6": "Ybodychange",
    "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52": "Ybodychange",
    "3b83110d5ed582b9f913ecf3f62ce410535f8fca": "Ybodychange",
    "0e820f16af309cc8476edba448dd548686431133": "Ybodychange",
    "5179d99b7e1faeac1ce041967480115913d9f795": "Ybodychange",
    "b4be288c5d6801988f555a566c2eb793c88a15a4": "Ybodychange",
    "5566177c9af913baf380811dbbb1fa7e70235491": "Ybodychange",
    "4895c73dd493a53eab43f0d16e92c19af15c460b": "Ybodychange",
    "192112d5a2e7ce4ec8eb47e21ab744b34c848893": "Ybodychange",
    "ddfe6774c21c8ccf5582a05bb0b58e961bbec309": "Ybodychange",
    "e01c6ea688e62f25c4310e771a0cd85b53a5fb87": "Yintroduced"
  },
  "changeHistoryDetails": {
    "209630472a3216c9f13bcffa62b553f9fb7675ca": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-15120. Refresh BlockPlacementPolicy at runtime. Contributed by Jinglun.\n",
      "commitDate": "26/02/20 12:52 PM",
      "commitName": "209630472a3216c9f13bcffa62b553f9fb7675ca",
      "commitAuthor": "Ayush Saxena",
      "commitDateOld": "23/02/20 10:37 AM",
      "commitNameOld": "b5698e0c33efd546dfea99980840c6e726795df3",
      "commitAuthorOld": "Ayush Saxena",
      "daysBetweenCommits": 3.09,
      "commitsBetweenForRepo": 17,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,27 +1,31 @@\n   protected String reconfigurePropertyImpl(String property, String newVal)\n       throws ReconfigurationException {\n     final DatanodeManager datanodeManager \u003d namesystem.getBlockManager()\n         .getDatanodeManager();\n \n     if (property.equals(DFS_HEARTBEAT_INTERVAL_KEY)) {\n       return reconfHeartbeatInterval(datanodeManager, property, newVal);\n     } else if (property.equals(DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY)) {\n       return reconfHeartbeatRecheckInterval(datanodeManager, property, newVal);\n     } else if (property.equals(FS_PROTECTED_DIRECTORIES)) {\n       return reconfProtectedDirectories(newVal);\n     } else if (property.equals(HADOOP_CALLER_CONTEXT_ENABLED_KEY)) {\n       return reconfCallerContextEnabled(newVal);\n     } else if (property.equals(ipcClientRPCBackoffEnable)) {\n       return reconfigureIPCBackoffEnabled(newVal);\n     } else if (property.equals(DFS_STORAGE_POLICY_SATISFIER_MODE_KEY)) {\n       return reconfigureSPSModeEvent(newVal, property);\n     } else if (property.equals(DFS_NAMENODE_REPLICATION_MAX_STREAMS_KEY)\n         || property.equals(DFS_NAMENODE_REPLICATION_STREAMS_HARD_LIMIT_KEY)\n         || property.equals(\n             DFS_NAMENODE_REPLICATION_WORK_MULTIPLIER_PER_ITERATION)) {\n       return reconfReplicationParameters(newVal, property);\n+    } else if (property.equals(DFS_BLOCK_REPLICATOR_CLASSNAME_KEY) || property\n+        .equals(DFS_BLOCK_PLACEMENT_EC_CLASSNAME_KEY)) {\n+      reconfBlockPlacementPolicy();\n+      return newVal;\n     } else {\n       throw new ReconfigurationException(property, newVal, getConf().get(\n           property));\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected String reconfigurePropertyImpl(String property, String newVal)\n      throws ReconfigurationException {\n    final DatanodeManager datanodeManager \u003d namesystem.getBlockManager()\n        .getDatanodeManager();\n\n    if (property.equals(DFS_HEARTBEAT_INTERVAL_KEY)) {\n      return reconfHeartbeatInterval(datanodeManager, property, newVal);\n    } else if (property.equals(DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY)) {\n      return reconfHeartbeatRecheckInterval(datanodeManager, property, newVal);\n    } else if (property.equals(FS_PROTECTED_DIRECTORIES)) {\n      return reconfProtectedDirectories(newVal);\n    } else if (property.equals(HADOOP_CALLER_CONTEXT_ENABLED_KEY)) {\n      return reconfCallerContextEnabled(newVal);\n    } else if (property.equals(ipcClientRPCBackoffEnable)) {\n      return reconfigureIPCBackoffEnabled(newVal);\n    } else if (property.equals(DFS_STORAGE_POLICY_SATISFIER_MODE_KEY)) {\n      return reconfigureSPSModeEvent(newVal, property);\n    } else if (property.equals(DFS_NAMENODE_REPLICATION_MAX_STREAMS_KEY)\n        || property.equals(DFS_NAMENODE_REPLICATION_STREAMS_HARD_LIMIT_KEY)\n        || property.equals(\n            DFS_NAMENODE_REPLICATION_WORK_MULTIPLIER_PER_ITERATION)) {\n      return reconfReplicationParameters(newVal, property);\n    } else if (property.equals(DFS_BLOCK_REPLICATOR_CLASSNAME_KEY) || property\n        .equals(DFS_BLOCK_PLACEMENT_EC_CLASSNAME_KEY)) {\n      reconfBlockPlacementPolicy();\n      return newVal;\n    } else {\n      throw new ReconfigurationException(property, newVal, getConf().get(\n          property));\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java",
      "extendedDetails": {}
    },
    "4f455290b15902e7e44c4b1a762bf915414b2bb6": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14560. Allow block replication parameters to be refreshable. Contributed by Stephen O\u0027Donnell.\n",
      "commitDate": "13/06/19 6:26 PM",
      "commitName": "4f455290b15902e7e44c4b1a762bf915414b2bb6",
      "commitAuthor": "Inigo Goiri",
      "commitDateOld": "24/12/18 9:33 AM",
      "commitNameOld": "091ad974cd29fae0cf8fbc98ab84900a1a324839",
      "commitAuthorOld": "Erik Krogen",
      "daysBetweenCommits": 171.33,
      "commitsBetweenForRepo": 1205,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,27 @@\n   protected String reconfigurePropertyImpl(String property, String newVal)\n       throws ReconfigurationException {\n     final DatanodeManager datanodeManager \u003d namesystem.getBlockManager()\n         .getDatanodeManager();\n \n     if (property.equals(DFS_HEARTBEAT_INTERVAL_KEY)) {\n       return reconfHeartbeatInterval(datanodeManager, property, newVal);\n     } else if (property.equals(DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY)) {\n       return reconfHeartbeatRecheckInterval(datanodeManager, property, newVal);\n     } else if (property.equals(FS_PROTECTED_DIRECTORIES)) {\n       return reconfProtectedDirectories(newVal);\n     } else if (property.equals(HADOOP_CALLER_CONTEXT_ENABLED_KEY)) {\n       return reconfCallerContextEnabled(newVal);\n     } else if (property.equals(ipcClientRPCBackoffEnable)) {\n       return reconfigureIPCBackoffEnabled(newVal);\n     } else if (property.equals(DFS_STORAGE_POLICY_SATISFIER_MODE_KEY)) {\n       return reconfigureSPSModeEvent(newVal, property);\n+    } else if (property.equals(DFS_NAMENODE_REPLICATION_MAX_STREAMS_KEY)\n+        || property.equals(DFS_NAMENODE_REPLICATION_STREAMS_HARD_LIMIT_KEY)\n+        || property.equals(\n+            DFS_NAMENODE_REPLICATION_WORK_MULTIPLIER_PER_ITERATION)) {\n+      return reconfReplicationParameters(newVal, property);\n     } else {\n       throw new ReconfigurationException(property, newVal, getConf().get(\n           property));\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected String reconfigurePropertyImpl(String property, String newVal)\n      throws ReconfigurationException {\n    final DatanodeManager datanodeManager \u003d namesystem.getBlockManager()\n        .getDatanodeManager();\n\n    if (property.equals(DFS_HEARTBEAT_INTERVAL_KEY)) {\n      return reconfHeartbeatInterval(datanodeManager, property, newVal);\n    } else if (property.equals(DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY)) {\n      return reconfHeartbeatRecheckInterval(datanodeManager, property, newVal);\n    } else if (property.equals(FS_PROTECTED_DIRECTORIES)) {\n      return reconfProtectedDirectories(newVal);\n    } else if (property.equals(HADOOP_CALLER_CONTEXT_ENABLED_KEY)) {\n      return reconfCallerContextEnabled(newVal);\n    } else if (property.equals(ipcClientRPCBackoffEnable)) {\n      return reconfigureIPCBackoffEnabled(newVal);\n    } else if (property.equals(DFS_STORAGE_POLICY_SATISFIER_MODE_KEY)) {\n      return reconfigureSPSModeEvent(newVal, property);\n    } else if (property.equals(DFS_NAMENODE_REPLICATION_MAX_STREAMS_KEY)\n        || property.equals(DFS_NAMENODE_REPLICATION_STREAMS_HARD_LIMIT_KEY)\n        || property.equals(\n            DFS_NAMENODE_REPLICATION_WORK_MULTIPLIER_PER_ITERATION)) {\n      return reconfReplicationParameters(newVal, property);\n    } else {\n      throw new ReconfigurationException(property, newVal, getConf().get(\n          property));\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java",
      "extendedDetails": {}
    },
    "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13097: [SPS]: Fix the branch review comments(Part1). Contributed by Surendra Singh.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "3b83110d5ed582b9f913ecf3f62ce410535f8fca",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,22 @@\n   protected String reconfigurePropertyImpl(String property, String newVal)\n       throws ReconfigurationException {\n     final DatanodeManager datanodeManager \u003d namesystem.getBlockManager()\n         .getDatanodeManager();\n \n     if (property.equals(DFS_HEARTBEAT_INTERVAL_KEY)) {\n       return reconfHeartbeatInterval(datanodeManager, property, newVal);\n     } else if (property.equals(DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY)) {\n       return reconfHeartbeatRecheckInterval(datanodeManager, property, newVal);\n     } else if (property.equals(FS_PROTECTED_DIRECTORIES)) {\n       return reconfProtectedDirectories(newVal);\n     } else if (property.equals(HADOOP_CALLER_CONTEXT_ENABLED_KEY)) {\n       return reconfCallerContextEnabled(newVal);\n     } else if (property.equals(ipcClientRPCBackoffEnable)) {\n       return reconfigureIPCBackoffEnabled(newVal);\n     } else if (property.equals(DFS_STORAGE_POLICY_SATISFIER_MODE_KEY)) {\n-      return reconfigureSPSEnabled(newVal, property);\n+      return reconfigureSPSModeEvent(newVal, property);\n     } else {\n       throw new ReconfigurationException(property, newVal, getConf().get(\n           property));\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected String reconfigurePropertyImpl(String property, String newVal)\n      throws ReconfigurationException {\n    final DatanodeManager datanodeManager \u003d namesystem.getBlockManager()\n        .getDatanodeManager();\n\n    if (property.equals(DFS_HEARTBEAT_INTERVAL_KEY)) {\n      return reconfHeartbeatInterval(datanodeManager, property, newVal);\n    } else if (property.equals(DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY)) {\n      return reconfHeartbeatRecheckInterval(datanodeManager, property, newVal);\n    } else if (property.equals(FS_PROTECTED_DIRECTORIES)) {\n      return reconfProtectedDirectories(newVal);\n    } else if (property.equals(HADOOP_CALLER_CONTEXT_ENABLED_KEY)) {\n      return reconfCallerContextEnabled(newVal);\n    } else if (property.equals(ipcClientRPCBackoffEnable)) {\n      return reconfigureIPCBackoffEnabled(newVal);\n    } else if (property.equals(DFS_STORAGE_POLICY_SATISFIER_MODE_KEY)) {\n      return reconfigureSPSModeEvent(newVal, property);\n    } else {\n      throw new ReconfigurationException(property, newVal, getConf().get(\n          property));\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java",
      "extendedDetails": {}
    },
    "3b83110d5ed582b9f913ecf3f62ce410535f8fca": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13057: [SPS]: Revisit configurations to make SPS service modes internal/external/none. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "3b83110d5ed582b9f913ecf3f62ce410535f8fca",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "0e820f16af309cc8476edba448dd548686431133",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 13,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,22 @@\n   protected String reconfigurePropertyImpl(String property, String newVal)\n       throws ReconfigurationException {\n     final DatanodeManager datanodeManager \u003d namesystem.getBlockManager()\n         .getDatanodeManager();\n \n     if (property.equals(DFS_HEARTBEAT_INTERVAL_KEY)) {\n       return reconfHeartbeatInterval(datanodeManager, property, newVal);\n     } else if (property.equals(DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY)) {\n       return reconfHeartbeatRecheckInterval(datanodeManager, property, newVal);\n     } else if (property.equals(FS_PROTECTED_DIRECTORIES)) {\n       return reconfProtectedDirectories(newVal);\n     } else if (property.equals(HADOOP_CALLER_CONTEXT_ENABLED_KEY)) {\n       return reconfCallerContextEnabled(newVal);\n     } else if (property.equals(ipcClientRPCBackoffEnable)) {\n       return reconfigureIPCBackoffEnabled(newVal);\n-    } else if (property.equals(DFS_STORAGE_POLICY_SATISFIER_ENABLED_KEY)) {\n+    } else if (property.equals(DFS_STORAGE_POLICY_SATISFIER_MODE_KEY)) {\n       return reconfigureSPSEnabled(newVal, property);\n     } else {\n       throw new ReconfigurationException(property, newVal, getConf().get(\n           property));\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected String reconfigurePropertyImpl(String property, String newVal)\n      throws ReconfigurationException {\n    final DatanodeManager datanodeManager \u003d namesystem.getBlockManager()\n        .getDatanodeManager();\n\n    if (property.equals(DFS_HEARTBEAT_INTERVAL_KEY)) {\n      return reconfHeartbeatInterval(datanodeManager, property, newVal);\n    } else if (property.equals(DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY)) {\n      return reconfHeartbeatRecheckInterval(datanodeManager, property, newVal);\n    } else if (property.equals(FS_PROTECTED_DIRECTORIES)) {\n      return reconfProtectedDirectories(newVal);\n    } else if (property.equals(HADOOP_CALLER_CONTEXT_ENABLED_KEY)) {\n      return reconfCallerContextEnabled(newVal);\n    } else if (property.equals(ipcClientRPCBackoffEnable)) {\n      return reconfigureIPCBackoffEnabled(newVal);\n    } else if (property.equals(DFS_STORAGE_POLICY_SATISFIER_MODE_KEY)) {\n      return reconfigureSPSEnabled(newVal, property);\n    } else {\n      throw new ReconfigurationException(property, newVal, getConf().get(\n          property));\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java",
      "extendedDetails": {}
    },
    "0e820f16af309cc8476edba448dd548686431133": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12214: [SPS]: Fix review comments of StoragePolicySatisfier feature. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "0e820f16af309cc8476edba448dd548686431133",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:05 AM",
      "commitNameOld": "681d2804c95e5a569ffb8d9ceafaf5a4f8be2b88",
      "commitAuthorOld": "Rakesh Radhakrishnan",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 20,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,22 @@\n   protected String reconfigurePropertyImpl(String property, String newVal)\n       throws ReconfigurationException {\n     final DatanodeManager datanodeManager \u003d namesystem.getBlockManager()\n         .getDatanodeManager();\n \n     if (property.equals(DFS_HEARTBEAT_INTERVAL_KEY)) {\n       return reconfHeartbeatInterval(datanodeManager, property, newVal);\n     } else if (property.equals(DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY)) {\n       return reconfHeartbeatRecheckInterval(datanodeManager, property, newVal);\n     } else if (property.equals(FS_PROTECTED_DIRECTORIES)) {\n       return reconfProtectedDirectories(newVal);\n     } else if (property.equals(HADOOP_CALLER_CONTEXT_ENABLED_KEY)) {\n       return reconfCallerContextEnabled(newVal);\n     } else if (property.equals(ipcClientRPCBackoffEnable)) {\n       return reconfigureIPCBackoffEnabled(newVal);\n-    } else if (property.equals(DFS_STORAGE_POLICY_SATISFIER_ACTIVATE_KEY)) {\n-      return reconfigureSPSActivate(newVal, property);\n+    } else if (property.equals(DFS_STORAGE_POLICY_SATISFIER_ENABLED_KEY)) {\n+      return reconfigureSPSEnabled(newVal, property);\n     } else {\n       throw new ReconfigurationException(property, newVal, getConf().get(\n           property));\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected String reconfigurePropertyImpl(String property, String newVal)\n      throws ReconfigurationException {\n    final DatanodeManager datanodeManager \u003d namesystem.getBlockManager()\n        .getDatanodeManager();\n\n    if (property.equals(DFS_HEARTBEAT_INTERVAL_KEY)) {\n      return reconfHeartbeatInterval(datanodeManager, property, newVal);\n    } else if (property.equals(DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY)) {\n      return reconfHeartbeatRecheckInterval(datanodeManager, property, newVal);\n    } else if (property.equals(FS_PROTECTED_DIRECTORIES)) {\n      return reconfProtectedDirectories(newVal);\n    } else if (property.equals(HADOOP_CALLER_CONTEXT_ENABLED_KEY)) {\n      return reconfCallerContextEnabled(newVal);\n    } else if (property.equals(ipcClientRPCBackoffEnable)) {\n      return reconfigureIPCBackoffEnabled(newVal);\n    } else if (property.equals(DFS_STORAGE_POLICY_SATISFIER_ENABLED_KEY)) {\n      return reconfigureSPSEnabled(newVal, property);\n    } else {\n      throw new ReconfigurationException(property, newVal, getConf().get(\n          property));\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java",
      "extendedDetails": {}
    },
    "5179d99b7e1faeac1ce041967480115913d9f795": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11123. [SPS] Make storage policy satisfier daemon work on/off dynamically. Contributed by Uma Maheswara Rao G\n",
      "commitDate": "12/08/18 3:05 AM",
      "commitName": "5179d99b7e1faeac1ce041967480115913d9f795",
      "commitAuthor": "Rakesh Radhakrishnan",
      "commitDateOld": "10/08/18 3:59 PM",
      "commitNameOld": "a2a8c486998b81d2c73804a07cc74f5269bfd904",
      "commitAuthorOld": "Chao Sun",
      "daysBetweenCommits": 1.46,
      "commitsBetweenForRepo": 11,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,22 @@\n   protected String reconfigurePropertyImpl(String property, String newVal)\n       throws ReconfigurationException {\n     final DatanodeManager datanodeManager \u003d namesystem.getBlockManager()\n         .getDatanodeManager();\n \n     if (property.equals(DFS_HEARTBEAT_INTERVAL_KEY)) {\n       return reconfHeartbeatInterval(datanodeManager, property, newVal);\n     } else if (property.equals(DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY)) {\n       return reconfHeartbeatRecheckInterval(datanodeManager, property, newVal);\n     } else if (property.equals(FS_PROTECTED_DIRECTORIES)) {\n       return reconfProtectedDirectories(newVal);\n     } else if (property.equals(HADOOP_CALLER_CONTEXT_ENABLED_KEY)) {\n       return reconfCallerContextEnabled(newVal);\n     } else if (property.equals(ipcClientRPCBackoffEnable)) {\n       return reconfigureIPCBackoffEnabled(newVal);\n+    } else if (property.equals(DFS_STORAGE_POLICY_SATISFIER_ACTIVATE_KEY)) {\n+      return reconfigureSPSActivate(newVal, property);\n     } else {\n       throw new ReconfigurationException(property, newVal, getConf().get(\n           property));\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected String reconfigurePropertyImpl(String property, String newVal)\n      throws ReconfigurationException {\n    final DatanodeManager datanodeManager \u003d namesystem.getBlockManager()\n        .getDatanodeManager();\n\n    if (property.equals(DFS_HEARTBEAT_INTERVAL_KEY)) {\n      return reconfHeartbeatInterval(datanodeManager, property, newVal);\n    } else if (property.equals(DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY)) {\n      return reconfHeartbeatRecheckInterval(datanodeManager, property, newVal);\n    } else if (property.equals(FS_PROTECTED_DIRECTORIES)) {\n      return reconfProtectedDirectories(newVal);\n    } else if (property.equals(HADOOP_CALLER_CONTEXT_ENABLED_KEY)) {\n      return reconfCallerContextEnabled(newVal);\n    } else if (property.equals(ipcClientRPCBackoffEnable)) {\n      return reconfigureIPCBackoffEnabled(newVal);\n    } else if (property.equals(DFS_STORAGE_POLICY_SATISFIER_ACTIVATE_KEY)) {\n      return reconfigureSPSActivate(newVal, property);\n    } else {\n      throw new ReconfigurationException(property, newVal, getConf().get(\n          property));\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java",
      "extendedDetails": {}
    },
    "b4be288c5d6801988f555a566c2eb793c88a15a4": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10207. Support enable Hadoop IPC backoff without namenode restart. Contributed by Xiaobing Zhou.\n",
      "commitDate": "21/04/16 10:18 AM",
      "commitName": "b4be288c5d6801988f555a566c2eb793c88a15a4",
      "commitAuthor": "Xiaoyu Yao",
      "commitDateOld": "13/04/16 4:51 PM",
      "commitNameOld": "5566177c9af913baf380811dbbb1fa7e70235491",
      "commitAuthorOld": "Xiaoyu Yao",
      "daysBetweenCommits": 7.73,
      "commitsBetweenForRepo": 44,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,57 +1,20 @@\n   protected String reconfigurePropertyImpl(String property, String newVal)\n       throws ReconfigurationException {\n     final DatanodeManager datanodeManager \u003d namesystem.getBlockManager()\n         .getDatanodeManager();\n \n-    switch (property) {\n-    case DFS_HEARTBEAT_INTERVAL_KEY:\n-      namesystem.writeLock();\n-      try {\n-        if (newVal \u003d\u003d null) {\n-          // set to default\n-          datanodeManager.setHeartbeatInterval(DFS_HEARTBEAT_INTERVAL_DEFAULT);\n-          return String.valueOf(DFS_HEARTBEAT_INTERVAL_DEFAULT);\n-        } else {\n-          datanodeManager.setHeartbeatInterval(Long.parseLong(newVal));\n-          return String.valueOf(datanodeManager.getHeartbeatInterval());\n-        }\n-      } catch (NumberFormatException nfe) {\n-        throw new ReconfigurationException(property, newVal, getConf().get(\n-            property), nfe);\n-      } finally {\n-        namesystem.writeUnlock();\n-        LOG.info(\"RECONFIGURE* changed heartbeatInterval to \"\n-            + datanodeManager.getHeartbeatInterval());\n-      }\n-    case DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY:\n-      namesystem.writeLock();\n-      try {\n-        if (newVal \u003d\u003d null) {\n-          // set to default\n-          datanodeManager\n-              .setHeartbeatRecheckInterval(\n-                  DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_DEFAULT);\n-          return String\n-              .valueOf(DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_DEFAULT);\n-        } else {\n-          datanodeManager.setHeartbeatRecheckInterval(Integer.parseInt(newVal));\n-          return String.valueOf(datanodeManager.getHeartbeatRecheckInterval());\n-        }\n-      } catch (NumberFormatException nfe) {\n-        throw new ReconfigurationException(property, newVal, getConf().get(\n-            property), nfe);\n-      } finally {\n-        namesystem.writeUnlock();\n-        LOG.info(\"RECONFIGURE* changed heartbeatRecheckInterval to \"\n-            + datanodeManager.getHeartbeatRecheckInterval());\n-      }\n-    case FS_PROTECTED_DIRECTORIES:\n+    if (property.equals(DFS_HEARTBEAT_INTERVAL_KEY)) {\n+      return reconfHeartbeatInterval(datanodeManager, property, newVal);\n+    } else if (property.equals(DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY)) {\n+      return reconfHeartbeatRecheckInterval(datanodeManager, property, newVal);\n+    } else if (property.equals(FS_PROTECTED_DIRECTORIES)) {\n       return reconfProtectedDirectories(newVal);\n-    case HADOOP_CALLER_CONTEXT_ENABLED_KEY:\n+    } else if (property.equals(HADOOP_CALLER_CONTEXT_ENABLED_KEY)) {\n       return reconfCallerContextEnabled(newVal);\n-    default:\n-      break;\n+    } else if (property.equals(ipcClientRPCBackoffEnable)) {\n+      return reconfigureIPCBackoffEnabled(newVal);\n+    } else {\n+      throw new ReconfigurationException(property, newVal, getConf().get(\n+          property));\n     }\n-    throw new ReconfigurationException(property, newVal, getConf()\n-        .get(property));\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected String reconfigurePropertyImpl(String property, String newVal)\n      throws ReconfigurationException {\n    final DatanodeManager datanodeManager \u003d namesystem.getBlockManager()\n        .getDatanodeManager();\n\n    if (property.equals(DFS_HEARTBEAT_INTERVAL_KEY)) {\n      return reconfHeartbeatInterval(datanodeManager, property, newVal);\n    } else if (property.equals(DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY)) {\n      return reconfHeartbeatRecheckInterval(datanodeManager, property, newVal);\n    } else if (property.equals(FS_PROTECTED_DIRECTORIES)) {\n      return reconfProtectedDirectories(newVal);\n    } else if (property.equals(HADOOP_CALLER_CONTEXT_ENABLED_KEY)) {\n      return reconfCallerContextEnabled(newVal);\n    } else if (property.equals(ipcClientRPCBackoffEnable)) {\n      return reconfigureIPCBackoffEnabled(newVal);\n    } else {\n      throw new ReconfigurationException(property, newVal, getConf().get(\n          property));\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java",
      "extendedDetails": {}
    },
    "5566177c9af913baf380811dbbb1fa7e70235491": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10209. Support enable caller context in HDFS namenode audit log without restart namenode. Contributed by Xiaobing Zhou.\n",
      "commitDate": "13/04/16 4:51 PM",
      "commitName": "5566177c9af913baf380811dbbb1fa7e70235491",
      "commitAuthor": "Xiaoyu Yao",
      "commitDateOld": "13/04/16 4:45 PM",
      "commitNameOld": "4895c73dd493a53eab43f0d16e92c19af15c460b",
      "commitAuthorOld": "Xiaoyu Yao",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,55 +1,57 @@\n   protected String reconfigurePropertyImpl(String property, String newVal)\n       throws ReconfigurationException {\n     final DatanodeManager datanodeManager \u003d namesystem.getBlockManager()\n         .getDatanodeManager();\n \n     switch (property) {\n     case DFS_HEARTBEAT_INTERVAL_KEY:\n       namesystem.writeLock();\n       try {\n         if (newVal \u003d\u003d null) {\n           // set to default\n           datanodeManager.setHeartbeatInterval(DFS_HEARTBEAT_INTERVAL_DEFAULT);\n           return String.valueOf(DFS_HEARTBEAT_INTERVAL_DEFAULT);\n         } else {\n           datanodeManager.setHeartbeatInterval(Long.parseLong(newVal));\n           return String.valueOf(datanodeManager.getHeartbeatInterval());\n         }\n       } catch (NumberFormatException nfe) {\n         throw new ReconfigurationException(property, newVal, getConf().get(\n             property), nfe);\n       } finally {\n         namesystem.writeUnlock();\n         LOG.info(\"RECONFIGURE* changed heartbeatInterval to \"\n             + datanodeManager.getHeartbeatInterval());\n       }\n     case DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY:\n       namesystem.writeLock();\n       try {\n         if (newVal \u003d\u003d null) {\n           // set to default\n           datanodeManager\n               .setHeartbeatRecheckInterval(\n                   DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_DEFAULT);\n           return String\n               .valueOf(DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_DEFAULT);\n         } else {\n           datanodeManager.setHeartbeatRecheckInterval(Integer.parseInt(newVal));\n           return String.valueOf(datanodeManager.getHeartbeatRecheckInterval());\n         }\n       } catch (NumberFormatException nfe) {\n         throw new ReconfigurationException(property, newVal, getConf().get(\n             property), nfe);\n       } finally {\n         namesystem.writeUnlock();\n         LOG.info(\"RECONFIGURE* changed heartbeatRecheckInterval to \"\n             + datanodeManager.getHeartbeatRecheckInterval());\n       }\n     case FS_PROTECTED_DIRECTORIES:\n-      return getNamesystem().getFSDirectory().setProtectedDirectories(newVal);\n+      return reconfProtectedDirectories(newVal);\n+    case HADOOP_CALLER_CONTEXT_ENABLED_KEY:\n+      return reconfCallerContextEnabled(newVal);\n     default:\n       break;\n     }\n     throw new ReconfigurationException(property, newVal, getConf()\n         .get(property));\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected String reconfigurePropertyImpl(String property, String newVal)\n      throws ReconfigurationException {\n    final DatanodeManager datanodeManager \u003d namesystem.getBlockManager()\n        .getDatanodeManager();\n\n    switch (property) {\n    case DFS_HEARTBEAT_INTERVAL_KEY:\n      namesystem.writeLock();\n      try {\n        if (newVal \u003d\u003d null) {\n          // set to default\n          datanodeManager.setHeartbeatInterval(DFS_HEARTBEAT_INTERVAL_DEFAULT);\n          return String.valueOf(DFS_HEARTBEAT_INTERVAL_DEFAULT);\n        } else {\n          datanodeManager.setHeartbeatInterval(Long.parseLong(newVal));\n          return String.valueOf(datanodeManager.getHeartbeatInterval());\n        }\n      } catch (NumberFormatException nfe) {\n        throw new ReconfigurationException(property, newVal, getConf().get(\n            property), nfe);\n      } finally {\n        namesystem.writeUnlock();\n        LOG.info(\"RECONFIGURE* changed heartbeatInterval to \"\n            + datanodeManager.getHeartbeatInterval());\n      }\n    case DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY:\n      namesystem.writeLock();\n      try {\n        if (newVal \u003d\u003d null) {\n          // set to default\n          datanodeManager\n              .setHeartbeatRecheckInterval(\n                  DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_DEFAULT);\n          return String\n              .valueOf(DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_DEFAULT);\n        } else {\n          datanodeManager.setHeartbeatRecheckInterval(Integer.parseInt(newVal));\n          return String.valueOf(datanodeManager.getHeartbeatRecheckInterval());\n        }\n      } catch (NumberFormatException nfe) {\n        throw new ReconfigurationException(property, newVal, getConf().get(\n            property), nfe);\n      } finally {\n        namesystem.writeUnlock();\n        LOG.info(\"RECONFIGURE* changed heartbeatRecheckInterval to \"\n            + datanodeManager.getHeartbeatRecheckInterval());\n      }\n    case FS_PROTECTED_DIRECTORIES:\n      return reconfProtectedDirectories(newVal);\n    case HADOOP_CALLER_CONTEXT_ENABLED_KEY:\n      return reconfCallerContextEnabled(newVal);\n    default:\n      break;\n    }\n    throw new ReconfigurationException(property, newVal, getConf()\n        .get(property));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java",
      "extendedDetails": {}
    },
    "4895c73dd493a53eab43f0d16e92c19af15c460b": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-10209. Support enable caller context in HDFS namenode audit log without restart namenode\"\n\nThis reverts commit 192112d5a2e7ce4ec8eb47e21ab744b34c848893.\n",
      "commitDate": "13/04/16 4:45 PM",
      "commitName": "4895c73dd493a53eab43f0d16e92c19af15c460b",
      "commitAuthor": "Xiaoyu Yao",
      "commitDateOld": "13/04/16 3:34 PM",
      "commitNameOld": "192112d5a2e7ce4ec8eb47e21ab744b34c848893",
      "commitAuthorOld": "Xiaobing Zhou",
      "daysBetweenCommits": 0.05,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,57 +1,55 @@\n   protected String reconfigurePropertyImpl(String property, String newVal)\n       throws ReconfigurationException {\n     final DatanodeManager datanodeManager \u003d namesystem.getBlockManager()\n         .getDatanodeManager();\n \n     switch (property) {\n     case DFS_HEARTBEAT_INTERVAL_KEY:\n       namesystem.writeLock();\n       try {\n         if (newVal \u003d\u003d null) {\n           // set to default\n           datanodeManager.setHeartbeatInterval(DFS_HEARTBEAT_INTERVAL_DEFAULT);\n           return String.valueOf(DFS_HEARTBEAT_INTERVAL_DEFAULT);\n         } else {\n           datanodeManager.setHeartbeatInterval(Long.parseLong(newVal));\n           return String.valueOf(datanodeManager.getHeartbeatInterval());\n         }\n       } catch (NumberFormatException nfe) {\n         throw new ReconfigurationException(property, newVal, getConf().get(\n             property), nfe);\n       } finally {\n         namesystem.writeUnlock();\n         LOG.info(\"RECONFIGURE* changed heartbeatInterval to \"\n             + datanodeManager.getHeartbeatInterval());\n       }\n     case DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY:\n       namesystem.writeLock();\n       try {\n         if (newVal \u003d\u003d null) {\n           // set to default\n           datanodeManager\n               .setHeartbeatRecheckInterval(\n                   DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_DEFAULT);\n           return String\n               .valueOf(DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_DEFAULT);\n         } else {\n           datanodeManager.setHeartbeatRecheckInterval(Integer.parseInt(newVal));\n           return String.valueOf(datanodeManager.getHeartbeatRecheckInterval());\n         }\n       } catch (NumberFormatException nfe) {\n         throw new ReconfigurationException(property, newVal, getConf().get(\n             property), nfe);\n       } finally {\n         namesystem.writeUnlock();\n         LOG.info(\"RECONFIGURE* changed heartbeatRecheckInterval to \"\n             + datanodeManager.getHeartbeatRecheckInterval());\n       }\n     case FS_PROTECTED_DIRECTORIES:\n-      return reconfProtectedDirectories(newVal);\n-    case HADOOP_CALLER_CONTEXT_ENABLED_KEY:\n-      return reconfCallerContextEnabled(newVal);\n+      return getNamesystem().getFSDirectory().setProtectedDirectories(newVal);\n     default:\n       break;\n     }\n     throw new ReconfigurationException(property, newVal, getConf()\n         .get(property));\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected String reconfigurePropertyImpl(String property, String newVal)\n      throws ReconfigurationException {\n    final DatanodeManager datanodeManager \u003d namesystem.getBlockManager()\n        .getDatanodeManager();\n\n    switch (property) {\n    case DFS_HEARTBEAT_INTERVAL_KEY:\n      namesystem.writeLock();\n      try {\n        if (newVal \u003d\u003d null) {\n          // set to default\n          datanodeManager.setHeartbeatInterval(DFS_HEARTBEAT_INTERVAL_DEFAULT);\n          return String.valueOf(DFS_HEARTBEAT_INTERVAL_DEFAULT);\n        } else {\n          datanodeManager.setHeartbeatInterval(Long.parseLong(newVal));\n          return String.valueOf(datanodeManager.getHeartbeatInterval());\n        }\n      } catch (NumberFormatException nfe) {\n        throw new ReconfigurationException(property, newVal, getConf().get(\n            property), nfe);\n      } finally {\n        namesystem.writeUnlock();\n        LOG.info(\"RECONFIGURE* changed heartbeatInterval to \"\n            + datanodeManager.getHeartbeatInterval());\n      }\n    case DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY:\n      namesystem.writeLock();\n      try {\n        if (newVal \u003d\u003d null) {\n          // set to default\n          datanodeManager\n              .setHeartbeatRecheckInterval(\n                  DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_DEFAULT);\n          return String\n              .valueOf(DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_DEFAULT);\n        } else {\n          datanodeManager.setHeartbeatRecheckInterval(Integer.parseInt(newVal));\n          return String.valueOf(datanodeManager.getHeartbeatRecheckInterval());\n        }\n      } catch (NumberFormatException nfe) {\n        throw new ReconfigurationException(property, newVal, getConf().get(\n            property), nfe);\n      } finally {\n        namesystem.writeUnlock();\n        LOG.info(\"RECONFIGURE* changed heartbeatRecheckInterval to \"\n            + datanodeManager.getHeartbeatRecheckInterval());\n      }\n    case FS_PROTECTED_DIRECTORIES:\n      return getNamesystem().getFSDirectory().setProtectedDirectories(newVal);\n    default:\n      break;\n    }\n    throw new ReconfigurationException(property, newVal, getConf()\n        .get(property));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java",
      "extendedDetails": {}
    },
    "192112d5a2e7ce4ec8eb47e21ab744b34c848893": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10209. Support enable caller context in HDFS namenode audit log without restart namenode\n",
      "commitDate": "13/04/16 3:34 PM",
      "commitName": "192112d5a2e7ce4ec8eb47e21ab744b34c848893",
      "commitAuthor": "Xiaobing Zhou",
      "commitDateOld": "29/03/16 1:55 PM",
      "commitNameOld": "ddfe6774c21c8ccf5582a05bb0b58e961bbec309",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 15.07,
      "commitsBetweenForRepo": 97,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,55 +1,57 @@\n   protected String reconfigurePropertyImpl(String property, String newVal)\n       throws ReconfigurationException {\n     final DatanodeManager datanodeManager \u003d namesystem.getBlockManager()\n         .getDatanodeManager();\n \n     switch (property) {\n     case DFS_HEARTBEAT_INTERVAL_KEY:\n       namesystem.writeLock();\n       try {\n         if (newVal \u003d\u003d null) {\n           // set to default\n           datanodeManager.setHeartbeatInterval(DFS_HEARTBEAT_INTERVAL_DEFAULT);\n           return String.valueOf(DFS_HEARTBEAT_INTERVAL_DEFAULT);\n         } else {\n           datanodeManager.setHeartbeatInterval(Long.parseLong(newVal));\n           return String.valueOf(datanodeManager.getHeartbeatInterval());\n         }\n       } catch (NumberFormatException nfe) {\n         throw new ReconfigurationException(property, newVal, getConf().get(\n             property), nfe);\n       } finally {\n         namesystem.writeUnlock();\n         LOG.info(\"RECONFIGURE* changed heartbeatInterval to \"\n             + datanodeManager.getHeartbeatInterval());\n       }\n     case DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY:\n       namesystem.writeLock();\n       try {\n         if (newVal \u003d\u003d null) {\n           // set to default\n           datanodeManager\n               .setHeartbeatRecheckInterval(\n                   DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_DEFAULT);\n           return String\n               .valueOf(DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_DEFAULT);\n         } else {\n           datanodeManager.setHeartbeatRecheckInterval(Integer.parseInt(newVal));\n           return String.valueOf(datanodeManager.getHeartbeatRecheckInterval());\n         }\n       } catch (NumberFormatException nfe) {\n         throw new ReconfigurationException(property, newVal, getConf().get(\n             property), nfe);\n       } finally {\n         namesystem.writeUnlock();\n         LOG.info(\"RECONFIGURE* changed heartbeatRecheckInterval to \"\n             + datanodeManager.getHeartbeatRecheckInterval());\n       }\n     case FS_PROTECTED_DIRECTORIES:\n-      return getNamesystem().getFSDirectory().setProtectedDirectories(newVal);\n+      return reconfProtectedDirectories(newVal);\n+    case HADOOP_CALLER_CONTEXT_ENABLED_KEY:\n+      return reconfCallerContextEnabled(newVal);\n     default:\n       break;\n     }\n     throw new ReconfigurationException(property, newVal, getConf()\n         .get(property));\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected String reconfigurePropertyImpl(String property, String newVal)\n      throws ReconfigurationException {\n    final DatanodeManager datanodeManager \u003d namesystem.getBlockManager()\n        .getDatanodeManager();\n\n    switch (property) {\n    case DFS_HEARTBEAT_INTERVAL_KEY:\n      namesystem.writeLock();\n      try {\n        if (newVal \u003d\u003d null) {\n          // set to default\n          datanodeManager.setHeartbeatInterval(DFS_HEARTBEAT_INTERVAL_DEFAULT);\n          return String.valueOf(DFS_HEARTBEAT_INTERVAL_DEFAULT);\n        } else {\n          datanodeManager.setHeartbeatInterval(Long.parseLong(newVal));\n          return String.valueOf(datanodeManager.getHeartbeatInterval());\n        }\n      } catch (NumberFormatException nfe) {\n        throw new ReconfigurationException(property, newVal, getConf().get(\n            property), nfe);\n      } finally {\n        namesystem.writeUnlock();\n        LOG.info(\"RECONFIGURE* changed heartbeatInterval to \"\n            + datanodeManager.getHeartbeatInterval());\n      }\n    case DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY:\n      namesystem.writeLock();\n      try {\n        if (newVal \u003d\u003d null) {\n          // set to default\n          datanodeManager\n              .setHeartbeatRecheckInterval(\n                  DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_DEFAULT);\n          return String\n              .valueOf(DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_DEFAULT);\n        } else {\n          datanodeManager.setHeartbeatRecheckInterval(Integer.parseInt(newVal));\n          return String.valueOf(datanodeManager.getHeartbeatRecheckInterval());\n        }\n      } catch (NumberFormatException nfe) {\n        throw new ReconfigurationException(property, newVal, getConf().get(\n            property), nfe);\n      } finally {\n        namesystem.writeUnlock();\n        LOG.info(\"RECONFIGURE* changed heartbeatRecheckInterval to \"\n            + datanodeManager.getHeartbeatRecheckInterval());\n      }\n    case FS_PROTECTED_DIRECTORIES:\n      return reconfProtectedDirectories(newVal);\n    case HADOOP_CALLER_CONTEXT_ENABLED_KEY:\n      return reconfCallerContextEnabled(newVal);\n    default:\n      break;\n    }\n    throw new ReconfigurationException(property, newVal, getConf()\n        .get(property));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java",
      "extendedDetails": {}
    },
    "ddfe6774c21c8ccf5582a05bb0b58e961bbec309": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9439. Support reconfiguring fs.protected.directories without NN restart. (Contributed by Xiaobing Zhou)\n",
      "commitDate": "29/03/16 1:55 PM",
      "commitName": "ddfe6774c21c8ccf5582a05bb0b58e961bbec309",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "10/03/16 7:03 PM",
      "commitNameOld": "e01c6ea688e62f25c4310e771a0cd85b53a5fb87",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 18.74,
      "commitsBetweenForRepo": 92,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,53 +1,55 @@\n   protected String reconfigurePropertyImpl(String property, String newVal)\n       throws ReconfigurationException {\n     final DatanodeManager datanodeManager \u003d namesystem.getBlockManager()\n         .getDatanodeManager();\n \n     switch (property) {\n     case DFS_HEARTBEAT_INTERVAL_KEY:\n       namesystem.writeLock();\n       try {\n         if (newVal \u003d\u003d null) {\n           // set to default\n           datanodeManager.setHeartbeatInterval(DFS_HEARTBEAT_INTERVAL_DEFAULT);\n           return String.valueOf(DFS_HEARTBEAT_INTERVAL_DEFAULT);\n         } else {\n           datanodeManager.setHeartbeatInterval(Long.parseLong(newVal));\n           return String.valueOf(datanodeManager.getHeartbeatInterval());\n         }\n       } catch (NumberFormatException nfe) {\n         throw new ReconfigurationException(property, newVal, getConf().get(\n             property), nfe);\n       } finally {\n         namesystem.writeUnlock();\n         LOG.info(\"RECONFIGURE* changed heartbeatInterval to \"\n             + datanodeManager.getHeartbeatInterval());\n       }\n     case DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY:\n       namesystem.writeLock();\n       try {\n         if (newVal \u003d\u003d null) {\n           // set to default\n           datanodeManager\n               .setHeartbeatRecheckInterval(\n                   DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_DEFAULT);\n           return String\n               .valueOf(DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_DEFAULT);\n         } else {\n           datanodeManager.setHeartbeatRecheckInterval(Integer.parseInt(newVal));\n           return String.valueOf(datanodeManager.getHeartbeatRecheckInterval());\n         }\n       } catch (NumberFormatException nfe) {\n         throw new ReconfigurationException(property, newVal, getConf().get(\n             property), nfe);\n       } finally {\n         namesystem.writeUnlock();\n         LOG.info(\"RECONFIGURE* changed heartbeatRecheckInterval to \"\n             + datanodeManager.getHeartbeatRecheckInterval());\n       }\n+    case FS_PROTECTED_DIRECTORIES:\n+      return getNamesystem().getFSDirectory().setProtectedDirectories(newVal);\n     default:\n       break;\n     }\n     throw new ReconfigurationException(property, newVal, getConf()\n         .get(property));\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected String reconfigurePropertyImpl(String property, String newVal)\n      throws ReconfigurationException {\n    final DatanodeManager datanodeManager \u003d namesystem.getBlockManager()\n        .getDatanodeManager();\n\n    switch (property) {\n    case DFS_HEARTBEAT_INTERVAL_KEY:\n      namesystem.writeLock();\n      try {\n        if (newVal \u003d\u003d null) {\n          // set to default\n          datanodeManager.setHeartbeatInterval(DFS_HEARTBEAT_INTERVAL_DEFAULT);\n          return String.valueOf(DFS_HEARTBEAT_INTERVAL_DEFAULT);\n        } else {\n          datanodeManager.setHeartbeatInterval(Long.parseLong(newVal));\n          return String.valueOf(datanodeManager.getHeartbeatInterval());\n        }\n      } catch (NumberFormatException nfe) {\n        throw new ReconfigurationException(property, newVal, getConf().get(\n            property), nfe);\n      } finally {\n        namesystem.writeUnlock();\n        LOG.info(\"RECONFIGURE* changed heartbeatInterval to \"\n            + datanodeManager.getHeartbeatInterval());\n      }\n    case DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY:\n      namesystem.writeLock();\n      try {\n        if (newVal \u003d\u003d null) {\n          // set to default\n          datanodeManager\n              .setHeartbeatRecheckInterval(\n                  DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_DEFAULT);\n          return String\n              .valueOf(DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_DEFAULT);\n        } else {\n          datanodeManager.setHeartbeatRecheckInterval(Integer.parseInt(newVal));\n          return String.valueOf(datanodeManager.getHeartbeatRecheckInterval());\n        }\n      } catch (NumberFormatException nfe) {\n        throw new ReconfigurationException(property, newVal, getConf().get(\n            property), nfe);\n      } finally {\n        namesystem.writeUnlock();\n        LOG.info(\"RECONFIGURE* changed heartbeatRecheckInterval to \"\n            + datanodeManager.getHeartbeatRecheckInterval());\n      }\n    case FS_PROTECTED_DIRECTORIES:\n      return getNamesystem().getFSDirectory().setProtectedDirectories(newVal);\n    default:\n      break;\n    }\n    throw new ReconfigurationException(property, newVal, getConf()\n        .get(property));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java",
      "extendedDetails": {}
    },
    "e01c6ea688e62f25c4310e771a0cd85b53a5fb87": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-1477. Support reconfiguring dfs.heartbeat.interval and dfs.namenode.heartbeat.recheck-interval without NN restart. (Contributed by Xiaobing Zhou)\n",
      "commitDate": "10/03/16 7:03 PM",
      "commitName": "e01c6ea688e62f25c4310e771a0cd85b53a5fb87",
      "commitAuthor": "Arpit Agarwal",
      "diff": "@@ -0,0 +1,53 @@\n+  protected String reconfigurePropertyImpl(String property, String newVal)\n+      throws ReconfigurationException {\n+    final DatanodeManager datanodeManager \u003d namesystem.getBlockManager()\n+        .getDatanodeManager();\n+\n+    switch (property) {\n+    case DFS_HEARTBEAT_INTERVAL_KEY:\n+      namesystem.writeLock();\n+      try {\n+        if (newVal \u003d\u003d null) {\n+          // set to default\n+          datanodeManager.setHeartbeatInterval(DFS_HEARTBEAT_INTERVAL_DEFAULT);\n+          return String.valueOf(DFS_HEARTBEAT_INTERVAL_DEFAULT);\n+        } else {\n+          datanodeManager.setHeartbeatInterval(Long.parseLong(newVal));\n+          return String.valueOf(datanodeManager.getHeartbeatInterval());\n+        }\n+      } catch (NumberFormatException nfe) {\n+        throw new ReconfigurationException(property, newVal, getConf().get(\n+            property), nfe);\n+      } finally {\n+        namesystem.writeUnlock();\n+        LOG.info(\"RECONFIGURE* changed heartbeatInterval to \"\n+            + datanodeManager.getHeartbeatInterval());\n+      }\n+    case DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY:\n+      namesystem.writeLock();\n+      try {\n+        if (newVal \u003d\u003d null) {\n+          // set to default\n+          datanodeManager\n+              .setHeartbeatRecheckInterval(\n+                  DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_DEFAULT);\n+          return String\n+              .valueOf(DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_DEFAULT);\n+        } else {\n+          datanodeManager.setHeartbeatRecheckInterval(Integer.parseInt(newVal));\n+          return String.valueOf(datanodeManager.getHeartbeatRecheckInterval());\n+        }\n+      } catch (NumberFormatException nfe) {\n+        throw new ReconfigurationException(property, newVal, getConf().get(\n+            property), nfe);\n+      } finally {\n+        namesystem.writeUnlock();\n+        LOG.info(\"RECONFIGURE* changed heartbeatRecheckInterval to \"\n+            + datanodeManager.getHeartbeatRecheckInterval());\n+      }\n+    default:\n+      break;\n+    }\n+    throw new ReconfigurationException(property, newVal, getConf()\n+        .get(property));\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  protected String reconfigurePropertyImpl(String property, String newVal)\n      throws ReconfigurationException {\n    final DatanodeManager datanodeManager \u003d namesystem.getBlockManager()\n        .getDatanodeManager();\n\n    switch (property) {\n    case DFS_HEARTBEAT_INTERVAL_KEY:\n      namesystem.writeLock();\n      try {\n        if (newVal \u003d\u003d null) {\n          // set to default\n          datanodeManager.setHeartbeatInterval(DFS_HEARTBEAT_INTERVAL_DEFAULT);\n          return String.valueOf(DFS_HEARTBEAT_INTERVAL_DEFAULT);\n        } else {\n          datanodeManager.setHeartbeatInterval(Long.parseLong(newVal));\n          return String.valueOf(datanodeManager.getHeartbeatInterval());\n        }\n      } catch (NumberFormatException nfe) {\n        throw new ReconfigurationException(property, newVal, getConf().get(\n            property), nfe);\n      } finally {\n        namesystem.writeUnlock();\n        LOG.info(\"RECONFIGURE* changed heartbeatInterval to \"\n            + datanodeManager.getHeartbeatInterval());\n      }\n    case DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY:\n      namesystem.writeLock();\n      try {\n        if (newVal \u003d\u003d null) {\n          // set to default\n          datanodeManager\n              .setHeartbeatRecheckInterval(\n                  DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_DEFAULT);\n          return String\n              .valueOf(DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_DEFAULT);\n        } else {\n          datanodeManager.setHeartbeatRecheckInterval(Integer.parseInt(newVal));\n          return String.valueOf(datanodeManager.getHeartbeatRecheckInterval());\n        }\n      } catch (NumberFormatException nfe) {\n        throw new ReconfigurationException(property, newVal, getConf().get(\n            property), nfe);\n      } finally {\n        namesystem.writeUnlock();\n        LOG.info(\"RECONFIGURE* changed heartbeatRecheckInterval to \"\n            + datanodeManager.getHeartbeatRecheckInterval());\n      }\n    default:\n      break;\n    }\n    throw new ReconfigurationException(property, newVal, getConf()\n        .get(property));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java"
    }
  }
}