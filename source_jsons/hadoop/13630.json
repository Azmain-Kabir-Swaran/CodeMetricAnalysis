{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DatanodeAdminBackoffMonitor.java",
  "functionName": "checkForCompletedNodes",
  "functionId": "checkForCompletedNodes___removeList-List__DatanodeDescriptor__",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminBackoffMonitor.java",
  "functionStartLine": 404,
  "functionEndLine": 426,
  "numCommitsSeen": 1,
  "timeTaken": 843,
  "changeHistory": [
    "c93cb6790e0f1c64efd03d859f907a0522010894"
  ],
  "changeHistoryShort": {
    "c93cb6790e0f1c64efd03d859f907a0522010894": "Yintroduced"
  },
  "changeHistoryDetails": {
    "c93cb6790e0f1c64efd03d859f907a0522010894": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-14854. Create improved decommission monitor implementation. Contributed by Stephen O\u0027Donnell.\n\nReviewed-by: Inigo Goiri \u003cinigoiri@apache.org\u003e\nSigned-off-by: Wei-Chiu Chuang \u003cweichiu@apache.org\u003e\n",
      "commitDate": "10/12/19 5:16 PM",
      "commitName": "c93cb6790e0f1c64efd03d859f907a0522010894",
      "commitAuthor": "Stephen O\u0027Donnell",
      "diff": "@@ -0,0 +1,23 @@\n+  private void checkForCompletedNodes(List\u003cDatanodeDescriptor\u003e removeList) {\n+    for (DatanodeDescriptor dn : outOfServiceNodeBlocks.keySet()) {\n+      // If the node is already in maintenance, we don\u0027t need to perform\n+      // any further checks on it.\n+      if (dn.isInMaintenance()) {\n+        LOG.debug(\"Node {} is currently in maintenance\", dn);\n+        continue;\n+      } else if (!dn.isInService()) {\n+        // A node could be inService if decom or maint has been cancelled, but\n+        // the cancelled list is yet to be processed. We don\u0027t need to check\n+        // inService nodes here\n+        int outstandingBlocks \u003d getPendingCountForNode(dn);\n+        if (outstandingBlocks \u003d\u003d 0) {\n+          scanDatanodeStorage(dn, false);\n+          outstandingBlocks \u003d getPendingCountForNode(dn);\n+        }\n+        LOG.info(\"Node {} has {} blocks yet to process\", dn, outstandingBlocks);\n+        if (outstandingBlocks \u003d\u003d 0) {\n+          removeList.add(dn);\n+        }\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void checkForCompletedNodes(List\u003cDatanodeDescriptor\u003e removeList) {\n    for (DatanodeDescriptor dn : outOfServiceNodeBlocks.keySet()) {\n      // If the node is already in maintenance, we don\u0027t need to perform\n      // any further checks on it.\n      if (dn.isInMaintenance()) {\n        LOG.debug(\"Node {} is currently in maintenance\", dn);\n        continue;\n      } else if (!dn.isInService()) {\n        // A node could be inService if decom or maint has been cancelled, but\n        // the cancelled list is yet to be processed. We don\u0027t need to check\n        // inService nodes here\n        int outstandingBlocks \u003d getPendingCountForNode(dn);\n        if (outstandingBlocks \u003d\u003d 0) {\n          scanDatanodeStorage(dn, false);\n          outstandingBlocks \u003d getPendingCountForNode(dn);\n        }\n        LOG.info(\"Node {} has {} blocks yet to process\", dn, outstandingBlocks);\n        if (outstandingBlocks \u003d\u003d 0) {\n          removeList.add(dn);\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminBackoffMonitor.java"
    }
  }
}