{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "HBaseTimelineReaderImpl.java",
  "functionName": "getEntities",
  "functionId": "getEntities___context-TimelineReaderContext__filters-TimelineEntityFilters__dataToRetrieve-TimelineDataToRetrieve",
  "sourceFilePath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-client/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/HBaseTimelineReaderImpl.java",
  "functionStartLine": 92,
  "functionEndLine": 100,
  "numCommitsSeen": 46,
  "timeTaken": 5779,
  "changeHistory": [
    "cda9f3374573f0cb5ae4f26ba3fbc77aae45ec58",
    "ba683204498c97654be4727ab9e128c433a45498",
    "9af30d46c6e82332a8eda20cb3eb5f987e25e7a2",
    "b01514f65bc6090a50a583f67d1ecb5d74b6d276",
    "9cb1287e9b8425f91de925f411c3c2a8fa9fe2a3",
    "6934b05c7117a12286fb2ba7a47f75e227cacb22",
    "8ef546c1ee9fce0b171813547253374d268566ba",
    "1f710484e5b8ab4d5c67379c012004e8a4242d15",
    "10fa6da7d8a6013698767c6136ae20f0e04415e9",
    "00e85e7a2b9446dc37265feba07473b156d66367",
    "9e5155be363c6610ccf41fe08b7f1394f353ea65"
  ],
  "changeHistoryShort": {
    "cda9f3374573f0cb5ae4f26ba3fbc77aae45ec58": "Ybodychange",
    "ba683204498c97654be4727ab9e128c433a45498": "Ybodychange",
    "9af30d46c6e82332a8eda20cb3eb5f987e25e7a2": "Yfilerename",
    "b01514f65bc6090a50a583f67d1ecb5d74b6d276": "Yfilerename",
    "9cb1287e9b8425f91de925f411c3c2a8fa9fe2a3": "Ymultichange(Yparameterchange,Ybodychange)",
    "6934b05c7117a12286fb2ba7a47f75e227cacb22": "Ymultichange(Yparameterchange,Ybodychange)",
    "8ef546c1ee9fce0b171813547253374d268566ba": "Ymultichange(Yparameterchange,Ybodychange)",
    "1f710484e5b8ab4d5c67379c012004e8a4242d15": "Ymultichange(Yparameterchange,Ybodychange)",
    "10fa6da7d8a6013698767c6136ae20f0e04415e9": "Ybodychange",
    "00e85e7a2b9446dc37265feba07473b156d66367": "Ybodychange",
    "9e5155be363c6610ccf41fe08b7f1394f353ea65": "Yintroduced"
  },
  "changeHistoryDetails": {
    "cda9f3374573f0cb5ae4f26ba3fbc77aae45ec58": {
      "type": "Ybodychange",
      "commitMessage": "YARN-8499 ATSv2 Generalize TimelineStorageMonitor.\n           Contributed by Prabhu Joseph\n",
      "commitDate": "14/06/19 3:59 PM",
      "commitName": "cda9f3374573f0cb5ae4f26ba3fbc77aae45ec58",
      "commitAuthor": "Eric Yang",
      "commitDateOld": "30/05/19 9:58 PM",
      "commitNameOld": "e49162f4b3791dbf51079e3b19dd0c8bc2a85158",
      "commitAuthorOld": "Sunil G",
      "daysBetweenCommits": 14.75,
      "commitsBetweenForRepo": 110,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,9 +1,9 @@\n   public Set\u003cTimelineEntity\u003e getEntities(TimelineReaderContext context,\n       TimelineEntityFilters filters, TimelineDataToRetrieve dataToRetrieve)\n       throws IOException {\n-    checkHBaseDown();\n+    storageMonitor.checkStorageIsUp();\n     TimelineEntityReader reader \u003d\n         TimelineEntityReaderFactory.createMultipleEntitiesReader(context,\n             filters, dataToRetrieve);\n     return reader.readEntities(hbaseConf, conn);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public Set\u003cTimelineEntity\u003e getEntities(TimelineReaderContext context,\n      TimelineEntityFilters filters, TimelineDataToRetrieve dataToRetrieve)\n      throws IOException {\n    storageMonitor.checkStorageIsUp();\n    TimelineEntityReader reader \u003d\n        TimelineEntityReaderFactory.createMultipleEntitiesReader(context,\n            filters, dataToRetrieve);\n    return reader.readEntities(hbaseConf, conn);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-client/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/HBaseTimelineReaderImpl.java",
      "extendedDetails": {}
    },
    "ba683204498c97654be4727ab9e128c433a45498": {
      "type": "Ybodychange",
      "commitMessage": "YARN-8302. ATS v2 should handle HBase connection issue properly. Contributed by Billie Rinaldi.\n",
      "commitDate": "06/07/18 3:19 PM",
      "commitName": "ba683204498c97654be4727ab9e128c433a45498",
      "commitAuthor": "Rohith Sharma K S",
      "commitDateOld": "17/02/18 7:00 AM",
      "commitNameOld": "9af30d46c6e82332a8eda20cb3eb5f987e25e7a2",
      "commitAuthorOld": "Rohith Sharma K S",
      "daysBetweenCommits": 139.3,
      "commitsBetweenForRepo": 1585,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,8 +1,9 @@\n   public Set\u003cTimelineEntity\u003e getEntities(TimelineReaderContext context,\n       TimelineEntityFilters filters, TimelineDataToRetrieve dataToRetrieve)\n       throws IOException {\n+    checkHBaseDown();\n     TimelineEntityReader reader \u003d\n         TimelineEntityReaderFactory.createMultipleEntitiesReader(context,\n             filters, dataToRetrieve);\n     return reader.readEntities(hbaseConf, conn);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public Set\u003cTimelineEntity\u003e getEntities(TimelineReaderContext context,\n      TimelineEntityFilters filters, TimelineDataToRetrieve dataToRetrieve)\n      throws IOException {\n    checkHBaseDown();\n    TimelineEntityReader reader \u003d\n        TimelineEntityReaderFactory.createMultipleEntitiesReader(context,\n            filters, dataToRetrieve);\n    return reader.readEntities(hbaseConf, conn);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-client/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/HBaseTimelineReaderImpl.java",
      "extendedDetails": {}
    },
    "9af30d46c6e82332a8eda20cb3eb5f987e25e7a2": {
      "type": "Yfilerename",
      "commitMessage": "YARN-7919. Refactor timelineservice-hbase module into submodules. Contributed by Haibo Chen.\n",
      "commitDate": "17/02/18 7:00 AM",
      "commitName": "9af30d46c6e82332a8eda20cb3eb5f987e25e7a2",
      "commitAuthor": "Rohith Sharma K S",
      "commitDateOld": "17/02/18 3:24 AM",
      "commitNameOld": "a1e56a62863d8d494af309ec5f476c4b7e4d5ef9",
      "commitAuthorOld": "Arun Suresh",
      "daysBetweenCommits": 0.15,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public Set\u003cTimelineEntity\u003e getEntities(TimelineReaderContext context,\n      TimelineEntityFilters filters, TimelineDataToRetrieve dataToRetrieve)\n      throws IOException {\n    TimelineEntityReader reader \u003d\n        TimelineEntityReaderFactory.createMultipleEntitiesReader(context,\n            filters, dataToRetrieve);\n    return reader.readEntities(hbaseConf, conn);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-client/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/HBaseTimelineReaderImpl.java",
      "extendedDetails": {
        "oldPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/HBaseTimelineReaderImpl.java",
        "newPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-client/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/HBaseTimelineReaderImpl.java"
      }
    },
    "b01514f65bc6090a50a583f67d1ecb5d74b6d276": {
      "type": "Yfilerename",
      "commitMessage": "YARN-5928. Move ATSv2 HBase backend code into a new module that is only dependent at runtime by yarn servers. Contributed by Haibo Chen.\n",
      "commitDate": "19/01/17 8:52 PM",
      "commitName": "b01514f65bc6090a50a583f67d1ecb5d74b6d276",
      "commitAuthor": "Sangjin Lee",
      "commitDateOld": "19/01/17 5:32 PM",
      "commitNameOld": "60865c8ea08053f3d6ac23f81c3376a3de3ca996",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 0.14,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public Set\u003cTimelineEntity\u003e getEntities(TimelineReaderContext context,\n      TimelineEntityFilters filters, TimelineDataToRetrieve dataToRetrieve)\n      throws IOException {\n    TimelineEntityReader reader \u003d\n        TimelineEntityReaderFactory.createMultipleEntitiesReader(context,\n            filters, dataToRetrieve);\n    return reader.readEntities(hbaseConf, conn);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/HBaseTimelineReaderImpl.java",
      "extendedDetails": {
        "oldPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/HBaseTimelineReaderImpl.java",
        "newPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/HBaseTimelineReaderImpl.java"
      }
    },
    "9cb1287e9b8425f91de925f411c3c2a8fa9fe2a3": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "YARN-4446. Refactor reader API for better extensibility (Varun Saxena via sjlee)\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "9cb1287e9b8425f91de925f411c3c2a8fa9fe2a3",
      "commitAuthor": "Sangjin Lee",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "YARN-4446. Refactor reader API for better extensibility (Varun Saxena via sjlee)\n",
          "commitDate": "10/07/16 8:45 AM",
          "commitName": "9cb1287e9b8425f91de925f411c3c2a8fa9fe2a3",
          "commitAuthor": "Sangjin Lee",
          "commitDateOld": "10/07/16 8:45 AM",
          "commitNameOld": "6934b05c7117a12286fb2ba7a47f75e227cacb22",
          "commitAuthorOld": "Naganarasimha",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 3,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,16 +1,8 @@\n-  public Set\u003cTimelineEntity\u003e getEntities(String userId, String clusterId,\n-      String flowName, Long flowRunId, String appId, String entityType,\n-      Long limit, Long createdTimeBegin, Long createdTimeEnd,\n-      Map\u003cString, Set\u003cString\u003e\u003e relatesTo, Map\u003cString, Set\u003cString\u003e\u003e isRelatedTo,\n-      Map\u003cString, Object\u003e infoFilters, Map\u003cString, String\u003e configFilters,\n-      Set\u003cString\u003e metricFilters, Set\u003cString\u003e eventFilters,\n-      TimelineFilterList confsToRetrieve, TimelineFilterList metricsToRetrieve,\n-      EnumSet\u003cField\u003e fieldsToRetrieve) throws IOException {\n+  public Set\u003cTimelineEntity\u003e getEntities(TimelineReaderContext context,\n+      TimelineEntityFilters filters, TimelineDataToRetrieve dataToRetrieve)\n+      throws IOException {\n     TimelineEntityReader reader \u003d\n-        TimelineEntityReaderFactory.createMultipleEntitiesReader(userId,\n-            clusterId, flowName, flowRunId, appId, entityType, limit,\n-            createdTimeBegin, createdTimeEnd, relatesTo, isRelatedTo,\n-            infoFilters, configFilters, metricFilters, eventFilters,\n-            confsToRetrieve, metricsToRetrieve, fieldsToRetrieve);\n+        TimelineEntityReaderFactory.createMultipleEntitiesReader(context,\n+            filters, dataToRetrieve);\n     return reader.readEntities(hbaseConf, conn);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public Set\u003cTimelineEntity\u003e getEntities(TimelineReaderContext context,\n      TimelineEntityFilters filters, TimelineDataToRetrieve dataToRetrieve)\n      throws IOException {\n    TimelineEntityReader reader \u003d\n        TimelineEntityReaderFactory.createMultipleEntitiesReader(context,\n            filters, dataToRetrieve);\n    return reader.readEntities(hbaseConf, conn);\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/HBaseTimelineReaderImpl.java",
          "extendedDetails": {
            "oldValue": "[userId-String, clusterId-String, flowName-String, flowRunId-Long, appId-String, entityType-String, limit-Long, createdTimeBegin-Long, createdTimeEnd-Long, relatesTo-Map\u003cString,Set\u003cString\u003e\u003e, isRelatedTo-Map\u003cString,Set\u003cString\u003e\u003e, infoFilters-Map\u003cString,Object\u003e, configFilters-Map\u003cString,String\u003e, metricFilters-Set\u003cString\u003e, eventFilters-Set\u003cString\u003e, confsToRetrieve-TimelineFilterList, metricsToRetrieve-TimelineFilterList, fieldsToRetrieve-EnumSet\u003cField\u003e]",
            "newValue": "[context-TimelineReaderContext, filters-TimelineEntityFilters, dataToRetrieve-TimelineDataToRetrieve]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-4446. Refactor reader API for better extensibility (Varun Saxena via sjlee)\n",
          "commitDate": "10/07/16 8:45 AM",
          "commitName": "9cb1287e9b8425f91de925f411c3c2a8fa9fe2a3",
          "commitAuthor": "Sangjin Lee",
          "commitDateOld": "10/07/16 8:45 AM",
          "commitNameOld": "6934b05c7117a12286fb2ba7a47f75e227cacb22",
          "commitAuthorOld": "Naganarasimha",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 3,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,16 +1,8 @@\n-  public Set\u003cTimelineEntity\u003e getEntities(String userId, String clusterId,\n-      String flowName, Long flowRunId, String appId, String entityType,\n-      Long limit, Long createdTimeBegin, Long createdTimeEnd,\n-      Map\u003cString, Set\u003cString\u003e\u003e relatesTo, Map\u003cString, Set\u003cString\u003e\u003e isRelatedTo,\n-      Map\u003cString, Object\u003e infoFilters, Map\u003cString, String\u003e configFilters,\n-      Set\u003cString\u003e metricFilters, Set\u003cString\u003e eventFilters,\n-      TimelineFilterList confsToRetrieve, TimelineFilterList metricsToRetrieve,\n-      EnumSet\u003cField\u003e fieldsToRetrieve) throws IOException {\n+  public Set\u003cTimelineEntity\u003e getEntities(TimelineReaderContext context,\n+      TimelineEntityFilters filters, TimelineDataToRetrieve dataToRetrieve)\n+      throws IOException {\n     TimelineEntityReader reader \u003d\n-        TimelineEntityReaderFactory.createMultipleEntitiesReader(userId,\n-            clusterId, flowName, flowRunId, appId, entityType, limit,\n-            createdTimeBegin, createdTimeEnd, relatesTo, isRelatedTo,\n-            infoFilters, configFilters, metricFilters, eventFilters,\n-            confsToRetrieve, metricsToRetrieve, fieldsToRetrieve);\n+        TimelineEntityReaderFactory.createMultipleEntitiesReader(context,\n+            filters, dataToRetrieve);\n     return reader.readEntities(hbaseConf, conn);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public Set\u003cTimelineEntity\u003e getEntities(TimelineReaderContext context,\n      TimelineEntityFilters filters, TimelineDataToRetrieve dataToRetrieve)\n      throws IOException {\n    TimelineEntityReader reader \u003d\n        TimelineEntityReaderFactory.createMultipleEntitiesReader(context,\n            filters, dataToRetrieve);\n    return reader.readEntities(hbaseConf, conn);\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/HBaseTimelineReaderImpl.java",
          "extendedDetails": {}
        }
      ]
    },
    "6934b05c7117a12286fb2ba7a47f75e227cacb22": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "YARN-4238. createdTime and modifiedTime is not reported while publishing entities to ATSv2. (Varun Saxena via Naganarasimha G R)\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "6934b05c7117a12286fb2ba7a47f75e227cacb22",
      "commitAuthor": "Naganarasimha",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "YARN-4238. createdTime and modifiedTime is not reported while publishing entities to ATSv2. (Varun Saxena via Naganarasimha G R)\n",
          "commitDate": "10/07/16 8:45 AM",
          "commitName": "6934b05c7117a12286fb2ba7a47f75e227cacb22",
          "commitAuthor": "Naganarasimha",
          "commitDateOld": "10/07/16 8:45 AM",
          "commitNameOld": "88f02941144824187b70fa2aaf0c6d90bcb77d8f",
          "commitAuthorOld": "Li Lu",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 3,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,18 +1,16 @@\n   public Set\u003cTimelineEntity\u003e getEntities(String userId, String clusterId,\n       String flowName, Long flowRunId, String appId, String entityType,\n       Long limit, Long createdTimeBegin, Long createdTimeEnd,\n-      Long modifiedTimeBegin, Long modifiedTimeEnd,\n       Map\u003cString, Set\u003cString\u003e\u003e relatesTo, Map\u003cString, Set\u003cString\u003e\u003e isRelatedTo,\n       Map\u003cString, Object\u003e infoFilters, Map\u003cString, String\u003e configFilters,\n       Set\u003cString\u003e metricFilters, Set\u003cString\u003e eventFilters,\n       TimelineFilterList confsToRetrieve, TimelineFilterList metricsToRetrieve,\n       EnumSet\u003cField\u003e fieldsToRetrieve) throws IOException {\n     TimelineEntityReader reader \u003d\n         TimelineEntityReaderFactory.createMultipleEntitiesReader(userId,\n             clusterId, flowName, flowRunId, appId, entityType, limit,\n-            createdTimeBegin, createdTimeEnd, modifiedTimeBegin,\n-            modifiedTimeEnd, relatesTo, isRelatedTo, infoFilters, configFilters,\n-            metricFilters, eventFilters, confsToRetrieve, metricsToRetrieve,\n-            fieldsToRetrieve);\n+            createdTimeBegin, createdTimeEnd, relatesTo, isRelatedTo,\n+            infoFilters, configFilters, metricFilters, eventFilters,\n+            confsToRetrieve, metricsToRetrieve, fieldsToRetrieve);\n     return reader.readEntities(hbaseConf, conn);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public Set\u003cTimelineEntity\u003e getEntities(String userId, String clusterId,\n      String flowName, Long flowRunId, String appId, String entityType,\n      Long limit, Long createdTimeBegin, Long createdTimeEnd,\n      Map\u003cString, Set\u003cString\u003e\u003e relatesTo, Map\u003cString, Set\u003cString\u003e\u003e isRelatedTo,\n      Map\u003cString, Object\u003e infoFilters, Map\u003cString, String\u003e configFilters,\n      Set\u003cString\u003e metricFilters, Set\u003cString\u003e eventFilters,\n      TimelineFilterList confsToRetrieve, TimelineFilterList metricsToRetrieve,\n      EnumSet\u003cField\u003e fieldsToRetrieve) throws IOException {\n    TimelineEntityReader reader \u003d\n        TimelineEntityReaderFactory.createMultipleEntitiesReader(userId,\n            clusterId, flowName, flowRunId, appId, entityType, limit,\n            createdTimeBegin, createdTimeEnd, relatesTo, isRelatedTo,\n            infoFilters, configFilters, metricFilters, eventFilters,\n            confsToRetrieve, metricsToRetrieve, fieldsToRetrieve);\n    return reader.readEntities(hbaseConf, conn);\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/HBaseTimelineReaderImpl.java",
          "extendedDetails": {
            "oldValue": "[userId-String, clusterId-String, flowName-String, flowRunId-Long, appId-String, entityType-String, limit-Long, createdTimeBegin-Long, createdTimeEnd-Long, modifiedTimeBegin-Long, modifiedTimeEnd-Long, relatesTo-Map\u003cString,Set\u003cString\u003e\u003e, isRelatedTo-Map\u003cString,Set\u003cString\u003e\u003e, infoFilters-Map\u003cString,Object\u003e, configFilters-Map\u003cString,String\u003e, metricFilters-Set\u003cString\u003e, eventFilters-Set\u003cString\u003e, confsToRetrieve-TimelineFilterList, metricsToRetrieve-TimelineFilterList, fieldsToRetrieve-EnumSet\u003cField\u003e]",
            "newValue": "[userId-String, clusterId-String, flowName-String, flowRunId-Long, appId-String, entityType-String, limit-Long, createdTimeBegin-Long, createdTimeEnd-Long, relatesTo-Map\u003cString,Set\u003cString\u003e\u003e, isRelatedTo-Map\u003cString,Set\u003cString\u003e\u003e, infoFilters-Map\u003cString,Object\u003e, configFilters-Map\u003cString,String\u003e, metricFilters-Set\u003cString\u003e, eventFilters-Set\u003cString\u003e, confsToRetrieve-TimelineFilterList, metricsToRetrieve-TimelineFilterList, fieldsToRetrieve-EnumSet\u003cField\u003e]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-4238. createdTime and modifiedTime is not reported while publishing entities to ATSv2. (Varun Saxena via Naganarasimha G R)\n",
          "commitDate": "10/07/16 8:45 AM",
          "commitName": "6934b05c7117a12286fb2ba7a47f75e227cacb22",
          "commitAuthor": "Naganarasimha",
          "commitDateOld": "10/07/16 8:45 AM",
          "commitNameOld": "88f02941144824187b70fa2aaf0c6d90bcb77d8f",
          "commitAuthorOld": "Li Lu",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 3,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,18 +1,16 @@\n   public Set\u003cTimelineEntity\u003e getEntities(String userId, String clusterId,\n       String flowName, Long flowRunId, String appId, String entityType,\n       Long limit, Long createdTimeBegin, Long createdTimeEnd,\n-      Long modifiedTimeBegin, Long modifiedTimeEnd,\n       Map\u003cString, Set\u003cString\u003e\u003e relatesTo, Map\u003cString, Set\u003cString\u003e\u003e isRelatedTo,\n       Map\u003cString, Object\u003e infoFilters, Map\u003cString, String\u003e configFilters,\n       Set\u003cString\u003e metricFilters, Set\u003cString\u003e eventFilters,\n       TimelineFilterList confsToRetrieve, TimelineFilterList metricsToRetrieve,\n       EnumSet\u003cField\u003e fieldsToRetrieve) throws IOException {\n     TimelineEntityReader reader \u003d\n         TimelineEntityReaderFactory.createMultipleEntitiesReader(userId,\n             clusterId, flowName, flowRunId, appId, entityType, limit,\n-            createdTimeBegin, createdTimeEnd, modifiedTimeBegin,\n-            modifiedTimeEnd, relatesTo, isRelatedTo, infoFilters, configFilters,\n-            metricFilters, eventFilters, confsToRetrieve, metricsToRetrieve,\n-            fieldsToRetrieve);\n+            createdTimeBegin, createdTimeEnd, relatesTo, isRelatedTo,\n+            infoFilters, configFilters, metricFilters, eventFilters,\n+            confsToRetrieve, metricsToRetrieve, fieldsToRetrieve);\n     return reader.readEntities(hbaseConf, conn);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public Set\u003cTimelineEntity\u003e getEntities(String userId, String clusterId,\n      String flowName, Long flowRunId, String appId, String entityType,\n      Long limit, Long createdTimeBegin, Long createdTimeEnd,\n      Map\u003cString, Set\u003cString\u003e\u003e relatesTo, Map\u003cString, Set\u003cString\u003e\u003e isRelatedTo,\n      Map\u003cString, Object\u003e infoFilters, Map\u003cString, String\u003e configFilters,\n      Set\u003cString\u003e metricFilters, Set\u003cString\u003e eventFilters,\n      TimelineFilterList confsToRetrieve, TimelineFilterList metricsToRetrieve,\n      EnumSet\u003cField\u003e fieldsToRetrieve) throws IOException {\n    TimelineEntityReader reader \u003d\n        TimelineEntityReaderFactory.createMultipleEntitiesReader(userId,\n            clusterId, flowName, flowRunId, appId, entityType, limit,\n            createdTimeBegin, createdTimeEnd, relatesTo, isRelatedTo,\n            infoFilters, configFilters, metricFilters, eventFilters,\n            confsToRetrieve, metricsToRetrieve, fieldsToRetrieve);\n    return reader.readEntities(hbaseConf, conn);\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/HBaseTimelineReaderImpl.java",
          "extendedDetails": {}
        }
      ]
    },
    "8ef546c1ee9fce0b171813547253374d268566ba": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "YARN-4445. Unify the term flowId and flowName in timeline v2 codebase.\nContributed by Zhan Zhang.\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "8ef546c1ee9fce0b171813547253374d268566ba",
      "commitAuthor": "Li Lu",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "YARN-4445. Unify the term flowId and flowName in timeline v2 codebase.\nContributed by Zhan Zhang.\n",
          "commitDate": "10/07/16 8:45 AM",
          "commitName": "8ef546c1ee9fce0b171813547253374d268566ba",
          "commitAuthor": "Li Lu",
          "commitDateOld": "10/07/16 8:45 AM",
          "commitNameOld": "1f710484e5b8ab4d5c67379c012004e8a4242d15",
          "commitAuthorOld": "Sangjin Lee",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 6,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,18 +1,18 @@\n   public Set\u003cTimelineEntity\u003e getEntities(String userId, String clusterId,\n-      String flowId, Long flowRunId, String appId, String entityType,\n+      String flowName, Long flowRunId, String appId, String entityType,\n       Long limit, Long createdTimeBegin, Long createdTimeEnd,\n       Long modifiedTimeBegin, Long modifiedTimeEnd,\n       Map\u003cString, Set\u003cString\u003e\u003e relatesTo, Map\u003cString, Set\u003cString\u003e\u003e isRelatedTo,\n       Map\u003cString, Object\u003e infoFilters, Map\u003cString, String\u003e configFilters,\n       Set\u003cString\u003e metricFilters, Set\u003cString\u003e eventFilters,\n       TimelineFilterList confsToRetrieve, TimelineFilterList metricsToRetrieve,\n       EnumSet\u003cField\u003e fieldsToRetrieve) throws IOException {\n     TimelineEntityReader reader \u003d\n         TimelineEntityReaderFactory.createMultipleEntitiesReader(userId,\n-            clusterId, flowId, flowRunId, appId, entityType, limit,\n+            clusterId, flowName, flowRunId, appId, entityType, limit,\n             createdTimeBegin, createdTimeEnd, modifiedTimeBegin,\n             modifiedTimeEnd, relatesTo, isRelatedTo, infoFilters, configFilters,\n             metricFilters, eventFilters, confsToRetrieve, metricsToRetrieve,\n             fieldsToRetrieve);\n     return reader.readEntities(hbaseConf, conn);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public Set\u003cTimelineEntity\u003e getEntities(String userId, String clusterId,\n      String flowName, Long flowRunId, String appId, String entityType,\n      Long limit, Long createdTimeBegin, Long createdTimeEnd,\n      Long modifiedTimeBegin, Long modifiedTimeEnd,\n      Map\u003cString, Set\u003cString\u003e\u003e relatesTo, Map\u003cString, Set\u003cString\u003e\u003e isRelatedTo,\n      Map\u003cString, Object\u003e infoFilters, Map\u003cString, String\u003e configFilters,\n      Set\u003cString\u003e metricFilters, Set\u003cString\u003e eventFilters,\n      TimelineFilterList confsToRetrieve, TimelineFilterList metricsToRetrieve,\n      EnumSet\u003cField\u003e fieldsToRetrieve) throws IOException {\n    TimelineEntityReader reader \u003d\n        TimelineEntityReaderFactory.createMultipleEntitiesReader(userId,\n            clusterId, flowName, flowRunId, appId, entityType, limit,\n            createdTimeBegin, createdTimeEnd, modifiedTimeBegin,\n            modifiedTimeEnd, relatesTo, isRelatedTo, infoFilters, configFilters,\n            metricFilters, eventFilters, confsToRetrieve, metricsToRetrieve,\n            fieldsToRetrieve);\n    return reader.readEntities(hbaseConf, conn);\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/HBaseTimelineReaderImpl.java",
          "extendedDetails": {
            "oldValue": "[userId-String, clusterId-String, flowId-String, flowRunId-Long, appId-String, entityType-String, limit-Long, createdTimeBegin-Long, createdTimeEnd-Long, modifiedTimeBegin-Long, modifiedTimeEnd-Long, relatesTo-Map\u003cString,Set\u003cString\u003e\u003e, isRelatedTo-Map\u003cString,Set\u003cString\u003e\u003e, infoFilters-Map\u003cString,Object\u003e, configFilters-Map\u003cString,String\u003e, metricFilters-Set\u003cString\u003e, eventFilters-Set\u003cString\u003e, confsToRetrieve-TimelineFilterList, metricsToRetrieve-TimelineFilterList, fieldsToRetrieve-EnumSet\u003cField\u003e]",
            "newValue": "[userId-String, clusterId-String, flowName-String, flowRunId-Long, appId-String, entityType-String, limit-Long, createdTimeBegin-Long, createdTimeEnd-Long, modifiedTimeBegin-Long, modifiedTimeEnd-Long, relatesTo-Map\u003cString,Set\u003cString\u003e\u003e, isRelatedTo-Map\u003cString,Set\u003cString\u003e\u003e, infoFilters-Map\u003cString,Object\u003e, configFilters-Map\u003cString,String\u003e, metricFilters-Set\u003cString\u003e, eventFilters-Set\u003cString\u003e, confsToRetrieve-TimelineFilterList, metricsToRetrieve-TimelineFilterList, fieldsToRetrieve-EnumSet\u003cField\u003e]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-4445. Unify the term flowId and flowName in timeline v2 codebase.\nContributed by Zhan Zhang.\n",
          "commitDate": "10/07/16 8:45 AM",
          "commitName": "8ef546c1ee9fce0b171813547253374d268566ba",
          "commitAuthor": "Li Lu",
          "commitDateOld": "10/07/16 8:45 AM",
          "commitNameOld": "1f710484e5b8ab4d5c67379c012004e8a4242d15",
          "commitAuthorOld": "Sangjin Lee",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 6,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,18 +1,18 @@\n   public Set\u003cTimelineEntity\u003e getEntities(String userId, String clusterId,\n-      String flowId, Long flowRunId, String appId, String entityType,\n+      String flowName, Long flowRunId, String appId, String entityType,\n       Long limit, Long createdTimeBegin, Long createdTimeEnd,\n       Long modifiedTimeBegin, Long modifiedTimeEnd,\n       Map\u003cString, Set\u003cString\u003e\u003e relatesTo, Map\u003cString, Set\u003cString\u003e\u003e isRelatedTo,\n       Map\u003cString, Object\u003e infoFilters, Map\u003cString, String\u003e configFilters,\n       Set\u003cString\u003e metricFilters, Set\u003cString\u003e eventFilters,\n       TimelineFilterList confsToRetrieve, TimelineFilterList metricsToRetrieve,\n       EnumSet\u003cField\u003e fieldsToRetrieve) throws IOException {\n     TimelineEntityReader reader \u003d\n         TimelineEntityReaderFactory.createMultipleEntitiesReader(userId,\n-            clusterId, flowId, flowRunId, appId, entityType, limit,\n+            clusterId, flowName, flowRunId, appId, entityType, limit,\n             createdTimeBegin, createdTimeEnd, modifiedTimeBegin,\n             modifiedTimeEnd, relatesTo, isRelatedTo, infoFilters, configFilters,\n             metricFilters, eventFilters, confsToRetrieve, metricsToRetrieve,\n             fieldsToRetrieve);\n     return reader.readEntities(hbaseConf, conn);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public Set\u003cTimelineEntity\u003e getEntities(String userId, String clusterId,\n      String flowName, Long flowRunId, String appId, String entityType,\n      Long limit, Long createdTimeBegin, Long createdTimeEnd,\n      Long modifiedTimeBegin, Long modifiedTimeEnd,\n      Map\u003cString, Set\u003cString\u003e\u003e relatesTo, Map\u003cString, Set\u003cString\u003e\u003e isRelatedTo,\n      Map\u003cString, Object\u003e infoFilters, Map\u003cString, String\u003e configFilters,\n      Set\u003cString\u003e metricFilters, Set\u003cString\u003e eventFilters,\n      TimelineFilterList confsToRetrieve, TimelineFilterList metricsToRetrieve,\n      EnumSet\u003cField\u003e fieldsToRetrieve) throws IOException {\n    TimelineEntityReader reader \u003d\n        TimelineEntityReaderFactory.createMultipleEntitiesReader(userId,\n            clusterId, flowName, flowRunId, appId, entityType, limit,\n            createdTimeBegin, createdTimeEnd, modifiedTimeBegin,\n            modifiedTimeEnd, relatesTo, isRelatedTo, infoFilters, configFilters,\n            metricFilters, eventFilters, confsToRetrieve, metricsToRetrieve,\n            fieldsToRetrieve);\n    return reader.readEntities(hbaseConf, conn);\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/HBaseTimelineReaderImpl.java",
          "extendedDetails": {}
        }
      ]
    },
    "1f710484e5b8ab4d5c67379c012004e8a4242d15": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "YARN-3862. Support for fetching specific configs and metrics based on prefixes (Varun Saxena via sjlee)\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "1f710484e5b8ab4d5c67379c012004e8a4242d15",
      "commitAuthor": "Sangjin Lee",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "YARN-3862. Support for fetching specific configs and metrics based on prefixes (Varun Saxena via sjlee)\n",
          "commitDate": "10/07/16 8:45 AM",
          "commitName": "1f710484e5b8ab4d5c67379c012004e8a4242d15",
          "commitAuthor": "Sangjin Lee",
          "commitDateOld": "10/07/16 8:45 AM",
          "commitNameOld": "10fa6da7d8a6013698767c6136ae20f0e04415e9",
          "commitAuthorOld": "Vrushali",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 12,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,16 +1,18 @@\n   public Set\u003cTimelineEntity\u003e getEntities(String userId, String clusterId,\n       String flowId, Long flowRunId, String appId, String entityType,\n       Long limit, Long createdTimeBegin, Long createdTimeEnd,\n       Long modifiedTimeBegin, Long modifiedTimeEnd,\n       Map\u003cString, Set\u003cString\u003e\u003e relatesTo, Map\u003cString, Set\u003cString\u003e\u003e isRelatedTo,\n       Map\u003cString, Object\u003e infoFilters, Map\u003cString, String\u003e configFilters,\n       Set\u003cString\u003e metricFilters, Set\u003cString\u003e eventFilters,\n+      TimelineFilterList confsToRetrieve, TimelineFilterList metricsToRetrieve,\n       EnumSet\u003cField\u003e fieldsToRetrieve) throws IOException {\n     TimelineEntityReader reader \u003d\n         TimelineEntityReaderFactory.createMultipleEntitiesReader(userId,\n             clusterId, flowId, flowRunId, appId, entityType, limit,\n             createdTimeBegin, createdTimeEnd, modifiedTimeBegin,\n             modifiedTimeEnd, relatesTo, isRelatedTo, infoFilters, configFilters,\n-            metricFilters, eventFilters, fieldsToRetrieve);\n+            metricFilters, eventFilters, confsToRetrieve, metricsToRetrieve,\n+            fieldsToRetrieve);\n     return reader.readEntities(hbaseConf, conn);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public Set\u003cTimelineEntity\u003e getEntities(String userId, String clusterId,\n      String flowId, Long flowRunId, String appId, String entityType,\n      Long limit, Long createdTimeBegin, Long createdTimeEnd,\n      Long modifiedTimeBegin, Long modifiedTimeEnd,\n      Map\u003cString, Set\u003cString\u003e\u003e relatesTo, Map\u003cString, Set\u003cString\u003e\u003e isRelatedTo,\n      Map\u003cString, Object\u003e infoFilters, Map\u003cString, String\u003e configFilters,\n      Set\u003cString\u003e metricFilters, Set\u003cString\u003e eventFilters,\n      TimelineFilterList confsToRetrieve, TimelineFilterList metricsToRetrieve,\n      EnumSet\u003cField\u003e fieldsToRetrieve) throws IOException {\n    TimelineEntityReader reader \u003d\n        TimelineEntityReaderFactory.createMultipleEntitiesReader(userId,\n            clusterId, flowId, flowRunId, appId, entityType, limit,\n            createdTimeBegin, createdTimeEnd, modifiedTimeBegin,\n            modifiedTimeEnd, relatesTo, isRelatedTo, infoFilters, configFilters,\n            metricFilters, eventFilters, confsToRetrieve, metricsToRetrieve,\n            fieldsToRetrieve);\n    return reader.readEntities(hbaseConf, conn);\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/HBaseTimelineReaderImpl.java",
          "extendedDetails": {
            "oldValue": "[userId-String, clusterId-String, flowId-String, flowRunId-Long, appId-String, entityType-String, limit-Long, createdTimeBegin-Long, createdTimeEnd-Long, modifiedTimeBegin-Long, modifiedTimeEnd-Long, relatesTo-Map\u003cString,Set\u003cString\u003e\u003e, isRelatedTo-Map\u003cString,Set\u003cString\u003e\u003e, infoFilters-Map\u003cString,Object\u003e, configFilters-Map\u003cString,String\u003e, metricFilters-Set\u003cString\u003e, eventFilters-Set\u003cString\u003e, fieldsToRetrieve-EnumSet\u003cField\u003e]",
            "newValue": "[userId-String, clusterId-String, flowId-String, flowRunId-Long, appId-String, entityType-String, limit-Long, createdTimeBegin-Long, createdTimeEnd-Long, modifiedTimeBegin-Long, modifiedTimeEnd-Long, relatesTo-Map\u003cString,Set\u003cString\u003e\u003e, isRelatedTo-Map\u003cString,Set\u003cString\u003e\u003e, infoFilters-Map\u003cString,Object\u003e, configFilters-Map\u003cString,String\u003e, metricFilters-Set\u003cString\u003e, eventFilters-Set\u003cString\u003e, confsToRetrieve-TimelineFilterList, metricsToRetrieve-TimelineFilterList, fieldsToRetrieve-EnumSet\u003cField\u003e]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-3862. Support for fetching specific configs and metrics based on prefixes (Varun Saxena via sjlee)\n",
          "commitDate": "10/07/16 8:45 AM",
          "commitName": "1f710484e5b8ab4d5c67379c012004e8a4242d15",
          "commitAuthor": "Sangjin Lee",
          "commitDateOld": "10/07/16 8:45 AM",
          "commitNameOld": "10fa6da7d8a6013698767c6136ae20f0e04415e9",
          "commitAuthorOld": "Vrushali",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 12,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,16 +1,18 @@\n   public Set\u003cTimelineEntity\u003e getEntities(String userId, String clusterId,\n       String flowId, Long flowRunId, String appId, String entityType,\n       Long limit, Long createdTimeBegin, Long createdTimeEnd,\n       Long modifiedTimeBegin, Long modifiedTimeEnd,\n       Map\u003cString, Set\u003cString\u003e\u003e relatesTo, Map\u003cString, Set\u003cString\u003e\u003e isRelatedTo,\n       Map\u003cString, Object\u003e infoFilters, Map\u003cString, String\u003e configFilters,\n       Set\u003cString\u003e metricFilters, Set\u003cString\u003e eventFilters,\n+      TimelineFilterList confsToRetrieve, TimelineFilterList metricsToRetrieve,\n       EnumSet\u003cField\u003e fieldsToRetrieve) throws IOException {\n     TimelineEntityReader reader \u003d\n         TimelineEntityReaderFactory.createMultipleEntitiesReader(userId,\n             clusterId, flowId, flowRunId, appId, entityType, limit,\n             createdTimeBegin, createdTimeEnd, modifiedTimeBegin,\n             modifiedTimeEnd, relatesTo, isRelatedTo, infoFilters, configFilters,\n-            metricFilters, eventFilters, fieldsToRetrieve);\n+            metricFilters, eventFilters, confsToRetrieve, metricsToRetrieve,\n+            fieldsToRetrieve);\n     return reader.readEntities(hbaseConf, conn);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public Set\u003cTimelineEntity\u003e getEntities(String userId, String clusterId,\n      String flowId, Long flowRunId, String appId, String entityType,\n      Long limit, Long createdTimeBegin, Long createdTimeEnd,\n      Long modifiedTimeBegin, Long modifiedTimeEnd,\n      Map\u003cString, Set\u003cString\u003e\u003e relatesTo, Map\u003cString, Set\u003cString\u003e\u003e isRelatedTo,\n      Map\u003cString, Object\u003e infoFilters, Map\u003cString, String\u003e configFilters,\n      Set\u003cString\u003e metricFilters, Set\u003cString\u003e eventFilters,\n      TimelineFilterList confsToRetrieve, TimelineFilterList metricsToRetrieve,\n      EnumSet\u003cField\u003e fieldsToRetrieve) throws IOException {\n    TimelineEntityReader reader \u003d\n        TimelineEntityReaderFactory.createMultipleEntitiesReader(userId,\n            clusterId, flowId, flowRunId, appId, entityType, limit,\n            createdTimeBegin, createdTimeEnd, modifiedTimeBegin,\n            modifiedTimeEnd, relatesTo, isRelatedTo, infoFilters, configFilters,\n            metricFilters, eventFilters, confsToRetrieve, metricsToRetrieve,\n            fieldsToRetrieve);\n    return reader.readEntities(hbaseConf, conn);\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/HBaseTimelineReaderImpl.java",
          "extendedDetails": {}
        }
      ]
    },
    "10fa6da7d8a6013698767c6136ae20f0e04415e9": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4074. [timeline reader] implement support for querying for flows and flow runs (sjlee via vrushali)\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "10fa6da7d8a6013698767c6136ae20f0e04415e9",
      "commitAuthor": "Vrushali",
      "commitDateOld": "10/07/16 8:45 AM",
      "commitNameOld": "7a41b5501ea76f94f15f53f6380b3c63f14b5a78",
      "commitAuthorOld": "Junping Du",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 6,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,78 +1,16 @@\n   public Set\u003cTimelineEntity\u003e getEntities(String userId, String clusterId,\n       String flowId, Long flowRunId, String appId, String entityType,\n       Long limit, Long createdTimeBegin, Long createdTimeEnd,\n       Long modifiedTimeBegin, Long modifiedTimeEnd,\n       Map\u003cString, Set\u003cString\u003e\u003e relatesTo, Map\u003cString, Set\u003cString\u003e\u003e isRelatedTo,\n       Map\u003cString, Object\u003e infoFilters, Map\u003cString, String\u003e configFilters,\n       Set\u003cString\u003e metricFilters, Set\u003cString\u003e eventFilters,\n       EnumSet\u003cField\u003e fieldsToRetrieve) throws IOException {\n-    validateParams(userId, clusterId, appId, entityType, null, false);\n-    // In reality both should be null or neither should be null\n-    if (flowId \u003d\u003d null || flowRunId \u003d\u003d null) {\n-      FlowContext context \u003d lookupFlowContext(clusterId, appId);\n-      flowId \u003d context.flowId;\n-      flowRunId \u003d context.flowRunId;\n-    }\n-    if (limit \u003d\u003d null) {\n-      limit \u003d TimelineReader.DEFAULT_LIMIT;\n-    }\n-    if (createdTimeBegin \u003d\u003d null) {\n-      createdTimeBegin \u003d DEFAULT_BEGIN_TIME;\n-    }\n-    if (createdTimeEnd \u003d\u003d null) {\n-      createdTimeEnd \u003d DEFAULT_END_TIME;\n-    }\n-    if (modifiedTimeBegin \u003d\u003d null) {\n-      modifiedTimeBegin \u003d DEFAULT_BEGIN_TIME;\n-    }\n-    if (modifiedTimeEnd \u003d\u003d null) {\n-      modifiedTimeEnd \u003d DEFAULT_END_TIME;\n-    }\n-    if (fieldsToRetrieve \u003d\u003d null) {\n-      fieldsToRetrieve \u003d EnumSet.noneOf(Field.class);\n-    }\n-\n-    NavigableSet\u003cTimelineEntity\u003e entities \u003d new TreeSet\u003c\u003e();\n-    boolean isApplication \u003d isApplicationEntity(entityType);\n-    if (isApplication) {\n-      // If getEntities() is called for an application, there can be at most\n-      // one entity. If the entity passes the filter, it is returned. Otherwise,\n-      // an empty set is returned.\n-      byte[] rowKey \u003d ApplicationRowKey.getRowKey(clusterId, userId, flowId,\n-          flowRunId, appId);\n-      Get get \u003d new Get(rowKey);\n-      get.setMaxVersions(Integer.MAX_VALUE);\n-      Result result \u003d applicationTable.getResult(hbaseConf, conn, get);\n-      TimelineEntity entity \u003d parseEntity(result, fieldsToRetrieve,\n-          true, createdTimeBegin, createdTimeEnd, true, modifiedTimeBegin,\n-          modifiedTimeEnd, isRelatedTo, relatesTo, infoFilters, configFilters,\n-          eventFilters, metricFilters, isApplication);\n-      if (entity !\u003d null) {\n-        entities.add(entity);\n-      }\n-    } else {\n-      // Scan through part of the table to find the entities belong to one app\n-      // and one type\n-      Scan scan \u003d new Scan();\n-      scan.setRowPrefixFilter(EntityRowKey.getRowKeyPrefix(\n-          clusterId, userId, flowId, flowRunId, appId, entityType));\n-      scan.setMaxVersions(Integer.MAX_VALUE);\n-      ResultScanner scanner \u003d\n-          entityTable.getResultScanner(hbaseConf, conn, scan);\n-      for (Result result : scanner) {\n-        TimelineEntity entity \u003d parseEntity(result, fieldsToRetrieve,\n-            true, createdTimeBegin, createdTimeEnd,\n-            true, modifiedTimeBegin, modifiedTimeEnd,\n-            isRelatedTo, relatesTo, infoFilters, configFilters, eventFilters,\n-            metricFilters, isApplication);\n-        if (entity \u003d\u003d null) {\n-          continue;\n-        }\n-        if (entities.size() \u003e limit) {\n-          entities.pollLast();\n-        }\n-        entities.add(entity);\n-      }\n-    }\n-    return entities;\n+    TimelineEntityReader reader \u003d\n+        TimelineEntityReaderFactory.createMultipleEntitiesReader(userId,\n+            clusterId, flowId, flowRunId, appId, entityType, limit,\n+            createdTimeBegin, createdTimeEnd, modifiedTimeBegin,\n+            modifiedTimeEnd, relatesTo, isRelatedTo, infoFilters, configFilters,\n+            metricFilters, eventFilters, fieldsToRetrieve);\n+    return reader.readEntities(hbaseConf, conn);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public Set\u003cTimelineEntity\u003e getEntities(String userId, String clusterId,\n      String flowId, Long flowRunId, String appId, String entityType,\n      Long limit, Long createdTimeBegin, Long createdTimeEnd,\n      Long modifiedTimeBegin, Long modifiedTimeEnd,\n      Map\u003cString, Set\u003cString\u003e\u003e relatesTo, Map\u003cString, Set\u003cString\u003e\u003e isRelatedTo,\n      Map\u003cString, Object\u003e infoFilters, Map\u003cString, String\u003e configFilters,\n      Set\u003cString\u003e metricFilters, Set\u003cString\u003e eventFilters,\n      EnumSet\u003cField\u003e fieldsToRetrieve) throws IOException {\n    TimelineEntityReader reader \u003d\n        TimelineEntityReaderFactory.createMultipleEntitiesReader(userId,\n            clusterId, flowId, flowRunId, appId, entityType, limit,\n            createdTimeBegin, createdTimeEnd, modifiedTimeBegin,\n            modifiedTimeEnd, relatesTo, isRelatedTo, infoFilters, configFilters,\n            metricFilters, eventFilters, fieldsToRetrieve);\n    return reader.readEntities(hbaseConf, conn);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/HBaseTimelineReaderImpl.java",
      "extendedDetails": {}
    },
    "00e85e7a2b9446dc37265feba07473b156d66367": {
      "type": "Ybodychange",
      "commitMessage": "YARN-3906. Split the application table from the entity table. Contributed by Sangjin Lee.\n\n(cherry picked from commit bcd755eba9466ce277d3c14192c31da6462c4ab3)\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "00e85e7a2b9446dc37265feba07473b156d66367",
      "commitAuthor": "Junping Du",
      "commitDateOld": "10/07/16 8:45 AM",
      "commitNameOld": "9e5155be363c6610ccf41fe08b7f1394f353ea65",
      "commitAuthorOld": "Sangjin Lee",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,58 +1,78 @@\n   public Set\u003cTimelineEntity\u003e getEntities(String userId, String clusterId,\n       String flowId, Long flowRunId, String appId, String entityType,\n       Long limit, Long createdTimeBegin, Long createdTimeEnd,\n       Long modifiedTimeBegin, Long modifiedTimeEnd,\n       Map\u003cString, Set\u003cString\u003e\u003e relatesTo, Map\u003cString, Set\u003cString\u003e\u003e isRelatedTo,\n       Map\u003cString, Object\u003e infoFilters, Map\u003cString, String\u003e configFilters,\n       Set\u003cString\u003e metricFilters, Set\u003cString\u003e eventFilters,\n       EnumSet\u003cField\u003e fieldsToRetrieve) throws IOException {\n     validateParams(userId, clusterId, appId, entityType, null, false);\n     // In reality both should be null or neither should be null\n     if (flowId \u003d\u003d null || flowRunId \u003d\u003d null) {\n       FlowContext context \u003d lookupFlowContext(clusterId, appId);\n       flowId \u003d context.flowId;\n       flowRunId \u003d context.flowRunId;\n     }\n     if (limit \u003d\u003d null) {\n       limit \u003d TimelineReader.DEFAULT_LIMIT;\n     }\n     if (createdTimeBegin \u003d\u003d null) {\n       createdTimeBegin \u003d DEFAULT_BEGIN_TIME;\n     }\n     if (createdTimeEnd \u003d\u003d null) {\n       createdTimeEnd \u003d DEFAULT_END_TIME;\n     }\n     if (modifiedTimeBegin \u003d\u003d null) {\n       modifiedTimeBegin \u003d DEFAULT_BEGIN_TIME;\n     }\n     if (modifiedTimeEnd \u003d\u003d null) {\n       modifiedTimeEnd \u003d DEFAULT_END_TIME;\n     }\n     if (fieldsToRetrieve \u003d\u003d null) {\n       fieldsToRetrieve \u003d EnumSet.noneOf(Field.class);\n     }\n \n     NavigableSet\u003cTimelineEntity\u003e entities \u003d new TreeSet\u003c\u003e();\n-    // Scan through part of the table to find the entities belong to one app and\n-    // one type\n-    Scan scan \u003d new Scan();\n-    scan.setRowPrefixFilter(EntityRowKey.getRowKeyPrefix(\n-        clusterId, userId, flowId, flowRunId, appId, entityType));\n-    scan.setMaxVersions(Integer.MAX_VALUE);\n-    ResultScanner scanner \u003d entityTable.getResultScanner(hbaseConf, conn, scan);\n-    for (Result result : scanner) {\n+    boolean isApplication \u003d isApplicationEntity(entityType);\n+    if (isApplication) {\n+      // If getEntities() is called for an application, there can be at most\n+      // one entity. If the entity passes the filter, it is returned. Otherwise,\n+      // an empty set is returned.\n+      byte[] rowKey \u003d ApplicationRowKey.getRowKey(clusterId, userId, flowId,\n+          flowRunId, appId);\n+      Get get \u003d new Get(rowKey);\n+      get.setMaxVersions(Integer.MAX_VALUE);\n+      Result result \u003d applicationTable.getResult(hbaseConf, conn, get);\n       TimelineEntity entity \u003d parseEntity(result, fieldsToRetrieve,\n-          true, createdTimeBegin, createdTimeEnd,\n-          true, modifiedTimeBegin, modifiedTimeEnd,\n-          isRelatedTo, relatesTo, infoFilters, configFilters, eventFilters,\n-          metricFilters);\n-      if (entity \u003d\u003d null) {\n-        continue;\n+          true, createdTimeBegin, createdTimeEnd, true, modifiedTimeBegin,\n+          modifiedTimeEnd, isRelatedTo, relatesTo, infoFilters, configFilters,\n+          eventFilters, metricFilters, isApplication);\n+      if (entity !\u003d null) {\n+        entities.add(entity);\n       }\n-      if (entities.size() \u003e limit) {\n-        entities.pollLast();\n+    } else {\n+      // Scan through part of the table to find the entities belong to one app\n+      // and one type\n+      Scan scan \u003d new Scan();\n+      scan.setRowPrefixFilter(EntityRowKey.getRowKeyPrefix(\n+          clusterId, userId, flowId, flowRunId, appId, entityType));\n+      scan.setMaxVersions(Integer.MAX_VALUE);\n+      ResultScanner scanner \u003d\n+          entityTable.getResultScanner(hbaseConf, conn, scan);\n+      for (Result result : scanner) {\n+        TimelineEntity entity \u003d parseEntity(result, fieldsToRetrieve,\n+            true, createdTimeBegin, createdTimeEnd,\n+            true, modifiedTimeBegin, modifiedTimeEnd,\n+            isRelatedTo, relatesTo, infoFilters, configFilters, eventFilters,\n+            metricFilters, isApplication);\n+        if (entity \u003d\u003d null) {\n+          continue;\n+        }\n+        if (entities.size() \u003e limit) {\n+          entities.pollLast();\n+        }\n+        entities.add(entity);\n       }\n-      entities.add(entity);\n     }\n     return entities;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public Set\u003cTimelineEntity\u003e getEntities(String userId, String clusterId,\n      String flowId, Long flowRunId, String appId, String entityType,\n      Long limit, Long createdTimeBegin, Long createdTimeEnd,\n      Long modifiedTimeBegin, Long modifiedTimeEnd,\n      Map\u003cString, Set\u003cString\u003e\u003e relatesTo, Map\u003cString, Set\u003cString\u003e\u003e isRelatedTo,\n      Map\u003cString, Object\u003e infoFilters, Map\u003cString, String\u003e configFilters,\n      Set\u003cString\u003e metricFilters, Set\u003cString\u003e eventFilters,\n      EnumSet\u003cField\u003e fieldsToRetrieve) throws IOException {\n    validateParams(userId, clusterId, appId, entityType, null, false);\n    // In reality both should be null or neither should be null\n    if (flowId \u003d\u003d null || flowRunId \u003d\u003d null) {\n      FlowContext context \u003d lookupFlowContext(clusterId, appId);\n      flowId \u003d context.flowId;\n      flowRunId \u003d context.flowRunId;\n    }\n    if (limit \u003d\u003d null) {\n      limit \u003d TimelineReader.DEFAULT_LIMIT;\n    }\n    if (createdTimeBegin \u003d\u003d null) {\n      createdTimeBegin \u003d DEFAULT_BEGIN_TIME;\n    }\n    if (createdTimeEnd \u003d\u003d null) {\n      createdTimeEnd \u003d DEFAULT_END_TIME;\n    }\n    if (modifiedTimeBegin \u003d\u003d null) {\n      modifiedTimeBegin \u003d DEFAULT_BEGIN_TIME;\n    }\n    if (modifiedTimeEnd \u003d\u003d null) {\n      modifiedTimeEnd \u003d DEFAULT_END_TIME;\n    }\n    if (fieldsToRetrieve \u003d\u003d null) {\n      fieldsToRetrieve \u003d EnumSet.noneOf(Field.class);\n    }\n\n    NavigableSet\u003cTimelineEntity\u003e entities \u003d new TreeSet\u003c\u003e();\n    boolean isApplication \u003d isApplicationEntity(entityType);\n    if (isApplication) {\n      // If getEntities() is called for an application, there can be at most\n      // one entity. If the entity passes the filter, it is returned. Otherwise,\n      // an empty set is returned.\n      byte[] rowKey \u003d ApplicationRowKey.getRowKey(clusterId, userId, flowId,\n          flowRunId, appId);\n      Get get \u003d new Get(rowKey);\n      get.setMaxVersions(Integer.MAX_VALUE);\n      Result result \u003d applicationTable.getResult(hbaseConf, conn, get);\n      TimelineEntity entity \u003d parseEntity(result, fieldsToRetrieve,\n          true, createdTimeBegin, createdTimeEnd, true, modifiedTimeBegin,\n          modifiedTimeEnd, isRelatedTo, relatesTo, infoFilters, configFilters,\n          eventFilters, metricFilters, isApplication);\n      if (entity !\u003d null) {\n        entities.add(entity);\n      }\n    } else {\n      // Scan through part of the table to find the entities belong to one app\n      // and one type\n      Scan scan \u003d new Scan();\n      scan.setRowPrefixFilter(EntityRowKey.getRowKeyPrefix(\n          clusterId, userId, flowId, flowRunId, appId, entityType));\n      scan.setMaxVersions(Integer.MAX_VALUE);\n      ResultScanner scanner \u003d\n          entityTable.getResultScanner(hbaseConf, conn, scan);\n      for (Result result : scanner) {\n        TimelineEntity entity \u003d parseEntity(result, fieldsToRetrieve,\n            true, createdTimeBegin, createdTimeEnd,\n            true, modifiedTimeBegin, modifiedTimeEnd,\n            isRelatedTo, relatesTo, infoFilters, configFilters, eventFilters,\n            metricFilters, isApplication);\n        if (entity \u003d\u003d null) {\n          continue;\n        }\n        if (entities.size() \u003e limit) {\n          entities.pollLast();\n        }\n        entities.add(entity);\n      }\n    }\n    return entities;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/HBaseTimelineReaderImpl.java",
      "extendedDetails": {}
    },
    "9e5155be363c6610ccf41fe08b7f1394f353ea65": {
      "type": "Yintroduced",
      "commitMessage": "YARN-3049. [Storage Implementation] Implement storage reader interface to fetch raw data from HBase backend (Zhijie Shen via sjlee)\n\n(cherry picked from commit 07433c2ad52df9e844dbd90020c277d3df844dcd)\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "9e5155be363c6610ccf41fe08b7f1394f353ea65",
      "commitAuthor": "Sangjin Lee",
      "diff": "@@ -0,0 +1,58 @@\n+  public Set\u003cTimelineEntity\u003e getEntities(String userId, String clusterId,\n+      String flowId, Long flowRunId, String appId, String entityType,\n+      Long limit, Long createdTimeBegin, Long createdTimeEnd,\n+      Long modifiedTimeBegin, Long modifiedTimeEnd,\n+      Map\u003cString, Set\u003cString\u003e\u003e relatesTo, Map\u003cString, Set\u003cString\u003e\u003e isRelatedTo,\n+      Map\u003cString, Object\u003e infoFilters, Map\u003cString, String\u003e configFilters,\n+      Set\u003cString\u003e metricFilters, Set\u003cString\u003e eventFilters,\n+      EnumSet\u003cField\u003e fieldsToRetrieve) throws IOException {\n+    validateParams(userId, clusterId, appId, entityType, null, false);\n+    // In reality both should be null or neither should be null\n+    if (flowId \u003d\u003d null || flowRunId \u003d\u003d null) {\n+      FlowContext context \u003d lookupFlowContext(clusterId, appId);\n+      flowId \u003d context.flowId;\n+      flowRunId \u003d context.flowRunId;\n+    }\n+    if (limit \u003d\u003d null) {\n+      limit \u003d TimelineReader.DEFAULT_LIMIT;\n+    }\n+    if (createdTimeBegin \u003d\u003d null) {\n+      createdTimeBegin \u003d DEFAULT_BEGIN_TIME;\n+    }\n+    if (createdTimeEnd \u003d\u003d null) {\n+      createdTimeEnd \u003d DEFAULT_END_TIME;\n+    }\n+    if (modifiedTimeBegin \u003d\u003d null) {\n+      modifiedTimeBegin \u003d DEFAULT_BEGIN_TIME;\n+    }\n+    if (modifiedTimeEnd \u003d\u003d null) {\n+      modifiedTimeEnd \u003d DEFAULT_END_TIME;\n+    }\n+    if (fieldsToRetrieve \u003d\u003d null) {\n+      fieldsToRetrieve \u003d EnumSet.noneOf(Field.class);\n+    }\n+\n+    NavigableSet\u003cTimelineEntity\u003e entities \u003d new TreeSet\u003c\u003e();\n+    // Scan through part of the table to find the entities belong to one app and\n+    // one type\n+    Scan scan \u003d new Scan();\n+    scan.setRowPrefixFilter(EntityRowKey.getRowKeyPrefix(\n+        clusterId, userId, flowId, flowRunId, appId, entityType));\n+    scan.setMaxVersions(Integer.MAX_VALUE);\n+    ResultScanner scanner \u003d entityTable.getResultScanner(hbaseConf, conn, scan);\n+    for (Result result : scanner) {\n+      TimelineEntity entity \u003d parseEntity(result, fieldsToRetrieve,\n+          true, createdTimeBegin, createdTimeEnd,\n+          true, modifiedTimeBegin, modifiedTimeEnd,\n+          isRelatedTo, relatesTo, infoFilters, configFilters, eventFilters,\n+          metricFilters);\n+      if (entity \u003d\u003d null) {\n+        continue;\n+      }\n+      if (entities.size() \u003e limit) {\n+        entities.pollLast();\n+      }\n+      entities.add(entity);\n+    }\n+    return entities;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public Set\u003cTimelineEntity\u003e getEntities(String userId, String clusterId,\n      String flowId, Long flowRunId, String appId, String entityType,\n      Long limit, Long createdTimeBegin, Long createdTimeEnd,\n      Long modifiedTimeBegin, Long modifiedTimeEnd,\n      Map\u003cString, Set\u003cString\u003e\u003e relatesTo, Map\u003cString, Set\u003cString\u003e\u003e isRelatedTo,\n      Map\u003cString, Object\u003e infoFilters, Map\u003cString, String\u003e configFilters,\n      Set\u003cString\u003e metricFilters, Set\u003cString\u003e eventFilters,\n      EnumSet\u003cField\u003e fieldsToRetrieve) throws IOException {\n    validateParams(userId, clusterId, appId, entityType, null, false);\n    // In reality both should be null or neither should be null\n    if (flowId \u003d\u003d null || flowRunId \u003d\u003d null) {\n      FlowContext context \u003d lookupFlowContext(clusterId, appId);\n      flowId \u003d context.flowId;\n      flowRunId \u003d context.flowRunId;\n    }\n    if (limit \u003d\u003d null) {\n      limit \u003d TimelineReader.DEFAULT_LIMIT;\n    }\n    if (createdTimeBegin \u003d\u003d null) {\n      createdTimeBegin \u003d DEFAULT_BEGIN_TIME;\n    }\n    if (createdTimeEnd \u003d\u003d null) {\n      createdTimeEnd \u003d DEFAULT_END_TIME;\n    }\n    if (modifiedTimeBegin \u003d\u003d null) {\n      modifiedTimeBegin \u003d DEFAULT_BEGIN_TIME;\n    }\n    if (modifiedTimeEnd \u003d\u003d null) {\n      modifiedTimeEnd \u003d DEFAULT_END_TIME;\n    }\n    if (fieldsToRetrieve \u003d\u003d null) {\n      fieldsToRetrieve \u003d EnumSet.noneOf(Field.class);\n    }\n\n    NavigableSet\u003cTimelineEntity\u003e entities \u003d new TreeSet\u003c\u003e();\n    // Scan through part of the table to find the entities belong to one app and\n    // one type\n    Scan scan \u003d new Scan();\n    scan.setRowPrefixFilter(EntityRowKey.getRowKeyPrefix(\n        clusterId, userId, flowId, flowRunId, appId, entityType));\n    scan.setMaxVersions(Integer.MAX_VALUE);\n    ResultScanner scanner \u003d entityTable.getResultScanner(hbaseConf, conn, scan);\n    for (Result result : scanner) {\n      TimelineEntity entity \u003d parseEntity(result, fieldsToRetrieve,\n          true, createdTimeBegin, createdTimeEnd,\n          true, modifiedTimeBegin, modifiedTimeEnd,\n          isRelatedTo, relatesTo, infoFilters, configFilters, eventFilters,\n          metricFilters);\n      if (entity \u003d\u003d null) {\n        continue;\n      }\n      if (entities.size() \u003e limit) {\n        entities.pollLast();\n      }\n      entities.add(entity);\n    }\n    return entities;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/HBaseTimelineReaderImpl.java"
    }
  }
}