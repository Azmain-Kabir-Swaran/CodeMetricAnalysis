{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FileChecksumHelper.java",
  "functionName": "checksumBlockGroup",
  "functionId": "checksumBlockGroup___blockGroup-LocatedStripedBlock",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/FileChecksumHelper.java",
  "functionStartLine": 646,
  "functionEndLine": 685,
  "numCommitsSeen": 9,
  "timeTaken": 1467,
  "changeHistory": [
    "e6cb07520f935efde3e881de8f84ee7f6e0a746f",
    "d749cf65e1ab0e0daf5be86931507183f189e855",
    "3a4ff7776e8fab6cc87932b9aa8fb48f7b69c720"
  ],
  "changeHistoryShort": {
    "e6cb07520f935efde3e881de8f84ee7f6e0a746f": "Ybodychange",
    "d749cf65e1ab0e0daf5be86931507183f189e855": "Ybodychange",
    "3a4ff7776e8fab6cc87932b9aa8fb48f7b69c720": "Yintroduced"
  },
  "changeHistoryDetails": {
    "e6cb07520f935efde3e881de8f84ee7f6e0a746f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10460. Recompute block checksum for a particular range less than file size on the fly by reconstructing missed block. Contributed by Rakesh R\n",
      "commitDate": "24/06/16 2:39 AM",
      "commitName": "e6cb07520f935efde3e881de8f84ee7f6e0a746f",
      "commitAuthor": "Kai Zheng",
      "commitDateOld": "01/06/16 9:56 PM",
      "commitNameOld": "d749cf65e1ab0e0daf5be86931507183f189e855",
      "commitAuthorOld": "Kai Zheng",
      "daysBetweenCommits": 22.2,
      "commitsBetweenForRepo": 141,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,38 +1,40 @@\n     private boolean checksumBlockGroup(\n         LocatedStripedBlock blockGroup) throws IOException {\n       ExtendedBlock block \u003d blockGroup.getBlock();\n+      long requestedNumBytes \u003d block.getNumBytes();\n       if (getRemaining() \u003c block.getNumBytes()) {\n-        block.setNumBytes(getRemaining());\n+        requestedNumBytes \u003d getRemaining();\n       }\n-      setRemaining(getRemaining() - block.getNumBytes());\n+      setRemaining(getRemaining() - requestedNumBytes);\n \n       StripedBlockInfo stripedBlockInfo \u003d new StripedBlockInfo(block,\n           blockGroup.getLocations(), blockGroup.getBlockTokens(),\n           blockGroup.getBlockIndices(), ecPolicy);\n       DatanodeInfo[] datanodes \u003d blockGroup.getLocations();\n \n       //try each datanode in the block group.\n       boolean done \u003d false;\n       for (int j \u003d 0; !done \u0026\u0026 j \u003c datanodes.length; j++) {\n         try {\n-          tryDatanode(blockGroup, stripedBlockInfo, datanodes[j]);\n+          tryDatanode(blockGroup, stripedBlockInfo, datanodes[j],\n+              requestedNumBytes);\n           done \u003d true;\n         } catch (InvalidBlockTokenException ibte) {\n           if (bgIdx \u003e getLastRetriedIndex()) {\n             LOG.debug(\"Got access token error in response to OP_BLOCK_CHECKSUM \"\n                     + \"for file {} for block {} from datanode {}. Will retry \"\n                     + \"the block once.\",\n                 getSrc(), block, datanodes[j]);\n             setLastRetriedIndex(bgIdx);\n             done \u003d true; // actually it\u0027s not done; but we\u0027ll retry\n             bgIdx--; // repeat at bgIdx-th block\n             setRefetchBlocks(true);\n           }\n         } catch (IOException ie) {\n           LOG.warn(\"src\u003d{}\" + \", datanodes[{}]\u003d{}\",\n               getSrc(), j, datanodes[j], ie);\n         }\n       }\n \n       return done;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private boolean checksumBlockGroup(\n        LocatedStripedBlock blockGroup) throws IOException {\n      ExtendedBlock block \u003d blockGroup.getBlock();\n      long requestedNumBytes \u003d block.getNumBytes();\n      if (getRemaining() \u003c block.getNumBytes()) {\n        requestedNumBytes \u003d getRemaining();\n      }\n      setRemaining(getRemaining() - requestedNumBytes);\n\n      StripedBlockInfo stripedBlockInfo \u003d new StripedBlockInfo(block,\n          blockGroup.getLocations(), blockGroup.getBlockTokens(),\n          blockGroup.getBlockIndices(), ecPolicy);\n      DatanodeInfo[] datanodes \u003d blockGroup.getLocations();\n\n      //try each datanode in the block group.\n      boolean done \u003d false;\n      for (int j \u003d 0; !done \u0026\u0026 j \u003c datanodes.length; j++) {\n        try {\n          tryDatanode(blockGroup, stripedBlockInfo, datanodes[j],\n              requestedNumBytes);\n          done \u003d true;\n        } catch (InvalidBlockTokenException ibte) {\n          if (bgIdx \u003e getLastRetriedIndex()) {\n            LOG.debug(\"Got access token error in response to OP_BLOCK_CHECKSUM \"\n                    + \"for file {} for block {} from datanode {}. Will retry \"\n                    + \"the block once.\",\n                getSrc(), block, datanodes[j]);\n            setLastRetriedIndex(bgIdx);\n            done \u003d true; // actually it\u0027s not done; but we\u0027ll retry\n            bgIdx--; // repeat at bgIdx-th block\n            setRefetchBlocks(true);\n          }\n        } catch (IOException ie) {\n          LOG.warn(\"src\u003d{}\" + \", datanodes[{}]\u003d{}\",\n              getSrc(), j, datanodes[j], ie);\n        }\n      }\n\n      return done;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/FileChecksumHelper.java",
      "extendedDetails": {}
    },
    "d749cf65e1ab0e0daf5be86931507183f189e855": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9833. Erasure coding: recomputing block checksum on the fly by reconstructing the missed/corrupt block data. Contributed by Rakesh R.\n",
      "commitDate": "01/06/16 9:56 PM",
      "commitName": "d749cf65e1ab0e0daf5be86931507183f189e855",
      "commitAuthor": "Kai Zheng",
      "commitDateOld": "26/03/16 7:58 PM",
      "commitNameOld": "3a4ff7776e8fab6cc87932b9aa8fb48f7b69c720",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 67.08,
      "commitsBetweenForRepo": 433,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,37 +1,38 @@\n     private boolean checksumBlockGroup(\n         LocatedStripedBlock blockGroup) throws IOException {\n       ExtendedBlock block \u003d blockGroup.getBlock();\n       if (getRemaining() \u003c block.getNumBytes()) {\n         block.setNumBytes(getRemaining());\n       }\n       setRemaining(getRemaining() - block.getNumBytes());\n \n       StripedBlockInfo stripedBlockInfo \u003d new StripedBlockInfo(block,\n-          blockGroup.getLocations(), blockGroup.getBlockTokens(), ecPolicy);\n+          blockGroup.getLocations(), blockGroup.getBlockTokens(),\n+          blockGroup.getBlockIndices(), ecPolicy);\n       DatanodeInfo[] datanodes \u003d blockGroup.getLocations();\n \n       //try each datanode in the block group.\n       boolean done \u003d false;\n       for (int j \u003d 0; !done \u0026\u0026 j \u003c datanodes.length; j++) {\n         try {\n           tryDatanode(blockGroup, stripedBlockInfo, datanodes[j]);\n           done \u003d true;\n         } catch (InvalidBlockTokenException ibte) {\n           if (bgIdx \u003e getLastRetriedIndex()) {\n             LOG.debug(\"Got access token error in response to OP_BLOCK_CHECKSUM \"\n                     + \"for file {} for block {} from datanode {}. Will retry \"\n                     + \"the block once.\",\n                 getSrc(), block, datanodes[j]);\n             setLastRetriedIndex(bgIdx);\n             done \u003d true; // actually it\u0027s not done; but we\u0027ll retry\n             bgIdx--; // repeat at bgIdx-th block\n             setRefetchBlocks(true);\n           }\n         } catch (IOException ie) {\n           LOG.warn(\"src\u003d{}\" + \", datanodes[{}]\u003d{}\",\n               getSrc(), j, datanodes[j], ie);\n         }\n       }\n \n       return done;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private boolean checksumBlockGroup(\n        LocatedStripedBlock blockGroup) throws IOException {\n      ExtendedBlock block \u003d blockGroup.getBlock();\n      if (getRemaining() \u003c block.getNumBytes()) {\n        block.setNumBytes(getRemaining());\n      }\n      setRemaining(getRemaining() - block.getNumBytes());\n\n      StripedBlockInfo stripedBlockInfo \u003d new StripedBlockInfo(block,\n          blockGroup.getLocations(), blockGroup.getBlockTokens(),\n          blockGroup.getBlockIndices(), ecPolicy);\n      DatanodeInfo[] datanodes \u003d blockGroup.getLocations();\n\n      //try each datanode in the block group.\n      boolean done \u003d false;\n      for (int j \u003d 0; !done \u0026\u0026 j \u003c datanodes.length; j++) {\n        try {\n          tryDatanode(blockGroup, stripedBlockInfo, datanodes[j]);\n          done \u003d true;\n        } catch (InvalidBlockTokenException ibte) {\n          if (bgIdx \u003e getLastRetriedIndex()) {\n            LOG.debug(\"Got access token error in response to OP_BLOCK_CHECKSUM \"\n                    + \"for file {} for block {} from datanode {}. Will retry \"\n                    + \"the block once.\",\n                getSrc(), block, datanodes[j]);\n            setLastRetriedIndex(bgIdx);\n            done \u003d true; // actually it\u0027s not done; but we\u0027ll retry\n            bgIdx--; // repeat at bgIdx-th block\n            setRefetchBlocks(true);\n          }\n        } catch (IOException ie) {\n          LOG.warn(\"src\u003d{}\" + \", datanodes[{}]\u003d{}\",\n              getSrc(), j, datanodes[j], ie);\n        }\n      }\n\n      return done;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/FileChecksumHelper.java",
      "extendedDetails": {}
    },
    "3a4ff7776e8fab6cc87932b9aa8fb48f7b69c720": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-9694. Make existing DFSClient#getFileChecksum() work for striped blocks. Contributed by Kai Zheng\n",
      "commitDate": "26/03/16 7:58 PM",
      "commitName": "3a4ff7776e8fab6cc87932b9aa8fb48f7b69c720",
      "commitAuthor": "Uma Maheswara Rao G",
      "diff": "@@ -0,0 +1,37 @@\n+    private boolean checksumBlockGroup(\n+        LocatedStripedBlock blockGroup) throws IOException {\n+      ExtendedBlock block \u003d blockGroup.getBlock();\n+      if (getRemaining() \u003c block.getNumBytes()) {\n+        block.setNumBytes(getRemaining());\n+      }\n+      setRemaining(getRemaining() - block.getNumBytes());\n+\n+      StripedBlockInfo stripedBlockInfo \u003d new StripedBlockInfo(block,\n+          blockGroup.getLocations(), blockGroup.getBlockTokens(), ecPolicy);\n+      DatanodeInfo[] datanodes \u003d blockGroup.getLocations();\n+\n+      //try each datanode in the block group.\n+      boolean done \u003d false;\n+      for (int j \u003d 0; !done \u0026\u0026 j \u003c datanodes.length; j++) {\n+        try {\n+          tryDatanode(blockGroup, stripedBlockInfo, datanodes[j]);\n+          done \u003d true;\n+        } catch (InvalidBlockTokenException ibte) {\n+          if (bgIdx \u003e getLastRetriedIndex()) {\n+            LOG.debug(\"Got access token error in response to OP_BLOCK_CHECKSUM \"\n+                    + \"for file {} for block {} from datanode {}. Will retry \"\n+                    + \"the block once.\",\n+                getSrc(), block, datanodes[j]);\n+            setLastRetriedIndex(bgIdx);\n+            done \u003d true; // actually it\u0027s not done; but we\u0027ll retry\n+            bgIdx--; // repeat at bgIdx-th block\n+            setRefetchBlocks(true);\n+          }\n+        } catch (IOException ie) {\n+          LOG.warn(\"src\u003d{}\" + \", datanodes[{}]\u003d{}\",\n+              getSrc(), j, datanodes[j], ie);\n+        }\n+      }\n+\n+      return done;\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    private boolean checksumBlockGroup(\n        LocatedStripedBlock blockGroup) throws IOException {\n      ExtendedBlock block \u003d blockGroup.getBlock();\n      if (getRemaining() \u003c block.getNumBytes()) {\n        block.setNumBytes(getRemaining());\n      }\n      setRemaining(getRemaining() - block.getNumBytes());\n\n      StripedBlockInfo stripedBlockInfo \u003d new StripedBlockInfo(block,\n          blockGroup.getLocations(), blockGroup.getBlockTokens(), ecPolicy);\n      DatanodeInfo[] datanodes \u003d blockGroup.getLocations();\n\n      //try each datanode in the block group.\n      boolean done \u003d false;\n      for (int j \u003d 0; !done \u0026\u0026 j \u003c datanodes.length; j++) {\n        try {\n          tryDatanode(blockGroup, stripedBlockInfo, datanodes[j]);\n          done \u003d true;\n        } catch (InvalidBlockTokenException ibte) {\n          if (bgIdx \u003e getLastRetriedIndex()) {\n            LOG.debug(\"Got access token error in response to OP_BLOCK_CHECKSUM \"\n                    + \"for file {} for block {} from datanode {}. Will retry \"\n                    + \"the block once.\",\n                getSrc(), block, datanodes[j]);\n            setLastRetriedIndex(bgIdx);\n            done \u003d true; // actually it\u0027s not done; but we\u0027ll retry\n            bgIdx--; // repeat at bgIdx-th block\n            setRefetchBlocks(true);\n          }\n        } catch (IOException ie) {\n          LOG.warn(\"src\u003d{}\" + \", datanodes[{}]\u003d{}\",\n              getSrc(), j, datanodes[j], ie);\n        }\n      }\n\n      return done;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/FileChecksumHelper.java"
    }
  }
}