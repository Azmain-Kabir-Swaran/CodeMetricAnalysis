{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockManager.java",
  "functionName": "chooseExcessRedundancyContiguous",
  "functionId": "chooseExcessRedundancyContiguous___nonExcess-Collection__DatanodeStorageInfo__(modifiers-final)__storedBlock-BlockInfo__replication-short__addedNode-DatanodeDescriptor__delNodeHint-DatanodeDescriptor__excessTypes-List__StorageType__",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
  "functionStartLine": 3926,
  "functionEndLine": 3937,
  "numCommitsSeen": 1099,
  "timeTaken": 11479,
  "changeHistory": [
    "51edaacd09d86419f99ca96545a1393db1f43f73",
    "a2a5d7b5bca715835d92816e7b267b59f7270708",
    "5865fe2bf01284993572ea60b3ec3bf8b4492818",
    "408f2c807bbaaaa37ce1b69a5dfa9d76ed427d6e",
    "e27c2ae8bafc94f18eb38f5d839dcef5652d424e"
  ],
  "changeHistoryShort": {
    "51edaacd09d86419f99ca96545a1393db1f43f73": "Ybodychange",
    "a2a5d7b5bca715835d92816e7b267b59f7270708": "Ybodychange",
    "5865fe2bf01284993572ea60b3ec3bf8b4492818": "Ymultichange(Yrename,Ybodychange)",
    "408f2c807bbaaaa37ce1b69a5dfa9d76ed427d6e": "Ybodychange",
    "e27c2ae8bafc94f18eb38f5d839dcef5652d424e": "Ymultichange(Yparameterchange,Ybodychange)"
  },
  "changeHistoryDetails": {
    "51edaacd09d86419f99ca96545a1393db1f43f73": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12445. Correct spellings of choosen to chosen. Contributed by hu xiaodong.\n",
      "commitDate": "19/09/17 1:48 PM",
      "commitName": "51edaacd09d86419f99ca96545a1393db1f43f73",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "15/09/17 12:12 PM",
      "commitNameOld": "fbe06b58805aac4861fb27dfa273914b69e8bdc6",
      "commitAuthorOld": "Lei Xu",
      "daysBetweenCommits": 4.07,
      "commitsBetweenForRepo": 31,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,12 @@\n   private void chooseExcessRedundancyContiguous(\n       final Collection\u003cDatanodeStorageInfo\u003e nonExcess, BlockInfo storedBlock,\n       short replication, DatanodeDescriptor addedNode,\n       DatanodeDescriptor delNodeHint, List\u003cStorageType\u003e excessTypes) {\n     BlockPlacementPolicy replicator \u003d placementPolicies.getPolicy(CONTIGUOUS);\n     List\u003cDatanodeStorageInfo\u003e replicasToDelete \u003d replicator\n         .chooseReplicasToDelete(nonExcess, nonExcess, replication, excessTypes,\n             addedNode, delNodeHint);\n-    for (DatanodeStorageInfo choosenReplica : replicasToDelete) {\n-      processChosenExcessRedundancy(nonExcess, choosenReplica, storedBlock);\n+    for (DatanodeStorageInfo chosenReplica : replicasToDelete) {\n+      processChosenExcessRedundancy(nonExcess, chosenReplica, storedBlock);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void chooseExcessRedundancyContiguous(\n      final Collection\u003cDatanodeStorageInfo\u003e nonExcess, BlockInfo storedBlock,\n      short replication, DatanodeDescriptor addedNode,\n      DatanodeDescriptor delNodeHint, List\u003cStorageType\u003e excessTypes) {\n    BlockPlacementPolicy replicator \u003d placementPolicies.getPolicy(CONTIGUOUS);\n    List\u003cDatanodeStorageInfo\u003e replicasToDelete \u003d replicator\n        .chooseReplicasToDelete(nonExcess, nonExcess, replication, excessTypes,\n            addedNode, delNodeHint);\n    for (DatanodeStorageInfo chosenReplica : replicasToDelete) {\n      processChosenExcessRedundancy(nonExcess, chosenReplica, storedBlock);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "a2a5d7b5bca715835d92816e7b267b59f7270708": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10759. Change fsimage bool isStriped from boolean to an enum. Contributed by Ewan Higgs.\n",
      "commitDate": "18/01/17 1:31 PM",
      "commitName": "a2a5d7b5bca715835d92816e7b267b59f7270708",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "05/12/16 10:54 AM",
      "commitNameOld": "1b5cceaffbdde50a87ede81552dc380832db8e79",
      "commitAuthorOld": "Wei-Chiu Chuang",
      "daysBetweenCommits": 44.11,
      "commitsBetweenForRepo": 218,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,12 @@\n   private void chooseExcessRedundancyContiguous(\n       final Collection\u003cDatanodeStorageInfo\u003e nonExcess, BlockInfo storedBlock,\n       short replication, DatanodeDescriptor addedNode,\n       DatanodeDescriptor delNodeHint, List\u003cStorageType\u003e excessTypes) {\n-    BlockPlacementPolicy replicator \u003d placementPolicies.getPolicy(false);\n+    BlockPlacementPolicy replicator \u003d placementPolicies.getPolicy(CONTIGUOUS);\n     List\u003cDatanodeStorageInfo\u003e replicasToDelete \u003d replicator\n         .chooseReplicasToDelete(nonExcess, nonExcess, replication, excessTypes,\n             addedNode, delNodeHint);\n     for (DatanodeStorageInfo choosenReplica : replicasToDelete) {\n       processChosenExcessRedundancy(nonExcess, choosenReplica, storedBlock);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void chooseExcessRedundancyContiguous(\n      final Collection\u003cDatanodeStorageInfo\u003e nonExcess, BlockInfo storedBlock,\n      short replication, DatanodeDescriptor addedNode,\n      DatanodeDescriptor delNodeHint, List\u003cStorageType\u003e excessTypes) {\n    BlockPlacementPolicy replicator \u003d placementPolicies.getPolicy(CONTIGUOUS);\n    List\u003cDatanodeStorageInfo\u003e replicasToDelete \u003d replicator\n        .chooseReplicasToDelete(nonExcess, nonExcess, replication, excessTypes,\n            addedNode, delNodeHint);\n    for (DatanodeStorageInfo choosenReplica : replicasToDelete) {\n      processChosenExcessRedundancy(nonExcess, choosenReplica, storedBlock);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "5865fe2bf01284993572ea60b3ec3bf8b4492818": {
      "type": "Ymultichange(Yrename,Ybodychange)",
      "commitMessage": "HDFS-9869. Erasure Coding: Rename replication-based names in BlockManager to more generic [part-2]. Contributed by Rakesh R.\n",
      "commitDate": "25/04/16 10:01 PM",
      "commitName": "5865fe2bf01284993572ea60b3ec3bf8b4492818",
      "commitAuthor": "Zhe Zhang",
      "subchanges": [
        {
          "type": "Yrename",
          "commitMessage": "HDFS-9869. Erasure Coding: Rename replication-based names in BlockManager to more generic [part-2]. Contributed by Rakesh R.\n",
          "commitDate": "25/04/16 10:01 PM",
          "commitName": "5865fe2bf01284993572ea60b3ec3bf8b4492818",
          "commitAuthor": "Zhe Zhang",
          "commitDateOld": "17/04/16 6:28 PM",
          "commitNameOld": "67523ffcf491f4f2db5335899c00a174d0caaa9b",
          "commitAuthorOld": "Walter Su",
          "daysBetweenCommits": 8.15,
          "commitsBetweenForRepo": 47,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,12 +1,12 @@\n-  private void chooseExcessReplicasContiguous(\n+  private void chooseExcessRedundancyContiguous(\n       final Collection\u003cDatanodeStorageInfo\u003e nonExcess, BlockInfo storedBlock,\n       short replication, DatanodeDescriptor addedNode,\n       DatanodeDescriptor delNodeHint, List\u003cStorageType\u003e excessTypes) {\n     BlockPlacementPolicy replicator \u003d placementPolicies.getPolicy(false);\n     List\u003cDatanodeStorageInfo\u003e replicasToDelete \u003d replicator\n         .chooseReplicasToDelete(nonExcess, nonExcess, replication, excessTypes,\n             addedNode, delNodeHint);\n     for (DatanodeStorageInfo choosenReplica : replicasToDelete) {\n-      processChosenExcessReplica(nonExcess, choosenReplica, storedBlock);\n+      processChosenExcessRedundancy(nonExcess, choosenReplica, storedBlock);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void chooseExcessRedundancyContiguous(\n      final Collection\u003cDatanodeStorageInfo\u003e nonExcess, BlockInfo storedBlock,\n      short replication, DatanodeDescriptor addedNode,\n      DatanodeDescriptor delNodeHint, List\u003cStorageType\u003e excessTypes) {\n    BlockPlacementPolicy replicator \u003d placementPolicies.getPolicy(false);\n    List\u003cDatanodeStorageInfo\u003e replicasToDelete \u003d replicator\n        .chooseReplicasToDelete(nonExcess, nonExcess, replication, excessTypes,\n            addedNode, delNodeHint);\n    for (DatanodeStorageInfo choosenReplica : replicasToDelete) {\n      processChosenExcessRedundancy(nonExcess, choosenReplica, storedBlock);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
          "extendedDetails": {
            "oldValue": "chooseExcessReplicasContiguous",
            "newValue": "chooseExcessRedundancyContiguous"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-9869. Erasure Coding: Rename replication-based names in BlockManager to more generic [part-2]. Contributed by Rakesh R.\n",
          "commitDate": "25/04/16 10:01 PM",
          "commitName": "5865fe2bf01284993572ea60b3ec3bf8b4492818",
          "commitAuthor": "Zhe Zhang",
          "commitDateOld": "17/04/16 6:28 PM",
          "commitNameOld": "67523ffcf491f4f2db5335899c00a174d0caaa9b",
          "commitAuthorOld": "Walter Su",
          "daysBetweenCommits": 8.15,
          "commitsBetweenForRepo": 47,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,12 +1,12 @@\n-  private void chooseExcessReplicasContiguous(\n+  private void chooseExcessRedundancyContiguous(\n       final Collection\u003cDatanodeStorageInfo\u003e nonExcess, BlockInfo storedBlock,\n       short replication, DatanodeDescriptor addedNode,\n       DatanodeDescriptor delNodeHint, List\u003cStorageType\u003e excessTypes) {\n     BlockPlacementPolicy replicator \u003d placementPolicies.getPolicy(false);\n     List\u003cDatanodeStorageInfo\u003e replicasToDelete \u003d replicator\n         .chooseReplicasToDelete(nonExcess, nonExcess, replication, excessTypes,\n             addedNode, delNodeHint);\n     for (DatanodeStorageInfo choosenReplica : replicasToDelete) {\n-      processChosenExcessReplica(nonExcess, choosenReplica, storedBlock);\n+      processChosenExcessRedundancy(nonExcess, choosenReplica, storedBlock);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void chooseExcessRedundancyContiguous(\n      final Collection\u003cDatanodeStorageInfo\u003e nonExcess, BlockInfo storedBlock,\n      short replication, DatanodeDescriptor addedNode,\n      DatanodeDescriptor delNodeHint, List\u003cStorageType\u003e excessTypes) {\n    BlockPlacementPolicy replicator \u003d placementPolicies.getPolicy(false);\n    List\u003cDatanodeStorageInfo\u003e replicasToDelete \u003d replicator\n        .chooseReplicasToDelete(nonExcess, nonExcess, replication, excessTypes,\n            addedNode, delNodeHint);\n    for (DatanodeStorageInfo choosenReplica : replicasToDelete) {\n      processChosenExcessRedundancy(nonExcess, choosenReplica, storedBlock);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "408f2c807bbaaaa37ce1b69a5dfa9d76ed427d6e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9866. BlockManager#chooseExcessReplicasStriped may weaken rack fault tolerance. Contributed by Jing Zhao.\n",
      "commitDate": "28/02/16 2:54 PM",
      "commitName": "408f2c807bbaaaa37ce1b69a5dfa9d76ed427d6e",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "24/02/16 7:42 PM",
      "commitNameOld": "6979cbfc1f4c28440816b56f5624765872b0be49",
      "commitAuthorOld": "Tsz-Wo Nicholas Sze",
      "daysBetweenCommits": 3.8,
      "commitsBetweenForRepo": 19,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,12 @@\n   private void chooseExcessReplicasContiguous(\n       final Collection\u003cDatanodeStorageInfo\u003e nonExcess, BlockInfo storedBlock,\n       short replication, DatanodeDescriptor addedNode,\n       DatanodeDescriptor delNodeHint, List\u003cStorageType\u003e excessTypes) {\n     BlockPlacementPolicy replicator \u003d placementPolicies.getPolicy(false);\n     List\u003cDatanodeStorageInfo\u003e replicasToDelete \u003d replicator\n-        .chooseReplicasToDelete(nonExcess, replication, excessTypes,\n+        .chooseReplicasToDelete(nonExcess, nonExcess, replication, excessTypes,\n             addedNode, delNodeHint);\n     for (DatanodeStorageInfo choosenReplica : replicasToDelete) {\n       processChosenExcessReplica(nonExcess, choosenReplica, storedBlock);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void chooseExcessReplicasContiguous(\n      final Collection\u003cDatanodeStorageInfo\u003e nonExcess, BlockInfo storedBlock,\n      short replication, DatanodeDescriptor addedNode,\n      DatanodeDescriptor delNodeHint, List\u003cStorageType\u003e excessTypes) {\n    BlockPlacementPolicy replicator \u003d placementPolicies.getPolicy(false);\n    List\u003cDatanodeStorageInfo\u003e replicasToDelete \u003d replicator\n        .chooseReplicasToDelete(nonExcess, nonExcess, replication, excessTypes,\n            addedNode, delNodeHint);\n    for (DatanodeStorageInfo choosenReplica : replicasToDelete) {\n      processChosenExcessReplica(nonExcess, choosenReplica, storedBlock);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "e27c2ae8bafc94f18eb38f5d839dcef5652d424e": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-8647. Abstract BlockManager\u0027s rack policy into BlockPlacementPolicy. (Brahma Reddy Battula via mingma)\n",
      "commitDate": "21/10/15 8:06 AM",
      "commitName": "e27c2ae8bafc94f18eb38f5d839dcef5652d424e",
      "commitAuthor": "Ming Ma",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-8647. Abstract BlockManager\u0027s rack policy into BlockPlacementPolicy. (Brahma Reddy Battula via mingma)\n",
          "commitDate": "21/10/15 8:06 AM",
          "commitName": "e27c2ae8bafc94f18eb38f5d839dcef5652d424e",
          "commitAuthor": "Ming Ma",
          "commitDateOld": "15/10/15 3:07 AM",
          "commitNameOld": "5411dc559d5f73e4153e76fdff94a26869c17a37",
          "commitAuthorOld": "Tsz-Wo Nicholas Sze",
          "daysBetweenCommits": 6.21,
          "commitsBetweenForRepo": 41,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,41 +1,12 @@\n-  private void chooseExcessReplicasContiguous(BlockCollection bc,\n-      final Collection\u003cDatanodeStorageInfo\u003e nonExcess,\n-      BlockInfo storedBlock, short replication,\n-      DatanodeDescriptor addedNode,\n-      DatanodeDescriptor delNodeHint,\n-      List\u003cStorageType\u003e excessTypes) {\n+  private void chooseExcessReplicasContiguous(\n+      final Collection\u003cDatanodeStorageInfo\u003e nonExcess, BlockInfo storedBlock,\n+      short replication, DatanodeDescriptor addedNode,\n+      DatanodeDescriptor delNodeHint, List\u003cStorageType\u003e excessTypes) {\n     BlockPlacementPolicy replicator \u003d placementPolicies.getPolicy(false);\n-    final Map\u003cString, List\u003cDatanodeStorageInfo\u003e\u003e rackMap \u003d new HashMap\u003c\u003e();\n-    final List\u003cDatanodeStorageInfo\u003e moreThanOne \u003d new ArrayList\u003c\u003e();\n-    final List\u003cDatanodeStorageInfo\u003e exactlyOne \u003d new ArrayList\u003c\u003e();\n-    \n-    // split nodes into two sets\n-    // moreThanOne contains nodes on rack with more than one replica\n-    // exactlyOne contains the remaining nodes\n-    replicator.splitNodesWithRack(nonExcess, rackMap, moreThanOne, exactlyOne);\n-    \n-    // pick one node to delete that favors the delete hint\n-    // otherwise pick one with least space from priSet if it is not empty\n-    // otherwise one node with least space from remains\n-    boolean firstOne \u003d true;\n-    final DatanodeStorageInfo delNodeHintStorage\n-        \u003d DatanodeStorageInfo.getDatanodeStorageInfo(nonExcess, delNodeHint);\n-    final DatanodeStorageInfo addedNodeStorage\n-        \u003d DatanodeStorageInfo.getDatanodeStorageInfo(nonExcess, addedNode);\n-    while (nonExcess.size() - replication \u003e 0) {\n-      final DatanodeStorageInfo cur;\n-      if (useDelHint(firstOne, delNodeHintStorage, addedNodeStorage,\n-          moreThanOne, excessTypes)) {\n-        cur \u003d delNodeHintStorage;\n-      } else { // regular excessive replica removal\n-        cur \u003d replicator.chooseReplicaToDelete(bc, storedBlock, replication,\n-            moreThanOne, exactlyOne, excessTypes);\n-      }\n-      firstOne \u003d false;\n-      // adjust rackmap, moreThanOne, and exactlyOne\n-      replicator.adjustSetsWithChosenReplica(rackMap, moreThanOne,\n-          exactlyOne, cur);\n-\n-      processChosenExcessReplica(nonExcess, cur, storedBlock);\n+    List\u003cDatanodeStorageInfo\u003e replicasToDelete \u003d replicator\n+        .chooseReplicasToDelete(nonExcess, replication, excessTypes,\n+            addedNode, delNodeHint);\n+    for (DatanodeStorageInfo choosenReplica : replicasToDelete) {\n+      processChosenExcessReplica(nonExcess, choosenReplica, storedBlock);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void chooseExcessReplicasContiguous(\n      final Collection\u003cDatanodeStorageInfo\u003e nonExcess, BlockInfo storedBlock,\n      short replication, DatanodeDescriptor addedNode,\n      DatanodeDescriptor delNodeHint, List\u003cStorageType\u003e excessTypes) {\n    BlockPlacementPolicy replicator \u003d placementPolicies.getPolicy(false);\n    List\u003cDatanodeStorageInfo\u003e replicasToDelete \u003d replicator\n        .chooseReplicasToDelete(nonExcess, replication, excessTypes,\n            addedNode, delNodeHint);\n    for (DatanodeStorageInfo choosenReplica : replicasToDelete) {\n      processChosenExcessReplica(nonExcess, choosenReplica, storedBlock);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
          "extendedDetails": {
            "oldValue": "[bc-BlockCollection, nonExcess-Collection\u003cDatanodeStorageInfo\u003e(modifiers-final), storedBlock-BlockInfo, replication-short, addedNode-DatanodeDescriptor, delNodeHint-DatanodeDescriptor, excessTypes-List\u003cStorageType\u003e]",
            "newValue": "[nonExcess-Collection\u003cDatanodeStorageInfo\u003e(modifiers-final), storedBlock-BlockInfo, replication-short, addedNode-DatanodeDescriptor, delNodeHint-DatanodeDescriptor, excessTypes-List\u003cStorageType\u003e]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-8647. Abstract BlockManager\u0027s rack policy into BlockPlacementPolicy. (Brahma Reddy Battula via mingma)\n",
          "commitDate": "21/10/15 8:06 AM",
          "commitName": "e27c2ae8bafc94f18eb38f5d839dcef5652d424e",
          "commitAuthor": "Ming Ma",
          "commitDateOld": "15/10/15 3:07 AM",
          "commitNameOld": "5411dc559d5f73e4153e76fdff94a26869c17a37",
          "commitAuthorOld": "Tsz-Wo Nicholas Sze",
          "daysBetweenCommits": 6.21,
          "commitsBetweenForRepo": 41,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,41 +1,12 @@\n-  private void chooseExcessReplicasContiguous(BlockCollection bc,\n-      final Collection\u003cDatanodeStorageInfo\u003e nonExcess,\n-      BlockInfo storedBlock, short replication,\n-      DatanodeDescriptor addedNode,\n-      DatanodeDescriptor delNodeHint,\n-      List\u003cStorageType\u003e excessTypes) {\n+  private void chooseExcessReplicasContiguous(\n+      final Collection\u003cDatanodeStorageInfo\u003e nonExcess, BlockInfo storedBlock,\n+      short replication, DatanodeDescriptor addedNode,\n+      DatanodeDescriptor delNodeHint, List\u003cStorageType\u003e excessTypes) {\n     BlockPlacementPolicy replicator \u003d placementPolicies.getPolicy(false);\n-    final Map\u003cString, List\u003cDatanodeStorageInfo\u003e\u003e rackMap \u003d new HashMap\u003c\u003e();\n-    final List\u003cDatanodeStorageInfo\u003e moreThanOne \u003d new ArrayList\u003c\u003e();\n-    final List\u003cDatanodeStorageInfo\u003e exactlyOne \u003d new ArrayList\u003c\u003e();\n-    \n-    // split nodes into two sets\n-    // moreThanOne contains nodes on rack with more than one replica\n-    // exactlyOne contains the remaining nodes\n-    replicator.splitNodesWithRack(nonExcess, rackMap, moreThanOne, exactlyOne);\n-    \n-    // pick one node to delete that favors the delete hint\n-    // otherwise pick one with least space from priSet if it is not empty\n-    // otherwise one node with least space from remains\n-    boolean firstOne \u003d true;\n-    final DatanodeStorageInfo delNodeHintStorage\n-        \u003d DatanodeStorageInfo.getDatanodeStorageInfo(nonExcess, delNodeHint);\n-    final DatanodeStorageInfo addedNodeStorage\n-        \u003d DatanodeStorageInfo.getDatanodeStorageInfo(nonExcess, addedNode);\n-    while (nonExcess.size() - replication \u003e 0) {\n-      final DatanodeStorageInfo cur;\n-      if (useDelHint(firstOne, delNodeHintStorage, addedNodeStorage,\n-          moreThanOne, excessTypes)) {\n-        cur \u003d delNodeHintStorage;\n-      } else { // regular excessive replica removal\n-        cur \u003d replicator.chooseReplicaToDelete(bc, storedBlock, replication,\n-            moreThanOne, exactlyOne, excessTypes);\n-      }\n-      firstOne \u003d false;\n-      // adjust rackmap, moreThanOne, and exactlyOne\n-      replicator.adjustSetsWithChosenReplica(rackMap, moreThanOne,\n-          exactlyOne, cur);\n-\n-      processChosenExcessReplica(nonExcess, cur, storedBlock);\n+    List\u003cDatanodeStorageInfo\u003e replicasToDelete \u003d replicator\n+        .chooseReplicasToDelete(nonExcess, replication, excessTypes,\n+            addedNode, delNodeHint);\n+    for (DatanodeStorageInfo choosenReplica : replicasToDelete) {\n+      processChosenExcessReplica(nonExcess, choosenReplica, storedBlock);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void chooseExcessReplicasContiguous(\n      final Collection\u003cDatanodeStorageInfo\u003e nonExcess, BlockInfo storedBlock,\n      short replication, DatanodeDescriptor addedNode,\n      DatanodeDescriptor delNodeHint, List\u003cStorageType\u003e excessTypes) {\n    BlockPlacementPolicy replicator \u003d placementPolicies.getPolicy(false);\n    List\u003cDatanodeStorageInfo\u003e replicasToDelete \u003d replicator\n        .chooseReplicasToDelete(nonExcess, replication, excessTypes,\n            addedNode, delNodeHint);\n    for (DatanodeStorageInfo choosenReplica : replicasToDelete) {\n      processChosenExcessReplica(nonExcess, choosenReplica, storedBlock);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
          "extendedDetails": {}
        }
      ]
    }
  }
}