{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DefaultAMSProcessor.java",
  "functionName": "handleNodeUpdates",
  "functionId": "handleNodeUpdates___app-RMApp__allocateResponse-AllocateResponse",
  "sourceFilePath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/DefaultAMSProcessor.java",
  "functionStartLine": 376,
  "functionEndLine": 404,
  "numCommitsSeen": 21,
  "timeTaken": 1339,
  "changeHistory": [
    "b46ca7e73b8bac3fdbff0b13afe009308078acf2",
    "5496a34c0cb2b1a83cfa6b0aba5a77b05ff2d8f0"
  ],
  "changeHistoryShort": {
    "b46ca7e73b8bac3fdbff0b13afe009308078acf2": "Ybodychange",
    "5496a34c0cb2b1a83cfa6b0aba5a77b05ff2d8f0": "Yintroduced"
  },
  "changeHistoryDetails": {
    "b46ca7e73b8bac3fdbff0b13afe009308078acf2": {
      "type": "Ybodychange",
      "commitMessage": "YARN-6483. Add nodes transitioning to DECOMMISSIONING state to the list of updated nodes returned to the AM. (Juan Rodriguez Hortala via asuresh)\n",
      "commitDate": "22/11/17 7:18 PM",
      "commitName": "b46ca7e73b8bac3fdbff0b13afe009308078acf2",
      "commitAuthor": "Arun Suresh",
      "commitDateOld": "26/10/17 8:15 PM",
      "commitNameOld": "36e158ae98ef8b72a7a9f63102b714e025cafcc5",
      "commitAuthorOld": "Wangda Tan",
      "daysBetweenCommits": 27.0,
      "commitsBetweenForRepo": 258,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,26 +1,29 @@\n   private void handleNodeUpdates(RMApp app, AllocateResponse allocateResponse) {\n-    List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003c\u003e();\n+    Map\u003cRMNode, NodeUpdateType\u003e updatedNodes \u003d new HashMap\u003c\u003e();\n     if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n       List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003c\u003e();\n-      for(RMNode rmNode: updatedNodes) {\n+      for(Map.Entry\u003cRMNode, NodeUpdateType\u003e rmNodeEntry :\n+          updatedNodes.entrySet()) {\n+        RMNode rmNode \u003d rmNodeEntry.getKey();\n         SchedulerNodeReport schedulerNodeReport \u003d\n             getScheduler().getNodeReport(rmNode.getNodeID());\n         Resource used \u003d BuilderUtils.newResource(0, 0);\n         int numContainers \u003d 0;\n         if (schedulerNodeReport !\u003d null) {\n           used \u003d schedulerNodeReport.getUsedResource();\n           numContainers \u003d schedulerNodeReport.getNumContainers();\n         }\n         NodeId nodeId \u003d rmNode.getNodeID();\n         NodeReport report \u003d\n             BuilderUtils.newNodeReport(nodeId, rmNode.getState(),\n                 rmNode.getHttpAddress(), rmNode.getRackName(), used,\n                 rmNode.getTotalCapability(), numContainers,\n                 rmNode.getHealthReport(), rmNode.getLastHealthReportTime(),\n-                rmNode.getNodeLabels());\n+                rmNode.getNodeLabels(), rmNode.getDecommissioningTimeout(),\n+                rmNodeEntry.getValue());\n \n         updatedNodeReports.add(report);\n       }\n       allocateResponse.setUpdatedNodes(updatedNodeReports);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void handleNodeUpdates(RMApp app, AllocateResponse allocateResponse) {\n    Map\u003cRMNode, NodeUpdateType\u003e updatedNodes \u003d new HashMap\u003c\u003e();\n    if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n      List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003c\u003e();\n      for(Map.Entry\u003cRMNode, NodeUpdateType\u003e rmNodeEntry :\n          updatedNodes.entrySet()) {\n        RMNode rmNode \u003d rmNodeEntry.getKey();\n        SchedulerNodeReport schedulerNodeReport \u003d\n            getScheduler().getNodeReport(rmNode.getNodeID());\n        Resource used \u003d BuilderUtils.newResource(0, 0);\n        int numContainers \u003d 0;\n        if (schedulerNodeReport !\u003d null) {\n          used \u003d schedulerNodeReport.getUsedResource();\n          numContainers \u003d schedulerNodeReport.getNumContainers();\n        }\n        NodeId nodeId \u003d rmNode.getNodeID();\n        NodeReport report \u003d\n            BuilderUtils.newNodeReport(nodeId, rmNode.getState(),\n                rmNode.getHttpAddress(), rmNode.getRackName(), used,\n                rmNode.getTotalCapability(), numContainers,\n                rmNode.getHealthReport(), rmNode.getLastHealthReportTime(),\n                rmNode.getNodeLabels(), rmNode.getDecommissioningTimeout(),\n                rmNodeEntry.getValue());\n\n        updatedNodeReports.add(report);\n      }\n      allocateResponse.setUpdatedNodes(updatedNodeReports);\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/DefaultAMSProcessor.java",
      "extendedDetails": {}
    },
    "5496a34c0cb2b1a83cfa6b0aba5a77b05ff2d8f0": {
      "type": "Yintroduced",
      "commitMessage": "YARN-6776. Refactor ApplicaitonMasterService to move actual processing logic to a separate class. (asuresh)\n",
      "commitDate": "10/07/17 2:34 PM",
      "commitName": "5496a34c0cb2b1a83cfa6b0aba5a77b05ff2d8f0",
      "commitAuthor": "Arun Suresh",
      "diff": "@@ -0,0 +1,26 @@\n+  private void handleNodeUpdates(RMApp app, AllocateResponse allocateResponse) {\n+    List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003c\u003e();\n+    if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n+      List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003c\u003e();\n+      for(RMNode rmNode: updatedNodes) {\n+        SchedulerNodeReport schedulerNodeReport \u003d\n+            getScheduler().getNodeReport(rmNode.getNodeID());\n+        Resource used \u003d BuilderUtils.newResource(0, 0);\n+        int numContainers \u003d 0;\n+        if (schedulerNodeReport !\u003d null) {\n+          used \u003d schedulerNodeReport.getUsedResource();\n+          numContainers \u003d schedulerNodeReport.getNumContainers();\n+        }\n+        NodeId nodeId \u003d rmNode.getNodeID();\n+        NodeReport report \u003d\n+            BuilderUtils.newNodeReport(nodeId, rmNode.getState(),\n+                rmNode.getHttpAddress(), rmNode.getRackName(), used,\n+                rmNode.getTotalCapability(), numContainers,\n+                rmNode.getHealthReport(), rmNode.getLastHealthReportTime(),\n+                rmNode.getNodeLabels());\n+\n+        updatedNodeReports.add(report);\n+      }\n+      allocateResponse.setUpdatedNodes(updatedNodeReports);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void handleNodeUpdates(RMApp app, AllocateResponse allocateResponse) {\n    List\u003cRMNode\u003e updatedNodes \u003d new ArrayList\u003c\u003e();\n    if(app.pullRMNodeUpdates(updatedNodes) \u003e 0) {\n      List\u003cNodeReport\u003e updatedNodeReports \u003d new ArrayList\u003c\u003e();\n      for(RMNode rmNode: updatedNodes) {\n        SchedulerNodeReport schedulerNodeReport \u003d\n            getScheduler().getNodeReport(rmNode.getNodeID());\n        Resource used \u003d BuilderUtils.newResource(0, 0);\n        int numContainers \u003d 0;\n        if (schedulerNodeReport !\u003d null) {\n          used \u003d schedulerNodeReport.getUsedResource();\n          numContainers \u003d schedulerNodeReport.getNumContainers();\n        }\n        NodeId nodeId \u003d rmNode.getNodeID();\n        NodeReport report \u003d\n            BuilderUtils.newNodeReport(nodeId, rmNode.getState(),\n                rmNode.getHttpAddress(), rmNode.getRackName(), used,\n                rmNode.getTotalCapability(), numContainers,\n                rmNode.getHealthReport(), rmNode.getLastHealthReportTime(),\n                rmNode.getNodeLabels());\n\n        updatedNodeReports.add(report);\n      }\n      allocateResponse.setUpdatedNodes(updatedNodeReports);\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/DefaultAMSProcessor.java"
    }
  }
}