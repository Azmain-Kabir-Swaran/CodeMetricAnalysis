{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSDirTruncateOp.java",
  "functionName": "truncate",
  "functionId": "truncate___fsn-FSNamesystem(modifiers-final)__srcArg-String(modifiers-final)__newLength-long(modifiers-final)__clientName-String(modifiers-final)__clientMachine-String(modifiers-final)__mtime-long(modifiers-final)__toRemoveBlocks-BlocksMapUpdateInfo(modifiers-final)__pc-FSPermissionChecker(modifiers-final)",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirTruncateOp.java",
  "functionStartLine": 68,
  "functionEndLine": 152,
  "numCommitsSeen": 1080,
  "timeTaken": 16213,
  "changeHistory": [
    "8d898ab25f1c2032a07c9bbd96ba3d0c4eb5be87",
    "1b5cceaffbdde50a87ede81552dc380832db8e79",
    "b9522e86a55564c2ccb5ca3f1ca871965cbe74de",
    "9d175853b0170683ad5f21d9bcdeaac49fe89e04",
    "869393643de23dcb010cc33091c8eb398de0fd6c",
    "03dea65e0b17ca2f9460bb6110f6ab3a321b8bf2",
    "164cbe643988f878f0f4100a4de51783e5b6738e",
    "e535e0f05b5fbd087c93238deb888cc985254b4c",
    "f4c523b69ba55b1fd35e8995c3011a9f546ac835",
    "31f117138a00794de4951ee8433e304d72b04094",
    "d3797f9f3cf502b7bfee3b64c641807b276c6faf",
    "c17439c2ddd921b63b1635e6f1cba634b8da8557",
    "4928f5473394981829e5ffd4b16ea0801baf5c45",
    "d368d3647a858644b9fcd3be33d9fea2a6962f69",
    "f446669afb5c3d31a00c65449f27088b39e11ae3",
    "8f7d4bb09f760780dd193c97796ebf4d22cfd2d7",
    "c09c65b2125908855a5f1d0047bc164ea4bea04d",
    "5a6c084f074990a1f412475b147fd4f040b57d57",
    "08ac06283a3e9bf0d49d873823aabd419b08e41f",
    "7e9358feb326d48b8c4f00249e7af5023cebd2e2"
  ],
  "changeHistoryShort": {
    "8d898ab25f1c2032a07c9bbd96ba3d0c4eb5be87": "Ybodychange",
    "1b5cceaffbdde50a87ede81552dc380832db8e79": "Ybodychange",
    "b9522e86a55564c2ccb5ca3f1ca871965cbe74de": "Ybodychange",
    "9d175853b0170683ad5f21d9bcdeaac49fe89e04": "Ybodychange",
    "869393643de23dcb010cc33091c8eb398de0fd6c": "Ybodychange",
    "03dea65e0b17ca2f9460bb6110f6ab3a321b8bf2": "Ybodychange",
    "164cbe643988f878f0f4100a4de51783e5b6738e": "Ybodychange",
    "e535e0f05b5fbd087c93238deb888cc985254b4c": "Ybodychange",
    "f4c523b69ba55b1fd35e8995c3011a9f546ac835": "Ybodychange",
    "31f117138a00794de4951ee8433e304d72b04094": "Ybodychange",
    "d3797f9f3cf502b7bfee3b64c641807b276c6faf": "Ymultichange(Ymovefromfile,Yreturntypechange,Ymodifierchange,Ybodychange,Yparametermetachange,Yrename,Yparameterchange)",
    "c17439c2ddd921b63b1635e6f1cba634b8da8557": "Ybodychange",
    "4928f5473394981829e5ffd4b16ea0801baf5c45": "Ybodychange",
    "d368d3647a858644b9fcd3be33d9fea2a6962f69": "Ybodychange",
    "f446669afb5c3d31a00c65449f27088b39e11ae3": "Ybodychange",
    "8f7d4bb09f760780dd193c97796ebf4d22cfd2d7": "Ybodychange",
    "c09c65b2125908855a5f1d0047bc164ea4bea04d": "Ybodychange",
    "5a6c084f074990a1f412475b147fd4f040b57d57": "Ymultichange(Yparameterchange,Ybodychange)",
    "08ac06283a3e9bf0d49d873823aabd419b08e41f": "Ybodychange",
    "7e9358feb326d48b8c4f00249e7af5023cebd2e2": "Yintroduced"
  },
  "changeHistoryDetails": {
    "8d898ab25f1c2032a07c9bbd96ba3d0c4eb5be87": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12884. BlockUnderConstructionFeature.truncateBlock should be of type BlockInfo. Contributed by chencan.",
      "commitDate": "21/03/18 4:46 PM",
      "commitName": "8d898ab25f1c2032a07c9bbd96ba3d0c4eb5be87",
      "commitAuthor": "Konstantin V Shvachko",
      "commitDateOld": "25/05/17 3:17 PM",
      "commitNameOld": "2b5ad48762587abbcd8bdb50d0ae98f8080d926c",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 300.06,
      "commitsBetweenForRepo": 2063,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,85 +1,85 @@\n   static TruncateResult truncate(final FSNamesystem fsn, final String srcArg,\n       final long newLength, final String clientName,\n       final String clientMachine, final long mtime,\n       final BlocksMapUpdateInfo toRemoveBlocks, final FSPermissionChecker pc)\n       throws IOException, UnresolvedLinkException {\n     assert fsn.hasWriteLock();\n \n     FSDirectory fsd \u003d fsn.getFSDirectory();\n     final String src;\n     final INodesInPath iip;\n     final boolean onBlockBoundary;\n     Block truncateBlock \u003d null;\n     fsd.writeLock();\n     try {\n       iip \u003d fsd.resolvePath(pc, srcArg, DirOp.WRITE);\n       src \u003d iip.getPath();\n       if (fsd.isPermissionEnabled()) {\n         fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n       }\n       INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n \n       // not support truncating file with striped blocks\n       if (file.isStriped()) {\n         throw new UnsupportedOperationException(\n             \"Cannot truncate file with striped block \" + src);\n       }\n \n       final BlockStoragePolicy lpPolicy \u003d fsd.getBlockManager()\n           .getStoragePolicy(\"LAZY_PERSIST\");\n \n       if (lpPolicy !\u003d null \u0026\u0026 lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n         throw new UnsupportedOperationException(\n             \"Cannot truncate lazy persist file \" + src);\n       }\n \n       // Check if the file is already being truncated with the same length\n       final BlockInfo last \u003d file.getLastBlock();\n       if (last !\u003d null \u0026\u0026 last.getBlockUCState()\n           \u003d\u003d BlockUCState.UNDER_RECOVERY) {\n-        final Block truncatedBlock \u003d last.getUnderConstructionFeature()\n+        final BlockInfo truncatedBlock \u003d last.getUnderConstructionFeature()\n             .getTruncateBlock();\n         if (truncatedBlock !\u003d null) {\n           final long truncateLength \u003d file.computeFileSize(false, false)\n               + truncatedBlock.getNumBytes();\n           if (newLength \u003d\u003d truncateLength) {\n             return new TruncateResult(false, fsd.getAuditFileInfo(iip));\n           }\n         }\n       }\n \n       // Opening an existing file for truncate. May need lease recovery.\n       fsn.recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE, iip, src,\n           clientName, clientMachine, false);\n       // Truncate length check.\n       long oldLength \u003d file.computeFileSize();\n       if (oldLength \u003d\u003d newLength) {\n         return new TruncateResult(true, fsd.getAuditFileInfo(iip));\n       }\n       if (oldLength \u003c newLength) {\n         throw new HadoopIllegalArgumentException(\n             \"Cannot truncate to a larger file size. Current size: \" + oldLength\n                 + \", truncate size: \" + newLength + \".\");\n       }\n       // Perform INodeFile truncation.\n       final QuotaCounts delta \u003d new QuotaCounts.Builder().build();\n       onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n           toRemoveBlocks, mtime, delta);\n       if (!onBlockBoundary) {\n         // Open file for write, but don\u0027t log into edits\n         long lastBlockDelta \u003d file.computeFileSize() - newLength;\n         assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n         truncateBlock \u003d prepareFileForTruncate(fsn, iip, clientName,\n             clientMachine, lastBlockDelta, null);\n       }\n \n       // update the quota: use the preferred block size for UC block\n       fsd.updateCountNoQuotaCheck(iip, iip.length() - 1, delta);\n     } finally {\n       fsd.writeUnlock();\n     }\n \n     fsn.getEditLog().logTruncate(src, clientName, clientMachine, newLength,\n         mtime, truncateBlock);\n     return new TruncateResult(onBlockBoundary, fsd.getAuditFileInfo(iip));\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static TruncateResult truncate(final FSNamesystem fsn, final String srcArg,\n      final long newLength, final String clientName,\n      final String clientMachine, final long mtime,\n      final BlocksMapUpdateInfo toRemoveBlocks, final FSPermissionChecker pc)\n      throws IOException, UnresolvedLinkException {\n    assert fsn.hasWriteLock();\n\n    FSDirectory fsd \u003d fsn.getFSDirectory();\n    final String src;\n    final INodesInPath iip;\n    final boolean onBlockBoundary;\n    Block truncateBlock \u003d null;\n    fsd.writeLock();\n    try {\n      iip \u003d fsd.resolvePath(pc, srcArg, DirOp.WRITE);\n      src \u003d iip.getPath();\n      if (fsd.isPermissionEnabled()) {\n        fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n      }\n      INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n\n      // not support truncating file with striped blocks\n      if (file.isStriped()) {\n        throw new UnsupportedOperationException(\n            \"Cannot truncate file with striped block \" + src);\n      }\n\n      final BlockStoragePolicy lpPolicy \u003d fsd.getBlockManager()\n          .getStoragePolicy(\"LAZY_PERSIST\");\n\n      if (lpPolicy !\u003d null \u0026\u0026 lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n        throw new UnsupportedOperationException(\n            \"Cannot truncate lazy persist file \" + src);\n      }\n\n      // Check if the file is already being truncated with the same length\n      final BlockInfo last \u003d file.getLastBlock();\n      if (last !\u003d null \u0026\u0026 last.getBlockUCState()\n          \u003d\u003d BlockUCState.UNDER_RECOVERY) {\n        final BlockInfo truncatedBlock \u003d last.getUnderConstructionFeature()\n            .getTruncateBlock();\n        if (truncatedBlock !\u003d null) {\n          final long truncateLength \u003d file.computeFileSize(false, false)\n              + truncatedBlock.getNumBytes();\n          if (newLength \u003d\u003d truncateLength) {\n            return new TruncateResult(false, fsd.getAuditFileInfo(iip));\n          }\n        }\n      }\n\n      // Opening an existing file for truncate. May need lease recovery.\n      fsn.recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE, iip, src,\n          clientName, clientMachine, false);\n      // Truncate length check.\n      long oldLength \u003d file.computeFileSize();\n      if (oldLength \u003d\u003d newLength) {\n        return new TruncateResult(true, fsd.getAuditFileInfo(iip));\n      }\n      if (oldLength \u003c newLength) {\n        throw new HadoopIllegalArgumentException(\n            \"Cannot truncate to a larger file size. Current size: \" + oldLength\n                + \", truncate size: \" + newLength + \".\");\n      }\n      // Perform INodeFile truncation.\n      final QuotaCounts delta \u003d new QuotaCounts.Builder().build();\n      onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n          toRemoveBlocks, mtime, delta);\n      if (!onBlockBoundary) {\n        // Open file for write, but don\u0027t log into edits\n        long lastBlockDelta \u003d file.computeFileSize() - newLength;\n        assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n        truncateBlock \u003d prepareFileForTruncate(fsn, iip, clientName,\n            clientMachine, lastBlockDelta, null);\n      }\n\n      // update the quota: use the preferred block size for UC block\n      fsd.updateCountNoQuotaCheck(iip, iip.length() - 1, delta);\n    } finally {\n      fsd.writeUnlock();\n    }\n\n    fsn.getEditLog().logTruncate(src, clientName, clientMachine, newLength,\n        mtime, truncateBlock);\n    return new TruncateResult(onBlockBoundary, fsd.getAuditFileInfo(iip));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirTruncateOp.java",
      "extendedDetails": {}
    },
    "1b5cceaffbdde50a87ede81552dc380832db8e79": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-11201. Spelling errors in the logging, help, assertions and exception messages. Contributed by Grant Sohn.\"\n\nThis reverts commit b9522e86a55564c2ccb5ca3f1ca871965cbe74de.\n",
      "commitDate": "05/12/16 10:54 AM",
      "commitName": "1b5cceaffbdde50a87ede81552dc380832db8e79",
      "commitAuthor": "Wei-Chiu Chuang",
      "commitDateOld": "05/12/16 10:48 AM",
      "commitNameOld": "b9522e86a55564c2ccb5ca3f1ca871965cbe74de",
      "commitAuthorOld": "Wei-Chiu Chuang",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,85 +1,85 @@\n   static TruncateResult truncate(final FSNamesystem fsn, final String srcArg,\n       final long newLength, final String clientName,\n       final String clientMachine, final long mtime,\n       final BlocksMapUpdateInfo toRemoveBlocks, final FSPermissionChecker pc)\n       throws IOException, UnresolvedLinkException {\n     assert fsn.hasWriteLock();\n \n     FSDirectory fsd \u003d fsn.getFSDirectory();\n     final String src;\n     final INodesInPath iip;\n     final boolean onBlockBoundary;\n     Block truncateBlock \u003d null;\n     fsd.writeLock();\n     try {\n       iip \u003d fsd.resolvePath(pc, srcArg, DirOp.WRITE);\n       src \u003d iip.getPath();\n       if (fsd.isPermissionEnabled()) {\n         fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n       }\n       INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n \n       // not support truncating file with striped blocks\n       if (file.isStriped()) {\n         throw new UnsupportedOperationException(\n             \"Cannot truncate file with striped block \" + src);\n       }\n \n       final BlockStoragePolicy lpPolicy \u003d fsd.getBlockManager()\n           .getStoragePolicy(\"LAZY_PERSIST\");\n \n       if (lpPolicy !\u003d null \u0026\u0026 lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n         throw new UnsupportedOperationException(\n             \"Cannot truncate lazy persist file \" + src);\n       }\n \n       // Check if the file is already being truncated with the same length\n       final BlockInfo last \u003d file.getLastBlock();\n       if (last !\u003d null \u0026\u0026 last.getBlockUCState()\n           \u003d\u003d BlockUCState.UNDER_RECOVERY) {\n         final Block truncatedBlock \u003d last.getUnderConstructionFeature()\n             .getTruncateBlock();\n         if (truncatedBlock !\u003d null) {\n           final long truncateLength \u003d file.computeFileSize(false, false)\n               + truncatedBlock.getNumBytes();\n           if (newLength \u003d\u003d truncateLength) {\n             return new TruncateResult(false, fsd.getAuditFileInfo(iip));\n           }\n         }\n       }\n \n       // Opening an existing file for truncate. May need lease recovery.\n       fsn.recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE, iip, src,\n           clientName, clientMachine, false);\n       // Truncate length check.\n       long oldLength \u003d file.computeFileSize();\n       if (oldLength \u003d\u003d newLength) {\n         return new TruncateResult(true, fsd.getAuditFileInfo(iip));\n       }\n       if (oldLength \u003c newLength) {\n         throw new HadoopIllegalArgumentException(\n             \"Cannot truncate to a larger file size. Current size: \" + oldLength\n                 + \", truncate size: \" + newLength + \".\");\n       }\n       // Perform INodeFile truncation.\n       final QuotaCounts delta \u003d new QuotaCounts.Builder().build();\n       onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n           toRemoveBlocks, mtime, delta);\n       if (!onBlockBoundary) {\n         // Open file for write, but don\u0027t log into edits\n         long lastBlockDelta \u003d file.computeFileSize() - newLength;\n-        assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block boundary\";\n+        assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n         truncateBlock \u003d prepareFileForTruncate(fsn, iip, clientName,\n             clientMachine, lastBlockDelta, null);\n       }\n \n       // update the quota: use the preferred block size for UC block\n       fsd.updateCountNoQuotaCheck(iip, iip.length() - 1, delta);\n     } finally {\n       fsd.writeUnlock();\n     }\n \n     fsn.getEditLog().logTruncate(src, clientName, clientMachine, newLength,\n         mtime, truncateBlock);\n     return new TruncateResult(onBlockBoundary, fsd.getAuditFileInfo(iip));\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static TruncateResult truncate(final FSNamesystem fsn, final String srcArg,\n      final long newLength, final String clientName,\n      final String clientMachine, final long mtime,\n      final BlocksMapUpdateInfo toRemoveBlocks, final FSPermissionChecker pc)\n      throws IOException, UnresolvedLinkException {\n    assert fsn.hasWriteLock();\n\n    FSDirectory fsd \u003d fsn.getFSDirectory();\n    final String src;\n    final INodesInPath iip;\n    final boolean onBlockBoundary;\n    Block truncateBlock \u003d null;\n    fsd.writeLock();\n    try {\n      iip \u003d fsd.resolvePath(pc, srcArg, DirOp.WRITE);\n      src \u003d iip.getPath();\n      if (fsd.isPermissionEnabled()) {\n        fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n      }\n      INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n\n      // not support truncating file with striped blocks\n      if (file.isStriped()) {\n        throw new UnsupportedOperationException(\n            \"Cannot truncate file with striped block \" + src);\n      }\n\n      final BlockStoragePolicy lpPolicy \u003d fsd.getBlockManager()\n          .getStoragePolicy(\"LAZY_PERSIST\");\n\n      if (lpPolicy !\u003d null \u0026\u0026 lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n        throw new UnsupportedOperationException(\n            \"Cannot truncate lazy persist file \" + src);\n      }\n\n      // Check if the file is already being truncated with the same length\n      final BlockInfo last \u003d file.getLastBlock();\n      if (last !\u003d null \u0026\u0026 last.getBlockUCState()\n          \u003d\u003d BlockUCState.UNDER_RECOVERY) {\n        final Block truncatedBlock \u003d last.getUnderConstructionFeature()\n            .getTruncateBlock();\n        if (truncatedBlock !\u003d null) {\n          final long truncateLength \u003d file.computeFileSize(false, false)\n              + truncatedBlock.getNumBytes();\n          if (newLength \u003d\u003d truncateLength) {\n            return new TruncateResult(false, fsd.getAuditFileInfo(iip));\n          }\n        }\n      }\n\n      // Opening an existing file for truncate. May need lease recovery.\n      fsn.recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE, iip, src,\n          clientName, clientMachine, false);\n      // Truncate length check.\n      long oldLength \u003d file.computeFileSize();\n      if (oldLength \u003d\u003d newLength) {\n        return new TruncateResult(true, fsd.getAuditFileInfo(iip));\n      }\n      if (oldLength \u003c newLength) {\n        throw new HadoopIllegalArgumentException(\n            \"Cannot truncate to a larger file size. Current size: \" + oldLength\n                + \", truncate size: \" + newLength + \".\");\n      }\n      // Perform INodeFile truncation.\n      final QuotaCounts delta \u003d new QuotaCounts.Builder().build();\n      onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n          toRemoveBlocks, mtime, delta);\n      if (!onBlockBoundary) {\n        // Open file for write, but don\u0027t log into edits\n        long lastBlockDelta \u003d file.computeFileSize() - newLength;\n        assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n        truncateBlock \u003d prepareFileForTruncate(fsn, iip, clientName,\n            clientMachine, lastBlockDelta, null);\n      }\n\n      // update the quota: use the preferred block size for UC block\n      fsd.updateCountNoQuotaCheck(iip, iip.length() - 1, delta);\n    } finally {\n      fsd.writeUnlock();\n    }\n\n    fsn.getEditLog().logTruncate(src, clientName, clientMachine, newLength,\n        mtime, truncateBlock);\n    return new TruncateResult(onBlockBoundary, fsd.getAuditFileInfo(iip));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirTruncateOp.java",
      "extendedDetails": {}
    },
    "b9522e86a55564c2ccb5ca3f1ca871965cbe74de": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11201. Spelling errors in the logging, help, assertions and exception messages. Contributed by Grant Sohn.\n",
      "commitDate": "05/12/16 10:48 AM",
      "commitName": "b9522e86a55564c2ccb5ca3f1ca871965cbe74de",
      "commitAuthor": "Wei-Chiu Chuang",
      "commitDateOld": "24/10/16 3:14 PM",
      "commitNameOld": "9d175853b0170683ad5f21d9bcdeaac49fe89e04",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 41.86,
      "commitsBetweenForRepo": 349,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,85 +1,85 @@\n   static TruncateResult truncate(final FSNamesystem fsn, final String srcArg,\n       final long newLength, final String clientName,\n       final String clientMachine, final long mtime,\n       final BlocksMapUpdateInfo toRemoveBlocks, final FSPermissionChecker pc)\n       throws IOException, UnresolvedLinkException {\n     assert fsn.hasWriteLock();\n \n     FSDirectory fsd \u003d fsn.getFSDirectory();\n     final String src;\n     final INodesInPath iip;\n     final boolean onBlockBoundary;\n     Block truncateBlock \u003d null;\n     fsd.writeLock();\n     try {\n       iip \u003d fsd.resolvePath(pc, srcArg, DirOp.WRITE);\n       src \u003d iip.getPath();\n       if (fsd.isPermissionEnabled()) {\n         fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n       }\n       INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n \n       // not support truncating file with striped blocks\n       if (file.isStriped()) {\n         throw new UnsupportedOperationException(\n             \"Cannot truncate file with striped block \" + src);\n       }\n \n       final BlockStoragePolicy lpPolicy \u003d fsd.getBlockManager()\n           .getStoragePolicy(\"LAZY_PERSIST\");\n \n       if (lpPolicy !\u003d null \u0026\u0026 lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n         throw new UnsupportedOperationException(\n             \"Cannot truncate lazy persist file \" + src);\n       }\n \n       // Check if the file is already being truncated with the same length\n       final BlockInfo last \u003d file.getLastBlock();\n       if (last !\u003d null \u0026\u0026 last.getBlockUCState()\n           \u003d\u003d BlockUCState.UNDER_RECOVERY) {\n         final Block truncatedBlock \u003d last.getUnderConstructionFeature()\n             .getTruncateBlock();\n         if (truncatedBlock !\u003d null) {\n           final long truncateLength \u003d file.computeFileSize(false, false)\n               + truncatedBlock.getNumBytes();\n           if (newLength \u003d\u003d truncateLength) {\n             return new TruncateResult(false, fsd.getAuditFileInfo(iip));\n           }\n         }\n       }\n \n       // Opening an existing file for truncate. May need lease recovery.\n       fsn.recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE, iip, src,\n           clientName, clientMachine, false);\n       // Truncate length check.\n       long oldLength \u003d file.computeFileSize();\n       if (oldLength \u003d\u003d newLength) {\n         return new TruncateResult(true, fsd.getAuditFileInfo(iip));\n       }\n       if (oldLength \u003c newLength) {\n         throw new HadoopIllegalArgumentException(\n             \"Cannot truncate to a larger file size. Current size: \" + oldLength\n                 + \", truncate size: \" + newLength + \".\");\n       }\n       // Perform INodeFile truncation.\n       final QuotaCounts delta \u003d new QuotaCounts.Builder().build();\n       onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n           toRemoveBlocks, mtime, delta);\n       if (!onBlockBoundary) {\n         // Open file for write, but don\u0027t log into edits\n         long lastBlockDelta \u003d file.computeFileSize() - newLength;\n-        assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n+        assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block boundary\";\n         truncateBlock \u003d prepareFileForTruncate(fsn, iip, clientName,\n             clientMachine, lastBlockDelta, null);\n       }\n \n       // update the quota: use the preferred block size for UC block\n       fsd.updateCountNoQuotaCheck(iip, iip.length() - 1, delta);\n     } finally {\n       fsd.writeUnlock();\n     }\n \n     fsn.getEditLog().logTruncate(src, clientName, clientMachine, newLength,\n         mtime, truncateBlock);\n     return new TruncateResult(onBlockBoundary, fsd.getAuditFileInfo(iip));\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static TruncateResult truncate(final FSNamesystem fsn, final String srcArg,\n      final long newLength, final String clientName,\n      final String clientMachine, final long mtime,\n      final BlocksMapUpdateInfo toRemoveBlocks, final FSPermissionChecker pc)\n      throws IOException, UnresolvedLinkException {\n    assert fsn.hasWriteLock();\n\n    FSDirectory fsd \u003d fsn.getFSDirectory();\n    final String src;\n    final INodesInPath iip;\n    final boolean onBlockBoundary;\n    Block truncateBlock \u003d null;\n    fsd.writeLock();\n    try {\n      iip \u003d fsd.resolvePath(pc, srcArg, DirOp.WRITE);\n      src \u003d iip.getPath();\n      if (fsd.isPermissionEnabled()) {\n        fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n      }\n      INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n\n      // not support truncating file with striped blocks\n      if (file.isStriped()) {\n        throw new UnsupportedOperationException(\n            \"Cannot truncate file with striped block \" + src);\n      }\n\n      final BlockStoragePolicy lpPolicy \u003d fsd.getBlockManager()\n          .getStoragePolicy(\"LAZY_PERSIST\");\n\n      if (lpPolicy !\u003d null \u0026\u0026 lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n        throw new UnsupportedOperationException(\n            \"Cannot truncate lazy persist file \" + src);\n      }\n\n      // Check if the file is already being truncated with the same length\n      final BlockInfo last \u003d file.getLastBlock();\n      if (last !\u003d null \u0026\u0026 last.getBlockUCState()\n          \u003d\u003d BlockUCState.UNDER_RECOVERY) {\n        final Block truncatedBlock \u003d last.getUnderConstructionFeature()\n            .getTruncateBlock();\n        if (truncatedBlock !\u003d null) {\n          final long truncateLength \u003d file.computeFileSize(false, false)\n              + truncatedBlock.getNumBytes();\n          if (newLength \u003d\u003d truncateLength) {\n            return new TruncateResult(false, fsd.getAuditFileInfo(iip));\n          }\n        }\n      }\n\n      // Opening an existing file for truncate. May need lease recovery.\n      fsn.recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE, iip, src,\n          clientName, clientMachine, false);\n      // Truncate length check.\n      long oldLength \u003d file.computeFileSize();\n      if (oldLength \u003d\u003d newLength) {\n        return new TruncateResult(true, fsd.getAuditFileInfo(iip));\n      }\n      if (oldLength \u003c newLength) {\n        throw new HadoopIllegalArgumentException(\n            \"Cannot truncate to a larger file size. Current size: \" + oldLength\n                + \", truncate size: \" + newLength + \".\");\n      }\n      // Perform INodeFile truncation.\n      final QuotaCounts delta \u003d new QuotaCounts.Builder().build();\n      onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n          toRemoveBlocks, mtime, delta);\n      if (!onBlockBoundary) {\n        // Open file for write, but don\u0027t log into edits\n        long lastBlockDelta \u003d file.computeFileSize() - newLength;\n        assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block boundary\";\n        truncateBlock \u003d prepareFileForTruncate(fsn, iip, clientName,\n            clientMachine, lastBlockDelta, null);\n      }\n\n      // update the quota: use the preferred block size for UC block\n      fsd.updateCountNoQuotaCheck(iip, iip.length() - 1, delta);\n    } finally {\n      fsd.writeUnlock();\n    }\n\n    fsn.getEditLog().logTruncate(src, clientName, clientMachine, newLength,\n        mtime, truncateBlock);\n    return new TruncateResult(onBlockBoundary, fsd.getAuditFileInfo(iip));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirTruncateOp.java",
      "extendedDetails": {}
    },
    "9d175853b0170683ad5f21d9bcdeaac49fe89e04": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10997. Reduce number of path resolving methods. Contributed by Daryn Sharp.\n",
      "commitDate": "24/10/16 3:14 PM",
      "commitName": "9d175853b0170683ad5f21d9bcdeaac49fe89e04",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "17/08/16 1:53 PM",
      "commitNameOld": "869393643de23dcb010cc33091c8eb398de0fd6c",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 68.06,
      "commitsBetweenForRepo": 438,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,85 +1,85 @@\n   static TruncateResult truncate(final FSNamesystem fsn, final String srcArg,\n       final long newLength, final String clientName,\n       final String clientMachine, final long mtime,\n       final BlocksMapUpdateInfo toRemoveBlocks, final FSPermissionChecker pc)\n       throws IOException, UnresolvedLinkException {\n     assert fsn.hasWriteLock();\n \n     FSDirectory fsd \u003d fsn.getFSDirectory();\n     final String src;\n     final INodesInPath iip;\n     final boolean onBlockBoundary;\n     Block truncateBlock \u003d null;\n     fsd.writeLock();\n     try {\n-      iip \u003d fsd.resolvePathForWrite(pc, srcArg);\n+      iip \u003d fsd.resolvePath(pc, srcArg, DirOp.WRITE);\n       src \u003d iip.getPath();\n       if (fsd.isPermissionEnabled()) {\n         fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n       }\n       INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n \n       // not support truncating file with striped blocks\n       if (file.isStriped()) {\n         throw new UnsupportedOperationException(\n             \"Cannot truncate file with striped block \" + src);\n       }\n \n       final BlockStoragePolicy lpPolicy \u003d fsd.getBlockManager()\n           .getStoragePolicy(\"LAZY_PERSIST\");\n \n       if (lpPolicy !\u003d null \u0026\u0026 lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n         throw new UnsupportedOperationException(\n             \"Cannot truncate lazy persist file \" + src);\n       }\n \n       // Check if the file is already being truncated with the same length\n       final BlockInfo last \u003d file.getLastBlock();\n       if (last !\u003d null \u0026\u0026 last.getBlockUCState()\n           \u003d\u003d BlockUCState.UNDER_RECOVERY) {\n         final Block truncatedBlock \u003d last.getUnderConstructionFeature()\n             .getTruncateBlock();\n         if (truncatedBlock !\u003d null) {\n           final long truncateLength \u003d file.computeFileSize(false, false)\n               + truncatedBlock.getNumBytes();\n           if (newLength \u003d\u003d truncateLength) {\n             return new TruncateResult(false, fsd.getAuditFileInfo(iip));\n           }\n         }\n       }\n \n       // Opening an existing file for truncate. May need lease recovery.\n       fsn.recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE, iip, src,\n           clientName, clientMachine, false);\n       // Truncate length check.\n       long oldLength \u003d file.computeFileSize();\n       if (oldLength \u003d\u003d newLength) {\n         return new TruncateResult(true, fsd.getAuditFileInfo(iip));\n       }\n       if (oldLength \u003c newLength) {\n         throw new HadoopIllegalArgumentException(\n             \"Cannot truncate to a larger file size. Current size: \" + oldLength\n                 + \", truncate size: \" + newLength + \".\");\n       }\n       // Perform INodeFile truncation.\n       final QuotaCounts delta \u003d new QuotaCounts.Builder().build();\n       onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n           toRemoveBlocks, mtime, delta);\n       if (!onBlockBoundary) {\n         // Open file for write, but don\u0027t log into edits\n         long lastBlockDelta \u003d file.computeFileSize() - newLength;\n         assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n         truncateBlock \u003d prepareFileForTruncate(fsn, iip, clientName,\n             clientMachine, lastBlockDelta, null);\n       }\n \n       // update the quota: use the preferred block size for UC block\n       fsd.updateCountNoQuotaCheck(iip, iip.length() - 1, delta);\n     } finally {\n       fsd.writeUnlock();\n     }\n \n     fsn.getEditLog().logTruncate(src, clientName, clientMachine, newLength,\n         mtime, truncateBlock);\n     return new TruncateResult(onBlockBoundary, fsd.getAuditFileInfo(iip));\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static TruncateResult truncate(final FSNamesystem fsn, final String srcArg,\n      final long newLength, final String clientName,\n      final String clientMachine, final long mtime,\n      final BlocksMapUpdateInfo toRemoveBlocks, final FSPermissionChecker pc)\n      throws IOException, UnresolvedLinkException {\n    assert fsn.hasWriteLock();\n\n    FSDirectory fsd \u003d fsn.getFSDirectory();\n    final String src;\n    final INodesInPath iip;\n    final boolean onBlockBoundary;\n    Block truncateBlock \u003d null;\n    fsd.writeLock();\n    try {\n      iip \u003d fsd.resolvePath(pc, srcArg, DirOp.WRITE);\n      src \u003d iip.getPath();\n      if (fsd.isPermissionEnabled()) {\n        fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n      }\n      INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n\n      // not support truncating file with striped blocks\n      if (file.isStriped()) {\n        throw new UnsupportedOperationException(\n            \"Cannot truncate file with striped block \" + src);\n      }\n\n      final BlockStoragePolicy lpPolicy \u003d fsd.getBlockManager()\n          .getStoragePolicy(\"LAZY_PERSIST\");\n\n      if (lpPolicy !\u003d null \u0026\u0026 lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n        throw new UnsupportedOperationException(\n            \"Cannot truncate lazy persist file \" + src);\n      }\n\n      // Check if the file is already being truncated with the same length\n      final BlockInfo last \u003d file.getLastBlock();\n      if (last !\u003d null \u0026\u0026 last.getBlockUCState()\n          \u003d\u003d BlockUCState.UNDER_RECOVERY) {\n        final Block truncatedBlock \u003d last.getUnderConstructionFeature()\n            .getTruncateBlock();\n        if (truncatedBlock !\u003d null) {\n          final long truncateLength \u003d file.computeFileSize(false, false)\n              + truncatedBlock.getNumBytes();\n          if (newLength \u003d\u003d truncateLength) {\n            return new TruncateResult(false, fsd.getAuditFileInfo(iip));\n          }\n        }\n      }\n\n      // Opening an existing file for truncate. May need lease recovery.\n      fsn.recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE, iip, src,\n          clientName, clientMachine, false);\n      // Truncate length check.\n      long oldLength \u003d file.computeFileSize();\n      if (oldLength \u003d\u003d newLength) {\n        return new TruncateResult(true, fsd.getAuditFileInfo(iip));\n      }\n      if (oldLength \u003c newLength) {\n        throw new HadoopIllegalArgumentException(\n            \"Cannot truncate to a larger file size. Current size: \" + oldLength\n                + \", truncate size: \" + newLength + \".\");\n      }\n      // Perform INodeFile truncation.\n      final QuotaCounts delta \u003d new QuotaCounts.Builder().build();\n      onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n          toRemoveBlocks, mtime, delta);\n      if (!onBlockBoundary) {\n        // Open file for write, but don\u0027t log into edits\n        long lastBlockDelta \u003d file.computeFileSize() - newLength;\n        assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n        truncateBlock \u003d prepareFileForTruncate(fsn, iip, clientName,\n            clientMachine, lastBlockDelta, null);\n      }\n\n      // update the quota: use the preferred block size for UC block\n      fsd.updateCountNoQuotaCheck(iip, iip.length() - 1, delta);\n    } finally {\n      fsd.writeUnlock();\n    }\n\n    fsn.getEditLog().logTruncate(src, clientName, clientMachine, newLength,\n        mtime, truncateBlock);\n    return new TruncateResult(onBlockBoundary, fsd.getAuditFileInfo(iip));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirTruncateOp.java",
      "extendedDetails": {}
    },
    "869393643de23dcb010cc33091c8eb398de0fd6c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10745. Directly resolve paths into INodesInPath. Contributed by Daryn Sharp.\n",
      "commitDate": "17/08/16 1:53 PM",
      "commitName": "869393643de23dcb010cc33091c8eb398de0fd6c",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "15/08/16 2:45 PM",
      "commitNameOld": "03dea65e0b17ca2f9460bb6110f6ab3a321b8bf2",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 1.96,
      "commitsBetweenForRepo": 23,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,85 +1,85 @@\n   static TruncateResult truncate(final FSNamesystem fsn, final String srcArg,\n       final long newLength, final String clientName,\n       final String clientMachine, final long mtime,\n       final BlocksMapUpdateInfo toRemoveBlocks, final FSPermissionChecker pc)\n       throws IOException, UnresolvedLinkException {\n     assert fsn.hasWriteLock();\n \n     FSDirectory fsd \u003d fsn.getFSDirectory();\n     final String src;\n     final INodesInPath iip;\n     final boolean onBlockBoundary;\n     Block truncateBlock \u003d null;\n     fsd.writeLock();\n     try {\n-      src \u003d fsd.resolvePath(pc, srcArg);\n-      iip \u003d fsd.getINodesInPath4Write(src, true);\n+      iip \u003d fsd.resolvePathForWrite(pc, srcArg);\n+      src \u003d iip.getPath();\n       if (fsd.isPermissionEnabled()) {\n         fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n       }\n       INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n \n       // not support truncating file with striped blocks\n       if (file.isStriped()) {\n         throw new UnsupportedOperationException(\n             \"Cannot truncate file with striped block \" + src);\n       }\n \n       final BlockStoragePolicy lpPolicy \u003d fsd.getBlockManager()\n           .getStoragePolicy(\"LAZY_PERSIST\");\n \n       if (lpPolicy !\u003d null \u0026\u0026 lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n         throw new UnsupportedOperationException(\n             \"Cannot truncate lazy persist file \" + src);\n       }\n \n       // Check if the file is already being truncated with the same length\n       final BlockInfo last \u003d file.getLastBlock();\n       if (last !\u003d null \u0026\u0026 last.getBlockUCState()\n           \u003d\u003d BlockUCState.UNDER_RECOVERY) {\n         final Block truncatedBlock \u003d last.getUnderConstructionFeature()\n             .getTruncateBlock();\n         if (truncatedBlock !\u003d null) {\n           final long truncateLength \u003d file.computeFileSize(false, false)\n               + truncatedBlock.getNumBytes();\n           if (newLength \u003d\u003d truncateLength) {\n             return new TruncateResult(false, fsd.getAuditFileInfo(iip));\n           }\n         }\n       }\n \n       // Opening an existing file for truncate. May need lease recovery.\n       fsn.recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE, iip, src,\n           clientName, clientMachine, false);\n       // Truncate length check.\n       long oldLength \u003d file.computeFileSize();\n       if (oldLength \u003d\u003d newLength) {\n         return new TruncateResult(true, fsd.getAuditFileInfo(iip));\n       }\n       if (oldLength \u003c newLength) {\n         throw new HadoopIllegalArgumentException(\n             \"Cannot truncate to a larger file size. Current size: \" + oldLength\n                 + \", truncate size: \" + newLength + \".\");\n       }\n       // Perform INodeFile truncation.\n       final QuotaCounts delta \u003d new QuotaCounts.Builder().build();\n       onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n           toRemoveBlocks, mtime, delta);\n       if (!onBlockBoundary) {\n         // Open file for write, but don\u0027t log into edits\n         long lastBlockDelta \u003d file.computeFileSize() - newLength;\n         assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n         truncateBlock \u003d prepareFileForTruncate(fsn, iip, clientName,\n             clientMachine, lastBlockDelta, null);\n       }\n \n       // update the quota: use the preferred block size for UC block\n       fsd.updateCountNoQuotaCheck(iip, iip.length() - 1, delta);\n     } finally {\n       fsd.writeUnlock();\n     }\n \n     fsn.getEditLog().logTruncate(src, clientName, clientMachine, newLength,\n         mtime, truncateBlock);\n     return new TruncateResult(onBlockBoundary, fsd.getAuditFileInfo(iip));\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static TruncateResult truncate(final FSNamesystem fsn, final String srcArg,\n      final long newLength, final String clientName,\n      final String clientMachine, final long mtime,\n      final BlocksMapUpdateInfo toRemoveBlocks, final FSPermissionChecker pc)\n      throws IOException, UnresolvedLinkException {\n    assert fsn.hasWriteLock();\n\n    FSDirectory fsd \u003d fsn.getFSDirectory();\n    final String src;\n    final INodesInPath iip;\n    final boolean onBlockBoundary;\n    Block truncateBlock \u003d null;\n    fsd.writeLock();\n    try {\n      iip \u003d fsd.resolvePathForWrite(pc, srcArg);\n      src \u003d iip.getPath();\n      if (fsd.isPermissionEnabled()) {\n        fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n      }\n      INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n\n      // not support truncating file with striped blocks\n      if (file.isStriped()) {\n        throw new UnsupportedOperationException(\n            \"Cannot truncate file with striped block \" + src);\n      }\n\n      final BlockStoragePolicy lpPolicy \u003d fsd.getBlockManager()\n          .getStoragePolicy(\"LAZY_PERSIST\");\n\n      if (lpPolicy !\u003d null \u0026\u0026 lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n        throw new UnsupportedOperationException(\n            \"Cannot truncate lazy persist file \" + src);\n      }\n\n      // Check if the file is already being truncated with the same length\n      final BlockInfo last \u003d file.getLastBlock();\n      if (last !\u003d null \u0026\u0026 last.getBlockUCState()\n          \u003d\u003d BlockUCState.UNDER_RECOVERY) {\n        final Block truncatedBlock \u003d last.getUnderConstructionFeature()\n            .getTruncateBlock();\n        if (truncatedBlock !\u003d null) {\n          final long truncateLength \u003d file.computeFileSize(false, false)\n              + truncatedBlock.getNumBytes();\n          if (newLength \u003d\u003d truncateLength) {\n            return new TruncateResult(false, fsd.getAuditFileInfo(iip));\n          }\n        }\n      }\n\n      // Opening an existing file for truncate. May need lease recovery.\n      fsn.recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE, iip, src,\n          clientName, clientMachine, false);\n      // Truncate length check.\n      long oldLength \u003d file.computeFileSize();\n      if (oldLength \u003d\u003d newLength) {\n        return new TruncateResult(true, fsd.getAuditFileInfo(iip));\n      }\n      if (oldLength \u003c newLength) {\n        throw new HadoopIllegalArgumentException(\n            \"Cannot truncate to a larger file size. Current size: \" + oldLength\n                + \", truncate size: \" + newLength + \".\");\n      }\n      // Perform INodeFile truncation.\n      final QuotaCounts delta \u003d new QuotaCounts.Builder().build();\n      onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n          toRemoveBlocks, mtime, delta);\n      if (!onBlockBoundary) {\n        // Open file for write, but don\u0027t log into edits\n        long lastBlockDelta \u003d file.computeFileSize() - newLength;\n        assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n        truncateBlock \u003d prepareFileForTruncate(fsn, iip, clientName,\n            clientMachine, lastBlockDelta, null);\n      }\n\n      // update the quota: use the preferred block size for UC block\n      fsd.updateCountNoQuotaCheck(iip, iip.length() - 1, delta);\n    } finally {\n      fsd.writeUnlock();\n    }\n\n    fsn.getEditLog().logTruncate(src, clientName, clientMachine, newLength,\n        mtime, truncateBlock);\n    return new TruncateResult(onBlockBoundary, fsd.getAuditFileInfo(iip));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirTruncateOp.java",
      "extendedDetails": {}
    },
    "03dea65e0b17ca2f9460bb6110f6ab3a321b8bf2": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10744. Internally optimize path component resolution. Contributed by Daryn Sharp.\n",
      "commitDate": "15/08/16 2:45 PM",
      "commitName": "03dea65e0b17ca2f9460bb6110f6ab3a321b8bf2",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "12/02/16 11:07 AM",
      "commitNameOld": "972782d9568e0849484c027f27c1638ba50ec56e",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 185.11,
      "commitsBetweenForRepo": 1311,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,87 +1,85 @@\n   static TruncateResult truncate(final FSNamesystem fsn, final String srcArg,\n       final long newLength, final String clientName,\n       final String clientMachine, final long mtime,\n       final BlocksMapUpdateInfo toRemoveBlocks, final FSPermissionChecker pc)\n       throws IOException, UnresolvedLinkException {\n     assert fsn.hasWriteLock();\n \n     FSDirectory fsd \u003d fsn.getFSDirectory();\n-    byte[][] pathComponents \u003d FSDirectory\n-        .getPathComponentsForReservedPath(srcArg);\n     final String src;\n     final INodesInPath iip;\n     final boolean onBlockBoundary;\n     Block truncateBlock \u003d null;\n     fsd.writeLock();\n     try {\n-      src \u003d fsd.resolvePath(pc, srcArg, pathComponents);\n+      src \u003d fsd.resolvePath(pc, srcArg);\n       iip \u003d fsd.getINodesInPath4Write(src, true);\n       if (fsd.isPermissionEnabled()) {\n         fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n       }\n       INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n \n       // not support truncating file with striped blocks\n       if (file.isStriped()) {\n         throw new UnsupportedOperationException(\n             \"Cannot truncate file with striped block \" + src);\n       }\n \n       final BlockStoragePolicy lpPolicy \u003d fsd.getBlockManager()\n           .getStoragePolicy(\"LAZY_PERSIST\");\n \n       if (lpPolicy !\u003d null \u0026\u0026 lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n         throw new UnsupportedOperationException(\n             \"Cannot truncate lazy persist file \" + src);\n       }\n \n       // Check if the file is already being truncated with the same length\n       final BlockInfo last \u003d file.getLastBlock();\n       if (last !\u003d null \u0026\u0026 last.getBlockUCState()\n           \u003d\u003d BlockUCState.UNDER_RECOVERY) {\n         final Block truncatedBlock \u003d last.getUnderConstructionFeature()\n             .getTruncateBlock();\n         if (truncatedBlock !\u003d null) {\n           final long truncateLength \u003d file.computeFileSize(false, false)\n               + truncatedBlock.getNumBytes();\n           if (newLength \u003d\u003d truncateLength) {\n             return new TruncateResult(false, fsd.getAuditFileInfo(iip));\n           }\n         }\n       }\n \n       // Opening an existing file for truncate. May need lease recovery.\n       fsn.recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE, iip, src,\n           clientName, clientMachine, false);\n       // Truncate length check.\n       long oldLength \u003d file.computeFileSize();\n       if (oldLength \u003d\u003d newLength) {\n         return new TruncateResult(true, fsd.getAuditFileInfo(iip));\n       }\n       if (oldLength \u003c newLength) {\n         throw new HadoopIllegalArgumentException(\n             \"Cannot truncate to a larger file size. Current size: \" + oldLength\n                 + \", truncate size: \" + newLength + \".\");\n       }\n       // Perform INodeFile truncation.\n       final QuotaCounts delta \u003d new QuotaCounts.Builder().build();\n       onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n           toRemoveBlocks, mtime, delta);\n       if (!onBlockBoundary) {\n         // Open file for write, but don\u0027t log into edits\n         long lastBlockDelta \u003d file.computeFileSize() - newLength;\n         assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n         truncateBlock \u003d prepareFileForTruncate(fsn, iip, clientName,\n             clientMachine, lastBlockDelta, null);\n       }\n \n       // update the quota: use the preferred block size for UC block\n       fsd.updateCountNoQuotaCheck(iip, iip.length() - 1, delta);\n     } finally {\n       fsd.writeUnlock();\n     }\n \n     fsn.getEditLog().logTruncate(src, clientName, clientMachine, newLength,\n         mtime, truncateBlock);\n     return new TruncateResult(onBlockBoundary, fsd.getAuditFileInfo(iip));\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static TruncateResult truncate(final FSNamesystem fsn, final String srcArg,\n      final long newLength, final String clientName,\n      final String clientMachine, final long mtime,\n      final BlocksMapUpdateInfo toRemoveBlocks, final FSPermissionChecker pc)\n      throws IOException, UnresolvedLinkException {\n    assert fsn.hasWriteLock();\n\n    FSDirectory fsd \u003d fsn.getFSDirectory();\n    final String src;\n    final INodesInPath iip;\n    final boolean onBlockBoundary;\n    Block truncateBlock \u003d null;\n    fsd.writeLock();\n    try {\n      src \u003d fsd.resolvePath(pc, srcArg);\n      iip \u003d fsd.getINodesInPath4Write(src, true);\n      if (fsd.isPermissionEnabled()) {\n        fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n      }\n      INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n\n      // not support truncating file with striped blocks\n      if (file.isStriped()) {\n        throw new UnsupportedOperationException(\n            \"Cannot truncate file with striped block \" + src);\n      }\n\n      final BlockStoragePolicy lpPolicy \u003d fsd.getBlockManager()\n          .getStoragePolicy(\"LAZY_PERSIST\");\n\n      if (lpPolicy !\u003d null \u0026\u0026 lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n        throw new UnsupportedOperationException(\n            \"Cannot truncate lazy persist file \" + src);\n      }\n\n      // Check if the file is already being truncated with the same length\n      final BlockInfo last \u003d file.getLastBlock();\n      if (last !\u003d null \u0026\u0026 last.getBlockUCState()\n          \u003d\u003d BlockUCState.UNDER_RECOVERY) {\n        final Block truncatedBlock \u003d last.getUnderConstructionFeature()\n            .getTruncateBlock();\n        if (truncatedBlock !\u003d null) {\n          final long truncateLength \u003d file.computeFileSize(false, false)\n              + truncatedBlock.getNumBytes();\n          if (newLength \u003d\u003d truncateLength) {\n            return new TruncateResult(false, fsd.getAuditFileInfo(iip));\n          }\n        }\n      }\n\n      // Opening an existing file for truncate. May need lease recovery.\n      fsn.recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE, iip, src,\n          clientName, clientMachine, false);\n      // Truncate length check.\n      long oldLength \u003d file.computeFileSize();\n      if (oldLength \u003d\u003d newLength) {\n        return new TruncateResult(true, fsd.getAuditFileInfo(iip));\n      }\n      if (oldLength \u003c newLength) {\n        throw new HadoopIllegalArgumentException(\n            \"Cannot truncate to a larger file size. Current size: \" + oldLength\n                + \", truncate size: \" + newLength + \".\");\n      }\n      // Perform INodeFile truncation.\n      final QuotaCounts delta \u003d new QuotaCounts.Builder().build();\n      onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n          toRemoveBlocks, mtime, delta);\n      if (!onBlockBoundary) {\n        // Open file for write, but don\u0027t log into edits\n        long lastBlockDelta \u003d file.computeFileSize() - newLength;\n        assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n        truncateBlock \u003d prepareFileForTruncate(fsn, iip, clientName,\n            clientMachine, lastBlockDelta, null);\n      }\n\n      // update the quota: use the preferred block size for UC block\n      fsd.updateCountNoQuotaCheck(iip, iip.length() - 1, delta);\n    } finally {\n      fsd.writeUnlock();\n    }\n\n    fsn.getEditLog().logTruncate(src, clientName, clientMachine, newLength,\n        mtime, truncateBlock);\n    return new TruncateResult(onBlockBoundary, fsd.getAuditFileInfo(iip));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirTruncateOp.java",
      "extendedDetails": {}
    },
    "164cbe643988f878f0f4100a4de51783e5b6738e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8909. Erasure coding: update BlockInfoContiguousUC and BlockInfoStripedUC to use BlockUnderConstructionFeature. Contributed by Jing Zhao.\n",
      "commitDate": "27/08/15 1:02 AM",
      "commitName": "164cbe643988f878f0f4100a4de51783e5b6738e",
      "commitAuthor": "Walter Su",
      "commitDateOld": "24/08/15 12:59 PM",
      "commitNameOld": "6b6a63bbbda920315d3d24b61ed3344a78a981b6",
      "commitAuthorOld": "",
      "daysBetweenCommits": 2.5,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,87 +1,87 @@\n   static TruncateResult truncate(final FSNamesystem fsn, final String srcArg,\n       final long newLength, final String clientName,\n       final String clientMachine, final long mtime,\n       final BlocksMapUpdateInfo toRemoveBlocks, final FSPermissionChecker pc)\n       throws IOException, UnresolvedLinkException {\n     assert fsn.hasWriteLock();\n \n     FSDirectory fsd \u003d fsn.getFSDirectory();\n     byte[][] pathComponents \u003d FSDirectory\n         .getPathComponentsForReservedPath(srcArg);\n     final String src;\n     final INodesInPath iip;\n     final boolean onBlockBoundary;\n     Block truncateBlock \u003d null;\n     fsd.writeLock();\n     try {\n       src \u003d fsd.resolvePath(pc, srcArg, pathComponents);\n       iip \u003d fsd.getINodesInPath4Write(src, true);\n       if (fsd.isPermissionEnabled()) {\n         fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n       }\n       INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n \n       // not support truncating file with striped blocks\n       if (file.isStriped()) {\n         throw new UnsupportedOperationException(\n             \"Cannot truncate file with striped block \" + src);\n       }\n \n       final BlockStoragePolicy lpPolicy \u003d fsd.getBlockManager()\n           .getStoragePolicy(\"LAZY_PERSIST\");\n \n       if (lpPolicy !\u003d null \u0026\u0026 lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n         throw new UnsupportedOperationException(\n             \"Cannot truncate lazy persist file \" + src);\n       }\n \n       // Check if the file is already being truncated with the same length\n       final BlockInfo last \u003d file.getLastBlock();\n       if (last !\u003d null \u0026\u0026 last.getBlockUCState()\n           \u003d\u003d BlockUCState.UNDER_RECOVERY) {\n-        final Block truncatedBlock \u003d ((BlockInfoContiguousUnderConstruction) last)\n+        final Block truncatedBlock \u003d last.getUnderConstructionFeature()\n             .getTruncateBlock();\n         if (truncatedBlock !\u003d null) {\n           final long truncateLength \u003d file.computeFileSize(false, false)\n               + truncatedBlock.getNumBytes();\n           if (newLength \u003d\u003d truncateLength) {\n             return new TruncateResult(false, fsd.getAuditFileInfo(iip));\n           }\n         }\n       }\n \n       // Opening an existing file for truncate. May need lease recovery.\n       fsn.recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE, iip, src,\n           clientName, clientMachine, false);\n       // Truncate length check.\n       long oldLength \u003d file.computeFileSize();\n       if (oldLength \u003d\u003d newLength) {\n         return new TruncateResult(true, fsd.getAuditFileInfo(iip));\n       }\n       if (oldLength \u003c newLength) {\n         throw new HadoopIllegalArgumentException(\n             \"Cannot truncate to a larger file size. Current size: \" + oldLength\n                 + \", truncate size: \" + newLength + \".\");\n       }\n       // Perform INodeFile truncation.\n       final QuotaCounts delta \u003d new QuotaCounts.Builder().build();\n       onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n           toRemoveBlocks, mtime, delta);\n       if (!onBlockBoundary) {\n         // Open file for write, but don\u0027t log into edits\n         long lastBlockDelta \u003d file.computeFileSize() - newLength;\n         assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n         truncateBlock \u003d prepareFileForTruncate(fsn, iip, clientName,\n             clientMachine, lastBlockDelta, null);\n       }\n \n       // update the quota: use the preferred block size for UC block\n       fsd.updateCountNoQuotaCheck(iip, iip.length() - 1, delta);\n     } finally {\n       fsd.writeUnlock();\n     }\n \n     fsn.getEditLog().logTruncate(src, clientName, clientMachine, newLength,\n         mtime, truncateBlock);\n     return new TruncateResult(onBlockBoundary, fsd.getAuditFileInfo(iip));\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static TruncateResult truncate(final FSNamesystem fsn, final String srcArg,\n      final long newLength, final String clientName,\n      final String clientMachine, final long mtime,\n      final BlocksMapUpdateInfo toRemoveBlocks, final FSPermissionChecker pc)\n      throws IOException, UnresolvedLinkException {\n    assert fsn.hasWriteLock();\n\n    FSDirectory fsd \u003d fsn.getFSDirectory();\n    byte[][] pathComponents \u003d FSDirectory\n        .getPathComponentsForReservedPath(srcArg);\n    final String src;\n    final INodesInPath iip;\n    final boolean onBlockBoundary;\n    Block truncateBlock \u003d null;\n    fsd.writeLock();\n    try {\n      src \u003d fsd.resolvePath(pc, srcArg, pathComponents);\n      iip \u003d fsd.getINodesInPath4Write(src, true);\n      if (fsd.isPermissionEnabled()) {\n        fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n      }\n      INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n\n      // not support truncating file with striped blocks\n      if (file.isStriped()) {\n        throw new UnsupportedOperationException(\n            \"Cannot truncate file with striped block \" + src);\n      }\n\n      final BlockStoragePolicy lpPolicy \u003d fsd.getBlockManager()\n          .getStoragePolicy(\"LAZY_PERSIST\");\n\n      if (lpPolicy !\u003d null \u0026\u0026 lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n        throw new UnsupportedOperationException(\n            \"Cannot truncate lazy persist file \" + src);\n      }\n\n      // Check if the file is already being truncated with the same length\n      final BlockInfo last \u003d file.getLastBlock();\n      if (last !\u003d null \u0026\u0026 last.getBlockUCState()\n          \u003d\u003d BlockUCState.UNDER_RECOVERY) {\n        final Block truncatedBlock \u003d last.getUnderConstructionFeature()\n            .getTruncateBlock();\n        if (truncatedBlock !\u003d null) {\n          final long truncateLength \u003d file.computeFileSize(false, false)\n              + truncatedBlock.getNumBytes();\n          if (newLength \u003d\u003d truncateLength) {\n            return new TruncateResult(false, fsd.getAuditFileInfo(iip));\n          }\n        }\n      }\n\n      // Opening an existing file for truncate. May need lease recovery.\n      fsn.recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE, iip, src,\n          clientName, clientMachine, false);\n      // Truncate length check.\n      long oldLength \u003d file.computeFileSize();\n      if (oldLength \u003d\u003d newLength) {\n        return new TruncateResult(true, fsd.getAuditFileInfo(iip));\n      }\n      if (oldLength \u003c newLength) {\n        throw new HadoopIllegalArgumentException(\n            \"Cannot truncate to a larger file size. Current size: \" + oldLength\n                + \", truncate size: \" + newLength + \".\");\n      }\n      // Perform INodeFile truncation.\n      final QuotaCounts delta \u003d new QuotaCounts.Builder().build();\n      onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n          toRemoveBlocks, mtime, delta);\n      if (!onBlockBoundary) {\n        // Open file for write, but don\u0027t log into edits\n        long lastBlockDelta \u003d file.computeFileSize() - newLength;\n        assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n        truncateBlock \u003d prepareFileForTruncate(fsn, iip, clientName,\n            clientMachine, lastBlockDelta, null);\n      }\n\n      // update the quota: use the preferred block size for UC block\n      fsd.updateCountNoQuotaCheck(iip, iip.length() - 1, delta);\n    } finally {\n      fsd.writeUnlock();\n    }\n\n    fsn.getEditLog().logTruncate(src, clientName, clientMachine, newLength,\n        mtime, truncateBlock);\n    return new TruncateResult(onBlockBoundary, fsd.getAuditFileInfo(iip));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirTruncateOp.java",
      "extendedDetails": {}
    },
    "e535e0f05b5fbd087c93238deb888cc985254b4c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8801. Convert BlockInfoUnderConstruction as a feature. Contributed by Jing Zhao.\n",
      "commitDate": "17/08/15 11:28 AM",
      "commitName": "e535e0f05b5fbd087c93238deb888cc985254b4c",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "06/08/15 10:21 AM",
      "commitNameOld": "f4c523b69ba55b1fd35e8995c3011a9f546ac835",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 11.05,
      "commitsBetweenForRepo": 46,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,80 +1,80 @@\n   static TruncateResult truncate(final FSNamesystem fsn, final String srcArg,\n       final long newLength, final String clientName,\n       final String clientMachine, final long mtime,\n       final BlocksMapUpdateInfo toRemoveBlocks, final FSPermissionChecker pc)\n       throws IOException, UnresolvedLinkException {\n     assert fsn.hasWriteLock();\n \n     FSDirectory fsd \u003d fsn.getFSDirectory();\n     byte[][] pathComponents \u003d FSDirectory\n         .getPathComponentsForReservedPath(srcArg);\n     final String src;\n     final INodesInPath iip;\n     final boolean onBlockBoundary;\n     Block truncateBlock \u003d null;\n     fsd.writeLock();\n     try {\n       src \u003d fsd.resolvePath(pc, srcArg, pathComponents);\n       iip \u003d fsd.getINodesInPath4Write(src, true);\n       if (fsd.isPermissionEnabled()) {\n         fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n       }\n       INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n       final BlockStoragePolicy lpPolicy \u003d fsd.getBlockManager()\n           .getStoragePolicy(\"LAZY_PERSIST\");\n \n       if (lpPolicy !\u003d null \u0026\u0026 lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n         throw new UnsupportedOperationException(\n             \"Cannot truncate lazy persist file \" + src);\n       }\n \n       // Check if the file is already being truncated with the same length\n       final BlockInfo last \u003d file.getLastBlock();\n       if (last !\u003d null \u0026\u0026 last.getBlockUCState()\n           \u003d\u003d BlockUCState.UNDER_RECOVERY) {\n-        final Block truncatedBlock \u003d ((BlockInfoContiguousUnderConstruction) last)\n+        final Block truncatedBlock \u003d last.getUnderConstructionFeature()\n             .getTruncateBlock();\n         if (truncatedBlock !\u003d null) {\n           final long truncateLength \u003d file.computeFileSize(false, false)\n               + truncatedBlock.getNumBytes();\n           if (newLength \u003d\u003d truncateLength) {\n             return new TruncateResult(false, fsd.getAuditFileInfo(iip));\n           }\n         }\n       }\n \n       // Opening an existing file for truncate. May need lease recovery.\n       fsn.recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE, iip, src,\n           clientName, clientMachine, false);\n       // Truncate length check.\n       long oldLength \u003d file.computeFileSize();\n       if (oldLength \u003d\u003d newLength) {\n         return new TruncateResult(true, fsd.getAuditFileInfo(iip));\n       }\n       if (oldLength \u003c newLength) {\n         throw new HadoopIllegalArgumentException(\n             \"Cannot truncate to a larger file size. Current size: \" + oldLength\n                 + \", truncate size: \" + newLength + \".\");\n       }\n       // Perform INodeFile truncation.\n       final QuotaCounts delta \u003d new QuotaCounts.Builder().build();\n       onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n           toRemoveBlocks, mtime, delta);\n       if (!onBlockBoundary) {\n         // Open file for write, but don\u0027t log into edits\n         long lastBlockDelta \u003d file.computeFileSize() - newLength;\n         assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n         truncateBlock \u003d prepareFileForTruncate(fsn, iip, clientName,\n             clientMachine, lastBlockDelta, null);\n       }\n \n       // update the quota: use the preferred block size for UC block\n       fsd.updateCountNoQuotaCheck(iip, iip.length() - 1, delta);\n     } finally {\n       fsd.writeUnlock();\n     }\n \n     fsn.getEditLog().logTruncate(src, clientName, clientMachine, newLength,\n         mtime, truncateBlock);\n     return new TruncateResult(onBlockBoundary, fsd.getAuditFileInfo(iip));\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static TruncateResult truncate(final FSNamesystem fsn, final String srcArg,\n      final long newLength, final String clientName,\n      final String clientMachine, final long mtime,\n      final BlocksMapUpdateInfo toRemoveBlocks, final FSPermissionChecker pc)\n      throws IOException, UnresolvedLinkException {\n    assert fsn.hasWriteLock();\n\n    FSDirectory fsd \u003d fsn.getFSDirectory();\n    byte[][] pathComponents \u003d FSDirectory\n        .getPathComponentsForReservedPath(srcArg);\n    final String src;\n    final INodesInPath iip;\n    final boolean onBlockBoundary;\n    Block truncateBlock \u003d null;\n    fsd.writeLock();\n    try {\n      src \u003d fsd.resolvePath(pc, srcArg, pathComponents);\n      iip \u003d fsd.getINodesInPath4Write(src, true);\n      if (fsd.isPermissionEnabled()) {\n        fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n      }\n      INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n      final BlockStoragePolicy lpPolicy \u003d fsd.getBlockManager()\n          .getStoragePolicy(\"LAZY_PERSIST\");\n\n      if (lpPolicy !\u003d null \u0026\u0026 lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n        throw new UnsupportedOperationException(\n            \"Cannot truncate lazy persist file \" + src);\n      }\n\n      // Check if the file is already being truncated with the same length\n      final BlockInfo last \u003d file.getLastBlock();\n      if (last !\u003d null \u0026\u0026 last.getBlockUCState()\n          \u003d\u003d BlockUCState.UNDER_RECOVERY) {\n        final Block truncatedBlock \u003d last.getUnderConstructionFeature()\n            .getTruncateBlock();\n        if (truncatedBlock !\u003d null) {\n          final long truncateLength \u003d file.computeFileSize(false, false)\n              + truncatedBlock.getNumBytes();\n          if (newLength \u003d\u003d truncateLength) {\n            return new TruncateResult(false, fsd.getAuditFileInfo(iip));\n          }\n        }\n      }\n\n      // Opening an existing file for truncate. May need lease recovery.\n      fsn.recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE, iip, src,\n          clientName, clientMachine, false);\n      // Truncate length check.\n      long oldLength \u003d file.computeFileSize();\n      if (oldLength \u003d\u003d newLength) {\n        return new TruncateResult(true, fsd.getAuditFileInfo(iip));\n      }\n      if (oldLength \u003c newLength) {\n        throw new HadoopIllegalArgumentException(\n            \"Cannot truncate to a larger file size. Current size: \" + oldLength\n                + \", truncate size: \" + newLength + \".\");\n      }\n      // Perform INodeFile truncation.\n      final QuotaCounts delta \u003d new QuotaCounts.Builder().build();\n      onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n          toRemoveBlocks, mtime, delta);\n      if (!onBlockBoundary) {\n        // Open file for write, but don\u0027t log into edits\n        long lastBlockDelta \u003d file.computeFileSize() - newLength;\n        assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n        truncateBlock \u003d prepareFileForTruncate(fsn, iip, clientName,\n            clientMachine, lastBlockDelta, null);\n      }\n\n      // update the quota: use the preferred block size for UC block\n      fsd.updateCountNoQuotaCheck(iip, iip.length() - 1, delta);\n    } finally {\n      fsd.writeUnlock();\n    }\n\n    fsn.getEditLog().logTruncate(src, clientName, clientMachine, newLength,\n        mtime, truncateBlock);\n    return new TruncateResult(onBlockBoundary, fsd.getAuditFileInfo(iip));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirTruncateOp.java",
      "extendedDetails": {}
    },
    "f4c523b69ba55b1fd35e8995c3011a9f546ac835": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-8499. Refactor BlockInfo class hierarchy with static helper class. Contributed by Zhe Zhang.\"\n\nThis reverts commit c17439c2ddd921b63b1635e6f1cba634b8da8557.\n",
      "commitDate": "06/08/15 10:21 AM",
      "commitName": "f4c523b69ba55b1fd35e8995c3011a9f546ac835",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "21/07/15 5:25 PM",
      "commitNameOld": "31f117138a00794de4951ee8433e304d72b04094",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 15.71,
      "commitsBetweenForRepo": 92,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,80 +1,80 @@\n   static TruncateResult truncate(final FSNamesystem fsn, final String srcArg,\n       final long newLength, final String clientName,\n       final String clientMachine, final long mtime,\n       final BlocksMapUpdateInfo toRemoveBlocks, final FSPermissionChecker pc)\n       throws IOException, UnresolvedLinkException {\n     assert fsn.hasWriteLock();\n \n     FSDirectory fsd \u003d fsn.getFSDirectory();\n     byte[][] pathComponents \u003d FSDirectory\n         .getPathComponentsForReservedPath(srcArg);\n     final String src;\n     final INodesInPath iip;\n     final boolean onBlockBoundary;\n     Block truncateBlock \u003d null;\n     fsd.writeLock();\n     try {\n       src \u003d fsd.resolvePath(pc, srcArg, pathComponents);\n       iip \u003d fsd.getINodesInPath4Write(src, true);\n       if (fsd.isPermissionEnabled()) {\n         fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n       }\n       INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n       final BlockStoragePolicy lpPolicy \u003d fsd.getBlockManager()\n           .getStoragePolicy(\"LAZY_PERSIST\");\n \n       if (lpPolicy !\u003d null \u0026\u0026 lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n         throw new UnsupportedOperationException(\n             \"Cannot truncate lazy persist file \" + src);\n       }\n \n       // Check if the file is already being truncated with the same length\n       final BlockInfo last \u003d file.getLastBlock();\n       if (last !\u003d null \u0026\u0026 last.getBlockUCState()\n           \u003d\u003d BlockUCState.UNDER_RECOVERY) {\n-        final Block truncatedBlock \u003d ((BlockInfoUnderConstruction) last)\n+        final Block truncatedBlock \u003d ((BlockInfoContiguousUnderConstruction) last)\n             .getTruncateBlock();\n         if (truncatedBlock !\u003d null) {\n           final long truncateLength \u003d file.computeFileSize(false, false)\n               + truncatedBlock.getNumBytes();\n           if (newLength \u003d\u003d truncateLength) {\n             return new TruncateResult(false, fsd.getAuditFileInfo(iip));\n           }\n         }\n       }\n \n       // Opening an existing file for truncate. May need lease recovery.\n       fsn.recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE, iip, src,\n           clientName, clientMachine, false);\n       // Truncate length check.\n       long oldLength \u003d file.computeFileSize();\n       if (oldLength \u003d\u003d newLength) {\n         return new TruncateResult(true, fsd.getAuditFileInfo(iip));\n       }\n       if (oldLength \u003c newLength) {\n         throw new HadoopIllegalArgumentException(\n             \"Cannot truncate to a larger file size. Current size: \" + oldLength\n                 + \", truncate size: \" + newLength + \".\");\n       }\n       // Perform INodeFile truncation.\n       final QuotaCounts delta \u003d new QuotaCounts.Builder().build();\n       onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n           toRemoveBlocks, mtime, delta);\n       if (!onBlockBoundary) {\n         // Open file for write, but don\u0027t log into edits\n         long lastBlockDelta \u003d file.computeFileSize() - newLength;\n         assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n         truncateBlock \u003d prepareFileForTruncate(fsn, iip, clientName,\n             clientMachine, lastBlockDelta, null);\n       }\n \n       // update the quota: use the preferred block size for UC block\n       fsd.updateCountNoQuotaCheck(iip, iip.length() - 1, delta);\n     } finally {\n       fsd.writeUnlock();\n     }\n \n     fsn.getEditLog().logTruncate(src, clientName, clientMachine, newLength,\n         mtime, truncateBlock);\n     return new TruncateResult(onBlockBoundary, fsd.getAuditFileInfo(iip));\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static TruncateResult truncate(final FSNamesystem fsn, final String srcArg,\n      final long newLength, final String clientName,\n      final String clientMachine, final long mtime,\n      final BlocksMapUpdateInfo toRemoveBlocks, final FSPermissionChecker pc)\n      throws IOException, UnresolvedLinkException {\n    assert fsn.hasWriteLock();\n\n    FSDirectory fsd \u003d fsn.getFSDirectory();\n    byte[][] pathComponents \u003d FSDirectory\n        .getPathComponentsForReservedPath(srcArg);\n    final String src;\n    final INodesInPath iip;\n    final boolean onBlockBoundary;\n    Block truncateBlock \u003d null;\n    fsd.writeLock();\n    try {\n      src \u003d fsd.resolvePath(pc, srcArg, pathComponents);\n      iip \u003d fsd.getINodesInPath4Write(src, true);\n      if (fsd.isPermissionEnabled()) {\n        fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n      }\n      INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n      final BlockStoragePolicy lpPolicy \u003d fsd.getBlockManager()\n          .getStoragePolicy(\"LAZY_PERSIST\");\n\n      if (lpPolicy !\u003d null \u0026\u0026 lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n        throw new UnsupportedOperationException(\n            \"Cannot truncate lazy persist file \" + src);\n      }\n\n      // Check if the file is already being truncated with the same length\n      final BlockInfo last \u003d file.getLastBlock();\n      if (last !\u003d null \u0026\u0026 last.getBlockUCState()\n          \u003d\u003d BlockUCState.UNDER_RECOVERY) {\n        final Block truncatedBlock \u003d ((BlockInfoContiguousUnderConstruction) last)\n            .getTruncateBlock();\n        if (truncatedBlock !\u003d null) {\n          final long truncateLength \u003d file.computeFileSize(false, false)\n              + truncatedBlock.getNumBytes();\n          if (newLength \u003d\u003d truncateLength) {\n            return new TruncateResult(false, fsd.getAuditFileInfo(iip));\n          }\n        }\n      }\n\n      // Opening an existing file for truncate. May need lease recovery.\n      fsn.recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE, iip, src,\n          clientName, clientMachine, false);\n      // Truncate length check.\n      long oldLength \u003d file.computeFileSize();\n      if (oldLength \u003d\u003d newLength) {\n        return new TruncateResult(true, fsd.getAuditFileInfo(iip));\n      }\n      if (oldLength \u003c newLength) {\n        throw new HadoopIllegalArgumentException(\n            \"Cannot truncate to a larger file size. Current size: \" + oldLength\n                + \", truncate size: \" + newLength + \".\");\n      }\n      // Perform INodeFile truncation.\n      final QuotaCounts delta \u003d new QuotaCounts.Builder().build();\n      onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n          toRemoveBlocks, mtime, delta);\n      if (!onBlockBoundary) {\n        // Open file for write, but don\u0027t log into edits\n        long lastBlockDelta \u003d file.computeFileSize() - newLength;\n        assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n        truncateBlock \u003d prepareFileForTruncate(fsn, iip, clientName,\n            clientMachine, lastBlockDelta, null);\n      }\n\n      // update the quota: use the preferred block size for UC block\n      fsd.updateCountNoQuotaCheck(iip, iip.length() - 1, delta);\n    } finally {\n      fsd.writeUnlock();\n    }\n\n    fsn.getEditLog().logTruncate(src, clientName, clientMachine, newLength,\n        mtime, truncateBlock);\n    return new TruncateResult(onBlockBoundary, fsd.getAuditFileInfo(iip));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirTruncateOp.java",
      "extendedDetails": {}
    },
    "31f117138a00794de4951ee8433e304d72b04094": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8495. Consolidate append() related implementation into a single class. Contributed by Rakesh R.\n",
      "commitDate": "21/07/15 5:25 PM",
      "commitName": "31f117138a00794de4951ee8433e304d72b04094",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "29/06/15 4:45 PM",
      "commitNameOld": "d3797f9f3cf502b7bfee3b64c641807b276c6faf",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 22.03,
      "commitsBetweenForRepo": 136,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,80 +1,80 @@\n   static TruncateResult truncate(final FSNamesystem fsn, final String srcArg,\n       final long newLength, final String clientName,\n       final String clientMachine, final long mtime,\n       final BlocksMapUpdateInfo toRemoveBlocks, final FSPermissionChecker pc)\n       throws IOException, UnresolvedLinkException {\n     assert fsn.hasWriteLock();\n \n     FSDirectory fsd \u003d fsn.getFSDirectory();\n     byte[][] pathComponents \u003d FSDirectory\n         .getPathComponentsForReservedPath(srcArg);\n     final String src;\n     final INodesInPath iip;\n     final boolean onBlockBoundary;\n     Block truncateBlock \u003d null;\n     fsd.writeLock();\n     try {\n       src \u003d fsd.resolvePath(pc, srcArg, pathComponents);\n       iip \u003d fsd.getINodesInPath4Write(src, true);\n-      if (fsn.isPermissionEnabled()) {\n+      if (fsd.isPermissionEnabled()) {\n         fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n       }\n       INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n-      final BlockStoragePolicy lpPolicy \u003d fsn.getBlockManager()\n+      final BlockStoragePolicy lpPolicy \u003d fsd.getBlockManager()\n           .getStoragePolicy(\"LAZY_PERSIST\");\n \n       if (lpPolicy !\u003d null \u0026\u0026 lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n         throw new UnsupportedOperationException(\n             \"Cannot truncate lazy persist file \" + src);\n       }\n \n       // Check if the file is already being truncated with the same length\n       final BlockInfo last \u003d file.getLastBlock();\n       if (last !\u003d null \u0026\u0026 last.getBlockUCState()\n           \u003d\u003d BlockUCState.UNDER_RECOVERY) {\n         final Block truncatedBlock \u003d ((BlockInfoUnderConstruction) last)\n             .getTruncateBlock();\n         if (truncatedBlock !\u003d null) {\n           final long truncateLength \u003d file.computeFileSize(false, false)\n               + truncatedBlock.getNumBytes();\n           if (newLength \u003d\u003d truncateLength) {\n             return new TruncateResult(false, fsd.getAuditFileInfo(iip));\n           }\n         }\n       }\n \n       // Opening an existing file for truncate. May need lease recovery.\n       fsn.recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE, iip, src,\n           clientName, clientMachine, false);\n       // Truncate length check.\n       long oldLength \u003d file.computeFileSize();\n       if (oldLength \u003d\u003d newLength) {\n         return new TruncateResult(true, fsd.getAuditFileInfo(iip));\n       }\n       if (oldLength \u003c newLength) {\n         throw new HadoopIllegalArgumentException(\n             \"Cannot truncate to a larger file size. Current size: \" + oldLength\n                 + \", truncate size: \" + newLength + \".\");\n       }\n       // Perform INodeFile truncation.\n       final QuotaCounts delta \u003d new QuotaCounts.Builder().build();\n       onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n           toRemoveBlocks, mtime, delta);\n       if (!onBlockBoundary) {\n         // Open file for write, but don\u0027t log into edits\n         long lastBlockDelta \u003d file.computeFileSize() - newLength;\n         assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n         truncateBlock \u003d prepareFileForTruncate(fsn, iip, clientName,\n             clientMachine, lastBlockDelta, null);\n       }\n \n       // update the quota: use the preferred block size for UC block\n       fsd.updateCountNoQuotaCheck(iip, iip.length() - 1, delta);\n     } finally {\n       fsd.writeUnlock();\n     }\n \n     fsn.getEditLog().logTruncate(src, clientName, clientMachine, newLength,\n         mtime, truncateBlock);\n     return new TruncateResult(onBlockBoundary, fsd.getAuditFileInfo(iip));\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static TruncateResult truncate(final FSNamesystem fsn, final String srcArg,\n      final long newLength, final String clientName,\n      final String clientMachine, final long mtime,\n      final BlocksMapUpdateInfo toRemoveBlocks, final FSPermissionChecker pc)\n      throws IOException, UnresolvedLinkException {\n    assert fsn.hasWriteLock();\n\n    FSDirectory fsd \u003d fsn.getFSDirectory();\n    byte[][] pathComponents \u003d FSDirectory\n        .getPathComponentsForReservedPath(srcArg);\n    final String src;\n    final INodesInPath iip;\n    final boolean onBlockBoundary;\n    Block truncateBlock \u003d null;\n    fsd.writeLock();\n    try {\n      src \u003d fsd.resolvePath(pc, srcArg, pathComponents);\n      iip \u003d fsd.getINodesInPath4Write(src, true);\n      if (fsd.isPermissionEnabled()) {\n        fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n      }\n      INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n      final BlockStoragePolicy lpPolicy \u003d fsd.getBlockManager()\n          .getStoragePolicy(\"LAZY_PERSIST\");\n\n      if (lpPolicy !\u003d null \u0026\u0026 lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n        throw new UnsupportedOperationException(\n            \"Cannot truncate lazy persist file \" + src);\n      }\n\n      // Check if the file is already being truncated with the same length\n      final BlockInfo last \u003d file.getLastBlock();\n      if (last !\u003d null \u0026\u0026 last.getBlockUCState()\n          \u003d\u003d BlockUCState.UNDER_RECOVERY) {\n        final Block truncatedBlock \u003d ((BlockInfoUnderConstruction) last)\n            .getTruncateBlock();\n        if (truncatedBlock !\u003d null) {\n          final long truncateLength \u003d file.computeFileSize(false, false)\n              + truncatedBlock.getNumBytes();\n          if (newLength \u003d\u003d truncateLength) {\n            return new TruncateResult(false, fsd.getAuditFileInfo(iip));\n          }\n        }\n      }\n\n      // Opening an existing file for truncate. May need lease recovery.\n      fsn.recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE, iip, src,\n          clientName, clientMachine, false);\n      // Truncate length check.\n      long oldLength \u003d file.computeFileSize();\n      if (oldLength \u003d\u003d newLength) {\n        return new TruncateResult(true, fsd.getAuditFileInfo(iip));\n      }\n      if (oldLength \u003c newLength) {\n        throw new HadoopIllegalArgumentException(\n            \"Cannot truncate to a larger file size. Current size: \" + oldLength\n                + \", truncate size: \" + newLength + \".\");\n      }\n      // Perform INodeFile truncation.\n      final QuotaCounts delta \u003d new QuotaCounts.Builder().build();\n      onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n          toRemoveBlocks, mtime, delta);\n      if (!onBlockBoundary) {\n        // Open file for write, but don\u0027t log into edits\n        long lastBlockDelta \u003d file.computeFileSize() - newLength;\n        assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n        truncateBlock \u003d prepareFileForTruncate(fsn, iip, clientName,\n            clientMachine, lastBlockDelta, null);\n      }\n\n      // update the quota: use the preferred block size for UC block\n      fsd.updateCountNoQuotaCheck(iip, iip.length() - 1, delta);\n    } finally {\n      fsd.writeUnlock();\n    }\n\n    fsn.getEditLog().logTruncate(src, clientName, clientMachine, newLength,\n        mtime, truncateBlock);\n    return new TruncateResult(onBlockBoundary, fsd.getAuditFileInfo(iip));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirTruncateOp.java",
      "extendedDetails": {}
    },
    "d3797f9f3cf502b7bfee3b64c641807b276c6faf": {
      "type": "Ymultichange(Ymovefromfile,Yreturntypechange,Ymodifierchange,Ybodychange,Yparametermetachange,Yrename,Yparameterchange)",
      "commitMessage": "HDFS-8493. Consolidate truncate() related implementation in a single class. Contributed by Rakesh R.\n",
      "commitDate": "29/06/15 4:45 PM",
      "commitName": "d3797f9f3cf502b7bfee3b64c641807b276c6faf",
      "commitAuthor": "Haohui Mai",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-8493. Consolidate truncate() related implementation in a single class. Contributed by Rakesh R.\n",
          "commitDate": "29/06/15 4:45 PM",
          "commitName": "d3797f9f3cf502b7bfee3b64c641807b276c6faf",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "29/06/15 2:56 PM",
          "commitNameOld": "8e333720e13428a4d0d0f65692102f8f2e5da98d",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 0.08,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,72 +1,80 @@\n-  boolean truncateInternal(String src, long newLength,\n-                           String clientName, String clientMachine,\n-                           long mtime, FSPermissionChecker pc,\n-                           BlocksMapUpdateInfo toRemoveBlocks)\n+  static TruncateResult truncate(final FSNamesystem fsn, final String srcArg,\n+      final long newLength, final String clientName,\n+      final String clientMachine, final long mtime,\n+      final BlocksMapUpdateInfo toRemoveBlocks, final FSPermissionChecker pc)\n       throws IOException, UnresolvedLinkException {\n-    assert hasWriteLock();\n-    INodesInPath iip \u003d dir.getINodesInPath4Write(src, true);\n-    if (isPermissionEnabled) {\n-      dir.checkPathAccess(pc, iip, FsAction.WRITE);\n-    }\n-    INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n-    final BlockStoragePolicy lpPolicy \u003d\n-        blockManager.getStoragePolicy(\"LAZY_PERSIST\");\n+    assert fsn.hasWriteLock();\n \n-    if (lpPolicy !\u003d null \u0026\u0026\n-        lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n-      throw new UnsupportedOperationException(\n-          \"Cannot truncate lazy persist file \" + src);\n-    }\n+    FSDirectory fsd \u003d fsn.getFSDirectory();\n+    byte[][] pathComponents \u003d FSDirectory\n+        .getPathComponentsForReservedPath(srcArg);\n+    final String src;\n+    final INodesInPath iip;\n+    final boolean onBlockBoundary;\n+    Block truncateBlock \u003d null;\n+    fsd.writeLock();\n+    try {\n+      src \u003d fsd.resolvePath(pc, srcArg, pathComponents);\n+      iip \u003d fsd.getINodesInPath4Write(src, true);\n+      if (fsn.isPermissionEnabled()) {\n+        fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n+      }\n+      INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n+      final BlockStoragePolicy lpPolicy \u003d fsn.getBlockManager()\n+          .getStoragePolicy(\"LAZY_PERSIST\");\n \n-    // Check if the file is already being truncated with the same length\n-    final BlockInfo last \u003d file.getLastBlock();\n-    if (last !\u003d null \u0026\u0026 last.getBlockUCState() \u003d\u003d BlockUCState.UNDER_RECOVERY) {\n-      final Block truncateBlock\n-          \u003d ((BlockInfoUnderConstruction)last).getTruncateBlock();\n-      if (truncateBlock !\u003d null) {\n-        final long truncateLength \u003d file.computeFileSize(false, false)\n-            + truncateBlock.getNumBytes();\n-        if (newLength \u003d\u003d truncateLength) {\n-          return false;\n+      if (lpPolicy !\u003d null \u0026\u0026 lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n+        throw new UnsupportedOperationException(\n+            \"Cannot truncate lazy persist file \" + src);\n+      }\n+\n+      // Check if the file is already being truncated with the same length\n+      final BlockInfo last \u003d file.getLastBlock();\n+      if (last !\u003d null \u0026\u0026 last.getBlockUCState()\n+          \u003d\u003d BlockUCState.UNDER_RECOVERY) {\n+        final Block truncatedBlock \u003d ((BlockInfoUnderConstruction) last)\n+            .getTruncateBlock();\n+        if (truncatedBlock !\u003d null) {\n+          final long truncateLength \u003d file.computeFileSize(false, false)\n+              + truncatedBlock.getNumBytes();\n+          if (newLength \u003d\u003d truncateLength) {\n+            return new TruncateResult(false, fsd.getAuditFileInfo(iip));\n+          }\n         }\n       }\n-    }\n \n-    // Opening an existing file for truncate. May need lease recovery.\n-    recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE,\n-        iip, src, clientName, clientMachine, false);\n-    // Truncate length check.\n-    long oldLength \u003d file.computeFileSize();\n-    if(oldLength \u003d\u003d newLength) {\n-      return true;\n-    }\n-    if(oldLength \u003c newLength) {\n-      throw new HadoopIllegalArgumentException(\n-          \"Cannot truncate to a larger file size. Current size: \" + oldLength +\n-              \", truncate size: \" + newLength + \".\");\n-    }\n-    // Perform INodeFile truncation.\n-    final QuotaCounts delta \u003d new QuotaCounts.Builder().build();\n-    boolean onBlockBoundary \u003d dir.truncate(iip, newLength, toRemoveBlocks,\n-        mtime, delta);\n-    Block truncateBlock \u003d null;\n-    if(!onBlockBoundary) {\n-      // Open file for write, but don\u0027t log into edits\n-      long lastBlockDelta \u003d file.computeFileSize() - newLength;\n-      assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n-      truncateBlock \u003d prepareFileForTruncate(iip, clientName, clientMachine,\n-          lastBlockDelta, null);\n-    }\n+      // Opening an existing file for truncate. May need lease recovery.\n+      fsn.recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE, iip, src,\n+          clientName, clientMachine, false);\n+      // Truncate length check.\n+      long oldLength \u003d file.computeFileSize();\n+      if (oldLength \u003d\u003d newLength) {\n+        return new TruncateResult(true, fsd.getAuditFileInfo(iip));\n+      }\n+      if (oldLength \u003c newLength) {\n+        throw new HadoopIllegalArgumentException(\n+            \"Cannot truncate to a larger file size. Current size: \" + oldLength\n+                + \", truncate size: \" + newLength + \".\");\n+      }\n+      // Perform INodeFile truncation.\n+      final QuotaCounts delta \u003d new QuotaCounts.Builder().build();\n+      onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n+          toRemoveBlocks, mtime, delta);\n+      if (!onBlockBoundary) {\n+        // Open file for write, but don\u0027t log into edits\n+        long lastBlockDelta \u003d file.computeFileSize() - newLength;\n+        assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n+        truncateBlock \u003d prepareFileForTruncate(fsn, iip, clientName,\n+            clientMachine, lastBlockDelta, null);\n+      }\n \n-    // update the quota: use the preferred block size for UC block\n-    dir.writeLock();\n-    try {\n-      dir.updateCountNoQuotaCheck(iip, iip.length() - 1, delta);\n+      // update the quota: use the preferred block size for UC block\n+      fsd.updateCountNoQuotaCheck(iip, iip.length() - 1, delta);\n     } finally {\n-      dir.writeUnlock();\n+      fsd.writeUnlock();\n     }\n \n-    getEditLog().logTruncate(src, clientName, clientMachine, newLength, mtime,\n-        truncateBlock);\n-    return onBlockBoundary;\n+    fsn.getEditLog().logTruncate(src, clientName, clientMachine, newLength,\n+        mtime, truncateBlock);\n+    return new TruncateResult(onBlockBoundary, fsd.getAuditFileInfo(iip));\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static TruncateResult truncate(final FSNamesystem fsn, final String srcArg,\n      final long newLength, final String clientName,\n      final String clientMachine, final long mtime,\n      final BlocksMapUpdateInfo toRemoveBlocks, final FSPermissionChecker pc)\n      throws IOException, UnresolvedLinkException {\n    assert fsn.hasWriteLock();\n\n    FSDirectory fsd \u003d fsn.getFSDirectory();\n    byte[][] pathComponents \u003d FSDirectory\n        .getPathComponentsForReservedPath(srcArg);\n    final String src;\n    final INodesInPath iip;\n    final boolean onBlockBoundary;\n    Block truncateBlock \u003d null;\n    fsd.writeLock();\n    try {\n      src \u003d fsd.resolvePath(pc, srcArg, pathComponents);\n      iip \u003d fsd.getINodesInPath4Write(src, true);\n      if (fsn.isPermissionEnabled()) {\n        fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n      }\n      INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n      final BlockStoragePolicy lpPolicy \u003d fsn.getBlockManager()\n          .getStoragePolicy(\"LAZY_PERSIST\");\n\n      if (lpPolicy !\u003d null \u0026\u0026 lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n        throw new UnsupportedOperationException(\n            \"Cannot truncate lazy persist file \" + src);\n      }\n\n      // Check if the file is already being truncated with the same length\n      final BlockInfo last \u003d file.getLastBlock();\n      if (last !\u003d null \u0026\u0026 last.getBlockUCState()\n          \u003d\u003d BlockUCState.UNDER_RECOVERY) {\n        final Block truncatedBlock \u003d ((BlockInfoUnderConstruction) last)\n            .getTruncateBlock();\n        if (truncatedBlock !\u003d null) {\n          final long truncateLength \u003d file.computeFileSize(false, false)\n              + truncatedBlock.getNumBytes();\n          if (newLength \u003d\u003d truncateLength) {\n            return new TruncateResult(false, fsd.getAuditFileInfo(iip));\n          }\n        }\n      }\n\n      // Opening an existing file for truncate. May need lease recovery.\n      fsn.recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE, iip, src,\n          clientName, clientMachine, false);\n      // Truncate length check.\n      long oldLength \u003d file.computeFileSize();\n      if (oldLength \u003d\u003d newLength) {\n        return new TruncateResult(true, fsd.getAuditFileInfo(iip));\n      }\n      if (oldLength \u003c newLength) {\n        throw new HadoopIllegalArgumentException(\n            \"Cannot truncate to a larger file size. Current size: \" + oldLength\n                + \", truncate size: \" + newLength + \".\");\n      }\n      // Perform INodeFile truncation.\n      final QuotaCounts delta \u003d new QuotaCounts.Builder().build();\n      onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n          toRemoveBlocks, mtime, delta);\n      if (!onBlockBoundary) {\n        // Open file for write, but don\u0027t log into edits\n        long lastBlockDelta \u003d file.computeFileSize() - newLength;\n        assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n        truncateBlock \u003d prepareFileForTruncate(fsn, iip, clientName,\n            clientMachine, lastBlockDelta, null);\n      }\n\n      // update the quota: use the preferred block size for UC block\n      fsd.updateCountNoQuotaCheck(iip, iip.length() - 1, delta);\n    } finally {\n      fsd.writeUnlock();\n    }\n\n    fsn.getEditLog().logTruncate(src, clientName, clientMachine, newLength,\n        mtime, truncateBlock);\n    return new TruncateResult(onBlockBoundary, fsd.getAuditFileInfo(iip));\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirTruncateOp.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirTruncateOp.java",
            "oldMethodName": "truncateInternal",
            "newMethodName": "truncate"
          }
        },
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-8493. Consolidate truncate() related implementation in a single class. Contributed by Rakesh R.\n",
          "commitDate": "29/06/15 4:45 PM",
          "commitName": "d3797f9f3cf502b7bfee3b64c641807b276c6faf",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "29/06/15 2:56 PM",
          "commitNameOld": "8e333720e13428a4d0d0f65692102f8f2e5da98d",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 0.08,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,72 +1,80 @@\n-  boolean truncateInternal(String src, long newLength,\n-                           String clientName, String clientMachine,\n-                           long mtime, FSPermissionChecker pc,\n-                           BlocksMapUpdateInfo toRemoveBlocks)\n+  static TruncateResult truncate(final FSNamesystem fsn, final String srcArg,\n+      final long newLength, final String clientName,\n+      final String clientMachine, final long mtime,\n+      final BlocksMapUpdateInfo toRemoveBlocks, final FSPermissionChecker pc)\n       throws IOException, UnresolvedLinkException {\n-    assert hasWriteLock();\n-    INodesInPath iip \u003d dir.getINodesInPath4Write(src, true);\n-    if (isPermissionEnabled) {\n-      dir.checkPathAccess(pc, iip, FsAction.WRITE);\n-    }\n-    INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n-    final BlockStoragePolicy lpPolicy \u003d\n-        blockManager.getStoragePolicy(\"LAZY_PERSIST\");\n+    assert fsn.hasWriteLock();\n \n-    if (lpPolicy !\u003d null \u0026\u0026\n-        lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n-      throw new UnsupportedOperationException(\n-          \"Cannot truncate lazy persist file \" + src);\n-    }\n+    FSDirectory fsd \u003d fsn.getFSDirectory();\n+    byte[][] pathComponents \u003d FSDirectory\n+        .getPathComponentsForReservedPath(srcArg);\n+    final String src;\n+    final INodesInPath iip;\n+    final boolean onBlockBoundary;\n+    Block truncateBlock \u003d null;\n+    fsd.writeLock();\n+    try {\n+      src \u003d fsd.resolvePath(pc, srcArg, pathComponents);\n+      iip \u003d fsd.getINodesInPath4Write(src, true);\n+      if (fsn.isPermissionEnabled()) {\n+        fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n+      }\n+      INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n+      final BlockStoragePolicy lpPolicy \u003d fsn.getBlockManager()\n+          .getStoragePolicy(\"LAZY_PERSIST\");\n \n-    // Check if the file is already being truncated with the same length\n-    final BlockInfo last \u003d file.getLastBlock();\n-    if (last !\u003d null \u0026\u0026 last.getBlockUCState() \u003d\u003d BlockUCState.UNDER_RECOVERY) {\n-      final Block truncateBlock\n-          \u003d ((BlockInfoUnderConstruction)last).getTruncateBlock();\n-      if (truncateBlock !\u003d null) {\n-        final long truncateLength \u003d file.computeFileSize(false, false)\n-            + truncateBlock.getNumBytes();\n-        if (newLength \u003d\u003d truncateLength) {\n-          return false;\n+      if (lpPolicy !\u003d null \u0026\u0026 lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n+        throw new UnsupportedOperationException(\n+            \"Cannot truncate lazy persist file \" + src);\n+      }\n+\n+      // Check if the file is already being truncated with the same length\n+      final BlockInfo last \u003d file.getLastBlock();\n+      if (last !\u003d null \u0026\u0026 last.getBlockUCState()\n+          \u003d\u003d BlockUCState.UNDER_RECOVERY) {\n+        final Block truncatedBlock \u003d ((BlockInfoUnderConstruction) last)\n+            .getTruncateBlock();\n+        if (truncatedBlock !\u003d null) {\n+          final long truncateLength \u003d file.computeFileSize(false, false)\n+              + truncatedBlock.getNumBytes();\n+          if (newLength \u003d\u003d truncateLength) {\n+            return new TruncateResult(false, fsd.getAuditFileInfo(iip));\n+          }\n         }\n       }\n-    }\n \n-    // Opening an existing file for truncate. May need lease recovery.\n-    recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE,\n-        iip, src, clientName, clientMachine, false);\n-    // Truncate length check.\n-    long oldLength \u003d file.computeFileSize();\n-    if(oldLength \u003d\u003d newLength) {\n-      return true;\n-    }\n-    if(oldLength \u003c newLength) {\n-      throw new HadoopIllegalArgumentException(\n-          \"Cannot truncate to a larger file size. Current size: \" + oldLength +\n-              \", truncate size: \" + newLength + \".\");\n-    }\n-    // Perform INodeFile truncation.\n-    final QuotaCounts delta \u003d new QuotaCounts.Builder().build();\n-    boolean onBlockBoundary \u003d dir.truncate(iip, newLength, toRemoveBlocks,\n-        mtime, delta);\n-    Block truncateBlock \u003d null;\n-    if(!onBlockBoundary) {\n-      // Open file for write, but don\u0027t log into edits\n-      long lastBlockDelta \u003d file.computeFileSize() - newLength;\n-      assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n-      truncateBlock \u003d prepareFileForTruncate(iip, clientName, clientMachine,\n-          lastBlockDelta, null);\n-    }\n+      // Opening an existing file for truncate. May need lease recovery.\n+      fsn.recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE, iip, src,\n+          clientName, clientMachine, false);\n+      // Truncate length check.\n+      long oldLength \u003d file.computeFileSize();\n+      if (oldLength \u003d\u003d newLength) {\n+        return new TruncateResult(true, fsd.getAuditFileInfo(iip));\n+      }\n+      if (oldLength \u003c newLength) {\n+        throw new HadoopIllegalArgumentException(\n+            \"Cannot truncate to a larger file size. Current size: \" + oldLength\n+                + \", truncate size: \" + newLength + \".\");\n+      }\n+      // Perform INodeFile truncation.\n+      final QuotaCounts delta \u003d new QuotaCounts.Builder().build();\n+      onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n+          toRemoveBlocks, mtime, delta);\n+      if (!onBlockBoundary) {\n+        // Open file for write, but don\u0027t log into edits\n+        long lastBlockDelta \u003d file.computeFileSize() - newLength;\n+        assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n+        truncateBlock \u003d prepareFileForTruncate(fsn, iip, clientName,\n+            clientMachine, lastBlockDelta, null);\n+      }\n \n-    // update the quota: use the preferred block size for UC block\n-    dir.writeLock();\n-    try {\n-      dir.updateCountNoQuotaCheck(iip, iip.length() - 1, delta);\n+      // update the quota: use the preferred block size for UC block\n+      fsd.updateCountNoQuotaCheck(iip, iip.length() - 1, delta);\n     } finally {\n-      dir.writeUnlock();\n+      fsd.writeUnlock();\n     }\n \n-    getEditLog().logTruncate(src, clientName, clientMachine, newLength, mtime,\n-        truncateBlock);\n-    return onBlockBoundary;\n+    fsn.getEditLog().logTruncate(src, clientName, clientMachine, newLength,\n+        mtime, truncateBlock);\n+    return new TruncateResult(onBlockBoundary, fsd.getAuditFileInfo(iip));\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static TruncateResult truncate(final FSNamesystem fsn, final String srcArg,\n      final long newLength, final String clientName,\n      final String clientMachine, final long mtime,\n      final BlocksMapUpdateInfo toRemoveBlocks, final FSPermissionChecker pc)\n      throws IOException, UnresolvedLinkException {\n    assert fsn.hasWriteLock();\n\n    FSDirectory fsd \u003d fsn.getFSDirectory();\n    byte[][] pathComponents \u003d FSDirectory\n        .getPathComponentsForReservedPath(srcArg);\n    final String src;\n    final INodesInPath iip;\n    final boolean onBlockBoundary;\n    Block truncateBlock \u003d null;\n    fsd.writeLock();\n    try {\n      src \u003d fsd.resolvePath(pc, srcArg, pathComponents);\n      iip \u003d fsd.getINodesInPath4Write(src, true);\n      if (fsn.isPermissionEnabled()) {\n        fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n      }\n      INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n      final BlockStoragePolicy lpPolicy \u003d fsn.getBlockManager()\n          .getStoragePolicy(\"LAZY_PERSIST\");\n\n      if (lpPolicy !\u003d null \u0026\u0026 lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n        throw new UnsupportedOperationException(\n            \"Cannot truncate lazy persist file \" + src);\n      }\n\n      // Check if the file is already being truncated with the same length\n      final BlockInfo last \u003d file.getLastBlock();\n      if (last !\u003d null \u0026\u0026 last.getBlockUCState()\n          \u003d\u003d BlockUCState.UNDER_RECOVERY) {\n        final Block truncatedBlock \u003d ((BlockInfoUnderConstruction) last)\n            .getTruncateBlock();\n        if (truncatedBlock !\u003d null) {\n          final long truncateLength \u003d file.computeFileSize(false, false)\n              + truncatedBlock.getNumBytes();\n          if (newLength \u003d\u003d truncateLength) {\n            return new TruncateResult(false, fsd.getAuditFileInfo(iip));\n          }\n        }\n      }\n\n      // Opening an existing file for truncate. May need lease recovery.\n      fsn.recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE, iip, src,\n          clientName, clientMachine, false);\n      // Truncate length check.\n      long oldLength \u003d file.computeFileSize();\n      if (oldLength \u003d\u003d newLength) {\n        return new TruncateResult(true, fsd.getAuditFileInfo(iip));\n      }\n      if (oldLength \u003c newLength) {\n        throw new HadoopIllegalArgumentException(\n            \"Cannot truncate to a larger file size. Current size: \" + oldLength\n                + \", truncate size: \" + newLength + \".\");\n      }\n      // Perform INodeFile truncation.\n      final QuotaCounts delta \u003d new QuotaCounts.Builder().build();\n      onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n          toRemoveBlocks, mtime, delta);\n      if (!onBlockBoundary) {\n        // Open file for write, but don\u0027t log into edits\n        long lastBlockDelta \u003d file.computeFileSize() - newLength;\n        assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n        truncateBlock \u003d prepareFileForTruncate(fsn, iip, clientName,\n            clientMachine, lastBlockDelta, null);\n      }\n\n      // update the quota: use the preferred block size for UC block\n      fsd.updateCountNoQuotaCheck(iip, iip.length() - 1, delta);\n    } finally {\n      fsd.writeUnlock();\n    }\n\n    fsn.getEditLog().logTruncate(src, clientName, clientMachine, newLength,\n        mtime, truncateBlock);\n    return new TruncateResult(onBlockBoundary, fsd.getAuditFileInfo(iip));\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirTruncateOp.java",
          "extendedDetails": {
            "oldValue": "boolean",
            "newValue": "TruncateResult"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-8493. Consolidate truncate() related implementation in a single class. Contributed by Rakesh R.\n",
          "commitDate": "29/06/15 4:45 PM",
          "commitName": "d3797f9f3cf502b7bfee3b64c641807b276c6faf",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "29/06/15 2:56 PM",
          "commitNameOld": "8e333720e13428a4d0d0f65692102f8f2e5da98d",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 0.08,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,72 +1,80 @@\n-  boolean truncateInternal(String src, long newLength,\n-                           String clientName, String clientMachine,\n-                           long mtime, FSPermissionChecker pc,\n-                           BlocksMapUpdateInfo toRemoveBlocks)\n+  static TruncateResult truncate(final FSNamesystem fsn, final String srcArg,\n+      final long newLength, final String clientName,\n+      final String clientMachine, final long mtime,\n+      final BlocksMapUpdateInfo toRemoveBlocks, final FSPermissionChecker pc)\n       throws IOException, UnresolvedLinkException {\n-    assert hasWriteLock();\n-    INodesInPath iip \u003d dir.getINodesInPath4Write(src, true);\n-    if (isPermissionEnabled) {\n-      dir.checkPathAccess(pc, iip, FsAction.WRITE);\n-    }\n-    INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n-    final BlockStoragePolicy lpPolicy \u003d\n-        blockManager.getStoragePolicy(\"LAZY_PERSIST\");\n+    assert fsn.hasWriteLock();\n \n-    if (lpPolicy !\u003d null \u0026\u0026\n-        lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n-      throw new UnsupportedOperationException(\n-          \"Cannot truncate lazy persist file \" + src);\n-    }\n+    FSDirectory fsd \u003d fsn.getFSDirectory();\n+    byte[][] pathComponents \u003d FSDirectory\n+        .getPathComponentsForReservedPath(srcArg);\n+    final String src;\n+    final INodesInPath iip;\n+    final boolean onBlockBoundary;\n+    Block truncateBlock \u003d null;\n+    fsd.writeLock();\n+    try {\n+      src \u003d fsd.resolvePath(pc, srcArg, pathComponents);\n+      iip \u003d fsd.getINodesInPath4Write(src, true);\n+      if (fsn.isPermissionEnabled()) {\n+        fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n+      }\n+      INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n+      final BlockStoragePolicy lpPolicy \u003d fsn.getBlockManager()\n+          .getStoragePolicy(\"LAZY_PERSIST\");\n \n-    // Check if the file is already being truncated with the same length\n-    final BlockInfo last \u003d file.getLastBlock();\n-    if (last !\u003d null \u0026\u0026 last.getBlockUCState() \u003d\u003d BlockUCState.UNDER_RECOVERY) {\n-      final Block truncateBlock\n-          \u003d ((BlockInfoUnderConstruction)last).getTruncateBlock();\n-      if (truncateBlock !\u003d null) {\n-        final long truncateLength \u003d file.computeFileSize(false, false)\n-            + truncateBlock.getNumBytes();\n-        if (newLength \u003d\u003d truncateLength) {\n-          return false;\n+      if (lpPolicy !\u003d null \u0026\u0026 lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n+        throw new UnsupportedOperationException(\n+            \"Cannot truncate lazy persist file \" + src);\n+      }\n+\n+      // Check if the file is already being truncated with the same length\n+      final BlockInfo last \u003d file.getLastBlock();\n+      if (last !\u003d null \u0026\u0026 last.getBlockUCState()\n+          \u003d\u003d BlockUCState.UNDER_RECOVERY) {\n+        final Block truncatedBlock \u003d ((BlockInfoUnderConstruction) last)\n+            .getTruncateBlock();\n+        if (truncatedBlock !\u003d null) {\n+          final long truncateLength \u003d file.computeFileSize(false, false)\n+              + truncatedBlock.getNumBytes();\n+          if (newLength \u003d\u003d truncateLength) {\n+            return new TruncateResult(false, fsd.getAuditFileInfo(iip));\n+          }\n         }\n       }\n-    }\n \n-    // Opening an existing file for truncate. May need lease recovery.\n-    recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE,\n-        iip, src, clientName, clientMachine, false);\n-    // Truncate length check.\n-    long oldLength \u003d file.computeFileSize();\n-    if(oldLength \u003d\u003d newLength) {\n-      return true;\n-    }\n-    if(oldLength \u003c newLength) {\n-      throw new HadoopIllegalArgumentException(\n-          \"Cannot truncate to a larger file size. Current size: \" + oldLength +\n-              \", truncate size: \" + newLength + \".\");\n-    }\n-    // Perform INodeFile truncation.\n-    final QuotaCounts delta \u003d new QuotaCounts.Builder().build();\n-    boolean onBlockBoundary \u003d dir.truncate(iip, newLength, toRemoveBlocks,\n-        mtime, delta);\n-    Block truncateBlock \u003d null;\n-    if(!onBlockBoundary) {\n-      // Open file for write, but don\u0027t log into edits\n-      long lastBlockDelta \u003d file.computeFileSize() - newLength;\n-      assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n-      truncateBlock \u003d prepareFileForTruncate(iip, clientName, clientMachine,\n-          lastBlockDelta, null);\n-    }\n+      // Opening an existing file for truncate. May need lease recovery.\n+      fsn.recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE, iip, src,\n+          clientName, clientMachine, false);\n+      // Truncate length check.\n+      long oldLength \u003d file.computeFileSize();\n+      if (oldLength \u003d\u003d newLength) {\n+        return new TruncateResult(true, fsd.getAuditFileInfo(iip));\n+      }\n+      if (oldLength \u003c newLength) {\n+        throw new HadoopIllegalArgumentException(\n+            \"Cannot truncate to a larger file size. Current size: \" + oldLength\n+                + \", truncate size: \" + newLength + \".\");\n+      }\n+      // Perform INodeFile truncation.\n+      final QuotaCounts delta \u003d new QuotaCounts.Builder().build();\n+      onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n+          toRemoveBlocks, mtime, delta);\n+      if (!onBlockBoundary) {\n+        // Open file for write, but don\u0027t log into edits\n+        long lastBlockDelta \u003d file.computeFileSize() - newLength;\n+        assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n+        truncateBlock \u003d prepareFileForTruncate(fsn, iip, clientName,\n+            clientMachine, lastBlockDelta, null);\n+      }\n \n-    // update the quota: use the preferred block size for UC block\n-    dir.writeLock();\n-    try {\n-      dir.updateCountNoQuotaCheck(iip, iip.length() - 1, delta);\n+      // update the quota: use the preferred block size for UC block\n+      fsd.updateCountNoQuotaCheck(iip, iip.length() - 1, delta);\n     } finally {\n-      dir.writeUnlock();\n+      fsd.writeUnlock();\n     }\n \n-    getEditLog().logTruncate(src, clientName, clientMachine, newLength, mtime,\n-        truncateBlock);\n-    return onBlockBoundary;\n+    fsn.getEditLog().logTruncate(src, clientName, clientMachine, newLength,\n+        mtime, truncateBlock);\n+    return new TruncateResult(onBlockBoundary, fsd.getAuditFileInfo(iip));\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static TruncateResult truncate(final FSNamesystem fsn, final String srcArg,\n      final long newLength, final String clientName,\n      final String clientMachine, final long mtime,\n      final BlocksMapUpdateInfo toRemoveBlocks, final FSPermissionChecker pc)\n      throws IOException, UnresolvedLinkException {\n    assert fsn.hasWriteLock();\n\n    FSDirectory fsd \u003d fsn.getFSDirectory();\n    byte[][] pathComponents \u003d FSDirectory\n        .getPathComponentsForReservedPath(srcArg);\n    final String src;\n    final INodesInPath iip;\n    final boolean onBlockBoundary;\n    Block truncateBlock \u003d null;\n    fsd.writeLock();\n    try {\n      src \u003d fsd.resolvePath(pc, srcArg, pathComponents);\n      iip \u003d fsd.getINodesInPath4Write(src, true);\n      if (fsn.isPermissionEnabled()) {\n        fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n      }\n      INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n      final BlockStoragePolicy lpPolicy \u003d fsn.getBlockManager()\n          .getStoragePolicy(\"LAZY_PERSIST\");\n\n      if (lpPolicy !\u003d null \u0026\u0026 lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n        throw new UnsupportedOperationException(\n            \"Cannot truncate lazy persist file \" + src);\n      }\n\n      // Check if the file is already being truncated with the same length\n      final BlockInfo last \u003d file.getLastBlock();\n      if (last !\u003d null \u0026\u0026 last.getBlockUCState()\n          \u003d\u003d BlockUCState.UNDER_RECOVERY) {\n        final Block truncatedBlock \u003d ((BlockInfoUnderConstruction) last)\n            .getTruncateBlock();\n        if (truncatedBlock !\u003d null) {\n          final long truncateLength \u003d file.computeFileSize(false, false)\n              + truncatedBlock.getNumBytes();\n          if (newLength \u003d\u003d truncateLength) {\n            return new TruncateResult(false, fsd.getAuditFileInfo(iip));\n          }\n        }\n      }\n\n      // Opening an existing file for truncate. May need lease recovery.\n      fsn.recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE, iip, src,\n          clientName, clientMachine, false);\n      // Truncate length check.\n      long oldLength \u003d file.computeFileSize();\n      if (oldLength \u003d\u003d newLength) {\n        return new TruncateResult(true, fsd.getAuditFileInfo(iip));\n      }\n      if (oldLength \u003c newLength) {\n        throw new HadoopIllegalArgumentException(\n            \"Cannot truncate to a larger file size. Current size: \" + oldLength\n                + \", truncate size: \" + newLength + \".\");\n      }\n      // Perform INodeFile truncation.\n      final QuotaCounts delta \u003d new QuotaCounts.Builder().build();\n      onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n          toRemoveBlocks, mtime, delta);\n      if (!onBlockBoundary) {\n        // Open file for write, but don\u0027t log into edits\n        long lastBlockDelta \u003d file.computeFileSize() - newLength;\n        assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n        truncateBlock \u003d prepareFileForTruncate(fsn, iip, clientName,\n            clientMachine, lastBlockDelta, null);\n      }\n\n      // update the quota: use the preferred block size for UC block\n      fsd.updateCountNoQuotaCheck(iip, iip.length() - 1, delta);\n    } finally {\n      fsd.writeUnlock();\n    }\n\n    fsn.getEditLog().logTruncate(src, clientName, clientMachine, newLength,\n        mtime, truncateBlock);\n    return new TruncateResult(onBlockBoundary, fsd.getAuditFileInfo(iip));\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirTruncateOp.java",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[static]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-8493. Consolidate truncate() related implementation in a single class. Contributed by Rakesh R.\n",
          "commitDate": "29/06/15 4:45 PM",
          "commitName": "d3797f9f3cf502b7bfee3b64c641807b276c6faf",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "29/06/15 2:56 PM",
          "commitNameOld": "8e333720e13428a4d0d0f65692102f8f2e5da98d",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 0.08,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,72 +1,80 @@\n-  boolean truncateInternal(String src, long newLength,\n-                           String clientName, String clientMachine,\n-                           long mtime, FSPermissionChecker pc,\n-                           BlocksMapUpdateInfo toRemoveBlocks)\n+  static TruncateResult truncate(final FSNamesystem fsn, final String srcArg,\n+      final long newLength, final String clientName,\n+      final String clientMachine, final long mtime,\n+      final BlocksMapUpdateInfo toRemoveBlocks, final FSPermissionChecker pc)\n       throws IOException, UnresolvedLinkException {\n-    assert hasWriteLock();\n-    INodesInPath iip \u003d dir.getINodesInPath4Write(src, true);\n-    if (isPermissionEnabled) {\n-      dir.checkPathAccess(pc, iip, FsAction.WRITE);\n-    }\n-    INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n-    final BlockStoragePolicy lpPolicy \u003d\n-        blockManager.getStoragePolicy(\"LAZY_PERSIST\");\n+    assert fsn.hasWriteLock();\n \n-    if (lpPolicy !\u003d null \u0026\u0026\n-        lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n-      throw new UnsupportedOperationException(\n-          \"Cannot truncate lazy persist file \" + src);\n-    }\n+    FSDirectory fsd \u003d fsn.getFSDirectory();\n+    byte[][] pathComponents \u003d FSDirectory\n+        .getPathComponentsForReservedPath(srcArg);\n+    final String src;\n+    final INodesInPath iip;\n+    final boolean onBlockBoundary;\n+    Block truncateBlock \u003d null;\n+    fsd.writeLock();\n+    try {\n+      src \u003d fsd.resolvePath(pc, srcArg, pathComponents);\n+      iip \u003d fsd.getINodesInPath4Write(src, true);\n+      if (fsn.isPermissionEnabled()) {\n+        fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n+      }\n+      INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n+      final BlockStoragePolicy lpPolicy \u003d fsn.getBlockManager()\n+          .getStoragePolicy(\"LAZY_PERSIST\");\n \n-    // Check if the file is already being truncated with the same length\n-    final BlockInfo last \u003d file.getLastBlock();\n-    if (last !\u003d null \u0026\u0026 last.getBlockUCState() \u003d\u003d BlockUCState.UNDER_RECOVERY) {\n-      final Block truncateBlock\n-          \u003d ((BlockInfoUnderConstruction)last).getTruncateBlock();\n-      if (truncateBlock !\u003d null) {\n-        final long truncateLength \u003d file.computeFileSize(false, false)\n-            + truncateBlock.getNumBytes();\n-        if (newLength \u003d\u003d truncateLength) {\n-          return false;\n+      if (lpPolicy !\u003d null \u0026\u0026 lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n+        throw new UnsupportedOperationException(\n+            \"Cannot truncate lazy persist file \" + src);\n+      }\n+\n+      // Check if the file is already being truncated with the same length\n+      final BlockInfo last \u003d file.getLastBlock();\n+      if (last !\u003d null \u0026\u0026 last.getBlockUCState()\n+          \u003d\u003d BlockUCState.UNDER_RECOVERY) {\n+        final Block truncatedBlock \u003d ((BlockInfoUnderConstruction) last)\n+            .getTruncateBlock();\n+        if (truncatedBlock !\u003d null) {\n+          final long truncateLength \u003d file.computeFileSize(false, false)\n+              + truncatedBlock.getNumBytes();\n+          if (newLength \u003d\u003d truncateLength) {\n+            return new TruncateResult(false, fsd.getAuditFileInfo(iip));\n+          }\n         }\n       }\n-    }\n \n-    // Opening an existing file for truncate. May need lease recovery.\n-    recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE,\n-        iip, src, clientName, clientMachine, false);\n-    // Truncate length check.\n-    long oldLength \u003d file.computeFileSize();\n-    if(oldLength \u003d\u003d newLength) {\n-      return true;\n-    }\n-    if(oldLength \u003c newLength) {\n-      throw new HadoopIllegalArgumentException(\n-          \"Cannot truncate to a larger file size. Current size: \" + oldLength +\n-              \", truncate size: \" + newLength + \".\");\n-    }\n-    // Perform INodeFile truncation.\n-    final QuotaCounts delta \u003d new QuotaCounts.Builder().build();\n-    boolean onBlockBoundary \u003d dir.truncate(iip, newLength, toRemoveBlocks,\n-        mtime, delta);\n-    Block truncateBlock \u003d null;\n-    if(!onBlockBoundary) {\n-      // Open file for write, but don\u0027t log into edits\n-      long lastBlockDelta \u003d file.computeFileSize() - newLength;\n-      assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n-      truncateBlock \u003d prepareFileForTruncate(iip, clientName, clientMachine,\n-          lastBlockDelta, null);\n-    }\n+      // Opening an existing file for truncate. May need lease recovery.\n+      fsn.recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE, iip, src,\n+          clientName, clientMachine, false);\n+      // Truncate length check.\n+      long oldLength \u003d file.computeFileSize();\n+      if (oldLength \u003d\u003d newLength) {\n+        return new TruncateResult(true, fsd.getAuditFileInfo(iip));\n+      }\n+      if (oldLength \u003c newLength) {\n+        throw new HadoopIllegalArgumentException(\n+            \"Cannot truncate to a larger file size. Current size: \" + oldLength\n+                + \", truncate size: \" + newLength + \".\");\n+      }\n+      // Perform INodeFile truncation.\n+      final QuotaCounts delta \u003d new QuotaCounts.Builder().build();\n+      onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n+          toRemoveBlocks, mtime, delta);\n+      if (!onBlockBoundary) {\n+        // Open file for write, but don\u0027t log into edits\n+        long lastBlockDelta \u003d file.computeFileSize() - newLength;\n+        assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n+        truncateBlock \u003d prepareFileForTruncate(fsn, iip, clientName,\n+            clientMachine, lastBlockDelta, null);\n+      }\n \n-    // update the quota: use the preferred block size for UC block\n-    dir.writeLock();\n-    try {\n-      dir.updateCountNoQuotaCheck(iip, iip.length() - 1, delta);\n+      // update the quota: use the preferred block size for UC block\n+      fsd.updateCountNoQuotaCheck(iip, iip.length() - 1, delta);\n     } finally {\n-      dir.writeUnlock();\n+      fsd.writeUnlock();\n     }\n \n-    getEditLog().logTruncate(src, clientName, clientMachine, newLength, mtime,\n-        truncateBlock);\n-    return onBlockBoundary;\n+    fsn.getEditLog().logTruncate(src, clientName, clientMachine, newLength,\n+        mtime, truncateBlock);\n+    return new TruncateResult(onBlockBoundary, fsd.getAuditFileInfo(iip));\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static TruncateResult truncate(final FSNamesystem fsn, final String srcArg,\n      final long newLength, final String clientName,\n      final String clientMachine, final long mtime,\n      final BlocksMapUpdateInfo toRemoveBlocks, final FSPermissionChecker pc)\n      throws IOException, UnresolvedLinkException {\n    assert fsn.hasWriteLock();\n\n    FSDirectory fsd \u003d fsn.getFSDirectory();\n    byte[][] pathComponents \u003d FSDirectory\n        .getPathComponentsForReservedPath(srcArg);\n    final String src;\n    final INodesInPath iip;\n    final boolean onBlockBoundary;\n    Block truncateBlock \u003d null;\n    fsd.writeLock();\n    try {\n      src \u003d fsd.resolvePath(pc, srcArg, pathComponents);\n      iip \u003d fsd.getINodesInPath4Write(src, true);\n      if (fsn.isPermissionEnabled()) {\n        fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n      }\n      INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n      final BlockStoragePolicy lpPolicy \u003d fsn.getBlockManager()\n          .getStoragePolicy(\"LAZY_PERSIST\");\n\n      if (lpPolicy !\u003d null \u0026\u0026 lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n        throw new UnsupportedOperationException(\n            \"Cannot truncate lazy persist file \" + src);\n      }\n\n      // Check if the file is already being truncated with the same length\n      final BlockInfo last \u003d file.getLastBlock();\n      if (last !\u003d null \u0026\u0026 last.getBlockUCState()\n          \u003d\u003d BlockUCState.UNDER_RECOVERY) {\n        final Block truncatedBlock \u003d ((BlockInfoUnderConstruction) last)\n            .getTruncateBlock();\n        if (truncatedBlock !\u003d null) {\n          final long truncateLength \u003d file.computeFileSize(false, false)\n              + truncatedBlock.getNumBytes();\n          if (newLength \u003d\u003d truncateLength) {\n            return new TruncateResult(false, fsd.getAuditFileInfo(iip));\n          }\n        }\n      }\n\n      // Opening an existing file for truncate. May need lease recovery.\n      fsn.recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE, iip, src,\n          clientName, clientMachine, false);\n      // Truncate length check.\n      long oldLength \u003d file.computeFileSize();\n      if (oldLength \u003d\u003d newLength) {\n        return new TruncateResult(true, fsd.getAuditFileInfo(iip));\n      }\n      if (oldLength \u003c newLength) {\n        throw new HadoopIllegalArgumentException(\n            \"Cannot truncate to a larger file size. Current size: \" + oldLength\n                + \", truncate size: \" + newLength + \".\");\n      }\n      // Perform INodeFile truncation.\n      final QuotaCounts delta \u003d new QuotaCounts.Builder().build();\n      onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n          toRemoveBlocks, mtime, delta);\n      if (!onBlockBoundary) {\n        // Open file for write, but don\u0027t log into edits\n        long lastBlockDelta \u003d file.computeFileSize() - newLength;\n        assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n        truncateBlock \u003d prepareFileForTruncate(fsn, iip, clientName,\n            clientMachine, lastBlockDelta, null);\n      }\n\n      // update the quota: use the preferred block size for UC block\n      fsd.updateCountNoQuotaCheck(iip, iip.length() - 1, delta);\n    } finally {\n      fsd.writeUnlock();\n    }\n\n    fsn.getEditLog().logTruncate(src, clientName, clientMachine, newLength,\n        mtime, truncateBlock);\n    return new TruncateResult(onBlockBoundary, fsd.getAuditFileInfo(iip));\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirTruncateOp.java",
          "extendedDetails": {}
        },
        {
          "type": "Yparametermetachange",
          "commitMessage": "HDFS-8493. Consolidate truncate() related implementation in a single class. Contributed by Rakesh R.\n",
          "commitDate": "29/06/15 4:45 PM",
          "commitName": "d3797f9f3cf502b7bfee3b64c641807b276c6faf",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "29/06/15 2:56 PM",
          "commitNameOld": "8e333720e13428a4d0d0f65692102f8f2e5da98d",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 0.08,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,72 +1,80 @@\n-  boolean truncateInternal(String src, long newLength,\n-                           String clientName, String clientMachine,\n-                           long mtime, FSPermissionChecker pc,\n-                           BlocksMapUpdateInfo toRemoveBlocks)\n+  static TruncateResult truncate(final FSNamesystem fsn, final String srcArg,\n+      final long newLength, final String clientName,\n+      final String clientMachine, final long mtime,\n+      final BlocksMapUpdateInfo toRemoveBlocks, final FSPermissionChecker pc)\n       throws IOException, UnresolvedLinkException {\n-    assert hasWriteLock();\n-    INodesInPath iip \u003d dir.getINodesInPath4Write(src, true);\n-    if (isPermissionEnabled) {\n-      dir.checkPathAccess(pc, iip, FsAction.WRITE);\n-    }\n-    INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n-    final BlockStoragePolicy lpPolicy \u003d\n-        blockManager.getStoragePolicy(\"LAZY_PERSIST\");\n+    assert fsn.hasWriteLock();\n \n-    if (lpPolicy !\u003d null \u0026\u0026\n-        lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n-      throw new UnsupportedOperationException(\n-          \"Cannot truncate lazy persist file \" + src);\n-    }\n+    FSDirectory fsd \u003d fsn.getFSDirectory();\n+    byte[][] pathComponents \u003d FSDirectory\n+        .getPathComponentsForReservedPath(srcArg);\n+    final String src;\n+    final INodesInPath iip;\n+    final boolean onBlockBoundary;\n+    Block truncateBlock \u003d null;\n+    fsd.writeLock();\n+    try {\n+      src \u003d fsd.resolvePath(pc, srcArg, pathComponents);\n+      iip \u003d fsd.getINodesInPath4Write(src, true);\n+      if (fsn.isPermissionEnabled()) {\n+        fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n+      }\n+      INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n+      final BlockStoragePolicy lpPolicy \u003d fsn.getBlockManager()\n+          .getStoragePolicy(\"LAZY_PERSIST\");\n \n-    // Check if the file is already being truncated with the same length\n-    final BlockInfo last \u003d file.getLastBlock();\n-    if (last !\u003d null \u0026\u0026 last.getBlockUCState() \u003d\u003d BlockUCState.UNDER_RECOVERY) {\n-      final Block truncateBlock\n-          \u003d ((BlockInfoUnderConstruction)last).getTruncateBlock();\n-      if (truncateBlock !\u003d null) {\n-        final long truncateLength \u003d file.computeFileSize(false, false)\n-            + truncateBlock.getNumBytes();\n-        if (newLength \u003d\u003d truncateLength) {\n-          return false;\n+      if (lpPolicy !\u003d null \u0026\u0026 lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n+        throw new UnsupportedOperationException(\n+            \"Cannot truncate lazy persist file \" + src);\n+      }\n+\n+      // Check if the file is already being truncated with the same length\n+      final BlockInfo last \u003d file.getLastBlock();\n+      if (last !\u003d null \u0026\u0026 last.getBlockUCState()\n+          \u003d\u003d BlockUCState.UNDER_RECOVERY) {\n+        final Block truncatedBlock \u003d ((BlockInfoUnderConstruction) last)\n+            .getTruncateBlock();\n+        if (truncatedBlock !\u003d null) {\n+          final long truncateLength \u003d file.computeFileSize(false, false)\n+              + truncatedBlock.getNumBytes();\n+          if (newLength \u003d\u003d truncateLength) {\n+            return new TruncateResult(false, fsd.getAuditFileInfo(iip));\n+          }\n         }\n       }\n-    }\n \n-    // Opening an existing file for truncate. May need lease recovery.\n-    recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE,\n-        iip, src, clientName, clientMachine, false);\n-    // Truncate length check.\n-    long oldLength \u003d file.computeFileSize();\n-    if(oldLength \u003d\u003d newLength) {\n-      return true;\n-    }\n-    if(oldLength \u003c newLength) {\n-      throw new HadoopIllegalArgumentException(\n-          \"Cannot truncate to a larger file size. Current size: \" + oldLength +\n-              \", truncate size: \" + newLength + \".\");\n-    }\n-    // Perform INodeFile truncation.\n-    final QuotaCounts delta \u003d new QuotaCounts.Builder().build();\n-    boolean onBlockBoundary \u003d dir.truncate(iip, newLength, toRemoveBlocks,\n-        mtime, delta);\n-    Block truncateBlock \u003d null;\n-    if(!onBlockBoundary) {\n-      // Open file for write, but don\u0027t log into edits\n-      long lastBlockDelta \u003d file.computeFileSize() - newLength;\n-      assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n-      truncateBlock \u003d prepareFileForTruncate(iip, clientName, clientMachine,\n-          lastBlockDelta, null);\n-    }\n+      // Opening an existing file for truncate. May need lease recovery.\n+      fsn.recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE, iip, src,\n+          clientName, clientMachine, false);\n+      // Truncate length check.\n+      long oldLength \u003d file.computeFileSize();\n+      if (oldLength \u003d\u003d newLength) {\n+        return new TruncateResult(true, fsd.getAuditFileInfo(iip));\n+      }\n+      if (oldLength \u003c newLength) {\n+        throw new HadoopIllegalArgumentException(\n+            \"Cannot truncate to a larger file size. Current size: \" + oldLength\n+                + \", truncate size: \" + newLength + \".\");\n+      }\n+      // Perform INodeFile truncation.\n+      final QuotaCounts delta \u003d new QuotaCounts.Builder().build();\n+      onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n+          toRemoveBlocks, mtime, delta);\n+      if (!onBlockBoundary) {\n+        // Open file for write, but don\u0027t log into edits\n+        long lastBlockDelta \u003d file.computeFileSize() - newLength;\n+        assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n+        truncateBlock \u003d prepareFileForTruncate(fsn, iip, clientName,\n+            clientMachine, lastBlockDelta, null);\n+      }\n \n-    // update the quota: use the preferred block size for UC block\n-    dir.writeLock();\n-    try {\n-      dir.updateCountNoQuotaCheck(iip, iip.length() - 1, delta);\n+      // update the quota: use the preferred block size for UC block\n+      fsd.updateCountNoQuotaCheck(iip, iip.length() - 1, delta);\n     } finally {\n-      dir.writeUnlock();\n+      fsd.writeUnlock();\n     }\n \n-    getEditLog().logTruncate(src, clientName, clientMachine, newLength, mtime,\n-        truncateBlock);\n-    return onBlockBoundary;\n+    fsn.getEditLog().logTruncate(src, clientName, clientMachine, newLength,\n+        mtime, truncateBlock);\n+    return new TruncateResult(onBlockBoundary, fsd.getAuditFileInfo(iip));\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static TruncateResult truncate(final FSNamesystem fsn, final String srcArg,\n      final long newLength, final String clientName,\n      final String clientMachine, final long mtime,\n      final BlocksMapUpdateInfo toRemoveBlocks, final FSPermissionChecker pc)\n      throws IOException, UnresolvedLinkException {\n    assert fsn.hasWriteLock();\n\n    FSDirectory fsd \u003d fsn.getFSDirectory();\n    byte[][] pathComponents \u003d FSDirectory\n        .getPathComponentsForReservedPath(srcArg);\n    final String src;\n    final INodesInPath iip;\n    final boolean onBlockBoundary;\n    Block truncateBlock \u003d null;\n    fsd.writeLock();\n    try {\n      src \u003d fsd.resolvePath(pc, srcArg, pathComponents);\n      iip \u003d fsd.getINodesInPath4Write(src, true);\n      if (fsn.isPermissionEnabled()) {\n        fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n      }\n      INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n      final BlockStoragePolicy lpPolicy \u003d fsn.getBlockManager()\n          .getStoragePolicy(\"LAZY_PERSIST\");\n\n      if (lpPolicy !\u003d null \u0026\u0026 lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n        throw new UnsupportedOperationException(\n            \"Cannot truncate lazy persist file \" + src);\n      }\n\n      // Check if the file is already being truncated with the same length\n      final BlockInfo last \u003d file.getLastBlock();\n      if (last !\u003d null \u0026\u0026 last.getBlockUCState()\n          \u003d\u003d BlockUCState.UNDER_RECOVERY) {\n        final Block truncatedBlock \u003d ((BlockInfoUnderConstruction) last)\n            .getTruncateBlock();\n        if (truncatedBlock !\u003d null) {\n          final long truncateLength \u003d file.computeFileSize(false, false)\n              + truncatedBlock.getNumBytes();\n          if (newLength \u003d\u003d truncateLength) {\n            return new TruncateResult(false, fsd.getAuditFileInfo(iip));\n          }\n        }\n      }\n\n      // Opening an existing file for truncate. May need lease recovery.\n      fsn.recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE, iip, src,\n          clientName, clientMachine, false);\n      // Truncate length check.\n      long oldLength \u003d file.computeFileSize();\n      if (oldLength \u003d\u003d newLength) {\n        return new TruncateResult(true, fsd.getAuditFileInfo(iip));\n      }\n      if (oldLength \u003c newLength) {\n        throw new HadoopIllegalArgumentException(\n            \"Cannot truncate to a larger file size. Current size: \" + oldLength\n                + \", truncate size: \" + newLength + \".\");\n      }\n      // Perform INodeFile truncation.\n      final QuotaCounts delta \u003d new QuotaCounts.Builder().build();\n      onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n          toRemoveBlocks, mtime, delta);\n      if (!onBlockBoundary) {\n        // Open file for write, but don\u0027t log into edits\n        long lastBlockDelta \u003d file.computeFileSize() - newLength;\n        assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n        truncateBlock \u003d prepareFileForTruncate(fsn, iip, clientName,\n            clientMachine, lastBlockDelta, null);\n      }\n\n      // update the quota: use the preferred block size for UC block\n      fsd.updateCountNoQuotaCheck(iip, iip.length() - 1, delta);\n    } finally {\n      fsd.writeUnlock();\n    }\n\n    fsn.getEditLog().logTruncate(src, clientName, clientMachine, newLength,\n        mtime, truncateBlock);\n    return new TruncateResult(onBlockBoundary, fsd.getAuditFileInfo(iip));\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirTruncateOp.java",
          "extendedDetails": {
            "oldValue": "[src-String, newLength-long, clientName-String, clientMachine-String, mtime-long, pc-FSPermissionChecker, toRemoveBlocks-BlocksMapUpdateInfo]",
            "newValue": "[fsn-FSNamesystem(modifiers-final), srcArg-String(modifiers-final), newLength-long(modifiers-final), clientName-String(modifiers-final), clientMachine-String(modifiers-final), mtime-long(modifiers-final), toRemoveBlocks-BlocksMapUpdateInfo(modifiers-final), pc-FSPermissionChecker(modifiers-final)]"
          }
        },
        {
          "type": "Yrename",
          "commitMessage": "HDFS-8493. Consolidate truncate() related implementation in a single class. Contributed by Rakesh R.\n",
          "commitDate": "29/06/15 4:45 PM",
          "commitName": "d3797f9f3cf502b7bfee3b64c641807b276c6faf",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "29/06/15 2:56 PM",
          "commitNameOld": "8e333720e13428a4d0d0f65692102f8f2e5da98d",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 0.08,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,72 +1,80 @@\n-  boolean truncateInternal(String src, long newLength,\n-                           String clientName, String clientMachine,\n-                           long mtime, FSPermissionChecker pc,\n-                           BlocksMapUpdateInfo toRemoveBlocks)\n+  static TruncateResult truncate(final FSNamesystem fsn, final String srcArg,\n+      final long newLength, final String clientName,\n+      final String clientMachine, final long mtime,\n+      final BlocksMapUpdateInfo toRemoveBlocks, final FSPermissionChecker pc)\n       throws IOException, UnresolvedLinkException {\n-    assert hasWriteLock();\n-    INodesInPath iip \u003d dir.getINodesInPath4Write(src, true);\n-    if (isPermissionEnabled) {\n-      dir.checkPathAccess(pc, iip, FsAction.WRITE);\n-    }\n-    INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n-    final BlockStoragePolicy lpPolicy \u003d\n-        blockManager.getStoragePolicy(\"LAZY_PERSIST\");\n+    assert fsn.hasWriteLock();\n \n-    if (lpPolicy !\u003d null \u0026\u0026\n-        lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n-      throw new UnsupportedOperationException(\n-          \"Cannot truncate lazy persist file \" + src);\n-    }\n+    FSDirectory fsd \u003d fsn.getFSDirectory();\n+    byte[][] pathComponents \u003d FSDirectory\n+        .getPathComponentsForReservedPath(srcArg);\n+    final String src;\n+    final INodesInPath iip;\n+    final boolean onBlockBoundary;\n+    Block truncateBlock \u003d null;\n+    fsd.writeLock();\n+    try {\n+      src \u003d fsd.resolvePath(pc, srcArg, pathComponents);\n+      iip \u003d fsd.getINodesInPath4Write(src, true);\n+      if (fsn.isPermissionEnabled()) {\n+        fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n+      }\n+      INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n+      final BlockStoragePolicy lpPolicy \u003d fsn.getBlockManager()\n+          .getStoragePolicy(\"LAZY_PERSIST\");\n \n-    // Check if the file is already being truncated with the same length\n-    final BlockInfo last \u003d file.getLastBlock();\n-    if (last !\u003d null \u0026\u0026 last.getBlockUCState() \u003d\u003d BlockUCState.UNDER_RECOVERY) {\n-      final Block truncateBlock\n-          \u003d ((BlockInfoUnderConstruction)last).getTruncateBlock();\n-      if (truncateBlock !\u003d null) {\n-        final long truncateLength \u003d file.computeFileSize(false, false)\n-            + truncateBlock.getNumBytes();\n-        if (newLength \u003d\u003d truncateLength) {\n-          return false;\n+      if (lpPolicy !\u003d null \u0026\u0026 lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n+        throw new UnsupportedOperationException(\n+            \"Cannot truncate lazy persist file \" + src);\n+      }\n+\n+      // Check if the file is already being truncated with the same length\n+      final BlockInfo last \u003d file.getLastBlock();\n+      if (last !\u003d null \u0026\u0026 last.getBlockUCState()\n+          \u003d\u003d BlockUCState.UNDER_RECOVERY) {\n+        final Block truncatedBlock \u003d ((BlockInfoUnderConstruction) last)\n+            .getTruncateBlock();\n+        if (truncatedBlock !\u003d null) {\n+          final long truncateLength \u003d file.computeFileSize(false, false)\n+              + truncatedBlock.getNumBytes();\n+          if (newLength \u003d\u003d truncateLength) {\n+            return new TruncateResult(false, fsd.getAuditFileInfo(iip));\n+          }\n         }\n       }\n-    }\n \n-    // Opening an existing file for truncate. May need lease recovery.\n-    recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE,\n-        iip, src, clientName, clientMachine, false);\n-    // Truncate length check.\n-    long oldLength \u003d file.computeFileSize();\n-    if(oldLength \u003d\u003d newLength) {\n-      return true;\n-    }\n-    if(oldLength \u003c newLength) {\n-      throw new HadoopIllegalArgumentException(\n-          \"Cannot truncate to a larger file size. Current size: \" + oldLength +\n-              \", truncate size: \" + newLength + \".\");\n-    }\n-    // Perform INodeFile truncation.\n-    final QuotaCounts delta \u003d new QuotaCounts.Builder().build();\n-    boolean onBlockBoundary \u003d dir.truncate(iip, newLength, toRemoveBlocks,\n-        mtime, delta);\n-    Block truncateBlock \u003d null;\n-    if(!onBlockBoundary) {\n-      // Open file for write, but don\u0027t log into edits\n-      long lastBlockDelta \u003d file.computeFileSize() - newLength;\n-      assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n-      truncateBlock \u003d prepareFileForTruncate(iip, clientName, clientMachine,\n-          lastBlockDelta, null);\n-    }\n+      // Opening an existing file for truncate. May need lease recovery.\n+      fsn.recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE, iip, src,\n+          clientName, clientMachine, false);\n+      // Truncate length check.\n+      long oldLength \u003d file.computeFileSize();\n+      if (oldLength \u003d\u003d newLength) {\n+        return new TruncateResult(true, fsd.getAuditFileInfo(iip));\n+      }\n+      if (oldLength \u003c newLength) {\n+        throw new HadoopIllegalArgumentException(\n+            \"Cannot truncate to a larger file size. Current size: \" + oldLength\n+                + \", truncate size: \" + newLength + \".\");\n+      }\n+      // Perform INodeFile truncation.\n+      final QuotaCounts delta \u003d new QuotaCounts.Builder().build();\n+      onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n+          toRemoveBlocks, mtime, delta);\n+      if (!onBlockBoundary) {\n+        // Open file for write, but don\u0027t log into edits\n+        long lastBlockDelta \u003d file.computeFileSize() - newLength;\n+        assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n+        truncateBlock \u003d prepareFileForTruncate(fsn, iip, clientName,\n+            clientMachine, lastBlockDelta, null);\n+      }\n \n-    // update the quota: use the preferred block size for UC block\n-    dir.writeLock();\n-    try {\n-      dir.updateCountNoQuotaCheck(iip, iip.length() - 1, delta);\n+      // update the quota: use the preferred block size for UC block\n+      fsd.updateCountNoQuotaCheck(iip, iip.length() - 1, delta);\n     } finally {\n-      dir.writeUnlock();\n+      fsd.writeUnlock();\n     }\n \n-    getEditLog().logTruncate(src, clientName, clientMachine, newLength, mtime,\n-        truncateBlock);\n-    return onBlockBoundary;\n+    fsn.getEditLog().logTruncate(src, clientName, clientMachine, newLength,\n+        mtime, truncateBlock);\n+    return new TruncateResult(onBlockBoundary, fsd.getAuditFileInfo(iip));\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static TruncateResult truncate(final FSNamesystem fsn, final String srcArg,\n      final long newLength, final String clientName,\n      final String clientMachine, final long mtime,\n      final BlocksMapUpdateInfo toRemoveBlocks, final FSPermissionChecker pc)\n      throws IOException, UnresolvedLinkException {\n    assert fsn.hasWriteLock();\n\n    FSDirectory fsd \u003d fsn.getFSDirectory();\n    byte[][] pathComponents \u003d FSDirectory\n        .getPathComponentsForReservedPath(srcArg);\n    final String src;\n    final INodesInPath iip;\n    final boolean onBlockBoundary;\n    Block truncateBlock \u003d null;\n    fsd.writeLock();\n    try {\n      src \u003d fsd.resolvePath(pc, srcArg, pathComponents);\n      iip \u003d fsd.getINodesInPath4Write(src, true);\n      if (fsn.isPermissionEnabled()) {\n        fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n      }\n      INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n      final BlockStoragePolicy lpPolicy \u003d fsn.getBlockManager()\n          .getStoragePolicy(\"LAZY_PERSIST\");\n\n      if (lpPolicy !\u003d null \u0026\u0026 lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n        throw new UnsupportedOperationException(\n            \"Cannot truncate lazy persist file \" + src);\n      }\n\n      // Check if the file is already being truncated with the same length\n      final BlockInfo last \u003d file.getLastBlock();\n      if (last !\u003d null \u0026\u0026 last.getBlockUCState()\n          \u003d\u003d BlockUCState.UNDER_RECOVERY) {\n        final Block truncatedBlock \u003d ((BlockInfoUnderConstruction) last)\n            .getTruncateBlock();\n        if (truncatedBlock !\u003d null) {\n          final long truncateLength \u003d file.computeFileSize(false, false)\n              + truncatedBlock.getNumBytes();\n          if (newLength \u003d\u003d truncateLength) {\n            return new TruncateResult(false, fsd.getAuditFileInfo(iip));\n          }\n        }\n      }\n\n      // Opening an existing file for truncate. May need lease recovery.\n      fsn.recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE, iip, src,\n          clientName, clientMachine, false);\n      // Truncate length check.\n      long oldLength \u003d file.computeFileSize();\n      if (oldLength \u003d\u003d newLength) {\n        return new TruncateResult(true, fsd.getAuditFileInfo(iip));\n      }\n      if (oldLength \u003c newLength) {\n        throw new HadoopIllegalArgumentException(\n            \"Cannot truncate to a larger file size. Current size: \" + oldLength\n                + \", truncate size: \" + newLength + \".\");\n      }\n      // Perform INodeFile truncation.\n      final QuotaCounts delta \u003d new QuotaCounts.Builder().build();\n      onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n          toRemoveBlocks, mtime, delta);\n      if (!onBlockBoundary) {\n        // Open file for write, but don\u0027t log into edits\n        long lastBlockDelta \u003d file.computeFileSize() - newLength;\n        assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n        truncateBlock \u003d prepareFileForTruncate(fsn, iip, clientName,\n            clientMachine, lastBlockDelta, null);\n      }\n\n      // update the quota: use the preferred block size for UC block\n      fsd.updateCountNoQuotaCheck(iip, iip.length() - 1, delta);\n    } finally {\n      fsd.writeUnlock();\n    }\n\n    fsn.getEditLog().logTruncate(src, clientName, clientMachine, newLength,\n        mtime, truncateBlock);\n    return new TruncateResult(onBlockBoundary, fsd.getAuditFileInfo(iip));\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirTruncateOp.java",
          "extendedDetails": {
            "oldValue": "truncateInternal",
            "newValue": "truncate"
          }
        },
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-8493. Consolidate truncate() related implementation in a single class. Contributed by Rakesh R.\n",
          "commitDate": "29/06/15 4:45 PM",
          "commitName": "d3797f9f3cf502b7bfee3b64c641807b276c6faf",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "29/06/15 2:56 PM",
          "commitNameOld": "8e333720e13428a4d0d0f65692102f8f2e5da98d",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 0.08,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,72 +1,80 @@\n-  boolean truncateInternal(String src, long newLength,\n-                           String clientName, String clientMachine,\n-                           long mtime, FSPermissionChecker pc,\n-                           BlocksMapUpdateInfo toRemoveBlocks)\n+  static TruncateResult truncate(final FSNamesystem fsn, final String srcArg,\n+      final long newLength, final String clientName,\n+      final String clientMachine, final long mtime,\n+      final BlocksMapUpdateInfo toRemoveBlocks, final FSPermissionChecker pc)\n       throws IOException, UnresolvedLinkException {\n-    assert hasWriteLock();\n-    INodesInPath iip \u003d dir.getINodesInPath4Write(src, true);\n-    if (isPermissionEnabled) {\n-      dir.checkPathAccess(pc, iip, FsAction.WRITE);\n-    }\n-    INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n-    final BlockStoragePolicy lpPolicy \u003d\n-        blockManager.getStoragePolicy(\"LAZY_PERSIST\");\n+    assert fsn.hasWriteLock();\n \n-    if (lpPolicy !\u003d null \u0026\u0026\n-        lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n-      throw new UnsupportedOperationException(\n-          \"Cannot truncate lazy persist file \" + src);\n-    }\n+    FSDirectory fsd \u003d fsn.getFSDirectory();\n+    byte[][] pathComponents \u003d FSDirectory\n+        .getPathComponentsForReservedPath(srcArg);\n+    final String src;\n+    final INodesInPath iip;\n+    final boolean onBlockBoundary;\n+    Block truncateBlock \u003d null;\n+    fsd.writeLock();\n+    try {\n+      src \u003d fsd.resolvePath(pc, srcArg, pathComponents);\n+      iip \u003d fsd.getINodesInPath4Write(src, true);\n+      if (fsn.isPermissionEnabled()) {\n+        fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n+      }\n+      INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n+      final BlockStoragePolicy lpPolicy \u003d fsn.getBlockManager()\n+          .getStoragePolicy(\"LAZY_PERSIST\");\n \n-    // Check if the file is already being truncated with the same length\n-    final BlockInfo last \u003d file.getLastBlock();\n-    if (last !\u003d null \u0026\u0026 last.getBlockUCState() \u003d\u003d BlockUCState.UNDER_RECOVERY) {\n-      final Block truncateBlock\n-          \u003d ((BlockInfoUnderConstruction)last).getTruncateBlock();\n-      if (truncateBlock !\u003d null) {\n-        final long truncateLength \u003d file.computeFileSize(false, false)\n-            + truncateBlock.getNumBytes();\n-        if (newLength \u003d\u003d truncateLength) {\n-          return false;\n+      if (lpPolicy !\u003d null \u0026\u0026 lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n+        throw new UnsupportedOperationException(\n+            \"Cannot truncate lazy persist file \" + src);\n+      }\n+\n+      // Check if the file is already being truncated with the same length\n+      final BlockInfo last \u003d file.getLastBlock();\n+      if (last !\u003d null \u0026\u0026 last.getBlockUCState()\n+          \u003d\u003d BlockUCState.UNDER_RECOVERY) {\n+        final Block truncatedBlock \u003d ((BlockInfoUnderConstruction) last)\n+            .getTruncateBlock();\n+        if (truncatedBlock !\u003d null) {\n+          final long truncateLength \u003d file.computeFileSize(false, false)\n+              + truncatedBlock.getNumBytes();\n+          if (newLength \u003d\u003d truncateLength) {\n+            return new TruncateResult(false, fsd.getAuditFileInfo(iip));\n+          }\n         }\n       }\n-    }\n \n-    // Opening an existing file for truncate. May need lease recovery.\n-    recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE,\n-        iip, src, clientName, clientMachine, false);\n-    // Truncate length check.\n-    long oldLength \u003d file.computeFileSize();\n-    if(oldLength \u003d\u003d newLength) {\n-      return true;\n-    }\n-    if(oldLength \u003c newLength) {\n-      throw new HadoopIllegalArgumentException(\n-          \"Cannot truncate to a larger file size. Current size: \" + oldLength +\n-              \", truncate size: \" + newLength + \".\");\n-    }\n-    // Perform INodeFile truncation.\n-    final QuotaCounts delta \u003d new QuotaCounts.Builder().build();\n-    boolean onBlockBoundary \u003d dir.truncate(iip, newLength, toRemoveBlocks,\n-        mtime, delta);\n-    Block truncateBlock \u003d null;\n-    if(!onBlockBoundary) {\n-      // Open file for write, but don\u0027t log into edits\n-      long lastBlockDelta \u003d file.computeFileSize() - newLength;\n-      assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n-      truncateBlock \u003d prepareFileForTruncate(iip, clientName, clientMachine,\n-          lastBlockDelta, null);\n-    }\n+      // Opening an existing file for truncate. May need lease recovery.\n+      fsn.recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE, iip, src,\n+          clientName, clientMachine, false);\n+      // Truncate length check.\n+      long oldLength \u003d file.computeFileSize();\n+      if (oldLength \u003d\u003d newLength) {\n+        return new TruncateResult(true, fsd.getAuditFileInfo(iip));\n+      }\n+      if (oldLength \u003c newLength) {\n+        throw new HadoopIllegalArgumentException(\n+            \"Cannot truncate to a larger file size. Current size: \" + oldLength\n+                + \", truncate size: \" + newLength + \".\");\n+      }\n+      // Perform INodeFile truncation.\n+      final QuotaCounts delta \u003d new QuotaCounts.Builder().build();\n+      onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n+          toRemoveBlocks, mtime, delta);\n+      if (!onBlockBoundary) {\n+        // Open file for write, but don\u0027t log into edits\n+        long lastBlockDelta \u003d file.computeFileSize() - newLength;\n+        assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n+        truncateBlock \u003d prepareFileForTruncate(fsn, iip, clientName,\n+            clientMachine, lastBlockDelta, null);\n+      }\n \n-    // update the quota: use the preferred block size for UC block\n-    dir.writeLock();\n-    try {\n-      dir.updateCountNoQuotaCheck(iip, iip.length() - 1, delta);\n+      // update the quota: use the preferred block size for UC block\n+      fsd.updateCountNoQuotaCheck(iip, iip.length() - 1, delta);\n     } finally {\n-      dir.writeUnlock();\n+      fsd.writeUnlock();\n     }\n \n-    getEditLog().logTruncate(src, clientName, clientMachine, newLength, mtime,\n-        truncateBlock);\n-    return onBlockBoundary;\n+    fsn.getEditLog().logTruncate(src, clientName, clientMachine, newLength,\n+        mtime, truncateBlock);\n+    return new TruncateResult(onBlockBoundary, fsd.getAuditFileInfo(iip));\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static TruncateResult truncate(final FSNamesystem fsn, final String srcArg,\n      final long newLength, final String clientName,\n      final String clientMachine, final long mtime,\n      final BlocksMapUpdateInfo toRemoveBlocks, final FSPermissionChecker pc)\n      throws IOException, UnresolvedLinkException {\n    assert fsn.hasWriteLock();\n\n    FSDirectory fsd \u003d fsn.getFSDirectory();\n    byte[][] pathComponents \u003d FSDirectory\n        .getPathComponentsForReservedPath(srcArg);\n    final String src;\n    final INodesInPath iip;\n    final boolean onBlockBoundary;\n    Block truncateBlock \u003d null;\n    fsd.writeLock();\n    try {\n      src \u003d fsd.resolvePath(pc, srcArg, pathComponents);\n      iip \u003d fsd.getINodesInPath4Write(src, true);\n      if (fsn.isPermissionEnabled()) {\n        fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n      }\n      INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n      final BlockStoragePolicy lpPolicy \u003d fsn.getBlockManager()\n          .getStoragePolicy(\"LAZY_PERSIST\");\n\n      if (lpPolicy !\u003d null \u0026\u0026 lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n        throw new UnsupportedOperationException(\n            \"Cannot truncate lazy persist file \" + src);\n      }\n\n      // Check if the file is already being truncated with the same length\n      final BlockInfo last \u003d file.getLastBlock();\n      if (last !\u003d null \u0026\u0026 last.getBlockUCState()\n          \u003d\u003d BlockUCState.UNDER_RECOVERY) {\n        final Block truncatedBlock \u003d ((BlockInfoUnderConstruction) last)\n            .getTruncateBlock();\n        if (truncatedBlock !\u003d null) {\n          final long truncateLength \u003d file.computeFileSize(false, false)\n              + truncatedBlock.getNumBytes();\n          if (newLength \u003d\u003d truncateLength) {\n            return new TruncateResult(false, fsd.getAuditFileInfo(iip));\n          }\n        }\n      }\n\n      // Opening an existing file for truncate. May need lease recovery.\n      fsn.recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE, iip, src,\n          clientName, clientMachine, false);\n      // Truncate length check.\n      long oldLength \u003d file.computeFileSize();\n      if (oldLength \u003d\u003d newLength) {\n        return new TruncateResult(true, fsd.getAuditFileInfo(iip));\n      }\n      if (oldLength \u003c newLength) {\n        throw new HadoopIllegalArgumentException(\n            \"Cannot truncate to a larger file size. Current size: \" + oldLength\n                + \", truncate size: \" + newLength + \".\");\n      }\n      // Perform INodeFile truncation.\n      final QuotaCounts delta \u003d new QuotaCounts.Builder().build();\n      onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n          toRemoveBlocks, mtime, delta);\n      if (!onBlockBoundary) {\n        // Open file for write, but don\u0027t log into edits\n        long lastBlockDelta \u003d file.computeFileSize() - newLength;\n        assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n        truncateBlock \u003d prepareFileForTruncate(fsn, iip, clientName,\n            clientMachine, lastBlockDelta, null);\n      }\n\n      // update the quota: use the preferred block size for UC block\n      fsd.updateCountNoQuotaCheck(iip, iip.length() - 1, delta);\n    } finally {\n      fsd.writeUnlock();\n    }\n\n    fsn.getEditLog().logTruncate(src, clientName, clientMachine, newLength,\n        mtime, truncateBlock);\n    return new TruncateResult(onBlockBoundary, fsd.getAuditFileInfo(iip));\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirTruncateOp.java",
          "extendedDetails": {
            "oldValue": "[src-String, newLength-long, clientName-String, clientMachine-String, mtime-long, pc-FSPermissionChecker, toRemoveBlocks-BlocksMapUpdateInfo]",
            "newValue": "[fsn-FSNamesystem(modifiers-final), srcArg-String(modifiers-final), newLength-long(modifiers-final), clientName-String(modifiers-final), clientMachine-String(modifiers-final), mtime-long(modifiers-final), toRemoveBlocks-BlocksMapUpdateInfo(modifiers-final), pc-FSPermissionChecker(modifiers-final)]"
          }
        }
      ]
    },
    "c17439c2ddd921b63b1635e6f1cba634b8da8557": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8499. Refactor BlockInfo class hierarchy with static helper class. Contributed by Zhe Zhang.\n",
      "commitDate": "12/06/15 11:38 AM",
      "commitName": "c17439c2ddd921b63b1635e6f1cba634b8da8557",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "12/06/15 11:17 AM",
      "commitNameOld": "12b5b06c063d93e6c683c9b6fac9a96912f59e59",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,72 +1,72 @@\n   boolean truncateInternal(String src, long newLength,\n                            String clientName, String clientMachine,\n                            long mtime, FSPermissionChecker pc,\n                            BlocksMapUpdateInfo toRemoveBlocks)\n       throws IOException, UnresolvedLinkException {\n     assert hasWriteLock();\n     INodesInPath iip \u003d dir.getINodesInPath4Write(src, true);\n     if (isPermissionEnabled) {\n       dir.checkPathAccess(pc, iip, FsAction.WRITE);\n     }\n     INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n     final BlockStoragePolicy lpPolicy \u003d\n         blockManager.getStoragePolicy(\"LAZY_PERSIST\");\n \n     if (lpPolicy !\u003d null \u0026\u0026\n         lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n       throw new UnsupportedOperationException(\n           \"Cannot truncate lazy persist file \" + src);\n     }\n \n     // Check if the file is already being truncated with the same length\n     final BlockInfo last \u003d file.getLastBlock();\n     if (last !\u003d null \u0026\u0026 last.getBlockUCState() \u003d\u003d BlockUCState.UNDER_RECOVERY) {\n       final Block truncateBlock\n-          \u003d ((BlockInfoContiguousUnderConstruction)last).getTruncateBlock();\n+          \u003d ((BlockInfoUnderConstruction)last).getTruncateBlock();\n       if (truncateBlock !\u003d null) {\n         final long truncateLength \u003d file.computeFileSize(false, false)\n             + truncateBlock.getNumBytes();\n         if (newLength \u003d\u003d truncateLength) {\n           return false;\n         }\n       }\n     }\n \n     // Opening an existing file for truncate. May need lease recovery.\n     recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE,\n         iip, src, clientName, clientMachine, false);\n     // Truncate length check.\n     long oldLength \u003d file.computeFileSize();\n     if(oldLength \u003d\u003d newLength) {\n       return true;\n     }\n     if(oldLength \u003c newLength) {\n       throw new HadoopIllegalArgumentException(\n           \"Cannot truncate to a larger file size. Current size: \" + oldLength +\n               \", truncate size: \" + newLength + \".\");\n     }\n     // Perform INodeFile truncation.\n     final QuotaCounts delta \u003d new QuotaCounts.Builder().build();\n     boolean onBlockBoundary \u003d dir.truncate(iip, newLength, toRemoveBlocks,\n         mtime, delta);\n     Block truncateBlock \u003d null;\n     if(!onBlockBoundary) {\n       // Open file for write, but don\u0027t log into edits\n       long lastBlockDelta \u003d file.computeFileSize() - newLength;\n       assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n       truncateBlock \u003d prepareFileForTruncate(iip, clientName, clientMachine,\n           lastBlockDelta, null);\n     }\n \n     // update the quota: use the preferred block size for UC block\n     dir.writeLock();\n     try {\n       dir.updateCountNoQuotaCheck(iip, iip.length() - 1, delta);\n     } finally {\n       dir.writeUnlock();\n     }\n \n     getEditLog().logTruncate(src, clientName, clientMachine, newLength, mtime,\n         truncateBlock);\n     return onBlockBoundary;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  boolean truncateInternal(String src, long newLength,\n                           String clientName, String clientMachine,\n                           long mtime, FSPermissionChecker pc,\n                           BlocksMapUpdateInfo toRemoveBlocks)\n      throws IOException, UnresolvedLinkException {\n    assert hasWriteLock();\n    INodesInPath iip \u003d dir.getINodesInPath4Write(src, true);\n    if (isPermissionEnabled) {\n      dir.checkPathAccess(pc, iip, FsAction.WRITE);\n    }\n    INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n    final BlockStoragePolicy lpPolicy \u003d\n        blockManager.getStoragePolicy(\"LAZY_PERSIST\");\n\n    if (lpPolicy !\u003d null \u0026\u0026\n        lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n      throw new UnsupportedOperationException(\n          \"Cannot truncate lazy persist file \" + src);\n    }\n\n    // Check if the file is already being truncated with the same length\n    final BlockInfo last \u003d file.getLastBlock();\n    if (last !\u003d null \u0026\u0026 last.getBlockUCState() \u003d\u003d BlockUCState.UNDER_RECOVERY) {\n      final Block truncateBlock\n          \u003d ((BlockInfoUnderConstruction)last).getTruncateBlock();\n      if (truncateBlock !\u003d null) {\n        final long truncateLength \u003d file.computeFileSize(false, false)\n            + truncateBlock.getNumBytes();\n        if (newLength \u003d\u003d truncateLength) {\n          return false;\n        }\n      }\n    }\n\n    // Opening an existing file for truncate. May need lease recovery.\n    recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE,\n        iip, src, clientName, clientMachine, false);\n    // Truncate length check.\n    long oldLength \u003d file.computeFileSize();\n    if(oldLength \u003d\u003d newLength) {\n      return true;\n    }\n    if(oldLength \u003c newLength) {\n      throw new HadoopIllegalArgumentException(\n          \"Cannot truncate to a larger file size. Current size: \" + oldLength +\n              \", truncate size: \" + newLength + \".\");\n    }\n    // Perform INodeFile truncation.\n    final QuotaCounts delta \u003d new QuotaCounts.Builder().build();\n    boolean onBlockBoundary \u003d dir.truncate(iip, newLength, toRemoveBlocks,\n        mtime, delta);\n    Block truncateBlock \u003d null;\n    if(!onBlockBoundary) {\n      // Open file for write, but don\u0027t log into edits\n      long lastBlockDelta \u003d file.computeFileSize() - newLength;\n      assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n      truncateBlock \u003d prepareFileForTruncate(iip, clientName, clientMachine,\n          lastBlockDelta, null);\n    }\n\n    // update the quota: use the preferred block size for UC block\n    dir.writeLock();\n    try {\n      dir.updateCountNoQuotaCheck(iip, iip.length() - 1, delta);\n    } finally {\n      dir.writeUnlock();\n    }\n\n    getEditLog().logTruncate(src, clientName, clientMachine, newLength, mtime,\n        truncateBlock);\n    return onBlockBoundary;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "4928f5473394981829e5ffd4b16ea0801baf5c45": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8482. Rename BlockInfoContiguous to BlockInfo. Contributed by Zhe Zhang.\n",
      "commitDate": "27/05/15 3:42 PM",
      "commitName": "4928f5473394981829e5ffd4b16ea0801baf5c45",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "21/05/15 8:08 AM",
      "commitNameOld": "2b6bcfdafa91223a4116e3e9304579f5f91dccac",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 6.32,
      "commitsBetweenForRepo": 32,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,72 +1,72 @@\n   boolean truncateInternal(String src, long newLength,\n                            String clientName, String clientMachine,\n                            long mtime, FSPermissionChecker pc,\n                            BlocksMapUpdateInfo toRemoveBlocks)\n       throws IOException, UnresolvedLinkException {\n     assert hasWriteLock();\n     INodesInPath iip \u003d dir.getINodesInPath4Write(src, true);\n     if (isPermissionEnabled) {\n       dir.checkPathAccess(pc, iip, FsAction.WRITE);\n     }\n     INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n     final BlockStoragePolicy lpPolicy \u003d\n         blockManager.getStoragePolicy(\"LAZY_PERSIST\");\n \n     if (lpPolicy !\u003d null \u0026\u0026\n         lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n       throw new UnsupportedOperationException(\n           \"Cannot truncate lazy persist file \" + src);\n     }\n \n     // Check if the file is already being truncated with the same length\n-    final BlockInfoContiguous last \u003d file.getLastBlock();\n+    final BlockInfo last \u003d file.getLastBlock();\n     if (last !\u003d null \u0026\u0026 last.getBlockUCState() \u003d\u003d BlockUCState.UNDER_RECOVERY) {\n       final Block truncateBlock\n           \u003d ((BlockInfoContiguousUnderConstruction)last).getTruncateBlock();\n       if (truncateBlock !\u003d null) {\n         final long truncateLength \u003d file.computeFileSize(false, false)\n             + truncateBlock.getNumBytes();\n         if (newLength \u003d\u003d truncateLength) {\n           return false;\n         }\n       }\n     }\n \n     // Opening an existing file for truncate. May need lease recovery.\n     recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE,\n         iip, src, clientName, clientMachine, false);\n     // Truncate length check.\n     long oldLength \u003d file.computeFileSize();\n     if(oldLength \u003d\u003d newLength) {\n       return true;\n     }\n     if(oldLength \u003c newLength) {\n       throw new HadoopIllegalArgumentException(\n           \"Cannot truncate to a larger file size. Current size: \" + oldLength +\n               \", truncate size: \" + newLength + \".\");\n     }\n     // Perform INodeFile truncation.\n     final QuotaCounts delta \u003d new QuotaCounts.Builder().build();\n     boolean onBlockBoundary \u003d dir.truncate(iip, newLength, toRemoveBlocks,\n         mtime, delta);\n     Block truncateBlock \u003d null;\n     if(!onBlockBoundary) {\n       // Open file for write, but don\u0027t log into edits\n       long lastBlockDelta \u003d file.computeFileSize() - newLength;\n       assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n       truncateBlock \u003d prepareFileForTruncate(iip, clientName, clientMachine,\n           lastBlockDelta, null);\n     }\n \n     // update the quota: use the preferred block size for UC block\n     dir.writeLock();\n     try {\n       dir.updateCountNoQuotaCheck(iip, iip.length() - 1, delta);\n     } finally {\n       dir.writeUnlock();\n     }\n \n     getEditLog().logTruncate(src, clientName, clientMachine, newLength, mtime,\n         truncateBlock);\n     return onBlockBoundary;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  boolean truncateInternal(String src, long newLength,\n                           String clientName, String clientMachine,\n                           long mtime, FSPermissionChecker pc,\n                           BlocksMapUpdateInfo toRemoveBlocks)\n      throws IOException, UnresolvedLinkException {\n    assert hasWriteLock();\n    INodesInPath iip \u003d dir.getINodesInPath4Write(src, true);\n    if (isPermissionEnabled) {\n      dir.checkPathAccess(pc, iip, FsAction.WRITE);\n    }\n    INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n    final BlockStoragePolicy lpPolicy \u003d\n        blockManager.getStoragePolicy(\"LAZY_PERSIST\");\n\n    if (lpPolicy !\u003d null \u0026\u0026\n        lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n      throw new UnsupportedOperationException(\n          \"Cannot truncate lazy persist file \" + src);\n    }\n\n    // Check if the file is already being truncated with the same length\n    final BlockInfo last \u003d file.getLastBlock();\n    if (last !\u003d null \u0026\u0026 last.getBlockUCState() \u003d\u003d BlockUCState.UNDER_RECOVERY) {\n      final Block truncateBlock\n          \u003d ((BlockInfoContiguousUnderConstruction)last).getTruncateBlock();\n      if (truncateBlock !\u003d null) {\n        final long truncateLength \u003d file.computeFileSize(false, false)\n            + truncateBlock.getNumBytes();\n        if (newLength \u003d\u003d truncateLength) {\n          return false;\n        }\n      }\n    }\n\n    // Opening an existing file for truncate. May need lease recovery.\n    recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE,\n        iip, src, clientName, clientMachine, false);\n    // Truncate length check.\n    long oldLength \u003d file.computeFileSize();\n    if(oldLength \u003d\u003d newLength) {\n      return true;\n    }\n    if(oldLength \u003c newLength) {\n      throw new HadoopIllegalArgumentException(\n          \"Cannot truncate to a larger file size. Current size: \" + oldLength +\n              \", truncate size: \" + newLength + \".\");\n    }\n    // Perform INodeFile truncation.\n    final QuotaCounts delta \u003d new QuotaCounts.Builder().build();\n    boolean onBlockBoundary \u003d dir.truncate(iip, newLength, toRemoveBlocks,\n        mtime, delta);\n    Block truncateBlock \u003d null;\n    if(!onBlockBoundary) {\n      // Open file for write, but don\u0027t log into edits\n      long lastBlockDelta \u003d file.computeFileSize() - newLength;\n      assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n      truncateBlock \u003d prepareFileForTruncate(iip, clientName, clientMachine,\n          lastBlockDelta, null);\n    }\n\n    // update the quota: use the preferred block size for UC block\n    dir.writeLock();\n    try {\n      dir.updateCountNoQuotaCheck(iip, iip.length() - 1, delta);\n    } finally {\n      dir.writeUnlock();\n    }\n\n    getEditLog().logTruncate(src, clientName, clientMachine, newLength, mtime,\n        truncateBlock);\n    return onBlockBoundary;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "d368d3647a858644b9fcd3be33d9fea2a6962f69": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7957. Truncate should verify quota before making changes. Contributed by Jing Zhao.\n",
      "commitDate": "20/03/15 11:50 AM",
      "commitName": "d368d3647a858644b9fcd3be33d9fea2a6962f69",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "20/03/15 10:50 AM",
      "commitNameOld": "a6a5aae472d015d2ea5cd746719485dff93873a8",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 0.04,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,62 +1,72 @@\n   boolean truncateInternal(String src, long newLength,\n                            String clientName, String clientMachine,\n                            long mtime, FSPermissionChecker pc,\n                            BlocksMapUpdateInfo toRemoveBlocks)\n       throws IOException, UnresolvedLinkException {\n     assert hasWriteLock();\n     INodesInPath iip \u003d dir.getINodesInPath4Write(src, true);\n     if (isPermissionEnabled) {\n       dir.checkPathAccess(pc, iip, FsAction.WRITE);\n     }\n     INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n     final BlockStoragePolicy lpPolicy \u003d\n         blockManager.getStoragePolicy(\"LAZY_PERSIST\");\n \n     if (lpPolicy !\u003d null \u0026\u0026\n         lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n       throw new UnsupportedOperationException(\n           \"Cannot truncate lazy persist file \" + src);\n     }\n \n     // Check if the file is already being truncated with the same length\n     final BlockInfoContiguous last \u003d file.getLastBlock();\n     if (last !\u003d null \u0026\u0026 last.getBlockUCState() \u003d\u003d BlockUCState.UNDER_RECOVERY) {\n       final Block truncateBlock\n           \u003d ((BlockInfoContiguousUnderConstruction)last).getTruncateBlock();\n       if (truncateBlock !\u003d null) {\n         final long truncateLength \u003d file.computeFileSize(false, false)\n             + truncateBlock.getNumBytes();\n         if (newLength \u003d\u003d truncateLength) {\n           return false;\n         }\n       }\n     }\n \n     // Opening an existing file for truncate. May need lease recovery.\n     recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE,\n         iip, src, clientName, clientMachine, false);\n     // Truncate length check.\n     long oldLength \u003d file.computeFileSize();\n     if(oldLength \u003d\u003d newLength) {\n       return true;\n     }\n     if(oldLength \u003c newLength) {\n       throw new HadoopIllegalArgumentException(\n           \"Cannot truncate to a larger file size. Current size: \" + oldLength +\n               \", truncate size: \" + newLength + \".\");\n     }\n     // Perform INodeFile truncation.\n-    boolean onBlockBoundary \u003d dir.truncate(iip, newLength,\n-        toRemoveBlocks, mtime);\n+    final QuotaCounts delta \u003d new QuotaCounts.Builder().build();\n+    boolean onBlockBoundary \u003d dir.truncate(iip, newLength, toRemoveBlocks,\n+        mtime, delta);\n     Block truncateBlock \u003d null;\n-    if(! onBlockBoundary) {\n+    if(!onBlockBoundary) {\n       // Open file for write, but don\u0027t log into edits\n       long lastBlockDelta \u003d file.computeFileSize() - newLength;\n       assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n       truncateBlock \u003d prepareFileForTruncate(iip, clientName, clientMachine,\n           lastBlockDelta, null);\n     }\n+\n+    // update the quota: use the preferred block size for UC block\n+    dir.writeLock();\n+    try {\n+      dir.updateCountNoQuotaCheck(iip, iip.length() - 1, delta);\n+    } finally {\n+      dir.writeUnlock();\n+    }\n+\n     getEditLog().logTruncate(src, clientName, clientMachine, newLength, mtime,\n         truncateBlock);\n     return onBlockBoundary;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  boolean truncateInternal(String src, long newLength,\n                           String clientName, String clientMachine,\n                           long mtime, FSPermissionChecker pc,\n                           BlocksMapUpdateInfo toRemoveBlocks)\n      throws IOException, UnresolvedLinkException {\n    assert hasWriteLock();\n    INodesInPath iip \u003d dir.getINodesInPath4Write(src, true);\n    if (isPermissionEnabled) {\n      dir.checkPathAccess(pc, iip, FsAction.WRITE);\n    }\n    INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n    final BlockStoragePolicy lpPolicy \u003d\n        blockManager.getStoragePolicy(\"LAZY_PERSIST\");\n\n    if (lpPolicy !\u003d null \u0026\u0026\n        lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n      throw new UnsupportedOperationException(\n          \"Cannot truncate lazy persist file \" + src);\n    }\n\n    // Check if the file is already being truncated with the same length\n    final BlockInfoContiguous last \u003d file.getLastBlock();\n    if (last !\u003d null \u0026\u0026 last.getBlockUCState() \u003d\u003d BlockUCState.UNDER_RECOVERY) {\n      final Block truncateBlock\n          \u003d ((BlockInfoContiguousUnderConstruction)last).getTruncateBlock();\n      if (truncateBlock !\u003d null) {\n        final long truncateLength \u003d file.computeFileSize(false, false)\n            + truncateBlock.getNumBytes();\n        if (newLength \u003d\u003d truncateLength) {\n          return false;\n        }\n      }\n    }\n\n    // Opening an existing file for truncate. May need lease recovery.\n    recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE,\n        iip, src, clientName, clientMachine, false);\n    // Truncate length check.\n    long oldLength \u003d file.computeFileSize();\n    if(oldLength \u003d\u003d newLength) {\n      return true;\n    }\n    if(oldLength \u003c newLength) {\n      throw new HadoopIllegalArgumentException(\n          \"Cannot truncate to a larger file size. Current size: \" + oldLength +\n              \", truncate size: \" + newLength + \".\");\n    }\n    // Perform INodeFile truncation.\n    final QuotaCounts delta \u003d new QuotaCounts.Builder().build();\n    boolean onBlockBoundary \u003d dir.truncate(iip, newLength, toRemoveBlocks,\n        mtime, delta);\n    Block truncateBlock \u003d null;\n    if(!onBlockBoundary) {\n      // Open file for write, but don\u0027t log into edits\n      long lastBlockDelta \u003d file.computeFileSize() - newLength;\n      assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n      truncateBlock \u003d prepareFileForTruncate(iip, clientName, clientMachine,\n          lastBlockDelta, null);\n    }\n\n    // update the quota: use the preferred block size for UC block\n    dir.writeLock();\n    try {\n      dir.updateCountNoQuotaCheck(iip, iip.length() - 1, delta);\n    } finally {\n      dir.writeUnlock();\n    }\n\n    getEditLog().logTruncate(src, clientName, clientMachine, newLength, mtime,\n        truncateBlock);\n    return onBlockBoundary;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "f446669afb5c3d31a00c65449f27088b39e11ae3": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7926. NameNode implementation of ClientProtocol.truncate(..) is not idempotent. Contributed by Tsz Wo Nicholas Sze\n",
      "commitDate": "13/03/15 10:42 AM",
      "commitName": "f446669afb5c3d31a00c65449f27088b39e11ae3",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "04/03/15 1:08 AM",
      "commitNameOld": "3560180b6e9926aa3ee1357da59b28a4b4689a0d",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 9.36,
      "commitsBetweenForRepo": 67,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,47 +1,62 @@\n   boolean truncateInternal(String src, long newLength,\n                            String clientName, String clientMachine,\n                            long mtime, FSPermissionChecker pc,\n                            BlocksMapUpdateInfo toRemoveBlocks)\n       throws IOException, UnresolvedLinkException {\n     assert hasWriteLock();\n     INodesInPath iip \u003d dir.getINodesInPath4Write(src, true);\n     if (isPermissionEnabled) {\n       dir.checkPathAccess(pc, iip, FsAction.WRITE);\n     }\n     INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n     final BlockStoragePolicy lpPolicy \u003d\n         blockManager.getStoragePolicy(\"LAZY_PERSIST\");\n \n     if (lpPolicy !\u003d null \u0026\u0026\n         lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n       throw new UnsupportedOperationException(\n           \"Cannot truncate lazy persist file \" + src);\n     }\n+\n+    // Check if the file is already being truncated with the same length\n+    final BlockInfoContiguous last \u003d file.getLastBlock();\n+    if (last !\u003d null \u0026\u0026 last.getBlockUCState() \u003d\u003d BlockUCState.UNDER_RECOVERY) {\n+      final Block truncateBlock\n+          \u003d ((BlockInfoContiguousUnderConstruction)last).getTruncateBlock();\n+      if (truncateBlock !\u003d null) {\n+        final long truncateLength \u003d file.computeFileSize(false, false)\n+            + truncateBlock.getNumBytes();\n+        if (newLength \u003d\u003d truncateLength) {\n+          return false;\n+        }\n+      }\n+    }\n+\n     // Opening an existing file for truncate. May need lease recovery.\n     recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE,\n         iip, src, clientName, clientMachine, false);\n     // Truncate length check.\n     long oldLength \u003d file.computeFileSize();\n     if(oldLength \u003d\u003d newLength) {\n       return true;\n     }\n     if(oldLength \u003c newLength) {\n       throw new HadoopIllegalArgumentException(\n           \"Cannot truncate to a larger file size. Current size: \" + oldLength +\n               \", truncate size: \" + newLength + \".\");\n     }\n     // Perform INodeFile truncation.\n     boolean onBlockBoundary \u003d dir.truncate(iip, newLength,\n         toRemoveBlocks, mtime);\n     Block truncateBlock \u003d null;\n     if(! onBlockBoundary) {\n       // Open file for write, but don\u0027t log into edits\n       long lastBlockDelta \u003d file.computeFileSize() - newLength;\n       assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n       truncateBlock \u003d prepareFileForTruncate(iip, clientName, clientMachine,\n           lastBlockDelta, null);\n     }\n     getEditLog().logTruncate(src, clientName, clientMachine, newLength, mtime,\n         truncateBlock);\n     return onBlockBoundary;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  boolean truncateInternal(String src, long newLength,\n                           String clientName, String clientMachine,\n                           long mtime, FSPermissionChecker pc,\n                           BlocksMapUpdateInfo toRemoveBlocks)\n      throws IOException, UnresolvedLinkException {\n    assert hasWriteLock();\n    INodesInPath iip \u003d dir.getINodesInPath4Write(src, true);\n    if (isPermissionEnabled) {\n      dir.checkPathAccess(pc, iip, FsAction.WRITE);\n    }\n    INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n    final BlockStoragePolicy lpPolicy \u003d\n        blockManager.getStoragePolicy(\"LAZY_PERSIST\");\n\n    if (lpPolicy !\u003d null \u0026\u0026\n        lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n      throw new UnsupportedOperationException(\n          \"Cannot truncate lazy persist file \" + src);\n    }\n\n    // Check if the file is already being truncated with the same length\n    final BlockInfoContiguous last \u003d file.getLastBlock();\n    if (last !\u003d null \u0026\u0026 last.getBlockUCState() \u003d\u003d BlockUCState.UNDER_RECOVERY) {\n      final Block truncateBlock\n          \u003d ((BlockInfoContiguousUnderConstruction)last).getTruncateBlock();\n      if (truncateBlock !\u003d null) {\n        final long truncateLength \u003d file.computeFileSize(false, false)\n            + truncateBlock.getNumBytes();\n        if (newLength \u003d\u003d truncateLength) {\n          return false;\n        }\n      }\n    }\n\n    // Opening an existing file for truncate. May need lease recovery.\n    recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE,\n        iip, src, clientName, clientMachine, false);\n    // Truncate length check.\n    long oldLength \u003d file.computeFileSize();\n    if(oldLength \u003d\u003d newLength) {\n      return true;\n    }\n    if(oldLength \u003c newLength) {\n      throw new HadoopIllegalArgumentException(\n          \"Cannot truncate to a larger file size. Current size: \" + oldLength +\n              \", truncate size: \" + newLength + \".\");\n    }\n    // Perform INodeFile truncation.\n    boolean onBlockBoundary \u003d dir.truncate(iip, newLength,\n        toRemoveBlocks, mtime);\n    Block truncateBlock \u003d null;\n    if(! onBlockBoundary) {\n      // Open file for write, but don\u0027t log into edits\n      long lastBlockDelta \u003d file.computeFileSize() - newLength;\n      assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n      truncateBlock \u003d prepareFileForTruncate(iip, clientName, clientMachine,\n          lastBlockDelta, null);\n    }\n    getEditLog().logTruncate(src, clientName, clientMachine, newLength, mtime,\n        truncateBlock);\n    return onBlockBoundary;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "8f7d4bb09f760780dd193c97796ebf4d22cfd2d7": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7738. Revise the exception message for recover lease; add more truncate tests such as truncate with HA setup, negative tests, truncate with other operations and multiple truncates.\n",
      "commitDate": "07/02/15 3:21 PM",
      "commitName": "8f7d4bb09f760780dd193c97796ebf4d22cfd2d7",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "03/02/15 12:45 PM",
      "commitNameOld": "843806d03ab1a24f191782f42eb817505228eb9f",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 4.11,
      "commitsBetweenForRepo": 59,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,46 +1,47 @@\n   boolean truncateInternal(String src, long newLength,\n                            String clientName, String clientMachine,\n                            long mtime, FSPermissionChecker pc,\n                            BlocksMapUpdateInfo toRemoveBlocks)\n       throws IOException, UnresolvedLinkException {\n     assert hasWriteLock();\n     INodesInPath iip \u003d dir.getINodesInPath4Write(src, true);\n     if (isPermissionEnabled) {\n       dir.checkPathAccess(pc, iip, FsAction.WRITE);\n     }\n     INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n     final BlockStoragePolicy lpPolicy \u003d\n         blockManager.getStoragePolicy(\"LAZY_PERSIST\");\n \n     if (lpPolicy !\u003d null \u0026\u0026\n         lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n       throw new UnsupportedOperationException(\n           \"Cannot truncate lazy persist file \" + src);\n     }\n-    // Opening an existing file for write. May need lease recovery.\n-    recoverLeaseInternal(iip, src, clientName, clientMachine, false);\n+    // Opening an existing file for truncate. May need lease recovery.\n+    recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE,\n+        iip, src, clientName, clientMachine, false);\n     // Truncate length check.\n     long oldLength \u003d file.computeFileSize();\n     if(oldLength \u003d\u003d newLength) {\n       return true;\n     }\n     if(oldLength \u003c newLength) {\n       throw new HadoopIllegalArgumentException(\n           \"Cannot truncate to a larger file size. Current size: \" + oldLength +\n               \", truncate size: \" + newLength + \".\");\n     }\n     // Perform INodeFile truncation.\n     boolean onBlockBoundary \u003d dir.truncate(iip, newLength,\n         toRemoveBlocks, mtime);\n     Block truncateBlock \u003d null;\n     if(! onBlockBoundary) {\n       // Open file for write, but don\u0027t log into edits\n       long lastBlockDelta \u003d file.computeFileSize() - newLength;\n       assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n       truncateBlock \u003d prepareFileForTruncate(iip, clientName, clientMachine,\n           lastBlockDelta, null);\n     }\n     getEditLog().logTruncate(src, clientName, clientMachine, newLength, mtime,\n         truncateBlock);\n     return onBlockBoundary;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  boolean truncateInternal(String src, long newLength,\n                           String clientName, String clientMachine,\n                           long mtime, FSPermissionChecker pc,\n                           BlocksMapUpdateInfo toRemoveBlocks)\n      throws IOException, UnresolvedLinkException {\n    assert hasWriteLock();\n    INodesInPath iip \u003d dir.getINodesInPath4Write(src, true);\n    if (isPermissionEnabled) {\n      dir.checkPathAccess(pc, iip, FsAction.WRITE);\n    }\n    INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n    final BlockStoragePolicy lpPolicy \u003d\n        blockManager.getStoragePolicy(\"LAZY_PERSIST\");\n\n    if (lpPolicy !\u003d null \u0026\u0026\n        lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n      throw new UnsupportedOperationException(\n          \"Cannot truncate lazy persist file \" + src);\n    }\n    // Opening an existing file for truncate. May need lease recovery.\n    recoverLeaseInternal(RecoverLeaseOp.TRUNCATE_FILE,\n        iip, src, clientName, clientMachine, false);\n    // Truncate length check.\n    long oldLength \u003d file.computeFileSize();\n    if(oldLength \u003d\u003d newLength) {\n      return true;\n    }\n    if(oldLength \u003c newLength) {\n      throw new HadoopIllegalArgumentException(\n          \"Cannot truncate to a larger file size. Current size: \" + oldLength +\n              \", truncate size: \" + newLength + \".\");\n    }\n    // Perform INodeFile truncation.\n    boolean onBlockBoundary \u003d dir.truncate(iip, newLength,\n        toRemoveBlocks, mtime);\n    Block truncateBlock \u003d null;\n    if(! onBlockBoundary) {\n      // Open file for write, but don\u0027t log into edits\n      long lastBlockDelta \u003d file.computeFileSize() - newLength;\n      assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n      truncateBlock \u003d prepareFileForTruncate(iip, clientName, clientMachine,\n          lastBlockDelta, null);\n    }\n    getEditLog().logTruncate(src, clientName, clientMachine, newLength, mtime,\n        truncateBlock);\n    return onBlockBoundary;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "c09c65b2125908855a5f1d0047bc164ea4bea04d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7634. Disallow truncation of Lazy persist files. (Contributed by Yi Liu)\n",
      "commitDate": "20/01/15 12:11 PM",
      "commitName": "c09c65b2125908855a5f1d0047bc164ea4bea04d",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "19/01/15 8:45 AM",
      "commitNameOld": "5a6c084f074990a1f412475b147fd4f040b57d57",
      "commitAuthorOld": "yliu",
      "daysBetweenCommits": 1.14,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,38 +1,46 @@\n   boolean truncateInternal(String src, long newLength,\n                            String clientName, String clientMachine,\n                            long mtime, FSPermissionChecker pc,\n                            BlocksMapUpdateInfo toRemoveBlocks)\n       throws IOException, UnresolvedLinkException {\n     assert hasWriteLock();\n     INodesInPath iip \u003d dir.getINodesInPath4Write(src, true);\n     if (isPermissionEnabled) {\n       dir.checkPathAccess(pc, iip, FsAction.WRITE);\n     }\n     INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n+    final BlockStoragePolicy lpPolicy \u003d\n+        blockManager.getStoragePolicy(\"LAZY_PERSIST\");\n+\n+    if (lpPolicy !\u003d null \u0026\u0026\n+        lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n+      throw new UnsupportedOperationException(\n+          \"Cannot truncate lazy persist file \" + src);\n+    }\n     // Opening an existing file for write. May need lease recovery.\n     recoverLeaseInternal(iip, src, clientName, clientMachine, false);\n     // Truncate length check.\n     long oldLength \u003d file.computeFileSize();\n     if(oldLength \u003d\u003d newLength) {\n       return true;\n     }\n     if(oldLength \u003c newLength) {\n       throw new HadoopIllegalArgumentException(\n           \"Cannot truncate to a larger file size. Current size: \" + oldLength +\n               \", truncate size: \" + newLength + \".\");\n     }\n     // Perform INodeFile truncation.\n     boolean onBlockBoundary \u003d dir.truncate(iip, newLength,\n         toRemoveBlocks, mtime);\n     Block truncateBlock \u003d null;\n     if(! onBlockBoundary) {\n       // Open file for write, but don\u0027t log into edits\n       long lastBlockDelta \u003d file.computeFileSize() - newLength;\n       assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n       truncateBlock \u003d prepareFileForTruncate(iip, clientName, clientMachine,\n           lastBlockDelta, null);\n     }\n     getEditLog().logTruncate(src, clientName, clientMachine, newLength, mtime,\n         truncateBlock);\n     return onBlockBoundary;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  boolean truncateInternal(String src, long newLength,\n                           String clientName, String clientMachine,\n                           long mtime, FSPermissionChecker pc,\n                           BlocksMapUpdateInfo toRemoveBlocks)\n      throws IOException, UnresolvedLinkException {\n    assert hasWriteLock();\n    INodesInPath iip \u003d dir.getINodesInPath4Write(src, true);\n    if (isPermissionEnabled) {\n      dir.checkPathAccess(pc, iip, FsAction.WRITE);\n    }\n    INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n    final BlockStoragePolicy lpPolicy \u003d\n        blockManager.getStoragePolicy(\"LAZY_PERSIST\");\n\n    if (lpPolicy !\u003d null \u0026\u0026\n        lpPolicy.getId() \u003d\u003d file.getStoragePolicyID()) {\n      throw new UnsupportedOperationException(\n          \"Cannot truncate lazy persist file \" + src);\n    }\n    // Opening an existing file for write. May need lease recovery.\n    recoverLeaseInternal(iip, src, clientName, clientMachine, false);\n    // Truncate length check.\n    long oldLength \u003d file.computeFileSize();\n    if(oldLength \u003d\u003d newLength) {\n      return true;\n    }\n    if(oldLength \u003c newLength) {\n      throw new HadoopIllegalArgumentException(\n          \"Cannot truncate to a larger file size. Current size: \" + oldLength +\n              \", truncate size: \" + newLength + \".\");\n    }\n    // Perform INodeFile truncation.\n    boolean onBlockBoundary \u003d dir.truncate(iip, newLength,\n        toRemoveBlocks, mtime);\n    Block truncateBlock \u003d null;\n    if(! onBlockBoundary) {\n      // Open file for write, but don\u0027t log into edits\n      long lastBlockDelta \u003d file.computeFileSize() - newLength;\n      assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n      truncateBlock \u003d prepareFileForTruncate(iip, clientName, clientMachine,\n          lastBlockDelta, null);\n    }\n    getEditLog().logTruncate(src, clientName, clientMachine, newLength, mtime,\n        truncateBlock);\n    return onBlockBoundary;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "5a6c084f074990a1f412475b147fd4f040b57d57": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-7638: Small fix and few refinements for FSN#truncate. (yliu)\n",
      "commitDate": "19/01/15 8:45 AM",
      "commitName": "5a6c084f074990a1f412475b147fd4f040b57d57",
      "commitAuthor": "yliu",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-7638: Small fix and few refinements for FSN#truncate. (yliu)\n",
          "commitDate": "19/01/15 8:45 AM",
          "commitName": "5a6c084f074990a1f412475b147fd4f040b57d57",
          "commitAuthor": "yliu",
          "commitDateOld": "17/01/15 12:56 PM",
          "commitNameOld": "24315e7d374a1ddd4329b64350cf96fc9ab6f59c",
          "commitAuthorOld": "Haohui Mai",
          "daysBetweenCommits": 1.83,
          "commitsBetweenForRepo": 9,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,40 +1,38 @@\n   boolean truncateInternal(String src, long newLength,\n                            String clientName, String clientMachine,\n-                           long mtime, FSPermissionChecker pc)\n+                           long mtime, FSPermissionChecker pc,\n+                           BlocksMapUpdateInfo toRemoveBlocks)\n       throws IOException, UnresolvedLinkException {\n     assert hasWriteLock();\n     INodesInPath iip \u003d dir.getINodesInPath4Write(src, true);\n     if (isPermissionEnabled) {\n       dir.checkPathAccess(pc, iip, FsAction.WRITE);\n     }\n-    INodeFile file \u003d iip.getLastINode().asFile();\n+    INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n     // Opening an existing file for write. May need lease recovery.\n     recoverLeaseInternal(iip, src, clientName, clientMachine, false);\n-    file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n     // Truncate length check.\n     long oldLength \u003d file.computeFileSize();\n     if(oldLength \u003d\u003d newLength) {\n       return true;\n     }\n     if(oldLength \u003c newLength) {\n       throw new HadoopIllegalArgumentException(\n           \"Cannot truncate to a larger file size. Current size: \" + oldLength +\n               \", truncate size: \" + newLength + \".\");\n     }\n     // Perform INodeFile truncation.\n-    BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n     boolean onBlockBoundary \u003d dir.truncate(iip, newLength,\n-                                           collectedBlocks, mtime);\n+        toRemoveBlocks, mtime);\n     Block truncateBlock \u003d null;\n     if(! onBlockBoundary) {\n       // Open file for write, but don\u0027t log into edits\n       long lastBlockDelta \u003d file.computeFileSize() - newLength;\n       assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n       truncateBlock \u003d prepareFileForTruncate(iip, clientName, clientMachine,\n           lastBlockDelta, null);\n     }\n     getEditLog().logTruncate(src, clientName, clientMachine, newLength, mtime,\n         truncateBlock);\n-    removeBlocks(collectedBlocks);\n     return onBlockBoundary;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  boolean truncateInternal(String src, long newLength,\n                           String clientName, String clientMachine,\n                           long mtime, FSPermissionChecker pc,\n                           BlocksMapUpdateInfo toRemoveBlocks)\n      throws IOException, UnresolvedLinkException {\n    assert hasWriteLock();\n    INodesInPath iip \u003d dir.getINodesInPath4Write(src, true);\n    if (isPermissionEnabled) {\n      dir.checkPathAccess(pc, iip, FsAction.WRITE);\n    }\n    INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n    // Opening an existing file for write. May need lease recovery.\n    recoverLeaseInternal(iip, src, clientName, clientMachine, false);\n    // Truncate length check.\n    long oldLength \u003d file.computeFileSize();\n    if(oldLength \u003d\u003d newLength) {\n      return true;\n    }\n    if(oldLength \u003c newLength) {\n      throw new HadoopIllegalArgumentException(\n          \"Cannot truncate to a larger file size. Current size: \" + oldLength +\n              \", truncate size: \" + newLength + \".\");\n    }\n    // Perform INodeFile truncation.\n    boolean onBlockBoundary \u003d dir.truncate(iip, newLength,\n        toRemoveBlocks, mtime);\n    Block truncateBlock \u003d null;\n    if(! onBlockBoundary) {\n      // Open file for write, but don\u0027t log into edits\n      long lastBlockDelta \u003d file.computeFileSize() - newLength;\n      assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n      truncateBlock \u003d prepareFileForTruncate(iip, clientName, clientMachine,\n          lastBlockDelta, null);\n    }\n    getEditLog().logTruncate(src, clientName, clientMachine, newLength, mtime,\n        truncateBlock);\n    return onBlockBoundary;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {
            "oldValue": "[src-String, newLength-long, clientName-String, clientMachine-String, mtime-long, pc-FSPermissionChecker]",
            "newValue": "[src-String, newLength-long, clientName-String, clientMachine-String, mtime-long, pc-FSPermissionChecker, toRemoveBlocks-BlocksMapUpdateInfo]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7638: Small fix and few refinements for FSN#truncate. (yliu)\n",
          "commitDate": "19/01/15 8:45 AM",
          "commitName": "5a6c084f074990a1f412475b147fd4f040b57d57",
          "commitAuthor": "yliu",
          "commitDateOld": "17/01/15 12:56 PM",
          "commitNameOld": "24315e7d374a1ddd4329b64350cf96fc9ab6f59c",
          "commitAuthorOld": "Haohui Mai",
          "daysBetweenCommits": 1.83,
          "commitsBetweenForRepo": 9,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,40 +1,38 @@\n   boolean truncateInternal(String src, long newLength,\n                            String clientName, String clientMachine,\n-                           long mtime, FSPermissionChecker pc)\n+                           long mtime, FSPermissionChecker pc,\n+                           BlocksMapUpdateInfo toRemoveBlocks)\n       throws IOException, UnresolvedLinkException {\n     assert hasWriteLock();\n     INodesInPath iip \u003d dir.getINodesInPath4Write(src, true);\n     if (isPermissionEnabled) {\n       dir.checkPathAccess(pc, iip, FsAction.WRITE);\n     }\n-    INodeFile file \u003d iip.getLastINode().asFile();\n+    INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n     // Opening an existing file for write. May need lease recovery.\n     recoverLeaseInternal(iip, src, clientName, clientMachine, false);\n-    file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n     // Truncate length check.\n     long oldLength \u003d file.computeFileSize();\n     if(oldLength \u003d\u003d newLength) {\n       return true;\n     }\n     if(oldLength \u003c newLength) {\n       throw new HadoopIllegalArgumentException(\n           \"Cannot truncate to a larger file size. Current size: \" + oldLength +\n               \", truncate size: \" + newLength + \".\");\n     }\n     // Perform INodeFile truncation.\n-    BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n     boolean onBlockBoundary \u003d dir.truncate(iip, newLength,\n-                                           collectedBlocks, mtime);\n+        toRemoveBlocks, mtime);\n     Block truncateBlock \u003d null;\n     if(! onBlockBoundary) {\n       // Open file for write, but don\u0027t log into edits\n       long lastBlockDelta \u003d file.computeFileSize() - newLength;\n       assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n       truncateBlock \u003d prepareFileForTruncate(iip, clientName, clientMachine,\n           lastBlockDelta, null);\n     }\n     getEditLog().logTruncate(src, clientName, clientMachine, newLength, mtime,\n         truncateBlock);\n-    removeBlocks(collectedBlocks);\n     return onBlockBoundary;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  boolean truncateInternal(String src, long newLength,\n                           String clientName, String clientMachine,\n                           long mtime, FSPermissionChecker pc,\n                           BlocksMapUpdateInfo toRemoveBlocks)\n      throws IOException, UnresolvedLinkException {\n    assert hasWriteLock();\n    INodesInPath iip \u003d dir.getINodesInPath4Write(src, true);\n    if (isPermissionEnabled) {\n      dir.checkPathAccess(pc, iip, FsAction.WRITE);\n    }\n    INodeFile file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n    // Opening an existing file for write. May need lease recovery.\n    recoverLeaseInternal(iip, src, clientName, clientMachine, false);\n    // Truncate length check.\n    long oldLength \u003d file.computeFileSize();\n    if(oldLength \u003d\u003d newLength) {\n      return true;\n    }\n    if(oldLength \u003c newLength) {\n      throw new HadoopIllegalArgumentException(\n          \"Cannot truncate to a larger file size. Current size: \" + oldLength +\n              \", truncate size: \" + newLength + \".\");\n    }\n    // Perform INodeFile truncation.\n    boolean onBlockBoundary \u003d dir.truncate(iip, newLength,\n        toRemoveBlocks, mtime);\n    Block truncateBlock \u003d null;\n    if(! onBlockBoundary) {\n      // Open file for write, but don\u0027t log into edits\n      long lastBlockDelta \u003d file.computeFileSize() - newLength;\n      assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n      truncateBlock \u003d prepareFileForTruncate(iip, clientName, clientMachine,\n          lastBlockDelta, null);\n    }\n    getEditLog().logTruncate(src, clientName, clientMachine, newLength, mtime,\n        truncateBlock);\n    return onBlockBoundary;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {}
        }
      ]
    },
    "08ac06283a3e9bf0d49d873823aabd419b08e41f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7056. Snapshot support for truncate. Contributed by Konstantin Shvachko and Plamen Jeliazkov.",
      "commitDate": "13/01/15 12:24 AM",
      "commitName": "08ac06283a3e9bf0d49d873823aabd419b08e41f",
      "commitAuthor": "Konstantin V Shvachko",
      "commitDateOld": "12/01/15 10:50 PM",
      "commitNameOld": "7e9358feb326d48b8c4f00249e7af5023cebd2e2",
      "commitAuthorOld": "Plamen Jeliazkov",
      "daysBetweenCommits": 0.07,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,42 +1,40 @@\n   boolean truncateInternal(String src, long newLength,\n                            String clientName, String clientMachine,\n                            long mtime, FSPermissionChecker pc)\n       throws IOException, UnresolvedLinkException {\n     assert hasWriteLock();\n     INodesInPath iip \u003d dir.getINodesInPath4Write(src, true);\n     if (isPermissionEnabled) {\n       dir.checkPathAccess(pc, iip, FsAction.WRITE);\n     }\n     INodeFile file \u003d iip.getLastINode().asFile();\n-    // Data will be lost after truncate occurs so it cannot support snapshots.\n-    if(file.isInLatestSnapshot(iip.getLatestSnapshotId()))\n-      throw new HadoopIllegalArgumentException(\n-          \"Cannot truncate file with snapshot.\");\n     // Opening an existing file for write. May need lease recovery.\n     recoverLeaseInternal(iip, src, clientName, clientMachine, false);\n-    // Refresh INode as the file could have been closed\n-    iip \u003d dir.getINodesInPath4Write(src, true);\n     file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n     // Truncate length check.\n     long oldLength \u003d file.computeFileSize();\n-    if(oldLength \u003d\u003d newLength)\n+    if(oldLength \u003d\u003d newLength) {\n       return true;\n-    if(oldLength \u003c newLength)\n+    }\n+    if(oldLength \u003c newLength) {\n       throw new HadoopIllegalArgumentException(\n           \"Cannot truncate to a larger file size. Current size: \" + oldLength +\n               \", truncate size: \" + newLength + \".\");\n+    }\n     // Perform INodeFile truncation.\n     BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n     boolean onBlockBoundary \u003d dir.truncate(iip, newLength,\n                                            collectedBlocks, mtime);\n-\n+    Block truncateBlock \u003d null;\n     if(! onBlockBoundary) {\n       // Open file for write, but don\u0027t log into edits\n-      prepareFileForWrite(src, iip, clientName, clientMachine, false, false);\n-      file \u003d INodeFile.valueOf(dir.getINode4Write(src), src);\n-      initializeBlockRecovery(file);\n+      long lastBlockDelta \u003d file.computeFileSize() - newLength;\n+      assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n+      truncateBlock \u003d prepareFileForTruncate(iip, clientName, clientMachine,\n+          lastBlockDelta, null);\n     }\n-    getEditLog().logTruncate(src, clientName, clientMachine, newLength, mtime);\n+    getEditLog().logTruncate(src, clientName, clientMachine, newLength, mtime,\n+        truncateBlock);\n     removeBlocks(collectedBlocks);\n     return onBlockBoundary;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  boolean truncateInternal(String src, long newLength,\n                           String clientName, String clientMachine,\n                           long mtime, FSPermissionChecker pc)\n      throws IOException, UnresolvedLinkException {\n    assert hasWriteLock();\n    INodesInPath iip \u003d dir.getINodesInPath4Write(src, true);\n    if (isPermissionEnabled) {\n      dir.checkPathAccess(pc, iip, FsAction.WRITE);\n    }\n    INodeFile file \u003d iip.getLastINode().asFile();\n    // Opening an existing file for write. May need lease recovery.\n    recoverLeaseInternal(iip, src, clientName, clientMachine, false);\n    file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n    // Truncate length check.\n    long oldLength \u003d file.computeFileSize();\n    if(oldLength \u003d\u003d newLength) {\n      return true;\n    }\n    if(oldLength \u003c newLength) {\n      throw new HadoopIllegalArgumentException(\n          \"Cannot truncate to a larger file size. Current size: \" + oldLength +\n              \", truncate size: \" + newLength + \".\");\n    }\n    // Perform INodeFile truncation.\n    BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n    boolean onBlockBoundary \u003d dir.truncate(iip, newLength,\n                                           collectedBlocks, mtime);\n    Block truncateBlock \u003d null;\n    if(! onBlockBoundary) {\n      // Open file for write, but don\u0027t log into edits\n      long lastBlockDelta \u003d file.computeFileSize() - newLength;\n      assert lastBlockDelta \u003e 0 : \"delta is 0 only if on block bounday\";\n      truncateBlock \u003d prepareFileForTruncate(iip, clientName, clientMachine,\n          lastBlockDelta, null);\n    }\n    getEditLog().logTruncate(src, clientName, clientMachine, newLength, mtime,\n        truncateBlock);\n    removeBlocks(collectedBlocks);\n    return onBlockBoundary;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "7e9358feb326d48b8c4f00249e7af5023cebd2e2": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-3107. Introduce truncate. Contributed by Plamen Jeliazkov.",
      "commitDate": "12/01/15 10:50 PM",
      "commitName": "7e9358feb326d48b8c4f00249e7af5023cebd2e2",
      "commitAuthor": "Plamen Jeliazkov",
      "diff": "@@ -0,0 +1,42 @@\n+  boolean truncateInternal(String src, long newLength,\n+                           String clientName, String clientMachine,\n+                           long mtime, FSPermissionChecker pc)\n+      throws IOException, UnresolvedLinkException {\n+    assert hasWriteLock();\n+    INodesInPath iip \u003d dir.getINodesInPath4Write(src, true);\n+    if (isPermissionEnabled) {\n+      dir.checkPathAccess(pc, iip, FsAction.WRITE);\n+    }\n+    INodeFile file \u003d iip.getLastINode().asFile();\n+    // Data will be lost after truncate occurs so it cannot support snapshots.\n+    if(file.isInLatestSnapshot(iip.getLatestSnapshotId()))\n+      throw new HadoopIllegalArgumentException(\n+          \"Cannot truncate file with snapshot.\");\n+    // Opening an existing file for write. May need lease recovery.\n+    recoverLeaseInternal(iip, src, clientName, clientMachine, false);\n+    // Refresh INode as the file could have been closed\n+    iip \u003d dir.getINodesInPath4Write(src, true);\n+    file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n+    // Truncate length check.\n+    long oldLength \u003d file.computeFileSize();\n+    if(oldLength \u003d\u003d newLength)\n+      return true;\n+    if(oldLength \u003c newLength)\n+      throw new HadoopIllegalArgumentException(\n+          \"Cannot truncate to a larger file size. Current size: \" + oldLength +\n+              \", truncate size: \" + newLength + \".\");\n+    // Perform INodeFile truncation.\n+    BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n+    boolean onBlockBoundary \u003d dir.truncate(iip, newLength,\n+                                           collectedBlocks, mtime);\n+\n+    if(! onBlockBoundary) {\n+      // Open file for write, but don\u0027t log into edits\n+      prepareFileForWrite(src, iip, clientName, clientMachine, false, false);\n+      file \u003d INodeFile.valueOf(dir.getINode4Write(src), src);\n+      initializeBlockRecovery(file);\n+    }\n+    getEditLog().logTruncate(src, clientName, clientMachine, newLength, mtime);\n+    removeBlocks(collectedBlocks);\n+    return onBlockBoundary;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  boolean truncateInternal(String src, long newLength,\n                           String clientName, String clientMachine,\n                           long mtime, FSPermissionChecker pc)\n      throws IOException, UnresolvedLinkException {\n    assert hasWriteLock();\n    INodesInPath iip \u003d dir.getINodesInPath4Write(src, true);\n    if (isPermissionEnabled) {\n      dir.checkPathAccess(pc, iip, FsAction.WRITE);\n    }\n    INodeFile file \u003d iip.getLastINode().asFile();\n    // Data will be lost after truncate occurs so it cannot support snapshots.\n    if(file.isInLatestSnapshot(iip.getLatestSnapshotId()))\n      throw new HadoopIllegalArgumentException(\n          \"Cannot truncate file with snapshot.\");\n    // Opening an existing file for write. May need lease recovery.\n    recoverLeaseInternal(iip, src, clientName, clientMachine, false);\n    // Refresh INode as the file could have been closed\n    iip \u003d dir.getINodesInPath4Write(src, true);\n    file \u003d INodeFile.valueOf(iip.getLastINode(), src);\n    // Truncate length check.\n    long oldLength \u003d file.computeFileSize();\n    if(oldLength \u003d\u003d newLength)\n      return true;\n    if(oldLength \u003c newLength)\n      throw new HadoopIllegalArgumentException(\n          \"Cannot truncate to a larger file size. Current size: \" + oldLength +\n              \", truncate size: \" + newLength + \".\");\n    // Perform INodeFile truncation.\n    BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n    boolean onBlockBoundary \u003d dir.truncate(iip, newLength,\n                                           collectedBlocks, mtime);\n\n    if(! onBlockBoundary) {\n      // Open file for write, but don\u0027t log into edits\n      prepareFileForWrite(src, iip, clientName, clientMachine, false, false);\n      file \u003d INodeFile.valueOf(dir.getINode4Write(src), src);\n      initializeBlockRecovery(file);\n    }\n    getEditLog().logTruncate(src, clientName, clientMachine, newLength, mtime);\n    removeBlocks(collectedBlocks);\n    return onBlockBoundary;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java"
    }
  }
}