{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DFSInputStream.java",
  "functionName": "getBestNodeDNAddrPair",
  "functionId": "getBestNodeDNAddrPair___block-LocatedBlock__ignoredNodes-Collection__DatanodeInfo__",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
  "functionStartLine": 1051,
  "functionEndLine": 1091,
  "numCommitsSeen": 201,
  "timeTaken": 6721,
  "changeHistory": [
    "7fddf4855e92627e11063318ac70f59e9316879c",
    "b3119b9ab60a19d624db476c4e1c53410870c7a6",
    "70fc6746b326b9a913e8bebca5f5afaf01ab9e11",
    "39285e6a1978ea5e53bdc1b0aef62421382124a8",
    "6ee0539ede78b640f01c5eac18ded161182a7835",
    "d5a9a3daa0224249221ffa7b8bd5751ab2feca56",
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c",
    "bff5999d07e9416a22846c849487e509ede55040",
    "439614b0c8a3df3d8b7967451c5331a0e034e13a",
    "2cc9514ad643ae49d30524743420ee9744e571bd",
    "463aec11718e47d4aabb86a7a539cb973460aae6",
    "17db74a1c1972392a5aba48a3e0334dcd6c76487"
  ],
  "changeHistoryShort": {
    "7fddf4855e92627e11063318ac70f59e9316879c": "Ybodychange",
    "b3119b9ab60a19d624db476c4e1c53410870c7a6": "Ybodychange",
    "70fc6746b326b9a913e8bebca5f5afaf01ab9e11": "Ybodychange",
    "39285e6a1978ea5e53bdc1b0aef62421382124a8": "Ybodychange",
    "6ee0539ede78b640f01c5eac18ded161182a7835": "Ybodychange",
    "d5a9a3daa0224249221ffa7b8bd5751ab2feca56": "Ybodychange",
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c": "Yfilerename",
    "bff5999d07e9416a22846c849487e509ede55040": "Ymodifierchange",
    "439614b0c8a3df3d8b7967451c5331a0e034e13a": "Ymultichange(Yexceptionschange,Ybodychange)",
    "2cc9514ad643ae49d30524743420ee9744e571bd": "Ybodychange",
    "463aec11718e47d4aabb86a7a539cb973460aae6": "Ymultichange(Yparameterchange,Ybodychange)",
    "17db74a1c1972392a5aba48a3e0334dcd6c76487": "Yintroduced"
  },
  "changeHistoryDetails": {
    "7fddf4855e92627e11063318ac70f59e9316879c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14283. DFSInputStream to prefer cached replica. Contributed by Lisheng Sun.\n",
      "commitDate": "06/05/20 4:25 AM",
      "commitName": "7fddf4855e92627e11063318ac70f59e9316879c",
      "commitAuthor": "Ayush Saxena",
      "commitDateOld": "24/01/20 7:15 AM",
      "commitNameOld": "d10f77e3c91225f86ed9c0f0e6a9adf2e1434674",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 102.84,
      "commitsBetweenForRepo": 333,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,30 +1,41 @@\n   protected DNAddrPair getBestNodeDNAddrPair(LocatedBlock block,\n       Collection\u003cDatanodeInfo\u003e ignoredNodes) {\n     DatanodeInfo[] nodes \u003d block.getLocations();\n     StorageType[] storageTypes \u003d block.getStorageTypes();\n     DatanodeInfo chosenNode \u003d null;\n     StorageType storageType \u003d null;\n-    if (nodes !\u003d null) {\n+    if (dfsClient.getConf().isReadUseCachePriority()) {\n+      DatanodeInfo[] cachedLocs \u003d block.getCachedLocations();\n+      if (cachedLocs !\u003d null) {\n+        for (int i \u003d 0; i \u003c cachedLocs.length; i++) {\n+          if (isValidNode(cachedLocs[i], ignoredNodes)) {\n+            chosenNode \u003d cachedLocs[i];\n+            break;\n+          }\n+        }\n+      }\n+    }\n+\n+    if (chosenNode \u003d\u003d null \u0026\u0026 nodes !\u003d null) {\n       for (int i \u003d 0; i \u003c nodes.length; i++) {\n-        if (!dfsClient.getDeadNodes(this).containsKey(nodes[i])\n-            \u0026\u0026 (ignoredNodes \u003d\u003d null || !ignoredNodes.contains(nodes[i]))) {\n+        if (isValidNode(nodes[i], ignoredNodes)) {\n           chosenNode \u003d nodes[i];\n           // Storage types are ordered to correspond with nodes, so use the same\n           // index to get storage type.\n           if (storageTypes !\u003d null \u0026\u0026 i \u003c storageTypes.length) {\n             storageType \u003d storageTypes[i];\n           }\n           break;\n         }\n       }\n     }\n     if (chosenNode \u003d\u003d null) {\n       reportLostBlock(block, ignoredNodes);\n       return null;\n     }\n     final String dnAddr \u003d\n         chosenNode.getXferAddr(dfsClient.getConf().isConnectToDnViaHostname());\n     DFSClient.LOG.debug(\"Connecting to datanode {}\", dnAddr);\n     InetSocketAddress targetAddr \u003d NetUtils.createSocketAddr(dnAddr);\n     return new DNAddrPair(chosenNode, targetAddr, storageType, block);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected DNAddrPair getBestNodeDNAddrPair(LocatedBlock block,\n      Collection\u003cDatanodeInfo\u003e ignoredNodes) {\n    DatanodeInfo[] nodes \u003d block.getLocations();\n    StorageType[] storageTypes \u003d block.getStorageTypes();\n    DatanodeInfo chosenNode \u003d null;\n    StorageType storageType \u003d null;\n    if (dfsClient.getConf().isReadUseCachePriority()) {\n      DatanodeInfo[] cachedLocs \u003d block.getCachedLocations();\n      if (cachedLocs !\u003d null) {\n        for (int i \u003d 0; i \u003c cachedLocs.length; i++) {\n          if (isValidNode(cachedLocs[i], ignoredNodes)) {\n            chosenNode \u003d cachedLocs[i];\n            break;\n          }\n        }\n      }\n    }\n\n    if (chosenNode \u003d\u003d null \u0026\u0026 nodes !\u003d null) {\n      for (int i \u003d 0; i \u003c nodes.length; i++) {\n        if (isValidNode(nodes[i], ignoredNodes)) {\n          chosenNode \u003d nodes[i];\n          // Storage types are ordered to correspond with nodes, so use the same\n          // index to get storage type.\n          if (storageTypes !\u003d null \u0026\u0026 i \u003c storageTypes.length) {\n            storageType \u003d storageTypes[i];\n          }\n          break;\n        }\n      }\n    }\n    if (chosenNode \u003d\u003d null) {\n      reportLostBlock(block, ignoredNodes);\n      return null;\n    }\n    final String dnAddr \u003d\n        chosenNode.getXferAddr(dfsClient.getConf().isConnectToDnViaHostname());\n    DFSClient.LOG.debug(\"Connecting to datanode {}\", dnAddr);\n    InetSocketAddress targetAddr \u003d NetUtils.createSocketAddr(dnAddr);\n    return new DNAddrPair(chosenNode, targetAddr, storageType, block);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "b3119b9ab60a19d624db476c4e1c53410870c7a6": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14648. Implement DeadNodeDetector basic model. Contributed by Lisheng Sun.\n",
      "commitDate": "15/11/19 7:32 PM",
      "commitName": "b3119b9ab60a19d624db476c4e1c53410870c7a6",
      "commitAuthor": "Yiqun Lin",
      "commitDateOld": "06/11/19 5:58 AM",
      "commitNameOld": "c36014165c212b26d75268ee3659aa2cadcff349",
      "commitAuthorOld": "Surendra Singh Lilhore",
      "daysBetweenCommits": 9.57,
      "commitsBetweenForRepo": 36,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,30 +1,30 @@\n   protected DNAddrPair getBestNodeDNAddrPair(LocatedBlock block,\n       Collection\u003cDatanodeInfo\u003e ignoredNodes) {\n     DatanodeInfo[] nodes \u003d block.getLocations();\n     StorageType[] storageTypes \u003d block.getStorageTypes();\n     DatanodeInfo chosenNode \u003d null;\n     StorageType storageType \u003d null;\n     if (nodes !\u003d null) {\n       for (int i \u003d 0; i \u003c nodes.length; i++) {\n-        if (!deadNodes.containsKey(nodes[i])\n+        if (!dfsClient.getDeadNodes(this).containsKey(nodes[i])\n             \u0026\u0026 (ignoredNodes \u003d\u003d null || !ignoredNodes.contains(nodes[i]))) {\n           chosenNode \u003d nodes[i];\n           // Storage types are ordered to correspond with nodes, so use the same\n           // index to get storage type.\n           if (storageTypes !\u003d null \u0026\u0026 i \u003c storageTypes.length) {\n             storageType \u003d storageTypes[i];\n           }\n           break;\n         }\n       }\n     }\n     if (chosenNode \u003d\u003d null) {\n       reportLostBlock(block, ignoredNodes);\n       return null;\n     }\n     final String dnAddr \u003d\n         chosenNode.getXferAddr(dfsClient.getConf().isConnectToDnViaHostname());\n     DFSClient.LOG.debug(\"Connecting to datanode {}\", dnAddr);\n     InetSocketAddress targetAddr \u003d NetUtils.createSocketAddr(dnAddr);\n     return new DNAddrPair(chosenNode, targetAddr, storageType, block);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected DNAddrPair getBestNodeDNAddrPair(LocatedBlock block,\n      Collection\u003cDatanodeInfo\u003e ignoredNodes) {\n    DatanodeInfo[] nodes \u003d block.getLocations();\n    StorageType[] storageTypes \u003d block.getStorageTypes();\n    DatanodeInfo chosenNode \u003d null;\n    StorageType storageType \u003d null;\n    if (nodes !\u003d null) {\n      for (int i \u003d 0; i \u003c nodes.length; i++) {\n        if (!dfsClient.getDeadNodes(this).containsKey(nodes[i])\n            \u0026\u0026 (ignoredNodes \u003d\u003d null || !ignoredNodes.contains(nodes[i]))) {\n          chosenNode \u003d nodes[i];\n          // Storage types are ordered to correspond with nodes, so use the same\n          // index to get storage type.\n          if (storageTypes !\u003d null \u0026\u0026 i \u003c storageTypes.length) {\n            storageType \u003d storageTypes[i];\n          }\n          break;\n        }\n      }\n    }\n    if (chosenNode \u003d\u003d null) {\n      reportLostBlock(block, ignoredNodes);\n      return null;\n    }\n    final String dnAddr \u003d\n        chosenNode.getXferAddr(dfsClient.getConf().isConnectToDnViaHostname());\n    DFSClient.LOG.debug(\"Connecting to datanode {}\", dnAddr);\n    InetSocketAddress targetAddr \u003d NetUtils.createSocketAddr(dnAddr);\n    return new DNAddrPair(chosenNode, targetAddr, storageType, block);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "70fc6746b326b9a913e8bebca5f5afaf01ab9e11": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11708. Positional read will fail if replicas moved to different DNs after stream is opened. Contributed by Vinayakumar B.\n",
      "commitDate": "06/06/17 10:25 PM",
      "commitName": "70fc6746b326b9a913e8bebca5f5afaf01ab9e11",
      "commitAuthor": "Vinayakumar B",
      "commitDateOld": "03/04/17 8:13 PM",
      "commitNameOld": "6eba79232f36b36e0196163adc8fe4219a6b6bf9",
      "commitAuthorOld": "Chris Douglas",
      "daysBetweenCommits": 64.09,
      "commitsBetweenForRepo": 349,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,30 +1,30 @@\n   protected DNAddrPair getBestNodeDNAddrPair(LocatedBlock block,\n       Collection\u003cDatanodeInfo\u003e ignoredNodes) {\n     DatanodeInfo[] nodes \u003d block.getLocations();\n     StorageType[] storageTypes \u003d block.getStorageTypes();\n     DatanodeInfo chosenNode \u003d null;\n     StorageType storageType \u003d null;\n     if (nodes !\u003d null) {\n       for (int i \u003d 0; i \u003c nodes.length; i++) {\n         if (!deadNodes.containsKey(nodes[i])\n             \u0026\u0026 (ignoredNodes \u003d\u003d null || !ignoredNodes.contains(nodes[i]))) {\n           chosenNode \u003d nodes[i];\n           // Storage types are ordered to correspond with nodes, so use the same\n           // index to get storage type.\n           if (storageTypes !\u003d null \u0026\u0026 i \u003c storageTypes.length) {\n             storageType \u003d storageTypes[i];\n           }\n           break;\n         }\n       }\n     }\n     if (chosenNode \u003d\u003d null) {\n       reportLostBlock(block, ignoredNodes);\n       return null;\n     }\n     final String dnAddr \u003d\n         chosenNode.getXferAddr(dfsClient.getConf().isConnectToDnViaHostname());\n     DFSClient.LOG.debug(\"Connecting to datanode {}\", dnAddr);\n     InetSocketAddress targetAddr \u003d NetUtils.createSocketAddr(dnAddr);\n-    return new DNAddrPair(chosenNode, targetAddr, storageType);\n+    return new DNAddrPair(chosenNode, targetAddr, storageType, block);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected DNAddrPair getBestNodeDNAddrPair(LocatedBlock block,\n      Collection\u003cDatanodeInfo\u003e ignoredNodes) {\n    DatanodeInfo[] nodes \u003d block.getLocations();\n    StorageType[] storageTypes \u003d block.getStorageTypes();\n    DatanodeInfo chosenNode \u003d null;\n    StorageType storageType \u003d null;\n    if (nodes !\u003d null) {\n      for (int i \u003d 0; i \u003c nodes.length; i++) {\n        if (!deadNodes.containsKey(nodes[i])\n            \u0026\u0026 (ignoredNodes \u003d\u003d null || !ignoredNodes.contains(nodes[i]))) {\n          chosenNode \u003d nodes[i];\n          // Storage types are ordered to correspond with nodes, so use the same\n          // index to get storage type.\n          if (storageTypes !\u003d null \u0026\u0026 i \u003c storageTypes.length) {\n            storageType \u003d storageTypes[i];\n          }\n          break;\n        }\n      }\n    }\n    if (chosenNode \u003d\u003d null) {\n      reportLostBlock(block, ignoredNodes);\n      return null;\n    }\n    final String dnAddr \u003d\n        chosenNode.getXferAddr(dfsClient.getConf().isConnectToDnViaHostname());\n    DFSClient.LOG.debug(\"Connecting to datanode {}\", dnAddr);\n    InetSocketAddress targetAddr \u003d NetUtils.createSocketAddr(dnAddr);\n    return new DNAddrPair(chosenNode, targetAddr, storageType, block);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "39285e6a1978ea5e53bdc1b0aef62421382124a8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8971. Remove guards when calling LOG.debug() and LOG.trace() in client package. Contributed by Mingliang Liu.\n",
      "commitDate": "29/09/15 5:52 PM",
      "commitName": "39285e6a1978ea5e53bdc1b0aef62421382124a8",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "29/09/15 5:51 PM",
      "commitNameOld": "6ee0539ede78b640f01c5eac18ded161182a7835",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,34 +1,32 @@\n   protected DNAddrPair getBestNodeDNAddrPair(LocatedBlock block,\n       Collection\u003cDatanodeInfo\u003e ignoredNodes) {\n     DatanodeInfo[] nodes \u003d block.getLocations();\n     StorageType[] storageTypes \u003d block.getStorageTypes();\n     DatanodeInfo chosenNode \u003d null;\n     StorageType storageType \u003d null;\n     if (nodes !\u003d null) {\n       for (int i \u003d 0; i \u003c nodes.length; i++) {\n         if (!deadNodes.containsKey(nodes[i])\n             \u0026\u0026 (ignoredNodes \u003d\u003d null || !ignoredNodes.contains(nodes[i]))) {\n           chosenNode \u003d nodes[i];\n           // Storage types are ordered to correspond with nodes, so use the same\n           // index to get storage type.\n           if (storageTypes !\u003d null \u0026\u0026 i \u003c storageTypes.length) {\n             storageType \u003d storageTypes[i];\n           }\n           break;\n         }\n       }\n     }\n     if (chosenNode \u003d\u003d null) {\n       DFSClient.LOG.warn(\"No live nodes contain block \" + block.getBlock() +\n           \" after checking nodes \u003d \" + Arrays.toString(nodes) +\n           \", ignoredNodes \u003d \" + ignoredNodes);\n       return null;\n     }\n     final String dnAddr \u003d\n         chosenNode.getXferAddr(dfsClient.getConf().isConnectToDnViaHostname());\n-    if (DFSClient.LOG.isDebugEnabled()) {\n-      DFSClient.LOG.debug(\"Connecting to datanode \" + dnAddr);\n-    }\n+    DFSClient.LOG.debug(\"Connecting to datanode {}\", dnAddr);\n     InetSocketAddress targetAddr \u003d NetUtils.createSocketAddr(dnAddr);\n     return new DNAddrPair(chosenNode, targetAddr, storageType);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected DNAddrPair getBestNodeDNAddrPair(LocatedBlock block,\n      Collection\u003cDatanodeInfo\u003e ignoredNodes) {\n    DatanodeInfo[] nodes \u003d block.getLocations();\n    StorageType[] storageTypes \u003d block.getStorageTypes();\n    DatanodeInfo chosenNode \u003d null;\n    StorageType storageType \u003d null;\n    if (nodes !\u003d null) {\n      for (int i \u003d 0; i \u003c nodes.length; i++) {\n        if (!deadNodes.containsKey(nodes[i])\n            \u0026\u0026 (ignoredNodes \u003d\u003d null || !ignoredNodes.contains(nodes[i]))) {\n          chosenNode \u003d nodes[i];\n          // Storage types are ordered to correspond with nodes, so use the same\n          // index to get storage type.\n          if (storageTypes !\u003d null \u0026\u0026 i \u003c storageTypes.length) {\n            storageType \u003d storageTypes[i];\n          }\n          break;\n        }\n      }\n    }\n    if (chosenNode \u003d\u003d null) {\n      DFSClient.LOG.warn(\"No live nodes contain block \" + block.getBlock() +\n          \" after checking nodes \u003d \" + Arrays.toString(nodes) +\n          \", ignoredNodes \u003d \" + ignoredNodes);\n      return null;\n    }\n    final String dnAddr \u003d\n        chosenNode.getXferAddr(dfsClient.getConf().isConnectToDnViaHostname());\n    DFSClient.LOG.debug(\"Connecting to datanode {}\", dnAddr);\n    InetSocketAddress targetAddr \u003d NetUtils.createSocketAddr(dnAddr);\n    return new DNAddrPair(chosenNode, targetAddr, storageType);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "6ee0539ede78b640f01c5eac18ded161182a7835": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-9170. Move libhdfs / fuse-dfs / libwebhdfs to hdfs-client. Contributed by Haohui Mai.\"\n\nThis reverts commit d5a9a3daa0224249221ffa7b8bd5751ab2feca56.\n",
      "commitDate": "29/09/15 5:51 PM",
      "commitName": "6ee0539ede78b640f01c5eac18ded161182a7835",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "29/09/15 5:48 PM",
      "commitNameOld": "d5a9a3daa0224249221ffa7b8bd5751ab2feca56",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,32 +1,34 @@\n   protected DNAddrPair getBestNodeDNAddrPair(LocatedBlock block,\n       Collection\u003cDatanodeInfo\u003e ignoredNodes) {\n     DatanodeInfo[] nodes \u003d block.getLocations();\n     StorageType[] storageTypes \u003d block.getStorageTypes();\n     DatanodeInfo chosenNode \u003d null;\n     StorageType storageType \u003d null;\n     if (nodes !\u003d null) {\n       for (int i \u003d 0; i \u003c nodes.length; i++) {\n         if (!deadNodes.containsKey(nodes[i])\n             \u0026\u0026 (ignoredNodes \u003d\u003d null || !ignoredNodes.contains(nodes[i]))) {\n           chosenNode \u003d nodes[i];\n           // Storage types are ordered to correspond with nodes, so use the same\n           // index to get storage type.\n           if (storageTypes !\u003d null \u0026\u0026 i \u003c storageTypes.length) {\n             storageType \u003d storageTypes[i];\n           }\n           break;\n         }\n       }\n     }\n     if (chosenNode \u003d\u003d null) {\n       DFSClient.LOG.warn(\"No live nodes contain block \" + block.getBlock() +\n           \" after checking nodes \u003d \" + Arrays.toString(nodes) +\n           \", ignoredNodes \u003d \" + ignoredNodes);\n       return null;\n     }\n     final String dnAddr \u003d\n         chosenNode.getXferAddr(dfsClient.getConf().isConnectToDnViaHostname());\n-    DFSClient.LOG.debug(\"Connecting to datanode {}\", dnAddr);\n+    if (DFSClient.LOG.isDebugEnabled()) {\n+      DFSClient.LOG.debug(\"Connecting to datanode \" + dnAddr);\n+    }\n     InetSocketAddress targetAddr \u003d NetUtils.createSocketAddr(dnAddr);\n     return new DNAddrPair(chosenNode, targetAddr, storageType);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected DNAddrPair getBestNodeDNAddrPair(LocatedBlock block,\n      Collection\u003cDatanodeInfo\u003e ignoredNodes) {\n    DatanodeInfo[] nodes \u003d block.getLocations();\n    StorageType[] storageTypes \u003d block.getStorageTypes();\n    DatanodeInfo chosenNode \u003d null;\n    StorageType storageType \u003d null;\n    if (nodes !\u003d null) {\n      for (int i \u003d 0; i \u003c nodes.length; i++) {\n        if (!deadNodes.containsKey(nodes[i])\n            \u0026\u0026 (ignoredNodes \u003d\u003d null || !ignoredNodes.contains(nodes[i]))) {\n          chosenNode \u003d nodes[i];\n          // Storage types are ordered to correspond with nodes, so use the same\n          // index to get storage type.\n          if (storageTypes !\u003d null \u0026\u0026 i \u003c storageTypes.length) {\n            storageType \u003d storageTypes[i];\n          }\n          break;\n        }\n      }\n    }\n    if (chosenNode \u003d\u003d null) {\n      DFSClient.LOG.warn(\"No live nodes contain block \" + block.getBlock() +\n          \" after checking nodes \u003d \" + Arrays.toString(nodes) +\n          \", ignoredNodes \u003d \" + ignoredNodes);\n      return null;\n    }\n    final String dnAddr \u003d\n        chosenNode.getXferAddr(dfsClient.getConf().isConnectToDnViaHostname());\n    if (DFSClient.LOG.isDebugEnabled()) {\n      DFSClient.LOG.debug(\"Connecting to datanode \" + dnAddr);\n    }\n    InetSocketAddress targetAddr \u003d NetUtils.createSocketAddr(dnAddr);\n    return new DNAddrPair(chosenNode, targetAddr, storageType);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "d5a9a3daa0224249221ffa7b8bd5751ab2feca56": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9170. Move libhdfs / fuse-dfs / libwebhdfs to hdfs-client. Contributed by Haohui Mai.\n",
      "commitDate": "29/09/15 5:48 PM",
      "commitName": "d5a9a3daa0224249221ffa7b8bd5751ab2feca56",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "28/09/15 7:42 AM",
      "commitNameOld": "892ade689f9bcce76daae8f66fc00a49bee8548e",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 1.42,
      "commitsBetweenForRepo": 19,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,34 +1,32 @@\n   protected DNAddrPair getBestNodeDNAddrPair(LocatedBlock block,\n       Collection\u003cDatanodeInfo\u003e ignoredNodes) {\n     DatanodeInfo[] nodes \u003d block.getLocations();\n     StorageType[] storageTypes \u003d block.getStorageTypes();\n     DatanodeInfo chosenNode \u003d null;\n     StorageType storageType \u003d null;\n     if (nodes !\u003d null) {\n       for (int i \u003d 0; i \u003c nodes.length; i++) {\n         if (!deadNodes.containsKey(nodes[i])\n             \u0026\u0026 (ignoredNodes \u003d\u003d null || !ignoredNodes.contains(nodes[i]))) {\n           chosenNode \u003d nodes[i];\n           // Storage types are ordered to correspond with nodes, so use the same\n           // index to get storage type.\n           if (storageTypes !\u003d null \u0026\u0026 i \u003c storageTypes.length) {\n             storageType \u003d storageTypes[i];\n           }\n           break;\n         }\n       }\n     }\n     if (chosenNode \u003d\u003d null) {\n       DFSClient.LOG.warn(\"No live nodes contain block \" + block.getBlock() +\n           \" after checking nodes \u003d \" + Arrays.toString(nodes) +\n           \", ignoredNodes \u003d \" + ignoredNodes);\n       return null;\n     }\n     final String dnAddr \u003d\n         chosenNode.getXferAddr(dfsClient.getConf().isConnectToDnViaHostname());\n-    if (DFSClient.LOG.isDebugEnabled()) {\n-      DFSClient.LOG.debug(\"Connecting to datanode \" + dnAddr);\n-    }\n+    DFSClient.LOG.debug(\"Connecting to datanode {}\", dnAddr);\n     InetSocketAddress targetAddr \u003d NetUtils.createSocketAddr(dnAddr);\n     return new DNAddrPair(chosenNode, targetAddr, storageType);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected DNAddrPair getBestNodeDNAddrPair(LocatedBlock block,\n      Collection\u003cDatanodeInfo\u003e ignoredNodes) {\n    DatanodeInfo[] nodes \u003d block.getLocations();\n    StorageType[] storageTypes \u003d block.getStorageTypes();\n    DatanodeInfo chosenNode \u003d null;\n    StorageType storageType \u003d null;\n    if (nodes !\u003d null) {\n      for (int i \u003d 0; i \u003c nodes.length; i++) {\n        if (!deadNodes.containsKey(nodes[i])\n            \u0026\u0026 (ignoredNodes \u003d\u003d null || !ignoredNodes.contains(nodes[i]))) {\n          chosenNode \u003d nodes[i];\n          // Storage types are ordered to correspond with nodes, so use the same\n          // index to get storage type.\n          if (storageTypes !\u003d null \u0026\u0026 i \u003c storageTypes.length) {\n            storageType \u003d storageTypes[i];\n          }\n          break;\n        }\n      }\n    }\n    if (chosenNode \u003d\u003d null) {\n      DFSClient.LOG.warn(\"No live nodes contain block \" + block.getBlock() +\n          \" after checking nodes \u003d \" + Arrays.toString(nodes) +\n          \", ignoredNodes \u003d \" + ignoredNodes);\n      return null;\n    }\n    final String dnAddr \u003d\n        chosenNode.getXferAddr(dfsClient.getConf().isConnectToDnViaHostname());\n    DFSClient.LOG.debug(\"Connecting to datanode {}\", dnAddr);\n    InetSocketAddress targetAddr \u003d NetUtils.createSocketAddr(dnAddr);\n    return new DNAddrPair(chosenNode, targetAddr, storageType);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8053. Move DFSIn/OutputStream and related classes to hadoop-hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "26/09/15 11:08 AM",
      "commitName": "bf37d3d80e5179dea27e5bd5aea804a38aa9934c",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "26/09/15 9:06 AM",
      "commitNameOld": "861b52db242f238d7e36ad75c158025be959a696",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 0.08,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  protected DNAddrPair getBestNodeDNAddrPair(LocatedBlock block,\n      Collection\u003cDatanodeInfo\u003e ignoredNodes) {\n    DatanodeInfo[] nodes \u003d block.getLocations();\n    StorageType[] storageTypes \u003d block.getStorageTypes();\n    DatanodeInfo chosenNode \u003d null;\n    StorageType storageType \u003d null;\n    if (nodes !\u003d null) {\n      for (int i \u003d 0; i \u003c nodes.length; i++) {\n        if (!deadNodes.containsKey(nodes[i])\n            \u0026\u0026 (ignoredNodes \u003d\u003d null || !ignoredNodes.contains(nodes[i]))) {\n          chosenNode \u003d nodes[i];\n          // Storage types are ordered to correspond with nodes, so use the same\n          // index to get storage type.\n          if (storageTypes !\u003d null \u0026\u0026 i \u003c storageTypes.length) {\n            storageType \u003d storageTypes[i];\n          }\n          break;\n        }\n      }\n    }\n    if (chosenNode \u003d\u003d null) {\n      DFSClient.LOG.warn(\"No live nodes contain block \" + block.getBlock() +\n          \" after checking nodes \u003d \" + Arrays.toString(nodes) +\n          \", ignoredNodes \u003d \" + ignoredNodes);\n      return null;\n    }\n    final String dnAddr \u003d\n        chosenNode.getXferAddr(dfsClient.getConf().isConnectToDnViaHostname());\n    if (DFSClient.LOG.isDebugEnabled()) {\n      DFSClient.LOG.debug(\"Connecting to datanode \" + dnAddr);\n    }\n    InetSocketAddress targetAddr \u003d NetUtils.createSocketAddr(dnAddr);\n    return new DNAddrPair(chosenNode, targetAddr, storageType);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java"
      }
    },
    "bff5999d07e9416a22846c849487e509ede55040": {
      "type": "Ymodifierchange",
      "commitMessage": "HDFS-8703. Merge refactor of DFSInputStream from ErasureCoding branch (Contributed by Vinayakumar B)\n",
      "commitDate": "02/07/15 3:41 AM",
      "commitName": "bff5999d07e9416a22846c849487e509ede55040",
      "commitAuthor": "Vinayakumar B",
      "commitDateOld": "04/06/15 10:51 AM",
      "commitNameOld": "ade6d9a61eb2e57a975f0efcdf8828d51ffec5fd",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 27.7,
      "commitsBetweenForRepo": 196,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,34 +1,34 @@\n-  private DNAddrPair getBestNodeDNAddrPair(LocatedBlock block,\n+  protected DNAddrPair getBestNodeDNAddrPair(LocatedBlock block,\n       Collection\u003cDatanodeInfo\u003e ignoredNodes) {\n     DatanodeInfo[] nodes \u003d block.getLocations();\n     StorageType[] storageTypes \u003d block.getStorageTypes();\n     DatanodeInfo chosenNode \u003d null;\n     StorageType storageType \u003d null;\n     if (nodes !\u003d null) {\n       for (int i \u003d 0; i \u003c nodes.length; i++) {\n         if (!deadNodes.containsKey(nodes[i])\n             \u0026\u0026 (ignoredNodes \u003d\u003d null || !ignoredNodes.contains(nodes[i]))) {\n           chosenNode \u003d nodes[i];\n           // Storage types are ordered to correspond with nodes, so use the same\n           // index to get storage type.\n           if (storageTypes !\u003d null \u0026\u0026 i \u003c storageTypes.length) {\n             storageType \u003d storageTypes[i];\n           }\n           break;\n         }\n       }\n     }\n     if (chosenNode \u003d\u003d null) {\n       DFSClient.LOG.warn(\"No live nodes contain block \" + block.getBlock() +\n           \" after checking nodes \u003d \" + Arrays.toString(nodes) +\n           \", ignoredNodes \u003d \" + ignoredNodes);\n       return null;\n     }\n     final String dnAddr \u003d\n         chosenNode.getXferAddr(dfsClient.getConf().isConnectToDnViaHostname());\n     if (DFSClient.LOG.isDebugEnabled()) {\n       DFSClient.LOG.debug(\"Connecting to datanode \" + dnAddr);\n     }\n     InetSocketAddress targetAddr \u003d NetUtils.createSocketAddr(dnAddr);\n     return new DNAddrPair(chosenNode, targetAddr, storageType);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected DNAddrPair getBestNodeDNAddrPair(LocatedBlock block,\n      Collection\u003cDatanodeInfo\u003e ignoredNodes) {\n    DatanodeInfo[] nodes \u003d block.getLocations();\n    StorageType[] storageTypes \u003d block.getStorageTypes();\n    DatanodeInfo chosenNode \u003d null;\n    StorageType storageType \u003d null;\n    if (nodes !\u003d null) {\n      for (int i \u003d 0; i \u003c nodes.length; i++) {\n        if (!deadNodes.containsKey(nodes[i])\n            \u0026\u0026 (ignoredNodes \u003d\u003d null || !ignoredNodes.contains(nodes[i]))) {\n          chosenNode \u003d nodes[i];\n          // Storage types are ordered to correspond with nodes, so use the same\n          // index to get storage type.\n          if (storageTypes !\u003d null \u0026\u0026 i \u003c storageTypes.length) {\n            storageType \u003d storageTypes[i];\n          }\n          break;\n        }\n      }\n    }\n    if (chosenNode \u003d\u003d null) {\n      DFSClient.LOG.warn(\"No live nodes contain block \" + block.getBlock() +\n          \" after checking nodes \u003d \" + Arrays.toString(nodes) +\n          \", ignoredNodes \u003d \" + ignoredNodes);\n      return null;\n    }\n    final String dnAddr \u003d\n        chosenNode.getXferAddr(dfsClient.getConf().isConnectToDnViaHostname());\n    if (DFSClient.LOG.isDebugEnabled()) {\n      DFSClient.LOG.debug(\"Connecting to datanode \" + dnAddr);\n    }\n    InetSocketAddress targetAddr \u003d NetUtils.createSocketAddr(dnAddr);\n    return new DNAddrPair(chosenNode, targetAddr, storageType);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {
        "oldValue": "[private]",
        "newValue": "[protected]"
      }
    },
    "439614b0c8a3df3d8b7967451c5331a0e034e13a": {
      "type": "Ymultichange(Yexceptionschange,Ybodychange)",
      "commitMessage": "HDFS-8280. Code Cleanup in DFSInputStream. Contributed by Jing Zhao.\n",
      "commitDate": "28/04/15 6:11 PM",
      "commitName": "439614b0c8a3df3d8b7967451c5331a0e034e13a",
      "commitAuthor": "Haohui Mai",
      "subchanges": [
        {
          "type": "Yexceptionschange",
          "commitMessage": "HDFS-8280. Code Cleanup in DFSInputStream. Contributed by Jing Zhao.\n",
          "commitDate": "28/04/15 6:11 PM",
          "commitName": "439614b0c8a3df3d8b7967451c5331a0e034e13a",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "16/04/15 1:22 PM",
          "commitNameOld": "75bbcc8bf3fa1daf54f56868dae737f6da12ab1f",
          "commitAuthorOld": "Tsz-Wo Nicholas Sze",
          "daysBetweenCommits": 12.2,
          "commitsBetweenForRepo": 109,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,33 +1,34 @@\n   private DNAddrPair getBestNodeDNAddrPair(LocatedBlock block,\n-      Collection\u003cDatanodeInfo\u003e ignoredNodes) throws IOException {\n+      Collection\u003cDatanodeInfo\u003e ignoredNodes) {\n     DatanodeInfo[] nodes \u003d block.getLocations();\n     StorageType[] storageTypes \u003d block.getStorageTypes();\n     DatanodeInfo chosenNode \u003d null;\n     StorageType storageType \u003d null;\n     if (nodes !\u003d null) {\n       for (int i \u003d 0; i \u003c nodes.length; i++) {\n         if (!deadNodes.containsKey(nodes[i])\n             \u0026\u0026 (ignoredNodes \u003d\u003d null || !ignoredNodes.contains(nodes[i]))) {\n           chosenNode \u003d nodes[i];\n           // Storage types are ordered to correspond with nodes, so use the same\n           // index to get storage type.\n           if (storageTypes !\u003d null \u0026\u0026 i \u003c storageTypes.length) {\n             storageType \u003d storageTypes[i];\n           }\n           break;\n         }\n       }\n     }\n     if (chosenNode \u003d\u003d null) {\n-      throw new IOException(\"No live nodes contain block \" + block.getBlock() +\n+      DFSClient.LOG.warn(\"No live nodes contain block \" + block.getBlock() +\n           \" after checking nodes \u003d \" + Arrays.toString(nodes) +\n           \", ignoredNodes \u003d \" + ignoredNodes);\n+      return null;\n     }\n     final String dnAddr \u003d\n         chosenNode.getXferAddr(dfsClient.getConf().isConnectToDnViaHostname());\n     if (DFSClient.LOG.isDebugEnabled()) {\n       DFSClient.LOG.debug(\"Connecting to datanode \" + dnAddr);\n     }\n     InetSocketAddress targetAddr \u003d NetUtils.createSocketAddr(dnAddr);\n     return new DNAddrPair(chosenNode, targetAddr, storageType);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private DNAddrPair getBestNodeDNAddrPair(LocatedBlock block,\n      Collection\u003cDatanodeInfo\u003e ignoredNodes) {\n    DatanodeInfo[] nodes \u003d block.getLocations();\n    StorageType[] storageTypes \u003d block.getStorageTypes();\n    DatanodeInfo chosenNode \u003d null;\n    StorageType storageType \u003d null;\n    if (nodes !\u003d null) {\n      for (int i \u003d 0; i \u003c nodes.length; i++) {\n        if (!deadNodes.containsKey(nodes[i])\n            \u0026\u0026 (ignoredNodes \u003d\u003d null || !ignoredNodes.contains(nodes[i]))) {\n          chosenNode \u003d nodes[i];\n          // Storage types are ordered to correspond with nodes, so use the same\n          // index to get storage type.\n          if (storageTypes !\u003d null \u0026\u0026 i \u003c storageTypes.length) {\n            storageType \u003d storageTypes[i];\n          }\n          break;\n        }\n      }\n    }\n    if (chosenNode \u003d\u003d null) {\n      DFSClient.LOG.warn(\"No live nodes contain block \" + block.getBlock() +\n          \" after checking nodes \u003d \" + Arrays.toString(nodes) +\n          \", ignoredNodes \u003d \" + ignoredNodes);\n      return null;\n    }\n    final String dnAddr \u003d\n        chosenNode.getXferAddr(dfsClient.getConf().isConnectToDnViaHostname());\n    if (DFSClient.LOG.isDebugEnabled()) {\n      DFSClient.LOG.debug(\"Connecting to datanode \" + dnAddr);\n    }\n    InetSocketAddress targetAddr \u003d NetUtils.createSocketAddr(dnAddr);\n    return new DNAddrPair(chosenNode, targetAddr, storageType);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
          "extendedDetails": {
            "oldValue": "[IOException]",
            "newValue": "[]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-8280. Code Cleanup in DFSInputStream. Contributed by Jing Zhao.\n",
          "commitDate": "28/04/15 6:11 PM",
          "commitName": "439614b0c8a3df3d8b7967451c5331a0e034e13a",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "16/04/15 1:22 PM",
          "commitNameOld": "75bbcc8bf3fa1daf54f56868dae737f6da12ab1f",
          "commitAuthorOld": "Tsz-Wo Nicholas Sze",
          "daysBetweenCommits": 12.2,
          "commitsBetweenForRepo": 109,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,33 +1,34 @@\n   private DNAddrPair getBestNodeDNAddrPair(LocatedBlock block,\n-      Collection\u003cDatanodeInfo\u003e ignoredNodes) throws IOException {\n+      Collection\u003cDatanodeInfo\u003e ignoredNodes) {\n     DatanodeInfo[] nodes \u003d block.getLocations();\n     StorageType[] storageTypes \u003d block.getStorageTypes();\n     DatanodeInfo chosenNode \u003d null;\n     StorageType storageType \u003d null;\n     if (nodes !\u003d null) {\n       for (int i \u003d 0; i \u003c nodes.length; i++) {\n         if (!deadNodes.containsKey(nodes[i])\n             \u0026\u0026 (ignoredNodes \u003d\u003d null || !ignoredNodes.contains(nodes[i]))) {\n           chosenNode \u003d nodes[i];\n           // Storage types are ordered to correspond with nodes, so use the same\n           // index to get storage type.\n           if (storageTypes !\u003d null \u0026\u0026 i \u003c storageTypes.length) {\n             storageType \u003d storageTypes[i];\n           }\n           break;\n         }\n       }\n     }\n     if (chosenNode \u003d\u003d null) {\n-      throw new IOException(\"No live nodes contain block \" + block.getBlock() +\n+      DFSClient.LOG.warn(\"No live nodes contain block \" + block.getBlock() +\n           \" after checking nodes \u003d \" + Arrays.toString(nodes) +\n           \", ignoredNodes \u003d \" + ignoredNodes);\n+      return null;\n     }\n     final String dnAddr \u003d\n         chosenNode.getXferAddr(dfsClient.getConf().isConnectToDnViaHostname());\n     if (DFSClient.LOG.isDebugEnabled()) {\n       DFSClient.LOG.debug(\"Connecting to datanode \" + dnAddr);\n     }\n     InetSocketAddress targetAddr \u003d NetUtils.createSocketAddr(dnAddr);\n     return new DNAddrPair(chosenNode, targetAddr, storageType);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private DNAddrPair getBestNodeDNAddrPair(LocatedBlock block,\n      Collection\u003cDatanodeInfo\u003e ignoredNodes) {\n    DatanodeInfo[] nodes \u003d block.getLocations();\n    StorageType[] storageTypes \u003d block.getStorageTypes();\n    DatanodeInfo chosenNode \u003d null;\n    StorageType storageType \u003d null;\n    if (nodes !\u003d null) {\n      for (int i \u003d 0; i \u003c nodes.length; i++) {\n        if (!deadNodes.containsKey(nodes[i])\n            \u0026\u0026 (ignoredNodes \u003d\u003d null || !ignoredNodes.contains(nodes[i]))) {\n          chosenNode \u003d nodes[i];\n          // Storage types are ordered to correspond with nodes, so use the same\n          // index to get storage type.\n          if (storageTypes !\u003d null \u0026\u0026 i \u003c storageTypes.length) {\n            storageType \u003d storageTypes[i];\n          }\n          break;\n        }\n      }\n    }\n    if (chosenNode \u003d\u003d null) {\n      DFSClient.LOG.warn(\"No live nodes contain block \" + block.getBlock() +\n          \" after checking nodes \u003d \" + Arrays.toString(nodes) +\n          \", ignoredNodes \u003d \" + ignoredNodes);\n      return null;\n    }\n    final String dnAddr \u003d\n        chosenNode.getXferAddr(dfsClient.getConf().isConnectToDnViaHostname());\n    if (DFSClient.LOG.isDebugEnabled()) {\n      DFSClient.LOG.debug(\"Connecting to datanode \" + dnAddr);\n    }\n    InetSocketAddress targetAddr \u003d NetUtils.createSocketAddr(dnAddr);\n    return new DNAddrPair(chosenNode, targetAddr, storageType);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
          "extendedDetails": {}
        }
      ]
    },
    "2cc9514ad643ae49d30524743420ee9744e571bd": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8100. Refactor DFSClient.Conf to a standalone class and separates short-circuit related conf to ShortCircuitConf.\n",
      "commitDate": "10/04/15 2:48 PM",
      "commitName": "2cc9514ad643ae49d30524743420ee9744e571bd",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "09/04/15 11:22 AM",
      "commitNameOld": "30acb7372ab97adf9bc86ead529c96cfe36e2396",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 1.14,
      "commitsBetweenForRepo": 18,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,33 +1,33 @@\n   private DNAddrPair getBestNodeDNAddrPair(LocatedBlock block,\n       Collection\u003cDatanodeInfo\u003e ignoredNodes) throws IOException {\n     DatanodeInfo[] nodes \u003d block.getLocations();\n     StorageType[] storageTypes \u003d block.getStorageTypes();\n     DatanodeInfo chosenNode \u003d null;\n     StorageType storageType \u003d null;\n     if (nodes !\u003d null) {\n       for (int i \u003d 0; i \u003c nodes.length; i++) {\n         if (!deadNodes.containsKey(nodes[i])\n             \u0026\u0026 (ignoredNodes \u003d\u003d null || !ignoredNodes.contains(nodes[i]))) {\n           chosenNode \u003d nodes[i];\n           // Storage types are ordered to correspond with nodes, so use the same\n           // index to get storage type.\n           if (storageTypes !\u003d null \u0026\u0026 i \u003c storageTypes.length) {\n             storageType \u003d storageTypes[i];\n           }\n           break;\n         }\n       }\n     }\n     if (chosenNode \u003d\u003d null) {\n       throw new IOException(\"No live nodes contain block \" + block.getBlock() +\n           \" after checking nodes \u003d \" + Arrays.toString(nodes) +\n           \", ignoredNodes \u003d \" + ignoredNodes);\n     }\n     final String dnAddr \u003d\n-        chosenNode.getXferAddr(dfsClient.getConf().connectToDnViaHostname);\n+        chosenNode.getXferAddr(dfsClient.getConf().isConnectToDnViaHostname());\n     if (DFSClient.LOG.isDebugEnabled()) {\n       DFSClient.LOG.debug(\"Connecting to datanode \" + dnAddr);\n     }\n     InetSocketAddress targetAddr \u003d NetUtils.createSocketAddr(dnAddr);\n     return new DNAddrPair(chosenNode, targetAddr, storageType);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private DNAddrPair getBestNodeDNAddrPair(LocatedBlock block,\n      Collection\u003cDatanodeInfo\u003e ignoredNodes) throws IOException {\n    DatanodeInfo[] nodes \u003d block.getLocations();\n    StorageType[] storageTypes \u003d block.getStorageTypes();\n    DatanodeInfo chosenNode \u003d null;\n    StorageType storageType \u003d null;\n    if (nodes !\u003d null) {\n      for (int i \u003d 0; i \u003c nodes.length; i++) {\n        if (!deadNodes.containsKey(nodes[i])\n            \u0026\u0026 (ignoredNodes \u003d\u003d null || !ignoredNodes.contains(nodes[i]))) {\n          chosenNode \u003d nodes[i];\n          // Storage types are ordered to correspond with nodes, so use the same\n          // index to get storage type.\n          if (storageTypes !\u003d null \u0026\u0026 i \u003c storageTypes.length) {\n            storageType \u003d storageTypes[i];\n          }\n          break;\n        }\n      }\n    }\n    if (chosenNode \u003d\u003d null) {\n      throw new IOException(\"No live nodes contain block \" + block.getBlock() +\n          \" after checking nodes \u003d \" + Arrays.toString(nodes) +\n          \", ignoredNodes \u003d \" + ignoredNodes);\n    }\n    final String dnAddr \u003d\n        chosenNode.getXferAddr(dfsClient.getConf().isConnectToDnViaHostname());\n    if (DFSClient.LOG.isDebugEnabled()) {\n      DFSClient.LOG.debug(\"Connecting to datanode \" + dnAddr);\n    }\n    InetSocketAddress targetAddr \u003d NetUtils.createSocketAddr(dnAddr);\n    return new DNAddrPair(chosenNode, targetAddr, storageType);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "463aec11718e47d4aabb86a7a539cb973460aae6": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-6934. Move checksum computation off the hot path when writing to RAM disk. Contributed by Chris Nauroth.\n",
      "commitDate": "27/10/14 9:38 AM",
      "commitName": "463aec11718e47d4aabb86a7a539cb973460aae6",
      "commitAuthor": "cnauroth",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-6934. Move checksum computation off the hot path when writing to RAM disk. Contributed by Chris Nauroth.\n",
          "commitDate": "27/10/14 9:38 AM",
          "commitName": "463aec11718e47d4aabb86a7a539cb973460aae6",
          "commitAuthor": "cnauroth",
          "commitDateOld": "03/10/14 1:35 PM",
          "commitNameOld": "7f6ed7fe365166e8075359f1d0ad035fa876c70f",
          "commitAuthorOld": "Colin Patrick Mccabe",
          "daysBetweenCommits": 23.84,
          "commitsBetweenForRepo": 188,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,33 @@\n-  private DNAddrPair getBestNodeDNAddrPair(final DatanodeInfo[] nodes,\n+  private DNAddrPair getBestNodeDNAddrPair(LocatedBlock block,\n       Collection\u003cDatanodeInfo\u003e ignoredNodes) throws IOException {\n-    DatanodeInfo chosenNode \u003d bestNode(nodes, deadNodes, ignoredNodes);\n+    DatanodeInfo[] nodes \u003d block.getLocations();\n+    StorageType[] storageTypes \u003d block.getStorageTypes();\n+    DatanodeInfo chosenNode \u003d null;\n+    StorageType storageType \u003d null;\n+    if (nodes !\u003d null) {\n+      for (int i \u003d 0; i \u003c nodes.length; i++) {\n+        if (!deadNodes.containsKey(nodes[i])\n+            \u0026\u0026 (ignoredNodes \u003d\u003d null || !ignoredNodes.contains(nodes[i]))) {\n+          chosenNode \u003d nodes[i];\n+          // Storage types are ordered to correspond with nodes, so use the same\n+          // index to get storage type.\n+          if (storageTypes !\u003d null \u0026\u0026 i \u003c storageTypes.length) {\n+            storageType \u003d storageTypes[i];\n+          }\n+          break;\n+        }\n+      }\n+    }\n+    if (chosenNode \u003d\u003d null) {\n+      throw new IOException(\"No live nodes contain block \" + block.getBlock() +\n+          \" after checking nodes \u003d \" + Arrays.toString(nodes) +\n+          \", ignoredNodes \u003d \" + ignoredNodes);\n+    }\n     final String dnAddr \u003d\n         chosenNode.getXferAddr(dfsClient.getConf().connectToDnViaHostname);\n     if (DFSClient.LOG.isDebugEnabled()) {\n       DFSClient.LOG.debug(\"Connecting to datanode \" + dnAddr);\n     }\n     InetSocketAddress targetAddr \u003d NetUtils.createSocketAddr(dnAddr);\n-    return new DNAddrPair(chosenNode, targetAddr);\n+    return new DNAddrPair(chosenNode, targetAddr, storageType);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private DNAddrPair getBestNodeDNAddrPair(LocatedBlock block,\n      Collection\u003cDatanodeInfo\u003e ignoredNodes) throws IOException {\n    DatanodeInfo[] nodes \u003d block.getLocations();\n    StorageType[] storageTypes \u003d block.getStorageTypes();\n    DatanodeInfo chosenNode \u003d null;\n    StorageType storageType \u003d null;\n    if (nodes !\u003d null) {\n      for (int i \u003d 0; i \u003c nodes.length; i++) {\n        if (!deadNodes.containsKey(nodes[i])\n            \u0026\u0026 (ignoredNodes \u003d\u003d null || !ignoredNodes.contains(nodes[i]))) {\n          chosenNode \u003d nodes[i];\n          // Storage types are ordered to correspond with nodes, so use the same\n          // index to get storage type.\n          if (storageTypes !\u003d null \u0026\u0026 i \u003c storageTypes.length) {\n            storageType \u003d storageTypes[i];\n          }\n          break;\n        }\n      }\n    }\n    if (chosenNode \u003d\u003d null) {\n      throw new IOException(\"No live nodes contain block \" + block.getBlock() +\n          \" after checking nodes \u003d \" + Arrays.toString(nodes) +\n          \", ignoredNodes \u003d \" + ignoredNodes);\n    }\n    final String dnAddr \u003d\n        chosenNode.getXferAddr(dfsClient.getConf().connectToDnViaHostname);\n    if (DFSClient.LOG.isDebugEnabled()) {\n      DFSClient.LOG.debug(\"Connecting to datanode \" + dnAddr);\n    }\n    InetSocketAddress targetAddr \u003d NetUtils.createSocketAddr(dnAddr);\n    return new DNAddrPair(chosenNode, targetAddr, storageType);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
          "extendedDetails": {
            "oldValue": "[nodes-DatanodeInfo[](modifiers-final), ignoredNodes-Collection\u003cDatanodeInfo\u003e]",
            "newValue": "[block-LocatedBlock, ignoredNodes-Collection\u003cDatanodeInfo\u003e]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-6934. Move checksum computation off the hot path when writing to RAM disk. Contributed by Chris Nauroth.\n",
          "commitDate": "27/10/14 9:38 AM",
          "commitName": "463aec11718e47d4aabb86a7a539cb973460aae6",
          "commitAuthor": "cnauroth",
          "commitDateOld": "03/10/14 1:35 PM",
          "commitNameOld": "7f6ed7fe365166e8075359f1d0ad035fa876c70f",
          "commitAuthorOld": "Colin Patrick Mccabe",
          "daysBetweenCommits": 23.84,
          "commitsBetweenForRepo": 188,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,33 @@\n-  private DNAddrPair getBestNodeDNAddrPair(final DatanodeInfo[] nodes,\n+  private DNAddrPair getBestNodeDNAddrPair(LocatedBlock block,\n       Collection\u003cDatanodeInfo\u003e ignoredNodes) throws IOException {\n-    DatanodeInfo chosenNode \u003d bestNode(nodes, deadNodes, ignoredNodes);\n+    DatanodeInfo[] nodes \u003d block.getLocations();\n+    StorageType[] storageTypes \u003d block.getStorageTypes();\n+    DatanodeInfo chosenNode \u003d null;\n+    StorageType storageType \u003d null;\n+    if (nodes !\u003d null) {\n+      for (int i \u003d 0; i \u003c nodes.length; i++) {\n+        if (!deadNodes.containsKey(nodes[i])\n+            \u0026\u0026 (ignoredNodes \u003d\u003d null || !ignoredNodes.contains(nodes[i]))) {\n+          chosenNode \u003d nodes[i];\n+          // Storage types are ordered to correspond with nodes, so use the same\n+          // index to get storage type.\n+          if (storageTypes !\u003d null \u0026\u0026 i \u003c storageTypes.length) {\n+            storageType \u003d storageTypes[i];\n+          }\n+          break;\n+        }\n+      }\n+    }\n+    if (chosenNode \u003d\u003d null) {\n+      throw new IOException(\"No live nodes contain block \" + block.getBlock() +\n+          \" after checking nodes \u003d \" + Arrays.toString(nodes) +\n+          \", ignoredNodes \u003d \" + ignoredNodes);\n+    }\n     final String dnAddr \u003d\n         chosenNode.getXferAddr(dfsClient.getConf().connectToDnViaHostname);\n     if (DFSClient.LOG.isDebugEnabled()) {\n       DFSClient.LOG.debug(\"Connecting to datanode \" + dnAddr);\n     }\n     InetSocketAddress targetAddr \u003d NetUtils.createSocketAddr(dnAddr);\n-    return new DNAddrPair(chosenNode, targetAddr);\n+    return new DNAddrPair(chosenNode, targetAddr, storageType);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private DNAddrPair getBestNodeDNAddrPair(LocatedBlock block,\n      Collection\u003cDatanodeInfo\u003e ignoredNodes) throws IOException {\n    DatanodeInfo[] nodes \u003d block.getLocations();\n    StorageType[] storageTypes \u003d block.getStorageTypes();\n    DatanodeInfo chosenNode \u003d null;\n    StorageType storageType \u003d null;\n    if (nodes !\u003d null) {\n      for (int i \u003d 0; i \u003c nodes.length; i++) {\n        if (!deadNodes.containsKey(nodes[i])\n            \u0026\u0026 (ignoredNodes \u003d\u003d null || !ignoredNodes.contains(nodes[i]))) {\n          chosenNode \u003d nodes[i];\n          // Storage types are ordered to correspond with nodes, so use the same\n          // index to get storage type.\n          if (storageTypes !\u003d null \u0026\u0026 i \u003c storageTypes.length) {\n            storageType \u003d storageTypes[i];\n          }\n          break;\n        }\n      }\n    }\n    if (chosenNode \u003d\u003d null) {\n      throw new IOException(\"No live nodes contain block \" + block.getBlock() +\n          \" after checking nodes \u003d \" + Arrays.toString(nodes) +\n          \", ignoredNodes \u003d \" + ignoredNodes);\n    }\n    final String dnAddr \u003d\n        chosenNode.getXferAddr(dfsClient.getConf().connectToDnViaHostname);\n    if (DFSClient.LOG.isDebugEnabled()) {\n      DFSClient.LOG.debug(\"Connecting to datanode \" + dnAddr);\n    }\n    InetSocketAddress targetAddr \u003d NetUtils.createSocketAddr(dnAddr);\n    return new DNAddrPair(chosenNode, targetAddr, storageType);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
          "extendedDetails": {}
        }
      ]
    },
    "17db74a1c1972392a5aba48a3e0334dcd6c76487": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-5776 Support \u0027hedged\u0027 reads in DFSClient\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1571466 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/02/14 2:34 PM",
      "commitName": "17db74a1c1972392a5aba48a3e0334dcd6c76487",
      "commitAuthor": "Michael Stack",
      "diff": "@@ -0,0 +1,11 @@\n+  private DNAddrPair getBestNodeDNAddrPair(final DatanodeInfo[] nodes,\n+      Collection\u003cDatanodeInfo\u003e ignoredNodes) throws IOException {\n+    DatanodeInfo chosenNode \u003d bestNode(nodes, deadNodes, ignoredNodes);\n+    final String dnAddr \u003d\n+        chosenNode.getXferAddr(dfsClient.getConf().connectToDnViaHostname);\n+    if (DFSClient.LOG.isDebugEnabled()) {\n+      DFSClient.LOG.debug(\"Connecting to datanode \" + dnAddr);\n+    }\n+    InetSocketAddress targetAddr \u003d NetUtils.createSocketAddr(dnAddr);\n+    return new DNAddrPair(chosenNode, targetAddr);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private DNAddrPair getBestNodeDNAddrPair(final DatanodeInfo[] nodes,\n      Collection\u003cDatanodeInfo\u003e ignoredNodes) throws IOException {\n    DatanodeInfo chosenNode \u003d bestNode(nodes, deadNodes, ignoredNodes);\n    final String dnAddr \u003d\n        chosenNode.getXferAddr(dfsClient.getConf().connectToDnViaHostname);\n    if (DFSClient.LOG.isDebugEnabled()) {\n      DFSClient.LOG.debug(\"Connecting to datanode \" + dnAddr);\n    }\n    InetSocketAddress targetAddr \u003d NetUtils.createSocketAddr(dnAddr);\n    return new DNAddrPair(chosenNode, targetAddr);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java"
    }
  }
}