{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockManager.java",
  "functionName": "chooseExcessRedundancies",
  "functionId": "chooseExcessRedundancies___nonExcess-Collection__DatanodeStorageInfo__(modifiers-final)__storedBlock-BlockInfo__replication-short__addedNode-DatanodeDescriptor__delNodeHint-DatanodeDescriptor",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
  "functionStartLine": 3892,
  "functionEndLine": 3910,
  "numCommitsSeen": 807,
  "timeTaken": 9851,
  "changeHistory": [
    "5865fe2bf01284993572ea60b3ec3bf8b4492818",
    "e27c2ae8bafc94f18eb38f5d839dcef5652d424e"
  ],
  "changeHistoryShort": {
    "5865fe2bf01284993572ea60b3ec3bf8b4492818": "Ymultichange(Yrename,Ybodychange)",
    "e27c2ae8bafc94f18eb38f5d839dcef5652d424e": "Ybodychange"
  },
  "changeHistoryDetails": {
    "5865fe2bf01284993572ea60b3ec3bf8b4492818": {
      "type": "Ymultichange(Yrename,Ybodychange)",
      "commitMessage": "HDFS-9869. Erasure Coding: Rename replication-based names in BlockManager to more generic [part-2]. Contributed by Rakesh R.\n",
      "commitDate": "25/04/16 10:01 PM",
      "commitName": "5865fe2bf01284993572ea60b3ec3bf8b4492818",
      "commitAuthor": "Zhe Zhang",
      "subchanges": [
        {
          "type": "Yrename",
          "commitMessage": "HDFS-9869. Erasure Coding: Rename replication-based names in BlockManager to more generic [part-2]. Contributed by Rakesh R.\n",
          "commitDate": "25/04/16 10:01 PM",
          "commitName": "5865fe2bf01284993572ea60b3ec3bf8b4492818",
          "commitAuthor": "Zhe Zhang",
          "commitDateOld": "17/04/16 6:28 PM",
          "commitNameOld": "67523ffcf491f4f2db5335899c00a174d0caaa9b",
          "commitAuthorOld": "Walter Su",
          "daysBetweenCommits": 8.15,
          "commitsBetweenForRepo": 47,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,19 +1,19 @@\n-  private void chooseExcessReplicates(\n+  private void chooseExcessRedundancies(\n       final Collection\u003cDatanodeStorageInfo\u003e nonExcess,\n       BlockInfo storedBlock, short replication,\n       DatanodeDescriptor addedNode,\n       DatanodeDescriptor delNodeHint) {\n     assert namesystem.hasWriteLock();\n     // first form a rack to datanodes map and\n     BlockCollection bc \u003d getBlockCollection(storedBlock);\n     if (storedBlock.isStriped()) {\n-      chooseExcessReplicasStriped(bc, nonExcess, storedBlock, delNodeHint);\n+      chooseExcessRedundancyStriped(bc, nonExcess, storedBlock, delNodeHint);\n     } else {\n       final BlockStoragePolicy storagePolicy \u003d storagePolicySuite.getPolicy(\n           bc.getStoragePolicyID());\n       final List\u003cStorageType\u003e excessTypes \u003d storagePolicy.chooseExcess(\n           replication, DatanodeStorageInfo.toStorageTypes(nonExcess));\n-      chooseExcessReplicasContiguous(nonExcess, storedBlock, replication,\n+      chooseExcessRedundancyContiguous(nonExcess, storedBlock, replication,\n           addedNode, delNodeHint, excessTypes);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void chooseExcessRedundancies(\n      final Collection\u003cDatanodeStorageInfo\u003e nonExcess,\n      BlockInfo storedBlock, short replication,\n      DatanodeDescriptor addedNode,\n      DatanodeDescriptor delNodeHint) {\n    assert namesystem.hasWriteLock();\n    // first form a rack to datanodes map and\n    BlockCollection bc \u003d getBlockCollection(storedBlock);\n    if (storedBlock.isStriped()) {\n      chooseExcessRedundancyStriped(bc, nonExcess, storedBlock, delNodeHint);\n    } else {\n      final BlockStoragePolicy storagePolicy \u003d storagePolicySuite.getPolicy(\n          bc.getStoragePolicyID());\n      final List\u003cStorageType\u003e excessTypes \u003d storagePolicy.chooseExcess(\n          replication, DatanodeStorageInfo.toStorageTypes(nonExcess));\n      chooseExcessRedundancyContiguous(nonExcess, storedBlock, replication,\n          addedNode, delNodeHint, excessTypes);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
          "extendedDetails": {
            "oldValue": "chooseExcessReplicates",
            "newValue": "chooseExcessRedundancies"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-9869. Erasure Coding: Rename replication-based names in BlockManager to more generic [part-2]. Contributed by Rakesh R.\n",
          "commitDate": "25/04/16 10:01 PM",
          "commitName": "5865fe2bf01284993572ea60b3ec3bf8b4492818",
          "commitAuthor": "Zhe Zhang",
          "commitDateOld": "17/04/16 6:28 PM",
          "commitNameOld": "67523ffcf491f4f2db5335899c00a174d0caaa9b",
          "commitAuthorOld": "Walter Su",
          "daysBetweenCommits": 8.15,
          "commitsBetweenForRepo": 47,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,19 +1,19 @@\n-  private void chooseExcessReplicates(\n+  private void chooseExcessRedundancies(\n       final Collection\u003cDatanodeStorageInfo\u003e nonExcess,\n       BlockInfo storedBlock, short replication,\n       DatanodeDescriptor addedNode,\n       DatanodeDescriptor delNodeHint) {\n     assert namesystem.hasWriteLock();\n     // first form a rack to datanodes map and\n     BlockCollection bc \u003d getBlockCollection(storedBlock);\n     if (storedBlock.isStriped()) {\n-      chooseExcessReplicasStriped(bc, nonExcess, storedBlock, delNodeHint);\n+      chooseExcessRedundancyStriped(bc, nonExcess, storedBlock, delNodeHint);\n     } else {\n       final BlockStoragePolicy storagePolicy \u003d storagePolicySuite.getPolicy(\n           bc.getStoragePolicyID());\n       final List\u003cStorageType\u003e excessTypes \u003d storagePolicy.chooseExcess(\n           replication, DatanodeStorageInfo.toStorageTypes(nonExcess));\n-      chooseExcessReplicasContiguous(nonExcess, storedBlock, replication,\n+      chooseExcessRedundancyContiguous(nonExcess, storedBlock, replication,\n           addedNode, delNodeHint, excessTypes);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void chooseExcessRedundancies(\n      final Collection\u003cDatanodeStorageInfo\u003e nonExcess,\n      BlockInfo storedBlock, short replication,\n      DatanodeDescriptor addedNode,\n      DatanodeDescriptor delNodeHint) {\n    assert namesystem.hasWriteLock();\n    // first form a rack to datanodes map and\n    BlockCollection bc \u003d getBlockCollection(storedBlock);\n    if (storedBlock.isStriped()) {\n      chooseExcessRedundancyStriped(bc, nonExcess, storedBlock, delNodeHint);\n    } else {\n      final BlockStoragePolicy storagePolicy \u003d storagePolicySuite.getPolicy(\n          bc.getStoragePolicyID());\n      final List\u003cStorageType\u003e excessTypes \u003d storagePolicy.chooseExcess(\n          replication, DatanodeStorageInfo.toStorageTypes(nonExcess));\n      chooseExcessRedundancyContiguous(nonExcess, storedBlock, replication,\n          addedNode, delNodeHint, excessTypes);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "e27c2ae8bafc94f18eb38f5d839dcef5652d424e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8647. Abstract BlockManager\u0027s rack policy into BlockPlacementPolicy. (Brahma Reddy Battula via mingma)\n",
      "commitDate": "21/10/15 8:06 AM",
      "commitName": "e27c2ae8bafc94f18eb38f5d839dcef5652d424e",
      "commitAuthor": "Ming Ma",
      "commitDateOld": "15/10/15 3:07 AM",
      "commitNameOld": "5411dc559d5f73e4153e76fdff94a26869c17a37",
      "commitAuthorOld": "Tsz-Wo Nicholas Sze",
      "daysBetweenCommits": 6.21,
      "commitsBetweenForRepo": 41,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,19 +1,19 @@\n   private void chooseExcessReplicates(\n       final Collection\u003cDatanodeStorageInfo\u003e nonExcess,\n       BlockInfo storedBlock, short replication,\n       DatanodeDescriptor addedNode,\n       DatanodeDescriptor delNodeHint) {\n     assert namesystem.hasWriteLock();\n     // first form a rack to datanodes map and\n     BlockCollection bc \u003d getBlockCollection(storedBlock);\n     if (storedBlock.isStriped()) {\n       chooseExcessReplicasStriped(bc, nonExcess, storedBlock, delNodeHint);\n     } else {\n       final BlockStoragePolicy storagePolicy \u003d storagePolicySuite.getPolicy(\n           bc.getStoragePolicyID());\n       final List\u003cStorageType\u003e excessTypes \u003d storagePolicy.chooseExcess(\n           replication, DatanodeStorageInfo.toStorageTypes(nonExcess));\n-      chooseExcessReplicasContiguous(bc, nonExcess, storedBlock,\n-          replication, addedNode, delNodeHint, excessTypes);\n+      chooseExcessReplicasContiguous(nonExcess, storedBlock, replication,\n+          addedNode, delNodeHint, excessTypes);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void chooseExcessReplicates(\n      final Collection\u003cDatanodeStorageInfo\u003e nonExcess,\n      BlockInfo storedBlock, short replication,\n      DatanodeDescriptor addedNode,\n      DatanodeDescriptor delNodeHint) {\n    assert namesystem.hasWriteLock();\n    // first form a rack to datanodes map and\n    BlockCollection bc \u003d getBlockCollection(storedBlock);\n    if (storedBlock.isStriped()) {\n      chooseExcessReplicasStriped(bc, nonExcess, storedBlock, delNodeHint);\n    } else {\n      final BlockStoragePolicy storagePolicy \u003d storagePolicySuite.getPolicy(\n          bc.getStoragePolicyID());\n      final List\u003cStorageType\u003e excessTypes \u003d storagePolicy.chooseExcess(\n          replication, DatanodeStorageInfo.toStorageTypes(nonExcess));\n      chooseExcessReplicasContiguous(nonExcess, storedBlock, replication,\n          addedNode, delNodeHint, excessTypes);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    }
  }
}