{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "EntityRowKey.java",
  "functionName": "encode",
  "functionId": "encode___rowKey-EntityRowKey",
  "sourceFilePath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-common/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/entity/EntityRowKey.java",
  "functionStartLine": 183,
  "functionEndLine": 226,
  "numCommitsSeen": 16,
  "timeTaken": 4078,
  "changeHistory": [
    "9af30d46c6e82332a8eda20cb3eb5f987e25e7a2",
    "a990ff70c25e2ab746578500720c531f23e0851e",
    "02a9710a099fc9572122d87dd3e90c78522f5836",
    "05ff04439e2edeef0460bc9e21034535b8b6eb9e",
    "b01514f65bc6090a50a583f67d1ecb5d74b6d276",
    "892b193bd77c15932b4c084c1d525b7017def0d4",
    "7b8cfa5c2ff62005c8b78867fedd64b48e50383d"
  ],
  "changeHistoryShort": {
    "9af30d46c6e82332a8eda20cb3eb5f987e25e7a2": "Yfilerename",
    "a990ff70c25e2ab746578500720c531f23e0851e": "Ybodychange",
    "02a9710a099fc9572122d87dd3e90c78522f5836": "Ybodychange",
    "05ff04439e2edeef0460bc9e21034535b8b6eb9e": "Ybodychange",
    "b01514f65bc6090a50a583f67d1ecb5d74b6d276": "Yfilerename",
    "892b193bd77c15932b4c084c1d525b7017def0d4": "Ymultichange(Ymovefromfile,Ybodychange)",
    "7b8cfa5c2ff62005c8b78867fedd64b48e50383d": "Yintroduced"
  },
  "changeHistoryDetails": {
    "9af30d46c6e82332a8eda20cb3eb5f987e25e7a2": {
      "type": "Yfilerename",
      "commitMessage": "YARN-7919. Refactor timelineservice-hbase module into submodules. Contributed by Haibo Chen.\n",
      "commitDate": "17/02/18 7:00 AM",
      "commitName": "9af30d46c6e82332a8eda20cb3eb5f987e25e7a2",
      "commitAuthor": "Rohith Sharma K S",
      "commitDateOld": "17/02/18 3:24 AM",
      "commitNameOld": "a1e56a62863d8d494af309ec5f476c4b7e4d5ef9",
      "commitAuthorOld": "Arun Suresh",
      "daysBetweenCommits": 0.15,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    public byte[] encode(EntityRowKey rowKey) {\n      byte[] user \u003d\n          Separator.encode(rowKey.getUserId(), Separator.SPACE, Separator.TAB,\n              Separator.QUALIFIERS);\n      byte[] cluster \u003d\n          Separator.encode(rowKey.getClusterId(), Separator.SPACE,\n              Separator.TAB, Separator.QUALIFIERS);\n      byte[] flow \u003d\n          Separator.encode(rowKey.getFlowName(), Separator.SPACE,\n              Separator.TAB, Separator.QUALIFIERS);\n      byte[] first \u003d Separator.QUALIFIERS.join(user, cluster, flow);\n      // Note that flowRunId is a long, so we can\u0027t encode them all at the same\n      // time.\n      byte[] second \u003d\n          Bytes.toBytes(LongConverter.invertLong(rowKey.getFlowRunId()));\n      byte[] third \u003d appIDKeyConverter.encode(rowKey.getAppId());\n      if (rowKey.getEntityType() \u003d\u003d null) {\n        return Separator.QUALIFIERS.join(first, second, third,\n            Separator.EMPTY_BYTES);\n      }\n      byte[] entityType \u003d\n          Separator.encode(rowKey.getEntityType(), Separator.SPACE,\n              Separator.TAB, Separator.QUALIFIERS);\n\n      if (rowKey.getEntityIdPrefix() \u003d\u003d null) {\n        return Separator.QUALIFIERS.join(first, second, third, entityType,\n            Separator.EMPTY_BYTES);\n      }\n\n      byte[] entityIdPrefix \u003d Bytes.toBytes(rowKey.getEntityIdPrefix());\n\n      if (rowKey.getEntityId() \u003d\u003d null) {\n        return Separator.QUALIFIERS.join(first, second, third, entityType,\n            entityIdPrefix, Separator.EMPTY_BYTES);\n      }\n\n      byte[] entityId \u003d Separator.encode(rowKey.getEntityId(), Separator.SPACE,\n          Separator.TAB, Separator.QUALIFIERS);\n\n      byte[] fourth \u003d\n          Separator.QUALIFIERS.join(entityType, entityIdPrefix, entityId);\n\n      return Separator.QUALIFIERS.join(first, second, third, fourth);\n    }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-common/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/entity/EntityRowKey.java",
      "extendedDetails": {
        "oldPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/entity/EntityRowKey.java",
        "newPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-common/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/entity/EntityRowKey.java"
      }
    },
    "a990ff70c25e2ab746578500720c531f23e0851e": {
      "type": "Ybodychange",
      "commitMessage": "YARN-6733. Add table for storing sub-application entities. Contributed by Vrushali C.\n",
      "commitDate": "29/08/17 10:59 PM",
      "commitName": "a990ff70c25e2ab746578500720c531f23e0851e",
      "commitAuthor": "Rohith Sharma K S",
      "commitDateOld": "29/08/17 10:59 PM",
      "commitNameOld": "c3bd8d6ad3e30c08865cc1a5f374d1d2a485f844",
      "commitAuthorOld": "Varun Saxena",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 13,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,44 +1,44 @@\n     public byte[] encode(EntityRowKey rowKey) {\n       byte[] user \u003d\n           Separator.encode(rowKey.getUserId(), Separator.SPACE, Separator.TAB,\n               Separator.QUALIFIERS);\n       byte[] cluster \u003d\n           Separator.encode(rowKey.getClusterId(), Separator.SPACE,\n               Separator.TAB, Separator.QUALIFIERS);\n       byte[] flow \u003d\n           Separator.encode(rowKey.getFlowName(), Separator.SPACE,\n               Separator.TAB, Separator.QUALIFIERS);\n       byte[] first \u003d Separator.QUALIFIERS.join(user, cluster, flow);\n       // Note that flowRunId is a long, so we can\u0027t encode them all at the same\n       // time.\n       byte[] second \u003d\n           Bytes.toBytes(LongConverter.invertLong(rowKey.getFlowRunId()));\n       byte[] third \u003d appIDKeyConverter.encode(rowKey.getAppId());\n       if (rowKey.getEntityType() \u003d\u003d null) {\n         return Separator.QUALIFIERS.join(first, second, third,\n             Separator.EMPTY_BYTES);\n       }\n       byte[] entityType \u003d\n           Separator.encode(rowKey.getEntityType(), Separator.SPACE,\n               Separator.TAB, Separator.QUALIFIERS);\n \n       if (rowKey.getEntityIdPrefix() \u003d\u003d null) {\n         return Separator.QUALIFIERS.join(first, second, third, entityType,\n             Separator.EMPTY_BYTES);\n       }\n \n-      byte[] enitityIdPrefix \u003d Bytes.toBytes(rowKey.getEntityIdPrefix());\n+      byte[] entityIdPrefix \u003d Bytes.toBytes(rowKey.getEntityIdPrefix());\n \n       if (rowKey.getEntityId() \u003d\u003d null) {\n         return Separator.QUALIFIERS.join(first, second, third, entityType,\n-            enitityIdPrefix, Separator.EMPTY_BYTES);\n+            entityIdPrefix, Separator.EMPTY_BYTES);\n       }\n \n       byte[] entityId \u003d Separator.encode(rowKey.getEntityId(), Separator.SPACE,\n           Separator.TAB, Separator.QUALIFIERS);\n \n       byte[] fourth \u003d\n-          Separator.QUALIFIERS.join(entityType, enitityIdPrefix, entityId);\n+          Separator.QUALIFIERS.join(entityType, entityIdPrefix, entityId);\n \n       return Separator.QUALIFIERS.join(first, second, third, fourth);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public byte[] encode(EntityRowKey rowKey) {\n      byte[] user \u003d\n          Separator.encode(rowKey.getUserId(), Separator.SPACE, Separator.TAB,\n              Separator.QUALIFIERS);\n      byte[] cluster \u003d\n          Separator.encode(rowKey.getClusterId(), Separator.SPACE,\n              Separator.TAB, Separator.QUALIFIERS);\n      byte[] flow \u003d\n          Separator.encode(rowKey.getFlowName(), Separator.SPACE,\n              Separator.TAB, Separator.QUALIFIERS);\n      byte[] first \u003d Separator.QUALIFIERS.join(user, cluster, flow);\n      // Note that flowRunId is a long, so we can\u0027t encode them all at the same\n      // time.\n      byte[] second \u003d\n          Bytes.toBytes(LongConverter.invertLong(rowKey.getFlowRunId()));\n      byte[] third \u003d appIDKeyConverter.encode(rowKey.getAppId());\n      if (rowKey.getEntityType() \u003d\u003d null) {\n        return Separator.QUALIFIERS.join(first, second, third,\n            Separator.EMPTY_BYTES);\n      }\n      byte[] entityType \u003d\n          Separator.encode(rowKey.getEntityType(), Separator.SPACE,\n              Separator.TAB, Separator.QUALIFIERS);\n\n      if (rowKey.getEntityIdPrefix() \u003d\u003d null) {\n        return Separator.QUALIFIERS.join(first, second, third, entityType,\n            Separator.EMPTY_BYTES);\n      }\n\n      byte[] entityIdPrefix \u003d Bytes.toBytes(rowKey.getEntityIdPrefix());\n\n      if (rowKey.getEntityId() \u003d\u003d null) {\n        return Separator.QUALIFIERS.join(first, second, third, entityType,\n            entityIdPrefix, Separator.EMPTY_BYTES);\n      }\n\n      byte[] entityId \u003d Separator.encode(rowKey.getEntityId(), Separator.SPACE,\n          Separator.TAB, Separator.QUALIFIERS);\n\n      byte[] fourth \u003d\n          Separator.QUALIFIERS.join(entityType, entityIdPrefix, entityId);\n\n      return Separator.QUALIFIERS.join(first, second, third, fourth);\n    }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/entity/EntityRowKey.java",
      "extendedDetails": {}
    },
    "02a9710a099fc9572122d87dd3e90c78522f5836": {
      "type": "Ybodychange",
      "commitMessage": "YARN-5585. [Atsv2] Reader side changes for entity prefix and support for pagination via additional filters (Rohith Sharma K S via Varun Saxena)\n",
      "commitDate": "29/08/17 10:59 PM",
      "commitName": "02a9710a099fc9572122d87dd3e90c78522f5836",
      "commitAuthor": "Varun Saxena",
      "commitDateOld": "29/08/17 10:59 PM",
      "commitNameOld": "05ff04439e2edeef0460bc9e21034535b8b6eb9e",
      "commitAuthorOld": "Sangjin Lee",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 9,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,34 +1,44 @@\n     public byte[] encode(EntityRowKey rowKey) {\n       byte[] user \u003d\n           Separator.encode(rowKey.getUserId(), Separator.SPACE, Separator.TAB,\n               Separator.QUALIFIERS);\n       byte[] cluster \u003d\n           Separator.encode(rowKey.getClusterId(), Separator.SPACE,\n               Separator.TAB, Separator.QUALIFIERS);\n       byte[] flow \u003d\n           Separator.encode(rowKey.getFlowName(), Separator.SPACE,\n               Separator.TAB, Separator.QUALIFIERS);\n       byte[] first \u003d Separator.QUALIFIERS.join(user, cluster, flow);\n       // Note that flowRunId is a long, so we can\u0027t encode them all at the same\n       // time.\n       byte[] second \u003d\n           Bytes.toBytes(LongConverter.invertLong(rowKey.getFlowRunId()));\n       byte[] third \u003d appIDKeyConverter.encode(rowKey.getAppId());\n       if (rowKey.getEntityType() \u003d\u003d null) {\n         return Separator.QUALIFIERS.join(first, second, third,\n             Separator.EMPTY_BYTES);\n       }\n       byte[] entityType \u003d\n           Separator.encode(rowKey.getEntityType(), Separator.SPACE,\n               Separator.TAB, Separator.QUALIFIERS);\n \n+      if (rowKey.getEntityIdPrefix() \u003d\u003d null) {\n+        return Separator.QUALIFIERS.join(first, second, third, entityType,\n+            Separator.EMPTY_BYTES);\n+      }\n+\n       byte[] enitityIdPrefix \u003d Bytes.toBytes(rowKey.getEntityIdPrefix());\n \n-      byte[] entityId \u003d\n-          rowKey.getEntityId() \u003d\u003d null ? Separator.EMPTY_BYTES : Separator\n-              .encode(rowKey.getEntityId(), Separator.SPACE, Separator.TAB,\n-                  Separator.QUALIFIERS);\n+      if (rowKey.getEntityId() \u003d\u003d null) {\n+        return Separator.QUALIFIERS.join(first, second, third, entityType,\n+            enitityIdPrefix, Separator.EMPTY_BYTES);\n+      }\n+\n+      byte[] entityId \u003d Separator.encode(rowKey.getEntityId(), Separator.SPACE,\n+          Separator.TAB, Separator.QUALIFIERS);\n+\n       byte[] fourth \u003d\n           Separator.QUALIFIERS.join(entityType, enitityIdPrefix, entityId);\n+\n       return Separator.QUALIFIERS.join(first, second, third, fourth);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public byte[] encode(EntityRowKey rowKey) {\n      byte[] user \u003d\n          Separator.encode(rowKey.getUserId(), Separator.SPACE, Separator.TAB,\n              Separator.QUALIFIERS);\n      byte[] cluster \u003d\n          Separator.encode(rowKey.getClusterId(), Separator.SPACE,\n              Separator.TAB, Separator.QUALIFIERS);\n      byte[] flow \u003d\n          Separator.encode(rowKey.getFlowName(), Separator.SPACE,\n              Separator.TAB, Separator.QUALIFIERS);\n      byte[] first \u003d Separator.QUALIFIERS.join(user, cluster, flow);\n      // Note that flowRunId is a long, so we can\u0027t encode them all at the same\n      // time.\n      byte[] second \u003d\n          Bytes.toBytes(LongConverter.invertLong(rowKey.getFlowRunId()));\n      byte[] third \u003d appIDKeyConverter.encode(rowKey.getAppId());\n      if (rowKey.getEntityType() \u003d\u003d null) {\n        return Separator.QUALIFIERS.join(first, second, third,\n            Separator.EMPTY_BYTES);\n      }\n      byte[] entityType \u003d\n          Separator.encode(rowKey.getEntityType(), Separator.SPACE,\n              Separator.TAB, Separator.QUALIFIERS);\n\n      if (rowKey.getEntityIdPrefix() \u003d\u003d null) {\n        return Separator.QUALIFIERS.join(first, second, third, entityType,\n            Separator.EMPTY_BYTES);\n      }\n\n      byte[] enitityIdPrefix \u003d Bytes.toBytes(rowKey.getEntityIdPrefix());\n\n      if (rowKey.getEntityId() \u003d\u003d null) {\n        return Separator.QUALIFIERS.join(first, second, third, entityType,\n            enitityIdPrefix, Separator.EMPTY_BYTES);\n      }\n\n      byte[] entityId \u003d Separator.encode(rowKey.getEntityId(), Separator.SPACE,\n          Separator.TAB, Separator.QUALIFIERS);\n\n      byte[] fourth \u003d\n          Separator.QUALIFIERS.join(entityType, enitityIdPrefix, entityId);\n\n      return Separator.QUALIFIERS.join(first, second, third, fourth);\n    }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/entity/EntityRowKey.java",
      "extendedDetails": {}
    },
    "05ff04439e2edeef0460bc9e21034535b8b6eb9e": {
      "type": "Ybodychange",
      "commitMessage": "YARN-5715. Introduce entity prefix for return and sort order. Contributed by Rohith Sharma K S.\n",
      "commitDate": "29/08/17 10:59 PM",
      "commitName": "05ff04439e2edeef0460bc9e21034535b8b6eb9e",
      "commitAuthor": "Sangjin Lee",
      "commitDateOld": "19/01/17 8:52 PM",
      "commitNameOld": "b01514f65bc6090a50a583f67d1ecb5d74b6d276",
      "commitAuthorOld": "Sangjin Lee",
      "daysBetweenCommits": 222.05,
      "commitsBetweenForRepo": 1248,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,30 +1,34 @@\n     public byte[] encode(EntityRowKey rowKey) {\n       byte[] user \u003d\n           Separator.encode(rowKey.getUserId(), Separator.SPACE, Separator.TAB,\n               Separator.QUALIFIERS);\n       byte[] cluster \u003d\n           Separator.encode(rowKey.getClusterId(), Separator.SPACE,\n               Separator.TAB, Separator.QUALIFIERS);\n       byte[] flow \u003d\n           Separator.encode(rowKey.getFlowName(), Separator.SPACE,\n               Separator.TAB, Separator.QUALIFIERS);\n       byte[] first \u003d Separator.QUALIFIERS.join(user, cluster, flow);\n       // Note that flowRunId is a long, so we can\u0027t encode them all at the same\n       // time.\n       byte[] second \u003d\n           Bytes.toBytes(LongConverter.invertLong(rowKey.getFlowRunId()));\n       byte[] third \u003d appIDKeyConverter.encode(rowKey.getAppId());\n       if (rowKey.getEntityType() \u003d\u003d null) {\n         return Separator.QUALIFIERS.join(first, second, third,\n             Separator.EMPTY_BYTES);\n       }\n       byte[] entityType \u003d\n           Separator.encode(rowKey.getEntityType(), Separator.SPACE,\n               Separator.TAB, Separator.QUALIFIERS);\n+\n+      byte[] enitityIdPrefix \u003d Bytes.toBytes(rowKey.getEntityIdPrefix());\n+\n       byte[] entityId \u003d\n           rowKey.getEntityId() \u003d\u003d null ? Separator.EMPTY_BYTES : Separator\n               .encode(rowKey.getEntityId(), Separator.SPACE, Separator.TAB,\n                   Separator.QUALIFIERS);\n-      byte[] fourth \u003d Separator.QUALIFIERS.join(entityType, entityId);\n+      byte[] fourth \u003d\n+          Separator.QUALIFIERS.join(entityType, enitityIdPrefix, entityId);\n       return Separator.QUALIFIERS.join(first, second, third, fourth);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public byte[] encode(EntityRowKey rowKey) {\n      byte[] user \u003d\n          Separator.encode(rowKey.getUserId(), Separator.SPACE, Separator.TAB,\n              Separator.QUALIFIERS);\n      byte[] cluster \u003d\n          Separator.encode(rowKey.getClusterId(), Separator.SPACE,\n              Separator.TAB, Separator.QUALIFIERS);\n      byte[] flow \u003d\n          Separator.encode(rowKey.getFlowName(), Separator.SPACE,\n              Separator.TAB, Separator.QUALIFIERS);\n      byte[] first \u003d Separator.QUALIFIERS.join(user, cluster, flow);\n      // Note that flowRunId is a long, so we can\u0027t encode them all at the same\n      // time.\n      byte[] second \u003d\n          Bytes.toBytes(LongConverter.invertLong(rowKey.getFlowRunId()));\n      byte[] third \u003d appIDKeyConverter.encode(rowKey.getAppId());\n      if (rowKey.getEntityType() \u003d\u003d null) {\n        return Separator.QUALIFIERS.join(first, second, third,\n            Separator.EMPTY_BYTES);\n      }\n      byte[] entityType \u003d\n          Separator.encode(rowKey.getEntityType(), Separator.SPACE,\n              Separator.TAB, Separator.QUALIFIERS);\n\n      byte[] enitityIdPrefix \u003d Bytes.toBytes(rowKey.getEntityIdPrefix());\n\n      byte[] entityId \u003d\n          rowKey.getEntityId() \u003d\u003d null ? Separator.EMPTY_BYTES : Separator\n              .encode(rowKey.getEntityId(), Separator.SPACE, Separator.TAB,\n                  Separator.QUALIFIERS);\n      byte[] fourth \u003d\n          Separator.QUALIFIERS.join(entityType, enitityIdPrefix, entityId);\n      return Separator.QUALIFIERS.join(first, second, third, fourth);\n    }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/entity/EntityRowKey.java",
      "extendedDetails": {}
    },
    "b01514f65bc6090a50a583f67d1ecb5d74b6d276": {
      "type": "Yfilerename",
      "commitMessage": "YARN-5928. Move ATSv2 HBase backend code into a new module that is only dependent at runtime by yarn servers. Contributed by Haibo Chen.\n",
      "commitDate": "19/01/17 8:52 PM",
      "commitName": "b01514f65bc6090a50a583f67d1ecb5d74b6d276",
      "commitAuthor": "Sangjin Lee",
      "commitDateOld": "19/01/17 5:32 PM",
      "commitNameOld": "60865c8ea08053f3d6ac23f81c3376a3de3ca996",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 0.14,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    public byte[] encode(EntityRowKey rowKey) {\n      byte[] user \u003d\n          Separator.encode(rowKey.getUserId(), Separator.SPACE, Separator.TAB,\n              Separator.QUALIFIERS);\n      byte[] cluster \u003d\n          Separator.encode(rowKey.getClusterId(), Separator.SPACE,\n              Separator.TAB, Separator.QUALIFIERS);\n      byte[] flow \u003d\n          Separator.encode(rowKey.getFlowName(), Separator.SPACE,\n              Separator.TAB, Separator.QUALIFIERS);\n      byte[] first \u003d Separator.QUALIFIERS.join(user, cluster, flow);\n      // Note that flowRunId is a long, so we can\u0027t encode them all at the same\n      // time.\n      byte[] second \u003d\n          Bytes.toBytes(LongConverter.invertLong(rowKey.getFlowRunId()));\n      byte[] third \u003d appIDKeyConverter.encode(rowKey.getAppId());\n      if (rowKey.getEntityType() \u003d\u003d null) {\n        return Separator.QUALIFIERS.join(first, second, third,\n            Separator.EMPTY_BYTES);\n      }\n      byte[] entityType \u003d\n          Separator.encode(rowKey.getEntityType(), Separator.SPACE,\n              Separator.TAB, Separator.QUALIFIERS);\n      byte[] entityId \u003d\n          rowKey.getEntityId() \u003d\u003d null ? Separator.EMPTY_BYTES : Separator\n              .encode(rowKey.getEntityId(), Separator.SPACE, Separator.TAB,\n                  Separator.QUALIFIERS);\n      byte[] fourth \u003d Separator.QUALIFIERS.join(entityType, entityId);\n      return Separator.QUALIFIERS.join(first, second, third, fourth);\n    }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/entity/EntityRowKey.java",
      "extendedDetails": {
        "oldPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/entity/EntityRowKey.java",
        "newPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/entity/EntityRowKey.java"
      }
    },
    "892b193bd77c15932b4c084c1d525b7017def0d4": {
      "type": "Ymultichange(Ymovefromfile,Ybodychange)",
      "commitMessage": "YARN-5170. Eliminate singleton converters and static method access. (Joep Rottinghuis via Varun Saxena)\n",
      "commitDate": "10/07/16 8:46 AM",
      "commitName": "892b193bd77c15932b4c084c1d525b7017def0d4",
      "commitAuthor": "Varun Saxena",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "YARN-5170. Eliminate singleton converters and static method access. (Joep Rottinghuis via Varun Saxena)\n",
          "commitDate": "10/07/16 8:46 AM",
          "commitName": "892b193bd77c15932b4c084c1d525b7017def0d4",
          "commitAuthor": "Varun Saxena",
          "commitDateOld": "10/07/16 8:46 AM",
          "commitNameOld": "3832795e3c3ea9dcf5c70f348f894882b2ace98e",
          "commitAuthorOld": "Vrushali Channapattan",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,25 +1,30 @@\n-  public byte[] encode(EntityRowKey rowKey) {\n-    byte[] user \u003d Separator.encode(rowKey.getUserId(),\n-        Separator.SPACE, Separator.TAB, Separator.QUALIFIERS);\n-    byte[] cluster \u003d Separator.encode(rowKey.getClusterId(),\n-        Separator.SPACE, Separator.TAB, Separator.QUALIFIERS);\n-    byte[] flow \u003d Separator.encode(rowKey.getFlowName(),\n-        Separator.SPACE, Separator.TAB, Separator.QUALIFIERS);\n-    byte[] first \u003d Separator.QUALIFIERS.join(user, cluster, flow);\n-    // Note that flowRunId is a long, so we can\u0027t encode them all at the same\n-    // time.\n-    byte[] second \u003d Bytes.toBytes(TimelineStorageUtils.invertLong(\n-        rowKey.getFlowRunId()));\n-    byte[] third \u003d AppIdKeyConverter.getInstance().encode(rowKey.getAppId());\n-    if (rowKey.getEntityType() \u003d\u003d null) {\n-      return Separator.QUALIFIERS.join(\n-          first, second, third, Separator.EMPTY_BYTES);\n-    }\n-    byte[] entityType \u003d Separator.encode(rowKey.getEntityType(),\n-        Separator.SPACE, Separator.TAB, Separator.QUALIFIERS);\n-    byte[] entityId \u003d rowKey.getEntityId() \u003d\u003d null ? Separator.EMPTY_BYTES :\n-        Separator.encode(rowKey.getEntityId(), Separator.SPACE, Separator.TAB,\n-        Separator.QUALIFIERS);\n-    byte[] fourth \u003d Separator.QUALIFIERS.join(entityType, entityId);\n-    return Separator.QUALIFIERS.join(first, second, third, fourth);\n-  }\n\\ No newline at end of file\n+    public byte[] encode(EntityRowKey rowKey) {\n+      byte[] user \u003d\n+          Separator.encode(rowKey.getUserId(), Separator.SPACE, Separator.TAB,\n+              Separator.QUALIFIERS);\n+      byte[] cluster \u003d\n+          Separator.encode(rowKey.getClusterId(), Separator.SPACE,\n+              Separator.TAB, Separator.QUALIFIERS);\n+      byte[] flow \u003d\n+          Separator.encode(rowKey.getFlowName(), Separator.SPACE,\n+              Separator.TAB, Separator.QUALIFIERS);\n+      byte[] first \u003d Separator.QUALIFIERS.join(user, cluster, flow);\n+      // Note that flowRunId is a long, so we can\u0027t encode them all at the same\n+      // time.\n+      byte[] second \u003d\n+          Bytes.toBytes(LongConverter.invertLong(rowKey.getFlowRunId()));\n+      byte[] third \u003d appIDKeyConverter.encode(rowKey.getAppId());\n+      if (rowKey.getEntityType() \u003d\u003d null) {\n+        return Separator.QUALIFIERS.join(first, second, third,\n+            Separator.EMPTY_BYTES);\n+      }\n+      byte[] entityType \u003d\n+          Separator.encode(rowKey.getEntityType(), Separator.SPACE,\n+              Separator.TAB, Separator.QUALIFIERS);\n+      byte[] entityId \u003d\n+          rowKey.getEntityId() \u003d\u003d null ? Separator.EMPTY_BYTES : Separator\n+              .encode(rowKey.getEntityId(), Separator.SPACE, Separator.TAB,\n+                  Separator.QUALIFIERS);\n+      byte[] fourth \u003d Separator.QUALIFIERS.join(entityType, entityId);\n+      return Separator.QUALIFIERS.join(first, second, third, fourth);\n+    }\n\\ No newline at end of file\n",
          "actualSource": "    public byte[] encode(EntityRowKey rowKey) {\n      byte[] user \u003d\n          Separator.encode(rowKey.getUserId(), Separator.SPACE, Separator.TAB,\n              Separator.QUALIFIERS);\n      byte[] cluster \u003d\n          Separator.encode(rowKey.getClusterId(), Separator.SPACE,\n              Separator.TAB, Separator.QUALIFIERS);\n      byte[] flow \u003d\n          Separator.encode(rowKey.getFlowName(), Separator.SPACE,\n              Separator.TAB, Separator.QUALIFIERS);\n      byte[] first \u003d Separator.QUALIFIERS.join(user, cluster, flow);\n      // Note that flowRunId is a long, so we can\u0027t encode them all at the same\n      // time.\n      byte[] second \u003d\n          Bytes.toBytes(LongConverter.invertLong(rowKey.getFlowRunId()));\n      byte[] third \u003d appIDKeyConverter.encode(rowKey.getAppId());\n      if (rowKey.getEntityType() \u003d\u003d null) {\n        return Separator.QUALIFIERS.join(first, second, third,\n            Separator.EMPTY_BYTES);\n      }\n      byte[] entityType \u003d\n          Separator.encode(rowKey.getEntityType(), Separator.SPACE,\n              Separator.TAB, Separator.QUALIFIERS);\n      byte[] entityId \u003d\n          rowKey.getEntityId() \u003d\u003d null ? Separator.EMPTY_BYTES : Separator\n              .encode(rowKey.getEntityId(), Separator.SPACE, Separator.TAB,\n                  Separator.QUALIFIERS);\n      byte[] fourth \u003d Separator.QUALIFIERS.join(entityType, entityId);\n      return Separator.QUALIFIERS.join(first, second, third, fourth);\n    }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/entity/EntityRowKey.java",
          "extendedDetails": {
            "oldPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/entity/EntityRowKeyConverter.java",
            "newPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/entity/EntityRowKey.java",
            "oldMethodName": "encode",
            "newMethodName": "encode"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-5170. Eliminate singleton converters and static method access. (Joep Rottinghuis via Varun Saxena)\n",
          "commitDate": "10/07/16 8:46 AM",
          "commitName": "892b193bd77c15932b4c084c1d525b7017def0d4",
          "commitAuthor": "Varun Saxena",
          "commitDateOld": "10/07/16 8:46 AM",
          "commitNameOld": "3832795e3c3ea9dcf5c70f348f894882b2ace98e",
          "commitAuthorOld": "Vrushali Channapattan",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,25 +1,30 @@\n-  public byte[] encode(EntityRowKey rowKey) {\n-    byte[] user \u003d Separator.encode(rowKey.getUserId(),\n-        Separator.SPACE, Separator.TAB, Separator.QUALIFIERS);\n-    byte[] cluster \u003d Separator.encode(rowKey.getClusterId(),\n-        Separator.SPACE, Separator.TAB, Separator.QUALIFIERS);\n-    byte[] flow \u003d Separator.encode(rowKey.getFlowName(),\n-        Separator.SPACE, Separator.TAB, Separator.QUALIFIERS);\n-    byte[] first \u003d Separator.QUALIFIERS.join(user, cluster, flow);\n-    // Note that flowRunId is a long, so we can\u0027t encode them all at the same\n-    // time.\n-    byte[] second \u003d Bytes.toBytes(TimelineStorageUtils.invertLong(\n-        rowKey.getFlowRunId()));\n-    byte[] third \u003d AppIdKeyConverter.getInstance().encode(rowKey.getAppId());\n-    if (rowKey.getEntityType() \u003d\u003d null) {\n-      return Separator.QUALIFIERS.join(\n-          first, second, third, Separator.EMPTY_BYTES);\n-    }\n-    byte[] entityType \u003d Separator.encode(rowKey.getEntityType(),\n-        Separator.SPACE, Separator.TAB, Separator.QUALIFIERS);\n-    byte[] entityId \u003d rowKey.getEntityId() \u003d\u003d null ? Separator.EMPTY_BYTES :\n-        Separator.encode(rowKey.getEntityId(), Separator.SPACE, Separator.TAB,\n-        Separator.QUALIFIERS);\n-    byte[] fourth \u003d Separator.QUALIFIERS.join(entityType, entityId);\n-    return Separator.QUALIFIERS.join(first, second, third, fourth);\n-  }\n\\ No newline at end of file\n+    public byte[] encode(EntityRowKey rowKey) {\n+      byte[] user \u003d\n+          Separator.encode(rowKey.getUserId(), Separator.SPACE, Separator.TAB,\n+              Separator.QUALIFIERS);\n+      byte[] cluster \u003d\n+          Separator.encode(rowKey.getClusterId(), Separator.SPACE,\n+              Separator.TAB, Separator.QUALIFIERS);\n+      byte[] flow \u003d\n+          Separator.encode(rowKey.getFlowName(), Separator.SPACE,\n+              Separator.TAB, Separator.QUALIFIERS);\n+      byte[] first \u003d Separator.QUALIFIERS.join(user, cluster, flow);\n+      // Note that flowRunId is a long, so we can\u0027t encode them all at the same\n+      // time.\n+      byte[] second \u003d\n+          Bytes.toBytes(LongConverter.invertLong(rowKey.getFlowRunId()));\n+      byte[] third \u003d appIDKeyConverter.encode(rowKey.getAppId());\n+      if (rowKey.getEntityType() \u003d\u003d null) {\n+        return Separator.QUALIFIERS.join(first, second, third,\n+            Separator.EMPTY_BYTES);\n+      }\n+      byte[] entityType \u003d\n+          Separator.encode(rowKey.getEntityType(), Separator.SPACE,\n+              Separator.TAB, Separator.QUALIFIERS);\n+      byte[] entityId \u003d\n+          rowKey.getEntityId() \u003d\u003d null ? Separator.EMPTY_BYTES : Separator\n+              .encode(rowKey.getEntityId(), Separator.SPACE, Separator.TAB,\n+                  Separator.QUALIFIERS);\n+      byte[] fourth \u003d Separator.QUALIFIERS.join(entityType, entityId);\n+      return Separator.QUALIFIERS.join(first, second, third, fourth);\n+    }\n\\ No newline at end of file\n",
          "actualSource": "    public byte[] encode(EntityRowKey rowKey) {\n      byte[] user \u003d\n          Separator.encode(rowKey.getUserId(), Separator.SPACE, Separator.TAB,\n              Separator.QUALIFIERS);\n      byte[] cluster \u003d\n          Separator.encode(rowKey.getClusterId(), Separator.SPACE,\n              Separator.TAB, Separator.QUALIFIERS);\n      byte[] flow \u003d\n          Separator.encode(rowKey.getFlowName(), Separator.SPACE,\n              Separator.TAB, Separator.QUALIFIERS);\n      byte[] first \u003d Separator.QUALIFIERS.join(user, cluster, flow);\n      // Note that flowRunId is a long, so we can\u0027t encode them all at the same\n      // time.\n      byte[] second \u003d\n          Bytes.toBytes(LongConverter.invertLong(rowKey.getFlowRunId()));\n      byte[] third \u003d appIDKeyConverter.encode(rowKey.getAppId());\n      if (rowKey.getEntityType() \u003d\u003d null) {\n        return Separator.QUALIFIERS.join(first, second, third,\n            Separator.EMPTY_BYTES);\n      }\n      byte[] entityType \u003d\n          Separator.encode(rowKey.getEntityType(), Separator.SPACE,\n              Separator.TAB, Separator.QUALIFIERS);\n      byte[] entityId \u003d\n          rowKey.getEntityId() \u003d\u003d null ? Separator.EMPTY_BYTES : Separator\n              .encode(rowKey.getEntityId(), Separator.SPACE, Separator.TAB,\n                  Separator.QUALIFIERS);\n      byte[] fourth \u003d Separator.QUALIFIERS.join(entityType, entityId);\n      return Separator.QUALIFIERS.join(first, second, third, fourth);\n    }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/entity/EntityRowKey.java",
          "extendedDetails": {}
        }
      ]
    },
    "7b8cfa5c2ff62005c8b78867fedd64b48e50383d": {
      "type": "Yintroduced",
      "commitMessage": "YARN-5109. timestamps are stored unencoded causing parse errors (Varun Saxena via sjlee)\n",
      "commitDate": "10/07/16 8:46 AM",
      "commitName": "7b8cfa5c2ff62005c8b78867fedd64b48e50383d",
      "commitAuthor": "Sangjin Lee",
      "diff": "@@ -0,0 +1,25 @@\n+  public byte[] encode(EntityRowKey rowKey) {\n+    byte[] user \u003d Separator.encode(rowKey.getUserId(),\n+        Separator.SPACE, Separator.TAB, Separator.QUALIFIERS);\n+    byte[] cluster \u003d Separator.encode(rowKey.getClusterId(),\n+        Separator.SPACE, Separator.TAB, Separator.QUALIFIERS);\n+    byte[] flow \u003d Separator.encode(rowKey.getFlowName(),\n+        Separator.SPACE, Separator.TAB, Separator.QUALIFIERS);\n+    byte[] first \u003d Separator.QUALIFIERS.join(user, cluster, flow);\n+    // Note that flowRunId is a long, so we can\u0027t encode them all at the same\n+    // time.\n+    byte[] second \u003d Bytes.toBytes(TimelineStorageUtils.invertLong(\n+        rowKey.getFlowRunId()));\n+    byte[] third \u003d AppIdKeyConverter.getInstance().encode(rowKey.getAppId());\n+    if (rowKey.getEntityType() \u003d\u003d null) {\n+      return Separator.QUALIFIERS.join(\n+          first, second, third, Separator.EMPTY_BYTES);\n+    }\n+    byte[] entityType \u003d Separator.encode(rowKey.getEntityType(),\n+        Separator.SPACE, Separator.TAB, Separator.QUALIFIERS);\n+    byte[] entityId \u003d rowKey.getEntityId() \u003d\u003d null ? Separator.EMPTY_BYTES :\n+        Separator.encode(rowKey.getEntityId(), Separator.SPACE, Separator.TAB,\n+        Separator.QUALIFIERS);\n+    byte[] fourth \u003d Separator.QUALIFIERS.join(entityType, entityId);\n+    return Separator.QUALIFIERS.join(first, second, third, fourth);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public byte[] encode(EntityRowKey rowKey) {\n    byte[] user \u003d Separator.encode(rowKey.getUserId(),\n        Separator.SPACE, Separator.TAB, Separator.QUALIFIERS);\n    byte[] cluster \u003d Separator.encode(rowKey.getClusterId(),\n        Separator.SPACE, Separator.TAB, Separator.QUALIFIERS);\n    byte[] flow \u003d Separator.encode(rowKey.getFlowName(),\n        Separator.SPACE, Separator.TAB, Separator.QUALIFIERS);\n    byte[] first \u003d Separator.QUALIFIERS.join(user, cluster, flow);\n    // Note that flowRunId is a long, so we can\u0027t encode them all at the same\n    // time.\n    byte[] second \u003d Bytes.toBytes(TimelineStorageUtils.invertLong(\n        rowKey.getFlowRunId()));\n    byte[] third \u003d AppIdKeyConverter.getInstance().encode(rowKey.getAppId());\n    if (rowKey.getEntityType() \u003d\u003d null) {\n      return Separator.QUALIFIERS.join(\n          first, second, third, Separator.EMPTY_BYTES);\n    }\n    byte[] entityType \u003d Separator.encode(rowKey.getEntityType(),\n        Separator.SPACE, Separator.TAB, Separator.QUALIFIERS);\n    byte[] entityId \u003d rowKey.getEntityId() \u003d\u003d null ? Separator.EMPTY_BYTES :\n        Separator.encode(rowKey.getEntityId(), Separator.SPACE, Separator.TAB,\n        Separator.QUALIFIERS);\n    byte[] fourth \u003d Separator.QUALIFIERS.join(entityType, entityId);\n    return Separator.QUALIFIERS.join(first, second, third, fourth);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/entity/EntityRowKeyConverter.java"
    }
  }
}