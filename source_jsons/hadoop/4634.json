{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ClientNamenodeProtocolServerSideTranslatorPB.java",
  "functionName": "updatePipeline",
  "functionId": "updatePipeline___controller-RpcController__req-UpdatePipelineRequestProto",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.java",
  "functionStartLine": 1182,
  "functionEndLine": 1196,
  "numCommitsSeen": 141,
  "timeTaken": 3563,
  "changeHistory": [
    "06022b8fdc40e50eaac63758246353058e8cfa6d",
    "e2c9b288b223b9fd82dc12018936e13128413492",
    "3f070e83b1f4e0211ece8c0ab508a61188ad352a",
    "d8dfcdcbc2e2df3aa1d7b309f263434739475e7e",
    "48da033901d3471ef176a94104158546152353e9"
  ],
  "changeHistoryShort": {
    "06022b8fdc40e50eaac63758246353058e8cfa6d": "Ybodychange",
    "e2c9b288b223b9fd82dc12018936e13128413492": "Ybodychange",
    "3f070e83b1f4e0211ece8c0ab508a61188ad352a": "Ybodychange",
    "d8dfcdcbc2e2df3aa1d7b309f263434739475e7e": "Ybodychange",
    "48da033901d3471ef176a94104158546152353e9": "Yintroduced"
  },
  "changeHistoryDetails": {
    "06022b8fdc40e50eaac63758246353058e8cfa6d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9111. Move hdfs-client protobuf convert methods from PBHelper to PBHelperClient. Contributed by Mingliang Liu.\n",
      "commitDate": "21/09/15 6:53 PM",
      "commitName": "06022b8fdc40e50eaac63758246353058e8cfa6d",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "28/08/15 2:38 PM",
      "commitNameOld": "e2c9b288b223b9fd82dc12018936e13128413492",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 24.18,
      "commitsBetweenForRepo": 143,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,15 +1,15 @@\n   public UpdatePipelineResponseProto updatePipeline(RpcController controller,\n       UpdatePipelineRequestProto req) throws ServiceException {\n     try {\n       List\u003cDatanodeIDProto\u003e newNodes \u003d req.getNewNodesList();\n       List\u003cString\u003e newStorageIDs \u003d req.getStorageIDsList();\n       server.updatePipeline(req.getClientName(),\n           PBHelperClient.convert(req.getOldBlock()),\n           PBHelperClient.convert(req.getNewBlock()),\n-          PBHelper.convert(newNodes.toArray(new DatanodeIDProto[newNodes.size()])),\n+          PBHelperClient.convert(newNodes.toArray(new DatanodeIDProto[newNodes.size()])),\n           newStorageIDs.toArray(new String[newStorageIDs.size()]));\n       return VOID_UPDATEPIPELINE_RESPONSE;\n     } catch (IOException e) {\n       throw new ServiceException(e);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public UpdatePipelineResponseProto updatePipeline(RpcController controller,\n      UpdatePipelineRequestProto req) throws ServiceException {\n    try {\n      List\u003cDatanodeIDProto\u003e newNodes \u003d req.getNewNodesList();\n      List\u003cString\u003e newStorageIDs \u003d req.getStorageIDsList();\n      server.updatePipeline(req.getClientName(),\n          PBHelperClient.convert(req.getOldBlock()),\n          PBHelperClient.convert(req.getNewBlock()),\n          PBHelperClient.convert(newNodes.toArray(new DatanodeIDProto[newNodes.size()])),\n          newStorageIDs.toArray(new String[newStorageIDs.size()]));\n      return VOID_UPDATEPIPELINE_RESPONSE;\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.java",
      "extendedDetails": {}
    },
    "e2c9b288b223b9fd82dc12018936e13128413492": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8925. Move BlockReaderLocal to hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "28/08/15 2:38 PM",
      "commitName": "e2c9b288b223b9fd82dc12018936e13128413492",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "22/08/15 1:31 PM",
      "commitNameOld": "490bb5ebd6c6d6f9c08fcad167f976687fc3aa42",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 6.05,
      "commitsBetweenForRepo": 33,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,15 +1,15 @@\n   public UpdatePipelineResponseProto updatePipeline(RpcController controller,\n       UpdatePipelineRequestProto req) throws ServiceException {\n     try {\n       List\u003cDatanodeIDProto\u003e newNodes \u003d req.getNewNodesList();\n       List\u003cString\u003e newStorageIDs \u003d req.getStorageIDsList();\n       server.updatePipeline(req.getClientName(),\n-          PBHelper.convert(req.getOldBlock()),\n-          PBHelper.convert(req.getNewBlock()),\n+          PBHelperClient.convert(req.getOldBlock()),\n+          PBHelperClient.convert(req.getNewBlock()),\n           PBHelper.convert(newNodes.toArray(new DatanodeIDProto[newNodes.size()])),\n           newStorageIDs.toArray(new String[newStorageIDs.size()]));\n       return VOID_UPDATEPIPELINE_RESPONSE;\n     } catch (IOException e) {\n       throw new ServiceException(e);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public UpdatePipelineResponseProto updatePipeline(RpcController controller,\n      UpdatePipelineRequestProto req) throws ServiceException {\n    try {\n      List\u003cDatanodeIDProto\u003e newNodes \u003d req.getNewNodesList();\n      List\u003cString\u003e newStorageIDs \u003d req.getStorageIDsList();\n      server.updatePipeline(req.getClientName(),\n          PBHelperClient.convert(req.getOldBlock()),\n          PBHelperClient.convert(req.getNewBlock()),\n          PBHelper.convert(newNodes.toArray(new DatanodeIDProto[newNodes.size()])),\n          newStorageIDs.toArray(new String[newStorageIDs.size()]));\n      return VOID_UPDATEPIPELINE_RESPONSE;\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.java",
      "extendedDetails": {}
    },
    "3f070e83b1f4e0211ece8c0ab508a61188ad352a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5009. Include storage information in the LocatedBlock.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2832@1519691 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "03/09/13 7:03 AM",
      "commitName": "3f070e83b1f4e0211ece8c0ab508a61188ad352a",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "26/07/13 12:21 PM",
      "commitNameOld": "07b076917e557b1ab8c5175618e49e7e308411b8",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 38.78,
      "commitsBetweenForRepo": 197,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,15 @@\n   public UpdatePipelineResponseProto updatePipeline(RpcController controller,\n       UpdatePipelineRequestProto req) throws ServiceException {\n     try {\n       List\u003cDatanodeIDProto\u003e newNodes \u003d req.getNewNodesList();\n-      server\n-          .updatePipeline(req.getClientName(), PBHelper.convert(req\n-              .getOldBlock()), PBHelper.convert(req.getNewBlock()), PBHelper\n-              .convert(newNodes.toArray(new DatanodeIDProto[newNodes.size()])));\n+      List\u003cString\u003e newStorageIDs \u003d req.getStorageIDsList();\n+      server.updatePipeline(req.getClientName(),\n+          PBHelper.convert(req.getOldBlock()),\n+          PBHelper.convert(req.getNewBlock()),\n+          PBHelper.convert(newNodes.toArray(new DatanodeIDProto[newNodes.size()])),\n+          newStorageIDs.toArray(new String[newStorageIDs.size()]));\n       return VOID_UPDATEPIPELINE_RESPONSE;\n     } catch (IOException e) {\n       throw new ServiceException(e);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public UpdatePipelineResponseProto updatePipeline(RpcController controller,\n      UpdatePipelineRequestProto req) throws ServiceException {\n    try {\n      List\u003cDatanodeIDProto\u003e newNodes \u003d req.getNewNodesList();\n      List\u003cString\u003e newStorageIDs \u003d req.getStorageIDsList();\n      server.updatePipeline(req.getClientName(),\n          PBHelper.convert(req.getOldBlock()),\n          PBHelper.convert(req.getNewBlock()),\n          PBHelper.convert(newNodes.toArray(new DatanodeIDProto[newNodes.size()])),\n          newStorageIDs.toArray(new String[newStorageIDs.size()]));\n      return VOID_UPDATEPIPELINE_RESPONSE;\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.java",
      "extendedDetails": {}
    },
    "d8dfcdcbc2e2df3aa1d7b309f263434739475e7e": {
      "type": "Ybodychange",
      "commitMessage": "    HDFS-2669 Enable protobuf rpc for ClientNamenodeProtocol\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1214128 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/12/11 1:27 AM",
      "commitName": "d8dfcdcbc2e2df3aa1d7b309f263434739475e7e",
      "commitAuthor": "Sanjay Radia",
      "commitDateOld": "13/12/11 3:31 PM",
      "commitNameOld": "3954a2fb1cbc7a8a0d1ad5859e7f5c9415530f4c",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 0.41,
      "commitsBetweenForRepo": 12,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,13 @@\n   public UpdatePipelineResponseProto updatePipeline(RpcController controller,\n       UpdatePipelineRequestProto req) throws ServiceException {\n     try {\n+      List\u003cDatanodeIDProto\u003e newNodes \u003d req.getNewNodesList();\n       server\n           .updatePipeline(req.getClientName(), PBHelper.convert(req\n               .getOldBlock()), PBHelper.convert(req.getNewBlock()), PBHelper\n-              .convert((DatanodeIDProto[]) req.getNewNodesList().toArray()));\n+              .convert(newNodes.toArray(new DatanodeIDProto[newNodes.size()])));\n       return VOID_UPDATEPIPELINE_RESPONSE;\n     } catch (IOException e) {\n       throw new ServiceException(e);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public UpdatePipelineResponseProto updatePipeline(RpcController controller,\n      UpdatePipelineRequestProto req) throws ServiceException {\n    try {\n      List\u003cDatanodeIDProto\u003e newNodes \u003d req.getNewNodesList();\n      server\n          .updatePipeline(req.getClientName(), PBHelper.convert(req\n              .getOldBlock()), PBHelper.convert(req.getNewBlock()), PBHelper\n              .convert(newNodes.toArray(new DatanodeIDProto[newNodes.size()])));\n      return VOID_UPDATEPIPELINE_RESPONSE;\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.java",
      "extendedDetails": {}
    },
    "48da033901d3471ef176a94104158546152353e9": {
      "type": "Yintroduced",
      "commitMessage": "    HDFS-2651 ClientNameNodeProtocol Translators for Protocol Buffers (sanjay)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1213143 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/12/11 9:36 PM",
      "commitName": "48da033901d3471ef176a94104158546152353e9",
      "commitAuthor": "Sanjay Radia",
      "diff": "@@ -0,0 +1,12 @@\n+  public UpdatePipelineResponseProto updatePipeline(RpcController controller,\n+      UpdatePipelineRequestProto req) throws ServiceException {\n+    try {\n+      server\n+          .updatePipeline(req.getClientName(), PBHelper.convert(req\n+              .getOldBlock()), PBHelper.convert(req.getNewBlock()), PBHelper\n+              .convert((DatanodeIDProto[]) req.getNewNodesList().toArray()));\n+      return VOID_UPDATEPIPELINE_RESPONSE;\n+    } catch (IOException e) {\n+      throw new ServiceException(e);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public UpdatePipelineResponseProto updatePipeline(RpcController controller,\n      UpdatePipelineRequestProto req) throws ServiceException {\n    try {\n      server\n          .updatePipeline(req.getClientName(), PBHelper.convert(req\n              .getOldBlock()), PBHelper.convert(req.getNewBlock()), PBHelper\n              .convert((DatanodeIDProto[]) req.getNewNodesList().toArray()));\n      return VOID_UPDATEPIPELINE_RESPONSE;\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.java"
    }
  }
}