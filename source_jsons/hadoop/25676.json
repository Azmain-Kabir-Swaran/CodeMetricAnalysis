{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "JobHistoryEventHandler.java",
  "functionName": "processEventForJobSummary",
  "functionId": "processEventForJobSummary___event-HistoryEvent__summary-JobSummary__jobId-JobId",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
  "functionStartLine": 755,
  "functionEndLine": 828,
  "numCommitsSeen": 70,
  "timeTaken": 8624,
  "changeHistory": [
    "d04f85f387e4a78816bc9966ee2b4a647ee05faf",
    "42f90ab885d9693fcc1e52f9637f7de4111110ae",
    "c271f3cded8636724673882eac3cd2229c157f31",
    "905b17876c44634545a68300ff2f2d73fb86d3b7",
    "2accda38a1e8d658ed1f6da4a583a81a151e17b4",
    "e8645636ce1721aa6dc3674fbc553a7bb3522fbe",
    "fffdf661e30afd10331d2153ff052c141b7ebe4b",
    "13e4562924a6cb3d16c262e0f595b2ffbf9e0546",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517"
  ],
  "changeHistoryShort": {
    "d04f85f387e4a78816bc9966ee2b4a647ee05faf": "Ybodychange",
    "42f90ab885d9693fcc1e52f9637f7de4111110ae": "Ybodychange",
    "c271f3cded8636724673882eac3cd2229c157f31": "Ybodychange",
    "905b17876c44634545a68300ff2f2d73fb86d3b7": "Ybodychange",
    "2accda38a1e8d658ed1f6da4a583a81a151e17b4": "Ybodychange",
    "e8645636ce1721aa6dc3674fbc553a7bb3522fbe": "Ybodychange",
    "fffdf661e30afd10331d2153ff052c141b7ebe4b": "Ymultichange(Ymodifierchange,Ybodychange)",
    "13e4562924a6cb3d16c262e0f595b2ffbf9e0546": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yintroduced"
  },
  "changeHistoryDetails": {
    "d04f85f387e4a78816bc9966ee2b4a647ee05faf": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6892. Issues with the count of failed/killed tasks in the jhist file. (Peter Bacsko via Haibo Chen)\n",
      "commitDate": "30/08/17 10:07 AM",
      "commitName": "d04f85f387e4a78816bc9966ee2b4a647ee05faf",
      "commitAuthor": "Haibo Chen",
      "commitDateOld": "29/08/17 10:59 PM",
      "commitNameOld": "684de1a9025261dcb6ab3b5ec9ba69738c947ecc",
      "commitAuthorOld": "Sangjin Lee",
      "daysBetweenCommits": 0.46,
      "commitsBetweenForRepo": 38,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,62 +1,74 @@\n   public void processEventForJobSummary(HistoryEvent event, JobSummary summary, \n       JobId jobId) {\n     // context.getJob could be used for some of this info as well.\n     switch (event.getEventType()) {\n     case JOB_SUBMITTED:\n       JobSubmittedEvent jse \u003d (JobSubmittedEvent) event;\n       summary.setUser(jse.getUserName());\n       summary.setQueue(jse.getJobQueueName());\n       summary.setJobSubmitTime(jse.getSubmitTime());\n       summary.setJobName(jse.getJobName());\n       break;\n     case NORMALIZED_RESOURCE:\n       NormalizedResourceEvent normalizedResourceEvent \u003d \n             (NormalizedResourceEvent) event;\n       if (normalizedResourceEvent.getTaskType() \u003d\u003d TaskType.MAP) {\n         summary.setResourcesPerMap((int) normalizedResourceEvent.getMemory());\n       } else if (normalizedResourceEvent.getTaskType() \u003d\u003d TaskType.REDUCE) {\n         summary.setResourcesPerReduce((int) normalizedResourceEvent.getMemory());\n       }\n       break;  \n     case JOB_INITED:\n       JobInitedEvent jie \u003d (JobInitedEvent) event;\n       summary.setJobLaunchTime(jie.getLaunchTime());\n       break;\n     case MAP_ATTEMPT_STARTED:\n       TaskAttemptStartedEvent mtase \u003d (TaskAttemptStartedEvent) event;\n       if (summary.getFirstMapTaskLaunchTime() \u003d\u003d 0)\n         summary.setFirstMapTaskLaunchTime(mtase.getStartTime());\n       break;\n     case REDUCE_ATTEMPT_STARTED:\n       TaskAttemptStartedEvent rtase \u003d (TaskAttemptStartedEvent) event;\n       if (summary.getFirstReduceTaskLaunchTime() \u003d\u003d 0)\n         summary.setFirstReduceTaskLaunchTime(rtase.getStartTime());\n       break;\n     case JOB_FINISHED:\n       JobFinishedEvent jfe \u003d (JobFinishedEvent) event;\n       summary.setJobFinishTime(jfe.getFinishTime());\n-      summary.setNumFinishedMaps(jfe.getFinishedMaps());\n+      summary.setNumSucceededMaps(jfe.getSucceededMaps());\n       summary.setNumFailedMaps(jfe.getFailedMaps());\n-      summary.setNumFinishedReduces(jfe.getFinishedReduces());\n+      summary.setNumSucceededReduces(jfe.getSucceededReduces());\n       summary.setNumFailedReduces(jfe.getFailedReduces());\n+      summary.setNumKilledMaps(jfe.getKilledMaps());\n+      summary.setNumKilledReduces(jfe.getKilledReduces());\n       if (summary.getJobStatus() \u003d\u003d null)\n         summary\n             .setJobStatus(org.apache.hadoop.mapreduce.JobStatus.State.SUCCEEDED\n                 .toString());\n       // TODO JOB_FINISHED does not have state. Effectively job history does not\n       // have state about the finished job.\n       setSummarySlotSeconds(summary, jfe.getTotalCounters());\n       break;\n     case JOB_FAILED:\n     case JOB_KILLED:\n+      Job job \u003d context.getJob(jobId);\n       JobUnsuccessfulCompletionEvent juce \u003d (JobUnsuccessfulCompletionEvent) event;\n+      int successfulMaps \u003d job.getCompletedMaps() - job.getFailedMaps()\n+          - job.getKilledMaps();\n+      int successfulReduces \u003d job.getCompletedReduces()\n+          - job.getFailedReduces() - job.getKilledReduces();\n+\n       summary.setJobStatus(juce.getStatus());\n-      summary.setNumFinishedMaps(context.getJob(jobId).getTotalMaps());\n-      summary.setNumFinishedReduces(context.getJob(jobId).getTotalReduces());\n+      summary.setNumSucceededMaps(successfulMaps);\n+      summary.setNumSucceededReduces(successfulReduces);\n+      summary.setNumFailedMaps(job.getFailedMaps());\n+      summary.setNumFailedReduces(job.getFailedReduces());\n       summary.setJobFinishTime(juce.getFinishTime());\n+      summary.setNumKilledMaps(juce.getKilledMaps());\n+      summary.setNumKilledReduces(juce.getKilledReduces());\n       setSummarySlotSeconds(summary, context.getJob(jobId).getAllCounters());\n       break;\n     default:\n       break;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void processEventForJobSummary(HistoryEvent event, JobSummary summary, \n      JobId jobId) {\n    // context.getJob could be used for some of this info as well.\n    switch (event.getEventType()) {\n    case JOB_SUBMITTED:\n      JobSubmittedEvent jse \u003d (JobSubmittedEvent) event;\n      summary.setUser(jse.getUserName());\n      summary.setQueue(jse.getJobQueueName());\n      summary.setJobSubmitTime(jse.getSubmitTime());\n      summary.setJobName(jse.getJobName());\n      break;\n    case NORMALIZED_RESOURCE:\n      NormalizedResourceEvent normalizedResourceEvent \u003d \n            (NormalizedResourceEvent) event;\n      if (normalizedResourceEvent.getTaskType() \u003d\u003d TaskType.MAP) {\n        summary.setResourcesPerMap((int) normalizedResourceEvent.getMemory());\n      } else if (normalizedResourceEvent.getTaskType() \u003d\u003d TaskType.REDUCE) {\n        summary.setResourcesPerReduce((int) normalizedResourceEvent.getMemory());\n      }\n      break;  \n    case JOB_INITED:\n      JobInitedEvent jie \u003d (JobInitedEvent) event;\n      summary.setJobLaunchTime(jie.getLaunchTime());\n      break;\n    case MAP_ATTEMPT_STARTED:\n      TaskAttemptStartedEvent mtase \u003d (TaskAttemptStartedEvent) event;\n      if (summary.getFirstMapTaskLaunchTime() \u003d\u003d 0)\n        summary.setFirstMapTaskLaunchTime(mtase.getStartTime());\n      break;\n    case REDUCE_ATTEMPT_STARTED:\n      TaskAttemptStartedEvent rtase \u003d (TaskAttemptStartedEvent) event;\n      if (summary.getFirstReduceTaskLaunchTime() \u003d\u003d 0)\n        summary.setFirstReduceTaskLaunchTime(rtase.getStartTime());\n      break;\n    case JOB_FINISHED:\n      JobFinishedEvent jfe \u003d (JobFinishedEvent) event;\n      summary.setJobFinishTime(jfe.getFinishTime());\n      summary.setNumSucceededMaps(jfe.getSucceededMaps());\n      summary.setNumFailedMaps(jfe.getFailedMaps());\n      summary.setNumSucceededReduces(jfe.getSucceededReduces());\n      summary.setNumFailedReduces(jfe.getFailedReduces());\n      summary.setNumKilledMaps(jfe.getKilledMaps());\n      summary.setNumKilledReduces(jfe.getKilledReduces());\n      if (summary.getJobStatus() \u003d\u003d null)\n        summary\n            .setJobStatus(org.apache.hadoop.mapreduce.JobStatus.State.SUCCEEDED\n                .toString());\n      // TODO JOB_FINISHED does not have state. Effectively job history does not\n      // have state about the finished job.\n      setSummarySlotSeconds(summary, jfe.getTotalCounters());\n      break;\n    case JOB_FAILED:\n    case JOB_KILLED:\n      Job job \u003d context.getJob(jobId);\n      JobUnsuccessfulCompletionEvent juce \u003d (JobUnsuccessfulCompletionEvent) event;\n      int successfulMaps \u003d job.getCompletedMaps() - job.getFailedMaps()\n          - job.getKilledMaps();\n      int successfulReduces \u003d job.getCompletedReduces()\n          - job.getFailedReduces() - job.getKilledReduces();\n\n      summary.setJobStatus(juce.getStatus());\n      summary.setNumSucceededMaps(successfulMaps);\n      summary.setNumSucceededReduces(successfulReduces);\n      summary.setNumFailedMaps(job.getFailedMaps());\n      summary.setNumFailedReduces(job.getFailedReduces());\n      summary.setJobFinishTime(juce.getFinishTime());\n      summary.setNumKilledMaps(juce.getKilledMaps());\n      summary.setNumKilledReduces(juce.getKilledReduces());\n      setSummarySlotSeconds(summary, context.getJob(jobId).getAllCounters());\n      break;\n    default:\n      break;\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
      "extendedDetails": {}
    },
    "42f90ab885d9693fcc1e52f9637f7de4111110ae": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4844. Add getMemorySize/getVirtualCoresSize to o.a.h.y.api.records.Resource. Contributed by Wangda Tan.\n",
      "commitDate": "29/05/16 8:54 AM",
      "commitName": "42f90ab885d9693fcc1e52f9637f7de4111110ae",
      "commitAuthor": "Varun Vasudev",
      "commitDateOld": "16/04/16 7:39 PM",
      "commitNameOld": "e6c0742012ffeacad2bcaf712d86a7e5d1420b26",
      "commitAuthorOld": "Xuan",
      "daysBetweenCommits": 42.55,
      "commitsBetweenForRepo": 282,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,62 +1,62 @@\n   public void processEventForJobSummary(HistoryEvent event, JobSummary summary, \n       JobId jobId) {\n     // context.getJob could be used for some of this info as well.\n     switch (event.getEventType()) {\n     case JOB_SUBMITTED:\n       JobSubmittedEvent jse \u003d (JobSubmittedEvent) event;\n       summary.setUser(jse.getUserName());\n       summary.setQueue(jse.getJobQueueName());\n       summary.setJobSubmitTime(jse.getSubmitTime());\n       summary.setJobName(jse.getJobName());\n       break;\n     case NORMALIZED_RESOURCE:\n       NormalizedResourceEvent normalizedResourceEvent \u003d \n             (NormalizedResourceEvent) event;\n       if (normalizedResourceEvent.getTaskType() \u003d\u003d TaskType.MAP) {\n-        summary.setResourcesPerMap(normalizedResourceEvent.getMemory());\n+        summary.setResourcesPerMap((int) normalizedResourceEvent.getMemory());\n       } else if (normalizedResourceEvent.getTaskType() \u003d\u003d TaskType.REDUCE) {\n-        summary.setResourcesPerReduce(normalizedResourceEvent.getMemory());\n+        summary.setResourcesPerReduce((int) normalizedResourceEvent.getMemory());\n       }\n       break;  \n     case JOB_INITED:\n       JobInitedEvent jie \u003d (JobInitedEvent) event;\n       summary.setJobLaunchTime(jie.getLaunchTime());\n       break;\n     case MAP_ATTEMPT_STARTED:\n       TaskAttemptStartedEvent mtase \u003d (TaskAttemptStartedEvent) event;\n       if (summary.getFirstMapTaskLaunchTime() \u003d\u003d 0)\n         summary.setFirstMapTaskLaunchTime(mtase.getStartTime());\n       break;\n     case REDUCE_ATTEMPT_STARTED:\n       TaskAttemptStartedEvent rtase \u003d (TaskAttemptStartedEvent) event;\n       if (summary.getFirstReduceTaskLaunchTime() \u003d\u003d 0)\n         summary.setFirstReduceTaskLaunchTime(rtase.getStartTime());\n       break;\n     case JOB_FINISHED:\n       JobFinishedEvent jfe \u003d (JobFinishedEvent) event;\n       summary.setJobFinishTime(jfe.getFinishTime());\n       summary.setNumFinishedMaps(jfe.getFinishedMaps());\n       summary.setNumFailedMaps(jfe.getFailedMaps());\n       summary.setNumFinishedReduces(jfe.getFinishedReduces());\n       summary.setNumFailedReduces(jfe.getFailedReduces());\n       if (summary.getJobStatus() \u003d\u003d null)\n         summary\n             .setJobStatus(org.apache.hadoop.mapreduce.JobStatus.State.SUCCEEDED\n                 .toString());\n       // TODO JOB_FINISHED does not have state. Effectively job history does not\n       // have state about the finished job.\n       setSummarySlotSeconds(summary, jfe.getTotalCounters());\n       break;\n     case JOB_FAILED:\n     case JOB_KILLED:\n       JobUnsuccessfulCompletionEvent juce \u003d (JobUnsuccessfulCompletionEvent) event;\n       summary.setJobStatus(juce.getStatus());\n       summary.setNumFinishedMaps(context.getJob(jobId).getTotalMaps());\n       summary.setNumFinishedReduces(context.getJob(jobId).getTotalReduces());\n       summary.setJobFinishTime(juce.getFinishTime());\n       setSummarySlotSeconds(summary, context.getJob(jobId).getAllCounters());\n       break;\n     default:\n       break;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void processEventForJobSummary(HistoryEvent event, JobSummary summary, \n      JobId jobId) {\n    // context.getJob could be used for some of this info as well.\n    switch (event.getEventType()) {\n    case JOB_SUBMITTED:\n      JobSubmittedEvent jse \u003d (JobSubmittedEvent) event;\n      summary.setUser(jse.getUserName());\n      summary.setQueue(jse.getJobQueueName());\n      summary.setJobSubmitTime(jse.getSubmitTime());\n      summary.setJobName(jse.getJobName());\n      break;\n    case NORMALIZED_RESOURCE:\n      NormalizedResourceEvent normalizedResourceEvent \u003d \n            (NormalizedResourceEvent) event;\n      if (normalizedResourceEvent.getTaskType() \u003d\u003d TaskType.MAP) {\n        summary.setResourcesPerMap((int) normalizedResourceEvent.getMemory());\n      } else if (normalizedResourceEvent.getTaskType() \u003d\u003d TaskType.REDUCE) {\n        summary.setResourcesPerReduce((int) normalizedResourceEvent.getMemory());\n      }\n      break;  \n    case JOB_INITED:\n      JobInitedEvent jie \u003d (JobInitedEvent) event;\n      summary.setJobLaunchTime(jie.getLaunchTime());\n      break;\n    case MAP_ATTEMPT_STARTED:\n      TaskAttemptStartedEvent mtase \u003d (TaskAttemptStartedEvent) event;\n      if (summary.getFirstMapTaskLaunchTime() \u003d\u003d 0)\n        summary.setFirstMapTaskLaunchTime(mtase.getStartTime());\n      break;\n    case REDUCE_ATTEMPT_STARTED:\n      TaskAttemptStartedEvent rtase \u003d (TaskAttemptStartedEvent) event;\n      if (summary.getFirstReduceTaskLaunchTime() \u003d\u003d 0)\n        summary.setFirstReduceTaskLaunchTime(rtase.getStartTime());\n      break;\n    case JOB_FINISHED:\n      JobFinishedEvent jfe \u003d (JobFinishedEvent) event;\n      summary.setJobFinishTime(jfe.getFinishTime());\n      summary.setNumFinishedMaps(jfe.getFinishedMaps());\n      summary.setNumFailedMaps(jfe.getFailedMaps());\n      summary.setNumFinishedReduces(jfe.getFinishedReduces());\n      summary.setNumFailedReduces(jfe.getFailedReduces());\n      if (summary.getJobStatus() \u003d\u003d null)\n        summary\n            .setJobStatus(org.apache.hadoop.mapreduce.JobStatus.State.SUCCEEDED\n                .toString());\n      // TODO JOB_FINISHED does not have state. Effectively job history does not\n      // have state about the finished job.\n      setSummarySlotSeconds(summary, jfe.getTotalCounters());\n      break;\n    case JOB_FAILED:\n    case JOB_KILLED:\n      JobUnsuccessfulCompletionEvent juce \u003d (JobUnsuccessfulCompletionEvent) event;\n      summary.setJobStatus(juce.getStatus());\n      summary.setNumFinishedMaps(context.getJob(jobId).getTotalMaps());\n      summary.setNumFinishedReduces(context.getJob(jobId).getTotalReduces());\n      summary.setJobFinishTime(juce.getFinishTime());\n      setSummarySlotSeconds(summary, context.getJob(jobId).getAllCounters());\n      break;\n    default:\n      break;\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
      "extendedDetails": {}
    },
    "c271f3cded8636724673882eac3cd2229c157f31": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4723 amendment. Fix JobHistory Event handling. (Contributed by Sandy Ryza)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1411292 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/11/12 8:43 AM",
      "commitName": "c271f3cded8636724673882eac3cd2229c157f31",
      "commitAuthor": "Siddharth Seth",
      "commitDateOld": "14/11/12 4:16 PM",
      "commitNameOld": "905b17876c44634545a68300ff2f2d73fb86d3b7",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 4.69,
      "commitsBetweenForRepo": 26,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,62 +1,62 @@\n   public void processEventForJobSummary(HistoryEvent event, JobSummary summary, \n       JobId jobId) {\n     // context.getJob could be used for some of this info as well.\n     switch (event.getEventType()) {\n     case JOB_SUBMITTED:\n       JobSubmittedEvent jse \u003d (JobSubmittedEvent) event;\n       summary.setUser(jse.getUserName());\n       summary.setQueue(jse.getJobQueueName());\n       summary.setJobSubmitTime(jse.getSubmitTime());\n       summary.setJobName(jse.getJobName());\n       break;\n     case NORMALIZED_RESOURCE:\n       NormalizedResourceEvent normalizedResourceEvent \u003d \n             (NormalizedResourceEvent) event;\n       if (normalizedResourceEvent.getTaskType() \u003d\u003d TaskType.MAP) {\n         summary.setResourcesPerMap(normalizedResourceEvent.getMemory());\n       } else if (normalizedResourceEvent.getTaskType() \u003d\u003d TaskType.REDUCE) {\n         summary.setResourcesPerReduce(normalizedResourceEvent.getMemory());\n       }\n       break;  \n     case JOB_INITED:\n       JobInitedEvent jie \u003d (JobInitedEvent) event;\n       summary.setJobLaunchTime(jie.getLaunchTime());\n       break;\n     case MAP_ATTEMPT_STARTED:\n       TaskAttemptStartedEvent mtase \u003d (TaskAttemptStartedEvent) event;\n       if (summary.getFirstMapTaskLaunchTime() \u003d\u003d 0)\n         summary.setFirstMapTaskLaunchTime(mtase.getStartTime());\n       break;\n     case REDUCE_ATTEMPT_STARTED:\n       TaskAttemptStartedEvent rtase \u003d (TaskAttemptStartedEvent) event;\n       if (summary.getFirstReduceTaskLaunchTime() \u003d\u003d 0)\n         summary.setFirstReduceTaskLaunchTime(rtase.getStartTime());\n       break;\n     case JOB_FINISHED:\n       JobFinishedEvent jfe \u003d (JobFinishedEvent) event;\n       summary.setJobFinishTime(jfe.getFinishTime());\n       summary.setNumFinishedMaps(jfe.getFinishedMaps());\n       summary.setNumFailedMaps(jfe.getFailedMaps());\n       summary.setNumFinishedReduces(jfe.getFinishedReduces());\n       summary.setNumFailedReduces(jfe.getFailedReduces());\n       if (summary.getJobStatus() \u003d\u003d null)\n         summary\n             .setJobStatus(org.apache.hadoop.mapreduce.JobStatus.State.SUCCEEDED\n                 .toString());\n       // TODO JOB_FINISHED does not have state. Effectively job history does not\n       // have state about the finished job.\n       setSummarySlotSeconds(summary, jfe.getTotalCounters());\n       break;\n     case JOB_FAILED:\n     case JOB_KILLED:\n       JobUnsuccessfulCompletionEvent juce \u003d (JobUnsuccessfulCompletionEvent) event;\n       summary.setJobStatus(juce.getStatus());\n       summary.setNumFinishedMaps(context.getJob(jobId).getTotalMaps());\n       summary.setNumFinishedReduces(context.getJob(jobId).getTotalReduces());\n       summary.setJobFinishTime(juce.getFinishTime());\n       setSummarySlotSeconds(summary, context.getJob(jobId).getAllCounters());\n       break;\n     default:\n-      throw new YarnException(\"Invalid event type\");\n+      break;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void processEventForJobSummary(HistoryEvent event, JobSummary summary, \n      JobId jobId) {\n    // context.getJob could be used for some of this info as well.\n    switch (event.getEventType()) {\n    case JOB_SUBMITTED:\n      JobSubmittedEvent jse \u003d (JobSubmittedEvent) event;\n      summary.setUser(jse.getUserName());\n      summary.setQueue(jse.getJobQueueName());\n      summary.setJobSubmitTime(jse.getSubmitTime());\n      summary.setJobName(jse.getJobName());\n      break;\n    case NORMALIZED_RESOURCE:\n      NormalizedResourceEvent normalizedResourceEvent \u003d \n            (NormalizedResourceEvent) event;\n      if (normalizedResourceEvent.getTaskType() \u003d\u003d TaskType.MAP) {\n        summary.setResourcesPerMap(normalizedResourceEvent.getMemory());\n      } else if (normalizedResourceEvent.getTaskType() \u003d\u003d TaskType.REDUCE) {\n        summary.setResourcesPerReduce(normalizedResourceEvent.getMemory());\n      }\n      break;  \n    case JOB_INITED:\n      JobInitedEvent jie \u003d (JobInitedEvent) event;\n      summary.setJobLaunchTime(jie.getLaunchTime());\n      break;\n    case MAP_ATTEMPT_STARTED:\n      TaskAttemptStartedEvent mtase \u003d (TaskAttemptStartedEvent) event;\n      if (summary.getFirstMapTaskLaunchTime() \u003d\u003d 0)\n        summary.setFirstMapTaskLaunchTime(mtase.getStartTime());\n      break;\n    case REDUCE_ATTEMPT_STARTED:\n      TaskAttemptStartedEvent rtase \u003d (TaskAttemptStartedEvent) event;\n      if (summary.getFirstReduceTaskLaunchTime() \u003d\u003d 0)\n        summary.setFirstReduceTaskLaunchTime(rtase.getStartTime());\n      break;\n    case JOB_FINISHED:\n      JobFinishedEvent jfe \u003d (JobFinishedEvent) event;\n      summary.setJobFinishTime(jfe.getFinishTime());\n      summary.setNumFinishedMaps(jfe.getFinishedMaps());\n      summary.setNumFailedMaps(jfe.getFailedMaps());\n      summary.setNumFinishedReduces(jfe.getFinishedReduces());\n      summary.setNumFailedReduces(jfe.getFailedReduces());\n      if (summary.getJobStatus() \u003d\u003d null)\n        summary\n            .setJobStatus(org.apache.hadoop.mapreduce.JobStatus.State.SUCCEEDED\n                .toString());\n      // TODO JOB_FINISHED does not have state. Effectively job history does not\n      // have state about the finished job.\n      setSummarySlotSeconds(summary, jfe.getTotalCounters());\n      break;\n    case JOB_FAILED:\n    case JOB_KILLED:\n      JobUnsuccessfulCompletionEvent juce \u003d (JobUnsuccessfulCompletionEvent) event;\n      summary.setJobStatus(juce.getStatus());\n      summary.setNumFinishedMaps(context.getJob(jobId).getTotalMaps());\n      summary.setNumFinishedReduces(context.getJob(jobId).getTotalReduces());\n      summary.setJobFinishTime(juce.getFinishTime());\n      setSummarySlotSeconds(summary, context.getJob(jobId).getAllCounters());\n      break;\n    default:\n      break;\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
      "extendedDetails": {}
    },
    "905b17876c44634545a68300ff2f2d73fb86d3b7": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4723. Fix warnings found by findbugs 2. Contributed by Sandy Ryza\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1409601 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/11/12 4:16 PM",
      "commitName": "905b17876c44634545a68300ff2f2d73fb86d3b7",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "31/08/12 1:43 PM",
      "commitNameOld": "25e96e455b3473387df865fbc1c3ad7ebf9ff1e4",
      "commitAuthorOld": "Thomas Graves",
      "daysBetweenCommits": 75.15,
      "commitsBetweenForRepo": 446,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,60 +1,62 @@\n   public void processEventForJobSummary(HistoryEvent event, JobSummary summary, \n       JobId jobId) {\n     // context.getJob could be used for some of this info as well.\n     switch (event.getEventType()) {\n     case JOB_SUBMITTED:\n       JobSubmittedEvent jse \u003d (JobSubmittedEvent) event;\n       summary.setUser(jse.getUserName());\n       summary.setQueue(jse.getJobQueueName());\n       summary.setJobSubmitTime(jse.getSubmitTime());\n       summary.setJobName(jse.getJobName());\n       break;\n     case NORMALIZED_RESOURCE:\n       NormalizedResourceEvent normalizedResourceEvent \u003d \n             (NormalizedResourceEvent) event;\n       if (normalizedResourceEvent.getTaskType() \u003d\u003d TaskType.MAP) {\n         summary.setResourcesPerMap(normalizedResourceEvent.getMemory());\n       } else if (normalizedResourceEvent.getTaskType() \u003d\u003d TaskType.REDUCE) {\n         summary.setResourcesPerReduce(normalizedResourceEvent.getMemory());\n       }\n       break;  \n     case JOB_INITED:\n       JobInitedEvent jie \u003d (JobInitedEvent) event;\n       summary.setJobLaunchTime(jie.getLaunchTime());\n       break;\n     case MAP_ATTEMPT_STARTED:\n       TaskAttemptStartedEvent mtase \u003d (TaskAttemptStartedEvent) event;\n       if (summary.getFirstMapTaskLaunchTime() \u003d\u003d 0)\n         summary.setFirstMapTaskLaunchTime(mtase.getStartTime());\n       break;\n     case REDUCE_ATTEMPT_STARTED:\n       TaskAttemptStartedEvent rtase \u003d (TaskAttemptStartedEvent) event;\n       if (summary.getFirstReduceTaskLaunchTime() \u003d\u003d 0)\n         summary.setFirstReduceTaskLaunchTime(rtase.getStartTime());\n       break;\n     case JOB_FINISHED:\n       JobFinishedEvent jfe \u003d (JobFinishedEvent) event;\n       summary.setJobFinishTime(jfe.getFinishTime());\n       summary.setNumFinishedMaps(jfe.getFinishedMaps());\n       summary.setNumFailedMaps(jfe.getFailedMaps());\n       summary.setNumFinishedReduces(jfe.getFinishedReduces());\n       summary.setNumFailedReduces(jfe.getFailedReduces());\n       if (summary.getJobStatus() \u003d\u003d null)\n         summary\n             .setJobStatus(org.apache.hadoop.mapreduce.JobStatus.State.SUCCEEDED\n                 .toString());\n       // TODO JOB_FINISHED does not have state. Effectively job history does not\n       // have state about the finished job.\n       setSummarySlotSeconds(summary, jfe.getTotalCounters());\n       break;\n     case JOB_FAILED:\n     case JOB_KILLED:\n       JobUnsuccessfulCompletionEvent juce \u003d (JobUnsuccessfulCompletionEvent) event;\n       summary.setJobStatus(juce.getStatus());\n       summary.setNumFinishedMaps(context.getJob(jobId).getTotalMaps());\n       summary.setNumFinishedReduces(context.getJob(jobId).getTotalReduces());\n       summary.setJobFinishTime(juce.getFinishTime());\n       setSummarySlotSeconds(summary, context.getJob(jobId).getAllCounters());\n       break;\n+    default:\n+      throw new YarnException(\"Invalid event type\");\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void processEventForJobSummary(HistoryEvent event, JobSummary summary, \n      JobId jobId) {\n    // context.getJob could be used for some of this info as well.\n    switch (event.getEventType()) {\n    case JOB_SUBMITTED:\n      JobSubmittedEvent jse \u003d (JobSubmittedEvent) event;\n      summary.setUser(jse.getUserName());\n      summary.setQueue(jse.getJobQueueName());\n      summary.setJobSubmitTime(jse.getSubmitTime());\n      summary.setJobName(jse.getJobName());\n      break;\n    case NORMALIZED_RESOURCE:\n      NormalizedResourceEvent normalizedResourceEvent \u003d \n            (NormalizedResourceEvent) event;\n      if (normalizedResourceEvent.getTaskType() \u003d\u003d TaskType.MAP) {\n        summary.setResourcesPerMap(normalizedResourceEvent.getMemory());\n      } else if (normalizedResourceEvent.getTaskType() \u003d\u003d TaskType.REDUCE) {\n        summary.setResourcesPerReduce(normalizedResourceEvent.getMemory());\n      }\n      break;  \n    case JOB_INITED:\n      JobInitedEvent jie \u003d (JobInitedEvent) event;\n      summary.setJobLaunchTime(jie.getLaunchTime());\n      break;\n    case MAP_ATTEMPT_STARTED:\n      TaskAttemptStartedEvent mtase \u003d (TaskAttemptStartedEvent) event;\n      if (summary.getFirstMapTaskLaunchTime() \u003d\u003d 0)\n        summary.setFirstMapTaskLaunchTime(mtase.getStartTime());\n      break;\n    case REDUCE_ATTEMPT_STARTED:\n      TaskAttemptStartedEvent rtase \u003d (TaskAttemptStartedEvent) event;\n      if (summary.getFirstReduceTaskLaunchTime() \u003d\u003d 0)\n        summary.setFirstReduceTaskLaunchTime(rtase.getStartTime());\n      break;\n    case JOB_FINISHED:\n      JobFinishedEvent jfe \u003d (JobFinishedEvent) event;\n      summary.setJobFinishTime(jfe.getFinishTime());\n      summary.setNumFinishedMaps(jfe.getFinishedMaps());\n      summary.setNumFailedMaps(jfe.getFailedMaps());\n      summary.setNumFinishedReduces(jfe.getFinishedReduces());\n      summary.setNumFailedReduces(jfe.getFailedReduces());\n      if (summary.getJobStatus() \u003d\u003d null)\n        summary\n            .setJobStatus(org.apache.hadoop.mapreduce.JobStatus.State.SUCCEEDED\n                .toString());\n      // TODO JOB_FINISHED does not have state. Effectively job history does not\n      // have state about the finished job.\n      setSummarySlotSeconds(summary, jfe.getTotalCounters());\n      break;\n    case JOB_FAILED:\n    case JOB_KILLED:\n      JobUnsuccessfulCompletionEvent juce \u003d (JobUnsuccessfulCompletionEvent) event;\n      summary.setJobStatus(juce.getStatus());\n      summary.setNumFinishedMaps(context.getJob(jobId).getTotalMaps());\n      summary.setNumFinishedReduces(context.getJob(jobId).getTotalReduces());\n      summary.setJobFinishTime(juce.getFinishTime());\n      setSummarySlotSeconds(summary, context.getJob(jobId).getAllCounters());\n      break;\n    default:\n      throw new YarnException(\"Invalid event type\");\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
      "extendedDetails": {}
    },
    "2accda38a1e8d658ed1f6da4a583a81a151e17b4": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4017. Add jobname to jobsummary log (tgraves and Koji Noguchi via bobby)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1311972 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/04/12 1:36 PM",
      "commitName": "2accda38a1e8d658ed1f6da4a583a81a151e17b4",
      "commitAuthor": "Robert Joseph Evans",
      "commitDateOld": "06/03/12 3:21 PM",
      "commitNameOld": "c3a4de0ec0389064f5468180d1b9024f64b00f40",
      "commitAuthorOld": "Robert Joseph Evans",
      "daysBetweenCommits": 34.89,
      "commitsBetweenForRepo": 246,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,59 +1,60 @@\n   public void processEventForJobSummary(HistoryEvent event, JobSummary summary, \n       JobId jobId) {\n     // context.getJob could be used for some of this info as well.\n     switch (event.getEventType()) {\n     case JOB_SUBMITTED:\n       JobSubmittedEvent jse \u003d (JobSubmittedEvent) event;\n       summary.setUser(jse.getUserName());\n       summary.setQueue(jse.getJobQueueName());\n       summary.setJobSubmitTime(jse.getSubmitTime());\n+      summary.setJobName(jse.getJobName());\n       break;\n     case NORMALIZED_RESOURCE:\n       NormalizedResourceEvent normalizedResourceEvent \u003d \n             (NormalizedResourceEvent) event;\n       if (normalizedResourceEvent.getTaskType() \u003d\u003d TaskType.MAP) {\n         summary.setResourcesPerMap(normalizedResourceEvent.getMemory());\n       } else if (normalizedResourceEvent.getTaskType() \u003d\u003d TaskType.REDUCE) {\n         summary.setResourcesPerReduce(normalizedResourceEvent.getMemory());\n       }\n       break;  \n     case JOB_INITED:\n       JobInitedEvent jie \u003d (JobInitedEvent) event;\n       summary.setJobLaunchTime(jie.getLaunchTime());\n       break;\n     case MAP_ATTEMPT_STARTED:\n       TaskAttemptStartedEvent mtase \u003d (TaskAttemptStartedEvent) event;\n       if (summary.getFirstMapTaskLaunchTime() \u003d\u003d 0)\n         summary.setFirstMapTaskLaunchTime(mtase.getStartTime());\n       break;\n     case REDUCE_ATTEMPT_STARTED:\n       TaskAttemptStartedEvent rtase \u003d (TaskAttemptStartedEvent) event;\n       if (summary.getFirstReduceTaskLaunchTime() \u003d\u003d 0)\n         summary.setFirstReduceTaskLaunchTime(rtase.getStartTime());\n       break;\n     case JOB_FINISHED:\n       JobFinishedEvent jfe \u003d (JobFinishedEvent) event;\n       summary.setJobFinishTime(jfe.getFinishTime());\n       summary.setNumFinishedMaps(jfe.getFinishedMaps());\n       summary.setNumFailedMaps(jfe.getFailedMaps());\n       summary.setNumFinishedReduces(jfe.getFinishedReduces());\n       summary.setNumFailedReduces(jfe.getFailedReduces());\n       if (summary.getJobStatus() \u003d\u003d null)\n         summary\n             .setJobStatus(org.apache.hadoop.mapreduce.JobStatus.State.SUCCEEDED\n                 .toString());\n       // TODO JOB_FINISHED does not have state. Effectively job history does not\n       // have state about the finished job.\n       setSummarySlotSeconds(summary, jfe.getTotalCounters());\n       break;\n     case JOB_FAILED:\n     case JOB_KILLED:\n       JobUnsuccessfulCompletionEvent juce \u003d (JobUnsuccessfulCompletionEvent) event;\n       summary.setJobStatus(juce.getStatus());\n       summary.setNumFinishedMaps(context.getJob(jobId).getTotalMaps());\n       summary.setNumFinishedReduces(context.getJob(jobId).getTotalReduces());\n       summary.setJobFinishTime(juce.getFinishTime());\n       setSummarySlotSeconds(summary, context.getJob(jobId).getAllCounters());\n       break;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void processEventForJobSummary(HistoryEvent event, JobSummary summary, \n      JobId jobId) {\n    // context.getJob could be used for some of this info as well.\n    switch (event.getEventType()) {\n    case JOB_SUBMITTED:\n      JobSubmittedEvent jse \u003d (JobSubmittedEvent) event;\n      summary.setUser(jse.getUserName());\n      summary.setQueue(jse.getJobQueueName());\n      summary.setJobSubmitTime(jse.getSubmitTime());\n      summary.setJobName(jse.getJobName());\n      break;\n    case NORMALIZED_RESOURCE:\n      NormalizedResourceEvent normalizedResourceEvent \u003d \n            (NormalizedResourceEvent) event;\n      if (normalizedResourceEvent.getTaskType() \u003d\u003d TaskType.MAP) {\n        summary.setResourcesPerMap(normalizedResourceEvent.getMemory());\n      } else if (normalizedResourceEvent.getTaskType() \u003d\u003d TaskType.REDUCE) {\n        summary.setResourcesPerReduce(normalizedResourceEvent.getMemory());\n      }\n      break;  \n    case JOB_INITED:\n      JobInitedEvent jie \u003d (JobInitedEvent) event;\n      summary.setJobLaunchTime(jie.getLaunchTime());\n      break;\n    case MAP_ATTEMPT_STARTED:\n      TaskAttemptStartedEvent mtase \u003d (TaskAttemptStartedEvent) event;\n      if (summary.getFirstMapTaskLaunchTime() \u003d\u003d 0)\n        summary.setFirstMapTaskLaunchTime(mtase.getStartTime());\n      break;\n    case REDUCE_ATTEMPT_STARTED:\n      TaskAttemptStartedEvent rtase \u003d (TaskAttemptStartedEvent) event;\n      if (summary.getFirstReduceTaskLaunchTime() \u003d\u003d 0)\n        summary.setFirstReduceTaskLaunchTime(rtase.getStartTime());\n      break;\n    case JOB_FINISHED:\n      JobFinishedEvent jfe \u003d (JobFinishedEvent) event;\n      summary.setJobFinishTime(jfe.getFinishTime());\n      summary.setNumFinishedMaps(jfe.getFinishedMaps());\n      summary.setNumFailedMaps(jfe.getFailedMaps());\n      summary.setNumFinishedReduces(jfe.getFinishedReduces());\n      summary.setNumFailedReduces(jfe.getFailedReduces());\n      if (summary.getJobStatus() \u003d\u003d null)\n        summary\n            .setJobStatus(org.apache.hadoop.mapreduce.JobStatus.State.SUCCEEDED\n                .toString());\n      // TODO JOB_FINISHED does not have state. Effectively job history does not\n      // have state about the finished job.\n      setSummarySlotSeconds(summary, jfe.getTotalCounters());\n      break;\n    case JOB_FAILED:\n    case JOB_KILLED:\n      JobUnsuccessfulCompletionEvent juce \u003d (JobUnsuccessfulCompletionEvent) event;\n      summary.setJobStatus(juce.getStatus());\n      summary.setNumFinishedMaps(context.getJob(jobId).getTotalMaps());\n      summary.setNumFinishedReduces(context.getJob(jobId).getTotalReduces());\n      summary.setJobFinishTime(juce.getFinishTime());\n      setSummarySlotSeconds(summary, context.getJob(jobId).getAllCounters());\n      break;\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
      "extendedDetails": {}
    },
    "e8645636ce1721aa6dc3674fbc553a7bb3522fbe": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3511. Removed a multitude of cloned/duplicate counters in the AM thereby reducing the AM heap size and preventing full GCs. (vinodkv)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1229347 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/01/12 1:04 PM",
      "commitName": "e8645636ce1721aa6dc3674fbc553a7bb3522fbe",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "07/11/11 11:28 PM",
      "commitNameOld": "9fe9f42c8fad872f7aab5f9bbdac4a860edb0d43",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 62.57,
      "commitsBetweenForRepo": 297,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,59 +1,59 @@\n   public void processEventForJobSummary(HistoryEvent event, JobSummary summary, \n       JobId jobId) {\n     // context.getJob could be used for some of this info as well.\n     switch (event.getEventType()) {\n     case JOB_SUBMITTED:\n       JobSubmittedEvent jse \u003d (JobSubmittedEvent) event;\n       summary.setUser(jse.getUserName());\n       summary.setQueue(jse.getJobQueueName());\n       summary.setJobSubmitTime(jse.getSubmitTime());\n       break;\n     case NORMALIZED_RESOURCE:\n       NormalizedResourceEvent normalizedResourceEvent \u003d \n             (NormalizedResourceEvent) event;\n       if (normalizedResourceEvent.getTaskType() \u003d\u003d TaskType.MAP) {\n         summary.setResourcesPerMap(normalizedResourceEvent.getMemory());\n       } else if (normalizedResourceEvent.getTaskType() \u003d\u003d TaskType.REDUCE) {\n         summary.setResourcesPerReduce(normalizedResourceEvent.getMemory());\n       }\n       break;  \n     case JOB_INITED:\n       JobInitedEvent jie \u003d (JobInitedEvent) event;\n       summary.setJobLaunchTime(jie.getLaunchTime());\n       break;\n     case MAP_ATTEMPT_STARTED:\n       TaskAttemptStartedEvent mtase \u003d (TaskAttemptStartedEvent) event;\n       if (summary.getFirstMapTaskLaunchTime() \u003d\u003d 0)\n         summary.setFirstMapTaskLaunchTime(mtase.getStartTime());\n       break;\n     case REDUCE_ATTEMPT_STARTED:\n       TaskAttemptStartedEvent rtase \u003d (TaskAttemptStartedEvent) event;\n       if (summary.getFirstReduceTaskLaunchTime() \u003d\u003d 0)\n         summary.setFirstReduceTaskLaunchTime(rtase.getStartTime());\n       break;\n     case JOB_FINISHED:\n       JobFinishedEvent jfe \u003d (JobFinishedEvent) event;\n       summary.setJobFinishTime(jfe.getFinishTime());\n       summary.setNumFinishedMaps(jfe.getFinishedMaps());\n       summary.setNumFailedMaps(jfe.getFailedMaps());\n       summary.setNumFinishedReduces(jfe.getFinishedReduces());\n       summary.setNumFailedReduces(jfe.getFailedReduces());\n       if (summary.getJobStatus() \u003d\u003d null)\n         summary\n             .setJobStatus(org.apache.hadoop.mapreduce.JobStatus.State.SUCCEEDED\n                 .toString());\n       // TODO JOB_FINISHED does not have state. Effectively job history does not\n       // have state about the finished job.\n-      setSummarySlotSeconds(summary, jobId);\n+      setSummarySlotSeconds(summary, jfe.getTotalCounters());\n       break;\n     case JOB_FAILED:\n     case JOB_KILLED:\n       JobUnsuccessfulCompletionEvent juce \u003d (JobUnsuccessfulCompletionEvent) event;\n       summary.setJobStatus(juce.getStatus());\n       summary.setNumFinishedMaps(context.getJob(jobId).getTotalMaps());\n       summary.setNumFinishedReduces(context.getJob(jobId).getTotalReduces());\n       summary.setJobFinishTime(juce.getFinishTime());\n-      setSummarySlotSeconds(summary, jobId);\n+      setSummarySlotSeconds(summary, context.getJob(jobId).getAllCounters());\n       break;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void processEventForJobSummary(HistoryEvent event, JobSummary summary, \n      JobId jobId) {\n    // context.getJob could be used for some of this info as well.\n    switch (event.getEventType()) {\n    case JOB_SUBMITTED:\n      JobSubmittedEvent jse \u003d (JobSubmittedEvent) event;\n      summary.setUser(jse.getUserName());\n      summary.setQueue(jse.getJobQueueName());\n      summary.setJobSubmitTime(jse.getSubmitTime());\n      break;\n    case NORMALIZED_RESOURCE:\n      NormalizedResourceEvent normalizedResourceEvent \u003d \n            (NormalizedResourceEvent) event;\n      if (normalizedResourceEvent.getTaskType() \u003d\u003d TaskType.MAP) {\n        summary.setResourcesPerMap(normalizedResourceEvent.getMemory());\n      } else if (normalizedResourceEvent.getTaskType() \u003d\u003d TaskType.REDUCE) {\n        summary.setResourcesPerReduce(normalizedResourceEvent.getMemory());\n      }\n      break;  \n    case JOB_INITED:\n      JobInitedEvent jie \u003d (JobInitedEvent) event;\n      summary.setJobLaunchTime(jie.getLaunchTime());\n      break;\n    case MAP_ATTEMPT_STARTED:\n      TaskAttemptStartedEvent mtase \u003d (TaskAttemptStartedEvent) event;\n      if (summary.getFirstMapTaskLaunchTime() \u003d\u003d 0)\n        summary.setFirstMapTaskLaunchTime(mtase.getStartTime());\n      break;\n    case REDUCE_ATTEMPT_STARTED:\n      TaskAttemptStartedEvent rtase \u003d (TaskAttemptStartedEvent) event;\n      if (summary.getFirstReduceTaskLaunchTime() \u003d\u003d 0)\n        summary.setFirstReduceTaskLaunchTime(rtase.getStartTime());\n      break;\n    case JOB_FINISHED:\n      JobFinishedEvent jfe \u003d (JobFinishedEvent) event;\n      summary.setJobFinishTime(jfe.getFinishTime());\n      summary.setNumFinishedMaps(jfe.getFinishedMaps());\n      summary.setNumFailedMaps(jfe.getFailedMaps());\n      summary.setNumFinishedReduces(jfe.getFinishedReduces());\n      summary.setNumFailedReduces(jfe.getFailedReduces());\n      if (summary.getJobStatus() \u003d\u003d null)\n        summary\n            .setJobStatus(org.apache.hadoop.mapreduce.JobStatus.State.SUCCEEDED\n                .toString());\n      // TODO JOB_FINISHED does not have state. Effectively job history does not\n      // have state about the finished job.\n      setSummarySlotSeconds(summary, jfe.getTotalCounters());\n      break;\n    case JOB_FAILED:\n    case JOB_KILLED:\n      JobUnsuccessfulCompletionEvent juce \u003d (JobUnsuccessfulCompletionEvent) event;\n      summary.setJobStatus(juce.getStatus());\n      summary.setNumFinishedMaps(context.getJob(jobId).getTotalMaps());\n      summary.setNumFinishedReduces(context.getJob(jobId).getTotalReduces());\n      summary.setJobFinishTime(juce.getFinishTime());\n      setSummarySlotSeconds(summary, context.getJob(jobId).getAllCounters());\n      break;\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
      "extendedDetails": {}
    },
    "fffdf661e30afd10331d2153ff052c141b7ebe4b": {
      "type": "Ymultichange(Ymodifierchange,Ybodychange)",
      "commitMessage": "MAPREDUCE-2821. Added missing fields (resourcePerMap \u0026 resourcePerReduce) to JobSummary logs. Contributed by Mahadev Konar.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1188528 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/10/11 11:26 PM",
      "commitName": "fffdf661e30afd10331d2153ff052c141b7ebe4b",
      "commitAuthor": "Arun Murthy",
      "subchanges": [
        {
          "type": "Ymodifierchange",
          "commitMessage": "MAPREDUCE-2821. Added missing fields (resourcePerMap \u0026 resourcePerReduce) to JobSummary logs. Contributed by Mahadev Konar.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1188528 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "24/10/11 11:26 PM",
          "commitName": "fffdf661e30afd10331d2153ff052c141b7ebe4b",
          "commitAuthor": "Arun Murthy",
          "commitDateOld": "18/10/11 10:21 PM",
          "commitNameOld": "13e4562924a6cb3d16c262e0f595b2ffbf9e0546",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 6.05,
          "commitsBetweenForRepo": 52,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,49 +1,59 @@\n-  private void processEventForJobSummary(HistoryEvent event, JobSummary summary, JobId jobId) {\n+  public void processEventForJobSummary(HistoryEvent event, JobSummary summary, \n+      JobId jobId) {\n     // context.getJob could be used for some of this info as well.\n     switch (event.getEventType()) {\n     case JOB_SUBMITTED:\n       JobSubmittedEvent jse \u003d (JobSubmittedEvent) event;\n       summary.setUser(jse.getUserName());\n       summary.setQueue(jse.getJobQueueName());\n       summary.setJobSubmitTime(jse.getSubmitTime());\n       break;\n+    case NORMALIZED_RESOURCE:\n+      NormalizedResourceEvent normalizedResourceEvent \u003d \n+            (NormalizedResourceEvent) event;\n+      if (normalizedResourceEvent.getTaskType() \u003d\u003d TaskType.MAP) {\n+        summary.setResourcesPerMap(normalizedResourceEvent.getMemory());\n+      } else if (normalizedResourceEvent.getTaskType() \u003d\u003d TaskType.REDUCE) {\n+        summary.setResourcesPerReduce(normalizedResourceEvent.getMemory());\n+      }\n+      break;  \n     case JOB_INITED:\n       JobInitedEvent jie \u003d (JobInitedEvent) event;\n       summary.setJobLaunchTime(jie.getLaunchTime());\n       break;\n     case MAP_ATTEMPT_STARTED:\n       TaskAttemptStartedEvent mtase \u003d (TaskAttemptStartedEvent) event;\n       if (summary.getFirstMapTaskLaunchTime() \u003d\u003d 0)\n         summary.setFirstMapTaskLaunchTime(mtase.getStartTime());\n       break;\n     case REDUCE_ATTEMPT_STARTED:\n       TaskAttemptStartedEvent rtase \u003d (TaskAttemptStartedEvent) event;\n       if (summary.getFirstReduceTaskLaunchTime() \u003d\u003d 0)\n         summary.setFirstReduceTaskLaunchTime(rtase.getStartTime());\n       break;\n     case JOB_FINISHED:\n       JobFinishedEvent jfe \u003d (JobFinishedEvent) event;\n       summary.setJobFinishTime(jfe.getFinishTime());\n       summary.setNumFinishedMaps(jfe.getFinishedMaps());\n       summary.setNumFailedMaps(jfe.getFailedMaps());\n       summary.setNumFinishedReduces(jfe.getFinishedReduces());\n       summary.setNumFailedReduces(jfe.getFailedReduces());\n       if (summary.getJobStatus() \u003d\u003d null)\n         summary\n             .setJobStatus(org.apache.hadoop.mapreduce.JobStatus.State.SUCCEEDED\n                 .toString());\n       // TODO JOB_FINISHED does not have state. Effectively job history does not\n       // have state about the finished job.\n       setSummarySlotSeconds(summary, jobId);\n       break;\n     case JOB_FAILED:\n     case JOB_KILLED:\n       JobUnsuccessfulCompletionEvent juce \u003d (JobUnsuccessfulCompletionEvent) event;\n       summary.setJobStatus(juce.getStatus());\n       summary.setNumFinishedMaps(context.getJob(jobId).getTotalMaps());\n       summary.setNumFinishedReduces(context.getJob(jobId).getTotalReduces());\n       summary.setJobFinishTime(juce.getFinishTime());\n       setSummarySlotSeconds(summary, jobId);\n       break;\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void processEventForJobSummary(HistoryEvent event, JobSummary summary, \n      JobId jobId) {\n    // context.getJob could be used for some of this info as well.\n    switch (event.getEventType()) {\n    case JOB_SUBMITTED:\n      JobSubmittedEvent jse \u003d (JobSubmittedEvent) event;\n      summary.setUser(jse.getUserName());\n      summary.setQueue(jse.getJobQueueName());\n      summary.setJobSubmitTime(jse.getSubmitTime());\n      break;\n    case NORMALIZED_RESOURCE:\n      NormalizedResourceEvent normalizedResourceEvent \u003d \n            (NormalizedResourceEvent) event;\n      if (normalizedResourceEvent.getTaskType() \u003d\u003d TaskType.MAP) {\n        summary.setResourcesPerMap(normalizedResourceEvent.getMemory());\n      } else if (normalizedResourceEvent.getTaskType() \u003d\u003d TaskType.REDUCE) {\n        summary.setResourcesPerReduce(normalizedResourceEvent.getMemory());\n      }\n      break;  \n    case JOB_INITED:\n      JobInitedEvent jie \u003d (JobInitedEvent) event;\n      summary.setJobLaunchTime(jie.getLaunchTime());\n      break;\n    case MAP_ATTEMPT_STARTED:\n      TaskAttemptStartedEvent mtase \u003d (TaskAttemptStartedEvent) event;\n      if (summary.getFirstMapTaskLaunchTime() \u003d\u003d 0)\n        summary.setFirstMapTaskLaunchTime(mtase.getStartTime());\n      break;\n    case REDUCE_ATTEMPT_STARTED:\n      TaskAttemptStartedEvent rtase \u003d (TaskAttemptStartedEvent) event;\n      if (summary.getFirstReduceTaskLaunchTime() \u003d\u003d 0)\n        summary.setFirstReduceTaskLaunchTime(rtase.getStartTime());\n      break;\n    case JOB_FINISHED:\n      JobFinishedEvent jfe \u003d (JobFinishedEvent) event;\n      summary.setJobFinishTime(jfe.getFinishTime());\n      summary.setNumFinishedMaps(jfe.getFinishedMaps());\n      summary.setNumFailedMaps(jfe.getFailedMaps());\n      summary.setNumFinishedReduces(jfe.getFinishedReduces());\n      summary.setNumFailedReduces(jfe.getFailedReduces());\n      if (summary.getJobStatus() \u003d\u003d null)\n        summary\n            .setJobStatus(org.apache.hadoop.mapreduce.JobStatus.State.SUCCEEDED\n                .toString());\n      // TODO JOB_FINISHED does not have state. Effectively job history does not\n      // have state about the finished job.\n      setSummarySlotSeconds(summary, jobId);\n      break;\n    case JOB_FAILED:\n    case JOB_KILLED:\n      JobUnsuccessfulCompletionEvent juce \u003d (JobUnsuccessfulCompletionEvent) event;\n      summary.setJobStatus(juce.getStatus());\n      summary.setNumFinishedMaps(context.getJob(jobId).getTotalMaps());\n      summary.setNumFinishedReduces(context.getJob(jobId).getTotalReduces());\n      summary.setJobFinishTime(juce.getFinishTime());\n      setSummarySlotSeconds(summary, jobId);\n      break;\n    }\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
          "extendedDetails": {
            "oldValue": "[private]",
            "newValue": "[public]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "MAPREDUCE-2821. Added missing fields (resourcePerMap \u0026 resourcePerReduce) to JobSummary logs. Contributed by Mahadev Konar.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1188528 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "24/10/11 11:26 PM",
          "commitName": "fffdf661e30afd10331d2153ff052c141b7ebe4b",
          "commitAuthor": "Arun Murthy",
          "commitDateOld": "18/10/11 10:21 PM",
          "commitNameOld": "13e4562924a6cb3d16c262e0f595b2ffbf9e0546",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 6.05,
          "commitsBetweenForRepo": 52,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,49 +1,59 @@\n-  private void processEventForJobSummary(HistoryEvent event, JobSummary summary, JobId jobId) {\n+  public void processEventForJobSummary(HistoryEvent event, JobSummary summary, \n+      JobId jobId) {\n     // context.getJob could be used for some of this info as well.\n     switch (event.getEventType()) {\n     case JOB_SUBMITTED:\n       JobSubmittedEvent jse \u003d (JobSubmittedEvent) event;\n       summary.setUser(jse.getUserName());\n       summary.setQueue(jse.getJobQueueName());\n       summary.setJobSubmitTime(jse.getSubmitTime());\n       break;\n+    case NORMALIZED_RESOURCE:\n+      NormalizedResourceEvent normalizedResourceEvent \u003d \n+            (NormalizedResourceEvent) event;\n+      if (normalizedResourceEvent.getTaskType() \u003d\u003d TaskType.MAP) {\n+        summary.setResourcesPerMap(normalizedResourceEvent.getMemory());\n+      } else if (normalizedResourceEvent.getTaskType() \u003d\u003d TaskType.REDUCE) {\n+        summary.setResourcesPerReduce(normalizedResourceEvent.getMemory());\n+      }\n+      break;  \n     case JOB_INITED:\n       JobInitedEvent jie \u003d (JobInitedEvent) event;\n       summary.setJobLaunchTime(jie.getLaunchTime());\n       break;\n     case MAP_ATTEMPT_STARTED:\n       TaskAttemptStartedEvent mtase \u003d (TaskAttemptStartedEvent) event;\n       if (summary.getFirstMapTaskLaunchTime() \u003d\u003d 0)\n         summary.setFirstMapTaskLaunchTime(mtase.getStartTime());\n       break;\n     case REDUCE_ATTEMPT_STARTED:\n       TaskAttemptStartedEvent rtase \u003d (TaskAttemptStartedEvent) event;\n       if (summary.getFirstReduceTaskLaunchTime() \u003d\u003d 0)\n         summary.setFirstReduceTaskLaunchTime(rtase.getStartTime());\n       break;\n     case JOB_FINISHED:\n       JobFinishedEvent jfe \u003d (JobFinishedEvent) event;\n       summary.setJobFinishTime(jfe.getFinishTime());\n       summary.setNumFinishedMaps(jfe.getFinishedMaps());\n       summary.setNumFailedMaps(jfe.getFailedMaps());\n       summary.setNumFinishedReduces(jfe.getFinishedReduces());\n       summary.setNumFailedReduces(jfe.getFailedReduces());\n       if (summary.getJobStatus() \u003d\u003d null)\n         summary\n             .setJobStatus(org.apache.hadoop.mapreduce.JobStatus.State.SUCCEEDED\n                 .toString());\n       // TODO JOB_FINISHED does not have state. Effectively job history does not\n       // have state about the finished job.\n       setSummarySlotSeconds(summary, jobId);\n       break;\n     case JOB_FAILED:\n     case JOB_KILLED:\n       JobUnsuccessfulCompletionEvent juce \u003d (JobUnsuccessfulCompletionEvent) event;\n       summary.setJobStatus(juce.getStatus());\n       summary.setNumFinishedMaps(context.getJob(jobId).getTotalMaps());\n       summary.setNumFinishedReduces(context.getJob(jobId).getTotalReduces());\n       summary.setJobFinishTime(juce.getFinishTime());\n       setSummarySlotSeconds(summary, jobId);\n       break;\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void processEventForJobSummary(HistoryEvent event, JobSummary summary, \n      JobId jobId) {\n    // context.getJob could be used for some of this info as well.\n    switch (event.getEventType()) {\n    case JOB_SUBMITTED:\n      JobSubmittedEvent jse \u003d (JobSubmittedEvent) event;\n      summary.setUser(jse.getUserName());\n      summary.setQueue(jse.getJobQueueName());\n      summary.setJobSubmitTime(jse.getSubmitTime());\n      break;\n    case NORMALIZED_RESOURCE:\n      NormalizedResourceEvent normalizedResourceEvent \u003d \n            (NormalizedResourceEvent) event;\n      if (normalizedResourceEvent.getTaskType() \u003d\u003d TaskType.MAP) {\n        summary.setResourcesPerMap(normalizedResourceEvent.getMemory());\n      } else if (normalizedResourceEvent.getTaskType() \u003d\u003d TaskType.REDUCE) {\n        summary.setResourcesPerReduce(normalizedResourceEvent.getMemory());\n      }\n      break;  \n    case JOB_INITED:\n      JobInitedEvent jie \u003d (JobInitedEvent) event;\n      summary.setJobLaunchTime(jie.getLaunchTime());\n      break;\n    case MAP_ATTEMPT_STARTED:\n      TaskAttemptStartedEvent mtase \u003d (TaskAttemptStartedEvent) event;\n      if (summary.getFirstMapTaskLaunchTime() \u003d\u003d 0)\n        summary.setFirstMapTaskLaunchTime(mtase.getStartTime());\n      break;\n    case REDUCE_ATTEMPT_STARTED:\n      TaskAttemptStartedEvent rtase \u003d (TaskAttemptStartedEvent) event;\n      if (summary.getFirstReduceTaskLaunchTime() \u003d\u003d 0)\n        summary.setFirstReduceTaskLaunchTime(rtase.getStartTime());\n      break;\n    case JOB_FINISHED:\n      JobFinishedEvent jfe \u003d (JobFinishedEvent) event;\n      summary.setJobFinishTime(jfe.getFinishTime());\n      summary.setNumFinishedMaps(jfe.getFinishedMaps());\n      summary.setNumFailedMaps(jfe.getFailedMaps());\n      summary.setNumFinishedReduces(jfe.getFinishedReduces());\n      summary.setNumFailedReduces(jfe.getFailedReduces());\n      if (summary.getJobStatus() \u003d\u003d null)\n        summary\n            .setJobStatus(org.apache.hadoop.mapreduce.JobStatus.State.SUCCEEDED\n                .toString());\n      // TODO JOB_FINISHED does not have state. Effectively job history does not\n      // have state about the finished job.\n      setSummarySlotSeconds(summary, jobId);\n      break;\n    case JOB_FAILED:\n    case JOB_KILLED:\n      JobUnsuccessfulCompletionEvent juce \u003d (JobUnsuccessfulCompletionEvent) event;\n      summary.setJobStatus(juce.getStatus());\n      summary.setNumFinishedMaps(context.getJob(jobId).getTotalMaps());\n      summary.setNumFinishedReduces(context.getJob(jobId).getTotalReduces());\n      summary.setJobFinishTime(juce.getFinishTime());\n      setSummarySlotSeconds(summary, jobId);\n      break;\n    }\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
          "extendedDetails": {}
        }
      ]
    },
    "13e4562924a6cb3d16c262e0f595b2ffbf9e0546": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3144. Augmented JobHistory with the information needed for serving aggregated logs. Contributed by Siddharth Seth.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1185976 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/10/11 10:21 PM",
      "commitName": "13e4562924a6cb3d16c262e0f595b2ffbf9e0546",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "18/09/11 12:16 AM",
      "commitNameOld": "61900651b1b85cf235e01142acf2a51727fc5537",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 30.92,
      "commitsBetweenForRepo": 230,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,48 +1,49 @@\n   private void processEventForJobSummary(HistoryEvent event, JobSummary summary, JobId jobId) {\n     // context.getJob could be used for some of this info as well.\n     switch (event.getEventType()) {\n     case JOB_SUBMITTED:\n       JobSubmittedEvent jse \u003d (JobSubmittedEvent) event;\n       summary.setUser(jse.getUserName());\n       summary.setQueue(jse.getJobQueueName());\n+      summary.setJobSubmitTime(jse.getSubmitTime());\n       break;\n     case JOB_INITED:\n       JobInitedEvent jie \u003d (JobInitedEvent) event;\n       summary.setJobLaunchTime(jie.getLaunchTime());\n       break;\n     case MAP_ATTEMPT_STARTED:\n       TaskAttemptStartedEvent mtase \u003d (TaskAttemptStartedEvent) event;\n       if (summary.getFirstMapTaskLaunchTime() \u003d\u003d 0)\n         summary.setFirstMapTaskLaunchTime(mtase.getStartTime());\n       break;\n     case REDUCE_ATTEMPT_STARTED:\n       TaskAttemptStartedEvent rtase \u003d (TaskAttemptStartedEvent) event;\n       if (summary.getFirstReduceTaskLaunchTime() \u003d\u003d 0)\n         summary.setFirstReduceTaskLaunchTime(rtase.getStartTime());\n       break;\n     case JOB_FINISHED:\n       JobFinishedEvent jfe \u003d (JobFinishedEvent) event;\n       summary.setJobFinishTime(jfe.getFinishTime());\n       summary.setNumFinishedMaps(jfe.getFinishedMaps());\n       summary.setNumFailedMaps(jfe.getFailedMaps());\n       summary.setNumFinishedReduces(jfe.getFinishedReduces());\n       summary.setNumFailedReduces(jfe.getFailedReduces());\n       if (summary.getJobStatus() \u003d\u003d null)\n         summary\n             .setJobStatus(org.apache.hadoop.mapreduce.JobStatus.State.SUCCEEDED\n                 .toString());\n       // TODO JOB_FINISHED does not have state. Effectively job history does not\n       // have state about the finished job.\n       setSummarySlotSeconds(summary, jobId);\n       break;\n     case JOB_FAILED:\n     case JOB_KILLED:\n       JobUnsuccessfulCompletionEvent juce \u003d (JobUnsuccessfulCompletionEvent) event;\n       summary.setJobStatus(juce.getStatus());\n       summary.setNumFinishedMaps(context.getJob(jobId).getTotalMaps());\n       summary.setNumFinishedReduces(context.getJob(jobId).getTotalReduces());\n       summary.setJobFinishTime(juce.getFinishTime());\n       setSummarySlotSeconds(summary, jobId);\n       break;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void processEventForJobSummary(HistoryEvent event, JobSummary summary, JobId jobId) {\n    // context.getJob could be used for some of this info as well.\n    switch (event.getEventType()) {\n    case JOB_SUBMITTED:\n      JobSubmittedEvent jse \u003d (JobSubmittedEvent) event;\n      summary.setUser(jse.getUserName());\n      summary.setQueue(jse.getJobQueueName());\n      summary.setJobSubmitTime(jse.getSubmitTime());\n      break;\n    case JOB_INITED:\n      JobInitedEvent jie \u003d (JobInitedEvent) event;\n      summary.setJobLaunchTime(jie.getLaunchTime());\n      break;\n    case MAP_ATTEMPT_STARTED:\n      TaskAttemptStartedEvent mtase \u003d (TaskAttemptStartedEvent) event;\n      if (summary.getFirstMapTaskLaunchTime() \u003d\u003d 0)\n        summary.setFirstMapTaskLaunchTime(mtase.getStartTime());\n      break;\n    case REDUCE_ATTEMPT_STARTED:\n      TaskAttemptStartedEvent rtase \u003d (TaskAttemptStartedEvent) event;\n      if (summary.getFirstReduceTaskLaunchTime() \u003d\u003d 0)\n        summary.setFirstReduceTaskLaunchTime(rtase.getStartTime());\n      break;\n    case JOB_FINISHED:\n      JobFinishedEvent jfe \u003d (JobFinishedEvent) event;\n      summary.setJobFinishTime(jfe.getFinishTime());\n      summary.setNumFinishedMaps(jfe.getFinishedMaps());\n      summary.setNumFailedMaps(jfe.getFailedMaps());\n      summary.setNumFinishedReduces(jfe.getFinishedReduces());\n      summary.setNumFailedReduces(jfe.getFailedReduces());\n      if (summary.getJobStatus() \u003d\u003d null)\n        summary\n            .setJobStatus(org.apache.hadoop.mapreduce.JobStatus.State.SUCCEEDED\n                .toString());\n      // TODO JOB_FINISHED does not have state. Effectively job history does not\n      // have state about the finished job.\n      setSummarySlotSeconds(summary, jobId);\n      break;\n    case JOB_FAILED:\n    case JOB_KILLED:\n      JobUnsuccessfulCompletionEvent juce \u003d (JobUnsuccessfulCompletionEvent) event;\n      summary.setJobStatus(juce.getStatus());\n      summary.setNumFinishedMaps(context.getJob(jobId).getTotalMaps());\n      summary.setNumFinishedReduces(context.getJob(jobId).getTotalReduces());\n      summary.setJobFinishTime(juce.getFinishTime());\n      setSummarySlotSeconds(summary, jobId);\n      break;\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private void processEventForJobSummary(HistoryEvent event, JobSummary summary, JobId jobId) {\n    // context.getJob could be used for some of this info as well.\n    switch (event.getEventType()) {\n    case JOB_SUBMITTED:\n      JobSubmittedEvent jse \u003d (JobSubmittedEvent) event;\n      summary.setUser(jse.getUserName());\n      summary.setQueue(jse.getJobQueueName());\n      break;\n    case JOB_INITED:\n      JobInitedEvent jie \u003d (JobInitedEvent) event;\n      summary.setJobLaunchTime(jie.getLaunchTime());\n      break;\n    case MAP_ATTEMPT_STARTED:\n      TaskAttemptStartedEvent mtase \u003d (TaskAttemptStartedEvent) event;\n      if (summary.getFirstMapTaskLaunchTime() \u003d\u003d 0)\n        summary.setFirstMapTaskLaunchTime(mtase.getStartTime());\n      break;\n    case REDUCE_ATTEMPT_STARTED:\n      TaskAttemptStartedEvent rtase \u003d (TaskAttemptStartedEvent) event;\n      if (summary.getFirstReduceTaskLaunchTime() \u003d\u003d 0)\n        summary.setFirstReduceTaskLaunchTime(rtase.getStartTime());\n      break;\n    case JOB_FINISHED:\n      JobFinishedEvent jfe \u003d (JobFinishedEvent) event;\n      summary.setJobFinishTime(jfe.getFinishTime());\n      summary.setNumFinishedMaps(jfe.getFinishedMaps());\n      summary.setNumFailedMaps(jfe.getFailedMaps());\n      summary.setNumFinishedReduces(jfe.getFinishedReduces());\n      summary.setNumFailedReduces(jfe.getFailedReduces());\n      if (summary.getJobStatus() \u003d\u003d null)\n        summary\n            .setJobStatus(org.apache.hadoop.mapreduce.JobStatus.State.SUCCEEDED\n                .toString());\n      // TODO JOB_FINISHED does not have state. Effectively job history does not\n      // have state about the finished job.\n      setSummarySlotSeconds(summary, jobId);\n      break;\n    case JOB_FAILED:\n    case JOB_KILLED:\n      JobUnsuccessfulCompletionEvent juce \u003d (JobUnsuccessfulCompletionEvent) event;\n      summary.setJobStatus(juce.getStatus());\n      summary.setNumFinishedMaps(context.getJob(jobId).getTotalMaps());\n      summary.setNumFinishedReduces(context.getJob(jobId).getTotalReduces());\n      summary.setJobFinishTime(juce.getFinishTime());\n      setSummarySlotSeconds(summary, jobId);\n      break;\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
        "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "diff": "@@ -0,0 +1,48 @@\n+  private void processEventForJobSummary(HistoryEvent event, JobSummary summary, JobId jobId) {\n+    // context.getJob could be used for some of this info as well.\n+    switch (event.getEventType()) {\n+    case JOB_SUBMITTED:\n+      JobSubmittedEvent jse \u003d (JobSubmittedEvent) event;\n+      summary.setUser(jse.getUserName());\n+      summary.setQueue(jse.getJobQueueName());\n+      break;\n+    case JOB_INITED:\n+      JobInitedEvent jie \u003d (JobInitedEvent) event;\n+      summary.setJobLaunchTime(jie.getLaunchTime());\n+      break;\n+    case MAP_ATTEMPT_STARTED:\n+      TaskAttemptStartedEvent mtase \u003d (TaskAttemptStartedEvent) event;\n+      if (summary.getFirstMapTaskLaunchTime() \u003d\u003d 0)\n+        summary.setFirstMapTaskLaunchTime(mtase.getStartTime());\n+      break;\n+    case REDUCE_ATTEMPT_STARTED:\n+      TaskAttemptStartedEvent rtase \u003d (TaskAttemptStartedEvent) event;\n+      if (summary.getFirstReduceTaskLaunchTime() \u003d\u003d 0)\n+        summary.setFirstReduceTaskLaunchTime(rtase.getStartTime());\n+      break;\n+    case JOB_FINISHED:\n+      JobFinishedEvent jfe \u003d (JobFinishedEvent) event;\n+      summary.setJobFinishTime(jfe.getFinishTime());\n+      summary.setNumFinishedMaps(jfe.getFinishedMaps());\n+      summary.setNumFailedMaps(jfe.getFailedMaps());\n+      summary.setNumFinishedReduces(jfe.getFinishedReduces());\n+      summary.setNumFailedReduces(jfe.getFailedReduces());\n+      if (summary.getJobStatus() \u003d\u003d null)\n+        summary\n+            .setJobStatus(org.apache.hadoop.mapreduce.JobStatus.State.SUCCEEDED\n+                .toString());\n+      // TODO JOB_FINISHED does not have state. Effectively job history does not\n+      // have state about the finished job.\n+      setSummarySlotSeconds(summary, jobId);\n+      break;\n+    case JOB_FAILED:\n+    case JOB_KILLED:\n+      JobUnsuccessfulCompletionEvent juce \u003d (JobUnsuccessfulCompletionEvent) event;\n+      summary.setJobStatus(juce.getStatus());\n+      summary.setNumFinishedMaps(context.getJob(jobId).getTotalMaps());\n+      summary.setNumFinishedReduces(context.getJob(jobId).getTotalReduces());\n+      summary.setJobFinishTime(juce.getFinishTime());\n+      setSummarySlotSeconds(summary, jobId);\n+      break;\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void processEventForJobSummary(HistoryEvent event, JobSummary summary, JobId jobId) {\n    // context.getJob could be used for some of this info as well.\n    switch (event.getEventType()) {\n    case JOB_SUBMITTED:\n      JobSubmittedEvent jse \u003d (JobSubmittedEvent) event;\n      summary.setUser(jse.getUserName());\n      summary.setQueue(jse.getJobQueueName());\n      break;\n    case JOB_INITED:\n      JobInitedEvent jie \u003d (JobInitedEvent) event;\n      summary.setJobLaunchTime(jie.getLaunchTime());\n      break;\n    case MAP_ATTEMPT_STARTED:\n      TaskAttemptStartedEvent mtase \u003d (TaskAttemptStartedEvent) event;\n      if (summary.getFirstMapTaskLaunchTime() \u003d\u003d 0)\n        summary.setFirstMapTaskLaunchTime(mtase.getStartTime());\n      break;\n    case REDUCE_ATTEMPT_STARTED:\n      TaskAttemptStartedEvent rtase \u003d (TaskAttemptStartedEvent) event;\n      if (summary.getFirstReduceTaskLaunchTime() \u003d\u003d 0)\n        summary.setFirstReduceTaskLaunchTime(rtase.getStartTime());\n      break;\n    case JOB_FINISHED:\n      JobFinishedEvent jfe \u003d (JobFinishedEvent) event;\n      summary.setJobFinishTime(jfe.getFinishTime());\n      summary.setNumFinishedMaps(jfe.getFinishedMaps());\n      summary.setNumFailedMaps(jfe.getFailedMaps());\n      summary.setNumFinishedReduces(jfe.getFinishedReduces());\n      summary.setNumFailedReduces(jfe.getFailedReduces());\n      if (summary.getJobStatus() \u003d\u003d null)\n        summary\n            .setJobStatus(org.apache.hadoop.mapreduce.JobStatus.State.SUCCEEDED\n                .toString());\n      // TODO JOB_FINISHED does not have state. Effectively job history does not\n      // have state about the finished job.\n      setSummarySlotSeconds(summary, jobId);\n      break;\n    case JOB_FAILED:\n    case JOB_KILLED:\n      JobUnsuccessfulCompletionEvent juce \u003d (JobUnsuccessfulCompletionEvent) event;\n      summary.setJobStatus(juce.getStatus());\n      summary.setNumFinishedMaps(context.getJob(jobId).getTotalMaps());\n      summary.setNumFinishedReduces(context.getJob(jobId).getTotalReduces());\n      summary.setJobFinishTime(juce.getFinishTime());\n      setSummarySlotSeconds(summary, jobId);\n      break;\n    }\n  }",
      "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java"
    }
  }
}