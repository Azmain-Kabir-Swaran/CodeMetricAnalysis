{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "RMAppManager.java",
  "functionName": "recover",
  "functionId": "recover___state-RMState",
  "sourceFilePath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/RMAppManager.java",
  "functionStartLine": 611,
  "functionEndLine": 630,
  "numCommitsSeen": 106,
  "timeTaken": 3947,
  "changeHistory": [
    "f216276d2164c6564632c571fd3adbb03bc8b3e4",
    "5805a81efbc024024d8172489dfdc6cf77879416",
    "4de17c60528cb29bf7306dbaa720b96063948b17",
    "305ae48136d6e201de4451e824cb7b84f94ba2e0",
    "512475e56f0a27bf3c3ff596184f96993bb4bef4",
    "9f4d4e27fb1760b352cc5b301cd65a50d2d43ff6",
    "259edf8dca44de54033e96f7eb65a83aaa6096f2",
    "74231f027607ff1a6fe7d72fad28108826963cf3",
    "e24a9b83f137c7a27d57934580140693b5a86826",
    "ef9f251679d7e87698eecd6a119652900274a172",
    "7d00d3d20fc33e2de85f3864e8a1ad68695c526e",
    "6cd0736cc57849e4f7c5d38a3986432a9717fe39"
  ],
  "changeHistoryShort": {
    "f216276d2164c6564632c571fd3adbb03bc8b3e4": "Ybodychange",
    "5805a81efbc024024d8172489dfdc6cf77879416": "Ybodychange",
    "4de17c60528cb29bf7306dbaa720b96063948b17": "Ybodychange",
    "305ae48136d6e201de4451e824cb7b84f94ba2e0": "Ybodychange",
    "512475e56f0a27bf3c3ff596184f96993bb4bef4": "Ybodychange",
    "9f4d4e27fb1760b352cc5b301cd65a50d2d43ff6": "Ybodychange",
    "259edf8dca44de54033e96f7eb65a83aaa6096f2": "Ybodychange",
    "74231f027607ff1a6fe7d72fad28108826963cf3": "Ybodychange",
    "e24a9b83f137c7a27d57934580140693b5a86826": "Ybodychange",
    "ef9f251679d7e87698eecd6a119652900274a172": "Ybodychange",
    "7d00d3d20fc33e2de85f3864e8a1ad68695c526e": "Ybodychange",
    "6cd0736cc57849e4f7c5d38a3986432a9717fe39": "Yintroduced"
  },
  "changeHistoryDetails": {
    "f216276d2164c6564632c571fd3adbb03bc8b3e4": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4882. Change the log level to DEBUG for recovering completed applications (templedf via rkanter)\n",
      "commitDate": "28/12/16 3:21 PM",
      "commitName": "f216276d2164c6564632c571fd3adbb03bc8b3e4",
      "commitAuthor": "Robert Kanter",
      "commitDateOld": "06/12/16 9:09 PM",
      "commitNameOld": "563480dccd0136d82730f4228f1df44449ed5822",
      "commitAuthorOld": "Rohith Sharma K S",
      "daysBetweenCommits": 21.76,
      "commitsBetweenForRepo": 102,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,11 +1,20 @@\n   public void recover(RMState state) throws Exception {\n     RMStateStore store \u003d rmContext.getStateStore();\n     assert store !\u003d null;\n     // recover applications\n     Map\u003cApplicationId, ApplicationStateData\u003e appStates \u003d\n         state.getApplicationState();\n     LOG.info(\"Recovering \" + appStates.size() + \" applications\");\n-    for (ApplicationStateData appState : appStates.values()) {\n-      recoverApplication(appState, state);\n+\n+    int count \u003d 0;\n+\n+    try {\n+      for (ApplicationStateData appState : appStates.values()) {\n+        recoverApplication(appState, state);\n+        count +\u003d 1;\n+      }\n+    } finally {\n+      LOG.info(\"Successfully recovered \" + count  + \" out of \"\n+          + appStates.size() + \" applications\");\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void recover(RMState state) throws Exception {\n    RMStateStore store \u003d rmContext.getStateStore();\n    assert store !\u003d null;\n    // recover applications\n    Map\u003cApplicationId, ApplicationStateData\u003e appStates \u003d\n        state.getApplicationState();\n    LOG.info(\"Recovering \" + appStates.size() + \" applications\");\n\n    int count \u003d 0;\n\n    try {\n      for (ApplicationStateData appState : appStates.values()) {\n        recoverApplication(appState, state);\n        count +\u003d 1;\n      }\n    } finally {\n      LOG.info(\"Successfully recovered \" + count  + \" out of \"\n          + appStates.size() + \" applications\");\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/RMAppManager.java",
      "extendedDetails": {}
    },
    "5805a81efbc024024d8172489dfdc6cf77879416": {
      "type": "Ybodychange",
      "commitMessage": "YARN-2404. Removed ApplicationAttemptState and ApplicationState class in RMStateStore. Contributed by Tsuyoshi OZAWA\n",
      "commitDate": "25/11/14 12:48 PM",
      "commitName": "5805a81efbc024024d8172489dfdc6cf77879416",
      "commitAuthor": "Jian He",
      "commitDateOld": "12/11/14 9:01 AM",
      "commitNameOld": "f8aefa5e9c8c6d2817205b5ed8d914db31f56ae7",
      "commitAuthorOld": "Jason Lowe",
      "daysBetweenCommits": 13.16,
      "commitsBetweenForRepo": 94,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,10 +1,11 @@\n   public void recover(RMState state) throws Exception {\n     RMStateStore store \u003d rmContext.getStateStore();\n     assert store !\u003d null;\n     // recover applications\n-    Map\u003cApplicationId, ApplicationState\u003e appStates \u003d state.getApplicationState();\n+    Map\u003cApplicationId, ApplicationStateData\u003e appStates \u003d\n+        state.getApplicationState();\n     LOG.info(\"Recovering \" + appStates.size() + \" applications\");\n-    for (ApplicationState appState : appStates.values()) {\n+    for (ApplicationStateData appState : appStates.values()) {\n       recoverApplication(appState, state);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void recover(RMState state) throws Exception {\n    RMStateStore store \u003d rmContext.getStateStore();\n    assert store !\u003d null;\n    // recover applications\n    Map\u003cApplicationId, ApplicationStateData\u003e appStates \u003d\n        state.getApplicationState();\n    LOG.info(\"Recovering \" + appStates.size() + \" applications\");\n    for (ApplicationStateData appState : appStates.values()) {\n      recoverApplication(appState, state);\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/RMAppManager.java",
      "extendedDetails": {}
    },
    "4de17c60528cb29bf7306dbaa720b96063948b17": {
      "type": "Ybodychange",
      "commitMessage": "YARN-1812. Fixed ResourceManager to synchrously renew tokens after recovery and thus recover app itself synchronously and avoid races with resyncing NodeManagers. Contributed by Jian He.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1576843 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/03/14 11:25 AM",
      "commitName": "4de17c60528cb29bf7306dbaa720b96063948b17",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "04/02/14 8:55 PM",
      "commitNameOld": "ebe0c17a95ae37d4768f2928ea193e89db34ead5",
      "commitAuthorOld": "Zhijie Shen",
      "daysBetweenCommits": 35.56,
      "commitsBetweenForRepo": 336,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,11 +1,10 @@\n   public void recover(RMState state) throws Exception {\n     RMStateStore store \u003d rmContext.getStateStore();\n     assert store !\u003d null;\n     // recover applications\n     Map\u003cApplicationId, ApplicationState\u003e appStates \u003d state.getApplicationState();\n     LOG.info(\"Recovering \" + appStates.size() + \" applications\");\n     for (ApplicationState appState : appStates.values()) {\n-      submitApplication(appState.getApplicationSubmissionContext(),\n-        appState.getSubmitTime(), appState.getUser(), true, state);\n+      recoverApplication(appState, state);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void recover(RMState state) throws Exception {\n    RMStateStore store \u003d rmContext.getStateStore();\n    assert store !\u003d null;\n    // recover applications\n    Map\u003cApplicationId, ApplicationState\u003e appStates \u003d state.getApplicationState();\n    LOG.info(\"Recovering \" + appStates.size() + \" applications\");\n    for (ApplicationState appState : appStates.values()) {\n      recoverApplication(appState, state);\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/RMAppManager.java",
      "extendedDetails": {}
    },
    "305ae48136d6e201de4451e824cb7b84f94ba2e0": {
      "type": "Ybodychange",
      "commitMessage": "YARN-1378. Implemented a cleaner of old finished applications from the RM state-store. Contributed by Jian He.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1548990 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/12/13 8:17 PM",
      "commitName": "305ae48136d6e201de4451e824cb7b84f94ba2e0",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "18/11/13 9:20 PM",
      "commitNameOld": "512475e56f0a27bf3c3ff596184f96993bb4bef4",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 18.96,
      "commitsBetweenForRepo": 109,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,11 @@\n   public void recover(RMState state) throws Exception {\n     RMStateStore store \u003d rmContext.getStateStore();\n     assert store !\u003d null;\n     // recover applications\n     Map\u003cApplicationId, ApplicationState\u003e appStates \u003d state.getApplicationState();\n     LOG.info(\"Recovering \" + appStates.size() + \" applications\");\n     for (ApplicationState appState : appStates.values()) {\n-      LOG.info(\"Recovering application \" + appState.getAppId());\n-      \n       submitApplication(appState.getApplicationSubmissionContext(),\n         appState.getSubmitTime(), appState.getUser(), true, state);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void recover(RMState state) throws Exception {\n    RMStateStore store \u003d rmContext.getStateStore();\n    assert store !\u003d null;\n    // recover applications\n    Map\u003cApplicationId, ApplicationState\u003e appStates \u003d state.getApplicationState();\n    LOG.info(\"Recovering \" + appStates.size() + \" applications\");\n    for (ApplicationState appState : appStates.values()) {\n      submitApplication(appState.getApplicationSubmissionContext(),\n        appState.getSubmitTime(), appState.getUser(), true, state);\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/RMAppManager.java",
      "extendedDetails": {}
    },
    "512475e56f0a27bf3c3ff596184f96993bb4bef4": {
      "type": "Ybodychange",
      "commitMessage": "YARN-674. Fixed ResourceManager to renew DelegationTokens on submission asynchronously to work around potential slowness in state-store. Contributed by Omkar Vinit Joshi.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1543312 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/11/13 9:20 PM",
      "commitName": "512475e56f0a27bf3c3ff596184f96993bb4bef4",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "18/11/13 4:50 PM",
      "commitNameOld": "4341562622df16b8a0c13af257ac0d03919b374d",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 0.19,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,13 @@\n   public void recover(RMState state) throws Exception {\n     RMStateStore store \u003d rmContext.getStateStore();\n     assert store !\u003d null;\n     // recover applications\n     Map\u003cApplicationId, ApplicationState\u003e appStates \u003d state.getApplicationState();\n     LOG.info(\"Recovering \" + appStates.size() + \" applications\");\n     for (ApplicationState appState : appStates.values()) {\n       LOG.info(\"Recovering application \" + appState.getAppId());\n+      \n       submitApplication(appState.getApplicationSubmissionContext(),\n-        appState.getSubmitTime(), true, appState.getUser());\n-      // re-populate attempt information in application\n-      RMAppImpl appImpl \u003d\n-          (RMAppImpl) rmContext.getRMApps().get(appState.getAppId());\n-      appImpl.recover(state);\n-      // Recover the app synchronously, as otherwise client is possible to see\n-      // the application not recovered before it is actually recovered because\n-      // ClientRMService is already started at this point of time.\n-      appImpl.handle(new RMAppEvent(appImpl.getApplicationId(),\n-        RMAppEventType.RECOVER));\n+        appState.getSubmitTime(), appState.getUser(), true, state);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void recover(RMState state) throws Exception {\n    RMStateStore store \u003d rmContext.getStateStore();\n    assert store !\u003d null;\n    // recover applications\n    Map\u003cApplicationId, ApplicationState\u003e appStates \u003d state.getApplicationState();\n    LOG.info(\"Recovering \" + appStates.size() + \" applications\");\n    for (ApplicationState appState : appStates.values()) {\n      LOG.info(\"Recovering application \" + appState.getAppId());\n      \n      submitApplication(appState.getApplicationSubmissionContext(),\n        appState.getSubmitTime(), appState.getUser(), true, state);\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/RMAppManager.java",
      "extendedDetails": {}
    },
    "9f4d4e27fb1760b352cc5b301cd65a50d2d43ff6": {
      "type": "Ybodychange",
      "commitMessage": "YARN-891. Modified ResourceManager state-store to remember completed applications so that clients can get information about them post RM-restart. Contributed by Jian He.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1537560 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "31/10/13 10:25 AM",
      "commitName": "9f4d4e27fb1760b352cc5b301cd65a50d2d43ff6",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "28/09/13 9:29 AM",
      "commitNameOld": "4ce930ea444d313eeb49e1f9ddbe5f52c7dc63a2",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 33.04,
      "commitsBetweenForRepo": 233,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,55 +1,21 @@\n   public void recover(RMState state) throws Exception {\n     RMStateStore store \u003d rmContext.getStateStore();\n     assert store !\u003d null;\n     // recover applications\n     Map\u003cApplicationId, ApplicationState\u003e appStates \u003d state.getApplicationState();\n     LOG.info(\"Recovering \" + appStates.size() + \" applications\");\n-    for(ApplicationState appState : appStates.values()) {\n-      boolean shouldRecover \u003d true;\n-      if(appState.getApplicationSubmissionContext().getUnmanagedAM()) {\n-        // do not recover unmanaged applications since current recovery \n-        // mechanism of restarting attempts does not work for them.\n-        // This will need to be changed in work preserving recovery in which \n-        // RM will re-connect with the running AM\u0027s instead of restarting them\n-        LOG.info(\"Not recovering unmanaged application \" + appState.getAppId());\n-        shouldRecover \u003d false;\n-      }\n-      int individualMaxAppAttempts \u003d appState.getApplicationSubmissionContext()\n-          .getMaxAppAttempts();\n-      int maxAppAttempts;\n-      if (individualMaxAppAttempts \u003c\u003d 0 ||\n-          individualMaxAppAttempts \u003e globalMaxAppAttempts) {\n-        maxAppAttempts \u003d globalMaxAppAttempts;\n-        LOG.warn(\"The specific max attempts: \" + individualMaxAppAttempts\n-            + \" for application: \" + appState.getAppId()\n-            + \" is invalid, because it is out of the range [1, \"\n-            + globalMaxAppAttempts + \"]. Use the global max attempts instead.\");\n-      } else {\n-        maxAppAttempts \u003d individualMaxAppAttempts;\n-      }\n-      // In work-preserve restart, if attemptCount \u003d\u003d maxAttempts, the job still\n-      // needs to be recovered because the last attempt may still be running.\n-      if(appState.getAttemptCount() \u003e\u003d maxAppAttempts) {\n-        LOG.info(\"Not recovering application \" + appState.getAppId() +\n-            \" due to recovering attempt is beyond maxAppAttempt limit\");\n-        shouldRecover \u003d false;\n-      }\n-\n-      // re-submit the application\n-      // this is going to send an app start event but since the async dispatcher\n-      // has not started that event will be queued until we have completed re\n-      // populating the state\n-      if(shouldRecover) {\n-        LOG.info(\"Recovering application \" + appState.getAppId());\n-        submitApplication(appState.getApplicationSubmissionContext(), \n-                        appState.getSubmitTime(), true, appState.getUser());\n-        // re-populate attempt information in application\n-        RMAppImpl appImpl \u003d (RMAppImpl) rmContext.getRMApps().get(\n-                                                        appState.getAppId());\n-        appImpl.recover(state);\n-      }\n-      else {\n-        store.removeApplication(appState);\n-      }\n+    for (ApplicationState appState : appStates.values()) {\n+      LOG.info(\"Recovering application \" + appState.getAppId());\n+      submitApplication(appState.getApplicationSubmissionContext(),\n+        appState.getSubmitTime(), true, appState.getUser());\n+      // re-populate attempt information in application\n+      RMAppImpl appImpl \u003d\n+          (RMAppImpl) rmContext.getRMApps().get(appState.getAppId());\n+      appImpl.recover(state);\n+      // Recover the app synchronously, as otherwise client is possible to see\n+      // the application not recovered before it is actually recovered because\n+      // ClientRMService is already started at this point of time.\n+      appImpl.handle(new RMAppEvent(appImpl.getApplicationId(),\n+        RMAppEventType.RECOVER));\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void recover(RMState state) throws Exception {\n    RMStateStore store \u003d rmContext.getStateStore();\n    assert store !\u003d null;\n    // recover applications\n    Map\u003cApplicationId, ApplicationState\u003e appStates \u003d state.getApplicationState();\n    LOG.info(\"Recovering \" + appStates.size() + \" applications\");\n    for (ApplicationState appState : appStates.values()) {\n      LOG.info(\"Recovering application \" + appState.getAppId());\n      submitApplication(appState.getApplicationSubmissionContext(),\n        appState.getSubmitTime(), true, appState.getUser());\n      // re-populate attempt information in application\n      RMAppImpl appImpl \u003d\n          (RMAppImpl) rmContext.getRMApps().get(appState.getAppId());\n      appImpl.recover(state);\n      // Recover the app synchronously, as otherwise client is possible to see\n      // the application not recovered before it is actually recovered because\n      // ClientRMService is already started at this point of time.\n      appImpl.handle(new RMAppEvent(appImpl.getApplicationId(),\n        RMAppEventType.RECOVER));\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/RMAppManager.java",
      "extendedDetails": {}
    },
    "259edf8dca44de54033e96f7eb65a83aaa6096f2": {
      "type": "Ybodychange",
      "commitMessage": "YARN-571. Remove user from ContainerLaunchContext. Contributed by Omkar Vinit Joshi.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1485928 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "23/05/13 8:22 PM",
      "commitName": "259edf8dca44de54033e96f7eb65a83aaa6096f2",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "23/05/13 11:02 AM",
      "commitNameOld": "43876770d91a374563bf3379a5ffab5c2bac2264",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 0.39,
      "commitsBetweenForRepo": 7,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,55 +1,55 @@\n   public void recover(RMState state) throws Exception {\n     RMStateStore store \u003d rmContext.getStateStore();\n     assert store !\u003d null;\n     // recover applications\n     Map\u003cApplicationId, ApplicationState\u003e appStates \u003d state.getApplicationState();\n     LOG.info(\"Recovering \" + appStates.size() + \" applications\");\n     for(ApplicationState appState : appStates.values()) {\n       boolean shouldRecover \u003d true;\n       if(appState.getApplicationSubmissionContext().getUnmanagedAM()) {\n         // do not recover unmanaged applications since current recovery \n         // mechanism of restarting attempts does not work for them.\n         // This will need to be changed in work preserving recovery in which \n         // RM will re-connect with the running AM\u0027s instead of restarting them\n         LOG.info(\"Not recovering unmanaged application \" + appState.getAppId());\n         shouldRecover \u003d false;\n       }\n       int individualMaxAppAttempts \u003d appState.getApplicationSubmissionContext()\n           .getMaxAppAttempts();\n       int maxAppAttempts;\n       if (individualMaxAppAttempts \u003c\u003d 0 ||\n           individualMaxAppAttempts \u003e globalMaxAppAttempts) {\n         maxAppAttempts \u003d globalMaxAppAttempts;\n         LOG.warn(\"The specific max attempts: \" + individualMaxAppAttempts\n             + \" for application: \" + appState.getAppId()\n             + \" is invalid, because it is out of the range [1, \"\n             + globalMaxAppAttempts + \"]. Use the global max attempts instead.\");\n       } else {\n         maxAppAttempts \u003d individualMaxAppAttempts;\n       }\n       // In work-preserve restart, if attemptCount \u003d\u003d maxAttempts, the job still\n       // needs to be recovered because the last attempt may still be running.\n       if(appState.getAttemptCount() \u003e\u003d maxAppAttempts) {\n         LOG.info(\"Not recovering application \" + appState.getAppId() +\n             \" due to recovering attempt is beyond maxAppAttempt limit\");\n         shouldRecover \u003d false;\n       }\n \n       // re-submit the application\n       // this is going to send an app start event but since the async dispatcher\n       // has not started that event will be queued until we have completed re\n       // populating the state\n       if(shouldRecover) {\n         LOG.info(\"Recovering application \" + appState.getAppId());\n         submitApplication(appState.getApplicationSubmissionContext(), \n-                        appState.getSubmitTime(), true);\n+                        appState.getSubmitTime(), true, appState.getUser());\n         // re-populate attempt information in application\n         RMAppImpl appImpl \u003d (RMAppImpl) rmContext.getRMApps().get(\n                                                         appState.getAppId());\n         appImpl.recover(state);\n       }\n       else {\n         store.removeApplication(appState);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void recover(RMState state) throws Exception {\n    RMStateStore store \u003d rmContext.getStateStore();\n    assert store !\u003d null;\n    // recover applications\n    Map\u003cApplicationId, ApplicationState\u003e appStates \u003d state.getApplicationState();\n    LOG.info(\"Recovering \" + appStates.size() + \" applications\");\n    for(ApplicationState appState : appStates.values()) {\n      boolean shouldRecover \u003d true;\n      if(appState.getApplicationSubmissionContext().getUnmanagedAM()) {\n        // do not recover unmanaged applications since current recovery \n        // mechanism of restarting attempts does not work for them.\n        // This will need to be changed in work preserving recovery in which \n        // RM will re-connect with the running AM\u0027s instead of restarting them\n        LOG.info(\"Not recovering unmanaged application \" + appState.getAppId());\n        shouldRecover \u003d false;\n      }\n      int individualMaxAppAttempts \u003d appState.getApplicationSubmissionContext()\n          .getMaxAppAttempts();\n      int maxAppAttempts;\n      if (individualMaxAppAttempts \u003c\u003d 0 ||\n          individualMaxAppAttempts \u003e globalMaxAppAttempts) {\n        maxAppAttempts \u003d globalMaxAppAttempts;\n        LOG.warn(\"The specific max attempts: \" + individualMaxAppAttempts\n            + \" for application: \" + appState.getAppId()\n            + \" is invalid, because it is out of the range [1, \"\n            + globalMaxAppAttempts + \"]. Use the global max attempts instead.\");\n      } else {\n        maxAppAttempts \u003d individualMaxAppAttempts;\n      }\n      // In work-preserve restart, if attemptCount \u003d\u003d maxAttempts, the job still\n      // needs to be recovered because the last attempt may still be running.\n      if(appState.getAttemptCount() \u003e\u003d maxAppAttempts) {\n        LOG.info(\"Not recovering application \" + appState.getAppId() +\n            \" due to recovering attempt is beyond maxAppAttempt limit\");\n        shouldRecover \u003d false;\n      }\n\n      // re-submit the application\n      // this is going to send an app start event but since the async dispatcher\n      // has not started that event will be queued until we have completed re\n      // populating the state\n      if(shouldRecover) {\n        LOG.info(\"Recovering application \" + appState.getAppId());\n        submitApplication(appState.getApplicationSubmissionContext(), \n                        appState.getSubmitTime(), true, appState.getUser());\n        // re-populate attempt information in application\n        RMAppImpl appImpl \u003d (RMAppImpl) rmContext.getRMApps().get(\n                                                        appState.getAppId());\n        appImpl.recover(state);\n      }\n      else {\n        store.removeApplication(appState);\n      }\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/RMAppManager.java",
      "extendedDetails": {}
    },
    "74231f027607ff1a6fe7d72fad28108826963cf3": {
      "type": "Ybodychange",
      "commitMessage": "YARN-582. Changed ResourceManager to recover Application token and client tokens for app attempt so that RM can be restarted while preserving current applications. Contributed by Jian He.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1480168 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/05/13 11:20 PM",
      "commitName": "74231f027607ff1a6fe7d72fad28108826963cf3",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "29/04/13 10:44 PM",
      "commitNameOld": "6de09af24487e2ff5bc22c7b1a07348c7119de80",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 8.03,
      "commitsBetweenForRepo": 34,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,55 +1,55 @@\n   public void recover(RMState state) throws Exception {\n     RMStateStore store \u003d rmContext.getStateStore();\n     assert store !\u003d null;\n     // recover applications\n     Map\u003cApplicationId, ApplicationState\u003e appStates \u003d state.getApplicationState();\n     LOG.info(\"Recovering \" + appStates.size() + \" applications\");\n     for(ApplicationState appState : appStates.values()) {\n       boolean shouldRecover \u003d true;\n-      // re-submit the application\n-      // this is going to send an app start event but since the async dispatcher \n-      // has not started that event will be queued until we have completed re\n-      // populating the state\n       if(appState.getApplicationSubmissionContext().getUnmanagedAM()) {\n         // do not recover unmanaged applications since current recovery \n         // mechanism of restarting attempts does not work for them.\n         // This will need to be changed in work preserving recovery in which \n         // RM will re-connect with the running AM\u0027s instead of restarting them\n         LOG.info(\"Not recovering unmanaged application \" + appState.getAppId());\n         shouldRecover \u003d false;\n       }\n       int individualMaxAppAttempts \u003d appState.getApplicationSubmissionContext()\n           .getMaxAppAttempts();\n       int maxAppAttempts;\n       if (individualMaxAppAttempts \u003c\u003d 0 ||\n           individualMaxAppAttempts \u003e globalMaxAppAttempts) {\n         maxAppAttempts \u003d globalMaxAppAttempts;\n         LOG.warn(\"The specific max attempts: \" + individualMaxAppAttempts\n             + \" for application: \" + appState.getAppId()\n             + \" is invalid, because it is out of the range [1, \"\n             + globalMaxAppAttempts + \"]. Use the global max attempts instead.\");\n       } else {\n         maxAppAttempts \u003d individualMaxAppAttempts;\n       }\n       // In work-preserve restart, if attemptCount \u003d\u003d maxAttempts, the job still\n       // needs to be recovered because the last attempt may still be running.\n       if(appState.getAttemptCount() \u003e\u003d maxAppAttempts) {\n         LOG.info(\"Not recovering application \" + appState.getAppId() +\n             \" due to recovering attempt is beyond maxAppAttempt limit\");\n         shouldRecover \u003d false;\n       }\n \n+      // re-submit the application\n+      // this is going to send an app start event but since the async dispatcher\n+      // has not started that event will be queued until we have completed re\n+      // populating the state\n       if(shouldRecover) {\n         LOG.info(\"Recovering application \" + appState.getAppId());\n         submitApplication(appState.getApplicationSubmissionContext(), \n                         appState.getSubmitTime(), true);\n         // re-populate attempt information in application\n         RMAppImpl appImpl \u003d (RMAppImpl) rmContext.getRMApps().get(\n                                                         appState.getAppId());\n         appImpl.recover(state);\n       }\n       else {\n         store.removeApplication(appState);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void recover(RMState state) throws Exception {\n    RMStateStore store \u003d rmContext.getStateStore();\n    assert store !\u003d null;\n    // recover applications\n    Map\u003cApplicationId, ApplicationState\u003e appStates \u003d state.getApplicationState();\n    LOG.info(\"Recovering \" + appStates.size() + \" applications\");\n    for(ApplicationState appState : appStates.values()) {\n      boolean shouldRecover \u003d true;\n      if(appState.getApplicationSubmissionContext().getUnmanagedAM()) {\n        // do not recover unmanaged applications since current recovery \n        // mechanism of restarting attempts does not work for them.\n        // This will need to be changed in work preserving recovery in which \n        // RM will re-connect with the running AM\u0027s instead of restarting them\n        LOG.info(\"Not recovering unmanaged application \" + appState.getAppId());\n        shouldRecover \u003d false;\n      }\n      int individualMaxAppAttempts \u003d appState.getApplicationSubmissionContext()\n          .getMaxAppAttempts();\n      int maxAppAttempts;\n      if (individualMaxAppAttempts \u003c\u003d 0 ||\n          individualMaxAppAttempts \u003e globalMaxAppAttempts) {\n        maxAppAttempts \u003d globalMaxAppAttempts;\n        LOG.warn(\"The specific max attempts: \" + individualMaxAppAttempts\n            + \" for application: \" + appState.getAppId()\n            + \" is invalid, because it is out of the range [1, \"\n            + globalMaxAppAttempts + \"]. Use the global max attempts instead.\");\n      } else {\n        maxAppAttempts \u003d individualMaxAppAttempts;\n      }\n      // In work-preserve restart, if attemptCount \u003d\u003d maxAttempts, the job still\n      // needs to be recovered because the last attempt may still be running.\n      if(appState.getAttemptCount() \u003e\u003d maxAppAttempts) {\n        LOG.info(\"Not recovering application \" + appState.getAppId() +\n            \" due to recovering attempt is beyond maxAppAttempt limit\");\n        shouldRecover \u003d false;\n      }\n\n      // re-submit the application\n      // this is going to send an app start event but since the async dispatcher\n      // has not started that event will be queued until we have completed re\n      // populating the state\n      if(shouldRecover) {\n        LOG.info(\"Recovering application \" + appState.getAppId());\n        submitApplication(appState.getApplicationSubmissionContext(), \n                        appState.getSubmitTime(), true);\n        // re-populate attempt information in application\n        RMAppImpl appImpl \u003d (RMAppImpl) rmContext.getRMApps().get(\n                                                        appState.getAppId());\n        appImpl.recover(state);\n      }\n      else {\n        store.removeApplication(appState);\n      }\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/RMAppManager.java",
      "extendedDetails": {}
    },
    "e24a9b83f137c7a27d57934580140693b5a86826": {
      "type": "Ybodychange",
      "commitMessage": "YARN-594. Update test and add comments in YARN-534 (Jian He via bikas)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1470243 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/04/13 3:04 PM",
      "commitName": "e24a9b83f137c7a27d57934580140693b5a86826",
      "commitAuthor": "Bikas Saha",
      "commitDateOld": "17/04/13 1:19 PM",
      "commitNameOld": "ef9f251679d7e87698eecd6a119652900274a172",
      "commitAuthorOld": "Bikas Saha",
      "daysBetweenCommits": 3.07,
      "commitsBetweenForRepo": 25,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,53 +1,55 @@\n   public void recover(RMState state) throws Exception {\n     RMStateStore store \u003d rmContext.getStateStore();\n     assert store !\u003d null;\n     // recover applications\n     Map\u003cApplicationId, ApplicationState\u003e appStates \u003d state.getApplicationState();\n     LOG.info(\"Recovering \" + appStates.size() + \" applications\");\n     for(ApplicationState appState : appStates.values()) {\n       boolean shouldRecover \u003d true;\n       // re-submit the application\n       // this is going to send an app start event but since the async dispatcher \n       // has not started that event will be queued until we have completed re\n       // populating the state\n       if(appState.getApplicationSubmissionContext().getUnmanagedAM()) {\n         // do not recover unmanaged applications since current recovery \n         // mechanism of restarting attempts does not work for them.\n         // This will need to be changed in work preserving recovery in which \n         // RM will re-connect with the running AM\u0027s instead of restarting them\n         LOG.info(\"Not recovering unmanaged application \" + appState.getAppId());\n         shouldRecover \u003d false;\n       }\n       int individualMaxAppAttempts \u003d appState.getApplicationSubmissionContext()\n           .getMaxAppAttempts();\n       int maxAppAttempts;\n       if (individualMaxAppAttempts \u003c\u003d 0 ||\n           individualMaxAppAttempts \u003e globalMaxAppAttempts) {\n         maxAppAttempts \u003d globalMaxAppAttempts;\n         LOG.warn(\"The specific max attempts: \" + individualMaxAppAttempts\n             + \" for application: \" + appState.getAppId()\n             + \" is invalid, because it is out of the range [1, \"\n             + globalMaxAppAttempts + \"]. Use the global max attempts instead.\");\n       } else {\n         maxAppAttempts \u003d individualMaxAppAttempts;\n       }\n+      // In work-preserve restart, if attemptCount \u003d\u003d maxAttempts, the job still\n+      // needs to be recovered because the last attempt may still be running.\n       if(appState.getAttemptCount() \u003e\u003d maxAppAttempts) {\n         LOG.info(\"Not recovering application \" + appState.getAppId() +\n             \" due to recovering attempt is beyond maxAppAttempt limit\");\n         shouldRecover \u003d false;\n       }\n \n       if(shouldRecover) {\n         LOG.info(\"Recovering application \" + appState.getAppId());\n         submitApplication(appState.getApplicationSubmissionContext(), \n                         appState.getSubmitTime(), true);\n         // re-populate attempt information in application\n         RMAppImpl appImpl \u003d (RMAppImpl) rmContext.getRMApps().get(\n                                                         appState.getAppId());\n         appImpl.recover(state);\n       }\n       else {\n         store.removeApplication(appState);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void recover(RMState state) throws Exception {\n    RMStateStore store \u003d rmContext.getStateStore();\n    assert store !\u003d null;\n    // recover applications\n    Map\u003cApplicationId, ApplicationState\u003e appStates \u003d state.getApplicationState();\n    LOG.info(\"Recovering \" + appStates.size() + \" applications\");\n    for(ApplicationState appState : appStates.values()) {\n      boolean shouldRecover \u003d true;\n      // re-submit the application\n      // this is going to send an app start event but since the async dispatcher \n      // has not started that event will be queued until we have completed re\n      // populating the state\n      if(appState.getApplicationSubmissionContext().getUnmanagedAM()) {\n        // do not recover unmanaged applications since current recovery \n        // mechanism of restarting attempts does not work for them.\n        // This will need to be changed in work preserving recovery in which \n        // RM will re-connect with the running AM\u0027s instead of restarting them\n        LOG.info(\"Not recovering unmanaged application \" + appState.getAppId());\n        shouldRecover \u003d false;\n      }\n      int individualMaxAppAttempts \u003d appState.getApplicationSubmissionContext()\n          .getMaxAppAttempts();\n      int maxAppAttempts;\n      if (individualMaxAppAttempts \u003c\u003d 0 ||\n          individualMaxAppAttempts \u003e globalMaxAppAttempts) {\n        maxAppAttempts \u003d globalMaxAppAttempts;\n        LOG.warn(\"The specific max attempts: \" + individualMaxAppAttempts\n            + \" for application: \" + appState.getAppId()\n            + \" is invalid, because it is out of the range [1, \"\n            + globalMaxAppAttempts + \"]. Use the global max attempts instead.\");\n      } else {\n        maxAppAttempts \u003d individualMaxAppAttempts;\n      }\n      // In work-preserve restart, if attemptCount \u003d\u003d maxAttempts, the job still\n      // needs to be recovered because the last attempt may still be running.\n      if(appState.getAttemptCount() \u003e\u003d maxAppAttempts) {\n        LOG.info(\"Not recovering application \" + appState.getAppId() +\n            \" due to recovering attempt is beyond maxAppAttempt limit\");\n        shouldRecover \u003d false;\n      }\n\n      if(shouldRecover) {\n        LOG.info(\"Recovering application \" + appState.getAppId());\n        submitApplication(appState.getApplicationSubmissionContext(), \n                        appState.getSubmitTime(), true);\n        // re-populate attempt information in application\n        RMAppImpl appImpl \u003d (RMAppImpl) rmContext.getRMApps().get(\n                                                        appState.getAppId());\n        appImpl.recover(state);\n      }\n      else {\n        store.removeApplication(appState);\n      }\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/RMAppManager.java",
      "extendedDetails": {}
    },
    "ef9f251679d7e87698eecd6a119652900274a172": {
      "type": "Ybodychange",
      "commitMessage": "YARN-514.Delayed store operations should not result in RM unavailability for app submission (Zhijie Shen via bikas)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1469059 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/04/13 1:19 PM",
      "commitName": "ef9f251679d7e87698eecd6a119652900274a172",
      "commitAuthor": "Bikas Saha",
      "commitDateOld": "11/04/13 12:28 PM",
      "commitNameOld": "e4c55e17fea55e2fcbef182bb2b0c4b22686f38c",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 6.04,
      "commitsBetweenForRepo": 26,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,53 +1,53 @@\n   public void recover(RMState state) throws Exception {\n     RMStateStore store \u003d rmContext.getStateStore();\n     assert store !\u003d null;\n     // recover applications\n     Map\u003cApplicationId, ApplicationState\u003e appStates \u003d state.getApplicationState();\n     LOG.info(\"Recovering \" + appStates.size() + \" applications\");\n     for(ApplicationState appState : appStates.values()) {\n       boolean shouldRecover \u003d true;\n       // re-submit the application\n       // this is going to send an app start event but since the async dispatcher \n       // has not started that event will be queued until we have completed re\n       // populating the state\n       if(appState.getApplicationSubmissionContext().getUnmanagedAM()) {\n         // do not recover unmanaged applications since current recovery \n         // mechanism of restarting attempts does not work for them.\n         // This will need to be changed in work preserving recovery in which \n         // RM will re-connect with the running AM\u0027s instead of restarting them\n         LOG.info(\"Not recovering unmanaged application \" + appState.getAppId());\n         shouldRecover \u003d false;\n       }\n       int individualMaxAppAttempts \u003d appState.getApplicationSubmissionContext()\n           .getMaxAppAttempts();\n       int maxAppAttempts;\n       if (individualMaxAppAttempts \u003c\u003d 0 ||\n           individualMaxAppAttempts \u003e globalMaxAppAttempts) {\n         maxAppAttempts \u003d globalMaxAppAttempts;\n         LOG.warn(\"The specific max attempts: \" + individualMaxAppAttempts\n             + \" for application: \" + appState.getAppId()\n             + \" is invalid, because it is out of the range [1, \"\n             + globalMaxAppAttempts + \"]. Use the global max attempts instead.\");\n       } else {\n         maxAppAttempts \u003d individualMaxAppAttempts;\n       }\n       if(appState.getAttemptCount() \u003e\u003d maxAppAttempts) {\n         LOG.info(\"Not recovering application \" + appState.getAppId() +\n             \" due to recovering attempt is beyond maxAppAttempt limit\");\n         shouldRecover \u003d false;\n       }\n \n       if(shouldRecover) {\n         LOG.info(\"Recovering application \" + appState.getAppId());\n         submitApplication(appState.getApplicationSubmissionContext(), \n-                        appState.getSubmitTime());\n+                        appState.getSubmitTime(), true);\n         // re-populate attempt information in application\n         RMAppImpl appImpl \u003d (RMAppImpl) rmContext.getRMApps().get(\n                                                         appState.getAppId());\n         appImpl.recover(state);\n       }\n       else {\n         store.removeApplication(appState);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void recover(RMState state) throws Exception {\n    RMStateStore store \u003d rmContext.getStateStore();\n    assert store !\u003d null;\n    // recover applications\n    Map\u003cApplicationId, ApplicationState\u003e appStates \u003d state.getApplicationState();\n    LOG.info(\"Recovering \" + appStates.size() + \" applications\");\n    for(ApplicationState appState : appStates.values()) {\n      boolean shouldRecover \u003d true;\n      // re-submit the application\n      // this is going to send an app start event but since the async dispatcher \n      // has not started that event will be queued until we have completed re\n      // populating the state\n      if(appState.getApplicationSubmissionContext().getUnmanagedAM()) {\n        // do not recover unmanaged applications since current recovery \n        // mechanism of restarting attempts does not work for them.\n        // This will need to be changed in work preserving recovery in which \n        // RM will re-connect with the running AM\u0027s instead of restarting them\n        LOG.info(\"Not recovering unmanaged application \" + appState.getAppId());\n        shouldRecover \u003d false;\n      }\n      int individualMaxAppAttempts \u003d appState.getApplicationSubmissionContext()\n          .getMaxAppAttempts();\n      int maxAppAttempts;\n      if (individualMaxAppAttempts \u003c\u003d 0 ||\n          individualMaxAppAttempts \u003e globalMaxAppAttempts) {\n        maxAppAttempts \u003d globalMaxAppAttempts;\n        LOG.warn(\"The specific max attempts: \" + individualMaxAppAttempts\n            + \" for application: \" + appState.getAppId()\n            + \" is invalid, because it is out of the range [1, \"\n            + globalMaxAppAttempts + \"]. Use the global max attempts instead.\");\n      } else {\n        maxAppAttempts \u003d individualMaxAppAttempts;\n      }\n      if(appState.getAttemptCount() \u003e\u003d maxAppAttempts) {\n        LOG.info(\"Not recovering application \" + appState.getAppId() +\n            \" due to recovering attempt is beyond maxAppAttempt limit\");\n        shouldRecover \u003d false;\n      }\n\n      if(shouldRecover) {\n        LOG.info(\"Recovering application \" + appState.getAppId());\n        submitApplication(appState.getApplicationSubmissionContext(), \n                        appState.getSubmitTime(), true);\n        // re-populate attempt information in application\n        RMAppImpl appImpl \u003d (RMAppImpl) rmContext.getRMApps().get(\n                                                        appState.getAppId());\n        appImpl.recover(state);\n      }\n      else {\n        store.removeApplication(appState);\n      }\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/RMAppManager.java",
      "extendedDetails": {}
    },
    "7d00d3d20fc33e2de85f3864e8a1ad68695c526e": {
      "type": "Ybodychange",
      "commitMessage": "YARN-534. Change RM restart recovery to also account for AM max-attempts configuration after the restart. Contributed by Jian He.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1466208 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/04/13 1:16 PM",
      "commitName": "7d00d3d20fc33e2de85f3864e8a1ad68695c526e",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "06/02/13 7:26 AM",
      "commitNameOld": "d27291842605555f6727faa4454211f55da28cca",
      "commitAuthorOld": "Daryn Sharp",
      "daysBetweenCommits": 62.2,
      "commitsBetweenForRepo": 292,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,29 +1,53 @@\n   public void recover(RMState state) throws Exception {\n     RMStateStore store \u003d rmContext.getStateStore();\n     assert store !\u003d null;\n     // recover applications\n     Map\u003cApplicationId, ApplicationState\u003e appStates \u003d state.getApplicationState();\n     LOG.info(\"Recovering \" + appStates.size() + \" applications\");\n     for(ApplicationState appState : appStates.values()) {\n+      boolean shouldRecover \u003d true;\n       // re-submit the application\n       // this is going to send an app start event but since the async dispatcher \n       // has not started that event will be queued until we have completed re\n       // populating the state\n       if(appState.getApplicationSubmissionContext().getUnmanagedAM()) {\n         // do not recover unmanaged applications since current recovery \n         // mechanism of restarting attempts does not work for them.\n         // This will need to be changed in work preserving recovery in which \n         // RM will re-connect with the running AM\u0027s instead of restarting them\n         LOG.info(\"Not recovering unmanaged application \" + appState.getAppId());\n-        store.removeApplication(appState);\n+        shouldRecover \u003d false;\n+      }\n+      int individualMaxAppAttempts \u003d appState.getApplicationSubmissionContext()\n+          .getMaxAppAttempts();\n+      int maxAppAttempts;\n+      if (individualMaxAppAttempts \u003c\u003d 0 ||\n+          individualMaxAppAttempts \u003e globalMaxAppAttempts) {\n+        maxAppAttempts \u003d globalMaxAppAttempts;\n+        LOG.warn(\"The specific max attempts: \" + individualMaxAppAttempts\n+            + \" for application: \" + appState.getAppId()\n+            + \" is invalid, because it is out of the range [1, \"\n+            + globalMaxAppAttempts + \"]. Use the global max attempts instead.\");\n       } else {\n+        maxAppAttempts \u003d individualMaxAppAttempts;\n+      }\n+      if(appState.getAttemptCount() \u003e\u003d maxAppAttempts) {\n+        LOG.info(\"Not recovering application \" + appState.getAppId() +\n+            \" due to recovering attempt is beyond maxAppAttempt limit\");\n+        shouldRecover \u003d false;\n+      }\n+\n+      if(shouldRecover) {\n         LOG.info(\"Recovering application \" + appState.getAppId());\n         submitApplication(appState.getApplicationSubmissionContext(), \n-                          appState.getSubmitTime());\n+                        appState.getSubmitTime());\n         // re-populate attempt information in application\n         RMAppImpl appImpl \u003d (RMAppImpl) rmContext.getRMApps().get(\n-                                                          appState.getAppId());\n+                                                        appState.getAppId());\n         appImpl.recover(state);\n       }\n+      else {\n+        store.removeApplication(appState);\n+      }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void recover(RMState state) throws Exception {\n    RMStateStore store \u003d rmContext.getStateStore();\n    assert store !\u003d null;\n    // recover applications\n    Map\u003cApplicationId, ApplicationState\u003e appStates \u003d state.getApplicationState();\n    LOG.info(\"Recovering \" + appStates.size() + \" applications\");\n    for(ApplicationState appState : appStates.values()) {\n      boolean shouldRecover \u003d true;\n      // re-submit the application\n      // this is going to send an app start event but since the async dispatcher \n      // has not started that event will be queued until we have completed re\n      // populating the state\n      if(appState.getApplicationSubmissionContext().getUnmanagedAM()) {\n        // do not recover unmanaged applications since current recovery \n        // mechanism of restarting attempts does not work for them.\n        // This will need to be changed in work preserving recovery in which \n        // RM will re-connect with the running AM\u0027s instead of restarting them\n        LOG.info(\"Not recovering unmanaged application \" + appState.getAppId());\n        shouldRecover \u003d false;\n      }\n      int individualMaxAppAttempts \u003d appState.getApplicationSubmissionContext()\n          .getMaxAppAttempts();\n      int maxAppAttempts;\n      if (individualMaxAppAttempts \u003c\u003d 0 ||\n          individualMaxAppAttempts \u003e globalMaxAppAttempts) {\n        maxAppAttempts \u003d globalMaxAppAttempts;\n        LOG.warn(\"The specific max attempts: \" + individualMaxAppAttempts\n            + \" for application: \" + appState.getAppId()\n            + \" is invalid, because it is out of the range [1, \"\n            + globalMaxAppAttempts + \"]. Use the global max attempts instead.\");\n      } else {\n        maxAppAttempts \u003d individualMaxAppAttempts;\n      }\n      if(appState.getAttemptCount() \u003e\u003d maxAppAttempts) {\n        LOG.info(\"Not recovering application \" + appState.getAppId() +\n            \" due to recovering attempt is beyond maxAppAttempt limit\");\n        shouldRecover \u003d false;\n      }\n\n      if(shouldRecover) {\n        LOG.info(\"Recovering application \" + appState.getAppId());\n        submitApplication(appState.getApplicationSubmissionContext(), \n                        appState.getSubmitTime());\n        // re-populate attempt information in application\n        RMAppImpl appImpl \u003d (RMAppImpl) rmContext.getRMApps().get(\n                                                        appState.getAppId());\n        appImpl.recover(state);\n      }\n      else {\n        store.removeApplication(appState);\n      }\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/RMAppManager.java",
      "extendedDetails": {}
    },
    "6cd0736cc57849e4f7c5d38a3986432a9717fe39": {
      "type": "Yintroduced",
      "commitMessage": "YARN-230. RM Restart phase 1 - includes support for saving/restarting all applications on an RM bounce. Contributed by Bikas Saha.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1423758 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/12/12 8:21 PM",
      "commitName": "6cd0736cc57849e4f7c5d38a3986432a9717fe39",
      "commitAuthor": "Arun Murthy",
      "diff": "@@ -0,0 +1,29 @@\n+  public void recover(RMState state) throws Exception {\n+    RMStateStore store \u003d rmContext.getStateStore();\n+    assert store !\u003d null;\n+    // recover applications\n+    Map\u003cApplicationId, ApplicationState\u003e appStates \u003d state.getApplicationState();\n+    LOG.info(\"Recovering \" + appStates.size() + \" applications\");\n+    for(ApplicationState appState : appStates.values()) {\n+      // re-submit the application\n+      // this is going to send an app start event but since the async dispatcher \n+      // has not started that event will be queued until we have completed re\n+      // populating the state\n+      if(appState.getApplicationSubmissionContext().getUnmanagedAM()) {\n+        // do not recover unmanaged applications since current recovery \n+        // mechanism of restarting attempts does not work for them.\n+        // This will need to be changed in work preserving recovery in which \n+        // RM will re-connect with the running AM\u0027s instead of restarting them\n+        LOG.info(\"Not recovering unmanaged application \" + appState.getAppId());\n+        store.removeApplication(appState);\n+      } else {\n+        LOG.info(\"Recovering application \" + appState.getAppId());\n+        submitApplication(appState.getApplicationSubmissionContext(), \n+                          appState.getSubmitTime());\n+        // re-populate attempt information in application\n+        RMAppImpl appImpl \u003d (RMAppImpl) rmContext.getRMApps().get(\n+                                                          appState.getAppId());\n+        appImpl.recover(state);\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void recover(RMState state) throws Exception {\n    RMStateStore store \u003d rmContext.getStateStore();\n    assert store !\u003d null;\n    // recover applications\n    Map\u003cApplicationId, ApplicationState\u003e appStates \u003d state.getApplicationState();\n    LOG.info(\"Recovering \" + appStates.size() + \" applications\");\n    for(ApplicationState appState : appStates.values()) {\n      // re-submit the application\n      // this is going to send an app start event but since the async dispatcher \n      // has not started that event will be queued until we have completed re\n      // populating the state\n      if(appState.getApplicationSubmissionContext().getUnmanagedAM()) {\n        // do not recover unmanaged applications since current recovery \n        // mechanism of restarting attempts does not work for them.\n        // This will need to be changed in work preserving recovery in which \n        // RM will re-connect with the running AM\u0027s instead of restarting them\n        LOG.info(\"Not recovering unmanaged application \" + appState.getAppId());\n        store.removeApplication(appState);\n      } else {\n        LOG.info(\"Recovering application \" + appState.getAppId());\n        submitApplication(appState.getApplicationSubmissionContext(), \n                          appState.getSubmitTime());\n        // re-populate attempt information in application\n        RMAppImpl appImpl \u003d (RMAppImpl) rmContext.getRMApps().get(\n                                                          appState.getAppId());\n        appImpl.recover(state);\n      }\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/RMAppManager.java"
    }
  }
}