{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "StripedBlockChecksumReconstructor.java",
  "functionName": "reconstruct",
  "functionId": "reconstruct",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/erasurecode/StripedBlockChecksumReconstructor.java",
  "functionStartLine": 73,
  "functionEndLine": 101,
  "numCommitsSeen": 12,
  "timeTaken": 3892,
  "changeHistory": [
    "7c9cdad6d04c98db5a83e2108219bf6e6c903daf",
    "84d787b9d51196010495d51dc5ebf66c01c340ab",
    "e6cb07520f935efde3e881de8f84ee7f6e0a746f",
    "d749cf65e1ab0e0daf5be86931507183f189e855",
    "3c18a53cbd2efabb2ad108d63a0b0b558424115f"
  ],
  "changeHistoryShort": {
    "7c9cdad6d04c98db5a83e2108219bf6e6c903daf": "Ybodychange",
    "84d787b9d51196010495d51dc5ebf66c01c340ab": "Ybodychange",
    "e6cb07520f935efde3e881de8f84ee7f6e0a746f": "Ybodychange",
    "d749cf65e1ab0e0daf5be86931507183f189e855": "Ymultichange(Ymovefromfile,Ymodifierchange,Ybodychange,Yrename)",
    "3c18a53cbd2efabb2ad108d63a0b0b558424115f": "Yintroduced"
  },
  "changeHistoryDetails": {
    "7c9cdad6d04c98db5a83e2108219bf6e6c903daf": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13056. Expose file-level composite CRCs in HDFS which are comparable across different instances/layouts. Contributed by Dennis Huo.\n",
      "commitDate": "10/04/18 9:31 PM",
      "commitName": "7c9cdad6d04c98db5a83e2108219bf6e6c903daf",
      "commitAuthor": "Xiao Chen",
      "commitDateOld": "13/12/17 2:56 PM",
      "commitNameOld": "46e18c8da76ea8d91a16e59ba1154c30f37cb9fd",
      "commitAuthorOld": "Chen Liang",
      "daysBetweenCommits": 118.23,
      "commitsBetweenForRepo": 858,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,31 +1,29 @@\n   public void reconstruct() throws IOException {\n-    MessageDigest digester \u003d MD5Hash.getDigester();\n+    prepareDigester();\n     long maxTargetLength \u003d getMaxTargetLength();\n     try {\n       while (requestedLen \u003e 0 \u0026\u0026 getPositionInBlock() \u003c maxTargetLength) {\n         long remaining \u003d maxTargetLength - getPositionInBlock();\n         final int toReconstructLen \u003d (int) Math\n             .min(getStripedReader().getBufferSize(), remaining);\n         // step1: read from minimum source DNs required for reconstruction.\n         // The returned success list is the source DNs we do real read from\n         getStripedReader().readMinimumSources(toReconstructLen);\n \n         // step2: decode to reconstruct targets\n         reconstructTargets(toReconstructLen);\n \n         // step3: calculate checksum\n-        checksumDataLen +\u003d checksumWithTargetOutput(targetBuffer.array(),\n-            toReconstructLen, digester);\n+        checksumDataLen +\u003d checksumWithTargetOutput(\n+            targetBuffer.array(), toReconstructLen);\n \n         updatePositionInBlock(toReconstructLen);\n         requestedLen -\u003d toReconstructLen;\n         clearBuffers();\n       }\n \n-      byte[] digest \u003d digester.digest();\n-      md5 \u003d new MD5Hash(digest);\n-      md5.write(checksumWriter);\n+      commitDigest();\n     } finally {\n       cleanup();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void reconstruct() throws IOException {\n    prepareDigester();\n    long maxTargetLength \u003d getMaxTargetLength();\n    try {\n      while (requestedLen \u003e 0 \u0026\u0026 getPositionInBlock() \u003c maxTargetLength) {\n        long remaining \u003d maxTargetLength - getPositionInBlock();\n        final int toReconstructLen \u003d (int) Math\n            .min(getStripedReader().getBufferSize(), remaining);\n        // step1: read from minimum source DNs required for reconstruction.\n        // The returned success list is the source DNs we do real read from\n        getStripedReader().readMinimumSources(toReconstructLen);\n\n        // step2: decode to reconstruct targets\n        reconstructTargets(toReconstructLen);\n\n        // step3: calculate checksum\n        checksumDataLen +\u003d checksumWithTargetOutput(\n            targetBuffer.array(), toReconstructLen);\n\n        updatePositionInBlock(toReconstructLen);\n        requestedLen -\u003d toReconstructLen;\n        clearBuffers();\n      }\n\n      commitDigest();\n    } finally {\n      cleanup();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/erasurecode/StripedBlockChecksumReconstructor.java",
      "extendedDetails": {}
    },
    "84d787b9d51196010495d51dc5ebf66c01c340ab": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11541. Call RawErasureEncoder and RawErasureDecoder release() methods. Contributed by SammiChen.\n",
      "commitDate": "28/03/17 11:11 PM",
      "commitName": "84d787b9d51196010495d51dc5ebf66c01c340ab",
      "commitAuthor": "Rakesh Radhakrishnan",
      "commitDateOld": "25/10/16 8:40 PM",
      "commitNameOld": "287effff9327450240d65e27e31bed2649a7a100",
      "commitAuthorOld": "Kai Zheng",
      "daysBetweenCommits": 154.11,
      "commitsBetweenForRepo": 930,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,27 +1,31 @@\n   public void reconstruct() throws IOException {\n     MessageDigest digester \u003d MD5Hash.getDigester();\n     long maxTargetLength \u003d getMaxTargetLength();\n-    while (requestedLen \u003e 0 \u0026\u0026 getPositionInBlock() \u003c maxTargetLength) {\n-      long remaining \u003d maxTargetLength - getPositionInBlock();\n-      final int toReconstructLen \u003d (int) Math\n-          .min(getStripedReader().getBufferSize(), remaining);\n-      // step1: read from minimum source DNs required for reconstruction.\n-      // The returned success list is the source DNs we do real read from\n-      getStripedReader().readMinimumSources(toReconstructLen);\n+    try {\n+      while (requestedLen \u003e 0 \u0026\u0026 getPositionInBlock() \u003c maxTargetLength) {\n+        long remaining \u003d maxTargetLength - getPositionInBlock();\n+        final int toReconstructLen \u003d (int) Math\n+            .min(getStripedReader().getBufferSize(), remaining);\n+        // step1: read from minimum source DNs required for reconstruction.\n+        // The returned success list is the source DNs we do real read from\n+        getStripedReader().readMinimumSources(toReconstructLen);\n \n-      // step2: decode to reconstruct targets\n-      reconstructTargets(toReconstructLen);\n+        // step2: decode to reconstruct targets\n+        reconstructTargets(toReconstructLen);\n \n-      // step3: calculate checksum\n-      checksumDataLen +\u003d checksumWithTargetOutput(targetBuffer.array(),\n-          toReconstructLen, digester);\n+        // step3: calculate checksum\n+        checksumDataLen +\u003d checksumWithTargetOutput(targetBuffer.array(),\n+            toReconstructLen, digester);\n \n-      updatePositionInBlock(toReconstructLen);\n-      requestedLen -\u003d toReconstructLen;\n-      clearBuffers();\n+        updatePositionInBlock(toReconstructLen);\n+        requestedLen -\u003d toReconstructLen;\n+        clearBuffers();\n+      }\n+\n+      byte[] digest \u003d digester.digest();\n+      md5 \u003d new MD5Hash(digest);\n+      md5.write(checksumWriter);\n+    } finally {\n+      cleanup();\n     }\n-\n-    byte[] digest \u003d digester.digest();\n-    md5 \u003d new MD5Hash(digest);\n-    md5.write(checksumWriter);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void reconstruct() throws IOException {\n    MessageDigest digester \u003d MD5Hash.getDigester();\n    long maxTargetLength \u003d getMaxTargetLength();\n    try {\n      while (requestedLen \u003e 0 \u0026\u0026 getPositionInBlock() \u003c maxTargetLength) {\n        long remaining \u003d maxTargetLength - getPositionInBlock();\n        final int toReconstructLen \u003d (int) Math\n            .min(getStripedReader().getBufferSize(), remaining);\n        // step1: read from minimum source DNs required for reconstruction.\n        // The returned success list is the source DNs we do real read from\n        getStripedReader().readMinimumSources(toReconstructLen);\n\n        // step2: decode to reconstruct targets\n        reconstructTargets(toReconstructLen);\n\n        // step3: calculate checksum\n        checksumDataLen +\u003d checksumWithTargetOutput(targetBuffer.array(),\n            toReconstructLen, digester);\n\n        updatePositionInBlock(toReconstructLen);\n        requestedLen -\u003d toReconstructLen;\n        clearBuffers();\n      }\n\n      byte[] digest \u003d digester.digest();\n      md5 \u003d new MD5Hash(digest);\n      md5.write(checksumWriter);\n    } finally {\n      cleanup();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/erasurecode/StripedBlockChecksumReconstructor.java",
      "extendedDetails": {}
    },
    "e6cb07520f935efde3e881de8f84ee7f6e0a746f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10460. Recompute block checksum for a particular range less than file size on the fly by reconstructing missed block. Contributed by Rakesh R\n",
      "commitDate": "24/06/16 2:39 AM",
      "commitName": "e6cb07520f935efde3e881de8f84ee7f6e0a746f",
      "commitAuthor": "Kai Zheng",
      "commitDateOld": "01/06/16 9:56 PM",
      "commitNameOld": "d749cf65e1ab0e0daf5be86931507183f189e855",
      "commitAuthorOld": "Kai Zheng",
      "daysBetweenCommits": 22.2,
      "commitsBetweenForRepo": 141,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,28 +1,27 @@\n   public void reconstruct() throws IOException {\n     MessageDigest digester \u003d MD5Hash.getDigester();\n-    while (getPositionInBlock() \u003c getMaxTargetLength()) {\n-      long remaining \u003d getMaxTargetLength() - getPositionInBlock();\n+    long maxTargetLength \u003d getMaxTargetLength();\n+    while (requestedLen \u003e 0 \u0026\u0026 getPositionInBlock() \u003c maxTargetLength) {\n+      long remaining \u003d maxTargetLength - getPositionInBlock();\n       final int toReconstructLen \u003d (int) Math\n           .min(getStripedReader().getBufferSize(), remaining);\n       // step1: read from minimum source DNs required for reconstruction.\n       // The returned success list is the source DNs we do real read from\n       getStripedReader().readMinimumSources(toReconstructLen);\n \n       // step2: decode to reconstruct targets\n       reconstructTargets(toReconstructLen);\n \n       // step3: calculate checksum\n-      getChecksum().calculateChunkedSums(targetBuffer.array(), 0,\n-          targetBuffer.remaining(), checksumBuf, 0);\n+      checksumDataLen +\u003d checksumWithTargetOutput(targetBuffer.array(),\n+          toReconstructLen, digester);\n \n-      // step4: updates the digest using the checksum array of bytes\n-      digester.update(checksumBuf, 0, checksumBuf.length);\n-      checksumDataLen +\u003d checksumBuf.length;\n       updatePositionInBlock(toReconstructLen);\n+      requestedLen -\u003d toReconstructLen;\n       clearBuffers();\n     }\n \n     byte[] digest \u003d digester.digest();\n     md5 \u003d new MD5Hash(digest);\n     md5.write(checksumWriter);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void reconstruct() throws IOException {\n    MessageDigest digester \u003d MD5Hash.getDigester();\n    long maxTargetLength \u003d getMaxTargetLength();\n    while (requestedLen \u003e 0 \u0026\u0026 getPositionInBlock() \u003c maxTargetLength) {\n      long remaining \u003d maxTargetLength - getPositionInBlock();\n      final int toReconstructLen \u003d (int) Math\n          .min(getStripedReader().getBufferSize(), remaining);\n      // step1: read from minimum source DNs required for reconstruction.\n      // The returned success list is the source DNs we do real read from\n      getStripedReader().readMinimumSources(toReconstructLen);\n\n      // step2: decode to reconstruct targets\n      reconstructTargets(toReconstructLen);\n\n      // step3: calculate checksum\n      checksumDataLen +\u003d checksumWithTargetOutput(targetBuffer.array(),\n          toReconstructLen, digester);\n\n      updatePositionInBlock(toReconstructLen);\n      requestedLen -\u003d toReconstructLen;\n      clearBuffers();\n    }\n\n    byte[] digest \u003d digester.digest();\n    md5 \u003d new MD5Hash(digest);\n    md5.write(checksumWriter);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/erasurecode/StripedBlockChecksumReconstructor.java",
      "extendedDetails": {}
    },
    "d749cf65e1ab0e0daf5be86931507183f189e855": {
      "type": "Ymultichange(Ymovefromfile,Ymodifierchange,Ybodychange,Yrename)",
      "commitMessage": "HDFS-9833. Erasure coding: recomputing block checksum on the fly by reconstructing the missed/corrupt block data. Contributed by Rakesh R.\n",
      "commitDate": "01/06/16 9:56 PM",
      "commitName": "d749cf65e1ab0e0daf5be86931507183f189e855",
      "commitAuthor": "Kai Zheng",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-9833. Erasure coding: recomputing block checksum on the fly by reconstructing the missed/corrupt block data. Contributed by Rakesh R.\n",
          "commitDate": "01/06/16 9:56 PM",
          "commitName": "d749cf65e1ab0e0daf5be86931507183f189e855",
          "commitAuthor": "Kai Zheng",
          "commitDateOld": "31/05/16 5:54 PM",
          "commitNameOld": "8ceb06e2392763726210f96bb1c176e6a9fe7b53",
          "commitAuthorOld": "Colin Patrick Mccabe",
          "daysBetweenCommits": 1.17,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,23 +1,28 @@\n-  void reconstructAndTransfer() throws IOException {\n-    while (positionInBlock \u003c stripedWriter.getMaxTargetLength()) {\n-      long remaining \u003d stripedWriter.getMaxTargetLength() - positionInBlock;\n-      final int toReconstructLen \u003d\n-          (int) Math.min(stripedReader.getBufferSize(), remaining);\n+  public void reconstruct() throws IOException {\n+    MessageDigest digester \u003d MD5Hash.getDigester();\n+    while (getPositionInBlock() \u003c getMaxTargetLength()) {\n+      long remaining \u003d getMaxTargetLength() - getPositionInBlock();\n+      final int toReconstructLen \u003d (int) Math\n+          .min(getStripedReader().getBufferSize(), remaining);\n       // step1: read from minimum source DNs required for reconstruction.\n       // The returned success list is the source DNs we do real read from\n-      stripedReader.readMinimumSources(toReconstructLen);\n+      getStripedReader().readMinimumSources(toReconstructLen);\n \n       // step2: decode to reconstruct targets\n       reconstructTargets(toReconstructLen);\n \n-      // step3: transfer data\n-      if (stripedWriter.transferData2Targets() \u003d\u003d 0) {\n-        String error \u003d \"Transfer failed for all targets.\";\n-        throw new IOException(error);\n-      }\n+      // step3: calculate checksum\n+      getChecksum().calculateChunkedSums(targetBuffer.array(), 0,\n+          targetBuffer.remaining(), checksumBuf, 0);\n \n-      positionInBlock +\u003d toReconstructLen;\n-\n+      // step4: updates the digest using the checksum array of bytes\n+      digester.update(checksumBuf, 0, checksumBuf.length);\n+      checksumDataLen +\u003d checksumBuf.length;\n+      updatePositionInBlock(toReconstructLen);\n       clearBuffers();\n     }\n+\n+    byte[] digest \u003d digester.digest();\n+    md5 \u003d new MD5Hash(digest);\n+    md5.write(checksumWriter);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void reconstruct() throws IOException {\n    MessageDigest digester \u003d MD5Hash.getDigester();\n    while (getPositionInBlock() \u003c getMaxTargetLength()) {\n      long remaining \u003d getMaxTargetLength() - getPositionInBlock();\n      final int toReconstructLen \u003d (int) Math\n          .min(getStripedReader().getBufferSize(), remaining);\n      // step1: read from minimum source DNs required for reconstruction.\n      // The returned success list is the source DNs we do real read from\n      getStripedReader().readMinimumSources(toReconstructLen);\n\n      // step2: decode to reconstruct targets\n      reconstructTargets(toReconstructLen);\n\n      // step3: calculate checksum\n      getChecksum().calculateChunkedSums(targetBuffer.array(), 0,\n          targetBuffer.remaining(), checksumBuf, 0);\n\n      // step4: updates the digest using the checksum array of bytes\n      digester.update(checksumBuf, 0, checksumBuf.length);\n      checksumDataLen +\u003d checksumBuf.length;\n      updatePositionInBlock(toReconstructLen);\n      clearBuffers();\n    }\n\n    byte[] digest \u003d digester.digest();\n    md5 \u003d new MD5Hash(digest);\n    md5.write(checksumWriter);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/erasurecode/StripedBlockChecksumReconstructor.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/erasurecode/StripedReconstructor.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/erasurecode/StripedBlockChecksumReconstructor.java",
            "oldMethodName": "reconstructAndTransfer",
            "newMethodName": "reconstruct"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-9833. Erasure coding: recomputing block checksum on the fly by reconstructing the missed/corrupt block data. Contributed by Rakesh R.\n",
          "commitDate": "01/06/16 9:56 PM",
          "commitName": "d749cf65e1ab0e0daf5be86931507183f189e855",
          "commitAuthor": "Kai Zheng",
          "commitDateOld": "31/05/16 5:54 PM",
          "commitNameOld": "8ceb06e2392763726210f96bb1c176e6a9fe7b53",
          "commitAuthorOld": "Colin Patrick Mccabe",
          "daysBetweenCommits": 1.17,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,23 +1,28 @@\n-  void reconstructAndTransfer() throws IOException {\n-    while (positionInBlock \u003c stripedWriter.getMaxTargetLength()) {\n-      long remaining \u003d stripedWriter.getMaxTargetLength() - positionInBlock;\n-      final int toReconstructLen \u003d\n-          (int) Math.min(stripedReader.getBufferSize(), remaining);\n+  public void reconstruct() throws IOException {\n+    MessageDigest digester \u003d MD5Hash.getDigester();\n+    while (getPositionInBlock() \u003c getMaxTargetLength()) {\n+      long remaining \u003d getMaxTargetLength() - getPositionInBlock();\n+      final int toReconstructLen \u003d (int) Math\n+          .min(getStripedReader().getBufferSize(), remaining);\n       // step1: read from minimum source DNs required for reconstruction.\n       // The returned success list is the source DNs we do real read from\n-      stripedReader.readMinimumSources(toReconstructLen);\n+      getStripedReader().readMinimumSources(toReconstructLen);\n \n       // step2: decode to reconstruct targets\n       reconstructTargets(toReconstructLen);\n \n-      // step3: transfer data\n-      if (stripedWriter.transferData2Targets() \u003d\u003d 0) {\n-        String error \u003d \"Transfer failed for all targets.\";\n-        throw new IOException(error);\n-      }\n+      // step3: calculate checksum\n+      getChecksum().calculateChunkedSums(targetBuffer.array(), 0,\n+          targetBuffer.remaining(), checksumBuf, 0);\n \n-      positionInBlock +\u003d toReconstructLen;\n-\n+      // step4: updates the digest using the checksum array of bytes\n+      digester.update(checksumBuf, 0, checksumBuf.length);\n+      checksumDataLen +\u003d checksumBuf.length;\n+      updatePositionInBlock(toReconstructLen);\n       clearBuffers();\n     }\n+\n+    byte[] digest \u003d digester.digest();\n+    md5 \u003d new MD5Hash(digest);\n+    md5.write(checksumWriter);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void reconstruct() throws IOException {\n    MessageDigest digester \u003d MD5Hash.getDigester();\n    while (getPositionInBlock() \u003c getMaxTargetLength()) {\n      long remaining \u003d getMaxTargetLength() - getPositionInBlock();\n      final int toReconstructLen \u003d (int) Math\n          .min(getStripedReader().getBufferSize(), remaining);\n      // step1: read from minimum source DNs required for reconstruction.\n      // The returned success list is the source DNs we do real read from\n      getStripedReader().readMinimumSources(toReconstructLen);\n\n      // step2: decode to reconstruct targets\n      reconstructTargets(toReconstructLen);\n\n      // step3: calculate checksum\n      getChecksum().calculateChunkedSums(targetBuffer.array(), 0,\n          targetBuffer.remaining(), checksumBuf, 0);\n\n      // step4: updates the digest using the checksum array of bytes\n      digester.update(checksumBuf, 0, checksumBuf.length);\n      checksumDataLen +\u003d checksumBuf.length;\n      updatePositionInBlock(toReconstructLen);\n      clearBuffers();\n    }\n\n    byte[] digest \u003d digester.digest();\n    md5 \u003d new MD5Hash(digest);\n    md5.write(checksumWriter);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/erasurecode/StripedBlockChecksumReconstructor.java",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[public]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-9833. Erasure coding: recomputing block checksum on the fly by reconstructing the missed/corrupt block data. Contributed by Rakesh R.\n",
          "commitDate": "01/06/16 9:56 PM",
          "commitName": "d749cf65e1ab0e0daf5be86931507183f189e855",
          "commitAuthor": "Kai Zheng",
          "commitDateOld": "31/05/16 5:54 PM",
          "commitNameOld": "8ceb06e2392763726210f96bb1c176e6a9fe7b53",
          "commitAuthorOld": "Colin Patrick Mccabe",
          "daysBetweenCommits": 1.17,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,23 +1,28 @@\n-  void reconstructAndTransfer() throws IOException {\n-    while (positionInBlock \u003c stripedWriter.getMaxTargetLength()) {\n-      long remaining \u003d stripedWriter.getMaxTargetLength() - positionInBlock;\n-      final int toReconstructLen \u003d\n-          (int) Math.min(stripedReader.getBufferSize(), remaining);\n+  public void reconstruct() throws IOException {\n+    MessageDigest digester \u003d MD5Hash.getDigester();\n+    while (getPositionInBlock() \u003c getMaxTargetLength()) {\n+      long remaining \u003d getMaxTargetLength() - getPositionInBlock();\n+      final int toReconstructLen \u003d (int) Math\n+          .min(getStripedReader().getBufferSize(), remaining);\n       // step1: read from minimum source DNs required for reconstruction.\n       // The returned success list is the source DNs we do real read from\n-      stripedReader.readMinimumSources(toReconstructLen);\n+      getStripedReader().readMinimumSources(toReconstructLen);\n \n       // step2: decode to reconstruct targets\n       reconstructTargets(toReconstructLen);\n \n-      // step3: transfer data\n-      if (stripedWriter.transferData2Targets() \u003d\u003d 0) {\n-        String error \u003d \"Transfer failed for all targets.\";\n-        throw new IOException(error);\n-      }\n+      // step3: calculate checksum\n+      getChecksum().calculateChunkedSums(targetBuffer.array(), 0,\n+          targetBuffer.remaining(), checksumBuf, 0);\n \n-      positionInBlock +\u003d toReconstructLen;\n-\n+      // step4: updates the digest using the checksum array of bytes\n+      digester.update(checksumBuf, 0, checksumBuf.length);\n+      checksumDataLen +\u003d checksumBuf.length;\n+      updatePositionInBlock(toReconstructLen);\n       clearBuffers();\n     }\n+\n+    byte[] digest \u003d digester.digest();\n+    md5 \u003d new MD5Hash(digest);\n+    md5.write(checksumWriter);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void reconstruct() throws IOException {\n    MessageDigest digester \u003d MD5Hash.getDigester();\n    while (getPositionInBlock() \u003c getMaxTargetLength()) {\n      long remaining \u003d getMaxTargetLength() - getPositionInBlock();\n      final int toReconstructLen \u003d (int) Math\n          .min(getStripedReader().getBufferSize(), remaining);\n      // step1: read from minimum source DNs required for reconstruction.\n      // The returned success list is the source DNs we do real read from\n      getStripedReader().readMinimumSources(toReconstructLen);\n\n      // step2: decode to reconstruct targets\n      reconstructTargets(toReconstructLen);\n\n      // step3: calculate checksum\n      getChecksum().calculateChunkedSums(targetBuffer.array(), 0,\n          targetBuffer.remaining(), checksumBuf, 0);\n\n      // step4: updates the digest using the checksum array of bytes\n      digester.update(checksumBuf, 0, checksumBuf.length);\n      checksumDataLen +\u003d checksumBuf.length;\n      updatePositionInBlock(toReconstructLen);\n      clearBuffers();\n    }\n\n    byte[] digest \u003d digester.digest();\n    md5 \u003d new MD5Hash(digest);\n    md5.write(checksumWriter);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/erasurecode/StripedBlockChecksumReconstructor.java",
          "extendedDetails": {}
        },
        {
          "type": "Yrename",
          "commitMessage": "HDFS-9833. Erasure coding: recomputing block checksum on the fly by reconstructing the missed/corrupt block data. Contributed by Rakesh R.\n",
          "commitDate": "01/06/16 9:56 PM",
          "commitName": "d749cf65e1ab0e0daf5be86931507183f189e855",
          "commitAuthor": "Kai Zheng",
          "commitDateOld": "31/05/16 5:54 PM",
          "commitNameOld": "8ceb06e2392763726210f96bb1c176e6a9fe7b53",
          "commitAuthorOld": "Colin Patrick Mccabe",
          "daysBetweenCommits": 1.17,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,23 +1,28 @@\n-  void reconstructAndTransfer() throws IOException {\n-    while (positionInBlock \u003c stripedWriter.getMaxTargetLength()) {\n-      long remaining \u003d stripedWriter.getMaxTargetLength() - positionInBlock;\n-      final int toReconstructLen \u003d\n-          (int) Math.min(stripedReader.getBufferSize(), remaining);\n+  public void reconstruct() throws IOException {\n+    MessageDigest digester \u003d MD5Hash.getDigester();\n+    while (getPositionInBlock() \u003c getMaxTargetLength()) {\n+      long remaining \u003d getMaxTargetLength() - getPositionInBlock();\n+      final int toReconstructLen \u003d (int) Math\n+          .min(getStripedReader().getBufferSize(), remaining);\n       // step1: read from minimum source DNs required for reconstruction.\n       // The returned success list is the source DNs we do real read from\n-      stripedReader.readMinimumSources(toReconstructLen);\n+      getStripedReader().readMinimumSources(toReconstructLen);\n \n       // step2: decode to reconstruct targets\n       reconstructTargets(toReconstructLen);\n \n-      // step3: transfer data\n-      if (stripedWriter.transferData2Targets() \u003d\u003d 0) {\n-        String error \u003d \"Transfer failed for all targets.\";\n-        throw new IOException(error);\n-      }\n+      // step3: calculate checksum\n+      getChecksum().calculateChunkedSums(targetBuffer.array(), 0,\n+          targetBuffer.remaining(), checksumBuf, 0);\n \n-      positionInBlock +\u003d toReconstructLen;\n-\n+      // step4: updates the digest using the checksum array of bytes\n+      digester.update(checksumBuf, 0, checksumBuf.length);\n+      checksumDataLen +\u003d checksumBuf.length;\n+      updatePositionInBlock(toReconstructLen);\n       clearBuffers();\n     }\n+\n+    byte[] digest \u003d digester.digest();\n+    md5 \u003d new MD5Hash(digest);\n+    md5.write(checksumWriter);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void reconstruct() throws IOException {\n    MessageDigest digester \u003d MD5Hash.getDigester();\n    while (getPositionInBlock() \u003c getMaxTargetLength()) {\n      long remaining \u003d getMaxTargetLength() - getPositionInBlock();\n      final int toReconstructLen \u003d (int) Math\n          .min(getStripedReader().getBufferSize(), remaining);\n      // step1: read from minimum source DNs required for reconstruction.\n      // The returned success list is the source DNs we do real read from\n      getStripedReader().readMinimumSources(toReconstructLen);\n\n      // step2: decode to reconstruct targets\n      reconstructTargets(toReconstructLen);\n\n      // step3: calculate checksum\n      getChecksum().calculateChunkedSums(targetBuffer.array(), 0,\n          targetBuffer.remaining(), checksumBuf, 0);\n\n      // step4: updates the digest using the checksum array of bytes\n      digester.update(checksumBuf, 0, checksumBuf.length);\n      checksumDataLen +\u003d checksumBuf.length;\n      updatePositionInBlock(toReconstructLen);\n      clearBuffers();\n    }\n\n    byte[] digest \u003d digester.digest();\n    md5 \u003d new MD5Hash(digest);\n    md5.write(checksumWriter);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/erasurecode/StripedBlockChecksumReconstructor.java",
          "extendedDetails": {
            "oldValue": "reconstructAndTransfer",
            "newValue": "reconstruct"
          }
        }
      ]
    },
    "3c18a53cbd2efabb2ad108d63a0b0b558424115f": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-9719. Refactoring ErasureCodingWorker into smaller reusable constructs. Contributed by Kai Zheng.\n",
      "commitDate": "06/04/16 10:50 PM",
      "commitName": "3c18a53cbd2efabb2ad108d63a0b0b558424115f",
      "commitAuthor": "Uma Maheswara Rao G",
      "diff": "@@ -0,0 +1,23 @@\n+  void reconstructAndTransfer() throws IOException {\n+    while (positionInBlock \u003c stripedWriter.getMaxTargetLength()) {\n+      long remaining \u003d stripedWriter.getMaxTargetLength() - positionInBlock;\n+      final int toReconstructLen \u003d\n+          (int) Math.min(stripedReader.getBufferSize(), remaining);\n+      // step1: read from minimum source DNs required for reconstruction.\n+      // The returned success list is the source DNs we do real read from\n+      stripedReader.readMinimumSources(toReconstructLen);\n+\n+      // step2: decode to reconstruct targets\n+      reconstructTargets(toReconstructLen);\n+\n+      // step3: transfer data\n+      if (stripedWriter.transferData2Targets() \u003d\u003d 0) {\n+        String error \u003d \"Transfer failed for all targets.\";\n+        throw new IOException(error);\n+      }\n+\n+      positionInBlock +\u003d toReconstructLen;\n+\n+      clearBuffers();\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  void reconstructAndTransfer() throws IOException {\n    while (positionInBlock \u003c stripedWriter.getMaxTargetLength()) {\n      long remaining \u003d stripedWriter.getMaxTargetLength() - positionInBlock;\n      final int toReconstructLen \u003d\n          (int) Math.min(stripedReader.getBufferSize(), remaining);\n      // step1: read from minimum source DNs required for reconstruction.\n      // The returned success list is the source DNs we do real read from\n      stripedReader.readMinimumSources(toReconstructLen);\n\n      // step2: decode to reconstruct targets\n      reconstructTargets(toReconstructLen);\n\n      // step3: transfer data\n      if (stripedWriter.transferData2Targets() \u003d\u003d 0) {\n        String error \u003d \"Transfer failed for all targets.\";\n        throw new IOException(error);\n      }\n\n      positionInBlock +\u003d toReconstructLen;\n\n      clearBuffers();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/erasurecode/StripedReconstructor.java"
    }
  }
}