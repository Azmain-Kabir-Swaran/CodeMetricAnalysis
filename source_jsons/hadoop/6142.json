{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSImageFormat.java",
  "functionName": "load",
  "functionId": "load___curFile-File",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
  "functionStartLine": 308,
  "functionEndLine": 450,
  "numCommitsSeen": 134,
  "timeTaken": 11333,
  "changeHistory": [
    "7a3188d054481b9bd563e337901e93476303ce7f",
    "ec25c7f9c7e60c077d8c4143253c20445fcdaecf",
    "3a9571308e99cc374681bbc451a517d41a150aa0",
    "8a91109d16394310f2568717f103e6fff7cbddb0",
    "c304890c8c7782d835896859f5b7f60b96c306c0",
    "49d5cff49011cc0878665204e22b5c832bc914ce",
    "1e1e93040748231dc913190aec1e031c379d8271",
    "75ead273bea8a7dad61c4f99c3a16cab2697c498",
    "185e0c7b4c056b88f606362c71e4a22aae7076e0",
    "571e9c623241106dad5521a870fb8daef3f2b00a",
    "a2edb11b68ae01a44092cb14ac2717a6aad93305",
    "00067895a01c66d53715b50bbcb3605efd6425f2",
    "a7ec44d41b0ad1fa133408a10caaae32a27ea569",
    "af1ac9a5e8d8d97a855940d853dd59ab4666f6e2",
    "da8e962e39bd41b73b53966826c82e741b08010b",
    "6770de7ec4f73e16740f1723f4e35d2fef2c22c8",
    "a764da16d6a02372f19b45cc841f0dff001d7b24",
    "4c00514ede4e7e028b18f76a9b8edfedab8631d4",
    "19201622be1db8e166d1cc0dd7e62af4702d2784",
    "1096917649fd951be633e5619518764f23cca645",
    "bcabbcdf4cf7b4bcda62d74b06c9736bc55f6fc1",
    "5988208b7d2fa3c0378f17fe67ada99a25342829",
    "fe3584aadfc7839abcd03239e4d07afd12b8b90f",
    "0fa9c7a825f444d50c89b986bacea7a547e4ab8b",
    "64641c28b5ea8538033060452b0c45b7f2eeb60c",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "28e6a4e44a3e920dcaf858f9a74a6358226b3a63",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "7a3188d054481b9bd563e337901e93476303ce7f": "Ybodychange",
    "ec25c7f9c7e60c077d8c4143253c20445fcdaecf": "Ybodychange",
    "3a9571308e99cc374681bbc451a517d41a150aa0": "Ybodychange",
    "8a91109d16394310f2568717f103e6fff7cbddb0": "Ybodychange",
    "c304890c8c7782d835896859f5b7f60b96c306c0": "Ybodychange",
    "49d5cff49011cc0878665204e22b5c832bc914ce": "Ybodychange",
    "1e1e93040748231dc913190aec1e031c379d8271": "Ybodychange",
    "75ead273bea8a7dad61c4f99c3a16cab2697c498": "Ybodychange",
    "185e0c7b4c056b88f606362c71e4a22aae7076e0": "Ybodychange",
    "571e9c623241106dad5521a870fb8daef3f2b00a": "Ybodychange",
    "a2edb11b68ae01a44092cb14ac2717a6aad93305": "Ymodifierchange",
    "00067895a01c66d53715b50bbcb3605efd6425f2": "Ybodychange",
    "a7ec44d41b0ad1fa133408a10caaae32a27ea569": "Ybodychange",
    "af1ac9a5e8d8d97a855940d853dd59ab4666f6e2": "Ybodychange",
    "da8e962e39bd41b73b53966826c82e741b08010b": "Ybodychange",
    "6770de7ec4f73e16740f1723f4e35d2fef2c22c8": "Ybodychange",
    "a764da16d6a02372f19b45cc841f0dff001d7b24": "Ybodychange",
    "4c00514ede4e7e028b18f76a9b8edfedab8631d4": "Ybodychange",
    "19201622be1db8e166d1cc0dd7e62af4702d2784": "Ybodychange",
    "1096917649fd951be633e5619518764f23cca645": "Ybodychange",
    "bcabbcdf4cf7b4bcda62d74b06c9736bc55f6fc1": "Ybodychange",
    "5988208b7d2fa3c0378f17fe67ada99a25342829": "Ybodychange",
    "fe3584aadfc7839abcd03239e4d07afd12b8b90f": "Ybodychange",
    "0fa9c7a825f444d50c89b986bacea7a547e4ab8b": "Ybodychange",
    "64641c28b5ea8538033060452b0c45b7f2eeb60c": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "28e6a4e44a3e920dcaf858f9a74a6358226b3a63": "Ybodychange",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "7a3188d054481b9bd563e337901e93476303ce7f": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-16282. Avoid FileStream to improve performance. Contributed by Ayush Saxena.\n",
      "commitDate": "02/05/19 12:58 PM",
      "commitName": "7a3188d054481b9bd563e337901e93476303ce7f",
      "commitAuthor": "Giovanni Matteo Fumarola",
      "commitDateOld": "06/09/18 2:48 PM",
      "commitNameOld": "eca1a4bfe952fc184fe90dde50bac9b0e5293568",
      "commitAuthorOld": "Giovanni Matteo Fumarola",
      "daysBetweenCommits": 237.92,
      "commitsBetweenForRepo": 1864,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,143 +1,143 @@\n     public void load(File curFile) throws IOException {\n       checkNotLoaded();\n       assert curFile !\u003d null : \"curFile is null\";\n \n       StartupProgress prog \u003d NameNode.getStartupProgress();\n       Step step \u003d new Step(StepType.INODES);\n       prog.beginStep(Phase.LOADING_FSIMAGE, step);\n       long startTime \u003d monotonicNow();\n \n       //\n       // Load in bits\n       //\n       MessageDigest digester \u003d MD5Hash.getDigester();\n       DigestInputStream fin \u003d new DigestInputStream(\n-           new FileInputStream(curFile), digester);\n+          Files.newInputStream(curFile.toPath()), digester);\n \n       DataInputStream in \u003d new DataInputStream(fin);\n       try {\n         // read image version: first appeared in version -1\n         int imgVersion \u003d in.readInt();\n         if (getLayoutVersion() !\u003d imgVersion) {\n           throw new InconsistentFSStateException(curFile, \n               \"imgVersion \" + imgVersion +\n               \" expected to be \" + getLayoutVersion());\n         }\n         boolean supportSnapshot \u003d NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.SNAPSHOT, imgVersion);\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.ADD_LAYOUT_FLAGS, imgVersion)) {\n           LayoutFlags.read(in);\n         }\n \n         // read namespaceID: first appeared in version -2\n         in.readInt();\n \n         long numFiles \u003d in.readLong();\n \n         // read in the last generation stamp for legacy blocks.\n         long genstamp \u003d in.readLong();\n         final BlockIdManager blockIdManager \u003d namesystem.getBlockManager()\n             .getBlockIdManager();\n         blockIdManager.setLegacyGenerationStamp(genstamp);\n \n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.SEQUENTIAL_BLOCK_ID, imgVersion)) {\n           // read the starting generation stamp for sequential block IDs\n           genstamp \u003d in.readLong();\n           blockIdManager.setGenerationStamp(genstamp);\n \n           // read the last generation stamp for blocks created after\n           // the switch to sequential block IDs.\n           long stampAtIdSwitch \u003d in.readLong();\n           blockIdManager.setLegacyGenerationStampLimit(stampAtIdSwitch);\n \n           // read the max sequential block ID.\n           long maxSequentialBlockId \u003d in.readLong();\n           blockIdManager.setLastAllocatedContiguousBlockId(maxSequentialBlockId);\n         } else {\n           long startingGenStamp \u003d blockIdManager.upgradeLegacyGenerationStamp();\n           // This is an upgrade.\n           LOG.info(\"Upgrading to sequential block IDs. Generation stamp \" +\n                    \"for new blocks set to \" + startingGenStamp);\n         }\n \n         // read the transaction ID of the last edit represented by\n         // this image\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.STORED_TXIDS, imgVersion)) {\n           imgTxId \u003d in.readLong();\n         } else {\n           imgTxId \u003d 0;\n         }\n \n         // read the last allocated inode id in the fsimage\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.ADD_INODE_ID, imgVersion)) {\n           long lastInodeId \u003d in.readLong();\n           namesystem.dir.resetLastInodeId(lastInodeId);\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"load last allocated InodeId from fsimage:\" + lastInodeId);\n           }\n         } else {\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"Old layout version doesn\u0027t have inode id.\"\n                 + \" Will assign new id for each inode.\");\n           }\n         }\n         \n         if (supportSnapshot) {\n           snapshotMap \u003d namesystem.getSnapshotManager().read(in, this);\n         }\n \n         // read compression related info\n         FSImageCompression compression;\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n           compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n         } else {\n           compression \u003d FSImageCompression.createNoopCompression();\n         }\n         in \u003d compression.unwrapInputStream(fin);\n \n         LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n         \n         // load all inodes\n         LOG.info(\"Number of files \u003d \" + numFiles);\n         prog.setTotal(Phase.LOADING_FSIMAGE, step, numFiles);\n         Counter counter \u003d prog.getCounter(Phase.LOADING_FSIMAGE, step);\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.FSIMAGE_NAME_OPTIMIZATION, imgVersion)) {\n           if (supportSnapshot) {\n             loadLocalNameINodesWithSnapshot(numFiles, in, counter);\n           } else {\n             loadLocalNameINodes(numFiles, in, counter);\n           }\n         } else {\n           loadFullNameINodes(numFiles, in, counter);\n         }\n \n         loadFilesUnderConstruction(in, supportSnapshot, counter);\n         prog.endStep(Phase.LOADING_FSIMAGE, step);\n         // Now that the step is finished, set counter equal to total to adjust\n         // for possible under-counting due to reference inodes.\n         prog.setCount(Phase.LOADING_FSIMAGE, step, numFiles);\n \n         loadSecretManagerState(in);\n \n         loadCacheManagerState(in);\n \n         // make sure to read to the end of file\n         boolean eof \u003d (in.read() \u003d\u003d -1);\n         assert eof : \"Should have reached the end of image file \" + curFile;\n       } finally {\n         in.close();\n       }\n \n       imgDigest \u003d new MD5Hash(digester.digest());\n       loaded \u003d true;\n       \n       LOG.info(\"Image file \" + curFile + \" of size \" + curFile.length()\n           + \" bytes loaded in \" + (monotonicNow() - startTime) / 1000\n           + \" seconds.\");\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void load(File curFile) throws IOException {\n      checkNotLoaded();\n      assert curFile !\u003d null : \"curFile is null\";\n\n      StartupProgress prog \u003d NameNode.getStartupProgress();\n      Step step \u003d new Step(StepType.INODES);\n      prog.beginStep(Phase.LOADING_FSIMAGE, step);\n      long startTime \u003d monotonicNow();\n\n      //\n      // Load in bits\n      //\n      MessageDigest digester \u003d MD5Hash.getDigester();\n      DigestInputStream fin \u003d new DigestInputStream(\n          Files.newInputStream(curFile.toPath()), digester);\n\n      DataInputStream in \u003d new DataInputStream(fin);\n      try {\n        // read image version: first appeared in version -1\n        int imgVersion \u003d in.readInt();\n        if (getLayoutVersion() !\u003d imgVersion) {\n          throw new InconsistentFSStateException(curFile, \n              \"imgVersion \" + imgVersion +\n              \" expected to be \" + getLayoutVersion());\n        }\n        boolean supportSnapshot \u003d NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.SNAPSHOT, imgVersion);\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.ADD_LAYOUT_FLAGS, imgVersion)) {\n          LayoutFlags.read(in);\n        }\n\n        // read namespaceID: first appeared in version -2\n        in.readInt();\n\n        long numFiles \u003d in.readLong();\n\n        // read in the last generation stamp for legacy blocks.\n        long genstamp \u003d in.readLong();\n        final BlockIdManager blockIdManager \u003d namesystem.getBlockManager()\n            .getBlockIdManager();\n        blockIdManager.setLegacyGenerationStamp(genstamp);\n\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.SEQUENTIAL_BLOCK_ID, imgVersion)) {\n          // read the starting generation stamp for sequential block IDs\n          genstamp \u003d in.readLong();\n          blockIdManager.setGenerationStamp(genstamp);\n\n          // read the last generation stamp for blocks created after\n          // the switch to sequential block IDs.\n          long stampAtIdSwitch \u003d in.readLong();\n          blockIdManager.setLegacyGenerationStampLimit(stampAtIdSwitch);\n\n          // read the max sequential block ID.\n          long maxSequentialBlockId \u003d in.readLong();\n          blockIdManager.setLastAllocatedContiguousBlockId(maxSequentialBlockId);\n        } else {\n          long startingGenStamp \u003d blockIdManager.upgradeLegacyGenerationStamp();\n          // This is an upgrade.\n          LOG.info(\"Upgrading to sequential block IDs. Generation stamp \" +\n                   \"for new blocks set to \" + startingGenStamp);\n        }\n\n        // read the transaction ID of the last edit represented by\n        // this image\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.STORED_TXIDS, imgVersion)) {\n          imgTxId \u003d in.readLong();\n        } else {\n          imgTxId \u003d 0;\n        }\n\n        // read the last allocated inode id in the fsimage\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.ADD_INODE_ID, imgVersion)) {\n          long lastInodeId \u003d in.readLong();\n          namesystem.dir.resetLastInodeId(lastInodeId);\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"load last allocated InodeId from fsimage:\" + lastInodeId);\n          }\n        } else {\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Old layout version doesn\u0027t have inode id.\"\n                + \" Will assign new id for each inode.\");\n          }\n        }\n        \n        if (supportSnapshot) {\n          snapshotMap \u003d namesystem.getSnapshotManager().read(in, this);\n        }\n\n        // read compression related info\n        FSImageCompression compression;\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n          compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n        } else {\n          compression \u003d FSImageCompression.createNoopCompression();\n        }\n        in \u003d compression.unwrapInputStream(fin);\n\n        LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n        \n        // load all inodes\n        LOG.info(\"Number of files \u003d \" + numFiles);\n        prog.setTotal(Phase.LOADING_FSIMAGE, step, numFiles);\n        Counter counter \u003d prog.getCounter(Phase.LOADING_FSIMAGE, step);\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.FSIMAGE_NAME_OPTIMIZATION, imgVersion)) {\n          if (supportSnapshot) {\n            loadLocalNameINodesWithSnapshot(numFiles, in, counter);\n          } else {\n            loadLocalNameINodes(numFiles, in, counter);\n          }\n        } else {\n          loadFullNameINodes(numFiles, in, counter);\n        }\n\n        loadFilesUnderConstruction(in, supportSnapshot, counter);\n        prog.endStep(Phase.LOADING_FSIMAGE, step);\n        // Now that the step is finished, set counter equal to total to adjust\n        // for possible under-counting due to reference inodes.\n        prog.setCount(Phase.LOADING_FSIMAGE, step, numFiles);\n\n        loadSecretManagerState(in);\n\n        loadCacheManagerState(in);\n\n        // make sure to read to the end of file\n        boolean eof \u003d (in.read() \u003d\u003d -1);\n        assert eof : \"Should have reached the end of image file \" + curFile;\n      } finally {\n        in.close();\n      }\n\n      imgDigest \u003d new MD5Hash(digester.digest());\n      loaded \u003d true;\n      \n      LOG.info(\"Image file \" + curFile + \" of size \" + curFile.length()\n          + \" bytes loaded in \" + (monotonicNow() - startTime) / 1000\n          + \" seconds.\");\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {}
    },
    "ec25c7f9c7e60c077d8c4143253c20445fcdaecf": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9677. Rename generationStampV1/generationStampV2 to legacyGenerationStamp/generationStamp. Contributed by Mingliang Liu.\n",
      "commitDate": "27/01/16 4:34 PM",
      "commitName": "ec25c7f9c7e60c077d8c4143253c20445fcdaecf",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "27/01/16 4:31 PM",
      "commitNameOld": "3a9571308e99cc374681bbc451a517d41a150aa0",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,143 +1,143 @@\n     public void load(File curFile) throws IOException {\n       checkNotLoaded();\n       assert curFile !\u003d null : \"curFile is null\";\n \n       StartupProgress prog \u003d NameNode.getStartupProgress();\n       Step step \u003d new Step(StepType.INODES);\n       prog.beginStep(Phase.LOADING_FSIMAGE, step);\n       long startTime \u003d monotonicNow();\n \n       //\n       // Load in bits\n       //\n       MessageDigest digester \u003d MD5Hash.getDigester();\n       DigestInputStream fin \u003d new DigestInputStream(\n            new FileInputStream(curFile), digester);\n \n       DataInputStream in \u003d new DataInputStream(fin);\n       try {\n         // read image version: first appeared in version -1\n         int imgVersion \u003d in.readInt();\n         if (getLayoutVersion() !\u003d imgVersion) {\n           throw new InconsistentFSStateException(curFile, \n               \"imgVersion \" + imgVersion +\n               \" expected to be \" + getLayoutVersion());\n         }\n         boolean supportSnapshot \u003d NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.SNAPSHOT, imgVersion);\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.ADD_LAYOUT_FLAGS, imgVersion)) {\n           LayoutFlags.read(in);\n         }\n \n         // read namespaceID: first appeared in version -2\n         in.readInt();\n \n         long numFiles \u003d in.readLong();\n \n         // read in the last generation stamp for legacy blocks.\n         long genstamp \u003d in.readLong();\n         final BlockIdManager blockIdManager \u003d namesystem.getBlockManager()\n             .getBlockIdManager();\n-        blockIdManager.setGenerationStampV1(genstamp);\n+        blockIdManager.setLegacyGenerationStamp(genstamp);\n \n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.SEQUENTIAL_BLOCK_ID, imgVersion)) {\n           // read the starting generation stamp for sequential block IDs\n           genstamp \u003d in.readLong();\n-          blockIdManager.setGenerationStampV2(genstamp);\n+          blockIdManager.setGenerationStamp(genstamp);\n \n           // read the last generation stamp for blocks created after\n           // the switch to sequential block IDs.\n           long stampAtIdSwitch \u003d in.readLong();\n-          blockIdManager.setGenerationStampV1Limit(stampAtIdSwitch);\n+          blockIdManager.setLegacyGenerationStampLimit(stampAtIdSwitch);\n \n           // read the max sequential block ID.\n           long maxSequentialBlockId \u003d in.readLong();\n           blockIdManager.setLastAllocatedContiguousBlockId(maxSequentialBlockId);\n         } else {\n-          long startingGenStamp \u003d blockIdManager.upgradeGenerationStampToV2();\n+          long startingGenStamp \u003d blockIdManager.upgradeLegacyGenerationStamp();\n           // This is an upgrade.\n           LOG.info(\"Upgrading to sequential block IDs. Generation stamp \" +\n                    \"for new blocks set to \" + startingGenStamp);\n         }\n \n         // read the transaction ID of the last edit represented by\n         // this image\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.STORED_TXIDS, imgVersion)) {\n           imgTxId \u003d in.readLong();\n         } else {\n           imgTxId \u003d 0;\n         }\n \n         // read the last allocated inode id in the fsimage\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.ADD_INODE_ID, imgVersion)) {\n           long lastInodeId \u003d in.readLong();\n           namesystem.dir.resetLastInodeId(lastInodeId);\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"load last allocated InodeId from fsimage:\" + lastInodeId);\n           }\n         } else {\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"Old layout version doesn\u0027t have inode id.\"\n                 + \" Will assign new id for each inode.\");\n           }\n         }\n         \n         if (supportSnapshot) {\n           snapshotMap \u003d namesystem.getSnapshotManager().read(in, this);\n         }\n \n         // read compression related info\n         FSImageCompression compression;\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n           compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n         } else {\n           compression \u003d FSImageCompression.createNoopCompression();\n         }\n         in \u003d compression.unwrapInputStream(fin);\n \n         LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n         \n         // load all inodes\n         LOG.info(\"Number of files \u003d \" + numFiles);\n         prog.setTotal(Phase.LOADING_FSIMAGE, step, numFiles);\n         Counter counter \u003d prog.getCounter(Phase.LOADING_FSIMAGE, step);\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.FSIMAGE_NAME_OPTIMIZATION, imgVersion)) {\n           if (supportSnapshot) {\n             loadLocalNameINodesWithSnapshot(numFiles, in, counter);\n           } else {\n             loadLocalNameINodes(numFiles, in, counter);\n           }\n         } else {\n           loadFullNameINodes(numFiles, in, counter);\n         }\n \n         loadFilesUnderConstruction(in, supportSnapshot, counter);\n         prog.endStep(Phase.LOADING_FSIMAGE, step);\n         // Now that the step is finished, set counter equal to total to adjust\n         // for possible under-counting due to reference inodes.\n         prog.setCount(Phase.LOADING_FSIMAGE, step, numFiles);\n \n         loadSecretManagerState(in);\n \n         loadCacheManagerState(in);\n \n         // make sure to read to the end of file\n         boolean eof \u003d (in.read() \u003d\u003d -1);\n         assert eof : \"Should have reached the end of image file \" + curFile;\n       } finally {\n         in.close();\n       }\n \n       imgDigest \u003d new MD5Hash(digester.digest());\n       loaded \u003d true;\n       \n       LOG.info(\"Image file \" + curFile + \" of size \" + curFile.length()\n           + \" bytes loaded in \" + (monotonicNow() - startTime) / 1000\n           + \" seconds.\");\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void load(File curFile) throws IOException {\n      checkNotLoaded();\n      assert curFile !\u003d null : \"curFile is null\";\n\n      StartupProgress prog \u003d NameNode.getStartupProgress();\n      Step step \u003d new Step(StepType.INODES);\n      prog.beginStep(Phase.LOADING_FSIMAGE, step);\n      long startTime \u003d monotonicNow();\n\n      //\n      // Load in bits\n      //\n      MessageDigest digester \u003d MD5Hash.getDigester();\n      DigestInputStream fin \u003d new DigestInputStream(\n           new FileInputStream(curFile), digester);\n\n      DataInputStream in \u003d new DataInputStream(fin);\n      try {\n        // read image version: first appeared in version -1\n        int imgVersion \u003d in.readInt();\n        if (getLayoutVersion() !\u003d imgVersion) {\n          throw new InconsistentFSStateException(curFile, \n              \"imgVersion \" + imgVersion +\n              \" expected to be \" + getLayoutVersion());\n        }\n        boolean supportSnapshot \u003d NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.SNAPSHOT, imgVersion);\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.ADD_LAYOUT_FLAGS, imgVersion)) {\n          LayoutFlags.read(in);\n        }\n\n        // read namespaceID: first appeared in version -2\n        in.readInt();\n\n        long numFiles \u003d in.readLong();\n\n        // read in the last generation stamp for legacy blocks.\n        long genstamp \u003d in.readLong();\n        final BlockIdManager blockIdManager \u003d namesystem.getBlockManager()\n            .getBlockIdManager();\n        blockIdManager.setLegacyGenerationStamp(genstamp);\n\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.SEQUENTIAL_BLOCK_ID, imgVersion)) {\n          // read the starting generation stamp for sequential block IDs\n          genstamp \u003d in.readLong();\n          blockIdManager.setGenerationStamp(genstamp);\n\n          // read the last generation stamp for blocks created after\n          // the switch to sequential block IDs.\n          long stampAtIdSwitch \u003d in.readLong();\n          blockIdManager.setLegacyGenerationStampLimit(stampAtIdSwitch);\n\n          // read the max sequential block ID.\n          long maxSequentialBlockId \u003d in.readLong();\n          blockIdManager.setLastAllocatedContiguousBlockId(maxSequentialBlockId);\n        } else {\n          long startingGenStamp \u003d blockIdManager.upgradeLegacyGenerationStamp();\n          // This is an upgrade.\n          LOG.info(\"Upgrading to sequential block IDs. Generation stamp \" +\n                   \"for new blocks set to \" + startingGenStamp);\n        }\n\n        // read the transaction ID of the last edit represented by\n        // this image\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.STORED_TXIDS, imgVersion)) {\n          imgTxId \u003d in.readLong();\n        } else {\n          imgTxId \u003d 0;\n        }\n\n        // read the last allocated inode id in the fsimage\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.ADD_INODE_ID, imgVersion)) {\n          long lastInodeId \u003d in.readLong();\n          namesystem.dir.resetLastInodeId(lastInodeId);\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"load last allocated InodeId from fsimage:\" + lastInodeId);\n          }\n        } else {\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Old layout version doesn\u0027t have inode id.\"\n                + \" Will assign new id for each inode.\");\n          }\n        }\n        \n        if (supportSnapshot) {\n          snapshotMap \u003d namesystem.getSnapshotManager().read(in, this);\n        }\n\n        // read compression related info\n        FSImageCompression compression;\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n          compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n        } else {\n          compression \u003d FSImageCompression.createNoopCompression();\n        }\n        in \u003d compression.unwrapInputStream(fin);\n\n        LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n        \n        // load all inodes\n        LOG.info(\"Number of files \u003d \" + numFiles);\n        prog.setTotal(Phase.LOADING_FSIMAGE, step, numFiles);\n        Counter counter \u003d prog.getCounter(Phase.LOADING_FSIMAGE, step);\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.FSIMAGE_NAME_OPTIMIZATION, imgVersion)) {\n          if (supportSnapshot) {\n            loadLocalNameINodesWithSnapshot(numFiles, in, counter);\n          } else {\n            loadLocalNameINodes(numFiles, in, counter);\n          }\n        } else {\n          loadFullNameINodes(numFiles, in, counter);\n        }\n\n        loadFilesUnderConstruction(in, supportSnapshot, counter);\n        prog.endStep(Phase.LOADING_FSIMAGE, step);\n        // Now that the step is finished, set counter equal to total to adjust\n        // for possible under-counting due to reference inodes.\n        prog.setCount(Phase.LOADING_FSIMAGE, step, numFiles);\n\n        loadSecretManagerState(in);\n\n        loadCacheManagerState(in);\n\n        // make sure to read to the end of file\n        boolean eof \u003d (in.read() \u003d\u003d -1);\n        assert eof : \"Should have reached the end of image file \" + curFile;\n      } finally {\n        in.close();\n      }\n\n      imgDigest \u003d new MD5Hash(digester.digest());\n      loaded \u003d true;\n      \n      LOG.info(\"Image file \" + curFile + \" of size \" + curFile.length()\n          + \" bytes loaded in \" + (monotonicNow() - startTime) / 1000\n          + \" seconds.\");\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {}
    },
    "3a9571308e99cc374681bbc451a517d41a150aa0": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-9677. Rename generationStampV1/generationStampV2 to legacyGenerationStamp/generationStamp. Contributed by Mingliang Liu.\"\n\nThis reverts commit 8a91109d16394310f2568717f103e6fff7cbddb0.\n",
      "commitDate": "27/01/16 4:31 PM",
      "commitName": "3a9571308e99cc374681bbc451a517d41a150aa0",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "27/01/16 3:48 PM",
      "commitNameOld": "8a91109d16394310f2568717f103e6fff7cbddb0",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 0.03,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,143 +1,143 @@\n     public void load(File curFile) throws IOException {\n       checkNotLoaded();\n       assert curFile !\u003d null : \"curFile is null\";\n \n       StartupProgress prog \u003d NameNode.getStartupProgress();\n       Step step \u003d new Step(StepType.INODES);\n       prog.beginStep(Phase.LOADING_FSIMAGE, step);\n       long startTime \u003d monotonicNow();\n \n       //\n       // Load in bits\n       //\n       MessageDigest digester \u003d MD5Hash.getDigester();\n       DigestInputStream fin \u003d new DigestInputStream(\n            new FileInputStream(curFile), digester);\n \n       DataInputStream in \u003d new DataInputStream(fin);\n       try {\n         // read image version: first appeared in version -1\n         int imgVersion \u003d in.readInt();\n         if (getLayoutVersion() !\u003d imgVersion) {\n           throw new InconsistentFSStateException(curFile, \n               \"imgVersion \" + imgVersion +\n               \" expected to be \" + getLayoutVersion());\n         }\n         boolean supportSnapshot \u003d NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.SNAPSHOT, imgVersion);\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.ADD_LAYOUT_FLAGS, imgVersion)) {\n           LayoutFlags.read(in);\n         }\n \n         // read namespaceID: first appeared in version -2\n         in.readInt();\n \n         long numFiles \u003d in.readLong();\n \n         // read in the last generation stamp for legacy blocks.\n         long genstamp \u003d in.readLong();\n         final BlockIdManager blockIdManager \u003d namesystem.getBlockManager()\n             .getBlockIdManager();\n-        blockIdManager.setLegacyGenerationStamp(genstamp);\n+        blockIdManager.setGenerationStampV1(genstamp);\n \n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.SEQUENTIAL_BLOCK_ID, imgVersion)) {\n           // read the starting generation stamp for sequential block IDs\n           genstamp \u003d in.readLong();\n-          blockIdManager.setGenerationStamp(genstamp);\n+          blockIdManager.setGenerationStampV2(genstamp);\n \n           // read the last generation stamp for blocks created after\n           // the switch to sequential block IDs.\n           long stampAtIdSwitch \u003d in.readLong();\n-          blockIdManager.setLegacyGenerationStampLimit(stampAtIdSwitch);\n+          blockIdManager.setGenerationStampV1Limit(stampAtIdSwitch);\n \n           // read the max sequential block ID.\n           long maxSequentialBlockId \u003d in.readLong();\n           blockIdManager.setLastAllocatedContiguousBlockId(maxSequentialBlockId);\n         } else {\n-          long startingGenStamp \u003d blockIdManager.upgradeLegacyGenerationStamp();\n+          long startingGenStamp \u003d blockIdManager.upgradeGenerationStampToV2();\n           // This is an upgrade.\n           LOG.info(\"Upgrading to sequential block IDs. Generation stamp \" +\n                    \"for new blocks set to \" + startingGenStamp);\n         }\n \n         // read the transaction ID of the last edit represented by\n         // this image\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.STORED_TXIDS, imgVersion)) {\n           imgTxId \u003d in.readLong();\n         } else {\n           imgTxId \u003d 0;\n         }\n \n         // read the last allocated inode id in the fsimage\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.ADD_INODE_ID, imgVersion)) {\n           long lastInodeId \u003d in.readLong();\n           namesystem.dir.resetLastInodeId(lastInodeId);\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"load last allocated InodeId from fsimage:\" + lastInodeId);\n           }\n         } else {\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"Old layout version doesn\u0027t have inode id.\"\n                 + \" Will assign new id for each inode.\");\n           }\n         }\n         \n         if (supportSnapshot) {\n           snapshotMap \u003d namesystem.getSnapshotManager().read(in, this);\n         }\n \n         // read compression related info\n         FSImageCompression compression;\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n           compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n         } else {\n           compression \u003d FSImageCompression.createNoopCompression();\n         }\n         in \u003d compression.unwrapInputStream(fin);\n \n         LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n         \n         // load all inodes\n         LOG.info(\"Number of files \u003d \" + numFiles);\n         prog.setTotal(Phase.LOADING_FSIMAGE, step, numFiles);\n         Counter counter \u003d prog.getCounter(Phase.LOADING_FSIMAGE, step);\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.FSIMAGE_NAME_OPTIMIZATION, imgVersion)) {\n           if (supportSnapshot) {\n             loadLocalNameINodesWithSnapshot(numFiles, in, counter);\n           } else {\n             loadLocalNameINodes(numFiles, in, counter);\n           }\n         } else {\n           loadFullNameINodes(numFiles, in, counter);\n         }\n \n         loadFilesUnderConstruction(in, supportSnapshot, counter);\n         prog.endStep(Phase.LOADING_FSIMAGE, step);\n         // Now that the step is finished, set counter equal to total to adjust\n         // for possible under-counting due to reference inodes.\n         prog.setCount(Phase.LOADING_FSIMAGE, step, numFiles);\n \n         loadSecretManagerState(in);\n \n         loadCacheManagerState(in);\n \n         // make sure to read to the end of file\n         boolean eof \u003d (in.read() \u003d\u003d -1);\n         assert eof : \"Should have reached the end of image file \" + curFile;\n       } finally {\n         in.close();\n       }\n \n       imgDigest \u003d new MD5Hash(digester.digest());\n       loaded \u003d true;\n       \n       LOG.info(\"Image file \" + curFile + \" of size \" + curFile.length()\n           + \" bytes loaded in \" + (monotonicNow() - startTime) / 1000\n           + \" seconds.\");\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void load(File curFile) throws IOException {\n      checkNotLoaded();\n      assert curFile !\u003d null : \"curFile is null\";\n\n      StartupProgress prog \u003d NameNode.getStartupProgress();\n      Step step \u003d new Step(StepType.INODES);\n      prog.beginStep(Phase.LOADING_FSIMAGE, step);\n      long startTime \u003d monotonicNow();\n\n      //\n      // Load in bits\n      //\n      MessageDigest digester \u003d MD5Hash.getDigester();\n      DigestInputStream fin \u003d new DigestInputStream(\n           new FileInputStream(curFile), digester);\n\n      DataInputStream in \u003d new DataInputStream(fin);\n      try {\n        // read image version: first appeared in version -1\n        int imgVersion \u003d in.readInt();\n        if (getLayoutVersion() !\u003d imgVersion) {\n          throw new InconsistentFSStateException(curFile, \n              \"imgVersion \" + imgVersion +\n              \" expected to be \" + getLayoutVersion());\n        }\n        boolean supportSnapshot \u003d NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.SNAPSHOT, imgVersion);\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.ADD_LAYOUT_FLAGS, imgVersion)) {\n          LayoutFlags.read(in);\n        }\n\n        // read namespaceID: first appeared in version -2\n        in.readInt();\n\n        long numFiles \u003d in.readLong();\n\n        // read in the last generation stamp for legacy blocks.\n        long genstamp \u003d in.readLong();\n        final BlockIdManager blockIdManager \u003d namesystem.getBlockManager()\n            .getBlockIdManager();\n        blockIdManager.setGenerationStampV1(genstamp);\n\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.SEQUENTIAL_BLOCK_ID, imgVersion)) {\n          // read the starting generation stamp for sequential block IDs\n          genstamp \u003d in.readLong();\n          blockIdManager.setGenerationStampV2(genstamp);\n\n          // read the last generation stamp for blocks created after\n          // the switch to sequential block IDs.\n          long stampAtIdSwitch \u003d in.readLong();\n          blockIdManager.setGenerationStampV1Limit(stampAtIdSwitch);\n\n          // read the max sequential block ID.\n          long maxSequentialBlockId \u003d in.readLong();\n          blockIdManager.setLastAllocatedContiguousBlockId(maxSequentialBlockId);\n        } else {\n          long startingGenStamp \u003d blockIdManager.upgradeGenerationStampToV2();\n          // This is an upgrade.\n          LOG.info(\"Upgrading to sequential block IDs. Generation stamp \" +\n                   \"for new blocks set to \" + startingGenStamp);\n        }\n\n        // read the transaction ID of the last edit represented by\n        // this image\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.STORED_TXIDS, imgVersion)) {\n          imgTxId \u003d in.readLong();\n        } else {\n          imgTxId \u003d 0;\n        }\n\n        // read the last allocated inode id in the fsimage\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.ADD_INODE_ID, imgVersion)) {\n          long lastInodeId \u003d in.readLong();\n          namesystem.dir.resetLastInodeId(lastInodeId);\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"load last allocated InodeId from fsimage:\" + lastInodeId);\n          }\n        } else {\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Old layout version doesn\u0027t have inode id.\"\n                + \" Will assign new id for each inode.\");\n          }\n        }\n        \n        if (supportSnapshot) {\n          snapshotMap \u003d namesystem.getSnapshotManager().read(in, this);\n        }\n\n        // read compression related info\n        FSImageCompression compression;\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n          compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n        } else {\n          compression \u003d FSImageCompression.createNoopCompression();\n        }\n        in \u003d compression.unwrapInputStream(fin);\n\n        LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n        \n        // load all inodes\n        LOG.info(\"Number of files \u003d \" + numFiles);\n        prog.setTotal(Phase.LOADING_FSIMAGE, step, numFiles);\n        Counter counter \u003d prog.getCounter(Phase.LOADING_FSIMAGE, step);\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.FSIMAGE_NAME_OPTIMIZATION, imgVersion)) {\n          if (supportSnapshot) {\n            loadLocalNameINodesWithSnapshot(numFiles, in, counter);\n          } else {\n            loadLocalNameINodes(numFiles, in, counter);\n          }\n        } else {\n          loadFullNameINodes(numFiles, in, counter);\n        }\n\n        loadFilesUnderConstruction(in, supportSnapshot, counter);\n        prog.endStep(Phase.LOADING_FSIMAGE, step);\n        // Now that the step is finished, set counter equal to total to adjust\n        // for possible under-counting due to reference inodes.\n        prog.setCount(Phase.LOADING_FSIMAGE, step, numFiles);\n\n        loadSecretManagerState(in);\n\n        loadCacheManagerState(in);\n\n        // make sure to read to the end of file\n        boolean eof \u003d (in.read() \u003d\u003d -1);\n        assert eof : \"Should have reached the end of image file \" + curFile;\n      } finally {\n        in.close();\n      }\n\n      imgDigest \u003d new MD5Hash(digester.digest());\n      loaded \u003d true;\n      \n      LOG.info(\"Image file \" + curFile + \" of size \" + curFile.length()\n          + \" bytes loaded in \" + (monotonicNow() - startTime) / 1000\n          + \" seconds.\");\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {}
    },
    "8a91109d16394310f2568717f103e6fff7cbddb0": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9677. Rename generationStampV1/generationStampV2 to legacyGenerationStamp/generationStamp. Contributed by Mingliang Liu.\n",
      "commitDate": "27/01/16 3:48 PM",
      "commitName": "8a91109d16394310f2568717f103e6fff7cbddb0",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "21/01/16 11:13 AM",
      "commitNameOld": "c304890c8c7782d835896859f5b7f60b96c306c0",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 6.19,
      "commitsBetweenForRepo": 45,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,143 +1,143 @@\n     public void load(File curFile) throws IOException {\n       checkNotLoaded();\n       assert curFile !\u003d null : \"curFile is null\";\n \n       StartupProgress prog \u003d NameNode.getStartupProgress();\n       Step step \u003d new Step(StepType.INODES);\n       prog.beginStep(Phase.LOADING_FSIMAGE, step);\n       long startTime \u003d monotonicNow();\n \n       //\n       // Load in bits\n       //\n       MessageDigest digester \u003d MD5Hash.getDigester();\n       DigestInputStream fin \u003d new DigestInputStream(\n            new FileInputStream(curFile), digester);\n \n       DataInputStream in \u003d new DataInputStream(fin);\n       try {\n         // read image version: first appeared in version -1\n         int imgVersion \u003d in.readInt();\n         if (getLayoutVersion() !\u003d imgVersion) {\n           throw new InconsistentFSStateException(curFile, \n               \"imgVersion \" + imgVersion +\n               \" expected to be \" + getLayoutVersion());\n         }\n         boolean supportSnapshot \u003d NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.SNAPSHOT, imgVersion);\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.ADD_LAYOUT_FLAGS, imgVersion)) {\n           LayoutFlags.read(in);\n         }\n \n         // read namespaceID: first appeared in version -2\n         in.readInt();\n \n         long numFiles \u003d in.readLong();\n \n         // read in the last generation stamp for legacy blocks.\n         long genstamp \u003d in.readLong();\n         final BlockIdManager blockIdManager \u003d namesystem.getBlockManager()\n             .getBlockIdManager();\n-        blockIdManager.setGenerationStampV1(genstamp);\n+        blockIdManager.setLegacyGenerationStamp(genstamp);\n \n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.SEQUENTIAL_BLOCK_ID, imgVersion)) {\n           // read the starting generation stamp for sequential block IDs\n           genstamp \u003d in.readLong();\n-          blockIdManager.setGenerationStampV2(genstamp);\n+          blockIdManager.setGenerationStamp(genstamp);\n \n           // read the last generation stamp for blocks created after\n           // the switch to sequential block IDs.\n           long stampAtIdSwitch \u003d in.readLong();\n-          blockIdManager.setGenerationStampV1Limit(stampAtIdSwitch);\n+          blockIdManager.setLegacyGenerationStampLimit(stampAtIdSwitch);\n \n           // read the max sequential block ID.\n           long maxSequentialBlockId \u003d in.readLong();\n           blockIdManager.setLastAllocatedContiguousBlockId(maxSequentialBlockId);\n         } else {\n-          long startingGenStamp \u003d blockIdManager.upgradeGenerationStampToV2();\n+          long startingGenStamp \u003d blockIdManager.upgradeLegacyGenerationStamp();\n           // This is an upgrade.\n           LOG.info(\"Upgrading to sequential block IDs. Generation stamp \" +\n                    \"for new blocks set to \" + startingGenStamp);\n         }\n \n         // read the transaction ID of the last edit represented by\n         // this image\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.STORED_TXIDS, imgVersion)) {\n           imgTxId \u003d in.readLong();\n         } else {\n           imgTxId \u003d 0;\n         }\n \n         // read the last allocated inode id in the fsimage\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.ADD_INODE_ID, imgVersion)) {\n           long lastInodeId \u003d in.readLong();\n           namesystem.dir.resetLastInodeId(lastInodeId);\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"load last allocated InodeId from fsimage:\" + lastInodeId);\n           }\n         } else {\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"Old layout version doesn\u0027t have inode id.\"\n                 + \" Will assign new id for each inode.\");\n           }\n         }\n         \n         if (supportSnapshot) {\n           snapshotMap \u003d namesystem.getSnapshotManager().read(in, this);\n         }\n \n         // read compression related info\n         FSImageCompression compression;\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n           compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n         } else {\n           compression \u003d FSImageCompression.createNoopCompression();\n         }\n         in \u003d compression.unwrapInputStream(fin);\n \n         LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n         \n         // load all inodes\n         LOG.info(\"Number of files \u003d \" + numFiles);\n         prog.setTotal(Phase.LOADING_FSIMAGE, step, numFiles);\n         Counter counter \u003d prog.getCounter(Phase.LOADING_FSIMAGE, step);\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.FSIMAGE_NAME_OPTIMIZATION, imgVersion)) {\n           if (supportSnapshot) {\n             loadLocalNameINodesWithSnapshot(numFiles, in, counter);\n           } else {\n             loadLocalNameINodes(numFiles, in, counter);\n           }\n         } else {\n           loadFullNameINodes(numFiles, in, counter);\n         }\n \n         loadFilesUnderConstruction(in, supportSnapshot, counter);\n         prog.endStep(Phase.LOADING_FSIMAGE, step);\n         // Now that the step is finished, set counter equal to total to adjust\n         // for possible under-counting due to reference inodes.\n         prog.setCount(Phase.LOADING_FSIMAGE, step, numFiles);\n \n         loadSecretManagerState(in);\n \n         loadCacheManagerState(in);\n \n         // make sure to read to the end of file\n         boolean eof \u003d (in.read() \u003d\u003d -1);\n         assert eof : \"Should have reached the end of image file \" + curFile;\n       } finally {\n         in.close();\n       }\n \n       imgDigest \u003d new MD5Hash(digester.digest());\n       loaded \u003d true;\n       \n       LOG.info(\"Image file \" + curFile + \" of size \" + curFile.length()\n           + \" bytes loaded in \" + (monotonicNow() - startTime) / 1000\n           + \" seconds.\");\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void load(File curFile) throws IOException {\n      checkNotLoaded();\n      assert curFile !\u003d null : \"curFile is null\";\n\n      StartupProgress prog \u003d NameNode.getStartupProgress();\n      Step step \u003d new Step(StepType.INODES);\n      prog.beginStep(Phase.LOADING_FSIMAGE, step);\n      long startTime \u003d monotonicNow();\n\n      //\n      // Load in bits\n      //\n      MessageDigest digester \u003d MD5Hash.getDigester();\n      DigestInputStream fin \u003d new DigestInputStream(\n           new FileInputStream(curFile), digester);\n\n      DataInputStream in \u003d new DataInputStream(fin);\n      try {\n        // read image version: first appeared in version -1\n        int imgVersion \u003d in.readInt();\n        if (getLayoutVersion() !\u003d imgVersion) {\n          throw new InconsistentFSStateException(curFile, \n              \"imgVersion \" + imgVersion +\n              \" expected to be \" + getLayoutVersion());\n        }\n        boolean supportSnapshot \u003d NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.SNAPSHOT, imgVersion);\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.ADD_LAYOUT_FLAGS, imgVersion)) {\n          LayoutFlags.read(in);\n        }\n\n        // read namespaceID: first appeared in version -2\n        in.readInt();\n\n        long numFiles \u003d in.readLong();\n\n        // read in the last generation stamp for legacy blocks.\n        long genstamp \u003d in.readLong();\n        final BlockIdManager blockIdManager \u003d namesystem.getBlockManager()\n            .getBlockIdManager();\n        blockIdManager.setLegacyGenerationStamp(genstamp);\n\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.SEQUENTIAL_BLOCK_ID, imgVersion)) {\n          // read the starting generation stamp for sequential block IDs\n          genstamp \u003d in.readLong();\n          blockIdManager.setGenerationStamp(genstamp);\n\n          // read the last generation stamp for blocks created after\n          // the switch to sequential block IDs.\n          long stampAtIdSwitch \u003d in.readLong();\n          blockIdManager.setLegacyGenerationStampLimit(stampAtIdSwitch);\n\n          // read the max sequential block ID.\n          long maxSequentialBlockId \u003d in.readLong();\n          blockIdManager.setLastAllocatedContiguousBlockId(maxSequentialBlockId);\n        } else {\n          long startingGenStamp \u003d blockIdManager.upgradeLegacyGenerationStamp();\n          // This is an upgrade.\n          LOG.info(\"Upgrading to sequential block IDs. Generation stamp \" +\n                   \"for new blocks set to \" + startingGenStamp);\n        }\n\n        // read the transaction ID of the last edit represented by\n        // this image\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.STORED_TXIDS, imgVersion)) {\n          imgTxId \u003d in.readLong();\n        } else {\n          imgTxId \u003d 0;\n        }\n\n        // read the last allocated inode id in the fsimage\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.ADD_INODE_ID, imgVersion)) {\n          long lastInodeId \u003d in.readLong();\n          namesystem.dir.resetLastInodeId(lastInodeId);\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"load last allocated InodeId from fsimage:\" + lastInodeId);\n          }\n        } else {\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Old layout version doesn\u0027t have inode id.\"\n                + \" Will assign new id for each inode.\");\n          }\n        }\n        \n        if (supportSnapshot) {\n          snapshotMap \u003d namesystem.getSnapshotManager().read(in, this);\n        }\n\n        // read compression related info\n        FSImageCompression compression;\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n          compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n        } else {\n          compression \u003d FSImageCompression.createNoopCompression();\n        }\n        in \u003d compression.unwrapInputStream(fin);\n\n        LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n        \n        // load all inodes\n        LOG.info(\"Number of files \u003d \" + numFiles);\n        prog.setTotal(Phase.LOADING_FSIMAGE, step, numFiles);\n        Counter counter \u003d prog.getCounter(Phase.LOADING_FSIMAGE, step);\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.FSIMAGE_NAME_OPTIMIZATION, imgVersion)) {\n          if (supportSnapshot) {\n            loadLocalNameINodesWithSnapshot(numFiles, in, counter);\n          } else {\n            loadLocalNameINodes(numFiles, in, counter);\n          }\n        } else {\n          loadFullNameINodes(numFiles, in, counter);\n        }\n\n        loadFilesUnderConstruction(in, supportSnapshot, counter);\n        prog.endStep(Phase.LOADING_FSIMAGE, step);\n        // Now that the step is finished, set counter equal to total to adjust\n        // for possible under-counting due to reference inodes.\n        prog.setCount(Phase.LOADING_FSIMAGE, step, numFiles);\n\n        loadSecretManagerState(in);\n\n        loadCacheManagerState(in);\n\n        // make sure to read to the end of file\n        boolean eof \u003d (in.read() \u003d\u003d -1);\n        assert eof : \"Should have reached the end of image file \" + curFile;\n      } finally {\n        in.close();\n      }\n\n      imgDigest \u003d new MD5Hash(digester.digest());\n      loaded \u003d true;\n      \n      LOG.info(\"Image file \" + curFile + \" of size \" + curFile.length()\n          + \" bytes loaded in \" + (monotonicNow() - startTime) / 1000\n          + \" seconds.\");\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {}
    },
    "c304890c8c7782d835896859f5b7f60b96c306c0": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9542. Move BlockIdManager from FSNamesystem to BlockManager. Contributed by Jing Zhao.\n",
      "commitDate": "21/01/16 11:13 AM",
      "commitName": "c304890c8c7782d835896859f5b7f60b96c306c0",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "12/01/16 9:22 AM",
      "commitNameOld": "25051c3bd08efc12333a6acb51782cc7800403a4",
      "commitAuthorOld": "Yongjun Zhang",
      "daysBetweenCommits": 9.08,
      "commitsBetweenForRepo": 71,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,144 +1,143 @@\n     public void load(File curFile) throws IOException {\n       checkNotLoaded();\n       assert curFile !\u003d null : \"curFile is null\";\n \n       StartupProgress prog \u003d NameNode.getStartupProgress();\n       Step step \u003d new Step(StepType.INODES);\n       prog.beginStep(Phase.LOADING_FSIMAGE, step);\n       long startTime \u003d monotonicNow();\n \n       //\n       // Load in bits\n       //\n       MessageDigest digester \u003d MD5Hash.getDigester();\n       DigestInputStream fin \u003d new DigestInputStream(\n            new FileInputStream(curFile), digester);\n \n       DataInputStream in \u003d new DataInputStream(fin);\n       try {\n         // read image version: first appeared in version -1\n         int imgVersion \u003d in.readInt();\n         if (getLayoutVersion() !\u003d imgVersion) {\n           throw new InconsistentFSStateException(curFile, \n               \"imgVersion \" + imgVersion +\n               \" expected to be \" + getLayoutVersion());\n         }\n         boolean supportSnapshot \u003d NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.SNAPSHOT, imgVersion);\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.ADD_LAYOUT_FLAGS, imgVersion)) {\n           LayoutFlags.read(in);\n         }\n \n         // read namespaceID: first appeared in version -2\n         in.readInt();\n \n         long numFiles \u003d in.readLong();\n \n         // read in the last generation stamp for legacy blocks.\n         long genstamp \u003d in.readLong();\n-        namesystem.getBlockIdManager().setGenerationStampV1(genstamp);\n+        final BlockIdManager blockIdManager \u003d namesystem.getBlockManager()\n+            .getBlockIdManager();\n+        blockIdManager.setGenerationStampV1(genstamp);\n \n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.SEQUENTIAL_BLOCK_ID, imgVersion)) {\n           // read the starting generation stamp for sequential block IDs\n           genstamp \u003d in.readLong();\n-          namesystem.getBlockIdManager().setGenerationStampV2(genstamp);\n+          blockIdManager.setGenerationStampV2(genstamp);\n \n           // read the last generation stamp for blocks created after\n           // the switch to sequential block IDs.\n           long stampAtIdSwitch \u003d in.readLong();\n-          namesystem.getBlockIdManager().setGenerationStampV1Limit(stampAtIdSwitch);\n+          blockIdManager.setGenerationStampV1Limit(stampAtIdSwitch);\n \n           // read the max sequential block ID.\n           long maxSequentialBlockId \u003d in.readLong();\n-          namesystem.getBlockIdManager().setLastAllocatedContiguousBlockId(\n-              maxSequentialBlockId);\n+          blockIdManager.setLastAllocatedContiguousBlockId(maxSequentialBlockId);\n         } else {\n-\n-          long startingGenStamp \u003d namesystem.getBlockIdManager()\n-            .upgradeGenerationStampToV2();\n+          long startingGenStamp \u003d blockIdManager.upgradeGenerationStampToV2();\n           // This is an upgrade.\n           LOG.info(\"Upgrading to sequential block IDs. Generation stamp \" +\n                    \"for new blocks set to \" + startingGenStamp);\n         }\n \n         // read the transaction ID of the last edit represented by\n         // this image\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.STORED_TXIDS, imgVersion)) {\n           imgTxId \u003d in.readLong();\n         } else {\n           imgTxId \u003d 0;\n         }\n \n         // read the last allocated inode id in the fsimage\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.ADD_INODE_ID, imgVersion)) {\n           long lastInodeId \u003d in.readLong();\n           namesystem.dir.resetLastInodeId(lastInodeId);\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"load last allocated InodeId from fsimage:\" + lastInodeId);\n           }\n         } else {\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"Old layout version doesn\u0027t have inode id.\"\n                 + \" Will assign new id for each inode.\");\n           }\n         }\n         \n         if (supportSnapshot) {\n           snapshotMap \u003d namesystem.getSnapshotManager().read(in, this);\n         }\n \n         // read compression related info\n         FSImageCompression compression;\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n           compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n         } else {\n           compression \u003d FSImageCompression.createNoopCompression();\n         }\n         in \u003d compression.unwrapInputStream(fin);\n \n         LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n         \n         // load all inodes\n         LOG.info(\"Number of files \u003d \" + numFiles);\n         prog.setTotal(Phase.LOADING_FSIMAGE, step, numFiles);\n         Counter counter \u003d prog.getCounter(Phase.LOADING_FSIMAGE, step);\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.FSIMAGE_NAME_OPTIMIZATION, imgVersion)) {\n           if (supportSnapshot) {\n             loadLocalNameINodesWithSnapshot(numFiles, in, counter);\n           } else {\n             loadLocalNameINodes(numFiles, in, counter);\n           }\n         } else {\n           loadFullNameINodes(numFiles, in, counter);\n         }\n \n         loadFilesUnderConstruction(in, supportSnapshot, counter);\n         prog.endStep(Phase.LOADING_FSIMAGE, step);\n         // Now that the step is finished, set counter equal to total to adjust\n         // for possible under-counting due to reference inodes.\n         prog.setCount(Phase.LOADING_FSIMAGE, step, numFiles);\n \n         loadSecretManagerState(in);\n \n         loadCacheManagerState(in);\n \n         // make sure to read to the end of file\n         boolean eof \u003d (in.read() \u003d\u003d -1);\n         assert eof : \"Should have reached the end of image file \" + curFile;\n       } finally {\n         in.close();\n       }\n \n       imgDigest \u003d new MD5Hash(digester.digest());\n       loaded \u003d true;\n       \n       LOG.info(\"Image file \" + curFile + \" of size \" + curFile.length()\n           + \" bytes loaded in \" + (monotonicNow() - startTime) / 1000\n           + \" seconds.\");\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void load(File curFile) throws IOException {\n      checkNotLoaded();\n      assert curFile !\u003d null : \"curFile is null\";\n\n      StartupProgress prog \u003d NameNode.getStartupProgress();\n      Step step \u003d new Step(StepType.INODES);\n      prog.beginStep(Phase.LOADING_FSIMAGE, step);\n      long startTime \u003d monotonicNow();\n\n      //\n      // Load in bits\n      //\n      MessageDigest digester \u003d MD5Hash.getDigester();\n      DigestInputStream fin \u003d new DigestInputStream(\n           new FileInputStream(curFile), digester);\n\n      DataInputStream in \u003d new DataInputStream(fin);\n      try {\n        // read image version: first appeared in version -1\n        int imgVersion \u003d in.readInt();\n        if (getLayoutVersion() !\u003d imgVersion) {\n          throw new InconsistentFSStateException(curFile, \n              \"imgVersion \" + imgVersion +\n              \" expected to be \" + getLayoutVersion());\n        }\n        boolean supportSnapshot \u003d NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.SNAPSHOT, imgVersion);\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.ADD_LAYOUT_FLAGS, imgVersion)) {\n          LayoutFlags.read(in);\n        }\n\n        // read namespaceID: first appeared in version -2\n        in.readInt();\n\n        long numFiles \u003d in.readLong();\n\n        // read in the last generation stamp for legacy blocks.\n        long genstamp \u003d in.readLong();\n        final BlockIdManager blockIdManager \u003d namesystem.getBlockManager()\n            .getBlockIdManager();\n        blockIdManager.setGenerationStampV1(genstamp);\n\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.SEQUENTIAL_BLOCK_ID, imgVersion)) {\n          // read the starting generation stamp for sequential block IDs\n          genstamp \u003d in.readLong();\n          blockIdManager.setGenerationStampV2(genstamp);\n\n          // read the last generation stamp for blocks created after\n          // the switch to sequential block IDs.\n          long stampAtIdSwitch \u003d in.readLong();\n          blockIdManager.setGenerationStampV1Limit(stampAtIdSwitch);\n\n          // read the max sequential block ID.\n          long maxSequentialBlockId \u003d in.readLong();\n          blockIdManager.setLastAllocatedContiguousBlockId(maxSequentialBlockId);\n        } else {\n          long startingGenStamp \u003d blockIdManager.upgradeGenerationStampToV2();\n          // This is an upgrade.\n          LOG.info(\"Upgrading to sequential block IDs. Generation stamp \" +\n                   \"for new blocks set to \" + startingGenStamp);\n        }\n\n        // read the transaction ID of the last edit represented by\n        // this image\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.STORED_TXIDS, imgVersion)) {\n          imgTxId \u003d in.readLong();\n        } else {\n          imgTxId \u003d 0;\n        }\n\n        // read the last allocated inode id in the fsimage\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.ADD_INODE_ID, imgVersion)) {\n          long lastInodeId \u003d in.readLong();\n          namesystem.dir.resetLastInodeId(lastInodeId);\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"load last allocated InodeId from fsimage:\" + lastInodeId);\n          }\n        } else {\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Old layout version doesn\u0027t have inode id.\"\n                + \" Will assign new id for each inode.\");\n          }\n        }\n        \n        if (supportSnapshot) {\n          snapshotMap \u003d namesystem.getSnapshotManager().read(in, this);\n        }\n\n        // read compression related info\n        FSImageCompression compression;\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n          compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n        } else {\n          compression \u003d FSImageCompression.createNoopCompression();\n        }\n        in \u003d compression.unwrapInputStream(fin);\n\n        LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n        \n        // load all inodes\n        LOG.info(\"Number of files \u003d \" + numFiles);\n        prog.setTotal(Phase.LOADING_FSIMAGE, step, numFiles);\n        Counter counter \u003d prog.getCounter(Phase.LOADING_FSIMAGE, step);\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.FSIMAGE_NAME_OPTIMIZATION, imgVersion)) {\n          if (supportSnapshot) {\n            loadLocalNameINodesWithSnapshot(numFiles, in, counter);\n          } else {\n            loadLocalNameINodes(numFiles, in, counter);\n          }\n        } else {\n          loadFullNameINodes(numFiles, in, counter);\n        }\n\n        loadFilesUnderConstruction(in, supportSnapshot, counter);\n        prog.endStep(Phase.LOADING_FSIMAGE, step);\n        // Now that the step is finished, set counter equal to total to adjust\n        // for possible under-counting due to reference inodes.\n        prog.setCount(Phase.LOADING_FSIMAGE, step, numFiles);\n\n        loadSecretManagerState(in);\n\n        loadCacheManagerState(in);\n\n        // make sure to read to the end of file\n        boolean eof \u003d (in.read() \u003d\u003d -1);\n        assert eof : \"Should have reached the end of image file \" + curFile;\n      } finally {\n        in.close();\n      }\n\n      imgDigest \u003d new MD5Hash(digester.digest());\n      loaded \u003d true;\n      \n      LOG.info(\"Image file \" + curFile + \" of size \" + curFile.length()\n          + \" bytes loaded in \" + (monotonicNow() - startTime) / 1000\n          + \" seconds.\");\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {}
    },
    "49d5cff49011cc0878665204e22b5c832bc914ce": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8559. Erasure Coding: fix non-protobuf fsimage for striped blocks. (Jing Zhao via yliu)\n",
      "commitDate": "14/06/15 12:39 AM",
      "commitName": "49d5cff49011cc0878665204e22b5c832bc914ce",
      "commitAuthor": "yliu",
      "commitDateOld": "26/05/15 12:02 PM",
      "commitNameOld": "c9103e9cacc67a614940e32fa87c5dbc3daa60de",
      "commitAuthorOld": "Kai Zheng",
      "daysBetweenCommits": 18.53,
      "commitsBetweenForRepo": 43,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,150 +1,144 @@\n     public void load(File curFile) throws IOException {\n       checkNotLoaded();\n       assert curFile !\u003d null : \"curFile is null\";\n \n       StartupProgress prog \u003d NameNode.getStartupProgress();\n       Step step \u003d new Step(StepType.INODES);\n       prog.beginStep(Phase.LOADING_FSIMAGE, step);\n       long startTime \u003d monotonicNow();\n \n       //\n       // Load in bits\n       //\n       MessageDigest digester \u003d MD5Hash.getDigester();\n       DigestInputStream fin \u003d new DigestInputStream(\n            new FileInputStream(curFile), digester);\n \n       DataInputStream in \u003d new DataInputStream(fin);\n       try {\n         // read image version: first appeared in version -1\n         int imgVersion \u003d in.readInt();\n         if (getLayoutVersion() !\u003d imgVersion) {\n           throw new InconsistentFSStateException(curFile, \n               \"imgVersion \" + imgVersion +\n               \" expected to be \" + getLayoutVersion());\n         }\n         boolean supportSnapshot \u003d NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.SNAPSHOT, imgVersion);\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.ADD_LAYOUT_FLAGS, imgVersion)) {\n           LayoutFlags.read(in);\n         }\n \n         // read namespaceID: first appeared in version -2\n         in.readInt();\n \n         long numFiles \u003d in.readLong();\n \n         // read in the last generation stamp for legacy blocks.\n         long genstamp \u003d in.readLong();\n         namesystem.getBlockIdManager().setGenerationStampV1(genstamp);\n \n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.SEQUENTIAL_BLOCK_ID, imgVersion)) {\n           // read the starting generation stamp for sequential block IDs\n           genstamp \u003d in.readLong();\n           namesystem.getBlockIdManager().setGenerationStampV2(genstamp);\n \n           // read the last generation stamp for blocks created after\n           // the switch to sequential block IDs.\n           long stampAtIdSwitch \u003d in.readLong();\n           namesystem.getBlockIdManager().setGenerationStampV1Limit(stampAtIdSwitch);\n \n           // read the max sequential block ID.\n           long maxSequentialBlockId \u003d in.readLong();\n           namesystem.getBlockIdManager().setLastAllocatedContiguousBlockId(\n               maxSequentialBlockId);\n-          if (NameNodeLayoutVersion.supports(\n-              NameNodeLayoutVersion.Feature.ERASURE_CODING, imgVersion)) {\n-            final long maxStripedBlockId \u003d in.readLong();\n-            namesystem.getBlockIdManager().setLastAllocatedStripedBlockId(\n-                maxStripedBlockId);\n-          }\n         } else {\n \n           long startingGenStamp \u003d namesystem.getBlockIdManager()\n             .upgradeGenerationStampToV2();\n           // This is an upgrade.\n           LOG.info(\"Upgrading to sequential block IDs. Generation stamp \" +\n                    \"for new blocks set to \" + startingGenStamp);\n         }\n \n         // read the transaction ID of the last edit represented by\n         // this image\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.STORED_TXIDS, imgVersion)) {\n           imgTxId \u003d in.readLong();\n         } else {\n           imgTxId \u003d 0;\n         }\n \n         // read the last allocated inode id in the fsimage\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.ADD_INODE_ID, imgVersion)) {\n           long lastInodeId \u003d in.readLong();\n           namesystem.dir.resetLastInodeId(lastInodeId);\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"load last allocated InodeId from fsimage:\" + lastInodeId);\n           }\n         } else {\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"Old layout version doesn\u0027t have inode id.\"\n                 + \" Will assign new id for each inode.\");\n           }\n         }\n         \n         if (supportSnapshot) {\n           snapshotMap \u003d namesystem.getSnapshotManager().read(in, this);\n         }\n \n         // read compression related info\n         FSImageCompression compression;\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n           compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n         } else {\n           compression \u003d FSImageCompression.createNoopCompression();\n         }\n         in \u003d compression.unwrapInputStream(fin);\n \n         LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n         \n         // load all inodes\n         LOG.info(\"Number of files \u003d \" + numFiles);\n         prog.setTotal(Phase.LOADING_FSIMAGE, step, numFiles);\n         Counter counter \u003d prog.getCounter(Phase.LOADING_FSIMAGE, step);\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.FSIMAGE_NAME_OPTIMIZATION, imgVersion)) {\n           if (supportSnapshot) {\n             loadLocalNameINodesWithSnapshot(numFiles, in, counter);\n           } else {\n             loadLocalNameINodes(numFiles, in, counter);\n           }\n         } else {\n           loadFullNameINodes(numFiles, in, counter);\n         }\n \n         loadFilesUnderConstruction(in, supportSnapshot, counter);\n         prog.endStep(Phase.LOADING_FSIMAGE, step);\n         // Now that the step is finished, set counter equal to total to adjust\n         // for possible under-counting due to reference inodes.\n         prog.setCount(Phase.LOADING_FSIMAGE, step, numFiles);\n \n         loadSecretManagerState(in);\n \n         loadCacheManagerState(in);\n \n         // make sure to read to the end of file\n         boolean eof \u003d (in.read() \u003d\u003d -1);\n         assert eof : \"Should have reached the end of image file \" + curFile;\n       } finally {\n         in.close();\n       }\n \n       imgDigest \u003d new MD5Hash(digester.digest());\n       loaded \u003d true;\n       \n       LOG.info(\"Image file \" + curFile + \" of size \" + curFile.length()\n           + \" bytes loaded in \" + (monotonicNow() - startTime) / 1000\n           + \" seconds.\");\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void load(File curFile) throws IOException {\n      checkNotLoaded();\n      assert curFile !\u003d null : \"curFile is null\";\n\n      StartupProgress prog \u003d NameNode.getStartupProgress();\n      Step step \u003d new Step(StepType.INODES);\n      prog.beginStep(Phase.LOADING_FSIMAGE, step);\n      long startTime \u003d monotonicNow();\n\n      //\n      // Load in bits\n      //\n      MessageDigest digester \u003d MD5Hash.getDigester();\n      DigestInputStream fin \u003d new DigestInputStream(\n           new FileInputStream(curFile), digester);\n\n      DataInputStream in \u003d new DataInputStream(fin);\n      try {\n        // read image version: first appeared in version -1\n        int imgVersion \u003d in.readInt();\n        if (getLayoutVersion() !\u003d imgVersion) {\n          throw new InconsistentFSStateException(curFile, \n              \"imgVersion \" + imgVersion +\n              \" expected to be \" + getLayoutVersion());\n        }\n        boolean supportSnapshot \u003d NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.SNAPSHOT, imgVersion);\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.ADD_LAYOUT_FLAGS, imgVersion)) {\n          LayoutFlags.read(in);\n        }\n\n        // read namespaceID: first appeared in version -2\n        in.readInt();\n\n        long numFiles \u003d in.readLong();\n\n        // read in the last generation stamp for legacy blocks.\n        long genstamp \u003d in.readLong();\n        namesystem.getBlockIdManager().setGenerationStampV1(genstamp);\n\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.SEQUENTIAL_BLOCK_ID, imgVersion)) {\n          // read the starting generation stamp for sequential block IDs\n          genstamp \u003d in.readLong();\n          namesystem.getBlockIdManager().setGenerationStampV2(genstamp);\n\n          // read the last generation stamp for blocks created after\n          // the switch to sequential block IDs.\n          long stampAtIdSwitch \u003d in.readLong();\n          namesystem.getBlockIdManager().setGenerationStampV1Limit(stampAtIdSwitch);\n\n          // read the max sequential block ID.\n          long maxSequentialBlockId \u003d in.readLong();\n          namesystem.getBlockIdManager().setLastAllocatedContiguousBlockId(\n              maxSequentialBlockId);\n        } else {\n\n          long startingGenStamp \u003d namesystem.getBlockIdManager()\n            .upgradeGenerationStampToV2();\n          // This is an upgrade.\n          LOG.info(\"Upgrading to sequential block IDs. Generation stamp \" +\n                   \"for new blocks set to \" + startingGenStamp);\n        }\n\n        // read the transaction ID of the last edit represented by\n        // this image\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.STORED_TXIDS, imgVersion)) {\n          imgTxId \u003d in.readLong();\n        } else {\n          imgTxId \u003d 0;\n        }\n\n        // read the last allocated inode id in the fsimage\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.ADD_INODE_ID, imgVersion)) {\n          long lastInodeId \u003d in.readLong();\n          namesystem.dir.resetLastInodeId(lastInodeId);\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"load last allocated InodeId from fsimage:\" + lastInodeId);\n          }\n        } else {\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Old layout version doesn\u0027t have inode id.\"\n                + \" Will assign new id for each inode.\");\n          }\n        }\n        \n        if (supportSnapshot) {\n          snapshotMap \u003d namesystem.getSnapshotManager().read(in, this);\n        }\n\n        // read compression related info\n        FSImageCompression compression;\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n          compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n        } else {\n          compression \u003d FSImageCompression.createNoopCompression();\n        }\n        in \u003d compression.unwrapInputStream(fin);\n\n        LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n        \n        // load all inodes\n        LOG.info(\"Number of files \u003d \" + numFiles);\n        prog.setTotal(Phase.LOADING_FSIMAGE, step, numFiles);\n        Counter counter \u003d prog.getCounter(Phase.LOADING_FSIMAGE, step);\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.FSIMAGE_NAME_OPTIMIZATION, imgVersion)) {\n          if (supportSnapshot) {\n            loadLocalNameINodesWithSnapshot(numFiles, in, counter);\n          } else {\n            loadLocalNameINodes(numFiles, in, counter);\n          }\n        } else {\n          loadFullNameINodes(numFiles, in, counter);\n        }\n\n        loadFilesUnderConstruction(in, supportSnapshot, counter);\n        prog.endStep(Phase.LOADING_FSIMAGE, step);\n        // Now that the step is finished, set counter equal to total to adjust\n        // for possible under-counting due to reference inodes.\n        prog.setCount(Phase.LOADING_FSIMAGE, step, numFiles);\n\n        loadSecretManagerState(in);\n\n        loadCacheManagerState(in);\n\n        // make sure to read to the end of file\n        boolean eof \u003d (in.read() \u003d\u003d -1);\n        assert eof : \"Should have reached the end of image file \" + curFile;\n      } finally {\n        in.close();\n      }\n\n      imgDigest \u003d new MD5Hash(digester.digest());\n      loaded \u003d true;\n      \n      LOG.info(\"Image file \" + curFile + \" of size \" + curFile.length()\n          + \" bytes loaded in \" + (monotonicNow() - startTime) / 1000\n          + \" seconds.\");\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {}
    },
    "1e1e93040748231dc913190aec1e031c379d8271": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7837. Erasure Coding: allocate and persist striped blocks in NameNode. Contributed by Jing Zhao.\n",
      "commitDate": "26/05/15 11:32 AM",
      "commitName": "1e1e93040748231dc913190aec1e031c379d8271",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "26/05/15 11:07 AM",
      "commitNameOld": "9f2f583f401189c3f4a2687795a9e3e0b288322b",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 0.02,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,143 +1,150 @@\n     public void load(File curFile) throws IOException {\n       checkNotLoaded();\n       assert curFile !\u003d null : \"curFile is null\";\n \n       StartupProgress prog \u003d NameNode.getStartupProgress();\n       Step step \u003d new Step(StepType.INODES);\n       prog.beginStep(Phase.LOADING_FSIMAGE, step);\n       long startTime \u003d monotonicNow();\n \n       //\n       // Load in bits\n       //\n       MessageDigest digester \u003d MD5Hash.getDigester();\n       DigestInputStream fin \u003d new DigestInputStream(\n            new FileInputStream(curFile), digester);\n \n       DataInputStream in \u003d new DataInputStream(fin);\n       try {\n         // read image version: first appeared in version -1\n         int imgVersion \u003d in.readInt();\n         if (getLayoutVersion() !\u003d imgVersion) {\n           throw new InconsistentFSStateException(curFile, \n               \"imgVersion \" + imgVersion +\n               \" expected to be \" + getLayoutVersion());\n         }\n         boolean supportSnapshot \u003d NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.SNAPSHOT, imgVersion);\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.ADD_LAYOUT_FLAGS, imgVersion)) {\n           LayoutFlags.read(in);\n         }\n \n         // read namespaceID: first appeared in version -2\n         in.readInt();\n \n         long numFiles \u003d in.readLong();\n \n         // read in the last generation stamp for legacy blocks.\n         long genstamp \u003d in.readLong();\n         namesystem.getBlockIdManager().setGenerationStampV1(genstamp);\n \n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.SEQUENTIAL_BLOCK_ID, imgVersion)) {\n           // read the starting generation stamp for sequential block IDs\n           genstamp \u003d in.readLong();\n           namesystem.getBlockIdManager().setGenerationStampV2(genstamp);\n \n           // read the last generation stamp for blocks created after\n           // the switch to sequential block IDs.\n           long stampAtIdSwitch \u003d in.readLong();\n           namesystem.getBlockIdManager().setGenerationStampV1Limit(stampAtIdSwitch);\n \n           // read the max sequential block ID.\n           long maxSequentialBlockId \u003d in.readLong();\n-          namesystem.getBlockIdManager().setLastAllocatedBlockId(maxSequentialBlockId);\n+          namesystem.getBlockIdManager().setLastAllocatedContiguousBlockId(\n+              maxSequentialBlockId);\n+          if (NameNodeLayoutVersion.supports(\n+              NameNodeLayoutVersion.Feature.ERASURE_CODING, imgVersion)) {\n+            final long maxStripedBlockId \u003d in.readLong();\n+            namesystem.getBlockIdManager().setLastAllocatedStripedBlockId(\n+                maxStripedBlockId);\n+          }\n         } else {\n \n           long startingGenStamp \u003d namesystem.getBlockIdManager()\n             .upgradeGenerationStampToV2();\n           // This is an upgrade.\n           LOG.info(\"Upgrading to sequential block IDs. Generation stamp \" +\n                    \"for new blocks set to \" + startingGenStamp);\n         }\n \n         // read the transaction ID of the last edit represented by\n         // this image\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.STORED_TXIDS, imgVersion)) {\n           imgTxId \u003d in.readLong();\n         } else {\n           imgTxId \u003d 0;\n         }\n \n         // read the last allocated inode id in the fsimage\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.ADD_INODE_ID, imgVersion)) {\n           long lastInodeId \u003d in.readLong();\n           namesystem.dir.resetLastInodeId(lastInodeId);\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"load last allocated InodeId from fsimage:\" + lastInodeId);\n           }\n         } else {\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"Old layout version doesn\u0027t have inode id.\"\n                 + \" Will assign new id for each inode.\");\n           }\n         }\n         \n         if (supportSnapshot) {\n           snapshotMap \u003d namesystem.getSnapshotManager().read(in, this);\n         }\n \n         // read compression related info\n         FSImageCompression compression;\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n           compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n         } else {\n           compression \u003d FSImageCompression.createNoopCompression();\n         }\n         in \u003d compression.unwrapInputStream(fin);\n \n         LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n         \n         // load all inodes\n         LOG.info(\"Number of files \u003d \" + numFiles);\n         prog.setTotal(Phase.LOADING_FSIMAGE, step, numFiles);\n         Counter counter \u003d prog.getCounter(Phase.LOADING_FSIMAGE, step);\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.FSIMAGE_NAME_OPTIMIZATION, imgVersion)) {\n           if (supportSnapshot) {\n             loadLocalNameINodesWithSnapshot(numFiles, in, counter);\n           } else {\n             loadLocalNameINodes(numFiles, in, counter);\n           }\n         } else {\n           loadFullNameINodes(numFiles, in, counter);\n         }\n \n         loadFilesUnderConstruction(in, supportSnapshot, counter);\n         prog.endStep(Phase.LOADING_FSIMAGE, step);\n         // Now that the step is finished, set counter equal to total to adjust\n         // for possible under-counting due to reference inodes.\n         prog.setCount(Phase.LOADING_FSIMAGE, step, numFiles);\n \n         loadSecretManagerState(in);\n \n         loadCacheManagerState(in);\n \n         // make sure to read to the end of file\n         boolean eof \u003d (in.read() \u003d\u003d -1);\n         assert eof : \"Should have reached the end of image file \" + curFile;\n       } finally {\n         in.close();\n       }\n \n       imgDigest \u003d new MD5Hash(digester.digest());\n       loaded \u003d true;\n       \n       LOG.info(\"Image file \" + curFile + \" of size \" + curFile.length()\n           + \" bytes loaded in \" + (monotonicNow() - startTime) / 1000\n           + \" seconds.\");\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void load(File curFile) throws IOException {\n      checkNotLoaded();\n      assert curFile !\u003d null : \"curFile is null\";\n\n      StartupProgress prog \u003d NameNode.getStartupProgress();\n      Step step \u003d new Step(StepType.INODES);\n      prog.beginStep(Phase.LOADING_FSIMAGE, step);\n      long startTime \u003d monotonicNow();\n\n      //\n      // Load in bits\n      //\n      MessageDigest digester \u003d MD5Hash.getDigester();\n      DigestInputStream fin \u003d new DigestInputStream(\n           new FileInputStream(curFile), digester);\n\n      DataInputStream in \u003d new DataInputStream(fin);\n      try {\n        // read image version: first appeared in version -1\n        int imgVersion \u003d in.readInt();\n        if (getLayoutVersion() !\u003d imgVersion) {\n          throw new InconsistentFSStateException(curFile, \n              \"imgVersion \" + imgVersion +\n              \" expected to be \" + getLayoutVersion());\n        }\n        boolean supportSnapshot \u003d NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.SNAPSHOT, imgVersion);\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.ADD_LAYOUT_FLAGS, imgVersion)) {\n          LayoutFlags.read(in);\n        }\n\n        // read namespaceID: first appeared in version -2\n        in.readInt();\n\n        long numFiles \u003d in.readLong();\n\n        // read in the last generation stamp for legacy blocks.\n        long genstamp \u003d in.readLong();\n        namesystem.getBlockIdManager().setGenerationStampV1(genstamp);\n\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.SEQUENTIAL_BLOCK_ID, imgVersion)) {\n          // read the starting generation stamp for sequential block IDs\n          genstamp \u003d in.readLong();\n          namesystem.getBlockIdManager().setGenerationStampV2(genstamp);\n\n          // read the last generation stamp for blocks created after\n          // the switch to sequential block IDs.\n          long stampAtIdSwitch \u003d in.readLong();\n          namesystem.getBlockIdManager().setGenerationStampV1Limit(stampAtIdSwitch);\n\n          // read the max sequential block ID.\n          long maxSequentialBlockId \u003d in.readLong();\n          namesystem.getBlockIdManager().setLastAllocatedContiguousBlockId(\n              maxSequentialBlockId);\n          if (NameNodeLayoutVersion.supports(\n              NameNodeLayoutVersion.Feature.ERASURE_CODING, imgVersion)) {\n            final long maxStripedBlockId \u003d in.readLong();\n            namesystem.getBlockIdManager().setLastAllocatedStripedBlockId(\n                maxStripedBlockId);\n          }\n        } else {\n\n          long startingGenStamp \u003d namesystem.getBlockIdManager()\n            .upgradeGenerationStampToV2();\n          // This is an upgrade.\n          LOG.info(\"Upgrading to sequential block IDs. Generation stamp \" +\n                   \"for new blocks set to \" + startingGenStamp);\n        }\n\n        // read the transaction ID of the last edit represented by\n        // this image\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.STORED_TXIDS, imgVersion)) {\n          imgTxId \u003d in.readLong();\n        } else {\n          imgTxId \u003d 0;\n        }\n\n        // read the last allocated inode id in the fsimage\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.ADD_INODE_ID, imgVersion)) {\n          long lastInodeId \u003d in.readLong();\n          namesystem.dir.resetLastInodeId(lastInodeId);\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"load last allocated InodeId from fsimage:\" + lastInodeId);\n          }\n        } else {\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Old layout version doesn\u0027t have inode id.\"\n                + \" Will assign new id for each inode.\");\n          }\n        }\n        \n        if (supportSnapshot) {\n          snapshotMap \u003d namesystem.getSnapshotManager().read(in, this);\n        }\n\n        // read compression related info\n        FSImageCompression compression;\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n          compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n        } else {\n          compression \u003d FSImageCompression.createNoopCompression();\n        }\n        in \u003d compression.unwrapInputStream(fin);\n\n        LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n        \n        // load all inodes\n        LOG.info(\"Number of files \u003d \" + numFiles);\n        prog.setTotal(Phase.LOADING_FSIMAGE, step, numFiles);\n        Counter counter \u003d prog.getCounter(Phase.LOADING_FSIMAGE, step);\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.FSIMAGE_NAME_OPTIMIZATION, imgVersion)) {\n          if (supportSnapshot) {\n            loadLocalNameINodesWithSnapshot(numFiles, in, counter);\n          } else {\n            loadLocalNameINodes(numFiles, in, counter);\n          }\n        } else {\n          loadFullNameINodes(numFiles, in, counter);\n        }\n\n        loadFilesUnderConstruction(in, supportSnapshot, counter);\n        prog.endStep(Phase.LOADING_FSIMAGE, step);\n        // Now that the step is finished, set counter equal to total to adjust\n        // for possible under-counting due to reference inodes.\n        prog.setCount(Phase.LOADING_FSIMAGE, step, numFiles);\n\n        loadSecretManagerState(in);\n\n        loadCacheManagerState(in);\n\n        // make sure to read to the end of file\n        boolean eof \u003d (in.read() \u003d\u003d -1);\n        assert eof : \"Should have reached the end of image file \" + curFile;\n      } finally {\n        in.close();\n      }\n\n      imgDigest \u003d new MD5Hash(digester.digest());\n      loaded \u003d true;\n      \n      LOG.info(\"Image file \" + curFile + \" of size \" + curFile.length()\n          + \" bytes loaded in \" + (monotonicNow() - startTime) / 1000\n          + \" seconds.\");\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {}
    },
    "75ead273bea8a7dad61c4f99c3a16cab2697c498": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6841. Use Time.monotonicNow() wherever applicable instead of Time.now(). Contributed by Vinayakumar B\n",
      "commitDate": "20/03/15 12:02 PM",
      "commitName": "75ead273bea8a7dad61c4f99c3a16cab2697c498",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "13/02/15 9:01 PM",
      "commitNameOld": "f2231cebcddc80f0b753c4a7cb45ee4040846951",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 34.58,
      "commitsBetweenForRepo": 294,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,142 +1,143 @@\n     public void load(File curFile) throws IOException {\n       checkNotLoaded();\n       assert curFile !\u003d null : \"curFile is null\";\n \n       StartupProgress prog \u003d NameNode.getStartupProgress();\n       Step step \u003d new Step(StepType.INODES);\n       prog.beginStep(Phase.LOADING_FSIMAGE, step);\n-      long startTime \u003d now();\n+      long startTime \u003d monotonicNow();\n \n       //\n       // Load in bits\n       //\n       MessageDigest digester \u003d MD5Hash.getDigester();\n       DigestInputStream fin \u003d new DigestInputStream(\n            new FileInputStream(curFile), digester);\n \n       DataInputStream in \u003d new DataInputStream(fin);\n       try {\n         // read image version: first appeared in version -1\n         int imgVersion \u003d in.readInt();\n         if (getLayoutVersion() !\u003d imgVersion) {\n           throw new InconsistentFSStateException(curFile, \n               \"imgVersion \" + imgVersion +\n               \" expected to be \" + getLayoutVersion());\n         }\n         boolean supportSnapshot \u003d NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.SNAPSHOT, imgVersion);\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.ADD_LAYOUT_FLAGS, imgVersion)) {\n           LayoutFlags.read(in);\n         }\n \n         // read namespaceID: first appeared in version -2\n         in.readInt();\n \n         long numFiles \u003d in.readLong();\n \n         // read in the last generation stamp for legacy blocks.\n         long genstamp \u003d in.readLong();\n         namesystem.getBlockIdManager().setGenerationStampV1(genstamp);\n \n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.SEQUENTIAL_BLOCK_ID, imgVersion)) {\n           // read the starting generation stamp for sequential block IDs\n           genstamp \u003d in.readLong();\n           namesystem.getBlockIdManager().setGenerationStampV2(genstamp);\n \n           // read the last generation stamp for blocks created after\n           // the switch to sequential block IDs.\n           long stampAtIdSwitch \u003d in.readLong();\n           namesystem.getBlockIdManager().setGenerationStampV1Limit(stampAtIdSwitch);\n \n           // read the max sequential block ID.\n           long maxSequentialBlockId \u003d in.readLong();\n           namesystem.getBlockIdManager().setLastAllocatedBlockId(maxSequentialBlockId);\n         } else {\n \n           long startingGenStamp \u003d namesystem.getBlockIdManager()\n             .upgradeGenerationStampToV2();\n           // This is an upgrade.\n           LOG.info(\"Upgrading to sequential block IDs. Generation stamp \" +\n                    \"for new blocks set to \" + startingGenStamp);\n         }\n \n         // read the transaction ID of the last edit represented by\n         // this image\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.STORED_TXIDS, imgVersion)) {\n           imgTxId \u003d in.readLong();\n         } else {\n           imgTxId \u003d 0;\n         }\n \n         // read the last allocated inode id in the fsimage\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.ADD_INODE_ID, imgVersion)) {\n           long lastInodeId \u003d in.readLong();\n           namesystem.dir.resetLastInodeId(lastInodeId);\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"load last allocated InodeId from fsimage:\" + lastInodeId);\n           }\n         } else {\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"Old layout version doesn\u0027t have inode id.\"\n                 + \" Will assign new id for each inode.\");\n           }\n         }\n         \n         if (supportSnapshot) {\n           snapshotMap \u003d namesystem.getSnapshotManager().read(in, this);\n         }\n \n         // read compression related info\n         FSImageCompression compression;\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n           compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n         } else {\n           compression \u003d FSImageCompression.createNoopCompression();\n         }\n         in \u003d compression.unwrapInputStream(fin);\n \n         LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n         \n         // load all inodes\n         LOG.info(\"Number of files \u003d \" + numFiles);\n         prog.setTotal(Phase.LOADING_FSIMAGE, step, numFiles);\n         Counter counter \u003d prog.getCounter(Phase.LOADING_FSIMAGE, step);\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.FSIMAGE_NAME_OPTIMIZATION, imgVersion)) {\n           if (supportSnapshot) {\n             loadLocalNameINodesWithSnapshot(numFiles, in, counter);\n           } else {\n             loadLocalNameINodes(numFiles, in, counter);\n           }\n         } else {\n           loadFullNameINodes(numFiles, in, counter);\n         }\n \n         loadFilesUnderConstruction(in, supportSnapshot, counter);\n         prog.endStep(Phase.LOADING_FSIMAGE, step);\n         // Now that the step is finished, set counter equal to total to adjust\n         // for possible under-counting due to reference inodes.\n         prog.setCount(Phase.LOADING_FSIMAGE, step, numFiles);\n \n         loadSecretManagerState(in);\n \n         loadCacheManagerState(in);\n \n         // make sure to read to the end of file\n         boolean eof \u003d (in.read() \u003d\u003d -1);\n         assert eof : \"Should have reached the end of image file \" + curFile;\n       } finally {\n         in.close();\n       }\n \n       imgDigest \u003d new MD5Hash(digester.digest());\n       loaded \u003d true;\n       \n-      LOG.info(\"Image file \" + curFile + \" of size \" + curFile.length() +\n-          \" bytes loaded in \" + (now() - startTime)/1000 + \" seconds.\");\n+      LOG.info(\"Image file \" + curFile + \" of size \" + curFile.length()\n+          + \" bytes loaded in \" + (monotonicNow() - startTime) / 1000\n+          + \" seconds.\");\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void load(File curFile) throws IOException {\n      checkNotLoaded();\n      assert curFile !\u003d null : \"curFile is null\";\n\n      StartupProgress prog \u003d NameNode.getStartupProgress();\n      Step step \u003d new Step(StepType.INODES);\n      prog.beginStep(Phase.LOADING_FSIMAGE, step);\n      long startTime \u003d monotonicNow();\n\n      //\n      // Load in bits\n      //\n      MessageDigest digester \u003d MD5Hash.getDigester();\n      DigestInputStream fin \u003d new DigestInputStream(\n           new FileInputStream(curFile), digester);\n\n      DataInputStream in \u003d new DataInputStream(fin);\n      try {\n        // read image version: first appeared in version -1\n        int imgVersion \u003d in.readInt();\n        if (getLayoutVersion() !\u003d imgVersion) {\n          throw new InconsistentFSStateException(curFile, \n              \"imgVersion \" + imgVersion +\n              \" expected to be \" + getLayoutVersion());\n        }\n        boolean supportSnapshot \u003d NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.SNAPSHOT, imgVersion);\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.ADD_LAYOUT_FLAGS, imgVersion)) {\n          LayoutFlags.read(in);\n        }\n\n        // read namespaceID: first appeared in version -2\n        in.readInt();\n\n        long numFiles \u003d in.readLong();\n\n        // read in the last generation stamp for legacy blocks.\n        long genstamp \u003d in.readLong();\n        namesystem.getBlockIdManager().setGenerationStampV1(genstamp);\n\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.SEQUENTIAL_BLOCK_ID, imgVersion)) {\n          // read the starting generation stamp for sequential block IDs\n          genstamp \u003d in.readLong();\n          namesystem.getBlockIdManager().setGenerationStampV2(genstamp);\n\n          // read the last generation stamp for blocks created after\n          // the switch to sequential block IDs.\n          long stampAtIdSwitch \u003d in.readLong();\n          namesystem.getBlockIdManager().setGenerationStampV1Limit(stampAtIdSwitch);\n\n          // read the max sequential block ID.\n          long maxSequentialBlockId \u003d in.readLong();\n          namesystem.getBlockIdManager().setLastAllocatedBlockId(maxSequentialBlockId);\n        } else {\n\n          long startingGenStamp \u003d namesystem.getBlockIdManager()\n            .upgradeGenerationStampToV2();\n          // This is an upgrade.\n          LOG.info(\"Upgrading to sequential block IDs. Generation stamp \" +\n                   \"for new blocks set to \" + startingGenStamp);\n        }\n\n        // read the transaction ID of the last edit represented by\n        // this image\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.STORED_TXIDS, imgVersion)) {\n          imgTxId \u003d in.readLong();\n        } else {\n          imgTxId \u003d 0;\n        }\n\n        // read the last allocated inode id in the fsimage\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.ADD_INODE_ID, imgVersion)) {\n          long lastInodeId \u003d in.readLong();\n          namesystem.dir.resetLastInodeId(lastInodeId);\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"load last allocated InodeId from fsimage:\" + lastInodeId);\n          }\n        } else {\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Old layout version doesn\u0027t have inode id.\"\n                + \" Will assign new id for each inode.\");\n          }\n        }\n        \n        if (supportSnapshot) {\n          snapshotMap \u003d namesystem.getSnapshotManager().read(in, this);\n        }\n\n        // read compression related info\n        FSImageCompression compression;\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n          compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n        } else {\n          compression \u003d FSImageCompression.createNoopCompression();\n        }\n        in \u003d compression.unwrapInputStream(fin);\n\n        LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n        \n        // load all inodes\n        LOG.info(\"Number of files \u003d \" + numFiles);\n        prog.setTotal(Phase.LOADING_FSIMAGE, step, numFiles);\n        Counter counter \u003d prog.getCounter(Phase.LOADING_FSIMAGE, step);\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.FSIMAGE_NAME_OPTIMIZATION, imgVersion)) {\n          if (supportSnapshot) {\n            loadLocalNameINodesWithSnapshot(numFiles, in, counter);\n          } else {\n            loadLocalNameINodes(numFiles, in, counter);\n          }\n        } else {\n          loadFullNameINodes(numFiles, in, counter);\n        }\n\n        loadFilesUnderConstruction(in, supportSnapshot, counter);\n        prog.endStep(Phase.LOADING_FSIMAGE, step);\n        // Now that the step is finished, set counter equal to total to adjust\n        // for possible under-counting due to reference inodes.\n        prog.setCount(Phase.LOADING_FSIMAGE, step, numFiles);\n\n        loadSecretManagerState(in);\n\n        loadCacheManagerState(in);\n\n        // make sure to read to the end of file\n        boolean eof \u003d (in.read() \u003d\u003d -1);\n        assert eof : \"Should have reached the end of image file \" + curFile;\n      } finally {\n        in.close();\n      }\n\n      imgDigest \u003d new MD5Hash(digester.digest());\n      loaded \u003d true;\n      \n      LOG.info(\"Image file \" + curFile + \" of size \" + curFile.length()\n          + \" bytes loaded in \" + (monotonicNow() - startTime) / 1000\n          + \" seconds.\");\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {}
    },
    "185e0c7b4c056b88f606362c71e4a22aae7076e0": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7462. Consolidate implementation of mkdirs() into a single class. Contributed by Haohui Mai.\n",
      "commitDate": "02/12/14 2:53 PM",
      "commitName": "185e0c7b4c056b88f606362c71e4a22aae7076e0",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "25/11/14 3:37 PM",
      "commitNameOld": "f43a20c529ac3f104add95b222de6580757b3763",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 6.97,
      "commitsBetweenForRepo": 34,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,142 +1,142 @@\n     public void load(File curFile) throws IOException {\n       checkNotLoaded();\n       assert curFile !\u003d null : \"curFile is null\";\n \n       StartupProgress prog \u003d NameNode.getStartupProgress();\n       Step step \u003d new Step(StepType.INODES);\n       prog.beginStep(Phase.LOADING_FSIMAGE, step);\n       long startTime \u003d now();\n \n       //\n       // Load in bits\n       //\n       MessageDigest digester \u003d MD5Hash.getDigester();\n       DigestInputStream fin \u003d new DigestInputStream(\n            new FileInputStream(curFile), digester);\n \n       DataInputStream in \u003d new DataInputStream(fin);\n       try {\n         // read image version: first appeared in version -1\n         int imgVersion \u003d in.readInt();\n         if (getLayoutVersion() !\u003d imgVersion) {\n           throw new InconsistentFSStateException(curFile, \n               \"imgVersion \" + imgVersion +\n               \" expected to be \" + getLayoutVersion());\n         }\n         boolean supportSnapshot \u003d NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.SNAPSHOT, imgVersion);\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.ADD_LAYOUT_FLAGS, imgVersion)) {\n           LayoutFlags.read(in);\n         }\n \n         // read namespaceID: first appeared in version -2\n         in.readInt();\n \n         long numFiles \u003d in.readLong();\n \n         // read in the last generation stamp for legacy blocks.\n         long genstamp \u003d in.readLong();\n         namesystem.getBlockIdManager().setGenerationStampV1(genstamp);\n \n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.SEQUENTIAL_BLOCK_ID, imgVersion)) {\n           // read the starting generation stamp for sequential block IDs\n           genstamp \u003d in.readLong();\n           namesystem.getBlockIdManager().setGenerationStampV2(genstamp);\n \n           // read the last generation stamp for blocks created after\n           // the switch to sequential block IDs.\n           long stampAtIdSwitch \u003d in.readLong();\n           namesystem.getBlockIdManager().setGenerationStampV1Limit(stampAtIdSwitch);\n \n           // read the max sequential block ID.\n           long maxSequentialBlockId \u003d in.readLong();\n           namesystem.getBlockIdManager().setLastAllocatedBlockId(maxSequentialBlockId);\n         } else {\n \n           long startingGenStamp \u003d namesystem.getBlockIdManager()\n             .upgradeGenerationStampToV2();\n           // This is an upgrade.\n           LOG.info(\"Upgrading to sequential block IDs. Generation stamp \" +\n                    \"for new blocks set to \" + startingGenStamp);\n         }\n \n         // read the transaction ID of the last edit represented by\n         // this image\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.STORED_TXIDS, imgVersion)) {\n           imgTxId \u003d in.readLong();\n         } else {\n           imgTxId \u003d 0;\n         }\n \n         // read the last allocated inode id in the fsimage\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.ADD_INODE_ID, imgVersion)) {\n           long lastInodeId \u003d in.readLong();\n-          namesystem.resetLastInodeId(lastInodeId);\n+          namesystem.dir.resetLastInodeId(lastInodeId);\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"load last allocated InodeId from fsimage:\" + lastInodeId);\n           }\n         } else {\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"Old layout version doesn\u0027t have inode id.\"\n                 + \" Will assign new id for each inode.\");\n           }\n         }\n         \n         if (supportSnapshot) {\n           snapshotMap \u003d namesystem.getSnapshotManager().read(in, this);\n         }\n \n         // read compression related info\n         FSImageCompression compression;\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n           compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n         } else {\n           compression \u003d FSImageCompression.createNoopCompression();\n         }\n         in \u003d compression.unwrapInputStream(fin);\n \n         LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n         \n         // load all inodes\n         LOG.info(\"Number of files \u003d \" + numFiles);\n         prog.setTotal(Phase.LOADING_FSIMAGE, step, numFiles);\n         Counter counter \u003d prog.getCounter(Phase.LOADING_FSIMAGE, step);\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.FSIMAGE_NAME_OPTIMIZATION, imgVersion)) {\n           if (supportSnapshot) {\n             loadLocalNameINodesWithSnapshot(numFiles, in, counter);\n           } else {\n             loadLocalNameINodes(numFiles, in, counter);\n           }\n         } else {\n           loadFullNameINodes(numFiles, in, counter);\n         }\n \n         loadFilesUnderConstruction(in, supportSnapshot, counter);\n         prog.endStep(Phase.LOADING_FSIMAGE, step);\n         // Now that the step is finished, set counter equal to total to adjust\n         // for possible under-counting due to reference inodes.\n         prog.setCount(Phase.LOADING_FSIMAGE, step, numFiles);\n \n         loadSecretManagerState(in);\n \n         loadCacheManagerState(in);\n \n         // make sure to read to the end of file\n         boolean eof \u003d (in.read() \u003d\u003d -1);\n         assert eof : \"Should have reached the end of image file \" + curFile;\n       } finally {\n         in.close();\n       }\n \n       imgDigest \u003d new MD5Hash(digester.digest());\n       loaded \u003d true;\n       \n       LOG.info(\"Image file \" + curFile + \" of size \" + curFile.length() +\n           \" bytes loaded in \" + (now() - startTime)/1000 + \" seconds.\");\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void load(File curFile) throws IOException {\n      checkNotLoaded();\n      assert curFile !\u003d null : \"curFile is null\";\n\n      StartupProgress prog \u003d NameNode.getStartupProgress();\n      Step step \u003d new Step(StepType.INODES);\n      prog.beginStep(Phase.LOADING_FSIMAGE, step);\n      long startTime \u003d now();\n\n      //\n      // Load in bits\n      //\n      MessageDigest digester \u003d MD5Hash.getDigester();\n      DigestInputStream fin \u003d new DigestInputStream(\n           new FileInputStream(curFile), digester);\n\n      DataInputStream in \u003d new DataInputStream(fin);\n      try {\n        // read image version: first appeared in version -1\n        int imgVersion \u003d in.readInt();\n        if (getLayoutVersion() !\u003d imgVersion) {\n          throw new InconsistentFSStateException(curFile, \n              \"imgVersion \" + imgVersion +\n              \" expected to be \" + getLayoutVersion());\n        }\n        boolean supportSnapshot \u003d NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.SNAPSHOT, imgVersion);\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.ADD_LAYOUT_FLAGS, imgVersion)) {\n          LayoutFlags.read(in);\n        }\n\n        // read namespaceID: first appeared in version -2\n        in.readInt();\n\n        long numFiles \u003d in.readLong();\n\n        // read in the last generation stamp for legacy blocks.\n        long genstamp \u003d in.readLong();\n        namesystem.getBlockIdManager().setGenerationStampV1(genstamp);\n\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.SEQUENTIAL_BLOCK_ID, imgVersion)) {\n          // read the starting generation stamp for sequential block IDs\n          genstamp \u003d in.readLong();\n          namesystem.getBlockIdManager().setGenerationStampV2(genstamp);\n\n          // read the last generation stamp for blocks created after\n          // the switch to sequential block IDs.\n          long stampAtIdSwitch \u003d in.readLong();\n          namesystem.getBlockIdManager().setGenerationStampV1Limit(stampAtIdSwitch);\n\n          // read the max sequential block ID.\n          long maxSequentialBlockId \u003d in.readLong();\n          namesystem.getBlockIdManager().setLastAllocatedBlockId(maxSequentialBlockId);\n        } else {\n\n          long startingGenStamp \u003d namesystem.getBlockIdManager()\n            .upgradeGenerationStampToV2();\n          // This is an upgrade.\n          LOG.info(\"Upgrading to sequential block IDs. Generation stamp \" +\n                   \"for new blocks set to \" + startingGenStamp);\n        }\n\n        // read the transaction ID of the last edit represented by\n        // this image\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.STORED_TXIDS, imgVersion)) {\n          imgTxId \u003d in.readLong();\n        } else {\n          imgTxId \u003d 0;\n        }\n\n        // read the last allocated inode id in the fsimage\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.ADD_INODE_ID, imgVersion)) {\n          long lastInodeId \u003d in.readLong();\n          namesystem.dir.resetLastInodeId(lastInodeId);\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"load last allocated InodeId from fsimage:\" + lastInodeId);\n          }\n        } else {\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Old layout version doesn\u0027t have inode id.\"\n                + \" Will assign new id for each inode.\");\n          }\n        }\n        \n        if (supportSnapshot) {\n          snapshotMap \u003d namesystem.getSnapshotManager().read(in, this);\n        }\n\n        // read compression related info\n        FSImageCompression compression;\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n          compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n        } else {\n          compression \u003d FSImageCompression.createNoopCompression();\n        }\n        in \u003d compression.unwrapInputStream(fin);\n\n        LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n        \n        // load all inodes\n        LOG.info(\"Number of files \u003d \" + numFiles);\n        prog.setTotal(Phase.LOADING_FSIMAGE, step, numFiles);\n        Counter counter \u003d prog.getCounter(Phase.LOADING_FSIMAGE, step);\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.FSIMAGE_NAME_OPTIMIZATION, imgVersion)) {\n          if (supportSnapshot) {\n            loadLocalNameINodesWithSnapshot(numFiles, in, counter);\n          } else {\n            loadLocalNameINodes(numFiles, in, counter);\n          }\n        } else {\n          loadFullNameINodes(numFiles, in, counter);\n        }\n\n        loadFilesUnderConstruction(in, supportSnapshot, counter);\n        prog.endStep(Phase.LOADING_FSIMAGE, step);\n        // Now that the step is finished, set counter equal to total to adjust\n        // for possible under-counting due to reference inodes.\n        prog.setCount(Phase.LOADING_FSIMAGE, step, numFiles);\n\n        loadSecretManagerState(in);\n\n        loadCacheManagerState(in);\n\n        // make sure to read to the end of file\n        boolean eof \u003d (in.read() \u003d\u003d -1);\n        assert eof : \"Should have reached the end of image file \" + curFile;\n      } finally {\n        in.close();\n      }\n\n      imgDigest \u003d new MD5Hash(digester.digest());\n      loaded \u003d true;\n      \n      LOG.info(\"Image file \" + curFile + \" of size \" + curFile.length() +\n          \" bytes loaded in \" + (now() - startTime)/1000 + \" seconds.\");\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {}
    },
    "571e9c623241106dad5521a870fb8daef3f2b00a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7381. Decouple the management of block id and gen stamps from FSNamesystem. Contributed by Haohui Mai.\n",
      "commitDate": "11/11/14 12:42 PM",
      "commitName": "571e9c623241106dad5521a870fb8daef3f2b00a",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "15/10/14 10:27 AM",
      "commitNameOld": "18620649f96d9e378fb7ea40de216284a9d525c7",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 27.14,
      "commitsBetweenForRepo": 268,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,140 +1,142 @@\n     public void load(File curFile) throws IOException {\n       checkNotLoaded();\n       assert curFile !\u003d null : \"curFile is null\";\n \n       StartupProgress prog \u003d NameNode.getStartupProgress();\n       Step step \u003d new Step(StepType.INODES);\n       prog.beginStep(Phase.LOADING_FSIMAGE, step);\n       long startTime \u003d now();\n \n       //\n       // Load in bits\n       //\n       MessageDigest digester \u003d MD5Hash.getDigester();\n       DigestInputStream fin \u003d new DigestInputStream(\n            new FileInputStream(curFile), digester);\n \n       DataInputStream in \u003d new DataInputStream(fin);\n       try {\n         // read image version: first appeared in version -1\n         int imgVersion \u003d in.readInt();\n         if (getLayoutVersion() !\u003d imgVersion) {\n           throw new InconsistentFSStateException(curFile, \n               \"imgVersion \" + imgVersion +\n               \" expected to be \" + getLayoutVersion());\n         }\n         boolean supportSnapshot \u003d NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.SNAPSHOT, imgVersion);\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.ADD_LAYOUT_FLAGS, imgVersion)) {\n           LayoutFlags.read(in);\n         }\n \n         // read namespaceID: first appeared in version -2\n         in.readInt();\n \n         long numFiles \u003d in.readLong();\n \n         // read in the last generation stamp for legacy blocks.\n         long genstamp \u003d in.readLong();\n-        namesystem.setGenerationStampV1(genstamp);\n-        \n+        namesystem.getBlockIdManager().setGenerationStampV1(genstamp);\n+\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.SEQUENTIAL_BLOCK_ID, imgVersion)) {\n           // read the starting generation stamp for sequential block IDs\n           genstamp \u003d in.readLong();\n-          namesystem.setGenerationStampV2(genstamp);\n+          namesystem.getBlockIdManager().setGenerationStampV2(genstamp);\n \n           // read the last generation stamp for blocks created after\n           // the switch to sequential block IDs.\n           long stampAtIdSwitch \u003d in.readLong();\n-          namesystem.setGenerationStampV1Limit(stampAtIdSwitch);\n+          namesystem.getBlockIdManager().setGenerationStampV1Limit(stampAtIdSwitch);\n \n           // read the max sequential block ID.\n           long maxSequentialBlockId \u003d in.readLong();\n-          namesystem.setLastAllocatedBlockId(maxSequentialBlockId);\n+          namesystem.getBlockIdManager().setLastAllocatedBlockId(maxSequentialBlockId);\n         } else {\n-          long startingGenStamp \u003d namesystem.upgradeGenerationStampToV2();\n+\n+          long startingGenStamp \u003d namesystem.getBlockIdManager()\n+            .upgradeGenerationStampToV2();\n           // This is an upgrade.\n           LOG.info(\"Upgrading to sequential block IDs. Generation stamp \" +\n                    \"for new blocks set to \" + startingGenStamp);\n         }\n \n         // read the transaction ID of the last edit represented by\n         // this image\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.STORED_TXIDS, imgVersion)) {\n           imgTxId \u003d in.readLong();\n         } else {\n           imgTxId \u003d 0;\n         }\n \n         // read the last allocated inode id in the fsimage\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.ADD_INODE_ID, imgVersion)) {\n           long lastInodeId \u003d in.readLong();\n           namesystem.resetLastInodeId(lastInodeId);\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"load last allocated InodeId from fsimage:\" + lastInodeId);\n           }\n         } else {\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"Old layout version doesn\u0027t have inode id.\"\n                 + \" Will assign new id for each inode.\");\n           }\n         }\n         \n         if (supportSnapshot) {\n           snapshotMap \u003d namesystem.getSnapshotManager().read(in, this);\n         }\n \n         // read compression related info\n         FSImageCompression compression;\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n           compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n         } else {\n           compression \u003d FSImageCompression.createNoopCompression();\n         }\n         in \u003d compression.unwrapInputStream(fin);\n \n         LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n         \n         // load all inodes\n         LOG.info(\"Number of files \u003d \" + numFiles);\n         prog.setTotal(Phase.LOADING_FSIMAGE, step, numFiles);\n         Counter counter \u003d prog.getCounter(Phase.LOADING_FSIMAGE, step);\n         if (NameNodeLayoutVersion.supports(\n             LayoutVersion.Feature.FSIMAGE_NAME_OPTIMIZATION, imgVersion)) {\n           if (supportSnapshot) {\n             loadLocalNameINodesWithSnapshot(numFiles, in, counter);\n           } else {\n             loadLocalNameINodes(numFiles, in, counter);\n           }\n         } else {\n           loadFullNameINodes(numFiles, in, counter);\n         }\n \n         loadFilesUnderConstruction(in, supportSnapshot, counter);\n         prog.endStep(Phase.LOADING_FSIMAGE, step);\n         // Now that the step is finished, set counter equal to total to adjust\n         // for possible under-counting due to reference inodes.\n         prog.setCount(Phase.LOADING_FSIMAGE, step, numFiles);\n \n         loadSecretManagerState(in);\n \n         loadCacheManagerState(in);\n \n         // make sure to read to the end of file\n         boolean eof \u003d (in.read() \u003d\u003d -1);\n         assert eof : \"Should have reached the end of image file \" + curFile;\n       } finally {\n         in.close();\n       }\n \n       imgDigest \u003d new MD5Hash(digester.digest());\n       loaded \u003d true;\n       \n       LOG.info(\"Image file \" + curFile + \" of size \" + curFile.length() +\n           \" bytes loaded in \" + (now() - startTime)/1000 + \" seconds.\");\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void load(File curFile) throws IOException {\n      checkNotLoaded();\n      assert curFile !\u003d null : \"curFile is null\";\n\n      StartupProgress prog \u003d NameNode.getStartupProgress();\n      Step step \u003d new Step(StepType.INODES);\n      prog.beginStep(Phase.LOADING_FSIMAGE, step);\n      long startTime \u003d now();\n\n      //\n      // Load in bits\n      //\n      MessageDigest digester \u003d MD5Hash.getDigester();\n      DigestInputStream fin \u003d new DigestInputStream(\n           new FileInputStream(curFile), digester);\n\n      DataInputStream in \u003d new DataInputStream(fin);\n      try {\n        // read image version: first appeared in version -1\n        int imgVersion \u003d in.readInt();\n        if (getLayoutVersion() !\u003d imgVersion) {\n          throw new InconsistentFSStateException(curFile, \n              \"imgVersion \" + imgVersion +\n              \" expected to be \" + getLayoutVersion());\n        }\n        boolean supportSnapshot \u003d NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.SNAPSHOT, imgVersion);\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.ADD_LAYOUT_FLAGS, imgVersion)) {\n          LayoutFlags.read(in);\n        }\n\n        // read namespaceID: first appeared in version -2\n        in.readInt();\n\n        long numFiles \u003d in.readLong();\n\n        // read in the last generation stamp for legacy blocks.\n        long genstamp \u003d in.readLong();\n        namesystem.getBlockIdManager().setGenerationStampV1(genstamp);\n\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.SEQUENTIAL_BLOCK_ID, imgVersion)) {\n          // read the starting generation stamp for sequential block IDs\n          genstamp \u003d in.readLong();\n          namesystem.getBlockIdManager().setGenerationStampV2(genstamp);\n\n          // read the last generation stamp for blocks created after\n          // the switch to sequential block IDs.\n          long stampAtIdSwitch \u003d in.readLong();\n          namesystem.getBlockIdManager().setGenerationStampV1Limit(stampAtIdSwitch);\n\n          // read the max sequential block ID.\n          long maxSequentialBlockId \u003d in.readLong();\n          namesystem.getBlockIdManager().setLastAllocatedBlockId(maxSequentialBlockId);\n        } else {\n\n          long startingGenStamp \u003d namesystem.getBlockIdManager()\n            .upgradeGenerationStampToV2();\n          // This is an upgrade.\n          LOG.info(\"Upgrading to sequential block IDs. Generation stamp \" +\n                   \"for new blocks set to \" + startingGenStamp);\n        }\n\n        // read the transaction ID of the last edit represented by\n        // this image\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.STORED_TXIDS, imgVersion)) {\n          imgTxId \u003d in.readLong();\n        } else {\n          imgTxId \u003d 0;\n        }\n\n        // read the last allocated inode id in the fsimage\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.ADD_INODE_ID, imgVersion)) {\n          long lastInodeId \u003d in.readLong();\n          namesystem.resetLastInodeId(lastInodeId);\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"load last allocated InodeId from fsimage:\" + lastInodeId);\n          }\n        } else {\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Old layout version doesn\u0027t have inode id.\"\n                + \" Will assign new id for each inode.\");\n          }\n        }\n        \n        if (supportSnapshot) {\n          snapshotMap \u003d namesystem.getSnapshotManager().read(in, this);\n        }\n\n        // read compression related info\n        FSImageCompression compression;\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n          compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n        } else {\n          compression \u003d FSImageCompression.createNoopCompression();\n        }\n        in \u003d compression.unwrapInputStream(fin);\n\n        LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n        \n        // load all inodes\n        LOG.info(\"Number of files \u003d \" + numFiles);\n        prog.setTotal(Phase.LOADING_FSIMAGE, step, numFiles);\n        Counter counter \u003d prog.getCounter(Phase.LOADING_FSIMAGE, step);\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.FSIMAGE_NAME_OPTIMIZATION, imgVersion)) {\n          if (supportSnapshot) {\n            loadLocalNameINodesWithSnapshot(numFiles, in, counter);\n          } else {\n            loadLocalNameINodes(numFiles, in, counter);\n          }\n        } else {\n          loadFullNameINodes(numFiles, in, counter);\n        }\n\n        loadFilesUnderConstruction(in, supportSnapshot, counter);\n        prog.endStep(Phase.LOADING_FSIMAGE, step);\n        // Now that the step is finished, set counter equal to total to adjust\n        // for possible under-counting due to reference inodes.\n        prog.setCount(Phase.LOADING_FSIMAGE, step, numFiles);\n\n        loadSecretManagerState(in);\n\n        loadCacheManagerState(in);\n\n        // make sure to read to the end of file\n        boolean eof \u003d (in.read() \u003d\u003d -1);\n        assert eof : \"Should have reached the end of image file \" + curFile;\n      } finally {\n        in.close();\n      }\n\n      imgDigest \u003d new MD5Hash(digester.digest());\n      loaded \u003d true;\n      \n      LOG.info(\"Image file \" + curFile + \" of size \" + curFile.length() +\n          \" bytes loaded in \" + (now() - startTime)/1000 + \" seconds.\");\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {}
    },
    "a2edb11b68ae01a44092cb14ac2717a6aad93305": {
      "type": "Ymodifierchange",
      "commitMessage": "HDFS-5698. Use protobuf to serialize / deserialize FSImage. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1566359 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/02/14 11:18 AM",
      "commitName": "a2edb11b68ae01a44092cb14ac2717a6aad93305",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "04/02/14 10:48 PM",
      "commitNameOld": "d6bd920bba0d7cb77ca76c3a79d1ba1e039da9e5",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 4.52,
      "commitsBetweenForRepo": 29,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,135 +1,135 @@\n-    void load(File curFile) throws IOException {\n+    public void load(File curFile) throws IOException {\n       checkNotLoaded();\n       assert curFile !\u003d null : \"curFile is null\";\n \n       StartupProgress prog \u003d NameNode.getStartupProgress();\n       Step step \u003d new Step(StepType.INODES);\n       prog.beginStep(Phase.LOADING_FSIMAGE, step);\n       long startTime \u003d now();\n \n       //\n       // Load in bits\n       //\n       MessageDigest digester \u003d MD5Hash.getDigester();\n       DigestInputStream fin \u003d new DigestInputStream(\n            new FileInputStream(curFile), digester);\n \n       DataInputStream in \u003d new DataInputStream(fin);\n       try {\n         // read image version: first appeared in version -1\n         int imgVersion \u003d in.readInt();\n         if (getLayoutVersion() !\u003d imgVersion) {\n           throw new InconsistentFSStateException(curFile, \n               \"imgVersion \" + imgVersion +\n               \" expected to be \" + getLayoutVersion());\n         }\n         boolean supportSnapshot \u003d LayoutVersion.supports(Feature.SNAPSHOT,\n             imgVersion);\n         if (LayoutVersion.supports(Feature.ADD_LAYOUT_FLAGS, imgVersion)) {\n           LayoutFlags.read(in);\n         }\n \n         // read namespaceID: first appeared in version -2\n         in.readInt();\n \n         long numFiles \u003d in.readLong();\n \n         // read in the last generation stamp for legacy blocks.\n         long genstamp \u003d in.readLong();\n         namesystem.setGenerationStampV1(genstamp);\n         \n         if (LayoutVersion.supports(Feature.SEQUENTIAL_BLOCK_ID, imgVersion)) {\n           // read the starting generation stamp for sequential block IDs\n           genstamp \u003d in.readLong();\n           namesystem.setGenerationStampV2(genstamp);\n \n           // read the last generation stamp for blocks created after\n           // the switch to sequential block IDs.\n           long stampAtIdSwitch \u003d in.readLong();\n           namesystem.setGenerationStampV1Limit(stampAtIdSwitch);\n \n           // read the max sequential block ID.\n           long maxSequentialBlockId \u003d in.readLong();\n           namesystem.setLastAllocatedBlockId(maxSequentialBlockId);\n         } else {\n           long startingGenStamp \u003d namesystem.upgradeGenerationStampToV2();\n           // This is an upgrade.\n           LOG.info(\"Upgrading to sequential block IDs. Generation stamp \" +\n                    \"for new blocks set to \" + startingGenStamp);\n         }\n \n         // read the transaction ID of the last edit represented by\n         // this image\n         if (LayoutVersion.supports(Feature.STORED_TXIDS, imgVersion)) {\n           imgTxId \u003d in.readLong();\n         } else {\n           imgTxId \u003d 0;\n         }\n \n         // read the last allocated inode id in the fsimage\n         if (LayoutVersion.supports(Feature.ADD_INODE_ID, imgVersion)) {\n           long lastInodeId \u003d in.readLong();\n           namesystem.resetLastInodeId(lastInodeId);\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"load last allocated InodeId from fsimage:\" + lastInodeId);\n           }\n         } else {\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"Old layout version doesn\u0027t have inode id.\"\n                 + \" Will assign new id for each inode.\");\n           }\n         }\n         \n         if (supportSnapshot) {\n           snapshotMap \u003d namesystem.getSnapshotManager().read(in, this);\n         }\n \n         // read compression related info\n         FSImageCompression compression;\n         if (LayoutVersion.supports(Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n           compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n         } else {\n           compression \u003d FSImageCompression.createNoopCompression();\n         }\n         in \u003d compression.unwrapInputStream(fin);\n \n         LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n         \n         // load all inodes\n         LOG.info(\"Number of files \u003d \" + numFiles);\n         prog.setTotal(Phase.LOADING_FSIMAGE, step, numFiles);\n         Counter counter \u003d prog.getCounter(Phase.LOADING_FSIMAGE, step);\n         if (LayoutVersion.supports(Feature.FSIMAGE_NAME_OPTIMIZATION,\n             imgVersion)) {\n           if (supportSnapshot) {\n             loadLocalNameINodesWithSnapshot(numFiles, in, counter);\n           } else {\n             loadLocalNameINodes(numFiles, in, counter);\n           }\n         } else {\n           loadFullNameINodes(numFiles, in, counter);\n         }\n \n         loadFilesUnderConstruction(in, supportSnapshot, counter);\n         prog.endStep(Phase.LOADING_FSIMAGE, step);\n         // Now that the step is finished, set counter equal to total to adjust\n         // for possible under-counting due to reference inodes.\n         prog.setCount(Phase.LOADING_FSIMAGE, step, numFiles);\n \n         loadSecretManagerState(in);\n \n         loadCacheManagerState(in);\n \n         // make sure to read to the end of file\n         boolean eof \u003d (in.read() \u003d\u003d -1);\n         assert eof : \"Should have reached the end of image file \" + curFile;\n       } finally {\n         in.close();\n       }\n \n       imgDigest \u003d new MD5Hash(digester.digest());\n       loaded \u003d true;\n       \n       LOG.info(\"Image file \" + curFile + \" of size \" + curFile.length() +\n           \" bytes loaded in \" + (now() - startTime)/1000 + \" seconds.\");\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void load(File curFile) throws IOException {\n      checkNotLoaded();\n      assert curFile !\u003d null : \"curFile is null\";\n\n      StartupProgress prog \u003d NameNode.getStartupProgress();\n      Step step \u003d new Step(StepType.INODES);\n      prog.beginStep(Phase.LOADING_FSIMAGE, step);\n      long startTime \u003d now();\n\n      //\n      // Load in bits\n      //\n      MessageDigest digester \u003d MD5Hash.getDigester();\n      DigestInputStream fin \u003d new DigestInputStream(\n           new FileInputStream(curFile), digester);\n\n      DataInputStream in \u003d new DataInputStream(fin);\n      try {\n        // read image version: first appeared in version -1\n        int imgVersion \u003d in.readInt();\n        if (getLayoutVersion() !\u003d imgVersion) {\n          throw new InconsistentFSStateException(curFile, \n              \"imgVersion \" + imgVersion +\n              \" expected to be \" + getLayoutVersion());\n        }\n        boolean supportSnapshot \u003d LayoutVersion.supports(Feature.SNAPSHOT,\n            imgVersion);\n        if (LayoutVersion.supports(Feature.ADD_LAYOUT_FLAGS, imgVersion)) {\n          LayoutFlags.read(in);\n        }\n\n        // read namespaceID: first appeared in version -2\n        in.readInt();\n\n        long numFiles \u003d in.readLong();\n\n        // read in the last generation stamp for legacy blocks.\n        long genstamp \u003d in.readLong();\n        namesystem.setGenerationStampV1(genstamp);\n        \n        if (LayoutVersion.supports(Feature.SEQUENTIAL_BLOCK_ID, imgVersion)) {\n          // read the starting generation stamp for sequential block IDs\n          genstamp \u003d in.readLong();\n          namesystem.setGenerationStampV2(genstamp);\n\n          // read the last generation stamp for blocks created after\n          // the switch to sequential block IDs.\n          long stampAtIdSwitch \u003d in.readLong();\n          namesystem.setGenerationStampV1Limit(stampAtIdSwitch);\n\n          // read the max sequential block ID.\n          long maxSequentialBlockId \u003d in.readLong();\n          namesystem.setLastAllocatedBlockId(maxSequentialBlockId);\n        } else {\n          long startingGenStamp \u003d namesystem.upgradeGenerationStampToV2();\n          // This is an upgrade.\n          LOG.info(\"Upgrading to sequential block IDs. Generation stamp \" +\n                   \"for new blocks set to \" + startingGenStamp);\n        }\n\n        // read the transaction ID of the last edit represented by\n        // this image\n        if (LayoutVersion.supports(Feature.STORED_TXIDS, imgVersion)) {\n          imgTxId \u003d in.readLong();\n        } else {\n          imgTxId \u003d 0;\n        }\n\n        // read the last allocated inode id in the fsimage\n        if (LayoutVersion.supports(Feature.ADD_INODE_ID, imgVersion)) {\n          long lastInodeId \u003d in.readLong();\n          namesystem.resetLastInodeId(lastInodeId);\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"load last allocated InodeId from fsimage:\" + lastInodeId);\n          }\n        } else {\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Old layout version doesn\u0027t have inode id.\"\n                + \" Will assign new id for each inode.\");\n          }\n        }\n        \n        if (supportSnapshot) {\n          snapshotMap \u003d namesystem.getSnapshotManager().read(in, this);\n        }\n\n        // read compression related info\n        FSImageCompression compression;\n        if (LayoutVersion.supports(Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n          compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n        } else {\n          compression \u003d FSImageCompression.createNoopCompression();\n        }\n        in \u003d compression.unwrapInputStream(fin);\n\n        LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n        \n        // load all inodes\n        LOG.info(\"Number of files \u003d \" + numFiles);\n        prog.setTotal(Phase.LOADING_FSIMAGE, step, numFiles);\n        Counter counter \u003d prog.getCounter(Phase.LOADING_FSIMAGE, step);\n        if (LayoutVersion.supports(Feature.FSIMAGE_NAME_OPTIMIZATION,\n            imgVersion)) {\n          if (supportSnapshot) {\n            loadLocalNameINodesWithSnapshot(numFiles, in, counter);\n          } else {\n            loadLocalNameINodes(numFiles, in, counter);\n          }\n        } else {\n          loadFullNameINodes(numFiles, in, counter);\n        }\n\n        loadFilesUnderConstruction(in, supportSnapshot, counter);\n        prog.endStep(Phase.LOADING_FSIMAGE, step);\n        // Now that the step is finished, set counter equal to total to adjust\n        // for possible under-counting due to reference inodes.\n        prog.setCount(Phase.LOADING_FSIMAGE, step, numFiles);\n\n        loadSecretManagerState(in);\n\n        loadCacheManagerState(in);\n\n        // make sure to read to the end of file\n        boolean eof \u003d (in.read() \u003d\u003d -1);\n        assert eof : \"Should have reached the end of image file \" + curFile;\n      } finally {\n        in.close();\n      }\n\n      imgDigest \u003d new MD5Hash(digester.digest());\n      loaded \u003d true;\n      \n      LOG.info(\"Image file \" + curFile + \" of size \" + curFile.length() +\n          \" bytes loaded in \" + (now() - startTime)/1000 + \" seconds.\");\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {
        "oldValue": "[]",
        "newValue": "[public]"
      }
    },
    "00067895a01c66d53715b50bbcb3605efd6425f2": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5754. Split LayoutVerion into NameNodeLayoutVersion and DataNodeLayoutVersion. Contributed by Brandon Li\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535@1563041 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "30/01/14 7:21 PM",
      "commitName": "00067895a01c66d53715b50bbcb3605efd6425f2",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "16/01/14 5:32 PM",
      "commitNameOld": "a7ec44d41b0ad1fa133408a10caaae32a27ea569",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 14.08,
      "commitsBetweenForRepo": 56,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,135 +1,140 @@\n     void load(File curFile) throws IOException {\n       checkNotLoaded();\n       assert curFile !\u003d null : \"curFile is null\";\n \n       StartupProgress prog \u003d NameNode.getStartupProgress();\n       Step step \u003d new Step(StepType.INODES);\n       prog.beginStep(Phase.LOADING_FSIMAGE, step);\n       long startTime \u003d now();\n \n       //\n       // Load in bits\n       //\n       MessageDigest digester \u003d MD5Hash.getDigester();\n       DigestInputStream fin \u003d new DigestInputStream(\n            new FileInputStream(curFile), digester);\n \n       DataInputStream in \u003d new DataInputStream(fin);\n       try {\n         // read image version: first appeared in version -1\n         int imgVersion \u003d in.readInt();\n         if (getLayoutVersion() !\u003d imgVersion) {\n           throw new InconsistentFSStateException(curFile, \n               \"imgVersion \" + imgVersion +\n               \" expected to be \" + getLayoutVersion());\n         }\n-        boolean supportSnapshot \u003d LayoutVersion.supports(Feature.SNAPSHOT,\n-            imgVersion);\n-        if (LayoutVersion.supports(Feature.ADD_LAYOUT_FLAGS, imgVersion)) {\n+        boolean supportSnapshot \u003d NameNodeLayoutVersion.supports(\n+            LayoutVersion.Feature.SNAPSHOT, imgVersion);\n+        if (NameNodeLayoutVersion.supports(\n+            LayoutVersion.Feature.ADD_LAYOUT_FLAGS, imgVersion)) {\n           LayoutFlags.read(in);\n         }\n \n         // read namespaceID: first appeared in version -2\n         in.readInt();\n \n         long numFiles \u003d in.readLong();\n \n         // read in the last generation stamp for legacy blocks.\n         long genstamp \u003d in.readLong();\n         namesystem.setGenerationStampV1(genstamp);\n         \n-        if (LayoutVersion.supports(Feature.SEQUENTIAL_BLOCK_ID, imgVersion)) {\n+        if (NameNodeLayoutVersion.supports(\n+            LayoutVersion.Feature.SEQUENTIAL_BLOCK_ID, imgVersion)) {\n           // read the starting generation stamp for sequential block IDs\n           genstamp \u003d in.readLong();\n           namesystem.setGenerationStampV2(genstamp);\n \n           // read the last generation stamp for blocks created after\n           // the switch to sequential block IDs.\n           long stampAtIdSwitch \u003d in.readLong();\n           namesystem.setGenerationStampV1Limit(stampAtIdSwitch);\n \n           // read the max sequential block ID.\n           long maxSequentialBlockId \u003d in.readLong();\n           namesystem.setLastAllocatedBlockId(maxSequentialBlockId);\n         } else {\n           long startingGenStamp \u003d namesystem.upgradeGenerationStampToV2();\n           // This is an upgrade.\n           LOG.info(\"Upgrading to sequential block IDs. Generation stamp \" +\n                    \"for new blocks set to \" + startingGenStamp);\n         }\n \n         // read the transaction ID of the last edit represented by\n         // this image\n-        if (LayoutVersion.supports(Feature.STORED_TXIDS, imgVersion)) {\n+        if (NameNodeLayoutVersion.supports(\n+            LayoutVersion.Feature.STORED_TXIDS, imgVersion)) {\n           imgTxId \u003d in.readLong();\n         } else {\n           imgTxId \u003d 0;\n         }\n \n         // read the last allocated inode id in the fsimage\n-        if (LayoutVersion.supports(Feature.ADD_INODE_ID, imgVersion)) {\n+        if (NameNodeLayoutVersion.supports(\n+            LayoutVersion.Feature.ADD_INODE_ID, imgVersion)) {\n           long lastInodeId \u003d in.readLong();\n           namesystem.resetLastInodeId(lastInodeId);\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"load last allocated InodeId from fsimage:\" + lastInodeId);\n           }\n         } else {\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"Old layout version doesn\u0027t have inode id.\"\n                 + \" Will assign new id for each inode.\");\n           }\n         }\n         \n         if (supportSnapshot) {\n           snapshotMap \u003d namesystem.getSnapshotManager().read(in, this);\n         }\n \n         // read compression related info\n         FSImageCompression compression;\n-        if (LayoutVersion.supports(Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n+        if (NameNodeLayoutVersion.supports(\n+            LayoutVersion.Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n           compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n         } else {\n           compression \u003d FSImageCompression.createNoopCompression();\n         }\n         in \u003d compression.unwrapInputStream(fin);\n \n         LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n         \n         // load all inodes\n         LOG.info(\"Number of files \u003d \" + numFiles);\n         prog.setTotal(Phase.LOADING_FSIMAGE, step, numFiles);\n         Counter counter \u003d prog.getCounter(Phase.LOADING_FSIMAGE, step);\n-        if (LayoutVersion.supports(Feature.FSIMAGE_NAME_OPTIMIZATION,\n-            imgVersion)) {\n+        if (NameNodeLayoutVersion.supports(\n+            LayoutVersion.Feature.FSIMAGE_NAME_OPTIMIZATION, imgVersion)) {\n           if (supportSnapshot) {\n             loadLocalNameINodesWithSnapshot(numFiles, in, counter);\n           } else {\n             loadLocalNameINodes(numFiles, in, counter);\n           }\n         } else {\n           loadFullNameINodes(numFiles, in, counter);\n         }\n \n         loadFilesUnderConstruction(in, supportSnapshot, counter);\n         prog.endStep(Phase.LOADING_FSIMAGE, step);\n         // Now that the step is finished, set counter equal to total to adjust\n         // for possible under-counting due to reference inodes.\n         prog.setCount(Phase.LOADING_FSIMAGE, step, numFiles);\n \n         loadSecretManagerState(in);\n \n         loadCacheManagerState(in);\n \n         // make sure to read to the end of file\n         boolean eof \u003d (in.read() \u003d\u003d -1);\n         assert eof : \"Should have reached the end of image file \" + curFile;\n       } finally {\n         in.close();\n       }\n \n       imgDigest \u003d new MD5Hash(digester.digest());\n       loaded \u003d true;\n       \n       LOG.info(\"Image file \" + curFile + \" of size \" + curFile.length() +\n           \" bytes loaded in \" + (now() - startTime)/1000 + \" seconds.\");\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void load(File curFile) throws IOException {\n      checkNotLoaded();\n      assert curFile !\u003d null : \"curFile is null\";\n\n      StartupProgress prog \u003d NameNode.getStartupProgress();\n      Step step \u003d new Step(StepType.INODES);\n      prog.beginStep(Phase.LOADING_FSIMAGE, step);\n      long startTime \u003d now();\n\n      //\n      // Load in bits\n      //\n      MessageDigest digester \u003d MD5Hash.getDigester();\n      DigestInputStream fin \u003d new DigestInputStream(\n           new FileInputStream(curFile), digester);\n\n      DataInputStream in \u003d new DataInputStream(fin);\n      try {\n        // read image version: first appeared in version -1\n        int imgVersion \u003d in.readInt();\n        if (getLayoutVersion() !\u003d imgVersion) {\n          throw new InconsistentFSStateException(curFile, \n              \"imgVersion \" + imgVersion +\n              \" expected to be \" + getLayoutVersion());\n        }\n        boolean supportSnapshot \u003d NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.SNAPSHOT, imgVersion);\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.ADD_LAYOUT_FLAGS, imgVersion)) {\n          LayoutFlags.read(in);\n        }\n\n        // read namespaceID: first appeared in version -2\n        in.readInt();\n\n        long numFiles \u003d in.readLong();\n\n        // read in the last generation stamp for legacy blocks.\n        long genstamp \u003d in.readLong();\n        namesystem.setGenerationStampV1(genstamp);\n        \n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.SEQUENTIAL_BLOCK_ID, imgVersion)) {\n          // read the starting generation stamp for sequential block IDs\n          genstamp \u003d in.readLong();\n          namesystem.setGenerationStampV2(genstamp);\n\n          // read the last generation stamp for blocks created after\n          // the switch to sequential block IDs.\n          long stampAtIdSwitch \u003d in.readLong();\n          namesystem.setGenerationStampV1Limit(stampAtIdSwitch);\n\n          // read the max sequential block ID.\n          long maxSequentialBlockId \u003d in.readLong();\n          namesystem.setLastAllocatedBlockId(maxSequentialBlockId);\n        } else {\n          long startingGenStamp \u003d namesystem.upgradeGenerationStampToV2();\n          // This is an upgrade.\n          LOG.info(\"Upgrading to sequential block IDs. Generation stamp \" +\n                   \"for new blocks set to \" + startingGenStamp);\n        }\n\n        // read the transaction ID of the last edit represented by\n        // this image\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.STORED_TXIDS, imgVersion)) {\n          imgTxId \u003d in.readLong();\n        } else {\n          imgTxId \u003d 0;\n        }\n\n        // read the last allocated inode id in the fsimage\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.ADD_INODE_ID, imgVersion)) {\n          long lastInodeId \u003d in.readLong();\n          namesystem.resetLastInodeId(lastInodeId);\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"load last allocated InodeId from fsimage:\" + lastInodeId);\n          }\n        } else {\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Old layout version doesn\u0027t have inode id.\"\n                + \" Will assign new id for each inode.\");\n          }\n        }\n        \n        if (supportSnapshot) {\n          snapshotMap \u003d namesystem.getSnapshotManager().read(in, this);\n        }\n\n        // read compression related info\n        FSImageCompression compression;\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n          compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n        } else {\n          compression \u003d FSImageCompression.createNoopCompression();\n        }\n        in \u003d compression.unwrapInputStream(fin);\n\n        LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n        \n        // load all inodes\n        LOG.info(\"Number of files \u003d \" + numFiles);\n        prog.setTotal(Phase.LOADING_FSIMAGE, step, numFiles);\n        Counter counter \u003d prog.getCounter(Phase.LOADING_FSIMAGE, step);\n        if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.FSIMAGE_NAME_OPTIMIZATION, imgVersion)) {\n          if (supportSnapshot) {\n            loadLocalNameINodesWithSnapshot(numFiles, in, counter);\n          } else {\n            loadLocalNameINodes(numFiles, in, counter);\n          }\n        } else {\n          loadFullNameINodes(numFiles, in, counter);\n        }\n\n        loadFilesUnderConstruction(in, supportSnapshot, counter);\n        prog.endStep(Phase.LOADING_FSIMAGE, step);\n        // Now that the step is finished, set counter equal to total to adjust\n        // for possible under-counting due to reference inodes.\n        prog.setCount(Phase.LOADING_FSIMAGE, step, numFiles);\n\n        loadSecretManagerState(in);\n\n        loadCacheManagerState(in);\n\n        // make sure to read to the end of file\n        boolean eof \u003d (in.read() \u003d\u003d -1);\n        assert eof : \"Should have reached the end of image file \" + curFile;\n      } finally {\n        in.close();\n      }\n\n      imgDigest \u003d new MD5Hash(digester.digest());\n      loaded \u003d true;\n      \n      LOG.info(\"Image file \" + curFile + \" of size \" + curFile.length() +\n          \" bytes loaded in \" + (now() - startTime)/1000 + \" seconds.\");\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {}
    },
    "a7ec44d41b0ad1fa133408a10caaae32a27ea569": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5784. Reserve space in edit log header and fsimage header for feature flag section (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1558974 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/01/14 5:32 PM",
      "commitName": "a7ec44d41b0ad1fa133408a10caaae32a27ea569",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "15/01/14 3:15 PM",
      "commitNameOld": "a506df8e483cdd27629cfcbc2b0e1aecd27e448a",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 1.09,
      "commitsBetweenForRepo": 10,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,132 +1,135 @@\n     void load(File curFile) throws IOException {\n       checkNotLoaded();\n       assert curFile !\u003d null : \"curFile is null\";\n \n       StartupProgress prog \u003d NameNode.getStartupProgress();\n       Step step \u003d new Step(StepType.INODES);\n       prog.beginStep(Phase.LOADING_FSIMAGE, step);\n       long startTime \u003d now();\n \n       //\n       // Load in bits\n       //\n       MessageDigest digester \u003d MD5Hash.getDigester();\n       DigestInputStream fin \u003d new DigestInputStream(\n            new FileInputStream(curFile), digester);\n \n       DataInputStream in \u003d new DataInputStream(fin);\n       try {\n         // read image version: first appeared in version -1\n         int imgVersion \u003d in.readInt();\n         if (getLayoutVersion() !\u003d imgVersion) {\n           throw new InconsistentFSStateException(curFile, \n               \"imgVersion \" + imgVersion +\n               \" expected to be \" + getLayoutVersion());\n         }\n         boolean supportSnapshot \u003d LayoutVersion.supports(Feature.SNAPSHOT,\n             imgVersion);\n+        if (LayoutVersion.supports(Feature.ADD_LAYOUT_FLAGS, imgVersion)) {\n+          LayoutFlags.read(in);\n+        }\n \n         // read namespaceID: first appeared in version -2\n         in.readInt();\n \n         long numFiles \u003d in.readLong();\n \n         // read in the last generation stamp for legacy blocks.\n         long genstamp \u003d in.readLong();\n         namesystem.setGenerationStampV1(genstamp);\n         \n         if (LayoutVersion.supports(Feature.SEQUENTIAL_BLOCK_ID, imgVersion)) {\n           // read the starting generation stamp for sequential block IDs\n           genstamp \u003d in.readLong();\n           namesystem.setGenerationStampV2(genstamp);\n \n           // read the last generation stamp for blocks created after\n           // the switch to sequential block IDs.\n           long stampAtIdSwitch \u003d in.readLong();\n           namesystem.setGenerationStampV1Limit(stampAtIdSwitch);\n \n           // read the max sequential block ID.\n           long maxSequentialBlockId \u003d in.readLong();\n           namesystem.setLastAllocatedBlockId(maxSequentialBlockId);\n         } else {\n           long startingGenStamp \u003d namesystem.upgradeGenerationStampToV2();\n           // This is an upgrade.\n           LOG.info(\"Upgrading to sequential block IDs. Generation stamp \" +\n                    \"for new blocks set to \" + startingGenStamp);\n         }\n \n         // read the transaction ID of the last edit represented by\n         // this image\n         if (LayoutVersion.supports(Feature.STORED_TXIDS, imgVersion)) {\n           imgTxId \u003d in.readLong();\n         } else {\n           imgTxId \u003d 0;\n         }\n \n         // read the last allocated inode id in the fsimage\n         if (LayoutVersion.supports(Feature.ADD_INODE_ID, imgVersion)) {\n           long lastInodeId \u003d in.readLong();\n           namesystem.resetLastInodeId(lastInodeId);\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"load last allocated InodeId from fsimage:\" + lastInodeId);\n           }\n         } else {\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"Old layout version doesn\u0027t have inode id.\"\n                 + \" Will assign new id for each inode.\");\n           }\n         }\n         \n         if (supportSnapshot) {\n           snapshotMap \u003d namesystem.getSnapshotManager().read(in, this);\n         }\n \n         // read compression related info\n         FSImageCompression compression;\n         if (LayoutVersion.supports(Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n           compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n         } else {\n           compression \u003d FSImageCompression.createNoopCompression();\n         }\n         in \u003d compression.unwrapInputStream(fin);\n \n         LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n         \n         // load all inodes\n         LOG.info(\"Number of files \u003d \" + numFiles);\n         prog.setTotal(Phase.LOADING_FSIMAGE, step, numFiles);\n         Counter counter \u003d prog.getCounter(Phase.LOADING_FSIMAGE, step);\n         if (LayoutVersion.supports(Feature.FSIMAGE_NAME_OPTIMIZATION,\n             imgVersion)) {\n           if (supportSnapshot) {\n             loadLocalNameINodesWithSnapshot(numFiles, in, counter);\n           } else {\n             loadLocalNameINodes(numFiles, in, counter);\n           }\n         } else {\n           loadFullNameINodes(numFiles, in, counter);\n         }\n \n         loadFilesUnderConstruction(in, supportSnapshot, counter);\n         prog.endStep(Phase.LOADING_FSIMAGE, step);\n         // Now that the step is finished, set counter equal to total to adjust\n         // for possible under-counting due to reference inodes.\n         prog.setCount(Phase.LOADING_FSIMAGE, step, numFiles);\n \n         loadSecretManagerState(in);\n \n         loadCacheManagerState(in);\n \n         // make sure to read to the end of file\n         boolean eof \u003d (in.read() \u003d\u003d -1);\n         assert eof : \"Should have reached the end of image file \" + curFile;\n       } finally {\n         in.close();\n       }\n \n       imgDigest \u003d new MD5Hash(digester.digest());\n       loaded \u003d true;\n       \n       LOG.info(\"Image file \" + curFile + \" of size \" + curFile.length() +\n           \" bytes loaded in \" + (now() - startTime)/1000 + \" seconds.\");\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void load(File curFile) throws IOException {\n      checkNotLoaded();\n      assert curFile !\u003d null : \"curFile is null\";\n\n      StartupProgress prog \u003d NameNode.getStartupProgress();\n      Step step \u003d new Step(StepType.INODES);\n      prog.beginStep(Phase.LOADING_FSIMAGE, step);\n      long startTime \u003d now();\n\n      //\n      // Load in bits\n      //\n      MessageDigest digester \u003d MD5Hash.getDigester();\n      DigestInputStream fin \u003d new DigestInputStream(\n           new FileInputStream(curFile), digester);\n\n      DataInputStream in \u003d new DataInputStream(fin);\n      try {\n        // read image version: first appeared in version -1\n        int imgVersion \u003d in.readInt();\n        if (getLayoutVersion() !\u003d imgVersion) {\n          throw new InconsistentFSStateException(curFile, \n              \"imgVersion \" + imgVersion +\n              \" expected to be \" + getLayoutVersion());\n        }\n        boolean supportSnapshot \u003d LayoutVersion.supports(Feature.SNAPSHOT,\n            imgVersion);\n        if (LayoutVersion.supports(Feature.ADD_LAYOUT_FLAGS, imgVersion)) {\n          LayoutFlags.read(in);\n        }\n\n        // read namespaceID: first appeared in version -2\n        in.readInt();\n\n        long numFiles \u003d in.readLong();\n\n        // read in the last generation stamp for legacy blocks.\n        long genstamp \u003d in.readLong();\n        namesystem.setGenerationStampV1(genstamp);\n        \n        if (LayoutVersion.supports(Feature.SEQUENTIAL_BLOCK_ID, imgVersion)) {\n          // read the starting generation stamp for sequential block IDs\n          genstamp \u003d in.readLong();\n          namesystem.setGenerationStampV2(genstamp);\n\n          // read the last generation stamp for blocks created after\n          // the switch to sequential block IDs.\n          long stampAtIdSwitch \u003d in.readLong();\n          namesystem.setGenerationStampV1Limit(stampAtIdSwitch);\n\n          // read the max sequential block ID.\n          long maxSequentialBlockId \u003d in.readLong();\n          namesystem.setLastAllocatedBlockId(maxSequentialBlockId);\n        } else {\n          long startingGenStamp \u003d namesystem.upgradeGenerationStampToV2();\n          // This is an upgrade.\n          LOG.info(\"Upgrading to sequential block IDs. Generation stamp \" +\n                   \"for new blocks set to \" + startingGenStamp);\n        }\n\n        // read the transaction ID of the last edit represented by\n        // this image\n        if (LayoutVersion.supports(Feature.STORED_TXIDS, imgVersion)) {\n          imgTxId \u003d in.readLong();\n        } else {\n          imgTxId \u003d 0;\n        }\n\n        // read the last allocated inode id in the fsimage\n        if (LayoutVersion.supports(Feature.ADD_INODE_ID, imgVersion)) {\n          long lastInodeId \u003d in.readLong();\n          namesystem.resetLastInodeId(lastInodeId);\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"load last allocated InodeId from fsimage:\" + lastInodeId);\n          }\n        } else {\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Old layout version doesn\u0027t have inode id.\"\n                + \" Will assign new id for each inode.\");\n          }\n        }\n        \n        if (supportSnapshot) {\n          snapshotMap \u003d namesystem.getSnapshotManager().read(in, this);\n        }\n\n        // read compression related info\n        FSImageCompression compression;\n        if (LayoutVersion.supports(Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n          compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n        } else {\n          compression \u003d FSImageCompression.createNoopCompression();\n        }\n        in \u003d compression.unwrapInputStream(fin);\n\n        LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n        \n        // load all inodes\n        LOG.info(\"Number of files \u003d \" + numFiles);\n        prog.setTotal(Phase.LOADING_FSIMAGE, step, numFiles);\n        Counter counter \u003d prog.getCounter(Phase.LOADING_FSIMAGE, step);\n        if (LayoutVersion.supports(Feature.FSIMAGE_NAME_OPTIMIZATION,\n            imgVersion)) {\n          if (supportSnapshot) {\n            loadLocalNameINodesWithSnapshot(numFiles, in, counter);\n          } else {\n            loadLocalNameINodes(numFiles, in, counter);\n          }\n        } else {\n          loadFullNameINodes(numFiles, in, counter);\n        }\n\n        loadFilesUnderConstruction(in, supportSnapshot, counter);\n        prog.endStep(Phase.LOADING_FSIMAGE, step);\n        // Now that the step is finished, set counter equal to total to adjust\n        // for possible under-counting due to reference inodes.\n        prog.setCount(Phase.LOADING_FSIMAGE, step, numFiles);\n\n        loadSecretManagerState(in);\n\n        loadCacheManagerState(in);\n\n        // make sure to read to the end of file\n        boolean eof \u003d (in.read() \u003d\u003d -1);\n        assert eof : \"Should have reached the end of image file \" + curFile;\n      } finally {\n        in.close();\n      }\n\n      imgDigest \u003d new MD5Hash(digester.digest());\n      loaded \u003d true;\n      \n      LOG.info(\"Image file \" + curFile + \" of size \" + curFile.length() +\n          \" bytes loaded in \" + (now() - startTime)/1000 + \" seconds.\");\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {}
    },
    "af1ac9a5e8d8d97a855940d853dd59ab4666f6e2": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5119. Persist CacheManager state in the edit log. (Contributed by Andrew Wang)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1529238 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/10/13 10:46 AM",
      "commitName": "af1ac9a5e8d8d97a855940d853dd59ab4666f6e2",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "10/07/13 10:35 PM",
      "commitNameOld": "da8e962e39bd41b73b53966826c82e741b08010b",
      "commitAuthorOld": "Chris Nauroth",
      "daysBetweenCommits": 85.51,
      "commitsBetweenForRepo": 398,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,130 +1,132 @@\n     void load(File curFile) throws IOException {\n       checkNotLoaded();\n       assert curFile !\u003d null : \"curFile is null\";\n \n       StartupProgress prog \u003d NameNode.getStartupProgress();\n       Step step \u003d new Step(StepType.INODES);\n       prog.beginStep(Phase.LOADING_FSIMAGE, step);\n       long startTime \u003d now();\n \n       //\n       // Load in bits\n       //\n       MessageDigest digester \u003d MD5Hash.getDigester();\n       DigestInputStream fin \u003d new DigestInputStream(\n            new FileInputStream(curFile), digester);\n \n       DataInputStream in \u003d new DataInputStream(fin);\n       try {\n         // read image version: first appeared in version -1\n         int imgVersion \u003d in.readInt();\n         if (getLayoutVersion() !\u003d imgVersion) {\n           throw new InconsistentFSStateException(curFile, \n               \"imgVersion \" + imgVersion +\n               \" expected to be \" + getLayoutVersion());\n         }\n         boolean supportSnapshot \u003d LayoutVersion.supports(Feature.SNAPSHOT,\n             imgVersion);\n \n         // read namespaceID: first appeared in version -2\n         in.readInt();\n \n         long numFiles \u003d in.readLong();\n \n         // read in the last generation stamp for legacy blocks.\n         long genstamp \u003d in.readLong();\n         namesystem.setGenerationStampV1(genstamp);\n         \n         if (LayoutVersion.supports(Feature.SEQUENTIAL_BLOCK_ID, imgVersion)) {\n           // read the starting generation stamp for sequential block IDs\n           genstamp \u003d in.readLong();\n           namesystem.setGenerationStampV2(genstamp);\n \n           // read the last generation stamp for blocks created after\n           // the switch to sequential block IDs.\n           long stampAtIdSwitch \u003d in.readLong();\n           namesystem.setGenerationStampV1Limit(stampAtIdSwitch);\n \n           // read the max sequential block ID.\n           long maxSequentialBlockId \u003d in.readLong();\n           namesystem.setLastAllocatedBlockId(maxSequentialBlockId);\n         } else {\n           long startingGenStamp \u003d namesystem.upgradeGenerationStampToV2();\n           // This is an upgrade.\n           LOG.info(\"Upgrading to sequential block IDs. Generation stamp \" +\n                    \"for new blocks set to \" + startingGenStamp);\n         }\n \n         // read the transaction ID of the last edit represented by\n         // this image\n         if (LayoutVersion.supports(Feature.STORED_TXIDS, imgVersion)) {\n           imgTxId \u003d in.readLong();\n         } else {\n           imgTxId \u003d 0;\n         }\n \n         // read the last allocated inode id in the fsimage\n         if (LayoutVersion.supports(Feature.ADD_INODE_ID, imgVersion)) {\n           long lastInodeId \u003d in.readLong();\n           namesystem.resetLastInodeId(lastInodeId);\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"load last allocated InodeId from fsimage:\" + lastInodeId);\n           }\n         } else {\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"Old layout version doesn\u0027t have inode id.\"\n                 + \" Will assign new id for each inode.\");\n           }\n         }\n         \n         if (supportSnapshot) {\n           snapshotMap \u003d namesystem.getSnapshotManager().read(in, this);\n         }\n \n         // read compression related info\n         FSImageCompression compression;\n         if (LayoutVersion.supports(Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n           compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n         } else {\n           compression \u003d FSImageCompression.createNoopCompression();\n         }\n         in \u003d compression.unwrapInputStream(fin);\n \n         LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n         \n         // load all inodes\n         LOG.info(\"Number of files \u003d \" + numFiles);\n         prog.setTotal(Phase.LOADING_FSIMAGE, step, numFiles);\n         Counter counter \u003d prog.getCounter(Phase.LOADING_FSIMAGE, step);\n         if (LayoutVersion.supports(Feature.FSIMAGE_NAME_OPTIMIZATION,\n             imgVersion)) {\n           if (supportSnapshot) {\n             loadLocalNameINodesWithSnapshot(numFiles, in, counter);\n           } else {\n             loadLocalNameINodes(numFiles, in, counter);\n           }\n         } else {\n           loadFullNameINodes(numFiles, in, counter);\n         }\n \n         loadFilesUnderConstruction(in, supportSnapshot, counter);\n         prog.endStep(Phase.LOADING_FSIMAGE, step);\n         // Now that the step is finished, set counter equal to total to adjust\n         // for possible under-counting due to reference inodes.\n         prog.setCount(Phase.LOADING_FSIMAGE, step, numFiles);\n \n         loadSecretManagerState(in);\n \n+        loadCacheManagerState(in);\n+\n         // make sure to read to the end of file\n         boolean eof \u003d (in.read() \u003d\u003d -1);\n         assert eof : \"Should have reached the end of image file \" + curFile;\n       } finally {\n         in.close();\n       }\n \n       imgDigest \u003d new MD5Hash(digester.digest());\n       loaded \u003d true;\n       \n       LOG.info(\"Image file \" + curFile + \" of size \" + curFile.length() +\n           \" bytes loaded in \" + (now() - startTime)/1000 + \" seconds.\");\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void load(File curFile) throws IOException {\n      checkNotLoaded();\n      assert curFile !\u003d null : \"curFile is null\";\n\n      StartupProgress prog \u003d NameNode.getStartupProgress();\n      Step step \u003d new Step(StepType.INODES);\n      prog.beginStep(Phase.LOADING_FSIMAGE, step);\n      long startTime \u003d now();\n\n      //\n      // Load in bits\n      //\n      MessageDigest digester \u003d MD5Hash.getDigester();\n      DigestInputStream fin \u003d new DigestInputStream(\n           new FileInputStream(curFile), digester);\n\n      DataInputStream in \u003d new DataInputStream(fin);\n      try {\n        // read image version: first appeared in version -1\n        int imgVersion \u003d in.readInt();\n        if (getLayoutVersion() !\u003d imgVersion) {\n          throw new InconsistentFSStateException(curFile, \n              \"imgVersion \" + imgVersion +\n              \" expected to be \" + getLayoutVersion());\n        }\n        boolean supportSnapshot \u003d LayoutVersion.supports(Feature.SNAPSHOT,\n            imgVersion);\n\n        // read namespaceID: first appeared in version -2\n        in.readInt();\n\n        long numFiles \u003d in.readLong();\n\n        // read in the last generation stamp for legacy blocks.\n        long genstamp \u003d in.readLong();\n        namesystem.setGenerationStampV1(genstamp);\n        \n        if (LayoutVersion.supports(Feature.SEQUENTIAL_BLOCK_ID, imgVersion)) {\n          // read the starting generation stamp for sequential block IDs\n          genstamp \u003d in.readLong();\n          namesystem.setGenerationStampV2(genstamp);\n\n          // read the last generation stamp for blocks created after\n          // the switch to sequential block IDs.\n          long stampAtIdSwitch \u003d in.readLong();\n          namesystem.setGenerationStampV1Limit(stampAtIdSwitch);\n\n          // read the max sequential block ID.\n          long maxSequentialBlockId \u003d in.readLong();\n          namesystem.setLastAllocatedBlockId(maxSequentialBlockId);\n        } else {\n          long startingGenStamp \u003d namesystem.upgradeGenerationStampToV2();\n          // This is an upgrade.\n          LOG.info(\"Upgrading to sequential block IDs. Generation stamp \" +\n                   \"for new blocks set to \" + startingGenStamp);\n        }\n\n        // read the transaction ID of the last edit represented by\n        // this image\n        if (LayoutVersion.supports(Feature.STORED_TXIDS, imgVersion)) {\n          imgTxId \u003d in.readLong();\n        } else {\n          imgTxId \u003d 0;\n        }\n\n        // read the last allocated inode id in the fsimage\n        if (LayoutVersion.supports(Feature.ADD_INODE_ID, imgVersion)) {\n          long lastInodeId \u003d in.readLong();\n          namesystem.resetLastInodeId(lastInodeId);\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"load last allocated InodeId from fsimage:\" + lastInodeId);\n          }\n        } else {\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Old layout version doesn\u0027t have inode id.\"\n                + \" Will assign new id for each inode.\");\n          }\n        }\n        \n        if (supportSnapshot) {\n          snapshotMap \u003d namesystem.getSnapshotManager().read(in, this);\n        }\n\n        // read compression related info\n        FSImageCompression compression;\n        if (LayoutVersion.supports(Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n          compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n        } else {\n          compression \u003d FSImageCompression.createNoopCompression();\n        }\n        in \u003d compression.unwrapInputStream(fin);\n\n        LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n        \n        // load all inodes\n        LOG.info(\"Number of files \u003d \" + numFiles);\n        prog.setTotal(Phase.LOADING_FSIMAGE, step, numFiles);\n        Counter counter \u003d prog.getCounter(Phase.LOADING_FSIMAGE, step);\n        if (LayoutVersion.supports(Feature.FSIMAGE_NAME_OPTIMIZATION,\n            imgVersion)) {\n          if (supportSnapshot) {\n            loadLocalNameINodesWithSnapshot(numFiles, in, counter);\n          } else {\n            loadLocalNameINodes(numFiles, in, counter);\n          }\n        } else {\n          loadFullNameINodes(numFiles, in, counter);\n        }\n\n        loadFilesUnderConstruction(in, supportSnapshot, counter);\n        prog.endStep(Phase.LOADING_FSIMAGE, step);\n        // Now that the step is finished, set counter equal to total to adjust\n        // for possible under-counting due to reference inodes.\n        prog.setCount(Phase.LOADING_FSIMAGE, step, numFiles);\n\n        loadSecretManagerState(in);\n\n        loadCacheManagerState(in);\n\n        // make sure to read to the end of file\n        boolean eof \u003d (in.read() \u003d\u003d -1);\n        assert eof : \"Should have reached the end of image file \" + curFile;\n      } finally {\n        in.close();\n      }\n\n      imgDigest \u003d new MD5Hash(digester.digest());\n      loaded \u003d true;\n      \n      LOG.info(\"Image file \" + curFile + \" of size \" + curFile.length() +\n          \" bytes loaded in \" + (now() - startTime)/1000 + \" seconds.\");\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {}
    },
    "da8e962e39bd41b73b53966826c82e741b08010b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4372. Track NameNode startup progress. Contributed by Chris Nauroth.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1502120 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/07/13 10:35 PM",
      "commitName": "da8e962e39bd41b73b53966826c82e741b08010b",
      "commitAuthor": "Chris Nauroth",
      "commitDateOld": "07/07/13 10:29 PM",
      "commitNameOld": "6770de7ec4f73e16740f1723f4e35d2fef2c22c8",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 3.0,
      "commitsBetweenForRepo": 22,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,121 +1,130 @@\n     void load(File curFile) throws IOException {\n       checkNotLoaded();\n       assert curFile !\u003d null : \"curFile is null\";\n \n+      StartupProgress prog \u003d NameNode.getStartupProgress();\n+      Step step \u003d new Step(StepType.INODES);\n+      prog.beginStep(Phase.LOADING_FSIMAGE, step);\n       long startTime \u003d now();\n \n       //\n       // Load in bits\n       //\n       MessageDigest digester \u003d MD5Hash.getDigester();\n       DigestInputStream fin \u003d new DigestInputStream(\n            new FileInputStream(curFile), digester);\n \n       DataInputStream in \u003d new DataInputStream(fin);\n       try {\n         // read image version: first appeared in version -1\n         int imgVersion \u003d in.readInt();\n         if (getLayoutVersion() !\u003d imgVersion) {\n           throw new InconsistentFSStateException(curFile, \n               \"imgVersion \" + imgVersion +\n               \" expected to be \" + getLayoutVersion());\n         }\n         boolean supportSnapshot \u003d LayoutVersion.supports(Feature.SNAPSHOT,\n             imgVersion);\n \n         // read namespaceID: first appeared in version -2\n         in.readInt();\n \n         long numFiles \u003d in.readLong();\n \n         // read in the last generation stamp for legacy blocks.\n         long genstamp \u003d in.readLong();\n         namesystem.setGenerationStampV1(genstamp);\n         \n         if (LayoutVersion.supports(Feature.SEQUENTIAL_BLOCK_ID, imgVersion)) {\n           // read the starting generation stamp for sequential block IDs\n           genstamp \u003d in.readLong();\n           namesystem.setGenerationStampV2(genstamp);\n \n           // read the last generation stamp for blocks created after\n           // the switch to sequential block IDs.\n           long stampAtIdSwitch \u003d in.readLong();\n           namesystem.setGenerationStampV1Limit(stampAtIdSwitch);\n \n           // read the max sequential block ID.\n           long maxSequentialBlockId \u003d in.readLong();\n           namesystem.setLastAllocatedBlockId(maxSequentialBlockId);\n         } else {\n           long startingGenStamp \u003d namesystem.upgradeGenerationStampToV2();\n           // This is an upgrade.\n           LOG.info(\"Upgrading to sequential block IDs. Generation stamp \" +\n                    \"for new blocks set to \" + startingGenStamp);\n         }\n \n         // read the transaction ID of the last edit represented by\n         // this image\n         if (LayoutVersion.supports(Feature.STORED_TXIDS, imgVersion)) {\n           imgTxId \u003d in.readLong();\n         } else {\n           imgTxId \u003d 0;\n         }\n \n         // read the last allocated inode id in the fsimage\n         if (LayoutVersion.supports(Feature.ADD_INODE_ID, imgVersion)) {\n           long lastInodeId \u003d in.readLong();\n           namesystem.resetLastInodeId(lastInodeId);\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"load last allocated InodeId from fsimage:\" + lastInodeId);\n           }\n         } else {\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"Old layout version doesn\u0027t have inode id.\"\n                 + \" Will assign new id for each inode.\");\n           }\n         }\n         \n         if (supportSnapshot) {\n           snapshotMap \u003d namesystem.getSnapshotManager().read(in, this);\n         }\n \n         // read compression related info\n         FSImageCompression compression;\n         if (LayoutVersion.supports(Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n           compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n         } else {\n           compression \u003d FSImageCompression.createNoopCompression();\n         }\n         in \u003d compression.unwrapInputStream(fin);\n \n         LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n         \n         // load all inodes\n         LOG.info(\"Number of files \u003d \" + numFiles);\n+        prog.setTotal(Phase.LOADING_FSIMAGE, step, numFiles);\n+        Counter counter \u003d prog.getCounter(Phase.LOADING_FSIMAGE, step);\n         if (LayoutVersion.supports(Feature.FSIMAGE_NAME_OPTIMIZATION,\n             imgVersion)) {\n           if (supportSnapshot) {\n-            loadLocalNameINodesWithSnapshot(in);\n+            loadLocalNameINodesWithSnapshot(numFiles, in, counter);\n           } else {\n-            loadLocalNameINodes(numFiles, in);\n+            loadLocalNameINodes(numFiles, in, counter);\n           }\n         } else {\n-          loadFullNameINodes(numFiles, in);\n+          loadFullNameINodes(numFiles, in, counter);\n         }\n \n-        loadFilesUnderConstruction(in, supportSnapshot);\n+        loadFilesUnderConstruction(in, supportSnapshot, counter);\n+        prog.endStep(Phase.LOADING_FSIMAGE, step);\n+        // Now that the step is finished, set counter equal to total to adjust\n+        // for possible under-counting due to reference inodes.\n+        prog.setCount(Phase.LOADING_FSIMAGE, step, numFiles);\n \n         loadSecretManagerState(in);\n \n         // make sure to read to the end of file\n         boolean eof \u003d (in.read() \u003d\u003d -1);\n         assert eof : \"Should have reached the end of image file \" + curFile;\n       } finally {\n         in.close();\n       }\n \n       imgDigest \u003d new MD5Hash(digester.digest());\n       loaded \u003d true;\n       \n       LOG.info(\"Image file \" + curFile + \" of size \" + curFile.length() +\n           \" bytes loaded in \" + (now() - startTime)/1000 + \" seconds.\");\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void load(File curFile) throws IOException {\n      checkNotLoaded();\n      assert curFile !\u003d null : \"curFile is null\";\n\n      StartupProgress prog \u003d NameNode.getStartupProgress();\n      Step step \u003d new Step(StepType.INODES);\n      prog.beginStep(Phase.LOADING_FSIMAGE, step);\n      long startTime \u003d now();\n\n      //\n      // Load in bits\n      //\n      MessageDigest digester \u003d MD5Hash.getDigester();\n      DigestInputStream fin \u003d new DigestInputStream(\n           new FileInputStream(curFile), digester);\n\n      DataInputStream in \u003d new DataInputStream(fin);\n      try {\n        // read image version: first appeared in version -1\n        int imgVersion \u003d in.readInt();\n        if (getLayoutVersion() !\u003d imgVersion) {\n          throw new InconsistentFSStateException(curFile, \n              \"imgVersion \" + imgVersion +\n              \" expected to be \" + getLayoutVersion());\n        }\n        boolean supportSnapshot \u003d LayoutVersion.supports(Feature.SNAPSHOT,\n            imgVersion);\n\n        // read namespaceID: first appeared in version -2\n        in.readInt();\n\n        long numFiles \u003d in.readLong();\n\n        // read in the last generation stamp for legacy blocks.\n        long genstamp \u003d in.readLong();\n        namesystem.setGenerationStampV1(genstamp);\n        \n        if (LayoutVersion.supports(Feature.SEQUENTIAL_BLOCK_ID, imgVersion)) {\n          // read the starting generation stamp for sequential block IDs\n          genstamp \u003d in.readLong();\n          namesystem.setGenerationStampV2(genstamp);\n\n          // read the last generation stamp for blocks created after\n          // the switch to sequential block IDs.\n          long stampAtIdSwitch \u003d in.readLong();\n          namesystem.setGenerationStampV1Limit(stampAtIdSwitch);\n\n          // read the max sequential block ID.\n          long maxSequentialBlockId \u003d in.readLong();\n          namesystem.setLastAllocatedBlockId(maxSequentialBlockId);\n        } else {\n          long startingGenStamp \u003d namesystem.upgradeGenerationStampToV2();\n          // This is an upgrade.\n          LOG.info(\"Upgrading to sequential block IDs. Generation stamp \" +\n                   \"for new blocks set to \" + startingGenStamp);\n        }\n\n        // read the transaction ID of the last edit represented by\n        // this image\n        if (LayoutVersion.supports(Feature.STORED_TXIDS, imgVersion)) {\n          imgTxId \u003d in.readLong();\n        } else {\n          imgTxId \u003d 0;\n        }\n\n        // read the last allocated inode id in the fsimage\n        if (LayoutVersion.supports(Feature.ADD_INODE_ID, imgVersion)) {\n          long lastInodeId \u003d in.readLong();\n          namesystem.resetLastInodeId(lastInodeId);\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"load last allocated InodeId from fsimage:\" + lastInodeId);\n          }\n        } else {\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Old layout version doesn\u0027t have inode id.\"\n                + \" Will assign new id for each inode.\");\n          }\n        }\n        \n        if (supportSnapshot) {\n          snapshotMap \u003d namesystem.getSnapshotManager().read(in, this);\n        }\n\n        // read compression related info\n        FSImageCompression compression;\n        if (LayoutVersion.supports(Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n          compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n        } else {\n          compression \u003d FSImageCompression.createNoopCompression();\n        }\n        in \u003d compression.unwrapInputStream(fin);\n\n        LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n        \n        // load all inodes\n        LOG.info(\"Number of files \u003d \" + numFiles);\n        prog.setTotal(Phase.LOADING_FSIMAGE, step, numFiles);\n        Counter counter \u003d prog.getCounter(Phase.LOADING_FSIMAGE, step);\n        if (LayoutVersion.supports(Feature.FSIMAGE_NAME_OPTIMIZATION,\n            imgVersion)) {\n          if (supportSnapshot) {\n            loadLocalNameINodesWithSnapshot(numFiles, in, counter);\n          } else {\n            loadLocalNameINodes(numFiles, in, counter);\n          }\n        } else {\n          loadFullNameINodes(numFiles, in, counter);\n        }\n\n        loadFilesUnderConstruction(in, supportSnapshot, counter);\n        prog.endStep(Phase.LOADING_FSIMAGE, step);\n        // Now that the step is finished, set counter equal to total to adjust\n        // for possible under-counting due to reference inodes.\n        prog.setCount(Phase.LOADING_FSIMAGE, step, numFiles);\n\n        loadSecretManagerState(in);\n\n        // make sure to read to the end of file\n        boolean eof \u003d (in.read() \u003d\u003d -1);\n        assert eof : \"Should have reached the end of image file \" + curFile;\n      } finally {\n        in.close();\n      }\n\n      imgDigest \u003d new MD5Hash(digester.digest());\n      loaded \u003d true;\n      \n      LOG.info(\"Image file \" + curFile + \" of size \" + curFile.length() +\n          \" bytes loaded in \" + (now() - startTime)/1000 + \" seconds.\");\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {}
    },
    "6770de7ec4f73e16740f1723f4e35d2fef2c22c8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4645.  Move from randomly generated block ID to sequentially generated block ID.  Contributed by Arpit Agarwal\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1500580 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/07/13 10:29 PM",
      "commitName": "6770de7ec4f73e16740f1723f4e35d2fef2c22c8",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "19/06/13 10:10 PM",
      "commitNameOld": "c02953dbc344b39e0eb0d13fe2d899cdcdc46380",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 18.01,
      "commitsBetweenForRepo": 59,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,101 +1,121 @@\n     void load(File curFile) throws IOException {\n       checkNotLoaded();\n       assert curFile !\u003d null : \"curFile is null\";\n \n       long startTime \u003d now();\n \n       //\n       // Load in bits\n       //\n       MessageDigest digester \u003d MD5Hash.getDigester();\n       DigestInputStream fin \u003d new DigestInputStream(\n            new FileInputStream(curFile), digester);\n \n       DataInputStream in \u003d new DataInputStream(fin);\n       try {\n         // read image version: first appeared in version -1\n         int imgVersion \u003d in.readInt();\n         if (getLayoutVersion() !\u003d imgVersion) {\n           throw new InconsistentFSStateException(curFile, \n               \"imgVersion \" + imgVersion +\n               \" expected to be \" + getLayoutVersion());\n         }\n         boolean supportSnapshot \u003d LayoutVersion.supports(Feature.SNAPSHOT,\n             imgVersion);\n \n         // read namespaceID: first appeared in version -2\n         in.readInt();\n \n         long numFiles \u003d in.readLong();\n \n-        // read in the last generation stamp.\n+        // read in the last generation stamp for legacy blocks.\n         long genstamp \u003d in.readLong();\n-        namesystem.setGenerationStamp(genstamp); \n+        namesystem.setGenerationStampV1(genstamp);\n         \n+        if (LayoutVersion.supports(Feature.SEQUENTIAL_BLOCK_ID, imgVersion)) {\n+          // read the starting generation stamp for sequential block IDs\n+          genstamp \u003d in.readLong();\n+          namesystem.setGenerationStampV2(genstamp);\n+\n+          // read the last generation stamp for blocks created after\n+          // the switch to sequential block IDs.\n+          long stampAtIdSwitch \u003d in.readLong();\n+          namesystem.setGenerationStampV1Limit(stampAtIdSwitch);\n+\n+          // read the max sequential block ID.\n+          long maxSequentialBlockId \u003d in.readLong();\n+          namesystem.setLastAllocatedBlockId(maxSequentialBlockId);\n+        } else {\n+          long startingGenStamp \u003d namesystem.upgradeGenerationStampToV2();\n+          // This is an upgrade.\n+          LOG.info(\"Upgrading to sequential block IDs. Generation stamp \" +\n+                   \"for new blocks set to \" + startingGenStamp);\n+        }\n+\n         // read the transaction ID of the last edit represented by\n         // this image\n         if (LayoutVersion.supports(Feature.STORED_TXIDS, imgVersion)) {\n           imgTxId \u003d in.readLong();\n         } else {\n           imgTxId \u003d 0;\n         }\n \n         // read the last allocated inode id in the fsimage\n         if (LayoutVersion.supports(Feature.ADD_INODE_ID, imgVersion)) {\n           long lastInodeId \u003d in.readLong();\n           namesystem.resetLastInodeId(lastInodeId);\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"load last allocated InodeId from fsimage:\" + lastInodeId);\n           }\n         } else {\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"Old layout version doesn\u0027t have inode id.\"\n                 + \" Will assign new id for each inode.\");\n           }\n         }\n         \n         if (supportSnapshot) {\n           snapshotMap \u003d namesystem.getSnapshotManager().read(in, this);\n         }\n \n         // read compression related info\n         FSImageCompression compression;\n         if (LayoutVersion.supports(Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n           compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n         } else {\n           compression \u003d FSImageCompression.createNoopCompression();\n         }\n         in \u003d compression.unwrapInputStream(fin);\n \n         LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n         \n         // load all inodes\n         LOG.info(\"Number of files \u003d \" + numFiles);\n         if (LayoutVersion.supports(Feature.FSIMAGE_NAME_OPTIMIZATION,\n             imgVersion)) {\n           if (supportSnapshot) {\n             loadLocalNameINodesWithSnapshot(in);\n           } else {\n             loadLocalNameINodes(numFiles, in);\n           }\n         } else {\n           loadFullNameINodes(numFiles, in);\n         }\n \n         loadFilesUnderConstruction(in, supportSnapshot);\n \n         loadSecretManagerState(in);\n \n         // make sure to read to the end of file\n         boolean eof \u003d (in.read() \u003d\u003d -1);\n         assert eof : \"Should have reached the end of image file \" + curFile;\n       } finally {\n         in.close();\n       }\n \n       imgDigest \u003d new MD5Hash(digester.digest());\n       loaded \u003d true;\n       \n       LOG.info(\"Image file \" + curFile + \" of size \" + curFile.length() +\n           \" bytes loaded in \" + (now() - startTime)/1000 + \" seconds.\");\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void load(File curFile) throws IOException {\n      checkNotLoaded();\n      assert curFile !\u003d null : \"curFile is null\";\n\n      long startTime \u003d now();\n\n      //\n      // Load in bits\n      //\n      MessageDigest digester \u003d MD5Hash.getDigester();\n      DigestInputStream fin \u003d new DigestInputStream(\n           new FileInputStream(curFile), digester);\n\n      DataInputStream in \u003d new DataInputStream(fin);\n      try {\n        // read image version: first appeared in version -1\n        int imgVersion \u003d in.readInt();\n        if (getLayoutVersion() !\u003d imgVersion) {\n          throw new InconsistentFSStateException(curFile, \n              \"imgVersion \" + imgVersion +\n              \" expected to be \" + getLayoutVersion());\n        }\n        boolean supportSnapshot \u003d LayoutVersion.supports(Feature.SNAPSHOT,\n            imgVersion);\n\n        // read namespaceID: first appeared in version -2\n        in.readInt();\n\n        long numFiles \u003d in.readLong();\n\n        // read in the last generation stamp for legacy blocks.\n        long genstamp \u003d in.readLong();\n        namesystem.setGenerationStampV1(genstamp);\n        \n        if (LayoutVersion.supports(Feature.SEQUENTIAL_BLOCK_ID, imgVersion)) {\n          // read the starting generation stamp for sequential block IDs\n          genstamp \u003d in.readLong();\n          namesystem.setGenerationStampV2(genstamp);\n\n          // read the last generation stamp for blocks created after\n          // the switch to sequential block IDs.\n          long stampAtIdSwitch \u003d in.readLong();\n          namesystem.setGenerationStampV1Limit(stampAtIdSwitch);\n\n          // read the max sequential block ID.\n          long maxSequentialBlockId \u003d in.readLong();\n          namesystem.setLastAllocatedBlockId(maxSequentialBlockId);\n        } else {\n          long startingGenStamp \u003d namesystem.upgradeGenerationStampToV2();\n          // This is an upgrade.\n          LOG.info(\"Upgrading to sequential block IDs. Generation stamp \" +\n                   \"for new blocks set to \" + startingGenStamp);\n        }\n\n        // read the transaction ID of the last edit represented by\n        // this image\n        if (LayoutVersion.supports(Feature.STORED_TXIDS, imgVersion)) {\n          imgTxId \u003d in.readLong();\n        } else {\n          imgTxId \u003d 0;\n        }\n\n        // read the last allocated inode id in the fsimage\n        if (LayoutVersion.supports(Feature.ADD_INODE_ID, imgVersion)) {\n          long lastInodeId \u003d in.readLong();\n          namesystem.resetLastInodeId(lastInodeId);\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"load last allocated InodeId from fsimage:\" + lastInodeId);\n          }\n        } else {\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Old layout version doesn\u0027t have inode id.\"\n                + \" Will assign new id for each inode.\");\n          }\n        }\n        \n        if (supportSnapshot) {\n          snapshotMap \u003d namesystem.getSnapshotManager().read(in, this);\n        }\n\n        // read compression related info\n        FSImageCompression compression;\n        if (LayoutVersion.supports(Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n          compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n        } else {\n          compression \u003d FSImageCompression.createNoopCompression();\n        }\n        in \u003d compression.unwrapInputStream(fin);\n\n        LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n        \n        // load all inodes\n        LOG.info(\"Number of files \u003d \" + numFiles);\n        if (LayoutVersion.supports(Feature.FSIMAGE_NAME_OPTIMIZATION,\n            imgVersion)) {\n          if (supportSnapshot) {\n            loadLocalNameINodesWithSnapshot(in);\n          } else {\n            loadLocalNameINodes(numFiles, in);\n          }\n        } else {\n          loadFullNameINodes(numFiles, in);\n        }\n\n        loadFilesUnderConstruction(in, supportSnapshot);\n\n        loadSecretManagerState(in);\n\n        // make sure to read to the end of file\n        boolean eof \u003d (in.read() \u003d\u003d -1);\n        assert eof : \"Should have reached the end of image file \" + curFile;\n      } finally {\n        in.close();\n      }\n\n      imgDigest \u003d new MD5Hash(digester.digest());\n      loaded \u003d true;\n      \n      LOG.info(\"Image file \" + curFile + \" of size \" + curFile.length() +\n          \" bytes loaded in \" + (now() - startTime)/1000 + \" seconds.\");\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {}
    },
    "a764da16d6a02372f19b45cc841f0dff001d7b24": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4880. Print the image and edits file loaded by the namenode in the logs. Contributed by Arpit Agarwal.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1490746 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/06/13 10:35 AM",
      "commitName": "a764da16d6a02372f19b45cc841f0dff001d7b24",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "04/06/13 10:26 PM",
      "commitNameOld": "e00f828b119b6a271b6319b6c4885228cd4cb3ed",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 2.51,
      "commitsBetweenForRepo": 17,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,101 +1,101 @@\n     void load(File curFile) throws IOException {\n       checkNotLoaded();\n       assert curFile !\u003d null : \"curFile is null\";\n \n       long startTime \u003d now();\n \n       //\n       // Load in bits\n       //\n       MessageDigest digester \u003d MD5Hash.getDigester();\n       DigestInputStream fin \u003d new DigestInputStream(\n            new FileInputStream(curFile), digester);\n \n       DataInputStream in \u003d new DataInputStream(fin);\n       try {\n         // read image version: first appeared in version -1\n         int imgVersion \u003d in.readInt();\n         if (getLayoutVersion() !\u003d imgVersion) {\n           throw new InconsistentFSStateException(curFile, \n               \"imgVersion \" + imgVersion +\n               \" expected to be \" + getLayoutVersion());\n         }\n         boolean supportSnapshot \u003d LayoutVersion.supports(Feature.SNAPSHOT,\n             imgVersion);\n \n         // read namespaceID: first appeared in version -2\n         in.readInt();\n \n         long numFiles \u003d in.readLong();\n \n         // read in the last generation stamp.\n         long genstamp \u003d in.readLong();\n         namesystem.setGenerationStamp(genstamp); \n         \n         // read the transaction ID of the last edit represented by\n         // this image\n         if (LayoutVersion.supports(Feature.STORED_TXIDS, imgVersion)) {\n           imgTxId \u003d in.readLong();\n         } else {\n           imgTxId \u003d 0;\n         }\n \n         // read the last allocated inode id in the fsimage\n         if (LayoutVersion.supports(Feature.ADD_INODE_ID, imgVersion)) {\n           long lastInodeId \u003d in.readLong();\n           namesystem.resetLastInodeId(lastInodeId);\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"load last allocated InodeId from fsimage:\" + lastInodeId);\n           }\n         } else {\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"Old layout version doesn\u0027t have inode id.\"\n                 + \" Will assign new id for each inode.\");\n           }\n         }\n         \n         if (supportSnapshot) {\n           snapshotMap \u003d namesystem.getSnapshotManager().read(in, this);\n         }\n \n         // read compression related info\n         FSImageCompression compression;\n         if (LayoutVersion.supports(Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n           compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n         } else {\n           compression \u003d FSImageCompression.createNoopCompression();\n         }\n         in \u003d compression.unwrapInputStream(fin);\n \n         LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n         \n         // load all inodes\n         LOG.info(\"Number of files \u003d \" + numFiles);\n         if (LayoutVersion.supports(Feature.FSIMAGE_NAME_OPTIMIZATION,\n             imgVersion)) {\n           if (supportSnapshot) {\n             loadLocalNameINodesWithSnapshot(in);\n           } else {\n             loadLocalNameINodes(numFiles, in);\n           }\n         } else {\n           loadFullNameINodes(numFiles, in);\n         }\n \n         loadFilesUnderConstruction(in, supportSnapshot);\n \n         loadSecretManagerState(in);\n \n         // make sure to read to the end of file\n         boolean eof \u003d (in.read() \u003d\u003d -1);\n         assert eof : \"Should have reached the end of image file \" + curFile;\n       } finally {\n         in.close();\n       }\n \n       imgDigest \u003d new MD5Hash(digester.digest());\n       loaded \u003d true;\n       \n-      LOG.info(\"Image file of size \" + curFile.length() + \" loaded in \" \n-          + (now() - startTime)/1000 + \" seconds.\");\n+      LOG.info(\"Image file \" + curFile + \" of size \" + curFile.length() +\n+          \" bytes loaded in \" + (now() - startTime)/1000 + \" seconds.\");\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void load(File curFile) throws IOException {\n      checkNotLoaded();\n      assert curFile !\u003d null : \"curFile is null\";\n\n      long startTime \u003d now();\n\n      //\n      // Load in bits\n      //\n      MessageDigest digester \u003d MD5Hash.getDigester();\n      DigestInputStream fin \u003d new DigestInputStream(\n           new FileInputStream(curFile), digester);\n\n      DataInputStream in \u003d new DataInputStream(fin);\n      try {\n        // read image version: first appeared in version -1\n        int imgVersion \u003d in.readInt();\n        if (getLayoutVersion() !\u003d imgVersion) {\n          throw new InconsistentFSStateException(curFile, \n              \"imgVersion \" + imgVersion +\n              \" expected to be \" + getLayoutVersion());\n        }\n        boolean supportSnapshot \u003d LayoutVersion.supports(Feature.SNAPSHOT,\n            imgVersion);\n\n        // read namespaceID: first appeared in version -2\n        in.readInt();\n\n        long numFiles \u003d in.readLong();\n\n        // read in the last generation stamp.\n        long genstamp \u003d in.readLong();\n        namesystem.setGenerationStamp(genstamp); \n        \n        // read the transaction ID of the last edit represented by\n        // this image\n        if (LayoutVersion.supports(Feature.STORED_TXIDS, imgVersion)) {\n          imgTxId \u003d in.readLong();\n        } else {\n          imgTxId \u003d 0;\n        }\n\n        // read the last allocated inode id in the fsimage\n        if (LayoutVersion.supports(Feature.ADD_INODE_ID, imgVersion)) {\n          long lastInodeId \u003d in.readLong();\n          namesystem.resetLastInodeId(lastInodeId);\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"load last allocated InodeId from fsimage:\" + lastInodeId);\n          }\n        } else {\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Old layout version doesn\u0027t have inode id.\"\n                + \" Will assign new id for each inode.\");\n          }\n        }\n        \n        if (supportSnapshot) {\n          snapshotMap \u003d namesystem.getSnapshotManager().read(in, this);\n        }\n\n        // read compression related info\n        FSImageCompression compression;\n        if (LayoutVersion.supports(Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n          compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n        } else {\n          compression \u003d FSImageCompression.createNoopCompression();\n        }\n        in \u003d compression.unwrapInputStream(fin);\n\n        LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n        \n        // load all inodes\n        LOG.info(\"Number of files \u003d \" + numFiles);\n        if (LayoutVersion.supports(Feature.FSIMAGE_NAME_OPTIMIZATION,\n            imgVersion)) {\n          if (supportSnapshot) {\n            loadLocalNameINodesWithSnapshot(in);\n          } else {\n            loadLocalNameINodes(numFiles, in);\n          }\n        } else {\n          loadFullNameINodes(numFiles, in);\n        }\n\n        loadFilesUnderConstruction(in, supportSnapshot);\n\n        loadSecretManagerState(in);\n\n        // make sure to read to the end of file\n        boolean eof \u003d (in.read() \u003d\u003d -1);\n        assert eof : \"Should have reached the end of image file \" + curFile;\n      } finally {\n        in.close();\n      }\n\n      imgDigest \u003d new MD5Hash(digester.digest());\n      loaded \u003d true;\n      \n      LOG.info(\"Image file \" + curFile + \" of size \" + curFile.length() +\n          \" bytes loaded in \" + (now() - startTime)/1000 + \" seconds.\");\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {}
    },
    "4c00514ede4e7e028b18f76a9b8edfedab8631d4": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4684. Use INode id for image serialization when writing INodeReference.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2802@1466718 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/04/13 3:24 PM",
      "commitName": "4c00514ede4e7e028b18f76a9b8edfedab8631d4",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "10/04/13 1:17 PM",
      "commitNameOld": "3209d4a3c4d4c227ca50bbcd1ab3e939beceec35",
      "commitAuthorOld": "",
      "daysBetweenCommits": 0.09,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,101 +1,101 @@\n     void load(File curFile) throws IOException {\n       checkNotLoaded();\n       assert curFile !\u003d null : \"curFile is null\";\n \n       long startTime \u003d now();\n \n       //\n       // Load in bits\n       //\n       MessageDigest digester \u003d MD5Hash.getDigester();\n       DigestInputStream fin \u003d new DigestInputStream(\n            new FileInputStream(curFile), digester);\n \n       DataInputStream in \u003d new DataInputStream(fin);\n       try {\n         // read image version: first appeared in version -1\n         int imgVersion \u003d in.readInt();\n         if (getLayoutVersion() !\u003d imgVersion) {\n           throw new InconsistentFSStateException(curFile, \n               \"imgVersion \" + imgVersion +\n               \" expected to be \" + getLayoutVersion());\n         }\n         boolean supportSnapshot \u003d LayoutVersion.supports(Feature.SNAPSHOT,\n             imgVersion);\n \n         // read namespaceID: first appeared in version -2\n         in.readInt();\n \n         long numFiles \u003d in.readLong();\n \n         // read in the last generation stamp.\n         long genstamp \u003d in.readLong();\n         namesystem.setGenerationStamp(genstamp); \n         \n         // read the transaction ID of the last edit represented by\n         // this image\n         if (LayoutVersion.supports(Feature.STORED_TXIDS, imgVersion)) {\n           imgTxId \u003d in.readLong();\n         } else {\n           imgTxId \u003d 0;\n         }\n-        \n-        if (supportSnapshot) {\n-          snapshotMap \u003d namesystem.getSnapshotManager().read(in, this);\n-        }\n \n         // read the last allocated inode id in the fsimage\n         if (LayoutVersion.supports(Feature.ADD_INODE_ID, imgVersion)) {\n           long lastInodeId \u003d in.readLong();\n           namesystem.resetLastInodeId(lastInodeId);\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"load last allocated InodeId from fsimage:\" + lastInodeId);\n           }\n         } else {\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"Old layout version doesn\u0027t have inode id.\"\n                 + \" Will assign new id for each inode.\");\n           }\n         }\n         \n+        if (supportSnapshot) {\n+          snapshotMap \u003d namesystem.getSnapshotManager().read(in, this);\n+        }\n+\n         // read compression related info\n         FSImageCompression compression;\n         if (LayoutVersion.supports(Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n           compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n         } else {\n           compression \u003d FSImageCompression.createNoopCompression();\n         }\n         in \u003d compression.unwrapInputStream(fin);\n \n         LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n         \n         // load all inodes\n         LOG.info(\"Number of files \u003d \" + numFiles);\n         if (LayoutVersion.supports(Feature.FSIMAGE_NAME_OPTIMIZATION,\n             imgVersion)) {\n           if (supportSnapshot) {\n             loadLocalNameINodesWithSnapshot(in);\n           } else {\n             loadLocalNameINodes(numFiles, in);\n           }\n         } else {\n           loadFullNameINodes(numFiles, in);\n         }\n \n         loadFilesUnderConstruction(in, supportSnapshot);\n \n         loadSecretManagerState(in);\n \n         // make sure to read to the end of file\n         boolean eof \u003d (in.read() \u003d\u003d -1);\n         assert eof : \"Should have reached the end of image file \" + curFile;\n       } finally {\n         in.close();\n       }\n \n       imgDigest \u003d new MD5Hash(digester.digest());\n       loaded \u003d true;\n       \n       LOG.info(\"Image file of size \" + curFile.length() + \" loaded in \" \n           + (now() - startTime)/1000 + \" seconds.\");\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void load(File curFile) throws IOException {\n      checkNotLoaded();\n      assert curFile !\u003d null : \"curFile is null\";\n\n      long startTime \u003d now();\n\n      //\n      // Load in bits\n      //\n      MessageDigest digester \u003d MD5Hash.getDigester();\n      DigestInputStream fin \u003d new DigestInputStream(\n           new FileInputStream(curFile), digester);\n\n      DataInputStream in \u003d new DataInputStream(fin);\n      try {\n        // read image version: first appeared in version -1\n        int imgVersion \u003d in.readInt();\n        if (getLayoutVersion() !\u003d imgVersion) {\n          throw new InconsistentFSStateException(curFile, \n              \"imgVersion \" + imgVersion +\n              \" expected to be \" + getLayoutVersion());\n        }\n        boolean supportSnapshot \u003d LayoutVersion.supports(Feature.SNAPSHOT,\n            imgVersion);\n\n        // read namespaceID: first appeared in version -2\n        in.readInt();\n\n        long numFiles \u003d in.readLong();\n\n        // read in the last generation stamp.\n        long genstamp \u003d in.readLong();\n        namesystem.setGenerationStamp(genstamp); \n        \n        // read the transaction ID of the last edit represented by\n        // this image\n        if (LayoutVersion.supports(Feature.STORED_TXIDS, imgVersion)) {\n          imgTxId \u003d in.readLong();\n        } else {\n          imgTxId \u003d 0;\n        }\n\n        // read the last allocated inode id in the fsimage\n        if (LayoutVersion.supports(Feature.ADD_INODE_ID, imgVersion)) {\n          long lastInodeId \u003d in.readLong();\n          namesystem.resetLastInodeId(lastInodeId);\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"load last allocated InodeId from fsimage:\" + lastInodeId);\n          }\n        } else {\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Old layout version doesn\u0027t have inode id.\"\n                + \" Will assign new id for each inode.\");\n          }\n        }\n        \n        if (supportSnapshot) {\n          snapshotMap \u003d namesystem.getSnapshotManager().read(in, this);\n        }\n\n        // read compression related info\n        FSImageCompression compression;\n        if (LayoutVersion.supports(Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n          compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n        } else {\n          compression \u003d FSImageCompression.createNoopCompression();\n        }\n        in \u003d compression.unwrapInputStream(fin);\n\n        LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n        \n        // load all inodes\n        LOG.info(\"Number of files \u003d \" + numFiles);\n        if (LayoutVersion.supports(Feature.FSIMAGE_NAME_OPTIMIZATION,\n            imgVersion)) {\n          if (supportSnapshot) {\n            loadLocalNameINodesWithSnapshot(in);\n          } else {\n            loadLocalNameINodes(numFiles, in);\n          }\n        } else {\n          loadFullNameINodes(numFiles, in);\n        }\n\n        loadFilesUnderConstruction(in, supportSnapshot);\n\n        loadSecretManagerState(in);\n\n        // make sure to read to the end of file\n        boolean eof \u003d (in.read() \u003d\u003d -1);\n        assert eof : \"Should have reached the end of image file \" + curFile;\n      } finally {\n        in.close();\n      }\n\n      imgDigest \u003d new MD5Hash(digester.digest());\n      loaded \u003d true;\n      \n      LOG.info(\"Image file of size \" + curFile.length() + \" loaded in \" \n          + (now() - startTime)/1000 + \" seconds.\");\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {}
    },
    "19201622be1db8e166d1cc0dd7e62af4702d2784": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4339. Persist inode id in fsimage and editlog. Contributed by Brandon Li.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1465835 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/04/13 4:57 PM",
      "commitName": "19201622be1db8e166d1cc0dd7e62af4702d2784",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "14/03/13 11:04 AM",
      "commitNameOld": "bcabbcdf4cf7b4bcda62d74b06c9736bc55f6fc1",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 25.25,
      "commitsBetweenForRepo": 130,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,80 +1,93 @@\n     void load(File curFile)\n       throws IOException\n     {\n       checkNotLoaded();\n       assert curFile !\u003d null : \"curFile is null\";\n \n       long startTime \u003d now();\n \n       //\n       // Load in bits\n       //\n       MessageDigest digester \u003d MD5Hash.getDigester();\n       DigestInputStream fin \u003d new DigestInputStream(\n            new FileInputStream(curFile), digester);\n \n       DataInputStream in \u003d new DataInputStream(fin);\n       try {\n         // read image version: first appeared in version -1\n         int imgVersion \u003d in.readInt();\n         if (getLayoutVersion() !\u003d imgVersion) {\n           throw new InconsistentFSStateException(curFile, \n               \"imgVersion \" + imgVersion +\n               \" expected to be \" + getLayoutVersion());\n         }\n \n         // read namespaceID: first appeared in version -2\n         in.readInt();\n \n         long numFiles \u003d in.readLong();\n \n         // read in the last generation stamp.\n         long genstamp \u003d in.readLong();\n         namesystem.setGenerationStamp(genstamp); \n         \n         // read the transaction ID of the last edit represented by\n         // this image\n         if (LayoutVersion.supports(Feature.STORED_TXIDS, imgVersion)) {\n           imgTxId \u003d in.readLong();\n         } else {\n           imgTxId \u003d 0;\n         }\n \n+        // read the last allocated inode id in the fsimage\n+        if (LayoutVersion.supports(Feature.ADD_INODE_ID, imgVersion)) {\n+          long lastInodeId \u003d in.readLong();\n+          namesystem.resetLastInodeId(lastInodeId);\n+          if (LOG.isDebugEnabled()) {\n+            LOG.debug(\"load last allocated InodeId from fsimage:\" + lastInodeId);\n+          }\n+        } else {\n+          if (LOG.isDebugEnabled()) {\n+            LOG.debug(\"Old layout version doesn\u0027t have inode id.\"\n+                + \" Will assign new id for each inode.\");\n+          }\n+        }\n+        \n         // read compression related info\n         FSImageCompression compression;\n         if (LayoutVersion.supports(Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n           compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n         } else {\n           compression \u003d FSImageCompression.createNoopCompression();\n         }\n         in \u003d compression.unwrapInputStream(fin);\n \n         LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n-        // reset INodeId. TODO: remove this after inodeId is persisted in fsimage\n-        namesystem.resetLastInodeIdWithoutChecking(INodeId.LAST_RESERVED_ID); \n+        \n         // load all inodes\n         LOG.info(\"Number of files \u003d \" + numFiles);\n         if (LayoutVersion.supports(Feature.FSIMAGE_NAME_OPTIMIZATION,\n             imgVersion)) {\n           loadLocalNameINodes(numFiles, in);\n         } else {\n           loadFullNameINodes(numFiles, in);\n         }\n \n         loadFilesUnderConstruction(in);\n \n         loadSecretManagerState(in);\n \n         // make sure to read to the end of file\n         boolean eof \u003d (in.read() \u003d\u003d -1);\n         assert eof : \"Should have reached the end of image file \" + curFile;\n       } finally {\n         in.close();\n       }\n \n       imgDigest \u003d new MD5Hash(digester.digest());\n       loaded \u003d true;\n       \n       LOG.info(\"Image file of size \" + curFile.length() + \" loaded in \" \n           + (now() - startTime)/1000 + \" seconds.\");\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void load(File curFile)\n      throws IOException\n    {\n      checkNotLoaded();\n      assert curFile !\u003d null : \"curFile is null\";\n\n      long startTime \u003d now();\n\n      //\n      // Load in bits\n      //\n      MessageDigest digester \u003d MD5Hash.getDigester();\n      DigestInputStream fin \u003d new DigestInputStream(\n           new FileInputStream(curFile), digester);\n\n      DataInputStream in \u003d new DataInputStream(fin);\n      try {\n        // read image version: first appeared in version -1\n        int imgVersion \u003d in.readInt();\n        if (getLayoutVersion() !\u003d imgVersion) {\n          throw new InconsistentFSStateException(curFile, \n              \"imgVersion \" + imgVersion +\n              \" expected to be \" + getLayoutVersion());\n        }\n\n        // read namespaceID: first appeared in version -2\n        in.readInt();\n\n        long numFiles \u003d in.readLong();\n\n        // read in the last generation stamp.\n        long genstamp \u003d in.readLong();\n        namesystem.setGenerationStamp(genstamp); \n        \n        // read the transaction ID of the last edit represented by\n        // this image\n        if (LayoutVersion.supports(Feature.STORED_TXIDS, imgVersion)) {\n          imgTxId \u003d in.readLong();\n        } else {\n          imgTxId \u003d 0;\n        }\n\n        // read the last allocated inode id in the fsimage\n        if (LayoutVersion.supports(Feature.ADD_INODE_ID, imgVersion)) {\n          long lastInodeId \u003d in.readLong();\n          namesystem.resetLastInodeId(lastInodeId);\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"load last allocated InodeId from fsimage:\" + lastInodeId);\n          }\n        } else {\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Old layout version doesn\u0027t have inode id.\"\n                + \" Will assign new id for each inode.\");\n          }\n        }\n        \n        // read compression related info\n        FSImageCompression compression;\n        if (LayoutVersion.supports(Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n          compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n        } else {\n          compression \u003d FSImageCompression.createNoopCompression();\n        }\n        in \u003d compression.unwrapInputStream(fin);\n\n        LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n        \n        // load all inodes\n        LOG.info(\"Number of files \u003d \" + numFiles);\n        if (LayoutVersion.supports(Feature.FSIMAGE_NAME_OPTIMIZATION,\n            imgVersion)) {\n          loadLocalNameINodes(numFiles, in);\n        } else {\n          loadFullNameINodes(numFiles, in);\n        }\n\n        loadFilesUnderConstruction(in);\n\n        loadSecretManagerState(in);\n\n        // make sure to read to the end of file\n        boolean eof \u003d (in.read() \u003d\u003d -1);\n        assert eof : \"Should have reached the end of image file \" + curFile;\n      } finally {\n        in.close();\n      }\n\n      imgDigest \u003d new MD5Hash(digester.digest());\n      loaded \u003d true;\n      \n      LOG.info(\"Image file of size \" + curFile.length() + \" loaded in \" \n          + (now() - startTime)/1000 + \" seconds.\");\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {}
    },
    "1096917649fd951be633e5619518764f23cca645": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4611. Update FSImage for INodeReference.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2802@1463332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "01/04/13 4:24 PM",
      "commitName": "1096917649fd951be633e5619518764f23cca645",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "24/03/13 7:53 AM",
      "commitNameOld": "993a76f2dd1ca75194b857f01bebba548b963318",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 8.35,
      "commitsBetweenForRepo": 42,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,88 +1,88 @@\n     void load(File curFile) throws IOException {\n       checkNotLoaded();\n       assert curFile !\u003d null : \"curFile is null\";\n \n       long startTime \u003d now();\n \n       //\n       // Load in bits\n       //\n       MessageDigest digester \u003d MD5Hash.getDigester();\n       DigestInputStream fin \u003d new DigestInputStream(\n            new FileInputStream(curFile), digester);\n \n       DataInputStream in \u003d new DataInputStream(fin);\n       try {\n         // read image version: first appeared in version -1\n         int imgVersion \u003d in.readInt();\n         if (getLayoutVersion() !\u003d imgVersion) {\n           throw new InconsistentFSStateException(curFile, \n               \"imgVersion \" + imgVersion +\n               \" expected to be \" + getLayoutVersion());\n         }\n         boolean supportSnapshot \u003d LayoutVersion.supports(Feature.SNAPSHOT,\n             imgVersion);\n \n         // read namespaceID: first appeared in version -2\n         in.readInt();\n \n         long numFiles \u003d in.readLong();\n \n         // read in the last generation stamp.\n         long genstamp \u003d in.readLong();\n         namesystem.setGenerationStamp(genstamp); \n         \n         // read the transaction ID of the last edit represented by\n         // this image\n         if (LayoutVersion.supports(Feature.STORED_TXIDS, imgVersion)) {\n           imgTxId \u003d in.readLong();\n         } else {\n           imgTxId \u003d 0;\n         }\n         \n         if (supportSnapshot) {\n-          namesystem.getSnapshotManager().read(in);\n+          snapshotMap \u003d namesystem.getSnapshotManager().read(in, this);\n         }\n \n         // read compression related info\n         FSImageCompression compression;\n         if (LayoutVersion.supports(Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n           compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n         } else {\n           compression \u003d FSImageCompression.createNoopCompression();\n         }\n         in \u003d compression.unwrapInputStream(fin);\n \n         LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n         // reset INodeId. TODO: remove this after inodeId is persisted in fsimage\n         namesystem.resetLastInodeIdWithoutChecking(INodeId.LAST_RESERVED_ID); \n         // load all inodes\n         LOG.info(\"Number of files \u003d \" + numFiles);\n         if (LayoutVersion.supports(Feature.FSIMAGE_NAME_OPTIMIZATION,\n             imgVersion)) {\n           if (supportSnapshot) {\n             loadLocalNameINodesWithSnapshot(in);\n           } else {\n             loadLocalNameINodes(numFiles, in);\n           }\n         } else {\n           loadFullNameINodes(numFiles, in);\n         }\n \n         loadFilesUnderConstruction(in, supportSnapshot);\n \n         loadSecretManagerState(in);\n \n         // make sure to read to the end of file\n         boolean eof \u003d (in.read() \u003d\u003d -1);\n         assert eof : \"Should have reached the end of image file \" + curFile;\n       } finally {\n         in.close();\n       }\n \n       imgDigest \u003d new MD5Hash(digester.digest());\n       loaded \u003d true;\n       \n       LOG.info(\"Image file of size \" + curFile.length() + \" loaded in \" \n           + (now() - startTime)/1000 + \" seconds.\");\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void load(File curFile) throws IOException {\n      checkNotLoaded();\n      assert curFile !\u003d null : \"curFile is null\";\n\n      long startTime \u003d now();\n\n      //\n      // Load in bits\n      //\n      MessageDigest digester \u003d MD5Hash.getDigester();\n      DigestInputStream fin \u003d new DigestInputStream(\n           new FileInputStream(curFile), digester);\n\n      DataInputStream in \u003d new DataInputStream(fin);\n      try {\n        // read image version: first appeared in version -1\n        int imgVersion \u003d in.readInt();\n        if (getLayoutVersion() !\u003d imgVersion) {\n          throw new InconsistentFSStateException(curFile, \n              \"imgVersion \" + imgVersion +\n              \" expected to be \" + getLayoutVersion());\n        }\n        boolean supportSnapshot \u003d LayoutVersion.supports(Feature.SNAPSHOT,\n            imgVersion);\n\n        // read namespaceID: first appeared in version -2\n        in.readInt();\n\n        long numFiles \u003d in.readLong();\n\n        // read in the last generation stamp.\n        long genstamp \u003d in.readLong();\n        namesystem.setGenerationStamp(genstamp); \n        \n        // read the transaction ID of the last edit represented by\n        // this image\n        if (LayoutVersion.supports(Feature.STORED_TXIDS, imgVersion)) {\n          imgTxId \u003d in.readLong();\n        } else {\n          imgTxId \u003d 0;\n        }\n        \n        if (supportSnapshot) {\n          snapshotMap \u003d namesystem.getSnapshotManager().read(in, this);\n        }\n\n        // read compression related info\n        FSImageCompression compression;\n        if (LayoutVersion.supports(Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n          compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n        } else {\n          compression \u003d FSImageCompression.createNoopCompression();\n        }\n        in \u003d compression.unwrapInputStream(fin);\n\n        LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n        // reset INodeId. TODO: remove this after inodeId is persisted in fsimage\n        namesystem.resetLastInodeIdWithoutChecking(INodeId.LAST_RESERVED_ID); \n        // load all inodes\n        LOG.info(\"Number of files \u003d \" + numFiles);\n        if (LayoutVersion.supports(Feature.FSIMAGE_NAME_OPTIMIZATION,\n            imgVersion)) {\n          if (supportSnapshot) {\n            loadLocalNameINodesWithSnapshot(in);\n          } else {\n            loadLocalNameINodes(numFiles, in);\n          }\n        } else {\n          loadFullNameINodes(numFiles, in);\n        }\n\n        loadFilesUnderConstruction(in, supportSnapshot);\n\n        loadSecretManagerState(in);\n\n        // make sure to read to the end of file\n        boolean eof \u003d (in.read() \u003d\u003d -1);\n        assert eof : \"Should have reached the end of image file \" + curFile;\n      } finally {\n        in.close();\n      }\n\n      imgDigest \u003d new MD5Hash(digester.digest());\n      loaded \u003d true;\n      \n      LOG.info(\"Image file of size \" + curFile.length() + \" loaded in \" \n          + (now() - startTime)/1000 + \" seconds.\");\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {}
    },
    "bcabbcdf4cf7b4bcda62d74b06c9736bc55f6fc1": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3277. fail over to loading a different FSImage if the first one we try to load is corrupt. Contributed by Colin Patrick McCabe and Andrew Wang.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1456578 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/03/13 11:04 AM",
      "commitName": "bcabbcdf4cf7b4bcda62d74b06c9736bc55f6fc1",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "11/01/13 8:57 AM",
      "commitNameOld": "bbc21ad5d491810b968c5d2a4df9f6c7a8fe29b8",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 62.05,
      "commitsBetweenForRepo": 282,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,80 +1,80 @@\n     void load(File curFile)\n       throws IOException\n     {\n       checkNotLoaded();\n       assert curFile !\u003d null : \"curFile is null\";\n \n       long startTime \u003d now();\n \n       //\n       // Load in bits\n       //\n       MessageDigest digester \u003d MD5Hash.getDigester();\n       DigestInputStream fin \u003d new DigestInputStream(\n            new FileInputStream(curFile), digester);\n \n       DataInputStream in \u003d new DataInputStream(fin);\n       try {\n         // read image version: first appeared in version -1\n         int imgVersion \u003d in.readInt();\n         if (getLayoutVersion() !\u003d imgVersion) {\n           throw new InconsistentFSStateException(curFile, \n               \"imgVersion \" + imgVersion +\n               \" expected to be \" + getLayoutVersion());\n         }\n \n         // read namespaceID: first appeared in version -2\n         in.readInt();\n \n         long numFiles \u003d in.readLong();\n \n         // read in the last generation stamp.\n         long genstamp \u003d in.readLong();\n         namesystem.setGenerationStamp(genstamp); \n         \n         // read the transaction ID of the last edit represented by\n         // this image\n         if (LayoutVersion.supports(Feature.STORED_TXIDS, imgVersion)) {\n           imgTxId \u003d in.readLong();\n         } else {\n           imgTxId \u003d 0;\n         }\n \n         // read compression related info\n         FSImageCompression compression;\n         if (LayoutVersion.supports(Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n           compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n         } else {\n           compression \u003d FSImageCompression.createNoopCompression();\n         }\n         in \u003d compression.unwrapInputStream(fin);\n \n         LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n         // reset INodeId. TODO: remove this after inodeId is persisted in fsimage\n         namesystem.resetLastInodeIdWithoutChecking(INodeId.LAST_RESERVED_ID); \n         // load all inodes\n         LOG.info(\"Number of files \u003d \" + numFiles);\n         if (LayoutVersion.supports(Feature.FSIMAGE_NAME_OPTIMIZATION,\n             imgVersion)) {\n           loadLocalNameINodes(numFiles, in);\n         } else {\n           loadFullNameINodes(numFiles, in);\n         }\n \n         loadFilesUnderConstruction(in);\n \n         loadSecretManagerState(in);\n \n         // make sure to read to the end of file\n-        int eof \u003d in.read();\n-        assert eof \u003d\u003d -1 : \"Should have reached the end of image file \" + curFile;\n+        boolean eof \u003d (in.read() \u003d\u003d -1);\n+        assert eof : \"Should have reached the end of image file \" + curFile;\n       } finally {\n         in.close();\n       }\n \n       imgDigest \u003d new MD5Hash(digester.digest());\n       loaded \u003d true;\n       \n       LOG.info(\"Image file of size \" + curFile.length() + \" loaded in \" \n           + (now() - startTime)/1000 + \" seconds.\");\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void load(File curFile)\n      throws IOException\n    {\n      checkNotLoaded();\n      assert curFile !\u003d null : \"curFile is null\";\n\n      long startTime \u003d now();\n\n      //\n      // Load in bits\n      //\n      MessageDigest digester \u003d MD5Hash.getDigester();\n      DigestInputStream fin \u003d new DigestInputStream(\n           new FileInputStream(curFile), digester);\n\n      DataInputStream in \u003d new DataInputStream(fin);\n      try {\n        // read image version: first appeared in version -1\n        int imgVersion \u003d in.readInt();\n        if (getLayoutVersion() !\u003d imgVersion) {\n          throw new InconsistentFSStateException(curFile, \n              \"imgVersion \" + imgVersion +\n              \" expected to be \" + getLayoutVersion());\n        }\n\n        // read namespaceID: first appeared in version -2\n        in.readInt();\n\n        long numFiles \u003d in.readLong();\n\n        // read in the last generation stamp.\n        long genstamp \u003d in.readLong();\n        namesystem.setGenerationStamp(genstamp); \n        \n        // read the transaction ID of the last edit represented by\n        // this image\n        if (LayoutVersion.supports(Feature.STORED_TXIDS, imgVersion)) {\n          imgTxId \u003d in.readLong();\n        } else {\n          imgTxId \u003d 0;\n        }\n\n        // read compression related info\n        FSImageCompression compression;\n        if (LayoutVersion.supports(Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n          compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n        } else {\n          compression \u003d FSImageCompression.createNoopCompression();\n        }\n        in \u003d compression.unwrapInputStream(fin);\n\n        LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n        // reset INodeId. TODO: remove this after inodeId is persisted in fsimage\n        namesystem.resetLastInodeIdWithoutChecking(INodeId.LAST_RESERVED_ID); \n        // load all inodes\n        LOG.info(\"Number of files \u003d \" + numFiles);\n        if (LayoutVersion.supports(Feature.FSIMAGE_NAME_OPTIMIZATION,\n            imgVersion)) {\n          loadLocalNameINodes(numFiles, in);\n        } else {\n          loadFullNameINodes(numFiles, in);\n        }\n\n        loadFilesUnderConstruction(in);\n\n        loadSecretManagerState(in);\n\n        // make sure to read to the end of file\n        boolean eof \u003d (in.read() \u003d\u003d -1);\n        assert eof : \"Should have reached the end of image file \" + curFile;\n      } finally {\n        in.close();\n      }\n\n      imgDigest \u003d new MD5Hash(digester.digest());\n      loaded \u003d true;\n      \n      LOG.info(\"Image file of size \" + curFile.length() + \" loaded in \" \n          + (now() - startTime)/1000 + \" seconds.\");\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {}
    },
    "5988208b7d2fa3c0378f17fe67ada99a25342829": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4432. Support INodeFileUnderConstructionWithSnapshot in FSImage saving/loading. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2802@1439682 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/01/13 2:48 PM",
      "commitName": "5988208b7d2fa3c0378f17fe67ada99a25342829",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "22/01/13 6:48 PM",
      "commitNameOld": "fe3584aadfc7839abcd03239e4d07afd12b8b90f",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 5.83,
      "commitsBetweenForRepo": 11,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,86 +1,88 @@\n     void load(File curFile) throws IOException {\n       checkNotLoaded();\n       assert curFile !\u003d null : \"curFile is null\";\n \n       long startTime \u003d now();\n \n       //\n       // Load in bits\n       //\n       MessageDigest digester \u003d MD5Hash.getDigester();\n       DigestInputStream fin \u003d new DigestInputStream(\n            new FileInputStream(curFile), digester);\n \n       DataInputStream in \u003d new DataInputStream(fin);\n       try {\n         // read image version: first appeared in version -1\n         int imgVersion \u003d in.readInt();\n         if (getLayoutVersion() !\u003d imgVersion) {\n           throw new InconsistentFSStateException(curFile, \n               \"imgVersion \" + imgVersion +\n               \" expected to be \" + getLayoutVersion());\n         }\n+        boolean supportSnapshot \u003d LayoutVersion.supports(Feature.SNAPSHOT,\n+            imgVersion);\n \n         // read namespaceID: first appeared in version -2\n         in.readInt();\n \n         long numFiles \u003d in.readLong();\n \n         // read in the last generation stamp.\n         long genstamp \u003d in.readLong();\n         namesystem.setGenerationStamp(genstamp); \n         \n         // read the transaction ID of the last edit represented by\n         // this image\n         if (LayoutVersion.supports(Feature.STORED_TXIDS, imgVersion)) {\n           imgTxId \u003d in.readLong();\n         } else {\n           imgTxId \u003d 0;\n         }\n         \n-        if (LayoutVersion.supports(Feature.SNAPSHOT, imgVersion)) {\n+        if (supportSnapshot) {\n           namesystem.getSnapshotManager().read(in);\n         }\n \n         // read compression related info\n         FSImageCompression compression;\n         if (LayoutVersion.supports(Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n           compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n         } else {\n           compression \u003d FSImageCompression.createNoopCompression();\n         }\n         in \u003d compression.unwrapInputStream(fin);\n \n         LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n         // reset INodeId. TODO: remove this after inodeId is persisted in fsimage\n         namesystem.resetLastInodeIdWithoutChecking(INodeId.LAST_RESERVED_ID); \n         // load all inodes\n         LOG.info(\"Number of files \u003d \" + numFiles);\n         if (LayoutVersion.supports(Feature.FSIMAGE_NAME_OPTIMIZATION,\n             imgVersion)) {\n-          if (LayoutVersion.supports(Feature.SNAPSHOT, imgVersion)) {\n+          if (supportSnapshot) {\n             loadLocalNameINodesWithSnapshot(in);\n           } else {\n             loadLocalNameINodes(numFiles, in);\n           }\n         } else {\n           loadFullNameINodes(numFiles, in);\n         }\n \n-        loadFilesUnderConstruction(in);\n+        loadFilesUnderConstruction(in, supportSnapshot);\n \n         loadSecretManagerState(in);\n \n         // make sure to read to the end of file\n         int eof \u003d in.read();\n         assert eof \u003d\u003d -1 : \"Should have reached the end of image file \" + curFile;\n       } finally {\n         in.close();\n       }\n \n       imgDigest \u003d new MD5Hash(digester.digest());\n       loaded \u003d true;\n       \n       LOG.info(\"Image file of size \" + curFile.length() + \" loaded in \" \n           + (now() - startTime)/1000 + \" seconds.\");\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void load(File curFile) throws IOException {\n      checkNotLoaded();\n      assert curFile !\u003d null : \"curFile is null\";\n\n      long startTime \u003d now();\n\n      //\n      // Load in bits\n      //\n      MessageDigest digester \u003d MD5Hash.getDigester();\n      DigestInputStream fin \u003d new DigestInputStream(\n           new FileInputStream(curFile), digester);\n\n      DataInputStream in \u003d new DataInputStream(fin);\n      try {\n        // read image version: first appeared in version -1\n        int imgVersion \u003d in.readInt();\n        if (getLayoutVersion() !\u003d imgVersion) {\n          throw new InconsistentFSStateException(curFile, \n              \"imgVersion \" + imgVersion +\n              \" expected to be \" + getLayoutVersion());\n        }\n        boolean supportSnapshot \u003d LayoutVersion.supports(Feature.SNAPSHOT,\n            imgVersion);\n\n        // read namespaceID: first appeared in version -2\n        in.readInt();\n\n        long numFiles \u003d in.readLong();\n\n        // read in the last generation stamp.\n        long genstamp \u003d in.readLong();\n        namesystem.setGenerationStamp(genstamp); \n        \n        // read the transaction ID of the last edit represented by\n        // this image\n        if (LayoutVersion.supports(Feature.STORED_TXIDS, imgVersion)) {\n          imgTxId \u003d in.readLong();\n        } else {\n          imgTxId \u003d 0;\n        }\n        \n        if (supportSnapshot) {\n          namesystem.getSnapshotManager().read(in);\n        }\n\n        // read compression related info\n        FSImageCompression compression;\n        if (LayoutVersion.supports(Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n          compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n        } else {\n          compression \u003d FSImageCompression.createNoopCompression();\n        }\n        in \u003d compression.unwrapInputStream(fin);\n\n        LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n        // reset INodeId. TODO: remove this after inodeId is persisted in fsimage\n        namesystem.resetLastInodeIdWithoutChecking(INodeId.LAST_RESERVED_ID); \n        // load all inodes\n        LOG.info(\"Number of files \u003d \" + numFiles);\n        if (LayoutVersion.supports(Feature.FSIMAGE_NAME_OPTIMIZATION,\n            imgVersion)) {\n          if (supportSnapshot) {\n            loadLocalNameINodesWithSnapshot(in);\n          } else {\n            loadLocalNameINodes(numFiles, in);\n          }\n        } else {\n          loadFullNameINodes(numFiles, in);\n        }\n\n        loadFilesUnderConstruction(in, supportSnapshot);\n\n        loadSecretManagerState(in);\n\n        // make sure to read to the end of file\n        int eof \u003d in.read();\n        assert eof \u003d\u003d -1 : \"Should have reached the end of image file \" + curFile;\n      } finally {\n        in.close();\n      }\n\n      imgDigest \u003d new MD5Hash(digester.digest());\n      loaded \u003d true;\n      \n      LOG.info(\"Image file of size \" + curFile.length() + \" loaded in \" \n          + (now() - startTime)/1000 + \" seconds.\");\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {}
    },
    "fe3584aadfc7839abcd03239e4d07afd12b8b90f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4126. Add reading/writing snapshot information to FSImage. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2802@1437256 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "22/01/13 6:48 PM",
      "commitName": "fe3584aadfc7839abcd03239e4d07afd12b8b90f",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "13/01/13 7:44 PM",
      "commitNameOld": "90d6d55a4bef8d5ebc130fe0be870652798d4ef6",
      "commitAuthorOld": "",
      "daysBetweenCommits": 8.96,
      "commitsBetweenForRepo": 6,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,80 +1,86 @@\n-    void load(File curFile)\n-      throws IOException\n-    {\n+    void load(File curFile) throws IOException {\n       checkNotLoaded();\n       assert curFile !\u003d null : \"curFile is null\";\n \n       long startTime \u003d now();\n \n       //\n       // Load in bits\n       //\n       MessageDigest digester \u003d MD5Hash.getDigester();\n       DigestInputStream fin \u003d new DigestInputStream(\n            new FileInputStream(curFile), digester);\n \n       DataInputStream in \u003d new DataInputStream(fin);\n       try {\n         // read image version: first appeared in version -1\n         int imgVersion \u003d in.readInt();\n         if (getLayoutVersion() !\u003d imgVersion) {\n           throw new InconsistentFSStateException(curFile, \n               \"imgVersion \" + imgVersion +\n               \" expected to be \" + getLayoutVersion());\n         }\n \n         // read namespaceID: first appeared in version -2\n         in.readInt();\n \n         long numFiles \u003d in.readLong();\n \n         // read in the last generation stamp.\n         long genstamp \u003d in.readLong();\n         namesystem.setGenerationStamp(genstamp); \n         \n         // read the transaction ID of the last edit represented by\n         // this image\n         if (LayoutVersion.supports(Feature.STORED_TXIDS, imgVersion)) {\n           imgTxId \u003d in.readLong();\n         } else {\n           imgTxId \u003d 0;\n         }\n+        \n+        if (LayoutVersion.supports(Feature.SNAPSHOT, imgVersion)) {\n+          namesystem.getSnapshotManager().read(in);\n+        }\n \n         // read compression related info\n         FSImageCompression compression;\n         if (LayoutVersion.supports(Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n           compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n         } else {\n           compression \u003d FSImageCompression.createNoopCompression();\n         }\n         in \u003d compression.unwrapInputStream(fin);\n \n         LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n         // reset INodeId. TODO: remove this after inodeId is persisted in fsimage\n         namesystem.resetLastInodeIdWithoutChecking(INodeId.LAST_RESERVED_ID); \n         // load all inodes\n         LOG.info(\"Number of files \u003d \" + numFiles);\n         if (LayoutVersion.supports(Feature.FSIMAGE_NAME_OPTIMIZATION,\n             imgVersion)) {\n-          loadLocalNameINodes(numFiles, in);\n+          if (LayoutVersion.supports(Feature.SNAPSHOT, imgVersion)) {\n+            loadLocalNameINodesWithSnapshot(in);\n+          } else {\n+            loadLocalNameINodes(numFiles, in);\n+          }\n         } else {\n           loadFullNameINodes(numFiles, in);\n         }\n \n         loadFilesUnderConstruction(in);\n \n         loadSecretManagerState(in);\n \n         // make sure to read to the end of file\n         int eof \u003d in.read();\n         assert eof \u003d\u003d -1 : \"Should have reached the end of image file \" + curFile;\n       } finally {\n         in.close();\n       }\n \n       imgDigest \u003d new MD5Hash(digester.digest());\n       loaded \u003d true;\n       \n       LOG.info(\"Image file of size \" + curFile.length() + \" loaded in \" \n           + (now() - startTime)/1000 + \" seconds.\");\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void load(File curFile) throws IOException {\n      checkNotLoaded();\n      assert curFile !\u003d null : \"curFile is null\";\n\n      long startTime \u003d now();\n\n      //\n      // Load in bits\n      //\n      MessageDigest digester \u003d MD5Hash.getDigester();\n      DigestInputStream fin \u003d new DigestInputStream(\n           new FileInputStream(curFile), digester);\n\n      DataInputStream in \u003d new DataInputStream(fin);\n      try {\n        // read image version: first appeared in version -1\n        int imgVersion \u003d in.readInt();\n        if (getLayoutVersion() !\u003d imgVersion) {\n          throw new InconsistentFSStateException(curFile, \n              \"imgVersion \" + imgVersion +\n              \" expected to be \" + getLayoutVersion());\n        }\n\n        // read namespaceID: first appeared in version -2\n        in.readInt();\n\n        long numFiles \u003d in.readLong();\n\n        // read in the last generation stamp.\n        long genstamp \u003d in.readLong();\n        namesystem.setGenerationStamp(genstamp); \n        \n        // read the transaction ID of the last edit represented by\n        // this image\n        if (LayoutVersion.supports(Feature.STORED_TXIDS, imgVersion)) {\n          imgTxId \u003d in.readLong();\n        } else {\n          imgTxId \u003d 0;\n        }\n        \n        if (LayoutVersion.supports(Feature.SNAPSHOT, imgVersion)) {\n          namesystem.getSnapshotManager().read(in);\n        }\n\n        // read compression related info\n        FSImageCompression compression;\n        if (LayoutVersion.supports(Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n          compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n        } else {\n          compression \u003d FSImageCompression.createNoopCompression();\n        }\n        in \u003d compression.unwrapInputStream(fin);\n\n        LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n        // reset INodeId. TODO: remove this after inodeId is persisted in fsimage\n        namesystem.resetLastInodeIdWithoutChecking(INodeId.LAST_RESERVED_ID); \n        // load all inodes\n        LOG.info(\"Number of files \u003d \" + numFiles);\n        if (LayoutVersion.supports(Feature.FSIMAGE_NAME_OPTIMIZATION,\n            imgVersion)) {\n          if (LayoutVersion.supports(Feature.SNAPSHOT, imgVersion)) {\n            loadLocalNameINodesWithSnapshot(in);\n          } else {\n            loadLocalNameINodes(numFiles, in);\n          }\n        } else {\n          loadFullNameINodes(numFiles, in);\n        }\n\n        loadFilesUnderConstruction(in);\n\n        loadSecretManagerState(in);\n\n        // make sure to read to the end of file\n        int eof \u003d in.read();\n        assert eof \u003d\u003d -1 : \"Should have reached the end of image file \" + curFile;\n      } finally {\n        in.close();\n      }\n\n      imgDigest \u003d new MD5Hash(digester.digest());\n      loaded \u003d true;\n      \n      LOG.info(\"Image file of size \" + curFile.length() + \" loaded in \" \n          + (now() - startTime)/1000 + \" seconds.\");\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {}
    },
    "0fa9c7a825f444d50c89b986bacea7a547e4ab8b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4334. Add a unique id to INode.  Contributed by Brandon Li\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1426429 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/12/12 12:26 AM",
      "commitName": "0fa9c7a825f444d50c89b986bacea7a547e4ab8b",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "27/11/12 2:36 PM",
      "commitNameOld": "9047eb516261b8c9c380d140a43dfdd5d701dee5",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 30.41,
      "commitsBetweenForRepo": 112,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,79 +1,80 @@\n     void load(File curFile)\n       throws IOException\n     {\n       checkNotLoaded();\n       assert curFile !\u003d null : \"curFile is null\";\n \n       long startTime \u003d now();\n \n       //\n       // Load in bits\n       //\n       MessageDigest digester \u003d MD5Hash.getDigester();\n       DigestInputStream fin \u003d new DigestInputStream(\n            new FileInputStream(curFile), digester);\n \n       DataInputStream in \u003d new DataInputStream(fin);\n       try {\n         // read image version: first appeared in version -1\n         int imgVersion \u003d in.readInt();\n         if (getLayoutVersion() !\u003d imgVersion) {\n           throw new InconsistentFSStateException(curFile, \n               \"imgVersion \" + imgVersion +\n               \" expected to be \" + getLayoutVersion());\n         }\n \n         // read namespaceID: first appeared in version -2\n         in.readInt();\n \n         long numFiles \u003d in.readLong();\n \n         // read in the last generation stamp.\n         long genstamp \u003d in.readLong();\n         namesystem.setGenerationStamp(genstamp); \n         \n         // read the transaction ID of the last edit represented by\n         // this image\n         if (LayoutVersion.supports(Feature.STORED_TXIDS, imgVersion)) {\n           imgTxId \u003d in.readLong();\n         } else {\n           imgTxId \u003d 0;\n         }\n \n         // read compression related info\n         FSImageCompression compression;\n         if (LayoutVersion.supports(Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n           compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n         } else {\n           compression \u003d FSImageCompression.createNoopCompression();\n         }\n         in \u003d compression.unwrapInputStream(fin);\n \n         LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n-\n+        // reset INodeId. TODO: remove this after inodeId is persisted in fsimage\n+        namesystem.resetLastInodeIdWithoutChecking(INodeId.LAST_RESERVED_ID); \n         // load all inodes\n         LOG.info(\"Number of files \u003d \" + numFiles);\n         if (LayoutVersion.supports(Feature.FSIMAGE_NAME_OPTIMIZATION,\n             imgVersion)) {\n           loadLocalNameINodes(numFiles, in);\n         } else {\n           loadFullNameINodes(numFiles, in);\n         }\n \n         loadFilesUnderConstruction(in);\n \n         loadSecretManagerState(in);\n \n         // make sure to read to the end of file\n         int eof \u003d in.read();\n         assert eof \u003d\u003d -1 : \"Should have reached the end of image file \" + curFile;\n       } finally {\n         in.close();\n       }\n \n       imgDigest \u003d new MD5Hash(digester.digest());\n       loaded \u003d true;\n       \n       LOG.info(\"Image file of size \" + curFile.length() + \" loaded in \" \n           + (now() - startTime)/1000 + \" seconds.\");\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void load(File curFile)\n      throws IOException\n    {\n      checkNotLoaded();\n      assert curFile !\u003d null : \"curFile is null\";\n\n      long startTime \u003d now();\n\n      //\n      // Load in bits\n      //\n      MessageDigest digester \u003d MD5Hash.getDigester();\n      DigestInputStream fin \u003d new DigestInputStream(\n           new FileInputStream(curFile), digester);\n\n      DataInputStream in \u003d new DataInputStream(fin);\n      try {\n        // read image version: first appeared in version -1\n        int imgVersion \u003d in.readInt();\n        if (getLayoutVersion() !\u003d imgVersion) {\n          throw new InconsistentFSStateException(curFile, \n              \"imgVersion \" + imgVersion +\n              \" expected to be \" + getLayoutVersion());\n        }\n\n        // read namespaceID: first appeared in version -2\n        in.readInt();\n\n        long numFiles \u003d in.readLong();\n\n        // read in the last generation stamp.\n        long genstamp \u003d in.readLong();\n        namesystem.setGenerationStamp(genstamp); \n        \n        // read the transaction ID of the last edit represented by\n        // this image\n        if (LayoutVersion.supports(Feature.STORED_TXIDS, imgVersion)) {\n          imgTxId \u003d in.readLong();\n        } else {\n          imgTxId \u003d 0;\n        }\n\n        // read compression related info\n        FSImageCompression compression;\n        if (LayoutVersion.supports(Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n          compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n        } else {\n          compression \u003d FSImageCompression.createNoopCompression();\n        }\n        in \u003d compression.unwrapInputStream(fin);\n\n        LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n        // reset INodeId. TODO: remove this after inodeId is persisted in fsimage\n        namesystem.resetLastInodeIdWithoutChecking(INodeId.LAST_RESERVED_ID); \n        // load all inodes\n        LOG.info(\"Number of files \u003d \" + numFiles);\n        if (LayoutVersion.supports(Feature.FSIMAGE_NAME_OPTIMIZATION,\n            imgVersion)) {\n          loadLocalNameINodes(numFiles, in);\n        } else {\n          loadFullNameINodes(numFiles, in);\n        }\n\n        loadFilesUnderConstruction(in);\n\n        loadSecretManagerState(in);\n\n        // make sure to read to the end of file\n        int eof \u003d in.read();\n        assert eof \u003d\u003d -1 : \"Should have reached the end of image file \" + curFile;\n      } finally {\n        in.close();\n      }\n\n      imgDigest \u003d new MD5Hash(digester.digest());\n      loaded \u003d true;\n      \n      LOG.info(\"Image file of size \" + curFile.length() + \" loaded in \" \n          + (now() - startTime)/1000 + \" seconds.\");\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {}
    },
    "64641c28b5ea8538033060452b0c45b7f2eeb60c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3137. Bump LAST_UPGRADABLE_LAYOUT_VERSION to -16. Contributed by Eli Collins\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1307173 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "29/03/12 5:11 PM",
      "commitName": "64641c28b5ea8538033060452b0c45b7f2eeb60c",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "27/10/11 3:11 PM",
      "commitNameOld": "646e855f6ef058b636a5fc85637a3f8e17fddaba",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 154.08,
      "commitsBetweenForRepo": 1071,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,96 +1,79 @@\n     void load(File curFile)\n       throws IOException\n     {\n       checkNotLoaded();\n       assert curFile !\u003d null : \"curFile is null\";\n \n       long startTime \u003d now();\n \n       //\n       // Load in bits\n       //\n       MessageDigest digester \u003d MD5Hash.getDigester();\n       DigestInputStream fin \u003d new DigestInputStream(\n            new FileInputStream(curFile), digester);\n \n       DataInputStream in \u003d new DataInputStream(fin);\n       try {\n-        /*\n-         * Note: Remove any checks for version earlier than \n-         * Storage.LAST_UPGRADABLE_LAYOUT_VERSION since we should never get \n-         * to here with older images.\n-         */\n-\n-        /*\n-         * TODO we need to change format of the image file\n-         * it should not contain version and namespace fields\n-         */\n         // read image version: first appeared in version -1\n         int imgVersion \u003d in.readInt();\n-        if(getLayoutVersion() !\u003d imgVersion)\n+        if (getLayoutVersion() !\u003d imgVersion) {\n           throw new InconsistentFSStateException(curFile, \n               \"imgVersion \" + imgVersion +\n               \" expected to be \" + getLayoutVersion());\n+        }\n \n         // read namespaceID: first appeared in version -2\n         in.readInt();\n \n-        // read number of files\n-        long numFiles \u003d readNumFiles(in);\n+        long numFiles \u003d in.readLong();\n \n         // read in the last generation stamp.\n-        if (imgVersion \u003c\u003d -12) {\n-          long genstamp \u003d in.readLong();\n-          namesystem.setGenerationStamp(genstamp); \n-        }\n+        long genstamp \u003d in.readLong();\n+        namesystem.setGenerationStamp(genstamp); \n         \n         // read the transaction ID of the last edit represented by\n         // this image\n         if (LayoutVersion.supports(Feature.STORED_TXIDS, imgVersion)) {\n           imgTxId \u003d in.readLong();\n         } else {\n           imgTxId \u003d 0;\n         }\n-        \n \n         // read compression related info\n         FSImageCompression compression;\n         if (LayoutVersion.supports(Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n           compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n         } else {\n           compression \u003d FSImageCompression.createNoopCompression();\n         }\n         in \u003d compression.unwrapInputStream(fin);\n \n         LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n \n         // load all inodes\n         LOG.info(\"Number of files \u003d \" + numFiles);\n         if (LayoutVersion.supports(Feature.FSIMAGE_NAME_OPTIMIZATION,\n             imgVersion)) {\n           loadLocalNameINodes(numFiles, in);\n         } else {\n           loadFullNameINodes(numFiles, in);\n         }\n \n-        // load datanode info\n-        this.loadDatanodes(in);\n+        loadFilesUnderConstruction(in);\n \n-        // load Files Under Construction\n-        this.loadFilesUnderConstruction(in);\n-\n-        this.loadSecretManagerState(in);\n+        loadSecretManagerState(in);\n \n         // make sure to read to the end of file\n         int eof \u003d in.read();\n         assert eof \u003d\u003d -1 : \"Should have reached the end of image file \" + curFile;\n       } finally {\n         in.close();\n       }\n \n       imgDigest \u003d new MD5Hash(digester.digest());\n       loaded \u003d true;\n       \n       LOG.info(\"Image file of size \" + curFile.length() + \" loaded in \" \n           + (now() - startTime)/1000 + \" seconds.\");\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void load(File curFile)\n      throws IOException\n    {\n      checkNotLoaded();\n      assert curFile !\u003d null : \"curFile is null\";\n\n      long startTime \u003d now();\n\n      //\n      // Load in bits\n      //\n      MessageDigest digester \u003d MD5Hash.getDigester();\n      DigestInputStream fin \u003d new DigestInputStream(\n           new FileInputStream(curFile), digester);\n\n      DataInputStream in \u003d new DataInputStream(fin);\n      try {\n        // read image version: first appeared in version -1\n        int imgVersion \u003d in.readInt();\n        if (getLayoutVersion() !\u003d imgVersion) {\n          throw new InconsistentFSStateException(curFile, \n              \"imgVersion \" + imgVersion +\n              \" expected to be \" + getLayoutVersion());\n        }\n\n        // read namespaceID: first appeared in version -2\n        in.readInt();\n\n        long numFiles \u003d in.readLong();\n\n        // read in the last generation stamp.\n        long genstamp \u003d in.readLong();\n        namesystem.setGenerationStamp(genstamp); \n        \n        // read the transaction ID of the last edit represented by\n        // this image\n        if (LayoutVersion.supports(Feature.STORED_TXIDS, imgVersion)) {\n          imgTxId \u003d in.readLong();\n        } else {\n          imgTxId \u003d 0;\n        }\n\n        // read compression related info\n        FSImageCompression compression;\n        if (LayoutVersion.supports(Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n          compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n        } else {\n          compression \u003d FSImageCompression.createNoopCompression();\n        }\n        in \u003d compression.unwrapInputStream(fin);\n\n        LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n\n        // load all inodes\n        LOG.info(\"Number of files \u003d \" + numFiles);\n        if (LayoutVersion.supports(Feature.FSIMAGE_NAME_OPTIMIZATION,\n            imgVersion)) {\n          loadLocalNameINodes(numFiles, in);\n        } else {\n          loadFullNameINodes(numFiles, in);\n        }\n\n        loadFilesUnderConstruction(in);\n\n        loadSecretManagerState(in);\n\n        // make sure to read to the end of file\n        int eof \u003d in.read();\n        assert eof \u003d\u003d -1 : \"Should have reached the end of image file \" + curFile;\n      } finally {\n        in.close();\n      }\n\n      imgDigest \u003d new MD5Hash(digester.digest());\n      loaded \u003d true;\n      \n      LOG.info(\"Image file of size \" + curFile.length() + \" loaded in \" \n          + (now() - startTime)/1000 + \" seconds.\");\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    void load(File curFile)\n      throws IOException\n    {\n      checkNotLoaded();\n      assert curFile !\u003d null : \"curFile is null\";\n\n      long startTime \u003d now();\n\n      //\n      // Load in bits\n      //\n      MessageDigest digester \u003d MD5Hash.getDigester();\n      DigestInputStream fin \u003d new DigestInputStream(\n           new FileInputStream(curFile), digester);\n\n      DataInputStream in \u003d new DataInputStream(fin);\n      try {\n        /*\n         * Note: Remove any checks for version earlier than \n         * Storage.LAST_UPGRADABLE_LAYOUT_VERSION since we should never get \n         * to here with older images.\n         */\n\n        /*\n         * TODO we need to change format of the image file\n         * it should not contain version and namespace fields\n         */\n        // read image version: first appeared in version -1\n        int imgVersion \u003d in.readInt();\n        if(getLayoutVersion() !\u003d imgVersion)\n          throw new InconsistentFSStateException(curFile, \n              \"imgVersion \" + imgVersion +\n              \" expected to be \" + getLayoutVersion());\n\n        // read namespaceID: first appeared in version -2\n        in.readInt();\n\n        // read number of files\n        long numFiles \u003d readNumFiles(in);\n\n        // read in the last generation stamp.\n        if (imgVersion \u003c\u003d -12) {\n          long genstamp \u003d in.readLong();\n          namesystem.setGenerationStamp(genstamp); \n        }\n        \n        // read the transaction ID of the last edit represented by\n        // this image\n        if (LayoutVersion.supports(Feature.STORED_TXIDS, imgVersion)) {\n          imgTxId \u003d in.readLong();\n        } else {\n          imgTxId \u003d 0;\n        }\n        \n\n        // read compression related info\n        FSImageCompression compression;\n        if (LayoutVersion.supports(Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n          compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n        } else {\n          compression \u003d FSImageCompression.createNoopCompression();\n        }\n        in \u003d compression.unwrapInputStream(fin);\n\n        LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n\n        // load all inodes\n        LOG.info(\"Number of files \u003d \" + numFiles);\n        if (LayoutVersion.supports(Feature.FSIMAGE_NAME_OPTIMIZATION,\n            imgVersion)) {\n          loadLocalNameINodes(numFiles, in);\n        } else {\n          loadFullNameINodes(numFiles, in);\n        }\n\n        // load datanode info\n        this.loadDatanodes(in);\n\n        // load Files Under Construction\n        this.loadFilesUnderConstruction(in);\n\n        this.loadSecretManagerState(in);\n\n        // make sure to read to the end of file\n        int eof \u003d in.read();\n        assert eof \u003d\u003d -1 : \"Should have reached the end of image file \" + curFile;\n      } finally {\n        in.close();\n      }\n\n      imgDigest \u003d new MD5Hash(digester.digest());\n      loaded \u003d true;\n      \n      LOG.info(\"Image file of size \" + curFile.length() + \" loaded in \" \n          + (now() - startTime)/1000 + \" seconds.\");\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    void load(File curFile)\n      throws IOException\n    {\n      checkNotLoaded();\n      assert curFile !\u003d null : \"curFile is null\";\n\n      long startTime \u003d now();\n\n      //\n      // Load in bits\n      //\n      MessageDigest digester \u003d MD5Hash.getDigester();\n      DigestInputStream fin \u003d new DigestInputStream(\n           new FileInputStream(curFile), digester);\n\n      DataInputStream in \u003d new DataInputStream(fin);\n      try {\n        /*\n         * Note: Remove any checks for version earlier than \n         * Storage.LAST_UPGRADABLE_LAYOUT_VERSION since we should never get \n         * to here with older images.\n         */\n\n        /*\n         * TODO we need to change format of the image file\n         * it should not contain version and namespace fields\n         */\n        // read image version: first appeared in version -1\n        int imgVersion \u003d in.readInt();\n        if(getLayoutVersion() !\u003d imgVersion)\n          throw new InconsistentFSStateException(curFile, \n              \"imgVersion \" + imgVersion +\n              \" expected to be \" + getLayoutVersion());\n\n        // read namespaceID: first appeared in version -2\n        in.readInt();\n\n        // read number of files\n        long numFiles \u003d readNumFiles(in);\n\n        // read in the last generation stamp.\n        if (imgVersion \u003c\u003d -12) {\n          long genstamp \u003d in.readLong();\n          namesystem.setGenerationStamp(genstamp); \n        }\n        \n        // read the transaction ID of the last edit represented by\n        // this image\n        if (LayoutVersion.supports(Feature.STORED_TXIDS, imgVersion)) {\n          imgTxId \u003d in.readLong();\n        } else {\n          imgTxId \u003d 0;\n        }\n        \n\n        // read compression related info\n        FSImageCompression compression;\n        if (LayoutVersion.supports(Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n          compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n        } else {\n          compression \u003d FSImageCompression.createNoopCompression();\n        }\n        in \u003d compression.unwrapInputStream(fin);\n\n        LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n\n        // load all inodes\n        LOG.info(\"Number of files \u003d \" + numFiles);\n        if (LayoutVersion.supports(Feature.FSIMAGE_NAME_OPTIMIZATION,\n            imgVersion)) {\n          loadLocalNameINodes(numFiles, in);\n        } else {\n          loadFullNameINodes(numFiles, in);\n        }\n\n        // load datanode info\n        this.loadDatanodes(in);\n\n        // load Files Under Construction\n        this.loadFilesUnderConstruction(in);\n\n        this.loadSecretManagerState(in);\n\n        // make sure to read to the end of file\n        int eof \u003d in.read();\n        assert eof \u003d\u003d -1 : \"Should have reached the end of image file \" + curFile;\n      } finally {\n        in.close();\n      }\n\n      imgDigest \u003d new MD5Hash(digester.digest());\n      loaded \u003d true;\n      \n      LOG.info(\"Image file of size \" + curFile.length() + \" loaded in \" \n          + (now() - startTime)/1000 + \" seconds.\");\n    }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java"
      }
    },
    "28e6a4e44a3e920dcaf858f9a74a6358226b3a63": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-1073. Redesign the NameNode\u0027s storage layout for image checkpoints and edit logs to introduce transaction IDs and be more robust. Contributed by Todd Lipcon and Ivan Kelly.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1152295 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "29/07/11 9:28 AM",
      "commitName": "28e6a4e44a3e920dcaf858f9a74a6358226b3a63",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "28/06/11 6:31 PM",
      "commitNameOld": "09b6f98de431628c80bc8a6faf0070eeaf72ff2a",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 30.62,
      "commitsBetweenForRepo": 109,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,83 +1,96 @@\n     void load(File curFile)\n       throws IOException\n     {\n       checkNotLoaded();\n       assert curFile !\u003d null : \"curFile is null\";\n \n       long startTime \u003d now();\n \n       //\n       // Load in bits\n       //\n       MessageDigest digester \u003d MD5Hash.getDigester();\n       DigestInputStream fin \u003d new DigestInputStream(\n            new FileInputStream(curFile), digester);\n \n       DataInputStream in \u003d new DataInputStream(fin);\n       try {\n         /*\n          * Note: Remove any checks for version earlier than \n          * Storage.LAST_UPGRADABLE_LAYOUT_VERSION since we should never get \n          * to here with older images.\n          */\n \n         /*\n          * TODO we need to change format of the image file\n          * it should not contain version and namespace fields\n          */\n         // read image version: first appeared in version -1\n-        imgVersion \u003d in.readInt();\n+        int imgVersion \u003d in.readInt();\n+        if(getLayoutVersion() !\u003d imgVersion)\n+          throw new InconsistentFSStateException(curFile, \n+              \"imgVersion \" + imgVersion +\n+              \" expected to be \" + getLayoutVersion());\n \n         // read namespaceID: first appeared in version -2\n-        imgNamespaceID \u003d in.readInt();\n+        in.readInt();\n \n         // read number of files\n         long numFiles \u003d readNumFiles(in);\n \n         // read in the last generation stamp.\n         if (imgVersion \u003c\u003d -12) {\n           long genstamp \u003d in.readLong();\n           namesystem.setGenerationStamp(genstamp); \n         }\n+        \n+        // read the transaction ID of the last edit represented by\n+        // this image\n+        if (LayoutVersion.supports(Feature.STORED_TXIDS, imgVersion)) {\n+          imgTxId \u003d in.readLong();\n+        } else {\n+          imgTxId \u003d 0;\n+        }\n+        \n \n         // read compression related info\n         FSImageCompression compression;\n         if (LayoutVersion.supports(Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n           compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n         } else {\n           compression \u003d FSImageCompression.createNoopCompression();\n         }\n         in \u003d compression.unwrapInputStream(fin);\n \n         LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n \n         // load all inodes\n         LOG.info(\"Number of files \u003d \" + numFiles);\n         if (LayoutVersion.supports(Feature.FSIMAGE_NAME_OPTIMIZATION,\n             imgVersion)) {\n           loadLocalNameINodes(numFiles, in);\n         } else {\n           loadFullNameINodes(numFiles, in);\n         }\n \n         // load datanode info\n         this.loadDatanodes(in);\n \n         // load Files Under Construction\n         this.loadFilesUnderConstruction(in);\n \n         this.loadSecretManagerState(in);\n \n         // make sure to read to the end of file\n         int eof \u003d in.read();\n         assert eof \u003d\u003d -1 : \"Should have reached the end of image file \" + curFile;\n       } finally {\n         in.close();\n       }\n \n       imgDigest \u003d new MD5Hash(digester.digest());\n       loaded \u003d true;\n       \n       LOG.info(\"Image file of size \" + curFile.length() + \" loaded in \" \n           + (now() - startTime)/1000 + \" seconds.\");\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void load(File curFile)\n      throws IOException\n    {\n      checkNotLoaded();\n      assert curFile !\u003d null : \"curFile is null\";\n\n      long startTime \u003d now();\n\n      //\n      // Load in bits\n      //\n      MessageDigest digester \u003d MD5Hash.getDigester();\n      DigestInputStream fin \u003d new DigestInputStream(\n           new FileInputStream(curFile), digester);\n\n      DataInputStream in \u003d new DataInputStream(fin);\n      try {\n        /*\n         * Note: Remove any checks for version earlier than \n         * Storage.LAST_UPGRADABLE_LAYOUT_VERSION since we should never get \n         * to here with older images.\n         */\n\n        /*\n         * TODO we need to change format of the image file\n         * it should not contain version and namespace fields\n         */\n        // read image version: first appeared in version -1\n        int imgVersion \u003d in.readInt();\n        if(getLayoutVersion() !\u003d imgVersion)\n          throw new InconsistentFSStateException(curFile, \n              \"imgVersion \" + imgVersion +\n              \" expected to be \" + getLayoutVersion());\n\n        // read namespaceID: first appeared in version -2\n        in.readInt();\n\n        // read number of files\n        long numFiles \u003d readNumFiles(in);\n\n        // read in the last generation stamp.\n        if (imgVersion \u003c\u003d -12) {\n          long genstamp \u003d in.readLong();\n          namesystem.setGenerationStamp(genstamp); \n        }\n        \n        // read the transaction ID of the last edit represented by\n        // this image\n        if (LayoutVersion.supports(Feature.STORED_TXIDS, imgVersion)) {\n          imgTxId \u003d in.readLong();\n        } else {\n          imgTxId \u003d 0;\n        }\n        \n\n        // read compression related info\n        FSImageCompression compression;\n        if (LayoutVersion.supports(Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n          compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n        } else {\n          compression \u003d FSImageCompression.createNoopCompression();\n        }\n        in \u003d compression.unwrapInputStream(fin);\n\n        LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n\n        // load all inodes\n        LOG.info(\"Number of files \u003d \" + numFiles);\n        if (LayoutVersion.supports(Feature.FSIMAGE_NAME_OPTIMIZATION,\n            imgVersion)) {\n          loadLocalNameINodes(numFiles, in);\n        } else {\n          loadFullNameINodes(numFiles, in);\n        }\n\n        // load datanode info\n        this.loadDatanodes(in);\n\n        // load Files Under Construction\n        this.loadFilesUnderConstruction(in);\n\n        this.loadSecretManagerState(in);\n\n        // make sure to read to the end of file\n        int eof \u003d in.read();\n        assert eof \u003d\u003d -1 : \"Should have reached the end of image file \" + curFile;\n      } finally {\n        in.close();\n      }\n\n      imgDigest \u003d new MD5Hash(digester.digest());\n      loaded \u003d true;\n      \n      LOG.info(\"Image file of size \" + curFile.length() + \" loaded in \" \n          + (now() - startTime)/1000 + \" seconds.\");\n    }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {}
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,83 @@\n+    void load(File curFile)\n+      throws IOException\n+    {\n+      checkNotLoaded();\n+      assert curFile !\u003d null : \"curFile is null\";\n+\n+      long startTime \u003d now();\n+\n+      //\n+      // Load in bits\n+      //\n+      MessageDigest digester \u003d MD5Hash.getDigester();\n+      DigestInputStream fin \u003d new DigestInputStream(\n+           new FileInputStream(curFile), digester);\n+\n+      DataInputStream in \u003d new DataInputStream(fin);\n+      try {\n+        /*\n+         * Note: Remove any checks for version earlier than \n+         * Storage.LAST_UPGRADABLE_LAYOUT_VERSION since we should never get \n+         * to here with older images.\n+         */\n+\n+        /*\n+         * TODO we need to change format of the image file\n+         * it should not contain version and namespace fields\n+         */\n+        // read image version: first appeared in version -1\n+        imgVersion \u003d in.readInt();\n+\n+        // read namespaceID: first appeared in version -2\n+        imgNamespaceID \u003d in.readInt();\n+\n+        // read number of files\n+        long numFiles \u003d readNumFiles(in);\n+\n+        // read in the last generation stamp.\n+        if (imgVersion \u003c\u003d -12) {\n+          long genstamp \u003d in.readLong();\n+          namesystem.setGenerationStamp(genstamp); \n+        }\n+\n+        // read compression related info\n+        FSImageCompression compression;\n+        if (LayoutVersion.supports(Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n+          compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n+        } else {\n+          compression \u003d FSImageCompression.createNoopCompression();\n+        }\n+        in \u003d compression.unwrapInputStream(fin);\n+\n+        LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n+\n+        // load all inodes\n+        LOG.info(\"Number of files \u003d \" + numFiles);\n+        if (LayoutVersion.supports(Feature.FSIMAGE_NAME_OPTIMIZATION,\n+            imgVersion)) {\n+          loadLocalNameINodes(numFiles, in);\n+        } else {\n+          loadFullNameINodes(numFiles, in);\n+        }\n+\n+        // load datanode info\n+        this.loadDatanodes(in);\n+\n+        // load Files Under Construction\n+        this.loadFilesUnderConstruction(in);\n+\n+        this.loadSecretManagerState(in);\n+\n+        // make sure to read to the end of file\n+        int eof \u003d in.read();\n+        assert eof \u003d\u003d -1 : \"Should have reached the end of image file \" + curFile;\n+      } finally {\n+        in.close();\n+      }\n+\n+      imgDigest \u003d new MD5Hash(digester.digest());\n+      loaded \u003d true;\n+      \n+      LOG.info(\"Image file of size \" + curFile.length() + \" loaded in \" \n+          + (now() - startTime)/1000 + \" seconds.\");\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    void load(File curFile)\n      throws IOException\n    {\n      checkNotLoaded();\n      assert curFile !\u003d null : \"curFile is null\";\n\n      long startTime \u003d now();\n\n      //\n      // Load in bits\n      //\n      MessageDigest digester \u003d MD5Hash.getDigester();\n      DigestInputStream fin \u003d new DigestInputStream(\n           new FileInputStream(curFile), digester);\n\n      DataInputStream in \u003d new DataInputStream(fin);\n      try {\n        /*\n         * Note: Remove any checks for version earlier than \n         * Storage.LAST_UPGRADABLE_LAYOUT_VERSION since we should never get \n         * to here with older images.\n         */\n\n        /*\n         * TODO we need to change format of the image file\n         * it should not contain version and namespace fields\n         */\n        // read image version: first appeared in version -1\n        imgVersion \u003d in.readInt();\n\n        // read namespaceID: first appeared in version -2\n        imgNamespaceID \u003d in.readInt();\n\n        // read number of files\n        long numFiles \u003d readNumFiles(in);\n\n        // read in the last generation stamp.\n        if (imgVersion \u003c\u003d -12) {\n          long genstamp \u003d in.readLong();\n          namesystem.setGenerationStamp(genstamp); \n        }\n\n        // read compression related info\n        FSImageCompression compression;\n        if (LayoutVersion.supports(Feature.FSIMAGE_COMPRESSION, imgVersion)) {\n          compression \u003d FSImageCompression.readCompressionHeader(conf, in);\n        } else {\n          compression \u003d FSImageCompression.createNoopCompression();\n        }\n        in \u003d compression.unwrapInputStream(fin);\n\n        LOG.info(\"Loading image file \" + curFile + \" using \" + compression);\n\n        // load all inodes\n        LOG.info(\"Number of files \u003d \" + numFiles);\n        if (LayoutVersion.supports(Feature.FSIMAGE_NAME_OPTIMIZATION,\n            imgVersion)) {\n          loadLocalNameINodes(numFiles, in);\n        } else {\n          loadFullNameINodes(numFiles, in);\n        }\n\n        // load datanode info\n        this.loadDatanodes(in);\n\n        // load Files Under Construction\n        this.loadFilesUnderConstruction(in);\n\n        this.loadSecretManagerState(in);\n\n        // make sure to read to the end of file\n        int eof \u003d in.read();\n        assert eof \u003d\u003d -1 : \"Should have reached the end of image file \" + curFile;\n      } finally {\n        in.close();\n      }\n\n      imgDigest \u003d new MD5Hash(digester.digest());\n      loaded \u003d true;\n      \n      LOG.info(\"Image file of size \" + curFile.length() + \" loaded in \" \n          + (now() - startTime)/1000 + \" seconds.\");\n    }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java"
    }
  }
}