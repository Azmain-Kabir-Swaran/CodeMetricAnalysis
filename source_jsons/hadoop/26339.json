{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "MRAppMaster.java",
  "functionName": "createJob",
  "functionId": "createJob___conf-Configuration__forcedState-JobStateInternal__diagnostic-String",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/MRAppMaster.java",
  "functionStartLine": 765,
  "functionEndLine": 781,
  "numCommitsSeen": 172,
  "timeTaken": 9147,
  "changeHistory": [
    "b64572b06b1282128180b9ebdd971f9b1e973e61",
    "6a1c41111edcdc58c846fc50e53554fbba230171",
    "64e4fb983e022d8d3375a3e1b8facbf95f7ba403",
    "402eb1851341fce72c8e46266a2578bb67b5b684",
    "c3a4de0ec0389064f5468180d1b9024f64b00f40",
    "408656614495674992349fbda3981559ada3de0b",
    "13e4562924a6cb3d16c262e0f595b2ffbf9e0546",
    "51a667bef8300d6499c9867b50eee352311a4185",
    "fa2529c9317b2f27dec16411b99f296904ea095d",
    "c9a7d3dbf902244902b636bf566154c09ecd1116",
    "d00b3c49f6fb3f6a617add6203c6b55f6c345940",
    "61900651b1b85cf235e01142acf2a51727fc5537",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "7c8fcbecf14b2e24d54ccb276bb684fdbe62b669",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517"
  ],
  "changeHistoryShort": {
    "b64572b06b1282128180b9ebdd971f9b1e973e61": "Ybodychange",
    "6a1c41111edcdc58c846fc50e53554fbba230171": "Ybodychange",
    "64e4fb983e022d8d3375a3e1b8facbf95f7ba403": "Ymultichange(Yparameterchange,Ybodychange)",
    "402eb1851341fce72c8e46266a2578bb67b5b684": "Ybodychange",
    "c3a4de0ec0389064f5468180d1b9024f64b00f40": "Ybodychange",
    "408656614495674992349fbda3981559ada3de0b": "Ybodychange",
    "13e4562924a6cb3d16c262e0f595b2ffbf9e0546": "Ybodychange",
    "51a667bef8300d6499c9867b50eee352311a4185": "Ybodychange",
    "fa2529c9317b2f27dec16411b99f296904ea095d": "Ybodychange",
    "c9a7d3dbf902244902b636bf566154c09ecd1116": "Ybodychange",
    "d00b3c49f6fb3f6a617add6203c6b55f6c345940": "Ybodychange",
    "61900651b1b85cf235e01142acf2a51727fc5537": "Ymultichange(Yparameterchange,Ybodychange)",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "7c8fcbecf14b2e24d54ccb276bb684fdbe62b669": "Ymultichange(Yparameterchange,Ybodychange)",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yintroduced"
  },
  "changeHistoryDetails": {
    "b64572b06b1282128180b9ebdd971f9b1e973e61": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5199. Removing ApplicationTokens file as it is no longer needed. Contributed by Daryn Sharp.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1492848 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/06/13 1:20 PM",
      "commitName": "b64572b06b1282128180b9ebdd971f9b1e973e61",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "13/06/13 8:54 AM",
      "commitNameOld": "0928502029ef141759008997335ea2cd836a7154",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 0.18,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,17 @@\n   protected Job createJob(Configuration conf, JobStateInternal forcedState, \n       String diagnostic) {\n \n     // create single job\n     Job newJob \u003d\n         new JobImpl(jobId, appAttemptID, conf, dispatcher.getEventHandler(),\n-            taskAttemptListener, jobTokenSecretManager, fsTokens, clock,\n+            taskAttemptListener, jobTokenSecretManager, jobCredentials, clock,\n             completedTasksFromPreviousRun, metrics,\n             committer, newApiCommitter,\n             currentUser.getUserName(), appSubmitTime, amInfos, context, \n             forcedState, diagnostic);\n     ((RunningAppContext) context).jobs.put(newJob.getID(), newJob);\n \n     dispatcher.register(JobFinishEvent.Type.class,\n         createJobFinishEventHandler());     \n     return newJob;\n   } // end createJob()\n\\ No newline at end of file\n",
      "actualSource": "  protected Job createJob(Configuration conf, JobStateInternal forcedState, \n      String diagnostic) {\n\n    // create single job\n    Job newJob \u003d\n        new JobImpl(jobId, appAttemptID, conf, dispatcher.getEventHandler(),\n            taskAttemptListener, jobTokenSecretManager, jobCredentials, clock,\n            completedTasksFromPreviousRun, metrics,\n            committer, newApiCommitter,\n            currentUser.getUserName(), appSubmitTime, amInfos, context, \n            forcedState, diagnostic);\n    ((RunningAppContext) context).jobs.put(newJob.getID(), newJob);\n\n    dispatcher.register(JobFinishEvent.Type.class,\n        createJobFinishEventHandler());     \n    return newJob;\n  } // end createJob()",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/MRAppMaster.java",
      "extendedDetails": {}
    },
    "6a1c41111edcdc58c846fc50e53554fbba230171": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5079. Changes job recovery to restore state directly from job history, instaed of simulating state machine events. Contributed by Jason Lowe and Robert Parker.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1466767 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/04/13 9:52 PM",
      "commitName": "6a1c41111edcdc58c846fc50e53554fbba230171",
      "commitAuthor": "Siddharth Seth",
      "commitDateOld": "03/04/13 6:56 PM",
      "commitNameOld": "fc75d3f3dc2733d6c783eb4d4f1c5c6ae680f08e",
      "commitAuthorOld": "Jason Darrell Lowe",
      "daysBetweenCommits": 7.12,
      "commitsBetweenForRepo": 36,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,17 @@\n   protected Job createJob(Configuration conf, JobStateInternal forcedState, \n       String diagnostic) {\n \n     // create single job\n     Job newJob \u003d\n         new JobImpl(jobId, appAttemptID, conf, dispatcher.getEventHandler(),\n             taskAttemptListener, jobTokenSecretManager, fsTokens, clock,\n-            completedTasksFromPreviousRun, metrics, newApiCommitter,\n+            completedTasksFromPreviousRun, metrics,\n+            committer, newApiCommitter,\n             currentUser.getUserName(), appSubmitTime, amInfos, context, \n             forcedState, diagnostic);\n     ((RunningAppContext) context).jobs.put(newJob.getID(), newJob);\n \n     dispatcher.register(JobFinishEvent.Type.class,\n         createJobFinishEventHandler());     \n     return newJob;\n   } // end createJob()\n\\ No newline at end of file\n",
      "actualSource": "  protected Job createJob(Configuration conf, JobStateInternal forcedState, \n      String diagnostic) {\n\n    // create single job\n    Job newJob \u003d\n        new JobImpl(jobId, appAttemptID, conf, dispatcher.getEventHandler(),\n            taskAttemptListener, jobTokenSecretManager, fsTokens, clock,\n            completedTasksFromPreviousRun, metrics,\n            committer, newApiCommitter,\n            currentUser.getUserName(), appSubmitTime, amInfos, context, \n            forcedState, diagnostic);\n    ((RunningAppContext) context).jobs.put(newJob.getID(), newJob);\n\n    dispatcher.register(JobFinishEvent.Type.class,\n        createJobFinishEventHandler());     \n    return newJob;\n  } // end createJob()",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/MRAppMaster.java",
      "extendedDetails": {}
    },
    "64e4fb983e022d8d3375a3e1b8facbf95f7ba403": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "MAPREDUCE-4819. AM can rerun job after reporting final job status to the client (bobby and Bikas Saha via bobby)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1429114 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/01/13 12:35 PM",
      "commitName": "64e4fb983e022d8d3375a3e1b8facbf95f7ba403",
      "commitAuthor": "Robert Joseph Evans",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "MAPREDUCE-4819. AM can rerun job after reporting final job status to the client (bobby and Bikas Saha via bobby)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1429114 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "04/01/13 12:35 PM",
          "commitName": "64e4fb983e022d8d3375a3e1b8facbf95f7ba403",
          "commitAuthor": "Robert Joseph Evans",
          "commitDateOld": "04/01/13 11:15 AM",
          "commitNameOld": "78ab699fe93cafbaff8f496be53d26aff40a68b1",
          "commitAuthorOld": "Jason Darrell Lowe",
          "daysBetweenCommits": 0.06,
          "commitsBetweenForRepo": 3,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,14 +1,16 @@\n-  protected Job createJob(Configuration conf) {\n+  protected Job createJob(Configuration conf, JobStateInternal forcedState, \n+      String diagnostic) {\n \n     // create single job\n     Job newJob \u003d\n         new JobImpl(jobId, appAttemptID, conf, dispatcher.getEventHandler(),\n             taskAttemptListener, jobTokenSecretManager, fsTokens, clock,\n             completedTasksFromPreviousRun, metrics, newApiCommitter,\n-            currentUser.getUserName(), appSubmitTime, amInfos, context);\n+            currentUser.getUserName(), appSubmitTime, amInfos, context, \n+            forcedState, diagnostic);\n     ((RunningAppContext) context).jobs.put(newJob.getID(), newJob);\n \n     dispatcher.register(JobFinishEvent.Type.class,\n         createJobFinishEventHandler());     \n     return newJob;\n   } // end createJob()\n\\ No newline at end of file\n",
          "actualSource": "  protected Job createJob(Configuration conf, JobStateInternal forcedState, \n      String diagnostic) {\n\n    // create single job\n    Job newJob \u003d\n        new JobImpl(jobId, appAttemptID, conf, dispatcher.getEventHandler(),\n            taskAttemptListener, jobTokenSecretManager, fsTokens, clock,\n            completedTasksFromPreviousRun, metrics, newApiCommitter,\n            currentUser.getUserName(), appSubmitTime, amInfos, context, \n            forcedState, diagnostic);\n    ((RunningAppContext) context).jobs.put(newJob.getID(), newJob);\n\n    dispatcher.register(JobFinishEvent.Type.class,\n        createJobFinishEventHandler());     \n    return newJob;\n  } // end createJob()",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/MRAppMaster.java",
          "extendedDetails": {
            "oldValue": "[conf-Configuration]",
            "newValue": "[conf-Configuration, forcedState-JobStateInternal, diagnostic-String]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "MAPREDUCE-4819. AM can rerun job after reporting final job status to the client (bobby and Bikas Saha via bobby)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1429114 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "04/01/13 12:35 PM",
          "commitName": "64e4fb983e022d8d3375a3e1b8facbf95f7ba403",
          "commitAuthor": "Robert Joseph Evans",
          "commitDateOld": "04/01/13 11:15 AM",
          "commitNameOld": "78ab699fe93cafbaff8f496be53d26aff40a68b1",
          "commitAuthorOld": "Jason Darrell Lowe",
          "daysBetweenCommits": 0.06,
          "commitsBetweenForRepo": 3,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,14 +1,16 @@\n-  protected Job createJob(Configuration conf) {\n+  protected Job createJob(Configuration conf, JobStateInternal forcedState, \n+      String diagnostic) {\n \n     // create single job\n     Job newJob \u003d\n         new JobImpl(jobId, appAttemptID, conf, dispatcher.getEventHandler(),\n             taskAttemptListener, jobTokenSecretManager, fsTokens, clock,\n             completedTasksFromPreviousRun, metrics, newApiCommitter,\n-            currentUser.getUserName(), appSubmitTime, amInfos, context);\n+            currentUser.getUserName(), appSubmitTime, amInfos, context, \n+            forcedState, diagnostic);\n     ((RunningAppContext) context).jobs.put(newJob.getID(), newJob);\n \n     dispatcher.register(JobFinishEvent.Type.class,\n         createJobFinishEventHandler());     \n     return newJob;\n   } // end createJob()\n\\ No newline at end of file\n",
          "actualSource": "  protected Job createJob(Configuration conf, JobStateInternal forcedState, \n      String diagnostic) {\n\n    // create single job\n    Job newJob \u003d\n        new JobImpl(jobId, appAttemptID, conf, dispatcher.getEventHandler(),\n            taskAttemptListener, jobTokenSecretManager, fsTokens, clock,\n            completedTasksFromPreviousRun, metrics, newApiCommitter,\n            currentUser.getUserName(), appSubmitTime, amInfos, context, \n            forcedState, diagnostic);\n    ((RunningAppContext) context).jobs.put(newJob.getID(), newJob);\n\n    dispatcher.register(JobFinishEvent.Type.class,\n        createJobFinishEventHandler());     \n    return newJob;\n  } // end createJob()",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/MRAppMaster.java",
          "extendedDetails": {}
        }
      ]
    },
    "402eb1851341fce72c8e46266a2578bb67b5b684": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4813. AM timing out during job commit (jlowe via bobby)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1426536 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/12/12 7:01 AM",
      "commitName": "402eb1851341fce72c8e46266a2578bb67b5b684",
      "commitAuthor": "Robert Joseph Evans",
      "commitDateOld": "01/11/12 3:59 PM",
      "commitNameOld": "42d1eaf237ef0a3a30c061888d35329b2a2e1453",
      "commitAuthorOld": "Jason Darrell Lowe",
      "daysBetweenCommits": 56.67,
      "commitsBetweenForRepo": 239,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,14 @@\n   protected Job createJob(Configuration conf) {\n \n     // create single job\n     Job newJob \u003d\n         new JobImpl(jobId, appAttemptID, conf, dispatcher.getEventHandler(),\n             taskAttemptListener, jobTokenSecretManager, fsTokens, clock,\n-            completedTasksFromPreviousRun, metrics, committer, newApiCommitter,\n+            completedTasksFromPreviousRun, metrics, newApiCommitter,\n             currentUser.getUserName(), appSubmitTime, amInfos, context);\n     ((RunningAppContext) context).jobs.put(newJob.getID(), newJob);\n \n     dispatcher.register(JobFinishEvent.Type.class,\n         createJobFinishEventHandler());     \n     return newJob;\n   } // end createJob()\n\\ No newline at end of file\n",
      "actualSource": "  protected Job createJob(Configuration conf) {\n\n    // create single job\n    Job newJob \u003d\n        new JobImpl(jobId, appAttemptID, conf, dispatcher.getEventHandler(),\n            taskAttemptListener, jobTokenSecretManager, fsTokens, clock,\n            completedTasksFromPreviousRun, metrics, newApiCommitter,\n            currentUser.getUserName(), appSubmitTime, amInfos, context);\n    ((RunningAppContext) context).jobs.put(newJob.getID(), newJob);\n\n    dispatcher.register(JobFinishEvent.Type.class,\n        createJobFinishEventHandler());     \n    return newJob;\n  } // end createJob()",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/MRAppMaster.java",
      "extendedDetails": {}
    },
    "c3a4de0ec0389064f5468180d1b9024f64b00f40": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3961. Map/ReduceSlotMillis computation incorrect (Siddharth Seth via bobby)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1297788 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "06/03/12 3:21 PM",
      "commitName": "c3a4de0ec0389064f5468180d1b9024f64b00f40",
      "commitAuthor": "Robert Joseph Evans",
      "commitDateOld": "03/03/12 9:23 PM",
      "commitNameOld": "5f52156aa2389e8583a699fb3ba7b78250390154",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 2.75,
      "commitsBetweenForRepo": 21,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,14 @@\n   protected Job createJob(Configuration conf) {\n \n     // create single job\n-    Job newJob \u003d new JobImpl(jobId, appAttemptID, conf, dispatcher\n-        .getEventHandler(), taskAttemptListener, jobTokenSecretManager,\n-        fsTokens, clock, completedTasksFromPreviousRun, metrics, committer,\n-        newApiCommitter, currentUser.getUserName(), appSubmitTime, amInfos);\n+    Job newJob \u003d\n+        new JobImpl(jobId, appAttemptID, conf, dispatcher.getEventHandler(),\n+            taskAttemptListener, jobTokenSecretManager, fsTokens, clock,\n+            completedTasksFromPreviousRun, metrics, committer, newApiCommitter,\n+            currentUser.getUserName(), appSubmitTime, amInfos, context);\n     ((RunningAppContext) context).jobs.put(newJob.getID(), newJob);\n \n     dispatcher.register(JobFinishEvent.Type.class,\n         createJobFinishEventHandler());     \n     return newJob;\n   } // end createJob()\n\\ No newline at end of file\n",
      "actualSource": "  protected Job createJob(Configuration conf) {\n\n    // create single job\n    Job newJob \u003d\n        new JobImpl(jobId, appAttemptID, conf, dispatcher.getEventHandler(),\n            taskAttemptListener, jobTokenSecretManager, fsTokens, clock,\n            completedTasksFromPreviousRun, metrics, committer, newApiCommitter,\n            currentUser.getUserName(), appSubmitTime, amInfos, context);\n    ((RunningAppContext) context).jobs.put(newJob.getID(), newJob);\n\n    dispatcher.register(JobFinishEvent.Type.class,\n        createJobFinishEventHandler());     \n    return newJob;\n  } // end createJob()",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/MRAppMaster.java",
      "extendedDetails": {}
    },
    "408656614495674992349fbda3981559ada3de0b": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-2708. Designed and implemented MR Application Master recovery to make MR AMs resume their progress after restart. Contributed by Sharad Agarwal.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1188043 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/10/11 1:41 AM",
      "commitName": "408656614495674992349fbda3981559ada3de0b",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "18/10/11 10:21 PM",
      "commitNameOld": "13e4562924a6cb3d16c262e0f595b2ffbf9e0546",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 5.14,
      "commitsBetweenForRepo": 38,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,13 @@\n   protected Job createJob(Configuration conf) {\n \n     // create single job\n-    Job newJob \u003d new JobImpl(appAttemptID, conf, dispatcher.getEventHandler(),\n-        taskAttemptListener, jobTokenSecretManager, fsTokens, clock,\n-        completedTasksFromPreviousRun, metrics, currentUser.getUserName(),\n-        appSubmitTime, amInfos);\n+    Job newJob \u003d new JobImpl(jobId, appAttemptID, conf, dispatcher\n+        .getEventHandler(), taskAttemptListener, jobTokenSecretManager,\n+        fsTokens, clock, completedTasksFromPreviousRun, metrics, committer,\n+        newApiCommitter, currentUser.getUserName(), appSubmitTime, amInfos);\n     ((RunningAppContext) context).jobs.put(newJob.getID(), newJob);\n \n     dispatcher.register(JobFinishEvent.Type.class,\n         createJobFinishEventHandler());     \n     return newJob;\n   } // end createJob()\n\\ No newline at end of file\n",
      "actualSource": "  protected Job createJob(Configuration conf) {\n\n    // create single job\n    Job newJob \u003d new JobImpl(jobId, appAttemptID, conf, dispatcher\n        .getEventHandler(), taskAttemptListener, jobTokenSecretManager,\n        fsTokens, clock, completedTasksFromPreviousRun, metrics, committer,\n        newApiCommitter, currentUser.getUserName(), appSubmitTime, amInfos);\n    ((RunningAppContext) context).jobs.put(newJob.getID(), newJob);\n\n    dispatcher.register(JobFinishEvent.Type.class,\n        createJobFinishEventHandler());     \n    return newJob;\n  } // end createJob()",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/MRAppMaster.java",
      "extendedDetails": {}
    },
    "13e4562924a6cb3d16c262e0f595b2ffbf9e0546": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3144. Augmented JobHistory with the information needed for serving aggregated logs. Contributed by Siddharth Seth.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1185976 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/10/11 10:21 PM",
      "commitName": "13e4562924a6cb3d16c262e0f595b2ffbf9e0546",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "18/10/11 3:46 PM",
      "commitNameOld": "b4d20c707af6fe8b9b3e5ffa95a88012a1cdfc17",
      "commitAuthorOld": "Mahadev Konar",
      "daysBetweenCommits": 0.27,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,13 @@\n   protected Job createJob(Configuration conf) {\n \n     // create single job\n     Job newJob \u003d new JobImpl(appAttemptID, conf, dispatcher.getEventHandler(),\n         taskAttemptListener, jobTokenSecretManager, fsTokens, clock,\n-        completedTasksFromPreviousRun, metrics, currentUser.getUserName());\n+        completedTasksFromPreviousRun, metrics, currentUser.getUserName(),\n+        appSubmitTime, amInfos);\n     ((RunningAppContext) context).jobs.put(newJob.getID(), newJob);\n \n     dispatcher.register(JobFinishEvent.Type.class,\n         createJobFinishEventHandler());     \n     return newJob;\n   } // end createJob()\n\\ No newline at end of file\n",
      "actualSource": "  protected Job createJob(Configuration conf) {\n\n    // create single job\n    Job newJob \u003d new JobImpl(appAttemptID, conf, dispatcher.getEventHandler(),\n        taskAttemptListener, jobTokenSecretManager, fsTokens, clock,\n        completedTasksFromPreviousRun, metrics, currentUser.getUserName(),\n        appSubmitTime, amInfos);\n    ((RunningAppContext) context).jobs.put(newJob.getID(), newJob);\n\n    dispatcher.register(JobFinishEvent.Type.class,\n        createJobFinishEventHandler());     \n    return newJob;\n  } // end createJob()",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/MRAppMaster.java",
      "extendedDetails": {}
    },
    "51a667bef8300d6499c9867b50eee352311a4185": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-2762. Cleanup MR staging directory on completion. Contributed by Mahadev Konar.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1185880 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/10/11 2:37 PM",
      "commitName": "51a667bef8300d6499c9867b50eee352311a4185",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "07/10/11 4:35 AM",
      "commitNameOld": "fa2529c9317b2f27dec16411b99f296904ea095d",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 11.42,
      "commitsBetweenForRepo": 83,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,41 +1,12 @@\n   protected Job createJob(Configuration conf) {\n \n     // create single job\n     Job newJob \u003d new JobImpl(appAttemptID, conf, dispatcher.getEventHandler(),\n         taskAttemptListener, jobTokenSecretManager, fsTokens, clock,\n         completedTasksFromPreviousRun, metrics, currentUser.getUserName());\n     ((RunningAppContext) context).jobs.put(newJob.getID(), newJob);\n \n     dispatcher.register(JobFinishEvent.Type.class,\n-        new EventHandler\u003cJobFinishEvent\u003e() {\n-          @Override\n-          public void handle(JobFinishEvent event) {\n-            // job has finished\n-            // this is the only job, so shut down the Appmaster\n-            // note in a workflow scenario, this may lead to creation of a new\n-            // job (FIXME?)\n-\n-            // TODO:currently just wait for some time so clients can know the\n-            // final states. Will be removed once RM come on.\n-            try {\n-              Thread.sleep(5000);\n-            } catch (InterruptedException e) {\n-              e.printStackTrace();\n-            }\n-            LOG.info(\"Calling stop for all the services\");\n-            try {\n-              stop();\n-            } catch (Throwable t) {\n-              LOG.warn(\"Graceful stop failed \", t);\n-            }\n-            //TODO: this is required because rpc server does not shut down\n-            // in spite of calling server.stop().\n-            //Bring the process down by force.\n-            //Not needed after HADOOP-7140\n-            LOG.info(\"Exiting MR AppMaster..GoodBye!\");\n-            System.exit(0);\n-          }\n-        });\n-\n+        createJobFinishEventHandler());     \n     return newJob;\n   } // end createJob()\n\\ No newline at end of file\n",
      "actualSource": "  protected Job createJob(Configuration conf) {\n\n    // create single job\n    Job newJob \u003d new JobImpl(appAttemptID, conf, dispatcher.getEventHandler(),\n        taskAttemptListener, jobTokenSecretManager, fsTokens, clock,\n        completedTasksFromPreviousRun, metrics, currentUser.getUserName());\n    ((RunningAppContext) context).jobs.put(newJob.getID(), newJob);\n\n    dispatcher.register(JobFinishEvent.Type.class,\n        createJobFinishEventHandler());     \n    return newJob;\n  } // end createJob()",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/MRAppMaster.java",
      "extendedDetails": {}
    },
    "fa2529c9317b2f27dec16411b99f296904ea095d": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3141. Fix the broken MRAppMaster to work over YARN in security mode.(vinodkv)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1180007 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/10/11 4:35 AM",
      "commitName": "fa2529c9317b2f27dec16411b99f296904ea095d",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "04/10/11 2:37 AM",
      "commitNameOld": "e979a3ddb17f32582e36cdc9b826f06c80c473f2",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 3.08,
      "commitsBetweenForRepo": 30,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,72 +1,41 @@\n   protected Job createJob(Configuration conf) {\n \n-    // ////////// Obtain the tokens needed by the job. //////////\n-    Credentials fsTokens \u003d new Credentials();\n-    UserGroupInformation currentUser \u003d null;\n-\n-    try {\n-      currentUser \u003d UserGroupInformation.getCurrentUser();\n-\n-      if (UserGroupInformation.isSecurityEnabled()) {\n-        // Read the file-system tokens from the localized tokens-file.\n-        Path jobSubmitDir \u003d \n-            FileContext.getLocalFSFileContext().makeQualified(\n-                new Path(new File(MRJobConfig.JOB_SUBMIT_DIR)\n-                    .getAbsolutePath()));\n-        Path jobTokenFile \u003d \n-            new Path(jobSubmitDir, MRJobConfig.APPLICATION_TOKENS_FILE);\n-        fsTokens.addAll(Credentials.readTokenStorageFile(jobTokenFile, conf));\n-        LOG.info(\"jobSubmitDir\u003d\" + jobSubmitDir + \" jobTokenFile\u003d\"\n-            + jobTokenFile);\n-\n-        for (Token\u003c? extends TokenIdentifier\u003e tk : fsTokens.getAllTokens()) {\n-          LOG.info(\" --- DEBUG: Token of kind \" + tk.getKind()\n-              + \"in current ugi in the AppMaster for service \"\n-              + tk.getService());\n-          currentUser.addToken(tk); // For use by AppMaster itself.\n-        }\n-      }\n-    } catch (IOException e) {\n-      throw new YarnException(e);\n-    }\n-    // ////////// End of obtaining the tokens needed by the job. //////////\n-\n     // create single job\n     Job newJob \u003d new JobImpl(appAttemptID, conf, dispatcher.getEventHandler(),\n         taskAttemptListener, jobTokenSecretManager, fsTokens, clock,\n         completedTasksFromPreviousRun, metrics, currentUser.getUserName());\n     ((RunningAppContext) context).jobs.put(newJob.getID(), newJob);\n \n     dispatcher.register(JobFinishEvent.Type.class,\n         new EventHandler\u003cJobFinishEvent\u003e() {\n           @Override\n           public void handle(JobFinishEvent event) {\n             // job has finished\n             // this is the only job, so shut down the Appmaster\n             // note in a workflow scenario, this may lead to creation of a new\n             // job (FIXME?)\n \n             // TODO:currently just wait for some time so clients can know the\n             // final states. Will be removed once RM come on.\n             try {\n               Thread.sleep(5000);\n             } catch (InterruptedException e) {\n               e.printStackTrace();\n             }\n             LOG.info(\"Calling stop for all the services\");\n             try {\n               stop();\n             } catch (Throwable t) {\n               LOG.warn(\"Graceful stop failed \", t);\n             }\n             //TODO: this is required because rpc server does not shut down\n             // in spite of calling server.stop().\n             //Bring the process down by force.\n             //Not needed after HADOOP-7140\n             LOG.info(\"Exiting MR AppMaster..GoodBye!\");\n             System.exit(0);\n           }\n         });\n \n     return newJob;\n   } // end createJob()\n\\ No newline at end of file\n",
      "actualSource": "  protected Job createJob(Configuration conf) {\n\n    // create single job\n    Job newJob \u003d new JobImpl(appAttemptID, conf, dispatcher.getEventHandler(),\n        taskAttemptListener, jobTokenSecretManager, fsTokens, clock,\n        completedTasksFromPreviousRun, metrics, currentUser.getUserName());\n    ((RunningAppContext) context).jobs.put(newJob.getID(), newJob);\n\n    dispatcher.register(JobFinishEvent.Type.class,\n        new EventHandler\u003cJobFinishEvent\u003e() {\n          @Override\n          public void handle(JobFinishEvent event) {\n            // job has finished\n            // this is the only job, so shut down the Appmaster\n            // note in a workflow scenario, this may lead to creation of a new\n            // job (FIXME?)\n\n            // TODO:currently just wait for some time so clients can know the\n            // final states. Will be removed once RM come on.\n            try {\n              Thread.sleep(5000);\n            } catch (InterruptedException e) {\n              e.printStackTrace();\n            }\n            LOG.info(\"Calling stop for all the services\");\n            try {\n              stop();\n            } catch (Throwable t) {\n              LOG.warn(\"Graceful stop failed \", t);\n            }\n            //TODO: this is required because rpc server does not shut down\n            // in spite of calling server.stop().\n            //Bring the process down by force.\n            //Not needed after HADOOP-7140\n            LOG.info(\"Exiting MR AppMaster..GoodBye!\");\n            System.exit(0);\n          }\n        });\n\n    return newJob;\n  } // end createJob()",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/MRAppMaster.java",
      "extendedDetails": {}
    },
    "c9a7d3dbf902244902b636bf566154c09ecd1116": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3090. Fix MR AM to use ApplicationAttemptId rather than (ApplicationId, startCount) consistently. \n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1175718 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "26/09/11 1:44 AM",
      "commitName": "c9a7d3dbf902244902b636bf566154c09ecd1116",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "23/09/11 7:07 AM",
      "commitNameOld": "b549c107825581b15fd14494099a943ff3213c6f",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 2.78,
      "commitsBetweenForRepo": 11,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,72 +1,72 @@\n   protected Job createJob(Configuration conf) {\n \n     // ////////// Obtain the tokens needed by the job. //////////\n     Credentials fsTokens \u003d new Credentials();\n     UserGroupInformation currentUser \u003d null;\n \n     try {\n       currentUser \u003d UserGroupInformation.getCurrentUser();\n \n       if (UserGroupInformation.isSecurityEnabled()) {\n         // Read the file-system tokens from the localized tokens-file.\n         Path jobSubmitDir \u003d \n             FileContext.getLocalFSFileContext().makeQualified(\n                 new Path(new File(MRJobConfig.JOB_SUBMIT_DIR)\n                     .getAbsolutePath()));\n         Path jobTokenFile \u003d \n             new Path(jobSubmitDir, MRJobConfig.APPLICATION_TOKENS_FILE);\n         fsTokens.addAll(Credentials.readTokenStorageFile(jobTokenFile, conf));\n         LOG.info(\"jobSubmitDir\u003d\" + jobSubmitDir + \" jobTokenFile\u003d\"\n             + jobTokenFile);\n \n         for (Token\u003c? extends TokenIdentifier\u003e tk : fsTokens.getAllTokens()) {\n           LOG.info(\" --- DEBUG: Token of kind \" + tk.getKind()\n               + \"in current ugi in the AppMaster for service \"\n               + tk.getService());\n           currentUser.addToken(tk); // For use by AppMaster itself.\n         }\n       }\n     } catch (IOException e) {\n       throw new YarnException(e);\n     }\n     // ////////// End of obtaining the tokens needed by the job. //////////\n \n     // create single job\n-    Job newJob \u003d new JobImpl(appID, conf, dispatcher.getEventHandler(),\n-        taskAttemptListener, jobTokenSecretManager, fsTokens, clock, startCount,\n+    Job newJob \u003d new JobImpl(appAttemptID, conf, dispatcher.getEventHandler(),\n+        taskAttemptListener, jobTokenSecretManager, fsTokens, clock,\n         completedTasksFromPreviousRun, metrics, currentUser.getUserName());\n     ((RunningAppContext) context).jobs.put(newJob.getID(), newJob);\n \n     dispatcher.register(JobFinishEvent.Type.class,\n         new EventHandler\u003cJobFinishEvent\u003e() {\n           @Override\n           public void handle(JobFinishEvent event) {\n             // job has finished\n             // this is the only job, so shut down the Appmaster\n             // note in a workflow scenario, this may lead to creation of a new\n             // job (FIXME?)\n \n             // TODO:currently just wait for some time so clients can know the\n             // final states. Will be removed once RM come on.\n             try {\n               Thread.sleep(5000);\n             } catch (InterruptedException e) {\n               e.printStackTrace();\n             }\n             LOG.info(\"Calling stop for all the services\");\n             try {\n               stop();\n             } catch (Throwable t) {\n               LOG.warn(\"Graceful stop failed \", t);\n             }\n             //TODO: this is required because rpc server does not shut down\n             // in spite of calling server.stop().\n             //Bring the process down by force.\n             //Not needed after HADOOP-7140\n             LOG.info(\"Exiting MR AppMaster..GoodBye!\");\n             System.exit(0);\n           }\n         });\n \n     return newJob;\n   } // end createJob()\n\\ No newline at end of file\n",
      "actualSource": "  protected Job createJob(Configuration conf) {\n\n    // ////////// Obtain the tokens needed by the job. //////////\n    Credentials fsTokens \u003d new Credentials();\n    UserGroupInformation currentUser \u003d null;\n\n    try {\n      currentUser \u003d UserGroupInformation.getCurrentUser();\n\n      if (UserGroupInformation.isSecurityEnabled()) {\n        // Read the file-system tokens from the localized tokens-file.\n        Path jobSubmitDir \u003d \n            FileContext.getLocalFSFileContext().makeQualified(\n                new Path(new File(MRJobConfig.JOB_SUBMIT_DIR)\n                    .getAbsolutePath()));\n        Path jobTokenFile \u003d \n            new Path(jobSubmitDir, MRJobConfig.APPLICATION_TOKENS_FILE);\n        fsTokens.addAll(Credentials.readTokenStorageFile(jobTokenFile, conf));\n        LOG.info(\"jobSubmitDir\u003d\" + jobSubmitDir + \" jobTokenFile\u003d\"\n            + jobTokenFile);\n\n        for (Token\u003c? extends TokenIdentifier\u003e tk : fsTokens.getAllTokens()) {\n          LOG.info(\" --- DEBUG: Token of kind \" + tk.getKind()\n              + \"in current ugi in the AppMaster for service \"\n              + tk.getService());\n          currentUser.addToken(tk); // For use by AppMaster itself.\n        }\n      }\n    } catch (IOException e) {\n      throw new YarnException(e);\n    }\n    // ////////// End of obtaining the tokens needed by the job. //////////\n\n    // create single job\n    Job newJob \u003d new JobImpl(appAttemptID, conf, dispatcher.getEventHandler(),\n        taskAttemptListener, jobTokenSecretManager, fsTokens, clock,\n        completedTasksFromPreviousRun, metrics, currentUser.getUserName());\n    ((RunningAppContext) context).jobs.put(newJob.getID(), newJob);\n\n    dispatcher.register(JobFinishEvent.Type.class,\n        new EventHandler\u003cJobFinishEvent\u003e() {\n          @Override\n          public void handle(JobFinishEvent event) {\n            // job has finished\n            // this is the only job, so shut down the Appmaster\n            // note in a workflow scenario, this may lead to creation of a new\n            // job (FIXME?)\n\n            // TODO:currently just wait for some time so clients can know the\n            // final states. Will be removed once RM come on.\n            try {\n              Thread.sleep(5000);\n            } catch (InterruptedException e) {\n              e.printStackTrace();\n            }\n            LOG.info(\"Calling stop for all the services\");\n            try {\n              stop();\n            } catch (Throwable t) {\n              LOG.warn(\"Graceful stop failed \", t);\n            }\n            //TODO: this is required because rpc server does not shut down\n            // in spite of calling server.stop().\n            //Bring the process down by force.\n            //Not needed after HADOOP-7140\n            LOG.info(\"Exiting MR AppMaster..GoodBye!\");\n            System.exit(0);\n          }\n        });\n\n    return newJob;\n  } // end createJob()",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/MRAppMaster.java",
      "extendedDetails": {}
    },
    "d00b3c49f6fb3f6a617add6203c6b55f6c345940": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-2880. Improved classpath-construction for mapreduce AM and containers. Contributed by Arun C Murthy.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1173783 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/09/11 11:28 AM",
      "commitName": "d00b3c49f6fb3f6a617add6203c6b55f6c345940",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "18/09/11 12:16 AM",
      "commitNameOld": "61900651b1b85cf235e01142acf2a51727fc5537",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 3.47,
      "commitsBetweenForRepo": 26,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,72 +1,72 @@\n   protected Job createJob(Configuration conf) {\n \n     // ////////// Obtain the tokens needed by the job. //////////\n     Credentials fsTokens \u003d new Credentials();\n     UserGroupInformation currentUser \u003d null;\n \n     try {\n       currentUser \u003d UserGroupInformation.getCurrentUser();\n \n       if (UserGroupInformation.isSecurityEnabled()) {\n         // Read the file-system tokens from the localized tokens-file.\n         Path jobSubmitDir \u003d \n             FileContext.getLocalFSFileContext().makeQualified(\n-                new Path(new File(MRConstants.JOB_SUBMIT_DIR)\n+                new Path(new File(MRJobConfig.JOB_SUBMIT_DIR)\n                     .getAbsolutePath()));\n         Path jobTokenFile \u003d \n-            new Path(jobSubmitDir, MRConstants.APPLICATION_TOKENS_FILE);\n+            new Path(jobSubmitDir, MRJobConfig.APPLICATION_TOKENS_FILE);\n         fsTokens.addAll(Credentials.readTokenStorageFile(jobTokenFile, conf));\n         LOG.info(\"jobSubmitDir\u003d\" + jobSubmitDir + \" jobTokenFile\u003d\"\n             + jobTokenFile);\n \n         for (Token\u003c? extends TokenIdentifier\u003e tk : fsTokens.getAllTokens()) {\n           LOG.info(\" --- DEBUG: Token of kind \" + tk.getKind()\n               + \"in current ugi in the AppMaster for service \"\n               + tk.getService());\n           currentUser.addToken(tk); // For use by AppMaster itself.\n         }\n       }\n     } catch (IOException e) {\n       throw new YarnException(e);\n     }\n     // ////////// End of obtaining the tokens needed by the job. //////////\n \n     // create single job\n     Job newJob \u003d new JobImpl(appID, conf, dispatcher.getEventHandler(),\n         taskAttemptListener, jobTokenSecretManager, fsTokens, clock, startCount,\n         completedTasksFromPreviousRun, metrics, currentUser.getUserName());\n     ((RunningAppContext) context).jobs.put(newJob.getID(), newJob);\n \n     dispatcher.register(JobFinishEvent.Type.class,\n         new EventHandler\u003cJobFinishEvent\u003e() {\n           @Override\n           public void handle(JobFinishEvent event) {\n             // job has finished\n             // this is the only job, so shut down the Appmaster\n             // note in a workflow scenario, this may lead to creation of a new\n             // job (FIXME?)\n \n             // TODO:currently just wait for some time so clients can know the\n             // final states. Will be removed once RM come on.\n             try {\n               Thread.sleep(5000);\n             } catch (InterruptedException e) {\n               e.printStackTrace();\n             }\n             LOG.info(\"Calling stop for all the services\");\n             try {\n               stop();\n             } catch (Throwable t) {\n               LOG.warn(\"Graceful stop failed \", t);\n             }\n             //TODO: this is required because rpc server does not shut down\n             // in spite of calling server.stop().\n             //Bring the process down by force.\n             //Not needed after HADOOP-7140\n             LOG.info(\"Exiting MR AppMaster..GoodBye!\");\n             System.exit(0);\n           }\n         });\n \n     return newJob;\n   } // end createJob()\n\\ No newline at end of file\n",
      "actualSource": "  protected Job createJob(Configuration conf) {\n\n    // ////////// Obtain the tokens needed by the job. //////////\n    Credentials fsTokens \u003d new Credentials();\n    UserGroupInformation currentUser \u003d null;\n\n    try {\n      currentUser \u003d UserGroupInformation.getCurrentUser();\n\n      if (UserGroupInformation.isSecurityEnabled()) {\n        // Read the file-system tokens from the localized tokens-file.\n        Path jobSubmitDir \u003d \n            FileContext.getLocalFSFileContext().makeQualified(\n                new Path(new File(MRJobConfig.JOB_SUBMIT_DIR)\n                    .getAbsolutePath()));\n        Path jobTokenFile \u003d \n            new Path(jobSubmitDir, MRJobConfig.APPLICATION_TOKENS_FILE);\n        fsTokens.addAll(Credentials.readTokenStorageFile(jobTokenFile, conf));\n        LOG.info(\"jobSubmitDir\u003d\" + jobSubmitDir + \" jobTokenFile\u003d\"\n            + jobTokenFile);\n\n        for (Token\u003c? extends TokenIdentifier\u003e tk : fsTokens.getAllTokens()) {\n          LOG.info(\" --- DEBUG: Token of kind \" + tk.getKind()\n              + \"in current ugi in the AppMaster for service \"\n              + tk.getService());\n          currentUser.addToken(tk); // For use by AppMaster itself.\n        }\n      }\n    } catch (IOException e) {\n      throw new YarnException(e);\n    }\n    // ////////// End of obtaining the tokens needed by the job. //////////\n\n    // create single job\n    Job newJob \u003d new JobImpl(appID, conf, dispatcher.getEventHandler(),\n        taskAttemptListener, jobTokenSecretManager, fsTokens, clock, startCount,\n        completedTasksFromPreviousRun, metrics, currentUser.getUserName());\n    ((RunningAppContext) context).jobs.put(newJob.getID(), newJob);\n\n    dispatcher.register(JobFinishEvent.Type.class,\n        new EventHandler\u003cJobFinishEvent\u003e() {\n          @Override\n          public void handle(JobFinishEvent event) {\n            // job has finished\n            // this is the only job, so shut down the Appmaster\n            // note in a workflow scenario, this may lead to creation of a new\n            // job (FIXME?)\n\n            // TODO:currently just wait for some time so clients can know the\n            // final states. Will be removed once RM come on.\n            try {\n              Thread.sleep(5000);\n            } catch (InterruptedException e) {\n              e.printStackTrace();\n            }\n            LOG.info(\"Calling stop for all the services\");\n            try {\n              stop();\n            } catch (Throwable t) {\n              LOG.warn(\"Graceful stop failed \", t);\n            }\n            //TODO: this is required because rpc server does not shut down\n            // in spite of calling server.stop().\n            //Bring the process down by force.\n            //Not needed after HADOOP-7140\n            LOG.info(\"Exiting MR AppMaster..GoodBye!\");\n            System.exit(0);\n          }\n        });\n\n    return newJob;\n  } // end createJob()",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/MRAppMaster.java",
      "extendedDetails": {}
    },
    "61900651b1b85cf235e01142acf2a51727fc5537": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "MAPREDUCE-3006. Fixed MapReduce AM to exit only after properly writing out history file. (vinodkv)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1172206 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/09/11 12:16 AM",
      "commitName": "61900651b1b85cf235e01142acf2a51727fc5537",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "MAPREDUCE-3006. Fixed MapReduce AM to exit only after properly writing out history file. (vinodkv)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1172206 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/09/11 12:16 AM",
          "commitName": "61900651b1b85cf235e01142acf2a51727fc5537",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "14/09/11 10:57 AM",
          "commitNameOld": "4ba2acf3363bdfd7fcdd9de496cd57f8af6f03ad",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 3.55,
          "commitsBetweenForRepo": 22,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,42 +1,72 @@\n-  protected Job createJob(Configuration conf, Credentials fsTokens, \n-      String user) {\n+  protected Job createJob(Configuration conf) {\n+\n+    // ////////// Obtain the tokens needed by the job. //////////\n+    Credentials fsTokens \u003d new Credentials();\n+    UserGroupInformation currentUser \u003d null;\n+\n+    try {\n+      currentUser \u003d UserGroupInformation.getCurrentUser();\n+\n+      if (UserGroupInformation.isSecurityEnabled()) {\n+        // Read the file-system tokens from the localized tokens-file.\n+        Path jobSubmitDir \u003d \n+            FileContext.getLocalFSFileContext().makeQualified(\n+                new Path(new File(MRConstants.JOB_SUBMIT_DIR)\n+                    .getAbsolutePath()));\n+        Path jobTokenFile \u003d \n+            new Path(jobSubmitDir, MRConstants.APPLICATION_TOKENS_FILE);\n+        fsTokens.addAll(Credentials.readTokenStorageFile(jobTokenFile, conf));\n+        LOG.info(\"jobSubmitDir\u003d\" + jobSubmitDir + \" jobTokenFile\u003d\"\n+            + jobTokenFile);\n+\n+        for (Token\u003c? extends TokenIdentifier\u003e tk : fsTokens.getAllTokens()) {\n+          LOG.info(\" --- DEBUG: Token of kind \" + tk.getKind()\n+              + \"in current ugi in the AppMaster for service \"\n+              + tk.getService());\n+          currentUser.addToken(tk); // For use by AppMaster itself.\n+        }\n+      }\n+    } catch (IOException e) {\n+      throw new YarnException(e);\n+    }\n+    // ////////// End of obtaining the tokens needed by the job. //////////\n \n     // create single job\n     Job newJob \u003d new JobImpl(appID, conf, dispatcher.getEventHandler(),\n         taskAttemptListener, jobTokenSecretManager, fsTokens, clock, startCount,\n-        completedTasksFromPreviousRun, metrics, user);\n+        completedTasksFromPreviousRun, metrics, currentUser.getUserName());\n     ((RunningAppContext) context).jobs.put(newJob.getID(), newJob);\n \n     dispatcher.register(JobFinishEvent.Type.class,\n         new EventHandler\u003cJobFinishEvent\u003e() {\n           @Override\n           public void handle(JobFinishEvent event) {\n             // job has finished\n             // this is the only job, so shut down the Appmaster\n             // note in a workflow scenario, this may lead to creation of a new\n             // job (FIXME?)\n \n             // TODO:currently just wait for some time so clients can know the\n             // final states. Will be removed once RM come on.\n             try {\n               Thread.sleep(5000);\n             } catch (InterruptedException e) {\n               e.printStackTrace();\n             }\n             LOG.info(\"Calling stop for all the services\");\n             try {\n               stop();\n             } catch (Throwable t) {\n               LOG.warn(\"Graceful stop failed \", t);\n             }\n             //TODO: this is required because rpc server does not shut down\n             // in spite of calling server.stop().\n             //Bring the process down by force.\n             //Not needed after HADOOP-7140\n             LOG.info(\"Exiting MR AppMaster..GoodBye!\");\n             System.exit(0);\n           }\n         });\n \n     return newJob;\n   } // end createJob()\n\\ No newline at end of file\n",
          "actualSource": "  protected Job createJob(Configuration conf) {\n\n    // ////////// Obtain the tokens needed by the job. //////////\n    Credentials fsTokens \u003d new Credentials();\n    UserGroupInformation currentUser \u003d null;\n\n    try {\n      currentUser \u003d UserGroupInformation.getCurrentUser();\n\n      if (UserGroupInformation.isSecurityEnabled()) {\n        // Read the file-system tokens from the localized tokens-file.\n        Path jobSubmitDir \u003d \n            FileContext.getLocalFSFileContext().makeQualified(\n                new Path(new File(MRConstants.JOB_SUBMIT_DIR)\n                    .getAbsolutePath()));\n        Path jobTokenFile \u003d \n            new Path(jobSubmitDir, MRConstants.APPLICATION_TOKENS_FILE);\n        fsTokens.addAll(Credentials.readTokenStorageFile(jobTokenFile, conf));\n        LOG.info(\"jobSubmitDir\u003d\" + jobSubmitDir + \" jobTokenFile\u003d\"\n            + jobTokenFile);\n\n        for (Token\u003c? extends TokenIdentifier\u003e tk : fsTokens.getAllTokens()) {\n          LOG.info(\" --- DEBUG: Token of kind \" + tk.getKind()\n              + \"in current ugi in the AppMaster for service \"\n              + tk.getService());\n          currentUser.addToken(tk); // For use by AppMaster itself.\n        }\n      }\n    } catch (IOException e) {\n      throw new YarnException(e);\n    }\n    // ////////// End of obtaining the tokens needed by the job. //////////\n\n    // create single job\n    Job newJob \u003d new JobImpl(appID, conf, dispatcher.getEventHandler(),\n        taskAttemptListener, jobTokenSecretManager, fsTokens, clock, startCount,\n        completedTasksFromPreviousRun, metrics, currentUser.getUserName());\n    ((RunningAppContext) context).jobs.put(newJob.getID(), newJob);\n\n    dispatcher.register(JobFinishEvent.Type.class,\n        new EventHandler\u003cJobFinishEvent\u003e() {\n          @Override\n          public void handle(JobFinishEvent event) {\n            // job has finished\n            // this is the only job, so shut down the Appmaster\n            // note in a workflow scenario, this may lead to creation of a new\n            // job (FIXME?)\n\n            // TODO:currently just wait for some time so clients can know the\n            // final states. Will be removed once RM come on.\n            try {\n              Thread.sleep(5000);\n            } catch (InterruptedException e) {\n              e.printStackTrace();\n            }\n            LOG.info(\"Calling stop for all the services\");\n            try {\n              stop();\n            } catch (Throwable t) {\n              LOG.warn(\"Graceful stop failed \", t);\n            }\n            //TODO: this is required because rpc server does not shut down\n            // in spite of calling server.stop().\n            //Bring the process down by force.\n            //Not needed after HADOOP-7140\n            LOG.info(\"Exiting MR AppMaster..GoodBye!\");\n            System.exit(0);\n          }\n        });\n\n    return newJob;\n  } // end createJob()",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/MRAppMaster.java",
          "extendedDetails": {
            "oldValue": "[conf-Configuration, fsTokens-Credentials, user-String]",
            "newValue": "[conf-Configuration]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "MAPREDUCE-3006. Fixed MapReduce AM to exit only after properly writing out history file. (vinodkv)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1172206 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/09/11 12:16 AM",
          "commitName": "61900651b1b85cf235e01142acf2a51727fc5537",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "14/09/11 10:57 AM",
          "commitNameOld": "4ba2acf3363bdfd7fcdd9de496cd57f8af6f03ad",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 3.55,
          "commitsBetweenForRepo": 22,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,42 +1,72 @@\n-  protected Job createJob(Configuration conf, Credentials fsTokens, \n-      String user) {\n+  protected Job createJob(Configuration conf) {\n+\n+    // ////////// Obtain the tokens needed by the job. //////////\n+    Credentials fsTokens \u003d new Credentials();\n+    UserGroupInformation currentUser \u003d null;\n+\n+    try {\n+      currentUser \u003d UserGroupInformation.getCurrentUser();\n+\n+      if (UserGroupInformation.isSecurityEnabled()) {\n+        // Read the file-system tokens from the localized tokens-file.\n+        Path jobSubmitDir \u003d \n+            FileContext.getLocalFSFileContext().makeQualified(\n+                new Path(new File(MRConstants.JOB_SUBMIT_DIR)\n+                    .getAbsolutePath()));\n+        Path jobTokenFile \u003d \n+            new Path(jobSubmitDir, MRConstants.APPLICATION_TOKENS_FILE);\n+        fsTokens.addAll(Credentials.readTokenStorageFile(jobTokenFile, conf));\n+        LOG.info(\"jobSubmitDir\u003d\" + jobSubmitDir + \" jobTokenFile\u003d\"\n+            + jobTokenFile);\n+\n+        for (Token\u003c? extends TokenIdentifier\u003e tk : fsTokens.getAllTokens()) {\n+          LOG.info(\" --- DEBUG: Token of kind \" + tk.getKind()\n+              + \"in current ugi in the AppMaster for service \"\n+              + tk.getService());\n+          currentUser.addToken(tk); // For use by AppMaster itself.\n+        }\n+      }\n+    } catch (IOException e) {\n+      throw new YarnException(e);\n+    }\n+    // ////////// End of obtaining the tokens needed by the job. //////////\n \n     // create single job\n     Job newJob \u003d new JobImpl(appID, conf, dispatcher.getEventHandler(),\n         taskAttemptListener, jobTokenSecretManager, fsTokens, clock, startCount,\n-        completedTasksFromPreviousRun, metrics, user);\n+        completedTasksFromPreviousRun, metrics, currentUser.getUserName());\n     ((RunningAppContext) context).jobs.put(newJob.getID(), newJob);\n \n     dispatcher.register(JobFinishEvent.Type.class,\n         new EventHandler\u003cJobFinishEvent\u003e() {\n           @Override\n           public void handle(JobFinishEvent event) {\n             // job has finished\n             // this is the only job, so shut down the Appmaster\n             // note in a workflow scenario, this may lead to creation of a new\n             // job (FIXME?)\n \n             // TODO:currently just wait for some time so clients can know the\n             // final states. Will be removed once RM come on.\n             try {\n               Thread.sleep(5000);\n             } catch (InterruptedException e) {\n               e.printStackTrace();\n             }\n             LOG.info(\"Calling stop for all the services\");\n             try {\n               stop();\n             } catch (Throwable t) {\n               LOG.warn(\"Graceful stop failed \", t);\n             }\n             //TODO: this is required because rpc server does not shut down\n             // in spite of calling server.stop().\n             //Bring the process down by force.\n             //Not needed after HADOOP-7140\n             LOG.info(\"Exiting MR AppMaster..GoodBye!\");\n             System.exit(0);\n           }\n         });\n \n     return newJob;\n   } // end createJob()\n\\ No newline at end of file\n",
          "actualSource": "  protected Job createJob(Configuration conf) {\n\n    // ////////// Obtain the tokens needed by the job. //////////\n    Credentials fsTokens \u003d new Credentials();\n    UserGroupInformation currentUser \u003d null;\n\n    try {\n      currentUser \u003d UserGroupInformation.getCurrentUser();\n\n      if (UserGroupInformation.isSecurityEnabled()) {\n        // Read the file-system tokens from the localized tokens-file.\n        Path jobSubmitDir \u003d \n            FileContext.getLocalFSFileContext().makeQualified(\n                new Path(new File(MRConstants.JOB_SUBMIT_DIR)\n                    .getAbsolutePath()));\n        Path jobTokenFile \u003d \n            new Path(jobSubmitDir, MRConstants.APPLICATION_TOKENS_FILE);\n        fsTokens.addAll(Credentials.readTokenStorageFile(jobTokenFile, conf));\n        LOG.info(\"jobSubmitDir\u003d\" + jobSubmitDir + \" jobTokenFile\u003d\"\n            + jobTokenFile);\n\n        for (Token\u003c? extends TokenIdentifier\u003e tk : fsTokens.getAllTokens()) {\n          LOG.info(\" --- DEBUG: Token of kind \" + tk.getKind()\n              + \"in current ugi in the AppMaster for service \"\n              + tk.getService());\n          currentUser.addToken(tk); // For use by AppMaster itself.\n        }\n      }\n    } catch (IOException e) {\n      throw new YarnException(e);\n    }\n    // ////////// End of obtaining the tokens needed by the job. //////////\n\n    // create single job\n    Job newJob \u003d new JobImpl(appID, conf, dispatcher.getEventHandler(),\n        taskAttemptListener, jobTokenSecretManager, fsTokens, clock, startCount,\n        completedTasksFromPreviousRun, metrics, currentUser.getUserName());\n    ((RunningAppContext) context).jobs.put(newJob.getID(), newJob);\n\n    dispatcher.register(JobFinishEvent.Type.class,\n        new EventHandler\u003cJobFinishEvent\u003e() {\n          @Override\n          public void handle(JobFinishEvent event) {\n            // job has finished\n            // this is the only job, so shut down the Appmaster\n            // note in a workflow scenario, this may lead to creation of a new\n            // job (FIXME?)\n\n            // TODO:currently just wait for some time so clients can know the\n            // final states. Will be removed once RM come on.\n            try {\n              Thread.sleep(5000);\n            } catch (InterruptedException e) {\n              e.printStackTrace();\n            }\n            LOG.info(\"Calling stop for all the services\");\n            try {\n              stop();\n            } catch (Throwable t) {\n              LOG.warn(\"Graceful stop failed \", t);\n            }\n            //TODO: this is required because rpc server does not shut down\n            // in spite of calling server.stop().\n            //Bring the process down by force.\n            //Not needed after HADOOP-7140\n            LOG.info(\"Exiting MR AppMaster..GoodBye!\");\n            System.exit(0);\n          }\n        });\n\n    return newJob;\n  } // end createJob()",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/MRAppMaster.java",
          "extendedDetails": {}
        }
      ]
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  protected Job createJob(Configuration conf, Credentials fsTokens, \n      String user) {\n\n    // create single job\n    Job newJob \u003d new JobImpl(appID, conf, dispatcher.getEventHandler(),\n        taskAttemptListener, jobTokenSecretManager, fsTokens, clock, startCount,\n        completedTasksFromPreviousRun, metrics, user);\n    ((RunningAppContext) context).jobs.put(newJob.getID(), newJob);\n\n    dispatcher.register(JobFinishEvent.Type.class,\n        new EventHandler\u003cJobFinishEvent\u003e() {\n          @Override\n          public void handle(JobFinishEvent event) {\n            // job has finished\n            // this is the only job, so shut down the Appmaster\n            // note in a workflow scenario, this may lead to creation of a new\n            // job (FIXME?)\n\n            // TODO:currently just wait for some time so clients can know the\n            // final states. Will be removed once RM come on.\n            try {\n              Thread.sleep(5000);\n            } catch (InterruptedException e) {\n              e.printStackTrace();\n            }\n            LOG.info(\"Calling stop for all the services\");\n            try {\n              stop();\n            } catch (Throwable t) {\n              LOG.warn(\"Graceful stop failed \", t);\n            }\n            //TODO: this is required because rpc server does not shut down\n            // in spite of calling server.stop().\n            //Bring the process down by force.\n            //Not needed after HADOOP-7140\n            LOG.info(\"Exiting MR AppMaster..GoodBye!\");\n            System.exit(0);\n          }\n        });\n\n    return newJob;\n  } // end createJob()",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/MRAppMaster.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/MRAppMaster.java",
        "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/MRAppMaster.java"
      }
    },
    "7c8fcbecf14b2e24d54ccb276bb684fdbe62b669": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "MAPREDUCE-2701. app/Job.java needs UGI for the user that launched it. (Robert Evans via mahadev)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1160392 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "22/08/11 12:36 PM",
      "commitName": "7c8fcbecf14b2e24d54ccb276bb684fdbe62b669",
      "commitAuthor": "Mahadev Konar",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "MAPREDUCE-2701. app/Job.java needs UGI for the user that launched it. (Robert Evans via mahadev)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1160392 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "22/08/11 12:36 PM",
          "commitName": "7c8fcbecf14b2e24d54ccb276bb684fdbe62b669",
          "commitAuthor": "Mahadev Konar",
          "commitDateOld": "18/08/11 4:07 AM",
          "commitNameOld": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 4.35,
          "commitsBetweenForRepo": 14,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,41 +1,42 @@\n-  protected Job createJob(Configuration conf, Credentials fsTokens) {\n+  protected Job createJob(Configuration conf, Credentials fsTokens, \n+      String user) {\n \n     // create single job\n     Job newJob \u003d new JobImpl(appID, conf, dispatcher.getEventHandler(),\n         taskAttemptListener, jobTokenSecretManager, fsTokens, clock, startCount,\n-        completedTasksFromPreviousRun, metrics);\n+        completedTasksFromPreviousRun, metrics, user);\n     ((RunningAppContext) context).jobs.put(newJob.getID(), newJob);\n \n     dispatcher.register(JobFinishEvent.Type.class,\n         new EventHandler\u003cJobFinishEvent\u003e() {\n           @Override\n           public void handle(JobFinishEvent event) {\n             // job has finished\n             // this is the only job, so shut down the Appmaster\n             // note in a workflow scenario, this may lead to creation of a new\n             // job (FIXME?)\n \n             // TODO:currently just wait for some time so clients can know the\n             // final states. Will be removed once RM come on.\n             try {\n               Thread.sleep(5000);\n             } catch (InterruptedException e) {\n               e.printStackTrace();\n             }\n             LOG.info(\"Calling stop for all the services\");\n             try {\n               stop();\n             } catch (Throwable t) {\n               LOG.warn(\"Graceful stop failed \", t);\n             }\n             //TODO: this is required because rpc server does not shut down\n             // in spite of calling server.stop().\n             //Bring the process down by force.\n             //Not needed after HADOOP-7140\n             LOG.info(\"Exiting MR AppMaster..GoodBye!\");\n             System.exit(0);\n           }\n         });\n \n     return newJob;\n   } // end createJob()\n\\ No newline at end of file\n",
          "actualSource": "  protected Job createJob(Configuration conf, Credentials fsTokens, \n      String user) {\n\n    // create single job\n    Job newJob \u003d new JobImpl(appID, conf, dispatcher.getEventHandler(),\n        taskAttemptListener, jobTokenSecretManager, fsTokens, clock, startCount,\n        completedTasksFromPreviousRun, metrics, user);\n    ((RunningAppContext) context).jobs.put(newJob.getID(), newJob);\n\n    dispatcher.register(JobFinishEvent.Type.class,\n        new EventHandler\u003cJobFinishEvent\u003e() {\n          @Override\n          public void handle(JobFinishEvent event) {\n            // job has finished\n            // this is the only job, so shut down the Appmaster\n            // note in a workflow scenario, this may lead to creation of a new\n            // job (FIXME?)\n\n            // TODO:currently just wait for some time so clients can know the\n            // final states. Will be removed once RM come on.\n            try {\n              Thread.sleep(5000);\n            } catch (InterruptedException e) {\n              e.printStackTrace();\n            }\n            LOG.info(\"Calling stop for all the services\");\n            try {\n              stop();\n            } catch (Throwable t) {\n              LOG.warn(\"Graceful stop failed \", t);\n            }\n            //TODO: this is required because rpc server does not shut down\n            // in spite of calling server.stop().\n            //Bring the process down by force.\n            //Not needed after HADOOP-7140\n            LOG.info(\"Exiting MR AppMaster..GoodBye!\");\n            System.exit(0);\n          }\n        });\n\n    return newJob;\n  } // end createJob()",
          "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/MRAppMaster.java",
          "extendedDetails": {
            "oldValue": "[conf-Configuration, fsTokens-Credentials]",
            "newValue": "[conf-Configuration, fsTokens-Credentials, user-String]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "MAPREDUCE-2701. app/Job.java needs UGI for the user that launched it. (Robert Evans via mahadev)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1160392 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "22/08/11 12:36 PM",
          "commitName": "7c8fcbecf14b2e24d54ccb276bb684fdbe62b669",
          "commitAuthor": "Mahadev Konar",
          "commitDateOld": "18/08/11 4:07 AM",
          "commitNameOld": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 4.35,
          "commitsBetweenForRepo": 14,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,41 +1,42 @@\n-  protected Job createJob(Configuration conf, Credentials fsTokens) {\n+  protected Job createJob(Configuration conf, Credentials fsTokens, \n+      String user) {\n \n     // create single job\n     Job newJob \u003d new JobImpl(appID, conf, dispatcher.getEventHandler(),\n         taskAttemptListener, jobTokenSecretManager, fsTokens, clock, startCount,\n-        completedTasksFromPreviousRun, metrics);\n+        completedTasksFromPreviousRun, metrics, user);\n     ((RunningAppContext) context).jobs.put(newJob.getID(), newJob);\n \n     dispatcher.register(JobFinishEvent.Type.class,\n         new EventHandler\u003cJobFinishEvent\u003e() {\n           @Override\n           public void handle(JobFinishEvent event) {\n             // job has finished\n             // this is the only job, so shut down the Appmaster\n             // note in a workflow scenario, this may lead to creation of a new\n             // job (FIXME?)\n \n             // TODO:currently just wait for some time so clients can know the\n             // final states. Will be removed once RM come on.\n             try {\n               Thread.sleep(5000);\n             } catch (InterruptedException e) {\n               e.printStackTrace();\n             }\n             LOG.info(\"Calling stop for all the services\");\n             try {\n               stop();\n             } catch (Throwable t) {\n               LOG.warn(\"Graceful stop failed \", t);\n             }\n             //TODO: this is required because rpc server does not shut down\n             // in spite of calling server.stop().\n             //Bring the process down by force.\n             //Not needed after HADOOP-7140\n             LOG.info(\"Exiting MR AppMaster..GoodBye!\");\n             System.exit(0);\n           }\n         });\n \n     return newJob;\n   } // end createJob()\n\\ No newline at end of file\n",
          "actualSource": "  protected Job createJob(Configuration conf, Credentials fsTokens, \n      String user) {\n\n    // create single job\n    Job newJob \u003d new JobImpl(appID, conf, dispatcher.getEventHandler(),\n        taskAttemptListener, jobTokenSecretManager, fsTokens, clock, startCount,\n        completedTasksFromPreviousRun, metrics, user);\n    ((RunningAppContext) context).jobs.put(newJob.getID(), newJob);\n\n    dispatcher.register(JobFinishEvent.Type.class,\n        new EventHandler\u003cJobFinishEvent\u003e() {\n          @Override\n          public void handle(JobFinishEvent event) {\n            // job has finished\n            // this is the only job, so shut down the Appmaster\n            // note in a workflow scenario, this may lead to creation of a new\n            // job (FIXME?)\n\n            // TODO:currently just wait for some time so clients can know the\n            // final states. Will be removed once RM come on.\n            try {\n              Thread.sleep(5000);\n            } catch (InterruptedException e) {\n              e.printStackTrace();\n            }\n            LOG.info(\"Calling stop for all the services\");\n            try {\n              stop();\n            } catch (Throwable t) {\n              LOG.warn(\"Graceful stop failed \", t);\n            }\n            //TODO: this is required because rpc server does not shut down\n            // in spite of calling server.stop().\n            //Bring the process down by force.\n            //Not needed after HADOOP-7140\n            LOG.info(\"Exiting MR AppMaster..GoodBye!\");\n            System.exit(0);\n          }\n        });\n\n    return newJob;\n  } // end createJob()",
          "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/MRAppMaster.java",
          "extendedDetails": {}
        }
      ]
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "diff": "@@ -0,0 +1,41 @@\n+  protected Job createJob(Configuration conf, Credentials fsTokens) {\n+\n+    // create single job\n+    Job newJob \u003d new JobImpl(appID, conf, dispatcher.getEventHandler(),\n+        taskAttemptListener, jobTokenSecretManager, fsTokens, clock, startCount,\n+        completedTasksFromPreviousRun, metrics);\n+    ((RunningAppContext) context).jobs.put(newJob.getID(), newJob);\n+\n+    dispatcher.register(JobFinishEvent.Type.class,\n+        new EventHandler\u003cJobFinishEvent\u003e() {\n+          @Override\n+          public void handle(JobFinishEvent event) {\n+            // job has finished\n+            // this is the only job, so shut down the Appmaster\n+            // note in a workflow scenario, this may lead to creation of a new\n+            // job (FIXME?)\n+\n+            // TODO:currently just wait for some time so clients can know the\n+            // final states. Will be removed once RM come on.\n+            try {\n+              Thread.sleep(5000);\n+            } catch (InterruptedException e) {\n+              e.printStackTrace();\n+            }\n+            LOG.info(\"Calling stop for all the services\");\n+            try {\n+              stop();\n+            } catch (Throwable t) {\n+              LOG.warn(\"Graceful stop failed \", t);\n+            }\n+            //TODO: this is required because rpc server does not shut down\n+            // in spite of calling server.stop().\n+            //Bring the process down by force.\n+            //Not needed after HADOOP-7140\n+            LOG.info(\"Exiting MR AppMaster..GoodBye!\");\n+            System.exit(0);\n+          }\n+        });\n+\n+    return newJob;\n+  } // end createJob()\n\\ No newline at end of file\n",
      "actualSource": "  protected Job createJob(Configuration conf, Credentials fsTokens) {\n\n    // create single job\n    Job newJob \u003d new JobImpl(appID, conf, dispatcher.getEventHandler(),\n        taskAttemptListener, jobTokenSecretManager, fsTokens, clock, startCount,\n        completedTasksFromPreviousRun, metrics);\n    ((RunningAppContext) context).jobs.put(newJob.getID(), newJob);\n\n    dispatcher.register(JobFinishEvent.Type.class,\n        new EventHandler\u003cJobFinishEvent\u003e() {\n          @Override\n          public void handle(JobFinishEvent event) {\n            // job has finished\n            // this is the only job, so shut down the Appmaster\n            // note in a workflow scenario, this may lead to creation of a new\n            // job (FIXME?)\n\n            // TODO:currently just wait for some time so clients can know the\n            // final states. Will be removed once RM come on.\n            try {\n              Thread.sleep(5000);\n            } catch (InterruptedException e) {\n              e.printStackTrace();\n            }\n            LOG.info(\"Calling stop for all the services\");\n            try {\n              stop();\n            } catch (Throwable t) {\n              LOG.warn(\"Graceful stop failed \", t);\n            }\n            //TODO: this is required because rpc server does not shut down\n            // in spite of calling server.stop().\n            //Bring the process down by force.\n            //Not needed after HADOOP-7140\n            LOG.info(\"Exiting MR AppMaster..GoodBye!\");\n            System.exit(0);\n          }\n        });\n\n    return newJob;\n  } // end createJob()",
      "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/MRAppMaster.java"
    }
  }
}