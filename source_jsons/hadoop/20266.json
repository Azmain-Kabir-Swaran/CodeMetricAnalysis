{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "Task.java",
  "functionName": "initialize",
  "functionId": "initialize___job-JobConf__id-JobID__reporter-Reporter__useNewApi-boolean",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/Task.java",
  "functionStartLine": 591,
  "functionEndLine": 631,
  "numCommitsSeen": 47,
  "timeTaken": 9451,
  "changeHistory": [
    "1a49c854386d3ba4aef6f29f46e2bd5e71e86dc1",
    "94242c93857a06fb9c56ee571a47d6ca18f00f48",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "1a49c854386d3ba4aef6f29f46e2bd5e71e86dc1": "Ybodychange",
    "94242c93857a06fb9c56ee571a47d6ca18f00f48": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Ymultichange(Ymovefromfile,Ybodychange)",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "1a49c854386d3ba4aef6f29f46e2bd5e71e86dc1": {
      "type": "Ybodychange",
      "commitMessage": "YARN-223. Update process tree instead of getting new process trees. (Radim Kolar via llu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1424244 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/12/12 4:20 PM",
      "commitName": "1a49c854386d3ba4aef6f29f46e2bd5e71e86dc1",
      "commitAuthor": "Luke Lu",
      "commitDateOld": "15/12/12 12:18 PM",
      "commitNameOld": "803e5155d1c8c842bed8e2d8624cb17ab11ec53b",
      "commitAuthorOld": "Alejandro Abdelnur",
      "daysBetweenCommits": 4.17,
      "commitsBetweenForRepo": 20,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,41 +1,41 @@\n   public void initialize(JobConf job, JobID id, \n                          Reporter reporter,\n                          boolean useNewApi) throws IOException, \n                                                    ClassNotFoundException,\n                                                    InterruptedException {\n     jobContext \u003d new JobContextImpl(job, id, reporter);\n     taskContext \u003d new TaskAttemptContextImpl(job, taskId, reporter);\n     if (getState() \u003d\u003d TaskStatus.State.UNASSIGNED) {\n       setState(TaskStatus.State.RUNNING);\n     }\n     if (useNewApi) {\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"using new api for output committer\");\n       }\n       outputFormat \u003d\n         ReflectionUtils.newInstance(taskContext.getOutputFormatClass(), job);\n       committer \u003d outputFormat.getOutputCommitter(taskContext);\n     } else {\n       committer \u003d conf.getOutputCommitter();\n     }\n     Path outputPath \u003d FileOutputFormat.getOutputPath(conf);\n     if (outputPath !\u003d null) {\n       if ((committer instanceof FileOutputCommitter)) {\n         FileOutputFormat.setWorkOutputPath(conf, \n           ((FileOutputCommitter)committer).getTaskAttemptPath(taskContext));\n       } else {\n         FileOutputFormat.setWorkOutputPath(conf, outputPath);\n       }\n     }\n     committer.setupTask(taskContext);\n-    Class\u003c? extends ResourceCalculatorPlugin\u003e clazz \u003d\n-        conf.getClass(MRConfig.RESOURCE_CALCULATOR_PLUGIN,\n-            null, ResourceCalculatorPlugin.class);\n-    resourceCalculator \u003d ResourceCalculatorPlugin\n-            .getResourceCalculatorPlugin(clazz, conf);\n-    LOG.info(\" Using ResourceCalculatorPlugin : \" + resourceCalculator);\n-    if (resourceCalculator !\u003d null) {\n-      initCpuCumulativeTime \u003d\n-        resourceCalculator.getProcResourceValues().getCumulativeCpuTime();\n+    Class\u003c? extends ResourceCalculatorProcessTree\u003e clazz \u003d\n+        conf.getClass(MRConfig.RESOURCE_CALCULATOR_PROCESS_TREE,\n+            null, ResourceCalculatorProcessTree.class);\n+    pTree \u003d ResourceCalculatorProcessTree\n+            .getResourceCalculatorProcessTree(System.getenv().get(\"JVM_PID\"), clazz, conf);\n+    LOG.info(\" Using ResourceCalculatorProcessTree : \" + pTree);\n+    if (pTree !\u003d null) {\n+      pTree.updateProcessTree();\n+      initCpuCumulativeTime \u003d pTree.getCumulativeCpuTime();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void initialize(JobConf job, JobID id, \n                         Reporter reporter,\n                         boolean useNewApi) throws IOException, \n                                                   ClassNotFoundException,\n                                                   InterruptedException {\n    jobContext \u003d new JobContextImpl(job, id, reporter);\n    taskContext \u003d new TaskAttemptContextImpl(job, taskId, reporter);\n    if (getState() \u003d\u003d TaskStatus.State.UNASSIGNED) {\n      setState(TaskStatus.State.RUNNING);\n    }\n    if (useNewApi) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"using new api for output committer\");\n      }\n      outputFormat \u003d\n        ReflectionUtils.newInstance(taskContext.getOutputFormatClass(), job);\n      committer \u003d outputFormat.getOutputCommitter(taskContext);\n    } else {\n      committer \u003d conf.getOutputCommitter();\n    }\n    Path outputPath \u003d FileOutputFormat.getOutputPath(conf);\n    if (outputPath !\u003d null) {\n      if ((committer instanceof FileOutputCommitter)) {\n        FileOutputFormat.setWorkOutputPath(conf, \n          ((FileOutputCommitter)committer).getTaskAttemptPath(taskContext));\n      } else {\n        FileOutputFormat.setWorkOutputPath(conf, outputPath);\n      }\n    }\n    committer.setupTask(taskContext);\n    Class\u003c? extends ResourceCalculatorProcessTree\u003e clazz \u003d\n        conf.getClass(MRConfig.RESOURCE_CALCULATOR_PROCESS_TREE,\n            null, ResourceCalculatorProcessTree.class);\n    pTree \u003d ResourceCalculatorProcessTree\n            .getResourceCalculatorProcessTree(System.getenv().get(\"JVM_PID\"), clazz, conf);\n    LOG.info(\" Using ResourceCalculatorProcessTree : \" + pTree);\n    if (pTree !\u003d null) {\n      pTree.updateProcessTree();\n      initCpuCumulativeTime \u003d pTree.getCumulativeCpuTime();\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/Task.java",
      "extendedDetails": {}
    },
    "94242c93857a06fb9c56ee571a47d6ca18f00f48": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3711. Fixed MR AM recovery so that only single selected task output is recovered and thus reduce the unnecessarily bloated recovery time. Contributed by Robert Joseph Evans.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1240413 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "03/02/12 4:04 PM",
      "commitName": "94242c93857a06fb9c56ee571a47d6ca18f00f48",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "16/01/12 10:10 PM",
      "commitNameOld": "d05e6d2671db3876756e5a55c369c189a8fcbdb7",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 17.75,
      "commitsBetweenForRepo": 113,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,41 +1,41 @@\n   public void initialize(JobConf job, JobID id, \n                          Reporter reporter,\n                          boolean useNewApi) throws IOException, \n                                                    ClassNotFoundException,\n                                                    InterruptedException {\n     jobContext \u003d new JobContextImpl(job, id, reporter);\n     taskContext \u003d new TaskAttemptContextImpl(job, taskId, reporter);\n     if (getState() \u003d\u003d TaskStatus.State.UNASSIGNED) {\n       setState(TaskStatus.State.RUNNING);\n     }\n     if (useNewApi) {\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"using new api for output committer\");\n       }\n       outputFormat \u003d\n         ReflectionUtils.newInstance(taskContext.getOutputFormatClass(), job);\n       committer \u003d outputFormat.getOutputCommitter(taskContext);\n     } else {\n       committer \u003d conf.getOutputCommitter();\n     }\n     Path outputPath \u003d FileOutputFormat.getOutputPath(conf);\n     if (outputPath !\u003d null) {\n       if ((committer instanceof FileOutputCommitter)) {\n         FileOutputFormat.setWorkOutputPath(conf, \n-          ((FileOutputCommitter)committer).getTempTaskOutputPath(taskContext));\n+          ((FileOutputCommitter)committer).getTaskAttemptPath(taskContext));\n       } else {\n         FileOutputFormat.setWorkOutputPath(conf, outputPath);\n       }\n     }\n     committer.setupTask(taskContext);\n     Class\u003c? extends ResourceCalculatorPlugin\u003e clazz \u003d\n         conf.getClass(MRConfig.RESOURCE_CALCULATOR_PLUGIN,\n             null, ResourceCalculatorPlugin.class);\n     resourceCalculator \u003d ResourceCalculatorPlugin\n             .getResourceCalculatorPlugin(clazz, conf);\n     LOG.info(\" Using ResourceCalculatorPlugin : \" + resourceCalculator);\n     if (resourceCalculator !\u003d null) {\n       initCpuCumulativeTime \u003d\n         resourceCalculator.getProcResourceValues().getCumulativeCpuTime();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void initialize(JobConf job, JobID id, \n                         Reporter reporter,\n                         boolean useNewApi) throws IOException, \n                                                   ClassNotFoundException,\n                                                   InterruptedException {\n    jobContext \u003d new JobContextImpl(job, id, reporter);\n    taskContext \u003d new TaskAttemptContextImpl(job, taskId, reporter);\n    if (getState() \u003d\u003d TaskStatus.State.UNASSIGNED) {\n      setState(TaskStatus.State.RUNNING);\n    }\n    if (useNewApi) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"using new api for output committer\");\n      }\n      outputFormat \u003d\n        ReflectionUtils.newInstance(taskContext.getOutputFormatClass(), job);\n      committer \u003d outputFormat.getOutputCommitter(taskContext);\n    } else {\n      committer \u003d conf.getOutputCommitter();\n    }\n    Path outputPath \u003d FileOutputFormat.getOutputPath(conf);\n    if (outputPath !\u003d null) {\n      if ((committer instanceof FileOutputCommitter)) {\n        FileOutputFormat.setWorkOutputPath(conf, \n          ((FileOutputCommitter)committer).getTaskAttemptPath(taskContext));\n      } else {\n        FileOutputFormat.setWorkOutputPath(conf, outputPath);\n      }\n    }\n    committer.setupTask(taskContext);\n    Class\u003c? extends ResourceCalculatorPlugin\u003e clazz \u003d\n        conf.getClass(MRConfig.RESOURCE_CALCULATOR_PLUGIN,\n            null, ResourceCalculatorPlugin.class);\n    resourceCalculator \u003d ResourceCalculatorPlugin\n            .getResourceCalculatorPlugin(clazz, conf);\n    LOG.info(\" Using ResourceCalculatorPlugin : \" + resourceCalculator);\n    if (resourceCalculator !\u003d null) {\n      initCpuCumulativeTime \u003d\n        resourceCalculator.getProcResourceValues().getCumulativeCpuTime();\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/Task.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void initialize(JobConf job, JobID id, \n                         Reporter reporter,\n                         boolean useNewApi) throws IOException, \n                                                   ClassNotFoundException,\n                                                   InterruptedException {\n    jobContext \u003d new JobContextImpl(job, id, reporter);\n    taskContext \u003d new TaskAttemptContextImpl(job, taskId, reporter);\n    if (getState() \u003d\u003d TaskStatus.State.UNASSIGNED) {\n      setState(TaskStatus.State.RUNNING);\n    }\n    if (useNewApi) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"using new api for output committer\");\n      }\n      outputFormat \u003d\n        ReflectionUtils.newInstance(taskContext.getOutputFormatClass(), job);\n      committer \u003d outputFormat.getOutputCommitter(taskContext);\n    } else {\n      committer \u003d conf.getOutputCommitter();\n    }\n    Path outputPath \u003d FileOutputFormat.getOutputPath(conf);\n    if (outputPath !\u003d null) {\n      if ((committer instanceof FileOutputCommitter)) {\n        FileOutputFormat.setWorkOutputPath(conf, \n          ((FileOutputCommitter)committer).getTempTaskOutputPath(taskContext));\n      } else {\n        FileOutputFormat.setWorkOutputPath(conf, outputPath);\n      }\n    }\n    committer.setupTask(taskContext);\n    Class\u003c? extends ResourceCalculatorPlugin\u003e clazz \u003d\n        conf.getClass(MRConfig.RESOURCE_CALCULATOR_PLUGIN,\n            null, ResourceCalculatorPlugin.class);\n    resourceCalculator \u003d ResourceCalculatorPlugin\n            .getResourceCalculatorPlugin(clazz, conf);\n    LOG.info(\" Using ResourceCalculatorPlugin : \" + resourceCalculator);\n    if (resourceCalculator !\u003d null) {\n      initCpuCumulativeTime \u003d\n        resourceCalculator.getProcResourceValues().getCumulativeCpuTime();\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/Task.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/Task.java",
        "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/Task.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Ymultichange(Ymovefromfile,Ybodychange)",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/08/11 4:07 AM",
          "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "17/08/11 8:02 PM",
          "commitNameOld": "dd86860633d2ed64705b669a75bf318442ed6225",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 0.34,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,41 +1,41 @@\n   public void initialize(JobConf job, JobID id, \n                          Reporter reporter,\n                          boolean useNewApi) throws IOException, \n                                                    ClassNotFoundException,\n                                                    InterruptedException {\n     jobContext \u003d new JobContextImpl(job, id, reporter);\n     taskContext \u003d new TaskAttemptContextImpl(job, taskId, reporter);\n     if (getState() \u003d\u003d TaskStatus.State.UNASSIGNED) {\n       setState(TaskStatus.State.RUNNING);\n     }\n     if (useNewApi) {\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"using new api for output committer\");\n       }\n       outputFormat \u003d\n         ReflectionUtils.newInstance(taskContext.getOutputFormatClass(), job);\n       committer \u003d outputFormat.getOutputCommitter(taskContext);\n     } else {\n       committer \u003d conf.getOutputCommitter();\n     }\n     Path outputPath \u003d FileOutputFormat.getOutputPath(conf);\n     if (outputPath !\u003d null) {\n       if ((committer instanceof FileOutputCommitter)) {\n         FileOutputFormat.setWorkOutputPath(conf, \n           ((FileOutputCommitter)committer).getTempTaskOutputPath(taskContext));\n       } else {\n         FileOutputFormat.setWorkOutputPath(conf, outputPath);\n       }\n     }\n     committer.setupTask(taskContext);\n     Class\u003c? extends ResourceCalculatorPlugin\u003e clazz \u003d\n-        conf.getClass(TTConfig.TT_RESOURCE_CALCULATOR_PLUGIN,\n+        conf.getClass(MRConfig.RESOURCE_CALCULATOR_PLUGIN,\n             null, ResourceCalculatorPlugin.class);\n     resourceCalculator \u003d ResourceCalculatorPlugin\n             .getResourceCalculatorPlugin(clazz, conf);\n     LOG.info(\" Using ResourceCalculatorPlugin : \" + resourceCalculator);\n     if (resourceCalculator !\u003d null) {\n       initCpuCumulativeTime \u003d\n         resourceCalculator.getProcResourceValues().getCumulativeCpuTime();\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void initialize(JobConf job, JobID id, \n                         Reporter reporter,\n                         boolean useNewApi) throws IOException, \n                                                   ClassNotFoundException,\n                                                   InterruptedException {\n    jobContext \u003d new JobContextImpl(job, id, reporter);\n    taskContext \u003d new TaskAttemptContextImpl(job, taskId, reporter);\n    if (getState() \u003d\u003d TaskStatus.State.UNASSIGNED) {\n      setState(TaskStatus.State.RUNNING);\n    }\n    if (useNewApi) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"using new api for output committer\");\n      }\n      outputFormat \u003d\n        ReflectionUtils.newInstance(taskContext.getOutputFormatClass(), job);\n      committer \u003d outputFormat.getOutputCommitter(taskContext);\n    } else {\n      committer \u003d conf.getOutputCommitter();\n    }\n    Path outputPath \u003d FileOutputFormat.getOutputPath(conf);\n    if (outputPath !\u003d null) {\n      if ((committer instanceof FileOutputCommitter)) {\n        FileOutputFormat.setWorkOutputPath(conf, \n          ((FileOutputCommitter)committer).getTempTaskOutputPath(taskContext));\n      } else {\n        FileOutputFormat.setWorkOutputPath(conf, outputPath);\n      }\n    }\n    committer.setupTask(taskContext);\n    Class\u003c? extends ResourceCalculatorPlugin\u003e clazz \u003d\n        conf.getClass(MRConfig.RESOURCE_CALCULATOR_PLUGIN,\n            null, ResourceCalculatorPlugin.class);\n    resourceCalculator \u003d ResourceCalculatorPlugin\n            .getResourceCalculatorPlugin(clazz, conf);\n    LOG.info(\" Using ResourceCalculatorPlugin : \" + resourceCalculator);\n    if (resourceCalculator !\u003d null) {\n      initCpuCumulativeTime \u003d\n        resourceCalculator.getProcResourceValues().getCumulativeCpuTime();\n    }\n  }",
          "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/Task.java",
          "extendedDetails": {
            "oldPath": "mapreduce/src/java/org/apache/hadoop/mapred/Task.java",
            "newPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/Task.java",
            "oldMethodName": "initialize",
            "newMethodName": "initialize"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/08/11 4:07 AM",
          "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "17/08/11 8:02 PM",
          "commitNameOld": "dd86860633d2ed64705b669a75bf318442ed6225",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 0.34,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,41 +1,41 @@\n   public void initialize(JobConf job, JobID id, \n                          Reporter reporter,\n                          boolean useNewApi) throws IOException, \n                                                    ClassNotFoundException,\n                                                    InterruptedException {\n     jobContext \u003d new JobContextImpl(job, id, reporter);\n     taskContext \u003d new TaskAttemptContextImpl(job, taskId, reporter);\n     if (getState() \u003d\u003d TaskStatus.State.UNASSIGNED) {\n       setState(TaskStatus.State.RUNNING);\n     }\n     if (useNewApi) {\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"using new api for output committer\");\n       }\n       outputFormat \u003d\n         ReflectionUtils.newInstance(taskContext.getOutputFormatClass(), job);\n       committer \u003d outputFormat.getOutputCommitter(taskContext);\n     } else {\n       committer \u003d conf.getOutputCommitter();\n     }\n     Path outputPath \u003d FileOutputFormat.getOutputPath(conf);\n     if (outputPath !\u003d null) {\n       if ((committer instanceof FileOutputCommitter)) {\n         FileOutputFormat.setWorkOutputPath(conf, \n           ((FileOutputCommitter)committer).getTempTaskOutputPath(taskContext));\n       } else {\n         FileOutputFormat.setWorkOutputPath(conf, outputPath);\n       }\n     }\n     committer.setupTask(taskContext);\n     Class\u003c? extends ResourceCalculatorPlugin\u003e clazz \u003d\n-        conf.getClass(TTConfig.TT_RESOURCE_CALCULATOR_PLUGIN,\n+        conf.getClass(MRConfig.RESOURCE_CALCULATOR_PLUGIN,\n             null, ResourceCalculatorPlugin.class);\n     resourceCalculator \u003d ResourceCalculatorPlugin\n             .getResourceCalculatorPlugin(clazz, conf);\n     LOG.info(\" Using ResourceCalculatorPlugin : \" + resourceCalculator);\n     if (resourceCalculator !\u003d null) {\n       initCpuCumulativeTime \u003d\n         resourceCalculator.getProcResourceValues().getCumulativeCpuTime();\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void initialize(JobConf job, JobID id, \n                         Reporter reporter,\n                         boolean useNewApi) throws IOException, \n                                                   ClassNotFoundException,\n                                                   InterruptedException {\n    jobContext \u003d new JobContextImpl(job, id, reporter);\n    taskContext \u003d new TaskAttemptContextImpl(job, taskId, reporter);\n    if (getState() \u003d\u003d TaskStatus.State.UNASSIGNED) {\n      setState(TaskStatus.State.RUNNING);\n    }\n    if (useNewApi) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"using new api for output committer\");\n      }\n      outputFormat \u003d\n        ReflectionUtils.newInstance(taskContext.getOutputFormatClass(), job);\n      committer \u003d outputFormat.getOutputCommitter(taskContext);\n    } else {\n      committer \u003d conf.getOutputCommitter();\n    }\n    Path outputPath \u003d FileOutputFormat.getOutputPath(conf);\n    if (outputPath !\u003d null) {\n      if ((committer instanceof FileOutputCommitter)) {\n        FileOutputFormat.setWorkOutputPath(conf, \n          ((FileOutputCommitter)committer).getTempTaskOutputPath(taskContext));\n      } else {\n        FileOutputFormat.setWorkOutputPath(conf, outputPath);\n      }\n    }\n    committer.setupTask(taskContext);\n    Class\u003c? extends ResourceCalculatorPlugin\u003e clazz \u003d\n        conf.getClass(MRConfig.RESOURCE_CALCULATOR_PLUGIN,\n            null, ResourceCalculatorPlugin.class);\n    resourceCalculator \u003d ResourceCalculatorPlugin\n            .getResourceCalculatorPlugin(clazz, conf);\n    LOG.info(\" Using ResourceCalculatorPlugin : \" + resourceCalculator);\n    if (resourceCalculator !\u003d null) {\n      initCpuCumulativeTime \u003d\n        resourceCalculator.getProcResourceValues().getCumulativeCpuTime();\n    }\n  }",
          "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/Task.java",
          "extendedDetails": {}
        }
      ]
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,41 @@\n+  public void initialize(JobConf job, JobID id, \n+                         Reporter reporter,\n+                         boolean useNewApi) throws IOException, \n+                                                   ClassNotFoundException,\n+                                                   InterruptedException {\n+    jobContext \u003d new JobContextImpl(job, id, reporter);\n+    taskContext \u003d new TaskAttemptContextImpl(job, taskId, reporter);\n+    if (getState() \u003d\u003d TaskStatus.State.UNASSIGNED) {\n+      setState(TaskStatus.State.RUNNING);\n+    }\n+    if (useNewApi) {\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(\"using new api for output committer\");\n+      }\n+      outputFormat \u003d\n+        ReflectionUtils.newInstance(taskContext.getOutputFormatClass(), job);\n+      committer \u003d outputFormat.getOutputCommitter(taskContext);\n+    } else {\n+      committer \u003d conf.getOutputCommitter();\n+    }\n+    Path outputPath \u003d FileOutputFormat.getOutputPath(conf);\n+    if (outputPath !\u003d null) {\n+      if ((committer instanceof FileOutputCommitter)) {\n+        FileOutputFormat.setWorkOutputPath(conf, \n+          ((FileOutputCommitter)committer).getTempTaskOutputPath(taskContext));\n+      } else {\n+        FileOutputFormat.setWorkOutputPath(conf, outputPath);\n+      }\n+    }\n+    committer.setupTask(taskContext);\n+    Class\u003c? extends ResourceCalculatorPlugin\u003e clazz \u003d\n+        conf.getClass(TTConfig.TT_RESOURCE_CALCULATOR_PLUGIN,\n+            null, ResourceCalculatorPlugin.class);\n+    resourceCalculator \u003d ResourceCalculatorPlugin\n+            .getResourceCalculatorPlugin(clazz, conf);\n+    LOG.info(\" Using ResourceCalculatorPlugin : \" + resourceCalculator);\n+    if (resourceCalculator !\u003d null) {\n+      initCpuCumulativeTime \u003d\n+        resourceCalculator.getProcResourceValues().getCumulativeCpuTime();\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void initialize(JobConf job, JobID id, \n                         Reporter reporter,\n                         boolean useNewApi) throws IOException, \n                                                   ClassNotFoundException,\n                                                   InterruptedException {\n    jobContext \u003d new JobContextImpl(job, id, reporter);\n    taskContext \u003d new TaskAttemptContextImpl(job, taskId, reporter);\n    if (getState() \u003d\u003d TaskStatus.State.UNASSIGNED) {\n      setState(TaskStatus.State.RUNNING);\n    }\n    if (useNewApi) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"using new api for output committer\");\n      }\n      outputFormat \u003d\n        ReflectionUtils.newInstance(taskContext.getOutputFormatClass(), job);\n      committer \u003d outputFormat.getOutputCommitter(taskContext);\n    } else {\n      committer \u003d conf.getOutputCommitter();\n    }\n    Path outputPath \u003d FileOutputFormat.getOutputPath(conf);\n    if (outputPath !\u003d null) {\n      if ((committer instanceof FileOutputCommitter)) {\n        FileOutputFormat.setWorkOutputPath(conf, \n          ((FileOutputCommitter)committer).getTempTaskOutputPath(taskContext));\n      } else {\n        FileOutputFormat.setWorkOutputPath(conf, outputPath);\n      }\n    }\n    committer.setupTask(taskContext);\n    Class\u003c? extends ResourceCalculatorPlugin\u003e clazz \u003d\n        conf.getClass(TTConfig.TT_RESOURCE_CALCULATOR_PLUGIN,\n            null, ResourceCalculatorPlugin.class);\n    resourceCalculator \u003d ResourceCalculatorPlugin\n            .getResourceCalculatorPlugin(clazz, conf);\n    LOG.info(\" Using ResourceCalculatorPlugin : \" + resourceCalculator);\n    if (resourceCalculator !\u003d null) {\n      initCpuCumulativeTime \u003d\n        resourceCalculator.getProcResourceValues().getCumulativeCpuTime();\n    }\n  }",
      "path": "mapreduce/src/java/org/apache/hadoop/mapred/Task.java"
    }
  }
}