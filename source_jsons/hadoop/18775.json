{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FrameworkUploader.java",
  "functionName": "parseLists",
  "functionId": "parseLists",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-uploader/src/main/java/org/apache/hadoop/mapred/uploader/FrameworkUploader.java",
  "functionStartLine": 356,
  "functionEndLine": 379,
  "numCommitsSeen": 12,
  "timeTaken": 772,
  "changeHistory": [
    "3b78607a02f3a81ad730975ecdfa35967413271d"
  ],
  "changeHistoryShort": {
    "3b78607a02f3a81ad730975ecdfa35967413271d": "Yintroduced"
  },
  "changeHistoryDetails": {
    "3b78607a02f3a81ad730975ecdfa35967413271d": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-6994. Uploader tool for Distributed Cache Deploy code changes  (miklos.szegedi@cloudera.com via rkanter)\n",
      "commitDate": "01/12/17 12:12 PM",
      "commitName": "3b78607a02f3a81ad730975ecdfa35967413271d",
      "commitAuthor": "Robert Kanter",
      "diff": "@@ -0,0 +1,24 @@\n+  private void parseLists() throws UploaderException {\n+    Map\u003cString, String\u003e env \u003d System.getenv();\n+    for(Map.Entry\u003cString, String\u003e item : env.entrySet()) {\n+      LOG.info(\"Environment \" + item.getKey() + \" \" + item.getValue());\n+    }\n+    String[] whiteListItems \u003d StringUtils.split(whitelist);\n+    for (String pattern : whiteListItems) {\n+      String expandedPattern \u003d\n+          expandEnvironmentVariables(pattern, env);\n+      Pattern compiledPattern \u003d\n+          Pattern.compile(\"^\" + expandedPattern + \"$\");\n+      LOG.info(\"Whitelisted \" + compiledPattern.toString());\n+      whitelistedFiles.add(compiledPattern);\n+    }\n+    String[] blacklistItems \u003d StringUtils.split(blacklist);\n+    for (String pattern : blacklistItems) {\n+      String expandedPattern \u003d\n+          expandEnvironmentVariables(pattern, env);\n+      Pattern compiledPattern \u003d\n+          Pattern.compile(\"^\" + expandedPattern + \"$\");\n+      LOG.info(\"Blacklisted \" + compiledPattern.toString());\n+      blacklistedFiles.add(compiledPattern);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void parseLists() throws UploaderException {\n    Map\u003cString, String\u003e env \u003d System.getenv();\n    for(Map.Entry\u003cString, String\u003e item : env.entrySet()) {\n      LOG.info(\"Environment \" + item.getKey() + \" \" + item.getValue());\n    }\n    String[] whiteListItems \u003d StringUtils.split(whitelist);\n    for (String pattern : whiteListItems) {\n      String expandedPattern \u003d\n          expandEnvironmentVariables(pattern, env);\n      Pattern compiledPattern \u003d\n          Pattern.compile(\"^\" + expandedPattern + \"$\");\n      LOG.info(\"Whitelisted \" + compiledPattern.toString());\n      whitelistedFiles.add(compiledPattern);\n    }\n    String[] blacklistItems \u003d StringUtils.split(blacklist);\n    for (String pattern : blacklistItems) {\n      String expandedPattern \u003d\n          expandEnvironmentVariables(pattern, env);\n      Pattern compiledPattern \u003d\n          Pattern.compile(\"^\" + expandedPattern + \"$\");\n      LOG.info(\"Blacklisted \" + compiledPattern.toString());\n      blacklistedFiles.add(compiledPattern);\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-uploader/src/main/java/org/apache/hadoop/mapred/uploader/FrameworkUploader.java"
    }
  }
}