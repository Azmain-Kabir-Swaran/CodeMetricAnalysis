{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ApplicationEntityReader.java",
  "functionName": "getResults",
  "functionId": "getResults___hbaseConf-Configuration__conn-Connection__filterList-FilterList",
  "sourceFilePath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-client/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/reader/ApplicationEntityReader.java",
  "functionStartLine": 381,
  "functionEndLine": 433,
  "numCommitsSeen": 30,
  "timeTaken": 6804,
  "changeHistory": [
    "9af30d46c6e82332a8eda20cb3eb5f987e25e7a2",
    "70078e91e3287aad51f6ddf6acd9ed75e7c6760d",
    "c3bd8d6ad3e30c08865cc1a5f374d1d2a485f844",
    "5e0acee75e259c4e241c89b8227efb85f6ea953a",
    "6f65cf27bb5bfdc03adf9db6c8a72f80d0aee0bd",
    "b01514f65bc6090a50a583f67d1ecb5d74b6d276",
    "892b193bd77c15932b4c084c1d525b7017def0d4",
    "c81a2e1d197b9995103797348cb5cc4bcf9a015b",
    "960af7d4717b8a8949d0b2e43949e7daab45aa88",
    "9cb1287e9b8425f91de925f411c3c2a8fa9fe2a3",
    "88f02941144824187b70fa2aaf0c6d90bcb77d8f",
    "8ef546c1ee9fce0b171813547253374d268566ba",
    "1f710484e5b8ab4d5c67379c012004e8a4242d15",
    "0f44b5508d2ffcae08f130b6535a9832d37e2b38",
    "708fa8b1ae85b6efda318368bc0c0ba02d4958c8",
    "10fa6da7d8a6013698767c6136ae20f0e04415e9"
  ],
  "changeHistoryShort": {
    "9af30d46c6e82332a8eda20cb3eb5f987e25e7a2": "Yfilerename",
    "70078e91e3287aad51f6ddf6acd9ed75e7c6760d": "Ybodychange",
    "c3bd8d6ad3e30c08865cc1a5f374d1d2a485f844": "Ybodychange",
    "5e0acee75e259c4e241c89b8227efb85f6ea953a": "Ybodychange",
    "6f65cf27bb5bfdc03adf9db6c8a72f80d0aee0bd": "Ybodychange",
    "b01514f65bc6090a50a583f67d1ecb5d74b6d276": "Yfilerename",
    "892b193bd77c15932b4c084c1d525b7017def0d4": "Ybodychange",
    "c81a2e1d197b9995103797348cb5cc4bcf9a015b": "Ybodychange",
    "960af7d4717b8a8949d0b2e43949e7daab45aa88": "Ybodychange",
    "9cb1287e9b8425f91de925f411c3c2a8fa9fe2a3": "Ybodychange",
    "88f02941144824187b70fa2aaf0c6d90bcb77d8f": "Yfilerename",
    "8ef546c1ee9fce0b171813547253374d268566ba": "Ybodychange",
    "1f710484e5b8ab4d5c67379c012004e8a4242d15": "Ymultichange(Yparameterchange,Ybodychange)",
    "0f44b5508d2ffcae08f130b6535a9832d37e2b38": "Ybodychange",
    "708fa8b1ae85b6efda318368bc0c0ba02d4958c8": "Ymultichange(Yreturntypechange,Ybodychange)",
    "10fa6da7d8a6013698767c6136ae20f0e04415e9": "Yintroduced"
  },
  "changeHistoryDetails": {
    "9af30d46c6e82332a8eda20cb3eb5f987e25e7a2": {
      "type": "Yfilerename",
      "commitMessage": "YARN-7919. Refactor timelineservice-hbase module into submodules. Contributed by Haibo Chen.\n",
      "commitDate": "17/02/18 7:00 AM",
      "commitName": "9af30d46c6e82332a8eda20cb3eb5f987e25e7a2",
      "commitAuthor": "Rohith Sharma K S",
      "commitDateOld": "17/02/18 3:24 AM",
      "commitNameOld": "a1e56a62863d8d494af309ec5f476c4b7e4d5ef9",
      "commitAuthorOld": "Arun Suresh",
      "daysBetweenCommits": 0.15,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  protected ResultScanner getResults(Configuration hbaseConf,\n      Connection conn, FilterList filterList) throws IOException {\n    Scan scan \u003d new Scan();\n    TimelineReaderContext context \u003d getContext();\n    RowKeyPrefix\u003cApplicationRowKey\u003e applicationRowKeyPrefix \u003d null;\n\n    // Whether or not flowRunID is null doesn\u0027t matter, the\n    // ApplicationRowKeyPrefix will do the right thing.\n    // default mode, will always scans from beginning of entity type.\n    if (getFilters().getFromId() \u003d\u003d null) {\n      applicationRowKeyPrefix \u003d new ApplicationRowKeyPrefix(\n          context.getClusterId(), context.getUserId(), context.getFlowName(),\n          context.getFlowRunId());\n      scan.setRowPrefixFilter(applicationRowKeyPrefix.getRowKeyPrefix());\n    } else {\n      ApplicationRowKey applicationRowKey \u003d null;\n      try {\n        applicationRowKey \u003d\n            ApplicationRowKey.parseRowKeyFromString(getFilters().getFromId());\n      } catch (IllegalArgumentException e) {\n        throw new BadRequestException(\"Invalid filter fromid is provided.\");\n      }\n      if (!context.getClusterId().equals(applicationRowKey.getClusterId())) {\n        throw new BadRequestException(\n            \"fromid doesn\u0027t belong to clusterId\u003d\" + context.getClusterId());\n      }\n\n      // set start row\n      scan.setStartRow(applicationRowKey.getRowKey());\n\n      // get the bytes for stop row\n      applicationRowKeyPrefix \u003d new ApplicationRowKeyPrefix(\n          context.getClusterId(), context.getUserId(), context.getFlowName(),\n          context.getFlowRunId());\n\n      // set stop row\n      scan.setStopRow(\n          HBaseTimelineStorageUtils.calculateTheClosestNextRowKeyForPrefix(\n              applicationRowKeyPrefix.getRowKeyPrefix()));\n    }\n\n    FilterList newList \u003d new FilterList();\n    newList.addFilter(new PageFilter(getFilters().getLimit()));\n    if (filterList !\u003d null \u0026\u0026 !filterList.getFilters().isEmpty()) {\n      newList.addFilter(filterList);\n    }\n    scan.setFilter(newList);\n\n    // Set time range for metric values.\n    setMetricsTimeRange(scan);\n    scan.setMaxVersions(getDataToRetrieve().getMetricsLimit());\n    return getTable().getResultScanner(hbaseConf, conn, scan);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-client/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/reader/ApplicationEntityReader.java",
      "extendedDetails": {
        "oldPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/reader/ApplicationEntityReader.java",
        "newPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-client/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/reader/ApplicationEntityReader.java"
      }
    },
    "70078e91e3287aad51f6ddf6acd9ed75e7c6760d": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4455. Support fetching metrics by time range. Contributed by Varun Saxena.\n",
      "commitDate": "29/08/17 10:59 PM",
      "commitName": "70078e91e3287aad51f6ddf6acd9ed75e7c6760d",
      "commitAuthor": "Rohith Sharma K S",
      "commitDateOld": "29/08/17 10:59 PM",
      "commitNameOld": "c3bd8d6ad3e30c08865cc1a5f374d1d2a485f844",
      "commitAuthorOld": "Varun Saxena",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 11,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,50 +1,53 @@\n   protected ResultScanner getResults(Configuration hbaseConf,\n       Connection conn, FilterList filterList) throws IOException {\n     Scan scan \u003d new Scan();\n     TimelineReaderContext context \u003d getContext();\n     RowKeyPrefix\u003cApplicationRowKey\u003e applicationRowKeyPrefix \u003d null;\n \n     // Whether or not flowRunID is null doesn\u0027t matter, the\n     // ApplicationRowKeyPrefix will do the right thing.\n     // default mode, will always scans from beginning of entity type.\n     if (getFilters().getFromId() \u003d\u003d null) {\n       applicationRowKeyPrefix \u003d new ApplicationRowKeyPrefix(\n           context.getClusterId(), context.getUserId(), context.getFlowName(),\n           context.getFlowRunId());\n       scan.setRowPrefixFilter(applicationRowKeyPrefix.getRowKeyPrefix());\n     } else {\n       ApplicationRowKey applicationRowKey \u003d null;\n       try {\n         applicationRowKey \u003d\n             ApplicationRowKey.parseRowKeyFromString(getFilters().getFromId());\n       } catch (IllegalArgumentException e) {\n         throw new BadRequestException(\"Invalid filter fromid is provided.\");\n       }\n       if (!context.getClusterId().equals(applicationRowKey.getClusterId())) {\n         throw new BadRequestException(\n             \"fromid doesn\u0027t belong to clusterId\u003d\" + context.getClusterId());\n       }\n \n       // set start row\n       scan.setStartRow(applicationRowKey.getRowKey());\n \n       // get the bytes for stop row\n       applicationRowKeyPrefix \u003d new ApplicationRowKeyPrefix(\n           context.getClusterId(), context.getUserId(), context.getFlowName(),\n           context.getFlowRunId());\n \n       // set stop row\n       scan.setStopRow(\n           HBaseTimelineStorageUtils.calculateTheClosestNextRowKeyForPrefix(\n               applicationRowKeyPrefix.getRowKeyPrefix()));\n     }\n \n     FilterList newList \u003d new FilterList();\n     newList.addFilter(new PageFilter(getFilters().getLimit()));\n     if (filterList !\u003d null \u0026\u0026 !filterList.getFilters().isEmpty()) {\n       newList.addFilter(filterList);\n     }\n     scan.setFilter(newList);\n+\n+    // Set time range for metric values.\n+    setMetricsTimeRange(scan);\n     scan.setMaxVersions(getDataToRetrieve().getMetricsLimit());\n     return getTable().getResultScanner(hbaseConf, conn, scan);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected ResultScanner getResults(Configuration hbaseConf,\n      Connection conn, FilterList filterList) throws IOException {\n    Scan scan \u003d new Scan();\n    TimelineReaderContext context \u003d getContext();\n    RowKeyPrefix\u003cApplicationRowKey\u003e applicationRowKeyPrefix \u003d null;\n\n    // Whether or not flowRunID is null doesn\u0027t matter, the\n    // ApplicationRowKeyPrefix will do the right thing.\n    // default mode, will always scans from beginning of entity type.\n    if (getFilters().getFromId() \u003d\u003d null) {\n      applicationRowKeyPrefix \u003d new ApplicationRowKeyPrefix(\n          context.getClusterId(), context.getUserId(), context.getFlowName(),\n          context.getFlowRunId());\n      scan.setRowPrefixFilter(applicationRowKeyPrefix.getRowKeyPrefix());\n    } else {\n      ApplicationRowKey applicationRowKey \u003d null;\n      try {\n        applicationRowKey \u003d\n            ApplicationRowKey.parseRowKeyFromString(getFilters().getFromId());\n      } catch (IllegalArgumentException e) {\n        throw new BadRequestException(\"Invalid filter fromid is provided.\");\n      }\n      if (!context.getClusterId().equals(applicationRowKey.getClusterId())) {\n        throw new BadRequestException(\n            \"fromid doesn\u0027t belong to clusterId\u003d\" + context.getClusterId());\n      }\n\n      // set start row\n      scan.setStartRow(applicationRowKey.getRowKey());\n\n      // get the bytes for stop row\n      applicationRowKeyPrefix \u003d new ApplicationRowKeyPrefix(\n          context.getClusterId(), context.getUserId(), context.getFlowName(),\n          context.getFlowRunId());\n\n      // set stop row\n      scan.setStopRow(\n          HBaseTimelineStorageUtils.calculateTheClosestNextRowKeyForPrefix(\n              applicationRowKeyPrefix.getRowKeyPrefix()));\n    }\n\n    FilterList newList \u003d new FilterList();\n    newList.addFilter(new PageFilter(getFilters().getLimit()));\n    if (filterList !\u003d null \u0026\u0026 !filterList.getFilters().isEmpty()) {\n      newList.addFilter(filterList);\n    }\n    scan.setFilter(newList);\n\n    // Set time range for metric values.\n    setMetricsTimeRange(scan);\n    scan.setMaxVersions(getDataToRetrieve().getMetricsLimit());\n    return getTable().getResultScanner(hbaseConf, conn, scan);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/reader/ApplicationEntityReader.java",
      "extendedDetails": {}
    },
    "c3bd8d6ad3e30c08865cc1a5f374d1d2a485f844": {
      "type": "Ybodychange",
      "commitMessage": "YARN-6256. Add FROM_ID info key for timeline entities in reader response (Rohith Sharma K S via Varun Saxena)\n",
      "commitDate": "29/08/17 10:59 PM",
      "commitName": "c3bd8d6ad3e30c08865cc1a5f374d1d2a485f844",
      "commitAuthor": "Varun Saxena",
      "commitDateOld": "29/08/17 10:59 PM",
      "commitNameOld": "5e0acee75e259c4e241c89b8227efb85f6ea953a",
      "commitAuthorOld": "Varun Saxena",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 7,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,51 +1,50 @@\n   protected ResultScanner getResults(Configuration hbaseConf,\n       Connection conn, FilterList filterList) throws IOException {\n     Scan scan \u003d new Scan();\n     TimelineReaderContext context \u003d getContext();\n     RowKeyPrefix\u003cApplicationRowKey\u003e applicationRowKeyPrefix \u003d null;\n \n     // Whether or not flowRunID is null doesn\u0027t matter, the\n     // ApplicationRowKeyPrefix will do the right thing.\n     // default mode, will always scans from beginning of entity type.\n     if (getFilters().getFromId() \u003d\u003d null) {\n       applicationRowKeyPrefix \u003d new ApplicationRowKeyPrefix(\n           context.getClusterId(), context.getUserId(), context.getFlowName(),\n           context.getFlowRunId());\n       scan.setRowPrefixFilter(applicationRowKeyPrefix.getRowKeyPrefix());\n     } else {\n-      Long flowRunId \u003d context.getFlowRunId();\n-      if (flowRunId \u003d\u003d null) {\n-        AppToFlowRowKey appToFlowRowKey \u003d new AppToFlowRowKey(\n-            getFilters().getFromId());\n-        FlowContext flowContext \u003d lookupFlowContext(appToFlowRowKey,\n-            context.getClusterId(), hbaseConf, conn);\n-        flowRunId \u003d flowContext.getFlowRunId();\n+      ApplicationRowKey applicationRowKey \u003d null;\n+      try {\n+        applicationRowKey \u003d\n+            ApplicationRowKey.parseRowKeyFromString(getFilters().getFromId());\n+      } catch (IllegalArgumentException e) {\n+        throw new BadRequestException(\"Invalid filter fromid is provided.\");\n       }\n-\n-      ApplicationRowKey applicationRowKey \u003d\n-          new ApplicationRowKey(context.getClusterId(), context.getUserId(),\n-              context.getFlowName(), flowRunId, getFilters().getFromId());\n+      if (!context.getClusterId().equals(applicationRowKey.getClusterId())) {\n+        throw new BadRequestException(\n+            \"fromid doesn\u0027t belong to clusterId\u003d\" + context.getClusterId());\n+      }\n \n       // set start row\n       scan.setStartRow(applicationRowKey.getRowKey());\n \n       // get the bytes for stop row\n       applicationRowKeyPrefix \u003d new ApplicationRowKeyPrefix(\n           context.getClusterId(), context.getUserId(), context.getFlowName(),\n           context.getFlowRunId());\n \n       // set stop row\n       scan.setStopRow(\n           HBaseTimelineStorageUtils.calculateTheClosestNextRowKeyForPrefix(\n               applicationRowKeyPrefix.getRowKeyPrefix()));\n     }\n \n     FilterList newList \u003d new FilterList();\n     newList.addFilter(new PageFilter(getFilters().getLimit()));\n     if (filterList !\u003d null \u0026\u0026 !filterList.getFilters().isEmpty()) {\n       newList.addFilter(filterList);\n     }\n     scan.setFilter(newList);\n     scan.setMaxVersions(getDataToRetrieve().getMetricsLimit());\n     return getTable().getResultScanner(hbaseConf, conn, scan);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected ResultScanner getResults(Configuration hbaseConf,\n      Connection conn, FilterList filterList) throws IOException {\n    Scan scan \u003d new Scan();\n    TimelineReaderContext context \u003d getContext();\n    RowKeyPrefix\u003cApplicationRowKey\u003e applicationRowKeyPrefix \u003d null;\n\n    // Whether or not flowRunID is null doesn\u0027t matter, the\n    // ApplicationRowKeyPrefix will do the right thing.\n    // default mode, will always scans from beginning of entity type.\n    if (getFilters().getFromId() \u003d\u003d null) {\n      applicationRowKeyPrefix \u003d new ApplicationRowKeyPrefix(\n          context.getClusterId(), context.getUserId(), context.getFlowName(),\n          context.getFlowRunId());\n      scan.setRowPrefixFilter(applicationRowKeyPrefix.getRowKeyPrefix());\n    } else {\n      ApplicationRowKey applicationRowKey \u003d null;\n      try {\n        applicationRowKey \u003d\n            ApplicationRowKey.parseRowKeyFromString(getFilters().getFromId());\n      } catch (IllegalArgumentException e) {\n        throw new BadRequestException(\"Invalid filter fromid is provided.\");\n      }\n      if (!context.getClusterId().equals(applicationRowKey.getClusterId())) {\n        throw new BadRequestException(\n            \"fromid doesn\u0027t belong to clusterId\u003d\" + context.getClusterId());\n      }\n\n      // set start row\n      scan.setStartRow(applicationRowKey.getRowKey());\n\n      // get the bytes for stop row\n      applicationRowKeyPrefix \u003d new ApplicationRowKeyPrefix(\n          context.getClusterId(), context.getUserId(), context.getFlowName(),\n          context.getFlowRunId());\n\n      // set stop row\n      scan.setStopRow(\n          HBaseTimelineStorageUtils.calculateTheClosestNextRowKeyForPrefix(\n              applicationRowKeyPrefix.getRowKeyPrefix()));\n    }\n\n    FilterList newList \u003d new FilterList();\n    newList.addFilter(new PageFilter(getFilters().getLimit()));\n    if (filterList !\u003d null \u0026\u0026 !filterList.getFilters().isEmpty()) {\n      newList.addFilter(filterList);\n    }\n    scan.setFilter(newList);\n    scan.setMaxVersions(getDataToRetrieve().getMetricsLimit());\n    return getTable().getResultScanner(hbaseConf, conn, scan);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/reader/ApplicationEntityReader.java",
      "extendedDetails": {}
    },
    "5e0acee75e259c4e241c89b8227efb85f6ea953a": {
      "type": "Ybodychange",
      "commitMessage": "Addendum for YARN-6064. Support fromId for flowRuns and flow/flowRun apps REST API\u0027s\n",
      "commitDate": "29/08/17 10:59 PM",
      "commitName": "5e0acee75e259c4e241c89b8227efb85f6ea953a",
      "commitAuthor": "Varun Saxena",
      "commitDateOld": "29/08/17 10:59 PM",
      "commitNameOld": "6f65cf27bb5bfdc03adf9db6c8a72f80d0aee0bd",
      "commitAuthorOld": "Varun Saxena",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,51 +1,51 @@\n   protected ResultScanner getResults(Configuration hbaseConf,\n       Connection conn, FilterList filterList) throws IOException {\n     Scan scan \u003d new Scan();\n     TimelineReaderContext context \u003d getContext();\n     RowKeyPrefix\u003cApplicationRowKey\u003e applicationRowKeyPrefix \u003d null;\n \n     // Whether or not flowRunID is null doesn\u0027t matter, the\n     // ApplicationRowKeyPrefix will do the right thing.\n     // default mode, will always scans from beginning of entity type.\n     if (getFilters().getFromId() \u003d\u003d null) {\n       applicationRowKeyPrefix \u003d new ApplicationRowKeyPrefix(\n           context.getClusterId(), context.getUserId(), context.getFlowName(),\n           context.getFlowRunId());\n       scan.setRowPrefixFilter(applicationRowKeyPrefix.getRowKeyPrefix());\n     } else {\n       Long flowRunId \u003d context.getFlowRunId();\n       if (flowRunId \u003d\u003d null) {\n         AppToFlowRowKey appToFlowRowKey \u003d new AppToFlowRowKey(\n-            context.getClusterId(), getFilters().getFromId());\n-        FlowContext flowContext \u003d\n-            lookupFlowContext(appToFlowRowKey, hbaseConf, conn);\n+            getFilters().getFromId());\n+        FlowContext flowContext \u003d lookupFlowContext(appToFlowRowKey,\n+            context.getClusterId(), hbaseConf, conn);\n         flowRunId \u003d flowContext.getFlowRunId();\n       }\n \n       ApplicationRowKey applicationRowKey \u003d\n           new ApplicationRowKey(context.getClusterId(), context.getUserId(),\n               context.getFlowName(), flowRunId, getFilters().getFromId());\n \n       // set start row\n       scan.setStartRow(applicationRowKey.getRowKey());\n \n       // get the bytes for stop row\n       applicationRowKeyPrefix \u003d new ApplicationRowKeyPrefix(\n           context.getClusterId(), context.getUserId(), context.getFlowName(),\n           context.getFlowRunId());\n \n       // set stop row\n       scan.setStopRow(\n           HBaseTimelineStorageUtils.calculateTheClosestNextRowKeyForPrefix(\n               applicationRowKeyPrefix.getRowKeyPrefix()));\n     }\n \n     FilterList newList \u003d new FilterList();\n     newList.addFilter(new PageFilter(getFilters().getLimit()));\n     if (filterList !\u003d null \u0026\u0026 !filterList.getFilters().isEmpty()) {\n       newList.addFilter(filterList);\n     }\n     scan.setFilter(newList);\n     scan.setMaxVersions(getDataToRetrieve().getMetricsLimit());\n     return getTable().getResultScanner(hbaseConf, conn, scan);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected ResultScanner getResults(Configuration hbaseConf,\n      Connection conn, FilterList filterList) throws IOException {\n    Scan scan \u003d new Scan();\n    TimelineReaderContext context \u003d getContext();\n    RowKeyPrefix\u003cApplicationRowKey\u003e applicationRowKeyPrefix \u003d null;\n\n    // Whether or not flowRunID is null doesn\u0027t matter, the\n    // ApplicationRowKeyPrefix will do the right thing.\n    // default mode, will always scans from beginning of entity type.\n    if (getFilters().getFromId() \u003d\u003d null) {\n      applicationRowKeyPrefix \u003d new ApplicationRowKeyPrefix(\n          context.getClusterId(), context.getUserId(), context.getFlowName(),\n          context.getFlowRunId());\n      scan.setRowPrefixFilter(applicationRowKeyPrefix.getRowKeyPrefix());\n    } else {\n      Long flowRunId \u003d context.getFlowRunId();\n      if (flowRunId \u003d\u003d null) {\n        AppToFlowRowKey appToFlowRowKey \u003d new AppToFlowRowKey(\n            getFilters().getFromId());\n        FlowContext flowContext \u003d lookupFlowContext(appToFlowRowKey,\n            context.getClusterId(), hbaseConf, conn);\n        flowRunId \u003d flowContext.getFlowRunId();\n      }\n\n      ApplicationRowKey applicationRowKey \u003d\n          new ApplicationRowKey(context.getClusterId(), context.getUserId(),\n              context.getFlowName(), flowRunId, getFilters().getFromId());\n\n      // set start row\n      scan.setStartRow(applicationRowKey.getRowKey());\n\n      // get the bytes for stop row\n      applicationRowKeyPrefix \u003d new ApplicationRowKeyPrefix(\n          context.getClusterId(), context.getUserId(), context.getFlowName(),\n          context.getFlowRunId());\n\n      // set stop row\n      scan.setStopRow(\n          HBaseTimelineStorageUtils.calculateTheClosestNextRowKeyForPrefix(\n              applicationRowKeyPrefix.getRowKeyPrefix()));\n    }\n\n    FilterList newList \u003d new FilterList();\n    newList.addFilter(new PageFilter(getFilters().getLimit()));\n    if (filterList !\u003d null \u0026\u0026 !filterList.getFilters().isEmpty()) {\n      newList.addFilter(filterList);\n    }\n    scan.setFilter(newList);\n    scan.setMaxVersions(getDataToRetrieve().getMetricsLimit());\n    return getTable().getResultScanner(hbaseConf, conn, scan);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/reader/ApplicationEntityReader.java",
      "extendedDetails": {}
    },
    "6f65cf27bb5bfdc03adf9db6c8a72f80d0aee0bd": {
      "type": "Ybodychange",
      "commitMessage": "YARN-6064. Support fromId for flowRuns and flow/flowRun apps REST API\u0027s (Rohith Sharma K S via Varun Saxena)\n",
      "commitDate": "29/08/17 10:59 PM",
      "commitName": "6f65cf27bb5bfdc03adf9db6c8a72f80d0aee0bd",
      "commitAuthor": "Varun Saxena",
      "commitDateOld": "29/08/17 10:59 PM",
      "commitNameOld": "02a9710a099fc9572122d87dd3e90c78522f5836",
      "commitAuthorOld": "Varun Saxena",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,51 @@\n   protected ResultScanner getResults(Configuration hbaseConf,\n       Connection conn, FilterList filterList) throws IOException {\n     Scan scan \u003d new Scan();\n     TimelineReaderContext context \u003d getContext();\n+    RowKeyPrefix\u003cApplicationRowKey\u003e applicationRowKeyPrefix \u003d null;\n+\n     // Whether or not flowRunID is null doesn\u0027t matter, the\n     // ApplicationRowKeyPrefix will do the right thing.\n-    RowKeyPrefix\u003cApplicationRowKey\u003e applicationRowKeyPrefix \u003d\n-        new ApplicationRowKeyPrefix(context.getClusterId(),\n-            context.getUserId(), context.getFlowName(),\n-            context.getFlowRunId());\n-    scan.setRowPrefixFilter(applicationRowKeyPrefix.getRowKeyPrefix());\n+    // default mode, will always scans from beginning of entity type.\n+    if (getFilters().getFromId() \u003d\u003d null) {\n+      applicationRowKeyPrefix \u003d new ApplicationRowKeyPrefix(\n+          context.getClusterId(), context.getUserId(), context.getFlowName(),\n+          context.getFlowRunId());\n+      scan.setRowPrefixFilter(applicationRowKeyPrefix.getRowKeyPrefix());\n+    } else {\n+      Long flowRunId \u003d context.getFlowRunId();\n+      if (flowRunId \u003d\u003d null) {\n+        AppToFlowRowKey appToFlowRowKey \u003d new AppToFlowRowKey(\n+            context.getClusterId(), getFilters().getFromId());\n+        FlowContext flowContext \u003d\n+            lookupFlowContext(appToFlowRowKey, hbaseConf, conn);\n+        flowRunId \u003d flowContext.getFlowRunId();\n+      }\n+\n+      ApplicationRowKey applicationRowKey \u003d\n+          new ApplicationRowKey(context.getClusterId(), context.getUserId(),\n+              context.getFlowName(), flowRunId, getFilters().getFromId());\n+\n+      // set start row\n+      scan.setStartRow(applicationRowKey.getRowKey());\n+\n+      // get the bytes for stop row\n+      applicationRowKeyPrefix \u003d new ApplicationRowKeyPrefix(\n+          context.getClusterId(), context.getUserId(), context.getFlowName(),\n+          context.getFlowRunId());\n+\n+      // set stop row\n+      scan.setStopRow(\n+          HBaseTimelineStorageUtils.calculateTheClosestNextRowKeyForPrefix(\n+              applicationRowKeyPrefix.getRowKeyPrefix()));\n+    }\n+\n     FilterList newList \u003d new FilterList();\n     newList.addFilter(new PageFilter(getFilters().getLimit()));\n     if (filterList !\u003d null \u0026\u0026 !filterList.getFilters().isEmpty()) {\n       newList.addFilter(filterList);\n     }\n     scan.setFilter(newList);\n     scan.setMaxVersions(getDataToRetrieve().getMetricsLimit());\n     return getTable().getResultScanner(hbaseConf, conn, scan);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected ResultScanner getResults(Configuration hbaseConf,\n      Connection conn, FilterList filterList) throws IOException {\n    Scan scan \u003d new Scan();\n    TimelineReaderContext context \u003d getContext();\n    RowKeyPrefix\u003cApplicationRowKey\u003e applicationRowKeyPrefix \u003d null;\n\n    // Whether or not flowRunID is null doesn\u0027t matter, the\n    // ApplicationRowKeyPrefix will do the right thing.\n    // default mode, will always scans from beginning of entity type.\n    if (getFilters().getFromId() \u003d\u003d null) {\n      applicationRowKeyPrefix \u003d new ApplicationRowKeyPrefix(\n          context.getClusterId(), context.getUserId(), context.getFlowName(),\n          context.getFlowRunId());\n      scan.setRowPrefixFilter(applicationRowKeyPrefix.getRowKeyPrefix());\n    } else {\n      Long flowRunId \u003d context.getFlowRunId();\n      if (flowRunId \u003d\u003d null) {\n        AppToFlowRowKey appToFlowRowKey \u003d new AppToFlowRowKey(\n            context.getClusterId(), getFilters().getFromId());\n        FlowContext flowContext \u003d\n            lookupFlowContext(appToFlowRowKey, hbaseConf, conn);\n        flowRunId \u003d flowContext.getFlowRunId();\n      }\n\n      ApplicationRowKey applicationRowKey \u003d\n          new ApplicationRowKey(context.getClusterId(), context.getUserId(),\n              context.getFlowName(), flowRunId, getFilters().getFromId());\n\n      // set start row\n      scan.setStartRow(applicationRowKey.getRowKey());\n\n      // get the bytes for stop row\n      applicationRowKeyPrefix \u003d new ApplicationRowKeyPrefix(\n          context.getClusterId(), context.getUserId(), context.getFlowName(),\n          context.getFlowRunId());\n\n      // set stop row\n      scan.setStopRow(\n          HBaseTimelineStorageUtils.calculateTheClosestNextRowKeyForPrefix(\n              applicationRowKeyPrefix.getRowKeyPrefix()));\n    }\n\n    FilterList newList \u003d new FilterList();\n    newList.addFilter(new PageFilter(getFilters().getLimit()));\n    if (filterList !\u003d null \u0026\u0026 !filterList.getFilters().isEmpty()) {\n      newList.addFilter(filterList);\n    }\n    scan.setFilter(newList);\n    scan.setMaxVersions(getDataToRetrieve().getMetricsLimit());\n    return getTable().getResultScanner(hbaseConf, conn, scan);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/reader/ApplicationEntityReader.java",
      "extendedDetails": {}
    },
    "b01514f65bc6090a50a583f67d1ecb5d74b6d276": {
      "type": "Yfilerename",
      "commitMessage": "YARN-5928. Move ATSv2 HBase backend code into a new module that is only dependent at runtime by yarn servers. Contributed by Haibo Chen.\n",
      "commitDate": "19/01/17 8:52 PM",
      "commitName": "b01514f65bc6090a50a583f67d1ecb5d74b6d276",
      "commitAuthor": "Sangjin Lee",
      "commitDateOld": "19/01/17 5:32 PM",
      "commitNameOld": "60865c8ea08053f3d6ac23f81c3376a3de3ca996",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 0.14,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  protected ResultScanner getResults(Configuration hbaseConf,\n      Connection conn, FilterList filterList) throws IOException {\n    Scan scan \u003d new Scan();\n    TimelineReaderContext context \u003d getContext();\n    // Whether or not flowRunID is null doesn\u0027t matter, the\n    // ApplicationRowKeyPrefix will do the right thing.\n    RowKeyPrefix\u003cApplicationRowKey\u003e applicationRowKeyPrefix \u003d\n        new ApplicationRowKeyPrefix(context.getClusterId(),\n            context.getUserId(), context.getFlowName(),\n            context.getFlowRunId());\n    scan.setRowPrefixFilter(applicationRowKeyPrefix.getRowKeyPrefix());\n    FilterList newList \u003d new FilterList();\n    newList.addFilter(new PageFilter(getFilters().getLimit()));\n    if (filterList !\u003d null \u0026\u0026 !filterList.getFilters().isEmpty()) {\n      newList.addFilter(filterList);\n    }\n    scan.setFilter(newList);\n    scan.setMaxVersions(getDataToRetrieve().getMetricsLimit());\n    return getTable().getResultScanner(hbaseConf, conn, scan);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/reader/ApplicationEntityReader.java",
      "extendedDetails": {
        "oldPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/reader/ApplicationEntityReader.java",
        "newPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/reader/ApplicationEntityReader.java"
      }
    },
    "892b193bd77c15932b4c084c1d525b7017def0d4": {
      "type": "Ybodychange",
      "commitMessage": "YARN-5170. Eliminate singleton converters and static method access. (Joep Rottinghuis via Varun Saxena)\n",
      "commitDate": "10/07/16 8:46 AM",
      "commitName": "892b193bd77c15932b4c084c1d525b7017def0d4",
      "commitAuthor": "Varun Saxena",
      "commitDateOld": "10/07/16 8:46 AM",
      "commitNameOld": "c81a2e1d197b9995103797348cb5cc4bcf9a015b",
      "commitAuthorOld": "Sangjin Lee",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,20 @@\n   protected ResultScanner getResults(Configuration hbaseConf,\n       Connection conn, FilterList filterList) throws IOException {\n     Scan scan \u003d new Scan();\n     TimelineReaderContext context \u003d getContext();\n-    if (context.getFlowRunId() !\u003d null) {\n-      scan.setRowPrefixFilter(ApplicationRowKey.\n-          getRowKeyPrefix(context.getClusterId(), context.getUserId(),\n-              context.getFlowName(), context.getFlowRunId()));\n-    } else {\n-      scan.setRowPrefixFilter(ApplicationRowKey.\n-          getRowKeyPrefix(context.getClusterId(), context.getUserId(),\n-              context.getFlowName()));\n-    }\n+    // Whether or not flowRunID is null doesn\u0027t matter, the\n+    // ApplicationRowKeyPrefix will do the right thing.\n+    RowKeyPrefix\u003cApplicationRowKey\u003e applicationRowKeyPrefix \u003d\n+        new ApplicationRowKeyPrefix(context.getClusterId(),\n+            context.getUserId(), context.getFlowName(),\n+            context.getFlowRunId());\n+    scan.setRowPrefixFilter(applicationRowKeyPrefix.getRowKeyPrefix());\n     FilterList newList \u003d new FilterList();\n     newList.addFilter(new PageFilter(getFilters().getLimit()));\n     if (filterList !\u003d null \u0026\u0026 !filterList.getFilters().isEmpty()) {\n       newList.addFilter(filterList);\n     }\n     scan.setFilter(newList);\n     scan.setMaxVersions(getDataToRetrieve().getMetricsLimit());\n     return getTable().getResultScanner(hbaseConf, conn, scan);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected ResultScanner getResults(Configuration hbaseConf,\n      Connection conn, FilterList filterList) throws IOException {\n    Scan scan \u003d new Scan();\n    TimelineReaderContext context \u003d getContext();\n    // Whether or not flowRunID is null doesn\u0027t matter, the\n    // ApplicationRowKeyPrefix will do the right thing.\n    RowKeyPrefix\u003cApplicationRowKey\u003e applicationRowKeyPrefix \u003d\n        new ApplicationRowKeyPrefix(context.getClusterId(),\n            context.getUserId(), context.getFlowName(),\n            context.getFlowRunId());\n    scan.setRowPrefixFilter(applicationRowKeyPrefix.getRowKeyPrefix());\n    FilterList newList \u003d new FilterList();\n    newList.addFilter(new PageFilter(getFilters().getLimit()));\n    if (filterList !\u003d null \u0026\u0026 !filterList.getFilters().isEmpty()) {\n      newList.addFilter(filterList);\n    }\n    scan.setFilter(newList);\n    scan.setMaxVersions(getDataToRetrieve().getMetricsLimit());\n    return getTable().getResultScanner(hbaseConf, conn, scan);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/reader/ApplicationEntityReader.java",
      "extendedDetails": {}
    },
    "c81a2e1d197b9995103797348cb5cc4bcf9a015b": {
      "type": "Ybodychange",
      "commitMessage": "YARN-5015. entire time series is returned for YARN container system metrics (CPU and memory) (Varun Saxena via sjlee)\n",
      "commitDate": "10/07/16 8:46 AM",
      "commitName": "c81a2e1d197b9995103797348cb5cc4bcf9a015b",
      "commitAuthor": "Sangjin Lee",
      "commitDateOld": "10/07/16 8:45 AM",
      "commitNameOld": "8c8183e515b42b7fff7d56a14ea7af78d3fdc772",
      "commitAuthorOld": "Sangjin Lee",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 7,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,22 @@\n   protected ResultScanner getResults(Configuration hbaseConf,\n       Connection conn, FilterList filterList) throws IOException {\n     Scan scan \u003d new Scan();\n     TimelineReaderContext context \u003d getContext();\n     if (context.getFlowRunId() !\u003d null) {\n       scan.setRowPrefixFilter(ApplicationRowKey.\n           getRowKeyPrefix(context.getClusterId(), context.getUserId(),\n               context.getFlowName(), context.getFlowRunId()));\n     } else {\n       scan.setRowPrefixFilter(ApplicationRowKey.\n           getRowKeyPrefix(context.getClusterId(), context.getUserId(),\n               context.getFlowName()));\n     }\n     FilterList newList \u003d new FilterList();\n     newList.addFilter(new PageFilter(getFilters().getLimit()));\n     if (filterList !\u003d null \u0026\u0026 !filterList.getFilters().isEmpty()) {\n       newList.addFilter(filterList);\n     }\n     scan.setFilter(newList);\n+    scan.setMaxVersions(getDataToRetrieve().getMetricsLimit());\n     return getTable().getResultScanner(hbaseConf, conn, scan);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected ResultScanner getResults(Configuration hbaseConf,\n      Connection conn, FilterList filterList) throws IOException {\n    Scan scan \u003d new Scan();\n    TimelineReaderContext context \u003d getContext();\n    if (context.getFlowRunId() !\u003d null) {\n      scan.setRowPrefixFilter(ApplicationRowKey.\n          getRowKeyPrefix(context.getClusterId(), context.getUserId(),\n              context.getFlowName(), context.getFlowRunId()));\n    } else {\n      scan.setRowPrefixFilter(ApplicationRowKey.\n          getRowKeyPrefix(context.getClusterId(), context.getUserId(),\n              context.getFlowName()));\n    }\n    FilterList newList \u003d new FilterList();\n    newList.addFilter(new PageFilter(getFilters().getLimit()));\n    if (filterList !\u003d null \u0026\u0026 !filterList.getFilters().isEmpty()) {\n      newList.addFilter(filterList);\n    }\n    scan.setFilter(newList);\n    scan.setMaxVersions(getDataToRetrieve().getMetricsLimit());\n    return getTable().getResultScanner(hbaseConf, conn, scan);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/reader/ApplicationEntityReader.java",
      "extendedDetails": {}
    },
    "960af7d4717b8a8949d0b2e43949e7daab45aa88": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4409. Fix javadoc and checkstyle issues in timelineservice code (Varun Saxena via sjlee)\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "960af7d4717b8a8949d0b2e43949e7daab45aa88",
      "commitAuthor": "Sangjin Lee",
      "commitDateOld": "10/07/16 8:45 AM",
      "commitNameOld": "9cb1287e9b8425f91de925f411c3c2a8fa9fe2a3",
      "commitAuthorOld": "Sangjin Lee",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,21 @@\n   protected ResultScanner getResults(Configuration hbaseConf,\n       Connection conn, FilterList filterList) throws IOException {\n     Scan scan \u003d new Scan();\n     TimelineReaderContext context \u003d getContext();\n     if (context.getFlowRunId() !\u003d null) {\n       scan.setRowPrefixFilter(ApplicationRowKey.\n           getRowKeyPrefix(context.getClusterId(), context.getUserId(),\n               context.getFlowName(), context.getFlowRunId()));\n     } else {\n       scan.setRowPrefixFilter(ApplicationRowKey.\n           getRowKeyPrefix(context.getClusterId(), context.getUserId(),\n               context.getFlowName()));\n     }\n     FilterList newList \u003d new FilterList();\n     newList.addFilter(new PageFilter(getFilters().getLimit()));\n     if (filterList !\u003d null \u0026\u0026 !filterList.getFilters().isEmpty()) {\n       newList.addFilter(filterList);\n     }\n     scan.setFilter(newList);\n-    return table.getResultScanner(hbaseConf, conn, scan);\n+    return getTable().getResultScanner(hbaseConf, conn, scan);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected ResultScanner getResults(Configuration hbaseConf,\n      Connection conn, FilterList filterList) throws IOException {\n    Scan scan \u003d new Scan();\n    TimelineReaderContext context \u003d getContext();\n    if (context.getFlowRunId() !\u003d null) {\n      scan.setRowPrefixFilter(ApplicationRowKey.\n          getRowKeyPrefix(context.getClusterId(), context.getUserId(),\n              context.getFlowName(), context.getFlowRunId()));\n    } else {\n      scan.setRowPrefixFilter(ApplicationRowKey.\n          getRowKeyPrefix(context.getClusterId(), context.getUserId(),\n              context.getFlowName()));\n    }\n    FilterList newList \u003d new FilterList();\n    newList.addFilter(new PageFilter(getFilters().getLimit()));\n    if (filterList !\u003d null \u0026\u0026 !filterList.getFilters().isEmpty()) {\n      newList.addFilter(filterList);\n    }\n    scan.setFilter(newList);\n    return getTable().getResultScanner(hbaseConf, conn, scan);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/reader/ApplicationEntityReader.java",
      "extendedDetails": {}
    },
    "9cb1287e9b8425f91de925f411c3c2a8fa9fe2a3": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4446. Refactor reader API for better extensibility (Varun Saxena via sjlee)\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "9cb1287e9b8425f91de925f411c3c2a8fa9fe2a3",
      "commitAuthor": "Sangjin Lee",
      "commitDateOld": "10/07/16 8:45 AM",
      "commitNameOld": "6934b05c7117a12286fb2ba7a47f75e227cacb22",
      "commitAuthorOld": "Naganarasimha",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,18 +1,21 @@\n   protected ResultScanner getResults(Configuration hbaseConf,\n       Connection conn, FilterList filterList) throws IOException {\n     Scan scan \u003d new Scan();\n-    if (flowRunId !\u003d null) {\n+    TimelineReaderContext context \u003d getContext();\n+    if (context.getFlowRunId() !\u003d null) {\n       scan.setRowPrefixFilter(ApplicationRowKey.\n-          getRowKeyPrefix(clusterId, userId, flowName, flowRunId));\n+          getRowKeyPrefix(context.getClusterId(), context.getUserId(),\n+              context.getFlowName(), context.getFlowRunId()));\n     } else {\n       scan.setRowPrefixFilter(ApplicationRowKey.\n-          getRowKeyPrefix(clusterId, userId, flowName));\n+          getRowKeyPrefix(context.getClusterId(), context.getUserId(),\n+              context.getFlowName()));\n     }\n     FilterList newList \u003d new FilterList();\n-    newList.addFilter(new PageFilter(limit));\n+    newList.addFilter(new PageFilter(getFilters().getLimit()));\n     if (filterList !\u003d null \u0026\u0026 !filterList.getFilters().isEmpty()) {\n       newList.addFilter(filterList);\n     }\n     scan.setFilter(newList);\n     return table.getResultScanner(hbaseConf, conn, scan);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected ResultScanner getResults(Configuration hbaseConf,\n      Connection conn, FilterList filterList) throws IOException {\n    Scan scan \u003d new Scan();\n    TimelineReaderContext context \u003d getContext();\n    if (context.getFlowRunId() !\u003d null) {\n      scan.setRowPrefixFilter(ApplicationRowKey.\n          getRowKeyPrefix(context.getClusterId(), context.getUserId(),\n              context.getFlowName(), context.getFlowRunId()));\n    } else {\n      scan.setRowPrefixFilter(ApplicationRowKey.\n          getRowKeyPrefix(context.getClusterId(), context.getUserId(),\n              context.getFlowName()));\n    }\n    FilterList newList \u003d new FilterList();\n    newList.addFilter(new PageFilter(getFilters().getLimit()));\n    if (filterList !\u003d null \u0026\u0026 !filterList.getFilters().isEmpty()) {\n      newList.addFilter(filterList);\n    }\n    scan.setFilter(newList);\n    return table.getResultScanner(hbaseConf, conn, scan);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/reader/ApplicationEntityReader.java",
      "extendedDetails": {}
    },
    "88f02941144824187b70fa2aaf0c6d90bcb77d8f": {
      "type": "Yfilerename",
      "commitMessage": "YARN-4200. Refactor reader classes in storage to nest under hbase\nspecific package name. Contributed by Li Lu.\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "88f02941144824187b70fa2aaf0c6d90bcb77d8f",
      "commitAuthor": "Li Lu",
      "commitDateOld": "10/07/16 8:45 AM",
      "commitNameOld": "cc16683cefe2611cf4de7819496aa54854f5394c",
      "commitAuthorOld": "Sangjin Lee",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  protected ResultScanner getResults(Configuration hbaseConf,\n      Connection conn, FilterList filterList) throws IOException {\n    Scan scan \u003d new Scan();\n    if (flowRunId !\u003d null) {\n      scan.setRowPrefixFilter(ApplicationRowKey.\n          getRowKeyPrefix(clusterId, userId, flowName, flowRunId));\n    } else {\n      scan.setRowPrefixFilter(ApplicationRowKey.\n          getRowKeyPrefix(clusterId, userId, flowName));\n    }\n    FilterList newList \u003d new FilterList();\n    newList.addFilter(new PageFilter(limit));\n    if (filterList !\u003d null \u0026\u0026 !filterList.getFilters().isEmpty()) {\n      newList.addFilter(filterList);\n    }\n    scan.setFilter(newList);\n    return table.getResultScanner(hbaseConf, conn, scan);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/reader/ApplicationEntityReader.java",
      "extendedDetails": {
        "oldPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/ApplicationEntityReader.java",
        "newPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/reader/ApplicationEntityReader.java"
      }
    },
    "8ef546c1ee9fce0b171813547253374d268566ba": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4445. Unify the term flowId and flowName in timeline v2 codebase.\nContributed by Zhan Zhang.\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "8ef546c1ee9fce0b171813547253374d268566ba",
      "commitAuthor": "Li Lu",
      "commitDateOld": "10/07/16 8:45 AM",
      "commitNameOld": "1f710484e5b8ab4d5c67379c012004e8a4242d15",
      "commitAuthorOld": "Sangjin Lee",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 6,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,18 +1,18 @@\n   protected ResultScanner getResults(Configuration hbaseConf,\n       Connection conn, FilterList filterList) throws IOException {\n     Scan scan \u003d new Scan();\n     if (flowRunId !\u003d null) {\n       scan.setRowPrefixFilter(ApplicationRowKey.\n-          getRowKeyPrefix(clusterId, userId, flowId, flowRunId));\n+          getRowKeyPrefix(clusterId, userId, flowName, flowRunId));\n     } else {\n       scan.setRowPrefixFilter(ApplicationRowKey.\n-          getRowKeyPrefix(clusterId, userId, flowId));\n+          getRowKeyPrefix(clusterId, userId, flowName));\n     }\n     FilterList newList \u003d new FilterList();\n     newList.addFilter(new PageFilter(limit));\n     if (filterList !\u003d null \u0026\u0026 !filterList.getFilters().isEmpty()) {\n       newList.addFilter(filterList);\n     }\n     scan.setFilter(newList);\n     return table.getResultScanner(hbaseConf, conn, scan);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected ResultScanner getResults(Configuration hbaseConf,\n      Connection conn, FilterList filterList) throws IOException {\n    Scan scan \u003d new Scan();\n    if (flowRunId !\u003d null) {\n      scan.setRowPrefixFilter(ApplicationRowKey.\n          getRowKeyPrefix(clusterId, userId, flowName, flowRunId));\n    } else {\n      scan.setRowPrefixFilter(ApplicationRowKey.\n          getRowKeyPrefix(clusterId, userId, flowName));\n    }\n    FilterList newList \u003d new FilterList();\n    newList.addFilter(new PageFilter(limit));\n    if (filterList !\u003d null \u0026\u0026 !filterList.getFilters().isEmpty()) {\n      newList.addFilter(filterList);\n    }\n    scan.setFilter(newList);\n    return table.getResultScanner(hbaseConf, conn, scan);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/ApplicationEntityReader.java",
      "extendedDetails": {}
    },
    "1f710484e5b8ab4d5c67379c012004e8a4242d15": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "YARN-3862. Support for fetching specific configs and metrics based on prefixes (Varun Saxena via sjlee)\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "1f710484e5b8ab4d5c67379c012004e8a4242d15",
      "commitAuthor": "Sangjin Lee",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "YARN-3862. Support for fetching specific configs and metrics based on prefixes (Varun Saxena via sjlee)\n",
          "commitDate": "10/07/16 8:45 AM",
          "commitName": "1f710484e5b8ab4d5c67379c012004e8a4242d15",
          "commitAuthor": "Sangjin Lee",
          "commitDateOld": "10/07/16 8:45 AM",
          "commitNameOld": "09649005ca269f249f98384ecd1abf9fb6d5b0c1",
          "commitAuthorOld": "Sangjin Lee",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 3,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,13 +1,18 @@\n   protected ResultScanner getResults(Configuration hbaseConf,\n-      Connection conn) throws IOException {\n+      Connection conn, FilterList filterList) throws IOException {\n     Scan scan \u003d new Scan();\n     if (flowRunId !\u003d null) {\n       scan.setRowPrefixFilter(ApplicationRowKey.\n           getRowKeyPrefix(clusterId, userId, flowId, flowRunId));\n     } else {\n       scan.setRowPrefixFilter(ApplicationRowKey.\n           getRowKeyPrefix(clusterId, userId, flowId));\n     }\n-    scan.setFilter(new PageFilter(limit));\n+    FilterList newList \u003d new FilterList();\n+    newList.addFilter(new PageFilter(limit));\n+    if (filterList !\u003d null \u0026\u0026 !filterList.getFilters().isEmpty()) {\n+      newList.addFilter(filterList);\n+    }\n+    scan.setFilter(newList);\n     return table.getResultScanner(hbaseConf, conn, scan);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected ResultScanner getResults(Configuration hbaseConf,\n      Connection conn, FilterList filterList) throws IOException {\n    Scan scan \u003d new Scan();\n    if (flowRunId !\u003d null) {\n      scan.setRowPrefixFilter(ApplicationRowKey.\n          getRowKeyPrefix(clusterId, userId, flowId, flowRunId));\n    } else {\n      scan.setRowPrefixFilter(ApplicationRowKey.\n          getRowKeyPrefix(clusterId, userId, flowId));\n    }\n    FilterList newList \u003d new FilterList();\n    newList.addFilter(new PageFilter(limit));\n    if (filterList !\u003d null \u0026\u0026 !filterList.getFilters().isEmpty()) {\n      newList.addFilter(filterList);\n    }\n    scan.setFilter(newList);\n    return table.getResultScanner(hbaseConf, conn, scan);\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/ApplicationEntityReader.java",
          "extendedDetails": {
            "oldValue": "[hbaseConf-Configuration, conn-Connection]",
            "newValue": "[hbaseConf-Configuration, conn-Connection, filterList-FilterList]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-3862. Support for fetching specific configs and metrics based on prefixes (Varun Saxena via sjlee)\n",
          "commitDate": "10/07/16 8:45 AM",
          "commitName": "1f710484e5b8ab4d5c67379c012004e8a4242d15",
          "commitAuthor": "Sangjin Lee",
          "commitDateOld": "10/07/16 8:45 AM",
          "commitNameOld": "09649005ca269f249f98384ecd1abf9fb6d5b0c1",
          "commitAuthorOld": "Sangjin Lee",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 3,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,13 +1,18 @@\n   protected ResultScanner getResults(Configuration hbaseConf,\n-      Connection conn) throws IOException {\n+      Connection conn, FilterList filterList) throws IOException {\n     Scan scan \u003d new Scan();\n     if (flowRunId !\u003d null) {\n       scan.setRowPrefixFilter(ApplicationRowKey.\n           getRowKeyPrefix(clusterId, userId, flowId, flowRunId));\n     } else {\n       scan.setRowPrefixFilter(ApplicationRowKey.\n           getRowKeyPrefix(clusterId, userId, flowId));\n     }\n-    scan.setFilter(new PageFilter(limit));\n+    FilterList newList \u003d new FilterList();\n+    newList.addFilter(new PageFilter(limit));\n+    if (filterList !\u003d null \u0026\u0026 !filterList.getFilters().isEmpty()) {\n+      newList.addFilter(filterList);\n+    }\n+    scan.setFilter(newList);\n     return table.getResultScanner(hbaseConf, conn, scan);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected ResultScanner getResults(Configuration hbaseConf,\n      Connection conn, FilterList filterList) throws IOException {\n    Scan scan \u003d new Scan();\n    if (flowRunId !\u003d null) {\n      scan.setRowPrefixFilter(ApplicationRowKey.\n          getRowKeyPrefix(clusterId, userId, flowId, flowRunId));\n    } else {\n      scan.setRowPrefixFilter(ApplicationRowKey.\n          getRowKeyPrefix(clusterId, userId, flowId));\n    }\n    FilterList newList \u003d new FilterList();\n    newList.addFilter(new PageFilter(limit));\n    if (filterList !\u003d null \u0026\u0026 !filterList.getFilters().isEmpty()) {\n      newList.addFilter(filterList);\n    }\n    scan.setFilter(newList);\n    return table.getResultScanner(hbaseConf, conn, scan);\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/ApplicationEntityReader.java",
          "extendedDetails": {}
        }
      ]
    },
    "0f44b5508d2ffcae08f130b6535a9832d37e2b38": {
      "type": "Ybodychange",
      "commitMessage": "YARN-3864. Implement support for querying single app and all apps for a flow run (Varun Saxena via sjlee)\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "0f44b5508d2ffcae08f130b6535a9832d37e2b38",
      "commitAuthor": "Sangjin Lee",
      "commitDateOld": "10/07/16 8:45 AM",
      "commitNameOld": "708fa8b1ae85b6efda318368bc0c0ba02d4958c8",
      "commitAuthorOld": "Vrushali Channapattan",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,5 +1,13 @@\n   protected ResultScanner getResults(Configuration hbaseConf,\n       Connection conn) throws IOException {\n-    throw new UnsupportedOperationException(\n-        \"we don\u0027t support multiple apps query\");\n+    Scan scan \u003d new Scan();\n+    if (flowRunId !\u003d null) {\n+      scan.setRowPrefixFilter(ApplicationRowKey.\n+          getRowKeyPrefix(clusterId, userId, flowId, flowRunId));\n+    } else {\n+      scan.setRowPrefixFilter(ApplicationRowKey.\n+          getRowKeyPrefix(clusterId, userId, flowId));\n+    }\n+    scan.setFilter(new PageFilter(limit));\n+    return table.getResultScanner(hbaseConf, conn, scan);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected ResultScanner getResults(Configuration hbaseConf,\n      Connection conn) throws IOException {\n    Scan scan \u003d new Scan();\n    if (flowRunId !\u003d null) {\n      scan.setRowPrefixFilter(ApplicationRowKey.\n          getRowKeyPrefix(clusterId, userId, flowId, flowRunId));\n    } else {\n      scan.setRowPrefixFilter(ApplicationRowKey.\n          getRowKeyPrefix(clusterId, userId, flowId));\n    }\n    scan.setFilter(new PageFilter(limit));\n    return table.getResultScanner(hbaseConf, conn, scan);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/ApplicationEntityReader.java",
      "extendedDetails": {}
    },
    "708fa8b1ae85b6efda318368bc0c0ba02d4958c8": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": "YARN-4210. HBase reader throws NPE if Get returns no rows (Varun Saxena via vrushali)\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "708fa8b1ae85b6efda318368bc0c0ba02d4958c8",
      "commitAuthor": "Vrushali Channapattan",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "YARN-4210. HBase reader throws NPE if Get returns no rows (Varun Saxena via vrushali)\n",
          "commitDate": "10/07/16 8:45 AM",
          "commitName": "708fa8b1ae85b6efda318368bc0c0ba02d4958c8",
          "commitAuthor": "Vrushali Channapattan",
          "commitDateOld": "10/07/16 8:45 AM",
          "commitNameOld": "10fa6da7d8a6013698767c6136ae20f0e04415e9",
          "commitAuthorOld": "Vrushali",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 3,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,19 +1,5 @@\n-  protected Iterable\u003cResult\u003e getResults(Configuration hbaseConf,\n+  protected ResultScanner getResults(Configuration hbaseConf,\n       Connection conn) throws IOException {\n-    // If getEntities() is called for an application, there can be at most\n-    // one entity. If the entity passes the filter, it is returned. Otherwise,\n-    // an empty set is returned.\n-    byte[] rowKey \u003d ApplicationRowKey.getRowKey(clusterId, userId, flowId,\n-        flowRunId, appId);\n-    Get get \u003d new Get(rowKey);\n-    get.setMaxVersions(Integer.MAX_VALUE);\n-    Result result \u003d table.getResult(hbaseConf, conn, get);\n-    TimelineEntity entity \u003d parseEntity(result);\n-    Set\u003cResult\u003e set;\n-    if (entity !\u003d null) {\n-      set \u003d Collections.singleton(result);\n-    } else {\n-      set \u003d Collections.emptySet();\n-    }\n-    return set;\n+    throw new UnsupportedOperationException(\n+        \"we don\u0027t support multiple apps query\");\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected ResultScanner getResults(Configuration hbaseConf,\n      Connection conn) throws IOException {\n    throw new UnsupportedOperationException(\n        \"we don\u0027t support multiple apps query\");\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/ApplicationEntityReader.java",
          "extendedDetails": {
            "oldValue": "Iterable\u003cResult\u003e",
            "newValue": "ResultScanner"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-4210. HBase reader throws NPE if Get returns no rows (Varun Saxena via vrushali)\n",
          "commitDate": "10/07/16 8:45 AM",
          "commitName": "708fa8b1ae85b6efda318368bc0c0ba02d4958c8",
          "commitAuthor": "Vrushali Channapattan",
          "commitDateOld": "10/07/16 8:45 AM",
          "commitNameOld": "10fa6da7d8a6013698767c6136ae20f0e04415e9",
          "commitAuthorOld": "Vrushali",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 3,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,19 +1,5 @@\n-  protected Iterable\u003cResult\u003e getResults(Configuration hbaseConf,\n+  protected ResultScanner getResults(Configuration hbaseConf,\n       Connection conn) throws IOException {\n-    // If getEntities() is called for an application, there can be at most\n-    // one entity. If the entity passes the filter, it is returned. Otherwise,\n-    // an empty set is returned.\n-    byte[] rowKey \u003d ApplicationRowKey.getRowKey(clusterId, userId, flowId,\n-        flowRunId, appId);\n-    Get get \u003d new Get(rowKey);\n-    get.setMaxVersions(Integer.MAX_VALUE);\n-    Result result \u003d table.getResult(hbaseConf, conn, get);\n-    TimelineEntity entity \u003d parseEntity(result);\n-    Set\u003cResult\u003e set;\n-    if (entity !\u003d null) {\n-      set \u003d Collections.singleton(result);\n-    } else {\n-      set \u003d Collections.emptySet();\n-    }\n-    return set;\n+    throw new UnsupportedOperationException(\n+        \"we don\u0027t support multiple apps query\");\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected ResultScanner getResults(Configuration hbaseConf,\n      Connection conn) throws IOException {\n    throw new UnsupportedOperationException(\n        \"we don\u0027t support multiple apps query\");\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/ApplicationEntityReader.java",
          "extendedDetails": {}
        }
      ]
    },
    "10fa6da7d8a6013698767c6136ae20f0e04415e9": {
      "type": "Yintroduced",
      "commitMessage": "YARN-4074. [timeline reader] implement support for querying for flows and flow runs (sjlee via vrushali)\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "10fa6da7d8a6013698767c6136ae20f0e04415e9",
      "commitAuthor": "Vrushali",
      "diff": "@@ -0,0 +1,19 @@\n+  protected Iterable\u003cResult\u003e getResults(Configuration hbaseConf,\n+      Connection conn) throws IOException {\n+    // If getEntities() is called for an application, there can be at most\n+    // one entity. If the entity passes the filter, it is returned. Otherwise,\n+    // an empty set is returned.\n+    byte[] rowKey \u003d ApplicationRowKey.getRowKey(clusterId, userId, flowId,\n+        flowRunId, appId);\n+    Get get \u003d new Get(rowKey);\n+    get.setMaxVersions(Integer.MAX_VALUE);\n+    Result result \u003d table.getResult(hbaseConf, conn, get);\n+    TimelineEntity entity \u003d parseEntity(result);\n+    Set\u003cResult\u003e set;\n+    if (entity !\u003d null) {\n+      set \u003d Collections.singleton(result);\n+    } else {\n+      set \u003d Collections.emptySet();\n+    }\n+    return set;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  protected Iterable\u003cResult\u003e getResults(Configuration hbaseConf,\n      Connection conn) throws IOException {\n    // If getEntities() is called for an application, there can be at most\n    // one entity. If the entity passes the filter, it is returned. Otherwise,\n    // an empty set is returned.\n    byte[] rowKey \u003d ApplicationRowKey.getRowKey(clusterId, userId, flowId,\n        flowRunId, appId);\n    Get get \u003d new Get(rowKey);\n    get.setMaxVersions(Integer.MAX_VALUE);\n    Result result \u003d table.getResult(hbaseConf, conn, get);\n    TimelineEntity entity \u003d parseEntity(result);\n    Set\u003cResult\u003e set;\n    if (entity !\u003d null) {\n      set \u003d Collections.singleton(result);\n    } else {\n      set \u003d Collections.emptySet();\n    }\n    return set;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/ApplicationEntityReader.java"
    }
  }
}