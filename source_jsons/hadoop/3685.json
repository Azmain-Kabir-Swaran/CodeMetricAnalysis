{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DFSPacket.java",
  "functionName": "getTraceParents",
  "functionId": "getTraceParents",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSPacket.java",
  "functionStartLine": 332,
  "functionEndLine": 355,
  "numCommitsSeen": 8,
  "timeTaken": 1627,
  "changeHistory": [
    "892ade689f9bcce76daae8f66fc00a49bee8548e",
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c",
    "8234fd0e1087e0e49aa1d6f286f292b7f70b368e"
  ],
  "changeHistoryShort": {
    "892ade689f9bcce76daae8f66fc00a49bee8548e": "Ymultichange(Yreturntypechange,Ybodychange)",
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c": "Yfilerename",
    "8234fd0e1087e0e49aa1d6f286f292b7f70b368e": "Yintroduced"
  },
  "changeHistoryDetails": {
    "892ade689f9bcce76daae8f66fc00a49bee8548e": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-9080. Update htrace version to 4.0.1 (cmccabe)\n",
      "commitDate": "28/09/15 7:42 AM",
      "commitName": "892ade689f9bcce76daae8f66fc00a49bee8548e",
      "commitAuthor": "Colin Patrick Mccabe",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-9080. Update htrace version to 4.0.1 (cmccabe)\n",
          "commitDate": "28/09/15 7:42 AM",
          "commitName": "892ade689f9bcce76daae8f66fc00a49bee8548e",
          "commitAuthor": "Colin Patrick Mccabe",
          "commitDateOld": "26/09/15 11:08 AM",
          "commitNameOld": "bf37d3d80e5179dea27e5bd5aea804a38aa9934c",
          "commitAuthorOld": "Haohui Mai",
          "daysBetweenCommits": 1.86,
          "commitsBetweenForRepo": 5,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,24 @@\n-  public long[] getTraceParents() {\n+  public SpanId[] getTraceParents() {\n     // Remove duplicates from the array.\n     int len \u003d traceParentsUsed;\n     Arrays.sort(traceParents, 0, len);\n     int i \u003d 0, j \u003d 0;\n-    long prevVal \u003d 0; // 0 is not a valid span id\n+    SpanId prevVal \u003d SpanId.INVALID;\n     while (true) {\n       if (i \u003d\u003d len) {\n         break;\n       }\n-      long val \u003d traceParents[i];\n-      if (val !\u003d prevVal) {\n+      SpanId val \u003d traceParents[i];\n+      if (!val.equals(prevVal)) {\n         traceParents[j] \u003d val;\n         j++;\n         prevVal \u003d val;\n       }\n       i++;\n     }\n     if (j \u003c traceParents.length) {\n       traceParents \u003d Arrays.copyOf(traceParents, j);\n       traceParentsUsed \u003d traceParents.length;\n     }\n     return traceParents;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public SpanId[] getTraceParents() {\n    // Remove duplicates from the array.\n    int len \u003d traceParentsUsed;\n    Arrays.sort(traceParents, 0, len);\n    int i \u003d 0, j \u003d 0;\n    SpanId prevVal \u003d SpanId.INVALID;\n    while (true) {\n      if (i \u003d\u003d len) {\n        break;\n      }\n      SpanId val \u003d traceParents[i];\n      if (!val.equals(prevVal)) {\n        traceParents[j] \u003d val;\n        j++;\n        prevVal \u003d val;\n      }\n      i++;\n    }\n    if (j \u003c traceParents.length) {\n      traceParents \u003d Arrays.copyOf(traceParents, j);\n      traceParentsUsed \u003d traceParents.length;\n    }\n    return traceParents;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSPacket.java",
          "extendedDetails": {
            "oldValue": "long[]",
            "newValue": "SpanId[]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-9080. Update htrace version to 4.0.1 (cmccabe)\n",
          "commitDate": "28/09/15 7:42 AM",
          "commitName": "892ade689f9bcce76daae8f66fc00a49bee8548e",
          "commitAuthor": "Colin Patrick Mccabe",
          "commitDateOld": "26/09/15 11:08 AM",
          "commitNameOld": "bf37d3d80e5179dea27e5bd5aea804a38aa9934c",
          "commitAuthorOld": "Haohui Mai",
          "daysBetweenCommits": 1.86,
          "commitsBetweenForRepo": 5,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,24 @@\n-  public long[] getTraceParents() {\n+  public SpanId[] getTraceParents() {\n     // Remove duplicates from the array.\n     int len \u003d traceParentsUsed;\n     Arrays.sort(traceParents, 0, len);\n     int i \u003d 0, j \u003d 0;\n-    long prevVal \u003d 0; // 0 is not a valid span id\n+    SpanId prevVal \u003d SpanId.INVALID;\n     while (true) {\n       if (i \u003d\u003d len) {\n         break;\n       }\n-      long val \u003d traceParents[i];\n-      if (val !\u003d prevVal) {\n+      SpanId val \u003d traceParents[i];\n+      if (!val.equals(prevVal)) {\n         traceParents[j] \u003d val;\n         j++;\n         prevVal \u003d val;\n       }\n       i++;\n     }\n     if (j \u003c traceParents.length) {\n       traceParents \u003d Arrays.copyOf(traceParents, j);\n       traceParentsUsed \u003d traceParents.length;\n     }\n     return traceParents;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public SpanId[] getTraceParents() {\n    // Remove duplicates from the array.\n    int len \u003d traceParentsUsed;\n    Arrays.sort(traceParents, 0, len);\n    int i \u003d 0, j \u003d 0;\n    SpanId prevVal \u003d SpanId.INVALID;\n    while (true) {\n      if (i \u003d\u003d len) {\n        break;\n      }\n      SpanId val \u003d traceParents[i];\n      if (!val.equals(prevVal)) {\n        traceParents[j] \u003d val;\n        j++;\n        prevVal \u003d val;\n      }\n      i++;\n    }\n    if (j \u003c traceParents.length) {\n      traceParents \u003d Arrays.copyOf(traceParents, j);\n      traceParentsUsed \u003d traceParents.length;\n    }\n    return traceParents;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSPacket.java",
          "extendedDetails": {}
        }
      ]
    },
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8053. Move DFSIn/OutputStream and related classes to hadoop-hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "26/09/15 11:08 AM",
      "commitName": "bf37d3d80e5179dea27e5bd5aea804a38aa9934c",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "26/09/15 9:06 AM",
      "commitNameOld": "861b52db242f238d7e36ad75c158025be959a696",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 0.08,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public long[] getTraceParents() {\n    // Remove duplicates from the array.\n    int len \u003d traceParentsUsed;\n    Arrays.sort(traceParents, 0, len);\n    int i \u003d 0, j \u003d 0;\n    long prevVal \u003d 0; // 0 is not a valid span id\n    while (true) {\n      if (i \u003d\u003d len) {\n        break;\n      }\n      long val \u003d traceParents[i];\n      if (val !\u003d prevVal) {\n        traceParents[j] \u003d val;\n        j++;\n        prevVal \u003d val;\n      }\n      i++;\n    }\n    if (j \u003c traceParents.length) {\n      traceParents \u003d Arrays.copyOf(traceParents, j);\n      traceParentsUsed \u003d traceParents.length;\n    }\n    return traceParents;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSPacket.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSPacket.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSPacket.java"
      }
    },
    "8234fd0e1087e0e49aa1d6f286f292b7f70b368e": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-7054. Make DFSOutputStream tracing more fine-grained (cmccabe)\n",
      "commitDate": "18/03/15 6:14 PM",
      "commitName": "8234fd0e1087e0e49aa1d6f286f292b7f70b368e",
      "commitAuthor": "Colin Patrick Mccabe",
      "diff": "@@ -0,0 +1,24 @@\n+  public long[] getTraceParents() {\n+    // Remove duplicates from the array.\n+    int len \u003d traceParentsUsed;\n+    Arrays.sort(traceParents, 0, len);\n+    int i \u003d 0, j \u003d 0;\n+    long prevVal \u003d 0; // 0 is not a valid span id\n+    while (true) {\n+      if (i \u003d\u003d len) {\n+        break;\n+      }\n+      long val \u003d traceParents[i];\n+      if (val !\u003d prevVal) {\n+        traceParents[j] \u003d val;\n+        j++;\n+        prevVal \u003d val;\n+      }\n+      i++;\n+    }\n+    if (j \u003c traceParents.length) {\n+      traceParents \u003d Arrays.copyOf(traceParents, j);\n+      traceParentsUsed \u003d traceParents.length;\n+    }\n+    return traceParents;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public long[] getTraceParents() {\n    // Remove duplicates from the array.\n    int len \u003d traceParentsUsed;\n    Arrays.sort(traceParents, 0, len);\n    int i \u003d 0, j \u003d 0;\n    long prevVal \u003d 0; // 0 is not a valid span id\n    while (true) {\n      if (i \u003d\u003d len) {\n        break;\n      }\n      long val \u003d traceParents[i];\n      if (val !\u003d prevVal) {\n        traceParents[j] \u003d val;\n        j++;\n        prevVal \u003d val;\n      }\n      i++;\n    }\n    if (j \u003c traceParents.length) {\n      traceParents \u003d Arrays.copyOf(traceParents, j);\n      traceParentsUsed \u003d traceParents.length;\n    }\n    return traceParents;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSPacket.java"
    }
  }
}