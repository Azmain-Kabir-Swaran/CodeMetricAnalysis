{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "MountTableResolver.java",
  "functionName": "refreshEntries",
  "functionId": "refreshEntries___entries-Collection__MountTable__(modifiers-final)",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/resolver/MountTableResolver.java",
  "functionStartLine": 287,
  "functionEndLine": 338,
  "numCommitsSeen": 21,
  "timeTaken": 2972,
  "changeHistory": [
    "6e2b5fa493ff8e8c2bb28e6f6f4c19347bc9b99d",
    "e71bc00a471422ddb26dd54e706f09f0fe09925c",
    "afe1a3ccd56a12fec900360a8a2855c080728e65",
    "83b513ac6d5448f3771b0b95f91e7aa7961ae2cc",
    "6f0de2731806628b5b01bd1350225692147590da"
  ],
  "changeHistoryShort": {
    "6e2b5fa493ff8e8c2bb28e6f6f4c19347bc9b99d": "Yfilerename",
    "e71bc00a471422ddb26dd54e706f09f0fe09925c": "Ybodychange",
    "afe1a3ccd56a12fec900360a8a2855c080728e65": "Ybodychange",
    "83b513ac6d5448f3771b0b95f91e7aa7961ae2cc": "Ybodychange",
    "6f0de2731806628b5b01bd1350225692147590da": "Yintroduced"
  },
  "changeHistoryDetails": {
    "6e2b5fa493ff8e8c2bb28e6f6f4c19347bc9b99d": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-13215. RBF: Move Router to its own module. Contributed by Wei Yan\n",
      "commitDate": "19/03/18 10:13 PM",
      "commitName": "6e2b5fa493ff8e8c2bb28e6f6f4c19347bc9b99d",
      "commitAuthor": "weiy",
      "commitDateOld": "19/03/18 5:19 PM",
      "commitNameOld": "e65ff1c8be48ef4f04ed96f96ac4caef4974944d",
      "commitAuthorOld": "Inigo Goiri",
      "daysBetweenCommits": 0.2,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void refreshEntries(final Collection\u003cMountTable\u003e entries) {\n    // The tree read/write must be atomic\n    writeLock.lock();\n    try {\n      // New entries\n      Map\u003cString, MountTable\u003e newEntries \u003d new ConcurrentHashMap\u003c\u003e();\n      for (MountTable entry : entries) {\n        String srcPath \u003d entry.getSourcePath();\n        newEntries.put(srcPath, entry);\n      }\n\n      // Old entries (reversed to sort from the leaves to the root)\n      Set\u003cString\u003e oldEntries \u003d new TreeSet\u003c\u003e(Collections.reverseOrder());\n      for (MountTable entry : getTreeValues(\"/\")) {\n        String srcPath \u003d entry.getSourcePath();\n        oldEntries.add(srcPath);\n      }\n\n      // Entries that need to be removed\n      for (String srcPath : oldEntries) {\n        if (!newEntries.containsKey(srcPath)) {\n          this.tree.remove(srcPath);\n          invalidateLocationCache(srcPath);\n          LOG.info(\"Removed stale mount point {} from resolver\", srcPath);\n        }\n      }\n\n      // Entries that need to be added\n      for (MountTable entry : entries) {\n        String srcPath \u003d entry.getSourcePath();\n        if (!oldEntries.contains(srcPath)) {\n          // Add node, it does not exist\n          this.tree.put(srcPath, entry);\n          invalidateLocationCache(srcPath);\n          LOG.info(\"Added new mount point {} to resolver\", srcPath);\n        } else {\n          // Node exists, check for updates\n          MountTable existingEntry \u003d this.tree.get(srcPath);\n          if (existingEntry !\u003d null \u0026\u0026 !existingEntry.equals(entry)) {\n            LOG.info(\"Entry has changed from \\\"{}\\\" to \\\"{}\\\"\",\n                existingEntry, entry);\n            this.tree.put(srcPath, entry);\n            invalidateLocationCache(srcPath);\n            LOG.info(\"Updated mount point {} in resolver\", srcPath);\n          }\n        }\n      }\n    } finally {\n      writeLock.unlock();\n    }\n    this.init \u003d true;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/resolver/MountTableResolver.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/federation/resolver/MountTableResolver.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/resolver/MountTableResolver.java"
      }
    },
    "e71bc00a471422ddb26dd54e706f09f0fe09925c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13224. RBF: Resolvers to support mount points across multiple subclusters. Contributed by Inigo Goiri.\n",
      "commitDate": "15/03/18 10:32 AM",
      "commitName": "e71bc00a471422ddb26dd54e706f09f0fe09925c",
      "commitAuthor": "Inigo Goiri",
      "commitDateOld": "12/03/18 7:30 PM",
      "commitNameOld": "7fab787de72756863a91c2358da5c611afdb80e9",
      "commitAuthorOld": "Yiqun Lin",
      "daysBetweenCommits": 2.63,
      "commitsBetweenForRepo": 36,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,52 +1,52 @@\n   public void refreshEntries(final Collection\u003cMountTable\u003e entries) {\n     // The tree read/write must be atomic\n     writeLock.lock();\n     try {\n       // New entries\n       Map\u003cString, MountTable\u003e newEntries \u003d new ConcurrentHashMap\u003c\u003e();\n       for (MountTable entry : entries) {\n         String srcPath \u003d entry.getSourcePath();\n         newEntries.put(srcPath, entry);\n       }\n \n       // Old entries (reversed to sort from the leaves to the root)\n       Set\u003cString\u003e oldEntries \u003d new TreeSet\u003c\u003e(Collections.reverseOrder());\n       for (MountTable entry : getTreeValues(\"/\")) {\n         String srcPath \u003d entry.getSourcePath();\n         oldEntries.add(srcPath);\n       }\n \n       // Entries that need to be removed\n       for (String srcPath : oldEntries) {\n         if (!newEntries.containsKey(srcPath)) {\n           this.tree.remove(srcPath);\n           invalidateLocationCache(srcPath);\n           LOG.info(\"Removed stale mount point {} from resolver\", srcPath);\n         }\n       }\n \n       // Entries that need to be added\n       for (MountTable entry : entries) {\n         String srcPath \u003d entry.getSourcePath();\n         if (!oldEntries.contains(srcPath)) {\n           // Add node, it does not exist\n           this.tree.put(srcPath, entry);\n           invalidateLocationCache(srcPath);\n           LOG.info(\"Added new mount point {} to resolver\", srcPath);\n         } else {\n           // Node exists, check for updates\n           MountTable existingEntry \u003d this.tree.get(srcPath);\n           if (existingEntry !\u003d null \u0026\u0026 !existingEntry.equals(entry)) {\n             LOG.info(\"Entry has changed from \\\"{}\\\" to \\\"{}\\\"\",\n                 existingEntry, entry);\n             this.tree.put(srcPath, entry);\n             invalidateLocationCache(srcPath);\n-            LOG.info(\"Updated mount point {} in resolver\");\n+            LOG.info(\"Updated mount point {} in resolver\", srcPath);\n           }\n         }\n       }\n     } finally {\n       writeLock.unlock();\n     }\n     this.init \u003d true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void refreshEntries(final Collection\u003cMountTable\u003e entries) {\n    // The tree read/write must be atomic\n    writeLock.lock();\n    try {\n      // New entries\n      Map\u003cString, MountTable\u003e newEntries \u003d new ConcurrentHashMap\u003c\u003e();\n      for (MountTable entry : entries) {\n        String srcPath \u003d entry.getSourcePath();\n        newEntries.put(srcPath, entry);\n      }\n\n      // Old entries (reversed to sort from the leaves to the root)\n      Set\u003cString\u003e oldEntries \u003d new TreeSet\u003c\u003e(Collections.reverseOrder());\n      for (MountTable entry : getTreeValues(\"/\")) {\n        String srcPath \u003d entry.getSourcePath();\n        oldEntries.add(srcPath);\n      }\n\n      // Entries that need to be removed\n      for (String srcPath : oldEntries) {\n        if (!newEntries.containsKey(srcPath)) {\n          this.tree.remove(srcPath);\n          invalidateLocationCache(srcPath);\n          LOG.info(\"Removed stale mount point {} from resolver\", srcPath);\n        }\n      }\n\n      // Entries that need to be added\n      for (MountTable entry : entries) {\n        String srcPath \u003d entry.getSourcePath();\n        if (!oldEntries.contains(srcPath)) {\n          // Add node, it does not exist\n          this.tree.put(srcPath, entry);\n          invalidateLocationCache(srcPath);\n          LOG.info(\"Added new mount point {} to resolver\", srcPath);\n        } else {\n          // Node exists, check for updates\n          MountTable existingEntry \u003d this.tree.get(srcPath);\n          if (existingEntry !\u003d null \u0026\u0026 !existingEntry.equals(entry)) {\n            LOG.info(\"Entry has changed from \\\"{}\\\" to \\\"{}\\\"\",\n                existingEntry, entry);\n            this.tree.put(srcPath, entry);\n            invalidateLocationCache(srcPath);\n            LOG.info(\"Updated mount point {} in resolver\", srcPath);\n          }\n        }\n      }\n    } finally {\n      writeLock.unlock();\n    }\n    this.init \u003d true;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/federation/resolver/MountTableResolver.java",
      "extendedDetails": {}
    },
    "afe1a3ccd56a12fec900360a8a2855c080728e65": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13212. RBF: Fix router location cache issue. Contributed by Weiwei Wu.\n",
      "commitDate": "09/03/18 5:18 PM",
      "commitName": "afe1a3ccd56a12fec900360a8a2855c080728e65",
      "commitAuthor": "Inigo Goiri",
      "commitDateOld": "08/03/18 11:42 PM",
      "commitNameOld": "122805b43acff2b094bd984fa76dbc8d2e110edd",
      "commitAuthorOld": "Yiqun Lin",
      "daysBetweenCommits": 0.73,
      "commitsBetweenForRepo": 9,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,51 +1,52 @@\n   public void refreshEntries(final Collection\u003cMountTable\u003e entries) {\n     // The tree read/write must be atomic\n     writeLock.lock();\n     try {\n       // New entries\n       Map\u003cString, MountTable\u003e newEntries \u003d new ConcurrentHashMap\u003c\u003e();\n       for (MountTable entry : entries) {\n         String srcPath \u003d entry.getSourcePath();\n         newEntries.put(srcPath, entry);\n       }\n \n       // Old entries (reversed to sort from the leaves to the root)\n       Set\u003cString\u003e oldEntries \u003d new TreeSet\u003c\u003e(Collections.reverseOrder());\n       for (MountTable entry : getTreeValues(\"/\")) {\n         String srcPath \u003d entry.getSourcePath();\n         oldEntries.add(srcPath);\n       }\n \n       // Entries that need to be removed\n       for (String srcPath : oldEntries) {\n         if (!newEntries.containsKey(srcPath)) {\n           this.tree.remove(srcPath);\n           invalidateLocationCache(srcPath);\n           LOG.info(\"Removed stale mount point {} from resolver\", srcPath);\n         }\n       }\n \n       // Entries that need to be added\n       for (MountTable entry : entries) {\n         String srcPath \u003d entry.getSourcePath();\n         if (!oldEntries.contains(srcPath)) {\n           // Add node, it does not exist\n           this.tree.put(srcPath, entry);\n+          invalidateLocationCache(srcPath);\n           LOG.info(\"Added new mount point {} to resolver\", srcPath);\n         } else {\n           // Node exists, check for updates\n           MountTable existingEntry \u003d this.tree.get(srcPath);\n           if (existingEntry !\u003d null \u0026\u0026 !existingEntry.equals(entry)) {\n             LOG.info(\"Entry has changed from \\\"{}\\\" to \\\"{}\\\"\",\n                 existingEntry, entry);\n             this.tree.put(srcPath, entry);\n             invalidateLocationCache(srcPath);\n             LOG.info(\"Updated mount point {} in resolver\");\n           }\n         }\n       }\n     } finally {\n       writeLock.unlock();\n     }\n     this.init \u003d true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void refreshEntries(final Collection\u003cMountTable\u003e entries) {\n    // The tree read/write must be atomic\n    writeLock.lock();\n    try {\n      // New entries\n      Map\u003cString, MountTable\u003e newEntries \u003d new ConcurrentHashMap\u003c\u003e();\n      for (MountTable entry : entries) {\n        String srcPath \u003d entry.getSourcePath();\n        newEntries.put(srcPath, entry);\n      }\n\n      // Old entries (reversed to sort from the leaves to the root)\n      Set\u003cString\u003e oldEntries \u003d new TreeSet\u003c\u003e(Collections.reverseOrder());\n      for (MountTable entry : getTreeValues(\"/\")) {\n        String srcPath \u003d entry.getSourcePath();\n        oldEntries.add(srcPath);\n      }\n\n      // Entries that need to be removed\n      for (String srcPath : oldEntries) {\n        if (!newEntries.containsKey(srcPath)) {\n          this.tree.remove(srcPath);\n          invalidateLocationCache(srcPath);\n          LOG.info(\"Removed stale mount point {} from resolver\", srcPath);\n        }\n      }\n\n      // Entries that need to be added\n      for (MountTable entry : entries) {\n        String srcPath \u003d entry.getSourcePath();\n        if (!oldEntries.contains(srcPath)) {\n          // Add node, it does not exist\n          this.tree.put(srcPath, entry);\n          invalidateLocationCache(srcPath);\n          LOG.info(\"Added new mount point {} to resolver\", srcPath);\n        } else {\n          // Node exists, check for updates\n          MountTable existingEntry \u003d this.tree.get(srcPath);\n          if (existingEntry !\u003d null \u0026\u0026 !existingEntry.equals(entry)) {\n            LOG.info(\"Entry has changed from \\\"{}\\\" to \\\"{}\\\"\",\n                existingEntry, entry);\n            this.tree.put(srcPath, entry);\n            invalidateLocationCache(srcPath);\n            LOG.info(\"Updated mount point {} in resolver\");\n          }\n        }\n      }\n    } finally {\n      writeLock.unlock();\n    }\n    this.init \u003d true;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/federation/resolver/MountTableResolver.java",
      "extendedDetails": {}
    },
    "83b513ac6d5448f3771b0b95f91e7aa7961ae2cc": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12988. RBF: Mount table entries not properly updated in the local cache. Contributed by Inigo Goiri.\n",
      "commitDate": "05/01/18 9:11 AM",
      "commitName": "83b513ac6d5448f3771b0b95f91e7aa7961ae2cc",
      "commitAuthor": "Inigo Goiri",
      "commitDateOld": "29/11/17 9:43 AM",
      "commitNameOld": "301641811d93ac22dc6fe1a05f18c1f266cc5e54",
      "commitAuthorOld": "Wei Yan",
      "daysBetweenCommits": 36.98,
      "commitsBetweenForRepo": 219,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,49 +1,51 @@\n   public void refreshEntries(final Collection\u003cMountTable\u003e entries) {\n     // The tree read/write must be atomic\n     writeLock.lock();\n     try {\n       // New entries\n       Map\u003cString, MountTable\u003e newEntries \u003d new ConcurrentHashMap\u003c\u003e();\n       for (MountTable entry : entries) {\n         String srcPath \u003d entry.getSourcePath();\n         newEntries.put(srcPath, entry);\n       }\n \n       // Old entries (reversed to sort from the leaves to the root)\n       Set\u003cString\u003e oldEntries \u003d new TreeSet\u003c\u003e(Collections.reverseOrder());\n       for (MountTable entry : getTreeValues(\"/\")) {\n         String srcPath \u003d entry.getSourcePath();\n         oldEntries.add(srcPath);\n       }\n \n       // Entries that need to be removed\n       for (String srcPath : oldEntries) {\n         if (!newEntries.containsKey(srcPath)) {\n           this.tree.remove(srcPath);\n           invalidateLocationCache(srcPath);\n           LOG.info(\"Removed stale mount point {} from resolver\", srcPath);\n         }\n       }\n \n       // Entries that need to be added\n       for (MountTable entry : entries) {\n         String srcPath \u003d entry.getSourcePath();\n         if (!oldEntries.contains(srcPath)) {\n           // Add node, it does not exist\n           this.tree.put(srcPath, entry);\n           LOG.info(\"Added new mount point {} to resolver\", srcPath);\n         } else {\n           // Node exists, check for updates\n           MountTable existingEntry \u003d this.tree.get(srcPath);\n           if (existingEntry !\u003d null \u0026\u0026 !existingEntry.equals(entry)) {\n-            // Entry has changed\n+            LOG.info(\"Entry has changed from \\\"{}\\\" to \\\"{}\\\"\",\n+                existingEntry, entry);\n+            this.tree.put(srcPath, entry);\n             invalidateLocationCache(srcPath);\n             LOG.info(\"Updated mount point {} in resolver\");\n           }\n         }\n       }\n     } finally {\n       writeLock.unlock();\n     }\n     this.init \u003d true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void refreshEntries(final Collection\u003cMountTable\u003e entries) {\n    // The tree read/write must be atomic\n    writeLock.lock();\n    try {\n      // New entries\n      Map\u003cString, MountTable\u003e newEntries \u003d new ConcurrentHashMap\u003c\u003e();\n      for (MountTable entry : entries) {\n        String srcPath \u003d entry.getSourcePath();\n        newEntries.put(srcPath, entry);\n      }\n\n      // Old entries (reversed to sort from the leaves to the root)\n      Set\u003cString\u003e oldEntries \u003d new TreeSet\u003c\u003e(Collections.reverseOrder());\n      for (MountTable entry : getTreeValues(\"/\")) {\n        String srcPath \u003d entry.getSourcePath();\n        oldEntries.add(srcPath);\n      }\n\n      // Entries that need to be removed\n      for (String srcPath : oldEntries) {\n        if (!newEntries.containsKey(srcPath)) {\n          this.tree.remove(srcPath);\n          invalidateLocationCache(srcPath);\n          LOG.info(\"Removed stale mount point {} from resolver\", srcPath);\n        }\n      }\n\n      // Entries that need to be added\n      for (MountTable entry : entries) {\n        String srcPath \u003d entry.getSourcePath();\n        if (!oldEntries.contains(srcPath)) {\n          // Add node, it does not exist\n          this.tree.put(srcPath, entry);\n          LOG.info(\"Added new mount point {} to resolver\", srcPath);\n        } else {\n          // Node exists, check for updates\n          MountTable existingEntry \u003d this.tree.get(srcPath);\n          if (existingEntry !\u003d null \u0026\u0026 !existingEntry.equals(entry)) {\n            LOG.info(\"Entry has changed from \\\"{}\\\" to \\\"{}\\\"\",\n                existingEntry, entry);\n            this.tree.put(srcPath, entry);\n            invalidateLocationCache(srcPath);\n            LOG.info(\"Updated mount point {} in resolver\");\n          }\n        }\n      }\n    } finally {\n      writeLock.unlock();\n    }\n    this.init \u003d true;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/federation/resolver/MountTableResolver.java",
      "extendedDetails": {}
    },
    "6f0de2731806628b5b01bd1350225692147590da": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-10880. Federation Mount Table State Store internal API. Contributed by Jason Kace and Inigo Goiri.\n\n(cherry picked from commit 58b97df661441150d35abd44b3a8606206b46441)\n",
      "commitDate": "06/10/17 6:50 PM",
      "commitName": "6f0de2731806628b5b01bd1350225692147590da",
      "commitAuthor": "Inigo Goiri",
      "diff": "@@ -0,0 +1,49 @@\n+  public void refreshEntries(final Collection\u003cMountTable\u003e entries) {\n+    // The tree read/write must be atomic\n+    writeLock.lock();\n+    try {\n+      // New entries\n+      Map\u003cString, MountTable\u003e newEntries \u003d new ConcurrentHashMap\u003c\u003e();\n+      for (MountTable entry : entries) {\n+        String srcPath \u003d entry.getSourcePath();\n+        newEntries.put(srcPath, entry);\n+      }\n+\n+      // Old entries (reversed to sort from the leaves to the root)\n+      Set\u003cString\u003e oldEntries \u003d new TreeSet\u003c\u003e(Collections.reverseOrder());\n+      for (MountTable entry : getTreeValues(\"/\")) {\n+        String srcPath \u003d entry.getSourcePath();\n+        oldEntries.add(srcPath);\n+      }\n+\n+      // Entries that need to be removed\n+      for (String srcPath : oldEntries) {\n+        if (!newEntries.containsKey(srcPath)) {\n+          this.tree.remove(srcPath);\n+          invalidateLocationCache(srcPath);\n+          LOG.info(\"Removed stale mount point {} from resolver\", srcPath);\n+        }\n+      }\n+\n+      // Entries that need to be added\n+      for (MountTable entry : entries) {\n+        String srcPath \u003d entry.getSourcePath();\n+        if (!oldEntries.contains(srcPath)) {\n+          // Add node, it does not exist\n+          this.tree.put(srcPath, entry);\n+          LOG.info(\"Added new mount point {} to resolver\", srcPath);\n+        } else {\n+          // Node exists, check for updates\n+          MountTable existingEntry \u003d this.tree.get(srcPath);\n+          if (existingEntry !\u003d null \u0026\u0026 !existingEntry.equals(entry)) {\n+            // Entry has changed\n+            invalidateLocationCache(srcPath);\n+            LOG.info(\"Updated mount point {} in resolver\");\n+          }\n+        }\n+      }\n+    } finally {\n+      writeLock.unlock();\n+    }\n+    this.init \u003d true;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void refreshEntries(final Collection\u003cMountTable\u003e entries) {\n    // The tree read/write must be atomic\n    writeLock.lock();\n    try {\n      // New entries\n      Map\u003cString, MountTable\u003e newEntries \u003d new ConcurrentHashMap\u003c\u003e();\n      for (MountTable entry : entries) {\n        String srcPath \u003d entry.getSourcePath();\n        newEntries.put(srcPath, entry);\n      }\n\n      // Old entries (reversed to sort from the leaves to the root)\n      Set\u003cString\u003e oldEntries \u003d new TreeSet\u003c\u003e(Collections.reverseOrder());\n      for (MountTable entry : getTreeValues(\"/\")) {\n        String srcPath \u003d entry.getSourcePath();\n        oldEntries.add(srcPath);\n      }\n\n      // Entries that need to be removed\n      for (String srcPath : oldEntries) {\n        if (!newEntries.containsKey(srcPath)) {\n          this.tree.remove(srcPath);\n          invalidateLocationCache(srcPath);\n          LOG.info(\"Removed stale mount point {} from resolver\", srcPath);\n        }\n      }\n\n      // Entries that need to be added\n      for (MountTable entry : entries) {\n        String srcPath \u003d entry.getSourcePath();\n        if (!oldEntries.contains(srcPath)) {\n          // Add node, it does not exist\n          this.tree.put(srcPath, entry);\n          LOG.info(\"Added new mount point {} to resolver\", srcPath);\n        } else {\n          // Node exists, check for updates\n          MountTable existingEntry \u003d this.tree.get(srcPath);\n          if (existingEntry !\u003d null \u0026\u0026 !existingEntry.equals(entry)) {\n            // Entry has changed\n            invalidateLocationCache(srcPath);\n            LOG.info(\"Updated mount point {} in resolver\");\n          }\n        }\n      }\n    } finally {\n      writeLock.unlock();\n    }\n    this.init \u003d true;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/federation/resolver/MountTableResolver.java"
    }
  }
}