{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DataStreamer.java",
  "functionName": "updatePipeline",
  "functionId": "updatePipeline___newGS-long",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DataStreamer.java",
  "functionStartLine": 1636,
  "functionEndLine": 1643,
  "numCommitsSeen": 53,
  "timeTaken": 3475,
  "changeHistory": [
    "8455d70756b584ddf27fc626a147f4eb2e1dc94e",
    "627da6f7178e18aa41996969c408b6f344e297d1",
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c",
    "8f378733423a5244461df79a92c00239514b8b93"
  ],
  "changeHistoryShort": {
    "8455d70756b584ddf27fc626a147f4eb2e1dc94e": "Ymodifierchange",
    "627da6f7178e18aa41996969c408b6f344e297d1": "Ymultichange(Yreturntypechange,Ymodifierchange,Ybodychange)",
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c": "Yfilerename",
    "8f378733423a5244461df79a92c00239514b8b93": "Yintroduced"
  },
  "changeHistoryDetails": {
    "8455d70756b584ddf27fc626a147f4eb2e1dc94e": {
      "type": "Ymodifierchange",
      "commitMessage": "HDFS-12299. Race Between update pipeline and DN Re-Registration\n",
      "commitDate": "25/08/17 12:49 PM",
      "commitName": "8455d70756b584ddf27fc626a147f4eb2e1dc94e",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "25/05/17 11:05 AM",
      "commitNameOld": "29b7df960fc3d0a7d1416225c3106c7d4222f0ca",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 92.07,
      "commitsBetweenForRepo": 527,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,8 +1,8 @@\n-  private void updatePipeline(long newGS) throws IOException {\n+  public void updatePipeline(long newGS) throws IOException {\n     final ExtendedBlock oldBlock \u003d block.getCurrentBlock();\n     // the new GS has been propagated to all DN, it should be ok to update the\n     // local block state\n     updateBlockGS(newGS);\n     dfsClient.namenode.updatePipeline(dfsClient.clientName, oldBlock,\n         block.getCurrentBlock(), nodes, storageIDs);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void updatePipeline(long newGS) throws IOException {\n    final ExtendedBlock oldBlock \u003d block.getCurrentBlock();\n    // the new GS has been propagated to all DN, it should be ok to update the\n    // local block state\n    updateBlockGS(newGS);\n    dfsClient.namenode.updatePipeline(dfsClient.clientName, oldBlock,\n        block.getCurrentBlock(), nodes, storageIDs);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DataStreamer.java",
      "extendedDetails": {
        "oldValue": "[private]",
        "newValue": "[public]"
      }
    },
    "627da6f7178e18aa41996969c408b6f344e297d1": {
      "type": "Ymultichange(Yreturntypechange,Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-8498. Blocks can be committed with wrong size. Contributed by Jing Zhao.\n",
      "commitDate": "15/02/17 10:44 AM",
      "commitName": "627da6f7178e18aa41996969c408b6f344e297d1",
      "commitAuthor": "Jing Zhao",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-8498. Blocks can be committed with wrong size. Contributed by Jing Zhao.\n",
          "commitDate": "15/02/17 10:44 AM",
          "commitName": "627da6f7178e18aa41996969c408b6f344e297d1",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "02/02/17 10:08 AM",
          "commitNameOld": "0914fcca312b5e9d20bcf1b6633bc13c9034ba46",
          "commitAuthorOld": "Xiao Chen",
          "daysBetweenCommits": 13.03,
          "commitsBetweenForRepo": 61,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,6 +1,8 @@\n-  ExtendedBlock updatePipeline(long newGS) throws IOException {\n-    final ExtendedBlock newBlock \u003d newBlock(block, newGS);\n-    dfsClient.namenode.updatePipeline(dfsClient.clientName, block, newBlock,\n-        nodes, storageIDs);\n-    return newBlock;\n+  private void updatePipeline(long newGS) throws IOException {\n+    final ExtendedBlock oldBlock \u003d block.getCurrentBlock();\n+    // the new GS has been propagated to all DN, it should be ok to update the\n+    // local block state\n+    updateBlockGS(newGS);\n+    dfsClient.namenode.updatePipeline(dfsClient.clientName, oldBlock,\n+        block.getCurrentBlock(), nodes, storageIDs);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void updatePipeline(long newGS) throws IOException {\n    final ExtendedBlock oldBlock \u003d block.getCurrentBlock();\n    // the new GS has been propagated to all DN, it should be ok to update the\n    // local block state\n    updateBlockGS(newGS);\n    dfsClient.namenode.updatePipeline(dfsClient.clientName, oldBlock,\n        block.getCurrentBlock(), nodes, storageIDs);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DataStreamer.java",
          "extendedDetails": {
            "oldValue": "ExtendedBlock",
            "newValue": "void"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-8498. Blocks can be committed with wrong size. Contributed by Jing Zhao.\n",
          "commitDate": "15/02/17 10:44 AM",
          "commitName": "627da6f7178e18aa41996969c408b6f344e297d1",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "02/02/17 10:08 AM",
          "commitNameOld": "0914fcca312b5e9d20bcf1b6633bc13c9034ba46",
          "commitAuthorOld": "Xiao Chen",
          "daysBetweenCommits": 13.03,
          "commitsBetweenForRepo": 61,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,6 +1,8 @@\n-  ExtendedBlock updatePipeline(long newGS) throws IOException {\n-    final ExtendedBlock newBlock \u003d newBlock(block, newGS);\n-    dfsClient.namenode.updatePipeline(dfsClient.clientName, block, newBlock,\n-        nodes, storageIDs);\n-    return newBlock;\n+  private void updatePipeline(long newGS) throws IOException {\n+    final ExtendedBlock oldBlock \u003d block.getCurrentBlock();\n+    // the new GS has been propagated to all DN, it should be ok to update the\n+    // local block state\n+    updateBlockGS(newGS);\n+    dfsClient.namenode.updatePipeline(dfsClient.clientName, oldBlock,\n+        block.getCurrentBlock(), nodes, storageIDs);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void updatePipeline(long newGS) throws IOException {\n    final ExtendedBlock oldBlock \u003d block.getCurrentBlock();\n    // the new GS has been propagated to all DN, it should be ok to update the\n    // local block state\n    updateBlockGS(newGS);\n    dfsClient.namenode.updatePipeline(dfsClient.clientName, oldBlock,\n        block.getCurrentBlock(), nodes, storageIDs);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DataStreamer.java",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[private]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-8498. Blocks can be committed with wrong size. Contributed by Jing Zhao.\n",
          "commitDate": "15/02/17 10:44 AM",
          "commitName": "627da6f7178e18aa41996969c408b6f344e297d1",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "02/02/17 10:08 AM",
          "commitNameOld": "0914fcca312b5e9d20bcf1b6633bc13c9034ba46",
          "commitAuthorOld": "Xiao Chen",
          "daysBetweenCommits": 13.03,
          "commitsBetweenForRepo": 61,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,6 +1,8 @@\n-  ExtendedBlock updatePipeline(long newGS) throws IOException {\n-    final ExtendedBlock newBlock \u003d newBlock(block, newGS);\n-    dfsClient.namenode.updatePipeline(dfsClient.clientName, block, newBlock,\n-        nodes, storageIDs);\n-    return newBlock;\n+  private void updatePipeline(long newGS) throws IOException {\n+    final ExtendedBlock oldBlock \u003d block.getCurrentBlock();\n+    // the new GS has been propagated to all DN, it should be ok to update the\n+    // local block state\n+    updateBlockGS(newGS);\n+    dfsClient.namenode.updatePipeline(dfsClient.clientName, oldBlock,\n+        block.getCurrentBlock(), nodes, storageIDs);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void updatePipeline(long newGS) throws IOException {\n    final ExtendedBlock oldBlock \u003d block.getCurrentBlock();\n    // the new GS has been propagated to all DN, it should be ok to update the\n    // local block state\n    updateBlockGS(newGS);\n    dfsClient.namenode.updatePipeline(dfsClient.clientName, oldBlock,\n        block.getCurrentBlock(), nodes, storageIDs);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DataStreamer.java",
          "extendedDetails": {}
        }
      ]
    },
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8053. Move DFSIn/OutputStream and related classes to hadoop-hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "26/09/15 11:08 AM",
      "commitName": "bf37d3d80e5179dea27e5bd5aea804a38aa9934c",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "26/09/15 9:06 AM",
      "commitNameOld": "861b52db242f238d7e36ad75c158025be959a696",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 0.08,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  ExtendedBlock updatePipeline(long newGS) throws IOException {\n    final ExtendedBlock newBlock \u003d new ExtendedBlock(\n        block.getBlockPoolId(), block.getBlockId(), block.getNumBytes(), newGS);\n    dfsClient.namenode.updatePipeline(dfsClient.clientName, block, newBlock,\n        nodes, storageIDs);\n    return newBlock;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DataStreamer.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DataStreamer.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DataStreamer.java"
      }
    },
    "8f378733423a5244461df79a92c00239514b8b93": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-8397. Refactor the error handling code in DataStreamer. Contributed by Tsz Wo Nicholas Sze.\n",
      "commitDate": "15/05/15 4:14 PM",
      "commitName": "8f378733423a5244461df79a92c00239514b8b93",
      "commitAuthor": "Jing Zhao",
      "diff": "@@ -0,0 +1,7 @@\n+  ExtendedBlock updatePipeline(long newGS) throws IOException {\n+    final ExtendedBlock newBlock \u003d new ExtendedBlock(\n+        block.getBlockPoolId(), block.getBlockId(), block.getNumBytes(), newGS);\n+    dfsClient.namenode.updatePipeline(dfsClient.clientName, block, newBlock,\n+        nodes, storageIDs);\n+    return newBlock;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  ExtendedBlock updatePipeline(long newGS) throws IOException {\n    final ExtendedBlock newBlock \u003d new ExtendedBlock(\n        block.getBlockPoolId(), block.getBlockId(), block.getNumBytes(), newGS);\n    dfsClient.namenode.updatePipeline(dfsClient.clientName, block, newBlock,\n        nodes, storageIDs);\n    return newBlock;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DataStreamer.java"
    }
  }
}