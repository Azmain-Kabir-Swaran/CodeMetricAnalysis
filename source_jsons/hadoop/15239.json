{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DFSAdmin.java",
  "functionName": "refreshCallQueue",
  "functionId": "refreshCallQueue",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java",
  "functionStartLine": 1794,
  "functionEndLine": 1841,
  "numCommitsSeen": 114,
  "timeTaken": 4260,
  "changeHistory": [
    "01bd6ab18fa48f4c7cac1497905b52e547962599",
    "6f8003dc7bc9e8be7b0512c514d370c303faf003",
    "e8ca6480050e38d2fe4859baf4f9a8d22e7f9b85",
    "02d28907beab7110abf768fd4006b076a6bf2bd2",
    "a5b37c6ed14e92f5a7f7dd76a9a82b3f859fb6dd",
    "d00605f8f0214ed8e2304db8688e140f0a1d62d8"
  ],
  "changeHistoryShort": {
    "01bd6ab18fa48f4c7cac1497905b52e547962599": "Ybodychange",
    "6f8003dc7bc9e8be7b0512c514d370c303faf003": "Ybodychange",
    "e8ca6480050e38d2fe4859baf4f9a8d22e7f9b85": "Ybodychange",
    "02d28907beab7110abf768fd4006b076a6bf2bd2": "Ybodychange",
    "a5b37c6ed14e92f5a7f7dd76a9a82b3f859fb6dd": "Ybodychange",
    "d00605f8f0214ed8e2304db8688e140f0a1d62d8": "Yintroduced"
  },
  "changeHistoryDetails": {
    "01bd6ab18fa48f4c7cac1497905b52e547962599": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12935. Get ambiguous result for DFSAdmin command in HA mode when only one namenode is up. Contributed by Jianfei Jiang.\n",
      "commitDate": "07/02/18 9:40 AM",
      "commitName": "01bd6ab18fa48f4c7cac1497905b52e547962599",
      "commitAuthor": "Brahma Reddy Battula",
      "commitDateOld": "05/01/18 10:31 PM",
      "commitNameOld": "bf5c94899537011465350d5d999fad9ffaeb605d",
      "commitAuthorOld": "Yiqun Lin",
      "daysBetweenCommits": 32.46,
      "commitsBetweenForRepo": 204,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,38 +1,48 @@\n   public int refreshCallQueue() throws IOException {\n     // Get the current configuration\n     Configuration conf \u003d getConf();\n     \n     // for security authorization\n     // server principal for this call   \n     // should be NN\u0027s one.\n     conf.set(CommonConfigurationKeys.HADOOP_SECURITY_SERVICE_USER_NAME_KEY, \n         conf.get(DFSConfigKeys.DFS_NAMENODE_KERBEROS_PRINCIPAL_KEY, \"\"));\n \n     DistributedFileSystem dfs \u003d getDFS();\n     URI dfsUri \u003d dfs.getUri();\n     boolean isHaEnabled \u003d HAUtilClient.isLogicalUri(conf, dfsUri);\n \n     if (isHaEnabled) {\n       // Run refreshCallQueue for all NNs if HA is enabled\n       String nsId \u003d dfsUri.getHost();\n       List\u003cProxyAndInfo\u003cRefreshCallQueueProtocol\u003e\u003e proxies \u003d\n           HAUtil.getProxiesForAllNameNodesInNameservice(conf, nsId,\n               RefreshCallQueueProtocol.class);\n+      List\u003cIOException\u003e exceptions \u003d new ArrayList\u003c\u003e();\n       for (ProxyAndInfo\u003cRefreshCallQueueProtocol\u003e proxy : proxies) {\n-        proxy.getProxy().refreshCallQueue();\n-        System.out.println(\"Refresh call queue successful for \"\n-            + proxy.getAddress());\n+        try{\n+          proxy.getProxy().refreshCallQueue();\n+          System.out.println(\"Refresh call queue successful for \"\n+              + proxy.getAddress());\n+        }catch (IOException ioe){\n+          System.out.println(\"Refresh call queue failed for \"\n+              + proxy.getAddress());\n+          exceptions.add(ioe);\n+        }\n+      }\n+      if(!exceptions.isEmpty()){\n+        throw MultipleIOException.createIOException(exceptions);\n       }\n     } else {\n       // Create the client\n       RefreshCallQueueProtocol refreshProtocol \u003d\n           NameNodeProxies.createProxy(conf, FileSystem.getDefaultUri(conf),\n               RefreshCallQueueProtocol.class).getProxy();\n \n       // Refresh the call queue\n       refreshProtocol.refreshCallQueue();\n       System.out.println(\"Refresh call queue successful\");\n     }\n \n     return 0;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int refreshCallQueue() throws IOException {\n    // Get the current configuration\n    Configuration conf \u003d getConf();\n    \n    // for security authorization\n    // server principal for this call   \n    // should be NN\u0027s one.\n    conf.set(CommonConfigurationKeys.HADOOP_SECURITY_SERVICE_USER_NAME_KEY, \n        conf.get(DFSConfigKeys.DFS_NAMENODE_KERBEROS_PRINCIPAL_KEY, \"\"));\n\n    DistributedFileSystem dfs \u003d getDFS();\n    URI dfsUri \u003d dfs.getUri();\n    boolean isHaEnabled \u003d HAUtilClient.isLogicalUri(conf, dfsUri);\n\n    if (isHaEnabled) {\n      // Run refreshCallQueue for all NNs if HA is enabled\n      String nsId \u003d dfsUri.getHost();\n      List\u003cProxyAndInfo\u003cRefreshCallQueueProtocol\u003e\u003e proxies \u003d\n          HAUtil.getProxiesForAllNameNodesInNameservice(conf, nsId,\n              RefreshCallQueueProtocol.class);\n      List\u003cIOException\u003e exceptions \u003d new ArrayList\u003c\u003e();\n      for (ProxyAndInfo\u003cRefreshCallQueueProtocol\u003e proxy : proxies) {\n        try{\n          proxy.getProxy().refreshCallQueue();\n          System.out.println(\"Refresh call queue successful for \"\n              + proxy.getAddress());\n        }catch (IOException ioe){\n          System.out.println(\"Refresh call queue failed for \"\n              + proxy.getAddress());\n          exceptions.add(ioe);\n        }\n      }\n      if(!exceptions.isEmpty()){\n        throw MultipleIOException.createIOException(exceptions);\n      }\n    } else {\n      // Create the client\n      RefreshCallQueueProtocol refreshProtocol \u003d\n          NameNodeProxies.createProxy(conf, FileSystem.getDefaultUri(conf),\n              RefreshCallQueueProtocol.class).getProxy();\n\n      // Refresh the call queue\n      refreshProtocol.refreshCallQueue();\n      System.out.println(\"Refresh call queue successful\");\n    }\n\n    return 0;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java",
      "extendedDetails": {}
    },
    "6f8003dc7bc9e8be7b0512c514d370c303faf003": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8185. Separate client related routines in HAUtil into a new class. Contributed by Haohui Mai.\n",
      "commitDate": "21/04/15 9:59 PM",
      "commitName": "6f8003dc7bc9e8be7b0512c514d370c303faf003",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "25/03/15 10:38 AM",
      "commitNameOld": "5e21e4ca377f68e030f8f3436cd93fd7a74dc5e0",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 27.47,
      "commitsBetweenForRepo": 221,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,38 +1,38 @@\n   public int refreshCallQueue() throws IOException {\n     // Get the current configuration\n     Configuration conf \u003d getConf();\n     \n     // for security authorization\n     // server principal for this call   \n     // should be NN\u0027s one.\n     conf.set(CommonConfigurationKeys.HADOOP_SECURITY_SERVICE_USER_NAME_KEY, \n         conf.get(DFSConfigKeys.DFS_NAMENODE_KERBEROS_PRINCIPAL_KEY, \"\"));\n \n     DistributedFileSystem dfs \u003d getDFS();\n     URI dfsUri \u003d dfs.getUri();\n-    boolean isHaEnabled \u003d HAUtil.isLogicalUri(conf, dfsUri);\n+    boolean isHaEnabled \u003d HAUtilClient.isLogicalUri(conf, dfsUri);\n \n     if (isHaEnabled) {\n       // Run refreshCallQueue for all NNs if HA is enabled\n       String nsId \u003d dfsUri.getHost();\n       List\u003cProxyAndInfo\u003cRefreshCallQueueProtocol\u003e\u003e proxies \u003d\n           HAUtil.getProxiesForAllNameNodesInNameservice(conf, nsId,\n               RefreshCallQueueProtocol.class);\n       for (ProxyAndInfo\u003cRefreshCallQueueProtocol\u003e proxy : proxies) {\n         proxy.getProxy().refreshCallQueue();\n         System.out.println(\"Refresh call queue successful for \"\n             + proxy.getAddress());\n       }\n     } else {\n       // Create the client\n       RefreshCallQueueProtocol refreshProtocol \u003d\n           NameNodeProxies.createProxy(conf, FileSystem.getDefaultUri(conf),\n               RefreshCallQueueProtocol.class).getProxy();\n \n       // Refresh the call queue\n       refreshProtocol.refreshCallQueue();\n       System.out.println(\"Refresh call queue successful\");\n     }\n \n     return 0;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int refreshCallQueue() throws IOException {\n    // Get the current configuration\n    Configuration conf \u003d getConf();\n    \n    // for security authorization\n    // server principal for this call   \n    // should be NN\u0027s one.\n    conf.set(CommonConfigurationKeys.HADOOP_SECURITY_SERVICE_USER_NAME_KEY, \n        conf.get(DFSConfigKeys.DFS_NAMENODE_KERBEROS_PRINCIPAL_KEY, \"\"));\n\n    DistributedFileSystem dfs \u003d getDFS();\n    URI dfsUri \u003d dfs.getUri();\n    boolean isHaEnabled \u003d HAUtilClient.isLogicalUri(conf, dfsUri);\n\n    if (isHaEnabled) {\n      // Run refreshCallQueue for all NNs if HA is enabled\n      String nsId \u003d dfsUri.getHost();\n      List\u003cProxyAndInfo\u003cRefreshCallQueueProtocol\u003e\u003e proxies \u003d\n          HAUtil.getProxiesForAllNameNodesInNameservice(conf, nsId,\n              RefreshCallQueueProtocol.class);\n      for (ProxyAndInfo\u003cRefreshCallQueueProtocol\u003e proxy : proxies) {\n        proxy.getProxy().refreshCallQueue();\n        System.out.println(\"Refresh call queue successful for \"\n            + proxy.getAddress());\n      }\n    } else {\n      // Create the client\n      RefreshCallQueueProtocol refreshProtocol \u003d\n          NameNodeProxies.createProxy(conf, FileSystem.getDefaultUri(conf),\n              RefreshCallQueueProtocol.class).getProxy();\n\n      // Refresh the call queue\n      refreshProtocol.refreshCallQueue();\n      System.out.println(\"Refresh call queue successful\");\n    }\n\n    return 0;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java",
      "extendedDetails": {}
    },
    "e8ca6480050e38d2fe4859baf4f9a8d22e7f9b85": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6507. Improve DFSAdmin to support HA cluster better. (Contributd by Zesheng Wu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1604692 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "22/06/14 10:16 PM",
      "commitName": "e8ca6480050e38d2fe4859baf4f9a8d22e7f9b85",
      "commitAuthor": "Vinayakumar B",
      "commitDateOld": "11/06/14 6:27 PM",
      "commitNameOld": "34e9173c00f7e1ae55dec365850849c793cde8e3",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 11.16,
      "commitsBetweenForRepo": 76,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,38 @@\n   public int refreshCallQueue() throws IOException {\n     // Get the current configuration\n     Configuration conf \u003d getConf();\n     \n     // for security authorization\n     // server principal for this call   \n     // should be NN\u0027s one.\n     conf.set(CommonConfigurationKeys.HADOOP_SECURITY_SERVICE_USER_NAME_KEY, \n         conf.get(DFSConfigKeys.DFS_NAMENODE_KERBEROS_PRINCIPAL_KEY, \"\"));\n- \n-    // Create the client\n-    RefreshCallQueueProtocol refreshProtocol \u003d\n-      NameNodeProxies.createProxy(conf, FileSystem.getDefaultUri(conf),\n-          RefreshCallQueueProtocol.class).getProxy();\n \n-    // Refresh the call queue\n-    refreshProtocol.refreshCallQueue();\n-    \n+    DistributedFileSystem dfs \u003d getDFS();\n+    URI dfsUri \u003d dfs.getUri();\n+    boolean isHaEnabled \u003d HAUtil.isLogicalUri(conf, dfsUri);\n+\n+    if (isHaEnabled) {\n+      // Run refreshCallQueue for all NNs if HA is enabled\n+      String nsId \u003d dfsUri.getHost();\n+      List\u003cProxyAndInfo\u003cRefreshCallQueueProtocol\u003e\u003e proxies \u003d\n+          HAUtil.getProxiesForAllNameNodesInNameservice(conf, nsId,\n+              RefreshCallQueueProtocol.class);\n+      for (ProxyAndInfo\u003cRefreshCallQueueProtocol\u003e proxy : proxies) {\n+        proxy.getProxy().refreshCallQueue();\n+        System.out.println(\"Refresh call queue successful for \"\n+            + proxy.getAddress());\n+      }\n+    } else {\n+      // Create the client\n+      RefreshCallQueueProtocol refreshProtocol \u003d\n+          NameNodeProxies.createProxy(conf, FileSystem.getDefaultUri(conf),\n+              RefreshCallQueueProtocol.class).getProxy();\n+\n+      // Refresh the call queue\n+      refreshProtocol.refreshCallQueue();\n+      System.out.println(\"Refresh call queue successful\");\n+    }\n+\n     return 0;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int refreshCallQueue() throws IOException {\n    // Get the current configuration\n    Configuration conf \u003d getConf();\n    \n    // for security authorization\n    // server principal for this call   \n    // should be NN\u0027s one.\n    conf.set(CommonConfigurationKeys.HADOOP_SECURITY_SERVICE_USER_NAME_KEY, \n        conf.get(DFSConfigKeys.DFS_NAMENODE_KERBEROS_PRINCIPAL_KEY, \"\"));\n\n    DistributedFileSystem dfs \u003d getDFS();\n    URI dfsUri \u003d dfs.getUri();\n    boolean isHaEnabled \u003d HAUtil.isLogicalUri(conf, dfsUri);\n\n    if (isHaEnabled) {\n      // Run refreshCallQueue for all NNs if HA is enabled\n      String nsId \u003d dfsUri.getHost();\n      List\u003cProxyAndInfo\u003cRefreshCallQueueProtocol\u003e\u003e proxies \u003d\n          HAUtil.getProxiesForAllNameNodesInNameservice(conf, nsId,\n              RefreshCallQueueProtocol.class);\n      for (ProxyAndInfo\u003cRefreshCallQueueProtocol\u003e proxy : proxies) {\n        proxy.getProxy().refreshCallQueue();\n        System.out.println(\"Refresh call queue successful for \"\n            + proxy.getAddress());\n      }\n    } else {\n      // Create the client\n      RefreshCallQueueProtocol refreshProtocol \u003d\n          NameNodeProxies.createProxy(conf, FileSystem.getDefaultUri(conf),\n              RefreshCallQueueProtocol.class).getProxy();\n\n      // Refresh the call queue\n      refreshProtocol.refreshCallQueue();\n      System.out.println(\"Refresh call queue successful\");\n    }\n\n    return 0;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java",
      "extendedDetails": {}
    },
    "02d28907beab7110abf768fd4006b076a6bf2bd2": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-10508. RefreshCallQueue fails when authorization is enabled. Contributed by Chris Li.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1590876 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/04/14 11:04 PM",
      "commitName": "02d28907beab7110abf768fd4006b076a6bf2bd2",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "07/04/14 11:55 AM",
      "commitNameOld": "a5b37c6ed14e92f5a7f7dd76a9a82b3f859fb6dd",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 21.46,
      "commitsBetweenForRepo": 145,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,20 @@\n   public int refreshCallQueue() throws IOException {\n     // Get the current configuration\n     Configuration conf \u003d getConf();\n     \n     // for security authorization\n     // server principal for this call   \n     // should be NN\u0027s one.\n     conf.set(CommonConfigurationKeys.HADOOP_SECURITY_SERVICE_USER_NAME_KEY, \n         conf.get(DFSConfigKeys.DFS_NAMENODE_KERBEROS_PRINCIPAL_KEY, \"\"));\n  \n     // Create the client\n     RefreshCallQueueProtocol refreshProtocol \u003d\n       NameNodeProxies.createProxy(conf, FileSystem.getDefaultUri(conf),\n           RefreshCallQueueProtocol.class).getProxy();\n \n-    // Refresh the user-to-groups mappings\n+    // Refresh the call queue\n     refreshProtocol.refreshCallQueue();\n     \n     return 0;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int refreshCallQueue() throws IOException {\n    // Get the current configuration\n    Configuration conf \u003d getConf();\n    \n    // for security authorization\n    // server principal for this call   \n    // should be NN\u0027s one.\n    conf.set(CommonConfigurationKeys.HADOOP_SECURITY_SERVICE_USER_NAME_KEY, \n        conf.get(DFSConfigKeys.DFS_NAMENODE_KERBEROS_PRINCIPAL_KEY, \"\"));\n \n    // Create the client\n    RefreshCallQueueProtocol refreshProtocol \u003d\n      NameNodeProxies.createProxy(conf, FileSystem.getDefaultUri(conf),\n          RefreshCallQueueProtocol.class).getProxy();\n\n    // Refresh the call queue\n    refreshProtocol.refreshCallQueue();\n    \n    return 0;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java",
      "extendedDetails": {}
    },
    "a5b37c6ed14e92f5a7f7dd76a9a82b3f859fb6dd": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6181. Fix the wrong property names in NFS user guide. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1585563 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/04/14 11:55 AM",
      "commitName": "a5b37c6ed14e92f5a7f7dd76a9a82b3f859fb6dd",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "03/04/14 1:18 PM",
      "commitNameOld": "620809b9a063bd6ea84d582166eed3fb957dcd0a",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 3.94,
      "commitsBetweenForRepo": 14,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,20 @@\n   public int refreshCallQueue() throws IOException {\n     // Get the current configuration\n     Configuration conf \u003d getConf();\n     \n     // for security authorization\n     // server principal for this call   \n     // should be NN\u0027s one.\n     conf.set(CommonConfigurationKeys.HADOOP_SECURITY_SERVICE_USER_NAME_KEY, \n-        conf.get(DFSConfigKeys.DFS_NAMENODE_USER_NAME_KEY, \"\"));\n+        conf.get(DFSConfigKeys.DFS_NAMENODE_KERBEROS_PRINCIPAL_KEY, \"\"));\n  \n     // Create the client\n     RefreshCallQueueProtocol refreshProtocol \u003d\n       NameNodeProxies.createProxy(conf, FileSystem.getDefaultUri(conf),\n           RefreshCallQueueProtocol.class).getProxy();\n \n     // Refresh the user-to-groups mappings\n     refreshProtocol.refreshCallQueue();\n     \n     return 0;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int refreshCallQueue() throws IOException {\n    // Get the current configuration\n    Configuration conf \u003d getConf();\n    \n    // for security authorization\n    // server principal for this call   \n    // should be NN\u0027s one.\n    conf.set(CommonConfigurationKeys.HADOOP_SECURITY_SERVICE_USER_NAME_KEY, \n        conf.get(DFSConfigKeys.DFS_NAMENODE_KERBEROS_PRINCIPAL_KEY, \"\"));\n \n    // Create the client\n    RefreshCallQueueProtocol refreshProtocol \u003d\n      NameNodeProxies.createProxy(conf, FileSystem.getDefaultUri(conf),\n          RefreshCallQueueProtocol.class).getProxy();\n\n    // Refresh the user-to-groups mappings\n    refreshProtocol.refreshCallQueue();\n    \n    return 0;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java",
      "extendedDetails": {}
    },
    "d00605f8f0214ed8e2304db8688e140f0a1d62d8": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-10285. Admin interface to swap callqueue at runtime. (Contributed by Chris Li)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1573052 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/02/14 11:48 AM",
      "commitName": "d00605f8f0214ed8e2304db8688e140f0a1d62d8",
      "commitAuthor": "Arpit Agarwal",
      "diff": "@@ -0,0 +1,20 @@\n+  public int refreshCallQueue() throws IOException {\n+    // Get the current configuration\n+    Configuration conf \u003d getConf();\n+    \n+    // for security authorization\n+    // server principal for this call   \n+    // should be NN\u0027s one.\n+    conf.set(CommonConfigurationKeys.HADOOP_SECURITY_SERVICE_USER_NAME_KEY, \n+        conf.get(DFSConfigKeys.DFS_NAMENODE_USER_NAME_KEY, \"\"));\n+ \n+    // Create the client\n+    RefreshCallQueueProtocol refreshProtocol \u003d\n+      NameNodeProxies.createProxy(conf, FileSystem.getDefaultUri(conf),\n+          RefreshCallQueueProtocol.class).getProxy();\n+\n+    // Refresh the user-to-groups mappings\n+    refreshProtocol.refreshCallQueue();\n+    \n+    return 0;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public int refreshCallQueue() throws IOException {\n    // Get the current configuration\n    Configuration conf \u003d getConf();\n    \n    // for security authorization\n    // server principal for this call   \n    // should be NN\u0027s one.\n    conf.set(CommonConfigurationKeys.HADOOP_SECURITY_SERVICE_USER_NAME_KEY, \n        conf.get(DFSConfigKeys.DFS_NAMENODE_USER_NAME_KEY, \"\"));\n \n    // Create the client\n    RefreshCallQueueProtocol refreshProtocol \u003d\n      NameNodeProxies.createProxy(conf, FileSystem.getDefaultUri(conf),\n          RefreshCallQueueProtocol.class).getProxy();\n\n    // Refresh the user-to-groups mappings\n    refreshProtocol.refreshCallQueue();\n    \n    return 0;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java"
    }
  }
}