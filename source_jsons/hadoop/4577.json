{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DatanodeProtocolClientSideTranslatorPB.java",
  "functionName": "sendHeartbeat",
  "functionId": "sendHeartbeat___registration-DatanodeRegistration__reports-StorageReport[]__cacheCapacity-long__cacheUsed-long__xmitsInProgress-int__xceiverCount-int__failedVolumes-int__volumeFailureSummary-VolumeFailureSummary__requestFullBlockReportLease-boolean__slowPeers-SlowPeerReports(annotations-@Nonnull)__slowDisks-SlowDiskReports(annotations-@Nonnull)",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolClientSideTranslatorPB.java",
  "functionStartLine": 135,
  "functionEndLine": 187,
  "numCommitsSeen": 400,
  "timeTaken": 13881,
  "changeHistory": [
    "2acc50b826fa8b00f2b09d9546c4b3215b89d46d",
    "00eceed233d6e80d5c7137bf5b5286746ec4d5fb",
    "0f2d1ddc2c41c8db800c58cabb150e71804fe23a",
    "e7c8da614c37e36fb8081234f4c639d6054f6082",
    "b57368b6f893cb27d77fc9425e116f1312f4790f",
    "9f256d1d716a7e17606245fcfc619901a8fa299a",
    "06022b8fdc40e50eaac63758246353058e8cfa6d",
    "12b5b06c063d93e6c683c9b6fac9a96912f59e59",
    "9729b244de50322c2cc889c97c2ffb2b4675cf77",
    "4f9ffc7455ae2182df1da1b7e3f5a55e645fc8a4",
    "b2ce764093ba3007df67022b3bcbc43d3fe2b173",
    "4f92eb2f613e4de59c2d31a563e16aba4846c61a",
    "9673baa7e8b43fa6300080f72ebce0189ea775e5",
    "f9c08d02ebe4a5477cf5d753f0d9d48fc6f9fa48",
    "fc14a92c6b46cc435a8f33e6fa0512c70caa06e0",
    "28eadb7cd71e99d563fb5c41aec563ab11e293e5",
    "f88574acdefae2816236bf6180916be96c6a6874",
    "3cffe34177c72ea67194c3b0aaf0ddbf67ff3a0c",
    "38a19bc293dec6221ae96e304fc6ab660d94e706"
  ],
  "changeHistoryShort": {
    "2acc50b826fa8b00f2b09d9546c4b3215b89d46d": "Ymultichange(Yparameterchange,Ybodychange)",
    "00eceed233d6e80d5c7137bf5b5286746ec4d5fb": "Ymultichange(Yparameterchange,Ybodychange)",
    "0f2d1ddc2c41c8db800c58cabb150e71804fe23a": "Ymultichange(Yparameterchange,Ybodychange)",
    "e7c8da614c37e36fb8081234f4c639d6054f6082": "Ymultichange(Yparameterchange,Ybodychange)",
    "b57368b6f893cb27d77fc9425e116f1312f4790f": "Ymultichange(Yparameterchange,Ybodychange)",
    "9f256d1d716a7e17606245fcfc619901a8fa299a": "Ybodychange",
    "06022b8fdc40e50eaac63758246353058e8cfa6d": "Ybodychange",
    "12b5b06c063d93e6c683c9b6fac9a96912f59e59": "Ymultichange(Yparameterchange,Ybodychange)",
    "9729b244de50322c2cc889c97c2ffb2b4675cf77": "Ymultichange(Yparameterchange,Ybodychange)",
    "4f9ffc7455ae2182df1da1b7e3f5a55e645fc8a4": "Ybodychange",
    "b2ce764093ba3007df67022b3bcbc43d3fe2b173": "Ybodychange",
    "4f92eb2f613e4de59c2d31a563e16aba4846c61a": "Ybodychange",
    "9673baa7e8b43fa6300080f72ebce0189ea775e5": "Ymultichange(Yparameterchange,Ybodychange)",
    "f9c08d02ebe4a5477cf5d753f0d9d48fc6f9fa48": "Ymultichange(Yparameterchange,Ybodychange)",
    "fc14a92c6b46cc435a8f33e6fa0512c70caa06e0": "Ymultichange(Yparameterchange,Ybodychange)",
    "28eadb7cd71e99d563fb5c41aec563ab11e293e5": "Ymultichange(Yparameterchange,Ybodychange)",
    "f88574acdefae2816236bf6180916be96c6a6874": "Ybodychange",
    "3cffe34177c72ea67194c3b0aaf0ddbf67ff3a0c": "Ybodychange",
    "38a19bc293dec6221ae96e304fc6ab660d94e706": "Yintroduced"
  },
  "changeHistoryDetails": {
    "2acc50b826fa8b00f2b09d9546c4b3215b89d46d": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-13165: [SPS]: Collects successfully moved block details via IBR. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "2acc50b826fa8b00f2b09d9546c4b3215b89d46d",
      "commitAuthor": "Rakesh Radhakrishnan",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-13165: [SPS]: Collects successfully moved block details via IBR. Contributed by Rakesh R.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "2acc50b826fa8b00f2b09d9546c4b3215b89d46d",
          "commitAuthor": "Rakesh Radhakrishnan",
          "commitDateOld": "12/08/18 3:06 AM",
          "commitNameOld": "00eceed233d6e80d5c7137bf5b5286746ec4d5fb",
          "commitAuthorOld": "Uma Maheswara Rao G",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 17,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,61 +1,53 @@\n   public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n       StorageReport[] reports, long cacheCapacity, long cacheUsed,\n       int xmitsInProgress, int xceiverCount, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary,\n       boolean requestFullBlockReportLease,\n       @Nonnull SlowPeerReports slowPeers,\n-      @Nonnull SlowDiskReports slowDisks,\n-      BlocksStorageMoveAttemptFinished storageMovementFinishedBlks)\n+      @Nonnull SlowDiskReports slowDisks)\n           throws IOException {\n     HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n         .setRegistration(PBHelper.convert(registration))\n         .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n         .setFailedVolumes(failedVolumes)\n         .setRequestFullBlockReportLease(requestFullBlockReportLease);\n     builder.addAllReports(PBHelperClient.convertStorageReports(reports));\n     if (cacheCapacity !\u003d 0) {\n       builder.setCacheCapacity(cacheCapacity);\n     }\n     if (cacheUsed !\u003d 0) {\n       builder.setCacheUsed(cacheUsed);\n     }\n     if (volumeFailureSummary !\u003d null) {\n       builder.setVolumeFailureSummary(PBHelper.convertVolumeFailureSummary(\n           volumeFailureSummary));\n     }\n     if (slowPeers.haveSlowPeers()) {\n       builder.addAllSlowPeers(PBHelper.convertSlowPeerInfo(slowPeers));\n     }\n     if (slowDisks.haveSlowDisks()) {\n       builder.addAllSlowDisks(PBHelper.convertSlowDiskInfo(slowDisks));\n     }\n \n-    // Adding blocks movement results to the heart beat request.\n-    if (storageMovementFinishedBlks !\u003d null\n-        \u0026\u0026 storageMovementFinishedBlks.getBlocks() !\u003d null) {\n-      builder.setStorageMoveAttemptFinishedBlks(\n-          PBHelper.convertBlksMovReport(storageMovementFinishedBlks));\n-    }\n-\n     HeartbeatResponseProto resp;\n     try {\n       resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n     } catch (ServiceException se) {\n       throw ProtobufHelper.getRemoteException(se);\n     }\n     DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n     int index \u003d 0;\n     for (DatanodeCommandProto p : resp.getCmdsList()) {\n       cmds[index] \u003d PBHelper.convert(p);\n       index++;\n     }\n     RollingUpgradeStatus rollingUpdateStatus \u003d null;\n     // Use v2 semantics if available.\n     if (resp.hasRollingUpgradeStatusV2()) {\n       rollingUpdateStatus \u003d PBHelperClient.convert(resp.getRollingUpgradeStatusV2());\n     } else if (resp.hasRollingUpgradeStatus()) {\n       rollingUpdateStatus \u003d PBHelperClient.convert(resp.getRollingUpgradeStatus());\n     }\n     return new HeartbeatResponse(cmds, PBHelper.convert(resp.getHaStatus()),\n         rollingUpdateStatus, resp.getFullBlockReportLeaseId());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n      StorageReport[] reports, long cacheCapacity, long cacheUsed,\n      int xmitsInProgress, int xceiverCount, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary,\n      boolean requestFullBlockReportLease,\n      @Nonnull SlowPeerReports slowPeers,\n      @Nonnull SlowDiskReports slowDisks)\n          throws IOException {\n    HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n        .setRegistration(PBHelper.convert(registration))\n        .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n        .setFailedVolumes(failedVolumes)\n        .setRequestFullBlockReportLease(requestFullBlockReportLease);\n    builder.addAllReports(PBHelperClient.convertStorageReports(reports));\n    if (cacheCapacity !\u003d 0) {\n      builder.setCacheCapacity(cacheCapacity);\n    }\n    if (cacheUsed !\u003d 0) {\n      builder.setCacheUsed(cacheUsed);\n    }\n    if (volumeFailureSummary !\u003d null) {\n      builder.setVolumeFailureSummary(PBHelper.convertVolumeFailureSummary(\n          volumeFailureSummary));\n    }\n    if (slowPeers.haveSlowPeers()) {\n      builder.addAllSlowPeers(PBHelper.convertSlowPeerInfo(slowPeers));\n    }\n    if (slowDisks.haveSlowDisks()) {\n      builder.addAllSlowDisks(PBHelper.convertSlowDiskInfo(slowDisks));\n    }\n\n    HeartbeatResponseProto resp;\n    try {\n      resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n    } catch (ServiceException se) {\n      throw ProtobufHelper.getRemoteException(se);\n    }\n    DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n    int index \u003d 0;\n    for (DatanodeCommandProto p : resp.getCmdsList()) {\n      cmds[index] \u003d PBHelper.convert(p);\n      index++;\n    }\n    RollingUpgradeStatus rollingUpdateStatus \u003d null;\n    // Use v2 semantics if available.\n    if (resp.hasRollingUpgradeStatusV2()) {\n      rollingUpdateStatus \u003d PBHelperClient.convert(resp.getRollingUpgradeStatusV2());\n    } else if (resp.hasRollingUpgradeStatus()) {\n      rollingUpdateStatus \u003d PBHelperClient.convert(resp.getRollingUpgradeStatus());\n    }\n    return new HeartbeatResponse(cmds, PBHelper.convert(resp.getHaStatus()),\n        rollingUpdateStatus, resp.getFullBlockReportLeaseId());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolClientSideTranslatorPB.java",
          "extendedDetails": {
            "oldValue": "[registration-DatanodeRegistration, reports-StorageReport[], cacheCapacity-long, cacheUsed-long, xmitsInProgress-int, xceiverCount-int, failedVolumes-int, volumeFailureSummary-VolumeFailureSummary, requestFullBlockReportLease-boolean, slowPeers-SlowPeerReports(annotations-@Nonnull), slowDisks-SlowDiskReports(annotations-@Nonnull), storageMovementFinishedBlks-BlocksStorageMoveAttemptFinished]",
            "newValue": "[registration-DatanodeRegistration, reports-StorageReport[], cacheCapacity-long, cacheUsed-long, xmitsInProgress-int, xceiverCount-int, failedVolumes-int, volumeFailureSummary-VolumeFailureSummary, requestFullBlockReportLease-boolean, slowPeers-SlowPeerReports(annotations-@Nonnull), slowDisks-SlowDiskReports(annotations-@Nonnull)]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-13165: [SPS]: Collects successfully moved block details via IBR. Contributed by Rakesh R.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "2acc50b826fa8b00f2b09d9546c4b3215b89d46d",
          "commitAuthor": "Rakesh Radhakrishnan",
          "commitDateOld": "12/08/18 3:06 AM",
          "commitNameOld": "00eceed233d6e80d5c7137bf5b5286746ec4d5fb",
          "commitAuthorOld": "Uma Maheswara Rao G",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 17,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,61 +1,53 @@\n   public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n       StorageReport[] reports, long cacheCapacity, long cacheUsed,\n       int xmitsInProgress, int xceiverCount, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary,\n       boolean requestFullBlockReportLease,\n       @Nonnull SlowPeerReports slowPeers,\n-      @Nonnull SlowDiskReports slowDisks,\n-      BlocksStorageMoveAttemptFinished storageMovementFinishedBlks)\n+      @Nonnull SlowDiskReports slowDisks)\n           throws IOException {\n     HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n         .setRegistration(PBHelper.convert(registration))\n         .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n         .setFailedVolumes(failedVolumes)\n         .setRequestFullBlockReportLease(requestFullBlockReportLease);\n     builder.addAllReports(PBHelperClient.convertStorageReports(reports));\n     if (cacheCapacity !\u003d 0) {\n       builder.setCacheCapacity(cacheCapacity);\n     }\n     if (cacheUsed !\u003d 0) {\n       builder.setCacheUsed(cacheUsed);\n     }\n     if (volumeFailureSummary !\u003d null) {\n       builder.setVolumeFailureSummary(PBHelper.convertVolumeFailureSummary(\n           volumeFailureSummary));\n     }\n     if (slowPeers.haveSlowPeers()) {\n       builder.addAllSlowPeers(PBHelper.convertSlowPeerInfo(slowPeers));\n     }\n     if (slowDisks.haveSlowDisks()) {\n       builder.addAllSlowDisks(PBHelper.convertSlowDiskInfo(slowDisks));\n     }\n \n-    // Adding blocks movement results to the heart beat request.\n-    if (storageMovementFinishedBlks !\u003d null\n-        \u0026\u0026 storageMovementFinishedBlks.getBlocks() !\u003d null) {\n-      builder.setStorageMoveAttemptFinishedBlks(\n-          PBHelper.convertBlksMovReport(storageMovementFinishedBlks));\n-    }\n-\n     HeartbeatResponseProto resp;\n     try {\n       resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n     } catch (ServiceException se) {\n       throw ProtobufHelper.getRemoteException(se);\n     }\n     DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n     int index \u003d 0;\n     for (DatanodeCommandProto p : resp.getCmdsList()) {\n       cmds[index] \u003d PBHelper.convert(p);\n       index++;\n     }\n     RollingUpgradeStatus rollingUpdateStatus \u003d null;\n     // Use v2 semantics if available.\n     if (resp.hasRollingUpgradeStatusV2()) {\n       rollingUpdateStatus \u003d PBHelperClient.convert(resp.getRollingUpgradeStatusV2());\n     } else if (resp.hasRollingUpgradeStatus()) {\n       rollingUpdateStatus \u003d PBHelperClient.convert(resp.getRollingUpgradeStatus());\n     }\n     return new HeartbeatResponse(cmds, PBHelper.convert(resp.getHaStatus()),\n         rollingUpdateStatus, resp.getFullBlockReportLeaseId());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n      StorageReport[] reports, long cacheCapacity, long cacheUsed,\n      int xmitsInProgress, int xceiverCount, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary,\n      boolean requestFullBlockReportLease,\n      @Nonnull SlowPeerReports slowPeers,\n      @Nonnull SlowDiskReports slowDisks)\n          throws IOException {\n    HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n        .setRegistration(PBHelper.convert(registration))\n        .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n        .setFailedVolumes(failedVolumes)\n        .setRequestFullBlockReportLease(requestFullBlockReportLease);\n    builder.addAllReports(PBHelperClient.convertStorageReports(reports));\n    if (cacheCapacity !\u003d 0) {\n      builder.setCacheCapacity(cacheCapacity);\n    }\n    if (cacheUsed !\u003d 0) {\n      builder.setCacheUsed(cacheUsed);\n    }\n    if (volumeFailureSummary !\u003d null) {\n      builder.setVolumeFailureSummary(PBHelper.convertVolumeFailureSummary(\n          volumeFailureSummary));\n    }\n    if (slowPeers.haveSlowPeers()) {\n      builder.addAllSlowPeers(PBHelper.convertSlowPeerInfo(slowPeers));\n    }\n    if (slowDisks.haveSlowDisks()) {\n      builder.addAllSlowDisks(PBHelper.convertSlowDiskInfo(slowDisks));\n    }\n\n    HeartbeatResponseProto resp;\n    try {\n      resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n    } catch (ServiceException se) {\n      throw ProtobufHelper.getRemoteException(se);\n    }\n    DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n    int index \u003d 0;\n    for (DatanodeCommandProto p : resp.getCmdsList()) {\n      cmds[index] \u003d PBHelper.convert(p);\n      index++;\n    }\n    RollingUpgradeStatus rollingUpdateStatus \u003d null;\n    // Use v2 semantics if available.\n    if (resp.hasRollingUpgradeStatusV2()) {\n      rollingUpdateStatus \u003d PBHelperClient.convert(resp.getRollingUpgradeStatusV2());\n    } else if (resp.hasRollingUpgradeStatus()) {\n      rollingUpdateStatus \u003d PBHelperClient.convert(resp.getRollingUpgradeStatus());\n    }\n    return new HeartbeatResponse(cmds, PBHelper.convert(resp.getHaStatus()),\n        rollingUpdateStatus, resp.getFullBlockReportLeaseId());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolClientSideTranslatorPB.java",
          "extendedDetails": {}
        }
      ]
    },
    "00eceed233d6e80d5c7137bf5b5286746ec4d5fb": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-12570: [SPS]: Refactor Co-ordinator datanode logic to track the block storage movements. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "00eceed233d6e80d5c7137bf5b5286746ec4d5fb",
      "commitAuthor": "Uma Maheswara Rao G",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-12570: [SPS]: Refactor Co-ordinator datanode logic to track the block storage movements. Contributed by Rakesh R.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "00eceed233d6e80d5c7137bf5b5286746ec4d5fb",
          "commitAuthor": "Uma Maheswara Rao G",
          "commitDateOld": "12/08/18 3:05 AM",
          "commitNameOld": "0f2d1ddc2c41c8db800c58cabb150e71804fe23a",
          "commitAuthorOld": "Rakesh Radhakrishnan",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 36,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,57 +1,61 @@\n   public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n       StorageReport[] reports, long cacheCapacity, long cacheUsed,\n       int xmitsInProgress, int xceiverCount, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary,\n       boolean requestFullBlockReportLease,\n       @Nonnull SlowPeerReports slowPeers,\n       @Nonnull SlowDiskReports slowDisks,\n-      BlocksStorageMovementResult[] blksMovementResults) throws IOException {\n+      BlocksStorageMoveAttemptFinished storageMovementFinishedBlks)\n+          throws IOException {\n     HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n         .setRegistration(PBHelper.convert(registration))\n         .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n         .setFailedVolumes(failedVolumes)\n         .setRequestFullBlockReportLease(requestFullBlockReportLease);\n     builder.addAllReports(PBHelperClient.convertStorageReports(reports));\n     if (cacheCapacity !\u003d 0) {\n       builder.setCacheCapacity(cacheCapacity);\n     }\n     if (cacheUsed !\u003d 0) {\n       builder.setCacheUsed(cacheUsed);\n     }\n     if (volumeFailureSummary !\u003d null) {\n       builder.setVolumeFailureSummary(PBHelper.convertVolumeFailureSummary(\n           volumeFailureSummary));\n     }\n     if (slowPeers.haveSlowPeers()) {\n       builder.addAllSlowPeers(PBHelper.convertSlowPeerInfo(slowPeers));\n     }\n     if (slowDisks.haveSlowDisks()) {\n       builder.addAllSlowDisks(PBHelper.convertSlowDiskInfo(slowDisks));\n     }\n \n     // Adding blocks movement results to the heart beat request.\n-    builder.addAllBlksMovementResults(\n-        PBHelper.convertBlksMovResults(blksMovementResults));\n+    if (storageMovementFinishedBlks !\u003d null\n+        \u0026\u0026 storageMovementFinishedBlks.getBlocks() !\u003d null) {\n+      builder.setStorageMoveAttemptFinishedBlks(\n+          PBHelper.convertBlksMovReport(storageMovementFinishedBlks));\n+    }\n \n     HeartbeatResponseProto resp;\n     try {\n       resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n     } catch (ServiceException se) {\n       throw ProtobufHelper.getRemoteException(se);\n     }\n     DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n     int index \u003d 0;\n     for (DatanodeCommandProto p : resp.getCmdsList()) {\n       cmds[index] \u003d PBHelper.convert(p);\n       index++;\n     }\n     RollingUpgradeStatus rollingUpdateStatus \u003d null;\n     // Use v2 semantics if available.\n     if (resp.hasRollingUpgradeStatusV2()) {\n       rollingUpdateStatus \u003d PBHelperClient.convert(resp.getRollingUpgradeStatusV2());\n     } else if (resp.hasRollingUpgradeStatus()) {\n       rollingUpdateStatus \u003d PBHelperClient.convert(resp.getRollingUpgradeStatus());\n     }\n     return new HeartbeatResponse(cmds, PBHelper.convert(resp.getHaStatus()),\n         rollingUpdateStatus, resp.getFullBlockReportLeaseId());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n      StorageReport[] reports, long cacheCapacity, long cacheUsed,\n      int xmitsInProgress, int xceiverCount, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary,\n      boolean requestFullBlockReportLease,\n      @Nonnull SlowPeerReports slowPeers,\n      @Nonnull SlowDiskReports slowDisks,\n      BlocksStorageMoveAttemptFinished storageMovementFinishedBlks)\n          throws IOException {\n    HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n        .setRegistration(PBHelper.convert(registration))\n        .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n        .setFailedVolumes(failedVolumes)\n        .setRequestFullBlockReportLease(requestFullBlockReportLease);\n    builder.addAllReports(PBHelperClient.convertStorageReports(reports));\n    if (cacheCapacity !\u003d 0) {\n      builder.setCacheCapacity(cacheCapacity);\n    }\n    if (cacheUsed !\u003d 0) {\n      builder.setCacheUsed(cacheUsed);\n    }\n    if (volumeFailureSummary !\u003d null) {\n      builder.setVolumeFailureSummary(PBHelper.convertVolumeFailureSummary(\n          volumeFailureSummary));\n    }\n    if (slowPeers.haveSlowPeers()) {\n      builder.addAllSlowPeers(PBHelper.convertSlowPeerInfo(slowPeers));\n    }\n    if (slowDisks.haveSlowDisks()) {\n      builder.addAllSlowDisks(PBHelper.convertSlowDiskInfo(slowDisks));\n    }\n\n    // Adding blocks movement results to the heart beat request.\n    if (storageMovementFinishedBlks !\u003d null\n        \u0026\u0026 storageMovementFinishedBlks.getBlocks() !\u003d null) {\n      builder.setStorageMoveAttemptFinishedBlks(\n          PBHelper.convertBlksMovReport(storageMovementFinishedBlks));\n    }\n\n    HeartbeatResponseProto resp;\n    try {\n      resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n    } catch (ServiceException se) {\n      throw ProtobufHelper.getRemoteException(se);\n    }\n    DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n    int index \u003d 0;\n    for (DatanodeCommandProto p : resp.getCmdsList()) {\n      cmds[index] \u003d PBHelper.convert(p);\n      index++;\n    }\n    RollingUpgradeStatus rollingUpdateStatus \u003d null;\n    // Use v2 semantics if available.\n    if (resp.hasRollingUpgradeStatusV2()) {\n      rollingUpdateStatus \u003d PBHelperClient.convert(resp.getRollingUpgradeStatusV2());\n    } else if (resp.hasRollingUpgradeStatus()) {\n      rollingUpdateStatus \u003d PBHelperClient.convert(resp.getRollingUpgradeStatus());\n    }\n    return new HeartbeatResponse(cmds, PBHelper.convert(resp.getHaStatus()),\n        rollingUpdateStatus, resp.getFullBlockReportLeaseId());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolClientSideTranslatorPB.java",
          "extendedDetails": {
            "oldValue": "[registration-DatanodeRegistration, reports-StorageReport[], cacheCapacity-long, cacheUsed-long, xmitsInProgress-int, xceiverCount-int, failedVolumes-int, volumeFailureSummary-VolumeFailureSummary, requestFullBlockReportLease-boolean, slowPeers-SlowPeerReports(annotations-@Nonnull), slowDisks-SlowDiskReports(annotations-@Nonnull), blksMovementResults-BlocksStorageMovementResult[]]",
            "newValue": "[registration-DatanodeRegistration, reports-StorageReport[], cacheCapacity-long, cacheUsed-long, xmitsInProgress-int, xceiverCount-int, failedVolumes-int, volumeFailureSummary-VolumeFailureSummary, requestFullBlockReportLease-boolean, slowPeers-SlowPeerReports(annotations-@Nonnull), slowDisks-SlowDiskReports(annotations-@Nonnull), storageMovementFinishedBlks-BlocksStorageMoveAttemptFinished]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-12570: [SPS]: Refactor Co-ordinator datanode logic to track the block storage movements. Contributed by Rakesh R.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "00eceed233d6e80d5c7137bf5b5286746ec4d5fb",
          "commitAuthor": "Uma Maheswara Rao G",
          "commitDateOld": "12/08/18 3:05 AM",
          "commitNameOld": "0f2d1ddc2c41c8db800c58cabb150e71804fe23a",
          "commitAuthorOld": "Rakesh Radhakrishnan",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 36,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,57 +1,61 @@\n   public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n       StorageReport[] reports, long cacheCapacity, long cacheUsed,\n       int xmitsInProgress, int xceiverCount, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary,\n       boolean requestFullBlockReportLease,\n       @Nonnull SlowPeerReports slowPeers,\n       @Nonnull SlowDiskReports slowDisks,\n-      BlocksStorageMovementResult[] blksMovementResults) throws IOException {\n+      BlocksStorageMoveAttemptFinished storageMovementFinishedBlks)\n+          throws IOException {\n     HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n         .setRegistration(PBHelper.convert(registration))\n         .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n         .setFailedVolumes(failedVolumes)\n         .setRequestFullBlockReportLease(requestFullBlockReportLease);\n     builder.addAllReports(PBHelperClient.convertStorageReports(reports));\n     if (cacheCapacity !\u003d 0) {\n       builder.setCacheCapacity(cacheCapacity);\n     }\n     if (cacheUsed !\u003d 0) {\n       builder.setCacheUsed(cacheUsed);\n     }\n     if (volumeFailureSummary !\u003d null) {\n       builder.setVolumeFailureSummary(PBHelper.convertVolumeFailureSummary(\n           volumeFailureSummary));\n     }\n     if (slowPeers.haveSlowPeers()) {\n       builder.addAllSlowPeers(PBHelper.convertSlowPeerInfo(slowPeers));\n     }\n     if (slowDisks.haveSlowDisks()) {\n       builder.addAllSlowDisks(PBHelper.convertSlowDiskInfo(slowDisks));\n     }\n \n     // Adding blocks movement results to the heart beat request.\n-    builder.addAllBlksMovementResults(\n-        PBHelper.convertBlksMovResults(blksMovementResults));\n+    if (storageMovementFinishedBlks !\u003d null\n+        \u0026\u0026 storageMovementFinishedBlks.getBlocks() !\u003d null) {\n+      builder.setStorageMoveAttemptFinishedBlks(\n+          PBHelper.convertBlksMovReport(storageMovementFinishedBlks));\n+    }\n \n     HeartbeatResponseProto resp;\n     try {\n       resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n     } catch (ServiceException se) {\n       throw ProtobufHelper.getRemoteException(se);\n     }\n     DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n     int index \u003d 0;\n     for (DatanodeCommandProto p : resp.getCmdsList()) {\n       cmds[index] \u003d PBHelper.convert(p);\n       index++;\n     }\n     RollingUpgradeStatus rollingUpdateStatus \u003d null;\n     // Use v2 semantics if available.\n     if (resp.hasRollingUpgradeStatusV2()) {\n       rollingUpdateStatus \u003d PBHelperClient.convert(resp.getRollingUpgradeStatusV2());\n     } else if (resp.hasRollingUpgradeStatus()) {\n       rollingUpdateStatus \u003d PBHelperClient.convert(resp.getRollingUpgradeStatus());\n     }\n     return new HeartbeatResponse(cmds, PBHelper.convert(resp.getHaStatus()),\n         rollingUpdateStatus, resp.getFullBlockReportLeaseId());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n      StorageReport[] reports, long cacheCapacity, long cacheUsed,\n      int xmitsInProgress, int xceiverCount, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary,\n      boolean requestFullBlockReportLease,\n      @Nonnull SlowPeerReports slowPeers,\n      @Nonnull SlowDiskReports slowDisks,\n      BlocksStorageMoveAttemptFinished storageMovementFinishedBlks)\n          throws IOException {\n    HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n        .setRegistration(PBHelper.convert(registration))\n        .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n        .setFailedVolumes(failedVolumes)\n        .setRequestFullBlockReportLease(requestFullBlockReportLease);\n    builder.addAllReports(PBHelperClient.convertStorageReports(reports));\n    if (cacheCapacity !\u003d 0) {\n      builder.setCacheCapacity(cacheCapacity);\n    }\n    if (cacheUsed !\u003d 0) {\n      builder.setCacheUsed(cacheUsed);\n    }\n    if (volumeFailureSummary !\u003d null) {\n      builder.setVolumeFailureSummary(PBHelper.convertVolumeFailureSummary(\n          volumeFailureSummary));\n    }\n    if (slowPeers.haveSlowPeers()) {\n      builder.addAllSlowPeers(PBHelper.convertSlowPeerInfo(slowPeers));\n    }\n    if (slowDisks.haveSlowDisks()) {\n      builder.addAllSlowDisks(PBHelper.convertSlowDiskInfo(slowDisks));\n    }\n\n    // Adding blocks movement results to the heart beat request.\n    if (storageMovementFinishedBlks !\u003d null\n        \u0026\u0026 storageMovementFinishedBlks.getBlocks() !\u003d null) {\n      builder.setStorageMoveAttemptFinishedBlks(\n          PBHelper.convertBlksMovReport(storageMovementFinishedBlks));\n    }\n\n    HeartbeatResponseProto resp;\n    try {\n      resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n    } catch (ServiceException se) {\n      throw ProtobufHelper.getRemoteException(se);\n    }\n    DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n    int index \u003d 0;\n    for (DatanodeCommandProto p : resp.getCmdsList()) {\n      cmds[index] \u003d PBHelper.convert(p);\n      index++;\n    }\n    RollingUpgradeStatus rollingUpdateStatus \u003d null;\n    // Use v2 semantics if available.\n    if (resp.hasRollingUpgradeStatusV2()) {\n      rollingUpdateStatus \u003d PBHelperClient.convert(resp.getRollingUpgradeStatusV2());\n    } else if (resp.hasRollingUpgradeStatus()) {\n      rollingUpdateStatus \u003d PBHelperClient.convert(resp.getRollingUpgradeStatus());\n    }\n    return new HeartbeatResponse(cmds, PBHelper.convert(resp.getHaStatus()),\n        rollingUpdateStatus, resp.getFullBlockReportLeaseId());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolClientSideTranslatorPB.java",
          "extendedDetails": {}
        }
      ]
    },
    "0f2d1ddc2c41c8db800c58cabb150e71804fe23a": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-10954. [SPS]: Provide mechanism to send blocks movement result back to NN from coordinator DN. Contributed by Rakesh R\n",
      "commitDate": "12/08/18 3:05 AM",
      "commitName": "0f2d1ddc2c41c8db800c58cabb150e71804fe23a",
      "commitAuthor": "Rakesh Radhakrishnan",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-10954. [SPS]: Provide mechanism to send blocks movement result back to NN from coordinator DN. Contributed by Rakesh R\n",
          "commitDate": "12/08/18 3:05 AM",
          "commitName": "0f2d1ddc2c41c8db800c58cabb150e71804fe23a",
          "commitAuthor": "Rakesh Radhakrishnan",
          "commitDateOld": "20/03/17 9:54 PM",
          "commitNameOld": "e7c8da614c37e36fb8081234f4c639d6054f6082",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 509.22,
          "commitsBetweenForRepo": 4067,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,51 +1,57 @@\n   public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n       StorageReport[] reports, long cacheCapacity, long cacheUsed,\n       int xmitsInProgress, int xceiverCount, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary,\n       boolean requestFullBlockReportLease,\n       @Nonnull SlowPeerReports slowPeers,\n-      @Nonnull SlowDiskReports slowDisks) throws IOException {\n+      @Nonnull SlowDiskReports slowDisks,\n+      BlocksStorageMovementResult[] blksMovementResults) throws IOException {\n     HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n         .setRegistration(PBHelper.convert(registration))\n         .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n         .setFailedVolumes(failedVolumes)\n         .setRequestFullBlockReportLease(requestFullBlockReportLease);\n     builder.addAllReports(PBHelperClient.convertStorageReports(reports));\n     if (cacheCapacity !\u003d 0) {\n       builder.setCacheCapacity(cacheCapacity);\n     }\n     if (cacheUsed !\u003d 0) {\n       builder.setCacheUsed(cacheUsed);\n     }\n     if (volumeFailureSummary !\u003d null) {\n       builder.setVolumeFailureSummary(PBHelper.convertVolumeFailureSummary(\n           volumeFailureSummary));\n     }\n     if (slowPeers.haveSlowPeers()) {\n       builder.addAllSlowPeers(PBHelper.convertSlowPeerInfo(slowPeers));\n     }\n     if (slowDisks.haveSlowDisks()) {\n       builder.addAllSlowDisks(PBHelper.convertSlowDiskInfo(slowDisks));\n     }\n+\n+    // Adding blocks movement results to the heart beat request.\n+    builder.addAllBlksMovementResults(\n+        PBHelper.convertBlksMovResults(blksMovementResults));\n+\n     HeartbeatResponseProto resp;\n     try {\n       resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n     } catch (ServiceException se) {\n       throw ProtobufHelper.getRemoteException(se);\n     }\n     DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n     int index \u003d 0;\n     for (DatanodeCommandProto p : resp.getCmdsList()) {\n       cmds[index] \u003d PBHelper.convert(p);\n       index++;\n     }\n     RollingUpgradeStatus rollingUpdateStatus \u003d null;\n     // Use v2 semantics if available.\n     if (resp.hasRollingUpgradeStatusV2()) {\n       rollingUpdateStatus \u003d PBHelperClient.convert(resp.getRollingUpgradeStatusV2());\n     } else if (resp.hasRollingUpgradeStatus()) {\n       rollingUpdateStatus \u003d PBHelperClient.convert(resp.getRollingUpgradeStatus());\n     }\n     return new HeartbeatResponse(cmds, PBHelper.convert(resp.getHaStatus()),\n         rollingUpdateStatus, resp.getFullBlockReportLeaseId());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n      StorageReport[] reports, long cacheCapacity, long cacheUsed,\n      int xmitsInProgress, int xceiverCount, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary,\n      boolean requestFullBlockReportLease,\n      @Nonnull SlowPeerReports slowPeers,\n      @Nonnull SlowDiskReports slowDisks,\n      BlocksStorageMovementResult[] blksMovementResults) throws IOException {\n    HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n        .setRegistration(PBHelper.convert(registration))\n        .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n        .setFailedVolumes(failedVolumes)\n        .setRequestFullBlockReportLease(requestFullBlockReportLease);\n    builder.addAllReports(PBHelperClient.convertStorageReports(reports));\n    if (cacheCapacity !\u003d 0) {\n      builder.setCacheCapacity(cacheCapacity);\n    }\n    if (cacheUsed !\u003d 0) {\n      builder.setCacheUsed(cacheUsed);\n    }\n    if (volumeFailureSummary !\u003d null) {\n      builder.setVolumeFailureSummary(PBHelper.convertVolumeFailureSummary(\n          volumeFailureSummary));\n    }\n    if (slowPeers.haveSlowPeers()) {\n      builder.addAllSlowPeers(PBHelper.convertSlowPeerInfo(slowPeers));\n    }\n    if (slowDisks.haveSlowDisks()) {\n      builder.addAllSlowDisks(PBHelper.convertSlowDiskInfo(slowDisks));\n    }\n\n    // Adding blocks movement results to the heart beat request.\n    builder.addAllBlksMovementResults(\n        PBHelper.convertBlksMovResults(blksMovementResults));\n\n    HeartbeatResponseProto resp;\n    try {\n      resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n    } catch (ServiceException se) {\n      throw ProtobufHelper.getRemoteException(se);\n    }\n    DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n    int index \u003d 0;\n    for (DatanodeCommandProto p : resp.getCmdsList()) {\n      cmds[index] \u003d PBHelper.convert(p);\n      index++;\n    }\n    RollingUpgradeStatus rollingUpdateStatus \u003d null;\n    // Use v2 semantics if available.\n    if (resp.hasRollingUpgradeStatusV2()) {\n      rollingUpdateStatus \u003d PBHelperClient.convert(resp.getRollingUpgradeStatusV2());\n    } else if (resp.hasRollingUpgradeStatus()) {\n      rollingUpdateStatus \u003d PBHelperClient.convert(resp.getRollingUpgradeStatus());\n    }\n    return new HeartbeatResponse(cmds, PBHelper.convert(resp.getHaStatus()),\n        rollingUpdateStatus, resp.getFullBlockReportLeaseId());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolClientSideTranslatorPB.java",
          "extendedDetails": {
            "oldValue": "[registration-DatanodeRegistration, reports-StorageReport[], cacheCapacity-long, cacheUsed-long, xmitsInProgress-int, xceiverCount-int, failedVolumes-int, volumeFailureSummary-VolumeFailureSummary, requestFullBlockReportLease-boolean, slowPeers-SlowPeerReports(annotations-@Nonnull), slowDisks-SlowDiskReports(annotations-@Nonnull)]",
            "newValue": "[registration-DatanodeRegistration, reports-StorageReport[], cacheCapacity-long, cacheUsed-long, xmitsInProgress-int, xceiverCount-int, failedVolumes-int, volumeFailureSummary-VolumeFailureSummary, requestFullBlockReportLease-boolean, slowPeers-SlowPeerReports(annotations-@Nonnull), slowDisks-SlowDiskReports(annotations-@Nonnull), blksMovementResults-BlocksStorageMovementResult[]]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-10954. [SPS]: Provide mechanism to send blocks movement result back to NN from coordinator DN. Contributed by Rakesh R\n",
          "commitDate": "12/08/18 3:05 AM",
          "commitName": "0f2d1ddc2c41c8db800c58cabb150e71804fe23a",
          "commitAuthor": "Rakesh Radhakrishnan",
          "commitDateOld": "20/03/17 9:54 PM",
          "commitNameOld": "e7c8da614c37e36fb8081234f4c639d6054f6082",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 509.22,
          "commitsBetweenForRepo": 4067,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,51 +1,57 @@\n   public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n       StorageReport[] reports, long cacheCapacity, long cacheUsed,\n       int xmitsInProgress, int xceiverCount, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary,\n       boolean requestFullBlockReportLease,\n       @Nonnull SlowPeerReports slowPeers,\n-      @Nonnull SlowDiskReports slowDisks) throws IOException {\n+      @Nonnull SlowDiskReports slowDisks,\n+      BlocksStorageMovementResult[] blksMovementResults) throws IOException {\n     HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n         .setRegistration(PBHelper.convert(registration))\n         .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n         .setFailedVolumes(failedVolumes)\n         .setRequestFullBlockReportLease(requestFullBlockReportLease);\n     builder.addAllReports(PBHelperClient.convertStorageReports(reports));\n     if (cacheCapacity !\u003d 0) {\n       builder.setCacheCapacity(cacheCapacity);\n     }\n     if (cacheUsed !\u003d 0) {\n       builder.setCacheUsed(cacheUsed);\n     }\n     if (volumeFailureSummary !\u003d null) {\n       builder.setVolumeFailureSummary(PBHelper.convertVolumeFailureSummary(\n           volumeFailureSummary));\n     }\n     if (slowPeers.haveSlowPeers()) {\n       builder.addAllSlowPeers(PBHelper.convertSlowPeerInfo(slowPeers));\n     }\n     if (slowDisks.haveSlowDisks()) {\n       builder.addAllSlowDisks(PBHelper.convertSlowDiskInfo(slowDisks));\n     }\n+\n+    // Adding blocks movement results to the heart beat request.\n+    builder.addAllBlksMovementResults(\n+        PBHelper.convertBlksMovResults(blksMovementResults));\n+\n     HeartbeatResponseProto resp;\n     try {\n       resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n     } catch (ServiceException se) {\n       throw ProtobufHelper.getRemoteException(se);\n     }\n     DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n     int index \u003d 0;\n     for (DatanodeCommandProto p : resp.getCmdsList()) {\n       cmds[index] \u003d PBHelper.convert(p);\n       index++;\n     }\n     RollingUpgradeStatus rollingUpdateStatus \u003d null;\n     // Use v2 semantics if available.\n     if (resp.hasRollingUpgradeStatusV2()) {\n       rollingUpdateStatus \u003d PBHelperClient.convert(resp.getRollingUpgradeStatusV2());\n     } else if (resp.hasRollingUpgradeStatus()) {\n       rollingUpdateStatus \u003d PBHelperClient.convert(resp.getRollingUpgradeStatus());\n     }\n     return new HeartbeatResponse(cmds, PBHelper.convert(resp.getHaStatus()),\n         rollingUpdateStatus, resp.getFullBlockReportLeaseId());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n      StorageReport[] reports, long cacheCapacity, long cacheUsed,\n      int xmitsInProgress, int xceiverCount, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary,\n      boolean requestFullBlockReportLease,\n      @Nonnull SlowPeerReports slowPeers,\n      @Nonnull SlowDiskReports slowDisks,\n      BlocksStorageMovementResult[] blksMovementResults) throws IOException {\n    HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n        .setRegistration(PBHelper.convert(registration))\n        .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n        .setFailedVolumes(failedVolumes)\n        .setRequestFullBlockReportLease(requestFullBlockReportLease);\n    builder.addAllReports(PBHelperClient.convertStorageReports(reports));\n    if (cacheCapacity !\u003d 0) {\n      builder.setCacheCapacity(cacheCapacity);\n    }\n    if (cacheUsed !\u003d 0) {\n      builder.setCacheUsed(cacheUsed);\n    }\n    if (volumeFailureSummary !\u003d null) {\n      builder.setVolumeFailureSummary(PBHelper.convertVolumeFailureSummary(\n          volumeFailureSummary));\n    }\n    if (slowPeers.haveSlowPeers()) {\n      builder.addAllSlowPeers(PBHelper.convertSlowPeerInfo(slowPeers));\n    }\n    if (slowDisks.haveSlowDisks()) {\n      builder.addAllSlowDisks(PBHelper.convertSlowDiskInfo(slowDisks));\n    }\n\n    // Adding blocks movement results to the heart beat request.\n    builder.addAllBlksMovementResults(\n        PBHelper.convertBlksMovResults(blksMovementResults));\n\n    HeartbeatResponseProto resp;\n    try {\n      resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n    } catch (ServiceException se) {\n      throw ProtobufHelper.getRemoteException(se);\n    }\n    DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n    int index \u003d 0;\n    for (DatanodeCommandProto p : resp.getCmdsList()) {\n      cmds[index] \u003d PBHelper.convert(p);\n      index++;\n    }\n    RollingUpgradeStatus rollingUpdateStatus \u003d null;\n    // Use v2 semantics if available.\n    if (resp.hasRollingUpgradeStatusV2()) {\n      rollingUpdateStatus \u003d PBHelperClient.convert(resp.getRollingUpgradeStatusV2());\n    } else if (resp.hasRollingUpgradeStatus()) {\n      rollingUpdateStatus \u003d PBHelperClient.convert(resp.getRollingUpgradeStatus());\n    }\n    return new HeartbeatResponse(cmds, PBHelper.convert(resp.getHaStatus()),\n        rollingUpdateStatus, resp.getFullBlockReportLeaseId());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolClientSideTranslatorPB.java",
          "extendedDetails": {}
        }
      ]
    },
    "e7c8da614c37e36fb8081234f4c639d6054f6082": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-11545. Propagate DataNode\u0027s slow disks info to the NameNode via Heartbeats. Contributed by Hanisha Koneru.\n",
      "commitDate": "20/03/17 9:54 PM",
      "commitName": "e7c8da614c37e36fb8081234f4c639d6054f6082",
      "commitAuthor": "Arpit Agarwal",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-11545. Propagate DataNode\u0027s slow disks info to the NameNode via Heartbeats. Contributed by Hanisha Koneru.\n",
          "commitDate": "20/03/17 9:54 PM",
          "commitName": "e7c8da614c37e36fb8081234f4c639d6054f6082",
          "commitAuthor": "Arpit Agarwal",
          "commitDateOld": "24/01/17 4:58 PM",
          "commitNameOld": "b57368b6f893cb27d77fc9425e116f1312f4790f",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 55.16,
          "commitsBetweenForRepo": 295,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,47 +1,51 @@\n   public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n       StorageReport[] reports, long cacheCapacity, long cacheUsed,\n       int xmitsInProgress, int xceiverCount, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary,\n       boolean requestFullBlockReportLease,\n-      @Nonnull SlowPeerReports slowPeers) throws IOException {\n+      @Nonnull SlowPeerReports slowPeers,\n+      @Nonnull SlowDiskReports slowDisks) throws IOException {\n     HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n         .setRegistration(PBHelper.convert(registration))\n         .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n         .setFailedVolumes(failedVolumes)\n         .setRequestFullBlockReportLease(requestFullBlockReportLease);\n     builder.addAllReports(PBHelperClient.convertStorageReports(reports));\n     if (cacheCapacity !\u003d 0) {\n       builder.setCacheCapacity(cacheCapacity);\n     }\n     if (cacheUsed !\u003d 0) {\n       builder.setCacheUsed(cacheUsed);\n     }\n     if (volumeFailureSummary !\u003d null) {\n       builder.setVolumeFailureSummary(PBHelper.convertVolumeFailureSummary(\n           volumeFailureSummary));\n     }\n     if (slowPeers.haveSlowPeers()) {\n       builder.addAllSlowPeers(PBHelper.convertSlowPeerInfo(slowPeers));\n     }\n+    if (slowDisks.haveSlowDisks()) {\n+      builder.addAllSlowDisks(PBHelper.convertSlowDiskInfo(slowDisks));\n+    }\n     HeartbeatResponseProto resp;\n     try {\n       resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n     } catch (ServiceException se) {\n       throw ProtobufHelper.getRemoteException(se);\n     }\n     DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n     int index \u003d 0;\n     for (DatanodeCommandProto p : resp.getCmdsList()) {\n       cmds[index] \u003d PBHelper.convert(p);\n       index++;\n     }\n     RollingUpgradeStatus rollingUpdateStatus \u003d null;\n     // Use v2 semantics if available.\n     if (resp.hasRollingUpgradeStatusV2()) {\n       rollingUpdateStatus \u003d PBHelperClient.convert(resp.getRollingUpgradeStatusV2());\n     } else if (resp.hasRollingUpgradeStatus()) {\n       rollingUpdateStatus \u003d PBHelperClient.convert(resp.getRollingUpgradeStatus());\n     }\n     return new HeartbeatResponse(cmds, PBHelper.convert(resp.getHaStatus()),\n         rollingUpdateStatus, resp.getFullBlockReportLeaseId());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n      StorageReport[] reports, long cacheCapacity, long cacheUsed,\n      int xmitsInProgress, int xceiverCount, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary,\n      boolean requestFullBlockReportLease,\n      @Nonnull SlowPeerReports slowPeers,\n      @Nonnull SlowDiskReports slowDisks) throws IOException {\n    HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n        .setRegistration(PBHelper.convert(registration))\n        .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n        .setFailedVolumes(failedVolumes)\n        .setRequestFullBlockReportLease(requestFullBlockReportLease);\n    builder.addAllReports(PBHelperClient.convertStorageReports(reports));\n    if (cacheCapacity !\u003d 0) {\n      builder.setCacheCapacity(cacheCapacity);\n    }\n    if (cacheUsed !\u003d 0) {\n      builder.setCacheUsed(cacheUsed);\n    }\n    if (volumeFailureSummary !\u003d null) {\n      builder.setVolumeFailureSummary(PBHelper.convertVolumeFailureSummary(\n          volumeFailureSummary));\n    }\n    if (slowPeers.haveSlowPeers()) {\n      builder.addAllSlowPeers(PBHelper.convertSlowPeerInfo(slowPeers));\n    }\n    if (slowDisks.haveSlowDisks()) {\n      builder.addAllSlowDisks(PBHelper.convertSlowDiskInfo(slowDisks));\n    }\n    HeartbeatResponseProto resp;\n    try {\n      resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n    } catch (ServiceException se) {\n      throw ProtobufHelper.getRemoteException(se);\n    }\n    DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n    int index \u003d 0;\n    for (DatanodeCommandProto p : resp.getCmdsList()) {\n      cmds[index] \u003d PBHelper.convert(p);\n      index++;\n    }\n    RollingUpgradeStatus rollingUpdateStatus \u003d null;\n    // Use v2 semantics if available.\n    if (resp.hasRollingUpgradeStatusV2()) {\n      rollingUpdateStatus \u003d PBHelperClient.convert(resp.getRollingUpgradeStatusV2());\n    } else if (resp.hasRollingUpgradeStatus()) {\n      rollingUpdateStatus \u003d PBHelperClient.convert(resp.getRollingUpgradeStatus());\n    }\n    return new HeartbeatResponse(cmds, PBHelper.convert(resp.getHaStatus()),\n        rollingUpdateStatus, resp.getFullBlockReportLeaseId());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolClientSideTranslatorPB.java",
          "extendedDetails": {
            "oldValue": "[registration-DatanodeRegistration, reports-StorageReport[], cacheCapacity-long, cacheUsed-long, xmitsInProgress-int, xceiverCount-int, failedVolumes-int, volumeFailureSummary-VolumeFailureSummary, requestFullBlockReportLease-boolean, slowPeers-SlowPeerReports(annotations-@Nonnull)]",
            "newValue": "[registration-DatanodeRegistration, reports-StorageReport[], cacheCapacity-long, cacheUsed-long, xmitsInProgress-int, xceiverCount-int, failedVolumes-int, volumeFailureSummary-VolumeFailureSummary, requestFullBlockReportLease-boolean, slowPeers-SlowPeerReports(annotations-@Nonnull), slowDisks-SlowDiskReports(annotations-@Nonnull)]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-11545. Propagate DataNode\u0027s slow disks info to the NameNode via Heartbeats. Contributed by Hanisha Koneru.\n",
          "commitDate": "20/03/17 9:54 PM",
          "commitName": "e7c8da614c37e36fb8081234f4c639d6054f6082",
          "commitAuthor": "Arpit Agarwal",
          "commitDateOld": "24/01/17 4:58 PM",
          "commitNameOld": "b57368b6f893cb27d77fc9425e116f1312f4790f",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 55.16,
          "commitsBetweenForRepo": 295,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,47 +1,51 @@\n   public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n       StorageReport[] reports, long cacheCapacity, long cacheUsed,\n       int xmitsInProgress, int xceiverCount, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary,\n       boolean requestFullBlockReportLease,\n-      @Nonnull SlowPeerReports slowPeers) throws IOException {\n+      @Nonnull SlowPeerReports slowPeers,\n+      @Nonnull SlowDiskReports slowDisks) throws IOException {\n     HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n         .setRegistration(PBHelper.convert(registration))\n         .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n         .setFailedVolumes(failedVolumes)\n         .setRequestFullBlockReportLease(requestFullBlockReportLease);\n     builder.addAllReports(PBHelperClient.convertStorageReports(reports));\n     if (cacheCapacity !\u003d 0) {\n       builder.setCacheCapacity(cacheCapacity);\n     }\n     if (cacheUsed !\u003d 0) {\n       builder.setCacheUsed(cacheUsed);\n     }\n     if (volumeFailureSummary !\u003d null) {\n       builder.setVolumeFailureSummary(PBHelper.convertVolumeFailureSummary(\n           volumeFailureSummary));\n     }\n     if (slowPeers.haveSlowPeers()) {\n       builder.addAllSlowPeers(PBHelper.convertSlowPeerInfo(slowPeers));\n     }\n+    if (slowDisks.haveSlowDisks()) {\n+      builder.addAllSlowDisks(PBHelper.convertSlowDiskInfo(slowDisks));\n+    }\n     HeartbeatResponseProto resp;\n     try {\n       resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n     } catch (ServiceException se) {\n       throw ProtobufHelper.getRemoteException(se);\n     }\n     DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n     int index \u003d 0;\n     for (DatanodeCommandProto p : resp.getCmdsList()) {\n       cmds[index] \u003d PBHelper.convert(p);\n       index++;\n     }\n     RollingUpgradeStatus rollingUpdateStatus \u003d null;\n     // Use v2 semantics if available.\n     if (resp.hasRollingUpgradeStatusV2()) {\n       rollingUpdateStatus \u003d PBHelperClient.convert(resp.getRollingUpgradeStatusV2());\n     } else if (resp.hasRollingUpgradeStatus()) {\n       rollingUpdateStatus \u003d PBHelperClient.convert(resp.getRollingUpgradeStatus());\n     }\n     return new HeartbeatResponse(cmds, PBHelper.convert(resp.getHaStatus()),\n         rollingUpdateStatus, resp.getFullBlockReportLeaseId());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n      StorageReport[] reports, long cacheCapacity, long cacheUsed,\n      int xmitsInProgress, int xceiverCount, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary,\n      boolean requestFullBlockReportLease,\n      @Nonnull SlowPeerReports slowPeers,\n      @Nonnull SlowDiskReports slowDisks) throws IOException {\n    HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n        .setRegistration(PBHelper.convert(registration))\n        .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n        .setFailedVolumes(failedVolumes)\n        .setRequestFullBlockReportLease(requestFullBlockReportLease);\n    builder.addAllReports(PBHelperClient.convertStorageReports(reports));\n    if (cacheCapacity !\u003d 0) {\n      builder.setCacheCapacity(cacheCapacity);\n    }\n    if (cacheUsed !\u003d 0) {\n      builder.setCacheUsed(cacheUsed);\n    }\n    if (volumeFailureSummary !\u003d null) {\n      builder.setVolumeFailureSummary(PBHelper.convertVolumeFailureSummary(\n          volumeFailureSummary));\n    }\n    if (slowPeers.haveSlowPeers()) {\n      builder.addAllSlowPeers(PBHelper.convertSlowPeerInfo(slowPeers));\n    }\n    if (slowDisks.haveSlowDisks()) {\n      builder.addAllSlowDisks(PBHelper.convertSlowDiskInfo(slowDisks));\n    }\n    HeartbeatResponseProto resp;\n    try {\n      resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n    } catch (ServiceException se) {\n      throw ProtobufHelper.getRemoteException(se);\n    }\n    DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n    int index \u003d 0;\n    for (DatanodeCommandProto p : resp.getCmdsList()) {\n      cmds[index] \u003d PBHelper.convert(p);\n      index++;\n    }\n    RollingUpgradeStatus rollingUpdateStatus \u003d null;\n    // Use v2 semantics if available.\n    if (resp.hasRollingUpgradeStatusV2()) {\n      rollingUpdateStatus \u003d PBHelperClient.convert(resp.getRollingUpgradeStatusV2());\n    } else if (resp.hasRollingUpgradeStatus()) {\n      rollingUpdateStatus \u003d PBHelperClient.convert(resp.getRollingUpgradeStatus());\n    }\n    return new HeartbeatResponse(cmds, PBHelper.convert(resp.getHaStatus()),\n        rollingUpdateStatus, resp.getFullBlockReportLeaseId());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolClientSideTranslatorPB.java",
          "extendedDetails": {}
        }
      ]
    },
    "b57368b6f893cb27d77fc9425e116f1312f4790f": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-11194. Maintain aggregated peer performance metrics on NameNode.\n",
      "commitDate": "24/01/17 4:58 PM",
      "commitName": "b57368b6f893cb27d77fc9425e116f1312f4790f",
      "commitAuthor": "Arpit Agarwal",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-11194. Maintain aggregated peer performance metrics on NameNode.\n",
          "commitDate": "24/01/17 4:58 PM",
          "commitName": "b57368b6f893cb27d77fc9425e116f1312f4790f",
          "commitAuthor": "Arpit Agarwal",
          "commitDateOld": "02/02/16 11:23 AM",
          "commitNameOld": "dd9ebf6eedfd4ff8b3486eae2a446de6b0c7fa8a",
          "commitAuthorOld": "Colin Patrick Mccabe",
          "daysBetweenCommits": 357.23,
          "commitsBetweenForRepo": 2460,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,43 +1,47 @@\n   public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n       StorageReport[] reports, long cacheCapacity, long cacheUsed,\n       int xmitsInProgress, int xceiverCount, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary,\n-      boolean requestFullBlockReportLease) throws IOException {\n+      boolean requestFullBlockReportLease,\n+      @Nonnull SlowPeerReports slowPeers) throws IOException {\n     HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n         .setRegistration(PBHelper.convert(registration))\n         .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n         .setFailedVolumes(failedVolumes)\n         .setRequestFullBlockReportLease(requestFullBlockReportLease);\n     builder.addAllReports(PBHelperClient.convertStorageReports(reports));\n     if (cacheCapacity !\u003d 0) {\n       builder.setCacheCapacity(cacheCapacity);\n     }\n     if (cacheUsed !\u003d 0) {\n       builder.setCacheUsed(cacheUsed);\n     }\n     if (volumeFailureSummary !\u003d null) {\n       builder.setVolumeFailureSummary(PBHelper.convertVolumeFailureSummary(\n           volumeFailureSummary));\n     }\n+    if (slowPeers.haveSlowPeers()) {\n+      builder.addAllSlowPeers(PBHelper.convertSlowPeerInfo(slowPeers));\n+    }\n     HeartbeatResponseProto resp;\n     try {\n       resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n     } catch (ServiceException se) {\n       throw ProtobufHelper.getRemoteException(se);\n     }\n     DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n     int index \u003d 0;\n     for (DatanodeCommandProto p : resp.getCmdsList()) {\n       cmds[index] \u003d PBHelper.convert(p);\n       index++;\n     }\n     RollingUpgradeStatus rollingUpdateStatus \u003d null;\n     // Use v2 semantics if available.\n     if (resp.hasRollingUpgradeStatusV2()) {\n       rollingUpdateStatus \u003d PBHelperClient.convert(resp.getRollingUpgradeStatusV2());\n     } else if (resp.hasRollingUpgradeStatus()) {\n       rollingUpdateStatus \u003d PBHelperClient.convert(resp.getRollingUpgradeStatus());\n     }\n     return new HeartbeatResponse(cmds, PBHelper.convert(resp.getHaStatus()),\n         rollingUpdateStatus, resp.getFullBlockReportLeaseId());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n      StorageReport[] reports, long cacheCapacity, long cacheUsed,\n      int xmitsInProgress, int xceiverCount, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary,\n      boolean requestFullBlockReportLease,\n      @Nonnull SlowPeerReports slowPeers) throws IOException {\n    HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n        .setRegistration(PBHelper.convert(registration))\n        .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n        .setFailedVolumes(failedVolumes)\n        .setRequestFullBlockReportLease(requestFullBlockReportLease);\n    builder.addAllReports(PBHelperClient.convertStorageReports(reports));\n    if (cacheCapacity !\u003d 0) {\n      builder.setCacheCapacity(cacheCapacity);\n    }\n    if (cacheUsed !\u003d 0) {\n      builder.setCacheUsed(cacheUsed);\n    }\n    if (volumeFailureSummary !\u003d null) {\n      builder.setVolumeFailureSummary(PBHelper.convertVolumeFailureSummary(\n          volumeFailureSummary));\n    }\n    if (slowPeers.haveSlowPeers()) {\n      builder.addAllSlowPeers(PBHelper.convertSlowPeerInfo(slowPeers));\n    }\n    HeartbeatResponseProto resp;\n    try {\n      resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n    } catch (ServiceException se) {\n      throw ProtobufHelper.getRemoteException(se);\n    }\n    DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n    int index \u003d 0;\n    for (DatanodeCommandProto p : resp.getCmdsList()) {\n      cmds[index] \u003d PBHelper.convert(p);\n      index++;\n    }\n    RollingUpgradeStatus rollingUpdateStatus \u003d null;\n    // Use v2 semantics if available.\n    if (resp.hasRollingUpgradeStatusV2()) {\n      rollingUpdateStatus \u003d PBHelperClient.convert(resp.getRollingUpgradeStatusV2());\n    } else if (resp.hasRollingUpgradeStatus()) {\n      rollingUpdateStatus \u003d PBHelperClient.convert(resp.getRollingUpgradeStatus());\n    }\n    return new HeartbeatResponse(cmds, PBHelper.convert(resp.getHaStatus()),\n        rollingUpdateStatus, resp.getFullBlockReportLeaseId());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolClientSideTranslatorPB.java",
          "extendedDetails": {
            "oldValue": "[registration-DatanodeRegistration, reports-StorageReport[], cacheCapacity-long, cacheUsed-long, xmitsInProgress-int, xceiverCount-int, failedVolumes-int, volumeFailureSummary-VolumeFailureSummary, requestFullBlockReportLease-boolean]",
            "newValue": "[registration-DatanodeRegistration, reports-StorageReport[], cacheCapacity-long, cacheUsed-long, xmitsInProgress-int, xceiverCount-int, failedVolumes-int, volumeFailureSummary-VolumeFailureSummary, requestFullBlockReportLease-boolean, slowPeers-SlowPeerReports(annotations-@Nonnull)]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-11194. Maintain aggregated peer performance metrics on NameNode.\n",
          "commitDate": "24/01/17 4:58 PM",
          "commitName": "b57368b6f893cb27d77fc9425e116f1312f4790f",
          "commitAuthor": "Arpit Agarwal",
          "commitDateOld": "02/02/16 11:23 AM",
          "commitNameOld": "dd9ebf6eedfd4ff8b3486eae2a446de6b0c7fa8a",
          "commitAuthorOld": "Colin Patrick Mccabe",
          "daysBetweenCommits": 357.23,
          "commitsBetweenForRepo": 2460,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,43 +1,47 @@\n   public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n       StorageReport[] reports, long cacheCapacity, long cacheUsed,\n       int xmitsInProgress, int xceiverCount, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary,\n-      boolean requestFullBlockReportLease) throws IOException {\n+      boolean requestFullBlockReportLease,\n+      @Nonnull SlowPeerReports slowPeers) throws IOException {\n     HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n         .setRegistration(PBHelper.convert(registration))\n         .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n         .setFailedVolumes(failedVolumes)\n         .setRequestFullBlockReportLease(requestFullBlockReportLease);\n     builder.addAllReports(PBHelperClient.convertStorageReports(reports));\n     if (cacheCapacity !\u003d 0) {\n       builder.setCacheCapacity(cacheCapacity);\n     }\n     if (cacheUsed !\u003d 0) {\n       builder.setCacheUsed(cacheUsed);\n     }\n     if (volumeFailureSummary !\u003d null) {\n       builder.setVolumeFailureSummary(PBHelper.convertVolumeFailureSummary(\n           volumeFailureSummary));\n     }\n+    if (slowPeers.haveSlowPeers()) {\n+      builder.addAllSlowPeers(PBHelper.convertSlowPeerInfo(slowPeers));\n+    }\n     HeartbeatResponseProto resp;\n     try {\n       resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n     } catch (ServiceException se) {\n       throw ProtobufHelper.getRemoteException(se);\n     }\n     DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n     int index \u003d 0;\n     for (DatanodeCommandProto p : resp.getCmdsList()) {\n       cmds[index] \u003d PBHelper.convert(p);\n       index++;\n     }\n     RollingUpgradeStatus rollingUpdateStatus \u003d null;\n     // Use v2 semantics if available.\n     if (resp.hasRollingUpgradeStatusV2()) {\n       rollingUpdateStatus \u003d PBHelperClient.convert(resp.getRollingUpgradeStatusV2());\n     } else if (resp.hasRollingUpgradeStatus()) {\n       rollingUpdateStatus \u003d PBHelperClient.convert(resp.getRollingUpgradeStatus());\n     }\n     return new HeartbeatResponse(cmds, PBHelper.convert(resp.getHaStatus()),\n         rollingUpdateStatus, resp.getFullBlockReportLeaseId());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n      StorageReport[] reports, long cacheCapacity, long cacheUsed,\n      int xmitsInProgress, int xceiverCount, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary,\n      boolean requestFullBlockReportLease,\n      @Nonnull SlowPeerReports slowPeers) throws IOException {\n    HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n        .setRegistration(PBHelper.convert(registration))\n        .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n        .setFailedVolumes(failedVolumes)\n        .setRequestFullBlockReportLease(requestFullBlockReportLease);\n    builder.addAllReports(PBHelperClient.convertStorageReports(reports));\n    if (cacheCapacity !\u003d 0) {\n      builder.setCacheCapacity(cacheCapacity);\n    }\n    if (cacheUsed !\u003d 0) {\n      builder.setCacheUsed(cacheUsed);\n    }\n    if (volumeFailureSummary !\u003d null) {\n      builder.setVolumeFailureSummary(PBHelper.convertVolumeFailureSummary(\n          volumeFailureSummary));\n    }\n    if (slowPeers.haveSlowPeers()) {\n      builder.addAllSlowPeers(PBHelper.convertSlowPeerInfo(slowPeers));\n    }\n    HeartbeatResponseProto resp;\n    try {\n      resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n    } catch (ServiceException se) {\n      throw ProtobufHelper.getRemoteException(se);\n    }\n    DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n    int index \u003d 0;\n    for (DatanodeCommandProto p : resp.getCmdsList()) {\n      cmds[index] \u003d PBHelper.convert(p);\n      index++;\n    }\n    RollingUpgradeStatus rollingUpdateStatus \u003d null;\n    // Use v2 semantics if available.\n    if (resp.hasRollingUpgradeStatusV2()) {\n      rollingUpdateStatus \u003d PBHelperClient.convert(resp.getRollingUpgradeStatusV2());\n    } else if (resp.hasRollingUpgradeStatus()) {\n      rollingUpdateStatus \u003d PBHelperClient.convert(resp.getRollingUpgradeStatus());\n    }\n    return new HeartbeatResponse(cmds, PBHelper.convert(resp.getHaStatus()),\n        rollingUpdateStatus, resp.getFullBlockReportLeaseId());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolClientSideTranslatorPB.java",
          "extendedDetails": {}
        }
      ]
    },
    "9f256d1d716a7e17606245fcfc619901a8fa299a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9426. Rollingupgrade finalization is not backward compatible (Contributed by Kihwal Lee)\n\n(cherry picked from commit c62d42cd8bb09a5ffc0c5eefa2d87913e71b9e7e)\n\nConflicts:\n\thadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolClientSideTranslatorPB.java\n\thadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolServerSideTranslatorPB.java\n\thadoop-hdfs-project/hadoop-hdfs/src/main/proto/DatanodeProtocol.proto\n",
      "commitDate": "25/11/15 8:09 PM",
      "commitName": "9f256d1d716a7e17606245fcfc619901a8fa299a",
      "commitAuthor": "Vinayakumar B",
      "commitDateOld": "29/09/15 1:39 AM",
      "commitNameOld": "8fd55202468b28422b0df888641c9b08906fe4a7",
      "commitAuthorOld": "",
      "daysBetweenCommits": 57.81,
      "commitsBetweenForRepo": 473,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,40 +1,43 @@\n   public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n       StorageReport[] reports, long cacheCapacity, long cacheUsed,\n       int xmitsInProgress, int xceiverCount, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary,\n       boolean requestFullBlockReportLease) throws IOException {\n     HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n         .setRegistration(PBHelper.convert(registration))\n         .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n         .setFailedVolumes(failedVolumes)\n         .setRequestFullBlockReportLease(requestFullBlockReportLease);\n     builder.addAllReports(PBHelperClient.convertStorageReports(reports));\n     if (cacheCapacity !\u003d 0) {\n       builder.setCacheCapacity(cacheCapacity);\n     }\n     if (cacheUsed !\u003d 0) {\n       builder.setCacheUsed(cacheUsed);\n     }\n     if (volumeFailureSummary !\u003d null) {\n       builder.setVolumeFailureSummary(PBHelper.convertVolumeFailureSummary(\n           volumeFailureSummary));\n     }\n     HeartbeatResponseProto resp;\n     try {\n       resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n     } catch (ServiceException se) {\n       throw ProtobufHelper.getRemoteException(se);\n     }\n     DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n     int index \u003d 0;\n     for (DatanodeCommandProto p : resp.getCmdsList()) {\n       cmds[index] \u003d PBHelper.convert(p);\n       index++;\n     }\n     RollingUpgradeStatus rollingUpdateStatus \u003d null;\n-    if (resp.hasRollingUpgradeStatus()) {\n+    // Use v2 semantics if available.\n+    if (resp.hasRollingUpgradeStatusV2()) {\n+      rollingUpdateStatus \u003d PBHelperClient.convert(resp.getRollingUpgradeStatusV2());\n+    } else if (resp.hasRollingUpgradeStatus()) {\n       rollingUpdateStatus \u003d PBHelperClient.convert(resp.getRollingUpgradeStatus());\n     }\n     return new HeartbeatResponse(cmds, PBHelper.convert(resp.getHaStatus()),\n         rollingUpdateStatus, resp.getFullBlockReportLeaseId());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n      StorageReport[] reports, long cacheCapacity, long cacheUsed,\n      int xmitsInProgress, int xceiverCount, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary,\n      boolean requestFullBlockReportLease) throws IOException {\n    HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n        .setRegistration(PBHelper.convert(registration))\n        .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n        .setFailedVolumes(failedVolumes)\n        .setRequestFullBlockReportLease(requestFullBlockReportLease);\n    builder.addAllReports(PBHelperClient.convertStorageReports(reports));\n    if (cacheCapacity !\u003d 0) {\n      builder.setCacheCapacity(cacheCapacity);\n    }\n    if (cacheUsed !\u003d 0) {\n      builder.setCacheUsed(cacheUsed);\n    }\n    if (volumeFailureSummary !\u003d null) {\n      builder.setVolumeFailureSummary(PBHelper.convertVolumeFailureSummary(\n          volumeFailureSummary));\n    }\n    HeartbeatResponseProto resp;\n    try {\n      resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n    } catch (ServiceException se) {\n      throw ProtobufHelper.getRemoteException(se);\n    }\n    DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n    int index \u003d 0;\n    for (DatanodeCommandProto p : resp.getCmdsList()) {\n      cmds[index] \u003d PBHelper.convert(p);\n      index++;\n    }\n    RollingUpgradeStatus rollingUpdateStatus \u003d null;\n    // Use v2 semantics if available.\n    if (resp.hasRollingUpgradeStatusV2()) {\n      rollingUpdateStatus \u003d PBHelperClient.convert(resp.getRollingUpgradeStatusV2());\n    } else if (resp.hasRollingUpgradeStatus()) {\n      rollingUpdateStatus \u003d PBHelperClient.convert(resp.getRollingUpgradeStatus());\n    }\n    return new HeartbeatResponse(cmds, PBHelper.convert(resp.getHaStatus()),\n        rollingUpdateStatus, resp.getFullBlockReportLeaseId());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolClientSideTranslatorPB.java",
      "extendedDetails": {}
    },
    "06022b8fdc40e50eaac63758246353058e8cfa6d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9111. Move hdfs-client protobuf convert methods from PBHelper to PBHelperClient. Contributed by Mingliang Liu.\n",
      "commitDate": "21/09/15 6:53 PM",
      "commitName": "06022b8fdc40e50eaac63758246353058e8cfa6d",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "22/08/15 1:31 PM",
      "commitNameOld": "490bb5ebd6c6d6f9c08fcad167f976687fc3aa42",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 30.22,
      "commitsBetweenForRepo": 176,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,40 +1,40 @@\n   public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n       StorageReport[] reports, long cacheCapacity, long cacheUsed,\n       int xmitsInProgress, int xceiverCount, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary,\n       boolean requestFullBlockReportLease) throws IOException {\n     HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n         .setRegistration(PBHelper.convert(registration))\n         .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n         .setFailedVolumes(failedVolumes)\n         .setRequestFullBlockReportLease(requestFullBlockReportLease);\n-    builder.addAllReports(PBHelper.convertStorageReports(reports));\n+    builder.addAllReports(PBHelperClient.convertStorageReports(reports));\n     if (cacheCapacity !\u003d 0) {\n       builder.setCacheCapacity(cacheCapacity);\n     }\n     if (cacheUsed !\u003d 0) {\n       builder.setCacheUsed(cacheUsed);\n     }\n     if (volumeFailureSummary !\u003d null) {\n       builder.setVolumeFailureSummary(PBHelper.convertVolumeFailureSummary(\n           volumeFailureSummary));\n     }\n     HeartbeatResponseProto resp;\n     try {\n       resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n     } catch (ServiceException se) {\n       throw ProtobufHelper.getRemoteException(se);\n     }\n     DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n     int index \u003d 0;\n     for (DatanodeCommandProto p : resp.getCmdsList()) {\n       cmds[index] \u003d PBHelper.convert(p);\n       index++;\n     }\n     RollingUpgradeStatus rollingUpdateStatus \u003d null;\n     if (resp.hasRollingUpgradeStatus()) {\n-      rollingUpdateStatus \u003d PBHelper.convert(resp.getRollingUpgradeStatus());\n+      rollingUpdateStatus \u003d PBHelperClient.convert(resp.getRollingUpgradeStatus());\n     }\n     return new HeartbeatResponse(cmds, PBHelper.convert(resp.getHaStatus()),\n         rollingUpdateStatus, resp.getFullBlockReportLeaseId());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n      StorageReport[] reports, long cacheCapacity, long cacheUsed,\n      int xmitsInProgress, int xceiverCount, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary,\n      boolean requestFullBlockReportLease) throws IOException {\n    HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n        .setRegistration(PBHelper.convert(registration))\n        .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n        .setFailedVolumes(failedVolumes)\n        .setRequestFullBlockReportLease(requestFullBlockReportLease);\n    builder.addAllReports(PBHelperClient.convertStorageReports(reports));\n    if (cacheCapacity !\u003d 0) {\n      builder.setCacheCapacity(cacheCapacity);\n    }\n    if (cacheUsed !\u003d 0) {\n      builder.setCacheUsed(cacheUsed);\n    }\n    if (volumeFailureSummary !\u003d null) {\n      builder.setVolumeFailureSummary(PBHelper.convertVolumeFailureSummary(\n          volumeFailureSummary));\n    }\n    HeartbeatResponseProto resp;\n    try {\n      resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n    } catch (ServiceException se) {\n      throw ProtobufHelper.getRemoteException(se);\n    }\n    DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n    int index \u003d 0;\n    for (DatanodeCommandProto p : resp.getCmdsList()) {\n      cmds[index] \u003d PBHelper.convert(p);\n      index++;\n    }\n    RollingUpgradeStatus rollingUpdateStatus \u003d null;\n    if (resp.hasRollingUpgradeStatus()) {\n      rollingUpdateStatus \u003d PBHelperClient.convert(resp.getRollingUpgradeStatus());\n    }\n    return new HeartbeatResponse(cmds, PBHelper.convert(resp.getHaStatus()),\n        rollingUpdateStatus, resp.getFullBlockReportLeaseId());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolClientSideTranslatorPB.java",
      "extendedDetails": {}
    },
    "12b5b06c063d93e6c683c9b6fac9a96912f59e59": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-7923. The DataNodes should rate-limit their full block reports by asking the NN on heartbeat messages (cmccabe)\n",
      "commitDate": "12/06/15 11:17 AM",
      "commitName": "12b5b06c063d93e6c683c9b6fac9a96912f59e59",
      "commitAuthor": "Colin Patrick Mccabe",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-7923. The DataNodes should rate-limit their full block reports by asking the NN on heartbeat messages (cmccabe)\n",
          "commitDate": "12/06/15 11:17 AM",
          "commitName": "12b5b06c063d93e6c683c9b6fac9a96912f59e59",
          "commitAuthor": "Colin Patrick Mccabe",
          "commitDateOld": "23/03/15 10:00 PM",
          "commitNameOld": "50ee8f4e67a66aa77c5359182f61f3e951844db6",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 80.55,
          "commitsBetweenForRepo": 743,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,38 +1,40 @@\n   public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n       StorageReport[] reports, long cacheCapacity, long cacheUsed,\n       int xmitsInProgress, int xceiverCount, int failedVolumes,\n-      VolumeFailureSummary volumeFailureSummary) throws IOException {\n+      VolumeFailureSummary volumeFailureSummary,\n+      boolean requestFullBlockReportLease) throws IOException {\n     HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n         .setRegistration(PBHelper.convert(registration))\n         .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n-        .setFailedVolumes(failedVolumes);\n+        .setFailedVolumes(failedVolumes)\n+        .setRequestFullBlockReportLease(requestFullBlockReportLease);\n     builder.addAllReports(PBHelper.convertStorageReports(reports));\n     if (cacheCapacity !\u003d 0) {\n       builder.setCacheCapacity(cacheCapacity);\n     }\n     if (cacheUsed !\u003d 0) {\n       builder.setCacheUsed(cacheUsed);\n     }\n     if (volumeFailureSummary !\u003d null) {\n       builder.setVolumeFailureSummary(PBHelper.convertVolumeFailureSummary(\n           volumeFailureSummary));\n     }\n     HeartbeatResponseProto resp;\n     try {\n       resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n     } catch (ServiceException se) {\n       throw ProtobufHelper.getRemoteException(se);\n     }\n     DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n     int index \u003d 0;\n     for (DatanodeCommandProto p : resp.getCmdsList()) {\n       cmds[index] \u003d PBHelper.convert(p);\n       index++;\n     }\n     RollingUpgradeStatus rollingUpdateStatus \u003d null;\n     if (resp.hasRollingUpgradeStatus()) {\n       rollingUpdateStatus \u003d PBHelper.convert(resp.getRollingUpgradeStatus());\n     }\n     return new HeartbeatResponse(cmds, PBHelper.convert(resp.getHaStatus()),\n-        rollingUpdateStatus);\n+        rollingUpdateStatus, resp.getFullBlockReportLeaseId());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n      StorageReport[] reports, long cacheCapacity, long cacheUsed,\n      int xmitsInProgress, int xceiverCount, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary,\n      boolean requestFullBlockReportLease) throws IOException {\n    HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n        .setRegistration(PBHelper.convert(registration))\n        .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n        .setFailedVolumes(failedVolumes)\n        .setRequestFullBlockReportLease(requestFullBlockReportLease);\n    builder.addAllReports(PBHelper.convertStorageReports(reports));\n    if (cacheCapacity !\u003d 0) {\n      builder.setCacheCapacity(cacheCapacity);\n    }\n    if (cacheUsed !\u003d 0) {\n      builder.setCacheUsed(cacheUsed);\n    }\n    if (volumeFailureSummary !\u003d null) {\n      builder.setVolumeFailureSummary(PBHelper.convertVolumeFailureSummary(\n          volumeFailureSummary));\n    }\n    HeartbeatResponseProto resp;\n    try {\n      resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n    } catch (ServiceException se) {\n      throw ProtobufHelper.getRemoteException(se);\n    }\n    DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n    int index \u003d 0;\n    for (DatanodeCommandProto p : resp.getCmdsList()) {\n      cmds[index] \u003d PBHelper.convert(p);\n      index++;\n    }\n    RollingUpgradeStatus rollingUpdateStatus \u003d null;\n    if (resp.hasRollingUpgradeStatus()) {\n      rollingUpdateStatus \u003d PBHelper.convert(resp.getRollingUpgradeStatus());\n    }\n    return new HeartbeatResponse(cmds, PBHelper.convert(resp.getHaStatus()),\n        rollingUpdateStatus, resp.getFullBlockReportLeaseId());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolClientSideTranslatorPB.java",
          "extendedDetails": {
            "oldValue": "[registration-DatanodeRegistration, reports-StorageReport[], cacheCapacity-long, cacheUsed-long, xmitsInProgress-int, xceiverCount-int, failedVolumes-int, volumeFailureSummary-VolumeFailureSummary]",
            "newValue": "[registration-DatanodeRegistration, reports-StorageReport[], cacheCapacity-long, cacheUsed-long, xmitsInProgress-int, xceiverCount-int, failedVolumes-int, volumeFailureSummary-VolumeFailureSummary, requestFullBlockReportLease-boolean]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7923. The DataNodes should rate-limit their full block reports by asking the NN on heartbeat messages (cmccabe)\n",
          "commitDate": "12/06/15 11:17 AM",
          "commitName": "12b5b06c063d93e6c683c9b6fac9a96912f59e59",
          "commitAuthor": "Colin Patrick Mccabe",
          "commitDateOld": "23/03/15 10:00 PM",
          "commitNameOld": "50ee8f4e67a66aa77c5359182f61f3e951844db6",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 80.55,
          "commitsBetweenForRepo": 743,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,38 +1,40 @@\n   public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n       StorageReport[] reports, long cacheCapacity, long cacheUsed,\n       int xmitsInProgress, int xceiverCount, int failedVolumes,\n-      VolumeFailureSummary volumeFailureSummary) throws IOException {\n+      VolumeFailureSummary volumeFailureSummary,\n+      boolean requestFullBlockReportLease) throws IOException {\n     HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n         .setRegistration(PBHelper.convert(registration))\n         .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n-        .setFailedVolumes(failedVolumes);\n+        .setFailedVolumes(failedVolumes)\n+        .setRequestFullBlockReportLease(requestFullBlockReportLease);\n     builder.addAllReports(PBHelper.convertStorageReports(reports));\n     if (cacheCapacity !\u003d 0) {\n       builder.setCacheCapacity(cacheCapacity);\n     }\n     if (cacheUsed !\u003d 0) {\n       builder.setCacheUsed(cacheUsed);\n     }\n     if (volumeFailureSummary !\u003d null) {\n       builder.setVolumeFailureSummary(PBHelper.convertVolumeFailureSummary(\n           volumeFailureSummary));\n     }\n     HeartbeatResponseProto resp;\n     try {\n       resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n     } catch (ServiceException se) {\n       throw ProtobufHelper.getRemoteException(se);\n     }\n     DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n     int index \u003d 0;\n     for (DatanodeCommandProto p : resp.getCmdsList()) {\n       cmds[index] \u003d PBHelper.convert(p);\n       index++;\n     }\n     RollingUpgradeStatus rollingUpdateStatus \u003d null;\n     if (resp.hasRollingUpgradeStatus()) {\n       rollingUpdateStatus \u003d PBHelper.convert(resp.getRollingUpgradeStatus());\n     }\n     return new HeartbeatResponse(cmds, PBHelper.convert(resp.getHaStatus()),\n-        rollingUpdateStatus);\n+        rollingUpdateStatus, resp.getFullBlockReportLeaseId());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n      StorageReport[] reports, long cacheCapacity, long cacheUsed,\n      int xmitsInProgress, int xceiverCount, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary,\n      boolean requestFullBlockReportLease) throws IOException {\n    HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n        .setRegistration(PBHelper.convert(registration))\n        .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n        .setFailedVolumes(failedVolumes)\n        .setRequestFullBlockReportLease(requestFullBlockReportLease);\n    builder.addAllReports(PBHelper.convertStorageReports(reports));\n    if (cacheCapacity !\u003d 0) {\n      builder.setCacheCapacity(cacheCapacity);\n    }\n    if (cacheUsed !\u003d 0) {\n      builder.setCacheUsed(cacheUsed);\n    }\n    if (volumeFailureSummary !\u003d null) {\n      builder.setVolumeFailureSummary(PBHelper.convertVolumeFailureSummary(\n          volumeFailureSummary));\n    }\n    HeartbeatResponseProto resp;\n    try {\n      resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n    } catch (ServiceException se) {\n      throw ProtobufHelper.getRemoteException(se);\n    }\n    DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n    int index \u003d 0;\n    for (DatanodeCommandProto p : resp.getCmdsList()) {\n      cmds[index] \u003d PBHelper.convert(p);\n      index++;\n    }\n    RollingUpgradeStatus rollingUpdateStatus \u003d null;\n    if (resp.hasRollingUpgradeStatus()) {\n      rollingUpdateStatus \u003d PBHelper.convert(resp.getRollingUpgradeStatus());\n    }\n    return new HeartbeatResponse(cmds, PBHelper.convert(resp.getHaStatus()),\n        rollingUpdateStatus, resp.getFullBlockReportLeaseId());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolClientSideTranslatorPB.java",
          "extendedDetails": {}
        }
      ]
    },
    "9729b244de50322c2cc889c97c2ffb2b4675cf77": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-7604. Track and display failed DataNode storage locations in NameNode. Contributed by Chris Nauroth.\n",
      "commitDate": "16/02/15 2:43 PM",
      "commitName": "9729b244de50322c2cc889c97c2ffb2b4675cf77",
      "commitAuthor": "cnauroth",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-7604. Track and display failed DataNode storage locations in NameNode. Contributed by Chris Nauroth.\n",
          "commitDate": "16/02/15 2:43 PM",
          "commitName": "9729b244de50322c2cc889c97c2ffb2b4675cf77",
          "commitAuthor": "cnauroth",
          "commitDateOld": "28/07/14 4:43 PM",
          "commitNameOld": "4f9ffc7455ae2182df1da1b7e3f5a55e645fc8a4",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 202.96,
          "commitsBetweenForRepo": 1752,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,34 +1,38 @@\n   public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n       StorageReport[] reports, long cacheCapacity, long cacheUsed,\n-          int xmitsInProgress, int xceiverCount, int failedVolumes)\n-              throws IOException {\n+      int xmitsInProgress, int xceiverCount, int failedVolumes,\n+      VolumeFailureSummary volumeFailureSummary) throws IOException {\n     HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n         .setRegistration(PBHelper.convert(registration))\n         .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n         .setFailedVolumes(failedVolumes);\n     builder.addAllReports(PBHelper.convertStorageReports(reports));\n     if (cacheCapacity !\u003d 0) {\n       builder.setCacheCapacity(cacheCapacity);\n     }\n     if (cacheUsed !\u003d 0) {\n       builder.setCacheUsed(cacheUsed);\n     }\n+    if (volumeFailureSummary !\u003d null) {\n+      builder.setVolumeFailureSummary(PBHelper.convertVolumeFailureSummary(\n+          volumeFailureSummary));\n+    }\n     HeartbeatResponseProto resp;\n     try {\n       resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n     } catch (ServiceException se) {\n       throw ProtobufHelper.getRemoteException(se);\n     }\n     DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n     int index \u003d 0;\n     for (DatanodeCommandProto p : resp.getCmdsList()) {\n       cmds[index] \u003d PBHelper.convert(p);\n       index++;\n     }\n     RollingUpgradeStatus rollingUpdateStatus \u003d null;\n     if (resp.hasRollingUpgradeStatus()) {\n       rollingUpdateStatus \u003d PBHelper.convert(resp.getRollingUpgradeStatus());\n     }\n     return new HeartbeatResponse(cmds, PBHelper.convert(resp.getHaStatus()),\n         rollingUpdateStatus);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n      StorageReport[] reports, long cacheCapacity, long cacheUsed,\n      int xmitsInProgress, int xceiverCount, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary) throws IOException {\n    HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n        .setRegistration(PBHelper.convert(registration))\n        .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n        .setFailedVolumes(failedVolumes);\n    builder.addAllReports(PBHelper.convertStorageReports(reports));\n    if (cacheCapacity !\u003d 0) {\n      builder.setCacheCapacity(cacheCapacity);\n    }\n    if (cacheUsed !\u003d 0) {\n      builder.setCacheUsed(cacheUsed);\n    }\n    if (volumeFailureSummary !\u003d null) {\n      builder.setVolumeFailureSummary(PBHelper.convertVolumeFailureSummary(\n          volumeFailureSummary));\n    }\n    HeartbeatResponseProto resp;\n    try {\n      resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n    } catch (ServiceException se) {\n      throw ProtobufHelper.getRemoteException(se);\n    }\n    DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n    int index \u003d 0;\n    for (DatanodeCommandProto p : resp.getCmdsList()) {\n      cmds[index] \u003d PBHelper.convert(p);\n      index++;\n    }\n    RollingUpgradeStatus rollingUpdateStatus \u003d null;\n    if (resp.hasRollingUpgradeStatus()) {\n      rollingUpdateStatus \u003d PBHelper.convert(resp.getRollingUpgradeStatus());\n    }\n    return new HeartbeatResponse(cmds, PBHelper.convert(resp.getHaStatus()),\n        rollingUpdateStatus);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolClientSideTranslatorPB.java",
          "extendedDetails": {
            "oldValue": "[registration-DatanodeRegistration, reports-StorageReport[], cacheCapacity-long, cacheUsed-long, xmitsInProgress-int, xceiverCount-int, failedVolumes-int]",
            "newValue": "[registration-DatanodeRegistration, reports-StorageReport[], cacheCapacity-long, cacheUsed-long, xmitsInProgress-int, xceiverCount-int, failedVolumes-int, volumeFailureSummary-VolumeFailureSummary]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7604. Track and display failed DataNode storage locations in NameNode. Contributed by Chris Nauroth.\n",
          "commitDate": "16/02/15 2:43 PM",
          "commitName": "9729b244de50322c2cc889c97c2ffb2b4675cf77",
          "commitAuthor": "cnauroth",
          "commitDateOld": "28/07/14 4:43 PM",
          "commitNameOld": "4f9ffc7455ae2182df1da1b7e3f5a55e645fc8a4",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 202.96,
          "commitsBetweenForRepo": 1752,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,34 +1,38 @@\n   public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n       StorageReport[] reports, long cacheCapacity, long cacheUsed,\n-          int xmitsInProgress, int xceiverCount, int failedVolumes)\n-              throws IOException {\n+      int xmitsInProgress, int xceiverCount, int failedVolumes,\n+      VolumeFailureSummary volumeFailureSummary) throws IOException {\n     HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n         .setRegistration(PBHelper.convert(registration))\n         .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n         .setFailedVolumes(failedVolumes);\n     builder.addAllReports(PBHelper.convertStorageReports(reports));\n     if (cacheCapacity !\u003d 0) {\n       builder.setCacheCapacity(cacheCapacity);\n     }\n     if (cacheUsed !\u003d 0) {\n       builder.setCacheUsed(cacheUsed);\n     }\n+    if (volumeFailureSummary !\u003d null) {\n+      builder.setVolumeFailureSummary(PBHelper.convertVolumeFailureSummary(\n+          volumeFailureSummary));\n+    }\n     HeartbeatResponseProto resp;\n     try {\n       resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n     } catch (ServiceException se) {\n       throw ProtobufHelper.getRemoteException(se);\n     }\n     DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n     int index \u003d 0;\n     for (DatanodeCommandProto p : resp.getCmdsList()) {\n       cmds[index] \u003d PBHelper.convert(p);\n       index++;\n     }\n     RollingUpgradeStatus rollingUpdateStatus \u003d null;\n     if (resp.hasRollingUpgradeStatus()) {\n       rollingUpdateStatus \u003d PBHelper.convert(resp.getRollingUpgradeStatus());\n     }\n     return new HeartbeatResponse(cmds, PBHelper.convert(resp.getHaStatus()),\n         rollingUpdateStatus);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n      StorageReport[] reports, long cacheCapacity, long cacheUsed,\n      int xmitsInProgress, int xceiverCount, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary) throws IOException {\n    HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n        .setRegistration(PBHelper.convert(registration))\n        .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n        .setFailedVolumes(failedVolumes);\n    builder.addAllReports(PBHelper.convertStorageReports(reports));\n    if (cacheCapacity !\u003d 0) {\n      builder.setCacheCapacity(cacheCapacity);\n    }\n    if (cacheUsed !\u003d 0) {\n      builder.setCacheUsed(cacheUsed);\n    }\n    if (volumeFailureSummary !\u003d null) {\n      builder.setVolumeFailureSummary(PBHelper.convertVolumeFailureSummary(\n          volumeFailureSummary));\n    }\n    HeartbeatResponseProto resp;\n    try {\n      resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n    } catch (ServiceException se) {\n      throw ProtobufHelper.getRemoteException(se);\n    }\n    DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n    int index \u003d 0;\n    for (DatanodeCommandProto p : resp.getCmdsList()) {\n      cmds[index] \u003d PBHelper.convert(p);\n      index++;\n    }\n    RollingUpgradeStatus rollingUpdateStatus \u003d null;\n    if (resp.hasRollingUpgradeStatus()) {\n      rollingUpdateStatus \u003d PBHelper.convert(resp.getRollingUpgradeStatus());\n    }\n    return new HeartbeatResponse(cmds, PBHelper.convert(resp.getHaStatus()),\n        rollingUpdateStatus);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolClientSideTranslatorPB.java",
          "extendedDetails": {}
        }
      ]
    },
    "4f9ffc7455ae2182df1da1b7e3f5a55e645fc8a4": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6739. Add getDatanodeStorageReport to ClientProtocol.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1614215 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/07/14 4:43 PM",
      "commitName": "4f9ffc7455ae2182df1da1b7e3f5a55e645fc8a4",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "17/07/14 10:37 AM",
      "commitNameOld": "f4151bbf4f54dc33836c76e6860aa043a9626e48",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 11.25,
      "commitsBetweenForRepo": 89,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,36 +1,34 @@\n   public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n       StorageReport[] reports, long cacheCapacity, long cacheUsed,\n           int xmitsInProgress, int xceiverCount, int failedVolumes)\n               throws IOException {\n     HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n         .setRegistration(PBHelper.convert(registration))\n         .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n         .setFailedVolumes(failedVolumes);\n-    for (StorageReport r : reports) {\n-      builder.addReports(PBHelper.convert(r));\n-    }\n+    builder.addAllReports(PBHelper.convertStorageReports(reports));\n     if (cacheCapacity !\u003d 0) {\n       builder.setCacheCapacity(cacheCapacity);\n     }\n     if (cacheUsed !\u003d 0) {\n       builder.setCacheUsed(cacheUsed);\n     }\n     HeartbeatResponseProto resp;\n     try {\n       resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n     } catch (ServiceException se) {\n       throw ProtobufHelper.getRemoteException(se);\n     }\n     DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n     int index \u003d 0;\n     for (DatanodeCommandProto p : resp.getCmdsList()) {\n       cmds[index] \u003d PBHelper.convert(p);\n       index++;\n     }\n     RollingUpgradeStatus rollingUpdateStatus \u003d null;\n     if (resp.hasRollingUpgradeStatus()) {\n       rollingUpdateStatus \u003d PBHelper.convert(resp.getRollingUpgradeStatus());\n     }\n     return new HeartbeatResponse(cmds, PBHelper.convert(resp.getHaStatus()),\n         rollingUpdateStatus);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n      StorageReport[] reports, long cacheCapacity, long cacheUsed,\n          int xmitsInProgress, int xceiverCount, int failedVolumes)\n              throws IOException {\n    HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n        .setRegistration(PBHelper.convert(registration))\n        .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n        .setFailedVolumes(failedVolumes);\n    builder.addAllReports(PBHelper.convertStorageReports(reports));\n    if (cacheCapacity !\u003d 0) {\n      builder.setCacheCapacity(cacheCapacity);\n    }\n    if (cacheUsed !\u003d 0) {\n      builder.setCacheUsed(cacheUsed);\n    }\n    HeartbeatResponseProto resp;\n    try {\n      resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n    } catch (ServiceException se) {\n      throw ProtobufHelper.getRemoteException(se);\n    }\n    DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n    int index \u003d 0;\n    for (DatanodeCommandProto p : resp.getCmdsList()) {\n      cmds[index] \u003d PBHelper.convert(p);\n      index++;\n    }\n    RollingUpgradeStatus rollingUpdateStatus \u003d null;\n    if (resp.hasRollingUpgradeStatus()) {\n      rollingUpdateStatus \u003d PBHelper.convert(resp.getRollingUpgradeStatus());\n    }\n    return new HeartbeatResponse(cmds, PBHelper.convert(resp.getHaStatus()),\n        rollingUpdateStatus);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolClientSideTranslatorPB.java",
      "extendedDetails": {}
    },
    "b2ce764093ba3007df67022b3bcbc43d3fe2b173": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5890. Avoid NPE in Datanode heartbeat. Contributed by Vinay\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535@1565023 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "05/02/14 4:40 PM",
      "commitName": "b2ce764093ba3007df67022b3bcbc43d3fe2b173",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "01/02/14 12:58 AM",
      "commitNameOld": "4f92eb2f613e4de59c2d31a563e16aba4846c61a",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 4.65,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,33 +1,36 @@\n   public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n       StorageReport[] reports, long cacheCapacity, long cacheUsed,\n           int xmitsInProgress, int xceiverCount, int failedVolumes)\n               throws IOException {\n     HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n         .setRegistration(PBHelper.convert(registration))\n         .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n         .setFailedVolumes(failedVolumes);\n     for (StorageReport r : reports) {\n       builder.addReports(PBHelper.convert(r));\n     }\n     if (cacheCapacity !\u003d 0) {\n       builder.setCacheCapacity(cacheCapacity);\n     }\n     if (cacheUsed !\u003d 0) {\n       builder.setCacheUsed(cacheUsed);\n     }\n     HeartbeatResponseProto resp;\n     try {\n       resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n     } catch (ServiceException se) {\n       throw ProtobufHelper.getRemoteException(se);\n     }\n     DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n     int index \u003d 0;\n     for (DatanodeCommandProto p : resp.getCmdsList()) {\n       cmds[index] \u003d PBHelper.convert(p);\n       index++;\n     }\n-    return new HeartbeatResponse(cmds,\n-        PBHelper.convert(resp.getHaStatus()),\n-        PBHelper.convert(resp.getRollingUpgradeStatus()));\n+    RollingUpgradeStatus rollingUpdateStatus \u003d null;\n+    if (resp.hasRollingUpgradeStatus()) {\n+      rollingUpdateStatus \u003d PBHelper.convert(resp.getRollingUpgradeStatus());\n+    }\n+    return new HeartbeatResponse(cmds, PBHelper.convert(resp.getHaStatus()),\n+        rollingUpdateStatus);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n      StorageReport[] reports, long cacheCapacity, long cacheUsed,\n          int xmitsInProgress, int xceiverCount, int failedVolumes)\n              throws IOException {\n    HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n        .setRegistration(PBHelper.convert(registration))\n        .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n        .setFailedVolumes(failedVolumes);\n    for (StorageReport r : reports) {\n      builder.addReports(PBHelper.convert(r));\n    }\n    if (cacheCapacity !\u003d 0) {\n      builder.setCacheCapacity(cacheCapacity);\n    }\n    if (cacheUsed !\u003d 0) {\n      builder.setCacheUsed(cacheUsed);\n    }\n    HeartbeatResponseProto resp;\n    try {\n      resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n    } catch (ServiceException se) {\n      throw ProtobufHelper.getRemoteException(se);\n    }\n    DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n    int index \u003d 0;\n    for (DatanodeCommandProto p : resp.getCmdsList()) {\n      cmds[index] \u003d PBHelper.convert(p);\n      index++;\n    }\n    RollingUpgradeStatus rollingUpdateStatus \u003d null;\n    if (resp.hasRollingUpgradeStatus()) {\n      rollingUpdateStatus \u003d PBHelper.convert(resp.getRollingUpgradeStatus());\n    }\n    return new HeartbeatResponse(cmds, PBHelper.convert(resp.getHaStatus()),\n        rollingUpdateStatus);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolClientSideTranslatorPB.java",
      "extendedDetails": {}
    },
    "4f92eb2f613e4de59c2d31a563e16aba4846c61a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5848. Add rolling upgrade status to heartbeat response.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535@1563384 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "01/02/14 12:58 AM",
      "commitName": "4f92eb2f613e4de59c2d31a563e16aba4846c61a",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "11/11/13 5:16 PM",
      "commitNameOld": "ec5eebc450c54171ac783a20a030a637de1722de",
      "commitAuthorOld": "",
      "daysBetweenCommits": 81.32,
      "commitsBetweenForRepo": 459,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,31 +1,33 @@\n   public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n       StorageReport[] reports, long cacheCapacity, long cacheUsed,\n           int xmitsInProgress, int xceiverCount, int failedVolumes)\n               throws IOException {\n     HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n         .setRegistration(PBHelper.convert(registration))\n         .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n         .setFailedVolumes(failedVolumes);\n     for (StorageReport r : reports) {\n       builder.addReports(PBHelper.convert(r));\n     }\n     if (cacheCapacity !\u003d 0) {\n       builder.setCacheCapacity(cacheCapacity);\n     }\n     if (cacheUsed !\u003d 0) {\n       builder.setCacheUsed(cacheUsed);\n     }\n     HeartbeatResponseProto resp;\n     try {\n       resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n     } catch (ServiceException se) {\n       throw ProtobufHelper.getRemoteException(se);\n     }\n     DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n     int index \u003d 0;\n     for (DatanodeCommandProto p : resp.getCmdsList()) {\n       cmds[index] \u003d PBHelper.convert(p);\n       index++;\n     }\n-    return new HeartbeatResponse(cmds, PBHelper.convert(resp.getHaStatus()));\n+    return new HeartbeatResponse(cmds,\n+        PBHelper.convert(resp.getHaStatus()),\n+        PBHelper.convert(resp.getRollingUpgradeStatus()));\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n      StorageReport[] reports, long cacheCapacity, long cacheUsed,\n          int xmitsInProgress, int xceiverCount, int failedVolumes)\n              throws IOException {\n    HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n        .setRegistration(PBHelper.convert(registration))\n        .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n        .setFailedVolumes(failedVolumes);\n    for (StorageReport r : reports) {\n      builder.addReports(PBHelper.convert(r));\n    }\n    if (cacheCapacity !\u003d 0) {\n      builder.setCacheCapacity(cacheCapacity);\n    }\n    if (cacheUsed !\u003d 0) {\n      builder.setCacheUsed(cacheUsed);\n    }\n    HeartbeatResponseProto resp;\n    try {\n      resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n    } catch (ServiceException se) {\n      throw ProtobufHelper.getRemoteException(se);\n    }\n    DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n    int index \u003d 0;\n    for (DatanodeCommandProto p : resp.getCmdsList()) {\n      cmds[index] \u003d PBHelper.convert(p);\n      index++;\n    }\n    return new HeartbeatResponse(cmds,\n        PBHelper.convert(resp.getHaStatus()),\n        PBHelper.convert(resp.getRollingUpgradeStatus()));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolClientSideTranslatorPB.java",
      "extendedDetails": {}
    },
    "9673baa7e8b43fa6300080f72ebce0189ea775e5": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-5320. Add datanode caching metrics. Contributed by Andrew Wang.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1540796 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/11/13 10:30 AM",
      "commitName": "9673baa7e8b43fa6300080f72ebce0189ea775e5",
      "commitAuthor": "Andrew Wang",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-5320. Add datanode caching metrics. Contributed by Andrew Wang.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1540796 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "11/11/13 10:30 AM",
          "commitName": "9673baa7e8b43fa6300080f72ebce0189ea775e5",
          "commitAuthor": "Andrew Wang",
          "commitDateOld": "21/10/13 12:29 PM",
          "commitNameOld": "f9c08d02ebe4a5477cf5d753f0d9d48fc6f9fa48",
          "commitAuthorOld": "Colin McCabe",
          "daysBetweenCommits": 20.96,
          "commitsBetweenForRepo": 85,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,31 +1,31 @@\n   public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n-      StorageReport[] reports, long dnCacheCapacity, long dnCacheUsed,\n+      StorageReport[] reports, long cacheCapacity, long cacheUsed,\n           int xmitsInProgress, int xceiverCount, int failedVolumes)\n               throws IOException {\n     HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n         .setRegistration(PBHelper.convert(registration))\n         .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n         .setFailedVolumes(failedVolumes);\n     for (StorageReport r : reports) {\n       builder.addReports(PBHelper.convert(r));\n     }\n-    if (dnCacheCapacity !\u003d 0) {\n-      builder.setDnCacheCapacity(dnCacheCapacity);\n+    if (cacheCapacity !\u003d 0) {\n+      builder.setCacheCapacity(cacheCapacity);\n     }\n-    if (dnCacheUsed !\u003d 0) {\n-      builder.setDnCacheUsed(dnCacheUsed);\n+    if (cacheUsed !\u003d 0) {\n+      builder.setCacheUsed(cacheUsed);\n     }\n     HeartbeatResponseProto resp;\n     try {\n       resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n     } catch (ServiceException se) {\n       throw ProtobufHelper.getRemoteException(se);\n     }\n     DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n     int index \u003d 0;\n     for (DatanodeCommandProto p : resp.getCmdsList()) {\n       cmds[index] \u003d PBHelper.convert(p);\n       index++;\n     }\n     return new HeartbeatResponse(cmds, PBHelper.convert(resp.getHaStatus()));\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n      StorageReport[] reports, long cacheCapacity, long cacheUsed,\n          int xmitsInProgress, int xceiverCount, int failedVolumes)\n              throws IOException {\n    HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n        .setRegistration(PBHelper.convert(registration))\n        .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n        .setFailedVolumes(failedVolumes);\n    for (StorageReport r : reports) {\n      builder.addReports(PBHelper.convert(r));\n    }\n    if (cacheCapacity !\u003d 0) {\n      builder.setCacheCapacity(cacheCapacity);\n    }\n    if (cacheUsed !\u003d 0) {\n      builder.setCacheUsed(cacheUsed);\n    }\n    HeartbeatResponseProto resp;\n    try {\n      resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n    } catch (ServiceException se) {\n      throw ProtobufHelper.getRemoteException(se);\n    }\n    DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n    int index \u003d 0;\n    for (DatanodeCommandProto p : resp.getCmdsList()) {\n      cmds[index] \u003d PBHelper.convert(p);\n      index++;\n    }\n    return new HeartbeatResponse(cmds, PBHelper.convert(resp.getHaStatus()));\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolClientSideTranslatorPB.java",
          "extendedDetails": {
            "oldValue": "[registration-DatanodeRegistration, reports-StorageReport[], dnCacheCapacity-long, dnCacheUsed-long, xmitsInProgress-int, xceiverCount-int, failedVolumes-int]",
            "newValue": "[registration-DatanodeRegistration, reports-StorageReport[], cacheCapacity-long, cacheUsed-long, xmitsInProgress-int, xceiverCount-int, failedVolumes-int]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5320. Add datanode caching metrics. Contributed by Andrew Wang.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1540796 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "11/11/13 10:30 AM",
          "commitName": "9673baa7e8b43fa6300080f72ebce0189ea775e5",
          "commitAuthor": "Andrew Wang",
          "commitDateOld": "21/10/13 12:29 PM",
          "commitNameOld": "f9c08d02ebe4a5477cf5d753f0d9d48fc6f9fa48",
          "commitAuthorOld": "Colin McCabe",
          "daysBetweenCommits": 20.96,
          "commitsBetweenForRepo": 85,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,31 +1,31 @@\n   public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n-      StorageReport[] reports, long dnCacheCapacity, long dnCacheUsed,\n+      StorageReport[] reports, long cacheCapacity, long cacheUsed,\n           int xmitsInProgress, int xceiverCount, int failedVolumes)\n               throws IOException {\n     HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n         .setRegistration(PBHelper.convert(registration))\n         .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n         .setFailedVolumes(failedVolumes);\n     for (StorageReport r : reports) {\n       builder.addReports(PBHelper.convert(r));\n     }\n-    if (dnCacheCapacity !\u003d 0) {\n-      builder.setDnCacheCapacity(dnCacheCapacity);\n+    if (cacheCapacity !\u003d 0) {\n+      builder.setCacheCapacity(cacheCapacity);\n     }\n-    if (dnCacheUsed !\u003d 0) {\n-      builder.setDnCacheUsed(dnCacheUsed);\n+    if (cacheUsed !\u003d 0) {\n+      builder.setCacheUsed(cacheUsed);\n     }\n     HeartbeatResponseProto resp;\n     try {\n       resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n     } catch (ServiceException se) {\n       throw ProtobufHelper.getRemoteException(se);\n     }\n     DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n     int index \u003d 0;\n     for (DatanodeCommandProto p : resp.getCmdsList()) {\n       cmds[index] \u003d PBHelper.convert(p);\n       index++;\n     }\n     return new HeartbeatResponse(cmds, PBHelper.convert(resp.getHaStatus()));\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n      StorageReport[] reports, long cacheCapacity, long cacheUsed,\n          int xmitsInProgress, int xceiverCount, int failedVolumes)\n              throws IOException {\n    HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n        .setRegistration(PBHelper.convert(registration))\n        .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n        .setFailedVolumes(failedVolumes);\n    for (StorageReport r : reports) {\n      builder.addReports(PBHelper.convert(r));\n    }\n    if (cacheCapacity !\u003d 0) {\n      builder.setCacheCapacity(cacheCapacity);\n    }\n    if (cacheUsed !\u003d 0) {\n      builder.setCacheUsed(cacheUsed);\n    }\n    HeartbeatResponseProto resp;\n    try {\n      resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n    } catch (ServiceException se) {\n      throw ProtobufHelper.getRemoteException(se);\n    }\n    DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n    int index \u003d 0;\n    for (DatanodeCommandProto p : resp.getCmdsList()) {\n      cmds[index] \u003d PBHelper.convert(p);\n      index++;\n    }\n    return new HeartbeatResponse(cmds, PBHelper.convert(resp.getHaStatus()));\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolClientSideTranslatorPB.java",
          "extendedDetails": {}
        }
      ]
    },
    "f9c08d02ebe4a5477cf5d753f0d9d48fc6f9fa48": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-5378. In CacheReport, don\u0027t send genstamp and length on the wire (Contributed by Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1534334 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/10/13 12:29 PM",
      "commitName": "f9c08d02ebe4a5477cf5d753f0d9d48fc6f9fa48",
      "commitAuthor": "Colin McCabe",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-5378. In CacheReport, don\u0027t send genstamp and length on the wire (Contributed by Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1534334 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "21/10/13 12:29 PM",
          "commitName": "f9c08d02ebe4a5477cf5d753f0d9d48fc6f9fa48",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "30/08/13 3:15 PM",
          "commitNameOld": "fc14a92c6b46cc435a8f33e6fa0512c70caa06e0",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 51.88,
          "commitsBetweenForRepo": 332,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,28 +1,31 @@\n   public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n-      StorageReport[] reports, CacheReport[] cacheReports, int xmitsInProgress,\n-      int xceiverCount, int failedVolumes) throws IOException {\n+      StorageReport[] reports, long dnCacheCapacity, long dnCacheUsed,\n+          int xmitsInProgress, int xceiverCount, int failedVolumes)\n+              throws IOException {\n     HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n         .setRegistration(PBHelper.convert(registration))\n         .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n         .setFailedVolumes(failedVolumes);\n     for (StorageReport r : reports) {\n       builder.addReports(PBHelper.convert(r));\n     }\n-    for (CacheReport r : cacheReports) {\n-      builder.addCacheReports(PBHelper.convert(r));\n+    if (dnCacheCapacity !\u003d 0) {\n+      builder.setDnCacheCapacity(dnCacheCapacity);\n     }\n-    \n+    if (dnCacheUsed !\u003d 0) {\n+      builder.setDnCacheUsed(dnCacheUsed);\n+    }\n     HeartbeatResponseProto resp;\n     try {\n       resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n     } catch (ServiceException se) {\n       throw ProtobufHelper.getRemoteException(se);\n     }\n     DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n     int index \u003d 0;\n     for (DatanodeCommandProto p : resp.getCmdsList()) {\n       cmds[index] \u003d PBHelper.convert(p);\n       index++;\n     }\n     return new HeartbeatResponse(cmds, PBHelper.convert(resp.getHaStatus()));\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n      StorageReport[] reports, long dnCacheCapacity, long dnCacheUsed,\n          int xmitsInProgress, int xceiverCount, int failedVolumes)\n              throws IOException {\n    HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n        .setRegistration(PBHelper.convert(registration))\n        .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n        .setFailedVolumes(failedVolumes);\n    for (StorageReport r : reports) {\n      builder.addReports(PBHelper.convert(r));\n    }\n    if (dnCacheCapacity !\u003d 0) {\n      builder.setDnCacheCapacity(dnCacheCapacity);\n    }\n    if (dnCacheUsed !\u003d 0) {\n      builder.setDnCacheUsed(dnCacheUsed);\n    }\n    HeartbeatResponseProto resp;\n    try {\n      resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n    } catch (ServiceException se) {\n      throw ProtobufHelper.getRemoteException(se);\n    }\n    DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n    int index \u003d 0;\n    for (DatanodeCommandProto p : resp.getCmdsList()) {\n      cmds[index] \u003d PBHelper.convert(p);\n      index++;\n    }\n    return new HeartbeatResponse(cmds, PBHelper.convert(resp.getHaStatus()));\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolClientSideTranslatorPB.java",
          "extendedDetails": {
            "oldValue": "[registration-DatanodeRegistration, reports-StorageReport[], cacheReports-CacheReport[], xmitsInProgress-int, xceiverCount-int, failedVolumes-int]",
            "newValue": "[registration-DatanodeRegistration, reports-StorageReport[], dnCacheCapacity-long, dnCacheUsed-long, xmitsInProgress-int, xceiverCount-int, failedVolumes-int]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5378. In CacheReport, don\u0027t send genstamp and length on the wire (Contributed by Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1534334 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "21/10/13 12:29 PM",
          "commitName": "f9c08d02ebe4a5477cf5d753f0d9d48fc6f9fa48",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "30/08/13 3:15 PM",
          "commitNameOld": "fc14a92c6b46cc435a8f33e6fa0512c70caa06e0",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 51.88,
          "commitsBetweenForRepo": 332,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,28 +1,31 @@\n   public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n-      StorageReport[] reports, CacheReport[] cacheReports, int xmitsInProgress,\n-      int xceiverCount, int failedVolumes) throws IOException {\n+      StorageReport[] reports, long dnCacheCapacity, long dnCacheUsed,\n+          int xmitsInProgress, int xceiverCount, int failedVolumes)\n+              throws IOException {\n     HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n         .setRegistration(PBHelper.convert(registration))\n         .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n         .setFailedVolumes(failedVolumes);\n     for (StorageReport r : reports) {\n       builder.addReports(PBHelper.convert(r));\n     }\n-    for (CacheReport r : cacheReports) {\n-      builder.addCacheReports(PBHelper.convert(r));\n+    if (dnCacheCapacity !\u003d 0) {\n+      builder.setDnCacheCapacity(dnCacheCapacity);\n     }\n-    \n+    if (dnCacheUsed !\u003d 0) {\n+      builder.setDnCacheUsed(dnCacheUsed);\n+    }\n     HeartbeatResponseProto resp;\n     try {\n       resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n     } catch (ServiceException se) {\n       throw ProtobufHelper.getRemoteException(se);\n     }\n     DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n     int index \u003d 0;\n     for (DatanodeCommandProto p : resp.getCmdsList()) {\n       cmds[index] \u003d PBHelper.convert(p);\n       index++;\n     }\n     return new HeartbeatResponse(cmds, PBHelper.convert(resp.getHaStatus()));\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n      StorageReport[] reports, long dnCacheCapacity, long dnCacheUsed,\n          int xmitsInProgress, int xceiverCount, int failedVolumes)\n              throws IOException {\n    HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n        .setRegistration(PBHelper.convert(registration))\n        .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n        .setFailedVolumes(failedVolumes);\n    for (StorageReport r : reports) {\n      builder.addReports(PBHelper.convert(r));\n    }\n    if (dnCacheCapacity !\u003d 0) {\n      builder.setDnCacheCapacity(dnCacheCapacity);\n    }\n    if (dnCacheUsed !\u003d 0) {\n      builder.setDnCacheUsed(dnCacheUsed);\n    }\n    HeartbeatResponseProto resp;\n    try {\n      resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n    } catch (ServiceException se) {\n      throw ProtobufHelper.getRemoteException(se);\n    }\n    DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n    int index \u003d 0;\n    for (DatanodeCommandProto p : resp.getCmdsList()) {\n      cmds[index] \u003d PBHelper.convert(p);\n      index++;\n    }\n    return new HeartbeatResponse(cmds, PBHelper.convert(resp.getHaStatus()));\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolClientSideTranslatorPB.java",
          "extendedDetails": {}
        }
      ]
    },
    "fc14a92c6b46cc435a8f33e6fa0512c70caa06e0": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-5141. Add cache status information to datanode heartbeat. (Contributed by Andrew Wang)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1519101 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "30/08/13 3:15 PM",
      "commitName": "fc14a92c6b46cc435a8f33e6fa0512c70caa06e0",
      "commitAuthor": "Andrew Wang",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-5141. Add cache status information to datanode heartbeat. (Contributed by Andrew Wang)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1519101 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "30/08/13 3:15 PM",
          "commitName": "fc14a92c6b46cc435a8f33e6fa0512c70caa06e0",
          "commitAuthor": "Andrew Wang",
          "commitDateOld": "13/08/13 2:05 PM",
          "commitNameOld": "52ccc6c6d539d0587c3fd9693709bd1f6e12619d",
          "commitAuthorOld": "Colin McCabe",
          "daysBetweenCommits": 17.05,
          "commitsBetweenForRepo": 15,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,25 +1,28 @@\n   public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n-      StorageReport[] reports, int xmitsInProgress, int xceiverCount,\n-      int failedVolumes) throws IOException {\n+      StorageReport[] reports, CacheReport[] cacheReports, int xmitsInProgress,\n+      int xceiverCount, int failedVolumes) throws IOException {\n     HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n         .setRegistration(PBHelper.convert(registration))\n         .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n         .setFailedVolumes(failedVolumes);\n     for (StorageReport r : reports) {\n       builder.addReports(PBHelper.convert(r));\n     }\n+    for (CacheReport r : cacheReports) {\n+      builder.addCacheReports(PBHelper.convert(r));\n+    }\n     \n     HeartbeatResponseProto resp;\n     try {\n       resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n     } catch (ServiceException se) {\n       throw ProtobufHelper.getRemoteException(se);\n     }\n     DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n     int index \u003d 0;\n     for (DatanodeCommandProto p : resp.getCmdsList()) {\n       cmds[index] \u003d PBHelper.convert(p);\n       index++;\n     }\n     return new HeartbeatResponse(cmds, PBHelper.convert(resp.getHaStatus()));\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n      StorageReport[] reports, CacheReport[] cacheReports, int xmitsInProgress,\n      int xceiverCount, int failedVolumes) throws IOException {\n    HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n        .setRegistration(PBHelper.convert(registration))\n        .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n        .setFailedVolumes(failedVolumes);\n    for (StorageReport r : reports) {\n      builder.addReports(PBHelper.convert(r));\n    }\n    for (CacheReport r : cacheReports) {\n      builder.addCacheReports(PBHelper.convert(r));\n    }\n    \n    HeartbeatResponseProto resp;\n    try {\n      resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n    } catch (ServiceException se) {\n      throw ProtobufHelper.getRemoteException(se);\n    }\n    DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n    int index \u003d 0;\n    for (DatanodeCommandProto p : resp.getCmdsList()) {\n      cmds[index] \u003d PBHelper.convert(p);\n      index++;\n    }\n    return new HeartbeatResponse(cmds, PBHelper.convert(resp.getHaStatus()));\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolClientSideTranslatorPB.java",
          "extendedDetails": {
            "oldValue": "[registration-DatanodeRegistration, reports-StorageReport[], xmitsInProgress-int, xceiverCount-int, failedVolumes-int]",
            "newValue": "[registration-DatanodeRegistration, reports-StorageReport[], cacheReports-CacheReport[], xmitsInProgress-int, xceiverCount-int, failedVolumes-int]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5141. Add cache status information to datanode heartbeat. (Contributed by Andrew Wang)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1519101 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "30/08/13 3:15 PM",
          "commitName": "fc14a92c6b46cc435a8f33e6fa0512c70caa06e0",
          "commitAuthor": "Andrew Wang",
          "commitDateOld": "13/08/13 2:05 PM",
          "commitNameOld": "52ccc6c6d539d0587c3fd9693709bd1f6e12619d",
          "commitAuthorOld": "Colin McCabe",
          "daysBetweenCommits": 17.05,
          "commitsBetweenForRepo": 15,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,25 +1,28 @@\n   public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n-      StorageReport[] reports, int xmitsInProgress, int xceiverCount,\n-      int failedVolumes) throws IOException {\n+      StorageReport[] reports, CacheReport[] cacheReports, int xmitsInProgress,\n+      int xceiverCount, int failedVolumes) throws IOException {\n     HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n         .setRegistration(PBHelper.convert(registration))\n         .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n         .setFailedVolumes(failedVolumes);\n     for (StorageReport r : reports) {\n       builder.addReports(PBHelper.convert(r));\n     }\n+    for (CacheReport r : cacheReports) {\n+      builder.addCacheReports(PBHelper.convert(r));\n+    }\n     \n     HeartbeatResponseProto resp;\n     try {\n       resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n     } catch (ServiceException se) {\n       throw ProtobufHelper.getRemoteException(se);\n     }\n     DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n     int index \u003d 0;\n     for (DatanodeCommandProto p : resp.getCmdsList()) {\n       cmds[index] \u003d PBHelper.convert(p);\n       index++;\n     }\n     return new HeartbeatResponse(cmds, PBHelper.convert(resp.getHaStatus()));\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public HeartbeatResponse sendHeartbeat(DatanodeRegistration registration,\n      StorageReport[] reports, CacheReport[] cacheReports, int xmitsInProgress,\n      int xceiverCount, int failedVolumes) throws IOException {\n    HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n        .setRegistration(PBHelper.convert(registration))\n        .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n        .setFailedVolumes(failedVolumes);\n    for (StorageReport r : reports) {\n      builder.addReports(PBHelper.convert(r));\n    }\n    for (CacheReport r : cacheReports) {\n      builder.addCacheReports(PBHelper.convert(r));\n    }\n    \n    HeartbeatResponseProto resp;\n    try {\n      resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n    } catch (ServiceException se) {\n      throw ProtobufHelper.getRemoteException(se);\n    }\n    DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n    int index \u003d 0;\n    for (DatanodeCommandProto p : resp.getCmdsList()) {\n      cmds[index] \u003d PBHelper.convert(p);\n      index++;\n    }\n    return new HeartbeatResponse(cmds, PBHelper.convert(resp.getHaStatus()));\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolClientSideTranslatorPB.java",
          "extendedDetails": {}
        }
      ]
    },
    "28eadb7cd71e99d563fb5c41aec563ab11e293e5": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-2899. Service protocol changes in DatanodeProtocol to add multiple storages. Contributed by Suresh Srinivas.\n\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1241519 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/02/12 8:59 AM",
      "commitName": "28eadb7cd71e99d563fb5c41aec563ab11e293e5",
      "commitAuthor": "Suresh Srinivas",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-2899. Service protocol changes in DatanodeProtocol to add multiple storages. Contributed by Suresh Srinivas.\n\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1241519 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "07/02/12 8:59 AM",
          "commitName": "28eadb7cd71e99d563fb5c41aec563ab11e293e5",
          "commitAuthor": "Suresh Srinivas",
          "commitDateOld": "06/02/12 5:33 AM",
          "commitNameOld": "2a9e430ff9327ad311db7954400ff664ae66ec45",
          "commitAuthorOld": "Suresh Srinivas",
          "daysBetweenCommits": 1.14,
          "commitsBetweenForRepo": 17,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,28 +1,25 @@\n   public DatanodeCommand[] sendHeartbeat(DatanodeRegistration registration,\n-      long capacity, long dfsUsed, long remaining, long blockPoolUsed,\n-      int xmitsInProgress, int xceiverCount, int failedVolumes)\n-      throws IOException {\n-    StorageReportProto report \u003d StorageReportProto.newBuilder()\n-        .setBlockPoolUsed(blockPoolUsed).setCapacity(capacity)\n-        .setDfsUsed(dfsUsed).setRemaining(remaining)\n-        .setStorageID(registration.getStorageID()).build();\n-    \n-    HeartbeatRequestProto req \u003d HeartbeatRequestProto.newBuilder()\n-        .setRegistration(PBHelper.convert(registration)).addReports(report)\n+      StorageReport[] reports, int xmitsInProgress, int xceiverCount,\n+      int failedVolumes) throws IOException {\n+    HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n+        .setRegistration(PBHelper.convert(registration))\n         .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n-        .setFailedVolumes(failedVolumes)\n-        .build();\n+        .setFailedVolumes(failedVolumes);\n+    for (StorageReport r : reports) {\n+      builder.addReports(PBHelper.convert(r));\n+    }\n+    \n     HeartbeatResponseProto resp;\n     try {\n-      resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, req);\n+      resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n     } catch (ServiceException se) {\n       throw ProtobufHelper.getRemoteException(se);\n     }\n     DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n     int index \u003d 0;\n     for (DatanodeCommandProto p : resp.getCmdsList()) {\n       cmds[index] \u003d PBHelper.convert(p);\n       index++;\n     }\n     return cmds;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public DatanodeCommand[] sendHeartbeat(DatanodeRegistration registration,\n      StorageReport[] reports, int xmitsInProgress, int xceiverCount,\n      int failedVolumes) throws IOException {\n    HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n        .setRegistration(PBHelper.convert(registration))\n        .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n        .setFailedVolumes(failedVolumes);\n    for (StorageReport r : reports) {\n      builder.addReports(PBHelper.convert(r));\n    }\n    \n    HeartbeatResponseProto resp;\n    try {\n      resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n    } catch (ServiceException se) {\n      throw ProtobufHelper.getRemoteException(se);\n    }\n    DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n    int index \u003d 0;\n    for (DatanodeCommandProto p : resp.getCmdsList()) {\n      cmds[index] \u003d PBHelper.convert(p);\n      index++;\n    }\n    return cmds;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolClientSideTranslatorPB.java",
          "extendedDetails": {
            "oldValue": "[registration-DatanodeRegistration, capacity-long, dfsUsed-long, remaining-long, blockPoolUsed-long, xmitsInProgress-int, xceiverCount-int, failedVolumes-int]",
            "newValue": "[registration-DatanodeRegistration, reports-StorageReport[], xmitsInProgress-int, xceiverCount-int, failedVolumes-int]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-2899. Service protocol changes in DatanodeProtocol to add multiple storages. Contributed by Suresh Srinivas.\n\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1241519 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "07/02/12 8:59 AM",
          "commitName": "28eadb7cd71e99d563fb5c41aec563ab11e293e5",
          "commitAuthor": "Suresh Srinivas",
          "commitDateOld": "06/02/12 5:33 AM",
          "commitNameOld": "2a9e430ff9327ad311db7954400ff664ae66ec45",
          "commitAuthorOld": "Suresh Srinivas",
          "daysBetweenCommits": 1.14,
          "commitsBetweenForRepo": 17,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,28 +1,25 @@\n   public DatanodeCommand[] sendHeartbeat(DatanodeRegistration registration,\n-      long capacity, long dfsUsed, long remaining, long blockPoolUsed,\n-      int xmitsInProgress, int xceiverCount, int failedVolumes)\n-      throws IOException {\n-    StorageReportProto report \u003d StorageReportProto.newBuilder()\n-        .setBlockPoolUsed(blockPoolUsed).setCapacity(capacity)\n-        .setDfsUsed(dfsUsed).setRemaining(remaining)\n-        .setStorageID(registration.getStorageID()).build();\n-    \n-    HeartbeatRequestProto req \u003d HeartbeatRequestProto.newBuilder()\n-        .setRegistration(PBHelper.convert(registration)).addReports(report)\n+      StorageReport[] reports, int xmitsInProgress, int xceiverCount,\n+      int failedVolumes) throws IOException {\n+    HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n+        .setRegistration(PBHelper.convert(registration))\n         .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n-        .setFailedVolumes(failedVolumes)\n-        .build();\n+        .setFailedVolumes(failedVolumes);\n+    for (StorageReport r : reports) {\n+      builder.addReports(PBHelper.convert(r));\n+    }\n+    \n     HeartbeatResponseProto resp;\n     try {\n-      resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, req);\n+      resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n     } catch (ServiceException se) {\n       throw ProtobufHelper.getRemoteException(se);\n     }\n     DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n     int index \u003d 0;\n     for (DatanodeCommandProto p : resp.getCmdsList()) {\n       cmds[index] \u003d PBHelper.convert(p);\n       index++;\n     }\n     return cmds;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public DatanodeCommand[] sendHeartbeat(DatanodeRegistration registration,\n      StorageReport[] reports, int xmitsInProgress, int xceiverCount,\n      int failedVolumes) throws IOException {\n    HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n        .setRegistration(PBHelper.convert(registration))\n        .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n        .setFailedVolumes(failedVolumes);\n    for (StorageReport r : reports) {\n      builder.addReports(PBHelper.convert(r));\n    }\n    \n    HeartbeatResponseProto resp;\n    try {\n      resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, builder.build());\n    } catch (ServiceException se) {\n      throw ProtobufHelper.getRemoteException(se);\n    }\n    DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n    int index \u003d 0;\n    for (DatanodeCommandProto p : resp.getCmdsList()) {\n      cmds[index] \u003d PBHelper.convert(p);\n      index++;\n    }\n    return cmds;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolClientSideTranslatorPB.java",
          "extendedDetails": {}
        }
      ]
    },
    "f88574acdefae2816236bf6180916be96c6a6874": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2880. Protobuf chagnes in DatanodeProtocol to add multiple storages. Contributed by Suresh Srinivas.\n\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1240653 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/02/12 5:39 PM",
      "commitName": "f88574acdefae2816236bf6180916be96c6a6874",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "28/01/12 6:01 PM",
      "commitNameOld": "98302971c240858c1c8018affb11bac453a83db2",
      "commitAuthorOld": "Jitendra Nath Pandey",
      "daysBetweenCommits": 6.98,
      "commitsBetweenForRepo": 56,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,28 @@\n   public DatanodeCommand[] sendHeartbeat(DatanodeRegistration registration,\n       long capacity, long dfsUsed, long remaining, long blockPoolUsed,\n       int xmitsInProgress, int xceiverCount, int failedVolumes)\n       throws IOException {\n-    HeartbeatRequestProto req \u003d HeartbeatRequestProto.newBuilder()\n-        .setRegistration(PBHelper.convert(registration)).setCapacity(capacity)\n+    StorageReportProto report \u003d StorageReportProto.newBuilder()\n+        .setBlockPoolUsed(blockPoolUsed).setCapacity(capacity)\n         .setDfsUsed(dfsUsed).setRemaining(remaining)\n-        .setBlockPoolUsed(blockPoolUsed).setXmitsInProgress(xmitsInProgress)\n-        .setXceiverCount(xceiverCount).setFailedVolumes(failedVolumes).build();\n+        .setStorageID(registration.getStorageID()).build();\n+    \n+    HeartbeatRequestProto req \u003d HeartbeatRequestProto.newBuilder()\n+        .setRegistration(PBHelper.convert(registration)).addReports(report)\n+        .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n+        .setFailedVolumes(failedVolumes)\n+        .build();\n     HeartbeatResponseProto resp;\n     try {\n       resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, req);\n     } catch (ServiceException se) {\n       throw ProtobufHelper.getRemoteException(se);\n     }\n     DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n     int index \u003d 0;\n     for (DatanodeCommandProto p : resp.getCmdsList()) {\n       cmds[index] \u003d PBHelper.convert(p);\n       index++;\n     }\n     return cmds;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public DatanodeCommand[] sendHeartbeat(DatanodeRegistration registration,\n      long capacity, long dfsUsed, long remaining, long blockPoolUsed,\n      int xmitsInProgress, int xceiverCount, int failedVolumes)\n      throws IOException {\n    StorageReportProto report \u003d StorageReportProto.newBuilder()\n        .setBlockPoolUsed(blockPoolUsed).setCapacity(capacity)\n        .setDfsUsed(dfsUsed).setRemaining(remaining)\n        .setStorageID(registration.getStorageID()).build();\n    \n    HeartbeatRequestProto req \u003d HeartbeatRequestProto.newBuilder()\n        .setRegistration(PBHelper.convert(registration)).addReports(report)\n        .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n        .setFailedVolumes(failedVolumes)\n        .build();\n    HeartbeatResponseProto resp;\n    try {\n      resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, req);\n    } catch (ServiceException se) {\n      throw ProtobufHelper.getRemoteException(se);\n    }\n    DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n    int index \u003d 0;\n    for (DatanodeCommandProto p : resp.getCmdsList()) {\n      cmds[index] \u003d PBHelper.convert(p);\n      index++;\n    }\n    return cmds;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolClientSideTranslatorPB.java",
      "extendedDetails": {}
    },
    "3cffe34177c72ea67194c3b0aaf0ddbf67ff3a0c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2661. Enable protobuf RPC for DatanodeProtocol.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1214033 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/12/11 6:15 PM",
      "commitName": "3cffe34177c72ea67194c3b0aaf0ddbf67ff3a0c",
      "commitAuthor": "Jitendra Nath Pandey",
      "commitDateOld": "13/12/11 3:31 PM",
      "commitNameOld": "3954a2fb1cbc7a8a0d1ad5859e7f5c9415530f4c",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 0.11,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,23 @@\n   public DatanodeCommand[] sendHeartbeat(DatanodeRegistration registration,\n       long capacity, long dfsUsed, long remaining, long blockPoolUsed,\n       int xmitsInProgress, int xceiverCount, int failedVolumes)\n       throws IOException {\n     HeartbeatRequestProto req \u003d HeartbeatRequestProto.newBuilder()\n         .setRegistration(PBHelper.convert(registration)).setCapacity(capacity)\n-        .setCapacity(dfsUsed).setRemaining(remaining)\n+        .setDfsUsed(dfsUsed).setRemaining(remaining)\n         .setBlockPoolUsed(blockPoolUsed).setXmitsInProgress(xmitsInProgress)\n         .setXceiverCount(xceiverCount).setFailedVolumes(failedVolumes).build();\n     HeartbeatResponseProto resp;\n     try {\n       resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, req);\n     } catch (ServiceException se) {\n       throw ProtobufHelper.getRemoteException(se);\n     }\n     DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n     int index \u003d 0;\n     for (DatanodeCommandProto p : resp.getCmdsList()) {\n       cmds[index] \u003d PBHelper.convert(p);\n       index++;\n     }\n     return cmds;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public DatanodeCommand[] sendHeartbeat(DatanodeRegistration registration,\n      long capacity, long dfsUsed, long remaining, long blockPoolUsed,\n      int xmitsInProgress, int xceiverCount, int failedVolumes)\n      throws IOException {\n    HeartbeatRequestProto req \u003d HeartbeatRequestProto.newBuilder()\n        .setRegistration(PBHelper.convert(registration)).setCapacity(capacity)\n        .setDfsUsed(dfsUsed).setRemaining(remaining)\n        .setBlockPoolUsed(blockPoolUsed).setXmitsInProgress(xmitsInProgress)\n        .setXceiverCount(xceiverCount).setFailedVolumes(failedVolumes).build();\n    HeartbeatResponseProto resp;\n    try {\n      resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, req);\n    } catch (ServiceException se) {\n      throw ProtobufHelper.getRemoteException(se);\n    }\n    DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n    int index \u003d 0;\n    for (DatanodeCommandProto p : resp.getCmdsList()) {\n      cmds[index] \u003d PBHelper.convert(p);\n      index++;\n    }\n    return cmds;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolClientSideTranslatorPB.java",
      "extendedDetails": {}
    },
    "38a19bc293dec6221ae96e304fc6ab660d94e706": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-2642. Protobuf translators for DatanodeProtocol.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1212606 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/12/11 12:02 PM",
      "commitName": "38a19bc293dec6221ae96e304fc6ab660d94e706",
      "commitAuthor": "Jitendra Nath Pandey",
      "diff": "@@ -0,0 +1,23 @@\n+  public DatanodeCommand[] sendHeartbeat(DatanodeRegistration registration,\n+      long capacity, long dfsUsed, long remaining, long blockPoolUsed,\n+      int xmitsInProgress, int xceiverCount, int failedVolumes)\n+      throws IOException {\n+    HeartbeatRequestProto req \u003d HeartbeatRequestProto.newBuilder()\n+        .setRegistration(PBHelper.convert(registration)).setCapacity(capacity)\n+        .setCapacity(dfsUsed).setRemaining(remaining)\n+        .setBlockPoolUsed(blockPoolUsed).setXmitsInProgress(xmitsInProgress)\n+        .setXceiverCount(xceiverCount).setFailedVolumes(failedVolumes).build();\n+    HeartbeatResponseProto resp;\n+    try {\n+      resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, req);\n+    } catch (ServiceException se) {\n+      throw ProtobufHelper.getRemoteException(se);\n+    }\n+    DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n+    int index \u003d 0;\n+    for (DatanodeCommandProto p : resp.getCmdsList()) {\n+      cmds[index] \u003d PBHelper.convert(p);\n+      index++;\n+    }\n+    return cmds;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public DatanodeCommand[] sendHeartbeat(DatanodeRegistration registration,\n      long capacity, long dfsUsed, long remaining, long blockPoolUsed,\n      int xmitsInProgress, int xceiverCount, int failedVolumes)\n      throws IOException {\n    HeartbeatRequestProto req \u003d HeartbeatRequestProto.newBuilder()\n        .setRegistration(PBHelper.convert(registration)).setCapacity(capacity)\n        .setCapacity(dfsUsed).setRemaining(remaining)\n        .setBlockPoolUsed(blockPoolUsed).setXmitsInProgress(xmitsInProgress)\n        .setXceiverCount(xceiverCount).setFailedVolumes(failedVolumes).build();\n    HeartbeatResponseProto resp;\n    try {\n      resp \u003d rpcProxy.sendHeartbeat(NULL_CONTROLLER, req);\n    } catch (ServiceException se) {\n      throw ProtobufHelper.getRemoteException(se);\n    }\n    DatanodeCommand[] cmds \u003d new DatanodeCommand[resp.getCmdsList().size()];\n    int index \u003d 0;\n    for (DatanodeCommandProto p : resp.getCmdsList()) {\n      cmds[index] \u003d PBHelper.convert(p);\n      index++;\n    }\n    return cmds;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolClientSideTranslatorPB.java"
    }
  }
}