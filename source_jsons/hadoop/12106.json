{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DataNode.java",
  "functionName": "getHostName",
  "functionId": "getHostName___config-Configuration",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java",
  "functionStartLine": 943,
  "functionEndLine": 967,
  "numCommitsSeen": 358,
  "timeTaken": 2150,
  "changeHistory": [
    "dfcb331ba3516264398121c9f23af3a79c0509cc"
  ],
  "changeHistoryShort": {
    "dfcb331ba3516264398121c9f23af3a79c0509cc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "dfcb331ba3516264398121c9f23af3a79c0509cc": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-13076: [SPS]: Addendum. Resolve conflicts after rebasing branch to trunk. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "dfcb331ba3516264398121c9f23af3a79c0509cc",
      "commitAuthor": "Rakesh Radhakrishnan",
      "diff": "@@ -0,0 +1,25 @@\n+  private static String getHostName(Configuration config)\n+      throws UnknownHostException {\n+    String name \u003d config.get(DFS_DATANODE_HOST_NAME_KEY);\n+    if (name \u003d\u003d null) {\n+      String dnsInterface \u003d config.get(\n+          CommonConfigurationKeys.HADOOP_SECURITY_DNS_INTERFACE_KEY);\n+      String nameServer \u003d config.get(\n+          CommonConfigurationKeys.HADOOP_SECURITY_DNS_NAMESERVER_KEY);\n+      boolean fallbackToHosts \u003d false;\n+\n+      if (dnsInterface \u003d\u003d null) {\n+        // Try the legacy configuration keys.\n+        dnsInterface \u003d config.get(DFS_DATANODE_DNS_INTERFACE_KEY);\n+        nameServer \u003d config.get(DFS_DATANODE_DNS_NAMESERVER_KEY);\n+      } else {\n+        // If HADOOP_SECURITY_DNS_* is set then also attempt hosts file\n+        // resolution if DNS fails. We will not use hosts file resolution\n+        // by default to avoid breaking existing clusters.\n+        fallbackToHosts \u003d true;\n+      }\n+\n+      name \u003d DNS.getDefaultHost(dnsInterface, nameServer, fallbackToHosts);\n+    }\n+    return name;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private static String getHostName(Configuration config)\n      throws UnknownHostException {\n    String name \u003d config.get(DFS_DATANODE_HOST_NAME_KEY);\n    if (name \u003d\u003d null) {\n      String dnsInterface \u003d config.get(\n          CommonConfigurationKeys.HADOOP_SECURITY_DNS_INTERFACE_KEY);\n      String nameServer \u003d config.get(\n          CommonConfigurationKeys.HADOOP_SECURITY_DNS_NAMESERVER_KEY);\n      boolean fallbackToHosts \u003d false;\n\n      if (dnsInterface \u003d\u003d null) {\n        // Try the legacy configuration keys.\n        dnsInterface \u003d config.get(DFS_DATANODE_DNS_INTERFACE_KEY);\n        nameServer \u003d config.get(DFS_DATANODE_DNS_NAMESERVER_KEY);\n      } else {\n        // If HADOOP_SECURITY_DNS_* is set then also attempt hosts file\n        // resolution if DNS fails. We will not use hosts file resolution\n        // by default to avoid breaking existing clusters.\n        fallbackToHosts \u003d true;\n      }\n\n      name \u003d DNS.getDefaultHost(dnsInterface, nameServer, fallbackToHosts);\n    }\n    return name;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java"
    }
  }
}