{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockStorageMovementNeeded.java",
  "functionName": "addAll",
  "functionId": "addAll___startPath-long__itemInfoList-List__ItemInfo____scanCompleted-boolean",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/BlockStorageMovementNeeded.java",
  "functionStartLine": 99,
  "functionEndLine": 103,
  "numCommitsSeen": 36,
  "timeTaken": 7565,
  "changeHistory": [
    "66e8f9b31529226309c924226a53dead3e6fcf11",
    "8467ec24fb74f30371d5a13e893fc56309ee9372",
    "3159b39cf8ef704835325263154fb1a1cecc109d",
    "78420719eb1f138c6f10558befb7bc8ebcc28a54",
    "bfd3f8bd8a9ae2186ec3e4addc71f912ec7b8923",
    "7ea24fc06c081e2ba6f5f66d212abb14b80c9064"
  ],
  "changeHistoryShort": {
    "66e8f9b31529226309c924226a53dead3e6fcf11": "Yparameterchange",
    "8467ec24fb74f30371d5a13e893fc56309ee9372": "Ymultichange(Yparameterchange,Ybodychange)",
    "3159b39cf8ef704835325263154fb1a1cecc109d": "Ybodychange",
    "78420719eb1f138c6f10558befb7bc8ebcc28a54": "Yfilerename",
    "bfd3f8bd8a9ae2186ec3e4addc71f912ec7b8923": "Ymultichange(Yparameterchange,Ymodifierchange,Ybodychange)",
    "7ea24fc06c081e2ba6f5f66d212abb14b80c9064": "Yintroduced"
  },
  "changeHistoryDetails": {
    "66e8f9b31529226309c924226a53dead3e6fcf11": {
      "type": "Yparameterchange",
      "commitMessage": "HDFS-13381 : [SPS]: Use DFSUtilClient#makePathFromFileId() to prepare satisfier file path. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "66e8f9b31529226309c924226a53dead3e6fcf11",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "8467ec24fb74f30371d5a13e893fc56309ee9372",
      "commitAuthorOld": "Rakesh Radhakrishnan",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,5 +1,5 @@\n-  public synchronized void addAll(T startPath, List\u003cItemInfo\u003cT\u003e\u003e itemInfoList,\n+  public synchronized void addAll(long startPath, List\u003cItemInfo\u003e itemInfoList,\n       boolean scanCompleted) {\n     storageMovementNeeded.addAll(itemInfoList);\n     updatePendingDirScanStats(startPath, itemInfoList.size(), scanCompleted);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void addAll(long startPath, List\u003cItemInfo\u003e itemInfoList,\n      boolean scanCompleted) {\n    storageMovementNeeded.addAll(itemInfoList);\n    updatePendingDirScanStats(startPath, itemInfoList.size(), scanCompleted);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/BlockStorageMovementNeeded.java",
      "extendedDetails": {
        "oldValue": "[startPath-T, itemInfoList-List\u003cItemInfo\u003cT\u003e\u003e, scanCompleted-boolean]",
        "newValue": "[startPath-long, itemInfoList-List\u003cItemInfo\u003e, scanCompleted-boolean]"
      }
    },
    "8467ec24fb74f30371d5a13e893fc56309ee9372": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-13110: [SPS]: Reduce the number of APIs in NamenodeProtocol used by external satisfier. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "8467ec24fb74f30371d5a13e893fc56309ee9372",
      "commitAuthor": "Rakesh Radhakrishnan",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-13110: [SPS]: Reduce the number of APIs in NamenodeProtocol used by external satisfier. Contributed by Rakesh R.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "8467ec24fb74f30371d5a13e893fc56309ee9372",
          "commitAuthor": "Rakesh Radhakrishnan",
          "commitDateOld": "12/08/18 3:06 AM",
          "commitNameOld": "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52",
          "commitAuthorOld": "Uma Maheswara Rao G",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,5 +1,5 @@\n-  public synchronized void addAll(long startId, List\u003cItemInfo\u003e itemInfoList,\n+  public synchronized void addAll(T startPath, List\u003cItemInfo\u003cT\u003e\u003e itemInfoList,\n       boolean scanCompleted) {\n     storageMovementNeeded.addAll(itemInfoList);\n-    updatePendingDirScanStats(startId, itemInfoList.size(), scanCompleted);\n+    updatePendingDirScanStats(startPath, itemInfoList.size(), scanCompleted);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public synchronized void addAll(T startPath, List\u003cItemInfo\u003cT\u003e\u003e itemInfoList,\n      boolean scanCompleted) {\n    storageMovementNeeded.addAll(itemInfoList);\n    updatePendingDirScanStats(startPath, itemInfoList.size(), scanCompleted);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/BlockStorageMovementNeeded.java",
          "extendedDetails": {
            "oldValue": "[startId-long, itemInfoList-List\u003cItemInfo\u003e, scanCompleted-boolean]",
            "newValue": "[startPath-T, itemInfoList-List\u003cItemInfo\u003cT\u003e\u003e, scanCompleted-boolean]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-13110: [SPS]: Reduce the number of APIs in NamenodeProtocol used by external satisfier. Contributed by Rakesh R.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "8467ec24fb74f30371d5a13e893fc56309ee9372",
          "commitAuthor": "Rakesh Radhakrishnan",
          "commitDateOld": "12/08/18 3:06 AM",
          "commitNameOld": "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52",
          "commitAuthorOld": "Uma Maheswara Rao G",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,5 +1,5 @@\n-  public synchronized void addAll(long startId, List\u003cItemInfo\u003e itemInfoList,\n+  public synchronized void addAll(T startPath, List\u003cItemInfo\u003cT\u003e\u003e itemInfoList,\n       boolean scanCompleted) {\n     storageMovementNeeded.addAll(itemInfoList);\n-    updatePendingDirScanStats(startId, itemInfoList.size(), scanCompleted);\n+    updatePendingDirScanStats(startPath, itemInfoList.size(), scanCompleted);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public synchronized void addAll(T startPath, List\u003cItemInfo\u003cT\u003e\u003e itemInfoList,\n      boolean scanCompleted) {\n    storageMovementNeeded.addAll(itemInfoList);\n    updatePendingDirScanStats(startPath, itemInfoList.size(), scanCompleted);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/BlockStorageMovementNeeded.java",
          "extendedDetails": {}
        }
      ]
    },
    "3159b39cf8ef704835325263154fb1a1cecc109d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13025. [SPS]: Implement a mechanism to scan the files for external SPS. Contributed by Uma Maheswara Rao G.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "3159b39cf8ef704835325263154fb1a1cecc109d",
      "commitAuthor": "Rakesh Radhakrishnan",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "8d4f74e7339abc77dc0daa162d7bd2814bd79b3d",
      "commitAuthorOld": "Rakesh Radhakrishnan",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,5 @@\n-  public synchronized void addAll(long startId,\n-      List\u003cItemInfo\u003e itemInfoList, boolean scanCompleted) {\n+  public synchronized void addAll(long startId, List\u003cItemInfo\u003e itemInfoList,\n+      boolean scanCompleted) {\n     storageMovementNeeded.addAll(itemInfoList);\n-    DirPendingWorkInfo pendingWork \u003d pendingWorkForDirectory.get(startId);\n-    if (pendingWork \u003d\u003d null) {\n-      pendingWork \u003d new DirPendingWorkInfo();\n-      pendingWorkForDirectory.put(startId, pendingWork);\n-    }\n-    pendingWork.addPendingWorkCount(itemInfoList.size());\n-    if (scanCompleted) {\n-      pendingWork.markScanCompleted();\n-    }\n+    updatePendingDirScanStats(startId, itemInfoList.size(), scanCompleted);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void addAll(long startId, List\u003cItemInfo\u003e itemInfoList,\n      boolean scanCompleted) {\n    storageMovementNeeded.addAll(itemInfoList);\n    updatePendingDirScanStats(startId, itemInfoList.size(), scanCompleted);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/BlockStorageMovementNeeded.java",
      "extendedDetails": {}
    },
    "78420719eb1f138c6f10558befb7bc8ebcc28a54": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-12955: [SPS]: Move SPS classes to a separate package. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "78420719eb1f138c6f10558befb7bc8ebcc28a54",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "c561cb316e365ef674784cd6cf0b12c0fbc271a3",
      "commitAuthorOld": "Surendra Singh Lilhore",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public synchronized void addAll(long startId,\n      List\u003cItemInfo\u003e itemInfoList, boolean scanCompleted) {\n    storageMovementNeeded.addAll(itemInfoList);\n    DirPendingWorkInfo pendingWork \u003d pendingWorkForDirectory.get(startId);\n    if (pendingWork \u003d\u003d null) {\n      pendingWork \u003d new DirPendingWorkInfo();\n      pendingWorkForDirectory.put(startId, pendingWork);\n    }\n    pendingWork.addPendingWorkCount(itemInfoList.size());\n    if (scanCompleted) {\n      pendingWork.markScanCompleted();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/BlockStorageMovementNeeded.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/BlockStorageMovementNeeded.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/BlockStorageMovementNeeded.java"
      }
    },
    "bfd3f8bd8a9ae2186ec3e4addc71f912ec7b8923": {
      "type": "Ymultichange(Yparameterchange,Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-12291: [SPS]: Provide a mechanism to recursively iterate and satisfy storage policy of all the files under the given dir. Contributed by Surendra Singh Lilhore.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "bfd3f8bd8a9ae2186ec3e4addc71f912ec7b8923",
      "commitAuthor": "Uma Maheswara Rao G",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-12291: [SPS]: Provide a mechanism to recursively iterate and satisfy storage policy of all the files under the given dir. Contributed by Surendra Singh Lilhore.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "bfd3f8bd8a9ae2186ec3e4addc71f912ec7b8923",
          "commitAuthor": "Uma Maheswara Rao G",
          "commitDateOld": "12/08/18 3:06 AM",
          "commitNameOld": "7ea24fc06c081e2ba6f5f66d212abb14b80c9064",
          "commitAuthorOld": "Uma Maheswara Rao G",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,5 +1,13 @@\n-  private synchronized void addAll(Long rootId,\n-      List\u003cItemInfo\u003e itemInfoList) {\n+  public synchronized void addAll(long startId,\n+      List\u003cItemInfo\u003e itemInfoList, boolean scanCompleted) {\n     storageMovementNeeded.addAll(itemInfoList);\n-    pendingWorkForDirectory.put(rootId, itemInfoList.size());\n+    DirPendingWorkInfo pendingWork \u003d pendingWorkForDirectory.get(startId);\n+    if (pendingWork \u003d\u003d null) {\n+      pendingWork \u003d new DirPendingWorkInfo();\n+      pendingWorkForDirectory.put(startId, pendingWork);\n+    }\n+    pendingWork.addPendingWorkCount(itemInfoList.size());\n+    if (scanCompleted) {\n+      pendingWork.markScanCompleted();\n+    }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public synchronized void addAll(long startId,\n      List\u003cItemInfo\u003e itemInfoList, boolean scanCompleted) {\n    storageMovementNeeded.addAll(itemInfoList);\n    DirPendingWorkInfo pendingWork \u003d pendingWorkForDirectory.get(startId);\n    if (pendingWork \u003d\u003d null) {\n      pendingWork \u003d new DirPendingWorkInfo();\n      pendingWorkForDirectory.put(startId, pendingWork);\n    }\n    pendingWork.addPendingWorkCount(itemInfoList.size());\n    if (scanCompleted) {\n      pendingWork.markScanCompleted();\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/BlockStorageMovementNeeded.java",
          "extendedDetails": {
            "oldValue": "[rootId-Long, itemInfoList-List\u003cItemInfo\u003e]",
            "newValue": "[startId-long, itemInfoList-List\u003cItemInfo\u003e, scanCompleted-boolean]"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-12291: [SPS]: Provide a mechanism to recursively iterate and satisfy storage policy of all the files under the given dir. Contributed by Surendra Singh Lilhore.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "bfd3f8bd8a9ae2186ec3e4addc71f912ec7b8923",
          "commitAuthor": "Uma Maheswara Rao G",
          "commitDateOld": "12/08/18 3:06 AM",
          "commitNameOld": "7ea24fc06c081e2ba6f5f66d212abb14b80c9064",
          "commitAuthorOld": "Uma Maheswara Rao G",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,5 +1,13 @@\n-  private synchronized void addAll(Long rootId,\n-      List\u003cItemInfo\u003e itemInfoList) {\n+  public synchronized void addAll(long startId,\n+      List\u003cItemInfo\u003e itemInfoList, boolean scanCompleted) {\n     storageMovementNeeded.addAll(itemInfoList);\n-    pendingWorkForDirectory.put(rootId, itemInfoList.size());\n+    DirPendingWorkInfo pendingWork \u003d pendingWorkForDirectory.get(startId);\n+    if (pendingWork \u003d\u003d null) {\n+      pendingWork \u003d new DirPendingWorkInfo();\n+      pendingWorkForDirectory.put(startId, pendingWork);\n+    }\n+    pendingWork.addPendingWorkCount(itemInfoList.size());\n+    if (scanCompleted) {\n+      pendingWork.markScanCompleted();\n+    }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public synchronized void addAll(long startId,\n      List\u003cItemInfo\u003e itemInfoList, boolean scanCompleted) {\n    storageMovementNeeded.addAll(itemInfoList);\n    DirPendingWorkInfo pendingWork \u003d pendingWorkForDirectory.get(startId);\n    if (pendingWork \u003d\u003d null) {\n      pendingWork \u003d new DirPendingWorkInfo();\n      pendingWorkForDirectory.put(startId, pendingWork);\n    }\n    pendingWork.addPendingWorkCount(itemInfoList.size());\n    if (scanCompleted) {\n      pendingWork.markScanCompleted();\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/BlockStorageMovementNeeded.java",
          "extendedDetails": {
            "oldValue": "[private, synchronized]",
            "newValue": "[public, synchronized]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-12291: [SPS]: Provide a mechanism to recursively iterate and satisfy storage policy of all the files under the given dir. Contributed by Surendra Singh Lilhore.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "bfd3f8bd8a9ae2186ec3e4addc71f912ec7b8923",
          "commitAuthor": "Uma Maheswara Rao G",
          "commitDateOld": "12/08/18 3:06 AM",
          "commitNameOld": "7ea24fc06c081e2ba6f5f66d212abb14b80c9064",
          "commitAuthorOld": "Uma Maheswara Rao G",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,5 +1,13 @@\n-  private synchronized void addAll(Long rootId,\n-      List\u003cItemInfo\u003e itemInfoList) {\n+  public synchronized void addAll(long startId,\n+      List\u003cItemInfo\u003e itemInfoList, boolean scanCompleted) {\n     storageMovementNeeded.addAll(itemInfoList);\n-    pendingWorkForDirectory.put(rootId, itemInfoList.size());\n+    DirPendingWorkInfo pendingWork \u003d pendingWorkForDirectory.get(startId);\n+    if (pendingWork \u003d\u003d null) {\n+      pendingWork \u003d new DirPendingWorkInfo();\n+      pendingWorkForDirectory.put(startId, pendingWork);\n+    }\n+    pendingWork.addPendingWorkCount(itemInfoList.size());\n+    if (scanCompleted) {\n+      pendingWork.markScanCompleted();\n+    }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public synchronized void addAll(long startId,\n      List\u003cItemInfo\u003e itemInfoList, boolean scanCompleted) {\n    storageMovementNeeded.addAll(itemInfoList);\n    DirPendingWorkInfo pendingWork \u003d pendingWorkForDirectory.get(startId);\n    if (pendingWork \u003d\u003d null) {\n      pendingWork \u003d new DirPendingWorkInfo();\n      pendingWorkForDirectory.put(startId, pendingWork);\n    }\n    pendingWork.addPendingWorkCount(itemInfoList.size());\n    if (scanCompleted) {\n      pendingWork.markScanCompleted();\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/BlockStorageMovementNeeded.java",
          "extendedDetails": {}
        }
      ]
    },
    "7ea24fc06c081e2ba6f5f66d212abb14b80c9064": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-12225: [SPS]: Optimize extended attributes for tracking SPS movements. Contributed by Surendra Singh Lilhore.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "7ea24fc06c081e2ba6f5f66d212abb14b80c9064",
      "commitAuthor": "Uma Maheswara Rao G",
      "diff": "@@ -0,0 +1,5 @@\n+  private synchronized void addAll(Long rootId,\n+      List\u003cItemInfo\u003e itemInfoList) {\n+    storageMovementNeeded.addAll(itemInfoList);\n+    pendingWorkForDirectory.put(rootId, itemInfoList.size());\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void addAll(Long rootId,\n      List\u003cItemInfo\u003e itemInfoList) {\n    storageMovementNeeded.addAll(itemInfoList);\n    pendingWorkForDirectory.put(rootId, itemInfoList.size());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/BlockStorageMovementNeeded.java"
    }
  }
}