{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "NameNodeRpcServer.java",
  "functionName": "append",
  "functionId": "append___src-String__clientName-String__flag-EnumSetWritable__CreateFlag__",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeRpcServer.java",
  "functionStartLine": 820,
  "functionEndLine": 846,
  "numCommitsSeen": 484,
  "timeTaken": 12781,
  "changeHistory": [
    "8fb5ca3f405550828a17e689b9c60ddf7fb95ec1",
    "024c87291cb4cc67282fe5645fb827427cc581c6",
    "7817674a3a4d097b647dd77f1345787dd376d5ea",
    "2848db814a98b83e7546f65a2751e56fb5b2dbe0",
    "db334bb8625da97c7e518cbcf477530c7ba7001e",
    "1556f86a31a54733d6550363aa0e027acca7823b",
    "8e253cb93030642f5a7324bad0f161cd0ad33206",
    "36d1c49486587c2dbb193e8538b1d4510c462fa6",
    "b0632df93ae5d00180b21983d960d50a45f8fb7a",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "8fb5ca3f405550828a17e689b9c60ddf7fb95ec1": "Ybodychange",
    "024c87291cb4cc67282fe5645fb827427cc581c6": "Ybodychange",
    "7817674a3a4d097b647dd77f1345787dd376d5ea": "Ybodychange",
    "2848db814a98b83e7546f65a2751e56fb5b2dbe0": "Ymultichange(Yparameterchange,Ybodychange)",
    "db334bb8625da97c7e518cbcf477530c7ba7001e": "Ybodychange",
    "1556f86a31a54733d6550363aa0e027acca7823b": "Ymultichange(Yreturntypechange,Ybodychange)",
    "8e253cb93030642f5a7324bad0f161cd0ad33206": "Ybodychange",
    "36d1c49486587c2dbb193e8538b1d4510c462fa6": "Ybodychange",
    "b0632df93ae5d00180b21983d960d50a45f8fb7a": "Ymovefromfile",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "8fb5ca3f405550828a17e689b9c60ddf7fb95ec1": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14611. Move handshake secret field from Token to BlockAccessToken. Contributed by Chen Liang.\n",
      "commitDate": "11/07/19 1:23 PM",
      "commitName": "8fb5ca3f405550828a17e689b9c60ddf7fb95ec1",
      "commitAuthor": "Chen Liang",
      "commitDateOld": "17/06/19 4:20 PM",
      "commitNameOld": "6822193ee6d6ac8b08822fa76c89e1dd61c5ddca",
      "commitAuthorOld": "Santosh Marella",
      "daysBetweenCommits": 23.88,
      "commitsBetweenForRepo": 218,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,30 +1,27 @@\n   public LastBlockWithStatus append(String src, String clientName,\n       EnumSetWritable\u003cCreateFlag\u003e flag) throws IOException {\n     checkNNStartup();\n     String clientMachine \u003d getClientMachine();\n     if (stateChangeLog.isDebugEnabled()) {\n       stateChangeLog.debug(\"*DIR* NameNode.append: file \"\n           +src+\" for \"+clientName+\" at \"+clientMachine);\n     }\n     namesystem.checkOperation(OperationCategory.WRITE);\n     CacheEntryWithPayload cacheEntry \u003d RetryCache.waitForCompletion(retryCache,\n         null);\n     if (cacheEntry !\u003d null \u0026\u0026 cacheEntry.isSuccess()) {\n       return (LastBlockWithStatus) cacheEntry.getPayload();\n     }\n \n     LastBlockWithStatus info \u003d null;\n     boolean success \u003d false;\n     try {\n       info \u003d namesystem.appendFile(src, clientName, clientMachine, flag.get(),\n           cacheEntry !\u003d null);\n       success \u003d true;\n     } finally {\n       RetryCache.setState(cacheEntry, success, info);\n     }\n     metrics.incrFilesAppended();\n-    if (shouldSendQOP) {\n-      wrapEstablishedQOP(info.getLastBlock(), getEstablishedClientQOP());\n-    }\n     return info;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public LastBlockWithStatus append(String src, String clientName,\n      EnumSetWritable\u003cCreateFlag\u003e flag) throws IOException {\n    checkNNStartup();\n    String clientMachine \u003d getClientMachine();\n    if (stateChangeLog.isDebugEnabled()) {\n      stateChangeLog.debug(\"*DIR* NameNode.append: file \"\n          +src+\" for \"+clientName+\" at \"+clientMachine);\n    }\n    namesystem.checkOperation(OperationCategory.WRITE);\n    CacheEntryWithPayload cacheEntry \u003d RetryCache.waitForCompletion(retryCache,\n        null);\n    if (cacheEntry !\u003d null \u0026\u0026 cacheEntry.isSuccess()) {\n      return (LastBlockWithStatus) cacheEntry.getPayload();\n    }\n\n    LastBlockWithStatus info \u003d null;\n    boolean success \u003d false;\n    try {\n      info \u003d namesystem.appendFile(src, clientName, clientMachine, flag.get(),\n          cacheEntry !\u003d null);\n      success \u003d true;\n    } finally {\n      RetryCache.setState(cacheEntry, success, info);\n    }\n    metrics.incrFilesAppended();\n    return info;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeRpcServer.java",
      "extendedDetails": {}
    },
    "024c87291cb4cc67282fe5645fb827427cc581c6": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13617. Allow wrapping NN QOP into token in encrypted message. Contributed by Chen Liang\n",
      "commitDate": "13/02/19 12:40 PM",
      "commitName": "024c87291cb4cc67282fe5645fb827427cc581c6",
      "commitAuthor": "Chen Liang",
      "commitDateOld": "24/12/18 9:34 AM",
      "commitNameOld": "652b257478f723a9e119e5e9181f3c7450ac92b5",
      "commitAuthorOld": "Chen Liang",
      "daysBetweenCommits": 51.13,
      "commitsBetweenForRepo": 326,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,27 +1,30 @@\n   public LastBlockWithStatus append(String src, String clientName,\n       EnumSetWritable\u003cCreateFlag\u003e flag) throws IOException {\n     checkNNStartup();\n     String clientMachine \u003d getClientMachine();\n     if (stateChangeLog.isDebugEnabled()) {\n       stateChangeLog.debug(\"*DIR* NameNode.append: file \"\n           +src+\" for \"+clientName+\" at \"+clientMachine);\n     }\n     namesystem.checkOperation(OperationCategory.WRITE);\n     CacheEntryWithPayload cacheEntry \u003d RetryCache.waitForCompletion(retryCache,\n         null);\n     if (cacheEntry !\u003d null \u0026\u0026 cacheEntry.isSuccess()) {\n       return (LastBlockWithStatus) cacheEntry.getPayload();\n     }\n \n     LastBlockWithStatus info \u003d null;\n     boolean success \u003d false;\n     try {\n       info \u003d namesystem.appendFile(src, clientName, clientMachine, flag.get(),\n           cacheEntry !\u003d null);\n       success \u003d true;\n     } finally {\n       RetryCache.setState(cacheEntry, success, info);\n     }\n     metrics.incrFilesAppended();\n+    if (shouldSendQOP) {\n+      wrapEstablishedQOP(info.getLastBlock(), getEstablishedClientQOP());\n+    }\n     return info;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public LastBlockWithStatus append(String src, String clientName,\n      EnumSetWritable\u003cCreateFlag\u003e flag) throws IOException {\n    checkNNStartup();\n    String clientMachine \u003d getClientMachine();\n    if (stateChangeLog.isDebugEnabled()) {\n      stateChangeLog.debug(\"*DIR* NameNode.append: file \"\n          +src+\" for \"+clientName+\" at \"+clientMachine);\n    }\n    namesystem.checkOperation(OperationCategory.WRITE);\n    CacheEntryWithPayload cacheEntry \u003d RetryCache.waitForCompletion(retryCache,\n        null);\n    if (cacheEntry !\u003d null \u0026\u0026 cacheEntry.isSuccess()) {\n      return (LastBlockWithStatus) cacheEntry.getPayload();\n    }\n\n    LastBlockWithStatus info \u003d null;\n    boolean success \u003d false;\n    try {\n      info \u003d namesystem.appendFile(src, clientName, clientMachine, flag.get(),\n          cacheEntry !\u003d null);\n      success \u003d true;\n    } finally {\n      RetryCache.setState(cacheEntry, success, info);\n    }\n    metrics.incrFilesAppended();\n    if (shouldSendQOP) {\n      wrapEstablishedQOP(info.getLastBlock(), getEstablishedClientQOP());\n    }\n    return info;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeRpcServer.java",
      "extendedDetails": {}
    },
    "7817674a3a4d097b647dd77f1345787dd376d5ea": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7609. Avoid retry cache collision when Standby NameNode loading edits. Contributed by Ming Ma.\n",
      "commitDate": "29/05/15 11:05 AM",
      "commitName": "7817674a3a4d097b647dd77f1345787dd376d5ea",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "15/05/15 7:09 PM",
      "commitNameOld": "e5afac5896a1a88e152746598527d91f73cbb724",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 13.66,
      "commitsBetweenForRepo": 105,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,26 +1,27 @@\n   public LastBlockWithStatus append(String src, String clientName,\n       EnumSetWritable\u003cCreateFlag\u003e flag) throws IOException {\n     checkNNStartup();\n     String clientMachine \u003d getClientMachine();\n     if (stateChangeLog.isDebugEnabled()) {\n       stateChangeLog.debug(\"*DIR* NameNode.append: file \"\n           +src+\" for \"+clientName+\" at \"+clientMachine);\n     }\n+    namesystem.checkOperation(OperationCategory.WRITE);\n     CacheEntryWithPayload cacheEntry \u003d RetryCache.waitForCompletion(retryCache,\n         null);\n     if (cacheEntry !\u003d null \u0026\u0026 cacheEntry.isSuccess()) {\n       return (LastBlockWithStatus) cacheEntry.getPayload();\n     }\n \n     LastBlockWithStatus info \u003d null;\n     boolean success \u003d false;\n     try {\n       info \u003d namesystem.appendFile(src, clientName, clientMachine, flag.get(),\n           cacheEntry !\u003d null);\n       success \u003d true;\n     } finally {\n       RetryCache.setState(cacheEntry, success, info);\n     }\n     metrics.incrFilesAppended();\n     return info;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public LastBlockWithStatus append(String src, String clientName,\n      EnumSetWritable\u003cCreateFlag\u003e flag) throws IOException {\n    checkNNStartup();\n    String clientMachine \u003d getClientMachine();\n    if (stateChangeLog.isDebugEnabled()) {\n      stateChangeLog.debug(\"*DIR* NameNode.append: file \"\n          +src+\" for \"+clientName+\" at \"+clientMachine);\n    }\n    namesystem.checkOperation(OperationCategory.WRITE);\n    CacheEntryWithPayload cacheEntry \u003d RetryCache.waitForCompletion(retryCache,\n        null);\n    if (cacheEntry !\u003d null \u0026\u0026 cacheEntry.isSuccess()) {\n      return (LastBlockWithStatus) cacheEntry.getPayload();\n    }\n\n    LastBlockWithStatus info \u003d null;\n    boolean success \u003d false;\n    try {\n      info \u003d namesystem.appendFile(src, clientName, clientMachine, flag.get(),\n          cacheEntry !\u003d null);\n      success \u003d true;\n    } finally {\n      RetryCache.setState(cacheEntry, success, info);\n    }\n    metrics.incrFilesAppended();\n    return info;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeRpcServer.java",
      "extendedDetails": {}
    },
    "2848db814a98b83e7546f65a2751e56fb5b2dbe0": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-3689. Add support for variable length block. Contributed by Jing Zhao.\n",
      "commitDate": "27/01/15 12:58 PM",
      "commitName": "2848db814a98b83e7546f65a2751e56fb5b2dbe0",
      "commitAuthor": "Jing Zhao",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-3689. Add support for variable length block. Contributed by Jing Zhao.\n",
          "commitDate": "27/01/15 12:58 PM",
          "commitName": "2848db814a98b83e7546f65a2751e56fb5b2dbe0",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "21/01/15 11:33 AM",
          "commitNameOld": "db334bb8625da97c7e518cbcf477530c7ba7001e",
          "commitAuthorOld": "Tsz-Wo Nicholas Sze",
          "daysBetweenCommits": 6.06,
          "commitsBetweenForRepo": 43,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,25 +1,26 @@\n-  public LastBlockWithStatus append(String src, String clientName) \n-      throws IOException {\n+  public LastBlockWithStatus append(String src, String clientName,\n+      EnumSetWritable\u003cCreateFlag\u003e flag) throws IOException {\n     checkNNStartup();\n     String clientMachine \u003d getClientMachine();\n     if (stateChangeLog.isDebugEnabled()) {\n       stateChangeLog.debug(\"*DIR* NameNode.append: file \"\n           +src+\" for \"+clientName+\" at \"+clientMachine);\n     }\n-    CacheEntryWithPayload cacheEntry \u003d RetryCache.waitForCompletion(retryCache, null);\n+    CacheEntryWithPayload cacheEntry \u003d RetryCache.waitForCompletion(retryCache,\n+        null);\n     if (cacheEntry !\u003d null \u0026\u0026 cacheEntry.isSuccess()) {\n       return (LastBlockWithStatus) cacheEntry.getPayload();\n     }\n \n     LastBlockWithStatus info \u003d null;\n     boolean success \u003d false;\n     try {\n-      info \u003d namesystem.appendFile(src, clientName, clientMachine,\n+      info \u003d namesystem.appendFile(src, clientName, clientMachine, flag.get(),\n           cacheEntry !\u003d null);\n       success \u003d true;\n     } finally {\n       RetryCache.setState(cacheEntry, success, info);\n     }\n     metrics.incrFilesAppended();\n     return info;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public LastBlockWithStatus append(String src, String clientName,\n      EnumSetWritable\u003cCreateFlag\u003e flag) throws IOException {\n    checkNNStartup();\n    String clientMachine \u003d getClientMachine();\n    if (stateChangeLog.isDebugEnabled()) {\n      stateChangeLog.debug(\"*DIR* NameNode.append: file \"\n          +src+\" for \"+clientName+\" at \"+clientMachine);\n    }\n    CacheEntryWithPayload cacheEntry \u003d RetryCache.waitForCompletion(retryCache,\n        null);\n    if (cacheEntry !\u003d null \u0026\u0026 cacheEntry.isSuccess()) {\n      return (LastBlockWithStatus) cacheEntry.getPayload();\n    }\n\n    LastBlockWithStatus info \u003d null;\n    boolean success \u003d false;\n    try {\n      info \u003d namesystem.appendFile(src, clientName, clientMachine, flag.get(),\n          cacheEntry !\u003d null);\n      success \u003d true;\n    } finally {\n      RetryCache.setState(cacheEntry, success, info);\n    }\n    metrics.incrFilesAppended();\n    return info;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeRpcServer.java",
          "extendedDetails": {
            "oldValue": "[src-String, clientName-String]",
            "newValue": "[src-String, clientName-String, flag-EnumSetWritable\u003cCreateFlag\u003e]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-3689. Add support for variable length block. Contributed by Jing Zhao.\n",
          "commitDate": "27/01/15 12:58 PM",
          "commitName": "2848db814a98b83e7546f65a2751e56fb5b2dbe0",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "21/01/15 11:33 AM",
          "commitNameOld": "db334bb8625da97c7e518cbcf477530c7ba7001e",
          "commitAuthorOld": "Tsz-Wo Nicholas Sze",
          "daysBetweenCommits": 6.06,
          "commitsBetweenForRepo": 43,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,25 +1,26 @@\n-  public LastBlockWithStatus append(String src, String clientName) \n-      throws IOException {\n+  public LastBlockWithStatus append(String src, String clientName,\n+      EnumSetWritable\u003cCreateFlag\u003e flag) throws IOException {\n     checkNNStartup();\n     String clientMachine \u003d getClientMachine();\n     if (stateChangeLog.isDebugEnabled()) {\n       stateChangeLog.debug(\"*DIR* NameNode.append: file \"\n           +src+\" for \"+clientName+\" at \"+clientMachine);\n     }\n-    CacheEntryWithPayload cacheEntry \u003d RetryCache.waitForCompletion(retryCache, null);\n+    CacheEntryWithPayload cacheEntry \u003d RetryCache.waitForCompletion(retryCache,\n+        null);\n     if (cacheEntry !\u003d null \u0026\u0026 cacheEntry.isSuccess()) {\n       return (LastBlockWithStatus) cacheEntry.getPayload();\n     }\n \n     LastBlockWithStatus info \u003d null;\n     boolean success \u003d false;\n     try {\n-      info \u003d namesystem.appendFile(src, clientName, clientMachine,\n+      info \u003d namesystem.appendFile(src, clientName, clientMachine, flag.get(),\n           cacheEntry !\u003d null);\n       success \u003d true;\n     } finally {\n       RetryCache.setState(cacheEntry, success, info);\n     }\n     metrics.incrFilesAppended();\n     return info;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public LastBlockWithStatus append(String src, String clientName,\n      EnumSetWritable\u003cCreateFlag\u003e flag) throws IOException {\n    checkNNStartup();\n    String clientMachine \u003d getClientMachine();\n    if (stateChangeLog.isDebugEnabled()) {\n      stateChangeLog.debug(\"*DIR* NameNode.append: file \"\n          +src+\" for \"+clientName+\" at \"+clientMachine);\n    }\n    CacheEntryWithPayload cacheEntry \u003d RetryCache.waitForCompletion(retryCache,\n        null);\n    if (cacheEntry !\u003d null \u0026\u0026 cacheEntry.isSuccess()) {\n      return (LastBlockWithStatus) cacheEntry.getPayload();\n    }\n\n    LastBlockWithStatus info \u003d null;\n    boolean success \u003d false;\n    try {\n      info \u003d namesystem.appendFile(src, clientName, clientMachine, flag.get(),\n          cacheEntry !\u003d null);\n      success \u003d true;\n    } finally {\n      RetryCache.setState(cacheEntry, success, info);\n    }\n    metrics.incrFilesAppended();\n    return info;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeRpcServer.java",
          "extendedDetails": {}
        }
      ]
    },
    "db334bb8625da97c7e518cbcf477530c7ba7001e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3443. Fix NPE when namenode transition to active during startup by adding checkNNStartup() in NameNodeRpcServer.  Contributed by Vinayakumar B\n",
      "commitDate": "21/01/15 11:33 AM",
      "commitName": "db334bb8625da97c7e518cbcf477530c7ba7001e",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "12/01/15 10:50 PM",
      "commitNameOld": "7e9358feb326d48b8c4f00249e7af5023cebd2e2",
      "commitAuthorOld": "Plamen Jeliazkov",
      "daysBetweenCommits": 8.53,
      "commitsBetweenForRepo": 59,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,25 @@\n   public LastBlockWithStatus append(String src, String clientName) \n       throws IOException {\n+    checkNNStartup();\n     String clientMachine \u003d getClientMachine();\n     if (stateChangeLog.isDebugEnabled()) {\n       stateChangeLog.debug(\"*DIR* NameNode.append: file \"\n           +src+\" for \"+clientName+\" at \"+clientMachine);\n     }\n     CacheEntryWithPayload cacheEntry \u003d RetryCache.waitForCompletion(retryCache, null);\n     if (cacheEntry !\u003d null \u0026\u0026 cacheEntry.isSuccess()) {\n       return (LastBlockWithStatus) cacheEntry.getPayload();\n     }\n \n     LastBlockWithStatus info \u003d null;\n     boolean success \u003d false;\n     try {\n       info \u003d namesystem.appendFile(src, clientName, clientMachine,\n           cacheEntry !\u003d null);\n       success \u003d true;\n     } finally {\n       RetryCache.setState(cacheEntry, success, info);\n     }\n     metrics.incrFilesAppended();\n     return info;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public LastBlockWithStatus append(String src, String clientName) \n      throws IOException {\n    checkNNStartup();\n    String clientMachine \u003d getClientMachine();\n    if (stateChangeLog.isDebugEnabled()) {\n      stateChangeLog.debug(\"*DIR* NameNode.append: file \"\n          +src+\" for \"+clientName+\" at \"+clientMachine);\n    }\n    CacheEntryWithPayload cacheEntry \u003d RetryCache.waitForCompletion(retryCache, null);\n    if (cacheEntry !\u003d null \u0026\u0026 cacheEntry.isSuccess()) {\n      return (LastBlockWithStatus) cacheEntry.getPayload();\n    }\n\n    LastBlockWithStatus info \u003d null;\n    boolean success \u003d false;\n    try {\n      info \u003d namesystem.appendFile(src, clientName, clientMachine,\n          cacheEntry !\u003d null);\n      success \u003d true;\n    } finally {\n      RetryCache.setState(cacheEntry, success, info);\n    }\n    metrics.incrFilesAppended();\n    return info;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeRpcServer.java",
      "extendedDetails": {}
    },
    "1556f86a31a54733d6550363aa0e027acca7823b": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-7210. Avoid two separate RPC\u0027s namenode.append() and namenode.getFileInfo() for an append call from DFSClient. (Vinayakumar B via umamahesh)\n",
      "commitDate": "28/11/14 7:39 AM",
      "commitName": "1556f86a31a54733d6550363aa0e027acca7823b",
      "commitAuthor": "Uma Maheswara Rao G",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-7210. Avoid two separate RPC\u0027s namenode.append() and namenode.getFileInfo() for an append call from DFSClient. (Vinayakumar B via umamahesh)\n",
          "commitDate": "28/11/14 7:39 AM",
          "commitName": "1556f86a31a54733d6550363aa0e027acca7823b",
          "commitAuthor": "Uma Maheswara Rao G",
          "commitDateOld": "24/11/14 11:11 AM",
          "commitNameOld": "8e253cb93030642f5a7324bad0f161cd0ad33206",
          "commitAuthorOld": "Haohui Mai",
          "daysBetweenCommits": 3.85,
          "commitsBetweenForRepo": 17,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,24 @@\n-  public LocatedBlock append(String src, String clientName) \n+  public LastBlockWithStatus append(String src, String clientName) \n       throws IOException {\n     String clientMachine \u003d getClientMachine();\n     if (stateChangeLog.isDebugEnabled()) {\n       stateChangeLog.debug(\"*DIR* NameNode.append: file \"\n           +src+\" for \"+clientName+\" at \"+clientMachine);\n     }\n     CacheEntryWithPayload cacheEntry \u003d RetryCache.waitForCompletion(retryCache, null);\n     if (cacheEntry !\u003d null \u0026\u0026 cacheEntry.isSuccess()) {\n-      return (LocatedBlock) cacheEntry.getPayload();\n+      return (LastBlockWithStatus) cacheEntry.getPayload();\n     }\n \n-    LocatedBlock info \u003d null;\n+    LastBlockWithStatus info \u003d null;\n     boolean success \u003d false;\n     try {\n       info \u003d namesystem.appendFile(src, clientName, clientMachine,\n           cacheEntry !\u003d null);\n       success \u003d true;\n     } finally {\n       RetryCache.setState(cacheEntry, success, info);\n     }\n     metrics.incrFilesAppended();\n     return info;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public LastBlockWithStatus append(String src, String clientName) \n      throws IOException {\n    String clientMachine \u003d getClientMachine();\n    if (stateChangeLog.isDebugEnabled()) {\n      stateChangeLog.debug(\"*DIR* NameNode.append: file \"\n          +src+\" for \"+clientName+\" at \"+clientMachine);\n    }\n    CacheEntryWithPayload cacheEntry \u003d RetryCache.waitForCompletion(retryCache, null);\n    if (cacheEntry !\u003d null \u0026\u0026 cacheEntry.isSuccess()) {\n      return (LastBlockWithStatus) cacheEntry.getPayload();\n    }\n\n    LastBlockWithStatus info \u003d null;\n    boolean success \u003d false;\n    try {\n      info \u003d namesystem.appendFile(src, clientName, clientMachine,\n          cacheEntry !\u003d null);\n      success \u003d true;\n    } finally {\n      RetryCache.setState(cacheEntry, success, info);\n    }\n    metrics.incrFilesAppended();\n    return info;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeRpcServer.java",
          "extendedDetails": {
            "oldValue": "LocatedBlock",
            "newValue": "LastBlockWithStatus"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7210. Avoid two separate RPC\u0027s namenode.append() and namenode.getFileInfo() for an append call from DFSClient. (Vinayakumar B via umamahesh)\n",
          "commitDate": "28/11/14 7:39 AM",
          "commitName": "1556f86a31a54733d6550363aa0e027acca7823b",
          "commitAuthor": "Uma Maheswara Rao G",
          "commitDateOld": "24/11/14 11:11 AM",
          "commitNameOld": "8e253cb93030642f5a7324bad0f161cd0ad33206",
          "commitAuthorOld": "Haohui Mai",
          "daysBetweenCommits": 3.85,
          "commitsBetweenForRepo": 17,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,24 @@\n-  public LocatedBlock append(String src, String clientName) \n+  public LastBlockWithStatus append(String src, String clientName) \n       throws IOException {\n     String clientMachine \u003d getClientMachine();\n     if (stateChangeLog.isDebugEnabled()) {\n       stateChangeLog.debug(\"*DIR* NameNode.append: file \"\n           +src+\" for \"+clientName+\" at \"+clientMachine);\n     }\n     CacheEntryWithPayload cacheEntry \u003d RetryCache.waitForCompletion(retryCache, null);\n     if (cacheEntry !\u003d null \u0026\u0026 cacheEntry.isSuccess()) {\n-      return (LocatedBlock) cacheEntry.getPayload();\n+      return (LastBlockWithStatus) cacheEntry.getPayload();\n     }\n \n-    LocatedBlock info \u003d null;\n+    LastBlockWithStatus info \u003d null;\n     boolean success \u003d false;\n     try {\n       info \u003d namesystem.appendFile(src, clientName, clientMachine,\n           cacheEntry !\u003d null);\n       success \u003d true;\n     } finally {\n       RetryCache.setState(cacheEntry, success, info);\n     }\n     metrics.incrFilesAppended();\n     return info;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public LastBlockWithStatus append(String src, String clientName) \n      throws IOException {\n    String clientMachine \u003d getClientMachine();\n    if (stateChangeLog.isDebugEnabled()) {\n      stateChangeLog.debug(\"*DIR* NameNode.append: file \"\n          +src+\" for \"+clientName+\" at \"+clientMachine);\n    }\n    CacheEntryWithPayload cacheEntry \u003d RetryCache.waitForCompletion(retryCache, null);\n    if (cacheEntry !\u003d null \u0026\u0026 cacheEntry.isSuccess()) {\n      return (LastBlockWithStatus) cacheEntry.getPayload();\n    }\n\n    LastBlockWithStatus info \u003d null;\n    boolean success \u003d false;\n    try {\n      info \u003d namesystem.appendFile(src, clientName, clientMachine,\n          cacheEntry !\u003d null);\n      success \u003d true;\n    } finally {\n      RetryCache.setState(cacheEntry, success, info);\n    }\n    metrics.incrFilesAppended();\n    return info;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeRpcServer.java",
          "extendedDetails": {}
        }
      ]
    },
    "8e253cb93030642f5a7324bad0f161cd0ad33206": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7412. Move RetryCache to NameNodeRpcServer. Contributed by Haohui Mai.\n",
      "commitDate": "24/11/14 11:11 AM",
      "commitName": "8e253cb93030642f5a7324bad0f161cd0ad33206",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "04/11/14 4:02 PM",
      "commitNameOld": "5bd3a569f941ffcfc425a55288bec78a37a75aa1",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 19.8,
      "commitsBetweenForRepo": 170,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,11 +1,24 @@\n   public LocatedBlock append(String src, String clientName) \n       throws IOException {\n     String clientMachine \u003d getClientMachine();\n     if (stateChangeLog.isDebugEnabled()) {\n       stateChangeLog.debug(\"*DIR* NameNode.append: file \"\n           +src+\" for \"+clientName+\" at \"+clientMachine);\n     }\n-    LocatedBlock info \u003d namesystem.appendFile(src, clientName, clientMachine);\n+    CacheEntryWithPayload cacheEntry \u003d RetryCache.waitForCompletion(retryCache, null);\n+    if (cacheEntry !\u003d null \u0026\u0026 cacheEntry.isSuccess()) {\n+      return (LocatedBlock) cacheEntry.getPayload();\n+    }\n+\n+    LocatedBlock info \u003d null;\n+    boolean success \u003d false;\n+    try {\n+      info \u003d namesystem.appendFile(src, clientName, clientMachine,\n+          cacheEntry !\u003d null);\n+      success \u003d true;\n+    } finally {\n+      RetryCache.setState(cacheEntry, success, info);\n+    }\n     metrics.incrFilesAppended();\n     return info;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public LocatedBlock append(String src, String clientName) \n      throws IOException {\n    String clientMachine \u003d getClientMachine();\n    if (stateChangeLog.isDebugEnabled()) {\n      stateChangeLog.debug(\"*DIR* NameNode.append: file \"\n          +src+\" for \"+clientName+\" at \"+clientMachine);\n    }\n    CacheEntryWithPayload cacheEntry \u003d RetryCache.waitForCompletion(retryCache, null);\n    if (cacheEntry !\u003d null \u0026\u0026 cacheEntry.isSuccess()) {\n      return (LocatedBlock) cacheEntry.getPayload();\n    }\n\n    LocatedBlock info \u003d null;\n    boolean success \u003d false;\n    try {\n      info \u003d namesystem.appendFile(src, clientName, clientMachine,\n          cacheEntry !\u003d null);\n      success \u003d true;\n    } finally {\n      RetryCache.setState(cacheEntry, success, info);\n    }\n    metrics.incrFilesAppended();\n    return info;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeRpcServer.java",
      "extendedDetails": {}
    },
    "36d1c49486587c2dbb193e8538b1d4510c462fa6": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2693. Fix synchronization issues around state transition. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1221582 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/12/11 7:03 PM",
      "commitName": "36d1c49486587c2dbb193e8538b1d4510c462fa6",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "18/12/11 9:24 PM",
      "commitNameOld": "329717264f8380a1f0fd2cdabd1bf0517ff1067b",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 1.9,
      "commitsBetweenForRepo": 8,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,11 @@\n   public LocatedBlock append(String src, String clientName) \n       throws IOException {\n-    nn.checkOperation(OperationCategory.WRITE);\n     String clientMachine \u003d getClientMachine();\n     if (stateChangeLog.isDebugEnabled()) {\n       stateChangeLog.debug(\"*DIR* NameNode.append: file \"\n           +src+\" for \"+clientName+\" at \"+clientMachine);\n     }\n     LocatedBlock info \u003d namesystem.appendFile(src, clientName, clientMachine);\n     metrics.incrFilesAppended();\n     return info;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public LocatedBlock append(String src, String clientName) \n      throws IOException {\n    String clientMachine \u003d getClientMachine();\n    if (stateChangeLog.isDebugEnabled()) {\n      stateChangeLog.debug(\"*DIR* NameNode.append: file \"\n          +src+\" for \"+clientName+\" at \"+clientMachine);\n    }\n    LocatedBlock info \u003d namesystem.appendFile(src, clientName, clientMachine);\n    metrics.incrFilesAppended();\n    return info;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeRpcServer.java",
      "extendedDetails": {}
    },
    "b0632df93ae5d00180b21983d960d50a45f8fb7a": {
      "type": "Ymovefromfile",
      "commitMessage": "HDFS-2197. Refactor RPC call implementations out of NameNode class. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1165463 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "05/09/11 5:41 PM",
      "commitName": "b0632df93ae5d00180b21983d960d50a45f8fb7a",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "05/09/11 5:34 PM",
      "commitNameOld": "d1438b501dae9efc7aa84de35a57e1b8e6f5645e",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public LocatedBlock append(String src, String clientName) \n      throws IOException {\n    String clientMachine \u003d getClientMachine();\n    if (stateChangeLog.isDebugEnabled()) {\n      stateChangeLog.debug(\"*DIR* NameNode.append: file \"\n          +src+\" for \"+clientName+\" at \"+clientMachine);\n    }\n    LocatedBlock info \u003d namesystem.appendFile(src, clientName, clientMachine);\n    metrics.incrFilesAppended();\n    return info;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeRpcServer.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeRpcServer.java",
        "oldMethodName": "append",
        "newMethodName": "append"
      }
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public LocatedBlock append(String src, String clientName) \n      throws IOException {\n    String clientMachine \u003d getClientMachine();\n    if (stateChangeLog.isDebugEnabled()) {\n      stateChangeLog.debug(\"*DIR* NameNode.append: file \"\n          +src+\" for \"+clientName+\" at \"+clientMachine);\n    }\n    LocatedBlock info \u003d namesystem.appendFile(src, clientName, clientMachine);\n    metrics.incrFilesAppended();\n    return info;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public LocatedBlock append(String src, String clientName) \n      throws IOException {\n    String clientMachine \u003d getClientMachine();\n    if (stateChangeLog.isDebugEnabled()) {\n      stateChangeLog.debug(\"*DIR* NameNode.append: file \"\n          +src+\" for \"+clientName+\" at \"+clientMachine);\n    }\n    LocatedBlock info \u003d namesystem.appendFile(src, clientName, clientMachine);\n    metrics.incrFilesAppended();\n    return info;\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,11 @@\n+  public LocatedBlock append(String src, String clientName) \n+      throws IOException {\n+    String clientMachine \u003d getClientMachine();\n+    if (stateChangeLog.isDebugEnabled()) {\n+      stateChangeLog.debug(\"*DIR* NameNode.append: file \"\n+          +src+\" for \"+clientName+\" at \"+clientMachine);\n+    }\n+    LocatedBlock info \u003d namesystem.appendFile(src, clientName, clientMachine);\n+    metrics.incrFilesAppended();\n+    return info;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public LocatedBlock append(String src, String clientName) \n      throws IOException {\n    String clientMachine \u003d getClientMachine();\n    if (stateChangeLog.isDebugEnabled()) {\n      stateChangeLog.debug(\"*DIR* NameNode.append: file \"\n          +src+\" for \"+clientName+\" at \"+clientMachine);\n    }\n    LocatedBlock info \u003d namesystem.appendFile(src, clientName, clientMachine);\n    metrics.incrFilesAppended();\n    return info;\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java"
    }
  }
}